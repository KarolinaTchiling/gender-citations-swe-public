FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Droua-Hamdani, G
AF Droua-Hamdani, Ghania
TI Design of accent classifier based on speech rhythm features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rhythm metrics; MLP-NN classifier; Native speakers; Non-native speakers;
   Gender; Statistical analysis; Modern Standard Arabic
AB Recognition systems suffer from significant performance degradation when operating in foreign accent conditions. Speech rhythm, which is considered the most discriminating prosody parameter, has been proposed in the study to help recognition systems overcome the mismatching issue. Thus, the study presents a new approach to evaluating the MLP classifier based on the speech rhythm of native and non-native speakers by involving statistical knowledge. The gender of speakers was also investigated. Nine measures of speech rate were computed using the most established rhythm models. The set of statistical analyses was conducted to obtain an overall picture of speakers' rhythm variability. For the recognition tasks, the engine was learned and tested using a set of combined rhythm metric vectors. The statistical analysis results helped us to explain some unexpected recognition outcomes and to choose the most suitable rhythm metrics to achieve our objectives. From all the experiments, the most appropriate rhythmic metric to categorize native and non-native speakers is the framework that combines VarcoX and CCI rhythmic measures. The recognition accuracy then reached about 81%. The efficiency of the system increased by about 9% compared to the other configurations. The performance of the system increases significantly (87%) when only male rhythm values are used.
C1 [Droua-Hamdani, Ghania] Ctr Rech Sci & Tech Dev Langue Arabe CRSTDLA, Algiers, Algeria.
RP Droua-Hamdani, G (corresponding author), Ctr Rech Sci & Tech Dev Langue Arabe CRSTDLA, Algiers, Algeria.
EM gh.droua@post.com
RI Droua-Hamdani, Ghania/ITT-4977-2023
OI Droua-Hamdani, Ghania/0000-0001-7291-1872
CR Abercrombie David., 1967, ELEMENTS GEN PHONETI
   Bertinetto PM, 2008, P 4 INT C SPEECH PRO, P427
   Bhargava M, 2013, Arxiv, DOI arXiv:1303.1761
   Boll-Avetisyan N, 2020, P 9 INT C SPEECH PRO
   Dellwo V, 2006, LANGUAGE LANGUAGE PR
   Ding HW, 2020, INTERSPEECH, P4481, DOI 10.21437/Interspeech.2020-2207
   Droua-Hamdani G., 2013, P 1 INT C COMM SIGN, P1, DOI DOI 10.1109/ICCSPA.2013.6487262
   Droua-Hamdani G, 2019, LECT NOTES ARTIF INT, V11658, P75, DOI 10.1007/978-3-030-26061-3_8
   Droua-Hamdani G, 2015, INT CONF INTELL SYST, P325, DOI 10.1109/ISDA.2015.7489248
   Droua-Hamdani G, 2016, ARAB J SCI ENG, V41, P1173, DOI 10.1007/s13369-015-1962-9
   Droua-Hamdani G, 2012, INT J SPEECH TECHNOL, V15, P487, DOI 10.1007/s10772-012-9146-4
   Gasparini L, 2021, COGNITION, V213, DOI 10.1016/j.cognition.2021.104757
   Grabe E, 2002, PHONOL PHONET, V4-1, P515
   Hernandez A, 2020, INTERSPEECH, P2897, DOI 10.21437/Interspeech.2020-2354
   Ioffe S., 2015, P INT C MACH LEARN, VVolume 1, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Jayalakshmi T., 2011, IJCTE, V3, P1, DOI [10.7763/IJCTE.2011.V3.288, DOI 10.7763/IJCTE.2011.V3.288]
   Kyriakopoulos K, 2019, INTERSPEECH, P1836, DOI 10.21437/Interspeech.2019-3186
   Ladefoged P., 1975, A course in phonetics
   Lin BH, 2021, IEEE W SP LANG TECH, P713, DOI 10.1109/SLT48900.2021.9383455
   Linguistic Data Consortium LDC, US
   Liss JM, 2009, J SPEECH LANG HEAR R, V52, P1334, DOI 10.1044/1092-4388(2009/08-0208)
   Maffia M, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.668291
   Mahdavi R, 2020, IEEE INT COMPUT C, P1
   Mary L, 2018, Extraction of Prosody for Automatic Speaker, Language, Emotion and Speech Recognition
   MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5
   Nguyen A.T. T., 2018, The Linguistics Journal, V12, P22
   Pike K., 1946, The Intonation of American English, V2nd
   Polyanskaya L, 2017, LANG SPEECH, V60, P333, DOI 10.1177/0023830916648720
   Radzikowski K, 2019, P VOLUME 11176 PHOTO, V11176, P750, DOI DOI 10.1007/978-3-030-26061-3_8
   Ramus F, 1999, COGNITION, V73, P265, DOI 10.1016/S0010-0277(99)00058-X
   Sabira I., 2014, LINGUISTICS LIT STUD, V2, P185
   Shuju S, 2016, P 2016 10 INT S CHIN, P1
   Vazquez LQ, 2018, ISAPH 2018 INT S APP
   White L, 2007, J PHONETICS, V35, P501, DOI 10.1016/j.wocn.2007.02.003
NR 34
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21715
EP 21728
DI 10.1007/s11042-023-14724-3
EA FEB 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000936195100014
DA 2024-07-18
ER

PT J
AU Haghanifar, A
   Majdabadi, MM
   Haghanifar, S
   Choi, Y
   Ko, SB
AF Haghanifar, Arman
   Majdabadi, Mahdiyar Molahasani
   Haghanifar, Sina
   Choi, Younhee
   Ko, Seok-Bum
TI PaXNet: Tooth segmentation and dental caries detection in panoramic
   X-ray using ensemble transfer learning and capsule classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dental caries detection; Image classification; Deep learning;
   Convolutional neural networks
ID APPROXIMAL CARIES; ACCURACY; IMAGES
AB Dental caries is one of the most chronic diseases involving the majority of the population during their lifetime. Caries lesions are typically diagnosed by general dentists relying only on their visual inspection using dental x-rays. In many cases, dental caries is hard to identify in x-rays and can be misinterpreted as shadows due to the low image quality. In this research study, we propose an automatic diagnosis system to detect dental caries in Panoramic images, which benefits from various deep pretrained models through transfer learning to extract relevant features and uses a capsule network to draw prediction results. Using a dataset of 470 Panoramic images, our model achieved an accuracy of 86.05% on the test set. The obtained score demonstrates acceptable detection performance and an increase in caries detection speed, as long as the challenges of using Panoramic x-rays are taken into account. Among carious samples, our model acquired recall scores of 69.44% and 90.52% for mild and severe ones, confirming the fact that severe caries spots are more straightforward to detect and efficient mild caries detection needs a larger dataset. Considering the novelty of current study as using Panoramic images, following work is a step towards developing a fully automated system to assist domain experts.
C1 [Haghanifar, Arman; Ko, Seok-Bum] Univ Saskatchewan, Div Biomed Engn, Saskatoon, SK, Canada.
   [Majdabadi, Mahdiyar Molahasani; Ko, Seok-Bum] Univ Saskatchewan, Dept Elect & Comp Engn, Saskatoon, SK, Canada.
   [Haghanifar, Sina] Babol Univ Med Sci, Dent Fac, Dept Oral Maxillofacial Radiol, Babol, Iran.
   [Choi, Younhee] Int Rd Dynam, Saskatoon, SK, Canada.
C3 University of Saskatchewan; University of Saskatchewan; Babol University
   of Medical Sciences
RP Ko, SB (corresponding author), Univ Saskatchewan, Div Biomed Engn, Saskatoon, SK, Canada.; Ko, SB (corresponding author), Univ Saskatchewan, Dept Elect & Comp Engn, Saskatoon, SK, Canada.
EM seokbum.ko@usask.ca
RI Ko, Seokbum/H-8366-2012; Molahasani Majdabadi, Mahdiyar/AHE-4246-2022
OI Ko, Seokbum/0000-0002-9287-317X; 
CR Abdel-Mottaleb M, 2003, Proceedings of the 46th IEEE International Midwest Symposium on Circuits & Systems, Vols 1-3, P411
   Akarslan ZZ, 2008, DENTOMAXILLOFAC RAD, V37, P458, DOI 10.1259/dmfr/84698143
   Akkaya N, 2006, DENTOMAXILLOFAC RAD, V35, P170, DOI 10.1259/dmfr/26750940
   Al-sherif N, 2012, 2012 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P145, DOI 10.1109/ISM.2012.35
   Amrollahi P, 2016, MAT SCI ENG C-MATER, V69, P1383, DOI 10.1016/j.msec.2016.08.045
   Beltran-Aguilar Eugenio D., 2005, Morbidity and Mortality Weekly Report, V54, P1
   Casalegno F, 2019, J DENT RES, V98, P1227, DOI 10.1177/0022034519871884
   Choi J, 2018, J SIGNAL PROCESS SYS, V90, P87, DOI 10.1007/s11265-016-1214-6
   Fejerskov O., 2008, DENT CARIES DIS ITS
   Flint DJ, 1998, ORAL SURG ORAL MED O, V85, P731, DOI 10.1016/S1079-2104(98)90043-9
   Fried D., 2020, Opt. PhotonicsNews, V31, P48, DOI [10.1364/OPN.31.5.000048, DOI 10.1364/OPN.31.5.000048]
   Goldberg DE, 2006, Genetic algorithms
   HAGHANIFAR A, 2020, 2020 IEEE INT S CIRC, DOI DOI 10.1021/ACSNANO.0C06452
   Haghanifar A, 2018, IRAN CONF ELECTR ENG, P976, DOI 10.1109/ICEE.2018.8472687
   Harlan J., 2016, INT J ADV SCI ENG IN, DOI [10.18517/ijaseit.6.6.1480, DOI 10.18517/IJASEIT.6.6.1480]
   Iesmantas T, 2018, LECT NOTES COMPUT SC, V10882, P853, DOI 10.1007/978-3-319-93000-8_97
   Jader G, 2018, SIBGRAPI, P400, DOI 10.1109/SIBGRAPI.2018.00058
   Khan HA, 2020, OR SURG OR MED OR PA
   Laishram Anuradha, 2020, 2020 7th International Conference on Signal Processing and Integrated Networks (SPIN), P423, DOI 10.1109/SPIN48934.2020.9071242
   Lee JH, 2018, J DENT, V77, P106, DOI 10.1016/j.jdent.2018.07.015
   Lira Pedro H.M., 2009, P WORKSHOP COMPUTING
   Majdabadi MM, 2020, 2020 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC)
   Martínez-Rus F, 2011, INT J PROSTHODONT, V24, P144
   Majdabadi MM, 2020, MULTIMED TOOLS APPL, V79, P31205, DOI 10.1007/s11042-020-09489-y
   Nomir O, 2005, PATTERN RECOGN, V38, P1295, DOI 10.1016/j.patcog.2004.12.010
   Olberg JV, 2016, SCAND J FORENSIC SCI, V22, P44, DOI 10.1515/sjfs-2016-0008
   Oliveira J, 2011, COMPUT METH APPL SCI, V19, P175, DOI 10.1007/978-94-007-0011-6_10
   Pal A, 2018, LECT NOTES COMPUT SC, V11071, P389, DOI 10.1007/978-3-030-00934-2_44
   Pitts NB., 2016, White Paper on Dental Caries Prevention and Management
   Qu XM, 2011, EUR J RADIOL, V79, pE24, DOI 10.1016/j.ejrad.2009.05.063
   Rad AE, 2018, MULTIMED TOOLS APPL, V77, P28843, DOI 10.1007/s11042-018-6035-0
   Rajpurkar P, 2017, Arxiv, DOI arXiv:1711.05225
   Ramachandran P., 2017, ARXIV
   Sabour S, 2017, ADV NEUR IN, V30
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Selwitz RH, 2007, LANCET, V369, P51, DOI 10.1016/S0140-6736(07)60031-2
   Sheta A, 2012, INT CONF MULTIMED, P83
   Silva G, 2018, EXPERT SYST APPL, V107, P15, DOI 10.1016/j.eswa.2018.04.001
   Smith LN, 2017, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV.2017.58
   Srivastava MM, 2017, ARXIV
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tagliaferro EPS, 2019, OPER DENT, V44, pE23, DOI 10.2341/18-034-C
   Tang B, 2019, IEEE ACCESS, V7, P26022, DOI 10.1109/ACCESS.2019.2901049
   Zhao TM, 2019, IEEE ACCESS, V7, P49691, DOI 10.1109/ACCESS.2019.2911056
NR 44
TC 5
Z9 5
U1 4
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27659
EP 27679
DI 10.1007/s11042-023-14435-9
EA FEB 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000934850300010
DA 2024-07-18
ER

PT J
AU Jiang, YH
   Zheng, LK
AF Jiang, Yuhang
   Zheng, Lukun
TI Deep learning for video game genre classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video games; Genre classification; Multi-modal learning; Transfer
   learning; Neural networks
AB In this paper, we propose a new multi-modal deep learning framework with a visual modality and a textual modality for video game genre classification. The proposed framework consists of three parts: two deeep networks for textual data and imaginary data, a feature concatenation algorithm, and then a softmax classifier. Video game covers and textual descriptions are usually the very first impression to its consumers and they often convey important information about the video games. Video game genre classification based on its cover and textual description would be utterly beneficial to many modern identification, collocation, and retrieval systems. At the same time, it is also an extremely challenging task due to the following reasons: First, there exists a wide variety of video game genres, many of which are not concretely defined. Second, video game covers vary in many different ways such as colors, styles, textual information, etc, even for games of the same genre. Third, cover designs and textual descriptions may vary due to many external factors such as country, culture, target reader populations, etc. With the growing competitiveness in the video game industry, the cover designers and typographers push the cover designs to its limit in the hope of attracting sales. The computer-based automatic video game genre classification systems become a particularly exciting research topic in recent years. The contribution of this paper is four-fold. First, we compiles a large dataset consisting of 50,000 video games from 21 genres made of cover images, description text, and title text and the genre information. Second, image-based and text-based, state-of-the-art models are evaluated thoroughly for the task of genre classification for video games. Third, we developed an efficient and scalable multi-modal framework based on both images and texts. Fourth, a thorough analysis of the experimental results is given and future works to improve the performance is suggested. The results show that the multi-modal framework outperforms the current state-of-the-art image-based or text-based models. Several challenges are outlined for this task. More efforts and resources are needed for this classification task in order to reach a satisfactory level.
C1 [Jiang, Yuhang; Zheng, Lukun] Western Kentucky Univ, 1906 Coll Hts Blvd, Bowling Green, KY 42101 USA.
C3 Western Kentucky University
RP Zheng, LK (corresponding author), Western Kentucky Univ, 1906 Coll Hts Blvd, Bowling Green, KY 42101 USA.
EM lukun.zheng@wku.edu
CR Amiriparian S, 2019, IEEE T GAMES
   Barr M, 2017, COMPUT EDUC, V113, P86, DOI 10.1016/j.compedu.2017.05.016
   Bean AM, 2017, PROF PSYCHOL-RES PR, V48, P378, DOI 10.1037/pro0000150
   Biradar Ganeshprasad R., 2019, 2019 IEEE International Conference on Intelligent Systems and Green Technology (ICISGT). Proceedings, P72, DOI 10.1109/ICISGT44072.2019.00031
   Buczkowski P, 2018, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS (ICPRAM 2018), P309, DOI 10.5220/0006556103090316
   Cao CS, 2018, GENOM PROTEOM BIOINF, V16, P17, DOI 10.1016/j.gpb.2017.07.003
   Cer D., 2018, ARXIV
   Chiang H., 2015, CLASSIFICATION BOOK
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Clarke RI, 2017, GAMES CULT, V12, P445, DOI 10.1177/1555412015591900
   Costa YMG, 2017, APPL SOFT COMPUT, V52, P28, DOI 10.1016/j.asoc.2016.12.024
   Cui C, 2022, ARXIV
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dieleman S., 2011, 12th International Society for Music Information Retrieval Conference (ISMIR-2011), P669
   Dong M, 2018, ARXIV
   Ebner M, 2013, VIDEO GAME DESCRIPTI
   Fang J., 2017, ISMIR, P464, DOI 10.5281/zenodo.1416946
   Feng D, 2021, IEEE T INTELL TRANSP, V22, P1341, DOI 10.1109/TITS.2020.2972974
   Ferguson CJ, 2018, ANNU REV LAW SOC SCI, V14, P411, DOI 10.1146/annurev-lawsocsci-101317-031036
   Goh GB, 2017, J COMPUT CHEM, V38, P1291, DOI 10.1002/jcc.24764
   Gouyon F., 2004, Proc. AES 25th International Conference, P196
   Guggisberg M, 2020, AGGRESS VIOLENT BEH, V53, DOI 10.1016/j.avb.2020.101432
   Guo YL, 2021, IEEE T PATTERN ANAL, V43, P4338, DOI 10.1109/TPAMI.2020.3005434
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang Yu, 2021, ADV NEUR IN
   Iwana B.K., 2016, ARXIV
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Keeler KR, 2020, VISIONS RES MUSIC ED
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kundu C., 2020, ARXIV
   Laurier C, 2008, SEVENTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P688, DOI 10.1109/ICMLA.2008.96
   Logan, 2000, ISMIR, P1
   Lougheed T, 2019, VIDEO GAMES BRING NE
   Lucieri A., 2020, SN COMPUT SCI, V1, P1, DOI [10.1007/s42979-020-00132-z, DOI 10.1007/S42979-020-00132-Z]
   Mater AC, 2019, J CHEM INF MODEL, V59, P2545, DOI 10.1021/acs.jcim.9b00266
   Mayo MJ, 2009, SCIENCE, V323, P79, DOI 10.1126/science.1166900
   Newman James., 2013, Videogames, V2nd
   Nguyen ND, 2022, NAT COMPUT SCI, V2, P38, DOI 10.1038/s43588-021-00185-x
   Oramas S, 2017, ARXIV
   Oramas S., 2016, 17 INT SOC MUSIC INF
   Oramas S., 2018, T INT SOC MUSIC INFO, V1, P4, DOI DOI 10.5334/TISMIR.10
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Pitner G, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9371899
   Ravì D, 2017, IEEE J BIOMED HEALTH, V21, P4, DOI 10.1109/JBHI.2016.2636665
   Sahu S, 2019, INTERSPEECH, P3302, DOI 10.21437/Interspeech.2019-1149
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Squire K., 2003, INT J INTELLIGENT SI, V2, P49, DOI DOI 10.1145/950566.950583
   Strubell Emma, 2019, ARXIV
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang LL, 2019, IEEE T COGN DEV SYST, V11, P107, DOI 10.1109/TCDS.2018.2866587
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Zhang WB, 2016, INTERSPEECH, P3304, DOI 10.21437/Interspeech.2016-1236
   Zhou DX, 2020, APPL COMPUT HARMON A, V48, P787, DOI 10.1016/j.acha.2019.06.004
NR 57
TC 0
Z9 0
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21085
EP 21099
DI 10.1007/s11042-023-14560-5
EA FEB 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000934222700004
DA 2024-07-18
ER

PT J
AU Saha, S
   Senapati, A
   Maity, R
AF Saha, Sangita
   Senapati, Apurbalal
   Maity, Ranjan
TI An approach to predict the task efficiency of web pages
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Usability evaluation; Efficiency modeling; Computational model;
   Empirical study; Machine learning; Support vector regression; Analysis
   of Variance (ANOVA); Support Vector Machine (SVM)
ID COMPUTATIONAL MODEL; THINKING ALOUD; INFORMATION; QUALITY
AB Usability is generally considered as a metric to judge the efficacy of any interface. This is also true for the web pages of a website. There are different factors - efficiency, memorability, learnability, errors, and aesthetics play significant roles in order to determine usability. In this work, we proposed a computational model to predict the efficiency with which users can do a particular task on a website. We considered seventeen features of web pages that may affect the efficiency of a task. The statistical significance of these features was tested based on the empirical data collected using twenty websites. For each website, a representative task was identified. Twenty participants completed these tasks using a controlled environment within a group. Task completion times were recorded for feature identification. The one Dimensional ANOVA study reveals sixteen out of the seventeen are statistically significant for efficiency measurement. Using these features, a computational model was developed based on the Support Vector Regression. Experimental results show that our model can predict the efficiency of web pages' tasks with an accuracy of 90.64%.
C1 [Saha, Sangita; Senapati, Apurbalal; Maity, Ranjan] Cent Inst Technol Kokrajhar, Dept Comp Sci & Engn, Kokrajhar 783370, Assam, India.
RP Saha, S (corresponding author), Cent Inst Technol Kokrajhar, Dept Comp Sci & Engn, Kokrajhar 783370, Assam, India.
EM sangitasaha1234@gmail.com; a.senapati@cit.ac.in; r.maity@cit.ac.in
RI Senapati, Apurbalal/AAS-4087-2021; Maity, Ranjan/ABD-9545-2020; Maity,
   Ranjan/IUN-0034-2023
OI Senapati, Apurbalal/0000-0001-9124-2563; Maity,
   Ranjan/0000-0002-6865-1067; Maity, Ranjan/0000-0002-6865-1067
CR Agoston, 2005, COMPUTER GRAPHICS GE
   Alhadreti O, 2017, J USABILITY STUD, V12, P111
   [Anonymous], 1983, The Psychology of Human-Computer Interaction
   [Anonymous], 2001, IBM COST JUSTIFYING
   [Anonymous], 2014, Journal of Online Learning and Teaching
   Berry LH, 2000, INSTRUCTIONAL AND COGNITIVE IMPACTS OF WEB-BASED EDUCATION, P41
   Blackmon M. H., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P463, DOI 10.1145/503376.503459
   Boren MT, 2000, IEEE T PROF COMMUN, V43, P261, DOI 10.1109/47.867942
   Borges J., 1996, Conference Companion on Human Factors in Computing Systems: Common Ground, April 1996, Vancouver, Canada, P277, DOI DOI 10.1145/257089.257320
   Bylinskii Z, 2015, THESIS MIT
   Card S., 1983, The psychology of human computer interaction, DOI DOI 10.1201/9780203736166
   CARD SK, 1980, COMMUN ACM, V23, P396, DOI 10.1145/358886.358895
   Cawley GC, 2010, J MACH LEARN RES, V11, P2079
   Cohendet R, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P178, DOI 10.1145/3206025.3206056
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Faraday P, 2000, SPRING COMP SCI, P155
   Fetterly D, 2004, SOFTWARE PRACT EXPER, V34, P213, DOI 10.1002/spe.577
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Galitz W. O., 2007, The essential guide to user interface design: An introduction to gui design principles and techniques, V3rd ed.
   Hick WE, 1952, Q J EXP PSYCHOL, V4, P11, DOI 10.1080/17470215208416600
   Hill AL, 2001, READABILITY SCREEN D
   HYMAN R, 1953, J EXP PSYCHOL, V45, P188, DOI 10.1037/h0056940
   Ivory M. Y., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P53, DOI 10.1145/365024.365035
   John B., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P147, DOI 10.1145/503376.503404
   Kieras D.E., 1988, HDB HUMAN COMPUTER I, P135, DOI DOI 10.1016/B978-0-444-47970536-5.50012-9
   Kieras David., 1994, CHI 94, P371
   Landauer Thomas K., 2007, Handbook of latent semantic analysis
   Larson K., 1998, P ACM C HUMAN FACTOR, P25, DOI DOI 10.1145/274644.274649
   Lee S, 2020, INT J HUM-COMPUT INT, V36, P199, DOI 10.1080/10447318.2019.1625569
   Liu WY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376878
   Mahatody T, 2010, INT J HUM-COMPUT INT, V26, P741, DOI 10.1080/10447311003781409
   Maity R., 2015, OZCHI 2015 BEING HUM, P44, DOI [10.1145/2838739.2838743, DOI 10.1145/2838739.2838743]
   Maity R, 2020, INT J TECHNOL HUM IN, V16, P53, DOI 10.4018/IJTHI.2020040105
   Maity R, 2019, IEEE T COMPUT SOC SY, V6, P149, DOI 10.1109/TCSS.2019.2891126
   Maity R, 2017, LECT NOTES COMPUT SC, V10515, P85, DOI 10.1007/978-3-319-67687-6_7
   Maity R, 2016, PROCEDIA COMPUT SCI, V84, P152, DOI 10.1016/j.procs.2016.04.081
   Morris ME, 1996, WEB PAGE DESIGN DIFF
   Nielsen, 1994, USABILITY ENG
   NIELSEN J, 1994, INT J HUM-COMPUT ST, V41, P385, DOI 10.1006/ijhc.1994.1065
   Nielsen J., 2012, Usability 101: Introduction to Usability
   Nielsen Jakob., 1995, CONDUCT HEURISTIC EV, V1, P1
   Oulasvirta Antti, 2019, Interactions, V26, P52, DOI DOI 10.1145/3330340
   Quiñones D, 2017, COMPUT STAND INTER, V53, P89, DOI 10.1016/j.csi.2017.03.009
   Saha S, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9534391
   Seow SC, 2005, HUM-COMPUT INTERACT, V20, P315, DOI 10.1207/s15327051hci2003_3
   Shneiderman B., 2010, DESIGNING USER INTER
   Singh P, 2010, INT CONF NETWORK INF, P29, DOI 10.1109/ICNIT.2010.5508563
   Smith-Jackson TL, 2004, HDB HUMAN FACTORS ER, P785
   Squalli-Houssaini H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2371, DOI 10.1109/ICASSP.2018.8462292
NR 49
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 25217
EP 25233
DI 10.1007/s11042-023-14619-3
EA FEB 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000939670800006
PM 36820085
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Suresh, PPJ
   Acharya, UD
   Reddy, NVS
AF Suresh, P. P. Jashma
   Acharya, U. Dinesh
   Reddy, N. V. Subba
TI Mining frequent Itemsets from transaction databases using hybrid
   switching framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data mining; Frequent itemsets; Data structures; Hashing; Optimization
ID FP-TREE; ALGORITHM; PREPOST(+)
AB With the growing volume of data, mining Frequent Itemsets remains of paramount importance. These have applications in various domains such as market basket analysis, clustering, classification, software bug detection web-mining to name a few. Over the recent years, several "data-structures" were employed to mine "frequent itemsets". Unfortunately, many of them showed less efficiency in runtime or memory. This resulted in the design of Hybrid Frameworks that uses a combination of two or more data structures to extract frequent itemsets. This exploiting the benefits of different data structures while minimizing their drawbacks. This paper employs a tree-based data structure named as NegNodesets in collaboration with the list-based structure N-list for developing a novel Hybrid Framework for mining the frequent itemsets. NegNodesets have the advantage of employing bitmaps for generating a concise representation of itemsets. The N-list structure on the other hand depends on list based intersection operation for generating frequent itemsets, which is much faster than other conventional approaches. Transaction merging concept is utilized in this work to minimize the run time by merging several transactions into a single itemset. A switching criterion depends on the length of nodelist is used for switching between the algorithms. The efficacy of this approach has been enhanced by using a hash-based mechanism for generating the final set of frequent item sets. JAVA is the programming language used for coding the algorithms. The simulation analysis is carried out to know the efficacy of proposed approach in run time, memory consumption and compared with some existing approaches. From the comparative analysis, it is proved that the proposed NPLengthSwitch consumes lesser memory and run time than other techniques.
C1 [Suresh, P. P. Jashma; Acharya, U. Dinesh] Manipal Acad Higher Educ, Manipal Inst Technol, Dept Comp Sci & Engn, Manipal 576104, Karnataka, India.
   [Reddy, N. V. Subba] Manipal Acad Higher Educ, Manipal Inst Technol Bengaluru, Dept Informat Technol, Bengaluru 560064, Karnataka, India.
C3 Manipal Academy of Higher Education (MAHE); Manipal Academy of Higher
   Education (MAHE)
RP Acharya, UD (corresponding author), Manipal Acad Higher Educ, Manipal Inst Technol, Dept Comp Sci & Engn, Manipal 576104, Karnataka, India.
EM dinesh.acharya@manipal.edu
OI Acharya, Dinesh/0000-0002-0304-4725
CR Aryabarzan N, 2018, EXPERT SYST APPL, V105, P129, DOI 10.1016/j.eswa.2018.03.041
   Vo B, 2020, KNOWL-BASED SYST, V201, DOI 10.1016/j.knosys.2020.106064
   Bhatt R., 2010, SKIN SEGMENTATION DA
   Bui H, 2021, APPL INTELL, V51, P1439, DOI 10.1007/s10489-020-01899-7
   Bustio-Martínez L, 2019, J PARALLEL DISTR COM, V125, P58, DOI 10.1016/j.jpdc.2018.11.002
   Chen DD, 2015, ONLINE RETAIL DATA S
   Chon KW, 2018, INFORM SCIENCES, V439, P19, DOI 10.1016/j.ins.2018.01.046
   Cui YL, 2022, APPL INTELL, V52, P3387, DOI 10.1007/s10489-021-02574-1
   Davashi R, 2021, ENG APPL ARTIF INTEL, V106, DOI 10.1016/j.engappai.2021.104477
   Dawar S, 2017, APPL INTELL, V47, P809, DOI 10.1007/s10489-017-0932-1
   Deng ZH, 2015, EXPERT SYST APPL, V42, P5424, DOI 10.1016/j.eswa.2015.03.004
   Djenouri Y, 2018, KNOWL-BASED SYST, V139, P132, DOI 10.1016/j.knosys.2017.10.016
   Gatuha G, 2017, TURK J ELECTR ENG CO, V25, P2096, DOI 10.3906/elk-1602-113
   Goyal P, 2020, BIG DATA RES, V21, DOI 10.1016/j.bdr.2020.100146
   Hebrail G, 2012, Individual household electric power consumption data set
   Bui H, 2018, EXPERT SYST APPL, V96, P388, DOI 10.1016/j.eswa.2017.10.039
   Ilamchezhian J., 2021, TURK J COMPUT MATH E, V12, P3529
   Jamsheela O, 2021, INT ARAB J INF TECHN, V18, P208, DOI 10.34028/iajit/18/2/9
   Kaliappan J., 2019, INT J INNOV TECHNOL, V8, P1727
   Lessanibahri S, 2020, EXPERT SYST APPL, V142, DOI 10.1016/j.eswa.2019.113004
   Leung CK, 2018, LECT NOTES COMPUT SC, V11029, P3, DOI 10.1007/978-3-319-98809-2_1
   Li ZY, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12551
   Lin JCW, 2021, APPL INTELL, V51, P4806, DOI 10.1007/s10489-020-02080-w
   Liu DL, 2022, ACM T KNOWL DISCOV D, V16, DOI 10.1145/3488380
   Liu JQ, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116220
   Mao YM, 2021, MULTIMEDIA SYST, V27, P709, DOI 10.1007/s00530-020-00725-x
   Nguyen H, 2019, ARXIV
   Ponmudiyan Poovan JS, 2022, IJECE, V12, P3249, DOI [10.11591/ijece.v12i3, DOI 10.11591/IJECE.V12I3]
   Qu JF, 2020, IEEE ACCESS, V8, P183722, DOI 10.1109/ACCESS.2020.3029302
   Rahman MM, 2019, INFORM SCIENCES, V479, P76, DOI 10.1016/j.ins.2018.11.026
   Reiss A, 2019, STRICKER D PAMAP2 PH
   Siahaan APU, 2018, NOVELTY DATA MINING
   Sohrabi MK, 2018, J CHIN INST ENG, V41, P229, DOI 10.1080/02533839.2018.1454853
   Son LH, 2018, KNOWL-BASED SYST, V154, P68, DOI 10.1016/j.knosys.2018.04.038
   Stolfo S., 1999, KDD cup 1999 dataset
   Nguyen TN, 2020, IEEE ACCESS, V8, P116840, DOI 10.1109/ACCESS.2020.3004530
   Vanahalli MK, 2019, DATA KNOWL ENG, V123, DOI 10.1016/j.datak.2019.101721
   Waghere SS, 2021, RETRIEVAL FREQUENT I, P787, DOI [10.1007/978-981-15-5148-2_68, DOI 10.1007/978-981-15-5148-2_68]
   Wang GT, 2022, ACM T KNOWL DISCOV D, V16, DOI 10.1145/3465238
   Wang L, 2018, APPL SOFT COMPUT, V62, P817, DOI 10.1016/j.asoc.2017.09.013
   Wu N, 2021, LECT NOTES COMPUT SC, V12999, P225, DOI 10.1007/978-3-030-87571-8_20
   Wu YX, 2022, ACM T KNOWL DISCOV D, V16, DOI 10.1145/3480245
   Xun YL, 2021, PARALLEL COMPUT, V101, DOI 10.1016/j.parco.2020.102738
   Yamamoto Y, 2020, J INTELL INF SYST, V55, P119, DOI 10.1007/s10844-019-00590-9
   Zhang CK, 2019, INT J MACH LEARN CYB, V10, P3003, DOI 10.1007/s13042-018-00918-x
   Zhang CK, 2019, IEEE INTERNET THINGS, V6, P3948, DOI 10.1109/JIOT.2018.2885851
   Zhang R, 2019, J SUPERCOMPUT, V75, P646, DOI 10.1007/s11227-017-2049-z
   Zhao X, 2021, IMPROVED ALGORITHM M, P206, DOI [10.1007/978-3-030-92632-8_20, DOI 10.1007/978-3-030-92632-8_20]
NR 48
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27571
EP 27591
DI 10.1007/s11042-023-14484-0
EA FEB 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000937945000002
DA 2024-07-18
ER

PT J
AU Gao, J
   Yi, JG
   Murphey, YL
AF Gao, Jun
   Yi, Jiangang
   Murphey, Yi Lu
TI Multi-scale space-time transformer for driving behavior detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Driving behavior detection; MSTR; Multi-modal data; Multi-patch
   space-time attention
AB The advent of advanced in-vehicle sensors and communication technologies have facilitated the collection of large volume and almost real-time data on vehicles and drivers. Processing and analyzing this data provides unprecedented opportunities to offer remarkable insights and solutions for driving behavior detection. Characterizing driving behavior plays a key role in a variety of research areas such as traffic safety, the development of autonomous driving, and risk assessment. In this research, a novel framework, Multi-scale Space-time TRansformer (MSTR) is proposed for driving behavior detection using multi-modal data, i.e. front view video frames and vehicle signals. In particular, a multi-patch architecture is explored to capture driving scene features generated from different scales. Meanwhile, a Multi-patch Space-time Attention (MSA) module is designed for MSTR to model multi-scale features and capture spatial-temporal correlation simultaneously. Moreover, the extracted vehicle dynamics features are used as auxiliary to improve the robustness of detection, and a customized Cross-Modal Fusion (CMF) module is introduced to integrate these two different modality features efficiently. Finally, we experimentally validate the efficiency of our approach on a naturalistic driving data set containing over 2800 maneuvers recorded. The MSTR achieves state-of-the-art results with a low inference cost when compared to 3D convolutional networks, and it performs superior to a number of Transformer-based models and other advanced detection methods.
C1 [Gao, Jun; Yi, Jiangang] Jianghan Univ, State Key Lab Precis Blasting, Wuhan 430056, Peoples R China.
   [Gao, Jun; Yi, Jiangang] Jianghan Univ, Sch Smart Mfg, Wuhan 430056, Peoples R China.
   [Murphey, Yi Lu] Univ Michigan, Dept Elect & Comp Engn, Dearborn, MI 48128 USA.
C3 Jianghan University; Jianghan University; University of Michigan System;
   University of Michigan
RP Gao, J (corresponding author), Jianghan Univ, State Key Lab Precis Blasting, Wuhan 430056, Peoples R China.; Gao, J (corresponding author), Jianghan Univ, Sch Smart Mfg, Wuhan 430056, Peoples R China.
EM gaojun407104739@163.com
OI Gao, Jun/0000-0001-9857-531X
FU Wuhan Science and Technology Bureau [2022010801020380]; State Key
   Laboratory of Precision Blasting [PBSKL2022302]; Jianghan University
   [2021yb148]
FX AcknowledgmentsThis research is supported by the Wuhan Science and
   Technology Bureau (2022010801020380), State Key Laboratory of Precision
   Blasting (PBSKL2022302) and Jianghan University (2021yb148).
CR Akai N, 2019, IEEE INT VEH SYM, P949, DOI 10.1109/IVS.2019.8814287
   Arnab A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6816, DOI 10.1109/ICCV48922.2021.00676
   Bertasius G., 2021, arXiv
   Bulat A., 2021, Advances in Neural Information Processing Systems
   CAI Z, 2016, EUR C COMP VIS, P354, DOI DOI 10.1007/978-3-319-46493-0_22
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Deng Q, 2020, IEEE T INTELL TRANSP, V21, P3561, DOI 10.1109/TITS.2019.2937287
   Devlin J., 2018, BERT PRE TRAINING DE
   Diaz-Alvarez A, 2018, TRANSPORT RES F-TRAF, V56, P134, DOI 10.1016/j.trf.2018.04.004
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Fan HQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6804, DOI 10.1109/ICCV48922.2021.00675
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Gao J, 2022, TRANSPORTMETRICA A, V18, P1234, DOI 10.1080/23249935.2021.1936279
   Gao J, 2022, TRANSPORTMETRICA B, V10, P831, DOI 10.1080/21680566.2020.1782786
   Gao J, 2019, COMPUTING, V101, P1837, DOI 10.1007/s00607-019-00712-9
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Hong J, 2019, PROC CVPR IEEE, P8446, DOI 10.1109/CVPR.2019.00865
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu L., 2019, arXiv
   Liu Yinhan, 2019, ARXIV190711692
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Murphey YL, 2020, SAE INT J TRANSP SAF, V8, P77, DOI 10.4271/09-08-02-0005
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Peng XS, 2018, INT C PATT RECOG, P1265, DOI 10.1109/ICPR.2018.8546255
   Ramanishka V, 2018, PROC CVPR IEEE, P7699, DOI 10.1109/CVPR.2018.00803
   Rueckauer B, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00682
   Sevilla-Lara L, 2021, IEEE WINT CONF APPL, P535, DOI 10.1109/WACV48630.2021.00058
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Vaswani A, 2017, ADV NEUR IN, V30
   [王清华 Wang Qinghua], 2021, [计算机应用研究, Application Research of Computers], V38, P1381
   Wang W., 2021, ARXIV
   Wang W, 2021, INT C PATT RECOG, P6359, DOI 10.1109/ICPR48806.2021.9412302
   Xie DF, 2019, TRANSPORT RES C-EMER, V106, P41, DOI 10.1016/j.trc.2019.07.002
   Xie J, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114442
   Xu HZ, 2017, PROC CVPR IEEE, P3530, DOI 10.1109/CVPR.2017.376
   Yang FZ, 2020, PROC CVPR IEEE, P5790, DOI 10.1109/CVPR42600.2020.00583
   Yang SM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.601109
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhu X., 2020, arXiv
NR 49
TC 1
Z9 1
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24289
EP 24308
DI 10.1007/s11042-023-14499-7
EA FEB 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000931739200001
DA 2024-07-18
ER

PT J
AU Enireddy, V
   Anitha, J
   Mahendra, N
   Kishore, G
AF Enireddy, Vamsidhar
   Anitha, J.
   Mahendra, N.
   Kishore, G.
TI An optimized automated recognition of infant sign language using
   enhanced convolution neural network and deep LSTM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Baby sign language; Automated recognition; Computer vision; Optimization
AB In the world, several sign languages (SL) are used, and BSL (Baby Sign Language) is the process of communication between the parents and baby using gestures. Communication by gestures is a non-verbal process that utilizes motion to pass on realities, expressions and feelings to people. SL is the communication mode in which the information is conveyed via movement of body parts like cheeks, eyebrows and head. Even though many research works based on SL are available, research in BSL remains a challenge. Hence, this paper presents an optimization-based automated recognition of the deep BSL system, which determines the gesture signalled by the kids. Initially, the image frames are extracted from the videos and data augmentation processes are performed. After pre-processing, the features are extracted from the frames using the Enhanced Convolution Neural Network (ECNN). The optimal characteristics are then selected by a new Life Choice Based Optimizer (LCBO). Finally, the classification is carried out by the Deep Long Short-Term Memory (DLSTM) scheme. The implementation is performed on the Python platform, and the performances are evaluated using several performance metrics such as accuracy, precision, kappa, f1-score and recall. The performance of the proposed approach (ECNN-DLSTM) is compared with several deep and machine learning approaches and obtains an accuracy of 99% and a kappa of 96%.
C1 [Enireddy, Vamsidhar] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Guntur 522502, Andhra Pradesh, India.
   [Anitha, J.] Malla Reddy Engn Coll, Dept Comp Sci & Engn, Hyderabad 500100, Telangana, India.
   [Mahendra, N.] Miracle Educ Soc Grp Inst, Miracle City 535216, Andhra Pradesh, India.
   [Kishore, G.] RISE Krishna Sai Prakasam Grp Inst, Dept CSE, Ongole 523272, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   Miracle Educational Society Group Of Institutions
RP Enireddy, V (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Guntur 522502, Andhra Pradesh, India.
EM enireddy.vamsidhar@gmail.com
RI J., Anitha/AAE-8829-2021; ENIREDDY, VAMSIDHAR/S-2920-2018
OI J., Anitha/0000-0001-6017-6129; ENIREDDY, VAMSIDHAR/0000-0001-6082-7497
CR Albanie S, 2020, ARXIV
   Aly W, 2019, IEEE ACCESS, V7, P123138, DOI 10.1109/ACCESS.2019.2938829
   Arora M, 2020, INT C INNOVATIVE COM, P427
   Asadi-Aghbolaghi M, 2017, SPRING SER CHALLENGE, P539, DOI 10.1007/978-3-319-57021-1_19
   Bragg D, 2019, ASSETS'19: THE 21ST INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P16, DOI 10.1145/3308561.3353774
   Cai WW, 2021, DISPLAYS, V69, DOI 10.1016/j.displa.2021.102076
   Cui RP, 2019, IEEE T MULTIMEDIA, V21, P1880, DOI 10.1109/TMM.2018.2889563
   Deng X., 2017, ARXIV
   Farooq U, 2021, NEURAL COMPUT APPL, V33, P14357, DOI 10.1007/s00521-021-06079-3
   Ferreira PM, 2019, MULTIMED TOOLS APPL, V78, P10035, DOI 10.1007/s11042-018-6565-5
   Gao LQ, 2021, NEUROCOMPUTING, V434, P45, DOI 10.1016/j.neucom.2020.12.006
   Guo H., 2017, arXiv
   Imran J, 2020, VISUAL COMPUT, V36, P1233, DOI 10.1007/s00371-019-01725-3
   Kamruzzaman MM, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/3685614
   Khatri A, 2020, SOFT COMPUT, V24, P9121, DOI 10.1007/s00500-019-04443-z
   Koller O, 2018, INT J COMPUT VISION, V126, P1311, DOI 10.1007/s11263-018-1121-3
   Kowdiki M, 2021, COMPUT SCI REV, V39, DOI 10.1016/j.cosrev.2020.100320
   Li DX, 2020, IEEE WINT CONF APPL, P1448, DOI [10.1109/WACV45572.2020.9093512, 10.1109/wacv45572.2020.9093512]
   Liao YQ, 2019, IEEE ACCESS, V7, P38044, DOI 10.1109/ACCESS.2019.2904749
   Lim KM, 2019, MULTIMED TOOLS APPL, V78, P19917, DOI 10.1007/s11042-019-7263-7
   Masood Sarfaraz, 2018, Intelligent Engineering Informatics. Proceedings of the 6th International Conference on FICTA. Advances in Intelligent Systems and Computing (AISC 695), P623, DOI 10.1007/978-981-10-7566-7_63
   Nadgeri S, 2020, P INT C RECENT ADV C
   Nadgeri S., 2019, IEEE, V1, P854
   Naranjo-Zeledón L, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8091047
   Neiva DH, 2018, EXPERT SYST APPL, V103, P159, DOI 10.1016/j.eswa.2018.01.051
   Ning X, 2021, NEUROCOMPUTING, V453, P801, DOI 10.1016/j.neucom.2020.05.106
   Prietch SS, 2019, UNITED ACAD J, P112
   Rao GA, 2018, AIN SHAMS ENG J, V9, P1929, DOI 10.1016/j.asej.2016.10.013
   Rastgoo R, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20110809
   Saunders B, 2021, INT J COMPUT VISION, V129, P2113, DOI 10.1007/s11263-021-01457-9
   Sullivan AL, 2019, EARLY CHILD RES Q, V47, P496, DOI 10.1016/j.ecresq.2018.07.005
   Wadhawan A, 2020, NEURAL COMPUT APPL, V32, P7957, DOI 10.1007/s00521-019-04691-y
   Wang C, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108498
   Wangchuk K, 2021, ICT EXPRESS, V7, P215, DOI 10.1016/j.icte.2020.08.002
   Wei SJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16040556
   Wu F, 2020, IEEE T CYBERNETICS, V50, P1009, DOI 10.1109/TCYB.2018.2876591
   Yang S, 2017, PROC SPIE, V10420, DOI 10.1117/12.2281671
   Zheng LH, 2017, 2017 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING - TECHNIQUES AND APPLICATIONS (DICTA), P454
NR 38
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28043
EP 28065
DI 10.1007/s11042-023-14428-8
EA FEB 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000929502800004
DA 2024-07-18
ER

PT J
AU Basha, HA
   Sangeetha, SKB
   Sasikumar, S
   Arunnehru, J
   Subramaniam, M
AF Basha, H. Anwar
   Sangeetha, S. K. B.
   Sasikumar, S.
   Arunnehru, J.
   Subramaniam, M.
TI A proficient video recommendation framework using hybrid fuzzy C means
   clustering and Kullback-Leibler divergence algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommendation systems; Content-based filtering; Knowledge base; Fuzzy
   C-means algorithm
AB A video recommendation framework for e-commerce clients is proposed using the collaborative filtering (CF) process. One of the most important features of the CF algorithm is its scalability. To avoid the issue, a hybrid model-based collaborative filtering approach is proposed. KL Divergence was developed to address the CF technique's scalability problem. The clustering with enhanced sqrt-cosine similarity Recommender scheme is proposed. For successful clustering, Kullback-Leibler Divergence-based Fuzzy C-Means clustering is suggested, with the aim of focusing on greater accuracy during movie recommendation.The proposed scheme is viewed as a trustworthy contribution that significantly improves the ability of movie recommendation by virtue of the KL divergence-based Fuzzy C-Means clustering mechanism and enhanced sqrt-cosine similarity. The proposed scheme highlighted and addressed the critical role of the KL divergence-based cluster ensemble factor in improving clustering stability and robustness. For prediction, the enhanced sqrt-cosine similarity was used to calculate successful related neighbor users. The performance of Recommendation is improved when KLD-FCM is combined with improved sqrt-cosine similarity.The proposed scheme's empirical work on the Movielens dataset in terms of MAE, RMSE, SD, and Recall were found to be superior in recommendation accuracy compared to traditional approaches and some non-clustering based methods recommended for study. With the specified number of clusters, it is capable of providing accurate and customized movie recommendation systems.
C1 [Basha, H. Anwar] REVA Univ, Sch Comp Sci & Engn, Bengaluru, India.
   [Sangeetha, S. K. B.; Arunnehru, J.] SRM Inst Sci & Technol, Coll Engn & Technol, Fac Engn & Technol, Dept Comp Sci & Engn, Vadapalani Campus, Chennai, India.
   [Sasikumar, S.] Saveetha Engn Coll, Dept Comp Sci & Engn, Chennai, India.
   [Subramaniam, M.] Chaitanya Bharathi Inst Technol, Dept CSE, Hyderabad, India.
C3 REVA University; SRM Institute of Science & Technology Chennai;
   Chaitanya Bharathi Institute of Technology
RP Basha, HA (corresponding author), REVA Univ, Sch Comp Sci & Engn, Bengaluru, India.
EM anwar.mtech@gmail.com; sangeets8@srmist.edu.in;
   sasikumar@saveetha.ac.in; arunnehru.aucse@gmail.com;
   subbu.21074@gmail.com
RI S, murugavalli/AAC-9610-2019; s, sasikumar/AAG-1209-2021; H, Dr. Anwar
   Basha/HPG-1336-2023; S K B, Sangeetha/AAS-9527-2021; COLLEGE OF
   TECHNOLOGY, SRI VENKATESWARAA/IXN-6644-2023; J, Arunnehru/JBR-7884-2023
OI S, murugavalli/0000-0003-3827-8596; s, sasikumar/0000-0001-9732-3268; H,
   Dr. Anwar Basha/0000-0001-9002-6316; S K B,
   Sangeetha/0000-0002-6927-6916; COLLEGE OF TECHNOLOGY, SRI
   VENKATESWARAA/0009-0000-5834-4031; S, Dr.SASIKUMAR/0000-0001-6914-9741
CR Antony Vijay J, 2020, Computational methods and data engineering, V2, P331, DOI DOI 10.1007/978-981-15-7907-3_25
   Asadi E., 2012, 2012 20th Iranian Conference on Electrical Engineering (ICEE 2012), P690, DOI 10.1109/IranianCEE.2012.6292442
   Basha SM, 2019, DEEP LEARNING AND PARALLEL COMPUTING ENVIRONMENT FOR BIOENGINEERING SYSTEMS, P153, DOI 10.1016/B978-0-12-816718-2.00016-6
   Clement J., 2020, IMPACT RECOMMENDATIO, DOI [10.13140/RG.2.2.15746.50882, DOI 10.13140/RG.2.2.15746.50882]
   Cui LZ, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3900
   Davidson James, 2010, P 4 ACM C REC SYST, P293, DOI [DOI 10.1145/1864708.1864770, 10.1145/1864708]
   De Vriendt J, 2011, BELL LABS TECH J, V16, P235, DOI 10.1002/bltj.20513
   Deldjoo Y, 2015, BUILDING CONTENT BAS, DOI [10.1007/978-3-319-27729-5, DOI 10.1007/978-3-319-27729-5]
   Deldjoo Y., 2019, ENHANCING VIDEO RECO, DOI [10.1007/978-3-030-32094-2_6, DOI 10.1007/978-3-030-32094-2_6]
   Deldjoo Y, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3407190
   Deldjoo Y, 2016, J DATA SEMANT, V5, P99, DOI 10.1007/s13740-016-0060-9
   Gupta M, 2021, MOVIE RECOMMENDER SY
   Homann L, 2019, VIETNAM J COMPUT SCI, V6, P3, DOI 10.1142/S2196888819500040
   Huang YX, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P35, DOI 10.1145/2882903.2903743
   Kamran M, 2020, MOVIE RECOMMENDER SY
   Khadse V. P., 2018, INT J ADV SCI TECHNO, V110, P65, DOI [10.14257/ijast.2018.110.07, DOI 10.14257/IJAST.2018.110.07]
   Lu W, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P793, DOI 10.1145/2911451.2914707
   Mercanoglu O, 2017, VIDEO RECOMMENDATION
   Mohamed A, 2020, NEW CHALLENGE VIDEO, DOI [10.1109/ICCES48960.2019.9068169, DOI 10.1109/ICCES48960.2019.9068169]
   Patil Lalit, 2016, FUZZY C MEANS CLUSTE, DOI [10.13140/RG.2.1.3924.9046, DOI 10.13140/RG.2.1.3924.9046]
   Ramezani M, 2016, PHYSICA A, V457, P607, DOI 10.1016/j.physa.2016.03.101
   Shah P, 2020, VIDEO RECOMMENDER SY
   Tohidi N, 2020, INT J NONLINEAR ANAL, V11, P483, DOI 10.22075/ijnaa.2020.19127.2058
   Zhou XM, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1645, DOI 10.1145/2723372.2749444
NR 24
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 20989
EP 21004
DI 10.1007/s11042-023-14460-8
EA FEB 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000926356100002
DA 2024-07-18
ER

PT J
AU Das, S
   Gayen, PK
   Pal, S
   Nayyar, A
AF Das, Sudip
   Gayen, Pritam Kumar
   Pal, Souvik
   Nayyar, Anand
TI Quality and leakage detection based water pricing scheme for
   multi-consumer building with real-time implementation using IoT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Water tariff; rate; Multi-consumer building; Water quality; Internet of
   things (IoT); Leakage; Real-time
ID DEMAND MANAGEMENT; URBAN WATER; CITIES
AB Nowadays, multi-consumer buildings are growing rapidly as living place in city or megacity of developing nation to accommodate large group of people. The urban people are facing bigger threat on water prone disease i.e., water quality is stringent requirement. Here, traditional fixed or block rate tariff does not provide price reduction for comparatively poor water quality. Though water quality is a vital factor, this is not significantly focused in the traditional policies for strictly ensuring safe water from supplier's end. Thus, a novel tariff policy is proposed for multi-family building. Here, rebate amounts due to violations of turbidity, pH value, electrical conductivity, chlorine and coliform count are proposed. In an illustrative simulation study, water price is reduced by 5%-27% in comparison with fixed and block rate tariffs for violation of electrical conductivity. In IoT based working prototype, it is observed rebate due to inferior water quality is significant proportion (about 25%) of total cost. Here, charge on leakage water is also segregated from consumption cost, which is not possible in case of traditional tariffs. Therefore, price penalty for quality violation and leakage water cost segregation are assured through suggested policy.
C1 [Das, Sudip] JIS Coll Engn, Dept Elect Engn, Kalyani, India.
   [Gayen, Pritam Kumar] Kalyani Govt Engn Coll, Dept Elect Engn, Kalyani, India.
   [Pal, Souvik] Sister Nivedita Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Nayyar, Anand] Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang, Vietnam.
C3 Kalyani Government Engineering College; Duy Tan University
RP Nayyar, A (corresponding author), Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang, Vietnam.
EM sudipdas1380@gmail.com; pkgtar@gmail.com; souvikpal22@gmail.com;
   anandnayyar@duytan.edu.vn
RI Nayyar, Anand/F-3732-2015; Pal, Souvik/L-2616-2015
OI Nayyar, Anand/0000-0002-9821-6146; Pal, Souvik/0000-0001-9884-0160
CR Aggarwal RM, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11195314
   Al-Saidi M, 2019, WATER-SUI, V11, DOI 10.3390/w11040704
   AlMetwally Saif Allah H., 2020, Procedia CIRP, V91, P478, DOI 10.1016/j.procir.2020.03.107
   Antzoulatos G, 2020, WATER SCI TECHNOL, V82, P2691, DOI 10.2166/wst.2020.391
   Cloete NA, 2016, IEEE ACCESS, V4, P3975, DOI 10.1109/ACCESS.2016.2592958
   Crookes DJ, 2018, WATER RESOUR ECON, V21, P29, DOI 10.1016/j.wre.2017.11.002
   Damkjaer S, 2020, H2OPEN J, V3, P355, DOI 10.2166/h2oj.2020.031
   delhijalboard, CONT WAT 0
   Demetillo AT, 2019, SUSTAIN ENVIRON RES, V29, DOI 10.1186/s42834-019-0009-4
   DEPAULA HTL, 2019, IEEE INT CONF COMM, pNI615
   Deyà-Tortella B, 2017, WATER-SUI, V9, DOI 10.3390/w9060425
   Fuente D, 2019, UTIL POLICY, V61, DOI 10.1016/j.jup.2019.100975
   Fuentes H, 2020, ENVIRON MONIT ASSESS, V192, DOI 10.1007/s10661-020-08535-4
   Garcia L., 2018, Network Protocols and Algorithms, V10, P23, DOI DOI 10.5296/NPA.V10I1.12798
   Gavande M, 2020, 2 INT C COMMUNICATIO
   Hamid Shabinar Abdul, 2020, 2020 10th IEEE International Conference on Control System, Computing and Engineering (ICCSCE), P102, DOI 10.1109/ICCSCE50387.2020.9204931
   healthline, HLTH PH DRINK WAT AL
   Islam MM., 2020, INT C IMAGE PROCESSI, P561
   Jan F, 2021, WATER-SUI, V13, DOI 10.3390/w13131729
   kmcgov, KMCPORTAL JSP WATERS
   Lakshmikantha V., 2021, Glob. Transitions Proc., V2, P181, DOI [10.1016/j.gltp.2021.08.062, DOI 10.1016/J.GLTP.2021.08.062]
   Lay-Ekuakille A, 2019, MEASUREMENT, V137, P566, DOI 10.1016/j.measurement.2019.01.052
   Li SZ, 2018, MEASUREMENT, V115, P39, DOI 10.1016/j.measurement.2017.10.021
   Luo PP, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219009
   Ma XZ, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10103526
   Molinos-Senante M, 2016, UTIL POLICY, V43, P107, DOI 10.1016/j.jup.2016.04.014
   Myint CZ, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P435
   Omer N.H., 2019, Water Quality-Science, Assessments and Policy
   Pesic R, 2013, J CLEAN PROD, V60, P147, DOI 10.1016/j.jclepro.2012.10.037
   Pinto FS, 2015, WATER POLICY, V17, P1108, DOI 10.2166/wp.2015.188
   Pujar PM, 2019, APPL WATER SCI, V10, DOI 10.1007/s13201-019-1111-9
   quora, WHAT IS AM AV WAT BI
   Raad AM, 2021, INT J ADV COMPUT SC, V12, DOI 10.14569/ijacsa.2021.0120848
   rb.gy, US
   Reddy P.S., 2018, INT J ENG TECHNOLOGY, V7, P120
   Stavenhagen M, 2018, CITIES, V79, P187, DOI 10.1016/j.cities.2018.03.008
   Tortajada C, 2019, SUSTAIN CITIES SOC, V45, P649, DOI 10.1016/j.scs.2018.11.044
   van Leeuwen K, 2016, ENVIRON DEV SUSTAIN, V18, P1, DOI 10.1007/s10668-015-9636-z
   Vijayakumar N, 2015, 2015 INTERNATIONAL CONFERENCED ON CIRCUITS, POWER AND COMPUTING TECHNOLOGIES (ICCPCT-2015)
   Wang YC, 2018, IEEE SENS J, V18, P4689, DOI 10.1109/JSEN.2018.2826778
   Xu LD, 2014, IEEE T IND INFORM, V10, P2233, DOI 10.1109/TII.2014.2300753
   Yuan ZG, 2019, WATER RES, V155, P381, DOI 10.1016/j.watres.2019.02.034
   Zeng DZ, 2016, IEEE T IND INFORM, V12, P2177, DOI 10.1109/TII.2016.2569413
   Zhang YY, 2019, WATER RES, V164, DOI 10.1016/j.watres.2019.114888
NR 44
TC 0
Z9 0
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26317
EP 26352
DI 10.1007/s11042-023-14402-4
EA JAN 2023
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000920970500001
DA 2024-07-18
ER

PT J
AU Gilani, SQ
   Marques, O
AF Gilani, Syed Qasim
   Marques, Oge
TI Skin lesion analysis using generative adversarial networks: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Deep learning; Image analysis; Generative adversarial networks; GANs;
   Skin lesion classification; Skin lesion segmentation
ID CLASSIFICATION; CANCER
AB Skin cancer is one of the primary causes of death in the world. Timely diagnosis of skin cancer can reduce the number of deaths. Skin cancer can be diagnosed early using deep learning-based systems. The performance of deep learning-based systems suffers from overfitting if we don't have enough data to train them. Acquiring a large amount of skin lesion images for training a deep learning-based system is a difficult task. Overfitting can be avoided using data augmentation. Generative adversarial networks (GANs) are very popular in skin lesion tasks because of their ability to generate high-quality synthetic skin lesion images. GANs are used for the classification and segmentation of skin-lesion images. We review the most relevant papers discussing the use of GANs for augmenting skin lesion datasets in this work. We gave an overview of the most commonly used GAN architectures in skin lesion analysis.
C1 [Gilani, Syed Qasim; Marques, Oge] Florida Atlantic Univ, Dept Elect Engn & Comp Sci, Boca Raton, FL 33431 USA.
C3 State University System of Florida; Florida Atlantic University
RP Gilani, SQ (corresponding author), Florida Atlantic Univ, Dept Elect Engn & Comp Sci, Boca Raton, FL 33431 USA.
EM sgilani2020@fau.edu; omarques@fau.edu
OI Gilani, Syed Qasim/0000-0001-7863-6648
CR Abdelhalim ISA, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113922
   Abhishek K, 2019, LECT NOTES COMPUT SC, V11827, P71, DOI 10.1007/978-3-030-32778-1_8
   Adegun A, 2021, ARTIF INTELL REV, V54, P811, DOI 10.1007/s10462-020-09865-y
   Annala L, 2020, IEEE ENG MED BIO, P1600, DOI [10.1109/embc44109.2020.9176292, 10.1109/EMBC44109.2020.9176292]
   [Anonymous], 2015, Dermoscopy image analysis, DOI DOI 10.1201/B19107
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Ballerini L., 2013, Color medical image analysis, P63
   Baur C., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.04338
   Baur C, 2018, LECT NOTES COMPUT SC, V11041, P260, DOI 10.1007/978-3-030-01201-4_28
   Bi L, 2019, I S BIOMED IMAGING, P1100, DOI [10.1109/isbi.2019.8759479, 10.1109/ISBI.2019.8759479]
   Bisla D, 2019, IEEE COMPUT SOC CONF, P2720, DOI 10.1109/CVPRW.2019.00330
   Bissoto A, 2020, ANAIS ESTENDIDOS 33, P70
   Bissoto A, 2021, IEEE COMPUT SOC CONF, P1847, DOI 10.1109/CVPRW53098.2021.00204
   Bissoto A, 2018, LECT NOTES COMPUT SC, V11041, P294, DOI 10.1007/978-3-030-01201-4_32
   Oliveira DAB, 2020, I S BIOMED IMAGING, P1798, DOI 10.1109/ISBI45749.2020.9098676
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chi YC, 2018, IEEE ENG MED BIO, P2591, DOI 10.1109/EMBC.2018.8512842
   Codella NCF, 2017, IBM J RES DEV, V61, DOI 10.1147/JRD.2017.2708299
   Codella Noel, 2019, arXiv
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Combalia M, 2019, ARXIV
   Denton E., 2015, ARXIV
   Diaz I. G., 2017, ARXIV
   Dildar M, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18105479
   Ding SS, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102224
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fan HD, 2017, COMPUT BIOL MED, V85, P75, DOI 10.1016/j.compbiomed.2017.03.025
   Fornaciali M, 2016, ARXIV
   Fossen-Romsaas Sondre., 2020, Synthesizing skin lesion images using CycleGANs-a case study"
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Furger Fabian, 2020, Artificial Neural Networks in Pattern Recognition. 9th IAPR TC3 Workshop, ANNPR 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12294), P187, DOI 10.1007/978-3-030-58309-5_15
   Gatys L. A., 2015, arXiv
   Ghorbani Amirata, 2020, P MACH LEARN HLTH NE, P155
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gutman D, 2016, ARXIV
   Hasan MK, 2020, COMPUT BIOL MED, V120, DOI 10.1016/j.compbiomed.2020.103738
   Hasan MdKamrul., 2021, medRxiv
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hensel M, 2017, ADV NEUR IN, V30
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Izadi S, 2018, I S BIOMED IMAGING, P881, DOI 10.1109/ISBI.2018.8363712
   Jalalian A, 2017, EXCLI J, V16, P113, DOI [10.17179/excli201-701, 10.17179/excli2016-701]
   Kang YH, 2019, INT J CARTOGRAPHY, V5, P115, DOI 10.1080/23729333.2019.1615729
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Kawahara J, 2019, IEEE J BIOMED HEALTH, V23, P538, DOI 10.1109/JBHI.2018.2824327
   Kittler H, 2002, LANCET ONCOL, V3, P159, DOI 10.1016/S1470-2045(02)00679-4
   Korotkov K, 2012, ARTIF INTELL MED, V56, P69, DOI 10.1016/j.artmed.2012.08.002
   Lazo C, 2021, ARXIV
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lei BY, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101716
   Lucieri A, 2021, ARXIV
   Matsunaga K., 2017, ARXIV
   Mendonca Teresa, 2013, 2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), P5437, DOI 10.1109/EMBC.2013.6610779
   Menegola A, ARXIV
   Menegola A, 2017, I S BIOMED IMAGING, P297, DOI 10.1109/ISBI.2017.7950523
   Mikolajczyk Agnieszka, 2018, 2018 International Interdisciplinary PhD Workshop (IIPhDW), P117, DOI 10.1109/IIPHDW.2018.8388338
   Mikolajczyk A, 2019, 2019 24TH INTERNATIONAL CONFERENCE ON METHODS AND MODELS IN AUTOMATION AND ROBOTICS (MMAR), P42, DOI [10.1109/mmar.2019.8864616, 10.1109/MMAR.2019.8864616]
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Mishra NK, 2016, ARXIV
   Odena A, 2017, PR MACH LEARN RES, V70
   Osuala R, 2021, ARXIV
   Pacheco Andre GC, 2019, ARXIV
   Palatucci M. M., 2009, Zero-shot learning with semantic output codes"
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Perez F, 2018, LECT NOTES COMPUT SC, V11041, P303, DOI 10.1007/978-3-030-01201-4_33
   Pollastri F, 2020, MULTIMED TOOLS APPL, V79, P15575, DOI 10.1007/s11042-019-7717-y
   Pollastri F, 2018, COMP MED SY, P442, DOI 10.1109/CBMS.2018.00086
   Qasim AB, 2020, PR MACH LEARN RES, V121, P655
   Qin ZW, 2020, COMPUT METH PROG BIO, V195, DOI 10.1016/j.cmpb.2020.105568
   Radford A., 2015, ARXIV
   Rashid H, 2019, IEEE ENG MED BIO, P916, DOI [10.1109/EMBC.2019.8857905, 10.1109/embc.2019.8857905]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rotemberg V, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00815-z
   Sarker MMK, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115433
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Pham TC, 2018, LECT NOTES ARTIF INT, V10752, P573, DOI 10.1007/978-3-319-75420-8_54
   Trivedi A, 2020, ARXIV
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Tu WL, 2019, IEEE ACCESS, V7, P77037, DOI 10.1109/ACCESS.2019.2921815
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wei J, 2019, PR MACH LEARN RES, V116, P10
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Xue Y, 2018, I S BIOMED IMAGING, P859, DOI 10.1109/ISBI.2018.8363707
   Zhao C, 2021, IEEE ACCESS, V9, P8659, DOI 10.1109/ACCESS.2021.3049600
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zunair H, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/ab86d3
NR 92
TC 5
Z9 5
U1 5
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 30065
EP 30106
DI 10.1007/s11042-022-14267-z
EA JAN 2023
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000919698400001
DA 2024-07-18
ER

PT J
AU Nie, TY
   Wang, SR
   Wang, YQ
   Tong, XQ
   Sun, F
AF Nie, Tongyu
   Wang, Sirui
   Wang, Yuqi
   Tong, Xunqian
   Sun, Feng
TI An effective recognition of moving target seismic anomaly for security
   region based on deep bidirectional LSTM combined CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Seismic signal anomaly; Moving target recognition; Temporal
   effectiveness; Deep learning
ID NEURAL-NETWORKS; FOOTSTEP
AB Ground motion target recognition based on seismic signals is more convenient and efficient than traditional manual patrol identification. However, current high-precision identification methods are limited to single-target classification. In this paper, the embedded adaptive learning technology was utilized to solve the problem of timeliness for the real-time moving target monitoring. We propose a deep bidirectional long short-term memory (DBiLSTM) algorithm that is implemented based on extracting spatial properties. The sequence data is processed by using three models including the convolutional neural network (CNN) and CNN-LSTM and CNN-DBiLSTM respectively, the target labels are categorized in the last layer. Identification results on the JL dataset are indicated that the CNN-DBiLSTM model produces the best performance. The algorithm we proposed improves the identification accuracy by 3.26% compared with the benchmark CNN method and the total number of layers of the network is only five. And the stability is the best among the three algorithms in ten independent experiments. Which Provides a practical classification and identification method for real-time target monitoring system.
C1 [Nie, Tongyu; Wang, Sirui; Wang, Yuqi; Tong, Xunqian; Sun, Feng] Jilin Univ, Coll Instrumentat & Elect Engn, Changchun 130000, Peoples R China.
C3 Jilin University
RP Tong, XQ; Sun, F (corresponding author), Jilin Univ, Coll Instrumentat & Elect Engn, Changchun 130000, Peoples R China.
EM txq@jlu.edu.cn; sunfeng@jlu.edu.cn
RI Nie, Tongyu/HPG-2235-2023
OI tong, xunqian/0000-0003-2535-3593
FU National Natural Science Foundation of China [41804167]; National Key
   R&D Program of China [2018YFC0603204]
FX AcknowledgmentsThis work was supported in part by the National Natural
   Science Foundation of China under Grant 41804167 and in part by the
   National Key R&D Program of China under Grant 2018YFC0603204.
CR Abdulmasih D, 2014, J SYST ARCHITECT, V60, P405, DOI 10.1016/j.sysarc.2014.02.002
   Aktas M, 2017, SIG PROCESS COMMUN
   Bacanin N, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09744-2
   Bin KC, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3108467
   Das Chakladar D, 2020, BIOMED SIGNAL PROCES, V60, DOI 10.1016/j.bspc.2020.101989
   Dibazar AA, 2007, IEEE IJCNN, P1842, DOI 10.1109/IJCNN.2007.4371238
   Drira S, 2021, ADV ENG INFORM, V49, DOI 10.1016/j.aei.2021.101289
   Geng Y, 2019, J ELECTR COMPUT ENG, V2019, DOI 10.1155/2019/7343784
   Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015
   Ghosh R, 2020, IEEE SENS J, V20, P3678, DOI 10.1109/JSEN.2019.2959652
   Glüge S, 2014, NEUROCOMPUTING, V141, P54, DOI 10.1016/j.neucom.2013.11.043
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Guo YM, 2018, MULTIMED TOOLS APPL, V77, P10251, DOI 10.1007/s11042-017-5443-x
   Lecocq T, 2020, SCIENCE, V369, P1338, DOI 10.1126/science.abd2438
   Levy R, 2017, IEEE SENS J, V17, P7306, DOI 10.1109/JSEN.2017.2731858
   Li FY, 2020, IEEE SYST J, V14, P3383, DOI 10.1109/JSYST.2019.2937960
   Li JX, 2022, MULTIMED TOOLS APPL, V81, P4621, DOI 10.1007/s11042-020-10465-9
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Long Y, 2020, IEEE GEOSCI REMOTE S, V17, P1832, DOI 10.1109/LGRS.2019.2952571
   Ma HB, 2020, IEEE ACCESS, V8, P78923, DOI 10.1109/ACCESS.2020.2988727
   Mallapaty S, 2020, NATURE, V580, P176, DOI 10.1038/d41586-020-00965-x
   Prabu P, 2020, COMPUT ELECTR ENG, V87, DOI 10.1016/j.compeleceng.2020.106778
   Smagulova K, 2019, EUR PHYS J-SPEC TOP, V228, P2313, DOI 10.1140/epjst/e2019-900046-x
   Soltau H, 2017, INTERSPEECH, P3707, DOI 10.21437/Interspeech.2017-1566
   Wang Y, 2019, IEEE SENS J, V19, P5751, DOI 10.1109/JSEN.2019.2907051
   Yoon D, 2021, IEEE GEOSCI REMOTE S, V18, P1298, DOI 10.1109/LGRS.2020.2993847
   Zhang YW, 2017, IEEE INT C CL COMP, P629, DOI 10.1109/CLUSTER.2017.45
   Zhao JF, 2018, IET SIGNAL PROCESS, V12, P713, DOI 10.1049/iet-spr.2017.0320
   Zhou QW, 2017, IEEE T IND ELECTRON, V64, P6565, DOI 10.1109/TIE.2017.2682015
   Zubair M, 2011, IEEE INT SYMP SIGNAL, P438
NR 30
TC 3
Z9 3
U1 11
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JAN 19
PY 2023
DI 10.1007/s11042-023-14382-5
EA JAN 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Z8OR
UT WOS:000915813000003
DA 2024-07-18
ER

PT J
AU Ganguly, S
   Mandal, S
   Malakar, S
   Sarkar, R
AF Ganguly, Sagnik
   Mandal, Sanmit
   Malakar, Samir
   Sarkar, Ram
TI Copy-move forgery detection using local tetra pattern based texture
   descriptor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move forgery; Digital image forensics; GRIP; CoMoFoD; Duplicated
   region detection; Local tetra pattern
AB In modern era it has become increasingly easier to manipulate and tamper digital images, one of the primary reasons being the boon of commonplace availability of powerful image editing tools and software. These tools become a bane when used for malicious reasons as users can possibly add or remove important features from an image without leaving any obvious marks of tampering. Hence the need of forgery detection techniques which show high accuracy in detection arises. One of the most prevalent forms of image tampering is the copy-move forgery attack. In this type of forgery, a part of an image is copied and then pasted somewhere else in the same image with the intent to hide key features of the image. This paper introduces a new copy-move image forgery detection technique which relies on a texture feature descriptor called Local Tetra Pattern (LTrP) for block level image comparison used to localize tampered region(s). Initially, the input image is divided into overlapping blocks, then LTrP features are extracted from each block to form a single feature vector. Next, the feature vectors of all image blocks are sorted lexicographically, and then similar blocks are identified by matching the features from neighboring blocks. Finally, blocks matched falsely due to the presence of homogeneous color information like sea, field, and sky are removed using a shift vector aided outlier removal method. Experiments have been conducted on two standard datasets - GRIP and CoMoFoD. We have obtained 0.9834 and 0.9093 average F-1 scores at pixel-level for GRIP and CoMoFoD datasets respectively. The experimental results demonstrate that the proposed technique has been able to detect the forged regions with higher accuracy as compared to many state-of-the-art copy-move forgery detection methods. Moreover, experimental results on CoMoFoD dataset show that the method is able to correctly detect the forgery even after various post-processing attacks. The source code of proposed method is available at .
C1 [Ganguly, Sagnik; Mandal, Sanmit; Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Malakar, Samir] Asutosh Coll, Dept Comp Sci, Kolkata, India.
C3 Jadavpur University
RP Malakar, S (corresponding author), Asutosh Coll, Dept Comp Sci, Kolkata, India.
EM sagnikg2013@gmail.com; sanmitmandal17@gmail.com; malakarsamir@gmail.com;
   raamsarkar@gmail.com
RI Sarkar, Ram/AAX-3822-2020
OI Sarkar, Ram/0000-0001-8813-4086
CR Abhishek, 2021, MULTIMED TOOLS APPL, V80, P3571, DOI 10.1007/s11042-020-09816-3
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Barni M, 2021, IEEE T INF FOREN SEC, V16, P1825, DOI 10.1109/TIFS.2020.3045903
   Bi XL, 2018, PATTERN RECOGN, V81, P161, DOI 10.1016/j.patcog.2018.03.028
   Bi XL, 2016, INFORM SCIENCES, V345, P226, DOI 10.1016/j.ins.2016.01.061
   Chauhan R, 2016, INTERNATIONAL CONFERENCE ON ADVANCES IN INFORMATION COMMUNICATION TECHNOLOGY & COMPUTING, 2016, DOI 10.1145/2979779.2979873
   Chen BJ, 2021, IEEE T MULTIMEDIA, V23, P3506, DOI 10.1109/TMM.2020.3026868
   Chen BJ, 2019, MULTIMED TOOLS APPL, V78, P8057, DOI 10.1007/s11042-018-6595-z
   Chen LK, 2013, J VIS COMMUN IMAGE R, V24, P244, DOI 10.1016/j.jvcir.2013.01.008
   Costanzo A, 2014, IEEE T INF FOREN SEC, V9, P1450, DOI 10.1109/TIFS.2014.2337654
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Cozzolino D, 2014, IEEE IMAGE PROC, P5312, DOI 10.1109/ICIP.2014.7026075
   Elaskily MA, 2021, J INTELL FUZZY SYST, V40, P4385, DOI 10.3233/JIFS-201192
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Gan YN, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102783
   Hussain M, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA 2014), P197, DOI 10.1109/INISTA.2014.6873618
   Jaiswal AK, 2022, NEURAL PROCESS LETT, V54, P75, DOI 10.1007/s11063-021-10620-9
   Kumar N, 2022, APPL INTELL, V52, P15417, DOI [10.1007/s10489-022-03215-x, 10.1049/PBHE040E_ch1]
   Kumar S, 2023, MULTIMED TOOLS APPL, V82, P1431, DOI 10.1007/s11042-022-12391-4
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu YQ, 2018, MULTIMED TOOLS APPL, V77, P18269, DOI 10.1007/s11042-017-5374-6
   Mahmood T, 2018, APPL INTELL, V48, P1791, DOI 10.1007/s10489-017-1038-5
   Meena KB, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102481
   Meena KB, 2020, MULTIMED TOOLS APPL, V79, P8197, DOI 10.1007/s11042-019-08343-0
   Meena KB, 2019, MULTIMED TOOLS APPL, V78, P33505, DOI 10.1007/s11042-019-08082-2
   Mohiuddin S, 2021, P 3 INT C COMPUTATIO, P29
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Niu P, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103068
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Tahaoglu G, 2022, MULTIMED TOOLS APPL, V81, P22867, DOI 10.1007/s11042-021-11503-w
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Ustubioglu B, 2016, LECT NOTES ELECTR EN, V363, P127, DOI 10.1007/978-3-319-22635-4_11
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P2311, DOI 10.1007/s11042-018-6354-1
   Wang Y, 2017, IEEE INT SYM MULTIM, P553, DOI 10.1109/ISM.2017.108
   Wu Y, 2018, LECT NOTES COMPUT SC, V11210, P170, DOI 10.1007/978-3-030-01231-1_11
   Yang JX, 2021, DIGIT SIGNAL PROCESS, V113, DOI 10.1016/j.dsp.2021.103032
   Zandi M, 2016, IEEE T INF FOREN SEC, V11, P2499, DOI 10.1109/TIFS.2016.2585118
   Zhong JL, 2020, IEEE T INF FOREN SEC, V15, P2134, DOI 10.1109/TIFS.2019.2957693
   Zhu Y, 2020, IEEE T IND INFORM, V16, P6714, DOI 10.1109/TII.2020.2982705
NR 47
TC 4
Z9 4
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19621
EP 19642
DI 10.1007/s11042-022-14287-9
EA JAN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000919383900001
DA 2024-07-18
ER

PT J
AU De Angeli, A
   Falduti, M
   Menendez-Blanco, M
   Tessaris, S
AF De Angeli, Antonella
   Falduti, Mattia
   Menendez-Blanco, Maria
   Tessaris, Sergio
TI Reporting non-consensual pornography: clarity, efficiency and distress
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image-based sexual abuse; Abusive content report; Revenge porn;
   Secondary victimisation
ID GENDER; ABUSE; MISUSE
AB According to recent legislative initiatives, non-consensual pornography is a crime in several countries and social media providers have a duty to provide their users easy to use mechanisms to report abuses. In this paper, we analyse the state of the art of the interfaces for reporting non-consensual pornography from the victim's perspective. Firstly, we analysed 45 content sharing platforms where aggressors might post non-consensual pornography. The analysis identified three distinct interaction styles for reporting the crime: Scriptum (a text-field where the user verbally describes the abuse), Bonam (a multilayered menu that includes a correct option), and Malam (a multilayered menu that does not include a correct option). Secondly, we conducted a within-subject study to evaluate the experience elicited by these interaction styles. Participants (N = 39) were given a scenario and asked to report six blurred images as non-consensual pornography using a medium-fidelity prototype. The results exposed complex trade-offs between clarity, efficiency, and distress among the different interaction styles. These trade-offs open foundational research directions transcending boundaries between human-computer interaction and multimedia studies and interfacing computer science research with the law.
C1 [De Angeli, Antonella; Falduti, Mattia; Menendez-Blanco, Maria; Tessaris, Sergio] Free Univ Bozen Bolzano, Fac Comp Sci, Piazza Domenicani 3, I-39100 Bolzano, Italy.
C3 Free University of Bozen-Bolzano
RP Falduti, M (corresponding author), Free Univ Bozen Bolzano, Fac Comp Sci, Piazza Domenicani 3, I-39100 Bolzano, Italy.
EM Antonella.DeAngeli@unibz.it; Mattia.Falduti@unibz.it;
   Maria.MenendezBlanco@unibz.it; tessaris@inf.unibz.it
RI Blanco, Maria Menendez/AAY-3819-2020
OI Blanco, Maria Menendez/0000-0002-7353-5183
FU Libera Universita di Bolzano
FX Open access funding provided by Libera Universita di Bolzano within the
   CRUI-CARE Agreement. All authors certify that they have no affiliations
   with or involvement in anyorganization or entity with any financial
   interest or non-financial interest in the subject matter or
   materialsdiscussed in this manuscript. The authors have no financial or
   proprietary interests in any material discussedin this article.
CR Anonymous, 2022, Zenodo, DOI 10.5281/ZENODO.5821243
   [Anonymous], 2022, GOV BILL ONL SAF BIL
   [Anonymous], 2012, EU PARL COUNC 2012 2
   [Anonymous], 2020, EUR PARL ONL PLATF M
   Attrill-Smith A, 2021, CYBERPSYCHOLOGY, V15, DOI 10.5817/CP2021-4-3
   Auxier B., 2021, PEW RES CTR, DOI DOI 10.4135/9781412963947.N376
   Bar-Ziv S., 2018, CONN L REV, V50, P339
   Bartneck C, 2008, INTERACT STUD, V9, P397, DOI 10.1075/is.9.3.01edi
   Bellini R, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3375176
   Bevan N, 2015, LECT NOTES COMPUT SC, V9169, P143, DOI 10.1007/978-3-319-20901-2_13
   Blackwell Lindsay, 2017, Proceedings of the ACM on Human-Computer Interaction, V1, DOI 10.1145/3134659
   Bothamley S, 2018, J AGGRESS CONFL PEAC, V10, P1, DOI 10.1108/JACPR-09-2016-0253
   Brahnam S, 2008, INTERACT COMPUT, V20, P287, DOI 10.1016/j.intcom.2008.02.001
   Brahnam S, 2012, INTERACT COMPUT, V24, P139, DOI 10.1016/j.intcom.2012.05.001
   Bundeskriminalamt, 2022, BKA POL CRIM STAT
   Caletti G. M., 2021, Virginia Journal of Law and Technology, V25, P112
   Cooper K, 2016, COMPUT HUM BEHAV, V55, P706, DOI 10.1016/j.chb.2015.10.003
   Cotten SR, 2022, CURR OPIN PSYCHOL, V45, DOI 10.1016/j.copsyc.2021.12.005
   Crawford K, 2016, NEW MEDIA SOC, V18, P410, DOI 10.1177/1461444814543163
   crimestoppers, 2022, CRIM SPEAK U P STAY
   De Angeli A., 2006, Designing Interactive Systems. DIS2006, P271
   De Angeli A., 2001, P INT C AFF HUM FACT, P467
   De Angeli A, 2008, INTERACT COMPUT, V20, P302, DOI 10.1016/j.intcom.2008.02.004
   De Angeli A, 2021, PROCEEDINGS OF THE 14TH BIANNUAL CONFERENCE OF THE ITALIAN SIGCHI CHAPTER (CHIITALY 2021), DOI 10.1145/3464385.3464739
   De Angeli A, 2009, LECT NOTES COMPUT SC, V5727, P638, DOI 10.1007/978-3-642-03658-3_69
   Drouin M, 2013, COMPUT HUM BEHAV, V29, pA25, DOI 10.1016/j.chb.2012.12.030
   Etikan I., 2016, American Journal of Theoretical and Applied Statistics, V5, P1, DOI [DOI 10.11648/J.AJTAS.20160501.11, 10.11648/j.ajtas.20160501]
   European Commission, 2000, PROP REG EUR PARL CO
   European institute for gender equality (EIGE), 2017, CYB VIOL WOM GIRLS, DOI [10.2839/876816, DOI 10.2839/876816]
   Fido D, 2020, NONCONSENSUAL IMAGE, P1, DOI [10.1007/978-3-030-59284-4_1, DOI 10.1007/978-3-030-59284-4_1]
   Freed Diana, 2017, Proceedings of the ACM on Human-Computer Interaction, V1, DOI 10.1145/3134681
   Freed D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174241
   Furlo N, 2021, CONFERENCE COMPANION PUBLICATION OF THE 2021 COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, CSCW 2021 COMPANION, P53, DOI 10.1145/3462204.3481770
   Goldstein D, 2011, INCREASING LEGAL REQ
   Halder D, 2011, VICTIMS OFFENDERS, V6, P386, DOI 10.1080/15564886.2011.607402
   Hartmann J, 2008, ACM T COMPUT-HUM INT, V15, DOI 10.1145/1460355.1460357
   Hearn J, 2019, SEXUALITIES, V22, P860, DOI 10.1177/1363460718779965
   Im Jane, 2021, P 2021 CHI C HUMAN F, P1, DOI DOI 10.1145/3411764.3445778
   Katarya Rahul, 2020, 2020 Fourth International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P485, DOI 10.1109/I-SMAC49090.2020.9243588
   Kleeman J, 2018, GUARDIAN
   Kou YB, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445279
   Kuczerawy Aleksandra, 2019, OXFORD HDB ONLINE IN
   Kumar A, 2020, I W BIOMETRIC FORENS, DOI [10.1109/IDEA49133.2020.9170705, 10.1109/iwbf49977.2020.9107962]
   Kumar A, 2019, MULTIMED TOOLS APPL, V78, P23973, DOI 10.1007/s11042-019-7234-z
   Liagre F, 2016, EUROPEAN CRIME PREVE
   Llorent VJ, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01507
   Maddocks S, 2019, REVENGE PORN 5 IMPOR
   Maeng W, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517629
   Marganski A, 2018, J INTERPERS VIOLENCE, V33, P1071, DOI 10.1177/0886260515614283
   Marwick AE, 2017, ETHICS INF TECHNOL, V19, P177, DOI 10.1007/s10676-017-9431-7
   McCann W., 2018, Criminal Justice Review, V43, P399, DOI [DOI 10.1177/0734016817741342, 10.1177/0734016817741342]
   McGlynn C, 2017, OXFORD J LEGAL STUD, V37, P534, DOI 10.1093/ojls/gqw033
   Mohanty M, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P5, DOI 10.1109/MIPR.2019.00009
   Montada L., 1994, SOC JUSTICE RES, V7, P5, DOI DOI 10.1007/BF02333820
   Niksirat KS, 2021, PROCEEDINGS OF THE 2021 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2021), P104, DOI 10.1145/3461778.3462040
   North Yorkshire Police, 2018, FIRE CRIME COMMISSIO
   Nurse JRC, 2018, OXFORD HDB CYBERPSYC, P662, DOI 10.1093/oxfordhb/9780198812746.013.35
   O'Connell A, 2020, J INTELLET PROP LAW, V15, P55, DOI 10.1093/jiplp/jpz150
   O'Malley RL, 2022, J INTERPERS VIOLENCE, V37, P258, DOI 10.1177/0886260520909186
   Obar JA, 2020, INFORM COMMUN SOC, V23, P128, DOI 10.1080/1369118X.2018.1486870
   Orth U., 2002, Social Justice Research, V15, P313, DOI [https://doi.org/10.1023/A:1021210323461, DOI 10.1023/A:1021210323461]
   Pandya A, 2021, FRONT HUM DYNAM, V3, DOI 10.3389/fhumd.2021.684137
   Polizei Berlin, 2022, INT POL BERL
   Polizia di Stato, 2022, DAT 2021 POL POST
   Polizia di Stato, 2022, SEGN ONL
   Powell A, 2019, COMPUT HUM BEHAV, V92, P393, DOI 10.1016/j.chb.2018.11.009
   Price Monroe., 2000, PROTECTING OUR CHILD, P133
   Sambasivan Nithya, 2019, proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, P1, DOI [DOI 10.1145/3290605.3300232, 10.1145/3290605]
   Smith J. A., 2015, Qualitative psychology: A practical guide to research methods
   Strohmayer A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300882
   Takhar P, 2018, HARVARD J LAW TECHNO
   Terry K, 2021, PANDEMIC FUELS 329 R
   Vallina P, 2019, IMC'19: PROCEEDINGS OF THE 2019 ACM INTERNET MEASUREMENT CONFERENCE, P245, DOI 10.1145/3355369.3355583
   van de Weijer SGA, 2019, EUR J CRIMINOL, V16, P486, DOI 10.1177/1477370818773610
   Web Foundation, 2021, ONL GEND BAS VIOL AF
   Yan J, 2017, LECT NOTES COMPUT SC, V10368, P96, DOI 10.1007/978-3-319-62033-6_12
   Yeh CY, 2020, IEEE WINT CONF APPL, P53, DOI [10.1109/WACVW50321.2020.9096939, 10.1109/wacvw50321.2020.9096939]
NR 77
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JAN 17
PY 2023
DI 10.1007/s11042-022-14291-z
EA JAN 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G4YR2
UT WOS:000989233400001
OA hybrid
DA 2024-07-18
ER

PT J
AU Rani, JSJ
   Augasta, MG
AF Rani, J. Stella Janci
   Augasta, M. Gethsiyal
TI PoolNet deep feature based person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human; person re-identification; Deep features; Feature extraction; Deep
   learning; Convolution neural networks
ID NETWORK
AB Learning with Deep Neural Networks has recently reached state-of-the-art outcomes for Person Re-Identification. Effective learning can be accomplished only with efficient features robust to illumination and viewpoint changes. This paper proposes a new feature representation method called PoolNet Deep Feature (PNDF) for person re-identification with Convolution Neural Networks. The proposed CNN architecture called PoolNet consists of two Pool Added Blocks (PAB) and a Pool Concatenated Block (PCB) to extract the more sophisticated dominant and precise features for better learning towards a person's re-identification. The efficiency of the proposed method is demonstrated in terms of re-identification accuracy by implementing it on the challenging small scale & large-scale person re-identification datasets such as VIPeR, Market1501, CUHK03, GRID, and LaST.
C1 [Rani, J. Stella Janci] Manonmaniam Sundaranar Univ, Tirunelveli, Tamil Nadu, India.
   [Rani, J. Stella Janci] Sarah Tucker Coll, Tirunelveli, Tamil Nadu, India.
   [Augasta, M. Gethsiyal] Kamaraj Coll, Thoothukudi, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University
RP Augasta, MG (corresponding author), Kamaraj Coll, Thoothukudi, Tamil Nadu, India.
EM jstellajara17@gmail.com; augastaglady@gmail.com
RI M, Gethsiyal Augasta/AAS-2164-2020; J, STELLA JANCI RANI/HJH-0349-2022
OI M, Gethsiyal Augasta/0000-0002-1975-7623; J, STELLA JANCI
   RANI/0000-0002-9381-9482
CR Ainam JP, 2019, IEEE ACCESS, V7, P27899, DOI 10.1109/ACCESS.2019.2901599
   [Anonymous], 2015, PROC CVPR IEEE
   Chen BH, 2019, IEEE I CONF COMP VIS, P371, DOI 10.1109/ICCV.2019.00046
   Chen JX, 2017, PROC CVPR IEEE, P5330, DOI 10.1109/CVPR.2017.566
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Dai ZZ, 2019, IEEE I CONF COMP VIS, P3690, DOI 10.1109/ICCV.2019.00379
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Guan'an Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P275, DOI 10.1007/978-3-030-58598-3_17
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans Alexander, 2017, ARXIV170307737
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Jayapriya K, 2020, MULTIMED TOOLS APPL, V79, P29399, DOI 10.1007/s11042-020-09528-8
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar M, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3439798
   Lee HT, 2009, ACM T WEB, V3, DOI 10.1145/1541822.1541823
   Lefkimmiatis S, 2018, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR.2018.00338
   Li MX, 2020, IEEE T PATTERN ANAL, V42, P1770, DOI 10.1109/TPAMI.2019.2903058
   Li W, 2017, P 26 INT JOINT C ART, DOI [10.48550/arXiv.1705.04724, DOI 10.48550/ARXIV.1705.04724]
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin Y., 2017, ARXIV
   Liu FY, 2019, IEEE I CONF COMP VIS, P6638, DOI 10.1109/ICCV.2019.00674
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Loy CC, 2010, INT J COMPUT VISION, V90, P106, DOI 10.1007/s11263-010-0347-5
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2019, NEUROCOMPUTING, V349, P133, DOI 10.1016/j.neucom.2019.02.021
   Luo CC, 2019, IEEE I CONF COMP VIS, P4975, DOI 10.1109/ICCV.2019.00508
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Martinel N, 2019, IEEE COMPUT SOC CONF, P1544, DOI 10.1109/CVPRW.2019.00196
   Opitz M, 2016, LECT NOTES COMPUT SC, V9907, P386, DOI 10.1007/978-3-319-46487-9_24
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Qiang-Qiang Ren, 2019, Intelligent Computing Methodologies. 15th International Conference, ICIC 2019. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11645), P65, DOI 10.1007/978-3-030-26766-7_7
   Quispe R, 2021, INT C PATT RECOG, P2980, DOI 10.1109/ICPR48806.2021.9412017
   Rani J, 2020, TEST ENG MANAGEMENT, P13776
   Rani JSJ, 2022, MULTIMED TOOLS APPL, V81, P26035, DOI 10.1007/s11042-022-12888-y
   Ren CX, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106995
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Shengcai Liao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P456, DOI 10.1007/978-3-030-58621-8_27
   Shi H, 2015, ARXIV, DOI DOI 10.48550/ARXIV.1511.07545
   Shu XJ, 2022, IEEE T CIRC SYST VID, V32, P4390, DOI 10.1109/TCSVT.2021.3128214
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song JF, 2019, PROC CVPR IEEE, P719, DOI 10.1109/CVPR.2019.00081
   Song M, 2015, 8 INT C IMAGE SIGNAL, DOI [10.1109/CISP.2015.7407963, DOI 10.1109/CISP.2015.7407963]
   Su C, 2016, LECT NOTES COMPUT SC, V9906, P475, DOI 10.1007/978-3-319-46475-6_30
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tang ZM, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3501405
   Tao DP, 2018, IEEE T CIRC SYST VID, V28, P2657, DOI 10.1109/TCSVT.2017.2726580
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang N, 2013, P ADV NEURAL INFORM
   Wu D, 2019, NEUROCOMPUTING, V324, P69, DOI 10.1016/j.neucom.2018.03.073
   Wu L, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1601.07255
   Wu SX, 2016, IEEE WINT CONF APPL
   Yang F, 2019, PATTERN RECOGN, V86, P143, DOI 10.1016/j.patcog.2018.08.015
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Yu HX, 2020, IEEE T PATTERN ANAL, V42, P956, DOI 10.1109/TPAMI.2018.2886878
   Zeng XY, 2013, IEEE I CONF COMP VIS, P121, DOI 10.1109/ICCV.2013.22
   Zhang J, 2019, NIGHT PERSON RE IDEN, DOI [10.1109/ACCESS.2019.2929854, DOI 10.1109/ACCESS.2019.2929854]
   Zhang X, 2017, ARXIV
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou KY, 2022, IEEE T PATTERN ANAL, V44, P5056, DOI 10.1109/TPAMI.2021.3069237
   Zhou SP, 2019, IEEE T IMAGE PROCESS, V28, P4671, DOI 10.1109/TIP.2019.2908065
NR 70
TC 3
Z9 3
U1 3
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24967
EP 24989
DI 10.1007/s11042-023-14364-7
EA JAN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000913484600001
DA 2024-07-18
ER

PT J
AU Srinivasulu, M
   Shivamurthy, G
   Venkataramana, B
AF Srinivasulu, M.
   Shivamurthy, G.
   Venkataramana, B.
TI Quality of service aware energy efficient multipath routing protocol for
   internet of things using hybrid optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IoT; Routing scheme; Hybrid optimization; QoS aware energy efficient
   multipath; Clustering; Cluster head
ID IOT; NETWORK
AB The Internet of Things (IoT) is evolving from a media term to a reality. We entered a new age of invention and creativity as a result of the development of IoT. Despite the fact that IoT has a lot of promise in the modern world, there are still a lot of obstacles. The main focus of this study is to improve the IoT's resilience by resolving energy optimization, routing, and other issues to increase network lifetime. In this research, we present an IoT hybrid optimization algorithm-based QoS aware energy efficient multipath routing (QEMR) protocol. The first step is to achieve optimal clustering using a modified teaching-learning-based optimization (MTLO) method. Next, we determine the cluster head (CH) using the nonlinear regression-based pigeon optimization (NR-PO) method. For routing and determining the optimum path, we use the Deep Kronecker Neural Network (DKNN). The NS-3 simulation tool is utilised to model our proposed routing QEMR system and assess its effectiveness. The proposed QEMR scheme's simulation findings are contrasted with existing techniques: REER, Rumor, and EOMR techniques in terms of the impacts of node density, node speed, and network traffic. In comparison of energy usage and the effect of node density, the suggested QEMR system uses less energy than the REER, Rumor, and EOMR schemes by 86.296%, 81.94%, and 75% respectively. The proposed QEMR scheme is used for studying the application of problem by enhancing the network performance and improving QoS by implementing DKNN based routing methodology to send data from source to the destination by selecting the optimal path.
C1 [Srinivasulu, M.] Univ BDT, Dept MCA, Coll Engn, Davanagere 577004, Karnataka, India.
   [Shivamurthy, G.] VTU PG Ctr, Dept CSE Master Comp Applicat, Muddenahalli 562101, Karnataka, India.
   [Venkataramana, B.] VIT, Sch Adv Sci, Dept Math, Vellore 632014, Tamil Nadu, India.
C3 Visvesvaraya Technological University; Visvesvaraya Technological
   University; Vellore Institute of Technology (VIT); VIT Vellore
RP Srinivasulu, M (corresponding author), Univ BDT, Dept MCA, Coll Engn, Davanagere 577004, Karnataka, India.
EM srinivasulu@vtu.ac.in
RI V, Balaji/IAP-7861-2023
OI V, Balaji/0000-0002-7795-641X
CR Ahmadkelayeh S, 2023, CHEM ENG COMMUN, V210, P398, DOI 10.1080/00986445.2022.2050711
   Badi A, 2021, IEEE INTERNET THINGS, V8, P13582, DOI 10.1109/JIOT.2021.3066531
   Balakrishnan N, 2021, INTERNET THINGS-NETH, V14, DOI 10.1016/j.iot.2019.100112
   Bebortta S, 2021, J NETW SYST MANAG, V29, DOI 10.1007/s10922-020-09572-7
   Bhatia VK, 2021, MATER TODAY-PROC
   Dogra R, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/8006751
   Du YF, 2021, INT J ELEC POWER, V133, DOI 10.1016/j.ijepes.2021.107110
   Famitafreshi G, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093097
   Ghalambaz M., 2021, THERM ENG, V27
   Goudarzi S, 2021, IEEE T GREEN COMMUN, V5, P2076, DOI 10.1109/TGCN.2021.3091388
   Ibrahim M, 2021, PEER PEER NETW APPL, V14, P1154, DOI 10.1007/s12083-021-01095-5
   Iwendi C, 2021, SOFTWARE PRACT EXPER, V51, P2558, DOI 10.1002/spe.2797
   Jaiswal K, 2020, WIRELESS PERS COMMUN, V111, P2493, DOI 10.1007/s11277-019-07000-x
   Khaleghnasab R, 2020, INT J INF TECH DECIS, V19, P1581, DOI 10.1142/S0219622020500388
   Kumar S, 2020, IEEE SYST J, V14, P4663, DOI 10.1109/JSYST.2020.2975823
   Nizetic S, 2020, J CLEAN PROD, V274, DOI 10.1016/j.jclepro.2020.122877
   Pirbhulal S, 2020, IEEE NETWORK, V34, P72, DOI 10.1109/MNET.001.1800547
   Prasad AY, 2019, INT J INTELL UNMANNE, V8, P23, DOI 10.1108/IJIUS-02-2019-0011
   Prasad A.Y., 2019, TELKOMNIKA, V17, P1758, DOI DOI 10.12928/TELKOMNIKA.V17I4.12004
   Praveen KV, 2021, WIRELESS PERS COMMUN, V117, P1187, DOI 10.1007/s11277-020-07917-8
   Rana B, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4166
   Raval M, 2021, INTERNET THINGS-NETH, V13, DOI 10.1016/j.iot.2020.100354
   Sadeeq M.A., 2021, J. Appl. Sci. Technol. Trends, V2, P80, DOI [10.38094/jastt20285, DOI 10.38094/JASTT20285]
   Sadrishojaei M, 2021, INT J COMMUN SYST, V34, DOI 10.1002/dac.4964
   Shad MN, 2022, WIRELESS PERS COMMUN, V126, P2249, DOI 10.1007/s11277-021-09051-5
   Shahryari OK, 2021, PERVASIVE MOB COMPUT, V74, DOI 10.1016/j.pmcj.2021.101395
   Shreyas J., 2021, International Journal of Intelligent Internet of Things Computing, V1, P230, DOI [10.1504/IJIITC.2021.115705, DOI 10.1504/IJIITC.2021.115705]
   Singh J, 2022, SECURITY COMMUNICATI
   Singh P, 2019, J SENSORS, V2019, DOI 10.1155/2019/8691878
   Tabatabaei S, 2021, CYBERNET SYST, V52, P477, DOI 10.1080/01969722.2021.1899597
   Yang S, 2022, J SENSORS, V2022, DOI 10.1155/2022/4327414
   Zhang XD, 2021, SUSTAIN ENERGY TECHN, V46, DOI 10.1016/j.seta.2021.101208
NR 32
TC 11
Z9 11
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26829
EP 26858
DI 10.1007/s11042-022-14285-x
EA JAN 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000926402900002
DA 2024-07-18
ER

PT J
AU Chowdhuri, P
   Pal, P
   Si, T
AF Chowdhuri, Partha
   Pal, Pabitra
   Si, Tapas
TI A novel steganographic technique for medical image using SVM and IWT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Integer wavelet transform; Support vector machine;
   Circular array; ROI & NROI; Medical image
ID HIGH-CAPACITY; WATERMARKING
AB This study presents an efficient authentication scheme for digital image steganography on medical images benefiting from the combination of both techniques: Support Vector Machine (SVM) and Integer Wavelet Transform (IWT). We use two different strategies in this paper, where SVM is used first to separate the Region of Interest (ROI) from Non-Region of Interest (NROI) in the medical image. Then IWT is applied to embed secret information within the NROI part of the medical image (Cover Image). Moreover, we have applied a circular array and a shared secret key to enhance the robustness of the proposed scheme. The research looked into the various experimental analyses to establish the acceptability of the existing scheme. The simulation is performed to measure the imperceptibility using Peak Signal to Noise Ratio (PSNR) and to test the robustness using the Structural Similarity Index Measure (SSIM). The experimental result shows good imperceptibility with a PSNR of 64 dB and better robustness with a SSIM of 0.96 for the proposed steganographic scheme.
C1 [Chowdhuri, Partha] Vidyasagar Univ, Comp Sci, Vidyasagar Univ Rd, Paschim Medinipur 721102, West Bengal, India.
   [Pal, Pabitra] Maulana Abul Kalam Azad Univ Technol, Dept Comp Applicat, Haringhata 741249, West Bengal, India.
   [Si, Tapas] Bankura Unnayani Inst Engn, Dept Comp Sci & Engn, Bankura 722146, West Bengal, India.
C3 Vidyasagar University; Maulana Abul Kalam Azad University of Technology
RP Pal, P (corresponding author), Maulana Abul Kalam Azad Univ Technol, Dept Comp Applicat, Haringhata 741249, West Bengal, India.
EM prc.email@gmail.com; pabipaltra@gmail.com; shritapassi.ai@gmail.com
RI Pal, Pabitra/AAA-1391-2020
OI Pal, Pabitra/0000-0002-2866-7320; Si, Tapas/0000-0001-8267-0304
CR An FP, 2021, MULTIMED TOOLS APPL, V80, P15017, DOI 10.1007/s11042-021-10515-w
   Filippini J, 2020, RADIOLOGY DATA CANC
   Ganic Emir., 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Garg M, 2023, MULTIMED TOOLS APPL, V82, P6271, DOI 10.1007/s11042-022-13596-3
   Ghosal SK, 2018, MULTIMED TOOLS APPL, V77, P30403, DOI 10.1007/s11042-018-6126-y
   Jeevitha S, 2020, HEALTH TECHNOL-GER, V10, P217, DOI 10.1007/s12553-018-00285-1
   Kadhim IJ, 2020, COGN SYST RES, V60, P20, DOI 10.1016/j.cogsys.2019.11.002
   Karakus S, 2020, MED HYPOTHESES, V139, DOI 10.1016/j.mehy.2020.109691
   Kumar V, 2018, MULTIMED TOOLS APPL, V77, P13279, DOI 10.1007/s11042-017-4947-8
   Mehta D, 2022, MULTIMED TOOLS APPL, V81, P459, DOI 10.1007/s11042-021-11351-8
   Meng L, 2022, MULTIMED TOOLS APPL, P1
   Muhuri PK, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106257
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P3943, DOI 10.1007/s11042-016-4196-2
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Rai A, 2017, MULTIMED TOOLS APPL, V76, P18605, DOI 10.1007/s11042-016-4215-3
   Sabbane F, 2019, MULTIMED TOOLS APPL, V78, P34129, DOI 10.1007/s11042-019-08134-7
   Singh A, 2017, INT J MED INFORM, V108, P110, DOI 10.1016/j.ijmedinf.2017.10.010
   Smith K, 2020, CANC IMAGING ARCHIVE
   Song XX, 2022, MATH COMPUT SIMULAT, V198, P1, DOI 10.1016/j.matcom.2022.02.008
   Subhedar MS, 2019, MULTIMED TOOLS APPL, V78, P22155, DOI 10.1007/s11042-019-7512-9
   Thabit R, 2021, MULTIMED TOOLS APPL, V80, P13439, DOI 10.1007/s11042-020-10421-7
   Thanki R, 2017, ENG SCI TECHNOL, V20, P1366, DOI 10.1016/j.jestch.2017.06.001
   The cancer imaging archive, 2019, TCGA BRCA
   Tseng YC, 2002, IEEE T COMMUN, V50, P1227, DOI 10.1109/TCOMM.2002.801488
   Vulli A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082988
   Yadav SK, 2023, P 3 INT C INFORM MAN, P53
   Zhang B, 2023, MULTIMED TOOLS APPL, V82, P21867, DOI 10.1007/s11042-020-09629-4
NR 27
TC 4
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20497
EP 20516
DI 10.1007/s11042-022-14301-0
EA JAN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000909480400001
PM 36628353
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Mundhe, P
   Phad, P
   Yuvaraj, R
   Verma, S
   Venkatesan, S
AF Mundhe, Pravin
   Phad, Pooja
   Yuvaraj, R.
   Verma, Shekhar
   Venkatesan, S.
TI Blockchain-based conditional privacy-preserving authentication scheme in
   VANETs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VANETs; Security; Conditional privacy; Blockchain
ID EFFICIENT; SECURITY; FRAMEWORK; VEHICLES; CLOUD
AB In vehicular ad hoc networks (VANETs), a vehicle must be authenticated to ensure its messages' correctness. The authentication mechanism should be privacy-preserving to protect the vehicle's real identity. However, an authenticated vehicle may misbehave, which forms the basis for certificate revocation lists (CRLs) requirement. But, the CRLs need a large storage and communication overhead. The difficulties like the huge computation overhead, the heavy burden of storing and managing pseudo-identities, and handling ever-increasing certificate revocation makes the existing authentication schemes impracticable. To overcome these difficulties, we propose a hybrid blockchain-based conditional privacy-preserving authentication (BCPPA) scheme in VANETs. In BCPPA, vehicles obtain pseudo-identities from the trusted authority that manages the network. A vehicle uses the received pseudo-identities to achieve anonymous authentication and communicate with other network members. The pseudo-identities with encrypted, real identities are both saved into the blockchain to ensure conditional privacy and member revocation. A receiver can verify the sender's pseudo-identity using the proposed privacy-preserving authentication mechanism. We evaluate the scheme's performance using the Ethereum blockchain and computing platform. The security analysis and experimental results show that the proposed scheme is effective in providing authentication and privacy and has reduced computation overhead as compared to existing schemes.
C1 [Mundhe, Pravin] GITAM Sch Technol, Dept CSE, Hyderabad, India.
   [Phad, Pooja] G Narayanamma Inst Technol & Sci, Dept IT, Hyderabad, India.
   [Yuvaraj, R.; Verma, Shekhar; Venkatesan, S.] IIIT, Dept IT, Allahabad, India.
C3 Gandhi Institute of Technology & Management (GITAM); Indian Institute of
   Information Technology Allahabad
RP Mundhe, P (corresponding author), GITAM Sch Technol, Dept CSE, Hyderabad, India.
EM mundhe.pravin@gmail.com; poojaphad26@gmail.com; pc12016003@iiita.ac.in;
   sverma@iiita.ac.in; venkat@iiita.ac.in
OI Mundhe, Pravin/0000-0002-1290-8281
CR Akinyele JA, 2013, J CRYPTOGR ENG, V3, P111, DOI 10.1007/s13389-013-0057-3
   Ali I, 2021, IEEE T VEH TECHNOL, V70, P1278, DOI 10.1109/TVT.2021.3050399
   Ali I, 2019, J SYST ARCHITECT, V99, DOI 10.1016/j.sysarc.2019.101636
   Aloqaily M, 2019, AD HOC NETW, V90, DOI 10.1016/j.adhoc.2019.02.001
   Alrawais A, 2018, PROCEDIA COMPUT SCI, V129, P312, DOI 10.1016/j.procs.2018.03.081
   [Anonymous], 2010, International Conference on Heterogeneous Networking for Quality, Reliability, Security and Robustness
   Azees M, 2017, IEEE T INTELL TRANSP, V18, P2467, DOI 10.1109/TITS.2016.2634623
   Bao Z, 2018, ARXIV
   Biswas S, 2019, IEEE INTERNET THINGS, V6, P4650, DOI 10.1109/JIOT.2018.2874095
   Canetti R, 2016, LECT NOTES COMPUT SC, V9615, P265, DOI 10.1007/978-3-662-49387-8_11
   Cui ZH, 2020, IEEE T SERV COMPUT, V13, P241, DOI 10.1109/TSC.2020.2964537
   Dorri A, 2017, IEEE COMMUN MAG, V55, P119, DOI 10.1109/MCOM.2017.1700879
   Han Y, 2018, IEEE ACCESS, V6, P20209, DOI 10.1109/ACCESS.2018.2822806
   Karati A, 2018, IEEE INTERNET THINGS, V5, P2904, DOI 10.1109/JIOT.2017.2741580
   Kondareddy Y., 2010, P IEEE GLOB TEL C GL, P1
   Kumar V., 2018, SOFT COMPUTING THEOR, P715
   Lai YX, 2019, AD HOC NETW, V91, DOI 10.1016/j.adhoc.2019.101876
   Liu H, 2018, IEEE NETWORK, V32, P78, DOI 10.1109/MNET.2018.1700344
   Lu ZJ, 2019, IEEE T VLSI SYST, V27, P2792, DOI 10.1109/TVLSI.2019.2929420
   Marvasti-Zadeh S. M., 2019, IEEE Trans. Intell. Transp. Syst.
   Mundhe P, 2021, COMPUT SCI REV, V41, DOI 10.1016/j.cosrev.2021.100411
   Mundhe P, 2020, IEEE SYST J, V14, P5463, DOI 10.1109/JSYST.2020.2980297
   Mundhe P, 2020, WIRELESS PERS COMMUN, V114, P853, DOI 10.1007/s11277-020-07396-x
   Nakamoto S, 2008, BITCOIN PEER TO PEER, DOI DOI 10.1007/S10838-008-9062-0
   Rajput U, 2017, IEEE ACCESS, V5, P12014, DOI 10.1109/ACCESS.2017.2717999
   Sakiz F, 2017, AD HOC NETW, V61, P33, DOI 10.1016/j.adhoc.2017.03.006
   Shao J, 2016, IEEE T VEH TECHNOL, V65, P1711, DOI 10.1109/TVT.2015.2405853
   Vijayakumar P, 2018, FUTURE GENER COMP SY, V78, P943, DOI 10.1016/j.future.2016.11.024
   Vijayakumar P, 2022, IEEE T INTELL TRANSP, V23, P1630, DOI 10.1109/TITS.2021.3099488
   Vijayakumar P, 2017, CLUSTER COMPUT, V20, P2439, DOI 10.1007/s10586-017-0848-x
   Vijayakumar P, 2016, IEEE T INTELL TRANSP, V17, P1015, DOI 10.1109/TITS.2015.2492981
   Yang XD, 2018, PROCEEDINGS OF 2018 IEEE 3RD ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC 2018), P2334, DOI 10.1109/IAEAC.2018.8577477
   Zhang L, 2019, VEH COMMUN, V16, P85, DOI 10.1016/j.vehcom.2019.03.003
   Zhang L, 2020, IEEE T DEPEND SECURE, V17, P634, DOI 10.1109/TDSC.2018.2797190
   Zhang L, 2017, IEEE T INTELL TRANSP, V18, P516, DOI 10.1109/TITS.2016.2579162
   Zhang LL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (IEEE ICIA 2017), P947, DOI 10.1109/ICInfA.2017.8079039
   Zhang XH, 2019, IEEE ACCESS, V7, P58241, DOI 10.1109/ACCESS.2018.2890736
   Zhang YH, 2018, INFORM SCIENCES, V462, P262, DOI 10.1016/j.ins.2018.06.018
NR 38
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24155
EP 24179
DI 10.1007/s11042-022-14288-8
EA DEC 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000901695800001
DA 2024-07-18
ER

PT J
AU Lasker, A
   Ghosh, M
   Obaidullah, SM
   Chakraborty, C
   Roy, K
AF Lasker, Asifuzzaman
   Ghosh, Mridul
   Obaidullah, Sk Md
   Chakraborty, Chandan
   Roy, Kaushik
TI LWSNet-a novel deep-learning architecture to segregate Covid-19 and
   pneumonia from x-ray imagery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stack ensemble technique; Deep neural network; Chest radiography; Lung
   diseases; Pneumonia; Covid-19
ID CLASSIFICATION
AB Automatic detection of lung diseases using AI-based tools became very much necessary to handle the huge number of cases occurring across the globe and support the doctors. This paper proposed a novel deep learning architecture named LWSNet (Light Weight Stacking Network) to separate Covid-19, cold pneumonia, and normal chest x-ray images. This framework is based on single, double, triple, and quadruple stack mechanisms to address the above-mentioned tri-class problem. In this framework, a truncated version of standard deep learning models and a lightweight CNN model was considered to conviniently deploy in resource-constraint devices. An evaluation was conducted on three publicly available datasets alongwith their combination. We received 97.28%, 96.50%, 97.41%, and 98.54% highest classification accuracies using quadruple stack. On further investigation, we found, using LWSNet, the average accuracy got improved from individual model to quadruple model by 2.31%, 2.55%, 2.88%, and 2.26% on four respective datasets.
C1 [Lasker, Asifuzzaman; Obaidullah, Sk Md] Aliah Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Ghosh, Mridul] Shyampur Siddheswari Mahavidyalaya, Dept Comp Sci, Howrah, India.
   [Chakraborty, Chandan] NITTTR, Dept Comp Sci & Engn, Kolkata, India.
   [Roy, Kaushik] West Bengal State Univ, Dept Comp Sci, Barasat, India.
C3 Aliah University; National Institute of Technical Teachers Training &
   Research, Kolkata; West Bengal State University
RP Ghosh, M (corresponding author), Shyampur Siddheswari Mahavidyalaya, Dept Comp Sci, Howrah, India.
EM asifuzzaman.lasker@gmail.com; mridulxyz@gmail.com;
   sk.obaidullah@gmail.com; chakraborty.nitttrk@gmail.com;
   kaushik.mrg@gmail.com
RI GHOSH, DR. MRIDUL/AEY-8327-2022
OI GHOSH, DR. MRIDUL/0000-0002-4777-2492
FU Indian Council of Medical Research, Govt of India;  [BMI/12(81)/2021]
FX AcknowledgementThe fourth author would like to acknowledge Indian
   Council of Medical Research, Govt of India [Ref. No. BMI/12(81)/2021]
   for the research work.
CR Abdar M, 2021, ARXIV
   Aggarwal S, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12749
   Ahmed Faizan, 2021, ACM Digital Government: Research and Practice, V2, DOI 10.1145/3431804
   Ai T, 2020, RADIOLOGY, V296, pE32, DOI 10.1148/radiol.2020200642
   [Anonymous], 2020, PEDIATR MED RODZ, V16, P9, DOI 10.15557/PiMR.2020.0003
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Babu PSA, 2021, APPL INTELL, V51, P3104, DOI 10.1007/s10489-021-02199-4
   Chakraborty S, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19042013
   Chatterjee S, 2020, ARXIV
   Chowdhury M., 2022, COVID 19 RADIOGRAPHY
   Chowdhury NK, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.551
   Cohen J.P., 2020, arXiv
   Fan ZM, 2020, J HEALTHC ENG, V2020, DOI 10.1155/2020/8889412
   Ghosh M, 2022, DEEP LEARNING BASED, P121
   Ghosh M, 2021, MULTIMED TOOLS APPL, V80, P29095, DOI 10.1007/s11042-021-11103-8
   Ghosh M, 2022, VISUAL COMPUT, V38, P1645, DOI 10.1007/s00371-021-02094-6
   Gifani P, 2021, INT J COMPUT ASS RAD, V16, P115, DOI 10.1007/s11548-020-02286-w
   Gour M, 2020, ARXIV
   Gupta A, 2019, COMPUT SCI-AGH, V20, P389, DOI 10.7494/csci.2019.20.4.3163
   Gupta A, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106859
   Gupta RK, 2021, INT J UNCERTAIN FUZZ, V29, P921, DOI 10.1142/S0218488521500410
   Hou J, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-95680-6
   Huang CL, 2020, LANCET, V395, P497, DOI [10.1016/S0140-6736(20)30183-5, 10.1016/S0140-6736(20)30211-7]
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Jain R, 2021, APPL INTELL, V51, P1690, DOI 10.1007/s10489-020-01902-1
   Jakubovitz D, 2018, ARXIV
   Kanwal A, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14116785
   Karakanis S, 2021, COMPUT BIOL MED, V130, DOI 10.1016/j.compbiomed.2020.104181
   Lafraxo S, 2020, COLLOQ INF SCI TECH, P489, DOI [10.1109/CiSt49399.2021.9357250, 10.1109/CIST49399.2021.9357250]
   Lasker Asifuzzaman, 2022, Computational Intelligence in Pattern Recognition: Proceedings of CIPR 2022. Lecture Notes in Networks and Systems (480), P313, DOI 10.1007/978-981-19-3089-8_30
   Li T., 2020, ARXIV
   Li XS, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/5528441
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Loey M, 2022, COMPUT BIOL MED, V142, DOI 10.1016/j.compbiomed.2022.105213
   Mangal A, 2020, ARXIV
   Mohamed MT, 2019, PHYSIOTHER THEOR PR, V35, P1233, DOI 10.1080/09593985.2018.1474511
   Mooney P, 2020, Chest X-Ray Images (Pneumonia)
   Mukherjee H, 2021, COVID 19 PREDICTION, P99
   Mukherjee H, 2021, APPL INTELL, V51, P2777, DOI 10.1007/s10489-020-01943-6
   Mukherjee H, 2021, COGN COMPUT, DOI 10.1007/s12559-020-09775-9
   Munusamy H, 2021, BIOCYBERN BIOMED ENG, V41, P1025, DOI 10.1016/j.bbe.2021.06.011
   Niu ST, 2021, IEEE J BIOMED HEALTH, V25, P3784, DOI 10.1109/JBHI.2021.3051470
   Paluru N, 2021, IEEE T NEUR NET LEAR, V32, P932, DOI 10.1109/TNNLS.2021.3054746
   Prashant P, 2020, COVID 19 DIAGNOSIS U
   R Mohammadi, 2020, J Biomed Phys Eng, V10, P559, DOI 10.31661/jbpe.v0i0.2008-1153
   Rahman T, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104319
   Refat CMM, 2020, CHEST XRAY IMAGES PN
   Rezaee Khosro, 2020, 2020 27th National and 5th International Iranian Conference on Biomedical Engineering (ICBME), P234, DOI 10.1109/ICBME51989.2020.9319426
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saha P, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-87523-1
   Saha Prottoy, 2021, Inform Med Unlocked, V22, P100505, DOI 10.1016/j.imu.2020.100505
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sharifrazi D, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102622
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh D, 2021, INT J PATTERN RECOGN, V35, DOI 10.1142/S0218001421510046
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tang SJ, 2021, IEEE T IND INFORM, V17, P6539, DOI 10.1109/TII.2021.3057683
   Ter-Sarkisov A, 2021, INT J AUTOMATION ART, V2, P01
   Trivedi M, 2022, MULTIMED TOOLS APPL, V81, P5515, DOI 10.1007/s11042-021-11807-x
   Upadhyay K, 2020, IET IMAGE PROCESS, V14, P4059, DOI 10.1049/iet-ipr.2020.1127
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Zhang X, 2021, STRESS BIOL, V1, DOI [10.1007/s44154-021-00004-3, 10.1038/s41598-021-86694-1]
   Zhou C, 2021, J MED VIROL, V93, P2857, DOI 10.1002/jmv.26741
   Zhu J, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0236621
NR 64
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21801
EP 21823
DI 10.1007/s11042-022-14247-3
EA DEC 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000896312100001
PM 36532598
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Devi, DAS
   Eluri, S
AF Devi, Anjani Suputri D.
   Eluri, Suneetha
TI A novel Leaky Rectified Triangle Linear Unit based Deep Convolutional
   Neural Network for facial emotion recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive Bilateral Filter Contourlet Transform (ABFCT); Chehra face
   detector; Cascaded regression tree; Local Shearlet Tetra Pattern
   (LSTrP); Leaky Rectified Triangle Linear Unit activation function based
   Deep Convolutional Neural Network (LRTLU-DCNN)
ID SELECTION
AB In numerous fields, Facial Expression Recognitions (FER) is employed, which is a vital topic. The Facial Expressions (FE) is categorized by the FER into human emotions. Most networks are formed for facial Emotion Recognitions (ER); however, they all still possess some challenges like performance degradation together with the lowest accuracy. A novel Leaky Rectified Triangle Linear Unit (LRTLU) Activation Function (AF) based Deep Convolutionals Neural Networks (DCNN) is proposed for achieving better CA. To pre-process the input images, the unique filtering technique Adaptive Bilateral Filter Contourlet Transform (ABFCT) is used. The Chehra face detector was then used to detect the face in the filtered image. The Facial landmarks are recovered from the facial detected image using a cascaded regression tree, and essential features are extracted based on the identified Facial LandMarks. The recovered feature set is then fed into the Leaky Rectified Triangle Linear Unit AF-based Deep Convolutional Neural Networks (LRTLU-DCNN). It classifies the expressions of the inputted image into '6' emotions, say happy, sad, neutral, angry, disgust, together with surprise. The experimentation is performed utilizing the CK+ and JAFFE datasets. The proposed work attains the classification's accuracy of 99.67347% for the CK+ dataset together with 99.65986% for the JAFFE dataset. The experimental outcome exhibits that the LRTLU-DCNN is better analogized to other prevailing methods.
C1 [Devi, Anjani Suputri D.; Eluri, Suneetha] Jawaharlal Nehru Technol Univ, Dept Comp Sci & Engn, Kakinada, India.
C3 Jawaharlal Nehru Technological University - Kakinada
RP Devi, DAS (corresponding author), Jawaharlal Nehru Technol Univ, Dept Comp Sci & Engn, Kakinada, India.
EM anjanisuputridevi@gmail.com
CR Aamir M, 2020, ARAB J SCI ENG, V45, P10605, DOI 10.1007/s13369-020-04811-0
   Alphonse AS, 2021, J AMB INTEL HUM COMP, V12, P3447, DOI 10.1007/s12652-020-02517-7
   Altameem T, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.104044
   Arora M, 2018, NATL ACAD SCI LETT, V41, P365, DOI 10.1007/s40009-018-0694-2
   Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240
   Bougourzi F, 2020, EXPERT SYST APPL, V156, DOI 10.1016/j.eswa.2020.113459
   Boutorh A, 2016, ENG APPL ARTIF INTEL, V51, P58, DOI 10.1016/j.engappai.2016.01.004
   Cai Y., 2018, Smart Health, V5, P15, DOI [10.1016/j.smhl.2017.11.002, DOI 10.1016/J.SMHL.2017.11.002]
   Chowdary MK, 2023, NEURAL COMPUT APPL, V35, P23311, DOI 10.1007/s00521-021-06012-8
   Happy SL, 2019, PATTERN RECOGN LETT, V128, P162, DOI 10.1016/j.patrec.2019.08.025
   Janu N, 2017, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE AND ENGINEERING (CONFLUENCE 2017), P591, DOI 10.1109/CONFLUENCE.2017.7943220
   Jiao J, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.951
   Kas M, 2021, INFORM SCIENCES, V549, P200, DOI 10.1016/j.ins.2020.10.065
   Kumar P, 2018, INFORM SCIENCES, V428, P30, DOI 10.1016/j.ins.2017.10.046
   Lakshmi D, 2021, MICROPROCESS MICROSY, V82, DOI 10.1016/j.micpro.2021.103834
   Lekdioui K, 2017, SIGNAL PROCESS-IMAGE, V58, P300, DOI 10.1016/j.image.2017.08.001
   Li HD, 2020, KNOWL-BASED SYST, V204, DOI 10.1016/j.knosys.2020.106172
   Li J, 2020, NEUROCOMPUTING, V411, P340, DOI 10.1016/j.neucom.2020.06.014
   Li ZD, 2021, FUTURE GENER COMP SY, V114, P619, DOI 10.1016/j.future.2020.08.034
   Lin CH, 2016, ISA T, V64, P405, DOI 10.1016/j.isatra.2016.05.013
   Liu YY, 2018, PATTERN RECOGN, V84, P251, DOI 10.1016/j.patcog.2018.07.016
   Mehendale N, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-2234-1
   Mishra S, 2022, LECT NOTE DATA ENG, V68, P301, DOI 10.1007/978-981-16-1866-6_22
   Mlakar U, 2017, EXPERT SYST APPL, V89, P129, DOI 10.1016/j.eswa.2017.07.037
   Kurup AR, 2019, NEUROCOMPUTING, V367, P188, DOI 10.1016/j.neucom.2019.08.029
   Rescigno M, 2020, MULTIMED TOOLS APPL, V79, P35811, DOI 10.1007/s11042-020-09405-4
   Revina IM, 2019, J VIS COMMUN IMAGE R, V62, P43, DOI 10.1016/j.jvcir.2019.04.013
   Sánchez D, 2017, ENG APPL ARTIF INTEL, V64, P172, DOI 10.1016/j.engappai.2017.06.007
   Shao J, 2021, APPL INTELL, V51, P549, DOI 10.1007/s10489-020-01855-5
   Singh Alpna, 2020, 2020 International Conference on Contemporary Computing and Applications (IC3A), P187, DOI 10.1109/IC3A48958.2020.233294
   Sreedharan NPN, 2018, IET BIOMETRICS, V7, P490, DOI 10.1049/iet-bmt.2017.0160
   Sun X, 2021, NEUROCOMPUTING, V444, P378, DOI 10.1016/j.neucom.2019.11.127
   Wang SC, 2021, NEUROCOMPUTING, V453, P742, DOI 10.1016/j.neucom.2020.07.120
   Wang XH, 2015, OPTIK, V126, P3132, DOI 10.1016/j.ijleo.2015.07.073
   Wang YY, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051897
   Yang ML, 2017, NEUROCOMPUTING, V267, P195, DOI 10.1016/j.neucom.2017.06.007
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zheng H, 2020, INFORM SCIENCES, V533, P60, DOI 10.1016/j.ins.2020.04.041
   Zhou L, 2021, J AFFECT DISORDERS, V279, P630, DOI 10.1016/j.jad.2020.10.050
NR 39
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18669
EP 18689
DI 10.1007/s11042-022-14186-z
EA NOV 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000886859100003
DA 2024-07-18
ER

PT J
AU Charroud, A
   Moutaouakil, KE
   Yahyaouy, A
AF Charroud, Anas
   Moutaouakil, Karim El
   Yahyaouy, Ali
TI Fast and accurate localization and mapping method for self-driving
   vehicles based on a modified clustering particle filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Localization; Mapping; Particle filter; SLAM; Features extraction;
   Clusteringz
AB Self-driving systems require the creation of perception, which means that they must learn to interact with their environment, gather information and perform tasks while driving. Localization and mapping are essential concepts that any autonomous vehicle must perceive, as they provide information about the location and distance between objects. The absence of GPS, for example, in tunnels and urban canyons, makes it necessary to develop robust methods based on other vehicle equipment, such as Lidar, cameras, IMU, or to combine them all. Based on Lidar measurements, our work presents an architecture consisting of two main phases of mapping and localization; The mapping phase creates a global map of the environment based on non-semantic features using a fuzzy c-means algorithm instead of a semantic algorithm as it was done in some state-of-the-art work. In addition, the remaining clusters were filtered using the DBSCAN algorithm. The localization phase adopted here followed the particle filter architecture; motion update, measurement update, and resampling to estimate the positions. The main contribution of this work is the novel extension of selecting particles to reduce computational time and maintain long-term localization reliability. We have exhibited a method to select relevant particles after motion updates, based on two approaches: clustering with the k-means algorithm and the sigma points algorithm, which were thoroughly examined on short sequences of the Kitti dataset to discover the best one. The selected approach thoroughly tested on the Pandaset dataset. In addition, we tested our method on a long sequence dataset and compared it with the most recent methods. The analysis performed demonstrated the speed of our method and its ability to capture the features needed for real-time localization. Furthermore, it outperformed the well-known localization methods.
C1 [Charroud, Anas] Univ Sidi Mohamed Ben Abdellah Morocco, Engn Sci Lab, FST Fes, Fes, Morocco.
   [Moutaouakil, Karim El] Univ Sidi Mohamed Ben Abdellah Morocco, Engn Sci Lab, FPT Taza, Taza, Morocco.
   [Yahyaouy, Ali] USMBA, Comp Sci Signals Automat & Cognitivism Lab, FSDM, Fes 30050, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Charroud, A (corresponding author), Univ Sidi Mohamed Ben Abdellah Morocco, Engn Sci Lab, FST Fes, Fes, Morocco.
EM anas.charroud@usmba.ac.ma
RI Yahyaouy, Ali/JNE-0618-2023
OI Yahyaouy, Ali/0000-0003-1954-2734; El moutaouakil,
   Karim/0000-0003-3922-5592; CHARROUD, ANAS/0000-0002-6425-3096
CR Biber P, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2743, DOI 10.1109/iros.2003.1249285
   Charroud A., 2022, 2022 INT C INTELLIGE, DOI [10.1109/iscv54655.2022.9806102, DOI 10.1109/ISCV54655.2022.9806102]
   Daszykowski M, 2009, COMPREHENSIVE CHEMOMETRICS: CHEMICAL AND BIOCHEMICAL DATA ANALYSIS, VOLS 1-4, pA635
   Du SY, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0188039
   Dym N, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130826
   Farag W, 2021, J CONTROL AUTOM ELEC, V32, P309, DOI 10.1007/s40313-020-00666-w
   Gálvez-López D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   HKUST-Aerial-Robotics, 2022, HKUST AER ROB A LOAM
   Huang XS, 2018, IEEE T CIRC SYST VID, V28, P2965, DOI 10.1109/TCSVT.2017.2730232
   Huang XY, 2022, CURR ISSUES TOUR, V25, P2631, DOI 10.1080/13683500.2021.1980503
   Julier SJ, 1997, P SOC PHOTO-OPT INS, V3068, P182, DOI 10.1117/12.280797
   Karaim M., 2018, Multifunctional Operation and Application of GPS, P69, DOI [DOI 10.5772/INTECHOPEN.71221, 10.5772/intechopen.71221]
   Kim D, 2015, IEEE INT VEH SYM, P680, DOI 10.1109/IVS.2015.7225763
   Kümmerle J, 2019, IEEE INT CONF ROBOT, P5965, DOI [10.1109/icra.2019.8793497, 10.1109/ICRA.2019.8793497]
   Künsch HR, 2013, BERNOULLI, V19, P1391, DOI 10.3150/12-BEJSP07
   Kuutti S, 2018, IEEE INTERNET THINGS, V5, P829, DOI 10.1109/JIOT.2018.2812300
   Laboshinl, 2022, LAB LOAM VEL
   Levinson J., 2007, Robotics: Science and systems
   Li Q, 2019, PROC CVPR IEEE, P8465, DOI 10.1109/CVPR.2019.00867
   Liang S, 2021, IEEE SYST J, V15, P1390, DOI 10.1109/JSYST.2020.2995727
   Liu Z, 2021, IEEE ROBOT AUTOM LET, V6, P3184, DOI 10.1109/LRA.2021.3062815
   Lu WX, 2019, IEEE I CONF COMP VIS, P12, DOI 10.1109/ICCV.2019.00010
   Moireau P, 2011, ESAIM CONTR OPTIM CA, V17, P380, DOI 10.1051/cocv/2010006
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Nerem RS, 2001, GLOBAL POSITIONING S, DOI [10.1029/01-o00224, DOI 10.1029/01-O00224]
   Onyekpe U, 2021, ENG APPL ARTIF INTEL, V105, DOI 10.1016/j.engappai.2021.104421
   Schaefer A, 2021, ROBOT AUTON SYST, V136, DOI 10.1016/j.robot.2020.103709
   Sefati M, 2017, IEEE INT VEH SYM, P13, DOI 10.1109/IVS.2017.7995692
   Shan TX, 2018, IEEE INT C INT ROBOT, P4758, DOI 10.1109/IROS.2018.8594299
   Sjafrie H, 2019, Introduction To Self-Driving Vehicle Technology, DOI DOI 10.1201/9780429316777
   Sjafrie H., 2013, BERNOULLI, V19, P1391
   Team CARLA, 2022, CARL CARLA SIM, P9
   Thrun S, 2002, COMMUN ACM, V45, P52, DOI 10.1145/504729.504754
   van der Merwe R., 2004, Ph.D. Thesis
   Weng LH, 2018, PROCEEDINGS OF 2018 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (IEEE RCAR), P96, DOI 10.1109/RCAR.2018.8621688
   Wentao Yuan, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P733, DOI 10.1007/978-3-030-58558-7_43
   Xia DW, 2021, NEURAL COMPUT APPL, V33, P2393, DOI 10.1007/s00521-020-05076-2
   Xiao PC, 2021, IEEE INT C INTELL TR, P3095, DOI 10.1109/ITSC48978.2021.9565009
   Yurtsever E, 2020, IEEE ACCESS, V8, P58443, DOI 10.1109/ACCESS.2020.2983149
   Zhang J, 2017, AUTON ROBOT, V41, P401, DOI 10.1007/s10514-016-9548-2
NR 42
TC 6
Z9 6
U1 5
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18435
EP 18457
DI 10.1007/s11042-022-14111-4
EA NOV 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000882819700001
DA 2024-07-18
ER

PT J
AU Babu, GLA
   Badugu, S
AF Babu, G. L. Anand
   Badugu, Srinivasu
TI Deep learning based sequence to sequence model for abstractive telugu
   text summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sequence-to-sequence model; Temporal attention mechanism; Coverage
   mechanism; Diverse beam search; Pointer generator network
AB With the emergence of deep learning, the attention of researchers has increased significantly towards abstractive text summarization approaches. Though extractive text summarization (ETS) is an important approach, the generated summaries are not always coherent. This paper mainly focuses on the abstractive text summarization (ATS) approach for Telugu language to generate coherent summary. The majority research on ATS approach is conducted in English, while no significant research in Telugu has been documented. An abstractive Telugu text summarization model based on sequence-to-sequence (seq2seq) encoder-decoder architecture is proposed in this paper. The seq2seq model is implemented with bidirectional long short-term memory (Bi-LSTM) based encoder and long short-term memory (LSTM) based decoder. The existing ATS approaches have some drawbacks such as they cannot handle out vocabulary words, attention deficiency issue arising while handling long text sequence and repetition problem. To overcome these issues, some operating mechanisms like pointer generator network, temporal attention mechanism and coverage mechanism are also integrated in the proposed model. Besides, diverse beam search decoding algorithm is also employed to increase the diversity of generated summary. Thus, the proposed seq2seq model is the combination of Bi-LSTM and LSTM based encoder-decoder, pointer generator network, temporal attention mechanism, coverage mechanism and diverse beam search decoding algorithm. The performance of the proposed work is evaluated using the ROUGE toolkit in terms of F-measure, recall and precision. The experimental results of the proposed scheme are evaluated with other existing methods to show that the proposed ATS model outperforms existing Telugu text summarization models.
C1 [Babu, G. L. Anand] Osmania Univ, Univ Coll Engn, Hyderabad, India.
   [Badugu, Srinivasu] Stanley Coll Engn & Technol Women, Dept CSE, Hyderabad, India.
C3 Osmania University
RP Babu, GLA (corresponding author), Osmania Univ, Univ Coll Engn, Hyderabad, India.
EM anandbabu77@gmail.com; srinivasucse@gmail.com
RI BABU, G.L.ANAND/HDO-0973-2022
OI BABU, G.L.ANAND/0000-0002-6438-220X; babu, anand/0000-0002-6210-963X
CR Allahyari M, 2017, ARXIV, DOI [10.1177/1010428317692226, DOI 10.1177/1010428317692226]
   Alquliti WH, 2019, INT J ADV COMPUT SC, V10, P200
   [Anonymous], NOTEBOOKS INTRO IPYN
   [Anonymous], 2015, Advances in neural information processing systems
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bird S., 2006, P COLING ACL INT PRE, P69, DOI DOI 10.3115/1118108.1118117
   Chung J., 2014, NIPS 2014 WORKSH DEE
   Cibils A, 2018, ARXIV
   Gimpel K., 2013, P 2013 C EMP METH NA, P1100
   Gu J, 2016, ARXIV, DOI DOI 10.13703/J.0255-2930.2016.11.022
   Gulati AN, 2017, 2017 INTERNATIONAL CONFERENCE ON NASCENT TECHNOLOGIES IN ENGINEERING (ICNTE-2017)
   Heng-Xi Pan, 2019, Web Information Systems and Applications. 16th International Conference, WISA 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11817), P285, DOI 10.1007/978-3-030-30952-7_29
   Hernández-Castañeda A, 2020, IEEE ACCESS, V8, P49896, DOI 10.1109/ACCESS.2020.2980226
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hssayni E, 2022, NEURAL COMPUT APPL, V34, P2443, DOI 10.1007/s00521-021-06540-3
   Kallimani J. S., 2011, 2011 7th International Conference on Natural Language Processing and Knowledge Engineering (NLPKE), P319, DOI 10.1109/NLPKE.2011.6138217
   Kanitha DK., 2018, INT J COMPUT SCI INF, V9, P40
   Krause J, 2017, PROC CVPR IEEE, P3337, DOI 10.1109/CVPR.2017.356
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Mamidala KK, 2021, INT J COMPUT DIGITAL, V11
   Manjari KU, 2020, 2020 4 INT C I SMAC, DOI [10.1109/i-smac49090.2020.9243568, DOI 10.1109/I-SMAC49090.2020.9243568]
   Mohammad Masum AK, 2019, INT CONF COMPUT, P1, DOI DOI 10.1109/icccnt45670.2019.8944620
   Mohan bharath B., 2022, Soft Computing and Signal Processing: Proceedings of 3rd ICSCSP 2020. Advances in Intelligent Systems and Computing, P61, DOI 10.1007/978-981-16-1249-7_7
   Naidu R, 2017, TEXT SUMMARIZATION A, DOI [10.21037/cdt.2017.08.14, DOI 10.21037/CDT.2017.08.14]
   Nallapati R., 2016, P 20 SIGNLL C COMP N, P280, DOI DOI 10.18653/V1/K16-1028
   Norouzi R, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/6536908
   Paulus R, 2017, ARXIV, DOI DOI 10.3389/FPSYG.2017.01779
   Priyadharshan T, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY RESEARCH (ICITR)
   Rodrigo Sergio G., 2019, 2019 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2019.8872869
   Rush Alexander M., 2015, P 2015 C EMPIRICAL M, P379, DOI [10.48550/arXiv.1509.00685, DOI 10.18653/V1/D15-1044]
   Rush Alexander M, 2015, arXiv
   Sarwadnya VV, 2018, 2018 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION (ICCUBEA)
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Shi T, 2020, ACM T DATA SCI
   Song SL, 2019, MULTIMED TOOLS APPL, V78, P857, DOI 10.1007/s11042-018-5749-3
   Sudha DN., 2020, Int. J. Adv. Sci. Technol, V29, P513
   Sutskever I., 2014, ADV NEURAL INFORM PR, V4, P3104, DOI DOI 10.5555/2969033.2969173
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang S, 2017, IEEE INT CONGR BIG, P305, DOI 10.1109/BigDataCongress.2017.46
   Zhang Y, 2018, IEEE ACCESS, V6, P46047, DOI 10.1109/ACCESS.2018.2865589
   Zhang YJ, 2019, MULTIMED TOOLS APPL, V78, P35237, DOI 10.1007/s11042-019-08175-y
   Zhang YJ, 2020, PATTERN RECOGN LETT, V130, P376, DOI 10.1016/j.patrec.2018.07.030
NR 42
TC 5
Z9 5
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17075
EP 17096
DI 10.1007/s11042-022-14099-x
EA NOV 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000879267000001
DA 2024-07-18
ER

PT J
AU Vijayalakshmi, D
   Nath, MK
AF Vijayalakshmi, D.
   Nath, Malaya Kumar
TI A strategic approach towards contrast enhancement by two-dimensional
   histogram equalization based on total variational decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Total variation minimization; Detailed information; Two-Dimensional
   histogram equalization; Contrast enhancement
ID IMAGE; ENTROPY
AB The histogram equalization technique used for image enhancement diminishes the number of pixel intensities resulting in loss of details and artificial impression. This paper proposes to use a two-dimensional histogram equalization technique based on edge detail to increase contrast while conserving information and maintaining the image's natural appearance. First, the total variational (TV)/L1 decomposition method retrieves the detailed information present in the low contrast image. The decomposition problem uses an augmented Lagrangian approach to address constraints and an alternate direction technique to determine solutions iteratively. Following that, a two-dimensional histogram is constructed using the detailed image created by the iterative method to determine the cumulative distribution function (CDF). Then the CDF is transferred to distribute the intensities in the whole dynamic range to yield the improved image. The algorithm's effectiveness is tested on seven databases, including LIME, CSIQ, Dresden, and others, and validated using standard deviation (SD), contrast improvement index (CII), discrete entropy (DE), and the natural image quality evaluator (NIQE). Experimental results show that the proposed method provides better results than the other algorithms. Furthermore, it achieves higher uniformity than existing strategies for all seven databases, as determined by the Kullback-Leibler distance.
C1 [Vijayalakshmi, D.; Nath, Malaya Kumar] NIT Puducherry, Dept ECE, Pondicherry, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Puducherry
RP Vijayalakshmi, D (corresponding author), NIT Puducherry, Dept ECE, Pondicherry, India.
EM vijaya1183@gmail.com; malaya.nath@nitpy.ac.in
RI padmavathy engg college, prince shri venkateshwara/GOH-3256-2022; NATH,
   MALAYA KUMAR/N-4584-2019
OI NATH, MALAYA KUMAR/0000-0002-1959-6452; Dhurairajan,
   Vijayalakshmi/0000-0001-5567-4019
FU department of ECE, National Institute of Technology Puducherry, India
FX The work has been supported by the department of ECE, National Institute
   of Technology Puducherry, India.
CR Acharya UK, 2021, MULTIMED TOOLS APPL, V80, P24005, DOI 10.1007/s11042-021-10855-7
   Agrawal S, 2022, J KING SAUD UNIV-COM, V34, P1172, DOI 10.1016/j.jksuci.2019.05.010
   [Anonymous], 2021, DATASETS
   Cao G, 2018, IET IMAGE PROCESS, V12, P447, DOI 10.1049/iet-ipr.2017.0789
   Celik T, 2016, J MOD OPTIC, V63, P1600, DOI 10.1080/09500340.2016.1163427
   Celik T, 2014, IEEE T IMAGE PROCESS, V23, P5298, DOI 10.1109/TIP.2014.2364537
   Chan SH, 2011, IEEE T IMAGE PROCESS, V20, P3097, DOI 10.1109/TIP.2011.2158229
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Diwakar Manoj, 2020, International Journal of Information and Computer Security, V12, P234
   Diwakar Manoj, 2019, Soft Computing: Theories and Applications. Proceedings of SoCTA 2017. Advances in Intelligent Systems and Computing (AISC 742), P343, DOI 10.1007/978-981-13-0589-4_32
   Diwakar M, 2019, HDB MULTIMEDIA INFOR, P501, DOI DOI 10.1007/978-3-030-15887-3_24
   Diwakar M, 2020, MULTIMED TOOLS APPL, V79, P14449, DOI 10.1007/s11042-018-6897-1
   Diwakar M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101754
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Diwakar M, 2015, PROCEEDING OF THE THIRD INTERNATIONAL SYMPOSIUM ON WOMEN IN COMPUTING AND INFORMATICS (WCI-2015), P297, DOI 10.1145/2791405.2791430
   Diwakar M, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P160, DOI 10.1109/ICIIP.2013.6707574
   Feng XM, 2020, MULTIMED TOOLS APPL, V79, P32973, DOI 10.1007/s11042-020-09562-6
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Kandhway P, 2019, MULTIDIM SYST SIGN P, V30, P1859, DOI 10.1007/s11045-019-00633-y
   Kansal S, 2018, MULTIMED TOOLS APPL, V77, P26919, DOI 10.1007/s11042-018-5894-8
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Li C., 2010, An efficient algorithm for total variation regularization with applications to the single pixel camera and compressive sensingD
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mun J, 2019, J VIS COMMUN IMAGE R, V58, P688, DOI 10.1016/j.jvcir.2018.12.037
   Nath MK, 2012, INT J IMAG SYST TECH, V22, P161, DOI 10.1002/ima.22017
   Ooi CH, 2009, IEEE T CONSUM ELECTR, V55, P2072, DOI 10.1109/TCE.2009.5373771
   r0k.us, 2013, US
   Sengupta D, 2021, MULTIMED TOOLS APPL, V80, P3835, DOI 10.1007/s11042-020-09583-1
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Tang JR, 2014, COMPUT ELECTR ENG, V40, P86, DOI 10.1016/j.compeleceng.2014.05.017
   Veluchamy M, 2020, MULTIMED TOOLS APPL, V79, P19945, DOI 10.1007/s11042-020-08870-1
   Vijayalakshmi D, 2020, PATTERN RECOGN IMAGE, V30, P691, DOI 10.1134/S1054661820040240
   Vijayalakshmi D, 2020, SENS IMAGING, V21, DOI 10.1007/s11220-020-00305-3
   VIJAYALAKSHMI D, 2021, CIRCUITS SYSTEM SIGN, P1
   Wang P, 2021, MULTIMED TOOLS APPL, V80, P17705, DOI 10.1007/s11042-021-10607-7
   Wang XW, 2018, SIGNAL IMAGE VIDEO P, V12, P685, DOI 10.1007/s11760-017-1208-2
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Zeng PX, 2004, IEEE ROBIO 2004: Proceedings of the IEEE International Conference on Robotics and Biomimetics, P574
   Zhuang PX, 2020, MULTIMED TOOLS APPL, V79, P17257, DOI 10.1007/s11042-019-08404-4
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 46
TC 9
Z9 9
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19247
EP 19274
DI 10.1007/s11042-022-13932-7
EA OCT 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000871318500001
DA 2024-07-18
ER

PT J
AU Aryanmehr, S
   Boroujeni, FZ
AF Aryanmehr, Saeed
   Boroujeni, Farsad Zamani
TI Efficient deep CNN-based gender classification using Iris wavelet
   scattering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gender Classification; Iris; Wavelet scattering; Convolutional Neural
   Network (CNN)
ID PATTERN; IMAGES
AB Recognition of gender from iris images can be considered a texture classification task in which a classification model discriminates iris textures of male and female subjects. Although many researchers have proposed efficient iris texture classification methods that rely on deep features or employ Fourier and wavelet transforms, several issues have still been reported in the literature. On the one hand, it is difficult to discriminate the details of iris textures using the features extracted by traditional frequency domain transforms. On the other hand, in different imaging conditions, small changes in pupil diameter or head rotations result in the translation and deformation of the iris texture and inaccurate classification results. To overcome these challenges, the current study proposes an approach that employs a feature extraction method based on a wavelet scattering transform comparable with deep features extracted from raw image data using convolutional neural networks. In the proposed method, the scattering coefficients are extracted from each RGB channel, followed by applying the principal component analysis (PCA) to reduce the extracted features' dimensionality. These features are used to train a convolutional neural network. The current paper compares the deep feature vectors extracted from raw RGB images against features obtained from the wavelet scattering transform. This comparison is made according to the performance results obtained from a fine-tuned multi-layer perceptron (MLP) model trained by both feature sets. Experiments conducted on CVBL and UTIRIS databases indicate that using a wavelet scattering transform and extracting second-order features can significantly enhance the performance of the iris-based gender classification in comparison to deep features achieved from applying a deep neural network to raw pixel information. Moreover, our feature extraction method provides learnable features, thus eliminating the need for an additional training step to obtain deep features, as performed in the most recent state-of-the-art methods.
C1 [Aryanmehr, Saeed; Boroujeni, Farsad Zamani] Islamic Azad Univ, Dept Comp Engn, Isfahan Khorasgan Branch, Esfahan, Iran.
C3 Islamic Azad University
RP Boroujeni, FZ (corresponding author), Islamic Azad Univ, Dept Comp Engn, Isfahan Khorasgan Branch, Esfahan, Iran.
EM saeed.alyamnehr@khuisf.ac.ir; f.zamani@khuisf.ac.ir
RI Zamani Boroujeni, Farsad/I-5842-2019
OI Zamani Boroujeni, Farsad/0000-0002-2279-488X
CR Alaslani Maram G., 2018, International Journal of Computer Science & Information Technology, V10, P65, DOI 10.5121/ijcsit.2018.10206
   Andén J, 2015, IEEE INT WORKS MACH
   Andén J, 2014, IEEE T SIGNAL PROCES, V62, P4114, DOI 10.1109/TSP.2014.2326991
   [Anonymous], 2013, Advanced data analysis from an elementary point of view
   [Anonymous], 2007, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2007.383003
   Aryanmehr S, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P433, DOI 10.1109/ICIVC.2018.8492757
   Bansal A., 2014, Research Journal of Recent Sciences, V2277, P2502
   Bansal A, 2012, 4 INT C COMP INT COM, P425
   Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   Bradley Derek, 2007, Journal of Graphics Tools, V12, P13
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Daugman J., 1994, Biometric personal identification system based on iris analysis
   Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540
   Davarzani R, 2015, SIGNAL PROCESS, V111, P274, DOI 10.1016/j.sigpro.2014.11.005
   Davies E. R., 2004, Machine vision: theory, algorithms, practicalities
   Hosseini MS, 2010, IEEE T INSTRUM MEAS, V59, P792, DOI 10.1109/TIM.2009.2037996
   Izadpanahi S, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414560035
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Khalifa Nour Eldeen M, 2019, Acta Inform Med, V27, P96, DOI 10.5455/aim.2019.27.96-102
   Khan AR, 2021, MICROSC RES TECHNIQ, V84, P2666, DOI 10.1002/jemt.23816
   Kingma D. P., 2014, arXiv
   Kuehlkamp A, 2017, IEEE WINT CONF APPL, P1151, DOI 10.1109/WACV.2017.133
   Lagree S., 2011, 2011 IEEE International Conference on Technologies for Homeland Security (HST 2011), P440, DOI 10.1109/THS.2011.6107909
   Liu XM, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P118
   Mallat S, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2015.0203
   Mallat S, 2012, COMMUN PUR APPL MATH, V65, P1331, DOI 10.1002/cpa.21413
   Nguyen K, 2018, IEEE ACCESS, V6, P18848, DOI 10.1109/ACCESS.2017.2784352
   O'Mahony N, 2020, ADV INTELL SYST COMP, V943, P128, DOI 10.1007/978-3-030-17795-9_10
   Okokpujie K., 2019, INT J CIVIL ENG TECH, V10, P57
   Omran EM, 2020, MENOUFIA J ELECT ENG, V29, P64
   Oyallon E, 2013, ARXIV
   Proença H, 2009, CIB: 2009 IEEE WORKSHOP ON COMPUTATIONAL INTELLIGENCE IN BIOMETRICS: THEORY, ALGORITHMS, AND APPLICATIONS, P9
   Qiu XC, 2006, LECT NOTES COMPUT SC, V3832, P411
   Rajput M., 2019, P INT C ADV EL EL CO
   Rajput M.R., 2019, P INT C SOFT COMPUTI, P519
   Rong WB, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (IEEE ICMA 2014), P577, DOI 10.1109/ICMA.2014.6885761
   Sable G., 2020, COMPUTATIONAL INTELL, P189, DOI [10.1201/9781003079996-13, DOI 10.1201/9781003079996-13]
   Sable Ganesh S., 2020, Computing in Engineering and Technology. Proceedings of ICCET 2019. Advances in Intelligent Systems and Computing (AISC 1025), P29, DOI 10.1007/978-981-32-9515-5_4
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Sifre L, 2013, PROC CVPR IEEE, P1233, DOI 10.1109/CVPR.2013.163
   Singh M, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P666, DOI 10.1109/BTAS.2017.8272755
   Tapia J., 2018, IEEE 4th International Conference on Identity, Security, and Behavior Analysis ISBA, P1, DOI DOI 10.1109/ISBA.2018.8311465
   Tapia J, 2019, INT CONF BIOMETR
   Tapia J, 2017, ADV COMPUT VIS PATT, P219, DOI 10.1007/978-3-319-61657-5_9
   Tapia JE, 2016, IEEE T INF FOREN SEC, V11, P1771, DOI 10.1109/TIFS.2016.2550418
   Tapia JE, 2015, LECT NOTES COMPUT SC, V8926, P751, DOI 10.1007/978-3-319-16181-5_57
   Thenuwara SS., 2022, MULTIAGENT ENHANCEME, V14, P100171, DOI [10.1016/j.array.2022.100171, DOI 10.1016/J.ARRAY.2022.100171]
   Thomas VM, 2007, IEEE INT SYMP ELECTR, P180, DOI 10.1109/ISEE.2007.369390
   Trokielewicz M, 2018, ARXIV
   Vyas R, 2019, MULTIMED TOOLS APPL, V78, P5681, DOI 10.1007/s11042-018-5689-y
   Yang K, 2021, IEEE WINT CONF APPL, P888, DOI 10.1109/WACV48630.2021.00093
   YUEN HK, 1990, IMAGE VISION COMPUT, V8, P71, DOI 10.1016/0262-8856(90)90059-E
NR 52
TC 3
Z9 3
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 19041
EP 19065
DI 10.1007/s11042-022-14062-w
EA OCT 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000874060500004
DA 2024-07-18
ER

PT J
AU Yadav, AK
   Yadav, D
   Verma, A
   Akbar, M
   Tewari, K
AF Yadav, Arun Kumar
   Yadav, Divakar
   Verma, Akhilesh
   Akbar, Mohd
   Tewari, Kartikey
TI Scalable thread based index construction using wavelet tree
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wavelet tree; Inverted index; Map-reduce; Search time; Parallel
   algorithms; Dictionary searching
ID RETRIEVAL
AB Indexing is one of the key components of any search tool to be optimized for searching documents. Among the existing indexing techniques, inverted indexing is one of the best methods used at a larger scale for various applications. Under this method, the index is designed using a signature file, hash tree and B-tree to retrieve the required document in efficient time. B-tree is popular due to its searching efficiency, but its performance degrades with increasing data set size. The wavelet tree has become a popular and versatile data structure in the last decade, used in various domains such as sequences, indexing, compression, and grid-point with surprising results. This study proposes a parallel wavelet tree algorithm with hybridization of the Map-Reduce concept to construct an index for textual search. The proposed algorithm reduces the index construction time considerably. Experiments show that the proposed algorithm takes a reasonable trade-off with existing indexing approaches. For large data sets, index construction time has been reduced with respect to other existing state-of-art schemes. Also, results show that the algorithm performs well when the data-set scales up to up-to-the full utilization of available cores. It is possible due to the use of multiple threads working in parallel. Our experiment demonstrated consistent performance with 2-core, 4-core, 8-core, 12-core and results of 16-core show increase in index construction time due to parallel overhead when the data-set in not sufficiently large.
C1 [Yadav, Arun Kumar; Yadav, Divakar; Tewari, Kartikey] NIT Hamirpur, Dept Comp Sci & Engn, Hamirpur, India.
   [Verma, Akhilesh; Akbar, Mohd] Ajay Kumar Garg Engn Coll, Dept Comp Sci & Engn, Ghaziabad, UP, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur
RP Yadav, D (corresponding author), NIT Hamirpur, Dept Comp Sci & Engn, Hamirpur, India.
EM ayadav@nith.ac.in; dsy99@rediffmail.com; akhilesh.verma@hotmail.com;
   akbar@gmail.com; kartikeya30@gmail.com
RI Yadav, DIVAKAR/AAF-1777-2020; Verma, Dr Akhilesh/K-1726-2019; YADAV,
   ARUN KUMAR/AAS-6212-2021
OI Yadav, DIVAKAR/0000-0001-6051-479X; Verma, Dr
   Akhilesh/0000-0002-4422-3690; YADAV, ARUN KUMAR/0000-0001-9774-7917
CR Arroyuelo D, 2012, INFORM PROCESS MANAG, V48, P819, DOI 10.1016/j.ipm.2011.01.008
   Barbay J, 2013, THEOR COMPUT SCI, V513, P109, DOI 10.1016/j.tcs.2013.10.019
   Barbay J, 2010, LECT NOTES COMPUT SC, V6507, P315, DOI 10.1007/978-3-642-17514-5_27
   Bayer R., 1977, ACM Transactions on Database Systems, V2, P11, DOI 10.1145/320521.320530
   BELKIN NJ, 1992, COMMUN ACM, V35, P29, DOI 10.1145/138859.138861
   Biswas I, PROJECT REPORT COMP
   Brisaboa NR, 2007, DEXA 2007: 18TH INTERNATIONAL CONFERENCE ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P69, DOI 10.1109/DEXA.2007.118
   Brisaboa NR, 2010, LECT NOTES COMPUT SC, V6099, P77
   CHRISTODOULAKIS S, 1987, ACM T DATABASE SYST, V12, P137, DOI 10.1145/22952.23015
   Claude F, 2008, LECT NOTES COMPUT SC, V5280, P176
   Cormen T. H., 2002, INTRO ALGORITHMS 2 E, V47, P11
   Cutting D., 1989, Proceedings of the 13th International Conference on Research and Development in Information Retrieval, P405
   Faloutsos C., 1998, SURVEY INFORM RETRIE
   Faro S, 2012, LECT NOTES COMPUT SC, V7608, P217, DOI 10.1007/978-3-642-34109-0_23
   Frakes WB., 1992, Space, V14, P10
   Fuentes-Sepúlveda J, 2017, KNOWL INF SYST, V51, P1043, DOI 10.1007/s10115-016-1000-6
   Fuentes-Sepúlveda J, 2014, LECT NOTES COMPUT SC, V8504, P150, DOI 10.1007/978-3-319-07959-2_13
   Gagie T, 2012, THEOR COMPUT SCI, V426, P25, DOI 10.1016/j.tcs.2011.12.002
   Gonnet G.H., 1992, INFORMATION RETRIEVA, P66
   Grossi R, 2003, SIAM PROC S, P841
   Grossi R, 2011, 18 INT S SPIRE 2011
   Johnson T, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P278
   Labeit J, 2016, IEEE DATA COMPR CONF, P33, DOI 10.1109/DCC.2016.117
   Ladra Susana, 2012, Advances in Databases and Information Systems. Proceedings 16th East European Conference, ADBIS 2012, P254, DOI 10.1007/978-3-642-33074-2_19
   Lin J., 2010, Synthesis Lectures on Human Language Technologies, V3, P1, DOI [DOI 10.1007/978-3-031-02136-7, 10.2200/S00274ED1V01Y201006HLT007, DOI 10.2200/S00274ED1V01Y201006HLT007]
   LIN Z, 1992, IEEE T KNOWL DATA EN, V4, P281, DOI 10.1109/69.142018
   Makris C, 2012, COMPUT SCI INF SYST, V9, P585, DOI 10.2298/CSIS110606004M
   MANBER U, 1993, SIAM J COMPUT, V22, P935, DOI 10.1137/0222058
   Navarro G, 2007, ACM COMPUT SURV, V39, DOI 10.1145/1216370.1216372
   Navarro G, 2014, J DISCRET ALGORITHMS, V25, P2, DOI 10.1016/j.jda.2013.07.004
   Shun JL, 2020, INFORM COMPUT, V273, DOI 10.1016/j.ic.2020.104516
   Shun JL, 2017, IEEE DATA COMPR CONF, P92, DOI 10.1109/DCC.2017.85
   Shun JL, 2015, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2015.7
   Waisman A, 1986, US Patent, Patent No. [4,606,002, 4606002]
   Yadav A, 2015, INT J BIOMATH, V8, DOI 10.1142/S1793524515500011
   Yadav AK, 2019, INT ARAB J INF TECHN, V16, P624
   Yadav AK, 2016, INT J INF RETR RES, V6, P16, DOI 10.4018/IJIRR.2016100102
   Yadav Divakar, 2012, Journal of Theoretical and Applied Information Technology, V43, P8
   Zobel J, 1998, ACM T DATABASE SYST, V23, P453, DOI 10.1145/296854.277632
NR 39
TC 0
Z9 0
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 14037
EP 14053
DI 10.1007/s11042-022-13906-9
EA SEP 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000860416900007
DA 2024-07-18
ER

PT J
AU Ram, PK
   Kuila, P
AF Ram, Pintu Kumar
   Kuila, Pratyay
TI Dynamic scaling factor based differential evolution with multi-layer
   perceptron for gene selection from pathway information of microarray
   data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Differential evolution; Microarray data; Pathway; T-score; Biological
   significance
ID ALGORITHM; CLASSIFICATION; OPTIMIZATION
AB The microarray data contains the high volume of genes having multiple values of expressions and small number of samples. Therefore, the selection of gene from microarray data is an extremely challenging and important issue to analyze the biological behavior of features. In this context, dynamic scaling factor based differential evolution (DE) with multi-layer perceptron (MLP) is designed for selection of genes from pathway information of microarray data. At first DE is employed to select the relevant and lesser number of genes. Then MLP is used to build a classifier model over the selected genes. A suitable and efficient representation of vector is designed for DE. The fitness function is derived separately as T-score, classification accuracy and weight sum approach of both. Simulation and further analysis is performed in terms of sensitivity, specificity, accuracy and F-score. Moreover, statistical and biological analysis are also conducted.
C1 [Ram, Pintu Kumar; Kuila, Pratyay] Natl Inst Technol Sikkim, Dept Comp Sci & Engn, Ravangla 737139, Sikkim, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Sikkim
RP Ram, PK (corresponding author), Natl Inst Technol Sikkim, Dept Comp Sci & Engn, Ravangla 737139, Sikkim, India.
EM rampintu570@gmail.com; pratyay_kuila@yahoo.com
RI ; Kuila, Pratyay/O-3544-2017
OI Ram, Pintu Kumar/0000-0003-1969-5255; Kuila, Pratyay/0000-0002-4549-3246
CR Agarwalla P, 2018, APPL SOFT COMPUT, V62, P230, DOI 10.1016/j.asoc.2017.10.024
   Ali IM, 2020, SWARM EVOL COMPUT, V52, DOI 10.1016/j.swevo.2019.100607
   Bakhshandeh S, 2020, INT J MACH LEARN CYB, V11, P15, DOI 10.1007/s13042-019-00932-7
   Berahmand K, 2021, COMPUT BIOL MED, V138, DOI 10.1016/j.compbiomed.2021.104933
   Fan GF, 2021, UTIL POLICY, V73, DOI 10.1016/j.jup.2021.101294
   Gao LY, 2017, GENOM PROTEOM BIOINF, V15, P389, DOI 10.1016/j.gpb.2017.08.002
   Geeitha S, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1092-5
   Ghosh M, 2021, APPL SOFT COMPUT, V105, DOI 10.1016/j.asoc.2021.107221
   Ghosh M, 2019, EXPERT SYST APPL, V116, P172, DOI 10.1016/j.eswa.2018.06.057
   Han F, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0097530
   Hassanat A, 2019, INFORMATION, V10, DOI 10.3390/info10120390
   Katiyar S, 2021, J FOOD QUALITY, V2021, DOI 10.1155/2021/4881289
   Khan, 2014, INT J APPL INNOV ENG, V3
   Khan RU, 2023, ANIM BIOTECHNOL, V34, P1635, DOI 10.1080/10495398.2021.2013861
   Khan Rijwan, 2021, Comput Intell Neurosci, V2021, P5942574, DOI 10.1155/2021/5942574
   Khan R, 2022, WORLD J ENG, V19, P204, DOI 10.1108/WJE-05-2021-0269
   Kuila P, 2014, APPL SOFT COMPUT, V25, P414, DOI 10.1016/j.asoc.2014.08.064
   Kuila P, 2014, ENG APPL ARTIF INTEL, V33, P127, DOI 10.1016/j.engappai.2014.04.009
   Lee J, 2021, EXPERT SYST APPL, V166, DOI 10.1016/j.eswa.2020.113971
   Mabarti I., 2020, J DATA SCI APPL, V3, P38
   Mandal M, 2015, IEEE T NANOBIOSCI, V14, P591, DOI 10.1109/TNB.2015.2425471
   Mandal M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090949
   Polat H, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0703-x
   Prasad Y, 2018, APPL SOFT COMPUT, V71, P213, DOI 10.1016/j.asoc.2018.06.019
   Ram P.K., 2021, Mach. Learn. Algorithms Appl., P159
   Rani MJ, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1372-8
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Rostami M, 2022, ARTIF INTELL MED, V123, DOI 10.1016/j.artmed.2021.102228
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Sakr WS, 2017, APPL SOFT COMPUT, V53, P336, DOI 10.1016/j.asoc.2017.01.004
   Salem H, 2017, APPL SOFT COMPUT, V50, P124, DOI 10.1016/j.asoc.2016.11.026
   Shahbeig S, 2018, BIOCYBERN BIOMED ENG, V38, P313, DOI 10.1016/j.bbe.2018.02.002
   Sharma H, 2012, ADV INTEL SOFT COMPU, V130, P73
   Shukla AK, 2020, GENES GENOM, V42, P449, DOI 10.1007/s13258-020-00916-w
   Sujamol S, 2021, APPL ARTIF INTELL, V35, P206, DOI 10.1080/08839514.2020.1854988
   Sun GJ, 2020, SOFT COMPUT, V24, P6277, DOI 10.1007/s00500-019-03934-3
   Vijay SAA, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0910-0
   Wang D, 2016, IEEE ACM T COMPUT BI, V13, P1059, DOI 10.1109/TCBB.2015.2505294
   Xu P, 2020, IEEE ACCESS, V8, P30515, DOI 10.1109/ACCESS.2020.2973220
   Zhang G, 2020, INTERDISCIP SCI, V12, P288, DOI 10.1007/s12539-020-00372-w
   Zhou WG, 2014, COMPUT BIOL MED, V47, P66, DOI 10.1016/j.compbiomed.2014.01.014
NR 41
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13453
EP 13478
DI 10.1007/s11042-022-13964-z
EA SEP 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000857279500001
DA 2024-07-18
ER

PT J
AU Guerdelli, H
   Ferrari, C
   Berretti, S
AF Guerdelli, Hajer
   Ferrari, Claudio
   Berretti, Stefano
TI Interpersonal relation recognition: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interpersonal relation recognition; Facial expression; Emotions
ID EMOTION RECOGNITION; FACIAL EXPRESSIONS; FRAMEWORK
AB People spend a considerable amount of their time in social activities, where person-to-person relations are of main relevance. Recently, there has been an increasing research interest in automatically analyzing interpersonal relations, for the social and behavioral implications, and the many practical applications it may have. However, to the best of our knowledge, there is not a systematic study providing a harmonized view of the literature in the field. On this ground, we summarize in our work interpersonal relation recognition datasets and methods aiming to help researchers to have a better understanding of the characteristics of the state-of-the-art. In the proposed study, we distinguish between methods that address objective relations that do not depend on behavior or emotional state, and methods that consider subjective ones that depend on emotions. It turns out quite evidently that aiming at the latter recognition task is more challenging, with the existing methods that provide convincing results only on limited and very specific cases. For both the broad categories, we discuss datasets and methods according to the different behavioural and psychological models used to annotate and classify the data. We conclude our review work, by providing a comprehensive discussion pointing out current limitations and future research perspectives.
C1 [Guerdelli, Hajer] Univ Tunis El Manar, Inst Super dInformat Manar, LR16ES06 Lab Rech Informat Modelisat & Traitement, Res Team Intelligent Syst Imaging & Artificial Vi, 2 Rue Abou Rayhane Bayrouni, Ariana Tunis 2080, Tunisia.
   [Guerdelli, Hajer; Berretti, Stefano] Univ Parma, Dept Engn & Architecture, Parco Area Sci 181-A, I-43124 Parma, Italy.
   [Ferrari, Claudio] Univ Florence, Dept Informat Engn, Via Santa Marta 3, I-50139 Florence, Italy.
C3 Universite de Tunis-El-Manar; University of Parma; University of
   Florence
RP Guerdelli, H (corresponding author), Univ Tunis El Manar, Inst Super dInformat Manar, LR16ES06 Lab Rech Informat Modelisat & Traitement, Res Team Intelligent Syst Imaging & Artificial Vi, 2 Rue Abou Rayhane Bayrouni, Ariana Tunis 2080, Tunisia.
EM hajer.guerdelli@unifi.it; claudio.ferrari2@unipr.it;
   stefano.berretti@unifi.it
RI Ferrari, Claudio/AEQ-4611-2022; Berretti, Stefano/U-9004-2019
OI Berretti, Stefano/0000-0003-1219-4386; Guerdelli,
   Hajer/0000-0003-3746-5007
FU Universita degli Studi di Firenze within the CRUI-CARE Agreement;
   MOBIDOC scheme - Ministry of Higher Education and Scientific Research
   through the PromEssE project
FX Open access funding provided by Universit`a degli Studi di Firenze
   within the CRUI-CARE Agreement. Hajer Guerdelli was partially supported
   by the MOBIDOC scheme, funded by the Ministry of Higher Education and
   Scientific Research through the PromEssE project and managed by the
   ANPR.
CR Alhagry S, 2017, INT J ADV COMPUT SC, V8, P355, DOI 10.14569/IJACSA.2017.081046
   [Anonymous], 2011, Biometrics (IJCB), 2011 International Joint Conference on
   [Anonymous], 2012, C PATT REC APPL METH
   Ariano L, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020589
   Bargal SA, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P433, DOI 10.1145/2993148.2997627
   Bugental DB, 2000, PSYCHOL BULL, V126, P187, DOI 10.1037/0033-2909.126.2.187
   Chanel G, 2007, IEEE SYS MAN CYBERN, P375
   CLARK MS, 1979, J PERS SOC PSYCHOL, V37, P12, DOI 10.1037/0022-3514.37.1.12
   Cristani M, 2013, NEUROCOMPUTING, V100, P86, DOI 10.1016/j.neucom.2011.12.038
   Dai QY, 2015, IEEE WINT CONF APPL, P982, DOI 10.1109/WACV.2015.136
   Dehshibi Mohammad Mahdi, 2010, Proceedings of the 2010 International Conference on Image Processing and Computer Vision (IVPCV-10), P132
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Fang RG, 2010, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2010.5652590
   Ferrari C., 2018, P EUR C COMP VIS ECC
   Ferrari C, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P509, DOI 10.1109/3DV.2015.63
   FISKE AP, 1992, PSYCHOL REV, V99, P689, DOI 10.1037/0033-295X.99.4.689
   Foa E., 1980, SOCIAL EXCHANGE, P77, DOI [10.1007/978-1-4613-3087-5_4, DOI 10.1007/978-1-4613-3087-5_4]
   Frith C, 2009, PHILOS T R SOC B, V364, P3453, DOI 10.1098/rstb.2009.0142
   Gao JJ, 2021, NEUROCOMPUTING, V456, P243, DOI 10.1016/j.neucom.2021.05.097
   Goel A, 2019, PROC CVPR IEEE, P11178, DOI 10.1109/CVPR.2019.01144
   Guo X, 2019, IEEE INT CONF AUTOMA, P626, DOI 10.1109/fg.2019.8756602
   Hajer G., 2022, SENSORS-BASEL, V4, P22
   Ho D.Y. F., 1998, Asian Journal of Social Psychology, V1, P1, DOI DOI 10.1111/1467-839X.00002
   Ingo S, 2013, HUMAN BEHAVIOUR HCI, P8212, DOI [10.1007/978-3-319-02714-2-21, DOI 10.1007/978-3-319-02714-2-21]
   KIESLER DJ, 1983, PSYCHOL REV, V90, P185, DOI 10.1037/0033-295X.90.3.185
   KLEMMER ET, 1972, J COMMUN, V22, P142, DOI 10.1111/j.1460-2466.1972.tb00141.x
   Li JN, 2017, IEEE I CONF COMP VIS, P2669, DOI 10.1109/ICCV.2017.289
   Li XS, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS - COMPUTING TECHNOLOGY, INTELLIGENT TECHNOLOGY, INDUSTRIAL INFORMATION INTEGRATION (ICIICII), P1, DOI 10.1109/ICIICII.2015.88
   Liu XC, 2019, PROC CVPR IEEE, P3561, DOI 10.1109/CVPR.2019.00368
   Liu YS, 2011, LECT NOTES COMPUT SC, V6670, P256, DOI 10.1007/978-3-642-22336-5_13
   LUNDQVIST LO, 1995, J PSYCHOPHYSIOL, V9, P203
   Lv JN, 2018, LECT NOTES COMPUT SC, V10704, P355, DOI 10.1007/978-3-319-73603-7_29
   MACCRIMMON KR, 1976, BEHAV SCI, V21, P86, DOI 10.1002/bs.3830210203
   Palmero C, 2020, ARXIV
   Parsons T., 1965, GEN THEORY ACTION TH
   Razuri J. G., 2015, INT J COMPUTER SCI I, V12, P7
   Robinson J., 2020, arXiv
   Robinson J. P., 2016, P 24 ACM INT C MULT, P242, DOI DOI 10.1145/2964284.2967219
   Song SY, 2018, IEEE INT CONF AUTOMA, P158, DOI 10.1109/FG.2018.00032
   Sun QR, 2017, PROC CVPR IEEE, P435, DOI 10.1109/CVPR.2017.54
   Tanisik G, 2016, PATTERN RECOGNIT LET
   Tyshchuk Y, 2018, IEEE T COMPUT SOC SY, V5, P444, DOI 10.1109/TCSS.2018.2815786
   Vicol P, 2018, PROC CVPR IEEE, P8581, DOI 10.1109/CVPR.2018.00895
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang MY, 2020, PATTERN RECOGN LETT, V138, P410, DOI 10.1016/j.patrec.2020.08.005
   Wang SQ, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE AND APPLICATIONS (IEEE BIGDATASERVICE 2019), P159, DOI 10.1109/BigDataService.2019.00028
   Wang ZX, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1021
   Wanhua Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P18, DOI 10.1007/978-3-030-58555-6_2
   Yan HB, 2019, PATTERN RECOGN LETT, V128, P78, DOI 10.1016/j.patrec.2019.08.015
   Yan HB, 2018, PATTERN RECOGN, V75, P15, DOI 10.1016/j.patcog.2017.03.001
   Zeng ZH, 2007, LECT NOTES COMPUT SC, V4451, P72
   Zhang M, 2019, IEEE INT CON MULTI, P1618, DOI 10.1109/ICME.2019.00279
   Zhang N, 2015, PROC CVPR IEEE, P4804, DOI 10.1109/CVPR.2015.7299113
   Zhang Zhe, 2016, ARXIV
   Zhou L, 2018, CCF C BIG DAT, P442
NR 55
TC 2
Z9 2
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11417
EP 11439
DI 10.1007/s11042-022-13816-w
EA SEP 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000854848100003
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Xu, C
   Yang, HM
   Han, C
   Zhang, C
AF Xu, Chao
   Yang, Huamin
   Han, Cheng
   Zhang, Chao
TI Learning high-quality depth map from 360° multi-exposure imagery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Omnidirectional media; 360 degrees imagery; Depth estimation;
   Multi-exposure
AB Monocular 360 degrees depth estimation is an important and challenging task in computer vision and 3D vision. Recently, deep neural networks have shown great abilities in estimating depth map from a single 360 degrees image. However, existing 360 degrees depth estimation networks typically employ well-exposed 360 degrees images and corresponding depth maps as the supervision data, ignoring the learning of under-exposed and over-exposed images, which results in the generation of low-quality depth maps and the poor generalization capabilities of the networks. In the current paper, we train an improved convolutional neural network URectNet with a distortion weighted loss function to learn high-quality depth maps from multi-exposure 360 degrees images. Firstly, we insert skip connections into the baseline network of 360 degrees depth estimation to improve performance. Then, we design a distortion weighted loss function to eliminate the effect of distortion caused by 360 degrees images during network training. Due to the lack of 360 degrees multi-exposure images, we render a 360 degrees multi-exposure dataset from Matterport3D for network training. The generalization capability of the network is enhanced by increasing the dynamic range of the training images. Finally, extensive experiments and ablation studies are provided to validate our method against existing state-of-the-art algorithms, demonstrating the ability of the proposed method to achieve a favorable performance.
C1 [Xu, Chao; Yang, Huamin; Han, Cheng; Zhang, Chao] Changchun Univ Sci & Technol, Sch Comp Sci & Technol, Changchun, Jilin, Peoples R China.
C3 Changchun University of Science & Technology
RP Yang, HM; Han, C (corresponding author), Changchun Univ Sci & Technol, Sch Comp Sci & Technol, Changchun, Jilin, Peoples R China.
EM yanghuamin@cust.edu.cn; hancheng@cust.edu.cn
RI CHEN, AN/KFT-3370-2024; LIU, HAO/JBI-9623-2023; cheng,
   cheng/JBR-8359-2023; wang, wei/JBS-7400-2023; Lin, Fan/JZT-1441-2024;
   WANG, YONGJIA/KFQ-4823-2024; li, xiaomin/KCX-9845-2024; Han,
   Yang/JVN-5921-2024; LI, Xiang-Yang/JZE-0275-2024; zhong,
   jing/KBP-7800-2024
OI Lin, Fan/0000-0002-7330-3833; 
FU Natural Science Foundation of Jilin of China [20190201255JC]; Key
   Science and Technology Project of Jilin Province [20180201069GX]
FX This work was supported by Natural Science Foundation of Jilin of China
   (20190201255JC) and the Key Science and Technology Project of Jilin
   Province (20180201069GX).
CR Chang A, 2017, ARXIV
   de La Garanderie GP, 2018, LECT NOTES COMPUT SC, V11217, P812, DOI 10.1007/978-3-030-01261-8_48
   Eder M, 2019, INT CONF 3D VISION, P76, DOI 10.1109/3DV.2019.00018
   Eigen D., 2014, arXiv
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Endo Y, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130834
   Fernandez-Labrador C, 2020, IEEE ROBOT AUTOM LET, V5, P1255, DOI 10.1109/LRA.2020.2967274
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang JW, 2017, P IEEE VIRT REAL ANN, P37, DOI 10.1109/VR.2017.7892229
   Im S, 2016, LECT NOTES COMPUT SC, V9907, P156, DOI 10.1007/978-3-319-46487-9_10
   Jin L, 2020, PROC CVPR IEEE, P886, DOI 10.1109/CVPR42600.2020.00097
   Kingma D. P., 2014, arXiv
   Kuznietsov Y, 2017, PROC CVPR IEEE, P2215, DOI 10.1109/CVPR.2017.238
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Liao K, 2021, IEEE T IMAGE PROCESS, V30, P3362, DOI 10.1109/TIP.2021.3061283
   Liao K, 2020, IEEE T IMAGE PROCESS, V29, P3707, DOI 10.1109/TIP.2020.2964523
   Mahjourian R, 2018, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2018.00594
   Pagani A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P375, DOI 10.1109/ICCVW.2011.6130266
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Su YC, 2017, ADV NEUR IN, V30
   Su YC, 2019, PROC CVPR IEEE, P9434, DOI 10.1109/CVPR.2019.00967
   Tateno K, 2018, LECT NOTES COMPUT SC, V11220, P732, DOI 10.1007/978-3-030-01270-0_43
   Wang CY, 2018, PROC CVPR IEEE, P2022, DOI 10.1109/CVPR.2018.00216
   Wang FE, 2020, PROC CVPR IEEE, P459, DOI 10.1109/CVPR42600.2020.00054
   Wang FE, 2019, LECT NOTES COMPUT SC, V11365, P53, DOI 10.1007/978-3-030-20873-8_4
   Wang NH, 2020, IEEE INT CONF ROBOT, P582, DOI 10.1109/ICRA40945.2020.9196975
   Wei Zeng, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P666, DOI 10.1007/978-3-030-58517-4_39
   Yin ZC, 2018, PROC CVPR IEEE, P1983, DOI 10.1109/CVPR.2018.00212
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
   Zioulis N, 2019, INT CONF 3D VISION, P690, DOI 10.1109/3DV.2019.00081
   Zioulis N, 2018, LECT NOTES COMPUT SC, V11210, P453, DOI 10.1007/978-3-030-01231-1_28
NR 36
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35965
EP 35980
DI 10.1007/s11042-022-13340-x
EA SEP 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000850023000004
DA 2024-07-18
ER

PT J
AU Chatterjee, SK
   Vittapu, SK
AF Chatterjee, Sumit Kumar
   Vittapu, Sravan Kumar
TI FPGA implementation of EFSME for high efficient video coding standard
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High efficiency video coding (HEVC); Full search motion estimation
   (FSME); Sum of absolute difference (SAD); Particle swarm optimization
   (PSO); Field programmable gate Array (FPGA)
ID MOTION ESTIMATION; ARCHITECTURE; ALGORITHM
AB Nowadays. High Efficiency Video Coding (HEVC) is widely used in video compression techniques due to the utilization of less bit rate than Advanced Video Coding (AVC) encoders. Motion Estimation (ME) is a vital task in HEVC video compression technique which consumes more encoding time. Various algorithms are proposed in existing studies to deal with ME process in HEVC. Full Search Motion Estimation (FSME) method is most suitable for HEVC because, it is better in terms of high data flow and operating speed. In this work, Particle Swarm Optimization (PSO) is proposed to optimize Sum of Absolute Difference (SAD) calculation value hence, it is named as Enhanced FSME (EFSME). SAD calculation of EFSME not requires adder tree, comparison block and control unit. Hence, there is great reduction in area, power and operating frequency. Proposed work is implemented in Xilinx ZYNQ XA7Z010 FPGA board and it is evaluated by means of power, area and operational frequency. For HEVC, EFSME outputs 65 mW as power consumption rate which is 28.94% lower than Vayalil et al. (2017), 3.03% lesser than Xu et al. (2018) and 80.05% lesser than Singh and Ahamed (2018). Moreover, the proposed design accomplishes 431.906 MHz as operating speed that is 0.44% greater than Vayalil et al. (2017), 20.95% higher than Xu et al. (2018) and 53.35% higher than Singh and Ahamed (2018). Overall, the simulation results proved that the proposed enhanced architecture is better than the existing methodologies in terms of different parameters.
C1 [Chatterjee, Sumit Kumar; Vittapu, Sravan Kumar] BITS Pilani, Dept EEE, Hyderabad Campus, Hyderabad 500078, India.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani)
RP Chatterjee, SK (corresponding author), BITS Pilani, Dept EEE, Hyderabad Campus, Hyderabad 500078, India.
EM sumit2702@hyderabad.bits-pilani.ac.in
CR AlQaralleh EA, 2018, PROCEDIA COMPUT SCI, V141, P40, DOI 10.1016/j.procs.2018.10.147
   Bakir N., 2020, PROC IEEE INT C MULT, P1
   Braly M, 2017, DEPENDABLE SECURE CO
   Çetinkaya E, 2020, IEEE I C VI COM I PR, P87, DOI 10.1109/vcip49819.2020.9301850
   Chen YH, 2017, INT J CIRC THEOR APP, V45, P2260, DOI 10.1002/cta.2376
   Duan LY, 2020, IEEE T IMAGE PROCESS, V29, P8680, DOI 10.1109/TIP.2020.3016485
   Fan R, 2017, IEEE T MULTIMEDIA, V19, P893, DOI 10.1109/TMM.2016.2642786
   Goel S, 2012, COMPUT J, V55, P35, DOI 10.1093/comjnl/bxr034
   Hiramori M, 2016, CONS EL 2016 IEEE 5, P1
   Ismail Y, 2016, INT J COMPUTING DIGI
   Jia LH, 2020, IEEE T CIRC SYST VID, V30, P243, DOI 10.1109/TCSVT.2018.2890204
   Kumar BS, 2020, J KING SAUD UNIV-COM, V32, P784, DOI 10.1016/j.jksuci.2017.11.004
   Lu GL, 2018, OPT LASER ENG, V111, P246, DOI 10.1016/j.optlaseng.2018.08.011
   Makryniotis T., 2017, MOD CIRC SYST TECHN, P1
   Rufenacht D, 2017, MULTIMEDIA SIGNAL PR, P1
   Shah NN, 2018, IET COMPUT DIGIT TEC, V12, P95, DOI 10.1049/iet-cdt.2016.0178
   Silveira B, 2017, IEEE T CIRCUITS-I, V64, P3126, DOI 10.1109/TCSI.2017.2728802
   Singh K, THESIS
   Singh K, 2018, IEEE T CONSUM ELECTR, V64, P267, DOI 10.1109/TCE.2018.2867823
   Siqueira I, 2020, IEEE LAT AMER SYMP
   Tariq J, 2020, J VIS COMMUN IMAGE R, V68, DOI 10.1016/j.jvcir.2020.102766
   Trudeau L, 2018, IEEE T BROADCAST, V64, P922, DOI 10.1109/TBC.2018.2847444
   Tseng YH, 2019, IEEE INT SYMP CIRC S
   Vayalil NC, 2017, IEEE T CIRC SYST VID
   Wang Y, 2020, 2020 13TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2020), P407, DOI 10.1109/CISP-BMEI51763.2020.9263529
   Wu MH, 2019, J AMB INTEL HUM COMP, V10, P439, DOI 10.1007/s12652-017-0660-8
   Xu K, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8350934
   Xue YG, 2017, SCI PROGRAMMING-NETH, V2017, DOI 10.1155/2017/1431574
   Zhu SP, 2017, MULTIMED TOOLS APPL, V76, P21707, DOI 10.1007/s11042-016-4056-0
NR 29
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 34087
EP 34103
DI 10.1007/s11042-022-13051-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000843962500064
DA 2024-07-18
ER

PT J
AU Kumar, S
   Kumar, D
AF Kumar, Sunil
   Kumar, Dilip
TI Human brain tumor classification and segmentation using CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data augmentation; Brain tumor; Convolution neural network; Deep
   learning; Transfer learning; Image classification and segmentation; MRI
   images
ID IMAGES
AB The study of tumors in brain segmentation with classification through neuroimaging methodologies has become significant in recent years. A brain tumor, if not detected on time, maybe fatal. An improper tumor diagnosis might result in severe problems, as there are various tumors. Hence, the proper classification will help clinicians to provide an appropriate cure. Deep Learning may be a kind of an artificial intelligence that has recently achieved fantastic success in classification and segmentation tasks. This study uses a convolution neural network that classifies brain tumors using two public datasets, describing the different tumor forms (glioma, meningioma, and pituitary tumor) as with three glioma grades (as describes, Grade II, Grade III, and Grade IV). A public MRI imaging dataset includes 233 and 73 patients with 516 and 3064 images on T1-weighted images. Where methodology employs a 25-layer CNN model using T1-weighted Magnetic Resonance Imaging (MRI) images to evaluate our method's performance against previously published approaches in the field. Our method outperformed the other methods using the same dataset. The experimental results demonstrated that this proposed method achieved a tumor classification accuracy in study I is, 86.23.% using Adam optimizer, and study II is 81.6% using Sgdam optimizer. The proposed algorithm has produced impressive results in the classification and segmentation of MRI brain images. It will help clinicians to detect and classify brain tumors.
C1 [Kumar, Sunil; Kumar, Dilip] Natl Inst Technol, Dept CSE, Jamshedpur, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur
RP Kumar, S (corresponding author), Natl Inst Technol, Dept CSE, Jamshedpur, Bihar, India.
EM 2018rscs016@nitjsr.ac.in; dilip.ese@nitjsr.ac.in
RI Kumar, Sunil/ACL-3070-2022; Kumar, Sunil/GYV-0347-2022
OI Kumar, Sunil/0000-0002-1953-6273
CR Abir T.A., 2018, Int. J. Sci. Res. Sci. Eng. Technol, V4, P65
   Abiwinanda N, 2019, IFMBE PROC, V68, P183, DOI 10.1007/978-981-10-9035-6_33
   Afshar P, 2019, INT CONF ACOUST SPEE, P1368, DOI 10.1109/ICASSP.2019.8683759
   Agarwal P, 2018, MATEC WEB CONF, V210, DOI 10.1051/matecconf/201821003016
   Anaraki AK, 2019, BIOCYBERN BIOMED ENG, V39, P63, DOI 10.1016/j.bbe.2018.10.004
   Anjali R, 2017, EFFICIENT CLASSIFIER
   [Anonymous], 2015, Data from rembrandt. the cancer imaging archive
   Behin A, 2003, LANCET, V361, P323, DOI 10.1016/S0140-6736(03)12328-8
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   DeAngelis LM, 2001, NEW ENGL J MED, V344, P114, DOI 10.1056/NEJM200101113440207
   Drevelegas A, 2002, Imaging of Brain Tumors with Histological Correlations
   Ertosun Mehmet Gunhan, 2015, AMIA Annu Symp Proc, V2015, P1899
   Fang TT, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING TECHNOLOGY (CCET), P286, DOI 10.1109/CCET.2018.8542189
   Gautam A, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102178
   Gautam A, 2020, PATTERN ANAL APPL, V23, P797, DOI 10.1007/s10044-019-00838-8
   Goswami S, 2013, INT CONF COMM SYST, P573, DOI 10.1109/CSNT.2013.123
   Kumar S, 2017, PROCEDIA COMPUT SCI, V122, P510, DOI 10.1016/j.procs.2017.11.400
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Lu SY, 2019, J COMPUT SCI-NETH, V30, P41, DOI 10.1016/j.jocs.2018.11.008
   Machhale K, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INSTRUMENTATION AND CONTROL (ICIC), P60, DOI 10.1109/IIC.2015.7150592
   Mohsen Heba, 2018, Future Computing and Informatics Journal, V3, P68, DOI 10.1016/j.fcij.2017.12.001
   Mzoughi H, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP'2020), DOI 10.1109/atsip49331.2020.9231681
   Mzoughi H, 2021, MULTIMED TOOLS APPL, V80, P899, DOI 10.1007/s11042-020-09786-6
   Mzoughi H, 2020, J DIGIT IMAGING, V33, P903, DOI 10.1007/s10278-020-00347-9
   Pashaei A, 2018, 2018 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P314, DOI 10.1109/ICCKE.2018.8566571
   Rajesh T, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCED NANOMATERIALS AND EMERGING ENGINEERING TECHNOLOGIES (ICANMEET), P240, DOI 10.1109/ICANMEET.2013.6609287
   Razzak MI, 2020, NEURAL COMPUT APPL, V32, P4417, DOI 10.1007/s00521-019-04095-y
   Shasidhar M., 2011, 2011 International Conference on Communication Systems and Network Technologies (CSNT), P473, DOI 10.1109/CSNT.2011.102
   Stewart B. W., 2003, World Cancer Report
   Sultan HH, 2019, IEEE ACCESS, V7, P69215, DOI 10.1109/ACCESS.2019.2919122
   Tavakoli N, 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01639-x
   Widhiarso W., 2018, IJEIS INDONES J ELEC, V8, P179, DOI [10.22146/ijeis.34713, DOI 10.22146/IJEIS.34713]
   Williams T., 2018, P INT C LEARN REPR
   Zacharaki EI, 2009, MAGN RESON MED, V62, P1609, DOI 10.1002/mrm.22147
   Zhou YF, 2019, LECT NOTES COMPUT SC, V11383, P208, DOI 10.1007/978-3-030-11723-8_21
NR 35
TC 5
Z9 5
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7599
EP 7620
DI 10.1007/s11042-022-13713-2
EA AUG 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000847629600005
DA 2024-07-18
ER

PT J
AU Nguyen, TV
   Vien, AG
   Lee, C
AF Thuong Van Nguyen
   An Gia Vien
   Lee, Chul
TI Real-time image and video dehazing based on multiscale guided filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image dehazing; Image enhancement; Image restoration; Guided image
   filtering
ID SINGLE; NETWORK; WEATHER
AB We propose a real-time dehazing algorithm for hazy images and videos based on multiscale guided filtering. The most time-consuming step in physical model-based algorithms is estimating the transmission map and atmospheric light. In this work, we develop a computationally efficient approach for the estimation. First, we construct an image pyramid from a hazy image. Then, we estimate the transmission map and atmospheric light at the coarsest level. Next, we obtain the transmission at the finest level by iterative upsampling with guide image filtering to avoid information loss. Furthermore, we extend the single-image dehazing algorithm to real-time video dehazing to reduce flickering artifacts in dehazed videos by making transmission values temporally coherent. Experimental results show that the proposed algorithm is applicable in real-time applications, while providing comparable or even better performance than that of state-of-the-art algorithms.
C1 [Thuong Van Nguyen; An Gia Vien; Lee, Chul] Dongguk Univ, Dept Multimedia Engn, Seoul 04620, South Korea.
C3 Dongguk University
RP Lee, C (corresponding author), Dongguk Univ, Dept Multimedia Engn, Seoul 04620, South Korea.
EM thuongnguyen@mme.dongguk.edu; viengiaan@mme.dongguk.edu;
   chullee@dongguk.edu
RI Vien, An Gia/AHE-7143-2022
OI Vien, An Gia/0000-0003-0067-0285; Lee, Chul/0000-0001-9329-7365
FU National Research Foundation of Korea (NRF) - Korea Government (MSIT)
   [NRF-2019R1A2C4069806, NRF-2022R1F1A1074402]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea Government (MSIT) (No.
   NRF-2019R1A2C4069806 and NRF-2022R1F1A1074402).
CR Ancuti CO, 2019, IEEE COMPUT SOC CONF, P2241, DOI 10.1109/CVPRW.2019.00277
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Bui TM, 2018, IEEE T IMAGE PROCESS, V27, P999, DOI 10.1109/TIP.2017.2771158
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen C, 2016, LECT NOTES COMPUT SC, V9906, P576, DOI 10.1007/978-3-319-46475-6_36
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He LY, 2017, IEEE T IMAGE PROCESS, V26, P1063, DOI 10.1109/TIP.2016.2644267
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Kou F, 2015, IEEE T IMAGE PROCESS, V24, P4528, DOI 10.1109/TIP.2015.2468183
   Li BY, 2018, AAAI CONF ARTIF INTE, P7016
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li RD, 2018, PROC CVPR IEEE, P8202, DOI 10.1109/CVPR.2018.00856
   Li ZW, 2015, PROC CVPR IEEE, P4988, DOI 10.1109/CVPR.2015.7299133
   Liu Q, 2018, IEEE T IMAGE PROCESS, V27, P5178, DOI 10.1109/TIP.2018.2849928
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Lucas B. D., 1981, P 7 INT JOINT C ART, V81, P674, DOI DOI 10.5555/1623264.1623280
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Nguyen TV, 2021, IEEE ACCESS, V9, P34590, DOI 10.1109/ACCESS.2021.3060439
   Nguyen TV, 2019, PROC INT WORKSHOP AD, P182
   Park J, 2020, IEEE T IMAGE PROCESS, V29, P4721, DOI 10.1109/TIP.2020.2975986
   Qin BY, 2015, IEEE IMAGE PROC, P4233, DOI 10.1109/ICIP.2015.7351604
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P1895, DOI 10.1109/TIP.2018.2876178
   Shao YJ, 2020, PROC CVPR IEEE, P2805, DOI 10.1109/CVPR42600.2020.00288
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Vazquez-Corral J, 2020, J REAL-TIME IMAGE PR, V17, P607, DOI 10.1007/s11554-018-0816-6
   Venkatanath N, 2015, NATL CONF COMMUN
   Wang WC, 2017, IEEE T MULTIMEDIA, V19, P1142, DOI 10.1109/TMM.2017.2652069
   Xu HT, 2014, IEEE T MULTIMEDIA, V16, P68, DOI 10.1109/TMM.2013.2283453
   Xu ZY, 2009, PROCEEDINGS OF THE 2009 2ND INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOLS 1-9, P508
   Yang D, 2018, LECT NOTES COMPUT SC, V11211, P729, DOI 10.1007/978-3-030-01234-2_43
   Yang JC, 2017, J REAL-TIME IMAGE PR, V13, P479, DOI 10.1007/s11554-017-0671-x
   Zhang H, 2018, IEEE COMPUT SOC CONF, P1015, DOI 10.1109/CVPRW.2018.00135
   Zhang XY, 2021, PROC CVPR IEEE, P9235, DOI 10.1109/CVPR46437.2021.00912
   Zhao D, 2021, IEEE T CIRC SYST VID, V31, P3037, DOI 10.1109/TCSVT.2020.3036992
   Zhu HY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1234
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 45
TC 2
Z9 2
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36567
EP 36584
DI 10.1007/s11042-022-13533-4
EA AUG 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000840291300006
DA 2024-07-18
ER

PT J
AU Wang, FL
   Lu, YY
   Cheng, G
   Xie, HR
   Rao, YH
AF Wang, Fu Lee
   Lu, Yuyin
   Cheng, Gary
   Xie, Haoran
   Rao, Yanghui
TI Learning Chinese word embeddings from semantic and phonetic components
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chinese word embedding; Semantic components; Phonetic information
AB As an important task in Asian language information processing, Chinese word embedding learning has attracted much attention recently. Based on either Skip-gram or CBOW, several methods have been proposed to exploit Chinese characters and sub-character components for learning Chinese word embeddings. Chinese characters are combinations of meaning, structure, and phonetic information (pinyin). However, previous works only cover the former two aspects and cannot effectively explore distinct semantics of characters. To address this issue, we develop a Pinyin-enhance Skip-gram model named rsp2vec, in addition to a radical and pinyin-enhanced Chinese word embedding (rPCWE) learning models based on CBOW. For our models, the phonetic information and semantic components of Chinese characters are encoded into embeddings simultaneously. Evaluations on word analogy reasoning, word relevance, text classification, named entity recognition, and case studies validate the effectiveness of our models.
C1 [Wang, Fu Lee] Hong Kong Metropolitan Univ, Sch Sci & Technol, Ho Man Tin, Hong Kong, Peoples R China.
   [Lu, Yuyin; Rao, Yanghui] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
   [Cheng, Gary] Educ Univ Hong Kong, Dept Math & Informat Technol, Tai Po, Hong Kong, Peoples R China.
   [Xie, Haoran] Lingnan Univ, Dept Comp & Decis Sci, Tuen Mun, Hong Kong, Peoples R China.
C3 Hong Kong Metropolitan University; Sun Yat Sen University; Education
   University of Hong Kong (EdUHK); Lingnan University
RP Cheng, G (corresponding author), Educ Univ Hong Kong, Dept Math & Informat Technol, Tai Po, Hong Kong, Peoples R China.
EM pwang@hkmu.edu.hk; luyy37@mail2.sysu.edu.cn; chengks@eduhk.hk;
   hrxie2@gmail.com; raoyangh@mail.sysu.edu.cn
RI Xie, Haoran/AFS-3515-2022; Wang, Fu Lee/AAD-9782-2021
OI Xie, Haoran/0000-0003-0965-3617; Wang, Fu Lee/0000-0002-3976-0053;
   Cheng, Gary/0000-0002-5614-3348
FU Research Grants Council of the Hong Kong Special Administrative Region,
   China [UGC/FDS16/E01/19]; Research Cluster Fund [RG 78/2019-2020R];
   Interdisciplinary Research Scheme of the Dean's Research Fund 2019-20 of
   The Education University of Hong Kong [FLASS/DRF/IDS-2]; Lam Woo
   Research Fund of Lingnan University, Hong Kong [LWI20011]; One-off
   Special Fund from Central and Faculty Fund [MIT02/19-20]
FX The work described in this paper was fully supported by a grant from the
   Research Grants Council of the Hong Kong Special Administrative Region,
   China (UGC/FDS16/E01/19), the One-off Special Fund from Central and
   Faculty Fund in Support of Research from 2019/20 to 2021/22
   (MIT02/1920), the Research Cluster Fund (RG 78/2019-2020R), the
   Interdisciplinary Research Scheme of the Dean's Research Fund 2019-20
   (FLASS/DRF/IDS-2) of The Education University of Hong Kong, and the Lam
   Woo Research Fund (LWI20011) of Lingnan University, Hong Kong.
CR Baroni M, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P238
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Cao SS, 2018, AAAI CONF ARTIF INTE, P5053
   Chen HY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2865
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen XX, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1236
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Huang Z., 2015, ARXIV
   Li HH, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17081792
   Li Y., 2015, P 2015 C EMP METH NA, P829, DOI DOI 10.18653/V1/D15-1098
   Ma B, 2020, COMPUT SPEECH LANG, V60, DOI 10.1016/j.csl.2019.101031
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   RUBENSTEIN H, 1965, COMMUN ACM, V8, P627, DOI 10.1145/365628.365657
   Schnabel T., 2015, P 2015 C EMPIRICAL M, P298, DOI DOI 10.18653/V1/D15-1036
   Shi XL, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P594
   Su TR, 2017, P 2017 C EMP METH NA, P264, DOI [10.18653/v1/d17-1025, DOI 10.18653/V1/D17-1025]
   Sun ZJ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2065
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Wang SR, 2020, NEURAL PROCESS LETT, V52, P1109, DOI 10.1007/s11063-020-10289-6
   Wu M, 2015, SENSORS-BASEL, V15, P248, DOI 10.3390/s150100248
   Yang, 2015, P 14 CHIN NAT C CHIN, P15
   Yang QJ, 2021, COGN COMPUT, V13, P688, DOI 10.1007/s12559-021-09850-9
   Yin R., 2016, P 2016 C EMP METH NA, P981, DOI DOI 10.18653/V1/D16-1100
   Yu JX, 2017, P 2017 C EMP METH NA, P286, DOI [10.18653/v1/d17-1027, DOI 10.18653/V1/D17-1027, 10.18653/ v1/d17-1027]
   Zeng YY, 2011, SENSORS-BASEL, V11, P2899, DOI 10.3390/s110302899
   Zhang Y, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1011, DOI 10.1145/3357384.3358005
NR 27
TC 0
Z9 0
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42805
EP 42820
DI 10.1007/s11042-022-13488-6
EA AUG 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000838552300007
DA 2024-07-18
ER

PT J
AU Khmag, A
AF Khmag, Asem
TI Additive Gaussian noise removal based on generative adversarial network
   model and semi-soft thresholding approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generative adversarial networks; Image denoising; Image enhancement;
   Thresholding optimization; Second-generation wavelets
ID IMAGE; ROBUST
AB In digital image analysis and processing field of study, noise reduction and suppression have been stated as a common query. However, it is mostly essential issue to demesne the fine edges and ridges and tiny texture while suppressing the noise in processing of the digital images. In order to avoid causing "Over-strangling" phenomenon, semi-soft thresholding model is exploited to classify the sharp edges of the contaminated images. In this study, a self-adjusting generative adversarial network GAN is utilized. This procedure is used to extract the fine edge of the noised digital images in order to improve the actual signal in the high frequency components where the main parts of the clean pixels may consider as noise pixels, and as a result delete the unwanted noise from the tested image that might cause over smoothing to the resulted images. In order to further denoise the contaminated digital image, adaptive learning GAN model throughout scoring machine is exploited. Therefore, it preserves the information of input image and feature maps, learns the correlation between global and local features, improves image restoration performance, and suppresses phenomena such as over-smoothing that tend to occur in wavelets-based denoising. The proposed method is an end-to-end network structure with CNN-based preprocessing methods. Experimental results demonstrate that, in comparison with state-of-the-art noise removal techniques, the proposed method has better visual quality, and the proposed method improves PSNR by 2.27 dB and 0.85 dB on average compared with state-of-the-art- denoising methods. In addition, the proposed method could shorten the processing time noticeably.
C1 [Khmag, Asem] Univ Zawia, Fac Engn, Dept Comp Syst Engn, Zawia, Libya.
RP Khmag, A (corresponding author), Univ Zawia, Fac Engn, Dept Comp Syst Engn, Zawia, Libya.
EM khmaj2002@gmail.com
RI Khmag, Asem/AAH-1051-2019
OI Khmag, Asem/0000-0002-1360-5346
CR [Anonymous], 2021, Artificial intelligence, machine learning and big data in finance: Opportunities, challenges, and implications for policy makers
   Bai Jing, 2008, Chinese Journal of Computers, V31, P1234
   [蔡鑫鑫 Cai Xinxin], 2020, [计算机辅助设计与图形学学报, Journal of Computer-Aided Design & Computer Graphics], V32, P751
   Cao Yang, 2009, Chinese Journal of Computers, V32, P2260, DOI 10.3724/SP.J.1016.2009.02260
   [曹仰杰 Cao Yangjie], 2018, [中国图象图形学报, Journal of Image and Graphics], V23, P1433
   [陈虎 Chen Hu], 2004, [工程图学学报, Journal of Engineering Graphics], V25, P116
   Dantas CF, 2017, IEEE SIGNAL PROC LET, V24, P559, DOI 10.1109/LSP.2017.2681159
   Djurovic I, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0113-x
   Fan Q., 2019, PROC CVPR IEEE
   [高伟 GAO Wei], 2011, [工程图学学报, Journal of Engineering Graphics], V32, P84
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Guo TT, 2017, IEEE COMPUT SOC CONF, P1100, DOI 10.1109/CVPRW.2017.148
   He Y., 2021, MODERN COMPUTER, V12, P87
   Hsieh SH, 2014, 2014 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P492, DOI 10.1109/GlobalSIP.2014.7032166
   Irofti P, 2019, INT CONF ACOUST SPEE, P3677, DOI 10.1109/ICASSP.2019.8683788
   Jin H., 2007, Chinese Journal of Computers, V3, P491
   Khmag A, 2022, MULTIMED TOOLS APPL, V81, P16645, DOI 10.1007/s11042-022-12774-7
   Khmag A, 2018, VISUAL COMPUT, V34, P1661, DOI 10.1007/s00371-017-1439-9
   Khmag A, 2018, VISUAL COMPUT, V34, P675, DOI 10.1007/s00371-017-1406-5
   Khmag A, 2017, VISUAL COMPUT, V33, P1141, DOI 10.1007/s00371-016-1273-5
   Khmag A, 2016, IEEJ T ELECTR ELECTR, V11, P339, DOI 10.1002/tee.22223
   [刘可佳 Liu Kejia], 2018, [图学学报, Journal of Graphics], V39, P1048
   Liu PJ, 2019, IEEE ACCESS, V7, P74973, DOI 10.1109/ACCESS.2019.2921451
   Meng YZ, 2022, IEEE ACCESS, V10, P49657, DOI 10.1109/ACCESS.2022.3169131
   Park B, 2019, IEEE ACCESS, V7, P128076, DOI 10.1109/ACCESS.2019.2939578
   Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6
   Sailaja R, 2017, TRAIT SIGNAL, V34, P45, DOI 10.3166/TS.34.45-55
   Seghouane AK, 2018, SIGNAL PROCESS, V153, P300, DOI 10.1016/j.sigpro.2018.07.018
   Shi KH, 2021, J COMPUT APPL MATH, V395, DOI 10.1016/j.cam.2021.113605
   Srivastava A., 2017, Int. J. Latest Technol. Eng. Manag. Appl. Sci. (IJLTEMAS) VI, VVI
   Tan ET, 2021, MAGN RESON IMAGING, V79, P103, DOI 10.1016/j.mri.2021.03.013
   Thukral R, 2022, P INT C REC TRENDS C, P827, DOI DOI 10.1007/978-981-16-7118-0_70
   Thukral R, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT COMMUNICATION AND COMPUTATIONAL TECHNIQUES (ICCT), P161, DOI [10.1109/icct46177.2019.8969036, 10.1109/ICCT46177.2019.8969036]
   Ubhi JS, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103483
   Wang H., 2021, J COMMUNICATIONS, V42, P229
   [王相海 Wang Xianghai], 2018, [计算机学报, Chinese Journal of Computers], V41, P2496
   [叶仕通 Ye Shitong], 2014, [图学学报, Journal of Graphics], V35, P571
   Yu JB, 2021, NEURAL NETWORKS, V137, P31, DOI 10.1016/j.neunet.2021.01.010
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhou YY, 2021, PATTERN RECOGN, V120, DOI 10.1016/j.patcog.2021.108128
NR 40
TC 29
Z9 29
U1 6
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7757
EP 7777
DI 10.1007/s11042-022-13569-6
EA AUG 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000837590100003
DA 2024-07-18
ER

PT J
AU Pandit, BR
   Alsadoon, A
   Prasad, PWC
   Al Aloussi, S
   Rashid, TA
   Alsadoon, OH
   Jerew, OD
AF Pandit, Bhoj Raj
   Alsadoon, Abeer
   Prasad, P. W. C.
   Al Aloussi, Sarmad
   Rashid, Tarik A.
   Alsadoon, Omar Hisham
   Jerew, Oday D.
TI Deep learning neural network for lung cancer classification: enhanced
   optimization function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Auto-encoders; Multispace image
   reconstruction; Deep learning; Lung cancer; Prediction
AB Convolutional neural network is widely used for image recognition in the medical area at nowadays. However, overall accuracy in predicting lung tumor is low and the processing time is high as the error occurred while reconstructing the CT image. The aim of this work is to increase the overall prediction accuracy along with reducing processing time by using multispace image in pooling layer of convolution neural network. The proposed method has the autoencoder system to improve the overall accuracy, and to predict lung cancer by using multispace image in pooling layer of convolution neural network and Adam Algorithm for optimization. First, the CT images were pre-processed by feeding image to the convolution filter and down sampled by using max pooling. Then, features are extracted using the autoencoder model based on convolutional neural network and multispace image reconstruction technique is used to reduce error while reconstructing the image which then results improved accuracy to predict lung nodule. Finally, the reconstructed images are taken as input for SoftMax classifier to classify the CT images. The state-of-art and proposed solutions were processed in Python Tensor Flow and It provides significant increase in accuracy in classification of lung cancer to 99.5 from 98.9 and decrease in processing time from 10 frames/second to 12 seconds/second. The proposed solution provides high classification accuracy along with less processing time compared to the state of art. For future research, large dataset can be implemented, and low pixel image can be processed to evaluate the classification.
C1 [Pandit, Bhoj Raj; Alsadoon, Abeer; Prasad, P. W. C.] Charles Sturt Univ CSU, Sch Comp Math & Engn, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Kent Inst Australia, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Jerew, Oday D.] Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Al Aloussi, Sarmad] Massasoit Community Coll, Comp Technol & Informat Management Dept, Brockton, MA 02302 USA.
   [Rashid, Tarik A.] Univ Kurdistan Hewler, Comp Sci & Engn Dept, Erbil, KR, Iraq.
   [Alsadoon, Omar Hisham] Al Iraqia Univ, Dept Islamic Sci, Baghdad, Iraq.
C3 Charles Sturt University; Western Sydney University; University of
   Kurdistan Hewler; Al-Iraqia University
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp Math & Engn, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Massasoit Community Coll, Comp Technol & Informat Management Dept, Brockton, MA 02302 USA.
EM alsadoon.abeer@gmail.com
RI Rashid, Tarik A./P-3473-2019; Rashid, Tarik A./HLX-0184-2023; Alsadoon,
   A/Prof. Abeer/AAU-1532-2021
OI Rashid, Tarik A./0000-0002-8661-258X; Rashid, Tarik
   A./0000-0002-8661-258X; Alsadoon, A/Prof. Abeer/0000-0002-2309-3540;
   Alsadoon, Omar Hisham/0000-0001-7797-6392; withana,
   chandana/0000-0002-3007-687X
CR Antonio VAA, 2018, INT J COMPUT ASS RAD, V13, P1905, DOI 10.1007/s11548-018-1835-2
   Causey JL, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-27569-w
   Coudray N, 2018, NAT MED, V24, P1559, DOI 10.1038/s41591-018-0177-5
   Gertych A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37638-9
   Honglin, 2019, BIOMED RES INT
   Hosny A, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002711
   Hussein S, 2019, IEEE T MED IMAGING, V38, P1777, DOI 10.1109/TMI.2019.2894349
   Lakshmanaprabu SK, 2019, FUTURE GENER COMP SY, V92, P374, DOI 10.1016/j.future.2018.10.009
   Lang N, 2019, MAGN RESON IMAGING, V64, P4, DOI 10.1016/j.mri.2019.02.013
   Shakeel PM, 2020, NEURAL COMPUT APPL, V32, P777, DOI 10.1007/s00521-018-03972-2
   Shen SW, 2019, EXPERT SYST APPL, V128, P84, DOI 10.1016/j.eswa.2019.01.048
   Sun WQ, 2017, COMPUT BIOL MED, V89, P530, DOI 10.1016/j.compbiomed.2017.04.006
   Wang C, 2019, RADIOTHER ONCOL, V131, P101, DOI 10.1016/j.radonc.2018.10.037
NR 13
TC 11
Z9 11
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6605
EP 6624
DI 10.1007/s11042-022-13566-9
EA AUG 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000837148800003
DA 2024-07-18
ER

PT J
AU Talat, N
   Alsadoon, A
   Prasad, PWC
   Dawoud, A
   Rashid, TA
   Haddad, S
AF Talat, Nazish
   Alsadoon, Abeer
   Prasad, P. W. C.
   Dawoud, Ahmed
   Rashid, Tarik A.
   Haddad, Sami
TI A novel enhanced normalization technique for a mandible bones
   segmentation using deep learning: batch normalization with the dropout
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic segmentation; Mandible bone; Computed tomography images;
   Convolutional neural network; Oral and maxillofacial surgery
AB Several cases of oral and maxillofacial surgery require 3D virtual surgical planning, which is essential for craniofacial tumor resection and flap reconstruction of the mandible. This could only be achieved if the mandible bone was segmented accurately using computed Tomography (CT) images. The convolutional Neural Network (CNN) has achieved high accuracy and more robust segmentation within less processing time in segmentation. In this research, we propose a CNN-based system to improve the accuracy and performance of the segmentation. The proposed system consists of U-Net-based on CNN for the segmentation of mandible bone using the dropout technique and batch normalization in fully connected layers of a convolutional neural network to avoid over-fitting and instability of the process. This method provides 3D segmentation of mandible bones from 2D segmented regions from three different orthogonal planes. Four different types of planar data were used to achieve better accuracy and processing time of the segmentation of mandible bones. Dataset was taken from Public Domain Database for Computational Anatomy (PDDCA). Greyscale computed tomography (CT) images were used. 310 CT scan images were used. A confusion matrix has been used to measure the accuracy, i.e., true positive, false positive, and false negative. In contrast to the state-of-art solutions, Results of the proposed solution show that the accuracy of mandible bones' segmentation has been improved by 21%, on average, and the processing time has been reduced by 30% second. Our proposed enhanced system is based on the accurate segmentation of mandible bones in datasets from two different kinds of planes, i.e., single-planar and multi-planar. And single planar data has further been divided into three types i.e., axial, sagittal, and coronal planes.
C1 [Talat, Nazish; Alsadoon, Abeer; Prasad, P. W. C.; Dawoud, Ahmed] Charles Sturt Univ CSU, Sch Comp Math & Engn, Wagga Wagga, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.; Dawoud, Ahmed] Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.] Kent Inst Australia, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
   [Rashid, Tarik A.] Univ Kurdistan Hewler, Comp Sci & Engn, Erbil, Iraq.
   [Haddad, Sami] Greater Western Sydney Area Hlth Serv, Dept Oral & Maxillofacial Serv, Sydney, NSW, Australia.
   [Haddad, Sami] Cent Coast Area Hlth, Dept Oral & Maxillofacial Serv, Gosford, Australia.
C3 Charles Sturt University; Western Sydney University; University of
   Kurdistan Hewler; Florey Institute of Neuroscience & Mental Health
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp Math & Engn, Wagga Wagga, NSW, Australia.; Alsadoon, A (corresponding author), Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021; Rashid, Tarik A./HLX-0184-2023;
   Rashid, Tarik A./P-3473-2019
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; Rashid, Tarik
   A./0000-0002-8661-258X; Rashid, Tarik A./0000-0002-8661-258X; withana,
   chandana/0000-0002-3007-687X
CR Aslani S, 2019, NEUROIMAGE, V196, P1, DOI 10.1016/j.neuroimage.2019.03.068
   Belal SL, 2019, EUR J RADIOL, V113, P89, DOI 10.1016/j.ejrad.2019.01.028
   Chmelik J, 2018, MED IMAGE ANAL, V49, P76, DOI 10.1016/j.media.2018.07.008
   Fritscher KD, 2014, MED PHYS, V41, DOI 10.1118/1.4871623
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Huff TJ, 2019, INT J COMPUT ASS RAD, V14, P1923, DOI 10.1007/s11548-019-02038-5
   Ibragimov B, 2017, MED PHYS, V44, P547, DOI 10.1002/mp.12045
   Klein A, 2019, INT J COMPUT ASS RAD, V14, P21, DOI 10.1007/s11548-018-1883-7
   Liang SJ, 2019, EUR RADIOL, V29, P1961, DOI 10.1007/s00330-018-5748-9
   Minnema J, 2018, COMPUT BIOL MED, V103, P130, DOI 10.1016/j.compbiomed.2018.10.012
   Qiu BJ, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab2c95
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Tong N, 2018, MED PHYS, V45, P4558, DOI 10.1002/mp.13147
   Yan M, 2018, KNOWL-BASED SYST, V159, P63, DOI 10.1016/j.knosys.2018.06.003
   Zhu WT, 2019, MED PHYS, V46, P576, DOI 10.1002/mp.13300
NR 16
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 6147
EP 6166
DI 10.1007/s11042-022-13399-6
EA AUG 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000836084200001
DA 2024-07-18
ER

PT J
AU Raghavan, R
   Verma, DC
   Pandey, D
   Anand, R
   Pandey, BK
   Singh, H
AF Raghavan, Ramesh
   Verma, Dinesh Chander
   Pandey, Digvijay
   Anand, Rohit
   Pandey, Binay Kumar
   Singh, Harinder
TI Optimized building extraction from high-resolution satellite imagery
   using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High-resolution remote sensing images; Deep learning; Deep convolutional
   networks; Building extraction; Mask-RCNN
AB Building extraction is very essential in various urban dynamics like disaster management and change detection, finding the estimated population, and so on. Building extraction from satellite data is a challenging task as the images may be subjected to different illumination or structure due to very large variations of the appearance of buildings which may correspond to the different area/terrain. Although satellite imagery is readily available from various sources, translating the imagery includes intensive effort. Many computer-vision tasks have been carried out successfully but understanding the impact of them on building extraction with remote sensing imagery is a growing need.To overcome this kind of problem, an algorithm is proposed which extends the convolutional neural network for pixel-wise classification of images. Furthermore, to resolve the problem of extraction and masking of images, Mask-RCNN (i.e., Mask Region-based Convolutional Neural Network) algorithm is used which makes this process easier and more efficient.The model is trained on a complex dataset that is significantly larger. Also, to make this algorithm more scalable, an advanced image augmentation technique is used in the pre-processing step.The results show that the algorithm achieves better performance in terms of accuracy.
C1 [Raghavan, Ramesh] Ubisoft, Mumbai, Maharashtra, India.
   [Verma, Dinesh Chander] Panipat Inst Engn & Technol, Dept Comp Applicat, Panipat, Haryana, India.
   [Pandey, Digvijay] Dr APJ Abdul Kalam Tech Univ, IET, Dept Tech Educ, Lucknow 226021, Uttar Pradesh, India.
   [Anand, Rohit] GBPant DSEU Okhla 1 Campus, GB Pant Engn Coll, Dept ECE, New Delhi, India.
   [Pandey, Binay Kumar] Govind Ballabh Pant Univ Agr & Technol, Coll Technol, Dept Informat Technol, Udham Singh Nagar, Uttrakhand, India.
   [Singh, Harinder] St Baba Attar Singh Khalsa Coll, Dept CS & IT, Sandaur, Punjab, India.
C3 Panipat Institute of Engineering & Technology; Dr. A.P.J. Abdul Kalam
   Technical University (AKTU); Institute of Engineering & Technology
   Lucknow; Govind Ballabh Pant University of Agriculture Technology
RP Pandey, D (corresponding author), Dr APJ Abdul Kalam Tech Univ, IET, Dept Tech Educ, Lucknow 226021, Uttar Pradesh, India.
EM ramesh.raghavan@yahoo.com; me.dinesh17@gmail.com;
   digit11011989@gmail.com; roh_anand@rediffmail.com; binaydece@gmail.com;
   dhaliwalhsingh@gmail.com
RI Pandey, Binay Kumar/ABI-3245-2022
OI Pandey, Binay Kumar/0000-0002-4041-1213; PANDEY,
   DIGVIJAY/0000-0003-0353-174X
CR Agarwal G., 2021, EAI Endorsed Trans Ind Netw Intell Syst, V8, pe3, DOI 10.4108/eai.17-9-2021.170961
   Akter S, 2016, ELECTRON MARK, V26, P173, DOI 10.1007/s12525-016-0219-0
   [Anonymous], 2014, INT J ENG RES
   Ardila JP, 2012, INT J APPL EARTH OBS, V15, P57, DOI 10.1016/j.jag.2011.06.005
   Azimi SM, 2019, LECT NOTES COMPUT SC, V11363, P150, DOI 10.1007/978-3-030-20893-6_10
   Chen KQ, 2017, INT GEOSCI REMOTE SE, P1672, DOI 10.1109/IGARSS.2017.8127295
   Cook K, 1975, TRANSMISSION SYSTEMS, V20, P219, DOI [10.1049/pbte071-_ch4, DOI 10.1049/PBTE071-_CH4]
   Duan YR, 2019, INT GEOSCI REMOTE SE, P3959, DOI [10.1109/igarss.2019.8899798, 10.1109/IGARSS.2019.8899798]
   Ghiasi G, 2016, LECT NOTES COMPUT SC, V9907, P519, DOI 10.1007/978-3-319-46487-9_32
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Gupta A, 2021, INT J DISTRIB SYST T, V12, DOI 10.4018/IJDST.287859
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Huang X, 2012, IEEE J-STARS, V5, P161, DOI 10.1109/JSTARS.2011.2168195
   Huang ZM, 2016, INT GEOSCI REMOTE SE, P1835, DOI 10.1109/IGARSS.2016.7729471
   Hui J, 2019, IEEE GEOSCI REMOTE S, V16, P786, DOI 10.1109/LGRS.2018.2880986
   Jin XY, 2005, EURASIP J APPL SIG P, V2005, P2196, DOI 10.1155/ASP.2005.2196
   Li WM, 2006, INT C PATT RECOG, P312
   Li X, 2018, IEEE J-STARS, V11, P3680, DOI 10.1109/JSTARS.2018.2865187
   Liu YH, 2020, IEEE ACCESS, V8, P154997, DOI 10.1109/ACCESS.2020.3015701
   Liu YH, 2019, IEEE ACCESS, V7, P128774, DOI 10.1109/ACCESS.2019.2940527
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Madhumathy P, 2022, MULTIMED TOOLS APPL, V81, P7501, DOI 10.1007/s11042-022-11903-6
   Majd RD, 2019, IEEE J-STARS, V12, P2627, DOI 10.1109/JSTARS.2019.2924582
   Marmanis D, 2015, ISPRS ANN PHOTO REM, V2-3, P103, DOI 10.5194/isprsannals-II-3-W4-103-2015
   Meivel S, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/2103975
   PAL SK, 1992, IEEE T NEURAL NETWOR, V3, P683, DOI 10.1109/72.159058
   Pandey B. K., 2021, PROC MULTIDISCIP APP, P146
   Pandey BK., 2021, AUGMENTED HUMAN RES, V6, DOI [10.1007/s41133-021-00051-5, DOI 10.1007/S41133-021-00051-5]
   Pandey D, 2022, PROCESS MINING TECHN, P121
   Pandey D, 2021, SOFT COMPUT, V25, P1563, DOI 10.1007/s00500-020-05245-4
   Papadomanolaki M, 2016, ISPRS ANN PHOTO REM, V3, P83, DOI 10.5194/isprsannals-III-7-83-2016
   Sindhwani N, 2021, INT J INF SYST MODEL, V12, P131, DOI 10.4018/IJISMD.2021010107
   Singh Shubham Kumar, 2022, 2022 9th International Conference on Computing for Sustainable Global Development (INDIACom), P530, DOI 10.23919/INDIACom54597.2022.9763165
   Vakalopoulou M, 2015, INT GEOSCI REMOTE SE, P1873, DOI 10.1109/IGARSS.2015.7326158
   Wang M, 2013, INT GEOSCI REMOTE SE, P508, DOI 10.1109/IGARSS.2013.6721204
   Wang XL, 2017, PROC CVPR IEEE, P3039, DOI 10.1109/CVPR.2017.324
   Wang YH, 2021, IEEE GEOSCI REMOTE S, V18, P1645, DOI 10.1109/LGRS.2020.3005018
   Xu YY, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010144
   Yuan J, 2016, ARXIV
NR 40
TC 9
Z9 10
U1 4
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42309
EP 42323
DI 10.1007/s11042-022-13493-9
EA JUL 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000833514100002
DA 2024-07-18
ER

PT J
AU Verma, A
   Singh, VP
AF Verma, Aman
   Singh, Vibhav Prakash
TI Design, analysis and implementation of efficient deep learning
   frameworks for brain tumor classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CAD system; Brain tumour; Deep learning; Transfer learning; Weight
   freezing
ID MACHINE; NETWORKS; IMAGES
AB Computer-aided diagnosis (CAD) system may be utilized as assistants for doctors and radiologists for the detection of disease. CAD systems using deep learning approaches are promising in diagnosing brain tumors but due to their computationally intensive nature, they are resilient to deploy in real-time scenarios where speed, as well as accuracy, is required. Further, it is necessary for the deep-learning models to capture multi-scale information as the task brain-tumor classification requires modelling pixel-to-pixel relationship and spatial-contexts in tumor-affected regions. To this end, this paper introduces the representational feature learning powers of deep, efficient and lighter deep learning architectures based on novel weight initialization and layers freezing for brain tumor classification. We use five different weight initialization and freezing configurations, four from the domain of transfer learning and the remaining being random initialization. These configurations are applied over different parameters and memory efficient architectures. Results suggest that when architecture is initiated adequately with correct weight initialization configuration based on the number of trainable parameters and architectural depth, performance obtained is optimal. Experimentation over eight different CNN architectures and five different weight initialization configurations was conducted and therefore training and evaluation of 40 deep learning frameworks was carried out. From the comprehensive experimental analyses of classification performances over three classes of brain tumor, it is evident that DenseNet201 based transfer learning model with initial 5 convolution layers frozen attains state-of-the-art accuracy of 98.22% while the lightweight models of MobileNet outperform many other models attaining the highest 97.87% accuracy for transfer learning configuration with initial 3 convolutional layers frozen while sizing only 42.6 MBs. The DenseNet201 model utilizes densely-flowing skip connections which in-turn allows the model to utilize the features learning from different spatial-contexts to formulate understanding of features in accordance with current receptive fields. With the 5 convolutional layer frozen transfer-learning scheme the same architecture achieves a performance gain of 0.88% over the state-of-art-methods. Further, the efficacy of the random initialization paradigm for brain tumor classification is investigated, results suggest that the random initialization framework can be promising if the number of trainable parameters is kept in accordance with training data quantities.
C1 [Verma, Aman] Natl Inst Technol Raipur, Dept Elect & Commun Engn, Raipur, Madhya Pradesh, India.
   [Singh, Vibhav Prakash] Motilal Nehru Natl Inst Technol Allahabad, Dept Comp Sci & Engn, Prayagraj 211004, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur; National Institute of Technology (NIT System);
   Motilal Nehru National Institute of Technology
RP Singh, VP (corresponding author), Motilal Nehru Natl Inst Technol Allahabad, Dept Comp Sci & Engn, Prayagraj 211004, India.
EM aman.verma.nitrr@gmail.com; vibhav@mnnit.ac.in
OI Singh, Dr. Vibhav Prakash/0000-0002-6823-2524
CR Abiwinanda N, 2019, IFMBE PROC, V68, P183, DOI 10.1007/978-981-10-9035-6_33
   Afshar P, 2019, INT CONF ACOUST SPEE, P1368, DOI 10.1109/ICASSP.2019.8683759
   BUETOW PC, 1990, AM J ROENTGENOL, V155, P587, DOI 10.2214/ajr.155.3.2167004
   Cascio D, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9081618
   Cheng J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0115339
   Cheplygina V, 2019, MED IMAGE ANAL, V54, P280, DOI 10.1016/j.media.2019.03.009
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Deepak S, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103345
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002
   Dong YH, 2017, 2017 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), P101, DOI 10.1109/BHI.2017.7897215
   Erickson BJ, 2017, RADIOGRAPHICS, V37, P505, DOI 10.1148/rg.2017160130
   Ghassemi N, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101678
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Gumaei A, 2019, IEEE ACCESS, V7, P36266, DOI 10.1109/ACCESS.2019.2904145
   Harvard Medical School, ABOUT US
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Ismael MR, 2018, INT CONF ELECTRO INF, P252, DOI 10.1109/EIT.2018.8500308
   Kaur T, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01069-2
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Mehrotra R, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100003
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nayak DR, 2016, NEUROCOMPUTING, V177, P188, DOI 10.1016/j.neucom.2015.11.034
   Raghu M, 2019, ADV NEUR IN, V32
   Ranjan A, 2021, J NEUROLINGUIST, V59, DOI 10.1016/j.jneuroling.2021.100985
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Surawicz T S, 1999, Neuro Oncol, V1, P14, DOI 10.1093/neuonc/1.1.14
   Swati ZNK, 2019, COMPUT MED IMAG GRAP, V75, P34, DOI 10.1016/j.compmedimag.2019.05.001
   Szegedy C., 2016, ARXIV
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Ting DSW, 2017, JAMA-J AM MED ASSOC, V318, P2211, DOI 10.1001/jama.2017.18152
   Togaçar M, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109531
   Vasan D, 2020, COMPUT NETW, V171, DOI 10.1016/j.comnet.2020.107138
   Vaswani A, 2017, ADV NEUR IN, V30
   Wernick MN, 2010, IEEE SIGNAL PROC MAG, V27, P25, DOI 10.1109/MSP.2010.936730
NR 44
TC 10
Z9 10
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37541
EP 37567
DI 10.1007/s11042-022-13545-0
EA JUL 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000832843900001
DA 2024-07-18
ER

PT J
AU Schledermann, KM
   Hansen, TS
   Bjorner, T
AF Schledermann, Kathrine M.
   Hansen, Torben Skov
   Bjorner, Thomas
TI Perceived visual comfort and usefulness of a circadian lighting system
   implemented at a nursing home
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Circadian lighting; Visual comfort; Perceived usefulness; Action
   research
ID ALZHEIMERS-DISEASE; JOB-SATISFACTION; SLEEP QUALITY; OLDER-ADULTS;
   INTERVENTION; PERFORMANCE; WORK; MOOD; ENVIRONMENT; PERCEPTION
AB This study is an investigation of how staff working at a Danish nursing home experienced, perceived, and used a circadian lighting system that has been operating since 2018. The purpose of the installed circadian lighting was to improve the staff and residents' health and well-being. This paper demonstrates the importance of training and introducing the staff to the lighting system, especially operating, and maintaining a prolonged desired utilization of the system. In this study, we employed an action research methodology that included interviews, observations, and a questionnaire. We investigated 42 staff members' perceived visual comfort with, satisfaction with, perceived ease of use, and perceptions of the usefulness of the circadian lighting. Mixed methods proved valuable in the subjective assessment of light and visual comfort. We present an alternative card sorting method to study perceptions of a 24-hour lighting system. The findings revealed that the staff considered circadian light as satisfactory and a more adequate light for work than the existing lighting system. The staff considered being able to adjust the light important for maintaining visibility, setting the lighting depending on the activities, and meeting residents' needs. Furthermore, the results showed that a thought-out strategy to introduce the staff to the new lighting can be important for satisfaction and prolonged use of the lighting. Lastly, we also found that the circadian lighting system can improve the caregiver burden for night shift workers.
C1 [Schledermann, Kathrine M.; Bjorner, Thomas] Aalborg Univ, Dept Architecture Design & Media Technol, Copenhagen SV, Denmark.
   [Hansen, Torben Skov] Hlth Promoting Lighting, Chromaviso, Aarhus, Denmark.
C3 Aalborg University
RP Bjorner, T (corresponding author), Aalborg Univ, Dept Architecture Design & Media Technol, Copenhagen SV, Denmark.
EM kmsc@create.aau.dk; tsh@chromaviso.com; tbj@create.aau.dk
RI Bjørner, Thomas/AAX-7018-2020
OI Bjørner, Thomas/0000-0001-9071-7168; Schledermann, Kathrine
   Marie/0000-0002-5785-5718
FU Innovation Fund Denmark
FX The authors wish to acknowledge the approval and the support of this
   research study by the Industrial PhD grant from Innovation Fund Denmark.
   Kathrine M. Schledermann has received research support from the company
   Chromaviso. Torben Skov Hansen is Head of Innovation and Quality at
   Chromaviso.
CR Al horr Yousef, 2016, International Journal of Sustainable Built Environment, V5, P1, DOI 10.1016/j.ijsbe.2016.03.006
   Allan AC, 2019, LEUKOS, V15, P115, DOI 10.1080/15502724.2018.1531017
   Applebaum D, 2010, J NURS ADMIN, V40, P323, DOI 10.1097/NNA.0b013e3181e9393b
   Bjorner T., 2015, Qualitative Methods for Consumer Research: The Value of the Qualitative Approach in Theory and Practice
   Boyce PR, 2006, LIGHTING RES TECHNOL, V38, P191, DOI 10.1191/1365782806lrt161oa
   Bryman A., 2001, SOCIAL RES METHODS
   Cajochen C, 2019, LIGHTING RES TECHNOL, V51, P1044, DOI 10.1177/1477153519828419
   Chen YJ, 2021, JT COMM J QUAL PATIE, V47, P165, DOI 10.1016/j.jcjq.2020.11.007
   Davis RG, 2020, HERD-HEALTH ENV RES, V13, P110, DOI 10.1177/1937586719890940
   de Kort YAW, 2010, LIGHTING RES TECHNOL, V42, P345, DOI 10.1177/1477153510378150
   Engwall M, 2015, INTENS CRIT CARE NUR, V31, P325, DOI 10.1016/j.iccn.2015.07.001
   Figueiro MG, 2021, LIGHTING RES TECHNOL, V53, P405, DOI 10.1177/14771535211005835
   Figueiro MG, 2018, LIGHTING RES TECHNOL, V50, P38, DOI 10.1177/1477153517721598
   Figueiro MG, 2019, J CLIN SLEEP MED, V15, P1757, DOI 10.5664/jcsm.8078
   Figueiro MG, 2017, NEURODEGENER DIS MAN, V7, P119, DOI 10.2217/nmt-2016-0060
   Figueiro MG, 2015, SLEEP HEALTH, V1, P322, DOI 10.1016/j.sleh.2015.09.003
   Figueiro MG, 2014, CLIN INTERV AGING, V9, P1527, DOI 10.2147/CIA.S68557
   Figueiro MG, 2012, J ALZHEIMERS DIS, V31, P711, DOI 10.3233/JAD-2012-120484
   Flynn JE., 1977, Lighting Design and Application, V2, P6, DOI DOI 10.21236/ADB020187
   Griepentrog JE, 2018, CRIT CARE, V22, DOI 10.1186/s13054-018-2233-4
   Hadi K, 2016, HERD-HEALTH ENV RES, V9, P17, DOI 10.1177/1937586715603194
   Hansen EK, 2022, INDOOR BUILT ENVIRON, V31, P355, DOI 10.1177/1420326X21991198
   Holden RJ, 2010, J BIOMED INFORM, V43, P159, DOI 10.1016/j.jbi.2009.07.002
   Houser K. W., 2003, Lighting Research & Technology, V35, P183, DOI 10.1191/1365782803li073oa
   Houser KW, 2021, LIGHTING RES TECHNOL, V53, P97, DOI 10.1177/1477153520958448
   Iskra-Golec IM, 2012, LIGHTING RES TECHNOL, V44, P506, DOI 10.1177/1477153512447528
   Khachiyants N, 2011, PSYCHIAT INVEST, V8, P275, DOI 10.4306/pi.2011.8.4.275
   Lo Verso VRM, 2016, INDOOR BUILT ENVIRON, V25, P809, DOI 10.1177/1420326X15588337
   McCunn LJ, 2021, HERD-HEALTH ENV RES, V14, P204, DOI 10.1177/1937586720946669
   Newsham G, 2009, BUILD RES INF, V37, P129, DOI 10.1080/09613210802710298
   Nilsen ER, 2016, BMC HEALTH SERV RES, V16, DOI 10.1186/s12913-016-1913-5
   Norman RM, 2017, BMC NURS, V16, DOI 10.1186/s12912-017-0256-9
   O'Brien BC, 2014, ACAD MED, V89, P1245, DOI 10.1097/ACM.0000000000000388
   Ooms S, 2016, CURR TREAT OPTION NE, V18, DOI 10.1007/s11940-016-0424-3
   Sander B, 2015, CHRONOBIOL INT, V32, P1049, DOI 10.3109/07420528.2015.1056304
   Schledermann Kathrine M., 2021, GoodIT '21: Proceedings of the Conference on Information Technology for Social Good, P91, DOI 10.1145/3462203.3475881
   Schledermann KM, 2021, SINTEF P, V8, P194
   Stokkermans M, 2018, LIGHTING RES TECHNOL, V50, P1164, DOI 10.1177/1477153517722384
   van Duijnhoven J, 2019, INDOOR BUILT ENVIRON, V28, P152, DOI 10.1177/1420326X17735162
   van Lieshout-van Dal E, 2019, BUILD ENVIRON, V150, P245, DOI 10.1016/j.buildenv.2019.01.010
   Veitch JA, 2008, LIGHTING RES TECHNOL, V40, P133, DOI 10.1177/1477153507086279
   Veitch JA, 2013, ENVIRON BEHAV, V45, P198, DOI 10.1177/0013916511420560
   West A, 2019, NEUROREHABILITATION, V44, P341, DOI 10.3233/NRE-182565
NR 43
TC 2
Z9 2
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5253
EP 5269
DI 10.1007/s11042-022-13364-3
EA JUL 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000830967300002
DA 2024-07-18
ER

PT J
AU Kee, KW
   Lim, KH
   Lim, CH
   Lim, WL
   Yap, HE
AF Kee, Kia Wei
   Lim, King Hann
   Lim, Chin Hong
   Lim, Wen Loong
   Yap, Huei Ee
TI Cracks identification using mask region-based denoised deformable
   convolutional network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cracks identification; Mask R-CNN; Denoised deformable Convolutional
   network
AB Cracks are one of the critical structural defects in building assessment to determine the integrity of civil structure. Structural surveying process using computer vision is required to automatically identify cracks. The application of Convolutional Neural Networks (CNNs) is limited by its fixed geometric kernels to extract the irregular shape of cracks. In this paper, a mask Region-based Denoised Deformable Convolutional Network (R-DDCN) is proposed to detect cracks for accurate instance segmentation and image classification. Denoised deformable convolution is introduced to improve the modeling capability of convolution layer. It adopts the existing deformable convolution, with non-local means as a denoising mechanism to optimize the augmentation of spatial sampling locations with filtered offsets. Experimental results show that the proposed mask R-DDCN has lower validation loss and improved mean accuracy precision of mAP(75) from 66.7% to 76.7% as compared to the mask R-CNN. Mask R-DDCN can perform better modeling capability in cracks identification.
C1 [Kee, Kia Wei; Lim, King Hann] Curtin Univ Malaysia, CDT 250, Miri 98000, Malaysia.
   [Lim, Chin Hong; Lim, Wen Loong] SafeT5 Sdn Bhd, Sungai Buloh, Selangor, Malaysia.
   [Yap, Huei Ee] LP Res Inc, Tokyo, Japan.
C3 Curtin University Malaysia
RP Kee, KW (corresponding author), Curtin Univ Malaysia, CDT 250, Miri 98000, Malaysia.
EM keekw97@hotmail.com
RI Lim, Hann/AAI-9930-2020
OI Lim, Hann/0000-0002-5679-7747; Kee, Kia Wei/0000-0002-5506-1121
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions
CR Aire, 2016, 19 WORLD C NONDESTRU
   [Anonymous], 2020, ARXIV
   Bai T, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12050762
   Boyat A.K., 2015, ARXIV
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Changqian Yu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P379, DOI 10.1007/978-3-030-58571-6_23
   Cho, 2019, SMAR 2019 5 C SMART
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dwivedi SK, 2018, MATER TODAY-PROC, V5, P3690, DOI 10.1016/j.matpr.2017.11.620
   Enze Xie, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12190, DOI 10.1109/CVPR42600.2020.01221
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Geethalakshmi S., 2018, INT J PURE APPL MATH, V118, P215
   Ghasemian A, 2020, IEEE T KNOWL DATA EN, V32, P1722, DOI 10.1109/TKDE.2019.2911585
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hu J, 2018, METALS-BASEL, V8, DOI 10.3390/met8080612
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jamaluddin N, 2017, MATEC WEB CONF, V103, DOI 10.1051/matecconf/201710302016
   Jeon YH, 2017, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2017.200
   Lee CW, 2016, AUTOMATIC CRACK DETE, P1
   Lee WQ., 2020, ASM SCI J, V13, P74
   Li SY, 2018, PROC SPIE, V10598, DOI 10.1117/12.2296536
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Mei QP, 2020, AUTOMAT CONSTR, V110, DOI 10.1016/j.autcon.2019.103018
   Hoang DN, 2018, ADV CIV ENG, V2018, DOI 10.1155/2018/3924120
   Ozgenel CF, 2018, IS P INT S AUT ROB C, V35, P1, DOI DOI 10.22260/ISARC2018/0094
   Prasanna P, 2016, IEEE T AUTOM SCI ENG, V13, P591, DOI 10.1109/TASE.2014.2354314
   Qu Z, 2018, CONCRETE SURFACE CRA, P7
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ryu E, 2020, INT J CONCR STRUCT M, V14, DOI 10.1186/s40069-019-0387-3
   Shan BH, 2016, KSCE J CIV ENG, V20, P803
   Sida Peng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8530, DOI 10.1109/CVPR42600.2020.00856
   Singh J., 2018, ARXIV181104535
   Singh K, 2019, SURFACE CRACK DETECT
   Song WD, 2020, J ADV TRANSPORT, V2020, DOI 10.1155/2020/6412562
   SUN T, 1994, SIGNAL PROCESS, V35, P213, DOI 10.1016/0165-1684(94)90212-7
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Xie CH, 2019, PROC CVPR IEEE, P501, DOI 10.1109/CVPR.2019.00059
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu HY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9142867
   YANG RK, 1995, IEEE T SIGNAL PROCES, V43, P591, DOI 10.1109/78.370615
   Zhang HZ, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9071503
   Zhang L, 2016, IEEE IMAGE PROC, P3708, DOI 10.1109/ICIP.2016.7533052
   Zhang R, 2020, IEEE T PATTERN ANAL, V42, P909, DOI 10.1109/TPAMI.2018.2890637
   Zhang WY, 2014, SENSORS-BASEL, V14, P19307, DOI 10.3390/s141019307
   Zou, 2011, CRACKTREE AUTOMATIC, P11
NR 51
TC 1
Z9 1
U1 4
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4387
EP 4404
AR s11042-022-13422-w
DI 10.1007/s11042-022-13422-w
EA JUL 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9MF1
UT WOS:000830266500003
OA hybrid
DA 2024-07-18
ER

PT J
AU Gururaj, N
   Vinod, V
   Vijayakumar, K
AF Gururaj, Nirmala
   Vinod, Viji
   Vijayakumar, K.
TI Deep grading of mangoes using Convolutional Neural Network and Computer
   Vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Computer vision; Image processing; Classifier; Accuracy;
   Grading; Variety; Random forest; Convolutional neural network
ID CLASSIFICATION
AB The grading of mangoes is an essential aspect of providing quality fruits to consumers and control the needs of the fruit processing industry. Manual visual inspection leads to inconsistencies, and it is human labour intensive. This paper is focused on improving the accuracy of the automatic mango grading system by doing multi-level grading using Deep Learning, Computer Vision and Image processing techniques. The proposed system is based on the mango maturity ripening stage, shape, texture features, colour and defects to identify the mango variety and classify based on quality. The maturity ripening stage of the mango is extracted using the Convolutional Neural Network (CNN). Computer Vision and Image processing techniques are used to extract shape, texture features and defects. The extracted features are input to the Random Forest classifier to identify the mango variety and grade the mango quality into three classes Notfit, Average and Good. The system has been validated on the dataset created for this study across three different varieties, Banganapalli, Neelam and Rumani, the most popular in Tamil Nadu. The proposed system using features extracted from CNN enhanced the system's efficiency with an accuracy of 93.23% for variety recognition and 95.11% for quality grading. Hence the proposed system is fully automated, commercially viable and has improved accuracy in variety recognition and quality grading of mangoes across different varieties.
C1 [Gururaj, Nirmala; Vinod, Viji] Dr MGR Educ & Res Inst, Comp Applicat Dept, Chennai 600095, Tamil Nadu, India.
   [Vijayakumar, K.] St Josephs Inst Technol, Dept Comp Sci & Engn, Chennai 600119, Tamil Nadu, India.
RP Gururaj, N (corresponding author), Dr MGR Educ & Res Inst, Comp Applicat Dept, Chennai 600095, Tamil Nadu, India.
EM gururaj.nirmala@gmail.com; vijivino@gmail.com; mkvijay@msn.com
RI K, VIJAYAKUMAR/I-6554-2019
OI K, VIJAYAKUMAR/0000-0002-5379-5703
CR Altaheri H, 2019, IEEE ACCESS, V7, P117115, DOI 10.1109/ACCESS.2019.2936536
   [Anonymous], 2021, FARM MINISTRY NEWS
   [Anonymous], 2021, The Times of India
   [Anonymous], APEDA AGR EXPORT POL
   [Anonymous], 2013, International Journal of Computer Applications
   Behera SK, 2021, INFORM PROCESS AGR, V8, P244, DOI 10.1016/j.inpa.2020.05.003
   De Goma JC., 2018, J TELECOMMUN ELECT C, V10, P39
   Ganiron TU., 2014, INT J BIOSCIENCE BIO, V6, P31, DOI [10.14257/ijbsbt.2014.6.2.03, DOI 10.14257/IJBSBT.2014.6.2.03]
   Gururaj, 2019, J ADV RES DYNAMICAL, V11, P1444
   Gururaj N., 2019, Int J Innov Technol Exploring Eng (IJITEE), V9, P3567, DOI [10.35940/ijitee.B7387.129219, DOI 10.35940/IJITEE.B7387.129219]
   Iqbal SM, 2016, INT J FOOD PROP, V19, P272, DOI 10.1080/10942912.2015.1020439
   Kamble, 2020, INT J ADV SCI TECHNO, V29, P2766
   Kamel, 2015, EGYPT J AGRIC RES, V93, P147, DOI [10.21608/ejar.2015.153315, DOI 10.21608/EJAR.2015.153315]
   Li ZB, 2020, INT J COMPUT INT SYS, V13, P559, DOI 10.2991/ijcis.d.200425.001
   Momin, 2017, CHINA AGR U, V4, P150
   Naik, 2014, NATL J SYSTEM INFORM, V7
   Naik S, 2019, P INT C SUST COMP SC, P670
   Nandi CS., 2014, Smart Sensors, Measurement and Instrumentation, P27, DOI [DOI 10.1007/978-3-319-02315-1_2, 10.1007/978-3-319-02315-1_2]
   Naranjo-Torres J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103443
   Long NTM, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10175775
   Pathanjali, 2018, INT J ENG TECHNOL, V7, P521
   Ronald M., 2016, Ind. J. Comput. Sci. Eng. (IJCSE), V7, P13
   Salunkhe RP, 2015, 2015 THIRD INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P362, DOI 10.1109/ICIIP.2015.7414796
   Srinivasan, 2020, APPLE FRUIT DETECTIO, V9, P1055
   Supekar Amruta Deepak, 2020, INFOCOMP J. Comput. Sci., V19, P175
   Vyas, 2014, INT J COMPUTER APPL, V98, P1
   Widiyanto, 2019, TECHNO J FAKULTAS TE, V20, P1, DOI [10.30595/techno.v20i1.3541, DOI 10.30595/TECHNO.V20I1.3541]
   Win O., 2019, INT J TREND SCI RES, V3, P1475
   Yossy, 2017, SCIENCEDIRECT 2 INT, P2
   Zhang, 2018, EURASIP J IMAGE VIDE, V46, P1
NR 30
TC 14
Z9 14
U1 3
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39525
EP 39550
DI 10.1007/s11042-021-11616-2
EA JUL 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000825246000002
DA 2024-07-18
ER

PT J
AU Carnovalini, F
   Rodà, A
   Caneva, P
AF Carnovalini, Filippo
   Roda, Antonio
   Caneva, Paolo
TI A rhythm-aware serious game for social interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Serious games; Sound and music computing; Music generation; Tempo
   detection; Human-computer interaction
ID MUSIC; SIMULATIONS
AB Making music with others is both an artistic act and a social activity. Music therapists can leverage the social aspects of music to increase the well-being of their patients by interacting with them musically, improvising rhythms and melodies together on shared musical instruments. This activity requires highly trained professionals and is therefore expensive for the clients. We propose a serious game that can help people without musical training interact by collaboratively creating a rhythm using MIDI drum pads. The gaming system analyzes the rhythm in real-time and adds musical feedback that is synchronized to what the users play, enhancing the aesthetical experience that is crucial to the musical interaction and its therapeutic effects. We assessed our system through quantitative metrics showing its capability of following a user-established tempo. Test players also completed a questionnaire, which showed they found the experience pleasant and engaging, and that the musical augmentation was helpful to their interaction.
C1 [Carnovalini, Filippo; Roda, Antonio] Univ Padua, Computat Sonol Ctr, Via Giovanni Gradenigo 6, Padua, Italy.
   [Caneva, Paolo] Verona Conservatory Mus, Dept Mus Therapy, Via Abramo Massalongo 2, Verona, Italy.
C3 University of Padua
RP Carnovalini, F (corresponding author), Univ Padua, Computat Sonol Ctr, Via Giovanni Gradenigo 6, Padua, Italy.
EM filippo.carnovalini@dei.unipd.it
RI Carnovalini, Filippo/GSN-1965-2022
OI Carnovalini, Filippo/0000-0002-2996-9486
FU Universita degli Studi di Padova within the CRUI-CARE Agreement;
   Universit`a degli Studi di Padova
FX Open access funding provided by Universita degli Studi di Padova within
   the CRUI-CARE Agreement. The first author is funded by a Doctoral Grant
   by Universit`a degli Studi di Padova. No further funding was received
   for conducting this study.
CR Agres K.R., 2021, Music Sci, V4, DOI [DOI 10.1177/2059204321997709, 10.1177/2059204321997709]
   Agres K, 2017, INT CONF ORANGE TECH, P95, DOI 10.1109/ICOT.2017.8336097
   Aigen K, 2007, NORD J MUSIC THER, V16, P112, DOI 10.1080/08098130709478181
   Allen R, 2010, MUSIC PERCEPT, V27, P251, DOI 10.1525/MP.2010.27.4.251
   [Anonymous], 1987, Improvisational Models of Music Therapy
   [Anonymous], 2012, STRUCTURING MUSIC MA, DOI DOI 10.4018/978-1-4666-2497-9.CH008
   Begel V., 2018, MUSIC SCI, V1, p2059204318794369, DOI [10.1177/2059204318794369, DOI 10.1177/2059204318794369]
   Benveniste S., 2009, Proceedings of the 8th International Conference on Interaction Design and Children, P18, DOI [10.1145/1551788.1551793, DOI 10.1145/1551788.1551793]
   Biles J. A., 2013, MUME 2013 WORKSH
   Brown, 2012, AAAI TECHNICAL REPOR, P7
   Canazza S, 2015, ADV HUM-COMPUT INTER, V2015, DOI 10.1155/2015/850474
   Carnovalini F, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL AUDIO MOSTLY CONFERENCE, AM 2019, P24, DOI 10.1145/3356590.3356596
   Carnovalini F, 2020, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.00014
   Carnovalini F, 2019, PROCEEDINGS OF THE 5TH EAI INTERNATIONAL CONFERENCE ON SMART OBJECTS AND TECHNOLOGIES FOR SOCIAL GOOD (GOODTECHS 2019), P124, DOI 10.1145/3342428.3342678
   Carnovalini F, 2019, 2019 INTERNATIONAL WORKSHOP ON MULTILAYER MUSIC REPRESENTATION AND PROCESSING (MMRP 2019), P41, DOI [10.1109/MMRP.2019.00016, 10.1109/MMRP.2019.8665367]
   Chen JL, 2018, ANN NY ACAD SCI, V1423, P57, DOI 10.1111/nyas.13726
   Corneli, 2018, CONCEPT INVENTION FD, P153, DOI [10.1007/978-3-319-65602-1_6, DOI 10.1007/978-3-319-65602-1_6]
   Cristani M., 2010, P C ACM MULT 2010 IN, P551
   Dannenberg R, 1984, P 1984 INT COMP MUS, P193
   Dixon S, 2001, J NEW MUSIC RES, V30, P39, DOI 10.1076/jnmr.30.1.39.7119
   Frieler Klaus, 2004, ISMIR, P6
   Fujioka T, 2018, ANN NY ACAD SCI, V1423, P264, DOI 10.1111/nyas.13706
   Gillick J, 2019, PR MACH LEARN RES, V97
   Gouyon Fabien, 2003, AES CONV AES AMST N, P8
   Hallam S, 2010, INT J MUSIC EDUC, V28, P269, DOI 10.1177/0255761410370658
   Hawryshkewich A., 2010, P NEW INTERFACES MUS, P100
   Hove MJ, 2009, SOC COGNITION, V27, P949, DOI 10.1521/soco.2009.27.6.949
   Koelsch S, 2015, ANN NY ACAD SCI, V1337, P193, DOI 10.1111/nyas.12684
   Kokotsaki D., 2007, MUSIC EDUC RES, V9, P93, DOI [DOI 10.1080/14613800601127577, 10.1080/14613800601127577]
   Moens B, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0114234
   Muller Meinard, 2004, ISMIR, V8, P8
   Pachet F., 2002, Music and Artificial Intelligence. Second International Conference, ICMAI 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2445), P119
   PARNCUTT R, 1994, MUSIC PERCEPT, V11, P409
   Perez-Arevalo C, 2017, P 18 INT C HUM COMP, P4, DOI [10.1145/3123818.3123853, DOI 10.1145/3123818.3123853]
   Perret D, 2005, Roots of musicality: Music therapy and personal development
   Quintin EM, 2011, J AUTISM DEV DISORD, V41, P1240, DOI 10.1007/s10803-010-1146-0
   Raphael C, 2002, ADV NEUR IN, V14, P1433
   Ritterfeld U., 2009, Serious Games: Mechanisms and Effects, P1, DOI [DOI 10.4324/9780203891650, 10.4324/9780203891650]
   Robertson Andrew, 2007, P NIME 07, P234, DOI 10.1145/1279740.1279787
   Santolin C, 2019, INFANCY, V24, P827, DOI 10.1111/infa.12295
   Schreiber H, 2018, P 19 INT SOC MUS INF, P8
   Scirea M, 2017, PROCEEDINGS OF THE 2017 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'17), P211, DOI 10.1145/3071178.3071314
   Shah V, 2019, 2019 58TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P737, DOI [10.23919/SICE.2019.8859927, 10.23919/sice.2019.8859927]
   Simonetta F, 2018, 2018 CONFERENCE ON INTERACTION WITH SOUND (AUDIO MOSTLY): SOUND IN IMMERSION AND EMOTION (AM'18), DOI 10.1145/3243274.3243301
   Stige B., 1998, NORD J MUSIC THER, V7, P121, DOI DOI 10.1080/08098139809477932
   SWINGLER T., 1998, 2 EUR C DIS VIRT REA, P253
   Toiviainen P, 1998, COMPUT MUSIC J, V22, P63, DOI 10.2307/3680894
   Turchet L, 2017, IEEE T AFFECT COMPUT, V8, P340, DOI 10.1109/TAFFC.2016.2552515
   Turchet L, 2017, IEEE T AFFECT COMPUT, V8, P241, DOI 10.1109/TAFFC.2016.2520924
   Whiteley N., 2006, ISMIR, V29, P34
   Williams D, 2015, PSYCHOL MUSIC, V43, P831, DOI 10.1177/0305735614543282
   Xia Gus G., 2017, NIME 17, P5
   Zhang JD, 2019, MUSIC PERCEPT, V36, P457, DOI 10.1525/MP.2019.36.5.457
NR 53
TC 1
Z9 1
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4749
EP 4771
DI 10.1007/s11042-022-13372-3
EA JUL 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000823376700002
OA hybrid
DA 2024-07-18
ER

PT J
AU Barra, S
   Carta, SM
   Giuliani, A
   Pisu, A
   Podda, AS
   Riboni, D
AF Barra, Silvio
   Carta, Salvatore M.
   Giuliani, Alessandro
   Pisu, Alessia
   Podda, Alessandro Sebastian
   Riboni, Daniele
TI FootApp: An AI-powered system for football match annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent user interfaces; Pattern recognition; Artificial
   intelligence
ID SOCCER; VIDEOS
AB In the last years, scientific and industrial research has experienced a growing interest in acquiring large annotated data sets to train artificial intelligence algorithms for tackling problems in different domains. In this context, we have observed that even the market for football data has substantially grown. The analysis of football matches relies on the annotation of both individual players' and team actions, as well as the athletic performance of players. Consequently, annotating football events at a fine-grained level is a very expensive and error-prone task. Most existing semi-automatic tools for football match annotation rely on cameras and computer vision. However, those tools fall short in capturing team dynamics and in extracting data of players who are not visible in the camera frame. To address these issues, in this manuscript we present FootApp, an AI-based system for football match annotation. First, our system relies on an advanced and mixed user interface that exploits both vocal and touch interaction. Second, the motor performance of players is captured and processed by applying machine learning algorithms to data collected from inertial sensors worn by players. Artificial intelligence techniques are then used to check the consistency of generated labels, including those regarding the physical activity of players, to automatically recognize annotation errors. Notably, we implemented a full prototype of the proposed system, performing experiments to show its effectiveness in a real-world adoption scenario.
C1 [Barra, Silvio] Univ Naples Federico II, Dept Informat Technol & Elect Engn, Via Claudio 21, I-80125 Naples, Italy.
   [Carta, Salvatore M.; Giuliani, Alessandro; Pisu, Alessia; Podda, Alessandro Sebastian; Riboni, Daniele] Univ Cagliari, Dept Math & Comp Sci, Via Osped 72, I-09124 Cagliari, Italy.
C3 University of Naples Federico II; University of Cagliari
RP Podda, AS (corresponding author), Univ Cagliari, Dept Math & Comp Sci, Via Osped 72, I-09124 Cagliari, Italy.
EM sebastianpodda@unica.it
RI Podda, Alessandro Sebastian/AAQ-6091-2020; Riboni, Daniele/H-8225-2012
OI Podda, Alessandro Sebastian/0000-0002-7862-8362; Giuliani,
   Alessandro/0000-0001-5576-7311
FU POR FESR Sardegna 2014-2020 project "MISTER: Match Information System
   and Technologies for the Evaluation of the Performance"
FX This work was partially funded by the POR FESR Sardegna 2014-2020
   project "MISTER: Match Information System and Technologies for the
   Evaluation of the Performance".
CR Alan O, 2008, 2008 23 INT S COMP I, P1, DOI [10.1109/ISCIS.2008.4717936, DOI 10.1109/ISCIS.2008.4717936]
   Altun K, 2010, PATTERN RECOGN, V43, P3605, DOI 10.1016/j.patcog.2010.04.019
   [Anonymous], 2013, Web Speech API
   [Anonymous], 2008, Performance assessment for field sports, DOI DOI 10.4324/9780203890691
   [Anonymous], 2017, IEEE IJCNN, DOI DOI 10.1109/IJCNN.2017.7966291
   Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004
   Ballan L, 2010, MULTIMED TOOLS APPL, V48, P313, DOI 10.1007/s11042-009-0342-4
   Barra S, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399967
   Barra S, 2020, IEEE-CAA J AUTOMATIC, V7, P683, DOI 10.1109/JAS.2020.1003132
   Borgelt C, 2002, COMPSTAT 2002: PROCEEDINGS IN COMPUTATIONAL STATISTICS, P395
   Chen LM, 2012, IEEE T SYST MAN CY C, V42, P790, DOI 10.1109/TSMCC.2012.2198883
   Cioppa Anthony, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13123, DOI 10.1109/CVPR42600.2020.01314
   Fernández D, 2017, IEEE INT CONF COMP V, P337, DOI 10.1109/ICCVW.2017.48
   Goal.com, FOOTB DONT WEAR BRAS
   Grehaigne JF, 1997, J TEACH PHYS EDUC, V16, P500, DOI 10.1123/jtpe.16.4.500
   Hao DG, 2020, IEEE J BIOMED HEALTH, V24, P2701, DOI 10.1109/JBHI.2020.2974425
   Haryanto Ardy Wibowo, 2018, 2018 3rd International Seminar on Application for Technology of Information and Communication. Proceedings, P229, DOI 10.1109/ISEMANTIC.2018.8549748
   Hosseini MS, 2013, APPL SOFT COMPUT, V13, P846, DOI 10.1016/j.asoc.2012.10.007
   Khan AM, 2010, IEEE T INF TECHNOL B, V14, P1166, DOI 10.1109/TITB.2010.2051955
   Li XR, 2019, IEEE T MULTIMEDIA, V21, P2347, DOI 10.1109/TMM.2019.2896494
   Liu H, 2005, IEEE INTELL SYST, V20, P64, DOI 10.1109/MIS.2005.105
   Lo Presti D, 2021, IEEE INT SYM MED MEA, DOI 10.1109/MeMeA52024.2021.9478750
   Luna JM, 2019, WIRES DATA MIN KNOWL, V9, DOI 10.1002/widm.1329
   Morra L, 2020, SOFTWAREX, V12, DOI 10.1016/j.softx.2020.100612
   Qian XL, 2021, IEEE SIGNAL PROC LET, V28, P180, DOI 10.1109/LSP.2021.3049997
   Riboni D, 2011, PERS UBIQUIT COMPUT, V15, P271, DOI 10.1007/s00779-010-0331-7
   Samano A, GVR INTUITIVE TOOL V
   Sharma RA, 2017, SIGNAL IMAGE VIDEO P, V11, P171, DOI 10.1007/s11760-016-0916-3
   Shawe-Taylor J., 2000, SUPPORT VECTOR MACHI, V2
   Sifan Ma, 2020, 2020 IEEE 6th International Conference on Computer and Communications (ICCC), P1852, DOI 10.1109/ICCC51575.2020.9344896
   Sorano D, 2020, ARXIV 200706475
   Sorano D, 2021, LECT NOTES ARTIF INT, V12461, P475, DOI 10.1007/978-3-030-67670-4_29
   Stein M, 2016, IEEE COMPUT GRAPH, V36, P50, DOI 10.1109/MCG.2016.102
   Theagarajan R, 2021, IEEE T CIRC SYST VID, V31, P632, DOI 10.1109/TCSVT.2020.2982580
   Verikas A, 2011, PATTERN RECOGN, V44, P330, DOI 10.1016/j.patcog.2010.08.011
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Wang ZK, 2017, IEEE T CIRC SYST VID, V27, P1104, DOI 10.1109/TCSVT.2016.2515280
   Yan F., 2005, BRIT MACHINE VISION, P619
NR 38
TC 1
Z9 1
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5547
EP 5567
DI 10.1007/s11042-022-13359-0
EA JUL 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000820564000001
OA Green Submitted, Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Bonny, T
   Al Nassan, W
   Baba, A
AF Bonny, Talal
   Al Nassan, Wafaa
   Baba, Abdullatif
TI Voice encryption using a unified hyper-chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unified hyper-chaotic system; Security analysis; Chaos-based
   cryptosystem; Secure communication system; Voice encryption
ID CIRCUIT IMPLEMENTATION; SYNCHRONIZATION
AB A Chaos-based cryptosystem is a vital method to enhance information protection in communication systems. The previous works have addressed this topic either by using highly complicated algorithms that are difficult to apply in practice or have a few encryption keys. This paper presents a new, highly secure chaos-based secure communication system that combines a conventional cryptography algorithm with two levels of chaotic masking technique. Furthermore, to enhance the security level, we employ the characteristic of a unified hyper-chaotic system to generate three different types of attractors. A Simulink of the stated system is implemented using MATLAB SIMULINK (R2013) to transmit a voice signal. Several testing methods such as power spectral density, spectrogram, histogram analysis, key sensitivity, correlation coefficient, signal to noise ratio (SNR), Percent Residual Deviation (PRD) are carried out to evaluate the quality of the proposed algorithm in several domains, time, frequency, and statistics. The simulation and comparison results demonstrate the high efficiency of the suggested cryptosystem and robustness against various cryptographic attacks.
C1 [Bonny, Talal; Al Nassan, Wafaa] Univ Sharjah, Dept Comp Engn, Sharjah, U Arab Emirates.
   [Baba, Abdullatif] Univ Turkish Aeronaut Assoc, Dept Mechatron Engn, Ankara, Turkey.
C3 University of Sharjah; Turk Hava Kurumu University; Turkish Aeronautical
   Association
RP Bonny, T (corresponding author), Univ Sharjah, Dept Comp Engn, Sharjah, U Arab Emirates.
EM tbonny@sharjah.ac.ae; walnassan@sharjah.ac.ae; ababa@thk.edu.tr
RI Bonny, Talal/HLX-3107-2023; BABA, Abdullatif/K-6266-2019
OI BABA, Abdullatif/0000-0001-5165-4205; Bonny, Talal/0000-0003-1111-0304
CR Al Nassan W, 2020, 2020 3 INT C SIGNAL, P14
   Al-kateeb ZN, 2020, MULTIMED TOOLS APPL, V79, P19615, DOI 10.1007/s11042-020-08869-8
   AlMutairi F, 2020, 2020 3 INT C SIGN PR, ppp1, DOI DOI 10.1109/ICSPIS51252.2020.9340157
   AlMutairi F, 2019, IEEE INT C EL COMP T, P15
   Alwahbani SMH, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTING, ELECTRICAL AND ELECTRONICS ENGINEERING (ICCEEE), P128, DOI 10.1109/ICCEEE.2013.6633919
   [Anonymous], 1979, ANN NY ACAD SCI
   Babanli K, 2022, INFORM SCIENCES, V594, P217, DOI 10.1016/j.ins.2022.02.020
   Bonny T, 2021, CIRC SYST SIGNAL PR, V40, P1061, DOI 10.1007/s00034-020-01521-8
   Bonny T, 2019, NONLINEAR DYNAM, V96, P2087, DOI 10.1007/s11071-019-04907-9
   Bonny T, 2019, CIRC SYST SIGNAL PR, V38, P1342, DOI 10.1007/s00034-018-0905-6
   Bonny T, 2018, NONLINEAR DYNAM, V93, P819, DOI 10.1007/s11071-018-4229-7
   Chen GR, 2004, INT J BIFURCAT CHAOS, V14, P2229, DOI 10.1142/S0218127404010655
   CUOMO KM, 1993, PHYS REV LETT, V71, P65, DOI 10.1103/PhysRevLett.71.65
   CUOMO KM, 1993, IEEE T CIRCUITS-II, V40, P626, DOI 10.1109/82.246163
   Farsana FJ, 2023, APPL COMPUT INFORM, V19, P239, DOI 10.1016/j.aci.2019.10.001
   Farsana FJ, 2020, ADV MATH PHYS, V2020, DOI 10.1155/2020/8050934
   Fawzy M., 2017, EGYPT J LANG ENG, V4, P1
   Gao TG, 2007, PHYS LETT A, V361, P78, DOI 10.1016/j.physleta.2006.09.042
   Goel N, 2014, ADV MULTIMED, V2014, DOI 10.1155/2014/910106
   Kordov K, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8050530
   Li CH, 2017, FRONT INFORM TECH EL, V18, P1305, DOI 10.1631/FITEE.1601253
   Liu X, 2022, NONLINEAR DYNAM, V130
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Muthuswamy B, 2010, INT J BIFURCAT CHAOS, V20, P1335, DOI 10.1142/S0218127410026514
   Nakamura Y, 2001, IEEE T ROBOTIC AUTOM, V17, P898, DOI 10.1109/70.976022
   Petavratzis E, 2021, ROBOT AUTON SYST, V143, DOI 10.1016/j.robot.2021.103826
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Rajagopal K, 2018, AEU-INT J ELECTRON C, V94, P55, DOI 10.1016/j.aeue.2018.06.043
   Razmara S, 2022, ARAB J SCI ENG, V47, P10471, DOI 10.1007/s13369-022-06606-x
   Sathiyamurthi P, 2020, MULTIMED TOOLS APPL, V79, P17817, DOI 10.1007/s11042-020-08729-5
   Sathiyamurthi P, 2017, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-017-0118-0
   Sen Teh J, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102421
   Shah D, 2019, MULTIMEDIA SYST, P111
   Sheela SJ, 2017, PROCEEDINGS OF THE 2017 IEEE SECOND INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND COMMUNICATION TECHNOLOGIES (ICECCT)
   Taneja N, 2012, MULTIMED TOOLS APPL, V61, P281, DOI 10.1007/s11042-011-0837-7
   Taneja N, 2012, MULTIMED TOOLS APPL, V59, P775, DOI 10.1007/s11042-011-0775-4
   Wang FQ, 2006, CHINESE PHYS, V15, P963, DOI 10.1088/1009-1963/15/5/016
   Wang XY, 2010, INT J MOD PHYS B, V24, P4619, DOI 10.1142/S0217979210053847
   Yousif SF., 2019, J ENG APPL SCI, V14, P6392, DOI [10.36478/jeasci.2019.6392.6399, DOI 10.36478/JEASCI.2019.6392.6399]
   Zghair H. K., 2021, J. Phys. Conf. Ser., V1804
NR 40
TC 6
Z9 6
U1 6
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1067
EP 1085
DI 10.1007/s11042-022-13317-w
EA JUN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000809315500002
DA 2024-07-18
ER

PT J
AU Kumar, S
   Kumar, N
   Dev, A
   Naorem, S
AF Kumar, Sanjay
   Kumar, Nikhil
   Dev, Aditya
   Naorem, Siraz
TI Movie genre classification using binary relevance, label powerset, and
   machine learning classifiers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Binary relevance; Label powerset; Machine learning classifiers; Movie
   genre classification; Multi-label text classification; Support vector
   classifier
AB Multi-label text classification (MLTC) is a technique to categorize texts into more than a single category and used extensively in various real-life problems. Such classifications problems are challenging and dependent on many factors and changes according to the problem. Movie genre classification is a popular multi-label text classification problem as movies may belong to multiple genres at the same time. The major factors used for movie genre classification are based on parameters like movie plot, title, summary, and subtitles. In recent years, some neural networks based approaches are proposed for solving such problems, which turns the solution into resource intensive and time consuming activities. In this paper, we propose a novel method of movie genre classification using a combination of problem transformation techniques, namely binary relevance (BR) and label powerset (LP), text vectorizers and machine learning classifier models. We perform binary relevance task (BR) that converts multi-label classification tasks into independent binary classification tasks whereas label powerset transforms a multi-label problem into a multiclass problem with one multiclass classifier trained on all unique label combinations found in the training data. Further, we apply text vectorizers namely, CV (Count Vectorizer) and TF-IDF (Term Frequency - Inverse Document Frequency) to tokenize the textual data to build a word vocabulary followed by employing various classifiers i.e., Logistic Regression (LR), Multinomial Naive Bayes (MNB), K-Nearest Neighbor (KNN), Support Vector Classifier (SVC) with the combination of different vectorizers and problem transformation methods. To test the effectiveness of these combinations, we use the k-fold cross-validation technique. We construct different combination using problem transformation approaches, text vectorizers and classifier models leading to overall 16 different combinations for classifying movies into appropriate genres. Finally, we evaluate the performance of each combination on publicly available IMDb datasets with target on 27 major parent genres using different performance measures and reveal that the best result is obtained using the combination comprising of label powerset (LP) as Problem transformation approach, TF-IDF as the text vectorizer and support vector classifier (SVC) as the machine learning classifier model with a commendable accuracy of 0.95 and F1-score of 0.86.
C1 [Kumar, Sanjay; Kumar, Nikhil; Dev, Aditya; Naorem, Siraz] Delhi Technol Univ, Dept Comp Sci & Engn, New Delhi 110042, India.
C3 Delhi Technological University
RP Kumar, S (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, New Delhi 110042, India.
EM sanjay.kumar@dtu.ac.in; nikhilkumar_2k17se70@dtu.ac.in;
   adityadev_2k17se10@dtu.ac.in; siraznaorem_2k17se113@dtu.ac.in
OI Kumar, Dr. Sanjay/0000-0002-8951-5996
CR [Anonymous], 2018, ARXIV180104813
   Berger M. J., 2015, TECHNICAL REPORT
   Bhowmik A, 2019, EANN COMMUNICATIONS
   Bhowmik A, 2021, MULTIMED TOOLS APPL, V80, P28015, DOI 10.1007/s11042-021-10964-3
   Bird S., 2004, P ACL INTERACTIVE PO, P214
   Cai LK, 2020, IEEE ACCESS, V8, P152183, DOI 10.1109/ACCESS.2020.3017382
   Chu W. -T., 2017, MUSA2 2017 PROC WORK, P39, DOI DOI 10.1145/3132515.3132516
   de Carvalho ACPLF, 2009, STUD COMPUT INTELL, V205, P177
   Divya R, 2021, NEURAL COMPUT APPL, V33, P8435, DOI 10.1007/s00521-020-05596-x
   Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379
   Dong S, 2021, EXPERT SYST APPL, V176, DOI 10.1016/j.eswa.2021.114885
   Doshi P, 2018, LECT NOTES ARTIF INT, V11171, P117, DOI 10.1007/978-3-030-00810-9_11
   Ertugrul AM, 2018, IEEE INT C SEMANT CO, P248, DOI 10.1109/ICSC.2018.00043
   fu berlin, IMDB DATA
   Ganda Dhatri, 2018, Recent Trends in Programming Languages, V5, P19
   Godbole S, 2004, LECT NOTES ARTIF INT, V3056, P22
   Huang YR, 2021, INT J MACH LEARN CYB, V12, P1639, DOI 10.1007/s13042-020-01260-x
   Jiang HY, 2020, WORLD WIDE WEB, V23, P1693, DOI 10.1007/s11280-019-00752-3
   Katyal S, 2018, I CONF SENS TECHNOL, P154, DOI 10.1109/ICSensT.2018.8603632
   Khurana Gurpreet, 2021, Advances in Electromechanical Technologies. Select Proceedings of TEMT 2019. Lecture Notes in Mechanical Engineering (LNME), P671, DOI 10.1007/978-981-15-5463-6_60
   Kumar S, 2019, COMM COM INF SC, V1000, P299, DOI 10.1007/978-3-030-20257-6_25
   Longato E, 2020, J DIABETES SCI TECHN, V14, P297, DOI 10.1177/1932296819838856
   Mangolin RB, 2022, MULTIMED TOOLS APPL, V81, P19071, DOI 10.1007/s11042-020-10086-2
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pobar M, 2017, LECT NOTES COMPUT SC, V10425, P367, DOI 10.1007/978-3-319-64698-5_31
   Portolese G, 2019, LECT NOTES ARTIF INT, V11805, P669, DOI 10.1007/978-3-030-30244-3_55
   Rajaraman Anand, 2011, Mining of Massive Datasets
   Saputra Antonius Christiyanto, 2019, 2019 International Conference of Artificial Intelligence and Information Technology (ICAIIT). Proceedings, P201, DOI 10.1109/ICAIIT.2019.8834606
   scikit learn, 2020, STABLE MODULES GENER
   Sinha Arghyadip, 2021, Proceedings of International Conference on Frontiers in Computing and Systems. COMSYS 2020. Advances in Intelligent Systems and Computing (AISC 1255), P299, DOI 10.1007/978-981-15-7834-2_28
   Spolaór N, 2013, ELECTRON NOTES THEOR, V292, P135, DOI 10.1016/j.entcs.2013.02.010
   Sun JS, 2021, J ASSOC INF SCI TECH, V72, P173, DOI 10.1002/asi.24400
   Tawiah Clifford A., 2013, Advances in Data Mining. Applications and Theoretical Aspects. 13th Industrial Conference, ICDM 2013. Proceedings: LNCS 7987, P137, DOI 10.1007/978-3-642-39736-3_11
   Wang TS, 2020, APPL INTELL, V50, P2339, DOI 10.1007/s10489-020-01680-w
   Wehrmann J, 2018, 31TH INT FLAIRS C
   Xia YL, 2021, INFORM SCIENCES, V557, P421, DOI 10.1016/j.ins.2020.06.017
   YANG P., 2018, P INT C COMP LING, P3915
   Yong ZJ, 2020, LECT NOTES ARTIF INT, V12595, P244, DOI 10.1007/978-3-030-66645-3_21
   Yu YT, 2021, MULTIMED TOOLS APPL, V80, P9749, DOI 10.1007/s11042-020-10125-y
   Zhang ML, 2018, FRONT COMPUT SCI-CHI, V12, P191, DOI 10.1007/s11704-017-7031-7
NR 40
TC 3
Z9 3
U1 3
U2 294
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 945
EP 968
DI 10.1007/s11042-022-13211-5
EA JUN 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000809315500001
DA 2024-07-18
ER

PT J
AU Kalsekar, A
   Khade, R
   Jariwala, K
   Chattopadhyay, C
AF Kalsekar, Atharva
   Khade, Rasika
   Jariwala, Krupa
   Chattopadhyay, Chiranjoy
TI RISC-Net : rotation invariant siamese convolution network for floor plan
   image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Floor plan; Retrieval; Rotation invariance; Siamese network
AB A floor plan represents the blue print of a building. Organizing a massive set of such floor plans and accessing them based on similarity is challenging for any architect. During the digitization process printed floor plan images are rotated slightly by a small degree of angle. Handcrafted feature-based methods proposed in the literature fail to generalize on such scenarios efficiently. In this paper we propose a deep learning-based model, Rotation Invariant Siamese Convolution Network (RISC-Net), which is able to retrieve similar floor plan images from the dataset, even in the presence of rotation. Uniqueness of RISC-Net is the ability to handle scan-time rotation both in the query as well as the images in the database. The proposed method is trained and evaluated on a publicly available floor plan image ROBIN dataset and achieved the best retrieval results 79% as compared to the state-of-the-art methods proposed in the same problem domain.
C1 [Kalsekar, Atharva; Khade, Rasika; Jariwala, Krupa] Sardar Vallabhbhai Natl Inst Technol, Surat, India.
   [Chattopadhyay, Chiranjoy] Indian Inst Technol, Jodhpur, Rajasthan, India.
C3 National Institute of Technology (NIT System); Sardar Vallabhbhai
   National Institute of Technology; Indian Institute of Technology System
   (IIT System); Indian Institute of Technology (IIT) - Jodhpur
RP Chattopadhyay, C (corresponding author), Indian Inst Technol, Jodhpur, Rajasthan, India.
EM kalsekar.atharva7@gmail.com; rasika.khandre@gmail.com;
   knj@coed.svnit.ac.in; chiranjoy@iitj.ac.in
RI Khade, Rasika/JYO-6541-2024; CHATTOPADHYAY, CHIRANJOY/AFP-0794-2022;
   Jariwala, Krupa/AAE-8865-2019
OI Khade, Rasika/0000-0002-7992-7188; CHATTOPADHYAY,
   CHIRANJOY/0000-0002-3431-0483; Jariwala, Krupa/0000-0002-9675-0548
FU Science and Engineering Research Board, India [ECR/2016/000953]
FX This work is partially supported by Science and Engineering Research
   Board, India, under the project id ECR/2016/000953.
CR Aigrain P, 1996, MULTIMED TOOLS APPL, V3, P179, DOI 10.1007/BF00393937
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Chowdhury M, 2015, MULTIMED TOOLS APPL, V74, P11595, DOI 10.1007/s11042-014-2252-3
   Garcia-Gasulla D., 2017, On the behavior of convolutional nets for feature extraction
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   Hu WM, 2018, IEEE T IMAGE PROCESS, V27, P4452, DOI 10.1109/TIP.2018.2839886
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jang H, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9020065
   Sikha OK, 2021, MULTIMED TOOLS APPL, V80, P15937, DOI 10.1007/s11042-020-10315-8
   Kapoor R, 2021, MULTIMED TOOLS APPL, V80, P29561, DOI 10.1007/s11042-021-11045-1
   Khade R, 2021, PATTERN RECOGN LETT, V145, P1, DOI 10.1016/j.patrec.2021.01.020
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Mewada HK, 2020, AUTOMATIC ROOM INFOR
   Pass G., 1996, Proceeding. Third IEEE Workshop on Applications of Computer Vision. WACV'96 (Cat. No.96TB100084), P96, DOI 10.1109/ACV.1996.572008
   Pavlidis T, 2008, 19 INT C PATT REC TA, P811
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Rezaei M, 2019, ARXIV 190909722
   Sardey MP, 2015, ARXIV 150806728
   Sharma D, 2019, DOCUMENT ANAL RECOGN, P1526
   Sharma D, 2018, IET COMPUT VIS, V12, P702, DOI 10.1049/iet-cvi.2017.0581
   Sharma D, 2017, PROC INT CONF DOC, P420, DOI 10.1109/ICDAR.2017.76
   Sharma D, 2016, INT C PATT RECOG, P2422, DOI 10.1109/ICPR.2016.7899999
   Shi Y, 2020, PERSON RETRIEVAL SUR
   Torres R. S. D., 2006, RITA, V13, P161
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Yang X, 2020, IEEE T IMAGE PROCESS, V29, P5447, DOI 10.1109/TIP.2020.2983554
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zagoruyko S., 2015, PROC CVPR IEEE, P4353, DOI DOI 10.1109/CVPR.2015.7299064
   Ziran Z, 2018, LECT NOTES ARTIF INT, V11081, P383, DOI 10.1007/978-3-319-99978-4_30
NR 32
TC 1
Z9 1
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 41199
EP 41223
DI 10.1007/s11042-022-13124-3
EA MAY 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000797298300001
DA 2024-07-18
ER

PT J
AU Roy, P
   Bag, S
AF Roy, Priyanka
   Bag, Soumen
TI Ink analysis based forensic investigation of handwritten legal documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alteration; DCNN; Forensic; Forgery detection; Handwritten legal
   document; Similar pen ink
ID INFRARED LUMINESCENCE; IMAGE-ANALYSIS; DIFFERENTIATE
AB Document falsification is among the fastest growing problems all over the world. Disclosure of such document is not always possible due to the conspiracy of attorney bodies; especially legal documents such as bank cheques, contracts, cash memos, and so on. Handwritten document tampering detection due to addition of new word(s) in judicial documents is the prime objective of this research. Minute alteration in writing causes financial loss to a person or to an organization and decreases the global economy. Such intangible assets remain undiscovered owing to lack of proper forensic techniques. Though writing style imitation can be possible, however, the possibility of getting exactly the same pen of the authorized document is quite impossible for an imitator. Hence, the paper introduces a solution to detect forgery in handwritten legal documents by analyzing perceptually similar pen ink. Forgery activity happens either ends of a written document by appending new word(s)/letter(s) with similar type of pen. The work is formulated as a binary classification problem and established with the help of several statistical features and three different classifiers: Multilayer Perceptron(MLP), RBF-SVM, and Random Forest(RF). Besides, the problem has also been implemented through some DCNN approaches to check whether it is possible to reflect the forgery by direct approaches. The efficiency of the proposed method is quite promising for involvement in the examination of forensic documents.
C1 [Roy, Priyanka; Bag, Soumen] Indian Sch Mines, Indian Inst Technol, Dhanbad 826004, Jharkhand, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Roy, P (corresponding author), Indian Sch Mines, Indian Inst Technol, Dhanbad 826004, Jharkhand, India.
EM priyankarooy@gmail.com; soumen@iitism.ac.in
RI Roy, Priyanka/GQI-2612-2022; Roy, Priyanka/GXM-5243-2022
FU SERB [ECR/2016/001251, Dt.16.03.2017]
FX The authors are very thankful for the financial support provided by the
   sponsor of the project named "Design and Implementation ofMultiple
   Strategies to Identify Handwritten Forgery Activities in Legal
   Documents" (No. ECR/2016/001251, Dt.16.03.2017), SERB, Govt. of India.
CR [Anonymous], TIMESNOWNEWS
   Barbosa RS, 2014, P INT C DOCUMENT ANA
   Bertrand R, 2013, PROC INT CONF DOC, P106, DOI 10.1109/ICDAR.2013.29
   Brauns EB, 2006, APPL SPECTROSC, V60, P833, DOI 10.1366/000370206778062093
   Brown C, 1954, J CRIM LAW CRIMINOL, V45, P473, DOI 10.2307/1140040
   Chen H., 2002, Forensic Sci Int, V1, P1
   Chen Y, 2020, PROCEEDINGS OF 2020 IEEE 5TH INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC 2020), P201, DOI 10.1109/ITOEC49072.2020.9141830
   Colwell L KB, 1964, J ASS ANAL CHEM, V60, P613
   Crown D., 1961, J CRIM LAW, V5, P338
   Dansena P, 2017, P INT C PATTERN RECO, V10597
   Dansena P, 2021, IEEE ACCESS, V9, P38979, DOI 10.1109/ACCESS.2021.3059342
   Dansena P, 2020, IET IMAGE PROCESS, V14, P1594, DOI 10.1049/iet-ipr.2018.6616
   Dasari H, 2007, P INT C DOCUMENT ANA
   Deng XY, 2016, INFORM SCIENCES, V340, P250, DOI 10.1016/j.ins.2016.01.033
   Duch W, 2004, P INT C JOINT C NEUR
   Edelman GJ, 2012, FORENSIC SCI INT, V223, P28, DOI 10.1016/j.forsciint.2012.09.012
   Gorai A, 2016, P INT JOINT C NEURAL
   Han J, 2012, MOR KAUF D, P1
   HARDCASTLE RA, 1978, J FORENSIC SCI SOC, V18, P53, DOI 10.1016/S0015-7368(78)71182-5
   HORTON RA, 1991, J FORENSIC SCI, V36, P838
   idrbt, IDRBT CHEQ IM DAT
   Kao HH, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10113716
   Khan MJ, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P393, DOI 10.1109/DAS.2018.26
   Khan Z, 2015, PATTERN RECOGN, V48, P3615, DOI 10.1016/j.patcog.2015.04.008
   Khan Z, 2013, PROC INT CONF DOC, P877, DOI 10.1109/ICDAR.2013.179
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2019, INT J ENG TECHNICAL, V9, P12
   Kumar R, 2012, IEEE T INF FOREN SEC, V7, P809, DOI 10.1109/TIFS.2011.2176119
   Kumar R, 2009, LECT NOTES COMPUT SC, V5909, P400, DOI 10.1007/978-3-642-11164-8_65
   Laylo A.M.C., 2019, Int. J. Recent Technol. Eng. (IJRTE), V8, P1763, DOI [10.35940/ijrte.B1015.078219, DOI 10.35940/IJRTE.B1015.078219]
   Megahed A, 2017, INT CONF SOFTW ENG, P141, DOI 10.1109/ICSESS.2017.8342883
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PACKARD R J, 1964, J Forensic Sci, V9, P100
   Pak M., 2017, INT CONF COMP APPL I, P1
   Roy P, 2018, P INT C COMPUTER VIS, V1024
   Roy P, 2019, P INT C PATTERN RECO, V1941
   Roy P, 2019, P INT C IDENTITY SEC, P19
   Ryu SJ, 2008, LECT NOTES COMPUT SC, V5353, P486
   SENSI CA, 1982, J FORENSIC SCI, V27, P196
   TAYLOR LR, 1984, J FORENSIC SCI, V29, P92
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Wadhwa A, 2018, IEEE INDIA COUNCIL I, P16
   Wang WL, 2017, 2017 9TH INTERNATIONAL CONFERENCE ON ADVANCED INFOCOMM TECHNOLOGY (ICAIT 2017), P345, DOI 10.1109/ICAIT.2017.8388943
NR 45
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 23007
EP 23047
DI 10.1007/s11042-022-12175-w
EA MAY 2022
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000795177900002
DA 2024-07-18
ER

PT J
AU Chen, ZY
   Zhang, YN
   Zhang, SY
   Yang, C
AF Chen, Zeyu
   Zhang, Yana
   Zhang, Suya
   Yang, Cheng
TI Study on location bias of CNN for shot scale classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image location features; VH-Pooling; CNN; Shot scale classification;
   Video auto-editing
AB With the development of artificial intelligence, the application of AI technology in the media industry is in progress. Video auto-editing is one of the directions. In video editing, the shot scale is am important reference for shot arrangement. The existing algorithms tend to classify the shot scale based on CNN, but fail to work well on all kinds of frames with various aspect ratios. One of the focuses in this paper is to explore the relationship between pooling method and location bias in CNN, so that location features and non-location features could be treated reasonably to reach a better classification performance on kinds of frames with various aspect ratios. In a set of interesting experiments, we change the output feature maps of pooling(OFMP) to observe how CNN classify a group of images by location features and non-location features. Then, a vertical and horizontal pooling method(VH-Pooling) is proposed for a robust shot scale classification, which achieves 94.24% accuracy on a multi-aspect-ratio shot scale dataset within a high operation speed. Finally, a practical shot scale classification system is designed with a post-processing module, and successfully applied in a live news AI-editing platform.
C1 [Chen, Zeyu; Zhang, Yana; Zhang, Suya; Yang, Cheng] Commun Univ China, Sch Informat & Commun Engn, Beijing 100024, Peoples R China.
   [Zhang, Suya] XinHuaZhiYunInc, 28 Xuanwumenwai St, Beijing 100075, Peoples R China.
C3 Communication University of China
RP Chen, ZY (corresponding author), Commun Univ China, Sch Informat & Commun Engn, Beijing 100024, Peoples R China.
EM gd@cuc.edu.cn; zynjenny@cuc.edu.cn; ersu@cuc.edu.cn; chy@cuc.edu.cn
OI CHEN, ZEYU/0000-0003-2766-2031
FU Fundamental Research Funds for the Central Universities [CUC210B018];
   National Natural Science Foundation of China [61901422]
FX This work was supported by the Fundamental Research Funds for the
   Central Universities under Grant CUC210B018 and the National Natural
   Science Foundation of China under Grant 61901422.
CR Bak HY, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103390
   Baker N, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1006613
   Benini S, 2016, MULTIMED TOOLS APPL, V75, P16499, DOI 10.1007/s11042-016-3339-9
   Benini S, 2010, IEEE INT CON MULTI, P855, DOI 10.1109/ICME.2010.5582611
   Carreira J., 2017, P IEEE C COMPUTER VI, p6299 6308
   Cherif I, 2007, P 2007 9 ISSPA SHARJ, P14
   Geirhos GR, 2019, INT C LEARN REPR
   Girshick R., 2015, IEEE I CONF COMP VIS, DOI [DOI 10.1109/ICCV.2015.169, 10.1109/ICCV.2015.169]
   He K, 2017, PROC IEEE ICCV
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hermann KL, 2020, ADV NEU INFOR P, P33
   Howard A. G., 2017, PREPRINT
   Hui J, 2011, P IEEE CSAE SHANGH C
   Iandola NF, 2016, COMPUT SCI
   Islam M. A., 2020, P INT C LEARN REPR I
   Jia D, 2009, P IEEE CVPR
   Lin JC, 2018, IEEE T MULTIMEDIA, V20, P3123, DOI 10.1109/TMM.2018.2820904
   Minhas RA, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9030483
   Rao A, 2020, P ECCV, P1734
   Savardi M, 2018, IEEE IMAGE PROC, P2620, DOI 10.1109/ICIP.2018.8451474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Vacchetti B, 2020, P IEEE COMPSAC MADR
   Wang Linzhao, 2016, EUROPEAN C COMPUTER
   Yu Jun-qing, 2009, Journal of Computer Applications, V29, P3422
   [周艺华 Zhou yihua], 2005, [北京理工大学学报, Journal of beijing institute of technology], V25, P1079
NR 26
TC 3
Z9 3
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40289
EP 40309
DI 10.1007/s11042-022-13111-8
EA MAY 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000791885300006
DA 2024-07-18
ER

PT J
AU Basu, S
   Debnath, A
   Basu, A
   Das, TS
AF Basu, Sharbari
   Debnath, Arunothpol
   Basu, Abhishek
   Das, Tirtha Sankar
TI An image data hiding technique using Differential Evolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermark; LSB; Spatial domain; Optimization; Differential Evolution;
   Data hiding
ID WATERMARKING TECHNIQUE; ROBUST; OPTIMIZATION; EXPANSION; QUALITY
AB The techniques of data hiding have turned out to be one of the prominent factors to ensure security and confidentiality of the communication network adopting untrustworthy and insecure means to transfer delicate information. This paper proposes a novel watermarking scheme that has used Differential Evolution(DE) optimization algorithm to efficiently hide data. The key factors of any watermarking scheme are imperceptibility and robustness. The present work has tried to gain the relevant degree of optimization between these two disagreeable factors by using the optimization technique of DE. The novelty of this paper lies in: (i) the proposed method applies DE on the pixel intensities of host image to locate the cognitively insignificant regions, (ii) the scaling factor of DE is so chosen, that when the same mathematical value of scaling factor is applied to embed watermark, it can keep the trade-off between imperceptibility and robustness. The resultant covert regions are capable to uphold a high level of transparency and are robust enough to survive against attacks. The method is carried out in the spatial domain. Experimental output depicts that the proposed method maintains competent image quality. Nevertheless, the watermark can still be recognized after various attacks even if it is distorted by a significant amount.
C1 [Basu, Sharbari] MAKAUT, Dept Comp Sci, Kolkata, India.
   [Debnath, Arunothpol; Basu, Abhishek] RCC Inst Informat Technol, Kolkata, India.
   [Das, Tirtha Sankar] Ramkrishna Mahato Govt Engn Coll, Purulia, India.
C3 Maulana Abul Kalam Azad University of Technology; RCC Institute of
   Information Technology (RCCIIT)
RP Basu, S (corresponding author), MAKAUT, Dept Comp Sci, Kolkata, India.
EM basu.sharbari@gmail.com; arunothpol003@gmail.com;
   idabhishek23@yahoo.com; reach2tirtha@gmail.com
RI Basu, Abhishek/S-6016-2019
OI Basu, Abhishek/0000-0003-4167-3722
CR Abdelhakim AM, 2016, IET IMAGE PROCESS, V10, P247, DOI 10.1049/iet-ipr.2015.0379
   Abdelhakim AM, 2018, EXPERT SYST APPL, V100, P197, DOI 10.1016/j.eswa.2018.02.002
   Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   [Anonymous], 2013, INT J COMPUT APPL
   Anushiadevi R, 2021, MULTIMED TOOLS APPL, V80, P19695, DOI 10.1007/s11042-021-10729-y
   Anushiadevi R, 2020, J INTELL FUZZY SYST, V39, P2977, DOI 10.3233/JIFS-191478
   Anushiadevi R, 2020, J INTELL FUZZY SYST, V38, P6403, DOI 10.3233/JIFS-179721
   Araghi T.K., 2016, Int. J. Adv. Image Process. Tech, V3, P6
   Basu S, 2021, ADV ELECT COMMUNICAT, P4150, DOI [10.1007/978-981-15-8752-8_5, DOI 10.1007/978-981-15-8752-8_5]
   Campidoglio M, 2009, 2009 4 INT C INTERNE
   Debnath A, 2021, PROGRESSIVE PERFORMA, P540, DOI [10.1002/9781119571452.ch2, DOI 10.1002/9781119571452.CH2]
   Goyal R., 2014, Int J Appl Innov Eng Manag, V3, P15
   Gui XL, 2014, SIGNAL PROCESS, V98, P370, DOI 10.1016/j.sigpro.2013.12.005
   Han SC, 2018, OPTOELECTRON LETT, V14, P61, DOI 10.1007/s11801-018-7212-0
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Jain A., 2013, Advances in Electronic and Electric Engineering, V3, P797
   Karaboga D., 2004, Turkish Journal Electrical Engineering and Computer Sciences, Elektrik, V12, P53
   Khanna AK, 2016, 2016 INT C COMPUTING
   Kumar C, 2020, MULTIMED TOOLS APPL, V79, P11069, DOI 10.1007/s11042-018-6177-0
   Majumder S, 2011, 2011 INT C REC TREND
   Makbol NM, 2014, DIGIT SIGNAL PROCESS, V33, P134, DOI 10.1016/j.dsp.2014.06.012
   Potdar VA, 2005, 2005 3RD IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS (INDIN), P709
   Rashid A, 2016, INT J SECUR APPL, V10, P259, DOI 10.14257/ijsia.2016.10.3.24
   Robert L., 2009, International Journal of Recent Trends in Engineering, V1, P223
   Saini LK., 2014, INT J COMPUTER SCI T, V2, P3
   Sharma VK, 2022, J KING SAUD UNIV-COM, V34, P615, DOI 10.1016/j.jksuci.2019.03.009
   Sinha Roy S, 2015, P FRCCD 2015
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Strecher V J, 1999, J Natl Cancer Inst Monogr, P134
   Su QT, 2020, MULTIMED TOOLS APPL, V79, P30023, DOI 10.1007/s11042-020-09436-x
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Sumathi C, 2014, INT J COMPUT SCI ENG, V4
   USC, 1977, USC SIPI IMAGE DATAB
   Verma M., 2013, INT J ADV RES COMPUT, V2, P2913
   Voyatzis G, 1998, 9 EUR SIGN PROC C EU, P14
   Wang J, 2011, INFORM SCIENCES, V181, P5501, DOI 10.1016/j.ins.2011.07.040
   Wong M. L. D., 2013, INT J INNOVATION MAN, V4, P228
   Wu Q, 2016, J INF SECUR APPL, V26, P1, DOI 10.1016/j.jisa.2015.08.003
   Xu H, 2010, INFORM SCIENCES, V180, P1201, DOI 10.1016/j.ins.2009.12.027
   Yang CH, 2008, PATTERN RECOGN, V41, P2674, DOI 10.1016/j.patcog.2008.01.019
   Yuan ZH, 2021, VISUAL COMPUT, V37, P1867, DOI 10.1007/s00371-020-01945-y
   Zhang XT, 2020, OPTIK, V219, DOI 10.1016/j.ijleo.2020.165272
   Zhou G, 2011, 2011 4 INT JOINT C C
NR 44
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 39995
EP 40012
DI 10.1007/s11042-022-12557-0
EA MAY 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000791088200002
DA 2024-07-18
ER

PT J
AU Gujjunoori, S
   Oruganti, M
   Pais, AR
AF Gujjunoori, Sagar
   Oruganti, Madhu
   Pais, Alwyn Roshan
TI Enhanced optical flow-based full reference video quality assessment
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video Qualti assessment; DMOS; Optcial flow; Human visual system (HVS)
AB Full reference video quality assessment based on optical flow is emerging. Human Visual System (HVS) based video quality assessment algorithms are playing an important role in effectively assessing the distortions in video sequences. There exist very few video quality assessment algorithms which consider spatio-temporal distortions effectively. To address the above issues, we present an enhanced optical flow based full reference video quality algorithm which considers the orientation feature of the optical flow while computing the temporal distortions as opposed to the use of feature, minimum eigenvalue as in the state of the art. Further, it presents an interquartile range based comparative weighted closeness (INT-CWC) measure which aimed to measure the comparative dispersion of video quality scores of any two video quality assessment algorithms with DMOS scores. Here INT-CWC measure is a novel attempt. The performance of proposed scheme is evaluated using the LIVE dataset and scheme is shown to be competitive with, and even out-perform, existing video quality assessment algorithms.
C1 [Gujjunoori, Sagar; Oruganti, Madhu] Vardhaman Coll Engn, Dept Informat Technol, Shamshabad 501218, Telangana, India.
   [Pais, Alwyn Roshan] NITK Surathkal, Dept Comp Sci & Engn, Mangalore, India.
C3 Vardhaman College of Engineering; National Institute of Technology (NIT
   System); National Institute of Technology Karnataka
RP Gujjunoori, S (corresponding author), Vardhaman Coll Engn, Dept Informat Technol, Shamshabad 501218, Telangana, India.
EM sagar4u.nitk@gmail.com; oruganti.madhu@gmail.com
RI Oruganti, Madhu/KIJ-9331-2024
OI Oruganti, Madhu/0000-0002-6274-3606; Pais, Alwyn/0000-0003-4571-4608
FU Department of Science and Technology (DST), Government of India, New
   Delhi under the Fast Track Young Scientist-Engineering Science Scheme
   [SB/FTP/ETA-0192/2014]
FX The work presented in this paper is part of the project Ref:
   SB/FTP/ETA-0192/2014 and is financially supported by the Department of
   Science and Technology (DST), Government of India, New Delhi under the
   Fast Track Young Scientist-Engineering Science Scheme. It is gratefully
   acknowledged.
CR [Anonymous], 2002, Methodology for the subjective assessment of the quality of television pictures
   [Anonymous], WIKIPEDIA CONTRIBUTO
   Benhur, 2014, 2014 INT C COMP VIS, V2
   Born RT, 2005, ANNU REV NEUROSCI, V28, P157, DOI 10.1146/annurev.neuro.26.041002.131052
   Brunnstrom Kjell, 2009, IEEE Signal Processing Magazine, V26, P96, DOI 10.1109/MSP.2009.932162
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Gujjunoori Sagar, 2020, International Journal of High Performance Computing and Networking, V16, P148, DOI 10.1504/IJHPCN.2020.112701
   Gujjunoori S, 2018, PRAI 2018: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE, P70, DOI 10.1145/3243250.3243271
   Gunnar F., 2003, 2 FRAME MOTION ESTIM
   Guo LF, 2006, IASTED INT CONF SIGN, P212
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Index, 2010, CISC VIS NETW IND GL, P9
   Liu K, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/680623
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Manasa K, 2016, IEEE T IMAGE PROCESS, V25, P2480, DOI 10.1109/TIP.2016.2548247
   Ninassi A, 2009, IEEE J-STSP, V3, P253, DOI 10.1109/JSTSP.2009.2014806
   Recommendation ITU-T, 1999, SUBJ VID QUAL ASS ME
   Seshadrinathan K, 2010, PROC SPIE, V7527, DOI 10.1117/12.845382
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Staelens N, 2010, IEEE T BROADCAST, V56, P458, DOI 10.1109/TBC.2010.2067710
   Video Qual. Experts Group Mountain View CA USA, 2010, Report on theValidation of Video Quality Models for High Definition Video Content
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 25
TC 1
Z9 2
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39491
EP 39505
DI 10.1007/s11042-022-12591-y
EA APR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000788980000002
DA 2024-07-18
ER

PT J
AU Tripathy, A
   Anand, A
   Kadyan, V
AF Tripathy, Abinash
   Anand, Abhishek
   Kadyan, Virender
TI Sentiment classification of movie reviews using GA and NeuroGA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Document level sentiment analysis; Genetic Algorithm (GA); NeuroGA;
   Performance evaluation parameter; Confusion matrix
ID ALGORITHM
AB Views or comments expressed in favor or against of any item, a product or a movie, etc. are often available in the form of sentiments of users. These reviews are analyzed with an aim to provide meaningful information to the provider of the product and help in guiding the future users in a more meaningful way. In this manuscript, two different machine learning algorithms are considered for classification of movie reviews. Firstly, Genetic Algorithm (GA), where the movie reviews under analysis are transformed into chromosomes and these chromosomes are then classified using proper technique. Secondly, a combination of GA and Artificial Neural Network (ANN) is considered for the classification purpose. The best fit chromosomes obtained from GA is considered as input for ANN and further processing is carried out by changing the hidden nodes in ANN. The performance of these classifiers are then evaluated using different parameters like recall, precision, f-measure and accuracy.
C1 [Tripathy, Abinash] Raghu Engn Coll Autonomous, Dept Comp Sci & Engn, Visakhapatnam, Andhra Pradesh, India.
   [Anand, Abhishek] Google India Private Ltd, Bengaluru, Karnataka, India.
   [Kadyan, Virender] Univ Petr & Energy Studies, Sch Comp Sci, Dehra Dun, Uttarakhand, India.
C3 University of Petroleum & Energy Studies (UPES)
RP Tripathy, A (corresponding author), Raghu Engn Coll Autonomous, Dept Comp Sci & Engn, Visakhapatnam, Andhra Pradesh, India.
EM abi.tripathy@gmail.com; abhianand1093@gmail.com; vkadyan@ddn.upes.ac.in
RI Tripathy, Abinash/K-2195-2015
OI Tripathy, Abinash/0000-0001-9919-3399
CR Abbasi Ahmed, 2008, ACM Transactions on Information Systems, V26, DOI 10.1145/1361684.1361685
   AlBadani B, 2022, APPL SYST INNOV, V5, DOI 10.3390/asi5010013
   [Anonymous], 2013, Learning scikit-learn: machine learning in python
   [Anonymous], 2014, SEMEVAL
   [Anonymous], 1975, ADAPTATION NATURAL A
   Aue A., 2005, P RECENT ADV NATURAL, DOI DOI 10.1111/J.1745-3992.1984.TB00758.X
   Babatunde O., 2014, Int. J. Electron. Commun. Comput. Eng, V5, P889
   BEASLEY D, 1993, U COMPUT, V15, P58
   Dadhich A, 2022, SMART INNOV SYST TEC, V235, P173, DOI 10.1007/978-981-16-2877-1_17
   Das, 2010, 1 WORKSH COMP APPR S
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Fei H, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P553, DOI 10.1145/3442381.3449789
   Feldman R, 2013, COMMUN ACM, V56, P82, DOI 10.1145/2436256.2436274
   Gautam G, 2014, INT CONF CONTEMP, P437, DOI 10.1109/IC3.2014.6897213
   Govindarajan M., 2013, International Journal of Advanced Computer Research, V3, P139
   Hady MFA., 2013, HDB NEURAL INFORM PR, P215, DOI [10.1007/978-3-642-36657-4_7, DOI 10.1007/978-3-642-36657-4_7]
   Hastie T., 2009, ELEMENTS STAT LEARNI
   Jagtap B., 2014, INT J EMERGING TREND, V3, P229
   Jian Zhu, 2010, 2010 2nd IEEE International Conference on Information Management and Engineering (ICIME 2010), P193, DOI 10.1109/ICIME.2010.5478084
   Jiang SY, 2012, EXPERT SYST APPL, V39, P1503, DOI 10.1016/j.eswa.2011.08.040
   Kennedy A, 2006, COMPUT INTELL-US, V22, P110, DOI 10.1111/j.1467-8640.2006.00277.x
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Liu FG, 2020, NEUROCOMPUTING, V371, P39, DOI 10.1016/j.neucom.2019.09.012
   Liu SM, 2015, EXPERT SYST APPL, V42, P1083, DOI 10.1016/j.eswa.2014.08.036
   Luo BH, 2016, EXPERT SYST APPL, V44, P138, DOI 10.1016/j.eswa.2015.08.023
   Matsumoto S, 2005, LECT NOTES ARTIF INT, V3518, P301
   Moraes R, 2013, EXPERT SYST APPL, V40, P621, DOI 10.1016/j.eswa.2012.07.059
   Niu T., 2016, MULTIMEDIA MODELING, P15, DOI [DOI 10.1007/978-3-319-27674-82, 10.1007/978-3-319-27674-8_2]
   Oreski S, 2014, EXPERT SYST APPL, V41, P2052, DOI 10.1016/j.eswa.2013.09.004
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Pang B., 2004, ANN M ASS COMP LING, P271, DOI [10.3115/1218955.1218990, DOI 10.3115/1218955.1218990]
   Pang B, 2005, P 43 ANN M ASS COMP, P115, DOI [10.3115/1219840.1219855, DOI 10.3115/1219840.1219855]
   Rao GZ, 2018, NEUROCOMPUTING, V308, P49, DOI 10.1016/j.neucom.2018.04.045
   Read J, 2005, Proceedings of the ACL Student Research Workshop, ACLstudent'05, P43
   Refaeilzadeh Payam., Cross-Validation
   Shinde G.K., 2021, Int. J. Res. Appl. Sci. Eng. Technol, V9, P282, DOI [10.22214/ijraset.2021.39202, DOI 10.22214/IJRASET.2021.39202]
   Tan SB, 2008, EXPERT SYST APPL, V34, P2622, DOI 10.1016/j.eswa.2007.05.028
   Tang HF, 2009, EXPERT SYST APPL, V36, P10760, DOI 10.1016/j.eswa.2009.02.063
   Tripathy A, 2017, KNOWL INF SYST, V53, P805, DOI 10.1007/s10115-017-1055-z
   Tripathy A, 2016, EXPERT SYST APPL, V57, P117, DOI 10.1016/j.eswa.2016.03.028
   Wang S, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 3, PROCEEDINGS, P435, DOI 10.1109/FSKD.2007.49
   Whitelaw C, 2005, P 14 ACM INT C INF K, P625, DOI 10.1145/1099554.1099714
   Zhang DW, 2015, EXPERT SYST APPL, V42, P1857, DOI 10.1016/j.eswa.2014.09.011
   Zhang GQP, 2000, IEEE T SYST MAN CY C, V30, P451, DOI 10.1109/5326.897072
NR 44
TC 4
Z9 4
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 7991
EP 8011
DI 10.1007/s11042-022-13047-z
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000788980000011
DA 2024-07-18
ER

PT J
AU Chen, T
   Zhang, X
   Hamann, B
   Wang, DJ
   Zhang, H
AF Chen, Tao
   Zhang, Xin
   Hamann, Bernd
   Wang, Dongjing
   Zhang, Hua
TI A multi-level feature integration network for image inpainting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image inpainting; Multi-level; Feature integration; Skip connection
AB Deep learning-based methods have shown great potential in image inpainting, especially when dealing with large missing regions. However, the inpainted results often suffer from blurring, and improper textures can be created without an understanding of semantic information. In order to extract more features from the known regions, we propose a multi-level feature integration (MFI) network for image inpainting. We complete hole regions by two generators. For each generator, we use the MFI network to fill the hole region with multi-level skip connections. With multi-level feature integration, the network gains more knowledge about the global semantic structures and local fine details. Moreover, instead of a deconvolution layer or an interpolation algorithm, we adopt a sub-pixel layer to up-sample feature maps and produce more coherent results. We use PatchGAN to support the refinement generator network to produce more discriminative detail. Our experiments done with the Paris StreetView, CelebA-HQ and Places2 datasets demonstrate the effectiveness of our MFI network for producing visually pleasing results with semantically ordered textures.
C1 [Chen, Tao; Zhang, Xin; Wang, Dongjing; Zhang, Hua] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.
   [Zhang, Xin] Hangzhou Dianzi Univ, Shangyu Inst Sci & Engn, Shaoxing 312000, Peoples R China.
   [Zhang, Xin] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
   [Hamann, Bernd] Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.
C3 Hangzhou Dianzi University; Hangzhou Dianzi University; Nanjing
   University of Science & Technology; University of California System;
   University of California Davis
RP Zhang, X (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.; Zhang, X (corresponding author), Hangzhou Dianzi Univ, Shangyu Inst Sci & Engn, Shaoxing 312000, Peoples R China.; Zhang, X (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
EM chenboluo@hdu.edu.cn; zhangxin@hdu.edu.cn; hamann@cs.ucdavis.edu;
   dongjing.wang@hdu.edu.cn; zhangh@hdu.edu.cn
RI zhou, xuan/GZA-8157-2022
FU Zhejiang Provincial Natural Science Foundation of China
FX This research was supported by Zhejiang Provincial Natural Science
   Foundation of China under Grant No.LQ21F020015 and No.LQ20F020015.
CR Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Ding D, 2019, IEEE T IMAGE PROCESS, V28, P1705, DOI 10.1109/TIP.2018.2880681
   Drozdzal M, 2016, LECT NOTES COMPUT SC, V10008, P179, DOI 10.1007/978-3-319-46976-8_19
   Fan Q, 2018, MULTIMED TOOLS APPL, V77, P10807, DOI 10.1007/s11042-017-5077-z
   Guillemot C, 2014, IEEE SIGNAL PROC MAG, V31, P127, DOI 10.1109/MSP.2013.2273004
   Guo Q, 2018, IEEE T VIS COMPUT GR, V24, P2023, DOI 10.1109/TVCG.2017.2702738
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hensel M, 2017, ADV NEUR IN, V30
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Li F, 2014, IEEE T IMAGE PROCESS, V23, P4242, DOI 10.1109/TIP.2014.2346030
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Liu HY, 2019, IEEE I CONF COMP VIS, P4169, DOI 10.1109/ICCV.2019.00427
   Liu JY, 2018, IEEE T MULTIMEDIA, V20, P3252, DOI 10.1109/TMM.2018.2831636
   Liu J, 2019, IEEE INT CON MULTI, P1168, DOI 10.1109/ICME.2019.00204
   Liu X., 2021, J KING SAUD UNIV-COM, V1, P1, DOI 10.1016/j.jksuci.2021.07.014
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lu HY, 2018, MULTIMED TOOLS APPL, V77, P5969, DOI 10.1007/s11042-017-4509-0
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Nazeri K, 2019, IEEE INT CONF COMP V, P3265, DOI 10.1109/ICCVW.2019.00408
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Ren YR, 2019, IEEE I CONF COMP VIS, P181, DOI 10.1109/ICCV.2019.00027
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shen L, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1861, DOI 10.1145/3343031.3350903
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Song Yuhang, 2018, ARXIV180503356
   Tschumperlé D, 2006, INT J COMPUT VISION, V68, P65, DOI 10.1007/s11263-006-5631-z
   Wan Z., 2021, P IEEECVF INT C COMP, P4692
   Wang N, 2021, IEEE T IMAGE PROCESS, V30, P1784, DOI 10.1109/TIP.2020.3048629
   Wang N, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107448
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Xie CH, 2019, IEEE I CONF COMP VIS, P8857, DOI 10.1109/ICCV.2019.00895
   Yaghmaee F, 2020, MULTIMED TOOLS APPL, V79, P13795, DOI 10.1007/s11042-020-08650-x
   Yan ZY, 2018, LECT NOTES COMPUT SC, V11218, P3, DOI 10.1007/978-3-030-01264-9_1
   Yang C, 2017, PROC CVPR IEEE, P4076, DOI 10.1109/CVPR.2017.434
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Yu T, 2020, AAAI CONF ARTIF INTE, V34, P12733
   Zamir AR, 2014, IEEE T PATTERN ANAL, V36, P1546, DOI 10.1109/TPAMI.2014.2299799
   Zeng YH, 2019, PROC CVPR IEEE, P1486, DOI 10.1109/CVPR.2019.00158
   Zhang J, 2014, IEEE T IMAGE PROCESS, V23, P3336, DOI 10.1109/TIP.2014.2323127
   Zhang L, 2021, MULTIMED TOOLS APPL, V80, P4607, DOI 10.1007/s11042-020-09835-0
   Zhang X, 2017, IEEE IMAGE PROC, P3785, DOI 10.1109/ICIP.2017.8296990
   Zhijiao Xiao, 2021, MultiMedia Modeling. 27th International Conference, MMM 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12572), P162, DOI 10.1007/978-3-030-67832-6_14
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhu MY, 2021, IEEE T IMAGE PROCESS, V30, P4855, DOI 10.1109/TIP.2021.3076310
NR 50
TC 1
Z9 1
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38781
EP 38802
DI 10.1007/s11042-022-13028-2
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000787666500001
DA 2024-07-18
ER

PT J
AU Rathi, RN
   Mustafi, A
AF Rathi, R. N.
   Mustafi, A.
TI Designing an efficient unigram keyword detector for documents using
   Relative Entropy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Keyword extraction; Feature extraction
ID KEYPHRASE EXTRACTION
AB In this work we propose a statistical approach to identify unigram keywords for a document. We identify unigram keywords as features which effectively captures the importance of a word in a document and evaluates its potential to be a keyword. We make use of relative entropy, displacement and variance of terms in a document have been evaluated in the context of keyword identification. The proposed approach works on single documents without the requirement of any pre-training of the model. We also evaluate the effectiveness of our features against the gold standard of "term frequency" and compare the usefulness of the proposed feature set with term frequency. The results of our proposed method are presented and compared with existing algorithms.
C1 [Rathi, R. N.; Mustafi, A.] Birla Inst Technol, Mesra, India.
C3 Birla Institute of Technology Mesra
RP Rathi, RN (corresponding author), Birla Inst Technol, Mesra, India.
EM raunakrathi.rathi@gmail.com; abhijit@bitmesra.ac.in
OI Rathi, Raunak/0000-0002-1387-4191; Mustafi, Abhijit/0000-0003-3454-0470
CR Aggarwal A, 2018, COMPUT SIST, V22, P1307, DOI [10.13053/cys-22-4-3077, 10.13053/CyS-22-4-3077]
   [Anonymous], 2016, P 2016 C EMP METH NA, DOI DOI 10.18653/V1/D16-1191
   Bafna P, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P61, DOI 10.1109/ICEEOT.2016.7754750
   Biswas SK, 2018, EXPERT SYST APPL, V97, P51, DOI 10.1016/j.eswa.2017.12.025
   Brinker K, 2010, US Patent, Patent No. [7,711,668, 7711668]
   Campos R, 2020, INFORM SCIENCES, V509, P257, DOI 10.1016/j.ins.2019.09.013
   Campos R, 2018, LECT NOTES COMPUT SC, V10772, P684, DOI 10.1007/978-3-319-76941-7_63
   Chen KW, 2016, EXPERT SYST APPL, V66, P245, DOI 10.1016/j.eswa.2016.09.009
   Chen Y, 2019, COMPUT SPEECH LANG, V57, P98, DOI 10.1016/j.csl.2019.01.007
   Chenchen Zhang, 2018, 2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS). Proceedings, P339, DOI 10.1109/ICIS.2018.8466534
   Duari S, 2019, INFORM SCIENCES, V477, P100, DOI 10.1016/j.ins.2018.10.034
   Duwairi R, 2016, J INTELL FUZZY SYST, V30, P2101, DOI 10.3233/IFS-151923
   Ercan G., 2006, Automated Text Summarization and Keyphrase Extraction
   Feduhko S, 2014, WEBOLOGY, V11
   Florescu C, 2017, AAAI CONF ARTIF INTE, P4923
   Haque Md Majharul, 2013, International Journal of Innovation and Applied Studies, V3, P121
   Korzh R, 2015, METHODS FORMING INFO
   Krapivin M, 2010, LECT NOTES COMPUT SC, V6102, P102, DOI 10.1007/978-3-642-13654-2_12
   Lahiri S, 2017, NAT LANG ENG, V23, P295, DOI 10.1017/S1351324916000231
   Li G., 2014, CCF INT C NATURAL LA, P403, DOI [10.1007/978-3-662-45924-9_36, DOI 10.1007/978-3-662-45924-9_36]
   Li Juanzi, 2007, Wuhan University Journal of Natural Sciences, V12, P917, DOI 10.1007/s11859-007-0038-4
   Li XM, 2018, INFORM PROCESS MANAG, V54, P1345, DOI 10.1016/j.ipm.2018.05.009
   Liu F., 2009, NAACL HLT 2009-Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Proceedings of the Conference, P620, DOI DOI 10.3115/1620754.1620845
   Liu Zhiyuan, 2009, P 2009 C EMP METH NA, P257, DOI DOI 10.3115/1699510.1699544
   Matsuo Y., 2004, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V13, P157, DOI 10.1142/S0218213004001466
   McMahon D., 2007, Quantum computing explained
   Mihalcea, 2005, P C INCL POST DEM TU
   Mihalcea R., 2004, P 2004 C EMPIRICAL M, P404, DOI DOI 10.3115/1219044.1219064
   Naderalvojoud B, 2020, NAT LANG ENG, V26, P31, DOI 10.1017/S1351324919000317
   Nguyen TD, 2007, LECT NOTES COMPUT SC, V4822, P317
   Rose D., 2010, TEXT MINING APPL THE, V1, P1, DOI [DOI 10.1002/9780470689646.CH1, 10.1002/9780470689646.CH1]
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Wu Yifang Brook., 2005, CIKM '05: Proceedings of the 14th ACM international conference on Information and knowledge management, New York, NY, USA, P283, DOI DOI 10.1145/1099554.1099628
NR 33
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37747
EP 37761
DI 10.1007/s11042-022-12657-x
EA APR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000786824500001
DA 2024-07-18
ER

PT J
AU Swetha, G
   Janaki, K
AF Swetha, Gadde
   Janaki, Karur
TI Cloud based secure multimedia medical data using optimized convolutional
   neural network and cryptography mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud storage; Multimedia medical data; Classification; Cryptography;
   Data security; Authentication; Encryption
ID STORAGE; PRIVACY; CLASSIFICATION; ALGORITHM
AB Cloud storage system (CSS) is a significant service of cloud computing that permits the data owner to store their data in the cloud. Though the system is efficient, the system needs to provide privacy and security to the users. This paper presents a solution for securing multimedia data in the cloud using different techniques. The major phases of the proposed system are the data classification and data authentication phases. Initially, the acquired data is classified based on its sensitivity using the proposed optimized convolutional neural network (CNN-EEO). Then, the key pair is generated and encrypted using the proposed infinite elliptic curve cryptography with Merkle hash digest algorithm (IECC-MHDA). Finally, the classified data is encrypted using the proposed Kernel Homomorphic chaos encryption algorithm (KHCEA), which is decrypted at the user end. The simulation of the proposed scheme proved its excellence against the other existing schemes in terms of major metrics.
C1 [Swetha, Gadde] Visvesvaraya Technol Univ, Rajarajeswari Coll Engn Res Ctr, Dept Comp Sci & Engn, Bengaluru, Karnataka, India.
   [Swetha, Gadde] RVR&JC Coll Engn, Dept Informat Technol, Guntur, Andhra Pradesh, India.
   [Janaki, Karur] Visvesvaraya Technol Univ, Rajarajeswari Coll Engn, Dept Comp Sci & Engn, Bengaluru, Karnataka, India.
C3 Visvesvaraya Technological University; RVR & JC College of Engineering;
   Visvesvaraya Technological University
RP Swetha, G (corresponding author), Visvesvaraya Technol Univ, Rajarajeswari Coll Engn Res Ctr, Dept Comp Sci & Engn, Bengaluru, Karnataka, India.; Swetha, G (corresponding author), RVR&JC Coll Engn, Dept Informat Technol, Guntur, Andhra Pradesh, India.
EM ursgadde@gmail.com
RI gadde, swetha/ACH-2186-2022
OI KANDASAMY, JANAKI/0000-0002-0993-2889
CR Atiewi S, 2020, IEEE ACCESS, V8, P113498, DOI 10.1109/ACCESS.2020.3002815
   BARRETT P, 1987, LECT NOTES COMPUT SC, V263, P311
   Chidambaram N, 2020, IET IMAGE PROCESS, V14, P3143, DOI 10.1049/iet-ipr.2018.5654
   Fu XB, 2018, J SYST SOFTWARE, V135, P157, DOI 10.1016/j.jss.2017.10.020
   Gomathi N, 2019, INT J ARTIF INTELL T, V28, DOI 10.1142/S021821301950009X
   Guan YG, 2018, IEEE NETWORK, V32, P106, DOI 10.1109/MNET.2018.1700250
   Gudeme JR, 2021, J AMB INTEL HUM COMP, V12, P2019, DOI 10.1007/s12652-020-02302-6
   Guo C, 2020, COMPUT SECUR, V99, DOI 10.1016/j.cose.2020.102021
   Gupta S, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106542
   Jan SU, 2020, ISSUES CHALLENGES CL
   Jayapandian N, 2017, CLUSTER COMPUT, V20, P1561, DOI 10.1007/s10586-017-0809-4
   Kavin BP, 2019, COMPUT NETW, V151, P181, DOI 10.1016/j.comnet.2019.01.032
   Kim P., 2017, MATLAB DEEP LEARNING, P121, DOI DOI 10.1007/978-1-4842-2845-6
   Kumar PR, 2018, PROCEDIA COMPUT SCI, V125, P691, DOI 10.1016/j.procs.2017.12.089
   Li JG, 2021, IEEE SYST J, V15, P577, DOI 10.1109/JSYST.2020.2978146
   Liang JW, 2021, IEEE T COMPUT, V70, P1612, DOI 10.1109/TC.2020.3020545
   Liang JW, 2021, IEEE T DEPEND SECURE, V18, P1632, DOI 10.1109/TDSC.2019.2922958
   Majhi M, 2022, MULTIMED TOOLS APPL, V81, P41545, DOI 10.1007/s11042-020-10483-7
   Masala G.L., 2018, COMPUTER NETWORK SEC, P337
   Moorthy U, 2021, J AMB INTEL HUM COMP, V12, P3527, DOI 10.1007/s12652-020-02592-w
   Morales-Sandoval M, 2018, INT J INF SECUR, V17, P441, DOI 10.1007/s10207-017-0375-z
   Namasudra S, 2020, COMPUT COMMUN, V151, P539, DOI 10.1016/j.comcom.2019.12.041
   Namasudra S, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.4364
   Ogiela U, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5557
   Pasupuleti S.K., 2020, Lightweight Ciphertext-Policy Attribute-Based Encryption Scheme for Data Privacy and Security in Cloud-assisted IoT in Real-Time Data Analytics for Large Scale Sensor Data, P97
   Pitchaiah M, 2012, IMPLEMENTATION ADV E
   Reddy KS, 2018, MATER TODAY-PROC, V5, P557
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Rostami M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-020-00398-3
   Rostami M, 2020, GENOMICS, V112, P4370, DOI 10.1016/j.ygeno.2020.07.027
   Sanjay K. R., 2019, J. Amb. Intell. Hum. Comput., V10, P1
   Schneier B., 1993, INT WORKSH FAST SOFT, P191, DOI DOI 10.1007/3-540-58108-1_24
   Seth B, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.4108
   Singh A, 2019, ADV INTELL SYST COMP, V841, P157, DOI 10.1007/978-981-13-2285-3_20
   Standard D.E., 1999, FEDERAL INFORM PROCE, P112
   Subramanian EK, 2020, CLUSTER COMPUT, V23, P3057, DOI 10.1007/s10586-020-03069-3
   Suresha K., 2020, Lecture Notes in Electrical Engineering, P231, DOI [10.1007/978-981-15-3125-5_25, DOI 10.1007/978-981-15-3125-5_25]
   Tahir M, 2021, CLUSTER COMPUT, V24, P739, DOI 10.1007/s10586-020-03157-4
   Thabit F, 2021, GLOBAL T PROCEED
   Viswanath G, 2021, EVOL INTELL, V14, P691, DOI 10.1007/s12065-020-00404-w
   Yang P, 2020, IEEE ACCESS, V8, P131723, DOI 10.1109/ACCESS.2020.3009876
   Yuan YL, 2020, IEEE ACCESS, V8, P120778, DOI 10.1109/ACCESS.2020.3006278
   Zhang YH, 2018, SOFT COMPUT, V22, P7763, DOI 10.1007/s00500-018-3435-z
   Zhang YY, 2020, DRUG DEV IND PHARM, V46, P42, DOI 10.1080/03639045.2019.1698597
NR 44
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33971
EP 34007
DI 10.1007/s11042-022-12466-2
EA APR 2022
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784679300026
DA 2024-07-18
ER

PT J
AU Hamzehi, M
   Hosseini, S
AF Hamzehi, Morteza
   Hosseini, Soodeh
TI Business intelligence using machine learning algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Business intelligence; Management dashboards; Machine learning;
   Association rules; Clustering methods
AB Business intelligence, as one of the branches of information technology, is increasingly considered by managers in today's business world. In order to make better decisions about the business process, most business organizations are very willing to use intelligent systems. Intelligence refers to the ability to pursue a goal in the human way; therefore, it can be said that the more human-like a system is, the more intelligent it is. Through learning and gaining experience or acquiring new knowledge, the intelligent system can increase its knowledge. One of the main goals of implementing business intelligence in any organization is to create reports using variety of management dashboards for effective and critical decisions based on the organization's key indicators. The present study aims to provide an efficient model for optimizing the products sales system in a pharmaceutical company using clustering methods and based on machine learning indicators and algorithms. The studied model uses RFM (Recency Frequency Monetary)-LRFM (Length Recency Frequency Monetary)-NLRFM (Number Length Recency Frequency Monetary) indices to utilize customer clustering algorithms. Also, the association rules method has been used in this study in order to show the relationship between the sold products, to analyze the customers' shopping cart, and to offer to the customers based on the obtained rules. Finally, the results are reviewed with K-mean, DBSCAN (Density-Based Spatial Clustering of Applications with Noise) and Optics algorithms. According to the obtained results, the proposed model will provide the best results using the K-means algorithm.
C1 [Hamzehi, Morteza; Hosseini, Soodeh] Shahid Bahonar Univ Kerman, Fac Math & Comp, Dept Comp Sci, Kerman, Iran.
C3 Shahid Bahonar University of Kerman (SBUK)
RP Hosseini, S (corresponding author), Shahid Bahonar Univ Kerman, Fac Math & Comp, Dept Comp Sci, Kerman, Iran.
EM mor_hamz@yahoo.com; so_hosseini@uk.ac.ir
CR Alazab M., 2020, ARXIV PREPRINT ARXIV
   Barboza F, 2017, EXPERT SYST APPL, V83, P405, DOI 10.1016/j.eswa.2017.04.006
   Bayer H., 2017, Journal of Asian Business Strategy, V7, P23, DOI DOI 10.18488/JOURNAL.1006/2017.7.1/1006.1.23
   Cheng CH, 2009, EXPERT SYST APPL, V36, P4176, DOI 10.1016/j.eswa.2008.04.003
   Cheng C, 2020, J BUS RES, V110, P95, DOI 10.1016/j.jbusres.2020.01.003
   Eghdami E, 2015, FINANC ENG SECUR MAN, P165
   Gomonova O, 2020, DEV LEARN SHARE BUIL
   Gustriansyah R., 2020, Indonesian Journal of Electrical Engineering and Computer Science, V18, P470, DOI DOI 10.11591/IJEECS.V18.I1.PP470-477
   Gutnik S., 2021, DIGITAL STRATEGIES G, P131, DOI [10.1007/978-3-030-58267-8_10, DOI 10.1007/978-3-030-58267-8_10]
   Hlavác J, 2020, PROCEEDINGS OF THE 2020 30TH INTERNATIONAL CONFERENCE CYBERNETICS & INFORMATICS (K&I '20), DOI 10.1109/ki48306.2020.9039874
   Howson, 2008, SUCCESSFUL BUSINESS, DOI [10.1021/ic50054a003, DOI 10.1021/IC50054A003]
   Kemp J, 2009, TECHNOL INNOV MANAG
   Khare N, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040692
   Masa'Deh R, 2021, INT J HOSP TOUR ADM, V22, P64, DOI 10.1080/15256480.2018.1547239
   Mashayekhi B., 2014, FINANC ACCOUNT AUDIT, V6, P147
   Mohaghar A, 2008, IT MANAGEMENT, V1, P105
   Parimala M, 2021, SOFTWARE PRACT EXPER, V51, P550, DOI 10.1002/spe.2851
   Priya RMS, 2020, COMPUT COMMUN, V160, P139, DOI 10.1016/j.comcom.2020.05.048
   Rath, 2021, INTERNET THINGS BUSI, V5, P169, DOI DOI 10.1002/9781119711148.CH10
   Reddy GT, 2020, ENSEMBLE BASED MACHI, P1
   Reddy GT, 2020, COMPUT COMMUN, V157, P64, DOI 10.1016/j.comcom.2020.04.004
   Safari G, 2018, 4 NAT C NEW TECHN EL
   Sh Nosrati, 2015, INT C MAN EC FIN SYS
   Sinaga KP, 2020, IEEE ACCESS, V8, P80716, DOI 10.1109/ACCESS.2020.2988796
   Sreesurya I, 2020, MULTIMED TOOLS APPL, V79, P35641, DOI 10.1007/s11042-020-08930-6
   Tripathi A., 2020, Prabandhan: Indian Journal of Management, V13, P35, DOI DOI 10.17010/PIJOM/2020/V13I3/151175
   Tutunea MF, 2012, PROC ECON FINANC, V3, P865, DOI 10.1016/S2212-5671(12)00242-0
   Wang MD, 2020, ANAL NAVIGATION CHAR, P220
   Whig P., 2021, INT J INTEGR ED, V2, P334128
   Zarei b., 2018, Journal of applied economics studies in iran, V7, P111
NR 30
TC 3
Z9 3
U1 5
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33233
EP 33251
DI 10.1007/s11042-022-13132-3
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784122800005
DA 2024-07-18
ER

PT J
AU Incetas, MO
   Uçar, M
   Uçar, E
   Köse, U
AF Incetas, Mursel Ozan
   Ucar, Murat
   Ucar, Emine
   Kose, Utku
TI A novel image Denoising approach using super resolution densely
   connected convolutional networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Densely connected convolutional networks; Deep learning
ID DIFFUSION; CNN
AB Image distortion effects, called noise, may occur due to various reasons such as image acquisition, transfer, and duplication. Image denoising is a preliminary step for many studies in the field of image processing. The vast majority of techniques in the literature require parameters that the user must determine according to the noise intensity. Due to the user requirement, the developed techniques become almost impossible to use by another computer system. Therefore, the Densely Connected Convolutional Networks structure-based model is proposed to remove noise from gray-level images with different noise levels in this study. With the developed approach, the obligation of the user to enter any parameters has been eliminated. For the training of the proposed method, 2200 noisy images with 11 different levels derived from the BSDS300 Train dataset (original 200 images) were used, and the success of the method was evaluated with 1100 noisy images derived from the BSDS300 Test dataset (original 100 images). The images used to evaluate the success of the proposed method were compared to both the traditional and state-of-the-art techniques. It was observed that the average SSIM / PSNR values obtained with the proposed method for the whole test dataset were 0.9236 / 33.94 at low noise level (sigma(2) = 0.001) and 0.7156 / 26.39 at high noise level (sigma(2) = 0.020). The results show that the proposed method is a very effective and efficient noise filter for image denoising.
C1 [Incetas, Mursel Ozan] Alanya Alaaddin Keykubat Univ, Dept Comp Technol, TR-07425 Antalya, Turkey.
   [Ucar, Murat; Ucar, Emine] Iskenderun Tech Univ, Dept Management Informat Syst, TR-31200 Antakya, Turkey.
   [Kose, Utku] Suleyman Demirel Univ, Dept Comp Engn, TR-32260 Isparta, Turkey.
C3 Alanya Alaaddin Keykubat University; Iskenderun Technical University;
   Suleyman Demirel University
RP Incetas, MO (corresponding author), Alanya Alaaddin Keykubat Univ, Dept Comp Technol, TR-07425 Antalya, Turkey.; Uçar, M (corresponding author), Iskenderun Tech Univ, Dept Management Informat Syst, TR-31200 Antakya, Turkey.
EM ozan.incetas@alanya.edu.tr; murat.ucar@iste.edu.tr;
   emine.ucar@iste.edu.tr; utkukose@sdu.edu.tr
RI Kose, Utku/C-8683-2009; UÇAR, Murat/AFT-1801-2022
OI Kose, Utku/0000-0002-9652-6415; UÇAR, Murat/0000-0001-9997-4267
CR Aljadaany R, 2019, LECT NOTES COMPUT SC, V11662, P3, DOI 10.1007/978-3-030-27202-9_1
   Alsaiari A, 2019, 2019 IEEE 2ND INTERNATIONAL CONFERENCE ON INFORMATION AND COMPUTER TECHNOLOGIES (ICICT), P126, DOI [10.1109/INFOCT.2019.8710893, 10.1109/infoct.2019.8710893]
   Benesty J, 2010, INT CONF ACOUST SPEE, P205, DOI 10.1109/ICASSP.2010.5496033
   Burger H., 2012, CVPR
   CHARBONNIER P, 1994, IEEE IMAGE PROC, P168
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Divakar N, 2017, IEEE COMPUT SOC CONF, P1076, DOI 10.1109/CVPRW.2017.145
   Diwakar M, 2020, MULTIMED TOOLS APPL, V79, P14449, DOI 10.1007/s11042-018-6897-1
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   El Helou M, 2020, IEEE T IMAGE PROCESS, V29, P4885, DOI 10.1109/TIP.2020.2976814
   Fan LW, 2019, VIS COMPUT IND BIOME, V2, DOI 10.1186/s42492-019-0016-7
   Gonzalez R.C., 2002, DIGITAL IMAGE PROCES, P793
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Harmeling M, 2016, P 10 INT C INTELLIGE
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Incetaș M. O., 2017, Yunus Araștirma BultenI, V17, P283
   Incetas MO., 2019, J ENGIN SCI DESIGN, V7, P725
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Jain V., 2009, ADV NEURAL INFORM PR, P769, DOI DOI 10.5555/2981780.2981876
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Kostopoulos SA, 2017, MAGN RESON IMAGING, V35, P39, DOI 10.1016/j.mri.2016.08.007
   Li XX, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102774
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Muhammad N, 2020, MULTIMED TOOLS APPL, V79, P26327, DOI 10.1007/s11042-020-09158-0
   Nadeem M, 2019, MULTIMED TOOLS APPL, V78, P18531, DOI 10.1007/s11042-019-7221-4
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pitas I., 2013, The Springer International Series in Engineering and Computer Science
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Quan YH, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107639
   Rafsanjani HK, 2017, DIGIT SIGNAL PROCESS, V64, P71, DOI 10.1016/j.dsp.2017.02.004
   Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6
   Savkare S.S., 2016, Proceedings of the Third International Symposium on Computer Vision and the Internet, P8, DOI DOI 10.1145/2983402
   Shi WZ, 2019, SIGNAL PROCESS-IMAGE, V76, P243, DOI 10.1016/j.image.2019.05.007
   Singh R, 2015, INT JOURNALL SCI TEC, V04, P336
   Tanyeri U, 2018, ADV ELECTR COMPUT EN, V18, P99, DOI 10.4316/AECE.2018.04012
   Tian CW, 2021, KNOWL-BASED SYST, V226, DOI 10.1016/j.knosys.2021.106949
   Tian CW, 2020, NEURAL NETWORKS, V121, P461, DOI 10.1016/j.neunet.2019.08.022
   Tian CW, 2019, CAAI T INTELL TECHNO, V4, P17, DOI 10.1049/trit.2018.1054
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Valsesia D, 2020, IEEE T IMAGE PROCESS, V29, P8226, DOI 10.1109/TIP.2020.3013166
   van der Walt S, 2014, PEERJ, V2, DOI 10.7717/peerj.453
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
   YANG RK, 1995, IEEE T SIGNAL PROCES, V43, P591, DOI 10.1109/78.370615
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang L, 2019, APPL SOFT COMPUT, V83, DOI 10.1016/j.asoc.2019.105603
   Zhong Y, 2020, MULTIMED TOOLS APPL, V79, P16517, DOI 10.1007/s11042-019-7556-x
NR 53
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33291
EP 33309
DI 10.1007/s11042-022-13096-4
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784122800007
DA 2024-07-18
ER

PT J
AU Chung, KL
   Chen, SN
AF Chung, Kuo-Liang
   Chen, Szu-Ni
TI An effective bilinear interpolation-based iterative chroma subsampling
   method for color images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bayer color filter array (CFA) image; Chroma subsampling; Convex
   block-distortion function; Digital time delay integration CFA image;
   Quality-bitrate tradeoff; Quality enhancement; RGB full-color image
AB Prior to encoding a color image, such as the RGB full-color image I-RGB, the Bayer color filter array (CFA) image I-Bayer, or the digital time delay integration CFA image I-DTDI, performing chroma subsampling on the converted chroma image is a necessary step. Previously, several chroma subsampling methods were developed for I-RGB, I-Bayer, and I-DTDI independently. In this paper, we propose an effective bilinear interpolation-based iterative chroma subsampling method for the considered three image types simultaneously, achieving better reconstructed images. Based on the considered three types of images collected from the Kodak, IMAX, and SCI (screen content images), the comprehensive experimental results demonstrated that under the versatile video coding (VVC) platform, our chroma subsampling method achieves the best quality and quality-bitrate tradeoff of the reconstructed color images when compared with the existing chroma subsampling methods.
C1 [Chung, Kuo-Liang; Chen, Szu-Ni] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Sect 4,Keelung Rd, Taipei 10672, Taiwan.
C3 National Taiwan University of Science & Technology
RP Chung, KL (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Sect 4,Keelung Rd, Taipei 10672, Taiwan.
EM klchung01@gmail.com
FU Ministry of Science and Technology, Taiwan [MOST-107-2221-E-011-108-MY3,
   MOST-108-2221-E-011-077-MY3]
FX This work was supported by the contracts MOST-107-2221-E-011-108-MY3 and
   MOST-108-2221-E-011-077-MY3 of the Ministry of Science and Technology,
   Taiwan. The authors appreciate the valuable comments of the three
   anonymous referees and the proofreading help of Ms. C. Harrington to
   improve the manuscript.
CR Allebach J, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P707, DOI 10.1109/ICIP.1996.560768
   [Anonymous], 2021, SCI IMAGE DATABASE
   Babu C, 2020, NEURAL COMPUT APPL, V32, P6353, DOI 10.1007/s00521-019-04143-7
   Bayer B. E., 1976, U.S. patent, Patent No. 3,971,065
   Bjontegaard G, 2001, VCEGM33
   Bodenstorfer E, 2007, PROC SPIE, V6496, DOI 10.1117/12.704516
   Chen H, 2009, IEEE T CIRC SYST VID, V19, P1891, DOI 10.1109/TCSVT.2009.2031370
   Chung KL, 2019, IEEE T CIRC SYST VID, V29, P3281, DOI 10.1109/TCSVT.2018.2879095
   Chung KL, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3586799
   Datta B.N., 1995, Numerical Linear Algebra and Applications
   Eastman Kodak Company, 2014, KOD DAT
   ITU-R, 2011, BT6015 ITUR
   ITU-T Video Coding Experts Group and the ISO/IEC Moving Picture Experts Group, 2020, VTM 8 0
   Kiku D, 2013, IEEE IMAGE PROC, P2304, DOI 10.1109/ICIP.2013.6738475
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Li X, 2008, PROC SPIE, V6822, DOI 10.1117/12.766768
   Lin CH, 2016, IEEE T CIRC SYST VID, V26, P1722, DOI 10.1109/TCSVT.2015.2472118
   Lin TL, 2020, IEEE T CIRC SYST VID, V30, P3167, DOI 10.1109/TCSVT.2019.2939280
   Lu Y, 2011, IEEE MULTIMEDIA, V18, P4, DOI 10.1109/MMUL.2011.33
   Lukac R, 2005, IEEE T CONSUM ELECTR, V51, P1260, DOI 10.1109/TCE.2005.1561853
   Ni ZK, 2020, IEEE T IMAGE PROCESS, V29, P4952, DOI 10.1109/TIP.2020.2975978
   Ridge J, 2007, JOINT VIDEO TEAM JVT
   Tan DS, 2018, IEEE T IMAGE PROCESS, V27, P2408, DOI 10.1109/TIP.2018.2803341
   Wang SQ, 2016, IEEE T CIRC SYST VID, V26, P1595, DOI 10.1109/TCSVT.2015.2461891
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yi-Chieh Yu, 2017, 2017 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), P163, DOI 10.1109/ICCE-China.2017.7991046
   Zhang L, 2014, IMAX DATASET
   [张黎明 ZHANG Liming], 2011, [生态环境学报, Ecology and Environmental Sciences], V20, P1
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang YB, 2011, IEEE T IMAGE PROCESS, V20, P3291, DOI 10.1109/TIP.2011.2158226
NR 30
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32191
EP 32213
DI 10.1007/s11042-022-12743-0
EA APR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781941600007
DA 2024-07-18
ER

PT J
AU Laddha, S
   Kumar, V
AF Laddha, Saloni
   Kumar, Vijay
TI DGCNN: deep convolutional generative adversarial network based
   convolutional neural network for diagnosis of COVID-19
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chest X-ray; Generative adversarial network; COVID-19; Convolutional
   neural network; Data augmentation
ID CLASSIFICATION; AUGMENTATION; GAN
AB The latest threat to global health is the coronavirus disease 2019 (COVID-19) pandemic. To prevent COVID-19, recognizing and isolating the infected patients is an essential step. The primary diagnosis method is Reverse Transcription Polymerase Chain Reaction (RT-PCR) test. However, the sensitivity of this test is not satisfactory to successfully control the COVID-19 outbreak. Although there exist many datasets of chest X-rays (CXR) images, but few COVID-19 CXRs are presently accessible owing to privacy of patients. Thus, many researehers have utilized data augmentation techniques to augment the datasets. But, it may cause over-fitting issues, as the existing data augmentation techniques include small modifications to CXRs. Therefore, in this paper. an efficient deep convolutional generative adversarial network and convolutional neural network (DGCNN) is designed to diagnose COVID-19 suspected subjects. Deep convolutional generative adversarial network (DGAN) consists of two networks trained adversarially such that one generates fake images and the other differentiates between them. Thereafter, convolutional neural network (CNN) is utilized for classification purpose. Extensive experiments are conducted to evaluate the performance of the proposed DGCNN. Performance analysis demonstrates that DGCNN can highly improves the diagnosis performance.
C1 [Laddha, Saloni; Kumar, Vijay] Natl Inst Technol, Comp Sci & Engn, Hamirpur, Himachal Prades, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur
RP Kumar, V (corresponding author), Natl Inst Technol, Comp Sci & Engn, Hamirpur, Himachal Prades, India.
EM vijaykumarchahar@gmail.com
RI Chahar, Vijay Kumar/A-2782-2015
OI Chahar, Vijay Kumar/0000-0002-3460-6989
CR Acar E, 2021, NEURAL COMPUT APPL, V33, P17589, DOI 10.1007/s00521-021-06344-5
   Al-Shargabi AA, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11167174
   [Anonymous], Transfer learning for computer vison tutorial
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Beers A, 2018, HIGH RESOLUTION MED
   Chen XY, 2021, NEUROCOMPUTING, V428, P332, DOI 10.1016/j.neucom.2020.03.120
   DeGrave Alex J, 2020, medRxiv, DOI 10.1101/2020.09.13.20193565
   Erol B, 2020, IEEE T AERO ELEC SYS, V56, P3197, DOI 10.1109/TAES.2020.2969579
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   Gonog L, 2019, C IND ELECT APPL, P505, DOI [10.1109/ICIEA.2019.8833686, 10.1109/iciea.2019.8833686]
   Hanlin Chen, 2019, 2019 IEEE International Conference on Power, Intelligent Computing and Systems (ICPICS). Proceedings, P300
   Hemdan E. E.- D., 2020, . arXiv preprint arXiv:2003.11055
   Motamed S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-87994-2
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   Ng MY, 2020, RADIOL-CARDIOTHORAC, V2, DOI 10.1148/ryct.2020200034
   Radford A., 2015, ARXIV
   Rubin M, 2019, MED IMAGE ANAL, V57, P176, DOI 10.1016/j.media.2019.06.014
   Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12
   Sethy PK, 2020, INT J MATH ENG MANAG, V5, P643, DOI 10.33889/IJMEMS.2020.5.4.052
   Sharma A, 2020, INT J BIOMED IMAGING, V2020, DOI 10.1155/2020/8889023
   Shi GH, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105611
   Vaya m, 2020, BIMCV COVID 19 LARGE
   Waheed A, 2020, IEEE ACCESS, V8, P91916, DOI 10.1109/ACCESS.2020.2994762
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   Yoon, 2020, ARXIV PREPRINT ARXIV
   Zhao DF, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10100519
NR 26
TC 3
Z9 3
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31201
EP 31218
DI 10.1007/s11042-022-12640-6
EA APR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781336500011
PM 35431606
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Gan, ZY
   Yu, Y
   Luo, M
AF Gan, Zhen-ye
   Yu, Yue
   Luo, Min
TI A tibetan-dependent speaker recognition method based on deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Residual network; Speaker verification; Speech
   recognition
AB For the text content is known, the semantic information and speaker characteristics in the speech signal can be used for speech recognition and speaker verification respectively in text prompt speaker recognition, which solves the problem of forged recordings in the process of text association. In practical applications, by combining speech recognition and speaker recognition technologies, a double verification effect can be achieved, which also can effectively improve security. There are few studies on the combination of speaker recognition and speech recognition in Tibetan, mainly using non-end-to-end methods, and the performance of the model is not ideal. Based on the original research, this paper uses the mainstream end-to-end method to study the speaker verification part. The network model uses ResNet-34 and ResNet-50, and fine-tuned them. "Open set" speaker verification is essentially metric learning. The ideal embedding is to compress the frame-level features into a compact speech-level representation, thereby maximizing the inter-class distance and minimizing the intra-class distance. For the loss function, we use three classification objective loss functions and three metric learning objective loss functions to extensively evaluate the performance of the model. In order to further improve the performance of the model, we fused the two loss functions of Softmax and Angular Prototype. The experimental results show that the effect of Fast ResNet-50 is better than that of Fast ResNet-34, and the model effect of the Angular Prototype loss function is better than other single loss functions. The model with the fused loss function has the best performance, with an equal error rate of 4.25%.
C1 [Gan, Zhen-ye; Yu, Yue; Luo, Min] Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
   [Gan, Zhen-ye; Yu, Yue] Northwest Normal Univ, Engn Res Ctr Gansu Prov Intelligent Informat Tech, Lanzhou 730070, Peoples R China.
C3 Northwest Normal University - China; Northwest Normal University - China
RP Gan, ZY (corresponding author), Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.; Gan, ZY (corresponding author), Northwest Normal Univ, Engn Res Ctr Gansu Prov Intelligent Informat Tech, Lanzhou 730070, Peoples R China.
EM ganzy@nwnu.edu.cn; 835055664@qq.com; 1343966912@qq.com
CR Abdel-Hamid O, 2012, INT CONF ACOUST SPEE, P4277, DOI 10.1109/ICASSP.2012.6288864
   Cai W., 2018, ARXIV180405160, P74
   Campbell WM, 2006, IEEE SIGNAL PROC LET, V13, P308, DOI 10.1109/LSP.2006.870086
   Chen NX, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P185
   Chung J. S., 2020, SPEAKER ODYSSEY, P349, DOI DOI 10.21437/ODYSSEY.2020-49
   Chung JS, 2020, INTERSPEECH, P2977, DOI 10.21437/Interspeech.2020-1064
   Chung JS, 2018, INTERSPEECH, P1086
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Gan Z., 2020, J PHYS C SERIES, V1693
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Heo, 2020, ARXIV PREPRINT ARXIV
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Jian Wang, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2612, DOI 10.1109/ICCV.2017.283
   Kenny P, 2007, IEEE T AUDIO SPEECH, V15, P1435, DOI 10.1109/TASL.2006.881693
   Li CJ, 2018, DESIGN CODE CRYPTOGR, V86, P2261, DOI 10.1007/s10623-017-0447-0
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Luo RL, 2012, 2012 IEEE FIFTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P641, DOI 10.1109/ICACI.2012.6463244
   Nagrani A, 2017, INTERSPEECH, P2616, DOI 10.21437/Interspeech.2017-950
   Okabel K, 2018, INTERSPEECH, P2252, DOI 10.21437/Interspeech.2018-993
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Snell J, 2017, ADV NEUR IN, V30
   Snyder David, 2018, 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5329, DOI 10.1109/ICASSP.2018.8461375
   Snyder D, 2017, INTERSPEECH, P999, DOI 10.21437/Interspeech.2017-620
   Variani Ehsan, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4052, DOI 10.1109/ICASSP.2014.6854363
   WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701
   Wan L, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4879, DOI 10.1109/ICASSP.2018.8462665
   Wang F, 2018, IEEE SIGNAL PROC LET, V25, P926, DOI 10.1109/LSP.2018.2822810
   Zhang CL, 2017, INTERSPEECH, P1487, DOI 10.21437/Interspeech.2017-1608
NR 29
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30821
EP 30840
DI 10.1007/s11042-022-12540-9
EA APR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779233200001
DA 2024-07-18
ER

PT J
AU Pokharel, M
   Alsadoon, A
   Nguyen, TQV
   Al-Dala'in, T
   Pham, DTH
   Prasad, PWC
   Mai, H
AF Pokharel, Monima
   Alsadoon, Abeer
   Tran Quoc Vinh Nguyen
   Al-Dala'in, Thair
   Duong Thu Hang Pham
   Prasad, P. W. C.
   Ha Thi Mai
TI Deep learning for predicting the onset of type 2 diabetes: enhanced
   ensemble classifier using modified t-SNE
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Prediction of type 2 diabetes mellitus; Wide and deep learning;
   t-distributed Stochastic Neighbor Embedding (t-SNE); Embedding;
   Overfitting; Dimension reduction
AB Several methods have been used for detecting Type 2 diabetes mellitus (T2DM), but deep learning has not been successfully used to predict T2DM due to the low accuracy and performance. Using a traditional method like the synthetic minority over-sampling technique (SMOTE) affects the system's accuracy. This study proposed an enhanced embedding technique that aims to increase the accuracy of predicting T2DM with minimum error. The proposed system uses the t-distributed Stochastic Neighbor Embedding (t-SNE), which visualizes the high dimension data with imbalanced and insufficient data to improve the accuracy, sensitivity, and specificity of T2DM production. It consists of three components: Pre-processing, feature extraction and selection, and classification. Pima Indians diabetics, Polarity, and Luzhou, are three datasets used for this proposed solution. The proposed system increased the overall performance of the model. It provides an accuracy of 85.34% from 83.96%, a sensitivity of 33.06% from 31.22%, and a specificity of 97.26% from 96.00% compared to the state-of-the-art. The proposed system reduced the overfitting problem, which affects the model's accuracy. It also uses a non-linear technique for dimension reduction that is used for the visualization of high dimension datasets to deal with large, insufficient, and inconsistent datasets.
C1 [Pokharel, Monima; Alsadoon, Abeer; Al-Dala'in, Thair; Prasad, P. W. C.] Charles Sturt Univ CSU, Sch Comp Math & Engn, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.] Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.] Kent Inst Australia, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Al-Dala'in, Thair] Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
   [Tran Quoc Vinh Nguyen; Duong Thu Hang Pham; Ha Thi Mai] Univ Da Nang, Univ Sci & Educ, Fac Informat Technol, Da Nang, Vietnam.
C3 Charles Sturt University; Western Sydney University; University of
   Danang
RP Nguyen, TQV (corresponding author), Univ Da Nang, Univ Sci & Educ, Fac Informat Technol, Da Nang, Vietnam.
EM ntquocvinh@ued.udn.vn
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; withana,
   chandana/0000-0002-3007-687X; Nguyen, Tran Quoc Vinh/0000-0003-2281-0429
FU University of Da Nang - University of Science and Education, Vietnam
   [T2020-TD-03-BS]
FX This research is partially supported by The University of Da Nang -
   University of Science and Education, Vietnam, under the grant
   "T2020-TD-03-BS".
CR Alghamdi M, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179805
   Bernardini M, 2020, IEEE J BIOMED HEALTH, V24, P235, DOI 10.1109/JBHI.2019.2899218
   Calvert J, 2016, COMPUT BIOL MED, V75, P74, DOI 10.1016/j.compbiomed.2016.05.015
   Chan DM, 2019, J PARALLEL DISTR COM, V131, P1, DOI 10.1016/j.jpdc.2019.04.008
   Chan DM, 2018, INT SYM COMP ARCHIT, P330, DOI [10.1109/CAHPC.2018.8645912, 10.1109/SBAC-PAD.2018.00060]
   Chen JL, 2018, SENSOR ACTUAT A-PHYS, V284, P52, DOI 10.1016/j.sna.2018.10.021
   Fang X, 2019, SOFT COMPUT, V23, P5645, DOI 10.1007/s00500-018-3221-y
   Houri O, 2020, AM J OBSTET GYNECOL, V222, pS228
   Huang JL, 2017, MACH LEARN, V106, P337, DOI 10.1007/s10994-016-5608-2
   Joshi RD, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18147346
   Li F, 2015, IEEE GEOSCI REMOTE S, V12, P2486, DOI 10.1109/LGRS.2015.2487226
   Mallika GC, 2021, PROGRAM COMPUT SOFT+, V47, P402, DOI 10.1134/S0361768821050054
   Nguyen BP, 2019, COMPUT METH PROG BIO, V182, DOI 10.1016/j.cmpb.2019.105055
   Purushotham S, 2018, J BIOMED INFORM, V83, P112, DOI 10.1016/j.jbi.2018.04.007
   Ravaut M, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.11315
   Shafi Salliah, 2021, P INT C SMART DAT IN, DOI 10.2139/ssrn.3852590
   Song WJ, 2019, MULTIMED TOOLS APPL, V78, P4311, DOI 10.1007/s11042-018-5715-0
   Tomohide Yamada K., 2000, CURR MEDIA RES OPTIO, V36, P404, DOI [10.1080/03007995.2019.1706043, DOI 10.1080/03007995.2019.1706043]
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wei LY, 2019, BIOINFORMATICS, V35, P4272, DOI 10.1093/bioinformatics/btz246
   Wei LY, 2018, BIOINFORMATICS, V34, P4007, DOI 10.1093/bioinformatics/bty451
   Zaitcev A, 2020, IEEE J BIOMED HEALTH, V24, P2932, DOI 10.1109/JBHI.2020.2967546
   Zou Q, 2018, FRONT GENET, V9, DOI 10.3389/fgene.2018.00515
NR 23
TC 3
Z9 3
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27837
EP 27852
DI 10.1007/s11042-022-12950-9
EA MAR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000774644100008
DA 2024-07-18
ER

PT J
AU Gupta, G
   Lakhwani, K
AF Gupta, Gitanjali
   Lakhwani, Kamlesh
TI An enhanced approach to improve the encryption of big data using
   intelligent classification technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent cryptography; Cyber-security; Encryption; Cloud computing;
   Big data
ID CLOUD; SECURITY; MOBILE
AB Data is undoubtedly one of the most significant assets in the current competitive era and to ensure its value is retained, data safety emerges as a principle concern. Another technology asset is the cloud that is proficient in storing data at very little cost or even no cost at all. There are two main challenges that come with storing data in the cloud, safe storage of data and another is encryption of data with as little time and storage space as possible. These challenges have come in the way of various financial and government organizations tapping the benefits of the cloud. A two-step solution is illustrated in this research study in response to the raised issue. The initial part of this study discusses the classification of data into sensitive data and non-sensitive data. This is done to ensure that precious resources are used only to encrypt sensitive data and are not wasted on encryption data that doesn't require encryption. To implement this, a mechanism based on Convolutional Neural Network with Logistic Regression(CNN-LR) is proposed. The next phase of this research work discusses the encryption method that is mainly focused on ensuring time and space complexity while encrypting data. For this, Ellipticcurve Diffie Hellman and Shifted Adaption Homomorphism Encryption (ECDH-SAHE) has been used and for decryption of data, Elliptic-curve DiffieHellman-Shifted Adaption Homomorphism Decryption (ECDH-SAHD) has been used. The proposed approach is titled Sensitive Encrypted Storage (SES). The results from the proposed methods are highly motivating and present great efficiency and capability which shall provide new dimension to the researchers in the future.
C1 [Gupta, Gitanjali] Lovely Profess Univ, Phagwara, Punjab, India.
   [Lakhwani, Kamlesh] JECRC Univ, Jaipur, Rajasthan, India.
C3 Lovely Professional University
RP Gupta, G (corresponding author), Lovely Profess Univ, Phagwara, Punjab, India.
EM gitagupta32@gmail.com; kamlesh.lakhwani@gmail.com
OI Lakhwani, Kamlesh/0000-0002-4731-5179; Gupta,
   Gitanjali/0000-0002-2551-4660
CR Abdul-Mageed M., 2011, P 49 ANN M ASS COMPU, P587
   Almorsy M., 2011, Proceedings of the 2011 IEEE 4th International Conference on Cloud Computing (CLOUD 2011), P364, DOI 10.1109/CLOUD.2011.9
   Antonopoulos N, 2010, COMPUT COMMUN NETW S, P1, DOI 10.1007/978-1-84996-241-4
   Arora R., 2013, International Journal of Engineering Research and Applications, V3, P1922
   Balachandran L, 2017, I C SOFTWARE KNOWL I
   Benkhelifa E, 2015, PROCEDIA COMPUT SCI, V52, P1159, DOI 10.1016/j.procs.2015.05.151
   Cao DL, 2016, MULTIMED TOOLS APPL, V75, P8955, DOI 10.1007/s11042-014-2337-z
   Chauhan A, 2017, IEEE INT CONF SIG PR, P349, DOI 10.1109/ISPCC.2017.8269702
   Coppersmith D, 1996, IBM J RES DEV, V40, P253, DOI 10.1147/rd.402.0253
   Dreiseitl S, 2002, J BIOMED INFORM, V35, P352, DOI 10.1016/S1532-0464(03)00034-0
   Elliott C, 2004, IEEE SECUR PRIV, V2, P57, DOI 10.1109/MSP.2004.54
   Gardner MW, 1998, ATMOS ENVIRON, V32, P2627, DOI 10.1016/S1352-2310(97)00447-0
   Gehlot P, 2013, INT J COMPUT APPL, V70
   Gitanjali K L, 2019, NOVEL APPROACH SENSI
   Guo GD, 2003, LECT NOTES COMPUT SC, V2888, P986
   Hagge M, 2017, CONF BUS INFORM, V1, P379, DOI 10.1109/CBI.2017.68
   Han YZ, 2009, 2009 FIFTH INTERNATIONAL CONFERENCE ON SEMANTICS, KNOWLEDGE AND GRID (SKG 2009), P128, DOI 10.1109/SKG.2009.83
   Jain R, 2014, IJARCSSE
   Kalpana G, 2018, COMPUT ELECTR ENG, V65, P178, DOI 10.1016/j.compeleceng.2017.05.022
   Li YB, 2017, INFORM SCIENCES, V387, P103, DOI 10.1016/j.ins.2016.09.005
   Li Yin., 2013, International Journal of Statistics and Probability, V2, P64
   MANOJ Prabhakar D, 2013, INT J COMPUTER TREND, P1202
   Moghaddam FF, 2014, 2014 IEEE CONFERENCE ON SYSTEMS, PROCESS AND CONTROL (ICSPC 2014), P53, DOI 10.1109/SPC.2014.7086229
   Pannala NU, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (CIT), P662, DOI 10.1109/CIT.2016.107
   Pappas N., 2014, EMNLP, P455
   Port D, 2013, CONF SOFTW ENG EDUC, P99, DOI 10.1109/CSEET.2013.6595241
   Rewagad P, 2013, INT CONF COMM SYST, P437, DOI 10.1109/CSNT.2013.97
   Sachdev A, 2013, INT J COMPUT APPL, V67
   Sengupta, 2013, DESIGNING CRYPTOGRAP
   Shaikh R, 2015, PROCEDIA COMPUT SCI, V45, P493, DOI 10.1016/j.procs.2015.03.087
   Shrestha P, 2018, WISEC'18: PROCEEDINGS OF THE 11TH ACM CONFERENCE ON SECURITY & PRIVACY IN WIRELESS AND MOBILE NETWORKS, P99, DOI 10.1145/3212480.3212501
   Singh Sehra, 2013, ARXIV1308
   Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Somani Uma, 2010, 2010 1st International Conference on Parallel, Distributed and Grid Computing (PDGC 2010), P211, DOI 10.1109/PDGC.2010.5679895
   Sood SK, 2012, J NETW COMPUT APPL, V35, P1831, DOI 10.1016/j.jnca.2012.07.007
   Soutar C., 1999, ICSA GUIDE CRYPTOGRA
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   Xin Zhou, 2011, 2011 6th International Forum on Strategic Technology (IFOST 2011), P1118, DOI 10.1109/IFOST.2011.6021216
   Zardari MA, 2015, 2015 INTERNATIONAL SYMPOSIUM ON MATHEMATICAL SCIENCES AND COMPUTING RESEARCH (ISMSC), P280, DOI 10.1109/ISMSC.2015.7594066
   Zardari MA, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCOINS)
NR 40
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25171
EP 25204
DI 10.1007/s11042-022-12401-5
EA MAR 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000771882300011
DA 2024-07-18
ER

PT J
AU Sun, KY
   Liu, XY
AF Sun, Kaiyue
   Liu, Xiangyang
TI Heat method of non-uniform diffusion for computing geodesic distance on
   images and surfaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heat diffusion; Geodesic distance; Geodesic curves; Heat Method;
   Skeleton extraction; Path planning
ID EQUATIONS; CONTOURS
AB This paper presents a non-uniform heat method to calculate geodesic distance and geodesic curves on the images and surfaces. Different from the varadhan's formula-based heat method, our non-uniform heat method first finds the direction of distance increases by heat diffusion, and then recovers the geodesic distance by solving a Poisson equation. Various heat diffusion metrics obtained from different potentials and tensors, such as intensity-based metrics, gradient-based metrics, and anisotropy metrics et., describe the differences of geodesic distances in various regions. Combined with automatic geodesic segmentation technology, our heat method can be effectively and quickly applied to centerlines extraction and salient curves detection in images, skeleton extraction of shapes, and 3D path planning on surfaces. Two categories of discretization algorithms on scattered points and triangle meshes are more flexible and can often be used to more complicated cases. The algorithm is robust and simple to implement since it is based on solving a pair of standard sparse linear systems. Pre-calculation also greatly reduces time consumption and memory footprint.
C1 [Sun, Kaiyue; Liu, Xiangyang] Hohai Univ, Nanjing, Peoples R China.
C3 Hohai University
RP Sun, KY (corresponding author), Hohai Univ, Nanjing, Peoples R China.
EM sunky0708@hhu.edu.cn; liuxy@hhu.edu.cn
FU Major Project of Science and Technology of Yunnan Province
   [202002AE090010]; National Key Research and Development Program of China
   [2018YFC1508100]; Fundamental Research Funds for the Central
   Universities [2019B44914]
FX This work was supported by the Major Project of Science and Technology
   of Yunnan Province(202002AE090010), by the National Key Research and
   Development Program of China(2018YFC1508100) and by the Fundamental
   Research Funds for the Central Universities(2019B44914).
CR Belkin M, 2005, LECT NOTES COMPUT SC, V3559, P486, DOI 10.1007/11503415_33
   Bryner D, 2014, IEEE T PATTERN ANAL, V36, P998, DOI 10.1109/TPAMI.2013.199
   Crane K, 2017, COMMUN ACM, V60, P90, DOI 10.1145/3131280
   Crane K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2516971.2516977
   Hassouna, 2005, IEEE INT C IM PROC
   Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431
   Kurtek S, 2011, LECT NOTES COMPUT SC, V6801, P147, DOI 10.1007/978-3-642-22092-0_13
   Liu Y, 2012, IEEE T VIS COMPUT GR, V18, P1693, DOI 10.1109/TVCG.2011.152
   Martínez D, 2005, COMPUT GRAPH-UK, V29, P667, DOI 10.1016/j.cag.2005.08.003
   Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pêtrès C, 2007, IEEE T ROBOT, V23, P331, DOI 10.1109/TRO.2007.895057
   Peyré G, 2009, FOUND TRENDS COMPUT, V5, DOI 10.1561/0600000029
   Qian JL, 2007, SIAM J NUMER ANAL, V45, P83, DOI 10.1137/050627083
   Rouchdy Y, 2011, I S BIOMED IMAGING, P979, DOI 10.1109/ISBI.2011.5872566
   Sethian J., 1999, LEVEL SET METHODS FA
   Sethian JA, 2000, P NATL ACAD SCI USA, V97, P5699, DOI 10.1073/pnas.090060097
   Tao J, 2019, IEEE T PATTERN ANAL
   UNSWORTH J, 1979, AM J PHYS, V47, P981, DOI 10.1119/1.11601
   Van Uitert R, 2007, MED PHYS, V34, P627, DOI 10.1118/1.2409238
   VARADHAN SR, 1967, COMMUN PUR APPL MATH, V20, P431
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Yang F, 2018, AS C COMP VIS, P371
   Yang F, 2016, J MATH IMAGING VIS, V55, P210, DOI 10.1007/s10851-015-0621-9
   Zigelman G, 2002, IEEE T VIS COMPUT GR, V8, P198, DOI 10.1109/2945.998671
   Zou Q, 2014, COMPUT AIDED DESIGN, V53, P117, DOI 10.1016/j.cad.2014.04.006
NR 27
TC 0
Z9 0
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36293
EP 36308
DI 10.1007/s11042-021-11851-7
EA MAR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000770549800002
DA 2024-07-18
ER

PT J
AU Kumar, A
AF Kumar, Ashwani
TI A cloud-based buyer-seller watermarking protocol (CB-BSWP) using
   semi-trusted third party for copy deterrence and privacy preserving
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Access control; Cloud computing environment; Copy deterrence;
   Infrastructure provider; Privacy-preserving tamper resistance
ID SECURE; SCHEMES; CHALLENGES; PROTECTION; OWNERSHIP; EFFICIENT
AB Nowadays, cloud computing provides a platform infrastructure for the secure dealing of digital data, but privacy and copy control are the two important issues in it over a network. Cloud data is available to the end user and requires enormous security and privacy techniques to protect the data. Moreover, the access control mechanism with encryption-based technique protects the digital rights for participants in a transaction, but they do not protect the media from being illegally redistributed and do not restrict an authorized user to reveal their secret information this is referred to as you can access but you cannot leak. This brought out a need for controlling copy deterrence and preserving the privacy of digital media over the internet. To overlook this, we proposed a cloud-based buyer-seller watermarking protocol (CB-BSWP) with the use of a semi-trusted third party for copy deterrence and privacy-preserving in the cloud environment. The suggested scheme uses 1) a privacy homomorphism cryptosystem with Diffie-Hellman key exchange algorithm to provide an encrypted domain for the secure exchange of digital media 2) adopt robust and fair watermarking techniques to ensure high imperceptibility and robustness for the watermarked images against attacks 3) two services of cloud Infrastructure as a service (IaaS) to support virtualized computing infrastructure and Watermarking as a service (WaaS) to execute the speedy process of watermarking, this process is supported by watermarking generation and signing phase (WGSP) and watermark extraction and verifying phase reported in 4th section. 4) cloud service provider (CSP) considered as a "semi-trusted" third party to reduce the burden from the trusted third party (TTP) server and provide storage for the encrypted digital media on cloud databases, this frees content owner from not having a separate storage infrastructure. The proposed scheme encrypts the digital content by using SHA-512 algorithm with key size 512-bits to ensure that it doesn't affect computational time during the process of encryption. The suggested scheme addresses the problems of piracy tracing, anonymity, tamper resistance, non-framing, customer rights problem. The role of cloud is crucial because it reduces communication overhead, provides unlimited storage, supports the watermarking process and offers a solution for the secure distribution of end-to-end security of digital content over cloud. To check the performance of the suggested CB-BSWP protocol against common image processing attacks, we have conducted experiments in which the perceptual quality of watermarked digital media was found enhanced, resulting in a robust watermark.
C1 [Kumar, Ashwani] Sreyas Inst Engn & Technol, Dept Comp Sci & Engn AIML, Hyderabad 500068, India.
RP Kumar, A (corresponding author), Sreyas Inst Engn & Technol, Dept Comp Sci & Engn AIML, Hyderabad 500068, India.
EM ashwani.kumarcse@gmail.com
RI Kumar, Ashwani/I-3181-2013
OI Kumar, Ashwani/0000-0002-2100-900X
CR [Anonymous], 2020, WORLDS BIGGEST DATA
   [Anonymous], 2020, USC SIPI IMAGE DATAB
   Armbrust M, 2010, COMMUN ACM, V53, P50, DOI 10.1145/1721654.1721672
   Bhattacharya P, 2005, 2005 International Conference on Wireless Networks, Communications and Mobile Computing, Vols 1 and 2, P193
   Bianchi T, 2013, IEEE SIGNAL PROC MAG, V30, P87, DOI 10.1109/MSP.2012.2228342
   Bjorklund J, 2017, BUYER SELLER PROTOCO
   Boneh D., 2015, HOSTING SERVICES UNT
   Chang CC, 2010, COMPUT SECUR, V29, P269, DOI 10.1016/j.cose.2009.08.008
   Chen CL, 2015, IETE TECH REV, V32, P104, DOI 10.1080/02564602.2014.983565
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Domingo-Ferrer J, 2013, COMPUT COMMUN, V36, P542, DOI 10.1016/j.comcom.2012.12.005
   Dong XJ, 2018, INT J DIGIT CRIME FO, V10, P118, DOI 10.4018/IJDCF.2018100109
   Eslami Z, 2014, MULTIMED TOOLS APPL, V72, P2723, DOI 10.1007/s11042-013-1555-0
   Fontaine C, 2007, EURASIP J INF SECUR, DOI 10.1155/2007/13801
   Frattolillo F, 2019, J INF SECUR APPL, V47, P246, DOI 10.1016/j.jisa.2019.05.011
   Frattolillo F, 2016, ACM T WEB, V10, DOI 10.1145/2856036
   Hsu IC, 2019, CMC-COMPUT MATER CON, V61, P929, DOI 10.32604/cmc.2019.07876
   Jayashree N, 2019, CMC-COMPUT MATER CON, V58, P263, DOI 10.32604/cmc.2019.03924
   Jianquan Xie, 2012, ADV ENG FORUM, V6-7, P452
   Katzenbeisser S, 2002, PROC SPIE, V4675, P260, DOI 10.1117/12.465283
   Katzenbeisser S, 2008, IEEE T INF FOREN SEC, V3, P783, DOI 10.1109/TIFS.2008.2002939
   Khan A, 2016, J NETW COMPUT APPL, V75, P317, DOI 10.1016/j.jnca.2016.08.026
   Kumar A, 2019, INT J CLOUD APPL COM, V9, P22, DOI 10.4018/IJCAC.2019070102
   Kumar A, 2017, PERTANIKA J SCI TECH, V25, P57
   Lei CL, 2004, IEEE T IMAGE PROCESS, V13, P1618, DOI 10.1109/TIP.2004.837553
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Liu K., 2017, SECUR COMM NETWORKS, V2017
   Liu K.J. R., 2005, MULTIMEDIA FINGERPRI
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Memon N, 2001, IEEE T IMAGE PROCESS, V10, P643, DOI 10.1109/83.913598
   Mintzer F, 1999, INT CONF ACOUST SPEE, P2067, DOI 10.1109/ICASSP.1999.758338
   Mukwevho MA, 2021, IEEE T SERV COMPUT, V14, P589, DOI 10.1109/TSC.2018.2816644
   Munadi K, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1052-1
   Naz F, 2020, MULTIMED TOOLS APPL, V79, P16051, DOI 10.1007/s11042-018-7074-2
   Pan W, 2018, COMPUT METH PROG BIO, V160, P119, DOI 10.1016/j.cmpb.2018.03.011
   Pass R, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P207, DOI 10.1145/2810103.2813713
   Peng YJ, 2017, 2017 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTED, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI)
   Qiao LT, 1998, J VIS COMMUN IMAGE R, V9, P194, DOI 10.1006/jvci.1998.0391
   Ren K, 2012, IEEE INTERNET COMPUT, V16, P69, DOI 10.1109/MIC.2012.14
   Rivest Ronald L., 1978, Found. Secure Comput., V4, P169
   Shao MH, 2007, LECT NOTES COMPUT SC, V4657, P44
   Terelius B, 2013, IEEE INT WORKS INFOR, P197, DOI 10.1109/WIFS.2013.6707818
   Trappe W, 2003, IEEE T SIGNAL PROCES, V51, P1069, DOI 10.1109/TSP.2003.809378
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xiong LZ, 2019, MULTIMED TOOLS APPL, V78, P30297, DOI 10.1007/s11042-018-6981-6
   Yu ZW, 2012, SOFTWARE PRACT EXPER, V42, P409, DOI 10.1002/spe.1088
   Zeng P, 2011, COMPUT ELECTR ENG, V37, P526, DOI 10.1016/j.compeleceng.2011.04.014
   Zhang J., 2006, IEE Proceedings-Information Security, V153, P15, DOI 10.1049/ip-ifs:20055069
   Zhang K, 2014, IEEE COMMUN MAG, V52, P58, DOI 10.1109/MCOM.2014.6766086
   Zhang L, 2018, IEEE ACCESS, V6, P75545, DOI [10.1109/ACCESS.2018.2873617, 10.1109/TCBB.2018.2848633]
   Zhang XR, 2020, CMC-COMPUT MATER CON, V64, P1435, DOI 10.32604/cmc.2020.011359
   Zheng YF, 2017, IEEE T INF FOREN SEC, V12, P1285, DOI 10.1109/TIFS.2017.2656824
   Zheng YF, 2017, IEEE T MULTIMEDIA, V19, P251, DOI 10.1109/TMM.2016.2612760
   Zhu JZ, 2010, HANDBOOK OF CLOUD COMPUTING, P21, DOI 10.1007/978-1-4419-6524-0_2
NR 57
TC 12
Z9 12
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21417
EP 21448
DI 10.1007/s11042-022-12550-7
EA MAR 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000769297700006
PM 35310887
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Paul, A
   Kandar, S
   Dhara, BC
AF Paul, Aakash
   Kandar, Shyamalendu
   Dhara, Bibhas Chandra
TI Boolean operation based lossless threshold secret image sharing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret image sharing; Threshold secret image sharing; Image encryption;
   Boolean operation; Bitwise OR operation
ID SHADOW SIZE; SCHEME; GRAYSCALE; CHAOS
AB Secret image sharing is a security technique which plays its role in multi-user environment. Secret image sharing using binary operation is a fast and lightweight technique but partial information leakage from the shares or less than threshold number of shares is the main disadvantage; to prevent which image encryption is adopted as a preprocessing step. This invites the burden of securely sending encryption key to get the image decrypted. In this paper, a lossless threshold secret image sharing using bitwise OR operation is proposed. As a preprocessing step the secret image is encrypted using chaotic logistic map taking information entropy as the key. The important advancement of the technique is that the encryption key need not required to be transmitted to the combiner side. Experimental results produce noise like image and MSE and PSNR value of the shares say in support of that. NPCR value found by comparing the retrieved image from less than threshold number of shares with the test image is more than 99%, and this signify no visual similarity with the original image. Comparative analysis with some state of the art techniques provides the proposed method a platform in secret image sharing.
C1 [Paul, Aakash; Kandar, Shyamalendu] Indian Inst Engn Sci & Technol, Dept Informat Technol, Sibpur, India.
   [Dhara, Bibhas Chandra] Jadavpur Univ, Dept Informat Technol, Saltlake Campus, Kolkata, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST);
   Jadavpur University
RP Kandar, S (corresponding author), Indian Inst Engn Sci & Technol, Dept Informat Technol, Sibpur, India.
EM aakash18iiest@gmail.com; shyamalenduk@it.iiests.ac.in; bcdhara@gmail.com
CR [Anonymous], 2009, 2009 INT C APPL INF
   Anwar S, 2019, MULTIMED TOOLS APPL, V78, P27569, DOI 10.1007/s11042-019-07852-2
   Arab A, 2019, J SUPERCOMPUT, V75, P6663, DOI 10.1007/s11227-019-02878-7
   ASMUTH C, 1983, IEEE T INFORM THEORY, V29, P208, DOI 10.1109/TIT.1983.1056651
   Bai L, 2006, DASC 2006: 2ND IEEE INTERNATIONAL SYMPOSIUM ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, PROCEEDINGS, P31
   Bhattacharjee T, 2017, J INF SECUR APPL, V33, P16, DOI 10.1016/j.jisa.2017.01.001
   Biswas P., 2017, PROC 6 INT C SOFTW C, P112
   Biswas P, 2020, MULTIMED TOOLS APPL, V79, P31715, DOI 10.1007/s11042-020-09497-y
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Blesswin AJ, 2013, INT CONF ADV COMPU, P560, DOI 10.1109/ICoAC.2013.6922012
   Chen YC, 2018, MULTIMED TOOLS APPL, V77, P27107, DOI 10.1007/s11042-018-5908-6
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   Deepa AK, 2014, INT CONF SIGN PROCES, P653, DOI 10.1109/ICOSP.2014.7015084
   Deshmukh M, 2019, KNOWL INF SYST, V60, P1377, DOI 10.1007/s10115-018-1268-9
   Dhiman K, 2018, COMPUT ELECTR ENG, V70, P647, DOI 10.1016/j.compeleceng.2017.09.017
   Dong L, 2012, SCI CHINA INFORM SCI, V55, P1151, DOI 10.1007/s11432-011-4302-z
   Gong LH, 2019, OPT LASER ENG, V121, P169, DOI 10.1016/j.optlaseng.2019.03.006
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Ji YD, 2018, COMMUN NONLINEAR SCI, V57, P352, DOI 10.1016/j.cnsns.2017.10.009
   Kalubandi VKP, 2016, PROCEEDINGS ON 2016 2ND INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P808, DOI 10.1109/NGCT.2016.7877521
   Kandar S, 2019, J INF SECUR APPL, V44, P117, DOI 10.1016/j.jisa.2018.12.003
   Kannojia SP, 2021, MULTIMED TOOLS APPL, V80, P14609, DOI 10.1007/s11042-020-10352-3
   Khalil N, 2021, OPT LASER TECHNOL, V143, DOI 10.1016/j.optlastec.2021.107326
   Koikara R., 2016, INT C SEC MAN SAM 16, P318
   Le THN, 2011, DIGIT SIGNAL PROCESS, V21, P734, DOI 10.1016/j.dsp.2011.07.004
   Li XS, 2020, MULTIMED TOOLS APPL, V79, P453, DOI 10.1007/s11042-019-08077-z
   Lin CS, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9060612
   Lin YY, 2010, IEEE SIGNAL PROC LET, V17, P316, DOI 10.1109/LSP.2009.2038113
   Liu YX, 2018, SIGNAL PROCESS-IMAGE, V66, P77, DOI 10.1016/j.image.2018.05.004
   Liu YX, 2014, SECUR COMMUN NETW, V7, P2237, DOI 10.1002/sec.930
   Loukhaoukha K, 2012, J ELECTR COMPUT ENG, V2012, DOI 10.1155/2012/173931
   Merabet NEA, 2018, INF SECUR J, V27, P14, DOI 10.1080/19393555.2018.1423712
   Nag A, 2014, CYBERN INF TECHNOL, V14, P98, DOI 10.2478/cait-2014-0023
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Patel T, 2016, 2016 INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT), VOL 2, P17
   Patro KAK, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102470
   Prasetyo H, 2019, 2019 INTERNATIONAL SYMPOSIUM ON ELECTRONICS AND SMART DEVICES (ISESD 2019), DOI [10.1109/isesd.2019.8909613, 10.1109/ispacs48206.2019.8986253, 10.1109/ICITAET47105.2019.9170223]
   Prasetyo H, 2019, MULTIMED TOOLS APPL, V78, P24837, DOI 10.1007/s11042-019-7710-5
   Roy R, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2072, DOI 10.1109/ICACCI.2015.7275922
   Shakir HR, 2019, MULTIMED TOOLS APPL, V78, P26073, DOI 10.1007/s11042-019-07766-z
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Thomas Sandhya Anne, 2020, Emerging Trends in Photonics, Signal Processing and Communication Engineering. Proceedings of ICPSPCT 2018. Lecture Notes in Electrical Engineering (LNEE 649), P99, DOI 10.1007/978-981-15-3477-5_13
   Tso HK, 2008, OPT ENG, V47, DOI 10.1117/1.2955502
   Verma M, 2017, CYBERN INF TECHNOL, V17, P134, DOI 10.1515/cait-2017-0022
   Verma M, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1145, DOI 10.1109/CCAA.2016.7813889
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang Q, 2018, OPT COMMUN, V415, P56, DOI 10.1016/j.optcom.2018.01.018
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Wang RZ, 2010, J VIS COMMUN IMAGE R, V21, P751, DOI 10.1016/j.jvcir.2010.06.001
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
   Xiong LZ, 2021, SIGNAL PROCESS, V185, DOI 10.1016/j.sigpro.2021.108064
   Yan XH, 2017, LECT NOTES COMPUT SC, V10603, P433, DOI 10.1007/978-3-319-68542-7_36
   Yang CN, 2011, J SYST SOFTWARE, V84, P1726, DOI 10.1016/j.jss.2011.05.008
   Yang CN, 2010, OPT COMMUN, V283, P1750, DOI 10.1016/j.optcom.2009.12.077
   Zhou ZL, 2018, IEEE ACCESS, V6, P15021, DOI 10.1109/ACCESS.2018.2811722
NR 56
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 35293
EP 35316
DI 10.1007/s11042-022-12320-5
EA MAR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000770061500007
DA 2024-07-18
ER

PT J
AU Hou, J
   Gao, T
AF Hou, Jie
   Gao, Terry
TI A method of shear line detection in vector fields based on descriptive
   statistics of circular data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shear line detection; Flow field pattern classification; Circular data;
   Kurtosis
ID IDENTIFICATION; VORTICES; PATTERNS
AB In the intelligent weather forecast business, the detection of shear line systems in 2-D numerical wind fields is a critical research topic for analysis and predict severe convective weather intelligently. However, the actual wind field is quite complicated, which contains more than ten types of wind field patterns and random noise, which brings challenges to the identification of the shear line. In this paper, a kurtosis based descriptive statistic of circular data was proposed to detect shear pattern from other types of flow patterns. In the experimental part, the classification characteristics of descriptive statistics were analyzed qualitatively and quantitatively in ten types of simulated flow patterns, which verified the identify advantage of kurtosis on the shear field. Finally, a shear line detection algorithm based on kurtosis is designed to applying to the actual wind field, and it has the advantage of global detection, better robustness, and faster execution.
C1 [Hou, Jie] Guangdong Med Univ, Sch Biomed Engn, Dongguan 523808, Peoples R China.
   [Gao, Terry] Counties Manukau Hlth, Auckland 1640, New Zealand.
C3 Guangdong Medical University
RP Gao, T (corresponding author), Counties Manukau Hlth, Auckland 1640, New Zealand.
EM houjie_82@126.com; terrygao366@gmail.com
FU Research Fund for Doctor of Guangdong Medical University [GDMUB2020010]
FX This work was supported by the Research Fund for Doctor of Guangdong
   Medical University (GDMUB2020010).
CR Basha Syed Muzamil, 2019, International Journal of Business Innovation and Research, V20, P375
   Basha SM, 2019, MULTIMED TOOLS APPL, V78, P29463, DOI 10.1007/s11042-018-7093-z
   Berens P, 2009, J STAT SOFTW, V31, P1, DOI 10.18637/jss.v031.i10
   Cremers J, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02040
   Ebling J, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P193, DOI 10.1109/VISUAL.2003.1250372
   ELAOUNI A, 2019, CHAOS, V29
   Epps B., 2017, P 55 AIAA AER SCI M, DOI DOI 10.2514/6.2017-0989
   Fisher N. I., 1993, STAT ANAL CIRCULAR D, DOI DOI 10.1017/CBO9780511564345
   [高嵩 Gao Song], 2017, [应用气象学报, Journal of Applied Meteorolgical Science], V28, P513
   Günther T, 2018, COMPUT GRAPH FORUM, V37, P149, DOI 10.1111/cgf.13319
   Haller G, 2021, J FLUID MECH, V908, DOI 10.1017/jfm.2020.937
   Ho SS, 2012, INT C PATT RECOG, P2643
   Holmen V., 2012, Methods for vortex identification
   Hou J, 2018, 2018 13TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P704, DOI 10.1109/WCICA.2018.8630549
   Hou J, 2017, MULTIMED TOOLS APPL, V76, P14617, DOI 10.1007/s11042-016-3812-5
   Hou J, 2017, J ATMOS OCEAN TECH, V34, P101, DOI 10.1175/JTECH-D-15-0197.1
   Huang Y, 2017, ATMOSPHERE-BASEL, V8, DOI 10.3390/atmos8070121
   Kida S, 1998, EUR J MECH B-FLUID, V17, P471, DOI 10.1016/S0997-7546(98)80005-8
   Kubiak T, 2007, EUR J PSYCHOL ASSESS, V23, P227, DOI 10.1027/1015-5759.23.4.227
   Landler L, 2018, BEHAV ECOL SOCIOBIOL, V72, DOI 10.1007/s00265-018-2538-y
   Liu W, 2012, PATTERN RECOGN, V45, P3912, DOI 10.1016/j.patcog.2012.04.025
   [刘自牧 Liu Zimu], 2019, [大气科学, Chinese Journal of Atmospheric Sciences], V43, P13
   [刘自牧 Liu Zimu], 2018, [高原气象, Plateau Meteorology], V37, P1233
   [罗文 Luo Wen], 2012, [电子学报, Acta Electronica Sinica], V40, P1729
   Reddy MSK, 2021, SADHANA-ACAD P ENG S, V46, DOI 10.1007/s12046-021-01570-y
   SHU CF, 1994, IEEE T PATTERN ANAL, V16, P946, DOI 10.1109/34.310692
   Varun AV, 2008, EXP FLUIDS, V45, P857, DOI 10.1007/s00348-008-0505-5
   [于连庆 Yu Lianqing], 2011, [应用气象学报, Journal of Applied Meteorolgical Science], V22, P375
   Zhang X., 2010, IDENTIFICATION APPL
   Zhang YN, 2018, J HYDRODYN, V30, P767, DOI 10.1007/s42241-018-0112-8
   Zhou J, 1999, J FLUID MECH, V387, P353, DOI 10.1017/S002211209900467X
NR 31
TC 2
Z9 2
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20853
EP 20870
DI 10.1007/s11042-022-12734-1
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767922000003
DA 2024-07-18
ER

PT J
AU Ban, Y
   Chen, LX
   Wang, XW
AF Ban, Ying
   Chen, Lixia
   Wang, Xuewen
TI Background subtraction based on logarithm rank function and structured
   sparsity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background subtraction; Segmentation; Logarithm rank function; Index
   tree; Structured sparsity
ID SEGMENTATION
AB Background subtraction is one of the key technologies for recognizing and detecting moving targets in the field of video surveillance. To cope with the dynamic background and slow moving objects, a new background subtraction model with logarithm rank function and structured sparsity was proposed based on Robust Principal Component Analysis (RPCA). In this model, the segmentation and index trees were used to dynamically process the foreground, enhancing the appearance similarity and spatial continuity between the pixels. Then, C(2,1) norm was applied to constrain the sparsity of the image block and to strengthen the structured sparsity of foreground. Finally, the background was constrained by the logarithm rank function, which adaptively scaled the weight of large singular values and considered the influence of different singular values on the rank function. The experimental results show that, compared to the state-of-the-art algorithms, 90% of the F-measure values of the proposed model are the best and 10% are the second best. In addition, our new approach exhibits superior performance in subjective evaluation, particularly in dynamic backgrounds, slow moving targets and camera jitter.
C1 [Ban, Ying; Chen, Lixia] Guilin Univ Elect Technol, Sch Math & Comp Sci, Guangxi Coll & Univ Key Lab Data Anal & Computat, 1 Jinji Rd, Guilin 541004, Guangxi, Peoples R China.
   [Ban, Ying] Yanching Inst Technol, Sch Architecture, 45 Yingbin North Rd, Langfang 065201, Hebei, Peoples R China.
   [Wang, Xuewen] Guilin Univ Elect Technol, Sch Comp Sci & Informat Secur, 1 Jinji Rd, Guilin 6541004, Guangxi, Peoples R China.
C3 Guilin University of Electronic Technology; Guilin University of
   Electronic Technology
RP Chen, LX (corresponding author), Guilin Univ Elect Technol, Sch Math & Comp Sci, Guangxi Coll & Univ Key Lab Data Anal & Computat, 1 Jinji Rd, Guilin 541004, Guangxi, Peoples R China.
EM clx_2001@126.com
FU National Natural Science Foundation of China [11961010, 61941111];
   National Natural Science Foundation of Guangxi Province
   [2018GXNSFAA138169]
FX This project is partially supported by the National Natural Science
   Foundation of China (11961010, 61941111), National Natural Science
   Foundation of Guangxi Province (2018GXNSFAA138169).
CR Bouwmans T, 2014, COMPUT VIS IMAGE UND, V122, P22, DOI 10.1016/j.cviu.2013.11.009
   Cai ST, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9071411
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Cao WF, 2016, IEEE T IMAGE PROCESS, V25, P4075, DOI 10.1109/TIP.2016.2579262
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1014, DOI 10.1109/TCYB.2015.2419737
   Cheng MY, 2006, IEEE SYS MAN CYBERN, P3983, DOI 10.1109/ICSMC.2006.384755
   Deng W, 2016, J SCI COMPUT, V66, P889, DOI 10.1007/s10915-015-0048-x
   Ebadi SE, 2018, IEEE T PATTERN ANAL, V40, P2273, DOI 10.1109/TPAMI.2017.2745573
   Friedman N., 1997, PROC UNCERTAINTY ART, P175
   Goldfarb D, 2014, SIAM J MATRIX ANAL A, V35, P225, DOI 10.1137/130905010
   Jenatton R, 2011, J MACH LEARN RES, V12, P2297
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Li Y., 2018, ARXIV PREPRINT ARXIV
   Li YF, 2019, SIGNAL PROCESS-IMAGE, V76, P214, DOI 10.1016/j.image.2019.05.002
   Li Y, 2019, NEUROCOMPUTING, V323, P352, DOI 10.1016/j.neucom.2018.10.012
   Liu J., 2010, ADV NEURAL INFORM PR, P1459
   Lu CY, 2020, IEEE T PATTERN ANAL, V42, P925, DOI 10.1109/TPAMI.2019.2891760
   Mahadevan Vijay., 2008, Computer Vision and Pattern Recognition, IEEE Computer Society Conference on, P1, DOI 10.1109/CVPR.2008.4587576
   Monnet A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1305
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Rezaei B, 2017, IEEE INT CONF COMP V, P1871, DOI 10.1109/ICCVW.2017.221
   Tom AJ, 2018, INT CO SIG PROC COMM, P327, DOI 10.1109/SPCOM.2018.8724459
   Wang MR, 2017, SIGNAL PROCESS-IMAGE, V56, P28, DOI 10.1016/j.image.2017.04.007
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Wang Y, 2019, J SCI COMPUT, V78, P29, DOI 10.1007/s10915-018-0757-z
   Xie Q, 2018, IEEE T PATTERN ANAL, V40, P1888, DOI 10.1109/TPAMI.2017.2734888
   [徐剑 XU Jian], 2009, [自动化学报, Acta Automatica Sinica], V35, P1145
   Xue JZ, 2019, INFORM SCIENCES, V503, P109, DOI 10.1016/j.ins.2019.06.061
   Yang JY, 2020, SIGNAL PROCESS, V168, DOI 10.1016/j.sigpro.2019.107362
   Yuan M., 2006, Journal of the Royal Statistical Society, Series B, V70, P53
   Zheng JB, 2002, 2002 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-4, PROCEEDINGS, P1626, DOI 10.1109/ICMLC.2002.1167486
   Zhou XW, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2674559
NR 32
TC 0
Z9 0
U1 2
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20465
EP 20481
DI 10.1007/s11042-022-11916-1
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767713900001
DA 2024-07-18
ER

PT J
AU Wang, KS
   Liu, MQ
   Zhang, ZH
   Gao, TG
AF Wang, Kunshu
   Liu, Mengqi
   Zhang, Zehui
   Gao, Tiegang
TI Optimized visually meaningful image embedding strategy based on
   compressive sensing and 2D DWT-SVD
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressive sensing; Singular value decomposition; Chaotic system; Two
   dimensional discrete wavelet transform; Visually meaningful embedded
   image
ID RESTRICTED ISOMETRY PROPERTY; DNA ENCRYPTION; ALGORITHM; PERMUTATION;
   TRANSFORM; ROBUST
AB This paper presents an optimized embedding strategy for visually meaningful embedded image based on compressive sensing (CS), two dimensional discrete wavelet transform (2D DWT) and singular value decomposition (SVD). The embedding strategy consists of four main processes: keys generation; compress the original signal; bit-level image encryption; information hiding. Firstly, the Mahalanobis distance between the original image and the host image is used as the parameter of the SHA-512, and then iterate two chaotic systems with hash values to generate key streams. Then, the components of the plain image are sparsely represented by the optimal direction method, and liner measurement these sparse matrices according to the theory of CS, which can achieve compressing and encrypting simultaneously. Thirdly, the bit-level XOR operation is performed on the compressed sensing image by shuffle and diffusion simultaneously. Finally, decomposing the encrypted image and the carrier image by 2D DWT, and modifying sub-bands of the host image with encrypted sub-bands based on SVD, one can obtain a visually meaningful embedded image, which peak signal-to-noise ratio (PSNR) is 0.08% higher than some traditional optimal algorithms. In particular, the size of the plain image is larger than the host image, which requires stronger embedding capacity. In order to enhance the ability to the defense against plaintext attacks, key streams of two chaotic systems are highly correlated with original images and host images. Moreover, the method of compression and encryption can greatly reduce storage space and process time. Simulation results demonstrate the security and effectiveness of the proposed algorithm.
C1 [Wang, Kunshu; Liu, Mengqi; Zhang, Zehui; Gao, Tiegang] Nankai Univ, Coll Software, Tianjin 300350, Peoples R China.
C3 Nankai University
RP Gao, TG (corresponding author), Nankai Univ, Coll Software, Tianjin 300350, Peoples R China.
EM gaotiegang@nankai.edu.cn
RI Liu, Meng/GRF-0962-2022
FU National Science and Technology Major Project of China [2018YFB0204304];
   2021 Tianjin Graduate Scientific Research Innovation Project
   [2021YJSB012]
FX This work is supported by the National Science and Technology Major
   Project of China (Grant No. 2018YFB0204304) and 2021 Tianjin Graduate
   Scientific Research Innovation Project (Grant No. 2021YJSB012).
CR ADA B, 2020, J KING SAUD UNIV-COM, DOI [10.1016/j.jksuci.2020.10.008, DOI 10.1016/J.JKSUCI.2020.10.008]
   Anand A, 2020, IEEE MULTIMEDIA, V27, P133, DOI 10.1109/MMUL.2020.2993269
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   [Anonymous], 2018, IDENTITY THEFT RESOU
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Biggs NL, 2008, SPRINGER UNDERGRADUA, DOI 10.1007/978-1-84800-273-9_12
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014
   Chai XL, 2021, INFORM SCIENCES, V556, P305, DOI 10.1016/j.ins.2020.10.007
   Chai XL, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107525
   Chai XL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105837
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Chen JX, 2018, OPT LASER TECHNOL, V99, P238, DOI 10.1016/j.optlastec.2017.09.008
   Dong CE, 2014, SIGNAL PROCESS-IMAGE, V29, P628, DOI 10.1016/j.image.2013.09.006
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Endra, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND CYBERNETICS (CYBERNETICSCOM), P122, DOI 10.1109/CyberneticsCom.2013.6865794
   Engan K, 1999, INT CONF ACOUST SPEE, P2443, DOI 10.1109/ICASSP.1999.760624
   Ernawan F, 2021, IEEE ACCESS, V9, P45474, DOI 10.1109/ACCESS.2021.3067245
   Fang H, 2014, IEEE T SIGNAL PROCES, V62, P196, DOI 10.1109/TSP.2013.2284762
   Ghai D, 2020, INT J MOD PHYS B, V34, DOI 10.1142/S0217979220500095
   Hu GQ, 2017, J VIS COMMUN IMAGE R, V44, P116, DOI 10.1016/j.jvcir.2017.01.022
   Ivanna D., 2020, FOURIER TRANSFORM EL, V9, P1108, DOI [10.3390/electronics9071108, DOI 10.3390/ELECTRONICS9071108]
   Jiang FF, 2020, MULTIMED TOOLS APPL, V79, P7599, DOI 10.1007/s11042-019-08459-3
   Jiang X, 2021, OPT COMMUN, V484, DOI 10.1016/j.optcom.2020.126683
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Kanso A, 2017, OPT LASER ENG, V90, P196, DOI 10.1016/j.optlaseng.2016.10.009
   Li CQ, 2018, IEEE MULTIMEDIA, V25, P46, DOI 10.1109/MMUL.2018.2873472
   Li YM, 2021, INFORM SCIENCES, V551, P205, DOI 10.1016/j.ins.2020.11.020
   Liu HJ, 2015, SIGNAL PROCESS, V113, P104, DOI 10.1016/j.sigpro.2015.01.016
   Liu QL, 2020, APPL MATH MODEL, V85, P273, DOI 10.1016/j.apm.2020.04.015
   Liu XY, 2013, OPTIK, V124, P6590, DOI 10.1016/j.ijleo.2013.05.092
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Mohammed EA, 2019, OPT LASER TECHNOL, V118, P13, DOI 10.1016/j.optlastec.2019.04.035
   Moshtaghpour A, 2020, IEEE T INFORM THEORY, V66, P7253, DOI 10.1109/TIT.2020.2992852
   Mukherjee I., 2015, IPSI BGD INTERNET RE, V11, P25
   Ponnaian D, 2017, OPTIK, V147, P263, DOI 10.1016/j.ijleo.2017.07.063
   Pourhashemi SM, 2021, NEURAL COMPUT APPL, V33, P6161, DOI 10.1007/s00521-020-05389-2
   RYKACZEWSKI R, 2017, IEEE T MULTIMEDIA, V9
   Shen YX, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114414
   Singha A, 2021, MULTIMEDIA SYST, V27, P89, DOI 10.1007/s00530-020-00708-y
   Tao Y, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102650
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Tresor LO, 2019, IEEE ACCESS, V7, P103463, DOI 10.1109/ACCESS.2019.2929244
   Wang BW, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8050691
   Wang Q, 2018, OPT COMMUN, V415, P56, DOI 10.1016/j.optcom.2018.01.018
   Wang XY, 2016, OPT LASER ENG, V82, P79, DOI 10.1016/j.optlaseng.2015.12.006
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wang XY, 2010, COMMUN NONLINEAR SCI, V15, P4052, DOI 10.1016/j.cnsns.2010.02.014
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2017, NONLINEAR DYNAM, V90, P855, DOI 10.1007/s11071-017-3698-4
   Yang JB, 2015, IEEE T IMAGE PROCESS, V24, P106, DOI 10.1109/TIP.2014.2365720
   Zear A, 2022, MULTIMED TOOLS APPL, V81, P26721, DOI 10.1007/s11042-020-10472-w
   Zermi N, 2021, FORENSIC SCI INT, V320, DOI 10.1016/j.forsciint.2021.110691
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 57
TC 6
Z9 6
U1 5
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 20175
EP 20199
DI 10.1007/s11042-022-12305-4
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000767748600018
DA 2024-07-18
ER

PT J
AU Feng, YC
   Guo, R
   Shen, XJ
   Zhang, XL
AF Feng, Yuncong
   Guo, Rui
   Shen, Xuanjing
   Zhang, Xiaoli
TI A measure for the evaluation of multi-focus image fusion at feature
   level
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Objective evaluation; Feature level; Corner detection;
   Similarity
ID QUALITY ASSESSMENT MODEL; INFORMATION MEASURE; PERFORMANCE; EDGE
AB Most multi-focus image fusion evaluation methods are based on focus detection and measuring the similarity between the fused image and the whole source images including defocused regions, which is liable to result in the difference between the evaluation result and the real image fusion quality. To overcome the problem above, we proposed a novel objective measure for multi-focus image fusion assessment in feature level. Firstly, the corners in source images and the fused image are separately detected based on Smallest Univalue Segment Assimilating Nucleus (SUSAN) algorithm. Then, a corner similarity measure based on overlapping rate is proposed to measure the fusion quality. The proposed method avoids focus detection in the assessment procedure, which make evaluation results more reliable. Experimental results demonstrate that the proposed measure is more consistent with subjective evaluation. Comparing with other objective metrics, two meta-measures including correct ranking (CR) and subjective relevance (R) give our proposed measure the highest scores, 0.8377 and 0.7384, respectively. The area under the ROC curve (AUC) gives our metric the second-best scores of 0.8428.
C1 [Feng, Yuncong] Changchun Univ Technol, Coll Comp Sci & Engn, Changchun 130012, Peoples R China.
   [Guo, Rui] Changchun Univ Technol, Artificial Intelligence Res Inst, Changchun 130012, Peoples R China.
   [Feng, Yuncong; Guo, Rui; Shen, Xuanjing; Zhang, Xiaoli] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn Minist E, Changchun 130012, Peoples R China.
   [Guo, Rui; Shen, Xuanjing; Zhang, Xiaoli] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Zhang, Xiaoli] Hainan Vocat Univ Sci & Technol, Dept Informat Engn, Haikou 571126, Hainan, Peoples R China.
C3 Changchun University of Technology; Changchun University of Technology;
   Jilin University; Jilin University; Hainan Vocational University of
   Science & Technology
RP Zhang, XL (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn Minist E, Changchun 130012, Peoples R China.; Zhang, XL (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.; Zhang, XL (corresponding author), Hainan Vocat Univ Sci & Technol, Dept Informat Engn, Haikou 571126, Hainan, Peoples R China.
EM zhangxiaoli@jlu.edu.cn
RI Zhang, Xiaoli/ABC-2210-2021
FU Youth Growth Science and Technology Plan Project of Jilin Provincial
   Department of Science and Technology [20210508039RQ]; "Thirteenth
   Five-Year Plan" Scientific Research Planning Project of Education
   Department of Jilin Province [JJKH20200678KJ,, JJKH20210752KJ,
   JJKH20200677KJ]; Fundamental Research Funds for the Central
   Universities, JLU [93K172020K05]; National Natural Science Foundation of
   China [61806024, 61876070, 61801190]
FX The work was supported by Youth Growth Science and Technology Plan
   Project of Jilin Provincial Department of Science and Technology
   (NO.20210508039RQ), "Thirteenth Five-Year Plan" Scientific Research
   Planning Project of Education Department of Jilin Province
   (NO.JJKH20200678KJ, NO.JJKH20210752KJ, NO.JJKH20200677KJ), Fundamental
   Research Funds for the Central Universities, JLU(NO.93K172020K05), and
   National Natural Science Foundation of China (NO.61806024, NO.61876070,
   NO.61801190).
CR Bouzos O, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2922097
   Chen YB, 2018, IEEE T IMAGE PROCESS, V27, P1526, DOI 10.1109/TIP.2017.2779274
   Fang YM, 2020, IEEE T IMAGE PROCESS, V29, P1127, DOI 10.1109/TIP.2019.2940678
   Han YY, 2015, OPTIK, V126, P5842, DOI 10.1016/j.ijleo.2015.08.250
   Han Y, 2013, INFORM FUSION, V14, P127, DOI 10.1016/j.inffus.2011.08.002
   Hassen R, 2015, IEEE T IMAGE PROCESS, V24, P2712, DOI 10.1109/TIP.2015.2428051
   Zhu HP, 2020, FUTURE GENER COMP SY, V112, P501, DOI 10.1016/j.future.2020.05.037
   Hossny M, 2008, ELECTRON LETT, V44, P1066, DOI 10.1049/el:20081754
   Li H, 2021, PATTERN RECOGN LETT, V141, P45, DOI 10.1016/j.patrec.2020.11.014
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Liu Y, 2020, INFORM FUSION, V64, P71, DOI 10.1016/j.inffus.2020.06.013
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Martinez J, 2019, INFORM FUSION, V50, P197, DOI 10.1016/j.inffus.2019.01.003
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Nian ZC, 2019, IEEE IMAGE PROC, P1044, DOI [10.1109/icip.2019.8803065, 10.1109/ICIP.2019.8803065]
   Petrovic V, 2007, INFORM FUSION, V8, P208, DOI 10.1016/j.inffus.2005.05.001
   Petrovic V, 2015, INFORM FUSION, V22, P119, DOI 10.1016/j.inffus.2014.05.002
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Possa PR, 2014, IEEE T COMPUT, V63, P2376, DOI 10.1109/TC.2013.130
   Qiu XH, 2019, SIGNAL PROCESS-IMAGE, V72, P35, DOI 10.1016/j.image.2018.12.004
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Tan J, 2021, SIGNAL PROCESS-IMAGE, V92, DOI 10.1016/j.image.2020.116130
   Tang H, 2018, INFORM SCIENCES, V433, P125, DOI 10.1016/j.ins.2017.12.043
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Xiao Zuzhang, MULTIFOCUS IMAGE FUS
   Xing L, 2018, SIGNAL PROCESS, V145, P233, DOI 10.1016/j.sigpro.2017.12.013
   Xu KP, 2018, KSII T INTERNET INF, V12, P2253, DOI 10.3837/tiis.2018.05.019
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yu S, 2021, MULTIMED TOOLS APPL, V80, P5673, DOI 10.1007/s11042-020-09877-4
   Zhang XL, 2015, SIGNAL PROCESS, V115, P38, DOI 10.1016/j.sigpro.2015.03.007
   Zhang Y, 2017, INFORM FUSION, V35, P81, DOI 10.1016/j.inffus.2016.09.006
   Zhao WD, 2019, IEEE T CIRC SYST VID, V29, P1102, DOI 10.1109/TCSVT.2018.2821177
NR 33
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18053
EP 18071
DI 10.1007/s11042-022-11976-3
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766064000007
DA 2024-07-18
ER

PT J
AU Yalamanchili, B
   Anne, KR
   Samayamantula, SK
AF Yalamanchili, Bhanusree
   Anne, Koteswara Rao
   Samayamantula, Srinivas Kumar
TI Speech Emotion Recognition using Time Distributed 2D-Convolution layers
   for CAPSULENETS
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech Emotion Recognition (SER); Spectrogram; Time distributed layers;
   CapsuleNets; Deep Neural Networks (DNN); RAVDESS; And IEMOCAP
ID NEURAL-NETWORKS; FEATURES; CLASSIFIERS; RECURRENT
AB Speech Emotion Recognition (SER) determines human emotions using linguistic and nonlinguistic features of the uttered speech. The nonlinguistic process is more suitable for applications where language is not a concern. In this paper, Capsule Network (CapsuleNets) with a combination of Time Distributed 2D-Convolution layers is used for classifying emotions using speech signals. CapsuleNets are specially designed to capture the spatial cues of the data but fail in considering temporal cues in time series data like speech. In order to capture the temporal cues, along with spatial cues, Time distributed 2D- convolution neural layers are introduced before the CapsuleNets. Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) and Interactive Emotional Dyadic Motion Capture (IEMOCAP) speech data sets are used for experimenting with the proposed network architecture. The log-mel spectrogram of the speech samples is extracted and used for training and testing of the proposed model. The combination of CapsuleNets with Time Distributed 2D-Convolution layers has achieved a classification accuracy of 92.6% on the RAVDESS dataset and 93.2% on the IEMOCAP dataset. These results are compared with the plain CapsuleNets model, and remarkable improvement is observed. Also, the proposed system has outperformed the existing models on the mentioned benchmarked datasets. The confusion matrix shows consistent improvement in the accuracy of every emotion, including sad and disgust in RAVDESS and angry in IEMOCAP, which are poorly classified by classifiers such as variants in CNN, RNN, LSTM.
C1 [Yalamanchili, Bhanusree] Jawaharlal Nehru Technol Univ, Dept CSE, Kakinada, India.
   [Anne, Koteswara Rao] Kalasalingam Acad Res & Educ, Dept CSE, Srivilliputhur, Tamil Nadu, India.
   [Samayamantula, Srinivas Kumar] Jawaharlal Nehru Technol Univ, Dept ECE, Kakinada, India.
C3 Jawaharlal Nehru Technological University - Kakinada; Kalasalingam
   Academy of Research & Education; Jawaharlal Nehru Technological
   University - Kakinada
RP Yalamanchili, B (corresponding author), Jawaharlal Nehru Technol Univ, Dept CSE, Kakinada, India.
EM bhanusree_y@vnrvjiet.in; raoanne@gmail.com; samayamantula1963@gmail.com
RI Anne, Koteswara Rao/GPP-2224-2022; Yalamanchili, Dr.
   Bhanusree/Q-6139-2016; samayamantula, srinivas kumar/AAR-9833-2020;
   Anne, Koteswara rao/GPS-7514-2022
OI Yalamanchili, Dr. Bhanusree/0000-0003-2056-9379; Anne, Koteswara
   rao/0000-0003-1735-6540
CR Akçay MB, 2020, SPEECH COMMUN, V116, P56, DOI 10.1016/j.specom.2019.12.001
   Anagnostopoulos CN, 2015, ARTIF INTELL REV, V43, P155, DOI 10.1007/s10462-012-9368-5
   Atmaja BT, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON SIGNALS AND SYSTEMS (ICSIGSYS), P40, DOI [10.1109/icsigsys.2019.8811080, 10.1109/ICSIGSYS.2019.8811080]
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Chen MY, 2018, IEEE SIGNAL PROC LET, V25, P1440, DOI 10.1109/LSP.2018.2860246
   Cummins N, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P478, DOI 10.1145/3123266.3123371
   Dzedzickis A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030592
   Fayek HM, 2017, NEURAL NETWORKS, V92, P60, DOI 10.1016/j.neunet.2017.02.013
   Hinton G.E., 2018, INT C LEARN REPR
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Huang CW, 2016, INTERSPEECH, P1387, DOI 10.21437/Interspeech.2016-448
   Issa D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101894
   Jain R., 2019, Improving performance and inference on audio classification tasks using capsule networks
   Jing SL, 2018, DIGIT SIGNAL PROCESS, V72, P216, DOI 10.1016/j.dsp.2017.10.016
   Kuchibhotla S, 2016, INT J SPEECH TECHNOL, V19, P657, DOI 10.1007/s10772-016-9358-0
   Kuchibhotla S, 2014, INT J SPEECH TECHNOL, V17, P401, DOI 10.1007/s10772-014-9239-3
   Lalitha S, 2019, INT J SPEECH TECHNOL, V22, P497, DOI 10.1007/s10772-018-09572-8
   Lim W, 2016, ASIAPAC SIGN INFO PR, DOI 10.1109/APSIPA.2016.7820699
   Liu ZT, 2018, NEUROCOMPUTING, V273, P271, DOI 10.1016/j.neucom.2017.07.050
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Madhu G, 2021, CMC-COMPUT MATER CON, V68, P903, DOI 10.32604/cmc.2021.016114
   Meng H, 2019, IEEE ACCESS, V7, P125868, DOI 10.1109/ACCESS.2019.2938007
   Mustageem, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8122133
   Mustaqeem, 2020, IEEE ACCESS, V8, P79861, DOI 10.1109/ACCESS.2020.2990405
   Palaz D, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P11
   Patrick MK, 2022, J KING SAUD UNIV-COM, V34, P1295, DOI 10.1016/j.jksuci.2019.09.014
   Peer D, 2021, PATTERN RECOGN LETT, V144, P68, DOI 10.1016/j.patrec.2021.01.017
   Qiao HH, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092932
   RUSSELL JA, 1977, J RES PERS, V11, P273, DOI 10.1016/0092-6566(77)90037-X
   Sabour S, 2017, ADV NEUR IN, V30
   Satt A, 2017, INTERSPEECH, P1089, DOI 10.21437/Interspeech.2017-200
   Wu XX, 2019, INT CONF ACOUST SPEE, P6695, DOI 10.1109/ICASSP.2019.8683163
   Xie Y, 2019, IEEE-ACM T AUDIO SPE, V27, P1675, DOI 10.1109/TASLP.2019.2925934
   Zhang XQ, 2019, INT J IMAG SYST TECH, V29, P19, DOI 10.1002/ima.22291
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
   Zhao ZP, 2019, IEEE ACCESS, V7, P97515, DOI 10.1109/ACCESS.2019.2928625
NR 36
TC 1
Z9 1
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16945
EP 16966
DI 10.1007/s11042-022-12112-x
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000764599600001
DA 2024-07-18
ER

PT J
AU Chang, CW
   Santra, S
   Hsieh, JW
   Hendri, P
   Lin, CF
AF Chang, Chuan-Wang
   Santra, Santanu
   Hsieh, Jun-Wei
   Hendri, Pirdiansyah
   Lin, Chi-Fang
TI Multi-fusion feature pyramid for real-time hand detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Hand detection; Embedded system; Human; YOLOV4
ID GESTURE RECOGNITION
AB Real-time HI (Human Interface) systems need accurate and efficient hand detection models to meet the limited resources in budget, dimension, memory, computing, and electric power. The detection task is also important for other applications such as homecare systems, fine-grained action recognition, movie interpretation, and even for understanding dance gestures. In recent years, object detection has become a less challenging task with the latest deep CNN-based state-of-the-art models, i.e., RCNN, SSD, and YOLO. However, these models cannot achieve desired efficiency and accuracy on HI-based embedded devices due to their complex time-consuming architecture. Another critical issue in hand detection is that small hands (<30 x 30 pixels) are still challenging for all the above methods. We proposed a shallow model named Multi-fusion Feature Pyramid for real-time hand detection to deal with the above problems. Experimental results on the Oxford hand dataset combined with the skin dataset show that the proposed method outperforms other SoTA methods in terms of accuracy, efficiency, and real-time speed. The COCO dataset is also used to compare with other state-of-the-art method and shows the highest efficiency and accuracy with the proposed CFPN model. Thus we conclude that the proposed model is useful for real-life small hand detection on embedded devices.
C1 [Chang, Chuan-Wang] Natl Chin Yi Univ Technol, Dept Comp Sci & Informat Engn, 57,Sec 2,Zhongshan Rd, Taichung 41170, Taiwan.
   [Santra, Santanu; Lin, Chi-Fang] Yuan Ze Univ, Dept Comp Sci & Engn, 135 Yuan Tung Rd, Taoyuan 32003, Taiwan.
   [Hsieh, Jun-Wei] Natl Chiao Tung Univ, Coll Artificial Intelligence, 301,Gaofa 3rd Rd, Tainan 71150, Taiwan.
   [Hendri, Pirdiansyah] Natl Taiwan Ocean Univ, Dept Comp Sci & Informat Engn, 2 Pei Ning Rd, Keelung 20224, Taiwan.
C3 National Chin-Yi University of Technology; Yuan Ze University; National
   Yang Ming Chiao Tung University; National Taiwan Ocean University
RP Hsieh, JW (corresponding author), Natl Chiao Tung Univ, Coll Artificial Intelligence, 301,Gaofa 3rd Rd, Tainan 71150, Taiwan.
EM cwchang@ncut.edu.tw; jwhsieh@nctu.edu.tw; hendriplg@gmail.com
OI Chang, Chuan-Wang/0000-0001-5010-2767
CR [Anonymous], 2017, arXiv
   Bambach S, 2015, IEEE I CONF COMP VIS, P1949, DOI 10.1109/ICCV.2015.226
   Bosquet B., 2019, BR MACH VIS C 2018 B
   Chen MY, 2016, IEEE T HUM-MACH SYST, V46, P403, DOI 10.1109/THMS.2015.2492598
   Chen Q, 2008, IEEE T INSTRUM MEAS, V57, P1562, DOI 10.1109/TIM.2008.922070
   Dardas NH, 2011, IEEE T INSTRUM MEAS, V60, P3592, DOI 10.1109/TIM.2011.2161140
   Deng XM, 2018, IEEE T IMAGE PROCESS, V27, P1888, DOI 10.1109/TIP.2017.2779600
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gupta L, 2001, IEEE T SYST MAN CY C, V31, P114, DOI 10.1109/5326.923274
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Infantino I, 2007, IEEE T SYST MAN CY C, V37, P1034, DOI 10.1109/TSMCC.2007.900624
   Kim SW, 2018, LECT NOTES COMPUT SC, V11209, P239, DOI 10.1007/978-3-030-01228-1_15
   Kölsch M, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P614, DOI 10.1109/AFGR.2004.1301601
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Le THN, 2017, IEEE COMPUT SOC CONF, P1203, DOI 10.1109/CVPRW.2017.159
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lun R, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415550083
   Mei KZ, 2015, NEUROCOMPUTING, V158, P184, DOI 10.1016/j.neucom.2015.01.049
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Mittal A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.75
   Mohanty A., 2017, P INT C COMP VIS IM, P93, DOI DOI 10.1007/978-981-10-2107-7_9
   Novak B, 2020, 2020 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P165, DOI [10.1109/zinc50678.2020.9161446, 10.1109/ZINC50678.2020.9161446]
   Ong EJ, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P889
   Redmon J., 2018, IEEE C COMPUTER VISI
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roy K, 2017, IEEE INT CONF COMP V, P640, DOI 10.1109/ICCVW.2017.81
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Le TH, 2019, IEEE SENS J, V19, P4696, DOI 10.1109/JSEN.2019.2901259
   Tsai TH., 2017, UBI MED 2017
   Wang RJ, 2018, 32 C NEURAL INFORM P
   Yang YZ, 2015, PROC CVPR IEEE, P400, DOI 10.1109/CVPR.2015.7298637
   Zhang LC, 2015, PROCEEDINGS OF 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC), P192, DOI 10.1109/ICCI-CC.2015.7259385
   Zhang X, 2013, IEEE MULTIMEDIA, V20, P85, DOI 10.1109/MMUL.2013.50
   Zhang X, 2011, IEEE T SYST MAN CY A, V41, P1064, DOI 10.1109/TSMCA.2011.2116004
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
NR 42
TC 1
Z9 1
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 11917
EP 11929
DI 10.1007/s11042-021-11897-7
EA MAR 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000763872100001
DA 2024-07-18
ER

PT J
AU Lanjewar, MG
   Morajkar, PP
   Parab, J
AF Lanjewar, Madhusudan G.
   Morajkar, Pranay P.
   Parab, Jivan
TI Detection of tartrazine colored rice flour adulteration in turmeric from
   multi-spectral images on smartphone using convolutional neural network
   deployed on PaaS cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adulteration; Tartrazine; Turmeric; CNN; Cloud computing; PaaS cloud
ID LIQUID-CHROMATOGRAPHY; SUDAN-I; SPECTROSCOPY; SPICES; DYES;
   CLASSIFICATION; PRODUCTS; CURCUMIN; SAFFRON; POWDER
AB Food adulteration occurs globally, in many facets, and affects almost all food commodities. Adulteration is not just a crucial economic problem, but it may also lead to serious health problems for consumers. Turmeric (Curcuma longa) is a world-class spice commonly contaminated with various chemicals and colors. It has also been used extensively in many Asian curries, sauces, and medications. Different traditional approaches, such as chemical and physical methods, are available for detecting adulterants in turmeric. These approaches are rather time-consuming and inaccurate methods. Therefore, it is of utmost importance to identify the adulterants in turmeric accurately and instantly. A cloud-based system was developed to detect adulteration in adulterated turmeric. The dataset consists of spectral images of turmeric with tartrazine-colored rice flour adulterant. Adulterants in weight percentages of 0%, 5%, 10%, and 15% were mixed with turmeric. A convolutional neural network (CNN) was implemented to detect adulteration, which achieved 100% accuracy for training and 94.35% accuracy for validation. The deep CNN (DCNN) models, namely, VGG16, DenseNet201, and MobileNet, were implemented to detect adulteration. The proposed CNN model outperforms DCNN models in terms of accuracy and layers. The CNN model is deployed to the platform as a service (PaaS) cloud. The deployed model link can be accessed using a smartphone. Uploading the adulterated turmeric image to a cloud link can analyze and detect adulteration.
C1 [Lanjewar, Madhusudan G.; Parab, Jivan] Goa Univ, Sch Phys & Appl Sci, Taleigao Plateau 403206, Goa, India.
   [Morajkar, Pranay P.] Goa Univ, Sch Chem Sci, Taleigao Plateau 403206, Goa, India.
C3 Goa University; Goa University
RP Parab, J (corresponding author), Goa Univ, Sch Phys & Appl Sci, Taleigao Plateau 403206, Goa, India.
EM madhusudan@unigoa.ac.in; pranay@unigoa.acin; jsparab@unigoa.ac.in
OI Lanjewar, Madhusudan/0000-0002-9670-3020
CR Akbar A, 2018, COMPUT ELECTRON AGR, V148, P160, DOI 10.1016/j.compag.2018.03.002
   Amani M, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12213561
   [Anonymous], 2015, ARXIV151201400CS
   [Anonymous], 2017, J COMMUN INF NETW, DOI DOI 10.1007/S41650-017-0031-9
   Ashok V, 2015, ANAL METHODS-UK, V7, P9324, DOI 10.1039/c5ay02377g
   Bandara WGC, 2020, J FOOD ENG, V266, DOI 10.1016/j.jfoodeng.2019.109700
   Bertelli D, 2007, FOOD CHEM, V101, P1565, DOI 10.1016/j.foodchem.2006.04.010
   Bhowmik D, 2021, DIRECT CAB
   Boureau Y. L., 2010, P 27 INT C MACH LEAR, P111
   Chawki E, 2018, PROCEDIA COMPUT SCI, V134, P328, DOI 10.1016/j.procs.2018.07.180
   Chen LY, 2015, FOOD ANAL METHOD, V8, P1903, DOI 10.1007/s12161-014-0074-6
   Dhakal S, 2016, FOODS, V5, DOI 10.3390/foods5020036
   Di Anibal CV, 2011, FOOD CHEM, V124, P1139, DOI 10.1016/j.foodchem.2010.07.025
   Di Anibal CV, 2009, TALANTA, V79, P887, DOI 10.1016/j.talanta.2009.05.023
   Dong TF, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8040281
   Donghoon Kim, 2017, International Journal of Cloud Computing, V6, P325
   Ennis R, 2018, J OPT SOC AM A, V35, pB256, DOI 10.1364/JOSAA.35.00B256
   Fadda E, 2021, Recent advances in computational optimization. Springer studies in computational intelligence, V920, P71
   Fadda E, 2021, TRANSPORT RES E-LOG, V145, DOI 10.1016/j.tre.2020.102174
   Fuh MR, 2002, TALANTA, V56, P663, DOI 10.1016/S0039-9140(01)00625-7
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guari Q, 2019, J CANCER, V10, P4876, DOI 10.7150/jca.28769
   Hatcher H, 2008, CELL MOL LIFE SCI, V65, P1631, DOI 10.1007/s00018-008-7452-4
   He K., 2015, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2015.7299173, DOI 10.1109/CVPR.2015.7299173]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hu LQ, 2018, COMPUT ELECTRON AGR, V154, P491, DOI 10.1016/j.compag.2018.09.029
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Izquierdo M, 2020, COMPUT ELECTRON AGR, V171, DOI 10.1016/j.compag.2020.105290
   Jayaprakasha GK, 2002, J AGR FOOD CHEM, V50, P3668, DOI 10.1021/jf025506a
   Khodabakhshian R., 2017, Journal of the Saudi Society of Agricultural Sciences, V16, P322, DOI 10.1016/j.jssas.2015.10.004
   Kiani S, 2018, COMPUT ELECTRON AGR, V152, P9, DOI 10.1016/j.compag.2018.06.025
   Kiani S, 2017, COMPUT ELECTRON AGR, V141, P46, DOI 10.1016/j.compag.2017.06.018
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar N., 2020, Int. J. Adv. Sci. Technol., V29, P1471
   Kumar N., 2020, Int. J. Adv. Sci. Technol, V29, P1495
   Kwan C, 2019, INFORMATION, V10, DOI 10.3390/info10110353
   Kyuchang Lee, 2021, Computers & Electrical Engineering, V89, P119, DOI 10.1016/j.compeleceng.2020.106909
   Lan H, 2018, J SENSORS, V2018, DOI 10.1155/2018/2075057
   Lee B.-H., 2018, 2018 27th Wireless and Optical Communication Conference, P1, DOI [DOI 10.1109/WOCC.2018.8372705, 10.1109/WOCC.2018.8372705]
   Liu CH, 2017, J FOOD ENG, V215, P78, DOI 10.1016/j.jfoodeng.2017.07.026
   Liu J, 2017, MULTIMEDIA SYST, V23, P95, DOI 10.1007/s00530-015-0455-8
   Malapela, E AGR
   McNairn H, 2004, CAN J REMOTE SENS, V30, P525, DOI 10.5589/m03-069
   Morajkar PP, 2019, ADVANCES IN BIOLOGICAL SCIENCE RESEARCH: A PRACTICAL APPROACH, P327, DOI 10.1016/B978-0-12-817497-5.00020-3
   Mujtaba, INTRO RECTIFIED LINE
   Naik AP, 2021, J MOL LIQ, V325, DOI 10.1016/j.molliq.2020.115235
   Naik AP, 2017, PHOTOCH PHOTOBIO SCI, V16, P1126, DOI 10.1039/c7pp00090a
   Naz S, 2022, MULTIMEDIA SYST, V28, P85, DOI 10.1007/s00530-021-00797-3
   Oquab M., 2015, PROC CVPR IEEE, P685
   Ouyang WL, 2015, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2015.7298854
   Parvathy VA, 2015, PHARM BIOL, V53, P1774, DOI 10.3109/13880209.2015.1005756
   Prabhath Gode Withanage, 2019, MULTISPECTRAL IMAGIN, DOI [10.1364/HISE.2019.HTu3B.3, DOI 10.1364/HISE.2019.HTU3B.3]
   Ropodi AI, 2017, FOOD CONTROL, V73, P57, DOI 10.1016/j.foodcont.2016.05.048
   Salmerón-García JJ, 2019, MULTIMEDIA SYST, V25, P535, DOI 10.1007/s00530-017-0558-5
   Sha O, 2014, J ANAL METHODS CHEM, V2014, DOI 10.1155/2014/964273
   Shafiee S, 2016, IFAC PAPERSONLINE, V49, P311, DOI 10.1016/j.ifacol.2016.10.057
   Shah R., 2017, World Journal of Pharmacy and Pharmaceutical Sciences, V6, P2034, DOI [10.20959/wjpps20178-9867, DOI 10.20959/WJPPS20178-9867]
   Sinha RK, 2018, ARXIV180403928CS
   Su WH, 2016, COMPUT ELECTRON AGR, V125, P113, DOI 10.1016/j.compag.2016.04.034
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tanaka F, 2020, FOOD CHEM, V303, DOI 10.1016/j.foodchem.2019.125381
   Tateo F, 2004, J AGR FOOD CHEM, V52, P655, DOI 10.1021/jf030721s
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wu L, 2021, Innovative Food Analysis, P157, DOI [10.1016/B978-0-12-819493-5.00007-8, DOI 10.1016/B978-0-12-819493-5.00007-8]
   Xu P., 2013, FRONTIERS INTERNET T, P145, DOI [10.1007/978-3-642-53959-6_14, DOI 10.1007/978-3-642-53959-6_14]
   Yang XP, 2017, FOOD ANAL METHOD, V10, P1308, DOI 10.1007/s12161-016-0691-3
   Zhang LY, 2015, J AM SOC MASS SPECTR, V26, P1414, DOI 10.1007/s13361-015-1142-x
   Zhao S, 2012, FOOD ANAL METHOD, V5, P1018, DOI 10.1007/s12161-011-9337-7
   Zoughi S, 2021, FOOD CHEM, V350, DOI 10.1016/j.foodchem.2021.129197
NR 69
TC 14
Z9 14
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16537
EP 16562
DI 10.1007/s11042-022-12392-3
EA MAR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763256300007
DA 2024-07-18
ER

PT J
AU Chen, HY
   Lin, CS
AF Chen, Hong-Yun
   Lin, Chow-Sing
TI Tiled streaming for layered 3D virtual reality videos with viewport
   prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; SHVC; Viewport prediction; Tiling; Metaverse
ID HEVC
AB In recent years, the demand of 3D video services has gradually increased. More and more bandwidth hungry applications are proposed, such as immersive media services which need a virtual reality (VR) headset and 3D VR videos to provide users immersive experience of watching 3D VR videos. Tiled streaming is often used for providing 3D VR videos die to the high bitrates of 3D VR videos. In a VR headset the sight is limited. Users can only watch a fraction of entire 3D VR videos in the viewport. Transmitting the content of a VR video outside the viewport is unnecessary and infeasible due to the high bitarate of 3D VR videos. Generally, In VR applications, content within the viewport should keep the highest quality while providing only basic quality outside the viewprot. Such an adaptive streaming relies on the precision of viewport prediction. Errors of viewport prediction result in the expensive overhead of quality repairing and re-transmission delay on the traditional versioned coded VR videos,, where a whole new version of video content needs to be resent and the sent content of low-quality version is discarded and cannot be reused. In this paper, we propose a novel adaptative streaming approach for providing 3D VR videos using Scalable Video Coding (SVC) with viewport prediction. For better quality adaptation, we take CubeMap projection as the projection format of 3D VR videos. Besides, we use the Scalability extension of High Efficiency Video Coding (SHVC) to encode 3D VR videos to multiple layers for supplying different qualities and also use the tiling to divide videos into rectangular regions for finer quality adaptation. The experimental results show that our proposed method outperformed other previous approaches in terms of the weighted video quality and the relative time spent on the highest quality, especially with low available network bandwidth. Even under certain miss rates of tiles, compared to previous approaches, our proposed method requires fewer bandwidth overhead and shorter re-transmission delay for repairing the quality of missed tiles in most cases.
C1 [Chen, Hong-Yun; Lin, Chow-Sing] Natl Univ Tainan, Dept Comp Sci & Informat Engn, 33,Sec 2,Shu Lin St, Tainan 70005, Taiwan.
C3 National University Tainan
RP Lin, CS (corresponding author), Natl Univ Tainan, Dept Comp Sci & Informat Engn, 33,Sec 2,Shu Lin St, Tainan 70005, Taiwan.
EM m10559005@stumail.nutn.edu.tw; mikelin@mail.nutn.edu.tw
RI Lin, Chow-Sing/JPX-6621-2023
OI Lin, Chow-Sing/0000-0002-3937-7919
FU National Science Council in Taiwan (R.O.C.) [MOST 107-2221-E-024-002-]
FX This work was partially supported by National Science Council in Taiwan
   (R.O.C.) under contract MOST 107-2221-E-024-002-.
CR Akamai's, 2017, STAT INT
   Alface PR, 2012, BELL LABS TECH J, V16, P135, DOI 10.1002/bltj.20538
   Boyce JM, 2016, IEEE T CIRC SYST VID, V26, P20, DOI 10.1109/TCSVT.2015.2461951
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Dionisio JDN, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2480741.2480751
   Duan H., 2021, P 29 ACM INT C MULTI, P153, DOI [DOI 10.1145/3474085.3479238, 10.1145/3474085.3479238]
   Github, 2020, FAC TRANSF TRANSF EQ
   Gupta S, 2019, MULTIMED TOOLS APPL, V78, P34157, DOI 10.1007/s11042-019-08232-6
   Hevc, 2020, SCAL EXT SHVC JCT VC
   HOOFT JVD, 2019, ACM T MULTIM COMPUT, V15
   Hosseini M, 2016, IEEE INT SYM MULTIM, P107, DOI [10.1109/ISM.2016.45, 10.1109/ISM.2016.0028]
   Nasrabadi AT, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1689, DOI 10.1145/3123266.3123414
   Petrangeli S, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P306, DOI 10.1145/3123266.3123453
   Pourazad MT, 2012, IEEE CONSUM ELECTR M, V1, P36, DOI 10.1109/MCE.2012.2192754
   Qian F., 2016, Proceedings of the 5th Workshop on All Things Cellular: Operations, Applications and Challenges, P1, DOI DOI 10.1145/2980055.2980056
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   van der Hooft J, 2019, CONF INNOV CLOUD, P19, DOI 10.1109/ICIN.2019.8685904
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu CL, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P193, DOI 10.1145/3083187.3083210
   Zare A., 2016, P 24 ACM INT C MULT, P601, DOI DOI 10.1145/2964284.2967292
NR 21
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13867
EP 13888
DI 10.1007/s11042-022-12277-5
EA FEB 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761979300011
DA 2024-07-18
ER

PT J
AU Dhiman, G
   Kumar, AV
   Nirmalan, R
   Sujitha, S
   Srihari, K
   Yuvaraj, N
   Arulprakash, P
   Raja, RA
AF Dhiman, Gaurav
   Kumar, A. Vignesh
   Nirmalan, R.
   Sujitha, S.
   Srihari, K.
   Yuvaraj, N.
   Arulprakash, P.
   Raja, R. Arshath
TI Multi-modal active learning with deep reinforcement learning for target
   feature extraction in multi-media image processing applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal active learning; Convolutional neural network; Deep
   reinforcement learning; Feature extraction; Multimedia Streaming Systems
ID ANNOTATION
AB The advancement in on demand Multimedia Streaming Applications (MAS) enables faster video transmission as per the user request in various fields. This system suffers from poor speed, flexibility and efficiency in accessing and presenting the multimedia contents from the archive. It mostly undergoes delay, packet loss and congestion during data delivery. Hence, the requirement of manual annotation is required for access and retrieval but it suffers from poor retrieval accuracy over large databases. The need of automatic annotation in MAS takes the lead for increased retrieval accuracy on most similar image retrieval systems based on various low-level features. Thus, it eliminates the gap between the high-level semantics and low-level feature representation. The approach on automated annotation of images is considered dependent on the accuracy of a model while detecting edges, color, texture, shape and spatial information. In this paper, we develop an automated annotation model that retrieves visually similar images from online multimedia streams with optimal feature extraction. The automated annotation model is designed with a Multi-modal Active Learning (MAL) that uses Convolutional Recurrent Neural Network (CRNN) for automatic annotation of labels based on visually similar contents or features like edges, color, texture, shape and spatial information. Further, a Deep Reinforcement Learning (DRL) algorithm is used that increases the performance of the retrieval engine based on validating the visually extracted features. The simulation of MAL-CNN is conducted over large online streaming databases and it is then validated by DRL on an online real-time streaming. The performance is validated in terms of its retrieval accuracy, sensitivity, specificity, f-measure, geometric mean and mean absolute percentage error (MAPE). The results confirm the accuracy of the proposed MAL-DRL model against conventional machine learning, reinforcement learning and deep learning automatic annotation models.
C1 [Dhiman, Gaurav] Govt Bikram Coll Commerce, Dept Comp Sci, Patiala, Punjab, India.
   [Dhiman, Gaurav] Chandigarh Univ, Univ Ctr Res & Dev, Dept Comp Sci & Engn, Mohali, Punjab, India.
   [Dhiman, Gaurav] Graph Era Deemed Univ, Dept Comp Sci & Engn, Dehra Dun, Uttarakhand, India.
   [Kumar, A. Vignesh] Jai Shriram Engn Coll, Dept Comp Sci & Engn, Tiruppur, Tamil Nadu, India.
   [Nirmalan, R.] Kalasalingam Acad Res & Educ, Dept Comp Sci & Engn, Krishnankoil, Tamil Nadu, India.
   [Sujitha, S.] Sri Vidya Coll Engn & Technol, Dept Comp Sci & Engn, Virudunagar, Tamil Nadu, India.
   [Srihari, K.] SNS Coll Technol, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
   [Yuvaraj, N.] ICT Acad, Training & Res, Chennai, Tamil Nadu, India.
   [Arulprakash, P.] Dept Comp Sci & Engn, Rathinam Tech Campus, Coimbatore 641021, Tamil Nadu, India.
   [Raja, R. Arshath] ICT Acad, Res & Publicat, IIT Madras Res Pk, Chennai, Tamil Nadu, India.
C3 Chandigarh University; Graphic Era University; Kalasalingam Academy of
   Research & Education; SNS College of Technology; Indian Institute of
   Technology System (IIT System); Indian Institute of Technology (IIT) -
   Madras
RP Dhiman, G (corresponding author), Govt Bikram Coll Commerce, Dept Comp Sci, Patiala, Punjab, India.; Dhiman, G (corresponding author), Chandigarh Univ, Univ Ctr Res & Dev, Dept Comp Sci & Engn, Mohali, Punjab, India.; Dhiman, G (corresponding author), Graph Era Deemed Univ, Dept Comp Sci & Engn, Dehra Dun, Uttarakhand, India.
EM gdhiman0001@gmail.com; vigneshkumarun@gmail.com; rnirmalan@yahoo.co.in;
   sujisrinivasan92@gmail.com; harionto@gmail.com; yraj1989@gmail.com;
   amlprakash247@gmail.com; arshathraja.ru@gmail.com
RI Natarajan, Yuvaraj/C-4392-2017; R, Nirmalan/JCO-4101-2023; Dhiman,
   Gaurav/AAP-6925-2020
OI R, Nirmalan/0000-0001-7260-2893; Dhiman, Gaurav/0000-0002-6343-5197;
   Raja R, Arshath/0000-0003-4750-4559
CR AbdelMottaleb M, 1996, PHILIPS J RES, V50, P227, DOI 10.1016/0165-5817(96)81312-X
   Abu-El-Haija Sami, 2016, arXiv
   Alansary A, 2019, MED IMAGE ANAL, V53, P156, DOI 10.1016/j.media.2019.02.007
   Chatterjee I., 2021, Int. J. Mod. Res, V1, P15
   Duraimurugan S, 2020, MULTIMED TOOLS APPL, V79, P4185, DOI 10.1007/s11042-019-07935-0
   Goyal R, 2017, IEEE I CONF COMP VIS, P5843, DOI 10.1109/ICCV.2017.622
   Hashemzehi R, 2020, BIOCYBERN BIOMED ENG, V40, P1225, DOI 10.1016/j.bbe.2020.06.001
   He S, 2021, IRBM, V42, P334, DOI 10.1016/j.irbm.2020.06.001
   Huang G, 2022, IEEE T PATTERN ANAL, V44, P8704, DOI 10.1109/TPAMI.2019.2918284
   Ide H, 2020, PATTERN RECOGN LETT, V135, P90, DOI 10.1016/j.patrec.2020.03.034
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Ke X, 2017, PATTERN RECOGN, V71, P60, DOI 10.1016/j.patcog.2017.05.020
   Khalil T, 2018, IEEE ACCESS, V6, P4560, DOI 10.1109/ACCESS.2018.2791427
   Kiran R, 2020, EXPERT SYST APPL, V157, DOI 10.1016/j.eswa.2020.113488
   Koriem, 2004, J KING SAUD UNIV-COM, V17, P65
   Krishna R, 2017, IEEE I CONF COMP VIS, P706, DOI 10.1109/ICCV.2017.83
   Kumar R., 2021, Int. J. Modern Res, V1, P1, DOI DOI 10.1109/ICMLC.2007.4370325
   Kuminski E, 2018, ASTRON COMPUT, V25, P257, DOI 10.1016/j.ascom.2018.10.008
   Li HL, 2020, BIOCYBERN BIOMED ENG, V40, P787, DOI 10.1016/j.bbe.2020.03.005
   Luo C, 2019, PATTERN RECOGN LETT, V125, P341, DOI 10.1016/j.patrec.2019.05.011
   Mishkin D, 2017, COMPUT VIS IMAGE UND, V161, P11, DOI 10.1016/j.cviu.2017.05.007
   Mishra SR, 2020, PATTERN RECOGN LETT, V135, P329, DOI 10.1016/j.patrec.2020.04.031
   Mo KC, 2019, PROC CVPR IEEE, P909, DOI 10.1109/CVPR.2019.00100
   Piras L, 2017, INFORM FUSION, V37, P50, DOI 10.1016/j.inffus.2017.01.003
   Qi XJ, 2007, PATTERN RECOGN, V40, P728, DOI 10.1016/j.patcog.2006.04.042
   Qin JH, 2020, ECOL INFORM, V58, DOI 10.1016/j.ecoinf.2020.101093
   Real E, 2017, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR.2017.789
   Rohrbach M, 2012, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2012.6247801
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Tian F, 2019, J VIS COMMUN IMAGE R, V58, P544, DOI 10.1016/j.jvcir.2018.12.028
   Tran Dustin, 2016, Edward: A library for probabilistic modeling, inference, and criticism
   Vaishnav P.K., 2021, Int. J. Mod. Res, V1, P22, DOI DOI 10.31838/IJPR/2021.13.01.268
   Wang C, 2020, NEUROCOMPUTING, V382, P64, DOI 10.1016/j.neucom.2019.11.062
   Wang RG, 2017, J VIS COMMUN IMAGE R, V49, P213, DOI 10.1016/j.jvcir.2017.07.004
   Wang R, 2019, SIGNAL PROCESS-IMAGE, V70, P145, DOI 10.1016/j.image.2018.09.013
   Weinzaepfel P, 2016, ARXIV PREPRINT ARXIV
   Xie Y, 2018, EUR J OPER RES, V265, P26, DOI 10.1016/j.ejor.2017.07.052
   Xue Z, 2018, INFORM SCIENCES, V451, P180, DOI 10.1016/j.ins.2018.03.051
   Zafar B, 2018, COMPUT SCI INF SYST, V15, P615, DOI [10.2298/CSIS180105025z, 10.2298/CSIS180105025Z]
   Zhao MB, 2015, KNOWL-BASED SYST, V76, P148, DOI 10.1016/j.knosys.2014.12.014
   Zhao WH, 2018, GEO-SPAT INF SCI, V21, P115, DOI 10.1080/10095020.2018.1441754
   Zhen Z, 2019, ENERG CONVERS MANAGE, V197, DOI 10.1016/j.enconman.2019.111853
NR 42
TC 9
Z9 9
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5343
EP 5367
DI 10.1007/s11042-022-12178-7
EA FEB 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000761979300012
DA 2024-07-18
ER

PT J
AU Fazlali, H
   Shirani, S
   Bradford, M
   Kirubarajan, T
AF Fazlali, Hamidreza
   Shirani, Shahram
   Bradford, Michael
   Kirubarajan, Thia
TI Single image rain/snow removal using distortion type information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rain removal; Snow removal; Convolutional neural network; Dehazing;
   Intensity map; Direction map
ID RAIN STREAKS REMOVAL; MODEL
AB Rainy or snowy weather conditions can severely impair the visual quality of images and videos. The rain streaks or snow particles that may vary in shape and size can also affect high-level computer vision system performance. Therefore, pre-processing of these distorted images prior to any other task is necessary. Moreover, due to the lack of temporal information in single images, removal of these artifacts becomes more challenging. In this paper, both the de-raining and de-snowing problems within a single algorithmic framework using a data-driven approach are addressed. In this method, the spatial characteristics of rain streaks and snow particles are investigated and two maps, namely, direction map and intensity map, are generated and exploited in the removal process. Using these two maps, the type of the distortion is classified using a convolutional neural network (CNN) and this information is used in the removal step, where the input image along with the two extracted maps and the information about the distortion type are used to train a deep fully convolutional rain/snow removal network (RSRNet). This network is trained such that it separates the important background scene edges from rain streaks or snow particles and uses the extracted edge map to augment the quality of the output image. Moreover, single images usually suffer from atmospheric haze in the presence of heavy rain or snow. Therefore, a simple dehazing method based on the dark channel prior (DCP) algorithm, which uses the edge map extracted in the RSRNet, is proposed to build a transmission map for the haze removal task. The experimental results on both the real and synthetic single rainy/snowy images demonstrate the superiority of the proposed method compared to the other rain/snow removal methods.
C1 [Fazlali, Hamidreza; Shirani, Shahram; Bradford, Michael; Kirubarajan, Thia] ITB A-111,1280 Main St West, Hamilton, ON L8S 4K1, Canada.
RP Fazlali, H (corresponding author), ITB A-111,1280 Main St West, Hamilton, ON L8S 4K1, Canada.
EM fazlalih@mcmaster.ca
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Aittala M, 2018, LECT NOTES COMPUT SC, V11212, P748, DOI 10.1007/978-3-030-01237-3_45
   Bossu J, 2011, INT J COMPUT VISION, V93, P348, DOI 10.1007/s11263-011-0421-7
   Brewer N, 2008, LECT NOTES COMPUT SC, V5342, P451, DOI 10.1007/978-3-540-89689-0_49
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen DY, 2014, IEEE T CIRC SYST VID, V24, P1430, DOI 10.1109/TCSVT.2014.2308627
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen YL, 2013, IEEE I CONF COMP VIS, P1968, DOI 10.1109/ICCV.2013.247
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346
   Fu XY, 2020, IEEE T NEUR NET LEAR, V31, P1794, DOI 10.1109/TNNLS.2019.2926481
   Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186
   Fu XY, 2017, IEEE T IMAGE PROCESS, V26, P2944, DOI 10.1109/TIP.2017.2691802
   Girshick R, 2015, IEEE T NEUR NET LEAR
   GRAPS A, 1995, IEEE COMPUT SCI ENG, V2, P50, DOI 10.1109/99.388960
   Gu SH, 2017, IEEE I CONF COMP VIS, P1717, DOI 10.1109/ICCV.2017.189
   Hao D, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013020
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jégou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057
   Kim JH, 2013, IEEE IMAGE PROC, P914, DOI 10.1109/ICIP.2013.6738189
   Kingma D. P., 2014, arXiv
   Lee S, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0104-y
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li MH, 2018, PROC CVPR IEEE, P6644, DOI 10.1109/CVPR.2018.00695
   Li Y, 2017, IEEE T IMAGE PROCESS, V26, P3874, DOI 10.1109/TIP.2017.2708841
   Li Y, 2016, PROC CVPR IEEE, P2736, DOI 10.1109/CVPR.2016.299
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu JY, 2018, PROC CVPR IEEE, P3233, DOI 10.1109/CVPR.2018.00341
   Liu YF, 2018, IEEE T IMAGE PROCESS, V27, P3064, DOI 10.1109/TIP.2018.2806202
   Luo Y, 2015, IEEE I CONF COMP VIS, P3397, DOI 10.1109/ICCV.2015.388
   MANNOS JL, 1974, IEEE T INFORM THEORY, V20, P525, DOI 10.1109/TIT.1974.1055250
   McCartney E. J., 1976, Optics of the atmosphere. Scattering by molecules and particles
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Noroozi M, 2017, LECT NOTES COMPUT SC, V10496, P65, DOI 10.1007/978-3-319-66709-6_6
   Pei Soo-Chang, 2014, IEEE International Conference on Multimedia and Expo Workshops (ICMEW), P1
   Santhaseelan V, 2015, INT J COMPUT VISION, V112, P71, DOI 10.1007/s11263-014-0759-8
   Shen L, 2018, INT C PATT RECOG, P2821, DOI 10.1109/ICPR.2018.8545729
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tang HZ, 2019, IET IMAGE PROCESS, V13, P1797, DOI 10.1049/iet-ipr.2018.5122
   Wang H., 2019, ARXIV190908326
   Wang YL, 2017, IEEE T IMAGE PROCESS, V26, P3936, DOI 10.1109/TIP.2017.2708502
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei W, 2019, PROC CVPR IEEE, P3872, DOI 10.1109/CVPR.2019.00400
   Xu J., 2012, CANADIAN CTR SCI ED, V5, P49, DOI DOI 10.5539/CIS.V5N3P49
   Xu J., 2012, 2012 IEEE INT C COMP, P304
   Xu L, 2014, ADV NEUR IN, V27
   Yang W., 2017, PROC CVPR IEEE, P1685, DOI DOI 10.1109/CVPR.2017.183
   Yasarla R, 2019, PROC CVPR IEEE, P8397, DOI 10.1109/CVPR.2019.00860
   You S, 2016, IEEE T PATTERN ANAL, V38, P1721, DOI 10.1109/TPAMI.2015.2491937
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407
   Zhang H, 2018, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2018.00079
NR 56
TC 6
Z9 6
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14105
EP 14131
DI 10.1007/s11042-022-12012-0
EA FEB 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761979300010
DA 2024-07-18
ER

PT J
AU Shah, A
   Gor, M
   Sagar, M
   Shah, M
AF Shah, Atharva
   Gor, Maharshi
   Sagar, Meet
   Shah, Manan
TI A stock market trading framework based on deep learning architectures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network (CNN); Long short term memory; Deep
   learning architecture
ID PREDICTING STOCK; RETURNS
AB Market prediction has been a key interest for professionals around the world. Numerous modern technologies have been applied in addition to statistical models over the years. Among the modern technologies, machine learning and in general artificial intelligence have been at the core of numerous market prediction models. Deep learning techniques in particular have been successful in modeling the market movements. It is seen that automatic feature extraction models and time series forecasting techniques have been investigated separately however a stacked framework with a variety of inputs is not explored in detail. In the present article, we suggest a framework based on a convolutional neural network (CNN) paired with long-short term memory (LSTM) to predict the closing price of the Nifty 50 stock market index. A CNN-LSTM framework extracts features from a rich feature set and applies time series modeling with a look-up period of 20 trading days to predict the movement of the next day. Feature sets include raw price data of target index as well as foreign indices, technical indicators, currency exchange rates, commodities price data which are all chosen by similarities and well-known trade setups across the industry. The model is able to capture the information based on these features to predict the target variable i.e. closing price with a mean absolute percentage error of 2.54% across 10 years of data. The suggested framework shows a huge improvement on return than the traditional buy and hold method.
C1 [Shah, Atharva] Nirma Univ, Dept Mech Engn, Ahmadabad, Gujarat, India.
   [Gor, Maharshi] Software Engineer Quinbay Technol, Bangalore, Karnataka, India.
   [Sagar, Meet] Data Sci Associate ZS, Pune, Maharashtra, India.
   [Shah, Manan] Pandit Deendayal Petr Univ, Sch Technol, Dept Chem Engn, Gandhinagar, India.
C3 Nirma University; Pandit Deendayal Energy University
RP Shah, A (corresponding author), Nirma Univ, Dept Mech Engn, Ahmadabad, Gujarat, India.
EM manan.shah@spt.pdpu.ac.in
RI Shah, Manan/Y-9430-2019
OI Shah, Manan/0000-0002-8665-5010
CR Agarwal, 2021, INT J FINANCIAL ACCO, V3, P275, DOI [10.35912/ijfam.v3i3.604, DOI 10.35912/IJFAM.V3I3.604]
   Arévalo R, 2017, EXPERT SYST APPL, V81, P177, DOI 10.1016/j.eswa.2017.03.028
   Atsalakis GS, 2009, EXPERT SYST APPL, V36, P5932, DOI 10.1016/j.eswa.2008.07.006
   Avci E., 2007, Forecasting daily and sessional returns of the ISE-100 index with neural network models
   Beck T, 2004, J BANK FINANC, V28, P423, DOI 10.1016/S0378-4266(02)00408-9
   Birz G, 2011, J BANK FINANC, V35, P2791, DOI 10.1016/j.jbankfin.2011.03.006
   Chen K, 2021, ARXIV PREPRINT ARXIV, P1, DOI DOI 10.1061/(ASCE)EY.1943-7897.0000804
   Chollet F., 2017, DEEP LEARNING PYTHON
   Chong E, 2017, EXPERT SYST APPL, V83, P187, DOI 10.1016/j.eswa.2017.04.030
   Choudhry R, 2008, PROC WRLD ACAD SCI E, V29, P315
   Di Persio Luca, 2016, International Journal of Circuits, Systems and Signal Processing, V10, P403
   Egeli B., 2003, P 3 HAW INT C BUS HO
   Ghorbani M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0230124
   Gu SH, 2021, J ECONOMETRICS, V222, P429, DOI 10.1016/j.jeconom.2020.07.009
   Gunduz H, 2021, FINANC INNOV, V7, DOI 10.1186/s40854-021-00243-3
   Gunduz H, 2017, KNOWL-BASED SYST, V137, P138, DOI 10.1016/j.knosys.2017.09.023
   Gupta Anu, 2012, Progress in VLSI Design and Test. Proceedings 16th International Symposium, VDAT 2012, P1, DOI 10.1007/978-3-642-31494-0_1
   Guresen E, 2011, EXPERT SYST APPL, V38, P10389, DOI 10.1016/j.eswa.2011.02.068
   Hiransha M., 2018, Procedia Computer Science, V132, P1351, DOI 10.1016/j.procs.2018.05.050
   Hoseinzade E, 2019, EXPERT SYST APPL, V129, P273, DOI 10.1016/j.eswa.2019.03.029
   Hussain W, 2022, INT J INTELL SYST, V37, P4586, DOI 10.1002/int.22732
   Kara Y, 2011, EXPERT SYST APPL, V38, P5311, DOI 10.1016/j.eswa.2010.10.027
   Khare K, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P482, DOI 10.1109/RTEICT.2017.8256643
   Kimoto T., 1990, IJCNN International Joint Conference on Neural Networks (Cat. No.90CH2879-5), P1, DOI 10.1109/IJCNN.1990.137535
   Manojlovic T, 2015, 2015 8TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1189, DOI 10.1109/MIPRO.2015.7160456
   Mbah TJ, 2021, MINING METALL EXPLOR, V38, P913, DOI 10.1007/s42461-020-00362-y
   Nabipour M, 2020, IEEE ACCESS, V8, P150199, DOI 10.1109/ACCESS.2020.3015966
   Nelson DMQ., 2010, IEEE T NEURAL NETWOR, V21, P1378, DOI [10.1109/tnn.2010.2063350, DOI 10.1109/TNN.2010.2063350]
   Neri, 2002, MONETARY POLICY STOC
   Nikou M, 2019, INTELL SYST ACCOUNT, V26, P164, DOI 10.1002/isaf.1459
   Nousi C., 2021, 2021 6 S E EUR DES A, P1, DOI [DOI 10.1109/SEEDA-CECNSM53056.2021.9566242, 10.1109/SEEDACECNSM53056.2021.9566242, DOI 10.1109/SEEDACECNSM53056.2021.9566242]
   Olson D, 2003, INT J FORECASTING, V19, P453, DOI 10.1016/S0169-2070(02)00058-4
   Pang XW, 2020, J SUPERCOMPUT, V76, P2098, DOI 10.1007/s11227-017-2228-y
   Patel J, 2015, EXPERT SYST APPL, V42, P259, DOI 10.1016/j.eswa.2014.07.040
   Qian B, 2007, APPL INTELL, V26, P25, DOI 10.1007/s10489-006-0001-7
   Radeerom M., 2014, INTELLIGENT INFORM D, V8398, DOI [10.1007/978-3-319-05458-2_43, DOI 10.1007/978-3-319-05458-2_43]
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Selvin S, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1643, DOI 10.1109/ICACCI.2017.8126078
   Shuanglong Liu, 2017, Neural Information Processing. 24th International Conference, ICONIP 2017. Proceedings: LNCS 10635, P198, DOI 10.1007/978-3-319-70096-0_21
   Singh R, 2017, MULTIMED TOOLS APPL, V76, P18569, DOI 10.1007/s11042-016-4159-7
   Wang J, 2015, NEUROCOMPUTING, V156, P68, DOI 10.1016/j.neucom.2014.12.084
   White H., 1988, IEEE International Conference on Neural Networks (IEEE Cat. No.88CH2632-8), P451, DOI 10.1109/ICNN.1988.23959
   Xianggao Cai, 2012, Proceedings of the 2012 IEEE International Conference on Computer Science and Automation Engineering (CSAE 2012), P80, DOI 10.1109/CSAE.2012.6272913
   Yoshihara A, 2014, LECT NOTES ARTIF INT, V8862, P759, DOI 10.1007/978-3-319-13560-1_60
   Youngohc Yoon, 1991, Proceedings of the Twenty-Fourth Annual Hawaii International Conference on System Sciences (Cat. No.91TH0350-9), P156, DOI 10.1109/HICSS.1991.184055
   Zhong X, 2017, EXPERT SYST APPL, V67, P126, DOI 10.1016/j.eswa.2016.09.027
NR 46
TC 7
Z9 7
U1 4
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14153
EP 14171
DI 10.1007/s11042-022-12328-x
EA FEB 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761979300029
PM 35233176
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Wang, J
   Peng, CL
   Li, M
   Li, Y
   Du, SD
AF Wang, Jie
   Peng, Chenglei
   Li, Ming
   Li, Yang
   Du, Sidan
TI The study of stereo matching optimization based on multi-baseline
   trinocular model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Trinocular stereo matching; Multi-baseline; Computer vision; Disparity
   estimation
ID VISION
AB The huge computational complexity, occlusion and low texture region problems make stereo matching a big challenge. In this work, we use multi-baseline trinocular camera model to study how to accelerate the stereo matching algorithms and improve the accuracy of disparity estimation. A special scheme named the trinocular dynamic disparity range (T-DDR) was designed to accelerate the stereo matching algorithms. In this scheme, we optimize matching cost calculation, cost aggregation and disparity computation steps by narrowing disparity searching range. Meanwhile, we designed another novel scheme called the trinocular disparity confidence measure (T-DCM) to improve the accuracy of the disparity map. Based on those, we proposed the semi-global matching with T-DDR (T-DDR-SGM) and T-DCM (T-DCM-SGM) algorithms for trinocular stereo matching. According to the evaluation results, the T-DDR-SGM could not only significantly reduce the computational complexity but also slightly improving the accuracy, while the T-DCM-SGM could excellently handle the occlusion and low texture region problems. Both of them achieved a better result. Moreover, the optimization schemes we designed can be extended to the other stereo matching algorithms which possesses pixel-wise matching cost calculation and aggregation steps not only the SGM. We proved that the proposed optimization methods for the trinocular stereo matching are effective and the trinocular stereo matching is useful for either improving accuracy or reducing computational complexity.
C1 [Wang, Jie; Peng, Chenglei; Li, Ming; Li, Yang; Du, Sidan] Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210023, Jiangsu, Peoples R China.
   [Wang, Jie; Peng, Chenglei] Nanjing Inst Adv Artificial Intelligence, Nanjing 210023, Jiangsu, Peoples R China.
C3 Nanjing University
RP Li, Y; Du, SD (corresponding author), Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210023, Jiangsu, Peoples R China.
EM yogo@nju.edu.cn; coff128@nju.edu.cn
RI Du, Sidan/JVN-2413-2024
OI Du, Sidan/0000-0002-7079-0066
CR Akin Abdulkadir, 2015, 2015 International Symposium on VLSI Design, Automation and Test (VLSI-DAT). Proceedings, P1, DOI 10.1109/VLSI-DAT.2015.7114525
   Dosovitskiy A., 2017, P 1 ANN C ROB LEARN, P1, DOI DOI 10.48550/ARXIV.1711.03938
   El Jaafari I, 2016, NEUROCOMPUTING, V194, P24, DOI 10.1016/j.neucom.2016.02.010
   Gehrig SK, 2009, LECT NOTES COMPUT SC, V5815, P134, DOI 10.1007/978-3-642-04667-4_14
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hirschmüller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56
   Honegger Dominik, 2017, P IEEE ICRA, P5245
   Hu XY, 2012, IEEE T PATTERN ANAL, V34, P2121, DOI 10.1109/TPAMI.2012.46
   Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17
   Lee Kyuho J., 2016, 2016 IEEE Hot Chips 28 Symposium (HCS), DOI 10.1109/HOTCHIPS.2016.7936225
   Li M, 2019, IEICE T INF SYST, VE102D, P1183, DOI 10.1587/transinf.2018EDP7273
   LUO WJ, 2016, PROC CVPR IEEE, P5695, DOI DOI 10.1109/CVPR.2016.614
   MENZE M, 2015, PROC CVPR IEEE, P3061, DOI DOI 10.1109/CVPR.2015.7298925
   Michael M, 2013, IEEE INT VEH SYM, P1197, DOI 10.1109/IVS.2013.6629629
   Narinx J, 2017, SYMP VLSI CIRCUITS, pC228, DOI 10.23919/VLSIC.2017.8008489
   Park H, 2017, IEEE SIGNAL PROC LET, V24, P1788, DOI 10.1109/LSP.2016.2637355
   Pritchett P, 1998, EUR WORKSH 3D STRUCT
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Strecha C, 2010, PROC CVPR IEEE, P406, DOI 10.1109/CVPR.2010.5540184
   Yang WZ, 2012, PROC CVPR IEEE, P1466, DOI 10.1109/CVPR.2012.6247835
   Zagoruyko S., 2015, PROC CVPR IEEE, P4353, DOI DOI 10.1109/CVPR.2015.7299064
   Zbontar J, 2016, J MACH LEARN RES, V17
   Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767
   Zhang K, 2009, IEEE T CIRC SYST VID, V19, P1073, DOI 10.1109/TCSVT.2009.2020478
   Zhou J, 2015, IEEE INT SYM BROADB
NR 26
TC 0
Z9 0
U1 6
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12961
EP 12972
DI 10.1007/s11042-022-12579-8
EA FEB 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000759366800004
DA 2024-07-18
ER

PT J
AU Roy, RK
   Mukherjee, H
   Roy, K
   Pal, U
AF Roy, Ramit Kumar
   Mukherjee, Himadri
   Roy, Kaushik
   Pal, Umapada
TI CNN based recognition of handwritten multilingual city names
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multilingual city names; Mixed script scenario; CNN; Indian postal
   automation
ID CONVOLUTIONAL NEURAL-NETWORK; POSTAL DOCUMENTS; ADDRESS; CLASSIFICATION;
   BANGLA; SYSTEM; MODEL; WORD
AB It is important to recognize the destination city name correctly for a postal document to reach its desired address. In India people often mix up scripts while writing the address. Often the script of the destination city name is different from the other part of the postal document. This is common in India due to the multilingual and multi script nature of the country. In this paper, a Convolutional Neural Network (CNN) based approach towards the recognition of handwritten multilingual multiscript Indian city names is presented. Experiments were performed not only in a single script scenario but also in multi script, considering English, Bangla and Devanagari scripts. An accuracy of 91.72% was obtained on 106 city names in mixed script scenario from the proposed scheme and the data set will be made available to the researcher on request. Further experiments were also performed with different script combinations and obtained results up to 98.01%. The system also produced a mean performance difference of approximately +/- 1% for successive changes in the data set size, thereby pointing to the robustness of the proposed architecture.
C1 [Roy, Ramit Kumar] St Xaviers Coll Autonomous, Kolkata, India.
   [Mukherjee, Himadri; Roy, Kaushik] West Bengal State Univ, Dept Comp Sci, Kolkata, India.
   [Pal, Umapada] Indian Stat Inst, CVPR Unit, Kolkata, India.
C3 St. Xavier's College Kolkata; West Bengal State University; Indian
   Statistical Institute; Indian Statistical Institute Kolkata
RP Roy, K (corresponding author), West Bengal State Univ, Dept Comp Sci, Kolkata, India.
EM ramitkumar.roy@sxccal.edu; himadrim027@gmail.com; kaushik.mrg@gmail.com;
   umapada@isical.ac.in
RI Pal, Umapada/AAC-4930-2022; Roy, Kaushik/O-7021-2019
OI Roy, Kaushik/0000-0002-3360-7576
CR Acharyya A., 2013, International Journal of Computer Science Issues, V10, P422
   [Anonymous], 2012, ACM Transactions on Asian Language Information Processing, DOI [DOI 10.1145/2090176.2090177, DOI 10.1145/2090176]
   Basu S, 2005, SOFT COMPUT, P239
   Bera S, 2020, INT J REMOTE SENS, V41, P2664, DOI 10.1080/01431161.2019.1694725
   Chaudhuri B.B., 1995, J ACOUST SOC INDIA, V23, P67
   Chevtchenko SF, 2018, APPL SOFT COMPUT, V73, P748, DOI 10.1016/j.asoc.2018.09.010
   Gao X, 2012, J INF SCI ENG, V28, P31
   Ghosh D, 2010, IEEE T PATTERN ANAL, V32, P2142, DOI 10.1109/TPAMI.2010.30
   Ghosh M, 2022, VISUAL COMPUT, V38, P1645, DOI 10.1007/s00371-021-02094-6
   Ghosh M, 2019, PROC INT CONF DOC, P86, DOI 10.1109/ICDARW.2019.00020
   Halder C, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418560116
   Hijam D., 2018, 2018 4 INT C COMP CO, P1
   Hou YW, 2017, INT CONF INTEL INFOR, P35, DOI 10.1109/ICIIBMS.2017.8279710
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Kaur H., 2019, DOCUMENT ANAL RECOGN, V1020, P152
   Kaur H, 2021, SOFT COMPUT, V25, P4451, DOI 10.1007/s00500-020-05455-w
   Liu L, 2014, POWER ELECT IEEE T, P1, DOI DOI 10.1109/IWJT.2014.6842058.
   Mukherjee H, 2020, MULTIMED TOOLS APPL, V79, P34913, DOI 10.1007/s11042-019-08553-6
   Nagabhushan P, 2006, LECT NOTES COMPUT SC, V4223, P937
   Nagabhushan P, 2005, LECT NOTES COMPUT SC, V3776, P388
   Nagabhushan P, 2009, APPL SOFT COMPUT, V9, P806, DOI 10.1016/j.asoc.2008.06.005
   Obaidullah SM, 2018, MULTIMED TOOLS APPL, V77, P1643, DOI 10.1007/s11042-017-4373-y
   Olivas-Padilla BE, 2019, APPL SOFT COMPUT, V75, P461, DOI 10.1016/j.asoc.2018.11.031
   Pal Umapada, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1985, DOI 10.1109/ICPR.2010.489
   Pal U., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P456, DOI 10.1109/ICDAR.2009.171
   Pal U, 2012, INT CONF FRONT HAND, P169, DOI 10.1109/ICFHR.2012.238
   Pal U, 2009, IEICE T INF SYST, VE92D, P1146, DOI 10.1587/transinf.E92.D.1146
   Patel MS, 2015, ADV INTELL SYST, V328, P563, DOI 10.1007/978-3-319-12012-6_62
   Rakshit P, 2018, ADV INTELL SYST COMP, V666, P109, DOI 10.1007/978-981-10-8180-4_7
   Roy K, 2005, PROC INT CONF DOC, P1060, DOI 10.1109/ICDAR.2005.259
   Roy K., 2008, THESIS JADAVPUR U
   Roy RK, 2020, MALAYS J COMPUT SCI, V33, P202, DOI 10.22452/mjcs.vol33no3.3
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sang JT, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1354, DOI 10.1145/3123266.3133336
   Sharma N, 2017, INT CONF IMAG VIS
   SHAW B, 2008, 2008 19 INT C PATTER, P1
   Thadchanamoorthy S, 2013, PROC INT CONF DOC, P793, DOI 10.1109/ICDAR.2013.162
   Vajda S, 2009, INT J PATTERN RECOGN, V23, P1599, DOI 10.1142/S0218001409007776
   Wanchoo AnkitaS., 2016, INT J APPL ENG RES, V11, P4529
   Wang Y, 2019, APPL SOFT COMPUT, V74, P40, DOI 10.1016/j.asoc.2018.10.006
   Zhang DX, 2018, CSEE J POWER ENERGY, V4, P362, DOI 10.17775/CSEEJPES.2018.00520
NR 41
TC 3
Z9 3
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11501
EP 11517
DI 10.1007/s11042-022-12193-8
EA FEB 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757777400008
DA 2024-07-18
ER

PT J
AU Tuna, OF
   Catak, FO
   Eskil, MT
AF Tuna, Omer Faruk
   Catak, Ferhat Ozgur
   Eskil, M. Taner
TI Exploiting epistemic uncertainty of the deep learning models to generate
   adversarial samples
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia security; Uncertainty; Adversarial machine learning; Deep
   learning; Loss maximization
ID NEURAL-NETWORK
AB Deep neural network (DNN) architectures are considered to be robust to random perturbations. Nevertheless, it was shown that they could be severely vulnerable to slight but carefully crafted perturbations of the input, termed as adversarial samples. In recent years, numerous studies have been conducted in this new area called ``Adversarial Machine Learning" to devise new adversarial attacks and to defend against these attacks with more robust DNN architectures. However, most of the current research has concentrated on utilising model loss function to craft adversarial examples or to create robust models. This study explores the usage of quantified epistemic uncertainty obtained from Monte-Carlo Dropout Sampling for adversarial attack purposes by which we perturb the input to the shifted-domain regions where the model has not been trained on. We proposed new attack ideas by exploiting the difficulty of the target model to discriminate between samples drawn from original and shifted versions of the training data distribution by utilizing epistemic uncertainty of the model. Our results show that our proposed hybrid attack approach increases the attack success rates from 82.59% to 85.14%, 82.96% to 90.13% and 89.44% to 91.06% on MNIST Digit, MNIST Fashion and CIFAR-10 datasets, respectively.
C1 [Tuna, Omer Faruk; Eskil, M. Taner] Isik Univ Istanbul, Istanbul, Turkey.
   [Catak, Ferhat Ozgur] Univ Stavanger Fornebu, Stavanger, Norway.
C3 Isik University
RP Tuna, OF (corresponding author), Isik Univ Istanbul, Istanbul, Turkey.
EM omer.tuna@isikun.edu.tr; f.ozgur.catak@uis.no; taner.eskil@isikun.edu.tr
OI Tuna, Omer Faruk/0000-0002-6214-6262
CR Aladag M., 2019, INT INF SOFTW ENG C, P1, DOI [10.1109/UBMYK48245.2019.8965459, DOI 10.1109/UBMYK48245.2019.8965459]
   An DD, 2020, J SYST SOFTWARE, V167, DOI 10.1016/j.jss.2020.110617
   Andriushchenko Maksym, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P484, DOI 10.1007/978-3-030-58592-1_29
   [Anonymous], 2014, Multi-digit number recognition from street view imagery using deep convolutional neural networks
   Antonelli F, 2020, FUTURE GENER COMP SY, V102, P746, DOI 10.1016/j.future.2019.09.006
   Ayhan M. S., 2018, Test-time data augmentation for estimation of heteroscedastic aleatoric uncertainty in deep neural networks, P1
   BLUM AL, 1992, NEURAL NETWORKS, V5, P117, DOI 10.1016/S0893-6080(05)80010-3
   Blundell C, 2015, PR MACH LEARN RES, V37, P1613
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Chen JB, 2020, P IEEE S SECUR PRIV, P1277, DOI 10.1109/SP40000.2020.00045
   Chouard T., 2016, Nature, DOI [10.1038/nature.2016.19575, DOI 10.1038/NATURE.2016.19575]
   Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274
   Eaton-Rosen Z, 2018, LECT NOTES COMPUT SC, V11070, P691, DOI 10.1007/978-3-030-00928-1_78
   Finlayson SG, 2019, ADVERSARIAL ATTACKS
   Gal Y, 2016, PR MACH LEARN RES, V48
   Gawlikowski Jakob, 2021, ARXIV210703342
   Ghoshal B., 2020, ARXIV200310769
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Graves Alex, 2011, ADV NEURAL INFORM PR, P2348, DOI DOI 10.5555/2986459.2986721
   Guo CA, 2017, PR MACH LEARN RES, V70
   Gurevich P, 2019, NEUROCOMPUTING, V350, P291, DOI 10.1016/j.neucom.2019.03.031
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoffman MD, 2013, J MACH LEARN RES, V14, P1303
   Huang XW, 2020, COMPUT SCI REV, V37, DOI 10.1016/j.cosrev.2020.100270
   Hullermeier E, 2020, ALEATORIC EPISTEMIC
   Ilyas A, 2019, PRIOR CONVICTIONS BL
   Judd JS., 1990, NEURAL NETWORK DESIG, DOI [10.7551/mitpress/4932.001.0001, DOI 10.7551/MITPRESS/4932.001.0001]
   Kurakin A., 2016, Adversarial machine learning at scale
   Kurakin Alexey, 2017, INT C LEARN REPR
   Lakshminarayanan B, 2017, ADV NEUR IN, V30
   Laves M.H., 2019, arXiv, P1
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu H, 2019, IEEE I CONF COMP VIS, P2941, DOI 10.1109/ICCV.2019.00303
   Loquercio A, 2020, IEEE ROBOT AUTOM LET, V5, P3153, DOI 10.1109/LRA.2020.2974682
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Morgulis N., 2019, FOOLING REAL CAR ADV
   Nair T, 2018, LECT NOTES COMPUT SC, V11070, P655, DOI 10.1007/978-3-030-00928-1_74
   Neal R. M., 2012, BAYESIAN LEARNING NE, V118, DOI DOI 10.1007/978-1-4612-0745-0
   Ozgur Catak F, 2020, A generative model based adversarial security of deep learning and linear classifier models
   Paisley J, 2012, VARIATIONAL BAYESIAN
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Qayyum A, 2020, IEEE COMMUN SURV TUT, V22, P998, DOI 10.1109/COMST.2020.2975048
   Sadeghi K, 2020, IEEE T EM TOP COMP I, V4, P450, DOI [10.1109/TETCI.2020.2968933, 10.1109/tetci.2020.2968933]
   Senge R, 2014, INFORM SCIENCES, V255, P16, DOI 10.1016/j.ins.2013.07.030
   Serban AC, 2019, ADVERSARIAL EXAMPLES
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sitawarin C., 2018, Darts: Deceiving autonomous cars with toxic signs
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tuna OF, 2020, CLOSENESS UNCERTAINT
   Vladu Adrian, 2018, PROC 6 INT C LEARN R
   Xiao H., 2017, ARXIV170807747
   Zheng R, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107046
   Zhou DX, 2018, ANAL APPL, V16, P895, DOI 10.1142/S0219530518500124
NR 56
TC 12
Z9 12
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11479
EP 11500
DI 10.1007/s11042-022-12132-7
EA FEB 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757777400006
PM 35221776
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Ganeshkumar, M
   Ravi, V
   Sowmya, 
   Gopalakrishnan, EA
   Soman, KP
   Chakraborty, C
AF Ganeshkumar, M.
   Ravi, Vinayakumar
   Sowmya, V
   Gopalakrishnan, E. A.
   Soman, K. P.
   Chakraborty, Chinmay
TI Identification of intracranial haemorrhage (ICH) using ResNet with data
   augmentation using CycleGAN and ICH segmentation using SegAN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CycleGAN; Haemorrhage; Intracranial haemorrhage (ICH); ResNet; Deep
   learning
AB Intracranial Haemorrhage (ICH) occurring due to any injury to the brain is a fatal condition and its timely diagnosis is critically important. In this work, we propose a complete one-stop model for the identification of Intracranial Haemorrhage (ICH) and for the segmentation of ICH regions in Computerized Tomography (CT) images. The proposed method incorporates Residual Neural Network (ResNet) architecture for ICH identification and further segments the ICH region using an Adversarial Network called SegAN. This work incorporates a data augmentation method using CycleGAN, to solve the problem of class imbalance in the ICH dataset, leading to improved performance in the ICH identification task. CycleGAN is trained to convert a non-ICH CT slice into a synthetic CT slice with ICH, thereby augmenting the ICH sub-class, where there is a lack of data points. The proposed method achieved a macro average F1-score of 0.91 and a specificity of 0.99 and a sensitivity of 0.80 in the ICH identification task. Also, the proposed method works as a segmentation tool for all the five ICH sub-types and achieved a dice score of 0.32 and a mean Intersection Over Union (IOU) of 0.22. Thus, our proposed ICH identification and segmentation model can aid doctors in the accurate and timely diagnosis of ICH.
C1 [Ganeshkumar, M.; Sowmya, V; Gopalakrishnan, E. A.; Soman, K. P.] Amrita Vishwa Vidyapeetham, Amrita Sch Engn, Ctr Computat Engn & Networking CEN, Coimbatore, Tamil Nadu, India.
   [Ravi, Vinayakumar] Prince Mohammad Bin Fahd Univ, Ctr Artificial Intelligence, Khobar, Khobar, Saudi Arabia.
   [Chakraborty, Chinmay] Birla Inst Technol, Dept Elect & Commun Engn, Ranchi, Jharkhand, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Coimbatore;
   Prince Mohammad Bin Fahd University; Birla Institute of Technology Mesra
RP Ravi, V (corresponding author), Prince Mohammad Bin Fahd Univ, Ctr Artificial Intelligence, Khobar, Khobar, Saudi Arabia.
EM m.ganeshdeveloper@gmail.com; vravi@pmu.edu.sa
RI Chakraborty, Chinmay/N-3608-2017; Ravi, Vinayakumar/L-4202-2018; V,
   Sowmya/R-5897-2017
OI Chakraborty, Chinmay/0000-0002-4385-0975; Ravi,
   Vinayakumar/0000-0001-6873-6469; V, Sowmya/0000-0003-3745-6944
CR Currie S, 2016, POSTGRAD MED J, V92, P41, DOI 10.1136/postgradmedj-2014-133211
   Grewal M, 2018, I S BIOMED IMAGING, P281, DOI 10.1109/ISBI.2018.8363574
   Hssayeni MD, 2020, DATA, V5, DOI 10.3390/data5010014
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Lee H, 2019, NAT BIOMED ENG, V3, P173, DOI 10.1038/s41551-018-0324-9
   Li L, 2021, IEEE J BIOMED HEALTH, V25, P1646, DOI 10.1109/JBHI.2020.3028243
   Nag MK, 2019, INT J COMPUT ASS RAD, V14, P259, DOI 10.1007/s11548-018-1873-9
   Taylor CA, 2017, MMWR SURVEILL SUMM, V66, P1, DOI 10.15585/mmwr.ss6609a1
   van Asch CJJ, 2010, LANCET NEUROL, V9, P167, DOI 10.1016/S1474-4422(09)70340-0
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wu ZF, 2019, PATTERN RECOGN, V90, P119, DOI 10.1016/j.patcog.2019.01.006
   Xue Y, 2018, NEUROINFORMATICS, V16, P383, DOI 10.1007/s12021-018-9377-x
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 13
TC 7
Z9 8
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36257
EP 36273
DI 10.1007/s11042-021-11478-8
EA FEB 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000756332700007
DA 2024-07-18
ER

PT J
AU Zhang, QY
   Zhao, XJ
   Zhang, QW
   Li, YZ
AF Zhang, Qiu-yu
   Zhao, Xue-jiao
   Zhang, Qi-wen
   Li, Yu-zhou
TI Content-based encrypted speech retrieval scheme with deep hashing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encrypted speech retrieval; Deep hashing; Convolutional neural network
   (CNN); Spectrogram; Deep semantic feature
ID FEATURE-EXTRACTION; ALGORITHM; TRANSFORM
AB In order to improve the limitations of manual features and poor feature semantics in the feature extraction process of existing content-based encrypted speech retrieval methods, and as well as improve retrieval accuracy and retrieval efficiency, a content-based encrypted speech retrieval scheme with deep hashing was proposed. Firstly, the original speech file is encrypted by using Henon mapping chaotic encryption to construct encrypted speech library. Secondly, adopting secondary feature extraction method to extract the spectrogram feature, and using the spectrogram as the input of the designed convolutional neural network (CNN) for model training and deep hashing feature learning, to obtain the deep hash binary code of original speech, and upload it to the deep hash index table in the cloud. In addition, the batch normalization (BN) method is introduced to improve robustness and generalization ability of the model. Finally, establish a one-to-one mapping relationship between the encrypt speech in the encrypted speech library and the hash sequence in the deep hash index table. When retrieving for speech users, the normalized Hamming distance algorithm is used for retrieve matching. The experimental results show that the deep hash binary code constructed by the proposed method has strong discriminability and robustness, and it still has high recall rate, precision rate and retrieval efficiency under various general content preserving operations.
C1 [Zhang, Qiu-yu; Zhao, Xue-jiao; Zhang, Qi-wen; Li, Yu-zhou] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
C3 Lanzhou University of Technology
RP Zhang, QY (corresponding author), Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
EM zhangqylz@163.com; wlbzhaoxj@163.com; tdyy2010@126.com;
   alexanderlyz@163.com
RI zhang, qiu/GXG-5600-2022; zhang, qiuyu/V-9223-2019
OI zhang, qiuyu/0000-0003-1488-388X
FU National Natural Science Foundation of China [61862041, 61363078]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61862041, 61363078). The authors also gratefully acknowledge
   the helpful comments and suggestions of the reviewers, which have
   improved the presentation.
CR Ali TS, 2020, IEEE ACCESS, V8, P71974, DOI 10.1109/ACCESS.2020.2987615
   [Anonymous], 2016, INT C CIRC POW COMP, DOI DOI 10.1109/ICCPCT.2016.7530308
   Bartz C, 2017, LECT NOTES COMPUT SC, V10639, P880, DOI 10.1007/978-3-319-70136-3_93
   Bo Zhang, 2018, 2018 International Conference on Intelligent Transportation, Big Data & Smart City (ICITBS). Proceedings, P617, DOI 10.1109/ICITBS.2018.00161
   Choi K, 2017, INT CONF ACOUST SPEE, P2392, DOI 10.1109/ICASSP.2017.7952585
   Dhiraj, 2019, MULTIMED TOOLS APPL, V78, P23949, DOI 10.1007/s11042-018-6706-x
   ElMaghraby E., 2020, EGYPT J LANG ENG, V7, P27, DOI DOI 10.21608/EJLE.2020.22022.1002
   Fan L, 2019, INTERSPEECH, P2908, DOI 10.21437/Interspeech.2019-2457
   Glackin C, 2017, INT CONF ACOUST SPEE, P6414, DOI 10.1109/ICASSP.2017.7953391
   He SF, 2017, COMPUT SCI INF SYST, V14, P703, DOI 10.2298/CSIS170112024H
   Hung JW, 2018, APPL SYST INNOV, V1, DOI 10.3390/asi1030028
   Kim B, 2019, INT CONF ACOUST SPEE, P4100, DOI 10.1109/ICASSP.2019.8683461
   Li HG, 2020, China Patent, Patent No. [CN108366072B, 108366072]
   Li W, 2020, INTERNET THINGS-NETH, V11, DOI 10.1016/j.iot.2020.100180
   Li YN, 2019, MULTIMED TOOLS APPL, V78, P24431, DOI 10.1007/s11042-018-7072-4
   Li Y, 2019, MULTIMED TOOLS APPL, V78, P30585, DOI 10.1007/s11042-018-6414-6
   Nayyar RK, 2017, 2017 INTERNATIONAL CONFERENCE ON BIG DATA, IOT AND DATA SCIENCE (BID), P30, DOI 10.1109/BID.2017.8336569
   Patil NM, 2019, ADV INTELL SYST, V924, P263, DOI 10.1007/978-981-13-6861-5_23
   Qin PL, 2018, COMPUT SCI INF SYST, V15, P517, DOI 10.2298/CSIS171210020Q
   Qin QB, 2019, INT CONF ACOUST SPEE, P2067, DOI 10.1109/ICASSP.2019.8683328
   Shan YH, 2019, ASIAPAC SIGN INFO PR, P650, DOI 10.1109/APSIPAASC47483.2019.9023251
   Sharma Usha, 2015, 2015 International Conference on Futuristic Trends on Computational Analysis and Knowledge Management (ABLAZE). Proceedings, P654, DOI 10.1109/ABLAZE.2015.7154944
   Shi CH, 2020, IEEE ACCESS, V8, P22249, DOI 10.1109/ACCESS.2020.2970093
   Shon S, 2019, INTERSPEECH, P2963, DOI 10.21437/Interspeech.2019-1498
   Tang ZZ, 2019, INT J INNOV COMPUT I, V15, P845, DOI 10.24507/ijicic.15.03.845
   Wang D., 2015, ARXIV PREPRINT ARXIV
   Wang H. X., 2015, China Patent, Patent No. [CN104835499A, 104835499]
   Wang HX, 2014, LECT NOTES COMPUT SC, V8389, P423, DOI 10.1007/978-3-662-43886-2_30
   Winursito Anggun, 2018, 2018 International Conference on Information and Communications Technology (ICOIACT), P379, DOI 10.1109/ICOIACT.2018.8350748
   Xu Y, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P121, DOI 10.1109/ICASSP.2018.8461975
   Zeng FF, 2019, MULTIMED TOOLS APPL, V78, P32419, DOI 10.1007/s11042-019-07980-9
   Zhang QY, 2020, MULTIMED TOOLS APPL, V79, P6337, DOI 10.1007/s11042-019-08450-y
   Zhang QY, 2019, MULTIMED TOOLS APPL, V78, P17825, DOI 10.1007/s11042-019-7180-9
   Zhang QY, 2020, IEEE ACCESS, V8, P148556, DOI 10.1109/ACCESS.2020.3015876
   Zhang QY, 2019, TURK J ELECTR ENG CO, V27, P1719, DOI 10.3906/elk-1808-161
   Zhang SX, 2019, INT CONF ACOUST SPEE, P5691, DOI [10.1109/icassp.2019.8683721, 10.1109/ICASSP.2019.8683721]
   Zhao H, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P1840, DOI 10.1109/FSKD.2016.7603458
NR 37
TC 5
Z9 6
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 10221
EP 10242
DI 10.1007/s11042-022-12123-8
EA FEB 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756497800024
DA 2024-07-18
ER

PT J
AU Maharjan, P
   Alsadoon, A
   Prasad, PWC
   Al-Khalil, AB
   Jerew, OD
   Alsadoon, G
   Chapagain, B
AF Maharjan, Pooja
   Alsadoon, Abeer
   Prasad, P. W. C.
   Al-Khalil, Ahmad B.
   Jerew, Oday D.
   Alsadoon, Ghossoon
   Chapagain, Binod
TI An enhanced algorithm for improving real-time video transmission for
   tele-training education
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surgical tele-training; Distortion minimization; Video quality;
   Heterogeneous wireless networks; Reliability
AB Tele-training in surgical education has not been effectively implemented. There is a stringent need for a high transmission rate, reliability, throughput, and reduced distortion for high-quality video transmission in the real-time network. This work aims to propose a system that improves video quality during real-time surgical tele-training. The proposed approach aims to minimise the video frame's total distortion, ensuring better flow rate allocation and enhancing the video frames' reliability. The proposed system consists of a proposed algorithm for Enhancing Video Quality, Distorting Minimization, Bandwidth efficiency, and Reliability Maximization called (EVQDMBRM) algorithm. The proposed algorithm reduces the video frame's total distortion. In addition, it enhances the video quality in a real-time network by dynamically allocating the flow rate at the video source and maximizing the transmission reliability of the video frames. The result shows that the proposed EVQDMBRM algorithm improves the video quality with the minimized total distortion. Therefore, it improves the Peak Signal to Noise Ratio (PSNR) average by 51.13 dB against 47.28 dB in the existing systems. Furthermore, it reduces the video frames processing time average by 58.2 milliseconds (ms) against 76.1, and the end-to-end delay average by 114.57 ms against 133.58 ms comparing to the traditional methods. The proposed system concentrates on minimizing video distortion and improving the surgical video transmission quality by using an EVQDMBRM algorithm. It provides the mechanism to allocate the video rate at the source dynamically. Besides that, it minimizes the packet loss ratio and probing status, which estimates the available bandwidth.
C1 [Maharjan, Pooja; Alsadoon, Abeer; Prasad, P. W. C.; Chapagain, Binod] Charles Sturt Univ CSU, Sch Comp Math & Engn, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.] Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.] Kent Inst Australia, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Jerew, Oday D.] Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
   [Prasad, P. W. C.] Australian Inst Higher Educ, Sydney, NSW, Australia.
   [Al-Khalil, Ahmad B.] Univ Duhok, Coll Sci, Dept Comp Sci, Duhok, Krg, Iraq.
   [Alsadoon, Ghossoon] AMA Int Univ Bahrain AMAIUB, Business Informat Dept, Salmabad, Bahrain.
C3 Charles Sturt University; Western Sydney University; University of Duhok
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp Math & Engn, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Al-Khalil, Ahmad/AAS-7475-2020; Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Al-Khalil, Ahmad/0000-0002-4855-4147; Alsadoon, A/Prof.
   Abeer/0000-0002-2309-3540; AlSadoon, Ghossoon/0000-0001-7516-7540;
   withana, chandana/0000-0002-3007-687X
CR Bernardo V, 2016, WIRELESS PERS COMMUN, V87, P565, DOI 10.1007/s11277-015-3150-3
   Chapagain B, 2021, MULTIMED TOOLS APPL, V80, P9615, DOI 10.1007/s11042-020-10115-0
   Chernenko EM, 2020, 2 INT SCI PRACT C DI, P663
   Escobar-Castillejos D, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10175752
   Feizi N, 2021, FRONT ROBOT AI, V8, DOI 10.3389/frobt.2021.610677
   Givi B, 2020, HEAD NECK-J SCI SPEC, V42, P1411, DOI 10.1002/hed.26252
   He G, 2018, IEEE COMMUN LETT, V22, P25, DOI 10.1109/LCOMM.2017.2764021
   Huang SW, 2018, IEEE T WIREL COMMUN, V17, P112, DOI 10.1109/TWC.2017.2762680
   Katt BM, 2020, JAAOS GLOB RES REV, V4, DOI 10.5435/JAAOSGlobal-D-20-00127
   Persaud YK, 2021, J ALLER CL IMM-PRACT, V9, P13, DOI 10.1016/j.jaip.2020.10.005
   Sedrati M, 2018, WIRELESS PERS COMMUN, V99, P999, DOI 10.1007/s11277-017-5163-6
   Wei L, 2017, IEEE T CIRC SYST VID, V27, P49, DOI 10.1109/TCSVT.2016.2589621
   Wu JY, 2019, IEEE T MOBILE COMPUT, V18, P458, DOI 10.1109/TMC.2018.2836914
   Wu JY, 2018, IEEE T MULTIMEDIA, V20, P457, DOI 10.1109/TMM.2017.2741425
   Wu JY, 2017, IEEE T MOBILE COMPUT, V16, P1090, DOI 10.1109/TMC.2016.2584049
   Wu JY, 2017, IEEE J SEL AREA COMM, V35, P30, DOI 10.1109/JSAC.2016.2632599
   Wu JY, 2016, IEEE T COMMUN, V64, P2477, DOI 10.1109/TCOMM.2016.2553138
   Wu JY, 2016, IEEE T MOBILE COMPUT, V15, P641, DOI 10.1109/TMC.2015.2426710
   Yan Y, 2018, IEEE T VEH TECHNOL, V67, P6203, DOI 10.1109/TVT.2018.2816822
   Zheng X, 2017, IEEE T MOBILE COMPUT, V16, P1787, DOI 10.1109/TMC.2016.2613529
   Zhu X, 2021, TELEMED E-HEALTH, V27, P441, DOI 10.1089/tmj.2020.0042
NR 21
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8409
EP 8428
DI 10.1007/s11042-022-12045-5
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749966800013
PM 35125927
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Lyle, M
   Sarosh, P
   Parah, SA
AF Lyle, Munazah
   Sarosh, Parsa
   Parah, Shabir A.
TI Adaptive image encryption based on twin chaotic maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Privacy; Security; Quadratic map; Henon map; Brute
   force attack
ID TRANSFORM; SYSTEM
AB The information stored or shared via the internet is growing massively and includes images primarily. The images are vulnerable to attacks when transferred over the internet as they contain confidential information about a person. We propose an adaptive image encryption scheme for the security of images based on twin chaotic maps; Quadratic map and 2-dimensional chaotic Henon map. In the proposed encryption scheme, the Pseudo-Random Number (PRN) sequence for shuffling the pixels has been generated from the Henon map. The PRN sequence for the diffusion process has been produced from the classical Quadratic map. The significant contribution of the presented work is that both the chaotic sequences (for confusion and diffusion) are plain image dependent, making the encryption scheme adaptive and hence highly resilient to brute force attack. Image quality analysis, histogram analysis, correlation coefficient analysis, entropy analysis, key sensitivity analysis, and differential attack analysis have been carried out on eight natural images of size 512 x 512 to validate the performance of the proposed encryption scheme. The proposed encryption algorithm has correlation coefficient values that are very close to zero, entropy value of 7.9993 (average), Net Pixels Change Rate (NPCR), and Unified Average Changing Intensity (UACI) values of 99.62% (average) and 33.3% (average) respectively. The histogram of the encrypted images is flat, meaning no information can be deduced about the plain image. The comparison of the proposed encryption technique with other recent encryption schemes validates the performance of the proposed cryptosystem. The computational time taken to encrypt Lena image of size 512 x 512 using the proposed encryption scheme is 0.25 s.
C1 [Lyle, Munazah; Sarosh, Parsa; Parah, Shabir A.] Univ Kashmir, Post Grad Dept Elect & Instrumentat Technol, Srinagar, India.
C3 University of Kashmir
RP Parah, SA (corresponding author), Univ Kashmir, Post Grad Dept Elect & Instrumentat Technol, Srinagar, India.
EM shabireltr@gmail.com
RI Sarosh, Parsa/GYV-3178-2022
OI Sarosh, Parsa/0000-0001-5760-9667; Parah, Shabir/0000-0001-5983-0912
FU Department of Science and Technology (DST) New Delhi, Government of
   India
FX The authors would like to thank the Department of Science and Technology
   (DST) New Delhi, Government of India for providing financial support
   under the DST Inspire Fellowship Scheme.
CR Abdelfatah RI, 2020, MULTIMED TOOLS APPL, V79, P19717, DOI 10.1007/s11042-020-08788-8
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   AlZu'bi S, 2020, PATTERN RECOGN LETT, V130, P312, DOI 10.1016/j.patrec.2018.07.026
   Arab A, 2019, J SUPERCOMPUT, V75, P6663, DOI 10.1007/s11227-019-02878-7
   Askar SS, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21010044
   Chai XL, 2019, MULTIMED TOOLS APPL, V78, P35419, DOI 10.1007/s11042-019-08168-x
   Chatterjee G., 2017, AUSTR U POW ENG C AU, P1
   Darwish SM, 2019, MULTIMED TOOLS APPL, V78, P19229, DOI 10.1007/s11042-019-7256-6
   Ferdush J, 2021, ADV MULTIMED, V2021, DOI 10.1155/2021/5527295
   Gayathri J., 2016, International Journal of Information and Computer Security, V8, P347
   Ge B, 2021, IEEE ACCESS, V9, P137635, DOI 10.1109/ACCESS.2021.3118377
   Gopalakrishnan T, 2019, WIRELESS PERS COMMUN, V109, P437, DOI 10.1007/s11277-019-06573-x
   Gupta MD, 2021, INTEGRATION, V81, P137, DOI 10.1016/j.vlsi.2021.07.002
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hosny KM, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091066
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Huang LL, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/3965281
   Idrees B, 2020, MULTIMED TOOLS APPL, V79, P6135, DOI 10.1007/s11042-019-08282-w
   Islam N, 2016, SIGNAL PROCESS-IMAGE, V41, P15, DOI 10.1016/j.image.2015.11.003
   Khan JS, 2019, MULTIDIM SYST SIGN P, V30, P943, DOI 10.1007/s11045-018-0589-x
   Khan MA, 2017, J MOD OPTIC, V64, P531, DOI 10.1080/09500340.2016.1246680
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Li CH, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/8132547
   Li T, 2020, IEEE ACCESS, V8, P13792, DOI 10.1109/ACCESS.2020.2966264
   Li Z, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/8824915
   Lin CY, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22050589
   Liu DD, 2018, SIGNAL PROCESS, V151, P130, DOI 10.1016/j.sigpro.2018.05.008
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Mishra K, 2019, P ICACIE 2017, V1
   Mondal B, 2021, J REAL-TIME IMAGE PR, V18, P1, DOI 10.1007/s11554-019-00940-4
   Mondal B, 2019, J INF SECUR APPL, V45, P117, DOI 10.1016/j.jisa.2019.01.010
   Ramadan N., 2016, AM J SIGNAL PROCESS, V6, P1, DOI DOI 10.5923/J
   Ramasamy P, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21070656
   Tang ZJ, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/8694678
   Tian JF, 2021, MULTIMED TOOLS APPL, V80, P32841, DOI 10.1007/s11042-021-11218-y
   Wang HX, 2020, PATTERN RECOGN LETT, V130, P64, DOI 10.1016/j.patrec.2018.08.010
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Yan XP, 2021, MULTIMED TOOLS APPL, V80, P10949, DOI 10.1007/s11042-020-10218-8
   Yasser I, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/9597619
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhan P., 2018, SECURE TECHNOL APPL, V9, P42
   Zhang XC, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/6919675
   Zhu SL, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21080790
   Zhu SQ, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22070772
NR 44
TC 12
Z9 12
U1 6
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8179
EP 8198
DI 10.1007/s11042-022-11917-0
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749407800001
DA 2024-07-18
ER

PT J
AU Sarosh, P
   Parah, SA
   Bhat, GM
AF Sarosh, Parsa
   Parah, Shabir A.
   Bhat, G. Mohiuddin
TI An efficient image encryption scheme for healthcare applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical images; Biomedical systems; Privacy; Security; Healthcare; Image
   Encryption; Big data
AB In recent years, there has been an enormous demand for the security of image multimedia in healthcare organizations. Many schemes have been developed for the security preservation of data in e-health systems however the schemes are not adaptive and cannot resist chosen and known-plaintext attacks. In this contribution, we present an adaptive framework aimed at preserving the security and confidentiality of images transmitted through an e-healthcare system. Our scheme utilizes the 3D-chaotic system to generate a keystream which is used to perform 8-bit and 2-bit permutations of the image. We perform pixel diffusion by a key-image generated using the Piecewise Linear Chaotic Map (PWLCM). We calculate an image parameter using the pixels of the image and perform criss-cross diffusion to enhance security. We evaluate the scheme's performance in terms of histogram analysis, information entropy analysis, statistical analysis, and differential analysis. Using the scheme, we obtain the average Number of Pixels Change Rate (NPCR) and Unified Average Changing Intensity (UACI) values for an image of size 256 x 256 equal to 99.5996 and 33.499 respectively. Furthermore, the average entropy is 7.9971 and the average Peak Signal to Noise Ratio (PSNR) is 7.4756. We further test the scheme on 50 chest X-Ray images of patients having COVID-19 and viral pneumonia and found the average values of variance, PSNR, entropy, and Structural Similarity Index (SSIM) to be 257.6268, 7.7389, 7.9971, and 0.0089 respectively. Furthermore, the scheme generates completely uniform histograms for medical images which reveals that the scheme can resist statistical attacks and can be applied as a security framework in AI-based healthcare.
C1 [Sarosh, Parsa; Parah, Shabir A.] Univ Kashmir, Post Grad Dept Elect & Instrumentat Technol, Srinagar, India.
   [Bhat, G. Mohiuddin] Inst Technol, Dept Elect & Commun Engn, New Delhi, India.
C3 University of Kashmir
RP Parah, SA (corresponding author), Univ Kashmir, Post Grad Dept Elect & Instrumentat Technol, Srinagar, India.
EM shabireltr@gmail.com
RI Sarosh, Parsa/GYV-3178-2022
OI Sarosh, Parsa/0000-0001-5760-9667
FU Department of Science and Technology (DST) New Delhi, Government of
   India [DST/INSPIRE/03/2018/000093]
FX The authors would like to thank the Department of Science and Technology
   (DST) New Delhi, Government of India for providing financial support
   under the DST Inspire Fellowship Scheme with reference number
   DST/INSPIRE/03/2018/000093.
CR Abdulla AA, 2020, IET IMAGE PROCESS, V14, P4435, DOI 10.1049/iet-ipr.2020.0978
   Alghafis A, 2021, MULTIMED TOOLS APPL, V80, P7967, DOI 10.1007/s11042-020-10142-x
   Alshehri F, 2021, IEEE ACCESS, V9, P3660, DOI 10.1109/ACCESS.2020.3047960
   An FP, 2019, J SENSORS, V2019, DOI 10.1155/2019/2768121
   Askar SS, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21010044
   Belfiore MP, 2020, RADIOL MED, V125, P500, DOI 10.1007/s11547-020-01195-x
   Chai XL, 2019, MULTIMED TOOLS APPL, V78, P35419, DOI 10.1007/s11042-019-08168-x
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Ferdush J, 2021, ADV MULTIMED, V2021, DOI 10.1155/2021/5527295
   Fouad H, 2020, MEASUREMENT, V159, DOI 10.1016/j.measurement.2020.107757
   Hossain MB, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV)
   Kaw JA, 2019, INT J INFORM MANAGE, V45, P262, DOI 10.1016/j.ijinfomgt.2018.09.008
   Khade P.N., 2012, Int. J. Comput. Sci. Issues, V9, P323
   Li T, 2020, IEEE ACCESS, V8, P13792, DOI 10.1109/ACCESS.2020.2966264
   Malik MGA, 2020, IEEE ACCESS, V8, P88093, DOI 10.1109/ACCESS.2020.2990170
   Masood F, 2022, WIRELESS PERS COMMUN, V127, P1405, DOI 10.1007/s11277-021-08584-z
   Mohamed Heba G, 2020, Entropy (Basel), V22, DOI 10.3390/e22020158
   Mohammed ZF, 2021, MULTIMED TOOLS APPL, V80, P6355, DOI 10.1007/s11042-020-10066-6
   Mohan S, 2019, IEEE ACCESS, V7, P81542, DOI 10.1109/ACCESS.2019.2923707
   Muhammad G, 2021, IEEE J SEL AREA COMM, V39, P603, DOI 10.1109/JSAC.2020.3020654
   Muhammad G, 2019, IEEE NETWORK, V33, P44, DOI 10.1109/MNET.001.1900045
   Noorbakhsh-Sabet N, 2019, AM J MED, V132, P795, DOI 10.1016/j.amjmed.2019.01.017
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Kari AP, 2021, MULTIMED TOOLS APPL, V80, P2753, DOI 10.1007/s11042-020-09648-1
   Rong G, 2020, ENGINEERING-PRC, V6, P291, DOI 10.1016/j.eng.2019.08.015
   Sadek I, 2019, LECT NOTES COMPUT SC, V11862, P3, DOI 10.1007/978-3-030-32785-9_1
   Sarosh P, 2021, BIG DATA RES, V25, DOI 10.1016/j.bdr.2021.100225
   Shaw JA, 2021, INTENS CARE MED, V47, P157, DOI 10.1007/s00134-020-06277-y
   Tariq S, 2020, MULTIMED TOOLS APPL, V79, P23507, DOI 10.1007/s11042-020-09134-8
   Tsafack N, 2020, IEEE ACCESS, V8, P137731, DOI 10.1109/ACCESS.2020.3010794
   Wan YJ, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22020171
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Zareai D, 2021, MULTIMED TOOLS APPL, V80, P18317, DOI 10.1007/s11042-021-10576-x
   Zhan K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013021
   [朱从旭 Zhu Congxu], 2012, [电子与信息学报, Journal of Electronics & Information Technology], V34, P1735
NR 35
TC 28
Z9 28
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7253
EP 7270
DI 10.1007/s11042-021-11812-0
EA JAN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000746780700004
PM 35095330
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Shi, TQ
   Li, CQ
   Xu, D
   Fan, XY
AF Shi, Tangqi
   Li, Chaoqun
   Xu, Dou
   Fan, Xiayue
TI Fine-grained histopathological cell segmentation through residual
   attention with prior embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cell segmentation; Feature extraction; Multiscale convolution; Residual
   attention; Prior embedding
AB In the task of histopathological cell segmentation, traditional algorithms struggle with cell edge processing, which leads to the blurring of cell edges. To strengthen the ability to learn the features of cell edges, this paper develops a novel deep neural network for robust and fine-grained cell segmentation. The proposed deep model mines global and local features by multiscale convolution and dilated convolution. Subsequently, the residual attention module is introduced in the third to fifth layers of the encoder; this module assigns a group of weight coefficients to all the deep features to boost the segmentation performance. In addition, to further improve the quality of the features in the decoder, we first introduce the strategy of U-Net for the extraction of prior information, where we filter the fused features and compress the features by using the prior information and the filtered features again to integrate more semantic information into the feature refinement in the decoding process. We tested the model on three public data sets: Multiorgan Nucleus Segmentation (MoNuSeg) (Dice 94.9%), Triple Negative Breast Cancer (TNBC) (Dice 95.4%) and Data Science Bowl (Dice 98.2%). Extensive experiments demonstrate the superior performance of our proposed method in comparison with that of state-of-the-art models; our method can effectively identify cell edges to produce fine-grained segmentation results.
C1 [Shi, Tangqi; Li, Chaoqun; Xu, Dou; Fan, Xiayue] Xi An Jiao Tong Univ, Sch Software Engn, Xian, Peoples R China.
C3 Xi'an Jiaotong University
RP Shi, TQ (corresponding author), Xi An Jiao Tong Univ, Sch Software Engn, Xian, Peoples R China.
EM stq5626@stu.xjtu.edu.cn
RI Li, Chao/GSM-8117-2022
OI Li, Chao/0000-0001-6110-6210
CR An FP, 2021, MULTIMED TOOLS APPL, V80, P15017, DOI 10.1007/s11042-021-10515-w
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Ben Naceur M, 2020, MED IMAGE ANAL, V63, DOI 10.1016/j.media.2020.101692
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Fang X, 2021, PROC SPIE, V11313, DOI 10.1117/12.2549382
   Fe, 2017, CVPR
   Gao H, 2020, IEEE ACCESS, V8, P142483, DOI 10.1109/ACCESS.2020.3013898
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Kaggle, 2018, KAGGLE 2018 DATA SCI
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Lee H, 2018, I S BIOMED IMAGING, P1538, DOI 10.1109/ISBI.2018.8363866
   Lei BY, 2021, MULTIMED TOOLS APPL, V80, P36341, DOI 10.1007/s11042-021-11208-0
   Li C, 2020, COMPUT GRAPH-UK, V90, P11, DOI 10.1016/j.cag.2020.05.003
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Naylor P, 2019, IEEE T MED IMAGING, V38, P448, DOI 10.1109/TMI.2018.2865709
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shen Wei, 2015, Inf Process Med Imaging, V24, P588, DOI 10.1007/978-3-319-19992-4_46
   Sinha A., 2020, IEEE J BIOMED HEALTH
   Thoben KD, 1998, ADV DES MAN, V8, P453
   Tran ST, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9010054
   Valanarasu Jeya Maria Jose, 2021, Medical Image Computing and Computer Assisted Intervention - MICCAI 2021: 24th International Conference, Proceedings. Lecture Notes in Computer Science, Image Processing, Computer Vision, Pattern Recognition, and Graphics (12901), P36, DOI 10.1007/978-3-030-87193-2_4
   Vidyarthi A, 2020, MULTIMED TOOLS APPL, V79, P28105, DOI 10.1007/s11042-020-09357-9
   Wang B, 2020, ARXIV PREPRINT ARXIV
   Wang ZS, 2020, MULTIMED TOOLS APPL, V79, P32525, DOI 10.1007/s11042-020-09641-8
   Xia HY, 2020, NEURAL PROCESS LETT, V51, P2915, DOI 10.1007/s11063-020-10230-x
   Xinpeng Xie, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12265), P341, DOI 10.1007/978-3-030-59722-1_33
   Yang J, 2022, MULTIMED TOOLS APPL, V81, P35983, DOI 10.1007/s11042-021-10841-z
   You HF, 2021, KNOWL-BASED SYST, V231, DOI 10.1016/j.knosys.2021.107456
   Yu F., 2015, ARXIV
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 35
TC 0
Z9 1
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6497
EP 6511
DI 10.1007/s11042-021-11835-7
EA JAN 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000742319000002
DA 2024-07-18
ER

PT J
AU Minoofam, SAH
   Bastanfard, A
   Keyvanpour, MR
AF Minoofam, Seyyed Amir Hadi
   Bastanfard, Azam
   Keyvanpour, Mohammad Reza
TI RALF: an adaptive reinforcement learning framework for teaching dyslexic
   students
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Educational multimedia; Integrated communication; Intelligent tutoring
   system; Orthographic knowledge; Pandemic crisis
ID CHILDREN; SYSTEM; GENERATION; AUTOMATA; CONTEXT
AB Dyslexia is a learning disorder in which individuals have significant reading difficulties. Previous studies found that using machine learning techniques in content supplements is vital in adapting the course concepts to the learners' educational level. However, to the best of our knowledge, no research objectively applied machine learning methods to adaptive content generation. This study introduces an adaptive reinforcement learning framework known as RALF through Cellular Learning Automata (CLA) to generate content automatically for students with dyslexia. At first, RALF generates online alphabet models as a simplified font. CLA structure learns each rule of character generation through the reinforcement learning cycle asynchronously. Second, Persian words are generated algorithmically. This process also considers each character's state to decide the alphabet cursiveness and the cells' response to the environment. Finally, RALF can generate long texts and sentences using the embedded word-formation algorithm. The spaces between words are proceeds through the CLA neighboring states. Besides, RALF provides word pronunciation and several exams and games to improve the learning performance of people with dyslexia. The proposed reinforcement learning tool enhances students' learning rate with dyslexia by almost 27% compared to the face-to-face approach. The findings of this research show the applicability of this approach in dyslexia treatment during Lockdown of COVID-19.
C1 [Minoofam, Seyyed Amir Hadi; Bastanfard, Azam] Islamic Azad Univ, Dept Comp Engn, Karaj Branch, Karaj, Iran.
   [Keyvanpour, Mohammad Reza] Alzahra Univ, Fac Engn, Dept Comp Engn, Tehran, Iran.
C3 Islamic Azad University; Alzahra University
RP Bastanfard, A (corresponding author), Islamic Azad Univ, Dept Comp Engn, Karaj Branch, Karaj, Iran.
EM minoofam@qiau.ac.ir; bastanfard@kiau.ac.ir; keyvanpour@alzahra.ac.ir
RI Keyvanpour, Mohammad Reza/AAL-5574-2020; Bastanfard, Azam/AAX-8571-2020
OI Keyvanpour, Mohammad Reza/0000-0003-2115-9099; Bastanfard,
   Azam/0000-0002-7935-819X
CR AHUJA M, 1995, LEONARDO, V28, P41, DOI 10.2307/1576154
   Al Abodi J, 2014, COMPUT ELECTR ENG, V40, P1883, DOI 10.1016/j.compeleceng.2014.04.014
   Alghabban WG, 2017, COMPUT HUM BEHAV, V75, P160, DOI 10.1016/j.chb.2017.05.014
   Ali S, 2021, MULTIMED TOOLS APPL, V80, P33329, DOI 10.1007/s11042-021-11414-w
   Aljojo N, 2020, EDUC TECHNOL SOC, V23, P47
   Almaiah MA, 2020, EDUC INF TECHNOL, V25, P5261, DOI 10.1007/s10639-020-10219-y
   [Anonymous], 2003, SHARIF J SCI TECHNOL
   Arifoglu D, 2015, PATTERN ANAL APPL, V18, P601, DOI 10.1007/s10044-014-0437-z
   Bastanfard A, 2010, LECT NOTES COMPUT SC, V6298, P705, DOI 10.1007/978-3-642-15696-0_65
   Bastanfard A, 2009, LECT NOTES COMPUT SC, V5879, P1080, DOI 10.1007/978-3-642-10467-1_104
   Bastanfard A, 2009, IEEE SYS MAN CYBERN, P169, DOI 10.1109/ICSMC.2009.5346591
   Beigy H, 2004, ADV COMPLEX SYST, V7, P295, DOI 10.1142/S0219525904000202
   Beigy H, 2008, AUTOMATICA, V44, P1350, DOI 10.1016/j.automatica.2007.09.018
   Beigy H, 2007, ADV COMPLEX SYST, V10, P527, DOI 10.1142/S0219525907001264
   Beigy H, 2010, IEEE T SYST MAN CY B, V40, P54, DOI 10.1109/TSMCB.2009.2030786
   Benmarrakchi FE, 2017, INT J CLOUD APPL COM, V7, P1, DOI 10.4018/IJCAC.2017040101
   Berget G, 2016, INT J HUM-COMPUT ST, V92-93, P17, DOI 10.1016/j.ijhcs.2016.04.006
   Blom E, 2017, COMPUT HUM BEHAV, V66, P42, DOI 10.1016/j.chb.2016.09.010
   Botvinick M, 2019, TRENDS COGN SCI, V23, P408, DOI 10.1016/j.tics.2019.02.006
   Carlotto T, 2016, INT J HUM-COMPUT ST, V95, P15, DOI 10.1016/j.ijhcs.2016.06.001
   Cordón O, 1999, INT J INTELL SYST, V14, P1123, DOI 10.1002/(SICI)1098-111X(199911)14:11<1123::AID-INT4>3.0.CO;2-6
   Nguyen CT, 2019, PATTERN RECOGN LETT, V121, P140, DOI 10.1016/j.patrec.2018.07.025
   Daloiso M., 2017, Supporting learners with dyslexia in the ELT classroom
   DAVIDSON RB, 1997, P S DOC IM UND TECHN, P303
   Dehshibi MM, 2015, AIP CONF PROC, V1648, DOI 10.1063/1.4912823
   Redondo RPD, 2021, MULTIMED TOOLS APPL, V80, P3121, DOI 10.1007/s11042-020-09523-z
   Dimauro G, 2020, IEEE ACCESS, V8, P19564, DOI 10.1109/ACCESS.2020.2968367
   Drotár P, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-78611-9
   Edwards A, 2019, COMPUT HUM BEHAV, V90, P308, DOI 10.1016/j.chb.2018.08.042
   Emtiyaz S, 2012, ARXIV12011670
   Esnaashari M, 2015, IEEE T CYBERNETICS, V45, P1622, DOI 10.1109/TCYB.2014.2356591
   Ezatzadeh S, 2019, MULTIMED TOOLS APPL, V78, P25515, DOI 10.1007/s11042-019-7720-3
   Farhady H., 2013, ASSESSING FARSI COMP, V4, P1790
   Franceschini S, 2019, NEUROPSYCHOLOGIA, V130, P100, DOI 10.1016/j.neuropsychologia.2018.10.023
   Gelsomini M, 2021, MULTIMED TOOLS APPL, V80, P34843, DOI 10.1007/s11042-021-11164-9
   Hagelkruys D, 2016, COMPUT HUM BEHAV, V63, P757, DOI 10.1016/j.chb.2016.05.069
   Hajihashemi V., 2020, 2020 INT C MACH VIS, P1, DOI DOI 10.1109/MVIP49855.2020.9116913
   Kardan AA, 2015, ARTIF INTELL REV, V44, P365, DOI 10.1007/s10462-015-9430-1
   Kastner MA, 2020, MULTIMED TOOLS APPL, V79, P18167, DOI 10.1007/s11042-019-08571-4
   Keyvanpour MR, 2021, MULTIMED TOOLS APPL, V80, P20449, DOI 10.1007/s11042-021-10730-5
   Keyvanpour MR, 2021, MULTIMED TOOLS APPL, V80, P13879, DOI 10.1007/s11042-020-10418-2
   Keyvanpour MR, 2020, MULTIMED TOOLS APPL, V79, P31819, DOI 10.1007/s11042-020-09485-2
   Keyvanpour MR, 2015, GLOB J INF TECHNOL, V4
   Khan FA, 2019, CLUSTER COMPUT, V22, pS7099, DOI 10.1007/s10586-017-1036-8
   Knoop-van Campen CAN, 2020, COMPUT EDUC, V150, DOI 10.1016/j.compedu.2020.103858
   Kumar M, 2020, ARTIF INTELL REV, V53, P2075, DOI 10.1007/s10462-019-09727-2
   Kumar M, 2019, NEURAL PROCESS LETT, V50, P43, DOI 10.1007/s11063-018-9913-6
   Kumar M, 2017, P NATL A SCI INDIA A, V87, P137, DOI 10.1007/s40010-016-0284-y
   LUNDBERG I, 1993, COMPUT HUM BEHAV, V9, P283, DOI 10.1016/0747-5632(93)90012-H
   Minoofam SAH, 2015, 2015 4 IRANIAN JOINT, P1
   Minoofam SAH, 2017, 2017 IR C EL ENG
   Minoofam SAH, 2008, MATH COMPUT SCI ENG, P339
   Minoofam SAH, 2023, IEEE T NEUR NET LEAR, V34, P2480, DOI 10.1109/TNNLS.2021.3106705
   Minoofam SAH, 2012, J CELL AUTOM, V7, P321
   Minoofam SAH, 2010, LECT NOTES COMPUT SC, V6350, P79
   Modhej N, 2020, PATTERN SEPARATION N
   Moradi Mohammad, 2020, International Journal of Electronic Business, V15, P368, DOI 10.1504/IJEB.2020.111061
   Moradi M, 2015, SECUR COMMUN NETW, V8, P2135, DOI 10.1002/sec.1157
   Movahedi Z, 2021, MULTIMED TOOLS APPL, V80, P26773, DOI 10.1007/s11042-021-10968-z
   Mulenga EM., 2020, Eurasia Journal of Mathematics, Science and Technology Education, V16, DOI DOI 10.29333/EJMSTE/8345
   Mushtaq F, 2021, NEURAL COMPUT APPL, V33, P15229, DOI 10.1007/s00521-021-06144-x
   Narang SR, 2021, MULTIMED TOOLS APPL, V80, P20671, DOI 10.1007/s11042-021-10775-6
   Narendra K. S., 2012, Learning Automata: An Introduction
   Ojeda-Castelo JJ, 2021, MULTIMED TOOLS APPL, V80, P6675, DOI 10.1007/s11042-020-10026-0
   Parray IR, 2020, SOFT COMPUT, V24, P16509, DOI 10.1007/s00500-020-04957-x
   Peng XL, 2018, INT J HUM-COMPUT ST, V109, P26, DOI 10.1016/j.ijhcs.2017.08.001
   Phelps C, 2021, IEEE T PROF COMMUN, V64, P250, DOI 10.1109/TPC.2021.3089859
   Pise A, 2022, MULTIMED TOOLS APPL, V81, P26633, DOI 10.1007/s11042-020-10133-y
   Prabu A, 2021, INT J AMBIENT ENERGY, V42, P981, DOI 10.1080/01430750.2019.1583128
   Rello L, 2016, ACM T ACCESS COMPUT, V8, DOI 10.1145/2897736
   Rohani AR., 2016, UCT J RES SCI ENG TE, V4, P11
   Rubio G, 2014, MULTIMED TOOLS APPL, V71, P1771, DOI 10.1007/s11042-012-1304-9
   Sabetfard M, 2019, NEXUS NETW J, P1
   Saeed-Ul Hassan, 2019, INT J INTELL SYST, V34, P1935, DOI 10.1002/int.22129
   Sakkal M, 2018, J MATH ARTS, V12, P65, DOI 10.1080/17513472.2018.1468178
   Salehi F, 2021, J AMB INTEL HUM COMP, P1
   Salehi F, 2021, INFORM SCIENCES, V578, P297, DOI 10.1016/j.ins.2021.07.037
   Kumar MS, 2022, SILICON-NETH, V14, P629, DOI 10.1007/s12633-020-00886-4
   Shaker N., 2016, Procedural Content Generation in Games, P31
   Simonnet D, 2019, PATTERN RECOGN LETT, V121, P133, DOI 10.1016/j.patrec.2018.07.021
   Simonnet D, 2017, PATTERN RECOGN, V69, P310, DOI 10.1016/j.patcog.2017.04.003
   Sintema E. J., 2020, EURASIA J MATH SCI T, V16, DOI DOI 10.29333/EJMSTE/7893
   Sipior JC, 2020, INT J INFORM MANAGE, V55, DOI 10.1016/j.ijinfomgt.2020.102170
   Smith C., 2020, Innovative Technologies and Learning Third International Conference, ICITL 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12555), P504, DOI 10.1007/978-3-030-63885-6_55
   Srivastava B, 2017, J KING SAUD U INF SC
   Takbiri Y, 2019, 2019 5 IR C SIGN PRO, P1, DOI [10.1109/ICSPIS48872.2019.9066006, DOI 10.1109/ICSPIS48872.2019.9066006]
   Taskov Tihomir, 2021, Intelligent Computing. Proceedings of the 2021 Computing Conference. Lecture Notes in Networks and Systems (LNNS 285), P233, DOI 10.1007/978-3-030-80129-8_18
   Thomas Michael S C, 2020, Prospects (Paris), V49, P87, DOI 10.1007/s11125-020-09468-z
   Truong HM, 2016, COMPUT HUM BEHAV, V55, P1185, DOI 10.1016/j.chb.2015.02.014
   Ullah F, 2020, MULTIMED TOOLS APPL, V79, P8581, DOI 10.1007/s11042-018-5827-6
   Vafashoar R, CELLULAR LEARNING AU
   Vaivre-Douret L, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-79315-w
   van der Linden R, 2014, IEEE T COMP INTEL AI, V6, P78, DOI 10.1109/TCIAIG.2013.2290371
   Viner RM, 2020, LANCET CHILD ADOLESC, V4, P397, DOI 10.1016/S2352-4642(20)30095-X
   WANER S, 1988, INT J INTELL SYST, V3, P19, DOI 10.1002/int.4550030103
   Waters TEA, 2019, CURR OPIN PSYCHOL, V25, P162, DOI 10.1016/j.copsyc.2018.08.002
   Wolfram S, 1986, WORLD SCI
   Wu ZM, 2019, IEICE T INF SYST, VE102D, P147, DOI 10.1587/transinf.2017EDP7224
   Zhang ZN, 2021, MULTIMED TOOLS APPL, V80, P575, DOI 10.1007/s11042-020-09684-x
   Zomarshidi, 2001, IRANIAN ARCHITECTURE
NR 100
TC 19
Z9 19
U1 4
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6389
EP 6412
DI 10.1007/s11042-021-11806-y
EA JAN 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000741624700002
PM 35035266
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Gelmecha, DJ
   Singh, RS
   Sinha, DK
   Tekilu, D
AF Gelmecha, Demissie J.
   Singh, Ram S.
   Sinha, Devendra K.
   Tekilu, Dereje
TI Automated health detection of congestive heart failure subject using
   rank multiresolution wavelet packet attributes and 1-norm linear
   programming ELM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bhatacharya ranking method; Regularization parameters; Multiresolution
   Wavelet Packet (MRWP) decomposition; Quadrature mirror filter
ID EXTREME LEARNING-MACHINE; FEATURE-EXTRACTION; CLASSIFICATION;
   OPTIMIZATION; PREDICTION; DIAGNOSIS; NETWORKS; DEATH; PCA
AB As far as the mortality of the global population is concerned, it is cardiovascular diseases which cause the highest death rate worldwide, mostly due to the Congestive Heart Failure (CHF). Therefore, an initial detection and diagnosis of CHF becomes essential. This manuscript presents a novel approach to detect health of CHF subject which is based on Multiresolution Wavelet Packet (MRWP) decomposition method, attributes ranking approach, kernel principle component analysis (KPCA) and 1 - Norm Linear Programming Extreme Learning Machine (1 - NLPELM). For this investigation, the heart rate variability (HRV) signal has been decomposed up to 5-level using MRWP decomposition method. The sixty three log root mean square (LRMS) attributes were extracted from the decomposed HRV signal. The top ten attributes are selected by ranking approaches such asFisher, Wilcoxon,Entropy, Bhattacharya, and receiver operating characteristic( ROC). The ten ranked attributes were then mapped to one new feature by KPCA and fed to1 - NLPELM. The HRV database of normal subjects (normal sinus rhythm( NSR), age 22-45 years old and elderly (ELY), age 60-82 years old) and CHF subjects (age 32-71 years old) were obtained from PhysioNet ATM. The simulation results demonstrated that Bhatacharya + KPCA with 1 - NLPELM approach achieved an accuracy of98.44 +/- 1.4%, 99.13 +/- 1.85 % for NSR - CHF and ELY - CHF respectively. Out of all ranking methods, Bhatacharya combined with KPCA + 1 - NLPELM provided the highest degree of accuracy for all datasets. In addition, the proposed method has also achieved very good generalization performance and less execution time as compared to1 - NLPELM, KPCA + PNN, KPCA + SVM, probabilistic neural network ( PNN) and support vector machine (SVM).
C1 [Gelmecha, Demissie J.; Singh, Ram S.; Tekilu, Dereje] Adama Sci & Technol Univ, Sch Elect Engn & Comp, Elect & Commun Eng Dept SIG, Adama 1888, Ethiopia.
   [Sinha, Devendra K.] Adama Sci & Technol Univ, Ctr Excellence Adv Mfg Engg, Sch Mech Chem & Mat Engn, Mech Design & Mfg Eng Dept, Adama, Ethiopia.
C3 Adama Science & Technology University; Adama Science & Technology
   University
RP Singh, RS (corresponding author), Adama Sci & Technol Univ, Sch Elect Engn & Comp, Elect & Commun Eng Dept SIG, Adama 1888, Ethiopia.
EM gelmechad@gmail.com; ramsewaknitj@gmail.com; ds3621781@gmail.com;
   dereteklu@gmail.com
RI Gelmecha, Demissie/ABB-8141-2020
OI Gelmecha, Demissie/0000-0002-7948-8285
CR Acharya R, 2004, PHYSIOL MEAS, V25, P1139, DOI 10.1088/0967-3334/25/5/005
   ALGRA A, 1991, CIRCULATION, V83, P1888, DOI 10.1161/01.CIR.83.6.1888
   Aran O, 2010, PATTERN RECOGN, V43, P1776, DOI 10.1016/j.patcog.2009.12.002
   Asl BM, 2008, ARTIF INTELL MED, V44, P51, DOI 10.1016/j.artmed.2008.04.007
   Babaoglu I, 2010, EXPERT SYST APPL, V37, P3177, DOI 10.1016/j.eswa.2009.09.064
   Bartlett PL, 1998, IEEE T INFORM THEORY, V44, P525, DOI 10.1109/18.661502
   Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980
   Braunschweig F, 2010, EUROPACE, V12, P1673, DOI 10.1093/europace/euq316
   Cao JW, 2012, INFORM SCIENCES, V185, P66, DOI 10.1016/j.ins.2011.09.015
   Castiglioni P, 2018, COMPLEXITY, DOI 10.1155/2018/4801924
   Ding SF, 2015, ARTIF INTELL REV, V44, P103, DOI 10.1007/s10462-013-9405-z
   Dua S, 2012, J MECH MED BIOL, V12, DOI 10.1142/S0219519412400179
   Ebrahimzadeh Elias., 2011, J BIOMEDICAL SCI ENG, V04, P699, DOI DOI 10.4236/JBISE.2011.411087
   Gao YL, 2020, MULTIMED TOOLS APPL, V79, P32285, DOI 10.1007/s11042-020-09477-2
   Giri D, 2013, KNOWL-BASED SYST, V37, P274, DOI 10.1016/j.knosys.2012.08.011
   Hallstrom AP, 2005, INT J CARDIOL, V100, P37, DOI 10.1016/j.ijcard.2004.05.047
   Hemamalini B, 2020, MULTIMED TOOLS APPL, V79, P8727, DOI 10.1007/s11042-018-6096-0
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huang GB, 2011, INT J MACH LEARN CYB, V2, P107, DOI 10.1007/s13042-011-0019-y
   Huang GB, 2010, NEUROCOMPUTING, V74, P155, DOI 10.1016/j.neucom.2010.02.019
   Huikuri HV, 2003, J AM COLL CARDIOL, V42, P652, DOI 10.1016/S0735-1097(03)00783-6
   Hussain L, 2020, MATH BIOSCI ENG, V18, P69, DOI 10.3934/mbe.2021004
   Kampouraki A, 2009, IEEE T INF TECHNOL B, V13, P512, DOI 10.1109/TITB.2008.2003323
   Karimi M., 2005, 3rd IEE International Seminar on Medical Applications of Signal Processing, P117, DOI 10.1049/ic:20050342
   Khushaba RN, 2011, IEEE T BIO-MED ENG, V58, P121, DOI 10.1109/TBME.2010.2077291
   Li KZ, 2020, IEEE J BIOMED HEALTH, V24, P603, DOI 10.1109/JBHI.2019.2908488
   Li SQ, 2020, MULTIMED TOOLS APPL, V79, P32065, DOI 10.1007/s11042-020-09510-4
   Linder, 2013, ESSENTIAL GUIDE BLOO, P97, DOI [10.1002/9781118327517.ch9, DOI 10.1002/9781118327517.CH9]
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Patel Dilip R, 2011, Asian J Sports Med, V2, P120
   Poddar Monappa Gundappa, 2015, Journal of Medical Engineering & Technology, V39, P331, DOI 10.3109/03091902.2015.1063721
   Richman JS, 2000, AM J PHYSIOL-HEART C, V278, pH2039
   Singh RS, 2018, IRBM, V39, P54, DOI 10.1016/j.irbm.2017.12.004
   Singh RS, 2018, INT J MULTISCALE COM, V16, P465, DOI 10.1615/IntJMultCompEng.2018026587
   Singh RS, 2018, BIOMED ENG-APP BAS C, V30, DOI 10.4015/S1016237218500163
   Tamil EM, 2008, IFMBE PROC, V21, P107
   Tang J., 2014, Data Classification, V37, DOI DOI 10.1201/B17320
   Vollmer M, 2015, COMPUT CARDIOL CONF, V42, P609, DOI 10.1109/CIC.2015.7410984
   Xie LP, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20216318
NR 41
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19587
EP 19608
DI 10.1007/s11042-021-11562-z
EA JAN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000740429700030
DA 2024-07-18
ER

PT J
AU Rathee, DS
   Yadav, R
   Ahuja, K
AF Rathee, Davinder Singh
   Yadav, Ritu
   Ahuja, Kiran
TI Reduction of drain induced barrier lowering by optimization Trimetal-
   GAA -Si -NW MOSFET in multimedia tools
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Short channel effects; DIBL(Drain induce barrier lowering); Trimetal
   asymmetrical gate all around; Enhanced multimedia tools performance
ID ANALYTICAL-MODEL; THRESHOLD VOLTAGE; GATE
AB To keep continue the miniaturization of VLSI technology a Trimetal asymmetrical gate all around (TG-GAA) device is proposed to narrow the short channel effects of the scaling down of devices in terms of the improved subthreshold slope by reducing the leakage current up to 2.37E(-13) A and have the better control on the channel at lower supply voltages from 0.1 V to 1 V. The analytical electrical field distribution, channel length characterization and potential profile of the proposed device based on Gate all around Silicon nanowire MOSFET channel are enclosed by the Trimetal gate have been observed Using 2-D Poisson equation by considering parabolic approximation with appropriate boundary condition in cylindrical coordinates. Further subthreshold drain current model is derived by applying derived potential profile at subthreshold condition by considering the diffusion transportation. The surface & centre potential has been carried out to satisfy the basic optimum parameters for this new structure, which further supports that the DIBL effects was been minimized and observed that by reducing silicon thickness at (tSi =5 nm) lower leakage current 2.37E-13A and improved drain current(Id) of 2.159E-05A is obtained. Further proposed device exhibit decline DIBL of 23.3 mV/V, magnificent subthreshold slope 63.5 mV/decade and improved higher threshold voltage improved ON/OFF ratio. Additionally, well agreement has been observed between the derived 2-D analytical model with the simulated results obtained from numerical simulator Cogenda visual TCAD.
C1 [Rathee, Davinder Singh] ADAMA Univ Sci & Technol, Dept ECE, SOEEC, Adama, Ethiopia.
   [Rathee, Davinder Singh; Yadav, Ritu; Ahuja, Kiran] MDU, EE Dept, UIET, Rohtak, Haryana, India.
   [Yadav, Ritu; Ahuja, Kiran] Punjab Tech Univ, ECE Dept, Jalandhar, Punjab, India.
C3 Maharshi Dayanand University; I. K. Gujral Punjab Technical University
RP Rathee, DS (corresponding author), ADAMA Univ Sci & Technol, Dept ECE, SOEEC, Adama, Ethiopia.; Rathee, DS (corresponding author), MDU, EE Dept, UIET, Rohtak, Haryana, India.
EM davinder.rathee@astu.edu.et; raoritu14@gmail.com; askahuja2002@gmail.com
OI Singh Rathee, Dr. Davinder/0000-0002-4382-1824
CR Arora N., 1993, MOSFET MODELS VLSI C
   Colinge JP, 2004, SOLID STATE ELECTRON, V48, P897, DOI 10.1016/j.sse.2003.12.020
   Committee, 2007, INT TECHNOLOGY ROADM, P1
   Dennard R.H., 1972, IEEE INT ELECT DEVIC, V18, P168
   Dubey S, 2013, IEEE T NANOTECHNOL, V12, P766, DOI 10.1109/TNANO.2013.2273805
   El Hamid HA, 2007, IEEE T ELECTRON DEV, V54, P572, DOI 10.1109/TED.2006.890595
   Iniguez B., 2005, COMPACT MODEL MULTIP
   Iñiguez B, 2006, IEEE T ELECTRON DEV, V53, P2128, DOI 10.1109/TED.2006.881007
   Iwai H, 2011, SCI CHINA INFORM SCI, V54, P1004, DOI 10.1007/s11432-011-4220-0
   Karbalaei M, 2020, RESULTS PHYS, V16, DOI 10.1016/j.rinp.2019.102823
   Kaur A, 2019, AEU-INT J ELECTRON C, V111, DOI 10.1016/j.aeue.2019.152888
   Kranti A, 2001, MICROELECTR J, V32, P305, DOI 10.1016/S0026-2692(01)00008-8
   Lee Y., 2020, Semiconductor Science and Technology, V35, p03LT01
   Moore G.E., 1975, Progress in digital integrated electronics
   Moore G. E., 1965, Cramming more components onto integrated circuits
   Narula V, 2019, SEMICOND SCI TECH, V34, DOI 10.1088/1361-6641/ab3cac
   Pal A, 2014, ENG SCI TECHNOL, V17, P205, DOI 10.1016/j.jestch.2014.06.002
   Pradhan KP, 2015, AIN SHAMS ENG J, V6, P1171, DOI 10.1016/j.asej.2015.04.009
   Rahou FZ, 2016, IETE J RES, V62, P331, DOI 10.1080/03772063.2015.1084898
   Rewari S, 2018, IEEE T ELECTRON DEV, V65, P3, DOI 10.1109/TED.2017.2771814
   Suh CH, 2011, J SEMICOND TECH SCI, V11, P111, DOI 10.5573/JSTS.2011.11.2.111
   Sun Y, 2021, J OCEANOL LIMNOL, V39, P732, DOI 10.1007/s00343-019-9216-4
   Sze SM., 2007, PHYS SEMICONDUCTOR D, P247
   Tiwari PK, 2016, J COMPUT ELECTRON, V15, P516, DOI 10.1007/s10825-016-0819-0
NR 24
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19849
EP 19862
DI 10.1007/s11042-021-11518-3
EA JAN 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000740429700003
DA 2024-07-18
ER

PT J
AU Vishwakarma, A
   Bhuyan, MK
AF Vishwakarma, Amit
   Bhuyan, M. K.
TI A curvelet-based multi-sensor image denoising for KLT-based image fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-sensor image denoising; Curvelet; Meyer window; Unequally-spaced
   fast Fourier transform (USFFT); Wrapping window (WW); Multi-sensor image
   fusion; Karhunen-Loeve transform (KLT)
ID CONTOURLET TRANSFORM; MULTIRESOLUTION; FRAMEWORK; CLASSIFICATION;
   SELECTION; FEATURES; WAVELET
AB The transform-based multi-sensor image denoising methods are inefficient in restoring fine details and texture information of noisy images. The fixed and non-adaptive curvelet transform (CT) design limits its performance in image denoising tasks. Moreover, the Karhunen-Loeve Transform (KLT)-based multi-sensor image fusion techniques premise that high variance's first two principal components are an excellent option for weights used for the weighted average multi-sensor source images. However, the selected weights are non-optimal in this method, considering the less relevant information of source images. The experimental section has several examples showing the key advantages of the proposed optimized CT-based natural image denoising technique over seven existing denoising methods. First, our image denoising method introduces a modified Meyer window (used in unequally-spaced fast Fourier transform (USFFT))-based novel optimized USFFT CT (OUSFFT CT) and a modified wrapping window (WW)-based novel optimized WW CT (OWW CT) to address non-adaptive nature of curvelet transform. These windows are used for the decomposition of noisy source images into low- and high-frequency coefficients. The coefficients are hard thresholds to remove the noisy artifacts in the source image. Moreover, the denoised images are used for fusion purposes to obtain fused images with less noise. Secondly, our proposed image fusion method presents an optimized algorithm to fuse multi-sensor source images. In this method, KLT based weights are optimized by considering more relative information of source images and improve the fused image's information interpretation capability. The qualitative and quantitative evaluations of fused images show that our method provides better fusion results than five different state-of-the-art medical, multi-focus, and infrared image fusion methods. The proposed image denoising method has 1% and 2.2% increment on average of PSNR and SSIM values, respectively, compared to existing state-of-the-art methods. The proposed image fusion method has a 9.04% increment on the average value of image fusion metrics compared to existing state-of-the-art methods.
C1 [Vishwakarma, Amit] Pandit Dwarka Prasad Mishra Indian Inst Informat, Discipline Elect & Commun Engn, Jabalpur 482005, India.
   [Bhuyan, M. K.] Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur; Indian Institute of Technology System (IIT System); Indian
   Institute of Technology (IIT) - Guwahati
RP Vishwakarma, A (corresponding author), Pandit Dwarka Prasad Mishra Indian Inst Informat, Discipline Elect & Commun Engn, Jabalpur 482005, India.
EM amity@iiitdmj.ac.in; mkb@iitg.ac.in
RI Vishwakarma, Amit/ABE-7268-2020
OI Vishwakarma, Amit/0000-0002-0591-8940
CR Achanta SDM, 2019, SOFT COMPUT, V23, P8359, DOI 10.1007/s00500-019-04108-x
   Aishwarya N, 2018, MULTIMED TOOLS APPL, V77, P9719, DOI 10.1007/s11042-017-5562-4
   Aymaz S, 2020, MULTIMED TOOLS APPL, V79, P13311, DOI 10.1007/s11042-020-08670-7
   Bavirisetti DP, 2016, IEEE SENS J, V16, P203, DOI 10.1109/JSEN.2015.2478655
   Bhateja V, 2015, IEEE SENS J, V15, P6783, DOI 10.1109/JSEN.2015.2465935
   Bhatnagar G, 2013, IEEE T MULTIMEDIA, V15, P1014, DOI 10.1109/TMM.2013.2244870
   Candes E.J., 2000, CURVE SURFACE FITTIN, P105
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   CHAVEZ PS, 1991, PHOTOGRAMM ENG REM S, V57, P295
   Chen T, 2005, INT GEOSCI REMOTE SE, P1150
   Choi J, 2011, IEEE T GEOSCI REMOTE, V49, P295, DOI 10.1109/TGRS.2010.2051674
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Fauvel M, 2006, IEEE T GEOSCI REMOTE, V44, P2828, DOI 10.1109/TGRS.2006.876708
   Gao GR, 2013, IET IMAGE PROCESS, V7, P633, DOI 10.1049/iet-ipr.2012.0558
   Gao HT, 2020, MULTIMED TOOLS APPL, V79, P9657, DOI 10.1007/s11042-017-5399-x
   Gao R, 2017, IEEE SIGNAL PROC LET, V24, P943, DOI 10.1109/LSP.2017.2696055
   Huo FC, 2021, MULTIMED TOOLS APPL, V80, P14101, DOI 10.1007/s11042-020-10428-0
   Jin C, 2020, MULTIMED TOOLS APPL, V79, P20947, DOI 10.1007/s11042-020-08871-0
   Jin C, 2019, MULTIMED TOOLS APPL, V78, P28331, DOI 10.1007/s11042-019-07912-7
   Khare A, 2021, MULTIMED TOOLS APPL, V80, P11491, DOI 10.1007/s11042-020-10184-1
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   Li ST, 2008, PATTERN RECOGN LETT, V29, P1295, DOI 10.1016/j.patrec.2008.02.002
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li ST, 2010, IEEE SENS J, V10, P1519, DOI 10.1109/JSEN.2010.2041924
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Meraoumia A, 2011, IEEE ICC
   Nomura K, 2018, IEEE SIGNAL PROC LET, V25, P893, DOI 10.1109/LSP.2018.2831630
   Papyan V, 2016, IEEE T IMAGE PROCESS, V25, P249, DOI 10.1109/TIP.2015.2499698
   Paramanandham N, 2018, MULTIMED TOOLS APPL, V77, P32133, DOI 10.1007/s11042-018-6233-9
   Rahman MM, 2011, IEEE T INF TECHNOL B, V15, P640, DOI 10.1109/TITB.2011.2151258
   Redondo R, 2009, INFORM FUSION, V10, P163, DOI 10.1016/j.inffus.2008.08.006
   Sahu S, 2019, MULTIMED TOOLS APPL, V78, P4089, DOI 10.1007/s11042-017-5221-9
   SDMTK Achanta, 2020, INT J INTELL UNMANNE, V8, P43
   SHETTIGARA VK, 1992, PHOTOGRAMM ENG REM S, V58, P561
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Summers D, 2003, J NEUROL NEUROSUR PS, V74, P288, DOI 10.1136/jnnp.74.3.288
   Swathika R, 2020, MULTIMED TOOLS APPL, V79, P4239, DOI 10.1007/s11042-019-07872-y
   Valsesia D, 2020, IEEE T IMAGE PROCESS, V29, P8226, DOI 10.1109/TIP.2020.3013166
   Verma R, 2018, MULTIMED TOOLS APPL, V77, P549, DOI 10.1007/s11042-016-4227-z
   Vishwakarma A., 2018, IEEE T INSTRUM MEAS, P1
   Vishwakarma A, 2020, MULTIMED TOOLS APPL, V79, P23599, DOI 10.1007/s11042-020-09124-w
   Vishwakarma A, 2018, J VIS COMMUN IMAGE R, V57, P48, DOI 10.1016/j.jvcir.2018.10.005
   Vishwakarma A, 2018, MULTIMED TOOLS APPL, V77, P32013, DOI 10.1007/s11042-018-6254-4
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JY, 2009, IEEE SIGNAL PROC LET, V16, P97, DOI 10.1109/LSP.2008.2010070
   Wu J, 2020, MULTIMED TOOLS APPL, V79, P34795, DOI 10.1007/s11042-019-08194-9
   Xu J, 2020, IEEE T IMAGE PROCESS, V29, P9316, DOI 10.1109/TIP.2020.3026622
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang C, 2008, INFORM FUSION, V9, P156, DOI 10.1016/j.inffus.2006.09.001
   Yang SY, 2010, INFORM FUSION, V11, P78, DOI 10.1016/j.inffus.2009.05.001
   Yang Y, 2016, IEEE SENS J, V16, P3735, DOI 10.1109/JSEN.2016.2533864
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zheng YH, 2018, MULTIMED TOOLS APPL, V77, P30121, DOI 10.1007/s11042-018-6360-3
   Zhou X, 2014, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2014-19
NR 56
TC 3
Z9 3
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 4991
EP 5016
DI 10.1007/s11042-021-11570-z
EA JAN 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000740429700034
DA 2024-07-18
ER

PT J
AU Gugnani, V
   Singh, RK
AF Gugnani, Veena
   Singh, Rajeev Kumar
TI Analysis of deep learning approaches for air pollution prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Air pollution; LSTM; Particulate matter; Spatiotemporal
   deep learning
AB Due to the urban and industrial growth, many evolving countries suffer from excessive air pollution. The growing concern about air pollution has been raised by the government and people because it affects individual's health and sustainable development globally. Recent methods for the prediction of air quality primarily use vast models; furthermore, these approaches yield inconsistent results, inspiring us to inspect air quality prediction methods based on deep learning architectures. While there is a range of efforts in the literature to figure pollution levels, recent developments in deep learning techniques, along with the incorporation of more data, offer more precise predictive accuracy. The paper analyses the previous deep learning frameworks proposed for air quality prediction. This paper discusses and reviews the different deep learning architectures with their advantages and disadvantages for air pollution forecasting.
C1 [Gugnani, Veena; Singh, Rajeev Kumar] Madhav Inst Sci & Technol, Gwalior, Madhya Pradesh, India.
C3 Madhav Institute of Technology & Science
RP Gugnani, V (corresponding author), Madhav Inst Sci & Technol, Gwalior, Madhya Pradesh, India.
EM veenaaneja@gmail.com; rajeev.mits1@gmail.com
RI Singh, Rajeev Kumar/HKN-4005-2023
OI Singh, Rajeev Kumar/0000-0003-1009-3637
CR [Anonymous], 2017, EPA, V53, P1689, DOI DOI 10.1017/CBO9781107415324.004
   Athira V., 2018, Procedia Computer Science, V132, P1394, DOI 10.1016/j.procs.2018.05.068
   CAI J, 2020, MATH PROBL ENG, V2020
   Chao K., 2014, LEARNING PHRASE REPR
   Chaterjee, 2019, IMPLEMENTATION RNN L
   Chugh, 2019, DEEP LEARNING INTRO
   Cigizoglu HK, 2005, NATO SCI S SS IV EAR, V54, P63
   Delgado A, 2020, INT J ADV COMPUT SC, V11, P318
   Deng L, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/atsip.2013.9
   Diaz, 2018, INTELLIGENT TRANSPOR, DOI 10.1007/s00521-018-3850-1
   Donnelly A, 2015, ATMOS ENVIRON, V103, P53, DOI 10.1016/j.atmosenv.2014.12.011
   DRNN, DEEP REC NEUR NETW D
   [范竣翔 Fan Junxiang], 2017, [测绘科学, Science of Surveying and Mapping], V42, P76
   Freeman BS, 2018, J AIR WASTE MANAGE, V68, P866, DOI 10.1080/10962247.2018.1459956
   Guo CY, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8854649
   Gupta S, 2020, CONCURRENT ENG-RES A, V28, DOI 10.1177/1063293X19891770
   Hable-Khandekar V, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, CONTROL AND AUTOMATION (ICCUBEA)
   Health Effects Institute, 2017, Special Report
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang CJ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072220
   Ibrahim H, 2020, 8 INT S DIG FOR SEC, DOI 10.1109/ISDFS49300.2020.9116286
   Jeya S, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P736, DOI [10.1109/iciccs48265.2020.9120932, 10.1109/ICICCS48265.2020.9120932]
   Kaya K, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-60102-6
   Khan A, 2018, DEEP REINFORCEMENT L, P1
   Kostadinov S., 2017, Understanding GRU Networks. Towards Data Science
   Krishana V, 2018, MEDIUM
   Kumar SV, 2015, P 2 ACM SIGSPATIAL I, V4, P664
   Le VD, 2020, INT CONF BIG DATA, P55, DOI 10.1109/BigComp48618.2020.00-99
   Lee P, 2018, ATMOSPHERE-BASEL, V9, DOI 10.3390/atmos9030089
   Li LF, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020264
   Li XH, 2016, ENVIRON SCI POLLUT R, V23, P19341, DOI 10.1007/s11356-016-7143-x
   Liao Q, 2020, CURR POLLUT REP, V6, P399, DOI 10.1007/s40726-020-00159-z
   Logan, ALL CHEM IS DRIVEN P
   Lv YS, 2015, IEEE T INTELL TRANSP, V16, P865, DOI 10.1109/TITS.2014.2345663
   Miglionico M.:., 2019, A Deep Learning Framework for Air Pollution Forecasting and Interpolation
   NOAA, 2001, AIR QUAL RES SUBC CO
   Pandey VK., 2020, J CRIT REV, V7, P1170, DOI [10.31838/jcr.07.10.230, DOI 10.31838/JCR.07.10.230]
   Qi YL, 2019, SCI TOTAL ENVIRON, V664, P1, DOI 10.1016/j.scitotenv.2019.01.333
   Saha S., 2018, A comprehensive guide to convolutional neural networks-the ELI5 way, DOI 10.1080/09640560500294277
   Sánchez-Balseca J, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e04794
   Seng DW, 2021, ALEX ENG J, V60, P2021, DOI 10.1016/j.aej.2020.12.009
   Septiawan WM, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON INFORMATICS AND COMPUTATIONAL SCIENCES (ICICOS), P196
   Sharp Tom., 2020, INTRO SUPPORT VECTOR
   Singh, 2018, DEEP BILIEF NETWORKS
   Soh PW, 2018, IEEE ACCESS, V6, P38186, DOI 10.1109/ACCESS.2018.2849820
   Sun XT, 2019, PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P1265
   Thaweephol K, 2019, INT CONF ICT KNOWL, P22, DOI 10.1109/ictke47035.2019.8966854
   Tsai YT, 2018, 2018 16TH IEEE INT CONF ON DEPENDABLE, AUTONOM AND SECURE COMP, 16TH IEEE INT CONF ON PERVAS INTELLIGENCE AND COMP, 4TH IEEE INT CONF ON BIG DATA INTELLIGENCE AND COMP, 3RD IEEE CYBER SCI AND TECHNOL CONGRESS (DASC/PICOM/DATACOM/CYBERSCITECH), P1074, DOI 10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.00178
   Walczak S., 2003, Artificial Neural Networks, V3rd
   Xayasouk T, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12062570
   Xu XH, 2021, IEEE T CYBERNETICS, V51, P2577, DOI 10.1109/TCYB.2019.2945999
   Yazdan, STACKED AUTOENCODERS
   Zhang B, 2020, ENVIRON MODELL SOFTW, V124, DOI 10.1016/j.envsoft.2019.104600
   Zhang L, 2020, IEEE ACCESS, V8, P66037, DOI 10.1109/ACCESS.2020.2985657
   Zhang L, 2021, ATMOS POLLUT RES, V12, P328, DOI 10.1016/j.apr.2020.09.003
   Zhang Q, 2020, SCI TOTAL ENVIRON, V724, DOI 10.1016/j.scitotenv.2020.138178
   Zhou XL, 2020, EARTH SCI INFORM, V13, P859, DOI 10.1007/s12145-020-00470-9
NR 57
TC 9
Z9 10
U1 8
U2 96
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 6031
EP 6049
DI 10.1007/s11042-021-11734-x
EA JAN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000739252400002
DA 2024-07-18
ER

PT J
AU Agarwal, N
   Singh, PK
AF Agarwal, Namita
   Singh, Pradeep Kumar
TI Discrete cosine transforms and genetic algorithm based watermarking
   method for robustness and imperceptibility of color images for
   intelligent multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Genetic algorithm; Transform domain technique;
   DCT; Peak signal to noise ratio (PSNR); Normalized cross-correlation
   (NCC)
ID DWT-SVD; DCT; DOMAIN; SCHEME
AB Due to developments in the Internet and communication technology, the world has become an international parish in a digital era. The number of bits is generated, replicated, and transferred through the internet or mobile phones in the blink of an eye. Digital watermarking is implemented to assure and provide data authentication, copyright protection to such type of transmission. This paper presents a robust and imperceptible watermarking technique that is achieved with the combination of discrete cosine transform (DCT) and the genetic algorithm for color images. In this paper, DCT transform is based on dividing the cover image into 8X8 blocks, and a genetic algorithm is employed here for answering the optimization problem of digital watermarking as it plays a major role in obtaining an optimized solution. So main advantage of the proposed work can be described as the selection of the best pixel group for embedding so the quality of the watermarked image is better. Due to better pixels group selection for embedding the data losses is less during watermarking and we achieve better results. The purpose of optimization is to maximize the watermarking results in the presented watermarking method. In this work, various images have been imperiled to test the quality measurement in terms of standard metrics such as Peak Signal to Noise Ratio (PSNR), Normalized Cross-Correlation (NCC). Proposed work is compared with existing approach DCT and decision tree induction ID3. Further performance evaluation for different color models such as Red, Green, and Blue (RGB), YCbCr, YIQ color spaces have been calculated. Results of the composing approach are found better than the existing approach in terms of PSNR. In the red plane, the PSNR value is increased by 12%, 18% in the green plane, and 14% in the blue plane for image Lena. The proposed scheme achieves good imperceptibility and robustness against many watermarking attacks too. It can be applied to digital repositories and libraries, ownership authentication, and optimizing the parameters of watermarking in terms of PSNR and NCC.
C1 [Agarwal, Namita] Jaypee Univ Informat Technol, Dept Comp Sci & Engn, Waknaghat, HP, India.
   [Singh, Pradeep Kumar] Delhi NCR, KIET Grp Inst, Dept Comp Sci, Ghaziabad, UP, India.
C3 Jaypee University of Information Technology; KIET Group of Institutions
RP Singh, PK (corresponding author), Delhi NCR, KIET Grp Inst, Dept Comp Sci, Ghaziabad, UP, India.
EM namita312@gmail.com; pradeep_84cs@yahoo.com
RI Singh, Pradeep Kumar/M-4363-2016
OI Singh, Pradeep Kumar/0000-0002-7676-9014
CR Agbaje M, 2015, P INF SCI IT ED C IN, P1
   Ahmadi SBB, 2021, APPL INTELL, V51, P1701, DOI 10.1007/s10489-020-01903-0
   Ali M, 2015, EXPERT SYST APPL, V42, P2392, DOI 10.1016/j.eswa.2014.10.045
   Ansari IA, 2017, PATTERN RECOGN LETT, V94, P228, DOI 10.1016/j.patrec.2016.12.010
   Ariatmanto D, 2020, MULTIMED TOOLS APPL, V79, P12041, DOI 10.1007/s11042-019-08338-x
   Aslantas V, 2008, AEU-INT J ELECTRON C, V62, P386, DOI 10.1016/j.aeue.2007.02.010
   Darwish SM, 2020, MULTIMED TOOLS APPL, V79, P6503, DOI 10.1007/s11042-019-08290-w
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Deeba F, 2020, IET IMAGE PROCESS, V14, P1005, DOI 10.1049/iet-ipr.2018.6040
   Dyer JD, 2012, APPL MATH COMPUT, V218, P4710, DOI 10.1016/j.amc.2011.07.038
   El Houby EMF, 2020, MULTIMED TOOLS APPL, V79, P28453, DOI 10.1007/s11042-020-09333-3
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Thakkar F, 2021, MULTIMED TOOLS APPL, V80, P12275, DOI 10.1007/s11042-020-10220-0
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   Gopal G., 2021, INT J INF RETR RES, P851
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Hsu LY, 2015, J VIS COMMUN IMAGE R, V32, P130, DOI 10.1016/j.jvcir.2015.07.017
   Huang CH, 2000, P SOC PHOTO-OPT INS, V3971, P516, DOI 10.1117/12.385007
   IFTIKHAR S, 2015, IEEE T KNOWL DATA, VE27
   Islam M, 2020, NEURAL COMPUT APPL, V32, P1379, DOI 10.1007/s00521-018-3647-2
   Islam M, 2018, MULTIMED TOOLS APPL, V77, P14407, DOI 10.1007/s11042-017-5035-9
   Katoch S, 2021, MULTIMED TOOLS APPL, V80, P8091, DOI 10.1007/s11042-020-10139-6
   Ko HJ, 2020, INFORM SCIENCES, V517, P128, DOI 10.1016/j.ins.2019.11.005
   Kumar S., 2016, INT J CONTROL THEORY, V9, P277
   LIN SD, 2010, COMPUT STAND INTER
   Mehta R, 2020, MULTIMED TOOLS APPL, V79, P18657, DOI 10.1007/s11042-020-08634-x
   Mehta R, 2018, INT J MACH LEARN CYB, V9, P145, DOI 10.1007/s13042-015-0329-6
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Mohananthini N., 2016, Journal of Electrical Systems and Information Technology, V3, P68, DOI 10.1016/j.jesit.2015.11.009
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Patel S. B., 2011, Technol Research, V3, P81, DOI [10.1504/ijitst.2011.039680,2, DOI 10.1504/IJITST.2011.039680, DOI 10.1504/IJITST.2011.039680,2]
   Priya S, 2018, PERS UBIQUIT COMPUT, V22, P1141, DOI 10.1007/s00779-018-1131-8
   Roy S, 2017, MULTIMED TOOLS APPL, V76, P3577, DOI 10.1007/s11042-016-3902-4
   Sadeghzadeh M, 2014, INT J PEDIAT, V2014, DOI 10.1155/2014/937212
   Shieh CS, 2004, PATTERN RECOGN, V37, P555, DOI 10.1016/j.patcog.2003.07.003
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Su QT, 2020, SOFT COMPUT, V24, P445, DOI 10.1007/s00500-019-03924-5
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Thien HT, 2016, EXPERT SYST APPL, V62, P177, DOI 10.1016/j.eswa.2016.06.015
   Wang, 2021, SYSTEMS SIGNAL PROCE, P1
   Xingyu Zhou, 2018, Mathematical Problems in Engineering, V2018, DOI 10.1155/2018/4907423
   Yadav AK, 2016, MULTIMED TOOLS APPL, V75, P9371, DOI 10.1007/s11042-016-3381-7
   Yen GG., 2018, IEEE C EVOL COMP
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhou Y, 2021, IEEE T CYBERNETICS, V51, P1626, DOI 10.1109/TCYB.2019.2928174
   Zhu Y.M, 2021, OPTIMIZED IMAGE WATE, V38, P122
NR 48
TC 6
Z9 6
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19751
EP 19777
DI 10.1007/s11042-021-11337-6
EA JAN 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000737741900006
DA 2024-07-18
ER

PT J
AU Kebede, SD
   Tiwari, B
   Tiwari, V
   Chandravanshi, K
AF Kebede, Solomon Damena
   Tiwari, Basant
   Tiwari, Vivek
   Chandravanshi, Kamlesh
TI Predictive machine learning-based integrated approach for DDoS detection
   and prevention
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CICIDS2017; DDoS Attack; Machine learning; Classification algorithm;
   DDoS Detection; DDoS Prevention
AB Distributed Denial of Service attack has been a huge threat to the Internet and may carry extreme losses to systems, companies, and national security. The invader can disseminate Distributed denial of service (DDoS) attacks easily, and it ends up being significantly harder to recognize and forestall DDoS attacks. In recent years, many IT-based companies are attacked by DDoS attacks. In this view, the primary concern of this work is to detect and prevent DDoS attacks. To fulfill the objective, various data mining techniques such that Jrip, J48, and k-NN have been employed for DDoS attacks detection. These algorithms are implemented and thoroughly evaluated individually to validate their performance in this domain. The presented work has been evaluated using the latest dataset CICIDS2017. The dataset characterizes different DDoS attacks viz. brute force SSH, brute force FTP, Heartbleed, infiltration, botnet TCP, UDP, and HTTP with port scan attack. Further, the prevention method takes place in progress to block the malicious nodes participates in any of the said attacks. The proposed DDoS prevention works in a proactive mode to defend all these attack types and gets evaluated concerning various parameters such as Throughput, PDR, End-to-End Delay, and NRL. This study claimed that the proposed technique outperforms with respect to the AODV routing algorithm.
C1 [Kebede, Solomon Damena] Hawassa Univ, Inst Technol, Dept Informat Technol, Hawassa, Ethiopia.
   [Tiwari, Basant] Hawassa Univ, Inst Technol, Dept Comp Sci, Hawassa, Ethiopia.
   [Tiwari, Vivek] Dr SP Mukherjee IIIT NR, Dept CSE, Raipur, Madhya Pradesh, India.
   [Chandravanshi, Kamlesh] LNCT, Dept Informat Technol, Bhopal, India.
C3 Hawassa University; Hawassa University
RP Tiwari, V (corresponding author), Dr SP Mukherjee IIIT NR, Dept CSE, Raipur, Madhya Pradesh, India.
EM viveknitbpl@gmail.com
RI Chandravanshi, Kamlesh/ABQ-6805-2022; 100360, Dr.Kamlesh
   Chandravanshi/HKM-4694-2023; Tiwari, Basant/ABB-2402-2022
OI Chandravanshi, Kamlesh/0000-0003-0569-0357; Tiwari,
   Basant/0000-0002-3113-4760; Kebede, Solomon/0000-0003-0221-0020
CR Abdulhammed R, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030322
   Ahmed N, 2019, INT J COMPUT SCI NET, V19, P128
   Akram B, 2019, CICIDS2017 DATASET P
   [Anonymous], 2017, Intrusion Detection Evaluation Dataset (CIC-IDS2017)
   [Anonymous], 2018, Journal of Information Security, V9, P225, DOI 10.4236/JIS.2018.94016
   Batra J, 2019, INT J RECENT TECHNOL, V8
   Bista S., 2017, J INF SECUR, V9, P33, DOI DOI 10.4236/JIS.2018.91004
   Chapaneri Radhika, 2019, Smart Intelligent Computing and Applications. Proceedings of the Second International Conference on SCI 2018. Smart Innovation, Systems and Technologies (SIST 104), P345, DOI 10.1007/978-981-13-1921-1_35
   Dejene D, 2020, INT J INTERACT MULTI, V6, P146, DOI 10.9781/ijimai.2020.10.002
   Garg T, 2014, 2014 RECENT ADVANCES AND INNOVATIONS IN ENGINEERING (ICRAIE)
   Gupta PK, 2017, INTRO PREDICTIVE COM, DOI 10.1007/978-981-10-5107-4_1
   Haydari A, 2018, IEEE INT C INTELL TR, P157, DOI 10.1109/ITSC.2018.8569698
   Kanimozhi V, 2019, ICT EXPRESS
   Liu Z, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), P1050, DOI 10.1109/ITME.2018.00232
   Maccari L, 2019, SECUR PRIVACY, V2, DOI 10.1002/spy2.53
   Misbahuddin M, 2021, J KING SAUD UNIV-COM, V33, P436, DOI 10.1016/j.jksuci.2019.02.003
   Nema Aditi Basant, 2016, P ACM S WOM RES, P26
   Patil NV, 2020, J INTELL FUZZY SYST, V38, P6527, DOI 10.3233/JIFS-179733
   Roempluk Tanaphon OS, 2019, INT C DIG ARTS MED T, P146
   Roopak M, 2020, 2020 10TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P562, DOI [10.1109/CCWC47524.2020.9031206, 10.1109/ccwc47524.2020.9031206]
   Sallam AA, 2020, 2020 16TH IEEE INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2020), P255, DOI [10.1109/cspa48992.2020.9068679, 10.1109/CSPA48992.2020.9068679]
   Salloum Said A., 2020, Proceedings of the International Conference on Artificial Intelligence and Computer Vision (AICV2020). Advances in Intelligent Systems and Computing (AISC 1153), P50, DOI 10.1007/978-3-030-44289-7_5
   Sharawat IK, 2021, PEDIATR EMERG CARE, V37, pE60, DOI 10.1097/PEC.0000000000001555
   Sharma Kavita, 2018, International Journal of E-Services and Mobile Applications, V10, P58, DOI 10.4018/IJESMA.2018040104
   Shrivastava A., 2017, INT RES J ENG APPL S, V5, P14
   Si-Mohammed H, 2020, IEEE T VIS COMPUT GR, V26, P1608, DOI 10.1109/TVCG.2018.2873737
   Singh M, 2019, PREDICTIVE INTELLIGE, P128
   Singh N, 2018, J COMPUT ENG INF TEC, V7, P5, DOI [10.4172/2324-9307.1000214, DOI 10.4172/2324-9307.1000214]
   Tandon R, 2021, DEFENCE SCI J, V71, P192, DOI 10.14429/dsj.71.15534
   Vaseer G, 2017, 2017 3RD IEEE INTERNATIONAL SYMPOSIUM ON NANOELECTRONIC AND INFORMATION SYSTEMS (INIS), P111, DOI 10.1109/iNIS.2017.32
   Wang H, 2020, J INTELL FUZZY SYST, V38, P7623, DOI 10.3233/JIFS-179833
   Xie JF, 2019, IEEE COMMUN SURV TUT, V21, P393, DOI 10.1109/COMST.2018.2866942
   Yadav S, 2016, P ACM S WOM RES, P158
NR 33
TC 2
Z9 2
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 4185
EP 4211
DI 10.1007/s11042-021-11740-z
EA DEC 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000725909900002
DA 2024-07-18
ER

PT J
AU Naderi, N
   Nasersharif, B
   Nikoofard, A
AF Naderi, Navid
   Nasersharif, Babak
   Nikoofard, Amirhossein
TI Persian speech synthesis using enhanced tacotron based on
   multi-resolution convolution layers and a convex optimization method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE End-to-end speech synthesizer; Persian speech syntesizer; Convex
   optimization; Transfer learning
ID TEXT-TO-SPEECH; ATTENTION; PITCH
AB An end-to-end text-to-speech system generates acoustic features directly from input text to synthesize speech from it. The challenges of using these models for Persian language are lack of a proper data, and also detection of exceptions and Ezafe between words inherently (without grapheme-to-phoneme). In this paper, we propose to use an special end-to-end tts system named Tacotron2, and suggest solutions for the mentioned problems. For the lack of data problem, we collect a dataset proper for end-to-end text-to-speech including 21 hours of Persian speech and corresponding text. We use multi-resolution convolution and part of speech embedding layers in the encoder part of Tacotron2, to overcome the exceptions and Ezafe detection problem. In addition, in the case of Tacotron2, Mel-spectrogram generation process is unstable due to high dropout rate at inference time. To handle this problem, we propose to use a convex optimization method, named Net-Trim. Experimental results show that our proposed method increases Tacotron2 mean opinion score from 3.01 to 3.97. Furthermore, the proposed method decreases Mel cepstral distortion in comparison with Tacotron2.
C1 [Naderi, Navid; Nasersharif, Babak] KN Toosi Univ Technol, Dept Comp Engn, Tehran, Iran.
   [Nikoofard, Amirhossein] KN Toosi Univ Technol, Fac Elect Engn, Dept Syst & Control, Tehran, Iran.
C3 K. N. Toosi University of Technology; K. N. Toosi University of
   Technology
RP Nasersharif, B (corresponding author), KN Toosi Univ Technol, Dept Comp Engn, Tehran, Iran.
EM navid.naderi@email.kntu.ac.ir; bnasersharif@kntu.ac.ir;
   a.nikoofard@kntu.ac.ir
RI Nikoofard, Amirhossein/AAB-6369-2019; naderi, navid/AAG-1037-2019
OI Nikoofard, Amirhossein/0000-0002-4628-5238; Nasersharif,
   Babak/0000-0002-8098-6222
CR Aghasi A., 2017, ADV NEURAL INFORM PR, V30, P3177
   Arik SÖ, 2017, ADV NEUR IN, V30
   Arik SO, 2017, PR MACH LEARN RES, V70
   Battenberg E, 2019, INT C LEARN REPR ICL
   Battenberg E, 2020, INT CONF ACOUST SPEE, P6194, DOI [10.1109/icassp40776.2020.9054106, 10.1109/ICASSP40776.2020.9054106]
   Bollepalli B, 2019, INTERSPEECH, P2833, DOI 10.21437/Interspeech.2019-1333
   Chen MN, 2019, INTERSPEECH, P2105, DOI 10.21437/Interspeech.2019-1632
   Chung YA, 2019, INT CONF ACOUST SPEE, P6940, DOI 10.1109/ICASSP.2019.8683862
   Haig G, 2011, TYPOL ST L, V96, P363
   Halabi N., 2016, Modern standard arabic phonetics for speech synthesis
   Hashemian M., 2013, RES ENGLISH LANGUAGE, V1, P5
   Hendessi F., 2005, ACM TRANS ASIAN LANG, V4, P38, DOI [10.1145/1066078.1066081, DOI 10.1145/1066078.1066081]
   King S., 2011, P BLIZZ CHALL WORKSH
   KUBICHEK RF, 1993, IEEE PACIF, P125, DOI 10.1109/PACRIM.1993.407206
   Lancucki A, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6588, DOI 10.1109/ICASSP39728.2021.9413889
   Lee Y, 2017, P INT C NEUR INF PRO
   Luo RQ, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P5699, DOI 10.1109/ICASSP39728.2021.9414403
   Miao C., 2021, INT C MACHINE LEARNI, V139, P7700
   Naderi N, 2017, IRAN CONF ELECTR ENG, P1459, DOI 10.1109/IranianCEE.2017.7985272
   Ning YS, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194050
   Oord A., 2016, ARXIV160903499
   Park K, 2019, INTERSPEECH, P1566, DOI 10.21437/Interspeech.2019-1500
   Ping Wei, 2018, ARXIV180707281
   Ratnaparkhi Adwait., 1997, IRCS Technical Reports Series
   Rosenberg A, 2017, INTERSPEECH, P3976, DOI 10.21437/Interspeech.2017-479
   Seraji M, 2013, 5 INT C IR LING ICIL
   Shamsfard Mehrnoush., 2011, Proceedings of Language Technology Conference, V11, P65
   Shen J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4779, DOI 10.1109/ICASSP.2018.8461368
   Skerry-Ryan RJ, 2018, PR MACH LEARN RES, V80
   Soozandehfar S.A., 2011, Journal Of Language Teaching Research, V2, P1086, DOI DOI 10.4304/JLTR.2.5.1086-1098
   Sotelo J., 2017, ICLR WORKSH TRACK
   Toghyani Khorasgani A., 2017, INDONESIAN EFL J, V1, P189, DOI [10.25134/ieflj.v1i2.626, DOI 10.25134/IEFLJ.V1I2.626]
   Tokuda K, 2000, INT CONF ACOUST SPEE, P1315, DOI 10.1109/ICASSP.2000.861820
   Valle R, 2020, INT CONF ACOUST SPEE, P6189, DOI [10.1109/icassp40776.2020.9054556, 10.1109/ICASSP40776.2020.9054556]
   Wang YQ, 2018, PR MACH LEARN RES, V80
   Wang YX, 2017, INTERSPEECH, P4006, DOI 10.21437/Interspeech.2017-1452
   Weiss RJ, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P5679, DOI 10.1109/ICASSP39728.2021.9413851
   Yang G, 2021, IEEE W SP LANG TECH, P492, DOI 10.1109/SLT48900.2021.9383551
   Yasuda Y, 2019, INT CONF ACOUST SPEE, P6905, DOI [10.1109/icassp.2019.8682353, 10.1109/ICASSP.2019.8682353]
   Zen HG, 2019, INTERSPEECH, P1526, DOI 10.21437/Interspeech.2019-2441
   Zhang JX, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4789, DOI 10.1109/ICASSP.2018.8462020
   Zhang MY, 2019, INTERSPEECH, P1298, DOI 10.21437/Interspeech.2019-1357
   Zivkovic M, 2021, SUSTAIN CITIES SOC, V66, DOI 10.1016/j.scs.2020.102669
NR 43
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3629
EP 3645
DI 10.1007/s11042-021-11719-w
EA NOV 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000719156700001
DA 2024-07-18
ER

PT J
AU Ray, B
   Ghosh, S
   Ahmed, S
   Sarkar, R
   Nasipuri, M
AF Ray, Biswarup
   Ghosh, Soulib
   Ahmed, Shameem
   Sarkar, Ram
   Nasipuri, Mita
TI Outlier detection using an ensemble of clustering algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Outlier detection; Ensemble approach; Unsupervised learning; Clustering
   algorithm; UCI dataset
ID FEATURE-EXTRACTION; NOVELTY DETECTION; CLASSIFICATION; PERFORMANCE
AB Outlier detection is an important research area in the field of machine learning and data science. The presence of outliers in a dataset limits its true usefulness in a real-life scenario. Due to the varied challenges, researchers strive to find a general method to be useful for different datasets. In this paper, we have proposed an outlier detection technique based on unsupervised learning using an ensemble of three clustering algorithms, namely K-means, K-means++ and Fuzzy C-means. We have proposed a unique way to deal with clustered outliers. Outcomes of the three aforementioned clustering algorithms are combined intelligently to accumulate all the complementary information. To combine the decisions of the hard and soft clustering algorithms, we have proposed a novel probability-based technique, which assigns a membership value to each data point in the case of a hard clustering algorithm. Three cluster validity indices are used as our evaluation metrics, which measure the goodness of a cluster. Significant improvement of cluster validity indices is observed after removing the outliers, which ensures the removal of outliers has resulted in stringent clusters. The method is evaluated on eight datasets, among which, three datasets are comparatively large. Source code of this work is available at: https://github.com/biswarup9/Outlier-Detection-Using-an-Ensemble-of-Clustering-Algorithms-.
C1 [Ray, Biswarup; Ghosh, Soulib; Ahmed, Shameem; Sarkar, Ram; Nasipuri, Mita] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
C3 Jadavpur University
RP Sarkar, R (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
EM raybiswarup9@gmail.com; ghoshsoulib@gmail.com;
   shameemahmed20apr2000@gmail.com; ramjucse@gmail.com;
   mitanasipuri@gmail.com
RI Sarkar, Ram/AAX-3822-2020
OI Sarkar, Ram/0000-0001-8813-4086; GHOSH, SOULIB/0000-0001-6458-8681;
   Ahmed, Shameem/0000-0003-1795-3361; Ray, Biswarup/0000-0002-7378-0920
CR Agarwal S, 2012, 2012 STUD C ENG SYST
   Aggarwal C.C., 2017, Outlier Analysis, P219
   Ahmed M, 2013, C IND ELECT APPL, P577
   Ahmed S, 2020, IEEE ACCESS, V8, P102629, DOI 10.1109/ACCESS.2020.2999093
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Bera SK, 2021, MULTIMED TOOLS APPL, V80, P7653, DOI 10.1007/s11042-020-09836-z
   Boddy AJ, 2019, IEEE ACCESS, V7, P40285, DOI 10.1109/ACCESS.2019.2906503
   Boodhun N, 2018, COMPLEX INTELL SYST, V4, P145, DOI 10.1007/s40747-018-0072-1
   Boukerche A, 2020, ACM COMPUT SURV, V53, DOI [10.1145/3381028, 10.1145/3421763]
   Chakraborty D, 2019, PATTERN RECOGN, V89, P161, DOI 10.1016/j.patcog.2019.01.002
   Chawla S., 2013, P 2013 SIAM INT C DA, P189, DOI [DOI 10.1137/1.9781611972832.21, 10.1137/1.9781611972832.21]
   Chopra P, 2015, COMPLEX INTELL SYST, V1, P35, DOI 10.1007/s40747-016-0008-6
   Chopra P, 2015, COMPLEX INTELL SYST, V1, P25, DOI 10.1007/s40747-015-0004-2
   Daneshpazhouh A, 2014, PATTERN RECOGN LETT, V49, P77, DOI 10.1016/j.patrec.2014.06.012
   Daneshpazhouh A, 2013, 2013 5TH CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT), P344, DOI 10.1109/IKT.2013.6620091
   Du HZ, 2016, IEEE CONF COMPUT, DOI 10.1109/INFCOMW.2016.7562187
   Dwivedi RK, 2018, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE CONFLUENCE 2018 ON CLOUD COMPUTING, DATA SCIENCE AND ENGINEERING, P189, DOI 10.1109/CONFLUENCE.2018.8442992
   Ghosh S, 2021, VISUAL COMPUT, V37, P1781, DOI 10.1007/s00371-020-01938-x
   Hoque N, 2018, COMPLEX INTELL SYST, V4, P105, DOI 10.1007/s40747-017-0060-x
   Hussien Abdelazim G., 2019, Recent Trends in Signal and Image Processing. ISSIP 2017. Advances in Intelligent Systems and Computing (AISC 727), P79, DOI 10.1007/978-981-10-8863-6_9
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Jana P, 2017, 2017 NINTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION (ICAPR), P332
   Jana P, 2017, 2017 IEEE CALCUTTA CONFERENCE (CALCON), P226, DOI 10.1109/CALCON.2017.8280729
   Jiang MF, 2001, PATTERN RECOGN LETT, V22, P691, DOI 10.1016/S0167-8655(00)00131-8
   Kieu T, 2018, IEEE INT CONF MOB DA, P125, DOI 10.1109/MDM.2018.00029
   Li YM, 2019, IEEE ACCESS, V7, P152267, DOI 10.1109/ACCESS.2019.2947736
   Liu YZ, 2020, IEEE T ENG MANAGE, V67, P483, DOI 10.1109/TEM.2018.2887118
   Malakar, 2019, COMMUN COMPUT INF SC, V1020, P27, DOI DOI 10.1007/978-981-13-9361-7_3
   Mandal A, 2018, INT C EM TECHN SUST
   Markou M, 2003, SIGNAL PROCESS, V83, P2499, DOI 10.1016/j.sigpro.2003.07.019
   Markou M, 2003, SIGNAL PROCESS, V83, P2481, DOI 10.1016/j.sigpro.2003.07.018
   Maulik U, 2002, IEEE T PATTERN ANAL, V24, P1650, DOI 10.1109/TPAMI.2002.1114856
   Mishra Gaurav, 2019, International Conference on Advanced Computing Networking and Informatics (ICANI-2018). Advances in Intelligent Systems and Computing (AISC 870), P521, DOI 10.1007/978-981-13-2673-8_55
   Munoz-Organero M, 2019, IEEE ACCESS, V7, P74422, DOI 10.1109/ACCESS.2019.2921096
   NAKAI K, 1991, PROTEINS, V11, P95, DOI 10.1002/prot.340110203
   Panwar LK, 2018, SWARM EVOL COMPUT, V38, P251, DOI 10.1016/j.swevo.2017.08.002
   Pendharkar PC, 2004, COMPUT OPER RES, V31, P481, DOI 10.1016/S0305-0548(02)00229-0
   Peng CYJ, 2002, J EDUC RES, V96, P3, DOI 10.1080/00220670209598786
   Rish Irina, 2001, IJCAI 2001 WORKSHOP, V3, P41
   Saha A, 2021, MULTIMED TOOLS APPL, V80, P35145, DOI 10.1007/s11042-020-09628-5
   Saha S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082816
   Sharma D, 2021, COMPLEX INTELL SYST, V7, P41, DOI 10.1007/s40747-020-00169-w
   SIGILLITO VG, 1989, J HOPKINS APL TECH D, V10, P262
   Starczewski A, 2015, LECT NOTES COMPUT SC, V9120, P49, DOI 10.1007/978-3-319-19369-4_5
   Stucker C., 2018, ISPRS ANN PHOTOGRAMM, V4, P263, DOI [DOI 10.5194/ISPRS-ANNALS-IV-2-263-2018, DOI 10.5194/isprs-annals-IV-2-263-2018]
   Thomas Roy, 2020, Advances in Communication Systems and Networks. Select Proceedings of ComNet 2019. Lecture Notes in Electrical Engineering (LNEE 656), P501, DOI 10.1007/978-981-15-3992-3_42
   Wahid A, 2021, CLUSTER COMPUT, V24, P569, DOI 10.1007/s10586-020-03136-9
   Wang K, 2019, PROCEEDINGS OF 2019 IEEE 3RD INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2019), P583, DOI [10.1109/itnec.2019.8729176, 10.1109/ITNEC.2019.8729176]
   Wang YF, 2019, SUSTAIN CITIES SOC, V45, P197, DOI 10.1016/j.scs.2018.11.031
   Wang ZM, 2019, IEEE ACCESS, V7, P96319, DOI 10.1109/ACCESS.2019.2929581
   Whang JJ, 2015, P 2015 SIAM INT C DA, P936, DOI DOI 10.1109/TPAMI.2018.2863278
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Yan HQ, 2019, NEUROCOMPUTING, V329, P348, DOI 10.1016/j.neucom.2018.10.067
   Yi Y, 2018, IEEE ACCESS, V6, P63923, DOI 10.1109/ACCESS.2018.2877701
   Yu QY, 2016, APPL INTELL, V45, P1179, DOI 10.1007/s10489-016-0813-z
   Zhang K, 2009, LECT NOTES ARTIF INT, V5476, P813, DOI 10.1007/978-3-642-01307-2_84
   Zhang Y, 2010, IEEE COMMUN SURV TUT, V12, P159, DOI 10.1109/SURV.2010.021510.00088
   Zhao Y, 2018, IEEE IJCNN, P558
   Zhou YH, 2009, 2009 SECOND INTERNATIONAL CONFERENCE ON FUTURE INFORMATION TECHNOLOGY AND MANAGEMENT ENGINEERING, FITME 2009, P476, DOI 10.1109/FITME.2009.125
NR 59
TC 6
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2681
EP 2709
DI 10.1007/s11042-021-11671-9
EA NOV 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000714312500002
DA 2024-07-18
ER

PT J
AU Rodrigues, IR
   Barbosa, G
   Filho, AO
   Cani, C
   Dantas, M
   Sadok, DH
   Kelner, J
   Souza, RS
   Marquezini, MV
   Lins, S
AF Rodrigues, Iago Richard
   Barbosa, Gibson
   Filho, Assis Oliveira
   Cani, Carolina
   Dantas, Marrone
   Sadok, Djamel H.
   Kelner, Judith
   Souza, Ricardo Silva
   Marquezini, Maria Valeria
   Lins, Silvia
TI Modeling and assessing an intelligent system for safety in human-robot
   collaboration using deep and machine learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-robot collaboration; Safety; Deep learning; Machine learning;
   Semantic segmentation; Collision detection
ID COLLISION DETECTION; IMAGE
AB The introduction of technological innovations is essential for accident mitigation in work environments. In a human-robot collaboration scenario, the current number of accidents raises a safety problem that must be dealt. This work proposes an intelligent system that aims to address such problems using deep and machine learning techniques. More specifically, this solution is divided into two modules: (i) collision detection between humans and robots and (ii) worker's clothing detection. We evaluated these modules separately and concluded that the proposed intelligent system is efficient in supporting safe human-robot collaboration. The results achieved a sensitivity level greater than 90% in identifying collisions and an accuracy above 94% in identifying the worker's clothing.
C1 [Rodrigues, Iago Richard; Barbosa, Gibson; Filho, Assis Oliveira; Cani, Carolina; Dantas, Marrone; Sadok, Djamel H.; Kelner, Judith] Univ Fed Pernambuco, Recife, PE, Brazil.
   [Souza, Ricardo Silva; Marquezini, Maria Valeria; Lins, Silvia] Ericsson Res, Indaiatuba, SP, Brazil.
C3 Universidade Federal de Pernambuco
RP Rodrigues, IR (corresponding author), Univ Fed Pernambuco, Recife, PE, Brazil.
EM iago.silva@gprt.ufpe.br; gibson.nunes@gprt.ufpe.br;
   assis.tiago@gprt.ufpe.br; carolina.cani@gprt.ufpe.br;
   marrone.dantas@gprt.ufpe.br; jamel@gprt.ufpe.br; jk@gprt.ufpe.br;
   ricardo.s.souza@ericsson.com; maria.marquezini@ericsson.com;
   silvia.lins@ericsson.com
RI Kelner, Judith/C-6746-2009; Sadok, Djamel F Hadj/M-9814-2015; Rodrigues
   Silva, Iago Richard/AAX-3739-2021
OI Rodrigues Silva, Iago Richard/0000-0002-8242-9059; Tiago de Oliveira
   Filho, Assis/0000-0001-9873-6929
FU Research, Development and Innovation Center, Ericsson Telecommunications
   Inc., Brazil; Conselho Nacional de Desenvolvimento Cientifico e
   Tecnologico (CNPq); Coordenacao de Aperfeicoamento de Pessoal de Nivel
   Superior (CAPES); Fundacao de Amparo a Ciencia e Tecnologia de
   Pernambuco (FACEPE)
FX This work was supported by the YResearch, Development and Innovation
   Center, Ericsson Telecommunications Inc., Brazil, Conselho Nacional de
   Desenvolvimento Cientifico e Tecnologico (CNPq), Coordenacao de
   Aperfeicoamento de Pessoal de Nivel Superior (CAPES), and the Fundacao
   de Amparo a Ciencia e Tecnologia de Pernambuco (FACEPE).
CR [Anonymous], 2013, INT J SCI RES PUBL
   Anvaripour M, 2019, IEEE SYS MAN CYBERN, P2149, DOI 10.1109/SMC.2019.8914660
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   bbc, MAN CRUSH DEATH ROB
   Ben Salem Y, 2010, SIGNAL IMAGE VIDEO P, V4, P429, DOI 10.1007/s11760-009-0132-5
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Garcia-Garcia A, 2018, APPL SOFT COMPUT, V70, P41, DOI 10.1016/j.asoc.2018.05.018
   Graczyk M, 2010, LECT NOTES ARTIF INT, V5991, P340, DOI 10.1007/978-3-642-12101-2_35
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Heo YJ, 2019, IEEE ROBOT AUTOM LET, V4, P740, DOI 10.1109/LRA.2019.2893400
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Jocelyn S., 2019, Collaborative Robotics: Assessment of Safety Functions and Feedback from Workers, Users and Integrators in Quebec
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   Kelm A, 2013, AUTOMAT CONSTR, V36, P38, DOI 10.1016/j.autcon.2013.08.009
   Khalid S, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P372, DOI 10.1109/SAI.2014.6918213
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kleinbaum D.G., 2002, Logistic Regression
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee SD, 2015, IEEE INT C INT ROBOT, P2392, DOI 10.1109/IROS.2015.7353701
   Liu XL, 2019, ARTIF INTELL REV, V52, P1089, DOI 10.1007/s10462-018-9641-3
   Mittal S, 2021, IEEE T PATTERN ANAL, V43, P1369, DOI 10.1109/TPAMI.2019.2960224
   Mohammed A, 2017, INT J COMPUT INTEG M, V30, P970, DOI 10.1080/0951192X.2016.1268269
   Nath ND, 2020, AUTOMAT CONSTR, V112, DOI 10.1016/j.autcon.2020.103085
   Nekrasov V, 2018, ARXIVARXIV181003272
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pan B, 2019, IEEE GEOSCI REMOTE S, V16, P816, DOI 10.1109/LGRS.2018.2880756
   Pengfei L., 2014, ADV IMAGE GRAPHICS T, P274
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruck D W, 1990, IEEE Trans Neural Netw, V1, P296, DOI 10.1109/72.80266
   Ruder S., ARXIV160904747
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sevastopolsky A., 2017, Pattern Recognition and Image Analysis, V27, P618, DOI 10.1134/S1054661817030269
   Sharkawy A., 2018, INT J MECH ENG ROBOT, V7, P150, DOI DOI 10.18178/IJMERR.7.2.150-157
   Sharkawy AN, 2020, SOFT COMPUT, V24, P6687, DOI 10.1007/s00500-019-04306-7
   Sharkawy AN, 2019, MECH MACH SCI, V67, P3, DOI 10.1007/978-3-030-00232-9_1
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shin H, 2019, 2019 THIRD IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC 2019), P509, DOI 10.1109/IRC.2019.00106
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Surakarin W, 2015, 2015 INTERNATIONAL COMPUTER SCIENCE AND ENGINEERING CONFERENCE (ICSEC), P90
   Takiguchi T, 2018, P INT MULT ENG COMP, V1
   Tokunaga H, 2019, PROC CVPR IEEE, P12589, DOI 10.1109/CVPR.2019.01288
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wang YW, 2017, IEEE COMPUT SOC CONF, P492, DOI 10.1109/CVPRW.2017.72
NR 44
TC 3
Z9 3
U1 5
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2213
EP 2239
DI 10.1007/s11042-021-11643-z
EA OCT 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000710608700002
DA 2024-07-18
ER

PT J
AU Chen, XL
   Wang, XN
AF Chen, Xilan
   Wang, Xiaonan
TI Content-centric framework for Internet of Things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-centric; Internet; IoT; Anycast
ID VEHICULAR NETWORKS; SCHEME; PROTOCOL
AB The Internet of Things (IoT) concentrates on content dissemination and retrieval, so it is significant to achieve efficient content delivery. However, the Internet focuses on end-to-end communications, which might degrade the content retrieval performance in mobile environments. By contrast, the content-centric mechanism might be an ideal method for achieving efficient content delivery although it suffers from flooding and reverse-path disruptions. Therefore, we are motivated to exploit the content-centric mechanism to achieve IoT-based content delivery, and employ the address-centric anycast to overcome the limitations of the content-centric mechanism. Inspired by the idea, we propose a content-centric framework for IoT. The experimental results show that the proposed framework reduces the content communication cost and improves the content acquisition success rate.
C1 [Chen, Xilan; Wang, Xiaonan] Changshu Inst Technol, Suzhou, Peoples R China.
C3 Changshu Institute of Technology
RP Wang, XN (corresponding author), Changshu Inst Technol, Suzhou, Peoples R China.
EM ninawang9@163.com
FU CERNET Innovation Project [NGII20170106]
FX This work is supported by the CERNET Innovation Project under Grant No.
   NGII20170106.
CR Ahmed E, 2018, IEEE T INTELL TRANSP, V19, P996, DOI 10.1109/TITS.2018.2795381
   Ahmed SH, 2018, IEEE T INTELL TRANSP, V19, P3076, DOI 10.1109/TITS.2017.2768329
   Bastos IV, 2019, COMPUT NETW, V157, P11, DOI 10.1016/j.comnet.2019.04.003
   Bouk SH, 2019, IEEE ACCESS, V7, P51799, DOI 10.1109/ACCESS.2019.2910281
   Cadger F, 2013, IEEE COMMUN SURV TUT, V15, P621, DOI 10.1109/SURV.2012.062612.00109
   Carofiglio G, 2012, IEEE CONF COMPUT, P304, DOI 10.1109/INFCOMW.2012.6193510
   Dou ZX, 2019, TELECOMMUN SYST, V71, P121, DOI 10.1007/s11235-018-0499-0
   Gao DM, 2019, IEEE ACCESS, V7, P40663, DOI 10.1109/ACCESS.2019.2902902
   Gao DM, 2016, COMPUT STAND INTER, V43, P12, DOI 10.1016/j.csi.2015.07.002
   Han SY, 2013, IEEE COMMUN LETT, V17, P1040, DOI 10.1109/LCOMM.2013.040213.130076
   IEEE 802.11 Working Group, 2016, 80211 ANSIIEEE
   Jacobson V, 2012, COMMUN ACM, V55, P117, DOI 10.1145/2063176.2063204
   Khelifi H, 2020, IEEE COMMUN SURV TUT, V22, P320, DOI 10.1109/COMST.2019.2894816
   Kostin AE, 2016, WIREL NETW, V22, P579, DOI 10.1007/s11276-015-0975-3
   Li H, 2018, IEEE WIREL COMMUN, V25, P88, DOI 10.1109/MWC.2018.1700315
   McPherson D., 2014, RFC 7094, V1, P1
   Ortega V, 2018, IEEE VEH TECHNOL MAG, V13, P121, DOI 10.1109/MVT.2018.2813422
   Rezaeifar Z, 2019, FUTURE GENER COMP SY, V96, P538, DOI 10.1016/j.future.2018.12.049
   Su Z, 2015, IEEE COMMUN MAG, V53, P66, DOI 10.1109/MCOM.2015.7120047
   Wang D, 2021, WIRELESS PERS COMMUN, V116, P2135, DOI 10.1007/s11277-020-07783-4
   Wang XN, 2019, WIRELESS PERS COMMUN, V109, P89, DOI 10.1007/s11277-019-06552-2
   Wang XN, 2018, IEEE SYST J, V12, P1679, DOI 10.1109/JSYST.2016.2619374
   Wang XN, 2015, T EMERG TELECOMMUN T, V26, P836, DOI 10.1002/ett.2743
   Wu J, 2019, IEEE T EMERG TOP COM, V7, P553, DOI 10.1109/TETC.2017.2747158
   Xu JW, 2020, IEEE T EMERG TOP COM, V8, P845, DOI 10.1109/TETC.2017.2775798
NR 25
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12371
EP 12385
DI 10.1007/s11042-021-11434-6
EA SEP 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000696465700002
DA 2024-07-18
ER

PT J
AU Shafi, J
   Obaidat, MS
   Krishna, PV
   Sadoun, B
   Pounambal, M
   Gitanjali, J
AF Shafi, Jana
   Obaidat, Mohammad S.
   Krishna, P. Venkata
   Sadoun, Balqies
   Pounambal, M.
   Gitanjali, J.
TI Prediction of heart abnormalities using deep learning model and
   wearabledevices in smart health homes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Prediction; Smarty health homes; Abnormality; Heart;
   Wearable devices
ID STRESS; SYSTEM; RECOGNITION; EPILEPSY; TRENDS
AB The prediction of abnormality in the heart functionality at an early stage increases the chances of saving the life of people. Thus, this paper proposes a technique which predicts the abnormality in the functionality of the heart using heart rate in the form of beats per minute using wearable devices and deep learning model. The devices used are wrist strap and devices that can be fixed near the chest of the person or back of the person where heart beat can be detected. The proposed system is divided into 3 modules: (1) data collection and processing module, (2) prediction module and (3) communication module. First module is used to collect data and process, while prediction module predicts the abnormal functionality of the heart using deep learning model. One of the advantage of the proposed work in this paper is communication module as the communication is given to the doctor who can perform analysis before the patient reaches the hospital. A message is sent to the ambulance so that it reaches the destination on time. The message related to first aid is sent to two dear ones and the patient such that appropriate measures can be taken. The proposed technique is evaluated in terms of sensitivity, specificity, F-1-Score, time and ROC curve metrics. It is also compared with the Two Stage Neural Network and TSNN and proved to be performing better.
C1 [Shafi, Jana; Krishna, P. Venkata] Sri PadmavatiMahila Univ Tirupati, Tirupati, Andhra Pradesh, India.
   [Obaidat, Mohammad S.] Univ Sharjah, Coll Comp & Informat, Sharjah 27272, U Arab Emirates.
   [Obaidat, Mohammad S.] Univ Jordan, King Abdullah II Sch Informat Technol, Amman 11942, Jordan.
   [Obaidat, Mohammad S.] Univ Sci & Technol Beijing, Beijing 100083, Peoples R China.
   [Sadoun, Balqies] Univ Sharjah, Coll Engn, Sharjah 27272, U Arab Emirates.
   [Pounambal, M.; Gitanjali, J.] VIT Univ, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
C3 Sri Padmavati Mahila Vishwavidyalayam; University of Sharjah; University
   of Jordan; University of Science & Technology Beijing; University of
   Sharjah; Vellore Institute of Technology (VIT); VIT Vellore
RP Krishna, PV (corresponding author), Sri PadmavatiMahila Univ Tirupati, Tirupati, Andhra Pradesh, India.
EM parimalavk@gmail.com
RI J, Gitanjali/AAW-8193-2020; Shafi, Jana/AAZ-8175-2021; Obaidat, Mohammad
   S./KBC-2747-2024; Shafi, Jana/G-5563-2016; Parimala, Venkata
   Krishna/C-9554-2018
OI J, Gitanjali/0000-0002-2296-800X; Shafi, Jana/0000-0001-6859-670X;
   Parimala, Venkata Krishna/0000-0001-8138-5878
CR Abdel-Basset M, 2020, MULTIMED TOOLS APPL, V79, P9977, DOI 10.1007/s11042-019-07742-7
   Abreu R., 2017, PROC IJCAI KNOWLEDGE
   Al-Makhadmeh Z, 2019, MEASUREMENT, V147, DOI 10.1016/j.measurement.2019.07.043
   Alberdi A, 2016, J BIOMED INFORM, V59, P49, DOI 10.1016/j.jbi.2015.11.007
   American Psychology Association, 2019, STR DIFF KINDS STR A
   Amiriparian S, 2018, IEEE ENG MED BIO, P4776, DOI 10.1109/EMBC.2018.8513102
   [Anonymous], 2011, NATL HLTH STAT REPOR
   [Anonymous], 2001, P 9 DATA MINING C
   [Anonymous], 2014, EPIDEMIOL RES INT
   Can YS, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19081849
   Carrera D, 2019, PATTERN RECOGN, V88, P482, DOI 10.1016/j.patcog.2018.11.019
   Colligan TW, 2006, J WORKPLACE BEHAV HE, V21, P89, DOI 10.1300/J490v21n02_07
   Ed-daoudy A, 2019, 2019 INTERNATIONAL CONFERENCE ON WIRELESS TECHNOLOGIES, EMBEDDED AND INTELLIGENT SYSTEMS (WITS), DOI 10.1109/wits.2019.8723839
   England MJ, 2012, EPILEPSY BEHAV, V25, P266, DOI 10.1016/j.yebeh.2012.06.016
   European Agency for Safety and Health at Work, 2013, EUR OPIN POLL OCC SA, DOI 10.2802/55505
   Ganesh SK, 2013, CIRCULATION, V128, P2813, DOI 10.1161/01.cir.0000437913.98912.1d
   Herbert J, 1997, BRIT MED J, V315, P530, DOI 10.1136/bmj.315.7107.530
   Hung LP, 2020, INT J HUM-COMPUT ST, V136, DOI 10.1016/j.ijhcs.2019.102381
   Kalantari A, 2018, NEUROCOMPUTING, V276, P2, DOI 10.1016/j.neucom.2017.01.126
   Komatsu M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11010371
   Krantz D.S., 2011, HEART MIND EVOLUTION
   Milczarek M., 2009, OSH in figures: Stress at work - facts and figures
   Mönnikes H, 2001, DIGEST DIS, V19, P201, DOI 10.1159/000050681
   Obaidat MS., 2016, SMART CITES HOMES KE
   Picard RW, 2016, IEEE MULTIMEDIA, V23, P3, DOI 10.1109/MMUL.2016.38
   Pickering T G, 2001, Curr Hypertens Rep, V3, P249, DOI 10.1007/s11906-001-0047-1
   Ryvlin P, 2013, LANCET NEUROL, V12, P966, DOI 10.1016/S1474-4422(13)70214-X
   Sagir AM, 2017, PERTANIKA J SCI TECH, V25, P43
   Sarmah SS, 2020, IEEE ACCESS, V8, P135784, DOI 10.1109/ACCESS.2020.3007561
   Shakeel PM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1045-z
   Shen YC, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1909, DOI 10.1145/3292500.3330657
   Shomaji S, 2019, IEEE CONSUM ELECTR M, V8, P12, DOI 10.1109/MCE.2019.2941350
   Tariq T, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON COMMUNICATION, COMPUTING AND DIGITAL SYSTEMS (C-CODE), P137, DOI [10.1109/C-CODE.2019.8680983, 10.1109/c-code.2019.8680983]
   Veazie M, 2014, AM J PUBLIC HEALTH, V104, pS359, DOI 10.2105/AJPH.2013.301715
   Wang N, 2019, IEEE T BIOMED CIRC S, V13, P1112, DOI 10.1109/TBCAS.2019.2930215
   Xu BY, 2017, ENTERP INF SYST-UK, V11, P17, DOI 10.1080/17517575.2015.1053416
   Yang QH, 2014, J ADOLESCENT HEALTH, V55, P513, DOI 10.1016/j.jadohealth.2014.03.013
   Young S.S., 2001, Computerized Data Acquisition and Analysis for the Life Sciences
NR 38
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 543
EP 557
DI 10.1007/s11042-021-11346-5
EA SEP 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000695454400004
DA 2024-07-18
ER

PT J
AU Liang, BY
   Tong, C
   Lang, C
   Wang, QL
   Rodrigues, JJPC
   Kozlov, S
AF Liang, Baoyu
   Tong, Chao
   Lang, Chao
   Wang, Qinglong
   Rodrigues, Joel J. P. C.
   Kozlov, Sergei
TI Protecting image privacy through adversarial perturbation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Privacy; Adversarial Sample; Neural Networks; Human Detection; Social
   Network Services
AB In current digital era, users of various social media upload photos which usually contain tremendous amount of private information on daily basis. Though the private information contained within photos can assist enterprises to provide users with better services, it is also at the risk of being disclosed. Especially, with deep learning techniques developed for object detection tasks, users' privacy can be extracted with no difficulty. Therefore, we propose an approach to prevent DNN detectors from detecting private objects, especially human body. An algorithm is developed by exploiting an inherent vulnerability of deep learning models known as the adversarial sample problem, and is integrated under a general framework which is also proposed in this work. We evaluate our method on the task of reducing the performance of DNN detectors on PASCAL VOC dataset. Our proposed algorithm can reduce the recall of human detection from 81.1% to 18.0%, while having few effects on pixel value. The results show that our proposed method performs remarkably well on preventing privacy from being exposed by DNN detectors, while causing very limited degradation to the visual quality of images.
C1 [Liang, Baoyu; Tong, Chao; Lang, Chao] Beihang Univ, Sch Comp Sci, Beijing 100191, Peoples R China.
   [Wang, Qinglong] McGill Univ Montreal, Sch Comp Sci, Montreal, PQ H3A 0E9, Canada.
   [Rodrigues, Joel J. P. C.] Fed Univ Piaui UFPI, Teresina, Brazil.
   [Rodrigues, Joel J. P. C.; Kozlov, Sergei] ITMO Univ, St Petersburg, Russia.
C3 Beihang University; Universidade Federal do Piaui; ITMO University
RP Tong, C (corresponding author), Beihang Univ, Sch Comp Sci, Beijing 100191, Peoples R China.
EM tongchao@buaa.edu.cn
RI Rodrigues, Joel J. P. C./A-8103-2013; Liang, Baoyu/HWQ-4668-2023
OI Rodrigues, Joel J. P. C./0000-0001-8657-3800; Tong,
   Chao/0000-0003-4414-4965
FU National Key R&D Program of China [2018YFB2101100, 2019YFB2101600];
   National Natural Science Foundation of China [62176016]; Guizhou
   Province Science and Technology Project: Research and Demonstration of
   Sci. & Tech Big Data Mining Technology Based on Knowledge Graph
   [Qiankehe[2021] General 382]; Training Program of the Major Research
   Plan of the National Natural Science Foundation of China [92046015];
   Beijing Natural Science Foundation Program [KZ202010025047]; Scientific
   Research Key Program of Beijing Municipal Commission of Education
   [KZ202010025047]
FX This study is partially supported by the National Key R&D Program of
   China (No. 2018YFB2101100 and No.2019YFB2101600),National Natural
   Science Foundation of China (62176016), Guizhou Province Science and
   Technology Project: Research and Demonstration of Sci. & Tech Big Data
   Mining Technology Based on Knowledge Graph (supported by Qiankehe[2021]
   General 382),Training Program of the Major Research Plan of the National
   Natural Science Foundation of China (Grant No. 92046015),andBeijing
   Natural Science Foundation Program and Scientific Research Key Program
   of Beijing Municipal Commission of Education (Grant No. KZ202010025047).
CR Blank Grant, 2019, Perceived threats to privacy online: The Internet in Britain, Oxford Internet Survey, 2019, DOI 10.2139/ssrn.3522083
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Croce F, 2019, IEEE I CONF COMP VIS, P4723, DOI 10.1109/ICCV.2019.00482
   Dabbagh M., 2019, Internet of Things Security and Privacy, P211
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Hao H, 2019, ARXIV190611979
   Jia XJ, 2019, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2019.00624
   Jiang LX, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P864, DOI 10.1145/3343031.3351088
   Jiao R, 2020, 2020 6TH INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING AND COMMUNICATIONS (BIGCOM 2020), P91, DOI 10.1109/BigCom51056.2020.00020
   Jinao Yu, 2020, 2020 IEEE 9th Joint International Information Technology and Artificial Intelligence Conference (ITAIC), P2184, DOI 10.1109/ITAIC49862.2020.9338847
   Kopeykina L, 2020, PHOTOPRIVACY DETECTI
   Kurakin A., 2016, WORKSHOP TRACK P
   Li X, 2017, IEEE ACCESS, V5, P24332, DOI 10.1109/ACCESS.2017.2767622
   Liu Y, 2016, EMNLP
   Madry A., 2018, ARXIV
   McPherson Richard., 2016, Defeating image obfuscation with deep learning
   Mirjalili V, 2018, INT CONF BIOMETR THE
   Oh SJ, 2017, IEEE I CONF COMP VIS, P1491, DOI 10.1109/ICCV.2017.165
   Qiu H., 2020, ARXIV PREPRINT ARXIV
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rouhani BD, 2019, IEEE SECUR PRIV, V17, P31, DOI 10.1109/MSEC.2018.2888779
   Subbaraju V, 2020, INT C PATTERN RECOGN, P10
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tonge A, 2020, ACM T WEB, V14, DOI 10.1145/3386082
   Tonge A, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P1829, DOI 10.1145/3308558.3313691
   Yu J, 2017, IEEE T INF FOREN SEC, V12, P1005, DOI 10.1109/TIFS.2016.2636090
   Yuan L, 2017, IET SIGNAL PROCESS, V11, P1031, DOI 10.1049/iet-spr.2016.0756
   Zhao ZY, 2020, PROC CVPR IEEE, P1036, DOI 10.1109/CVPR42600.2020.00112
NR 30
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34759
EP 34774
DI 10.1007/s11042-021-11394-x
EA SEP 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000692075600005
DA 2024-07-18
ER

PT J
AU Aghajani, K
AF Aghajani, Khadijeh
TI Multi-modal image registration in the presence of spatially varying
   intensity distortion using structural representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-rigid multi-modal image registration; Spatially-varying intensity
   distortion; Structural representation
ID MUTUAL INFORMATION; ROBUST; DESCRIPTOR; ENTROPY
AB Non-rigid multi-modal image registration remains a challenging task due to the complex intensity relation between the two images to be registered. Especially in the presence of spatially varying intensity distortion, the conventional methods are unable to register the two images. Here, the proposed framework includes two steps. First, a structural representation of each image is computed, and then a conventional similarity metric such as mutual information (MI) or sum of squared distance (SSD) is used to register the two structural images. The structural image is obtained by utilizing a modified second-order entropy image and the gradient information. The proposed framework is tested on some data ranging from simulated to real data. Quantitative and qualitative results demonstrate that applying MI similarity metric on the proposed representation is capable of achieving high accuracy results.
C1 [Aghajani, Khadijeh] Univ Mazandaran, Dept Comp Engn, Babolsar, Iran.
C3 University of Mazandaran
RP Aghajani, K (corresponding author), Univ Mazandaran, Dept Comp Engn, Babolsar, Iran.
EM kh.aghajani@umz.ac.ir
CR Aghajani K, 2019, BIOMED SIGNAL PROCES, V49, P96, DOI 10.1016/j.bspc.2018.11.001
   Alipour SHM, 2012, COMPUT MATH METHOD M, V2012, DOI 10.1155/2012/761901
   [Anonymous], 2003, DICTA, DOI [10.1177/0734242X0302100404, DOI 10.1177/0734242X0302100404]
   Bai L, 2018, 2018 11TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2018)
   Borvornvitchotikarn T, 2018, INT CONF SYST SIGNAL, DOI 10.1109/IWSSIP.2018.8439707
   Cao ZL, 2014, ELECTRON LETT, V50, P752, DOI 10.1049/el.2014.0795
   Cun XD, 2018, SIGNAL PROCESS-IMAGE, V65, P201, DOI 10.1016/j.image.2018.03.021
   Ding L, 2020, IEEE T IMAGE PROCESS, V29, P6561, DOI 10.1109/TIP.2020.2991530
   Ding L, 2018, IEEE IMAGE PROC, P356, DOI 10.1109/ICIP.2018.8451482
   Fan JW, 2018, IEEE T GEOSCI REMOTE, V56, P5368, DOI 10.1109/TGRS.2018.2815523
   Guan Q, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Heinrich MP, 2012, MED IMAGE ANAL, V16, P1423, DOI 10.1016/j.media.2012.05.008
   Hervella AS, 2018, PROCEDIA COMPUT SCI, V126, P97, DOI 10.1016/j.procs.2018.07.213
   Jiang DS, 2017, INT J COMPUT ASS RAD, V12, P2157, DOI 10.1007/s11548-017-1661-y
   Jiang DS, 2017, MED PHYS, V44, P497, DOI 10.1002/mp.12049
   Jiang DS, 2016, INT J COMPUT ASS RAD, V11, P997, DOI 10.1007/s11548-016-1407-2
   Kasiri K, 2016, IEEE ENG MED BIO, P1151, DOI 10.1109/EMBC.2016.7590908
   Legg PA, 2015, PATTERN RECOGN, V48, P1937, DOI 10.1016/j.patcog.2014.12.014
   Li Z, 2016, IEEE T MED IMAGING, V35, P63, DOI 10.1109/TMI.2015.2455416
   Li Z, 2015, PROC SPIE, V9413, DOI 10.1117/12.2081840
   Liu QG, 2017, 2017 20TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P487
   Liu XZ, 2019, IEEE T IND ELECTRON, V66, P1335, DOI 10.1109/TIE.2018.2833051
   Liu XL, 2019, MED BIOL ENG COMPUT, V57, P1037, DOI 10.1007/s11517-018-1924-y
   Liu XL, 2019, J MED IMAG HEALTH IN, V9, P153, DOI 10.1166/jmihi.2019.2554
   Liu XL, 2017, COMPUT ASSIST SURG, V22, P295, DOI 10.1080/24699322.2017.1389408
   Loeckx D, 2010, IEEE T MED IMAGING, V29, P19, DOI 10.1109/TMI.2009.2021843
   Myronenko A, 2010, IEEE T MED IMAGING, V29, P1882, DOI 10.1109/TMI.2010.2053043
   Rivaz H, 2014, MED IMAGE ANAL, V18, P343, DOI 10.1016/j.media.2013.12.003
   Russakoff DB, 2004, LECT NOTES COMPUT SC, V3023, P596
   Samant Sunita, 2020, Advances in Intelligent Computing and Communication. Proceedings of ICAC 2019. Lecture Notes in Networks and Systems (LNNS 109), P289, DOI 10.1007/978-981-15-2774-6_36
   Szeliski R, 1997, INT J COMPUT VISION, V22, P199, DOI 10.1023/A:1007996332012
   Wachinger C, 2012, MED IMAGE ANAL, V16, P1, DOI 10.1016/j.media.2011.03.001
   Xu Zhe, 2020, Med Image Comput Comput Assist Interv, V12263, P222, DOI 10.1007/978-3-030-59716-0_22
   Yelampalli PKR, 2018, IET IMAGE PROCESS, V12, P1692, DOI 10.1049/iet-ipr.2017.1305
   Zhang JY, 2015, INT J COMPUT ASS RAD, V10, P1765, DOI 10.1007/s11548-015-1219-9
   Zhang JK, 2019, IEEE IMAGE PROC, P839, DOI [10.1109/ICIP.2019.8802932, 10.1109/icip.2019.8802932]
   Zhu F, 2016, INFORM SCIENCES, V372, P16, DOI 10.1016/j.ins.2016.08.031
   Zhu XX, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051477
NR 38
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 25
BP 33885
EP 33909
DI 10.1007/s11042-021-11294-0
EA AUG 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WK6LS
UT WOS:000690339900002
DA 2024-07-18
ER

PT J
AU Dhingra, G
   Kumar, V
   Joshi, HD
AF Dhingra, Gittaly
   Kumar, Vinay
   Joshi, Hem Dutt
TI Clustering-based shadow detection from images with texture and color
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shadow detection; Image analysis; Color space; Clustering; Segmentation;
   Region classification
ID OBJECT DETECTION; CAST SHADOWS; REMOVAL
AB Shadow is inexorable essential in a scene created due to the presence of illumination variation and obstructed object. Shadow depicts information of images such as shape, position, orientation, and camera parameters. But sometimes, shadow degrades the quality of the image while objection segmentation, merging, scene analysis, scene interpretation, object recognition, and tracking. The presented paper aims are to provide a comprehensive technique to detect both indistinct and hard shadows from images. Firstly, a unique combination of 'luminance (L)', 'green-red (a*)' components, and 'blue-yellow (b*)' components of CIELab color space is used to differentiate shadows from objects. After color transformation, shadow regions are differentiated from background and object with an amalgamation of clustering techniques with the help of texture information. According to the extracted regions classification, finally suspected shadow regions are obtained. Experimental results verify that it robustly detects vague and hard shadows in the image.
C1 [Dhingra, Gittaly; Kumar, Vinay; Joshi, Hem Dutt] Thapar Inst Engn & Technol, Elect & Commun Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Dhingra, G (corresponding author), Thapar Inst Engn & Technol, Elect & Commun Engn Dept, Patiala, Punjab, India.
EM gittaly@thapar.edu; vinay.kumar@thapar.edu; Hemdutt.joshi@thapar.edu
CR Benedek C, 2007, INT J IMAG SYST TECH, V17, P190, DOI 10.1002/ima.20110
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Cavallaro A, 2005, IEE P-VIS IMAGE SIGN, V152, P398, DOI 10.1049/ip-vis:20045108
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Fang LZ, 2008, PATTERN RECOGN LETT, V29, P2182, DOI 10.1016/j.patrec.2008.08.009
   Figov Z, 2004, 7 IASTED INT C COMP
   Finlayson GD, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P117
   Finlayson GD, 2001, J OPT SOC AM A, V18, P253, DOI 10.1364/JOSAA.18.000253
   Garg P., 2014, INT J COMPUTSCI INFO, V5, P5745
   Glaister J, 2014, IEEE T BIO-MED ENG, V61, P1220, DOI 10.1109/TBME.2013.2297622
   Gomes V, 2017, PATTERN RECOGN, V63, P30, DOI 10.1016/j.patcog.2016.09.008
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Guo RQ, 2013, IEEE T PATTERN ANAL, V35, P2956, DOI 10.1109/TPAMI.2012.214
   Hirai S, 2013, IEEE T INFORM THEORY, V59, P7718, DOI 10.1109/TIT.2013.2276036
   Hsieh JW, 2003, IMAGE VISION COMPUT, V21, P505, DOI 10.1016/S0262-8856(03)00030-1
   Jiang K, 2013, IET COMPUT VIS, V7, P115, DOI 10.1049/iet-cvi.2012.0106
   Joshi AJ, 2008, IEEE T PATTERN ANAL, V30, P2055, DOI 10.1109/TPAMI.2008.150
   Khan EA, 2004, S APPL PERC GRAPH VI, P160
   Khan SH, 2016, IEEE T PATTERN ANAL, V38, P431, DOI 10.1109/TPAMI.2015.2462355
   Leng L, 2014, 2014 11TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS (ITNG), P523, DOI 10.1109/ITNG.2014.18
   Liu P, 2014, INT J FUTURE COMPUT, V3, P113
   Martel-Brisson N, 2007, IEEE T PATTERN ANAL, V29, P1133, DOI 10.1109/TPAMI.2007.1039
   Nadimi S, 2004, IEEE T PATTERN ANAL, V26, P1079, DOI 10.1109/TPAMI.2004.51
   Salvador E, 2004, COMPUT VIS IMAGE UND, V95, P238, DOI 10.1016/j.cviu.2004.03.008
   Shen L, 2015, PROC CVPR IEEE, P2067, DOI 10.1109/CVPR.2015.7298818
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Vicente TFY, 2018, IEEE T PATTERN ANAL, V40, P682, DOI 10.1109/TPAMI.2017.2691703
   Nguyen V, 2017, IEEE I CONF COMP VIS, P4520, DOI 10.1109/ICCV.2017.483
   Wang BS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20236929
   Wang Fei, 2020, Journal of Multimedia Information System, V7, P97
   Wu MH, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/2075781
   Yuan XS, 2015, IET IMAGE PROCESS, V9, P118, DOI 10.1049/iet-ipr.2014.0242
   Zhu J, 2010, ASIA S PACIF DES AUT, P220
NR 34
TC 6
Z9 6
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 25
BP 33763
EP 33778
DI 10.1007/s11042-021-11427-5
EA AUG 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WK6LS
UT WOS:000689522000001
DA 2024-07-18
ER

PT J
AU Korba, KA
   Abed, D
   Fezari, M
AF Korba, Karima Amara
   Abed, Djamel
   Fezari, Mohamed
TI Securing physical layer using new chaotic parametric maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic encryption; Multicarrier frequency-division multiplexing(OFDM);
   Physical layer security; Steganography; Passive optical network (PON)
ID SYSTEM; CONSTELLATION; SCHEME; TRANSFORM
AB In this work, to overcome the flaws of standard chaotic maps we generated two new cascaded structures, 3D Cubic-Sine and 2D Cubic-Cat chaotic parametric maps, based on a new parameter-varied Cubic map that enhance the chaos complexity and therefore offering a high randomness's level of the chaotic sequences and a huge key space.To provide optimum security for image transmission, we introduce several methods with a new approaches in Stenography and encryption of quadrature amplitude modulation symbols (QAM)based on the new maps, all in a purpose of enhancement physical layer security. Some of the best results obtained are: the peak signal-to-noise ratio (PSNR) values of 96.2956 dB, 88.767 dB, 78.1094 dB respectively with the three methods, also the entropy of encrypted image reaching much closely the ideal value, being 8 approximate to 7.9999868, strong resistance against differential attack with Number of Pixels Change Rate (NPCR) of 99.63%, Unified Average Changing Intensity (UACI) of 33.54% and high speed ciphering based on 3D Cubic-Sine noise encryption time of 0.024s.The experimental results indicate that these new maps outperforms the most competitive recently proposed maps in multimedia cryptosystems.
C1 [Korba, Karima Amara; Abed, Djamel] Univ 8 Mai 1945 Guelma, LABCAV Lab, Box 401, Guelma 24000, Algeria.
   [Fezari, Mohamed] Univ Badji Mokhtar Annaba, LASA Lab, Box 12, Annaba 23000, Algeria.
C3 Universite 8 Mai 1945 de Guelma; Universite Badji Mokhtar - Annaba
RP Korba, KA (corresponding author), Univ 8 Mai 1945 Guelma, LABCAV Lab, Box 401, Guelma 24000, Algeria.
EM amarakorba.karima@univ-guelma.dz; abed.djamel@univ-guelma.dz
RI Korba, karima Amara/K-8510-2018; ABED, Djamel/N-3962-2016
OI Korba, karima Amara/0000-0003-1769-3782; ABED,
   Djamel/0000-0001-6153-1073
CR Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Andreatos AS, 2013, J ENG SCI TECHNOLOGY, V6
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Bouchemel A, 2018, IEEE COMMUN LETT, V22, P934, DOI 10.1109/LCOMM.2018.2812821
   Cao WJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107457
   Chen B, 2010, 2010 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, NETWORKING AND INFORMATION SECURITY (WCNIS), VOL 2, P6, DOI 10.1109/WCINS.2010.5541875
   Guesmi R, 2021, MULTIMED TOOLS APPL, V80, P1925, DOI 10.1007/s11042-020-09672-1
   Hua ZY, 2018, IEEE T CIRCUITS-I, V65, P235, DOI 10.1109/TCSI.2017.2717943
   Hua ZY, 2018, IEEE T IND ELECTRON, V65, P2557, DOI 10.1109/TIE.2017.2736515
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Lasota A., 1994, Chaos, Fractals, and Noise; Stochastic Aspects of Dynamics
   Liu B, 2018, OPT EXPRESS, V26, P6890, DOI 10.1364/OE.26.006890
   Moldovyan NA, 2006, PROGRAMMING SERIES
   Saljoughi AS, 2019, PATTERN ANAL APPL, V22, P243, DOI 10.1007/s10044-018-0765-5
   Sayed WS, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S021812741730004X
   Sultan A, 2018, IEEE ACCESS, V6, P47199, DOI 10.1109/ACCESS.2018.2866797
   Sultan A, 2018, INT BHURBAN C APPL S, P446, DOI 10.1109/IBCAST.2018.8312262
   Wu QL, 2022, CURR PSYCHOL, V41, P2668, DOI 10.1007/s12144-020-00780-7
   Yang B, 2018, MULTIMED TOOLS APPL, V77, P21803, DOI 10.1007/s11042-017-5590-0
   Yasser I, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/9597619
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang GD, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12030355
   Zhang LJ, 2015, OPT LETT, V40, P2711, DOI 10.1364/OL.40.002711
   Zhang LJ, 2013, OPT EXPRESS, V21, P15627, DOI 10.1364/OE.21.015627
   Zhang W, 2017, J LIGHTWAVE TECHNOL, V35, P1524, DOI 10.1109/JLT.2017.2669909
   Zhou YC, 2015, IEEE T CYBERNETICS, V45, P2001, DOI 10.1109/TCYB.2014.2363168
   Zhou YC, 2013, SIGNAL PROCESS, V93, P3039, DOI 10.1016/j.sigpro.2013.04.021
   Zhuo XH, 2020, OPT COMMUN, V462, DOI 10.1016/j.optcom.2020.125304
NR 29
TC 3
Z9 4
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32595
EP 32613
DI 10.1007/s11042-021-11226-y
EA JUL 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000679633200002
DA 2024-07-18
ER

PT J
AU Dhiman, R
   Kang, GS
   Gupta, V
AF Dhiman, Ritika
   Kang, Gurkanwal Singh
   Gupta, Varun
TI Modified dense convolutional networks based emotion detection from
   speech using its paralinguistic features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion detection; Speech emotion recognition; Paralinguistic features;
   Dense convolutional networks; Residual networks; Convolutional neural
   networks; Deep neural networks; Machine learning
ID EMPIRICAL MODE DECOMPOSITION; RECOGNITION; REGRESSION
AB Emotion recognition through speech is one of the fundamental approaches for human interaction. Speech modulations stipulate different emotions and context. In this paper, we propose modified dense convolutional networks (modified DenseNet201) for emotion detection from speech using its paralinguistic features such as vocal tract features. The proposed network performs emotion classification from speech using spectrograms of its audio files. The proposed network outperforms other alternative models like residual networks, AlexNet, VGG16, SVM, XGBoost, boosted random forest etc. for emotion classification from speech. Moreover, the proposed network surpasses all other existing methods proposed in the literature and obtains state-of-the-art results in most of the cases. Further, the proposed network has been successfully validated on two different language datasets: 'EmoDB' and 'SAVEE' which qualifies it as a language-independent emotion detection system from speech.
C1 [Dhiman, Ritika; Kang, Gurkanwal Singh; Gupta, Varun] Chandigarh Coll Engn & Technol, Dept Comp Sci & Engn, Degree Wing, Chandigarh, India.
RP Gupta, V (corresponding author), Chandigarh Coll Engn & Technol, Dept Comp Sci & Engn, Degree Wing, Chandigarh, India.
EM varungupta@ccet.ac.in
RI Gupta, Varun/KFA-9728-2024; Gupta, Varun/AAW-9860-2020
OI Gupta, Varun/0000-0002-2633-5920
CR Abdelwahab M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5084, DOI 10.1109/ICASSP.2018.8461866
   [Anonymous], 2017, ARXIV170401444CS
   [Anonymous], 2010, P 27 INT C INT C MAC, DOI DOI 10.1155/2011/176802
   [Anonymous], 2016, ARXIV160202410CS
   Arora P, 2015, PROCEEDINGS OF THE 4TH INTERNATIONAL WORKSHOP ON MULTIMODAL ANALYSES ENABLING ARTIFICIAL AGENTS IN HUMAN-MACHINE INTERACTION (MA3HMI 2018), P15, DOI 10.1145/3279972.3279980
   Barsoum E, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P279, DOI 10.1145/2993148.2993165
   Bin Abdul Qayyum Alif, 2019, 2019 IEEE International Conference on Signal Processing, Information, Communication & Systems (SPICSCON), P122, DOI 10.1109/SPICSCON48833.2019.9065172
   Birhala A, 2020, 2020 43RD INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P305, DOI [10.1109/TSP49548.2020.9163474, 10.1109/tsp49548.2020.9163474]
   Blouin, 2005, 9 EUR C SPEECH COMM
   Bothe C, 2018, INTERSPEECH, P996
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Burmania A, 2017, INTERSPEECH, P152, DOI 10.21437/Interspeech.2017-1278
   Cao HW, 2014, IEEE T AFFECT COMPUT, V5, P377, DOI 10.1109/TAFFC.2014.2336244
   CUMMINGS KE, 1995, J ACOUST SOC AM, V98, P88, DOI 10.1121/1.413664
   Dai DY, 2019, INT CONF ACOUST SPEE, P7405, DOI [10.1109/icassp.2019.8683765, 10.1109/ICASSP.2019.8683765]
   Dörfler M, 2017, 2017 INTERNATIONAL CONFERENCE ON SAMPLING THEORY AND APPLICATIONS (SAMPTA), P152, DOI 10.1109/SAMPTA.2017.8024472
   Fan GF, 2020, SUSTAIN CITIES SOC, V61, DOI 10.1016/j.scs.2020.102320
   Fan GF, 2020, J FORECASTING, V39, P737, DOI 10.1002/for.2655
   Fan GF, 2016, NEUROCOMPUTING, V173, P958, DOI 10.1016/j.neucom.2015.08.051
   Fan GF, 2013, ENERGIES, V6, P1887, DOI 10.3390/en6041887
   Fayek HM, 2017, NEURAL NETWORKS, V92, P60, DOI 10.1016/j.neunet.2017.02.013
   Fourier Analysis and Synthesis,, 2018, HYPERPHYSICS
   Fox E., 2018, BRAIN NEUROSCI ADV, DOI 10.1177/2398212818812628
   Ghaleb E, 2019, INT CONF AFFECT, DOI [10.1109/acii.2019.8925444, 10.1109/ACII.2019.8925444]
   Gulcehre C, 2014, ARXIV PREPRINT ARXIV
   Gulcehre C, 2017, IEEE IJCNN, P125, DOI 10.1109/IJCNN.2017.7965845
   Hannun Awni, 2014, ARXIV
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hong WC, 2019, ENERGIES, V12, DOI 10.3390/en12061093
   Huang CW, 2016, INTERSPEECH, P1387, DOI 10.21437/Interspeech.2016-448
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iwendi C, 2020, FRONT PUBLIC HEALTH, V8, DOI 10.3389/fpubh.2020.00357
   Jackson P., 2014, Surrey audio-visual expressed emotion (savee) database
   Lakomkin E, 2018, IEEE INT CONF ROBOT, P4445
   Lee J, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1537
   Li MW, 2019, NONLINEAR DYNAM, V97, P2579, DOI 10.1007/s11071-019-05149-5
   McFee B., 2015, P 14 PYTH SCI C, P18, DOI [DOI 10.25080/MAJORA-7B98E3ED-003, 10.25080/Majora-7b98e3ed-003]
   Neiberg D., 2006, P FONETIK, P101
   Oudeyer, 2002, SPEECH PROSODY 2002
   Ravindran G., 2010, Journal of Biomedical Science & Engineering, V3, P85, DOI 10.4236/jbise.20010.31013
   Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Singh R, 2020, ARAB J SCI ENG, V45, P3111, DOI 10.1007/s13369-019-04293-9
   Smith LN, 2019, PROC SPIE, V11006, DOI 10.1117/12.2520589
   Smith LN, 2017, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV.2017.58
   Smith L, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P560
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Vlasenko B, 2008, LECT NOTES ARTIF INT, V5078, P217, DOI 10.1007/978-3-540-69369-7_24
   Wang ZQ, 2017, INT CONF ACOUST SPEE, P5150, DOI 10.1109/ICASSP.2017.7953138
   Wu Y., 2016, GOOGLES NEURAL MACHI
   Zhang ZC, 2020, NEUROCOMPUTING, V410, P185, DOI 10.1016/j.neucom.2020.05.075
NR 51
TC 1
Z9 1
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32041
EP 32069
DI 10.1007/s11042-021-11210-6
EA JUL 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000678031600002
DA 2024-07-18
ER

PT J
AU Hajihashemi, V
   Najafabadi, HE
   Gharahbagh, AA
   Leung, H
   Yousefan, M
   Tavares, JMRS
AF Hajihashemi, Vahid
   Najafabadi, Hamid Esmaeili
   Gharahbagh, Abdoreza Alavi
   Leung, Henry
   Yousefan, Mahdi
   Tavares, Joao Manuel R. S.
TI A novel high-efficiency holography image compression method, based on
   HEVC, Wavelet, and nearest-neighbor interpolation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compression; Digital holography; HEVC; Wavelet; Interpolation
ID DIGITAL HOLOGRAM; ALGORITHM
AB One of the critical challenges facing 3D video systems and images such as holography lies in their compression technique. High-efficiency video coding (HEVC) has emerged as one of the leading schemes to address this challenge. In this article, a novel method based on wavelet transform is presented to improve HEVC, particularly in digital holography systems (object plane). In this regard, wavelet and resizing are included in the coding process, while extra HEVC decoders and encoders are added to predict and decrease errors in the target. Simulation results reveals that the proposed algorithm reduces Bjontegaard-Delta (BD) bitrate 17.5% (based on average BD-Rate values) compared to the original HEVC (H.265) scheme while maintaining signal fidelity and even enhancing it slightly. We observe an increased BD-peak-signal-to-noise ratio (BD-PSNR) in real and imaginary parts of digital holograms of high rate quantization values up to 1.1 dB.
C1 [Hajihashemi, Vahid; Gharahbagh, Abdoreza Alavi] Univ Porto, Fac Engn, Porto, Portugal.
   [Najafabadi, Hamid Esmaeili; Leung, Henry] Univ Calgary, 2500 Univ Dr NW, Calgary, AB T2N 1N4, Canada.
   [Yousefan, Mahdi] Yazd Univ, Yazd, Iran.
   [Tavares, Joao Manuel R. S.] Univ Porto, Fac Engn, Dept Engn Mecan, Inst Ciencia & Inovacao Engn Mecan & Engn Ind, Porto, Portugal.
C3 Universidade do Porto; University of Calgary; University of Yazd;
   Universidade do Porto
RP Najafabadi, HE (corresponding author), Univ Calgary, 2500 Univ Dr NW, Calgary, AB T2N 1N4, Canada.
EM hajihashemi.vahid@ieee.org; hamid.esmaeili@gmail.com;
   abalavi.gh@gmail.com; tavares@fe.up.pt
RI Hajihashemi, Vahid/KEZ-9848-2024; Esmaeili Najafabadi,
   hamid/AAZ-4165-2020; Tavares, João Manuel R.S./M-5305-2013
OI Esmaeili Najafabadi, hamid/0000-0003-1653-9900; Tavares, João Manuel
   R.S./0000-0001-7603-6526; Alavi Gharahbagh,
   Abdorreza/0000-0003-0863-1977
CR Amish F, 2019, J REAL-TIME IMAGE PR, V16, P1559, DOI 10.1007/s11554-016-0664-1
   Bernardo, 2018, BENCHMARKING CODING, P18, DOI [10.1117/12.2315361, DOI 10.1117/12.2315361]
   Bernardo MV, 2018, SIGNAL PROCESS-IMAGE, V68, P193, DOI 10.1016/j.image.2018.08.006
   Blinder, 2015, 2015 7 INT WORKSH QU, P2015, DOI [10.1109/QoMEX.2015.7148145, DOI 10.1109/QOMEX.2015.7148145]
   Blinder D, 2016, OPT EXPRESS, V24, P23094, DOI 10.1364/OE.24.023094
   Blinder D, 2013, PROC SPIE, V8856, DOI 10.1117/12.2027114
   Chen J, 2019, MULTIMED TOOLS APPL, V78, P29291, DOI 10.1007/s11042-018-6832-5
   Chen Y, 2018, PICT COD SYMP, P41, DOI 10.1109/PCS.2018.8456249
   Cheremkhin PA, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-44119-0
   Darakis E, 2007, APPL OPTICS, V46, P4579, DOI 10.1364/AO.46.004579
   Gajitzki P, 2014, 2014 11TH INTERNATIONAL SYMPOSIUM ON ELECTRONICS AND TELECOMMUNICATIONS (ISETC)
   Grgic, 2007, POSSIBILITIES LIMITA
   Hamout H, 2019, J REAL-TIME IMAGE PR, V16, P2093, DOI 10.1007/s11554-017-0718-z
   J. O.-S. L, 2017, CTR UNDEFINED AV1 GE
   Karpinsky N, 2013, OPT LASER ENG, V51, P620, DOI 10.1016/j.optlaseng.2012.12.021
   Bang LT, 2011, OPT EXPRESS, V19, P8019, DOI 10.1364/OE.19.008019
   Milicevic ZM, 2018, 2018 26TH TELECOMMUNICATIONS FORUM (TELFOR), P603
   Pastuszak G, 2016, IEEE T CIRC SYST VID, V26, P210, DOI 10.1109/TCSVT.2015.2428571
   Peixeiro JP, 2018, IEEE T MULTIMEDIA, V20, P282, DOI 10.1109/TMM.2017.2742701
   Perra, 2019, EXPLORATORY STUDY OB, P49, DOI [10.1117/12.2528402, DOI 10.1117/12.2528402]
   Saldanha M, 2020, IEEE T CIRCUITS-I, V67, P1704, DOI 10.1109/TCSI.2020.2977297
   Senoh T, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.11.112302
   Seo YH, 2007, SIGNAL PROCESS-IMAGE, V22, P144, DOI 10.1016/j.image.2006.11.007
   Sharabayko M., 2013, APPL MATH SCI, V7, P6803, DOI DOI 10.12988/AMS.2013
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Symeonidou A, 2019, OPT EXPRESS, V27, P37383, DOI 10.1364/OE.27.037383
   Symeonidou A, 2016, PROC SPIE, V9896, DOI 10.1117/12.2225201
   Viswanathan K, 2013, PROC SPIE, V8856, DOI 10.1117/12.2027199
   Viswanathan K, 2015, IEEE IMAGE PROC, P3334, DOI 10.1109/ICIP.2015.7351421
   Viswanathan K, 2014, PROC SPIE, V9216, DOI 10.1117/12.2061588
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhang QW, 2020, IEEE ACCESS, V8, P129075, DOI 10.1109/ACCESS.2020.3009424
NR 32
TC 6
Z9 6
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 31953
EP 31966
DI 10.1007/s11042-021-11232-0
EA JUL 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000675334700004
DA 2024-07-18
ER

PT J
AU Leng, LX
   Li, JC
   Shi, HB
   Zhu, Y
AF Leng, Lixiong
   Li, Jingchen
   Shi, Haobin
   Zhu, Yi'an
TI Graph convolutional network-based reinforcement learning for tasks
   offloading in multi-access edge computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-access edge computing; Graph convolutional network; Reinforcement
   learning
ID ALGORITHM; OPTIMIZATION
AB To achieve high quality of service for computation-intensive applications, multi-access edge computing (MEC) is proposed for offloading tasks to MEC servers. The emerging reinforcement learning-based task offloading strategies have attracted attention of researchers, but the incomplete Markov models in them result in limited improvements. This work proposes a graph convolutional network-based reinforcement learning (GRL-based) method to enhance the reinforcement learning-based task offloading in MEC. The Graph Convolutional Network is introduced to extract features from tasks through regarding the task set as a directed acyclic graph. Then we construct a complete Markov model for the offloading strategy. In the proposed GRL-based method, the decision process is deployed in the user layer, while the training process is deployed in the cloud layer. An off-policy reinforcement learning method, soft actor-critic, is used to train the offloading strategy, by which the sampling and training can be implemented separately. Several simulation experiments show the proposed GRL-based method performs better than baseline methods, and it can achieve continuous decisions for task offloading efficiently.
C1 [Leng, Lixiong; Li, Jingchen; Shi, Haobin; Zhu, Yi'an] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University
RP Shi, HB (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.
EM shihaobin@nwpu.edu.cn
OI Jingchen, Li/0000-0003-0905-0816
FU National Natural Science Foundation of China [62076202, 61976178]
FX This work is supported by National Natural Science Foundation of China
   under Grant 62076202, 61976178.
CR Al-Habob AA, 2020, IEEE COMMUN LETT, V24, P71, DOI 10.1109/LCOMM.2019.2948179
   Alameddine HA, 2019, IEEE J SEL AREA COMM, V37, P668, DOI 10.1109/JSAC.2019.2894306
   Aliyu M, 2020, INT J CLOUD APPL COM, V10, P1, DOI 10.4018/IJCAC.2020040101
   Alweshah M, 2022, NEURAL COMPUT APPL, V34, P11267, DOI 10.1007/s00521-020-05210-0
   Andrews JG, 2014, IEEE J SEL AREA COMM, V32, P1065, DOI 10.1109/JSAC.2014.2328098
   [Anonymous], 2018, ARXIV180801977
   Babaeizadeh M., 2016, ARXIV PREPRINT ARXIV
   Barto Andrew G, 2004, Handbook of Learning and Approximate Dynamic Programming, V10
   Cao XW, 2018, IEEE INT WORK SIGN P, P111
   Chen M, 2015, IEEE NETWORK, V29, P32, DOI 10.1109/MNET.2015.7064900
   Ferrer AJ, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3243929
   François-Lavet V, 2018, FOUND TRENDS MACH LE, V11, P219, DOI 10.1561/2200000071
   Gläscher J, 2010, NEURON, V66, P585, DOI 10.1016/j.neuron.2010.04.016
   Hämäläinen P, 2020, IEEE INT WORKS MACH, DOI [10.1109/mlsp49062.2020.9231618, 10.1109/MLSP49062.2020.9231618]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu H, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3233
   Khekare G, 2020, INT J SOFTW SCI COMP, V12, P1, DOI 10.4018/IJSSCI.2020100101
   Kibria MG, 2018, IEEE ACCESS, V6, P32328, DOI 10.1109/ACCESS.2018.2837692
   Kipf TN, 2017, INT C LEARN REPR
   Konda VR, 2003, SIAM J CONTROL OPTIM, V42, P1143, DOI 10.1137/S0363012901385691
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Li J, 2018, IEEE WCNC, DOI 10.1109/WCNC.2018.8377343
   Liu LQ, 2017, IEEE SYMP COMP COMMU, P832, DOI 10.1109/ISCC.2017.8024630
   Lv ZH, 2021, FUTURE GENER COMP SY, V115, P90, DOI 10.1016/j.future.2020.08.037
   Lv ZH, 2021, IEEE T INTELL TRANSP, V22, P2048, DOI 10.1109/TITS.2020.3019756
   Lv ZH, 2020, COMPUT COMMUN, V161, P19, DOI 10.1016/j.comcom.2020.07.022
   Lv ZH, 2020, IEEE INTERNET THINGS, V7, P5706, DOI 10.1109/JIOT.2019.2942719
   Lv ZH, 2021, SOFTWARE PRACT EXPER, V51, P2446, DOI 10.1002/spe.2806
   Mehrabi M, 2019, IEEE ACCESS, V7, P166079, DOI 10.1109/ACCESS.2019.2953172
   Memos VA, 2018, FUTURE GENER COMP SY, V83, P619, DOI 10.1016/j.future.2017.04.039
   Mirri S, 2020, COMPUTATION, V8, DOI 10.3390/computation8030074
   Munos R, 2016, NEURAL INFORM PROCES, P1054
   Nachum O, 2017, ADV NEUR IN, V30
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Tian YR, 2017, PROC CVPR IEEE, P6128, DOI 10.1109/CVPR.2017.649
   Tran TX, 2019, IEEE T VEH TECHNOL, V68, P856, DOI 10.1109/TVT.2018.2881191
   Uva G, 2019, MEASUREMENT, V131, P183, DOI 10.1016/j.measurement.2018.08.014
   Van Brummelen J, 2018, TRANSPORT RES C-EMER, V89, P384, DOI 10.1016/j.trc.2018.02.012
   Wang J, 2019, IEEE COMMUN MAG, V57, P64, DOI 10.1109/MCOM.2019.1800971
   Yao L., 2019, Proceedings of the AAAI Conference on Artificial Intelligence, V33, P7370
   Zhang K, 2019, IEEE INTERNET THINGS, V6, P7635, DOI 10.1109/JIOT.2019.2903191
   Zhang YT, 2018, 2018 5TH IEEE INTERNATIONAL CONFERENCE ON CYBER SECURITY AND CLOUD COMPUTING (IEEE CSCLOUD 2018) / 2018 4TH IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING AND SCALABLE CLOUD (IEEE EDGECOM 2018), P190, DOI 10.1109/CSCloud/EdgeCom.2018.00041
   Zhao XL, 2019, FUTURE GENER COMP SY, V99, P346, DOI 10.1016/j.future.2019.04.039
NR 43
TC 12
Z9 13
U1 4
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29163
EP 29175
DI 10.1007/s11042-021-11130-5
EA JUN 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000663990000003
DA 2024-07-18
ER

PT J
AU Kim, G
   Shu, DW
   Kwon, J
AF Kim, Guisik
   Shu, Dong Wook
   Kwon, Junseok
TI Robust person re-identification via graph convolution networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Graph convolution
AB Person re-identification (re-id) aims to identity the same person over multiple cameras; it has been successfully applied to various computer vision applications as a fundamental method. Owing to the development of deep learning, person re-id methods, which typically use triplet networks based on triplet loss, have demonstrated great success. However, the appearances of people are similar and hence difficult to distinguish in many cases. Therefore, we present a novel graph convolution network and enhances traditional triplet loss functions. Our method defines reference, positive, and negative features for triplet loss as three vertices of a graph, respectively, and adjusts their mutual distance through learning. The method adopts graph convolutions efficiently, thereby affording low computational costs. Experimental results demonstrate that our method is superior to the baseline on the Market-1501 dataset. The proposed GCN-based triplet loss considerably contributes to improve re-identification methods quantitatively and qualitatively.
C1 [Kim, Guisik; Shu, Dong Wook; Kwon, Junseok] Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
C3 Chung Ang University
RP Kwon, J (corresponding author), Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
EM jskwon@cau.ac.kr
OI kwon, junseok/0000-0001-9526-7549; Kim, Guisik/0000-0002-8254-0881
FU Chung-Ang University Graduate Research Scholarship Grants in 2018;
   National Research Foundation of Korea (NRF) - Korea government(MSIT)
   [NRF-2020R1C1C1004907]
FX This work was partly supported by the Chung-Ang University Graduate
   Research Scholarship Grants in 2018 and partly supported by the National
   Research Foundation of Korea (NRF) grant funded by the Korea
   government(MSIT) (NRF-2020R1C1C1004907).
CR [Anonymous], 2016, IEEE INT CON MULTI
   Bai S, 2017, AAAI CONF ARTIF INTE, P1281
   Barbosa IB, 2018, COMPUT VIS IMAGE UND, V167, P50, DOI 10.1016/j.cviu.2017.12.002
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen YB, 2017, IEEE INT CONF COMP V, P2590, DOI 10.1109/ICCVW.2017.304
   Fan X, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10062198
   Hermans Alexander, 2017, ARXIV170307737
   Hou RB, 2019, PROC CVPR IEEE, P7176, DOI 10.1109/CVPR.2019.00735
   Jiang Bo, 2019, CORR
   Li W, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2194
   LI Y, 2017, PROC CVPR IEEE, P4438, DOI [DOI 10.1109/CVPR.2017.472, DOI 10.1109/CVPR.2017.199]
   Liu JX, 2018, PROC CVPR IEEE, P4099, DOI 10.1109/CVPR.2018.00431
   Liu XL, 2017, IEEE I CONF COMP VIS, P1040, DOI 10.1109/ICCV.2017.118
   Ristani E, 2018, PROC CVPR IEEE, P6036, DOI 10.1109/CVPR.2018.00632
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shen YT, 2018, LECT NOTES COMPUT SC, V11219, P508, DOI 10.1007/978-3-030-01267-0_30
   Su C, 2017, IEEE ICC
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang YC, 2018, PROC CVPR IEEE, P1470, DOI 10.1109/CVPR.2018.00159
   Wojke N, 2018, IEEE WINT CONF APPL, P748, DOI 10.1109/WACV.2018.00087
   Xiao Q., 2017, ARXIV171000478
   Xiao Tong, 2016, arXiv preprint arXiv:1604.01850, V2
   Yang JR, 2020, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR42600.2020.00335
   Ye M, 2019, IEEE T IMAGE PROCESS, V28, P2976, DOI 10.1109/TIP.2019.2893066
   Yu R, 2018, LECT NOTES COMPUT SC, V11220, P196, DOI 10.1007/978-3-030-01270-0_12
   Zhai Y, 2019, IEEE COMPUT SOC CONF, P1526, DOI 10.1109/CVPRW.2019.00194
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2019, IEEE T CIRC SYST VID, V29, P3037, DOI 10.1109/TCSVT.2018.2873599
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhou SP, 2017, PROC CVPR IEEE, P5028, DOI 10.1109/CVPR.2017.534
NR 34
TC 4
Z9 4
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29129
EP 29138
DI 10.1007/s11042-021-11127-0
EA JUN 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000662846600002
DA 2024-07-18
ER

PT J
AU Mishra, R
AF Mishra, Ravi
TI Video shot boundary detection using hybrid dual tree complex wavelet
   transform with Walsh Hadamard transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shot boundary detection; Feature extraction; Classification; Cut
   transition; Gradual transition
ID EXTRACTION
AB Shot boundary detection (SBD) is the initial process in the video analysis, indexing, summarization, and retrieval. Detection of correct transition from a video sequence and the feature extraction and their effectiveness of presenting the visual content of the video frames are the main factors in SBD. In this paper, the Hybrid Dual-Tree Complex Wavelet Transform with Walsh Hadamard transform (DTCWT-WHT) and the optimized Deep belief network (DBN) are proposed for the SBD. A new feature extraction technique is developed for extracting the feature vector from each block of the image frames. Preprocessing is the initial step to remove the illumination noise in the video frames. In preprocessing, the Fast Averaging Peer Group filter is designed, and the significant feature of this filter is the computational efficiency. After preprocessing, the distance of the adjacent frame is computed using HSV color histogram distance. Hybrid approach is proposed to extract feature and the edge boundaries from the frames, and the continuity signal is constructed. Then, the extracted features are fed to the DBN for the classification process. Social ski driver optimization algorithm (SSDOA) is utilized to update the weights of DBN. Finally, this proposed method detects the abrupt (cut) and gradual (fade in and fade out) transitions from the video frames. Four well-known datasets such as TRECVID 2016, 2017, 2018 and 2019 datasets are utilized to examine the proposed framework. The capability of proposed work is reinforced by performing the comparison with the recent techniques. The experimental outcomes showed the efficiency of the proposed framework by comparing with the existing techniques.
C1 [Mishra, Ravi] GH Raisoni Inst Engn & Technol, Dept Elect & Telecommun, Nagpur, Maharashtra, India.
RP Mishra, R (corresponding author), GH Raisoni Inst Engn & Technol, Dept Elect & Telecommun, Nagpur, Maharashtra, India.
EM ravi.mishra@raisoni.net
RI Mishra, Ravi/AAS-4398-2021
CR Abdulhussain SH, 2019, MULTIMED TOOLS APPL, V78, P20361, DOI 10.1007/s11042-019-7364-3
   Asha D., 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 900), P703, DOI 10.1007/978-981-13-3600-3_67
   Bhaumik H, 2019, APPL SOFT COMPUT, V75, P633, DOI 10.1016/j.asoc.2018.10.053
   Bi CK, 2018, IEEE ACCESS, V6, P21397, DOI 10.1109/ACCESS.2018.2825106
   Chakraborty S, 2021, MULTIMED TOOLS APPL, V80, P3071, DOI 10.1007/s11042-020-09683-y
   Chakraborty S, 2019, APPL INTELL, V49, P3207, DOI 10.1007/s10489-019-01444-1
   Chen Y, 2014, IEEE T MED IMAGING, V33, P2271, DOI 10.1109/TMI.2014.2336860
   Fan JY, 2017, MULTIMED TOOLS APPL, V76, P10169, DOI 10.1007/s11042-016-3604-y
   Gygli M., 2018, 2018 INT C CONT BAS, P1
   Hannane R, 2016, INT J MULTIMED INF R, V5, P89, DOI 10.1007/s13735-016-0095-6
   Kar T, 2017, SIGNAL IMAGE VIDEO P, V11, P1237, DOI 10.1007/s11760-017-1080-0
   Kumar G. S. Naveen, 2018, Proceedings of the Second International Conference on Computational Intelligence and Informatics. ICCII-2017. Advances in Intelligent Systems and Computing (AISC 712), P557, DOI 10.1007/978-981-10-8228-3_51
   Kumar R, 2020, LECT NOTES ELECTR EN, V587, P991, DOI 10.1007/978-981-32-9775-3_88
   Li YS, 2017, IEEE ACCESS, V5, P10323, DOI 10.1109/ACCESS.2017.2712789
   Liang R, 2017, IEEE INT SYM MULTIM, P489, DOI 10.1109/ISM.2017.97
   Liu F, 2015, 2015 SEVENTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P351, DOI 10.1109/ICACI.2015.7184728
   Malinski L, 2016, J REAL-TIME IMAGE PR, V11, P427, DOI 10.1007/s11554-015-0500-z
   Mondal J, 2018, MULTIMED TOOLS APPL, V77, P8139, DOI 10.1007/s11042-017-4707-9
   Parmar M, 2015, COMPUT J, V58, P2135, DOI 10.1093/comjnl/bxv042
   Prabavathy AK, 2019, CLUSTER COMPUT, V22, P1211, DOI 10.1007/s10586-017-1201-0
   Prathiba T, 2021, WIRELESS PERS COMMUN, V116, P411, DOI 10.1007/s11277-020-07721-4
   Rashmi BS, 2021, MULTIMED TOOLS APPL, V80, P641, DOI 10.1007/s11042-020-09697-6
   Sasithradevi A, 2020, J VIS COMMUN IMAGE R, V67, DOI 10.1016/j.jvcir.2020.102754
   Singh A, 2020, SOFTWARE PRACT EXPER, V50, P2012, DOI 10.1002/spe.2722
   Tharwat A, 2020, NEURAL COMPUT APPL, V32, P6925, DOI 10.1007/s00521-019-04159-z
   Thounaojam DM, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/8469428
   Tippaya S, 2017, IEEE ACCESS, V5, P12563, DOI 10.1109/ACCESS.2017.2717998
   Wu LF, 2019, IEEE ACCESS, V7, P77268, DOI 10.1109/ACCESS.2019.2922038
   Xu JW, 2016, 2016 30TH ANNIVERSARY OF VISUAL COMMUNICATION AND IMAGE PROCESSING (VCIP)
   Yang SH, 2019, APPL ARTIF INTELL, V33, P1035, DOI 10.1080/08839514.2019.1661118
   Youssef B, 2017, COMPUT VIS IMAGE UND, V161, P20, DOI 10.1016/j.cviu.2017.06.003
NR 31
TC 9
Z9 9
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28109
EP 28135
DI 10.1007/s11042-021-11052-2
EA MAY 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000655960200005
DA 2024-07-18
ER

PT J
AU Sabir, S
   Guleria, V
AF Sabir, Shazia
   Guleria, Vandana
TI Multi-layer color image encryption using random matrix affine cipher,
   RP2DFrHT and 2D Arnold map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Random matrix affine cipher; Reality preserving two dimensional discrete
   fractional Hartley transform; 2D Arnold map; Image encryption and image
   decryption
ID FRACTIONAL FOURIER-TRANSFORM; HARTLEY TRANSFORM; SECURITY; ALGORITHM
AB Confidentiality, integrity, authenticity, non-repudiation and storing and transmitting images over the unsecured channel has become a challenging task nowadays. In this scenario, a robust image encryption technique over open network has grasped a great deal of attention. In this paper to meet this challenge, we have established a new multi-layer robust color image encryption using random matrix affine cipher (RMAC), reality preserving two dimensional discrete fractional Hartley transform (RP2DFrHT) and two dimensional Arnold map. The first stage of encryption is designed through RMAC. RMAC provides security in co-ordinate domain as well as in geometrical domain. So if a hacker has knowledge about all the pixels of an image, but has no information about the mechanism of co-ordinate domain he/she cannot steal any information. The second stage of encryption is obtained incorporating the concept of RP2DFrHT. The reality preserving transform eliminates the complex-valued coefficients and provides the real-valued coefficients of encrypted image. The real-valuedness of data provides convenient platform for display, storage and transmission in digital domain. The third stage of encryption is done using 2D Arnold map, which not only enhances the security but also enlarges key space. Therefore, the proposed technique provides security in geometrical, co-ordinate, frequency and time domains simultaneously. The security of our proposed technique depends upon the secret keys as well as their correct arrangements. Simulation analysis provides the complete visual results of all stages of encrypted and decrypted images. Sensitivity analysis validates that our proposed technique is highly sensitive towards its secret keys and their arrangements. Statistical analysis such as histogram analysis, MSE, PSNR, correlation coefficient, entropy analysis and resistivity of classical attacks validates the effectiveness and feasibility of our proposed work. Moreover, comparison analysis testifies that our proposed technique functions significantly well as compared to existing similar techniques.
C1 [Sabir, Shazia; Guleria, Vandana] Birla Inst Technol Mesra, Dept Math, Ranchi, Bihar, India.
C3 Birla Institute of Technology Mesra
RP Guleria, V (corresponding author), Birla Inst Technol Mesra, Dept Math, Ranchi, Bihar, India.
EM vandana@bitmesra.ac.in
CR Abdulla A. A., 2015, Ph.D. dissertation
   Abuturab MR, 2015, OPT LASER ENG, V69, P49, DOI 10.1016/j.optlaseng.2015.01.001
   Abuturab MR, 2013, OPT LASER ENG, V51, P317, DOI 10.1016/j.optlaseng.2012.09.008
   Abuturab MR, 2012, OPT LASER ENG, V50, P772, DOI 10.1016/j.optlaseng.2011.12.006
   Candan Ç, 2000, IEEE T SIGNAL PROCES, V48, P1329, DOI 10.1109/78.839980
   Chen H, 2013, OPT LASER ENG, V51, P768, DOI 10.1016/j.optlaseng.2013.01.016
   Chen LF, 2005, OPT COMMUN, V254, P361, DOI 10.1016/j.optcom.2005.05.052
   Chen LF, 2008, OPTIK, V119, P286, DOI 10.1016/j.ijleo.2006.11.005
   Chen LF, 2006, OPT EXPRESS, V14, P8552, DOI 10.1364/OE.14.008552
   Guleria V, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102524
   Guo Q, 2010, OPT LASER ENG, V48, P1174, DOI 10.1016/j.optlaseng.2010.07.005
   Hennelly B, 2003, OPT COMMUN, V226, P61, DOI 10.1016/j.optcom.2003.08.030
   Huang JJ, 2012, OPT LASER TECHNOL, V44, P2238, DOI 10.1016/j.optlastec.2012.02.032
   Hussain I, 2016, J VIB CONTROL, V22, P1143, DOI 10.1177/1077546314536919
   Hwang HE, 2011, OPT COMMUN, V284, P3243, DOI 10.1016/j.optcom.2011.03.030
   Joshi M, 2007, OPT COMMUN, V279, P35, DOI 10.1016/j.optcom.2007.07.012
   Kang XJ, 2017, IEEE IMAGE PROC, P4362, DOI 10.1109/ICIP.2017.8297106
   Kumar M, 2014, OPT LASER ENG, V52, P27, DOI 10.1016/j.optlaseng.2013.07.015
   Lang J, 2012, OPT COMMUN, V285, P2584, DOI 10.1016/j.optcom.2012.01.085
   Liu ZJ, 2011, OPT LASER ENG, V49, P542, DOI 10.1016/j.optlaseng.2010.12.005
   Liu ZJ, 2011, OPT COMMUN, V284, P123, DOI 10.1016/j.optcom.2010.09.013
   Liu ZJ, 2010, OPT LASER ENG, V48, P800, DOI 10.1016/j.optlaseng.2010.02.005
   Mehra I, 2015, OPT COMMUN, V335, P153, DOI 10.1016/j.optcom.2014.09.040
   Mishra DC, 2016, INF SECUR J, V25, P213, DOI 10.1080/19393555.2016.1241323
   Nishchal NK, 2004, OPT COMMUN, V235, P253, DOI 10.1016/j.optcom.2004.02.052
   Pei SC, 1998, IEEE T CIRCUITS-II, V45, P665, DOI 10.1109/82.686685
   Pei SC, 2006, IEEE SIGNAL PROC LET, V13, P329, DOI 10.1109/LSP.2006.871721
   Prasad A, 2012, OPT COMMUN, V285, P1005, DOI 10.1016/j.optcom.2011.10.019
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Singh P, 2017, OPT APPL, V47, P421, DOI 10.5277/oa170308
   Singh P, 2017, AIP CONF PROC, V1802, DOI 10.1063/1.4973267
   Situ GH, 2004, OPT LETT, V29, P1584, DOI 10.1364/OL.29.001584
   Soleymani A., 2014, THESCIENTIFICWORLDJO, P2014
   Tao R, 2010, IEEE T INF FOREN SEC, V5, P734, DOI 10.1109/TIFS.2010.2068289
   Tao R, 2009, OPT COMMUN, V282, P1531, DOI 10.1016/j.optcom.2008.12.070
   Vashisth S, 2014, OPTIK, V125, P5309, DOI 10.1016/j.ijleo.2014.06.068
   Venturini I, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P205
   Wu JH, 2010, OPT COMMUN, V283, P1720, DOI 10.1016/j.optcom.2009.12.066
   Wu XJ, 2016, INFORM SCIENCES, V349, P137, DOI 10.1016/j.ins.2016.02.041
   Yadav PL, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0172-0
   Zhang YS, 2013, OPT LASER ENG, V51, P472, DOI 10.1016/j.optlaseng.2012.11.001
   Zhao DM, 2008, OPT COMMUN, V281, P5326, DOI 10.1016/j.optcom.2008.07.049
   Zhou NR, 2011, OPT COMMUN, V284, P5588, DOI 10.1016/j.optcom.2011.08.034
   Zhou NR, 2011, OPT COMMUN, V284, P3234, DOI 10.1016/j.optcom.2011.02.065
   Zhu HG, 2014, OPTIK, V125, P6672, DOI 10.1016/j.ijleo.2014.06.149
   Zhu Z, 2020, IEEE PHOTONICS J, V12, DOI 10.1109/JPHOT.2020.2981494
NR 46
TC 11
Z9 11
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27829
EP 27853
DI 10.1007/s11042-021-11003-x
EA MAY 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000654112900003
DA 2024-07-18
ER

PT J
AU Jan, F
   Alrashed, S
   Min-Allah, N
AF Jan, Farmanullah
   Alrashed, Saleh
   Min-Allah, Nasro
TI Iris segmentation for non-ideal Iris biometric systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iris biometrics; Iris-at-a-distance; Iris segmentation; Iris
   localization; Smart cities; Smart homes; Cloud computing
ID LOCALIZATION; RECOGNITION; IMAGES; FRAMEWORK; ALGORITHM; SELECTION;
   FUSION
AB At present, iris recognition systems are highly demanded for covert applications such as monitoring terrorist activities at public places, walk-through portals, smart cities, etc. In general, these systems use image acquisition setups working under relaxed conditions due to which the quality of acquired images is usually poor. For example, images may contain non-uniform illumination, defocus, blur, reflections and eyelids/eyelashes occlusion. Due to these issues, most contemporary iris segmentation schemes do not perform well. In addition, precise localization of eyes in human face images is also a challenging task. No doubt, wrong localization of eyes may certainly lead to failure of the subsequent system modules. To contribute in this regard, this study offers a robust scheme that functions as follows. First, it supplements the Viola-Jones algorithm with the geometrical information of human face to segment eyes. Next, it preprocesses an eyeimage to enhance its contrast, suppress reflections, smooth down spiky gray-level variations if any and marks a circular region-of-interest (ROI) containing iris. Then, it applies an iterative scheme involving Hough transform to segment iris. Finally, it extracts non-circular iris contours using an effective scheme centered on the Lagrange interpolating polynomial. This scheme has shown improved performance on public face-dataset (CASIA-IrisV4-Distance) and two iris datasets, MMU V1.0 and IITD V1.0. On average, it attained 97.97% accuracy rate on these databases.
C1 [Jan, Farmanullah; Min-Allah, Nasro] Imam Abdulrahman Bin Faisal Univ, Coll Comp Sci & Informat Technol, Dept Comp Sci, POB 1982, Dammam, Saudi Arabia.
   [Alrashed, Saleh] Imam Abdulrahman Bin Faisal Univ, Coll Appl Studies & Community Serv, Management Informat Syst Dept, POB 1982, Dammam, Saudi Arabia.
C3 Imam Abdulrahman Bin Faisal University; Imam Abdulrahman Bin Faisal
   University
RP Jan, F (corresponding author), Imam Abdulrahman Bin Faisal Univ, Coll Comp Sci & Informat Technol, Dept Comp Sci, POB 1982, Dammam, Saudi Arabia.
EM fzmjan@iau.edu.sa; salrashed@iau.edu.sa; nabdullatief@iau.edu.sa
RI Min-Allah, Nasro/O-3147-2019
OI Jan, Farmanullah/0000-0002-9118-3652; min-allah,
   nasro/0000-0002-3435-8823
FU Deanship of Scientific Research (DSR), Imam Abdulrahman Bin Faisal
   University (IAU) [2019-359-CSIT]
FX The Deanship of Scientific Research (DSR), Imam Abdulrahman Bin Faisal
   University (IAU) has funded this study under project numbered
   2019-359-CSIT.
CR Ahad MAR, 2018, APPL SOFT COMPUT
   [Anonymous], CASIA Iris Database Version 2
   [Anonymous], 2019, IITD IRIS DATABASES
   [Anonymous], BIOMETRIC SMARTCITY
   Arshad H, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12541
   Arshad H, 2019, INT J MACH LEARN CYB, V10, P3601, DOI 10.1007/s13042-019-00947-0
   Arum Sari Y, 2017, INT J ELECT COMPUTER
   Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240
   Boonchuan T., 2018, ELECT LETT COMPUTER, V17, P16, DOI DOI 10.5565/REV/ELCVIA.1044
   Bowyer K, 2012, HDB IRIS RECOGNITION
   Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   CASIA_database, CASIA DATABASE
   Cho DH, 2006, SNPD 2006: SEVENTH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING ARTIFICIAL INTELLIGENCE, NETWORKING, AND PARALLEL/DISTRIBUTED COMPUTING, PROCEEDINGS, P197
   Dantcheva Antitza., 2011, IEEE Workshop on Applications of Computer Vision, P227, DOI [DOI 10.1109/WACV.2011.5711507, 10.1109/WACV.2011.5711507]
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540
   el Kaddouhi S., 2018, INT J CONTROL AUTOM, V11, P59, DOI [10.14257/ijca.2018.11.5.06, DOI 10.14257/IJCA.2018.11.5.06]
   Fan D-P, 2020, UC NET UNCERTAINTY I
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fu KR, 2020, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR42600.2020.00312
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Fuentes-Hurtado F, 2019, EURASIP J IMAGE VIDE, V2019, DOI 10.1186/s13640-019-0473-0
   Goel, 2018, NATURE INSPIRED COMP, V652
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Jan F., 2014, THESIS COMSATS U ISL
   Jan F, 2013, CHIN OPT LETT, V11, DOI 10.3788/COL201311.081501
   Jan F, 2013, SIGNAL PROCESS, V93, P230, DOI 10.1016/j.sigpro.2012.07.033
   Jan F, 2012, DIGIT SIGNAL PROCESS, V22, P971, DOI 10.1016/j.dsp.2012.06.001
   Jeong DS, 2010, IMAGE VISION COMPUT, V28, P254, DOI 10.1016/j.imavis.2009.04.001
   Kang JS, 2010, PROCEDIA COMPUT SCI, V1, P475, DOI 10.1016/j.procs.2010.04.051
   Khan TM, 2011, OPT LASER ENG, V49, P177, DOI 10.1016/j.optlaseng.2010.08.020
   Lagrange_Interpolating_Polynomial, LAGR INT POL
   Leo M, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.3.033033
   Li YK, 2021, IEEE T SYST MAN CY-S, V51, P6040, DOI [10.1109/TSMC.2019.2958861, 10.1109/TCDS.2020.2999337]
   Li YG, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3378026
   Li YH, 2019, MOB INF SYST, V2019, DOI 10.1155/2019/6142839
   Ma, 2012, PATTERN RECOGN
   Ma L, 2020, DIGIT SIGNAL PROCESS, V100, DOI 10.1016/j.dsp.2020.102682
   Mehmood A, 2024, MULTIMED TOOLS APPL, V83, P14979, DOI 10.1007/s11042-020-08928-0
   Min-Allah N, 2021, J SUPERCOMPUT, V77, P2069, DOI 10.1007/s11227-020-03334-7
   Min-Allah N, 2020, SUSTAIN CITIES SOC, V59, DOI 10.1016/j.scs.2020.102231
   Min-Allah N, 2019, SUSTAIN CITIES SOC, V48, DOI 10.1016/j.scs.2019.101523
   Nguyen K, 2017, PATTERN RECOGN, V72, P123, DOI 10.1016/j.patcog.2017.05.021
   Ogla R., 2017, IRAQ J SCI, V58, P735
   Orman Z., 2011, INT J COMPUT SCI ENG, V2, P29, DOI [10.5121/ijcses.2011.2303, DOI 10.5121/IJCSES.2011.2303]
   Prabhakar, 2018, J ADV RES DYNAMICAL, V10, P1837
   Pundlik S, 2010, IMAGE VISION COMPUT, V28, P1671, DOI 10.1016/j.imavis.2010.05.004
   Salah Albert Ali, 2009, 2009 IEEE 17th Signal Processing and Communications Applications Conference (SIU), P712, DOI 10.1109/SIU.2009.5136495
   Sardar M, 2018, APPL SOFT COMPUT, V67, P61, DOI 10.1016/j.asoc.2018.02.047
   Sharif M, 2020, J ORGAN END USER COM, V32, P67, DOI 10.4018/JOEUC.2020040104
   Soliman NF, 2017, OPTIK, V140, P469, DOI 10.1016/j.ijleo.2016.11.150
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Vyas R., 2018, ADV INTELLIGENT SYST, P99, DOI [10.1007/978-981-10-6747-1_12, DOI 10.1007/978-981-10-6747-1_12]
   Wang Q, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/7952152
   Wang TT, 2019, IEEE I CONF COMP VIS, P8837, DOI 10.1109/ICCV.2019.00893
   Wang YQ, 2014, IMAGE PROCESS ON LIN, V4, P128, DOI 10.5201/ipol.2014.104
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Yadav KS, 2020, MULTIMED TOOLS APPL, V79, P13089, DOI 10.1007/s11042-019-08443-x
   Yingyu Ji, 2018, Journal of Electronic Imaging, V27, DOI 10.1117/1.JEI.27.5.051205
   You Li, 2018, International Journal of Aerospace Engineering, V2018, DOI 10.1155/2018/8302324
   Zhang L, 2019, PROC CVPR IEEE, P6017, DOI 10.1109/CVPR.2019.00618
NR 61
TC 9
Z9 9
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 15223
EP 15251
DI 10.1007/s11042-021-11075-9
EA MAY 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000653635800002
DA 2024-07-18
ER

PT J
AU Singh, BK
   Kumar, R
   Kishore, RR
AF Singh, Brajesh Kumar
   Kumar, Ravinder
   Kishore, R. Rama
TI A Biometric System Design using Finger Knuckle Biological Trait
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Finger knuckle biological trait; Feature detector; Feature descriptor;
   Robust feature; Zero-score imposter probability; Zero-score genuine
   probability; Biometric system
ID PRINT; RECOGNITION; SURF; DESCRIPTOR; INVARIANT; STEREO; BRISK; SIFT
AB Various biometric traits are available but recently finger knuckle image has attracted great attention to biometric research community due to its potentiality and ease of use. The performance of any biometric system heavily depends on the accuracy of feature detection and robustness of feature description. A number of feature descriptors are available but selection is being determined by the type of application such as image retrieval, biometric system, remote sensing etc. This paper proposed a biometric system using leading descriptor for finger knuckle biological trait image recognition and also compare the proposed system with existing leading state-of-art finger knuckle print recognition. The recognition performance is measured by some standard evaluation protocol such as Equal Error Rate (EER), Decidability index, Computation cost, Zero-score imposter probability, Zero-score genuine probability, Receiver Operating Characteristic (ROC), Detection Error Trade-off (DET) over PolyU Finger Knuckle benchmark database. The experimental results show that, the performance of SURF, KAZE and ORB are comparable and are better as compared to BRISK and MSER descriptor. The ERR of 0.0010% is obtained with ORB descriptor while the Decidability index of 6.4645 is obtained for KAZE. The minimum Computational cost of 0.1442 s is obtained for SURF as compares to other of its class.
C1 [Singh, Brajesh Kumar; Kishore, R. Rama] GGSIP Univ, USICT, Delhi, India.
   [Kumar, Ravinder] Shri Vishwakarma Skill Univ, Gurgaon, India.
C3 GGS Indraprastha University
RP Kumar, R (corresponding author), Shri Vishwakarma Skill Univ, Gurgaon, India.
EM brajeshsingh.dce@gmail.com; ravinder_y@yahoo.com; ram_kish@yahoo.com
RI Singh, Dr Brajesh Kumar/HRB-4433-2023
OI Singh, Dr Brajesh Kumar/0000-0001-8709-3219; KUMAR,
   RAVINDER/0000-0003-2117-5734
CR Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   Aoyama S, 2014, INFORM SCIENCES, V268, P53, DOI 10.1016/j.ins.2013.08.025
   Badrinath GS, 2011, LECT NOTES COMPUT SC, V7043, P374, DOI 10.1007/978-3-642-25243-3_30
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222
   Cheng K., 2012, Proceedings of the International Conference of the Biometrics Special Interest Group (BIOSIG), P1
   Darini M., 2015, INT J INNOVATIVE RES, V4, P21
   El-Alfy EM, 2014, COGN COMPUT, V6, P321, DOI 10.1007/s12559-013-9241-0
   El-Tarhouni W, 2014, INT C MICROELECTRON, P184, DOI 10.1109/ICM.2014.7071837
   Fàbregas J, 2009, COGN COMPUT, V1, P257, DOI 10.1007/s12559-009-9018-7
   Faundez-Zanuy M, 2014, COGN COMPUT, V6, P230, DOI 10.1007/s12559-013-9230-3
   Figat J, 2014, LECT NOTES COMPUT SC, V8671, P187, DOI 10.1007/978-3-319-11331-9_23
   Hu HF, 2016, COGN COMPUT, V8, P900, DOI 10.1007/s12559-016-9403-y
   Jain A.K., 1999, Proceedings of Second International Conference on Audio and Video-Based Biometric Person Authentication (AVBPA), P166
   Jain A. K., 2010, Second Gener Biom, V12, P2
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jaswal G, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON IDENTITY, SECURITY AND BEHAVIOR ANALYSIS (ISBA)
   Jeon HK, 2015, INT SOC DESIGN CONF, P91, DOI 10.1109/ISOCC.2015.7401661
   Jiang YL, 2013, NEUROCOMPUTING, V120, P380, DOI 10.1016/j.neucom.2012.06.055
   Kashif M, 2016, COMPUT BIOL MED, V68, P67, DOI 10.1016/j.compbiomed.2015.11.006
   Krajník T, 2017, ROBOT AUTON SYST, V88, P127, DOI 10.1016/j.robot.2016.11.011
   Kumar A., 2009, P INT C BIOM THEOR A, P1
   Kumar A, 2009, IEEE T IMAGE PROCESS, V18, P2127, DOI 10.1109/TIP.2009.2023153
   Kumar R, 2018, HDB RES NETWORK FORE, P416
   Kumar R, 2017, STUD COMPUT INTELL, V660, P201, DOI 10.1007/978-3-319-44790-2_10
   Kumar R, 2016, J INF PROCESS SYST, V12, P83, DOI 10.3745/JIPS.02.0020
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mi JX, 2016, COGN COMPUT, V8, P818, DOI 10.1007/s12559-016-9420-x
   Morales A, 2011, ELECTRON LETT, V47, P380, DOI 10.1049/el.2011.0156
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Nigam A, 2016, NEUROCOMPUTING, V188, P190, DOI 10.1016/j.neucom.2015.04.126
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Peng, 2019, ARXIV PREPRINT ARXIV
   Peng JL, 2013, IEICE T INF SYST, VE96D, P1886, DOI 10.1587/transinf.E96.D.1886
   Perumal E., 2015, INT ARAB J INFORM TE, V12
   Rani R, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1517, DOI 10.1109/ICACCI.2016.7732263
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Rusiñol M, 2015, PROC INT CONF DOC, P596, DOI 10.1109/ICDAR.2015.7333831
   Sanderson S., 2000, Authentication for secure environments based on iris scanning technology
   SivacBryant S, 2016, PALGR STUD COMPROM, P1, DOI 10.1057/978-1-137-58838-8
   Tiwari RK, 2015, PROCEDIA COMPUT SCI, V54, P703, DOI 10.1016/j.procs.2015.06.083
   Vinay A, 2015, PROCEDIA COMPUT SCI, V70, P174, DOI 10.1016/j.procs.2015.10.068
   Wang Y, 2007, IEEE T PATTERN ANAL, V29, P573, DOI 10.1109/TPAMI.2007.1003
   Wang Y, 2011, IEEE T PATTERN ANAL, V33, P72, DOI 10.1109/TPAMI.2010.73
   Xie SJ, 2014, COGN COMPUT, V6, P446, DOI 10.1007/s12559-014-9254-3
   Xu XM, 2015, SENSORS-BASEL, V15, P4326, DOI 10.3390/s150204326
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang L, 2011, PATTERN RECOGN, V44, P1990, DOI 10.1016/j.patcog.2010.06.007
   Zhang L, 2009, IEEE IMAGE PROC, P1981, DOI 10.1109/ICIP.2009.5413734
   Zhang L, 2010, PATTERN RECOGN, V43, P2560, DOI 10.1016/j.patcog.2010.01.020
   Zheng P, 2010, COGN COMPUT, V2, P303, DOI 10.1007/s12559-010-9054-3
NR 53
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 36835
EP 36852
DI 10.1007/s11042-021-10987-w
EA MAY 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000648016200001
DA 2024-07-18
ER

PT J
AU Pati, R
   Pujari, AK
   Gahan, P
AF Pati, Rasmikanta
   Pujari, Arun K.
   Gahan, Padmavati
TI Face recognition using particle swarm optimization based block ICA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Block independent component analysis; Subspace methods; Swarm
   optimization; Face recognition
ID DECONVOLUTION; EIGENFACES
AB Face recognition is one of the most important and widely applicable research problems in the subject area of machine learning and computer vision. Extraction of features, local or holistic, is the fundamental step and subspace method has been a natural choice for facial feature extraction. Among these, methods like PCA, ICA, LDA aim to reduce the dimension of the data while retaining the statistical separation property between distinct classes. Unlike the traditional ICA, in which the whole face image is stretched into a vector before calculating the independent components (ICs), Block ICA (B-ICA) partitions the facial images into blocks and takes the block as the training vector. Since the dimensionality of the training vector in B-ICA is much smaller than that in traditional ICA, reduction in face recognition error is expected. The objective of ICA is to find a separation matrix and it is achieved by a process of optimization, such as maximization of non-Gaussianity, maximum likelihood estimation, and minimization of mutual information. We observe here that the gradient-based learning can be efficiently and effectively achieved by the application of swarm-based optimization. We propose here the application of our Gradient-based Swarm Optimization method for Block ICA, where gradient information is combined with conventional swarm search to optimize the contrast function. We compare our method with B-ICA on three benchmark image data sets and show that our method achieved a better recognition rate compared to B-ICA in different block sizes with 70%, 80% and 90% data used for training the model.
C1 [Pati, Rasmikanta] Sambalpur Univ, SUIIT, Burla, India.
   [Pujari, Arun K.] Cent Univ Rajasthan, Ajmer, India.
   [Gahan, Padmavati] Sambalpur Univ, Dept Business Adm, Burla, India.
C3 Sambalpur University; Central University of Rajasthan (CURAJ); Sambalpur
   University
RP Pati, R (corresponding author), Sambalpur Univ, SUIIT, Burla, India.
EM rkpati@suiit.ac.in
RI PUJARI, ARUN K/ABG-9196-2021
OI Pati, Rasmikanta/0000-0002-5592-3182
CR Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Castella M, 2012, IEEE T SIGNAL PROCES, V60, P1319, DOI 10.1109/TSP.2011.2177828
   Castella M, 2010, INT CONF ACOUST SPEE, P2670, DOI 10.1109/ICASSP.2010.5496250
   Choi H, 2019, PROC VLDB ENDOW, V12, P1842, DOI 10.14778/3352063.3352080
   Chu YJ, 2019, VISUAL COMPUT, V35, P239, DOI 10.1007/s00371-017-1468-4
   De-la-Torre M, 2015, INFORM FUSION, V24, P31, DOI 10.1016/j.inffus.2014.05.006
   DeVault D, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1061
   Kawamoto M, 2007, IEEE SIGNAL PROC LET, V14, P996, DOI 10.1109/LSP.2007.906225
   Kumar PM, 2019, CLUSTER COMPUT, V22, pS7733, DOI 10.1007/s10586-017-1323-4
   Bao LN, 2016, ADV INTELL SYST, V435, P287, DOI 10.1007/978-81-322-2757-1_29
   Li Q., 2005, ADV NEURAL INFORM PR, P1569, DOI DOI 10.5555/2976040.2976237
   Liu CJ, 2004, IEEE T SYST MAN CY B, V34, P1117, DOI 10.1109/TSMCB.2003.821449
   Mehta BB, 2014, ARXIV 14030485
   Pati Rasmikanta, 2019, Progress in Advanced Computing and Intelligent Engineering. Proceedings of ICACIE 2017. Advances in Intelligent Systems and Computing (AISC 713), P225, DOI 10.1007/978-981-13-1708-8_21
   Simon C, 1999, INT CONF ACOUST SPEE, P1429
   Tugnait JK, 1997, IEEE T SIGNAL PROCES, V45, P658, DOI 10.1109/78.558482
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Yang J, 2005, PATTERN RECOGN, V38, P1125, DOI 10.1016/j.patcog.2004.11.019
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Zhang L, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P217, DOI 10.1109/ICIAP.2007.4362782
   Zhang Y, 2010, IEEE T SYST MAN CY A, V40, P475, DOI 10.1109/TSMCA.2010.2041654
NR 22
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35685
EP 35695
DI 10.1007/s11042-021-10792-5
EA APR 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000645187700001
DA 2024-07-18
ER

PT J
AU Dehkordy, DT
   Rasoolzadegan, A
AF Dehkordy, Diyana Tehrany
   Rasoolzadegan, Abbas
TI A new machine learning-based method for android malware detection on
   imbalanced dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Malware detection; Android applications classification; Dataset
   balancing; SMOTE balancing
ID CLASSIFICATION; CHALLENGES; SMOTE
AB Nowadays, malware applications are dangerous threats to Android devices, users, developers, and application stores. Researchers are trying to discover new methods for malware detection because the complexity of malwares, their continuous changes, and damages caused by their attacks have increased. One of the most important challenges in detecting malware is to have a balanced dataset. In this paper, a detection method is proposed to identify malware to improve accuracy and reduce error rates by preprocessing the used dataset and balancing it. To attain these purposes, the static analysis is used to extract features of the applications. The ranking methods of features are used to preprocess the feature set and the low-effective features are removed. The proposed method also balances the dataset by using the techniques of undersampling, the Synthetic Minority Oversampling Technique (SMOTE), and a combination of both methods, which have not yet been studied among detection methods. Then, the classifiers of K-Nearest Neighbor (KNN), Support Vector Machine, and Iterative Dichotomiser 3 are used to create the detection model. The performance of KNN with SMOTE is better than the performance of the other classifiers. The obtained results indicate that the criteria of precision, recall, accuracy, F-measure, and Matthews Correlation Coefficient are over 97%. The proposed method is effective in detecting 99.49% of the malware's existing in the used dataset and new malware.
C1 [Dehkordy, Diyana Tehrany; Rasoolzadegan, Abbas] Ferdowsi Univ Mashhad, Fac Engn, Dept Comp Engn, Mashhad, Razavi Khorasan, Iran.
C3 Ferdowsi University Mashhad
RP Rasoolzadegan, A (corresponding author), Ferdowsi Univ Mashhad, Fac Engn, Dept Comp Engn, Mashhad, Razavi Khorasan, Iran.
EM d.tehrany@mail.um.ac.ir; rasoolzadegan@um.ac.ir
RI Rasoolzadegan, Abbas/A-1729-2017
OI Rasoolzadegan, Abbas/0000-0001-8668-5650
CR Aafer Y, 2013, L N INST COMP SCI SO, V127, P86
   Abu Samra AA, 2019, 2019 IEEE 7TH PALESTINIAN INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (PICECE), DOI 10.1109/picece.2019.8747224
   Agrawal Prerna., 2019, 2019 IEEE INT C ELEC, P1, DOI DOI 10.1109/ICECCT.2019.8868951
   Ahmadi M, 2016, CODASPY'16: PROCEEDINGS OF THE SIXTH ACM CONFERENCE ON DATA AND APPLICATION SECURITY AND PRIVACY, P183, DOI 10.1145/2857705.2857713
   Alam S, 2017, COMPUT SECUR, V65, P230, DOI 10.1016/j.cose.2016.11.011
   [Anonymous], 2019, IRANAPPS APPS STORE
   [Anonymous], 2019, HUAWEI APPS STORE CH
   [Anonymous], 2018, IT THREAT EVOLUTION
   [Anonymous], 2013, Inter- national Journal of Scientific and Technology Research
   [Anonymous], 2019, APKPURE APPS STORE B
   Arp D, 2014, 21ST ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2014), DOI 10.14722/ndss.2014.23247
   Backes M, 2017, 2017 IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY (EUROS&P), P204, DOI 10.1109/EuroSP.2017.24
   Bekkar M., 2013, J Inf Eng Appl, V3, P15, DOI DOI 10.5121/IJDKP.2013.3402
   Canfora Gerardo, 2015, 2015 Mobile Systems Technologies Workshop (MST). Architecture, Technology Trends and Memory Solutions. Proceedings, P21, DOI 10.1109/MST.2015.8
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Dong SK, 2018, L N INST COMP SCI SO, V254, P172, DOI 10.1007/978-3-030-01701-9_10
   Fengguo Wei, 2017, Detection of Intrusions and Malware, and Vulnerability Assessment. 14th International Conference, DIMVA 2017. Proceedings: LNCS 10327, P252, DOI 10.1007/978-3-319-60876-1_12
   Fernandez A., 2018, LEARNING IMBALANCED
   Fernández A, 2018, J ARTIF INTELL RES, V61, P863, DOI 10.1613/jair.1.11192
   Garcia J, 2018, ACM T SOFTW ENG METH, V26, DOI 10.1145/3162625
   Grace M., 2012, P 10 INT C MOB SYST, P281
   Halimu C, 2019, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND SOFT COMPUTING (ICMLSC 2019), P1, DOI 10.1145/3310986.3311023
   Hung SH, 2016, 2016 INTERNATIONAL COMPUTER SYMPOSIUM (ICS), P537, DOI [10.1109/ICS.2016.0112, 10.1109/ICS.2016.111]
   Krawczyk B, 2016, PROG ARTIF INTELL, V5, P221, DOI 10.1007/s13748-016-0094-0
   Kuncheva LI, 2019, PROG ARTIF INTELL, V8, P215, DOI 10.1007/s13748-019-00172-4
   Leevy JL, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-018-0151-6
   LEI T, 2019, IEEE INTERNET THINGS
   Li J, 2018, IEEE T IND INFORM, V14, P3216, DOI 10.1109/TII.2017.2789219
   Ling CX, 2006, IEEE T KNOWL DATA EN, V18, P1055, DOI 10.1109/TKDE.2006.131
   Liu J, 2019, APPL SOFT COMPUT, V75, P702, DOI 10.1016/j.asoc.2018.11.045
   Lopez-Garcia P, 2019, APPL INTELL, V49, P2807, DOI 10.1007/s10489-019-01423-6
   Lou SH, 2019, 2019 IEEE 2ND INTERNATIONAL CONFERENCE ON INFORMATION AND COMPUTER TECHNOLOGIES (ICICT), P30, DOI [10.1109/infoct.2019.8711179, 10.1109/INFOCT.2019.8711179]
   Martín A, 2019, INFORM FUSION, V52, P128, DOI 10.1016/j.inffus.2018.12.006
   Martinelli F, 2018, J PARALLEL DISTR COM, V119, P203, DOI 10.1016/j.jpdc.2018.04.008
   McGiff J, 2019, INT CONF COMPUT NETW, P432, DOI [10.1109/ICCNC.2019.8685502, 10.1109/iccnc.2019.8685502]
   Odusami M., 2018, INT C APPL INF, P255, DOI DOI 10.1007/978-3-030-01535-0_19
   Pektas A, 2020, NEUROCOMPUTING, V396, P599, DOI 10.1016/j.neucom.2018.09.102
   Quan DY, 2014, IEEE INT CONF TRUST, P877, DOI 10.1109/TrustCom.2014.115
   Rout N, 2018, ADV INTELL SYST, V628, P431, DOI 10.1007/978-981-10-5272-9_39
   Saracino A, 2018, IEEE T DEPEND SECURE, V15, P83, DOI 10.1109/TDSC.2016.2536605
   Shrivastava G, 2019, MULTIMED TOOLS APPL, V78, P35713, DOI 10.1007/s11042-019-07899-1
   Siddiqui M., 2008, P 46 ANN SE REG C 20, P509
   Suarez-Tangil G, 2017, PROCEEDINGS OF THE SEVENTH ACM CONFERENCE ON DATA AND APPLICATION SECURITY AND PRIVACY (CODASPY'17), P309, DOI 10.1145/3029806.3029825
   Tavallaee M, 2010, IEEE T SYST MAN CY C, V40, P516, DOI 10.1109/TSMCC.2010.2048428
   Ucci D., 2018, Computers Security
   Wang S, 2009, 2009 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING, P324, DOI 10.1109/CIDM.2009.4938667
   Yan P, 2018, SOFTWARE QUAL J, V26, P891, DOI 10.1007/s11219-017-9368-4
   Yang Q, 2006, INT J INF TECH DECIS, V5, P597, DOI 10.1142/S0219622006002258
   Yang W, 2015, 2015 IEEE/ACM 37TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, VOL 1, P303, DOI 10.1109/ICSE.2015.50
   Yerima SY, 2019, IEEE T CYBERNETICS, V49, P453, DOI 10.1109/TCYB.2017.2777960
   Yuan ZL, 2016, TSINGHUA SCI TECHNOL, V21, P114
   Zhao, 2019, COST SENSITIVE META, DOI 10.1016/j.future.2019.05.080
   Zhou QG, 2019, MULTIMED TOOLS APPL, V78, P3529, DOI 10.1007/s11042-018-6498-z
NR 53
TC 13
Z9 13
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24533
EP 24554
DI 10.1007/s11042-021-10647-z
EA APR 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000637475800001
DA 2024-07-18
ER

PT J
AU Acharya, UK
   Kumar, S
AF Acharya, Upendra Kumar
   Kumar, Sandeep
TI Directed searching optimized mean-exposure based sub-image histogram
   equalization for grayscale image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enhancement; Histogram equalization; Directed searching
   optimization; Histogram sub-division
AB This paper presents a novel enhancement technique for low light grayscale images. The main goal of this work is to enhance the visual quality and improve the information contents (entropy) of the images using a novel Directed Searching Optimized mean-exposure based sub-image histogram equalization technique. Initially, the proposed method clips the original histogram to prevent over enhancement. The clipped histogram is divided into two sub-histograms, based on mean intensity value. A further division of the lower sub-histogram is carried out, based on an exposure threshold to avoid unnatural artifacts. Then, each sub-histogram is equalized independently followed by a modified transfer function. Two optimal constraint parameters are used in this paper, to reduce the information loss during histogram equalization. The Directed Searching Optimization algorithm is employed in this paper for automatic selection of the constraint parameters in order to maximize the fitness function. It makes the proposed technique more adaptive. Finally, the proposed method is compared with other existing histogram equalization based image enhancement techniques. Simulation results show that, the proposed method is able to maximize the information contents effectively and preserves the natural appearance of the image. It also results better visual quality image with improved PSNR, SSIM, FSIM and reduced MSE as compared to other state-of-the-art methods.
C1 [Acharya, Upendra Kumar] Galgotias Coll Engn & Technol, Dept Elect & Commun Engn, Greater Noida, Uttar Pradesh, India.
   [Acharya, Upendra Kumar; Kumar, Sandeep] Natl Inst Technol, Dept Elect & Commun Engn, Delhi, India.
C3 Galgotias College of Engineering & Technology (GCET); National Institute
   of Technology (NIT System); National Institute of Technology Delhi
RP Kumar, S (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Delhi, India.
EM sandeep@nitdelhi.ac.in
RI Kumar, Sandeep/V-7151-2019
OI Kumar, Sandeep/0000-0001-9922-2663; Acharya, Dr. Upendra
   Kumar/0000-0001-6271-2896
CR Abdoli M, 2019, IET IMAGE PROCESS, V13, P833, DOI 10.1049/iet-ipr.2018.5520
   Al-Ameen Z, 2019, IET IMAGE PROCESS, V13, P1314, DOI 10.1049/iet-ipr.2018.6585
   [Anonymous], 2016, USC SIPI IMAGE DATAB
   Bae TW, 2017, ETRI J, V39, P76, DOI 10.4218/etrij.17.0115.0880
   Bhandari AK, 2020, SOFT COMPUT, V24, P1619, DOI 10.1007/s00500-019-03992-7
   Chen J, 2018, SWARM EVOL COMPUT, V38, P287, DOI 10.1016/j.swevo.2017.09.002
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Chen SD, 2012, DIGIT SIGNAL PROCESS, V22, P640, DOI 10.1016/j.dsp.2012.04.002
   Deng H, 2016, IET IMAGE PROCESS, V10, P701, DOI 10.1049/iet-ipr.2016.0035
   Dhal KG, 2021, ARCH COMPUT METHOD E, V28, P1471, DOI 10.1007/s11831-020-09425-1
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hanmandlu M, 2009, IEEE T INSTRUM MEAS, V58, P2867, DOI 10.1109/TIM.2009.2016371
   Isa IS, 2017, BIOCYBERN BIOMED ENG, V37, P24, DOI 10.1016/j.bbe.2016.12.003
   Kandhway P, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101677
   Kanmani M, 2018, MULTIMED TOOLS APPL, V77, P23371, DOI 10.1007/s11042-018-5650-0
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Kumar RP., 2017, WORLD J MODEL SIMUL, V13, P66
   Mandal S., 2019, Statistical Approaches for Landslide Susceptibility Assessment and Prediction, P1, DOI [10.1007/978-3-319-93897-4_1, DOI 10.1007/978-3-319-93897-4_1]
   Meena AK, 2018, IEEE J-STARS, V1, P13
   Muniyappan S, 2019, MULTIMED TOOLS APPL, V78, P6487, DOI 10.1007/s11042-018-6355-0
   Peng F, 2017, AEU-INT J ELECTRON C, V71, P72, DOI 10.1016/j.aeue.2016.11.009
   Peng F, 2014, COMPUT AIDED DESIGN, V49, P42, DOI 10.1016/j.cad.2013.12.006
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P4364, DOI 10.1109/TIP.2019.2910412
   Shanmugavadivu P, 2014, VISUAL COMPUT, V30, P387, DOI 10.1007/s00371-013-0863-8
   Sharma U, 2013, INT J ENG RES TECHNO, V2
   Sim KS, 2007, PATTERN RECOGN LETT, V28, P1209, DOI 10.1016/j.patrec.2007.02.003
   Singh H, 2018, COMPUT ELECTR ENG, V70, P462, DOI 10.1016/j.compeleceng.2017.06.029
   Singh K, 2015, OPTIK, V126, P2619, DOI 10.1016/j.ijleo.2015.06.060
   Singh K, 2014, PATTERN RECOGN LETT, V36, P10, DOI 10.1016/j.patrec.2013.08.024
   Wan MJ, 2018, INFRARED PHYS TECHN, V91, P164, DOI 10.1016/j.infrared.2018.04.003
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Xu YJ, 2017, INFRARED PHYS TECHN, V87, P143, DOI 10.1016/j.infrared.2017.10.002
   Ying QC, 2019, IEEE ACCESS, V7, P46506, DOI 10.1109/ACCESS.2019.2909560
   Yuan LT, 2015, PATTERN RECOGN LETT, V54, P103, DOI 10.1016/j.patrec.2014.09.011
   Zarie M, 2019, IET IMAGE PROCESS, V13, P1081, DOI 10.1049/iet-ipr.2018.5395
   Zhang LB, 2018, J VIS COMMUN IMAGE R, V51, P56, DOI 10.1016/j.jvcir.2018.01.001
   Zhang LB, 2017, J VIS COMMUN IMAGE R, V48, P471, DOI 10.1016/j.jvcir.2016.12.013
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zou DX, 2011, EXPERT SYST APPL, V38, P8716, DOI 10.1016/j.eswa.2011.01.079
NR 40
TC 12
Z9 13
U1 4
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24005
EP 24025
DI 10.1007/s11042-021-10855-7
EA MAR 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000634660700001
DA 2024-07-18
ER

PT J
AU Fang, S
   Ma, YC
   Li, Z
   Zhang, B
AF Fang, Sheng
   Ma, Yichen
   Li, Zhe
   Zhang, Bin
TI A visual tracking algorithm via confidence-based multi-feature
   correlation filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Correlation filter; Short-term tracking; Confidence; Multi-feature
   fusion; Model rollback
ID OBJECT TRACKING; MODEL
AB Object tracking is an important issue in many practical computer vision applications, such as video surveillance, self-driving,and social scene understanding. Although the traditional correlation filter has been achieved the great performance in tracking accuracy and speed in a specific scenario, there are still some defects, such as weak robustness of trackers caused by using the single feature, boundary effects due to the circular shift and model corruption produced by the model update. To address the above problems, a visual tracking algorithm via confidence-based multi-feature correlation filtering is proposed in this paper. It adaptively selects histogram of oriented gradient (HOG) features or fusion features according to the confidence to improve the robustness and speed of target tracking. Firstly, a confidence level is proposed to evaluate the reliability of HOG feature based on the response map of the HOG feature. Secondly, a selective multi-feature fusion method is proposed to improve the robustness of the tracking algorithm. Thirdly, a novel model-updating mechanism, called model rollback mechanism, is proposed to reduce the impact of the model corruption. The algorithm is evaluated on the public datasets and compared with several state-of-the-art algorithms. Experimental results show that the proposed algorithm can effectively improve the performance in tracking accuracy of tracker in the above problems and is superior to the state-of-the-art tracking algorithms.
C1 [Fang, Sheng; Ma, Yichen; Li, Zhe; Zhang, Bin] Shandong Univ Sci & Technol, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology
RP Li, Z (corresponding author), Shandong Univ Sci & Technol, Qingdao 266590, Peoples R China.
EM lizhe@sdust.edu.cn
FU National Natural Science Foundation of China [61502278]; National Key
   R&D Program of China [2018YFC0831002]; Key R&D Program of Shandong
   Province [2018GGX101045]; Natural Science Foundation of Shandong
   Province [ZR2020MF132, ZR2018BF014]
FX This work is partially supported by the National Natural Science
   Foundation of China (No. 61502278), the National Key R&D Program of
   China (No. 2018YFC0831002), the Key R&D Program of Shandong Province
   (No. 2018GGX101045), the Natural Science Foundation of Shandong Province
   (No. ZR2020MF132,ZR2018BF014).
CR Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Chen K, 2019, IEEE T MULTIMEDIA, V21, P86, DOI 10.1109/TMM.2018.2846405
   [陈莹莹 Chen Yingying], 2019, [中国图象图形学报, Journal of Image and Graphics], V24, P291
   Dai KN, 2019, PROC CVPR IEEE, P4665, DOI 10.1109/CVPR.2019.00480
   Dai P, 2019, IEEE T MULTIMEDIA, V21, P1709, DOI 10.1109/TMM.2018.2885922
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Dong XP, 2017, IEEE T MULTIMEDIA, V19, P763, DOI 10.1109/TMM.2016.2631884
   Du B, 2018, IEEE GEOSCI REMOTE S, V15, P168, DOI 10.1109/LGRS.2017.2776899
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Galoogahi HK, 2015, PROC CVPR IEEE, P4630, DOI 10.1109/CVPR.2015.7299094
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Huang Y, 2019, MULTIMED TOOLS APPL, V78, P34725, DOI 10.1007/s11042-019-07901-w
   Huang Z., 2017, P IEEE C COMP VIS PA, P4021, DOI DOI 10.1109/CVPR.2017.510
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liang NX, 2018, IEEE T MULTIMEDIA, V20, P2289, DOI 10.1109/TMM.2018.2803518
   Liu FH, 2018, IEEE T IMAGE PROCESS, V27, P2777, DOI 10.1109/TIP.2018.2813161
   Ma C, 2017, IEEE T MULTIMEDIA, V19, P2415, DOI 10.1109/TMM.2017.2694219
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Possegger H, 2015, PROC CVPR IEEE, P2113, DOI 10.1109/CVPR.2015.7298823
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Wang, 2019, ROBUST VISUAL TRACKI, V78
   Wang J, 2018, SIGNAL PROCESS-IMAGE, V63, P44, DOI 10.1016/j.image.2018.01.005
   Wang N, 2019, IEEE T CIRC SYST VID, V29, P730, DOI 10.1109/TCSVT.2018.2816570
   Wang N, 2018, PROC CVPR IEEE, P4844, DOI 10.1109/CVPR.2018.00509
   Wang Q, 2018, PROC CVPR IEEE, P4854, DOI 10.1109/CVPR.2018.00510
   Wang QR, 2019, IEEE T MULTIMEDIA, V21, P930, DOI 10.1109/TMM.2018.2869277
   Wang Z, 2016, VISUAL COMPUT, V32, P307, DOI 10.1007/s00371-015-1067-1
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiao YF, 2018, IEEE IJCNN
   Yiming Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11920, DOI 10.1109/CVPR42600.2020.01194
   Yuan D, 2019, MULTIMED TOOLS APPL, V78, P27271, DOI 10.1007/s11042-019-07828-2
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao J, 2020, IEEE T FUZZY SYST, V28, P2287, DOI 10.1109/TFUZZ.2019.2930492
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhou H, 2019, IEEE T CIRC SYST VID, V29, P1011, DOI 10.1109/TCSVT.2018.2825679
   Zhou T, 2018, IEEE T CYBERNETICS, V48, P2643, DOI 10.1109/TCYB.2017.2747998
   Zhou T, 2017, IEEE T CIRC SYST VID, V27, P2153, DOI 10.1109/TCSVT.2016.2576941
   Zhou Y, 2019, IEEE T SIGNAL PROCES, V67, P3676, DOI 10.1109/TSP.2019.2917812
NR 50
TC 6
Z9 6
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 23963
EP 23982
DI 10.1007/s11042-021-10804-4
EA MAR 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000634660700004
DA 2024-07-18
ER

PT J
AU Luo, HW
   Zhang, HM
   Long, SG
   Lin, Y
AF Luo, Huiwen
   Zhang, Haoming
   Long, Shigong
   Lin, Yi
TI Enhancing frequent location privacy-preserving strategy based on
   geo-Indistinguishability
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Location privacy; Geo-Indistinguishability; Frequent location; Privacy
   protection
AB The increasing use of hand-held devices which have access to location information, has raised the risk of privacy disclosure. To implement privacy protection on the locations with plenty of check-ins, this thesis proposes a novel location perturbation method based on geo-indistinguishability, which has less quality loss and high privacy guarantee. In order to tackle the problem of how to preserve each person's frequently occurring position points, we reformulate this issue with a three-step framework. First, the location set is classified by the density-based clustering algorithm, and the privacy budget allocation function is used to allocate the corresponding budget for each cluster. Second, the real location is disturbed according to geo-indistinguishability, and the spanner structure is introduced to increase the efficiency of noise addition and the availability of location data. Finally, we present a privacy metric approach derived from the information entropy to quantify the information leakage by the mechanism, which provides the basis for the analysis of information loss. The experiments are carried out in two real datasets: GeoLife and Taxi GPS reports. Our evaluation confirms that the performance of the proposed strategy is superior to the state-of-the-art solutions in terms of quality loss and privacy metric.
C1 [Luo, Huiwen; Zhang, Haoming; Long, Shigong] Guizhou Univ, Guizhou Prov Key Lab Publ Big Data, Guiyang 550025, Peoples R China.
   [Luo, Huiwen; Zhang, Haoming; Long, Shigong] Guizhou Univ, Coll Comp Sci & Technol, Guiyang 550025, Peoples R China.
   [Lin, Yi] Informat Engn Univ, Coll Sci, Zhengzhou 450000, Peoples R China.
C3 Guizhou University; Guizhou University; PLA Information Engineering
   University
RP Long, SG (corresponding author), Guizhou Univ, Guizhou Prov Key Lab Publ Big Data, Guiyang 550025, Peoples R China.; Long, SG (corresponding author), Guizhou Univ, Coll Comp Sci & Technol, Guiyang 550025, Peoples R China.
EM 1136297177@qq.com; 657580249@qq.com; 526796467@qq.com; 948139238@qq.com
OI Long, Shigong/0000-0003-2674-4000
FU National Natural Science Foundation of China [62062020, 62002081,
   62002080]; Major Scientific and Technological Special Project of Guizhou
   Province [20183001]
FX This work is supported by the National Natural Science Foundation of
   China (NO.62062020)(NO.62002081)(NO.62002080), the Major Scientific and
   Technological Special Project of Guizhou Province (Grant NO.20183001),
   Great appreciation goes to the editorial board and the reviewers of this
   paper.
CR ALTHOFER I, 1993, DISCRETE COMPUT GEOM, V9, P81, DOI 10.1007/BF02189308
   Andrs Miguel E., 2013, P 2013 ACM SIGSAC C, P901, DOI DOI 10.1145/2508859.2516735
   [Anonymous], 2015, ACM Siglog News, DOI [DOI 10.1145/2815493.2815499, 10.1145/2815493.2815499]
   Beimel Amos, 2013, Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques. Algorithms and Techniques. 16th International Workshop, APPROX 2013 and 17th International Workshop, RANDOM 2013. Proceedings: LNCS 8096, P363, DOI 10.1007/978-3-642-40328-6_26
   Bordenabe NE, 2014, THESIS ECOLE POLYTEC
   Bordenabe NE, 2014, CCS'14: PROCEEDINGS OF THE 21ST ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P251, DOI 10.1145/2660267.2660345
   Chatzikokolakis K, 2015, LECT NOTES COMPUT SC, V8956, P49, DOI 10.1007/978-3-319-14977-6_4
   Chatzikokolakis K, 2014, LECT NOTES COMPUT SC, V8555, P21, DOI 10.1007/978-3-319-08506-7_2
   Chatzikokolakis Konstantinos, 2015, P PRIV ENH TECHN POP, V2, P156
   Cover, 2003, ELEMENTS INFORM THEO, P7
   Dewri R, 2013, IEEE T MOBILE COMPUT, V12, P2360, DOI 10.1109/TMC.2012.208
   Dwork C, 2006, LECT NOTES COMPUT SC, V4052, P1
   Dwork C, 2006, LECT NOTES COMPUT SC, V4004, P486
   Ho S.-S., 2011, Proceedings of the 4th ACM SIGSPATIAL International Workshop on Security and Privacy in GIS and LBS. SPRINGL'11, P17, DOI DOI 10.1145/2071880.2071884
   Hua JY, 2018, IEEE T INF FOREN SEC, V13, P1155, DOI 10.1109/TIFS.2017.2779402
   Kao, 2016, ENCY ALGORITHMS, DOI [10.1007/978-1-4939-2864-4_167, DOI 10.1007/978-1-4939-2864-4_167]
   Ngo H, 2015, 2015 IEEE 28TH COMPUTER SECURITY FOUNDATIONS SYMPOSIUM CSF 2015, P63, DOI 10.1109/CSF.2015.12
   Shokri R., 2012, Em: Proceedings of the 2012 ACM conference on Computer and communications security, P617, DOI [DOI 10.1145/2382196.2382261, 10.1145/2382196.2382261]
   Shokri R, 2011, P IEEE S SECUR PRIV, P247, DOI 10.1109/SP.2011.18
   Wang D, 2019, MULTIMED TOOLS APPL, V78, P34801, DOI 10.1007/s11042-019-08092-0
   Xiong P, 2016, KNOWL INF SYST, V47, P647, DOI 10.1007/s10115-015-0856-1
   Yin CY, 2018, IEEE T IND INFORM, V14, P3628, DOI 10.1109/TII.2017.2773646
   Zhu TQ, 2017, ADV INFORM SECUR, V69, P151, DOI 10.1007/978-3-319-62004-6_12
NR 23
TC 6
Z9 7
U1 1
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21823
EP 21841
DI 10.1007/s11042-021-10789-0
EA MAR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000630848100005
DA 2024-07-18
ER

PT J
AU Nizami, IF
   Akhtar, M
   Waqar, A
   Mann, AB
   Majid, M
AF Nizami, Imran Fareed
   Akhtar, Mehreen
   Waqar, Asad
   Mann, Amer Bilal
   Majid, Muhammad
TI Multiply distorted image quality assessment based on feature level
   fusion and optimal feature selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE No reference image quality assessment; Multiply distorted images;
   Feature selection; Feature extraction; Feature level fusion
ID STATISTICS; ALGORITHM
AB No reference image quality assessment (NR-IQA) has received considerable importance in the last decade due to a rise in the use of multimedia content in our daily lives. Due to limitations in technology, multiple distortions may be introduced in the images that need to be assessed. Recently feature selection has shown promising results for single distorted NR-IQA and their effectiveness on multiple distorted images still need to be addressed. In this paper, impact of feature level fusion and feature selection on multiple distorted image quality assessment is presented. To this end features are extracted from multiple distorted images using six NR-IQA techniques (BLIINDS-II, BRISQUE, CurveletQA, DIIVINE, GM-LOG, SSEQ) that extract features in different (discrete cosine transform, spatial, curvelet transform, wavelet transform, spatial and gradient, spatial and spectral) domains. The extracted features from different domains are fused to generate a single feature vector. All combinations of feature-level fusion from six different techniques have been evaluated. Three different feature selection algorithms (genetic search, linear forward search, particle swarm optimization) are then applied to select optimum features for NR-IQA. The selected features are then used by the support vector regression model to predict the quality score. The performance of the proposed methodology is evaluated for two multiple distorted IQA databases (LIVE multiple distorted image dataset (LIVEMD), multiply distorted image database (MDID2017)), two singly synthetically distorted IQA databases (Tampere image database (TID2013), Computational and subjective image quality database (CSIQ)), and one screen content IQA database (Screen content image quality database (SIQAD)). Experimental results show that the fusion of features from different domains gives better performance in comparison to existing multiple-distorted NR-IQA techniques with SROCC scores of 0.9555, 0.9587, 0.6892, 0.9452, and 0.7682 on the LIVEMD, MDID, TID2013, CSIQ, and SIQAD databases respectively. Moreover, the performance is further improved when the genetic search feature selection algorithm is applied to fused features to remove the redundant and irrelevant features. The SROCC scores are improved to 0.9691, 0.9723, and 0.6897 for LIVEMD, MDID, and TID2013 databases respectively.
C1 [Nizami, Imran Fareed; Waqar, Asad] Bahria Univ, Dept Elect Engn, Islamabad, Pakistan.
   [Akhtar, Mehreen; Majid, Muhammad] Univ Engn & Technol Taxila, Dept Comp Engn, Punjab, Pakistan.
   [Mann, Amer Bilal] Fed Urdu Univ Arts Sci & Technol, Dept Math Sci, Islamabad, Pakistan.
C3 Federal Urdu University of Arts Science & Technology
RP Nizami, IF (corresponding author), Bahria Univ, Dept Elect Engn, Islamabad, Pakistan.
EM imnizami.buic@bahria.edu.pk; m.majid@uettaxila.edu.pk
RI Majid, Muhammad/Z-5667-2019; Waqar, Asad/AEM-8407-2022
OI Majid, Muhammad/0000-0003-3662-2525; 
CR Chen YT, 2021, VISUAL COMPUT, V37, P1691, DOI 10.1007/s00371-020-01932-3
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02066-z
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Dai T, 2018, NEUROCOMPUTING, V290, P185, DOI 10.1016/j.neucom.2018.02.050
   Gu K, 2014, IEEE T BROADCAST, V60, P555, DOI 10.1109/TBC.2014.2344471
   Gütlein M, 2009, 2009 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING, P332, DOI 10.1109/CIDM.2009.4938668
   Jayaraman D, 2012, CONF REC ASILOMAR C, P1693, DOI 10.1109/ACSSC.2012.6489321
   Jiang QP, 2019, IEEE T IMAGE PROCESS, V28, P1866, DOI 10.1109/TIP.2018.2881828
   Kalatehjari E, 2018, MULTIMED TOOLS APPL, V77, P25053, DOI 10.1007/s11042-018-5757-3
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Lay D., LINEAR ALGEBRA ITS A
   Li CF, 2018, IEEE ACCESS, V6, P64577, DOI 10.1109/ACCESS.2018.2877714
   Li CF, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199430
   Li QH, 2016, IEEE SIGNAL PROC LET, V23, P541, DOI 10.1109/LSP.2016.2537321
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P494, DOI 10.1016/j.image.2014.02.004
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Miao XK, 2019, SIGNAL PROCESS-IMAGE, V79, P54, DOI 10.1016/j.image.2019.08.013
   Min XK, 2018, IEEE T MULTIMEDIA, V20, P2049, DOI 10.1109/TMM.2017.2788206
   Min XK, 2018, IEEE T BROADCAST, V64, P508, DOI 10.1109/TBC.2018.2816783
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Nizami IF, 2020, MULTIMED TOOLS APPL, V79, P7811, DOI 10.1007/s11042-019-08465-5
   Nizami IF, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0392-5
   Nizami IF, 2018, APPL INTELL, V48, P3482, DOI 10.1007/s10489-018-1151-0
   Nizami IF, 2018, ARAB J SCI ENG, V43, P4057, DOI 10.1007/s13369-017-2803-9
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8
   Sun L, 2020, IEEE J-STARS, V13, P1174, DOI 10.1109/JSTARS.2020.2980576
   Sun W, 2018, IEEE T IMAGE PROCESS, V27, P4232, DOI 10.1109/TIP.2018.2837341
   Sun W, 2017, PATTERN RECOGN, V61, P153, DOI 10.1016/j.patcog.2016.07.033
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Xue WF, 2013, PROC CVPR IEEE, P995, DOI 10.1109/CVPR.2013.133
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang H, 2015, IEEE T IMAGE PROCESS, V24, P4408, DOI 10.1109/TIP.2015.2465145
   Yin XF, 2020, MATER EXPRESS, V10, P1317, DOI 10.1166/mex.2020.1734
   Yu F, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/4047957
   Yu F, 2019, NEUROCOMPUTING, V350, P108, DOI 10.1016/j.neucom.2019.03.053
   Yue GH, 2018, IEEE T MULTIMEDIA, V20, P2722, DOI 10.1109/TMM.2018.2807589
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang Y, 2018, IEEE T IMAGE PROCESS, V27, P5433, DOI 10.1109/TIP.2018.2857413
   Zhang Y, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043025
   Zhang YB, 2020, IEEE T IMAGE PROCESS, V29, P1101, DOI 10.1109/TIP.2019.2938347
   Zhou LY, 2020, IEEE ACCESS, V8, P30436, DOI 10.1109/ACCESS.2020.2972269
   Zhu WH, 2019, IEEE T MULTIMEDIA, V21, P2334, DOI 10.1109/TMM.2019.2902484
NR 58
TC 0
Z9 0
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21843
EP 21883
DI 10.1007/s11042-021-10672-y
EA MAR 2021
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000630848100004
DA 2024-07-18
ER

PT J
AU Kumar, R
   Gupta, A
   Arora, HS
   Raman, B
AF Kumar, Rahul
   Gupta, Ankur
   Arora, Harkirat Singh
   Raman, Balasubramanian
TI CBSN: Comparative measures of normalization techniques for brain tumor
   segmentation using SRCNet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor segmentation; Data normalization; Deep learning;
   Convolutional block attention; Squeeze and excitation; Refinement module
ID MRI; REPRESENTATION
AB The segmentation of tumors in the brain MRI scans is a difficult job for doctors and radiologists. The segmentation done by different medical experts may also have differences in their opinion for the segmented region, which is popularly known as regions of interest (ROIs). To date, researchers and academicians have proposed several approaches and frameworks for semi- and full-automatic segmentation techniques to identify ROIs accurately. It is prevalent that automatic segmentation gives comparable or even better results compared to human experts for several publicly known and privately collected datasets. Additionally, these are beneficial in those areas where doctors and radiologists' availability is either uneven or scarce because of geographical dispersion. The convolutional neural networks (CNN) are considered for segmentation for ROIs due to their wide popularity. They have outperformed humans over tasks like object identification and image classification. The publicly available datasets or those collected from different medical institutions may have different statistics, resolution, and properties. Therefore, pre-processing has an essential role in achieving better and accurate delineation and segmentation of tumors. In the proposed work, CBSN, we consider well-known normalization techniques such as Gaussian Mixture Models (GMM), Fuzzy C-Means (FCM), and Z-score normalization for pre-processing the BraTS (Brain Tumor Segmentation Challenge) 2018 dataset. We utilized three variants of U-Net architecture, convolutional block attention module (CBAM), squeeze and excitation module (SEM), and refinement module (RM) for the segmentation of the ROIs. Utilizing Z-score performs better than other normalization techniques for tumor core (TC) and whole tumor (WT) segmentation. In contrast, FCM performs superior to the other two normalization techniques on enhancement tumor (ET) segmentation.
C1 [Kumar, Rahul; Gupta, Ankur; Raman, Balasubramanian] Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
   [Arora, Harkirat Singh] Indian Inst Technol Roorkee, Dept Chem Engn, Roorkee, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Roorkee
RP Kumar, R (corresponding author), Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
EM rkumar9@cs.iitr.ac.in; agupta4@cs.iitr.ac.in; harora@ch.iitr.ac.in;
   bala@cs.iitr.ac.in
RI GUPTA, ANKUR/ABE-7986-2020
OI Arora, Harkirat Singh/0000-0001-6866-8814; Gupta,
   Ankur/0000-0002-6515-2596; KUMAR, RAHUL/0000-0002-9266-9515
FU Ministry of Electronics & Information Technology (MeitY)
FX The author Rahul Kumar would like to thank for support through the
   "Visvesvaraya Ph.D. Scheme for Electronics & IT" by the Ministry of
   Electronics & Information Technology (MeitY), Govt. of India, to carry
   out this research.
CR Aboelenein NM, 2020, IEEE ACCESS, V8, P101406, DOI 10.1109/ACCESS.2020.2998601
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117
   Bakas Spyridon, 2018, ARXIV181102629, DOI DOI 10.17863/CAM.38755
   Bauer S, 2013, PHYS MED BIOL, V58, pR97, DOI 10.1088/0031-9155/58/13/R97
   Bezdek J. C., 1981, Pattern recognition with fuzzy objective function algorithms
   Cardinaux F, 2003, LECT NOTES COMPUT SC, V2688, P911
   Casamitjana A., 2016, P MICCAI CHALL MULT, P65
   Cheng JH, 2019, IEEE INT C BIOINFORM, P1031, DOI [10.1109/bibm47256.2019.8983092, 10.1109/BIBM47256.2019.8983092]
   Cordier N, 2016, IEEE T MED IMAGING, V35, P1066, DOI 10.1109/TMI.2015.2508150
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Geng ZQ, 2018, INT C CONTROL DECISI, P164, DOI 10.1109/CoDIT.2018.8394853
   Ghaffari M, 2020, IEEE REV BIOMED ENG, V13, P156, DOI 10.1109/RBME.2019.2946868
   Gupta N, 2019, BIOMED SIGNAL PROCES, V47, P115, DOI 10.1016/j.bspc.2018.06.003
   Gupta N, 2018, J COMPUT SCI-NETH, V25, P213, DOI 10.1016/j.jocs.2017.02.009
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Hu J., 2018, PROC IEEECVF C COMPU, P7132, DOI DOI 10.1109/CVPR.2018.00745
   IN A, 2016, PROCEDIA COMPUT SCI, V102, P317
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Liang Z-P, 2000, PRINCIPLES MAGNETIC
   Lin FM, 2021, MULTIMED TOOLS APPL, V80, P22951, DOI 10.1007/s11042-020-08795-9
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Long JS, 2020, MULTIMED TOOLS APPL, V79, P24929, DOI 10.1007/s11042-020-09210-z
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Louis DN, 2007, ACTA NEUROPATHOL, V114, P547, DOI 10.1007/s00401-007-0278-6
   Lucey S, 2004, PROC CVPR IEEE, P855
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Montague M., 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P427, DOI 10.1145/502585.502657
   Nefian AV, 2000, IEEE IMAGE PROC, P33, DOI 10.1109/ICIP.2000.900885
   Ostrom QT, 2016, NEURO-ONCOLOGY, V18, P1, DOI 10.1093/neuonc/nov297
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Pritchard R, 2020, J COMP NEUROL, V528, P199, DOI 10.1002/cne.24747
   Randhawa RS, 2016, LECT NOTES COMPUT SC, V10154, P65, DOI 10.1007/978-3-319-55524-9_7
   Romero JE, 2015, MAGN RESON IMAGING, V33, P474, DOI 10.1016/j.mri.2015.02.005
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rousseau F, 2011, IEEE T MED IMAGING, V30, P1852, DOI 10.1109/TMI.2011.2156806
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Tseng KL, 2017, PROC CVPR IEEE, P3739, DOI 10.1109/CVPR.2017.398
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Ying ZG, 2017, MED PHYS, V44, P5234, DOI 10.1002/mp.12481
   Zhang JX, 2020, IEEE ACCESS, V8, P58533, DOI 10.1109/ACCESS.2020.2983075
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
   Zhao XM, 2016, LECT NOTES COMPUT SC, V10154, P75, DOI 10.1007/978-3-319-55524-9_8
   Zheng CH, 2011, IEEE ACM T COMPUT BI, V8, P1273, DOI 10.1109/TCBB.2011.20
NR 47
TC 0
Z9 0
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13203
EP 13235
DI 10.1007/s11042-021-10565-0
EA MAR 2021
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000629494100006
DA 2024-07-18
ER

PT J
AU Tariq, J
   Armghan, A
   Ijaz, A
   Ashraf, I
AF Tariq, Junaid
   Armghan, Ammar
   Ijaz, Amir
   Ashraf, Imran
TI Light weight model for intra mode selection in HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Light weight; Optimal stopping theory; Intra mode
ID DECISION; PREDICTION; EFFICIENCY; ALGORITHM
AB The High Efficiency Video Coding (HEVC) efficiently reduces the size of the multimedia contents, but at the cost of high computation complexity. In order to make it work for the real time applications, a study is conducted in this article to speed up the intra mode decision of HEVC. Firstly, a novel early termination mechanism is proposed that is based on the duration problem. This model is designed such that it requires the least amount of computation and dynamically adjusts to the current best option. Secondly, a dynamic threshold is proposed that outperformed majority of the thresholds in-terms of computation and adjustment with-respect-to the current best option. Experimental results proved that when the proposed methods are incorporated in HEVC, they reduced the encoding time by 34.1% on average, with a minor bit-rate (BD-BR) increase of 1.4% on average.
C1 [Tariq, Junaid] HITEC Univ, Dept Comp Sci, Taxila, Pakistan.
   [Armghan, Ammar] Jouf Univ, Dept Elect Engn, Sakaka, Saudi Arabia.
   [Ijaz, Amir; Ashraf, Imran] HITEC Univ, Dept Comp Sci & Engn, Taxila, Pakistan.
C3 NITEC University; Al Jouf University; NITEC University
RP Tariq, J (corresponding author), HITEC Univ, Dept Comp Sci, Taxila, Pakistan.
EM jtariq2-c@my.cityu.edu.hk; aarmghan@ju.edu.sa;
   amir.ijaz@hitecuni.edu.pk; imran.ashraf@hitecuni.edu.pk
RI Armghan, Ammar/ABA-9560-2021; ashraf, imran/HJA-5212-2022; Ijaz,
   Amir/D-2503-2016
OI Armghan, Ammar/0000-0002-9062-7493; ashraf, imran/0000-0003-4480-2489;
   Ijaz, Amir/0000-0002-6764-667X
CR Bjotegaard G., 2001, VCEGM33
   Bossen F, 2011, COMMON TEST CONDITIO
   Hatchett J, 2018, VISUAL COMPUT, V34, P167, DOI 10.1007/s00371-016-1322-0
   Ho S-Y, 2015, ARXIV150807931
   Koyama Y, 2019, VISUAL COMPUT, V35, P1131, DOI 10.1007/s00371-019-01693-8
   Kuang W, 2020, IEEE T CIRC SYST VID, V30, P1481, DOI 10.1109/TCSVT.2019.2903547
   Men QH, 2019, VISUAL COMPUT, V35, P973, DOI 10.1007/s00371-019-01690-x
   Mercat A, 2019, IEEE IMAGE PROC, P2676, DOI [10.1109/icip.2019.8803288, 10.1109/ICIP.2019.8803288]
   Nair PS, 2019, J INTELL FUZZY SYST, V36, P2095, DOI 10.3233/JIFS-169921
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Presman E. L., 1972, Theory of Probability and Its Applications, V17, P657, DOI 10.1137/1117078
   Tan HL, 2012, JCTVCH0166 JCTVC ITU
   TARIQ J, 2019, MULTIMED TOOLS APPL, V78, P1, DOI DOI 10.1007/S11042-018-6670-5
   Tariq J, 2020, VISUAL COMPUT, V36, P1603, DOI 10.1007/s00371-019-01764-w
   Tariq J, 2020, J VIS COMMUN IMAGE R, V68, DOI 10.1016/j.jvcir.2020.102766
   Tariq J, 2019, MULTIMED TOOLS APPL, V78, P16783, DOI 10.1007/s11042-018-7111-1
   Tariq J, 2018, J VIS COMMUN IMAGE R, V51, P1, DOI 10.1016/j.jvcir.2017.12.008
   Tariq J, 2017, J VIS COMMUN IMAGE R, V44, P198, DOI 10.1016/j.jvcir.2017.01.029
   Tariq J, 2015, IEEE SYS MAN CYBERN, P1776, DOI 10.1109/SMC.2015.311
   Tian R, 2019, MULTIMED TOOLS APPL, V78, P289, DOI 10.1007/s11042-018-6001-x
   Tsang SH, 2019, IEEE T MULTIMEDIA, V21, P269, DOI 10.1109/TMM.2018.2856078
   Ugur K, 2010, IEEE T CIRC SYST VID, V20, P1688, DOI 10.1109/TCSVT.2010.2092613
   Wali I, 2019, SIGNAL IMAGE VIDEO P, V13, P145, DOI 10.1007/s11760-018-1339-0
   Wang LL, 2013, IEEE T CIRC SYST VID, V23, P1686, DOI 10.1109/TCSVT.2013.2255398
   Yan ZG, 2019, PROCEEDINGS OF 2019 INTERNATIONAL CONFERENCE ON IMAGE, VIDEO AND SIGNAL PROCESSING (IVSP 2019), P45, DOI 10.1145/3317640.3317645
   Yeh CH, 2014, IEEE T IND INFORM, V10, P594, DOI 10.1109/TII.2013.2273308
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P1714, DOI 10.1109/TCSVT.2016.2556518
   Zhao TS, 2012, IEEE T IMAGE PROCESS, V21, P2607, DOI 10.1109/TIP.2012.2186148
   Zhe Sheng, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P541, DOI 10.1007/978-3-319-04114-8_46
NR 30
TC 7
Z9 7
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21449
EP 21464
DI 10.1007/s11042-021-10677-7
EA MAR 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000629494100009
DA 2024-07-18
ER

PT J
AU Denis, R
   Madhubala, P
AF Denis, R.
   Madhubala, P.
TI Hybrid data encryption model integrating multi-objective adaptive
   genetic algorithm for secure medical data communication over cloud-based
   healthcare systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption; Decryption; Data hiding; Cloud environment; Health
   information exchange; Adaptive genetic algorithm; Steganalysis
ID IMAGE; INTERNET; STEGANOGRAPHY; CRYPTOGRAPHY; CHALLENGES; NETWORK;
   FUSION; SCHEME; ISSUES
AB The exponential rise in the development of cloud computing environments in the healthcare field, the protection and confidentiality of the medical records become a primary concern for healthcare services applications. Today, health data stored in the cloud is highly confidential information concealed to avoid unauthorized access to protect the patient's information. As cloud-based medical data transmission becomes more common, it receives growing attention from researchers and academics. Despite the potential for misuse, medical data transmitted through unreliable networks can be manipulated or compromised. The current cryptosystems alone are not sufficient to deal with these issues, and hence this paper introduces a new hybridization of data encryption model to shelter the diagnosis data in medical images. The proposed model is developed by combining either 2D Discrete Wavelet Transform 1 Level (2D-DWT-1 L) or 2D Discrete Wavelet Transform 2 Level (2D-DWT-2 L) steganography with the proposed hybrid encryption scheme. The hybrid encryption scheme is built by strategically applying Advanced Encryption Standard (AES) and Rivest-Shamir-Adleman (RSA) algorithms to secure diagnosis data to be embedded with the RGB channels of medical cover image. One of the key novelties is the use of an Adaptive Genetic Algorithm for Optimal Pixel Adjustment Process (AGA-OPAP) that enriches data hiding ability as well as imperceptibility features. To evaluate the efficiency of the proposed model, numerical tests are performed. The results show that the proposed algorithm is capable of safely transmitting medical data. Comparison of results is carried out concerning the datasets with the state-of-the-art algorithm. In terms of various statistical measures, the results showed the superiority of the proposed algorithm, such as peak signal to noise ratio (PSNR), correlation, structural content (SC), structure similarity (SSIM), entropy, histogram, NPCR, UACI and embedding capacity. The proposed model can also prevent attacks, such as steganalysis or RS attacks.
C1 [Denis, R.] Periyar Univ, Dept Comp Sci, Salem, TN, India.
   [Madhubala, P.] Don Bosco Coll, Dept Comp Sci, Dharmapuri, TN, India.
C3 Periyar University
RP Denis, R (corresponding author), Periyar Univ, Dept Comp Sci, Salem, TN, India.
EM denisatshc@gmail.com; madhubalasivaji@gmail.com
RI R, Denis/AAT-5051-2020
OI R, Denis/0000-0001-6260-8298
CR Abd-El-Atty B, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113108
   Ahmadi MH, 2019, J THERM ANAL CALORIM, V135, P271, DOI 10.1007/s10973-018-7035-z
   Ahmed DEM, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING (ICCCE), P288, DOI 10.1109/ICCCE.2014.88
   Al Barazanchi I., 2019, TELKOMNIKA TELECOMMU, V17, P2818, DOI DOI 10.12928/TELKOMNIKA.V17I6.13201
   Alam MS, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON POWER, CONTROL, SIGNALS AND INSTRUMENTATION ENGINEERING (ICPCSI), P649, DOI 10.1109/ICPCSI.2017.8391793
   [Anonymous], 2017, INT J BIOSCI, DOI DOI 10.12692/ijb/10.5.1-7
   [Anonymous], 2013, INT J EMERG TECHNOL
   Anwar A.S., 2015, INT J BIOMED INFORM, V3, P7
   Bairagi AK, 2016, INF SECUR J, V25, P197, DOI 10.1080/19393555.2016.1206640
   Bashir A., 2012, INT J COMPUTERS APPL, V42, P36, DOI DOI 10.5120/5723-7785
   Chidambaram N, 2019, MULTIMED TOOLS APPL, V78, P33837, DOI 10.1007/s11042-019-08166-z
   Duluta A, 2017, 2017 21ST INTERNATIONAL CONFERENCE ON CONTROL SYSTEMS AND COMPUTER SCIENCE (CSCS), P453, DOI 10.1109/CSCS.2017.70
   El-Emam NN, 2015, APPL SOFT COMPUT, V37, P830, DOI 10.1016/j.asoc.2015.08.057
   Elhayatmy G, 2018, STUD BIG DATA, V30, P3, DOI 10.1007/978-3-319-60435-0_1
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Gupta K, 2012, ADV ENG SOFTW, V49, P29, DOI 10.1016/j.advengsoft.2012.03.001
   Hajduk V, 2016, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE RADIOELEKTRONIKA (RADIOELEKTRONIKA 2016), P350, DOI 10.1109/RADIOELEK.2016.7477370
   Hashim MM, 2019, 2019 7TH INTERNATIONAL CONFERENCE ON MECHATRONICS ENGINEERING (ICOM), P48, DOI 10.1109/icom47790.2019.8952061
   Jain M, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P291, DOI 10.1109/IC3I.2016.7917977
   Kadhim KT, 2020, WIRELESS PERS COMMUN, V114, P2235, DOI 10.1007/s11277-020-07474-0
   Khalil M. I., 2017, International Journal of Computer Network and Information Security, V9, P22, DOI 10.5815/ijcnis.2017.02.03
   Kumar L, 2014, INT J SCI STUDY, V1, P5
   Laskar S. A., 2012, International Journal of Database Management Systems (IJDMS), V4, P57
   Leung YW, 2015, 2015 IEEE 4TH GLOBAL CONFERENCE ON CONSUMER ELECTRONICS (GCCE), P570, DOI 10.1109/GCCE.2015.7398667
   Li L, 2019, CLUSTER COMPUT, V22, P2293, DOI 10.1007/s10586-017-1345-y
   Li TH, 2011, 2011 INTERNATIONAL CONFERENCE ON MECHANICAL ENGINEERING AND TECHNOLOGY (ICMET 2011), P317
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Lili Yu, 2012, 2012 4th International Conference on Computational Intelligence and Communication Networks (CICN 2012), P762, DOI 10.1109/CICN.2012.195
   Madhusudhan KN, 2021, J AMB INTEL HUM COMP, V12, P5413, DOI 10.1007/s12652-020-02028-5
   Mansour RF, 2019, MULTIDIM SYST SIGN P, V30, P791, DOI 10.1007/s11045-018-0575-3
   Mare S. F., 2011, Proceedings 2011 IEEE 17th International Symposium for Design and Technology in Electronic Packaging (SIITME 2011), P339, DOI 10.1109/SIITME.2011.6102748
   Masood I, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/2143897
   Muhammad K, 2018, FUTURE GENER COMP SY, V86, P951, DOI 10.1016/j.future.2016.11.029
   Mukhedkar M., 2015, P ANN IEEE IND C IND, P1, DOI DOI 10.1109/INDICON.2015.7443808
   Nithyabharathi PV, 2014, IJSETR, V3
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Ou B, 2015, SIGNAL PROCESS, V108, P642, DOI 10.1016/j.sigpro.2014.10.012
   Panchal Dhvani, 2015, IJEDR, V3
   Pandey HM, 2020, FUTURE GENER COMP SY, V111, P213, DOI 10.1016/j.future.2020.04.034
   Paschou M, 2013, SIMUL MODEL PRACT TH, V34, P186, DOI 10.1016/j.simpat.2012.08.002
   Patil P, 2016, PROCEDIA COMPUT SCI, V78, P617, DOI 10.1016/j.procs.2016.02.108
   Pushpa B, 2020, 2020 4 INT COMP MET, P329, DOI DOI 10.1109/ICCMC48092.2020.ICCMC-00062
   RajeshKumar N, 2020, CMC-COMPUT MATER CON, V65, P1283, DOI 10.32604/cmc.2020.011226
   Ramalingam B, 2017, MICROPROCESS MICROSY, V50, P1, DOI 10.1016/j.micpro.2017.02.003
   Rathore S, 2017, INFORM SCIENCES, V421, P43, DOI 10.1016/j.ins.2017.08.063
   Ravichandran D, 2017, IEEE T NANOBIOSCI, V16, P850, DOI 10.1109/TNB.2017.2780881
   Razzaq MA, 2017, INT J ADV COMPUT SC, V8, P224
   Sajjad M, 2020, FUTURE GENER COMP SY, V108, P995, DOI 10.1016/j.future.2017.11.013
   Sajjad M, 2017, MULTIMED TOOLS APPL, V76, P3519, DOI 10.1007/s11042-016-3811-6
   Saleh ME, 2016, INT J ADV COMPUT SC, V7, P390
   Setyaningsih E, 2020, DIGIT COMMUN NETW, V6, P486, DOI 10.1016/j.dcan.2020.02.001
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Shahzadi S, 2017, J CLOUD COMPUT-ADV S, V6, DOI 10.1186/s13677-017-0097-9
   Shankar K, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5122
   Shilpi Harnal RK, 2019, IJITEE, V10
   Singh A, 2017, J NETW COMPUT APPL, V79, P88, DOI 10.1016/j.jnca.2016.11.027
   Sivaswamy J, 2014, I S BIOMED IMAGING, P53, DOI 10.1109/ISBI.2014.6867807
   Sreekutty MS, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON CIRCUIT ,POWER AND COMPUTING TECHNOLOGIES (ICCPCT)
   Stoyanov B, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22050501
   Su N, 2019, PROCEEDINGS OF 2019 IEEE 3RD INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2019), P2071, DOI [10.1109/ITNEC.2019.8729488, 10.1109/itnec.2019.8729488]
   Usman M., 2018, 2018 3 INT C EM TREN, P1, DOI [10.1109/ICEEST.2018.8643327, DOI 10.1109/ICEEST.2018.8643327]
   Venkatraman K, 2019, AUTOMATIKA-UK, V60, P314, DOI 10.1080/00051144.2019.1624409
   Wajgade VM, 2013, INT J EMERG TECHNOL, V3
   Yang RP, 2018, FUTURE GENER COMP SY, V78, P799, DOI 10.1016/j.future.2017.05.035
   Yu J, 2020, J HEALTHC ENG, V2020, DOI 10.1155/2020/1051394
   Zaw Z.M., 2015, INT J COMPUTER IJC, V19, P26
   Zhang M, 2015, MULTIMED TOOLS APPL, V74, P11255, DOI 10.1007/s11042-014-2227-4
NR 67
TC 31
Z9 31
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21165
EP 21202
DI 10.1007/s11042-021-10723-4
EA MAR 2021
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000628488100001
DA 2024-07-18
ER

PT J
AU Xu, SY
   Chang, CC
   Liu, YJ
AF Xu, Shuying
   Chang, Chin-Chen
   Liu, Yanjun
TI A high-capacity reversible data hiding scheme for encrypted images
   employing vector quantization prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encrypted image; VQ compression; Prediction error; Reversible data
   hiding
AB In this paper, a high-capacity RDHEI scheme based on Vector Quantization prediction (VQP) and adaptive block selection is proposed. VQ compression is a simple lossy compression method. In our scheme, VQ compression is used to estimate the original pixels to vacate room before encryption. Since the difference between the VQ decompressed image and the original image is small when the length of codebook is sufficient, using the difference as a prediction error can obtain more space for data embedding. Moreover, adaptive block selection is used in our scheme. Each block in the image dynamically adopts different data embedding strategies according to different block types. In addition, the experimental results show that our scheme can not only obtain considerable embedding capacity and perfect image restoration effect, but also has a good performance in terms of security.
C1 [Xu, Shuying; Chang, Chin-Chen; Liu, Yanjun] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 407, Taiwan.
C3 Feng Chia University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 407, Taiwan.
EM alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023; 刘, 严君/GZL-5764-2022; Xu,
   Shuying/KBA-0862-2024; liu, yan/HGV-1365-2022; liu, yan/HCI-5542-2022
CR Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chang CC, 2019, MATH BIOSCI ENG, V16, P3367, DOI 10.3934/mbe.2019168
   Chang CC, 2019, IEEE ACCESS, V7, P54117, DOI 10.1109/ACCESS.2019.2908924
   Chang CC, 2018, IEEE ACCESS, V6, P70720, DOI 10.1109/ACCESS.2018.2880904
   Gao K, 2020, IEEE ACCESS, V8, P130405, DOI 10.1109/ACCESS.2020.3009410
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Li FY, 2021, MULTIMED TOOLS APPL, V80, P2141, DOI 10.1007/s11042-020-09805-6
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Malik A, 2020, MULTIMED TOOLS APPL, V79, P11591, DOI 10.1007/s11042-019-08460-w
   Mohammadi A, 2020, IEEE T CIRC SYST VID, V30, P2366, DOI 10.1109/TCSVT.2020.2990952
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Wang P, 2020, IEEE ACCESS, V8, P28902, DOI 10.1109/ACCESS.2020.2972622
   Wu HB, 2019, MULTIMED TOOLS APPL, V78, P25349, DOI 10.1007/s11042-019-07769-w
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xie XZ, 2020, IEEE ACCESS, V8, P52028, DOI 10.1109/ACCESS.2020.2980302
   Xu DW, 2016, SIGNAL PROCESS, V123, P9, DOI 10.1016/j.sigpro.2015.12.012
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2013, SECUR COMMUN NETW, V6, P1396, DOI 10.1002/sec.742
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhang YS, 2015, NONLINEAR DYNAM, V82, P1831, DOI 10.1007/s11071-015-2280-1
   Zhou JT, 2016, IEEE T CIRC SYST VID, V26, P441, DOI 10.1109/TCSVT.2015.2416591
NR 29
TC 7
Z9 8
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20307
EP 20325
DI 10.1007/s11042-021-10698-2
EA MAR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625612900006
DA 2024-07-18
ER

PT J
AU Zouhri, A
   Boumhidi, I
AF Zouhri, Amal
   Boumhidi, Ismail
TI Stability analysis of interconnected complex nonlinear systems using the
   Lyapunov and Finsler property
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interconnected system; Lyapunov; H&#8734; control; Finsler;
   Decentralized state feedback; Linear matrix inequality (LMI)
AB This study focuses on the question of the stability analysis of complex interconnected nonlinear systems using the property of Lyapunov and Finsler. The main idea is to minimize the effect of interconnections between the subsystems, for that, we use the Lyapunov function and the H infinity control, then applying Finsler's lemma to release the conditions of stability, the independent matrices allow to obtain less conservative results. The proposed control approach is formulated in a minimization problem and derived in terms of linear matrix inequalities (LMIs) whose resolution yields the decentralized control gain matrices. All the developed results are tested on two representative examples and compared with some recent previous ones.
C1 [Zouhri, Amal; Boumhidi, Ismail] Sidi Mohammed Ben Abdellah Univ, Fac Sci Dhar El Mahraz, Lab Informat Signaux Automat & Cognitivisme, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP Zouhri, A (corresponding author), Sidi Mohammed Ben Abdellah Univ, Fac Sci Dhar El Mahraz, Lab Informat Signaux Automat & Cognitivisme, Fes, Morocco.
EM amal.zouhri@usmba.ac.ma; ismail.boumhidi@usmba.ac.ma
RI ZOUHRI, Amal/AAA-4511-2022; Boumhidi, Ismail/HTT-5066-2023
CR Abbaszadeh M, 2012, AUTOMATICA, V48, P894, DOI 10.1016/j.automatica.2012.02.033
   Bernussou J., 1982, Interconnected Dynamical Systems
   BOUMHIDI, 2016, INT J MATH STAT, V17, P55
   Cheng QC, 2019, CIRC SYST SIGNAL PR, V38, P2335, DOI 10.1007/s00034-018-0965-7
   Hwang HD, 2003, IEEE T NEURAL NETWOR, V14, P201, DOI 10.1109/TNN.2002.806643
   Jiekun Li, 2010, 2010 2nd International Conference on Education Technology and Computer (ICETC 2010), P344, DOI 10.1109/ICETC.2010.5530057
   Lin WW, 2007, IEEE T SYST MAN CY B, V37, P1074, DOI 10.1109/TSMCB.2007.896016
   Mahmoud MS, 2010, NONLINEAR ANAL-HYBRI, V4, P531, DOI 10.1016/j.nahs.2010.01.001
   Mahmoud MS, 2009, EUR J CONTROL, V15, P624, DOI 10.3166/EJC.15.624-633
   Souza M, 2017, IEEE T AUTOMAT CONTR, V62, P4167, DOI 10.1109/TAC.2017.2682032
   Stankovic SS, 2009, SYST CONTROL LETT, V58, P271, DOI 10.1016/j.sysconle.2008.11.003
   Thanh NT, 2012, J PROCESS CONTR, V22, P1325, DOI 10.1016/j.jprocont.2012.06.005
   Wang WJ, 2005, IEEE T FUZZY SYST, V13, P779, DOI 10.1109/TFUZZ.2005.859309
   Yi Z, 2002, IEEE T FUZZY SYST, V10, P92, DOI 10.1109/91.983283
   Zhu YL, 2007, IMA J MATH CONTROL I, V24, P57, DOI [10.1093/imamci/dn1007, 10.1093/imamci/dnl007]
   Zouhri Amal, 2017, CIT. Journal of Computing and Information Technology, V25, P167, DOI 10.20532/cit.2017.1003418
   Zouhri A., 2016, INT REV AUTOMATIC CO, V9, P103, DOI [10.15866/ireaco.v9i2.8728, DOI 10.15866/ireaco.v9i2.8728]
   Zouhri A, 2015, I C COMP SYST APPLIC, DOI 10.1109/AICCSA.2015.7507224
NR 18
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19971
EP 19988
DI 10.1007/s11042-020-10449-9
EA MAR 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625344600003
DA 2024-07-18
ER

PT J
AU Lu, TT
   Yeh, SC
   Wang, CH
   Wei, MR
AF Lu, Ta-Te
   Yeh, Sheng-Cheng
   Wang, Chia-Hui
   Wei, Min-Rou
TI Cost-effective real-time recognition for human emotion-age-gender using
   deep learning with normalized facial cropping preprocess
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection; Deep learning; Normalized facial cropping; Binocular
   line angle correction; Companion robot; Social applications
ID NETWORKS; FACE
AB Because of technological advancement, human face recognition has been commonly applied in various fields. There are some HCI-related applications, such as camera-ready chatbot and companion robot, require gathering more information from user's face. In this paper, we developed a system called EAGR for emotion, age, and gender recognition, which can perceive user's emotion, age and gender based on the face detection. The EAGR system first applies normalized facial cropping (NFC) as a preprocessing method for training data before data augmentation, then uses convolution neural network (CNN) as three training models for recognizing seven emotions (six basics plus one neutral emotion), four age groups, and two genders. For better emotion recognition, the NFC will extract facial features without hair retained. On the other hand, the NFC will extract facial features with hair retained for better age and gender recognition. The experiments were conducted on these three training models of emotion, age and gender recognitions. The recognition performance results from the testing dataset, which has been normalized for tilted head by proposed binocular line angle correction (BLAC), showed that the optimal mean accuracy rates of real-time recognition for seven emotions, four age groups and two genders were 82.4%, 74.95%, and 96.65% respectively. Furthermore, the training time can be substantially reduced via NFC preprocessing. Therefore, we believe that EAGR system is cost-effective in recognizing human emotions, ages, and genders. The EAGR system can be further applied in social applications to help HCI service provide more accurate feedback from pluralistic facial classifications.
C1 [Lu, Ta-Te] Chien Hsin Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taoyuan 320, Taiwan.
   [Yeh, Sheng-Cheng; Wei, Min-Rou] Ming Chuan Univ, Dept Comp & Commun Engn, Taoyuan 333, Taiwan.
   [Wang, Chia-Hui] Ming Chuan Univ, Dept Comp Sci & Informat Engn, Taoyuan 333, Taiwan.
C3 Chien Hsin University of Science & Technology; Ming Chuan University;
   Ming Chuan University
RP Wang, CH (corresponding author), Ming Chuan Univ, Dept Comp Sci & Informat Engn, Taoyuan 333, Taiwan.
EM ttlu@uch.edu.tw; peteryeh@mail.mcu.edu.tw; wangch@mail.mcu.edu.tw;
   asdfff31@gmail.com
OI Wang, Chia-Hui/0000-0002-3125-8632
CR [Anonymous], 2017, ARXIV170204280
   BALDI PF, 1995, IEEE T NEURAL NETWOR, V6, P837, DOI 10.1109/72.392248
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Ivakhnenko G, 1965, CYBERNETIC PREDICTIN
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li S., 2020, IEEE T AFFECT COMPUT, DOI DOI 10.1109/TAFFC.2020.2981446
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   MMI, FACIAL EXPRESSION DA
   Multimedia Understanding Group, FACIAL EXPRESSION DA
   Sharma M, 2019, MULTIMED TOOLS APPL, V78, P16195, DOI 10.1007/s11042-018-7030-1
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tang ZC, 2019, FRONT INFORM TECH EL, V20, P1087, DOI 10.1631/FITEE.1800083
   Tang ZC, 2019, IEEE ACCESS, V7, P128185, DOI 10.1109/ACCESS.2019.2940034
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
NR 21
TC 1
Z9 1
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19845
EP 19866
DI 10.1007/s11042-021-10673-x
EA MAR 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000624399500004
DA 2024-07-18
ER

PT J
AU Mujtaba, G
   Lee, S
   Kim, J
   Ryu, ES
AF Mujtaba, Ghulam
   Lee, Sangsoon
   Kim, Jaehyoun
   Ryu, Eun-Seok
TI Client-driven animated GIF generation framework using an acoustic
   feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Animated GIF; Acoustic feature; Client-driven
AB This paper proposes a novel, lightweight method to generate animated graphical interchange format images (GIFs) using the computational resources of a client device. The method analyzes an acoustic feature from the climax section of an audio file to estimate the timestamp corresponding to the maximum pitch. Further, it processes a small video segment to generate the GIF instead of processing the entire video. This makes the proposed method computationally efficient, unlike baseline approaches that use entire videos to create GIFs. The proposed method retrieves and uses the audio file and video segment so that communication and storage efficiencies are improved in the GIF generation process. Experiments on a set of 16 videos show that the proposed approach is 3.76 times more computationally efficient than a baseline method on an Nvidia Jetson TX2. Additionally, in a qualitative evaluation, the GIFs generated using the proposed method received higher overall ratings compared to those generated by the baseline method. To the best of our knowledge, this is the first technique that uses an acoustic feature in the GIF generation process.
C1 [Mujtaba, Ghulam; Lee, Sangsoon] Gachon Univ, Dept Comp Engn, Seongnam, South Korea.
   [Kim, Jaehyoun; Ryu, Eun-Seok] Sungkyunkwan Univ SKKU, Dept Comp Educ, Seoul, South Korea.
C3 Gachon University; Sungkyunkwan University (SKKU)
RP Kim, J; Ryu, ES (corresponding author), Sungkyunkwan Univ SKKU, Dept Comp Educ, Seoul, South Korea.
EM mujtaba@gachon.ac.kr; sslee@gachon.ac.kr; jaekim@skku.edu;
   esryu@skku.edu
RI Mujtaba, Ghulam/AAJ-9326-2020
OI Mujtaba, Ghulam/0000-0001-9244-5346
FU National Research Foundation of Korea (NRF) - Korean government (MSIT)
   [2019R1A2C1010476]; Gachon University [GCU-2019-0776]
FX This work was supported by a National Research Foundation of Korea (NRF)
   grant funded by the Korean government (MSIT) No.2019R1A2C1010476. This
   work was also supported in part by the Gachon University research fund
   of 2019 (Grant No. GCU-2019-0776).
CR Andén J, 2014, IEEE T SIGNAL PROCES, V62, P4114, DOI 10.1109/TSP.2014.2326991
   [Anonymous], 2015, 7540 RFC
   [Anonymous], 2014, ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing-Proceedings
   Bakhshi S, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P575, DOI 10.1145/2858036.2858532
   Chen WX, 2017, INT CONF AFFECT, P510
   Chiliguano P, 2016, INT CONF ACOUST SPEE, P2618, DOI 10.1109/ICASSP.2016.7472151
   Chiyuan Zhang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6984, DOI 10.1109/ICASSP.2014.6854954
   Choi K, 2017, INT CONF ACOUST SPEE, P2392, DOI 10.1109/ICASSP.2017.7952585
   Choi Keunwoo, 2016, ARXIV160600298, DOI 10.5281/zenodo.1416254
   Costa YMG, 2012, SIGNAL PROCESS, V92, P2723, DOI 10.1016/j.sigpro.2012.04.023
   Dai J, 2016, 2016 10TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP)
   Dev V, 2020, JAVASCRIPT HLS CLIEN
   Developer N, 2018, JETSON TX2 MODULE
   FFmpeg, 2020, FFMPEG GITH PAG
   Gygli M, 2016, PROC CVPR IEEE, P1001, DOI 10.1109/CVPR.2016.114
   Gygli M, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P122, DOI 10.1145/2964284.2967195
   Hamel P., 2010, ISMIR, P339
   Hauge M, 2017, 5 KEY TURNING POINTS
   HOPKINS R, 1994, IEEE T CONSUM ELECTR, V40, P185, DOI 10.1109/30.320795
   Jou B, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P213, DOI 10.1145/2647868.2656408
   Kim JW, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P161, DOI 10.1109/ICASSP.2018.8461329
   Li TLH, 2010, LECT NOTES ENG COMP, P546
   Li Y, 2020, KSII T INTERNET INF, V14, P2422
   Liu TL, 2020, IEEE T MULTIMEDIA, V22, P1098, DOI 10.1109/TMM.2019.2936805
   Loshchilov Ilya, 2018, Decoupled Weight Decay Regularization
   McFee B., 2015, P 14 PYTH SCI C, P18, DOI [DOI 10.25080/MAJORA-7B98E3ED-003, 10.25080/Majora-7b98e3ed-003]
   Mu RH, 2020, KSII T INTERNET INF, V14, P2310
   Mujtaba G, 2020, IEEE ACCESS, V8, P60417, DOI 10.1109/ACCESS.2020.2982992
   Mujtaba G, 2019, WIRELESS PERS COMMUN, V106, P2023, DOI 10.1007/s11277-018-5920-1
   OLeary M., 2019, CYBER OPERATIONS, P789
   Qiu SM, 2019, KSII T INTERNET INF, V13, P978, DOI 10.3837/tiis.2019.02.027
   RedwoodShores C, 2019, GIPHY SELECTS ORACLE
   Robert, 2020, PYDUB LIB
   Ryu ES, 2019, P KOR SOC BROADC ENG, P173
   Ryu ES, 2008, MULTIMED TOOLS APPL, V37, P319, DOI 10.1007/s11042-007-0166-z
   Ryu ES, 2011, IEEE T CONSUM ELECTR, V57, P1652, DOI 10.1109/TCE.2011.6131138
   Schindler A., 2016, FMT, P17
   Senac C, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095733
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Van den Oord A., 2013, ADV NEURAL INFORM PR, P2643, DOI [DOI 10.1109/MMUL.2011.34.VAN, 10.5555/2999792.2999907]
   Vernallis Carol., 2004, EXPERIENCING MUSIC V
   Wu MJ, 2015, ACM T MULTIM COMPUT, V12, DOI 10.1145/2801127
   Zhang C, 2020, KSII T INTERNET INF, V14, P1065, DOI 10.3837/tiis.2020.03.009
   Zhang PJ, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P379, DOI 10.1145/2671188.2749367
   Zhang WB, 2016, INTERSPEECH, P3304, DOI 10.21437/Interspeech.2016-1236
   Zhou YP, 2018, IEEE WINT CONF APPL, P170, DOI 10.1109/WACV.2018.00025
   Zurawski R., 2004, IND INFORM TECHNOLOG, P456
NR 47
TC 3
Z9 3
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35923
EP 35940
DI 10.1007/s11042-020-10236-6
EA FEB 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000617417600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Chidambaram, N
   Raj, P
   Thenmozhi, K
   Amirtharajan, R
AF Chidambaram, Nithya
   Raj, Pethuru
   Thenmozhi, K.
   Amirtharajan, Rengarajan
TI A new method for producing 320-bit modified hash towards tamper
   detection and restoration in colour images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hash; Image digest; Integrity check and restoration; Tamper detection
AB Image sharing in open and public communication infrastructure is vulnerable. There are several solutions articulated by worldwide researchers for secure image transmission. However, with the increasing computing capacity and capability, the currently available security solutions are being breached. This yearns for more robust solutions. The significant contribution of the proposed work involves in the generation of a new hash algorithm for the entire RGB image of size 256 x 256 with no Region of Interest (RoI) restriction. This paper mainly focuses on integrity verification, tamper detection, localisation of the tampered area and its restoration. The whole image is considered as sensitive data for which one-way integrity verification code is generated block-wise to locate the areas of tampering. Integrity validation phase will compare the received digest and generated the digest from the received image. Blocks which are failed to pass in integrity validation will undergo the recovery process.
C1 [Chidambaram, Nithya; Thenmozhi, K.; Amirtharajan, Rengarajan] SASTRA Deemed Univ, Sch EEE, ECE Dept, Thanjavur 613401, India.
   [Raj, Pethuru] Reliance Jio Info Comm Ltd RJIL, SRE Div, Bangalore 560025, Karnataka, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Amirtharajan, R (corresponding author), SASTRA Deemed Univ, Sch EEE, ECE Dept, Thanjavur 613401, India.
EM amir@ece.sastra.edu
RI Chidambaram, Nithya/AAU-7212-2021; Amirtharajan, Rengarajan/C-6471-2011
OI Amirtharajan, Rengarajan/0000-0003-1574-3045; Karuppuswamy,
   Thenmozhi/0000-0001-9829-0189; Chidambaram, Dr
   Nithya/0000-0001-6623-3825
FU Department of Science & Technology, New Delhi [SR/FST/ET-II/2018/221]
FX Authors thank Department of Science & Technology, New Delhi for the FIST
   funding (SR/FST/ET-II/2018/221). Also, Authors wish to thank the
   Intrusion Detection Lab at School of Electrical & Electronics
   Engineering, SASTRA Deemed University for providing infrastructural
   support to carry out this research work.
CR Abdelhakim A, 2019, MULTIMED TOOLS APPL, V78, P32523, DOI 10.1007/s11042-019-07986-3
   Al-Otum HM, 2019, MULTIMED TOOLS APPL, V78, P2199, DOI 10.1007/s11042-018-6328-3
   Al-Qershi OM, 2019, MULTIDIM SYST SIGN P, V30, P1671, DOI 10.1007/s11045-018-0624-y
   Asadi S, 2017, INFORM TECHNOL MANAG, V18, P305, DOI 10.1007/s10799-016-0270-8
   Barani MJ, 2019, OPTIK, V187, P205, DOI 10.1016/j.ijleo.2019.04.074
   Belferdi W, 2019, MULTIDIM SYST SIGN P, V30, P1093, DOI 10.1007/s11045-018-0597-x
   Bhattacharya A, 2018, MULTIDIM SYST SIGN P, V29, P1679, DOI 10.1007/s11045-017-0518-4
   Boussif M, 2018, IET NETW, V7, P294, DOI 10.1049/iet-net.2017.0180
   Chakravarthy S, 2019, MULTIMED TOOLS APPL, V78, P18693, DOI 10.1007/s11042-019-7265-5
   Gao GY, 2018, IEEE SIGNAL PROC LET, V25, P1099, DOI 10.1109/LSP.2018.2844562
   Haramoto H, 2019, MATH COMPUT SIMULAT, V161, P66, DOI 10.1016/j.matcom.2018.08.005
   Hu YC, 2016, FUTURE GENER COMP SY, V62, P92, DOI 10.1016/j.future.2016.04.001
   Kaur C., 2019, Stat. Optim. Inf. Comput, V7, P486, DOI DOI 10.19139/SOIC.V7I2.542
   Khan MA, 2016, J NETW COMPUT APPL, V71, P11, DOI 10.1016/j.jnca.2016.05.010
   Korus P, 2017, DIGIT SIGNAL PROCESS, V71, P1, DOI 10.1016/j.dsp.2017.08.009
   Laouamer L, 2018, IEEE ACCESS, V6, P26144, DOI 10.1109/ACCESS.2018.2831599
   Liu KC, 2012, IET IMAGE PROCESS, V6, P445, DOI 10.1049/iet-ipr.2011.0574
   Liu Y, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107293
   Prakash CS, 2018, MULTIMED TOOLS APPL, V77, P26939, DOI 10.1007/s11042-018-5899-3
   Rukhin A., 2010, NIST SPEC PUBL, V22
   Singh D, 2019, MULTIMED TOOLS APPL, V78, P4197, DOI 10.1007/s11042-017-5454-7
   Singh P, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3077140
   Soni B, 2018, IET IMAGE PROCESS, V12, P167, DOI 10.1049/iet-ipr.2017.0441
   Su QT, 2018, MULTIDIM SYST SIGN P, V29, P1055, DOI 10.1007/s11045-017-0487-7
   Teerakanok S, 2019, IEEE ACCESS, V7, P40550, DOI 10.1109/ACCESS.2019.2907316
   Walia S, 2019, AUST J FORENSIC SCI, V51, P488, DOI 10.1080/00450618.2018.1424241
   Wang XY, 2020, MULTIDIM SYST SIGN P, V31, P857, DOI 10.1007/s11045-019-00688-x
   Wirawan, 2019, INT J INTELL ENG SYS, V12, P62, DOI [10.22266/ijies2019.0831.07, DOI 10.22266/IJIES2019.0831.07]
   Xiang YP, 2019, SIGNAL PROCESS, V162, P282, DOI 10.1016/j.sigpro.2019.04.022
   Yang JC, 2017, FUTURE GENER COMP SY, V70, P94, DOI 10.1016/j.future.2016.06.015
   Zhang R, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/1591206
   Zhang Z, 2018, J INF PROCESS SYST, V14, P6
   Zheng LL, 2019, J VIS COMMUN IMAGE R, V58, P380, DOI 10.1016/j.jvcir.2018.12.022
   Zhu SY, 2016, LECT NOTES COMPUT SC, V10031, P307, DOI 10.1007/978-3-662-53887-6_11
NR 34
TC 4
Z9 4
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23359
EP 23375
DI 10.1007/s11042-020-10210-2
EA FEB 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000617417500001
DA 2024-07-18
ER

PT J
AU Pandey, F
   Dash, P
   Samanta, D
   Sarma, M
AF Pandey, Fagul
   Dash, Priyabrata
   Samanta, Debasis
   Sarma, Monalisa
TI ASRA: Automatic singular value decomposition-based robust fingerprint
   image alignment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Singular value decomposition; Segmentation; Fingerprint alignment;
   Uncontrolled environment
ID ADAPTIVE HISTOGRAM EQUALIZATION; ENHANCEMENT; REGISTRATION
AB Fingerprint-based user identification and authentication are now used in many applications, but achieving absolute accuracy (eliminating false matches) still remains an issue. One of the reasons behind this issue is inappropriate image alignment prior to the feature extraction. In this paper, a robust Singular Value Decomposition (SVD) based fingerprint alignment method is proposed which automatically aligns the segmented and rotated image within the angular range - 90(0) to 90(0). Further, it overcomes the limitations of the existing fingerprint alignment methods as it neither depends on the quality of the image nor requires any reference image. The effectiveness of the approach has been tested with the standard fingerprint image databases FVC2002 (DB1, DB2, DB3, and DB4), FVC2004 (DB1, DB2, DB3, and DB4) and captured sensor images in an uncontrolled environment. The proposed approach was found to be efficient both in terms of accuracy and computational time. Also, it worked well for both database images and captured sensor images.
C1 [Pandey, Fagul; Dash, Priyabrata; Samanta, Debasis] Indian Inst Technol Kharagpur, Dept Comp Sci & Engn, Kharagpur 721302, W Bengal, India.
   [Sarma, Monalisa] Indian Inst Technol Kharagpur, Subir Chowdhury Sch Qual & Reliabil, Kharagpur 721302, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Kharagpur
RP Samanta, D (corresponding author), Indian Inst Technol Kharagpur, Dept Comp Sci & Engn, Kharagpur 721302, W Bengal, India.
EM fagulpandey@iitkgp.ac.in; priya.fav67@iitkgp.ac.in;
   dsamanta@iitkgp.ac.in; monalisa@iitkgp.ac.in
OI dash, priyabrata/0000-0002-7246-9647; Samanta,
   Debasis/0000-0002-6104-3771
CR Atri, 2018, COMP STUD CFS IBP HO
   Boonchaiseree N, 2009, LECT NOTES COMPUT SC, V5558, P637, DOI 10.1007/978-3-642-01793-3_65
   Cao K, 2014, IEEE T PATTERN ANAL, V36, P1847, DOI 10.1109/TPAMI.2014.2302450
   Chang Y, 2018, IEEE ACCESS, V6, P11782, DOI 10.1109/ACCESS.2018.2797872
   Chen CI, 2017, IEEE SENS J, V17, P6995, DOI 10.1109/JSEN.2017.2747220
   Chen YL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106335
   Dedieu JP, 1997, LINEAR ALGEBRA APPL, V263, P1, DOI 10.1016/S0024-3795(96)00366-7
   DEMMEL J, 1992, SIAM J MATRIX ANAL A, V13, P1204, DOI 10.1137/0613074
   Dieckmann, 2019, INT C BIOMETRICS SPE, P1
   Dong SH, 2020, NEURAL COMPUT APPL, V32, P735, DOI 10.1007/s00521-018-03971-3
   Thai DH, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154160
   Eppstein, 2018, ARXIV180800561
   Feng JJ, 2008, PATTERN RECOGN, V41, P342, DOI 10.1016/j.patcog.2007.04.016
   Gao ZF, 2020, IEEE NETWORK, V34, P216, DOI 10.1109/MNET.001.1900260
   Goljan, 2018, ELECT IMAGING, V2018, P1
   Gu, 2020, ARXIV200505878
   Hossein-Nejad Z, 2017, COMPUT ELECTR ENG, V62, P524, DOI 10.1016/j.compeleceng.2016.11.034
   Huvanandana S, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P503, DOI 10.1109/ICIP.2000.899466
   Ibrahim H, 2009, IEEE T CONSUM ELECTR, V55, P891, DOI 10.1109/TCE.2009.5174471
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996
   Jayaram M.A., 2016, AM J INTELL SYST, V6, P48, DOI [DOI 10.5923/J.AJIS.20160602.03, 10.5923/j.ajis.20160602.03]
   Jolliffe IT, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2015.0202
   Kang B, 2018, IEEE T MULTIMEDIA, V20, P2478, DOI 10.1109/TMM.2018.2798282
   Khongkraphan K, 2019, J INF PROCESS SYST, V15, P22, DOI 10.3745/JIPS.04.0098
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Kour J, 2012, ADV COMPUTER SCI ENG, P93
   Lan S, 2019, PATTERN RECOGN, V95, P48, DOI 10.1016/j.patcog.2019.05.021
   Li, 2008, P IEEE RAD C ROM IT, P1
   Li HR, 2020, SOFT COMPUT, V24, P6851, DOI 10.1007/s00500-019-04324-5
   Lin CH, 2018, IEEE T IMAGE PROCESS, V27, P2008, DOI 10.1109/TIP.2017.2788866
   Liu LF, 2006, IEEE T IMAGE PROCESS, V15, P1100, DOI 10.1109/TIP.2005.864161
   Long Y, 2017, IEEE T GEOSCI REMOTE, V55, P2486, DOI 10.1109/TGRS.2016.2645610
   Ma, 2008, FAST OBJECT BASED IM
   Maio D, 2004, LECT NOTES COMPUT SC, V3072, P1
   Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144
   Mat Said KhairulAnuar., 2016, INT J CONTROL THEORY, V9, P15
   Merkle J, 2017, 2017 INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG)
   Mina Shaily, 2014, Psychiatry J, V2014, P897493, DOI [10.1109/SPMB.2015.7405471, 10.1155/2014/897493]
   Nussbaumer HJ, 1981, FAST FOURIER TRANSFO, P80, DOI DOI 10.1007/978-3-662-00551-4_4
   Padlia Minal, 2019, Nanoelectronics, Circuits and Communication Systems. Proceeding of NCCS 2017. Lecture Notes in Electrical Engineering (LNEE 511), P161, DOI 10.1007/978-981-13-0776-8_15
   Pandey, 2020, ASRA AUTOMATIC SINGU
   Panetta K, 2019, IEEE ACCESS, V7, P104567, DOI 10.1109/ACCESS.2019.2931980
   Park CH, 2005, LECT NOTES COMPUT SC, V3546, P693
   Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Prabhakar S, 2003, HDB FINGERPRINT RECO, P177
   QI J, 2005, PATTERN RECOGN, V26, P2424
   Raj S, 2020, PATTERN RECOGN LETT, V131, P79, DOI 10.1016/j.patrec.2019.12.003
   Ratha NK, 1996, IEEE T PATTERN ANAL, V18, P799, DOI 10.1109/34.531800
   Schuch P, 2018, 2018 INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG)
   Schuch P, 2018, IET BIOMETRICS, V7, P102, DOI 10.1049/iet-bmt.2016.0088
   Sharma A, 2013, INT J MACH LEARN CYB, V4, P679, DOI 10.1007/s13042-012-0131-7
   Tan, 2017, STUDY FINGERPRINT IM, P2114
   Tico M, 2003, IEEE T PATTERN ANAL, V25, P1009, DOI 10.1109/TPAMI.2003.1217604
   Tong XH, 2015, IEEE T GEOSCI REMOTE, V53, P4143, DOI 10.1109/TGRS.2015.2391999
   Vedrana K., 2012, P 27 C IMAGE VISION, P486
   Wang S, 2017, PATTERN RECOGN, V61, P447, DOI 10.1016/j.patcog.2016.08.017
   Wang S, 2016, PATTERN RECOGN, V54, P14, DOI 10.1016/j.patcog.2016.01.001
   Watson, 2004, NISTIR71515
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yager N, 2006, PATTERN RECOGN LETT, V27, P317, DOI 10.1016/j.patrec.2005.08.016
   Yan JJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P392, DOI 10.1109/ICCVW.2013.126
   Yang Yu, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P363, DOI 10.1109/TBIOM.2020.3007289
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P28525, DOI 10.1007/s11042-020-09311-9
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zahedi M, 2015, SIGNAL IMAGE VIDEO P, V9, P267, DOI 10.1007/s11760-013-0436-3
   Zanganeh O, 2014, 2014 INT C DIG IM CO, P1, DOI DOI 10.1109/DICTA.2014.7008121
   Zanganeh O, 2015, P 13 INT C ADV MOB C, P275
   Zhang D, 2018, ADV BIOMETRICS, P15
   Zhu E, 2005, PATTERN RECOGN, V38, P1685, DOI 10.1016/j.patcog.2005.02.016
   Zhu E, 2016, PATTERN RECOGN, V56, P116, DOI 10.1016/j.patcog.2016.02.015
   ZIMMERMAN JB, 1988, IEEE T MED IMAGING, V7, P304, DOI 10.1109/42.14513
NR 72
TC 5
Z9 5
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15647
EP 15675
DI 10.1007/s11042-021-10560-5
EA FEB 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000615174300009
DA 2024-07-18
ER

PT J
AU Cherifi, F
   Amroun, K
   Omar, M
AF Cherifi, Feriel
   Amroun, Kamal
   Omar, Mawloud
TI Robust multimodal biometric authentication on IoT device through ear
   shape and arm gesture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Multimodal authentication; Ear; Arm gesture; Score-level
   fusion
ID FEATURES; FUSION
AB Nowadays, authentication is required for both physical access to buildings and internal access to computers and systems. Biometrics are one of the emerging technologies used to protect these highly sensitive structures. However, biometric systems based on a single trait enclose several problems such as noise sensitivity and vulnerability to spoof attacks. In this regard, we present in this paper a fully unobtrusive and robust multimodal authentication system that automatically authenticates a user by the way he/she answers his/her phone, after extracting ear and arm gesture biometric modalities from this single action. To deal the challenges facing ear and arm gesture authentication systems in real-world applications, we propose a new method based on image fragmentation that makes the ear recognition more robust in relation to occlusion. The ear feature extraction process has been made locally using Local Phase Quantization (LPQ) in order to get robustness with respect to pose and illumination variation. We also propose a set of four statistical metrics to extract features from arm gesture signals. The two modalities are combined on score-level using a weighted sum. In order to evaluate our contribution, we conducted a set of experiments to demonstrate the contribution of each of the two biometrics and the advantage of their fusion on the overall performance of the system. The multimodal biometric system achieves an equal error rate (EER) of 5.15%.
C1 [Cherifi, Feriel; Amroun, Kamal] Univ Bejaia, Fac Sci Exactes, Lab Informat Med LIMED, Bejaia 06000, Algeria.
   [Omar, Mawloud] Univ Gustave Eiffel, ESIEE Paris, LIGM, Noisy Le Grand, France.
   [Omar, Mawloud] Univ Bejaia, Lab Modelisat & Optimisat Syst, Fac Sci Exactes, Bejaia 06000, Algeria.
C3 Universite de Bejaia; Universite Gustave-Eiffel; ESIEE Paris; Ecole des
   Ponts ParisTech; Universite de Bejaia
RP Cherifi, F (corresponding author), Univ Bejaia, Fac Sci Exactes, Lab Informat Med LIMED, Bejaia 06000, Algeria.
EM cherififeriel@gmail.com; kamalamroun@gmail.com;
   mawloud.omar@univ-eiffel.fr
RI cherifi, feriel/JEF-9730-2023; Kamal, Amroun/AAO-5968-2020
OI Kamal, Amroun/0000-0002-4259-2783
CR Abate AF, 2019, IEEE T SYST MAN CY-S, V49, P469, DOI 10.1109/TSMC.2017.2698258
   Abozaid A, 2019, MULTIMED TOOLS APPL, V78, P16345, DOI 10.1007/s11042-018-7012-3
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Akhtar Z, 2017, IEEE GLOB CONF SIG, P1368, DOI 10.1109/GlobalSIP.2017.8309185
   Akhtar Z, 2011, INT PROC COMPUT SCI, V4, P46
   [Anonymous], 2016, 8 INT C BUS INF SEC
   [Anonymous], IEEE ACS 13 INT C CO, DOI [10.1109/AICCSA.2016.7945755, DOI 10.1109/AICCSA.2016.7945755]
   [Anonymous], 2002, INTRO USTB EAR IMAGE
   Aronowitz, 2014, P 2014 IEEE INT JOIN, P1, DOI 10.1109/BTAS.2014.6996269
   Arteaga-Falconi JS, 2018, SUSTAIN CITIES SOC, V40, P274, DOI 10.1016/j.scs.2017.12.023
   Barra S, 2018, I W BIOMETRIC FORENS
   Buriro A., 2017, 2017 IEEE International Conference on Identity, Security and Behavior Analysis (ISBA), P1
   Chhabria SA, 2013, 2013 INTERNATIONAL CONFERENCE ON MACHINE INTELLIGENCE AND RESEARCH ADVANCEMENT (ICMIRA 2013), P486, DOI 10.1109/ICMIRA.2013.103
   Dornaika F, 2017, HANDBOOK OF NEURAL COMPUTATION, P591, DOI 10.1016/B978-0-12-811318-9.00032-6
   Emersic Z, 2017, NEUROCOMPUTING, V255, P26, DOI 10.1016/j.neucom.2016.08.139
   Gofman M, 2015, ICSEA 2015, P274
   Gofman MI, 2016, COMMUN ACM, V59, P58, DOI 10.1145/2818990
   Habib K., 2014, P INT C SMART SYSTEM, P32
   김동주, 2008, [Computer and Information, 전자공학회논문지 - CI], V45, P162
   Kandgaonkar T.V., 2015, IBMRDS J MANAG RES, V4, P88, DOI [DOI 10.17697/IBMRD/2015/V4I1/60357, 10.17697/ibmrd/2015/v4i1/60357]
   Kannala J, 2012, INT C PATT RECOG, P1363
   Krizaj J, 2010, LECT NOTES COMPUT SC, V6111, P394, DOI 10.1007/978-3-642-13772-3_40
   Kumar A, 2012, PATTERN RECOGN, V45, P956, DOI 10.1016/j.patcog.2011.06.005
   Mahmoud Rasha O., 2020, International Journal of Sociotechnology and Knowledge Development, V12, P67, DOI 10.4018/IJSKD.2020010104
   Malhotra A, 2017, HUMAN RECOGNITION IN UNCONSTRAINED ENVIRONMENTS: USING COMPUTER VISION, PATTERN RECOGNITION AND MACHINE LEARNING METHODS FOR BIOMETRICS, P119, DOI 10.1016/B978-0-08-100705-1.00006-3
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Mohapatra S., 2014, INT J COMPUT APPL, V102, P6
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Olazabal O, 2019, 2019 IEEE 9TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P886, DOI 10.1109/CCWC.2019.8666599
   Paul PP, 2014, IEEE T SYST MAN CY-S, V44, P1522, DOI 10.1109/TSMC.2014.2331920
   Pflug A, 2014, P INT JOINT C BIOM, P1, DOI [10.1109/BTAS.2014.6996239, DOI 10.1109/BTAS.2014.6996239]
   Rodrigues, 2010, 2010 4 IEEE INT C BI, DOI [10.1109/BTAS.2010.5634531, DOI 10.1109/BTAS.2010.5634531]
   Rodrigues RN, 2009, J VISUAL LANG COMPUT, V20, P169, DOI 10.1016/j.jvlc.2009.01.010
   Shah D, 2016, PROCEDIA COMPUT SCI, V79, P328, DOI 10.1016/j.procs.2016.03.043
   Sitová Z, 2016, IEEE T INF FOREN SEC, V11, P877, DOI 10.1109/TIFS.2015.2506542
   Vu, 2018, P INT C SEC MAN SAM
   Vu NS, 2010, LECT NOTES COMPUT SC, V6311, P313
   Wu LB, 2020, IEEE T INF FOREN SEC, V15, P1572, DOI 10.1109/TIFS.2019.2944058
   Zhang Q, 2018, IEEE T INF FOREN SEC, V13, P2897, DOI 10.1109/TIFS.2018.2833033
   Zhang Y, 2018, IET BIOMETRICS, V7, P185, DOI 10.1049/iet-bmt.2017.0176
NR 41
TC 7
Z9 7
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 14807
EP 14827
DI 10.1007/s11042-021-10524-9
EA JAN 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000612905100001
DA 2024-07-18
ER

PT J
AU Deng, D
   Li, XW
   Menon, VG
AF Deng, Dan
   Li, Xingwang
   Menon, Varun G.
TI Learning based MIMO communications with imperfect channel state
   information for Internet of Things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Imperfect CSI; MIMO communications; Deep learning; Detection
ID MASSIVE MIMO; RELAY SELECTION; PERFORMANCE; NETWORKS; DOWNLINK; POWER;
   CSI
AB Imperfect channel state information (CSI) may seriously worsen the system performance for classical MIMO communications. In order to overcome the impacts of imperfect CSI for Internet of things, we propose a deep convolutional neural network (DCNN) based MIMO detection algorithm, where the DCNN is trained offline and works online to refine the imperfect CSI and improve the bit error rate of the wireless systems. Two types of learning based detectors, i.e., with or without accurate CSI, are proposed in this paper to reduce the detrimental effects of imperfect CSI. The impacts of the important system parameters, such as normalized Doppler frequency and the correlation factor are evaluated in different setup scenarios. Simulation results suggest that, compared with the classical maximum likelihood detector, the proposed learning based detectors shows considerable gains.
C1 [Deng, Dan] Guangzhou Panyu Polytech, Sch Informat Engn, Guangzhou 511483, Peoples R China.
   [Li, Xingwang] Henan Polytech Univ, Sch Phys & Elect Informat Engn, Jiaozuo, Henan, Peoples R China.
   [Menon, Varun G.] SCMS Sch Engn & Technol, Dept Comp Sci & Engn, Ernakulam 683576, India.
C3 Guangzhou Panyu Polytechnic; Henan Polytechnic University
RP Li, XW (corresponding author), Henan Polytech Univ, Sch Phys & Elect Informat Engn, Jiaozuo, Henan, Peoples R China.
EM dengdan@ustc.edu; lixingwang@hpu.edu.cn; varungmenon46@gmail.com
RI Menon, Varun G/G-9841-2016; Deng, Dan/F-1768-2014; Li,
   Xingwang/K-8678-2019
OI Menon, Varun G/0000-0002-3055-9900; Deng, Dan/0000-0001-7760-5663; Li,
   Xingwang/0000-0002-0907-6517
FU Natural Science Foundation of Guangdong Province [2018A030313736];
   Scientific Research Project of Education Department of Guangdong
   [2019GZDXM002]; Application Technology Collaborative Innovation Center
   of GZPYP [2020ZX01]; Yangcheng scholar, scientific research project of
   Guangzhou Education Bureau [202032761]; Project of Technology
   Development Foundation of Guangdong [706049150203]; National Natural
   Science Foundation of China [62001320]; Key Scientific Research Projects
   of Higher Education Institutions in Henan Province [20A510007]; Natural
   Science Foundation of Shaanxi Province [2020JQ-844]; Fundamental
   Research Funds for the Universities of Henan Province [NSFRF180309]; Key
   Research and Development Program of Shanxi [201903D121117]
FX This work was partly supported by Natural Science Foundation of
   Guangdong Province with grant number 2018A030313736, Scientific Research
   Project of Education Department of Guangdong with grant number
   2019GZDXM002, Application Technology Collaborative Innovation Center of
   GZPYP with grant number 2020ZX01, Yangcheng scholar, scientific research
   project of Guangzhou Education Bureau with grant number 202032761,
   Project of Technology Development Foundation of Guangdong with grant
   number 706049150203, the National Natural Science Foundation of China
   Grant 62001320, Key Scientific Research Projects of Higher Education
   Institutions in Henan Province Grant 20A510007, the Natural Science
   Foundation of Shaanxi Province under Grant 2020JQ-844, the Fundamental
   Research Funds for the Universities of Henan Province under Grant
   NSFRF180309, the Key Research and Development Program of Shanxi under
   Grant 201903D121117.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Aquilina P, 2015, IEEE T COMMUN, V63, P1259, DOI 10.1109/TCOMM.2015.2408336
   Chen C, 2018, IEEE PHOTONIC TECH L, V30, P307, DOI 10.1109/LPT.2017.2785964
   Chen JJ, 2012, IEEE COMMUN LETT, V16, P1002, DOI 10.1109/LCOMM.2012.042512.120100
   Chen ZL, 2019, IEEE T WIREL COMMUN, V18, P4060, DOI 10.1109/TWC.2019.2920823
   Deng D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061730
   Deng D, 2017, IEEE ACCESS, V5, P20220, DOI 10.1109/ACCESS.2017.2751503
   Deng D, 2016, T EMERG TELECOMMUN T, V27, P494, DOI 10.1002/ett.2985
   Fan LS, 2012, IEEE COMMUN LETT, V16, P638, DOI 10.1109/LCOMM.2012.031212.112448
   Farrokhpay S, 2021, MIN PROC EXT MET REV, V42, P473, DOI 10.1080/08827508.2020.1793140
   Feng C, 2016, IEEE SIGNAL PROC LET, V23, P366, DOI 10.1109/LSP.2015.2511630
   Gao HY, 2019, CHINA COMMUN, V16, P1, DOI 10.12676/j.cc.2019.04.001
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gradshteyn I.S., 2007, Table of Integrals, Series, and Products, V7th
   He Q, 2019, IEEE SIGNAL PROC LET, V26, P194, DOI 10.1109/LSP.2018.2880836
   Lee H, 2019, IEEE J SEL AREA COMM, V37, P2251, DOI 10.1109/JSAC.2019.2933890
   Li XW, 2020, IEEE ACCESS, V8, P13329, DOI 10.1109/ACCESS.2020.2964730
   Li XW, 2020, IEEE T WIREL COMMUN, V19, P680, DOI 10.1109/TWC.2019.2947670
   Li XW, 2020, IEEE WIREL COMMUN LE, V9, P17, DOI 10.1109/LWC.2019.2939309
   Li XW, 2020, IEEE SYST J, V14, P669, DOI 10.1109/JSYST.2019.2919654
   Li YN, 2019, IEEE NETWORK, V33, P111, DOI [10.1109/MNET.2019.1800271, 10.1109/COASE.2019.8843280, 10.1109/coase.2019.8843280]
   Liu S, 2018, CHINA COMMUN, V15, P79, DOI 10.1109/CC.2018.8543051
   Luo TJ, 2020, MULTIMED TOOLS APPL, V79, P29513, DOI 10.1007/s11042-020-09536-8
   Mao Q, 2018, IEEE COMMUN SURV TUT, V20, P2595, DOI 10.1109/COMST.2018.2846401
   Michalopoulos DS, 2012, IEEE T COMMUN, V60, P1278, DOI 10.1109/TCOMM.2012.032012.110430
   O'Shea TJ, 2016, COMM COM INF SC, V629, P213, DOI 10.1007/978-3-319-44188-7_16
   Otoum Safa, 2019, IEEE Networking Letters, V1, P68, DOI 10.1109/LNET.2019.2901792
   Pan CH, 2020, IEEE T WIREL COMMUN, V19, P5218, DOI 10.1109/TWC.2020.2990766
   Qiu S, 2018, IEEE T VEH TECHNOL, V67, P3028, DOI 10.1109/TVT.2017.2774836
   Simon M. K., 2005, DIGITAL COMMUNICATIO
   Su YH, 2019, IEEE SENS J, V19, P9561, DOI 10.1109/JSEN.2019.2925719
   VANLUONG T, 2017, IEEE COMMUN LETT, V21, P2594, DOI DOI 10.1109/LCOMM.2017.2747549
   Wang YC, 2018, IEEE WIREL COMMUN LE, V7, P990, DOI 10.1109/LWC.2018.2846571
   Ye H, 2018, IEEE WIREL COMMUN LE, V7, P114, DOI 10.1109/LWC.2017.2757490
   Zhao M, 2017, IEEE COMMUN LETT, V21, P176, DOI 10.1109/LCOMM.2016.2613934
   Zhu JK, 2018, CHINA COMMUN, V15, P1
NR 36
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 31265
EP 31276
DI 10.1007/s11042-020-10387-6
EA JAN 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000611041300005
DA 2024-07-18
ER

PT J
AU Ranjithkumar, R
   Ganeshkumar, D
   Senthamilarasu, S
AF Ranjithkumar, R.
   Ganeshkumar, D.
   Senthamilarasu, S.
TI Efficient and secure data hiding in video sequence with three layer
   security: an approach using chaos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video steganography; Information security; Chaos; Spatial domain
ID STEGANOGRAPHY; ALGORITHM; SECRET; IMAGES
AB The fast development of communication and technology has created new challenges to transfer data securely. The techniques widely used to secure the data are cryptography and steganography. This paper presents a video steganography method to secure the information to be transmitted. Information transmitted can be an image, audio, text or video. This article presents a new technique that embeds data in the spatial domain of the cover video frame. The method employs chaotic maps to generate Random Positions (RP) to hide the information bits, random numbers for selecting the frames at which the information to be hidden and confusion order to encrypt the cover frame. The video frame is first selected based on Frame Selection (FS) is encrypted by applying Confusion Order (CO) and then embedding is carried out on the random positions generated. After embedding, the decrypted cover frame is replaced in a video sequence for transmission. This method provides three-level security in extracting the hidden secret information and also 25% of embedding capacity. Experimental outcomes (PSNR and payload) confirm that the method is competent.
C1 [Ranjithkumar, R.; Senthamilarasu, S.] PA Coll Engn & Technol, Coimbatore, Tamil Nadu, India.
   [Ganeshkumar, D.] KPR Inst Engn & Technol, Coimbatore, Tamil Nadu, India.
RP Ranjithkumar, R (corresponding author), PA Coll Engn & Technol, Coimbatore, Tamil Nadu, India.
EM rranjithkumar7@gmail.com
OI R, Ranjith kumar/0000-0003-0682-2892; ,
   senthamilarasu/0000-0001-7284-3654
CR Abdulla AA, 2015, THESIS BUCKINGHAM U
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abdulla AA, 2014, PROC SPIE, V9120, DOI 10.1117/12.2050518
   Alavianmehr M. A., 2012, 2012 2nd International eConference on Computer and Knowledge Engineering (ICCKE 2012), P194, DOI 10.1109/ICCKE.2012.6395377
   [Anonymous], 2012, INT C EM TRENDS SCI, DOI DOI 10.1109/INCOSET.2012.6513904
   [Anonymous], DATASET
   Aroukatos N., 2012, Proceedings of the 2012 Ninth International Conference on Information Technology: New Generations (ITNG), P392, DOI 10.1109/ITNG.2012.96
   Battisti F., 2006, P CODEC
   Cao Y., 2015, P 3 ACM WORKSH INF H, P25, DOI DOI 10.1145/2756601.2756609
   Chang CC, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P16, DOI 10.1109/ISECS.2008.222
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Cheddad A, 2009, SIGNAL PROCESS, V89, P2324, DOI 10.1016/j.sigpro.2009.02.001
   Dey Sandipan, 2007, 2007 3rd International Symposium on Information Assurance and Security, P101
   Dey S, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL II, PROCEEDINGS, P473
   Eltahir ME, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND ENGINEERING, PROCEEDINGS, P550, DOI 10.1109/ICIME.2009.13
   Hao Bin, 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P406, DOI 10.1109/ICCSN.2011.6013622
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Islam S, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-8
   Kar N, 2018, ICT EXPRESS, V4, P6, DOI 10.1016/j.icte.2018.01.003
   Kelash HM, 2013, 2013 INTERNATIONAL CONFERENCE ON ICT CONVERGENCE (ICTC 2013): FUTURE CREATIVE CONVERGENCE TECHNOLOGIES FOR NEW ICT ECOSYSTEMS, P353, DOI 10.1109/ICTC.2013.6675372
   Kumar RR, 2019, INT CONF ADVAN COMPU, P439, DOI [10.1109/icaccs.2019.8728443, 10.1109/ICACCS.2019.8728443]
   Kumar RR, 2016, INF SECUR J, V25, P235, DOI 10.1080/19393555.2016.1248582
   kumar R. Ranjith, 2014, ICTACT J IMAGE VIDEO, V4, P795, DOI [DOI 10.21917/IJIVP.2014.0114, 10.21917/ijivp.2014.0114]
   Lin YT, 2017, IEEE T MULTIMEDIA, V19, P196, DOI 10.1109/TMM.2016.2605499
   Mstafa RJ, 2017, IEEE ACCESS, V5, P5354, DOI 10.1109/ACCESS.2017.2691581
   Niu Ke, 2013, 2013 IEEE 4th International Conference on Software Engineering and Service Science (ICSESS), P447, DOI 10.1109/ICSESS.2013.6615345
   Oliver MS., 2005, P 5 ANN INF SEC S AS
   Parah SA, 2014, COMPUT ELECTR ENG, V40, P70, DOI 10.1016/j.compeleceng.2013.11.006
   Picione DDL, 2006, P EUSIPCO
   Ramalingam M., 2011, WORLD ACAD SCI ENG T, V74, P502
   Singh Amit Kumar, 2018, Future Generation Computer Systems, V86, P926, DOI 10.1016/j.future.2016.11.023
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Zeki Akram M., 2011, Information Technology Journal, V10, P1367, DOI 10.3923/itj.2011.1367.1373
   Zhang YN, 2017, TSINGHUA SCI TECHNOL, V22, P198
NR 34
TC 5
Z9 5
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13865
EP 13878
DI 10.1007/s11042-020-10324-7
EA JAN 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000608968500001
DA 2024-07-18
ER

PT J
AU El Hanouti, I
   El Fadili, H
   Zenkouar, K
AF El Hanouti, Imad
   El Fadili, Hakim
   Zenkouar, Khalid
TI Cryptanalysis of an embedded systems' image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptanalysis; Chaotic system; Embedded systems; Chosen-plaintext
   attack; Differential attack; Sorting stability
ID 2-DIMENSIONAL CHAOTIC MAP
AB Recently, a new image encryption-scheme for embedded systems based on continuous third-order hyperbolic sine chaotic system, has been proposed. The cryptosystem's main objective was to provide a lightweight cryptographic application for use in embedded systems, especially on a UAV (unmanned aerial vehicle) program. In this paper, we scrutinized the design and structure of this cryptosystem, and we evaluated its immunity against usual attacks (e.g., chosen-plaintext attack, differential attack, known-plaintext attack). The system was proven to be weak against the differential attack with only two required chosen plain-images, and against the chosen-plaintext attack with only one 3 x 400 pixel image. A brief description of the feasibility of a known-plaintext attack was given as well. To address these vulnerabilities, some recommendations are drawn in order to be considered for enhancing the underlying scheme or for further proposals to avoid the outlined weaknesses.
C1 [El Hanouti, Imad; El Fadili, Hakim] SMBA Univ, Comp Sci & Interdisciplinary Phys Lab LIPI, Fes, Morocco.
   [Zenkouar, Khalid] SMBA Univ, Lab Intelligent Syst & Applicat LSIA, FST, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP El Hanouti, I (corresponding author), SMBA Univ, Comp Sci & Interdisciplinary Phys Lab LIPI, Fes, Morocco.
EM imad.elhanouti@usmba.ac.ma
RI Hanouti, imad El/AAV-4597-2021
OI Hanouti, imad El/0000-0001-7228-2818
CR Abbou MF., 2019, P COMP SCI
   Akmansoy V, 2014, ED SCI THEORY PRACT, DOI [10.12738/estp.2014.2.1928, DOI 10.12738/ESTP.2014.2.1928]
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Arroyo D, 2009, INT J MOD PHYS B, V23, P651, DOI 10.1142/S0217979209049966
   Auger N., 2015, MERGE STRATEGIES MER
   Bassham L, 2010, CSRC
   Bin Muhaya F, 2009, LECT NOTES COMPUT SC, V5754, P1014, DOI 10.1007/978-3-642-04070-2_107
   Broemeling LD, 2011, AM STAT, V65, P255, DOI 10.1198/tas.2011.10191
   Bussolari CJ, 2009, J COUNS DEV, V87, P98, DOI 10.1002/j.1556-6678.2009.tb00555.x
   Du M, 2018, IEEE COMMUN MAG, V56, P62, DOI 10.1109/MCOM.2018.1701148
   El Hanouti I, 2020, 2020 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING IN DATA SCIENCES (ICDS), DOI 10.1109/ICDS50568.2020.9268715
   Farajallah M, 2018, MULTIMED TOOLS APPL, V77, P28225, DOI 10.1007/s11042-018-6015-4
   Fridrich J, 1997, IEEE SYS MAN CYBERN, P1105, DOI 10.1109/ICSMC.1997.638097
   Ge X, 2011, PHYS LETT A, V375, P908, DOI 10.1016/j.physleta.2010.12.065
   Hraoui S, 2013, P IEEE ACS INT C COM, P1, DOI [10.1109/AICCSA.2013.6616441, DOI 10.1109/AICCSA.2013.6616441]
   Jolfaei A, 2016, IEEE T INF FOREN SEC, V11, P235, DOI 10.1109/TIFS.2015.2489178
   LAREW K, 1968, AM HIST REV, V74, P537, DOI 10.2307/1853680
   Li CQ, 2009, IMAGE VISION COMPUT, V27, P1035, DOI 10.1016/j.imavis.2008.09.004
   Lian SG, 2009, CHAOS SOLITON FRACT, V40, P2509, DOI 10.1016/j.chaos.2007.10.054
   Lin ZH, 2019, MULTIMED TOOLS APPL, V78, P20511, DOI 10.1007/s11042-018-6824-5
   POLITE VC, 1994, J NEGRO EDUC, V63, P588, DOI 10.2307/2967297
   Rhouma R, 2008, PHYS LETT A, V372, P5790, DOI 10.1016/j.physleta.2008.07.042
   Shakir HR, 2019, MULTIMED TOOLS APPL, V78, P26073, DOI 10.1007/s11042-019-07766-z
   Smekal D, 2018, IFAC PAPERSONLINE, V51, P312, DOI 10.1016/j.ifacol.2018.07.172
   Wu Yue, 2011, NPCR UACI RANDOMNESS
   Zeraoulia E., 2011, ROBUST CHAOS ITS APP
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P2066, DOI 10.1016/j.cnsns.2012.12.012
NR 27
TC 13
Z9 13
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13801
EP 13820
DI 10.1007/s11042-020-10289-7
EA JAN 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000608669300003
DA 2024-07-18
ER

PT J
AU Kumar, RL
   Kakarla, J
   Isunuri, BV
   Singh, M
AF Kumar, R. Lokesh
   Kakarla, Jagadeesh
   Isunuri, B. Venkateswarlu
   Singh, Munesh
TI Multi-class brain tumor classification using residual network and global
   average pooling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-class classification; Brain tumor classification; Deep learning;
   Residual network; Global average pooling
AB A rapid increase in brain tumor cases mandates researchers for the automation of brain tumor detection and diagnosis. Multi-tumor brain image classification became a contemporary research task due to the diverse characteristics of tumors. Recently, deep neural networks are commonly used for medical image classification to assist neurologists. Vanishing gradient problem and overfitting are the demerits of the deep networks. In this paper, we have proposed a deep network model that uses ResNet-50 and global average pooling to resolve the vanishing gradient and overfitting problems. To evaluate the efficiency of the proposed model simulation has been carried out using a three-tumor brain magnetic resonance image dataset consisting of 3064 images. Key performance metrics have used to analyze the performance of the proposed model and its competitive models. We have achieved a mean accuracy of 97.08% and 97.48% with data augmentation and without data augmentation, respectively. Our proposed model outperforms existing models in classification accuracy.
C1 [Kumar, R. Lokesh; Kakarla, Jagadeesh; Isunuri, B. Venkateswarlu; Singh, Munesh] IIITDM Kancheepuram, Chennai, Tamil Nadu, India.
C3 Indian Institute of Information Technology, Design & Manufacturing,
   Kancheepuram
RP Kumar, RL (corresponding author), IIITDM Kancheepuram, Chennai, Tamil Nadu, India.
EM coe16b033@iiitdm.ac.in; jagadeeshk@iiitdm.ac.in; coe19d001@iiitdm.ac.in;
   munesh.singh@iiitdm.ac.in
RI B Venkateswarlu, Isunuri/ABD-7479-2020; RAMASAMY,
   LOKESHKUMAR/G-6028-2018
OI B Venkateswarlu, Isunuri/0000-0002-7671-8831; Singh,
   Munesh/0000-0002-0699-7273
CR American Brain Tumor Association, BRAIN TUM ED
   Anaraki AK, 2019, BIOCYBERN BIOMED ENG, V39, P63, DOI 10.1016/j.bbe.2018.10.004
   Chahal PK, 2020, MULTIMED TOOLS APPL, V79, P21771, DOI 10.1007/s11042-020-08898-3
   Cheng J., 2015, brain tumor dataset
   Deepak S, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103345
   Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   Gumaei A, 2019, IEEE ACCESS, V7, P36266, DOI 10.1109/ACCESS.2019.2904145
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hemanth DJ, 2019, APPL SOFT COMPUT, V75, P21, DOI 10.1016/j.asoc.2018.10.054
   Kaur T, 2018, BIOCYBERN BIOMED ENG, V38, P409, DOI 10.1016/j.bbe.2018.02.008
   Lee JY, 2019, MULTIMED TOOLS APPL, V78, P31231, DOI 10.1007/s11042-019-07948-9
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Lu SY, 2019, J COMPUT SCI-NETH, V30, P41, DOI 10.1016/j.jocs.2018.11.008
   Mallick PK, 2019, IEEE ACCESS, V7, P46278, DOI 10.1109/ACCESS.2019.2902252
   Nayak DR, 2020, IEEE T SUST COMPUT, V5, P416, DOI 10.1109/TSUSC.2018.2883822
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Swati ZNK, 2019, COMPUT MED IMAG GRAP, V75, P34, DOI 10.1016/j.compmedimag.2019.05.001
   Xu N, 2016, PLOS ONE, V11, DOI [10.1371/journal.pone.0159623, 10.1371/journal.pone.0152463]
NR 19
TC 106
Z9 108
U1 7
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13429
EP 13438
DI 10.1007/s11042-020-10335-4
EA JAN 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607776200001
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Leng, XL
   Miao, XA
   Liu, T
AF Leng, Xue-Liang
   Miao, Xiao-Ai
   Liu, Tao
TI Using recurrent neural network structure with Enhanced Multi-Head
   Self-Attention for sentiment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural language processing (NLP); Sentiment analysis; biLSTM; biGRU;
   Self-Attention; Transformer
AB Sentiment analysis is a process of analysis, processing, induction, and reasoning of subjective text with emotional color. It is a research direction of Natural Language Processing (NLP). It is often used to extract the attitudes towards someone or something of people. That can help users find potential problems to improve or predict. As one of the main resources of online media data, film review information is often used as a dataset in the field of sentiment analysis. Researchers put forward many models in sentiment analysis to analyze the film review dataset. Accuracy, precision, recall rate, F1-scores are important standards to measure the quality of a model. To improve these criteria, a new model is proposed in this paper. The new model combines a bidirectional Long Short-Term Memory network (biLSTM) or a bidirectional Gated Recurrent Unit (biGRU) and an Enhanced Multi-Head Self-Attention mechanism. The Enhanced Multi-Head Self-Attention is a two-layer modified Transformer encoder. This modified Transformer encoder is that its masking operation and the last feedforward layer are removed. Besides, the loss function of this new model is the sum of the weighted root mean square error (RMSE) and the cross entropy loss. The operation of this sum can improve the ability of auto-encoder to reproduce. That can improve classification accuracy. The proposed model is an autoencoder classification model. In this model, biLSTM or biGRU are used as encoders and decoders at both ends of the network. Enhanced Multi-Head Self-Attention is used to encode the inter-sentence information as the middle hidden layer. A four-layer autoencoder network model is constructed to perform sentiment analysis on movie review in this paper. The movie review data sets (IMDB movie comment data set and SST-2 sentiment data set) are used in experiments. Experiment results show that the proposed model performs better in terms of accuracy, precision, recall rate, and F1-scores comparing with the baseline models. BiLSTM is better than biGRU by comparing the effect of them in the model. Finally, Bidirectional Encoder Representations from Transformers (BERT) is used in our method instead of word2vec as a pre-training structure. Compared with the baseline model based on BERT, the proposed model is better.
C1 [Leng, Xue-Liang; Miao, Xiao-Ai; Liu, Tao] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology
RP Leng, XL (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
EM lxl13110572163@163.com
CR [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], CONVOLUTIONAL NEURAL
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Cho K., 2014, ARXIV14061078
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978
   Devlin J., 2018, BERT PRE TRAINING DE
   Dos Santos C., 2014, Coling, P69
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang TL, 2016, FUNDAMENTAL RESEARCH IN STRUCTURAL ENGINEERING: RETROSPECTIVE AND PROSPECTIVE, VOLS 1 AND 2, P1650
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Kingma D. P., 2014, arXiv
   Lai SW, 2015, AAAI CONF ARTIF INTE, P2267
   Lan Zhenzhong, 2019, CoRR
   Lerner I, 2020, J BIOMED INFORM, V102, DOI 10.1016/j.jbi.2019.103356
   Liu Yinhan, 2019, ARXIV190711692
   Ma J, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4902
   Maas Andrew, 2011, P 49 ANN M ASS COMP
   Miyato T., 2016, Patenting software
   Radford A., 2019, LANGUAGE MODELS ARE
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Rehman AU, 2019, MULTIMED TOOLS APPL, V78, P26597, DOI 10.1007/s11042-019-07788-7
   Shoham Y, 2019, ABS190805646 CORR
   Shrivastava K, 2019, MULTIMED TOOLS APPL, V78, P29607, DOI 10.1007/s11042-019-07813-9
   Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Vaswani A, 2017, ADV NEUR IN, V30
   Yang Z., 2016, P 2016 C N AM CHAPT, P1480, DOI [DOI 10.18653/V1/N16-1174, 10.18653/v1/n16-1174]
   Yang ZL, 2019, ADV NEUR IN, V32
   Zhang X, 2015, ADV NEUR IN, V28
   Zhang Y, 2015, ARXIV PREPRINT ARXIV
   Zhao JQ, 2018, IEEE ACCESS, V6, P23253, DOI 10.1109/ACCESS.2017.2776930
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
NR 32
TC 10
Z9 13
U1 5
U2 55
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12581
EP 12600
DI 10.1007/s11042-020-10336-3
EA JAN 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000607369100004
DA 2024-07-18
ER

PT J
AU Long, CR
   Yang, XS
   Xu, CS
AF Long, Cuirong
   Yang, Xiaoshan
   Xu, Changsheng
TI Cross-domain personalized image captioning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personalization; Image captioning; Domain adaptation
AB Image captioning aims to translate an image to a complete and natural sentence. It involves both computer vision and natural language processing. Though image captioning has achieved good results under the rapid development of deep neural networks, excessively pursuing the evaluation results of the captioning models makes the generated text description too conservative in practical applications. It is necessary to increase the diversity of the text description and account for prior knowledge such as the user's favorite vocabularies and writing styles. In this paper, we study the personalized image captioning which can generate sentences to describe the user's own story and feelings of life with the most preferred word expression. Moreover, we propose cross-domain personalized image captioning (CDPIC) to learn domain-invariant captioning models which can be applied on different social media platforms. The proposed method can flexibly model user interest by embedding the user ID as an interest vector. To the best of our knowledge, we propose the first cross-domain personalized image captioning approach by combining the user interest modeling and a simple and effective domain-invariant constraint. The effectiveness of the proposed method is verified on datasets from the Instagram and Lookbook platforms.
C1 [Long, Cuirong; Xu, Changsheng] HeFei Univ Technol, Hefei, Peoples R China.
   [Yang, Xiaoshan; Xu, Changsheng] Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
   [Yang, Xiaoshan; Xu, Changsheng] Univ Chinese Acad Sci, Beijing, Peoples R China.
C3 Hefei University of Technology; Chinese Academy of Sciences; Institute
   of Automation, CAS; Chinese Academy of Sciences; University of Chinese
   Academy of Sciences, CAS
RP Yang, XS (corresponding author), Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.; Yang, XS (corresponding author), Univ Chinese Acad Sci, Beijing, Peoples R China.
EM 2018110906@mail.hfut.edu.cn; xiaoshan.yang@nlpr.ia.ac.cn;
   csxu@nlpr.ia.ac.cn
RI xu, cj/HJZ-3488-2023; Xu, Chang/GQP-7280-2022
CR Ajakan H., 2014, ARXIV14124446
   Anderson P, 2017, BOTTOM TOP ATTENTION
   [Anonymous], 2016, KNOWING LOOK ADAPTIV
   [Anonymous], 2011, P 4 INT C ART INT ST
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bengio S, 2015, SCHEDULED SAMPLING S, P1171
   Chen TH, 2017, IEEE I CONF COMP VIS, P521, DOI 10.1109/ICCV.2017.64
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Jiang YG, 2018, IEEE T MULTIMEDIA, V20, P3137, DOI 10.1109/TMM.2018.2823900
   Jiang YG, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3184745
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Kingma D. P., 2014, arXiv
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin WH, 2018, COMP P WEB C
   Liu X, 2014, IEEE INT C MULT EXP
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Mathews A, 2016, AAAI CONF ARTIF INTE, P3574
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Park CC, 2017, PROC CVPR IEEE, P6432, DOI 10.1109/CVPR.2017.681
   Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303
   Qian XM, 2013, NEUROCOMPUTING, V111, P144, DOI 10.1016/j.neucom.2012.12.021
   Venugopalan S, 2017, PROC CVPR IEEE, P1170, DOI 10.1109/CVPR.2017.130
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang LQ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020646
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Zhao WNX, 2011, LECT NOTES COMPUT SC, V6611, P338, DOI 10.1007/978-3-642-20161-5_34
NR 28
TC 2
Z9 2
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33333
EP 33348
DI 10.1007/s11042-019-7441-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000594855000001
DA 2024-07-18
ER

PT J
AU Jahanbakhsh-Nagadeh, Z
   Feizi-Derakhshi, MR
   Sharifi, A
AF Jahanbakhsh-Nagadeh, Zoleikha
   Feizi-Derakhshi, Mohammad-Reza
   Sharifi, Arash
TI A semi-supervised model for Persian rumor verification based on content
   information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rumor verification; BERT; Speech act; Writing style; Persian rumor
   classification; Contextual features; Neural language model; Natural
   language processing
ID SYSTEM
AB Rumor is a collective attempt to interpret a vague but attractive situation by using the power of words. In social networks, false-rumors may have significantly different contextual characteristics from true-rumors at lexical, syntactic, semantic levels. Therefore, this study presents the BERT-SAWS semi-supervised learning model for early verification of Persian rumor by investigating content-based and context features at three views: Contextual Word Embeddings (CWE), speech act, and Writing Style (WS). This model is built by loading pre-trained Bidirectional Encoder Representations from Transformers (BERT) as an unsupervised language representation, fine-tuning it using a small Persian rumor dataset, and combining with a supervised learning model to provide an enriched text representation of the content of the rumor. This text representation enables the model to have a better comprehending of the rumor language to verify rumors better than baseline models for two reasons: (i) early rumor verification by focusing on content-based and context-based features of the source rumor. (ii) overcoming the problem of the shortcoming of the dataset in deep neural networks by loading pre-trained BERT, fine-tuning it using the Persian rumor dataset, and combining with speech act and WS-based features. The empirical results of applying the model on Twitter and Telegram datasets demonstrated that BERT-SAWS can enhance the performance of the classifier from 2% to 18%. It indicates that speech act and WS alongside semantic contextual vectors are helpful features in the rumor verification task.
C1 [Jahanbakhsh-Nagadeh, Zoleikha; Sharifi, Arash] Islamic Azad Univ, Sci & Res Branch, Dept Comp Engn, Tehran, Iran.
   [Feizi-Derakhshi, Mohammad-Reza] Univ Tabriz, Dept Comp Engn, ComInSys Lab, Tabriz, Iran.
C3 Islamic Azad University; University of Tabriz
RP Feizi-Derakhshi, MR (corresponding author), Univ Tabriz, Dept Comp Engn, ComInSys Lab, Tabriz, Iran.
EM mfeizi@tabrizu.ac.ir
RI Sharifi, Arash/AAU-2023-2021; Feizi Derakhshi, Mohammad
   Reza/AAK-1687-2020; Jahanbakhsh-Nagadeh, Zoleikha/AAT-3862-2021
OI Feizi Derakhshi, Mohammad Reza/0000-0002-8548-976X; Jahanbakhsh-Nagadeh,
   Zoleikha/0000-0002-9269-7858
CR Abualigah L. M. Q., 2019, Feature selection and enhanced krill herd algorithm for text document clustering, DOI [DOI 10.1007/978-3-030-10674-4, 10.1007/978-3-030-10674-4]
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   Afrooz GA, 2011, RAVANSHENASY SHAYEE
   Ahmed H, 2018, SECUR PRIVACY, V1, DOI 10.1002/spy2.9
   Alomari E, 2020, EAI SPRINGER INNOVAT, P37, DOI 10.1007/978-3-030-13705-2_2
   [Anonymous], 2012, CHIAYI CHRIST HOSP J
   [Anonymous], 1947, The Psychology of Rumor
   Arts M, 2008, AUTOMATIC DETECTION
   Bijad A., 2018, RAVANSHENASI E SHAYE
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Castillo C., 2011, P 20 INT C WORLD WID, P675, DOI DOI 10.1145/1963405.1963500
   Chen T, 2018, EL PACKAG TECH CONF, P401, DOI 10.1109/EPTC.2018.8654442
   Chen YB, 2017, IEEE IND ELEC, P465, DOI 10.1109/IECON.2017.8216082
   Chua Alton Y. K., 2016, International Multiconference of Engineers and Computer Scientists 2016 (IMECS). Proceedings, P387
   Devlin J, 2018, 41714186 NAACLHLT
   Geng Y, 2019, LECT NOTES COMPUT SC, V11536, P339, DOI 10.1007/978-3-030-22734-0_25
   Grifoni P, 2020, INT J COMPUT INT SYS, V13, P178, DOI 10.2991/ijcis.d.200208.001
   Guo H, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P943, DOI 10.1145/3269206.3271709
   Hamidian Sardar., 2016, Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, P3, DOI [10. 18653/v1/W16-0403, DOI 10.18653/V1/W16-0403]
   Homayounpour M, 2010, SPEECH ACTS CLASSIFI
   Jahanbakhsh-Nagadeh Z, 2020, J SOFT COMPUT INF TE, V9
   Jahanbakhsh-Nagadeh Z, 2020, ARXIV200207563
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Kashefi O, 2010, SUPREME COUNC INF CO
   Kim Y, 2014, IEEE ASME INT C ADV, P1747, DOI 10.1109/AIM.2014.6878336
   Kumar A, 2019, MULTIMED TOOLS APPL, V78, P24083, DOI 10.1007/s11042-019-7398-6
   Kumar S, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3767
   Kwon S, 2013, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2013.61
   Li LZ, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P755, DOI 10.1109/ICIVC.2018.8492819
   Lin DZ, 2015, INT CONF ASIAN LANG, P107, DOI 10.1109/IALP.2015.7451543
   Liu Y, 2018, AAAI CONF ARTIF INTE, P117
   Ma B, 2017, ADV INTELL SYST, V513, P245, DOI 10.1007/978-3-319-46562-3_16
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Mahmoodabad SD, 2018, 2018 9TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P597, DOI 10.1109/ISTEL.2018.8661007
   Minaee S., 2020, Deep learning based text classification: A comprehensive review
   Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x
   Morovati V, 2019, PROCEEDINGS OF THE ASME INTERNATIONAL MECHANICAL ENGINEERING CONGRESS AND EXPOSITION, 2018, VOL 9
   Poddar L, 2018, PROC INT C TOOLS ART, P65, DOI 10.1109/ICTAI.2018.00021
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Qazvinian V., 2011, RUMOR HAS IT IDENTIF
   Searle JohnR., 1979, EXPRESSION MEANING S
   Shamsfard M., 2009, 3 WORKSH COMP APPR A, P859
   Shu ML, 2017, IEEE INT CONF COMMUN, P1
   Singhal S, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P39, DOI [10.1109/BigMM.2019.00-44, 10.1109/BigMM.2019.00018]
   Undeutsch, 1967, HDB PSYCHOL, V11, P26
   Volkova S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P647, DOI 10.18653/v1/P17-2102
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wen H, 2019, AAAI CONF ARTIF INTE, P338
   Wingert T., 2020, SAE INT J ELECTR VEH, DOI [10.4271/2020-01-1210, DOI 10.4271/2020-01-1210]
   Wu K, 2015, PROC INT CONF DATA, P651, DOI 10.1109/ICDE.2015.7113322
   Xiangbo Shu, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P114, DOI 10.1007/978-3-319-27671-7_10
   Yu F, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3901
   Zamani S, 2017, IRAN CONF ELECTR ENG, P1532, DOI 10.1109/IranianCEE.2017.7985287
   Zarharan M., 2019, TTO
   Zhao Z, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1395, DOI 10.1145/2736277.2741637
   Zhenhuang Yong, 2018, 2018 2nd IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC). Proceedings, P1380, DOI 10.1109/IMCEC.2018.8469468
   Zhou KM, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1614
   Zhou L, 2004, GROUP DECIS NEGOT, V13, P81, DOI 10.1023/B:GRUP.0000011944.62889.6f
   Zubiaga A., 2017, P INT C SOCIAL INFOR, P109, DOI [10.1007/978-3-319-67217-5_8SeriesTitle:LectureNotesinComputerScience, DOI 10.1007/978-3-319-67217-5_8SERIESTITLE:LECTURENOTESINCOMPUTERSCIENCE, 10.1007/978-3-319-67217-58]
   Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603
NR 60
TC 11
Z9 11
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35267
EP 35295
DI 10.1007/s11042-020-10077-3
EA NOV 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000591138700002
DA 2024-07-18
ER

PT J
AU Park, HS
   Lee, GA
   Seo, BK
   Billinghurst, M
AF Park, Hye Sun
   Lee, Gun A.
   Seo, Byung-Kuk
   Billinghurst, Mark
TI User experience design for a smart-mirror-based personalized training
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User experience (UX) design; Personalized training system; Mirror
   visualization; User centered interaction; UX design guideline; Smart
   mirror
AB This paper describes the user experience (UX) design for a smart-mirror-based personalized training system which aims to help people live a healthy life. A number of researchers and companies have developed fitness systems that use a virtual coach which shows the user with actions they should perform. However such systems can be difficult to accurately follow the virtual guide's motions and there are also limitations in the feedback provided to inform users of their correct body posture. This is because most systems are designed for users to simply watch and follow a character's motions (poses) from a third person perspective. In our smart mirror-based system, users are able to follow the exercise-postures of a virtual professional trainer shown in a first person viewpoint and receive coaching through a real-time motion correction. This is based on a predefined database of the trainer's postures gained from motion-capture technology, and it is personalized to the user's body 3D model acquired through an instant one-time scanning process. In this paper, we report on the UX design of our system, mainly focusing on understandable visualization, intuitive interaction, attractive information representation and easily acceptable user scenarios. Through a series of user studies, we analyze and discuss user friendliness, information comprehension, and user satisfaction as they relate to our design. In addition, we also assess the similarity and effectiveness of the proposed system compared to traditional personalized training (PT) at a gym. Based on the implications, we discuss future research directions for improving the user experience of the smart-mirror-based PT system.
C1 [Park, Hye Sun; Seo, Byung-Kuk] Elect & Telecommun Res Inst, Daejeon, South Korea.
   [Lee, Gun A.; Billinghurst, Mark] Univ South Australia, Adelaide, SA, Australia.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   University of South Australia
RP Park, HS (corresponding author), Elect & Telecommun Res Inst, Daejeon, South Korea.
EM hspark78@etri.re.kr; gun.lee@unisa.edu.au; byungkuk.seo@etri.re.kr;
   mark.billinghurst@unisa.edu.au
RI Billinghurst, Mark/AAJ-4236-2020; Lee, Gun/AAS-9903-2021
OI Billinghurst, Mark/0000-0003-4172-6759; Lee, Gun/0000-0002-1644-6934
FU Institute of Information & Communications Technology Planning &
   Evaluation (IITP) - Korea government (MSIT) [15501-14-1016,
   2017-0-01849]
FX This work was supported by Institute of Information & Communications
   Technology Planning & Evaluation (IITP) grant funded by the Korea
   government (MSIT) (No.15501-14-1016, Instant 3D object based Join & Joy
   content technology supporting simultaneous participation of users in
   remote places and enabling realistic experience and No.2017-0-01849,
   Development of Core Technology for Real-Time Image Composition in
   Unstructured In-outdoor Environment). We thank all those who helped
   setting up and running the user study. Special thanks should be given to
   Dr. Ho Won Kim, Dr. Kyu Sung Jo, Dr. Tae Joon Kim and Mrs. Ki Nam Kim
   for support of 3D motion tracking and 3D modeling generation.
CR Albert W., 2013, Measuring the User Experience
   Anderson F., 2013, P 26 ANN ACM S US IN, P311, DOI [DOI 10.1145/2501988.2502045, 10.1145/2501988.2502045]
   [Anonymous], 2008, NINTENDO WII FIT
   [Anonymous], 2013, KINECT WINDOWS RETAI
   [Anonymous], 2018, CBS This Morning
   [Anonymous], 2012, NIKE TRAINING
   [Anonymous], 2007, INTERFACE DESIGN RUL
   Beck M, 2018, J RETAIL CONSUM SERV, V40, P279, DOI 10.1016/j.jretconser.2016.08.006
   Besserer D., 2016, P WORKSH MULT AN EN, P48, DOI DOI 10.1145/3011263.3011265
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Colantonio S, 2015, BIOSYST ENG, V138, P33, DOI 10.1016/j.biosystemseng.2015.06.008
   Ehara Jun, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P139, DOI 10.1109/ISMAR.2006.297805
   Eisert P., 2008, 2008 IEEE C COMPUTER, P1
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Kaiser E., 2003, ICMI 03, P12
   Kang H, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI [10.1145/3359996.3364256, 10.1109/IVEC.2019.8744769]
   Kurtenbach G, 1990, GESTURES HUMAN COMPU, P309
   Lee G. A., 2015, CHI EA 15 P 33 ANN A, P959
   Lee M, 2013, VIRTUAL REAL-LONDON, V17, P293, DOI 10.1007/s10055-013-0230-0
   Marquardt Z., 2012, CHI'12 Extended Abstracts on Human Factors in Computing Systems, P1619
   Miotto R, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0068-7
   Mottura S, 2007, FUTURE OF PRODUCT DEVELOPMENT, P441, DOI 10.1007/978-3-540-69820-3_43
   Ng K, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P339
   PerfectGym, 2018, IOT TRENDS WILL THEY
   PhysioRoom, 2018, CAN POOR POSTURE MAK
   Piumsomboon T, 2014, INT SYM MIX AUGMENT, P73, DOI 10.1109/ISMAR.2014.6948411
   Piumsomboon T, 2013, LECT NOTES COMPUT SC, V8118, P282
   PlayStation, 2010, PLAYSTATION MOVE
   Poh Ming-Zher., 2011, ACM SIGGRAPH 2011 Emerging Technologies, P2, DOI [DOI 10.1145/2048259.2048261, 10.1145/2048259.2048261]
   Poupyrev I., 1996, P 9 ANN ACM S USER I, P79, DOI [DOI 10.1145/237091.237102, 10.1145/237091.237102]
   Saakes D, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P6058, DOI 10.1145/2858036.2858282
   Thompson WR, 2016, ACSMS HEALTH FIT J, V20, P8, DOI 10.1249/FIT.0000000000000252
   Tonal, 2018, INTELLIGENT HOME GYM
   Trajkova Milka, 2015, Design, User Experience and Usability: Users and Interactions. 4th International Conference, DUXU 2015, held as part of HCI International 2015. Proceedings LNCS 9187, P464, DOI 10.1007/978-3-319-20898-5_45
   Vera L, 2011, LECT NOTES COMPUT SC, V6949, P483, DOI 10.1007/978-3-642-23768-3_63
   Webb Jarrett., 2012, Beginning Kinect Programming with the Microsoft Kinect SDK
   Wobbrock J.O., 2005, P CHI 05 HUM FACT CO, P1869, DOI [DOI 10.1145/1056808.1057043, 10.1145/1056808.1057043]
   Wobbrock JO, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1083
   Yong BB, 2018, J PARALLEL DISTR COM, V118, P14, DOI 10.1016/j.jpdc.2017.05.006
NR 39
TC 9
Z9 9
U1 4
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 31159
EP 31181
DI 10.1007/s11042-020-10148-5
EA NOV 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000590232700006
DA 2024-07-18
ER

PT J
AU Ashiba, HI
   Ashiba, MI
AF Ashiba, H. I.
   Ashiba, M. I.
TI Super-efficient enhancement algorithm for infrared night vision imaging
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IR images; Night vision; Gamma correction; CLAHE; HM; PHE; AWT;
   Homomorphic enhancement
ID FUSION
AB This paper presents new three proposed approaches for enhancement of Infrared (IR) night vision images. The first approach is based on merging gamma correction with the Histogram Matching (HM). The second approach depends on hybrid gamma correction with Contrast Limited Adaptive Histogram Equalization (CLAHE). The third approach is based on a trilateral enhancement that the IR images pass through three stages: segmentation, enhancement and sharpening. In the first stage, the IR image is divided into segments based on Optimum Global Thresholding (OTSU) method. The second stage, which is the heart of the enhancement approach, depends on Additive Wavelet Transform (AWT) to decompose the image into an approximation and details. Homomorphic enhancement is performed on the detail components, while Plateau Histogram Equalization (PHE) is performed on the approximation plane. Then, the image is reconstructed and subjected to a post-processing high pass filter. Average gradient, Sobel edge magnitude, entropy and spectral entropy has been used as quality metrics for assessment the three proposed approaches. It is clear that the third proposed approach gives superior results to the two proposed approaches point view the quality metrics. On the other hand, clear that the third proposed approach takes long computation time in the implementation with respect to the two proposed approaches. The first proposed approach gives better results to the two proposed approaches from the computation time perspective.
C1 [Ashiba, H. I.; Ashiba, M. I.] Bilbis Higher Inst Engn, Dept Elect & Elect Commun Engn, Bilbis, Sharqia, Egypt.
RP Ashiba, HI (corresponding author), Bilbis Higher Inst Engn, Dept Elect & Elect Commun Engn, Bilbis, Sharqia, Egypt.
EM eng_h_2006@yahoo.com
RI ashiba, huda/GQI-4310-2022
OI ashiba, huda/0000-0002-4926-8919
CR Affonso AA, 2018, PATTERN RECOGN LETT, V102, P50, DOI 10.1016/j.patrec.2017.12.015
   Alirezanejad M., 2014, INDIAN J SCI TECHNOL, V7, P517, DOI 10.17485/ijst/2014/v7i4.12
   Ashiba HI, 2019, MULTIMED TOOLS APPL, V78, P11277, DOI 10.1007/s11042-018-6545-9
   Ashiba HI, 2018, WIRELESS PERS COMMUN, V99, P619, DOI 10.1007/s11277-017-4958-9
   Ashiba MI, 2020, MULTIMED TOOLS APPL, V79, P6085, DOI 10.1007/s11042-019-7510-y
   Ashiba MI, 2019, MULTIMED TOOLS APPL, V78, P27771, DOI 10.1007/s11042-018-7086-y
   Bai XZ, 2017, INFRARED PHYS TECHN, V80, P44, DOI 10.1016/j.infrared.2016.11.011
   Cai HY, 2019, INFRARED PHYS TECHN, V98, P201, DOI 10.1016/j.infrared.2019.03.013
   Chen YZ, 2017, OPTIK, V144, P240, DOI 10.1016/j.ijleo.2017.05.079
   Deepa S, 2013, J AUTOMATION ARTIFIC, V1
   Gade R, 2014, MACH VISION APPL, V25, P245, DOI 10.1007/s00138-013-0570-5
   Gundogdu E, 2015, IEEE COMPUT SOC CONF
   Höglund J, 2019, VISION RES, V158, P109, DOI 10.1016/j.visres.2019.02.005
   Jung J, 2006, 2006 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, VOLS 1-6, PROCEEDINGS, P277, DOI 10.1109/ISIT.2006.261849
   Kong XY, 2019, INFRARED PHYS TECHN, V98, P161, DOI 10.1016/j.infrared.2019.03.008
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Qi W, 2016, INFRARED PHYS TECHN, V76, P684, DOI 10.1016/j.infrared.2016.04.038
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Torabi A, 2012, COMPUT VIS IMAGE UND, V116, P210, DOI 10.1016/j.cviu.2011.10.006
   Wang J, 2014, INFRARED PHYS TECHN, V67, P477, DOI 10.1016/j.infrared.2014.09.019
   Wu Z, THERMAL INFRARED VID
   Yang B., 2010, INFRARED PHYS TECHNO, V15, P6, DOI [10.1007/s12204-010-7186-y, DOI 10.1016/j.infrared.2017.01.012]
   Zhang SQ, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10080304
   Zhu P, 2017, INFRARED PHYS TECHN, V81, P282, DOI 10.1016/j.infrared.2017.01.013
NR 24
TC 5
Z9 7
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9721
EP 9747
DI 10.1007/s11042-020-09928-w
EA NOV 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000589699900004
DA 2024-07-18
ER

PT J
AU Ashiba, HI
AF Ashiba, H. I.
TI A proposed framework for diagnosis and breast cancer detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mammogram; Object detection; The BC; Pre-processing; AT; OT; HE;
   Segmentation; FE and classification
ID ENHANCEMENT; DENSITY; SEGMENTATION; IMAGES
AB This paper aims to early Breast Cancer (BC) detection by Mammography (MG) established on the production of excellent images and competent interpretation. This paper proposes two algorithms for Object Detection and Diagnosis (ODD) the BC. The first proposal is relied on merging the features of A Trous Algorithm (AT) with Homomorphic Processing (HP)Using Contrast Limited Histogram Equalization (AHUC) following by Segmentation and Feature Extraction (FE) for Classification (ASFC). The ASFC depends on enhancement using AHUC in addition to pre-processing followed by segmentation using Optimum Global Thresholding (OT) and finally FE for the detection or classification task. The second scheme is based segmentation after Hybrid structure HE and Fuzzy model (HEF) and finally FE for Classification (HEFC) The HEFC depends on improvement using HEF and pre-processing followed by segmentation using OT and finally FE for classification task. The performance quality metrics for the suggested techniques are entropy, average gradient, contrast, Sobel edge magnitude, homogeneity, sensitivity, specificity, precision and accuracy.Simulation results prove that the success of both techniques in detecting the BC objects. By comparing the first and the second presented algorithms, it is clear that the second suggested technique gives superior for the ODD the BC.
C1 [Ashiba, H. I.] Bilbis Higher Inst Engn, Dept Elect & Elect Commun, Bilbis, Sharqia, Egypt.
RP Ashiba, HI (corresponding author), Bilbis Higher Inst Engn, Dept Elect & Elect Commun, Bilbis, Sharqia, Egypt.
EM eng_h_2006@yahoo.com
RI ashiba, huda/GQI-4310-2022
OI ashiba, huda/0000-0002-4926-8919
CR Amato Flora, 2018, International Journal of High Performance Computing and Networking, V12, P391
   Ashiba HI, 2020, MULTIMED TOOLS APPL, V79, P2543, DOI 10.1007/s11042-019-08154-3
   Ashiba HI, 2019, MULTIMED TOOLS APPL, V78, P11277, DOI 10.1007/s11042-018-6545-9
   Ashiba HI, 2018, WIRELESS PERS COMMUN, V99, P619, DOI 10.1007/s11277-017-4958-9
   Ashiba H. I., 2008, Progress In Electromagnetics Research C, V1, P123, DOI 10.2528/PIERC08012301
   Aswathy MA, 2020, PROCEDIA COMPUT SCI, V167, P666, DOI 10.1016/j.procs.2020.03.333
   Dorgham O, 2018, INT J CLOUD APPL COM, V8, P154, DOI 10.4018/IJCAC.2018010108
   Ehsaeyan E, 2016, IRAN J ELECT ELECT E, V12
   George M, 2016, PROCEDIA COMPUT SCI, V90, P163, DOI 10.1016/j.procs.2016.07.020
   Ghoneim A, 2018, IEEE COMMUN MAG, V56, P33, DOI 10.1109/MCOM.2018.1700817
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Kim MY, 2014, CLIN IMAG, V38, P255, DOI 10.1016/j.clinimag.2013.05.010
   Koo HR, 2013, EUR J RADIOL, V82, P1738, DOI 10.1016/j.ejrad.2013.05.016
   Lather M, 2020, PROCEDIA COMPUT SCI, V167, P121, DOI 10.1016/j.procs.2020.03.189
   Lim J.S., 1990, Two-dimensional Signal and Image Processing
   Miller BC, 2019, SOC SCI MED, V239, DOI 10.1016/j.socscimed.2019.112494
   Mohideen K, 2011, INT ARAB J E TECHNOL, V2
   Murakami R, 2020, EUR J RADIOL OPEN, V7, DOI 10.1016/j.ejro.2019.12.001
   PAWAR MM, 2018, J KING SAUD U COMP I
   Peifang Guo, 2018, International Journal of Software Science and Computational Intelligence, V10, P36, DOI 10.4018/IJSSCI.2018040103
   Petrou M, 1999, IMAGE PROCESSING FUN, P355
   Raj SD, 2018, SEMIN ULTRASOUND CT, V39, P16, DOI 10.1053/j.sult.2017.08.001
   SECHOPOULOS I, 2020, SEMIN CANC BIOL
   Ursin G., 2009, Norsk Epidemiologi, V19, P59
   Vincent O., 2009, A descriptive algorithm for sobel image edge detection
   ZHANG SQ, 2018, SYMMETRY BASEL, V10
   Zhuqing J, 2011, THESIS
NR 28
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9333
EP 9369
DI 10.1007/s11042-020-10131-0
EA NOV 2020
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000588276000003
DA 2024-07-18
ER

PT J
AU Wang, SX
   Ge, HW
   Yang, JL
   Tong, YB
AF Wang, Shuangxi
   Ge, Hongwei
   Yang, Jinlong
   Tong, Yubing
TI Relaxed group low rank regression model for multi-class classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Group low-rank representation; Label relaxation; Image classification;
   Graph embedding
ID LEAST-SQUARES REGRESSION; FACE RECOGNITION; ALGORITHM
AB Least squares regression is an effective multi-classification method; however, in practical applications, many models based on the least squares regression method are significantly affected by noise (and outliers). Therefore, effectively reducing the adverse effects of noise is conducive to obtaining a better classification performance. Besides, preserving the intrinsic characteristics of samples to the greatest extent possible is beneficial for improving the discriminative ability of the model. Based on this analysis, we propose the relaxed group low-rank regression model for multi-class classification. The model effectively captures the hidden structural information of samples by exploiting the group low-rank constraint. Meanwhile, with the group low-rank constraint and the graph embedding constraint, the proposed method has more tolerance to noise (and outliers). The feature matrix with the L-21-norm and the graph embedding constraint complement each other to capture the intrinsic characteristics of the samples. In addition, a sparsity error term with the L-21 norm is utilized to relax the strict target label matrix. These factors guarantee that the original samples are converted into a more compact and discriminative characteristic space. Finally, we compare the proposed model with various popular algorithms on several benchmark datasets. The experimental results demonstrate that the performance of the proposed method outperforms those of state-of-the-art methods.
C1 [Wang, Shuangxi; Ge, Hongwei; Yang, Jinlong] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Jiangsu, Peoples R China.
   [Wang, Shuangxi; Ge, Hongwei; Yang, Jinlong] Jiangnan Univ, Minist Educ, Key Lab Adv Proc Control Light Ind, Wuxi 214122, Jiangsu, Peoples R China.
   [Tong, Yubing] Univ Penn, Dept Radiol, Med Image Proc Grp, Philadelphia, PA 19104 USA.
C3 Jiangnan University; Jiangnan University; University of Pennsylvania
RP Ge, HW (corresponding author), Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Jiangsu, Peoples R China.; Ge, HW (corresponding author), Jiangnan Univ, Minist Educ, Key Lab Adv Proc Control Light Ind, Wuxi 214122, Jiangsu, Peoples R China.
EM ghw8601@163.com
RI sun, jiamin/JPY-2155-2023; liu, peiyao/KFT-1810-2024
FU Graduate Innovation Foundation of Jiangsu Province [KYLX16_0781];
   Natural Science Foundation of Jiangsu Province [BK20181340]; 111 Project
   [B12018]; PAPD of Jiangsu Higher Education Institutions
FX This paper is supported by the Graduate Innovation Foundation of Jiangsu
   Province under Grant No. KYLX16_0781, the Natural Science Foundation of
   Jiangsu Province under Grants No. BK20181340, the 111 Project under
   Grants No. B12018, and PAPD of Jiangsu Higher Education Institutions.
CR Asgharian L, 2020, MULTIMED TOOLS APPL, V79, P29595, DOI 10.1007/s11042-020-09395-3
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Cai X, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P1124
   Chang KW, 2008, J MACH LEARN RES, V9, P1369
   Chen YB, 2020, J CONTEMP CHINA, V29, P1, DOI [10.1080/10670564.2019.1621526, 10.1080/01932691.2020.1791172, 10.1007/s12652-020-02066-z]
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   He X., 2003, ADV NEURAL INFORM PR, P153
   Hosmer DW, 2013, WILEY SER PROBAB ST, P89
   Li YF, 2013, IEEE ACM T COMPUT BI, V10, P447, DOI 10.1109/TCBB.2013.30
   Lin Z.C., 2010, 100920105055 ARXIV, V1009, P5055, DOI [DOI 10.1016/J.JSB.2012.10.010, 10.1016/j.jsb.2012.10.010]
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Nene S. A., 1996, Tech. Rep. CUCS-005-96
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Nie FP, 2012, PATTERN RECOGN LETT, V33, P485, DOI 10.1016/j.patrec.2011.11.028
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang LF, 2018, IEEE T NEUR NET LEAR, V29, P1352, DOI 10.1109/TNNLS.2017.2651169
   Wei L, 2018, NEURAL PROCESS LETT, V48, P1671, DOI 10.1007/s11063-018-9783-y
   Wen J, 2018, NEURAL NETWORKS, V102, P36, DOI 10.1016/j.neunet.2018.02.002
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xiang G, 2012, NEW TECHNOLOGIES OF RAILWAY ENGINEERING, P480
   Xiang SM, 2012, IEEE T NEUR NET LEAR, V23, P1738, DOI 10.1109/TNNLS.2012.2212721
   Xu Y, 2016, IEEE T IMAGE PROCESS, V25, P850, DOI 10.1109/TIP.2015.2510498
   Xu Y, 2014, NEUROCOMPUTING, V135, P253, DOI 10.1016/j.neucom.2013.11.025
   Yuan HL, 2018, INFORM SCIENCES, V429, P247, DOI 10.1016/j.ins.2017.11.020
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang XY, 2015, IEEE T NEUR NET LEAR, V26, P2206, DOI 10.1109/TNNLS.2014.2371492
   Zhang Z, 2017, IEEE T IMAGE PROCESS, V26, P1466, DOI 10.1109/TIP.2017.2651396
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
   Zhao HF, 2016, NEUROCOMPUTING, V216, P200, DOI 10.1016/j.neucom.2016.07.037
   Zheng W, 2014, SIGNAL PROCESS LETT, P1, DOI [10.1109/LSP.2014.2308954, DOI 10.1109/LSP.2014.2308954.1-1]
NR 36
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9459
EP 9477
DI 10.1007/s11042-020-10080-8
EA NOV 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000588276000001
DA 2024-07-18
ER

PT J
AU Singh, J
   Goyal, G
AF Singh, Jaiteg
   Goyal, Gaurav
TI Decoding depressive disorder using computer vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depressive disorder; Attention Deficit Hyperactivity Disorder;
   Convolutional Neural Network; DSM-V; Facial emotion recognition; Dlib-ML
ID WEB-BASED INFORMATION; PATTERN-CLASSIFICATION; MENTAL-HEALTH; FACIAL
   EXPRESSIONS; SOCIAL COGNITION; MACHINE; ANXIETY; PRESCHOOLERS;
   BIOMARKERS; DISEASE
AB This paper intends to decode depressive disorder using computer vision. Facial expressions rendered by a depressive and non-depressive person were studied against a given stimulus. A survey was conducted using Attention Deficit Hyperactivity Disorder (ADHD) questionnaire on a group of four hundred one volunteers between age group of nineteen to twenty-three years. A total of 254 male and 147 female volunteers participated in survey. Three hundred and eighty-seven responses were actually received and seventy-two respondents were identified as potential patients of depressive disorder. Amongst these anticipated depressive patients, thirty-eight were called for a personal assessment/ interview by practicing psychologists as per DSM-V standards. Data collected from these respondents were used to train a Convolutional Neural Network model, so as to classify a person as depressed or not depressed. The proposed system attained a precision of 74 in the identification of depressive patients. This study concludes to the fact that facial expressions rendered by a patient suffering from the depressive disorder are different from that of non-depressive person against any given psychological stimulus. Further, it was also concluded that facial expressions rendered by a respondent against any annotated quality stimulus like ADFES dataset could provide results comparable to that of ADHD questionnaire. The outcome of this research intends to facilitate doctors to identify potential depressive patients and make an early diagnosis.
C1 [Singh, Jaiteg; Goyal, Gaurav] Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
C3 Chitkara University, Punjab
RP Singh, J (corresponding author), Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
EM jaitegkhaira@gmail.com
RI Khaira, Jaiteg Singh/AFD-9547-2022; University, Chitkara/AAZ-3040-2021
OI University, Chitkara/0000-0003-3776-7136; Singh,
   Jaiteg/0000-0002-2370-9384
CR Adorni R, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00456
   Alghowinem S, 2019, 2015 11 IEEE INT C W, P1
   Alghowinem S, 2013, IEEE IMAGE PROC, P4220, DOI 10.1109/ICIP.2013.6738869
   [Anonymous], 2019, IMAGE VIS COMPUT, V32, P648
   [Anonymous], 2019, UNDERSTANDING FACIAL, DOI DOI 10.1007/978-81-322-1934-7_10
   [Anonymous], P 3 ACM INT WORKSH A, P1
   [Anonymous], 1976, Pictures of facial affect
   [Anonymous], CLIN PRACT EPIDEMOL
   [Anonymous], 2019, PLOS ONE, V11, pe0155885
   [Anonymous], 2019, J MULTIMODAL USER IN, V9, P17
   [Anonymous], IMAGE VIS COMPUT, V32, P641
   APA, 2013, DIAGNOSTIC STAT MANU, V5th ed.
   Arbabshirani MR, 2017, NEUROIMAGE, V145, P137, DOI 10.1016/j.neuroimage.2016.02.079
   Bennett K, 2010, J MED INTERNET RES, V12, DOI 10.2196/jmir.1468
   Bittner A, 2007, J CHILD PSYCHOL PSYC, V48, P1174, DOI 10.1111/j.1469-7610.2007.01812.x
   Bohannon J, 2015, SCIENCE, V349, P250, DOI 10.1126/science.349.6245.250
   Bufferd SJ, 2011, COMPR PSYCHIAT, V52, P359, DOI 10.1016/j.comppsych.2010.08.006
   Carcione A, 2008, PSYCHOTHER RES, V18, P667, DOI 10.1080/10503300802220132
   Chandrashekar P, 2019, MHEALTH, V4
   Chiarugi F, 2014, P INT C HLTH INF SCI, P555
   Cohn J.F, 2010, P 2 INT WORKSH SOC S, P1
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   CORYELL W, 1993, AM J PSYCHIAT, V150, P720
   Craske MG, 2016, LANCET, V388, P3048, DOI 10.1016/S0140-6736(16)30381-6
   Csernansky JG, 2004, AM J PSYCHIAT, V161, P896, DOI 10.1176/appi.ajp.161.5.896
   Cummins N, 2015, SPEECH COMMUN, V71, P10, DOI 10.1016/j.specom.2015.03.004
   Davatzikos C, 2008, NEUROBIOL AGING, V29, P514, DOI 10.1016/j.neurobiolaging.2006.11.010
   De La Torre F, 2009, P 2009 3 INT C AFF C, P1, DOI 10.1109/ACII.2009.5349358
   Egger HL, 2006, J CHILD PSYCHOL PSYC, V47, P313, DOI 10.1111/j.1469-7610.2006.01618.x
   Eichstaedt JC, 2015, PSYCHOL SCI, V26, P159, DOI 10.1177/0956797614557867
   Ekman P., 2002, FACIAL ACTION CODING
   Ellgring H., 2007, NON VERBAL COMMUNICA
   Ellgring H, 2008, NON VERBAL COMMUNICA
   Epstein J, 2001, COMPUT HUM BEHAV, V17, P295, DOI 10.1016/S0747-5632(01)00004-8
   Firth J, 2017, WORLD PSYCHIATRY, V16, P287, DOI 10.1002/wps.20472
   Fiske S.T., 1991, SOCIAL COGNITION
   Fu CHY, 2008, BIOL PSYCHIAT, V63, P656, DOI 10.1016/j.biopsych.2007.08.020
   Ghosh S, 2014, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2013, VOL 3B
   Girard JM, 2013, IEEE INT CONF AUTOMA
   Gould MS, 1998, J AM ACAD CHILD PSY, V37, P915, DOI 10.1097/00004583-199809000-00011
   Gratch J., 2014, DISTRESS ANAL INTERV
   Griffiths KM, 2000, BMJ-BRIT MED J, V321, P1511, DOI 10.1136/bmj.321.7275.1511
   Guntuku SC, 2017, CURR OPIN BEHAV SCI, V18, P43, DOI 10.1016/j.cobeha.2017.07.005
   Gupta A, 2014, 2014 INTERNATIONAL CONFERENCE ON POWER, AUTOMATION AND COMMUNICATION (INPAC), P33, DOI 10.1109/INPAC.2014.6981131
   Hess U, 2000, J NONVERBAL BEHAV, V24, P265, DOI 10.1023/A:1006623213355
   Hess U, 2005, COGNITION EMOTION, V19, P515, DOI 10.1080/02699930441000364
   Hirschfeld RMA, 2003, J CLIN PSYCHIAT, V64, P161, DOI 10.4088/JCP.v64n0209
   Hirschfeld RMA, 2000, J CLIN PSYCHIAT, V61, P268, DOI 10.4088/JCP.v61n0405
   Hosseinifard B, 2013, COMPUT METH PROG BIO, V109, P339, DOI 10.1016/j.cmpb.2012.10.008
   Jans M, 2019, ENTERP INF SYST-UK, V13, P601, DOI 10.1080/17517575.2019.1587788
   Jones NP, 2015, COGN AFFECT BEHAV NE, V15, P263, DOI 10.3758/s13415-014-0323-6
   Judd LL, 2000, ARCH GEN PSYCHIAT, V57, P375, DOI 10.1001/archpsyc.57.4.375
   Kambeitz J, 2017, BIOL PSYCHIAT, V82, P330, DOI 10.1016/j.biopsych.2016.10.028
   Khazaal Y, 2008, DEPRESS ANXIETY, V25, P461, DOI 10.1002/da.20381
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Klöppel S, 2008, BRAIN, V131, P2969, DOI 10.1093/brain/awn239
   Knutson B, 1996, J NONVERBAL BEHAV, V20, P165, DOI 10.1007/BF02281954
   Kosinski M, 2013, P NATL ACAD SCI USA, V110, P5802, DOI 10.1073/pnas.1218772110
   Koutsouleris N, 2015, BRAIN, V138, P2059, DOI 10.1093/brain/awv111
   Kudinova AY, 2019, PUPILLARY REACTIVITY
   Ladegaard N, 2014, PSYCHIAT RES, V220, P883, DOI 10.1016/j.psychres.2014.10.005
   Ladegaard N, 2014, PSYCHIAT RES, V216, P37, DOI 10.1016/j.psychres.2013.12.010
   Lavagnino L, 2015, PSYCHOL MED, V45, P2805, DOI 10.1017/S0033291715000768
   Li M, 2016, J INT MED RES, V44, P1072, DOI 10.1177/0300060516662134
   Lindefors N., 2016, Guided internet-based treatments in psychiatry
   Luby JL, 2009, J AFFECT DISORDERS, V112, P111, DOI 10.1016/j.jad.2008.03.026
   Lucas GM, 2015, INT CONF AFFECT, P539, DOI 10.1109/ACII.2015.7344622
   Lueken U, 2015, J AFFECT DISORDERS, V184, P182, DOI 10.1016/j.jad.2015.05.052
   Marquand AF, 2016, BIOL PSYCHIAT, V80, P552, DOI 10.1016/j.biopsych.2015.12.023
   Matsumoto D., 2008, Scholarpedia, V3, P4237, DOI DOI 10.4249/SCHOLARPEDIA.4237
   McIntyre G, 2011, FACIAL RESPONSE VIDE
   McIntyre G.J, 2010, COMPUTER ANAL FACIAL
   Mehrabian A., 1974, APPROACH ENV PSYCHOL, V12
   Mohr DC, 2017, ANNU REV CLIN PSYCHO, V13, P23, DOI 10.1146/annurev-clinpsy-032816-044949
   Morency LP, 2015, AAAI CONF ARTIF INTE, P4307
   Nielssen O, 2015, BMC PSYCHIATRY, V15, DOI 10.1186/s12888-015-0676-6
   Orrù G, 2012, NEUROSCI BIOBEHAV R, V36, P1140, DOI 10.1016/j.neubiorev.2012.01.004
   Pampouchidou A, 2019, IEEE T AFFECT COMPUT, V10, P445, DOI 10.1109/TAFFC.2017.2724035
   Park G, 2015, J PERS SOC PSYCHOL, V108, P934, DOI 10.1037/pspp0000020
   Pediaditis M, 2015, IEEE ENG MED BIO, P3711, DOI 10.1109/EMBC.2015.7319199
   Redlich R, 2014, JAMA PSYCHIAT, V71, P1222, DOI 10.1001/jamapsychiatry.2014.1100
   RUSSELL JA, 1985, J PERS SOC PSYCHOL, V48, P1290, DOI 10.1037/0022-3514.48.5.1290
   Saragih JM, 2009, IEEE I CONF COMP VIS, P1034, DOI 10.1109/ICCV.2009.5459377
   Scherer S, 2013, IEEE INT CONF AUTOMA
   Scherer S, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P135, DOI 10.1145/2522848.2522886
   Siegle GJ, 2011, BIOL PSYCHIAT, V69, P726, DOI 10.1016/j.biopsych.2010.12.041
   Silk JS, 2007, AM J PSYCHIAT, V164, P1873, DOI 10.1176/appi.ajp.2007.06111816
   Stratou G, 2013, INT CONF AFFECT, P147, DOI 10.1109/ACII.2013.31
   Suto T, 2004, BIOL PSYCHIAT, V55, P501, DOI 10.1016/j.biopsych.2003.09.008
   Valstar M, 2019, AVEC 2016 DEPR MOOD
   van der Schalk J, 2011, EMOTION, V11, P907, DOI 10.1037/a0023853
   Visser RM, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00222
   Vlaescu George, 2016, Internet Interv, V6, P107, DOI 10.1016/j.invent.2016.09.006
   Wang JK, 2014, INT J ENV RES PUB HE, V11, P2236, DOI 10.3390/ijerph110202236
   Wang QX, 2018, J VIS COMMUN IMAGE R, V57, P228, DOI 10.1016/j.jvcir.2018.11.003
   Wang Y, 2018, J PERS SOC PSYCHOL, V114, P246, DOI 10.1037/pspa0000098
   WATSON D, 1988, J ABNORM PSYCHOL, V97, P346, DOI 10.1037/0021-843X.97.3.346
   WAXER PH, 1974, J CLIN PSYCHOL, V30, P215, DOI 10.1002/1097-4679(197404)30:2<215::AID-JCLP2270300229>3.0.CO;2-Q
   Whalen DJ, 2017, CHILD ADOL PSYCH CL, V26, P503, DOI 10.1016/j.chc.2017.02.006
   Whelan R, 2014, BIOL PSYCHIAT, V75, P746, DOI 10.1016/j.biopsych.2013.05.014
   Williamson J.R, 2014, 2014 ACM INT WORKSH, P65
   Winograd-Gurvich C, 2006, J AFFECT DISORDERS, V93, P193, DOI 10.1016/j.jad.2006.03.018
   Winograd-Gurvich C, 2006, NEUROSCI RES, V56, P253, DOI 10.1016/j.neures.2006.07.003
   Wittchen H.-U., 2000, Eur. Neuropsychopharmacol, V10, P119, DOI [10.1016/S0924-977X(00)80014-0, DOI 10.1016/S0924-977X(00)80014-0]
   World Health Organization, 2017, Information Note-Novel Point-of-Care Tools for Early Infant Diagnosis of HIV, P1
   Wu YY, 2015, P NATL ACAD SCI USA, V112, P1036, DOI 10.1073/pnas.1418680112
   Yaden DB, 2018, SOC PSYCHOL PERS SCI, V9, P444, DOI 10.1177/1948550617711228
   Yang TH, 2017, J AMB INTEL HUM COMP, V8, P895, DOI 10.1007/s12652-016-0395-y
   Yu Z., 2013, MULTIMODAL PREDICTIO
   Zhou D, 2015, P 29 AAAI C ART INT
NR 110
TC 12
Z9 13
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8189
EP 8212
DI 10.1007/s11042-020-10128-9
EA OCT 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587057900002
DA 2024-07-18
ER

PT J
AU Kaur, S
   Bansal, S
   Bansal, RK
AF Kaur, Sumeet
   Bansal, Savina
   Bansal, Rakesh Kumar
TI Image steganography for securing secret data using hybrid hiding model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Encryption; Decryption; Whitefloor Square Attack;
   Mid-frequency; RS Steganalysis
ID ALGORITHM; TRANSMISSION; DOMAIN; ROBUST
AB Image steganography is the process of concealing the confidential message in digital images. The purpose of this research is to secure the transmission of an image from attackers. This research introduced an innovative Image Hiding Encryption and Decryption (IHED) for encrypting and decrypting images. Moreover, the encoding process is performed on the Mid-frequency (MF) values are identified by a novel Mid Search African Buffalo Model (MSABM). The efficiency of the proposed model is validated by applying some attacks such as a novel White Floor Square Attack (WFSA), RS steganalysis, Chi-square attack, and visual attack. Furthermore, the proposed methodology showed that the embedded image has high Peak Signal to Noise Ratio (PSNR), embedding rate, Structural Similarity Index Metric (SSIM) and reduced Mean Square Error (MSE). Finally, the proposed strategy is compared with existing approaches and achieved better results by increasing the security of embedded secrets in the steganography system.
C1 [Kaur, Sumeet] IK Gujral Punjab Tech Univ, Dept Comp Sci & Engn, Jalandhar Kapurthala Highway, Kapurthala 144603, Punjab, India.
   [Bansal, Savina; Bansal, Rakesh Kumar] Maharaja Ranjit Singh Punjab Tech Univ, Dept Elect & Commun Engn, Dabwali Rd, Bathinda 151001, Punjab, India.
C3 I. K. Gujral Punjab Technical University
RP Kaur, S (corresponding author), IK Gujral Punjab Tech Univ, Dept Comp Sci & Engn, Jalandhar Kapurthala Highway, Kapurthala 144603, Punjab, India.
EM purbasumeet@yahoo.co.in
RI Bansal, Savina/B-7082-2017; Bansal, Rakesh Kumar/AAM-2187-2021
OI Bansal, Savina/0000-0001-7483-1841; 
CR Abd El-Latif AA, 2020, PHYSICA A, V541, DOI 10.1016/j.physa.2019.123687
   Abd El-Latif AA, 2019, OPT LASER TECHNOL, V116, P92, DOI 10.1016/j.optlastec.2019.03.005
   Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abdulla AA, 2014, PROC SPIE, V9120, DOI 10.1117/12.2050518
   Agarwal P, 2020, ADV INTELL SYST COMP, V1056, P155, DOI 10.1007/978-981-15-0199-9_14
   Al-Nofaie SMA, 2020, MULTIMED TOOLS APPL, V79, P19, DOI 10.1007/s11042-019-08025-x
   [Anonymous], 2019, 2019 INT C ADV COMM
   Artiemjew P, 2020, COMPUTERS, V9, DOI 10.3390/computers9020038
   Arunkumar S, 2019, MEASUREMENT, V139, P426, DOI 10.1016/j.measurement.2019.02.069
   Biswas R, 2019, MULTIMED TOOLS APPL, V78, P20019, DOI 10.1007/s11042-019-7369-y
   Carpentieri B, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5322
   Chatterjee Ayan, 2020, Computational Intelligence in Pattern Recognition. Proceedings of CIPR 2019. Advances in Intelligent Systems and Computing (AISC 999), P897, DOI 10.1007/978-981-13-9042-5_77
   Chaumont M., 2020, Digital Media Steganography, P321, DOI [DOI 10.1016/B978-0-12-819438-6.00022-0, 10.1016/B978-0-12-819438-6.00022-0]
   Dalal M, 2019, MULTIMED TOOLS APPL, V78, P5769, DOI 10.1007/s11042-018-6093-3
   Duan XT, 2019, IEEE ACCESS, V7, P9314, DOI 10.1109/ACCESS.2019.2891247
   Fakhredanesh M, 2019, MULTIMED TOOLS APPL, V78, P18475, DOI 10.1007/s11042-019-7238-8
   Gutub A, 2020, MULTIMED TOOLS APPL, V79, P7951, DOI 10.1007/s11042-019-08427-x
   Kadhim IJ, 2020, COGN SYST RES, V60, P20, DOI 10.1016/j.cogsys.2019.11.002
   Kaur R, 2021, MULTIDIM SYST SIGN P, V32, P1, DOI 10.1007/s11045-020-00725-0
   Kini NG, 2019, STUD COMPUT INTELL, V771, P539, DOI 10.1007/978-981-10-8797-4_54
   Li Y, 2020, MULTIMED TOOLS APPL, V79, P9665, DOI 10.1007/s11042-017-5557-1
   Liu WT, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107287
   Mansour RF, 2019, MULTIDIM SYST SIGN P, V30, P791, DOI 10.1007/s11045-018-0575-3
   Mohammad AA, 2019, MULTIMED TOOLS APPL, V78, P7181, DOI 10.1007/s11042-018-6465-8
   Mohsin AH, 2019, IEEE ACCESS, V7, P168994, DOI 10.1109/ACCESS.2019.2949622
   Odili J. B., 2020, 2020 INT C MATH COMP, P1
   Pandey HM, 2020, FUTURE GENER COMP SY, V111, P213, DOI 10.1016/j.future.2020.04.034
   Patil AS, 2020, TECHNO-SOCIETAL 2018: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SOCIETAL APPLICATIONS - VOL 1, P95, DOI 10.1007/978-3-030-16848-3_10
   Qu ZG, 2019, MULTIMED TOOLS APPL, V78, P7981, DOI 10.1007/s11042-018-6476-5
   Rathor M, 2020, IEEE T CONSUM ELECTR, V66, P251, DOI 10.1109/TCE.2020.3006050
   Sahu AK, 2019, SENS IMAGING, V21, DOI 10.1007/s11220-019-0262-y
   Subhedar MS, 2020, MULTIMED TOOLS APPL, V79, P1865, DOI 10.1007/s11042-019-08221-9
   Taburet T, 2021, IEEE T INF FOREN SEC, V16, P173, DOI 10.1109/TIFS.2020.3007354
   Tang WX, 2019, IEEE T INF FOREN SEC, V14, P2074, DOI 10.1109/TIFS.2019.2891237
   Valandar MY, 2019, MULTIMED TOOLS APPL, V78, P9971, DOI 10.1007/s11042-018-6584-2
   Wang P, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107422
   Zhao CJ, 2020, IEEE ACCESS, V8, P73947, DOI 10.1109/ACCESS.2020.2987865
NR 38
TC 5
Z9 5
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7749
EP 7769
DI 10.1007/s11042-020-09939-7
EA OCT 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000587058000012
DA 2024-07-18
ER

PT J
AU Hughes, CJ
   Montagud, M
AF Hughes, Chris J.
   Montagud, Mario
TI Accessibility in 360° video players
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 360(o) video; Accessibility; Audio description; Immersive video; Sign
   language; Subtitling
AB Accessibility is a key requirement for any multimedia tool and application. With the current trend towards immersive experiences, such as Virtual Reality (VR) and 360(o) video, it becomes key that these environments are adapted to be fully accessible. However, until recently the focus has been mostly on adapting the existing techniques to fit immersive displays, rather than considering new approaches for accessibility designed specifically for these increasingly relevant media experiences. This paper surveys a wide range of 360(o) video players and examines the features they include for dealing with accessibility, such as Subtitles, Audio Description, Sign Language, User Interfaces and other interaction features, like voice control and support for multi-screen scenarios. These features have been chosen based on guidelines from standardization contributions, like in the World Wide Web Consortium (W3C) and the International Communication Union (ITU), and from research contributions for making 360 degrees video consumption experiences accessible. The in-depth analysis has been part of a research effort towards the development of a fully inclusive and accessible 360 degrees video player. The paper concludes by discussing how the newly developed player has gone above and beyond the existing solutions and guidelines, by providing accessibility features that meet the expectations for a widely used immersive medium, like 360 degrees video.
C1 [Hughes, Chris J.] Univ Salford, Sch Sci Engn & Environm, Salford, Lancs, England.
   [Montagud, Mario] i2CAT Fdn, Barcelona, Spain.
   [Montagud, Mario] Univ Valencia, Valencia, Spain.
C3 University of Salford; Internet I Innovacio Digital A Catalunya (I2CAT);
   University of Valencia
RP Hughes, CJ (corresponding author), Univ Salford, Sch Sci Engn & Environm, Salford, Lancs, England.
EM c.j.hughes@salford.ac.uk; mario.montagud@i2cat.net
OI Hughes, Chris/0000-0002-4468-6660
FU European Union's Horizon 2020 program [761974]; Spanish Ministry of
   Science, Innovation and Universities [IJCI-2017-34611,
   RED2018-102475-T]; H2020 - Industrial Leadership [761974] Funding
   Source: H2020 - Industrial Leadership
FX This work has been partially funded by the European Union's Horizon 2020
   program, under agreement no 761974 (ImAc project). Work by Mario
   Montagud has been additionally funded by the Spanish Ministry of
   Science, Innovation and Universities with a Juan de la Cierva -
   Incorporacion grant (with reference IJCI-2017-34611) and with the ALMA
   Excellence Network (with reference RED2018-102475-T).
CR Agullo B, 2020, SUBTITLES VIRTUAL RE
   Agullo B, 2019, J SPEC TRANSL, P32
   Agulló B, 2019, AI EDAM, V33, P416, DOI 10.1017/S0890060419000362
   [Anonymous], WEB CONT ACC GUID WC
   [Anonymous], JWPLAYER VOIC
   Brown A, 2017, NAT CLIM CHANGE, V7, P8, DOI 10.1038/nclimate3194
   Caro RB, 2019, HERMENEUS, P53, DOI 10.24197/her.21.2019.53-74
   European Broadcasting Union (EBU), 2017, VIRT REAL AR PUBL BR
   European Commission, 2018, 079 EUR COMM
   Fan CL, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3329119
   Fidyka A, 2018, TRANSL SPACES, V7, P285, DOI 10.1075/ts.18018.fid
   Hughes C, 2019, D3 1 ARCHITECTURAL D
   Hughes CJ, 2019, TVX 2019: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P216, DOI 10.1145/3317697.3325123
   Hybrid Broadcast Broadband TV (HbbTV), 2018, 2 0 2 SPEC HBBTV ASS
   International Communication Union (ITU), 2011, MAK TEL ACC
   Matamala A., 2019, D2 1 USER CTR DESIGN
   Matamala A., 2020, D5 4 PILOT EVALUATIO
   Matamala A., 2018, Journal of Audiovisual Translation, V1, P139, DOI DOI 10.47476/JAT.V1I1.49
   Mies R, 2019, D3 4 ACCESSIBILITY I, DOI [10.5281/zenodo.3413288, DOI 10.5281/ZEN0D0.3413288]
   Montagud M, 2020, ITU J ICT DISCOVERIE
   Montagud M, 2020, ACM IMX 2020 BARC SP
   Montagud M, 2016, CUSTOMIZABLE MULTIDE, V605
   Montagud M, 2019, ACM TVX 2019 JUN MAN
   Montagud M, 2020, MULTIMED TOOLS APPL, V79, P21889, DOI 10.1007/s11042-020-08955-x
   Montagud M, 2020, PERS UBIQUIT COMPUT, V24, P887, DOI 10.1007/s00779-019-01357-3
   Oncins E., 2020, MONTI J
   Orero P, 2020, TRANSLATION STUDIES
   Papachristos NM, 2017, IEEE INT CONF ADV LE, P477, DOI 10.1109/ICALT.2017.145
   Powers S, 2011, HTML5 MEDIA INTEGRAT, P82
   Srivastava P, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00050
   ttho Pesch P, 2020, ARXIV200503756CSMM
   Video Description Research and Development Center, 2013, YOUDESCRIBE, V1, P2
   W3C, 2020, WEBVTT WEB VID TEXT
   World Wide Web Consortium (W3C), 2010, TIM TEXT MARK LANG T
   Xu M, 2020, IEEE J-STSP, V14, P5, DOI 10.1109/JSTSP.2020.2966864
NR 35
TC 10
Z9 10
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30993
EP 31020
DI 10.1007/s11042-020-10088-0
EA OCT 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000581569800003
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Sarkar, K
   Halder, TK
   Mandal, A
AF Sarkar, Kanishka
   Halder, Tanmoy Kanti
   Mandal, Ardhendu
TI Adaptive power-law and cdf based geometric transformation for low
   contrast image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Geometric transformation based enhancement; Image enhancement; Low
   contrast image; Power-law transformation
ID GAMMA CORRECTION
AB Image enhancement is a technique that manipulates an image to make it more meaningful and effective to user specific problem. In most of the enhancement techniques, input image intensities are transformed into either higher order or lower order intensities according to the designed algorithmic characteristic. But, in certain cases the input intensities might require to be transformed in a balanced combination of both higher and lower order intensity. Moreover, 2D Geometric Transformation is mainly used to transform the objects presents in an image. Here a contemplative fusion of gamma and 2D Geometric Transformation concept has been used for intensity transformation. The proposed method first divides the histogram into three sub-sections according to the homogeneity value representing the dark, gray and bright section of histogram. Then each sub-section is transformed locally using adaptive gamma and 2D Geometric scaling transformation. These transformed sub-sections are merged again by employing 2D translation operation. On the other hand, a global gamma transformation is obtained for entire histogram. At last, the final transformation matrix is obtained by combining previously computed local and global transformation. The comparison of this technique with other state of art technique has been discussed to depict the significance of the proposed method. The proposed method gives a new and innovative dimension of image enhancement.
C1 [Sarkar, Kanishka] Ananda Chandra Coll, Jalpaiguri 735101, W Bengal, India.
   [Halder, Tanmoy Kanti] Prasannadeb Womens Coll, Jalpaiguri 735101, W Bengal, India.
   [Mandal, Ardhendu] Univ North Bengal, Darjeeling 734014, W Bengal, India.
C3 University of North Bengal
RP Sarkar, K (corresponding author), Ananda Chandra Coll, Jalpaiguri 735101, W Bengal, India.
EM kanishka.acc.cs@gmail.com; tanmoy.zx@gmail.com; am.csa.nbu@nbu.ac.in
RI Halder, Tanmoy/JWP-1028-2024; Mandal, Ardhendu/F-5184-2017
OI Sarkar, Kanishka/0000-0001-9695-894X; Mandal,
   Ardhendu/0000-0002-4685-7283
CR Poblete CA, 2018, REV LLENG DRET, P119, DOI 10.2436/rld.i69.2018.3051
   [Anonymous], 2017, CONTRAST ENHANCEMENT
   [Anonymous], 2016, EURASIP J IMAGE VIDE
   [Anonymous], 2009, MACH VIS APPL
   Cao G, 2018, COMPUT ELECTR ENG, V66, P569, DOI 10.1016/j.compeleceng.2017.09.012
   Chen Y, 2013, ROCK MECH ROCK ENG, P1, DOI DOI 10.1186/1741-7007-11-121
   Chen YT, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02066-z
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Cheng HD, 2012, 2012 19 IEEE INT C I, DOI [10.1109/icip.2012.6467021, DOI 10.1109/ICIP.2012.6467021.IEEE]
   HEARN BAKER, 1997, COMPUTER GRAPHICS C
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Huang ZH, 2018, INFRARED PHYS TECHN, V94, P38, DOI 10.1016/j.infrared.2018.08.019
   Huang ZH, 2016, INFRARED PHYS TECHN, V79, P205, DOI 10.1016/j.infrared.2016.11.001
   Hussain Khalid, 2018, IPSJ Transactions on Computer Vision and Applications, V10, DOI 10.1186/s41074-018-0040-0
   Jain AK, 2015, FUNDAMENTALS DIGITAL, P233
   Kaiser PK, 2017, JOY VISUAL PERCEPTIO
   Kallel F, 2018, SIGNAL IMAGE VIDEO P, V12, P905, DOI 10.1007/s11760-017-1232-2
   Kallel F, 2017, IEEE T NANOBIOSCI, V16, P666, DOI 10.1109/TNB.2017.2771350
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Mandal A, 2018, INT J MODERN ELECTRO, V6, P35
   Perry D, 2012, INTRO IMAGE PROCESSI
   Reddy ME, 2022, P NATL A SCI INDIA A, V92, P77, DOI 10.1007/s40010-020-00670-4
   Sahnoun M, 2020, SIGNAL IMAGE VIDEO P, V14, P377, DOI 10.1007/s11760-019-01561-x
   Sinecen M., 2016, Applications from Engineering with MATLAB Concepts chapter, V1
   Sonka M., 1993, Image Processing, Analysis and Machine Vision, P56, DOI [DOI 10.1007/978-1-4899-3216-7_4, 10.1007/978-1-4899-3216-7_4]
   Veluchamy M, 2019, OPTIK, V183, P329, DOI 10.1016/j.ijleo.2019.02.054
   Vimal SP, 2012, SADHANA-ACAD P ENG S, V37, P739, DOI 10.1007/s12046-012-0110-4
NR 28
TC 6
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6329
EP 6353
DI 10.1007/s11042-020-10004-6
EA OCT 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577869200002
DA 2024-07-18
ER

PT J
AU Dalal, M
   Juneja, M
AF Dalal, Mukesh
   Juneja, Mamta
TI Steganography and Steganalysis (in digital forensics): a Cybersecurity
   guide
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cybersecurity; Digital forensics; Steganography; Steganalysis; Tools
ID IMAGE STEGANOGRAPHY; VIDEO STEGANOGRAPHY; H.264/AVC VIDEO; QUANTITATIVE
   STEGANALYSIS; GENETIC ALGORITHM; LSB STEGANOGRAPHY; HIGH-CAPACITY;
   SCHEME; SECURE; DOMAIN
AB Steganography and steganalysis is a relatively new-fangled scientific discipline in security systems and digital forensics, respectively, but one that has matured greatly over the past two decades. In any specialism of human endeavour, it is imperative to periodically pause and review the state of the discipline for what has been achieved till date. This article scrutinizes where the discipline of steganography and steganalysis at this point in time in context to the common user and new researchers in terms of current trends. Also, what has been accomplished in order to critically examine what has been done well and what ought to be done better. The state-of-the-art techniques for steganography and steganalysis (image and video) have been deliberated for the last 5 years literature. Further, the paper also takes stock the dataset and tools available for multimedia steganography and steganalysis with the examples where steganography has been used in real-life. It is a corpus of the author's opinion and the viewpoints of different other researchers and practitioners, working in this discipline. Additionally, experiments were done using image steganography techniques to analyse the recent trends. This survey is intended to provide a complete guide for common people and new researchers and scholars approaching this field, sight on the existing and the future of steganography and steganalysis.
C1 [Dalal, Mukesh; Juneja, Mamta] Panjab Univ, UIET, Chandigarh, India.
C3 Panjab University
RP Dalal, M (corresponding author), Panjab Univ, UIET, Chandigarh, India.
EM mukeshdalal05@gmail.com; mamtajuneja@pu.ac.in
OI Juneja, Mamta/0000-0002-2611-9005
FU Technical Education Quality Improvement Project III (TEQIP III) of MHRD,
   Government of India [P154523]
FX This research work is supported by Technical Education Quality
   Improvement Project III (TEQIP III) of MHRD, Government of India
   assisted by World Bank under Grant Number P154523 and sanctioned to
   UIET, Panjab University, Chandigarh (India).
CR AACH T, 1993, SIGNAL PROCESS, V31, P165, DOI 10.1016/0165-1684(93)90063-G
   Abdolmohammadi M., 2019, Proceedings of the 2019 Mediterranean Conference on Pattern Recognition and Artificial Intelligence, P149, DOI [10.1007/978-3-030-37548-512, DOI 10.1007/978-3-030-37548-512]
   Abu-El-Haija Sami, 2016, arXiv
   Al-Dmour H, 2016, EXPERT SYST APPL, V46, P293, DOI 10.1016/j.eswa.2015.10.024
   Alam S, 2017, ADV INTELL SYST, V516, P467, DOI 10.1007/978-981-10-3156-4_48
   Aly HA, 2011, IEEE T INF FOREN SEC, V6, P14, DOI 10.1109/TIFS.2010.2090520
   [Anonymous], 2015, DIABETES CARE, V38, pS1, DOI 10.2337/dc15-S001
   [Anonymous], 2016, INT J IMAGE PROCESS
   [Anonymous], 2017, LECT NOTES NETWORKS, DOI DOI 10.1007/978-981-10-3818-1_19
   [Anonymous], 2018, SURVEILLANCE ACTION
   [Anonymous], 2010, RUSSIAN SPY RING HID
   [Anonymous], 2018, P EUR C COMP VIS ECC
   [Anonymous], 2000, Digital Watermarking
   Asikuzzaman M, 2018, IEEE T CIRC SYST VID, V28, P2131, DOI 10.1109/TCSVT.2017.2712162
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Attaby AA, 2018, AIN SHAMS ENG J, V9, P1965, DOI 10.1016/j.asej.2017.02.003
   Babaguchi N, 2013, IEEE T INF FOREN SEC, V8, P1559, DOI 10.1109/TIFS.2013.2279945
   Bagnall RJ, 2002, SANS INF SECUR READ, V19
   Balasubramanian C, 2014, MULTIMED TOOLS APPL, V73, P2223, DOI 10.1007/s11042-013-1640-4
   Balu S, 2019, CLUSTER COMPUT, V22, pS4057, DOI 10.1007/s10586-018-2639-4
   Bancroft FC, 2001, DNA BASED STEGANOGRA
   Banik BG, 2017, ADV INTELL SYST, V458, P623, DOI 10.1007/978-981-10-2035-3_63
   Barni M, 2010, INT CONF ACOUST SPEE, P1690, DOI 10.1109/ICASSP.2010.5495494
   Beebe N, 2009, IFIP ADV INF COMM TE, V306, P17
   Bin Li, 2018, IEEE Signal Processing Letters, V25, P650, DOI 10.1109/LSP.2018.2816569
   Cao G, 2008, INT CONF SIGN PROCES, P1187
   Cao Y, 2015, IEEE COMMUN LETT, V19, P203, DOI 10.1109/LCOMM.2014.2387160
   Chaeikar SS, 2018, MULTIMED TOOLS APPL, V77, P805, DOI 10.1007/s11042-016-4273-6
   CHAKKA S, 2020, MED TEACH 0424
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P7973, DOI 10.1007/s11042-016-3449-4
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen M., 2018, Electron. Imaging, V2018, P160
   Chen SY, 2018, INT J THEOR PHYS, V57, P3689, DOI 10.1007/s10773-018-3882-4
   Chutani S, 2019, MULTIMED TOOLS APPL, V78, P18169, DOI 10.1007/s11042-019-7217-0
   Chutani S, 2018, MULTIMED TOOLS APPL, V77, P7447, DOI 10.1007/s11042-017-4656-3
   Dadgostar H, 2016, J INF SECUR APPL, V30, P94, DOI 10.1016/j.jisa.2016.07.001
   Dalal Mukesh, 2018, Proceedings of the International Conference on Computing and Communication Systems. I3CS 2016. Lecture Notes in Networks and Systems (LNNS 24), P705, DOI 10.1007/978-981-10-6890-4_67
   Dalal M., 2018, International Journal of Computer Sciences and Engineering Open Access H . 264 / AVC Video Steganography Techniques: An Overview, DOI [DOI 10.26438/IJCSE/V6I5.297303, 10.26438/ijcse/v6i5.297303]
   Dalal M, 2020, INF SECUR J, V29, P40, DOI 10.1080/19393555.2020.1714822
   Dalal M, 2019, MULTIMED TOOLS APPL, V78, P5769, DOI 10.1007/s11042-018-6093-3
   Dalal M, 2018, INT J ELECTRON SECUR, V10, P338
   Divya V, 2016, PROCEEDINGS OF 2016 ONLINE INTERNATIONAL CONFERENCE ON GREEN ENGINEERING AND TECHNOLOGIES (IC-GET)
   Dogan S, 2016, ARTIF INTELL REV, V46, P129, DOI 10.1007/s10462-016-9459-9
   Duan XT, 2020, IEEE ACCESS, V8, P25777, DOI 10.1109/ACCESS.2020.2971528
   Duan XT, 2019, IEEE ACCESS, V7, P9314, DOI 10.1109/ACCESS.2019.2891247
   Ellleithy, 2015, NE  SECT C AM SOC EN
   Fan LY, 2019, MOBILE NETW APPL, V24, P1269, DOI 10.1007/s11036-018-1167-z
   Fan MQ, 2016, TELECOMMUN SYST, V63, P523, DOI 10.1007/s11235-016-0139-5
   Feng Pan, 2010, 2010 IEEE International Conference on Software Engineering and Service Sciences (ICSESS 2010), P592, DOI 10.1109/ICSESS.2010.5552283
   Filler T, 2011, PROC SPIE, V7880, DOI 10.1117/12.872192
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gallagher S., 2012, Steganography: How Al-Qaeda Hid Secret Documents in a Porn Video
   Giboulot Quentin, 2018, MEDIA WATERMARKING S, DOI [10.2352/ ISSN. 2470- 1173.2018.07. MWSF-318, DOI 10.2352/ISSN.2470-1173.2018.07.MWSF-318]
   Goljan M, 2015, PROC SPIE, V9409, DOI 10.1117/12.2078399
   Grajeda-Marín IR, 2016, LECT NOTES COMPUT SC, V9703, P125, DOI 10.1007/978-3-319-39393-3_13
   Guo LJ, 2014, IEEE T INF FOREN SEC, V9, P814, DOI 10.1109/TIFS.2014.2312817
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He YL, 2012, AEU-INT J ELECTRON C, V66, P305, DOI 10.1016/j.aeue.2011.08.007
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Hosam O, 2016, SECUR COMMUN NETW, V9, P5036, DOI 10.1002/sec.1676
   Hussain M., 2018, SIGNAL PROCESS IMAGE
   Hussain M, 2016, SYMMETRY-BASEL, V8, DOI 10.3390/sym8060041
   Huu QP, 2019, 8 GLOB C CONS EL GCC, P1
   Idbeaa T, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150732
   Jain Anil., 2002, P 3 WORKSHOP AUTOMAT, P97
   Jamil T., 1999, IEEE Potentials, V18, P10, DOI 10.1109/45.747237
   Jan B, 2019, COMPUT ELECTR ENG, V75, P275, DOI 10.1016/j.compeleceng.2017.12.009
   Johnson N.F., 2001, Information Hiding: Steganography and Watermarking-Attacks and Countermeasures: Steganography and Watermarking: Attacks and Countermeasures, V1
   Kadhim IJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107481
   Kadhim IJ, 2020, COGN SYST RES, V60, P20, DOI 10.1016/j.cogsys.2019.11.002
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Kadhim IJ, 2017, LECT NOTES COMPUT SC, V10362, P569, DOI 10.1007/978-3-319-63312-1_50
   Kalita M, 2016, 2016 INT C SYST SIGN, P1, DOI DOI 10.1109/IWS-SIP.2016.7502756
   Kang YH, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719852031
   Khan H, 2011, COMPUT SECUR, V30, P35, DOI 10.1016/j.cose.2010.10.005
   Khan S., 2018, Int J Electric Comput Eng (IJECE), V8, P379, DOI [10.11591/ijece.v8i1.pp379-389, DOI 10.11591/IJECE.V8I1.PP379-389]
   Khodaei M, 2016, CYBERNET SYST, V47, P617, DOI 10.1080/01969722.2016.1214459
   Kim J, 2020, MULTIMED TOOLS APPL, V79, P1355, DOI 10.1007/s11042-019-08251-3
   Kolakalur Anush, 2016, International Journal of Engineering and Technology, V8, P165, DOI 10.7763/IJET.2016.V8.878
   Konyar MZ, 2020, SIGNAL IMAGE VIDEO P, V14, P897, DOI 10.1007/s11760-019-01621-2
   Koptyra K, 2019, SOFT COMPUT, V23, P4357, DOI 10.1007/s00500-018-3089-x
   Kumar P, 2018, MULTIMED TOOLS APPL, V77, P24247, DOI 10.1007/s11042-018-5709-y
   Kumar V, 2018, MULTIMED TOOLS APPL, V77, P13279, DOI 10.1007/s11042-017-4947-8
   Kuo WC, 2016, INFORM PROCESS LETT, V116, P183, DOI 10.1016/j.ipl.2015.08.003
   Li ZH, 2019, CMC-COMPUT MATER CON, V59, P563, DOI 10.32604/cmc.2019.05565
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liu HH, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0458-z
   Liu P, 2020, IOP CONF SER-MAT SCI, V719, DOI 10.1088/1757-899X/719/1/012068
   Liu Y., 2018, Microsystems Nanoengineering, V4, P1
   Liu YL, 2016, J VIS COMMUN IMAGE R, V39, P51, DOI 10.1016/j.jvcir.2016.05.008
   Liu YX, 2016, NEUROCOMPUTING, V188, P113, DOI 10.1016/j.neucom.2015.02.102
   Lu W, 2020, IEEE T CIRC SYST VID, V30, P3081, DOI 10.1109/TCSVT.2019.2936028
   Lubacz J, 2014, IEEE COMMUN MAG, V52, P225, DOI 10.1109/MCOM.2014.6815916
   Luo T, 2018, MULTIMED TOOLS APPL, V77, P19027, DOI 10.1007/s11042-017-5356-8
   Manikandan G, 2017, BIOMED RES-INDIA, V28, P1031
   Manisha S, 2019, MULTIDIM SYST SIGN P, V30, P529, DOI 10.1007/s11045-018-0568-2
   Mazurczyk W, 2018, COMMUN ACM, V61, P86, DOI 10.1145/3158416
   Mazurczyk W, 2013, INT J COMPUT COMMUN, V8, P432, DOI 10.15837/ijccc.2013.3.469
   Mercuri RT, 2004, COMMUN ACM, V47, P25, DOI 10.1145/1005817.1005840
   Miri A, 2018, MULTIMED TOOLS APPL, V77, P13133, DOI 10.1007/s11042-017-4935-z
   Miri A, 2017, OPTIK, V145, P158, DOI 10.1016/j.ijleo.2017.07.043
   Mousavi SM, 2014, J DIGIT IMAGING, V27, P714, DOI 10.1007/s10278-014-9700-5
   Mstafa RJ, 2017, IEEE ACCESS, V5, P5354, DOI 10.1109/ACCESS.2017.2691581
   Mstafa RJ, 2016, 2016 IEEE LONG ISLAND SYSTEMS, APPLICATIONS AND TECHNOLOGY CONFERENCE (LISAT)
   Mstafa RJ, 2016, MULTIMED TOOLS APPL, V75, P10311, DOI 10.1007/s11042-015-3060-0
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P18985, DOI 10.1007/s11042-017-4420-8
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Muhammad K, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0473-x
   Mungmode S, 2016, PROCEDIA COMPUT SCI, V79, P912, DOI 10.1016/j.procs.2016.03.114
   Neuner S, 2016, DIGIT INVEST, V18, pS76, DOI 10.1016/j.diin.2016.04.010
   Nyeem H, 2017, 2017 20TH INTERNATIONAL CONFERENCE OF COMPUTER AND INFORMATION TECHNOLOGY (ICCIT)
   PATEL A, 2007, INT J NETWORK SECURI, V5, P41
   Patel HN, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2584, DOI 10.1109/WiSPNET.2017.8300230
   Peipei Wang, 2017, Security and Communication Networks, V2017, DOI 10.1155/2017/8051389
   Perumal K., 2018, CONCURR COMP-PRACT E, V31, P1
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Pfitzmann B., 1996, Information Hiding. First International Workshop Proceedings, P347
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Qian YL, 2016, IEEE IMAGE PROC, P2752, DOI 10.1109/ICIP.2016.7532860
   Qu ZG, 2019, IEEE ACCESS, V7, P35684, DOI 10.1109/ACCESS.2019.2894295
   Rabie T, 2019, IEEE ACCESS, V7, P21948, DOI 10.1109/ACCESS.2019.2898838
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P6473, DOI 10.1007/s11042-016-3301-x
   Rajalakshmi K, 2018, MULTIMED TOOLS APPL, V77, P13225, DOI 10.1007/s11042-017-4942-0
   Rajendran Sujarani, 2017, International Journal of Network Security, V19, P593, DOI 10.6633/IJNS.201707.19(4).12
   Ramalingam M, 2016, COMPUT ELECTR ENG, V54, P423, DOI 10.1016/j.compeleceng.2015.10.005
   Ramalingam M, 2015, APPL SOFT COMPUT, V34, P744, DOI 10.1016/j.asoc.2015.05.040
   Ren Yanzhen, 2014, P 2 ACM WORKSHOP INF, P83, DOI DOI 10.1145/2600918.2600938
   Rezagholipour K, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT), P183, DOI 10.1109/IKT.2016.7777764
   Richardson Iain E, 2004, H. 264 and MPEG-4 Video Compression: Video Coding for Next-Generation Multimedia
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
   Galiano DR, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106541
   Sadat ES, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040244
   Sadek MM, 2017, MULTIMED TOOLS APPL, V76, P3065, DOI 10.1007/s11042-015-3170-8
   Sahu AK, 2019, SENS IMAGING, V21, DOI 10.1007/s11220-019-0262-y
   Saidi M, 2017, MULTIMED TOOLS APPL, V76, P13493, DOI 10.1007/s11042-016-3722-6
   Sajasi S, 2013, 2013 13TH IRANIAN CONFERENCE ON FUZZY SYSTEMS (IFSC)
   Sathisha N, 2013, PROC SPIE, V9067, DOI 10.1117/12.2051889
   Savithri G, 2017, ADV INTELL SYST, V459, P593, DOI 10.1007/978-981-10-2104-6_53
   Shafi I, 2018, SOFT COMPUT, V22, P1555, DOI 10.1007/s00500-017-2944-5
   Shah PD, 2018, ADV INTELL SYST, V632, P119, DOI 10.1007/978-981-10-5520-1_12
   [盛琪 Sheng Qi], 2017, [光电子·激光, Journal of Optoelectronics·Laser], V28, P433
   Singla Deepali, 2014, Journal of Emerging Technologies in Web Intelligence, V6, P237, DOI 10.4304/jetwi.6.2.237-242
   Singla D, 2014, 2014 RECENT ADVANCES IN ENGINEERING AND COMPUTATIONAL SCIENCES (RAECS)
   Song X., 2015, P ACM WORKSH INF HID, P15, DOI DOI 10.1145/2756601.2756608
   Song XF, 2016, LECT NOTES COMPUT SC, V0067, P59, DOI 10.1007/978-3-319-49145-5_7
   Stutz T, 2013, INTERFRAME H 264 CAV
   Su YT, 2017, KSII T INTERNET INF, V11, P360, DOI 10.3837/tiis.2017.01.019
   Subhedar MS, 2018, MULTIMED TOOLS APPL, V77, P8115, DOI 10.1007/s11042-017-4706-x
   Subhedar MS, 2016, COMPUT ELECTR ENG, V54, P406, DOI 10.1016/j.compeleceng.2016.04.017
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Sudeepa KB, 2016, PROCEDIA COMPUT SCI, V78, P483, DOI 10.1016/j.procs.2016.02.092
   Suttichaiya A., 2017, J TELECOMMUNICATION, V9, P23
   Swain G, 2016, PROCEDIA COMPUT SCI, V85, P39, DOI 10.1016/j.procs.2016.05.174
   Tang MW, 2014, OPTIK, V125, P3972, DOI 10.1016/j.ijleo.2014.01.149
   Tang WX, 2019, IEEE T INF FOREN SEC, V14, P2074, DOI 10.1109/TIFS.2019.2891237
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Tanwar R, 2017, IOP CONF SER-MAT SCI, V225, DOI 10.1088/1757-899X/225/1/012077
   Tasdemir K, 2016, IEEE T IMAGE PROCESS, V25, P3316, DOI 10.1109/TIP.2016.2567073
   Tavares R, 2016, IEEE LAT AM T, V14, P1058, DOI 10.1109/TLA.2016.7437258
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Torkaman MRN, 2011, COMM COM INF SC, V194, P42
   Tsang CF., 2018, ELECT IMAG, V2018, p121, DOI [DOI 10.2352/ISSN.2470-1173.2018.07.MWSF-121, 10.2352/ISSN.2470-1173.2018.07.MWSF-121]
   Umadevi R, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P3104
   Veena ST, 2018, PATTERN RECOGN LETT, V105, P39, DOI 10.1016/j.patrec.2017.08.016
   Volkhonskiy D, 2020, PROC SPIE, V11433, DOI 10.1117/12.2559429
   Wang Y, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P97, DOI 10.1145/3206004.3206020
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Warkentin M, 2008, J DIGIT FORENSICS SE, V3, P17
   Wengrowski E, 2019, PROC CVPR IEEE, P1515, DOI 10.1109/CVPR.2019.00161
   Whitelam C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY (HST), P61, DOI 10.1109/THS.2013.6698977
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu X, 2017, IEEE IJCNN, P214, DOI 10.1109/IJCNN.2017.7965857
   Xu CY, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 1, PROCEEDINGS, P269
   Xu DW, 2016, J VIS COMMUN IMAGE R, V36, P229, DOI 10.1016/j.jvcir.2016.02.002
   Xu G., 2016, P 4 ACM WORKSH INF H, P103, DOI DOI 10.1145/2909827.2930798
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Xue YM, 2019, SIGNAL PROCESS-IMAGE, V76, P22, DOI 10.1016/j.image.2019.04.012
   Xue YJ, 2019, J REAL-TIME IMAGE PR, V16, P601, DOI 10.1007/s11554-018-0822-8
   YANG CF, 2020, INT J DISTRIB SENS N, V16
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CF, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9328-2
   Yao YZ, 2016, SIGNAL PROCESS, V128, P531, DOI 10.1016/j.sigpro.2016.05.004
   Yao YZ, 2015, MULTIMED TOOLS APPL, V74, P11163, DOI 10.1007/s11042-014-2223-8
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Yedroudj M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2092, DOI 10.1109/ICASSP.2018.8461438
   Yun Cao, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P193, DOI 10.1007/978-3-642-24178-9_14
   Zarmehi N, 2016, IET IMAGE PROCESS, V10, P1, DOI 10.1049/iet-ipr.2014.1019
   Zeng JS, 2018, IEEE T INF FOREN SEC, V13, P1200, DOI 10.1109/TIFS.2017.2779446
   Zhai LM, 2020, IEEE T INF FOREN SEC, V15, P1762, DOI 10.1109/TIFS.2019.2949428
   Zhang R., 2018, ARXIV180711428
   Zhang R, 2019, MULTIMED TOOLS APPL, V78, P8559, DOI 10.1007/s11042-018-6951-z
   Zhang T, 2003, SIGNAL PROCESS, V83, P2085, DOI 10.1016/S0165-1684(03)00169-5
   Zhang T, 2019, MATH BIOSCI ENG, V16, P4069, DOI 10.3934/mbe.2019201
   Zhang X, 2018, IEEE T MULTIMEDIA, V20, P3223, DOI 10.1109/TMM.2018.2838334
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   ZHAO Y, 2015, PROC INT WORKSHOP DI, P119
   Zicheng Wang, 2013, 2013 IEEE 4th International Conference on Software Engineering and Service Science (ICSESS), P946, DOI 10.1109/ICSESS.2013.6615462
NR 201
TC 26
Z9 26
U1 6
U2 55
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5723
EP 5771
DI 10.1007/s11042-020-09929-9
EA OCT 2020
PG 49
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577990600005
DA 2024-07-18
ER

PT J
AU Gilanie, G
   Bajwa, UI
   Waraich, MM
   Anwar, MW
AF Gilanie, Ghulam
   Bajwa, Usama Ijaz
   Waraich, Mustansar Mahmood
   Anwar, Muhammad Waqas
TI Risk-free WHO grading of astrocytoma using convolutional neural networks
   from MRI images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE WHO grading; Astrocytoma grading; Convolutional neural networks
ID TEXTURE ANALYSIS; BRAIN; CLASSIFICATION; DIAGNOSIS; BIOPSY
AB Astrocytoma is the most common and aggressive brain tumor, in its highest grade, the prognosis is 'low survival rate'. Spinal tap and biopsy are the methods executed in order to determine the grade of astrocytoma. Once the grade of astrocytoma is determined, treatment is planned to improve the life expectancy of oncological subjects. Spinal tap and biopsy are invasive diagnostic procedures. Magnetic resonance imaging (MRI) being widely used imaging modality to detect brain tumors, produces the large volume of MRI data each moment in clinical environments. Automated and reliable methods of astrocytoma grading from the analysis of MRI images are required as an alternative to biopsy and spinal tape. However, obtaining molecular information of brain cells using non-invasive methods is challenging. In this research work, an automatic method of astrocytoma grading using Convolutional Neural Networks (CNN) has been proposed. Results have been validated on a locally developed dataset, obtained from Department of Radiology (Diagnostics), Bahawal Victoria Hospital, Bahawalpur, Pakistan. The proposed method proved a significant achievement in terms of accuracy as 99.06% (for astrocytoma of Grade-I), 94.01% (for astrocytoma of Grade-II), 95.31% (for astrocytoma of Grade-III), 97.85% (for astrocytoma of Grade-IV), and overall accuracy of 96.56%.
C1 [Gilanie, Ghulam; Bajwa, Usama Ijaz; Anwar, Muhammad Waqas] COMSATS Univ Islamabad, Dept Comp Sci, Lahore Campus, Lahore, Pakistan.
   [Waraich, Mustansar Mahmood] Bahawal Victoria Hosp, Dept Radiol Diagnost, Bahawalpur, Pakistan.
C3 COMSATS University Islamabad (CUI)
RP Bajwa, UI (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Lahore Campus, Lahore, Pakistan.
EM gilanie@cuilahore.edu.pk; usamabajwa@cuilahore.edu.pk;
   mustansarwaraich@gmail.com; waqasanwar@cuilahore.edu.pk
RI Gilanie, Ghulam/HDN-2595-2022; Anwar, Muhammad Naseem/IAM-7949-2023
OI Gilanie, Ghulam/0000-0001-6880-8506; Anwar, Muhammad
   Naseem/0000-0002-4759-0656; Bajwa, Usama/0000-0001-5755-1194
CR Ertosun Mehmet Gunhan, 2015, AMIA Annu Symp Proc, V2015, P1899
   FOLKMAN J, 1971, NEW ENGL J MED, V285, P1182
   Gilanie G, 2019, INT J IMAG SYST TECH, V29, P531, DOI 10.1002/ima.22333
   Gilanie G, 2019, INT J IMAG SYST TECH, V29, P260, DOI 10.1002/ima.22312
   Gilanie G, 2018, SIGNAL IMAGE VIDEO P, V12, P479, DOI 10.1007/s11760-017-1182-8
   Jean-Quartier C, 2020, INT J MOL SCI, V21, DOI 10.3390/ijms21020547
   Louis DN, 2007, ACTA NEUROPATHOL, V114, P547, DOI 10.1007/s00401-007-0278-6
   MANKIN HJ, 1982, J BONE JOINT SURG AM, V64, P1121, DOI 10.2106/00004623-198264080-00002
   Nyúl LG, 2000, IEEE T MED IMAGING, V19, P143, DOI 10.1109/42.836373
   Ohgaki H, 2013, CLIN CANCER RES, V19, P764, DOI 10.1158/1078-0432.CCR-12-3002
   Pan YH, 2015, IEEE ENG MED BIO, P699, DOI 10.1109/EMBC.2015.7318458
   Priya K. M., 2016, 2016 INT C SIGNAL PR, P1
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Subashini MM, 2016, EXPERT SYST APPL, V43, P186, DOI 10.1016/j.eswa.2015.08.036
   Tearney GJ, 1997, SCIENCE, V276, P2037, DOI 10.1126/science.276.5321.2037
   Tustison NJ, 2010, IEEE T MED IMAGING, V29, P1310, DOI 10.1109/TMI.2010.2046908
   von Bartheld CS, 2016, J COMP NEUROL, V524, P3865, DOI 10.1002/cne.24040
   WEISS SW, 1983, LAB INVEST, V49, P299
NR 19
TC 7
Z9 7
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4295
EP 4306
DI 10.1007/s11042-020-09970-8
EA SEP 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000573567600002
DA 2024-07-18
ER

PT J
AU Shankar, DD
   Azhakath, AS
AF Shankar, Deepa D.
   Azhakath, Adresya Suresh
TI Minor blind feature based Steganalysis for calibrated JPEG images with
   cross validation and classification using SVM and SVM-PSO
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; SVM; SVM-PSO; DCT; PVD; ANOVA; Calibration; Cross
   validation; LSB matching; LSB replacement
ID DISCRIMINANT; SELECTION; MODEL
AB The spectacular progress of technology related to the information and communication arena throughout the past epoch made the internet a powerful media for faster communication of data. Though this technology is being admired at one side, there equally exists a challenge for safeguarding the data and privacy of information of a personal without any leak in the data and corresponding mistreatment. Hence, the proposed work primarily aims to investigate the internet communication as well as deter any unwanted happenings, which could occur because of the covert communication. The probable presence of hidden messages is inspected in the digital mass media using the technique of steganalysis. The distinctive features are to be identified, chosen and extracted for universal (blind) steganalysis and are decided by the format of image and its transformation. In this paper, the analysis is carried out in JPEG format images and 10% embedding with 10 fold cross validation. The technique of calibration is used to obtain an estimate of the cover image. Four embedded techniques that have been applied for stegananlysis are Least Significant Bit Matching, LSB Replacement, Pixel Value Differencing (PVD) and F5 respectively. Four different sampling like linear, shuffle, stratified and automatic are considered in this paper. The classifiers used for a comparative study are Support Vector Machine (SVM) and SVM- Particle Swarm Optimization (SVM-PSO). Several kernels namely linear, epanechnikov, multi-quadratic, radial, ANOVA and polynomial are used in classification. The classifier is trained to examine every single coefficient as a separate unit for analysis and the outcome of this analysis helps in finding the decision of steganalysis.
C1 [Shankar, Deepa D.] Abu Dhabi Univ, Coll Arts & Sci, Abu Dhabi, U Arab Emirates.
   [Azhakath, Adresya Suresh] BITS Pilani Dubai Campus, Coll Comp Sci, Dubai, U Arab Emirates.
C3 Abu Dhabi University
RP Shankar, DD (corresponding author), Abu Dhabi Univ, Coll Arts & Sci, Abu Dhabi, U Arab Emirates.
EM sudee99@gmail.com
RI D.Shankar, Deepa/AAI-5686-2021; D.Shankar, deepa/JCE-3604-2023
OI D.Shankar, Deepa/0000-0001-9103-4692; D.Shankar,
   deepa/0000-0001-9103-4692; Azhakath, Adresya/0000-0003-1861-6463
CR Allegrini F, 2018, ANAL CHIM ACTA, V1011, P20, DOI 10.1016/j.aca.2018.02.002
   Ashu A., 2014, INT J COMPUT APPL, V92, P17, DOI DOI 10.5120/16093-5372
   Attaby AA, 2018, AIN SHAMS ENG J, V9, P1965, DOI 10.1016/j.asej.2017.02.003
   Barkana BD, 2017, KNOWL-BASED SYST, V118, P165, DOI 10.1016/j.knosys.2016.11.022
   Bergmeir C, 2018, COMPUT STAT DATA AN, V120, P70, DOI 10.1016/j.csda.2017.11.003
   Berrar D., 2018, Cross-Validation, DOI [10.1016/B978-0-12-809633-8.20349-X, DOI 10.1016/B978-0-12-809633-8.20349-X]
   Bhasin V, 2013, IEEE SYS MAN CYBERN, P1361, DOI 10.1109/SMC.2013.235
   Bhat V.H., 2010, P 2010 INT C SECURIT, P1
   Briffa JA, 2009, HAS F5 REALLY BEEN B
   Castelli M., 2019, Encyclopedia of Bioinformatics and Computational Biology, P342, DOI [10.1016/B978-0-12-809633-8.20332-4, DOI 10.1016/B978-0-12-809633-8.20332-4]
   Celik GSMTMU, 2004, SPIE
   Chaeikar SS, 2019, SIGNAL PROCESS-IMAGE, V70, P233, DOI 10.1016/j.image.2018.10.004
   Christaline JA, 2014, STEGANALYSIS CLASSIF
   Demidova L, 2017, PROCEDIA COMPUT SCI, V103, P222, DOI 10.1016/j.procs.2017.01.070
   Elbasi E, 2006, LECT NOTES COMPUTER, V4105
   Fridrich J, 2003, LECT NOTES COMPUTER, V2578
   Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3
   Pedronette DCG, 2019, NEUROCOMPUTING, V340, P19, DOI 10.1016/j.neucom.2019.02.016
   Harmsen JJ, 2004, P SPIE
   Hou XD, 2017, J VIS COMMUN IMAGE R, V49, P243, DOI 10.1016/j.jvcir.2017.09.016
   Ibrahim Rosziati, 2011, Computer Technology and Application, P102
   Jassim Firas A., 2013, INT J COMPUTER APPL, V72, P39, DOI DOI 10.5120/12637-9448
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jiang GX, 2017, PATTERN RECOGN, V69, P94, DOI 10.1016/j.patcog.2017.03.025
   Jiang NMEWXWM, 2004, INT C IM PROC
   Kalita M, 2016, COMP STUDY STEGANOGR
   Kang JS, 2007, 2007 22ND INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, P104
   Kawaguchi E, 2005, LECT NOTES COMPUTER, V3684
   Ker A.D., 2013, P 1 ACM WORKSH INF H, P4558, DOI DOI 10.1145/2482513.2482965
   Kodovsky J, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P63
   Kokkinos Y, 2018, NEUROCOMPUTING, V295, P29, DOI 10.1016/j.neucom.2018.01.005
   Kumar B. R., 2011, INT J COMPUT SCI INF, V2, P1453
   Kumar UP, 2019, BLIND STEGANALYSIS J, DOI 10.35940/ijitee.K1250.09811S19
   Kumar UP, 2019, INT J INNOV TECHNOL, DOI 10.35940/ijitee.K1240.09811S19
   Li ZY, 2017, INFORM SCIENCES, V415, P85, DOI 10.1016/j.ins.2017.06.011
   Malathi P, 2016, PROCEDIA COMPUT SCI, V93, P878, DOI 10.1016/j.procs.2016.07.270
   Mehta Rachna, 2018, Procedia Computer Science, V132, P1695, DOI 10.1016/j.procs.2018.05.143
   Miche Y, 2010, INT J COMPUT APPL, DOI 10.5120/4347-046
   Miche Y, 2006, LECT NOTES COMPUTER, V4105
   Miche Y., 2007, EXTRACTING RELEVANT
   Nagaraj V, 2011, MODULO BASED IMAGE S
   Pevny T, 2007, PROC SPIE, V6505, DOI 10.1117/12.696774
   Rajput G, 2012, DEFENCE SCI J, V62, P19, DOI 10.14429/dsj.62.1437
   Sajedi H, 2016, J INF SECUR APPL, V30, P3, DOI 10.1016/j.jisa.2016.04.001
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Sharma A., 2016, MONTHLY J COMPUT SCI, V5, P827
   Sutariya VB, 2015, BIOINTERACTIONS OF NANOMATERIALS, P1
   Tan YF, 2013, PROC SPIE, V8878, DOI 10.1117/12.2031061
   Tang M., 2010, 2 INT WORKSHOP IMAGE, P1
   Thai TH, 2014, IEEE T IMAGE PROCESS, V23, P1980, DOI 10.1109/TIP.2014.2310126
   Veena ST, 2018, PATTERN RECOGN LETT, V105, P39, DOI 10.1016/j.patrec.2017.08.016
   Wang LN, 2019, PATTERN RECOGN, V87, P106, DOI 10.1016/j.patcog.2018.10.003
   Wu AX, 2016, J VIS COMMUN IMAGE R, V34, P103, DOI 10.1016/j.jvcir.2015.10.013
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Xia Z, 2011, LEARNING BASED STEGA
   Xu L, 2018, CHEMOMETR INTELL LAB, V183, P29, DOI 10.1016/j.chemolab.2018.10.008
   Yu XY, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P41, DOI 10.1109/MINES.2009.269
   Zhu YJ, 2018, KNOWL-BASED SYST, V150, P57, DOI 10.1016/j.knosys.2018.02.035
NR 58
TC 13
Z9 13
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4073
EP 4092
DI 10.1007/s11042-020-09820-7
EA SEP 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572865900005
DA 2024-07-18
ER

PT J
AU Yue, SH
   Zhang, HB
AF Yue, Shenghan
   Zhang, Hongbo
TI A hybrid grasshopper optimization algorithm with bat algorithm for
   global optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Grasshopper optimization algorithm; Bat algorithm; Levy flight; Random
   strategy; Global optimization
AB This paper introduces a hybrid grasshopper optimization algorithm with bat algorithm (BGOA) for global optimization. In the BGOA, the Levy flight with variable coefficient is employed to enhance the exploration capability of the GOA. Then, the local search operation of bat algorithm (BA) is combined to balance the exploration and exploitation. Additionally, the random strategy is introduced and applied to high quality population to improve the exploitation capability in the searching process. The performance of BGOA is evaluated on 23 benchmark test functions, and compares with genetic algorithm (GA), bat algorithm (BA), moth-flame optimization algorithm (MFO), dragonfly algorithm (DA) and basic GOA. The results establish that the BGOA is able to provide better outcomes than the other algorithms.
C1 [Yue, Shenghan; Zhang, Hongbo] Changchun Univ Technol, Sch Mechatron Engn, Changchun 130012, Peoples R China.
C3 Changchun University of Technology
RP Yue, SH (corresponding author), Changchun Univ Technol, Sch Mechatron Engn, Changchun 130012, Peoples R China.
EM Shenghan_Yue@126.com
CR Arora S, 2019, NEURAL COMPUT APPL, V31, P4385, DOI 10.1007/s00521-018-3343-2
   Chu XH, 2019, NEURAL COMPUT APPL, V31, P8423, DOI 10.1007/s00521-019-04538-6
   Digalakis JG, 2001, INT J COMPUT MATH, V77, P481, DOI 10.1080/00207160108805080
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Ewees AA, 2018, EXPERT SYST APPL, V112, P156, DOI 10.1016/j.eswa.2018.06.023
   Hazra S, 2019, INT J SWARM INTELL R, V10, P38, DOI 10.4018/IJSIR.2019010103
   Henly Santillan Jon, 2018, Journal of Industrial Engineering International, V14, P293, DOI 10.1007/s40092-017-0227-5
   Holland J. H., 1992, Scientific American (International Edition), V267, P44, DOI 10.1038/scientificamerican0792-66
   Karaboga D, 2008, APPL SOFT COMPUT, V8, P687, DOI 10.1016/j.asoc.2007.05.007
   Kumar Naveen, 2014, P 2014 INT C CIRC SY
   Liang HN, 2019, IEEE ACCESS, V7, P11258, DOI 10.1109/ACCESS.2019.2891673
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P495, DOI 10.1007/s00521-015-1870-7
   Molga Marcin., 2005, Test Functions for Optimization Needs
   Nouiri M, 2018, J INTELL MANUF, V29, P603, DOI 10.1007/s10845-015-1039-3
   Saremi S, 2017, ADV ENG SOFTW, V105, P30, DOI 10.1016/j.advengsoft.2017.01.004
   Satapathy SC, 2018, NEURAL COMPUT APPL, V29, P1285, DOI 10.1007/s00521-016-2645-5
   SCHAFFER JD, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P51
   Shareef H, 2015, APPL SOFT COMPUT, V36, P315, DOI 10.1016/j.asoc.2015.07.028
   Tharwat A, 2019, CLUSTER COMPUT, V22, pS4745, DOI 10.1007/s10586-018-2360-3
   Topaz CM, 2008, EUR PHYS J-SPEC TOP, V157, P93, DOI 10.1140/epjst/e2008-00633-y
   Wu JF, 2017, AEROSP SCI TECHNOL, V70, P497, DOI 10.1016/j.ast.2017.08.037
   Yang XS, 2010, INT J BIO-INSPIR COM, V2, P78, DOI 10.1504/IJBIC.2010.032124
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Yao X, 1999, IEEE T EVOLUT COMPUT, V3, P82, DOI 10.1109/4235.771163
   Yoshida H, 2018, ELECTR ENG JPN, V204, P31, DOI 10.1002/eej.23100
   Yue XF, 2020, IEEE ACCESS, V8, P5928, DOI 10.1109/ACCESS.2019.2963679
   Zhang X, 2018, MECH SYST SIGNAL PR, V108, P58, DOI 10.1016/j.ymssp.2017.11.029
   Zhou Yongquan, 2019, J PHYS C SER, V1176
NR 30
TC 15
Z9 16
U1 4
U2 56
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3863
EP 3884
DI 10.1007/s11042-020-09876-5
EA SEP 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572601100001
DA 2024-07-18
ER

PT J
AU Elnabawy, R
   Elias, R
   Salem, MAM
   Abdennadher, S
AF Elnabawy, Reham
   Elias, Rimon
   Salem, Mohammed A. -M.
   Abdennadher, Slim
TI Extending Gardiner's code for Hieroglyphic recognition and English
   mapping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optical character recognition (OCR); Hieroglyphics; Gardiner's code;
   Recognition accuracy; English mapping
ID BOX PLOT
AB "Knowledge is power" horizontal ellipsis Writing is the main way to preserve the humanity knowledge across the ages. Therefore, an automatic and accurate mapping from ancient scripts to modern live language is a must to have. Such a system will support knowledge transfer, tourism and education. This article presents a new algorithm to segment and recognize the ancient Egyptian Hieroglyphs from images and produce the corresponding English meaning. The algorithm used image processing along with Optical Character Recognition (OCR). Then, the meaning behind the image containing Hieroglyphs is interpreted based on the context of the mapped English sentence. Gardiner's sign list is a standard list used to classify the Hieroglyphics symbols such that similar shapes are grouped in the same category. Hence, Hieroglyphics script is mapped to the English language. Hieroglyphics could be either read from left to right or from right to left based on the face orientation of the Hieroglyphic symbol. However, Gardiner's code does not help to automate the reading direction of the Hieroglyphics script. In this work, an extension of the list is proposed to resolve the ambiguity in the reading direction. The results of the segmentation and recognition of Hieroglyphics symbols are demonstrated and compared to similar work for Chinese character recognition. Moreover, the results obtained from the state-of-the-art used in Hieroglyphic character recognition compared to the results obtained from the proposed algorithm on Hieroglyphic character are addressed. The mapped English sentence is then compared to some defined patterns. When a match is found, the input gets structured and reformatted accordingly. Tests on the defined patterns were conducted, and the results were successful, however, some additional results are generated that show equivalent synonyms to the input English sentence.
C1 [Elnabawy, Reham; Elias, Rimon; Salem, Mohammed A. -M.; Abdennadher, Slim] German Univ Cairo, Fac Media Engn & Technol, Cairo, Egypt.
   [Salem, Mohammed A. -M.] Ain Shams Univ, Fac Comp & Informat Sci, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); German University in Cairo; Egyptian
   Knowledge Bank (EKB); Ain Shams University
RP Elnabawy, R (corresponding author), German Univ Cairo, Fac Media Engn & Technol, Cairo, Egypt.
EM rehamhossam312@gmail.com
RI Salem, Mohammed A.-M/H-1922-2012; Elias, Rimon/KUC-9069-2024
OI Salem, Mohammed A.-M/0000-0003-1489-9830; Elnabawy,
   Reham/0000-0002-1703-0607; Elias, Rimon/0000-0001-6321-096X
CR Allen JP, 2013, ANCIENT EGYPTIAN LANGUAGE: AN HISTORICAL STUDY, P1, DOI 10.1017/CBO9781139506090
   Allen J.P., 2000, Middle Egyptian: An Introduction to the Language and Culture of Hieroglyphs
   [Anonymous], 2013, P 21 ACM INT C MULT, DOI DOI 10.1145/2502081.2502199
   Bell D. A., 2018, NAPOLEON VERY SHORT
   Bowen T, 2018, VIS COMMUN
   Chrysikopoulos V, 2018, P 4 BIENN ARCH URB R, P103
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Chung HKS, 2018, COGNITION, V178, P50, DOI 10.1016/j.cognition.2018.04.022
   Drucker Johanna., 2000, Information Design Journal, V10, P95, DOI DOI 10.1075/IDJ.10.2.04DRU
   Guthrie K.S., 1987, The Pythagorean Sourcebook and Library
   Hansen EJ, 2018, POE EGYPT EGYPTOMANI
   Hintze JL, 1998, AM STAT, V52, P181, DOI 10.2307/2685478
   JINDAL H, 2016, P INT C REC COGN WIR, P1
   Kashyap R., 2018, Int. J. Comput. Syst. Eng., V4, P195
   Kaur Sandeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P23, DOI 10.5815/ijigsp.2017.07.03
   Leach Neil., 2005, The hieroglyphics of space: Reading and experiencing the modern metropolis
   Leng L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092644
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Loprieno A., 1996, Ancient Egyptian Literature. History and Forms, V10
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Ma C, 2018, IEEE T MED IMAGING, V37, P1943, DOI 10.1109/TMI.2018.2805821
   Mander Kuldeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P17, DOI 10.5815/ijigsp.2017.08.03
   Marmanis D, 2018, ISPRS J PHOTOGRAMM, V135, P158, DOI 10.1016/j.isprsjprs.2017.11.009
   Mittal Archie, 2017, International Journal of Image, Graphics and Signal Processing, V9, P28, DOI 10.5815/ijigsp.2017.05.04
   Parkinson R., 1999, CRACKING CODES ROSET
   Pfannkuch M., 2006, STAT ED RES J, V5, P27, DOI [10.52041/serj.v5i2.498, DOI 10.52041/SERJ.V5I2.498]
   Richter Tonio Sebastian., 2009, From Hellenism to Islam: Cultural and Linguistic Change in the Roman Near East, P401, DOI [10.1017/CBO9780511641992.019, DOI 10.1017/CBO9780511641992.019]
   Roth AM, 2000, REV MIDDLE EAST STUD, V34, P89
   Schotter Jesse, 2018, Hieroglyphic Modernisms: Writing and New Media in the Twentieth Century
   WILLIAMSON DF, 1989, ANN INTERN MED, V110, P916, DOI 10.7326/0003-4819-110-11-916
   Yang ZY, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121464
   Zhang XY, 2018, IEEE T PATTERN ANAL, V40, P849, DOI 10.1109/TPAMI.2017.2695539
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
NR 33
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3391
EP 3408
DI 10.1007/s11042-020-09825-2
EA SEP 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000571363500001
DA 2024-07-18
ER

PT J
AU Khamparia, A
   Gupta, D
   Rodrigues, JJPC
   de Albuquerque, VHC
AF Khamparia, Aditya
   Gupta, Deepak
   Rodrigues, Joel J. P. C.
   de Albuquerque, Victor Hugo C.
TI DCAVN: Cervical cancer prediction and classification using deep
   convolutional and variational autoencoder network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Variational; Convolution; Cervical; Deep learning; Autoencoder
AB Early detection, early diagnosis and classification of the cancer type facilitates faster disease management of patients. Cervical cancer is fourth most pervasive cancer type which affects life of many people worldwide. The intent of this study is to automate cancer diagnosis and classification through deep learning techniques to ensure patients health condition progress timely. For this research, Herlev dataset was utilized which contains 917 benchmarked pap smear cells of cervical with 26 attributes and two target variables for training and testing phase. We have adopted combination of convolutional network with variational autoencoder for data classification. The usage of variational autoencoder reduces the dimensionality of data for further processing with involvement of softmax layer for training. The results have been obtained over 917 cancerous image type pap smear cells, where 70% (642) allocated for training and remaining 30% (275) considered for test data set. The proposed architecture achieved variational accuracy of 99.2% with 2*2 filter size and 99.4% with 3*3 filter size using different epochs. The proposed hybrid variational convolutional autoencoder approach applied first time for cervical cancer diagnosis and performed better than traditional machine learning methods.
C1 [Khamparia, Aditya] Lovely Profess Univ, Sch Comp Sci & Engn, Phagwara, Punjab, India.
   [Gupta, Deepak] Maharaja Agrasen Inst Technol, New Delhi, India.
   [Rodrigues, Joel J. P. C.] Univ Fed Piaui, Teresina, PI, Brazil.
   [Rodrigues, Joel J. P. C.] Inst Telecommun, P-1049001 Lisbon, Portugal.
   [de Albuquerque, Victor Hugo C.] Univ Fortaleza, Grad Program Appl Informat, Fortaleza, Ceara, Brazil.
C3 Lovely Professional University; Maharaja Agrasen Institute of
   Technology; Universidade Federal do Piaui; Universidade de Lisboa;
   Instituto de Telecomunicacoes; Universidade Fortaleza
RP Khamparia, A (corresponding author), Lovely Profess Univ, Sch Comp Sci & Engn, Phagwara, Punjab, India.
EM aditya.khamparia88@gmail.com
RI de Albuquerque, Victor Hugo C./C-3677-2016; Rodrigues, Joel J. P.
   C./A-8103-2013; Gupta, Deepak/AAV-2728-2020
OI de Albuquerque, Victor Hugo C./0000-0003-3886-4309; Rodrigues, Joel J.
   P. C./0000-0001-8657-3800; Gupta, Deepak/0000-0002-3019-7161
FU Brazilian National Council for Research and Development (CNPq)
   [309335/2017-5, 304315/2017-6, 430274/2018-1]; FCT/MCTES; EU funds
   [UIDB/EEA/50008/2020]
FX VHCA received support from the Brazilian National Council for Research
   and Development (CNPq, Grant#304315/2017-6 and #430274/2018-1). Joel JPC
   Rodrigues received supported by FCT/MCTES through national funds and
   when applicable co-funded EU funds under the Project
   UIDB/EEA/50008/2020; and by Brazilian National Council for Research and
   Development (CNPq) via Grant No. 309335/2017-5.
CR Adem K, 2019, EXPERT SYST APPL, V115, P557, DOI 10.1016/j.eswa.2018.08.050
   Almubarak HA, 2017, PROCEDIA COMPUT SCI, V114, P281, DOI 10.1016/j.procs.2017.09.044
   Chen WS, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010110
   Ferlay J., 2012, GLOBOCAN 2012 CANC I
   Fukushima K., 2007, Scholarpedia, V2, P1717, DOI DOI 10.4249/SCHOLARPEDIA.1717
   Goodman A, 2000, Clin Cornerstone, V3, P25, DOI 10.1016/S1098-3597(00)90019-X
   Ho SH, 2004, EXPERT SYST APPL, V27, P97, DOI 10.1016/j.eswa.2003.12.005
   Institute for Health Metrics and Evaluation, 2011, CHALL AH PROGR BREAS
   Jantzen J, 2006, P NAT INSP SMART INF
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kusy M, 2013, MED BIOL ENG COMPUT, V51, P1357, DOI 10.1007/s11517-013-1108-8
   Obukhova NA, 2017, PROC CONF OPEN INNOV, P345, DOI 10.23919/FRUCT.2017.8071332
   P Elayaraja, 2018, Asian Pac J Cancer Prev, V19, P3571
   Richhariya B, 2018, EXPERT SYST APPL, V106, P169, DOI 10.1016/j.eswa.2018.03.053
   Shao YH, 2011, IEEE T NEURAL NETWOR, V22, P962, DOI 10.1109/TNN.2011.2130540
   Sun G., 2017, INT J PERFORMABILITY, V13, P446, DOI [10.23940/ijpe.17.04.p12.446457, DOI 10.23940/IJPE.17.04.P12.446457]
   Verma A, 2017, MIDDLE EAST FERTIL S, V22, P39, DOI 10.1016/j.mefs.2016.09.002
   Wu W, 2017, IEEE ACCESS, V5, P25189, DOI 10.1109/ACCESS.2017.2763984
   Yamal JM, 2015, STAT ANAL DATA MIN, V8, P65, DOI 10.1002/sam.11261
   Zhang L, 2017, IEEE J BIOMED HEALTH, V21, P1633, DOI 10.1109/JBHI.2017.2705583
NR 20
TC 26
Z9 26
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30399
EP 30415
DI 10.1007/s11042-020-09607-w
EA SEP 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000570032900001
DA 2024-07-18
ER

PT J
AU Kari, AP
   Navin, AH
   Bidgoli, AM
   Mirnia, M
AF Pourjabbar Kari, Ahmad
   Habibizad Navin, Ahmad
   Bidgoli, Amir Massoud
   Mirnia, Mirkamal
TI A new image encryption scheme based on hybrid chaotic maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptography; Chaotic maps; Arnold's cat map; Tent map; Logistic map;
   Sine map
ID PERMUTATION; CRYPTANALYSIS; EFFICIENT; SYSTEM
AB In this paper, a novel grayscale image cryptosystem based on hybrid chaotic maps is proposed. The scheme employs both confusion phase to scramble the location of pixels and diffusion phase for changing the content of pixels in consecutive manner. In this scheme, Arnold's cat map is introduced to perform confusion operation and the principle of diffusion is achieved by using the proper selection of combined Sine map, Logistic map, and Tent map. Furthermore, exclusive OR (XOR), exchange, and transform operations are used to enhance the efficiency of diffusion phase. Accordingly, the use of chaotic maps and XOR operation provides a dual layer of security. Depending on the average absolute value of horizontal, vertical, and diagonal correlation coefficient of plain image as well as bifurcation properties of chaotic maps, one of the mentioned chaotic maps is selected for diffusion phase. First, original gray scale image matrix is extended to square matrix by adding the sequences generated with proper chaotic maps to implement the first step of diffusion phase. Then the Arnold's cat map changes pixels location of new extended matrix by means of certain equation as confusion phase. The encrypted image is generated after applying XOR, exchange and transform operations on the content of pixels as second step of diffusion phase. Thus the system is able to build several more complicated chaotic structures. In addition the encryption and decryption processing time directly depend on the value of correlation coefficient of original image. Plain images with less correlation coefficient have less encryption and decryption processing time, and vice versa. Compared with several existing methods, the proposed scheme has more better properties, including wider chaotic ranges and more complex chaotic behavior. Experimental results show that the proposed system has proper encryption and decryption processing time, unified average changing intensity (UACI), number of pixel change rate (NPCR), and extensive security analysis for kind of images.
C1 [Pourjabbar Kari, Ahmad; Bidgoli, Amir Massoud] Islamic Azad Univ, North Tehran Branch, Dept Comp Engn, Tehran, Iran.
   [Habibizad Navin, Ahmad] Islamic Azad Univ, Tabriz Branch, Dept Comp Engn, Tabriz, Iran.
   [Mirnia, Mirkamal] Univ Tabriz, Dept Math & Comp Sci, Tabriz, Iran.
C3 Islamic Azad University; Islamic Azad University; University of Tabriz
RP Kari, AP (corresponding author), Islamic Azad Univ, North Tehran Branch, Dept Comp Engn, Tehran, Iran.
EM a.pourjabar@gmail.com; a.habibizad@srbiau.ac.ir;
   Am_bidgoli@iau-tnb.ac.ir; mirnia-kam@tabrizu.ac.ir
RI BIDGOLI, AMIR/AAO-8029-2021
OI BIDGOLI, AMIR MASSOUD/0000-0001-9224-3525; habibizad navin,
   ahmad/0000-0003-2260-5871
CR Abbas NA, 2016, EGYPT INFORM J, V17, P139, DOI 10.1016/j.eij.2015.10.001
   Amina S, 2018, COMMUN NONLINEAR SCI, V60, P12, DOI 10.1016/j.cnsns.2017.12.017
   [Anonymous], 2018, Q INF PROCESS
   Bakhshandeh A, 2013, OPT LASER ENG, V51, P665, DOI 10.1016/j.optlaseng.2013.01.001
   Borujeni SE, 2013, TELECOMMUN SYST, V52, P525, DOI 10.1007/s11235-011-9458-8
   Chapaneri S, 2014, 2014 INTERNATIONAL CONFERENCE ON CIRCUITS, SYSTEMS, COMMUNICATION AND INFORMATION TECHNOLOGY APPLICATIONS (CSCITA), P59, DOI 10.1109/CSCITA.2014.6839235
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen JX, 2015, COMMUN NONLINEAR SCI, V23, P294, DOI 10.1016/j.cnsns.2014.11.021
   Chen JX, 2015, OPT LASER ENG, V67, P191, DOI 10.1016/j.optlaseng.2014.11.017
   Chen JX, 2015, COMMUN NONLINEAR SCI, V20, P846, DOI 10.1016/j.cnsns.2014.06.032
   Cheng GF, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419501153
   Dhall S, 2018, SIGNAL PROCESS, V146, P22, DOI 10.1016/j.sigpro.2017.12.021
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   Francois M., 2012, APPL MATH, V3, P1910, DOI DOI 10.4236/AM.2012.312262
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fu C, 2013, COMPUT BIOL MED, V43, P1000, DOI 10.1016/j.compbiomed.2013.05.005
   Fu C, 2012, OPT EXPRESS, V20, P2363, DOI 10.1364/OE.20.002363
   Gong LH, 2019, OPT LASER TECHNOL, V115, P257, DOI 10.1016/j.optlastec.2019.01.039
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Kanso A, 2015, COMMUN NONLINEAR SCI, V24, P98, DOI 10.1016/j.cnsns.2014.12.005
   Khanzadi H, 2014, ARAB J SCI ENG, V39, P1039, DOI 10.1007/s13369-013-0713-z
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Liu HJ, 2013, J SYST SOFTWARE, V86, P826, DOI 10.1016/j.jss.2012.11.026
   Liu YS, 2016, NONLINEAR DYNAM, V84, P2241, DOI 10.1007/s11071-016-2642-3
   del Rey AM, 2015, LOG J IGPL, V23, P485, DOI 10.1093/jigpal/jzv013
   Mohamed FK, 2014, ENG SCI TECHNOL, V17, P85, DOI 10.1016/j.jestch.2014.04.001
   Norouzi B, 2015, MULTIMED TOOLS APPL, V74, P781, DOI 10.1007/s11042-013-1699-y
   Pan SM, 2017, MULTIMED TOOLS APPL, V76, P2933, DOI 10.1007/s11042-015-3209-x
   Sha-ShaYu N-RZ, 2020, OPT LASER ENG, V124
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Song CY, 2013, OPTIK, V124, P3329, DOI 10.1016/j.ijleo.2012.11.002
   Souyah A, 2016, NONLINEAR DYNAM, V86, P639, DOI 10.1007/s11071-016-2912-0
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wang XY, 2014, NONLINEAR DYNAM, V76, P1943, DOI 10.1007/s11071-014-1259-7
   Wang XY, 2014, NONLINEAR DYNAM, V75, P345, DOI 10.1007/s11071-013-1070-x
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wong KW, 2009, CHAOS SOLITON FRACT, V41, P2652, DOI 10.1016/j.chaos.2008.09.047
   Wu JH, 2017, SIGNAL PROCESS, V141, P109, DOI 10.1016/j.sigpro.2017.04.006
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Yavuz E, 2015, COMPUT ELECT ENG
   Yu F, 2019, DISCRETE DYN NAT SOC, V2019, DOI 10.1155/2019/2545123
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang LY, 2018, INFORM SCIENCES, V430, P228, DOI 10.1016/j.ins.2017.11.021
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P584, DOI 10.1016/j.cnsns.2012.08.010
   Zhang XP, 2014, NONLINEAR DYNAM, V75, P319, DOI 10.1007/s11071-013-1068-4
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhang YS, 2014, NONLINEAR DYNAM, V78, P235, DOI 10.1007/s11071-014-1435-9
   Zhi-Jing H, 2020, OPT LASER ENG, V124
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 55
TC 53
Z9 53
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2753
EP 2772
DI 10.1007/s11042-020-09648-1
EA SEP 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000570041100001
DA 2024-07-18
ER

PT J
AU Chriki, A
   Touati, H
   Snoussi, H
   Kamoun, F
AF Chriki, Amira
   Touati, Haifa
   Snoussi, Hichem
   Kamoun, Farouk
TI Deep learning and handcrafted features for one-class anomaly detection
   in UAV video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE UAVs; Anomaly detection; Convolutional neural network; Handcrafted
   features; Unsupervised learning; One class classification
ID SURVEILLANCE
AB Visual surveillance systems have recently captured the attention of the research community. Most of the proposed surveillance systems deal with stationary cameras. Nevertheless, these systems may reflect minor applicability in anomaly detection when multiple cameras are required. Lately, under technological progress in electronic and avionics systems, Unmanned Aerial Vehicles (UAVs) are increasingly used in a wide variety of urban missions. Especially, in the surveillance context, UAVs can be used as mobile cameras to overcome weaknesses of stationary cameras. One of the principal advantages that makes UAVs attractive is their ability to provide a new aerial perspective. Despite their numerous advantages, there are many difficulties associated with automatic anomalies detection by an UAV, as there is a lack in the proposed contributions describing anomaly detection in videos recorded by a drone. In this paper, we propose new anomaly detection techniques for assisting UAV based surveillance mission where videos are acquired by a mobile camera. To extract robust features from UAV videos, three different features extraction methods were used, namely a pretrained Convolutional Neural Network (CNN) and two popular handcrafted methods (Histogram of Oriented Gradient (HOG) and HOG3D). One Class Support Vector Machine (OCSVM) has been then applied for the unsupervised classification. Extensive experiments carried on a dataset containing videos taken by an UAV monitoring a car parking, prove the efficiency of the proposed techniques. Specifically, the quantitative results obtained using the challenging Area Under Curve (AUC) evaluation metric show that, despite the variation among them, the proposed methods achieve good results in comparison to the existing technique with an AUC = 0.78 at worst and an AUC = 0.93 at best.
C1 [Chriki, Amira; Touati, Haifa] Univ Gabes, Hatem Bettaher IResCoMath Res Unit, Gabes, Tunisia.
   [Chriki, Amira; Kamoun, Farouk] Natl Sch Comp Sci ENSI, Manouba, Tunisia.
   [Snoussi, Hichem] Univ Technol Troyes, Troyes, France.
   [Kamoun, Farouk] Univ Manouba, CRISTAL Lab, Manouba, Tunisia.
C3 Universite de Gabes; Universite de la Manouba; Universite de Technologie
   de Troyes; Universite de la Manouba
RP Chriki, A (corresponding author), Univ Gabes, Hatem Bettaher IResCoMath Res Unit, Gabes, Tunisia.; Chriki, A (corresponding author), Natl Sch Comp Sci ENSI, Manouba, Tunisia.
EM amirachriki@gmail.com; haifa.touati@cristal.rnu.tn;
   hichem.snoussi@utt.fr; farouk.kamoun@ensi.rnu.tn
RI Touati, Haifa/AAT-2919-2021
OI Touati, Haifa/0000-0002-8391-3061; CHRIKI, Amira/0000-0002-9320-7814;
   Kamoun, Farouk/0000-0002-9932-9177
CR [Anonymous], 2020, EXTRACTHOGFEATURES
   [Anonymous], 2010, BRIT MACHINE VISION
   [Anonymous], 2020, GOOGL
   [Anonymous], 2001, London, DOI DOI 10.1080/14786440109462720
   Ballabio D, 2015, CHEMOMETR INTELL LAB, V149, P1, DOI 10.1016/j.chemolab.2015.10.003
   Bera A, 2016, IEEE COMPUT SOC CONF, P1289, DOI 10.1109/CVPRW.2016.163
   Bonetto M, 2015, IEEE IMAGE PROC, P2464, DOI 10.1109/ICIP.2015.7351245
   Bouindour S, 2019, 2019 IEEE SECOND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE), P172, DOI 10.1109/AIKE.2019.00039
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Cai Y, 2019, APPL ENG AGRIC, V35, P481, DOI 10.13031/aea.13007
   Carreño A, 2020, ARTIF INTELL REV, V53, P3575, DOI 10.1007/s10462-019-09771-y
   Chalapathy Raghavendra, 2019, ARXIV190103407
   Chan YT, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.5.051402
   Chandola V, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1541880.1541882
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chicco D, 2017, BIODATA MIN, V10, DOI 10.1186/s13040-017-0155-3
   Chriki A, 2019, COMPUT NETW, V163, DOI 10.1016/j.comnet.2019.106877
   Chriki A, 2019, INT WIREL COMMUN, P2064
   Chriki A, 2019, INT WIREL COMMUN, P1674, DOI 10.1109/IWCMC.2019.8766481
   Cinelli L. P., 2017, PROC 35 S BRASILEIRO, P3
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Diego F, 2012, NIGHT TIME OUTDOOR S
   Diego F, 2011, IEEE T IMAGE PROCESS, V20, P1858, DOI 10.1109/TIP.2010.2095873
   FAHN Chin-Shyurng, 2019, INT J FUTURE COMPUTE, V8
   Farooq MU, 2017, INT J ADV COMPUT SC, V8, P270
   Golda T., 2019, 2019 16 IEEE INT C A, P1
   Gordon G., 2012, Optimization, V10, P725
   Haering N, 2008, MACH VISION APPL, V19, P279, DOI 10.1007/s00138-008-0152-0
   Henrio J, 2018, IEEE SYS MAN CYBERN, P2503, DOI 10.1109/SMC.2018.00429
   Kawachi Y, 2019, INT CONF ACOUST SPEE, P3047, DOI 10.1109/ICASSP.2019.8683790
   Kiran BR, 2018, J IMAGING, V4, DOI 10.3390/jimaging4020036
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Medel J. R., 2016, Anomaly detection in video using predictive convolutional long short-term memory networks
   Mishra Soumya Ranjan, 2020, Smart Intelligent Computing and Applications. Proceedings of the Third International Conference on Smart Computing and Informatics. Smart Innovation, Systems and Technologies (SIST 159), P561, DOI 10.1007/978-981-13-9282-5_53
   Motlagh NH, 2017, IEEE COMMUN MAG, V55, P128, DOI 10.1109/MCOM.2017.1600587CM
   Nawaratne R, 2020, IEEE T IND INFORM, V16, P393, DOI 10.1109/TII.2019.2938527
   Olatunji I.E., 2019, ser. Learning and Analytics in Intelligent Systems, P475
   Patil N, 2016, 2016 SIXTH INTERNATIONAL SYMPOSIUM ON EMBEDDED COMPUTING AND SYSTEM DESIGN (ISED 2016), P217, DOI 10.1109/ISED.2016.7977085
   Ribeiro M, 2018, PATTERN RECOGN LETT, V105, P13, DOI 10.1016/j.patrec.2017.07.016
   Saini R, 2017, ADV INTELL SYST, V459, P261, DOI 10.1007/978-981-10-2104-6_24
   Schölkopf B, 2000, ADV NEUR IN, V12, P582
   STONE M, 1974, J R STAT SOC B, V36, P111, DOI 10.1111/j.2517-6161.1974.tb00994.x
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Thomaz LA, 2018, IEEE T CIRCUITS-I, V65, P1003, DOI 10.1109/TCSI.2017.2758379
   Wang SQ, 2016, INT C PATT RECOG, P3398, DOI 10.1109/ICPR.2016.7900159
   Wang T, 2018, MULTIMED TOOLS APPL, V77, P17375, DOI 10.1007/s11042-017-5309-2
   Wang T, 2014, IEEE T INF FOREN SEC, V9, P988, DOI 10.1109/TIFS.2014.2315971
   Wang Y, 2019, ADV MECH ENG, V11, DOI 10.1177/1687814018819287
   Wei J, 2018, IEEE COMPUT SOC CONF, P129, DOI 10.1109/CVPRW.2018.00025
   Wittek P, 2014, QUANTUM MACHINE LEARNING: WHAT QUANTUM COMPUTING MEANS TO DATA MINING, P1
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Yan W., 2019, P ANN C PROGN HLTH M, DOI DOI 10.48550/ARXIV.1908.09238
   Zhai X., 2020, SPE INT PETROLEUM TE, DOI [10.2523/IPTC-20111-MS, DOI 10.2523/IPTC-20111-MS]
   Zhang A, 2019, DIVE DEEP LEARNING U, V3, P319
   Zhou SF, 2016, SIGNAL PROCESS-IMAGE, V47, P358, DOI 10.1016/j.image.2016.06.007
NR 58
TC 35
Z9 36
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2599
EP 2620
DI 10.1007/s11042-020-09774-w
EA SEP 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000569701000009
DA 2024-07-18
ER

PT J
AU Chen, ST
   Jin, M
   Ding, J
AF Chen, Suting
   Jin, Meng
   Ding, Jie
TI Hyperspectral remote sensing image classification based on dense
   residual three-dimensional convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral remote sensing classification; Deep convolution;
   Three-dimensional convolution; Dense residual connection; Multi-label
   conditional random field
ID SPECTRAL-SPATIAL CLASSIFICATION; ATTRIBUTE PROFILES; FRAMEWORK;
   REPRESENTATIONS; ALGORITHM
AB Data-driven deep learning techniques set the current state of the art in image classification for hyperspectral remote sensing images. The lack of labeled training data and high dimensionality of hyperspectral images, results in these techniques being far from satisfactory with respect to accuracy and efficiency. To address the deficiencies of the existing approaches, we proposed a novel neural network technique, namely, dense residual three-dimensional convolutional neural network (DR-3D-CNN). Tailored for hyperspectral images, this network used 3D convolution instead of the conventional 2D convolution for more effective spectral feature extraction. It also employed dense residual connections to alleviate the problem of gradient dispersion. After the initial classification by the network, the proposed technique further refined the result using multi-label conditional random field optimization. Experimental results on various hyperspectral image datasets showed that the proposed model outperforms existing deep learning techniques with respect to accuracy by a large margin while requiring less training time.
C1 [Chen, Suting; Jin, Meng] Nanjing Univ Informat Sci & Technol, Jiangsu Key Lab Meteorol Observat & Informat Proc, Nanjing 210044, Peoples R China.
   [Chen, Suting; Ding, Jie] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology
RP Chen, ST (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Key Lab Meteorol Observat & Informat Proc, Nanjing 210044, Peoples R China.; Chen, ST (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Peoples R China.
EM sutingchen@nuist.edu.cn; jinmeng0722@gmail.com; 574428734@qq.com
FU National Natural Science Foundation of China [61705019]
FX This work was supported by National Natural Science Foundation of China
   (61705019).
CR [Anonymous], 2007, Hyperspectral Data Exploitation: Theory and Applications
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Camps-Valls G, 2005, IEEE T GEOSCI REMOTE, V43, P1351, DOI 10.1109/TGRS.2005.846154
   Chen L, 2017, SEMISUPERVISED DICT
   Chen Y, 2013, IEEE T GEOSCI REMOTE, V51, P217, DOI 10.1109/TGRS.2012.2201730
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Dong YQ, 2018, ENERGIES, V11, DOI 10.3390/en11041009
   Fauvel M, 2012, PATTERN RECOGN, V45, P381, DOI 10.1016/j.patcog.2011.03.035
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Fulkerson B, 2009, IEEE I CONF COMP VIS, P670
   Geiss C, 2018, IEEE GEOSCI REMOTE S, V15, P922, DOI 10.1109/LGRS.2018.2813436
   Ghamisi P, 2014, IEEE J-STARS, V7, P2147, DOI 10.1109/JSTARS.2014.2298876
   Ghamisi P, 2014, IEEE T GEOSCI REMOTE, V52, P5771, DOI 10.1109/TGRS.2013.2292544
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Gong C, 2015, CVPR
   Gu YF, 2012, IEEE T GEOSCI REMOTE, V50, P2852, DOI 10.1109/TGRS.2011.2176341
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hecker C, 2008, IEEE T GEOSCI REMOTE, V46, P4162, DOI 10.1109/TGRS.2008.2001035
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hong WC, 2019, APPL MATH MODEL, V72, P425, DOI 10.1016/j.apm.2019.03.031
   Hsieh PF, 2009, CAN J REMOTE SENS, V35, P248, DOI 10.5589/m09-011
   Huang GY, 2017, ATMOS MEAS TECH, V10, DOI 10.5194/amt-10-2455-2017
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   JIA XP, 1994, IEEE T GEOSCI REMOTE, V32, P274, DOI 10.1109/36.295042
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kundra H., 2015, RES J INF TECHNOL, V7, P58, DOI DOI 10.3923/RJIT.2015.58.69
   Li CH, 2012, IEEE T GEOSCI REMOTE, V50, P784, DOI 10.1109/TGRS.2011.2162246
   Li JY, 2014, IEEE GEOSCI REMOTE S, V11, P1409, DOI 10.1109/LGRS.2013.2294241
   Li J, 2013, IEEE T GEOSCI REMOTE, V51, P844, DOI 10.1109/TGRS.2012.2205263
   Li XK, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8050438
   Li Y, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010067
   Makantasis K, 2015, INT GEOSCI REMOTE SE, P4959, DOI 10.1109/IGARSS.2015.7326945
   Meyer A, 2003, P SOC PHOTO-OPT INS, V5001, P84, DOI 10.1117/12.500371
   Moser G, 2013, IEEE T GEOSCI REMOTE, V51, P2734, DOI 10.1109/TGRS.2012.2211882
   Moser G, 2013, P IEEE, V101, P631, DOI 10.1109/JPROC.2012.2211551
   Murray NJ, 2018, METHODS ECOL EVOL, V9, P2019, DOI 10.1111/2041-210X.13043
   Nie GY, 2019, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2019.00340
   Pinto N, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000579
   Song BQ, 2014, IEEE T GEOSCI REMOTE, V52, P5122, DOI 10.1109/TGRS.2013.2286953
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Willett RM, 2014, IEEE SIGNAL PROC MAG, V31, P116, DOI 10.1109/MSP.2013.2279507
   Zhang LF, 2012, IEEE T GEOSCI REMOTE, V50, P879, DOI 10.1109/TGRS.2011.2162339
   Zhang LP, 2013, IEEE T GEOSCI REMOTE, V51, P242, DOI [10.1109/TGRS.2011.2180392, 10.1109/TGRS.2012.2197860]
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao WZ, 2016, IEEE T GEOSCI REMOTE, V54, P4544, DOI 10.1109/TGRS.2016.2543748
   Zhao WZ, 2016, ISPRS J PHOTOGRAMM, V113, P155, DOI 10.1016/j.isprsjprs.2016.01.004
NR 52
TC 18
Z9 19
U1 3
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 1859
EP 1882
DI 10.1007/s11042-020-09480-7
EA SEP 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568765500002
DA 2024-07-18
ER

PT J
AU Si, WJ
   Wan, CX
   Zhang, CJ
AF Si, Weijian
   Wan, Chenxia
   Zhang, Chunjie
TI Towards an accurate radar waveform recognition algorithm based on dense
   CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Radar waveform recognition; Time frequency distribution; Convolutional
   neural network; Transfer learning
ID AUTOMATIC MODULATION CLASSIFICATION; NEURAL-NETWORKS; AUTOCORRELATION
AB Existing algorithms for radar waveform classification currently exhibit the lower recognition accuracy, especially at the lower signal to noise ratio (SNR) environment. To remedy these flaws, this paper proposes an accurate automatic modulation classification algorithm based on dense convolutional neural networks (AAMC-DCNN). The algorithm owns the competitive advantages of strengthening the feature reuse and extracting the detailed feature, for improving the recognition performance of radar waveform at the lower SNR. First, the dense convolutional neural networks (CNN) are designed, which connects each layer to every other layer in a feed-forward pattern. In the latter, 8 types of signals are converted into time-frequency images by choi-williams distribution (CWD), and the large training and testing datasets are fabricated. Then, the transfer learning and Adam optimization are introduced. Finally, the experimental analyses are carried out to evaluate the recognition performance. It is worth mentioning that the classification accuracy can be up to 93.4% when the SNR is -8 dB, and even reach to 100% at 0 dB, which demonstrates the superior performance over others. The present work provides a sound experimental basis for further studying automatic modulation classification for the sake of future field application in electronic warfare systems.
C1 [Si, Weijian; Wan, Chenxia; Zhang, Chunjie] Harbin Engn Univ, Coll Informat & Commun Engn, Harbin 150001, Peoples R China.
C3 Harbin Engineering University
RP Zhang, CJ (corresponding author), Harbin Engn Univ, Coll Informat & Commun Engn, Harbin 150001, Peoples R China.
EM zhangchunjie@hrbeu.edu.cn
FU National Natural Science Foundation of China [61671168, 61801143];
   National Natural Science Foundation of Heilongjiang Province
   [QC2016085]; Fundamental Research Funds for the Central Universities
   [HEUCFJ180801]
FX This work was financially supported in part by the National Natural
   Science Foundation of China (Grant No. 61671168 and 61801143), in part
   by the National Natural Science Foundation of Heilongjiang Province
   (Grant No. QC2016085), and in part by the Fundamental Research Funds for
   the Central Universities (Grant No. HEUCFJ180801).
CR Ayazgok S, 2018, IET RADAR SONAR NAV, V12, P466, DOI 10.1049/iet-rsn.2017.0354
   Cao R, 2019, MULTIMED TOOLS APPL, V78, P28953, DOI 10.1007/s11042-018-6134-y
   Caswell Hal, 2001, pi
   Gao JP, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8040463
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Guo Q, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11040540
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang Z, 2019, IEEE ACCESS, V7, P98653, DOI 10.1109/ACCESS.2019.2930250
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Key E. L., 2004, IEEE AEROSPACE ELECT, V19, P39, DOI DOI 10.1109/MAES.2004.1308837
   Kingma D. P., 2014, arXiv
   Kishore TR, 2017, IEEE T AERO ELEC SYS, V53, P901, DOI 10.1109/TAES.2017.2667142
   Kong SH, 2018, IEEE ACCESS, V6, P4207, DOI 10.1109/ACCESS.2017.2788942
   Hoang LM, 2019, IEEE T SIGNAL PROCES, V67, P3516, DOI 10.1109/TSP.2019.2918983
   Liu YJ, 2015, J SYST ENG ELECTRON, V26, P973, DOI 10.1109/JSEE.2015.00106
   Liu ZM, 2019, IEEE T AERO ELEC SYS, V55, P1624, DOI 10.1109/TAES.2018.2874139
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Lundén J, 2007, IEEE J-STSP, V1, P124, DOI 10.1109/JSTSP.2007.897055
   Ma ZY, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121419
   Noor A, 2020, MULTIMED TOOLS APPL, V79, P18553, DOI 10.1007/s11042-020-08657-4
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Qin ZJ, 2020, IEEE T COGN COMMUN, V6, P6, DOI 10.1109/TCCN.2019.2949279
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava RK, 2015, ADV NEUR IN, V28
   Wan J, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11050725
   Wang C, 2017, INT CONF ACOUST SPEE, P2437, DOI 10.1109/ICASSP.2017.7952594
   Wang F, 2019, IET RADAR SONAR NAV, V13, P998, DOI 10.1049/iet-rsn.2018.5549
   Wang Q, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107526
   Wang Q, 2019, SIGNAL PROCESS, V155, P259, DOI 10.1016/j.sigpro.2018.09.038
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wei SJ, 2020, IET RADAR SONAR NAV, V14, P803, DOI 10.1049/iet-rsn.2019.0436
   Wu ZL, 2017, IEEE ACCESS, V5, P19733, DOI 10.1109/ACCESS.2017.2746140
   Zhang J, 2018, IET RADAR SONAR NAV, V12, P244, DOI 10.1049/iet-rsn.2017.0265
   Zhang M, 2017, IEEE ACCESS, V5, P11074, DOI 10.1109/ACCESS.2017.2716191
   Zhang M, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9050075
   Zhang ZF, 2019, IEEE T SIGNAL INF PR, V5, P469, DOI 10.1109/TSIPN.2019.2900201
   Zhou RL, 2020, IEEE ACCESS, V8, P67366, DOI 10.1109/ACCESS.2020.2986330
   Zhu MT, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107393
   Zorzi S, 2019, IEEE T GEOSCI REMOTE, V57, P8255, DOI 10.1109/TGRS.2019.2919472
NR 41
TC 14
Z9 15
U1 3
U2 68
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 1779
EP 1792
DI 10.1007/s11042-020-09490-5
EA SEP 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568184100006
DA 2024-07-18
ER

PT J
AU Rezk, NG
   Hemdan, EE
   Attia, AF
   El-Sayed, A
   El-Rashidy, MA
AF Rezk, Nermeen Gamal
   Hemdan, Ezz El-Din
   Attia, Abdel-Fattah
   El-Sayed, Ayman
   El-Rashidy, Mohamed A.
TI An efficient IoT based smart farming system using machine learning
   algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Internet of things; Smart farming; Prediction;
   Drought; Crop productivity; And; Feature selection
ID PREDICTION
AB This paper suggests an IoT based smart farming system along with an efficient prediction method called WPART based on machine learning techniques to predict crop productivity and drought for proficient decision support making in IoT based smart farming systems. The crop productivity and drought predictions is very important to the farmers and agriculture's executives, which greatly help agriculture-affected countries around the world. Drought prediction plays a significant role in drought early warning to mitigate its impacts on crop productivity, drought prediction research aims to enhance our understanding of the physical mechanism of drought and improve predictability skill by taking full advantage of sources of predictability. In this work, an intelligent method based on the blend of a wrapper feature selection approach, and PART classification technique is proposed for crop productivity and drought predicting. Five datasets are used for estimating the proposed method. The results indicated that the projected method is robust, accurate, and precise to classify and predict crop productivity and drought in comparison with the existing techniques. From the results, the proposed method proved to be most accurate in providing drought prediction as well as the productivity of crops like Bajra, Soybean, Jowar, and Sugarcane. The WPART method attains the maximum accuracy compared to the existing supreme standard algorithms, it is obtained up to 92.51%, 96.77%, 98.04%, 96.12%, and 98.15% for the five datasets for drought classification, and crop productivity respectively. Likewise, the proposed method outperforms existing algorithms with precision, sensitivity, and F Score metrics.
C1 [Rezk, Nermeen Gamal; Attia, Abdel-Fattah] Kafrelsheikh Univ, Dept Comp Sci & Engn, Fac Engn, Kafrelsheikh, Egypt.
   [Hemdan, Ezz El-Din; El-Sayed, Ayman; El-Rashidy, Mohamed A.] Menoufia Univ, Dept Comp Sci & Engn, Fac Elect Engn, Menoufia, Egypt.
C3 Egyptian Knowledge Bank (EKB); Kafrelsheikh University; Egyptian
   Knowledge Bank (EKB); Menofia University
RP Hemdan, EE (corresponding author), Menoufia Univ, Dept Comp Sci & Engn, Fac Elect Engn, Menoufia, Egypt.
EM nermeenbarakaa@yahoo.com; ezzvip@yahoo.com; aheliel@eng.kfs.edu.eg;
   ayman.elsayed@el-eng.menofia.edu.eg;
   mohamed.elrashedy@el-eng.menofia.edu.eg
RI EL-SAYED, Ayman E./AFM-8547-2022; El-Rashidy, Mohamed/AAE-1211-2020
OI EL-SAYED, Ayman E./0000-0002-4437-259X; El-Rashidy,
   Mohamed/0000-0002-4699-4077; Attia, Abdel-Fattah/0000-0002-3621-5033
CR Agana NA, 2017, IEEE SOUTHEASTCON
   Amatya S, 2016, BIOSYST ENG, V146, P3, DOI 10.1016/j.biosystemseng.2015.10.003
   Ashok T, 2020, INTELLIGENT COMPUTIN
   Balakrishnan N., 2016, INT J COMPUT SCI SOF, V5, P148
   Bannerjee G., 2017, International Journal of Advanced Research in Computer Science and Software Engineering, V7, P665, DOI [DOI 10.23956/IJARCSSE/V7I5/0152, 10.23956/ijarcsse/V7I5/0152]
   Ben-Bassat M., 1982, Handbook of statistics, V2, P773, DOI DOI 10.1016/S0169-7161(82)02038-0
   Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5
   Brier ME, 2003, NEPHROL DIAL TRANSPL, V18, P2655, DOI 10.1093/ndt/gfg439
   Brown TS, 2012, AM J NEPHROL, V36, P561, DOI 10.1159/000345552
   Chen M, 2019, INT J COMPUTER SCI E
   Din IU, 2019, FUTURE GENER COMP SY, V100, P826, DOI 10.1016/j.future.2019.04.017
   El-Din HE, 2017, STUD BIG DATA, V25, P299, DOI 10.1007/978-3-319-53472-5_15
   ESSA YM, 2019, J MED SYST, V43
   Greaves A, 2015, No data
   Hemdan E. E. D., 2020, Deep Learning and Neural Networks: Concepts, Methodologies, Tools, and Applications
   Hemdan EE, 2018, LECT NOTE DATA ENG, V14, P39, DOI 10.1007/978-3-319-70688-7_2
   Iorkyase ET, 2019, IEEE T POWER DELIVER, V34, P1478, DOI 10.1109/TPWRD.2019.2907154
   Khalaf M, 2020, IEEE ACCESS, V8, P70375, DOI 10.1109/ACCESS.2020.2986090
   Khalaf M, 2018, IEEE C EVOL COMPUTAT, P230, DOI 10.1109/CEC.2018.8477904
   Kinderis M, 2018, BITCOIN CURRENCY FLU
   Kishore KVK, 2020, SMART TECHNOLOGIES D
   Liakos KG, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082674
   Mafarja MM, 2019, SOFT COMPUT, V23, P6249, DOI 10.1007/s00500-018-3282-y
   Mahbub M, 2020, INTERNET THINGS-NETH, V9, DOI 10.1016/j.iot.2020.100161
   Mondal MA, 2018, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE CONFLUENCE 2018 ON CLOUD COMPUTING, DATA SCIENCE AND ENGINEERING, P625, DOI 10.1109/CONFLUENCE.2018.8442535
   Moore J, 2005, 3RD INTERNATIONAL CONFERENCE ON AUTONOMIC COMPUTING, PROCEEDINGS, P155
   Morais R, 2019, COMPUT ELECTRON AGR, V162, P882, DOI 10.1016/j.compag.2019.05.028
   Muangprathub J, 2019, COMPUT ELECTRON AGR, V156, P467, DOI 10.1016/j.compag.2018.12.011
   PRAAGMAN J, 1985, EUR J OPER RES, V19, P144, DOI 10.1016/0377-2217(85)90321-2
   Punn M., 2013, INT J SCI REIJSR, V2, P363
   Varghese Reuben, 2018, 2018 Second International Conference on Intelligent Computing and Control Systems (ICICCS). Proceedings, P645, DOI 10.1109/ICCONS.2018.8663044
   VINCENT DR, 2019, SENSORS BASEL, V19
   Zikria YB, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082334
NR 33
TC 34
Z9 34
U1 3
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 773
EP 797
DI 10.1007/s11042-020-09740-6
EA SEP 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566043200005
DA 2024-07-18
ER

PT J
AU Rastgoo, R
   Kiani, K
   Escalera, S
AF Rastgoo, Razieh
   Kiani, Kourosh
   Escalera, Sergio
TI Hand pose aware multimodal isolated sign language recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sign language; Deep learning; Multimodal; Hand pose estimation; Scene
   flow
ID NEURAL-NETWORKS
AB Isolated hand sign language recognition from video is a challenging research area in computer vision. Some of the most important challenges in this area include dealing with hand occlusion, fast hand movement, illumination changes, or background complexity. While most of the state-of-the-art results in the field have been achieved using deep learning-based models, the previous challenges are not completely solved. In this paper, we propose a hand pose aware model for isolated hand sign language recognition using deep learning approaches from two input modalities, RGB and depth videos. Four spatial feature types: pixel-level, flow, deep hand, and hand pose features, fused from both visual modalities, are input to LSTM for temporal sign recognition. While we use Optical Flow (OF) for flow information in RGB video inputs, Scene Flow (SF) is used for depth video inputs. By including hand pose features, we show a consistent performance improvement of the sign language recognition model. To the best of our knowledge, this is the first time that this discriminant spatiotemporal features, benefiting from the hand pose estimation features and multi-modal inputs, are fused for isolated hand sign language recognition. We perform a step-by-step analysis of the impact in terms of recognition performance of the hand pose features, different combinations of the spatial features, and different recurrent models, especially LSTM and GRU. Results on four public datasets confirm that the proposed model outperforms the current state-of-the-art models on Montalbano II, MSR Daily Activity 3D, and CAD-60 datasets with a relative accuracy improvement of 1.64%, 6.5%, and 7.6%. Furthermore, our model obtains a competitive results on isoGD dataset with only 0.22% margin lower than the current state-of-the-art model.
C1 [Rastgoo, Razieh; Kiani, Kourosh] Semnan Univ, Dept Elect & Comp Engn, Semnan 3513119111, Iran.
   [Escalera, Sergio] Univ Barcelona, Dept Math & Informat, Barcelona 08007, Spain.
   [Escalera, Sergio] Comp Vis Ctr, Barcelona 08007, Spain.
C3 Semnan University; University of Barcelona; Centre de Visio per
   Computador (CVC)
RP Kiani, K (corresponding author), Semnan Univ, Dept Elect & Comp Engn, Semnan 3513119111, Iran.
EM rrastgoo@semnan.ac.ir; Kourosh.kiani@semnan.ac.ir; sergio@maia.ub.es
RI Rastgoo, Razieh/AFO-9957-2022; Kiani, Kourosh/T-7468-2019; Escalera,
   Sergio/L-2998-2015
OI Rastgoo, Razieh/0000-0001-7963-9461; Kiani, Kourosh/0000-0001-6582-8691;
   
FU Spanish project (MINECO/FEDER, UE) [PID2019-105093GB-I00]; CERCA
   Programme/Generalitat de Catalunya; ICREA under the ICREA Academia
   programme; High Intelligent Solution (HIS) company in Iran; NVIDIA
   Corporation
FX This work has been partially supported by the Spanish project
   PID2019-105093GB-I00 (MINECO/FEDER, UE) and CERCA Programme/Generalitat
   de Catalunya, and ICREA under the ICREA Academia programme and High
   Intelligent Solution (HIS) company in Iran. We gratefully acknowledge
   the support of NVIDIA Corporation with the donation of the Titan XP GPU
   used for this research. Also, we would like to thank the Deaf centers in
   Semnan and Tehran in Iran and Computer Vision Center (CVC) in Spain for
   their collaborations.
CR [Anonymous], 2016, INT JOINT C ART INT
   Asadi-Aghbolaghi M, 2017, IEEE INT CONF COMP V, P3179, DOI 10.1109/ICCVW.2017.376
   Avola D, 2019, IEEE T MULTIMEDIA, V21, P234, DOI 10.1109/TMM.2018.2856094
   Bin YR, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107410
   Camgoz Necati Cihan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10020, DOI 10.1109/CVPR42600.2020.01004
   Chen WY, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041074
   Cippitelli E, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/4351435
   Dabre K, 2014, 2014 INTERNATIONAL CONFERENCE ON CIRCUITS, SYSTEMS, COMMUNICATION AND INFORMATION TECHNOLOGY APPLICATIONS (CSCITA), P317, DOI 10.1109/CSCITA.2014.6839279
   Tran DS, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020722
   Ershadi-Nasab S, 2018, MULTIMED TOOLS APPL, V77, P15573, DOI 10.1007/s11042-017-5133-8
   Escalera S, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2522848.2532595
   García O, 2016, CLEM UNIV POWER SYST
   Gomez-Donoso F, 2019, EXPERT SYST APPL, V136, P327, DOI 10.1016/j.eswa.2019.06.055
   Guo H., 2017, ARXIV170707248
   Hosain AA, 2020, ARXIV200308753
   Jaimez M, 2015, IEEE INT CONF ROBOT, P98, DOI 10.1109/ICRA.2015.7138986
   Kim Y, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107462
   Köpüklü O, 2018, IEEE COMPUT SOC CONF, P2184, DOI 10.1109/CVPRW.2018.00284
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li LW, 2020, MULTIMED TOOLS APPL, V79, P6727, DOI 10.1007/s11042-019-08429-9
   Lim KM, 2019, MULTIMED TOOLS APPL, V78, P19917, DOI 10.1007/s11042-019-7263-7
   Lucas B. D., 1981, 7 INT JOINT C ART IN, V81, P674
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Oberweger M, 2015, ARXIV150206807V2
   Oberweger M, 2016, PROC CVPR IEEE, P4957, DOI 10.1109/CVPR.2016.536
   Paragios N, 2005, MATH MODELS COMPUTER, P39
   Rahim MA, 2020, MULTIMED TOOLS APPL, V79, P11813, DOI 10.1007/s11042-019-08448-6
   Rastgoo R, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.113794
   Rastgoo R, 2020, MULTIMED TOOLS APPL, V79, P22965, DOI 10.1007/s11042-020-09048-5
   Rastgoo R, 2020, EXPERT SYST APPL, V150, DOI 10.1016/j.eswa.2020.113336
   Rastgoo R, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20110809
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sarafianos N, 2016, COMPUT VIS IMAGE UND, V152, P1, DOI 10.1016/j.cviu.2016.09.002
   Shahroudy A, 2018, IEEE T PATTERN ANAL, V40, P1045, DOI 10.1109/TPAMI.2017.2691321
   Simon T, 2017, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2017.494
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Supancic JS, 2015, IEEE I CONF COMP VIS, P1868, DOI 10.1109/ICCV.2015.217
   Szczuko P, 2019, MULTIMED TOOLS APPL, V78, P29357, DOI 10.1007/s11042-019-7433-7
   Vedula S, 2015, IEEE T PATTERN ANAL, P475
   Wan J, 2016, IEEE COMPUT SOC CONF, P761, DOI 10.1109/CVPRW.2016.100
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang M, 2016, MEASUREMENT, V94, P734, DOI 10.1016/j.measurement.2016.09.018
   Zimmermann C, 2017, IEEE I CONF COMP VIS, P4913, DOI 10.1109/ICCV.2017.525
NR 45
TC 23
Z9 23
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 127
EP 163
DI 10.1007/s11042-020-09700-0
EA SEP 2020
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000565163400002
DA 2024-07-18
ER

PT J
AU Chen, JD
   Zhang, DF
   Nanehkaran, YA
AF Chen, Junde
   Zhang, Defu
   Nanehkaran, Y. A.
TI Identifying plant diseases using deep transfer learning and enhanced
   lightweight network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Plant disease identification; Transfer learning; Convolutional neural
   networks; Image classification
ID CLASSIFICATION; IDENTIFICATION
AB Plant diseases can cause significant reductions in both the quality and quantity of agricultural products, and they have a disastrous impact on the safety of food production. In severe cases, plant diseases may even lead to no grain harvest completely. Therefore, seeking fast, automatic, less expensive and accurate methods to detect plant diseases is of great realistic significance. In this paper, we studied the transfer learning for the deep CNNs and modified the network structure to enhance the learning ability of the tiny lesion symptoms. The pre-trained MobileNet-V2 was extended with the classification activation map (CAM), which was used for visualization as well as plant lesion positioning, and both were selected in our approach. Particularly, the transfer learning was performed twice in model training: the first phase only inferred the weights from scratch for new extended layers while the bottom convolution layers were frozen with the parameters trained from ImageNet; the second phase retrained the weights using the target dataset by loading the model trained in the first phase. Then, the yielded optimum model was used for identifying plant diseases. Experimental results demonstrate the validity of the proposed approach. It achieves an average recognition accuracy of 99.85% on the public dataset. Even under multiple classes and complex background conditions, the average accuracy reaches 99.11% on the collected plant disease images. Thus, the proposed approach efficiently accomplished plant disease identification and presented a superior performance relative to other state-of-the-art methods.
C1 [Chen, Junde; Zhang, Defu; Nanehkaran, Y. A.] Xiamen Univ, Sch Informat, Xiamen 361005, Peoples R China.
C3 Xiamen University
RP Zhang, DF (corresponding author), Xiamen Univ, Sch Informat, Xiamen 361005, Peoples R China.
EM dfzhang@xmu.edu.cn
RI Nanehkaran, Yaser Ahangari/AAN-6150-2021
OI Nanehkaran, Yaser Ahangari/0000-0002-8055-3195; Chen,
   Junde/0000-0003-1748-4374
FU National Natural Science Foundation of China [61672439]; Fundamental
   Research Funds for the Central Universities [20720181004]
FX This work is partly supported by the grants from the National Natural
   Science Foundation of China (Project no. 61672439) and the Fundamental
   Research Funds for the Central Universities (#20720181004). The authors
   would like to thank all the editors and anonymous reviewers for their
   constructive advice.
CR Adeel A, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12569
   Adeel A, 2019, SUSTAIN COMPUT-INFOR, V24, DOI 10.1016/j.suscom.2019.08.002
   Alghamdi A, 2024, MULTIMED TOOLS APPL, V83, P14913, DOI 10.1007/s11042-020-08769-x
   Amara J., 2017, DATENBANKSYSTEME BUS
   Anthonys G, 2009, 2009 INT C IND INF S
   Arsenovic M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11070939
   Aurangzeb K, 2020, 2020 6 C DAT SCI MAC
   Barbedo JGA, 2018, BIOSYST ENG, V172, P84, DOI 10.1016/j.biosystemseng.2018.05.013
   Brahimi M, 2017, APPL ARTIF INTELL, V31, P299, DOI 10.1080/08839514.2017.1315516
   Durmus H, 2017, INT CONF AGRO-GEOINF, P46
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Fina F, 2013, INT J ADV BIOTECHNOL, V4, P189
   Ghazi MM, 2017, NEUROCOMPUTING, V235, P228, DOI 10.1016/j.neucom.2017.01.018
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hemming J, 2001, J AGR ENG RES, V78, P233, DOI 10.1006/jaer.2000.0639
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hughes D., 2015, ABS151108060 CORR
   Kahar M. A., 2015, P 17 INT C MATH COMP, P248
   Kamal KC, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104948
   Khan MA, 2020, MULTIMED TOOLS APPL, V79, P18627, DOI 10.1007/s11042-020-08726-8
   Khan MA, 2019, IEEE ACCESS, V7, P46261, DOI 10.1109/ACCESS.2019.2908040
   King DB, 2015, ACS SYM SER, V1214, P1
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Kusumo BS, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P93, DOI 10.1109/IC3INA.2018.8629507
   Li C., 2011, Journal of Agricultural Mechanization Research, V6
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Nestor T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010083
   nvidia.com/en, GEFORCE GTX 106
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Rangarajan AK, 2018, PROCEDIA COMPUT SCI, V133, P1040, DOI 10.1016/j.procs.2018.07.070
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Safdar A, 2019, MICROSC RES TECHNIQ, V82, P1542, DOI 10.1002/jemt.23320
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sethy PK, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105527
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Sifre L., 2014, THESIS, V1, P3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/8141259
   Wang XL, 2017, J INDIAN SOC REMOTE, V45, P785, DOI 10.1007/s12524-016-0638-6
   Zhang XH, 2018, IEEE ACCESS, V6, P30370, DOI 10.1109/ACCESS.2018.2844405
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
NR 45
TC 48
Z9 50
U1 0
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31497
EP 31515
DI 10.1007/s11042-020-09669-w
EA AUG 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000561518100003
DA 2024-07-18
ER

PT J
AU Hassaballah, M
   Alshazly, HA
   Ali, AA
AF Hassaballah, M.
   Alshazly, H. A.
   Ali, Abdelmgeid A.
TI Robust local oriented patterns for ear recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Ear recognition; Features extraction; Local image
   descriptors; Local binary patterns
ID INVARIANT TEXTURE CLASSIFICATION; FACE RECOGNITION; HANDCRAFTED
   FEATURES; INFORMATION; BIOMETRICS; SCALE
AB Extraction and description of image features is an active research topic and important for several applications of computer vision field. This paper presents a new noise-tolerant and rotation-invariant local feature descriptor called robust local oriented patterns (RLOP). The proposed descriptor extracts local image structures utilizing edge directional information to provide rotation-invariant patterns and to be effective in noise and changing illumination situations. This is achieved by a non-linear amalgamation of two specific strategies; binarizing neighborhood pixels of a patch and assigning binomial weights in the same formula. In the encoding methodology, the neighboring pixels is binarized with respect to the mean value of pixels in an image patch of size 3 x 3 instead of the center pixel. Thus, the obtained codes are rotation-invariant and more robust against noise and other non-monotonic grayscale variations. Ear recognition is considered as the representative problem, where the ear involves localized patterns and textures. The proposed descriptor encodes all images' pixels and the resulting RLOP-encoded image is divided into several regions. Histograms of the regions are constructed to estimate the distribution of features. Then, all histograms are concatenated together to form the final descriptor. The robustness and effectiveness of the proposed descriptor are evaluated through conducting several identification and verification experiments on four different ear databases: IIT Delhi-I, IIT Delhi-II, AMI, and AWE. It is observed that the proposed descriptor outperforms the state-of-the-art texture based approaches achieving a recognition rate of 98% on the average providing the best performance among the tested descriptors.
C1 [Hassaballah, M.] South Valley Univ, Fac Comp & Informat, Dept Comp Sci, Qena, Egypt.
   [Alshazly, H. A.] South Valley Univ, Fac Sci, Dept Math, Qena 83523, Egypt.
   [Ali, Abdelmgeid A.] Minia Univ, Fac Sci, Dept Comp Sci, Al Minya 61519, Egypt.
C3 Egyptian Knowledge Bank (EKB); South Valley University Egypt; Egyptian
   Knowledge Bank (EKB); South Valley University Egypt; Egyptian Knowledge
   Bank (EKB); Minia University
RP Hassaballah, M (corresponding author), South Valley Univ, Fac Comp & Informat, Dept Comp Sci, Qena, Egypt.
EM m.hassaballah@svu.edu.eg; hammam.alshazly@sci.svu.edu.eg;
   dr_abdelmgeid@mu.edu.eg
RI Hassaballah, Mahmoud/A-5197-2018; Alshazly, Hammam/T-8666-2019
OI Hassaballah, Mahmoud/0000-0001-5655-8511; Alshazly,
   Hammam/0000-0002-9942-8642
CR Abaza A, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2431211.2431221
   Al Rahhal MM, 2018, IEEE ACCESS, V6, P11883, DOI 10.1109/ACCESS.2018.2810339
   Al Rahhal MM, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.1.013007
   Alagarsamy SB, 2019, MULTIMED TOOLS APPL, P1
   Alshazly H. A., 2018, INT C ADV INT SYST I, P435
   Awad AI, 2016, STUD COMPUT INTELL, V630, P1, DOI 10.1007/978-3-319-28854-3
   Benzaoui A, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.5.053008
   Cao K, 2019, IEEE T PATTERN ANAL, V41, P788, DOI 10.1109/TPAMI.2018.2818162
   Chakraborti T, 2018, IEEE SIGNAL PROC LET, V25, P635, DOI 10.1109/LSP.2018.2817176
   Chatterjee A, 2019, OPT LASER TECHNOL, V112, P368, DOI 10.1016/j.optlastec.2018.11.043
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Chowdhury DP, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0855-8
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Damer N., 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P21, DOI 10.1109/IIH-MSP.2012.12
   Das A, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P742, DOI 10.1109/BTAS.2017.8272764
   Dodge S, 2018, IET BIOMETRICS, V7, P207, DOI 10.1049/iet-bmt.2017.0208
   Doghmane H, 2019, INT J BIOMETRICS, V11, P50, DOI 10.1504/IJBM.2019.10016808
   Dubey SR, 2020, MULTIMED TOOLS APPL, V79, P6363, DOI 10.1007/s11042-019-08370-x
   El-Naggar Susan, 2016, 2016 IEEE S TECHNOLO, P1, DOI DOI 10.1109/THS.2016.7568939
   Emeri Meden B, 2019, NEURAL COMPUT APPL, P1
   Emersic Z, 2017, INT C WORKSH BIOINSP, P1, DOI DOI 10.1109/IW0BI.2017.7985520
   Emersic Z, 2017, NEUROCOMPUTING, V255, P26, DOI 10.1016/j.neucom.2016.08.139
   Fathi A, 2012, PATTERN RECOGN LETT, V33, P1093, DOI 10.1016/j.patrec.2012.01.017
   Fu X, 2019, ATMOS CHEM PHYS, V19, P1, DOI 10.5194/acp-19-1-2019
   Ghoualmi L, 2016, EXPERT SYST APPL, V57, P49, DOI 10.1016/j.eswa.2016.03.004
   Guei AC, 2018, PROC SPIE, V10652, DOI 10.1117/12.2304814
   Guo YM, 2008, IEEE IMAGE PROC, P289, DOI 10.1109/ICIP.2008.4711748
   Hansley EE, 2018, IET BIOMETRICS, V7, P215, DOI 10.1049/iet-bmt.2017.0210
   Hassaballah M, 2019, EXPERT SYST APPL, V118, P182, DOI 10.1016/j.eswa.2018.10.007
   Hassaballah M, 2016, STUD COMPUT INTELL, V630, P1, DOI 10.1007/978-3-319-28854-3_1
   Hassaballah M, 2015, IET COMPUT VIS, V9, P614, DOI 10.1049/iet-cvi.2014.0084
   Hassaballah M., 2019, Recent Advances in Computer Vision: Theories and Applications
   Hezil N, 2017, IET BIOMETRICS, V6, P351, DOI 10.1049/iet-bmt.2016.0072
   Jabid T, 2010, ETRI J, V32, P784, DOI 10.4218/etrij.10.1510.0132
   Kumar A, 2012, PATTERN RECOGN, V45, P956, DOI 10.1016/j.patcog.2011.06.005
   Kyrki V, 2004, PATTERN RECOGN LETT, V25, P311, DOI 10.1016/j.patrec.2003.10.008
   Larrain T, 2017, IEEE T INF FOREN SEC, V12, P1646, DOI 10.1109/TIFS.2017.2680403
   Liu L, 2019, INT J COMPUT VISION, V127, P74, DOI 10.1007/s11263-018-1125-z
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Galdámez PL, 2017, J APPL LOGIC, V24, P62, DOI 10.1016/j.jal.2016.11.014
   Nanni L, 2017, PATTERN RECOGN, V71, P158, DOI 10.1016/j.patcog.2017.05.025
   Nejati H, 2012, INT C PATT RECOG, P1201
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, INT C PATT RECOG, P3596
   Omara I., 2018, INT C BIOM ENG APPL, P69
   Omara I, 2018, IET BIOMETRICS, V7, P557, DOI 10.1049/iet-bmt.2017.0087
   Pan ZB, 2019, EXPERT SYST APPL, V120, P319, DOI 10.1016/j.eswa.2018.11.041
   Pflug A, 2012, IET BIOMETRICS, V1, P114, DOI 10.1049/iet-bmt.2011.0003
   Pflug A, 2014, IEEE INT JOINT C BIO, P1
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Rathgeb C, 2016, IET BIOMETRICS, V5, P252, DOI 10.1049/iet-bmt.2015.0098
   Regouid M, 2019, MULTIMED TOOLS APPL, P1
   Sarangi PP, 2018, MULTIMED TOOLS APPL, P1
   Sepas-Moghaddam A, 2018, IET BIOMETRICS, V7, P224, DOI 10.1049/iet-bmt.2017.0204
   Tian L, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P437, DOI 10.1109/CISP-BMEI.2016.7852751
   Unar JA, 2014, PATTERN RECOGN, V47, P2673, DOI 10.1016/j.patcog.2014.01.016
   Vu NS, 2010, LECT NOTES COMPUT SC, V6311, P313
   Yan P, 2007, IEEE T PATTERN ANAL, V29, P1297, DOI 10.1109/TPAMI.2007.1067
   Youbi Z, 2018, MULTIMED TOOLS APPL, P1
   Yuan L, 2012, PATTERN RECOGN LETT, V33, P182, DOI 10.1016/j.patrec.2011.09.041
NR 61
TC 24
Z9 25
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31183
EP 31204
DI 10.1007/s11042-020-09456-7
EA AUG 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560998800005
DA 2024-07-18
ER

PT J
AU Yang, CS
   Zhu, CQ
   Wang, YY
   Rui, T
   Zhu, JW
   Ding, KM
AF Yang, Chengsong
   Zhu, Changqing
   Wang, Yingying
   Rui, Ting
   Zhu, Jingwei
   Ding, Kaimeng
TI A Robust Watermarking Algorithm for Vector Geographic Data Based on Qim
   and Matching Detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Composite attack; Digital watermarking; Matching detection; Robustness;
   Vector geographic data
ID DIGITAL WATERMARKING
AB Vector geographic data are the fundamental achievements of national information infrastructure, and they play an important role in society's development. How to protect the copyright of vector geographic data has become a popular issue in the age of big data, and digital watermarking technology can be used to solve this problem. In this paper, a robust and blind watermarking algorithm for vector geographic data is proposed based on the technology of coordinate mapping and matching detection. First, the basic principle for resisting data translation based on quantization index modulation (QIM) and matching detection was analyzed. Second, a watermarking algorithm for vector geographic data was designed based on coordinate mapping, QIM and matching detection. Finally, we performed experiments to test the robustness and adaptability of the proposed algorithm. The experimental results show that the proposed watermarking algorithm is not only robust against the watermarking attacks of data compression, data adding, data deleting, data cropping, feature deleting and data translation but also against composite attack. The proposed algorithm is also suitable for small vector geographic datasets such as point-based data.
C1 [Yang, Chengsong; Rui, Ting; Zhu, Jingwei] Army Engn Univ PLA, Inst Field Engn, Nanjing 210007, Peoples R China.
   [Zhu, Changqing] Nanjing Normal Univ, Key Lab Virtual Geog Environm, Minist Educ, Nanjing 210023, Peoples R China.
   [Wang, Yingying; Ding, Kaimeng] Jinling Inst Technol, Coll Intelligent Sci & Control Engn, Nanjing 211169, Peoples R China.
C3 Army Engineering University of PLA; Nanjing Normal University; Jinling
   Institute of Technology
RP Zhu, CQ (corresponding author), Nanjing Normal Univ, Key Lab Virtual Geog Environm, Minist Educ, Nanjing 210023, Peoples R China.; Wang, YY (corresponding author), Jinling Inst Technol, Coll Intelligent Sci & Control Engn, Nanjing 211169, Peoples R China.
EM ycsdongshang@163.com; chqzhu88@163.com; wyychs@163.com
RI Ding, Kaimeng/GWQ-3519-2022; wang, yi/HOF-6668-2023; wang,
   yi/GVT-8516-2022; wang, yan/GSE-6489-2022; wang, yan/JBJ-7462-2023;
   Wang, Ying/HJI-2509-2023; wang, yingying/GRS-3058-2022; Wang,
   Yingying/HOA-6227-2023; wang, yingying/JCE-4984-2023
FU National Natural Science Foundation of China [41401518, 41801303];
   Natural Science Foundation of Jiangsu Province [BK20140066, BK20170116]
FX The work was supported by the National Natural Science Foundation of
   China (grant No. 41401518 and No. 41801303), the Natural Science
   Foundation of Jiangsu Province (grant No. BK20140066 and No.
   BK20170116).
CR Abubahia A, 2015, LECT NOTES COMPUT SC, V9097, P133, DOI 10.1007/978-3-319-19069-3_9
   Van BN, 2017, J INF PROCESS SYST, V13, P68, DOI 10.3745/JIPS.03.0059
   Benoraira A, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0239-5
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Cox I. J., 2002, Digital Watermarking
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Guo YF, 2018, IEEE T IMAGE PROCESS, V27, P3387, DOI 10.1109/TIP.2018.2815181
   Hwan Il K, 2002, P INT C INF TECH COD, P234
   Jungyeop Kim, 2011, Proceedings of the 2011 7th International Conference on Digital Content, Multimedia Technology and its Applications (IDCTA 2011), P154
   Lee SH, 2013, MULTIMED TOOLS APPL, V63, P757, DOI 10.1007/s11042-011-0894-y
   [李强 Li Qiang], 2011, [测绘科学, Science of Surveying and Mapping], V36, P119
   Li YY, 2003, ICCIMA 2003: FIFTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, PROCEEDINGS, P424
   Neyman S.N., 2014, Telecommun. Comput. Electron. Control, V12, P367
   Niu XM, 2006, INT J INNOV COMPUT I, V2, P1301
   Niu Y, 2010, KEY ENG MATER, V439-440, P652, DOI 10.4028/www.scientific.net/KEM.439-440.652
   Ohbuchi R, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P577, DOI 10.1109/ICME.2002.1035847
   Peng ZY, 2015, MULTIMED TOOLS APPL, V74, P11721, DOI 10.1007/s11042-014-2259-9
   Shao CY, 2006, IEICE T INF SYST, VE89D, P1290, DOI 10.1093/ietisy/e89-d.3.1290
   Solachidis V, 2000, INT CONF ACOUST SPEE, P1955, DOI 10.1109/ICASSP.2000.859213
   Voigt M, 2002, P SOC PHOTO-OPT INS, V4675, P621, DOI 10.1117/12.465322
   Voigt M, 2004, P 2004 MULT SEC WORK, P160, DOI DOI 10.1145/1022431.1022459
   Wang CJ, 2012, MULTIMED TOOLS APPL, V57, P67, DOI 10.1007/s11042-010-0536-9
   Wang Yun-fei, 2012, Computer Engineering, V38, P111, DOI 10.3969/j.issn.1000-3428.2012.22.027
   Yan HW, 2017, EARTH SCI INFORM, V10, P471, DOI 10.1007/s12145-017-0310-x
   Yang Chengsong, 2011, Geomatics and Information Science of Wuhan University, V36, P1402
   [杨成松 Yang Chengsong], 2011, [测绘学报, Acta Geodetica et Cartographica Sinica], V40, P256
   Zhang LM, 2016, J GEOM, V41, P32, DOI [10.14188/J.2095-6045.2016.05.008, DOI 10.14188/J.2095-6045.2016.05.008]
   Zhou X, 2006, INT J COMPUT SCI NET, V6, P202
NR 29
TC 12
Z9 15
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30709
EP 30733
DI 10.1007/s11042-020-08916-4
EA AUG 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560297300006
DA 2024-07-18
ER

PT J
AU Santhos, KA
   Kumar, A
   Bajaj, V
   Singh, GK
AF Santhos, Kumar A.
   Kumar, A.
   Bajaj, V.
   Singh, G. K.
TI McCulloch's algorithm inspired cuckoo search optimizer based
   mammographic image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mammogram; Pectoral muscle and breast segmentation; Multi-level
   thresholding; Nature inspired algorithms; Otsu and Kapur's technique
ID PECTORAL MUSCLE SEGMENTATION; MASSES
AB Multi-level thresholding for mammogram image segmentation leads to much better sub-sections of the intensity span, and hence very useful in breast cancer detection. In order to segment the mammogram image efficiently, in this paper, three popular nature inspired algorithms namely Harmony Search Algorithm (HSA), Electro-magnetism Optimization (EMO) and McCulloch's Algorithm inspired Cuckoo Search Optimization algorithm (MACSO) are studied in detail; and are employed for desired cost function maximization for two well-known multi-level thresholding methods like Otsu and Kapur efficiently. The proposed approach is applied to all the 322 test images of database presented by Mammographic Image Analysis Society (MIAS), to detect pectoral muscle, breast and suspicious mass efficiently. Performance of EMO, MACSO and HSA were analysed using measures like best fitness, MSE, PSNR, SSIM and TIME. From the experimental results, it is concluded that MACSO with Otsu was found to be robust for segmentation of mammogram images accurately.
C1 [Santhos, Kumar A.; Kumar, A.; Bajaj, V.] PDPM Indian Inst Informat Technol Design & Mfg, Jabalpur 482005, India.
   [Singh, G. K.] Indian Inst Technol Roorkee, Dept Elect Engn, Roorkee 247667, Uttarakhand, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur; Indian Institute of Technology System (IIT System); Indian
   Institute of Technology (IIT) - Roorkee
RP Santhos, KA (corresponding author), PDPM Indian Inst Informat Technol Design & Mfg, Jabalpur 482005, India.
EM hymavathisanthu@gmail.com; anilkdee@gmail.com;
   bajajvarun056@yahoo.co.in; gksnfee@gmail.com
RI A, SANTHOS KUMAR/ITV-1034-2023; Bajaj, Varun/AAP-4660-2020; Boothapati,
   Anil Kumar/HHS-1813-2022; Kumar, Anil/Q-6680-2016; KUMAR,
   ANIL/ACD-8340-2022; Kumar, Anil/HJB-2850-2022
OI Bajaj, Varun/0000-0002-8721-1219; Kumar, Anil/0000-0002-3945-4646;
   Kumar, Anil/0000-0002-5817-5829; A, Dr. SANTHOS
   KUMAR/0000-0003-0765-5096
CR [Anonymous], 1994, DIGITAL MAMMO, DOI DOI 10.1007/S11999-016-4732-4
   [Anonymous], 2000, P 5 INT WORKSH DIG M
   Avuti SK, 2019, BIOMED ENG LETT, V9, P481, DOI 10.1007/s13534-019-00135-7
   Bhandari AK, 2016, EXPERT SYST APPL, V63, P112, DOI 10.1016/j.eswa.2016.06.044
   Bhandari AK, 2014, EXPERT SYST APPL, V41, P3538, DOI 10.1016/j.eswa.2013.10.059
   Birbil SI, 2003, J GLOBAL OPTIM, V25, P263, DOI 10.1023/A:1022452626305
   CHAMBERS JM, 1976, J AM STAT ASSOC, V71, P340, DOI 10.2307/2285309
   Cowan E.W., 1968, Basic Electromagnetism
   Dey S, 2016, APPL SOFT COMPUT, V46, P677, DOI 10.1016/j.asoc.2015.09.042
   Ferrari RJ, 2001, IWDM 2000: 5TH INTERNATIONAL WORKSHOP ON DIGITAL MAMMOGRAPHY, P573
   GUPTA R, 1995, PHYS MED BIOL, V40, P835, DOI 10.1088/0031-9155/40/5/009
   Hatanaka Y, 2001, IEEE T MED IMAGING, V20, P1209, DOI 10.1109/42.974916
   Horng MH, 2011, EXPERT SYST APPL, V38, P13785, DOI 10.1016/j.eswa.2011.04.180
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Karnan M, 2007, COMPUT METH PROG BIO, V87, P12, DOI 10.1016/j.cmpb.2007.04.007
   Karssemeijer N, 1998, PHYS MED BIOL, V43, P365, DOI 10.1088/0031-9155/43/2/011
   Kumar AS, 2018, PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P160, DOI 10.1109/ICCSP.2018.8524302
   Kwok SM, 2004, IEEE T MED IMAGING, V23, P1129, DOI 10.1109/TMI.2004.830529
   Leccardi M, 2005, P 5 EUR NONL DYN C
   Maitra IK, 2011, TECHNIQUE PREPROCES
   Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, P21, DOI 10.1016/1047-3203(90)90014-M
   Moghbel M, 2020, ARTIF INTELL REV, V53, P1873, DOI 10.1007/s10462-019-09721-8
   Mustra M, 2013, SIGNAL PROCESS, V93, P2817, DOI 10.1016/j.sigpro.2012.07.026
   Oliva D, 2014, NEUROCOMPUTING, V139, P357, DOI 10.1016/j.neucom.2014.02.020
   Oliva D, 2013, J APPL MATH, DOI 10.1155/2013/575414
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ouadfel S, 2016, EXPERT SYST APPL, V55, P566, DOI 10.1016/j.eswa.2016.02.024
   PAL SK, 1994, PATTERN RECOGN LETT, V15, P261, DOI 10.1016/0167-8655(94)90058-2
   Raba D, 2005, LECT NOTES COMPUT SC, V3523, P471
   Rampun A, 2019, MED IMAGE ANAL, V57, P1, DOI 10.1016/j.media.2019.06.007
   Saha PK, 2001, IEEE T MED IMAGING, V20, P792, DOI 10.1109/42.938247
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Shen RB, 2018, J DIGIT IMAGING, V31, P680, DOI 10.1007/s10278-018-0068-9
   Singh H, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P431, DOI 10.1109/SPIN.2017.8049988
   Singh H, 2019, COMPUT ELECTR ENG, V75, P245, DOI 10.1016/j.compeleceng.2017.11.014
   Suresh S, 2016, EXPERT SYST APPL, V58, P184, DOI 10.1016/j.eswa.2016.03.032
   Taghanaki SA, 2017, IEEE T BIO-MED ENG, V64, P2662, DOI 10.1109/TBME.2017.2649481
   Tomas J.S., 2011, THESIS
   TSAI WH, 1985, COMPUT VISION GRAPH, V29, P377, DOI 10.1016/0734-189X(85)90133-1
   Tzikopoulos SD, 2011, COMPUT METH PROG BIO, V102, P47, DOI 10.1016/j.cmpb.2010.11.016
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Yapa R.D., 2007, INT J BIOL LIFE SCI, V3, P54
   Yin KM, 2019, INT J COMPUT ASS RAD, V14, P237, DOI 10.1007/s11548-018-1867-7
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 45
TC 4
Z9 5
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30453
EP 30488
DI 10.1007/s11042-020-09310-w
EA AUG 2020
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000559953900011
DA 2024-07-18
ER

PT J
AU Cheng, Q
   Wang, GD
   Dong, Q
   Wei, B
AF Cheng, Qi
   Wang, Guodong
   Dong, Qian
   Wei, Bin
TI Arbitrary-shaped text detection with adaptive convolution and path
   enhancement pyramid network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arbitrary shapes text detection; Adaptive convolution; Backbone network;
   Feature pyramid network; Multi-scale
AB Recently, scene text detection has become an active research field, which is an essential component of scene text reading. Especially, segmentation-based methods are commonly used, since the segmentation results can describe text of arbitrary shape. However, curve texts have a diversity of shapes, scales and orientations, which are difficult to locate, so the detector requires to adjust the local receptive fields size adaptively, which can aggregate multi-scale spatial information to accurately locate the curve text instance. Moreover, the low-level features are critical for localizing large text instances. When using Feature Pyramid Network (FPN) for multi-scale feature fusion, it will prevent the flow of accurate localization signals due to the long path from low-level to top-level. In order to solve these two problems, this paper proposes an Adaptive Convolution and Path Enhancement Pyramid Network (ACPEPNet), which can more accurately locate the text instances with arbitrary shapes. Firstly, an Adaptive Convolution Unit is introduced to improve the ability of backbone to aggregate multi-scale spatial information at the same stage. Specially, this unit is a lightweight component and without the cost of computations, based on this component we present a backbone network for text features extraction. Secondly, the original FPN structure is redesigned to build a short path from the low-level to top-level, in this way, we modify the path from one-way flow to two-way flow and add original features to the final stage of information fusion. Experiments on CTW1500, Total-Text, ICDAR 2015 and MSRA-TD500 validate the robustness of the proposed method. When there is no bells and whistles, this method achieves an F-measure of 80.8% without external training data on CTW1500.
C1 [Cheng, Qi; Wang, Guodong] Qingdao Univ, Coll Comp Sci & Technol, Qingdao, Peoples R China.
   [Dong, Qian] Qingdao Univ, Dept Pediat Surg, Affiliated Hosp, Qingdao, Peoples R China.
   [Wei, Bin] Qingdao Univ, Shandong Key Lab Digital Med & Comp Assisted Surg, Affiliated Hosp, Qingdao, Peoples R China.
C3 Qingdao University; Qingdao University; Qingdao University
RP Wang, GD (corresponding author), Qingdao Univ, Coll Comp Sci & Technol, Qingdao, Peoples R China.
EM doctorwgd@gmail.wm
FU Natural Science Foundation of Shandong Province [ZR2019MF050]; Shandong
   Province colleges and universities youth innovation technology plan
   innovation team project [2020KJN011]
FX This work is supported by the Natural Science Foundation of Shandong
   Province (ZR2019MF050), the Shandong Province colleges and universities
   youth innovation technology plan innovation team project under Grant
   (No.2020KJN011).
CR Bai Nong, 2016, ARXIV160609002
   Ch'ng CK, 2017, PROC INT CONF DOC, P935, DOI 10.1109/ICDAR.2017.157
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Chen XL, 2019, IEEE I CONF COMP VIS, P2061, DOI 10.1109/ICCV.2019.00215
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Deng D, 2018, AAAI CONF ARTIF INTE, P6773
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He P, 2017, IEEE I CONF COMP VIS, P3066, DOI 10.1109/ICCV.2017.331
   He WH, 2017, IEEE I CONF COMP VIS, P745, DOI 10.1109/ICCV.2017.87
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Hu H, 2017, IEEE I CONF COMP VIS, P4950, DOI 10.1109/ICCV.2017.529
   Hu SY, 2020, MULTIMED TOOLS APPL, V79, P1427, DOI 10.1007/s11042-019-08241-5
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang ZJ, 2019, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2019.00657
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Liao MH, 2018, PROC CVPR IEEE, P5909, DOI 10.1109/CVPR.2018.00619
   Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107
   Liao MH, 2017, AAAI CONF ARTIF INTE, P4161
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu Yuliang, 2017, Detecting Curve Text in the Wild: New Dataset and New Solution
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Long SB, 2018, LECT NOTES COMPUT SC, V11206, P19, DOI 10.1007/978-3-030-01216-8_2
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Lyu PY, 2018, PROC CVPR IEEE, P7553, DOI 10.1109/CVPR.2018.00788
   Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020
   Mateos LA, 2019, IEEE INT CONF ROBOT, P7933, DOI [10.1109/icra.2019.8793525, 10.1109/ICRA.2019.8793525]
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Nair V, 2010, P ICML, V807-814
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shi BG, 2017, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2017.371
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Tan M., 2020, INT C MACH LEARN, DOI DOI 10.48550/ARXIV.1905.11946
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4
   Wang YJ, 2020, MULTIMED TOOLS APPL, V79, P1057, DOI 10.1007/s11042-019-08208-6
   Wang YJ, 2019, MULTIMED TOOLS APPL, V78, P19945, DOI 10.1007/s11042-019-7377-y
   Xie EZ, 2019, AAAI CONF ARTIF INTE, P9038
   Yao C, 2014, IEEE T IMAGE PROCESS, V23, P4737, DOI 10.1109/TIP.2014.2353813
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Zhang Z, 2016, PROC CVPR IEEE, P4159, DOI 10.1109/CVPR.2016.451
   Zheng Q, 2019, P ICCV, P6718
   Zhou X, 2017, IEEE IMAGE PROC, P555, DOI 10.1109/ICIP.2017.8296342
NR 54
TC 3
Z9 3
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29225
EP 29242
DI 10.1007/s11042-020-09440-1
EA AUG 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559626400002
DA 2024-07-18
ER

PT J
AU Cheng, JR
   Xie, LY
   Tang, XY
   Xiong, NX
   Liu, BY
AF Cheng, Jieren
   Xie, Luyi
   Tang, Xiangyan
   Xiong, Naixue
   Liu, Boyi
TI A survey of security threats and defense on Blockchain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Security; Multimedia; Anonymity; Selfish mining
ID KEY MANAGEMENT; BITCOIN; EFFICIENT; ATTACKS; DEDUPLICATION
AB Blockchain provides a trusted environment for storing information and propagating transactions. Owing to the distributed property and integrity, blockchain has been employed in various domains. However, lots of studies prove that the security mechanism of blockchain exposes its vulnerability especially when the blockchain suffers attacks. This work provides a systematic summary of the security threats and countermeasures on blockchain. We first review the working procedure and its implementation techniques. We then summarize basic security properties of blockchain. From the view of the blockchain's architecture, we describe security threats of blockchain, including weak anonymity, vulnerability of P2P network, consensus mechanism, incentive mechanism and smart contract. We then describe the related attacks and summarize the current representative countermeasures which improve anonymity and robustness against security threats respectively. Finally, we also put forward future research directions on consensus, incentive mechanisms, privacy preservation and encryption algorithm to further enhance security and privacy of the blockchain-based multimedia.
C1 [Cheng, Jieren; Xie, Luyi; Tang, Xiangyan] Hainan Univ, Sch Compute Sci & Cyberspace Secur, Haikou 570228, Hainan, Peoples R China.
   [Cheng, Jieren] Hainan Blockchain Technol Engn Res Ctr, Haikou 570228, Hainan, Peoples R China.
   [Tang, Xiangyan] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.
   [Xiong, Naixue] Northeastern State Univ, Dept Math & Comp Sci, Tahlequah, OK USA.
   [Liu, Boyi] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
C3 Hainan University; Tianjin University; Chinese Academy of Sciences;
   Shenzhen Institute of Advanced Technology, CAS
RP Xie, LY (corresponding author), Hainan Univ, Sch Compute Sci & Cyberspace Secur, Haikou 570228, Hainan, Peoples R China.
EM acaxly@163.com
RI xiong, naixue/M-4277-2019
OI xiong, naixue/0000-0002-0394-4635
FU Hainan Provincial Natural Science Foundation of China [2019RC041,
   2019RC098]; National Natural Science Foundation of China [61762033]
FX This work was supported by the Hainan Provincial Natural Science
   Foundation of China (Grant No. 2019RC041 and 2019RC098); National
   Natural Science Foundation of China (Grant No. 61762033).
CR Androulaki E., 2013, LNCS, P34, DOI [DOI 10.1007/978-3-642-39884-1, 10.1007/978-3-642-39884-1_4, DOI 10.1007/978-3-642-39884-1_4]
   [Anonymous], 2017, SMART CONTRACTS MAKE
   Apostolaki M, 2017, P IEEE S SECUR PRIV, P375, DOI 10.1109/SP.2017.29
   Atzei N, 2017, LECT NOTES COMPUT SC, V10204, P164, DOI 10.1007/978-3-662-54455-6_8
   Babaioff M, 2011, ACM SIGECOM EXCH, V10, P5
   Banach R, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5749
   Banasik W, 2016, LECT NOTES COMPUT SC, V9879, P261, DOI 10.1007/978-3-319-45741-3_14
   Barber S, 2013, INT C FIN CRYPT DAT, DOI 10.1007/978-3-642-32946-3_29
   BELLARE M., 1999, FORWARD SECURE DIGIT
   Ben-Sasson E, 2016, CRYPTO
   Bentov I, 2019, INT C FIN CRYPT DAT
   Bhowmik D, 2017, INT CONF DIGIT SIG
   Bhowmik D, 2016, IEEE ACCESS, V4, P8002, DOI 10.1109/ACCESS.2016.2627241
   Bhowmik D, 2016, IEEE T IMAGE PROCESS, V25, P5158, DOI 10.1109/TIP.2016.2599785
   Biryukov A, 2015, INT C FIN CRYPT DAT
   Bissias G, 2014, WORKSH PRIV EL SOC, DOI 10.1145/2665943.2665955
   Bonneau J, 2015, P IEEE S SECUR PRIV, P104, DOI 10.1109/SP.2015.14
   Bonneau J, 2014, LECT NOTES COMPUT SC, V8437, P486, DOI 10.1007/978-3-662-45472-5_31
   Cai WJ, 2020, INT J DISTRIB SENS N, V16, DOI 10.1177/1550147720907335
   Cai ZY, 2019, IEEE ACCESS, V7, P138657, DOI 10.1109/ACCESS.2019.2941153
   Chaum D., 1983, Advances in Cryptology, Proceedings of Crypto 82, P199
   Cheng JR, 2018, CMC-COMPUT MATER CON, V55, P95, DOI 10.3970/cmc.2018.055.095
   Cho JH, 2016, AD HOC NETW, V44, P58, DOI 10.1016/j.adhoc.2016.02.014
   Courtois NicolasT., 2014, On subversive miner strategies and block with-holding attack in bitcoin digital currency
   Cremers C, 2016, INT J INF SECUR, V15, P659, DOI 10.1007/s10207-015-0306-9
   Decker Christian, 2015, Stabilization, Safety and Security of Distributed Systems. 17th International Symposium, SSS 2015. Proceedings: LNCS 9212, P3, DOI 10.1007/978-3-319-21741-3_1
   Decker C, 2014, COMPUT THERM SCI, DOI 10.1145/2833312.2833321
   Decker C, 2013, IEEE INT CONF PEER, P1, DOI [DOI 10.1109/P2P.2013.6688704, 10.1109/P2P.2013.6688704, 10.1109/P2P. 2013.6688704]
   Delmolino K, 2016, LECT NOTES COMPUT SC, V9604, P79, DOI 10.1007/978-3-662-53357-4_6
   Di W, 2019, RELIAB ENG SYST SAFE, V185, P318, DOI 10.1016/j.ress.2018.12.026
   Dziembowski S, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P949, DOI 10.1145/3243734.3243856
   Eyal I, 2015, P IEEE S SECUR PRIV, P89, DOI 10.1109/SP.2015.13
   Eyal I, 2014, LECT NOTES COMPUT SC, V8437, P436, DOI 10.1007/978-3-662-45472-5_28
   Fultz N, 2009, P 13 INT C FIN CRYPT
   Gao S, 2019, PROCEEDINGS OF THE 2019 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'19), P833, DOI 10.1145/3319535.3354203
   Gao YL, 2018, IEEE ACCESS, V6, P27205, DOI 10.1109/ACCESS.2018.2827203
   Gazi P, 2019, P IEEE S SECUR PRIV, P139, DOI 10.1109/SP.2019.00040
   George D, 2013, P 1 ACM WORKSH LANG, DOI 10.1145/2517872.2517878
   Gervais A., 2016, P 2016 ACMSIGSAC C C, P3
   Gervais A, 2014, IEEE SECUR PRIV, V12, P54, DOI 10.1109/MSP.2014.49
   Gong S, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030521
   GREEN M, 2017, BOLT ANONYMOUS PAYME, P473
   Grinberg R., 2011, Hastings Science and Technology Law Journal, V4, P159
   Gutoski G, 2015, LECT NOTES COMPUT SC, V8975, P497, DOI 10.1007/978-3-662-47854-7_31
   He YH, 2018, IEEE ACCESS, V6, P27324, DOI 10.1109/ACCESS.2018.2821705
   Heilman E, 2015, US C SEC S
   Heilman E, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI 10.14722/ndss.2017.23086
   Houda ZA, 2019, IEEE ACCESS, V7, P98893, DOI 10.1109/ACCESS.2019.2930715
   Johnson B, 2014, LECT NOTES COMPUT SC, V8438, P72, DOI 10.1007/978-3-662-44774-1_6
   JUELS A, 2016, ACM CCS, P283, DOI DOI 10.1145/2976749.2978362
   Kalra S, 2018, 25TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2018), DOI 10.14722/ndss.2018.23082
   Karame Ghassan O., 2012, P 2012 ACM C COMP CO, P906, DOI [10.1145/2382196.2382292, DOI 10.1145/2382196.2382292]
   Kiayias A, 2017, LECT NOTES COMPUT SC, V10401, P357, DOI 10.1007/978-3-319-63688-7_12
   Kiffer L, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P729, DOI 10.1145/3243734.3243814
   Kosba A, 2016, P IEEE S SECUR PRIV, P839, DOI 10.1109/SP.2016.55
   Kpoll JA, 2013, P WEIS
   Kumaresan R, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P195, DOI 10.1145/2810103.2813712
   Kumaresan R, 2014, CCS'14: PROCEEDINGS OF THE 21ST ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P30, DOI 10.1145/2660267.2660380
   Kwon H, 2019, PEER PEER NETW APPL, V12, P850, DOI 10.1007/s12083-018-0682-9
   Kwon Y, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P195, DOI 10.1145/3133956.3134019
   Li J, 2014, IEEE T PARALL DISTR, V25, P1615, DOI 10.1109/TPDS.2013.284
   Liu J, 2019, IEEE ACCESS, V7, P77894, DOI 10.1109/ACCESS.2019.2921624
   Liu Z, 2019, IEEE ACCESS, V7, P47615, DOI 10.1109/ACCESS.2019.2909924
   Luu L, 2015, IEEE 28 COMP SEC FDN
   Ma MX, 2019, IEEE ACCESS, V7, P34045, DOI 10.1109/ACCESS.2019.2904042
   Maximilian W, 2018, INT WORKSH BLOCKCH O, DOI 10.1109/IWBOSE.2018.8327565
   Miers I, 2013, P IEEE S SECUR PRIV, P397, DOI 10.1109/SP.2013.34
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   MOORE T, 2013, LECT NOTES COMPUTER, V7859
   Mwitende G, 2020, TELECOMMUN SYST, V74, P347, DOI 10.1007/s11235-020-00662-0
   Nakamoto S, 2008, BITCOIN PEER TO PEER, DOI DOI 10.1007/S10838-008-9062-0
   Otte P, 2020, FUTURE GENER COMP SY, V107, P770, DOI 10.1016/j.future.2017.08.048
   Pass R, 2017, LECT NOTES COMPUT SC, V10211, P643, DOI 10.1007/978-3-319-56614-6_22
   Pavlidis A, 2020, KNOWL ENG REV, V35, DOI 10.1017/S0269888920000259
   Qi F, 2018, SURVEY PRIVACY PROTE, DOI 10.1016/j.jnca.2018.10.020
   Rahouti M, 2018, IEEE ACCESS, V6, P67189, DOI 10.1109/ACCESS.2018.2874539
   Rosenstock Martin., 2014, Beyond Alterity: German Encounters with Modern East Asia, P1
   Ruffing T., 2017, MIXING CONFIDENTIAL
   Russell O' Connor, 2017, INT C FIN CRYPT DAT, DOI 10.1007/978-3-319-70278-0_12
   Sako K, 1995, P EUR, DOI 10.1007/3-540-49264-X_32
   Samaniego M, 2016, IEEE INT C COMP INF
   Samaniego M, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS (ITHINGS) AND IEEE GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) AND IEEE CYBER, PHYSICAL AND SOCIAL COMPUTING (CPSCOM) AND IEEE SMART DATA (SMARTDATA), P433, DOI 10.1109/iThings-GreenCom-CPSCom-SmartData.2016.102
   Sayeed S, 2020, IEEE ACCESS, V8, P24416, DOI 10.1109/ACCESS.2020.2970495
   Schrijvers O, 2017, LECT NOTES COMPUT SC, V9603, P477, DOI 10.1007/978-3-662-54970-4_28
   SHOR PW, 1994, AN S FDN CO, P124
   Singh SK, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11070941
   SUN X, 2019, ENTROPY SWITZ, V21
   Tang CB, 2020, IEEE T CIRCUITS-II, V67, P117, DOI 10.1109/TCSII.2019.2901746
   Tosh DK, 2017, 17 IEEE ACM INT S CL
   Valenta L, 2015, LECT NOTES COMPUT SC, V8976, P112, DOI 10.1007/978-3-662-48051-9_9
   Vasek M, 2014, INT C FIN CRYPT DAT
   Wang LC, 2019, J NETW COMPUT APPL, V127, P43, DOI 10.1016/j.jnca.2018.11.003
   Wang WB, 2019, IEEE ACCESS, V7, P22328, DOI 10.1109/ACCESS.2019.2896108
   Wang XM, 2020, IEEE T SERV COMPUT, V13, P314, DOI 10.1109/TSC.2019.2949561
   Xu CH, 2019, IEEE T PARALL DISTR, V30, P870, DOI 10.1109/TPDS.2018.2871449
   Xu GX, 2020, IEEE T IND INFORM, V16, P4252, DOI 10.1109/TII.2019.2955719
   Yang H, 2020, IEEE INTERNET THINGS, V7, P1667, DOI 10.1109/JIOT.2019.2961187
   Yao SX, 2019, IEEE ACCESS, V7, P6117, DOI 10.1109/ACCESS.2018.2889898
   Yin W, 2018, IEEE ACCESS, V6, P5393, DOI 10.1109/ACCESS.2017.2788411
   Zamani M, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P931, DOI 10.1145/3243734.3243853
   Zhang R, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3316481
   Zhang S, 2019, IEEE T IND INFORM, V15, P5715, DOI 10.1109/TII.2019.2921566
   Ziegeldorf JH, 2018, FUTURE GENER COMP SY, V80, P448, DOI 10.1016/j.future.2016.05.018
   Ziegeldorf JH, 2015, 5 ACM C DAT APPL SEC, DOI 10.1145/2699026.2699100
NR 104
TC 27
Z9 29
U1 0
U2 92
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30623
EP 30652
DI 10.1007/s11042-020-09368-6
EA AUG 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000557124000005
DA 2024-07-18
ER

PT J
AU Sun, JG
   Li, T
   Yan, H
   Dong, XJ
AF Sun, Jinguang
   Li, Tao
   Yan, Hua
   Dong, Xiangjun
TI Research on an expression classification method based on a probability
   graph model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine vision; Probability map model; Expression segmentation; Softmax
   classifier; Expression classification
AB There has been continuous development of deep learning models, which has resulted in significant improvement for the level of recognition. Herein we propose an expression classification algorithm that uses a probability graph model to improve the accuracy of learning algorithms on small-scale sample sets. An expression region segmentation method is proposed, which divides the facial expression image into five face regions. According to the theoretical basis for the classification method of the probability map model, an expression classification model based on the model is composed of five expression classification sub-networks and Softmax classification layers. By using these, the expression classification model can be used to classify human facial expression images.The experimental results on the JAFFE facial expression database and the CK expression database demonstrate recognition accuracies of 97.78% and 98.95%, i.e. improvements of 1.85% and 5.92%, respectively. The experimental results show that the proposed method is important for improving the recognition rate of the expressions. In addition, the method effectively improves the analysis and understanding ability for small sample images.
C1 [Sun, Jinguang; Li, Tao; Yan, Hua; Dong, Xiangjun] Liaoning Tech Univ, Fuxing, Peoples R China.
   [Dong, Xiangjun] Qilu Univ Techonl, Shandong Acad Sci, Jinan, Peoples R China.
C3 Liaoning Technical University; Qilu University of Technology
RP Dong, XJ (corresponding author), Liaoning Tech Univ, Fuxing, Peoples R China.; Dong, XJ (corresponding author), Qilu Univ Techonl, Shandong Acad Sci, Jinan, Peoples R China.
EM sunjinguang@lntu.edu.cn; 54602316@qq.com; yanhua_lngcjsdx@163.com;
   d-xj@163.com
RI Dong, Xiangjun/AAJ-3630-2021
OI Dong, Xiangjun/0000-0002-5364-5844
CR [Anonymous], 2014, PROCEDIA IEEE COMPUT, DOI DOI 10.1109/CVPR.2014.233
   [Anonymous], 2017, ARXIV170307140
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Ding Y, 2017, IEEE ACCESS, V99, P1, DOI [10.1109/ACCESS.2017.2740418, DOI 10.1109/ACCESS.2017.2740418]
   Garcia Victor., 2017, 6 INT C LEARN REPR
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Liu X, CVPRW, DOI [10.1109/CVPRW, DOI 10.1109/CVPRW]
   Sikka K, 2016, PROC CVPR IEEE, P5580, DOI 10.1109/CVPR.2016.602
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Snell J., 2017, ADV NEURAL INFORM PR, V30, P4077
   Sun Y., 2015, ARXIV150200873
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Xie S, 2016, CVPR
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   陈孝良, 2016, [科技导报, Science & Technology Review], V34, P82
NR 17
TC 0
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34029
EP 34043
DI 10.1007/s11042-020-09323-5
EA AUG 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000556646200001
DA 2024-07-18
ER

PT J
AU Jin, X
   Yu, HY
   Zhang, HY
   Li, XD
   Sun, HB
AF Jin, Xin
   Yu, Haoyang
   Zhang, Hongyu
   Li, Xiaodong
   Sun, Hongbo
TI Blind background extraction from videos in the cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Privacy preserving; Video surveillance; ViBE; CRT; Multiple cloud
   servers
AB Nowadays, more and more people choose to upload their data and information to cloud. The cloud saves users' data and information and starts providing computing services and artificial intelligence analysis. However, the privacy of users' information and data will be completely exposed to the cloud without any protection. In this paper, we propose two methods of the blind (privacy-preserving) background extraction from video surveillance for both scenarios with the single-party cloud server (SCS) and multi-party cloud servers (MCS). We combine 1D logistics chaotic encryption with background subtraction based on a mixed Gaussian model, and propose a blind background subtraction method for a single server (SCS) . We combine the Chinese Remainder Theorem (CRT) and the ViBE background subtraction method and propose a multi-server blind background subtraction method (MCS). The test set for the experiment is CDW-2014, the experimental results show that our method has satisfactory results in recognition accuracy, recognition speed, and security analysis. The proposed methods have several advantages: (1) Based on our encryption method, the background extraction method in the original video does not need to be changed; (2) The server does not recognize any valid information for the calculation results; (3) Single cloud server (SCS) uses the chaotic mapping can ensure high-level security and resistance to several attacks; (4) Multiple cloud servers (MCS) can improve data security and improve processing efficiency. This method can accurately extract the background like the original ViBE algorithm while protecting the privacy of client video data.
C1 [Jin, Xin; Zhang, Hongyu; Li, Xiaodong; Sun, Hongbo] Beijing Elect Sci & Technol Inst, Dept Cyber Secur, Beijing 100070, Peoples R China.
   [Jin, Xin] State Key Lab Cryptol, POB 5159, Beijing 100878, Peoples R China.
   [Yu, Haoyang] Beijing Univ Posts & Telecommun, Sch Cyberspace Secur, Beijing 100876, Peoples R China.
C3 Beijing Electronic Science & Technology Institute; Beijing University of
   Posts & Telecommunications
RP Li, XD (corresponding author), Beijing Elect Sci & Technol Inst, Dept Cyber Secur, Beijing 100070, Peoples R China.
EM jinxinbesti@foxmail.com; pec7@163.com; pnidemooo@gmail.com;
   lxdbesti@163.com; wr.sun@139.com
RI liang, liang/IAO-8518-2023; Chen, John/GPW-8839-2022; li,
   xiao/HJP-5134-2023; Yu, Haoyang/P-4934-2017; li, xiao/HKV-8405-2023; li,
   xiaofeng/GXF-9442-2022; jin, xin/GQZ-5811-2022; li, xiao/GSN-6181-2022
FU National Natural Science Foundation of China [61701008, 61772047]; Open
   Project Program of State Key Laboratory of Cryptology [MMKFKT201804];
   Beijing Natural Science Foundation [19L2040]; Open Project Program of
   State Key Laboratory of Virtual Reality Technology and Systems, Beihang
   University [VRLAB2019C03]; Fundamental Research Funds for the Central
   Universities [328201907]
FX This work is partially supported by the National Natural Science
   Foundation of China (grant numbers 61701008, 61772047), the Open Project
   Program of State Key Laboratory of Cryptology (grant number
   MMKFKT201804), the Beijing Natural Science Foundation (grant number
   19L2040), the Open Project Program of State Key Laboratory of Virtual
   Reality Technology and Systems, Beihang University (grant number
   VRLAB2019C03) and the Fundamental Research Funds for the Central
   Universities (grant number 328201907). Parts of this paper have
   previously appeared in our previous work. This is the extended journal
   version of the conference papers. The main differences between this
   journal version and the conference version are: We have expanded our
   previous work in more details and experimental results. We performed
   complete efficiency tests on single-party cloud server (SCS) method and
   multi-party cloud servers (MCS) method, including two methods for
   testing the processing speed of single-frame images at different
   resolutions, two methods for testing the accuracy of the complete
   segment video, and more comprehensive and reliable security analysis.
CR [Anonymous], 2019, NEURAL NETW
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Chen YD, 2019, IEEE T MULTIMEDIA, V21, P1934, DOI 10.1109/TMM.2018.2890361
   Chu K.-Y., 2013, Proceedings of the 21st ACM international conference on Multimedia, P597
   HUI ZY, 2016, MULTIMEDIA MODELING, P562
   Jin Xin., 2016, 2016 8th International Conference, P1
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Upmanyu M, 2009, IEEE I CONF COMP VIS, P1639, DOI 10.1109/ICCV.2009.5459370
   Wang Y., 2014, P IEEE C COMP VIS PA, P387, DOI 10.1109/ICIP40778.2020.9190887
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
NR 11
TC 0
Z9 0
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28755
EP 28771
DI 10.1007/s11042-020-09386-4
EA AUG 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000556646300009
DA 2024-07-18
ER

PT J
AU Gidaye, G
   Nirmal, J
   Ezzine, K
   Frikha, M
AF Gidaye, Girish
   Nirmal, Jagannath
   Ezzine, Kadria
   Frikha, Mondher
TI Wavelet sub-band features for voice disorder detection and
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Voice disorder detection; Stationary wavelet transform; Voice pathology;
   Statistical features; Feature selection; Information gain
ID SIGNAL-PROCESSING ALGORITHMS; PATHOLOGY DETECTION; DIAGNOSIS; SYSTEM;
   INFORMATION; EXTRACTION
AB Acoustic analysis of the speech signal enables non-intrusive, affordable, unbiased and fast assessment of voice pathologies. This assessment provides complimentary information to otolaryngologist for preliminary diagnosis of pathological larynx. Several voice impairment assessment systems focused on acoustic analysis have been introduced in recent years. Nevertheless, these systems are tested using only one or two datasets and are not independent of database and human bias. In this paper, a unified wavelet based framework is suggested for evaluating voice disorders, which is independent of database and human bias. Stationary wavelet transform (SWT) is used to decompose the speech signal, since it offers good time and frequency localization. Energy and statistical features are extracted from each sub-band after multilevel decomposition. Higher the decomposition level, higher is the order of feature vector. To decrease the dimension of the feature vector, information gain (IG) based feature selection technique is harnessed for selecting most relevant and discarding redundant features. The enriched feature vector is assessed using support vector machine (SVM), stochastic gradient descent (SGD) and artificial neural network (ANN) classifiers. Records of vowel /a/, vocalized at natural pitch for both healthy and pathological subjects, are mined from German, English, Arabic and Spanish speech databases. During the first phase of experiments, input speech signal is detected as healthy or pathological. Second phase classifies input speech samples into healthy, cyst, paralysis or polyp. Experimental results demonstrate that, the extracted energy and statistical features can be used as possible clues for voice disorder evaluation. The most important aspect of the proposed method is that the features are independent of the fundamental frequency. The detection and classification rates attained are comparable to other state-of-the-art approaches.
C1 [Gidaye, Girish] KJ Somaiya Coll Engn, Vidyalankar Inst Technol, Mumbai, Maharashtra, India.
   [Gidaye, Girish] Vidyalankar Inst Technol, Dept Elect Engn, Mumbai, Maharashtra, India.
   [Gidaye, Girish; Nirmal, Jagannath] KJ Somaiya Coll Engn, Mumbai, Maharashtra, India.
   [Ezzine, Kadria; Frikha, Mondher] Sfax Univ, ATISP, ENET COM, Sfax, Tunisia.
C3 Somaiya Vidyavihar University; K J Somaiya College of Engineering;
   Somaiya Vidyavihar University; K J Somaiya College of Engineering;
   Universite de Sfax
RP Gidaye, G (corresponding author), KJ Somaiya Coll Engn, Vidyalankar Inst Technol, Mumbai, Maharashtra, India.; Gidaye, G (corresponding author), Vidyalankar Inst Technol, Dept Elect Engn, Mumbai, Maharashtra, India.; Gidaye, G (corresponding author), KJ Somaiya Coll Engn, Mumbai, Maharashtra, India.
EM girish.gidaye@vit.edu.in
RI FRIKHA, Mondher/IAN-7365-2023; Nirmal, Jagannath/AAR-8479-2021
OI FRIKHA, Mondher/0000-0003-2584-5141; 
CR Al-Nasheri A, 2018, IEEE ACCESS, V6, P6961, DOI 10.1109/ACCESS.2017.2696056
   Al-nasheri A, 2017, J VOICE, V31, DOI 10.1016/j.jvoice.2016.03.019
   Al-nasheri A, 2017, J VOICE, V31, P3, DOI 10.1016/j.jvoice.2016.01.014
   Alhussein M, 2018, IEEE ACCESS, V6, P41034, DOI 10.1109/ACCESS.2018.2856238
   Ali Z, 2018, FUTURE GENER COMP SY, V85, P19, DOI 10.1016/j.future.2018.02.021
   Ali Z, 2017, IEEE ACCESS, V5, P3900, DOI 10.1109/ACCESS.2017.2680467
   Ali Z, 2016, BIOL INSPIR COGN ARC, V15, P10, DOI 10.1016/j.bica.2015.10.004
   Ali Z, 2016, J MED SYST, V40, DOI 10.1007/s10916-015-0392-2
   Amami R, 2017, COMPUT ELECTR ENG, V57, P257, DOI 10.1016/j.compeleceng.2016.08.021
   [Anonymous], SAARBRUCKEN VOICE DA
   [Anonymous], MEEI DIS VOIC DAT VO
   [Anonymous], 2017, PLANT MACR US EFF
   Arias-Londoño JD, 2011, LOGOP PHONIATR VOCO, V36, P60, DOI 10.3109/14015439.2010.528788
   Cesari U, 2018, COMPUT ELECTR ENG, V68, P310, DOI 10.1016/j.compeleceng.2018.04.008
   Chuang ZY, 2018, IEEE INT CONF BIG DA, P5238, DOI 10.1109/BigData.2018.8622317
   Deshpande PS, 2018, IEEE J BIOMED HEALTH, V22, P398, DOI 10.1109/JBHI.2017.2654683
   El Emary IMM, 2014, J COMMUN TECHNOL EL+, V59, P1280, DOI 10.1134/S1064226914110059
   Ezzine K., 2018, P 4 INT C ADV TECHN, P1, DOI DOI 10.1109/ATSIP.2018.8364517
   Fang SH, 2019, J VOICE, V33, P634, DOI 10.1016/j.jvoice.2018.02.003
   Farouk MH, 2018, SPRBRIEF ELECT, P77, DOI 10.1007/978-3-319-69002-5_14
   Godino-Llorente JI, 2006, MED ENG PHYS, V28, P276, DOI 10.1016/j.medengphy.2005.04.014
   Gómez-Vilda P, 2009, SPEECH COMMUN, V51, P759, DOI 10.1016/j.specom.2008.09.005
   Grzywalski T, 2018, IEEE INT CONF BIG DA, P5247, DOI 10.1109/BigData.2018.8622012
   Hadjitodorov S, 2000, IEEE T INF TECHNOL B, V4, P68, DOI 10.1109/4233.826861
   Hadjitodorov S, 2002, MED ENG PHYS, V24, P419, DOI 10.1016/S1350-4533(02)00031-0
   Hariharan M, 2014, INT J SYST SCI, V45, P1622, DOI 10.1080/00207721.2013.794905
   Hegde S, 2019, J VOICE, V33, DOI 10.1016/j.jvoice.2018.07.014
   Areiza-Laverde HJ, 2018, COMM COM INF SC, V915, P148, DOI 10.1007/978-3-030-00350-0_13
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Markaki M, 2011, IEEE T AUDIO SPEECH, V19, P1938, DOI 10.1109/TASL.2010.2104141
   Mesallam TA, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/8783751
   Muhammad G, 2017, IEEE COMMUN MAG, V55, P69, DOI 10.1109/MCOM.2017.1600425CM
   Muhammad G, 2014, BIOMED SIGNAL PROCES, V11, P1, DOI 10.1016/j.bspc.2014.02.001
   Murugesapandian P, 2008, IFMBE PROC, V21, P790
   Nongpiur RC, 2013, J ACOUST SOC AM, V133, P866, DOI 10.1121/1.4773264
   Novotny M, 2014, IEEE-ACM T AUDIO SPE, V22, P1366, DOI 10.1109/TASLP.2014.2329734
   Qi JP, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0093365
   Orozco-Arroyave JR, 2015, IEEE J BIOMED HEALTH, V19, P1820, DOI 10.1109/JBHI.2015.2467375
   Rufo MJ, 2019, BIOMETRICAL J, V61, P503, DOI 10.1002/bimj.201700233
   Saeedi NE, 2013, COMPUT BIOL MED, V43, P699, DOI 10.1016/j.compbiomed.2013.03.006
   Sakar CO, 2019, APPL SOFT COMPUT, V74, P255, DOI 10.1016/j.asoc.2018.10.022
   Selamtzis A, 2019, BIOMED SIGNAL PROCES, V47, P350, DOI 10.1016/j.bspc.2018.08.021
   Shahnaz C, 2012, IEEE INT SYMP CIRC S, P1030
   Shia SE, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT TECHNIQUES IN CONTROL, OPTIMIZATION AND SIGNAL PROCESSING (INCOS)
   Sreehari VR, 2018, TENCON IEEE REGION, P1595, DOI 10.1109/TENCON.2018.8650279
   Tang J., 2014, DATA CLASSIFICATION, P37, DOI DOI 10.1201/B17320
   Travieso CM, 2017, EXPERT SYST APPL, V82, P184, DOI 10.1016/j.eswa.2017.04.012
   Trinh N. H., 2019, PATHOLOGICAL SPEECH, DOI [10.21427/9dnc-n002, DOI 10.21427/9DNC-N002]
   Tsanas A, 2012, IEEE T BIO-MED ENG, V59, P1264, DOI 10.1109/TBME.2012.2183367
   Vaiciukynas E, 2014, APPL SOFT COMPUT, V18, P91, DOI 10.1016/j.asoc.2014.01.012
   Vaiciukynas E, 2012, SPEECH COMMUN, V54, P601, DOI 10.1016/j.specom.2011.04.004
   Verde L, 2018, IEEE ACCESS, V6, P16246, DOI 10.1109/ACCESS.2018.2816338
   Wu Huiyi, 2018, Annu Int Conf IEEE Eng Med Biol Soc, V2018, P1, DOI 10.1109/EMBC.2018.8513222
NR 53
TC 4
Z9 4
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28499
EP 28523
DI 10.1007/s11042-020-09424-1
EA AUG 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000555748500003
DA 2024-07-18
ER

PT J
AU Plesse, F
   Ginsca, A
   Delezoide, B
   Prêteux, F
AF Plesse, Francois
   Ginsca, Alexandru
   Delezoide, Bertrand
   Preteux, Francoise
TI Modelling relations with prototypes for visual relation detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual relation detection; Prototype; Metric learning; Nearest
   neighbors; Synonyms
AB Relations between objects drive our understanding of images. Modelling them poses several challenges due to the combinatorial nature of the problem and the complex structure of natural language. This paper tackles the task of predicting relationships in the form of (subject, relation, object) triplets from still images. To address these issues, we propose a framework for learning relation prototypes that aims to capture the complex nature of relation distributions. Concurrently, a network is trained to define a space in which relationship triplets with similar spatial layouts, interacting objects and relations are clustered together. Finally, the network is compared to two models explicitly tackling the problem of synonymy among relations. For this, two well known scene-graph labelling benchmarks are used for training and testing: VRD and Visual Genome. Prediction of relations based on distance to prototype provides a significant increase in the diversity of predicted relations, improving the average relation recall from 40.3% to 41.7% on the first and 31.3% to 35.4% on the second.
C1 [Plesse, Francois; Ginsca, Alexandru; Delezoide, Bertrand] CEA, LIST, F-91191 Gif Sur Yvette, France.
   [Plesse, Francois; Preteux, Francoise] Ecole Ponts, CERMICS, Champs Sur Marne, France.
C3 CEA; Universite Paris Saclay; Ecole des Ponts ParisTech
RP Plesse, F (corresponding author), CEA, LIST, F-91191 Gif Sur Yvette, France.; Plesse, F (corresponding author), Ecole Ponts, CERMICS, Champs Sur Marne, France.
EM francois.plesse@gmail.com; alexandru.ginsca@cea.fr;
   bertrand.delezoide@cea.fr; francoise.preteux@enpc.fr
CR [Anonymous], 2018, P ADV NEUR INF PROC
   Chao YW, 2015, IEEE I CONF COMP VIS, P1017, DOI 10.1109/ICCV.2015.122
   Chao YW, 2015, CVPR, DOI [10.1109/CVPR.2015.7299054, DOI 10.1109/CVPR.2015.7299054]
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Cui Yin., 2016, CVPR
   Dai B, 2017, PROC CVPR IEEE, P3298, DOI 10.1109/CVPR.2017.352
   de Boer M, 2016, MULTIMED TOOLS APPL, V75, P9025, DOI 10.1007/s11042-015-2757-4
   Deng Jia, 2014, EUR C COMP VIS ECCV
   Fang Y, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1661
   Fellbaum C.)., 1998, WordNet: An Electronic Lexical Database (Language, Speech, and Communication), P423, DOI [10.7551/mitpress/7287.001.0001, DOI 10.1139/H11-025]
   Girshick R., 2015, IEEE I CONF COMP VIS, DOI [DOI 10.1109/ICCV.2015.169, 10.1109/ICCV.2015.169]
   Gkioxari G, 2018, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2018.00872
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Herzig R., 2018, ARXIV180205451
   Hu ZT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2410, DOI 10.18653/v1/p16-1228
   Johnson J., Billion-scale similarity search with gpus
   Kaiser Lukasz, 2017, ICLR
   Koch G, TECHNICAL REPORT
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Li YK, 2017, PROC CVPR IEEE, P7244, DOI 10.1109/CVPR.2017.766
   Liang KM, 2018, AAAI CONF ARTIF INTE, P7098
   Liang XD, 2017, PROC CVPR IEEE, P4408, DOI 10.1109/CVPR.2017.469
   Long Y, 2017, PROC CVPR IEEE, P6165, DOI 10.1109/CVPR.2017.653
   Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51
   MacQueen J, 1965, P 5 BER S MATH STAT, P281
   Marino K, 2017, PROC CVPR IEEE, P20, DOI 10.1109/CVPR.2017.10
   Newell A., 2017, ADV NEUR IN, P2171
   Peyre J, 2017, IEEE I CONF COMP VIS, P5189, DOI 10.1109/ICCV.2017.554
   Plesse F, 2020, WACV
   Plesse F, 2018, IEEE INT CON MULTI
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sarullo A, 2019, CLASS IMBALANCE BACK
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Speer R, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3679
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vinyals O., 2016, ADV NEURAL INFORM PR, P3630, DOI DOI 10.48550/ARXIV.1606.04080
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Xu DF, 2017, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2017.330
   Yin Guojun., 2018, ECCV
   Yu RC, 2017, IEEE I CONF COMP VIS, P1068, DOI 10.1109/ICCV.2017.121
   Zellers R, 2018, PROC CVPR IEEE, P5831, DOI 10.1109/CVPR.2018.00611
   Zhu YH, 2017, IEEE INT CON MULTI, P379, DOI 10.1109/ICME.2017.8019448
NR 45
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22465
EP 22486
DI 10.1007/s11042-020-09001-6
EA AUG 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000555748500004
DA 2024-07-18
ER

PT J
AU Chen, Y
   Li, SJ
AF Chen, Yong
   Li, Shaojun
TI Contextual adaptive fourth-order smoothing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Noise removal; Adaptive smoothing; Fourth-order PDEs; Laplacian
   operator; Inhomogeneity
ID PARTIAL-DIFFERENTIAL-EQUATION; ANISOTROPIC DIFFUSION FILTER;
   IMAGE-RESTORATION; DENOISING MODEL; REGULARIZATION; SPACE
AB This paper aims to propose a novel contextual adaptive fourth-order smoothing method for noise removal. The classical Laplacian operator is first modified into a multi-scale and robust form, which combines two distinct discontinuity measures simultaneously, i.e., inhomogeneity and local spatial gradient. Then the contextual adaptive fourth-order smoothing method is proposed based on the new Laplacian operator. Moreover, a gain control function is employed for the gain control of smoothing in terms of contextual discontinuities to better preserve the important features. Experimental results support that the proposed method achieves the best performance among the comparative methods with respect to some objective evaluation metrics and visual effects.
C1 [Chen, Yong] Xihua Univ, Sch Econ, Chengdu 610039, Peoples R China.
   [Li, Shaojun] Xihua Univ, Sch Art & Design, Chengdu 610039, Peoples R China.
C3 Xihua University; Xihua University
RP Chen, Y (corresponding author), Xihua Univ, Sch Econ, Chengdu 610039, Peoples R China.
EM xihua_ychen@163.com; 15848492@qq.com
CR [Anonymous], DIGITAL IMAGE PROCES
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Chan T, 2000, SIAM J SCI COMPUT, V22, P503, DOI 10.1137/S1064827598344169
   Chao SM, 2010, PATTERN RECOGN LETT, V31, P2012, DOI 10.1016/j.patrec.2010.06.004
   Chen K, 2005, IEEE T PATTERN ANAL, V27, P1552, DOI 10.1109/TPAMI.2005.190
   Dabov K., 2008, P SIGN PROC AD SPARS, P1
   Deng LZ, 2019, OPT LASER TECHNOL, V110, P184, DOI 10.1016/j.optlastec.2018.08.043
   Didas S, 2009, ADV COMPUT MATH, V30, P79, DOI 10.1007/s10444-007-9061-4
   Hajiaboli MR, 2011, INT J COMPUT VISION, V92, P177, DOI 10.1007/s11263-010-0330-1
   Hu Y, 2012, IEEE T IMAGE PROCESS, V21, P2559, DOI 10.1109/TIP.2012.2183143
   Jia TT, 2016, J VIS COMMUN IMAGE R, V38, P461, DOI 10.1016/j.jvcir.2016.03.022
   Kang M, 2018, COMPUT MATH APPL, V76, P58, DOI 10.1016/j.camwa.2018.04.004
   Lefkimmiatis S, 2012, IEEE T IMAGE PROCESS, V21, P983, DOI 10.1109/TIP.2011.2168232
   Li F, 2007, J VIS COMMUN IMAGE R, V18, P322, DOI 10.1016/j.jvcir.2007.04.005
   Li HC, 2012, ELECTRON LETT, V48, P827, DOI 10.1049/el.2011.3994
   Liu XY, 2015, INT J COMPUT MATH, V92, P608, DOI 10.1080/00207160.2014.904854
   Liu XW, 2011, APPL MATH LETT, V24, P1282, DOI 10.1016/j.aml.2011.01.028
   Lu BB, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/9205809
   Lysaker M, 2006, INT J COMPUT VISION, V66, P5, DOI 10.1007/s11263-005-3219-7
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Papafitsoros K, 2014, J MATH IMAGING VIS, V48, P308, DOI 10.1007/s10851-013-0445-4
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Saha PK, 2001, IEEE T PATTERN ANAL, V23, P689, DOI 10.1109/34.935844
   Siddig A, 2018, COMPUT MATH APPL, V76, P1056, DOI 10.1016/j.camwa.2018.05.040
   Wang Y, 2007, IEEE T IMAGE PROCESS, V16, P1854, DOI 10.1109/TIP.2007.899002
   Xu JT, 2016, SIGNAL PROCESS, V119, P80, DOI 10.1016/j.sigpro.2015.07.017
   Yang JH, 2019, COMPUT MATH APPL, V77, P1255, DOI 10.1016/j.camwa.2018.11.003
   Yang YQ, 2015, INT J COMPUT MATH, V92, P181, DOI 10.1080/00207160.2014.888420
   You YL, 1996, IEEE T IMAGE PROCESS, V5, P1539, DOI 10.1109/83.541424
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
   Zeng W, 2015, MULTIMED TOOLS APPL, V74, P743, DOI 10.1007/s11042-013-1692-5
   Zhang XJ, 2017, COMPUT MATH APPL, V74, P2529, DOI 10.1016/j.camwa.2017.07.036
NR 33
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18435
EP 18446
DI 10.1007/s11042-020-08702-2
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000587677800051
DA 2024-07-18
ER

PT J
AU Jin, L
   Wen, ZJ
   Hu, ZY
AF Jin, Lei
   Wen, Zhijie
   Hu, Zhongyi
TI Topology-preserving nonlinear shape registration on the shape manifold
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shape registration; Hierarchically geodesic clustering; Shape atlas;
   Topology preserving
AB Shape registration is a vital task in computer vision and image processing, but the topology changes always occur in registration process of two shapes with large deformation. In this paper, we address the shape registration with large deformation by an atlas based method. Concretely, we first represent the shape by the square root velocity functions (SRVFs) which makes registration of two shapes with small deformation well. Then, we hierarchically cluster all shapes and form a clustering tree under this representation. Further, by searching the shortest path connecting two shapes we realize the registration with topology preserving. Finally, the numerical results on the Kimia shape dataset show that our proposed method achieves a better performance of registration than the conventional method. That is, the atlas-based strategy is valid for shape registration with large deformation.
C1 [Jin, Lei; Wen, Zhijie] Shanghai Univ, Sch Sci, Dept Math, Shanghai 200444, Peoples R China.
   [Hu, Zhongyi] Wenzhou Univ, Intelligent Informat Syst Inst, Wenzhou 325035, Zhejiang, Peoples R China.
C3 Shanghai University; Wenzhou University
RP Hu, ZY (corresponding author), Wenzhou Univ, Intelligent Informat Syst Inst, Wenzhou 325035, Zhejiang, Peoples R China.
EM hujunyi@163.com
RI zhu, yujie/KBC-4009-2024
OI Hu, Zhongyihu/0000-0002-9672-3734
FU National Natural Science Foundation of China [11971296, 11701357,
   U1809209]; Capacity Construction Project of Local Universities in
   Shanghai [18010500600]; Major Project of Wenzhou Natural Science
   Foundation [ZY2019020]
FX This research is supported by the National Natural Science Foundation of
   China under Grants 11971296, 11701357, U1809209, the Capacity
   Construction Project of Local Universities in Shanghai under Grant
   18010500600, and the Major Project of Wenzhou Natural Science Foundation
   under Grant ZY2019020.
CR [Anonymous], 2007, Pattern theory: from representation to inference
   Arsigny V, 2006, LECT NOTES COMPUT SC, V4190, P924
   Ashburner J, 2009, NEUROIMAGE, V45, P333, DOI 10.1016/j.neuroimage.2008.12.008
   Berger M., 2003, PANORAMIC VIEW RIEMA
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3
   Cootes T.F., 1998, COMPUTER VISION ECCV, V1407, P484, DOI [DOI 10.1007/BFB0054760, DOI 10.1109/34.927467]
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Demisse GG, 2018, IEEE T PATTERN ANAL, V40, P1338, DOI 10.1109/TPAMI.2017.2711607
   Du SY, 2017, MULTIMED TOOLS APPL, V76, P12065, DOI 10.1007/s11042-016-4018-6
   Du SY, 2010, PATTERN RECOGN LETT, V31, P791, DOI 10.1016/j.patrec.2010.01.020
   Fletcher PT, 2007, SIGNAL PROCESS, V87, P250, DOI 10.1016/j.sigpro.2005.12.018
   Hastie T., 2009, The Elements of Statistical Learning
   Huang XL, 2006, IEEE T PATTERN ANAL, V28, P1303, DOI 10.1109/TPAMI.2006.171
   Joshi S, 2004, NEUROIMAGE, V23, pS151, DOI 10.1016/j.neuroimage.2004.07.068
   KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81
   Klassen E, 2004, IEEE T PATTERN ANAL, V26, P372, DOI 10.1109/TPAMI.2004.1262333
   Peng YX, 2013, IET COMPUT VIS, V7, P437, DOI 10.1049/iet-cvi.2012.0147
   Srivastava A, 2005, IEEE T PATTERN ANAL, V27, P590, DOI 10.1109/TPAMI.2005.86
   Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184
   van de Giessen M, 2012, LECT NOTES COMPUT SC, V7512, P164, DOI 10.1007/978-3-642-33454-2_21
   Wood E, 2015, IEEE I CONF COMP VIS, P3756, DOI 10.1109/ICCV.2015.428
   Wu GR, 2012, NEUROIMAGE, V59, P404, DOI 10.1016/j.neuroimage.2011.07.026
   Wu ZZ, 2019, PATTERN RECOGN, V93, P14, DOI 10.1016/j.patcog.2019.03.013
   Xie YC, 2010, PROC CVPR IEEE, P2933, DOI 10.1109/CVPR.2010.5540035
   Ye M, 2016, IEEE T PATTERN ANAL, V38, P1517, DOI 10.1109/TPAMI.2016.2557783
   Ying SH, 2014, NEUROIMAGE, V84, P626, DOI 10.1016/j.neuroimage.2013.09.023
   Ying SH, 2011, PATTERN ANAL APPL, V14, P127, DOI 10.1007/s10044-010-0193-7
   Ying SH, 2009, IEEE T AUTOM SCI ENG, V6, P559, DOI 10.1109/TASE.2009.2021337
   Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134
   Zuffi S, 2015, PROC CVPR IEEE, P3537, DOI 10.1109/CVPR.2015.7298976
NR 31
TC 9
Z9 10
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17377
EP 17389
DI 10.1007/s11042-020-09203-y
EA JUN 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000542548200001
DA 2024-07-18
ER

PT J
AU Albataineh, M
   Jarrah, M
AF Albataineh, Majeda
   Jarrah, Moath
TI DEVS-IoT: performance evaluation of smart home devices network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DEVS formalism; Smart home network; Scheduling; Modeling and simulation;
   Poisson process
ID SIMULATION; INTERNET; OBJECTS; THINGS; MODEL
AB Advances in electronics and connectivity have enabled a wide range of applications that can harness data collection for better decision making and an improved lifestyle. The Internet of Things (IoT) provides the communication infrastructure that allows devices with sensing and control capabilities to be connected within a home network. Smart home systems are considered one of the prominent applications in IoT, where it is possible to control home devices to achieve a better usage in terms of cost and comfort. However, smart home networks contain a wide range of devices and finding an optimal schedule for their working hours is an NP-hard problem. Hence, rather than using mathematical optimization to find optimal solutions, this paper proposes a modeling and simulation methods in order to provide good decisions and recommendations for devices' scheduling. Discrete Event System Specification (DEVS) formalism is used to develop a model of a smart home network. The devices are categorized into two groups: monitoring devices and control devices. Monitoring devices include sensors that capture climate, energy, power, performance, and occupant's behavioral data. Control devices send signals remotely for setting and controlling different devices in the smart home network. The behavior in terms of power usage and cost is simulated under different scenarios and settings. The simulation results show that less energy consumption can be achieved if users adopt a behavior where the schedule of three devices is changed every week. As a result, the proposed method can be utilized to make better decisions in setting devices parameters and evaluating the performance of the smart devices network under different conditions, scenarios, and settings.
C1 [Albataineh, Majeda; Jarrah, Moath] Jordan Univ Sci & Technol, Dept Comp Engn, POB 3030, Irbid 22110, Jordan.
C3 Jordan University of Science & Technology
RP Jarrah, M (corresponding author), Jordan Univ Sci & Technol, Dept Comp Engn, POB 3030, Irbid 22110, Jordan.
EM mjarrah@just.edu.jo
OI Jarrah, Moath/0000-0002-5619-1032
CR Aid L, 2016, J AMB INTEL HUM COMP, V7, P579, DOI 10.1007/s12652-016-0352-9
   Akhtar N, 2011, J THEOR BIOL, V285, P103, DOI 10.1016/j.jtbi.2011.05.038
   Al-Fuqaha A, 2015, IEEE COMMUN SURV TUT, V17, P2347, DOI 10.1109/COMST.2015.2444095
   Alansari Z, 2018, L N INST COMP SCI SO, V200, P47, DOI 10.1007/978-3-319-95450-9_4
   [Anonymous], 2014, INT J COMPUTER APPL
   Balta-Ozkan N, 2013, ENERGY, V60, P361, DOI 10.1016/j.energy.2013.08.004
   Bhati A, 2017, ENERG POLICY, V104, P230, DOI 10.1016/j.enpol.2017.01.032
   Bilal M, 2017, ARXIV170804560CSNI
   Chan M, 2009, MATURITAS, V64, P90, DOI 10.1016/j.maturitas.2009.07.014
   Chen XJ, 2002, ASE 2002: 17TH IEEE INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, P279, DOI 10.1109/ASE.2002.1115030
   Chow A.C.H., 1994, WINT SIM C, DOI [10.1109/wsc.1994.717419, DOI 10.1109/WSC.1994.717419]
   Fioretto F, 2017, AAMAS'17: PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS, P981
   Getgood A, 2019, BMC MUSCULOSKEL DIS, V20, DOI 10.1186/s12891-019-2589-x
   Hargreaves T, 2018, BUILD RES INF, V46, P127, DOI 10.1080/09613218.2017.1286882
   Hu X, 2003, DYNAMIC RECONFIGURAT
   Hu XL, 2005, SIMUL-T SOC MOD SIM, V81, P91, DOI 10.1177/0037549705052227
   Hurrah NN, 2019, AD HOC NETW, V95, DOI 10.1016/j.adhoc.2019.101989
   Iqbal A, 2018, SUSTAIN CITIES SOC, V38, P636, DOI 10.1016/j.scs.2018.01.044
   Jaradat M, 2015, PROCEDIA COMPUT SCI, V56, P592, DOI 10.1016/j.procs.2015.07.250
   Jaradat M, 2014, INT RENEW SUST ENERG, P571, DOI 10.1109/IRSEC.2014.7059843
   Jarrah M, 2017, 2017 14TH INTERNATIONAL CONFERENCE ON SMART CITIES: IMPROVING QUALITY OF LIFE USING ICT & IOT (HONET-ICT), P36, DOI 10.1109/HONET.2017.8102217
   Jarrah M, 2016, PROCEDIA COMPUT SCI, V83, P642, DOI 10.1016/j.procs.2016.04.144
   Jarrah M, 2015, INFORM SYST, V53, P190, DOI 10.1016/j.is.2014.12.003
   Kane T, 2017, ENERG BUILDINGS, V148, P89, DOI 10.1016/j.enbuild.2017.04.059
   Karaboghossian T, 2018, OPTIM LETT, V12, P1553, DOI 10.1007/s11590-017-1209-7
   Khan M, 2019, J IEEE INTERNET THIN
   Knuth D. E., 1969, The Art of Computer Programming, Vol. 2, Seminumerical Algorithms, V2
   Kortuem G, 2010, IEEE INTERNET COMPUT, V14, P44, DOI 10.1109/MIC.2009.143
   Laraki M, 2018, INT CONF SEL TOP MOB, P149, DOI 10.1109/MoWNet.2018.8428865
   Lee E. J, 2013, J NANOMATER, V2013, P1
   Mehdi G, 2015, ENRGY PROCED, V83, P60, DOI 10.1016/j.egypro.2015.12.196
   Min Li, 2018, Procedia Computer Science, V131, P393, DOI 10.1016/j.procs.2018.04.219
   Mubdir B., 2016, European Scientific Journal, V12, P521, DOI [https://doi.org/10.19044/esj.2016.v12n33p521, DOI 10.19044/ESJ.2016.V12N33P521]
   Piyare R., 2011, 2011 IEEE 15th International Symposium on Consumer Electronics, P192, DOI 10.1109/ISCE.2011.5973811
   Ray AK, 2017, IJCA P INT C COMP SY, P14
   Theodoridis E., 2013, Developing an iot smart city framework, DOI [10.1109/IISA.2013.6623710, DOI 10.1109/IISA.2013.6623710]
   ULLMAN JD, 1975, J COMPUT SYST SCI, V10, P384, DOI 10.1016/S0022-0000(75)80008-0
   Van Tendeloo Y, 2018, WINT SIMUL C PROC, P162, DOI 10.1109/WSC.2018.8632372
   Van Woensel L., 2019, Ten Technologies Which Could Change Our Lives: Potential Impacts and Policy Implications
   Wainer GA, 2018, WINT SIMUL C PROC, P177, DOI 10.1109/WSC.2018.8632408
   Wilson C, 2017, ENERG POLICY, V103, P72, DOI 10.1016/j.enpol.2016.12.047
   Zeigler B. P., 1985, Proceedings of the 5th International Conference on Distributed Computing Systems (Cat. No. 85CH2149-3), P468
   Zeigler B. P., 1989, Modelling and Methodology. Knowledge Systems' Paradigms, P45
   ZEIGLER BP, 1993, J PARALLEL DISTR COM, V18, P77, DOI 10.1006/jpdc.1993.1046
   Zeigler BP, 2003, PROCEEDINGS OF THE 11TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON MODELING, ANALYSIS AND SIMULATION OF COMPUTER TELECOMMUNICATIONS SYSTEMS, P148
NR 45
TC 3
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16857
EP 16885
DI 10.1007/s11042-020-09186-w
EA JUN 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000541401100001
DA 2024-07-18
ER

PT J
AU Ishrat, M
   Abrol, P
AF Ishrat, Mohsina
   Abrol, Pawanesh
TI Image complexity analysis with scanpath identification using remote gaze
   estimation model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gaze; Fixation; Saccade; Voila Jones; CHT; Visual search
ID EYE-MOVEMENTS; VISUAL FATIGUE; TRACKING; ROBUST
AB Analysis of gaze points has been a vital tool for understanding varied human behavioral pattern and underlying psychological processing. Gaze points are analyzed generally in terms of two events of fixations and saccades that are collectively termed as scanpath. Scanpath could potentially establish correlation between visual scenery and human cognitive tendencies. Scanpath has been analyzed for different domains that include visual perception, usability, memory, visual search or low level attributes like color, illumination and edges in an image. Visual search is one prominent area that examines scanpath of subjects while a target object is searched in a given set of images. Visual search explores behavioral tendencies of subjects with respect to image complexity. Complexity of an image is governed by spatial, frequency and color information present in the image. Scanpath based image complexity analysis determines human visual behavior that could lead to development of interactive and intelligent systems. There are several sophisticated eye tracking devices and associated algorithms for recording and classification of scanpath. However, in the present scenario when the chances of viral infections (COVID-19) from known and unknown sources are high, it is very important that the contact less methods and models be designed. In addition, even though the devices acquire and process eye movement data with fair accuracy but are intrusive and costly. The objective of current research work is to establish the complexity of the given set of images while target objects are searched and to present analysis of gaze search pattern. To achieve these objectives a remote gaze estimation and analysis model has been proposed for scanpath identification and analysis. The model is an alternate option for gaze point tracking and scanpath analysis that is non intrusive and low cost. The gaze points are tracked remotely as against sophisticated wearable eye tracking devices available in the market. The model employs easily available softwares and hardware devices. In the current work, complexity is derived on the basis of analysis of fixation and saccade gaze points. Based on the results generated by the proposed model, influence on subjects due to external stimuli is studied. The set of images chosen, act as external stimuli for the subjects during visual search. In order to statistically analyze scanpath for different subjects, certain scanpath parameters have been identified. The model maps and classifies eye movement gaze points into fixations and saccades and generates data for identified parameters. For eye detection and subsequent iris detection voila jones and circular hough transform (CHT) algorithms have been used. Identification by dispersion threshold (I-DT) is implemented for scanpath identification. The algorithms are customized for better iris and scanpath detection. Algorithms are developed for gaze screen mapping and classification of fixations and saccades. The experimentation has been carried on different subjects. Variations during visual search have been observed and analyzed. The present model requires no contact of human subject with any equipment including eye tracking devices, screen or computing devices.
C1 [Ishrat, Mohsina; Abrol, Pawanesh] Univ Jammu J&K, Dept Comp Sci & IT, Jammu, India.
C3 University of Jammu
RP Ishrat, M (corresponding author), Univ Jammu J&K, Dept Comp Sci & IT, Jammu, India.
EM mohsina.ishrat@gmail.com; pawanesh.abrol@gmail.com
OI Ishrat, Mohsina/0000-0002-9298-4291
CR Andersson R, 2017, BEHAV RES METHODS, V49, P616, DOI 10.3758/s13428-016-0738-9
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], 2006, BMVC
   [Anonymous], P INT JOINT C BIOM
   Argilés M, 2015, INVEST OPHTH VIS SCI, V56, P6679, DOI 10.1167/iovs.15-16967
   Asgharil A, 2019, J MED ETHICS HIST ME, V12
   Benedetto S, 2014, COMPUT HUM BEHAV, V41, P112, DOI 10.1016/j.chb.2014.09.023
   Bertera JH, 2000, PERCEPT PSYCHOPHYS, V62, P576, DOI 10.3758/BF03212109
   Blignaut PJ, 2013, P EYE TRACK S AFR C, P29
   Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   Çöltekin A, 2010, INT J GEOGR INF SCI, V24, P1559, DOI 10.1080/13658816.2010.511718
   Corchs SE, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157986
   Coutrot A, 2018, BEHAV RES METHODS, V50, P362, DOI 10.3758/s13428-017-0876-8
   Coutrot A, 2012, J EYE MOVEMENT RES, V5
   Duchowski A., 2003, Eye Tracking Methodology: Theory and Practice
   Eckstein MP, 2011, J VISION, V11, DOI 10.1167/11.5.14
   El Kaddouhi S, 2017, MULTIMED TOOLS APPL, V76, P23077, DOI 10.1007/s11042-017-4415-5
   Eraslan S, 2016, ACM T WEB, V10, DOI 10.1145/2970818
   Findlay J.M., 2004, INTERFACE LANGUAGE V, P135
   Findlay J.M., 1998, Eye guidance in reading and scene perception, P295
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Ghazali KH, 2015, OPT LASER ENG, V67, P49, DOI 10.1016/j.optlaseng.2014.11.003
   Gou C, 2017, PATTERN RECOGN, V67, P23, DOI 10.1016/j.patcog.2017.01.023
   Guestrin ED, 2007, P ANN INT IEEE EMBS, P4556, DOI 10.1109/IEMBS.2007.4353353
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Hansen DW, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P132, DOI 10.1109/ACV.2002.1182170
   Hayes TR, 2019, PSYCHON B REV, V26, P1683, DOI 10.3758/s13423-019-01642-5
   He SY, 2017, TUNN UNDERGR SP TECH, V67, P52, DOI 10.1016/j.tust.2017.04.020
   Ishrat M, 2016, INT J COMPUT SYST IJ, V3, P3587
   Ishrat M, 2017, INT C INF HLTH TECHN, P1
   Kim H, 2017, IMAGE VISION COMPUT, V57, P147, DOI 10.1016/j.imavis.2016.10.003
   Laddi A, 2019, MULTIMED TOOLS APPL, V78, P31215, DOI 10.1007/s11042-019-07940-3
   Li Q, 2013, HYDRAULIC ENGINEERING, 2012 SREE CONFERENCE, P17
   Liu H, 2010, VISAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P267
   Morimoto CH, 2005, COMPUT VIS IMAGE UND, V98, P4, DOI 10.1016/j.cviu.2004.07.010
   Nagy AL, 2003, VISION RES, V43, P1541, DOI 10.1016/S0042-6989(03)00234-7
   NOTON D, 1971, SCIENCE, V171, P308, DOI 10.1126/science.171.3968.308
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Pomplun M, 2006, VISION RES, V46, P1886, DOI 10.1016/j.visres.2005.12.003
   Rubo M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22127-w
   Shahrbabaki S. T., 2015, THESIS U GRENOBLE AL
   Shen JY, 2000, PERCEPTION, V29, P241, DOI 10.1068/p2933
   Smeets JBJ, 2003, J NEUROPHYSIOL, V90, P12, DOI 10.1152/jn.01075.2002
   Song FY, 2013, PATTERN RECOGN, V46, P3157, DOI 10.1016/j.patcog.2013.05.009
   Viergever MA, 2016, MED IMAGE ANAL, V33, P140, DOI 10.1016/j.media.2016.06.030
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wan MH, 2014, INFORM SCIENCES, V274, P55, DOI 10.1016/j.ins.2014.02.145
   Wang DW, 2016, 2016 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P657, DOI 10.1109/CompComm.2016.7924783
   Wang Y, 2017, LIGHTING RES TECHNOL, V49, P1034, DOI 10.1177/1477153516677559
   Wedel M., 2017, REV MARKETING RES, P123, DOI 10.4324/9781351550932-5
   Williams O., 2006, P IEEE C CVPR, V1, P230, DOI DOI 10.1109/CVPR.2006.285
   Wolfe JM, 2017, NAT HUM BEHAV, V1, DOI 10.1038/s41562-017-0058
   Xue JG, 2017, MEDICINE, V96, DOI 10.1097/MD.0000000000006444
   Yamazoe H, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P245, DOI 10.1145/1344471.1344527
   Yarbus A. L., 1967, Eye Movements and Vision
   YIP RKK, 1992, PATTERN RECOGN, V25, P1007, DOI 10.1016/0031-3203(92)90064-P
   Young AH, 2013, J EXP PSYCHOL HUMAN, V39, P168, DOI 10.1037/a0028679
   Yu MX, 2018, INTELL DATA ANAL, V22, P345, DOI 10.3233/IDA-173361
   Zelinsky GJ, 1997, J EXP PSYCHOL HUMAN, V23, P244, DOI 10.1037/0096-1523.23.1.244
   Zhang M, 2019, NEUROCOMPUTING, V330, P238, DOI 10.1016/j.neucom.2017.12.053
   Zhu J, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P131, DOI 10.1109/AFGR.2002.1004144
   Zhu ZW, 2005, COMPUT VIS IMAGE UND, V98, P124, DOI 10.1016/j.cviu.2004.07.012
NR 62
TC 1
Z9 1
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24393
EP 24412
DI 10.1007/s11042-020-09117-9
EA JUN 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000541402000002
PM 32837248
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Waheed, M
   Hussain, S
   Khan, AA
   Ahmed, M
   Ahmad, B
AF Waheed, Moomina
   Hussain, Shahid
   Khan, Arif Ali
   Ahmed, Mansoor
   Ahmad, Bashir
TI A methodology for image annotation of human actions in videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image annotation; SIFT; Clustering; Semantic analysis; Image labeling;
   Action recognition
ID FEATURE-EXTRACTION; RECOGNITION; BAG
AB In the context of video-based image classification, image annotation plays a vital role in improving the image classification decision based on it's semantics. Though, several methods have been introduced to adopt the image annotation such as manual and semi-supervised. However, formal specification, high cost, high probability of errors and computation time remain major issues to perform image annotation. In order to overcome these issues, we propose a new image annotation technique which consists of three tiers namely frames extraction, interest point's generation, and clustering. The aim of the proposed technique is to automate the label generation of video frames. Moreover, an evaluation model to assess the effectiveness of the proposed technique is used. The promising results of the proposed technique indicate the effectiveness (77% in terms of Adjusted Random Index) of the proposed technique in the context label generation for video frames. In the end, a comparative study analysis is made between the existing techniques and proposed methodology.
C1 [Waheed, Moomina; Hussain, Shahid; Ahmed, Mansoor] COMSATS Univ, Islamabad, Pakistan.
   [Khan, Arif Ali] Nanjing Univ Aeronaut & Astronaut, Coll CS&T, Nanjing, Peoples R China.
   [Ahmad, Bashir] Qurtuba Univ Sci & Informat Technol, Dept Comp Sci, Dik, Pakistan.
C3 COMSATS University Islamabad (CUI); Nanjing University of Aeronautics &
   Astronautics
RP Hussain, S (corresponding author), COMSATS Univ, Islamabad, Pakistan.
EM moominawaheed@gmail.com; shussain@comsats.edu.pk;
   arif.khan1@nuaa.edu.cn; mansoor1@comsats.edu.pk; bashahmad2@gmail.com
RI Khan, Arif Ali/ABG-2862-2020; khan, Arif/HMV-3165-2023; Hussain,
   Shahid/AAP-5065-2021; Ahmed, Mansoor/IVU-8924-2023
OI Khan, Arif Ali/0000-0002-8479-1481; Hussain, Shahid/0000-0003-4826-3339;
   Ahmed, Mansoor/0000-0003-2034-1403; Waheed, Moomina/0000-0002-5507-3093
CR [Anonymous], 2015, KAP US SILH AN SEL 2
   Bi Y, 2018, IEEE C EVOL COMPUTAT, P392, DOI 10.1109/CEC.2018.8477911
   Bouguettaya A, 2015, EXPERT SYST APPL, V42, P2785, DOI 10.1016/j.eswa.2014.09.054
   Chen YJ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1226, DOI 10.1145/3219819.3219974
   Donges N, 2018, PROS CONS NEURAL NET
   Gerum RC, 2017, METHODS ECOL EVOL, V8, P750, DOI 10.1111/2041-210X.12702
   Hernández-García R, 2018, EXPERT SYST APPL, V92, P182, DOI 10.1016/j.eswa.2017.09.016
   Kavasidis I, 2014, MULTIMED TOOLS APPL, V70, P413, DOI 10.1007/s11042-013-1419-7
   Lonarkar V, 2017, INT C INV COMP INF I, DOI [10.1109/icici.2017.8365241, DOI 10.1109/ICICI.2017.8365241]
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo S, 2016, LECT NOTES COMPUT SC, V9887, P187, DOI 10.1007/978-3-319-44781-0_23
   Luo S, 2016, LECT NOTES COMPUT SC, V9949, P529, DOI 10.1007/978-3-319-46675-0_58
   Nemirovskiy VB, 2017, COMPUT OPT, V41, P59, DOI 10.18287/2412-6179-2017-41-1-59-66
   Pagare R., 2012, International Journal of Computer Applications, V37, P42, DOI DOI 10.5120/4616-6295
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   Peikari M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24876-0
   Peng X, 2017, IEEE T NEUR NET LEAR, V28, P791, DOI 10.1109/TNNLS.2016.2536741
   Rezaee MJ, 2018, PHYSICA A, V489, P78, DOI 10.1016/j.physa.2017.07.017
   Sarwas G, 2018, 2018 SIGNAL PROCESSI, DOI DOI 10.23919/SPA.2018.8563400
   Shi ZZ, 2010, IFIP ADV INF COMM TE, V340, P4, DOI 10.1007/978-3-642-16327-2_4
   Singla A, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING AND COMMUNICATION TECHNOLOGIES FOR SMART NATION (IC3TSN), P72, DOI 10.1109/IC3TSN.2017.8284453
   Steinley D, 2018, BRIT J MATH STAT PSY, V71, P287, DOI 10.1111/bmsp.12116
   Tran D, 2008, LECT NOTES COMPUT SC, V5302, P548, DOI 10.1007/978-3-540-88682-2_42
   UCF Center for Research, MENU
   Ukita N, 2018, COMPUT VIS IMAGE UND, V170, P67, DOI 10.1016/j.cviu.2018.02.003
   Wagner J, 2018, ARXIV PREPRINT ARXIV
   Wang C, 2016, 2016 INT JOINT C NEU, DOI [10.1109/ijcnn.2016.7727435, DOI 10.1109/IJCNN.2016.7727435]
NR 27
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24347
EP 24365
DI 10.1007/s11042-020-09091-2
EA JUN 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000541402000001
DA 2024-07-18
ER

PT J
AU Suh, MS
   Nam, C
AF Suh, Min-soo
   Nam, Choonsung
TI A study on operational ability comparing drone-centric and user-centric
   control in external piloting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Drone piloting; User-centric; Drone-centric; External piloting;
   Operational ability; Learning effect
AB Drone manipulation can be divided into external piloting and internal piloting. Internal piloting is a technique where a user monitors the status of a drone and controls it. On the other hand, external piloting is a technique in which the user controls a drone from the point of view of the user. In this case, external piloting can cause the operator to make a mistake regarding the operation of the drone due to the difference in viewpoint between the user and the drone when operating the drone. Therefore, this paper proposes a method to solve this difficulty of drone operation by mismatching the viewpoint between the drones and the users. We compare the user-centric method of con-trolling the drones considering the user's point of view and the drone-centric method of controlling the drones considering the drone's point of view. Through this experiment, we demonstrate the excellence of a user-centric point of view. Additional study includes whether the difficulty of drone manipulation can be overcome by learning.
C1 [Suh, Min-soo] Yonsei Univ, Grad Sch Informat, Seoul, South Korea.
   [Nam, Choonsung] Inha Univ, Dept Software Convergence Engn, Incheon, South Korea.
C3 Yonsei University; Inha University
RP Nam, C (corresponding author), Inha Univ, Dept Software Convergence Engn, Incheon, South Korea.
EM zeclix@yonsei.ac.kr; namgun99@inha.ac.kr
FU INHA UNIVERSITY Research Grant
FX This work was supported by INHA UNIVERSITY Research Grant.
CR Baiocchi V, 2013, INT ARCH PHOTOGRAMM, P21, DOI 10.5194/isprsarchives-XL-1-W2-21-2013
   Brooks JS, 2006, NEW J PHYS, V8, DOI 10.1088/1367-2630/8/10/255
   Canan JW, 1999, AEROSPACE AM, V37, P26
   Ercoline W, 2006, AVIAT SPACE ENV MED, V77, P12
   Garcia A, 2015, INT CONF UNMAN AIRCR, P338, DOI 10.1109/ICUAS.2015.7152308
   Hanafi D, 2013, SIMPLE GUI WIRELESS
   Hing JT, 2009, J INTELL ROBOT SYST, V54, P3, DOI 10.1007/s10846-008-9252-3
   Holton AE, 2015, JOURNAL PRACT, V9, P634, DOI 10.1080/17512786.2014.980596
   Hyneman J, 2002, U.S. Patent, Patent No. [6,458,008, 6458008]
   Kim BH, 2014, COMPUT BIOL MED, V51, P82, DOI 10.1016/j.compbiomed.2014.04.020
   Lee J, 2017, INT CONF SIM SEMI PR, P157, DOI 10.23919/SISPAD.2017.8085288
   Li HM, 2013, CHIN AUTOM CONGR, P697, DOI 10.1109/CAC.2013.6775824
   Mogili UMR, 2018, PROCEDIA COMPUT SCI, V133, P502, DOI 10.1016/j.procs.2018.07.063
   Newcome L. R., 2004, UNMANNED AVIATION BR
   Ribeiro R, 2018, 2018 2 INT C TECHN I, P1
   Rosales C, 2019, INT CONF UNMAN AIRCR, P93, DOI [10.1109/ICUAS.2019.8798282, 10.1109/icuas.2019.8798282]
   Saakes D, 2013, PROCEEDINGS OF 2013 23RD INTERNATIONAL CONFERENCE ON ARTIFICIAL REALITY AND TELEXISTENCE (ICAT 2013), P13
   Santos MCP, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P232, DOI 10.1109/ICIT.2015.7125104
   Shukla A, 2016, INT C CONTR AUTOMAT, P194, DOI 10.1109/ICCAS.2016.7832320
   WEIBEL R. E., 2006, SAFETY CONSIDERATION
NR 20
TC 1
Z9 1
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24265
EP 24279
DI 10.1007/s11042-020-09119-7
EA JUN 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000541303900001
DA 2024-07-18
ER

PT J
AU Bae, W
   Kwak, J
AF Bae, Won-il
   Kwak, Jin
TI Smart card-based secure authentication protocol in multi-server IoT
   environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User authentication; Multi server; Internet of things; Formal
   verification; Security
ID EFFICIENT
AB In recent years, the internet of things has been widely utilized in various fields, such as in smart factories or connected cars. As its domain of application has expanded, it has begun to be employed using multi-server architectures for a more efficient use of resources. However, because users wishing to receive IoT(Internet of Things) services connect to multi-servers over wireless networks, this can expose systems to various attacks and result in serious security risks. To protect systems (and users) from potential security vulnerabilities, a secure authentication technology is necessary. In this paper, we propose a smart card-based authentication protocol, which performs the authentication for each entity by allowing users to go through the authentication process using a smart card transmitted from an authentication server, and to login to a server connected to the IoT. Furthermore, the security of our proposed authentication protocol is verified by simulating a formal verification scenario using AVISPA(Automated Validation of Internet Security Protocols and Applications), a security protocol-verification tool.
C1 [Bae, Won-il] Ajou Univ, Dept Comp Engn, Suwon, South Korea.
   [Bae, Won-il; Kwak, Jin] Ajou Univ, Ind Univ Cooperat, 260 Worldcup Ro, Suwon 16499, Gyunggi Do, South Korea.
   [Kwak, Jin] Ajou Univ, Dept Cyber Secur, Suwon, South Korea.
C3 Ajou University; Ajou University; Ajou University
RP Kwak, J (corresponding author), Ajou Univ, Ind Univ Cooperat, 260 Worldcup Ro, Suwon 16499, Gyunggi Do, South Korea.; Kwak, J (corresponding author), Ajou Univ, Dept Cyber Secur, Suwon, South Korea.
EM wibae.isaa@gmail.com; security@ajou.ac.kr
OI Kwak, Jin/0000-0001-6931-2705
CR Abdellatif Riham., 2011, Int. J. Netw. Secur, V12, P13, DOI DOI 10.1016/J.EJRS.2011.11.003.
   Armando A, 2005, LECT NOTES COMPUT SC, V3576, P281
   Chang CC, 2013, J INF SCI ENG, V29, P1135
   El-Emam Eman., 2011, International Journal of Network Security, V12, P159
   He D., 2011, INT J NETWORK SECURI, V13, P58
   Hwang MS, 2010, J SYST SOFTWARE, V83, P163, DOI 10.1016/j.jss.2009.07.050
   Li X, 2012, J NETW COMPUT APPL, V35, P763, DOI 10.1016/j.jnca.2011.11.009
   Maitra T, 2016, SECUR COMMUN NETW, V9, P4615, DOI 10.1002/sec.1653
   Mittal H, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS, P808, DOI 10.1109/CICN.2014.173
   Odelu V, 2015, IEEE T INF FOREN SEC, V10, P1953, DOI 10.1109/TIFS.2015.2439964
   Ruhul A, 2016, RECENT ADV INFORM TE, DOI [10.1109/RAIT.2016.7507936, DOI 10.1109/RAIT.2016.7507936]
   Sethi P, 2017, J ELECTR COMPUT ENG, V2017, DOI 10.1155/2017/9324035
   Sood SK, 2011, J NETW COMPUT APPL, V34, P609, DOI 10.1016/j.jnca.2010.11.011
   Yoon E-J, 2009, IFIP INT C NETW PAR, DOI [10.1109/NPC.2009.42, DOI 10.1109/NPC.2009.42]
   Ziauddin S, 2013, ASIA JT CONF INF SEC, P108, DOI 10.1109/ASIAJCIS.2013.25
NR 15
TC 29
Z9 31
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 15793
EP 15811
DI 10.1007/s11042-017-5548-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600002
OA hybrid
DA 2024-07-18
ER

PT J
AU Ding, H
   Wei, B
   Gu, ZR
   Yu, ZB
   Zheng, HY
   Zheng, B
   Li, J
AF Ding, Hao
   Wei, Bin
   Gu, Zhaorui
   Yu, Zhibin
   Zheng, Haiyong
   Zheng, Bing
   Li, Juan
TI KA-Ensemble: towards imbalanced image classification ensembling
   under-sampling and over-sampling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Class-imbalance learning; Under-sampling; Over-sampling; Ensemble
   learning; Image classification
ID REGRESSION; PREDICTION; SMOTE
AB Imbalanced learning has become a research emphasis in recent years because of the growing number of class-imbalance classification problems in real applications. It is particularly challenging when the imbalanced rate is very high. Sampling, including under-sampling and over-sampling, is an intuitive and popular way in dealing with class-imbalance problems, which tries to regroup the original dataset and is also proved to be efficient. The main deficiency is that under-sampling methods usually ignore many majority class examples while over-sampling methods may easily cause over-fitting problem. In this paper, we propose a new algorithm dubbed KA-Ensemble ensembling under-sampling and over-sampling to overcome this issue. Our KA-Ensemble explores EasyEnsemble framework by under-sampling the majority class randomly and over-sampling the minority class via kernel based adaptive synthetic (Kernel-ADASYN) at meanwhile, yielding a group of balanced datasets to train corresponding classifiers separately, and the final result will be voted by all these trained classifiers. Through combining under-sampling and over-sampling in this way, KA-Ensemble is good at solving class-imbalance problems with large imbalanced rate. We evaluated our proposed method with state-of-the-art sampling methods on 9 image classification datasets with different imbalanced rates ranging from less than 2 to more than 15, and the experimental results show that our KA-Ensemble performs better in terms of accuracy (ACC), F-Measure, G-Mean, and area under curve (AUC). Moreover, it can be used in both dichotomy and multi-classification on both image classification and other class-imbalance problems.
C1 [Ding, Hao; Gu, Zhaorui; Yu, Zhibin; Zheng, Haiyong; Zheng, Bing] Ocean Univ China, Coll Informat Sci & Engn, Dept Elect Engn, Qingdao 266100, Peoples R China.
   [Wei, Bin] Qingdao Univ, Shandong Key Lab Digital Med & Comp Assisted Surg, Affiliated Hosp, Qingdao 266003, Peoples R China.
   [Zheng, Haiyong] Univ Dundee, Sch Sci & Engn, Dept Math, Dundee DD1 4HN, Scotland.
   [Li, Juan] Qingdao Agr Univ, Coll Mech & Elect Engn, Qingdao 266109, Peoples R China.
C3 Ocean University of China; Qingdao University; University of Dundee;
   Qingdao Agricultural University
RP Zheng, HY (corresponding author), Ocean Univ China, Coll Informat Sci & Engn, Dept Elect Engn, Qingdao 266100, Peoples R China.; Wei, B (corresponding author), Qingdao Univ, Shandong Key Lab Digital Med & Comp Assisted Surg, Affiliated Hosp, Qingdao 266003, Peoples R China.; Zheng, HY (corresponding author), Univ Dundee, Sch Sci & Engn, Dept Math, Dundee DD1 4HN, Scotland.
EM abbyzzpp@126.com; zhenghaiyong@ouc.edu.cn
RI Yu, Zhibin/Z-1138-2019; Zheng, Haiyong/I-7771-2014
OI Yu, Zhibin/0000-0003-4372-1767; Zheng, Haiyong/0000-0002-8027-0734
CR Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chawla NV, 2003, LECT NOTES ARTIF INT, V2838, P107, DOI 10.1007/978-3-540-39804-2_12
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361
   Estabrooks A, 2004, COMPUT INTELL-US, V20, P18, DOI 10.1111/j.0824-7935.2004.t01-1-00228.x
   Fan W, 1999, MACHINE LEARNING, PROCEEDINGS, P97
   Fanny, 2018, Procedia Computer Science, V135, P60, DOI 10.1016/j.procs.2018.08.150
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guo H., 2004, SIGKDD EXPLORATIONS, V6, P30, DOI DOI 10.1145/1007730.1007736
   Han H, 2005, LECT NOTES COMPUT SC, V3644, P878, DOI 10.1007/11538059_91
   HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155
   He H, 2013, IMBALANCED LEARNING: FOUNDATIONS, ALGORITHMS, AND APPLICATIONS, P1, DOI 10.1002/9781118646106
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holte R. C., 2003, Workshop on learning from imbalanced datasets II, V11, P1
   Huang C, 2016, PROC CVPR IEEE, P5375, DOI 10.1109/CVPR.2016.580
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Jo Taeho, 2004, ACM Sigkdd Explorations Newsletter, V6, P40, DOI DOI 10.1145/1007730.1007737
   Kaur P, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P2620
   Krawczyk B, 2016, PROG ARTIF INTELL, V5, P221, DOI 10.1007/s13748-016-0094-0
   Kubat M., 1997, ICML, P179
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu XY, 2009, IEEE T SYST MAN CY B, V39, P539, DOI 10.1109/TSMCB.2008.2007853
   Lu H, 2019, IEEE WIREL COMMUN, V26, P1
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   Ma JZ, 2017, IEEE T IMAGE PROCESS, V26, P1216, DOI 10.1109/TIP.2016.2631883
   Mao WT, 2019, IEEE ACCESS, V7, P9515, DOI 10.1109/ACCESS.2018.2890693
   Mao WT, 2017, MECH SYST SIGNAL PR, V83, P450, DOI 10.1016/j.ymssp.2016.06.024
   MOHAMED AM, 1995, IEEE T CONTR SYST T, V3, P202, DOI 10.1109/87.388128
   Najafabadi MM, 2015, Journal of big data, V2, P1, DOI [10.1186/s40537-014-0007-7, DOI 10.1186/S40537-014-0007-7]
   Ou WH, 2018, MULTIMED TOOLS APPL, V77, P10569, DOI 10.1007/s11042-017-4672-3
   Peng LZ, 2014, INFORM SCIENCES, V288, P347, DOI 10.1016/j.ins.2014.04.046
   PRESS SJ, 1978, J AM STAT ASSOC, V73, P699, DOI 10.2307/2286261
   Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Tang B, 2015, IEEE C EVOL COMPUTAT, P664, DOI 10.1109/CEC.2015.7256954
   Wang C, 2017, IEEE IMAGE PROC, P855, DOI 10.1109/ICIP.2017.8296402
   Wang QZ, 2016, IEEE T IMAGE PROCESS, V25, P1425, DOI 10.1109/TIP.2016.2521180
   Weiss G.M., 2004, SIGKDD Explor. Newsl., V6, P7, DOI [10.1145/1007730.1007734, DOI 10.1145/1007730.1007734]
   Yen SJ, 2009, EXPERT SYST APPL, V36, P5718, DOI 10.1016/j.eswa.2008.06.108
   Yu HL, 2013, NEUROCOMPUTING, V101, P309, DOI 10.1016/j.neucom.2012.08.018
   Zhou Q, 2019, WORLD WIDE WEB, V22, P555, DOI 10.1007/s11280-018-0556-3
   Zhou Q, 2016, PATTERN RECOGN, V59, P312, DOI 10.1016/j.patcog.2016.03.023
   Zhou Y, 2016, INT J COMPUT VISION, V118, P337, DOI 10.1007/s11263-015-0879-9
NR 50
TC 12
Z9 14
U1 3
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14871
EP 14888
DI 10.1007/s11042-019-07856-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900031
DA 2024-07-18
ER

PT J
AU Feng, YY
   Liu, H
   Zhao, SS
AF Feng, Yingying
   Liu, Hui
   Zhao, Shasha
TI Moving target recognition and tracking algorithm based on multi-source
   information perception
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quick calculation; Resampling; Particle wave filtering; Non; monitoring;
   Video tracking
AB This paper proposed a non- monitoring video multi- object tracking algorithm based on fast resampling particle wave filtering in order to improve the unsupervised monitoring effect of video moving objects. Each particle (sample) can represent the real state assumption. In each time step, the likelihood function is used to evaluate and quantify each particle. The estimated state is approximated by the average value of all the particles after evaluating each particle. To avoid degradation, we use particle resampling to create a new weighing set. Finally, by the simulation test of a real monitoring image show that the proposed algorithm improves the tracking accuracy by more than 20% and the computational efficiency by more than 30% compared with the contrast algorithm, which verifies the effectiveness of the proposed method.
C1 [Feng, Yingying; Liu, Hui; Zhao, Shasha] Fuyang Normal Univ, Coll Informat Engn, Fuyang 236041, Peoples R China.
C3 Fuyang Normal University
RP Liu, H (corresponding author), Fuyang Normal Univ, Coll Informat Engn, Fuyang 236041, Peoples R China.
EM laosun45a@163.com
CR Acharya UR, 2019, FUTURE GENER COMP SY, V91, P290, DOI 10.1016/j.future.2018.08.044
   Benjamini Y, 2001, ANN STAT, V29, P1165
   Benko M, 2009, ANN STAT, V37, P1, DOI 10.1214/07-AOS516
   Elamaran V, 2018, IEEE ACCESS, V6, P62874, DOI 10.1109/ACCESS.2018.2876119
   Jiao DD, 2019, FUTURE GENER COMP SY, V92, P324, DOI 10.1016/j.future.2018.10.019
   Khamparia A, 2020, NEURAL COMPUT APPL, V32, P11083, DOI 10.1007/s00521-018-3896-0
   Khan JA, 2010, COMPUT STAT DATA AN, V54, P3121, DOI 10.1016/j.csda.2010.01.031
   Li HY, 2019, FUTURE GENER COMP SY, V98, P69, DOI 10.1016/j.future.2018.12.001
   Li R., 2013, J INFORM COMPUTATION, V10, P2159, DOI [10.12733/jics20101694, DOI 10.12733/JICS20101694]
   Liu JJ, 2018, IEEE ACCESS, V6, P61457, DOI 10.1109/ACCESS.2018.2876135
   Medeiros H, 2010, COMPUT VIS IMAGE UND, V114, P1264, DOI 10.1016/j.cviu.2010.03.020
   Mihaylova L, 2007, IEEE T WIREL COMMUN, V6, P3589, DOI 10.1109/TWC.2007.05912
   Nei M, 1996, ANNU REV GENET, V30, P371, DOI 10.1146/annurev.genet.30.1.371
   Oh SL, 2020, NEURAL COMPUT APPL, V32, P10927, DOI 10.1007/s00521-018-3689-5
   Santamaria-Granados L, 2019, IEEE ACCESS, V7, P57, DOI 10.1109/ACCESS.2018.2883213
   Sathishkumar BR, 2020, NEURAL COMPUT APPL, V32, P11097, DOI 10.1007/s00521-018-3919-x
   Tsingos N, 2004, ACM T GRAPHIC, V23, P249, DOI 10.1145/1015706.1015710
   Turechek WW, 1999, PHYTOPATHOLOGY, V89, P421, DOI 10.1094/PHYTO.1999.89.5.421
   Wu ZC, 2019, FUTURE GENER COMP SY, V93, P170, DOI 10.1016/j.future.2018.10.018
   Yuan M, 2006, J AM STAT ASSOC, V101, P1323, DOI 10.1198/016214505000000394
   Zhao HY, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 3, PROCEEDINGS, P311, DOI 10.1109/FSKD.2007.221
NR 21
TC 4
Z9 4
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16941
EP 16954
DI 10.1007/s11042-019-7483-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600062
DA 2024-07-18
ER

PT J
AU Han, J
   Xie, L
   Liu, J
   Li, X
AF Han, Jing
   Xie, Lun
   Liu, Jing
   Li, Xue
TI Personalized broad learning system for facial expression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Broad learning system (BLS); Facial expression recognition; Singular
   value decomposition (SVD); Transfer learning; Sparse coding
ID RECOGNITION; MODEL
AB Understanding human emotions through facial expressions is key enabling technology for interactive robots. Most approaches of facial expression recognition are designed for the average user. It is difficult for them to maintain high accuracy for special users with different cultural backgrounds and personalities, which limits their application in real world scenarios. Personalized classifier is a feasible solution, but it needs to be retrained for new users outside the training set. In this paper we present a framework for personalizing facial expression recognition which does not require re-training models after entering new data. Personalized incremental updating mechanism is achieved by designing a novel broad learning system. Specifically, we propose a transfer learning model based on emotional information entropy as the mapping feature layer to ensure the accuracy of mapping under the condition of small sample size. Then, the weights of our proposed model can be updated by multi-layer singular value decomposition method if incremental data is entered. We exhibit the superiority of our approach in multiple facial expression datasets. Experimental results show that our method has higher accuracy and generalization ability with previous personalization techniques.
C1 [Han, Jing; Xie, Lun] Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Beijing 100083, Peoples R China.
   [Liu, Jing; Li, Xue] Peking Univ, Inst Mental Hlth, Beijing 100191, Peoples R China.
C3 University of Science & Technology Beijing; Peking University
RP Xie, L (corresponding author), Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Beijing 100083, Peoples R China.
EM xielun@ustb.edu.cn
RI chen, chen/JGD-3057-2023; LIU, Qing Yu/IWV-1159-2023
OI Liu, Jing/0000-0002-6720-2171
CR [Anonymous], COMPUTER VISION PATT
   Chen CLP, 2018, IEEE T NEUR NET LEAR, V29, P10, DOI 10.1109/TNNLS.2017.2716952
   Chen ZQ, 2017, NEUROCOMPUTING, V226, P262, DOI 10.1016/j.neucom.2016.12.004
   Cho D, 2019, IEEE T IMAGE PROCESS, V28, P1054, DOI 10.1109/TIP.2018.2872925
   Chu WS, 2017, IEEE T PATTERN ANAL, V39, P529, DOI 10.1109/TPAMI.2016.2547397
   Feng S, 2020, IEEE T CYBERNETICS, V50, P414, DOI 10.1109/TCYB.2018.2857815
   Feydy Jean, 2018, ARXIV181008278
   Gando G, 2016, EXPERT SYST APPL, V66, P295, DOI 10.1016/j.eswa.2016.08.057
   Goyani M.M., 2017, Electronic Letters on Computer Vision and Image Analysis, V16, P54
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hong H, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P354, DOI 10.1109/AFGR.1998.670974
   Hong MY, 2017, MATH PROGRAM, V162, P165, DOI 10.1007/s10107-016-1034-2
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Jia S, 2015, PATTERN RECOGN LETT, V58, P35, DOI 10.1016/j.patrec.2015.02.006
   Jiang R, 2017, PATTERN RECOGN, V67, P245, DOI 10.1016/j.patcog.2017.02.003
   Kokkinos Y, 2018, NEUROCOMPUTING, V295, P29, DOI 10.1016/j.neucom.2018.01.005
   Kong Y, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10050685
   Kow KW, 2016, P 9 INT C ROB VIS SI, P673
   Lee J, 2017, AAAI CONF ARTIF INTE, P2154
   Li C, 2018, NEURAL NETWORKS, V106, P294, DOI 10.1016/j.neunet.2018.07.015
   Lu J, 2015, KNOWL-BASED SYST, V80, P14, DOI 10.1016/j.knosys.2015.01.010
   Martinez DL, 2017, IEEE COMPUT SOC CONF, P2318, DOI 10.1109/CVPRW.2017.286
   Monteiro JC, 2015, SENSORS-BASEL, V15, P1903, DOI 10.3390/s150101903
   Owusu E, 2014, APPL INTELL, V40, P536, DOI 10.1007/s10489-013-0478-9
   Pratama M, 2017, IEEE T FUZZY SYST, V25, P1175, DOI 10.1109/TFUZZ.2016.2599855
   Rebuffi SA, 2018, PROC CVPR IEEE, P8119, DOI 10.1109/CVPR.2018.00847
   Ruiz A, 2018, IEEE T IMAGE PROCESS, V27, P3969, DOI 10.1109/TIP.2018.2830189
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Siddiqi MH, 2015, IEEE T IMAGE PROCESS, V24, P1386, DOI 10.1109/TIP.2015.2405346
   Tao DP, 2018, IEEE T IMAGE PROCESS, V27, P325, DOI 10.1109/TIP.2017.2762588
   Uçar A, 2016, NEURAL COMPUT APPL, V27, P131, DOI 10.1007/s00521-014-1569-1
   Uddin M, 2017, I C NETWORK PROTOCOL, DOI 10.1109/TPAMI.2017.2656884
   Wang JFJF, 2018, J KNOWL MANAG, V22, P1379, DOI 10.1108/JKM-04-2017-0145
   Xie L, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.026018
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Ye ZH, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (IEEE ICMA 2014), P269, DOI 10.1109/ICMA.2014.6885707
   Zen G, 2016, IEEE T MULTIMEDIA, V18, P775, DOI 10.1109/TMM.2016.2523421
   Zhang ZP, 2018, INT J COMPUT VISION, V126, P550, DOI 10.1007/s11263-017-1055-1
NR 38
TC 6
Z9 6
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16627
EP 16644
DI 10.1007/s11042-019-07979-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600046
DA 2024-07-18
ER

PT J
AU Lai, HY
   Tao, YZ
   Wang, CL
   Xu, LF
   Tang, DY
   Li, GL
AF Lai, Huiyuan
   Tao, Yizheng
   Wang, Chunliu
   Xu, Lunfan
   Tang, Dingyong
   Li, Gongliang
TI Bi-directional attention comparison for semantic sentence matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic matching; Alignment; Attention mechanism; Chinese
AB Semantic sentence matching, also known as calculation of text similarity, is one of the most important problems in natural language processing. Existing deep models mostly focus on the neural networks with attention mechanism. In this paper, we present a deep architecture to match two Chinese sentences, which only relies on alignment instead of long short-term memory network after attention mechanism is employed to get interaction information between sentence-pairs, the model becomes more lightweight and simple. Meanwhile, in order to capture semantic features enough, in addition to using max pooling and average pooling operation, we also employ a pooling operation named attention-pooling to aggregate information from the whole sentence, the final matching score is obtained after a multilayer perceptron classifier. Experiments are carried out on ATEC-NLP dataset and outline the effectiveness of our approach.
C1 [Lai, Huiyuan; Tao, Yizheng; Wang, Chunliu; Xu, Lunfan; Tang, Dingyong; Li, Gongliang] China Acad Engn Phys, Inst Comp Applicat, Mianyang, Sichuan, Peoples R China.
C3 Chinese Academy of Engineering Physics
RP Tao, YZ (corresponding author), China Acad Engn Phys, Inst Comp Applicat, Mianyang, Sichuan, Peoples R China.
EM lawecs@126.com; taolilan@126.com; spring_willow@163.com;
   xulunfan1994@outlook.com; tdy2000@126.com; ligongliang1982@126.com
CR Adit Deshpande, DIVING NATURAL LANGU
   Aliguliyev RM, 2009, EXPERT SYST APPL, V36, P7764, DOI 10.1016/j.eswa.2008.11.022
   [Anonymous], 2013, P 26 INT C NEUR INF
   [Anonymous], 2017, QUORA QUESTION PAIR
   [Anonymous], 2017, R NET MACH READ COMP
   [Anonymous], 2015, ARXIV, DOI DOI 10.1109/TASLP.2016.2520371
   Ant Financial, ANT FIN ART COMP
   Berger A., 2000, SIGIR Forum, V34, P192
   Bowman S. R., 2015, Proceedings of the 2015 conference on empirical methods in natural language processing, DOI [DOI 10.18653/V1/D15-1075, 10.18653/v1/d15-1075, 10.18653/v1/D15-1075]
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen Q, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1657, DOI 10.18653/v1/P17-1152
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Choi J, 2017, ARXIV170702786V4
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2333
   Junyi S., JIEBA
   Kingma D. P., 2014, arXiv
   Lu H, 2018, FUTURE GENER COMP SY, V10, P1016
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   Lu Huimin, 2016, CONCURRENCY COMPUTAT, V29
   Mou LL, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P130
   Nie Yixin, 2017, P 2 WORKSH EV VECT S, P41, DOI DOI 10.18653/V1/W17-5308
   Parikh AP., 2016, EMNLP
   Seo M., 2016, Bidirectional attention flow for machine comprehension
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Srivastava RupeshKumar., 2015, CoRR
   Williams A., 2017, ARXIV170405426
   Xing X, 2017, IEEE T IMAGE PROCESS
   Xu X, 2019, WORLD WIDE WEB, V22, P657, DOI 10.1007/s11280-018-0541-x
   Xu X, 2016, NEUROCOMPUTING, V213, P191, DOI 10.1016/j.neucom.2015.11.133
   Zhang S, 2017, APPL SCI-BASEL, V7
NR 33
TC 3
Z9 4
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14609
EP 14624
DI 10.1007/s11042-018-7063-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900017
DA 2024-07-18
ER

PT J
AU Huang, L
   Zhang, WF
   Nie, J
   Wei, ZQ
AF Huang, Lei
   Zhang, Wenfeng
   Nie, Jie
   Wei, Zhiqiang
TI Person re-identification based on multi-appearance model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Deep neural network; Video surveillance;
   Multi-appearance model; Person retrieval
AB Person re-identification plays important roles in many practical applications. Due to various human poses, complex backgrounds and similarity of person clothes, person re-identification is still a challenging task. In this paper, we mainly focus on the robust and discriminative appearance feature representation and proposed a novel multi-appearance method for person re-identification. First, we proposed a deep feature fusion method and get the multi-appearance feature by combining two Convolutional Neural Networks. Then, in order to further enhance the representation of the appearance feature, the multi-part model was constructed by combining the whole body and the six body parts. Additionally, we optimized the feature extraction process by adding a pooling layer. Comprehensive and comparative experiments with the state-of-the-art methods over publicly available datasets demonstrated that the proposed method can get promising results.
C1 [Huang, Lei; Zhang, Wenfeng; Nie, Jie; Wei, Zhiqiang] Ocean Univ China, Coll Informat Sci & Engn, Qingdao, Peoples R China.
C3 Ocean University of China
RP Nie, J (corresponding author), Ocean Univ China, Coll Informat Sci & Engn, Qingdao, Peoples R China.
EM niejie@ouc.edu.cn
RI Nie, Jie/ABG-9228-2021; wei, zhiqiang/M-8868-2013
OI Nie, Jie/0000-0003-4952-7666; 
FU National Natural Science Foundation of China [61702471, 61872326,
   61672475]; Shandong Provincial Natural Science Foundation [ZR2019MF044]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61702471, No. 61872326, No.61672475); Shandong Provincial
   Natural Science Foundation (ZR2019MF044).
CR Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen YP, 2016, LECT NOTES COMPUT SC, V9967, P695, DOI 10.1007/978-3-319-46654-5_76
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Gong A, 2018, ARXIV180305872CS
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Huang H, 2018, ARXIV181211369CS
   Kuo CH, 2013, IEEE WORK APP COMP, P281, DOI 10.1109/WACV.2013.6475030
   Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24
   Lee CY, 2018, IEEE T PATTERN ANAL, V40, P863, DOI 10.1109/TPAMI.2017.2703082
   Li AN, 2014, ADV COMPUT VIS PATT, P119, DOI 10.1007/978-1-4471-6296-4_6
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055
   Liu CX, 2014, PATTERN RECOGN, V47, P1602, DOI 10.1016/j.patcog.2013.11.001
   Ma BP, 2014, ADV COMPUT VIS PATT, P23, DOI 10.1007/978-1-4471-6296-4_2
   Mirmahboub B, 2016, IEEE IMAGE PROC, P774, DOI 10.1109/ICIP.2016.7532462
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Ren CX, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106995
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Wang D, 2016, IEEE IMAGE PROC, P4289, DOI 10.1109/ICIP.2016.7533169
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wang ZJ, 2014, J CHEM-NY, V2014, DOI 10.1155/2014/475389
   Wu Y, 2019, IEEE T IMAGE PROCESS, V28, P2872, DOI 10.1109/TIP.2019.2891895
   Xiao T, 2016, ARXIV160401850CS
   Yang H, 2015, COMM COM INF SC, V547, P219, DOI 10.1007/978-3-662-48570-5_21
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Yu HX, 2020, IEEE T PATTERN ANAL, V42, P956, DOI 10.1109/TPAMI.2018.2886878
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2017, ARXIV170108398CS
NR 37
TC 0
Z9 0
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16413
EP 16423
DI 10.1007/s11042-020-08927-1
EA MAY 2020
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000536434100001
DA 2024-07-18
ER

PT J
AU Guo, J
   Bai, H
   Tang, ZY
   Xu, PF
   Gan, DG
   Liu, BY
AF Guo, Jun
   Bai, Hao
   Tang, Zhanyong
   Xu, Pengfei
   Gan, Daguang
   Liu, Baoying
TI Multi modal human action recognition for video content matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Video and Wi-Fi clues; Multi modal learning;
   Convolutional neural networks
AB Human action recognition (HAR)in videos is a challenging task in computer vision. Conventional methods are prone to explore the spatiotemporal or optical representations for video actions. However, optical representation might be inefficient in some real-life situations, such as object occlusion and dim light. To address this issue, this paper presents a novel approach for human action recognition by jointly exploiting video and Wi-Fi clues. We leverage the fact that Wi-Fi signals carry discriminative information of human actions, which is robust to optical limitations. To validate this innovative thought, we conceive a practical framework for HAR and setup a dataset containing both video clips and Wi-Fi Channel State Information of human actions. The 3D convolutional neural network was used to extract the video features and the statistical algorithms were used to extract radio features. A classical linear support vector machine is employed as the classifier after the video and radio feature fusion. Comprehensive experiments on this dataset achieved desirable results with the maximum improvement in accuracy by 10%. This demonstrates our promising findings: with the aid of Wi-Fi Channel State Information, the performance of the video action recognition methods can be improved significantly, even under the optical limitation.
C1 [Guo, Jun; Bai, Hao; Tang, Zhanyong; Xu, Pengfei; Liu, Baoying] Northwest Univ, Sch Informat Sci & Technol, Xuefudajie St 1, Xian 710127, Shaanxi, Peoples R China.
   [Guo, Jun] Shaanxi Int Joint Res Ctr Battery Free Internet T, Taibaibeilu 229, Xian 710069, Shaanxi, Peoples R China.
   [Gan, Daguang] Wanfang Data Co Ltd, Haidianqu Fuxinglu 15, Beijing 100038, Peoples R China.
C3 Northwest University Xi'an
RP Tang, ZY; Xu, PF (corresponding author), Northwest Univ, Sch Informat Sci & Technol, Xuefudajie St 1, Xian 710127, Shaanxi, Peoples R China.
EM guojun@nwu.edu.cn; baihao2017@stumail.nwu.edu.cn; zytang@nwu.edu.cn;
   pfxu@nwu.edu.cn; gandg@wanfangdata.com.cn; paola.liu@nwu.edu.cn
FU National Key Research and Development Program of China [2017YFB1400301];
   National Science Foundation of China [61973250, 61702415, 61902318,
   61973249]; Shaanxi Science and Technology Innovation Team Support
   Project [2018TD-026]; China University of Labor Relations [20XYJ007]
FX This work is financially supported in part by the National Key Research
   and Development Program of China under Grant No.2017YFB1400301 and
   National Science Foundation of China under Grant No. 61973250, 61702415,
   61902318, 61973249.We are also grateful to all volunteers, the Shaanxi
   Science and Technology Innovation Team Support Project under grant
   agreement 2018TD-026, China University of Labor Relations (20XYJ007) and
   Wanfang Data Co. for their contribution to our dataset.
CR Adams WH, 2003, EURASIP J APPL SIG P, V2003, P170, DOI 10.1155/S1110865703211173
   Adib F., 2015, PROC 12 USENIX S NET, P279
   Adib F, 2013, ACM SIGCOMM COMP COM, V43, P75, DOI 10.1145/2534169.2486039
   Adib Fadel, 2014, Usenix NSDI, V14, P317
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2016, ARXIV161100850
   [Anonymous], 2015, ARXIV150702159
   [Anonymous], 2017, INT C MACH LEARN ICM
   [Anonymous], 2017, arXiv
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Duan SH, 2018, INT J WIREL INF NETW, V25, P146, DOI 10.1007/s10776-018-0389-0
   Feichtenhofer C., 2016, P INT C NEUR INF PRO, P3468
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Gu Y, 2014, 2014 IEEE ASIA PACIFIC CONFERENCE ON WIRELESS AND MOBILE, P60, DOI 10.1109/APWiMob.2014.6920266
   Guo K, 2013, IEEE T IMAGE PROCESS, V22, P2479, DOI 10.1109/TIP.2013.2252622
   Hara K, 2017, ARXIV170807632V1
   Igarashi Y, 2015, INT C NETWB INFO, P187, DOI 10.1109/NBiS.2015.32
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kar A, 2017, PROC CVPR IEEE, P5699, DOI 10.1109/CVPR.2017.604
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li YH, 2012, ENERGIES, V5, P181, DOI 10.3390/en5020181
   Liu Q, 2008, IEEE IC COMP COM NET, P1
   Melgarejo P, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P541, DOI 10.1145/2632048.2632095
   Peng XJ, 2016, LECT NOTES COMPUT SC, V9908, P744, DOI 10.1007/978-3-319-46493-0_45
   Pu S., 2013, P 19 ANN INT C MOB C, P27, DOI 10.1145/2500423.2500436
   Singh B, 2016, PROC CVPR IEEE, P1961, DOI 10.1109/CVPR.2016.216
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Tran A, 2017, IEEE INT CONF COMP V, P3110, DOI 10.1109/ICCVW.2017.368
   Wang W, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P363, DOI 10.1145/2971648.2971670
   Wang YX, 2017, IEEE T MOBILE COMPUT, V16, P581, DOI 10.1109/TMC.2016.2557792
   Zhang DQ, 2017, COMPUTER, V50, P48, DOI 10.1109/MC.2017.7
   Zhao MM, 2018, PROC CVPR IEEE, P7356, DOI 10.1109/CVPR.2018.00768
   Zhao MM, 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '18), P267, DOI 10.1145/3230543.3230579
   Zhu Y., 2017, ARXIV
NR 36
TC 6
Z9 6
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34665
EP 34683
DI 10.1007/s11042-020-08998-0
EA MAY 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000554789500003
DA 2024-07-18
ER

PT J
AU Mandikhanlou, K
   Ebrahimnezhad, H
AF Mandikhanlou, Khadijeh
   Ebrahimnezhad, Hossein
TI Multimodal 3D American sign language recognition for static alphabet and
   numbers using hand joints and shape coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand gesture recognition; Hand joints; Leap motion controller; 3D
   American sign language; Random decision Forest; Contour segment code;
   Shape contour; Hand direction
ID GESTURE RECOGNITION; LEAP MOTION; SEGMENTATION; HISTOGRAM; SYSTEM; POSE
AB American sign language recognition is still a research focus in computer vision community. Recently, most researches mainly extract low-level features for hand gesture recognition. These approaches perform poorly on recognizing gestures posed like a fist. In this paper, we propose a novel multimodal framework for sign language recognition system which exploits the Leap Motion Controller (LMC) and a webcam. We compute two sets of features. The first set is the angles at hand joints acquired by the LMC sensor. When, hand poses like a fist, the positions of the thumb joints captured by the LMC are not very precise. So, we should incorporate the second set of features extracted from the hand shape contour provided by a webcam. In this paper, we introduce a new mid-level feature, called Contour Segment Code (CSC), to represent hand shape contour. The proposed shape representation, first, extracts meaningful landmarks from the hand shape contour. CSC then encodes different segments of the hand contour into a code based on the shape landmarks. The extracted landmarks precisely determine the hand direction. The proposed method is tested by creating a very challenging dataset composed of 64,000 samples. Our experiments study the performance of the LMC and characteristics of CSC in different scenarios. The experimental results demonstrate the privileged performance of the proposed method against the systems which use depth images.
C1 [Mandikhanlou, Khadijeh; Ebrahimnezhad, Hossein] Sahand Univ Technol, Dept Elect Engn, Comp Vis Res Lab, Tabriz, Iran.
C3 Sahand University of Technology
RP Ebrahimnezhad, H (corresponding author), Sahand Univ Technol, Dept Elect Engn, Comp Vis Res Lab, Tabriz, Iran.
EM kh_mandikhanlou@sut.ac.ir; ebrahimnezhad@sut.ac.ir
RI ebrahimnezhad, hossein/ABC-3865-2021; Ebrahimnezhad,
   Hossein/ACP-2704-2022
OI ebrahimnezhad, hossein/0000-0003-4071-2750; 
CR Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545
   Amit Yali, 1994, Randomized Inquiries About Shape: Application to Handwritten Digit Recognition
   [Anonymous], EUR C COMP VIS
   Avola D, 2019, IEEE T MULTIMEDIA, V21, P234, DOI 10.1109/TMM.2018.2856094
   BEHERA S, 2018, ANAL 3D SIGNATURES R, P1, DOI DOI 10.1145/3265997.3265999
   Behera SK, 2018, EXPERT SYST APPL, V100, P106, DOI 10.1016/j.eswa.2018.01.042
   Bendib MM, 2015, PATTERN ANAL APPL, V18, P829, DOI 10.1007/s10044-014-0373-y
   Bernardos AM, 2016, J AMB INTEL HUM COMP, V7, P357, DOI 10.1007/s12652-016-0363-6
   Breiman L., 2017, Classification and Regression Trees, DOI [10.1201/9781315139470-8, DOI 10.1201/9781315139470-8, DOI 10.1201/9781315139470]
   Cao JT, 2016, MULTIMED TOOLS APPL, V75, P11909, DOI 10.1007/s11042-015-2628-z
   Chen MX, 2018, INTEL SERV ROBOT, V11, P269, DOI 10.1007/s11370-018-0251-3
   Chuang Yue-long, 2013, Journal of Zhejiang University. Engineering Science, V47, P1531, DOI 10.3785/j.issn.1008-973X.2013.09.003
   Criminisi A, 2013, DECISION FORESTCOM
   Cui J, 2018, COMPUT GRAPH-UK, V74, P1, DOI 10.1016/j.cag.2018.04.004
   Dardas NH, 2011, IEEE T INSTRUM MEAS, V60, P3592, DOI 10.1109/TIM.2011.2161140
   Feng B, 2017, IEEE T HUM-MACH SYST, V47, P511, DOI 10.1109/THMS.2016.2616278
   Hisham B., 2017, J. Comput. Sci, V13, P337, DOI DOI 10.3844/JCSSP.2017.337.354
   Hu K, 2013, P IEEE INT C COMP VI
   Huang D-Y, 2009, 2009 5 INT C INT INF
   Ibrahim M, 2017, ACM SIGIR FORUM
   Just A, 2006, 7 INT C AUT FAC GEST
   Kausar N, 2016, PATTERN ANAL APPL, V19, P221, DOI 10.1007/s10044-015-0448-4
   Kim M, 2016, MULTIMED TOOLS APPL, V75, P16529, DOI 10.1007/s11042-016-3355-9
   Kirac F, 2014, PATTERN RECOGN LETT, V50, P91, DOI 10.1016/j.patrec.2013.09.003
   Kumar P, 2018, PATTERN RECOGN LETT, V103, P1, DOI 10.1016/j.patrec.2017.12.014
   Kumar P, 2018, INFORM SCIENCES, V428, P30, DOI 10.1016/j.ins.2017.10.046
   Kumar P, 2017, MULTIMED TOOLS APPL, V76, P16491, DOI 10.1007/s11042-016-3923-z
   Kumar P, 2017, IEEE SENS J, V17, P1293, DOI 10.1109/JSEN.2016.2643165
   Li NJ, 2016, PATTERN ANAL APPL, V19, P267, DOI 10.1007/s10044-015-0463-5
   Liao GN, 2015, PHYSIOL REP, V3, DOI 10.14814/phy2.12541
   Marin G, 2016, MULTIMED TOOLS APPL, V75, P14991, DOI 10.1007/s11042-015-2451-6
   Nai WZ, 2017, PATTERN RECOGN, V65, P1, DOI 10.1016/j.patcog.2016.11.022
   Pedersoli F, 2014, VISUAL COMPUT, V30, P1107, DOI 10.1007/s00371-014-0921-x
   Priyal SP, 2013, PATTERN RECOGN, V46, P2202, DOI 10.1016/j.patcog.2013.01.033
   Pugeault N, 2011, IEEE INT C COMP VIS
   Rastgoo R, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20110809
   Ren YY, 2018, IEEE T CIRC SYST VID, V28, P364, DOI 10.1109/TCSVT.2016.2608837
   Ristin-Kaufmann M, 2015, THESIS
   Rivera-Acosta M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102176
   SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760
   Togootogtokh E, 2018, MULTIMED TOOLS APPL, V77, P9233, DOI 10.1007/s11042-017-4784-9
   Triesch J, 2002, IMAGE VISION COMPUT, V20, P937, DOI 10.1016/S0262-8856(02)00100-2
   Wang C, 2015, IEEE T MULTIMEDIA, V17, P29, DOI 10.1109/TMM.2014.2374357
   Zeng W, 2018, MULTIMED TOOLS APPL, V77, P28185, DOI 10.1007/s11042-018-5998-1
   Zhang CY, 2015, COMPUT VIS IMAGE UND, V139, P29, DOI 10.1016/j.cviu.2015.05.010
   Zhang Han-ling, 2013, Journal of Hunan University (Natural Science), V40, P87
   Zhou YM, 2016, PATTERN RECOGN, V49, P102, DOI 10.1016/j.patcog.2015.07.014
NR 47
TC 12
Z9 12
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22235
EP 22259
DI 10.1007/s11042-020-08982-8
EA MAY 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000534196400001
DA 2024-07-18
ER

PT J
AU Shukla, AK
   Pandey, RK
   Yadav, S
AF Shukla, Anil K.
   Pandey, Rajesh K.
   Yadav, Swati
TI Adaptive fractional masks and super resolution based approach for image
   enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Projection on convex set (POCS); Speeded up robust
   feature (SURF); Fractional calculus
ID HISTOGRAM EQUALIZATION; SUPERRESOLUTION; INTERPOLATION; EQUATIONS
AB This paper presents an image enhancement technique based on super-resolution approach. The method uses fractional filters and reconstructs the output image by projection on convex sets (POCS) method. First, we generate a reference frame by using low-resolution frames and enhanced it by an adaptive fractional mask. Then the speed-up robust feature (SURF) is used to find the matching between low-resolution frames and the reference frame. Finally, the residuals between matching are reduced by the POCS reconstruction approach. To recover the high-frequency components, we have used a fractional integral mask in the POCS reconstruction process. We have compared the experimental results with some other existing methods from literature. Simulation results show that the proposed approach is efficient and returns a good quality image.
C1 [Shukla, Anil K.; Pandey, Rajesh K.; Yadav, Swati] Indian Inst Technol BHU, Dept Math Sci, Varanasi 221005, Uttar Pradesh, India.
   [Pandey, Rajesh K.] Indian Inst Technol BHU, Ctr Adv Biomat & Tissue Engn, Varanasi 221005, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi); Indian Institute of
   Technology System (IIT System); Indian Institute of Technology BHU
   Varanasi (IIT BHU Varanasi)
RP Pandey, RK (corresponding author), Indian Inst Technol BHU, Dept Math Sci, Varanasi 221005, Uttar Pradesh, India.; Pandey, RK (corresponding author), Indian Inst Technol BHU, Ctr Adv Biomat & Tissue Engn, Varanasi 221005, Uttar Pradesh, India.
EM anil1shukla2@gmail.com; rkpandey.mat@iitbhu.ac.in
RI SHUKLA, ANIL KUMAR/AAQ-7621-2021; Yadav, Swati/ABB-4656-2021; Yadav,
   Swati/KBB-9636-2024
OI Yadav, Swati/0000-0002-5074-1259; Pandey, Rajesh K/0000-0002-5198-4340
CR Abu Arqub O, 2019, CHAOS SOLITON FRACT, V126, P394, DOI 10.1016/j.chaos.2019.07.023
   Abu Arqub O, 2019, CHAOS SOLITON FRACT, V125, P163, DOI 10.1016/j.chaos.2019.05.025
   Abu Arqub O, 2018, CHAOS SOLITON FRACT, V117, P161, DOI 10.1016/j.chaos.2018.10.013
   Abu Arqub O, 2018, CHAOS SOLITON FRACT, V117, P117, DOI 10.1016/j.chaos.2018.10.007
   Acton ST, 1998, J MATH IMAGING VIS, V8, P239, DOI 10.1023/A:1008222617999
   Agrawal OP, 2010, COMPUT MATH APPL, V59, P1852, DOI 10.1016/j.camwa.2009.08.029
   Anbarjafari G, 2010, ETRI J, V32, P390, DOI 10.4218/etrij.10.0109.0303
   [Anonymous], 2013, Int. J. Adv. Res. Comput. Commun. Eng
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Celik T, 2014, IEEE T IMAGE PROCESS, V23, P5298, DOI 10.1109/TIP.2014.2364537
   CHO DH, 2014, EUR C COMP VIS, P184
   Elad M, 2001, IEEE T IMAGE PROCESS, V10, P1187, DOI 10.1109/83.935034
   Fan C, 2006, ISDA 2006: SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, P333
   Farsiu S, 2004, INT J IMAG SYST TECH, V14, P47, DOI 10.1002/ima.20007
   Geng LL, 2018, IEEE-CAA J AUTOMATIC, V5, P555, DOI 10.1109/JAS.2017.7510412
   González ER, 2002, ORG DIVERS EVOL, V2
   Greenberg S, 2002, REAL-TIME IMAGING, V8, P227, DOI 10.1006/rtim.2001.0283
   Hao NB, 2016, IEEE-CAA J AUTOMATIC, V3, P213, DOI 10.1109/JAS.2016.7451109
   Hauser H, 2007, IEEE-RAS INT C HUMAN, P73, DOI 10.1109/ICHR.2007.4813851
   Hwang JW, 2004, IEEE SIGNAL PROC LET, V11, P359, DOI 10.1109/LSP.2003.821718
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Lei JF, 2018, GEO-SPAT INF SCI, V21, P56, DOI 10.1080/10095020.2018.1424409
   Li B, 2016, NEUROCOMPUTING, V175, P704, DOI 10.1016/j.neucom.2015.10.115
   Li B, 2015, COMPUT ELECTR ENG, V45, P324, DOI 10.1016/j.compeleceng.2015.02.013
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Mistry D., 2017, GRD JOURNALSGLOBAL R, V2, P7
   MITRA SK, 1991, INT CONF ACOUST SPEE, P2525, DOI 10.1109/ICASSP.1991.150915
   Ng MK, 2005, J MATH IMAGING VIS, V23, P367, DOI 10.1007/s10851-005-2028-5
   Panda SS, 2011, ARXIV11121484
   Pandey RK, 2015, J COMPUT NONLIN DYN, V10, DOI 10.1115/1.4028630
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Pu YF, 2010, IEEE T IMAGE PROCESS, V19, P491, DOI 10.1109/TIP.2009.2035980
   Rajan D, 2002, J MATH IMAGING VIS, V16, P5, DOI 10.1023/A:1013961817285
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Shih F., 2010, Image Processing and Pattern Recognition: Fundamentals and Techniques
   Shukla AK, 2018, INT J PURE APPL MATH, V119, P5147
   Shukla A, 2019, NETAI'19: PROCEEDINGS OF THE 2019 ACM SIGCOMM WORKSHOP ON NETWORK MEETS AI & ML, P1, DOI 10.1145/3341216.3342206
   Singh KK, 2018, IEEE-CAA J AUTOMATIC, V5, P628, DOI 10.1109/JAS.2017.7510670
   Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659
   Tanveer M, 2019, APPL SOFT COMPUT, V78, P164, DOI 10.1016/j.asoc.2019.02.022
   Tanveer M, 2015, INT J MACH LEARN CYB, V6, P1029, DOI 10.1007/s13042-015-0414-x
   Tanveer M., 2019, ACM T MULTIMEDIA COM
   Wang WC, 2017, IEEE-CAA J AUTOMATIC, V4, P410, DOI 10.1109/JAS.2017.7510532
   Wang XW, 2017, SIGNAL PROCESS-IMAGE, V58, P187, DOI 10.1016/j.image.2017.07.009
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao B, 2018, NEUROCOMPUTING, V275, P2798, DOI 10.1016/j.neucom.2017.11.057
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
NR 50
TC 8
Z9 8
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30213
EP 30236
DI 10.1007/s11042-020-08968-6
EA MAY 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000530202200001
DA 2024-07-18
ER

PT J
AU Guo, YY
   Ji, JS
   Shi, D
   Ye, QK
   Xie, H
AF Guo, Yiyou
   Ji, Jinsheng
   Shi, Dan
   Ye, Qiankun
   Xie, Huan
TI Multi-view feature learning for VHR remote sensing image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote sensing; Image classification; Multi-view feature learning;
   Visual attention
ID SCENE CLASSIFICATION; OBJECT DETECTION; NETWORKS
AB Learning high-level semantic information is important for the task of remote sensing(RS) image scene classification. Due to the great intraclass diversities and the interclass similarities, many researchers have explored the convolutional neural network(CNN) to handle this task recently. However, RS images usually have confusing backgrounds, such as the relevant objects, and features only derived from the whole RS images can not achieve satisfying results. Additionally, the great intraclass diversities also increase the difficulty of recognizing the RS images correctly. To solve the problem, the multi-view feature learning network(MVFLN) is proposed to obtain three domain-specific features for the scene categorization task. FC layers in the VGGNet are replaced by the channel-spatial branch and the other multiple metric branchs. The channel-spatial branch is utilized to localize and learn discriminative regions while the triplet metric branch and the center metric branch are used to enlarge the distance between different classes and reduce the distance of samples belonging to the same class, respectively. In this situation, the proposed MVFLN conducts in a concise way without extra SVM classifiers, achieving better performance. Experiments conducted on the AID, NWPU-RESISC45 and UC Merced datasets evaluate its effectiveness.
C1 [Guo, Yiyou; Xie, Huan] Tongji Univ, Coll Surveying & Geoinformat, Shanghai 200092, Peoples R China.
   [Ji, Jinsheng; Ye, Qiankun] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Dept Automat, Shanghai 200240, Peoples R China.
   [Shi, Dan] Workstn Command Automat 92608 PLA Troops, Shanghai 200083, Peoples R China.
C3 Tongji University; Shanghai Jiao Tong University
RP Xie, H (corresponding author), Tongji Univ, Coll Surveying & Geoinformat, Shanghai 200092, Peoples R China.
EM yiyouguo526@gmail.com; jinshengji@sjtu.edu.cn; 05shidan@163.com;
   yeqiankunyqk@qq.com; huanxie@tongji.edu.cn
RI JI, JINSHENG/KHW-3948-2024; xie, huan/GQQ-4398-2022
OI JI, JINSHENG/0000-0002-5360-919X; Guo, Yiyou/0000-0002-3497-6939
FU National Key Research and Development Program of China [2018YFB0505400];
   National Natural Science Foundation of China [41822106]; Dawn Scholar of
   Shanghai Program [18SG22]; State Key Laboratory of Disaster Reduction in
   Civil Engineering [SLDRCE19-B-35]; Fundamental Research Funds for the
   Central Universities of China
FX This paper was supported by the National Key Research and Development
   Program of China under grant 2018YFB0505400, the National Natural
   Science Foundation of China under grants 41822106, the Dawn Scholar of
   Shanghai Program under grant 18SG22, the State Key Laboratory of
   Disaster Reduction in Civil Engineering under grant SLDRCE19-B-35, and
   the Fundamental Research Funds for the Central Universities of China.
CR Chaib S, 2017, IEEE T GEOSCI REMOTE, V55, P4775, DOI 10.1109/TGRS.2017.2700322
   Chen C, 2016, SIGNAL IMAGE VIDEO P, V10, P745, DOI 10.1007/s11760-015-0804-2
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2017, IEEE GEOSCI REMOTE S, V14, P1735, DOI 10.1109/LGRS.2017.2731997
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cheng G, 2015, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2015.7298721
   Cheng G, 2015, IET COMPUT VIS, V9, P639, DOI 10.1049/iet-cvi.2014.0270
   Cheng G, 2015, IEEE T GEOSCI REMOTE, V53, P4238, DOI 10.1109/TGRS.2015.2393857
   Cheng G, 2014, ISPRS J PHOTOGRAMM, V98, P119, DOI 10.1016/j.isprsjprs.2014.10.002
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Guo YY, 2019, IEEE ACCESS, V7, P67200, DOI 10.1109/ACCESS.2019.2918732
   He NJ, 2018, IEEE T GEOSCI REMOTE, V56, P6899, DOI 10.1109/TGRS.2018.2845668
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Huang LH, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060483
   Ji JS, 2018, INT CONF SIGN PROCES, P544, DOI 10.1109/ICSP.2018.8652320
   Jia YQ, 2012, PROC CVPR IEEE, P3370, DOI 10.1109/CVPR.2012.6248076
   Li EZ, 2017, IEEE T GEOSCI REMOTE, V55, P5653, DOI 10.1109/TGRS.2017.2711275
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Liu YS, 2018, IEEE GEOSCI REMOTE S, V15, P183, DOI 10.1109/LGRS.2017.2779469
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Lu XK, 2019, NEUROCOMPUTING, V349, P133, DOI 10.1016/j.neucom.2019.02.021
   Lu XK, 2018, MULTIMED TOOLS APPL, V77, P15521, DOI 10.1007/s11042-017-5131-x
   Lu XQ, 2015, IEEE T CYBERNETICS, V45, P1967, DOI 10.1109/TCYB.2014.2362959
   Luus FPS, 2015, IEEE GEOSCI REMOTE S, V12, P2448, DOI 10.1109/LGRS.2015.2483680
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Othman E, 2017, IEEE T GEOSCI REMOTE, V55, P4441, DOI 10.1109/TGRS.2017.2692281
   Penatti Otavio A. B., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P44, DOI 10.1109/CVPRW.2015.7301382
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang GL, 2017, IEEE J-STARS, V10, P4104, DOI 10.1109/JSTARS.2017.2705419
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P1155, DOI 10.1109/TGRS.2018.2864987
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI [10.1145/1869790.1869829, DOI 10.1145/1869790.1869829]
   Yao XW, 2016, IEEE T GEOSCI REMOTE, V54, P3660, DOI 10.1109/TGRS.2016.2523563
   Zhang F, 2015, IEEE T GEOSCI REMOTE, V53, P2175, DOI 10.1109/TGRS.2014.2357078
   Zhao B, 2016, IEEE T GEOSCI REMOTE, V54, P2108, DOI 10.1109/TGRS.2015.2496185
   Zhao B, 2017, IEEE T MULTIMEDIA, V19, P1245, DOI 10.1109/TMM.2017.2648498
   Zhao WZ, 2016, INT J REMOTE SENS, V37, P4119, DOI 10.1080/01431161.2016.1207266
   Zou JY, 2016, INFORM SCIENCES, V348, P209, DOI 10.1016/j.ins.2016.02.021
NR 44
TC 8
Z9 8
U1 5
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23009
EP 23021
DI 10.1007/s11042-020-08713-z
EA APR 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000528521300001
DA 2024-07-18
ER

PT J
AU Zhang, L
   Zhang, XQ
AF Zhang, Lei
   Zhang, Xiaoqiang
TI Multiple-image encryption algorithm based on bit planes and chaos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple-image encryption (MIE); Bit plane; Chaotic system; Exclusive OR
   (XOR)
ID SCHEME; OPERATION; PERMUTATION; TRANSFORM; SECURE
AB In the era of big data, many fields produce massive images every day. To improve the security of image transmission, a multiple-image encryption algorithm based on bit planes and chaos is proposed. Firstly, k images are decomposed into 8k bit planes; secondly, the Chen chaotic system and two-dimensional Logistic map are used to scramble pixel positions of the 5th-8th bit planes of each image; thirdly, the scrambled bit planes and all the 1st-4th bit planes are randomly combined into k scrambled images; finally, to obtain k encrypted images, the exclusive OR operation is performed on the chaotic image and k scrambled images. Experimental results and algorithm analyses show that the proposed algorithm has the advantages of the excellent encryption effect, high encryption efficiency, large key space, key sensitivity, strong ability to resist the statistical attack, the brute-force attack, etc.
C1 [Zhang, Lei; Zhang, Xiaoqiang] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
   [Zhang, Lei; Zhang, Xiaoqiang] Xuzhou Key Lab Artificial Intelligence & Big Data, Xuzhou 221116, Jiangsu, Peoples R China.
C3 China University of Mining & Technology
RP Zhang, XQ (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.; Zhang, XQ (corresponding author), Xuzhou Key Lab Artificial Intelligence & Big Data, Xuzhou 221116, Jiangsu, Peoples R China.
EM grayqiang@163.com
OI Zhang, Xiaoqiang/0000-0002-7686-2841
FU National Natural Science Foundation of China [61501465]; Natural Science
   Foundation of Jiangsu Province [BK20190622]
FX The research work of this paper is partially supported by the National
   Natural Science Foundation of China (61501465) and the Natural Science
   Foundation of Jiangsu Province (BK20190622). Authors would like to
   express their sincerely thanks to the four anonymous reviewers and
   editors for their constructive comments and suggestions.
CR [Anonymous], 2018, RECENT ADV ELECT ELE
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen W, 2012, OPT COMMUN, V285, P225, DOI 10.1016/j.optcom.2011.09.045
   Enayatifar R, 2019, OPT LASER ENG, V115, P131, DOI 10.1016/j.optlaseng.2018.11.017
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Huo DM, 2019, PHYS LETT A, V383, P915, DOI 10.1016/j.physleta.2018.12.011
   Li SY, 2009, PHYS LETT A, V373, P4053, DOI 10.1016/j.physleta.2009.09.004
   Li XY, 2018, OPT LASER ENG, V102, P106, DOI 10.1016/j.optlaseng.2017.10.023
   Li YB, 2015, OPT LASER ENG, V72, P18, DOI 10.1016/j.optlaseng.2015.03.027
   Lin C, 2012, OPT COMMUN, V285, P1023, DOI 10.1016/j.optcom.2011.10.046
   Lin QH, 2008, IMAGE VISION COMPUT, V26, P788, DOI 10.1016/j.imavis.2007.08.017
   Liu JY, 2018, MULTIMED TOOLS APPL, V77, P10217, DOI 10.1007/s11042-017-5406-2
   Liu W, 2015, OPT COMMUN, V335, P205, DOI 10.1016/j.optcom.2014.09.046
   Liu XY, 2013, OPTIK, V124, P6590, DOI 10.1016/j.ijleo.2013.05.092
   Liu Y, 2018, EXPERT SYST APPL, V97, P95, DOI 10.1016/j.eswa.2017.12.003
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Poonam, 2018, Procedia Computer Science, V132, P1441, DOI 10.1016/j.procs.2018.05.076
   Qin Y, 2014, OPT COMMUN, V315, P220, DOI 10.1016/j.optcom.2013.11.018
   Ren HG, 2016, INT J SECUR APPL, V10, P241, DOI 10.14257/ijsia.2016.10.12.19
   Shao Z, 2019, SIGNAL PROCESS-IMAGE, V80, P1
   Tang ZJ, 2016, OPT LASER ENG, V80, P1, DOI 10.1016/j.optlaseng.2015.12.004
   Wan WB, 2020, MULTIMED TOOLS APPL, V79, P4907, DOI 10.1007/s11042-018-6860-1
   Wan YH, 2015, OPT COMMUN, V342, P95, DOI 10.1016/j.optcom.2014.12.044
   Wang J, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112868
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Weng DD, 2011, OPT COMMUN, V284, P2485, DOI 10.1016/j.optcom.2011.01.039
   Wu JH, 2018, SIGNAL PROCESS, V142, P292, DOI 10.1016/j.sigpro.2017.06.014
   Xiong Y, 2018, OPT LASER ENG, V101, P113, DOI 10.1016/j.optlaseng.2017.10.010
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Zhang XQ, 2019, MULTIMED TOOLS APPL, V78, P7841, DOI 10.1007/s11042-018-6496-1
   Zhang XQ, 2017, OPT LASER ENG, V92, P6, DOI 10.1016/j.optlaseng.2016.12.005
   Zhang XG, 2017, IET COMPUT VIS, V11, P1, DOI 10.1049/iet-cvi.2016.0022
NR 33
TC 56
Z9 56
U1 5
U2 92
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 20753
EP 20771
DI 10.1007/s11042-020-08835-4
EA APR 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000528521300002
DA 2024-07-18
ER

PT J
AU Wang, YP
   Zhang, JF
AF Wang, Yuping
   Zhang, Junfei
TI Reconstruction of compressively sampled light field by using tensor
   dictionaries
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Light field; Tensor; Dictionary learning; Compressive sensing
ID ALGORITHM
AB How to capture the high quality light field photography was one of important issue in computational photography. In fact, light field could be captured directly for all views or compressively reconstructed for each view just through one coded image. The latter kind of method was more feasible since only one exposure was needed for all views, among which dictionary-based light field reconstruction had been shown its effectiveness. In this paper, a more effective light field reconstruction method based on tensor dictionary was created. The proposed method is efficient because the trained tensor form dictionary can make better use of the rich structure of light field. Specifically, multiple small dictionaries were trained at the same time, and then were combined to a big dictionary using Kronecker product. Experimental results demonstrate the proposed method outperforms a state-of-the-art reconstruction method with the vector-form dictionary, in terms of higher reconstruction PSNR while reducing the scale of dictionary substantially.
C1 [Wang, Yuping] Capital Univ Econ & Business, Sch Stat, 121 Zhangjialukou, Beijing 100070, Peoples R China.
   [Zhang, Junfei] Cent Univ Finance & Econ, Sch Math & Stat, 39 South Coll Rd, Beijing 100081, Peoples R China.
C3 Capital University of Economics & Business; Central University of
   Finance & Economics
RP Zhang, JF (corresponding author), Cent Univ Finance & Econ, Sch Math & Stat, 39 South Coll Rd, Beijing 100081, Peoples R China.
EM zhangfei851115@163.com
FU Capital University of Economics and Business; Natural Science Foundation
   of China (NSFC) [11871488]; foundation "the Fundamental Research Funds
   for the Central Universities [QL18010]; School of Statistics and
   Mathematics of CUFE
FX We would like to thank the referees and editors for their helpful
   comments and suggestions. Yuping Wang would like thank to research fund
   support in 2019 from Capital University of Economics and Business.
   Jungfei Zhang would like thank to the support from Natural Science
   Foundation of China (NSFC NO. 11871488), the foundation "the Fundamental
   Research Funds for the Central Universities" (NO. QL18010) and School of
   Statistics and Mathematics of CUFE.
CR ADELSON EH, 1992, IEEE T PATTERN ANAL, V14, P99, DOI 10.1109/34.121783
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Amarlingam M, 2016, 2016 IEEE 3RD WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P289, DOI 10.1109/WF-IoT.2016.7845487
   [Anonymous], 2005, Comput. Sci. Tech. Rep.
   Ashok A, 2010, PROC SPIE, V7690, DOI 10.1117/12.852738
   Babacan SD, 2012, IEEE T IMAGE PROCESS, V21, P4746, DOI 10.1109/TIP.2012.2210237
   Buehler C, 2001, COMP GRAPH, P425, DOI 10.1145/383259.383309
   Caiafa CF, 2012, INT CONF ACOUST SPEE, P2709, DOI 10.1109/ICASSP.2012.6288476
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Cao X, 2014, OPT EXPRESS, V22, P24081, DOI 10.1364/OE.22.024081
   Chen Y, 2019, IEEE ACCESS, V7, P15623, DOI 10.1109/ACCESS.2019.2894694
   Davis A, 2012, COMPUT GRAPH FORUM, V31, P305, DOI 10.1111/j.1467-8659.2012.03009.x
   Fu Y, 2014, IEEE IJCNN, P2957, DOI 10.1109/IJCNN.2014.6889490
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Georgiev T. G., 2006, P 17 EUROGRAPHICS C, V2006
   Gortler S.J., 1996, ACM T GRAPH, V23, P43
   Kamal MH, 2012, INT CONF ACOUST SPEE, P5413, DOI 10.1109/ICASSP.2012.6289145
   Kauvar I, 2015, ACM T GRAPHIC, V34, DOI [10.1145/2682631, 10.1145/2816795.2818070]
   Kim C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461926
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Li ZC, 2017, IEEE INTERNET THINGS, V4, P505, DOI 10.1109/JIOT.2016.2583465
   Liang CK, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360654
   Marwah K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461914
   Memos VA, 2018, FUTURE GENER COMP SY, V83, P619, DOI 10.1016/j.future.2017.04.039
   Plageras AP, 2018, FUTURE GENER COMP SY, V82, P349, DOI 10.1016/j.future.2017.09.082
   Psannis KE, 2016, EURASIP J WIREL COMM, V2006, P24
   Qi N, 2018, IEEE T PATTERN ANAL, V40, P163, DOI 10.1109/TPAMI.2017.2663423
   Roemer Florian, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3963, DOI 10.1109/ICASSP.2014.6854345
   Shidanshidi H, 2015, IEEE T MULTIMEDIA, V17, P1677, DOI 10.1109/TMM.2015.2447274
   Stergiou C., 2018, Journal of Multimedia Information System, V5, P27
   Stergiou C, 2018, FUTURE GENER COMP SY, V78, P964, DOI 10.1016/j.future.2016.11.031
   Vagharshakyan S, 2018, IEEE T PATTERN ANAL, V40, P133, DOI 10.1109/TPAMI.2017.2653101
   Veeraraghavan A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239520
   Wang YP, 2015, IEEE T IMAGE PROCESS, V24, P5609, DOI 10.1109/TIP.2015.2468179
   Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259
   Williem, 2016, MULTIMED TOOLS APPL, V75, P16615, DOI 10.1007/s11042-016-3754-y
   Xu ZM, 2012, OPT EXPRESS, V20, P10971, DOI 10.1364/OE.20.010971
   Yang JC, 2002, REAL TIME DISTRIBUTE
   Zhang C, 2018, PATTERN RECOGN, V81, P176, DOI 10.1016/j.patcog.2018.03.020
   Zubair S., 2013, 2013 18th International Conference on Digital Signal Processing (DSP) IEEE, P1, DOI DOI 10.1109/ICDSP.2013.6622725
NR 41
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 20449
EP 20460
DI 10.1007/s11042-020-08903-9
EA APR 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000527911700004
DA 2024-07-18
ER

PT J
AU Liang, Q
   Xu, N
   Wang, WJ
   Long, XJ
AF Liang, Qi
   Xu, Ning
   Wang, Weijie
   Long, Xingjian
TI Multimodal information fusion based on LSTM for 3D model retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model retrieval; LSTM; Deep learning
ID CONVOLUTIONAL NEURAL-NETWORKS; OBJECT RETRIEVAL; SEARCH
AB With advances in low-cost 3D model capturing devices and virtual 3D model building software, the acquisition of 3D data has become increasingly easier. The subsequent 3D model retrieval skill has also become essential when we utilize 3D models. Although a large number of methods have been proposed to address this problem, most of them cannot fully utilize the information represented by 3D models. To solve this problem. We present a multimodal feature fusion method based on the LSTM network. First, we placed some cameras evenly around the 3D model at a fixed distance, which was aimed at the centroid of the 3D model to obtain a series of pictures. Second, the skeleton information is extracted from these rendered pictures. Finally, the rendered pictures, along with the skeleton information, were sequentially fed into the LSTM network to obtain the feature of the fusion information. The confusion matrix was completed to evaluate retrieval performance. In the experiment section, datasets named NTU and ModelNet40 were utilized to demonstrate the performance of the proposed method. Many experiments and corresponding experimental results also demonstrated the superiority of our approach.
C1 [Liang, Qi; Xu, Ning; Wang, Weijie; Long, Xingjian] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University
RP Xu, N; Wang, WJ (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM ningxu@tju.edu.cn; twowwj@163.com
RI Liang, Qi/ABF-4426-2021
FU National Natural Science Foundation of China [61472275, 61170239,
   61303208, 61502337]
FX This work was supported in part by the National Natural Science
   Foundation of China (61472275, 61170239, 61303208, 61502337).
CR Akgül CB, 2009, IEEE T PATTERN ANAL, V31, P1117, DOI 10.1109/TPAMI.2009.25
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   [Anonymous], 3D SHAPENETS DEEP RE
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Bai S, 2017, IEEE T MULTIMEDIA, V19, P1257, DOI 10.1109/TMM.2017.2652071
   Bu SH, 2014, IEEE T MULTIMEDIA, V16, P2154, DOI 10.1109/TMM.2014.2351788
   Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893
   Cao B, 2016, J INTELL FUZZY SYST, V31, P2637, DOI 10.3233/JIFS-169104
   Conrad M, 2014, EUR CONF POW ELECTR
   Feng YF, 2018, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2018.00035
   Furuya T., 2016, Deep aggregation of local 3D geometric features for 3D model retrieval, p121.1
   Gao Y, 2014, IEEE MULTIMEDIA, V21, P52, DOI 10.1109/MMUL.2014.20
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Irfanoglu MO, 2004, PROCEEDINGS OF THE IEEE 12TH SIGNAL PROCESSING AND COMMUNICATIONS APPLICATIONS CONFERENCE, P571, DOI 10.1109/SIU.2004.1338593
   Kanezaki A, 2018, PROC CVPR IEEE, P5010, DOI 10.1109/CVPR.2018.00526
   Kazhdan M., 2003, Symposium on Geometry Processing, P156
   Leng B, 2017, MULTIMEDIA SYST, V23, P19, DOI 10.1007/s00530-015-0454-9
   Liu AA, 2018, IEEE T CYBERNETICS, V48, P916, DOI 10.1109/TCYB.2017.2664503
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu A, 2015, INFORM SCIENCES, V320, P429, DOI 10.1016/j.ins.2015.04.042
   Liu Q, 2012, ARXIV12083670
   Ma C, 2019, IEEE T MULTIMEDIA, V21, P1169, DOI 10.1109/TMM.2018.2875512
   Nie LQ, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P695
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Nie W, 2019, CHARACTERISTIC VIEWS, P2389, DOI [10.1109/ICIP.2019.8803343, DOI 10.1109/ICIP.2019.8803343]
   Nie W, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194178
   Nie WZ, 2019, IEEE T CIRC SYST VID, V29, P1619, DOI 10.1109/TCSVT.2018.2852310
   Papoiu ADP, 2014, J NEUROPHYSIOL, V112, P1729, DOI 10.1152/jn.00827.2013
   Paquet E, 2000, SIGNAL PROCESS-IMAGE, V16, P103, DOI 10.1016/S0923-5965(00)00020-5
   Pickup D., 2015, P 8 EUR WORKSH 3D OB, P99
   Saupe D., 2001, Pattern Recognition. 23rd DAGM Symposium. Proceedings (Lecture Notes in Computer Science Vol.2191), P392
   Sfikas K., 2017, EXPLOITING PANORAMA, P1, DOI 10.2312/3dor.20171045
   Shen W, 2017, IEEE T IMAGE PROCESS, V26, P5298, DOI 10.1109/TIP.2017.2735182
   Shen WQ, 2016, IEEE WCNC
   Shi BG, 2015, IEEE SIGNAL PROC LET, V22, P2339, DOI 10.1109/LSP.2015.2480802
   SHINAGAWA Y, 1991, IEEE COMPUT GRAPH, V11, P44, DOI 10.1109/38.103393
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609
   Tangelder JWH, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P119
   Wang D, 2017, NEUROCOMPUTING, V252, P58, DOI 10.1016/j.neucom.2016.06.095
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xie J, 2015, PROC CVPR IEEE, P1275, DOI 10.1109/CVPR.2015.7298732
   Xu K, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980224
   Yang SF, 2015, IEEE I CONF COMP VIS, P1215, DOI 10.1109/ICCV.2015.144
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zhao XB, 2015, COMMUN STAT-THEOR M, V44, P5240, DOI 10.1080/03610926.2013.815207
   Zhao XB, 2013, J SYST ENG ELECTRON, V24, P1029, DOI 10.1109/JSEE.2013.00120
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
   Zhu L, 2015, IEEE T CYBERNETICS, V45, P2756, DOI 10.1109/TCYB.2014.2383389
NR 53
TC 3
Z9 3
U1 2
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33943
EP 33956
DI 10.1007/s11042-020-08817-6
EA APR 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000525159700001
DA 2024-07-18
ER

PT J
AU Bakiya, A
   Kamalanand, K
   Rajinikanth, V
   Nayak, RS
   Kadry, S
AF Bakiya, A.
   Kamalanand, K.
   Rajinikanth, V.
   Nayak, Ramesh Sunder
   Kadry, Seifedine
TI Deep neural network assisted diagnosis of time-frequency transformed
   electromyograms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electromyograms; Transformation techniques; Time-frequency features;
   Feature selection; Deep neural networks; Shallow neural networks
ID SEGMENTATION; TUMOR; ENTROPY; CLASSIFICATION; IMAGES
AB Electromyograms (EMG) are recorded electrical signals generated from the muscles and these signals are closely interrelated with the muscle activity and hence are useful for the investigation of neuro-muscular disorders. The feature mining, feature collection and development of classification systems are greatly significant steps in the differentiation of normal and abnormal EMG signals to evaluate the abnormality. In this work, time-frequency domain based features of regular, myopathy and Amyotrophic Lateral Sclerosis (ALS) EMG signals were extracted from four different techniques namely Stockwell-Transform (ST), Wigner-Ville Transform (WVT), Synchro-Extracting Transform (SET) and Short-Time Fourier Transform (STFT). The Particle Swarm Optimization (PSO) with fractional velocity update technique was implemented for feature reduction. Further, the classifier based on the Deep Neural Networks (DNN) was developed by employing the features selected using fractional PSO. Finally, the performance of the DNN was compared with that of the Shallow Neural Network (SNN) classifier. Results of this work demonstrate that, the performance measure of the DNN classifiers is higher than that of the SNN classifier. This work appears to be of good clinical significance since efficient classification techniques are required for the development of robust neuro-muscular diagnosis systems.
C1 [Bakiya, A.; Kamalanand, K.] Anna Univ, Dept Instrumentat Engn, MIT Campus, Chennai, Tamil Nadu, India.
   [Rajinikanth, V.] St Josephs Coll Engn, Dept Elect & Instrumentat Engn, Chennai, Tamil Nadu, India.
   [Nayak, Ramesh Sunder] Canara Engn Coll, Dept Informat Sci, Mangaluru, Karnataka, India.
   [Nayak, Ramesh Sunder] Canara Engn Coll, Engn Dept, Mangaluru, Karnataka, India.
   [Kadry, Seifedine] Beirut Arab Univ, Dept Math & Comp Sci, Beirut, Lebanon.
C3 Anna University; Anna University Chennai; St. Joseph's College of
   Engineering, Chennai; Beirut Arab University
RP Rajinikanth, V (corresponding author), St Josephs Coll Engn, Dept Elect & Instrumentat Engn, Chennai, Tamil Nadu, India.
EM v.rajinikanth@ieee.org
RI Ambikapathy, Bakiya/HKO-4822-2023; VENKATESAN, RAJINIKANTH/F-6734-2011;
   k, k/KFC-0221-2024; K, KAMALANAND/I-5050-2014; su, haobo/JPK-2362-2023;
   Kadry, Seifedine/C-7437-2011; Rajinikanth, V/X-9395-2018; k,
   k/KFT-2541-2024; k, k/HZK-4476-2023; Ambikapathy, Bakiya/AAQ-3062-2020
OI Ambikapathy, Bakiya/0000-0002-2416-0557; VENKATESAN,
   RAJINIKANTH/0000-0003-3897-4460; K, KAMALANAND/0000-0002-4381-7630;
   Kadry, Seifedine/0000-0002-1939-4842; Rajinikanth,
   V/0000-0003-3897-4460; Ambikapathy, Bakiya/0000-0002-2416-0557; Nayak,
   Ramesh/0000-0003-4403-4299
CR Al-Barazanchi KK, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON ADVANCES IN BIOMEDICAL ENGINEERING (ICABME), P81
   Alagumariappan Paramasivam, 2018, Proceedings of the International Conference on Computing and Communication Systems. I3CS 2016. Lecture Notes in Networks and Systems (LNNS 24), P463, DOI 10.1007/978-981-10-6890-4_45
   Alagumariappan P, 2017, POL J MED PHYS ENG, V23, P37, DOI 10.1515/pjmpe-2017-0007
   Ambikapathy B, 2018, J AMBIENT INTELL HUM, P1
   Amin J, 2018, FUTURE GENER COMP SY, V87, P290, DOI 10.1016/j.future.2018.04.065
   [Anonymous], IEEE T IND ELECT
   [Anonymous], 2018, PATTERN RECOGN LETT
   [Anonymous], 2012, BMC INFECT DIS, DOI DOI 10.1186/1471-2334-12-S1-P82
   [Anonymous], FEATURE EXTRACTION C
   [Anonymous], FUTURE GEN COMPUT SY
   [Anonymous], 2014, J ADV MICROSC RES, DOI DOI 10.1166/JAMR.2014.1194
   [Anonymous], METHODS APPL TIME FR
   [Anonymous], 3 INT EL FLIPP C ENT
   Arunkumar N, 2017, PATTERN RECOGN LETT, V94, P112, DOI 10.1016/j.patrec.2017.05.007
   Belkhou A., 2017, INT C EL INF TECHN, P1, DOI DOI 10.1109/EITECH.2017.8255232
   Boashash B., 1991, TIME FREQUENCY SIGNA
   Chandra B, 2016, NEUROCOMPUTING, V171, P1205, DOI 10.1016/j.neucom.2015.07.093
   Christodoulou CI, 1999, IEEE T BIO-MED ENG, V46, P169, DOI 10.1109/10.740879
   Daud Wan Mohd Bukhari Wan, 2013, International Journal of Modeling and Optimization, V3, P515, DOI 10.7763/IJMO.2013.V3.332
   Davies M. R., 1994, Proceedings of the 1994 20th Annual Northeast Bioengineering Conference (Cat. No.94CH3439-7), P93, DOI 10.1109/NEBC.1994.305165
   Fernandes SL, 2017, J MED IMAG HEALTH IN, V7, P1841, DOI 10.1166/jmihi.2017.2280
   Fernandes SL, 2016, J INTEGR DES PROCESS, V20, P33, DOI 10.3233/jid-2016-0002
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   JANG GC, 1994, PROCEEDINGS OF THE 16TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY - ENGINEERING ADVANCES: NEW OPPORTUNITIES FOR BIOMEDICAL ENGINEERS, PTS 1&2, P1242, DOI 10.1109/IEMBS.1994.415413
   Kamalanand K, 2016, INT J BIOMATH, V9, DOI 10.1142/S1793524516500248
   Kamalanand K., 2013, African Journal of Microbiology Research, V7, P2297
   Kamalanand K, 2014, BMC INFECT DIS, V14, pE14, DOI [10.1186/1471-2334-14-S3-E14, DOI 10.1186/1471-2334-14-S3-E14]
   Kamalanand K, 2015, IETE TECH REV, V32, P188, DOI 10.1080/02564602.2014.1000981
   Karthick PA, 2018, COMPUT METH PROG BIO, V154, P45, DOI 10.1016/j.cmpb.2017.10.024
   Kuniszyk-Jozkowiak Wieslawa, 2012, Annales UMCS, Informatica, V12, P19, DOI 10.2478/v10065-012-0001-7
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Monteiro HLM, 2014, INT C HARMON QUAL PO, P1, DOI 10.1109/ICHQP.2014.6842892
   Nikolic M., 2001, Detailed analysis of clinical electromyography signals EMG decomposition, findings and firing pattern analysis in controls and patients with myopathy and amytrophic lateral sclerosis
   Nuwer MR, 1999, EEG CL N SU, V50, P150
   Phinyomark A, 2012, EXPERT SYST APPL, V39, P7420, DOI 10.1016/j.eswa.2012.01.102
   Pires EJS, 2010, NONLINEAR DYNAM, V61, P295, DOI 10.1007/s11071-009-9649-y
   Ly QT, 2017, IEEE ENG MED BIO, P3044, DOI 10.1109/EMBC.2017.8037499
   Raja N. Sri Madhava, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P961, DOI 10.1007/s12652-018-0854-8
   Raja NSM, 2017, J MED IMAG HEALTH IN, V7, P1825, DOI 10.1166/jmihi.2017.2267
   Rajagopal A, 2018, ADV BIOINFORM BIOMED, P97, DOI 10.4018/978-1-5225-5149-2.ch005
   Rajinikanth V, 2018, FUTURE GENER COMP SY, V85, P160, DOI 10.1016/j.future.2018.03.025
   Rajinikanth V, 2017, J MED IMAG HEALTH IN, V7, P1837, DOI 10.1166/jmihi.2017.2265
   Rajinikanth V, 2017, CONTROL ENG APPL INF, V19, P97
   Rajinikanth V, 2017, PATTERN RECOGN LETT, V94, P87, DOI 10.1016/j.patrec.2017.05.028
   Ricamato A. L., 1992, Proceedings. Fifth Annual IEEE Symposium on Computer-Based Medical Systems (Cat. No.92CH3117-9), P520, DOI 10.1109/CBMS.1992.245010
   Stockwell RG, 1996, IEEE T SIGNAL PROCES, V44, P998, DOI 10.1109/78.492555
   Subasi A, 2012, APPL SOFT COMPUT, V12, P2188, DOI 10.1016/j.asoc.2012.03.035
   Wang G, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/284308
   Yousefi J, 2014, COMPUT BIOL MED, V51, P1, DOI 10.1016/j.compbiomed.2014.04.018
NR 50
TC 25
Z9 25
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 11051
EP 11067
DI 10.1007/s11042-018-6561-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600071
DA 2024-07-18
ER

PT J
AU Dharmalingham, V
   Kumar, D
AF Dharmalingham, Vivekanandan
   Kumar, Dhananjay
TI A model based segmentation approach for lung segmentation from chest
   computer tomography images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Segmentation; Sampling lines algorithm; Flood fill; Dice coefficient;
   Jaccard index
ID SHAPE
AB Segmentation of pathological lung regions from the body regions is the most challenging part in any Computer Aided Diagnosis (CAD) system due to the presence of Pathological Bearing Regions (PBR) which lies on the lung's periphery. Here, a unique pathological lung segmentation method called reference-model based segmentation that uses shape property of human lung is proposed. This method trounces the difficulties in segmentation from traditional approaches by examining the shape knowledge of lung. The proposed segmentation approach constructs a reference lung model from input slices using a novel Sampling Lines Algorithm (SLA) and extracts the shape features. The segmentation work is validated using dataset consisting of Digital Imaging and Communications in Medicines (DICOM) standard chest CT images of seven patients from cancer institute Chennai, nine patients from Gemini Scans, Chennai and fourteen patients from Lung Image Data-base Consortium image collection (LIDC-IDRI). The segmentation method's performance is analyzed against widely used segmentation methods namely Graph Cuts (GC), Region Growing (RG), Active Contour and Flood Fill in terms of accuracy, specificity, sensitivity, overlap score, Jaccard index, and also Dices similarity coefficients (DSC). The numerical outcomes specify that the proposed work attains an improved result against widely used segmentation techniques.
C1 [Dharmalingham, Vivekanandan; Kumar, Dhananjay] Anna Univ, Madras Inst Technol Campus, Dept Informat Technol, Chennai 600044, Tamil Nadu, India.
C3 Anna University; Anna University Chennai; Madras Institute of Technology
RP Dharmalingham, V (corresponding author), Anna Univ, Madras Inst Technol Campus, Dept Informat Technol, Chennai 600044, Tamil Nadu, India.
EM Vivek.Thanigai@gmail.com; dhananjay@annauniv.edu
RI Dharmalingam, Dr. Vivekanandan/CAG-9334-2022; Kumar,
   Dhananjay/H-9853-2012
OI Kumar, Dhananjay/0000-0003-3758-1841; Dharmalingam,
   Vivekanandan/0000-0002-1438-4063
CR An H, 2018, CAAI T INTELL TECHNO, V3, P28, DOI 10.1049/trit.2018.0005
   [Anonymous], COMPUT MED IMAGING G
   [Anonymous], INT J PURE APPL MATH
   [Anonymous], WORLD C MED PHYS BIO
   [Anonymous], AUTOMATIC CT IMAGE S
   [Anonymous], SEGMENTATION LUNGS C
   [Anonymous], P 2015 CHIN INT SYST
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], INT J ADV RES COMPUT
   [Anonymous], MED IMAGING TELEMEDI
   BalaAnand M, 2020, INT J PARALLEL PROG, V48, P329, DOI 10.1007/s10766-018-0598-2
   Dai SF, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P241, DOI 10.1109/ACPR.2015.7486502
   Dawoud A, 2011, IET COMPUT VIS, V5, P185, DOI 10.1049/iet-cvi.2009.0141
   Deng QL, 2018, CAAI T INTELL TECHNO, V3, P33, DOI 10.1049/trit.2018.0003
   Dhara AK, 2016, J DIGIT IMAGING, V29, P466, DOI 10.1007/s10278-015-9857-6
   Dong SH, 2020, NEURAL COMPUT APPL, V32, P735, DOI 10.1007/s00521-018-03971-3
   Gaidel A, 2017, PROCEDIA ENGINEER, V201, P258, DOI 10.1016/j.proeng.2017.09.612
   Hu SY, 2001, IEEE T MED IMAGING, V20, P490, DOI 10.1109/42.929615
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Ju W, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2488902
   Li Zheng, 2018, MATEC Web of Conferences, V232, DOI 10.1051/matecconf/201823202001
   Mansoor A, 2015, RADIOGRAPHICS, V35, P1056, DOI 10.1148/rg.2015140232
   Mansoor A, 2014, IEEE T MED IMAGING, V33, P2293, DOI 10.1109/TMI.2014.2337057
   Maram B, 2019, SERV ORIENTED COMPUT, V13, P3, DOI 10.1007/s11761-018-0249-x
   Mets OM, 2013, JACC-CARDIOVASC IMAG, V6, P899, DOI 10.1016/j.jcmg.2013.02.008
   Pirbhulal S, 2018, IEEE T BIO-MED ENG, V65, P2751, DOI 10.1109/TBME.2018.2815155
   Pu JT, 2012, MED PHYS, V39, P2603, DOI 10.1118/1.4703901
   Samuel RDJ, 2019, NEURAL COMPUT APPL, V31, P1533, DOI 10.1007/s00521-018-3564-4
   Shoaib M., 2013, European Journal of Scientific Research, V98, P45
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Sivaparthipan CB, 2018, MULTIMED TOOLS APPL
   Tan Z, 2018, CAAI T INTELL TECHNO, V3, P1, DOI 10.1049/trit.2018.0002
   Vuckovic V, 2019, J REAL-TIME IMAGE PR, V16, P2213, DOI 10.1007/s11554-017-0732-1
   Wang X, 2007, IEEE T PATTERN ANAL, V29, P886, DOI 10.1109/TPAMI.2007.1027
   Wei Y, 2013, J DIGIT IMAGING, V26, P483, DOI 10.1007/s10278-012-9528-9
   Wu WQ, 2018, FUTURE GENER COMP SY, V86, P515, DOI 10.1016/j.future.2018.04.024
   Yin J, 2018, ASIA COMMUN PHOTON
   Zhou SP, 2016, NEUROCOMPUTING, V186, P107, DOI 10.1016/j.neucom.2015.12.073
NR 38
TC 10
Z9 10
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10003
EP 10028
DI 10.1007/s11042-019-07854-0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600015
DA 2024-07-18
ER

PT J
AU Kumar, NS
   Mohanalin, J
   Mahil, J
AF Kumar, N. Satheesh
   Mohanalin, J.
   Mahil, J.
TI RETRACTED: Recognition of autism in children via electroencephalogram
   behaviour using particle swarm optimization based ANFIS classifier
   (Retracted article. See MAY, 2023)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Autism spectrum disorder; Electroencephalogram; Particle swarm
   optimization; Adaptive neuro-fuzzy inference system; SavitzkyGolay
   filter; Variational mode decomposition
ID SPECTRUM DISORDER
AB Autism spectrum disorders (ASD) are pervasive neuro developmental conditions portrayed by disabilities in social intercommunication, besides stereotyped conduct. Since Electroencephalogram (EEG) recording together with analysis stands one among the basic devices in diagnosing along with recognizing the issue in neurophysiology, utilized the signals of EEG aimed at diagnosing persons with ASD. These signals have heaps of data which mirror the conduct of brain functions which thusly catches the marker for autism, help to early analyze and speed the treatment. To beat such disadvantage, this given work proposes an Adaptive Neuro-Fuzzy Inference System classifier joined with Particle Swarm Optimization that is named as PSO-ANFIS for classifying the diagnosing signals of EEG. To start with, utilizing Savitzky Golay (S-G) filter pre-processed the input signal, after that by variational mode decomposition (VMD) disintegrated the signal. Presently, features are extracted; additionally, these are trained and also characterized utilizing PSO-ANFIS, which classifies whether the signal seems normal or else autism signal. The proposed strategy classified the abnormal besides normal signal, all the more precisely, when contrasted with the current ones are established through the experiment.
C1 [Kumar, N. Satheesh; Mahil, J.] Anna Univ, Udaya Sch Engn, Dept Elect & Commun Engn, Vellamodi, Tamil Nadu, India.
   [Mohanalin, J.] Coll Engn, Dept Elect & Elect Engn, Pathanapuram, Kerala, India.
C3 Anna University
RP Kumar, NS (corresponding author), Anna Univ, Udaya Sch Engn, Dept Elect & Commun Engn, Vellamodi, Tamil Nadu, India.
EM nandhikripa@gmail.com; mohanalin@gmail.com; mahilanto@gmail.com
RI Nagarajan, Satheesh Kumar/ITR-9988-2023
CR Abbas A, 2018, ENVIRON SCI POLLUT R, V25, P32491, DOI 10.1007/s11356-018-3203-8
   [Anonymous], 2010, P 3 INT C INF COMM T, DOI DOI 10.1109/ICT4M.2010.5971907
   [Anonymous], 2009, BIOMEDICAL SCI ENG C
   [Anonymous], NEUROPHYSIOLOGY
   [Anonymous], 2016, 2016 Second International Conference on Cognitive Computing and Information Processing (CCIP), DOI [10.1109/CCIP.2016.7802874, DOI 10.1109/CCIP.2016.7802874.[68]D, 10.1109/CCIP.2016.7802874.[68]D.]
   Begum D, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P1563, DOI 10.1109/RTEICT.2016.7808095
   Bi KX, 2013, INT C MANAGE SCI ENG, P569, DOI 10.1109/ICMSE.2013.6586337
   Black MH, 2017, NEUROSCI BIOBEHAV R, V80, P488, DOI 10.1016/j.neubiorev.2017.06.016
   Bosl W, 2011, BMC MED, V9, DOI 10.1186/1741-7015-9-18
   Boughorbel S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177678
   Boutros N.N., 2015, Neuropsychiatr. Electrophysiol, V1, P3, DOI [10.1186/s40810-014-0001-5, DOI 10.1186/S40810-014-0001-5]
   Chaspari T, 2012, INT CONF ACOUST SPEE, P4485, DOI 10.1109/ICASSP.2012.6288916
   Dang X, 2017, J AMB INTEL HUM COMP, V8, P907, DOI 10.1007/s12652-016-0424-x
   Eldridge J, 2014, J NEURODEV DISORD, V6, DOI 10.1186/1866-1955-6-12
   Fan J, 2015, IEEE ENG MED BIO, P3767, DOI 10.1109/EMBC.2015.7319213
   Feng ZP, 2017, IEEE ACCESS, V5, P24301, DOI 10.1109/ACCESS.2017.2766232
   Ganesh P, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P1507, DOI 10.1109/ICACCCT.2014.7019355
   Ghanbari Y, 2015, J AUTISM DEV DISORD, V45, P444, DOI 10.1007/s10803-013-1915-7
   Hoole P. R. P., 2012, 2012 IEEE EMBS Conference on Biomedical Engineering and Sciences (IECBES 2012), P541, DOI 10.1109/IECBES.2012.6498036
   Kakihara Y, 2013, 2013 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P490, DOI 10.1109/SII.2013.6776604
   Mazzei D, 2012, PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY, SECURITY, RISK AND TRUST AND 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM/PASSAT 2012), P766, DOI 10.1109/SocialCom-PASSAT.2012.101
   Min CH, 2010, INT CONF ACOUST SPEE, P2266, DOI 10.1109/ICASSP.2010.5495885
   Santos JF, 2013, INT CONF ACOUST SPEE, P7567, DOI 10.1109/ICASSP.2013.6639134
   Shams W. Khazaal, 2011, Proceedings 2011 IEEE Symposium on Industrial Electronics and Applications (ISIEA 2011), P653, DOI 10.1109/ISIEA.2011.6108797
   Shams W.K., 2013, P 5 INT C INF COMM T, P1
   Sudirman R, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM COMPUTING AND ENGINEERING, P626, DOI 10.1109/ICCSCE.2014.7072794
   Yin Z, 2016, CHIN CONTR CONF, P3907, DOI 10.1109/ChiCC.2016.7553961
NR 27
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8747
EP 8766
DI 10.1007/s11042-018-6290-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600020
DA 2024-07-18
ER

PT J
AU Lingaswamy, S
   Kumar, D
AF Lingaswamy, Sindhia
   Kumar, Dhananjay
TI An efficient moving object detection and tracking system based on
   fractional derivative
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fractional derivative; Motion detection; Object tracking; Video
   surveillance; Forward tracking; Backward tracking
ID MARKERLESS MOTION CAPTURE
AB Video shadowing is a blooming system with the intention of conserving the tangible and also capital resources in an organization. Simultaneously, the necessity to analyze additionally individuals, places, and objects pooled with a yearning to supplement enough valuable information from video information is inspiring novel prerequisites for scalability, capability, and capacity. The motion capture approach is comprehensively utilized for creating animation as it yields best character equivalent to the real object motion. A few methods are offered aimed at moving object detection basically towards human monitoring and also visual inspection. This paper projects moving object detection and tracking approach depending upon the fractional derivative technique, forward tracking and backward tracking. Principally, the obtained input video is isolated into a few frames and each frame is preprocessed by methods for the Gaussian filters with the intention of quelling the noise. For the forward tracking and the backward tracking, the fractional derivative is figured on the preprocessed frames consequent to acquiring the absolute difference. By employing the otsu thresholding approach on the resultant image, the object is detected on every frame. In the object tracking stage, the forward and also backward tracking's product is pooled to get the proper result. The anticipated strategy is executed on the MATLAB platform and the performance is evaluated with the assistance of number of videos. The expected approach is assessed by methods for statistical measures like f-measure, precision, recall, accuracy and estimated with the traditional movement motion detection approaches. The assessment result illustrate that the proposed system is enhanced than the ordinary methodologies of high precision rate.
C1 [Lingaswamy, Sindhia; Kumar, Dhananjay] Anna Univ, Dept Informat Technol, MIT Campus, Chennai 44, Tamil Nadu, India.
C3 Anna University
RP Lingaswamy, S (corresponding author), Anna Univ, Dept Informat Technol, MIT Campus, Chennai 44, Tamil Nadu, India.
EM lsindhia@mitindia.edu; dhananjay@annauniv.edu
RI Kumar, Dhananjay/H-9853-2012; Lingaswamy, Sindhia/JAO-2867-2023;
   LINGASWAMY, SINDHIA/AAC-2217-2021
OI Kumar, Dhananjay/0000-0003-3758-1841; Lingaswamy,
   Sindhia/0000-0002-4089-3961; 
CR [Anonymous], INT J ADV INFORM TEC
   Archana M, 2015, PROCEDIA COMPUT SCI, V58, P225, DOI 10.1016/j.procs.2015.08.060
   Bhaltilak K. V., 2014, INT J COMPUTER SCI I, V5, P6586
   Chenouard N, 2013, IEEE T PATTERN ANAL, V35, P2736, DOI 10.1109/TPAMI.2013.97
   Deepa TK, 2014, INT J MED RES HEALTH, V3, P1
   Deori B., 2014, Int. J. Inf. Theory, V3, P31, DOI [DOI 10.5121/IJIT.2014.3304, 10.5121/ijit.2014.3304]
   Han G, 2016, NEUROCOMPUTING, V184, P145, DOI 10.1016/j.neucom.2015.07.122
   Hu WM, 2013, IEEE T IMAGE PROCESS, V22, P1778, DOI 10.1109/TIP.2012.2236340
   Hua W-C, 2015, MOVING OBJECT DETECT, V30, P164
   Ke SR, 2013, COMPUTERS, V2, P88, DOI 10.3390/computers2020088
   Kothiya SV, 2015, EL EL SIGN COMM OPT, P1
   Lee KH, 2015, IEEE T CIRC SYST VID, V25, P38, DOI 10.1109/TCSVT.2014.2329355
   Li WY, 2016, SIGNAL PROCESS-IMAGE, V43, P28, DOI 10.1016/j.image.2016.01.001
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Liu YH, 2013, SOL ENERGY, V89, P42, DOI 10.1016/j.solener.2012.11.017
   Malik A. A., 2013, INT J COMPUT APPL, V75, P1
   Parekh H.S., 2014, INT J INNOVATIVE RES, V2, P2970
   Patel H., 2011, INT J EMERG TECHNOL, V2, P1
   Patel H.A., 2013, Int. J. Comput. Sci. Mob. Comput, V2, P326, DOI [DOI 10.1109/ICACCT.2018.8529402, DOI 10.1016/J.JVCIR.2006.03.004]
   Patel SandeepKumar., 2013, Indian Journal of Computer Science and Engineering, V4, P95, DOI DOI 10.1108/17595901311299026
   Pathan I., 2015, INT J COMPUT SCI INF, V6, P5212
   Prioletti A, 2013, IEEE T INTELL TRANSP, V14, P1346, DOI 10.1109/TITS.2013.2262045
   Ruan Y, 2016, J VIS COMMUN IMAGE R, V35, P146, DOI 10.1016/j.jvcir.2015.12.009
   Sandau M, 2014, MED ENG PHYS, V36, P1168, DOI 10.1016/j.medengphy.2014.07.007
   Sardari F, 2016, SWARM EVOL COMPUT, V30, P27, DOI 10.1016/j.swevo.2016.04.001
   Sharma V, 2015, INT J FUTUR REV COMP, V1, P13
   Singla N., 2014, INT J INFORM COMPUTA, V4, P1559
   Yang SXM, 2014, COMP M BIO BIO E-IV, V2, P46, DOI 10.1080/21681163.2013.834800
NR 28
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8519
EP 8537
DI 10.1007/s11042-018-5843-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600011
DA 2024-07-18
ER

PT J
AU Ramesh, S
   Yaashuwanth, C
AF Ramesh, S.
   Yaashuwanth, C.
TI Enhanced approach using trust based decision making for secured wireless
   streaming video sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cluster member; Cluster head; LEACH; Base station; Sinkhole; Black hole
AB The advances in the expanse of image sensors have made it conceivable to make high-resolution picture sensors easily accessible. The amelioration of wireless interactive media sensor networks are found to be greatly increased due to the day to day usage of cameras, microphones and smart devices. A secured multi-hop routing mechanism is addressed in surveillance areas which could be incorporated to the multimedia sensors that are capable of peruse the detected data comprises of recorded images and videos. Also, malevolent sensor hubs could be interjected into the vigilance area in an untrusted environment. In this contemplated venture, a novel lightweight trust decision-making framework is accomplished for QoS clustering to give secure routing in both intercluster and intracluster communication. A quantifiable aberrant trust value is the variable determined by the Cluster Head (CH) for its Cluster Member (CM) inside the cluster. The LEACH (Low Energy Adaptive Clustering Hierarchy) protocol is adopted for group formation and also for the exchange of the trust values among the master nodes, member nodes and Base station. In this way, the correspondence overhead, likelihood of dynamic assaults for example sinkhole and black hole assaults mount by eavesdroppers can be reduced by maintenance of trust values by cluster heads rather than cluster members. Besides, in wireless streaming video sensor networks this approach authorizes us to predict and counteract malicious untrusted and flawed nodes. Simulation results using NS-2 is examined and the suggested trust decision-making model escalates the dependability, elasticity and low memory aloft in comparison with the current trust models adopted for wireless video sensor network security.
C1 [Ramesh, S.; Yaashuwanth, C.] Sri Venkateswara Coll Engn, Dept Informat Technol, Chennai, Tamil Nadu, India.
RP Ramesh, S (corresponding author), Sri Venkateswara Coll Engn, Dept Informat Technol, Chennai, Tamil Nadu, India.
EM swami.itraj@gmail.com; yaashuwanth@gmail.com
RI S, Ramesh/AAG-3765-2019; Calpakkam, Yaashuwanth/GPF-4193-2022
CR Almalkawi IT, 2010, SENSORS-BASEL, V10, P6662, DOI 10.3390/s100706662
   [Anonymous], 2004, INPROCEEDINGS ACM
   [Anonymous], 2003, PROC 1 ACM WORKSHOP
   [Anonymous], 2018, 2018 9 IFIP INT C NE, DOI DOI 10.1109/NTMS.2018.8328728
   [Anonymous], INT J TECHNOLOGY ENG
   [Anonymous], 2018, INT C SOFT COMP NETW
   Arar AM, 2016, IEEE SYST J, P1
   BalaAnand M, 2020, INT J PARALLEL PROG, V48, P329, DOI 10.1007/s10766-018-0598-2
   Breivold HP, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA SCIENCE AND DATA INTENSIVE SYSTEMS, P532, DOI 10.1109/DSDIS.2015.11
   Cheng Y, 2007, P INT C COMM NETW IN
   Cho JH, 2011, IEEE COMMUN SURV TUT, V13, P562, DOI 10.1109/SURV.2011.092110.00088
   Dai R, 2010, GLOB TELECOMM CONF
   Felemban E, 2006, IEEE T MOBILE COMPUT, V5, P738, DOI 10.1109/TMC.2006.79
   Fenye Bao, 2012, IEEE Transactions on Network and Service Management, V9, P169, DOI 10.1109/TCOMM.2012.031912.110179
   Geetha V., 2014, Wireless Sensor Network, V6, P173, DOI DOI 10.4236/WSN.2014.69017
   Guyeux C., 2011, P INT C AD HOC NETW, V89, P1
   Guyeux C, 2017, ARXIV170608133V1CSDC
   Han GJ, 2014, J COMPUT SYST SCI, V80, P602, DOI 10.1016/j.jcss.2013.06.014
   Harjito B., 2010, Proceedings of the 2010 International Conference on Broadband, Wireless Computing, Communication and Applications (BWCCA 2010), P842, DOI 10.1109/BWCCA.2010.182
   He T., 2004, ENERGY EFFICIENT SUR, P270, DOI DOI 10.1145/990064.990096
   Hemalatha P., 2018, INT J PURE APPL MATH, V119, P557
   Huadong Ma, 2007, International Journal of Sensor Networks, V2, P44, DOI 10.1504/IJSNET.2007.012981
   Huang XX, 2008, WIREL NETW, V14, P465, DOI 10.1007/s11276-006-0731-9
   Hussain MA, 2009, 11TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, PROCEEDINGS,, P271
   Li XT, 2014, NEURAL COMPUT APPL, V24, P1867, DOI 10.1007/s00521-013-1433-8
   Li Xiaolong, 2013, IEEE T INFORM FORENS, V8
   Liu Y, 2005, IEEE INT C MOB ADH S
   Maram B, 2019, SERV ORIENTED COMPUT, V13, P3, DOI 10.1007/s11761-018-0249-x
   Mehta M, 2005, IEEE IPCCC, P193
   Melodia T, 2008, IEEE INFOCOM SER, P121
   Park J, 2005, P IEEE INT C MOB ADH
   Patel R., 2011, IJCA, V20, P4
   Punitha P., 2018, 2018 INT C SOFT COMP, P1, DOI [10.1109/ICSNS.2018.8573688, DOI 10.1109/ICSNS.2018.8573688]
   Shaikh RA, 2009, IEEE T PARALL DISTR, V20, P1698, DOI 10.1109/TPDS.2008.258
   Sivaparthipan CB, 2018, MULTIMED TOOLS APPL
   Souil M., 2013, Contribution to quality of service in wireless sensor networks
   Vimalkumar S., 2018, Asian Journal of Applied Science and Technololgy, V2, P287
   Willing A., 2005, Praxis der Informationsverarbeitung und Kommunikation, V28, P86
   Zhan GX, 2012, IEEE T DEPEND SECURE, V9, P184, DOI 10.1109/TDSC.2011.58
NR 39
TC 19
Z9 19
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10157
EP 10176
DI 10.1007/s11042-019-7585-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600023
OA hybrid
DA 2024-07-18
ER

PT J
AU Saranyaraj, D
   Manikandan, M
   Maheswari, S
AF Saranyaraj, D.
   Manikandan, M.
   Maheswari, S.
TI A deep convolutional neural network for the early detection of breast
   carcinoma with respect to hyper- parameter tuning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer detection; Deep learning; Deep convolutional neural
   network; Hyper-parameter tuning
ID COMPUTER-AIDED DIAGNOSIS; IMAGE FEATURES; CLASSIFICATION; SEGMENTATION;
   MAMMOGRAMS; EXTRACTION; MACHINE; ENTROPY; MODEL
AB Medical image processing needs attention towards accurate analysis rate which directly implies on the treatment. This paper focuses on the mammogram image analysis for early prediction of breast cancer (Screening) and reduce the mortality rate rather than using an invasive diagnosis technique. To classify the mammogram images a novel network called Deep Convolutional neural network (DCNN) is utilized in which multi-layer perceptron is used in the fully connected layer to accurately classify the mammogram images as three classes benign, malignant and normal. Before classifying the breast cancer, image pre-processing and feature extraction plays a major role in preserving the useful information and extracting the desired features. The Bilateral filter with a vector grid computing is used as the noise reduction filter to preserve the edge information which is essential in differentiating the masses and the dense tissue. The Features like Area, Radius, Perimeter and smoothness are extracted to train the network and to detect the malignant tumor stating if the patient is positive or negative with the cancer. Five stages have been proposed and implemented such as: (a) Crop and resize of the original mammogram; (b) De-Noising the DDSM (Digital Database for Screening Mammography) image to preserve the edge information. (c) Train the proposed DCNN model using the features extracted, (d) Classifying the DDSM images (e) Evaluating the performance using hyper parameter tuning of the proposed system. Unstinted Observations are made to justify the listed findings and by comparing the proposed outline with the help of the literature about the several in-use image classification models. A confusion matrix is drawn with the classes based on: Those with Benign, Malignant and normal tissues. The results are discussed (benchmarked) to show that fine-tuning of the final layers or the entire network parameters leads in achieving 96.23% of overall test accuracy and 97.46% of Average Classification Accuracy.
C1 [Saranyaraj, D.; Manikandan, M.; Maheswari, S.] Anna Univ, Dept Elect Engn, MIT Campus, Chennai, Tamil Nadu, India.
C3 Anna University; Anna University Chennai
RP Saranyaraj, D (corresponding author), Anna Univ, Dept Elect Engn, MIT Campus, Chennai, Tamil Nadu, India.
EM saranya.elec6691@gmail.com; maniiz@annauniv.edu; maheswariss96@gmail.com
RI M, Manikandan/AAR-4674-2020; m, m/GZB-2153-2022; m, w/IVV-5267-2023; D,
   saranyaraj/Q-2014-2016
OI M, Manikandan/0000-0002-9481-4608; D, saranyaraj/0000-0002-4463-3665
CR Alolfe MA, 2009, IEEE IMAGE PROC, P2609, DOI 10.1109/ICIP.2009.5413992
   Amin J, 2017, J COMPUT SCI-NETH, V19, P153, DOI 10.1016/j.jocs.2017.01.002
   [Anonymous], COMPUT BIOL MED
   [Anonymous], CURR MED IMAGING REV
   [Anonymous], 2012, INDIAN J COMPUTER SC
   [Anonymous], P 4 INT WORKSH DIG M
   [Anonymous], 2010, P 27 INT C MACHINE L
   [Anonymous], SPIE MED IMAGING STR
   [Anonymous], IND J SCI TECHNOL
   [Anonymous], CURR MED IMAGING REV
   [Anonymous], 2016, ADV BIOINFORMATICS B
   [Anonymous], 2002, HLTH STAT ATL MORT E
   [Anonymous], 2017, Cancer facts and figures
   [Anonymous], HARO LEADING CAUSE M
   [Anonymous], INT ARAB J INFO TECH
   [Anonymous], COMPUTER AIDED DIAGN
   Arevalo J, 2015, IEEE ENG MED BIO, P797, DOI 10.1109/EMBC.2015.7318482
   Arunkumar N, 2017, PATTERN RECOGN LETT, V94, P112, DOI 10.1016/j.patrec.2017.05.007
   Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8_26
   Carneiro G, 2017, IEEE T MED IMAGING, V36, P2355, DOI 10.1109/TMI.2017.2751523
   Elmoufidi A, 2018, IET IMAGE PROCESS, V12, P320, DOI 10.1049/iet-ipr.2017.0536
   Ertosun MG, 2015, IEEE INT C BIOINFORM, P1310, DOI 10.1109/BIBM.2015.7359868
   Esteve J., 1993, FACTS FIGURES CANC E
   Fernandes SL, 2017, CURR MED IMAGING REV, V13, P176, DOI 10.2174/1573405612666160606143938
   Fernandes SL, 2017, J MED IMAG HEALTH IN, V7, P1841, DOI 10.1166/jmihi.2017.2280
   Fernandes SL, 2016, J COMPUT SCI-NETH, V16, P217, DOI 10.1016/j.jocs.2016.07.013
   Fernandes SL, 2016, J INTEGR DES PROCESS, V20, P33, DOI 10.3233/jid-2016-0002
   Fernandes SL, 2016, COMPUT BIOL MED, V76, P215, DOI 10.1016/j.compbiomed.2016.07.007
   Foggia P, 2013, IEEE T MED IMAGING, V32, P1878, DOI 10.1109/TMI.2013.2268163
   Gao ZM, 2017, IEEE J BIOMED HEALTH, V21, P416, DOI 10.1109/JBHI.2016.2526603
   Glorot X., 2010, P INT C ART INT STAT, P249
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Jadoon MM, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/3640901
   Jain VK, 2017, J COMPUT SCI-NETH, V21, P316, DOI 10.1016/j.jocs.2017.01.010
   Jiao ZC, 2016, NEUROCOMPUTING, V197, P221, DOI 10.1016/j.neucom.2016.02.060
   Kamal S, 2018, NEURAL COMPUT APPL, V29, P1015, DOI 10.1007/s00521-016-2513-3
   Khan MW, 2016, J INTEGR DES PROCESS, V20, P77, DOI 10.3233/jid-2016-0004
   KIMME CAROLYN., 1977, Data structures, computer graphics, and pattern recognition, P427
   Koay J, 2004, P ANN INT IEEE EMBS, V26, P1159
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumara S, 2017, J COMPUT SCI-NETH, V19, P121, DOI 10.1016/j.jocs.2016.11.009
   Lan K, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1003-9
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin CM, 2014, IEEE T FUZZY SYST, V22, P693, DOI 10.1109/TFUZZ.2013.2269149
   Mäntylä MV, 2014, 36TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2014), P83, DOI 10.1145/2568225.2568245
   Oliver A, 2006, INT C PATT RECOG, P707
   Priebe C., 1994, Proceedings of the 2nd International Workshop on Digital Mammography, P111
   Quellec G, 2016, IEEE T MED IMAGING, V35, P1604, DOI 10.1109/TMI.2016.2521442
   Raja NSM, 2017, J MED IMAG HEALTH IN, V7, P1825, DOI 10.1166/jmihi.2017.2267
   Rajinikanth V, 2017, J MED IMAG HEALTH IN, V7, P1837, DOI 10.1166/jmihi.2017.2265
   Rajinikanth V, 2017, PATTERN RECOGN LETT, V94, P87, DOI 10.1016/j.patrec.2017.05.028
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Sameti M, 1998, COMPUT IMAGING VIS, V13, P127
   Shabbir B, 2016, J INTEGR DES PROCESS, V20, P65, DOI 10.3233/jid-2016-0003
   Shah JH, 2017, J MECH MED BIOL, V17, DOI 10.1142/S0219519417400115
   Si HQ, 2014, SCI WORLD J, DOI 10.1155/2014/371045
   Sickles E A, 1997, J Natl Cancer Inst Monogr, P99
   Tan M, 2016, IEEE T MED IMAGING, V35, P1719, DOI 10.1109/TMI.2016.2527619
   Tyagi SKS, 2017, J COMPUT SCI-NETH, V19, P112, DOI 10.1016/j.jocs.2016.11.012
   Wei LY, 2005, IEEE T MED IMAGING, V24, P371, DOI 10.1109/TMI.2004.842457
NR 60
TC 22
Z9 22
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 11013
EP 11038
DI 10.1007/s11042-018-6560-x
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600069
DA 2024-07-18
ER

PT J
AU Tian, C
   Xia, JF
   Tang, J
   Yin, H
AF Tian, Chi
   Xia, Jinfeng
   Tang, Ji
   Yin, Hui
TI Deep image retrieval of large-scale vessels images based on BoW model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Vessel recognition; Deep feature extraction;
   Bag-of-words model
AB This paper focuses on the vessel image retrieval from massive data, whose goal is to identify relevant records quickly and accurately when new images are given. Noteworthy, it is necessary to find features with high representativeness under the impact of moisture. Traditional features are extracted on the basis of single convolution feature and manual feature coding. However, only a few can express key features of vessels' images due to the incomplete or redundant information. In order to solve this problem, this paper proposes a new strategy. Two dictionary databases are constructed using different convolution layers in VGG16 network; then they are merged to one database that can strongly express the vessel image. Materially, the combined dictionary database consists of two-layer convolution features, which express the original image well with strengthening key information and less redundant information. The algorithm uses BoW (Bag-of-Words) expression of VGG16 neural network in the domain of image retrieval. Compared with traditional methods using SIFT or SUFT features as BoW, experiments on self-build database shows that the proposed algorithm performs better and achieves higher accuracy.
C1 [Tian, Chi; Xia, Jinfeng; Tang, Ji] CSIC PRIDe Nanjing Atmospher & Ocean Informat Sys, Nanjing 210000, Jiangsu, Peoples R China.
   [Yin, Hui] Zhenjiang Maritime Safety Adm, Nanjing 210000, Jiangsu, Peoples R China.
C3 China Shipbuilding Industry Corporation
RP Tian, C (corresponding author), CSIC PRIDe Nanjing Atmospher & Ocean Informat Sys, Nanjing 210000, Jiangsu, Peoples R China.
EM tianchinj@sina.com
CR [Anonymous], INT SOC OPTICS PHOTO
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Cai Junjie., 2014, Proceedings of International Conference on Multimedia Retrieval, P407
   Chao JS, 2015, IEEE INT CON MULTI
   Estlick M., 2001, FPGA 01, P103
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Horster E., 2008, Proceedings of the 16th ACM international conference on Multimedia, P643
   Ji RR, 2013, IEEE T MULTIMEDIA, V15, P153, DOI 10.1109/TMM.2012.2225035
   Lin Kevin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P27, DOI 10.1109/CVPRW.2015.7301269
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lv Q., 2007, P 33 INT C VER LARG, P950
   Paulin M, 2015, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2015.19
   Razavian A. S., 2016, ITE Trans. Media Technol. Appl., V4, P251, DOI [DOI 10.3169/MTA.4.251, 10.3169/mta.4.251]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Salvador A, 2016, IEEE COMPUT SOC CONF, P394, DOI 10.1109/CVPRW.2016.56
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang F, 2015, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2015.7298797
   Wang XY, 2011, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2011.6126244
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang F, 2015, LECT NOTES ARTIF INT, V8955, P436, DOI 10.1007/978-3-319-14803-8_34
   Zheng L, 2014, PROC CVPR IEEE, P1947, DOI 10.1109/CVPR.2014.250
NR 28
TC 4
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9387
EP 9401
DI 10.1007/s11042-019-7725-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600058
DA 2024-07-18
ER

PT J
AU Zhang, XH
   Gao, Y
AF Zhang, Xiaohong
   Gao, Yan
TI RETRACTED: Multimedia text classification algorithm using potential
   Dirichlet distribution in mobile cloud computing environment (Retracted
   article. See vol. 81, pg. 39827, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Multimedia text classification algorithm; Potential Dirichlet
   distribution; Gibbs sampling method; Relationship matrix; Mobile cloud
   computing
ID TIME
AB In order to solve the problem of inaccurate description of news content features and user interest features in mobile cloud computing, proposed a multimedia text classification algorithm that utilizes multi-tag potential Dirichlet distribution. The algorithm is based on the traditional latent Dirichlet allocation (LDA) model and assumes a linear relationship between user tags and potential topics. Therefore, a relational matrix is introduced in the LDA model to describe the corresponding relationship between the tag and the topic, so that the probability distribution of the tag on the word can be inferred from the probability distribution of the topic on the word. The algorithm first learns the probability distribution table of label words by Gibbs sampling method, then infers the probability distribution of new documents on labels according to the model parameters, so as to realize the purpose of predicting the corresponding multiple labels of documents. In order to improve the ability of the algorithm to deal with massive data, the parallel algorithm has been improved. Since the bottleneck of the algorithm lies mainly in the serial nature of global variable updating and communication, the core idea of our parallelization is that in massive text training, global delay updating and asynchronous communication will not affect the final training results. Experiments show that the proposed algorithm has greatly improved the training efficiency. The classification accuracy is higher than that of Naive Bayesian algorithm and Support Vector Machine (SVM) algorithm proposed in other literatures. The average classification accuracy can achieve at about 95%, and it can be used as a general parallel framework of supervised LDA algorithm.
C1 [Zhang, Xiaohong] Southwest Petr Univ, Sch Comp Sci, Chengdu 610500, Sichuan, Peoples R China.
   [Gao, Yan] Chengdu Univ Informat Technol, Sch Software Engn, Chengdu 610225, Peoples R China.
C3 Southwest Petroleum University; Chengdu University of Information
   Technology
RP Zhang, XH (corresponding author), Southwest Petr Univ, Sch Comp Sci, Chengdu 610500, Sichuan, Peoples R China.
EM Steven1999@126.com
RI Zhang, Xiaohong/A-3060-2015
CR Chen HK, 2015, J SYST SOFTWARE, V99, P20, DOI 10.1016/j.jss.2014.08.065
   El Kaitouni SE, 2018, MULTIMED TOOLS APPL, V77, P31347, DOI 10.1007/s11042-018-6089-z
   Fernández P, 2015, SOL ENERGY, V112, P458, DOI 10.1016/j.solener.2014.11.012
   Goudjil M, 2018, INT J AUTOM COMPUT, V15, P290, DOI 10.1007/s11633-015-0912-z
   Guo Y, 2018, IEEE T CLOUD COMPUT, V6, P209, DOI 10.1109/TCC.2015.2464795
   Ishizuka A, 2017, MICROSCOPY, V66, P1
   Jasim Mohammad OK, 2015, INT C CLOUD COMP
   Liu YP, 2017, KODAI MATH J, V40, P1
   Mohamed E, 2018, ACM T ASIAN LOW-RESO, V17, DOI 10.1145/3178459
   Nunez-Gonzalez JD, 2017, INT WORK C INT NAT A
   Sagnika S., 2018, INT J COMPUTER APPL, V89, P11
   Sain D, 2018, IFAC PAPERSONLINE, V51, P106, DOI 10.1016/j.ifacol.2018.05.018
   Shahab Y, 2019, APPL ECON LETT, V26, P261, DOI 10.1080/13504851.2018.1464643
   Singh S, 2016, KNOWL INF SYST, V49, P1005, DOI 10.1007/s10115-016-0922-3
   Sopin ES, 2018, AUTOM CONTROL COMPUT, V52, P60, DOI 10.3103/S0146411618010066
   Viegas F, 2018, NEUROCOMPUTING, V307, P153, DOI 10.1016/j.neucom.2018.04.033
   Wang HM, 2018, IET IMAGE PROCESS, V12, P1124, DOI 10.1049/iet-ipr.2017.0290
   Wang SH, 2015, NEUROCOMPUTING, V168, P747, DOI 10.1016/j.neucom.2015.05.049
   Wen WT, 2015, 9 INT C FRONT COMP S
   Yun XC, 2016, IEEE ACM T NETWORK, V24, P583, DOI 10.1109/TNET.2014.2381230
   Zhang C, 2018, INT CCF C ART INT
   Zhang ZX, 2016, IEEE T GEOSCI REMOTE, V54, P7309, DOI 10.1109/TGRS.2016.2599163
   Zhang ZX, 2016, IEEE T GEOSCI REMOTE, V54, P3309, DOI 10.1109/TGRS.2016.2514508
NR 23
TC 3
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9615
EP 9627
DI 10.1007/s11042-019-08253-1
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600071
DA 2024-07-18
ER

PT J
AU Jin, H
   Miao, YT
   Chen, XP
   Seo, JH
   Park, EM
AF Jin, Hong
   Miao, Yunting
   Chen, Xinping
   Seo, Joung-Hae
   Park, Eun-Mi
TI Motivation research on the participation of multimedia Web page users in
   "share" behavior: a case study of Alipay
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Web page; User engagement behavior; Motivation; Privacy
   concern; Knowledge discovery
ID CONSUMER PARTICIPATION; PRIVACY PARADOX; MODEL; ACCEPTANCE; DISCLOSURE
AB With the rapid development of mobile Internet technology, a series of activities such as "share billing bills", "share songs list", and "share footprints" in the past two years have won a great success and wide participation of users. It is of a great practical significance for enterprises to use multimedia to carry out "share" behavior to win users and gain competitive advantage. Therefore, this paper introduces the design of such multimedia pages and the multimedia technology used, and evaluates the interactivity of multimedia page design from the perspective of user experience. More specifically, we construct a motivation model for users to participate in "share" behavior, and use empirical research methods to analyze the impact of motivation (information motivation, social motivation, entertainment motivation) on users' participation in "share" behavior. The results demonstrate that information motivation, social motivation, and entertainment motivation have a significant impact on users' participation in "share" behavior. These influences, in the descending order of their importance, are entertainment motivation, information motivation, and social motivation. Privacy concerns do not play a mediating role in the relationship between motivation and user involvement in "share" behavior. Taken together, the results of the present study not only reveal and explain the motivation mechanism of consumers participating in "share" behavior in multimedia pages, but also help evaluate the perceived quality of emerging multimedia services from the perspective of consumer participation, as well as provide some inspiration for interactive design and improvement of multimedia pages.
C1 [Jin, Hong; Miao, Yunting] Jiangxi Normal Univ, Sch Business, 99 Ziyang Rd, Nanchang 330022, Jiangxi, Peoples R China.
   [Chen, Xinping] Nanchang Univ, Affiliated Hosp 1, 17 Yongwaizheng Rd, Nanchang 330022, Jiangxi, Peoples R China.
   [Seo, Joung-Hae; Park, Eun-Mi] Kyungpook Natl Univ, Sch Business, 80 Daehakro, Daegu 41566, South Korea.
C3 Jiangxi Normal University; Nanchang University; Kyungpook National
   University
RP Park, EM (corresponding author), Kyungpook Natl Univ, Sch Business, 80 Daehakro, Daegu 41566, South Korea.
EM 342944219@qq.com; 771022025@qq.com; chenxpdr@163.com; johseo@knu.ac.kr;
   issack38317@naver.com
RI Chen, Xinping/C-7877-2018
FU National Natural Science Foundation of China [71562020]; Thirteenth
   Five-Year Planning (2017) research project of Jiangxi Social Science
   [17GL05]; Jiangxi Universities Humanities and Social Sciences Research
   on Young Fund [GL17115]
FX This research was supported by National Natural Science Foundation of
   China (No.71562020), Thirteenth Five-Year Planning (2017) research
   project of Jiangxi Social Science (No.17GL05) and Jiangxi Universities
   Humanities and Social Sciences Research on Young Fund (GL17115).
CR [Anonymous], 1975, INTRINSIC MOTIVATION, DOI [10.1007/978-1-4613-4446-9_3, DOI 10.1007/978-1-4613-4446-9_3]
   Baek K, 2011, COMPUT HUM BEHAV, V27, P2243, DOI 10.1016/j.chb.2011.07.003
   Basak E, 2015, COMPUT HUM BEHAV, V48, P181, DOI 10.1016/j.chb.2015.01.055
   Chen HT, 2013, CYBERPSYCH BEH SOC N, V16, P806, DOI 10.1089/cyber.2011.0608
   Chen Z, 2017, J CONSUM RES, V44, P613, DOI 10.1093/jcr/ucx055
   Dholakia UM, 2004, INT J RES MARK, V21, P241, DOI 10.1016/j.ijresmar.2003.12.004
   Feng C, 2004, BASIS EMBEDDED REAL
   Foster M.K., 2010, International Journal of e-Business Management, V4, P3
   Hallam C, 2017, COMPUT HUM BEHAV, V68, P217, DOI 10.1016/j.chb.2016.11.033
   Kerlinger F, 1984, FDN BEHAV RES, P212
   Kim DJ, 2008, DECIS SUPPORT SYST, V44, P544, DOI 10.1016/j.dss.2007.07.001
   Kwon SJ, 2014, SOC SCI J, V51, P534, DOI 10.1016/j.soscij.2014.04.005
   Li L, 2017, MULTIMED TOOLS APPL, V76, P24955, DOI 10.1007/s11042-017-5212-x
   Li YS, 2015, MODERN ELECT TECHNIQ, V38, P32
   Liang Z, 2009, COMPUTER KNOWLEDGE T, V29, P8183
   Malhotra NK, 2004, INFORM SYST RES, V15, P336, DOI 10.1287/isre.1040.0032
   Moon Y, 2019, MULTIMED TOOLS APPL, V78, P28435, DOI 10.1007/s11042-017-5492-1
   Nambisan S, 2009, J PROD INNOVAT MANAG, V26, P388, DOI 10.1111/j.1540-5885.2009.00667.x
   Nogueira B, 2017, SOFT COMPUT, V21, P4141, DOI 10.1007/s00500-016-2061-x
   Norberg PA, 2007, J CONSUM AFF, V41, P100, DOI 10.1111/j.1745-6606.2006.00070.x
   Phelps JosephE., 2001, J INTERACT MARK, V15, P2, DOI [DOI 10.1002/DIR.1019, 10.1002/dir.1019]
   Ryan RM, 2006, MOTIV EMOTION, V30, P347, DOI 10.1007/s11031-006-9051-8
   Simonson I, 2005, J MARKETING, V69, P32, DOI 10.1509/jmkg.69.1.32.55512
   Sung YJ, 2010, J GLOB MARK, V23, P430, DOI 10.1080/08911762.2010.521115
   Tang JH, 2017, TELEMAT INFORM, V34, P1274, DOI 10.1016/j.tele.2017.05.012
   Vasalou A, 2010, INT J HUM-COMPUT ST, V68, P719, DOI 10.1016/j.ijhcs.2010.06.002
   Wasko MM, 2005, MIS QUART, V29, P35, DOI 10.2307/25148667
   Xiaojing Y, 2011, MOD ELECT TECHNOL, V34, P73
   Xinmin D, 2016, DIGITAL TECHNOLOGY A, V8, P136
   Yuan Y, 2019, MULTIMED TOOLS APPL, V11, P1
NR 30
TC 3
Z9 3
U1 3
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34571
EP 34589
DI 10.1007/s11042-020-08819-4
EA MAR 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000564403600002
DA 2024-07-18
ER

PT J
AU Jiang, YF
   Chang, S
   Zheng, EX
   Hu, LN
   Liu, RR
AF Jiang, Yifeng
   Chang, Shan
   Zheng, Enxing
   Hu, Linna
   Liu, Ranran
TI Exploiting Surroundedness and Superpixel cues for salient region
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual attention; Saliency detection; Salient region detection;
   Surroundedness; Superpixel
ID VISUAL-ATTENTION; IMAGE; INTEGRATION; MODEL
AB In this paper, we will present a new salient region detection method by exploiting its surrounding and superpixel cues. Its main highlights are: 1) An input image is quantized to 256 colors by using minimum variance quantization; 2) Saliency maps is computed based on the figure-ground segregation of the quantized image; 3) Mean saliency value of each superpixel is employed to refine saliency maps further. This can highlight salient objects robustly and suppress backgrounds evenly. Experimental results show that the proposed method produces more accurate saliency maps and performs well against twenty-one saliency models concerning three evaluation metrics on two public datasets.
C1 [Jiang, Yifeng] Jiangsu Univ Technol, Informat Ctr, Changzhou 213001, Jiangsu, Peoples R China.
   [Chang, Shan; Zheng, Enxing] Jiangsu Univ Technol, Inst Bioinformat & Med Engn, Sch Elect & Informat Engn, Changzhou 213001, Jiangsu, Peoples R China.
   [Hu, Linna] Nanjing Univ Sci & Technol, Zijin Coll, Nanjing 210023, Jiangsu, Peoples R China.
   [Liu, Ranran] Jiangsu Univ Technol, Sch Automot & Traff Engn, Changzhou 213001, Jiangsu, Peoples R China.
   [Liu, Ranran] Changzhou Vocat Inst Mechatron Technol, Changzhou Key Lab Ind Internet & Data Intelligenc, Changzhou 213164, Jiangsu, Peoples R China.
C3 Jiangsu University of Technology; Jiangsu University of Technology;
   Nanjing University of Science & Technology; Jiangsu University of
   Technology; Changzhou Vocational Institute of Mechatronic Technology
RP Liu, RR (corresponding author), Jiangsu Univ Technol, Sch Automot & Traff Engn, Changzhou 213001, Jiangsu, Peoples R China.; Liu, RR (corresponding author), Changzhou Vocat Inst Mechatron Technol, Changzhou Key Lab Ind Internet & Data Intelligenc, Changzhou 213164, Jiangsu, Peoples R China.
EM schang@jsut.edu.cn; lrr@jsut.edu.cn
RI jiang, yifeng/GWM-9104-2022; Liu, Ranran/JEC-0687-2023; jiang,
   yifeng/HSI-1947-2023
FU Jiangsu Policy Guidance (Industry University Research) Project
   [BY2018130]; Special Program for Applied Research on Super Computation
   of the NSFC-Guangdong Joint Fund [U1501501]; Industry-Academia
   Cooperation Innovation Fund Project of Jiangsu Province [BY2016030-06];
   Six Talent Peaks Project in Jiangsu Province [2016-XYDXXJS-020];
   Changzhou Key Laboratory of Industrial Internet and Data Intelligence
   [CM20183002]
FX This work was supported in part by Jiangsu Policy Guidance (Industry
   University Research) Project (Grant no. BY2018130), Special Program for
   Applied Research on Super Computation of the NSFC-Guangdong Joint Fund
   (Grant No. U1501501), Industry-Academia Cooperation Innovation Fund
   Project of Jiangsu Province(BY2016030-06), Six Talent Peaks Project in
   Jiangsu Province (2016-XYDXXJS-020) and Changzhou Key Laboratory of
   Industrial Internet and Data Intelligence (No.CM20183002).
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2003, P 11 ACM INT C MULTI, DOI DOI 10.1145/957013.957094
   [Anonymous], ARXIV170308912CSCV
   BORJI A, 2012, P IEEE C COMP VIS PA, P23
   CHEN Z, PATTERN RECOGN LETT
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Heckbert P., 1982, Computer Graphics, V16, P297, DOI 10.1145/965145.801294
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Lou J, 2017, MULTIMED TOOLS APPL, V76, P14781, DOI 10.1007/s11042-016-4025-7
   Lou J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0112475
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Palmer S., 1999, VISION SCI PHOTONS P
   Qin CC, 2014, NEUROCOMPUTING, V129, P378, DOI 10.1016/j.neucom.2013.09.021
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Ren ZX, 2014, IEEE T CIRC SYST VID, V24, P769, DOI 10.1109/TCSVT.2013.2280096
   Russell B.C., 2006, Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, V2, P1605, DOI DOI 10.1109/CVPR.2006.326
   Scharfenberger C, 2015, IEEE T IMAGE PROCESS, V24, P457, DOI 10.1109/TIP.2014.2380351
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Tavakoli HR, 2011, LECT NOTES COMPUT SC, V6688, P666, DOI 10.1007/978-3-642-21227-7_62
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   ZHANG J, 2019, VISUAL SALIENCY PIXE, P45
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
   Zhang K, 2019, SMART POLYMER CATALYSTS AND TUNABLE CATALYSIS, P95, DOI 10.1016/B978-0-12-811840-5.00005-8
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
NR 44
TC 0
Z9 0
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10935
EP 10951
DI 10.1007/s11042-020-08783-z
EA MAR 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000519417300001
DA 2024-07-18
ER

PT J
AU Kaur, B
AF Kaur, Bineet
TI Iris spoofing detection using discrete orthogonal moments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contact lens; Dual-Hahn moments; Iris spoofing; Krawtchouk moments;
   Orthogonal moments; Print attacks; Tchebichef moments
ID IMAGE-ANALYSIS; RECOGNITION; IDENTIFICATION; FINGERPRINT
AB Human iris being the most stable biometric modality suffers from presentation attacks like colored textured contact lenses and print attacks that obfuscate the natural iris texture. The paper presents discrete orthogonal moment-based invariant feature-set comprising of Tchebichef, Krawtchouk and Dual-Hahn moments which are extracted at localized iris regions to capture local intensity distributions of the iris texture. The orthogonal moment-based feature-set is made rotation, translation and scale-invariant in order to accommodate for geometric transformations when images are acquired in uncontrolled environment. The performance of the proposed techniques is evaluated using four publicly available iris spoofing databases: IIITD-Contact Lens Iris, IIITD Iris Spoofing, Clarkson LivDet 2015 and Warsaw LivDet 2015. The textured contact lens detection rate of 100% for IIITD-CLI and 99.48% for Clarkson datasets is achieved, respectively. Similarly, print+scan and print+capture attacks are detected with 99% and 98.93% accuracy for IIS datasets, respectively. The print attacks are detected with 99.63% and 98.89% accuracy for Clarkson and Warsaw datasets, respectively. The proposed techniques thus, prove to be effective in terms of contact lens and print attacks detection when acquired using multiple sensors.
C1 [Kaur, Bineet] Punjab Engn Coll, Dept Elect & Commun Engn, Chandigarh 160012, India.
C3 Punjab Engineering College (Deemed University)
RP Kaur, B (corresponding author), Punjab Engn Coll, Dept Elect & Commun Engn, Chandigarh 160012, India.
EM bineetkaur91@gmail.com
RI Maunder, Bineet Kaur/I-8506-2019
CR [Anonymous], IEEE Int. Conf. on Biometrics, DOI [DOI 10.1109/ICB.2013.6613021, 10.1109/ICB]
   Arora SS, 2012, IAPR INT C BIOM, P336, DOI DOI 10.1109/ICB.2012.6199829
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Daugman J., 2003, INT J WAVELETS MULTI, V1, P1, DOI DOI 10.1142/S0219691303000025
   Doyle JS, 2013, INT CONF BIOMETR
   Flom L., 1987, US Patent, Patent No. [4641349, 4,641,349]
   Flusser J, 2016, 2D and 3D image analysis by moments, P320, DOI DOI 10.1002/9781119039402
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Gragnaniello D, 2015, IEEE T INF FOREN SEC, V10, P849, DOI 10.1109/TIFS.2015.2404294
   Gragnaniello D, 2015, PATTERN RECOGN, V48, P1050, DOI 10.1016/j.patcog.2014.05.021
   Gupta P, 2014, INT C PATT RECOG, P1681, DOI 10.1109/ICPR.2014.296
   Han M.K. Jiawei., 2011, Data Mining: Concepts and Techniques: Concepts and Techniques, V3rd
   He XF, 2007, LECT NOTES COMPUT SC, V4642, P540
   Hollingsworth K, 2009, COMPUT VIS IMAGE UND, V113, P150, DOI 10.1016/j.cviu.2008.08.001
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hu Y, 2016, PATTERN RECOGN LETT, V82, P242, DOI 10.1016/j.patrec.2015.10.010
   Hui Zhang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4279, DOI 10.1109/ICPR.2010.1040
   Jain A K, 2011, Introduction to Biometrics
   Junying Gan, 2005, Advances in Biometrics. International Conference, ICB 2006. Proceedings (Lecture Notes in Computer Science Vol.3832), P443
   Kaur B, 2018, J ENG APPL SCI, V13, P2049
   Kaur B, 2019, INT J BIOMETRICS, V11, P160
   Kaur B, 2019, COMPUT ELECTR ENG, V73, P279, DOI 10.1016/j.compeleceng.2018.12.002
   Kaur B, 2018, INT J BIOMETRICS, V10, P352, DOI 10.1504/IJBM.2018.095293
   Kaur B, 2018, ARAB J SCI ENG, V43, P7209, DOI 10.1007/s13369-017-3057-2
   Kaur B, 2018, WIRELESS PERS COMMUN, V99, P799, DOI 10.1007/s11277-017-5153-8
   Kaur B, 2017, WIRELESS PERS COMMUN, V95, P4823, DOI 10.1007/s11277-017-4126-2
   Kaur B, 2017, IMAGING SCI J, V65, P171, DOI 10.1080/13682199.2017.1311524
   Kaur B, 2016, ADV HUM-COMPUT INTER, V2016, DOI 10.1155/2016/6727806
   Kaur B, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P1085, DOI 10.1109/CCAA.2015.7148567
   Ma L, 2003, IEEE T PATTERN ANAL, V25, P1519, DOI 10.1109/TPAMI.2003.1251145
   Masek Libor, 2003, RECOGNITION HUMAN IR, P1
   Menotti D, 2015, IEEE T INF FOREN SEC, V10, P864, DOI 10.1109/TIFS.2015.2398817
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Nalla PR, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2616281
   Nichols JJ, 2012, ANN REPORT CONTACT L
   Pala F, 2017, IEEE IMAGE PROC, P116, DOI 10.1109/ICIP.2017.8296254
   Pillai JK, 2014, IEEE T PATTERN ANAL, V36, P73, DOI 10.1109/TPAMI.2013.98
   Priyal SP, 2013, PATTERN RECOGN, V46, P2202, DOI 10.1016/j.patcog.2013.01.033
   Raghavendra R, 2017, IEEE WINT CONF APPL, P1160, DOI 10.1109/WACV.2017.134
   Raghavendra R, 2014, 2 INT WORKSH BIOM FO, p[1, 24]
   Rahman SMM, 2016, PATTERN RECOGN, V54, P83, DOI 10.1016/j.patcog.2016.01.003
   Sequeira AF, 2014, IEEE IJCNN, P3002, DOI 10.1109/IJCNN.2014.6889816
   Silva P, 2015, SIBGRAPI, P157, DOI 10.1109/SIBGRAPI.2015.16
   Tan CW, 2013, 2013 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS)
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Tsougenis ED, 2012, J SYST SOFTWARE, V85, P1864, DOI 10.1016/j.jss.2012.02.045
   UID Authority of India, 2012, ROL BIOM TECHN AADH
   Wei ZH, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.428
   Yadav D, 2014, IEEE T INF FOREN SEC, V9, P851, DOI 10.1109/TIFS.2014.2313025
   Yambay D, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON IDENTITY, SECURITY AND BEHAVIOR ANALYSIS (ISBA)
   Yap PT, 2007, IEEE T PATTERN ANAL, V29, P2057, DOI 10.1109/TPAMI.2007.70709
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zhang HY, 2016, IEEE IMAGE PROC, P1, DOI 10.1109/ICIP.2016.7532307
NR 53
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6623
EP 6647
DI 10.1007/s11042-019-08281-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900053
DA 2024-07-18
ER

PT J
AU Saremi, M
   Yaghmaee, F
AF Saremi, Mehrin
   Yaghmaee, Farzin
TI Efficient encoding of video descriptor distribution for action
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Video representation; Bag-of-words; Fisher vectors;
   Maclaurin expansion; Moments
ID HISTOGRAM; HISTORY; SCALE
AB Action recognition has been an active area of study in the literature. Many proposed methods extract a set of descriptors from the video, which embody information about gradient, motion, etc. Then, the descriptors are mapped to a feature vector, which is used for classification. Two widely used methods for this mapping are bag-of-words and Fisher vectors. The former requires k-means clustering and the latter Gaussian mixture model training, prior to making feature vectors. Both of these algorithms need a global training phase on the whole dataset which is expensive both in time and memory. Moreover, because the final feature vector depends on the initial training phase, these feature vectors are not very scalable. In this paper, we seek to use Maclaurin coefficients of the density function and moments of the distribution to encode the distribution of video descriptors. Experiments on three datasets namely UCF Sports, JHMDB, and KTH suggest that our methods are much faster than Fisher vectors in training and testing, and are more scalable, too. In fact, as the features only depend on the video descriptors and not cluster centers, they offer more scalability when new videos are added to the dataset. However, Fisher vectors are, in some cases, more accurate than the proposed approaches. Comparison to state-of-the-art shows that our method is faster, and in some cases, achieves comparable accuracy.
C1 [Saremi, Mehrin; Yaghmaee, Farzin] Semnan Univ, Elect & Comp Engn Dept, Campus 1,Opposite Soukan Pk, Semnan, Iran.
C3 Semnan University
RP Yaghmaee, F (corresponding author), Semnan Univ, Elect & Comp Engn Dept, Campus 1,Opposite Soukan Pk, Semnan, Iran.
EM m.saremi@semnan.ac.ir; f_yaghmaee@semnan.ac.ir
RI Yaghmaee, Farzin/AAZ-6590-2021; Saremi, Mehrin/HTM-6225-2023
OI Yaghmaee, Farzin/0000-0001-7430-542X; Saremi, Mehrin/0000-0001-6557-9656
CR Ahad MAR, 2016, J MULTIMODAL USER IN, V10, P335, DOI 10.1007/s12193-016-0229-4
   Ahmad M, 2006, PATT REC ICPR 2006 1
   [Anonymous], 2014, P IEEE C COMP VIS PA
   [Anonymous], P 15 INT C MULT
   [Anonymous], 2010, P ACM INT C IM VID R
   [Anonymous], P IEEE COMP SOC C CO
   [Anonymous], COMP VIS 2005 ICCV 2
   Atrey PK, 2011, MULTIMED TOOLS APPL, V51, P697, DOI 10.1007/s11042-010-0649-1
   Burghouts GJ, 2014, SIGNAL IMAGE VIDEO P, V8, pS191, DOI 10.1007/s11760-014-0672-1
   Cortes X, 2018, LECT NOTES COMPUTER
   Danafar S, 2007, COMPUTER VISION ACCV
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Dollar P., PIOTRS COMPUTER VISI
   Efros AA, 2003, COMP VIS P 9 IEEE IN
   Elshourbagy M, 2016, EGYPT INFORM J, V17, P227, DOI 10.1016/j.eij.2015.11.002
   Grushin A, 2013, IEEE IJCNN
   Harris C., 1988, ALVEY VISION C, P147151
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686
   Jaakkola T., 1998, ADV NEURAL INF PROCE, V11
   Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330
   Jhuang H, 2007, 2007 IEEE 11 INT C C
   Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Kuehne H., 2011, P INT C COMP VIS
   Laptev I, 2008, COMP VIS PATT REC CV
   Laptev I, 2003, P 9 IEEE INT C COMP
   Li XL, 2012, ADV INTEL SYS RES, V23
   Lin W, 2008, CIRC SYST ISCAS 2008
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahbub U, 2014, SIGNAL IMAGE VIDEO P, V8, P243, DOI 10.1007/s11760-013-0533-3
   Martinez-Contreras F, 2009, ADV VID SIGN BAS SUR
   Morariu VI, 2011, CVPR 2011
   Ning H, 2007, IM PROC ICIP 2007 IE
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oruganti VRM, 2016, IET COMPUT VIS
   Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38
   Perronnin F, 2007, COMP VIS PATT REC CV
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Qiao RZ, 2017, PATTERN RECOGN, V66, P202, DOI 10.1016/j.patcog.2017.01.015
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Rodriguez M.D., 2008, COMPUTER VISION PATT
   Ryoo MS, 2006, IEEE COMP SOC C COMP
   Sargano AB, 2017, P INT JOINT C NEUR N
   Schuldt C, 2004, PATT REC ICPR 2004 P
   Shao L, 2016, INT J COMPUT VISION, V118, P115, DOI 10.1007/s11263-015-0861-6
   Sivic J., 2003, COMP VIS P 9 IEEE IN
   Soomro K., 2014, COMPUTER VISION SPOR, V71, P181, DOI [DOI 10.1007/978-3-319-09396-3_9, DOI 10.1007/978-3-319-09396-39]
   Tsai DM, 2015, SIGNAL IMAGE VIDEO P, V9, P1897, DOI 10.1007/s11760-014-0677-9
   Tu ZG, 2018, PATTERN RECOGN, V79, P32, DOI 10.1016/j.patcog.2018.01.020
   Vezzani R, 2010, LECT NOTES COMPUT SC, V6388, P286, DOI 10.1007/978-3-642-17711-8_29
   Wang H, 2016, INT J COMPUT VISION, V119, P219, DOI 10.1007/s11263-015-0846-5
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang L, 2016, LECT NOTES COMPUTER
   Wang Y, 2017, P BRIT MACH VIS C BM
   Yeffet L, 2009, COMP VIS IEEE 12 INT
   Zhu XF, 2014, PHYS REV X, V4, DOI 10.1103/PhysRevX.4.031042
NR 57
TC 7
Z9 7
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6025
EP 6043
DI 10.1007/s11042-019-08483-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900027
DA 2024-07-18
ER

PT J
AU Shin, DK
   Ahmed, MU
   Kim, YH
   Rhee, PK
AF Shin, Dong Kyun
   Ahmed, Minhaz Uddin
   Kim, Yeong Hyeon
   Rhee, Phill Kyu
TI Dynamic MLML-tree based adaptive object detection using heterogeneous
   data distribution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Convolutional neural network; Multi-layer multi-label;
   Object detection
AB We propose a robust object-detector ensemble by introducing a dynamic multi-layer multi-label (MLML)-tree-based adaptive deep learning framework. In many heterogeneous data distributions, deep attributes show latent hierarchical clustering properties. Object detector performance can be enhanced using the dynamic MLML-tree, which can adjust the ambiguities between inter-class nodes and variations between sub-class nodes. In the MLML-tree, dynamic multi-label (DML) trees are configured in two layers and adapt to using a sparse working dataset. First, coarse object clusters are built using an outlier-aware soft-clustering algorithm. Each coarse cluster is denoted by an inter-class node and is associated with an adaptive object detector in DML tree layer 1. It is built by recursively partitioning inter-class nodes until homogeneous object-class leaves are built. DML tree layer 2 is built for each object-class node, which is associated with a convolutional neural network detector, recursively. A novel sub-class can be learned automatically in DML tree layer 2 by applying semi-supervised learning. Extensive experiments show that the proposed method is superior to state-of-the-art techniques using PASCAL Visual Object Classes (VOC) 2007, VOC 2012, and the Microsoft Common Objects in Context (COCO) datasets.
C1 [Shin, Dong Kyun; Ahmed, Minhaz Uddin; Kim, Yeong Hyeon; Rhee, Phill Kyu] Inha Univ, Dept Comp Engn, 100 Inha Ro, Incheon 22212, South Korea.
C3 Inha University
RP Rhee, PK (corresponding author), Inha Univ, Dept Comp Engn, 100 Inha Ro, Incheon 22212, South Korea.
EM pkrhee@inha.ac.kr
RI Ahmed, Minhaz Uddin/B-8803-2012; Rhee, Phill Kyu/AAP-5810-2021
OI Ahmed, Minhaz Uddin/0000-0002-8267-8506; 
CR Dai J., 2006, Proceedings of The 23rd International Conference on Machine Learning, P225
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding K, 2015, IEEE GEOSCI REMOTE S, V12, P577, DOI 10.1109/LGRS.2014.2351807
   Dong J, 2015, IEEE T CIRC SYST VID, V25, P1322, DOI 10.1109/TCSVT.2014.2355697
   Everingham M., 2007, The PASCAL Visual Object Classes Chal- lenge (VOC) Results, DOI 10.1007/s11263-009-0275-4
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan JP, 2017, IEEE T IMAGE PROCESS, V26, P1923, DOI 10.1109/TIP.2017.2667405
   Forero PA, 2012, IEEE T SIGNAL PROCES, V60, P4163, DOI 10.1109/TSP.2012.2196696
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25
   Hwang J, 2017, PREDICTIVE CODING BA, DOI [10.2307/253568?ref=search-gateway:8d3451497faea721824565a745fa2fea, DOI 10.2307/253568?REF=SEARCH-GATEWAY:8D3451497FAEA721824565A745FA2FEA]
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu BY, 2013, PROC CVPR IEEE, P843, DOI 10.1109/CVPR.2013.114
   Liu W, SSD SINGLE SHOT MULT, P1, DOI [10.1016/j.nima.2015.05.028, DOI 10.1016/J.NIMA.2015.05.028]
   Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229
   Mordan T, 2019, INT J COMPUT VISION, V127, P1659, DOI 10.1007/s11263-018-1109-z
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roy D, 2018, TREE CNN HIERARCHICA, P1
   Ruan ZW, 2015, IEEE SIGNAL PROC LET, V22, P244, DOI 10.1109/LSP.2014.2349940
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang LM, 2014, IEEE T IMAGE PROCESS, V23, P810, DOI 10.1109/TIP.2013.2295753
   Wu QY, 2016, IEEE T KNOWL DATA EN, V28, P2665, DOI 10.1109/TKDE.2016.2581161
   Wu S, 2020, IEEE T CIRC SYST VID, V30, P2057, DOI 10.1109/TCSVT.2019.2905373
   Xiang Y, 2017, IEEE WINT CONF APPL, P924, DOI 10.1109/WACV.2017.108
   Yan ZC, 2015, IEEE I CONF COMP VIS, P2740, DOI 10.1109/ICCV.2015.314
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Zhu J, 2015, LEARNING DEEP GENERA
NR 33
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6689
EP 6708
DI 10.1007/s11042-019-08285-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900056
DA 2024-07-18
ER

PT J
AU Santos, R
   Abreu, J
   Beça, P
   Rodrigues, A
   Fernandes, S
AF Santos, Rita
   Abreu, Jorge
   Beca, Pedro
   Rodrigues, Ana
   Fernandes, Silvia
TI Voice interaction on TV: analysis of natural language interaction models
   and recommendations for voice user interfaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural language interaction; Interactive TV; Evaluation of interactive
   systems; Usability; Voice user interfaces
AB The goal of this study was to perform an evaluation of a set of voice interaction models (supported by a hands-free solution activated by a wake-up word, a mobile app and a TV remote control with microphone) to identify the most appropriate solution for interactive television. The research addressed issues associated with natural language systems such as usability, interaction and privacy perception, and aimed to analyze the strengths and limitations of the voice interaction models. On a first evaluation approach, a prototype based on a Wizard-of-Oz methodology was used, while a second approach was based on a functional prototype. The preferred interaction model was the hands-free solution activated by a wake-up word because it was easy to use and raised the least difficulties in any task execution. Despite this result, the other two models are not disregarded for a future voice interaction system in television. The TV remote control was the most natural way of interaction for the study's participants. The need for control provided by the remote and by the app makes the participants feel like these grant more privacy. Participants considered that a voice-operated system for TV would be very useful and almost all were receptive to having such a system at home. Lastly, based on commercial standards and guidelines, solutions to issues identified by participants in the visual interface of the TV system were proposed and considered for the next phase of prototype development, also benefiting other researches in the field.
C1 [Santos, Rita; Abreu, Jorge; Beca, Pedro; Rodrigues, Ana; Fernandes, Silvia] Univ Aveiro, Agueda Sch Technol & Management, Digimedia, P-3754909 Agueda, Portugal.
C3 Universidade de Aveiro
RP Santos, R (corresponding author), Univ Aveiro, Agueda Sch Technol & Management, Digimedia, P-3754909 Agueda, Portugal.
EM rita.santos@ua.pt; jfa@ua.pt; pedrobeca@ua.pt; ana.rodrigues@ua.pt;
   silvia.fernandes@ua.pt
RI Beça, Pedro/G-9085-2011; Abreu, Jorge/G-9141-2014; Santos,
   Rita/AAF-1713-2020
OI Beça, Pedro/0000-0001-7332-4901; Abreu, Jorge/0000-0002-0492-2307;
   Santos, Rita/0000-0001-9741-6210; Morais Rodrigues,
   Ana/0000-0001-9485-1727
FU COMPETE 2020 [24498]; Portugal 2020 through the European Regional
   Development Fund (FEDER)
FX This paper is a result of the CHIC - Cooperative Holistic for Internet
   and Content project (grant agreement number 24498), funded by COMPETE
   2020 and Portugal 2020 through the European Regional Development Fund
   (FEDER).
CR Abreu J., 2018, PROC 19 INT C HUM CO
   [Anonymous], 2019, CUSTOM SKILLS
   [Anonymous], 2019, VOICE DESIGN BEST PR
   [Anonymous], 2009, MOBILE DEVICES MOBIL, DOI DOI 10.1145/1613858.1613898
   Archer J, 2013, LG SMART TV VOICE RE
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Bernhaupt R, 2012, SET RECOMMENDATIONS, DOI [10.1145/2325616.2325645, DOI 10.1145/2325616.2325645]
   Bernhaupt R, 2017, USING SPEECH SEARCH
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Cadwalladr C., 2018, REVEALED 50 MILLION
   Corpuz J, 2018, BEST ANDROID REMOTE
   Cutsinger P, 2018, BUILDING VOICE DIFFE
   DECO, 2014, COM TEL POR VOZ MOV
   ELDER HA, 1970, COMMUN ACM, V13, P339, DOI 10.1145/362384.362387
   FURNAS GW, 1987, COMMUN ACM, V30, P964, DOI 10.1145/32206.32212
   Giangola J., 2017, CONVERSATION DESIGN
   Giles, 2017, WHAT WILL TV TOMORRO
   Goto J., 2004, SPOKEN DIALOGUE INTE
   Ismail A, 2018, DIGITAL TRENDS
   Kishore A, 2016, USE SMARTPHONE REMOT
   Mortensen Ditte, 2018, DESIGN VOICE USER IN
   Pasztor D, 2017, SMASHING MAGAZINE
   Pearl C., 2017, Designing voice user interfaces
   Samsung, 2014, VOIC CONTR
   Seifert D, 2018, VERGE
   Spiliotopoulos D, 2009, LECT NOTES COMPUT SC, V5889, P484
   TIVO, 2016, Q4 2016 VID TRENDS R
   Ward N., 2005, DEP TECHNICAL REPORT
   Whitenton K., 2017, Audio Signifiers for Voice Interaction
   Whitenton K., 2017, VOICE 1 FUTURE INTER
   William LidwellK.H., 2003, UNIVERSAL PRINCIPLES
   Yankelovich N, DESIGNING SPEECH ACT
NR 32
TC 2
Z9 2
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35689
EP 35716
DI 10.1007/s11042-020-08710-2
EA FEB 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000516251700004
DA 2024-07-18
ER

PT J
AU Gonzalez-Lozoya, SM
   de la Calleja, J
   Pellegrin, L
   Escalante, HJ
   Medina, MA
   Benitez-Ruiz, A
AF Gonzalez-Lozoya, Sonia M.
   de la Calleja, Jorge
   Pellegrin, Luis
   Escalante, Hugo Jair
   Medina, Ma. Auxilio
   Benitez-Ruiz, Antonio
TI Recognition of facial expressions based on CNN features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Facial micro-expression recognition;
   Convolutional neural networks; Machine learning
ID FACE; DATABASE
AB Facial expressions are a natural way to communicate emotional states and intentions. In recent years, automatic facial expression recognition (FER) has been studied due to its practical importance in many human-behavior analysis tasks such as interviews, autonomous-driving, medical treatment, among others. In this paper we propose a method for facial expression recognition based on features extracted with convolutional neural networks (CNN), taking advantage of a pre-trained model in similar tasks. Unlike other approaches, the proposed FER method learns from mixed instances taken from different databases with the goal of improving generalization, a major issue in machine learning. Experimental results show that the FER method is able to recognize the six universal expressions with an accuracy above 92% considering five of the widely used databases. In addition, we have extended our method to deal with micro-expressions recognition (MER). In this regard, we propose three strategies to create a temporal-aggregated feature vector: mean, standard deviation and early fusion. In this case, the best result is 78.80% accuracy. Furthermore, we present a prototype system that implements the two proposed methods for FER and MER as a tool that allows to analyze videos.
C1 [Gonzalez-Lozoya, Sonia M.; Pellegrin, Luis] UABC, Ensenada, Baja California, Mexico.
   [de la Calleja, Jorge; Medina, Ma. Auxilio; Benitez-Ruiz, Antonio] Univ Politecn Puebla UPPuebla, Puebla, Mexico.
   [Escalante, Hugo Jair] INAOE, Puebla, Mexico.
C3 Universidad Autonoma de Baja California; Instituto Nacional de
   Astrofisica, Optica y Electronica
RP Gonzalez-Lozoya, SM (corresponding author), UABC, Ensenada, Baja California, Mexico.
EM sonia.gonzalez68@uabc.edu.mx; jorge.delacalleja@uppuebla.edu.mx;
   luis.pellegrin@uabc.edu.mx; hugojair@inaoep.mx;
   maria.medina@uppuebla.edu.mx; antonio.benitez@uppuebla.edu.mx
RI Medina Nieto, Maria Auxilio/AAN-4571-2020; Escalante, Hugo
   Jair/AEP-0896-2022
OI Medina Nieto, Maria Auxilio/0000-0001-6391-4799; Escalante, Hugo
   Jair/0000-0003-4603-3513; de la Calleja, Jorge/0000-0002-6846-3162; Luis
   Pellegrin, Luis/0000-0002-4898-1632
FU CONACyT [71150, 214764]; Red tematica en Inteligencia Computacional
   Aplicada (RedICA)
FX This work has been supported by the CONACyT with scholarships No. 71150
   and 214764. The authors also would like to thank sponsor Red tematica en
   Inteligencia Computacional Aplicada (RedICA).
CR Aifanti N., 2010, P 11 INT WORKSH IM A, DOI DOI 10.1371/JOURNAL.PONE.0009715
   Aifanti N, 2014, SIGNAL PROCESS-IMAGE, V29, P177, DOI 10.1016/j.image.2013.10.004
   [Anonymous], P 25 ANN ACM INT C M
   Dhall A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Dhall A, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P509, DOI 10.1145/2522848.2531739
   Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Goodfellow IJ, 2015, NEURAL NETWORKS, V64, P59, DOI 10.1016/j.neunet.2014.09.005
   Hall M., 2009, SIGKDD EXPLORATIONS, V11, P10, DOI [10.1145/1656274.1656278, DOI 10.1145/1656274.1656278]
   Happy SL, 2017, IEEE T AFFECT COMPUT, V8, P131, DOI 10.1109/TAFFC.2015.2498174
   Jain S., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1642, DOI 10.1109/ICCVW.2011.6130446
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Lee K, 2013, I S MOD ANAL SIM COM, P1, DOI 10.1109/MASCOTS.2013.8
   Lee SH, 2014, IEEE T AFFECT COMPUT, V5, P340, DOI 10.1109/TAFFC.2014.2346515
   Li QY, 2019, MULTIMED TOOLS APPL, V78, P29307, DOI 10.1007/s11042-018-6857-9
   Li XB, 2018, IEEE T AFFECT COMPUT, V9, P563, DOI 10.1109/TAFFC.2017.2667642
   Li Xueyi, 2013, ScientificWorldJournal, V2013, P624512, DOI 10.1155/2013/624512
   Littlewort G., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P298, DOI 10.1109/FG.2011.5771414
   Liu M., 2013, Automatic Face and Gesture Recognition (FG), 2013 10th IEEE International Conference and Workshops on, P1, DOI DOI 10.1109/FG.2013.6553734
   Liu MY, 2015, LECT NOTES COMPUT SC, V9006, P143, DOI 10.1007/978-3-319-16817-3_10
   Long J.L., 2014, Advances in neural information processing systems, V27, P1601
   Lucey P., 2010, ieee computer society conference on computer vision and pattern recognition-workshops, P94
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Mayer C., 2014, Pattern Recognition and Image Analysis, V24, P124, DOI 10.1134/S1054661814010106
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Mollahosseini A, 2016, IEEE COMPUT SOC CONF, P1509, DOI 10.1109/CVPRW.2016.188
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Peng M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01745
   Peng XL, 2016, IEEE COMPUT SOC CONF, P1544, DOI 10.1109/CVPRW.2016.192
   Pfister T, 2011, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2011.6126401
   POLIKOVSKY S., 2009, 3 INT C IM CRIM DET, P1, DOI [10.1049/ic.2009.0244, DOI 10.1049/IC.2009.0244]
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sadeghi H, 2019, MULTIMED TOOLS APPL, V78, P30335, DOI 10.1007/s11042-019-07863-z
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Taheri S, 2014, IEEE T IMAGE PROCESS, V23, P3590, DOI 10.1109/TIP.2014.2331141
   Tang Yichuan, 2013, CoRR
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang SJ, 2014, NEURAL PROCESS LETT, V39, P25, DOI 10.1007/s11063-013-9288-7
   WANG X, 2011, P 3 INT C INT MULT C, P124
   Wolf L, 2011, CVPR, DOI DOI 10.1109/CVPR.2011.5995566
   Wu WQ, 2018, INT C PATT RECOG, P1524, DOI 10.1109/ICPR.2018.8545725
   Yan WJ, 2014, NEUROCOMPUTING, V136, P82, DOI 10.1016/j.neucom.2014.01.029
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Yang B, 2018, IEEE ACCESS, V6, P4630, DOI 10.1109/ACCESS.2017.2784096
   Yu ZD, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P435
   Zhang X, 2015, MACH VISION APPL, V26, P467, DOI 10.1007/s00138-015-0677-y
NR 48
TC 32
Z9 34
U1 7
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13987
EP 14007
DI 10.1007/s11042-020-08681-4
EA FEB 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515931100001
DA 2024-07-18
ER

PT J
AU Jayapal, J
   Subban, R
AF Jayapal, J.
   Subban, Ravi
TI Automated lion optimization algorithm assisted Denoising approach with
   multiple filters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image quality enhancement; Noise; Noise removal; Optimization
AB The usage of digital images is growing exponentially yet, it suffers from numerous quality degradations. There are so many reasons for image quality degradations such as camera resolution, lighting conditions, environmental conditions and so on. However, the quality of a digital image is mostly affected by 'noise', which may occur during image acquisition or transmission. Though there are several denoising approaches in the existing literature, most of the denoising works are meant for treating a single type of noise. This work presents a denoising approach, which considers different noises and are treated with multiple adaptive filters under the assistance of the Lion Optimization Algorithm (LOA). The performance of the proposed denoising approach is tested by varying the noise variance against existing approaches. The proposed approach shows better results in terms of PSNR, FSIM and FoM by consuming minimal time with 2149 ms, when compared to the existing approaches.
C1 [Jayapal, J.] Bharathiar Univ, Coimbatore, Tamil Nadu, India.
   [Subban, Ravi] Pondicherry Univ, Dept Comp Sci, Sch Engn & Technol, Pondicherry, India.
C3 Bharathiar University; Pondicherry University
RP Jayapal, J (corresponding author), Bharathiar Univ, Coimbatore, Tamil Nadu, India.
EM jayapal.bu@gmail.com
RI Ravi, S./ABH-2092-2021
CR [Anonymous], 2019, IEEE T MULTIMED
   [Anonymous], INDIAN J COMPUT SCI
   Babers R, 2015, 2015 11TH INTERNATIONAL COMPUTER ENGINEERING CONFERENCE (ICENCO), P217, DOI 10.1109/ICENCO.2015.7416351
   Baloch G, 2018, IEEE SIGNAL PROC LET, V25, P298, DOI 10.1109/LSP.2017.2789018
   Chakraborty D, 2018, IET IMAGE PROCESS, V12, P1150, DOI 10.1049/iet-ipr.2017.0307
   Cheng W, 2018, IEEE T IMAGE PROCESS, V27, P3446, DOI 10.1109/TIP.2018.2820812
   Cho SI, 2018, IEEE T MULTIMEDIA, V20, P1738, DOI 10.1109/TMM.2017.2781371
   Dangeti S, 2003, THESIS
   Diwakar M, 2018, IET IMAGE PROCESS, V12, P708, DOI 10.1049/iet-ipr.2017.0639
   Du B, IEEE J SELECTED TOPI, V11, P1070
   He W, 2018, IEEE J-STARS, V11, P713, DOI 10.1109/JSTARS.2018.2800701
   Huang ZH, 2018, IEEE GEOSCI REMOTE S, V15, P759, DOI 10.1109/LGRS.2018.2796604
   Jayapal J, 2017, INT J INTEL ENG SYST, V11, P142
   Masse A, 2018, IEEE J-STARS, V11, P691, DOI 10.1109/JSTARS.2018.2793537
   MCCOMB K, 1993, P ROY SOC B-BIOL SCI, V252, P59, DOI 10.1098/rspb.1993.0046
   Mohapatra S, 2007, ELE COM ENG, P317
   Panigrahi SK, 2018, IET IMAGE PROCESS, V12, P909, DOI 10.1049/iet-ipr.2017.0825
   SCHALLER GB, 1972, WILDLIFE BEHAV ECOLO
   Wang HY, 2018, IEEE T IMAGE PROCESS, V27, DOI 10.1109/TIP.2017.2781425
   Wang XK, 2018, IET IMAGE PROCESS, V12, P778, DOI 10.1049/iet-ipr.2017.0647
   Xu J, 2018, IEEE T IMAGE PROCESS, V27, P2996, DOI 10.1109/TIP.2018.2811546
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yazdani M, 2016, J COMPUT DES ENG, V3, P24, DOI 10.1016/j.jcde.2015.06.003
   Zhang F, 2018, IET IMAGE PROCESS, V12, P485, DOI 10.1049/iet-ipr.2017.0389
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhao WZ, 2018, IEEE ACCESS, V6, P6303, DOI 10.1109/ACCESS.2017.2780985
   Zhuang L, 2018, IEEE J-STARS, V11, P730, DOI 10.1109/JSTARS.2018.2796570
NR 28
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 4041
EP 4056
DI 10.1007/s11042-019-07803-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700053
DA 2024-07-18
ER

PT J
AU Jercic, P
   Sennersten, C
   Lindley, C
AF Jercic, Petar
   Sennersten, Charlotte
   Lindley, Craig
TI Modeling cognitive load and physiological arousal through pupil diameter
   and heart rate
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Serious games; Physiology; Electrocardiogram; Pupil diameter; Arousal;
   Cognitive load
ID TASK; DILATION; EMOTION; SIZE
AB This study investigates individuals' cognitive load processing abilities while engaged on a decision-making task in serious games, to explore how a substantial cognitive load dominates over the physiological arousal effect on pupil diameter. A serious game was presented to the participants, which displayed the on-line biofeedback based on physiological measurements of arousal. In such dynamic decision-making environment, the pupil diameter was analyzed in relation to the heart rate, to evaluate if the former could be a useful measure of cognitive abilities of individuals. As pupil might reflect both cognitive activity and physiological arousal, the pupillary response will show an arousal effect only when the cognitive demands of the situation are minimal. Evidence shows that in a situation where a substantial level of cognitive activity is required, only that activity will be observable on the pupil diameter, dominating over the physiological arousal effect indicated by the pupillary response. It is suggested that it might be possible to design serious games tailored to the cognitive abilities of an individual player, using the proposed physiological measurements to observe the moment when such dominance occurs.
C1 [Jercic, Petar] Blekinge Inst Technol, Dept Creat Technol, SE-37179 Karlskrona, Sweden.
   [Sennersten, Charlotte] CSIRO Mineral Resources, Technol Court, Pullenvale, Australia.
   [Lindley, Craig] CSIRO, ICT Ctr, Intelligent Sensing & Syst Lab, Hobart, Tas, Australia.
C3 Blekinge Institute Technology; Commonwealth Scientific & Industrial
   Research Organisation (CSIRO); Mineral Resources; Commonwealth
   Scientific & Industrial Research Organisation (CSIRO)
RP Jercic, P (corresponding author), Blekinge Inst Technol, Dept Creat Technol, SE-37179 Karlskrona, Sweden.
EM petar.jercic@bth.se; charlotte.sennersten@csiro.au;
   craig.lindley@csiro.au
RI Jerčić, Petar/AAA-5997-2020
OI Jerčić, Petar/0000-0003-3298-7164; Lindley, Craig/0000-0002-6897-1327
CR Adam MTP, 2015, J RETAILING, V91, P468, DOI 10.1016/j.jretai.2015.01.003
   Al Osman H, 2014, MULTIMED TOOLS APPL, V72, P3143, DOI 10.1007/s11042-013-1590-x
   [Anonymous], 2013, Psychophysiology: Human behavior physiological response
   [Anonymous], ADV METHODS TOOLS EC
   [Anonymous], 2007, TECH REP
   [Anonymous], INT C COMP GAM CGAME
   [Anonymous], 51 ANN M SOC PSYCH R
   [Anonymous], ECIS 2012 P
   Astor PJ, 2013, J MANAGE INFORM SYST, V30, P247, DOI 10.2753/MIS0742-1222300309
   Benikos N, 2013, INT J PSYCHOPHYSIOL, V87, P262, DOI 10.1016/j.ijpsycho.2012.08.005
   Berntson GG, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P182, DOI 10.1017/CBO9780511546396.008
   Boutcher YN, 2006, BIOL PSYCHOL, V73, P235, DOI 10.1016/j.biopsycho.2006.04.005
   Bradley MM, 2008, PSYCHOPHYSIOLOGY, V45, P602, DOI 10.1111/j.1469-8986.2008.00654.x
   Bradley MM, 2001, EMOTION, V1, P276, DOI 10.1037//1528-3542.1.3.276
   Charles D., 2004, P INT C COMPUTER GAM, P29
   Charles D., 2005, P DIGRA 2005 C CHANG, DOI 10.4135/9781446211397.n5
   Cohen J., 1988, STAT POWER ANAL BEHA
   Cohen R.A., 2011, Encyclopedia of Clinical Neuropsychology, P2737, DOI DOI 10.1007/978-0-387-79948-31340
   Granholm E, 2004, INT J PSYCHOPHYSIOL, V52, P1, DOI 10.1016/j.ijpsycho.2003.12.001
   Guardini P, 2013, GAME ANAL, P325, DOI DOI 10.1007/978-1-4471-4769-5_16
   Hamilton P, 2002, COMPUT CARDIOL, V29, P101, DOI 10.1109/CIC.2002.1166717
   HESS EH, 1964, SCIENCE, V143, P1190, DOI 10.1126/science.143.3611.1190
   Hu YX, 2015, J RISK RES, V18, P637, DOI 10.1080/13669877.2014.910688
   Hung JCS, 2017, MULTIMED TOOLS APPL, V76, P18361, DOI 10.1007/s11042-016-4101-z
   KAHNEMAN D, 1966, SCIENCE, V154, P1583, DOI 10.1126/science.154.3756.1583
   Laeng B, 2012, PERSPECT PSYCHOL SCI, V7, P18, DOI 10.1177/1745691611427305
   LANG PJ, 1993, PSYCHOPHYSIOLOGY, V30, P261, DOI 10.1111/j.1469-8986.1993.tb03352.x
   Léger PM, 2011, J INF TECHNOL EDUC-R, V10, P39
   LOWENSTEIN O, 1955, NEUROLOGY, V5, P631, DOI 10.1212/WNL.5.9.631
   McAllister G., 2013, Game analytics: Maximizing the value of player data, P621, DOI [10.1007/978-1-4471-4769-5_27, DOI 10.1007/978-1-4471-4769-5_27]
   Moresi S, 2008, INT J PSYCHOPHYSIOL, V67, P124, DOI 10.1016/j.ijpsycho.2007.10.011
   Partala T, 2003, INT J HUM-COMPUT ST, V59, P185, DOI 10.1016/S1071-5819(03)00017-X
   Pehlivanoglu D, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00253
   Porges SW, 2007, BIOL PSYCHOL, V74, P116, DOI 10.1016/j.biopsycho.2006.06.009
   Posner J, 2005, DEV PSYCHOPATHOL, V17, P715, DOI 10.1017/S0954579405050340
   Rani P, 2007, ADV ENG INFORM, V21, P323, DOI 10.1016/j.aei.2006.11.009
   Recarte MA, 2003, J EXP PSYCHOL-APPL, V9, P119, DOI 10.1037/1076-898X.9.2.119
   Sennersten CC, 2009, PROCEEDINGS OF THE IEEE VIRTUAL WORLDS FOR SERIOUS APPLICATIONS, P68, DOI 10.1109/VS-GAMES.2009.25
   Sosnowski T, 2004, PSYCHOPHYSIOLOGY, V41, P467, DOI 10.1111/j.1469-8986.2004.00171.x
   STANNERS R F, 1979, Motivation and Emotion, V3, P319, DOI 10.1007/BF00994048
   Steinhauer SR, 2004, INT J PSYCHOPHYSIOL, V52, P77, DOI 10.1016/j.ijpsycho.2003.12.005
   Su CH, 2016, MULTIMED TOOLS APPL, V75, P10013, DOI 10.1007/s11042-015-2799-7
   Tychsen A., 2008, Comput. Entertain, V5, P1, DOI [10.1145/1324198.1324208, DOI 10.1145/1324198.1324208]
   Xu Ya, 2010, Journal of Electronics (China), V27, P8, DOI 10.1007/s11767-009-0094-3
NR 44
TC 24
Z9 29
U1 4
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3145
EP 3159
DI 10.1007/s11042-018-6518-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700006
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Mubarakali, A
   Ashwin, M
   Mavaluru, D
   Kumar, AD
AF Mubarakali, Azath
   Ashwin, M.
   Mavaluru, Dinesh
   Kumar, A. Dinesh
TI Design an attribute based health record protection algorithm for
   healthcare services in cloud environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Privacy-preserving; Cloud computing; E-health reports and analysis;
   Attribute-based health record protection algorithm; Patient health
   record (PHR)
AB Nowadays, personal health records (PHR) has built as a platform for health care data trading. The realistic deployment of PHR in distributed computing infrastructure raises the protection and data security hazards that need to be addressed. However, there have been broad security concerns as personal health data. It could be raised for external servers and treated as unauthenticated cloud servers. The large amount of clients and data owners in the PHR framework who have possibly heavy computational and administration load on the elements in the framework; which will restrict the PHR information accessibility and usability. To find a better solution of above issues, Attribute-based Health Record Protection (AHRP) algorithm is introduced to offer information access control confidentiality, credibility, and secrecy. It is provision of access control to encrypt the information, and a privilege mode for authenticating a message without uncovering the personal information of the patient. Based on Experimental evaluations, proposed Attribute based Health Record Protection Algorithm reduces 0.364 ET (encryption time) in seconds, 0.188 DT (Decryption Time) in seconds for respective records compared than existing methodologies.
C1 [Mubarakali, Azath] King Khalid Univ, Coll Comp Sci, Dept CNE, Abha, Saudi Arabia.
   [Ashwin, M.] Koneni Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Andra Prdesh, India.
   [Mavaluru, Dinesh] Saudi Elect Univ, Coll Comp & Informat, Abha, Saudi Arabia.
   [Kumar, A. Dinesh] Konen Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Andra Prdesh, India.
C3 King Khalid University; Saudi Electronic University; Koneru Lakshmaiah
   Education Foundation (K L Deemed to be University)
RP Mubarakali, A (corresponding author), King Khalid Univ, Coll Comp Sci, Dept CNE, Abha, Saudi Arabia.
EM mailmeazath@gmail.com; mailmeashwin@gmail.com; d.mavaluru@seu.edu.sa;
   adinesh@kluniversity.in
RI Mavaluru, Dinesh/D-5110-2016; MUBARAKALI, AZATH M/A-4543-2019; M,
   Ashwin/U-7630-2018; Anguraj, Dinesh Kumar/S-3163-2018
OI Mavaluru, Dinesh/0000-0001-5424-9600; MUBARAKALI, AZATH
   M/0000-0001-9939-1790; M, Ashwin/0000-0003-0994-8837; Anguraj, Dinesh
   Kumar/0000-0003-2008-6828
CR Duncan B, 2014, INT CONF CLOUD COMP, P805, DOI 10.1109/CloudCom.2014.165
   Duncan B, 2013, INT CONF CLOUD COMP, P120, DOI 10.1109/CloudCom.2013.144
   Fern'ndez G., 2012, 2012 Sixth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing (IMIS 2012), P927, DOI 10.1109/IMIS.2012.32
   Fernández-Cardeñosa G, 2012, J MED SYST, V36, P3777, DOI 10.1007/s10916-012-9850-2
   Ioannidis C., 2014, RN, V14, P15
   Low C, 2012, J MED SYST, V36, P3543, DOI 10.1007/s10916-012-9829-z
   Monikandan S, 2014, INT J ENG RES TECHNO, V3, P1053
   Motwani P, 2016, INT J COMPUTER SCI I, V7, P1417
   Poulymenopoulou M, 2012, J MED SYST, V36, P3233, DOI 10.1007/s10916-011-9814-y
   Praveen J., 2016, INDIAN J SCI TECHNOL, V9, DOI [10.17485/ijst/2016/v9i44/91477, DOI 10.17485/ijst/2016/v9i16/92203]
   Ruebsamen T, 2013, INT CONF CLOUD COMP, P185, DOI 10.1109/CloudCom.2013.32
   Thorpe Sean, 2013, 2013 IEEE Ninth World Congress on Services (SERVICES), P75, DOI 10.1109/SERVICES.2013.76
   Wu D, 2010, INT CONF COMP SCI, P268, DOI 10.1109/ICCSIT.2010.5563744
NR 13
TC 13
Z9 13
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3943
EP 3956
DI 10.1007/s11042-019-7494-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700047
DA 2024-07-18
ER

PT J
AU Chen, HY
   Du, JH
   Zhang, WN
   Li, BH
AF Chen, Haiyan
   Du, Jinghan
   Zhang, Weining
   Li, Bohan
TI An iterative end point fitting based trend segmentation representation
   of time series and its distance measure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Time series representation; Trend segmentation; Iterative end point
   fitting algorithm; Distance measure
ID APPROXIMATION
AB Symbolic approximation representation is a key problem in time series which can significantly affect the accuracy and efficiency of data mining. However, since currently used methods divide the original sequence into segments with equal size, they ignore one of the most important features of time series: the trend. To overcome the defect of equal-sized segmenting, we present a trend segmentation representation based on Iterative End Point Fitting algorithm (IEPF-TSR). Particularly, we use iterative end point fitting (IEPF) algorithm to search the break point of each segment and get the trend segmentation. Then a triplet based symbolic representation is proposed for each segment which includes the start point, mean and trend. Moreover, we define a new distance measure method based on trend segmentation representation (TSR-DIST) which can suit for two representations with different lengths, and prove it to be the lower bound of Euclidean distance. The experimental results on UCR datasets show that the proposed representation and distance measure achieve better performance than the state-of-the-art methods in the classification accuracy and the dimensionality reduction ratio.
C1 [Chen, Haiyan; Li, Bohan] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Peoples R China.
   [Du, Jinghan; Zhang, Weining] Nanjing Univ Aeronaut & Astronaut, Coll Civil Aviat, Nanjing 211106, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Nanjing University of
   Aeronautics & Astronautics
RP Chen, HY (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Peoples R China.
EM chenhaiyan@nuaa.edu.cn
RI Chen, Haiyan/HGB-6216-2022; Li, Chun/KBC-9591-2024; Li,
   Bohan/GRR-3628-2022
OI Li, Bohan/0000-0001-7686-8605
FU Fundamental Research Funds for the Central Universities [NS2019054]
FX The authors thank the anonymous reviewers for their valuable comments
   and suggestions. This work is partially supported by the Fundamental
   Research Funds for the Central Universities (NS2019054).
CR Baydogan MG, 2016, DATA MIN KNOWL DISC, V30, P476, DOI 10.1007/s10618-015-0425-y
   Castillo R.G., 2015, 2015 12th International Conference on Electrical Engineering, Computing Science and Automatic Control (CCE), IEEE, P1, DOI DOI 10.1109/ICEEE.2015.7357932
   Castillo-Ortega R, 2014, IEEE INT FUZZY SYST, P489, DOI 10.1109/FUZZ-IEEE.2014.6891840
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Ding H, 2008, PROC VLDB ENDOW, V1, P1542
   Esling P, 2012, ACM COMPUT SURV, V45, DOI 10.1145/2379776.2379788
   Fu TC, 2011, ENG APPL ARTIF INTEL, V24, P164, DOI 10.1016/j.engappai.2010.09.007
   Fuad Muhammad Marwan Muhammad, 2012, Data Warehousing and Knowledge Discovery. Proceedings of the 14th International Conference, DaWaK 2012, P105, DOI 10.1007/978-3-642-32584-7_9
   Guo CH, 2010, LECT NOTES ARTIF INT, V6291, P234, DOI 10.1007/978-3-642-15280-1_23
   Jones M, 2016, DATA MIN KNOWL DISC, V30, P1427, DOI 10.1007/s10618-015-0449-3
   Keogh E., 2001, Knowledge and Information Systems, V3, P263, DOI 10.1007/PL00011669
   Keogh E., 2001, SDM
   Keogh E., 2006, The UCR Time Series Classification/Clustering Homepage
   Kontaki M, 2005, LECT NOTES COMPUT SC, V3631, P294, DOI 10.1007/11547686_22
   Kontaki M, 2008, LECT NOTES COMPUT SC, V5182, P251, DOI 10.1007/978-3-540-85836-2_24
   Lange M, 2016, INT JOINT C SOCO 16, P584
   Li DY, 2016, INT J SOFTW ENG KNOW, V26, P1361, DOI 10.1142/S0218194016400088
   Li H, 2016, PHYSICA A, V468
   Li HL, 2011, EXPERT SYST APPL, V38, P14732, DOI 10.1016/j.eswa.2011.05.007
   Lin J., 2003, 8THACM SIGMOD WORKSH, DOI [10.1145/882082. 882086, DOI 10.1145/882082.882086]
   Lkhagva B., 2006, DEWS2006 4A I8, P7
   Luo MN, 2018, IEEE T CYBERNETICS, V48, P648, DOI 10.1109/TCYB.2017.2647904
   Malinowski S, 2013, LECT NOTES COMPUT SC, V8207, P273, DOI 10.1007/978-3-642-41398-8_24
   Ramer U., 1972, Comput. Graph. Image Process., V1, P244, DOI DOI 10.1016/S0146-664X(72)80017-0
   Samiee K, 2015, IEEE T BIO-MED ENG, V62, P541, DOI 10.1109/TBME.2014.2360101
   Senin P, 2016, PHYS REV LETT, V93
   Sun YQ, 2014, NEUROCOMPUTING, V138, P189, DOI 10.1016/j.neucom.2014.01.045
   Zan C.T., 2016, PROC 18 INT C INF IN, P72, DOI [10.1145/3011141.3011146, DOI 10.1145/3011141.3011146]
NR 28
TC 4
Z9 4
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13481
EP 13499
DI 10.1007/s11042-019-08440-0
EA JAN 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000510281800001
DA 2024-07-18
ER

PT J
AU Zhang, LL
   Zhao, MH
   Zhao, DZ
AF Zhang, Lingling
   Zhao, Minghui
   Zhao, Daozhen
TI Bipartite graph link prediction method with homogeneous nodes similarity
   for music recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music recommendation; Bipartite graph; Link prediction; Node similarity
ID SYSTEM; EMOTION
AB Through analyzing users' listening records, personalized music recommendation can not only help users find interesting music, but also help related enterprises improve user loyalty. This paper proposes an improved music recommendation method based on bipartite graph link prediction with homogeneous nodes similarity. Firstly, users' music preference relations are expressed as positive and negative binary preference relations by the Complex Representation-based Link Prediction (CORLP) method, which improves the limitation of traditional recommendation method that can only represent unary preference relations. Secondly, the new method improves the CORLP method by attribute extraction and similarity calculation of homogeneous nodes including user nodes and music nodes. Thirdly, a new dataset based on the practical data from Shrimp Music Community is collected for facilitating the music recommendation task. The first-class music genres and second-class music genres of users are extracted by web crawling technology to calculate the similarity between user nodes. The rhythm and tempo are extracted by open source software to calculate the similarity between music nodes. Finally, the Top-N experiment is used to prove the performance of the proposed method compared with CORLP. In addition, the results reveal several new findings. Firstly, performance is significantly improved when the homogeneous nodes similarity is taken into account. Secondly, recommendation method with user nodes similarity shows a better performance compared with recommendation method with music nodes similarity.
C1 [Zhang, Lingling; Zhao, Minghui; Zhao, Daozhen] Univ Chinese Acad Sci, Sch Econ & Management, Beijing 100190, Peoples R China.
   [Zhang, Lingling] Chinese Acad Sci, Res Ctr Fictitious Econ & Data Sci, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences
RP Zhang, LL (corresponding author), Univ Chinese Acad Sci, Sch Econ & Management, Beijing 100190, Peoples R China.; Zhang, LL (corresponding author), Chinese Acad Sci, Res Ctr Fictitious Econ & Data Sci, Beijing 100190, Peoples R China.
EM zhangll@ucas.ac.cn; zhaominghui1993@foxmail.com; zdz_86@126.com
RI zhang, lingling/HDM-2189-2022
OI zhang, ling ling/0000-0003-1405-0992
FU National Natural Science Foundation of China [91546201, 71471169,
   71071151]
FX This work is supported by National Natural Science Foundation of China
   (Grant No. 91546201, 71471169 and 71071151). The authors are very
   grateful for the valuable comments and suggestions from anonymous
   reviewers and editor of the journal, which significantly improved the
   quality of the paper.
CR Åman P, 2017, INT J HUM-COMPUT INT, V33, P165, DOI 10.1080/10447318.2016.1225881
   Andjelkovic I., 2016, UMAP 2016-Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization, P275, DOI DOI 10.1145/2930238.2930280
   Celma O, 2010, MUSIC RECOMMENDATION AND DISCOVERY, P43, DOI 10.1007/978-3-642-13287-2_3
   Chang HY, 2017, MULTIMED TOOLS APPL, V76, P19523, DOI 10.1007/s11042-015-3202-4
   Chen JP, 2019, MULTIMED TOOLS APPL, V78, P2667, DOI 10.1007/s11042-018-5745-7
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Deng SG, 2015, EXPERT SYST APPL, V42, P9284, DOI 10.1016/j.eswa.2015.08.029
   Dias R, 2013, PROC INT C TOOLS ART, P783, DOI 10.1109/ICTAI.2013.120
   Dolatkia I, 2016, 2016 SECOND INTERNATIONAL CONFERENCE ON WEB RESEARCH (ICWR), P108, DOI 10.1109/ICWR.2016.7498454
   Flexer A, 2018, J NEW MUSIC RES, V47, P17, DOI 10.1080/09298215.2017.1354891
   Gong NZ, 2014, ACM T INTEL SYST TEC, V5, DOI 10.1145/2594455
   Gossi D, 2016, STUD COMPUT INTELL, V644, P301, DOI 10.1007/978-3-319-30569-1_23
   Guo C, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16), P715, DOI 10.1145/2835776.2855088
   Katarya R, 2018, MULTIMED TOOLS APPL, V77, P2673, DOI 10.1007/s11042-017-4447-x
   Li YL, 2017, EUR J OPER RES, V260, P693, DOI 10.1016/j.ejor.2016.12.041
   Lichtenwalter RN, 2011, J MACH LEARN RES, V12, P2489
   Lin KH, 2016, INT CONF SOFTW ENG, P229, DOI 10.1109/ICSESS.2016.7883055
   Lin QK, 2018, IEEE ACCESS, V6, P58990, DOI 10.1109/ACCESS.2018.2874959
   Mao K, 2016, SIGNAL PROCESS, V120, P806, DOI 10.1016/j.sigpro.2015.03.026
   Melville P., 2017, Encyclopedia of Machine Learning and Data Mining, P1056, DOI DOI 10.1007/978-1-4899-7687-1_964
   Oramas S, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2926718
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Sánchez-Moreno D, 2016, EXPERT SYST APPL, V66, P234, DOI 10.1016/j.eswa.2016.09.019
   Schedl M, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P103, DOI 10.1145/2911996.2912004
   Sunitha M, 2018, LECT NOTE DATA ENG, V3, P267, DOI 10.1007/978-981-10-4585-1_22
   Wang DJ, 2018, INFORM RETRIEVAL J, V21, P230, DOI 10.1007/s10791-017-9317-7
   Wang H, 2017, IEEE T KNOWL DATA EN, V29, P2263, DOI 10.1109/TKDE.2017.2728527
   Xie F, 2015, KNOWL-BASED SYST, V81, P148, DOI 10.1016/j.knosys.2015.02.013
   Yan Y, 2015, COMM COM INF SC, V568, P233, DOI 10.1007/978-981-10-0080-5_23
   Yang J, 2016, LECT NOTES COMPUT SC, V9747, P110, DOI 10.1007/978-3-319-40355-7_11
   Zhu Yu-xiao, 2012, Journal of University of Electronic Science and Technology of China, V41, P163, DOI 10.3969/j.issn.1001-0548.2012.02.001
NR 31
TC 8
Z9 9
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13197
EP 13215
DI 10.1007/s11042-019-08451-x
EA JAN 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515728500002
DA 2024-07-18
ER

PT J
AU Hao, FC
   Chang, X
   Yang, GP
   Yang, L
   Li, CD
   Li, CL
   Xia, CL
AF Hao Fanchang
   Chang Xu
   Yang Gongping
   Yang Lu
   Li Chengdong
   Li Chenglong
   Xia Chuanliang
TI Local image quality measurement for multi-scale forensic palmprints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Forensic palmprint; Image quality; Measurement; Convolutional neural
   networks; Supervised classification
ID CONVOLUTIONAL NEURAL-NETWORKS; CLASSIFICATION
AB Numerous studies show that palmprint image quality has a significant effect on every stage of a palmprint recognition system. Although some palmprint image quality measurement(PIQM) methods are proposed, some insufficiency in classification accuracy occurs and attention to detail in measuring local area image quality of multi-scale palmprint images is lacking. On the one hand, the classification accuracy is not very high for 2-class classification and it degrades significantly as the number of classes increases. On the other hand, local area image quality measurement of multi-scale palmprint images has not yet been resolved since the handcrafted features designed through domain knowledge usually works for certain scale image blocks. Meanwhile, the intricate domain knowledge used in the previous methods is difficult for some common users to acquire. In this paper, we propose an end-to-end deep-learning method of strengthening representation ability that learns more abstract, essential, and reliable features to measure the local image quality for multi-scale forensic palmprints. Popular convolutional neural networks (CNNs) are considered because of their powerful representation ability in learning complex features. However, the powerful existing CNNs usually have complex architectures with a large amount of parameters, which need the support of high-performance computers. They are not suitable to be used directly for palmprint image quality assignment and the follow-up palmprint recognition work, which prefers real-time response on commonly available personal computers or even mobile devices. Hence, a new lightweight CNN must be designed to achieve a trade-off between high classification accuracy and practical usability. Considering the attributes of under-processed input images, we reduce the weight of the CNN architecture by reducing the amount of some parameters, and finally a lightweight CNN is designed. As a result, a raw rectangular palmprint image of variable size can be put into the trained model directly and a quality label quickly predicted with high accuracy. After comparison with previous methods, results show that the proposed method can deal with un-pre-processed raw images of a multi-scale input size. Furthermore, it can acquire a richer amount of quality classes with a higher accuracy, which are stable on many different datasets. It also leads to finer and more precise full palmprint image quality maps when compared to previous methods.
C1 [Hao Fanchang; Li Chenglong; Xia Chuanliang] Shandong Jianzhu Univ, Sch Comp Sci & Technol, Jinan 250101, Peoples R China.
   [Chang Xu] Shandong Univ Polit Sci & Law, Sch Cybersecur, Jinan 250014, Peoples R China.
   [Chang Xu] Shandong Univ Polit Sci & Law, Evidence Forens Lab Univ Shandong Prov, Jinan 250014, Peoples R China.
   [Yang Gongping] Shandong Univ, Sch Software, Jinan 250101, Peoples R China.
   [Yang Lu] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Peoples R China.
   [Li Chengdong] Shandong Jianzhu Univ, Sch Informat & Elect Engn, Jinan 250101, Peoples R China.
C3 Shandong Jianzhu University; Shandong University of Political Science
   and Law; Shandong University of Political Science and Law; Shandong
   University; Shandong University of Finance & Economics; Shandong Jianzhu
   University
RP Hao, FC (corresponding author), Shandong Jianzhu Univ, Sch Comp Sci & Technol, Jinan 250101, Peoples R China.
EM haofanchang18@sdjzu.edu.cn
RI Yang, Gongping/B-9923-2012
OI Yang, Gongping/0000-0001-7637-2749; Hao, Fanchang/0000-0003-1820-3490
FU National Natural Science Foundation of China [61503220, 61573219,
   61672328, 61703235]; Taishan Scholar Project of Shandong Province
   [TSQN201812092]; Key Research and Development Project of Shandong
   Province [2018GGX101032, 2019GGX101068]; Projects of Shandong Province
   Higher Educational Science and Technology Program [J17KB182, J18KA357];
   Shandong Jianzhu University [XNBS1810, XNBS1811]
FX This work is supported in part by the National Natural Science
   Foundation of China under Grant 61503220, 61573219, 61672328 and
   61703235. It is also supported by the Taishan Scholar Project of
   Shandong Province under Grant TSQN201812092, the Key Research and
   Development Project of Shandong Province under Grant 2018GGX101032,
   2019GGX101068, the Projects of Shandong Province Higher Educational
   Science and Technology Program under Grant J17KB182 and J18KA357, and
   the Doctoral Fund of Shandong Jianzhu University under Grant XNBS1810
   and XNBS1811.
CR Aberni Y, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P793, DOI 10.1109/TSP.2017.8076097
   Medina-Pérez MA, 2016, NEUROCOMPUTING, V175, P851, DOI 10.1016/j.neucom.2015.05.130
   [Anonymous], CoRR abs/1511.07122
   Barros RM, 2013, SCI JUSTICE, V53, P402, DOI 10.1016/j.scijus.2013.08.002
   Bianco S, 2018, SIGNAL IMAGE VIDEO P, V12, P355, DOI 10.1007/s11760-017-1166-8
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Cappelli R, 2011, IEEE T PATTERN ANAL, V33, P1051, DOI 10.1109/TPAMI.2010.228
   Cappelli R, 2010, IEEE T PATTERN ANAL, V32, P2128, DOI 10.1109/TPAMI.2010.52
   Chen GB, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102580
   Dai JF, 2012, IEEE T PATTERN ANAL, V34, P1618, DOI 10.1109/TPAMI.2011.237
   Dai JF, 2011, IEEE T PATTERN ANAL, V33, P945, DOI 10.1109/TPAMI.2010.164
   El-Sawy A, 2017, ADV INTELL SYST COMP, V533, P566, DOI 10.1007/978-3-319-48308-5_54
   FERRARA M, 2014, P 13 INT C BIOM SPEC, V230, P171
   Ferrara M, 2012, IEEE T INF FOREN SEC, V7, P1727, DOI 10.1109/TIFS.2012.2215326
   Fong CM, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102593
   Gao F, 2017, NEUROCOMPUTING, V257, P104, DOI 10.1016/j.neucom.2017.01.054
   Gu K, 2016, IEEE T CYBERNETICS, V46, P284, DOI 10.1109/TCYB.2015.2401732
   Hao FC, 2018, IEEE ACCESS, V6, P62076, DOI 10.1109/ACCESS.2018.2876406
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G. E., 2012, 12070580 ARXIV
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Jain AK, 2011, IEEE T PATTERN ANAL, V33, P88, DOI 10.1109/TPAMI.2010.59
   Jain AK, 2009, IEEE T PATTERN ANAL, V31, P1032, DOI 10.1109/TPAMI.2008.242
   Jia S, 2017, IEEE IMAGE PROC, P765, DOI 10.1109/ICIP.2017.8296384
   Kang L, 2014, IEEE IMAGE PROC, P2570, DOI 10.1109/ICIP.2014.7025520
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   KIM J, 2017, 2017 IEEE C COMP VIS
   Kim J, 2017, IEEE SIGNAL PROC MAG, V34, P130, DOI 10.1109/MSP.2017.2736018
   Kong A, 2009, PATTERN RECOGN, V42, P1408, DOI 10.1016/j.patcog.2009.01.018
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liang YD, 2016, LECT NOTES COMPUT SC, V9909, P3, DOI 10.1007/978-3-319-46454-1_1
   Lim HT, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6737, DOI 10.1109/ICASSP.2018.8461317
   Lin KY, 2018, PROC CVPR IEEE, P732, DOI 10.1109/CVPR.2018.00083
   Lin Kwan-Yee, 2018, BMVC, P70
   Liu EY, 2013, IEEE T PATTERN ANAL, V35, P2307, DOI 10.1109/TPAMI.2013.39
   Liu XL, 2017, IEEE I CONF COMP VIS, P1040, DOI 10.1109/ICCV.2017.118
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Mocanu DC, 2014, IEEE IMAGE PROC, P758, DOI 10.1109/ICIP.2014.7025152
   Morales A., 2014, Biometrics, P1, DOI DOI 10.1109/BTAS.2014.6996268
   PALANCAR JH, 2014, IJPRAI, V28
   Peralta D, 2018, INT J INTELL SYST, V33, P213, DOI 10.1002/int.21948
   Rajanna U, 2010, PATTERN ANAL APPL, V13, P263, DOI 10.1007/s10044-009-0160-3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun Y., 2015, ARXIV150200873
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Verdun FR, 2015, PHYS MEDICA, V31, P823, DOI 10.1016/j.ejmp.2015.08.007
   Yan J, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS (MFI), P342, DOI 10.1109/MFI.2017.8170452
   Yan Zheng, 2007, 2007 14th International Workshop in Systems, Signals and Image Processing and 6th EURASIP Conference focused on Speech and Image Processing, Multimedia Communications and Services - EC-SIPMCS 2007, P140
   Yang L, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.2.027003
   Yang SJ, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2087-4
   Yue Feng, 2010, Acta Automatica Sinica, V36, P353, DOI 10.3724/SP.J.1004.2010.00353
   Zago GT, 2018, COMPUT BIOL MED, V103, P64, DOI 10.1016/j.compbiomed.2018.10.004
NR 54
TC 3
Z9 4
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 12915
EP 12938
DI 10.1007/s11042-020-08625-y
EA JAN 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000509165900003
DA 2024-07-18
ER

PT J
AU Du, YY
AF Du, Yueyun
TI An anomaly detection method using deep convolution neural network for
   vision image of robot
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Convolutional neural network (CNN); Wireless visual
   sensing network (WVSN); Vision image of robot; Slow feature analysis
   (SFA); Region of interest (ROI); Support vector machine (SVM)
AB With the acceleration of urbanization, growing number of places are crowded with people, such as banks, shopping malls, schools and hospitals, and the incidence of abnormal events such as assault, fighting, trampling and evacuation is also increasing. Therefore, the need for intelligent detection and identification of abnormal events by security early warning robots is attracting much more attention. Aiming at the problem of anomaly detection for security early warning robots, an anomaly detection method using wireless vision sensor network (WVSN) and deep learning is proposed. Firstly, image collection is carried out by WVSN, and video image information in the monitoring range is transmitted and stored by WVSN. Then, the collected image is preprocessed, and the possible abnormal areas are effectively extracted by region of interest (ROI), image filtering and region segmentation. Finally, the abnormal areas are extracted by WVSN. The slow feature analysis (SFA) is used to solve the problem of insufficient training samples in the deep neural network. Furthermore, the deep convolution neural network (CNN) and the support vector machine (SVM) are used to train and complete the classification respectively. The experimental results on UMN and PETS 2009 database show that the abnormal events can be effectively detected by the proposed method. Compared with several other advanced methods, the proposed method has higher detection accuracy and area under the curve (AUC). Among them, AUC on the experimental data set can reach up to 0.998. Therefore, the proposed method has a good reference value for the application of security early warning robots in densely populated places.
C1 [Du, Yueyun] Shangqiu Vocat & Tech Coll, Dept Comp, Shangqiu 476000, Henan, Peoples R China.
RP Du, YY (corresponding author), Shangqiu Vocat & Tech Coll, Dept Comp, Shangqiu 476000, Henan, Peoples R China.
EM 2585150252@qq.com
FU Special projects of R AMP; D and promotion of Henan Provincial Science
   and Technology Department [182102210480]
FX This work was supported by the Special projects of R & D and promotion
   of Henan Provincial Science and Technology Department (No.
   182102210480).
CR Alatorre G, 2015, INT CONF NETW SER, P187, DOI 10.1109/CNSM.2015.7367358
   Aurangzeb K, 2018, IEEE ACCESS, V6, P16932, DOI 10.1109/ACCESS.2018.2816162
   Hëussermann K, 2015, J INTELL ROBOT SYST, V77, P361, DOI 10.1007/s10846-013-0014-5
   Hao T, 2018, MULTIMED TOOLS APPL, V77, P3623, DOI 10.1007/s11042-017-5218-4
   Ji QG, 2018, IET IMAGE PROCESS, V12, P133, DOI 10.1049/iet-ipr.2016.0044
   Khalid A, 2018, COMPUT IND, V97, P132, DOI 10.1016/j.compind.2018.02.009
   Kim K, 2017, J SUPERCOMPUT, V73, P1140, DOI 10.1007/s11227-016-1855-z
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Li YT, 2019, MULTIMED TOOLS APPL, V78, P17973, DOI 10.1007/s11042-018-7122-y
   Park D, 2016, IEEE INT CONF ROBOT, P407, DOI 10.1109/ICRA.2016.7487160
   Ruiz-Barradas A, 2018, TELLUS A, V70, P1, DOI 10.1080/16000870.2018.1481688
   Shi Z, 2019, MULTIMED TOOLS APPL, V78, P1
   SILLITO, 2008, P BMVC, V31, P1035
   Sun MJ, 2018, MULTIMED TOOLS APPL, V77, P29231, DOI 10.1007/s11042-018-5793-z
   Verma VS, 2019, MULTIMED TOOLS APPL, V78, P23203, DOI 10.1007/s11042-019-7599-z
   Wang GY, 2016, INT CONF CLOUD COMPU, P476, DOI 10.1109/CCIS.2016.7790305
   Xia KJ, 2019, IEEE ACCESS, V7, P96349, DOI 10.1109/ACCESS.2019.2929270
   Yu R, 2015, ACM T KNOWL DISCOV D, V10, DOI 10.1145/2811268
   Zhang J, 2019, J MOD POWER SYST CLE, V7, P948, DOI 10.1007/s40565-019-0498-5
   Zhang YH, 2015, IEEE T CIRC SYST VID, V25, P1231, DOI 10.1109/TCSVT.2014.2355711
   Zhao MM, 2017, IEEE GEOSCI REMOTE S, V14, P174, DOI 10.1109/LGRS.2016.2633426
   Zhou SF, 2016, SIGNAL PROCESS-IMAGE, V47, P358, DOI 10.1016/j.image.2016.06.007
NR 22
TC 3
Z9 3
U1 2
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9629
EP 9642
DI 10.1007/s11042-020-08684-1
EA JAN 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000508714800001
DA 2024-07-18
ER

PT J
AU Gutub, A
   Al-Ghamdi, M
AF Gutub, Adnan
   Al-Ghamdi, Maimoona
TI Hiding shares by multimedia image steganography for optimized
   counting-based secret sharing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Counting-based secret sharing; Image-based steganography; Information
   security; Key management; Key distribution; Secret reconstruction;
   Shares distribution; Shares generation
ID AUTHENTICATION
AB The secret sharing scheme is a data security tool that provides reliability and robustness for multi-user authentication systems. This work focus on improving the counting-based secret sharing technique for higher shares security as well as simple and fast computation. The research considers resolving some originally published defects in the shares reconstruction phase by proposing a new distribution model. This distribution model has been optimized practical and efficient. Also, the shares reconstruction model reflects increasing the security of the system by shares authenticity via steganography. We have employed multimedia image-based steganography methods to store the optimized shares that is presenting comparisons for proofed remarks. The paper experimentations tests the work of the enhancements by assuming different secret sharing key sizes of 64-bit, 128-bit, and 256-bit to make sure of practical variations within the security study. The shares usability has been further optimized by testing embedding each generated share using five different techniques of image-based steganography. The results showed a significant attractive impact making the optimized counting-based secret sharing scheme considered a promising solution for multi-user authentication security applications. This optimized system has been analyzed according to the distortion security and capacity parameters showing attractive contributions opening the research direction for further research to come.
C1 [Gutub, Adnan; Al-Ghamdi, Maimoona] Umm Al Qura Univ, Comp Engn Dept, Mecca, Saudi Arabia.
C3 Umm Al Qura University
RP Gutub, A (corresponding author), Umm Al Qura Univ, Comp Engn Dept, Mecca, Saudi Arabia.
EM aagutub@uqu.edu.sa
RI Gutub, Adnan Abdul-Aziz/O-1240-2016; Al-Ghamdi, Maimoona/AAN-5906-2020
OI Gutub, Adnan Abdul-Aziz/0000-0003-0923-202X; 
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Al-Ghamdi M, 2019, MULTIMED TOOLS APPL, V78, P16283, DOI 10.1007/s11042-018-6977-2
   Al-Juaid N, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-0875-8
   Al-Nofaie S, 2021, J KING SAUD UNIV-COM, V33, P963, DOI 10.1016/j.jksuci.2019.06.010
   Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   Al-Qurashi A., 2018, J. Comput. Sci. Comput. Math. (JCSCM), V8, P87, DOI [10.20967/jcscm.2018.04.006, DOI 10.20967/JCSCM.2018.04.006]
   Alaseri K., 2018, IJRDO J COMPUTER SCI, V4, P1
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   [Anonymous], 2019, J INFORM SECURITY CY
   [Anonymous], 2008, 5 IEEE INT WORKSH SI
   Arbogast J.K., 2018, J COMPUTING SCI COLL, V33, P12
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   BENALOH JC, 1987, LECT NOTES COMPUT SC, V263, P251
   Blakley G.R., 1979, INT WORKSH MAN REQ K
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chang CC, 2011, INFORM SCIENCES, V181, P3073, DOI 10.1016/j.ins.2011.03.002
   Das SK, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P395, DOI 10.1109/ICRCICN.2015.7434271
   Farooqi N, 2019, LIFE SCI J
   Gupta B, 2017, HDB RES MODERN CRYPT
   Gupta B.B., 2018, Computer and Cyber Security: Principles, Algorithm, Applications, and Perspectives
   Gutub A, 2019, J ENG RES JER
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub A, 2020, ARAB J SCI ENG, V45, P2433, DOI 10.1007/s13369-019-04010-6
   Gutub A, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0216-0
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Gutub AAA, 2021, J KING SAUD UNIV-COM, V33, P1108, DOI 10.1016/j.jksuci.2019.06.014
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin HC, 2013, J VIS COMMUN IMAGE R, V24, P318, DOI 10.1016/j.jvcir.2013.01.003
   Lin PY, 2010, PATTERN RECOGN LETT, V31, P1887, DOI 10.1016/j.patrec.2010.01.019
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Norah A, 2017, J RES ENG APPL SCI J, V2, P50, DOI DOI 10.46565/JREAS.2017.V02I02.002
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Raphel RK, 2015, LECT NOTES COMPUT SC, V9532, P476, DOI 10.1007/978-3-319-27161-3_43
   Shamir A, 1979, COMMUN ACM
   Shima K, 2016, ASIA JT CONF INF SEC, P108, DOI 10.1109/AsiaJCIS.2016.11
   Stoyanova V, 2015, TECHNICS TECHNOLOGIE
   Tewari A, 2017, J SUPERCOMPUT, V73, P1085, DOI 10.1007/s11227-016-1849-x
   Wiese O, 2018, 34TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2018), P478, DOI 10.1145/3274694.3274729
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
NR 41
TC 54
Z9 54
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7951
EP 7985
DI 10.1007/s11042-019-08427-x
EA JAN 2020
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000505356500005
DA 2024-07-18
ER

PT J
AU Li, XS
   Chang, CC
   He, MX
   Lin, CC
AF Li, Xiao-Shuang
   Chang, Chin-Chen
   He, Ming-Xing
   Lin, Chia-Chen
TI A lightweight authenticable visual secret sharing scheme based on turtle
   shell structure matrix
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Turtle shell structure matrix (TSSM); Visual secret sharing (VSS);
   Authentication; Reversibility; Lightweight
ID STEGANOGRAPHIC METHOD; IMAGES
AB This paper proposes a novel visual secret sharing scheme based on a turtle shell structure matrix (TSSM) with reversibility and lightweight authentication. With the assistance of TSSM, the secret data is embedded into the original cover image and three meaningful shadow images are generated. To increase the image quality of the generated shadows, the proposed scheme designs an embedding structure that will be used to embed a secret image into shadows based on the TSSM, rather than by directly embedding authentication codes. The designed embedding structure offers a robust authentication capability at the cost of lightweight computation. Moreover, the hidden secret data can be extracted completely and the cover image can be restored losslessly through the collaboration of the three received shadows. Experimental results, on various grayscale test images, confirmed that our proposed scheme provides high visual quality and excellent authentication.
C1 [Li, Xiao-Shuang] Xi Hua Univ, Dept Comp & Technol, 999 Jinzhou Rd, Chengdu, Sichuang, Peoples R China.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
   [He, Ming-Xing] Xi Hua Univ, Dept Comp & Technol, 999 Jinzhou Rd, Chengdu, Sichuang, Peoples R China.
   [Lin, Chia-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taichung 433, Taiwan.
C3 Feng Chia University; Providence University - Taiwan
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.; He, MX (corresponding author), Xi Hua Univ, Dept Comp & Technol, 999 Jinzhou Rd, Chengdu, Sichuang, Peoples R China.; Lin, CC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, Taichung 433, Taiwan.
EM lxspoppy@gmail.com; alan3c@gmail.com; he_mingxing64@aliyun.com;
   mhlin3@pu.edu.tw
RI Chang, Ching-Chun/JAN-6210-2023
OI Lin, Chia-Chen/0000-0003-4480-7351
FU National Natural Science Foundation of China [U143310218]; Chunhui
   Project of Education Ministry of China [Z2014045]; Science and Education
   and Technology Bureau Project of Cheng-du Municipality
   [2016-XT00-00015-GX]; Graduate Innovation Fund Project of Xi Hua
   University [ycjj2018003]; Civil aviation administration of China
   [PSDSA201802]
FX This research is funded by: (1) National Natural Science Foundation of
   China (nos.U143310218); (2) Chunhui Project of Education Ministry of
   China (nos.Z2014045); (3) Science and Education and Technology Bureau
   Project of Cheng-du Municipality (nos.2016-XT00-00015-GX); (4) Graduate
   Innovation Fund Project of Xi Hua University (nos.ycjj2018003); (5)
   Civil aviation administration of China (nos.PSDSA201802).
CR [Anonymous], MULT SEC WORKSH ACM
   [Anonymous], 2018, MATH GEOSCI
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2002, INFORM SCIENCES, V141, P123, DOI 10.1016/S0020-0255(01)00194-3
   Chang CC, 2006, PATTERN RECOGN, V39, P1155, DOI 10.1016/j.patcog.2005.12.011
   Chang Ch-Ch., 2014, J INF HIDING MULTIME, V5, P342
   Chang CP, 2008, IEEE POTENTIALS, V27, P17, DOI 10.1109/MPOT.2008.929294
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chang CC, 2016, IET IMAGE PROCESS, V10, P590, DOI 10.1049/iet-ipr.2015.0568
   Chang CC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P89, DOI 10.1109/IIH-MSP.2014.29
   Chin-Chen Chang, 2010, Journal of Communications, V5, P5, DOI 10.4304/jcm.5.1.5-12
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686
   Kundur D, 1999, P IEEE, V87, P1167, DOI 10.1109/5.771070
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu SH, 2006, PATTERN RECOGN, V39, P866, DOI 10.1016/j.patcog.2005.06.010
   Stinson D., 1999, IEEE Potentials, V18, P13, DOI 10.1109/45.747238
   Thien CC, 2003, IEEE T CIRC SYST VID, V13, P1161, DOI 10.1109/TCSVT.2003.819176
   Thien CC, 2003, PATTERN RECOGN, V36, P2875, DOI 10.1016/S0031-3203(03)00221-8
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu XT, 2013, IEEE T INF FOREN SEC, V8, P1541, DOI 10.1109/TIFS.2013.2274955
   Yang CN, 2007, INT J IMAG SYST TECH, V17, P40, DOI 10.1002/ima.20096
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2005, PATTERN RECOGN LETT, V26, P193, DOI 10.1016/j.patrec.2004.08.025
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 31
TC 9
Z9 9
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 453
EP 476
DI 10.1007/s11042-019-08077-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600019
DA 2024-07-18
ER

PT J
AU Kumar, C
   Singh, AK
   Kumar, P
AF Kumar, Chandan
   Singh, Amit Kumar
   Kumar, Pardeep
TI Dual watermarking: An approach for securing digital documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dual watermarking; DWT; SVD; Arnold transform; SPIHT; PSNR; SSIM; NC;
   BER; Attacks
ID IMAGE WATERMARKING; MULTIPLE WATERMARKING; ROBUST; SCHEME
AB This paper presents a dual watermarking technique using discrete wavelet transform (DWT), singular value decomposition (SVD) and set partitioning in hierarchical tree (SPIHT). The method uses second level DWT to transform the host image in to different frequency components. Next, we further transform the selected wavelet component via SVD. Before embedding, the logo watermark is secured via Arnold transform and signature watermark are encoded by hamming code. Finally, we embed both encoded watermarks into the transformed host image via an embedding approach. The watermarked image is further compress by SPIHT scheme along with the location key. With our scheme, maximum PSNR, NC and SSIM are obtained as 36.97 dB, 0.9965 and 0.9974, respectively. However best obtained BER is zero. Experimental results on various images demonstrate the importance of our scheme and superior to competing methods.
C1 [Kumar, Chandan; Kumar, Pardeep] JUIT, Dept CSE & IT, Solan, India.
   [Singh, Amit Kumar] NIT Patna, Dept CSE, Patna, Bihar, India.
C3 Jaypee University of Information Technology; National Institute of
   Technology (NIT System); National Institute of Technology Patna
RP Singh, AK (corresponding author), NIT Patna, Dept CSE, Patna, Bihar, India.
EM chandansharmahmr@gmail.com; amit_245singh@yahoo.com;
   pardeepkumarkhokhar@gmail.com
RI India, Career Point University Hamirpur Himachal Pradesh/HLX-5948-2023;
   Kumar, Chandan/ACB-0720-2022; Singh, Amit Kumar/D-1300-2015
OI India, Career Point University Hamirpur Himachal
   Pradesh/0000-0002-4828-4458; Kumar, Chandan/0000-0001-9163-3206; Singh,
   Amit Kumar/0000-0001-7359-2068
CR [Anonymous], 2017, BOOK SERIES MULTIMED
   Bhatnagar G, 2009, COMPUT STAND INTER, V31, P1002, DOI 10.1016/j.csi.2008.09.031
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Gunjal BL, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-0904-z
   KUMAR C, 2018, CONCURRENCY COMPUTAT
   Kumar C, 2020, MULTIMED TOOLS APPL, V79, P11069, DOI 10.1007/s11042-018-6177-0
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Meenpal T, 2018, SADHANA-ACAD P ENG S, V43, DOI 10.1007/s12046-017-0773-y
   Sharma A, 2017, WIRELESS PERS COMMUN, V92, P1611, DOI 10.1007/s11277-016-3625-x
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Shivani JLD, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9030033
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Singh AK, 2017, MULTIMED SYST APPL, P175, DOI 10.1007/978-3-319-57699-2_8
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh AK, 2014, P NATL A SCI INDIA A, V84, P345, DOI 10.1007/s40010-014-0140-x
   Singh L, 2020, MULTIMED TOOLS APPL, V79, P15901, DOI 10.1007/s11042-018-6407-5
   Singh RK, 2017, J BRAZ SOC MECH SCI, V39, P4677, DOI 10.1007/s40430-017-0839-0
   Thakur S, 2020, MULTIMED TOOLS APPL, V79, P4263, DOI 10.1007/s11042-018-6691-0
   Thakur S, 2018, Multimed Tools Appl, P1
   Xiao-Long Liu, 2018, IEEE Transactions on Circuits and Systems for Video Technology, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
NR 23
TC 19
Z9 20
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7339
EP 7354
DI 10.1007/s11042-019-08314-5
EA DEC 2019
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000504164600001
DA 2024-07-18
ER

PT J
AU Gao, GW
   Wang, YN
   Huang, P
   Chang, HY
   Lu, HM
   Yue, D
AF Gao, Guangwei
   Wang, Yannan
   Huang, Pu
   Chang, Heyou
   Lu, Huimin
   Yue, Dong
TI Locality-constrained feature space learning for cross-resolution
   sketch-photo face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Cross-resolution; Locality-constrained; Feature
   learning
ID HALLUCINATION
AB Matching sketch facial images to mug-shot images have crucial significance in law enforcement and digital entertainment. Conventional methods always assume that both the sketch and photo face images have the same resolutions. However, in real criminal detection, the target facial sketches obtained by the artist usually have different resolutions against the source photos in the mug-shot database. In this paper, we propose a locality-constrained feature space learning (LCFSL) method to address the above cross-resolution sketch-photo facial images matching problem. The proposed LCFSL approach not only build bridge to associate cross-domain face images, but also can learn resolution robust representation features for cross-resolution sketch-photo face recognition purpose. After common feature space learning, we simply use nearest neighbor classifier to perform recognition based on the projected features obtained from sketch-photo faces with different resolutions. Experiments conducted on CUHK student database and AR database have shown the effectiveness and superiority of our method to some state-of-the-art face recognition approaches.
C1 [Gao, Guangwei; Wang, Yannan; Huang, Pu; Yue, Dong] Nanjing Univ Posts & Telecommun, Inst Adv Technol, Nanjing, Jiangsu, Peoples R China.
   [Gao, Guangwei] Soochow Univ, Prov Key Lab Comp Informat Proc Technol, Suzhou, Peoples R China.
   [Wang, Yannan; Yue, Dong] Nanjing Univ Posts & Telecommun, Sch Automat, Nanjing, Jiangsu, Peoples R China.
   [Chang, Heyou] Nanjing XiaoZhuang Univ, Key Lab Trusted Cloud Comp & Big Data Anal, Nanjing, Jiangsu, Peoples R China.
   [Lu, Huimin] Kyushu Inst Technol, Dept Mech & Control Engn, Kitakyushu, Fukuoka, Japan.
C3 Nanjing University of Posts & Telecommunications; Soochow University -
   China; Nanjing University of Posts & Telecommunications; Nanjing
   Xiaozhuang University; Kyushu Institute of Technology
RP Gao, GW (corresponding author), Nanjing Univ Posts & Telecommun, Inst Adv Technol, Nanjing, Jiangsu, Peoples R China.; Gao, GW (corresponding author), Soochow Univ, Prov Key Lab Comp Informat Proc Technol, Suzhou, Peoples R China.
EM csggao@gmail.com
RI Yue, Dong/ITW-1999-2023; Yue, Dong/ITW-1908-2023
OI Yue, Dong/0000-0001-7810-9338
FU National Key Research and Development Program of China [2018AAA0100102];
   National Natural Science Foundation of China [61972212, 61772568,
   61806098, 61833011]; Six Talent Peaks Project in Jiangsu Province
   [RJFW-011]; open fund project of Science and Technology on Space
   Intelligent Control Laboratory [6142208180302]; Open Fund Project of
   Provincial Key Laboratory for Computer Information Processing Technology
   (Soochow University) [KJS1840]; Natural Science Foundation of Jiangsu
   Province [BK20190089]
FX This work was supported by the National Key Research and Development
   Program of China under Project no. 2018AAA0100102; the National Natural
   Science Foundation of China under Grant nos. 61972212, 61772568,
   61806098 and 61833011; the Natural Science Foundation of Jiangsu
   Province under Grant no. BK20190089; the Six Talent Peaks Project in
   Jiangsu Province under Grant no. RJFW-011; the open fund project of
   Science and Technology on Space Intelligent Control Laboratory under
   Grant no. 6142208180302; and the Open Fund Project of Provincial Key
   Laboratory for Computer Information Processing Technology (Soochow
   University) (No. KJS1840).
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   Benavente R, 1998, 24 COMP VIS CTR
   Bhatt HS, 2014, IEEE T IMAGE PROCESS, V23, P5654, DOI 10.1109/TIP.2014.2362658
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   Haghighat M, 2017, IEEE INT CONF AUTOMA, P912, DOI 10.1109/FG.2017.130
   He R, 2017, AAAI CONF ARTIF INTE, P2000
   Jiang J, 2018, LECT NOTES ARTIF INT, V10956, P1, DOI 10.1007/978-3-319-95957-3_1
   Jiang JJ, 2019, IEEE T IMAGE PROCESS, V28, P628, DOI 10.1109/TIP.2018.2870936
   Jiang JJ, 2017, IEEE T CYBERNETICS, V47, P3991, DOI 10.1109/TCYB.2016.2594184
   Jiang JJ, 2016, SIGNAL PROCESS, V124, P162, DOI 10.1016/j.sigpro.2015.09.026
   Jiang JJ, 2014, IEEE T MULTIMEDIA, V16, P1268, DOI 10.1109/TMM.2014.2311320
   Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Lezama J, 2017, PROC CVPR IEEE, P6807, DOI 10.1109/CVPR.2017.720
   Liu LC, 2018, IEEE T CYBERNETICS, V48, P1189, DOI 10.1109/TCYB.2017.2682853
   Lu T, 2018, IEEE ACCESS, V6, P56269, DOI 10.1109/ACCESS.2018.2872761
   Lu WP, 2018, IEICE T INF SYST, VE101D, P225, DOI 10.1587/transinf.2017EDP7090
   Ma X, 2010, PATTERN RECOGN, V43, P2224, DOI 10.1016/j.patcog.2009.12.019
   Mudunuri SP, 2016, IEEE T PATTERN ANAL, V38, P1034, DOI 10.1109/TPAMI.2015.2469282
   Oh BS, 2017, NEUROCOMPUTING, V261, P253, DOI 10.1016/j.neucom.2015.11.137
   Ou WH, 2018, PATTERN RECOGN LETT, V107, P41, DOI 10.1016/j.patrec.2017.07.006
   Ou WH, 2014, PATTERN RECOGN, V47, P1559, DOI 10.1016/j.patcog.2013.10.017
   Peng CL, 2018, PATTERN RECOGN, V84, P262, DOI 10.1016/j.patcog.2018.07.014
   Peng CL, 2017, IEEE T PATTERN ANAL, V39, P301, DOI 10.1109/TPAMI.2016.2542816
   Wang N, 2020, IEEE T SERV COMPUT, V13, P1086, DOI 10.1109/TSC.2017.2753775
   Wang NN, 2018, PATTERN RECOGN, V76, P215, DOI 10.1016/j.patcog.2017.11.008
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P1955, DOI 10.1109/TPAMI.2008.222
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhang YT, 2020, MULTIMED TOOLS APPL, V79, P14751, DOI 10.1007/s11042-019-7240-1
NR 29
TC 0
Z9 0
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14903
EP 14917
DI 10.1007/s11042-019-08488-y
EA DEC 2019
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000502584400005
DA 2024-07-18
ER

PT J
AU Fard, SMH
   Hashemi, S
AF Fard, Seyed Mehdi Hazrati
   Hashemi, Sattar
TI Proposing a sparse representational based face verification system to
   run in a shortage of memory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face verification; Sparse representation; Classification; Sample
   generation; Augmentation
ID TEXTURE CLASSIFICATION; RECOGNITION; PROJECTION; SCALE; AGE
AB Studying face verification has seen tremendous growth over the past years. During the last decade, with the improvement of system processors and memories, deep learning was growth widely and the applications of Convolutional Neural Network (CNN) affected all image processing tasks. But, needing much space to save several parameters of learned model is still a big challenge to use them on simple devices, e.g. cell phones. In this paper, to address the problem of face verification in a shortage of memory sparse representation has been employed. So, to compare two portraits a dictionary is generated from each image using augmentation techniques. Then, each face is reconstructed sparsely by the other dictionary and if there is a negligible average of reconstruction error, couple of faces are matched. The proposed method has been assessed in various conditions of several face datasets and the results show improvement comparing to all sparse representational approaches. Although the evaluations indicate a bit less accuracy than CNN-based methods, the main advantage is less usage of memory that can lead running on mobile devices.
C1 [Fard, Seyed Mehdi Hazrati; Hashemi, Sattar] Shiraz Univ, Dept Comp Sci & Engn, Shiraz, Iran.
C3 Shiraz University
RP Hashemi, S (corresponding author), Shiraz Univ, Dept Comp Sci & Engn, Shiraz, Iran.
EM hazrati@cse.shirazu.ac.ir; s_hashemi@shirazu.ac.ir
RI Fard, Seyed Mehdi Hazrati/AAQ-5374-2020
OI Fard, Seyed Mehdi Hazrati/0000-0002-2082-2840
CR Allison PD, 2000, SOCIOL METHOD RES, V28, P301, DOI 10.1177/0049124100028003003
   [Anonymous], 2013, J. Uncertain Syst.
   [Anonymous], 2008, LABELED FACES WILD D
   [Anonymous], 2015, DEEPID3 FACE RECOGNI
   [Anonymous], 2009, Scholarpedia, DOI [DOI 10.4249/SCHOLARPEDIA.2776, 10.4249/scholarpedia.2776]
   [Anonymous], 2016, P CVPR WORKSH
   [Anonymous], 2014, SPAMS: A sparse modeling software, v2.3
   [Anonymous], 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299058
   [Anonymous], 2017, IMPROVING DEEP LEARN
   Becker S, 2011, SIAM J IMAGING SCI, V4, P1, DOI 10.1137/090756855
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Cai D., 2007, P IEEE C COMP VIS PA
   Chen B, 2017, CYBER PHYS SYSTEM EN
   Chen BC, 2014, LECT NOTES COMPUT SC, V8694, P768, DOI 10.1007/978-3-319-10599-4_49
   Choudhury B, 2018, INT J IMAGE GRAPH, V18, DOI 10.1142/S0219467818500067
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Dewitt J, 2018, JMIR RES PROTOC, V7, DOI 10.2196/resprot.7655
   Dhamecha TI, 2013, INT CONF BIOMETR
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Emadi M, 2011, P INT C IM PROC COMP, P1
   Fard SMH, 2018, IRANIAN J SCI TECHNO, P1
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Galbally J, 2014, IEEE ACCESS, V2, P1530, DOI 10.1109/ACCESS.2014.2381273
   Guo H., 2012, IEEE COMP SOC C COMP, P37, DOI [10.1109/CVPRW.2012.6239213, DOI 10.1109/CVPRW.2012.6239213]
   He LX, 2018, PROC CVPR IEEE, P7054, DOI 10.1109/CVPR.2018.00737
   He R, 2011, NEURAL COMPUT, V23, P2074, DOI 10.1162/NECO_a_00155
   Hernandez-Garcia A., 2018, ARXIV PREPRINT ARXIV
   Hu B, 2015, 3RD INTERNATIONAL CONFERENCE ON ADVANCED COMPOSITE MATERIALS AND MANUFACTURING ENGINEERING (CMME 2015), P142
   Jin D, 2015, AAAI CONF ARTIF INTE, P160
   Jones M., 2003, Mitsubishi Electric Research Lab TR-20003-96, V3, P2
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Krishna Prasad K, 2017, CONCEPTUAL STUDY USE
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Lu Leng, 2012, Proceedings of the 2012 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR), P164, DOI 10.1109/ICWAPR.2012.6294772
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Martinez RAM, 1998, TECH REP
   Melgor, 2018, DEMYSTIFYING FACE RE
   Miri M, 2017, 2017 19TH CSI INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), P140, DOI 10.1109/AISP.2017.8324125
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Ortiz EG, 2014, COMPUT VIS IMAGE UND, V118, P153, DOI 10.1016/j.cviu.2013.09.004
   Osadchy M, 2010, P IEEE S SECUR PRIV, P239, DOI 10.1109/SP.2010.39
   Palm C, 2000, PROCEEDINGS OF THE FIFTH JOINT CONFERENCE ON INFORMATION SCIENCES, VOLS 1 AND 2, pA45
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Ramanathan N, 2004, IEEE IMAGE PROC, P1999
   Rao R. P. N., 2002, J MATH PSYCHOL
   Ratner Alexander J, 2017, P NEURIPS, P3236
   Sanguansat Parinya, 2010, Proceedings 2010 First International Conference on Pervasive Computing, Signal Processing and Applications (PCSPA 2010), P1107, DOI 10.1109/PCSPA.2010.272
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simard PY, 1998, LECT NOTES COMPUT SC, V1524, P239
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Turcot Panu, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P2109, DOI 10.1109/ICCVW.2009.5457541
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wright SJ, 2015, MATH PROGRAM, V151, P3, DOI 10.1007/s10107-015-0892-3
   Yan M, 2017, INT J IMAG SYST TECH, V27, P23, DOI 10.1002/ima.22207
   Yang ZY, 2018, PROCEEDINGS 2018 IEEE 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING (CLOUD), P277, DOI 10.1109/CLOUD.2018.00042
   Yuan XT, 2012, IEEE T IMAGE PROCESS, V21, P4349, DOI 10.1109/TIP.2012.2205006
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
   Zhao J, 2017, INFORM FUSION, V38, P43, DOI 10.1016/j.inffus.2017.02.007
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhu Q, 2014, ELECTRON LETT, V50, P1919, DOI 10.1049/el.2014.2816
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 66
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2965
EP 2985
DI 10.1007/s11042-019-08491-3
EA DEC 2019
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000500612000002
DA 2024-07-18
ER

PT J
AU Al-Radhi, MS
   Csapo, TG
   Nemeth, G
AF Al-Radhi, Mohammed Salah
   Csapo, Tamas Gabor
   Nemeth, Geza
TI Continuous vocoder applied in deep neural network based voice conversion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Voice conversion; Continuous vocoder; neural network; Speech synthesis
ID DYNAMIC-PROGRAMMING ALGORITHM; PLUS NOISE MODEL; SPEECH
AB In this paper, a novel vocoder is proposed for a Statistical Voice Conversion (SVC) framework using deep neural network, where multiple features from the speech of two speakers (source and target) are converted acoustically. Traditional conversion methods focus on the prosodic feature represented by the discontinuous fundamental frequency (F0) and the spectral envelope. Studies have shown that speech analysis/synthesis solutions play an important role in the overall quality of the converted voice. Recently, we have proposed a new continuous vocoder, originally for statistical parametric speech synthesis, in which all parameters are continuous. Therefore, this work introduces a new method by using a continuous F0 (contF0) in SVC to avoid alignment errors that may happen in voiced and unvoiced segments and can degrade the converted speech. Our contribution includes the following. (1) We integrate into the SVC framework the continuous vocoder, which provides an advanced model of the excitation signal, by converting its contF0, maximum voiced frequency, and spectral features. (2) We show that the feed-forward deep neural network (FF-DNN) using our vocoder yields high quality conversion. (3) We apply a geometric approach to spectral subtraction (GA-SS) in the final stage of the proposed framework, to improve the signal-to-noise ratio of the converted speech. Our experimental results, using two male and one female speakers, have shown that the resulting converted speech with the proposed SVC technique is similar to the target speaker and gives state-of-the-art performance as measured by objective evaluation and subjective listening tests.
C1 [Al-Radhi, Mohammed Salah; Csapo, Tamas Gabor; Nemeth, Geza] Budapest Univ Technol & Econ, Dept Telecommun & Media Informat, Budapest, Hungary.
   [Csapo, Tamas Gabor] MTA ELTE Lendulet Lingual Articulat Res Grp, Budapest, Hungary.
C3 Budapest University of Technology & Economics; Eotvos Lorand University
RP Al-Radhi, MS (corresponding author), Budapest Univ Technol & Econ, Dept Telecommun & Media Informat, Budapest, Hungary.
EM malradhi@tmit.bme.hu; csapot@tmit.bme.hu; nemeth@tmit.bme.hu
RI Al-Radhi, Mohammed Salah/C-9727-2018; Nemeth, Geza/N-1734-2013
OI Al-Radhi, Mohammed Salah/0000-0003-3094-6916; Nemeth,
   Geza/0000-0002-2311-4858
FU Budapest University of Technology and Economics (BME)
FX Open access funding provided by Budapest University of Technology and
   Economics (BME).
CR Aihara R., 2014, Proceedings of the 5th Workshop on Speech and Language Processing for Assistive Technologies, Maryland, USA, P29
   Al-Radhi M.S., 2017, P DIGITAL SPEECH IMA
   Al-Radhi MS, 2017, INTERSPEECH, P434, DOI 10.21437/Interspeech.2017-678
   [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], P EUR SIGN PROC C EU
   [Anonymous], 1997, METHODS CALCULATION
   [Anonymous], 2001, METH SUBJ ASS INT AU
   [Anonymous], 2003, COMPUT SYST
   [Anonymous], 1968, P 6 INT C ACOUST LOS
   Chen LH, 2014, IEEE-ACM T AUDIO SPE, V22, P1859, DOI 10.1109/TASLP.2014.2353991
   Childers D. G., 1985, ICASSP 85. Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No. 85CH2118-8), P748
   CHILDERS DG, 1989, SPEECH COMMUN, V8, P147, DOI 10.1016/0167-6393(89)90041-1
   CHILDERS DG, 1995, SPEECH COMMUN, V16, P127, DOI 10.1016/0167-6393(94)00050-K
   Csapó TG, 2016, EUR SIGNAL PR CONF, P1338, DOI 10.1109/EUSIPCO.2016.7760466
   Desai S, 2009, INT CONF ACOUST SPEE, P3893, DOI 10.1109/ICASSP.2009.4960478
   Doi H, 2014, IEEE-ACM T AUDIO SPE, V22, P172, DOI 10.1109/TASLP.2013.2286917
   Drugman Thomas, 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P2176
   Drugman Thomas, 2014, IEEE Signal Processing Letters, V21, P1230, DOI 10.1109/LSP.2014.2332186
   Drugman T, 2012, IEEE T AUDIO SPEECH, V20, P994, DOI 10.1109/TASL.2011.2170835
   Drugman T, 2012, IEEE T AUDIO SPEECH, V20, P968, DOI 10.1109/TASL.2011.2169787
   Dutoit T., 1997, Journal of Electrical and Electronics Engineering, Australia, V17, P25
   Erro D, 2014, IEEE J-STSP, V8, P184, DOI 10.1109/JSTSP.2013.2283471
   Garner PN, 2013, IEEE SIGNAL PROC LET, V20, P102, DOI 10.1109/LSP.2012.2231675
   Hashimoto K, 2015, INT CONF ACOUST SPEE, P4455, DOI 10.1109/ICASSP.2015.7178813
   Helander E, 2012, IEEE T AUDIO SPEECH, V20, P806, DOI 10.1109/TASL.2011.2165944
   Hu Q., 2013, Proc. ISCA SSW8, P155
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054
   Imai S., 1983, Electr. Commun. Jpn., V66, P10, DOI [DOI 10.1002/ECJA.4400660203, DOI 10.1002/ecja.4400660203]
   Kaneko T, 2017, INTERSPEECH, P1283, DOI 10.21437/Interspeech.2017-970
   Kenmochi H, 2012, INT CONF ACOUST SPEE, P5385, DOI 10.1109/ICASSP.2012.6289138
   Klatt D. H., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P1278
   Kobayashi K, 2017, INTERSPEECH, P1138, DOI 10.21437/Interspeech.2017-986
   KUBICHEK RF, 1993, IEEE PACIF, P125, DOI 10.1109/PACRIM.1993.407206
   Lenarczyk Michal, 2014, Text, Speech and Dialogue. 17th International Conference, TSD 2014. Proceedings: LNCS 8655, P507, DOI 10.1007/978-3-319-10816-2_61
   Ling ZH, 2013, IEEE T AUDIO SPEECH, V21, P2129, DOI 10.1109/TASL.2013.2269291
   Lu Y, 2008, SPEECH COMMUN, V50, P453, DOI 10.1016/j.specom.2008.01.003
   Ma JF, 2009, J ACOUST SOC AM, V125, P3387, DOI 10.1121/1.3097493
   MIZUNO H, 1995, SPEECH COMMUN, V16, P153, DOI 10.1016/0167-6393(94)00052-C
   Mohammadi SH, 2014, IEEE W SP LANG TECH, P19, DOI 10.1109/SLT.2014.7078543
   Morise M., 2010, The IEICE Transactions on Information and Systems, VJ93-D, P109
   Morise M, 2018, ACOUST SCI TECHNOL, V39, P263, DOI 10.1250/ast.39.263
   Morise M, 2016, IEICE T INF SYST, VE99D, P1877, DOI 10.1587/transinf.2015EDP7457
   Morise M, 2015, SPEECH COMMUN, V67, P1, DOI 10.1016/j.specom.2014.09.003
   Najafabadi MM, 2015, Journal of big data, V2, P1, DOI [10.1186/s40537-014-0007-7, DOI 10.1186/S40537-014-0007-7]
   Nakamura K, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P1628
   Nakashika T., 2014, P ISCA INTERSPEECH, P2278
   Nakashika T, 2013, INTERSPEECH, P369
   NEY H, 1984, IEEE T ACOUST SPEECH, V32, P263, DOI 10.1109/TASSP.1984.1164320
   Nose T, 2011, SPEECH COMMUN, V53, P973, DOI 10.1016/j.specom.2011.05.001
   Nwe TL, 2010, IEEE INT CON MULTI, P1421, DOI 10.1109/ICME.2010.5582961
   Quackenbush S.R., 1988, Objective Measures of Speech Quality
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Sisman B., 2018, IEEE SPOK LANG TECHN
   Sisman BM, 2018, INTERSPEECH, P52
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464
   Stylianou Y, 2001, IEEE T SPEECH AUDI P, V9, P21, DOI 10.1109/89.890068
   Takamichi S, 2016, IEEE-ACM T AUDIO SPE, V24, P755, DOI 10.1109/TASLP.2016.2522655
   Toda T, 2007, IEEE T AUDIO SPEECH, V15, P2222, DOI 10.1109/TASL.2007.907344
   Tokuda K., 1994, ICSLP 94. 1994 International Conference on Spoken Language Processing, P1043
   Valentini-Botinhao C, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P869
   Wang YX, 2017, INTERSPEECH, P4006, DOI 10.21437/Interspeech.2017-1452
   Wu LF, 2012, PROCEEDINGS OF THE 2012 SECOND INTERNATIONAL CONFERENCE ON INSTRUMENTATION & MEASUREMENT, COMPUTER, COMMUNICATION AND CONTROL (IMCCC 2012), P1575, DOI 10.1109/IMCCC.2012.367
   Wu ZZ, 2015, INT CONF ACOUST SPEE, P4460, DOI 10.1109/ICASSP.2015.7178814
   Wu ZZ, 2014, IEEE-ACM T AUDIO SPE, V22, P1506, DOI 10.1109/TASLP.2014.2333242
   Yao Qian, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3829, DOI 10.1109/ICASSP.2014.6854318
   Yu K, 2011, IEEE T AUDIO SPEECH, V19, P1071, DOI 10.1109/TASL.2010.2076805
   Zen HG, 2013, INT CONF ACOUST SPEE, P7962, DOI 10.1109/ICASSP.2013.6639215
   Zhizheng W., 2016, P 9 ISCA SPEECH SYNT
NR 68
TC 4
Z9 4
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33549
EP 33572
DI 10.1007/s11042-019-08198-5
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600045
OA hybrid
DA 2024-07-18
ER

PT J
AU Coletta, A
   De Marsico, M
   Panizzi, E
   Prenkaj, B
   Silvestri, D
AF Coletta, Andrea
   De Marsico, Maria
   Panizzi, Emanuele
   Prenkaj, Bardh
   Silvestri, Domenicomichele
TI MIMOSE: multimodal interaction for music orchestration sheet editors An
   integrable multimodal music editor interaction system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MIMOSE; Music sheet editor software; Multimodal wrapper; Gesture
   recognition; Hot-word recognition; User-system friendliness
ID VIRTUAL-REALITY
AB The increasing number and accuracy of sensors devoted to human-computer input are supporting the emergence of novel multimodal interaction paradigms. These, in turn, can unlock additional strategies to design innovative user-friendly systems. The underlying approaches to user-computer interaction leverage natural channels of communication (e.g. gestures and voice), therefore oftentimes are less cumbersome than traditional interface modalities. This paper proposes a wrapper-based strategy to easily map keyboard shortcuts onto multimodal actions. The presented case study is a music editor software. These applications are often overwhelming for novice users, therefore discouraging their interaction. MIMOSE - Multimodal Interaction for Music Orchestration Sheet Editors addresses these limitations. Instead of relying on buttons and mixture pads for the composition of a music opera, it provides a gesture- and voice-based multimodal wrapper for music editor applications. The user assumes the role of an orchestra conductor. Hence, the wrapper translates user gestures and music jargon keywords into mouse clicks or keyboard pressings, by substituting keyboard shortcuts with multimodal actions. This provides a user ecologically tuned and immersive environment of interaction. It is worth noticing that the wrapped application is not necessarily an open source one. In fact, events already captured by such application are just sent over different channels than keyboard and mouse and are triggered by multimodal actions instead of key pressing. After presenting the features of the wrapper, we describe its application to an open source software tool for music editing and present twofold evaluation results. We separately evaluated the performances of each interaction modality in terms of accuracy and F1 score. Furthermore, we asked real users to evaluate the usability of the application when extended by the wrapper. The user evaluation relies on ad-hoc tailored QUIS and SUXES questionnaires in order to assess the user-friendliness of the resulting application. The results are encouraging from both technical quality and usability points of view. The wrapper at the core of MIMOSE can be adapted to other kinds of applications, with a minimal coding effort.
C1 [Coletta, Andrea; De Marsico, Maria; Panizzi, Emanuele; Prenkaj, Bardh; Silvestri, Domenicomichele] Sapienza Univ Rome, Dept Comp Sci, Rome, Italy.
C3 Sapienza University Rome
RP De Marsico, M (corresponding author), Sapienza Univ Rome, Dept Comp Sci, Rome, Italy.
EM coletta@di.uniroma1.it; demarsico@di.uniroma1.it;
   panizzi@di.uniroma1.it; prenkaj@di.uniroma1.it;
   silvestri.1772915@studenti.uniroma1.it
RI Panizzi, Emanuele/JPL-0194-2023; Prenkaj, Bardh/AAL-6461-2020; De
   Marsico, Maria/K-6684-2015; Coletta, Andrea/H-9856-2012
OI Prenkaj, Bardh/0000-0002-2991-2279; De Marsico,
   Maria/0000-0002-1391-8502; Coletta, Andrea/0000-0003-1401-1715; PANIZZI,
   Emanuele/0000-0002-7442-8451
CR [Anonymous], 1988, Proceedings of the SIGCHI conference on Human factors in computing systems-CHI, DOI DOI 10.1145/57167.57203
   Awada IA, 2017, 2017 21ST INTERNATIONAL CONFERENCE ON CONTROL SYSTEMS AND COMPUTER SCIENCE (CSCS), P536, DOI 10.1109/CSCS.2017.82
   Barfield W., 2015, Fundamentals of wearable computers and augmented reality
   Caschera MC, 2013, LECT NOTES COMPUT SC, V8186, P694, DOI 10.1007/978-3-642-41033-8_87
   Edwards ADN, 2002, TEXT SPEECH LANG TEC, V19, P73
   Forsberg A., 1998, 11th Annual Symposium on User Interface Software and Technology. UIST. Proceedings of the ACM Symposium, P203, DOI 10.1145/288392.288608
   Gruenstein Alexander, 2008, P ACL 08 HLT WORKSH, P1
   Laver KE, 2015, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008349.pub3
   Li L, 2017, AM J TRANSL RES, V9, P3867
   Lin FH, 2002, INFORM SCIENCES, V140, P153, DOI 10.1016/S0020-0255(01)00185-2
   Ohta Y., 2014, MIXED REALITY MERGIN
   Piekarski W, 2002, COMMUN ACM, V45, P36, DOI 10.1145/502269.502291
   RUBINE D, 1991, COMP GRAPH, V25, P329, DOI 10.1145/127719.122753
   Rubine D. H., 1991, THESIS
   Sharma G, 2018, ANN CONF PRIV SECUR, P325
   Stone R, 2001, INT J HUM-COMPUT ST, V55, P699, DOI 10.1006/ijhc.2001.0497
   Tse E., 2007, COMPUTERS ENTERTAINM, V5, P12
   Turunen M, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P2551
   Wigdor D, 2011, BRAVE NUI WORLD: DESIGNING NATURAL USER INTERFACES FOR TOUCH AND GESTURE, P1
   Zyda M, 2005, COMPUTER, V38, P25, DOI 10.1109/MC.2005.297
NR 20
TC 2
Z9 2
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33041
EP 33068
DI 10.1007/s11042-019-07838-0
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600020
DA 2024-07-18
ER

PT J
AU Lu, TC
   Lu, YC
   Vo, TN
AF Lu, Tzu-Chuen
   Lu, Yu-Ching
   Thanh Nhan Vo
TI Dual-image based high image quality reversible hiding scheme with
   multiple folding zones
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dual-based reversible hiding scheme; Center-folding strategy;
   Steganalysis; Re-encoding; Multiple zones; StegExpose
ID DIFFERENCE EXPANSION
AB A dual-image technique is often used in reversible data hiding. In this technique, secret information is concealed within a host image to generate two stego-images. In 2015, Lu et al. proposed a center-folding strategy to enhance the performance of the reversible hiding scheme. In their scheme, the value range of the secret data is divided into two zones. The medium value is subtracted from each value of the value range to generate the folded value. The folded value is smaller than that of the original value such that the image quality of the stego-image can be increased. However, there is still room for improvement.
   This study proposes a novel method to further narrow down the folded value. The proposed scheme divides the value range into several zones instead of only two zones. Furthermore, the scheme re-encodes the secret information according to the number of zones and the maximum distortion between the stego-pixel and the host pixel. The re-encoded value is then separated into two parts and embedded in an image. Through this process, image quality can be significantly improved.
   The proposed scheme uses different zone sizes and the maximum distortion to control the hiding rate and image quality. The hiding rates of the proposed scheme with a zone size set at 12 and maximum distortion of each pixel set at 5 is 1.75 bit per pixel (bpp), and the image quality is 43.22 dB, which is higher than that of Lu et al.'s scheme, Lee et al.'s scheme, Chang's scheme and Wang's scheme. Using a similar hiding rate, the image quality of the proposed scheme has a higher embedding performance than that of the schemes of Xue et al., Arham et al., and Zhang et al.
C1 [Lu, Tzu-Chuen; Thanh Nhan Vo] Chaoyang Univ Technol, Dept Informat Management, 168 Jifeng East Rd, Taichung 41349, Taiwan.
   [Lu, Yu-Ching] Iwate Prefectural Univ, Sendai Fdn Appl Informat Sci, Fac Software Informat Sci, Sendai, Iwate, Japan.
C3 Chaoyang University of Technology
RP Lu, TC (corresponding author), Chaoyang Univ Technol, Dept Informat Management, 168 Jifeng East Rd, Taichung 41349, Taiwan.
EM s10614904@cyut.edu.tw; yuching1120@gmail.com; tclu@cyut.edu.tw
OI Lu, Tzu-Chuen/0000-0001-7305-4622
FU National Science Council (NSC), Taiwan, Republic of China
   [NSC107-2637-E-324 -004]; Chaoyang University of technology (CYUT);
   Higher Education Sprout Project, Ministry of Education, Taiwan
FX The authors gratefully acknowledge the financial support of this study
   from the National Science Council (NSC), Taiwan, Republic of China,
   under the Grant NSC107-2637-E-324 -004. This research is partially
   sponsored by Chaoyang University of technology (CYUT) and Higher
   Education Sprout Project, Ministry of Education, Taiwan, under the
   project: The R&D and the cultivation of talent for Health-promotion
   products. The authors also want to thank Prof. Goutam Chakraborty who
   give us a great help and served as scientific advisors.
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   Alaseri K., 2018, IJRDO J COMPUTER SCI, V4, P1
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   [Anonymous], 2018, J COMPUT SCI COMPUT, DOI DOI 10.20967/JCSCM.2018.03.002
   Arham A, 2017, SIGNAL PROCESS, V137, P52, DOI 10.1016/j.sigpro.2017.02.001
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Chang CC, 2008, P 2008 3 INT C INN C
   Chang CC, 2014, P INT INF HID MULT S
   Chang CC, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P145, DOI 10.1109/MUE.2009.35
   Chen GL, 2007, PROCEEDINGS OF THE 35TH INTERNATIONAL MATADOR CONFERENCE, P17, DOI 10.1007/978-1-84628-988-0_4
   Debasis G, 2016, ADV INTELL SYST, V434, P403, DOI 10.1007/978-81-322-2752-6_40
   Fan Wang, 2018, Procedia Computer Science, V131, P800, DOI 10.1016/j.procs.2018.04.265
   Gutub A, 2019, IMAGE BASED STEGANOG
   Gutub A, 2018, J COMPUTER HARDWARE, V1
   Jafar IF, 2016, SIGNAL PROCESS, V128, P98, DOI 10.1016/j.sigpro.2016.03.023
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Lee K.-H., 2009, P 3 INT C UB INF MAN, P228, DOI [10.1145/1516241.1516281.11T.-C, DOI 10.1145/1516241.1516281.11T.-C]
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   NI Z. C., 2003, CIRCUITS SYSTEMS VID, V16, P354
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wang WQ, 2018, SIGNAL PROCESS, V150, P102, DOI 10.1016/j.sigpro.2018.04.008
   Wang XP, 2008, J INNOV OPT HEAL SCI, V1, P151, DOI 10.1142/S1793545808000133
   Xue BW, 2017, MULTIMED TOOLS APPL, V76, P13473, DOI 10.1007/s11042-016-3763-x
   Yao H, 2017, SIGNAL PROCESS, V135, P26, DOI 10.1016/j.sigpro.2016.12.029
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
   Zheng QM, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2775038
   Zou LM, 2019, MULTIMED TOOLS APPL, V78, P7965, DOI 10.1007/s11042-018-6444-0
NR 33
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34397
EP 34435
DI 10.1007/s11042-019-07904-7
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800009
DA 2024-07-18
ER

PT J
AU Lumentut, JS
   Williem
   Park, IK
AF Lumentut, Jonathan Samuel
   Williem
   Park, In Kyu
TI 6-DOF motion blur synthesis and performance evaluation of light field
   deblurring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Light field; 6-DOF; Synthetic blur; Motion blur; Deblur
AB Motion deblurring is essential for reconstructing sharp images from given a blurry input caused by the camera motion. The complexity of this problem increases in a light field due to its depth-dependent blur constraint. A method of generating synthetic 3 degree-of-freedom (3-DOF) translation blur on a light field image without camera rotation has been introduced. In this study, we generate a camera translation and rotation (6-DOF) motion blur model that preserves the consistency of the light field image. Our experiment results show that the proposed blur model can maintain the parallax information (depth-dependent blur) in a light field image. Furthermore, we produce a synthetic blurry light field dataset based on the 6-DOF model. Finally, to validate the usability of the synthetic dataset, we conduct extensive benchmarking using state-of-the-art motion deblurring algorithms.
C1 [Lumentut, Jonathan Samuel; Park, In Kyu] Inha Univ, Dept Informat & Commun Engn, Incheon 22212, South Korea.
   [Williem] Bina Nusantara Univ, Sch Comp Sci, Dept Comp Sci, Jakarta 11480, Indonesia.
C3 Inha University; Universitas Bina Nusantara
RP Park, IK (corresponding author), Inha Univ, Dept Informat & Commun Engn, Incheon 22212, South Korea.
EM jlumentut@gmail.com; williem003@binus.ac.id; pik@inha.ac.kr
RI Park, In Kyu/B-5967-2013; Williem, Williem/O-6205-2019
OI Williem, Williem/0000-0002-2763-7883; Park, In Kyu/0000-0003-4774-7841;
   LUMENTUT, JONATHAN SAMUEL/0000-0001-5146-8648
FU Inha University Research Grant
FX This work was supported by Inha University Research Grant.
CR [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2010, IEEE INT C COMP VIS
   [Anonymous], P EUR C COMP VIS
   Bok Y, 2017, IEEE T PATTERN ANAL, V39, P287, DOI 10.1109/TPAMI.2016.2541145
   Chandramouli P, 2018, IEEE T IMAGE PROCESS, V27, P1723, DOI 10.1109/TIP.2017.2775062
   Cho D, 2013, IEEE I CONF COMP VIS, P3280, DOI 10.1109/ICCV.2013.407
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Dansereau DG, 2013, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2013.137
   Jia RX, 2015, BUILDSYS'15 PROCEEDINGS OF THE 2ND ACM INTERNATIONAL CONFERENCE ON EMBEDDED SYSTEMS FOR ENERGY-EFFICIENT BUILT, P109, DOI 10.1145/2821650.2830302
   Joshi N, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778767
   Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251
   Köhler R, 2012, LECT NOTES COMPUT SC, V7578, P27, DOI 10.1007/978-3-642-33786-4_3
   Kondermann D, 2016, IEEE COMPUT SOC CONF, P19, DOI 10.1109/CVPRW.2016.10
   Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521
   Lai WS, 2016, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2016.188
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Li X, 2012, IEEE C COMP INTEL FI, P1, DOI 10.1109/CIFEr.2012.6327833
   Mohan MRM, 2018, PROC CVPR IEEE, P6421, DOI 10.1109/CVPR.2018.00672
   Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180
   Pan JS, 2014, PROC CVPR IEEE, P2901, DOI 10.1109/CVPR.2014.371
   Sellent A, 2016, LECT NOTES COMPUT SC, V9906, P558, DOI 10.1007/978-3-319-46475-6_35
   Srinivasan PP, 2017, IEEE I CONF COMP VIS, P2262, DOI 10.1109/ICCV.2017.246
   Srinivasan Pratul P, 2017, P IEEE C COMP VIS PA, P3958
   Tai YW, 2011, IEEE T PATTERN ANAL, V33, P1603, DOI 10.1109/TPAMI.2010.222
   Wang TC, 2016, IEEE T PATTERN ANAL, V38, P2170, DOI 10.1109/TPAMI.2016.2515615
   Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7
   Williem, 2018, IEEE T PATTERN ANAL, V40, P2484, DOI 10.1109/TPAMI.2017.2746858
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
NR 30
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33723
EP 33746
DI 10.1007/s11042-019-08030-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600053
OA Bronze
DA 2024-07-18
ER

PT J
AU Silva, RA
   Pires, JM
   Datia, N
   Santos, MY
   Martins, B
   Birra, F
AF Silva, Ricardo Almeida
   Pires, Joao Moura
   Datia, Nuno
   Santos, Maribel Yasmina
   Martins, Bruno
   Birra, Fernando
TI Visual analytics for spatiotemporal events
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data visualization; Spatiotemporal patterns; Multiple levels of detail;
   Visual analytics
ID SPACE-TIME; SOCIAL MEDIA; EXPLORATION; PATTERNS; VISUALIZATION;
   VARIABLES; SYSTEM
AB Crimes, forest fires, accidents, infectious diseases, or human interactions with mobile devices (e.g., tweets) are being logged as spatiotemporal events. For each event, its geographic location, time and related attributes are known with high levels of detail (LoDs). The LoD plays a crucial role when analyzing data, as it can highlight useful patterns or insights and enhance the user' perception of phenomena. For this reason, modeling phenomena at different LoDs is needed to increase the analytical value of the data, as there is no exclusive LOD at which the data can be analyzed. Current practices work mainly on a single LoD of the phenomena, driven by the analysts' perception, ignoring that identifying the suitable LoDs is a key issue for pointing relevant patterns. This article presents a Visual Analytics approach called VAST, that allows users to simultaneously inspect a phenomenon at different LoDs, helping them to see in what LoDs do interesting patterns emerge, or in what LoDs the perception of the phenomenon is different. In this way, the analysis of vast amounts of spatiotemporal events is assisted, guiding the user in this process. The use of several synthetic and real datasets supported the evaluation and validation of VAST, suggesting LoDs with different interesting spatiotemporal patterns and pointing the type of expected patterns.
C1 [Silva, Ricardo Almeida; Datia, Nuno] Inst Politecn Lisboa, ISEL, Lisbon, Portugal.
   [Silva, Ricardo Almeida; Pires, Joao Moura; Datia, Nuno; Birra, Fernando] Univ Nova Lisboa, FCT, NOVA LINCS, Lisbon, Portugal.
   [Santos, Maribel Yasmina] Univ Minho, ALGORITMI Res Ctr, Braga, Portugal.
   [Martins, Bruno] Univ Lisbon, INESC ID, Lisbon, Portugal.
   [Martins, Bruno] Univ Lisbon, IST, Lisbon, Portugal.
C3 Polytechnic Institute of Lisbon; Universidade Nova de Lisboa;
   Universidade do Minho; Universidade de Lisboa; INESC-ID; Universidade de
   Lisboa
RP Datia, N (corresponding author), Inst Politecn Lisboa, ISEL, Lisbon, Portugal.; Datia, N (corresponding author), Univ Nova Lisboa, FCT, NOVA LINCS, Lisbon, Portugal.
EM datia@isel.pt
RI Datia, Nuno/R-7957-2016; Birra, Fernando/C-8253-2016; Moura Pires,
   Joao/D-5450-2013; Santos, Maribel Yasmina/M-5214-2013
OI Datia, Nuno/0000-0003-1600-0227; Birra, Fernando/0000-0002-4232-5079;
   Moura Pires, Joao/0000-0001-9933-936X; Santos, Maribel
   Yasmina/0000-0002-3249-6229
FU FCT - Fundacao para a Ciencia e Tecnologia MCTES [UID/CEC/04516/2013,
   UID/CEC/00319/2019, UID/CEC/50021/2019]; Fundação para a Ciência e a
   Tecnologia [UID/CEC/04516/2013] Funding Source: FCT
FX This work has been supported by FCT - Fundacao para a Ciencia e
   Tecnologia MCTES, UID/CEC/04516/2013 (NOVA LINCS), UID/CEC/00319/2019
   (ALGORITMI), and UID/CEC/50021/2019 (INESC-ID).
CR Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Almeida Silva Ricardo, 2015, International Journal of Business Intelligence and Data Mining, V10, P33
   Andrienko G, 2011, J VISUAL LANG COMPUT, V22, P213, DOI 10.1016/j.jvlc.2011.02.003
   Andrienko G., 2004, P WORK C ADV VIS INT, P417
   Andrienko G, 2013, COMPUT SCI ENG, V15, P72, DOI 10.1109/MCSE.2013.70
   Andrienko N, 2006, Exploratory Analysis of Spatial and Temporal Data: A Systematic Approach
   [Anonymous], 1984, MODIFIABLE AREAL UNI
   Bedard Y., 2007, DATA WAREHOUSES OLAP, P298
   Bertin J, 1983, IN PRESS
   Cardoso D, 2017, LECT NOTES COMPUT SC, V10409, P674, DOI 10.1007/978-3-319-62407-5_49
   Chae J, 2012, IEEE CONF VIS ANAL, P143, DOI 10.1109/VAST.2012.6400557
   Chen HC, 2004, COMPUTER, V37, P50, DOI 10.1109/MC.2004.1297301
   Cho I, 2016, IEEE T VIS COMPUT GR, V22, P210, DOI 10.1109/TVCG.2015.2467971
   Dykes J., 2005, Exploring geovisualization, V1
   Ebdon D., 1985, Statistics in geography
   Ferreira N, 2013, IEEE T VIS COMPUT GR, V19, P2149, DOI 10.1109/TVCG.2013.226
   Forlines C., 2010, Proceedings of the International Conference on Advanced Visual Interfaces, AVI '10, P33, DOI DOI 10.1145/1842993.1843000
   Fuchs G, 2004, IEEE INFOR VIS, P139, DOI 10.1109/IV.2004.1320136
   Gabriel E, 2014, METHODOL COMPUT APPL, V16, P411, DOI 10.1007/s11009-013-9358-3
   Gabriel E, 2013, J STAT SOFTW, V53, P1
   Gao YZ, 2018, INT J GEOGR INF SCI, V32, P425, DOI 10.1080/13658816.2017.1406943
   Gatalsky P, 2004, IEEE INFOR VIS, P145, DOI 10.1109/IV.2004.1320137
   GETIS A, 1992, GEOGR ANAL, V24, P189, DOI 10.1111/j.1538-4632.1992.tb00261.x
   GEURTS M, 1977, J MARKETING RES, V14, P269, DOI 10.2307/3150485
   Goodwin S, 2016, IEEE T VIS COMPUT GR, V22, P599, DOI 10.1109/TVCG.2015.2467199
   Guo DS, 2006, IEEE T VIS COMPUT GR, V12, P1461, DOI 10.1109/TVCG.2006.84
   Hadlak S, 2010, INT J GEOGR INF SCI, V24, P1497, DOI 10.1080/13658816.2010.510840
   Hering AS, 2009, ENVIRON ECOL STAT, V16, P225, DOI 10.1007/s10651-007-0080-6
   Jacquez GM, 1996, STAT MED, V15, P1935, DOI 10.1002/(SICI)1097-0258(19960930)15:18<1935::AID-SIM406>3.0.CO;2-I
   Kapler T, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P25, DOI 10.1109/INFVIS.2004.27
   Keim D, 2008, LECT NOTES COMPUT SC, V4950, P154, DOI 10.1007/978-3-540-70956-5
   Kisilevich S, 2010, IEEE INT CONF INF VI, P289, DOI 10.1109/IV.2010.94
   KNOX EG, 1964, ROY STAT SOC C-APP, V13, P25
   Kraak M.J., 2003, Cartography: Visualisation of Spatial Data
   Lahouari K., 2014, Representer les dynamiques des territoires: un etat des lieux, de nouveaux enjeux
   Leipnik M.R., 2003, GIS LAW ENFORCEMENT
   Li HB, 2016, J VISUAL-JAPAN, V19, P529, DOI 10.1007/s12650-015-0327-5
   Li MZ, 2018, J VISUAL LANG COMPUT, V45, P1, DOI 10.1016/j.jvlc.2018.02.001
   Li SN, 2016, ISPRS J PHOTOGRAMM, V115, P119, DOI 10.1016/j.isprsjprs.2015.10.012
   Lins L, 2013, IEEE T VIS COMPUT GR, V19, P2456, DOI 10.1109/TVCG.2013.179
   MacEachren A. M., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P181, DOI 10.1109/VAST.2011.6102456
   Maciejewski R, 2010, IEEE T VIS COMPUT GR, V16, P205, DOI 10.1109/TVCG.2009.100
   Malik A., 2010, 2010 IEEE International Conference on Technologies for Homeland Security (HST 2010), P222, DOI 10.1109/THS.2010.5655057
   MANTEL N, 1967, CANCER RES, V27, P209
   Miller HJ, 2009, CHAPMAN HALL CRC DAT
   Moller J, 2010, TECH REP
   MORAN PAP, 1950, BIOMETRIKA, V37, P17, DOI 10.1093/biomet/37.1-2.17
   Nelson JK, 2017, CARTOGR GEOGR INF SC, V44, P35, DOI 10.1080/15230406.2015.1093431
   Ostfeld RS, 2005, TRENDS ECOL EVOL, V20, P328, DOI 10.1016/j.tree.2005.03.009
   Robinson A. C., 2016, CARTOGR GEOGR INF SC, P1
   Roddick J.F., 1999, SIGKDD EXPLORATIONS, V1, P34, DOI DOI 10.1145/846170.846173
   Scherr M., 2008, Trends in Information Visualization, V38, P1
   Shanbhag P, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P211, DOI 10.1109/INFVIS.2005.1532149
   Shekhar S, 2015, ISPRS INT J GEO-INF, V4, P2306, DOI 10.3390/ijgi4042306
   Silva R., 2016, LECT NOTES GEOINFORM, DOI [10.1007/978-3-319-33783-813, DOI 10.1007/978-3-319-33783-813]
   Silva R, 2012, INT J DATA WAREHOUS, V8, P23, DOI 10.4018/jdwm.2012040102
   Silva RA, 2015, LECT NOTES GEOINF CA, P291, DOI 10.1007/978-3-319-16787-9_17
   Sips M, 2012, IEEE T VIS COMPUT GR, V18, P2899, DOI 10.1109/TVCG.2012.191
   Swedberg B., 2016, GEOINFORMATICA, P1
   Swedberg B, 2017, CARTOGRAPHICA, V52, P63, DOI 10.3138/cart.52.1.3820
   Thakur S, 2009, LECT NOTES COMPUT SC, V5876, P929, DOI 10.1007/978-3-642-10520-3_89
   Thom D, 2012, IEEE PAC VIS SYMP, P41, DOI 10.1109/PacificVis.2012.6183572
   Tominski C, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P175, DOI 10.1109/IV.2005.3
   Tominski C., 2012, Vision, Modeling, and Visualization, P199, DOI DOI 10.2312/PE/VMV/VMV12/199-206
   Tversky B, 2002, INT J HUM-COMPUT ST, V57, P247, DOI 10.1006/ijhc.1017
   Wang DW, 2013, COMPUT ENVIRON URBAN, V39, P93, DOI 10.1016/j.compenvurbsys.2013.01.008
   Weaver C, 2010, IEEE T VIS COMPUT GR, V16, P192, DOI 10.1109/TVCG.2009.94
   Yao JT, 2013, IEEE T CYBERNETICS, V43, P1977, DOI 10.1109/TSMCC.2012.2236648
   Yin JJ, 2016, ISPRS INT J GEO-INF, V5, DOI 10.3390/ijgi5100187
   Zhang LS, 2012, IEEE CONF VIS ANAL, P173, DOI 10.1109/VAST.2012.6400554
NR 70
TC 4
Z9 4
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 32805
EP 32847
DI 10.1007/s11042-019-08012-2
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600011
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU García-Lamont, F
   Cervantes, J
   López-Chau, A
   Ruiz-Castilla, S
AF Garcia-Lamont, Farid
   Cervantes, Jair
   Lopez-Chau, Asdrubal
   Ruiz-Castilla, Sergio
TI Color image segmentation using saturated RGB colors and decoupling the
   intensity from the hue
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RGB space; Color image segmentation; Self-organizing maps; Otsu method
ID C-MEANS; ALGORITHM; RECOGNITION; FRAMEWORK; NETWORKS; FEATURES; MODEL
AB Although the RGB space is accepted to represent colors, it is not adequate for color processing. In related works the colors are usually mapped to other color spaces more suitable for color processing, but it may imply an important computational load because of the non-linear operations involved to map the colors between spaces; nevertheless, it is common to find in the state-of-the-art works using the RGB space. In this paper we introduce an approach for color image segmentation, using the RGB space to represent and process colors; where the chromaticity and the intensity are processed separately, mimicking the human perception of color, reducing the underlying sensitiveness to intensity of the RGB space. We show the hue of colors can be processed by training a self-organizing map with chromaticity samples of the most saturated colors, where the training set is small but very representative; once the neural network is trained it can be employed to process any given image without training it again. We create an intensity channel by extracting the magnitudes of the color vectors; by using the Otsu method, we compute the threshold values to divide the intensity range in three classes. We perform experiments with the Berkeley segmentation database; in order to show the benefits of our proposal, we perform experiments with a neural network trained with different colors by subsampling the RGB space, where the chromaticity and the intensity are processed jointly. We evaluate and compare quantitatively the segmented images obtained with both approaches. We claim to obtain competitive results with respect to related works.
C1 [Garcia-Lamont, Farid; Cervantes, Jair; Ruiz-Castilla, Sergio] Univ Autonoma Estado Mexico, Ctr Univ UAEM Texcoco, Av Jardin Zumpango S-N, Texcoco 56259, Estado De Mexic, Mexico.
   [Lopez-Chau, Asdrubal] Univ Autonoma Estado Mexico, Ctr Univ UAEM Zumpango, Camino Viejo Jilotzingo Continuac Calle Rayon, Zumpango 55600, Estado De Mexic, Mexico.
RP García-Lamont, F (corresponding author), Univ Autonoma Estado Mexico, Ctr Univ UAEM Texcoco, Av Jardin Zumpango S-N, Texcoco 56259, Estado De Mexic, Mexico.
EM fgarcial@uaemex.mx; chazarra17@gmail.com; alchau@uaemex.mx;
   jsergioruizc@gmail.com
RI Cervantes, Jair/N-2617-2013; García-Lamont, Farid/B-4009-2016; Lopez
   Chau, Asdrubal/B-7737-2016
OI García-Lamont, Farid/0000-0002-9739-3802; Lopez Chau,
   Asdrubal/0000-0001-5254-0939
CR Bayá AE, 2017, EXPERT SYST APPL, V86, P258, DOI 10.1016/j.eswa.2017.05.064
   Behroozi-Khazaei N, 2017, COMPUT ELECTRON AGR, V142, P41, DOI 10.1016/j.compag.2017.08.025
   Bhavana N, 2013, IJCA P INT C GREEN C, P15
   Chakraborty BK, 2017, PATTERN RECOGN LETT, V88, P33, DOI 10.1016/j.patrec.2017.01.005
   Chang DX, 2016, PATTERN RECOGN, V60, P334, DOI 10.1016/j.patcog.2016.05.008
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chen W, 2016, MULTIMED TOOLS APPL, V75, P839, DOI 10.1007/s11042-014-2328-0
   Chen XM, 2013, J REAL-TIME IMAGE PR, V8, P35, DOI 10.1007/s11554-011-0222-9
   Huynh DT, 2019, FUTURE GENER COMP SY, V92, P1131, DOI 10.1016/j.future.2017.07.056
   Dubey SR, 2016, SIGNAL IMAGE VIDEO P, V10, P819, DOI 10.1007/s11760-015-0821-1
   El Joumani S, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0161-2
   Garcia-Lamont F, 2018, NEUROCOMPUTING, V292, P1, DOI 10.1016/j.neucom.2018.01.091
   Garcia-Zapirain B, 2017, COMPUT BIOL MED, V90, P137, DOI 10.1016/j.compbiomed.2017.09.015
   Gharieb RR, 2017, SIGNAL IMAGE VIDEO P, V11, P541, DOI 10.1007/s11760-016-0992-4
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hassan G, 2018, SIGNAL IMAGE VIDEO P, V12, P263, DOI 10.1007/s11760-017-1154-z
   Heidary K, 2014, SIGNAL IMAGE VIDEO P, V8, P1245, DOI 10.1007/s11760-012-0349-6
   Hettiarachchi R, 2017, PATTERN RECOGN, V65, P119, DOI 10.1016/j.patcog.2016.12.011
   Kermani S, 2015, OPTIK, V126, P3288, DOI 10.1016/j.ijleo.2015.08.007
   Khan A, 2015, APPL SOFT COMPUT, V32, P300, DOI 10.1016/j.asoc.2015.03.029
   Khan A, 2014, SIGNAL IMAGE VIDEO P, V8, P1233, DOI 10.1007/s11760-012-0347-8
   Khelifi L, 2017, INFORM FUSION, V38, P104, DOI 10.1016/j.inffus.2017.03.001
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Lézoray O, 2009, PATTERN RECOGN LETT, V30, P397, DOI 10.1016/j.patrec.2008.11.005
   Li KQ, 2018, PATTERN RECOGN, V76, P69, DOI 10.1016/j.patcog.2017.10.023
   Li ZG, 2012, PROC CVPR IEEE, P789, DOI [10.1109/CVPR.2012.6247750, 10.1109/ISRA.2012.6219309]
   Liang BM, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/464875
   Liang LM, 2017, CHEMOMETR INTELL LAB, V171, P259, DOI 10.1016/j.chemolab.2017.10.011
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   López-Rubio FJ, 2016, NEURAL PROCESS LETT, V43, P345, DOI 10.1007/s11063-015-9431-8
   Medeiros RS, 2013, INT CONF ACOUST SPEE, P1464, DOI 10.1109/ICASSP.2013.6637894
   Mignotte M, 2014, PATTERN ANAL APPL, V17, P129, DOI 10.1007/s10044-012-0272-z
   Ong SH, 2002, IMAGE VISION COMPUT, V20, P279, DOI 10.1016/S0262-8856(02)00021-5
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Rajaby E, 2016, DIGIT SIGNAL PROCESS, V51, P170, DOI 10.1016/j.dsp.2016.01.010
   Rajinikanth V, 2015, PROCEDIA COMPUT SCI, V46, P1449, DOI 10.1016/j.procs.2015.02.064
   Safuan SNM, 2018, MEASUREMENT, V116, P543, DOI 10.1016/j.measurement.2017.11.002
   Schu G, 2018, EXPERT SYST APPL, V98, P57, DOI 10.1016/j.eswa.2017.12.045
   Sridevi M, 2019, NEURAL COMPUT APPL, V31, P865, DOI 10.1007/s00521-017-3045-1
   Tan KS, 2013, APPL SOFT COMPUT, V13, P2017, DOI 10.1016/j.asoc.2012.11.038
   Tan KS, 2011, PATTERN RECOGN, V44, P1, DOI 10.1016/j.patcog.2010.07.013
   Wang JD, 2014, IEEE T IMAGE PROCESS, V23, P1909, DOI 10.1109/TIP.2014.2307479
   Wang XF, 2015, IEEE T IMAGE PROCESS, V24, P1399, DOI 10.1109/TIP.2015.2397313
   Wang Y, 2016, STEM CELLS INT, V2016, DOI 10.1155/2016/9313425
   Xiao QK, 2018, MULTIMED TOOLS APPL, V77, P6955, DOI 10.1007/s11042-017-4614-0
   Xiao QK, 2015, SOFT COMPUT, V19, P133, DOI 10.1007/s00500-014-1237-5
   Xiao QK, 2014, MULTIMED TOOLS APPL, V72, P951, DOI 10.1007/s11042-013-1416-x
   Xiao QK, 2011, NEUROCOMPUTING, V74, P3486, DOI 10.1016/j.neucom.2011.06.002
   Yin SB, 2017, PATTERN RECOGN, V68, P245, DOI 10.1016/j.patcog.2017.03.012
   You XG, 2011, PATTERN RECOGN, V44, P2314, DOI 10.1016/j.patcog.2011.01.007
   Zhang LG, 2017, MACH VISION APPL, V28, P293, DOI 10.1007/s00138-017-0833-7
   Zhang SW, 2019, NEURAL COMPUT APPL, V31, P1225, DOI 10.1007/s00521-017-3067-8
   Zhou ZP, 2018, MULTIMED TOOLS APPL, V77, P15139, DOI 10.1007/s11042-017-5096-9
NR 54
TC 4
Z9 5
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1555
EP 1584
DI 10.1007/s11042-019-08278-6
EA NOV 2019
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000494628400001
OA Green Published
DA 2024-07-18
ER

PT J
AU Bhatti, Z
AF Bhatti, Zeeshan
TI Oscillator driven central pattern generator (CPG) system for procedural
   animation of quadruped locomotion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quadruped; Animation; Oscillator; Procedural animation; Central pattern
   generator; Quadruped locomotion
ID ANIMALS
AB In this paper a procedural animation framework is developed and discussed, which consists of a oscillator based Central Pattern Generator (CPG) system. This CPG based animation model is able to produce coupled leg oscillation derived through user-controlled parameters, producing in-phase and out-of-phase leg swing motion curves. Each leg has a separate CPG unit that is able to generate and control the swing and stance phases of each gait cycle with couple oscillation, having a time shift in correspondence to each leg, in a permuted symmetry. The dynamic motion is calculated independently for each body part with user interaction and control over the speed, frequency and oscillation of body parts individually, during runtime, for high divergence control of the simulation. The user can manipulate the simulation parameters for leg impact phases and duration at runtime and the system will automatically adjust the motion gaits and transitions between each gait at runtime. This procedural model for animating quadrupeds can generate various locomotion gaits with varying speed and footfall patterns dynamically. The various gaits produced by the CPG system are, walk, trot, gallop, canter, pace, pronk and rack. Various gait and footfall timing test are performed to test and validate the motion, along with a study of user's perception test to determine a Visual Mean Opinion Score (VMOS) of the believability and accuracy of the generated animation with statistical significance.
C1 [Bhatti, Zeeshan] Univ Sindh, Inst Informat & Commun Technol, Jamshoro, Pakistan.
C3 University of Sindh
RP Bhatti, Z (corresponding author), Univ Sindh, Inst Informat & Commun Technol, Jamshoro, Pakistan.
EM zeeshan.bhatti@usindh.edu.pk
RI Bhatti, Zeeshan/JGC-7341-2023
OI Bhatti, Zeeshan/0000-0002-5462-6696
CR Agarwala A, 2004, ACM T GRAPHIC, V23, P584, DOI 10.1145/1015706.1015764
   Bhatti J, 2013, IEEE INT CONF ROBOT, P1, DOI 10.1109/ICRA.2013.6630548
   Bhatti Z, 2016, AFR J INF COMMUN TEC, V10, P131
   Bhatti Z., 2013, P VRCAI 2013 12 ACM, P139
   Bhatti Z, 2017, BAHRIA U J INFORM CO, V10
   Bhatti Z, 2015, ASIAN J SCI RES, V8, P165, DOI [10.3923/ajsr.2015.165.181, DOI 10.3923/ajsr.2015.165.181]
   Bhatti Z, 2013, 2013 INTERNATIONAL CONFERENCE ON INFORMATICS AND CREATIVE MULTIMEDIA (ICICM), P104, DOI 10.1109/ICICM.2013.25
   Castellini H, 2005, PRAMANA-J PHYS, V64, P525, DOI 10.1007/BF02706200
   Coros S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964954
   Cureton SM, 2013, USING FOURIER ANAL G
   Curtis Sean, 2011, Motion in Games. Proceedings 4th International Conference, MIG 2011, P400, DOI 10.1007/978-3-642-25090-3_34
   de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697
   Fukuoka Y, 2013, BIOL CYBERN, V107, P695, DOI 10.1007/s00422-013-0572-4
   Gibson D. P., 2005, P 2005 ACM SIGGRAPH, P39
   Griffin TM, 2004, J EXP BIOL, V207, P3545, DOI 10.1242/jeb.01177
   Hecker C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360626
   Ijspeert AJ, 2008, NEURAL NETWORKS, V21, P642, DOI 10.1016/j.neunet.2008.03.014
   Johansen RS, 2009, AUTOMATED SEMI PROCE
   Kry PG, 2009, COMPUT GRAPH FORUM, V28, P289, DOI 10.1111/j.1467-8659.2009.01368.x
   Liu CJ, 2009, IEEE SYS MAN CYBERN, P2368, DOI 10.1109/ICSMC.2009.5346399
   Marhefka DW, 2003, IEEE-ASME T MECH, V8, P446, DOI 10.1109/TMECH.2003.820001
   Morel Y, 2011, IEEE DECIS CONTR P, P6331, DOI 10.1109/CDC.2011.6160419
   Morimoto J, 2007, IEEE-RAS INT C HUMAN, P596, DOI 10.1109/ICHR.2007.4813932
   Ramanan D, 2006, IEEE T PATTERN ANAL, V28, P1319, DOI 10.1109/TPAMI.2006.155
   Skrba L, 2009, COMPUT GRAPH FORUM, V28, P1541, DOI 10.1111/j.1467-8659.2008.01312.x
   Tolani D, 2000, GRAPH MODELS, V62, P353, DOI 10.1006/gmod.2000.0528
   Wampler K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531366
   Yamamoto S, 2000, COMPUT PHYS COMMUN, V125, P1, DOI 10.1016/S0010-4655(99)00456-7
   Yang Z, 2014, LEGGED CENTRAL PATTE, P4
   Zajac J, 2003, P CESCG 03 CENTR EUR, P1
NR 30
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30485
EP 30502
DI 10.1007/s11042-019-7641-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200047
DA 2024-07-18
ER

PT J
AU Bonillo, C
   Marco, J
   Cerezo, E
AF Bonillo, Clara
   Marco, Javier
   Cerezo, Eva
TI Developing pervasive games in interactive spaces: the JUGUEMOS toolkit
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pervasive games; Interactive spaces; Toolkits; TUIML
AB The progress in the development of pervasive games is slowing down because of the multiple challenges that these games brings to developers, due to the great variety of interaction paradigms that this kind of games involve and the difficulties of developing applications where so many innovative technologies converge. In this article we present JUGUEMOS, a toolkit aimed at developers to help them in the creation of pervasive games for Interactive Spaces. The toolkit addresses three challenges that arise when developing pervasive games: the integration of heterogeneous devices, the management of multiple displays and the facilitation of the game coding. The toolkit is based on the TUIML modeling language that allows defining games easily, reducing the impact of the coding between iterations. The toolkit also makes use of the OSC Protocol to interconnect the different devices. Detailed descriptions of the toolkit design decisions, architecture and implementation are presented, together with three different case studies carried out in order to explore the toolkit expressivity, its capability to support collaborative multidisciplinary experiences, and its potential to support interactive experiences outside our Interactive Space. We hope this work would contribute to the spread of pervasive games in interactive spaces.
C1 [Bonillo, Clara] Univ Zaragoza, Dept Comp Sci, Adv Interfaces Grp, AffectiveLab, Ed Ada Byron,C Maria de Luna 1, Zaragoza 50015, Spain.
   [Marco, Javier] ESDA, C Maria Zambrano 3, Zaragoza 50018, Spain.
   [Cerezo, Eva] Univ Zaragoza, Engn Res Inst Aragon I3A, Dept Comp Sci, Adv Interfaces Grp,AffectiveLab, Ed Ada Byron,C Maria de Luna 1, Zaragoza 50015, Spain.
C3 University of Zaragoza; University of Zaragoza
RP Bonillo, C (corresponding author), Univ Zaragoza, Dept Comp Sci, Adv Interfaces Grp, AffectiveLab, Ed Ada Byron,C Maria de Luna 1, Zaragoza 50015, Spain.
EM clarabf@unizar.es; jmarco@esda.es; ecerezo@unizar.es
RI Cerezo, Eva/L-6095-2014
OI Cerezo, Eva/0000-0003-4424-0770; Marco Murria, Julio/0000-0001-9960-8945
FU Spanish Government; European Union [TIN2015-67149-C3-1R]; Aragonese
   Government; European Union through the FEDER 2014-2020 "Construyendo
   Europa desde Aragon" action [T25_17D]
FX We want to thank Belen Cebrian, Alejandro Navarro, the students and
   tutors of the School of Arts of Plymouth, the students and tutors of the
   EINA, the ESDA staff, and the Cesar-Etopia laboratories, for making this
   work possible. This work has been partly financed by the Spanish
   Government and the European Union through the contract
   TIN2015-67149-C3-1R (MINECO/ FEDER) and by the Aragonese Government and
   the European Union through the FEDER 2014-2020 "Construyendo Europa
   desde Aragon" action (Group T25_17D).
CR [Anonymous], 2009, PERVASIVE GAMES THEO
   [Anonymous], P 1 AUGM HUM INT C M
   [Anonymous], 2016, PROCEEDINGS OF THE 2
   Arango D, 2017, ORTHOP REV, V9, DOI 10.4081/or.2017.7067
   Guo B, 2008, INT J SEMANT COMPUT, V2, P469, DOI 10.1142/S1793351X08000555
   Bobick AF, 1999, PRESENCE-VIRTUAL AUG, V8, P369, DOI 10.1162/105474699566297
   Borchers J, 2006, WORKSH INF VIS INT T, V6
   Cerezo E., 2015, MORE PLAYFUL USER IN, P17, DOI [10.1007/978-981-287-546-4_2, DOI 10.1007/978-981-287-546-4_2]
   Chalmers M., 2005, P 2005 ACM SIGCHI IN, P306, DOI [DOI 10.1145/1178477.1178533, 10.1145/1178477.1178533]
   Cheok AD, 2002, PERS UBIQUIT COMPUT, V6, P430, DOI 10.1007/s007790200047
   Dionisio M, 2015, P 2015 INT C INT TAB, P401
   Flintham M., 2003, Proceedings of the SIGCHI conference on Human factors in computing systems, P569
   Gatti E, 2017, 2017 IEEE WORLD HAPTICS CONFERENCE (WHC), P430, DOI 10.1109/WHC.2017.7989940
   Guo B, 2012, MULTIMED TOOLS APPL, V59, P259, DOI 10.1007/s11042-010-0711-z
   Hornecker E, 2006, P SIGCHI C HUM FACT, P437, DOI [10.1145/1124772.1124838, DOI 10.1145/1124772.1124838]
   Jetter HC, 2014, PERS UBIQUIT COMPUT, V18, P1139, DOI 10.1007/s00779-013-0725-4
   Kaltenbrunner M., 2007, TEI'07 Proceedings, P69
   Kato H., 2007, 1 IEEE INT WORKSH AU
   Khoo ET, 2008, INT J VIRTUAL REAL, V5, P45
   Krzywinski A, 2009, P INT C ADV COMP ENT, P107
   Lahlou S, 2009, COMPUT SUPP COOP WOR, P1
   Magerkurth C., 2005, Computer in Entertainment (CIE), V3, P4
   Magerkurth C., 2006, Proceedings of the 2006 ACM SIGCHI international conference on Advances in computer entertainment technology, P15
   Magielse R, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2181
   MALONE TW, 1981, COGNITIVE SCI, V5, P333, DOI 10.1207/s15516709cog0504_2
   Marco J., 2012, Proceedings of the 4th ACM SIGCHI Symposium on Engineering Interactive Computing Systems, EICS '12, P71, DOI [10.1145/2305484.2305498, DOI 10.1145/2305484.2305498]
   Martins T, 2009, P INT C ADV COMP ENT, P446
   Montola M., 2005, Proc. DAC, V1966, P16
   Mora S, 2015, MAKE2LEARN ICEC, P21
   Morreale F, 2014, PERS UBIQUIT COMPUT, V18, P1187, DOI 10.1007/s00779-013-0728-1
   Myers B., 2000, ACM Transactions on Computer-Human Interaction, V7, P3, DOI 10.1145/344949.344959
   Nacenta M.A., 2005, P ACM C HUMAN FACTOR, P371, DOI DOI 10.1145/1054972.1055024
   Park JW, 2017, MULTIMED TOOLS APPL, V76, P17385, DOI 10.1007/s11042-017-4589-x
   Satyanarayanan M, 2001, IEEE PERS COMMUN, V8, P10, DOI 10.1109/98.943998
   Shaer O, 2004, PERS UBIQUIT COMPUT, V8, P359, DOI 10.1007/s00779-004-0298-3
   Shaer O, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1614390.1614395
   Soute I., 2013, P 12 INT C INT DES C, P74, DOI 10.1145/2485760.2485779
   Soute I, 2017, ACM T COMPUT-HUM INT, V24, DOI 10.1145/3105704
   Ullmer B, 2000, IBM SYST J, V39, P915, DOI 10.1147/sj.393.0915
   Ullmer B., 2005, ACM Transactions on Computer-Human Interaction, V12, P81, DOI 10.1145/1057237.1057242
   Wright M., 2005, Organised Sound, V10, P193
   Yamabe T, 2013, MULTIMED TOOLS APPL, V62, P259, DOI 10.1007/s11042-011-0979-7
   Yamaguchi S, 1999, CHEM LETT, P399
   Yanagida Y, 2004, P IEEE VIRT REAL ANN, P43, DOI 10.1109/VR.2004.1310054
NR 44
TC 3
Z9 3
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32261
EP 32305
DI 10.1007/s11042-019-07983-6
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000054
DA 2024-07-18
ER

PT J
AU Han, KY
   Xiao, GR
   Yang, XC
AF Han, Kaiyan
   Xiao, Guorong
   Yang, Xingchun
TI RETRACTED: An effective stadium monitoring control algorithm based on
   big data in emerging mobile networks (Retracted article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Emerging mobile networks; Big data; Effective stadium monitoring control
   algorithm; Topology control
ID WIND
AB In the process of monitoring the gymnasium by the traditional radio frequency technology, the parallel computing problem of the large data environment in the gymnasium monitoring cannot be handled effectively. It cannot be identified independently and accurately, and the gymnasium monitoring algorithm based on large data is proposed. In the process of Map-Reduce parallel monitoring based on AE, off-line training of monitoring image recognition model based on AE and neural network is carried out. Through the weighted fusion algorithm of trajectory correction, the best data fusion result is obtained, and the offline training recognition model is used to identify the image information. In parallel monitoring, if there is a correlation between the monitoring events, the Map function is used to read the test sample data, and the mapping of the corresponding key values is obtained. The mapping records generated by the Map function are performed by the Reduce function to obtain the monitoring and identification results of the gymnasium. The experimental results show that the proposed algorithm can accurately and efficiently identify the monitoring images of the gymnasium.
C1 [Han, Kaiyan] Jiujiang Univ, Phys Coll, Jiujiang 332005, Peoples R China.
   [Xiao, Guorong] Guangdong Univ Finance, Guangdong Prov Key Lab Technol & Finance & Big Da, Guangzhou 510521, Guangdong, Peoples R China.
   [Yang, Xingchun] Sichuan Police Coll, Comp Sci & Technol, Luzhou 646000, Sichuan, Peoples R China.
C3 Jiujiang University; Guangdong University of Finance; Sichuan Police
   College
RP Xiao, GR (corresponding author), Guangdong Univ Finance, Guangdong Prov Key Lab Technol & Finance & Big Da, Guangzhou 510521, Guangdong, Peoples R China.
EM zuowei3314@163.com; newducky@126.com; yangxc2004@163.com
FU Guangdong Provincial Key Laboratory of Technology and Finance & Big Data
   Analysis [2017B030301010]; Platform of Credit Financing and Trade for
   Guangdong Technological Enterprises [2014B080807035]; Construction of
   New Technology Credit Service Platform Based on O2O Mode
   [2017B080802004]; Guangdong Key Research Base of Technology and Finance
   [2014B030303005]; Guangdong Technology & Finance Information Service
   Platform [2015B080807015]
FX This work was supported by Guangdong Provincial Key Laboratory of
   Technology and Finance & Big Data Analysis (Grant No.2017B030301010);
   Platform of Credit Financing and Trade for Guangdong Technological
   Enterprises (Grant No.2014B080807035); Construction of New Technology
   Credit Service Platform Based on O2O Mode (Grant No.2017B080802004);
   Guangdong Key Research Base of Technology and Finance (Grant
   No.2014B030303005); Guangdong Technology & Finance Information Service
   Platform (Grant No.2015B080807015).
CR [Anonymous], MULTIBODY SYST DYN
   Biswas SS, 2015, IEEE T IND ELECTRON, V62, P3822, DOI 10.1109/TIE.2014.2362498
   Chaouch N, 2014, HYDROL PROCESS, V28, P62, DOI 10.1002/hyp.9548
   Chaudhry SA, 2017, CLUSTER COMPUT, V20, P1223, DOI 10.1007/s10586-017-0783-x
   Czaplewski RL, 2015, SENSORS-BASEL, V15, P23589, DOI 10.3390/s150923589
   Fan QF, 2016, INFORM SCIENCES, V367, P550, DOI 10.1016/j.ins.2016.06.049
   Lin B, 2016, IEEE T NETW SERV MAN, V13, P581, DOI 10.1109/TNSM.2016.2554143
   [马秋芳 Ma Qiufang], 2015, [计算机仿真, Computer Simulation], V32, P439
   Malik OA, 2015, IEEE-ASME T MECH, V20, P2328, DOI 10.1109/TMECH.2014.2376199
   Martins N, 2014, ENG STRUCT, V59, P80, DOI 10.1016/j.engstruct.2013.10.021
   Matthews MW, 2015, REMOTE SENS ENVIRON, V156, P374, DOI 10.1016/j.rse.2014.10.010
   Nabavi S, 2015, IEEE T SMART GRID, V6, P2529, DOI 10.1109/TSG.2015.2406578
   Sapundjiev D, 2014, ADV SPACE RES, V53, P71, DOI 10.1016/j.asr.2013.09.037
   Siegel D, 2014, WIND ENERGY, V17, P695, DOI 10.1002/we.1585
   Toté C, 2015, REMOTE SENS-BASEL, V7, P1758, DOI 10.3390/rs70201758
   Vinel A, 2016, IEEE WIREL COMMUN, V23, P8, DOI 10.1109/MWC.2016.7721735
   Xu S, 2016, J INTERNET TECHNOL, V17, P1151, DOI 10.6138/JIT.2016.17.6.20161007
   Yang DX, 2017, ADV ATMOS SCI, V34, P965, DOI 10.1007/s00376-017-6221-4
   Zheng HF, 2018, IEEE T SYST MAN CY-S, V48, P2315, DOI 10.1109/TSMC.2017.2734886
   Zhou CJ, 2015, IEEE T SYST MAN CY-S, V45, P647, DOI 10.1109/TSMC.2014.2384480
NR 20
TC 6
Z9 6
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 29971
EP 29987
DI 10.1007/s11042-018-6688-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200019
DA 2024-07-18
ER

PT J
AU Janakiraman, S
   Thenmozhi, K
   Rayappan, JBB
   Amirtharajan, R
AF Janakiraman, Siva
   Thenmozhi, K.
   Rayappan, John Bosco Balaguru
   Amirtharajan, Rengarajan
TI Indicator-based lightweight steganography on 32-bit RISC architectures
   for IoT security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Lightweight; Microcontroller; IoT security
ID ENCRYPTION ALGORITHM; IMAGE STEGANOGRAPHY; IMPLEMENTATION; HARDWARE;
   STEGO
AB Embedded devices with highly constrained resources are emerging in numerous application areas which include wireless sensor networks, Radio-Frequency IDentification (RFID) tags, and Internet of Things (IoT). These devices need to typically communicate small payload in the form of text/image/audio for which security is exceptionally essential. Considering the resource limitation on constrained devices, many crypto algorithms and a few stego algorithms have been designed with lightweight properties. Majority of these algorithms have been tested for lightweight property only based on their algorithmic attributes. Conversely, ensuring such lightweight characteristics by analysing their feasibility to reside and run in a constrained environment based on the device's architectural attribute is inevitable for IoT applications. This paper aims to contribute by proposing an indicator based lightweight Least Significant Bit (LSB) steganography algorithm and to compare it's algorithmic and device dependent implementation aspects with similar algorithms on popular 32-bit Reduced Instruction Set Computer (RISC) microcontrollers used in IoT platforms. The proposed variable embedding algorithm achieves a Peak Signal to Noise Ratio (PSNR) of over 46 dB with Normalised Cross Correlation (NCC) & Structural Similarity Index Measure (SSIM) being 0.9999 and 0.9998 respectively for an average embedding capacity of 1.5 bits per pixel. In addition to the above mentioned benchmarking parameter results, the Regular & Singular (RS) group and Sample Pair (SP) steganalysis, were also carried out to validate the security level of the proposed algorithm. On analysing the suitability of the proposed algorithm in terms of timing performance and memory requirements by implementing on different IoT hardware, the microcontroller with PIC32 core achieves a higher embedding throughput of over 2.7 Mega bits per second with a smaller memory footprint of less than 2 KB. Finally, the results obtained from the proposed work outperform the microcontroller implementation of stego algorithms reported in the literature.
C1 [Janakiraman, Siva; Thenmozhi, K.; Rayappan, John Bosco Balaguru; Amirtharajan, Rengarajan] SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Amirtharajan, R (corresponding author), SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur, Tamil Nadu, India.
EM amir@ece.sastra.edu
RI Amirtharajan, Rengarajan/C-6471-2011; Janakiraman, SIva/K-7624-2019;
   Rayappan, John Bosco Balaguru/K-6842-2013
OI Amirtharajan, Rengarajan/0000-0003-1574-3045; Janakiraman,
   SIva/0000-0003-4672-8163; Rayappan, John Bosco
   Balaguru/0000-0003-4641-9870; Karuppuswamy,
   Thenmozhi/0000-0001-9829-0189
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   Adat V, 2018, TELECOMMUN SYST, V67, P423, DOI 10.1007/s11235-017-0345-9
   Amirtharajan R., 2013, RES J INFORM TECHNOL, V5, P304, DOI DOI 10.3923/rjit.2013.263.276
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Bucerzan Dominic, 2017, SOFT COMPUTING APPL, P517
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Dinu D, 2015, NIST WORKSH LIGHTW, P128
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Gupta B., 2016, HDB RES MODERN CRYPT, DOI [10.4018/978-1-5225-0105-3, DOI 10.4018/978-1-5225-0105-3]
   Gupta BB, 2018, MULTIMED TOOLS APPL, V77, P9203, DOI 10.1007/s11042-017-5301-x
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Hyncica O., 2011, Proceedings of the 2011 IEEE 6th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS 2011), P277, DOI 10.1109/IDAACS.2011.6072756
   Janakiraman Siva, 2012, Information Technology Journal, V11, P9, DOI 10.3923/itj.2012.9.19
   Janakiraman S., 2015, ASIAN J SCI RES, V8, P278, DOI DOI 10.3923/ajsr.2015.278.290
   Janakiraman S., 2014, J INFORM TECHNOLOGY, V6, P188
   Janakiraman S., 2019, RELIABLE MED IMAGE C, P1
   Janakiraman S, 2018, MICROPROCESS MICROSY, V56, P1, DOI 10.1016/j.micpro.2017.10.013
   Jiao SM, 2019, OPT LASER TECHNOL, V109, P370, DOI 10.1016/j.optlastec.2018.08.011
   Kamil S, 2018, INT J ADV COMPUT SC, V9, P256
   Katzenbeisser SC, 2000, ART H COMP SCI LIBR, P17
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Liu HY, 2017, MICROCHIM ACTA, V184, P1267, DOI 10.1007/s00604-017-2179-2
   Manoharan Sathiamoorthy, 2008, Third International Conference on Internet Monitoring and Protection - ICIMP 2008, P172, DOI 10.1109/ICIMP.2008.15
   Mukherjee N, 2018, MULTIMED TOOLS APPL, V77, P18451, DOI 10.1007/s11042-018-5720-3
   Murillo-Escobar MA, 2016, MICROPROCESS MICROSY, V45, P297, DOI 10.1016/j.micpro.2016.06.004
   Murillo-Escobar M.A., 2014, Signal Process. Comput., P49
   Parah SA, 2018, MULTIMED TOOLS APPL, V77, P185, DOI 10.1007/s11042-016-4253-x
   Rajagopalan S, 2014, J SCI IND RES INDIA, V73, P701
   Rajagopalan S., 2019, MED DATA SECURITY BI, P278
   Ramalingam B, 2016, COMPUT ELECTR ENG, V55, P153, DOI 10.1016/j.compeleceng.2016.02.010
   Rangaswamaiah Chaitra, 2019, LECT NOTES NETWORKS, P739
   Ranjani JJ, 2017, MULTIMED TOOLS APPL, V76, P3715, DOI 10.1007/s11042-016-3974-1
   Rengarajan A., 2013, INFORM TECHNOLOGY, V5, P277
   Rengarajan Amirtharajan M., 2013, RES J INFORM TECHNOL, V5, P329
   Saha P, 2016, P INT CONF INTELL, P424, DOI 10.1109/ISMS.2016.87
   Shaik A., 2017, Journal of Artificial Intelligence, V10, P1, DOI DOI 10.3923/JAI.2017.1.21
   Stanescu Daniela, 2009, Proceedings 2009 5th International Symposium on Applied Computational Intelligence and Informatics (SACI), P313, DOI 10.1109/SACI.2009.5136263
   Tiwari N, 2010, INT J SECUR APPL, V4, P53
   Usman M, 2017, INT J ADV COMPUT SC, V8, P402
   Wadi SM, 2013, J ENG SCI TECHNOL, V8, P406
NR 42
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31485
EP 31513
DI 10.1007/s11042-019-07960-z
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000023
DA 2024-07-18
ER

PT J
AU Kumar, R
   Jung, KH
AF Kumar, Rajeev
   Jung, Ki-Hyun
TI A systematic survey on block truncation coding based data hiding
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Block truncation coding; Information hiding; BTC; AMBTC;
   Steganography
ID STEGANOGRAPHIC METHOD; IMAGES; SCHEME; EXPANSION; ALGORITHM
AB Block truncation coding is one of the simplest encoding methods which require insignificant computing cost to compress images. Due to the vast demand on embedding data into compressed images with low computing cost, a number of data hiding methods to improve block truncation coding have been proposed to be suitable for the low power devices such as IoT devices, field-programmable gate array, and portable image signal processor. In this paper, block truncation coding based data hiding methods will be discussed and analyzed on two key metrics - data hiding capacity and image quality - as many researchers are focusing to increase the image quality along with data hiding capacity. Here, our aim is to provide guidance to interested researchers for their future works in the field of block truncation coding based data hiding techniques. Finally, future directions of research with some suggestions will be discussed.
C1 [Kumar, Rajeev] Wookyung Informat Technol, IT Res & Dev Ctr, Daegu 41519, South Korea.
   [Kumar, Rajeev; Jung, Ki-Hyun] Kyungil Univ, Dept Cyber Secur, 50 Gamasil Gil, Gyongsan 38428, Gyeongbuk, South Korea.
C3 Kyungil University
RP Jung, KH (corresponding author), Kyungil Univ, Dept Cyber Secur, 50 Gamasil Gil, Gyongsan 38428, Gyeongbuk, South Korea.
EM rajivgarg@outlook.com; khanny.jung@gmail.com
RI Kumar, Rajeev/IUP-5006-2023
OI Kumar, Rajeev/0000-0002-5000-7644; Jung, Ki-Hyun/0000-0002-0662-8355
FU National Research Foundation of Korea (NRF) - Ministry of Education
   [NRF-2018R1D1A1A09081842]; Ministry of Science and ICT through the
   National Research Foundation of Korea [2018H1D3A2065993]
FX This work was supported by Basic Science Research Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education (NRF-2018R1D1A1A09081842) and Brain Pool program funded by the
   Ministry of Science and ICT through the National Research Foundation of
   Korea (No. 2018H1D3A2065993).
CR AMIRULHAQI A, 2017, INT J APPL ENG RES, V12, P13604
   Amita, 2018, International Journal of Information and Computer Security, V10, P261
   [Anonymous], 2009, INT J DATABASE THEOR
   Cai-Hua Li, 2011, Information Technology Journal, V10, P1421, DOI 10.3923/itj.2011.1421.1426
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chang CC, 2018, MULTIMED TOOLS APPL, V77, P9039, DOI 10.1007/s11042-017-4800-0
   Chang CC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P489, DOI 10.1109/IIH-MSP.2014.128
   Chang CC, 2015, PROC SPIE, V9443, DOI 10.1117/12.2179686
   Chang IC, 2015, SIGNAL PROCESS, V108, P376, DOI 10.1016/j.sigpro.2014.09.036
   Chen J, 2010, IMAGING SCI J, V58, P177, DOI 10.1179/136821910X12651933390629
   Chen Yung-Yao, 2023, Journal of Ambient Intelligence and Humanized Computing, P14785, DOI 10.1007/s12652-018-1048-0
   Chen YY, 2019, MULTIMEDIA SYST, V25, P551, DOI 10.1007/s00530-017-0560-y
   Chang CC, 2007, INFORM SCIENCES, V177, P1796, DOI 10.1016/j.ins.2006.09.014
   Chuang J. C., 2006, INT J COMPUT APPL, V28, P1735
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Hong W, 2018, MULTIMED TOOLS APPL, P1
   Hong WE, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10070254
   Hong W, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10020036
   Hong W, 2017, MULTIMED TOOLS APPL, V76, P5441, DOI 10.1007/s11042-016-4032-8
   Hong W, 2017, MULTIMED TOOLS APPL, V76, P3761, DOI 10.1007/s11042-016-3977-y
   Huang YH, 2017, MULTIMED TOOLS APPL, V76, P6159, DOI 10.1007/s11042-015-3208-y
   Kan Wang, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P317, DOI 10.1109/IIH-MSP.2012.83
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Kumar R, 2019, J INF SECUR APPL, V47, P94, DOI 10.1016/j.jisa.2019.04.007
   Kumar R, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1399, DOI 10.1109/CCAA.2016.7813937
   Kumar R, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P53, DOI 10.1109/SPIN.2016.7566661
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Li F, 2016, MULTIMED TOOLS APPL, V75, P16153, DOI 10.1007/s11042-015-2924-7
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liao X, 2013, IEICE T FUND ELECTR, VE96A, P2731, DOI 10.1587/transfun.E96.A.2731
   Lin C, 2013, MULTIMED TOOLS APPL, V74, P3823, DOI DOI 10.1007/S11042-013-1801-5
   Lin CC, 2012, INT CONF GENET EVOL, P157, DOI 10.1109/ICGEC.2012.29
   Lo CC, 2014, INT J SECUR APPL, V8, P301, DOI 10.14257/ijsia.2014.8.2.31
   Malik A, 2018, INT ARAB J INFORM TE
   Malik A, 2018, MULTIDIM SYST SIGN P, V29, P1801, DOI 10.1007/s11045-017-0530-8
   Malik A, 2017, MULTIMED TOOLS APPL, V76, P14151, DOI 10.1007/s11042-016-3815-2
   Huynh NT, 2018, MULTIMED TOOLS APPL, V77, P5767, DOI 10.1007/s11042-017-4487-2
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou DH, 2015, MULTIMED TOOLS APPL, V74, P9117, DOI 10.1007/s11042-014-2059-2
   Paruchuri JK, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/236139
   Shiu PF, 2019, SIGNAL PROCESS-IMAGE, V74, P64, DOI 10.1016/j.image.2019.01.003
   Sun S, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS (ISI), P113, DOI 10.1109/ISI.2017.8004884
   Sun W, 2013, SIGNAL IMAGE VIDEO P, V7, P297, DOI 10.1007/s11760-011-0238-4
   Tang MW, 2016, OPTIK, V127, P471, DOI 10.1016/j.ijleo.2015.09.216
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tsai YY, 2014, IMAGING SCI J, V62, P48, DOI 10.1179/1743131X12Y.0000000032
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Yang B, 2004, PROC SPIE, V5306, P405, DOI 10.1117/12.527216
   Yin ZX, 2018, MULTIMED TOOLS APPL, V77, P18067, DOI 10.1007/s11042-017-4957-6
   Zhang Y, 2013, IEICE T COMMUN, VE96B, P624, DOI 10.1587/transcom.E96.B.624
   Zhao ZF, 2012, INT J DIGIT CONTENT, V6, P205
   Zhou X, 2018, 11 INT C IM SIGN PRO
NR 57
TC 9
Z9 9
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32239
EP 32259
DI 10.1007/s11042-019-07997-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000053
DA 2024-07-18
ER

PT J
AU Liu, K
   Lu, W
   Lin, C
   Huang, XC
   Liu, XJ
   Yeung, YL
   Xue, YJ
AF Liu, Ke
   Lu, Wei
   Lin, Cong
   Huang, Xinchao
   Liu, Xianjin
   Yeung, Yuileong
   Xue, Yingjie
TI Copy move forgery detection based on keypoint and patch match
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy move forgery detection; Duplicated region localization; LIOP; SIFT;
   Patch match
ID IMAGE SPLICING DETECTION; DETECTION SCHEME; MARKOV FEATURES; DISTORTION;
   SEGMENTATION; RECOGNITION; FORENSICS; DCT
AB Copy move has become a simple and effective operation for image forgeries due to the advancement of image editing software, which is still challenging to be detected. In this paper, a novel method is proposed for copy move forgery detection based on Keypoint and Patch Match. Local Intensity Order Pattern (LIOP), a robust keypoint descriptor, is combined with SIFT to obtain reliable keypoints. After using g2NN to match the extracted keypoints, a new matched keypoint pair description model and a density grid-based filtering strategy are applied to removing the redundancy matched keypoint pairs. Finally an enhanced patch match approach is utilized to examine the matched keypoint pairs to accurately determine the existence of forgery. Compared with the state-of-the-art methods, the proposed method can detect copy move region more precisely according to the experimental result, even when detected objects are distorted by some processing such as rotation, scaling, JPEG compression and additional noise.
C1 [Liu, Ke; Xue, Yingjie] Sun Yat Sen Univ, Key Lab Machine Intelligence & Adv Comp, Guangdong Key Lab Informat Secur Technol, Sch Elect & Informat Technol,Minist Educ, Guangzhou 510006, Guangdong, Peoples R China.
   [Lu, Wei; Huang, Xinchao; Liu, Xianjin; Yeung, Yuileong] Sun Yat Sen Univ, Key Lab Machine Intelligence & Adv Comp, Guangdong Key Lab Informat Secur Technol, Sch Data & Comp Sci,Minist Educ, Guangzhou 510006, Guangdong, Peoples R China.
   [Lin, Cong] Guangdong Univ Finance & Econ, Ctr Fac Dev & Educ Technol, Guangzhou 510320, Guangdong, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University; Guangdong University of
   Finance & Economics
RP Lu, W (corresponding author), Sun Yat Sen Univ, Key Lab Machine Intelligence & Adv Comp, Guangdong Key Lab Informat Secur Technol, Sch Data & Comp Sci,Minist Educ, Guangzhou 510006, Guangdong, Peoples R China.
EM liuk66@mail2.sysu.edu.cn; luwei3@mail.sysu.edu.cn
RI Wang, Guang/JFS-8374-2023
OI Lu, Wei/0000-0002-4068-1766
FU National Natural Science Foundation of China [U1736118]; Key Areas R&D
   Program of Guangdong [2019B010136002]; Key Scientific Research Program
   of Guangzhou [201804020068]; Natural Science Foundation of Guangdong
   [2016A030313350]; Special Funds for Science and Technology Development
   of Guangdong [2016KZ010103]; Shanghai Minsheng Science and Technology
   Support Program [17DZ1205500]; Shanghai Sailing Program [17YF1420000];
   Fundamental Research Funds for the Central Universities [16lgjc83,
   17lgjc45]
FX This work is supported by the National Natural Science Foundation of
   China (No. U1736118), the Key Areas R&D Program of Guangdong (No.
   2019B010136002), the Key Scientific Research Program of Guangzhou (No.
   201804020068), the Natural Science Foundation of Guangdong (No.
   2016A030313350), the Special Funds for Science and Technology
   Development of Guangdong (No. 2016KZ010103), Shanghai Minsheng Science
   and Technology Support Program (17DZ1205500), Shanghai Sailing Program
   (17YF1420000), the Fundamental Research Funds for the Central
   Universities (No. 16lgjc83 and No. 17lgjc45).
CR Abd Warif NB, 2017, J VIS COMMUN IMAGE R, V46, P219, DOI 10.1016/j.jvcir.2017.04.004
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], TECH REP
   [Anonymous], 2003, PROC DIGIT FORENSIC, DOI DOI 10.1109/PACIIA.2008.240
   [Anonymous], MULTIMEDIA TOOLS APP
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Bedi G, 2018, IEEE INTERNET THINGS, V5, P847, DOI 10.1109/JIOT.2018.2802704
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   Chen JL, 2018, J VIS COMMUN IMAGE R, V55, P149, DOI 10.1016/j.jvcir.2018.06.004
   Chen JJ, 2018, CMC-COMPUT MATER CON, V55, P201, DOI 10.3970/cmc.2018.01781
   Chen LK, 2013, J VIS COMMUN IMAGE R, V24, P244, DOI 10.1016/j.jvcir.2013.01.008
   Chen X, 2018, IEEE T NEUR NET LEAR, V29, P3938, DOI 10.1109/TNNLS.2017.2740318
   Chen X, 2018, IEEE T PATTERN ANAL, V40, P1697, DOI 10.1109/TPAMI.2017.2726061
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Emam M, 2018, J FORENSIC SCI, V63, P102, DOI 10.1111/1556-4029.13456
   Fan B, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995385
   Feng BW, 2015, MULTIMED TOOLS APPL, V74, P9623, DOI 10.1007/s11042-014-2140-x
   Feng BW, 2015, IEEE T INF FOREN SEC, V10, P243, DOI 10.1109/TIFS.2014.2368364
   Feng BW, 2015, J VIS COMMUN IMAGE R, V26, P284, DOI 10.1016/j.jvcir.2014.10.003
   Hu CP, 2014, IEEE T EMERG TOP COM, V2, P376, DOI 10.1109/TETC.2014.2316525
   Huang XC, 2019, INT J DIGIT CRIME FO, V11, P47, DOI 10.4018/IJDCF.2019040104
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kim HS, 2003, IEEE T CIRC SYST VID, V13, P766, DOI 10.1109/TCSVT.2003.815955
   Kumar Sunil, 2015, International Journal of Computing and Digital Systems, V4, P27, DOI 10.12785/ijcds/040203
   Lee JC, 2015, J VIS COMMUN IMAGE R, V31, P320, DOI 10.1016/j.jvcir.2015.07.007
   Li GH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1750
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li J, 2016, J VIS COMMUN IMAGE R, V40, P14, DOI 10.1016/j.jvcir.2016.06.003
   Li JW, 2017, MULTIMED TOOLS APPL, V76, P20483, DOI 10.1007/s11042-016-3967-0
   Li JX, 2018, MULTIMED TOOLS APPL, V77, P31895, DOI 10.1007/s11042-018-6175-2
   Li L., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P46
   Li LD, 2014, COMPUT ELECTR ENG, V40, P1951, DOI 10.1016/j.compeleceng.2013.11.034
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Lin C, 2018, MULTIMED TOOLS APPL, V77, P14241, DOI 10.1007/s11042-017-5027-9
   Liu XJ, 2020, IEEE T CIRC SYST VID, V30, P618, DOI 10.1109/TCSVT.2019.2893353
   Liu XJ, 2019, IEEE ACCESS, V7, P24632, DOI 10.1109/ACCESS.2019.2901020
   Liu ZH, 2017, 2017 IEEE SECOND INTERNATIONAL CONFERENCE ON DATA SCIENCE IN CYBERSPACE (DSC), P625, DOI 10.1109/DSC.2017.11
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu W, 2019, IEEE T CIRC SYST VID, V29, P1608, DOI 10.1109/TCSVT.2018.2852702
   Luo XY, 2016, MULTIMED TOOLS APPL, V75, P13557, DOI 10.1007/s11042-015-2759-2
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Muhammad K, 2018, FUTURE GENER COMP SY, V86, P951, DOI 10.1016/j.future.2016.11.029
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Muhammad K, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0473-x
   Muhammad K, 2015, KSII T INTERNET INF, V9, P1938
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Toldo R, 2008, LECT NOTES COMPUT SC, V5302, P537, DOI 10.1007/978-3-540-88682-2_41
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Wang RX, 2018, INT J DIGIT CRIME FO, V10, P90, DOI 10.4018/IJDCF.2018100107
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P2311, DOI 10.1007/s11042-018-6354-1
   Wang ZH, 2011, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2011.6126294
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Xiao HM, 2019, J VIS COMMUN IMAGE R, V59, P52, DOI 10.1016/j.jvcir.2018.12.048
   Xin YQ, 2004, INT C PATT RECOG, P861, DOI 10.1109/ICPR.2004.1333908
   Xue Y, 2018, J CHEM-NY, V2018, DOI 10.1155/2018/7274020
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Zhang FJ, 2018, MULTIMED TOOLS APPL, V77, P26239, DOI 10.1007/s11042-018-5847-2
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhang QB, 2018, MULTIMED TOOLS APPL, V77, P31239, DOI 10.1007/s11042-018-6230-z
   Zhang QB, 2016, J VIS COMMUN IMAGE R, V40, P449, DOI 10.1016/j.jvcir.2016.07.013
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
NR 84
TC 13
Z9 14
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31387
EP 31413
DI 10.1007/s11042-019-07930-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000019
DA 2024-07-18
ER

PT J
AU Li, JY
   Zhang, CZ
AF Li, Jingyou
   Zhang, Chaozhu
TI Blind and robust watermarking scheme combining bimodal distribution
   structure with iterative selection method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bimodal distribution structure; Discrete cosine transform; Iterative
   selection method; Adaptive threshold
ID DIGITAL IMAGE WATERMARKING; FRAGILE WATERMARKING; SVD; TRANSFORM;
   ALGORITHM
AB To protect the ownership, a blind and robust watermarking scheme is devised by the coefficients of the discrete cosine transform. In the embedding process, the absolute differences of discrete cosine transform coefficients are divided into two groups according to the watermark. That's to say, the shape of the absolute difference histogram is modulated to build a bimodal structure. In the extraction process, an adaptive threshold is calculated with an iterative selection method. To our knowledge, it is the first time to take advantage of the robust characteristic in a particular shape. Besides, several attack experiments including JPEG compression, cropping, resizing and blurring are performed. The results in attack experiments and comparison experiments demonstrate the superiority of the proposed blind watermarking scheme.
C1 [Li, Jingyou; Zhang, Chaozhu] Harbin Engn Univ, Sch Informat & Commun Engn, Harbin 150001, Heilongjiang, Peoples R China.
   [Li, Jingyou] Qiqihar Univ, Sch Commun & Elect Engn, Qiqihar 161006, Peoples R China.
C3 Harbin Engineering University; Qiqihar University
RP Zhang, CZ (corresponding author), Harbin Engn Univ, Sch Informat & Commun Engn, Harbin 150001, Heilongjiang, Peoples R China.
EM lijingyou99@163.com; zhangchaozhu@hrbeu.edu.cn
FU National Natural Science Foundation of China [61172159]; Research
   Foundation of the Education Department of Heilongjiang Province
   [12541872]
FX This work is supported by the National Natural Science Foundation of
   China (grant no. 61172159), and the Research Foundation of the Education
   Department of Heilongjiang Province (grant no. 12541872).
CR Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   Amini M, 2018, IEEE T CIRC SYST VID, V28, P402, DOI 10.1109/TCSVT.2016.2607299
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Chang CS, 2017, IEEE T IMAGE PROCESS, V26, P3921, DOI 10.1109/TIP.2017.2706502
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Esgandari R, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P988, DOI 10.1109/KBEI.2015.7436179
   Fan MQ, 2018, SIGNAL PROCESS-IMAGE, V66, P19, DOI 10.1016/j.image.2018.04.003
   Farri E, 2018, NONLINEAR DYNAM, V93, P1875, DOI 10.1007/s11071-018-4295-x
   Guo Y, 2017, IET IMAGE PROCESS, V11, P406, DOI 10.1049/iet-ipr.2016.0515
   Guo Y, 2016, IET IMAGE PROCESS, V10, P773, DOI 10.1049/iet-ipr.2015.0818
   Kang XG, 2011, IEEE T MULTIMEDIA, V13, P181, DOI 10.1109/TMM.2010.2098850
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Loukhaoukha K, 2010, LECT NOTES COMPUT SC, V6134, P394, DOI 10.1007/978-3-642-13681-8_46
   Makbol NM, 2017, INFORM SCIENCES, V417, P381, DOI 10.1016/j.ins.2017.07.026
   Najafi E, 2019, J INF SECUR APPL, V44, P144, DOI 10.1016/j.jisa.2018.12.002
   Niu PP, 2011, EXPERT SYST APPL, V38, P2081, DOI 10.1016/j.eswa.2010.07.147
   RIDLER TW, 1978, IEEE T SYST MAN CYB, V8, P630, DOI 10.1109/tsmc.1978.4310039
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Run RS, 2011, EXPERT SYST APPL, V38, P14357, DOI 10.1016/j.eswa.2011.03.024
   Su QT, 2018, MULTIDIM SYST SIGN P, V29, P1055, DOI 10.1007/s11045-017-0487-7
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P8781, DOI 10.1007/s11042-016-3522-z
   Thien HT, 2018, INFORM SCIENCES, V426, P1, DOI 10.1016/j.ins.2017.10.016
   Thien HT, 2016, EXPERT SYST APPL, V62, P177, DOI 10.1016/j.eswa.2016.06.015
   Wang CY, 2018, J INF PROCESS SYST, V14, P666, DOI 10.3745/JIPS.03.0096
   Wang XY, 2016, INFORM SCIENCES, V372, P634, DOI 10.1016/j.ins.2016.08.076
   Weng SW, 2019, INFORM SCIENCES, V489, P136, DOI 10.1016/j.ins.2019.03.032
   Xiao-Long Liu, 2018, IEEE Transactions on Circuits and Systems for Video Technology, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Yuan XC, 2018, SIGNAL PROCESS, V149, P103, DOI 10.1016/j.sigpro.2018.03.007
   Zhou NR, 2019, MULTIMED TOOLS APPL, V78, P2507, DOI 10.1007/s11042-018-6322-9
NR 29
TC 8
Z9 9
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1373
EP 1407
DI 10.1007/s11042-019-08213-9
EA OCT 2019
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000493494100002
DA 2024-07-18
ER

PT J
AU Raikwar, SC
   Tapaswi, S
AF Raikwar, Suresh Chandra
   Tapaswi, Shashikala
TI Adaptive dehazing control factor based fast single image dehazing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Atmospheric scattering; Defogging; Dehazing; Fog; Haze; Optimization;
   Restoration; Transmission; Dark channel prior
ID ENHANCEMENT; FRAMEWORK
AB The single image dehazing is performed using atmospheric scattering model (ASM). The ASM is based on transmission and atmospheric light. Thus, accurate estimation of transmission is essential for quality single image dehazing. Single image dehazing is of prime focus in research nowadays. The proposed work presents a fast and accurate method for single image dehazing. The proposed method works in two folds; (i) An adaptive dehazing control factor is proposed to estimate accurate transmission, which is based on difference of maximum and minimum color channel of hazy image, and (ii) a mathematical model to compute probability of a pixel to be at short distance is presented, which is utilized to locate haziest region of the image to compute the value of atmospheric light. The proposed method obtains visually compelling results, and recovers the information content (such as structural similarity, color, and visibility) accurately. The computation speed and accuracy of the proposed method is proved using quantitative and qualitative comparison of results with state of the art dehazing methods.
C1 [Raikwar, Suresh Chandra] GLA Univ, Inst Engn & Technol, Dept Comp Engn & Applicat, Mathura, Uttar Pradesh, India.
   [Tapaswi, Shashikala] ABV Indian Inst Informat Technol & Management, Gwalior, Madhya Pradesh, India.
C3 GLA University; ABV-Indian Institute of Information Technology &
   Management, Gwalior
RP Raikwar, SC (corresponding author), GLA Univ, Inst Engn & Technol, Dept Comp Engn & Applicat, Mathura, Uttar Pradesh, India.
EM sureshc.rwr@gmail.com
RI TAPASWI, SHASHIKALA/AGZ-7714-2022; Raikwar, Suresh Chandra/AAO-5844-2021
OI Raikwar, Suresh Chandra/0000-0001-5139-217X
CR [Anonymous], 2003, The SSIM index for image quality assessment
   [Anonymous], THESIS
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Jha DK, 2016, IET COMPUT VIS, V10, P331, DOI 10.1049/iet-cvi.2014.0449
   Jing PG, 2019, IEEE T CIRC SYST VID, V29, P1296, DOI 10.1109/TCSVT.2018.2832095
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Kim JY, 2001, IEEE T CIRC SYST VID, V11, P475, DOI 10.1109/76.915354
   Kim TK, 1998, IEEE T CONSUM ELECTR, V44, P82, DOI 10.1109/30.663733
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li YA, 2016, NEUROCOMPUTING, V182, P221, DOI 10.1016/j.neucom.2015.12.032
   Ling ZG, 2017, NEUROCOMPUTING, V224, P82, DOI 10.1016/j.neucom.2016.10.050
   Liu SL, 2017, COMPUT ELECTR ENG, V62, P345, DOI 10.1016/j.compeleceng.2016.11.021
   Lu HM, 2016, IEEE IMAGE PROC, P1998, DOI 10.1109/ICIP.2016.7532708
   Lu HM, 2015, J OPT SOC AM A, V32, P886, DOI 10.1364/JOSAA.32.000886
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Middleton W. E. K., 1954, Phys. Today, V7, P21
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Nayar S.K., 2003, IEEE WORKSH COL PHOT
   Raikwar SC, 2018, VISUAL COMPUTER
   Raikwar SC, 2018, MULTIMED TOOLS APPL, V77, P19719, DOI 10.1007/s11042-017-5398-y
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Shwartz S., 2006, 2006 IEEE COMP SOC C, V2, P1984, DOI DOI 10.1109/CVPR.2006.71
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Tan KK, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P788, DOI 10.1109/ICIP.2000.899827
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Tarel JP, 2010, IEEE INT VEH SYM, P478, DOI 10.1109/IVS.2010.5548128
   Wang WC, 2017, IEEE T MULTIMEDIA, V19, P1142, DOI 10.1109/TMM.2017.2652069
   Wang WC, 2017, NEUROCOMPUTING, V238, P365, DOI 10.1016/j.neucom.2017.01.075
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao CX, 2012, VISUAL COMPUT, V28, P713, DOI 10.1007/s00371-012-0679-y
   Yuan H, 2017, IEEE ACCESS, V5, P1735, DOI 10.1109/ACCESS.2017.2660302
   ZHANG JA, 2015, IEEE INT C IM PROC
   Zhang YQ, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-220
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 45
TC 9
Z9 12
U1 3
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 891
EP 918
DI 10.1007/s11042-019-08120-z
EA OCT 2019
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000492481400001
DA 2024-07-18
ER

PT J
AU Alhassan, S
   Iddrisu, MM
   Daabo, MI
AF Alhassan, Salamudeen
   Iddrisu, Mohammed Muniru
   Daabo, Mohammed Ibrahim
TI Securing audio data using K-shuffle technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio encryption; Audio decryption; Perfect shuffle; K-shuffle; Sound
   data; Faro shuffle
AB This paper presents a k-shuffle based audio scrambling technique which yields cipher audio with varying audibility that is useful in perceptual video encryption algorithms. In this technique the encryption and decryption algorithms group the input audio signals into m-piles of n-values each. The encryption procedure retains the first signal value (of the first pile) and the last signal value (of the last pile) in their respective positions while re-arranging the rest by taking in turns, the 1st values of each of the m-piles, then the 2nd values, up to the n(th) values. At the receivers end, the decryption algorithm re-orders the scrambled audio signals back in to their respective original positions using the reverse of the k-shuffle technique. It is shown that, the audibility of the cipher audio is controlled by varying the number of piles. The performance of the proposed technique is demonstrated by simulations. The results of the simulations show that the proposed technique offers some level of resistance to chosen/known plaintext attacks.
C1 [Alhassan, Salamudeen] Bagabaga Coll Educ, Dept Math & Informat Technol, Tamale, Ghana.
   [Iddrisu, Mohammed Muniru] Univ Dev Studies, Dept Math, Navrongo Campus, Navrongo, Ghana.
   [Daabo, Mohammed Ibrahim] Univ Dev Studies, Dept Comp Sci, Navrongo Campus, Navrongo, Ghana.
C3 University for Development Studies; University for Development Studies
RP Alhassan, S (corresponding author), Bagabaga Coll Educ, Dept Math & Informat Technol, Tamale, Ghana.
EM salarnprog@yahoo.com; immuniru@gmail.com; daabo2005@yahoo.com
OI Iddrisu, Mohammed Muniru/0000-0001-7628-8168; ALHASSAN,
   SALAMUDEEN/0000-0001-8157-3051
CR Diaconis P., 1983, Adv._in_Appl._Math, V4, P175, DOI [10.1016/0196-8858(83)90009-X, DOI 10.1016/0196-8858(83)90009-X, https://doi.org/10.1016/0196-8858(83)90009-X]
   Farkash S., 1991, 17th Convention of Electrical and Electronics Engineers in Israel. Proceedings (Cat. No.90TH0360-8), P365, DOI 10.1109/EEIS.1991.217693
   Gnanajeyaraman R., 2009, International Journal of Recent Trends in Engineering, V1, P103
   Kaur M., 2014, IJARCSSE, V4, P1314
   Khalil M. I., 2016, International Journal of Computer Network and Information Security, V8, P25, DOI 10.5815/ijcnis.2016.02.03
   Khalil MI, 2017, INT J INF TECHNOL SE, V9, P3
   Makwana V, 2014, INT J COMPUT SCI INF, V5, P4473
   Menezes A. J., 1996, HDB APPL CRYPTOGRAPH, V1st
   PACKARD RW, 1994, FIBONACCI QUART, V32, P136
   Pitale P, 2015, INT J COMPUT APPL, V09758887, P1
   Sadkhan SB, 2015, PROCEDIA COMPUT SCI, V65, P314, DOI 10.1016/j.procs.2015.09.089
   Salamudeen A, 2018, APPL MATH INFORM SCI, V12, P923
   Sheetal S., 2013, INT J ADV RES COMPUT, V3, P79
   Sultana S., 2017, International Journal of Social Sciences and Education, V7, P1
   Tamimi A.A., 2014, P WORLD C ENG COMP S, V1
   Zhu Z, 2011, P 7 AS INT ENG C
NR 16
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33985
EP 33997
DI 10.1007/s11042-019-08151-6
EA OCT 2019
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000489286600001
DA 2024-07-18
ER

PT J
AU Ashiba, MI
   Tolba, MS
   El-Fishawy, AS
   Abd El-Samie, FE
AF Ashiba, M., I
   Tolba, M. S.
   El-Fishawy, A. S.
   Abd El-Samie, F. E.
TI Gamma correction enhancement of infrared night vision images using
   histogram processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Night vision; Histogram equalization; Gamma correction; CLAHE; HM
ID ALGORITHM
AB This paper presents two proposed approaches for enhancing the visibility of the infrared (IR) night vision images. The first approach is based on merging gamma correction with histogram matching (HM). On the other hand, the second approach depends on merging gamma correction with contrast limited adaptive histogram equalization (CLAHE). The HM depends on a reference visual image for converting IR night vision images into images with better visual quality. Quality metrics such as entropy, average gradient, and Sobel edge magnitude are used for performance evaluation of the proposed approaches.
C1 [Ashiba, M., I; Tolba, M. S.] Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia 32952, Egypt.
   [El-Fishawy, A. S.; Abd El-Samie, F. E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Menofia University
RP Ashiba, MI (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia 32952, Egypt.
EM engashiba@gmail.com; maha_saad_tolba@yahoo.com; aelfishawy@hotmail.com;
   fathi_sayed@yahoo.com
RI Sayed, Fathi/HRA-4752-2023; El-Fishawy, Adel S./AAH-7007-2019
OI Sayed, Fathi/0000-0001-8749-9518; El-Fishawy, Adel/0000-0003-1567-457X
CR [Anonymous], 2014, EUR C COMP VIS
   [Anonymous], 2015, ICCV
   Ashiba HI, 2018, WIRELESS PERS COMMUN, V99, P619, DOI 10.1007/s11277-017-4958-9
   Bai XZ, 2017, INFRARED PHYS TECHN, V80, P44, DOI 10.1016/j.infrared.2016.11.011
   Bai XZ, 2015, INFRARED PHYS TECHN, V68, P143, DOI 10.1016/j.infrared.2014.11.015
   Balntas V, 2016, ABS160105030 COBB
   Dai SS, 2015, INFRARED PHYS TECHN, V68, P10, DOI 10.1016/j.infrared.2014.09.042
   Donahue J., 2014, ICLR
   Fan B, 2014, IEEE T IMAGE PROCESS, V23, P2583, DOI 10.1109/TIP.2014.2317981
   Girshick R., 2013, IEEE Comput. Soc., P580
   Gonzalez RC, 2018, PEARSON DIGITAL IMAG
   Gupta S.G., 2013, Int. J. Adv. Res. Comput. Eng. Technol, V2, P2278
   Jung J, 2006, 2006 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, VOLS 1-6, PROCEEDINGS, P277, DOI 10.1109/ISIT.2006.261849
   Li Y, 2016, OPT LASER TECHNOL, V83, P99, DOI 10.1016/j.optlastec.2016.03.017
   Liang K, 2012, INFRARED PHYS TECHN, V55, P309, DOI 10.1016/j.infrared.2012.03.004
   Liu B, 2009, INT J INTELL SYST, V24, P989, DOI 10.1002/int.20374
   Liu N, 2016, INFRARED PHYS TECHN, V77, P405, DOI 10.1016/j.infrared.2016.06.017
   Pratt K.W., 1991, DIGITAL IMAGE PROCES
   Qi W, 2016, INFRARED PHYS TECHN, V76, P684, DOI 10.1016/j.infrared.2016.04.038
   Raghatate RP., 2013, IJMER, V3, P816
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Song Q, 2016, INFRARED PHYS TECHN, V77, P464, DOI 10.1016/j.infrared.2016.06.023
   Thakur P, 2016, INT J INNOV ENG TECH
   Zhang SQ, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10080304
   Zhao JC, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.703
NR 25
TC 8
Z9 14
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27771
EP 27783
DI 10.1007/s11042-018-7086-y
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000045
DA 2024-07-18
ER

PT J
AU Kwak, J
   Park, JH
   Sung, Y
AF Kwak, Jeonghoon
   Park, Jong Hyuk
   Sung, Yunsick
TI Affective social big data generation algorithm for autonomous controls
   by CRNN-based end-to-end controls
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective social big data; Multimedia data; Deep learning; Convolutional
   recurrent neural network
AB Affective social multimedia computing provides us the opportunity to improve our daily lives. Various things, such as devices in ubiquitous computing environments and autonomous vehicles in real environments considering human beings, can be controlled by analyzing and learning affective social big data. Deep learning is a core learning algorithm for autonomous control; however, it requires huge amounts of learning data, and the process of collecting various types of learning data is expensive. The collection limit of affective social videos for deep learning is resolved by analyzing affective social videos, such as YouTube and Closed Circuit Television (CCTV) videos collected in advance, and generating new affective social videos more as learning data without human beings autonomously controlling other cameras. The control signals of the cameras are generated by Convolutional Neural Network (CNN)-based end-to-end controls. However, images captured consecutively need to be analyzed to improve the quality of the generated control signals. This paper proposes a system that generates affective social videos for deep learning by Convolutional Recurrent Neural Network (CRNN)-based end-to-end controls. The extracted images in affective social videos are utilized for calculating the control signals based on the CRNN. Additional affective social videos are then generated by the extracted consecutive images and camera control signals. The effectiveness of the proposed method was verified in the experiments by comparing the results obtained using the proposed method with those obtained using the traditional CNN. The results showed that the accuracy of the control signals obtained using the proposed method was 56.30% higher than that of the control signals obtained using the traditional CNN.
C1 [Kwak, Jeonghoon; Sung, Yunsick] Dongguk Univ Seoul, Dept Multimedia Engn, 30 Pildong Ro,1 Gil, Seoul 04620, South Korea.
   [Park, Jong Hyuk] Seoul Natl Univ Sci & Technol, Dept Comp Sci & Engn, 232 Gongneung Ro,1 Gil, Seoul 01811, South Korea.
C3 Dongguk University; Seoul National University of Science & Technology
RP Sung, Y (corresponding author), Dongguk Univ Seoul, Dept Multimedia Engn, 30 Pildong Ro,1 Gil, Seoul 04620, South Korea.; Park, JH (corresponding author), Seoul Natl Univ Sci & Technol, Dept Comp Sci & Engn, 232 Gongneung Ro,1 Gil, Seoul 01811, South Korea.
EM jeonghoon@dongguk.edu; jhpark1@seoultech.ac.kr; sung@dongguk.edu
RI Park, Jong Hyuk/AHD-6698-2022
OI Sung, Yunsick/0000-0003-3732-5346
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - Ministry of Education [2018R1D1A1B07049990]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Education (2018R1D1A1B07049990).
CR [Anonymous], 2016, ARXIV PREPRINT ARXIV
   Chen Y, 2015, MULTIMED TOOLS APPL, V74, P1067, DOI 10.1007/s11042-013-1711-6
   Cheng C, 2015, SPRINGER THESES-RECO, P1, DOI 10.1007/978-3-662-47268-2
   Codevilla F, 2018, IEEE INT CONF ROBOT, P4693
   Ebeid E, 2018, MICROPROCESS MICROSY, V61, P11, DOI 10.1016/j.micpro.2018.05.002
   Giusti A, 2016, IEEE ROBOT AUTOM LET, V1, P661, DOI 10.1109/LRA.2015.2509024
   Hentati AI, 2018, INT WIREL COMMUN, P1495, DOI 10.1109/IWCMC.2018.8450505
   Herzig Jonathan., 2016, Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization, P115, DOI [10.1145/2930238.2930285, DOI 10.1145/2930238.2930285]
   Hussein A, 2018, NEURAL COMPUT APPL, V29, P389, DOI 10.1007/s00521-017-3241-z
   Kersandt K, 2018, P IEEE AIAA 37 DIG A, P1
   Kim J, 2017, HUM-CENTRIC COMPUT I, V7, DOI 10.1186/s13673-017-0106-5
   Lee SG, 2018, J INF PROCESS SYST, V14, P205, DOI 10.3745/JIPS.04.0061
   Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140
   Truong MTN, 2017, HUM-CENT COMPUT INFO, V7, DOI 10.1186/s13673-016-0082-1
   Merino L, 2012, J INTELL ROBOT SYST, V65, P533, DOI 10.1007/s10846-011-9560-x
   Polvara R, 2018, INT CONF UNMAN AIRCR, P115, DOI 10.1109/ICUAS.2018.8453449
   Sánchez-Escobedo D, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1563, DOI 10.1109/ICASSP.2018.8462433
   Shah Utsav, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1982, DOI 10.1109/ICRA.2017.7989229
   Shaharuddin US, 2016, INT CONF SYST ENG, P1, DOI 10.1109/ICSEngT.2016.7849613
   Shahidullah SM, 2017, PALGRAVE ADV CRIMIN, P1, DOI 10.1057/978-1-137-50750-1_1
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Simonyan K., 2014, 14091556 ARXIV
   Smolyanskiy N, 2017, P 2017 IEEE RSJ INT, P1
   Song Y, 2018, J INF PROCESS SYST, V14, P150
   Su YC, 2017, PROC CVPR IEEE, P1368, DOI 10.1109/CVPR.2017.150
   Sung Y, 2015, KOR MULT SOC SPRING, P828
   Sung Y, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10030816
   Wang YL, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2378
   Xu AB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3506, DOI 10.1145/3025453.3025496
   Yang XS, 2015, IEEE T MULTIMEDIA, V17, P346, DOI 10.1109/TMM.2015.2393635
   Zhou P, 2016, IEEE T MULTIMEDIA, V18, P1217, DOI 10.1109/TMM.2016.2537216
NR 31
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27175
EP 27192
DI 10.1007/s11042-019-7703-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000018
DA 2024-07-18
ER

PT J
AU Yu, E
   Sun, JD
   Wang, L
   Wan, WB
   Zhang, HX
AF Yu, En
   Sun, Jiande
   Wang, Li
   Wan, Wenbo
   Zhang, Huaxiang
TI Coupled feature selection based semi-supervised modality-dependent
   cross-modal retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-media retrieval; Feature selection; Semi-supervised; Pseudo data
ID REPRESENTATION; SPARSE
AB With the explosive growth of multimedia data, the information is usually represented in multi-modal version. The cross-modal based applications attracted increasing attention in recent years, and cross-modal retrieval is the popular one of them. In this paper, we propose a semi-supervised modality-dependent cross-modal retrieval method based on coupled feature selection (Semi-CoFe). It is different from most of the previous cross-modal retrieval methods, which usually used only labeled data for training to obtain the projection matrices under the constraint of l(2)-norm. In details, we propagate the label of cluster centers to unlabeled data via a devised weight matrix and construct the pseudo corresponding heterogeneous data. And then we jointly considered the semantic regression and pair-wised correlation analysis when learning the mapping matrices to keep the semantic consistency and the closeness of pair-wised data. Meanwhile, the l(2,1)-norm constraint is used for informative and discriminative features selection and noise reduction. In addition, we learn different mapping matrices for different sub-tasks (such as, using image to search text (I2T) and using text to search image (T2I)) to distinguish the semantic information of query data, and the optimal mapping matrices are achieved via an iterative optimization method. The experimental results on three public datasets verify that the proposed method performs better than the state-of-the-art methods.
C1 [Yu, En; Sun, Jiande; Wang, Li; Wan, Wenbo; Zhang, Huaxiang] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Zhang, Huaxiang] Shandong Normal Univ, Inst Data Sci & Technol, Jinan 250014, Shandong, Peoples R China.
C3 Shandong Normal University; Shandong Normal University
RP Sun, JD; Wan, WB (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
EM jiandesun@hotmail.com; wanwenbo@sdnu.edu.cn
RI YU, EN/JVZ-8283-2024
OI YU, EN/0009-0005-3335-5486
FU Natural Science Foundation for Distinguished Young Scholars of Shandong
   Province [JQ201718]; Key Research and Development Foundation of Shandong
   Province [2016GGX101009]; Natural Science Foundation of China [U1736122,
   61603225, 61601268]; Shandong Provincial Key Research and Development
   Plan [2017CXGC1504]; NVIDIA Corporation
FX This work is supported by Natural Science Foundation for Distinguished
   Young Scholars of Shandong Province (JQ201718), Key Research and
   Development Foundation of Shandong Province (2016GGX101009), the Natural
   Science Foundation of China (U1736122, 61603225, 61601268), Shandong
   Provincial Key Research and Development Plan (2017CXGC1504). And we
   gratefully acknowledge the support of NVIDIA Corporation with the
   donation of the TITAN X GPU used for this research.
CR [Anonymous], 2014, INF SOFTW TECHNOL
   [Anonymous], 2013, P 21 ACM INT C MULT
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   He JF, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P227, DOI 10.1145/2964284.2967216
   He R, 2012, PROC CVPR IEEE, P2504, DOI 10.1109/CVPR.2012.6247966
   Hua Y, 2016, IEEE T MULTIMEDIA, V18, P1201, DOI 10.1109/TMM.2016.2535864
   Jia YQ, 2011, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2011.6126524
   Kang CC, 2015, IEEE T MULTIMEDIA, V17, P370, DOI 10.1109/TMM.2015.2390499
   Katsurai M, 2014, IEEE T MULTIMEDIA, V16, P1059, DOI 10.1109/TMM.2014.2306655
   Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461
   Liang X, 2013, P 3 ACM INT C MULT R, P175
   Nie F., 2013, P INT JOINT C ART IN, P1572
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Peng YX, 2016, IEEE T CIRC SYST VID, V26, P583, DOI 10.1109/TCSVT.2015.2400779
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350
   Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311
   Wang KY, 2013, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2013.261
   Wei YC, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2775109
   Wu F, 2007, P IEEE INT C IM PROC, P1465
   Yan J., 2017, IEEE T MULTIMEDIA, V6, P1, DOI DOI 10.1063/1.5006865
   Yan JH, 2018, MULTIMED TOOLS APPL, V77, P3009, DOI 10.1007/s11042-017-4918-0
   Zhai X., 2013, PROC 27 AAAI C ARTIF, P1198
   Zhai XH, 2014, IEEE T CIRC SYST VID, V24, P965, DOI 10.1109/TCSVT.2013.2276704
   Zhang H, 2013, NEUROCOMPUTING, V119, P10, DOI 10.1016/j.neucom.2012.03.033
   Zhang HX, 2014, PATTERN RECOGN, V47, P3168, DOI 10.1016/j.patcog.2014.04.004
   Zhang L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1355, DOI 10.1145/2964284.2964336
   Zhuang Y, 2013, AAAI C ART INT
NR 39
TC 3
Z9 3
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28931
EP 28951
DI 10.1007/s11042-018-5958-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700032
DA 2024-07-18
ER

PT J
AU Ahmed, Z
   Hamma, S
   Nasir, Z
AF Ahmed, Zeeshan
   Hamma, Salima
   Nasir, Zafar
TI An optimal bandwidth allocation algorithm for improving QoS in WiMAX
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IEEE 802; 16; WiMAX; QoS; Packet scheduling; Bandwidth allocation
ID MANAGEMENT STRATEGY; SERVICE FLOW; EFFICIENCY; STANDARDS; SUPPORT; 5G
AB In the last few years, the term "quality of service" has become increasingly synonymous with digital cellular networks and has greatly influenced the way we manage network traffic. The IEEE 802.16 standard is a broadband wireless access system that enables high speed data transfer over large distances. It is one of the standards that meet the IMT-Advanced specifications. It also incorporates a quality of service framework to provide quality of service to both realtime and non-realtime multimedia applications. One of the critical contributions of a QoS framework is efficient scheduling of network traffic. This paper dilates on a two-level scheduling algorithm for base station uplink scheduler to provide quality of service to various classes of traffic. The proposed algorithm ensures efficient and fair multimedia transmission. We also deliberated on a video transmission framework based on the proposed algorithm. The performance of two-level scheduling algorithm has been extensively analyzed through simulations and the results have effectively established the efficacy of the proposed algorithm. The results reveal that the the proposed algorithm is able to fairly and efficiently schedule network traffic while ensuring quality of service for all classes of traffic.
C1 [Ahmed, Zeeshan] Natl Univ Comp & Emerging Sci, Dept Comp Sci, Karachi Campus, Karachi, Pakistan.
   [Hamma, Salima] Univ Nantes, LS2N, 2 Chemin Houssiniere, F-44322 Nantes, France.
   [Nasir, Zafar] Indus Univ, Dept Sci, Karachi, Pakistan.
C3 Nantes Universite
RP Ahmed, Z (corresponding author), Natl Univ Comp & Emerging Sci, Dept Comp Sci, Karachi Campus, Karachi, Pakistan.
EM zeeshanahmed@nu.edu.pk; salima.hamma@univ-nantes.fr;
   zafarnasir@indus.edu.pk
CR Ahmed Z, 2012, INT S PERF EV COMP T
   Ahmed Z, 2011, 4 JOINT IFIP IEEE WI
   [Anonymous], 2007, IFIP INT C WIR OPT C
   [Anonymous], 2012, 802162012 IEEE
   [Anonymous], 80216E IEEE
   [Anonymous], 2017, ADV WIR MOD LIB
   [Anonymous], 1996, P ACM SIGCOMM
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Ball C. F., 2005, 2005 IEEE 16th International Symposium on Personal, Indoor and Mobile Radio Communications (IEEE Cat. No. 05TH8889), P888
   Belghith A, 2008, P 14 EUR WIR C, P1
   Bennett JCR, 1996, IEEE INFOCOM SER, P120, DOI 10.1109/INFCOM.1996.497885
   Chaari L, 2012, QUALITY SERVICE RESO
   Chan L, 2006, INT C WIR COMM NETW, P1
   Chang CY, 2015, IEEE SYST J, V9, P542, DOI 10.1109/JSYST.2013.2271386
   Chen J, 2005, IEEE GLOB TEL C IEEE
   Chen JF, 2005, IEEE ICC, P3422
   Cicconetti C, 2006, IEEE NETWORK, V20, P50, DOI 10.1109/MNET.2006.1607896
   CRUZ RL, 1991, IEEE T INFORM THEORY, V37, P114, DOI 10.1109/18.61109
   Da-Nung Lai, 2011, 2011 International Conference on Parallel Processing, P115, DOI 10.1109/ICPP.2011.81
   Dutta UK, 2018, IEEE ACCESS, V6, P7958, DOI 10.1109/ACCESS.2018.2799603
   Fei RD, 2009, 2009 INTERNATIONAL CONFERENCE ON SCALABLE COMPUTING AND COMMUNICATIONS & EIGHTH INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTING, P200, DOI 10.1109/EmbeddedCom-ScalCom.2009.44
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Gupta BB, 2018, MULTIMED TOOLS APPL, V77, P9203, DOI 10.1007/s11042-017-5301-x
   HAHNE E, 1986, IEEE INT C COMM
   Hanhart P, 2012, PROC SPIE, V8499, DOI 10.1117/12.946036
   Ibtihal M, 2017, INT J CLOUD APPL COM, V7, P27, DOI 10.4018/IJCAC.2017040103
   Jararweh Y, 2019, MULTIMED TOOLS APPL, V78, P3961, DOI 10.1007/s11042-017-5092-0
   KATEVENIS M, 1991, IEEE J SEL AREA COMM, V9, P1265, DOI 10.1109/49.105173
   Ku J. M., 2006, P IEEE WIR COMM NETW, V2, P1142
   Linzer EN, 2005, uS Patent, Patent No. [6,927,710, 6927710]
   Liu HY, 2017, MICROCHIM ACTA, V184, P1267, DOI 10.1007/s00604-017-2179-2
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Rangel V, 2006, OPNETWORK TECHN C WA
   Rukmani P, 2017, J ENG SCI TECHNOL, V12, P2551
   Safa H, 2007, I C COMP SYST APPLIC, P203, DOI 10.1109/AICCSA.2007.370884
   Sayenko A, 2008, COMPUT NETW, V52, P96, DOI 10.1016/j.comnet.2007.09.021
   Sayenko Alexander., 2006, Proceedings of the 9th ACM international symposium on Modeling analysis and simulation of wireless and mobile systems, P108, DOI DOI 10.1145/1164717.1164737
   Sengupta Shiladitya, 2005, International Journal of Human Genetics, V5, P1
   Shafi M, 2017, IEEE J SEL AREA COMM, V35, P1201, DOI 10.1109/JSAC.2017.2692307
   Shang Y, 2005, 3 INT C NETW MOB COM, P652
   Sharman K, 2017, 16WP3 ITUT SG
   Shreedhar M, 1996, IEEE ACM T NETWORK, V4, P375, DOI 10.1109/90.502236
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Wang LL, 2008, C IND ELECT APPL, P1716, DOI 10.1109/ICIEA.2008.4582813
   Wang Y, 2008, IEEE ICC, P301
   WG802. 16-Broadband Wireless Access Working Group, 2012, WG80216 IEEE
   Wongthavarawat K, 2003, INT J COMMUN SYST, V16, P81, DOI 10.1002/dac.581
   Xu Z., 2011, IEEE Non-Volatile Memory Technology Symposium (NVMTS), P1
NR 48
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25937
EP 25976
DI 10.1007/s11042-019-07801-z
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700032
DA 2024-07-18
ER

PT J
AU Cao, ZL
   Wang, LD
AF Cao, Zhenlei
   Wang, Lidan
TI A secure video watermarking technique based on hyperchaotic Lorentz
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperchaotic Lorentz system; Color image; Discrete wavelet transform;
   Video watermark; Specific frames
AB The advancement of multimedia and computer technology has facilitated increasing number of research on digital video watermarking. Video watermarking techniques can be used not only in the protection of multimedia video works' copyright, but also in the transmission of confidential data. This paper presents a color video watermarking algorithm based on hyperchaotic Lorentz system. Firstly, the color watermark images are scrambled using hyperchaotic Lorentz system to enhance its confidentiality. Secondly, we use shot boundary detection to extract non-motion frames of the video. Then the chaotic sequence is used to determine the specific frames among the non-motion frames. Next, we apply the discrete wavelet transform to specific frames to get the appropriate subbands. And finally the encrypted watermarks are embedded into the selected subbands. The performance of proposed method is evaluated by Peak Signal-to-Noise Ratio, Normalized Correlation and Structural Similarity Index Measure. Experiments showed that the average PSNR and SSIM of watermarked frames are 57.00 dB and 0.99, respectively, which indicate that the proposed method has high imperceptibility. The NC value of 1.00 proves that the watermark can be transmitted without loss under no attacks. And we also tested the robustness and imperceptibility in the presence of various attacks including image processing attacks, geometrical attacks and video attacks. The method we proposed enrich the digital watermarking techniques.
C1 [Cao, Zhenlei; Wang, Lidan] Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
   [Wang, Lidan] Natl & Local Joint Engn Lab Intelligent Transmiss, Chongqing 400715, Peoples R China.
   [Wang, Lidan] Brain Inspired Comp & Intelligent Control Chongqi, Chongqing 400715, Peoples R China.
C3 Southwest University - China
RP Cao, ZL (corresponding author), Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
EM 1174577193@qq.com
RI Wang, Lidan/H-5117-2013
OI Wang, Lidan/0000-0003-0730-4202
FU National Natural Science Foundation of China [61571372, 61672436];
   Fundamental Research Funds for the Central Universities [XDJK2016A001,
   XDJK2017A005]; Special key project of basic science and frontier
   technology research of Chongqing [cstc2017jcyjBX0050]
FX The work is supported by National Natural Science Foundation of China
   (Grant Nos. 61571372, 61672436), Fundamental Research Funds for the
   Central Universities (Grant Nos. XDJK2016A001, XDJK2017A005) and Special
   key project of basic science and frontier technology research of
   Chongqing (Grant Nos. cstc2017jcyjBX0050).
CR Agilandeeswari L, 2016, MULTIMED TOOLS APPL, V75, P7211, DOI 10.1007/s11042-015-2642-1
   Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   Ali M, 2014, SIGNAL PROCESS, V94, P545, DOI 10.1016/j.sigpro.2013.07.024
   [Anonymous], 2016, CHAOTIC DIGITAL IMAG
   Boreczky JS, 1996, J ELECTRON IMAGING, V5, P122, DOI 10.1117/12.238675
   Caragata D, 2015, AEU-INT J ELECTRON C, V69, P53, DOI 10.1016/j.aeue.2015.09.005
   Carnec M, 2008, SIGNAL PROCESS-IMAGE, V23, P239, DOI 10.1016/j.image.2008.02.003
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Dogan S, 2016, ARTIF INTELL REV, V46, P129, DOI 10.1007/s10462-016-9459-9
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Hartung F, 1998, SIGNAL PROCESS, V66, P283, DOI 10.1016/S0165-1684(98)00011-5
   Hsu CT, 1998, IEEE T CONSUM ELECTR, V44, P206, DOI 10.1109/30.663749
   Jiang TF, 2015, DIGITAL WATERMARKING
   Jiang XM, 2013, MULTIMED TOOLS APPL, V62, P545, DOI 10.1007/s11042-011-0857-3
   Khan MK, 2011, MULTIMED TOOLS APPL, V52, P257, DOI 10.1007/s11042-011-0741-1
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Liu JX, 2017, MULTIMED TOOLS APPL, V76, P24009, DOI 10.1007/s11042-016-4178-4
   Liu XY, 2017, NEUROCOMPUTING, V222, P155, DOI 10.1016/j.neucom.2016.10.015
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Mehta R, 2016, MULTIMED TOOLS APPL, V75, P4129, DOI 10.1007/s11042-015-3084-5
   Mohammed AA, 2018, MULTIMED TOOLS APPL, V77, P2791, DOI 10.1007/s11042-017-4427-1
   Singh RP, 2016, NEUROCOMPUTING, V174, P238, DOI 10.1016/j.neucom.2015.03.115
   Song XH, 2014, MULTIMEDIA SYST, V20, P379, DOI 10.1007/s00530-014-0355-3
   Sridhar B, 2017, INT J SMART SENS INT, V10, P387, DOI 10.21307/ijssis-2017-217
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P8781, DOI 10.1007/s11042-016-3522-z
   Su QT, 2015, DIGITAL IMAGE BLIND
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   Vaidya SP, 2017, MULTIMED TOOLS APPL, V76, P25623, DOI 10.1007/s11042-017-4355-0
   Wang W, 2016, WIRELESS COMMUNICATION AND SENSOR NETWORK, P711
   Wang W, 2018, COMPUT ELECTR ENG, V65, P282, DOI 10.1016/j.compeleceng.2017.07.026
   Wang XY, 2008, PHYSICA A, V387, P3751, DOI 10.1016/j.physa.2008.02.020
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang F, 2005, NEUROCOMPUTING, V67, P345, DOI 10.1016/j.neucom.2004.12.007
   Zheng PP, 2014, NEUROCOMPUTING, V142, P520, DOI 10.1016/j.neucom.2014.04.005
NR 36
TC 17
Z9 18
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26089
EP 26109
DI 10.1007/s11042-019-07809-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700038
DA 2024-07-18
ER

PT J
AU Dhiraj
   Biswas, R
   Ghattamaraju, N
AF Dhiraj
   Biswas, Rohit
   Ghattamaraju, Nischay
TI An effective analysis of deep learning based approaches for audio based
   feature extraction and its visualization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep neural networks; Convolutional autoencoder; VGG; Alexnet; Audio
   feature extraction; Genre classifiers; Audio visualization; PCA; K-means
AB Visualizations help decipher latent patterns in music and garner a deep understanding of a song's characteristics. This paper offers a critical analysis of the effectiveness of various state-of-the-art Deep Neural Networks in visualizing music. Several implementations of auto encoders and genre classifiers have been explored for extracting meaningful features from audio tracks. Novel techniques have been devised to map these audio features to parameters that drive visualizations. These methodologies have been designed in a manner that enables the visualizations to be responsive to the music as well as provide unique visual experiences across different songs.
C1 [Dhiraj] CSIR Cent Elect Engn Res Inst CEERI, Pilani, Rajasthan, India.
   [Biswas, Rohit; Ghattamaraju, Nischay] Birla Inst Technol & Sci, Pilani, Rajasthan, India.
C3 Council of Scientific & Industrial Research (CSIR) - India; CSIR -
   Central Electronics Engineering Research Institute (CEERI); Birla
   Institute of Technology & Science Pilani (BITS Pilani)
RP Dhiraj (corresponding author), CSIR Cent Elect Engn Res Inst CEERI, Pilani, Rajasthan, India.
EM dhiraj@ceeri.res.in; biswasrohit143@gmail.com; nischay1234@gmail.com
OI , Dhiraj/0000-0003-3972-8368
CR [Anonymous], 2017, CHIN J OCEANOL LIMNO
   [Anonymous], 2016, ARXIV160909430
   [Anonymous], 2018, WWW
   [Anonymous], 2002, P INT COMPUTER MUSIC
   [Anonymous], REAL TIME MUSIC VISU
   [Anonymous], AENET LEARNING DEEP
   [Anonymous], 2007, P LARG SCAL SEM ACC
   [Anonymous], VISUALIZING MUSIC AU
   [Anonymous], 2015, ARXIV150804999
   [Anonymous], ARXIV161201840
   [Anonymous], VISUALIZATION CONCUR
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], ABS150607643 CORR
   [Anonymous], P INT C COMP INT MUL
   [Anonymous], J REAL TIME IMAGE P
   [Anonymous], 2016, P INTERSPEECH
   [Anonymous], UNSUPERVISED AUDIO F
   [Anonymous], 2017, ARXIV170100599
   Baniya BK, 2014, IEEE SYS MAN CYBERN, P457, DOI 10.1109/SMC.2014.6973950
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Congote J., 2011, P 16 INT C 3D WEB TE, P137, DOI [DOI 10.1145/2010425.2010449, 10.1145/2010425.2010449]
   Dieleman Sander, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6964, DOI 10.1109/ICASSP.2014.6854950
   Ha D. R., 2017, A Neural Representation of Sketch Drawings
   Humphrey EJ, 2013, J INTELL INF SYST, V41, P461, DOI 10.1007/s10844-013-0248-5
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Kim Junghwan., 2018, WWW
   Mao XJ, 2016, ADV NEUR IN, V29
   Mierswa I, 2005, MACH LEARN, V58, P127, DOI 10.1007/s10994-005-5824-7
   Pascual S, 2017, INTERSPEECH, P3642, DOI 10.21437/Interspeech.2017-1428
   Reed S, 2016, PR MACH LEARN RES, V48
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Sigtia S, 2014, INT CONF ACOUST SPEE
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Umapathy K, 2007, IEEE T AUDIO SPEECH, V15, P1236, DOI 10.1109/TASL.2006.885921
   Wang HH, 2015, IEEE INT C BIOINFORM, P442, DOI 10.1109/BIBM.2015.7359724
   Wyse L., 2017, P 1 INT C DEEP LEARN, P37
   Zeiler M.D., 2013, ARXIV201313013557, P1
NR 40
TC 11
Z9 11
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 23949
EP 23972
DI 10.1007/s11042-018-6706-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900009
DA 2024-07-18
ER

PT J
AU Palacios, S
   Santos, V
   Barsallo, E
   Bhargava, B
AF Palacios, Servio
   Santos, Victor
   Barsallo, Edgardo
   Bhargava, Bharat
TI MioStream: a peer-to-peer distributed live media streaming on the edge
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Edge computing; Event-driven model; Media streaming; Peer-to-Peer;
   WebRTC
ID SERVICE
AB The typical centralized cloud model is poorly suited to latency-sensitive applications requiring low-latency and high-throughput. This paper proposes an integrity-preserving serverless framework for live-video streaming that runs on the edge of the network. We present the design, implementation, and evaluation of a novel P2P service based on WebRTC (web browsers with Real-Time Communications) called MioStream. MioStream is an open-source alternative for distributed media streaming that runs on the edge of the network without incurring in costly and extensive CDN infrastructure. We contribute a unique mix of algorithms using WebRTC data channels. For instance, under network degradation and high-churn environments, MioStream restructures the topology dynamically. MioStream provides authentication, privacy, and integrity of video chunks. This paper exposes a set of micro-benchmarks to measure the quality of service under network degradation and high churn environment (inducing failures). The Mesh topology offers the highest goodput per peer; the stalled playback on a node equals 1.8% of the total video play. Our results show the feasibility of this proof of concept under high-churn environments. The total stream interruptions in the topology are not longer than one second under a binomial distributed series of failures. The integrity check applied to each package includes a considerable overhead and impact the quality of service.
C1 [Palacios, Servio; Santos, Victor; Barsallo, Edgardo; Bhargava, Bharat] Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA.
C3 Purdue University System; Purdue University
RP Palacios, S (corresponding author), Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA.
EM spalacio@purdue.edu; vsantosu@purdue.edu; ebarsall@purdue.edu;
   bbshail@purdue.edu
OI Palacios, Servio/0000-0002-5009-096X; Barsallo Yi,
   Edgardo/0000-0002-0194-0163
CR Ferreira RA, 2006, J PARALLEL DISTR COM, V66, P257, DOI 10.1016/j.jpdc.2005.09.002
   García B, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1205, DOI 10.1145/3123266.3129392
   Grigorik I., 2013, High Performance Browser Networking: What Every Web Developer Should Know About Networking and Browser Performance
   Habib A, 2005, VERIFYING DATA INTEG, DOI 10. 1117/12. 587201
   Hefeeda M, 2005, MULTIMEDIA SYST, V11, P68, DOI 10.1007/s00530-005-0191-6
   Hefeeda M., 2003, Proceedings of the eleventh ACM international conference on Multimedia, ser. MULTIMEDIA '03, P45, DOI [DOI 10.1145/957013.957022, 10.1145/957013.957022]
   López L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1187, DOI 10.1145/2964284.2973798
   Loreto S., 2014, RealTime Communication withWebRTC: PeertoPeer in the Browser
   Modadugu N, 2004, P 2004 NETW DISTR SY, DOI 10.1.1.74.6613
   Ratnasamy S, 2001, ACM SIGCOMM COMP COM, V31, P161, DOI 10.1145/964723.383072
   Rhinow F., 2014, 2014 World Congress on Computer Applications and Information Systems (WCCAIS), P1, DOI DOI 10.1109/WCCAIS.2014.6916588
   Roverso R, 2012, IEEE 12 INT C PEER P, DOI [10. 1109/P2P. 2012. 633581310. 1109/P2P. 2012. 6335813, DOI 10.1109/P2P.2012.633581310.1109/P2P.2012.6335813]
   Rowstron A., 2001, Proceedings of the Middleware 2001, P329, DOI DOI 10.1007/3-540-45518-3_18
   Stoica I, 2001, ACM SIGCOMM COMP COM, V31, P149, DOI 10.1145/964723.383071
   Vogt Christian., 2013, 2013 21st, P1, DOI DOI 10.1109/ICNP.2013.6733637
   Wichtlhuber M, 2012, P IEEE 12 INT C PEER, DOI [10. 1109/P2P. 2012. 6335812, DOI 10.1109/P2P.2012.6335812]
NR 16
TC 4
Z9 5
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24657
EP 24680
DI 10.1007/s11042-018-6940-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900046
DA 2024-07-18
ER

PT J
AU Qiu, YG
   Duan, HT
   Sun, JY
   Gu, HH
AF Qiu, Yinguo
   Duan, Hongtao
   Sun, Jiuyun
   Gu, Hehe
TI Rich-information reversible watermarking scheme of vector maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rich-information watermarking; Reversible watermarking; Vector map;
   Copyright protection
AB With the increasing rampant infringements of vector maps, rich-information watermarking technology is being more and more essential for forceful copyright declaration. Most of the existing watermarking algorithms of vector maps, however, cannot embed abundant copyright information. In this paper, a rich-information and reversible watermarking scheme is proposed for vector maps based on the ideas of compression coding of watermarking image and decimal-hex conversion of vertex coordinates. It recodes the original watermarking image to shorten the length of the final watermark data and groups map vertices to choose cover data for watermark embedding. And the reversible embedding is then carried out by modifying the polar coordinates of map vertices. While the proposed compression coding method of watermarking image and the decimal-hex conversion of map vertices guarantee the embedding of rich-information watermark data, the reversible watermarking method provides recovery of the original map content. Comprehensive experimental results show that the proposed scheme is suitable for vector map applications where abundant copyright information is required while the number of map vertices is limited.
C1 [Qiu, Yinguo; Duan, Hongtao] Chinese Acad Sci, Key Lab Watershed Geog Sci, Nanjing Inst Geog & Limnol, Nanjing 210008, Jiangsu, Peoples R China.
   [Sun, Jiuyun; Gu, Hehe] China Univ Min & Technol, Sch Environm Sci & Spatial Informat, Xuzhou 221116, Jiangsu, Peoples R China.
C3 Chinese Academy of Sciences; Nanjing Institute of Geography & Limnology,
   CAS; China University of Mining & Technology
RP Gu, HH (corresponding author), China Univ Min & Technol, Sch Environm Sci & Spatial Informat, Xuzhou 221116, Jiangsu, Peoples R China.
EM qiuyinguo@foxmail.com
RI Qiu, Yinguo/IZD-6490-2023; Duan, Hongtao/B-7210-2011
OI Duan, Hongtao/0000-0002-1985-2292
FU National Natural Science Foundation of China [41171343]; Start-up
   Project for Talents of Nanjing Institute of Geography Limnology, CAS
   [NIGLAS2018QD07]
FX This research is supported by the National Natural Science Foundation of
   China (Grant No. 41171343) and the Start-up Project for Talents of
   Nanjing Institute of Geography & Limnology, CAS (Grant No.
   NIGLAS2018QD07).
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   Al-Otaibi NA, 2014, P 2014 INT C ADV ENG, P243
   Almazrooie M, 2020, J KING SAUD UNIV-COM, V32, P24, DOI 10.1016/j.jksuci.2018.02.006
   [Anonymous], 2018, J Inf Secur Cybercrimes Res (JISCR), DOI DOI 10.26735/16587790.2018.006
   [Anonymous], 2008, 5 IEEE INT WORKSH SI
   Cao LJ, 2015, SIGNAL IMAGE VIDEO P, V9, P1387, DOI 10.1007/s11760-013-0606-3
   Cao LJ, 2013, VISUAL COMPUT, V29, P231, DOI 10.1007/s00371-012-0732-x
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Gutub A, 2007, P INT C SEC CRYPT
   Gutub A, 2018, J. Comput. Hardw. Eng, V1, P1
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Jian-Guo Sun, 2014, International Journal of Network Security, V16, P40
   Khan F, 2007, 4 IEEE GCC C EXH GUL, P11
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Qiu YG, 2018, MULTIMED TOOLS APPL, V77, P23651, DOI 10.1007/s11042-018-5680-7
   Qiu YG, 2018, MULTIMED TOOLS APPL, V77, P6385, DOI 10.1007/s11042-017-4546-8
   Voigt M, 2005, P SOC PHOTO-OPT INS, V5681, P409, DOI 10.1117/12.588195
   Voigt M, 2004, P 2004 MULT SEC WORK, P160, DOI DOI 10.1145/1022431.1022459
   Vybornova YD, 2017, COMPUT OPT, V41, P913, DOI 10.18287/2412-6179-2017-41-6-913-919
   Xiao D, 2015, MULTIMED TOOLS APPL, V74, P2109, DOI 10.1007/s11042-013-1744-x
   Yan HW, 2017, EARTH SCI INFORM, V10, P471, DOI 10.1007/s12145-017-0310-x
   [杨成松 YANG Chengsong], 2010, [中国图象图形学报, Journal of Image and Graphics], V15, P684
   Yao XC, 2018, BIG EARTH DATA, V2, P108, DOI 10.1080/20964471.2018.1432115
NR 26
TC 8
Z9 11
U1 2
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24955
EP 24977
DI 10.1007/s11042-019-7681-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900058
DA 2024-07-18
ER

PT J
AU Rajput, SS
   Arya, KV
AF Rajput, Shyam Singh
   Arya, K. V.
TI A robust facial image super-resolution model via mirror-patch based
   neighbor representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face super-resolution; Face hallucination; Position-patch based
   reconstruction
ID FACE HALLUCINATION; REGULARIZATION; REGRESSION; SPARSITY
AB Many patch-based facial image super-resolution (or hallucination) techniques have been proposed in literature but all of them fail in the presence of high-density impulse noise and occlusion. A novel mirror-patch based neighbor representation (MPNR) model is proposed here which uses mirror-patch based data fidelity along with the input-patch based fidelity in low-resolution (LR) space to address the above problem. The computation of mirror-patch based data fidelity helps in compensating the corrupted features of an input patch through its mirror-patch. The objective function of the proposed model is designed in such a way that it hallucinate the input LR faces and takes care of occlusion/heavy noise effect simultaneously in the reconstruction process. It is conspicuous from experimental results attained on FEI and CAS-PEAL-R1 databases that the proposed MPNR model has outperformed all the comparative methods.
C1 [Rajput, Shyam Singh] Bennett Univ, Dept Comp Sci & Engn, Greater Noida 201310, India.
   [Arya, K. V.] ABV Indian Inst Informat Technol & Management, Multimedia & Informat Secur Res Grp, Gwalior 474015, India.
C3 ABV-Indian Institute of Information Technology & Management, Gwalior
RP Rajput, SS (corresponding author), Bennett Univ, Dept Comp Sci & Engn, Greater Noida 201310, India.
EM ershyamrajput@gmail.com; kvarya@iiitm.ac.in
RI Rajput, Shyam Singh/AAU-4448-2020
OI Arya, Karm Veer/0000-0001-7117-1745; Rajput, Shyam
   Singh/0000-0002-1244-7366
CR An L, 2014, SIGNAL PROCESS, V103, P184, DOI 10.1016/j.sigpro.2013.10.004
   [Anonymous], 2016, IEEE T CYBERNETICS
   Baker S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P83, DOI 10.1109/AFGR.2000.840616
   Berretti S, 2012, LECT NOTES COMPUT SC, V7583, P73, DOI 10.1007/978-3-642-33863-2_8
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen CLP, 2015, IEEE T IMAGE PROCESS, V24, P4014, DOI 10.1109/TIP.2015.2456432
   Chen L, 2017, MULTIMED TOOLS APPL, V76, P2467, DOI 10.1007/s11042-015-3145-9
   Chou HH, 2013, IEEE T CYBERNETICS, V43, P296, DOI 10.1109/TSMCB.2012.2205678
   Cui Z, 2018, 2018 IEEE THIRD INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, APPLICATIONS AND SYSTEMS (IPAS), P1, DOI 10.1109/IPAS.2018.8708883
   Dai XY, 2015, IEEE PHOTONICS J, V7, DOI 10.1109/JPHOT.2015.2414181
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Hu Y, 2011, IEEE T IMAGE PROCESS, V20, P433, DOI 10.1109/TIP.2010.2063437
   Huang H, 2011, IEEE T CIRC SYST VID, V21, P1363, DOI 10.1109/TCSVT.2011.2163461
   Huang H, 2010, PATTERN RECOGN, V43, P2532, DOI 10.1016/j.patcog.2010.02.007
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Jia K, 2008, IEEE T IMAGE PROCESS, V17, P873, DOI 10.1109/TIP.2008.922421
   Jiang JL, 2014, IEEE T IMAGE PROCESS, V23, P2651, DOI 10.1109/TIP.2014.2317985
   Jiang JJ, 2017, IEEE INT CON MULTI, P469, DOI 10.1109/ICME.2017.8019459
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P27, DOI 10.1109/TMM.2016.2601020
   Jiang JJ, 2016, IEEE T CIRC SYST VID, V26, P1674, DOI 10.1109/TCSVT.2015.2433538
   Jiang JJ, 2016, INFORM SCIENCES, V367, P354, DOI 10.1016/j.ins.2016.05.032
   Jiang JJ, 2016, INT CONF ACOUST SPEE, P2089, DOI 10.1109/ICASSP.2016.7472045
   Jiang JJ, 2014, IEEE T IMAGE PROCESS, V23, P4220, DOI 10.1109/TIP.2014.2347201
   Jiang JJ, 2014, IEEE T MULTIMEDIA, V16, P1268, DOI 10.1109/TMM.2014.2311320
   Jiang JJ, 2014, SIGNAL PROCESS, V103, P168, DOI 10.1016/j.sigpro.2014.02.014
   Jung CK, 2011, IEEE SIGNAL PROC LET, V18, P367, DOI 10.1109/LSP.2011.2140370
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Liu C, 2001, PROC CVPR IEEE, P192
   Liu L., 2017, IEEE T CYBERNETICS, P1, DOI [10.1109/ICSPCC.2017.8242518, DOI 10.1007/S11581-017-1972-6]
   Ma X, 2010, PATTERN RECOGN, V43, P2224, DOI 10.1016/j.patcog.2009.12.019
   Rajput Shyam Singh, 2019, Computational Intelligence: Theories, Applications and Future DirectionsVolume II. ICCI-2017. Advances in Intelligent Systems and Computing (AISC 799), P635, DOI 10.1007/978-981-13-1135-2_48
   Rajput SS, 2019, APPL INTELL, V49, P1324, DOI 10.1007/s10489-018-1340-x
   Rajput SS, 2018, INFORM SCIENCES, V463, P227, DOI 10.1016/j.ins.2018.06.050
   Rajput SS, 2018, SIGNAL PROCESS, V147, P233, DOI 10.1016/j.sigpro.2018.01.030
   Rohit U, 2017, MULTIMED TOOLS APPL, V76, P16809, DOI 10.1007/s11042-016-3953-6
   Shi JG, 2018, IEEE T IMAGE PROCESS, V27, P2980, DOI 10.1109/TIP.2018.2813163
   Shi JG, 2014, PATTERN RECOGN, V47, P3520, DOI 10.1016/j.patcog.2014.04.023
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang XG, 2005, IEEE T SYST MAN CY C, V35, P425, DOI 10.1109/TSMCC.2005.848171
   Xing R, 2014, INT C INTEL HUM MACH, P67, DOI 10.1109/IHMSC.2014.119
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang J, 2008, IEEE IMAGE PROC, P1264, DOI 10.1109/ICIP.2008.4711992
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
NR 44
TC 7
Z9 7
U1 8
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25407
EP 25426
DI 10.1007/s11042-019-07791-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700009
DA 2024-07-18
ER

PT J
AU Shamsolmoali, P
   Jain, DK
   Zareapoor, M
   Yang, J
   Alam, MA
AF Shamsolmoali, Pourya
   Jain, Deepak Kumar
   Zareapoor, Masoumeh
   Yang, Jie
   Alam, M. Afshar
TI High-dimensional multimedia classification using deep CNN and extended
   residual units
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High dimensional; Multimedia data classification; Deep learning; Feature
   extraction; Residual network
ID FEATURE-SELECTION; REPRESENTATION
AB Processing multimedia data has emerged as a key area for the application of machine learning methods Building a robust classification model to use in high dimensional space requires the combination of a deep feature extractor and a powerful classifier. We present a new classification pipeline to facilitate multimedia data analysis based on convolutional neural network and the modified residual network which can integrate with the other feedforward network style in an endwise training fashion. The proposed residual network is producing attention-aware features. We proposed a unified deep CNN model to achieve promising performance in classifying high dimensional multimedia data by getting the advantages of the residual network. In every residual module, up-down and vice-versa feedforward structure is implemented to unfold the feedforward and backward process into a unique process. The hybrid proposed model evaluated on four datasets and have been shown promising results which outperform the previous best results. Last but not the least, the proposed model achieves detection speeds that are much faster than other approaches.
C1 [Shamsolmoali, Pourya; Zareapoor, Masoumeh; Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai, Peoples R China.
   [Jain, Deepak Kumar] Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
   [Alam, M. Afshar] Jamia Hamdard, Dept Comp Sci & Engn, New Delhi, India.
C3 Shanghai Jiao Tong University; Chinese Academy of Sciences; Institute of
   Automation, CAS; Jamia Hamdard University
RP Shamsolmoali, P (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai, Peoples R China.
EM pshams55@gmail.com; jieyang@sjtu.edu.cn
RI Zareapoor, Dr. Masoumeh/AAE-6067-2019; Yang, Jie/JCD-9867-2023
OI Zareapoor, Dr. Masoumeh/0000-0002-3991-0584; Zareapoor,
   Masoumeh/0000-0002-7569-9018
FU NSFC, China [61572315]; Committee of Science and Technology, Shanghai,
   China [17JC1403000]
FX This research is partly supported by NSFC, China (No: 61572315) and
   Committee of Science and Technology, Shanghai, China (No: 17JC1403000).
CR [Anonymous], IEEE INT C MULT EXP
   [Anonymous], 2014, P 5 ACM MULT SYST C
   [Anonymous], 2011, INT C ARTIFICIAL INT
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], 2016, ARXIV160608572
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2015, JMLR
   [Anonymous], MEDIAEVAL WORKSH
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], VLUDS
   [Anonymous], CVPR 2015
   [Anonymous], 2017, INTELL AUTOM SOFT CO, DOI DOI 10.1080/10798587.2017.1321228.544
   [Anonymous], INT J INF COMMUN TEC
   [Anonymous], PRINCIPAL COMPONENT
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Bianco S, 2017, J IMAGING, V3, DOI 10.3390/jimaging3030033
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Cheng DB, 2017, MULTIMEDIA SYST, V23, P285, DOI 10.1007/s00530-015-0487-0
   Cui GQ, 2016, INT CONF SYST INFORM, P1028, DOI 10.1109/ICSAI.2016.7811102
   Du SY, 2017, MULTIMEDIA SYST, V23, P293, DOI 10.1007/s00530-015-0483-4
   Fan JQ, 2008, ANN STAT, V36, P2605, DOI 10.1214/07-AOS504
   Gao LL, 2017, MULTIMEDIA SYST, V23, P303, DOI 10.1007/s00530-015-0494-1
   Getoor, 2011, P 28 INT C MACH LEAR, P833
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   He YS, 2016, IEEE WORK ADV ROBOT, P110, DOI 10.1109/ARSO.2016.7736266
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Jiang W, 2006, IEEE T IMAGE PROCESS, V15, P702, DOI 10.1109/TIP.2005.863105
   Kim KW, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071534
   Lu C, 2015, LECT NOTES COMPUT SC, V9315, P236, DOI 10.1007/978-3-319-24078-7_23
   Napoletano P, 2017, LECT NOTES COMPUT SC, V10213, P259, DOI 10.1007/978-3-319-56010-6_22
   Ng Andrew Y, 2012, P 26 ANN C NEUR PROC, P665, DOI DOI 10.1002/2014GB005021
   Nie WZ, 2017, MULTIMEDIA SYST, V23, P325, DOI 10.1007/s00530-015-0485-2
   Rehman A, 2015, EXPERT SYST APPL, V42, P3670, DOI 10.1016/j.eswa.2014.12.013
   Reunanen J., 2003, Journal of Machine Learning Research, V3, P1371, DOI 10.1162/153244303322753715
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Salakhutdinov R., 2009, AISTATS
   Schnitzer Dominik, 2014, Advances in Information Retrieval. 36th European Conference on IR Research, ECIR 2014. Proceedings: LNCS 8416, P687, DOI 10.1007/978-3-319-06028-6_77
   Seeja KR, 2014, SCI WORLD J, DOI 10.1155/2014/252797
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Song JK, 2013, IEEE T MULTIMEDIA, V15, P1997, DOI 10.1109/TMM.2013.2271746
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Uljarevic D, 2017, MULTIMEDIA SYST, V23, P333, DOI 10.1007/s00530-015-0492-3
   Walther D, 2002, LECT NOTES COMPUT SC, V2525, P472
   Wang W, 2014, IEEE COMPUT SOC CONF, P496, DOI 10.1109/CVPRW.2014.79
   Yan YL, 2015, IEEE INT SYM MULTIM, P483, DOI 10.1109/ISM.2015.126
   Zareapoor M, 2018, PATTERN RECOGN LETT, V115, P4, DOI 10.1016/j.patrec.2017.09.018
   Zareapoor M, 2015, PROCEDIA COMPUT SCI, V48, P679, DOI 10.1016/j.procs.2015.04.201
   Zhao ZC, 2018, MULTIMED TOOLS APPL, V77, P3209, DOI 10.1007/s11042-017-5058-2
   Zhou WX, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050489
   Zhu XF, 2017, MULTIMEDIA SYST, V23, P281, DOI 10.1007/s00530-016-0524-7
   Zhu YH, 2017, MULTIMEDIA SYST, V23, P351, DOI 10.1007/s00530-015-0486-1
NR 52
TC 12
Z9 12
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 23867
EP 23882
DI 10.1007/s11042-018-6146-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900005
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Lv, PH
   Lu, XB
   Li, J
AF Zhang, Yang
   Lv, Peihua
   Lu, Xiaobo
   Li, Jun
TI Face detection and alignment method for driver on highroad based on
   improved multi-task cascaded convolutional networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent transportation system; Face detection and alignment;
   Multi-task; Convolutional networks; Deep learning
ID RECOGNITION; ALGORITHM
AB Driver's face detection and alignment techniques in Intelligent Transportation System (ITS) under unlimited environment are challenging issues, which are conductive to supervising traffic order and maintaining public safety. This paper proposes the improved Multi-task Cascaded Convolutional Networks (ITS-MTCNN) to realize accurate face region detection and feature alignment of driver's face on highway, predicting face and feature location via a coarse-to-fine pattern. Moreover, the improved regularization method and effective online hard sample mining technique are proposed in ITS-MTCNN method. Then, the training model and contrast experiment are conducted on our self-build traffic driver's face database. Finally, the effectiveness of ITS-MTCNN method is validated by comparative experiments and verified under various complex highway conditions. At the same time, average alignment errors on left eye, right eye, nose, left mouth as well as right mouth of the proposed technique are performed. Experimental results show that ITS-MTCNN model shows satisfied performance compared to other state-of-the-art techniques used in driver's face detection and alignment, keeping robust to the occlusion, varying pose and extreme illumination on highway.
C1 [Zhang, Yang; Lv, Peihua; Lu, Xiaobo] Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
   [Zhang, Yang; Lv, Peihua; Lu, Xiaobo] Southeast Univ, Key Lab Measurement & Control Complex Syst Engn, Minist Educ, Nanjing 210096, Jiangsu, Peoples R China.
   [Li, Jun] Univ Technol Sydney, Fac Engn & Informat Technol, Ultimo, NSW 2007, Australia.
C3 Southeast University - China; Southeast University - China; University
   of Technology Sydney
RP Lu, XB (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.; Lu, XB (corresponding author), Southeast Univ, Key Lab Measurement & Control Complex Syst Engn, Minist Educ, Nanjing 210096, Jiangsu, Peoples R China.
EM xblu2013@126.com
OI Li, Jun/0000-0002-1336-2241
FU National Natural Science Foundation Projects of China [61871123];
   National Natural Science Foundation of China [61374194]; National Key
   Science and Technology Pillar Program of China [2014BAG01B03]; Key
   Research and Development Program of Jiangsu Province [BE2016739]; Public
   Security Department of Jiangsu Province
FX We would like to thank the National Natural Science Foundation Projects
   of China (No. 61871123), National Natural Science Foundation of China
   (No. 61374194), National Key Science and Technology Pillar Program of
   China (No. 2014BAG01B03) Key Research and Development Program of Jiangsu
   Province (No. BE2016739) for funding. In addition, we would like to
   thank the Public Security Department of Jiangsu Province for providing
   PSD-HIGHROAD database.
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   Alsmirat MA, 2018, Multimed Tools Appl
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], J COMMUNITY PSYCHOL
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23
   Chen DP, 2014, LECT NOTES COMPUT SC, V8689, P345, DOI 10.1007/978-3-319-10590-1_23
   Cheng ZY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3291060
   Chiang Hsin-Han, 2012, IEEE SYSTEMS J, V8, P681
   Gao SH, 2015, IEEE T INF FOREN SEC, V10, P2108, DOI 10.1109/TIFS.2015.2446438
   Guo Yangyang, 2018, 2018 ACM MULT C MULT
   Gupta B.B., 2018, Computer and Cyber Security: Principles, Algorithm, Applications, and Perspectives
   Hu CH, 2017, PATTERN RECOGN, V64, P60, DOI 10.1016/j.patcog.2016.10.029
   Jain V., 2010, FDDB BENCHMARK FACE, V2
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LI HX, 2015, PROC CVPR IEEE, P5325, DOI DOI 10.1109/CVPR.2015.7299170
   Marin-Jimenez MJ, 2014, INT J COMPUT VISION, V106, P282, DOI 10.1007/s11263-013-0655-7
   Martinez CM, 2018, IEEE T INTELL TRANSP, V19, P666, DOI 10.1109/TITS.2017.2706978
   Petty T., 2016, Handbook of Research on Professional Development for Quality Teaching and Learning
   Pham Minh-Tri, 2010, 2010 IEEE COMP SOC C
   Ramanan D, 2012, P 2012 IEEE C COMP V
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Van Gool Luc, 2006, 18 INT C PATT REC IC, V3
   Vetter Thomas, 2011, 2011 INT C COMP VIS
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yang B., 2014, IEEE INT JOINT C BIO, P1
   Yang S, 2016, PROC CVPR IEEE, P5525, DOI 10.1109/CVPR.2016.596
   Zeng WL, 2011, ELECTRON LETT, V47, P1125, DOI 10.1049/el.2011.2456
   Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao SC, 2016, MULTIMED TOOLS APPL, V75, P8921, DOI 10.1007/s11042-014-2342-2
   Zhao SC, 2013, NEUROCOMPUTING, V119, P101, DOI 10.1016/j.neucom.2012.04.042
   ZHENG Q, 2018, IEEE ACCESS, V6, P21075, DOI DOI 10.1109/ACCESS.2018.2820603
   Zhu Qiang, 2006, 2006 IEEE COMPUTER S, V2
   Zou LM, 2019, MULTIMED TOOLS APPL, V78, P7965, DOI 10.1007/s11042-018-6444-0
NR 39
TC 7
Z9 7
U1 1
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26661
EP 26679
DI 10.1007/s11042-019-07836-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700061
DA 2024-07-18
ER

PT J
AU Zheng, S
   Chen, J
   Kuo, YH
AF Zheng, Shuai
   Chen, Jian
   Kuo, Yonghong
TI A multi-level residual reconstruction based image compressed sensing
   recovery scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sensing; Image reconstruction; Multi-level residual
   reconstruction; Constraint-adaptive
ID ALGORITHM
AB Traditional image compressed sensing recovery focuses on the research of sparse representation and reweight processing of measurements. However, the image content and structural feature vary dramatically in different natural images. The improvements in reconstruction quality brought by exploring new sparse representation models are not satisfactory. This paper focuses on a multimedia application scenario where the encoder is resource-constrained and the decoder has powerful computing ability. A novel image compressed sensing recovery scheme based on multi-level residual reconstruction is proposed to further improve the reconstruction quality. By converting the original image recovery to the multi-level residual image recovery, the reconstruction process is divided into three phases. The hidden information in image recovery is fully utilized. Moreover, a constraint-adaptive recovery model is proposed to perform the initial reconstruction of the original image and the initial residual image reconstruction. Combining the multihypothesis prediction, the final recovered residual image is obtained in the secondary residual image recovery phase. The final recovered image is obtained by combining the recovered original image and the residual image. Experimental results show that our proposal outperforms the state-of-the-art methods for image compressed sensing reconstruction in both objective and subjective quality.
C1 [Zheng, Shuai; Chen, Jian; Kuo, Yonghong] Xidian Univ, Sch Telecommun Engn, Xian 710071, Peoples R China.
C3 Xidian University
RP Chen, J (corresponding author), Xidian Univ, Sch Telecommun Engn, Xian 710071, Peoples R China.
EM zhs_xd@163.com; jianchen@mail.xidian.edu.cn; yhkuo@mail.xidian.edu.cn
RI KUO, Yong-Hong/M-9078-2015; Zheng, Shuai/AAH-5647-2020
FU National Natural Science Foundation of China [61771366]; "111" project
   [B08038]
FX This work was supported by National Natural Science Foundation of China
   (Grant No. 61771366) and the "111" project (Grant No. B08038).
CR Afonso MV, 2010, IEEE T IMAGE PROCESS, V19, P2345, DOI 10.1109/TIP.2010.2047910
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], COMPUTATIONAL IMAG 4
   [Anonymous], 2009, THESIS
   [Anonymous], 2017, ARXIV170205743
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571
   Becker S, 2011, SIAM J IMAGING SCI, V4, P1, DOI 10.1137/090756855
   Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Chen C, 2011, CONF REC ASILOMAR C, P1193, DOI 10.1109/ACSSC.2011.6190204
   Chen J, 2017, CIRC SYST SIGNAL PR, V36, P1621, DOI 10.1007/s00034-016-0432-2
   Chen J, 2015, MULTIMED TOOLS APPL, V74, P2085, DOI 10.1007/s11042-013-1743-y
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Hao WL, 2015, ELECTRON LETT, V51, P1740, DOI 10.1049/el.2015.2551
   He LH, 2010, IEEE SIGNAL PROC LET, V17, P233, DOI 10.1109/LSP.2009.2037532
   He LH, 2009, IEEE T SIGNAL PROCES, V57, P3488, DOI 10.1109/TSP.2009.2022003
   Hosseini MS, 2014, IEEE T IMAGE PROCESS, V23, P3869, DOI 10.1109/TIP.2014.2332755
   Li Chengbo., 2009, Tval3: Tv minimization by augmented lagrangian and alternating direction algorithm
   Li HH, 2018, MACH VISION APPL, V29, P145, DOI 10.1007/s00138-017-0882-y
   Ma S, 2008, CAIRO INT BIOM ENG, P163
   Mun S, 2009, IEEE IMAGE PROC, P3021, DOI 10.1109/ICIP.2009.5414429
   Mun S, 2011, IEEE DATA COMPR CONF, P183, DOI 10.1109/DCC.2011.25
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sadeghipoor Z, 2013, P IEEE INT C AC SPEE, P1
   Shu XB, 2010, LECT NOTES COMPUT SC, V6316, P393
   Song XD, 2017, IEEE T MULTIMEDIA, V19, P1351, DOI 10.1109/TMM.2017.2654123
   Wang NN, 2011, INT GEOSCI REMOTE SE, P640, DOI 10.1109/IGARSS.2011.6049210
   Wang YH, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0315-5
   Xiao YH, 2012, J MATH IMAGING VIS, V44, P114, DOI 10.1007/s10851-011-0314-y
   Xu J, 2012, SIGNAL PROCESS, V92, P2614, DOI 10.1016/j.sigpro.2012.04.001
   Zhang J, 2014, IEEE T IMAGE PROCESS, V23, P3336, DOI 10.1109/TIP.2014.2323127
   Zhang J, 2014, SIGNAL PROCESS, V103, P114, DOI 10.1016/j.sigpro.2013.09.025
   Zhang J, 2012, IEEE DATA COMPR CONF, P287, DOI 10.1109/DCC.2012.71
   Zhang J, 2012, CLEANER COMBUSTION AND SUSTAINABLE WORLD, P283
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang WH, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCES ON BIG DATA AND CLOUD COMPUTING (BDCLOUD 2016) SOCIAL COMPUTING AND NETWORKING (SOCIALCOM 2016) SUSTAINABLE COMPUTING AND COMMUNICATIONS (SUSTAINCOM 2016) (BDCLOUD-SOCIALCOM-SUSTAINCOM 2016), P1, DOI 10.1109/BDCloud-SocialCom-SustainCom.2016.12
   Zhao C, 2017, IEEE T CIRC SYST VID, V27, P1182, DOI 10.1109/TCSVT.2016.2527181
NR 40
TC 2
Z9 2
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 25101
EP 25119
DI 10.1007/s11042-019-07746-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900065
DA 2024-07-18
ER

PT J
AU Bahran, NA
   El-Shafai, W
   Zekry, A
   El-Rabaie, S
   El-Halawany, MM
   Abd El-Samie, FE
AF Bahran, N. A.
   El-Shafai, W.
   Zekry, A.
   El-Rabaie, S.
   El-Halawany, M. M.
   Abd El-Samie, F. E.
TI An FPGA design and implementation of EPZS motion estimation algorithm
   for 3D H.264/MVC standard
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D video; Motion compensation and estimation; 3D H; 264; MVC standard;
   EPZS; FPGA
ID SEARCH ALGORITHM
AB In the Three-Dimensional H.264 Multi-view Video Coding (3D H.264/MVC), the original 3D Video (3DV) sequence is a combination of variable video frames captured for the same object by different cameras. Therefore, in order to transmit 3DV content over limited-resources networks, a highly-efficient compression mechanism must be applied, while achieving a better reception quality. Moreover, in real-time applications such as 3DV conference and streaming, it is mandatory that the process of 3DV compression/decompression is speedy. Because it is known that most of the design complexity of the utilized 3D H.264/MVC codec come from the encoder part not from the decoder part, where the Motion Estimation (ME) process presents the highest computational complexity. In this work, an efficient implementation of the Enhanced Predictive Zonal Search (EPZS) ME algorithm is introduced for the 3D H.264/MVC standard. The EPZS algorithm is one of the most common and best ME algorithms. The overall inter-frame and inter-view prediction mechanisms including Motion Compensation (MC) and ME have been implemented. For validation and comparative analysis purposes, the outcomes of the suggested 3DV design for the EPZS ME algorithm are contrasted to more state-of-the-art ME algorithms. The suggested architecture of the EPZS ME algorithm is implemented in VHDL, synthesized utilizing Xilinx Virtex-6 FPGA and Xilinx ISE Design Suite 13.3, simulated employing ModelSim SE 6.5, and validated utilizing MATLAB SIMULINK. Experimental results prove that the suggested architecture achieves a low hardware complexity implementation and high-speed of 3D H.264/MVC compression process. This can be exploited for the utilization of the proposed work for real-time 3DV applications.
C1 [Bahran, N. A.; Zekry, A.] Ain Shams Univ, Dept Elect & Commun Engn, Fac Engn, Cairo, Egypt.
   [El-Shafai, W.; El-Rabaie, S.; El-Halawany, M. M.; Abd El-Samie, F. E.] Menoufia Univ, Dept Elect & Elect Commun Engn, Fac Elect Engn, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Ain Shams University; Egyptian Knowledge
   Bank (EKB); Menofia University
RP El-Shafai, W (corresponding author), Menoufia Univ, Dept Elect & Elect Commun Engn, Fac Elect Engn, Menoufia 32952, Egypt.
EM albahrany12@gmail.com; eng.waled.elshafai@gmail.com;
   aaazekry@hotmail.com; elsayedelrabaie@gmail.com;
   mmohamedelhalawany@gmail.com; fathi_sayed@yahoo.com
RI Zekry, Abdelhalim/AAJ-3544-2021; Sayed, Fathi/HRA-4752-2023; El-Shafai,
   Walid/AAG-4796-2021
OI Sayed, Fathi/0000-0001-8749-9518; El-Shafai, Walid/0000-0001-7509-2120;
   zekry, abdelhalim/0000-0002-8752-9534; EL-Rabaie,
   El-Sayed/0000-0001-6854-5881
CR [Anonymous], 2015, H 264 AVC CODEC REFE
   [Anonymous], 1981, P NAT TEL C NTC NEW
   [Anonymous], 2018, STANDARD TESTING VID
   [Anonymous], 2016, WD 4 REFERENCE SOFTW
   [Anonymous], 2017, MODELSIM SOFTWARE
   [Anonymous], 2006, JTC1SC29WG11 ISOIEC
   Bala U, 2016, INT J ADV RES TRENDS
   Bhavsar D, 2014, P IRF INT C
   Chen Y, 2014, IEEE MULTIMEDIA, V21, P90, DOI 10.1109/MMUL.2014.31
   Choudhury H, 2013, INT J ADV COMPUT ENG, V1 10, P2320
   De Abreu A, 2015, IEEE J-STSP, V9, P487, DOI 10.1109/JSTSP.2015.2407320
   GHANBARI M, 1990, IEEE T COMMUN, V38, P950, DOI 10.1109/26.57512
   Hewage CTER, 2013, IEEE COMMUN MAG, V51, P101, DOI 10.1109/MCOM.2013.6515053
   Hosur P, 1999, P 2 INT C INF COMM S, P7
   Iain E., 2003, H 264 MPEG 4 VIDEO C
   Iain E.R., 2010, The H.264 Advanced Video Compression Standard, V2nd ed.
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Lin YC, 1997, IEEE T COMMUN, V45, P527, DOI 10.1109/26.592551
   Liu Z, 2013, IEEE T CIRC SYST VID, V23, P1781, DOI 10.1109/TCSVT.2013.2269019
   Mittal A, 2017, LOW POWER MOTION EST
   Nagai S, 2015, P 19 WORKSH SYNTH SY, P386
   Nie Y, 2002, IEEE T IMAGE PROCESS, V11, P1442, DOI 10.1109/TIP.2002.806251
   Ozcinar C, 2016, MULTIMED TOOLS APPL, V75, P12431, DOI 10.1007/s11042-016-3475-2
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Purica AI, 2016, IEEE T CIRC SYST VID, V26, P360, DOI 10.1109/TCSVT.2015.2389511
   Raghava R, 2014, INT J ELECT COMMUNIC, V5, P34
   Tourapis A. M., 2001, ISCAS 2001. The 2001 IEEE International Symposium on Circuits and Systems (Cat. No.01CH37196), P183, DOI 10.1109/ISCAS.2001.922015
   Tourapis A. M., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P610, DOI 10.1109/ICIP.1999.822967
   Tourapis AM, 2002, IEEE T CIRC SYST VID, V12, P934, DOI 10.1109/TCSVT.2002.804894
   Tourapis AM, 2002, PROC SPIE, V4671, P1069, DOI 10.1117/12.453031
   Tourapis AM, 2001, P SOC PHOTO-OPT INS, V4310, P883
   Tourapis AM, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL III, P674, DOI 10.1109/ISCAS.2000.856150
   Tourapis H.-Y. C., 2003, Proceedings 2003 International Conference on Multimedia and Expo (Cat. No.03TH8698), pIII, DOI 10.1109/ICME.2003.1221362
   Xiang W, 2017, IEEE SYST J, V11, P2456, DOI 10.1109/JSYST.2015.2414662
   Zeng HQ, 2014, IEEE T CIRC SYST VID, V24, P1566, DOI 10.1109/TCSVT.2014.2310143
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 36
TC 4
Z9 5
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22351
EP 22396
DI 10.1007/s11042-019-7562-z
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400009
DA 2024-07-18
ER

PT J
AU Dhar, S
   Kundu, MK
AF Dhar, Soumyadip
   Kundu, Malay K.
TI Interval type-2 fuzzy set and human vision based multi-scale geometric
   analysis for text-graphics segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text-graphics segmentation; Interval type-2; Fuzzy; HVS; Segmentation
   bound
ID CONTOURLET TRANSFORM; IMAGE-ANALYSIS; RECOGNITION
AB This paper presents a novel method for texture-based text-graphic segmentation in a text embedded image. In the method, features are computed applying Multi-scale Geometric Analysis(MGA). The MGA of the image is done by Nonsubsampled contourlet transform(NSCT). The NSCT sub-bands help to generate the features which represent textures of the text portions and graphics portions of the image. In a segmentation process, the uncertainties arise mainly for two reasons: one is the ambiguity in gray level and other is the spatial ambiguity. Here the uncertainties are managed by interval type2 fuzzy set (IT2FS). The human vision model called human psychovisual phenomenon (HVS) is incorporated in the process for generating the interval type-2 fuzzy membership functions (IT2FMF). The efficiency of the proposed scheme is measured on the benchmark dataset. The robustness and performance bound of the proposed technique under noise corruption are measured statistically using modified Cramer-Rao bound. We found that effectiveness of the features by NSCT in combination with the IT2FS are quite promising in comparison to the state-of-the-arts methods.
C1 [Dhar, Soumyadip] RCCIIT, Kolkata 700010, India.
   [Kundu, Malay K.] ISI, BT Rd, Kolkata 700108, India.
C3 RCC Institute of Information Technology (RCCIIT); Indian Statistical
   Institute; Indian Statistical Institute Kolkata
RP Dhar, S (corresponding author), RCCIIT, Kolkata 700010, India.
EM rccsoumya@gmail.com; malay@isical.ac.in
RI Dhar, Soumyadip/JNE-1736-2023
CR Acharyya M, 2002, IEEE T CIRC SYST VID, V12, P1117, DOI 10.1109/TCSVT.2002.806812
   Acharyya M, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P622, DOI 10.1109/ICIP.2001.958570
   [Anonymous], 2018, ABS181104256 CORR
   Bai B, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P262, DOI 10.1109/DAS.2014.34
   Bustince H, 2006, FUZZY SET SYST, V157, P2333, DOI 10.1016/j.fss.2006.03.018
   Candès EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116
   Chan W, 2001, PATTERN RECOGN, V34, P2523, DOI 10.1016/S0031-3203(00)00155-2
   Chen DT, 2004, PATTERN RECOGN, V37, P595, DOI 10.1016/j.patcog.2003.06.001
   Cho H, 2016, PROC CVPR IEEE, P3566, DOI 10.1109/CVPR.2016.388
   Cho N.I., 2018, ARXIV180107848
   Chung- Wei Liang and Po-Yueh Chen, 2004, INT J APPL SCI ENG, V2, P105
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Nguyen DT, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030699
   Dhar S, 2017, APPL SOFT COMPUT, V61, P412, DOI 10.1016/j.asoc.2017.08.005
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Gómez L, 2013, PROC INT CONF DOC, P467, DOI 10.1109/ICDAR.2013.100
   Grana C, 2016, MULTIMED TOOLS APPL, V75, P3879, DOI 10.1007/s11042-014-2360-0
   Hartnett Kevin., 2019, Quanta Magazine
   He P, 2017, P INT C COMP VIS ICC
   He T, 2016, IEEE T IMAGE PROCESS, V25, P2529, DOI 10.1109/TIP.2016.2547588
   Huang WL, 2013, IEEE I CONF COMP VIS, P1241, DOI 10.1109/ICCV.2013.157
   Huang WL, 2014, LECT NOTES COMPUT SC, V8692, P497, DOI 10.1007/978-3-319-10593-2_33
   Karnik NN, 1989, P INT C FUZZ SYST, P915
   Kim SH, 2016, MULTIMED TOOLS APPL, V75, P12815, DOI 10.1007/s11042-015-3237-6
   Kobchaisawat T, 2014, ASIAPAC SIGN INFO PR
   Kundu MK, 2012, PROCEEDINGS OF THE 2012 INTERNATIONAL CONFERENCE ON COMMUNICATIONS, DEVICES AND INTELLIGENT SYSTEMS (CODLS), P85, DOI 10.1109/CODIS.2012.6422142
   KUNDU MK, 1986, PATTERN RECOGN LETT, V4, P433, DOI 10.1016/0167-8655(86)90041-3
   Kundu MK, 2003, INT J WAVELETS MULTI, V1, P115, DOI DOI 10.1142/S0219691303000074
   Lan Z., 2016, P IEEE C COMP VIS PA, P123
   Le Pennec E, 2000, IEEE IMAGE PROC, P661, DOI 10.1109/ICIP.2000.901045
   Li Y, 2012, INT C PATT RECOG, P681
   Liu Z, 2017, INT CONF IMAG VIS
   López F, 2005, LECT NOTES COMPUT SC, V3523, P666
   Lucas SM, 2005, PROC INT CONF DOC, P80, DOI 10.1109/ICDAR.2005.231
   Maji P, 2015, APPL SOFT COMPUT, V30, P705, DOI 10.1016/j.asoc.2015.01.049
   Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133
   MURTHY CA, 1992, INFORM SCIENCES, V60, P107, DOI 10.1016/0020-0255(92)90007-U
   NAGY G, 1992, COMPUTER, V25, P10, DOI 10.1109/2.144436
   Park J, 2010, PATTERN RECOGN LETT, V31, P1728, DOI 10.1016/j.patrec.2010.05.024
   Peng RB, 2015, COMPUT VIS IMAGE UND, V132, P24, DOI 10.1016/j.cviu.2014.11.004
   Rosenfeld A, 1998, INFORM SCIENCES, V110, P127, DOI 10.1016/S0020-0255(98)10038-5
   Roy S, 1996, INFORM SCIENCES, V89, P193, DOI 10.1016/0020-0255(95)00232-4
   Shi CZ, 2013, PATTERN RECOGN LETT, V34, P107, DOI 10.1016/j.patrec.2012.09.019
   Szmidt E, 2001, FUZZY SET SYST, V118, P467, DOI 10.1016/S0165-0114(98)00402-3
   Tian Z, 2016, P EUR C COMP VIS ECC
   Wei YW, 2017, SIGNAL PROCESS-IMAGE, V50, P1, DOI 10.1016/j.image.2016.10.003
   Yang HJ, 2014, MULTIMED TOOLS APPL, V69, P217, DOI 10.1007/s11042-012-1250-6
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Yi Chucai, 2011, IEEE Trans Image Process, V20, P2594, DOI 10.1109/TIP.2011.2126586
   Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182
   Zhu AN, 2015, PATTERN RECOGN LETT, V67, P153, DOI 10.1016/j.patrec.2015.06.009
   Zhu WS, 2017, AIP CONF PROC, V1890, DOI 10.1063/1.5005199
   Zhu YY, 2016, FRONT COMPUT SCI-CHI, V10, P19, DOI 10.1007/s11704-015-4488-0
NR 54
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22939
EP 22957
DI 10.1007/s11042-019-7649-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400034
DA 2024-07-18
ER

PT J
AU Pavlovic, A
   Glisovic, N
   Gavrovska, A
   Reljin, I
AF Pavlovic, Aleksandra
   Glisovic, Natasa
   Gavrovska, Ana
   Reljin, Irini
TI Copy-move forgery detection based on multifractals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; CMFD (copy-move forgery detection); Multifractal
   spectrum; Holder exponent; Metaheuristic method; Semi-metric
AB Digital images and video are the basic media for communication nowadays. They are used as authenticated proofs or corroboratory evidence in different areas like: forensic studies, law enforcement, journalism and others. With development of software for editing digital images, it has become very easy to change image content, add or remove important information or even to make one image combining multiple images. Thus, the development of methods for such change detection has become very important. One of the most common methods is copy-move forgery detection (CMFD). Methods of this type include change detection that occur by copying a part of an image and pasting it to another location within the image. We propose new method for detection of such changes using certain multifractal parameters as characteristic features, as well as common statistical parameters. Before the analysis, images are divided into non-overlapping blocks of fixed dimensions. For each block, the characteristic features are calculated. In order to classify observed blocks, we used metaheuristic method and proposed new semi-metric function for similarity analysis between blocks. Simulation shows that the proposed method provides good results in terms of precision and recall, with low computational complexity.
C1 [Pavlovic, Aleksandra; Gavrovska, Ana; Reljin, Irini] Univ Belgrade, Sch Elect Engn, Telecommun Dept, Bulevar Kralja Aleksandra 73, Belgrade 11020, Serbia.
   [Pavlovic, Aleksandra; Glisovic, Natasa] State Univ Novi Pazar, Dept Tech Sci, Vuka Karadzica 36300, Novi Pazar, Serbia.
C3 University of Belgrade
RP Pavlovic, A (corresponding author), Univ Belgrade, Sch Elect Engn, Telecommun Dept, Bulevar Kralja Aleksandra 73, Belgrade 11020, Serbia.; Pavlovic, A (corresponding author), State Univ Novi Pazar, Dept Tech Sci, Vuka Karadzica 36300, Novi Pazar, Serbia.
EM sandra.pavlo@gmail.com; natasaglisovic@gmail.com; anaga777@gmail.com;
   irinitms@gmail.com
RI Milosavljević, Nataša/JSL-2307-2023
OI Milosavljević, Nataša/0000-0003-4056-089X
FU Serbian Ministry of Science [III044006, III44009, TR32023]
FX This work has been supported by the Serbian Ministry of Science, Grant
   nos. III044006, III44009 and TR32023.
CR Alahmadi A, 2017, SIGNAL IMAGE VIDEO P, V11, P81, DOI 10.1007/s11760-016-0899-0
   Alkawaz MH, 2018, NEURAL COMPUT APPL, V30, P183, DOI 10.1007/s00521-016-2663-3
   [Anonymous], INT J PERFORMABILITY
   Bi XL, 2018, PATTERN RECOGN, V81, P161, DOI 10.1016/j.patcog.2018.03.028
   Bi XL, 2018, MULTIMED TOOLS APPL, V77, P363, DOI 10.1007/s11042-016-4276-3
   Bi XL, 2016, INFORM SCIENCES, V345, P226, DOI 10.1016/j.ins.2016.01.061
   Chou C.-L., 2017, International Conference on Security with Intelligent Computing and Big-data Services, P47
   Emam M, 2016, MULTIMED TOOLS APPL, V75, P11513, DOI 10.1007/s11042-015-2872-2
   Gan YF, 2016, NONLINEAR DYNAM, V84, P341, DOI 10.1007/s11071-015-2524-0
   Glisovic N, 2017, C 35 S NEW TECHN POS
   Glisovic N, 2017, P SYM OP IS 2017 ZLA, P158
   Gong Jiachang, 2016, Transactions of Tianjin University, V22, P151, DOI 10.1007/s12209-016-2705-z
   Guo YF, 2018, IEEE T INF FOREN SEC, V13, P1932, DOI 10.1109/TIFS.2018.2806926
   Hayat K, 2017, COMPUT ELECTR ENG, V62, P448, DOI 10.1016/j.compeleceng.2017.03.013
   Jenadeleh M, 2016, J FORENSIC SCI, V61, P623, DOI 10.1111/1556-4029.13108
   Kaushik R, 2015, PROCEDIA COMPUT SCI, V70, P130, DOI 10.1016/j.procs.2015.10.058
   Lee JC, 2015, INFORM SCIENCES, V321, P250, DOI 10.1016/j.ins.2015.03.009
   Lin CS, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.3.033010
   Mahmood T, 2018, J VIS COMMUN IMAGE R, V53, P202, DOI 10.1016/j.jvcir.2018.03.015
   Malviya AV, 2016, PROCEDIA COMPUT SCI, V79, P383, DOI 10.1016/j.procs.2016.03.050
   Mladenovi N, 2018, INT T OPER RES, V25, P427
   Mladenovic N, 1997, COMPUT OPER RES, V24, P1097, DOI 10.1016/S0305-0548(97)00031-2
   Oommen RS, 2016, PROC TECH, V24, P1452, DOI 10.1016/j.protcy.2016.05.176
   Reljin I, 2000, IEEE MEDITERR ELECT, P490
   Shih FY, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S021800141554004X
   Soni B, 2018, ENG LETT, V26, DOI [10. 1109/TIFS. 2010. 2051666, DOI 10.1109/TIFS.2010.2051666]
   Ustubioglu B, 2016, AEU-INT J ELECTRON C, V70, P1076, DOI 10.1016/j.aeue.2016.05.005
   Wang XY, 2018, PATTERN ANAL APPL, V21, P451, DOI 10.1007/s10044-016-0588-1
   Yan YY, 2019, IEEE T INF FOREN SEC, V14, P5, DOI 10.1109/TIFS.2018.2834155
   Yang B, 2018, MULTIMED TOOLS APPL, V77, P837, DOI 10.1007/s11042-016-4289-y
   Zhang W, 2010, IEEE T INF FOREN SEC, V5, P544, DOI 10.1109/TIFS.2010.2051666
   Zhao Fei, 2017, Wuhan University Journal of Natural Sciences, V22, P141, DOI 10.1007/s11859-017-1227-4
   Zhong JL, 2017, MULTIMED TOOLS APPL, V76, P14887, DOI 10.1007/s11042-016-4201-9
   Zhong JL, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417540052
   Zhong JL, 2016, NONLINEAR DYNAM, V84, P189, DOI 10.1007/s11071-015-2374-9
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
   Zhu Y, 2016, MULTIMED TOOLS APPL, V75, P3221, DOI 10.1007/s11042-014-2431-2
NR 37
TC 13
Z9 13
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 20655
EP 20678
DI 10.1007/s11042-019-7277-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400005
DA 2024-07-18
ER

PT J
AU Pereira, MHR
   Pádua, FLC
   Dalip, DH
   Benevenuto, F
   Pereira, ACM
   Lacerda, AM
AF Pereira, Moises H. R.
   Padua, Flavio L. C.
   Dalip, Daniel H.
   Benevenuto, Fabricio
   Pereira, Adriano C. M.
   Lacerda, Anisio M.
TI Multimodal approach for tension levels estimation in news videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal approach; Tension levels estimation; News videos; Multimodal
   sentiment analysis; Discourse analysis
ID SENTIMENT ANALYSIS
AB In this paper, we present a novel multimodal approach to estimate tension levels in news videos. The news media constitute a particular type of discourse and has become a central part of the modern-day lives of millions of people. In this context, it is important to study how the news industry affects human life and how it works. To support such a study, our approach estimates tension levels (polarities) along the news narrative, revealing the communication patterns used. To achieve this goal, we combine audio and visual cues extracted from news participants (e.g., reporters and anchors), by using methods for: (1) emotion recognition from facial expressions, (2) field size estimation and (3) extraction of audio features (e.g., chroma and spectral features), as well as textual cues obtained from the (4) sentiment analysis of the speech transcriptions. Experimental results with a dataset containing 960 annotated news videos from three Brazilian and one American TV newscasts show that our approach achieves an overall accuracy as high as 64.17% in the tension levels classification task. Those results demonstrate the high potential of our approach to be used by media analysts in several applications, especially, in the journalistic domain.
C1 [Pereira, Moises H. R.] IFMG, Ribeirao Das Neves, MG, Brazil.
   [Padua, Flavio L. C.; Dalip, Daniel H.; Lacerda, Anisio M.] CEFET MG, Dept Comp, Belo Horizonte, MG, Brazil.
   [Benevenuto, Fabricio; Pereira, Adriano C. M.] Univ Fed Minas Gerais, Dept Comp Sci, Belo Horizonte, MG, Brazil.
C3 Instituto Federal de Educacao, Ciencia e Tecnologia de Minas Gerais
   (IFMG); Universidade Federal de Minas Gerais
RP Pereira, MHR (corresponding author), IFMG, Ribeirao Das Neves, MG, Brazil.
EM moises.pereira@ifmg.edu.br
RI Pádua, Flávio L C/N-7791-2013; Pereira, Adriano Machado/AAA-3995-2019
OI Pereira, Adriano Machado/0000-0003-2389-0512; Pereira,
   Moises/0000-0003-4993-6929
FU CNPq [307510/2017-4, 313163/2014-6]; FAPEMIG [PPM-00542-15,
   APQ-03445-16]; CEFET-MG; CAPES
FX The authors would like to thank the support of CNPq under Procs.
   307510/2017-4 and 313163/2014-6, FAPEMIG under Procs. PPM-00542-15 and
   APQ-03445-16, CEFET-MG and CAPES.
CR Conceiçao FLA, 2017, ACTA SCI-TECHNOL, V39, P357, DOI 10.4025/actascitechnol.v39i3.29763
   [Anonymous], 2013, KEY LEARNINGS EXERCI
   [Anonymous], 2012, IBM REDBOOKS
   [Anonymous], 2014, P 16 INT C MULT INT
   [Anonymous], 7 INT WORKSH SEM EV
   [Anonymous], 2008, AAAI
   [Anonymous], 2013, IEEE SSCI
   [Anonymous], 2013, ARXIV13086242
   [Anonymous], 2014, Advances in neural information processing systems
   [Anonymous], 2013, RE CURSIVE DEEP MODE
   [Anonymous], 1999, MISES SCENE VISUELLE
   [Anonymous], 2011, P 13 INT C MULT INT
   [Anonymous], 2010, CVPR
   Araujo M, 2016, 10 INT AAI C WEB SOC
   Baecchi C, 2016, MULTIMED TOOLS APPL, V75, P2507, DOI 10.1007/s11042-015-2646-x
   Baker P., 2006, APPL LINGUIST, V28, P327
   Bartlett MS, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P223, DOI 10.1109/fgr.2006.55
   Bautin M., 2008, Proceedings of the International Conference on Weblogs and Social Media (ICWSM), P19
   Bellard F., 2005, FFmpeg
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Cambria E., 2010, AAAI FALL S COMMONSE
   Charaudeau P., 2002, Discourse Studies, V4, P301
   Cheng F., 2012, ASIAN SOCIAL SCI, V8, P75, DOI DOI 10.5539/ASS.V8N12P75
   Chouliaraki Lilie., 2006, VISUAL COMMUN-US, V5, P261, DOI DOI 10.1177/1470357206068455
   Culpeper J, 2008, PRAGMATIC ANNOTATION
   Dodds PS, 2010, J HAPPINESS STUD, V11, P441, DOI 10.1007/s10902-009-9150-9
   Esuli S, 2006, C LAN RES EV
   Fierro R, 2013, IEEE WORKSH HYBRID, P51, DOI 10.1109/HIMA.2013.6615022
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Giannakopoulos T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144610
   Glasmachers T., 2017, P 9 ASIAN C MACHINE, P17
   Goncalves P, 2013, P BRAZ WORKSH SOC NE
   Goncalves P, 2012, I BRAZ WORKSH SOC NE
   Hannak A, 2012, AAAI C WEBL SOC MED
   Hasan T, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-173
   Hoey M., 1991, APPL LINGUISTICS ENG, P65
   Hu M., 2004, P 10 ACM SIGKDD INT, P168, DOI DOI 10.1145/1014052.1014073
   Hutto C.J., 2014, P ICWSM
   Jacob H, 2017, J INTELL INF SYST, V49, P193, DOI 10.1007/s10844-016-0441-4
   Kaur H, 2015, P INT C INF TECHN CO, P57
   Kechaou Zied, 2013, Journal of Systems and Information Technology, V15, P24, DOI 10.1108/13287261311322576
   Lajevardi S.M., 2008, Digital Image Computing
   Larose R, 1995, COMMUNICATIONS MEDIA
   Li H., 2012, P 8 INT C LANG RES E
   Li J., 2014, EMNLP, P467
   Littlewort G., 2004, C COMP VIS PATT REC
   Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Maynard D., 2013, BCS SGAI Workshop on Social Media Analytics, P44
   Mishra B.K., 2008, Psychology: A study of human behaviour
   Mitchell A., 2016, Pew Research Center
   Mitchell T. M., 1997, MACHINE LEARNING
   Mohammad Saif., 2012, Proceedings of the First Joint Conference on Lexical and Computational Semantics-Volume 1: Proceedings of the Main Conference and the Shared Task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation, SemEval'12, P246
   Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x
   Nadkarni PM, 2011, J AM MED INFORM ASSN, V18, P544, DOI 10.1136/amiajnl-2011-000464
   Nielsen F. A., 2011, ARXIV
   Nunes CFG, 2017, IEEE GEOSCI REMOTE S, V14, P1850, DOI 10.1109/LGRS.2017.2738632
   Pappas N, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P773
   Pereira MHR, 2016, P INT AAAI C WEB SOC, P659
   Pereira MHR, 2015, MULTIMED TOOLS APPL, V74, P10923, DOI 10.1007/s11042-014-2311-9
   Pimentel Filho C.A., 2010, J INF DATA MANAG, V1, P293
   Poria S, 2016, NEUROCOMPUTING, V174, P50, DOI 10.1016/j.neucom.2015.01.095
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   Schroder KC, 2015, JOURNALISM STUD, V16, P60, DOI 10.1080/1461670X.2014.890332
   Soleymani M, 2017, IMAGE VISION COMPUT, V65, P3, DOI 10.1016/j.imavis.2017.08.003
   Stegmeier J, 2012, STELLENBOSCH PAP LIN, V41, P91, DOI 10.5774/41-0-45
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Thelwall M, 2013, CYBEREMOTIONS CHAP H
   Van Dijk T. A., 1987, NEWS ANAL
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang H., 2012, P ACL 2012 SYST DEM, P115, DOI DOI 10.1145/1935826.1935854
   Wilson Theresa, 2005, EMNLP
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Yadav SK, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P1415
   Zhai Y, 2005, LECT NOTES COMPUT SC, V3568, P92
   Zheng D, 2004, P 6 LASTED INT C SIG
NR 76
TC 7
Z9 7
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23783
EP 23808
DI 10.1007/s11042-019-7691-4
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400070
DA 2024-07-18
ER

PT J
AU Aboshosha, S
   Zahran, O
   Dessouky, MI
   Abd El-Samie, FE
AF Aboshosha, Sahar
   Zahran, O.
   Dessouky, Moawad I.
   Abd El-Samie, F. E.
TI Resolution and quality enhancement of images using interpolation and
   contrast limited adaptive histogram equalization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CLAHE; Polynomial interpolation; Contrast enhancement; Inverse
   interpolation
ID EFFICIENT IMPLEMENTATION; PARALLEL FRAMEWORK; SIGNAL; SPLINES
AB In this paper, hybrid models for image quality enhancement are presented comprising both Contrast Limited Adaptive Histogram Equalization (CLAHE) and image interpolation. Adaptive histogram equalization is employed for contrast enhancement, while image interpolation is employed for resolution enhancement. Both the CLAHE and image interpolation are used interchangeably to check the most suitable model for quality enhancement of Low-Resolution (LR) images. The utilized interpolation techniques throughout this paper are polynomial and inverse techniques. Simulation results prove that the application of the CLAHE after interpolation gives the best image quality, especially with regularized inverseinterpolation.
C1 [Aboshosha, Sahar] Minist Elect & Renewable Energy, Elect Networks, Cairo, Egypt.
   [Zahran, O.; Dessouky, Moawad I.; Abd El-Samie, F. E.] Menoufia Univ, Fac Elect Engn, Elect & Elect Commun Engn Dept, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP Aboshosha, S (corresponding author), Minist Elect & Renewable Energy, Elect Networks, Cairo, Egypt.
EM sahar_aboshosha@yahoo.com; osama_zahran@el-eng.menofia.edu.eg;
   moawad_dessouky@yahoo.com; fathi_sayed@yahoo.com
RI Sayed, Fathi/HRA-4752-2023
OI Sayed, Fathi/0000-0001-8749-9518; Zahran, Osama/0000-0001-5334-5908
CR [Anonymous], 2013, INT J ENG SCI INNOV
   [Anonymous], INT J COMPUT APPL
   [Anonymous], INT J COMPUTER SCI E
   [Anonymous], INT J INNOVATIVE RES
   Blu T, 2001, IEEE T IMAGE PROCESS, V10, P1069, DOI 10.1109/83.931101
   Cha YJ, 2006, IEEE T IMAGE PROCESS, V15, P2315, DOI 10.1109/TIP.2006.875182
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   EI-Khamy SE, 2005, DIGIT SIGNAL PROCESS, V15, P137, DOI 10.1016/j.dsp.2004.10.003
   El-Khamy SE, 2003, Proceedings of the 46th IEEE International Midwest Symposium on Circuits & Systems, Vols 1-3, P656
   Garg R., 2011, International Journal of Electronics and Comunication Technologies, V2, P107
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Hwang JW, 2004, IEEE SIGNAL PROC LET, V11, P359, DOI 10.1109/LSP.2003.821718
   Kim M, 2008, IEEE T CONSUM ELECTR, V54, P1389, DOI 10.1109/TCE.2008.4637632
   Kim Y, 1999, United States Patent, Patent No. 5963665
   Leung WYV, 2001, OPT ENG, V40, P547, DOI 10.1117/1.1353799
   Liang LM, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 4, PROCEEDINGS, P102, DOI 10.1109/CISP.2008.584
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Min B. S., 2013, International Journal of Software Engineering and Its Applications, V7, P113, DOI DOI 10.14257/IJSEIA.2013.7.5.11
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Roy R, 2013, AIP ADV, V3, DOI 10.1063/1.4789409
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   유지현, 2012, [Journal of Internet Computing and Services, 인터넷정보학회논문지], V13, P61, DOI 10.7472/jksii.2012.13.3.61
   Thévenaz P, 2000, IEEE T MED IMAGING, V19, P739, DOI 10.1109/42.875199
   UNSER M, 1993, IEEE T SIGNAL PROCES, V41, P834, DOI 10.1109/78.193221
   UNSER M, 1993, IEEE T SIGNAL PROCES, V41, P821, DOI 10.1109/78.193220
   Unser M, 1999, IEEE SIGNAL PROC MAG, V16, P22, DOI 10.1109/79.799930
   Vrcelj B, 2001, IEEE T IMAGE PROCESS, V10, P1639, DOI 10.1109/83.967392
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Yan C, 2018, IEEE Transactions on Multimedia
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
NR 35
TC 12
Z9 14
U1 4
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18751
EP 18786
DI 10.1007/s11042-018-7022-1
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200063
DA 2024-07-18
ER

PT J
AU Ahangi, A
   Langroudi, AF
   Yazdanpanah, F
   Mirroshandel, SA
AF Ahangi, Amir
   Langroudi, Arash Fassihozzaman
   Yazdanpanah, Fatemeh
   Mirroshandel, Seyed Abolghasem
TI A novel fusion mixture of active experts algorithm for traffic signs
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic sign recognition; Feature descriptor; Mixture of experts; Active
   learning; Neural networks
AB Traffic sign recognition is an important problem in today's applications. In this paper, by combining ensemble and active learning methods, a novel fusion mixture of active experts algorithm is proposed for this problem. The active learning algorithm is a popular method for reducing the number of samples. The primary goal of active learning is diminishing complexity, increasing the convergence rate, speeding up training process, and decreasing the cost of samples labeling. The active learning, hence, chooses informative samples to train. In addition, ensemble methods are a combination of simple classifiers for improving accuracy. Each classifier tries to learn a region of dataset better than other regions that all opinions are considered on ensemble methods as an ultimate decision. The mixture of experts is one of the most modern hybrid methods in which the training process takes a relatively long time, and it is a problem for large datasets. Our proposed Mixture of Active Experts tries to solve this problem. It decreases the training time process and increases the speed of convergence for finding optimal weights by selecting only informative samples in active learning phase. It is also applicable for online situations, in which the model should be trained continuously. The results of different experiments on German Traffic Sign Recognition Benchmark dataset demonstrate that the proposed method shows 96.69% accuracy and achieved the 6th rank among all the state of the art algorithms using smaller number (only 60%) of training samples.
C1 [Ahangi, Amir; Langroudi, Arash Fassihozzaman; Yazdanpanah, Fatemeh; Mirroshandel, Seyed Abolghasem] Univ Guilan, Dept Comp Engn, POB 1841, Rasht, Iran.
C3 University of Guilan
RP Mirroshandel, SA (corresponding author), Univ Guilan, Dept Comp Engn, POB 1841, Rasht, Iran.
EM mirroshandel@guilan.ac.ir
CR [Anonymous], ARXIV151102992
   [Anonymous], ARXIV14101035
   Arnaiz-González A, 2016, EXPERT SYST APPL, V54, P340, DOI 10.1016/j.eswa.2015.12.046
   Cai ZX, 2013, J CENT SOUTH UNIV, V20, P433, DOI 10.1007/s11771-013-1504-0
   Ciresan D, 2012, NEURAL NETWORKS, V32, P333, DOI 10.1016/j.neunet.2012.02.023
   COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211
   de la Escalera A, 2003, IMAGE VISION COMPUT, V21, P247, DOI 10.1016/S0262-8856(02)00156-7
   De Vries Jelmer, 2006, OBJECT RECOGNITION S
   Dilip Singh Solanki D, 2015, INT J ADV RES COMPUT, V5, P2
   Ebrahimpour R, 2011, MIXTURE MLP EXPERTS, V27
   Fleyeh H, 2011, IET INTELL TRANSP SY, V5, P190, DOI 10.1049/iet-its.2010.0159
   Galar M, 2012, IEEE T SYST MAN CY C, V42, P463, DOI 10.1109/TSMCC.2011.2161285
   Gecer B, 2017, IMAGE VISION COMPUT, V57, P165, DOI 10.1016/j.imavis.2016.10.006
   Gomes HM, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3054925
   Gopalakrishnan S, 2012, J Family Med Prim Care, V1, P144, DOI 10.4103/2249-4863.104987
   Guo H., 2011, The Journal of China Universities of Posts and Telecommunications, V18, P12, DOI DOI 10.1016/S1005-8885(10)60139-2
   Huang ZY, 2014, 2014 11TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P1451, DOI 10.1109/WCICA.2014.7052932
   Jacobs RA, 1991, NEURAL COMPUT, V3, P79, DOI 10.1162/neco.1991.3.1.79
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kuncheva LI, 2004, COMBINING PATTERN CL, DOI DOI 10.1002/0471660264
   Liang RZ, 2016, INT C PATT RECOG, P2954, DOI 10.1109/ICPR.2016.7900086
   Bascón SM, 2010, COMPUT VIS IMAGE UND, V114, P373, DOI 10.1016/j.cviu.2009.12.002
   Marques Oge., 2011, Practical image and video processing using MATLAB
   Masoudnia S, 2014, ARTIF INTELL REV, V42, P275, DOI 10.1007/s10462-012-9338-y
   Meuter Mirko, 2010, 2010 13th International IEEE Conference on Intelligent Transportation Systems (ITSC 2010), P324, DOI 10.1109/ITSC.2010.5625088
   Mirroshandel S.A., 2011, P 12 INT C PARSING T, P140
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Polikar R, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P1, DOI 10.1007/978-1-4419-9326-7_1
   Sermanet P, 2011, TRAFFIC SIGN RECOGNI
   Settles B, 2010, ACTIVE LEARNING LIT, P07
   Settles B., 2012, ACTIVE LEARNING
   Shopa P, 2014, INT C INF COMM EMB S, P1
   Souani C, 2014, J REAL-TIME IMAGE PR, V9, P79, DOI 10.1007/s11554-013-0348-z
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Stallkamp J, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P1453, DOI 10.1109/IJCNN.2011.6033395
   Staravoitau A., 2018, Pattern Recognition and Image Analysis, V28, P155
   Sun ZL, 2014, NEUROCOMPUTING, V128, P153, DOI 10.1016/j.neucom.2012.11.057
   Tang B, 2002, IEEE IJCNN, P227, DOI 10.1109/IJCNN.2002.1005474
   Vinay A, 2016, PROCEDIA COMPUT SCI, V79, P533, DOI 10.1016/j.procs.2016.03.068
   Wei X, 2016, ARTIF INTELL REV, V45, P333, DOI 10.1007/s10462-015-9448-4
   Wozniak M, 2014, INFORM FUSION, V16, P3, DOI 10.1016/j.inffus.2013.04.006
   Yin SY, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS IEEE-ROBIO 2014, P2570, DOI 10.1109/ROBIO.2014.7090728
   Yuan X, 2014, IEEE T INTELL TRANSP, V15, P1466, DOI 10.1109/TITS.2014.2298912
   Yuksel SE, 2012, IEEE T NEUR NET LEAR, V23, P1177, DOI 10.1109/TNNLS.2012.2200299
   Zaklouta F, 2014, ROBOT AUTON SYST, V62, P16, DOI 10.1016/j.robot.2012.07.019
   Zaklouta F, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2151, DOI 10.1109/IJCNN.2011.6033494
   Zhou LP, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P578, DOI 10.1109/ITSC.2014.6957752
NR 47
TC 1
Z9 1
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20217
EP 20237
DI 10.1007/s11042-019-7391-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800058
OA Bronze
DA 2024-07-18
ER

PT J
AU Ahmadian, S
   Afsharchi, M
   Meghdadi, M
AF Ahmadian, Sajad
   Afsharchi, Mohsen
   Meghdadi, Majid
TI A novel approach based on multi-view reliability measures to alleviate
   data sparsity in recommender systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender systems; Collaborative filtering; Reliability measure; Data
   sparsity; Rating profile
ID COLD-START PROBLEM; MATRIX FACTORIZATION; TRUST; RATINGS; MODEL
AB Recommender systems are intelligent programs to suggest relevant contents to users according to their interests which are widely expressed as numerical ratings. Collaborative filtering is an important type of recommender systems which has established itself as the principal means of recommending items. However, collaborative filtering suffers from two important problems including cold start and data sparsity. These problems make it difficult to accurately compute user similarity and hence to find reliable similar users. To deal with these problems, a novel recommender method is proposed in this paper which is based on three different views of reliability measures. For the first view, a user-based reliability measure is proposed to evaluate the performance of users' rating profiles in predicting unseen items. Then, a novel mechanism is proposed to enhance the rating profiles with low quality by adding a number of reliable ratings. To this end, an item-based reliability measure is proposed as the second view of the reliability measures and then a number of items with highest reliability values are selected to add into the target rating profile. Then, similarity values between users and also initial ratings of unseen items are calculated using the enhanced users' rating profiles. Finally, a rating-based reliability measure is used as the third view of the reliability measures to evaluate the initial predicted ratings and a novel mechanism is proposed to recalculate unreliable predicted ratings. Experimental results using four well-known datasets indicate that the proposed method significantly outperforms other recommender methods.
C1 [Ahmadian, Sajad; Afsharchi, Mohsen; Meghdadi, Majid] Univ Zanjan, Dept Comp Engn, Zanjan, Iran.
C3 University Zanjan
RP Meghdadi, M (corresponding author), Univ Zanjan, Dept Comp Engn, Zanjan, Iran.
EM s.ahmadian@znu.ac.ir; afsharchim@znu.ac.ir; meghdadi@znu.ac.ir
RI Ahmadian, Sajad/ABE-4624-2021
OI Ahmadian, Sajad/0000-0002-3080-3192
CR Ahmadian S, 2019, J INF SCI, V45, P607, DOI 10.1177/0165551518808191
   Ahmadian S, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P1139, DOI 10.1109/ASONAM.2018.8508723
   Ahmadian S, 2018, APPL INTELL, V48, P4448, DOI 10.1007/s10489-018-1219-x
   Ahmadian S, 2018, INFORM PROCESS MANAG, V54, P707, DOI 10.1016/j.ipm.2017.03.002
   [Anonymous], 2006, Netflix update: Try this at home
   [Anonymous], 2014, SOCIAL NETW ANAL MIN
   Boratto L, 2017, NEUROCOMPUTING, V254, P79, DOI 10.1016/j.neucom.2016.10.079
   Chen CC, 2013, INFORM SCIENCES, V224, P19, DOI 10.1016/j.ins.2012.10.037
   da Silva EQ, 2016, EXPERT SYST APPL, V53, P204, DOI 10.1016/j.eswa.2015.12.050
   Formoso V, 2013, INFORM PROCESS MANAG, V49, P659, DOI 10.1016/j.ipm.2012.07.005
   Guo GB, 2017, KNOWL-BASED SYST, V138, P202, DOI 10.1016/j.knosys.2017.10.005
   Guo GB, 2014, KNOWL-BASED SYST, V57, P57, DOI 10.1016/j.knosys.2013.12.007
   He XS, 2015, PHYSICA A, V436, P658, DOI 10.1016/j.physa.2015.05.066
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Hernando A, 2016, KNOWL-BASED SYST, V97, P188, DOI 10.1016/j.knosys.2015.12.018
   Hernando A, 2013, INFORM SCIENCES, V218, P1, DOI 10.1016/j.ins.2012.06.027
   Hong FX, 2016, INFORM SCIENCES, V360, P202, DOI 10.1016/j.ins.2016.04.042
   Hu JM, 2015, INFORM PROCESS MANAG, V51, P329, DOI 10.1016/j.ipm.2015.02.002
   Huang L, 2019, MULTIMED TOOLS APPL, V78, P8711, DOI 10.1007/s11042-018-6232-x
   Katarya R, 2016, MULTIMED TOOLS APPL, V75, P9225, DOI 10.1007/s11042-016-3481-4
   Kim HN, 2011, DECIS SUPPORT SYST, V51, P519, DOI 10.1016/j.dss.2011.02.015
   Langseth H, 2015, DECIS SUPPORT SYST, V74, P1, DOI 10.1016/j.dss.2015.03.006
   Lee D., 2001, NEURAL INFORM PROCES
   Lemire D, 2005, SIAM PROC S, P471
   Lika B, 2014, EXPERT SYST APPL, V41, P2065, DOI 10.1016/j.eswa.2013.09.005
   Liu Y, 2018, MULTIMED TOOLS APPL, V77, P12533, DOI 10.1007/s11042-017-4902-8
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Luo X, 2012, ENG APPL ARTIF INTEL, V25, P1403, DOI 10.1016/j.engappai.2011.10.011
   Mazurowski MA, 2013, EXPERT SYST APPL, V40, P3847, DOI 10.1016/j.eswa.2012.12.102
   Mnih A., 2007, ADV NEURAL INFORM PR, V20
   Moradi P, 2015, EXPERT SYST APPL, V42, P7386, DOI 10.1016/j.eswa.2015.05.027
   Moradi P, 2015, PHYSICA A, V436, P462, DOI 10.1016/j.physa.2015.05.008
   Nikolakopoulos AN, 2015, NEUROCOMPUTING, V163, P126, DOI 10.1016/j.neucom.2014.09.082
   Nilashi M, 2014, KNOWL-BASED SYST, V60, P82, DOI 10.1016/j.knosys.2014.01.006
   Ortega F, 2016, INFORM SCIENCES, V345, P313, DOI 10.1016/j.ins.2016.01.083
   Polatidis N, 2016, EXPERT SYST APPL, V48, P100, DOI 10.1016/j.eswa.2015.11.023
   Ren Yongli, 2012, P 21 ACM INT C INFOR, P684, DOI DOI 10.1145/2396761.2396849
   Resnick P., 1994, Transcending Boundaries, CSCW '94. Proceedings of the Conference on Computer Supported Cooperative Work, P175, DOI 10.1145/192844.192905
   Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI 10.1145/371920.372071
   Shi Y, 2013, INFORM SCIENCES, V229, P29, DOI 10.1016/j.ins.2012.12.002
   Son LH, 2016, INFORM SYST, V58, P87, DOI 10.1016/j.is.2014.10.001
   Su XY, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P949
   Xia W, 2009, 5 INT JOINT C INC IM
   Xie F, 2014, KNOWL-BASED SYST, V69, P179, DOI 10.1016/j.knosys.2014.04.011
   Yang Z, 2018, NEUROCOMPUTING, V278, P126, DOI 10.1016/j.neucom.2017.04.080
   Yera R, 2016, APPL SOFT COMPUT, V40, P187, DOI 10.1016/j.asoc.2015.10.060
   Yu L, 2018, MULTIMED TOOLS APPL, V77, P4155, DOI 10.1007/s11042-017-4542-z
   Zhang HR, 2019, INT J MACH LEARN CYB, V10, P1165, DOI 10.1007/s13042-018-0795-8
   Zhang H, 2018, MULTIMED TOOLS APPL, V77, P4187, DOI 10.1007/s11042-017-4553-9
   Zhang MY, 2016, DECIS SUPPORT SYST, V83, P10, DOI 10.1016/j.dss.2015.12.004
   Zhang ZY, 2018, NEUROCOMPUTING, V285, P94, DOI 10.1016/j.neucom.2017.12.063
NR 52
TC 42
Z9 44
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17763
EP 17798
DI 10.1007/s11042-018-7079-x
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200021
DA 2024-07-18
ER

PT J
AU Chen, Z
   Wang, RL
   Ji, WT
   Zong, M
   Fan, TH
   Wang, HB
AF Chen, Zhe
   Wang, Ruili
   Ji, Wanting
   Zong, Ming
   Fan, Tanghuai
   Wang, Huibin
TI A novel monocular calibration method for underwater vision measurement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vision measurement; Monocular system; Underwater environment;
   Three-dimensional structure
ID ILLUMINATION; RECONSTRUCTION; COMPENSATION; DESIGN
AB Vision measurement systems have a reliable performance on ground, but it remains a challenge to apply commonly-used vision measurement systems (i.e. multi-camera systems and laser systems) in underwater environments. One of the most challenging issues is the transformation from an unscaled measurement to a scaled result, which is achieved by a calibration method and determinate the strategy used for underwater vision measurement. This paper proposes a novel monocular underwater calibration method underlying a simple underwater vision measurement system. Underwater unscaled measurement results are calculated by the dark channel prior model. These results are then processed by our calibration method, transforming the unscaled measurements to accurately scaled results. These measurement results finally are used to estimate the scaled 3D structure of underwater objects. Experimental results under natural open water show that our proposed method is reliable and efficient.
C1 [Chen, Zhe; Wang, Huibin] Hohai Univ, Coll Comp & Informat, Nanjing, Jiangsu, Peoples R China.
   [Wang, Ruili; Ji, Wanting; Zong, Ming] Massey Univ, Inst Nat & Math Sci, Auckland, New Zealand.
   [Fan, Tanghuai] Nanchang Inst Technol, Sch Informat Engn, Nanchang, Jiangxi, Peoples R China.
C3 Hohai University; Massey University; Nanchang Institute Technology
RP Wang, RL (corresponding author), Massey Univ, Inst Nat & Math Sci, Auckland, New Zealand.
EM chenzhe@hhu.edu.cn; Ruili.Wang@massey.ac.nz; jwt@escience.cn;
   zongming1483@gmail.com; fantanghuai@nit.edu.cn; hbwang@hhu.edu.cn
FU National Natural Science Foundation of China [61563036, 61671201];
   Fundamental Research Funds for the Central Universities [2017B01914];
   Marsden Fund of New Zealand
FX This work is supported in part by the National Natural Science
   Foundation of China (No. 61563036, 61671201), the Fundamental Research
   Funds for the Central Universities (No. 2017B01914), the Marsden Fund of
   New Zealand.
CR ARNUSH D, 1972, J OPT SOC AM, V62, P1109, DOI 10.1364/JOSA.62.001109
   Awanzino C, 2000, INT C PATT RECOG, P664, DOI 10.1109/ICPR.2000.905475
   Bosch J, 2015, SENSORS-BASEL, V15, P6033, DOI 10.3390/s150306033
   Chen Z, 2018, DESTECH TRANS ENVIR
   FRYER JG, 1986, PHOTOGRAMM REC, V12, P73
   Hildebrandt Marc, 2008, P OCEANS MTSIEEE KOB, P1, DOI DOI 10.1109/OCEANSKOBE.2008.4531026
   Iqbal Kashif, 2007, IAENG International Journal of Computer Science, V34, P239
   Jaffe JS, 2015, IEEE J OCEANIC ENG, V40, P683, DOI 10.1109/JOE.2014.2350751
   Jia ZY, 2015, OPT EXPRESS, V23, P15205, DOI 10.1364/OE.23.015205
   Jian MW, 2018, COMPUT IND, V99, P110, DOI 10.1016/j.compind.2018.03.034
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Jian MW, 2017, IEEE INT CON MULTI, P1297, DOI 10.1109/ICME.2017.8019324
   Jian MW, 2014, INFORM SCIENCES, V269, P60, DOI 10.1016/j.ins.2014.01.019
   Jian MW, 2013, COMPUT IND, V64, P1229, DOI 10.1016/j.compind.2013.06.011
   Johnson-Roberson M, 2017, J FIELD ROBOT, V34, P625, DOI 10.1002/rob.21658
   Johnson-Roberson M, 2010, J FIELD ROBOT, V27, P21, DOI 10.1002/rob.20324
   Jordt-Sedlazeck A, 2012, LECT NOTES COMPUT SC, V7576, P846, DOI 10.1007/978-3-642-33715-4_61
   Kim SH, 2014, MULTIMED TOOLS APPL, V68, P455, DOI 10.1007/s11042-013-1356-5
   Kristensson E, 2014, OPT LETT, V39, P2584, DOI 10.1364/OL.39.002584
   Lu HM, 2016, MULTIMED TOOLS APPL, V75, P17081, DOI 10.1007/s11042-015-2977-7
   Mallios A, 2016, J FIELD ROBOT, V33, P994, DOI 10.1002/rob.21640
   Miura N, 2016, RIVER RES APPL, V32, P1621, DOI 10.1002/rra.2986
   Muljowidodo K, 2009, INDIAN J MAR SCI, V38, P324
   Neto DM, 2013, COMPUT AIDED DESIGN, V45, P639, DOI 10.1016/j.cad.2012.10.046
   Russell C, 2014, LECT NOTES COMPUT SC, V8695, P583, DOI 10.1007/978-3-319-10584-0_38
   Sakka T, 2014, SPECTROCHIM ACTA B, V97, P94, DOI 10.1016/j.sab.2014.05.009
   Sanz PJ, 2013, IEEE SYS MAN CYBERN, P4036, DOI 10.1109/SMC.2013.689
   Schechner Y.Y., 2004, P 2004 IEEE COMP SOC, P89, DOI [10.1109/CVPR.2004.1315078, DOI 10.1109/CVPR.2004.1315078]
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Shortis M, 2015, SENSORS-BASEL, V15, P30810, DOI 10.3390/s151229831
   Sim KS, 2007, PATTERN RECOGN LETT, V28, P1209, DOI 10.1016/j.patrec.2007.02.003
   Sipiran I, 2011, VISUAL COMPUT, V27, P963, DOI 10.1007/s00371-011-0610-y
   Sonka M., 2014, CENGAGE LEARN
   Spampinato C, 2014, MULTIMED TOOLS APPL, V70, P199, DOI 10.1007/s11042-012-1101-5
   Sporer M, 2015, IEEE TOPIC CONF WIRE, P72, DOI 10.1109/WISNET.2015.7127405
   Wang JB, 2015, NEUROCOMPUTING, V149, P718, DOI 10.1016/j.neucom.2014.08.005
   Wang K, 2016, IEEE SENS J, V16, P4051, DOI 10.1109/JSEN.2015.2428712
   Wang YB, 2015, J COMPUT PHYS, V294, P149, DOI 10.1016/j.jcp.2015.03.046
   Yamakita T, 2017, MAR POLICY, V81, P273, DOI 10.1016/j.marpol.2017.03.040
   Yau T, 2013, PROC CVPR IEEE, P2499, DOI 10.1109/CVPR.2013.323
   Zhu XF, 2018, IEEE T KNOWL DATA EN, V30, P517, DOI 10.1109/TKDE.2017.2763618
NR 41
TC 3
Z9 3
U1 4
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19437
EP 19455
DI 10.1007/s11042-018-7105-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800023
DA 2024-07-18
ER

PT J
AU Fang, Z
   Yi, XM
AF Fang, Zhuang
   Yi, Xuming
TI A novel natural image noise level estimation based on flat patches and
   local statistics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Noise level estimation; Flat patches; Gaussian noise; Eigenvalue;
   Covariance matrix
ID ALGORITHM
AB This paper proposes a high-precision algorithm for noise level estimation. Different from existing algorithms, we present a new noise level estimation algorithm by linearly combining the overestimated and underestimated results using combinatorial coefficients that can be tailored to the problem at hand. The algorithm has two distinct features: it avoids the underestimation of noise level estimation algorithms that employ the minimum eigenvalue and demonstrates higher accuracy and robustness for a large range of visual content and noise conditions. The experimental results that are obtained in this study demonstrate that the proposed algorithm is effective for various scenes with various noise levels. The software release of the proposed algorithm is available online at https://ww2.mathworks.cn/matlabcentral/fileexchange/64519-natural-image-noise-level-estimation-based-on-flat-patches-and-local-statistics.
C1 [Fang, Zhuang; Yi, Xuming] Wuhan Univ, Sch Math & Stat, Wuhan 430072, Hubei, Peoples R China.
   [Fang, Zhuang] Hubei Univ Nationalities, Sch Sci, Enshi 445000, Hubei, Peoples R China.
C3 Wuhan University; Hubei Minzu University
RP Yi, XM (corresponding author), Wuhan Univ, Sch Math & Stat, Wuhan 430072, Hubei, Peoples R China.
EM wdfangzhuang@163.com; xmyi.math@whu.edu.cn
OI Fang, Zhuang/0000-0003-0358-5350
FU National Natural Science Foundation of China [11671307, 61561019,
   61763009, 11761030]; Nature Science Foundation of Hubei Province
   [2015CFB262]; Doctoral Scientific Fund Project of Hubei University for
   Nationalities [MY2015B001]
FX This study was supported by the National Natural Science Foundation of
   China (Grant no. 11671307, 61561019, 61763009 and 11761030), the Nature
   Science Foundation of Hubei Province (Grant no. 2015CFB262), and the
   Doctoral Scientific Fund Project of Hubei University for Nationalities
   (Grant no. MY2015B001). We would like to express our gratitude to the
   anonymous reviewers and editors for their valuable comments and
   suggestions, which led to the improvement of the original manuscript.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2005, SUBJECTIVE QUALITY A
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Ben Abdallah M, 2018, NEURAL COMPUT APPL, V29, P159, DOI 10.1007/s00521-016-2811-9
   Chen GY, 2015, IEEE I CONF COMP VIS, P477, DOI 10.1109/ICCV.2015.62
   Colom M, 2014, IEEE IMAGE PROC, P4261, DOI 10.1109/ICIP.2014.7025865
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong L, 2017, IEEE T IMAGE PROCESS, V26, P1017, DOI 10.1109/TIP.2016.2639447
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.1080/01621459.1995.10476626
   Ghazi MM, 2017, MULTIMED TOOLS APPL, V76, P2379, DOI 10.1007/s11042-015-3169-1
   Hashemi M, 2010, IEEE SIGNAL PROC LET, V17, P12, DOI 10.1109/LSP.2009.2030856
   Huang XT, 2014, COMPUT ELECTR ENG, V40, P796, DOI 10.1016/j.compeleceng.2013.08.002
   Jiang P, 2016, PATTERN RECOGN LETT, V78, P8, DOI 10.1016/j.patrec.2016.03.026
   Khmag A, 2018, VISUAL COMPUT, V34, P575, DOI 10.1007/s00371-017-1362-0
   Kim DG, 2018, NEUROCOMPUTING, V293, P1, DOI 10.1016/j.neucom.2018.02.063
   Liu XH, 2013, IEEE T IMAGE PROCESS, V22, P5226, DOI 10.1109/TIP.2013.2283400
   Mandal S, 2017, SIGNAL PROCESS, V132, P134, DOI 10.1016/j.sigpro.2016.09.017
   OLSEN SI, 1993, CVGIP-GRAPH MODEL IM, V55, P319, DOI 10.1006/cgip.1993.1022
   Oyet AJ, 2003, STAT PROBABIL LETT, V61, P97, DOI 10.1016/S0167-7152(02)00353-X
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Pyatykh S, 2013, IEEE T IMAGE PROCESS, V22, P687, DOI 10.1109/TIP.2012.2221728
   ROYSTON JP, 1982, J R STAT SOC C-APPL, V31, P161
   SHAPIRO SS, 1972, TECHNOMETRICS, V14, P355, DOI 10.2307/1267427
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Shi BL, 2015, APPL MATH COMPUT, V250, P402, DOI 10.1016/j.amc.2014.11.004
   Shin DH, 2005, IEEE T CONSUM ELECTR, V51, P218, DOI 10.1109/TCE.2005.1405723
   Witwit W, 2018, MULTIMED TOOLS APPL, V77, P27641, DOI 10.1007/s11042-018-5941-5
   Xie XM, 2014, OPTIK, V125, P2199, DOI 10.1016/j.ijleo.2013.10.026
   Xu SP, 2017, SIGNAL PROCESS, V131, P99, DOI 10.1016/j.sigpro.2016.08.006
   Zhu X, 2010, IEEE T IMAGE PROCESS, V19, P3116, DOI 10.1109/TIP.2010.2052820
   Zoran D, 2009, IEEE I CONF COMP VIS, P2209, DOI 10.1109/ICCV.2009.5459476
NR 34
TC 14
Z9 14
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17337
EP 17358
DI 10.1007/s11042-018-7137-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200002
DA 2024-07-18
ER

PT J
AU Ge, HW
   Yan, ZH
   Yu, WH
   Sun, L
AF Ge, Hongwei
   Yan, Zehang
   Yu, Wenhao
   Sun, Liang
TI An attention mechanism based convolutional LSTM network for video action
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Attention mechanism; Convolutional LSTM; Spatial transformer; Video
   action recognition
AB As an important issue in video classification, human action recognition is becoming a hot topic in computer vision. The ways of effectively representing the spatial static and temporal dynamic information of videos are important problems in video action recognition. This paper proposes an attention mechanism based convolutional LSTM action recognition algorithm to improve the accuracy of recognition by extracting the salient regions of actions in videos effectively. First, GoogleNet is used to extract the features of video frames. Then, those feature maps are processed by the spatial transformer network for the attention. Finally the sequential information of the features is modeled via the convolutional LSTM to classify the action in the original video. To accelerate the training speed, we adopt the analysis of temporal coherence to reduce the redundant features extracted by GoogleNet with trivial accuracy loss. In comparison with the state-of-the-art algorithms for video action recognition, competitive results are achieved on three widely-used datasets, UCF-11, HMDB-51 and UCF-101. Moreover, by using the analysis of temporal coherence, desirable results are obtained while the training time is reduced.
C1 [Ge, Hongwei; Yan, Zehang; Yu, Wenhao; Sun, Liang] Dalian Univ Technol, Coll Comp Sci & Technol, Dalian 116023, Peoples R China.
C3 Dalian University of Technology
RP Ge, HW (corresponding author), Dalian Univ Technol, Coll Comp Sci & Technol, Dalian 116023, Peoples R China.
EM hwge@dlut.edu.cn
OI Ge, Hongwei/0000-0002-8937-1515
FU National Natural Science Foundation of China [61572104, 61103146,
   61402076]; Fundamental Research Funds for the Central Universities
   [DUT17JC04]
FX The authors are grateful to the support of the National Natural Science
   Foundation of China (61572104, 61103146, 61402076) and the Fundamental
   Research Funds for the Central Universities (DUT17JC04).
CR [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], INT C LEARN REPR ICL
   [Anonymous], 2015, 3 INT C LEARN REPR
   [Anonymous], PROC CVPR IEEE
   [Anonymous], CRCVTR1201 UCF
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], INT C LEARN REPR ICL
   [Anonymous], INT C IM AN REC ICIA
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2015, PROC 28 INT C NEURAL
   Bhattacharya S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2593, DOI 10.1109/CVPR.2011.5995746
   Bourdev, 2014, ARXIV14120767, V2, P7
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Guo YN, 2017, IEEE T SYST MAN CY-S, V47, P617, DOI 10.1109/TSMC.2016.2617465
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ikizler-Cinbis N, 2010, LECT NOTES COMPUT SC, V6311, P494, DOI 10.1007/978-3-642-15549-9_36
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kingma Diederik P, 2014, INT C LEARN REPR ICL, Patent No. [1312.6114, 13126114]
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lan ZZ, 2015, PROC CVPR IEEE, P204, DOI 10.1109/CVPR.2015.7298616
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Li Q, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P159, DOI 10.1145/2911996.2912001
   Li ZY, 2018, COMPUT VIS IMAGE UND, V166, P41, DOI 10.1016/j.cviu.2017.10.011
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Luo YH, 2018, MULTIMED TOOLS APPL, V77, P24041, DOI 10.1007/s11042-018-5728-8
   Mnih V., 2014, Neural Information Processing Systems, P2204
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tao DP, 2018, IEEE T IMAGE PROCESS, V27, P325, DOI 10.1109/TIP.2017.2762588
   Tao DP, 2016, IEEE INTERNET THINGS, V3, P1124, DOI 10.1109/JIOT.2016.2561962
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang XL, 2016, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2016.291
   Wu CY, 2018, PROC CVPR IEEE, P6026, DOI 10.1109/CVPR.2018.00631
   Wu ZX, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P461, DOI 10.1145/2733373.2806222
   Wu ZX, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P791, DOI 10.1145/2964284.2964328
   Xu K., 2015, COMPUTER SCI, P2048
   Yan Y, 2017, ELEC COMP C, P324, DOI 10.1109/ECTC.2017.282
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Ye H, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P435, DOI 10.1145/2671188.2749406
   Zhu YS, 2019, IEEE T IMAGE PROCESS, V28, P113, DOI 10.1109/TIP.2018.2865280
NR 56
TC 50
Z9 53
U1 1
U2 75
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20533
EP 20556
DI 10.1007/s11042-019-7404-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800071
DA 2024-07-18
ER

PT J
AU Li, R
   Ji, BY
   Li, YL
   Wu, CG
AF Li, Ran
   Ji, Bingyu
   Li, Yanling
   Wu, Changan
TI A Bayer motion estimation for motion-compensated frame interpolation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion-compensated frame interpolation; Bayer pattern; Prediction model;
   Bilateral motion estimation; Motion vector prediction
ID SUCCESSIVE ELIMINATION ALGORITHM; CONVERSION
AB We propose a Bayer ME algorithm which is used to improve the performance of Motion-Compensated Frame Interpolation (MCFI). The core of the proposed algorithm is a predictive model designed from the alternate arrangement of Bayer pattern. According to the predictive model, the Motion Vector Field (MVF) of the interpolated frame is first split into basic blocks and absent blocks, and then an improved Bilateral Motion Estimation (BME) is proposed to compute the MVs of basic blocks. Finally, with the local stationary statistics of MVF, the MV of an absent block is predicted from the MVs of its neighboring basic blocks. Experimental results show that the proposed Bayer ME algorithm can improve both objective and subjective quality of the interpolated frame with a low computational complexity.
C1 [Li, Ran; Ji, Bingyu; Li, Yanling; Wu, Changan] Xinyang Normal Univ, Sch Comp & Informat Technol, Xinyang 464000, Peoples R China.
C3 Xinyang Normal University
RP Li, R (corresponding author), Xinyang Normal Univ, Sch Comp & Informat Technol, Xinyang 464000, Peoples R China.
EM liran@xynu.edu.cn
RI li, chunyuan/IQW-1618-2023; li, yan/GTI-4638-2022; Li, Ran/N-3389-2013
OI Li, Ran/0000-0001-7475-759X
FU National Natural Science Foundation of China [61501393, 61572417]; Nanhu
   Scholars Program for Young Scholars of XYNU; Innovation Team Support
   Plan of University Science and Technology of Henan Province
   [19IRTSTHN014]
FX This work was supported in part by the National Natural Science
   Foundation of China, under Grants nos. 61501393 and 61572417, in part by
   Nanhu Scholars Program for Young Scholars of XYNU, and in part by
   Innovation Team Support Plan of University Science and Technology of
   Henan Province (No. 19IRTSTHN014).
CR Alparone L, 1996, INT CONF ACOUST SPEE, P2267, DOI 10.1109/ICASSP.1996.545874
   [Anonymous], 1999, METH MULT APPL
   Chen WJ, 2012, DIGIT SIGNAL PROCESS, V22, P163, DOI 10.1016/j.dsp.2011.09.006
   Choi BT, 2000, IEEE T CONSUM ELECTR, V46, P603, DOI 10.1109/30.883418
   Choi BD, 2007, IEEE T CIRC SYST VID, V17, P407, DOI 10.1109/TCSVT.2007.893835
   Dar Yehuda, 2015, IEEE Trans Image Process, V24, P2051, DOI 10.1109/TIP.2015.2412378
   de Haan G, 1993, IEEE T CIRC SYST VID, V3, P368, DOI 10.1109/76.246088
   Dikbas S, 2013, IEEE T IMAGE PROCESS, V22, P2931, DOI 10.1109/TIP.2012.2222893
   Gao XQ, 2000, IEEE T IMAGE PROCESS, V9, P501, DOI 10.1109/83.826786
   Guo D, 2016, NEUROCOMPUTING, V181, P76, DOI 10.1016/j.neucom.2015.06.102
   Horé A, 2011, IEEE T IMAGE PROCESS, V20, P3136, DOI 10.1109/TIP.2011.2159229
   Huang Y.-W., IEEE T CIRC SYST VID
   Jeon BW, 2003, IEEE T CONSUM ELECTR, V49, P499, DOI 10.1109/TCE.2003.1233761
   Kang SJ, 2007, IEEE T CONSUM ELECTR, V53, P1759, DOI 10.1109/TCE.2007.4429281
   Kaviani HR, 2016, IEEE T CIRC SYST VID, V26, P1581, DOI 10.1109/TCSVT.2015.2469120
   Kim D, 2013, IEEE T CIRC SYST VID, V23, P445, DOI 10.1109/TCSVT.2012.2207271
   LI W, 1995, IEEE T IMAGE PROCESS, V4, P105, DOI 10.1109/83.350809
   Lin YC, 1997, IEEE T COMMUN, V45, P527, DOI 10.1109/26.592551
   Lu QC, 2016, J DISP TECHNOL, V12, P45, DOI 10.1109/JDT.2015.2453252
   ORCHARD MT, 1994, IEEE T IMAGE PROCESS, V3, P693, DOI 10.1109/83.334974
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Tsai TH, 2016, IEEE T BROADCAST, V62, P426, DOI 10.1109/TBC.2016.2550764
   Tsai TH, 2012, J DISP TECHNOL, V8, P341, DOI 10.1109/JDT.2012.2186555
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xia M, 2017, MULTIMED TOOLS APPL, V76, P8399, DOI 10.1007/s11042-016-3468-1
   Young DM, 1988, SURVEY NUMERICAL MAT, V2, P759
   Zhang YB, 2012, J VIS COMMUN IMAGE R, V23, P229, DOI 10.1016/j.jvcir.2011.10.001
NR 27
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19603
EP 19619
DI 10.1007/s11042-019-7337-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800031
DA 2024-07-18
ER

PT J
AU Nickfarjam, AM
   Ebrahimpour-Komleh, H
AF Nickfarjam, Ali Mohammad
   Ebrahimpour-Komleh, Hossein
TI Multi-input 1-dimensional deep belief network: action and activity
   recognition as case study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-input 1-Dimensional Deep Belief Network; Action Recognition;
   Activity Recognition; Spatial Description; Temporal Description
AB This paper develops a new variation of deep belief networks which is evaluated on the basis of supervised classification of human actions and activities. The proposed multi-input 1-dimensional deep belief network (M1DBN) can work based on three inputs which contain different information structures. The multi input features helps M1DBN automatically search the solution space more accurately and extract high-level representations more efficiently. M1DBN utilizes three inputs to provide spatial, short-term and long-term information for the action and activity recognition. Spatial information can distinguish between human movements which have a high inter-class variation. However, regarding similar inter-class variations, a temporal description is used. Short-term and long-term inputs learn actions or activities for short and long video intervals, respectively. Experimental results show the superiority of this approach over state-of-the-art methods on KTH (97.04%), HMDB51 (67.19%), UCI-HAD (97.16%) and Skoda (93.28%) datasets. Also, a detailed explanation of learning, training and test procedures used in M1DBN are available.
C1 [Nickfarjam, Ali Mohammad; Ebrahimpour-Komleh, Hossein] Univ Kashan, Dept Comp Engn, Fac Elect & Comp Engn, Kashan, Iran.
C3 University Kashan
RP Ebrahimpour-Komleh, H (corresponding author), Univ Kashan, Dept Comp Engn, Fac Elect & Comp Engn, Kashan, Iran.
EM amnickfarjam@grad.kashanu.ac.ir; ebrahimpour@kashanu.ac.ir
OI Ebrahimpour-Komleh, Hossein/0000-0002-9935-7821
CR Alsheikh M. A., 2016, AAAI WORKSH ART INT
   [Anonymous], 2017, IEEE T PATTERN ANAL
   [Anonymous], 2017, IEEE T PATTERN ANAL
   [Anonymous], 2013, PUBLIC DOMAIN DATASE
   [Anonymous], 2017, ARXIV170503148
   [Anonymous], 2016, IEEE 13 INT C WEAR I
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], P WORKSH MOT VID COM
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], CRC STANDARD MATH TA
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], ARXIV180507648
   [Anonymous], 2013, IEEE INT C COMP VIS
   [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], NEUR INF PROC SYST W
   [Anonymous], IEEE INT C INF AUT I
   [Anonymous], 2008, IEEE C COMP VIS PATT
   [Anonymous], 2015, ARXIV150702159
   [Anonymous], IEEE SIGN PROC COMM
   [Anonymous], J INFORM
   [Anonymous], IEEE INT C DIG IM CO
   [Anonymous], IEEE INT C EL ENG
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], ARXIV170908421
   [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], COMPUTER VISION IMAG
   [Anonymous], 2010, IEEE C COMP VIS PATT
   [Anonymous], 2015, 23 ACM INT C MULT
   [Anonymous], WIRELESS SENSOR NETW
   [Anonymous], 2013, INT J COMPUTER VISIO
   Bilinski P, 2013, IEEE INT CONF AUTOMA
   Chen JF, 2012, MATH PROBL ENG, V2012, DOI 10.1155/2012/235929
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Hinton G, 2014, COGNITIVE SCI, V38, P1078, DOI 10.1111/cogs.12049
   Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Jhuang H, 2007, IEEE I CONF COMP VIS, P1253
   Kolesov R, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms2034
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Kumar R C., 2016, 2016 second international conference on cognitive computing and information processing (ccip), P1
   Le QV, 2011, PROC CVPR IEEE
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Murad A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112556
   Pers J, 2010, PATTERN RECOGN LETT, V31, P1369, DOI 10.1016/j.patrec.2010.03.024
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4
   Sharma S., 2015, NEURAL INFORM PROCES
   Shi YM, 2017, IEEE T MULTIMEDIA, V19, P1510, DOI 10.1109/TMM.2017.2666540
   Uddin MZ, 2017, KSII T INTERNET INF, V11, P1118, DOI 10.3837/tiis.2017.02.028
   Wang H., 2009, BMVC 2009 BRIT MACH
   Wang L, 2007, IEEE T IMAGE PROCESS, V16, P1646, DOI 10.1109/TIP.2007.896661
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wen W, 2017, ICCAD-IEEE ACM INT, P261, DOI 10.1109/ICCAD.2017.8203787
NR 61
TC 1
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17739
EP 17761
DI 10.1007/s11042-018-7076-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200020
DA 2024-07-18
ER

PT J
AU Wang, DD
   He, DJ
   Song, HB
   Liu, C
   Xiong, HT
AF Wang, Dandan
   He, Dongjian
   Song, Huaibo
   Liu, Chang
   Xiong, Hongting
TI Combining SUN-based visual attention model and saliency contour
   detection algorithm for apple image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Apples; Growth stage; Fruit segmentation; SUN; gPb-OWT-UCM; Region
   growing
ID OBJECT DETECTION; FRUIT DETECTION; AUTOMATIC RECOGNITION; LOCALIZATION;
   NUMBER
AB Accurate segmentation of apple fruit under natural illumination conditions provides benefits for growers to plan relevant applications of nutrients and pesticides. It also plays an important role for monitoring the growth status of the fruit. However, the segmentation of apples throughout various growth stages had only achieved a limited success so far due to the color changes of apple fruit as it matures as well as occlusion and the non-uniform background of apple images acquired in an orchard environment. To achieve the segmentation of apples with different colors and with various illumination conditions for the whole growth stage, a segmentation method independent of color was investigated. Features, including saliency and contour of the image, were combined in this algorithm to remove background and extract apples. Saliency using natural statistics (SUN) visual attention model was used for background removal and it was combined with threshold segmentation algorithm to extract salient binary region of apple images. The centroids of the obtained salient binary region were then extracted as initial seed points. Image sharpening, globalized probability of boundary-oriented watershed transform-ultrametric contour map (gPb-OWT-UCM) and Otsu algorithms were applied to detect saliency contours of images. With the built seed points and extracted saliency contours, a region growing algorithm was performed to accurately segment apples by retaining as many fruit pixels and removing as many background pixels as possible. A total of 556 apple images captured in natural conditions were used to evaluate the effectiveness of the proposed method. An average segmentation error (SE), false positive rate (FPR), false negative rate (FNR) and overlap Index (OI) of 8.4, 0.8, 7.5 and 90.5% respectively, were achieved and the performance of the proposed method outperformed other six methods in comparison. The method developed in this study can provide a more effective way to segment apples with green, red, and partially red colors without changing any features and parameters and therefore it is also applicable for monitoring the growth status of apples.
C1 [Wang, Dandan; He, Dongjian; Song, Huaibo; Liu, Chang; Xiong, Hongting] Northwest A&F Univ, Coll Mech & Elect Engn, Yangling 712100, Shaanxi, Peoples R China.
   [Wang, Dandan; He, Dongjian; Song, Huaibo; Liu, Chang; Xiong, Hongting] Minist Agr & Rural Affairs, Key Lab Agr Internet Things, Yangling 712100, Shaanxi, Peoples R China.
   [Wang, Dandan; He, Dongjian; Song, Huaibo; Liu, Chang; Xiong, Hongting] Shaanxi Key Lab Agr Informat Percept & Intelligen, Yangling 712100, Shaanxi, Peoples R China.
C3 Northwest A&F University - China; Ministry of Agriculture & Rural
   Affairs
RP He, DJ (corresponding author), Northwest A&F Univ, Coll Mech & Elect Engn, Yangling 712100, Shaanxi, Peoples R China.; He, DJ (corresponding author), Minist Agr & Rural Affairs, Key Lab Agr Internet Things, Yangling 712100, Shaanxi, Peoples R China.; He, DJ (corresponding author), Shaanxi Key Lab Agr Informat Percept & Intelligen, Yangling 712100, Shaanxi, Peoples R China.
EM hdj168@nwsuaf.edu.cn
RI SONG, Huaibo/GXM-9402-2022
FU National High Technology Research and Development Program of China (863
   Program) [SS2013AA100304]
FX This work was supported by the National High Technology Research and
   Development Program of China (863 Program) (SS2013AA100304).
CR [Anonymous], P 13 INT S EXP ROB
   [Anonymous], EFFICIENT INFERENCE
   [Anonymous], 2017, IEEE T CYBERN
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Barnea E, 2016, BIOSYST ENG, V146, P57, DOI 10.1016/j.biosystemseng.2016.01.013
   Bulanon D. M., 2010, Agricultural Engineering International: CIGR Journal, V12, P203
   Bulanon DM, 2002, BIOSYST ENG, V83, P405, DOI 10.1006/bioe.2002.0132
   Chen JZ, 2018, J VIS COMMUN IMAGE R, V50, P270, DOI 10.1016/j.jvcir.2017.12.006
   Chen JZ, 2017, IET COMPUT VIS, V11, P479, DOI 10.1049/iet-cvi.2016.0453
   Chen JZ, 2017, NEUROCOMPUTING, V266, P79, DOI 10.1016/j.neucom.2017.04.066
   Chen JZ, 2017, NEUROCOMPUTING, V251, P16, DOI 10.1016/j.neucom.2017.04.020
   Chen SW, 2017, IEEE ROBOT AUTOM LET, V2, P781, DOI 10.1109/LRA.2017.2651944
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Gongal A, 2015, COMPUT ELECTRON AGR, V116, P8, DOI 10.1016/j.compag.2015.05.021
   Gonzalez R, 2009, DIGITAL IMAGE PROCES
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hu P, 2017, PROC CVPR IEEE, P540, DOI 10.1109/CVPR.2017.65
   Ji W, 2012, COMPUT ELECTR ENG, V38, P1186, DOI 10.1016/j.compeleceng.2011.11.005
   Kanan C, 2010, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2010.5539947
   Kelman E, 2014, BIOSYST ENG, V118, P174, DOI 10.1016/j.biosystemseng.2013.11.007
   Li H, 2016, PRECIS AGRIC, V17, P678, DOI 10.1007/s11119-016-9443-z
   Linker R, 2015, COMPUT ELECTRON AGR, V114, P154, DOI 10.1016/j.compag.2015.04.005
   Linker R, 2012, COMPUT ELECTRON AGR, V81, P45, DOI 10.1016/j.compag.2011.11.007
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Qu WF, 2015, SPAN J AGRIC RES, V13, DOI 10.5424/sjar/2015133-7047
   Sa I, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081222
   SCHERTZ C E, 1968, Transactions of the ASAE (American Society of Agricultural Engineers), V11, P343
   Sengupta S, 2014, BIOSYST ENG, V117, P51, DOI 10.1016/j.biosystemseng.2013.07.007
   Si YS, 2015, COMPUT ELECTRON AGR, V112, P68, DOI 10.1016/j.compag.2015.01.010
   Silwal A., 2014, Agricultural Engineering International: CIGR Journal, V16, P66
   Song Y, 2014, BIOSYST ENG, V118, P203, DOI 10.1016/j.biosystemseng.2013.12.008
   Stein M, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16111915
   Wang DD, 2016, MULTIMED TOOLS APPL, V75, P3177, DOI 10.1007/s11042-014-2429-9
   Wang JD, 2017, INT J COMPUT VISION, V123, P251, DOI 10.1007/s11263-016-0977-3
   Wang Wenguan, 2015, IEEE Trans Image Process, V24, P3137, DOI 10.1109/TIP.2015.2438550
   Wang X, 2016, PATTERN RECOGN LETT, V75, P1, DOI 10.1016/j.patrec.2016.02.008
   Yang JM, 2012, PROC CVPR IEEE, P2296, DOI 10.1109/CVPR.2012.6247940
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhao CY, 2016, COMPUT ELECTRON AGR, V124, P243, DOI 10.1016/j.compag.2016.04.009
   Zhou R, 2012, PRECIS AGRIC, V13, P568, DOI 10.1007/s11119-012-9269-2
NR 46
TC 18
Z9 21
U1 1
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17391
EP 17411
DI 10.1007/s11042-018-7106-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200004
DA 2024-07-18
ER

PT J
AU Zhang, WW
   Tang, XH
   Yang, ZH
   Niu, SZ
AF Zhang, Weiwei
   Tang, Xinhua
   Yang, Zhenghong
   Niu, Shaozhang
TI Multi-scale segmentation strategies in PRNU-based image tampering
   localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photo-response non-uniformity; Image tampering localization; Multi-scale
   segmentation; Adaptive fusion strategy; Conditional random field
ID SENSOR PATTERN NOISE; CAMERA IDENTIFICATION; FORGERIES
AB With the rapid development of advanced media technology, especially the popularization of digital cameras and image editing software, digital images can be easily forged without leaving visible clues. Therefore, image forensics technology for identifying the accuracy, integrity, and originality of digital images has become increasingly important. Photo-response non-uniformity (PRNU) noise, a unique fingerprint of imaging sensors, is a valuable forgery detection tool because of its consistently good detection performance. All kinds of forgeries, including copy-move and splicing, can be dealt with in a uniform manner. This paper addresses the problem of forgery localization based on PRNU estimation and aims to improve the resolution of PRNU-based algorithms. Different from traditional overlapping and sliding window-based methods, in which PRNU correlations are estimated on overlapped patches, the proposed scheme is analyzed based on nonoverlapping and irregular patches. First, the test image is segmented into nonoverlapped patches with multiple scales. Second, correlations of PRNU are estimated on nonoverlapped patches to obtain the real-valued candidate tampering probability map for each individual scale. Then, all of the candidate maps are fused into a single and more reliable probability map through an adaptive window strategy. In the final step, the final decision map is obtained by adopting a conditional random field (CRF) to model neighborhood interactions. The contributions of this work include the following: a novel PRNU-based forgery localization scheme using multi-scale nonoverlapping segmentation is proposed for the first time. Furthermore, the adaptive fusion strategy involves selecting the best candidate tampering probability individually for each location in the image. Additionally, the experimental results prove that the proposed scheme can achieve much better detection results and robustness compared with the existing state-of-the-art PRNU-based methods.
C1 [Zhang, Weiwei; Yang, Zhenghong] China Agr Univ, Sch Sci, Beijing 100083, Peoples R China.
   [Tang, Xinhua] Shandong Univ Polit Sci & Law, Sch Informat, Jinan 250014, Shandong, Peoples R China.
   [Niu, Shaozhang] Beijing Univ Posts & Telecommun, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
C3 China Agricultural University; Shandong University of Political Science
   and Law; Beijing University of Posts & Telecommunications
RP Niu, SZ (corresponding author), Beijing Univ Posts & Telecommun, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
EM szniu@bupt.edu.cn
RI yang, zheng/HGC-7753-2022
FU National Natural Science Foundation of China [61370195, U1536121]
FX This work was supported by National Natural Science Foundation of China
   (contract No. 61370195, U1536121).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Al-Haj A, 2014, J DIGIT IMAGING, V27, P737, DOI 10.1007/s10278-014-9709-9
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2017, INT C IM AN PROC
   Baccari GC, 2011, INT REV CEL MOL BIO, V290, P1, DOI 10.1016/B978-0-12-386037-8.00006-5
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Chierchia Giovanni, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6231, DOI 10.1109/ICASSP.2014.6854802
   Chierchia G, 2014, IEEE T INF FOREN SEC, V9, P554, DOI 10.1109/TIFS.2014.2302078
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2016, IEEE INT WORKS INFOR
   Cozzolino D, 2014, IEEE IMAGE PROC, P5302, DOI 10.1109/ICIP.2014.7026073
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Gaborini L, 2014, IEEE INT WORKS INFOR, P125, DOI 10.1109/WIFS.2014.7084315
   Ge L, 2015, LECT NOTES COMPUT SC, V9314, P114, DOI 10.1007/978-3-319-24075-6_12
   Hou JU, 2017, IEEE T CIRC SYST VID, V27, P1826, DOI 10.1109/TCSVT.2016.2539828
   Johnson MK, 2007, IEEE T INF FOREN SEC, V2, P450, DOI 10.1109/TIFS.2007.903848
   Kai SC, 2006, P SPIE INT SOC OPTIC, V6069
   Kang XG, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-19
   Kokkonis G, 2016, J REAL-TIME IMAGE PR, V12, P343, DOI 10.1007/s11554-015-0505-7
   Korus P, 2017, IEEE T INF FOREN SEC, V12, P809, DOI 10.1109/TIFS.2016.2636089
   Lawgaly A, 2017, IEEE T INF FOREN SEC, V12, P392, DOI 10.1109/TIFS.2016.2620280
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Lin XF, 2016, IEEE SIGNAL PROC LET, V23, P381, DOI 10.1109/LSP.2016.2521349
   Lin XF, 2016, IEEE T INF FOREN SEC, V11, P126, DOI 10.1109/TIFS.2015.2478748
   Liu QG, 2011, IEEE T INF FOREN SEC, V6, P1111, DOI 10.1109/TIFS.2011.2139209
   Lombaert H, 2005, IEEE I CONF COMP VIS, P259
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Memos VA, 2017, FUTURE GENERATION CO
   Memos VA, 2016, J REAL-TIME IMAGE PR, V12, P473, DOI 10.1007/s11554-015-0509-3
   Mishra P, 2013, SCI WORLD J, DOI 10.1155/2013/267691
   Psannis KE, 2006, EURASIP J WIREL COMM, DOI 10.1155/WCN/2006/24616
   Psannis KE, 2019, IEEE T SUST COMPUT, V4, P77, DOI 10.1109/TSUSC.2018.2817043
   Pun CM, 2016, J VIS COMMUN IMAGE R, V38, P195, DOI 10.1016/j.jvcir.2016.03.005
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Saiqa K, 2011, INT J COMPUT APPL, V6, P31
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Stergiou C, 2017, 26 IEEE INT S IND EL
   Wang H, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), P2001, DOI 10.1109/ICInfA.2016.7832147
   Yao H, 2017, MULTIMED TOOLS APPL, V76, P12457, DOI 10.1007/s11042-016-3660-3
   Zhao Y, 2013, IEEE T INF FOREN SEC, V8, P55, DOI 10.1109/TIFS.2012.2223680
NR 47
TC 9
Z9 9
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20113
EP 20132
DI 10.1007/s11042-019-7288-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800054
OA hybrid
DA 2024-07-18
ER

PT J
AU Alenizi, F
   Kurdahi, F
   Eltawil, AM
   Al-Asmari, AK
AF Alenizi, Farhan
   Kurdahi, Fadi
   Eltawil, Ahmed M.
   Al-Asmari, Awad Kh.
TI Hybrid pyramid-DWT-SVD dual data hiding technique for videos ownership
   protection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Filter banks; Data hiding; Pyramid transform; Video
   coding; Singular value decomposition
ID WATERMARKING; SCHEME
AB This paper proposes a hybrid pyramid Discrete-Wavelet-Transform (DWT) Singular-Value-Decomposition (SVD) data hiding scheme for video authentication and ownership protection. The data being hidden will be in the shape of a main color logo image watermark and another secondary Black and White (B&W) logo image. The color watermark will be decomposed to Bit-Slices. A pyramid transform is performed on the Y-frames of a video stream resulting in error images; then, a Discrete Wavelet Transform (DWT) process is implemented using orthonormal filter banks on these error images, and the Bit-Slices watermarks are inserted in one or more of the resulting subbands in a way that is fully controlled by the owner; then, the watermarked video is reconstructed. SVD will be performed on the color watermark Bit-Slices. A secondary B&W watermark will be inserted in the main color watermark using another SVD process. An enhanced detection technique is developed to estimate the Singular Values to reconstruct the original color watermark image. The overall robustness of this scheme is measured when common attacks are applied to the test videos. A main contribution in this research is that the original host video is not required for the extraction process, the good robustness against different attacks specifically compression, transcoding, temporal and geometrical attacks and the duality in the hiding process. The simulation results show that the proposed algorithm achieves well under both the visual and the metric tests. Furthermore, it performed well against intentional and unintentional attacks. The reconstruction was perfect without attacks, while the average Bit-Error-Rates (BER's) achieved under attacks are in the limits of 2% for the color watermark and 5% for the secondary watermark; meanwhile, the mean Peak Signal-to-Noise Ratio (PSNR) is 57 dB.
C1 [Alenizi, Farhan] Prince Sattam Bin Abdulaziz Univ, Al Kharj, Saudi Arabia.
   [Kurdahi, Fadi; Eltawil, Ahmed M.] Univ Calif Irvine, Ctr Embedded & Cyber Phys Syst, Irvine, CA USA.
   [Al-Asmari, Awad Kh.] Shaqra Univ, Shaqra, Saudi Arabia.
C3 Prince Sattam Bin Abdulaziz University; University of California System;
   University of California Irvine; Shaqra University
RP Alenizi, F (corresponding author), Prince Sattam Bin Abdulaziz Univ, Al Kharj, Saudi Arabia.
EM farhan414@gmail.com; kurdahi@uci.edu; aeltawil@uci.edu;
   alsruoor@gmail.com
RI Eltawil, Ahmed/M-6893-2019; Alenizi, Farhan/GRR-2306-2022
OI Eltawil, Ahmed/0000-0003-1849-083X; 
CR Abdallah EE, 2010, SIGNAL IMAGE VIDEO P, V4, P233, DOI 10.1007/s11760-009-0114-7
   Agarwal P, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTER AND COMPUTATIONAL SCIENCES (ICCCS), P151, DOI 10.1109/ICCACS.2015.7361341
   Agilandeeswari L, 2016, MULTIMED TOOLS APPL, V75, P8745, DOI 10.1007/s11042-015-2789-9
   Contreras FCA, 2008, ATELIE GEOGR, V2, P1, DOI 10.5216/ag.v2i3.5331
   Al-Asmari AK, 2009, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTING, ENGINEERING AND INFORMATION, P44, DOI 10.1109/ICC.2009.29
   ALASMARI AK, 1995, IEEE T CIRC SYST VID, V5, P182, DOI 10.1109/76.401095
   Bhatnagar G, 2009, COMPUT STAND INTER, V31, P1002, DOI 10.1016/j.csi.2008.09.031
   Bhattacharya S, 2006, I SYMP CONSUM ELECTR, P616
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Frieze A, 2004, J ACM, V51, P1025, DOI 10.1145/1039488.1039494
   Guzmán VVH, 2004, INT CONF ELECTR COMM, P283, DOI 10.1109/ICECC.2004.1269587
   Kundur D, 1998, INT CONF ACOUST SPEE, P2969, DOI 10.1109/ICASSP.1998.678149
   Kutter M, 1999, PROC SPIE, V3657, P226, DOI 10.1117/12.344672
   Lee MS, 2003, INT J COMPUT MATH, V80, P401, DOI 10.1080/0020716021000023060
   Li X, 2013, J NETW COMPUT APPL, V36, P1365, DOI 10.1016/j.jnca.2013.02.034
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liu Y, 2010, SIGNAL PROCESS, V90, P626, DOI 10.1016/j.sigpro.2009.08.001
   Meerwald P, 2001, PROC SPIE, V4314, P505, DOI 10.1117/12.435434
   Mohan B. Chandra, 2008, Journal of Multimedia, V3, P7, DOI 10.4304/jmm.3.1.7-15
   Panyavaraporn J, 2011, P ISPACS DEC, P1
   Panyavaraporn J, 2013, 2013 13TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT): COMMUNICATION AND INFORMATION TECHNOLOGY FOR NEW LIFE STYLE BEYOND THE CLOUD, P397, DOI 10.1109/ISCIT.2013.6645890
   Potdar VA, 2005, 2005 3RD IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS (INDIN), P709
   Su QT, 2013, APPL MATH COMPUT, V219, P8455, DOI 10.1016/j.amc.2013.03.013
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Vetterli M, 1995, J KOVA CEVI C WAVELE
   Vinod P, 2005, LECT NOTES COMPUT SC, V3710, P147
   Wang SH, 2004, IEEE T IMAGE PROCESS, V13, P154, DOI 10.1109/TIP.2004.823822
   Wu XT, 2013, APPL SOFT COMPUT, V13, P1170, DOI 10.1016/j.asoc.2012.09.028
   Xu D, 2008, I C COMP AID DES CON, P332, DOI 10.1109/CAIDCD.2008.4730582
NR 31
TC 4
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14511
EP 14547
DI 10.1007/s11042-018-6723-9
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700018
DA 2024-07-18
ER

PT J
AU Gopalakrishnan, U
   Rangan, PV
   Ramkumar, N
   Hariharan, B
AF Gopalakrishnan, Uma
   Rangan, P. Venkat
   Ramkumar, N.
   Hariharan, Balaji
TI Parametric evaluation of progressively immersive multimedia
   representations for teaching environment in eLearning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Synchronous eLearning; Contour extraction; Spatial coherence; Perception
   parameters; Teaching environment representation
ID FACE-TO-FACE; LEARNING ENVIRONMENTS; DESIGN; SYSTEMS
AB Live eLearning systems present multimedia elements constituting the teaching environment, such as - teacher, teaching aids, in various ways creating virtual representations. Often, teacher's video and screencast of the teaching material are streamed and displayed as mutually exclusive disconnected entities. Though the existing eLearning systems give a clear view of the screen and the instructor delivering the lecture, they break the spatial connection between teacher's gestures and content on the screen. In this paper, we identify five perception parameters that influence visual perception of the teaching environment. We introduce new multimedia based representations that circumvent shortcomings of current approaches and provide a spatially coherent view mimicking the real world classroom scenario. By improving the perception parameters, we arrange the representations in a stepwise hierarchy that progressively moves towards an immersive teaching environment. We then present a framework to evaluate the effectiveness of various representations based on these parameters. Finally, we present a user study to substantiate our findings. Results indicate significant enhancement in classroom experience with proposed new representations.
C1 [Gopalakrishnan, Uma; Rangan, P. Venkat; Ramkumar, N.; Hariharan, Balaji] Amrita Vishwa Vidyapeetham, Amrita Sch Engn, Amrita Ctr Wireless Networks & Applicat AmritaWNA, Amritapuri, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Amritapuri
RP Gopalakrishnan, U (corresponding author), Amrita Vishwa Vidyapeetham, Amrita Sch Engn, Amrita Ctr Wireless Networks & Applicat AmritaWNA, Amritapuri, India.
EM umag@am.amrita.edu; venkat@amrita.edu; ramkumar@am.amrita.edu;
   balajih@am.amrita.edu
CR Aguti B, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATION SOCIETY (I-SOCIETY 2014), P117, DOI 10.1109/i-Society.2014.7009023
   [Anonymous], E J STUDENT RES
   [Anonymous], 2010, Image Rochester NY
   Arkorful V., 2015, INT J INSTRUCTIONAL, V12, P29, DOI DOI 10.1016/J.PR0CS.2012.10.037
   Bell J., 2014, International Journal of Designs for Learning, V5, DOI DOI 10.14434/IJDL.V5I1.12657
   Bijlani K., 2011, P 3 INT ACM WORKSHOP, P13
   Bower M, 2017, BRIT J EDUC TECHNOL, V48, P407, DOI 10.1111/bjet.12435
   Bower M, 2015, COMPUT EDUC, V86, P1, DOI 10.1016/j.compedu.2015.03.006
   Bradski G., 2008, LEARNING OPENCV
   CHANDLER P, 1992, BRIT J EDUC PSYCHOL, V62, P233, DOI 10.1111/j.2044-8279.1992.tb01017.x
   Davison A., 2012, Kinect Open Source Programming Secrets: Hacking the Kinect with OpenNI, NITE, and Java
   Kloos CD, 2015, IEEE GLOB ENG EDUC C, P967, DOI 10.1109/EDUCON.2015.7096090
   Dunsworth Q, 2007, COMPUT EDUC, V49, P677, DOI 10.1016/j.compedu.2005.11.010
   Faiola T., 1988, Educational Technology, V28, P12
   Falloon G, 2011, EXPLORING VIRTUAL CL
   Foster J, 2014, GREEN SCREEN HDB REA
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Gedera D.S., 2014, International Journal of Education and Development using Information and Communication Technology, V10, P93
   Gedera D, 2015, MOTIVATION, LEADERSHIP AND CURRICULUM DESIGN: ENGAGING THE NET GENERATION AND 21ST CENTURY LEARNERS, P13, DOI 10.1007/978-981-287-230-2_2
   Gopalakrishnan U, 2017, IEEE INT SYM MULTIM, P138, DOI 10.1109/ISM.2017.120
   Gopalakrishnan U, 2016, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS, VOL 2 (ICEIS), P223, DOI 10.5220/0005820702230229
   Hariharan RNB, 2016, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON COMPUTER SUPPORTED EDUCATION, VOL 1 (CSEDU), P353, DOI 10.5220/0005803303530358
   Hartung K., 2015, Planning for Higher Education, V43, P40
   Hood S., 2011, Semiotic Margins: Meaning in Multimodalites, P31
   Hsu H.M. J., 2011, INT J INFORM ED TECH, V1, P365, DOI [10.7763/IJIET.2011.V1.59, DOI 10.7763/IJIET.2011.V1.59]
   Hyder K, 2007, SYNCHRONOUS LEARNING
   Istrate O, 2009, E LEARNING PAPERS, V17
   Kalyuga S, 2007, EDUC PSYCHOL REV, V19, P387, DOI 10.1007/s10648-007-9051-6
   Kim Juho, 2014, P 1 ACM C LEARN SCAL, P31, DOI [DOI 10.1145/2556325.2566237, DOI 10.1145/2556325.2566239]
   Konstantinidis A, 2009, MULTIMED TOOLS APPL, V44, P279, DOI 10.1007/s11042-009-0289-5
   Lee SH, 1999, INT J SYST SCI, V30, P19, DOI 10.1080/002077299292623
   Liaw SS, 2008, COMPUT EDUC, V51, P864, DOI 10.1016/j.compedu.2007.09.005
   Mayer RE, 1998, J EDUC PSYCHOL, V90, P312, DOI 10.1037/0022-0663.90.2.312
   McBrien J. L., 2009, The International Review of Research in Open and Distributed Learning, V10, DOI DOI 10.19173/IRRODL.V10I3.605
   Mertens R., 2006, E LEARN, P2937
   Moreno R., 2000, Interactive Multimedia Electronic Journal of Computer-Enhanced Learning, V2, P12
   Nascimento L, 2016, REV MANGAIO ACAD, V1, P12
   Ou C, 2016, PROCEEDINGS OF THE THIRD (2016) ACM CONFERENCE ON LEARNING @ SCALE (L@S 2016), P141, DOI 10.1145/2876034.2893391
   Popov O, 2009, INT REV RES OPEN DIS, V10
   Pylyshyn Z, 1999, BEHAV BRAIN SCI, V22, P341, DOI 10.1017/S0140525X99002022
   Reid-Griffin A, 2015, SOC INF TECHN TEACH, P455
   Roseth C, 2013, TECHTRENDS, V57, P54, DOI 10.1007/s11528-013-0663-z
   Roth WM, 2001, REV EDUC RES, V71, P365, DOI 10.3102/00346543071003365
   Saba T, 2012, HUM-CENT COMPUT INFO, V2, DOI 10.1186/2192-1962-2-6
   Santrac N, 2006, HIGH RESOLUTION SEGM
   Schullo S., 2007, MERLOT Journal of Online Learning and Teaching, V3, P331
   Stanisavljevic Z, 2015, MULTIMED TOOLS APPL, V74, P3843, DOI 10.1007/s11042-013-1802-4
   Subramanian N.S., 2014, P 2014 INT C INT ADV, P53
   Szeto E, 2015, COMPUT EDUC, V81, P191, DOI 10.1016/j.compedu.2014.10.015
   Tacca MC, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00358
   Wai CC, 2015, EDUC INF TECHNOL, V20, P429, DOI 10.1007/s10639-013-9293-5
   Wang QY, 2017, INT REV RES OPEN DIS, V18, P99
   Woodworth JW, 2017, P IEEE VIRT REAL ANN, P471, DOI 10.1109/VR.2017.7892384
NR 53
TC 1
Z9 1
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15403
EP 15432
DI 10.1007/s11042-018-6934-0
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700055
DA 2024-07-18
ER

PT J
AU Jelodar, H
   Wang, YL
   Yuan, C
   Feng, X
   Jiang, XH
   Li, YC
   Zhao, L
AF Jelodar, Hamed
   Wang, Yongli
   Yuan, Chi
   Feng, Xia
   Jiang, Xiahui
   Li, Yanchao
   Zhao, Liang
TI Latent Dirichlet allocation (LDA) and topic modeling: models,
   applications, a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Topic modeling; Latent Dirichlet allocation; Tag recommendation;
   Semantic web; Gibbs sampling
ID SENTIMENT ANALYSIS; TWITTER; LANGUAGE
AB Topic modeling is one of the most powerful techniques in text mining for data mining, latent data discovery, and finding relationships among data and text documents. Researchers have published many articles in the field of topic modeling and applied in various fields such as software engineering, political science, medical and linguistic science, etc. There are various methods for topic modelling; Latent Dirichlet Allocation (LDA) is one of the most popular in this field. Researchers have proposed various models based on the LDA in topic modeling. According to previous work, this paper will be very useful and valuable for introducing LDA approaches in topic modeling. In this paper, we investigated highly scholarly articles (between 2003 to 2016) related to topic modeling based on LDA to discover the research development, current trends and intellectual structure of topic modeling. In addition, we summarize challenges and introduce famous tools and datasets in topic modeling based on LDA.
C1 [Jelodar, Hamed; Wang, Yongli; Yuan, Chi; Feng, Xia; Jiang, Xiahui; Li, Yanchao; Zhao, Liang] Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Jiangsu, Peoples R China.
   [Wang, Yongli] China Elect Technol Cyber Secur Co Ltd, Chengdu, Sichuan, Peoples R China.
C3 Nanjing University of Science & Technology
RP Wang, YL (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Jiangsu, Peoples R China.; Wang, YL (corresponding author), China Elect Technol Cyber Secur Co Ltd, Chengdu, Sichuan, Peoples R China.
EM Jelodar@njust.edu.cn; YongliWang@njust.edu.cn; yuanchi@njust.edu.cn;
   779477284@qq.com; jxhchina@gmail.com
RI Jelodar, Hamed/HTM-7150-2023
OI Jelodar, Hamed/0000-0002-0713-3143
FU National Natural Science Foundation of China [61170035, 61272420,
   81674099, 61502233]; Fundamental Research Fund for the Central
   Universities [30916011328, 30918015103]; Nanjing Science and Technology
   Development Plan Project [201805036]
FX This article has been awarded by the National Natural Science Foundation
   of China (61170035, 61272420, 81674099, 61502233), the Fundamental
   Research Fund for the Central Universities (30916011328, 30918015103),
   and Nanjing Science and Technology Development Plan Project (201805036).
CR Ahmed A., 2012, P 5 ACM INT C WEB SE
   Alam MH, 2016, INFORM SCIENCES, V339, P206, DOI 10.1016/j.ins.2016.01.013
   Alashri S, 2016, IEEE ACM INT C ADV S
   AlSumait L, 2008, IEEE DATA MINING, P3, DOI 10.1109/ICDM.2008.140
   [Anonymous], 2006, Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P424, DOI [DOI 10.1145/1150402.1150450, 10.1145/1150402.1150450]
   [Anonymous], 2011, P 20 INT C COMPANION, DOI [10.1145/1963192.1963222, DOI 10.1145/1963192.1963222]
   [Anonymous], 2010, EMNLP
   [Anonymous], 2007, AAAI 07, DOI DOI 10.5555/1619645.1619752
   [Anonymous], 2012, Mining Text Data, DOI [10.1007/978-1-4614-3223-4_13, DOI 10.1007/978-1-4614-3223-4_13, DOI 10.1007/978-1-4614-3223-413]
   [Anonymous], 2008, P 17 INT C WORLD WID, DOI DOI 10.1145/1367497.1367513
   [Anonymous], 2002, Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence. UAI'02
   [Anonymous], 2008, The PASCAL visual object classes challenge 2008 (VOC2008) results
   [Anonymous], 2011, P 17 ACM SIGKDD INT
   [Anonymous], 2012, P DOCT S INF ENG
   [Anonymous], BMVC
   Asgari E., 2013, P 2 WORKSH COMP LING
   Asuncion H.U., 2010, P 32 ACM IEEE INT C, V1
   Bagheri A, 2014, J INF SCI, V40, P621, DOI 10.1177/0165551514538744
   Balasubramanyan R., 2012, ICWSM 2012 P 6 INT A, P18
   Bauer S, 2012, PRIVACY SECURITY RIS
   Bhattacharya P, 2014, PROCEEDINGS OF THE 8TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'14), P357, DOI 10.1145/2645710.2645765
   Bisgin H, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-267
   Blei D.M., 2003, P 26 ANN INT ACM SIG
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2006, P 23 INT C MACH LEAR, P113
   Chaney AllisonJ.B., 2012, ICWSM
   Chang J, 2009, REL TOP MOD DOC NETW
   Chang J., 2011, 1DA COLLAPSED GIBBS
   Chen B., 2010, AAAI
   CHEN L, 2013, INT C SERV OR COMP
   Chen S- H, 2015, 2015 INT CARN C SEC
   Chen T- H, 2012, 2012 9 IEEE WORK C M
   Chen TH, 2016, EMPIR SOFTW ENG, V21, P1843, DOI 10.1007/s10664-015-9402-8
   Chen Xiao, 2014, Reluctance torque evaluation for interior permanent magnet machines using frozen permeability, DOI 10.1049/iet-tv.50.19173
   Cheng VC, 2014, IEEE T KNOWL DATA EN, V26, P2002, DOI 10.1109/TKDE.2013.175
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Chien JT, 2011, IEEE T AUDIO SPEECH, V19, P482, DOI 10.1109/TASL.2010.2050717
   Chong W, 2009, IEEE C COMP VIS PATT
   Choo J, 2013, IEEE T VIS COMPUT GR, V19, P1992, DOI 10.1109/TVCG.2013.212
   Chuang J, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P74, DOI 10.1145/2254556.2254572
   Cohen R., 2013, Proceedings of the Seventh International AAAI Conference on Weblogs and Social Media, V7, P91, DOI [10.1609/icwsm.v7i1.14434, DOI 10.1609/ICWSM.V7I1.14434, https://doi.org/10.1609/icwsm.v7i1.14434]
   Cohen R, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0087555
   Cong Y, 2012, INT C ADV DAT MIN AP
   Cristani M, 2008, COMP VIS PATT REC 20, V2008
   Daud A, 2010, FRONT COMPUT SCI CHI, V4, P280, DOI 10.1007/s11704-009-0062-y
   Debortoli S, 2016, COMMUN ASSOC INF SYS, V39, P110, DOI 10.17705/1CAIS.03907
   Diao Q., 2012, P 50 ANN M ASS COMP, V1
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fang Y, 2012, P 5 ACM INT C WEB SE
   Fu XH, 2016, NEUROCOMPUTING, V171, P412, DOI 10.1016/j.neucom.2015.06.047
   Fu XH, 2015, KNOWL-BASED SYST, V82, P102, DOI 10.1016/j.knosys.2015.02.021
   Fu XH, 2013, KNOWL-BASED SYST, V37, P186, DOI 10.1016/j.knosys.2012.08.003
   Gerber MS, 2014, DECIS SUPPORT SYST, V61, P115, DOI 10.1016/j.dss.2014.02.003
   Gethers M, 2010, 2010 IEEE INT C SOFT
   Giri R, 2014, INT C INT DAT ENG AU
   Godin F, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P593
   Greene D., 2015, Proceedings of the ACM Web Science Conference, V1, P10, DOI DOI 10.1145/2786451.2786464
   Gretarsson B, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2089094.2089099
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Guo J., 2009, P 32 INT ACM SIGIR C
   Heintz I., 2013, P 1 WORKSH MET NLP, P58
   Henderson K, 2009, 2009 P ACM S APPL CO
   Hong L, 2016, AAAI
   Hou L, 2015, KNOWL-BASED SYST, V76, P17, DOI 10.1016/j.knosys.2014.11.017
   Hu PF, 2014, PATTERN RECOGN, V47, P1138, DOI 10.1016/j.patcog.2013.06.010
   Hu Y., 2012, AAAI
   Huang ZX, 2013, J MED SYST, V37, DOI 10.1007/s10916-012-9915-2
   Jagarlamudi J, 2010, ECIR
   Jiang D, 2015, KNOWL-BASED SYST, V84, P18, DOI 10.1016/j.knosys.2015.03.020
   Jiang Z, 2012, 2012 IEEE 14 INT C E
   Jo Yohan, 2011, P 4 ACM INT C WEB SE, P815, DOI DOI 10.1145/1935826.1935932
   Kim Minjeong, 2017, IEEE Trans Vis Comput Graph, V23, P151, DOI 10.1109/TVCG.2016.2598445
   Kim Y, 2014, INFORM SYST, V42, P59, DOI 10.1016/j.is.2013.11.003
   Lacoste-Julien S, 2009, ADV NEURAL INFORM PR
   Lange D, 2011, P 20 ACM INT C INF K
   Larkey LS, 2001, TREC
   Lee S., 2016, IEEE T DEPENDABLE SE
   Levy KEC, 2014, SOC SCI COMPUT REV, V32, P182, DOI 10.1177/0894439313506847
   Lewis DD, 2004, J MACH LEARN RES, V5, P361
   Lewis DD, 1997, REUTERS
   Li C, 2016, KNOWL-BASED SYST, V99, P168, DOI 10.1016/j.knosys.2016.02.005
   Li CS, 2015, KNOWL INF SYST, V44, P359, DOI 10.1007/s10115-014-0764-9
   Li Fangtao, 2010, AAAI
   Li Jiwei, 2013, ACL
   Li Rui., 2012, P 18 ACM SIGKDD INT, P1023
   Li Wei, 2006, P 23 INT C MACH LEAR, DOI [10.1145/1143844.1143917, DOI 10.1145/1143844.1143917]
   Li XM, 2015, NEUROCOMPUTING, V149, P811, DOI 10.1016/j.neucom.2014.07.053
   Li YG, 2016, CHINA COMMUN, V13, P91, DOI 10.1109/CC.2016.7781721
   Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140
   Li ZC, 2013, ACM T MULTIM COMPUT, V10, DOI 10.1145/2488732
   Li ZF, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2807705
   Li Zhizhong, 2018, IEEE transactions on pattern analysis and machine intelligence
   Liénou M, 2010, IEEE GEOSCI REMOTE S, V7, P28, DOI 10.1109/LGRS.2009.2023536
   Lin J., 2013, P 36 INT ACM SIGIR C
   Linstead E., 2007, P 22 IEEE ACM INT C
   Linstead E, 2008, SEVENTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P813, DOI 10.1109/ICMLA.2008.47
   Liu B, 2010, BIOINFORMATICS, V26, P3105, DOI 10.1093/bioinformatics/btq576
   Liu Yang, 2016, AAAI
   Liu YZ, 2016, NEUROCOMPUTING, V210, P155, DOI 10.1016/j.neucom.2015.10.144
   Liu ZY, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961198
   Lu HM, 2016, J BIOMED INFORM, V60, P210, DOI 10.1016/j.jbi.2016.02.003
   Lu HM, 2015, IEEE INTELL SYST, V30, P18, DOI 10.1109/MIS.2015.20
   Lui M., 2014, Transactions of the Association for Computational Linguistics, V2, P27
   Lukins SK, 2008, 15 WORK C REV ENG 20
   Lukins SK, 2010, INFORM SOFTWARE TECH, V52, P972, DOI 10.1016/j.infsof.2010.04.002
   Madan A, 2011, INT C PERV COMP
   Manandhar Suresh, 2013, 2 JOINT C LEX COMP S, V2
   Mao X-L, 2012, Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning, P800
   McCallum A.K., 2002, MALLET MACHINE LEARN
   McCallum A, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P786
   McFarland DA, 2013, POETICS, V41, P607, DOI 10.1016/j.poetic.2013.06.004
   McInerney J, 2014, WORKSH CONJ KDD2014
   Miao J, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2956234
   Millar JR, 2009, FLAIRS C
   Murdock J, 2015, AAAI
   Nakano T, 2014, IEEE INT C AC SPEECH
   Nguyen D. Q., 2015, Transactions of the Association for Computational Linguistics, V3, P299, DOI DOI 10.1162/TACL_A_00140
   Panichella  Annibale, 2013, P 2013 INT C SOFTW E
   Paul, 2010, Urbana, V51, P61801
   Paul M, 2012, LDA SPARSE MULTIDIME
   Paul Michael J., 2011, P 5 INT AAAI C WEBL, P265
   Phan Xuan-Hieu., 2006, Jgibblda: A java implementation of latent dirichlet allocation (lda) using gibbs sampling for parameter estimation and inference"
   Philbin J, 2011, INT J COMPUT VISION, V95, P138, DOI 10.1007/s11263-010-0363-5
   Preotiuc-Pietro D, 2017, P 55 ANN M ASS COMP, V1
   Prier KW, 2011, INT C SOC COMP
   Qian SS, 2016, IEEE T MULTIMEDIA, V18, P233, DOI 10.1109/TMM.2015.2510329
   Qin ZC, 2016, COMPUT SPEECH LANG, V40, P60, DOI 10.1016/j.csl.2016.03.004
   Ramage D., 2011, Stanford topic modeling toolbox
   Ramage Daniel., 2009, EMNLP, DOI DOI 10.3115/1699510.1699543
   Rao YH, 2016, IEEE INTELL SYST, V31, P41, DOI 10.1109/MIS.2015.91
   Rao YH, 2014, WORLD WIDE WEB, V17, P723, DOI 10.1007/s11280-013-0221-9
   Rehurek R., 2011, GENSIM STAT SEMANTIC
   Ren YF, 2016, INFORM SCIENCES, V369, P188, DOI 10.1016/j.ins.2016.06.040
   Rennie J, 2017, 20 NEWSGROUPS DATA S
   Resnik P., 2012, P 50 ANN M ASS COMP, V2
   Roberts K., 2012, LREC
   Rosen-Zvi M., 2004, Pro- ceedings of the 20th conference on Uncertainty in artificial intelligence, UAI '04, P487, DOI DOI 10.5555/1036843.1036902
   Sandhaus E., 2008, The New York Times Annotated Corpus, V6, P26752
   Savage T, 2010, PROC IEEE INT CONF S
   Sharma V, 2015, ANAL NEWSPAPER CRIME
   Shi B, 2016, DETECTING COMMON DIS
   Siersdorfer S, 2014, ACM T WEB, V8, DOI 10.1145/2628441
   Sizov S., 2010, WSDM
   Song M, 2014, IEEE INTELL SYST, V29, P18, DOI 10.1109/MIS.2014.20
   Srijith PK, 2017, INFORM PROCESS MANAG, V53, P989, DOI 10.1016/j.ipm.2016.10.004
   Steyvers M., 2015, Handbook of Latent Semantic Analysis, DOI [10.4324/9780203936399.ch21, DOI 10.4324/9780203936399.CH21, DOI 10.1371/JOURNAL.PONE.0073791]
   Steyvers M., 2011, Matlab topic modeling toolbox version 1.4
   Sun SL, 2017, INFORM FUSION, V36, P10, DOI 10.1016/j.inffus.2016.10.004
   Sun X, 2016, 2016 17 IEEE ACIS IN
   Tan SL, 2014, IEEE T KNOWL DATA EN, V26, P1158, DOI 10.1109/TKDE.2013.116
   Tang H, 2013, IEEE T GEOSCI REMOTE, V51, P1680, DOI 10.1109/TGRS.2012.2205579
   Thomas S. W., 2011, P 33 INT C SOFTW ENG
   Thomas SW, 2011, P 8 WORK C MIN SOFTW
   Tian K, 2009, 6 IEEE INT WORK C MI
   Vaduva C, 2013, IEEE T GEOSCI REMOTE, V51, P2770, DOI 10.1109/TGRS.2012.2219314
   Vulic I, 2011, P 49 ANN M ASS COMP, V2
   Wallach Hanna M., 2009, Advances in neural information processing systems, P1973, DOI DOI 10.1007/S10708-008-9161-9
   Wang C., 2009, NEURIPS, P1982
   Wang Chong, 2011, P 17 ACM SIGKDD INT, P448, DOI [DOI 10.1145/2020408.2020480, 10.1145/2020408.2020480]
   Wang HJ, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017243
   Wang JD, 2014, COMPUT VIS IMAGE UND, V124, P61, DOI 10.1016/j.cviu.2014.02.011
   Wang S, 2014, IEEE INT CON MULTI
   Wang T, 2014, KNOWL-BASED SYST, V71, P86, DOI 10.1016/j.knosys.2014.05.018
   Wang Y. C., 2013, P SIGCHI C HUM FACT, P31, DOI DOI 10.1145/2470654.2470659
   Wang Yang., 2016, ICWSM
   Weng J., 2021, Proc. Int. AAAI Conf. Web Soc. Media, V5, P401, DOI [10.1609/icwsm.v5i1.14102, DOI 10.1609/ICWSM.V5I1.14102]
   Weng J., 2010, P 3 ACM INT C WEB SE, P261, DOI [10.1145/1718487.1718520, DOI 10.1145/1718487.1718520]
   Wick M, 2007, 9 INT C DOC AN REC 2
   Wilson A., 2010, HUMAN LANGUAGE TECHN
   Wu H, 2012, PATTERN RECOGN, V45, P617, DOI 10.1016/j.patcog.2011.04.029
   Wu Y, 2012, PACIFIC S BIOCOMPUTI
   Xiao C, 2017, AAAI
   Xiaofeng Wang, 2012, Social Computing, Behavioral-Cultural Modeling and Prediction. Proceedings of the 5th International Conference, SBP 2012, P231, DOI 10.1007/978-3-642-29047-3_28
   Xie Pengtao, 2015, C N AM CHAPT ASS COM
   Xie W, 2016, IEEE T KNOWL DATA EN, V28, P2216, DOI 10.1109/TKDE.2016.2556661
   Xin Y, 2015, EXPERT SYST APPL, V42, P366, DOI 10.1016/j.eswa.2014.07.009
   Xu Z, 2017, MULTIMED TOOLS APPL, V76, P11567, DOI 10.1007/s11042-015-2731-1
   Yan X., 2013, P 22 INT C WORLD WID, P1445, DOI DOI 10.1145/2488388.2488514
   Yang M, 2015, 2015 48 HAW INT C SY
   Yang MC, 2014, EXPERT SYST APPL, V41, P4330, DOI 10.1016/j.eswa.2013.12.051
   Yang X, 2017, CHARACTERIZING MALIC
   Yano T., 2009, P HUM LANG TECHN 200
   Yano Tae, 2010, ICWSM
   Yeh JF, 2016, NEUROCOMPUTING, V216, P310, DOI 10.1016/j.neucom.2016.08.017
   Yin HZ, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1543, DOI 10.1145/2588555.2593685
   Yin Z, 2011, PROCEEDINGS OF THE 2
   Yoshii K, 2012, IEEE T AUDIO SPEECH, V20, P717, DOI 10.1109/TASL.2011.2164530
   Yu K, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-S17-S6
   Yu R, 2015, ACM T KNOWL DISCOV D, V10, DOI 10.1145/2811268
   Yuan B, 2014, 2014 INTERNATIONAL CONFERENCE ON POWER SYSTEM TECHNOLOGY (POWERCON)
   Yuan J., 2015, P 24 INT C WORLD WID
   Zeng J, 2016, IEEE T KNOWL DATA EN, V28, P675, DOI 10.1109/TKDE.2015.2492565
   Zhai Ke, 2012, P 21 INT C WORLD WID, P879, DOI 10.1145/2187836.2187955
   Zhai ZW, 2011, LECT NOTES ARTIF INT, V6634, P448, DOI 10.1007/978-3-642-20841-6_37
   Zhang J., 2013, IJCAI
   Zhang L, 2015, CONCURR COMP-PRACT E, V27, P4015, DOI 10.1002/cpe.3474
   Zhang XP, 2011, CHIN J INTEGR MED, V17, P307, DOI 10.1007/s11655-011-0699-x
   Zhang Y, 2017, FUTURE GENER COMP SY, V66, P30, DOI 10.1016/j.future.2015.12.001
   Zhao F, 2016, FUTURE GENER COMP SY, V65, P196, DOI 10.1016/j.future.2015.10.012
   Zhao WNX, 2011, LECT NOTES COMPUT SC, V6611, P338, DOI 10.1007/978-3-642-20161-5_34
   Zheng XL, 2014, KNOWL-BASED SYST, V61, P29, DOI 10.1016/j.knosys.2014.02.003
   Zhu Jun, 2009, INT C MACH LEARN ICM
   Zirn C, 2014, DATA KNOWL ENG, V90, P38, DOI 10.1016/j.datak.2013.07.003
   Zoghbi S, 2016, INFORM SCIENCES, V367, P573, DOI 10.1016/j.ins.2016.05.047
   [No title captured]
NR 205
TC 641
Z9 706
U1 155
U2 764
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15169
EP 15211
DI 10.1007/s11042-018-6894-4
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700046
OA Green Submitted
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Shubham, S
   Bhandari, AK
AF Shubham, Swapnil
   Bhandari, Ashish Kumar
TI A generalized Masi entropy based efficient multilevel thresholding
   method for color image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Efficient multilevel thresholding; Color image segmentation; Kapur's;
   Renyi's; Tsallis and Masi's entropy
ID CUCKOO SEARCH ALGORITHM; DIFFERENTIAL EVOLUTION; TSALLIS; RENYI;
   PERFORMANCE; KAPURS
AB Multilevel thresholding for image segmentation is a crucial process in several applications such as feature extraction and pattern recognition. In this paper, a novel Masi entropy-based criterion for color satellite image multilevel thresholding is proposed. The proposed algorithm is based on Masi entropy which can deal with the additive/non-extensive information through the aid of a concordant entropic parameter r' which is extended in favor of multilevel based color satellite image segmentation. In addition, a comparative study between proposed Masi entropy-based color image multilevel thresholding and well known state-of-the-art entropies such as Kapur's, Renyi's and Tsallis entropy is presented. The simulation results of the proposed Masi entropy-based algorithm illustrate better performance for normal and color satellite image segmentation. Trials are conducted on various color test images to concrete the efficiency of the proposed algorithm. For segmentation purpose numerous fidelity parameters are computed such as structural similarity index (SSIM), feature similarity index (FSIM), misclassification error (ME), mean square error (MSE) and peak signal to noise ratio (PSNR).
C1 [Shubham, Swapnil; Bhandari, Ashish Kumar] Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna 800005, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Bhandari, AK (corresponding author), Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna 800005, Bihar, India.
EM swapnil612chi@gmail.com; bhandari.iiitj@gmail.com
RI Bhandari, Ashish Kumar/AAA-9991-2019
OI Bhandari, Ashish Kumar/0000-0001-9842-8125
CR Abdel-Khalek S, 2017, OPTIK, V131, P414, DOI 10.1016/j.ijleo.2016.11.039
   [Anonymous], 2018, IEEE J-STARS
   [Anonymous], NOVEL ACTIVE CONTOUR
   [Anonymous], 2017, SIGNAL IMAGE VIDEO P
   Ben Ishak A, 2017, PHYSICA A, V466, P521, DOI 10.1016/j.physa.2016.09.053
   Bhandari AK, 2017, MULTIDIM SYST SIGN P, V28, P495, DOI 10.1007/s11045-015-0353-4
   Bhandari AK, 2016, EXPERT SYST APPL, V63, P112, DOI 10.1016/j.eswa.2016.06.044
   Bhandari AK, 2016, NEUROCOMPUTING, V174, P698, DOI 10.1016/j.neucom.2015.09.079
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P8707, DOI 10.1016/j.eswa.2015.07.025
   Bhandari AK, 2015, AEU-INT J ELECTRON C, V69, P579, DOI 10.1016/j.aeue.2014.11.012
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P1573, DOI 10.1016/j.eswa.2014.09.049
   Bhandari AK, 2012, PROC TECH, V1, P612, DOI 10.1016/j.protcy.2012.10.074
   Bhandari AK, 2018, NEURAL COMPUT APPL, P1
   Bhandari AK, 2016, J EXP THEOR ARTIF IN, V28, P71, DOI 10.1080/0952813X.2015.1020518
   Bhandari AK, 2014, EXPERT SYST APPL, V41, P3538, DOI 10.1016/j.eswa.2013.10.059
   Chao Y, 2016, OPTIK, V127, P5770, DOI 10.1016/j.ijleo.2016.03.059
   Choy SK, 2017, PATTERN RECOGN, V68, P141, DOI 10.1016/j.patcog.2017.03.009
   de Albuquerque MP, 2004, PATTERN RECOGN LETT, V25, P1059, DOI 10.1016/j.patrec.2004.03.003
   Han B, 2017, PATTERN RECOGN, V67, P396, DOI 10.1016/j.patcog.2017.02.022
   Kapoor S, 2017, PROCEDIA COMPUT SCI, V115, P415, DOI 10.1016/j.procs.2017.09.100
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kaur T, 2016, STUD COMPUT INTELL, V651, P461, DOI 10.1007/978-3-319-33793-7_20
   Kumar A, 2012, IET SIGNAL PROCESS, V6, P617, DOI 10.1049/iet-spr.2011.0298
   Li ZY, 2016, PATTERN RECOGN, V52, P317, DOI 10.1016/j.patcog.2015.10.009
   Masi M, 2005, PHYS LETT A, V338, P217, DOI 10.1016/j.physleta.2005.01.094
   Mlakar U, 2016, EXPERT SYST APPL, V65, P221, DOI 10.1016/j.eswa.2016.08.046
   Nie FY, 2017, SIGNAL PROCESS, V134, P23, DOI 10.1016/j.sigpro.2016.11.004
   Oliva D, 2017, EXPERT SYST APPL, V79, P164, DOI 10.1016/j.eswa.2017.02.042
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pare S, 2019, ADV INTELL SYST COMP, V748, P71, DOI 10.1007/978-981-13-0923-6_7
   Pare S, 2018, COMPUT ELECTR ENG, V70, P476, DOI 10.1016/j.compeleceng.2017.08.008
   Pare S, 2017, EXPERT SYST APPL, V87, P335, DOI 10.1016/j.eswa.2017.06.021
   Pare S, 2016, APPL SOFT COMPUT, V47, P76, DOI 10.1016/j.asoc.2016.05.040
   Pare S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P730, DOI 10.1109/ICDSP.2015.7251972
   Sahoo P, 1997, PATTERN RECOGN, V30, P71, DOI 10.1016/S0031-3203(96)00065-9
   Sahoo PK, 2006, PATTERN RECOGN LETT, V27, P520, DOI 10.1016/j.patrec.2005.09.017
   Sahoo PK, 2004, PATTERN RECOGN, V37, P1149, DOI 10.1016/j.patcog.2003.10.008
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Sarkar JP, 2016, APPL SOFT COMPUT, V46, P527, DOI 10.1016/j.asoc.2016.01.040
   Sarkar S, 2016, EXPERT SYST APPL, V50, P120, DOI 10.1016/j.eswa.2015.11.016
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Soni V, 2013, IET SIGNAL PROCESS, V7, P720, DOI 10.1049/iet-spr.2013.0139
   Suresh S, 2016, EXPERT SYST APPL, V58, P184, DOI 10.1016/j.eswa.2016.03.032
   TSAI WH, 1985, COMPUT VISION GRAPH, V29, P377, DOI 10.1016/0734-189X(85)90133-1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhao XL, 2016, APPL SOFT COMPUT, V48, P151, DOI 10.1016/j.asoc.2016.07.016
NR 47
TC 44
Z9 44
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 17197
EP 17238
DI 10.1007/s11042-018-7034-x
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500065
DA 2024-07-18
ER

PT J
AU Ziólko, M
   Kacprzak, S
AF Ziolko, Mariusz
   Kacprzak, Stanislaw
TI Language ranking based on frequency varieties of phones
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech technology; Frequency analysis; Language ranking
ID SPEECH SEGMENTATION
AB Phones for 239 non-annotated languages were selected by automatic segmentation based on changes of energy in the time-frequency representation of speech signals. Phone boundaries were set at location of relatively major changes in energy distribution between seven frequency bands. A vector of average energies calculated for eleven frequency bands was chosen as the representation of a single phone. We focus our research on an unsupervised comparison of phone distribution in 239 languages. Using the hierarchical clustering method, the relationship between the number of clusters and Ward's distance was determined. A mathematical model is proposed to describe this dependency. Its four parameters are determined for each language individually to model the relationship between the number of clusters and the frequency diversity of phones contained in clusters. We used these relationships to compare languages and to create their ranking based on the size of phone varieties in the frequency domain.
C1 [Ziolko, Mariusz; Kacprzak, Stanislaw] AGH Univ Sci & Technol, Fac Comp Sci Elect & Telecommun, Al Mickiewicza 30, PL-30059 Krakow, Poland.
C3 AGH University of Krakow
RP Ziólko, M (corresponding author), AGH Univ Sci & Technol, Fac Comp Sci Elect & Telecommun, Al Mickiewicza 30, PL-30059 Krakow, Poland.
EM ziolko@agh.edu.pl; skacprza@agh.edu.pl
RI Kacprzak, Stanisław/K-3405-2013
OI Kacprzak, Stanisław/0000-0002-8717-9327; Ziolko,
   Mariusz/0000-0001-6260-7850
FU National Science Centre [DEC-2011/03/B/ST7/00442]
FX The project was funded by the National Science Centre granted on the
   basis of the decision DEC-2011/03/B/ST7/00442.
CR Amirgaliyev Y, 2017, OPEN COMPUT SCI, V7, P1, DOI 10.1515/comp-2017-0001
   Atkinson QD, 2011, SCIENCE, V332, P346, DOI 10.1126/science.1199295
   Castaldo F, 2008, ISCA
   EASTERDAY SHELECE., 2011, ICPHC 17, P623
   Fukada T, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1077, DOI 10.1109/ICSLP.1996.607792
   Goldberger Jacob., 2004, Advances in Neural Information Processing Systems, P505
   Hoang DT, 2015, J ACOUST SOC AM, V137, P797, DOI 10.1121/1.4906147
   Holman EW, 1996, J CLASSIF, V13, P27, DOI 10.1007/BF01202581
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Jansen A., 2011, Proc. INTERSPEECH, P1693
   Kacprzak S, 2016, SIG P ALGO ARCH ARR, P310, DOI 10.1109/SPA.2016.7763633
   Laleye FAA, 2017, J SIGNAL PROCESS SYS, V88, P439, DOI 10.1007/s11265-016-1183-9
   Ma Bin, 2005, 9 EUR C SPEECH COMM
   Martínez-González B, 2017, EXPERT SYST APPL, V73, P27, DOI 10.1016/j.eswa.2016.12.005
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Rybka K, 2015, STATE OF THE ART DEV
   Scharenborg O, 2010, J ACOUST SOC AM, V127, P1084, DOI 10.1121/1.3277194
   Schüppert A, 2016, SPEECH COMMUN, V79, P47, DOI 10.1016/j.specom.2016.02.001
   Singh R, 2002, IEEE T SPEECH AUDI P, V10, P89, DOI 10.1109/89.985546
   TAN BT, 1994, P SOC PHOTO-OPT INS, V2242, P750, DOI 10.1117/12.170075
   Wang CC, 2012, SCIENCE, V335, DOI 10.1126/science.1207846
   WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967
   Ziólko M, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2234
NR 23
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15575
EP 15588
DI 10.1007/s11042-018-6933-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700062
OA hybrid
DA 2024-07-18
ER

PT J
AU Al-Zubi, M
   Abu-Shareha, AA
AF Al-Zubi, Moath
   Abu-Shareha, Ahmad Adel
TI Efficient signcryption scheme based on El-Gamal and Schnorr
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Signcryption; El-Gamal; Schnorr
ID PRIVACY
AB The recent advances in the Internet of Things (IoT) and wireless network applications required lightweight encryption and authentication algorithms in order to secure the communications among the distributed resources. While various mechanisms have been proposed in the cryptography, signcryption has been recognized as a suitable technique for such applications. Both functions of digital signature and public key encryption with a very low processing cost is implemented using a single logical step in the signcryption mechanism. The recent development in the signcryption concentrates on addressing extra security notions such as forward security and public verifiability scarifying some of the processing costs. The aim of this paper is to develop a new signcryption mechanism based on discrete logarithm and Schnorr algorithm to further reduce the signcryption complexity and enhance the confidentially for IoT and wireless network applications that do not required forward security and public verifiability, which increase the time significantly. Accordingly, the proposed mechanism implements minimal number of operations for session key generation, hashing and encryption. In comparison with the existing signcryption mechanism, the proposed method reduces the computational cost by reducing the number of operations while preserving the communication overhead as it is. In parallel environment, the proposed mechanism reduces the time significantly. In terms of the security concerns the confidentiality, integrity, unforgeability and verifiability were proven to be satisfied by the proposed mechanism as similar to the original signcryption.
C1 [Al-Zubi, Moath] Al Balqa Appl Univ, Fac Informat Technol, Dept Comp Sci, Amman, Jordan.
   [Abu-Shareha, Ahmad Adel] Middle East Univ, Fac Informat Technol, Dept Comp Sci, Amman, Jordan.
C3 Al-Balqa Applied University; Middle East University
RP Abu-Shareha, AA (corresponding author), Middle East Univ, Fac Informat Technol, Dept Comp Sci, Amman, Jordan.
EM moathalzubi@aau.edu.jo; aabushareha@meu.edu.jo
RI Abu-Shareha, Ahmad/S-8633-2016
OI Abu-Shareha, Ahmad/0000-0002-2374-3152
CR Abu-Shareha AA, 2012, MULTIMED TOOLS APPL, V61, P69, DOI 10.1007/s11042-010-0707-8
   Abualhaj MM, 2016, KSII T INTERNET INF, V10, P3728, DOI 10.3837/tiis.2016.08.017
   Agoyi M., 2010, Proceedings 2010 6th International Conference on Wireless and Mobile Communications (ICWMC 2010), P448, DOI 10.1109/ICWMC.2010.87
   Baek J, 2007, J CRYPTOL, V20, P203, DOI 10.1007/s00145-007-0211-0
   Bao F., 1998, Public Key Cryptography. First International Workshop on Practice and Theory in Public Key Cryptography, PKC'98. Proceedings, P55, DOI 10.1007/BFb0054014
   Boneh D, 2003, SIAM J COMPUT, V32, P586, DOI 10.1137/S0097539701398521
   Ch SA, 2015, MULTIMED TOOLS APPL, V74, P1711, DOI 10.1007/s11042-014-2283-9
   Dent AW, 2005, LECT NOTES COMPUT SC, V3574, P253
   Galindo D, 2009, LECT NOTES COMPUT SC, V5580, P135, DOI 10.1007/978-3-642-02384-2_9
   Han YL, 2006, LECT NOTES COMPUT SC, V4159, P956
   Hwang RJ, 2005, APPL MATH COMPUT, V167, P870, DOI 10.1016/j.amc.2004.06.124
   Jung HY, 2001, P WORLD C INF SEC AP, P4303
   Lai JC, 2017, INT J INF SECUR, V16, P299, DOI 10.1007/s10207-016-0320-6
   Li X, 2015, INT J COMMUN SYST, V28, P374, DOI 10.1002/dac.2676
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Libert B, 2004, LECT NOTES COMPUT SC, V2947, P187
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Malone-Lee J, 2003, LECT NOTES COMPUT SC, V2612, P211
   Potlapally NR, 2003, ISLPED'03: PROCEEDINGS OF THE 2003 INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND DESIGN, P30, DOI 10.1145/871506.871518
   Rostampour S, 2018, J SUPERCOMPUT, V74, P71, DOI 10.1007/s11227-017-2106-7
   Saraswat V, 2017, J MATH CRYPTOL, V11, P63, DOI 10.1515/jmc-2015-0014
   Savu Laura, 2012, J SOFTWARE ENG APPL, V5, P102, DOI DOI 10.4236/jsea.2012.52016
   Schneier B., 1996, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   Seo SH, 2016, TRANS DATA PRIV, V9, P101
   Steinfeld R, 2001, LECT NOTES COMPUT SC, V1975, P308
   Tariq MuhammadAdnan., 2010, Proceedings of the Fourth ACM International Conference on Distributed Event-Based Systems, DEBS'10, P38, DOI [10.1145/1827418.1827425., DOI 10.1145/1827418.1827425]
   Thota C., 2018, Exploring the convergence of big data and the internet of things, P141
   Toorani Mohsen, 2009, Journal of Applied Sciences, V9, P1025, DOI 10.3923/jas.2009.1025.1035
   Yu Y, 2007, LECT NOTES COMPUT SC, V4610, P13
   Zhang B, 2018, SECURITY COMMUNICATI, V2018, P1, DOI DOI 10.1155/2018/3159801
   Zheng Y, 1997, DIGITAL SIGNCRYPTION
   Zheng YL, 1998, LECT NOTES COMPUT SC, V1396, P291, DOI 10.1007/BFb0030430
   Zheng YL, 1998, INFORM PROCESS LETT, V68, P227, DOI 10.1016/S0020-0190(98)00167-7
NR 34
TC 5
Z9 6
U1 6
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11091
EP 11104
DI 10.1007/s11042-018-6636-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900001
DA 2024-07-18
ER

PT J
AU Bianco, S
   Buzzelli, M
   Schettini, R
AF Bianco, Simone
   Buzzelli, Marco
   Schettini, Raimondo
TI A unifying representation for pixel-precise distance estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distance estimation; Depth estimation; Perspective geometry;
   Convolutional neural network
ID DEPTH ESTIMATION; FAMILIAR SIZE; VISION
AB We propose a new representation of distance information that is independent from any specific acquisition device, based on the size of portrayed subjects. In this alternative description, each pixel of an image is associated with the size, in real life, of what it represents. Using our proposed representation, datasets acquired with different devices can be effortlessly combined to build more powerful models, and monocular distance estimation can be performed on images acquired from devices that were never used during training. To assess the advantages of the proposed representation, we used it to train a fully convolutional neural network that predicts with pixel-precision the size of different subjects depicted in the image, as a proxy for their distance. Experimental results show that our representation, allowing the combination of heterogeneous training datasets, makes it possible for the trained network to gain better results at test time.
C1 [Bianco, Simone; Buzzelli, Marco; Schettini, Raimondo] Univ Milano Bicocca, Dipartimento Informat Sistemist & Comunicaz, Viale Sarca 336, I-20126 Milan, Italy.
C3 University of Milano-Bicocca
RP Buzzelli, M (corresponding author), Univ Milano Bicocca, Dipartimento Informat Sistemist & Comunicaz, Viale Sarca 336, I-20126 Milan, Italy.
EM simone.bianco@disco.unimib.it; marco.buzzelli@disco.unimib.it;
   schettini@disco.unimib.it
RI Buzzelli, Marco/AAL-1194-2021; Bianco, Simone/T-1224-2019
OI Buzzelli, Marco/0000-0003-1138-3345; Bianco, Simone/0000-0002-7070-1545
FU NVIDIA Corporation
FX We gratefully acknowledge the support of NVIDIA Corporation with the
   donation of the Titan X Pascal GPU used for this research.
CR [Anonymous], P 2003 I E COMP SOC
   [Anonymous], 2016, CoRR
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2018, J ELECT IMAGING
   [Anonymous], 2011, PASCAL VISUAL OBJECT
   [Anonymous], 2010, CULT SOC NETW SITES
   [Anonymous], METHODS MEASURING AS
   Battiato S, 2018, COMPUT IND, V98, P208, DOI 10.1016/j.compind.2018.02.014
   Bianco S, 2017, NEUROCOMPUTING, V245, P23, DOI 10.1016/j.neucom.2017.03.051
   Burgos-Artizzu XP, 2014, LECT NOTES COMPUT SC, V8689, P313, DOI 10.1007/978-3-319-10590-1_21
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dong XC, 2014, INT J INNOV COMPUT I, V10, P659
   Eigen D, 2014, ADV NEUR IN, V27
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   ENS J, 1993, IEEE T PATTERN ANAL, V15, P97, DOI 10.1109/34.192482
   Flores A, 2013, LECT NOTES COMPUT SC, V8034, P513, DOI 10.1007/978-3-642-41939-3_50
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   HARKNESS L, 1977, NATURE, V267, P346, DOI 10.1038/267346a0
   Hirschmüller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56
   Hochberg CB, 1952, J PSYCHOL, V34, P107, DOI 10.1080/00223980.1952.9916110
   Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5
   Hong DH, 2014, COMPUT MED IMAG GRAP, V38, P22, DOI 10.1016/j.compmedimag.2013.10.005
   Howard Ian P, 1995, Binocular Vision and Stereopsis
   Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19
   Li B, 2015, PROC CVPR IEEE, P1119, DOI 10.1109/CVPR.2015.7298715
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   MAROTTA JJ, 1995, EXP BRAIN RES, V104, P107
   Neven D, 2017, FAST SCENE UNDERSTAN
   Prados E, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P375, DOI 10.1007/0-387-28831-7_23
   Ranftl R, 2016, PROC CVPR IEEE, P4058, DOI 10.1109/CVPR.2016.440
   Rodrigues D.G., 2013, CHI '13 Extended Abstracts on Human Factors in Computing Systems, P1197, DOI DOI 10.1145/2468356.2468570
   Ros G., 2016, Proceedings of the IEEE conference on computer vision and pattern recognition, P3234, DOI DOI 10.1109/CVPR.2016.352
   Simonyan K., 2014, 14091556 ARXIV
   Spinello L, 2011, IEEE INT C INT ROBOT, P3838, DOI 10.1109/IROS.2011.6048835
   SUBBARAO M, 1994, INT J COMPUT VISION, V13, P271, DOI 10.1007/BF02028349
   Torralba A, 2002, IEEE T PATTERN ANAL, V24, P1226, DOI 10.1109/TPAMI.2002.1033214
   Uhrig J, 2016, LECT NOTES COMPUT SC, V9796, P14, DOI 10.1007/978-3-319-45886-1_2
   Wedel A, 2006, LECT NOTES COMPUT SC, V4174, P475
   YONAS A, 1982, CHILD DEV, V53, P1285, DOI 10.2307/1129018
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 40
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13767
EP 13786
DI 10.1007/s11042-018-6568-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900052
DA 2024-07-18
ER

PT J
AU Walczak, K
   Flotynski, J
AF Walczak, Krzysztof
   Flotynski, Jakub
TI Inference-based creation of synthetic 3D content with ontologies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D web; Virtual and augmented reality; Semantic 3D; Ontologies; Semantic
   web
ID SEMANTIC WEB
AB Creation of synthetic 3D content is typically a complex task, covering different geometrical, structural, spatial and presentational elements. The available approaches enable 3D content creation by programming or visual modeling of its elements. This demands expertise in computer science from content authors, limits the possibilities of using domain knowledge, and requires to determine all content details within the content creation process. In this paper, we propose a new method of 3D content creation, which is based on ontologies. Ontologies are the foundation of the semantic web, enabling the use of knowledge in various domains. In the proposed method, the use of ontologies facilitates 3D content creation by domain experts without skills in programming and computer graphics. In addition, due to the use of ontologies, the method enables automated reasoning, liberating the authors from determining many elements of the created content, which can be inferred by the content generation algorithm on the basis of explicitly specified content elements. The method has been implemented and evaluated. It simplifies 3D content creation in comparison to the available approaches by reducing the number of activities that must be completed by the content authors. Hence, the proposed method can increase the use of 3D content in different application domains.
C1 [Walczak, Krzysztof; Flotynski, Jakub] Poznan Univ Econ & Business, Dept Informat Technol, Niepodleglosci 10, PL-61875 Poznan, Poland.
C3 Poznan University of Economics & Business
RP Walczak, K (corresponding author), Poznan Univ Econ & Business, Dept Informat Technol, Niepodleglosci 10, PL-61875 Poznan, Poland.
EM walczak@kti.ue.poznan.pl; flotynski@kti.ue.poznan.pl
RI Flotyński, Jakub/IWU-8229-2023; Walczak, Krzysztof/AAF-9685-2021
OI Flotyński, Jakub/0000-0001-5104-2022; Walczak,
   Krzysztof/0000-0001-8170-7910
CR Albrecht S., 2011, P ICRA 2011 WORKSH S, V4, P8
   [Anonymous], 2017, W3C VRML VIRTUAL REA
   [Anonymous], 2017, JAVA3D
   [Anonymous], 2018, RDF 1 1 TURTLE
   [Anonymous], 2018, 3DS MAX
   [Anonymous], ARXIV161101872
   [Anonymous], 2017, DIRECT3D 11 1 FEAT
   [Anonymous], 2018, MAYA
   [Anonymous], OWL WEB ONTOLOGY LAN
   [Anonymous], COMP LAB SAARL U IVC
   Attene M, 2007, LECT NOTES COMPUT SC, V4816, P126
   Attene M, 2009, COMPUT AIDED DESIGN, V41, P756, DOI 10.1016/j.cad.2009.01.003
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Bille W, 2005, P 11 INT C VIRT SYST, P17
   Blender, 2017, BLEND AP DOC
   Chaudhuri Siddhartha, 2013, P 26 ANN ACM S USER, P193, DOI [DOI 10.1145/2501988.2502008, 10.1145/2501988.2502008]
   De Floriani L, 2007, LECT NOTES COMPUT SC, V4816, P226
   De Troyer Olga, 2007, Virtual Reality, V11, P89, DOI 10.1007/s10055-006-0058-y
   De Troyer O., 2007, Tutorials, posters, panels and industrial contributions at the 26th international conference on Conceptual modeling-Volume 83, V83, P3
   Drap P, 2017, IN SY AP IN WE HC, V10577, P3, DOI 10.1007/978-3-319-70407-4_1
   Fischbach M, 2011, P IEEE VIRT REAL ANN, P255, DOI 10.1109/VR.2011.5759495
   Flotynski J, 2017, WEB3D 2017, DOI 10.1145/3055624.3075959
   Flotynski J, 2017, LECT NOTES COMPUT SC, V10700, P3, DOI 10.1007/978-3-319-72323-5_1
   Flotynski J, 2017, COMPUT GRAPH FORUM, V36, P329, DOI 10.1111/cgf.13083
   Flotynski J, 2016, GRAPH MODELS, V88, P23, DOI 10.1016/j.gmod.2016.07.001
   Flotynski J, 2015, VISUAL COMPUT, V31, P1287, DOI 10.1007/s00371-014-1011-9
   Flotynski J, 2014, COMPUT SCI INF SYST, V11, P1555, DOI 10.2298/CSIS131218073F
   Flotyski J, 2013, P 5 JOINT VIRT REAL
   Gutiérrez M, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P277, DOI 10.1109/MMMC.2005.65
   Gutierrez M, 2005, SEMANTIC VIRTUAL ENV
   Kalogerakis E, 2006, P IEEE VIRT REAL ANN, P43, DOI 10.1109/VR.2006.41
   Kapahnke P, 2010, LECT NOTES COMPUT SC, V6497, P161, DOI 10.1007/978-3-642-17749-1_11
   KLEINERMANN F, 2005, P 2 INTUITION INT WO, P5
   Latoschik ME, 2011, P IEEE VR 2011
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   PAPALEO L, 2007, P 10 INT C COMP GRAP
   Pellens B, 2005, LECT NOTES COMPUT SC, V3762, P1215
   Perez-Gallardo Y, 2017, INTEL SYST REF LIBR, V120, P137, DOI 10.1007/978-3-319-51905-0_7
   ROBBIANO F, 2007, 2013 INT CONF CYBERW, V427, P436, DOI DOI 10.1109/CW.2007.8
   Sikos LF, 2017, P 22 INT C 3D WEB TE, P19
   Trellet M, 2018, J INTEGR BIOINFORMAT, V15, DOI 10.1515/jib-2018-0004
   Trellet M, 2016, 2016 WORKSHOP ON IMMERSIVE ANALYTICS (IA), P48, DOI 10.1109/IMMERSIVE.2016.7932383
   VANGOOL L, 2007, 3DIM, V3, P118
   W3C, 2004, SWRL
   W3C, 2018, RDFS
   W3C, 2018, OWL
   W3C, 2018, GETT START X3D
   W3C, 2018, SPARQL QUERY LANGUAG
   W3C, 2018, RDF
   Wiebusch Dennis, 2012, 2012 5th Workshop on Software Engineering and Architectures for Realtime Interactive Systems, P43, DOI 10.1109/SEARIS.2012.6231168
   Zahariadis T, 2008, FUTURE 3D MEDIA INTE, P13
NR 52
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12607
EP 12638
DI 10.1007/s11042-018-6788-5
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900068
OA hybrid
DA 2024-07-18
ER

PT J
AU Xia, LK
   Yang, J
   Han, T
   Xu, HM
   Yang, Q
   Zhao, YT
   Wang, YT
AF Xia, Likun
   Yang, Jian
   Han, Tao
   Xu, Huiming
   Yang, Qi
   Zhao, Yitian
   Wang, Yongtian
TI A mobilized automatic human body measure system using neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anthropometry; Neural network; Mobile device; Silhouette detection;
   Feature point extraction; Segmentation
AB Mobilized automatic human body measurement systems possess high mobility, easy operation, and reasonable accuracy. However, existing systems focus on accuracy and robustness rather than mobility and convenience. To overcome this shortcoming, this work presents a mobilized automatic human body measure system using a neural network (MaHuMS-NN) to promote general measurement results by supervised learning. MaHuMS-NN based on general regression NN (GRNN) selects an image, performs image processing, segments the image, and detects a silhouette for feature point extraction in the silhouette. The system measures feature size. The significant contributions of this work are as follows. First, MaHuMS-NN is the first intelligent system for anthropometry in the Android platform. Second, unlike existing systems, MaHuMS-NN can intelligently adjust when the model is optimized for prediction and perform self-error correction based on individual characteristics. Experimental results indicate that compared with existing systems, MaHuMS-NN demonstrates better performance with an accuracy of less than 0.03m.
C1 [Xia, Likun] Capital Normal Univ, Coll Informat Engn, Beijing 100048, Peoples R China.
   [Xia, Likun] Beijing Adv Innovat Ctr Imaging Technol, Beijing 100048, Peoples R China.
   [Yang, Jian; Han, Tao; Xu, Huiming; Yang, Qi; Wang, Yongtian] Beijing Inst Technol, Sch Opt & Photon, Beijing Engn Res Ctr Mixed Real & Adv Display, Beijing 100081, Peoples R China.
   [Zhao, Yitian] Chinese Acad Sci, Ningbo Inst Ind Technol, Ningbo 315201, Zhejiang, Peoples R China.
C3 Capital Normal University; Beijing Institute of Technology; Chinese
   Academy of Sciences
RP Yang, J (corresponding author), Beijing Inst Technol, Sch Opt & Photon, Beijing Engn Res Ctr Mixed Real & Adv Display, Beijing 100081, Peoples R China.
EM jyang@bit.edu.cn
RI Zhao, Yitian/AAM-4907-2021
OI Zhao, Yitian/0000-0002-0962-8377; xia, likun/0000-0002-9593-2737
FU National Natural Science Foundation of China [61572076]; Beijing
   Advanced Innovation Center for Imaging Technology
FX This work is supported by the National Natural Science Foundation of
   China (No. 61572076), Beijing Advanced Innovation Center for Imaging
   Technology.
CR Adikari A, 2017, COMPUT ENG, V19, P80, DOI DOI 10.9790/0661-1903028085
   [Anonymous], 161602008 GBT
   [Anonymous], INT J AUTOM COMPUT
   [Anonymous], APPL RES COMPUT
   [Anonymous], J SE U NAT SCI ED
   [Anonymous], 2000, NEURAL NETWORK RF MI
   [Anonymous], CONTR AUT SYST ENG C
   [Anonymous], APPL NEURAL NETWORKS
   [Anonymous], INT J DIGIT CONTENT
   [Anonymous], ELECT IMAGING 97 INT
   [Anonymous], TAILOR MEASURE APP A
   [Anonymous], AS PAC SIGN INF PROC
   [Anonymous], DTIC DOCUMENT
   [Anonymous], P 3 AS TEXT C HONG K
   [Anonymous], DATA NORMALIZATION U
   [Anonymous], RECENT ADV 3D FULL B
   [Anonymous], 2011, COMPUTER MANAGEMENT
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Hurley JD, 1997, P SOC PHOTO-OPT INS, V3131, P212, DOI 10.1117/12.277751
   JONES PRM, 1989, ENDEAVOUR, V13, P162, DOI 10.1016/S0160-9327(89)80004-3
   Kaufmann K, 1997, IEEE CIRCUITS DEVICE, V13, P12, DOI 10.1109/101.589258
   Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1137
   Lecun Y., 2015, NAT METHODS, V521, P436, DOI DOI 10.1038/nmeth.3707
   Li JY, 2017, J SOIL SEDIMENT, V17, P1715, DOI 10.1007/s11368-016-1620-1
   MEADOWS DM, 1970, APPL OPTICS, V9, P942, DOI 10.1364/AO.9.000942
   Perez JM., 2006, P IEEE 32 ANN NE BIO, P33
   Peyer KE, 2015, PEERJ, V3, DOI 10.7717/peerj.831
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Simmons K., 2001, BODY MEASUREMENT TEC
   Tang M., 2013, P 2013 IEEE INT C CO, P1769, DOI DOI 10.1109/ICCV.2013.222
   Tong J, 2012, IEEE T VIS COMPUT GR, V18, P643, DOI 10.1109/TVCG.2012.56
   Treleaven P, 2007, COMPUTER, V40, P28, DOI 10.1109/MC.2007.225
   Uhm T, 2015, MEASUREMENT, V61, P169, DOI 10.1016/j.measurement.2014.10.044
   Weiss A, 2011, IEEE I CONF COMP VIS, P1951, DOI 10.1109/ICCV.2011.6126465
   Xu HH, 2013, SENSORS-BASEL, V13, P11362, DOI 10.3390/s130911362
   Yamauchi K, 2006, INT C PATT RECOG, P833
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Zhang XJ, 2011, ACS NANO, V5, P2013, DOI 10.1021/nn1030719
   Zhao YT, 2015, IEEE T MED IMAGING, V34, P1797, DOI 10.1109/TMI.2015.2409024
   [周平 ZHOU Ping], 2005, [光电工程, Opto-Electronic Engineering], V32, P90
NR 42
TC 4
Z9 7
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11291
EP 11311
DI 10.1007/s11042-018-6645-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900010
DA 2024-07-18
ER

PT J
AU Jiang, Y
AF Jiang, Yong
TI Wireless resource management mechanism with green communication for
   multimedia streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Resource management; Green communication; Wireless control; Multimedia
   streaming
AB In the face of massive parallel multimedia streaming and user access, multimedia servers are often in an overload state, resulting in the delay of service response and the low utilization of wireless resources, which makes it is difficult to satisfy the user experience quality. Aiming at the problems of low utilization rate of multimedia communication resources and large computing load of servers, this paper proposes a self management mechanism and architecture of wireless resources based on multimedia flow green communication. First, based on the combination of multimedia server, relay base station and user cluster, a multimedia green communication system architecture is built based on the comprehensive utilization rate of multimedia communication, and a cluster green communication control algorithm is proposed. Secondly, aiming at the dynamic service demand and asynchronous multimedia communication environment, aiming at ensuring the balance of resource allocation and accelerating the speed of resource allocation, we build a dynamic multimedia wireless resource architecture. Finally, the experimental results of statistics and analysis, from the server in different scale parallel multimedia streams under different scale delay, number of users relay network free resources proportion, user satisfaction, packet loss rate and other performance show that the proposed algorithm is effective and feasible.
C1 [Jiang, Yong] Jiangsu Union Tech Inst, Dept Informat Technol, Xuzhou, Jiangsu, Peoples R China.
RP Jiang, Y (corresponding author), Jiangsu Union Tech Inst, Dept Informat Technol, Xuzhou, Jiangsu, Peoples R China.
EM jiangyongls@sina.com
FU Jiangsu Province Qing Lan Project
FX This work is supported in part by Jiangsu Province Qing Lan Project.
CR Aliaskari M, 2017, INT S TEL, P6
   Arjomandy D, 2016, CAN J ADM SCI, V33, P108, DOI 10.1002/cjas.1380
   Castro A, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010068
   Chunlin Li, 2017, Journal of Supercomputing, V73, P5150, DOI 10.1007/s11227-017-2074-y
   Guo L, 2017, MULTIMED TOOLS APPL, V76, P16949, DOI 10.1007/s11042-016-3597-6
   Jin Yong, 2013, J INFORM COMPUTATION, V10, P2269, DOI [10.12733/jics20101772, DOI 10.12733/JICS20101772]
   Kobel C, 2017, ING DESARRO, V34, P370, DOI [10.14482/inde.34.2.7162, DOI 10.14482/INDE.34.2.7162]
   Li S, 2017, INT C MOB AD HOC SEN, P412
   López-Benítez M, 2011, IEEE T MOBILE COMPUT, V10, P1201, DOI 10.1109/TMC.2010.221
   Omheni N, 2017, TELECOMMUN SYST, V12, P1
   Sheng M, 2017, IEEE WIREL COMMUN, V24, P127, DOI 10.1109/MWC.2017.1600173
   Sivaprakash C, 2017, INDIAN J SCI TECHNOL, V10, P1, DOI DOI 10.17485/ijst/2017/v10i7/106508
   Song B, 2016, COMPUTING, V98, P119, DOI 10.1007/s00607-014-0411-z
   Yang Q, 2017, IEEE INTERNET THINGS, V4, P484, DOI 10.1109/JIOT.2017.2689659
   Yu J., 2017, WIRELESS PERS COMMUN, V95, P1
   Zhu CS, 2017, IEEE COMMUN MAG, V55, P24, DOI 10.1109/MCOM.2017.1700212
NR 16
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8699
EP 8710
DI 10.1007/s11042-018-6149-4
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800045
DA 2024-07-18
ER

PT J
AU Kallel, IK
   Almouahed, S
   Alsahwa, B
   Solaiman, B
AF Kallel, Imene Khanfir
   Almouahed, Shaban
   Alsahwa, Bassem
   Solaiman, Basel
TI The use of contextual spatial knowledge for low-quality image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Possibility modelling; Local pixel knowledge; Pixel classification
ID DISTRIBUTIONS
AB In this paper, a novel possibilistic approach for representing pixelic spatial knowledge is proposed to be used in classification; more specifically in segmentation of low quality images. This approach uses the spatial contextual information at the pixel level in order to produce a local possibility distribution. The similarity between this local possibility distribution representing the contextual pixelic information and the possibility distribution for each of the predetermined thematic classes is measured. This measure is used to assign one of these thematic classes to the pixel. In order to show the potential of the proposed possibilistic approach, synthetic and real images (Melanoma) are classified using the possibilistic similarity. The performance is compared with four relevant classic methods and one recent theory-like method (fuzzy c means). Our context-based possibilistic representation approach outperforms the other methods, in terms of classification recognition rate as well as in stability or robustness behavior when compared to those methods.
C1 [Kallel, Imene Khanfir] Univ Sfax, ENIS, CEM Lab, BP213, Sfax 3027, Tunisia.
   [Kallel, Imene Khanfir; Almouahed, Shaban; Alsahwa, Bassem; Solaiman, Basel] IMT Atlantique, ITi, Technopole Brest, Plouzane, France.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS); IMT -
   Institut Mines-Telecom; IMT Atlantique
RP Kallel, IK (corresponding author), Univ Sfax, ENIS, CEM Lab, BP213, Sfax 3027, Tunisia.; Kallel, IK (corresponding author), IMT Atlantique, ITi, Technopole Brest, Plouzane, France.
EM imen.khanfir.kallel@gmail.com
RI Kallel, Imene Khanfir/AAH-2043-2020
OI Khanfir Kallel, Imene/0000-0002-0618-5080
CR AARTS EHL, 1985, PHILIPS J RES, V40, P193
   Alsahwa B., 2013, Proceedings of the 2nd International Conference on Pattern Recognition Applications and Methods. ICPRAM 2013, P176
   Alsahwa B, 2016, IEEE T IMAGE PROCESS, V25, P3533, DOI 10.1109/TIP.2016.2574992
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], INT J INNOV RES ADV
   [Anonymous], J ROY STAT SOC B
   BALDUCCI F, 2017, LECT NOTES COMPUTER
   Bansal A, 2017, ARXIV170206506CSCV
   Diamond S, 2017, 170106487 ARXIVCSCV
   Dubois D, 1998, HDB DEFEASIBLE REASO, V1
   Eziddin W, 2012, SEGMENTATION ITERATI
   FORGY EW, 1965, BIOMETRICS, V21, P768
   GEMAN D, 1990, IEEE T PATTERN ANAL, V12, P609, DOI 10.1109/34.56204
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Hatt M, 2007, PHYS MED BIOL, V52, P3467, DOI 10.1088/0031-9155/52/12/010
   Khanfir Kallel I, 2017, 3 IEEE INT C ADV TEC
   Li BN, 2011, COMPUT BIOL MED, V41, P1, DOI 10.1016/j.compbiomed.2010.10.007
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lutton JL, 1988, SCIENCE, V129, P68
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Moiseev A, 2018, J BIOPHOTONICS, V11, DOI 10.1002/jbio.201700072
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pieczynski W., 2003, Traitement du Signal, V20, P255
   Roy P., 2014, INT J ROUGH SETS DAT, V1, P62, DOI [10.4018/ijrsda.2014070105, DOI 10.4018/IJRSDA.2014070105]
   Shafer Glenn, 1976, MATH THEORY EVIDENCE, P2
   Song J, 2017, CELL DEATH DIS, V8, DOI 10.1038/cddis.2017.491
   Taroun A., 2011, The Built Human Environment Review, V4, P155
   Vannoorenberghe P, 2003, REVUE, V3, P9
   Zhao F, 2017, SEGMENTATION BLOOD V
   Zhao WC, 2018, OPTIK, V158, P1160, DOI 10.1016/j.ijleo.2018.01.004
NR 31
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 9645
EP 9665
DI 10.1007/s11042-018-6540-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400007
DA 2024-07-18
ER

PT J
AU Rehman, A
   Naz, S
   Razzak, MI
AF Rehman, Arshia
   Naz, Saeeda
   Razzak, Muhammad Imran
TI Writer identification using machine learning approaches: a comprehensive
   review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Writer identification; Multi-script; Features extraction; Deep learning
ID HANDWRITING IDENTIFICATION; IMAGE FEATURES; TEXT; VERIFICATION;
   RECOGNITION; EXTRACTION; CODEBOOK; PATTERNS; WAVELET; SYSTEM
AB Handwriting is one of the most common types of questioned writing encountered and frequently attracts the attention in litigation. Contrary to the physiological characteristics, handwriting is a behavioral characteristic thus no two individuals with mature handwriting are exactly alike or an individual cannot produce the others writing exactly. Writing behavior and individualities are examined for similarities for both specimen and questioned document, thus, it is very efficient and effective strategy for biometrics. In this paper, we present a comprehensive review of writer identification methods and intend to provide taxonomy of dataset, feature extraction methods, as well as classification (conventional and deep learning based) for writer identification. For ease of reader, we grouped the discussion into English, Arabic, Western and Other languages from script prospective, whereas, from algorithm and methods perspective, we grouped the discussion with respect to implementation steps sequence. In the end, we highlighted the challenges and open research issues in the field of writer identification. Finally, we also suggest future direction.
C1 [Rehman, Arshia; Naz, Saeeda] Govt Girls Postgrad Coll 1, Abbottabad, Kpk, Pakistan.
   [Razzak, Muhammad Imran] Univ Technol Sydney, Adv Analyt Inst, Sydney, NSW, Australia.
C3 University of Technology Sydney
RP Naz, S (corresponding author), Govt Girls Postgrad Coll 1, Abbottabad, Kpk, Pakistan.
EM arshiar29@gmail.com; saeedanaz292@gmail.com; imran.razzak@ieee.org
RI Razzak, Imran/AEW-5139-2022
OI Razzak, Imran/0000-0002-3930-6600
CR Abdelhaleem A, 2017, 2017 1ST INTERNATIONAL WORKSHOP ON ARABIC SCRIPT ANALYSIS AND RECOGNITION (ASAR), P64, DOI 10.1109/ASAR.2017.8067761
   Abdi MN, 2015, PATTERN RECOGN
   Abdi MN, 2009, 2009 24TH INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, P595
   Ahmed A.A., 2017, KJAR, V2, P178, DOI DOI 10.24017/SCIENCE.2017.3.64
   Ahmed AA, 2014, J THEORETICAL APPL I
   Al Maadeed S, 2012, INT CONF FRONT HAND, P746, DOI 10.1109/ICFHR.2012.256
   Al-Dmour A, 2007, J EXP THEOR ARTIF IN, V19, P307, DOI 10.1080/09528130701228800
   Al-Ma'adeed S, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P485, DOI 10.1109/IWFHR.2002.1030957
   Al-Ma'adeed S, 2008, I C COMP SYST APPLIC, P582, DOI 10.1109/AICCSA.2008.4493590
   Al-Maadeed S, 2016, PATTERN ANAL APPL, V19, P699, DOI 10.1007/s10044-014-0438-y
   Alamri H, 2008, P 11 INT C FRONT HAN, P664
   Amaral AMM, 2012, P INT C IM PROC COMP, P1
   Amaricai A, 2013, 2013 NORCHIP, DOI 10.1109/NORCHIP.2013.6702028
   Amend Karen., 1980, Handwriting Analysis: The Complete Basic Book
   [Anonymous], 2008, P 11 INT C FRONT HAN
   [Anonymous], ARXIV170803361
   [Anonymous], 2012, BMVC
   [Anonymous], 2017, P 5 IIAE I IND APPL
   ARAZI B, 1983, IEEE T SYST MAN CYB, V13, P635, DOI 10.1109/TSMC.1983.6313153
   ARAZI B, 1977, IEEE T SYST MAN CYB, V7, P878
   Asi A, 2017, INT J DOC ANAL RECOG, V20, P173, DOI 10.1007/s10032-017-0289-3
   Awaida S, 2011, WRITER IDENTIFICATIO
   Awaida S. M., 2012, ED RES REV, P4
   Awaida SM, 2013, CYBERNET SYST, V44, P57, DOI 10.1080/01969722.2012.732802
   Baghshah MSoleymani., 2006, 2 INT C INF COMM TEC, V1, P1878
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bensefia A, 2005, PATTERN RECOGN LETT, V26, P2080, DOI 10.1016/j.patrec.2005.03.024
   Bensefia A., 2005, Electronic Letters on Computer Vision and Image Analysis, V5, P72, DOI DOI 10.5565/REV/ELCVIA.97
   Bensefia A, 2003, 3 INT WORKSH PATT RE, P56
   Bertolini D, 2016, INT C PATT RECOG, P3025, DOI 10.1109/ICPR.2016.7900098
   bin Abdl Khaled Mohammed, 2009, 2009 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2009), P459, DOI 10.1109/ICSIPA.2009.5478698
   Bisquerra AF, 2009, THESIS
   Blankers V, 2007, P 19 BELG DUTCH C AR, P17
   Bradford R.R., 1992, INTRO HANDWRITING EX
   Brink A, 2008, INT C PATT RECOG, P2519
   Bulacu M, 2005, PROC INT CONF DOC, P1275, DOI 10.1109/ICDAR.2005.4
   Bulacu M, 2003, LECT NOTES COMPUT SC, V2756, P460
   BULACU M, 2006, 10 INT WORKSH FRONT
   Bulacu M., 2003, WRITER, V1, P1
   Bulacu M. L., 2007, THESIS
   Bulacu M, 2007, PROC INT CONF DOC, P769
   Bulacu M, 2007, IEEE T PATTERN ANAL, V29, P701, DOI 10.1109/TPAMI.2007.1009
   Bulacu M, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P279, DOI 10.1109/ICIAP.2007.4362792
   Cha SH, 2000, FIFTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P42, DOI 10.1109/WACV.2000.895401
   Chahi A, 2018, EXPERT SYST APPL, V93, P1, DOI 10.1016/j.eswa.2017.10.010
   Chanda S., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P369, DOI 10.1109/DAS.2012.86
   Chanda Sukalpa, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2005, DOI 10.1109/ICPR.2010.494
   CHAPRAN J, 2006, P 10 INT WORKSH FRON, P505
   Chapran J, 2006, INT J PATTERN RECOGN, V20, P483, DOI 10.1142/S0218001406004831
   Chaudhry R, 2004, FORENSIC SCI INT, V141, P49, DOI 10.1016/j.forsciint.2003.11.033
   Christlein V., 2017, ARXIV170509369
   Christlein V, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P169, DOI 10.1109/DAS.2018.9
   Christlein V, 2017, PATTERN RECOGN, V63, P258, DOI 10.1016/j.patcog.2016.10.005
   Christlein V, 2015, LECT NOTES COMPUT SC, V9358, P540, DOI 10.1007/978-3-319-24947-6_45
   Christlein V, 2014, IEEE WINT CONF APPL, P998, DOI 10.1109/WACV.2014.6835995
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Djeddi C, 2016, INT CONF FRONT HAND, P602, DOI [10.1109/ICFHR.2016.0115, 10.1109/ICFHR.2016.117]
   Djeddi C, 2015, PROC INT CONF DOC, P1191, DOI 10.1109/ICDAR.2015.7333949
   Durou A, 2017, INFORM PROCESSING MA
   Duvoisin R., 2001, Parkinson's disease: a guide for patient and family
   Eaton HD, 1938, CALIFORNIA W MED, V61
   El Abed H, 2007, SIGN PROC ITS APPL I, P14
   El Abed H, 2011, INT J DOC ANAL RECOG, P313
   El-Sherif Ezzat Ali, 2007, Proceedings of the 2007 International Conference on Artificial Intelligence and Pattern Recognition (AIPR-07), P237
   Fecker D, 2014, INT C PATT RECOG, P3050, DOI 10.1109/ICPR.2014.526
   Fiel S, 2010, DOC AN SYST DAS 10 I, P145
   Fiel S, 2015, LECT NOTES COMPUT SC, V9257, P26, DOI 10.1007/978-3-319-23117-4_3
   Fiel S, 2013, PROC INT CONF DOC, P545, DOI 10.1109/ICDAR.2013.114
   Fornes A., 2012, P 8 IAPR INT WORKSHO, P27
   Fornes A, 2012, INT J DOC ANAL RECOG, P243
   Gargouri M, 2013, PROC INT CONF DOC, P428, DOI 10.1109/ICDAR.2013.93
   Garz A., 2016, ELECT IMAGING, V17, P1
   Geng YY, 2017, LECT NOTES COMPUT SC, V10614, P539, DOI 10.1007/978-3-319-68612-7_61
   Ghiasi G, 2013, IMAGE VISION COMPUT, V31, P379, DOI 10.1016/j.imavis.2013.03.002
   Gibbons M, 2005, LECT NOTES COMPUT SC, V3546, P823
   Grosicki E., 2008, 11 INT C FRONT HANDW, P16
   Hangai S, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P489, DOI 10.1109/ICME.2000.869645
   Hannad Y, 2016, EXPERT SYSTEMS APPL, P1422
   Hannad Y, 2016, EXPERT SYST APPL, V47, P14, DOI 10.1016/j.eswa.2015.11.002
   Hannad Y, 2015, LECT NOTES COMPUT SC, V9117, P237, DOI 10.1007/978-3-319-19390-8_27
   HASSAINE A, 2013, DOCUMENT ANALYSIS AN, V12, P1417, DOI DOI 10.1109/ICDAR.2013.286
   Hassaïne A, 2012, LECT NOTES COMPUT SC, V7667, P584, DOI 10.1007/978-3-642-34500-5_69
   He S, 2015, PATTERN RECOGN
   He S, 2017, PATTERN RECOGN, V63, P451, DOI 10.1016/j.patcog.2016.09.044
   He ZY, 2008, PATTERN RECOGN, V41, P1295, DOI 10.1016/j.patcog.2007.08.017
   He ZY, 2010, INTEGR COMPUT-AID E, V17, P157, DOI 10.3233/ICA-2010-0338
   He ZY, 2005, IEEE SYS MAN CYBERN, P364
   He ZY, 2005, PROC INT CONF DOC, P242
   He ZY, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3488
   Helli B, 2008, SIGN PROC INF TECHN
   Helli B, 2008, LECT NOTES COMPUT SC, V5112, P579, DOI 10.1007/978-3-540-69812-8_57
   Helli B, 2009, IEICE ELECTRON EXPR, V6, P623, DOI 10.1587/elex.6.623
   Hertel C, 2003, LECT NOTES COMPUT SC, V2688, P679
   Hu Y, 2014, IM PROC ICIP IEEE IN
   Idicula SM, 2011, SURVEY WRITER IDENTI, P15
   Imdad A, 2007, PROC INT CONF DOC, P839
   Jain R, 2011, PROC INT CONF DOC, P769, DOI 10.1109/ICDAR.2011.159
   Jin WF, 2005, LECT NOTES COMPUT SC, V3781, P197
   Kamal Parves, 2014, Journal of Computing Science and Engineering, V8, P11, DOI 10.5626/JCSE.2014.8.1.11
   Kameya H, 2003, PROC INT CONF DOC, P985
   Khalid Shehzad, 2015, 2015 International Conference on Computer, Communications and Control Technology (I4CT), P54, DOI 10.1109/I4CT.2015.7219536
   Khalifa E, 2015, PATTERN RECOGN LETT, V59, P18, DOI 10.1016/j.patrec.2015.03.004
   Khan FA, 2017, EXPERT SYST APPL, V71, P404, DOI 10.1016/j.eswa.2016.11.012
   Kharma N., 1999, Engineering Solutions for the Next Millennium. 1999 IEEE Canadian Conference on Electrical and Computer Engineering (Cat. No.99TH8411), P766, DOI 10.1109/CCECE.1999.808042
   Kleber F, 2013, PROC INT CONF DOC, P560, DOI 10.1109/ICDAR.2013.117
   Kozinets B, 1967, TECH REP
   Kumar M, 2014, NATL ACAD SCI LETT, V37, P567, DOI 10.1007/s40009-014-0280-1
   Kumar R, 2017, INT J SCI RES SCI EN
   Kumar R, 2014, PATTERN RECOGN LETT, V35, P105, DOI 10.1016/j.patrec.2013.07.001
   Leedham G, 2003, PROC INT CONF DOC, P413
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Märgner V, 2007, PROC INT CONF DOC, P1274
   Margner V, 2011, PROC INT CONF DOC, P1444, DOI 10.1109/ICDAR.2011.287
   Mahmoud SA, 2014, PATTERN RECOGN, V47, P1096, DOI 10.1016/j.patcog.2013.08.009
   Märgner V, 2005, PROC INT CONF DOC, P70, DOI 10.1109/ICDAR.2005.52
   Marti U.-V., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P705, DOI 10.1109/ICDAR.1999.791885
   Marti UV, 2001, PROC INT CONF DOC, P101, DOI 10.1109/ICDAR.2001.953763
   Miller JJ, 2017, J FORENSIC SCI, V62, P722, DOI 10.1111/1556-4029.13345
   MNISTWebsite, 2018, MNIST DATABASE HANDW
   Moghaddam ME, 2009, IM SIGN PROC CIS 09, P14
   Nakamura Y, 2005, PROC INT CONF DOC, P620, DOI 10.1109/ICDAR.2005.141
   Namboodiri A., 2006, P INT WORKSH FRONT H
   Nejad FS, 2007, PROC INT CONF DOC, P829
   Newell A. J., 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P191, DOI 10.1109/DICTA.2011.39
   Newell AJ, 2014, PATTERN RECOGN, V47, P2255, DOI 10.1016/j.patcog.2013.11.029
   Pandey Pallavi, 2018, Proceedings of First International Conference on Smart System, Innovations and Computing. SSIC 2017. Smart Innovation, Systems and Technologies (SIST 79), P129, DOI 10.1007/978-981-10-5828-8_13
   Pechwitz M, 2002, P CIFED
   Pervouchine V, 2007, PATTERN RECOGN, V40, P1004, DOI 10.1016/j.patcog.2006.08.008
   PLAMONDON R, 1989, PATTERN RECOGN, V22, P107, DOI 10.1016/0031-3203(89)90059-9
   Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821
   Rafiee Ali, 2007, 2007 Sixth Mexican International Conference on Artificial Intelligence, Special Session, MICAI, P193, DOI 10.1109/MICAI.2007.37
   Ram SS, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND ENGINEERING, PROCEEDINGS, P728, DOI 10.1109/ICIME.2009.71
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Said H, 1998, BMVC, P110
   Said HES, 2000, PATTERN RECOGN, V33, P149, DOI 10.1016/S0031-3203(99)00006-0
   Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347
   Sakshi, 2018, LECT NOTE DATA ENG, V9, P125, DOI 10.1007/978-981-10-6319-0_11
   Sas J, 2006, LECT NOTES COMPUT SC, V4029, P682, DOI 10.1007/11785231_71
   Schlapbach A, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P167, DOI 10.1109/IWFHR.2004.107
   Schlapbach A, 2005, PROC INT CONF DOC, P131, DOI 10.1109/ICDAR.2005.139
   Schlapbach A, 2004, INT C PATT RECOG, P654, DOI 10.1109/ICPR.2004.1334343
   SCHLAPBACH A., 2005, International Graphonomics Society Conference (IGS), P138
   Schlapbach A, 2008, PATTERN RECOGN, V41, P2381, DOI 10.1016/j.patcog.2008.01.006
   Schlapbach A, 2007, PATTERN ANAL APPL, V10, P33, DOI 10.1007/s10044-006-0047-5
   Schlapbach A, 2006, INT C PATT RECOG, P992
   Schomaker L, 2004, IEEE T PATTERN ANAL, V26, P787, DOI 10.1109/TPAMI.2004.18
   Schomaker L., 2000, Technical report
   Schomaker L, 2007, PROC INT CONF DOC, P1268
   Seropian A, 2003, PROC INT CONF DOC, P1163
   Shahabi F, 2009, 10 INT C DOC AN REC
   Sharma MK, 2015, INT J DOC ANAL RECOG, V18, P303, DOI 10.1007/s10032-015-0252-0
   Sheikh A, 2017, INT J ADV APPL SCI, V6, P98, DOI DOI 10.11591/IJAAS.V6.I2
   Shen C, 2002, PROCEEDINGS OF THE 4TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-4, P2061, DOI 10.1109/WCICA.2002.1021447
   Siddiqi Imran, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P981, DOI 10.1109/ICDAR.2009.136
   Siddiqi I, 2009, THESIS
   Siddiqi I, 2010, PATTERN RECOGN, V43, P3853, DOI 10.1016/j.patcog.2010.05.019
   Siddiqi I, 2009, LECT NOTES COMPUT SC, V5702, P245, DOI 10.1007/978-3-642-03767-2_30
   Siddiqi IA, 2007, PROC INT CONF DOC, P108
   Srihari SN, 2003, PROC INT CONF DOC, P1096
   Srihari SN, 2002, J FORENSIC SCI, P117
   Steinherz T., 1999, International Journal on Document Analysis and Recognition, V2, P90, DOI 10.1007/s100320050040
   Strassel S., 2009, MEDAR 2 INT C AR LAN, P37
   Sun Y., 2015, ARXIV150200873
   Sutanto PJ, 2003, PROC INT CONF DOC, P1091
   Tan GX, 2009, PATTERN RECOGN
   Tan T, 1998, IEEE T PATTERN ANAL
   Tan T. N., 1992, Proceedings. 11th IAPR International Conference on Pattern Recognition. Vol.III. Conference C: Image, Speech and Signal Analysis, P607, DOI 10.1109/ICPR.1992.202060
   Tang Y, 2014, CHIN C BIOM REC
   Tang Y, 2013, INT C WAVEL ANAL PAT, P1
   Thumwarin P, 2004, IEEE IMAGE PROC, P889
   Tomai CI, 2004, INT C PATT RECOG, P638, DOI 10.1109/ICPR.2004.1334329
   Ubul Kurban, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P1656, DOI 10.1109/ICOSP.2008.4697454
   Ünlü A, 2006, LECT NOTES COMPUT SC, V4345, P441
   Venugopal V, 2017, EXPERT SYST APPL, V72, P196, DOI 10.1016/j.eswa.2016.11.038
   Wang, 2016, ESANN 2017 P, P589
   Wang T, 2012, INT C PATT RECOG, P3304
   WANG X, 2003, LECT NOTES COMPUT SC, P9
   Wen J, 2012, NEUROCOMPUTING, P4551
   Woodcock Jim, 2010, Proceedings 2010 Fourth IEEE International Conference on Secure Software Integration and Reliability Improvement (SSIRI 2010), P1, DOI 10.1109/SSIRI.2010.7
   Wu XQ, 2014, IEEE T INF FOREN SEC, V9, P526, DOI 10.1109/TIFS.2014.2301274
   Wu YB, 2017, IEICE T INF SYST, VE100D, P332, DOI 10.1587/transinf.2016EDP7238
   Xing LJ, 2016, INT CONF FRONT HAND, P584, DOI 10.1109/ICFHR.2016.105
   Xiong YJ, 2015, PROC INT CONF DOC, P91, DOI 10.1109/ICDAR.2015.7333732
   Yakopcic C, 2016, IEEE IJCNN, P963, DOI 10.1109/IJCNN.2016.7727302
   Yang WX, 2016, IEEE INTELL SYST, V31, P45, DOI 10.1109/MIS.2016.22
   Yang WX, 2015, PROC INT CONF DOC, P546, DOI 10.1109/ICDAR.2015.7333821
   Yonggang Lu, 2017, Multimedia Tools and Applications, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Zhang B, 2003, PROC INT CONF DOC, P1142
   Zhang B, 2003, PROC INT CONF DOC, P1086
   Zhang GH, 2017, LECT NOTES COMPUT SC, V10585, P1, DOI 10.1007/978-3-319-68935-7_1
   Zhang JJ, 2009, LECT NOTES COMPUT SC, V5788, P535, DOI 10.1007/978-3-642-04394-9_65
   Zhang XY, 2017, IEEE T HUM-MACH SYST, V47, P285, DOI 10.1109/THMS.2016.2634921
   Zhu Y, 2001, IEEE T PATTERN ANAL, V23, P1192, DOI 10.1109/34.954608
   Zhu Y, 2000, INT C PATT RECOG, P797, DOI 10.1109/ICPR.2000.906196
   Zhu Y, 2016, PR IEEE I C PROGR IN, P432, DOI 10.1109/PIC.2016.7949540
   ZIMMERMANN KP, 1985, PATTERN RECOGN, V18, P63, DOI 10.1016/0031-3203(85)90007-X
   Zois EN, 2000, PATTERN RECOGN, V33, P385, DOI 10.1016/S0031-3203(99)00063-1
NR 201
TC 56
Z9 57
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10889
EP 10931
DI 10.1007/s11042-018-6577-1
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400061
DA 2024-07-18
ER

PT J
AU Ren, YZ
   Fang, Z
   Liu, DK
   Chen, CW
AF Ren, Yanzhen
   Fang, Zhong
   Liu, Dengkai
   Chen, Changwen
TI Replay attack detection based on distortion by loudspeaker for voice
   authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic Speaker Verification (ASV); Replay Attack Detection (RAD);
   Loudspeaker; Low-frequency attenuation; Spoofing attack
AB Identity authentication based on Automatic Speaker Verification (ASV) has attracted extensive attention. Voice can be used as a substitute of password in many applications. However, the security of current ASV systems has been seriously challenged by many malicious spoofing attacks. Among all those attacks, replay attack is one of the biggest threats to the ASV System, where an adversary can use a pre-recorded speech sample of the legal user to access the ASV system. In this paper, we present a replay attack detection (RAD) scheme to distinguish normal speech and replayed speech. We focus on the distortion caused by loudspeaker: low-frequency attenuation and high-frequency harmonics, and present a suite of RAD features DL-RAD, including Harmonic Energy Ratio (HER), Low Spectral Ratio (LSR), Low Spectral Variance (LSV), and Low Spectral Difference Variance (LSDV), to describe the different characteristics between the normal speech signal and replay speech signal. SVM is adopted as a classifier to evaluate the performance of these features. Experiment results show that the True Positive Rate (TPR), True Negative Rate (TNR) of the proposed method are about 98.15% and 98.75% respectively, which are significantly better than the existing scheme. The proposed scheme can be applied to both text-dependent and text-independent ASV systems.
C1 [Ren, Yanzhen; Liu, Dengkai] Wuhan Univ, Sch Cyber Sci & Engn, Minist Educ, Key Lab Aerosp Informat Secur & Trusted Comp, Wuhan, Hubei, Peoples R China.
   [Fang, Zhong] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Chen, Changwen] SUNY Buffalo, Buffalo, NY 14260 USA.
C3 Wuhan University; Chinese Academy of Sciences; Institute of Computing
   Technology, CAS; State University of New York (SUNY) System; State
   University of New York (SUNY) Buffalo
RP Ren, YZ (corresponding author), Wuhan Univ, Sch Cyber Sci & Engn, Minist Educ, Key Lab Aerosp Informat Secur & Trusted Comp, Wuhan, Hubei, Peoples R China.
EM renyz@whu.edu.cn; fangzhong@ict.ac.cn; dengkailiu@whu.edu.cn;
   chencw@buffalo.edu
OI Chen, Chang Wen/0000-0002-6720-234X
FU Natural Science Foundation of China (NSFC) [U1536114, 61872275,
   U1536204]; China Scholarship Council
FX This work is supported by the Natural Science Foundation of China (NSFC)
   under the grant NO. U1536114, NO. 61872275, NO. U1536204, and China
   Scholarship Council.
CR [Anonymous], 2015, DAILYMAIL
   [Anonymous], 2010, FALA WORKSH
   [Anonymous], 2016, The Guardian
   [Anonymous], 2015, REV JBL XTREME HOW M
   [Anonymous], 2011, LIBSVM: a library for support vector machines
   [Anonymous], 2015, VOIC BIOM PROT PAYM
   Brown Sarah, 2006, THESIS LEEDS
   Galka J, 2015, SPEECH COMMUN, V67, P143, DOI 10.1016/j.specom.2014.12.003
   Koga S, 2010, IEEE INT C AC SPEECH, P1678
   Lindberg J, 2012, VULNERABILITY SPEAKE
   MA YY, 2018, IEEE TRANS CIRC SYST, V99, P1
   Reynolds DA, 2002, OVERVIEW AUTOMATIC S
   Shen WC, 1997, P IEEE, V85, P1436
   Shiota S, 2015, VOICE LIVENESS DETEC
   Villalba J, 2011, COST 2101 EUR WORKSH, P274
   Villarreal-Q. José A., 2011, Polibotánica, P1
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Wang Z., 2011, TECHNOLOGY, V39, P7
   Wu Z, 2015, SIGN INF PROC ASS SU, P35
   Wu ZZ, 2016, MULTIMED TOOLS APPL, V75, P5311, DOI 10.1007/s11042-015-3080-9
   Wu ZZ, 2015, SPEECH COMMUN, V66, P130, DOI 10.1016/j.specom.2014.10.005
   Zhang L, 2008, J TSINGHUA U
   Zhang L, 2016, ACM SIGS C COMP COMM, P1080
   Zhang Y, 2018, SIGNAL PROCESSING
   Zhi-Feng Wang, 2011, Proceedings of the 2011 International Conference on Machine Learning and Cybernetics (ICMLC 2011), P1708, DOI 10.1109/ICMLC.2011.6016982
NR 25
TC 11
Z9 12
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8383
EP 8396
DI 10.1007/s11042-018-6834-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800028
DA 2024-07-18
ER

PT J
AU Xie, YF
   Liu, Z
   Zhou, XF
   Liu, W
   Zou, XM
AF Xie, Yufeng
   Liu, Zhi
   Zhou, Xiaofei
   Liu, Wei
   Zou, Xuemei
TI Video co-segmentation based on directed graph
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video co-segmentation; Saliency map; Directed graph
ID SALIENCY DETECTION; EXTRACTION
AB This paper proposes a novel video co-segmentation method, which aims to extract multi-class objects from a group of videos. A set of tracklets are first generated based on object proposals, and then a novel directed graph is constructed to connect object tracklets. The directed graph is transformed to an undirected graph, and the extraction of common object tracklets is solved by using maximum weighted clique. The obtained common object tracklets are used as seed regions to perform manifold ranking and to generate the object-level saliency maps. Based on common object tracklets and object-level saliency maps, GrabCut is exploited to get the refined co-segmentation results. Experimental results on a public video dataset show that the proposed video co-segmentation method consistently outperforms the state-of-the-art methods.
C1 [Xie, Yufeng; Liu, Zhi; Zhou, Xiaofei] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
   [Xie, Yufeng; Liu, Zhi; Zhou, Xiaofei; Zou, Xuemei] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Zhou, Xiaofei] Hangzhou Dianzi Univ, Inst Informat & Control, Hangzhou 310018, Zhejiang, Peoples R China.
   [Liu, Wei] Shanghai Jiao Tong Univ, Minist Educ Syst Control & Informat Proc, Key Lab, Shanghai 200240, Peoples R China.
C3 Shanghai University; Shanghai University; Hangzhou Dianzi University;
   Shanghai Jiao Tong University
RP Liu, Z (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.; Liu, Z (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM xieyufeng0227@163.com; liuzhisjtu@163.com; zxforchid@outlook.com;
   liuwei.1989@sjtu.edu.cn; zxm@staff.shu.edu.cn
RI Xiaofei, Zhou/AAE-8347-2020; wang, yan/GSE-6489-2022; LIU,
   Zhi/D-4518-2012
OI LIU, Zhi/0000-0002-8428-1131
FU National Natural Science Foundation of China [61471230]; Program for
   Professor of Special Appointment (Eastern Scholar) at Shanghai
   Institutions of Higher Learning
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61471230, and by the Program for Professor of
   Special Appointment (Eastern Scholar) at Shanghai Institutions of Higher
   Learning.
CR BRON C, 1973, COMMUN ACM, V16, P575, DOI 10.1145/362342.362367
   Chen D.-J., 2012, P 20 ACM INT C MULTI, P805, DOI [10.1145/2393347.2396317, DOI 10.1145/2393347.2396317]
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Chiu WC, 2013, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.2013.48
   Du H, 2013, J VIS COMMUN IMAGE R, V24, P499, DOI 10.1016/j.jvcir.2013.03.003
   Endres I, 2010, LECT NOTES COMPUT SC, V6315, P575, DOI 10.1007/978-3-642-15555-0_42
   Faktor Alon, 2014, BMVC
   Fu HZ, 2015, IEEE T IMAGE PROCESS, V24, P3415, DOI 10.1109/TIP.2015.2442915
   Guo J., 2014, P AS C COMP VIS, P241
   Guo JM, 2013, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2013.278
   Huang GH, 2017, MULTIMED TOOLS APPL, V76, P12941, DOI 10.1007/s11042-016-3709-3
   Jacobs D.E., 2010, ACM S USER INTERFACE, P219
   Kolmogorov V., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91
   Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471
   Liu Ce, 2009, THESIS
   Liu Z, 2014, IEEE SIGNAL PROC LET, V21, P88, DOI 10.1109/LSP.2013.2292873
   Lou ZY, 2014, IEEE T MULTIMEDIA, V16, P2110, DOI 10.1109/TMM.2014.2363936
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Perazzi F, 2015, IEEE I CONF COMP VIS, P3227, DOI 10.1109/ICCV.2015.369
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rubio J.C., 2012, ASIAN C COMPUTER VIS, P13, DOI DOI 10.1007/978-3-642-37444-9
   Vicente S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2217, DOI 10.1109/CVPR.2011.5995530
   Wang WG, 2018, IEEE T CIRC SYST VID, V28, P1727, DOI 10.1109/TCSVT.2017.2701279
   Wang Wenguan, 2015, IEEE Trans Image Process, V24, P3137, DOI 10.1109/TIP.2015.2438550
   Wen LY, 2015, PROC CVPR IEEE, P2226, DOI 10.1109/CVPR.2015.7298835
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Xiao FY, 2016, PROC CVPR IEEE, P933, DOI 10.1109/CVPR.2016.107
   Xie Y., 2016, P INT C DIG IM PROC
   Xu B, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P525
   Ye LW, 2015, IEEE SIGNAL PROC LET, V22, P2073, DOI 10.1109/LSP.2015.2458434
   Zhang D, 2014, LECT NOTES COMPUT SC, V8695, P551, DOI 10.1007/978-3-319-10584-0_36
   Zhang D, 2013, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2013.87
   Zhang JJ, 2016, IEEE SIGNAL PROC LET, V23, P785, DOI 10.1109/LSP.2016.2557346
NR 35
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10353
EP 10372
DI 10.1007/s11042-018-6614-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400038
DA 2024-07-18
ER

PT J
AU Ning, Y
   Liu, YF
   Zhang, YF
   Zhang, CM
AF Ning, Yang
   Liu, Yifang
   Zhang, Yunfeng
   Zhang, Caiming
TI Adaptive image rational upscaling with local structure as constraints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AIRU; PCE; Angle coefficient; Variation coefficient; Gray similarity
   coefficient; Parameter optimization
ID INTERPOLATION
AB In this paper, we develop a new interpolation fusion model, Adaptive Image Rational Upscaling (AIRU), based on classical rational interpolation. This model can synthetically consider the influence of the surrounding 12 pixels within the current interpolation cell. Considering the limitation of edge direction estimation of conventional edge detection methods, we introduce a new method to quantify the edge direction based on the Principal Component Edge (PCE). Adaptive weights for each triangular patch can be generated based on three coefficients: angle coefficient which can be estimated by PCE, variation coefficient and gray similarity coefficient. PCE can also be used to divide the image into non-smooth and smooth area. AIRU and conventional interpolation are used in these two areas respectively. Furthermore, the model parameter optimization can further improve the interpolation performance. Experimental results demonstrate that the proposed fusion model achieves competitive performance when compared with the state-of-the-arts.
C1 [Ning, Yang] Shandong Univ, Sch Comp Sci & Technol, Jinan 250100, Shandong, Peoples R China.
   [Zhang, Caiming] Shandong Univ, Sch Software, Jinan 250101, Shandong, Peoples R China.
   [Zhang, Caiming] Shandong Coinnovat Ctr Future Intelligent Comp, Yantai 264025, Peoples R China.
   [Zhang, Yunfeng; Zhang, Caiming] Shandong Univ Finance & Econ, Shandong Prov Key Lab Digital Media Technol, Jinan 250061, Shandong, Peoples R China.
   [Zhang, Yunfeng] Shandong Univ Finance & Econ, Dept Comp Sci & Technol, Jinan 250014, Shandong, Peoples R China.
   [Liu, Yifang] SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA.
C3 Shandong University; Shandong University; Shandong University of Finance
   & Economics; Shandong University of Finance & Economics; State
   University of New York (SUNY) System; State University of New York
   (SUNY) Buffalo
RP Zhang, CM (corresponding author), Shandong Univ, Sch Software, Jinan 250101, Shandong, Peoples R China.; Zhang, CM (corresponding author), Shandong Coinnovat Ctr Future Intelligent Comp, Yantai 264025, Peoples R China.; Zhang, CM (corresponding author), Shandong Univ Finance & Econ, Shandong Prov Key Lab Digital Media Technol, Jinan 250061, Shandong, Peoples R China.
EM czhang@sdu.edu.cn
RI ning, yang/JDW-5468-2023; Cheng, Lin/KFQ-3111-2024
FU National Nature Foundation of China [61602277, 61572292, 61332015]; NSFC
   [U1609218]; Zhejiang Integration of Informatization and
   Industrialization under Key Project [U1609218]
FX This work is supported by the National Nature Foundation of China
   (61602277, 61572292, 61332015), NSFC Joint Fund with Zhejiang
   Integration of Informatization and Industrialization under Key
   Project(U1609218).
CR [Anonymous], 2014, ACCV WORKSH IM REST
   Asuni N, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P58
   Bevilacqua M, 2012, P BRIT MACH VIS C, V135, P110
   Cui CR, 2015, J ASSOC INF SCI TECH, V66, P82, DOI 10.1002/asi.23163
   Cui CR, 2017, ACM T INTELLIGENT SY
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1382, DOI 10.1109/TIP.2012.2231086
   Duan Q, 1999, INT J COMPUT MATH, V72, P155, DOI 10.1080/00207169908804842
   Duan Q, 2006, COMPUT MATH APPL, V52, P975, DOI 10.1016/j.camwa.2006.04.021
   Duan Q, 2006, APPL MATH COMPUT, V179, P190, DOI 10.1016/j.amc.2005.11.094
   Edward A, 2009, DIR DEV, P69
   Giachetti A, 2011, IEEE T IMAGE PROCESS, V20, P2760, DOI 10.1109/TIP.2011.2136352
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   HUANG JB, 2015, PROC CVPR IEEE, P5197, DOI DOI 10.1109/CVPR.2015.7299156
   Hung KW, 2012, IEEE T IMAGE PROCESS, V21, P1061, DOI 10.1109/TIP.2011.2168416
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Shezaf N, 2000, 21ST IEEE CONVENTION OF THE ELECTRICAL AND ELECTRONIC ENGINEERS IN ISRAEL - IEEE PROCEEDINGS, P253, DOI 10.1109/EEEI.2000.924383
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Yao XX, 2018, MULTIMEDIA TOOLS APP
   Yunfeng Zhang, 2011, Proceedings of the 2011 Eighth International Symposium on Voronoi Diagrams in Science and Engineering (ISVD 2011), P200, DOI 10.1109/ISVD.2011.34
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang CM, 2013, IEEE IMAGE PROC, P1046, DOI 10.1109/ICIP.2013.6738216
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
   Zhang X, 2016, IET IMAGE PROCESS, V10, P398, DOI 10.1049/iet-ipr.2015.0467
   Zhang XF, 2009, LECT NOTES COMPUT SC, V5879, P1197, DOI 10.1007/978-3-642-10467-1_121
   Zhang YF, 2012, J COMPUT ANAL APPL, V14, P1303
   Zwart CM, 2013, IEEE T IMAGE PROCESS, V22, P2960, DOI 10.1109/TIP.2012.2228493
NR 29
TC 5
Z9 5
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6889
EP 6911
DI 10.1007/s11042-018-6182-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700022
DA 2024-07-18
ER

PT J
AU Singh, L
   Singh, S
   Aggarwal, N
AF Singh, Lovejit
   Singh, Sarbjeet
   Aggarwal, Naveen
TI Improved TOPSIS method for peak frame selection in audio-video human
   emotion recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Improved TOPSIS method; Peak frame selection;
   Audio-video emotion recognition
AB The peak frame selection with corresponding voice segment identification is a challenging problem in the audio-video human emotion recognition. The peak frame is a most relevant descriptor of facial expression that can be inferred from varied emotional states. In this paper, an improved Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) is proposed to select the key frame based on facial action units co-occurrence behavior in the visual sequences. The proposed method utilizes the experts judgments while identifying the peak frame in video modality. It locates the peak voiced segment in audio modality using synchronous and asynchronous temporal relationship with selected peak visual frame. The facial action unit features of peak frame are fused with nine statistical characteristics of spectral features of the voiced segment. The weighted product rule-based decision level fusion is performed to combine the posterior probabilities of two independent (i.e., audio, and video) support vector machines based classification models. The performance of the proposed peak frame and voiced segment selection method is evaluated and compared with the existing Maximum-Dissimilarity (MAX-DIST), Dendrogram-Clustering (DEND-CLUSTER), and Emotion Intensity (EIFS) based peak frame selection methods on two challenging emotion datasets in two different languages namely eNTERFACE'05 in English and BAUM-1a in Turkish. The results show that the system with the proposed method has performed better than the existing techniques, and it achieved 88.03%, and 84.61% emotion recognition accuracies on the eNTERFACE'05 and BAUM-1a datasets respectively.
C1 [Singh, Lovejit; Singh, Sarbjeet; Aggarwal, Naveen] Panjab Univ, UIET, Chandigarh, India.
C3 Panjab University
RP Singh, S (corresponding author), Panjab Univ, UIET, Chandigarh, India.
EM pu.lovejitjhajj@gmail.com; sarbjeet@pu.ac.in; navagg@gmail.com
RI Singh, Lovejit/GLT-0084-2022; Singh, Sarbjeet/K-7472-2012; Aggarwal,
   Naveen/F-3372-2019
OI Aggarwal, Naveen/0000-0003-1549-531X
FU University Grant Commission (UGC), Ministry of Human Resource
   Development (MHRD) of India [F. 25-1/2013-14(BSR)/7-379/2012(BSR)]
FX This work was supported by University Grant Commission (UGC), Ministry
   of Human Resource Development (MHRD) of India under Basic Scientific
   Research (BSR) fellowship for meritorious fellows vide UGC letter no. F.
   25-1/2013-14(BSR)/7-379/2012(BSR) Dated 30.5.2014.
CR Amiriparian S, 2017, INT CONF AFFECT, P30, DOI 10.1109/ACIIW.2017.8272619
   [Anonymous], SPRINGER SERIES ADV
   [Anonymous], 2016, P IEEE WINT C APPL C
   [Anonymous], 2006, 22 INT C DATA ENG WO
   [Anonymous], 2014, P NATL ACAD SCI, DOI DOI 10.1073/pnas.1322355111
   [Anonymous], 2009, A method for silence removal and segmentation of speech signals, implemented in Matlab
   [Anonymous], KNOWLEDGE BASED SYST
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Baltrusaitis T, 2015, IEEE INT CONF AUTOMA
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Baltrusaitis T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P354, DOI 10.1109/ICCVW.2013.54
   Baltrusaitis T, 2012, PROC CVPR IEEE, P2610, DOI 10.1109/CVPR.2012.6247980
   Ekman P., 2002, FACIAL ACTION CODING
   Escalera S, 2009, PATTERN RECOGN LETT, V30, P285, DOI 10.1016/j.patrec.2008.10.002
   Gharavian D, 2017, MULTIMED TOOLS APPL, V76, P2331, DOI 10.1007/s11042-015-3180-6
   Grant K.W., 2001, Auditory-Visual Speech Processing, P132
   Haq S., 2009, INT C AUDITORY VISUA, P53
   Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616
   Hwang C. L., 1981, MULTIPLE ATTRIBUTE D, P191, DOI DOI 10.1007/978-3-642-48318-9_3
   Kayaoglu M, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P519, DOI 10.1145/2818346.2830594
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kohler CG, 2004, PSYCHIAT RES, V128, P235, DOI 10.1016/j.psychres.2004.07.003
   Kolakowska A, 2014, ADV INTELL SYST, V300, P51, DOI 10.1007/978-3-319-08491-6_5
   Kowalska M., 2017, HDB COGNITION EMOTIO, P1, DOI [https://doi.org/10.1007/978-3-319-28099-8495-1, DOI 10.1002/0470013494.CH3, 10.1002/0470013494.ch3]
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   Picard R., 1997, Affective computing, P252
   Sidorov M, 2015, ICIMCO 2015 PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS, VOL. 2, P246
   Valstar M.F., 2015, P 2015 IEEE INT C WO, P1
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhalehpour S, 2017, IEEE T AFFECT COMPUT, V8, P300, DOI 10.1109/TAFFC.2016.2553038
   Zhalehpour S, 2016, SIGNAL IMAGE VIDEO P, V10, P827, DOI 10.1007/s11760-015-0822-0
   Zhalehpour S, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA 2014), P116, DOI 10.1109/INISTA.2014.6873606
   Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002
NR 36
TC 15
Z9 15
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 6277
EP 6308
DI 10.1007/s11042-018-6402-x
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100060
DA 2024-07-18
ER

PT J
AU Tripathi, RK
   Jalal, AS
   Agrawal, SC
AF Tripathi, Rajesh Kumar
   Jalal, Anand Singh
   Agrawal, Subhash Chand
TI Abandoned or removed object detection from visual surveillance: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Abandoned object; Foreground object; Tracking; Classification
ID REAL-TIME; CLASSIFICATION; RECOGNITION; TRACKING; HISTOGRAM; PEOPLE;
   SYSTEM; ROBUST; MODEL
AB Intelligent Visual Surveillance is an important and challenging research field of image processing and computer vision. To prevent the ecological and economical losses from bomb blasting, an intelligent visual surveillance is required to keep an eye on public areas, infrastructures and discriminate an unattended object left among multiple objects at public places. An unattended object without its owner since a long time at public place is considered as an abandoned object. Identification of an abandoned object on real-time can prevent the terrorists attack through an automated video surveillance system. In recent decade, a good number of publications have been presented in the field of intelligent visual surveillance to identify the abandoned or removed objects. Furthermore, few surveys can be seen in the literature for the various human activity recognition but none of them focused deeply on abandoned or removed object detection in a review. In this paper, we present the state-of-the-art which demonstrates the overall progress of abandoned or removed object detection from the surveillance videos in the last decade. We include a brief introduction of the abandoned object detection with its issues and challenges. To acknowledge to the new researchers of this field, core technologies, and frequently used general steps to recognize abandoned or removed objects have been discussed in the literature such as foreground extraction, static object detection based on non-tracking or tracking approaches, feature extraction, classification and activity analysis to recognize abandoned object. The objective of this paper is to provide the literature review in the field of abandoned or removed object recognition from visual surveillance systems with its general framework to the researchers of this field.
C1 [Tripathi, Rajesh Kumar; Jalal, Anand Singh; Agrawal, Subhash Chand] Dept Comp Engn & Applicat, Mathura, India.
RP Tripathi, RK (corresponding author), Dept Comp Engn & Applicat, Mathura, India.
EM rajesh.tripathi@gla.ac.in
RI Tripathi, Rajesh/AAE-6995-2020
OI Tripathi, Rajesh/0000-0003-3167-9338; Jalal, Anand/0000-0002-7469-6608
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   [Anonymous], 2001, PETS 2001 BENCHMARK
   [Anonymous], 2007, 2007 IEEE WORKSH MOT, DOI DOI 10.1109/WMVC.2007.1
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2007, PETS 2007 BENCHMARK
   [Anonymous], 2013, 4 NAT C COMP VIS PAT, DOI DOI 10.1109/NCVPRIPG.2013.6776161
   [Anonymous], 1999, COMP VIS PATT REC 19
   [Anonymous], P 10 IEEE INT WORKSH
   [Anonymous], 2000, Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations
   Auvinet E, 2006, P 9 IEEE INT WORKSH, P51
   Bangare PS, 2012, INT J COMPUT APPL, V57
   Beyan C, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3602204
   Beynon MD, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P221, DOI 10.1109/AVSS.2003.1217925
   Bhargava M, 2009, MACH VISION APPL, V20, P271, DOI 10.1007/s00138-008-0181-8
   Bird N, 2006, IEEE INT CONF ROBOT, P3775, DOI 10.1109/ROBOT.2006.1642279
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Calderara S, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P93
   Candamo J, 2010, IEEE T INTELL TRANSP, V11, P206, DOI 10.1109/TITS.2009.2030963
   Chitra M., 2013, INT J COMPUT APPL TE, V2, P708
   Chuang CH, 2008, IEEE INT SYMP CIRC S, P3546, DOI 10.1109/ISCAS.2008.4542225
   Chuang CH, 2009, IEEE T CIRC SYST VID, V19, P911, DOI 10.1109/TCSVT.2009.2017415
   Collazos Antonio, 2013, Natural and Artificial Computation in Engineering and Medical Applications. 5th International Work-Conference on the Interplay Between Natural and Artificial Computation, IWINAC 2013. Proceedings: LNCS 7931, P169, DOI 10.1007/978-3-642-38622-0_18
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Denman S, 2008, P INT C SIGN PROC CO, P439
   Elgammal A, 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48
   Ellingsen K., 2008, ACM WORKSHOP ANAL RE, P57
   EVANGELIO HERAS., 2011, Applications of Computer Vision (WACV), 2011 IEEE Workshop on, P534, DOI DOI 10.1109/WACV.2011.5711550
   Evangelio RH, 2010, EURASIP J IMAGE VIDE, V2011, P858
   Fan QF, 2013, IEEE I CONF COMP VIS, P2736, DOI 10.1109/ICCV.2013.340
   Fan QF, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P58, DOI 10.1109/AVSS.2012.62
   Femi PS, 2013, INT J COMPUTER APPL, V70
   Fernández-Caballero A, 2012, EXPERT SYST APPL, V39, P6982, DOI 10.1016/j.eswa.2012.01.050
   Ferrando Silvia., 2006, VIDEO SIGNAL BASED S, P21
   Ferryman J, 2013, PATTERN RECOGN LETT, V34, P789, DOI 10.1016/j.patrec.2013.01.018
   Foggia P, 2015, METHOD DETECTING LON
   Foresti GL, 2002, IEEE T MULTIMEDIA, V4, P459, DOI 10.1109/TMM.2002.802024
   Foresti GL, 2012, MULTIMEDIA VIDEO BAS, V573
   Foucher S, 2011, SPIE DEFENSE SECURIT, p[805, 610, 610]
   Gouaillier V, 2009, CRIM TECH DEFENCE SE, P456
   Guler S., 2006, P PETS, P18
   Guler S, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P248, DOI 10.1109/AVSS.2007.4425318
   Hardikar AA, 2014, J AM HEART ASSOC, V3, DOI 10.1161/JAHA.113.000792
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Haritaoglu I., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P102, DOI 10.1109/ICCV.1999.791204
   Hoferlin M, 2015, J SPATIAL INF SCI, V2, P87
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Huei-Hung Liao, 2008, 2008 IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance, P132, DOI 10.1109/AVSS.2008.9
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   JALAL A.S., 2012, INFORMATICA, V36
   Javed O, 2002, LECT NOTES COMPUT SC, V2353, P343
   Jiyan Pan, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3597, DOI 10.1109/ICIP.2011.6116495
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Khan S, 2003, IEEE T PATTERN ANAL, V25, P1355, DOI 10.1109/TPAMI.2003.1233912
   Khan SM, 2006, LECT NOTES COMPUT SC, V3954, P133
   Kim J, 2014, IEEE IMAGE PROC, P2358, DOI 10.1109/ICIP.2014.7025478
   KITAGAWA G, 1987, J AM STAT ASSOC, V82, P1032, DOI 10.2307/2289375
   Kong H, 2010, IEEE T IMAGE PROCESS, V19, P2201, DOI 10.1109/TIP.2010.2045714
   Krahnstoever N, 2006, P 9 IEEE INT WORKSH, V258
   Lavee G, 2005, FRAMEWORK VIDEO ANAL, P79
   Lavee G, 2007, MULTIMED TOOLS APPL, V35, P109, DOI 10.1007/s11042-007-0117-8
   Li L, 2006, P 9 IEEE INT WORKSH, P91
   Li QJ, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P156, DOI 10.1109/ICIG.2009.166
   Lin K, 2015, IEEE T INF FOREN SEC, V10, P1359, DOI 10.1109/TIFS.2015.2408263
   Lin K, 2014, INT C PATT RECOG, P4600, DOI 10.1109/ICPR.2014.787
   Lo BPL, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P158, DOI 10.1109/ISIMP.2001.925356
   LU S, 2006, P IEEE INT C VID SIG, P110
   Lu SJ, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P540, DOI 10.1109/AVSS.2007.4425368
   Lu SJ, 2007, PATTERN RECOGN, V40, P2173, DOI 10.1016/j.patcog.2006.12.013
   Lv F., 2006, 9 IEEE INT WORKSHOP, P83
   Maddalena L, 2013, IEEE T NEUR NET LEAR, V24, P723, DOI 10.1109/TNNLS.2013.2242092
   Mahin FS, 2015, P INT C IM PROC COMP, P427
   Martinez-del Rincon J., 2006, P 9 IEEE INT WORKSH, P59
   Mathew R, 2005, ELEC COMP C, P1
   McHugh JM, 2009, IEEE SIGNAL PROC LET, V16, P390, DOI 10.1109/LSP.2009.2016447
   Mittal A, 2001, 2001 IEEE WORKSHOP ON MULTI-OBJECT TRACKING, PROCEEDINGS, P3, DOI 10.1109/MOT.2001.937975
   Mukherjee D, 2014, IEEE T IND INFORM, V10, P1086, DOI 10.1109/TII.2013.2294134
   Otoom AF, 2008, IEEE IMAGE PROC, P1368, DOI 10.1109/ICIP.2008.4712018
   Pavithradevi MK, 2014, IJAICT, V1
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Porikli F., 2007, P 10 IEEE INT WORKSH, P79
   Porikli F, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P236, DOI 10.1109/AVSS.2007.4425316
   Porikli F, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/197875
   Prabhakar G., 2012, Int. J. Comput. Appl., V54, P22
   Quanfu Fan, 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P36, DOI 10.1109/AVSS.2011.6027290
   Regazzoni CS, 1998, ADV VIDEO BASED SURV, V488
   Rothkrantz L., 2011, P 12 INT C COMPUTER, P380
   Sacchi C, 2000, IEEE T VEH TECHNOL, V49, P2013, DOI 10.1109/25.892603
   Sajith K., 2013, International Journal of Engineering Research and Technology, V2
   San Miguel Juan Carlos, 2008, 2008 IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance, P18, DOI 10.1109/AVSS.2008.16
   SanMiguel C, 2012, ELECTRON LETT, V48, P86, DOI 10.1049/el.2011.3160
   SanMiguel JC, 2012, COMPUT VIS IMAGE UND, V116, P937, DOI 10.1016/j.cviu.2012.04.005
   Singh R., 2010, Proceedings of the First International Conference on Intelligent Interactive Technologies and Multimedia (ITTM), New York, NY, USA, P297
   Singh VK, 2008, MACH VISION APPL, V19, P375, DOI 10.1007/s00138-007-0082-2
   Smith KC, 2006, DETECTING ABANDONED
   Spengler M., 2003, P JOINT IEEE INT WOR
   Stringa E, 2000, IEEE T IMAGE PROCESS, V9, P69, DOI 10.1109/83.817599
   Stringa E, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P138, DOI 10.1109/ICIP.1998.727153
   Szwoch G, 2016, MULTIMED TOOLS APPL, V75, P761, DOI 10.1007/s11042-014-2324-4
   Tao Yang, 2004, Proceedings. Third International Conference on Image and Graphics, P112
   Tejas Naren TN, 2014, INT J ADV RES ELECT, V3
   Thi Thi Zin, 2012, IAENG International Journal of Computer Science, V39, P295
   Tian YL, 2012, MACH VISION APPL, V23, P967, DOI 10.1007/s00138-011-0377-1
   Tian YL, 2011, IEEE T SYST MAN CY C, V41, P565, DOI 10.1109/TSMCC.2010.2065803
   Tripathi RK., 2014, INT J MACH INTEL SEN, V1, P251, DOI DOI 10.1504/IJMISSP.2014.066433
   Tsai R.Y., 1986, P IEEE C COMPUTER VI, P364
   Vezzani R, 2010, MULTIMED TOOLS APPL, V50, P359, DOI 10.1007/s11042-009-0402-9
   Wan EA, 2000, IEEE 2000 ADAPTIVE SYSTEMS FOR SIGNAL PROCESSING, COMMUNICATIONS, AND CONTROL SYMPOSIUM - PROCEEDINGS, P153, DOI 10.1109/ASSPCC.2000.882463
   Webb GI, 2000, MACH LEARN, V40, P159, DOI 10.1023/A:1007659514849
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Xuli Li, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P436, DOI 10.1109/ICPR.2010.115
   Yadav P, 2015, STATIC OBJECT DETECT
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yue Z., 2004, AC SPEECH SIGN PROC, V3, piii
   Zeng YL, 2015, SENSORS-BASEL, V15, P6885, DOI 10.3390/s150306885
   Zhou Y, 2010, P 1 ACM INT WORKSH A, P21
   Ziaeefard M, 2015, PATTERN RECOGN, V48, P2329, DOI 10.1016/j.patcog.2015.03.006
   Zin T.T., 2012, P WORLD C ENG, V2
NR 122
TC 9
Z9 9
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7585
EP 7620
DI 10.1007/s11042-018-6472-9
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700053
DA 2024-07-18
ER

PT J
AU Zhou, JX
   Liu, XD
   Liu, WQ
   Gan, JH
AF Zhou, Juxiang
   Liu, Xiaodong
   Liu, Wanquan
   Gan, Jianhou
TI Image retrieval based on effective feature extraction and diffusion
   process
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Bag of features; Diffusion processes
ID FEATURE DESCRIPTOR; COLOR; EFFICIENT; TRANSFORM; HISTOGRAM; PATTERNS;
   FUSION; MODEL
AB Feature extraction and its matching are two critical tasks in image retrieval. This paper presents a new methodology for content-based image retrieval by integrating three features, and then optimizing feature metric by diffusion process. To boost the discriminative power, the color histogram, local directional pattern, and dense SIFT features based on bag of features (BoF) are selected. Then diffusion process is applied to seek a global optimization for image matching based on fused multi-features. The diffusion process can capture the intrinsic manifold structure on a dataset, and thus enhance the overall retrieval performance significantly. Finally, a new search strategy is explored to make the diffusion process work even better when the number of retrieval images is small. In order to validate our proposed approach, four benchmark databases are used, and the results of experiments show that the proposed approach outperforms all other existing approaches.
C1 [Zhou, Juxiang; Liu, Xiaodong] Dalian Univ Technol, Sch Control Sci & Engn, Dalian 116024, Peoples R China.
   [Liu, Wanquan] Curtin Univ, Dept Comp, Perth, WA 6102, Australia.
   [Zhou, Juxiang; Gan, Jianhou] Yunnan Normal Univ, Key Lab Educ Informatizat Nationalities, Minist Educ, Kunming 650500, Yunnan, Peoples R China.
C3 Dalian University of Technology; Curtin University; Yunnan Normal
   University
RP Liu, XD (corresponding author), Dalian Univ Technol, Sch Control Sci & Engn, Dalian 116024, Peoples R China.
EM xdliuros@dlut.edu.cn
RI Huang, Liping/KIB-4430-2024; Zhao, YuHan/KIE-0813-2024
OI liu, wanquan/0000-0003-4910-353X
FU NSFC [61673082, 61462097, 61602321, 61562093]; Application
   Infrastructure Projects of Science and Technology Plan in Yunnan
   Province [2016FD022]
FX We thank the anonymous reviewers and associate editor for their valuable
   comments that are invaluable in improving the quality of this paper.
   This work is supported by some grants from NSFC projects (Nos. 61673082,
   61462097, 61602321, 61562093), and Application Infrastructure Projects
   of Science and Technology Plan in Yunnan Province (No.2016FD022).
CR Ahmad J, 2016, MULTIMED TOOLS APPL, V75, P12669, DOI 10.1007/s11042-016-3436-9
   [Anonymous], 2010, BMVC 2010 21 BRIT MA
   [Anonymous], 2016, TIP, DOI DOI 10.1109/TIP.2016.2593344
   Belalia A, 2016, MULTIMED TOOLS APPL, V75, P10175, DOI 10.1007/s11042-015-3026-2
   BOUREAU YL, 2010, PROC CVPR IEEE, P2559, DOI DOI 10.1109/CVPR.2010.5539963
   D'Souza D, 2014, IEEE COMPUT SOC CONF, P27, DOI 10.1109/CVPRW.2014.10
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   de Ves E, 2016, NEUROCOMPUTING, V208, P99, DOI 10.1016/j.neucom.2016.02.073
   Deng C, 2013, IEEE I CONF COMP VIS, P2600, DOI 10.1109/ICCV.2013.323
   Deng C, 2014, IEEE T MULTIMEDIA, V16, P785, DOI 10.1109/TMM.2014.2298841
   Donoser M, 2013, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2013.174
   ElAlami ME, 2014, APPL SOFT COMPUT, V14, P407, DOI 10.1016/j.asoc.2013.10.003
   ElAlami ME, 2011, KNOWL-BASED SYST, V24, P23, DOI 10.1016/j.knosys.2010.06.001
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Giveki D, 2017, OPTIK, V131, P242, DOI 10.1016/j.ijleo.2016.11.046
   He ZY, 2008, NEUROCOMPUTING, V71, P1832, DOI 10.1016/j.neucom.2007.10.017
   Huang W, 2010, J SIGNAL PROCESS SYS, V59, P143, DOI 10.1007/s11265-008-0294-3
   Jabid Taskeed, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2162, DOI 10.1109/ICPR.2010.373
   Jabid T., 2010, Digest of Technical Papers Int. Conf. Consumer Electronics, P329, DOI DOI 10.1109/ICCE.2010.5418801
   Jabid T., 2010, 2010 7th IEEE International Conference of Advanced Video and Signal Based Surveillance, P482
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jing F, 2004, IEEE T IMAGE PROCESS, V13, P699, DOI 10.1109/TIP.2004.826125
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Liu GH, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P506, DOI 10.1109/FSKD.2016.7603225
   Liu GH, 2015, AER ADV ENG RES, V22, P838
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Liu Y, 2008, PATTERN RECOGN, V41, P2554, DOI 10.1016/j.patcog.2007.12.003
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lux M., 2013, Synthesis Lectures on Information Concepts, Retrieval, and Services, V5, P1
   OHara S, 2011, COMPUTER SCI
   Ojala T, 2000, TOPI MULTIRESOLUTION
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Rao M.B., 2011, INT J COMPUT APPL, V18, P40, DOI [10.5120/2285-2961, DOI 10.5120/2285-2961]
   Shrivastava N, 2015, COMPUT ELECTR ENG, V46, P314, DOI 10.1016/j.compeleceng.2014.11.009
   Singhai N., 2010, International Journal of Computer Applications IJCA, V4, P22, DOI DOI 10.5120/802-1139
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Subrahmanyam M, 2013, COMPUT ELECTR ENG, V39, P762, DOI 10.1016/j.compeleceng.2012.11.023
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Vadivel A, 2007, PATTERN RECOGN LETT, V28, P974, DOI 10.1016/j.patrec.2007.01.004
   Verma M, 2015, NEUROCOMPUTING, V165, P255, DOI 10.1016/j.neucom.2015.03.015
   Vimina ER, 2013, IJCSI INT J COMPUTER, V10, P686
   Vipparthi SK, 2015, OPTIK, V126, P1467, DOI 10.1016/j.ijleo.2015.04.018
   Vipparthi SK, 2014, EXPERT SYST APPL, V41, P8016, DOI 10.1016/j.eswa.2014.07.001
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Wengert C., 2011, P 19 ACM INT C MULT, P1437, DOI [DOI 10.1145/2072298.2072034, 10.1145/2072298.2072034]
   Yang F, 2015, IEEE WINT CONF APPL, P572, DOI 10.1109/WACV.2015.82
   Yang XW, 2013, IEEE T PATTERN ANAL, V35, P28, DOI 10.1109/TPAMI.2012.60
   Yang XW, 2009, PROC CVPR IEEE, P357, DOI 10.1109/CVPRW.2009.5206844
   Youssef SM, 2012, COMPUT ELECTR ENG, V38, P1358, DOI 10.1016/j.compeleceng.2012.05.010
   Yu J, 2013, NEUROCOMPUTING, V120, P355, DOI 10.1016/j.neucom.2012.08.061
   Zhou JX, 2018, INT J MACH LEARN CYB, V9, P677, DOI 10.1007/s13042-016-0597-9
   Zhou L, 2013, PATTERN RECOGN, V46, P424, DOI 10.1016/j.patcog.2012.07.017
   Zhou Y, 2016, COGN COMPUT, V8, P877, DOI 10.1007/s12559-016-9424-6
NR 58
TC 28
Z9 30
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 6163
EP 6190
DI 10.1007/s11042-018-6192-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100055
DA 2024-07-18
ER

PT J
AU Amati, G
   Angelini, S
   Gambosi, G
   Rossi, G
   Vocca, P
AF Amati, Giambattista
   Angelini, Simone
   Gambosi, Giorgio
   Rossi, Gianluca
   Vocca, Paola
TI Influential users in Twitter: detection and evolution analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph analysis; Social media; Twitter graph; Retweet graph; Graph
   dynamics; Centrality
ID SOCIAL NETWORKS; CENTRALITY
AB In this paper, we study how to detect the most influential users in the microblogging social network platform Twitter and their evolution over time. To this aim, we consider the Dynamic Retweet Graph (DRG) proposed in Amati et al. (2016) and partially analyzed in Amati et al. (IADIS Int J Comput Sci Inform Syst, 11(2) 2016), Amati et al. (2016). The model of the evolution of the Twitter social network is based here on the retweet relationship. In a DRGs, the last time a tweet has been retweeted we delete all the edges representing this tweet. In this way we model the decay of tweet life in the social platform. To detect the influential users, we consider the central nodes in the network with respect to the following centrality measures: degree, closeness, betweenness and PageRank-centrality. These measures have been widely studied in the static case and we analyze them on the sequence of DRG temporal graphs with special regard to the distribution of the 75% most central nodes. We derive the following results: (a) in all cases, applying the closeness measure results into many nodes with high centrality, so it is useless to detect influential users; (b) for all other measures, almost all nodes have null or very low centrality and (c) the number of vertices with significant centrality are often the same; (d) the above observations hold also for the cumulative retweet graph and, (e) central nodes in the sequence of DRG temporal graphs have high centrality in cumulative graph.
C1 [Amati, Giambattista; Angelini, Simone] Fdn Ugo Bordoni, Rome, Italy.
   [Gambosi, Giorgio] Univ Roma Tor Vergata, Rome, Italy.
   [Rossi, Gianluca] Univ Roma Tor Vergata, Comp Sci, Rome, Italy.
   [Vocca, Paola] Univ Tuscia, Viterbo, Italy.
C3 Ugo Bordoni Foundation; University of Rome Tor Vergata; University of
   Rome Tor Vergata; Tuscia University
RP Vocca, P (corresponding author), Univ Tuscia, Viterbo, Italy.
EM gba@fub.it; sangelini@fub.it; giorgio.gambosi@uniroma2.it;
   gianluca.rossi@uniroma2.it; vocca@unitus.it
RI Gambosi, Giorgio/KIH-1713-2024; VOCCA, Paola/ABE-1736-2020
OI Gambosi, Giorgio/0000-0001-9979-6931; VOCCA, Paola/0000-0002-8018-0309;
   Amati, Giambattista/0000-0002-7067-4583; ROSSI,
   GIANLUCA/0000-0002-6440-8203
FU ISIDE project
FX Partially supported by ISIDE project.
CR Amati G, 2016, IGDACI 2016 P INT C, V1
   Amati G, 2017, L N INST COMP SCI SO, V195, P243, DOI 10.1007/978-3-319-61949-1_26
   Amati G, 2016, IADIS-INT J COMPUT S, V11, P19
   Amati Giambattista, 2014, P INT WORKSH INF FIL, P12
   [Anonymous], 2010, ICWSM, DOI DOI 10.1016/J.IPM.2016.04.003
   BAVELAS A, 1950, J ACOUST SOC AM, V22, P723
   Bhattacharya D, 2012, 2012 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P966, DOI 10.1109/ASONAM.2012.170
   BONACICH P, 1987, AM J SOCIOL, V92, P1170, DOI 10.1086/228631
   Borgatti SP, 2005, SOC NETWORKS, V27, P55, DOI 10.1016/j.socnet.2004.11.008
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Conti M, 2014, LECT NOTES COMPUT SC, V8805, P311, DOI 10.1007/978-3-319-14325-5_27
   FREEMAN LC, 1979, SOC NETWORKS, V1, P215, DOI 10.1016/0378-8733(78)90021-7
   FREEMAN LC, 1977, SOCIOMETRY, V40, P35, DOI 10.2307/3033543
   Guille A, 2013, SIGMOD REC, V42, P17
   HAGE P, 1995, SOC NETWORKS, V17, P57, DOI 10.1016/0378-8733(94)00248-9
   Kwak H., WWW'10, DOI DOI 10.1145/1772690.1772751
   Myers SA, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P493, DOI 10.1145/2567948.2576939
   NIEMINEN J, 1974, SCAND J PSYCHOL, V15, P332, DOI 10.1111/j.1467-9450.1974.tb00598.x
   SHIMBEL ALFONSO, 1953, BULL MATH BIOPHYS, V15, P501, DOI 10.1007/BF02476438
NR 19
TC 11
Z9 12
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3395
EP 3407
DI 10.1007/s11042-018-6728-4
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600040
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Liang, D
   Lu, C
   Jin, H
AF Liang, Dong
   Lu, Chen
   Jin, Hao
TI Soft multimedia anomaly detection based on neural network and
   optimization driven support vector machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Soft multimedia; Anomaly detection; Neural network; Support vector
   machine
ID SPARSE REPRESENTATION; CLASSIFICATION; FUSION; MODEL
AB Software multimedia anomaly detection model based on neural network and optimization driven support vector machine is discussed in this paper. For multimedia information, most traditional information security technology has its limitations. For example, the limitation of the encryption technology is that on the one hand, the encrypted files resulting from the incomprehension of attributes interfere with the transfer of multimedia information. On the other hand, the encrypted multimedia information is likely to attract the attacker's curiosity and attention, and is likely to be cracked, and once it is cracked, the system loses control of the information. To deal with these challenges, this study integrates soft computing techniques to finalize the enhanced multimedia anomaly detection model. With respect to the neural network, a random system with random factors is referred to as a random system. These practical systems are generally described and modeled by stochastic differential equations. In this study, we combined the double support vector machine and decision tree support vector machine to construct a new double support vector machine decision tree classifier. Kernel function and convex optimization were integrated to guarantee an optimal solution. Experimental results demonstrated the robustness of the model compared with other recent techniques.
C1 [Liang, Dong; Lu, Chen; Jin, Hao] BUPT, Minist Educ, Key Lab Universal Wireless Commun, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Liang, D (corresponding author), BUPT, Minist Educ, Key Lab Universal Wireless Commun, Beijing, Peoples R China.
EM liangdongcn@yahoo.com
RI Dong, Liang/JZD-4605-2024
CR Bakshi S, 2018, MULTIMED TOOLS APPL, V77, P17595, DOI 10.1007/s11042-017-4965-6
   Bengio Y., 2013, ADV NEURAL INFORM PR
   Bhattacharya I, 2017, ADV INTELL SYST, V469, P621, DOI 10.1007/978-981-10-1678-3_59
   Callegari C, 2014, INT J COMMUN SYST, V27, P1731, DOI 10.1002/dac.2432
   Chang XJ, 2014, AAAI CONF ARTIF INTE, P1171
   Chen MM, 2014, PR MACH LEARN RES, V32, P1476
   Chen ZQ, 2017, NEUROCOMPUTING, V226, P262, DOI 10.1016/j.neucom.2016.12.004
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dai L, 2014, PROC SPIE, V9159, DOI 10.1117/12.2064052
   Dong LP, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P266, DOI 10.1109/ICDSP.2016.7868559
   El Aboudi N, 2017, INT J CLOUD APPL COM, V7, P57, DOI 10.4018/IJCAC.2017010104
   Gupta BB, 2017, INT J CLOUD APPL COM, V7, P1, DOI 10.4018/IJCAC.2017010101
   Ibtihal M, 2017, INT J CLOUD APPL COM, V7, P27, DOI 10.4018/IJCAC.2017040103
   Jain DK, 2018, J COMPUT SCI-NETH, V25, P252, DOI 10.1016/j.jocs.2017.07.016
   Jiang DD, 2016, MULTIMED TOOLS APPL, V75, P14281, DOI 10.1007/s11042-016-3402-6
   Jin R, 2013, IEEE T INFORM THEORY, V59, P6939, DOI 10.1109/TIT.2013.2271378
   Kim UH, 2014, MULTIMED TOOLS APPL, V71, P627, DOI 10.1007/s11042-013-1673-8
   Kirar JS, 2017, BIOMED SIGNAL PROCES, V33, P151, DOI 10.1016/j.bspc.2016.09.014
   Kumar D, 2017, VISUAL COMPUT, V33, P265, DOI 10.1007/s00371-015-1192-x
   Long J., 2016, STRUCTURAL CONTROL A
   Luo FL, 2017, PHOTOGRAMM ENG REM S, V83, P37, DOI 10.14358/PERS.83.1.37
   Mustafa H, 2014, J COMPUT COMMUN, V2, P1
   Muthuramalingam S, 2016, MULTIMED TOOLS APPL, V75, P13627, DOI 10.1007/s11042-015-2984-8
   Nan SY, 2017, IEEE T NEUR NET LEAR, V28, P94, DOI 10.1109/TNNLS.2015.2504382
   Rajasegarar S, 2014, PATTERN RECOGN, V47, P2867, DOI 10.1016/j.patcog.2014.04.006
   Salimi-Khorshidi G, 2014, NEUROIMAGE, V90, P449, DOI 10.1016/j.neuroimage.2013.11.046
   Sangaiah AK, 2018, COMPUT ELECTR ENG, V71, P833, DOI 10.1016/j.compeleceng.2017.07.022
   See J., 2014, P IM VIS COMP NZ IVC, P224
   Sermpinis G, 2017, EUR J OPER RES, V258, P372, DOI 10.1016/j.ejor.2016.09.005
   Shi Y, 2017, EXPERT SYST APPL, V72, P121, DOI 10.1016/j.eswa.2016.12.012
   Sonntag D, 2017, SP SER WIRELESS TECH, P487, DOI 10.1007/978-3-319-42559-7_19
   Tan P, 2016, J CHEM ENG JPN, V49, P211, DOI 10.1252/jcej.15we066
   Wang HX, 2014, PROC INT C TOOLS ART, P853, DOI 10.1109/ICTAI.2014.131
   Wang ZY, 2017, SIGNAL PROCESS, V133, P144, DOI 10.1016/j.sigpro.2016.10.022
   Yonggang Lu, 2017, Multimedia Tools and Applications, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Yoo H, 2015, MULTIMED TOOLS APPL, V74, P303, DOI 10.1007/s11042-014-1870-0
   Zhang SW, 2017, CLUSTER COMPUT, V20, P1517, DOI 10.1007/s10586-017-0859-7
   Zhang YX, 2016, IEEE T GEOSCI REMOTE, V54, P1376, DOI 10.1109/TGRS.2015.2479299
   Zhao J, 2014, IEEE T VIS COMPUT GR, V20, P1773, DOI 10.1109/TVCG.2014.2346922
   Zhu XB, 2014, PATTERN RECOGN, V47, P1791, DOI 10.1016/j.patcog.2013.11.018
   Zou L, 2017, DIGIT SIGNAL PROCESS, V62, P125, DOI 10.1016/j.dsp.2016.10.017
NR 41
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4131
EP 4154
DI 10.1007/s11042-017-5352-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200014
DA 2024-07-18
ER

PT J
AU Nanda, A
   Chauhan, DS
   Sa, PK
   Bakshi, S
AF Nanda, Aparajita
   Chauhan, Dushyant Singh
   Sa, Pankaj K.
   Bakshi, Sambit
TI Illumination and scale invariant relevant visual features with
   hypergraph-based learning for multi-shot person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance; Person re-identification; Illumination variations;
   Scale variations; Multi-camera; Multi-class group LASSO; Hypergraph
   learning
ID CLASSIFICATION
AB Person re-identification which aims at matching people across disjoint cameras has received increasing attention due to the widespread use of video surveillance applications. Existing methods concentrate either on robust feature extraction or view-invariant feature transformation. However, the extracted features suffer from various limitations such as color inconsistency and scale variations. Besides, during matching, a probe is compared against each gallery instance which represents only the pairwise relationship and ignores the high order relationship among them. To address these issues, we propose a multi-shot person re-identification framework that first performs a preprocessing task on images to address illumination variations for maintaining the color consistency. Subsequently, we formulate an approach to handle scale variations in the pedestrian appearances for keeping them with relatively a fixed scale ratio. Overlapped visual patches representing appearance cues are then extracted from the processed images. A structured multi-class feature selection approach is employed to select a set of relevant patches that simultaneously discriminates all distinct persons. These selected patches use a hypergraph to represent the visual association among a probe and gallery images. Finally, for matching, we formulate a hypergraph-based learning scheme, which considers both the pairwise and high-order association among the probe and gallery images. The hypergraph structure is then optimized to yield an improved similarity score for a probe against each gallery instance. The effectiveness of our proposed framework is validated on three public datasets and comparison with state-of-the-art methods shows the superior performance of our framework.
C1 [Nanda, Aparajita; Chauhan, Dushyant Singh; Sa, Pankaj K.; Bakshi, Sambit] Natl Inst Technol Rourkela, Dept Comp Sci & Engn, Rourkela 769008, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Nanda, A (corresponding author), Natl Inst Technol Rourkela, Dept Comp Sci & Engn, Rourkela 769008, India.
EM aparajita1.nanda@gmail.com; dushyantchauhan27@gmail.com;
   pankajksa@nitrkl.ac.in; bakshisambit@nitrkl.ac.in
RI Bakshi, Sambit/JDC-3355-2023; K, Pankaj/A-9362-2017
OI Bakshi, Sambit/0000-0002-6107-114X; Sa, Pankaj/0000-0002-8362-3873
FU Science and Engineering Research Board (SERB), Department of Science &
   Technology, Government of India [SB/FTP/ETA-0059/2014]
FX This work is supported by Grant Number SB/FTP/ETA-0059/2014 by Science
   and Engineering Research Board (SERB), Department of Science &
   Technology, Government of India.
CR An L, 2016, NEUROCOMPUTING, V182, P247, DOI 10.1016/j.neucom.2015.12.029
   [Anonymous], 2012, PROC ASIAN C COMPUT
   [Anonymous], 2011, BRIT MACH VIS C DUND
   [Anonymous], 2006, NIPS
   Avraham Tamar, 2012, Computer Vision - ECCV 2012. Proceedings of Workshops and Demonstrations, P381, DOI 10.1007/978-3-642-33863-2_38
   Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P435, DOI 10.1109/AVSS.2010.34
   Bak S, 2012, IMAGE VISION COMPUT, V30, P443, DOI 10.1016/j.imavis.2011.08.008
   Bazzani L, 2012, PATTERN RECOGN LETT, V33, P898, DOI 10.1016/j.patrec.2011.11.016
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   da Vinci L, VINCI NOTEBOOKS, P1
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Jojic N, 2009, PROC CVPR IEEE, P2044, DOI 10.1109/CVPRW.2009.5206581
   Karanam Srikrishna, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P33, DOI 10.1109/CVPRW.2015.7301392
   Karanam S, 2015, IEEE I CONF COMP VIS, P4516, DOI 10.1109/ICCV.2015.513
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Kviatkovsky Igor, 2013, IEEE Trans Pattern Anal Mach Intell, V35, P1622, DOI 10.1109/TPAMI.2012.246
   Li Y, 2015, IEEE WINT CONF APPL, P373, DOI 10.1109/WACV.2015.56
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, C ART INT
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu YF, 2017, MATH MECH SOLIDS, V22, P1997, DOI 10.1177/1081286516653272
   Ma BP, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.57
   Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41
   Ma BP, 2014, IMAGE VISION COMPUT, V32, P379, DOI 10.1016/j.imavis.2014.04.002
   Martinel N, 2015, LECT NOTES COMPUT SC, V8927, P191, DOI 10.1007/978-3-319-16199-0_14
   Martinel N, 2015, IEEE SIGNAL PROC LET, V22, P455, DOI 10.1109/LSP.2014.2362573
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42
   Tao DP, 2015, IEEE T CYBERNETICS, V45, P242, DOI 10.1109/TCYB.2014.2323992
   van de Weijer J, 2006, LECT NOTES COMPUT SC, V3952, P334
   Vezzani R, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543596
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wu Y, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.134
   Wu Y, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P140, DOI 10.1109/ACPR.2013.14
   Wu Y, 2012, LECT NOTES COMPUT SC, V7574, P497, DOI 10.1007/978-3-642-33712-3_36
   Wu ZY, 2015, IEEE T PATTERN ANAL, V37, P1095, DOI 10.1109/TPAMI.2014.2360373
   Xie Y, 2015, IEEE SIGNAL PROC LET, V22, P1854, DOI 10.1109/LSP.2015.2440294
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
   Zini L, 2015, PATTERN RECOGN LETT, V55, P35, DOI 10.1016/j.patrec.2014.07.004
NR 50
TC 18
Z9 18
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 3885
EP 3910
DI 10.1007/s11042-017-4875-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200003
DA 2024-07-18
ER

PT J
AU Pollacci, L
   Guidotti, R
   Rossetti, G
   Giannotti, F
   Pedreschi, D
AF Pollacci, Laura
   Guidotti, Riccardo
   Rossetti, Giulio
   Giannotti, Fosca
   Pedreschi, Dino
TI The italian music superdiversity: Geography, emotion and language: one
   resource to find them, one resource to rule them all
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music data analytics; Sentiment pattern discovery; Music sentiment
   analytics; Multi-source analytics; Music sentiment analysis;
   Superdiversity
AB Globalization can lead to a growing standardization of musical contents. Using a cross-service multi-level dataset we investigate the actual Italian music scene. The investigation highlights the musical Italian superdiversity both individually analyzing the geographical and lexical dimensions and combining them. Using different kinds of features over the geographical dimension leads to two similar, comparable and coherent results, confirming the strong and essential correlation between melodies and lyrics. The profiles identified are markedly distinct one from another with respect to sentiment, lexicon, and melodic features. Through a novel application of a sentiment spreading algorithm and songs' melodic features, we are able to highlight discriminant characteristics that violate the standard regional political boundaries, reconfiguring them following the actual musical communicative practices.
C1 [Pollacci, Laura; Guidotti, Riccardo; Rossetti, Giulio; Pedreschi, Dino] Univ Pisa, Dept Comp Sci, Pisa, Italy.
   [Guidotti, Riccardo; Rossetti, Giulio; Giannotti, Fosca] CNR, ISTI, Pisa, Italy.
C3 University of Pisa; Consiglio Nazionale delle Ricerche (CNR); Istituto
   di Scienza e Tecnologie dell'Informazione "Alessandro Faedo" (ISTI-CNR)
RP Pollacci, L (corresponding author), Univ Pisa, Dept Comp Sci, Pisa, Italy.
EM laura.pollacci@di.unipi.it; riccardo.guidotti@isti.cnr.it;
   giulio.rossetti@isti.cnr.it; fosca.giannotti@isti.cnr.it;
   dino.pedreschi@unipi.it
RI Rossetti, Giulio/AAH-7567-2020; Guidotti, Riccardo/ABB-9074-2021
OI Rossetti, Giulio/0000-0003-3373-1240; Guidotti,
   Riccardo/0000-0002-2827-7613; Pollacci, Laura/0000-0001-9914-1943;
   PEDRESCHI, DINO/0000-0003-4801-3225
FU European Community [GS501100001809, 654024]
FX This work is supported by the European Community's H2020 Program under
   the funding scheme "INFRAIA-1-2014-2015: Research Infrastructures" grant
   agreement, http://www.sobigdata.eu, GS501100001809, 654024 "SoBigData:
   Social Mining & Big Data Ecosystem".
CR [Anonymous], 2009, American music
   [Anonymous], 1999, TECH REP
   [Anonymous], 2008, ISMIR
   [Anonymous], 2014, 9 WEB CORP WORKSH WA, DOI [10.3115/v1/w14-0406, 10.3115/v1/W14-0406]
   [Anonymous], 2006, 0625 U OXF SCH ANTHR
   Bischoff K., 2009, ISMIR, P657
   C ano E., 2017, P 2017 INT C INT SYS, P118
   Cano E., 2017, MUSIC MOOD DATASET C
   Celma O, 2010, MUSIC RECOMMENDATION AND DISCOVERY, P43, DOI 10.1007/978-3-642-13287-2_3
   Dodds PS, 2010, J HAPPINESS STUD, V11, P441, DOI 10.1007/s10902-009-9150-9
   Guerini M., 2013, ARXIV13095843
   Helmholz P, SUMMER HOT WINTER NO
   Hu X., 2010, ISMIR, P619
   Hu X., 2008, Proceedings of the International Society for Music Information Retrieval Conference, P462
   Hu X., 2007, P 8 INT C MUSIC INFO, P67
   Lamere P., 2008, ISMIR 2008, P24
   Laurier C., 2009, ISMIR, P381
   Lee JinHa., 2012, Proceedings Of The 12th ACM /IEEE-CS Joint Conference On Digital Libraries, JCDL '12, P129
   Li Tao., 2004, P 12 ANN ACM INT C M, P364
   Malheiro R., 2016, 8 INT C KNOWL DISC I
   Mihalcea Rada., 2012, P 2012 JOINT C EMPIR, P590
   Perna S., 2016, AIDAINFORMAZIONI, V1, P209
   PODIUC RE, INFERRING SONG MOODS
   Pollacci L, 2016, 9 INT WORKSH MACH LE
   Pollacci L, 2017, INT C SMART OBJ TECH, P183
   Pollacci L, 2017, LECT NOTES ARTIF INT, V10640, P114, DOI 10.1007/978-3-319-70169-1_9
   Rawlings D., 1997, Psychology of Music, V25, P120, DOI [DOI 10.1177/0305735697252003, 10.1177/0305735697252003]
   Rentfrow PJ, 2003, J PERS SOC PSYCHOL, V84, P1236, DOI 10.1037/0022-3514.84.6.1236
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Schedl M., 2013, 4 ACM MULT SYST C OS, P78
   Schmid H., 1995, P ACL SIGDAT WORKSHO
   Schmid H., 2013, New methods in lan-guage processing, P154
   Sebastiani F., 2007, Evaluation, V17, P1
   Turnbull D, 2008, IEEE T AUDIO SPEECH, V16, P467, DOI 10.1109/TASL.2007.913750
   Vertovec S, 2007, ETHNIC RACIAL STUD, V30, P1024, DOI 10.1080/01419870701599465
NR 35
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3297
EP 3319
DI 10.1007/s11042-018-6511-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600036
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Tian, F
   Liu, XM
   Liu, ZX
   Sun, N
   Wang, M
   Wang, HC
   Zhang, FQ
AF Tian, Feng
   Liu, Xianmei
   Liu, Zhuoxuan
   Sun, Ning
   Wang, Mei
   Wang, Haochang
   Zhang, Fengquan
TI Multimedia integrated annotation based on common space learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia annotation; Automatic annotation; Common space leaning
ID IMAGE TAG REFINEMENT; RELEVANCE; MODEL; COMPLETION; RETRIEVAL; FEATURES
AB Multimedia automatic annotation, which assigns text labels to multimedia objects, has been widely studied. However, existing methods usually focus on modeling two types of media data or pairwise correlation. In fact, heterogeneous media are complementary to each other and optimizing them simultaneously can further improve accuracy. In this paper, a novel common space learning (CSL) algorithm for multimedia integrated annotation is presented, by which heterogeneous media data can be projected into a unified space and multimedia annotation is transformed to the nearest neighbor search in the space. Optimizing these heterogeneous media simultaneously makes the heterogeneous media complementary to each other and aligned in the common space. We solve the proposed CSL as an optimization problem mainly considering the following issues. First, different types of media objects with the similar labels should be closer in the common space. Second, the media similarity of the original space and the common space should be consistent. We attempt to solve the optimization problem in a sparse and semi-supervised learning framework, thus more unlabeled data can be integrated into the learning process, which can boost the performance of space learning. In addition, we proposed an iterative optimization algorithm to solve the problem. Since the projected samples in the common space share the same representation, the labels for new media object are assigned by a simple nearest neighbor voting mechanism. To the best of our knowledge, our method has made the first attempt to multimedia integrated annotation. Experiments on data sets with up to four media types (image, sound, video and 3D model) show the effectiveness of our proposed approach, as compared with the state-of-the-art methods.
C1 [Tian, Feng; Liu, Xianmei; Liu, Zhuoxuan; Sun, Ning; Wang, Mei; Wang, Haochang] Northeast Petr Univ, Sch Comp & Informat Technol, Daqing 163318, Peoples R China.
   [Tian, Feng] Natl Univ Singapore, Sch Comp, Singapore 119077, Singapore.
   [Zhang, Fengquan] North China Univ Technol, Sch Comp Sci, Beijing 100144, Peoples R China.
C3 Northeast Petroleum University; National University of Singapore; North
   China University of Technology
RP Tian, F (corresponding author), Northeast Petr Univ, Sch Comp & Informat Technol, Daqing 163318, Peoples R China.; Tian, F (corresponding author), Natl Univ Singapore, Sch Comp, Singapore 119077, Singapore.
EM tianfeng1980@163.com; liuxianmei78@gmail.com; 275349032@qq.com;
   sunnepu16@163.com; wangmay@nepu.edu.cn; wanghc@nepu.edu.cn;
   daiqing74@163.com
RI Sun, Ning/HLX-6289-2023
FU Natural Science Foundation of China [61502094,61402099,61402016];
   Natural Science Foundation of Heilongjiang Province of China [F2015020];
   Beijing Natural Science Foundation [4154067]
FX Special thanks should go to the collaborators in the Lab for Media
   Search of National University of Singapore, for their instructive advice
   and useful suggestions on this work. This work is supported by the
   Natural Science Foundation of China (No.61502094,61402099,61402016),
   Natural Science Foundation of Heilongjiang Province of China
   (No.F2016002,F2015020) and Beijing Natural Science Foundation
   (No.4154067).
CR [Anonymous], P EL IM
   [Anonymous], 2003, P ACM INT C MULT ACM
   [Anonymous], 2004, P 12 ANN ACM INT C M, DOI [10.1145/1027527.1027608, DOI 10.1145/1027527.1027608]
   [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], 2017, IEEE ICASSP
   [Anonymous], 2013, P 21 ACM INT C MULT
   [Anonymous], THESIS
   [Anonymous], 2008, Proceedings of the 9th International Workshop on Multimedia Data Mining: held in conjunction with the ACM SIGKDD 2008
   [Anonymous], P 2 ACM WORKSH MULT
   [Anonymous], INT C MULT RETR ICMR
   [Anonymous], P IEEE COMP SOC C CO
   [Anonymous], 2010, P ACM MULTIMEDIA
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Battiato S, 2009, MULTIMED TOOLS APPL, V42, P5, DOI 10.1007/s11042-008-0250-z
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen L, 2012, IEEE T MULTIMEDIA, V14, P1057, DOI 10.1109/TMM.2012.2187435
   Feng ZY, 2014, LECT NOTES COMPUT SC, V8695, P424, DOI 10.1007/978-3-319-10584-0_28
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hu YQ, 2009, IEEE T MULTIMEDIA, V11, P1434, DOI 10.1109/TMM.2009.2032676
   Jeon J., 2003, P 26 ANN INT ACM SIG
   Kalayeh MM, 2014, PROC CVPR IEEE, P184, DOI 10.1109/CVPR.2014.31
   Kennedy L., 2009, Proc. Workshop on Web-scale Multimedia Corpus, P17
   Khoshneshin M., 2010, P 4 ACM C RECOMMENDE, P87
   Kidron E, 2005, PROC CVPR IEEE, P88
   Kuo YH, 2012, IEEE T MULTIMEDIA, V14, P1079, DOI 10.1109/TMM.2012.2190386
   Lee S, 2014, MULTIMED TOOLS APPL, V72, P1363, DOI 10.1007/s11042-013-1439-3
   Li XR, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2906152
   Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598
   Liu AA, 2017, IEEE T CYBERNETICS, V47, P1781, DOI 10.1109/TCYB.2016.2582918
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Liu D., 2010, Proceedings of ACM International Conference on Multimedea, P25
   Liu J, 2013, NEUROCOMPUTING, V119, P3, DOI 10.1016/j.neucom.2012.02.052
   Liu Y., 2010, Proc. ACM International Conference on Image and Video Re- trieval, P89, DOI DOI 10.1145/1816041.1816057
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Nie WZ, 2016, MULTIMEDIA SYST, V22, P75, DOI 10.1007/s00530-014-0394-9
   Pan J-Y, 2004, P 10 ACM SIGKDD INT, P653, DOI DOI 10.1145/1014052.1014135
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Richter F, 2012, MULTIMED TOOLS APPL, V56, P35, DOI 10.1007/s11042-010-0554-7
   Rui X., 2007, Proc. 15th ACM intl. conf. on multimedia, P585, DOI DOI 10.1145/1291233.1291378
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P883, DOI 10.1109/TMM.2012.2188782
   Simonyan K., 2014, 14091556 ARXIV
   Verbeek J., 2010, Proc. ACM Multimedia Information Retrieval, P537
   Wang JD, 2014, COMPUT VIS IMAGE UND, V124, P61, DOI 10.1016/j.cviu.2014.02.011
   Wang M, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2333112.2333120
   Wu L, 2013, IEEE T PATTERN ANAL, V35, P716, DOI 10.1109/TPAMI.2012.124
   Wu P., 2013, P 21 ACM INT C MULT, P153, DOI DOI 10.1145/2502081.2502112
   Xia H., 2013, ACM INT C WEB SEARCH, P455
   Xu X., 2014, DATE, P349, DOI DOI 10.1080/00207543.2014.937013
   Yang Y, 2008, IEEE T MULTIMEDIA, V10, P437, DOI 10.1109/TMM.2008.917359
   Yang Yi., 2009, Proceedings of the 17th ACM international conference on Multimedia, P175
   Zbou BL, 2015, PROC CVPR IEEE, P1492, DOI 10.1109/CVPR.2015.7298756
   Zhu XF, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P223, DOI 10.1145/2600428.2609556
   Zhuang YT, 2008, IEEE T MULTIMEDIA, V10, P221, DOI 10.1109/TMM.2007.911822
   Znaidia A, 2012, INT C PATT RECOG, P1509
NR 60
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 437
EP 456
DI 10.1007/s11042-017-5068-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500023
DA 2024-07-18
ER

PT J
AU Yoon, SA
   Son, GY
   Kwon, S
AF Yoon, Shin-ae
   Son, Guiyoung
   Kwon, Soonil
TI Fear emotion classification in speech by acoustic and behavioral cues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotional speech classification; Emergency situation; Behavioral cue;
   Disfluency(interjection); Speech signal processing
ID VOCAL EXPRESSION; RECOGNITION; COMMUNICATION; DISCRETE; FEATURES
AB Machine-based emotional speech classification has become a requirement for natural and familiar human-computer interactions. Because emotional speech recognition systems use a person's voice to spontaneously detect their emotional status and take subsequent appropriate actions, they can be used widely for various reason in call centers and emotional based media services. Emotional speech recognition systems are primarily developed using emotional acoustic data. While there are several emotional acoustic databases available for emotion recognition systems in other countries, there is currently no real situational data related to the fear emotion available. Thus, in this study, we collected acoustic data recordings which represent real urgent and fearful situations from an emergency call center. To classify callers' emotions more accurately, we also included the additional behavioral feature interjection which can be classified as a type of disfluency which arises due to cognitive dysfunction observed in spontaneous speech when a speaker gets hyperemotional. We used Support Vector Machines (SVM), with the interjections feature, as well as conventionally used acoustic features (i.e., F0 variability, voice intensity variability, and Mel-Frequency Cepstral Coefficients; MFCCs) to identify which emotional category acoustic data fell into. The results of our study revealed that the MFCC was the best acoustic feature for spontaneous fear speech classification. In addition, we demonstrated the validity of behavioral features as an important criteria for emotional classification improvement.
C1 [Yoon, Shin-ae; Son, Guiyoung; Kwon, Soonil] Sejong Univ, Coll Software & Convergence Technol, Dept Software, 209 Neung Dong Ro, Seoul 05006, South Korea.
C3 Sejong University
RP Kwon, S (corresponding author), Sejong Univ, Coll Software & Convergence Technol, Dept Software, 209 Neung Dong Ro, Seoul 05006, South Korea.
EM sgy1017@sejong.ac.kr; sikwon@sejong.ac.kr; skwon@sejong.edu
OI KWON, SOONIL/0000-0001-5451-8815
FU Institute for Information & communications Technology Promotion (IITP) -
   Korea government (MSIT)
FX This work was supported by Institute for Information & communications
   Technology Promotion (IITP) grant funded by the Korea government (MSIT)
   (No.2017-0-00189, Voice emotion recognition and indexing for affective
   multimedia service)
CR [Anonymous], 2012, INT J SMART HOME
   [Anonymous], 1980, THEORIES EMOTION
   [Anonymous], INFORM MEDIA TECHNOL
   [Anonymous], 2005, Proceedings of INTERSPEECH
   [Anonymous], 2010, INT J COMPUT APPL
   Barrett LF, 1998, COGNITION EMOTION, V12, P579, DOI 10.1080/026999398379574
   Batliner A., 2000, DESPERATELY SEEKING
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Corley M, 2008, LANG LINGUIST COMPAS, V2, DOI 10.1111/j.1749-818x.2008.00068.x
   Davison GC, 1997, J CONSULT CLIN PSYCH, V65, P950, DOI 10.1037/0022-006X.65.6.950
   Devillers L, 2005, NEURAL NETWORKS, V18, P407, DOI 10.1016/j.neunet.2005.03.007
   DEVILLERS L, 2004, P SPEECH PROSODY, P205
   Dibble JL, 2015, COMMUN RES, V42, P213, DOI 10.1177/0093650212469401
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Fontaine JRJ, 2007, PSYCHOL SCI, V18, P1050, DOI 10.1111/j.1467-9280.2007.02024.x
   Forbes-Riley K, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P201
   Galanis D, 2013, INT CONF COGN INFO, P403, DOI 10.1109/CogInfoCom.2013.6719279
   Goberman AM, 2011, SPEECH COMMUN, V53, P867, DOI 10.1016/j.specom.2011.02.005
   Hamann S, 2012, TRENDS COGN SCI, V16, P458, DOI 10.1016/j.tics.2012.07.006
   Iliou T, 2009, ICDT: 2009 FOURTH INTERNATIONAL CONFERENCE ON DIGITAL TELECOMMUNICATIONS, P121, DOI 10.1109/ICDT.2009.30
   IZARD CE, 1993, J PERS SOC PSYCHOL, V64, P847, DOI 10.1037/0022-3514.64.5.847
   Juslin PN, 2003, PSYCHOL BULL, V129, P770, DOI 10.1037/0033-2909.129.5.770
   이현희, 2003, Korean Journal of Clinical Psychology, V22, P935
   Laukka P, 2005, COGNITION EMOTION, V19, P633, DOI 10.1080/02699930441000445
   Lee CM, 2005, IEEE T SPEECH AUDI P, V13, P293, DOI 10.1109/TSA.2004.838534
   Lee FM, 2008, PROCEEDINGS OF THE 7TH WSEAS INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, ROBOTICS AND AUTOMATION, P171
   Lee L-s, 2006, INTERSPEECH
   Lindsey A. E., 1995, COMMUNICATION Q, V43, P320, DOI DOI 10.1080/01463379509369979
   Lindström A, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1196
   Liscombe J., 2005, Interspeech, P1845
   Luengo I., 2005, INTERSPEECH 2005, P493
   Lugger M, 2007, INT CONF ACOUST SPEE, P17
   Mauss I, 2009, COGNITION EMOTION, V23, P209, DOI 10.1080/02699930802204677
   Mehrabian A., 1974, APPROACH ENV PSYCHOL, V12
   Metze F, 2009, UNIVERSAL ACCESS INF, V8, P97, DOI 10.1007/s10209-008-0133-0
   Morrison D, 2007, SPEECH COMMUN, V49, P98, DOI 10.1016/j.specom.2006.11.004
   Narayanan S, 2013, P IEEE, V101, P1203, DOI 10.1109/JPROC.2012.2236291
   Neiberg D, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P809
   Neiberg D, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2755
   Ostir GV, 2000, J AM GERIATR SOC, V48, P473, DOI 10.1111/j.1532-5415.2000.tb04991.x
   Panksepp J, 1989, NEUROBIOLOGY EMOTION
   Pao TL, 2006, INT C PATT RECOG, P1096
   Petrushin V., 1999, EMOTION SPEECH RECOG
   Pfister T., 2010, EMOTION DETECTION SP
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   Polzehl T, 2011, SPEECH COMMUN, V53, P1198, DOI 10.1016/j.specom.2011.05.002
   Rao KS, 2013, INT J SPEECH TECHNOL, V16, P143, DOI 10.1007/s10772-012-9172-2
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   Rv B, 1984, CHARACTERISTICS RECO
   Sahidullah M, 2012, SPEECH COMMUN, V54, P543, DOI 10.1016/j.specom.2011.11.004
   Salovey P., 2004, FEELINGS EMOTIONS AM
   Schuller B, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P577
   Schuller B, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P401
   Schuller B, 2011, SPEECH COMMUN, V53, P1062, DOI 10.1016/j.specom.2011.01.011
   Tahon M, 2011, INTERSPEECH
   Utane AS, 2013, IJARCSSE, V3
   Ververidis D, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P593
   Vidrascu L, 2005, MULT EXP 2005 ICME 2, P4
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   WINGATE ME, 1984, J FLUENCY DISORD, V9, P163, DOI 10.1016/0094-730X(84)90033-0
   Xia Mao, 2009, 2009 WRI World Congress on Computer Science and Information Engineering, CSIE, P225, DOI 10.1109/CSIE.2009.113
   Xiao ZZ, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P411
   Yik MSM, 1999, J PERS SOC PSYCHOL, V77, P600, DOI 10.1037/0022-3514.77.3.600
   Zhang SQ, 2008, LECT NOTES COMPUT SC, V5264, P457
   Zhu AQ, 2007, LECT NOTES COMPUT SC, V4552, P544
   [No title captured]
NR 67
TC 5
Z9 7
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2345
EP 2366
DI 10.1007/s11042-018-6329-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700046
DA 2024-07-18
ER

PT J
AU Ma, YR
   Peng, YJ
AF Ma, Yingran
   Peng, Yanjun
TI A level set method based on local direction gradient for image
   segmentation with intensity inhomogeneity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Image gradient; Level set method; Intensity
   inhomogeneity
ID BIAS FIELD ESTIMATION; ACTIVE CONTOURS; EVOLUTION; INFORMATION; MODELS
AB Many medical and real images are suffered from intensity inhomogeneity and weak edges. For higher image segmentation quality, lots of level set-based methods have been proposed. Some of them however cannot take advantage of image gradient information. And severe intensity inhomogeneity and weak edges are not disposed properly. To address these problems, a new level set method integrated with local direction gradient information is presented in this paper. Firstly, according to the two assumptions on image intensity inhomogeneity adopted by many existing methods, a new pixel classification model based on image gradient is introduced. Secondly, we employ variational level set method combined with image spatial information, which improves the anti-noise capability of the proposed method. Finally, considering the gray gradients in homogeneous regions are close to constants, an improved diffusion process is incorporated into the level set function to make the evolving curves stay around true image edges. To verify our method, different testing images including synthetic images, magnetic resonance imaging (MRI) and real-world images are introduced. The image segmentation results demonstrate that our method can deal with the relatively severe intensity inhomogeneity and obtain the comparatively ideal segmentation results efficiently.
C1 [Ma, Yingran; Peng, Yanjun] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
   [Peng, Yanjun] Shandong Univ Sci & Technol, Shandong Prov Key Lab Wisdom Min Informat Technol, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Peng, YJ (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.; Peng, YJ (corresponding author), Shandong Univ Sci & Technol, Shandong Prov Key Lab Wisdom Min Informat Technol, Qingdao 266590, Peoples R China.
EM pengyanjuncn@163.com
FU National key research and development project of China [2016YFC0801406];
   Natural Science Foundation of Shandong Province [ZR2015FM013]; National
   Natural Science Foundation of China [61502279]; National key research
   and development project of the Shandong Province [2016GSF120012];
   Special Project Fund of Taishan Scholars of Shandong Province, Leading
   Talent Project of Shandong University of Science and Technology
FX This work is supported by the National key research and development
   project of China under Grant No.2016YFC0801406, the Natural Science
   Foundation of Shandong Province under Grant No. ZR2015FM013, the
   National Natural Science Foundation of China under Grant No. 61502279,
   the National key research and development project of the Shandong
   Province under Grant No. 2016GSF120012, and by Special Project Fund of
   Taishan Scholars of Shandong Province, Leading Talent Project of
   Shandong University of Science and Technology.
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   [Anonymous], 0504 UCLA CAM
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Brox T, 2009, INT J COMPUT VISION, V84, P184, DOI 10.1007/s11263-008-0153-5
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chang HB, 2017, IEEE T MED IMAGING, V36, P721, DOI 10.1109/TMI.2016.2636026
   Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165
   CHOPP DL, 1993, J COMPUT PHYS, V106, P77, DOI 10.1006/jcph.1993.1092
   Chuang KS, 2006, COMPUT MED IMAG GRAP, V30, P9, DOI 10.1016/j.compmedimag.2005.10.001
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Duan YP, 2015, IEEE T IMAGE PROCESS, V24, P3927, DOI 10.1109/TIP.2015.2451957
   Huang J, 2009, SIGNAL PROCESS, V89, P2630, DOI 10.1016/j.sigpro.2009.05.001
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Konyushkova K, 2015, IEEE I CONF COMP VIS, P2974, DOI 10.1109/ICCV.2015.340
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Li C., 2007, IEEE C COMPUTER VISI, P1
   Li CM, 2014, MAGN RESON IMAGING, V32, P913, DOI 10.1016/j.mri.2014.03.010
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Li CM, 2005, PROC CVPR IEEE, P430
   Likar B, 2001, IEEE T MED IMAGING, V20, P1398, DOI 10.1109/42.974934
   Liu Y., 2016, 2016 3 INT C ARTIFIC, V2016, P2576
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Peng DP, 1999, J COMPUT PHYS, V155, P410, DOI 10.1006/jcph.1999.6345
   Shattuck DW, 2001, NEUROIMAGE, V13, P856, DOI 10.1006/nimg.2000.0730
   Shujian Yu, 2013, International Journal of Machine Learning and Computing, V3, P158, DOI 10.7763/IJMLC.2013.V3.293
   SUSSMAN M, 1994, J COMPUT PHYS, V114, P146, DOI 10.1006/jcph.1994.1155
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wang LF, 2017, IEEE IMAGE PROC, P4412, DOI 10.1109/ICIP.2017.8297116
   Xie XH, 2010, IEEE T IMAGE PROCESS, V19, P154, DOI 10.1109/TIP.2009.2032891
   Yang Y, 2015, INT J COMPUT VISION, V113, P113, DOI 10.1007/s11263-014-0781-x
   Yang Y, 2010, IEEE T IMAGE PROCESS, V19, P2761, DOI 10.1109/TIP.2010.2049235
   You XG, 2011, PATTERN RECOGN, V44, P2314, DOI 10.1016/j.patcog.2011.01.007
   Zhang KH, 2016, IEEE T CYBERNETICS, V46, P546, DOI 10.1109/TCYB.2015.2409119
   Zhang KH, 2013, IEEE T IMAGE PROCESS, V22, P258, DOI 10.1109/TIP.2012.2214046
   Zhao HK, 1996, J COMPUT PHYS, V127, P179, DOI 10.1006/jcph.1996.0167
NR 41
TC 2
Z9 2
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30703
EP 30727
DI 10.1007/s11042-018-6154-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600026
DA 2024-07-18
ER

PT J
AU Nasiri, M
   Behrad, A
AF Nasiri, Morteza
   Behrad, Alireza
TI Exposing forgeries in soccer images using geometric clues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Forgery detection; Automatic camera calibration; Soccer
   image analysis
ID CAMERA CALIBRATION TECHNIQUE; DIGITAL IMAGES; JPEG; ENVIRONMENTS;
   ALGORITHM; METROLOGY; TRACKING; POINTS; NOISE; PRNU
AB In this study, new algorithms are proposed for exposing forgeries in soccer images. We propose a new and automatic algorithm to extract the soccer field, field side and the lines of field in order to generate an image of real lines for forensic analysis. By comparing the image of real lines and the lines in the input image, the forensic analyzer can easily detect line displacements of the soccer field. To expose forgery in the location of a player, we measure the height of the player using the geometric information in the soccer image and use the inconsistency of the measured height with the true height of the player as a clue for detecting the displacement of the player. In this study, two novel approaches are proposed to measure the height of a player. In the first approach, the intersections of white lines in the soccer field are employed for automatic calibration of the camera. We derive a closed-form solution to calculate different camera parameters. Then the calculated parameters of the camera are used to measure the height of a player using an interactive approach. In the second approach, the geometry of vanishing lines and the dimensions of soccer gate are used to measure a player height. Various experiments using real and synthetic soccer images show the efficiency of the proposed algorithms.
C1 [Nasiri, Morteza; Behrad, Alireza] Shahed Univ, Dept Elect Engn, Tehran, Iran.
C3 Shahed University
RP Behrad, A (corresponding author), Shahed Univ, Dept Elect Engn, Tehran, Iran.
EM mo.nasiri@shahed.ac.ir; behrad@shahed.ac.ir
RI Behrad, Alireza/F-8795-2018
OI Behrad, Alireza/0000-0002-1990-6668
CR Abd Warif NB, 2016, J NETW COMPUT APPL, V75, P259, DOI 10.1016/j.jnca.2016.09.008
   Amiri SH, 2014, SIGNAL PROCESS-IMAGE, V29, P1181, DOI 10.1016/j.image.2014.07.004
   [Anonymous], 2014, APSIPA T SIGNAL INF
   [Anonymous], COMPUTER VISION MULT
   Babaee-Kashany V, 2010, IEEE INT S HAPT AUD, P1
   Battikh T, 2011, MULTIMED TOOLS APPL, V51, P997, DOI 10.1007/s11042-009-0434-1
   Bin Li, 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P730, DOI 10.1109/MMSP.2008.4665171
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Cao H, 2009, IEEE T INF FOREN SEC, V4, P899, DOI 10.1109/TIFS.2009.2033749
   CAPRILE B, 1990, INT J COMPUT VISION, V4, P127, DOI 10.1007/BF00127813
   Chen M, 2007, LECT NOTES COMPUT SC, V4567, P342
   Chen ZP, 2017, SIGNAL PROCESS-IMAGE, V57, P8, DOI 10.1016/j.image.2017.04.008
   Chierchia G, 2014, IEEE T INF FOREN SEC, V9, P554, DOI 10.1109/TIFS.2014.2302078
   Choi CH, 2013, FORENSIC SCI INT, V226, P94, DOI 10.1016/j.forsciint.2012.12.014
   Criminisi A, 2000, INT J COMPUT VISION, V40, P123, DOI 10.1023/A:1026598000963
   Desurmont X, 2006, WORKSH COMP VIS BAS, P92
   Emam M, 2018, J FORENSIC SCI, V63, P102, DOI 10.1111/1556-4029.13456
   Emam M, 2016, MULTIMED TOOLS APPL, V75, P11513, DOI 10.1007/s11042-015-2872-2
   Farid H, 2010, IS T SPIE ELECT IMAG, V2
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Farin D, 2004, PROC SPIE, V5307, P80
   Farin D., 2005, 2005 IEEE International Conference on Multimedia and Expo
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   Ge HY, 2015, 2015 INTERNATIONAL CONFERENCE ON INFORMATIVE AND CYBERNETICS FOR COMPUTATIONAL SOCIAL SYSTEMS (ICCSS), P116, DOI 10.1109/ICCSS.2015.7281160
   Hashimoto S, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1889, DOI 10.1109/ICME.2006.262924
   Hu WC, 2016, MULTIMED TOOLS APPL, V75, P3495, DOI 10.1007/s11042-015-2449-0
   Hwang MG, 2017, AUST J FORENSIC SCI, V49, P93, DOI 10.1080/00450618.2015.1128970
   Jin GN, 2017, SIGNAL PROCESS-IMAGE, V57, P113, DOI 10.1016/j.image.2017.05.010
   Johnson MK, 2007, IEEE T INF FOREN SEC, V2, P450, DOI 10.1109/TIFS.2007.903848
   Johnson Micah K, 2006, ACM WORKSHOP MULTIME, P48
   Kee E, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487236
   Khatoonabadi SH, 2009, IMAGE VISION COMPUT, V27, P469, DOI 10.1016/j.imavis.2008.06.015
   Kim H, 2001, PATTERN ANAL APPL, V4, P9, DOI 10.1007/s100440170020
   Lagarias JC, 1998, SIAM J OPTIMIZ, V9, P112, DOI 10.1137/S1052623496303470
   Li X, 2013, MATH COMPUT MODEL, V58, P85, DOI 10.1016/j.mcm.2012.06.033
   Liang ZS, 2015, J VIS COMMUN IMAGE R, V30, P75, DOI 10.1016/j.jvcir.2015.03.004
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Liu Y, 2006, IMAGE VISION COMPUT, V24, P1146, DOI 10.1016/j.imavis.2006.04.001
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Malviya P, 2014, LECT NOTES COMPUT SC, V8880, P437, DOI 10.1007/978-3-319-13841-1_25
   Mayer O, 2016, INT CONF ACOUST SPEE, P2024, DOI 10.1109/ICASSP.2016.7472032
   Meng XQ, 2003, PATTERN RECOGN, V36, P1155, DOI 10.1016/S0031-3203(02)00225-X
   Milani S, 2013, INT CONF ACOUST SPEE, P3053, DOI 10.1109/ICASSP.2013.6638219
   O'Brien JF, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2077341.2077345
   Peng F, 2014, DIGIT INVEST, V11, P111, DOI 10.1016/j.diin.2014.04.002
   Peng F, 2011, FORENSIC SCI INT, V212, pE21, DOI 10.1016/j.forsciint.2011.06.011
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406
   Qazi T, 2013, IET IMAGE PROCESS, V7, P660, DOI 10.1049/iet-ipr.2012.0388
   Saadat S, 2015, J FORENSIC SCI, V60, P1451, DOI 10.1111/1556-4029.12853
   Singh N, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION (ICSC), P413, DOI 10.1109/ICSPCom.2015.7150688
   Sirisantisamrid K., 2004, TENCON 2004. 2004 IEEE Region 10 Conference (IEEE Cat. No. 04CH37582), P677
   Szenberg F, 2001, INT C ADV PATT REC, P303, DOI DOI 10.1007/3-540-44732-6_31
   Taimori A, 2017, MULTIMED TOOLS APPL, V76, P7749, DOI 10.1007/s11042-016-3409-z
   Taimori A, 2016, J MATH IMAGING VIS, V54, P269, DOI 10.1007/s10851-015-0602-z
   Thajeel S. A., 2014, J THEORETICAL APPL I, V70, P25
   Thing VLL, 2012, 2012 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P290, DOI 10.1109/ISM.2012.61
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Zhong JL, 2017, MULTIMED TOOLS APPL, V76, P14887, DOI 10.1007/s11042-016-4201-9
NR 61
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 31363
EP 31396
DI 10.1007/s11042-018-6225-9
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600055
DA 2024-07-18
ER

PT J
AU Chen, F
   Jin, DF
   Peng, ZJ
   Jiang, GY
   Yu, M
   Chen, H
AF Chen, Fen
   Jin, Defu
   Peng, Zongju
   Jiang, Gangyi
   Yu, Mei
   Chen, Hua
TI Fast intra coding algorithm for HEVC based on depth range prediction and
   mode reduction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Intra coding; Prediction mode; CU distribution structure
ID CU SIZE DECISION; EFFICIENCY; OPTIMIZATION
AB The latest High Efficiency Video Coding (HEVC) standard only requires 50% bitrate of the H.264/AVC at the same video quality. Due to introduction of more advanced coding tools and techniques, its computational complexity rises rapidly. In this paper, we propose a novel fast Intra coding algorithm. Firstly, a novel feature is proposed to measure the complexity of video content based on the analysis of mode information obtained from a previous frame. Then, a model is built based on the relationship between this feature and Coding Tree Unit (CTU) depth range. According to the model, the unnecessary operations of Coding Unit (CU) split are skipped. Secondly, the correlation between CU distribution structure and mode selection is established. For the prediction of unlikely CU, the last few intra modes in candidate list are eliminated before rate-distortion optimization process. Experimental results demonstrate that the proposed algorithm reduces the encoding time by 43.2% with just 0.47% BD-rate increase compared with HEVC test model. Compared with other state-of-art algorithms, the proposed algorithm achieves better trade-off between complexity reduction and RD performance.
C1 [Chen, Fen; Jin, Defu; Peng, Zongju; Jiang, Gangyi; Yu, Mei; Chen, Hua] Ningbo Univ, Fac Informat Sci & Engn, Ningbo, Zhejiang, Peoples R China.
C3 Ningbo University
RP Peng, ZJ (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo, Zhejiang, Peoples R China.
EM pengzongju@126.com
RI Peng, Zongju/AAA-2914-2020; jiang, gang/KII-8233-2024; Chen,
   Fen/ABG-7013-2021
OI Peng, Zongju/0000-0001-8286-538X; 
FU Natural Science Foundation of China [61771269, 61620106012, 61671258];
   Natural Science Foundation of Zhejiang Province [LY17F010005,
   LY16F010002]; Ningbo University Research Foundation (Science)/Discipline
   Project [xkxl1502]; K.C. Wong Magna Fund in Ningbo University
FX This work is supported by the Natural Science Foundation of China
   (61771269, 61620106012, 61671258), Natural Science Foundation of
   Zhejiang Province (LY17F010005, LY16F010002) and Ningbo University
   Research Foundation (Science)/Discipline Project under Grant xkxl1502.
   It is also sponsored by K.C. Wong Magna Fund in Ningbo University.
CR Abdelrasoul M, 2017, IET IMAGE PROCESS, V11, P888, DOI 10.1049/iet-ipr.2016.0514
   Belghith F, 2015, SIVIP, P1
   Bjotegaard G., 2001, VCEGM33
   Bossen F, 2011, 6 M TOR IT
   Chen ZY, 2017, J VIS COMMUN IMAGE R, V43, P77, DOI 10.1016/j.jvcir.2016.12.007
   Correa G, 2015, IEEE T CIRC SYST VID, V25, P660, DOI 10.1109/TCSVT.2014.2363753
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Fang LY, 2017, J OPT SOC AM A, V34, P252, DOI 10.1364/JOSAA.34.000252
   Fang LY, 2015, IEEE T MED IMAGING, V34, P1306, DOI 10.1109/TMI.2014.2387336
   Fu W, 2017, IEEE T GEOSCI REMOTE, V55, P671, DOI 10.1109/TGRS.2016.2613848
   Ismail Y, 2012, IEEE T CIRC SYST VID, V22, P28, DOI 10.1109/TCSVT.2011.2148450
   Kim HS, 2016, IEEE T CIRC SYST VID, V26, P130, DOI 10.1109/TCSVT.2015.2444672
   Kim KB, 2008, IEEE T CONSUM ELECTR, V54, P1281, DOI 10.1109/TCE.2008.4637618
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Lee J, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1131, DOI 10.1109/ICME.2004.1394416
   Lee JY, 2012, IEEE T CIRC SYST VID, V22, P393, DOI 10.1109/TCSVT.2011.2163460
   Li FY, 2018, MULTIMED TOOLS APPL, V77, P17953, DOI 10.1007/s11042-017-4759-x
   Liao W, 2017, P 2016 IEEE VIS COMM, P1, DOI DOI 10.1109/VCIP.2016.7805540
   Lin WY, 2011, IEEE T CIRC SYST VID, V21, P237, DOI 10.1109/TCSVT.2011.2106290
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu XG, 2017, IEEE T CIRC SYST VID, V27, P1737, DOI 10.1109/TCSVT.2016.2556278
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu X., 2016, IEEE International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob), P1
   Marzuki I., 2016, J REAL-TIME IMAGE PR, V11, P1
   Min B, 2015, IEEE T CIRC SYST VID, V25, P892, DOI 10.1109/TCSVT.2014.2363739
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   Ramezanpour M, 2015, 2015 9TH IRANIAN CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P45, DOI 10.1109/IranianMVIP.2015.7397501
   Ruiz D, 2016, SIGNAL PROCESS-IMAGE, V44, P12, DOI 10.1016/j.image.2016.03.002
   Shang XW, 2015, IEEE IMAGE PROC, P1593, DOI 10.1109/ICIP.2015.7351069
   Shen LQ, 2014, IEEE T IMAGE PROCESS, V23, P4232, DOI 10.1109/TIP.2014.2341927
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1871
   Wang JC, 2007, IEEE T CIRC SYST VID, V17, P1414, DOI 10.1109/TCSVT.2007.903786
   Yang Y, 2015, INFORM SCIENCES, V320, P306, DOI 10.1016/j.ins.2014.11.014
   Yang Y, 2015, SIGNAL PROCESS, V112, P199, DOI 10.1016/j.sigpro.2014.07.020
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P1714, DOI 10.1109/TCSVT.2016.2556518
   Zhang Y, 2017, IEEE T CIRC SYST VID, P1
   Zhang Y, 2015, IEEE T IMAGE PROCESS, V24, P2225, DOI 10.1109/TIP.2015.2417498
   Zhao WJ, 2015, IEEE T CIRC SYST VID, V25, P1651, DOI 10.1109/TCSVT.2015.2395751
   Zhu LW, 2017, IEEE T BROADCAST, V63, P547, DOI 10.1109/TBC.2017.2711142
NR 44
TC 9
Z9 9
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28375
EP 28394
DI 10.1007/s11042-018-6011-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500026
DA 2024-07-18
ER

PT J
AU Zheng, W
   Zhu, XF
   Zhu, YH
   Hu, RY
   Lei, C
AF Zheng, Wei
   Zhu, Xiaofeng
   Zhu, Yonghua
   Hu, Rongyao
   Lei, Cong
TI Dynamic graph learning for spectral feature selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph learning; Optimization; Spectral feature selection
ID SUPPORT VECTOR MACHINES; ASSOCIATION RULES; CLASSIFICATION; REGRESSION;
   ALGORITHM
AB Previous spectral feature selection methods generate the similarity graph via ignoring the negative effect of noise and redundancy of the original feature space, and ignoring the association between graph matrix learning and feature selection, so that easily producing suboptimal results. To address these issues, this paper joints graph learning and feature selection in a framework to obtain optimal selected performance. More specifically, we use the least square loss function and an l(2,1)-norm regularization to remove the effect of noisy and redundancy features, and use the resulting local correlations among the features to dynamically learn a graph matrix from a low-dimensional space of original data. Experimental results on real data sets show that our method outperforms the state-of-the-art feature selection methods for classification tasks.
C1 [Zheng, Wei; Zhu, Xiaofeng; Hu, Rongyao; Lei, Cong] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Guangxi, Peoples R China.
   [Zhu, Yonghua] Guangxi Univ, Sch Comp Elect & Informat, Nanning 530004, Guangxi, Peoples R China.
C3 Guangxi Normal University; Guangxi University
RP Zhu, XF (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Guangxi, Peoples R China.
EM zwgxnu@163.com; seanzhuxf@gmail.com
RI zheng, wei/IQT-9639-2023; Wang, Ling/AGR-4917-2022; Zheng,
   Wei/GQQ-8951-2022; Zhu, Xiaofeng/HII-5291-2022; Hu,
   Rongyao/AAH-3834-2020
OI Wang, Ling/0000-0003-0272-2974; Zhu, Xiaofeng/0000-0001-6840-0578; Hu,
   Rongyao/0000-0001-9989-1103
FU China Key Research Program [2016YFB1000905]; China 1000-Plan National
   Distinguished Professorship; Nation Natural Science Foundation of China
   [61573270, 61672177]; Guangxi Natural Science Foundation
   [2015GXNSFCB139011]; Guang-xi High Institutions Program of Introducing
   100 High-Level Overseas Talents; Guangxi Collaborative Innovation Center
   of Multi-Source Information Integration and Intelligent Processing;
   Guangxi Bagui Teams for Innovation and Research; Research Fund of
   Guangxi Key Lab of MIMS [16-A-01-01, 16-A-01-02]; Innovation Project of
   Guangxi Graduate Education [XYCSZ2017064, XYCSZ2017067, YCSW2017065]
FX This work was supported in part by the China Key Research Program (Grant
   No: 2016YFB1000905), the China 1000-Plan National Distinguished
   Professorship, the Nation Natural Science Foundation of China (Grants
   No: 61573270, and 61672177), the Guangxi Natural Science Foundation
   (Grant No: 2015GXNSFCB139011), the Guang-xi High Institutions Program of
   Introducing 100 High-Level Overseas Talents, the Guangxi Collaborative
   Innovation Center of Multi-Source Information Integration and
   Intelligent Processing, the Guangxi Bagui Teams for Innovation and
   Research, the Research Fund of Guangxi Key Lab of MIMS (16-A-01-01 and
   16-A-01-02), the Guangxi Bagui Teams for Innovation and Research, and
   Innovation Project of Guangxi Graduate Education under grant
   XYCSZ2017064, XYCSZ2017067 and YCSW2017065.
CR [Anonymous], IEEE INT C DAT MIN
   [Anonymous], UNSUPERVISED SPECT C
   [Anonymous], DATA PREPARATION DAT
   [Anonymous], 2003, NIPS
   [Anonymous], WORKSH SPEECH NAT LA
   Boyd S., 2006, IEEE Trans Autom Control, V51, P1859, DOI DOI 10.1109/TAC.2006.884922
   Cai D., 2010, KDD, P333
   Daubechies I, 2010, COMMUN PUR APPL MATH, V63, P1, DOI 10.1002/cpa.20303
   De Wang, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8726, P306, DOI 10.1007/978-3-662-44845-8_20
   Gentile C, 2002, J MACH LEARN RES, V2, P213, DOI 10.1162/15324430260185600
   Gu Q., 2011, Proceedings of the Twenty-Second international joint conference on Artificial Intelligence, V2, P1294
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hu RY, 2017, NEUROCOMPUTING, V220, P130, DOI 10.1016/j.neucom.2016.05.081
   Jia YT, 2016, AAAI CONF ARTIF INTE, P992
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Ling Charles X., 2004, P 21 INT C MACH LEAR, P69, DOI DOI 10.1109/TSMCB.2008.2007853
   Liu HW, 2015, PATTERN RECOGN, V48, P1724, DOI 10.1016/j.patcog.2014.11.007
   Mangasarian OL, 2006, J MACH LEARN RES, V7, P1517
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Nie FP, 2017, AAAI CONF ARTIF INTE, P2422
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1302
   Nie FP, 2010, IEEE T IMAGE PROCESS, V19, P1921, DOI 10.1109/TIP.2010.2044958
   Peng HY, 2017, AAAI CONF ARTIF INTE, P2471
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Qin B, 2009, PROC INT CONF DATA, P1633, DOI 10.1109/ICDE.2009.164
   SHANG R, 2017, IEEE T CYBERNETICS, P1, DOI DOI 10.1109/ICAMMAET.2017.8186700
   Shi XS, 2015, IEEE T IMAGE PROCESS, V24, P1341, DOI 10.1109/TIP.2015.2405474
   Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2
   Tibshirani R, 2011, J R STAT SOC B, V73, P273, DOI 10.1111/j.1467-9868.2011.00771.x
   Wang L, 2008, BIOINFORMATICS, V24, P412, DOI 10.1093/bioinformatics/btm579
   Wen ZW, 2013, MATH PROGRAM, V142, P397, DOI 10.1007/s10107-012-0584-1
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wu XD, 2005, INFORM SYST, V30, P71, DOI 10.1016/j.is.2003.10.001
   Wu XD, 2004, ACM T INFORM SYST, V22, P381, DOI 10.1145/1010614.1010616
   Wu XD, 2003, IEEE T KNOWL DATA EN, V15, P353, DOI 10.1109/TKDE.2003.1185839
   Yan XW, 2009, EXPERT SYST APPL, V36, P3066, DOI 10.1016/j.eswa.2008.01.028
   Yang J, 2005, IEEE T PATTERN ANAL, V27, P230, DOI 10.1109/TPAMI.2005.33
   Zhang SC, 2005, IEEE T KNOWL DATA EN, V17, P1689, DOI 10.1109/TKDE.2005.188
   Zhang SC, 2003, INFORM SYST, V28, P691, DOI 10.1016/S0306-4379(02)00079-0
   Zhang SC, 2002, IEEE T SYST MAN CY A, V32, P515, DOI 10.1109/TSMCA.2002.804793
   Zhang Shichao., 2003, IEEE Computational Intelligence Bulletin, V2, P5
   Zhao YC, 2006, IEEE T KNOWL DATA EN, V18, P231, DOI 10.1109/TKDE.2006.30
   Zhao Z., 2007, P 24 INT C MACHINE L, P1151
   Zhu PF, 2015, PATTERN RECOGN, V48, P438, DOI 10.1016/j.patcog.2014.08.006
   Zhu XF, 2017, IEEE T BIG DATA, V3, P405, DOI 10.1109/TBDATA.2017.2735991
   Zhu XF, 2017, IEEE T MULTIMEDIA, V19, P2033, DOI 10.1109/TMM.2017.2703636
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
   Zhu XF, 2017, MED IMAGE ANAL, V38, P205, DOI 10.1016/j.media.2015.10.008
   Zhu XF, 2016, IEEE T BIO-MED ENG, V63, P607, DOI 10.1109/TBME.2015.2466616
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
   Zhu XF, 2013, PATTERN RECOGN, V46, P215, DOI 10.1016/j.patcog.2012.07.018
   Zhu XF, 2012, PATTERN RECOGN, V45, P3003, DOI 10.1016/j.patcog.2012.02.007
   Zhu XF, 2011, IEEE T KNOWL DATA EN, V23, P110, DOI 10.1109/TKDE.2010.99
NR 55
TC 76
Z9 77
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29739
EP 29755
DI 10.1007/s11042-017-5272-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800031
DA 2024-07-18
ER

PT J
AU Abd El Aziz, M
   Ewees, AA
   Hassanien, AE
AF Abd El Aziz, Mohamed
   Ewees, Ahmed A.
   Hassanien, Aboul Ella
TI Multi-objective whale optimization algorithm for content-based image
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based image retrieval; Multi-objective optimization; Whale
   optimization algorithm; Feature selection; Non-dominated sorting
ID PARTICLE SWARM OPTIMIZATION; FEATURE-SELECTION; DIFFERENTIAL EVOLUTION;
   FEATURE ADAPTATION; CLASSIFICATION; SEARCH; COLOR
AB In the recent years, there are massive digital images collections in many fields of our life, which led the technology to find methods to search and retrieve these images efficiently. The content-based is one of the popular methods used to retrieve images, which depends on the color, texture and shape descriptors to extract features from images. However, the performance of the content-based image retrieval methods depends on the size of features that are extracted from images and the classification accuracy. Therefore, this problem is considered as a multi-objective and there are several methods that used to manipulate it such as NSGA-II and NSMOPSO. However, these methods have drawbacks such as their time and space complexity are large since they used traditional non-dominated sorting methods. In this paper, a new non-dominated sorting based on multi-objective whale optimization algorithm is proposed for content-based image retrieval (NSMOWOA). The proposed method avoids the drawbacks in other non-dominated sorting multi-objective methods that have been used for content-based image retrieval through reducing the space and time complexity. The results of the NSMOWOA showed a good performance in content-based image retrieval problem in terms of recall and precision.
C1 [Abd El Aziz, Mohamed] Zagazig Univ, Fac Sci, Dept Math, Zagazig, Egypt.
   [Ewees, Ahmed A.] Damietta Univ, Dept Comp, Dumyat, Egypt.
   [Ewees, Ahmed A.] Univ Bisha, Bisha, Saudi Arabia.
   [Hassanien, Aboul Ella] Cairo Univ, Fac Comp & Informat, Informat Technol, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Zagazig University; Egyptian Knowledge
   Bank (EKB); Damietta University; University of Bisha; Egyptian Knowledge
   Bank (EKB); Cairo University
RP Ewees, AA (corresponding author), Damietta Univ, Dept Comp, Dumyat, Egypt.; Ewees, AA (corresponding author), Univ Bisha, Bisha, Saudi Arabia.
EM abd_el_aziz_m@yahoo.com; ewees@du.edu.eg
RI , mohamed/AAH-8886-2019; Ewees, Ahmed A./O-8211-2016; Hassanien, Aboul
   ella/O-5672-2014
OI , mohamed/0000-0002-7682-6269; Hassanien, Aboul ella/0000-0002-9989-6681
CR Abd El Aziz M, 2018, NEURAL COMPUT APPL, V29, P925, DOI 10.1007/s00521-016-2473-7
   Abd El Aziz M, 2017, EXPERT SYST APPL, V83, P242, DOI 10.1016/j.eswa.2017.04.023
   Abd El Aziz M, 2015, SIGNAL IMAGE VIDEO P, V9, P1825, DOI 10.1007/s11760-014-0661-4
   Abd Elaziz ME, 2017, LECT NOTES COMPUT SC, V10638, P145, DOI 10.1007/978-3-319-70139-4_15
   Agarwal S, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND COMPUTER NETWORKS (ISCON), P19, DOI 10.1109/ICISCON.2013.6524166
   [Anonymous], 2013, INT J INTELL COOPER
   [Anonymous], INT J APPL RES INF T
   [Anonymous], 2014, INT J SCI ENG TECHNO
   [Anonymous], 2017, NEURAL COMPUT APPL
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2014, INT J COMPUT SCI MOB
   [Anonymous], 2013, Int. J. Sci. Res.
   [Anonymous], PROC CVPR IEEE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], MATH PROBL ENG
   Arevalillo-Herráez M, 2013, APPL SOFT COMPUT, V13, P4358, DOI 10.1016/j.asoc.2013.06.016
   Arevalillo-Herráez M, 2008, PATTERN RECOGN LETT, V29, P2174, DOI 10.1016/j.patrec.2008.08.003
   Ayala G, 2001, IEEE T PATTERN ANAL, V23, P1430, DOI 10.1109/34.977566
   Bache K, 2013, UCI machine learning repository
   Balasubbareddy M, 2015, ENG SCI TECHNOL, V18, P603, DOI 10.1016/j.jestch.2015.04.005
   CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P959, DOI 10.1109/TASSP.1985.1164641
   Chen X, 2014, CHEMOMETR INTELL LAB, V136, P85, DOI 10.1016/j.chemolab.2014.05.007
   CHEN YD, 1994, OPT ENG, V33, P2713, DOI 10.1117/12.173552
   Chun YD, 2008, IEEE T MULTIMEDIA, V10, P1073, DOI 10.1109/TMM.2008.2001357
   Chun-Wei Tsai, 2014, 2014 14th International Conference on Intelligent Systems Design and Applications (ISDA), P62, DOI 10.1109/ISDA.2014.7066269
   Coello CAC, 2004, IEEE T EVOLUT COMPUT, V8, P256, DOI 10.1109/tevc.2004.826067
   CONNERS RW, 1984, COMPUT VISION GRAPH, V25, P273, DOI 10.1016/0734-189X(84)90197-X
   Das S., 2012, INT J MULTIMED ITS A, V4, P137, DOI [10.5121/ijma.2012.4412, DOI 10.5121/IJMA.2012.4412]
   de Ves E, 2006, PATTERN ANAL APPL, V9, P48, DOI 10.1007/s10044-006-0024-z
   Deb K., 2000, Parallel Problem Solving from Nature PPSN VI. 6th International Conference. Proceedings (Lecture Notes in Computer Science Vol.1917), P849
   ElAlami ME, 2011, KNOWL-BASED SYST, V24, P23, DOI 10.1016/j.knosys.2010.06.001
   Ewees AA, 2019, NEURAL COMPUT APPL, V31, P991, DOI 10.1007/s00521-017-3131-4
   Fadaei S, 2017, SIGNAL PROCESS, V137, P274, DOI 10.1016/j.sigpro.2017.02.013
   Fuad MMM, 2015, LECT NOTES COMPUT SC, V9028, P579, DOI 10.1007/978-3-319-16549-3_47
   Gahroudi MR, 2007, 9 INT S SIGNAL PROCE, P1
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Grigorova A, 2007, IEEE T MULTIMEDIA, V9, P1183, DOI 10.1109/TMM.2007.902828
   Guo JM, 2015, IEEE T MULTIMEDIA, V17, P1576, DOI 10.1109/TMM.2015.2449234
   Hancer E, 2015, IEEE C EVOL COMPUTAT, P2420, DOI 10.1109/CEC.2015.7257185
   Jalab H. A., 2011, 2011 IEEE Conference on Open Systems, P32, DOI 10.1109/ICOS.2011.6079266
   Jiji GW, 2015, APPL SOFT COMPUT, V30, P650, DOI 10.1016/j.asoc.2015.01.058
   Jin C, 2015, SIGNAL PROCESS, V109, P172, DOI 10.1016/j.sigpro.2014.10.031
   Kaveh A, 2017, MECH BASED DES STRUC, V45, P345, DOI 10.1080/15397734.2016.1213639
   Khan A., 2015, J. appl. res. technol, V13, P145
   Kumar CHS, 2016, INT J RENEW ENERGY D, V5, P225, DOI 10.14710/ijred.5.3.225-232
   Kundu PP, 2015, APPL SOFT COMPUT, V37, P751, DOI 10.1016/j.asoc.2015.08.042
   Lai CC, 2011, IEEE T INSTRUM MEAS, V60, P3318, DOI 10.1109/TIM.2011.2135010
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li XD, 2003, LECT NOTES COMPUT SC, V2723, P37
   Li Ying., 2016, Proceedings of the 2016 ACM on Multimedia Conference, P132
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Lu WY, 2012, IERI PROC, V3, P148, DOI 10.1016/j.ieri.2012.09.025
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Moreno-Picot S., 2013, LECT NOTES COMPUTER, P359
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Qiu GP, 2003, IEEE T IMAGE PROCESS, V12, P93, DOI 10.1109/TIP.2002.807356
   Rashedi E, 2013, KNOWL-BASED SYST, V39, P85, DOI 10.1016/j.knosys.2012.10.011
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saadatmand-Tarzjan M, 2007, IEEE T SYST MAN CY B, V37, P139, DOI 10.1109/TSMCB.2006.880137
   Sidhu S., 2015, International Journal of Research in Computer Applications and Robotics, V3, P84
   Smith G, 1997, PATTERN RECOGN LETT, V18, P1495, DOI 10.1016/S0167-8655(97)00132-3
   Soille P., 2013, MORPHOLOGICAL IMAGE
   Soyel H, 2011, COMPUT ELECTR ENG, V37, P1232, DOI 10.1016/j.compeleceng.2011.01.010
   Talib A., 2013, P 5 INT C ADV MULT, P52
   Tan CJ, 2014, NEUROCOMPUTING, V125, P217, DOI 10.1016/j.neucom.2012.12.057
   Tan MX, 2014, INT J COMPUT ASS RAD, V9, P1005, DOI 10.1007/s11548-014-0992-1
   Tiakas E, 2013, IEEE T MULTIMEDIA, V15, P1415, DOI 10.1109/TMM.2013.2247989
   Tiwari AK, 2017, SIGNAL PROCESS-IMAGE, V53, P73, DOI 10.1016/j.image.2017.01.010
   Tolias G., 2016, P INT C LEARNING REP
   Vasan KK., 2016, Perspect. Sci, V8, P510, DOI [DOI 10.1016/J.PISC.2016.05.010, 10.1016/j.pisc.2016.05, DOI 10.1016/J.PISC.2016.05]
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wu F, 2016, PATTERN RECOGN, V50, P143, DOI 10.1016/j.patcog.2015.08.012
   Xia H, 2014, NEUROCOMPUTING, V146, P113, DOI 10.1016/j.neucom.2014.06.075
   Xue B, 2013, IEEE T CYBERNETICS, V43, P1656, DOI 10.1109/TSMCB.2012.2227469
   Yan K, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P407, DOI 10.1145/2964284.2967252
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
   Yu FX, 2011, ELECTRON LETT, V47, P100, DOI 10.1049/el.2010.3232
   Yu Kai, 2010, ICML, P1215
   Zarchi MS, 2014, COMPUT ELECTR ENG, V40, P2062, DOI 10.1016/j.compeleceng.2014.07.008
   Zhang QF, 2007, IEEE T EVOLUT COMPUT, V11, P712, DOI 10.1109/TEVC.2007.892759
   Zhang TL, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SMART CLOUD (SMARTCLOUD), P152, DOI 10.1109/SmartCloud.2016.33
   Zhang XY, 2015, IEEE T EVOLUT COMPUT, V19, P201, DOI 10.1109/TEVC.2014.2308305
   Zhao L, 2015, IEEE T MULTIMEDIA, V17, P1936, DOI 10.1109/TMM.2015.2477058
   Zheng XL, 2014, 2014 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P626, DOI 10.1109/CEC.2014.6900249
   Zitzler E, 1999, IEEE T EVOLUT COMPUT, V3, P257, DOI 10.1109/4235.797969
NR 85
TC 46
Z9 47
U1 3
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 26135
EP 26172
DI 10.1007/s11042-018-5840-9
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400065
DA 2024-07-18
ER

PT J
AU Angelides, MC
   Wilson, LAC
   Echeverría, PLB
AF Angelides, Marios C.
   Wilson, Lissette Andrea Cabello
   Echeverria, Paola Liliana Burneo
TI Wearable data analysis, visualisation and recommendations on the go
   using android middleware
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wearable technology; Visual information systems; Machine learning
AB Wearable technology comes with the promise of improving one's lifestyles thru data mining of their physiological condition. The potential to generate a change in daily or routine habits thru these devices leaves little doubt. Whilst the hardware capabilities of wearables have evolved rapidly, software apps that interpret and present the physiological data and make recommendations in a simple, clear and meaningful way have not followed a similar pattern of evolution. Existing fitness apps provide routinely some information to the wearer by mining personal data but the subsequent analysis is limited to supporting ad hoc personal goals. The information and recommendations presented are often either not entirely relevant or incomplete and often not easy to interpret by the wearer. The primary motivation behind this research is to address this wearable technology software challenge by developing a middleware mobile app that is supported by data analytics and machine learning to assist with interpretation of wearer data and with making of personal lifestyle improvement recommendations on the go which may then be used to feedback to the wearer's daily goals and activities. The secondary motivation is to correlate and compare with trends in the wearer's peer community.
C1 [Angelides, Marios C.; Wilson, Lissette Andrea Cabello; Echeverria, Paola Liliana Burneo] Brunel Univ London, Coll Engn Design & Phys Sci, Dept Elect & Comp Engn, Uxbridge UB8 3PH, Middx, England.
C3 Brunel University
RP Angelides, MC (corresponding author), Brunel Univ London, Coll Engn Design & Phys Sci, Dept Elect & Comp Engn, Uxbridge UB8 3PH, Middx, England.
EM marios.angelides@brunel.ac.uk; lcabello@fiec.espol.edu.ec
CR Anaya LHS, 2017, SCI ENG ETHICS
   Argus Insights Inc, 2016, WEAR DEM REP
   ARM Ltd, 2014, CISC VIS NETW IND GL, P11
   Bandodkar AJ, 2016, ACS SENSORS, V1, P464, DOI 10.1021/acssensors.6b00250
   Chen M, 2016, MOBILE NETW APPL, V21, P729, DOI 10.1007/s11036-015-0665-5
   Delgado-Gonzalo R, 2015, IEEE ENG MED BIO, P430, DOI 10.1109/EMBC.2015.7318391
   Demir E., 2016, WORLD J EDU TECH, V8, P65, DOI [DOI 10.18844/WJET.V8I1.503, 10.18844/wjet.v8i1.503]
   Guesmi C, 2016, INT J COMMUNICATIONS, V6, P39
   Hill C., 2015, Biometric Technology Today, P5, DOI 10.1016/ S0969-4765(15)30138-7
   IDC Research Inc, 2016, IDC FOR WEAR SHIPM R
   Kalinauckas Alex, 2015, Engineering & Technology, V10, P36, DOI 10.1049/et.2015.0416
   Kalinauckas A, 2015, E T MAGAZINE
   Kolodzey L., 2017, BMJ Innov, V3, P55, DOI DOI 10.1136/BMJINNOV-2016-000133
   Ledger D, 2016, INSIDE WEARABLES 2
   Ledger D, 2016, INSIDE WEARABLES 1
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Matzeu G, 2015, SENSOR ACTUAT B-CHEM, V211, P403, DOI 10.1016/j.snb.2015.01.077
   News.samsung.com, 2016, SAMSUNG EXPANDS IND
   Parak J, 2015, IEEE ENG MED BIO, P8099, DOI 10.1109/EMBC.2015.7320273
   Park S., 2014, Wearable Sensors: Fundamentals, Implementation and Applications, DOI 10.1155/2014/640262
   Patel MS, 2015, JAMA-J AM MED ASSOC, V313, P459, DOI 10.1001/jama.2014.14781
   Rettberg J., 2016, SEEING OURSELVES TEC
   Richter F, 2016, STATISTA INFOGRAPHIC
   Robson K, 2016, DEV MKT SCI, P801, DOI 10.1007/978-3-319-26647-3_172
   Salah H, 2015, WEARABLE TECH LEVERA
   Schull NatashaD., 2016, BioSocieties, P1
   Shelgikar AV, 2016, CHEST, V150, P732, DOI 10.1016/j.chest.2016.04.016
   Shih P.C., 2015, ICONFERENCE
   Shoaib M, 2013, 2013 IEEE 10TH INTERNATIONAL CONFERENCE ON AND 10TH INTERNATIONAL CONFERENCE ON AUTONOMIC AND TRUSTED COMPUTING (UIC/ATC) UBIQUITOUS INTELLIGENCE AND COMPUTING, P80, DOI 10.1109/UIC-ATC.2013.43
   Sofokleous AA, 2008, MULTIMED TOOLS APPL, V40, P151, DOI 10.1007/s11042-008-0198-z
   Sofokleous AA, 2009, COMPUT J, V52, P413, DOI 10.1093/comjnl/bxn035
   Stoppa M, 2014, SENSORS-BASEL, V14, P11957, DOI 10.3390/s140711957
   Thierer A.D., 2015, INTERNET THINGS WEAR
   Viscusi S, 2016, CURRENT FUTURE STATE
   Woolley M, 2015, WOOLLEYS WEARABLES A
   Yang J, 2015, RSC ADV, V5, P25609, DOI 10.1039/c5ra00871a
   Zachariah T, 2015, 16TH INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS (HOTMOBILE' 15), P27, DOI 10.1145/2699343.2699344
NR 37
TC 10
Z9 11
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26397
EP 26448
DI 10.1007/s11042-018-5867-y
PG 52
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500010
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Hou, SJ
   Zhou, SB
   Liu, WJ
   Zheng, YJ
AF Hou, Sujuan
   Zhou, Shangbo
   Liu, Wenjie
   Zheng, Yuanjie
TI Classifying advertising video by topicalizing high-level semantic
   concepts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ad video; Video classification; High-level semantic; Latent Dirichlet
   allocation
ID CLASSIFICATION; DISCOVERY; CONTEXT; VECTOR
AB The recent proliferation of videos has driven the research into various applications, ranging from video analysis to indexing and retrieval. These applications greatly benefit from domain knowledge of videos. As a special kind of videos, classifying ad video is a key task because it allows automatic organization of videos according to categories or genres, and this further enables ad video indexing and retrieval. However, classifying ad video is challenging due to its unconstraint content and distinctive expression. While many studies focus on selecting ads relevant to the target videos, to the best of our knowledge, few focuses on ad video classification. To classify ad video, we propose a novel video representation that aims to capture the latent semantics of ad video in an unsupervised manner. In particular, this paper integrates the posterior occurrence probability between brand/logo information and the high-level object information into a latent Dirichlet allocation unified learning paradigm, named ppLDA. A topical representation for ad video is obtained by the proposed method, which can support category-related task. Our experiments on 10,111 real-world ad videos downloaded from Internet demonstrate that the proposed method could effectively differentiate ad videos.
C1 [Hou, Sujuan; Zheng, Yuanjie] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Hou, Sujuan; Zheng, Yuanjie] Shandong Normal Univ, Inst Life Sci, Jinan 250014, Shandong, Peoples R China.
   [Zhou, Shangbo] Chongqing Univ, Sch Comp Sci, Chongqing 400030, Peoples R China.
   [Liu, Wenjie] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.
   [Zheng, Yuanjie] Shandong Normal Univ, Key Lab Intelligent Informat Proc, Jinan 250014, Shandong, Peoples R China.
C3 Shandong Normal University; Shandong Normal University; Chongqing
   University; Nanjing University of Information Science & Technology;
   Shandong Normal University
RP Zheng, YJ (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.; Zheng, YJ (corresponding author), Shandong Normal Univ, Inst Life Sci, Jinan 250014, Shandong, Peoples R China.; Zhou, SB (corresponding author), Chongqing Univ, Sch Comp Sci, Chongqing 400030, Peoples R China.; Zheng, YJ (corresponding author), Shandong Normal Univ, Key Lab Intelligent Informat Proc, Jinan 250014, Shandong, Peoples R China.
EM shbzhou@cqu.edu.cn; zhengyuanjie@gmail.com
FU major project of Natural Science Foundation of Shandong Province
   [ZR2016FQ20]; Postdoctoral Science Foundation of China [2017 M612338];
   Fundamental Science and Frontier Technology Research of Chongqing CSTC
   [cstc2015jcyjBX0124]; Natural Science Foundation of China (NSFC)
   [61702313, 61572300]; Natural Science Foundation of Shandong Province in
   China [ZR2014FM001]; Taishan Scholar Program of Shandong Province in
   China [TSHW201502038]; Natural Science Foundation of Shandong Province
   [ZR2016FQ20]
FX S. Hou would like to thank Cheng Liang for her substantial effort in the
   revision, including the design and implementation of experiments as well
   as proofreading the manuscript. This work was made possible through
   support from the major project of Natural Science Foundation of Shandong
   Province (ZR2016FQ20), Postdoctoral Science Foundation of China (2017
   M612338), Fundamental Science and Frontier Technology Research of
   Chongqing CSTC (cstc2015jcyjBX0124), Natural Science Foundation of China
   (NSFC) (61702313,61572300), Natural Science Foundation of Shandong
   Province in China (ZR2014FM001), Taishan Scholar Program of Shandong
   Province in China (TSHW201502038).; Natural Science Foundation of China
   (NSFC) (61702313), Natural Science Foundation of Shandong Province
   (ZR2016FQ20), Postdoctoral Science Foundation of China (2017 M612338),
CR [Anonymous], 2000, P BRIT MACH VIS C
   [Anonymous], 2014, INT C MULTIMEDIA RET, DOI DOI 10.1145/2578726.2578744
   [Anonymous], 2010, P NIPS
   [Anonymous], 2006, Adv. Neural Inf. Process. Syst
   Bagdanov A.D., 2007, P INT WORKSH WORKSH, P79
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Brezeale D, 2006, SESS 7 INT WORKSH MU
   Brezeale D, 2008, IEEE T SYST MAN CY C, V38, P416, DOI 10.1109/TSMCC.2008.919173
   Cao XC, 2015, IEEE T CYBERNETICS, V45, P1327, DOI 10.1109/TCYB.2014.2350517
   Darji MC, 2016, INT S ADV COMP COMM, P60
   Dimitrova N, 2015, SIGN PROC C 2000 EUR
   Fan JH, 2018, NEURAL COMPUT APPL, V29, P733, DOI 10.1007/s00521-016-2603-2
   Fan JP, 2004, ACM-IEEE J CONF DIG, P192, DOI 10.1145/996350.996395
   Fernandez-Beltran R, 2016, PATTERN RECOGN, V51, P72, DOI 10.1016/j.patcog.2015.09.007
   Fu  Z., 1939, IEEE T SERV COMPUT, P1
   Gu B, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3532
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hou SJ, 2016, NEUROCOMPUTING, V171, P932, DOI 10.1016/j.neucom.2015.07.022
   INOUYE D., 2014, International Conference on Machine Learning, P683
   Jasinschi RS, 2001, EUROMICRO CONF PROC, P370, DOI 10.1109/EURMIC.2001.952477
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kobla V, 1999, ELECT IMAGING
   Liu YN, 2016, SIGNAL PROCESS, V120, P761, DOI 10.1016/j.sigpro.2015.01.001
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mironica I, 2016, MULTIMED TOOLS APPL, V75, P9045, DOI 10.1007/s11042-015-2819-7
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Ou W, 2015, IEEE SYS MAN CYBERN, P2938, DOI 10.1109/SMC.2015.511
   Peng Wang, 2003, ICICS-PCM 2003. Proceedings of the 2003 Joint Conference of the Fourth International Conference on Information, Communications and Signal Processing and Fourth Pacific-Rim Conference on Multimedia (IEEE Cat. No.03EX758), P787
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Psyllos AP, 2010, IEEE T INTELL TRANSP, V11, P322, DOI 10.1109/TITS.2010.2042714
   Roach M, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P157
   Roach M, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P146, DOI 10.1109/ISIMP.2001.925353
   Roach M., 2001, INTERSPEECH, V15, P2693
   Sahbi H, 2013, IEEE T IMAGE PROCESS, V22, P1018, DOI 10.1109/TIP.2012.2226046
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Song W, 2016, IEEE INT FUZZY SYST, P642, DOI 10.1109/FUZZ-IEEE.2016.7737747
   Soomro K., 2012, COMPUTER VISION PATT
   Wallach H.M., 2006, Proc. 23rd Int. Conf. Mach. Learn, P977984
   Wang M, 2015, IEEE T CYBERNETICS, V45, P1561, DOI 10.1109/TCYB.2014.2356136
   Wang XR, 2007, IEEE DATA MINING, P697, DOI 10.1109/ICDM.2007.86
   Wang ZY, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1171, DOI 10.1145/2733373.2806309
   Xu D, 2015, COMPUTER VISION PATT
   Xu LQ, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P485
   Xuanhan Wang, 2017, IEEE Signal Processing Letters, V24, P510, DOI 10.1109/LSP.2016.2611485
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P572, DOI 10.1109/TMM.2012.2234731
   Ye H, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P435, DOI 10.1145/2671188.2749406
   Yi J, 2013, IEEE T MULTIMEDIA, V15, P1400, DOI 10.1109/TMM.2013.2250266
   Zhang H, 2010, CREATING ENSEMBLES C
   Zhang HX, 2014, PATTERN RECOGN, V47, P3168, DOI 10.1016/j.patcog.2014.04.004
NR 52
TC 20
Z9 20
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25475
EP 25511
DI 10.1007/s11042-018-5801-3
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400039
DA 2024-07-18
ER

PT J
AU Maddodi, G
   Awad, A
   Awad, D
   Awad, M
   Lee, B
AF Maddodi, Gururaj
   Awad, Abir
   Awad, Dounia
   Awad, Mirna
   Lee, Brian
TI A new image encryption algorithm based on heterogeneous chaotic neural
   network generator and dna encoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image security; Encryption; Chaos theory; Neural networks; DNA encoding
AB This paper presents a new combined neural network and chaos based pseudo-random sequence generator and a DNA-rules based chaotic encryption algorithm for secure transmission and storage of images. The proposed scheme uses a new heterogeneous chaotic neural network generator controlling the operations of the encryption algorithm: pixel position permutation, DNA-based bit substitution and a new proposed DNA-based bit permutation method. The randomness of the generated chaotic sequence is improved by dynamically updating the control parameters as well as the number of iterations of the chaotic functions in the neural network. Several tests including auto correlation, 0/1 balance and NIST tests are performed to show high degree of randomness of the proposed chaotic generator. Experimental results such as pixel correlation coefficients, entropy, NPCR and UACI etc. as well as security analyses are given to demonstrate the security and efficiency of the proposed chaos based genetic encryption method.
C1 [Maddodi, Gururaj] Univ Utrecht, Dept Informat & Comp Sci, Utrecht, Netherlands.
   [Awad, Abir] Liverpool John Moores Univ, Fac Engn & Technol, Liverpool, Merseyside, England.
   [Awad, Dounia; Awad, Mirna; Lee, Brian] Athlone Inst Technol, Software Res Inst, Athlone, Ireland.
C3 Utrecht University; Liverpool John Moores University; Technological
   University of the Shannon: Midlands Midwest
RP Maddodi, G (corresponding author), Univ Utrecht, Dept Informat & Comp Sci, Utrecht, Netherlands.
EM g.maddodi@uu.nl; a.awad@ljmu.ac.uk; dounia.awad@gmail.com;
   m.awad@research.ait.ie; blee@ait.ie
OI Lee, Brian/0000-0002-8475-4074
CR [Anonymous], 2014, SCI WORLD J
   Avasare MG, 2015, 2015 INT C COMM INF, P1
   Awad A., 2012, IEEE International Conference on Communications (ICC 2012), P1011, DOI 10.1109/ICC.2012.6363965
   Burak D, 2013, PARALLEL PROCESSING, P364
   Chauhan M, PRAJAPATI R IMAGE EN
   Chen JX, 2015, COMMUN NONLINEAR SCI, V20, P846, DOI 10.1016/j.cnsns.2014.06.032
   Daemen J., 2013, DESIGN RIJNDAEL AES
   Dworkin M., 2001, RECOMMENDATION BLOCK
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Hossain M. A., 2014, MAT RENEWABLE SUSTAI, V3, P1
   Kassem A, 2014, DIGIT SIGNAL PROCESS, V25, P266, DOI 10.1016/j.dsp.2013.11.004
   Levenson Mark, SP 800 22 REV 1A STA
   Li XW, 2016, SIGNAL PROCESS, V125, P48, DOI 10.1016/j.sigpro.2015.11.017
   Lian SG, 2009, NEUROCOMPUTING, V72, P1296, DOI 10.1016/j.neucom.2008.11.005
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Qin K, 2014, INFORMATION SCIENCES AND SYSTEMS 2014, P167, DOI 10.1007/978-3-319-09465-6_18
   Singla P, 2014, INT C ADV COMPUT COM, P301, DOI 10.1109/ACCT.2014.38
   Tong XJ, 2015, J VIS COMMUN IMAGE R, V33, P219, DOI 10.1016/j.jvcir.2015.09.014
   Wu Y, 2011, J SELECTED AREAS TEL
   Zhang J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P78, DOI 10.1109/CICT.2015.134
   Zhang Q, 2014, AEU-INT J ELECTRON C, V68, P186, DOI 10.1016/j.aeue.2013.08.007
   Zhang YS, 2014, INFORM SCIENCES, V289, P254, DOI 10.1016/j.ins.2014.08.005
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 25
TC 47
Z9 47
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 24701
EP 24725
DI 10.1007/s11042-018-5669-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400007
OA hybrid
DA 2024-07-18
ER

PT J
AU Tsai, MJ
   Yuadi, I
   Tao, YH
AF Tsai, Min-Jen
   Yuadi, Imam
   Tao, Yu-Han
TI Decision-theoretic model to identify printed sources
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Decision fusion; Scanner; Feature filters; Feature selection; Support
   Vector Machines (SVM); Deep learning; Convolutional Neural Networks
   (CNNs)
ID DIGITAL FORENSICS; IDENTIFICATION; CLASSIFICATION; FEATURES
AB When trying to identify a printed forged document, examining digital evidence can prove to be a challenge. Over the past several years, digital forensics for printed document source identification has begun to be increasingly important which can be related to the investigation and prosecution of many types of crimes. Unlike invasive forensic approach which requires a fraction of the printed document as the specimen for verification, noninvasive forensic technique uses the optical mechanism to explore the relationship between the scanned images and the source printer. To explore the relationship between source printers and images obtained by the scanner, the proposed decision-theoretical approach utilizes image processing techniques and data exploration methods to calculate many important statistical features, including: Local Binary Pattern (LBP), Gray Level Co-occurrence Matrix (GLCM), Discrete Wavelet Transform (DWT), Spatial filters, the Wiener filter, the Gabor filter, Haralick, and SFTA features. Consequently, the proposed aggregation method intensively applies the extracted features and decision-fusion model of feature selections for classification. In addition, the impact of different paper texture or paper color for printed sources identification is also investigated. In the meantime, the up-to-date techniques based on deep learning system is developed by Convolutional Neural Networks (CNNs) which can learn the features automatically to solve the complex image classification problem. Both systems have been compared and the experimental results indicate that the proposed system achieve the overall best accuracy prediction for image and text input and is superior to the existing approaches. In brief, the proposed decision-theoretical model can be very efficiently implemented for real world digital forensic applications.
C1 [Tsai, Min-Jen; Yuadi, Imam; Tao, Yu-Han] Natl Chiao Tung Univ, Inst Informat Management, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
   [Yuadi, Imam] Airlangga Univ, Dept Informat & Lib Sci, Jl Airlangga 4-6, Surabaya 60286, East Java, Indonesia.
C3 National Yang Ming Chiao Tung University; Airlangga University
RP Tsai, MJ (corresponding author), Natl Chiao Tung Univ, Inst Informat Management, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
EM mjtsai@cc.nctu.edu.tw
RI Yuadi/V-3570-2018
FU National Science Council in Taiwan, Republic of China
   [NSC104-2410-H-009-020-MY2, NSC106-2410-H-009-022-]
FX This work was partially supported by the National Science Council in
   Taiwan, Republic of China, under NSC104-2410-H-009-020-MY2 and
   NSC106-2410-H-009-022-.
CR Ali GN, 2003, IS&T'S NIP19: INTERNATIONAL CONFERENCE ON DIGITAL PRINTING TECHNOLOGIES, P511
   [Anonymous], 2017, ELECT MICROSCOPE
   [Anonymous], P 2010 IEEE INT S CI
   [Anonymous], 2015, IEEE C COMP VIS PATT
   Bekhti MA, 2016, LECT NOTES COMPUT SC, V9431, P282, DOI 10.1007/978-3-319-29451-3_23
   Bulan O, 2009, INT CONF ACOUST SPEE, P1401, DOI 10.1109/ICASSP.2009.4959855
   Burger W, 2018, DIGITAL IMAGE PROCES
   Choi JH, 2013, MULTIMED TOOLS APPL, V67, P363, DOI 10.1007/s11042-011-0835-9
   Costa A. F., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P39, DOI 10.1109/SIBGRAPI.2012.15
   DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644
   Ferreira A, 2015, FORENSIC SCI INT, V247, P105, DOI 10.1016/j.forsciint.2014.11.030
   Gonzales R. C., 2008, DIGITAL IMAGE PROCES
   Gonzales Rafael C., 2009, Digital Image Processing Using MATLAB
   Haghighat M, 2015, EXPERT SYST APPL, V42, P7905, DOI 10.1016/j.eswa.2015.06.025
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hsu C.-W., 2003, PRACTICAL GUIDE SUPP
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Juric I, 2014, J GRAPHIC ENG DES, V5, P17
   Kawasaki M., 2009, TAPPI J, V63, P1362, DOI 10.2524/jtappij.63.1362
   Kee E, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P3, DOI 10.1145/1411328.1411332
   Kim DG, 2014, EUR SIGNAL PR CONF, P795
   Kim KI, 2002, IEEE T PATTERN ANAL, V24, P1542, DOI 10.1109/TPAMI.2002.1046177
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lewis JA, 2014, FORENSIC DOCUMENT EXAMINATION: FUNDAMENTALS AND CURRENT TRENDS, P1
   Lin CJ, 2007, TUTORIAL WAVELET TRA
   Lopes FM, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-451
   Maenpaa T, 2004, HDB PATTERN RECOGNIT, P115
   Markoff J, 2012, THE NEW YORK
   McAndrew A., 2016, A computational introduction to digital image processing, V2nd
   Mikkilineni AK, 2005, IS&T'S NIP21: INTERNATIONAL CONFERENCE ON DIGITAL PRINTING TECHNOLOGIES, FINAL PROGRAM AND PROCEEDINGS, P223
   Mikkilineni AK, 2005, PROC SPIE, V5681, P430, DOI 10.1117/12.593796
   Mikkilineni AK, 2004, IS&T'S NIP20: INTERNATIONAL CONFERENCE ON DIGITAL PRINTING TECHNOLOGIES, PROCEEDINGS, P306
   Mikkilineni AK, 2010, PROC SPIE, V7541, DOI 10.1117/12.845377
   Netzer Y., 2011, NIPS WORKSH DEEP LEA
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Pudil P, 1994, 1051465U9 IEEE, P1051
   Qiu ZY, 2016, NEUROCOMPUTING, V207, P519, DOI 10.1016/j.neucom.2016.05.035
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Ryu SJ, 2010, INT CONF ACOUST SPEE, P1846, DOI 10.1109/ICASSP.2010.5495377
   Say OT, 2013, 2013 IEEE REGIONAL SYMPOSIUM ON MICRO AND NANOELECTRONICS (RSM 2013), P273, DOI 10.1109/RSM.2013.6706528
   Schalkoff Robert J., 1989, Digital image processing and computer vision
   Su R, 2005, PHYS PROPERTIES LWC
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243
   Tsai MJ, 2015, IEEE INT SYMP CIRC S, P2800, DOI 10.1109/ISCAS.2015.7169268
   Tsai MJ, 2014, MULTIMED TOOLS APPL, V73, P2129, DOI 10.1007/s11042-013-1642-2
   Tsai MJ, 2013, IEEE INT SYMP CIRC S, P2347, DOI 10.1109/ISCAS.2013.6572349
   Tsai MJ, 2011, IEEE INT SYMP CIRC S, P2633
   Vega L.R., 2013, A Rapid Introduction to Adaptive Filtering
   Wu YB, 2009, IEEE IMAGE PROC, P2909, DOI 10.1109/ICIP.2009.5413420
   Zhou H, 2010, DIGITAL IMAGE PROC 1
NR 57
TC 11
Z9 12
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27543
EP 27587
DI 10.1007/s11042-018-5938-0
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500059
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Ahmed, A
   Latif, R
   Latif, S
   Abbas, H
   Khan, FA
AF Ahmed, Afsheen
   Latif, Rabia
   Latif, Seemab
   Abbas, Haider
   Khan, Farrukh Aslam
TI Malicious insiders attack in IoT based Multi-Cloud e-Healthcare
   environment: <i>A Systematic Literature Review</i>
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Internet of Things; Cloud Computing; Multi-Cloud; Confidentiality;
   Integrity; E-Healthcare; Malicious Insiders
ID THREATS; INTERNET; THINGS
AB The emergence of Internet of Things (IoT) has introduced smart objects as the fundamental building blocks for developing a smart cyber-physical universal environment. The IoTs have innumerable daily life applications. The healthcare industry particularly has been benefited due to the provision of ubiquitous health monitoring, emergency response services, electronic medical billing, etc. Since IoT devices possess limited storage and processing power, therefore these intelligent objects are unable to efficiently provide the e-health facilities, or process and store enormous amount of collected data. IoTs are merged with Cloud Computing technology in Multi-Cloud form that basically helps cover the limitations of IoTs by offering a secure and on-demand shared pool of resources i.e., networks, servers, storage, applications, etc., to deliver effective and well-organized e-health amenities. Although the framework based on the integration of IoT and Multi-Cloud is contributing towards better patient care, yet on the contrary, it is challenging the privacy and reliability of the patients' information. The purpose of this systematic literature review is to identify the top security threat and to evaluate the existing security techniques used to combat this attack and their applicability in IoT and Multi-Cloud based e-Healthcare environment.
C1 [Ahmed, Afsheen; Latif, Rabia; Latif, Seemab; Abbas, Haider] Natl Univ Sci & Technol, Islamabad, Pakistan.
   [Khan, Farrukh Aslam] King Saud Univ, Ctr Excellence Informat Assurance, Riyadh, Saudi Arabia.
C3 National University of Sciences & Technology - Pakistan; King Saud
   University
RP Abbas, H (corresponding author), Natl Univ Sci & Technol, Islamabad, Pakistan.
EM afsheenahmed.msis13@students.mcs.edu.pk; rabia.latif@mcs.edu.pk;
   seemab.latif@seecs.edu.pk; haiderabbas-mcs@nust.edu.pk;
   fakhan@ksu.edu.sa
RI Latif, Seemab/AFA-1299-2022; Latif, Rabia/AAJ-3471-2020; Abbas,
   Haider/ABB-1219-2021; Abbas, Haider/G-1077-2014; Khan, Farrukh
   Aslam/J-8358-2019
OI Latif, Seemab/0000-0002-5801-1568; Latif, Rabia/0000-0001-5304-5948;
   Abbas, Haider/0000-0002-2437-4870; Abbas, Haider/0000-0002-2437-4870;
   Khan, Farrukh Aslam/0000-0002-7023-7172
CR Abbas H, 2016, ANN TELECOMMUN, V71, P477, DOI 10.1007/s12243-016-0495-x
   [Anonymous], 2016, IBM X FORCE RES 2016
   [Anonymous], 2011, International Workshop on Critical Information Infrastructures Security
   [Anonymous], J MED SYST
   [Anonymous], 2017, SEC 1 1 3
   [Anonymous], 2017, WHAT AR SOM DIS HOM
   Balasaraswathi VR, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P1190, DOI 10.1109/ICACCCT.2014.7019286
   Chouhan P, 2016, INT J ADV RES COMPUT, V6, P92
   Claycomb WR, 2012, P INT COMP SOFTW APP, P387, DOI 10.1109/COMPSAC.2012.113
   Duncan A. J., 2012, 2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom), P857, DOI 10.1109/TrustCom.2012.188
   Duncan A, 2013, IEEE INT CONF TRUST, P493, DOI 10.1109/TrustCom.2013.62
   Eberle W, 2009, CATCH 2009: CYBERSECURITY APPLICATIONS AND TECHNOLOGY CONFERENCE FOR HOMELAND SECURITY, PROCEEDINGS, P237, DOI 10.1109/CATCH.2009.7
   Eken H, 2013, WOR CONGR INTERNET, P139, DOI 10.1109/WorldCIS.2013.6751034
   Garkoti G, 2014, P 2014 INT C INF TEC, P192
   Gelenbe E, 2013, LECT NOTES ELECTR EN, V264, P369, DOI 10.1007/978-3-319-01604-7_36
   Grobauer B, 2011, IEEE SECUR PRIV, V9, P50, DOI 10.1109/MSP.2010.115
   Gunasekhar T., 2015, International Journal of Electrical and Computer Engineering IJECE, V5, P136
   Hanley M, 2011, CMUSEI2011TN003
   Hu Y, 2018, MULTIMED TOOLS APPL, V77, P3729, DOI 10.1007/s11042-016-3719-1
   Inam ul Haq M, 2013, THESIS
   Islam SMR, 2015, IEEE ACCESS, V3, P678, DOI 10.1109/ACCESS.2015.2437951
   Kavyashree MU, 2014, INT J ADV COMPUTER T, V3, P12
   Kitchenham B, 2009, INFORM SOFTWARE TECH, V51, P7, DOI 10.1016/j.infsof.2008.09.009
   Latif R, 2016, INT J AD HOC UBIQ CO, V23, P24, DOI 10.1504/IJAHUC.2016.078474
   Latif R, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0515-4
   Latif R, 2015, MOB INF SYST, V2015, DOI 10.1155/2015/260594
   Mahajan A., 2015, International Journal of Engineering Research and General Science, V3, P245
   Mavoungou S, 2016, IEEE ACCESS, V4, P4543, DOI 10.1109/ACCESS.2016.2601009
   Minh-Duong Nguyen, 2014, International Journal of Information and Education Technology, V4, P483, DOI 10.7763/IJIET.2014.V4.455
   Muhil M, 2015, PROCEDIA COMPUT SCI, V50, P421, DOI 10.1016/j.procs.2015.04.011
   Munir k., 2013, ADV COMPUTING INT J, V4, P9
   Na W, 2015, P 17 INT C MEAS TECH, P585
   Noor Talal H., 2013, Web Engineering. 13th International Conference, ICWE 2013. Proceedings: LNCS 7977, P416, DOI 10.1007/978-3-642-39200-9_35
   Razaque A, 2016, PROC INT C EL EL OPT
   Rui J, 2015, P 17 INT C MEAS TECH, P206
   Salman T, 2015, SECURING MULTICLOUDS
   Sevak B., 2012, INT J ENG ADV TECHNO, V2, P183
   Shamir's Secret Sharing, 2017, SHAM SECR SHAR
   Singh A, 2016, INT RES J ENG TECHNO, V3, P895
   Singh Ajey., 2012, International Journal of Engineering and Innovative Technology, V1, P321
   Singh S, 2014, OPEN J MOBILE COMPUT, V1, P1
   Subramanian K, 2016, INT J COMPUTER SCI N, V4, P196
   Yusop ZM, 2014, PROCD SOC BEHV, V129, P611, DOI 10.1016/j.sbspro.2014.06.002
   Zhang Y, 2017, IEEE SYST J, V11, P88, DOI 10.1109/JSYST.2015.2460747
   Zhang Y, 2017, FUTURE GENER COMP SY, V66, P30, DOI 10.1016/j.future.2015.12.001
   Zhang YQ, 2014, CCS'14: PROCEEDINGS OF THE 21ST ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P990, DOI 10.1145/2660267.2660356
   Zhou JH, 2013, INT C COMP SUPP COOP, P651, DOI 10.1109/CSCWD.2013.6581037
   Zhou ZJ, 2013, INT J GRID DISTRIB, V6, P1, DOI 10.14257/ijgdc.2013.6.6.01
   Zibouh Ouadia, 2016, Journal of Theoretical and Applied Information Technology, V87, P300
   민영기, 2012, [Journal of Security Engineering, 보안공학연구논문지], V9, P135
NR 50
TC 32
Z9 36
U1 1
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 21947
EP 21965
DI 10.1007/s11042-017-5540-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500009
DA 2024-07-18
ER

PT J
AU Alkhalifa, S
   Al-Razgan, M
AF Alkhalifa, Shurug
   Al-Razgan, Muna
TI Enssat: wearable technology application for the deaf and hard of hearing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hardof hearing; Deaf; Assistive technology; Wearable computing;
   Head-mounted; Speech-to-text; Translation; Transcription
AB A large number of people around the globe experience hearing difficulties of varying degrees. Therefore, recent research has focused on developing applications and systems to aid the Deaf and Hard of Hearing (DHH). Wearable devices have significant potential in assistive applications owing to their low cost and lightweight. Wearable devices help the DHH perform their daily activities easily without requiring assistance from others. We present Enssat, a bilingual (Arabic/English) smartphone-based hearing aid application that uses Google Glass to assist DHH individuals. The application performs important tasks: real-time transcription, real-time translation, and alert management. A user study was performed to evaluate the application. In this study, 10 DHH users evaluated the processes of transcription, translation, and alerting and 15 non-DHH users evaluated the translation function of the system. All of them evaluated the usability and effectiveness of the Enssat application. The results demonstrated the ease of use and utility of the application.
C1 [Alkhalifa, Shurug; Al-Razgan, Muna] King Saud Univ, Informat Technol Dept, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
C3 King Saud University
RP Alkhalifa, S (corresponding author), King Saud Univ, Informat Technol Dept, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
EM salkhalifa@ksu.edu.sa; malrazgan@ksu.edu.sa
RI Al-Razgan, Muna/M-7736-2014
OI Al-Razgan, Muna/0000-0002-9705-3867
FU Research Center of the Female Scientific and Medical Colleges, Deanship
   of Scientific Research, King Saud University, Riyadh, Saudi Arabia
FX This research project was supported by a grant from the Research Center
   of the Female Scientific and Medical Colleges, Deanship of Scientific
   Research, King Saud University, Riyadh, Saudi Arabia. We would also like
   to specially thank the following students: Amal Alfawaz, Amal Alnaqeeb,
   Ameera Algabr, Ghada Alyousif, and Yosra Aldoeis for their contributions
   to the implementation and evaluation of the system.
CR [Anonymous], 2014, DEAF HEARING IMPAIRE
   [Anonymous], 2013, International Business Times
   Barrett K, 2013, KEITH BARRETT ONLINE
   Bianchini CS, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P390, DOI 10.1145/2254556.2254631
   Bragg D, P 18 INT ACM SIGACCE, P3
   Emotional Factors of HOH, HARD HEAR ADV SOL BE
   Glass, GOOGL DEV
   Google goggles, 2014, ANDR APPS GOOGL PLAY
   Google Inc, 2015, GOOGL TRANSL ANDR AP
   Group of researchers from Georgia Institute of Technology, 2014, CAPT GLASS COG
   Gugenheimer J, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P669, DOI 10.1145/2998181.2998203
   Jain D, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P241, DOI 10.1145/2702123.2702393
   Jones Michael., 2014, P 2014 C INTERACTION, P317, DOI DOI 10.1145/2593968.2610481
   Jones MD, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P331, DOI 10.1145/2700648.2811364
   Lasecki W, 2014, REAL TIME CAPTIONING
   Liu Sicong, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3090082
   LiveCaption Live Caption, 2010, ANDR APPS GOOGL PLAY
   Menasy M, 2013, ANDROID APPS GOOGLE
   Mielke M, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P301, DOI 10.1145/2700648.2811347
   Nguyen V., 2015, ACM SIGMOBILE MOBILE, V18, P44
   Profita H, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4884, DOI 10.1145/2858036.2858130
   Sapargaliyev D, 2015, COMM COM INF SC, V560, P343, DOI 10.1007/978-3-319-25684-9_25
   Sommerville I., 2010, SOFTWARE ENG
   Stinson Michael S., 2014, P 16 INT ACM SIGACCE, P317, DOI [10.1145/2661334.266133740, DOI 10.1145/2661334.2661337]
   Vernon M, 1999, AGGRESS VIOLENT BEH, V4, P259, DOI 10.1016/S1359-1789(97)00058-X
   Vondracek D, 2016, TAP TAP APP STORE
   WHO, Deafness and Hearing Loss
   Yassin E, 2015, DEAF APPL ANDROID AP
NR 28
TC 10
Z9 10
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22007
EP 22031
DI 10.1007/s11042-018-5860-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500012
DA 2024-07-18
ER

PT J
AU Dai, YX
   Wang, X
   Zhang, PB
   Zhang, WH
   Chen, JF
AF Dai, Yixiang
   Wang, Xue
   Zhang, Pengbo
   Zhang, Weihang
   Chen, Junfeng
TI Sparsity constrained differential evolution enabled
   feature-channel-sample hybrid selection for daily-life EEG emotion
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EEG signal processing; Emotion recognition; Feature selection; Channel
   selection; Sparsity constrained differential evolution (SCDE)
ID CLASSIFICATION; SYSTEM; BRAIN
AB Electroencephalography (EEG) reflects the activities of human brain and it can represent different emotional states to provide impersonal scientific evidence for daily-life emotional health monitoring. However, traditional multi-channel EEG sensing contains irrelevant or even interferential features, channels or samples, leading to redundant data and hardware complexity. This paper proposes a feature-channel-sample hybrid selection method to improve the channel selection, feature extraction and classification scheme for daily-life EEG emotion recognition. The features and channels are selected in pair with sparsity constrained differential evolution where the feature-channel pairs are optimized synchronously in the global search. Furthermore, the distance evaluation is carried out to remove abnormal samples to improve the emotion recognition accuracy. Therefore, efficient feature vectors for valence-arousal classification can be obtained by a small number of sparsely distributed channels. The experiments are based on the widely-used emotion recognition database DEAP and generate a feature-channel-sample hybrid selection scheme with optimized parameter settings. It can be derived that the proposed method can reduce the EEG channels sharply and maintain a relatively high accuracy compared with the related work. Furthermore, by applying this optimal scheme in practice, the real-scene daily-life EEG emotion recognition experiments are carried out on a sparsity constrained web-enabled system and a 10-fold cross validation is organized to confirm the performance. In conclusion, this paper provides a practical and efficient hardware configuration and feature-channel-sample optimal selection scheme for daily-life EEG emotion recognition.
C1 [Dai, Yixiang; Wang, Xue; Zhang, Pengbo; Zhang, Weihang; Chen, Junfeng] Tsinghua Univ, State Key Lab Precis Measurement Technol & Instru, Dept Precis Instrument, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Wang, X (corresponding author), Tsinghua Univ, State Key Lab Precis Measurement Technol & Instru, Dept Precis Instrument, Beijing 100084, Peoples R China.
EM daiyx12@mails.tsinghua.edu.cn; wangxue@mail.tsinghua.edu.cn
OI Wang, Xue/0000-0003-4842-3160
FU National Natural Science Foundation of China [61472216]; PhD Programs
   Foundation of Ministry of Education of China [20120002110067]
FX This paper is supported by National Natural Science Foundation of China
   under Grant #61472216, and by PhD Programs Foundation of Ministry of
   Education of China under Grant #20120002110067. The authors would like
   to thank Sander Koelstra, Christian Muhl and other dedicated researchers
   in the corresponding groups for providing DEAP dataset.
CR AlZoubi O, 2009, LECT NOTES ARTIF INT, V5866, P52, DOI 10.1007/978-3-642-10439-8_6
   Arvaneh M, 2011, IEEE T BIO-MED ENG, V58, P1865, DOI 10.1109/TBME.2011.2131142
   Casson AJ, 2010, IEEE ENG MED BIOL, V29, P44, DOI 10.1109/MEMB.2010.936545
   Chanel G, 2006, LECT NOTES COMPUT SC, V4105, P530
   Chanel G, 2011, IEEE T SYST MAN CY A, V41, P1052, DOI 10.1109/TSMCA.2011.2116000
   Chanel G, 2009, INT J HUM-COMPUT ST, V67, P607, DOI 10.1016/j.ijhcs.2009.03.005
   Chaovalitwongse WA, 2011, IEEE T SYST MAN CY A, V41, P977, DOI 10.1109/TSMCA.2011.2106118
   Chapman BP, 2013, J PSYCHOSOM RES, V75, P381, DOI 10.1016/j.jpsychores.2013.07.014
   Chung SY, 2012, 2012 12TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS), P1768
   Colwell KA, 2014, J NEUROSCI METH, V232, P6, DOI 10.1016/j.jneumeth.2014.04.009
   Dai YX, 2015, IEEE IMTC P, P1747, DOI 10.1109/I2MTC.2015.7151544
   Dai YX, 2015, MEASUREMENT, V74, P11, DOI 10.1016/j.measurement.2015.07.008
   Iacoviello D, 2015, COMPUT METH PROG BIO, V122, P293, DOI 10.1016/j.cmpb.2015.08.011
   Jenke R, 2014, IEEE T AFFECT COMPUT, V5, P327, DOI 10.1109/TAFFC.2014.2339834
   Jirayucharoensak S, 2014, SCI WORLD J, DOI 10.1155/2014/627892
   Kaur B, 2017, MULTIMED TOOLS APPL, V76, P25581, DOI 10.1007/s11042-016-4232-2
   Khezri M, 2015, COMPUT METH PROG BIO, V122, P149, DOI 10.1016/j.cmpb.2015.07.006
   Khosrowabadi R, 2014, IEEE T NEUR NET LEAR, V25, P609, DOI 10.1109/TNNLS.2013.2280271
   Khushaba RN, 2011, EXPERT SYST APPL, V38, P11515, DOI 10.1016/j.eswa.2011.03.028
   Kim JC, 2015, IEEE T AFFECT COMPUT, V6, P371, DOI 10.1109/TAFFC.2015.2411273
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Konstantinidis EI, 2012, COMPUT METH PROG BIO, V107, P16, DOI 10.1016/j.cmpb.2012.03.008
   Lal TN, 2004, IEEE T BIO-MED ENG, V51, P1003, DOI 10.1109/TBME.2004.827827
   Liang SF, 2012, IEEE T INSTRUM MEAS, V61, P1649, DOI 10.1109/TIM.2012.2187242
   Lin CT, 2014, IEEE SYST J, V8, P363, DOI 10.1109/JSYST.2012.2192756
   Lin YP, 2010, IEEE T BIO-MED ENG, V57, P1798, DOI 10.1109/TBME.2010.2048568
   Morris JD, 1995, J ADVERTISING RES, V35, P63
   Picard RW, 2016, IEEE MULTIMEDIA, V23, P3, DOI 10.1109/MMUL.2016.38
   Picot A, 2012, IEEE T SYST MAN CY A, V42, P764, DOI 10.1109/TSMCA.2011.2164242
   Popescu F, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000637
   Qaraqe M, 2014, 2014 EAI 4TH INTERNATIONAL CONFERENCE ON WIRELESS MOBILE COMMUNICATION AND HEALTHCARE (MOBIHEALTH), P258, DOI [10.4108/icst.mobihealth.2014.257277, 10.1109/MOBIHEALTH.2014.7015960]
   Richman LS, 2005, HEALTH PSYCHOL, V24, P422, DOI 10.1037/0278-6133.24.4.422
   Sannelli C, 2010, BRAIN TOPOGR, V23, P186, DOI 10.1007/s10548-010-0135-0
   Shin D, 2017, MULTIMED TOOLS APPL, V76, P11449, DOI 10.1007/s11042-016-4203-7
   Soleymani M, 2016, IEEE T AFFECT COMPUT, V7, P17, DOI 10.1109/TAFFC.2015.2436926
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   VERMA GK, 2016, MULTIMED TOOLS APPL, P1, DOI DOI 10.1007/S11042-015-3119-Y
   Wang X, 2011, IEEE T MOBILE COMPUT, V10, P1028, DOI 10.1109/TMC.2010.216
   Wang X, 2010, IEEE T INSTRUM MEAS, V59, P171, DOI 10.1109/TIM.2009.2022445
   Wen WH, 2014, IEEE T AFFECT COMPUT, V5, P126, DOI 10.1109/TAFFC.2014.2327617
   Xu HY, 2012, IEEE INT WORKSH MULT, P299, DOI 10.1109/MMSP.2012.6343458
   Xu P, 2007, IEEE T BIO-MED ENG, V54, P400, DOI 10.1109/TBME.2006.886640
   Yilmaz B, 2014, COMPUT METH PROG BIO, V113, P705, DOI 10.1016/j.cmpb.2013.11.010
   Yin Z, 2017, COMPUT METH PROG BIO, V140, P93, DOI 10.1016/j.cmpb.2016.12.005
   Yoon HJ, 2013, COMPUT BIOL MED, V43, P2230, DOI 10.1016/j.compbiomed.2013.10.017
NR 45
TC 9
Z9 9
U1 2
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 21967
EP 21994
DI 10.1007/s11042-018-5618-0
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500010
DA 2024-07-18
ER

PT J
AU Hu, TL
   Li, ZC
AF Hu, Tongling
   Li, Zechao
TI Video summarization via exploring the global and local importance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Global importance; Local importance
ID FRAMEWORK
AB Video Summarization is to generate an important or interesting short video from a long video. It is important to reduce the time required to analyze the same archived video by removing unnecessary video data. This work proposes a novel method to generate dynamic video summarization by fusing the global importance and local importance based on multiple features and image quality. First, videos are split into several suitable video clips. Second, video frames are extracted from each video clip, and the center parts of frames are also extracted. Third, for each frame and the center part, the global importance and the local importance are calculated by using a set of features and image quality. Finally, the global importance and the local importance are fused to select an optimal subset for generating video summarization. Extensive experiments are conducted to demonstrate that the proposed method enables to generate high-quality video summarization.
C1 [Hu, Tongling; Li, Zechao] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Li, ZC (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China.
EM hutongling1@163.com; zechao.li@njust.edu.cn
FU 973 Program [2014CB34 7600]; National Natural Science Foundation of
   China [61522203, 61772275]; Natural Science Foundation of Jiangsu
   Province [BK20140058, BK20170033]
FX This work was partially supported by the 973 Program (Project No.
   2014CB34 7600), the National Natural Science Foundation of China (Grant
   No. 61522203 and 61772275) and the Natural Science Foundation of Jiangsu
   Province (Grant BK20140058 and BK20170033).
CR [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], HUMAN VISION ELECT I
   [Anonymous], P 2006 IEEE COMP SOC
   Bahmanyar R, 2015, IEEE GEOSCI REMOTE S, V12, P2046, DOI 10.1109/LGRS.2015.2444666
   Chen X, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P315, DOI 10.1145/3077136.3080776
   Cheong LF, 2001, MULTIMED TOOLS APPL, V14, P175, DOI 10.1023/A:1011351316971
   Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23
   Dugad R, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P376, DOI 10.1109/MMSP.1998.738965
   Ejaz N, 2013, SIGNAL PROCESS-IMAGE, V28, P34, DOI 10.1016/j.image.2012.10.002
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Goldman DB, 2006, ACM T GRAPHIC, V25, P862, DOI 10.1145/1141911.1141967
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Hu TL, 2017, 2017 IEEE THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2017), P117, DOI 10.1109/BigMM.2017.19
   Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140
   Li ZC, 2014, IEEE T KNOWL DATA EN, V26, P2138, DOI 10.1109/TKDE.2013.65
   Liu Y., 2010, ACM Multimedia, P751
   Mahmoud KM, 2013, 2013 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2013), VOL 2, P303, DOI 10.1109/ICMLA.2013.140
   Mascelli J., 1998, 5 CS CINEMATOGRAPHY
   Min WQ, 2014, IEEE MULTIMEDIA, V21, P20, DOI 10.1109/MMUL.2014.1
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Pritch Y., 2007, IEEE INT C COMPUTER
   Rui Y., 2000, Proceedings ACM Multimedia 2000, P105, DOI 10.1145/354384.354443
   Shih CC, 2001, LECT NOTES COMPUT SC, V2195, P819
   Song ZX, 2009, MODELLING SIMULATION, P435, DOI 10.1109/ICIG.2009.17
   Sun M, 2014, LECT NOTES COMPUT SC, V8689, P787, DOI 10.1007/978-3-319-10590-1_51
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Wolf W, 1996, INT CONF ACOUST SPEE, P1228, DOI 10.1109/ICASSP.1996.543588
   Zhang HJ, 1997, PATTERN RECOGN, V30, P643, DOI 10.1016/S0031-3203(96)00109-4
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
   Zhao B, 2014, PROC CVPR IEEE, P2513, DOI 10.1109/CVPR.2014.322
NR 31
TC 2
Z9 3
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22083
EP 22098
DI 10.1007/s11042-017-5479-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500017
DA 2024-07-18
ER

PT J
AU Luo, XQ
   Li, XY
   Wang, PF
   Qi, SH
   Guan, J
   Zhang, ZC
AF Luo, Xiaoqing
   Li, Xinyi
   Wang, Pengfei
   Qi, Shuhan
   Guan, Jian
   Zhang, Zhancheng
TI Infrared and visible image fusion based on NSCT and stacked sparse
   autoencoders
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Stacked sparse autoencoders; Nonsubsampled contourlet
   transform; Infrared images
ID WAVELET TRANSFORM; CLASSIFICATION; RECOGNITION; INFORMATION; CONTOURLET;
   ALGORITHM; MODEL
AB To integrate the infrared object into the fused image effectively, a novel infrared (IR) and visible (VI) image fusion method by using nonsubsampled contourlet transform (NSCT) and stacked sparse autoencoders (SSAE) is proposed. Firstly, the IR and VI images are decomposed into low-frequency subbands and high-frequency subbands by using NSCT. Secondly, SSAE is performed on the low frequency subband of IR image to calculate the object reliabilities (OR) of the low frequency subband coefficients. Subsequently, an adaptive multi-strategy fusion rule based on OR is designed for the fusion of low frequency subbands and a choose-max fusion rule with the absolute values of high frequency subband coefficients are employed for the fusion of high frequency subbands. Experimental results show the proposed method is superior to the conventional methods in highlighting the infrared objects as well as keeping the background information in VI image.
C1 [Luo, Xiaoqing; Li, Xinyi; Wang, Pengfei] Jiangnan Univ, Sch IoT Engn, Wuxi, Peoples R China.
   [Luo, Xiaoqing] Jiangnan Univ, Jiangsu Prov Engn Lab Pattern Recognit & Computat, Wuxi 214122, Peoples R China.
   [Qi, Shuhan; Guan, Jian] Harbin Inst Technol, Comp Applicat Res Ctr, Shenzhen, Peoples R China.
   [Zhang, Zhancheng] Suzhou Univ Sci & Technol, Sch EIE, Suzhou, Peoples R China.
C3 Jiangnan University; Jiangnan University; Harbin Institute of
   Technology; Suzhou University of Science & Technology
RP Zhang, ZC (corresponding author), Suzhou Univ Sci & Technol, Sch EIE, Suzhou, Peoples R China.
EM cimszhang@163.com
RI li, xinyi/GWZ-8941-2022; li, xin/HHS-9461-2022; Wang,
   Pengfei/ABC-9076-2021; Li, xinyi/HJG-4670-2022
FU National Natural Science Foundation of P. R. China [61772237]; Suzhou
   science and technology project [SYG201702]; Fundamental Research Funds
   for the Central Universities [JUSRP51618B]; Equipment Development and
   Ministry of Education union fund [6141A02033312];  [BK20151358]; 
   [BK20151202]
FX This work was supported by the National Natural Science Foundation of P.
   R. China under grant no.61772237, the Provincial research grant no.
   BK20151358, BK20151202, the Suzhou science and technology project under
   Grant SYG201702, the Fundamental Research Funds for the Central
   Universities JUSRP51618B and the Equipment Development and Ministry of
   Education union fund 6141A02033312.
CR [Anonymous], 2011, INT J DIGITAL CONTEN
   [Anonymous], 2006, Advances in Neural Information Processing Systems 19
   Cai JJ, 2017, INFRARED PHYS TECHN, V82, P85, DOI 10.1016/j.infrared.2017.01.026
   Chai X, 2016, COMPUT BIOL MED, V79, P205, DOI 10.1016/j.compbiomed.2016.10.019
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen Y, 2014, OPTIK, V125, P4980, DOI 10.1016/j.ijleo.2014.04.006
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cui GM, 2015, OPT COMMUN, V341, P199, DOI 10.1016/j.optcom.2014.12.032
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Eckhorn R., 1989, MODELS BRAIN FUNCTIO, P255, DOI DOI 10.1139/W00-039
   Fu ZZ, 2016, INFRARED PHYS TECHN, V77, P114, DOI 10.1016/j.infrared.2016.05.012
   Fu ZZ, 2014, INT CONF SIGN PROCES, P861, DOI 10.1109/ICOSP.2014.7015126
   Gan W, 2015, INFRARED PHYS TECHN, V72, P37, DOI 10.1016/j.infrared.2015.07.003
   Gao CQ, 2013, IEEE T IMAGE PROCESS, V22, P4996, DOI 10.1109/TIP.2013.2281420
   Geng P, 2017, J MED BIOL ENG, V37, P230, DOI 10.1007/s40846-016-0200-6
   Geng X, 2015, IEEE I CONF COMP VIS, P4274, DOI 10.1109/ICCV.2015.486
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li HF, 2016, INFRARED PHYS TECHN, V76, P174, DOI 10.1016/j.infrared.2016.02.005
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Liang JL, 2012, IEEE T IMAGE PROCESS, V21, P2898, DOI 10.1109/TIP.2012.2183140
   Lu B, 2010, P INT S EL COMM
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Qu Xiao-Bo, 2008, Acta Automatica Sinica, V34, P1508, DOI 10.3724/SP.J.1004.2008.01508
   Seal A, 2016, AEU-INT J ELECTRON C, V70, P1041, DOI 10.1016/j.aeue.2016.04.016
   Wang L, 2014, INFORM FUSION, V19, P29, DOI 10.1016/j.inffus.2013.04.005
   Wang M, 2014, INT C PATT RECOG, P3002, DOI 10.1109/ICPR.2014.518
   Xiang TZ, 2015, INFRARED PHYS TECHN, V69, P53, DOI 10.1016/j.infrared.2015.01.002
   Xie L, 2016, MULTIMED TOOLS APPL, V75, P9185, DOI 10.1007/s11042-016-3432-0
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
   Yang L, 2008, NEUROCOMPUTING, V72, P203, DOI 10.1016/j.neucom.2008.02.025
   Yang SY, 2009, SIGNAL PROCESS, V89, P2596, DOI 10.1016/j.sigpro.2009.04.027
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yue C, 2015, INFRARED PHYS TECHN, V71, P313, DOI 10.1016/j.infrared.2015.05.007
   Zhang HW, 2017, IEEE I CONF COMP VIS, P4243, DOI 10.1109/ICCV.2017.454
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
   Zhang Hanwang, 2017, P IEEE C COMP VIS PA, P5532, DOI DOI 10.48550/ARXIV.1702.08319
   Zhang Q, 2016, INFRARED PHYS TECHN, V74, P11, DOI 10.1016/j.infrared.2015.11.003
   Zhang XL, 2017, MULTIMED TOOLS APPL, V76, P8175, DOI 10.1007/s11042-016-3453-8
   Zhang XS, 2016, IEEE T IMAGE PROCESS, V25, P1033, DOI 10.1109/TIP.2015.2511585
   Zhu L., 2016, IJCAI, P3959
   Zhu L, 2017, IEEE T CYBERNETICS, V47, P3941, DOI 10.1109/TCYB.2016.2591068
   Zhu L, 2014, IET IMAGE PROCESS, V8, P509, DOI 10.1049/iet-ipr.2013.0375
   Zhu L, 2014, J SUPERCOMPUT, V68, P820, DOI 10.1007/s11227-013-1068-7
   Zhu LG, 2019, IRONMAK STEELMAK, V46, P499, DOI 10.1080/03019233.2017.1405153
NR 49
TC 10
Z9 14
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22407
EP 22431
DI 10.1007/s11042-018-5985-6
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500036
DA 2024-07-18
ER

PT J
AU Nayak, DR
   Dash, R
   Majhi, B
AF Nayak, Deepak Ranjan
   Dash, Ratnakar
   Majhi, Banshidhar
TI Development of pathological brain detection system using Jaya optimized
   improved extreme learning machine and orthogonal ripplet-II transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pathological Brain Detection System (PBDS); Magnetic Resonance Imaging
   (MRI); Orthogonal Discrete Ripplet-II Transform (O-DR2T); Extreme
   Learning Machine (ELM); Jaya Algorithm
ID STATIONARY WAVELET TRANSFORM; SUPPORT VECTOR MACHINE; IMAGE
   CLASSIFICATION; TSALLIS ENTROPY; RADON-TRANSFORM; MRI; HYBRIDIZATION;
   DIAGNOSIS; ADABOOST; CURVES
AB Pathological brain detection systems (PBDSs) have drawn much attention from researchers over the past two decades because of their significance in taking correct clinical decisions. In this paper, an efficient PBDS based on MR images is introduced that markedly improves the recent results. The proposed system makes use of contrast limited adaptive histogram equalization (CLAHE) and orthogonal discrete ripplet-II transform (O-DR2T) with degree 2 to enhance the quality of the input MR images and extract the features respectively. Subsequently, relevant features are obtained using PCA+LDA approach. Finally, a novel learning algorithm called IJaya-ELM is proposed that combines improved Jaya algorithm (IJaya) and extreme learning machine (ELM) for segregation of MR images as pathological or healthy. The improved Jaya algorithm is utilized to optimize the input weights and hidden biases of single-hidden-layer feedforward neural networks (SLFN), whereas one analytical method is used for determining the output weights. The proposed algorithm performs optimization according to both the root mean squared error (RMSE) and the norm of the output weights of SLFNs. Extensive experiments are carried out using three benchmark datasets and the results are compared against other competent schemes. The experimental results demonstrate that the proposed scheme brings potential improvements in terms of classification accuracy and number of features. Moreover, the proposed IJaya-ELM classifier achieves higher accuracy and obtains compact network architecture compared to conventional ELM and BPNN classifier.
C1 [Nayak, Deepak Ranjan; Dash, Ratnakar; Majhi, Banshidhar] Natl Inst Technol, Dept Comp Sci & Engn, Pattern Recognit Lab, Rourkela 769008, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Nayak, DR (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Pattern Recognit Lab, Rourkela 769008, India.
EM depakranjannayak@gmail.com
RI Dash, Ratnakar/F-1498-2018; Nayak, Deepak Ranjan/AED-5548-2022
OI Nayak, Deepak Ranjan/0000-0002-8929-5778
CR [Anonymous], 2017, ARXIV170801104
   [Anonymous], SIMULATION
   [Anonymous], 5 NAT IEEE C COMP VI
   [Anonymous], 2015, 2015 INT C COMP COMM
   Candes E.J., 2000, CURVE SURFACE FITTIN, P105
   Candès EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116
   Candès EJ, 1999, PHILOS T R SOC A, V357, P2495, DOI 10.1098/rsta.1999.0444
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Chaplot S, 2006, BIOMED SIGNAL PROCES, V1, P86, DOI 10.1016/j.bspc.2006.05.002
   CORMACK AM, 1981, P AM MATH SOC, V83, P325, DOI 10.2307/2043520
   CORMACK AM, 1982, P AM MATH SOC, V86, P293, DOI 10.2307/2043399
   Das S, 2013, PROG ELECTROMAGN RES, V137, P1, DOI 10.2528/PIER13010105
   Do MN, 2003, IEEE T IMAGE PROCESS, V12, P16, DOI 10.1109/TIP.2002.806252
   Duan FF, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1054-z
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   El-Dahshan ESA, 2010, DIGIT SIGNAL PROCESS, V20, P433, DOI 10.1016/j.dsp.2009.07.002
   Ghahremani M, 2015, IEEE GEOSCI REMOTE S, V12, P502, DOI 10.1109/LGRS.2014.2347955
   Hamza R, 2017, PERVASIVE MOBILE COM
   Han F, 2013, NEUROCOMPUTING, V116, P87, DOI 10.1016/j.neucom.2011.12.062
   Holzinger A, 2016, LECT NOTES COMPUT SC, V9817, P81, DOI 10.1007/978-3-319-45507-5_6
   Holzinger Andreas, 2016, Brain Inform, V3, P119, DOI 10.1007/s40708-016-0042-6
   Holzinger Katharina, 2014, Interactive Knowledge Discovery and Data Mining in Biomedical Informatics. State-of-the-Art and Future Challenges: LNCS 8401, P35, DOI 10.1007/978-3-662-43968-5_3
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2011, INT J MACH LEARN CYB, V2, P107, DOI 10.1007/s13042-011-0019-y
   Johnson K.A., 1999, The whole brain atlas
   Liu YH, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6050142
   Maitra M, 2006, BIOMED SIGNAL PROCES, V1, P299, DOI 10.1016/j.bspc.2006.12.001
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Nayak D. R., 2016, MULTIMED TOOLS APPL, P1
   Nayak DR, 2017, CNS NEUROL DISORD-DR, V16, P137, DOI 10.2174/1871527315666161024142036
   Nayak DR, 2016, NEUROCOMPUTING, V177, P188, DOI 10.1016/j.neucom.2015.11.034
   Nayak DR, 2017, EXPERT SYSTEMS APPL
   Pizer S. M., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P337, DOI 10.1109/VBC.1990.109340
   Rao R., 2016, Int J Ind Eng Comput, V7, P19, DOI [DOI 10.5267/J.IJIEC.2015.8.004, 10.5267/j.ijiec.2015.8.004]
   Rao RV, 2016, APPL THERM ENG, V103, P572, DOI 10.1016/j.applthermaleng.2016.04.135
   Sajjad M, 2017, IEEE ACCESS, V5, P3475, DOI 10.1109/ACCESS.2016.2636218
   Saritha M, 2013, PATTERN RECOGN LETT, V34, P2151, DOI 10.1016/j.patrec.2013.08.017
   Suresh S, 2009, APPL SOFT COMPUT, V9, P541, DOI 10.1016/j.asoc.2008.07.005
   Wang SH, 2017, FUND INFORM, V151, P275, DOI 10.3233/FI-2017-1492
   Wang SH, 2017, FUND INFORM, V151, P191, DOI 10.3233/FI-2017-1487
   Wang SH, 2016, BIOMED ENG-BIOMED TE, V61, P431, DOI 10.1515/bmt-2015-0152
   Wang SH, 2015, ENTROPY-SWITZ, V17, P8278, DOI 10.3390/e17127877
   Wang SH, 2015, INT J IMAG SYST TECH, V25, P153, DOI 10.1002/ima.22132
   Westbrook C., 2014, HDB MRI TECHNIQUE, V4
   Xu J, 2012, IET IMAGE PROCESS, V6, P374, DOI 10.1049/iet-ipr.2010.0225
   Xu J, 2010, J VIS COMMUN IMAGE R, V21, P627, DOI 10.1016/j.jvcir.2010.04.002
   Xu Y, 2006, LECT NOTES COMPUT SC, V3971, P644
   Yang GL, 2016, MULTIMED TOOLS APPL, V75, P15601, DOI [10.1007/s11042-015-2649-7, 10.1155/2015/932029]
   Yang H, 2003, PATTERN RECOGN, V36, P563, DOI 10.1016/S0031-3203(02)00048-1
   Zhang GS, 2015, AER ADV ENG RES, V8, P683
   Zhang Y, 2012, PROG ELECTROMAGN RES, V130, P369, DOI 10.2528/PIER12061410
   Zhang Y, 2011, PROG ELECTROMAGN RES, V116, P65, DOI 10.2528/PIER11031709
   Zhang Y, 2010, PROG ELECTROMAGN RES, V109, P325, DOI 10.2528/PIER10090105
   Zhang YaKun Zhang YaKun, 2016, Journal of Nanjing Forestry University (Natural Sciences Edition), V40, P1
   Zhang YD, 2017, COMPUT ELECTR ENG, V63, P126, DOI 10.1016/j.compeleceng.2017.04.009
   Zhang YD, 2016, IEEE ACCESS, V4, P5937, DOI 10.1109/ACCESS.2016.2611530
   Zhang YD, 2015, INT J IMAG SYST TECH, V25, P317, DOI 10.1002/ima.22144
   Zhang YD, 2013, SCI WORLD J, DOI 10.1155/2013/130134
   Zhang YD, 2017, CNS NEUROL DISORD-DR, V16, P122, DOI 10.2174/1871527315666161026115046
   Zhang YD, 2015, J MED IMAG HEALTH IN, V5, P1395, DOI 10.1166/jmihi.2015.1542
   Zhang YD, 2015, PROG ELECTROMAGN RES, V152, P41, DOI 10.2528/PIER15040602
   Zhang YD, 2015, BIO-MED MATER ENG, V26, pS1283, DOI 10.3233/BME-151426
   Zhang YD, 2015, ENTROPY-SWITZ, V17, P1795, DOI 10.3390/e17041795
   Zhang YD, 2011, EXPERT SYST APPL, V38, P10049, DOI 10.1016/j.eswa.2011.02.012
   Zhao G., 2009, COMMUNICATIONS-GER, P1
   Zhou XX, 2015, LECT N BIOINFORMAT, V9043, P201, DOI 10.1007/978-3-319-16483-0_20
   Zhu QY, 2005, PATTERN RECOGN, V38, P1759, DOI 10.1016/j.patcog.2005.03.028
NR 68
TC 13
Z9 13
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22705
EP 22733
DI 10.1007/s11042-017-5281-x
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500051
DA 2024-07-18
ER

PT J
AU Chen, BJ
   Zhou, CF
   Jeon, B
   Zheng, YH
   Wang, JW
AF Chen, Beijing
   Zhou, Chunfei
   Jeon, Byeungwoo
   Zheng, Yuhui
   Wang, Jinwei
TI Quaternion discrete fractional random transform for color image adaptive
   watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image; Quaternion; Adaptive watermarking; Fractional random
   transform
ID FOURIER-TRANSFORM; COSINE; ROBUST; SINE
AB As for the fractional transforms, to date only fractional Fourier transform (FrFT) has been applicable to color images in a holistic manner by using the quatemion algebra, yet, discrete fractional random transform (DFRNT) with the useful intrinsic randomness is still to be explored. This paper first defines quaternion DFRNT (QDFRNT) which generalizes DFRNT to efficiently process quatemion signals, and then applies QDFRNT to color image adaptive watermarking. For the QDFRNT, this paper also derives the relationship between QDFRNT of a quatemion signal and DFRNT of four components for this signal to efficiently compute QDFRNT. For the color image adaptive watermarking based on QDFRNT and SVM, in order to efficiently utilize the color information in the adaptive process, this paper also exploits the human vision system's (HVS) masking properties of texture, edge and color tone directly from the color host image to adaptively adjust the watermark strength for each block. In addition, the constraints in watermark embedding are discussed to preserve the watennarking energy. Experimental results show that: (a) the proposed efficient computation method takes only half the computational time of the direct method; (b) the comparison of five color models (RGB, YUV, YIQ, CIEL*a*b* and YCbCr) shows that the proposed QDFRNT-based watermarking scheme using YCbCr color model has the overall best performance and can achieve a good balance between invisibility and robustness to the Checkmark attacks; (c) The proposed scheme is superior to the existing schemes respectively using DCT, DFRNT, discrete quatemion Fourier transform (DQFT), discrete fractional quatemion Fourier transform DFrQFT), and quatemion radial moments (QRMs). Moreover, the fractional order and the random matrix of QDFRNT enhance the security of the proposed scheme.
C1 [Chen, Beijing; Zhou, Chunfei; Zheng, Yuhui; Wang, Jinwei] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
   [Chen, Beijing; Zheng, Yuhui; Wang, Jinwei] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Jiangsu, Peoples R China.
   [Chen, Beijing; Jeon, Byeungwoo] Sungkyunkwan Univ, Coll Informat & Commun Engn, Suwon 440746, South Korea.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; Sungkyunkwan University
   (SKKU)
RP Chen, BJ (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.; Chen, BJ (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Jiangsu, Peoples R China.; Chen, BJ (corresponding author), Sungkyunkwan Univ, Coll Informat & Commun Engn, Suwon 440746, South Korea.
EM nbutimage@126.com
RI Jeon, Byeungwoo/AAS-1096-2021; Zheng, Yuhui/AAF-2420-2019
OI Jeon, Byeungwoo/0000-0002-5650-2881; 
FU NSFC [61572258, 61772281, 61572257, 61602253]; Natural Science
   Foundation of Jiangsu Province of China [BK20151530, BK20150925]; BK21+
   program by the Ministry of Education of Korea; G-ITRC support program
   [IITP-2017-2015-0-00742]; PAPD fund - Qing Lan Project
FX This work was supported by the NSFC under Grants 61572258, 61772281,
   61572257, and 61602253, the Natural Science Foundation of Jiangsu
   Province of China under Grants BK20151530, and BK20150925, BK21+ program
   by the Ministry of Education of Korea, the G-ITRC support program
   (IITP-2017-2015-0-00742) supervised by the IITP, the PAPD fund,
   sponsored by Qing Lan Project.
CR Bas P, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P521
   Chan WL, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P996
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chauhan DS, 2019, MULTIMED TOOLS APPL, V78, P3911, DOI 10.1007/s11042-017-4886-4
   Chen BJ, 2017, J VIS COMMUN IMAGE R, V49, P283, DOI 10.1016/j.jvcir.2017.08.011
   Chen BJ, 2017, NEUROCOMPUTING, V266, P293, DOI 10.1016/j.neucom.2017.05.047
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Chen BJ, 2014, DIGIT SIGNAL PROCESS, V28, P106, DOI 10.1016/j.dsp.2014.02.010
   Ell T.A., 2000, P 10 EUR SIGN PROC C, P1
   Ell TA, 2007, IEEE T IMAGE PROCESS, V16, P22, DOI 10.1109/TIP.2006.884955
   Fatima N, 2016, 2016 CONFERENCE ON ADVANCES IN SIGNAL PROCESSING (CASP), P13
   Feng W, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P252, DOI 10.1109/CISP.2008.61
   Guo J, 2007, OPT COMMUN, V272, P344, DOI 10.1016/j.optcom.2006.11.034
   Hamilton W., 1866, ELEMENTS QUATERNIONS
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Hu HT, 2017, MULTIMED TOOLS APPL, V76, P6575, DOI 10.1007/s11042-016-3332-3
   Jiang Shu-hong, 2009, Acta Electronica Sinica, V37, P1773
   Jin LH, 2013, IEEE IMAGE PROC, P3040, DOI 10.1109/ICIP.2013.6738626
   Jin R, 2012, COMM COM INF SC, V342, P39
   Kalra GS, 2015, MULTIMED TOOLS APPL, V74, P6849, DOI 10.1007/s11042-014-1932-3
   Lan RS, 2017, IEEE T CIRC SYST VID, V27, P261, DOI 10.1109/TCSVT.2015.2492839
   Liu ZJ, 2005, OPT COMMUN, V255, P357, DOI 10.1016/j.optcom.2005.06.031
   Lu CS, 2006, IEEE T MULTIMEDIA, V8, P668, DOI 10.1109/TMM.2006.876300
   Mendlovic D, 1997, APPL OPTICS, V36, P4801, DOI 10.1364/AO.36.004801
   NAMIAS V, 1980, J I MATH APPL, V25, P241
   Niu PP, 2016, MULTIMED TOOLS APPL, V75, P7655, DOI 10.1007/s11042-015-2687-1
   Novak CL., 1987, P DARPA IMAGE UNDERS, V1, P35
   Pandey R, 2016, MULTIMED TOOLS APPL, V75, P14381, DOI 10.1007/s11042-016-3536-6
   Pei SC, 2002, IEEE T SIGNAL PROCES, V50, P1661, DOI 10.1109/TSP.2002.1011207
   Pei SC, 2001, IEEE T SIGNAL PROCES, V49, P1198, DOI 10.1109/78.923302
   Peng H, 2010, J SYST SOFTWARE, V83, P1470, DOI 10.1016/j.jss.2010.03.006
   Peng H, 2009, LECT NOTES ARTIF INT, V5571, P213, DOI 10.1007/978-3-642-02282-1_27
   Pereira S., 2001, INFORM HIDING, P340, DOI [10.1007/3-540-45496-925, DOI 10.1007/3-540-45496-925]
   Qi HY, 2008, SIGNAL PROCESS, V88, P174, DOI 10.1016/j.sigpro.2007.07.020
   Roopkumar R, 2016, OPTIK, V127, P11657, DOI 10.1016/j.ijleo.2016.09.069
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh AK, 2015, WIRELESS PERS COMMUN, V83, P2133, DOI 10.1007/s11277-015-2505-0
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Subakan ON, 2011, INT J COMPUT VISION, V91, P233, DOI 10.1007/s11263-010-0388-9
   Tsai HH, 2007, INFORM SCIENCES, V177, P550, DOI 10.1016/j.ins.2006.05.002
   Tsougenis ED, 2014, EXPERT SYST APPL, V41, P6408, DOI 10.1016/j.eswa.2014.04.021
   Verma VS, 2015, J VIS COMMUN IMAGE R, V31, P75, DOI 10.1016/j.jvcir.2015.06.001
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Wang XY, 2013, J SYST SOFTWARE, V86, P255, DOI 10.1016/j.jss.2012.08.015
   Wang YQ, 2016, J APPL GEOPHYS, V129, P8, DOI 10.1016/j.jappgeo.2016.03.011
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei DY, 2013, OPTIK, V124, P6999, DOI 10.1016/j.ijleo.2013.05.163
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2017, PROC IEEE MICR ELECT, P813, DOI 10.1109/MEMSYS.2017.7863532
   Xie X, 2016, PROC IEEE MICR ELECT, P75, DOI 10.1109/MEMSYS.2016.7421561
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Xu GL, 2008, SIGNAL PROCESS, V88, P2511, DOI 10.1016/j.sigpro.2008.04.012
   Zear A, 2018, J INTELL SYST, V27, P5, DOI 10.1515/jisys-2016-0036
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang L, 2013, IEEE IMAGE PROC, P171, DOI 10.1109/ICIP.2013.6738036
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
NR 58
TC 36
Z9 36
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20809
EP 20837
DI 10.1007/s11042-017-5511-2
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300023
DA 2024-07-18
ER

PT J
AU Fan, HJ
   Li, M
   Liu, D
   An, K
AF Fan, Haiju
   Li, Ming
   Liu, Dong
   An, Kang
TI Cryptanalysis of a plaintext-related chaotic RGB image encryption scheme
   using total plain image characteristics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptanalysis; Chosen plaintext attack; Known plaintext attack; Logistic
   map; Permutation; Diffusion
ID ALGORITHM; BREAKING; IMPROVEMENT; STANDARD; MAP
AB Recently, a novel plaintext-related RGB image encryption scheme has been proposed, where the security is strengthened by associating the initial condition and control parameter of one logistic map with total plain image characteristics. This paper points out its weakness that the secret location storing the total characteristics cannot adapt to different plain images. Accordingly, we propose a strategy to break this encryption scheme by applying chosen/known plaintext attacks, where the data complexity of attack is reduced to the minimum. The experimental results prove that all the secret matrices can be revealed effectively. Meanwhile, three corresponding improvements are given to guarantee its security, which help to design more secure plaintext-related cryptosystems in the future.
C1 [Fan, Haiju; Li, Ming; Liu, Dong] Henan Normal Univ, Coll Comp & Informat Engn, Xinxiang 453007, Peoples R China.
   [Fan, Haiju] China Natl Digital Switching Syst Engn & Technol, Zhengzhou 450002, Henan, Peoples R China.
   [Li, Ming] Beihang Univ, Sch Automat Sci & Elect Engn, Beijing 100191, Peoples R China.
   [An, Kang] Shanghai Nonnal Univ, Coll Informat Mech & Elect Engn, Shanghai 200234, Peoples R China.
C3 Henan Normal University; PLA Information Engineering University; Beihang
   University
RP An, K (corresponding author), Shanghai Nonnal Univ, Coll Informat Mech & Elect Engn, Shanghai 200234, Peoples R China.
EM ankang526@foxmail.com
RI Li, Ming/Q-6532-2016
FU National Natural Science Foundation of China [61602158, U1404604,
   U1604156]; China Postdoctoral Science Foundation [2016 M600030]; Science
   Foundation for the Excellent Youth Scholars of Henan Normal University
   [YQ201607]; Shanghai Natural Science Foundation [6ZR1424600]
FX This work was supported through the National Natural Science Foundation
   of China (Grant Nos. 61602158, U1404604, U1604156), the China
   Postdoctoral Science Foundation (Grant No. 2016 M600030), the Science
   Foundation for the Excellent Youth Scholars of Henan Normal University
   (Grant No. YQ201607), and the Shanghai Natural Science Foundation (Grant
   No. 6ZR1424600).
CR Ahmad J, 2015, NONLINEAR DYNAM, V82, P1839, DOI 10.1007/s11071-015-2281-0
   Ahmad M, 2015, ADV INTELL SYST, V338, P381, DOI 10.1007/978-3-319-13731-5_41
   Alligood K. A., 1996, Chaos: An Introduction to Dynamical Systems
   [Anonymous], USC SIPI IM DAT
   Bechikh R, 2015, SIGNAL PROCESS-IMAGE, V39, P151, DOI 10.1016/j.image.2015.09.006
   Cheng PG, 2015, NONLINEAR DYNAM, V79, P2121, DOI 10.1007/s11071-014-1798-y
   Fan HJ, 2018, SIGNAL PROCESS, V143, P28, DOI 10.1016/j.sigpro.2017.08.018
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Hsiao HI, 2015, SIGNAL PROCESS, V117, P281, DOI 10.1016/j.sigpro.2015.06.007
   Jolfaei A, 2016, IEEE T INF FOREN SEC, V11, P235, DOI 10.1109/TIFS.2015.2489178
   Kerckhoffs A, 1978, J DES MILITAIRES, Vix, P5
   Li CQ, 2012, NONLINEAR DYNAM, V70, P2383, DOI 10.1007/s11071-012-0626-5
   Li CQ, 2011, COMMUN NONLINEAR SCI, V16, P837, DOI 10.1016/j.cnsns.2010.05.008
   Li M, 2016, OPT LASER TECHNOL, V86, P33, DOI 10.1016/j.optlastec.2016.06.012
   Li M, 2014, OPTIK, V125, P7231, DOI 10.1016/j.ijleo.2014.07.130
   Li M, 2014, SIGNAL PROCESS, V99, P17, DOI 10.1016/j.sigpro.2013.12.011
   Liao X, 2016, SECUR COMMUN NETW, V9, P5756, DOI 10.1002/sec.1734
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Norouzi B, 2017, MULTIMED TOOLS APPL, V76, P1817, DOI 10.1007/s11042-015-3085-4
   Norouzi B, 2014, MULTIMEDIA SYST, V20, P45, DOI 10.1007/s00530-013-0314-4
   Patidar V, 2010, COMMUN NONLINEAR SCI, V15, P2755, DOI 10.1016/j.cnsns.2009.11.010
   Ramalingam B, 2018, MULTIMED TOOLS APPL, V77, P11669, DOI 10.1007/s11042-017-4811-x
   Rhouma R, 2010, COMMUN NONLINEAR SCI, V15, P1887, DOI 10.1016/j.cnsns.2009.07.007
   Solak E, 2010, INT J BIFURCAT CHAOS, V20, P1405, DOI 10.1142/S0218127410026563
   Song CY, 2013, OPTIK, V124, P3329, DOI 10.1016/j.ijleo.2012.11.002
   Teng L, 2018, MULTIMED TOOLS APPL, V77, P6883, DOI 10.1007/s11042-017-4605-1
   Usama M, 2010, COMPUT MATH APPL, V60, P326, DOI 10.1016/j.camwa.2009.12.033
   Wang XY, 2012, INT J MOD PHYS B, V26, DOI 10.1142/S0217979212501755
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Xu Y, 2014, COMMUN NONLINEAR SCI, V19, P3735, DOI 10.1016/j.cnsns.2014.02.029
   Zhang E, 2017, INFORM SCIENCES, V387, P180, DOI 10.1016/j.ins.2016.09.056
   Zhang E, 2015, MOB INF SYST, V2015, DOI 10.1155/2015/462345
   Zhang LY, 2018, IEEE T CYBERNETICS, V48, P1163, DOI 10.1109/TCYB.2017.2682561
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P2066, DOI 10.1016/j.cnsns.2012.12.012
   Zhang Y, 2011, TELKOMNIKA INDONESIA, V12, P635
   Zhang Y., 2014, TELKOMNIKA INDONES J, V12, P7952
   Zhang Y., 2012, TELKOMNIKA, V10, P1254, DOI DOI 10.11591/TELKOMNIKA.V10I6.1599
   Zhang Y, 2016, IETE TECH REV, V33, P310, DOI 10.1080/02564602.2015.1087350
   Zhang Y, 2012, NONLINEAR DYNAM, V69, P1091, DOI 10.1007/s11071-012-0329-y
   Zhang YS, 2014, NONLINEAR DYNAM, V76, P1645, DOI 10.1007/s11071-014-1235-2
   Zhao JF, 2015, NONLINEAR DYNAM, V80, P1721, DOI 10.1007/s11071-015-1911-x
NR 45
TC 45
Z9 45
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 20103
EP 20127
DI 10.1007/s11042-017-5437-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500054
DA 2024-07-18
ER

PT J
AU Joy, E
   Peter, JD
AF Joy, Emmanuel
   Peter, J. Dinesh
TI Perspective model-based visual tracking scheme for robust tracking of
   objects in complex environs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Perspective model; Occlusion handling; Adaptive
   learning
ID LOW-RANK; SPARSE; FILTER; REPRESENTATION
AB Robust tracking of moving objects is still an open problem in computer vision. The problem and its difficulty depend on many factors, which includes the availability of prior knowledge of the target. Occlusions and fast motions are among the major challenges in the process. When such hindrances occur, misjudgment of the target causes incorrect updating of target template model. Therefore, preserving the stability and precision of the tracker becomes crucial. This paper addresses the problem of handling fast moving objects and dynamic occlusions in visual tracking. The novelty of the proposed method is in the usage of an active perspective learning and a new adaptive incremental model update mechanism. A consistency measure acquired using the information from the spatial viewpoint model and the perspective model differentiates the target from its surrounding at every instance of tracking. The Discrete Hartley transform (DHT) is applied for image transformation, learning and target prediction. To auto-adjust the bounding box during tracking, a new technique of dynamic scale fill-in is used. Experimental results of the proposed method, when tested on a number of challenging datasets with occlusion, non-rigid deformation, and other major challenges highlights the better ability and robustness of the proposed method under tough conditions.
C1 [Joy, Emmanuel; Peter, J. Dinesh] Kamnya Univ, Dept Informat Technol, Coimbatore, Tamil Nadu, India.
RP Joy, E (corresponding author), Kamnya Univ, Dept Informat Technol, Coimbatore, Tamil Nadu, India.
EM emmanueljoy@karunya.edu.in; dineshpeter@karunya.edu
RI Peter, J. Dinesh/E-2144-2018; Joy, Emmanuel/K-5447-2019
OI Peter, J. Dinesh/0000-0002-4357-7163; Joy, Emmanuel/0000-0003-0971-3720
CR Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108
   Amittal A, 2004, COMP VIS PATT REC 20, V2
   [Anonymous], P EUR C COMP VIS ECC
   [Anonymous], 2006, BMVC
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   [Anonymous], 2010, ECCV
   [Anonymous], 2014, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2013.230
   Asgarizadeh M, 2013, SIVIP, V9, P175
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P972, DOI 10.1109/TIP.2002.802531
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   Coifman B, 1998, TRANSPORT RES C-EMER, V6, P271, DOI 10.1016/S0968-090X(98)00019-9
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comport AI, 2006, IEEE T VIS COMPUT GR, V12, P615, DOI 10.1109/TVCG.2006.78
   Dyckmanns H, 2011, IEEE INT VEH SYM, P625, DOI 10.1109/IVS.2011.5940443
   Ellis L, 2011, INT J COMPUT VISION, V95, P154, DOI 10.1007/s11263-010-0364-4
   Grabner H., 2010, CVPR
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Ho MC, 2012, PATTERN RECOGN LETT, V33, P500, DOI 10.1016/j.patrec.2011.11.019
   Horbert E, 2011, INT C COMP VIS
   Hu WM, 2013, IEEE T IMAGE PROCESS, V22, P1778, DOI 10.1109/TIP.2012.2236340
   Joy E, 2017, MULTIMEDIA SYSTEMS, P1
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Kwon J., 2010, CVPR
   Lee K-C, 2005, COMP VIS PATT REC 20, V1
   Liu X, 2015, IEEE T IMAGE PROCESS, V24, P2502, DOI 10.1109/TIP.2015.2419084
   Liu X, 2013, NEUROCOMPUTING, V119, P439, DOI 10.1016/j.neucom.2013.03.013
   MALIK J, 1996, TRAFFIC SURVEILLANCE
   McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Nigam S, 2012, IET COMPUT VIS, V6, P231, DOI 10.1049/iet-cvi.2011.0023
   Papadakis N, 2011, IEEE T PATTERN ANAL, V33, P144, DOI 10.1109/TPAMI.2010.56
   Pau CA, 1996, TRANSP SENSORS CONTR, V2902, P156
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Polana R., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P77, DOI 10.1109/MNRAO.1994.346251
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Roth D, 2010, MULTIMED TOOLS APPL, V50, P29, DOI 10.1007/s11042-009-0365-x
   Schiele B., 2000, Proc. IEEE International Workshop Performance Evaluation of Tracking and Surveillance, P61
   Weng SK, 2006, J VIS COMMUN IMAGE R, V17, P1190, DOI 10.1016/j.jvcir.2006.03.004
   Subudhi BN, 2011, IEEE T CIRC SYST VID, V21, P993, DOI 10.1109/TCSVT.2011.2133870
   Sun X, 2011, COMP VIS PATT REC CV
   Wang D, 2014, PROC CVPR IEEE, P3478, DOI 10.1109/CVPR.2014.445
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Yadav K, 2016, ADV INTELL SYST, V384, P559, DOI 10.1007/978-3-319-23036-8_49
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zeisl Bernhard., 2010, CVPR
   Zhang B, 2008, IEEE T IMAGE PROCESS, V17, P664, DOI 10.1109/TIP.2008.919949
   Zhang L, 2014, IEEE T PATTERN ANAL, V36, P756, DOI 10.1109/TPAMI.2013.221
   Zhang TZ, 2016, IEEE T CYBERNETICS, V46, P51, DOI 10.1109/TCYB.2015.2393307
   Zhang TZ, 2015, INT J COMPUT VISION, V111, P171, DOI 10.1007/s11263-014-0738-0
   Zhang TZ, 2013, INT J COMPUT VISION, V101, P367, DOI 10.1007/s11263-012-0582-z
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
   Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
   Zimmermann K, 2009, IEEE T PATTERN ANAL, V31, P677, DOI 10.1109/TPAMI.2008.119
NR 56
TC 0
Z9 0
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19745
EP 19768
DI 10.1007/s11042-017-5424-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500039
DA 2024-07-18
ER

PT J
AU Méndez, R
   Flores, J
   Castelló, E
   Viqueira, JRR
AF Mendez, Roi
   Flores, Julian
   Castello, Enrique
   Rios Viqueira, Jose Ramon
TI New distributed virtual TV set architecture for a synergistic operation
   of sensors and improved interaction between real and virtual worlds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VirtualTVsets; Human computer interaction; TV; TVbroadcasting; Virtual
   reality
ID MICROSOFT KINECT; ACCURACY; TRACKING; CAMERA
AB A virtual TV set is a studio that is able to combine recorded actors and objects with computer generated virtual environments in real time. In order to achieve this combination seamlessly, in an ideal configuration, several elements such as cameras, objects and people should be tracked so that all their actions on the stage have a corresponding effect in the virtual world. However, in the actual professional virtual TV sets, the tracking possibilities are quite limited because of the hardware and software architecture used, which has not had a major evolution since the first prototypes presented in the nineties. This traditional architecture uses to be rigid, including just one monolithic tracking system and low levels of interactivity. In this paper, a new distributed, flexible and scalable hardware and software architecture that allows the inclusion of multiple kinds of devices in parallel is introduced. It breaks with the traditional structure of the virtual TV sets, opening the technology to an easier inclusion of new devices without the need of updating the proprietary software of the set, thus facilitating its future evolution. The design, implementation and test of this architecture, through the adaptation of a traditional virtual TV set, is presented. The tests are developed through the inclusion of modern devices (in our case Optitrack infrared cameras, Microsoft Kinect V2 and Leap Motion) that, through a synergistic operation, allow the system to solve some traditional drawbacks of this technology such as free and multiple object and camera tracking, presenter natural interaction and automatic distance keying.
C1 [Mendez, Roi; Flores, Julian; Rios Viqueira, Jose Ramon] Univ Santiago de Compostela, CITIUS, Santiago De Compostela, Spain.
   [Castello, Enrique] Univ Santiago de Compostela, Fac Commun Sci, Santiago De Compostela, Spain.
C3 Universidade de Santiago de Compostela; Universidade de Santiago de
   Compostela
RP Méndez, R (corresponding author), Univ Santiago de Compostela, CITIUS, Santiago De Compostela, Spain.
EM roi.mendez@usc.es; julian.flores@usc.es; enrique.castello@usc.es;
   jrr.viqueira@usc.es
RI Méndez, Roi/M-7839-2016; Fernandez, Roi Mendez/AAO-7148-2020; Viqueira,
   Jose R/L-5728-2014; Flores, Julian/L-5932-2014
OI Méndez, Roi/0000-0003-2405-6538; Fernandez, Roi
   Mendez/0000-0003-2405-6538; Flores, Julian/0000-0002-9607-1756;
   Viqueira, Jose R.R./0000-0002-1539-3746; Castello-Mayo,
   Enrique/0000-0003-1915-3990
FU Conselleria de Cultura, Educacion e Ordenacion Universitaria
   [ED431G/08]; European Regional Development Fund (ERDF)
FX Brainstorm Multimedia for their continuous support during the
   development of this project. Manuel Fidalgo for his help and advice.
   This work has received financial support from the Conselleria de
   Cultura, Educacion e Ordenacion Universitaria (accreditation 2016-2019,
   ED431G/08) and the European Regional Development Fund (ERDF).
CR [Anonymous], 2016, HD SD CHROMA KEYER V
   Blonde L, 1996, IEEE MULTIMEDIA, V3, P18, DOI 10.1109/93.502291
   Brainstorm, 2016, REAL TIM 3D GRAPH VI
   Eckerson W. W., 1995, OPEN INFORMATION SYS, V3, P1
   Fellous A, 1993, VIRTUAL WORLDS MULTI, P127
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Gibbs S, 1998, IEEE MULTIMEDIA, V5, P18, DOI 10.1109/93.664740
   Goldsmlith A. N., 1937, U S Patent No, Patent No. [2,073,370, 2073370]
   Gonzalez-Jorge H, 2013, MEASUREMENT, V46, P1800, DOI 10.1016/j.measurement.2013.01.011
   Guna J, 2014, SENSORS-BASEL, V14, P3702, DOI 10.3390/s140203702
   Hayashi M, 1998, IEEE MULTIMEDIA, V5, P36, DOI 10.1109/93.664741
   KENNEDY RC, 1958, P IRE, V46, P1798, DOI 10.1109/JRPROC.1958.286850
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437
   Lalioti V, 2003, MIX REAL PROD FUT IB
   Lange R, 2001, IEEE J QUANTUM ELECT, V37, P390, DOI 10.1109/3.910448
   Leap Motion, 2016, MAC PC MOT CONTR GAM
   Mendez R, 2016, P 2016 IEEE 21 INT C, P1
   SHIMODA S, 1989, IEEE T BROADCAST, V35, P357, DOI 10.1109/11.40835
   Suma EA, 2011, P IEEE VIRT REAL ANN, P247, DOI 10.1109/VR.2011.5759491
   Taylor R.M., 2001, Proceedings of the ACM Symposium on Virtual Reality Software and Technology - VRST '01, P55, DOI [10.1145/505008.505019, DOI 10.1145/505008.505019, 10.1145/505008.505019., DOI 10.1145/505008.5050192]
   Thomas G, 2006, INT WORKSH MIX REAL, P31
   Thomas GA, 1997, IEE CONF PUBL, P284, DOI 10.1049/cp:19971284
   Weichert F, 2013, SENSORS-BASEL, V13, P6380, DOI 10.3390/s130506380
   Wojdala A, 1998, IEEE MULTIMEDIA, V5, P50, DOI 10.1109/93.664742
   Xiao Q, 2008, KAM: 2008 INTERNATIONAL SYMPOSIUM ON KNOWLEDGE ACQUISITION AND MODELING, PROCEEDINGS, P741, DOI 10.1109/KAM.2008.186
   Xirouhakis YS, 2001, IEEE T IMAGE PROCESS, V10, P609, DOI 10.1109/83.913595
   Yang L, 2015, IEEE SENS J, V15, P4275, DOI 10.1109/JSEN.2015.2416651
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhao G, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON IT IN MEDICINE AND EDUCATION, VOLS 1 AND 2, PROCEEDINGS, P198, DOI 10.1109/ITME.2008.4743851
NR 29
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 18999
EP 19025
DI 10.1007/s11042-017-5353-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500006
DA 2024-07-18
ER

PT J
AU Picinin, D
   Farines, JM
   Santos, CAS
   Koliver, C
AF Picinin, Delcino, Jr.
   Farines, Jean-Marie
   Santos, Celso A. S.
   Koliver, Cristian
TI A design-oriented method to build correct hypermedia documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hypermedia document; Formal verification; Model checking; MDE
ID VERIFICATION; MODEL
AB Over the years, different approaches to identify temporal and spatial conflicts in hypermedia applications has been proposed. Most of them are based on formal verification techniques and impose to the designers to follow a formal model or language to ensure application's functional correctness. Furthermore, the error diagnose is hard to be interpreted by a non-specialist in this domain. In this paper, we present an approach which supports formal verification for documents written in markup languages. We proposed a method and built a verification toolchain that helps designers to verify time and spatial constraints in hypermedia applications. The input language is the designer language. Its translation towards the input of toolchain is automatic and transparent for the application designer. The errors scenarios provided by the verification tool are presented in a timeline way, easily understandable by the designer. The method and toolchain support different markup languages translated in the same intermediary language in order to facilitate the use of different verification tools in the same environment.
C1 [Picinin, Delcino, Jr.] Fed Inst Santa Catarina, BR-88495000 Garopaba, SC, Brazil.
   [Farines, Jean-Marie; Koliver, Cristian] Univ Fed Santa Catarina, BR-88040900 Florianopolis, SC, Brazil.
   [Santos, Celso A. S.] Univ Fed Espirito Santo, BR-29075910 Vitoria, ES, Brazil.
C3 Instituto Federal de Santa Catarina (IFSC); Universidade Federal de
   Santa Catarina (UFSC); Universidade Federal do Espirito Santo
RP Picinin, D (corresponding author), Fed Inst Santa Catarina, BR-88495000 Garopaba, SC, Brazil.
EM delcino.junior@ifsc.edu.br; j.m.farines@ufsc.br; saibel@inf.ufes.br;
   cristian.koliver@ufsc.br
RI SANTOS, CELSO Alberto Saibel/M-9733-2014
OI SANTOS, CELSO Alberto Saibel/0000-0002-3287-5843
CR Abid N, 2012, REAL TIME SPECIFICAT, P1
   ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   [Anonymous], 2008, ERTSS
   Azevedo RGA, 2014, MULTIMED TOOLS APPL, V70, P1199, DOI 10.1007/s11042-012-1216-8
   Beckert B, 2014, IEEE INTELL SYST, V29, P20, DOI 10.1109/MIS.2014.3
   Berthomieu B, 2004, INT J PROD RES, V42, P2741, DOI [10.1080/00207540412331312688, 10.1080/00207540410001705257]
   Berthomieu B, 2009, FORMAL VERIFICATION
   Bolton ML, 2013, IEEE T SYST MAN CY-S, V43, P488, DOI 10.1109/TSMCA.2012.2210406
   Bouyakoub S, 2011, ACM T MULTIM COMPUT, V30, P1
   Bridge JP, 2014, J AUTOM REASONING, V53, P141, DOI 10.1007/s10817-014-9301-5
   Burton JK, 1995, COMPUTERS HUMAN BEHA
   Clarke EM, 1999, MODEL CHECKING, P1
   Combéfis S, 2011, IEEE SYS MAN CYBERN, P1801, DOI 10.1109/ICSMC.2011.6083933
   De Oliveira MCF, 2001, ACM T INFORM SYST, V19, P28, DOI 10.1145/366836.366869
   dos Santos J, 2015, SCI COMPUT PROGRAM, V107, P64, DOI 10.1016/j.scico.2015.04.006
   dosSantos Joel A. F., 2015, DOCENG 15, P133, DOI DOI 10.1145/2682571.2797060
   Farail P, 2006, 3 EUR C EMB REAL TIM
   Felix MF, 2001, TECHNICAL REPORT
   dos Santos JAF, 2012, MULTIMED TOOLS APPL, V61, P645, DOI 10.1007/s11042-011-0732-2
   Gaggi O, 2011, MULTIMEDIA SYST, V17, P487, DOI 10.1007/s00530-011-0233-1
   Jin-Cheon Na, 2001, Proceedings of the ACM Symposium on Document Engineering (DocEng '01), P38
   Jouault F, 2006, LECT NOTES COMPUT SC, V3844, P128
   Junior D. P., 2012, P 18 BRAZ S M ULT WE, P223, DOI 10.1145/2382636.2382685
   Li Li, 2016, P 23 IEEE INT C SOFT
   Mekahlia FZ, 2016, J INTEGR DES PROCESS, V20, P39, DOI 10.3233/jid-2016-0020
   Moreno MF, 2006, P 2006 ACM S DOC ENG, P165, DOI [10.1145/1166160.1166202, DOI 10.1145/1166160.1166202]
   Palmeira AF, 2009, P 7 EUR C INT TV VID, P114
   Pandey M, 2016, PROCEEDINGS OF THE 2016 16TH CONFERENCE ON FORMAL METHODS IN COMPUTER-AIDED DESIGN (FMCAD 2016), P4, DOI 10.1109/FMCAD.2016.7886650
   Sampaio P. N. M., 2004, Journal of the Brazilian Computer Society, V9, P39, DOI [https://doi.org/10.1590/S0104-65002004000100004, DOI 10.1590/S0104-65002004000100004]
   Santos C. A. S., 1998, Proceedings ACM Multimedia 98, P39, DOI 10.1145/290747.290753
   Schmidt DC, 2006, COMPUTER, V39, P25, DOI 10.1109/MC.2006.58
   Yovine S, 2010, S BRAS SIST MULT WEB
   Yu HQ, 2002, FOURTH INTERNATIONAL SYMPOSIUM ON MULTIMEDIA SOFTWARE ENGINEERING, PROCEEDINGS, P132, DOI 10.1109/MMSE.2002.1181605
NR 33
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21003
EP 21032
DI 10.1007/s11042-017-5325-2
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300031
DA 2024-07-18
ER

PT J
AU Zeng, WL
   Fu, XP
   Hu, CH
   Du, YJ
AF Zeng, Weili
   Fu, Xiping
   Hu, Changhui
   Du, Yijun
TI Wavelet denoising with generalized bivariate prior model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Wavelet coefficient; Generalized bivariate prior model;
   Variance estimation
ID IMAGE; SHRINKAGE; DISTRIBUTIONS; MIXTURE
AB This paper presents a novel wavelet method based on a prior model of wavelet coefficient with a generalized bivariate distribution function. The generalized bivariate prior model extends the isotropic bivariate prior model and anisotropic prior model, and can well characterize the joint parent-child statistical properties of many categories of images. Owing to the fact that the variance of wavelet coefficients are quite different for different scales and positions, we propose a local adaptive marginal variance estimation method based on this newly generalized prior model to improve the accuracy of marginal variance by considering the distribution of wavelet coefficients as the combination of Gaussian distribution and Laplacian distribution. By simulation experiments from three aspects, the results of the proposed method outperform the mainstream isotropic wavelet methods and anisotropic wavelet methods, and the practicality of the proposed method is verified by real noise image experiments.
C1 [Zeng, Weili] Nanjing Univ Aeronaut & Astronaut, Coll Civil Aviat, Nanjing 210016, Jiangsu, Peoples R China.
   [Fu, Xiping] Univ Otago, Dept Comp Sci, Dunedin 9016, New Zealand.
   [Hu, Changhui; Du, Yijun] Southeast Univ, Sch Automat, Key Lab Measurement & Control CSE, Minist Educ, Nanjing 210096, Jiangsu, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; University of Otago;
   Southeast University - China
RP Zeng, WL (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Civil Aviat, Nanjing 210016, Jiangsu, Peoples R China.
EM zwlnuaa@nuaa.edu.cn
RI Hu, Chang-Hui/AAD-8822-2020
OI Zeng, Weili/0000-0002-5266-2423
FU National Natural Science Foundation of China [61403081, U1333202];
   Natural Science Foundation of Jiangsu Province [BK20140638]
FX The authors would like to thank the editors and anonymous reviewers for
   their constrctive and valuable comments, which helped in improving the
   presentation of our work. This work was supported by the National
   Natural Science Foundation of China (61403081, U1333202), and the
   Natural Science Foundation of Jiangsu Province (BK20140638).
CR Achim A, 2005, IEEE SIGNAL PROC LET, V12, P17, DOI 10.1109/LSP.2004.839692
   Chen G, 2016, NEUROCOMPUTING, V177, P215, DOI 10.1016/j.neucom.2015.11.031
   Chen GY, 2013, PROCEEDINGS OF THE 2013 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL AND INFORMATION PROCESSING (ICICIP), P570
   Chen GY, 2005, INTEGR COMPUT-AID E, V12, P99
   Chen GY, 2003, IEEE SIGNAL PROC LET, V10, P211, DOI 10.1109/LSP.2003.811586
   Cho D, 2005, SIGNAL PROCESS-IMAGE, V20, P77, DOI 10.1016/j.image.2004.10.003
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dong M, 2015, SIGNAL PROCESS, V109, P25, DOI 10.1016/j.sigpro.2014.10.017
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.1080/01621459.1995.10476626
   Du YJ, 2016, MULTIMED TOOLS APPL, V75, P987, DOI 10.1007/s11042-014-2338-y
   Figueiredo MAT, 2001, IEEE T IMAGE PROCESS, V10, P1322, DOI 10.1109/83.941856
   Hill PR, 2014, SIGNAL PROCESS, V105, P464, DOI 10.1016/j.sigpro.2014.03.028
   Hu CH, 2015, NEUROCOMPUTING, V160, P287, DOI 10.1016/j.neucom.2015.02.032
   Huang DA, 2014, IEEE T MULTIMEDIA, V16, P83, DOI 10.1109/TMM.2013.2284759
   Hyvärinen A, 1999, NEURAL COMPUT, V11, P1739, DOI 10.1162/089976699300016214
   Jain P, 2016, INFORM SYST FRONT, V18, P159, DOI 10.1007/s10796-014-9527-0
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Loza A, 2010, COMPUT VIS IMAGE UND, V114, P54, DOI 10.1016/j.cviu.2009.09.002
   Nasri M, 2009, NEUROCOMPUTING, V72, P1012, DOI 10.1016/j.neucom.2008.04.016
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Rabbani H, 2010, IET IMAGE PROCESS, V4, P413, DOI 10.1049/iet-ipr.2009.0048
   Rabbani H, 2006, IEEE IMAGE PROC, P2597, DOI 10.1109/ICIP.2006.313018
   Rabbani H, 2009, IEEE T BIO-MED ENG, V56, P2826, DOI 10.1109/TBME.2009.2028876
   Rahman SMM, 2008, IEEE T IMAGE PROCESS, V17, P1755, DOI 10.1109/TIP.2008.2002163
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sendur L, 2002, IEEE T SIGNAL PROCES, V50, P2744, DOI 10.1109/TSP.2002.804091
   Tan S, 2007, INT J COMPUT VISION, V75, P209, DOI 10.1007/s11263-006-0019-7
   Tomassi D, 2015, SIGNAL PROCESS, V106, P73, DOI 10.1016/j.sigpro.2014.07.001
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Yin SF, 2011, SIGNAL PROCESS, V91, P2078, DOI 10.1016/j.sigpro.2011.03.016
   Yoon SM, 2016, MULTIMED TOOLS APPL, V75, P15929, DOI 10.1007/s11042-015-2905-x
   Zeng W, 2015, MULTIMED TOOLS APPL, V74, P743, DOI 10.1007/s11042-013-1692-5
   Zeng WL, 2011, ELECTRON LETT, V47, P1125, DOI 10.1049/el.2011.2456
   Zeng WL, 2017, MULTIMED TOOLS APPL, V76, P13239, DOI 10.1007/s11042-016-3753-z
   Zeng WL, 2015, NEUROCOMPUTING, V162, P218, DOI 10.1016/j.neucom.2015.03.049
   Zeng WL, 2013, IET IMAGE PROCESS, V7, P335, DOI 10.1049/iet-ipr.2012.0155
NR 41
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20863
EP 20887
DI 10.1007/s11042-017-5497-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300025
DA 2024-07-18
ER

PT J
AU Zhang, Y
AF Zhang, Yong
TI The image encryption algorithm based on chaos and DNA computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DNA computing; Piecewise linear chaotic map; Image encryption;
   Information security; Sensitivity analysis
ID SEQUENCE OPERATION; SCHEME; IMPROVEMENT
AB The existing DNA based image cryptosystems, their DNA coding scheme just employs four DNA symbols, namely A, T, C and G, to represent the four binary two-tuples, namely 00b, 01b, 10b and 11b, respectively. And the used DNA computing algorithms, such as DNA addition and subtraction, are essentially the binary modulo 2 addition and XOR operations without any meanings of genetic engineering, which cannot apply to the DNA computer for processing. So, this paper discussed the DNA coding of image and proposed a new DNA join operation. And the complementary operation of DNA code instead of the complementary operation of binary number is used in the proposed. The piecewise linear chaotic map was employed to generate the key stream. Then, a new DNA based image cryptosystem including two rounds of DNA diffusion and DNA confusion was proposed, which can be rapidly implemented in the DNA computer. The image cryptosystem was simulated with an electronic computer, and the results show that the proposed system possesses the characteristics of large key space, good statistical properties of cipher images, high sensitivities of key and plain images and big information entropy. Therefore, the proposed image cryptosystem is a candidate for the future secure communication application to the DNA computer.
C1 [Zhang, Yong] Jiangxi Univ Finance & Econ, Sch Software & Commun Engn, Nanchang, Jiangxi, Peoples R China.
C3 Jiangxi University of Finance & Economics
RP Zhang, Y (corresponding author), Jiangxi Univ Finance & Econ, Sch Software & Commun Engn, Nanchang, Jiangxi, Peoples R China.
EM zhangyong@jxufe.edu.cn
OI Zhang, Yong/0000-0002-7428-1816
FU National Natural Science Foundation of China [61762043, 61562035];
   Natural Science Foundation of Jiangxi Province, China [20161BAB202058];
   Science and Technology Project of Education Department of Jiangxi
   Province, China [GJJ160426]
FX This work was fully supported by the National Natural Science Foundation
   of China (Grant Nos. 61762043 and 61562035), the Natural Science
   Foundation of Jiangxi Province, China (Grant No. 20161BAB202058), and
   the Science and Technology Project of Education Department of Jiangxi
   Province, China (Grant No. GJJ160426).
CR Belazi A, 2014, NONLINEAR DYNAM, V76, P1
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen JX, 2015, COMMUN NONLINEAR SCI, V20, P846, DOI 10.1016/j.cnsns.2014.06.032
   Cheng PG, 2015, NONLINEAR DYNAM, V79, P2121, DOI 10.1007/s11071-014-1798-y
   Eslami Z, 2013, OPT COMMUN, V286, P51, DOI 10.1016/j.optcom.2012.07.052
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Guesmi R., 2015, NONLINEAR DYNAM, V83, P1
   Hermassi H, 2014, MULTIMED TOOLS APPL, V72, P2211, DOI 10.1007/s11042-013-1533-6
   Li S., 2001, IMA International Conference on Cryptography and Coding, V2260, P205, DOI [10.1007/3-540-45325-319, DOI 10.1007/3-540-45325-319]
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Özkaynak F, 2014, NONLINEAR DYNAM, V78, P1311, DOI 10.1007/s11071-014-1517-8
   Pareschi F, 2012, IEEE T INF FOREN SEC, V7, P491, DOI 10.1109/TIFS.2012.2185227
   Su X, 2017, MULTIMED TOOLS APPL, V76, P14021, DOI 10.1007/s11042-016-3800-9
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wong KW, 2002, PHYS LETT A, V298, P238, DOI 10.1016/S0375-9601(02)00431-0
   Xie T, 2014, OPTIK, V125, P7166, DOI 10.1016/j.ijleo.2014.07.111
   Zeng L, 2015, OPTIK, V126, P5022, DOI 10.1016/j.ijleo.2015.09.219
   Zhang Q, 2013, OPTIK, V124, P6276, DOI 10.1016/j.ijleo.2013.05.009
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang Q, 2013, J COMPUT THEOR NANOS, V10, P341, DOI 10.1166/jctn.2013.2702
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang Y., 2016, J Comput Theor Nanosci, V13, P4025, DOI [10.1166/jctn.2016.5244, DOI 10.1166/JCTN.2016.5244]
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P6647, DOI 10.1007/s11042-017-4577-1
   Zhang Y, 2016, IETE TECH REV, V33, P310, DOI 10.1080/02564602.2015.1087350
   Zhang Y, 2015, OPTIK, V126, P223, DOI 10.1016/j.ijleo.2014.08.129
   Zhang YS, 2014, OPTIK, V125, P1562, DOI 10.1016/j.ijleo.2013.09.018
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
NR 29
TC 53
Z9 55
U1 1
U2 65
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21589
EP 21615
DI 10.1007/s11042-017-5585-x
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300056
DA 2024-07-18
ER

PT J
AU Zhu, XY
   Wang, P
   Huang, ZH
AF Zhu, Xiangyu
   Wang, Ping
   Huang, Zhenghai
TI Adaptive propagation matting based on transparency of image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Matting; Transparency; Propagation; Texture
ID COLOR
AB Image matting is an essential technique in many image and video editing applications. Although many matting methods have been proposed, it is still a challenge for most to obtain satisfactory matting results in the transparent foreground region of an image. To solve this problem, this paper proposes a novel matting algorithm, i.e. adaptive transparency-based propagation matting (ATPM) algorithm. ATPM algorithm considers image matting from a new slant. We pay attention to the transparencies of the input images and creatively assign them into three categories (highly transparent, strongly transparent and little transparent) according to the transparencies of the foreground objects in the images. Our matting model can make relevant adjustment in terms of the transparency types of the input images. Moreover, many current matting methods do not perform well when the foreground and background regions have similar color distributions. Our method adds texture as an additional feature to effectively discriminate the foreground and background regions. Experimental results on the benchmark dataset show that our method gets high-quality matting results for images of three transparency types, especially provides more accurate results for highly transparent images comparing with the state-of-the-art methods.
C1 [Zhu, Xiangyu; Wang, Ping; Huang, Zhenghai] Tianjin Univ, Sch Math, Tianjin 300354, Peoples R China.
C3 Tianjin University
RP Zhu, XY (corresponding author), Tianjin Univ, Sch Math, Tianjin 300354, Peoples R China.
EM xyzhu@tju.edu.cn; wang_ping@tju.edu.cn; huangzhenghai@tju.edu.cn
RI Wang, Ping/GPP-2471-2022; Huang, Zheng-Hai/F-8646-2012
OI Zhu, Xiangyu/0000-0003-1098-4069
FU National Natural Science Foundation of China [11431002]
FX This work was partially supported by the National Natural Science
   Foundation of China (Grant No. 11431002).
CR Aksoy Y, 2017, PROC CVPR IEEE, P228, DOI 10.1109/CVPR.2017.32
   [Anonymous], 2008 C COMP VIS PATT
   Bai XF, 2007, IEEE IC COMP COM NET, P1
   Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1
   Cao GY, 2016, I C VIRTUAL REALITY, P24, DOI 10.1109/ICVRV.2016.13
   Chen QF, 2013, IEEE T PATTERN ANAL, V35, P2175, DOI 10.1109/TPAMI.2013.18
   Chen XW, 2013, PROC CVPR IEEE, P1902, DOI 10.1109/CVPR.2013.248
   Cho D, 2016, LECT NOTES COMPUT SC, V9906, P626, DOI 10.1007/978-3-319-46475-6_39
   Chuang YY, 2001, PROC CVPR IEEE, P264
   Feng XX, 2016, LECT NOTES COMPUT SC, V9906, P204, DOI 10.1007/978-3-319-46475-6_13
   Gastal ESL, 2010, COMPUT GRAPH FORUM, V29, P575, DOI 10.1111/j.1467-8659.2009.01627.x
   Grady L, 2005, PROCEEDINGS OF THE FIFTH IASTED INTERNATIONAL CONFERENCE ON VISUALIZATION, IMAGING, AND IMAGE PROCESSING, P423
   He B, 2012, IEEE IMAGE PROC, P285, DOI 10.1109/ICIP.2012.6466851
   Hu WC, 2016, MULTIMED TOOLS APPL, V75, P3495, DOI 10.1007/s11042-015-2449-0
   Jin M, 2014, IEEE T CIRC SYST VID, V24, P1101, DOI 10.1109/TCSVT.2014.2302531
   Johnson J, 2016, IEEE T IMAGE PROCESS, V25, P3032, DOI 10.1109/TIP.2016.2555705
   Kaiming He, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2049, DOI 10.1109/CVPR.2011.5995495
   Karacan L, 2015, IEEE I CONF COMP VIS, P424, DOI 10.1109/ICCV.2015.56
   Lee P., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2193, DOI 10.1109/CVPR.2011.5995665
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P1699, DOI 10.1109/TPAMI.2008.168
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li C, 2017, COMPUT VIS IMAGE UND, V162, P34, DOI 10.1016/j.cviu.2017.06.011
   Lin YC, 2012, MULTIMED TOOLS APPL, V61, P551, DOI 10.1007/s11042-010-0678-9
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Omer I, 2004, PROC CVPR IEEE, P946
   Porter T., 1984, Computers & Graphics, V18, P253
   Rhemann C., 2008, P BRIT MACHINE VISIO, P1155
   Rhemann C, 2009, PROC CVPR IEEE, P1826, DOI 10.1109/CVPRW.2009.5206503
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Ruzon MA, 2000, PROC CVPR IEEE, P18, DOI 10.1109/CVPR.2000.855793
   Shahrian E, 2013, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2013.88
   Shahrian E, 2012, PROC CVPR IEEE, P718, DOI 10.1109/CVPR.2012.6247741
   Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721
   Tan GH, 2016, MULTIMED TOOLS APPL, V75, P10213, DOI 10.1007/s11042-015-3160-x
   Varnousfaderani ES, 2013, IEEE T IMAGE PROCESS, V22, P4260, DOI 10.1109/TIP.2013.2271549
   Wang J, 2005, IEEE I CONF COMP VIS, P936
   Wang J., 2007, 2007 IEEE C COMP VIS, P1
   Wang J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239460
   Wright S., 2006, DIGITAL COMPOSITING
   Xu Ning, 2017, PROC IEEE C COMPUT V, P2970
   Yang CK, 2016, MULTIMED TOOLS APPL, V75, P4441, DOI 10.1007/s11042-015-2483-y
   Zhang ZP, 2012, IEEE IMAGE PROC, P2109, DOI 10.1109/ICIP.2012.6467308
   Zheng YY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185595
   Zheng YJ, 2009, IEEE I CONF COMP VIS, P889, DOI 10.1109/ICCV.2009.5459326
NR 45
TC 5
Z9 6
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19089
EP 19112
DI 10.1007/s11042-017-5357-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500010
DA 2024-07-18
ER

PT J
AU Amato, F
   Castiglione, A
   Moscato, V
   Picariello, A
   Sperlì, G
AF Amato, Flora
   Castiglione, Aniello
   Moscato, Vincenzo
   Picariello, Antonio
   Sperli, Giancarlo
TI Multimedia summarization using social media content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual analytics; Multimedia summarization; Online social networks;
   Influence analysis
ID ALGORITHM
AB In this work, we propose a novel multimedia summarization technique from Online Social Networks (OSNs). In particular, we model each Multimedia Social Network (MSN)-i.e. an OSN focusing on the management and sharing of multimedia information-using an hypergraph based approach and exploit influence analysis methodologies to determine the most important multimedia objects with respect to one or more topics of interest. Successively, we obtain from the list of candidate objects a multimedia summary using a summarization model together with an heuristics that aims to generate summaries with priority (with respect to some user keywords), continuity, variety and not receptiveness features. The performed experiments on Flickr shows the effectiveness of proposed approach.
C1 [Amato, Flora; Picariello, Antonio; Sperli, Giancarlo] Univ Naples Federico II, Dept Elect Engn & Informat Technol, Via Claudio 21, I-80125 Naples, Italy.
   [Castiglione, Aniello] Univ Salerno, Via Giovanni Paolo II,132, Fisciano, Salerno, Italy.
C3 University of Naples Federico II; University of Salerno
RP Amato, F (corresponding author), Univ Naples Federico II, Dept Elect Engn & Informat Technol, Via Claudio 21, I-80125 Naples, Italy.
EM flora.amato@unina.it; castiglione@ieee.org; vmoscato@unina.it;
   picus@unina.it; giancarlo.sperli@unina.it
RI Moscato, Vincenzo/H-2526-2012; Picariello, Antonio/L-6820-2015;
   Castiglione, Aniello/F-1034-2011; Amato, Flora/N-1408-2016
OI Castiglione, Aniello/0000-0003-0571-1074; Amato,
   Flora/0000-0002-5128-5558
CR Aggarwal C, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2601412
   Albanese M, 2006, INFORM SYST, V31, P679, DOI 10.1016/j.is.2005.12.003
   Albanese M, 2010, MULTIMED TOOLS APPL, V50, P563, DOI 10.1007/s11042-010-0480-8
   Aljawarneh S, 2017, MULTIMED TOOLS APPL, V76, P22703, DOI 10.1007/s11042-016-4333-y
   Aljawarneh S, 2010, FOURTH INTERNATIONAL CONFERENCE ON DIGITAL SOCIETY: ICDS 2010, PROCEEDINGS, P192, DOI 10.1109/ICDS.2010.40
   Amato F, 2016, IEEE INT C SEMANT CO, P447, DOI 10.1109/ICSC.2016.20
   Amato F, 2016, J VISUAL LANG COMPUT, V32, P35, DOI 10.1016/j.jvlc.2015.10.012
   [Anonymous], 2006, NIPS
   Bian JW, 2015, IEEE T MULTIMEDIA, V17, P216, DOI 10.1109/TMM.2014.2384912
   Bian JW, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P1807, DOI 10.1145/2505515.2505652
   Carullo G, 2015, WORLD WIDE WEB, V18, P1579, DOI 10.1007/s11280-015-0333-5
   Castiglione A., 2011, Proceedings of the 2011 Third International Conference on Intelligent Networking and Collaborative Systems (INCoS 2011), P679, DOI 10.1109/INCoS.2011.17
   Castiglione A., 2011, 2011 International Conference on Broadband, Wireless Computing, Communication and Applications, P363, DOI 10.1109/BWCCA.2011.60
   Colace F, 2014, J VISUAL LANG COMPUT, V25, P818, DOI 10.1016/j.jvlc.2014.11.001
   Cook K. A., 2005, Illuminating the path: The research and development agenda for visual analytics
   d'Acierno A, 2009, 2009 10TH INTERNATIONAL WORKSHOP ON IMAGE ANALYSIS FOR MULTIMEDIA INTERACTIVE SERVICES, P57, DOI 10.1109/WIAMIS.2009.5031431
   d'Acierno A, 2015, SMART INNOV SYST TEC, V40, P21, DOI 10.1007/978-3-319-19830-9_3
   dAcierno A., 2012, 2012 IEEE Sixth International Conference on Semantic Computing (ICSC 2012), P162, DOI 10.1109/ICSC.2012.13
   Del Fabro M., 2012, P INT C ADV MULT, P119
   Ding D., 2012, P 2 ACM INT C MULT R, P2
   Fang B, 2017, IEEE T KNOWL DATA EN
   Fang Q, 2014, IEEE T MULTIMEDIA, V16, P796, DOI 10.1109/TMM.2014.2298216
   Flora A, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P343, DOI 10.1109/SITIS.2016.62
   Hahn U, 2000, COMPUTER, V33, P29, DOI 10.1109/2.881692
   Heintz Benjamin, 2014, ACM SIGMETRICS Performance Evaluation Review, V41, P94
   Imran A, 2016, J UNIVERS COMPUT SCI, V22, P494
   Kang CH, 2016, ARTIF INTELL, V239, P70, DOI 10.1016/j.artint.2016.06.008
   Kempe D, 2003, P 9 ACM SIGKDD INT C, P137, DOI DOI 10.1145/956750.956769
   Li ZC, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2822907
   LUHN HP, 1958, IBM J RES DEV, V2, P159, DOI 10.1147/rd.22.0159
   Modani N, 2016, LECT NOTES COMPUT SC, V10042, P340, DOI 10.1007/978-3-319-48743-4_27
   Nenkova A., 2012, MINING TEXT DATA, P43, DOI [10.1007/978-1-4614-3223-4_3, 10.1007/978- 1- 4614-3223- 4_3.]
   Qian SS, 2016, IEEE T MULTIMEDIA, V18, P233, DOI 10.1109/TMM.2015.2510329
   Rudinac S, 2013, IEEE T MULTIMEDIA, V15, P1231, DOI 10.1109/TMM.2013.2261481
   Sankar CP, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168125
   Schinas M, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P203, DOI 10.1145/2671188.2749407
   Scott John, 2012, Social network analysis
   Sevindik V, 2012, PROCEEDINGS OF THE 37TH ANNUAL IEEE CONFERENCE ON LOCAL COMPUTER NETWORKS WORKSHOPS (LCN 2012), P679, DOI 10.1109/LCNW.2012.6424050
   Shah RR, 2016, KNOWL-BASED SYST, V108, P102, DOI 10.1016/j.knosys.2016.05.022
   Wu YC, 2016, IEEE T MULTIMEDIA, V18, P2135, DOI 10.1109/TMM.2016.2614220
   Yang Q, 2017, IEEE T EVOLUT COMPUT, V21, P191, DOI 10.1109/TEVC.2016.2591064
   [No title captured]
   [No title captured]
NR 43
TC 22
Z9 23
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 17803
EP 17827
DI 10.1007/s11042-017-5556-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900013
DA 2024-07-18
ER

PT J
AU Jia, XY
   He, DB
   Li, L
   Choo, KKR
AF Jia, Xiaoying
   He, Debiao
   Li, Li
   Choo, Kim-Kwang Raymond
TI Signature-based three-factor authenticated key exchange for internet of
   things applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Three-factor authenticated key exchange; Biometrics;
   Fuzzy extractor
ID AGREEMENT; SCHEME; SECURE; IOT
AB Internet of Things (IoT) is one of several technology trends, and IoT applications are found in a wide range of industry sectors such as healthcare and critical infrastructure. Authenticated key exchange schemes play an important role in protecting user and data privacy and ensuring the security of data-in-transit in IoT infrastructure (e.g. via user identification and provision of secure communication). However, designing secure authenticated key exchange (AKE) schemes remain a challenging task. In this paper, we reveal that Challa et al.'s three-factor AKE scheme is vulnerable to a number of known attacks. Then, we present an improved signature-based three-factor authenticated key exchange protocol and prove its security under the extended model of Bellare et al. (Tecnologia Electronica E Informatica 1807:139-155, 2000). A comparative summary is also presented, which demonstrates that our proposed scheme is sufficiently lightweight for IoT deployment and outperforms those of Challa et al. (IEEE Access 5:3028-3043, 2017) and Turkanovi et al. (Ad Hoc Netw 20(2):96-112, 2014), in terms of security features, computation and communication costs.
C1 [Jia, Xiaoying] South Cent Univ Nationalities, Sch Math & Stat, Wuhan, Hubei, Peoples R China.
   [He, Debiao] Wuhan Univ, Comp Sch, State Key Lab Software Engn, Wuhan, Hubei, Peoples R China.
   [He, Debiao] State Key Lab Cryptol, Beijing, Peoples R China.
   [Li, Li] Wuhan Univ, Int Sch Software, Wuhan, Hubei, Peoples R China.
   [Choo, Kim-Kwang Raymond] Univ Texas San Antonio, Dept Informat Syst & Cyber Secur, San Antonio, TX USA.
   [Choo, Kim-Kwang Raymond] Univ South Australia, Sch Informat Technol & Math Sci, Adelaide, SA, Australia.
C3 South Central Minzu University; Wuhan University; Wuhan University;
   University of Texas System; University of Texas at San Antonio (UTSA);
   University of South Australia
RP He, DB (corresponding author), Wuhan Univ, Comp Sch, State Key Lab Software Engn, Wuhan, Hubei, Peoples R China.; He, DB (corresponding author), State Key Lab Cryptol, Beijing, Peoples R China.
EM xiaoyin.jia@mail.scuec.edu.cn; hedebiao@163.com; lli@whu.edu.cn;
   Raymond.Choo@fulbrightmail.org
RI Choo, Kim-Kwang Raymond/A-3634-2009; jia, xiaoying/ITT-5541-2023; He,
   Debiao/F-6355-2011
OI Choo, Kim-Kwang Raymond/0000-0001-9208-5336; He,
   Debiao/0000-0002-2446-7436
FU Fundamental Research Funds for the Central Universities [CZY15018];
   National Natural Science Foundation of China [61603419, 61572379,
   61501333]
FX The work of X. Jia was supported in part by the Fundamental Research
   Funds for the Central Universities under Grant CZY15018 and in part by
   the National Natural Science Foundation of China under Grant No.
   61603419. The work of D. He was supported in part by the National
   Natural Science Foundation of China under Grant 61572379, and Grant
   61501333.
CR Abdalla M, 2005, LECT NOTES COMPUT SC, V3386, P65
   Amin R, 2016, COMPUT NETW, V101, P42, DOI 10.1016/j.comnet.2016.01.006
   Atzori L, 2010, COMPUT NETW, V54, P2787, DOI 10.1016/j.comnet.2010.05.010
   Bellare M, 2000, LECT NOTES COMPUT SC, V1807, P139
   Challa S, 2017, IEEE ACCESS, V5, P3028, DOI 10.1109/ACCESS.2017.2676119
   Chen CL, 2012, MOBILE DEVICE INTEGR
   Das AK, 2016, PEER TO PEER NETWORK, V9, P1
   Ding W, 2016, IEEE T DEPENDABLE SE
   Doshi N, 2017, MULTIMED TOOLS APPL, V76, P25893, DOI 10.1007/s11042-017-4701-2
   Gennaro R, 2008, LECT NOTES COMPUT SC, V4948, P589, DOI 10.1007/978-3-540-78524-8_32
   Groce A, 2010, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'10), P516, DOI 10.1145/1866307.1866365
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Jiang Q, 2016, J SUPERCOMPUT, V72, P3826, DOI 10.1007/s11227-015-1610-x
   Khan MK, 2014, COMPUTING, V96, P793, DOI 10.1007/s00607-013-0308-2
   Kumari S, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3930
   Lee CC, 2014, NONLINEAR DYNAM, V76, P853, DOI 10.1007/s11071-013-1174-3
   LI CC, 2017, PEER TO PEER NETWORK, P1, DOI DOI 10.1007/S12083-017-0564-6
   Li CT, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0322-3
   Nam J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0116709
   Tan ZW, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0016-2
   Turkanovic M, 2014, AD HOC NETW, V20, P96, DOI 10.1016/j.adhoc.2014.03.009
   Wu F, 2015, COMPUT ELECTR ENG, V45, P274, DOI 10.1016/j.compeleceng.2015.02.015
   Yang Y, 2015, 21 AUSTR C INF SEC P, P265
   Zhang M, 2007, LECT NOTES COMPUT SC, V4859, P312
NR 24
TC 23
Z9 23
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18355
EP 18382
DI 10.1007/s11042-017-5560-6
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900041
DA 2024-07-18
ER

PT J
AU Chen, TY
   Hou, CP
   Wang, Z
   Chen, H
AF Chen, Tianyu
   Hou, Chunping
   Wang, Zhipeng
   Chen, Hua
TI Anomaly detection in crowded scenes using motion energy model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; Video surveillance; Motion energy; Optical flow
ID LOCALIZATION
AB We present a new method for detection of abnormal behaviors in crowded scenes. Based on statistics of low-level feature-optical flow, which describes human movement efficiently, the motion energy model is proposed to represent the local motion pattern in the crowd. The model stresses the difference between normal and abnormal behaviors by considering sum of square differences (SSD) metric of motion information in the center block and its neighboring blocks. Meanwhile, data increasing rate is introduced to filter outliers to achieve boundary values between abnormal and normal motion patterns. In this model, an abnormal behavior is detected if the occurrence probability of anomaly is higher than a preset threshold, namely the motion energy value of its corresponding block is higher than that of the normal one. We evaluate the proposed method on two public available datasets, showing competitive performance with respect to state-of-the-art approaches not only in detection accuracy, but also in computational efficiency.
C1 [Chen, Tianyu; Hou, Chunping; Wang, Zhipeng] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
   [Chen, Hua] Ningbo Univ, Fac Informat Sci & Engn, Ningbo, Zhejiang, Peoples R China.
C3 Tianjin University; Ningbo University
RP Chen, TY (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM chentianyu_7@126.com
FU National Natural Science Foundation of China [61471262]; International
   (Regional) Cooperation and Exchange [61520106002]; Doctoral Fund of
   Ministry of Education of China [20130032110010]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61471262, the International (Regional) Cooperation and
   Exchange under Grant 61520106002, and the Doctoral Fund of Ministry of
   Education of China under Grant 20130032110010.
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   [Anonymous], HIERARCHICAL LSTM AD
   Basharat A., 2008, Learning object motion patterns for anomaly detection and improved object detection, P1
   Chan AB, 2005, IEEE I CONF COMP VIS, P641
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Cong Y, 2011, SPARSE RECONSTRUCTIO, V32, P3449
   Tran D, 2014, IEEE T PATTERN ANAL, V36, P404, DOI 10.1109/TPAMI.2013.137
   Hämäläinen W, 2008, IEEE DATA MINING, P203, DOI 10.1109/ICDM.2008.144
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Kaltsa V, 2015, IEEE T IMAGE PROCESS, V24, P2153, DOI 10.1109/TIP.2015.2409559
   Kim J, 2009, PROC CVPR IEEE, P2913
   Kuettel D, 2010, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2010.5539869
   Kwon J, 2012, PROC CVPR IEEE, P1266, DOI 10.1109/CVPR.2012.6247810
   Lee DG, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P110, DOI 10.1109/ACPR.2013.30
   Lee KyoungMu, 2015, IEEE C COMP VIS PATT, P1737
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Nguyen NT, 2005, PROC CVPR IEEE, P955
   Piciarelli C, 2008, IEEE T CIRC SYST VID, V18, P1544, DOI 10.1109/TCSVT.2008.2005599
   Reddy V., 2011, Computer Vision and Pattern Recognition Workshops (CVPRW), 2011 IEEE Computer Society Conference on, P55
   Roshtkhari MJ, 2013, PROC CVPR IEEE, P2611, DOI 10.1109/CVPR.2013.337
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Xu D., 2015, Learning deep representations of appearance and motion for anomalous event detection
   Xuanhan Wang, 2017, IEEE Signal Processing Letters, V24, P510, DOI 10.1109/LSP.2016.2611485
   Zhang Y, 2016, PATTERN RECOGN, V51, P443, DOI 10.1016/j.patcog.2015.09.005
   Zhou SF, 2016, SIGNAL PROCESS-IMAGE, V47, P358, DOI 10.1016/j.image.2016.06.007
NR 27
TC 24
Z9 29
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 14137
EP 14152
DI 10.1007/s11042-017-5020-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900046
DA 2024-07-18
ER

PT J
AU Espejel-Trujillo, A
   Iwamoto, M
   Nakano-Miyatake, M
AF Espejel-Trujillo, Angelina
   Iwamoto, Mitsugu
   Nakano-Miyatake, Mariko
TI A proactive secret image sharing scheme with resistance to machine
   learning based steganalysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret image sharing scheme; Proactive secret sharing scheme; Ramp
   secret sharing scheme; Steganalysis; Machine learning; Support vector
   machine
ID CELLULAR-AUTOMATA; STEGANOGRAPHY; AUTHENTICATION
AB In secret image sharing (SIS) schemes, a secret image is shared among a set of n images called stego-images. Each stego-image is preserved by a participant. In the recovery stage, at least k out of n stego-images are required to obtain the secret image, while k - 1 cannot reveal the secret in the sense of perfect secrecy. Hence, SIS guarantees long-term security. However, as the longer the stego-images remain stored, the higher is the probability of being vulnerable against steganalysis. To resolve this issue, this paper proposes the use of proactive secret sharing in an SIS scheme (P-SIS). P-SIS allows the stego-images to be renewed frequently while these are stored, without changing both cover and secret images. However, direct implementation of a proactive SIS requires more embedding rate (ER), causing high steganalysis accuracy detection and loss of quality in the stego-images. Our proposal addresses this issue and presents the combination of a (k, L, n)-threshold ramp secret sharing scheme and least significant bit matching (LSBM) steganography to reduce the steganalysis accuracy detection. The results of the evaluation show effectiveness of the proposal in terms of good quality of the stego-images, accurate recovery of the secret, and reduce the ER. Note that, despite the extensive research of SIS presented until now, only a few previous work is found on steganalysis in SIS. Not only constructing P-SIS scheme, but we also experimented the tolerance of the proposed P-SIS scheme against stganalysis in this paper. As a result, it is shown that the proposed scheme can withstand steganalysis based on machine learning (i.e., based on subtractive pixel adjacency matrix, SPAM).
C1 [Espejel-Trujillo, Angelina; Iwamoto, Mitsugu] Univ Electrocommun, Grad Sch Informat & Engn, Dept Informat, 1-5-1 Chofugaoka, Chofu, Tokyo 1828585, Japan.
   [Nakano-Miyatake, Mariko] Inst Politecn Nacl, Mech Elect Engn Sch, Postgrad & Res Sect, Ave Santa Ana 1000, Mexico City, DF, Mexico.
C3 University of Electro-Communications - Japan; Instituto Politecnico
   Nacional - Mexico
RP Espejel-Trujillo, A (corresponding author), Univ Electrocommun, Grad Sch Informat & Engn, Dept Informat, 1-5-1 Chofugaoka, Chofu, Tokyo 1828585, Japan.
EM angelina.et@gmail.com; mitsugu@uec.ac.jp; mnakano@ipn.mx
RI Iwamoto, Mitsugu/F-6235-2015; Nakano, Mariko/N-4075-2019
OI Iwamoto, Mitsugu/0000-0003-1092-8489; /0000-0001-6563-1346
FU JSPS KAKENHI [JP26420345]; CONACYT (Consejo Nacional de Ciencia y
   Tecnologia / National Council for Science and Technology)
FX This work was partially supported by JSPS KAKENHI Grant Number
   JP26420345 and CONACYT (Consejo Nacional de Ciencia y Tecnologia /
   National Council for Science and Technology).
CR Alvarez G, 2003, INF SCI, V806, P17
   [Anonymous], P CRYPTO 95 AUG
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Bas TFP, 2016, BOWS 2
   Blakley G. R., 1979, 1979 International Workshop on Managing Requirements Knowledge (MARK), P313, DOI 10.1109/MARK.1979.8817296
   Blakley G. R., 1985, Advances in Cryptology-CRYPTO (Lecture Notes in Computer Science), V196, P242
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Droste S., 1996, Advances in Cryptology - CRYPTO'96. 16th Annual International Cryptology Conference. Proceedings, P401
   Eslami Z, 2010, INFORM SCIENCES, V180, P2889, DOI 10.1016/j.ins.2010.04.015
   Eslami Z, 2010, PATTERN RECOGN, V43, P397, DOI 10.1016/j.patcog.2009.06.007
   Espejel-Trujillo A, 2012, MIDWEST SYMP CIRCUIT, P1132, DOI 10.1109/MWSCAS.2012.6292224
   Gonzalez E, 2016, WOODS
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   Ker A, 2005, INFORM HIDING, V3200, P97
   Lin PY, 2010, PATTERN RECOGN LETT, V31, P1887, DOI 10.1016/j.patrec.2010.01.019
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Tong HHY, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P428, DOI 10.1109/ICIP.1998.999032
   Wu XT, 2012, J SYST SOFTWARE, V85, P1852, DOI 10.1016/j.jss.2012.02.046
   Yamamoto H., 1985, ELECTR COMMUN JPN, V69, P46
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Zarepour-Ahmadabadi J, 2016, INFORM SCIENCES, V369, P467, DOI 10.1016/j.ins.2016.07.001
NR 24
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15161
EP 15179
DI 10.1007/s11042-017-5097-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200033
DA 2024-07-18
ER

PT J
AU Lin, FJ
   Wang, TP
AF Lin, Fang-Ju
   Wang, Tsai-Pei
TI Metric learning for weather image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Metric learning; k nearest neighbor; Information-theoretic metric
   learning; Large-margin nearest-neighbor metric learning; Weather
   features; Weather image classification
AB Image classification is a core task in many applications of computer vision. Recognition of weather conditions based on large-volume image datasets is a challenging problem. However, there has been little research on weather-related recognition using color images, particularly with large datasets. In this study, we proposed a metric learning framework to investigate a two-class weather classification problem. We improve the classification accuracy using metric learning approaches. Extracting features from images is a challenging task and practical requirements such as domain knowledge and human intervention. In this paper, we define several categories of weather feature cures based on observations of outdoor images captured under different weather conditions. Experimental results show that a classifier based on metric learning framework is effective in weather classification and outperforms the previous approach when using the same dataset.
C1 [Lin, Fang-Ju; Wang, Tsai-Pei] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 30010, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Lin, FJ (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 30010, Taiwan.
EM fiona.cs97g@nctu.edu.tw; wangts@cs.nctu.edu.tw
CR [Anonymous], NATURE STATISTI810
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Davis J. V., 2007, ICML, P209
   Elhoseiny M, 2015, IEEE IMAGE PROC, P3349, DOI 10.1109/ICIP.2015.7351424
   Lu CW, 2014, PROC CVPR IEEE, P3718, DOI 10.1109/CVPR.2014.475
   Lu CW, 2013, PROC CVPR IEEE, P415, DOI 10.1109/CVPR.2013.60
   Rafael A, 2002, DIGITAL IMAGE PROCES
   Roser M, 2008, IEEE INT VEH SYM, P480
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Yan XS, 2009, LECT NOTES COMPUT SC, V5553, P390
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng Zhang, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P13, DOI 10.1007/978-3-319-14442-9_2
NR 15
TC 0
Z9 0
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13309
EP 13321
DI 10.1007/s11042-017-4948-7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900011
DA 2024-07-18
ER

PT J
AU Lin, FJ
   Chuang, JH
AF Lin, Fang-Ju
   Chuang, Jen-Hui
TI Alpha matting using robust color sampling and fully connected
   conditional random fields
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image matting; Alpha matting; Fully connected CRFs
ID IMAGE
AB Alpha matting refers to the problem of softly extracting the foreground from a given image. Previous matting approaches often focused on using na < ve color sampling methods to estimate foreground and background colors for unknown pixels. Existing sampling-based matting methods often collect samples only near the unknown pixels, which may yield poor results if the true foreground and background samples are not found. In this paper, we present novel approach to extract foreground elements from an image through color and opacity (i.e., alpha) estimations, which consider available samples in a search window of variable size for each unknown pixel. Our proposed sampling method is robust in that similar sampling results can be generated for input trimaps of different unknown regions. Further, after the initial estimation of the alpha matte, a fully connected conditional random field (CRF) is used to correct the predicted matte at the pixel level. Our experiments show that visually plausible alpha mattes can indeed be produced.
C1 [Lin, Fang-Ju; Chuang, Jen-Hui] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 30010, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Lin, FJ (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 30010, Taiwan.
EM fiona.cs97g@nctu.edu.tw; jchuang@cs.nctu.edu.tw
CR [Anonymous], 2011, ADV NEURAL INF PROCE
   [Anonymous], 2006, CVPR
   BERMAN A, 2000, Patent No. 6134346
   Chen QF, 2013, IEEE T PATTERN ANAL, V35, P2175, DOI 10.1109/TPAMI.2013.18
   Chen XW, 2013, PROC CVPR IEEE, P1902, DOI 10.1109/CVPR.2013.248
   Cho D., 2016, P ECCV
   Chuang YY, 2001, PROC CVPR IEEE, P264
   Gastal ESL, 2010, COMPUT GRAPH FORUM, V29, P575, DOI 10.1111/j.1467-8659.2009.01627.x
   Johnson J, 2014, P BRIT MACH VIS C BM
   Kaiming He, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2049, DOI 10.1109/CVPR.2011.5995495
   Karacan L, 2015, IEEE I CONF COMP VIS, P424, DOI 10.1109/ICCV.2015.56
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P1699, DOI 10.1109/TPAMI.2008.168
   Rhemann C., 2009, P BRIT MACH VIS C, P1155
   Rhemann C, 2009, PROC CVPR IEEE, P1826, DOI 10.1109/CVPRW.2009.5206503
   Ruzon MA, 2000, PROC CVPR IEEE, P18, DOI 10.1109/CVPR.2000.855793
   Shahrian E, 2013, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2013.88
   Shahrian E, 2012, PROC CVPR IEEE, P718, DOI 10.1109/CVPR.2012.6247741
   Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721
   Tarabalka Y, 2010, IEEE GEOSCI REMOTE S, V7, P736, DOI 10.1109/LGRS.2010.2047711
   Wang J., 2007, 2007 IEEE C COMP VIS, P1
   Zheng YJ, 2009, IEEE I CONF COMP VIS, P889, DOI 10.1109/ICCV.2009.5459326
   Zhu QS, 2015, IEEE T NEUR NET LEAR, V26, P185, DOI 10.1109/TNNLS.2014.2369426
NR 22
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 14327
EP 14342
DI 10.1007/s11042-017-5031-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900054
DA 2024-07-18
ER

PT J
AU Luque, A
   Peralta, ME
   Lama, JR
   Aguayo, F
AF Luque, Amalia
   Estela Peralta, M.
   Ramon Lama, Juan
   Aguayo, Francisco
TI Low cost multimedia sensor networks for obtaining lighting maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Light sensors; Wireless multimedia sensor networks; Light control; Light
   directional correction; Lighting maps; Position estimation
ID CONTROL-SYSTEM; DEVICES
AB In many applications, video streams, images, audio streams and scalar data are commonly used. In these fields, one of the most important magnitudes to be collected and controlled is the light intensity in different spots. So, it is extremely important to be able to deploy a network of light sensors which are usually integrated in a more general Wireless Multimedia Sensor Network (WMSN). Light control systems have increasing applications in many places like streets, roads, buildings, theaters, etc. In these situations having a dense grid of sensing spots significantly enhances measuring precision and control performance. When a great number of measuring spots are required, the cost of the sensor becomes a very important concern. In this paper the use of very low cost light sensors is proposed and it is shown how to overcome its limited performance by directionally correcting its results. A correction factor is derived for several lighting conditions. The proposed method is firstly applied to measure light in a single spot. Additionally a prototype of a sensor network is employed to draw the lighting map of a surface. Finally the sensor grid is employed to estimate the position and power of a set of light sources in a certain region of interest (street, building, aEuro broken vertical bar). These three applications have shown that using low cost sensors instead of luxmeters is a feasible approach to estimate illuminance levels in a room and to derive light sources maps. The obtained error measuring spots illuminance or estimating lamp emittances are quite acceptable in many practical applications.
C1 [Luque, Amalia; Estela Peralta, M.; Ramon Lama, Juan; Aguayo, Francisco] Univ Seville, Dept Ingn Diseno, Escuela Politecn Super, C Virgen Africa 7, Seville 41011, Spain.
C3 University of Sevilla
RP Luque, A (corresponding author), Univ Seville, Dept Ingn Diseno, Escuela Politecn Super, C Virgen Africa 7, Seville 41011, Spain.
EM amalialuque@us.es
RI Juan, Lama-Ruiz/H-9887-2015; Peralta-Alvarez, María Estela/Z-6212-2019;
   Luque, Amalia/I-7330-2015
OI Juan, Lama-Ruiz/0000-0003-1382-5274; Peralta-Alvarez, María
   Estela/0000-0003-0252-9349; 
FU Telefonica Chair "Intelligence in Networks" of the University of Seville
   (Spain)
FX This work has been supported by the Telefonica Chair "Intelligence in
   Networks" of the University of Seville (Spain).
CR Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   [Anonymous], 105261999 ISO
   Arfken George B., 2012, Mathematical Methods for Physicists: A Comprehensive Guide
   Bai YW, 2008, IEEE T CONSUM ELECTR, V54, P1173, DOI 10.1109/TCE.2008.4637603
   Caicedo D, 2013, IEEE SENS J, V13, P1092, DOI 10.1109/JSEN.2012.2228850
   DiBernardo E, 2014, Methods and apparatus for position estimation using reflected light sources, Patent No. [8,780,342, 8780342]
   Dibley M, 2012, INT J INNOV COMPUT I, V8, P8415
   Figueiro MG, 2013, LIGHTING RES TECHNOL, V45, P421, DOI 10.1177/1477153512450453
   Hui Ren, 2011, 2011 Fourth International Joint Conference on Computational Sciences and Optimization (CSO), P777, DOI 10.1109/CSO.2011.221
   Karthikeyan M., 2014, PRACT CHEMOINFORMATI, V100, P1, DOI [10.1007/978-81-322-1780-0_1, DOI 10.1007/978-81-322-1780-0_1]
   Kolivand H, 2014, MULTIMED TOOLS APPL, V73, P1225, DOI 10.1007/s11042-013-1630-6
   Luque A, 2016, MULTIMED TOOLS APPL, V75, P1
   Markvart J, 2015, LEUKOS, V11, P155, DOI 10.1080/15502724.2015.1020948
   Mendalka M., 2010, 2010 2nd International Conference on Information Technology (ICIT 2010), P99
   Miki M, 2013, 2013 IEEE 8TH INTERNATIONAL SYMPOSIUM ON APPLIED COMPUTATIONAL INTELLIGENCE AND INFORMATICS (SACI 2013), P137, DOI 10.1109/SACI.2013.6608954
   Mistrick R, 2015, BUILDINGS-BASEL, V5, P449, DOI 10.3390/buildings5020449
   Mohamaddoust R, 2011, SENSORS-BASEL, V11, P8933, DOI 10.3390/s110908933
   Neamen DA, 2007, MICROELECTRONICS CIR, P137
   OMEGA, 2016, CISC VIS NETW IND GL
   OSRAM Opto Semiconductors, 2014, SFH 213 DAT
   Pan MS, 2008, IEEE SENS J, V8, P1710, DOI 10.1109/JSEN.2008.2004294
   PCE Instruments, PCE 172 LIGHT MET
   Salata F, 2016, SUSTAINABILITY-BASEL, V8, DOI 10.3390/su8111092
   Schell S, 2005, Sensing device and method for measuring position and orientation relative to multiple light sources, Patent No. [11/ 090,405, 11090405]
   Skalicky S.E., 2016, OCULAR VISUAL PHYSL, P299, DOI DOI 10.1007/978-981-287-846-5_21
   Varshney LR, 2013, Significance, V10, P28, DOI [10.1111/j.1740-9713.2013.00636.x, DOI 10.1111/J.1740-9713.2013.00636.X]
   Vinutharani A, 2016, INT RES J ENG TECHNO, V3, P2328
   WorldMeteorological Organization, GUID MET INSTR METH
   Zhang DQ, 2013, MULTIMED TOOLS APPL, V67, P179, DOI 10.1007/s11042-011-0940-9
NR 29
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 14499
EP 14526
DI 10.1007/s11042-017-5040-z
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200002
OA hybrid
DA 2024-07-18
ER

PT J
AU Naik, K
   Trivedy, S
   Pal, AK
AF Naik, Kshiramani
   Trivedy, Saswati
   Pal, Arup Kumar
TI An IWT based blind and robust image watermarking scheme using secret key
   matrix
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind watermarking; Copyright protection; Integer wavelet transform;
   Logistic map; Robust watermarking
ID REVERSIBLE WATERMARKING; WAVELET DOMAIN; SVD; DWT
AB In this paper, the authors have proposed a binary watermark embedding approach for protecting the copyright ownership of the gray-scale images. The proposed watermark embedding process is realized in integer wavelet transform (IWT) domain to defend the robustness property. Instead of inserting the watermark bits directly in the coefficients of cover media, an indirect embedding mechanism is proposed with the reference to a logistic map based secret key matrix which enhance the secrecy of the proposed embedding approach. Initially, the approximate sub band of the IWT transformed cover image is selected with the intention to embed the watermark. Later, a secret key matrix of size corresponding to the approximate sub band of the cover image is formed using the logistic map with secret parameters. During the watermark embedding process, the approximate sub band is modified indirectly with reference to the secret key matrix and a proposed division table. The scheme is tested on a set of standard images and satisfactory results are achieved. In addition, the proposed schemes is also able to extract the watermark information in blind manner. Also, the scheme is comparable with some other related schemes. Finally, the proposed watermarking scheme is able to survive the watermark even after performing certain types of image manipulation attacks.
C1 [Naik, Kshiramani; Trivedy, Saswati; Pal, Arup Kumar] Indian Inst Technol ISM Dhanbad, Dept Comp Sci & Engn, Jharkhand 826004, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Naik, K (corresponding author), Indian Inst Technol ISM Dhanbad, Dept Comp Sci & Engn, Jharkhand 826004, India.
EM kshiramani@gmail.com; saswatialo12@gmail.com; arupkrpal@gmail.com
RI Pal, Arup Kumar/I-2496-2016
CR Ali M, 2015, INFORM SCIENCES, V301, P44, DOI 10.1016/j.ins.2014.12.042
   Ali M, 2014, SIGNAL PROCESS, V94, P545, DOI 10.1016/j.sigpro.2013.07.024
   Ansari IA, 2016, ENG APPL ARTIF INTEL, V49, P114, DOI 10.1016/j.engappai.2015.12.004
   Arsalan M, 2012, J SYST SOFTWARE, V85, P883, DOI 10.1016/j.jss.2011.11.005
   Bohra A, 2009, AEU-INT J ELECTRON C, V63, P703, DOI 10.1016/j.aeue.2008.05.010
   Chetan KR, 2015, J INF SECUR APPL, V24-25, P13, DOI 10.1016/j.jisa.2015.07.002
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   Furht B., 2004, MULTIMEDIA SECURITY
   Gunjal BaisaL., 2010, Journal of Emerging Trends in Computing and Information Sciences, V2, P37
   Hwang MS, 1999, IEEE T CONSUM ELECTR, V45, P286, DOI 10.1109/30.793411
   Jia SL, 2014, OPTIK, V125, P2868, DOI 10.1016/j.ijleo.2014.01.002
   Kaushik Awanish Kr., 2012, INT J ELECT COMP SCI, V1, P35
   Kumsawat P, 2007, LECT NOTES ENG COMP, P612
   Lingamgunta S., 2013, IMAGE PROCESS, V6, P145
   Maity SP, 2002, ICVGIP
   Mukherjee DP, 2004, IEEE T MULTIMEDIA, V6, P1, DOI 10.1109/TMM.2003.819759
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   Nin J, 2013, 2013 IEEE 27TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA), P1553, DOI 10.1109/WAINA.2013.171
   Pal AK, 2016, INT J INF COMPUT SEC
   Parashar P., 2014, International Journal of Signal Processing, Image Processing and Pattern Recognition, V7, P111, DOI DOI 10.14257/IJSIP.2014.7.6.10
   Sebe F., 2000, Information Security. Third International Workshop, ISW 2000. Proceedings (Lecture Notes in Computer Science Vol.1975), P44
   Sverdlov Alexander, 2005, 2005 13th European Signal Processing Conference, P1
   Tao PN, 2004, PROC SPIE, V5601, P133, DOI 10.1117/12.569641
   Thabit R, 2014, J SYST SOFTWARE, V88, P74, DOI 10.1016/j.jss.2013.09.033
   Verma VS, 2015, EXPERT SYST APPL, V42, P8184, DOI 10.1016/j.eswa.2015.06.041
   Wang C, 2010, IEEE IMAGE PROC, P3673, DOI 10.1109/ICIP.2010.5652508
   Wang YR, 2011, EXPERT SYST APPL, V38, P8024, DOI 10.1016/j.eswa.2010.12.129
   Weng SW, 2016, J VIS COMMUN IMAGE R, V35, P25, DOI 10.1016/j.jvcir.2015.11.005
NR 28
TC 7
Z9 7
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13721
EP 13752
DI 10.1007/s11042-017-4986-1
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900030
DA 2024-07-18
ER

PT J
AU Chen, H
   Trouve, A
   Murakami, KJ
   Fukuda, A
AF Chen, Hua
   Trouve, Antoine
   Murakami, Kazuaki J.
   Fukuda, Akira
TI Semantic image retrieval for complex queries using a knowledge parser
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Object retrieval; Commonsense knowledge; K-parser; RDF
ID CONCEPTNET; WORDNET
AB In order to improve the retrieval accuracy of image retrieval systems, research focus has been shifted from designing sophisticated low-level feature extraction algorithms to combining image retrieval processing with rich semantics and knowledge-based methods. In this paper, we aim at improving text-based image retrieval for complex natural language queries by using a semantic parser (Knowledge Parser or K-Parser). From text written in natural language, the K-parser extracts a graphical semantic representation of the objects involved, their properties as well as their relations. We analyze both the image textual captions and the natural language queries with the K-parser. As a technical solution, we leverage RDF in two ways: first, we store the parsed image captions as RDF triples; second, we translate image queries into SPARQL queries. When applied to the Flickr8k dataset with a set of 16 custom queries, we notice that the K-parser exhibits some biases that negatively affect the accuracy of the queries. We propose two techniques to address the weaknesses: (1) we introduce a set of rules to transform the output of K-parser and fix some basic, recurrent parsing mistakes that occur on the captions of Flickr8k; (2) we leverage two popular commonsense knowledge databases, ConceptNet and WordNet, to raise the accuracy of queries on broad concepts. Using those two techniques, we can fix most of the initial retrieval errors, and accurately execute our set of 16 queries on the Flickr8k dataset.
C1 [Chen, Hua; Murakami, Kazuaki J.; Fukuda, Akira] Kyushu Univ, Grad Sch Informat Sci & Elect Engn, Nishi Ku, 744 Motooka, Fukuoka, Fukuoka 8190395, Japan.
   [Trouve, Antoine] Inst Syst Informat Technol & Nanotechnol ISIT, Sawara Ku, 2-1-22-7F Momochihama, Fukuoka, Fukuoka 8140001, Japan.
C3 Kyushu University
RP Chen, H (corresponding author), Kyushu Univ, Grad Sch Informat Sci & Elect Engn, Nishi Ku, 744 Motooka, Fukuoka, Fukuoka 8190395, Japan.
EM chenhua5752@hotmail.com; trouve@isit.or.jp
FU Grants-in-Aid for Scientific Research [15H05708] Funding Source: KAKEN
CR [Anonymous], 2015, ARXIV151103292
   [Anonymous], 2017, IEEE T IMAGE PROCESS
   Chen H., 2016, COMPUT ELECT ENG
   Clark P, 2004, KM KNOWLEDGE MACHINE, V2, P5
   Dasiopoulou S, 2011, LECT NOTES ARTIF INT, V6050, P196, DOI 10.1007/978-3-642-20795-2_8
   Grobe M., 2009, P 37 ANN ACM SIGUCCS, P131
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Hsu MH, 2006, LECT NOTES COMPUT SC, V4182, P1
   Im DH, 2015, MULTIMED TOOLS APPL, V74, P2273, DOI 10.1007/s11042-014-1855-z
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d
   Lu HM, 2016, MULTIMED TOOLS APPL, V75, P17081, DOI 10.1007/s11042-015-2977-7
   MAGESH N, 2011, INT J COMPUTER APPL, V1, P12
   Manola F, 2004, W3C RECOMMENDATION, V10, P5
   McBride B, 2004, INTRO RDF JENA RDF A
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Mu N, 2017, IEEE INT C ELECTR TA
   Prud E., 2006, W3C RECOMMENDATION
   Sankar S, 2014, INT J COMPUT APPL, V86
   Scherp A, 2013, P 21 ACM INT C MULT, P1107
   Schuster S., 2015, P 4 WORKSHOP VISION, P70
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Sharma A, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1319
   Speer R, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3679
   Xu X, 2016, NONLINEAR MATRIX COM
   Xu X, 2016, NEUROCOMPUTING, V213, P191, DOI 10.1016/j.neucom.2015.11.133
   Yang Y, 2016, ADV COGN SYST
NR 28
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10733
EP 10751
DI 10.1007/s11042-017-4932-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900021
DA 2024-07-18
ER

PT J
AU Ghebleh, M
   Kanso, A
AF Ghebleh, Mohammad
   Kanso, Ali
TI A novel secret image sharing scheme using large primes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret sharing; Secret image sharing; (t, n)-threshold scheme; Chaos;
   Skew tent map
ID AUTHENTICATION; STEGANOGRAPHY
AB A secret image sharing scheme is any method of distributing shares of a secret image amongst a set of peers, such that the secret may be revealed only with participation of all members of a qualified set of peers. Following Shamir's (t, n)-threshold scheme, we propose a novel lossy/lossless secret image sharing scheme, that improves existing schemes in terms of security and performance. As opposed to the usual convention of representing a digital image by a collection of 8-bit integer values, we consider 8b-bit values where b is a positive integer. This approach accommodates a larger finite field, which in turn produces a less intrusive secret image sharing scheme. Extensive empirical results are presented to demonstrate the efficiency and robustness of the proposed scheme.
C1 [Ghebleh, Mohammad; Kanso, Ali] Kuwait Univ, Dept Math, POB 5969, Safat 13060, Kuwait.
C3 Kuwait University
RP Ghebleh, M (corresponding author), Kuwait Univ, Dept Math, POB 5969, Safat 13060, Kuwait.
EM mamad@sci.kuniv.edu.kw; akanso@sci.kuniv.edu.kw
RI Kanso, Ali/GVT-1076-2022; Ghebleh, Mohammad/I-1040-2014
OI Kanso, Ali/0000-0002-4366-841X; Ghebleh, Mohammad/0000-0003-2291-0892
CR Blakley GR, 1979, SAFEGUARDING CRYPTOG
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chang CC, 2014, SIGNAL PROCESS, V99, P159, DOI 10.1016/j.sigpro.2013.12.022
   Chen Y, 2015, CHEM ENG SCI, V132, P1, DOI 10.1016/j.ces.2015.04.006
   Chin-Chen Chang, 2010, Journal of Communications, V5, P5, DOI 10.4304/jcm.5.1.5-12
   Ghebleh M, 2014, COMMUN NONLINEAR SCI, V19, P1898, DOI 10.1016/j.cnsns.2013.10.014
   Guo C, 2014, MULTIMED TOOLS APPL, V72, P2195, DOI 10.1007/s11042-013-1510-0
   Kanso A, 2017, MULTIMED TOOLS APPL, V76, P16369, DOI 10.1007/s11042-016-3917-x
   Lee GH, 2016, INT J GENOMICS, V2016, DOI 10.1155/2016/2128010
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Liu L, 2014, SIGNAL PROCESS-IMAGE, V29, P128, DOI 10.1016/j.image.2013.10.003
   Rukhin A., 2010, NIST SPECIAL PUBLICA, P1, DOI DOI 10.6028/NIST.SP.800-22R1A
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   SHANNON CE, 1951, BELL SYST TECH J, V30, P50, DOI 10.1002/j.1538-7305.1951.tb01366.x
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
   Wu KS, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-49
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu YS, 2004, PATTERN RECOGN, V37, P1377, DOI 10.1016/j.patcog.2004.01.002
   Yang CN, 2015, SIGNAL PROCESS-IMAGE, V31, P1, DOI 10.1016/j.image.2014.11.003
   Zhao R, 2009, COMPUT STAND INTER, V31, P252, DOI 10.1016/j.csi.2007.10.012
NR 22
TC 24
Z9 25
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 11903
EP 11923
DI 10.1007/s11042-017-4841-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100014
DA 2024-07-18
ER

PT J
AU Sun, MS
   Ge, CP
   Fang, LM
   Wang, JD
AF Sun, Maosheng
   Ge, Chunpeng
   Fang, Liming
   Wang, Jiandong
TI A proxy broadcast re-encryption for cloud data sharing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Proxy re-encryption; Automatically re-encryption; Proxy broadcast
   re-encryption; Chosen-ciphertext secure
ID IDENTITY-BASED ENCRYPTION
AB Proxy re-encryption (PRE) enables a semi-trusted proxy to automatically convert a delegator's ciphertext to a delegate's ciphertext without learning anything about the underlying plaintext. PRE schemes have broad applications, such as cloud data sharing systems, distributed file systems, email forward systems and DRM systems. In this paper, we introduced a new notion of proxy broadcast re-encryption (PBRE). In a PBRE scheme, a delegator, Alice, can delegate the decryption right to a set of users at a time, which means that Alice's ciphertext can be broadcast re-encrypted. We propose a PBRE scheme and prove its security against a chosen-ciphertext attack (CCA) in the random oracle model under the decisional n-BDHE assumption. Furthermore, our scheme is collusion-resistant, which means the proxy cannot collude with a set of delegates to reveal the delegator's private key.
C1 [Sun, Maosheng; Fang, Liming; Wang, Jiandong] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing, Jiangsu, Peoples R China.
   [Ge, Chunpeng] Jiangsu Univ Technol, Dept Comp Engn, Changzhou, Peoples R China.
   [Sun, Maosheng] Yangzhou Univ, Dept Informat Ctr, Yangzhou, Jiangsu, Peoples R China.
   [Ge, Chunpeng] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Jiangsu University of
   Technology; Yangzhou University; Chinese Academy of Sciences; Institute
   of Information Engineering, CAS
RP Ge, CP (corresponding author), Jiangsu Univ Technol, Dept Comp Engn, Changzhou, Peoples R China.; Ge, CP (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
EM mssun@yzu.edu.cn; gecp@nuaa.edu.cn
FU National Natural Science Foundation of China [61672270, 61602216,
   6127208, 61300236]; Research Foundation for Humanities and Social
   Sciences of Ministry of Education, China [14YJAZH023, 15YJCZH129]; Qing
   Lan Project for Young Researchers of Jiangsu Province of China
   [KYQ14004]; Open Fund of State Key Laboratory of Information Security,
   Institute of Information Engineering, Chinese Academy of Sciences
   [2015-MSB-10]; National Science Foundation for Post-doctoral Scientists
   of China [2013M530254]; National Science Foundation for Post-doctoral
   Scientists of Jiangsu [1302137C]; China Postdoctoral Science special
   Foundation [2014T70518]
FX This paper is supported by the National Natural Science Foundation of
   China (No. 61672270, 61602216, 6127208, 61300236), the Research
   Foundation for Humanities and Social Sciences of Ministry of Education,
   China (No. 14YJAZH023,15YJCZH129), the Qing Lan Project for Young
   Researchers of Jiangsu Province of China(No. KYQ14004), and the Open
   Fund of State Key Laboratory of Information Security, Institute of
   Information Engineering, Chinese Academy of Sciences (No. 2015-MSB-10),
   the National Science Foundation for Post-doctoral Scientists of China
   (No. 2013M530254), the National Science Foundation for Post-doctoral
   Scientists of Jiangsu (No. 1302137C), and the China Postdoctoral Science
   special Foundation (No. 2014T70518).
CR Ateniese G., 2005, NDSS, P29
   Blaze M, 1998, LECT NOTES COMPUT SC, V1403, P127, DOI 10.1007/BFb0054122
   Boneh D, 2005, LECT NOTES COMPUT SC, V3621, P258
   Boneh D, 2005, LECT NOTES COMPUT SC, V3494, P440, DOI 10.1007/11426639_26
   Boneh D, 2004, LECT NOTES COMPUT SC, V3027, P223
   Boneh D., 2001, P CRYPTO 2001 SANT B, P231
   Chow SSM, 2010, LECT NOTES COMPUT SC, V6055, P316
   Deng RH, 2008, LECT NOTES COMPUT SC, V5339, P1, DOI 10.1007/978-3-540-89641-8_1
   Fang L, 2012, J SCI CHINA INF SCI, V56, P1
   Fang LM, 2009, LECT NOTES COMPUT SC, V5848, P47, DOI 10.1007/978-3-642-04642-1_6
   Libert B, 2008, LECT NOTES COMPUT SC, V4939, P360, DOI 10.1007/978-3-540-78440-1_21
   Shao J, 2009, LECT NOTES COMPUT SC, V5443, P357
   Weng J, 2009, P 4 INT S INF COMP C, P322, DOI DOI 10.1145/1533057.1533100
   Weng J, 2010, SCI CHINA INFORM SCI, V53, P593, DOI 10.1007/s11432-010-0047-3
NR 14
TC 30
Z9 32
U1 5
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10455
EP 10469
DI 10.1007/s11042-017-4448-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900005
DA 2024-07-18
ER

PT J
AU Yuan, CH
   Xu, CY
   Wang, TJ
   Liu, F
   Zhao, ZQ
   Feng, P
   Guo, JJ
AF Yuan, Caihong
   Xu, Chunyan
   Wang, Tianjiang
   Liu, Fang
   Zhao, Zhiqiang
   Feng, Ping
   Guo, Jingjuan
TI Deep multi-instance learning for end-to-end person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Deep multi-instance learning; Contrastive Loss
   function
ID CLASSIFICATION; RECOGNITION
AB In this paper, we introduce a deep multi-instance learning framework to boost the instance-level person re-identification performance. Motivated by the observation of considerably dramatic and complex varieties of visual appearances in many current person re-identification datasets, we explicitly represent a deep feature representation learning method for the final person re-identification task. However, most public datasets for person re-identification are usually small, that usually make deep learning model suffer from seriously over-fitting problem. To alleviate this matter, we formulate the problem of person re-identification as a deep multi-instance learning (DMIL) task. More specifically, We build a novel end-to-end person re-identification system by unifying DMIL with the convolutional feature learning. For well capturing these intra-class diversities and inter-class ambiguities of input visual samples across cameras, a multi-scale convolutional feature learning method is proposed by optimizing the Contrastive Loss function. Comprehensive evaluations over three public benchmark datasets (including VIPeR, ETHZ, and CUHK01 datasets) well demonstrate the encouraging performance of our proposed person re-identification framework on small datasets.
C1 [Yuan, Caihong; Wang, Tianjiang; Liu, Fang; Zhao, Zhiqiang; Feng, Ping; Guo, Jingjuan] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
   [Yuan, Caihong] Henan Univ, Sch Comp & Informat Engn, Kaifeng 475004, Peoples R China.
   [Xu, Chunyan] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Zhao, Zhiqiang; Guo, Jingjuan] Jiujiang Univ, Sch Informat Sci & Technol, Jiujiang 332005, Peoples R China.
C3 Huazhong University of Science & Technology; Henan University; Nanjing
   University of Science & Technology; Jiujiang University
RP Wang, TJ (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
EM yuanch@hust.edu.cn; cyx@njust.edu.cn; tjwang@hust.edu.cn;
   fliu@hust.edu.cn; zq_zhao@hust.edu.cn; fengping@hust.edu.cn;
   jj_guo@hust.edu.cn
FU Natural Science Foundation of China [61572214, 61602244, U1536203];
   Independent Innovation Research Fund - Huazhong university of science
   and technology [2016YXMS089]; CCF-Tencent Open Research Fund
FX This work is supported by the Natural Science Foundation of China (Grant
   61572214, 61602244 and U1536203), Independent Innovation Research Fund
   Sponsored by Huazhong university of science and technology (Project No.
   2016YXMS089) and partially sponsored by CCF-Tencent Open Research Fund.
   In addition, we would like to extend our sincere thanks to Gwangmin Choe
   who gave us some good suggestions at the early stage of our work.
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   Amores J, 2013, ARTIF INTELL, V201, P81, DOI 10.1016/j.artint.2013.06.003
   [Anonymous], COMBINED SALIENCE BA
   [Anonymous], 2013, NIPS
   [Anonymous], PROC CVPR IEEE
   [Anonymous], PERSONNET PERSON REI
   [Anonymous], 2011, ACM WORKSH HUM GEST
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], LEARNING DEEP FEATUR
   [Anonymous], INT J COMPUTER VISIO
   [Anonymous], FCV
   [Anonymous], 2007, P IEEE INT WORKSH PE
   [Anonymous], 2006, PROC IEEE COMPUT SOC
   [Anonymous], IEEE T CIRC SYST VID
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Barrow H. G., 1977, P IMAGE UNDERSTANDIN, P659
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Chen SZ, 2016, IEEE T IMAGE PROCESS, V25, P2353, DOI 10.1109/TIP.2016.2545929
   Chen ZH, 2013, NEUROCOMPUTING, V99, P298, DOI 10.1016/j.neucom.2012.08.001
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Davis J. V., 2007, ICML, P209
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Globerson A., 2005, ADV NEURAL INFORM PR
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Hinton G. E., 2012, 12070580 ARXIV
   Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li DX, 2014, J VIS COMMUN IMAGE R, V25, P1112, DOI 10.1016/j.jvcir.2014.03.011
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Linlin Shen, 2010, 2010 IEEE International Conference on Intelligent Computing and Intelligent Systems (ICIS 2010), P97, DOI 10.1109/ICICISYS.2010.5658534
   Liu CX, 2012, LECT NOTES COMPUT SC, V7583, P391, DOI 10.1007/978-3-642-33863-2_39
   Liu H, 2015, NEUROCOMPUTING, V151, P1283, DOI 10.1016/j.neucom.2014.11.002
   Ma B., 2012, BritishMachine Vision Conf., Surrey, P1
   Nguyen C, 2013, P 23 INT JOINT C ART, P1558
   Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42
   Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465
   Shen LL, 2012, INT C PATT RECOG, P1574
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   van Noord N, 2017, PATTERN RECOGN, V61, P583, DOI 10.1016/j.patcog.2016.06.005
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zeng XY, 2014, LECT NOTES COMPUT SC, V8691, P472, DOI 10.1007/978-3-319-10578-9_31
   Zhang RM, 2015, IEEE T IMAGE PROCESS, V24, P4766, DOI 10.1109/TIP.2015.2467315
   Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng L, 2015, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2015.7298783
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
   Zheng Wei-Shi, 2009, P BRIT MACH VIS C, P23, DOI DOI 10.5244/C.23.23
   Zhou Z., 2006, Advances in Neural Information Processing Systems, P1609
NR 59
TC 6
Z9 7
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12437
EP 12467
DI 10.1007/s11042-017-4896-2
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100035
DA 2024-07-18
ER

PT J
AU Wei, CY
   Zhou, BY
   Guo, W
AF Wei, Chunyu
   Zhou, Bingyin
   Guo, Wei
TI Multi-focus image fusion based on nonsubsampled compactly supported
   shearlet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-focus image fusion; Shearlet transform; Compactly supported
   shearlet; Translation invariance
ID CONTOURLET TRANSFORM; OBJECT RETRIEVAL; ALGORITHM; WAVELET;
   REPRESENTATIONS; PCNN
AB Multi-focus image fusion, which aims to combine multi-focus images of a scene to construct an all-in-focus image, has become a major topic in image processing. Different methods have been proposed in spatial or transform domain. But many methods usually suffer from fusion quality degradations, such as contrast reduction, artificial edges, and discontinuous phenomena at boundaries of focused regions, which may cause issues when going for further processing. In order to overcome these problems, we introduce a nonsubsampled compactly supported shearlet transform (NSCSST), which possesses multi-scale, multi-direction, translation invariance and spatial localization characteristics that are very important for image fusion in transform domain. The transform can be implemented sequentially by the shear transform and the separable anisotropic nonsubsampled wavelet transform (SANSWT). Furthermore, we propose a new image fusion method based on NSCSST. It consists of two aspects: multi-direction fusion and transform domain fusion, which respectively correspond to the shear transform and the SANSWT of NSCSST. For each sheared image pair, the SANSWT coefficients are firstly fused by the transform domain fusion rules. And then, the final fused image is obtained by the multi-direction fusion rules, ranging from the simple averaging method to the proposed complex genetic algorithm based method. Experimental results show that our method outperforms some other methods, such as the method based on bilateral gradient, the method based on nonsubsampled contourlet transform, the method based on simultaneous empirical wavelet transform, and the method based on guided filtering.
C1 [Wei, Chunyu; Zhou, Bingyin; Guo, Wei] Hebei Normal Univ, Coll Math & Informat Sci, Shijiazhuang 050024, Hebei, Peoples R China.
   [Zhou, Bingyin; Guo, Wei] Hebei Normal Univ, Hebei Key Lab Computat Math & Applicat, Shijiazhuang 050024, Hebei, Peoples R China.
C3 Hebei Normal University; Hebei Normal University
RP Wei, CY (corresponding author), Hebei Normal Univ, Coll Math & Informat Sci, Shijiazhuang 050024, Hebei, Peoples R China.
EM chunyuwei@yeah.net; zhoubingyin@163.com; guowei@chmiot.net
RI Zhou, Bingyin/O-4327-2017
OI Zhou, Bingyin/0000-0003-0190-7520
FU NSF of China [11301137]; NSF of Hebei Province, China [A2014205100];
   Educational Commission of Hebei Province, China [ZD2014062]
FX The authors would like to thank the editor and anonymous reviewers for
   their detailed review and valuable comments. This work was supported by
   the NSF of China (No. 11301137), the NSF of Hebei Province, China (No.
   A2014205100), the Educational Commission of Hebei Province, China (No.
   ZD2014062).
CR Aiazzi B, 1999, P IGARSS, V2, P1183
   [Anonymous], P 2002 INT C IM PROC
   Aslantas V, 2009, OPT COMMUN, V282, P3231, DOI 10.1016/j.optcom.2009.05.021
   Aslantas V, 2014, OPT COMMUN, V332, P350, DOI 10.1016/j.optcom.2014.07.044
   Baradarani A, 2012, PATTERN RECOGN, V45, P657, DOI 10.1016/j.patcog.2011.06.013
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Chen L, 2013, OPT EXPRESS, V21, P5182, DOI 10.1364/OE.21.005182
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Desai UY, 1996, AIM1584 MIT
   Ding GG, 2016, IEEE T IMAGE PROCESS, V25, P5427, DOI 10.1109/TIP.2016.2607421
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Eltoukhy HA, 2003, P SOC PHOTO-OPT INS, V5017, P332, DOI 10.1117/12.476754
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Gao GR, 2013, IET IMAGE PROCESS, V7, P633, DOI 10.1049/iet-ipr.2012.0558
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Geng P, 2016, MULTIMED TOOLS APPL, V75, P10583, DOI 10.1007/s11042-014-1942-1
   Goshtasby AA, 2007, INFORM FUSION, V8, P114, DOI 10.1016/j.inffus.2006.04.001
   Guo D, 2015, OPT COMMUN, V338, P138, DOI 10.1016/j.optcom.2014.10.031
   Guo K., 2006, Wavelets and Splines, P189
   Guo K, 2007, SIAM J MATH ANAL, V39, P298, DOI 10.1137/060649781
   Holland I.H., 1975, ADAPTATION NATURAL A
   Holschneider M, 1990, Wavelets, P286, DOI DOI 10.1007/978-3-642-75988-828
   Wei H, 2007, PATTERN RECOGN LETT, V28, P493, DOI 10.1016/j.patrec.2006.09.005
   Ji XX, 2017, MULTIMED TOOLS APPL, V76, P17633, DOI 10.1007/s11042-015-2879-8
   Kutyniok G., 2005, Wavelets XI, V5914, P254, DOI DOI 10.1117/12.613494
   Kutyniok G, 2012, APPL NUMER HARMON AN, P239, DOI 10.1007/978-0-8176-8316-0_7
   Kutyniok G, 2009, T AM MATH SOC, V361, P2719
   Le Pennec E, 2005, IEEE T IMAGE PROCESS, V14, P423, DOI 10.1109/TIP.2005.843753
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   Li CL, 2010, INT CONF COMP SCI, P246, DOI 10.1109/ICCSIT.2010.5563771
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li ST, 2012, IEEE T CONSUM ELECTR, V58, P626, DOI 10.1109/TCE.2012.6227469
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Li ST, 2002, PATTERN RECOGN LETT, V23, P985, DOI 10.1016/S0167-8655(02)00029-6
   Lim WQ, 2010, IEEE T IMAGE PROCESS, V19, P1166, DOI 10.1109/TIP.2010.2041410
   Lin Zhiting, 2016, OPEN ELECT ELECT ENG, V10, P1, DOI DOI 10.1109/TCYB.2016.2608906
   Lin ZJ, 2014, COMPUT VIS IMAGE UND, V124, P42, DOI 10.1016/j.cviu.2014.03.012
   Liu X, 2014, AEU-INT J ELECTRON C, V68, P471, DOI 10.1016/j.aeue.2013.12.003
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Miao Q., 2013, NEW ADV IMAGE FUSION, P113
   Miao QG, 2005, P SOC PHOTO-OPT INS, V5778, P704, DOI 10.1117/12.603092
   Miao QG, 2011, OPT COMMUN, V284, P1540, DOI 10.1016/j.optcom.2010.11.048
   Miao QG, 2011, CHIN OPT LETT, V9, DOI 10.3788/COL201109.041001
   Moonon AU, 2015, SENS IMAGING, V16, DOI 10.1007/s11220-015-0106-3
   Naidu VPS, 2008, DEFENCE SCI J, V58, P338
   NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Patel R., 2015, INT J COMPUT APPL, V109, P5
   Peyre G, 2005, P 2005 IEEE INT C IM
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Qu X.B., 2005, OPT PRECIS ENG, V13
   Qu Xiao-Bo, 2008, Acta Automatica Sinica, V34, P1508, DOI 10.3724/SP.J.1004.2008.01508
   Qu XB, 2007, CHIN OPT LETT, V5, P569
   Sharma M., 2016, Int J Comput Sci Inf Technol, V7, P1082
   Shutao Li, 2001, Information Fusion, V2, P169, DOI 10.1016/S1566-2535(01)00038-0
   Tian J, 2012, SIGNAL PROCESS, V92, P2137, DOI 10.1016/j.sigpro.2012.01.027
   Tian J, 2011, OPT COMMUN, V284, P80, DOI 10.1016/j.optcom.2010.08.085
   Wang HM, 2011, COMM COM INF SC, V227, P641
   Wang J, 2016, INT J DISTRIB SENS N, DOI 10.1155/2016/6138251
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang ZB, 2010, PATTERN RECOGN, V43, P2003, DOI 10.1016/j.patcog.2010.01.011
   Xiang TZ, 2015, INFRARED PHYS TECHN, V69, P53, DOI 10.1016/j.infrared.2015.01.002
   Xu J, 2010, J VIS COMMUN IMAGE R, V21, P627, DOI 10.1016/j.jvcir.2010.04.002
   Yang L, 2008, NEUROCOMPUTING, V72, P203, DOI 10.1016/j.neucom.2008.02.025
   Yang Y, 2015, IEEE SENS J, V15, P2824, DOI 10.1109/JSEN.2014.2380153
   Yang Y, 2014, MEAS SCI REV, V14, P102, DOI 10.2478/msr-2014-0014
   You XG, 2006, INT J PATTERN RECOGN, V20, P361, DOI 10.1142/S0218001406004764
   Yuan Cao, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P17, DOI 10.1109/ICIG.2011.37
   Zhang D, 2009, INT J PATTERN RECOGN, V23, P521, DOI 10.1142/S0218001409007260
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zhang XL, 2017, MULTIMED TOOLS APPL, V76, P8175, DOI 10.1007/s11042-016-3453-8
   Zhao SC, 2020, IEEE T AFFECT COMPUT, V11, P574, DOI [10.1109/TAFFC.2018.2818685, 10.1109/TAFFC.2016.2628787]
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1025, DOI 10.1145/2647868.2655035
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
NR 78
TC 6
Z9 6
U1 1
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8327
EP 8358
DI 10.1007/s11042-017-4731-9
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800025
DA 2024-07-18
ER

PT J
AU Zerdoumi, S
   Sabri, AQM
   Kamsin, A
   Hashem, IAT
   Gani, A
   Hakak, S
   Al-Garadi, MA
   Chang, V
AF Zerdoumi, Saber
   Sabri, Aznul Qalid Md
   Kamsin, Amirrudin
   Hashem, Ibrahim Abaker Targio
   Gani, Abdullah
   Hakak, Saqib
   Al-garadi, Mohammed Ali
   Chang, Victor
TI RETRACTED: Image pattern recognition in big data: taxonomy and open
   challenges: survey (Retracted article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Pattern Recognition; Big Data; Feature Extraction; Dimensionality
   Reduction
ID DIMENSIONALITY REDUCTION; MODEL SELECTION; NEXT-GENERATION;
   VISUALIZATION; ALGORITHMS; FRAMEWORK; CLASSIFICATION; REPRESENTATION;
   COLLECTIONS; FEATURES
AB Image pattern recognition in the field of big data has gained increasing importance and attention from researchers and practitioners in many domains of science and technology. This paper focuses on the usage of image pattern recognition for big data applications. In this context, the taxonomy of image pattern recognition and big data is revealed. The applications of image pattern recognition for big data, including multimedia, biometrics, and biology/biomedical, are also highlighted. Moreover, the significance of using pattern-based feature reduction in big data is discussed, and machine-learning techniques in pattern recognition applications are presented. A comparison based on the objectives of the approaches is presented to underline the taxonomy. This paper provides a novel review in exploring image recognition approaches for big data, which can be used in future research.
C1 [Zerdoumi, Saber; Sabri, Aznul Qalid Md; Kamsin, Amirrudin; Gani, Abdullah; Hakak, Saqib; Al-garadi, Mohammed Ali] Univ Malaya, Dept Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
   [Hashem, Ibrahim Abaker Targio] Asia Pacific Univ Technol & Innovat, Technol Pk Malaysia, Kuala Lumpur, Malaysia.
   [Chang, Victor] Xian Jiaotong Liverpool Univ, IBSS, Suzhou, Peoples R China.
C3 Universiti Malaya; Asia Pacific University of Technology & Innovation;
   Xi'an Jiaotong-Liverpool University
RP Sabri, AQM (corresponding author), Univ Malaya, Dept Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
EM zerdoumisaber@gmail.com; aznulqalid@um.edu.my; amir@um.edu.my;
   targio_123@yahoo.com; abdullah@um.edu.my; saqibhakak@gmail.com;
   jarade2007@yahoo.com; ic.victor.chang@gmail.com
RI KAMSIN, AMIRRUDIN/B-8220-2010; Hashem, Ibrahim Abaker
   Targio/AAP-1204-2020; MD SABRI, AZNUL QALID/AGY-6106-2022; Chang,
   Victor/AAC-7582-2019; Hakak, Saqib/AAC-5134-2021; Gani,
   Abdullah/C-2888-2009
OI KAMSIN, AMIRRUDIN/0000-0003-2796-3459; Hashem, Ibrahim Abaker
   Targio/0000-0001-7611-9540; MD SABRI, AZNUL QALID/0000-0002-4758-5400;
   Chang, Victor/0000-0002-8012-5852; Gani, Abdullah/0000-0002-4388-020X
FU Malaysian Ministry of Education under the University of Malaya
FX This paper is supported by the Malaysian Ministry of Education under the
   University of Malaya.
CR Abaei G, 2015, KNOWL-BASED SYST, V74, P28, DOI 10.1016/j.knosys.2014.10.017
   Alginahi YM, 2013, INT J DOC ANAL RECOG, V16, P105, DOI 10.1007/s10032-012-0188-6
   Almeida LG, 2015, J HIGH ENERGY PHYS, DOI 10.1007/JHEP07(2015)086
   Alvarez-Meza A, 2011, PATTERN RECOGN LETT, V32, P2171, DOI 10.1016/j.patrec.2011.05.011
   Amin A, 2000, PATTERN ANAL APPL, V3, P243, DOI 10.1007/s100440070009
   [Anonymous], ELECT IMAGING 2008
   [Anonymous], 2015, Advances in Neural Information Processing Systems
   [Anonymous], 2013, P 29 C UNC ART INT 2
   [Anonymous], INT J SIGNAL PROCESS
   [Anonymous], 2015 INT C MAN MACH
   [Anonymous], ARXIV160400056
   [Anonymous], P 13 INT C
   [Anonymous], INT ARAB J INF TECHN
   [Anonymous], CURR TOP RISK AN ICR
   [Anonymous], PATT REC ICPR 2010 2
   [Anonymous], P 3 INT C FRONT INT
   [Anonymous], FMLLR BASED FEATURE
   [Anonymous], INTRO PATTERN RECOGN
   [Anonymous], P 16 INT C COMP SYST
   [Anonymous], HIGH CAP OPT NETW EN
   [Anonymous], 2015, ARXIV150100725
   [Anonymous], 2015, INT J SIGNAL PROCESS, DOI DOI 10.14257/ijsip.2015.8.7.21
   [Anonymous], 2015, ARXIV150204681
   [Anonymous], P 21 ACM SIGKDD INT
   [Anonymous], IM PROC ICIP 2015 IE
   [Anonymous], 2014, WRITING LITERACY CHI
   [Anonymous], BILDVERARBEITUNG MED
   [Anonymous], W21584 NAT BUR EC RE
   [Anonymous], CLOUD ENG IC2E 2017
   [Anonymous], 2007, COMP VIS PATT REC 20
   [Anonymous], EM ICT BRID FUT P 49
   [Anonymous], 2015 IE INT C AC SPE
   [Anonymous], 2015, ADV NEURAL INFORM PR
   [Anonymous], PATT REC ICPR 2010 2
   [Anonymous], 2012, From statistics to neural networks: theory and pattern recognition applications
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], DOC AN REC 1999 ICDA
   [Anonymous], COMPUTATIONAL SCIENC
   [Anonymous], 2015, Reseaux de Neurones Profonds pour la Reconnaissance de Texte Manucrit a Large Vocabulaire
   [Anonymous], 2016, 10162 IZA
   [Anonymous], 2015, OCEANS 2015 MTS IEEE
   [Anonymous], DAGSTUHL REP
   Astudillo CA, 2013, PATTERN RECOGN, V46, P293, DOI 10.1016/j.patcog.2012.07.006
   Ben-David S, 2003, J COMPUT SYST SCI, V66, P496, DOI 10.1016/S0022-0000(03)00038-2
   Bigdeli B, 2015, INT J APPL EARTH OBS, V38, P309, DOI 10.1016/j.jag.2015.01.017
   Bolivar-Cime A, 2013, J MULTIVARIATE ANAL, V115, P108, DOI 10.1016/j.jmva.2012.10.001
   Bonissone P, 2010, INT J APPROX REASON, V51, P729, DOI 10.1016/j.ijar.2010.02.003
   Boubaker H, 2015, COMPUT METHOD BIOMEC, V18, P1632, DOI 10.1080/10255842.2014.940331
   Cervantes J, 2008, NEUROCOMPUTING, V71, P611, DOI 10.1016/j.neucom.2007.07.028
   Chang V, 2016, FUTURE GENER COMP SY, V57, P24, DOI 10.1016/j.future.2015.09.031
   Chang V, 2015, AD HOC NETW, V35, P65, DOI 10.1016/j.adhoc.2015.07.012
   Chapelle O., 2006, SEMISUPERVISED LEARN
   Chavez E, 2008, IEEE T PATTERN ANAL, V30, P1647, DOI 10.1109/TPAMI.2007.70815
   Chen F, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/431047
   CHERNOFF H, 1952, ANN MATH STAT, V23, P493, DOI 10.1214/aoms/1177729330
   Cheung A, 2001, PATTERN RECOGN, V34, P215, DOI 10.1016/S0031-3203(99)00227-7
   Chorowski J, 2015, ADV NEUR IN, V28
   Coronel C., 2016, DATABASE SYSTEMS DES
   Cruz-Roa A, 2011, ARTIF INTELL MED, V52, P91, DOI 10.1016/j.artmed.2011.04.010
   Daza-Santacoloma G, 2010, NEUROCOMPUTING, V73, P1595, DOI 10.1016/j.neucom.2009.11.038
   Deng ZY, 2016, NEUROCOMPUTING, V195, P143, DOI 10.1016/j.neucom.2015.08.112
   Di Martino M, 2013, PATTERN RECOGN, V46, P2249, DOI 10.1016/j.patcog.2013.01.006
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   Dirick L, 2015, EUR J OPER RES, V241, P449, DOI 10.1016/j.ejor.2014.08.038
   Duda R. O., 2012, PATTERN CLASSIFICATI, DOI DOI 10.1007/978-3-319-57027-3_4
   Dunren Che, 2013, Database Systems for Advanced Applications. 18th International Conference, DASFAA 2013. International Workshops: BDMA, SNSM, SeCop. Proceedings: LNCS 7827, P1, DOI 10.1007/978-3-642-40270-8_1
   Fehlings MG, 2016, SPINE, V41, P390, DOI 10.1097/BRS.0000000000001232
   Fernández A, 2015, PATTERN RECOGN, V48, P1185, DOI 10.1016/j.patcog.2014.04.012
   Filho M, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0354-8
   Franco-Arcega A, 2011, EXPERT SYST APPL, V38, P14290, DOI 10.1016/j.eswa.2011.05.087
   Galaz-Montoya JG, 2016, J STRUCT BIOL, V194, P383, DOI 10.1016/j.jsb.2016.03.018
   Gallistel CR, 2016, CURR OPIN BEHAV SCI, V11, P8, DOI 10.1016/j.cobeha.2016.02.025
   Gkarmiri K, 2015, BMC GENOMICS, V16, DOI 10.1186/s12864-015-1758-z
   Gokhale M, 2008, COMPUTER, V41, P60, DOI 10.1109/MC.2008.125
   Gruber L, 2015, BAYESIAN ANAL, V10, P937, DOI 10.1214/14-BA930
   Gupta S, 2016, KNOWL INF SYST, V49, P933, DOI 10.1007/s10115-016-0926-z
   Han J, 2012, MOR KAUF D, P1
   Hashem IAT, 2017, Multimedia Tools and Applications, P1
   Hashem IAT, 2016, SCIENTOMETRICS, V109, P389, DOI 10.1007/s11192-016-1945-y
   Hashem IAT, 2015, INFORM SYST, V47, P98, DOI 10.1016/j.is.2014.07.006
   He ZF, 2016, SOFT COMPUT, V20, P287, DOI 10.1007/s00500-014-1503-6
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Inbarani HH, 2015, NEURAL COMPUT APPL, V26, P1859, DOI 10.1007/s00521-015-1840-0
   Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415
   Kadane JB, 2015, PREV SCI, V16, P1017, DOI 10.1007/s11121-014-0531-x
   Khoshnevisan B, 2015, STOCH ENV RES RISK A, V29, P1921, DOI 10.1007/s00477-014-0972-6
   Kotsiantis S.B., 2007, Supervised machine learning: A review of classification techniques, V160, P3
   Koukouli ME, 2015, J GEOPHYS RES-ATMOS, V120, DOI 10.1002/2015JD023699
   Kvarnhammar AM, 2012, IMMUNOLOGY, V136, P11, DOI 10.1111/j.1365-2567.2012.03556.x
   Lauer F, 2007, PATTERN RECOGN, V40, P1816, DOI 10.1016/j.patcog.2006.10.011
   Lee I, 2017, BUS HORIZONS, V60, P293, DOI 10.1016/j.bushor.2017.01.004
   Li X., 2006, MULTIMEDIA 06, P607, DOI DOI 10.1145/1180639.1180764
   Luqman H, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S021800141553002X
   Lv ZH, 2017, IEEE T IND INFORM, V13, P1891, DOI 10.1109/TII.2017.2650204
   Ma GW, 2015, ARAB J GEOSCI, V8, P1881, DOI 10.1007/s12517-014-1379-x
   Maldonado S, 2009, INFORM SCIENCES, V179, P2208, DOI 10.1016/j.ins.2009.02.014
   Matty M, 2015, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2015/01/P01026
   Meng Z, 2000, IEEE T NEURAL NETWOR, V11, P1031, DOI 10.1109/72.857784
   Merkevicius E, 2007, INF TECHNOL CONTROL, V36, P145
   Mervis J, 2012, SCIENCE, V336, P22, DOI 10.1126/science.336.6077.22
   Meysman P, 2015, BIODATA MIN, V8, DOI 10.1186/s13040-015-0038-4
   Mohri M., 2012, Foundations of Machine Learning
   Nixon Mark S, 2012, FEATURE EXTRACTION I, DOI DOI 10.1016/B978-0-12-396549-3.00007-0
   O'Leary DE, 2013, IEEE INTELL SYST, V28, P96, DOI 10.1109/MIS.2013.39
   Pao YH, 1998, ENG APPL ARTIF INTEL, V11, P659, DOI 10.1016/S0952-1976(98)00031-1
   Pao YH, 1997, PATTERN RECOGN, V30, P1705, DOI 10.1016/S0031-3203(97)00002-2
   Parvez MT, 2013, PATTERN RECOGN, V46, P141, DOI 10.1016/j.patcog.2012.07.012
   Patil H, 2015, ARTIF INTELL REV, V44, P393, DOI 10.1007/s10462-015-9431-0
   Pattin KA, 2015, BIOCOMPUT-PAC SYM, P488
   Peña-Ayala A, 2014, EXPERT SYST APPL, V41, P1432, DOI 10.1016/j.eswa.2013.08.042
   Radtke JP, 2016, EUR UROL, V70, P846, DOI 10.1016/j.eururo.2015.12.052
   Rahman MN, 2016, BIG DATA RES, V5, P9, DOI 10.1016/j.bdr.2016.02.002
   Raith S, 2017, COMPUT BIOL MED, V80, P65, DOI 10.1016/j.compbiomed.2016.11.013
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Rueda L, 2008, PATTERN RECOGN, V41, P3138, DOI 10.1016/j.patcog.2008.01.016
   Schowengerdt R.A., 2012, TECHNIQUES IMAGE PRO
   Schuelke-Leech BA, 2015, RENEW SUST ENERG REV, V52, P937, DOI 10.1016/j.rser.2015.07.128
   Sharma R, 2015, EXPERT SYST APPL, V42, P1106, DOI 10.1016/j.eswa.2014.08.030
   Shen XH, 2003, IEEE T PARALL DISTR, V14, P1262, DOI 10.1109/TPDS.2003.1255638
   Vajda S, 2015, PATTERN RECOGN LETT, V58, P23, DOI 10.1016/j.patrec.2015.02.001
   Valle E, 2010, IEEE T CONSUM ELECTR, V56, P1167, DOI 10.1109/TCE.2010.5606242
   Wei R, 2015, MASS COMMUN SOC, V18, P1, DOI 10.1080/15205436.2015.997274
   Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2
   Zhou LN, 2017, NEUROCOMPUTING, V237, P350, DOI 10.1016/j.neucom.2017.01.026
   Zikopoulos P.C., 2012, Understanding big data: Analytics for enterprise class hadoop and streaming data
NR 125
TC 36
Z9 37
U1 4
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 10091
EP 10121
DI 10.1007/s11042-017-5045-7
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200048
DA 2024-07-18
ER

PT J
AU Lu, HY
   Liu, QG
   Zhang, MH
   Wang, YH
   Deng, XH
AF Lu, Hongyang
   Liu, Qiegen
   Zhang, Minghui
   Wang, Yuhao
   Deng, Xiaohua
TI Gradient-based low rank method and its application in image inpainting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image inpainting; Low rank; Gradient image; Sparse representation;
   Variational models; Deterministic annealing
ID SPARSE; RESTORATION; INTERPOLATION; COMPLETION; FRAMEWORK; DOMAIN; SPACE
AB Conventional inpainting methods generally apply textures that are most similar to the areas around the missing region or use large image database. Recently, low rank property of data shows that the non-convex optimization decreases measurements. In this paper, we propose a new image prior, which implies the low rank prior knowledge of image gradients. The proposed detail-preserving image inpainting algorithm adopts the low rank regularization to gradient similarity minimization, termed gradient-based low rank approximation (Grad-LR), namely that we employ the low rank constraints in the horizontal and vertical gradients of the image and then reconstruct the desired image using the adaptive iterative singular-value thresholding of both derivatives. In the method, by incorporating the spatially adaptive iterative singular-value thresholding (SAIST) to optimize our gradient scheme, the deterministic annealing iterates the procedure efficiently. As a result, the strength of the algorithm is obvious when filling large missing region. Experimental results consistently demonstrate that the proposed algorithm works well for both structural and texture images and outperforms other techniques, in terms of both objective and subjective performance measures.
C1 [Lu, Hongyang; Liu, Qiegen; Zhang, Minghui; Wang, Yuhao; Deng, Xiaohua] Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
   [Lu, Hongyang; Deng, Xiaohua] Nanchang Univ, Inst Space Sci & Technol, Nanchang 330031, Jiangxi, Peoples R China.
C3 Nanchang University; Nanchang University
RP Liu, QG (corresponding author), Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
EM luhongyang@email.ncu.edu.cn; liuqiegen@ncu.edu.cn; zhangmh@163.com;
   wangyuhao@ncu.edu.cn; dengxhua@gmail.com
RI WANG, Yuhao/O-9322-2019; Li, Yuanyuan/J-3539-2014
OI WANG, Yuhao/0000-0002-8445-0361; Li, Yuanyuan/0000-0001-6151-9306
FU National Natural Science Foundation of China [61661031, 61362001,
   61503176]; Jiangxi advanced projects for post-doctoral research funds
   [2014KY02]; international postdoctoral exchange fellowship program;
   international scientific and technological cooperation projects of
   Jiangxi Province [20141BDH80001]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments. This work was supported in part by the National
   Natural Science Foundation of China under 61661031, 61362001, 61503176,
   Jiangxi advanced projects for post-doctoral research funds (2014KY02),
   the international postdoctoral exchange fellowship program, the
   international scientific and technological cooperation projects of
   Jiangxi Province (No. 20141BDH80001).
CR ALGAZI VR, 1991, INT CONF ACOUST SPEE, P3005, DOI 10.1109/ICASSP.1991.151035
   Allebach J, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P707, DOI 10.1109/ICIP.1996.560768
   [Anonymous], SIAM NEWS
   Arias P, 2011, INT J COMPUT VISION, V93, P319, DOI 10.1007/s11263-010-0418-7
   Arias P, 2009, LECT NOTES COMPUT SC, V5681, P345, DOI 10.1007/978-3-642-03641-5_26
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Bertozzi AL, 2007, IEEE T IMAGE PROCESS, V16, P285, DOI 10.1109/TIP.2006.887728
   Bornemann F, 2007, J MATH IMAGING VIS, V28, P259, DOI 10.1007/s10851-007-0017-6
   Brandtberg T, 2003, IEEE T GEOSCI REMOTE, V41, P102, DOI 10.1109/TGRS.2002.808059
   Burger M, 2009, SIAM J IMAGING SCI, V2, P1129, DOI 10.1137/080728548
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Cai JF, 2009, NUMER MATH, V112, P509, DOI 10.1007/s00211-009-0222-x
   Carrato S, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P711, DOI 10.1109/ICIP.1996.560778
   Chan TF, 2005, COMMUN PUR APPL MATH, V58, P579, DOI 10.1002/cpa.20075
   Cho TS, 2012, IEEE T PATTERN ANAL, V34, P683, DOI 10.1109/TPAMI.2011.166
   Cho TS, 2010, PROC CVPR IEEE, P169, DOI 10.1109/CVPR.2010.5540214
   Coombs W., 2000, J PUBLIC RELATIONS R, V12, P163, DOI DOI 10.1207/S1532754XJPRR12022
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Elad M, 2005, APPL COMPUT HARMON A, V19, P340, DOI 10.1016/j.acha.2005.03.005
   Facciolo G, 2009, LECT NOTES COMPUT SC, V5681, P331, DOI 10.1007/978-3-642-03641-5_25
   Fadili MJ, 2009, COMPUT J, V52, P64, DOI 10.1093/comjnl/bxm055
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Gepshtein S, 2013, IEEE T IMAGE PROCESS, V22, P2983, DOI 10.1109/TIP.2013.2237916
   Guleryuz OG, 2006, IEEE T IMAGE PROCESS, V15, P555, DOI 10.1109/TIP.2005.863055
   JENSEN K, 1995, IEEE T IMAGE PROCESS, V4, P285, DOI 10.1109/83.366477
   Ji H, 2011, SIAM J IMAGING SCI, V4, P1122, DOI 10.1137/100817206
   Kindermann S, 2005, MULTISCALE MODEL SIM, V4, P1091, DOI 10.1137/050622249
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Li XT, 2008, IEEE BIPOL BICMOS, P1, DOI 10.1109/BIPOL.2008.4662699
   Li X, 2011, IEEE J-STSP, V5, P953, DOI 10.1109/JSTSP.2011.2138676
   Liu QG, 2013, IEEE T IMAGE PROCESS, V22, P4652, DOI 10.1109/TIP.2013.2277798
   Liu YQ, 2013, IEEE T IMAGE PROCESS, V22, P1699, DOI 10.1109/TIP.2012.2218828
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Morse BS, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P227, DOI 10.1109/ICIP.1998.999013
   Ogawa T, 2013, IEEE T IMAGE PROCESS, V22, P1252, DOI 10.1109/TIP.2012.2220152
   Ogawa T, 2011, IEEE T MULTIMEDIA, V13, P974, DOI 10.1109/TMM.2011.2161760
   Papafitsorosl K, 2013, IMAGE PROCESS ON LIN, V3, P112, DOI 10.5201/ipol.2013.40
   Paul G, 2013, INT J COMPUT VISION, V104, P69, DOI 10.1007/s11263-013-0615-2
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Ratakonda K, 1998, ICIP, P203
   Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6
   Schönlieb CB, 2011, COMMUN MATH SCI, V9, P413
   Sun J, 2011, IEEE T IMAGE PROCESS, V20, P1529, DOI 10.1109/TIP.2010.2095871
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Wang MH, 2013, SIGNAL PROCESS-IMAGE, V28, P753, DOI 10.1016/j.image.2013.03.002
   Wang S., 2012, PROC ASI C COMPUT VI, P231
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
   Zuo WM, 2013, PROC CVPR IEEE, P1203, DOI 10.1109/CVPR.2013.159
NR 52
TC 17
Z9 18
U1 1
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5969
EP 5993
DI 10.1007/s11042-017-4509-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800038
DA 2024-07-18
ER

PT J
AU Xu, LM
   Lv, JD
AF Xu, Liming
   Lv, Jidong
TI Recognition method for apple fruit based on SUSAN and PCNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Apple; Image processing; Target recognition; Image segmentation
ID SEGMENTATION; ALGORITHM; NUMBER
AB This study proposes a recognition method for apple fruit based on SUSAN (Smallest univalues segment assimilating nucleus) and PCNN (Pulse coupled neural network) to accurately identify and locate fruit targets. First, homomorphic filtering is used to conduct image enhancement by considering the influence of different lighting conditions on the segmentation effect, thus achieving light compensation. After an image is processed by R-G color differences in RGB color space, the apple image is segmented using the PCNN image segmentation method based on minimum cross entropy. In terms of prior knowledge of the maximum and minimum radius of the apple fruit, an improved random Hough transform method is used to detect the characteristic circle of the apple target; according to the edge of the apple target obtained by the SUSAN edge detection algorithm. Comparative experiments with different segmentation algorithms confirm that the algorithm of this study has outstanding performance in reducing the influence of insufficient light on the segmentation result. In 50 images, 93% of apples were accurately identified, which proves the effectiveness of the algorithm in this study.
C1 [Xu, Liming] Jiangsu Urban & Rural Construct Coll, Dept Equipment Engn, Changzhou 213147, Peoples R China.
   [Lv, Jidong] Changzhou Univ, Sch Informat Sci & Engn, Changzhou 213164, Peoples R China.
C3 Jiangsu Urban & Rural Construction Vocational College; Changzhou
   University
RP Lv, JD (corresponding author), Changzhou Univ, Sch Informat Sci & Engn, Changzhou 213164, Peoples R China.
EM vveaglevv@163.com
FU Natural Science Foundation of Jiangsu Province [BK20140266]; Natural
   Science Research Program for Higher Education in Jiangsu Province
   [14KJB210001]; Scientific Research Foundation for Changzhou University
   [ZMF13020019]
FX This work was partly supported by Natural Science Foundation of Jiangsu
   Province under Grant BK20140266, Natural Science Research Program for
   Higher Education in Jiangsu Province under Grant 14KJB210001, Scientific
   Research Foundation for Changzhou University under Grant ZMF13020019.
CR Adhikari B, 2011, 3D RECONSTRUCTION AP
   [Anonymous], 2013, EXPT ROBOTICS, DOI DOI 10.1007/978-3-319-00065-7_50
   Bac CW, 2013, COMPUT ELECTRON AGR, V96, P148, DOI 10.1016/j.compag.2013.05.004
   Burgos-Artizzu XP, 2011, COMPUT ELECTRON AGR, V75, P337, DOI 10.1016/j.compag.2010.12.011
   Chen KeYin Chen KeYin, 2013, Transactions of the Chinese Society of Agricultural Engineering, V29, P157
   Cui YongJie Cui YongJie, 2013, Nongye Jixie Xuebao = Transactions of the Chinese Society for Agricultural Machinery, V44, P247
   Dean Z, 2015, T CHINESE SOC AGR MA, V46, P15
   Eckhorn R, 1990, NEURAL COMPUT, V2, P293, DOI 10.1162/neco.1990.2.3.293
   Feng Juan Feng Juan, 2013, Nongye Jixie Xuebao = Transactions of the Chinese Society for Agricultural Machinery, V44, P217
   Gao C, 2013, NEUROCOMPUTING, V119, P332, DOI 10.1016/j.neucom.2013.03.025
   Gómez-Sanchis J, 2008, J FOOD ENG, V89, P80, DOI 10.1016/j.jfoodeng.2008.04.009
   Guijarro M, 2011, COMPUT ELECTRON AGR, V75, P75, DOI 10.1016/j.compag.2010.09.013
   Hayashi S, 2010, BIOSYST ENG, V105, P160, DOI 10.1016/j.biosystemseng.2009.09.011
   Jia WeiKuan Jia WeiKuan, 2015, Transactions of the Chinese Society of Agricultural Engineering, V31, P175
   Kelman E, 2014, BIOSYST ENG, V118, P174, DOI 10.1016/j.biosystemseng.2013.11.007
   Kurtulmus F, 2011, COMPUT ELECTRON AGR, V78, P140, DOI 10.1016/j.compag.2011.07.001
   Linker R, 2012, COMPUT ELECTRON AGR, V81, P45, DOI 10.1016/j.compag.2011.11.007
   [刘丽 LIU li], 2009, [中国图象图形学报, Journal of Image and Graphics], V14, P622
   [刘勍 Liu Qing], 2005, [中国图象图形学报. A, Journal of image and graphics], V10, P579
   Luo LuFeng Luo LuFeng, 2015, Transactions of the Chinese Society of Agricultural Engineering, V31, P14
   Rong M, 2005, ELECT OPT CONTROL, V12, P30
   Shidong C, 2011, OPTOELECTRON TECHNOL, V31, P5
   Silveira M, 2005, LECT NOTES COMPUT SC, V3523, P271
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Stajnko D, 2004, COMPUT ELECTRON AGR, V42, P31, DOI 10.1016/S0168-1699(03)00086-3
   TABB AL, 2006, ASABE M
   Tanigaki K, 2008, COMPUT ELECTRON AGR, V63, P65, DOI 10.1016/j.compag.2008.01.018
   Wang J., 2009, T CHINESE SOC AGR MA, V40, P147
   Wang Z.-W., 2012, MANUF AUTOM, V34, P14
   Wang ZB, 2010, IMAGE VISION COMPUT, V28, P5, DOI 10.1016/j.imavis.2009.06.007
   Xie Z.-x., 2009, J CHENGDU MED COLL, V4, P157
   XU L, 1993, CVGIP-IMAG UNDERSTAN, V57, P131, DOI 10.1006/ciun.1993.1009
   XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z
   Yafei Z, 2013, COMPUTER APPL SOFTWA, V30, P303
   Yongsheng SI, 2010, T CHINESE SOC AGR MA, V41, P148
   Zhuqing J, 2010, J OPTOELECTRONICS LA, V21, P602
NR 36
TC 19
Z9 22
U1 4
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7205
EP 7219
DI 10.1007/s11042-017-4629-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700036
DA 2024-07-18
ER

PT J
AU Akila, C
   Varatharajan, R
AF Akila, C.
   Varatharajan, R.
TI Color fidelity and visibility enhancement of underwater image de-hazing
   by enhanced fuzzy intensification operator
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater image; Enhancement; Color fidelity; Fuzzy intensification;
   Visibility
AB This paper presents an optimization based algorithm for underwater image de-hazing problem. Underwater image de-hazing is the most prominent area in research. Underwater images are corrupted due to absorption and scattering. With the effect of that, underwater images have the limitation of low visibility, low color and poor natural appearance. To avoid the mentioned problems, Enhanced fuzzy intensification method is proposed. For each color channel, enhanced fuzzy membership function is derived. Second, the correction of fuzzy based pixel intensification is carried out for each channel to remove haze and to enhance visibility and color. The post processing of fuzzy histogram equalization is implemented for red channel alone when the captured image is having highest value of red channel pixel values. The proposed method provides better results in terms maximum entropy and PSNR with minimum MSE with very minimum computational time compared to existing methodologies.
C1 [Akila, C.] Anna Univ, Reg Campus Tirunelveli, Tirunelveli 627007, India.
   [Varatharajan, R.] Sri Ramanujar Engn Coll, Dept ECE, Madras 600127, Tamil Nadu, India.
C3 Anna University; Anna University of Technology Tirunelveli
RP Varatharajan, R (corresponding author), Sri Ramanujar Engn Coll, Dept ECE, Madras 600127, Tamil Nadu, India.
EM akilavp@gmail.com; varathu21@yahoo.com
CR Al-Ameen Zohair, 2016, International Journal of Intelligent Systems and Applications, V8, P10, DOI 10.5815/ijisa.2016.08.02
   Ancuti C, 2012, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2012.6247661
   [Anonymous], 2015, P BMVC
   Carlevaris-Bianco N., 2010, OCEANS, P1, DOI DOI 10.1109/OCEANS.2010.5664428
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Codevilla F, 2015, P BRIT MACH VIS C BM
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Gao Y, 2016, MATH PROB ENG, V1-15
   Goel G, 2015, INDIAN J SCI TECHNOL, V8, P1
   Hamnandlu M, 2006, IEEE T IMAGE PROCESS, V15, P2956, DOI 10.1109/TIP.2006.877499
   Hitam MS, 2013, COMP APPL TECHN ICCA
   Kumar C., 2011, INT J MACHINE INTELL, V3, P217
   Li C, 2016, IEEE INT C AC SPEECH
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Lu H, MULTIMED TOOLS APPL
   Lu HM, 2015, J OPT SOC AM A, V32, P886, DOI 10.1364/JOSAA.32.000886
   Magudeeswaran V, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/891864
   Patil VS, 2016, IEEE INT C COMP INT
   Schettini R, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/746052
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Wen H, 2013, CIRC SYST ISCAS 2013
NR 22
TC 8
Z9 8
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4309
EP 4322
DI 10.1007/s11042-017-5187-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500015
DA 2024-07-18
ER

PT J
AU Ma, JW
   Li, G
   Zhong, MY
   Zhao, X
   Zhu, L
   Li, X
AF Ma, Jingwei
   Li, Guang
   Zhong, Mingyang
   Zhao, Xin
   Zhu, Lei
   Li, Xue
TI LGA: latent genre aware micro-video recommendation on social media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Micro-video recommendation; Genre aware; Neural network
AB Social media has evolved into one of the most important channels to share micro-videos nowadays. The sheer volume of micro-videos available in social networks often undermines users' capability to choose the micro-videos that best fit their interests. Recommendation appear as a natural solution to this problem. However, existing video recommendation methods only consider the users' historical preferences on videos, without exploring any video contents. In this paper, we develop a novel latent genre aware micro-video recommendation model to solve the problem. First, we extract user-item interaction features, and auxiliary features describing both contextual and visual contents of micro-videos. Second, these features are fed into the neural recommendation model that simultaneously learns the latent genres of micro-videos and the optimal recommendation scores. Experiments on real-world dataset demonstrate the effectiveness and the efficiency of our proposed method compared with several state-of-the-art approaches.
C1 [Ma, Jingwei; Zhong, Mingyang; Zhao, Xin; Zhu, Lei; Li, Xue] Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld, Australia.
   [Li, Guang] Tianjin Univ, Sch Comp Sci & Technol, Tianjin, Peoples R China.
C3 University of Queensland; Tianjin University
RP Zhong, MY (corresponding author), Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld, Australia.
EM m.zhong1@uq.edu.au
RI Zhu, Lei/GQQ-1130-2022; MA, JINGWEI/H-8829-2013
OI Zhu, Lei/0000-0002-5348-7532; MA, JINGWEI/0000-0002-8854-9756; Zhu,
   Lei/0000-0002-2993-7142; LI, Xue/0000-0002-4515-6792
CR [Anonymous], 2016, SHOW TELL LESSONS LE
   [Anonymous], 2016, ARXIV160400790
   [Anonymous], 2007, ADAPTIVE WEB, DOI DOI 10.1007/978-3-540-72079-9_10
   [Anonymous], 2015, P RECSYS
   [Anonymous], IEEE MULTIMEDIA
   Bordes Antoine, 2014, JOINT EUROPEAN C MAC, P165
   Burges Chris, 2005, P 22 INT C MACH LEAR, P89, DOI DOI 10.1145/1102351.1102363
   Chang XJ, 2016, AAAI CONF ARTIF INTE, P3464
   Chang XJ, 2016, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2016.208
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang X, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P581, DOI 10.1145/2733373.2806218
   Chang XJ, 2015, PR MACH LEARN RES, V37, P1348
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1454, DOI 10.1145/2964284.2971477
   Chen K., 2015, Abc-cnn: An attention based convolutional neural network for visual question answering
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ference G, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P721, DOI 10.1145/2505515.2505637
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Guo JF, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P55, DOI 10.1145/2983323.2983769
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu YF, 2008, IEEE DATA MINING, P263, DOI 10.1109/ICDM.2008.22
   Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2333
   Konstan J., 2001, P 10 INT C WORLD WID, P285
   Konstan JA, 1997, COMMUN ACM, V40, P77, DOI 10.1145/245108.245126
   Liu LC, 2017, PATTERN RECOGN, V64, P314, DOI 10.1016/j.patcog.2016.10.034
   Mei T., 2007, Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P767
   Park W., 2009, RecSys, P21
   Razavian A. S., 2014, Workshop on IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2014), P806, DOI [10.1109/cvprw.2014.131, DOI 10.1109/CVPRW.2014.131]
   Rendle S., 2009, P 25 C UNC ART INT, P452, DOI DOI 10.5555/1795114.1795167
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Severyn A, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P373, DOI 10.1145/2766462.2767738
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang H, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1235, DOI 10.1145/2783258.2783273
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yin HZ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P819, DOI 10.1145/2733373.2806339
   Zhai SF, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1295, DOI 10.1145/2939672.2939759
   Zhang J., 2016, P ACM INT C MULT, P1415
NR 37
TC 28
Z9 29
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 2991
EP 3008
DI 10.1007/s11042-017-4827-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600005
DA 2024-07-18
ER

PT J
AU Son, HS
   Kim, RYC
AF Son, Hyun Seung
   Kim, R. Young Chul
TI Automatic transformation tools of UML design models from virtual
   prototypes of multi-jointed robots
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Model transformation; UML; Virtual prototyping; Software controller;
   Multi-jointed robot; Virtual Robert (VirRobot)
AB Most of robotic companies develop a control programming of multi-jointed robots, which spend too much time to manually adjust the moving functions of the robots. To solve this problem, we adapt the virtual prototyping (VP) to develop the control program of the robotic behaviors. For software engineers, in order for them to easily program this robot, we also apply metamodel mechanism to convert UML models with virtual prototyping model. We propose the automatic model transformation from the virtual prototyping model to UML models, which will then develop coding based on UML models. To prove our mechanism's efficiency, we implement Robot to UML Translator (RUT) as our transformation rules with ATLAS transformational language. Lastly, we show experimental validation about the consistency of our proposed technique with an example of multi-joined robot prototype models.
C1 [Son, Hyun Seung; Kim, R. Young Chul] Hongik Univ, Dept Comp & Informat Commun, SE Lab, Sejong 30016, South Korea.
C3 Hongik University
RP Kim, RYC (corresponding author), Hongik Univ, Dept Comp & Informat Commun, SE Lab, Sejong 30016, South Korea.
EM son@selab.hongik.ac.kr; bob@selab.hongik.ac.kr
FU Human Resource Training Program for Regional Innovation and Creativity
   through the Ministry of Education; National Research Foundation of Korea
   [NRF-2015H1C1A1035548]
FX This work was supported by the Human Resource Training Program for
   Regional Innovation and Creativity through the Ministry of Education and
   National Research Foundation of Korea (NRF-2015H1C1A1035548)
CR [Anonymous], 2006, MET FAC MOF COR SPEC
   [Anonymous], XML MET INT XMI SPEC
   [Anonymous], 2015, MET FAC MOF 2 0 QUER
   [Anonymous], 2014, OBJ CONSTR LANG SPEC
   [Anonymous], 2 OOPSLA WORKSH GEN
   Gassmann B, 2001, IEEE ASME INT C ADV, P959, DOI 10.1109/AIM.2001.936810
   Grieco J. C., 1998, Proceedings of the 1998 IEEE International Conference on Control Applications (Cat. No.98CH36104), P446, DOI 10.1109/CCA.1998.728488
   Gronmo R, 2005, P 1 INT C INT ENT SO
   Hyun Seung Son, 2008, 2008 Second International Conference on Future Generation Communication and Networking Symposia (FGCNS), P93, DOI 10.1109/FGCNS.2008.132
   Jouault F, 2006, LECT NOTES COMPUT SC, V3844, P128
   Kerscher T, 2002, ROMOCO'02: PROCEEDINGS OF THE THIRD INTERNATIONAL WORKSHOP ON ROBOT MOTION AND CONTROL, P27, DOI 10.1109/ROMOCO.2002.1177079
   Kim DW, 2008, P 2008 COMM EL AG DE, P168
   Kim JS, 2008, J KOREAN ASS INF ED, V12, P469
   Kim W, 2008, J HIGH ENERGY PHYS, DOI 10.1088/1126-6708/2008/01/035
   Microsoft, 2007, MICR ROB STUD MSRS I
   OMG, 2014, MOD DRIV ARCH MDA GU
   OMG: OMG Unified Modeling Language (OMG UML), 2009, OMG UN MOD LANG OMG
   RAIBERT MH, 1986, COMMUN ACM, V29, P499, DOI 10.1145/5948.5950
   Smith R., 2006, OPEN DYNAMICS ENGINE
   Tseng M. M., 1998, Integrated Manufacturing Systems, V9, P334, DOI 10.1108/09576069810238682
   Vojtisek D, 2004, ERCIM NEWS
   WETTERGREEN D, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 3, P274, DOI 10.1109/IROS.1995.525895
   WooYeol Kim, 2009, 2009 WRI World Congress on Computer Science and Information Engineering, CSIE, P775, DOI 10.1109/CSIE.2009.998
   김우열, 2007, [The KIPS Transactions : Part D, 정보처리학회논문지D], V14, P83
NR 24
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 5083
EP 5106
DI 10.1007/s11042-017-5579-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500056
DA 2024-07-18
ER

PT J
AU Zhu, XN
   Ben, XY
   Liu, SG
   Yan, R
   Meng, WX
AF Zhu, Xuena
   Ben, Xianye
   Liu, Shigang
   Yan, Rui
   Meng, Weixiao
TI Coupled source domain targetized with updating tag vectors for
   micro-expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Micro-expression recognition; Coupled source domain targetized; Tag
   vectors; Transfer learning
ID LOCAL BINARY PATTERNS; FACE RECOGNITION; FEATURE-SELECTION; GAIT
   RECOGNITION; K-SVD; CLASSIFICATION; ADAPTATION; SPEECH
AB Micro-expression has raised increasing attention for analyzing human inner emotions. However, most micro-expression recognition methods are developed with specific feature representations and extraction methods, such as local binary pattern on three orthogonal planes (LBP-TOP) and optical flow. The performance in such micro-expression recognition models is not high due to the limited training samples and the unequal size of the sample category. To improve the performance, we present a novel algorithm, named coupled source domain targetized with updating tag vectors, and we apply it to the micro-expression recognition. This method leverages rich speech data to enhance micro-expression recognition by transferring learning from the speech to the micro-expression recognition. The method highlights are: it simultaneously projects micro-expression samples and speech samples into a common space, then minimizes the reconstruction error between the speech and micro-expression samples, with an updating tag vectors added in the reconstruction process. It performs recognition by using dictionary learning together with support vector machine (SVM). Experimental results on the CASIA Chinese emotional corpus and CASME II micro-expression database demonstrate the effectiveness of our method.
C1 [Zhu, Xuena; Ben, Xianye] Shandong Univ, Sch Informat Sci & Engn, 27 Shanda South Rd, Jinan 250100, Peoples R China.
   [Liu, Shigang] Shaanxi Normal Univ, Sch Comp Sci, Xian 710062, Peoples R China.
   [Yan, Rui] Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA.
   [Meng, Weixiao] Harbin Inst Technol, Sch Elect & Informat Engn, Harbin 150080, Heilongjiang, Peoples R China.
C3 Shandong University; Shaanxi Normal University; Rensselaer Polytechnic
   Institute; Harbin Institute of Technology
RP Ben, XY (corresponding author), Shandong Univ, Sch Informat Sci & Engn, 27 Shanda South Rd, Jinan 250100, Peoples R China.
EM benxianye@gmail.com
RI Zhu, Xuena/E-9071-2017
FU Natural Science Foundation of China [61571275, 61672333]; Young Scholars
   Program of Shandong University; National Key Research and Development
   Program of China [2017YFC0803400]
FX We sincerely thank the Institute of Psychology, Chinese Academy of
   Sciences for granting us permission to use the CASME database. This
   project is supported by the Natural Science Foundation of China (Grant
   No. 61571275, 61672333), the Young Scholars Program of Shandong
   University, and the National Key Research and Development Program of
   China (Grant No. 2017YFC0803400).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2013, IJCAI '13
   [Anonymous], 1966, Methods of research in psychotherapy, DOI [DOI 10.1007/978-1-4684-6045-2_14, 10.1007/978-1-4684-6045-2_14]
   Ben XY, 2016, NEURAL COMPUT APPL, V27, P2629, DOI 10.1007/s00521-015-2031-8
   Ben XY, 2016, NEUROCOMPUTING, V208, P153, DOI 10.1016/j.neucom.2016.01.098
   Ben XY, 2013, NEUROCOMPUTING, V120, P577, DOI 10.1016/j.neucom.2013.04.012
   Bryt O, 2008, J VIS COMMUN IMAGE R, V19, P270, DOI 10.1016/j.jvcir.2008.03.001
   CASIA, 2006, CASIA CHINESE EMOTIO
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Du B, 2017, IEEE T CYBERNETICS, V47, P14, DOI 10.1109/TCYB.2015.2496974
   Duan XD, 2016, NEUROCOMPUTING, V217, P27, DOI 10.1016/j.neucom.2016.03.090
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Ekman P., 2009, TELLING LIES CLUES D
   Endres J, 2009, BMC MED EDUC, V9, DOI 10.1186/1472-6920-9-47
   Engan K, 1999, INT CONF ACOUST SPEE, P2443, DOI 10.1109/ICASSP.1999.760624
   Fangbing Qu, 2018, IEEE Transactions on Affective Computing, V9, P424, DOI 10.1109/TAFFC.2017.2654440
   Gong C, 2016, IEEE T IMAGE PROCESS, V25, P3249, DOI 10.1109/TIP.2016.2563981
   Gong C, 2015, IEEE T NEUR NET LEAR, V26, P2261, DOI 10.1109/TNNLS.2014.2376936
   Gong C, 2015, IEEE T NEUR NET LEAR, V26, P2148, DOI 10.1109/TNNLS.2014.2376963
   Gu B, 2017, IEEE T NEUR NET LEAR, V28, P1646, DOI 10.1109/TNNLS.2016.2544779
   Guo YJ, 2014, IEEE IJCNN, P3473, DOI 10.1109/IJCNN.2014.6889620
   Han YH, 2015, IEEE T NEUR NET LEAR, V26, P252, DOI 10.1109/TNNLS.2014.2314123
   He JC, 2017, PATTERN RECOGN, V66, P44, DOI 10.1016/j.patcog.2016.11.029
   Jia XT, 2018, J COMPUT SCI-NETH, V25, P289, DOI 10.1016/j.jocs.2017.03.016
   Kan MN, 2014, INT J COMPUT VISION, V109, P94, DOI 10.1007/s11263-013-0693-1
   Li HB, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P754, DOI 10.1109/ICIG.2009.101
   Li Z., 2012, P AAAI C ART INT, P1026
   Li ZC, 2014, IEEE T KNOWL DATA EN, V26, P2138, DOI 10.1109/TKDE.2013.65
   Liao SC, 2013, IEEE T PATTERN ANAL, V35, P1193, DOI 10.1109/TPAMI.2012.191
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   MCCREE AV, 1995, IEEE T SPEECH AUDI P, V3, P242, DOI 10.1109/89.397089
   Miao YJ, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P167, DOI 10.1109/ASRU.2015.7404790
   Muda Lindasalwa, 2010, Voice recognition algorithms using mel frequency cepstral coefficient (mfcc) and dynamic time warping (dtw) techniques
   Murty KR, 2006, IEEE SIGNAL PROC LET, V13, P52, DOI 10.1109/LSP.2005.860538
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pati YC, 1993, SIGN SYST COMP 1993, P40, DOI DOI 10.1109/ACSSC.1993.342465
   Ren CX, 2010, PATTERN RECOGN, V43, P318, DOI 10.1016/j.patcog.2009.05.020
   Sobin C, 1999, J PSYCHOLINGUIST RES, V28, P347, DOI 10.1023/A:1023237014909
   Song L., 2007, P 24 INT C MACH LEAR, P823, DOI DOI 10.1145/1273496.1273600
   Vergyri D, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P208
   Wang SJ, 2016, NEUROCOMPUTING, V214, P218, DOI 10.1016/j.neucom.2016.05.083
   Wang SJ, 2014, INT C PATT RECOG, P4678, DOI 10.1109/ICPR.2014.800
   Wang SJ, 2014, NEURAL PROCESS LETT, V39, P25, DOI 10.1007/s11063-013-9288-7
   Wang ZY, 2015, NEURAL COMPUT APPL, V26, P1645, DOI 10.1007/s00521-015-1834-y
   Xia ZQ, 2016, COMPUT VIS IMAGE UND, V147, P87, DOI 10.1016/j.cviu.2015.12.006
   Xu F, 2017, IEEE T AFFECT COMPUT, V8, P254, DOI 10.1109/TAFFC.2016.2518162
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938
   Yang WK, 2015, PATTERN RECOGN, V48, P20, DOI 10.1016/j.patcog.2014.07.009
   Yang Y., 2011, P 22 INT JOINT C ART, P1589
   Yang Y, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2457450.2457456
   Yang Y, 2015, INT J COMPUT VISION, V113, P113, DOI 10.1007/s11263-014-0781-x
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Yeh YR, 2014, IEEE T IMAGE PROCESS, V23, P2009, DOI 10.1109/TIP.2014.2310992
   Zhang P, 2016, OPTIK, V127, P1395, DOI 10.1016/j.ijleo.2015.10.217
   Zhang S, 2017, LECT NOTES COMPUTER
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 59
TC 14
Z9 15
U1 0
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3105
EP 3124
DI 10.1007/s11042-017-4943-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600011
DA 2024-07-18
ER

PT J
AU Gao, Y
   Lee, H
AF Gao, Yongbin
   Lee, Hyo Jong
TI Learning warps based similarity for pose-unconstrained face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pattern recognition; Learning warps; Scale-invariant feature transform
ID PATTERNS; REPRESENTATION; MODEL
AB Face recognition techniques are widely used in many applications, such as automatic detection of crime scenes from surveillance cameras for public safety. In these real cases, the pose and illumination variances between two matching faces have a big influence on the identification performance. Handling pose changes is an especially challenging task. In this paper, we propose the learning warps based similarity method to deal with face recognition across the pose problem. Warps are learned between two patches from probe faces and gallery faces using the Lucas-Kanade algorithm. Based on these warps, a frontal face registered in the gallery is transformed into a series of non-frontal viewpoints, which enables non-frontal probe face matching with the frontal gallery face. Scale-invariant feature transform (SIFT) keypoints (interest points) are detected from the generated viewpoints and matched with the probe faces. Moreover, based on the learned warps, the probability likelihood is used to calculate the probability of two faces being the same subject. Finally, a hybrid similarity combining the number of matching keypoints and the probability likelihood is proposed to describe the similarity between a gallery face and a probe face. Experimental results show that our proposed method achieves better recognition accuracy than other algorithms it was compared to, especially when the pose difference is within 40 degrees.
C1 [Gao, Yongbin] Chonbuk Natl Univ, Div Comp Sci & Engn, Deokjin Ku, Baekje Dero 567, Jeonju 54896, Chonbuk, South Korea.
   [Lee, Hyo Jong] Chonbuk Natl Univ, Div Comp Sci & Engn, Ctr Adv Image & Informat Technol, Deokjin Ku, Baekje Dero 567, Jeonju 54896, Chonbuk, South Korea.
C3 Jeonbuk National University; Jeonbuk National University
RP Lee, H (corresponding author), Chonbuk Natl Univ, Div Comp Sci & Engn, Ctr Adv Image & Informat Technol, Deokjin Ku, Baekje Dero 567, Jeonju 54896, Chonbuk, South Korea.
EM gaoyongbin.sam@gmail.com; hlee@chonbuk.ac.kr
RI Lee, Hyo Jong/B-7565-2017
FU Brain Korea 21 PLUS Project; State Scholarship Fund; Business for
   Academic-Industrial Cooperative establishments - Korea Small and Medium
   Business Administration [C0221114]; MSIP (Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC (Information Technology Research
   Center) support program [IITP-2016-R0992-16-1023]; Basic Science
   Research Program through the National Research Foundation of Korea(NRF)
   - Ministry of Education [GR 2016R1D1A3B03931911]; project of local
   colleges' and universities' capacity construction of Science and
   Technology Commission in Shanghai [15590501300]; National Natural
   Science Foundation of China [61461021]
FX This work was supported by the Brain Korea 21 PLUS Project and the State
   Scholarship Fund organized by the China Scholarship Council. This work
   was also supported by the Business for Academic-Industrial Cooperative
   establishments that were funded by the Korea Small and Medium Business
   Administration in 2015 (Grants No. C0221114). This research was also
   supported by the MSIP (Ministry of Science, ICT and Future Planning),
   Korea, under the ITRC (Information Technology Research Center) support
   program (IITP-2016-R0992-16-1023) supervised by the IITP (Institute for
   Information & communications Technology Promotion). This work was also
   supported by Basic Science Research Program through the National
   Research Foundation of Korea(NRF) funded by the Ministry of Education
   (GR 2016R1D1A3B03931911). This paper was also supported by the project
   of local colleges' and universities' capacity construction of Science
   and Technology Commission in Shanghai (No. 15590501300) and by the
   National Natural Science Foundation of China (No. 61461021).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], VIDEO CHALLENGE PROB
   [Anonymous], 2008, CVPR, DOI DOI 10.1109/CVPR.2008.4587754
   [Anonymous], 2009, BRIT MACH VIS C BMVC
   Arashloo SR, 2011, IEEE T PATTERN ANAL, V33, P1274, DOI 10.1109/TPAMI.2010.209
   Asthana A, 2011, IEEE I CONF COMP VIS, P937, DOI 10.1109/ICCV.2011.6126336
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Chai XJ, 2007, IEEE T IMAGE PROCESS, V16, P1716, DOI 10.1109/TIP.2007.899195
   Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389
   Gao Y, 2014, 2014 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING (ICALIP), VOLS 1-2, P277, DOI 10.1109/ICALIP.2014.7009800
   Gao Y, 2015, PATTERN RECOGN LETT, V65, P170, DOI 10.1016/j.patrec.2015.07.018
   Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2
   Hua G, 2011, IEEE T PATTERN ANAL, V33, P1921, DOI 10.1109/TPAMI.2011.182
   Ho HT, 2013, IEEE T IMAGE PROCESS, V22, P1571, DOI 10.1109/TIP.2012.2233489
   Jiang YY, 2015, NEUROCOMPUTING, V165, P190, DOI 10.1016/j.neucom.2015.03.009
   Li AN, 2012, IEEE T IMAGE PROCESS, V21, P305, DOI 10.1109/TIP.2011.2160957
   Li SX, 2012, LECT NOTES COMPUT SC, V7572, P102, DOI 10.1007/978-3-642-33718-5_8
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolaczyk K, INTERNATIONAL
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730
   Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Prince SJD, 2008, IEEE T PATTERN ANAL, V30, P970, DOI 10.1109/TPAMI.2008.48
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhang YZ, 2013, IEEE I CONF COMP VIS, P2416, DOI 10.1109/ICCV.2013.300
   Zhu ZY, 2013, IEEE I CONF COMP VIS, P113, DOI 10.1109/ICCV.2013.21
NR 31
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1927
EP 1942
DI 10.1007/s11042-017-4359-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400021
DA 2024-07-18
ER

PT J
AU Nam, S
   Kim, Y
   Lim, Y
AF Nam, SangHun
   Kim, YoungEun
   Lim, YangMi
TI Materialization of interactive stereoscopic artwork based on
   hand-painted images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereoscopic art; Interactive art; Hand painting
AB This paper presents interactive stereoscopic artwork and an algorithm for natural artistic expression using hand-painted images expressed by the artist's manual brush strokes. The system proposes a new interactive method that allows a viewer to experience the painting process representing the consecutive process of an actual artist's oil painting. The combination of analog and digital techniques stimulates emotions of the audience. The system architecture is composed of the Kinect sensor, which recognizes the movement of the user, a module that generates real-time stereoscopic images, and a projection module that displays the generated image. The survey is conducted to evaluate the effects of the 3D modeling method and the artistic modeling method. The statistical result show that the proposed hand-painted method provides more artistic satisfaction to the viewers than the 3D modeling method.
C1 [Nam, SangHun] KIST, Ctr Human Ctr Interact Coexistence, L8325, Seoul 136791, South Korea.
   [Kim, YoungEun; Lim, YangMi] Duksung Womens Univ, Sch Digital Media, Seoul 132714, South Korea.
C3 Korea Institute of Science & Technology (KIST); Duksung Women's
   University
RP Lim, Y (corresponding author), Duksung Womens Univ, Sch Digital Media, Seoul 132714, South Korea.
EM sanghunnam@gmail.com; naankim@gmail.com; yosimi@duksung.ac.kr
RI Nam, SangHun/GZM-9726-2022
CR [Anonymous], 2012, P INT S NONPH AN REN
   Benko Hrvoje., 2012, P SIGCHI C HUMAN FAC, P199, DOI DOI 10.1145/2207676.2207704
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   Durand F., 2002, NPAR '02: Proceedings of the 2nd international symposium on Non-photorealistic animation and rendering, P111
   Grau O, 2003, LEONARDO SER, P1
   Kim Y, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462001
   Park Y, 2004, KOREA MULTIMEDIA SOC, V8, P76
   Rademacher P, 1999, COMP GRAPH, P439, DOI 10.1145/311535.311612
   Richardt C, 2010, NONPH AN REND
   Stavrakis E, 2005, PROC SPIE, V5664, P450, DOI 10.1117/12.586702
   Stavrakis E, 2005, IMAGE PROCESSING 200, pIII
   Stavrakis E, 2008, STEREOSCOPIC NONPHOT
   Stavrakis Efstathios, 2004, P EUR C REND TECHN, P53
   Tokunaga DM, 2010, ACM SIGGRAPH 2010, P131
   Zhang Cha., 2014, Computer Vision and Machine Learning with RGB-D Sensors, P47
NR 15
TC 3
Z9 3
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 149
EP 163
DI 10.1007/s11042-016-4235-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400007
DA 2024-07-18
ER

PT J
AU Serrano-Laguna, A
   Manero, B
   Freire, M
   Fernández-Manjón, B
AF Serrano-Laguna, Angel
   Manero, Borja
   Freire, Manuel
   Fernandez-Manjon, Baltasar
TI A methodology for assessing the effectiveness of serious games and for
   inferring player learning outcomes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Serious games; Learning analytics; Game design; Learning outcomes
   analysis; Educational games
ID DESIGN; ANALYTICS; FRAMEWORK; STUDENTS; MODEL
AB Although serious games are proven to serve as educational tools in many educational domains, there is a lack of reliable, automated and repeatable methodologies that measure their effectiveness: what do players know after playing serious games? Do they learn from them? Previous research shows that the vast majority of serious games are assessed by using questionnaires, which is in stark contrast to current trends in the video game industry. Commercial videogame developers have been learning from their players through Game Analytics for years via non-disruptive game tracking. In this paper, we propose a methodology for assessing serious game effectiveness based on non-disruptive in-game tracking. The methodology involves a design pattern that structures the delivery of educational goals through a game. This structure also allows one to infer learning outcomes for each individual player, which, when aggregated, determine the effectiveness of a serious game. We tested the methodology by having 320 students play a serious game. The proposed methodology allowed us to infer players' learning outcomes, to assess the game effectiveness levels and to identify issues in the game design.
C1 [Serrano-Laguna, Angel; Manero, Borja; Freire, Manuel; Fernandez-Manjon, Baltasar] Univ Complutense Madrid, Fac Informat, Dept Software Engn & Artificial Intelligence, C Prof Jose Garcia Santesmases S-N, E-28040 Madrid, Spain.
C3 Complutense University of Madrid
RP Serrano-Laguna, A (corresponding author), Univ Complutense Madrid, Fac Informat, Dept Software Engn & Artificial Intelligence, C Prof Jose Garcia Santesmases S-N, E-28040 Madrid, Spain.
EM angel.serrano@fdi.ucm.es
RI Fernandez-Manjon, Baltasar/A-5281-2011; Moreno-Ger, Pablo/B-5419-2009;
   Freire, Manuel/I-7942-2017
OI Freire, Manuel/0000-0003-4596-3823
FU Ministry of Education, Culture and Sport of Spain through FPU Programme
   [FPU12/04310]; Regional Government of Madrid [eMadrid S2013/ICE-2715];
   Complutense University of Madrid [GR3/14-921340]; Ministry of Education
   [TIN2013-46149-C2-1-R]; RIURE Network [CYTED 513RT0471]; European
   Commission [RAGE H2020-ICT-2014-1-644187, BEACONING
   H2020-ICT-2015-687676]
FX This research study was partially financed by the Ministry of Education,
   Culture and Sport of Spain through its FPU Programme (grant
   FPU12/04310), by the Regional Government of Madrid (eMadrid
   S2013/ICE-2715), by the Complutense University of Madrid
   (GR3/14-921340), by the Ministry of Education (TIN2013-46149-C2-1-R), by
   the RIURE Network (CYTED 513RT0471) and by the European Commission (RAGE
   H2020-ICT-2014-1-644187, BEACONING H2020-ICT-2015-687676).
CR All A, 2016, COMPUT EDUC, V92-93, P90, DOI 10.1016/j.compedu.2015.10.007
   All A, 2015, COMPUT EDUC, V88, P29, DOI 10.1016/j.compedu.2015.04.012
   Annetta LA, 2010, REV GEN PSYCHOL, V14, P105, DOI 10.1037/a0018985
   [Anonymous], 2012, P 2012 IEEE GLOB ENG
   [Anonymous], 2007, Journal of Applied Educational Technology
   Arnab S, 2015, BRIT J EDUC TECHNOL, V46, P391, DOI 10.1111/bjet.12113
   Calderón A, 2015, COMPUT EDUC, V87, P396, DOI 10.1016/j.compedu.2015.07.011
   Carvalho MB, 2015, COMPUT EDUC, V87, P166, DOI 10.1016/j.compedu.2015.03.023
   Chatti MA, 2012, INT J TECHNOL ENHANC, V4, P318, DOI 10.1504/IJTEL.2012.051815
   Chen J, 2007, COMMUN ACM, V50, P31, DOI 10.1145/1232743.1232769
   Comunidad de madrid, 2011, DAT CIFR ED
   Connolly TM, 2012, COMPUT EDUC, V59, P661, DOI 10.1016/j.compedu.2012.03.004
   Denis G., 2005, Proceedings of the 2005 ACM SIGCHI International Conference on Advances in computer entertainment technology, P462, DOI DOI 10.1145/1178477.1178581
   Dickey MD, 2007, ETR&D-EDUC TECH RES, V55, P253, DOI 10.1007/s11423-006-9004-7
   Dickey MD, 2006, ETR&D-EDUC TECH RES, V54, P245, DOI 10.1007/s11423-006-8806-y
   Dudzinski M, 2013, PROC EUR CONF GAME, P140
   El-nasr MS., 2013, Game Analytics, DOI [DOI 10.1007/978-1-4471-4769-5, 10.1007/978-1-4471-4769-5]
   Elias T, 2011, LEARNING, V23
   Ferguson R, 2012, INT J TECHNOL ENHANC, V4, P304, DOI 10.1504/IJTEL.2012.051816
   FUCHS LS, 1986, EXCEPT CHILDREN, V53, P199, DOI 10.1177/001440298605300301
   Hauge JB, 2014, IEEE INT CONF ADV LE, P230, DOI 10.1109/ICALT.2014.73
   Hollins P., 2015, AMPLIFYING APPL GAME
   Kiili K., 2005, Internet and Higher Education, V8, P13, DOI 10.1016/j.iheduc.2004.12.001
   Kiili K, 2007, ITI, P357
   Lee S.J., 2014, P 7 INT C ED DATA MI, P114
   Liu GM, 2011, LANGMUIR, V27, P2595, DOI 10.1021/la104669k
   Loh C. S., 2015, Serious Games Analytics: Methodologies for Performance Measurement, Assessment, and Improvement, P3, DOI [DOI 10.1007/978-3-319-05834-41, DOI 10.1007/978-3-319-05834-4, 10.1007/978-3-319-05834-4_1, DOI 10.1007/978-3-319-05834-4_1]
   Manero B, 2015, IEEE T LEAR IN PRESS
   Manero B., 2013, IEEE RITA, V1, P51
   Manero B, 2015, COMPUT EDUC, V87, P182, DOI 10.1016/j.compedu.2015.06.006
   Marne B, 2012, LECT NOTES COMPUT SC, V7563, P208, DOI 10.1007/978-3-642-33263-0_17
   Ministerio de Educacion, 2008, ESC POBL
   Moreno-Ger P, 2008, COMPUT HUM BEHAV, V24, P2530, DOI 10.1016/j.chb.2008.03.012
   Nutt Christian., 2012, Gamasutra
   Owen VElizabeth., 2014, American Educational Research Association Annual Meeting, P1
   Pallant J., 2016, SPSS Survival Guide, V6th, DOI https://doi.org/10.4324/97810031117452
   Santhosh S., 2013, GAMES ANAL MAXIMIZIN, P85, DOI 10.1007/978-1-4471-4769-5_6
   Serrano-Laguna A, 2012, PROCEDIA COMPUT SCI, V15, P203, DOI 10.1016/j.procs.2012.10.072
   Squire K., 2003, INT J INTELLIGENT SI, V2, P49, DOI DOI 10.1145/950566.950583
   Vargas JA., 2014, Proceedings, 18th International Conference on Evaluation and Assessment in Software Engineering (EASE'14), P1, DOI DOI 10.1145/2601248.2601261
   Ye F., 2014, Validity, reliability, and concordance of the Duolingo English
NR 41
TC 26
Z9 29
U1 0
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2849
EP 2871
DI 10.1007/s11042-017-4467-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400058
OA Green Accepted, Green Submitted
DA 2024-07-18
ER

PT J
AU Stai, E
   Kafetzoglou, S
   Tsiropoulou, EE
   Papavassiliou, S
AF Stai, Eleni
   Kafetzoglou, Stella
   Tsiropoulou, Eirini Eleni
   Papavassiliou, Symeon
TI A holistic approach for personalization, relevance feedback &
   recommendation in enriched multimedia content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender systems; Personalization; User profiling; Relevance
   feedback; Enriched multimedia content
ID SYSTEMS
AB As the prerequisites of production houses, broadcasters, advertising agencies and online publishing companies for enriched multimedia content increase rapidly, the need of innovative methods for the effective creation of enriched multimedia content is undeniable. Stemming from this need, in this paper we focus on the design, development and evaluation of a framework consisting of personalization, relevance feedback and recommendation mechanisms, as a principal method for the creation of enriched multimedia content targeted to each user's needs, preferences and interests. As the multimedia content proliferates along with its consumption by the users, more effective ways of presenting it to the viewers are demanded in order to facilitate them with the multimedia content search and selection and improve their Quality of Experience (QoE). The main contribution of the paper is the introduction of a holistic framework that offers personalized enriched multimedia content, by extending the recommendation process to the set of enrichments that accompany the video except from the video itself and by collecting explicit and implicit relevance feedback from the interactions of the user with both the video and its enrichments. We evaluate the proposed framework following a two-step approach. Firstly, we perform extended experiments by applying reasonably simulated user interactions, in order to calibrate its parameters that refer to multiple aspects of the enriched multimedia content, aiming at high performance in terms of QoE. Here, most importantly, we have shown that appropriately designing the enrichments and considering users' interactions with them allows for achieving a better quality in inferring users' profiles in many realistic cases. Secondly, we integrated our proposed recommender framework within the MECANEX streaming platform in order to perform user studies about its usability within a realistic environment of use.
C1 [Stai, Eleni; Kafetzoglou, Stella; Tsiropoulou, Eirini Eleni; Papavassiliou, Symeon] NTUA, ICCS, Athens 15780, Zografou, Greece.
C3 National Technical University of Athens
RP Stai, E (corresponding author), NTUA, ICCS, Athens 15780, Zografou, Greece.
EM estai@netmode.ntua.gr
RI Stai, Eleni/AAA-3296-2019; Tsiropoulou, Eirini Eleni/Y-6859-2019
OI Tsiropoulou, Eirini Eleni/0000-0003-1322-1876; Stai,
   Eleni/0000-0003-2283-3479
FU European Commission [645206 - MECANEX]
FX This work was partially supported by the European Commission, Horizon
   2020 Framework Programme for research and innovation under grant
   agreement no 645206 - MECANEX. The authors wish to thank their MECANEX
   collaborators that greatly contributed to this work with their ideas and
   support. Notably we appreciated the help of: Daniel Ockeloen and Pieter
   van Leeuwen (Noterik B. V.Holland, Netherlands) for their work in the
   integrated streaming platform, Miggi Zwicklbauer and Louay Bassbouss
   (FRAUNHOFER - Gesellschaft Zur Foerderung Der Angewandten Forschung E.V.
   Germany) for the implementation of the content enrichment component and
   Marco Rendina (Instituto Luce Cinecitta) for the provision of multimedia
   content.
CR [Anonymous], 2013, INTRO INFORM RETRIEV
   [Anonymous], 1983, INTRO MODERN INFORM
   Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124
   Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012
   Cha S.-H., 2007, Int. J. Math. Models Methods Appl. Sci., V1, P300
   Gauch S., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P54
   Gentili G, 2003, APPL ARTIFICIAL INTE, V17
   Hanani U, 2001, USER MODEL USER-ADAP, V11, P203, DOI 10.1023/A:1011196000674
   Hopfgartner F, 2007, EVALUATING IMPLICIT
   Kobsa A, 2001, J USER MODELING USER
   Manning CD, 2012, INTRO INFORM RETRIEV, P100
   Micarelli A, 2004, USER MODEL USER-ADAP, V14, P159, DOI 10.1023/B:USER.0000028981.43614.94
   Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943
   Pazzani MJ, 1999, ARTIF INTELL REV, V13, P393, DOI 10.1023/A:1006544522159
   Porcel C, 2012, INFORM SCIENCES, V184, P1, DOI 10.1016/j.ins.2011.08.026
   Rokach L, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P321, DOI 10.1007/0-387-25465-X_15
   Schafer B, 2007, COLLABORATIVE FILTER, P291
   Shani G, 2009, MSRTR2009159
   Tsiropoulou EE, 2015, IEEE STCSN E LETT IM, V3
   Van Meteren Robin, 2000, P MACH LEARN NEW INF, P47
NR 20
TC 56
Z9 59
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 283
EP 326
DI 10.1007/s11042-016-4209-1
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400013
DA 2024-07-18
ER

PT J
AU Chen, CC
   Wang, H
   Lin, CS
AF Chen, Chien-Chang
   Wang, Han
   Lin, Cheng-Shian
TI An efficiency enhanced cluster expanding block algorithm for copy-move
   forgery detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Forgery duplication; Invariant moment; Mean; Variance; Clustering
AB The proposed scheme detects the copy-move forgery detection regions through the invariant features extracted from each block. First, an image is divided into overlapping blocks, and seven invariant moments of the maximum circle area in each block are calculated as moment features. Two clustering features, denoted by mean and variance of these seven moment features, are acquired for block comparison to reduce computation time. Therefore, the proposed scheme takes limited computation time because the seven moment features in each block are only compared to other blocks under the intersection of closed mean and variance features. The copy-move forgery regions can be found by matching the detected blocks with relative distance calculation. Experimental results show that the adopted moment features are efficient for detecting rotational or flipped duplicated regions.
C1 [Chen, Chien-Chang; Wang, Han] Tamkang Univ, Dept Comp Sci & Informat Engn, 151 Yingzhuan Rd, New Taipei 25137, Taiwan.
   [Lin, Cheng-Shian] CTBC Financial Management Coll, Dept Business Adm, Tainan, Taiwan.
C3 Tamkang University; CTBC Financial Holding
RP Chen, CC (corresponding author), Tamkang Univ, Dept Comp Sci & Informat Engn, 151 Yingzhuan Rd, New Taipei 25137, Taiwan.
EM ccchen34@mail.tku.edu.tw
RI Chen, Chien-Chang/P-3956-2017
OI Chen, Chien-Chang/0000-0001-6974-2422
CR Al-Qershi OM, 2013, FORENSIC SCI INT, V231, P284, DOI 10.1016/j.forsciint.2013.05.027
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Bi XL, 2016, INFORM SCIENCES, V345, P226, DOI 10.1016/j.ins.2016.01.061
   Bravo-Solorio S, 2011, SIGNAL PROCESS, V91, P1759, DOI 10.1016/j.sigpro.2011.01.022
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Chen CC, 2017, MULTIMED TOOLS APPL, V76, P8497, DOI 10.1007/s11042-016-3452-9
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cox IJ., 2007, DIGITAL WATERMARKING
   Davarzani R, 2013, FORENSIC SCI INT, V231, P61, DOI 10.1016/j.forsciint.2013.04.023
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Hsu CC, 2007, P 6 WSEAS INT C ART, P170
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Kobayashi M, 2010, IEEE T INF FOREN SEC, V5, P883, DOI 10.1109/TIFS.2010.2074194
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Liao SY, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P864, DOI 10.1109/CISP.2013.6745286
   Lin CS, 2014, DIGIT INVEST, V11, P120, DOI 10.1016/j.diin.2014.03.016
   Lin CS, 2015, IEEE INT C INT NETW
   Lynch G, 2013, INFORM SCIENCES, V239, P253, DOI 10.1016/j.ins.2013.03.028
   Muhammad G, DIGIT INVESTIG, V9, P49
   Popescu A.C., 2004, Exposing digital forgeries by detecting duplicated image regions
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Subramanyam AV, 2013, INT CONF ACOUST SPEE, P3038, DOI 10.1109/ICASSP.2013.6638216
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Tu HK, 2015, IEEE INT C ADV TECHN
   Zhao J, 2013, FORENSIC SCI INT, V233, P158, DOI 10.1016/j.forsciint.2013.09.013
NR 28
TC 6
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26503
EP 26522
DI 10.1007/s11042-016-4179-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500044
DA 2024-07-18
ER

PT J
AU Wang, XB
   Song, YH
   Zhang, YL
   Xin, JM
AF Wang, Xiaobing
   Song, Yonghong
   Zhang, Yuanlin
   Xin, Jingmin
TI A hierarchical recursive method for text detection in natural scene
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene text detection; Hierarchical recursive architecture; Hierarchical
   random field; Text edge box
ID OBJECT DETECTION; SEGMENTATION
AB Text detection in natural scene images is a challenging problem in computer vision. To robust detect various texts in complex scenes, a hierarchical recursive text detection method is proposed in this paper. Usually, texts in natural scenes are not alone and arranged into lines for easy reading. To find all possible text lines in an image, candidate text lines are obtained using text edge box and conventional neural network at first. Then, to accurately find out the true text lines in the image, these candidate text lines are analyzed in a hierarchical recursive architecture. For each of them, connected components segmentation and hierarchical random field based analysis are recursively employed until the detected text line no more changes. Now the detected text lines are output as the text detection result. Experiments on ICDAR 2003 dataset, ICDAR 2013 dataset and Street View Dataset show that the hierarchical recursive architecture can improve text detection performance and the proposed method achieves the state-of-art in scene text detection.
C1 [Wang, Xiaobing; Song, Yonghong; Zhang, Yuanlin; Xin, Jingmin] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Song, YH (corresponding author), Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Peoples R China.
EM wxbxj@stu.xjtu.edu.cn; songyh@mail.xjtu.edu.cn;
   ylzhangxian@mail.xjtu.edu.cn; jxin@mail.xjtu.edu.cn
RI Zhang, Yuanlin/AAO-7260-2020; Song, YongHong/AEL-0628-2022
OI Zhang, Yuanlin/0000-0003-0960-3636; 
FU National Natural Science Foundation of China [91520301]
FX This work is supported by the National Natural Science Foundation of
   China (91520301).
CR Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen XR, 2004, PROC CVPR IEEE, P366
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0
   Ladicky L, 2014, IEEE T PATTERN ANAL, V36, P1056, DOI 10.1109/TPAMI.2013.165
   Lucas SM, 2003, PROC INT CONF DOC, P682
   Mariano VY, 2002, INT C PATT RECOG, P965, DOI 10.1109/ICPR.2002.1048198
   Minetto R, 2013, PATTERN RECOGN, V46, P1078, DOI 10.1016/j.patcog.2012.10.009
   Neumann L, 2015, IEEE C COMP VIS PATT
   Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097
   Neumann L, 2011, PROC INT CONF DOC, P687, DOI 10.1109/ICDAR.2011.144
   Opitz M, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P186, DOI 10.1109/DAS.2014.29
   Pan YF, 2011, IEEE T IMAGE PROCESS, V20, P800, DOI 10.1109/TIP.2010.2070803
   Phan T.Q., 2012, Proceedings of ACM MM'12, ACM, P765
   Redondo-Cabrera C, 2012, PROC CVPR IEEE, P3458, DOI 10.1109/CVPR.2012.6248087
   Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wang S, 2012, PROC CVPR IEEE, P1370, DOI 10.1109/CVPR.2012.6247823
   Wang T, 2012, INT C PATT RECOG, P3304
   Wang XB, 2015, PATTERN RECOGN LETT, V60-61, P41, DOI 10.1016/j.patrec.2015.04.005
   Wang XB, 2013, PROC INT CONF DOC, P1375, DOI 10.1109/ICDAR.2013.278
   Wolf C, 2006, INT J DOC ANAL RECOG, V8, P280, DOI 10.1007/s10032-006-0014-0
   Yang Y, 2013, IEEE I CONF COMP VIS, P2104, DOI 10.1109/ICCV.2013.456
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182
   Yu C, 2016, NEUROCOMPUTING, V175, P652, DOI 10.1016/j.neucom.2015.10.105
   Yuan J, 2015, MULTIMED TOOLS APPL, V74, P859, DOI 10.1007/s11042-013-1702-7
   Zhu KH, 2007, J ZHEJIANG UNIV-SC A, V8, P63, DOI 10.1631/jzus.2007.A0063
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 35
TC 5
Z9 5
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26201
EP 26223
DI 10.1007/s11042-016-4099-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500032
DA 2024-07-18
ER

PT J
AU Alsaedi, M
AF Alsaedi, Mohammed
TI Colored image encryption and decryption using multi-chaos 2D quadratic
   strange attractors and matrix transformations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gould transform; Arnold's cat map; Quadratic maps; Encryption;
   Decryption; Strange attractors; Chaos
AB Data security is an increasingly important issue. In this paper, a scheme to encrypt and decrypt colored images is presented in which two random secret keywords are used as parameters for quadratic maps with strange attractors. The scheme uses the well-known chaotic trait of sensitivity to initial conditions to ensure that the receiver generates the same sequences. After forming the quadratic maps and zeros removal from both maps, three codebooks are formed one from the original image and two from the two images of the quadratic maps. The input colored image is decomposed into three components and quantized using two of the three codebooks. The resulting image is subjected to partial extended Arnold's transform then to Gould transformation to hide image traces. The partial extended Arnold's matrix which is subjected to a determinant condition is studied for possible number of rotations for specific sizes of sub-blocks taken from a random image and then the results are used for encryption and decryption of different colored images. Then, the pixels of the components are shifted cyclically with a predefined number of shifts and quantized using the third codebook with maximum MSE. The results from the statistical analysis show that the pixels correlation is very low and the ciphered image is well shuffled. Also, the decrypted images have high PSNR at the receiver. Furthermore, compariosns with other schemes in the literature show that the performance of the proposed algorithm is high.
C1 [Alsaedi, Mohammed] Taibah Univ, Dept Comp Engn, Coll Comp Sci & Engn, POB 344, Medina 41411, Westren Region, Saudi Arabia.
C3 Taibah University
RP Alsaedi, M (corresponding author), Taibah Univ, Dept Comp Engn, Coll Comp Sci & Engn, POB 344, Medina 41411, Westren Region, Saudi Arabia.
EM msaiedy@gmail.com
CR Al-Shameri W.F. H., 2012, Int. J. Contemp. Math. Sciences, V7, P413
   Athanassios S., 2013, C SIGN PROC CIWSP 20, DOI [10.1049/ic.2013.0003, DOI 10.1049/IC.2013.0003]
   Biham E, 1993, DIFFERENTIAL CRYPTAN, V28
   Cheung G, 2011, IEEE IMAGE PROC, P129, DOI 10.1109/ICIP.2011.6115673
   Cusick TW, 1999, ELECTRON LETT, V35, P468, DOI 10.1049/el:19990336
   El-din H, 2007, INT J INF TECHNOL, V3, P245
   Feng Huang, 2011, Journal of Multimedia, V6, P510, DOI 10.4304/jmm.6.6.510-517
   Gupta P, 2014, IJARCSSE, V4, P807
   Hoang ML, 2006, P SOC PHOTO-OPT INS, V6064
   Huang XL, 2015, SECUR COMMUN NETW, V8, P3659, DOI 10.1002/sec.1289
   Keshari Sudhir, 2011, INT J COMPUTER SCI E, V2, P132
   Mishra Minati, 2012, ADV INTELLIGENT SOFT, V167/2012, P221
   Pisarchik AN, 2008, PHYSICA D, V237, P2638, DOI 10.1016/j.physd.2008.03.049
   Praveenkumar P, 2015, SECUR COMMUN NETW, V8, P3335, DOI 10.1002/sec.1257
   Som S, 2015, NONLINEAR DYNAM, V80, P615, DOI 10.1007/s11071-015-1893-8
   Tian-Gong P, 2013, INT J SECUR APPL, V7, P377, DOI 10.14257/ijsia.2013.7.5.34
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Ye GD, 2016, NONLINEAR DYNAM, V83, P2067, DOI 10.1007/s11071-015-2465-7
   Zhai TY, 2005, P AMER CONTR CONF, P4034, DOI 10.1109/ACC.2005.1470608
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
   Zhu H, 2012, NEW CHAOS BASED IMAG
   Zhu L, 2006, P 2006 INT C INT INF
NR 24
TC 9
Z9 9
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24527
EP 24547
DI 10.1007/s11042-016-4206-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700063
DA 2024-07-18
ER

PT J
AU Zeng, Y
   Wang, S
   Zhao, TZ
   Wang, J
AF Zeng, Yi
   Wang, Shuang
   Zhao, Tianzhong
   Wang, Jing
TI An application of tree species classification using high-resolution
   remote sensing image based on the rough set theory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rough set theory; Feature extraction; Object-oriented classification;
   Tree species recognition; Forest monitoring
ID DIMENSIONALITY; REDUCTION; RULES
AB Feature extraction is an essential task in the classification of high-resolution remote sensing images, with the primary technique being the object-oriented classification method. Current research describes object-oriented classification methods by using remote sensing data, wherein how to reduce the redundant feature information to achieve good classification results is the most challenging problem. The high-resolution remote sensing image is characteristic of a large amount of data and high feature dimensions, which also exist particularly in the forestry remote sensing. Feature information redundancy can reduce the extraction accuracy and make the classification results worse. To address this problem, in this paper we propose a framework that uses the rough set theory and the membership function to establish the classification rule set. In our approach, we first select an optimal segmentation scale to segment the remote sensing image with multi-scale and apply the rough set theory to reduce the feature dimensions of objects. We then use the selected features to establish classification rule set and classify image objects. This paper also presents a detailed study of the proposed framework for species classification with ALOS images, wherein 13 most effective feature parameters are selected from 34 feature parameters of objects, such as band ratio, brightness value, and average gray value. Our experimental results demonstrate that the proposed framework, applied to classify tree species, achieves a classification accuracy of 80.4509%, which is an improvement over both the classification accuracy of 77.2408% achieved with the traditional supervised classification and that of 75.5068% achieved with the nearest neighbor classification. The research proves that the proposed framework can effectively take advantage of tree species information in remote sensing images, and provides an auxiliary means for forest resources investigation and monitoring.
C1 [Zeng, Yi; Wang, Shuang; Zhao, Tianzhong] Beijing Forestry Univ, Coll Informat Sci, Beijing 100083, Peoples R China.
   [Wang, Jing] Chinese Acad Sci, Inst Geog Sci & Nat Resources Res, State Key Lab Resource & Environm Informat Syst, Beijing, Peoples R China.
C3 Beijing Forestry University; Chinese Academy of Sciences; Institute of
   Geographic Sciences & Natural Resources Research, CAS
RP Zeng, Y (corresponding author), Beijing Forestry Univ, Coll Informat Sci, Beijing 100083, Peoples R China.
EM zengyi@bjfu.edu.cn
RI zeng, yi/KFS-5661-2024
OI Wang, Shuang/0000-0002-1586-5117
FU Beijing Natural Science Foundation [6164038]; China Fundamental Research
   Funds for the Central Universities [TD2014-2]
FX This work was Supported by Beijing Natural Science Foundation (NO.
   6164038) and China Fundamental Research Funds for the Central
   Universities (NO. TD2014-2). The authors would like to express their
   gratitude to the funds for the financial support.
CR Brauner N, 2000, COMPUT CHEM ENG, V24, P2603, DOI 10.1016/S0098-1354(00)00616-5
   Bruzzone L, 2006, IEEE T GEOSCI REMOTE, V44, P2587, DOI 10.1109/TGRS.2006.875360
   [曹雪 CAO Xue], 2006, [遥感信息, Remote Sensing Information], P27
   Chen YH, 2006, GEOMATICS INF SCI WU
   Chen ZQ, 2013, J JILIN U, V43, P209
   Dash M., 1997, Intelligent Data Analysis, V1
   [郭亚鸽 Guo Yage], 2012, [地球信息科学学报, Journal of Geo-Information Science], V14, P514
   Hu QT, 2008, J JIANGXI BLUE SKY U, V11, P336
   Huang L, 2011, REMOTE SENS INFO, V39, P37
   Huang QY, 2012, RS IMAGE CLASSIFICAT
   Law MHC, 2006, IEEE T PATTERN ANAL, V28, P377, DOI 10.1109/TPAMI.2006.56
   Leung Y, 2007, INT J GEOGR INF SCI, V21, P1033, DOI 10.1080/13658810601169915
   Li HM, 2007, COMPUT APPL, V8, P76
   [李敏 LI Min], 2008, [遥感信息, Remote Sensing Information], P63
   Licciardi GA, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-207
   [林川 Lin Chuan], 2010, [生态学报, Acta Ecologica Sinica], V30, P6460
   Liu P., 2016, SOFT COMPUT, P1
   Ma Y, 2015, FUTURE GENER COMP SY, V51, P47, DOI 10.1016/j.future.2014.10.029
   Mu HJ, 2006, COMPUT ENG APPL
   Myint SW, 2004, PHOTOGRAMM ENG REM S, V70, P803, DOI 10.14358/PERS.70.7.803
   Nie Q, 2012, CLASSIFICATION HIGH
   PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956
   Susmaga R, 2000, CONTROL CYBERN, V29, P969
   Tang TQ, 2015, RES VEGETATION INFOR
   Tian X. G., 2007, HYDROGRAPHIC SURVEYI, V27, P41
   van der Maaten L., 2007, IEEE T PATTERN ANAL, V10, P1
   Wang L, 2016, FUTUR GENER COMPUT S
   Wang L., 2016, Soft Computing, P1
   Wang LZ, 2016, CLUSTER COMPUT, V19, P793, DOI 10.1007/s10586-016-0569-6
   Wang QL, 2008, STUDY OBJECT ORIENTE
   Xiao HG, 2006, COMPUT ENG APPL
   Zhang ZC, 2007, WETLAND RES REMOTE S
   Zhang ZY, 2012, IEEE T PATTERN ANAL, V34, P253, DOI 10.1109/TPAMI.2011.115
   [周林飞 Zhou Linfei], 2015, [吉林大学学报. 地球科学版, Journal of Jilin University. Earth Science Edition], V45, P1246
   Zhu Zheniian, 2010, STUDY MINE AREA INFO
NR 35
TC 4
Z9 4
U1 0
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22999
EP 23015
DI 10.1007/s11042-016-4210-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200057
DA 2024-07-18
ER

PT J
AU Benrhouma, O
   Hermassi, H
   Belghith, S
AF Benrhouma, Oussama
   Hermassi, Houcemeddine
   Belghith, Safya
TI Security analysis and improvement of an active watermarking system for
   image tampering detection using a self-recovery scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SVD; Tamper localization; Self-recovery; Attack; Improvement;
   Watermarking
ID FRAGILE WATERMARKING; RESTORATION CAPABILITY; AUTHENTICATION;
   CRYPTANALYSIS; PROTECTION
AB This paper analyses the security of an effective SVD-based image tampering detection and self-recovery scheme that has been recently proposed by S. Dadkhah et al. Some errors in the embedding/extraction processes are underlined and an attack against this scheme is demonstrated. The theoretical and experimental results show that the proposed scheme is not secure. Finally, an improvement of the scheme is proposed to enhance its security.
C1 [Benrhouma, Oussama; Hermassi, Houcemeddine; Belghith, Safya] Univ Tunis ElManar, Ecole Natl Ingenieurs Tunis, RISC Lab, Bnikhiar, Tunisia.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT)
RP Hermassi, H (corresponding author), Univ Tunis ElManar, Ecole Natl Ingenieurs Tunis, RISC Lab, Bnikhiar, Tunisia.
EM houcemeddine.hermassi@enit.rnu.tn
RI Benrhouma, Oussama/ABE-2730-2020; hermassi, houcemeddine/ADK-4317-2022;
   Benrhouma, Oussama/JCD-7434-2023; Hermassi, Houcemeddine/J-2352-2012
OI Hermassi, houcemeddine/0000-0002-4681-4312; Benrhouma,
   Oussama/0000-0002-4540-3650; Belghith, Safya/0000-0001-7408-7848
CR [Anonymous], 1883, J SCI MILITAIRES
   Arnold V, 1968, ERGODIC PROBLEMS CLA, P564
   Aslantas V, 2009, OPT COMMUN, V282, P2806, DOI 10.1016/j.optcom.2009.04.034
   Bao JH, 2012, NONLINEAR DYNAM, V70, P1365, DOI 10.1007/s11071-012-0539-3
   Benrhouma O, 2015, MULTIMED TOOLS APPL, P1
   Benrhouma O, 2015, NONLINEAR DYNAM, V79, P1817, DOI 10.1007/s11071-014-1777-3
   Bhatnagar G, 2011, MULTIMED TOOLS APPL, V52, P621, DOI 10.1007/s11042-009-0433-2
   Botta M, 2015, AEU-INT J ELECTRON C, V69, P242, DOI 10.1016/j.aeue.2014.09.004
   Chang CC, 2006, PATTERN RECOGN LETT, V27, P439, DOI 10.1016/j.patrec.2005.09.006
   Dadkhah S, 2014, SIGNAL PROCESS-IMAGE, V29, P1197, DOI 10.1016/j.image.2014.09.001
   DYSON FJ, 1992, AM MATH MON, V99, P603, DOI 10.2307/2324989
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li M, 2014, OPTIK, V125, P7231, DOI 10.1016/j.ijleo.2014.07.130
   Peterson G, 1997, ARNOLDS CAT MAP
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Teng L, 2013, AEU-INT J ELECTRON C, V67, P540, DOI 10.1016/j.aeue.2012.12.001
   Wang XF, 2015, IEEE T INF FOREN SEC, V10, P1336, DOI 10.1109/TIFS.2015.2407698
   Wu XY, 2007, PHYS LETT A, V365, P403, DOI 10.1016/j.physleta.2007.01.034
   Zhang XP, 2008, IEEE T MULTIMEDIA, V10, P1490, DOI 10.1109/TMM.2008.2007334
NR 23
TC 11
Z9 12
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21133
EP 21156
DI 10.1007/s11042-016-4054-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400036
DA 2024-07-18
ER

PT J
AU Charfi, N
   Trichili, H
   Alimi, AM
   Solaiman, B
AF Charfi, Nesrine
   Trichili, Hanene
   Alimi, Adel M.
   Solaiman, Basel
TI Bimodal biometric system for hand shape and palmprint recognition based
   on SIFT sparse representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand shape features; Palmprint features; SIFT sparse representation;
   Fusion
ID VERIFICATION; IDENTIFICATION
AB Biometric-based hand modality is considered as one of the most popular biometric technologies especially in forensic applications. In this paper, a bimodal hand identification system was proposed based on Scale Invariant Feature Transform (SIFT) descriptors, extracted from hand shape and palmprint modalities. A local sparse representation method was adopted in order to represent images with high discrimination. Moreover, fusion was performed at feature and decision levels using a cascade fusion in order to generate the final identification rate of our bimodal system. Our experiments were applied on two hand databases: Indian Institute of Technology of Delhi (IITD) hand database and Bosphorus hand database containing, respectively, 230 and 615 subjects. The results show that the proposed method offers high accuracies compared to other popular bimodal hand biometric methods over the two hand databases. The correct identification rate reaches 99.57 % which is competitive compared to systems existing in the literature.
C1 [Charfi, Nesrine; Trichili, Hanene; Alimi, Adel M.] ENIS, REs Grp Intelligent Machines REGIM, Sfax 3038, Tunisia.
   [Charfi, Nesrine; Trichili, Hanene; Solaiman, Basel] Telecom Bretagne, Dept Image & Informat Proc ITI, Technopole Brest Iroise, F-29238 Brest 3, France.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS); IMT -
   Institut Mines-Telecom; IMT Atlantique
RP Charfi, N (corresponding author), ENIS, REs Grp Intelligent Machines REGIM, Sfax 3038, Tunisia.; Charfi, N (corresponding author), Telecom Bretagne, Dept Image & Informat Proc ITI, Technopole Brest Iroise, F-29238 Brest 3, France.
EM nesrine.charfi@telecom-bretagne.eu; hanene.trichili@telecom-bretagne.eu;
   adel.alimi@ieee.org; basel.solaiman@telecom-bretagne.eu
RI Alimi, Adel M./A-5697-2012
OI Alimi, Adel M./0000-0002-0642-3384; TRICHILI, Hanene/0000-0003-4834-8658
CR Alsaade F, 2008, PATTERN RECOGN, V41, P814, DOI 10.1016/j.patcog.2007.06.028
   Amayeh G., 2006, PROC C COMPUTER VISI, P40, DOI DOI 10.1109/CVPRW.2006.155.17
   [Anonymous], P IEEE 3 INT C BIOM
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Briceno JC, 2011, INT C HAND BAS BIOM, P1, DOI DOI 10.1017/S1352465810000901
   Burges CJC, 1997, ADV NEUR IN, V9, P375
   Buyssens P, 2009, FUSION IR VISIBLE LI, P1
   Chang K, 2003, IEEE T PATTERN ANAL, V25, P1160, DOI 10.1109/TPAMI.2003.1227990
   Charfi Nesrine, 2015, 2015 11th International Conference on Information Assurance and Security (IAS). Proceedings, P13, DOI 10.1109/ISIAS.2015.7492764
   Charfi N, 2015, INT CONF INTELL SYST, P189, DOI 10.1109/ISDA.2015.7489223
   Charfi N, 2014, IEEE SYS MAN CYBERN, P4141, DOI 10.1109/SMC.2014.6974586
   Choras RS, 2007, LECT NOTES COMPUT SC, V4432, P407
   Dong KF, 2004, LECT NOTES COMPUT SC, V3338, P639
   Duta N, 2009, PATTERN RECOGN, V42, P2797, DOI 10.1016/j.patcog.2009.02.007
   El-Sallam A, 2011, C IND ELECT APPL, P281, DOI 10.1109/ICIEA.2011.5975595
   Ernst RH, U. S. Patent, Patent No. 3576537
   Ferrer M.A., 2011, PROC CONATEL, P1
   Fujisawa H, 2008, PATTERN RECOGN, V41, P2435, DOI 10.1016/j.patcog.2008.03.015
   Giot R, 2012, EXPERT SYST APPL, V39, P1837, DOI 10.1016/j.eswa.2011.08.066
   Guesmi H, 2015, PROCEEDINGS OF 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC), P418, DOI 10.1109/ICCI-CC.2015.7259419
   Guo JM, 2012, EXPERT SYST APPL, V39, P11728, DOI 10.1016/j.eswa.2012.04.081
   Han CC, 2004, IMAGE VISION COMPUT, V22, P909, DOI 10.1016/j.imavis.2004.05.008
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P1295, DOI 10.1109/34.735803
   Hu RX, 2012, PATTERN RECOGN, V45, P3348, DOI 10.1016/j.patcog.2012.02.018
   Jain A. K., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P857, DOI 10.1109/ICIP.1999.823019
   Jia W, 2008, PATTERN RECOGN, V41, P1504, DOI 10.1016/j.patcog.2007.10.011
   Kumar A, 2003, LECT NOTES COMPUT SC, V2688, P668
   Kumar A, 2006, IEEE T IMAGE PROCESS, V15, P2454, DOI 10.1109/TIP.2006.875214
   Kumar A, 2006, PATTERN RECOGN LETT, V27, P1478, DOI 10.1016/j.patrec.2006.02.021
   Kumar A, 2011, IEEE T SYST MAN CY C, V41, P743, DOI 10.1109/TSMCC.2010.2089516
   Kumar A, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P583, DOI 10.1109/ICVGIP.2008.73
   Ladoux PO, 2009, LECT NOTES COMPUT SC, V5558, P1290, DOI 10.1007/978-3-642-01793-3_130
   Leng L, 2015, MULTIMED TOOLS APPL, P1
   Leng L, 2014, 2014 11TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS (ITNG), P523, DOI 10.1109/ITNG.2014.18
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Lin CF, 2004, PATTERN RECOGN LETT, V25, P1647, DOI 10.1016/j.patrec.2004.06.009
   Lindeberg T., 1994, Journal of AppliedStatistics, V21, P225
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo YT, 2016, PATTERN RECOGN, V50, P26, DOI 10.1016/j.patcog.2015.08.025
   Luque-Baena RM, 2013, EXPERT SYST APPL, V40, P3580, DOI 10.1016/j.eswa.2012.12.065
   Lv ZH, 2015, PERS UBIQUIT COMPUT, V19, P551, DOI 10.1007/s00779-015-0844-1
   Michael GKO, 2012, J VIS COMMUN IMAGE R, V23, P1068, DOI 10.1016/j.jvcir.2012.07.004
   Ng, 2007, ADV NEURAL INF PROCE, P801
   Prasad SM, 2009, P INT C ADV COMP COM, P403
   Ross Arun, 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P1221
   Sanchez-Reillo R, 2000, IEEE T PATTERN ANAL, V22, P1168, DOI 10.1109/34.879796
   Shang L, 2012, LECT NOTES ARTIF INT, V6839, P701
   Shu W, 1998, INT C PATT RECOG, P219, DOI 10.1109/ICPR.1998.711120
   Sim T, 2007, IEEE T PATTERN ANAL, V29, P687, DOI 10.1109/TPAMI.2007.1010
   Srinivas BG, 2009, COMM COM INF SC, V40, P250, DOI 10.1007/978-3-642-03547-0_24
   Sun ZN, 2005, PROC CVPR IEEE, P279
   Tashk A, 2012, 2012 20TH TELECOMMUNICATIONS FORUM (TELFOR), P1729, DOI 10.1109/TELFOR.2012.6419561
   Tashk A, 2010, J ZHEJIANG U-SCI C, V11, P976, DOI 10.1631/jzus.C0910749
   Tashk A, 2011, AEU-INT J ELECTRON C, V65, P742, DOI 10.1016/j.aeue.2010.11.002
   Tounsi M, 2015, PROC INT CONF DOC, P1036, DOI 10.1109/ICDAR.2015.7333919
   Wang S, 2008, CONF CYBERN INTELL S, P59
   Wang WC, 2009, INT CONF ACOUST SPEE, P893, DOI 10.1109/ICASSP.2009.4959728
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu K, 2006, IEEE COMPUT INTELL M, V1, P10
   Wu XQ, 2014, PATTERN RECOGN, V47, P3314, DOI 10.1016/j.patcog.2014.04.008
   Yang J., 2009, LINEAR SPATIAL PYRAM
   Yap KH, 2005, IEEE T CIRC SYST VID, V15, P1557, DOI 10.1109/TCSVT.2005.856912
   Yörük E, 2006, IMAGE VISION COMPUT, V24, P483, DOI 10.1016/j.imavis.2006.01.020
   Zhihan L, 2014, ACM T MULTIM COMPUT, V11, P1
   Zuo WM, 2010, PROC CVPR IEEE, P2265, DOI 10.1109/CVPR.2010.5539909
NR 68
TC 20
Z9 20
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20457
EP 20482
DI 10.1007/s11042-016-3987-9
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400004
DA 2024-07-18
ER

PT J
AU Chen, KB
   Chang, HY
AF Chen, Kwei-Bor
   Chang, Hong-Yi
TI Complexity of cloud-based transcoding platform for scalable and
   effective video streaming services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud-based service; Real-time message protocol (RTMP); Real-time
   streaming protocols (RTSP); Transcoding; Video streaming
AB Nowadays, a fast network improves the quality of our daily life and we can enjoy a variety of services over the Internet. Different types of media streaming services have been proposed and utilized as the network speed is now sufficiently fast to deliver high-quality live streaming. Usually, different media streaming services deliver streaming data by using different protocols such as the real-time message protocol (RTMP), real-time streaming protocol (RTSP), and Windows media HTTP streaming protocol (WMSP). In this paper, we propose and implement a cloud-based scalable and cost-effective video streaming transcoding service platform to provide the service of changing real-time streaming protocols (RTMP/RTSP) and codecs (H.263/H.264). A transcoder dispatching problem (TDP) over the cloud platform is also defined, which attempts to serve all the transcoding requests by minimizing the cost of virtual machines. Further, a transcoder dispatching algorithm and an online transcoder dispatching algorithm are proposed for the TDP. These algorithms are implemented on the Amazon EC2 platform. Experimental results demonstrate that by renting different levels of virtual machines dynamically and intelligently, we can provide a scalable and cost-effective transcoding service for bridging heterogeneous streaming media.
C1 [Chen, Kwei-Bor] Minghsin Univ Sci & Technol, Dept Comp Sci & Informat Engn, Xinfen, Hsinchu County, Taiwan.
   [Chang, Hong-Yi] Natl Chiayi Univ, Dept Management Informat Syst, Chiayi, Taiwan.
C3 National Chiayi University
RP Chang, HY (corresponding author), Natl Chiayi Univ, Dept Management Informat Syst, Chiayi, Taiwan.
EM kbchen@must.edu.tw; alanc68@gmail.com
FU Ministry of Science and Technology (MOST) project of Taiwan [MOST
   103-2221-E-415-021-, MOST 104-2221-E-415-003-]
FX This work was supported by Ministry of Science and Technology (MOST)
   project of Taiwan [MOST 103-2221-E-415-021-] and [MOST
   104-2221-E-415-003-].
CR [Anonymous], TITLE ERROR
   Armbrust M, 2010, COMMUN ACM, V53, P50, DOI 10.1145/1721654.1721672
   Chieu TC, P 6 INT C E BUS ENG, P281
   de Assunçao MD, 2009, HPDC'09: 18TH ACM INTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE DISTRIBUTED COMPUTING, P141
   Jing Bi, 2010, 2010 IEEE 3rd International Conference on Cloud Computing (CLOUD 2010), P370, DOI 10.1109/CLOUD.2010.53
   Marshall Paul, 2010, Proceedings 2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing (CCGrid), P43, DOI 10.1109/CCGRID.2010.80
   Ming Mao, 2010, Proceedings 2010 11th IEEE/ACM International Conference on Grid Computing (GRID 2010), P41, DOI 10.1109/GRID.2010.5697966
   Pishinger D, 1995, LECT NOTES COMPUTER, V920
   Rombaut A., 2009, P 17 ACM INT C MULT, P929
   Young Choon Lee, 2010, Proceedings 2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing (CCGrid), P15, DOI 10.1109/CCGRID.2010.83
   Zhu Q., 2010, Proc. of the 19th ACM International Symposium on High Performance Distributed Computing, P304
NR 11
TC 9
Z9 10
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19557
EP 19574
DI 10.1007/s11042-016-3247-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500014
DA 2024-07-18
ER

PT J
AU Ghezaiel, W
   Ben Slimane, A
   Ben Braiek, E
AF Ghezaiel, Wajdi
   Ben Slimane, Amel
   Ben Braiek, Ezzedine
TI Nonlinear multi-scale decomposition by EMD for Co-Channel speaker
   identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Co-channel; Usable speech; Nonlinearmulti-scale decomposition; Empirical
   mode decomposition; Speaker identification
ID EMPIRICAL MODE DECOMPOSITION; EXTRACTION
AB A multi-scale analysis method, called Empirical Mode Decomposition (EMD), has been proposed for analysis of nonlinear and non stationary data. The empirical mode decomposition is a method initiated by Huang et al. as an alternative technique to the traditional Fourier and wavelet techniques for examining signals. It decomposes a signal into several components called intrinsic mode functions. This paper deals with this new tool to detect usable speech in co-channel speech. We applied empirical mode decomposition to decompose the co-channel speech signal into intrinsic oscillatory modes. Detected usable speech segments are organized into speaker streams, which are applied to speaker identification system. The system is evaluated on co-channel speech across various Targets to Interferer Ratios (TIR). Performance evaluation has shown that empirical mode decomposition performs better than linear multi-scale decomposition by discrete wavelet for usable speech detection.
C1 [Ghezaiel, Wajdi; Ben Braiek, Ezzedine] Univ Tunis, CEREP ENSIT, Tunis, Tunisia.
   [Ben Slimane, Amel] Univ Manouba, ENSI, Manouba, Tunisia.
C3 Universite de Tunis; Universite de la Manouba
RP Ghezaiel, W (corresponding author), Univ Tunis, CEREP ENSIT, Tunis, Tunisia.
EM wajdi.ghezaiel@gmail.com; Amel.benslimane@ensi.rnu.tn;
   Ezzedine.Benbraiek@esstt.rnu.tn
CR [Anonymous], P IEEE INT C PATT RE
   CARLSON BA, 1991, IEEE T PATTERN ANAL, V13, P1255, DOI 10.1109/34.106999
   Daqrouq K, 2011, ENG APPL ARTIF INTEL, V24, P796, DOI 10.1016/j.engappai.2011.01.001
   Flandrin P, 2004, IEEE SIGNAL PROC LET, V11, P112, DOI 10.1109/LSP.2003.821662
   Ghezaiel Wajdi, 2013, Advances in Nonlinear Speech Processing. 6th International Conference, NOLISP 2013. Proceedings. LNCS 7911, P184, DOI 10.1007/978-3-642-38847-7_24
   Ghezaiel W, 2013, ELECTRON LETT, V49, P503, DOI 10.1049/el.2012.3639
   Ghezaiel W, 2012, INT J COMPUT APPL, V59, P7
   Ghezaiel W, 2011, WORLD ACAD SCI ENG T, V5, P851
   Ghezaiel W., 2010, INT C EL SYST AUT CO
   Ghezaiel W, 2013, INT MULT SYST SIGN D
   Ghoraani B, 2011, IEEE T AUDIO SPEECH, V19, P2197, DOI 10.1109/TASL.2011.2118753
   Hershey JR, 2010, COMPUT SPEECH LANG, V24, P45, DOI 10.1016/j.csl.2008.11.001
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Kinnunen T, 2006, IEEE T AUDIO SPEECH, V14, P277, DOI 10.1109/TSA.2005.853206
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Kizhanatham A, 2003, 7 WORLD MULT SYST CY
   Krishnamachari K. R., 2000, IEEE INT S INT SIG P
   Kullback S., 1968, INFORM THEORY STAT
   Lovekin J, 2001, P ICASSP, P421
   Morgan DP, 1997, IEEE T SPEECH AUDI P, V5, P407, DOI 10.1109/89.622561
   NAYLOR J, 1991, INT CONF ACOUST SPEE, P937, DOI 10.1109/ICASSP.1991.150494
   QUATIERI TF, 1990, IEEE T ACOUST SPEECH, V38, P56, DOI 10.1109/29.45618
   REYNOLDS DA, 1995, SPEECH COMMUN, V17, P91, DOI 10.1016/0167-6393(95)00009-D
   Shao Y, 2003, INT CONF ACOUST SPEE, P205
   Smolenski Brett Y., 2011, IEEE CIRCUITS SYSTEM
   Wu JD, 2011, EXPERT SYST APPL, V38, P6112, DOI 10.1016/j.eswa.2010.11.013
   Yantorno R. E, 2008, J ACOUSTICAL SOC AM, V124
   Zissman M. A., 1991, TECHNICAL REPORT
NR 28
TC 7
Z9 7
U1 4
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20973
EP 20988
DI 10.1007/s11042-016-4044-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400029
DA 2024-07-18
ER

PT J
AU Hao, JB
   Yang, HF
   Li, ZK
AF Hao, Jingbin
   Yang, Haifeng
   Li, Zhongkai
TI Research of the reconstruction method for the image feature of non-rigid
   3D point cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-rigid; 3D point cloud; Image feature; Reconstruction
AB In the reconstruction of non-rigid three dimensional (3D) point cloud image features, the image data is large, which leads to the difficulty for analysis, and the achieving process is complex. In this paper, the reconstruction method for non-rigid 3D point cloud image features based on NURBS curve is proposed to collect non-rigid 3D point cloud image data, and achieve triangulation. The operation of point cloud data neighborhood search is limited in the local area, and the data of non-rigid 3D point cloud images are divided with the idea of space division. The least square plane is obtained by using preprocessed non-rigid 3D point cloud data, and the non-rigid 3D point cloud data is mapped and converted into a two dimensional (2D) point cloud model. The cumulative chord length parameterization method is adopted to introduce weighting factor for NURBS curve description using the rational polynomial function, based on the definition and properties of NURBS curve, point, line, surface reconstruction model is utilized to reconstruct the non-rigid 3D point cloud image feature. The simulation results show that the proposed method can reconstruct the 3D point cloud images feature with less time and the reconstruction effect is better than the Crust method.
C1 [Hao, Jingbin; Yang, Haifeng; Li, Zhongkai] China Univ Min & Technol, Coll Mech & Elect Engn, Xuzhou 221116, Peoples R China.
C3 China University of Mining & Technology
RP Hao, JB (corresponding author), China Univ Min & Technol, Coll Mech & Elect Engn, Xuzhou 221116, Peoples R China.
EM jingbinh@gmail.com; hfyang@cumt.edu.cn; lizk@cumt.edu.cn
RI Hao, Jingbin/KMY-5850-2024
OI Hao, Jingbin/0000-0001-8044-4178
FU National Natural Science Foundation of China [51305443]; Natural Science
   Foundation of Jiangsu Province [bk20130184]; Fundamental Research Funds
   for the Central Universities [2012QNA27]; State Key Laboratory of
   Materials Processing and Die & Mould Technology, Huazhong University of
   Science and Technology [P2016-18]; Priority Academic Program Development
   of Jiangsu Higher Education Institutions (PAPD)
FX This work was supported by National Natural Science Foundation of China
   (51305443), Natural Science Foundation of Jiangsu Province (bk20130184),
   Fundamental Research Funds for the Central Universities (2012QNA27),
   State Key Laboratory of Materials Processing and Die & Mould Technology,
   Huazhong University of Science and Technology (P2016-18), and A Project
   Funded by Priority Academic Program Development of Jiangsu Higher
   Education Institutions (PAPD).
CR Antonakos E, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2431445
   Chae J-K, 2015, IEEE T VIS COMPUT GR, V4796-4809, P17
   Chen L, 2015, IEEE T IMAGE PROCESS, V3282-3292, P23
   Duan G, 2015, IEEE T IMAGE PROCESS, V2344-2354, P30
   Halimi A, 2015, IEEE T VIS COMPUT GR, V4904-4917, P21
   Hell B, 2015, IEEE T IMAGE PROCESS, V24, P2633, DOI 10.1109/TIP.2015.2419078
   Hu S, 2015, IEEE T VIS COMPUT GR, V5594-5608, P11
   Hu YX, 2009, IEEE I CONF COMP VIS, P128, DOI 10.1109/ICCV.2009.5459153
   Ju F, 2015, IEEE T VIS COMPUT GR, V4834-4846, P12
   Jurie F, 2009, INT C COMP VIS, V237-244, P30
   Kav-Venaki E, 2009, INT C COMP VIS, V151-158, P8
   Kong SG, 2015, IEEE T IMAGE PROCESS, V24, P1801, DOI 10.1109/TIP.2015.2405483
   Lempitsky V, 2009, INT C COMP VIS, V277-284, P18
   Li M, 2015, IEEE T VIS COMPUT GR, V4876-4887, P21
   Liu J, 2015, IEEE T IMAGE PROCESS, V2797-2810, P25
   Liu S, 2014, APPL MATH COMPUT, V767-774, P6
   McNeill G, 2009, INT C COMP VIS, V245-252, P1
   Sun M, 2009, INT C COMP VIS, V213-220, P8
   Sun X, 2015, IEEE T IMAGE PROCESS, V1967-1982, P26
   Tang JH, 2015, IEEE T IMAGE PROCESS, V24, P2827, DOI 10.1109/TIP.2015.2421443
   Xiang T, 2009, INT C COMP VIS, V120-127, P9
   Yu L, 2015, IEEE T VIS COMPUT GR, V1315-1329, P19
   Zhang R, 2015, IEEE T VIS COMPUT GR, V4766-4779, P6
   Zhou H, 2015, IEEE T IMAGE PROCESS, V2317-2327, P14
NR 24
TC 1
Z9 1
U1 4
U2 61
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19591
EP 19603
DI 10.1007/s11042-015-3232-y
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500016
DA 2024-07-18
ER

PT J
AU Huang, L
   Luo, B
AF Huang, Lei
   Luo, Bin
TI Tag refinement of micro-videos by learning from multiple data sources
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Micro-video; Tag refinement; Multiple data sources
ID OBJECT; REPRESENTATION; RECOGNITION; MODEL
AB Micro-video is an increasingly prevalent social media form, which attracts much attention for its convenient acquisition and expressive ability. However, for the user-generated hashtags of micro-videos have seriously unbalanced distribution and low quality, the management of micro-videos becomes challenging. In this paper, we propose a novel tag refinement approach for micro-videos by learning from multiple public data sources with manually labelled tags, which can overcome the difficulty of directly refining the imprecise hashtags and address the problem of lacking manually labelled micro-video datasets for training. We define a set of target tags by referring to the widely used datasets for object, activity and scene detection. In tag refinement, we firstly transfer the tags from the images in NUS-WIDE to the micro-video keyframes by similarity measurement. Meanwhile, we complete the tags by detecting the objects, activities and scenes in micro-videos based on appearance features and motion features with the assistance of the datasets, namely, ImageNet, PASCAL VOC, HMDB51, UCF50 and SUN. We also denoise the hashtags by constructing the mapping relationships among hashtags and target tags based on the statistics on NUS-WIDE. The results of tag transfer, complement and denoising are finally linearly combined to generate the tag refinement results of micro-videos. To validate the performance, we construct a dataset with 600 micro-videos from Vine, and manually labelled the micro-videos with target tags. The experimental results show that our approach can obtain good performance in tag refinement of micro-videos by learning from multiple data sources.
C1 [Huang, Lei; Luo, Bin] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University
RP Luo, B (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Jiangsu, Peoples R China.
EM luobin@nju.edu.cn; leihuang@nju.edu.cn
RI huang, lei/GQP-8739-2022; HUANG, LING/HTR-1819-2023; Huang,
   Li/IUQ-0909-2023; lu, bin/HPE-4790-2023
FU National Science Foundation of China [61202320]; Research Project of
   Excellent State Key Laboratory [61223003]
FX The authors would like to thank the anonymous reviews for their helpful
   suggestion. This work is supported by National Science Foundation of
   China (61202320) and Research Project of Excellent State Key Laboratory
   (61223003).
CR [Anonymous], AAAI C ART INT
   [Anonymous], 2014 IEEE INT C MULT
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], INT C INT MULT COMP
   [Anonymous], OBJECT PROPOSAL RGB
   [Anonymous], 2013, P INT ACM C MULTIMED, DOI DOI 10.1145/2502081.2502093
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2016, ARXIV160309439
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI [10.1145/1899412.1899418, DOI 10.1145/1899412.1899418]
   [Anonymous], 2016, P 24 ACM INT C MULT
   [Anonymous], INT ACM SIGIR C RES
   [Anonymous], ACM T MULTIMED COMPU
   [Anonymous], 2016, P IEEE INFOCOM 16
   [Anonymous], 2010, P ACM MULTIMEDIA
   Bao BK, 2013, IEEE T IMAGE PROCESS, V22, P860, DOI 10.1109/TIP.2012.2219543
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1454, DOI 10.1145/2964284.2971477
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P898, DOI 10.1145/2964284.2964314
   Chen L, 2010, PROC CVPR IEEE, P3440, DOI 10.1109/CVPR.2010.5539988
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Gao K, 2013, SIGNAL PROCESS, V93, P2305, DOI 10.1016/j.sigpro.2012.10.011
   Gao K, 2012, PROC CVPR IEEE, P3234, DOI 10.1109/CVPR.2012.6248059
   Gao K, 2011, INT J COMPUT MATH, V88, P3953, DOI 10.1080/00207160.2011.583350
   Gao LL, 2015, PROC CVPR IEEE, P4371, DOI 10.1109/CVPR.2015.7299066
   Gao Z, 2015, NEUROCOMPUTING, V151, P554, DOI 10.1016/j.neucom.2014.06.085
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lin CL, 2003, IEEE ASME INT C ADV, P1
   Liu AA, 2016, IEEE T CYBERNETICS, P1
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu D, 2011, MULTIMED TOOLS APPL, V51, P723, DOI 10.1007/s11042-010-0647-3
   Liu D, 2009, INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL : ICACC 2009 - PROCEEDINGS, P351, DOI 10.1109/ICACC.2009.21
   Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4
   Redi M, 2014, PROC CVPR IEEE, P4272, DOI 10.1109/CVPR.2014.544
   Ren TW, 2016, MULTIMED TOOLS APPL, V75, P2543, DOI 10.1007/s11042-015-2875-z
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P883, DOI 10.1109/TMM.2012.2188782
   Sano S, 2014, IEEE IMAGE PROC, P5182, DOI 10.1109/ICIP.2014.7026049
   Simonyan K., 2015, P ICLR
   Sun C, 2015, IEEE T MULTIMEDIA, V17, P1747, DOI 10.1109/TMM.2015.2463218
   Tang JH, 2015, MULTIMEDIA SYST, V21, P267, DOI 10.1007/s00530-014-0357-1
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang M, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2333112.2333120
   Weinberger K.Q., 2008, Proceedings of Conference on Multimedia, P111
   Xiao J., 2014, IJCV, P1
   Xu XL, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/714530
   Yan R, 2009, IEEE MULTIMEDIA, V16, P26, DOI 10.1109/MMUL.2009.28
   Yang S, 2010, PROC CVPR IEEE, P2249, DOI 10.1109/CVPR.2010.5539907
   Yohan Jin, 2005, 13th Annual ACM International Conference on Multimedia, P706
   Yong SP, 2013, MULTIMED TOOLS APPL, V62, P359, DOI 10.1007/s11042-011-0902-2
   Yuan Z., 2013, Plane-based 3D mapping for structured indoor environment, P1
   Zhong SH, 2015, EXPERT SYST APPL, V42, P5658, DOI 10.1016/j.eswa.2015.01.012
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 55
TC 9
Z9 9
U1 12
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 20341
EP 20358
DI 10.1007/s11042-017-4781-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500057
DA 2024-07-18
ER

PT J
AU Lv, JW
   Wu, YR
   Chen, XQ
AF Lv, Jinwen
   Wu, Yirong
   Chen, Xianqiao
TI Segmentation optimization simulation of water remote congestion image of
   the ship
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Water remote ship congestion image; Segmentation; MCMC
ID RETRIEVAL; PATTERNS
AB In the process of segmenting water remote congestion image of the ship, due to interference of the external environment and the influence of the number of ships, the target is blocked, traditional methods for image segmentation region intersection, lead to target obscured, therefore, in this paper, a segmentation optimization method for water remote congestion image of the ship based on MCMC is proposed, through morphology denoising to preprocess water remote congestion image of the ship, and remove the noise of the image, ensure do not produce the global geometric distortion. Water remote ship congestion image field is divided into many disjoint areas, to give all states of the image, by using Bayesian method deduce the solution space of state, and setting up four classes of water remote ship congestion image model for four of the most frequent image regions appeared, the solution space structure is analyzed, and data driven method is used to classify the characteristics, according to the probability of each pixel eigenvector belonging to the cluster center to calculate the proposal probability, and transfer speed of Markov chain, establish ergodic Markov chain solution space, so as to achieve segmentation optimization of water remote ship congestion image. The simulation results show that the proposed method not only has the very high accuracy of image segmentation, also has complete segmentation result of target.
C1 [Lv, Jinwen; Chen, Xianqiao] Wuhan Univ Technol, Dept Comp Sci, Wuhan 430062, Hubei, Peoples R China.
   [Lv, Jinwen] Hubei Univ Technol, Dept Comp Sci, Wuhan 430068, Hubei, Peoples R China.
   [Wu, Yirong] Wisconsin Inst Med Res II, Madison, WI 53705 USA.
   [Lv, Jinwen] Wuhan Univ Technol, Dept Comp Sci, Wuhan 130118, Hubei, Peoples R China.
C3 Wuhan University of Technology; Hubei University of Technology; Wuhan
   University of Technology
RP Chen, XQ (corresponding author), Wuhan Univ Technol, Dept Comp Sci, Wuhan 430062, Hubei, Peoples R China.
EM lvjinwen458@163.com; chenxianqiao1005@163.com
CR Anibou C, 2015, J INF PROCESS SYST, V11, P421, DOI 10.3745/JIPS.02.0028
   [Anonymous], J CONVERG
   Jianxi W, 2015, MATH COMPUT SIMULAT, V5, P395
   Khongkraphan K, 2014, J INF PROCESS SYST, V10, P589, DOI 10.3745/JIPS.02.0010
   Koteswara Rao L, 2015, HUM CENTRIC INF SYST, V9, P26
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8
   Liu SA, 2017, MULTIMED TOOLS APPL, V76, P5787, DOI 10.1007/s11042-014-2408-1
   Liu S, 2014, APPL MATH COMPUT, V243, P767, DOI 10.1016/j.amc.2014.06.016
   Murala S, 2012, INT J MULTIMED INF R, V1, P191, DOI 10.1007/s13735-012-0008-2
   Murala S, 2013, NEUROCOMPUTING, V119, P399, DOI 10.1016/j.neucom.2013.03.018
   Punnappurath Abhijith, 2015, IEEE Trans Image Process, V24, P2067, DOI 10.1109/TIP.2015.2412379
   Reddy PVB, 2014, AEU-INT J ELECTRON C, V68, P637, DOI 10.1016/j.aeue.2014.01.012
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Shi CZ, 2015, IEEE T IMAGE PROCESS, V24, P4952, DOI 10.1109/TIP.2015.2473105
   Subrahmanyam M, 2012, SIGNAL PROCESS, V92, P1467, DOI 10.1016/j.sigpro.2011.12.005
   Sui Y, 2015, IEEE T IMAGE PROCESS, V24, P4686, DOI 10.1109/TIP.2015.2462076
   Vipparthi SK, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0006-x
   Vipparthi SK, 2014, EXPERT SYST APPL, V41, P8016, DOI 10.1016/j.eswa.2014.07.001
   Wang LB, 2015, IEEE T IMAGE PROCESS, V24, P5442, DOI 10.1109/TIP.2015.2481701
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yousaf S, 2015, IEEE T IMAGE PROCESS, V24, P5928, DOI 10.1109/TIP.2015.2492825
   Zhao L, 2015, IEEE T IMAGE PROCESS, V24, P5274, DOI 10.1109/TIP.2015.2473662
NR 22
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19605
EP 19620
DI 10.1007/s11042-015-3227-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500017
DA 2024-07-18
ER

PT J
AU Wei, LF
   Ji, JW
   Wu, HY
   Jing, K
AF Wei, Li-feng
   Ji, Jian-wei
   Wu, Hong-yuan
   Jing, Ke
TI Towards a cloud storage data management model based on RNPT network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Network structure; Data management model; Replica
   placement; Replica selection
AB Data management is the core module of cloud storage system. Constructed network topology of data center, the data management model of Recursion-based N-regular Polygon Topology (RNPT) was established referring to file systems as Google File System (GFS) and Hadoop Distributed File System (HDFS). The model uses central server mode as well as RNPT network structure to ensure system scalability. In addition to achieve high replica availability and reliability, the replica is reasonably allocated to reduce user access time, decrease communication delay as well as effectively cooperative load balancing strategy. The system resource is adequately used in the model to improve cloud storage performance and service quality. Comparison to HDFS by simulation experiments using CloudSim shows that the RNPT-based data management model can improve data access performance and reasonably utilize network bandwidth so that load balancing is achieved.
C1 [Wei, Li-feng; Wu, Hong-yuan; Jing, Ke] Shenyang Aerosp Univ, Coll Econ & Management, Shenyang, Liaoning, Peoples R China.
   [Wei, Li-feng; Ji, Jian-wei] Shenyang Agr Univ, Coll Informat & Elect Engn, Shenyang, Liaoning, Peoples R China.
C3 Shenyang Aerospace University; Shenyang Agricultural University
RP Wei, LF (corresponding author), Shenyang Aerosp Univ, Coll Econ & Management, Shenyang, Liaoning, Peoples R China.; Wei, LF (corresponding author), Shenyang Agr Univ, Coll Informat & Elect Engn, Shenyang, Liaoning, Peoples R China.
EM lifengmtap@gmail.com; jianweiji7879@hotmail.com; 69201512@qq.com;
   chloe.jingke@gmail.com
RI wangwangwang, yuanyaunyuan/HHN-6432-2022
FU National Natural Science Funds of China [71301108]
FX This work was supported in part by the National Natural Science Funds of
   China (Grant No. 71301108).
CR Al-Jaberi MF, 2014, 2014 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES (ISBAST), P280, DOI 10.1109/ISBAST.2014.7013135
   Aversa L., 2000, Conference Proceedings of the 2000 IEEE International Performance, Computing, and Communications Conference (Cat. No.00CH37086), P24, DOI 10.1109/PCCC.2000.830297
   Azzedin F, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS (CTS), P155
   Bochicchio M. A., 2011, Proceedings of the 2011 IEEE 4th International Conference on Cloud Computing (CLOUD 2011), P332, DOI 10.1109/CLOUD.2011.102
   Carman M, 2002, CCGRID 2002: 2ND IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID, PROCEEDINGS, P340, DOI 10.1109/CCGRID.2002.1017156
   Gilbert S, 2000, P ACM SIGACT NEWS, P51
   Guo C, 2008, P ACM SIGCOMM COMP C, P39
   Guo CX, 2009, SIGCOMM 2009, P63
   Gyuwon Song, 2009, Proceedings of the 2009 First International Conference on Advances in P2P Systems (AP2PS 2009), P160, DOI 10.1109/AP2PS.2009.33
   Huang KX, 2014, IEEE INT CONF COMMUN, P344, DOI 10.1109/ICCChina.2014.7008299
   Imran M, 2013, INT CONF SEMANT, P121, DOI 10.1109/SKG.2013.28
   Kauranen M, 2013, CHALL ADV COMPUT CHE, V15, P207, DOI 10.1007/978-94-007-7805-4_6
   Saraswathi M, 2014, 2014 INTERNATIONAL CONFERENCE ON COMMUNICATION AND NETWORK TECHNOLOGIES (ICCNT), P27, DOI 10.1109/CNT.2014.7062719
   Sashi K, 2010, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON DATA STORAGE AND DATA ENGINEERING (DSDE 2010), P265, DOI 10.1109/DSDE.2010.38
   SHEN WEI, 2006, COMPUTER ENG APPL, V35, P144
   Wang MD, 2014, IEEE PAC RIM INT SYM, P190, DOI 10.1109/PRDC.2014.32
NR 16
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19723
EP 19739
DI 10.1007/s11042-016-3438-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500024
DA 2024-07-18
ER

PT J
AU Wei, X
   Lu, W
   Xing, WW
AF Wei, Xiang
   Lu, Wei
   Xing, Weiwei
TI A rapid multi-source shortest path algorithm for interactive image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Multi-Source; Shortest path; Interactive
   segmentation; Dijkstra
ID RANDOM-WALKS; GRAPH CUTS; MRI
AB This paper addresses the problem of performing multiple objects, interactive image segmentation. Given a small number of pixels (seeds) with predefined labels, we can quickly and accurately determine the closest seed from each unlabeled pixel. By assigning each pixel to the label same as its closest seed, a rapid image segmentation result can be obtained. Since the shortest distance is considered in this paper which directs our attention of segmentation into path planning problem, Dijkstra occurs to mind. Modifying the classical single-source algorithm, a simple yet rapid multi-source Dijkstra (MSD) algorithm is put forward. From both theoretical and experimental aspects, the proposed algorithm performs quite well in resisting noise, and preserving the objects details. Moreover, under the situation of multiple sources, instead of performing Dijkstra several times to obtain the distance from each pixel to each seed and choose the closest seed, the proposed multi-source image segmentation algorithm could determine the closest seed by running Dijkstra only once. Its efficiency, which will not be affected by the number of initial seed settings, maintains the same as the Dijkstra.
C1 [Wei, Xiang; Lu, Wei; Xing, Weiwei] Beijing Jiaotong Univ, Sch Software Engn, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University
RP Lu, W (corresponding author), Beijing Jiaotong Univ, Sch Software Engn, Beijing 100044, Peoples R China.
EM weixiangkl2016@aliyun.com; luwei@bjtu.edu.cn
OI Wei, Xiang/0000-0002-8967-6423
FU National Natural Science Foundation of China [61100143, 61272353,
   61370128]; Program for New Century Excellent Talents in University
   [NCET-13-0659]; Beijing Higher Education Young Elite Teacher Project
   [YETP0583]; Fundamental Research Funds for the Central Universities
   [2014JBZ004, 2015RC031]
FX This work is supported in part by National Natural Science Foundation of
   China (No. 61100143, 61272353, 61370128), Program for New Century
   Excellent Talents in University (NCET-13-0659), Beijing Higher Education
   Young Elite Teacher Project (YETP0583), and Fundamental Research Funds
   for the Central Universities (2014JBZ004, 2015RC031).
CR Arandjelovic O, 2013, COMPUTER SCI
   Arias A, 2015, IEEE T MED IMAGING, V35, P1
   Barrett W A, 1997, Med Image Anal, V1, P331, DOI 10.1016/S1361-8415(97)85005-0
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Dong XP, 2016, IEEE T IMAGE PROCESS, V25, P516, DOI 10.1109/TIP.2015.2505184
   Ducournau A, 2014, COMPUT VIS IMAGE UND, V120, P91, DOI 10.1016/j.cviu.2013.10.012
   Eelke V, 2016, NEUROIMAGE, V125, P479
   Galceran E, 2013, ROBOT AUTON SYST, V61, P1258, DOI 10.1016/j.robot.2013.09.004
   Gong MG, 2015, INFORM SCIENCES, V293, P351, DOI 10.1016/j.ins.2014.09.023
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Haralick BRM, 2015, COMPUT VISION GRAPH, V29, P100
   Jha SK, 2013, PROC TECH, V10, P271, DOI 10.1016/j.protcy.2013.12.361
   Jin SH, 2014, INT J REMOTE SENS, V35, P3978, DOI 10.1080/01431161.2014.916447
   Katsigiannis S, 2015, IEEE T NANOBIOSCI, V14, P138, DOI 10.1109/TNB.2014.2369961
   Knuth DE, 2015, INFORM PROCESS LETT, V6, P1
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Mahapatra D, 2014, IEEE T BIO-MED ENG, V61, P756, DOI 10.1109/TBME.2013.2289306
   Treiber MA, 2013, ADV COMPUT VIS PATTE, V27, P177
   Wechsler H KidodeM, 1979, PATTERN ANAL MACHINE, P272
   WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673
   Xu Z, 2015, J OPT SOC AM A, V32, P463, DOI 10.1364/JOSAA.32.000463
   Yang XL, 2016, IET COMPUT VIS, V10, P79, DOI 10.1049/iet-cvi.2014.0450
   Yao F U, 2015, MODERN COMPUTER
   Zhang L, 2014, COMPUT MED IMAG GRAP, V38, P369, DOI 10.1016/j.compmedimag.2014.02.001
   Zhu QS, 2013, APPL MATH INFORM SCI, V7, P1387, DOI 10.12785/amis/070417
NR 25
TC 4
Z9 4
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21547
EP 21563
DI 10.1007/s11042-016-4073-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400054
DA 2024-07-18
ER

PT J
AU Berraho, S
   El Margae, S
   Kerroum, MA
   Fakhri, Y
AF Berraho, Sanae
   El Margae, Samira
   Kerroum, Mounir Ait
   Fakhri, Youssef
TI Texture classification based on curvelet transform and extreme learning
   machine with reduced feature set
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture classification; Digital curvelet transform; LSDA; Extreme
   learning machine; Dimension reduction
ID BREAST-CANCER DIAGNOSIS; SENSITIVE DISCRIMINANT-ANALYSIS;
   FEATURE-EXTRACTION; FACE RECOGNITION; WAVELET; ALGORITHMS
AB In this work, a novel approach for texture classification is proposed. We present a highly discriminative and simple descriptor to achieve feature learning and classification simultaneously for texture classification. The proposed method introduces the application of digital curvelet transform and explores feature reduction properties of locality sensitive discriminant analysis (LSDA) in conjunction with extreme learning machine (ELM) classifier. The image is mapped to the curvelet space. However, the curse of dimensionality problem arises when using the curvelet coefficients directly and therefore a reduction method is required. LSDA is used to reduce the data dimensionality to generate relevant features. These reduced features are used as the input to ELM classifier to analytically learn an optimal model. In contrast to traditional methods, the proposed method learns the features by the network itself and can be applied to more general applications. Extensive experiments conducted in two different domains using two benchmark databases, illustrate the effectiveness of the proposed method. In addition, empirical comparisons of the proposed method against curvelet transform in conjunction with traditional dimensionality reduction tools show that the suggested method does not only lead to a more reduced feature set, but it also outperforms all the compared methods in terms of accuracy.
C1 [Berraho, Sanae; El Margae, Samira; Kerroum, Mounir Ait; Fakhri, Youssef] Univ Ibn Tofail, LaRIT Lab, Team Network Telecommun & Artificial Intelligence, Fac Sci, BP 242, Kenitra, Morocco.
C3 Ibn Tofail University of Kenitra
RP Berraho, S; El Margae, S (corresponding author), Univ Ibn Tofail, LaRIT Lab, Team Network Telecommun & Artificial Intelligence, Fac Sci, BP 242, Kenitra, Morocco.
EM berraho.sanae@gmail.com; elmargaesamira@gmail.com
RI YOUSSEF, FAKHRI/AAA-8261-2020
OI YOUSSEF, FAKHRI/0000-0002-5647-303X; AIT KERROUM,
   MOUNIR/0000-0001-7519-4434
CR Amayeh G, 2008, LECT NOTES COMPUT SC, V5359, P541, DOI 10.1007/978-3-540-89646-3_53
   [Anonymous], ARXIV12030488
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Berraho S, 2015, INT REV COMPUTERS SO, V10
   Bhatia N., 2010, INT J COMPUT SCI INF, V8, DOI DOI 10.1016/J.PMCJ.2015.02.001
   BI-RADS, 2003, BREAST IM REP DAT SY
   Cai D, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P714
   Cai ZX, 2013, J CENT SOUTH UNIV, V20, P433, DOI 10.1007/s11771-013-1504-0
   Candes E.J., 2001, SPIE WAVELET APPL SI
   CANDES E.J., 1999, Curves and Surfaces, P1
   Candès EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Chen HT, IEEE COMP SOC C COMP, V2, P846
   Choi M., 2004, ISPRS J. Photogramm. Remote Sens., V35, P59
   Dettori L, 2007, COMPUT BIOL MED, V37, P486, DOI 10.1016/j.compbiomed.2006.08.002
   Dhahbi S, 2015, COMPUT BIOL MED, V64, P79, DOI 10.1016/j.compbiomed.2015.06.012
   Dong KF, 2004, LECT NOTES COMPUT SC, V3338, P639
   Eltoukhy MM, 2012, COMPUT BIOL MED, V42, P123, DOI 10.1016/j.compbiomed.2011.10.016
   Eltoukhy MM, 2010, COMPUT MED IMAG GRAP, V34, P269, DOI 10.1016/j.compmedimag.2009.11.002
   Fleyeh H, 2011, IET INTELL TRANSP SY, V5, P190, DOI 10.1049/iet-its.2010.0159
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Gao QX, 2014, NEURAL NETWORKS, V54, P49, DOI 10.1016/j.neunet.2014.02.009
   Gedik N, 2013, TURK J ELECTR ENG CO, V21, P1002, DOI 10.3906/elk-1201-8
   Gonzalez-Reyna Sheila Esmeralda, 2013, Advances in Soft Computing and Its Applications. 12th Mexican International Conference on Artificial Intelligence, MICAI 2013. Proceedings, LNCS 8266, P185, DOI 10.1007/978-3-642-45111-9_16
   Grigorescu SE, 2002, IEEE T IMAGE PROCESS, V11, P1160, DOI 10.1109/TIP.2002.804262
   He XF, 2004, ADV NEUR IN, V16, P153
   Heath M, 2001, IWDM 2000: 5TH INTERNATIONAL WORKSHOP ON DIGITAL MAMMOGRAPHY, P212
   Hsu C.-W., 2003, PRACTICAL GUIDE SUPP
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huang K, 2008, IEEE T IMAGE PROCESS, V17, P1709, DOI 10.1109/TIP.2008.2001050
   Huang ZY, 2014, 2014 11TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P1451, DOI 10.1109/WCICA.2014.7052932
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Li LF, 2015, PRECIS ENG, V39, P212, DOI 10.1016/j.precisioneng.2014.09.003
   Majumdar A, 2007, J PATTERN RECOGNIT R, V2, P17, DOI 10.13176/11.27
   Malar E, 2013, LECT NOTES COMPUT SC, V8298, P658, DOI 10.1007/978-3-319-03756-1_59
   Mandal T, 2007, LECT NOTES COMPUT SC, V4633, P806
   Menaka K, 2014, INT CONF COMP COMMUN
   Mohammed AA, 2011, PATTERN RECOGN, V44, P2588, DOI 10.1016/j.patcog.2011.03.013
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Skrzypek J, 1992, NEURAL NETWORKS VISI
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Starck JL, 2003, ASTRON ASTROPHYS, V398, P785, DOI 10.1051/0004-6361:20021571
   Starck JL, 2001, P SOC PHOTO-OPT INS, V4478, P9, DOI 10.1117/12.449693
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Van de Wouwer G, 1999, IEEE T IMAGE PROCESS, V8, P592, DOI 10.1109/83.753747
   Yi YG, 2015, MULTIMED TOOLS APPL, V74, P85, DOI 10.1007/s11042-013-1429-5
   Zhang J, 2007, P NATURAL COMPUTATIO
   Zhang ZB, 2006, INT C PATT RECOG, P145
NR 52
TC 5
Z9 5
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18425
EP 18448
DI 10.1007/s11042-016-4174-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800012
DA 2024-07-18
ER

PT J
AU Chen, SN
AF Chen, Shih-Nung
TI Storyboard-based accurate automatic summary video editing system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video search; Storyboard; Video content retrieval; Automatic video
   editing; Summary video
ID RETRIEVAL
AB The recent popularity of smart mobile devices has led to a significant increase in the needs of multimedia services. Finding new more efficient methods for automatic classification and retrieval of a large number of multimedia files will significantly reduce manpower costs. However, most current video content analysis methods adopt low-level features to analyze video frame by frame, and need to improve high-level semantic analysis on a number of issues. Hence, this study presents a storyboard-based accurate automatic summary video editing system that uses storyboard information, such as character dialogue, narration, caption, background music and shot changes, to enable accurate video content retrieval and automatic render summary videos. The proposed system can be applied to the course video trailer and the commercial video trailer for quick preview video content or suitable viewing configuration for smart mobile devices. Consequently, the audience can quickly understand the whole video story and the video editors can substantially reduce the time taken to publish videos.
C1 [Chen, Shih-Nung] Asia Univ, Dept Informat Commun, Taichung, Taiwan.
C3 Asia University Taiwan
RP Chen, SN (corresponding author), Asia Univ, Dept Informat Commun, Taichung, Taiwan.
EM nung@asia.edu.tw
FU Ministry of Science and Technology of the Republic of China, Taiwan
   [MOST 103-2221-E-468-029]
FX The author would like to thank the Ministry of Science and Technology of
   the Republic of China, Taiwan, for financially supporting this research
   under Contract No. MOST 103-2221-E-468-029.
CR Ansari Aasif., 2015, International Journal of Computer Applications, V112, P13
   Bastan M, 2010, IEEE MULTIMEDIA, V17, P62, DOI 10.1109/MMUL.2010.5692184
   Belongie S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P675, DOI 10.1109/ICCV.1998.710790
   Bhat SA, 2014, INT J ADV ENG GLOBAL, V2, P476
   Bregler C, 1997, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.1997.609382
   Bruno E, 2003, 3 INT WORKSH CONT BA
   Chen Liang-Hua., 2008, P C AUSTRALASIAN DAT, P49
   Deng Y, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P534, DOI 10.1109/ICIP.1997.638826
   Djeraba C, 2002, IEEE MULTIMEDIA, V9, P18, DOI 10.1109/MMUL.2002.998047
   ELGMAGARMID AK, 1997, VIDEO DATABASE SYSTE
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Ianeva TI, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1607, DOI 10.1109/ICME.2004.1394557
   Jawahar C. V., 2005, 13 INT C ADV COMP CO
   Lu G., 1999, MULTIMEDIA DATABASE
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Sebe N, 2003, COMPUT VIS IMAGE UND, V92, P141, DOI 10.1016/j.cviu.2003.08.003
   Shen H.T., 2007, VLDB, P1374
   Su JH, 2010, EXPERT SYST APPL, V37, P5068, DOI 10.1016/j.eswa.2009.12.003
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Tusch R., 2000, Proceedings ACM Multimedia 2000, P448, DOI 10.1145/354384.376360
   Yang CW, 2012, INVESTIGATION METHOD
NR 22
TC 0
Z9 0
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18409
EP 18423
DI 10.1007/s11042-016-4160-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800011
DA 2024-07-18
ER

PT J
AU Singh, R
   Srivastava, S
AF Singh, Ritika
   Srivastava, Shashi
TI Stock prediction using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep Learning; Stock Prediction; Neural Network; (2D)(2)PCA; Radial
   Basis Function Neural Network; Regularization; Multimedia
ID BELIEF NETWORKS
AB Stock market is considered chaotic, complex, volatile and dynamic. Undoubtedly, its prediction is one of the most challenging tasks in time series forecasting. Moreover existing Artificial Neural Network (ANN) approaches fail to provide encouraging results. Meanwhile advances in machine learning have presented favourable results for speech recognition, image classification and language processing. Methods applied in digital signal processing can be applied to stock data as both are time series. Similarly, learning outcome of this paper can be applied to speech time series data. Deep learning for stock prediction has been introduced in this paper and its performance is evaluated on Google stock price multimedia data (chart) from NASDAQ. The objective of this paper is to demonstrate that deep learning can improve stock market forecasting accuracy. For this, (2D)(2)PCA + Deep Neural Network (DNN) method is compared with state of the art method 2-Directional 2-Dimensional Principal Component Analysis (2D)(2)PCA + Radial Basis Function Neural Network (RBFNN). It is found that the proposed method is performing better than the existing method RBFNN with an improved accuracy of 4.8% for Hit Rate with a window size of 20. Also the results of the proposed model are compared with the Recurrent Neural Network (RNN) and it is found that the accuracy for Hit Rate is improved by 15.6%. The correlation coefficient between the actual and predicted return for DNN is 17.1% more than RBFNN and it is 43.4% better than RNN.
C1 [Singh, Ritika] Indian Sch Mines, Dhanbad, Bihar, India.
   [Srivastava, Shashi] Banaras Hindu Univ, Fac Management Studies, Varanasi, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad; Banaras Hindu University
   (BHU)
RP Singh, R (corresponding author), Indian Sch Mines, Dhanbad, Bihar, India.
EM ritikasingh.ism@gmail.com; shashi_cheshta@rediffmail.com
RI Srivastava, Shashi/HTM-2072-2023
CR [Anonymous], P NIPS
   [Anonymous], 2007, A Random Walk Down Wall Street
   [Anonymous], 2014, EXTREME LEARNING MAC
   [Anonymous], 2015, DEEP LEARNING REGULA
   [Anonymous], 2012, ARXIV PREPRINT ARXIV
   Atsalakis GS, 2009, EXPERT SYST APPL, V36, P5932, DOI 10.1016/j.eswa.2008.07.006
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Guo ZQ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0122385
   Guresen E, 2011, EXPERT SYST APPL, V38, P10389, DOI 10.1016/j.eswa.2011.02.068
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang CJ, 2008, EXPERT SYST APPL, V34, P2870, DOI 10.1016/j.eswa.2007.05.035
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuremoto T, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), P1130, DOI 10.1109/CISP.2014.7003950
   Kuremoto T, 2014, NEUROCOMPUTING, V137, P47, DOI 10.1016/j.neucom.2013.03.047
   Kwon YK, 2007, IEEE T NEURAL NETWOR, V18, P851, DOI 10.1109/TNN.2007.891629
   Larochelle H, 2009, J MACH LEARN RES, V10, P1
   Le Roux N, 2010, NEURAL COMPUT, V22, P2192, DOI 10.1162/neco.2010.08-09-1081
   Lendasse A., 2000, European Journal of Economic and Social Systems, V14, P81, DOI 10.1051/ejess:2000110
   Mohamed AR, 2011, INT CONF ACOUST SPEE, P5060
   Murphy JJ., 1999, Technical analysis of the financial markets: A comprehensive guide to trading methods and applications
   Pan HP, 2003, LECT NOTES ARTIF INT, V2903, P327
   Patel J, 2015, EXPERT SYST APPL, V42, P2162, DOI 10.1016/j.eswa.2014.10.031
   Patel J, 2015, EXPERT SYST APPL, V42, P259, DOI 10.1016/j.eswa.2014.07.040
   Shen W, 2011, KNOWL-BASED SYST, V24, P378, DOI 10.1016/j.knosys.2010.11.001
   Situngkir H, 2004, PHYSICA A, V344, P100, DOI 10.1016/j.physa.2004.06.095
   Sutskever I, 2008, NEURAL COMPUT, V20, P2629, DOI 10.1162/neco.2008.12-07-661
   Takeuchi Lawrence., 2013, Applying deep learning to enhance momentum trading strategies in stocks. In Technical Report
   Teixeira LA, 2010, EXPERT SYST APPL, V37, P6885, DOI 10.1016/j.eswa.2010.03.033
   White H., 1988, IEEE International Conference on Neural Networks (IEEE Cat. No.88CH2632-8), P451, DOI 10.1109/ICNN.1988.23959
   Yu K., 2009, Advances in Neural Information Processing Systems, P1889
   Zhang DQ, 2005, NEUROCOMPUTING, V69, P224, DOI 10.1016/j.neucom.2005.06.004
   Zuo Z, 2014, IEEE SIGNAL PROC LET, V21, P1159, DOI 10.1109/LSP.2014.2298888
NR 34
TC 145
Z9 156
U1 9
U2 294
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18569
EP 18584
DI 10.1007/s11042-016-4159-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800020
DA 2024-07-18
ER

PT J
AU Chen, XJ
   Ke, J
   Zhan, TM
   Wang, WX
   Zhan, YZ
   Chen, XB
   Song, XP
AF Chen, Xiao-jun
   Ke, Jia
   Zhan, Tian-ming
   Wang, Wen-xin
   Zhan, Yong-zhao
   Chen, Xiao-bo
   Song, Xin-ping
TI A cloud computing architecture for characterization and classification
   of moving object
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Combined moment invariants; Multi-moving objects;
   SF-ISF; Moving object classification; SVR
ID IMAGE-ANALYSIS; MOMENT INVARIANTS
AB Video surveillance big data contains a great deal of information about moving objects. Multi moving object characterization and classification methods is the main characteristics to find a suitable description of the scene in all kinds of sports objects, features and match unknown similarity between moving objects. This paper presents a calculation of all the moving objects in the scene using cloud computing architecture with invariant moment value weighting method, combined with the invariant moments as the input parameter value, the establishment of multi-class classification model for multiple moving object classification. Experimental results show that this method can effectively improve the recognition rate of the moving object.
C1 [Chen, Xiao-jun] Jiangsu Univ, Affiliated Hosp, Jiefang Rd 438, Zhenjiang 212001, Jiangsu, Peoples R China.
   [Chen, Xiao-jun; Ke, Jia; Zhan, Tian-ming; Zhan, Yong-zhao] JiangSu Univ, Sch Comp Sci & Commun Engn, Zhenjiang, Peoples R China.
   [Ke, Jia; Wang, Wen-xin; Song, Xin-ping] Jiangsu Univ, Sch Management, Zhenjiang, Peoples R China.
   [Chen, Xiao-bo] Jiangsu Univ, Automot Engn Res Inst, Zhenjiang, Peoples R China.
C3 Jiangsu University; Jiangsu University; Jiangsu University
RP Chen, XJ (corresponding author), Jiangsu Univ, Affiliated Hosp, Jiefang Rd 438, Zhenjiang 212001, Jiangsu, Peoples R China.; Chen, XJ (corresponding author), JiangSu Univ, Sch Comp Sci & Commun Engn, Zhenjiang, Peoples R China.
EM cxj@ujs.edu.cn
RI wang, wenxin/HGD-7043-2022
FU Department of Transportation Informatization [2013-364-836-900]; Key
   Project of Jiangsu for Research and Development [BE2015137]; National
   Natural Science Foundation of China [71573107, 41374129, 41474095,
   60673190, 61203244]; College Natural Science Research of Jiangsu
   Province [14KJB520008]; Senior Technical Personnel of Scientific
   Research Fund of Jiangsu University [13JDG126]; Research Innovation
   Program for College Graduates of Jiangsu Province [KYLX15_1078]; Basic
   research project of science and technology research; Development Fund of
   Shenzhen [JCYJ20150401092136087]
FX This research has partially been supported by the project funded of the
   Department of Transportation Informatization under Grant No.
   2013-364-836-900, Key Project of Jiangsu for Research and Development
   under Grant No. BE2015137, National Natural Science Foundation of China
   under Grant No. 71573107, 41374129, 41474095, 60673190 and 61203244,
   College Natural Science Research of Jiangsu Province under Grant No.
   14KJB520008, Senior Technical Personnel of Scientific Research Fund of
   Jiangsu University under Grant No. 13JDG126, Research Innovation Program
   for College Graduates of Jiangsu Province under Grant No. KYLX15_1078,
   Basic research project of science and technology research and
   Development Fund of Shenzhen under Grand No. JCYJ20150401092136087.
CR ABUMOSTAFA YS, 1984, IEEE T PATTERN ANAL, V6, P698, DOI 10.1109/TPAMI.1984.4767594
   [Anonymous], INFRARED
   [Anonymous], 2011, J FUTURE GENER COMPU
   [Anonymous], NEURAL COMPUT APPL
   [Anonymous], ELECT OPTI CONTROL
   [Anonymous], INT J COMPUT VIS
   [Anonymous], J OPT LASER
   [Anonymous], ATTRIBUTE BASED ENCR
   [Anonymous], MOMENTS ITS APPL GEO
   [Anonymous], EL COMM NETW 4 P 4 I
   Beach T, 2015, IEEE T SERV COMPUT, V8, P314, DOI 10.1109/TSC.2013.50
   Brons R., 1974, Computer Graphics and Image Processing, V3, P48
   Chen BJ, 2012, SIGNAL PROCESS, V92, P308, DOI 10.1016/j.sigpro.2011.07.018
   Chen XB, 2012, NEUROCOMPUTING, V97, P63, DOI 10.1016/j.neucom.2012.05.004
   Chen XB, 2012, NEURAL COMPUT APPL, V21, P505, DOI 10.1007/s00521-010-0454-9
   Doukas C., 2012, 2012 Sixth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing (IMIS 2012), P922, DOI 10.1109/IMIS.2012.26
   Fan LN, 2005, Proceedings of 2005 Chinese Control and Decision Conference, Vols 1 and 2, P579
   Flusser J, 2000, PATTERN RECOGN, V33, P1405, DOI 10.1016/S0031-3203(99)00127-2
   FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H
   GUPTA L, 1987, PATTERN RECOGN, V20, P267, DOI 10.1016/0031-3203(87)90001-X
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   LENZ R, 1994, PATTERN RECOGN, V27, P1523, DOI 10.1016/0031-3203(94)90130-9
   Li XO, 2013, J INTELL FUZZY SYST, V24, P665, DOI 10.3233/IFS-2012-0586
   [李学勇 LI Xueyong], 2007, [光电子·激光, Journal of Optoelectronics·Laser], V18, P1244
   PAVLIDIS T, 1975, IEEE T SYST MAN CYB, V5, P610, DOI 10.1109/TSMC.1975.4309402
   PIZLO Z, 1992, CVGIP-IMAG UNDERSTAN, V56, P330, DOI 10.1016/1049-9660(92)90046-6
   REDDI SS, 1981, IEEE T PATTERN ANAL, V3, P240, DOI 10.1109/TPAMI.1981.4767087
   Schneider S, 2016, J INF TECHNOL-UK, V31, P1, DOI 10.1057/jit.2014.25
   Shenga YH, 2014, J INTELL FUZZY SYST, V26, P1263, DOI 10.3233/IFS-130812
   Singh S., 2016, J Grid Comput, P1
   Srinivasan V, 2013, J INTELL FUZZY SYST, V24, P555, DOI 10.3233/IFS-2012-0574
   Suk T, 2011, PATTERN RECOGN, V44, P2047, DOI 10.1016/j.patcog.2010.05.015
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   [吴晓光 Wu Xiaoguang], 2004, [计算机工程, Computer Engineering], V30, P124
   Zeng Wanmei, 2009, Electronics Optics & Control, V16, P21
   Zhong LJ, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/205106
NR 37
TC 0
Z9 0
U1 7
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17319
EP 17336
DI 10.1007/s11042-016-4086-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500024
DA 2024-07-18
ER

PT J
AU Nazari, M
   Sharif, A
   Mollaeefar, M
AF Nazari, Mahboubeh
   Sharif, Amir
   Mollaeefar, Majid
TI An improved method for digital image fragile watermarking based on
   chaotic maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fragile watermarking; Chaos; Tempering localization; Image security
ID SCHEME; AUTHENTICATION; COMPRESSION
AB In this paper, the digital image fragile watermarking method based on chaotic maps is proposed. Our method has some significant advantageous in comparison with other available methods. Firstly, we reduce watermark payloads, while they have high quality of recovery and security. In watermark embedding phase, we process the image in order to produce the information array for each block, which finally embedded in the host image to build watermarked image. The information array for each block has different length, which is defined based on block characteristic that could be smooth or rough. The second superiority of the proposed method is proposing a new metric for calculating roughness of image block, which leads to less consume of bandwidth in comparison with other available methods. Finally, we use chaotic map for block-mapping that enhances the security. Our method provides basic requirements of watermarking scheme such as, invisibility, recover quality and security. Experimental Results have proved that our method is powerful in tamper detection, self-recovery and robust against known watermarking attacks.
C1 [Nazari, Mahboubeh] Ferdowsi Univ Mashhad, Dept Math, Mashhad, Iran.
   [Sharif, Amir; Mollaeefar, Majid] Imam Reza Int Univ, Dept Comp & Informat Technol, Mashhad, Iran.
C3 Ferdowsi University Mashhad
RP Nazari, M (corresponding author), Ferdowsi Univ Mashhad, Dept Math, Mashhad, Iran.
EM ma.am.math@gmail.com; amir.sharif@imamreza.ac.ir;
   m.mollaeefar@imamreza.ac.ir
RI Sharif, Amir/Y-7447-2019
OI Sharif, Amir/0000-0001-6290-3588; /0000-0002-0277-3029
CR [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], S CONT SEC DAT HID D
   Arshad H, 2015, J SUPERCOMPUT, V71, P3163, DOI 10.1007/s11227-015-1434-8
   Arshad H, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0259-6
   Arshad H, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0136-8
   Barani MJ, 2015, SECUR COMMUN NETW, V8, P4343, DOI 10.1002/sec.1365
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Chen F, 2014, MULTIMED TOOLS APPL, V72, P41, DOI 10.1007/s11042-012-1332-5
   Fan Chen, 2012, Digital-Forensics and Watermarking 10th International Workshop, IWDW 2011. Revised Selected Papers, P142, DOI 10.1007/978-3-642-32205-1_13
   Gong LH, 2013, J MOD OPTIC, V60, P1074, DOI 10.1080/09500340.2013.831139
   Huo YR, 2012, OPT COMMUN, V285, P1759, DOI 10.1016/j.optcom.2011.12.044
   Hwang HE, 2012, OPT COMMUN, V285, P567, DOI 10.1016/j.optcom.2011.11.007
   Kumari S, 2016, FUTURE GENER COMP SY, V63, P56, DOI 10.1016/j.future.2016.04.016
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Mollaeefar M, 2015, MULTIMEDIA TOOLS APP, P1
   Provos N., 2001, Detecting steganographic content on the internet
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Qin C, 2013, SIGNAL PROCESS, V93, P2687, DOI 10.1016/j.sigpro.2013.03.036
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Saha Chandan, 2016, International Journal of Image, Graphics and Signal Processing, V8, P51, DOI 10.5815/ijigsp.2016.01.06
   Sharif Ami, 2016, MULTIMEDIA TOOLS APP, P1
   Yang CW, 2010, SIGNAL PROCESS, V90, P331, DOI 10.1016/j.sigpro.2009.07.007
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
   Zhou NR, 2011, OPT COMMUN, V284, P3234, DOI 10.1016/j.optcom.2011.02.065
NR 29
TC 28
Z9 29
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16107
EP 16123
DI 10.1007/s11042-016-3897-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100003
DA 2024-07-18
ER

PT J
AU Zhang, SC
   Yang, LF
   Deng, ZY
   Cheng, DB
   Li, YG
AF Zhang, Shichao
   Yang, Lifeng
   Deng, Zhenyun
   Cheng, Debo
   Li, Yonggang
TI Leverage triple relational structures via low-rank feature reduction for
   multi-output regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-output regression; Low-rank regression; Feature selection;
   Orthogonal subspace learning
ID FEATURE-SELECTION; MODEL
AB Multi-output regression aims at learning a mapping from feature variables to multiple output variables. It is significant to utilize variety of inherent relational structure information of observations to conduct multi-output regression task when learning a best mapping from high-dimensional data. In this paper, we propose a new multi-output regression method, which simultaneously takes advantage of the low-rank constraint, sample selection, and feature selection in a unified framework. We first take the effect of low-rank constraint to search the correlation of output variables and impose a"" (2,p) -norm regularization on the coefficient matrix to capture the correlation between features and outputs. And then, the a"" (2,p) -norm on the loss function is designed to discover the correlation between samples, so as to select those informative samples to learn the model for improving predictive capacity. Thirdly, orthogonal subspace learning is exploited to ensure multi-output variables share the same low-rank structure of data by rotating the results of feature selection. In addition, to get the optimal solution of the objective function, we propose an effective iterative optimization algorithm. Finally, we conduct sets of experimental results on real datasets, and show the proposed method outperforms the state-of-the-art methods in terms of aCC and aRMSE.
C1 [Zhang, Shichao; Yang, Lifeng; Deng, Zhenyun; Cheng, Debo; Li, Yonggang] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Guangxi, Peoples R China.
C3 Guangxi Normal University
RP Zhang, SC (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Guangxi, Peoples R China.
EM zhangsc@mailbox.gxnu.edu.cn; 517567113@qq.com; 597277287@qq.com;
   15676209686@163.com; 574717541@qq.com
RI Cheng, Debo/Y-5226-2019; Zhang, Shichao/AAA-7608-2020; Zhang,
   Shichao/JXW-9650-2024
OI Cheng, Debo/0000-0002-0383-1462; Li, Yonggang/0000-0001-7867-9795
FU China "1000-Plan" National Distinguished Professorship; National Natural
   Science Foundation of China [61450001, 61263035, 61573270, 61672177];
   China 973 Program [2013CB329404]; China Key Research Program
   [2016YFB1000905]; Guangxi Natural Science Foundation [2012GXNSFGA060004,
   2015GXNSFCB139011]; Innovation Project of Guangxi Graduate Education
   [YCSZ2016046, YCSZ2016045]; Guangxi Higher Institutions' Program of
   Introducing 100 High-Level Overseas Talents; Guangxi Collaborative
   Innovation Center of Multi-Source Information Integration and
   Intelligent Processing; Guangxi Bagui Scholar Teams for Innovation and
   Research Project
FX This work was supported in part by the China "1000-Plan" National
   Distinguished Professorship; the National Natural Science Foundation of
   China (Grant Nos: 61450001, 61263035, 61573270 and 61672177); the China
   973 Program (Grant No: 2013CB329404); the China Key Research Program
   (Grant No: 2016YFB1000905); the Guangxi Natural Science Foundation
   (Grant Nos: 2012GXNSFGA060004 and 2015GXNSFCB139011); the Innovation
   Project of Guangxi Graduate Education (Grant Nos: YCSZ2016046 and
   YCSZ2016045); the Guangxi Higher Institutions' Program of Introducing
   100 High-Level Overseas Talents; the Guangxi Collaborative Innovation
   Center of Multi-Source Information Integration and Intelligent
   Processing; and the Guangxi Bagui Scholar Teams for Innovation and
   Research Project.
CR ANDERSON TW, 1951, ANN MATH STAT, V22, P327, DOI 10.1214/aoms/1177729580
   [Anonymous], 2004, PROCRUSTES PROBLEMS
   [Anonymous], 2006, Advances in Neural Information Processing Systems, DOI DOI 10.1007/S10994-007-5040-8
   Bache K., UCI machine learning repository
   Borchani H, 2015, WIRES DATA MIN KNOWL, V5, P216, DOI 10.1002/widm.1157
   Cai X, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P1124
   Cai X, 2013, IEEE I CONF COMP VIS, P801, DOI 10.1109/ICCV.2013.104
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Chang XJ, 2014, AAAI CONF ARTIF INTE, P1171
   Cheng B, 2011, IEEE I CONF COMP VIS, P2439, DOI 10.1109/ICCV.2011.6126528
   Dzeroski S, 2000, APPL INTELL, V13, P7, DOI 10.1023/A:1008323212047
   Feng JS, 2014, PROC CVPR IEEE, P3818, DOI 10.1109/CVPR.2014.482
   Gao LL, 2016, AAAI CONF ARTIF INTE, P1188
   Gao LL, 2017, MULTIMEDIA SYST, V23, P303, DOI 10.1007/s00530-015-0494-1
   Gao LL, 2015, PROC CVPR IEEE, P4371, DOI 10.1109/CVPR.2015.7299066
   Izenman A. J., 1975, Journal of Multivariate Analysis, V5, P248, DOI 10.1016/0047-259X(75)90042-1
   Karalic A, 1997, MACH LEARN, V26, P147, DOI 10.1023/A:1007365207130
   Kocev D, 2009, ECOL MODEL, V220, P1159, DOI 10.1016/j.ecolmodel.2009.01.037
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Qin YS, 2007, APPL INTELL, V27, P79, DOI 10.1007/s10489-006-0032-0
   Rai P., 2012, ADV NEURAL INF PROCE, V25, P1
   Rothman AJ, 2010, J COMPUT GRAPH STAT, V19, P947, DOI 10.1198/jcgs.2010.09188
   Shen HF, 2010, IEEE INT CON MULTI, P980, DOI 10.1109/ICME.2010.5583900
   Spyromitros-Xioufis E, 2016, MACH LEARN, P1
   Spyromitros-Xioufis Eleftherios., 2012, Multi-label classification methods for multi-target regression, P1159
   Tuia D, 2011, IEEE GEOSCI REMOTE S, V8, P804, DOI 10.1109/LGRS.2011.2109934
   Wang H, 2011, IEEE I CONF COMP VIS, P557, DOI 10.1109/ICCV.2011.6126288
   Wang S, 2016, SIGNAL PROCESS, V120, P746, DOI 10.1016/j.sigpro.2014.12.012
   Zhang M, 2014, AAAI CONF ARTIF INTE, P1355
   Zhang SC, 2005, IEEE T KNOWL DATA EN, V17, P1689, DOI 10.1109/TKDE.2005.188
   Zhao YC, 2006, IEEE T KNOWL DATA EN, V18, P231, DOI 10.1109/TKDE.2006.30
   Zhu PF, 2015, PATTERN RECOGN, V48, P438, DOI 10.1016/j.patcog.2014.08.006
   Zhu XF, 2016, IEEE T BIO-MED ENG, V63, P607, DOI 10.1109/TBME.2015.2466616
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2013, ACM T INFORM SYST, V31, DOI 10.1145/2457465.2457469
   Zhu XF, 2012, PATTERN RECOGN, V45, P3003, DOI 10.1016/j.patcog.2012.02.007
   Zhu XF, 2011, IEEE T KNOWL DATA EN, V23, P110, DOI 10.1109/TKDE.2010.99
NR 37
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17461
EP 17477
DI 10.1007/s11042-016-3980-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500032
DA 2024-07-18
ER

PT J
AU Lu, GF
   Zou, J
   Wang, Y
   Wang, ZQ
AF Lu, Gui-Fu
   Zou, Jian
   Wang, Yong
   Wang, Zhongqun
TI L1-norm based null space discriminant analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature extraction; Dimensionality reduction; Null space linear
   discriminant analysis; L1-norm based null space linear discriminant
   analysis
ID RECOGNITION
AB Null space based linear discriminant analysis (NSLDA) is a well-known feature extraction method, which can make use of the most discriminant information in the null space of within-class scatter matrix. However, the conventional formulation of NSLDA is based on L2-norm which makes NSLDA be sensitive to outlier. To address the problem of NSLDA, in this paper, we propose a simple and robust NSLDA based on L1-norm (L1-NSLDA). An iterative algorithm for solving L1-NSLDA is also proposed. Compared to NSLDA, L1-NSLDA is more robust than NSLDA since it is more robust to outliers and noise. Experiment results on some image databases confirm the effectiveness of the proposed L1-NSLDA.
C1 [Lu, Gui-Fu; Zou, Jian; Wang, Yong; Wang, Zhongqun] AnHui Polytech Univ, Sch Comp & Informat, Wuhu 241000, Anhui, Peoples R China.
C3 Anhui Polytechnic University
RP Lu, GF (corresponding author), AnHui Polytech Univ, Sch Comp & Informat, Wuhu 241000, Anhui, Peoples R China.
EM luguifu_tougao@163.com
RI Wang, Yong/HLW-0025-2023
OI Wang, Yong/0000-0002-2719-1017
FU NSFC of China [61572033, 71371012, 61672386]; Natural Science Foundation
   of Education Department of Anhui Province of China [KJ2015ZD08]; Program
   for Excellent Youth Talents in University; Social Science and Humanity
   Foundation of the Ministry of Education of China [13YJA630098]; Anhui
   Provincial Natural Science Foundation [1608085MF147]
FX This research is supported by NSFC of China (No. 61572033, 71371012,
   61672386), the Natural Science Foundation of Education Department of
   Anhui Province of China (No. KJ2015ZD08), 2014 Program for Excellent
   Youth Talents in University, the Social Science and Humanity Foundation
   of the Ministry of Education of China (No. 13YJA630098), Anhui
   Provincial Natural Science Foundation (No. 1608085MF147). The authors
   would like to thank the anonymous reviews and the editor for their
   helpful comments and suggestions to improve the quality of this paper.
CR Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Cevikalp H, 2005, IEEE T PATTERN ANAL, V27, P4, DOI 10.1109/TPAMI.2005.9
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Chu DL, 2010, PATTERN RECOGN, V43, P1373, DOI 10.1016/j.patcog.2009.10.004
   Ding C., 2006, P 23 INT C MACH LEAR, P281, DOI DOI 10.1145/1143844.1143880
   Duda R., 1973, Pattern Classification and Scene Analysis
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Howland P, 2006, PATTERN RECOGN, V39, P277, DOI 10.1016/j.patcog.2005.06.013
   Huang R, 2002, INT C PATT RECOG, P29, DOI 10.1109/ICPR.2002.1047787
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Ke Q, 2005, P IEEE C COMP VIS PA, P1
   Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114
   Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852
   Li HF, 2004, ADV NEUR IN, V16, P97
   Li X, 2010, NEUROCOMPUTING, V73, P2571, DOI 10.1016/j.neucom.2010.05.016
   Li XL, 2010, IEEE T SYST MAN CY B, V40, P1170, DOI 10.1109/TSMCB.2009.2035629
   Lu GF, 2013, NEURAL NETWORKS, V46, P165, DOI 10.1016/j.neunet.2013.05.010
   Nie F., 2011, P 22 INT JOINT C ART, P1
   Pang YW, 2010, IEEE T CIRC SYST VID, V20, P172, DOI 10.1109/TCSVT.2009.2020337
   Wang HX, 2014, IEEE T CYBERNETICS, V44, P828, DOI 10.1109/TCYB.2013.2273355
   Wang HX, 2012, IEEE T BIO-MED ENG, V59, P653, DOI 10.1109/TBME.2011.2177523
   Zheng WM, 2014, IEEE T NEUR NET LEAR, V25, P793, DOI 10.1109/TNNLS.2013.2281428
   Zhong FJ, 2013, IEEE T IMAGE PROCESS, V22, P3018, DOI 10.1109/TIP.2013.2253476
NR 23
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15801
EP 15816
DI 10.1007/s11042-016-3870-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900026
DA 2024-07-18
ER

PT J
AU Xu, WD
   Yang, JT
   Xu, ZZ
AF Xu Weidong
   Yang Juntang
   Xu Zhongze
TI The detection algorithm of irregular dynamic objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ocean background; Dynamic objects; Irregular patches; Image detection
AB Using remote sensing data for marine monitoring, marine rescue, marine pollution monitoring which has a broad monitoring area and fast response time, so in the last 10 years, satellite borne or airborne optical and SAR sensor data have been increasingly used in the field of ocean monitoring. However, based on the dynamic video to carry out the study of the detection of irregular debris blocks from the wrecked ship, aircraft is less. To a great extent, it affects the efficiency of maritime rescue. This paper, based on the dynamic objects detection, Color Space Quantization and property of Human Vision System, takes the irregular wreckage patches as research. And a detection algorithm for dynamic objects is developed with the foundation of Lab channels. To verify that, the calculation of the Euclidean distance between the characteristic parameters of irregular wreckage patches and regular floating ones, and the average Euclidean distance is 0.8245 between the irregular1 and the regular while that between irregular2 and the regular is 4.3645. At the same time, the Hausdorff distance was calculated and verified, and the average distance between the irregular block 1 and the regular block was 2.5975. The average distance between the block 2 and the rule block was 13.8962. Experimental results show that the method is consistent with the results of the second methods, which proves that the first method is scientific and operational. Therefore, it can be found that some parameters including divergence, elongation and eccentricity fluctuate dramatically from those in irregular ones to the regular one, which could be extracted to recognize or distinguish the patches. That is why this paper is of importance in marine rescue and detection of objects on the sea surface.
C1 [Xu Weidong; Yang Juntang] PLA Univ Sci & Technol, Nanjing, Jiangsu, Peoples R China.
   [Xu Zhongze] Nanjing Univ Technol, Nanjing, Jiangsu, Peoples R China.
C3 Army Engineering University of PLA; Nanjing Tech University
RP Yang, JT (corresponding author), PLA Univ Sci & Technol, Nanjing, Jiangsu, Peoples R China.
EM xweibing1968@aliyun.com; yangjt12605@aliyun.com; 434581040@QQ.com
RI Xu, Zhongze/GLU-8416-2022
OI Xu, Zhongze/0000-0002-2564-5118
CR Attilio G, 2012, IEEE GEOSCI REMOTE S, V5, P760
   CAO X, 2015, J ELECT TECHNOLOGY, V4, P91
   Coelho LDS, 2012, CHAOS SOLITON FRACT, V37, P1607
   Crisp DJ, 2012, IEEE GEOSCI REMOTE S, V2, P201
   He H, 2012, ADV SCI LETT, V11, P606
   HOU L, 2013, FOREIGN ELECT MEASUR, V32, p23~27
   Jun L, 2014, J COMPUTER SCI ENG, V3, P1
   Junying Z, 2012, INFRARED TECHNOLOGY, V30, P373
   Kaplan LM, 2012, IEEE T AERO ELEC SYS, V37, P436
   Liao MS, 2013, IEEE GEOSCI REMOTE S, V5, P632
   LING H, 2011, P 2011 IEEE 12 INT C, V12, p1537~1539
   Liu D, 2014, J COMPUT SCI ENG, V21, P110
   Nazhi TQZ, 2013, INFRARED TECHNOL, V25, P54
   Pan B, 2013, APPL OPTICS, V49, P234
   Run Z, 2012, NANJING U INFORM ENG, V15, P84
   Sun Q, 2013, COMPUT DIGIT ENG, V4, P134
   Tommy D, 2013, J MARINE SYST, V12, P41
   [王展 Wang Zhan], 2013, [兵工学报, Acta Armamentarii], V34, P1250
   Xu L, 2013, J HUANGZHONG U SCI T, V41, P220
   Xu Z, 2016, CLUSTER COMPUT, V19, P1283, DOI 10.1007/s10586-016-0581-x
   Xu Z, 2016, MULTIMED TOOLS APPL, V75, P12155, DOI 10.1007/s11042-015-3112-5
   Xu Z, 2015, J SYST SOFTWARE, V102, P217, DOI 10.1016/j.jss.2014.07.024
   YU J, 2015, COMPUTER DIGITAL ENG, V49, p494~498
   Yuantao C, 2012, J CONVERG INF TECHNO, V7, P218
   Zhao YQ, 2012, 2012 IEEE 11 INT C, V11, P1252
NR 25
TC 1
Z9 1
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14599
EP 14615
DI 10.1007/s11042-016-3810-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400004
DA 2024-07-18
ER

PT J
AU Shen, G
   Liu, F
   Fu, ZX
   Yu, B
AF Shen, Gang
   Liu, Feng
   Fu, Zhengxin
   Yu, Bin
TI New insight into linear algebraic technique to construct visual
   cryptography scheme for general access structure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptography; Basis matrices; Linear algebra; More equations;
   Common columns
ID CONTRAST
AB The most essential advantage of applying linear algebra to construct visual cryptography scheme (VCS) lies in that it only requires solving linear equations in the construction of initial basis matrices, which are the basis matrices before removing the common columns. In this paper, we give some new insight into linear algebraic technique to construct VCS, where we can take more equations simultaneously. Then based on this knowledge, we propose a construction of VCS for general access structure. The construction is efficient in the sense that it gets the smallest initial pixel expansion compared with some well-known constructions. At the same time, by using the technique of deleting common columns from the initial basis matrices, the proposed construction achieves the optimal pixel expansions in most cases according to our experimental results. However, finding exact number of common columns in the initial basis matrices is a challenging issue. Then we deal with this issue and find out that the exact number of common columns is n - 2 for (2, n) threshold access structures. Finally, we provide some future research directions in the algebraic aspect of VCS.
C1 [Shen, Gang; Fu, Zhengxin] Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Peoples R China.
   [Yu, Bin] Zhengzhou Informat Sci & Technol Inst, Dept Comp Sci & Informat Engn, Zhengzhou, Peoples R China.
   [Liu, Feng] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
   [Liu, Feng] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.
C3 PLA Information Engineering University; PLA Information Engineering
   University; Chinese Academy of Sciences; Institute of Information
   Engineering, CAS; Chinese Academy of Sciences; University of Chinese
   Academy of Sciences, CAS
RP Shen, G (corresponding author), Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Peoples R China.
EM shengang_zisti@163.com
RI Fu, Zhengxin/AAD-7881-2019; liu, feng/B-3050-2019
OI Fu, Zhengxin/0000-0001-8587-0942; 
FU National Natural Science Foundation of China [61602513, 61671448];
   Chinese Academy of Sciences [XDA06010701]
FX The authors would like to thank the anonymous reviewers for their
   helpful and constructive comments that improved the clarity and quality
   of this paper. This work was supported by the National Natural Science
   Foundation of China (Grant No.61602513 and No.61671448) and the
   Strategic Priority Research Program of the Chinese Academy of Sciences
   (Grant No.XDA06010701).
CR Adhikari A, 2014, DESIGN CODE CRYPTOGR, V73, P865, DOI 10.1007/s10623-013-9832-5
   Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Blundo C, 1999, J CRYPTOL, V12, P261, DOI 10.1007/s001459900057
   Blundo C, 2003, SIAM J DISCRETE MATH, V16, P224, DOI 10.1137/S0895480198336683
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Cimato S, 2005, DESIGN CODE CRYPTOGR, V35, P311, DOI 10.1007/s10623-003-6741-z
   Dutta S, 2016, DESIGN CODE CRYPTOGR, V80, P165, DOI 10.1007/s10623-015-0075-5
   Guo T, 2014, LECT NOTES COMPUT SC, V8317, P56, DOI 10.1007/978-3-319-04268-8_4
   Hou YC, 2013, INFORM SCIENCES, V233, P290, DOI 10.1016/j.ins.2013.01.006
   Hu CM, 2007, IEEE T IMAGE PROCESS, V16, P36, DOI 10.1109/TIP.2006.884916
   Liu F, 2011, IET INFORM SECUR, V5, P51, DOI 10.1049/iet-ifs.2008.0064
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Peng Li, 2012, ICIC Express Letters, V6, P2033
   Shyu SJ, 2015, IEEE T CIRC SYST VID, V25, P1557, DOI 10.1109/TCSVT.2015.2389372
   Shyu SJ, 2013, IEEE T INF FOREN SEC, V8, P733, DOI 10.1109/TIFS.2013.2250432
   Shyu SJ, 2011, IEEE T INF FOREN SEC, V6, P960, DOI 10.1109/TIFS.2011.2158096
   Wang DS, 2009, PATTERN RECOGN, V42, P3071, DOI 10.1016/j.patcog.2009.02.015
   Wu XT, 2013, IEEE T INF FOREN SEC, V8, P1541, DOI 10.1109/TIFS.2013.2274955
   Yamaguchi Yasushi, 2012, Digital-Forensics and Watermarking 10th International Workshop, IWDW 2011. Revised Selected Papers, P228, DOI 10.1007/978-3-642-32205-1_19
   Yan WQ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 5, PROCEEDINGS, P572
   Yan XH, 2015, DIGIT SIGNAL PROCESS, V38, P53, DOI 10.1016/j.dsp.2014.12.002
   Yang CN, 2012, IEEE T CIRC SYST VID, V22, P799, DOI 10.1109/TCSVT.2011.2180952
   Yang CN, 2006, PATTERN RECOGN, V39, P1300, DOI 10.1016/j.patcog.2006.01.013
   Yu B, 2014, MULTIMED TOOLS APPL, V72, P1867, DOI 10.1007/s11042-013-1479-8
NR 24
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 14511
EP 14533
DI 10.1007/s11042-016-3867-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800036
DA 2024-07-18
ER

PT J
AU Sakamoto, M
   Nakajima, T
   Akioka, S
AF Sakamoto, Mizuki
   Nakajima, Tatsuo
   Akioka, Sayaka
TI Gamifying collective human behavior with gameful digital rhetoric
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital rhetoric; Design framework; Social infrastructure; Collective
   human behavior; Social influence; Sustainable society; Gamification;
   Crowdsourcing
AB This paper presents a design framework called Gameful Digital Rhetoric that offers a set of design frames for designing meaningful digital rhetoric that guides collective human behavior in ubiquitous social digital services, such as crowdsourcing. The framework is extracted from our experiences with building and developing crowdsourcing case studies. From a video game perspective, the paper has categorized our experiences into seven design frames to encourage collective human activity. This approach is different from traditional gamification, as it focuses more on the semiotic aspect of virtuality in the video games, not game mechanics; it helps to enhance the current meaning of the real world for changing human attitude and behavior through various socio-cultural and psychological techniques. Therefore, it is possible to discuss respective design frames for enhancing crowdsourcing by incrementally adding new digital rhetoric. The paper also presents how Gameful Digital Rhetoric allows us to guide collective human behavior in Collectivist Crowdsourcing; the design is explained through a scenario-based and experiment-based analyses. The paper then discusses how to design collective human behavior with Gameful Digital Rhetoric and how to identify the design's potential pitfalls. Our approach offers useful insights into the design of future social digital services that influence collective human behavior.
C1 [Sakamoto, Mizuki; Nakajima, Tatsuo] Waseda Univ, Dept Comp Sci & Engn, Shinjuku Ku, Tokyo, Japan.
   [Akioka, Sayaka] Meiji Univ, Dept Network Design, Tokyo, Japan.
C3 Waseda University; Meiji University
RP Nakajima, T (corresponding author), Waseda Univ, Dept Comp Sci & Engn, Shinjuku Ku, Tokyo, Japan.
EM tatsuo@dcl.cs.waseda.ac.jp
CR [Anonymous], P IPP 2014 CROWDS PO
   [Anonymous], 2015, How's life? 2015: Measuring well-being
   [Anonymous], P 25 INT C DAT EXP S
   [Anonymous], 2014, 25 ACM C HYP SOC MED
   [Anonymous], 2008, NEW
   [Anonymous], P 13 INT C ADV MOB C
   [Anonymous], 2012, Thinking fast and slow
   [Anonymous], P 11 INT C UB COMP
   [Anonymous], 2013, GET PEOPLE STUFF MAS
   [Anonymous], P 2011 ACM C COMP SU
   [Anonymous], P 26 INT C HUM FACT
   [Anonymous], P DRS 2014 DES BIG D
   [Anonymous], P 49 ANN HAW INT C S
   [Anonymous], P 4 INT C DISTR AMB
   [Anonymous], MINDSPACE INFL BEH P
   [Anonymous], 2013, PROC CHI 2013
   [Anonymous], 2009, PERVASIVE GAMES THEO
   [Anonymous], 2013, P INT C MOB UB MULT
   [Anonymous], P DIGRA 2009 BREAK N
   [Anonymous], LNCS
   [Anonymous], P INT C DIGRA 2007
   [Anonymous], P 31 INT C HUM FACT
   [Anonymous], POSTMODERN 2 BORN AN
   [Anonymous], P INT C INT POL POL
   [Anonymous], P 29 INT C HUM FACT
   [Anonymous], THESIS
   [Anonymous], P 18 INT C MOB COMP
   [Anonymous], 2011, P AAAI WORKSH HUM CO
   [Anonymous], P INT C HUM FACT COM
   [Anonymous], UNDERSTANDING AM INT
   [Anonymous], DESIGN FICTIONAL INT
   [Anonymous], ENVIRON MONIT ASSESS
   [Anonymous], 2009, 473209 MIT SLOAN SCH
   [Anonymous], 2011, P INT AAAI C WEB SOC
   [Anonymous], ENRICHING URBAN SPAC
   [Anonymous], Q J EC
   [Anonymous], INT J HUMANITIES SOC
   [Anonymous], NATURAL EC ORDER
   [Anonymous], P 31 INT C HUM FACT
   Antikainen Maria J., 2010, International Journal of Entrepreneurship and Innovation Management, V11, P440, DOI 10.1504/IJEIM.2010.032267
   Bogost I., 2007, PERSUASIVE GAMES
   Chandler D, 2013, J ECON BEHAV ORGAN, V90, P123, DOI 10.1016/j.jebo.2013.03.003
   Cialdini R.B., 2006, INFLUENCE PSYCHOL PE
   Deci E.L., 1980, The psychology of self-determination
   Desmet PMA, 2013, INT J DES, V7, P5
   Deterding S., 2011, P 15 INT AC MINDTREK, P9, DOI [10.1145/2181037.2181040, DOI 10.1145/2181037.2181040]
   Deterding S, 2015, HUM-COMPUT INTERACT, V30, P294, DOI 10.1080/07370024.2014.993471
   Ducatel K., 2001, SCENARIOS AMBIENT IN
   Dunne Anthony, 2013, SPECULATIVE EVERYTHI, DOI DOI 10.1093/JDH/EPV001
   Fahey L., 1997, Learning from the future: Competitive foresight scenarios
   Frasca G., 2007, Tese (Doutorado em Filosofia)
   Galbraith PatrickW., 2011, Game Studies, V11
   Gerber ElizabethM., 2012, Proceedings of the International Workshop on Design, Influence, and Social Technologies: Techniques, Impacts and Ethics, V2
   Glas R., 2013, Transactions of the Digital Games Research Association, V1, P1
   Hamari J, 2017, COMPUT HUM BEHAV, V71, P469, DOI 10.1016/j.chb.2015.03.036
   Huotari K., 2012, P 16 INT AC MINDTREK, P17
   Huotari K, 2017, ELECTRON MARK, V27, P21, DOI 10.1007/s12525-015-0212-z
   Ipeirotis Panagiotis G., 2010, XRDS: Crossroads, V17, P16, DOI [10.1145/1869086.1869094, DOI 10.1145/1869086.1869094]
   Jordan P.W., 2002, Designing pleasurable products: An introduction to the new human factors
   Juul J., 2005, HALF REAL VIDEO GAME
   Kirby D, 2010, SOC STUD SCI, V40, P41, DOI 10.1177/0306312709338325
   Layous K., 2014, Positive emotion: Integrating the light sides and dark sides, P473, DOI [DOI 10.1093/ACPROF:OSO/9780199926725.003.0025, 10.1093/acprof:oso/9780199926725.003.0025]
   Lehdonvirta V., 2014, Virtual Economies: Design and Analysis (Information Policy)
   Lindley J., 2015, P 11 EUR AC DES C
   Liu Y., 2013, P 22 INT C WORLD WID, P803, DOI DOI 10.1145/2488388.2488458
   Mayer FrederickW., 2014, Narrative Politics: Stories and Collective Action
   McGonical Jane., 2011, REALITY IS BROKEN WH
   McGonigal Kelly., 2013, WILLPOWER INSTINCT S
   Midden C., 2011, P 6 INT C PERS TECHN
   Miller J., 2003, Game theory at work: How to use game theory to outthink and outmaneuver your competition
   Nakajima T, 2013, PERS UBIQUIT COMPUT, V17, P107, DOI 10.1007/s00779-011-0469-y
   Nicholson S., 2012, P GAMES LEARNING SOC
   Olson Judith S., 2014, Knowing in HCI, P167, DOI [DOI 10.1007/978-1-4939-0378-8_8, 10.1007/978-1-4939-0378-8_8]
   Olson M., 1965, The logic of collective action, V124
   Paul CL, 2008, J USABILITY STUD, V4, P7
   Ryan RM, 2000, CONTEMP EDUC PSYCHOL, V25, P54, DOI 10.1006/ceps.1999.1020
   Sakamoto M, 2016, MULTIMED TOOLS APPL, V75, P8289, DOI 10.1007/s11042-015-2751-x
   Sakamoto M, 2015, LECT NOTES COMPUT SC, V9186, P654, DOI 10.1007/978-3-319-20886-2_61
   Sakamoto M, 2015, MULTIMED TOOLS APPL, V74, P11537, DOI 10.1007/s11042-014-2250-5
   Schwartz Barry., 2005, The Paradox of Choice: Why More Is Less
   Seligman M. E. P., 2011, Flourish: A visionary new understanding of happiness and wellbeing, DOI DOI 10.5860/CHOICE.48-7217
   Sen A., 1974, PRACTICAL REASON, P54
   Spagnolli A, 2016, INT J HUM-COMPUT INT, V32, P177, DOI 10.1080/10447318.2016.1142798
   Sun YQ, 2011, COMPUT HUM BEHAV, V27, P1033, DOI 10.1016/j.chb.2010.12.007
   Teasdale, 2002, MINDFULNESS BASED CO
   Todd PM, 2007, EUR J OPER RES, V177, P1317, DOI 10.1016/j.ejor.2005.04.005
   von Ahn L, 2008, COMMUN ACM, V51, P58, DOI 10.1145/1378704.1378719
   WEBER M, 1987, EUR J OPER RES, V28, P44, DOI 10.1016/0377-2217(87)90168-8
   Wolfe A.K., 2014, Behavioral Change and Building Performance: Strategies for Significant, Persistent, and Measurable Institutional Change
   Zuckerman O, 2014, PERS UBIQUIT COMPUT, V18, P1705, DOI 10.1007/s00779-014-0783-2
NR 90
TC 13
Z9 14
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12539
EP 12581
DI 10.1007/s11042-016-3665-y
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200017
DA 2024-07-18
ER

PT J
AU Xing, N
   Zhang, JQ
AF Xing, Nan
   Zhang, Jianqi
TI Graphical-character-based shredded Chinese document reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Document recovery; Text graphic; Piece matching; Digital forensics
AB Paper documents are shredded into pieces by a shredder in what is currently a common means of ensuring text information security. Because such pieces have certain characteristics, such as being of large number and low discrimination, shredded document reconstruction by a reverse operation represents a challenge. However, recovering shredded documents is an important research aspect of digital forensics and has broad applicability in information security and judicial investigations. Researchers have proposed various feasible algorithms to restore shredded documents; however, most such algorithms are aimed at western language documents. Because of large differences between languages, these algorithms are difficult to apply to other language document reconstruction tasks directly. The Chinese language is used worldwide. Chinese documents are also widely used; accordingly, there are great demands for Chinese document reconstruction. This paper presents a complete shredded Chinese document reconstruction algorithm. According to the structural features of the characters, we apply graphics processing to the texts in pieces, the pieces are matched by graph assembling, and the shredded document is restored. We test the algorithm's performance using an actual sample, and the experimental results show that the proposed method can effectively restore the shredded document. The average obtained accuracy is 85.78 %. Moreover, the algorithm is highly intelligent; a human only participates in the step that involves scanning the pieces, and the other calculation steps are automatically completed by the computer.
C1 [Xing, Nan; Zhang, Jianqi] Xidian Univ, Sch Phys & Optoelect Engn, Xian 710071, Peoples R China.
C3 Xidian University
RP Xing, N (corresponding author), Xidian Univ, Sch Phys & Optoelect Engn, Xian 710071, Peoples R China.
EM xingnan@xaut.edu.cn; jqzhang@mail.xidian.edu.cn
FU Xidian University; Xi'an University of Technology
FX Support for this program is provided by Xidian University. Additional
   support has been provided by Xi'an University of Technology.
CR [Anonymous], 2009, THESIS
   Biswas A., 2005, P INT C IM PROC ICIP, P517, DOI [10.1109/ICIP.2005.1530442, DOI 10.1109/ICIP.2005.1530442]
   Butler P, 2012, IEEE CONF VIS ANAL, P113, DOI 10.1109/VAST.2012.6400560
   Chan AHS, 2014, HUM FACTORS, V56, P521, DOI 10.1177/0018720813499368
   Cheng H.J., 2015, THESIS
   De Smet P, 2005, P SOC PHOTO-OPT INS, V5685, P239, DOI 10.1117/12.586340
   FREEMAN H, 1964, IEEE T COMPUT, VEC13, P118, DOI 10.1109/PGEC.1964.263781
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   HARWOOD D, 1987, PATTERN RECOGN LETT, V6, P155, DOI 10.1016/0167-8655(87)90002-X
   Justino E, 2006, FORENSIC SCI INT, V160, P140, DOI 10.1016/j.forsciint.2005.09.001
   Li P, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/514748
   Lin HY, 2012, EXPERT SYST APPL, V39, P3324, DOI 10.1016/j.eswa.2011.09.019
   McClelland J L, 1986, Parallel distributed processing
   Ng HF, 2006, PATTERN RECOGN LETT, V27, P1644, DOI 10.1016/j.patrec.2006.03.009
   Pan G, 2006, THESIS
   Perl J, 2011, P 4 INT C IM CRIM DE, P35, DOI [10.1049/ic.2011.0132, DOI 10.1049/IC.2011.0132]
   Pimenta A, 2009, INT CONF ACOUST SPEE, P1393, DOI 10.1109/ICASSP.2009.4959853
   Skeoch  A., 2006, THESIS
   Tsamoura E, 2010, IEEE T IMAGE PROCESS, V19, P680, DOI 10.1109/TIP.2009.2035840
   Ukovich A, 2004, PROCEEDINGS OF THE FOURTH IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, P334, DOI 10.1109/ISSPIT.2004.1433788
   Ukovich A., 2007, THESIS
   Ukovich A, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2898551
   Zhang H, 2012, P WORKSH 26 AAAI C A, P121
   Zhao B, 2014, PROC INT C TOOLS ART, P1016, DOI 10.1109/ICTAI.2014.154
   Zhu LJ, 2008, IEEE T PATTERN ANAL, V30, P1, DOI 10.1109/TPAMI.2007.1163
NR 25
TC 8
Z9 9
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12871
EP 12891
DI 10.1007/s11042-016-3685-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200031
DA 2024-07-18
ER

PT J
AU Fati, SM
   Sumari, P
AF Fati, Suliman Mohamed
   Sumari, Putra
TI Content-aware replica placement strategy for IPTV services over
   peer-service area architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Replica placement; Content status; Load balancing; IPTV delivery
   networks; Hybrid genetic algorithm; Heuristic repair algorithm
ID GENETIC ALGORITHM; VIDEO REPLICATION; STORAGE CAPACITY; ALLOCATION;
   OPTIMIZATION; HEURISTICS; INTERNET; CLUSTER
AB Due to the enormous improvement in networking and multimedia, IPTV has become recently a popular means to distribute high quality TV services over IP networks. Accordingly, Telecommunication companies started the competition to provide IPTV services to increase their customer base and profit. The key concern of service providers in this hectic competition is to provide high quality service with lower cost. However, the contents' popularity and the users' preferences are fluctuated rapidly, which leads to resources waste and load imbalance. Thus, the contents' status should be considered during the content replication to save resources and reduce service cost. To the best of our knowledge, there is no work investigate the impact of contents' status on building Replica Placement Strategy. Therefore, this paper studies the impact of contents' status on replica placement strategy over the peer-service area architecture. Two optimization models are proposed Cost Effective Model (CE), which replicates the contents partially without considering contents' status and Cost Effective with Load Balance model (CELB), which considers the contents' status. Both models have been solved using Hybrid Genetic Algorithm. The experimental results show that CELB model outperforms the other models in terms of Storage Saving Ratio (SSR), load distribution, and allocation cost.
C1 [Fati, Suliman Mohamed] Univ Tunku Abdulrahman, Fac Informat Commun & Technol, Kampar, Malaysia.
   [Sumari, Putra] Univ Sains Malaysia, Sch Comp Sci, Multimedia Res Grp, P Penang 11800, Malaysia.
C3 Universiti Sains Malaysia
RP Fati, SM (corresponding author), Univ Tunku Abdulrahman, Fac Informat Commun & Technol, Kampar, Malaysia.
EM smfati@yahoo.com
RI Fati, Suliman Mohamed/W-9547-2018; Sumari, Putra/I-1070-2016
OI Sumari, Putra/0000-0002-2644-6428; Fati, Suliman/0000-0002-6969-2338
CR Aldana Diaz ME, 2011, P 5 ACM INT C UB INF, P114
   [Anonymous], HPL2002
   [Anonymous], 1989, GENETIC ALGORITHM SE
   [Anonymous], THESIS
   [Anonymous], 2010, P ACM MM WORKSH SOC
   Bektas T, 2008, COMPUT OPER RES, V35, P3860, DOI 10.1016/j.cor.2007.02.005
   Bisdikian CC, 1996, IEEE MULTIMEDIA, V3, P62, DOI 10.1109/93.556540
   Bolosky WJ, 1996, MSRTR9609
   Bowen Y, 2011, AM J ENG TECHNOL RES, V11, P2429
   Brubeck DW, 1996, IEEE MULTIMEDIA, V3, P37, DOI 10.1109/93.556538
   Cheng-Fu Chou, 2000, Proceedings 20th IEEE International Conference on Distributed Computing Systems, P64, DOI 10.1109/ICDCS.2000.840908
   Choi KMF, 1998, PROC INT C TOOLS ART, P166, DOI 10.1109/TAI.1998.744838
   Cholvi V, 2008, COMPUT COMMUN, V31, P3604, DOI 10.1016/j.comcom.2008.06.012
   Cidon I, 2002, COMPUT NETW, V40, P205, DOI 10.1016/S1389-1286(02)00251-7
   Codognet Philippe., 2001, SAGA 01, P73
   Llopis LJD, 2012, COMPUT COMMUN, V35, P993, DOI 10.1016/j.comcom.2012.02.015
   Du ZH, 2011, J SYST SOFTWARE, V84, P1224, DOI 10.1016/j.jss.2011.02.038
   Dukes J, 2004, LECT NOTES COMPUT SC, V3311, P194
   Ebara H, 2005, IEICE T COMMUN, VE88B, P4598, DOI 10.1093/ietcom/e88-b.12.4598
   El-Mihoub T. A., 2006, Engineering Letters, V13, P124
   Fati S, 2015, INT J COMPUT APPL, V131, P21
   Gaber SMA, 2014, MULTIMED TOOLS APPL, V70, P1987, DOI 10.1007/s11042-012-1209-7
   Gafsi J, 2000, IEEE T PARALL DISTR, V11, P412, DOI 10.1109/71.850836
   Ganger G. R., 1993, Proceeding of the Twenty-Sixth Hawaii International Conference on System Sciences (Cat. No.93TH0501-7), P40, DOI 10.1109/HICSS.1993.270759
   Gkatzikis L, 2015, IEEE ICC, P5872, DOI 10.1109/ICC.2015.7249258
   Guo J, 2008, IEEE T KNOWL DATA EN, V20, P836, DOI 10.1109/TKDE.2007.190742
   Hei XJ, 2007, IEEE T MULTIMEDIA, V9, P1672, DOI 10.1109/TMM.2007.907451
   Henny Bekker H, 2000, VIPD31C2 SURFN
   Ho KM, 2010, INT J DIGIT MULTIMED, V2010, DOI 10.1155/2010/645049
   Huang C, 2007, ACM SIGCOMM COMP COM, V37, P133, DOI 10.1145/1282427.1282396
   Jing Sun, 2011, Journal of Networks, V6, P416, DOI 10.4304/jnw.6.3.416-423
   Joe I, 2011, COMM COM INF SC, V262, P28
   Karlsson M, 2004, INT CON DISTR COMP S, P350, DOI 10.1109/ICDCS.2004.1281600
   Khan SU, 2008, J PARALLEL DISTR COM, V68, P113, DOI 10.1016/j.jpdc.2007.06.009
   Kim C, 2006, 8 INT C ADV COMM TEC, V2, P1147
   Kokash Natalia., 2005, An introduction to heuristic algorithms
   Konak A, 2007, OMEGA-INT J MANAGE S, V35, P645, DOI 10.1016/j.omega.2006.04.010
   Konak A, 2006, OPER RES LETT, V34, P660, DOI 10.1016/j.orl.2005.09.009
   Kulatunga C, 2011, P INT C COMM ICC 11, P1
   Laoutaris N, 2005, COMPUT NETW, V47, P409, DOI 10.1016/j.comnet.2004.07.020
   Lee JYB, 2000, IEEE T PARALL DISTR, V11, P1217, DOI 10.1109/71.895790
   Lee SB, 2009, IEEE T BROADCAST, V55, P516, DOI 10.1109/TBC.2009.2015985
   Li MF, 2010, COMPUT COMMUN, V33, P83, DOI 10.1016/j.comcom.2009.08.003
   Lie PWK, 2000, MULTIMED TOOLS APPL, V11, P35, DOI 10.1023/A:1009673332611
   Lin YD, 1996, CONF LOCAL COMPUT NE, P355, DOI 10.1109/LCN.1996.558164
   Little T., 1993, LECT NOTES COMPUTER, P204
   Loukopoulos T, 2004, J PARALLEL DISTR COM, V64, P1270, DOI 10.1016/j.jpdc.2004.04.005
   Maaranen H, 2007, J GLOBAL OPTIM, V37, P405, DOI 10.1007/s10898-006-9056-6
   Mahmood A, 2010, INFORM PROCESS MANAG, V46, P170, DOI 10.1016/j.ipm.2009.06.006
   Montpetit MJ, 2011, MULTIMED TOOLS APPL, V53, P519, DOI 10.1007/s11042-010-0504-4
   Montpetit MJ, 2010, HUM-COMPUT INT-SPRIN, P305, DOI 10.1007/978-1-84882-701-1_21
   Nafaa A, 2008, IEEE COMMUN MAG, V46, P47, DOI 10.1109/MCOM.2008.4689207
   Neves T.A., 2010, ELECT NOTES DISCRETE, V36, P89
   NUSSBAUMER JP, 1995, IEEE J SEL AREA COMM, V13, P779, DOI 10.1109/49.391753
   NWOSU KC, 1995, CONFERENCE PROCEEDINGS OF THE 1995 IEEE FOURTEENTH ANNUAL INTERNATIONAL PHOENIX CONFERENCE ON COMPUTERS AND COMMUNICATIONS, P629, DOI 10.1109/PCCC.1995.472427
   Osorio-Hernández LG, 2009, IEEE C EVOL COMPUTAT, P1422, DOI 10.1109/CEC.2009.4983110
   Salcedo-Sanz S, 2009, COMPUT SCI REV, V3, P175, DOI 10.1016/j.cosrev.2009.07.001
   Saxena D, 2016, COMPUT SCI REV
   Scheuermann P, 1998, VLDB J, V7, P48, DOI 10.1007/s007780050053
   Sujatha DN, 2008, LECT NOTES COMPUT SC, V4904, P478
   Tang KS, 2001, IEEE T IND ELECTRON, V48, P891, DOI 10.1109/41.954552
   Tang XY, 2005, IEEE T PARALL DISTR, V16, P921, DOI 10.1109/TPDS.2005.126
   Tenzakhti F, 2004, J SYST ARCHITECT, V50, P591, DOI 10.1016/j.sysarc.2003.12.003
   Tsao SL, 1999, J VIS COMMUN IMAGE R, V10, P197, DOI 10.1006/jvci.1999.0420
   Vinay A, 2011, P INT C ICWET, P344
   WAH BW, 1984, IEEE COMPUT, V17, P23
   Wang YW, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P102, DOI 10.1109/MMCS.1997.609580
   Wang Z, 2012, J SUPERCOMPUT, V62, P227, DOI 10.1007/s11227-011-0708-z
   Wauters T, 2006, COMPUT COMMUN, V29, P3313, DOI 10.1016/j.comcom.2006.05.008
   WOLF J, 1989, PERF E R SI, V17, P1, DOI 10.1145/75372.75373
   Xinjie Yu., 2010, Introduction to Evolutionary Algorithms
   Yarali A., 2005, INTERNET PROTOCOL TE, P1
   Zaman S, 2011, IEEE T PARALL DISTR, V22, P1455, DOI 10.1109/TPDS.2011.27
   Zhiyong X, 2005, GLOB TEL C 2005 GLOB, P866
   Zhou XB, 2002, PROC INT CONF PARAL, P547, DOI 10.1109/ICPP.2002.1040912
   Zhou XB, 2007, J NETW COMPUT APPL, V30, P515, DOI 10.1016/j.jnca.2006.03.001
   Zhu L, 2003, C INF SCI SYST CISS
NR 77
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 10041
EP 10065
DI 10.1007/s11042-016-3593-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300042
DA 2024-07-18
ER

PT J
AU Hsu, CH
   Cheng, WH
   Hua, KL
AF Hsu, Che-Hao
   Cheng, Weng-Huang
   Hua, Kai-Lung
TI HoloTabletop: an anamorphic illusion interactive holographic-like
   tabletop system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Holographic display; Anamorphic illusion; Head pose estimation; Mid-air
   interactiont
AB HoloTabletop is a low-cost holographic-like tabletop interactive system. This system analyzes user's head position and gaze location in a real time setting and computes the corresponding anamorphic illusion image. The anamorphic illusion image is displayed on a 2D horizontally-located monitor, yet offers stereo vision to the user. The user is able to view and interact with the 3D virtual objects without wearing any special glasses or devices. The experimental results and user studies verify that the proposed HoloTabletop system offers excellent stereo vision while no visual fatigue will be caused to human eyes. This system is a great solution for many interactive applications such as 3D board games and stereo map browsing.
C1 [Hsu, Che-Hao; Hua, Kai-Lung] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
   [Cheng, Weng-Huang] Acad Sinica, Res Ctr Informat Technol Innovat CITI, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology; Academia Sinica -
   Taiwan
RP Hua, KL (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
EM hua@mail.ntust.edu.tw
RI Cheng, Wen-Huang/AAK-2774-2020
OI Hua, Kai-Lung/0000-0002-7735-243X
CR [Anonymous], 2013, Proceedings of the 2013 ACM annual conference on Human factors in computing systems (CHI '13), DOI DOI 10.1145/2470654.2466191
   [Anonymous], 2010, PATTERN RECOGN
   [Anonymous], 2015, OPENCV3 CAMERA CALIB
   [Anonymous], 2014, ACM SIGGRAPH 2014 PO, DOI DOI 10.1145/2614217.2630585
   Bai H, 2013, 2013 IEEE INT S MIX, P1
   Benko Hrvoje., 2012, P SIGCHI C HUMAN FAC, P199, DOI DOI 10.1145/2207676.2207704
   Bogdan N, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P51, DOI 10.1109/3DUI.2014.6798842
   Borst CW, 2013, P IEEE VIRT REAL ANN, P35, DOI 10.1109/VR.2013.6549355
   Bruder G., 2013, P 1 S SPATIAL USER I, P9, DOI [DOI 10.1145/2491367.2491369, 10.1145/2491367.2491369]
   Butler A., 2011, UIST '11 Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology, P569
   Fei Y, 2012, P SIGGRAPH 12 EM TEC, DOI [10.1145/2343456.2343477, DOI 10.1145/2343456.2343477]
   Hachet Martin., 2011, Proceedings of the 24th annual ACM symposium on User interface software and technology, P587, DOI [DOI 10.1145/2047196.2047273, 10.1145/2047196.2047273]
   Hilliges O., 2012, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI '12, P2421
   Hilliges O, 2009, UIST 2009: PROCEEDINGS OF THE 22ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P139
   Hoshi Takayuki., 2009, ACM SIGGRAPH 2009 EM, P1, DOI [DOI 10.1145/1597956.1597979, 10.1145/1597956.1597979]
   Hunt JL, 2000, AM J PHYS, V68, P232, DOI 10.1119/1.19406
   Kim D, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1377, DOI 10.1145/2556288.2557336
   Kim K, 2012, P SIGCHI C HUM FACT, P2531, DOI DOI 10.1145/2207676.2208640
   Lee JE, 2009, LECT NOTES COMPUT SC, V5615, P209
   Lee Jinha., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI '13, P189, DOI [https://doi.org/10.1145/2470654.2470680, DOI 10.1145/2470654.2470680]
   Levoy M, 2005, The Stanford 3D scanning repository
   Lucey S, 2010, IMAGE VISION COMPUT, V28, P781, DOI 10.1016/j.imavis.2009.09.009
   Mendes D, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P3, DOI 10.1109/3DUI.2014.6798833
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Seungju Han, 2014, 2014 IEEE International Conference on Consumer Electronics (ICCE), P512, DOI 10.1109/ICCE.2014.6776110
   Van Krevelen D. W. F., 2010, INT J VIRTUAL REALIT, V9, P1, DOI 10/ggxxt5
   Weichel C, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3855, DOI 10.1145/2556288.2557090
   Wilson A.D., 2010, Proc. UIST, P273
   Yoo B, P CHI EA 10, P3709, DOI [10.1145/1753846.1754043, DOI 10.1145/1753846.1754043]
NR 29
TC 7
Z9 8
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9245
EP 9264
DI 10.1007/s11042-016-3531-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300006
DA 2024-07-18
ER

PT J
AU Li, Y
   Zhang, SY
   Ye, XZ
AF Li, Yi
   Zhang, Sanyuan
   Ye, Xiuzi
TI Penalty-based haptic rendering technique on medicinal healthy dental
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medicinal simulation; Haptic rendering; Texture surface; Generalized
   penetration depth; Friction
ID DEPTH; CUES
AB We present a penalty-based haptic rendering analysis method for medicinal dentistry diagnose simulation. The method is based on the locally optimized generalized penetration computation algorithm which computes the minimum translational and rotational motion to separate two overlapping objects. The essence of penalty-based haptic rendering method is computing an amount of penetration depth, and the output force magnitude is following the Hooke's law. We use the virtual coupling method to calculate the output force and analysis the damping and stiffness coefficient in order to get a rendering force which optimizes the haptic feedback value and resolves the instability problems in haptic rendering system. Furthermore, we introduce friction force on different surface textures of the interacting objects. And successfully mapped the virtual contact results to force feedback and integrated the algorithm into the off-the-shelf 6Dof haptic device. The experiment result shows that our method can generate stable and realistic haptic feedback in dentistry diagnose simulation near ideal update rate.
C1 [Li, Yi; Ye, Xiuzi] Wenzhou Univ, Coll Math & Informat Sci, Wenzhou 325035, Peoples R China.
   [Zhang, Sanyuan] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.
C3 Wenzhou University; Zhejiang University
RP Li, Y (corresponding author), Wenzhou Univ, Coll Math & Informat Sci, Wenzhou 325035, Peoples R China.
EM eloveven@gmail.com
FU Zhejiang Provincial Natural Science Foundation of China [LQ16F020007]
FX This work is funded by Zhejiang Provincial Natural Science Foundation of
   China (No. LQ16F020007). We would thank the Graphics Lab of Ewha Womans
   University for the previous work: PolyDepth++ library.
CR Cameron S. A., 1986, Proceedings 1986 IEEE International Conference on Robotics and Automation (Cat. No.86CH2282-2), P591
   Cao Yong-gang, 2007, Journal of System Simulation, V19, P1086
   DOBKIN D, 1993, ALGORITHMICA, V9, P518, DOI 10.1007/BF01190153
   Je C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2077341.2077346
   Kim Y. J., 2012, CSETR201201 EWH WOM
   Kim YJ, 2004, IEEE T VIS COMPUT GR, V10, P152, DOI 10.1109/TVCG.2004.1260767
   Kim YJ, 2003, PRESENCE-VIRTUAL AUG, V12, P277, DOI 10.1162/105474603765879530
   Kim YJ, 2002, P ACM S COMP AN
   Konukseven EI, 2010, J DENT EDUC, V74, P880
   Li Y, 2013, 2013 WORLD HAPTICS CONFERENCE (WHC), P289, DOI 10.1109/WHC.2013.6548423
   McNeely WA, 1999, COMP GRAPH, P401, DOI 10.1145/311535.311600
   Nawratil G, 2009, COMPUT AIDED GEOM D, V26, P425, DOI 10.1016/j.cagd.2009.01.001
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P695
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   Ortega M, P IEEE C VIRT REAL, P191
   Otaduy MA, 2003, ACM T GRAPHIC, V22, P543, DOI 10.1145/882262.882305
   Redon S., 2006, Journal of Graphics Tools, V11, P37
   Rydén F, 2013, IEEE T HAPTICS, V6, P257, DOI 10.1109/TOH.2013.20
   Tang M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185603
   Wang Dang-xiao, 2004, Journal of System Simulation, V16, P1729
   Wang DX, 2011, IEEE INT CONF ROBOT, P906
   Wang DX, 2012, IEEE T HAPTICS, V5, P332, DOI [10.1109/TOH.2011.59, 10.1109/ToH.2011.59]
   Wang DX, 2009, SCI CHINA SER F, V52, P529, DOI 10.1007/s11432-009-0062-4
   Wu J, 2011, LECT NOTES ARTIF INT, V7101, P532, DOI 10.1007/978-3-642-25486-4_53
   Zhang L, 2013, IEEE COMPUT VISION P
   Zhang LJ, 2007, COMPUT AIDED DESIGN, V39, P625, DOI 10.1016/j.cad.2007.05.012
   Zhang LM, 2016, IEEE T AUTOM SCI ENG, V13, P894, DOI 10.1109/TASE.2015.2418223
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, SIGNAL PROCESS, V93, P1597, DOI 10.1016/j.sigpro.2012.05.012
   Zhang SL, 2013, IEEE T IMAGE PROCESS, V22, P2889, DOI 10.1109/TIP.2013.2251650
   ZILLES CB, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 3, P146, DOI 10.1109/IROS.1995.525876
NR 37
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10825
EP 10835
DI 10.1007/s11042-016-3985-y
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400029
DA 2024-07-18
ER

PT J
AU Cui, CR
   Shen, JL
   Ma, J
   Lian, T
AF Cui, Chaoran
   Shen, Jialie
   Ma, Jun
   Lian, Tao
TI Social tag relevance learning via ranking-oriented neighbor voting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tag-based image search; Tag relevance learning; Neighbor voting;
   Learning to rank
ID IMAGE ANNOTATION; COMPLETION; REFINEMENT; SEARCH
AB High quality tags play a critical role in applications involving online multimedia search, such as social image annotation, sharing and browsing. However, user-generated tags in real world are often imprecise and incomplete to describe the image contents, which severely degrades the performance of current search systems. To improve the descriptive powers of social tags, a fundamental issue is tag relevance learning, which concerns how to interpret the relevance of a tag with respect to the contents of an image effectively. In this paper, we investigate the problem from a new perspective of learning to rank, and develop a novel approach to facilitate tag relevance learning to directly optimize the ranking performance of tag-based image search. Specifically, a supervision step is introduced into the neighbor voting scheme, in which the tag relevance is estimated by accumulating votes from visual neighbors. Through explicitly modeling the neighbor weights and tag correlations, the risk of making heuristic assumptions is effectively avoided. Besides, our approach does not suffer from the scalability problem since a generic model is learned that can be applied to all tags. Extensive experiments on two benchmark datasets in comparison with the state-of-the-art methods demonstrate the promise of our approach.
C1 [Cui, Chaoran] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Peoples R China.
   [Shen, Jialie] Singapore Management Univ, Sch Informat Syst, Singapore, Singapore.
   [Ma, Jun; Lian, Tao] Shandong Univ, Sch Comp Sci & Technol, Jinan, Peoples R China.
C3 Shandong University of Finance & Economics; Singapore Management
   University; Shandong University
RP Cui, CR (corresponding author), Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Peoples R China.
EM bruincui@gmail.com; jlshen@smu.edu.sg; majun@sdu.edu.cn;
   liantao1988@gmail.com
RI SHEN, Jialie/E-8573-2012; Shen, Jialie/AAX-6851-2020
FU Natural Science Foundation of China [61272240, 71402083, 61103151];
   Doctoral Fund of Ministry of Education of China [20110131110028];
   Natural Science Foundation of Shandong province [ZR2012FM037]; Singapore
   Ministry of Education under Academic Research Fund (MOE)
   [MOE2013-T2-2-156]
FX This work is supported by the Natural Science Foundation of China
   (61272240, 71402083, 61103151), the Doctoral Fund of Ministry of
   Education of China (20110131110028), and the Natural Science Foundation
   of Shandong province (ZR2012FM037). Dr. Jialie Shen is supported by
   Singapore Ministry of Education under Academic Research Fund Tier-2 (MOE
   Ref: MOE2013-T2-2-156).
CR [Anonymous], 2006, ACM INT C MULTIMEDIA, DOI [10.1145/1180639.1180727, DOI 10.1145/1180639.1180727]
   [Anonymous], 2009, PROC INT C WORLD WID
   [Anonymous], P ACM MULT
   [Anonymous], 2008, P 14 ACM SIGKDD INT, DOI DOI 10.1145/1401890.1401906
   [Anonymous], ICME
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2009, P ACM INT C IM VID R
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI [10.1145/1899412.1899418, DOI 10.1145/1899412.1899418]
   [Anonymous], 2010, P ACM MULTIMEDIA
   [Anonymous], 2007, P CIKM
   Ballan L., 2014, P INT C MULTIMEDIA R, P73
   Ballan L, 2015, MULTIMED TOOLS APPL, V74, P1443, DOI 10.1007/s11042-014-1976-4
   Chen L, 2012, IEEE T MULTIMEDIA, V14, P1057, DOI 10.1109/TMM.2012.2187435
   Cheng ZY, 2016, MULTIMEDIA SYST, V22, P509, DOI 10.1007/s00530-014-0432-7
   Cui CR, 2015, J ASSOC INF SCI TECH, V66, P82, DOI 10.1002/asi.23163
   Feng SH, 2015, IEEE T IMAGE PROCESS, V24, P1223, DOI 10.1109/TIP.2015.2395816
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]
   Joachims Thorsten, 2005, P 22 INT C MACH LEAR, P377, DOI DOI 10.1145/1102351.1102399
   Kennedy L.S., 2006, Proc. ACM Multimedia Information Retrieval, P249, DOI DOI 10.1145/1178677.1178712
   Lee S, 2014, MULTIMED TOOLS APPL, V72, P1363, DOI 10.1007/s11042-013-1439-3
   Li X., 2006, MULTIMEDIA 06, P607, DOI DOI 10.1145/1180639.1180764
   Li X, 2015, ARXIV150308248 CORR
   Li XR, 2017, MULTIMEDIA SYST, V23, P29, DOI 10.1007/s00530-014-0430-9
   Li XR, 2013, IEEE T MULTIMEDIA, V15, P933, DOI 10.1109/TMM.2013.2238523
   Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598
   Li Xirong., 2010, Proceedings of the ACM International Conference on Image and Video Retrieval, CIVR '10, P10
   Lin ZJ, 2013, PROC CVPR IEEE, P1618, DOI 10.1109/CVPR.2013.212
   Liu Dong., 2010, Proceedings of the International Conference on Multimedia, P491
   Liu Dong., 2009, P 18 INT C WORLD WID, P351
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P883, DOI 10.1109/TMM.2012.2188782
   Shalev-Shwartz S, 2011, MATH PROGRAM, V127, P3, DOI 10.1007/s10107-010-0420-4
   Shen J, 2011, ACM MULTIMEDIA, P639, DOI DOI 10.1145/2072298.2072405
   Shengli Yuan, 2010, Proceedings 2010 IEEE Global Communications Conference (GLOBECOM 2010), DOI 10.1109/GLOCOM.2010.5683786
   Teo CH, 2010, J MACH LEARN RES, V11, P311
   Truong B. Q., 2012, P ACM INT C MULT RET, V9, P1
   Verbeek J., 2010, Proc. ACM Multimedia Information Retrieval, P537
   Wang JD, 2014, COMPUT VIS IMAGE UND, V124, P61, DOI 10.1016/j.cviu.2014.02.011
   Wang M, 2010, IEEE T MULTIMEDIA, V12, P829, DOI 10.1109/TMM.2010.2055045
   Wang Zheng., 2010, Proceedings of the ACM International Conference on Image and Video Retrieval, CIVR '10, P42
   Weston J, 2011, IJCAI
   Wu L, 2013, IEEE T PATTERN ANAL, V35, P716, DOI 10.1109/TPAMI.2012.124
   Yisong Yue, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P271
   Zhao R, 2002, IEEE T MULTIMEDIA, V4, P189, DOI 10.1109/TMM.2002.1017733
   Zhou B, 2014, ABS14115328 CORR
   Zhu XF, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P223, DOI 10.1145/2600428.2609556
NR 49
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8831
EP 8857
DI 10.1007/s11042-016-3512-1
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800053
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Gu, YF
   Cao, ZM
   Dong, LM
AF Gu, Yanfeng
   Cao, Zhimin
   Dong, Limin
TI A hierarchical energy minimization method for building roof segmentation
   from airborne LiDAR data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Airborne LiDAR; Building roof segmentation; Energy minimization; Plane
   fitting
ID POINT; RECONSTRUCTION; EXTRACTION
AB This paper presents a reliable and accurate method for building roof segmentation from airborne LiDAR data. In order to obtain the optimal results in both object level and pixel level, three energy minimization procedures are conducted consecutively in a hierarchical way. Firstly, an active multi-plane fitting method is conducted to obtain reliable initial segmentations. Then, the coarsest energy function composed of both the plane fitting errors in pixel level and the number of plane hypotheses in object level is minimized to obtain the optimal label space. Next, energy function composing of plane fitting errors and spatial smoothness between neighboring planes is minimized to obtain the optimal segmentation results. Finally, by taking prior knowledge of building roof structure into consideration, the optimal plane parameters for the segmented plane hypotheses are obtained by minimizing energy function of the structural adjusted plane fitting errors. Two real LiDAR data sets with different point densities and different building styles are used to evaluate the performance of the proposed method, and experimental results demonstrate that the proposed method is fast, stable, and reliable for accurate building roof segmentation from airborne LiDAR data.
C1 [Gu, Yanfeng; Cao, Zhimin; Dong, Limin] Sch Elect & Informat Engn, Harbin, Peoples R China.
   [Cao, Zhimin] North East Petr Univ, Sch Elect Sci, Daqing, Peoples R China.
   [Dong, Limin] Harbin Inst Technol, Dept Aerosp Sci & Technol, Harbin, Peoples R China.
C3 Harbin Institute of Technology
RP Dong, LM (corresponding author), Sch Elect & Informat Engn, Harbin, Peoples R China.; Dong, LM (corresponding author), Harbin Inst Technol, Dept Aerosp Sci & Technol, Harbin, Peoples R China.
EM donglimin@hit.edu.cn
RI Gu, Yanfeng/F-7781-2015; Zhimin, Cao/J-7973-2015; zhang,
   ye/HKN-5128-2023
OI Zhimin, Cao/0000-0002-3679-6288; 
FU Natural Science Foundation of China [61371180]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant 61371180. The authors would like to thank USGS and
   ISPRS for providing the data sets used in this study. Special thanks to
   Dr. Lu Xin for his assistance about the writing of this paper.
CR Abdullah S., 2014, ISPRS Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci, VXL-3, P1, DOI [10.5194/isprsarchives-XL-3-1-2014, DOI 10.5194/ISPRSARCHIVES-XL-3-1-2014]
   Vo AV, 2015, ISPRS J PHOTOGRAMM, V104, P88, DOI 10.1016/j.isprsjprs.2015.01.011
   Awrangjeb M, 2014, REMOTE SENS-BASEL, V6, P3716, DOI 10.3390/rs6053716
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Chauve AL, 2010, PROC CVPR IEEE, P1261, DOI 10.1109/CVPR.2010.5539824
   Dorninger P, 2008, SENSORS-BASEL, V8, P7323, DOI 10.3390/s8117323
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Fan HC, 2014, REMOTE SENS-BASEL, V6, P3284, DOI 10.3390/rs6043284
   Filin S, 2006, ISPRS J PHOTOGRAMM, V60, P71, DOI 10.1016/j.isprsjprs.2005.10.005
   Fischler M, 1999, COMMUN ACM, V24, P381
   Isack H, 2012, INT J COMPUT VISION, V97, P123, DOI 10.1007/s11263-011-0474-7
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Kong DM, 2014, IEEE T INSTRUM MEAS, V63, P1200, DOI 10.1109/TIM.2013.2292310
   Limberger FA, 2015, PATTERN RECOGN, V48, P2043, DOI 10.1016/j.patcog.2014.12.020
   Mount DavidM., 2010, ANN programming manual
   Nurunnabi A, 2014, ISPRS J PHOTOGRAMM, V96, P106, DOI 10.1016/j.isprsjprs.2014.07.004
   Pham TT, 2014, IEEE T PATTERN ANAL, V36, P1658, DOI 10.1109/TPAMI.2013.2296310
   Sampath A, 2010, IEEE T GEOSCI REMOTE, V48, P1554, DOI 10.1109/TGRS.2009.2030180
   Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x
   Sun SH, 2013, IEEE J-STARS, V6, P1440, DOI 10.1109/JSTARS.2013.2251457
   Tarsha-Kurdi F., 2007, INT ARCH PHOTOGRAMME, V36, P407
   Yan JX, 2014, ISPRS J PHOTOGRAMM, V94, P183, DOI 10.1016/j.isprsjprs.2014.04.022
NR 23
TC 5
Z9 5
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4197
EP 4210
DI 10.1007/s11042-016-3337-y
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200049
DA 2024-07-18
ER

PT J
AU Song, W
   Le, AV
   Yun, S
   Jung, SW
   Won, CS
AF Song, Wanbin
   Anh Vu Le
   Yun, Seokmin
   Jung, Seung-Won
   Won, Chee Sun
TI Depth completion for kinect v2 sensor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kinect v2; Hole-filling; Depth completion; Depth and color fusion
AB Kinect v2 adopts a time-of-flight (ToF) depth sensing mechanism, which causes different type of depth artifacts comparing to the original Kinect v1. The goal of this paper is to propose a depth completion method, which is designed especially for the Kinect v2 depth artifacts. Observing the specific types of depth errors in the Kinect v2 such as thin hole-lines along the object boundaries and the new type of holes in the image corners, in this paper, we exploit the position information of the color edges extracted from the Kinect v2 sensor to guide the accurate hole-filling around the object boundaries. Since our approach requires a precise registration between color and depth images, we also introduce the transformation matrix which yields point-to-point correspondence with a pixel-accuracy. Experimental results demonstrate the effectiveness of the proposed depth image completion algorithm for the Kinect v2 in terms of completion accuracy and execution time.
C1 [Song, Wanbin; Anh Vu Le; Yun, Seokmin; Won, Chee Sun] Dongguk Univ Seoul, Dept Elect & Elect Engn, 26 Pildongro1 Gil, Seoul 100715, South Korea.
   [Jung, Seung-Won] Dongguk Univ Seoul, Dept Multimedia Engn, 26 Pildongro1 Gil, Seoul 100715, South Korea.
C3 Dongguk University; Dongguk University
RP Won, CS (corresponding author), Dongguk Univ Seoul, Dept Elect & Elect Engn, 26 Pildongro1 Gil, Seoul 100715, South Korea.
EM wbsong@dongguk.edu; levuanh.hut@gmail.com; smyun@dongguk.edu;
   swjung83@dongguk.edu; cswon@dongguk.edu
RI Won, Chee Sun/AAI-1101-2020; Le, Anh Vu/G-2886-2019
OI Le, Anh Vu/0000-0002-4804-7540; Jung, Seung-Won/0000-0002-0319-4467;
   Won, Chee Sun/0000-0002-3400-0792
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under ITRC
   support program [IITP-2016-H8501-16-1014]; Basic Science Research
   Program through the National Research Foundation of Korea (NRF) -
   Ministry of Education [NRF-2015R1D1A1A01057269]; Dongguk University
FX This work was supported by the MSIP (Ministry of Science, ICT and Future
   Planning), Korea, under ITRC support program (IITP-2016-H8501-16-1014)
   supervised by IITP and by Basic Science Research Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education (NRF-2015R1D1A1A01057269). C.S. Won was supported by the
   research program of Dongguk University, 2016.
CR Le AV, 2014, SENSORS-BASEL, V14, P11362, DOI 10.3390/s140711362
   [Anonymous], J CONVERGENCE
   [Anonymous], SPIE SECURITY DEFENC
   [Anonymous], 1971, ASP S CLOS RANG PHOT
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen CY, 2013, IEEE INT WORKSH MULT, P7, DOI 10.1109/MMSP.2013.6659255
   Chen L, 2012, INT C PATT RECOG, P3070
   El-laithy RA, 2012, IEEE POSITION LOCAT, P1280, DOI 10.1109/PLANS.2012.6236985
   Horng YR, 2010, IEEE INT SYMP CIRC S, P2650, DOI 10.1109/ISCAS.2010.5537052
   Jung SW, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.10.103104
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Qi F, 2013, PATTERN RECOGN LETT, V34, P70, DOI 10.1016/j.patrec.2012.06.003
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rothwell C. A., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P573, DOI 10.1109/ICCV.1993.378159
   Scharstein D., 2007, IEEE COMPUTER SOC C
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Vipparthi SK, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0006-x
   Wasza J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1221, DOI 10.1109/ICCVW.2011.6130390
   Yang JY, 2014, IEEE T IMAGE PROCESS, V23, P3443, DOI 10.1109/TIP.2014.2329776
NR 21
TC 8
Z9 8
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4357
EP 4380
DI 10.1007/s11042-016-3523-y
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200057
DA 2024-07-18
ER

PT J
AU Yáñez-Gómez, R
   Cascado-Caballero, D
   Sevillano, JL
AF Yanez-Gomez, Rosa
   Cascado-Caballero, Daniel
   Sevillano, Jose-Luis
TI Academic methods for usability evaluation of serious games: a systematic
   review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-computer interaction.; Usability; Usability evaluation; Serious
   games; Interactivemedia; Systematic review
ID REHABILITATION SYSTEM; EXPERT EVALUATION; COMPUTER GAME; DESIGN;
   EDUCATION; CHILDREN; REALITY; PEOPLE; PLAYABILITY; INTERFACE
AB In the last years, there has been an increasing interest in the design of video games as a tool for education, training, health promotion, socialization, etc. Usability, which is a key factor in any video game, becomes even more important in these so-called ''serious games'', where the users' special characteristics should be considered, and the game efficacy depends on the users' adherence and engagement. However, evaluation of the usability of this kind of games requires a redefinition of techniques, methods and even terminology. In this paper, we elicit six research questions and conduct a systematic review of the scientific literature, which resulted in the selection of 187 papers that contained the most relevant responses.The conclusions of this systematic review illustrate the general status of current academic usability evaluations of these games and the main trends in the selection of methodologies and how are they applied. This view may be a very valuable foundation for future research.
C1 [Yanez-Gomez, Rosa; Cascado-Caballero, Daniel; Sevillano, Jose-Luis] Univ Seville, ETS Ingn Informat, Dept Comp Technol & Architecture, Avda Reina Mercedes S-N, E-41012 Seville, Spain.
C3 University of Sevilla
RP Yáñez-Gómez, R (corresponding author), Univ Seville, ETS Ingn Informat, Dept Comp Technol & Architecture, Avda Reina Mercedes S-N, E-41012 Seville, Spain.
EM ryanez@us.es
RI Sevillano, Jose Luis/K-2484-2013
OI Sevillano, Jose Luis/0000-0002-1392-1832
FU INNPACTO of MINECO; FEDER; Universidad de Sevilla, Spain; 
   [IPT-2011-1038-900000]
FX This work has been supported by project PROCUR@-IPT-2011-1038-900000,
   funded by the program INNPACTO of MINECO and FEDER funds; and by the
   Telefonica Chair "Intelligence in Networks" of the Universidad de
   Sevilla, Spain.
CR Abdulhak SA, 2012, 2011 6TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCES AND CONVERGENCE INFORMATION TECHNOLOGY (ICCIT), P7
   Abeele VV, 2008, LECT NOTES COMPUT SC, V5294, P118, DOI 10.1007/978-3-540-88322-7_12
   Ahmad W. F. W., 2012, Proceedings of the 2012 International Conference on Computer & Information Science (ICCIS), P1099, DOI 10.1109/ICCISci.2012.6297190
   Albu M, 2015, HEALTH EDUC J, V74, P244, DOI 10.1177/0017896914532623
   Ancker Jessica S, 2007, AMIA Annu Symp Proc, P16
   Ang C.S., 2008, International Journal on ELearning, V7, P533
   Annett J., 1967, OCCUP PSYCHOL, V41, P211
   [Anonymous], P 15 INT C HUM COMP
   [Anonymous], 1994, Usability Inspections Methods
   [Anonymous], 2013, PROC AM SOC INFO SCI
   [Anonymous], DEV USER SATISFACTIO
   [Anonymous], P 2006 C INT DES CHI
   [Anonymous], 2006, WEB BROWSING MOBILE
   [Anonymous], INT J COMPUT GAMES T
   [Anonymous], DESIGNING USER INTER
   [Anonymous], 2015, P 2015 ANN S COMPUTE
   [Anonymous], ACM T ACCESS COMPUT
   [Anonymous], 2010, ACM T ACCESS COMPUT
   [Anonymous], INT C NETW INT C SYS
   [Anonymous], 2012, P 24 AUSTR COMP HUM
   [Anonymous], CHI 14 HUM FACT COMP
   [Anonymous], 2013, P 1 INT C GAM DES RE
   [Anonymous], THESIS
   [Anonymous], ADV HUM COMPUT INTER
   [Anonymous], INT J COMPUT GAMES T
   [Anonymous], 1998, ERG REQ OFF WORK VIS
   [Anonymous], 2010, PROC IEEE INT S WEAR
   [Anonymous], J ACAD NUTR DIET
   [Anonymous], ARXIV150406359
   [Anonymous], P 8 INT C ADV COMP E
   [Anonymous], INT J COMPUT GAMES T
   [Anonymous], DO GAMES MOTIVATE MO
   [Anonymous], 2010, P 6 NORDIC C HUMAN C
   [Anonymous], 2015, Interaction design: Beyond human-computer interaction
   [Anonymous], P 2005 ACM SIGCHI IN
   [Anonymous], GAM INN C ICE GIC 20
   [Anonymous], ACM SIGGRAPH 2007 ED
   [Anonymous], P CCI COGN SCI HCI R
   [Anonymous], END USER FACILITATOR
   [Anonymous], 2011, P SANDB 11
   [Anonymous], IEEE T COMP IN PRESS
   [Anonymous], 2008, THESIS
   [Anonymous], P 9 INT C UB INF MAN
   [Anonymous], GAM DEV C SAN JOS CA
   [Anonymous], 2012, PRENSA PERIODISMO ES
   [Anonymous], 156 INRIA
   [Anonymous], 2014, 2014 IEEE INNOVATION
   [Anonymous], WORK READING MASS
   [Anonymous], BRAIN COMPUTER INTER
   [Anonymous], SIRIUS SISTEMA EVALU
   [Anonymous], 2002, THESIS
   [Anonymous], P 2015 ANN S COMP HU
   [Anonymous], 2010, FUTUREPLAY 10 FUTURE, DOI DOI 10.1145/1920778.1920786
   [Anonymous], ERG HUM SYST INT 210
   [Anonymous], 2004, NARRATIVES MEDIA LAN
   [Anonymous], 2014, P 1 ACM SIGCHI ANN S, DOI DOI 10.1145/2658537.2658703
   [Anonymous], HUM FACTORS J HUM FA
   [Anonymous], 2010, 2010 IEEE INT WORKSH
   [Anonymous], 2013, P 1 INT C GAMEFUL DE
   [Anonymous], 2011, ACM INT C P SER, DOI DOI 10.1145/2071423.2071443
   Arroyo-Palacios Jorge, 2009, 2009 International IEEE Consumer Electronics Society's Games Innovations Conference (ICE-GIC 2009), P154, DOI 10.1109/ICEGIC.2009.5293588
   Aung YM, 2014, IEEE ENG MED BIO, P3614, DOI 10.1109/EMBC.2014.6944405
   Baauw E, 2005, LECT NOTES COMPUT SC, V3585, P457, DOI 10.1007/11555261_38
   Bekker Mathilde M., 2008, Cognition, Technology & Work, V10, P129, DOI 10.1007/s10111-007-0068-x
   Bellotti F, 2005, LECT NOTES COMPUT SC, V3814, P13, DOI 10.1007/11590323_2
   Bellotti F., 2012, J. Comput. Cult. Herit., V5, P4, DOI [DOI 10.1145/2399180.2399185, https://doi.org/10.1145/2399180.2399185]
   Benveniste S, 2010, LECT NOTES COMPUT SC, V6243, P79, DOI 10.1007/978-3-642-15399-0_8
   Bernhaupt R., 2007, Proceedings of the International Conference on Advances in Computer Entertainment Technology - ACE'07, P224, DOI [10.1145/1255047.1255096, DOI 10.1145/1255047.1255096]
   BIAS R, 1991, IEEE SOFTWARE, V8, P94, DOI 10.1109/52.84220
   Bias Randolph., 1994, USABILITY INSPECTION, P63
   Boulay M, 2011, TECHNOL HEALTH CARE, V19, P233, DOI 10.3233/THC-2011-0628
   Brereton P, 2007, J SYST SOFTWARE, V80, P571, DOI 10.1016/j.jss.2006.07.009
   Bronner S, 2015, COMPUT HUM BEHAV, V51, P34, DOI 10.1016/j.chb.2015.04.047
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Brown DJ, 2011, COMPUT EDUC, V56, P11, DOI 10.1016/j.compedu.2010.04.014
   Brown-Johnson CG, 2015, PATIENT EDUC COUNS, V98, P506, DOI 10.1016/j.pec.2014.12.006
   Browne Kevin, 2013, P 1 INT C GAM DES RE, P50, DOI [10.1145/2583008.2583015, DOI 10.1145/2583008.2583015]
   Burns Mathew, 2013, Advances in Computer Entertainment. 10th International Conference, ACE 2013. Proceedings: LNCS 8253, P1, DOI 10.1007/978-3-319-03161-3_1
   Cameirao MS, 2010, J NEUROENG REHABIL, V7, DOI 10.1186/1743-0003-7-48
   Cao Y, 2013, RISK ANAL, V33, P1066, DOI 10.1111/j.1539-6924.2012.01907.x
   Caputo FabioMarco., C PAPER CHITALY 2015, P2
   Carter C, 2012, 2012 17TH INTERNATIONAL CONFERENCE ON COMPUTER GAMES (CGAMES), P86, DOI 10.1109/CGames.2012.6314557
   Centieiro Pedro., 2011, Proceedings of the 8th International Conference on Advances in Computer Entertainment Technology, page, P31, DOI DOI 10.1145/2071423.2071461
   Chang SB, 2007, DIGITEL 2007: The First IEEE International Workshop on Digital Game and Intelligent Toy Enhanced Learning, Proceedings, P99
   Chen KH, 2012, INTERNET RES, V22, P467, DOI 10.1108/10662241211250999
   Choi YJ, 2009, I C COMP GRAPH IM VI, P129, DOI 10.1109/CGIV.2009.51
   Chung KM, 2015, INT J HUM-COMPUT ST, V83, P12, DOI 10.1016/j.ijhcs.2015.06.003
   Clanton C., 1998, CHI 98 C SUMMARY HUM, P1
   Cornett S., 2004, P ACM SIG CHI 2004, V6, P703
   Couceiro RM, 2013, EDUC INF TECHNOL, V18, P531, DOI 10.1007/s10639-011-9179-3
   Cruz VT, 2013, JMIR RES PROTOC, V2, DOI 10.2196/resprot.2899
   Cybis W., 2010, Ergonomia e usabilidade: conhecimentos, metodos e aplicacoes, V2a
   de Carvalho Breno Jose Andrade, 2013, Design, User Experience, and Usability. Health, Learning, Playing, Cultural, and Cross-Cultural User Experience.Second International Conference, DUXU 2013 Held as Part of HCI International 2013. Proceedings. LNCS 8013, P508, DOI 10.1007/978-3-642-39241-2_56
   DeShazo J, 2010, J TELEMED TELECARE, V16, P378, DOI 10.1258/jtt.2010.091012
   Desurvire H., 2004, EXTENDED ABSTRACTS 2, P1509, DOI [DOI 10.1145/985921.986102, 10.1145/985921.986102]
   Deterding S., 2011, P 15 INT AC MINDTREK, P9, DOI [10.1145/2181037.2181040, DOI 10.1145/2181037.2181040]
   Diah Norizan Mat, 2010, Proceedings of the 2010 International Conference on Information Retrieval and Knowledge Management (CAMP 2010), P157, DOI 10.1109/INFRKM.2010.5466926
   Diehl LA, 2013, JMIR RES PROTOC, V2, DOI 10.2196/resprot.2431
   Dion Hoe-Lian Goh, 2011, Proceedings of the 2011 IEEE International Conference on Internet of Things and 4th IEEE International Conference on Cyber, Physical and Social Computing (iThings/CPSCom 2011), P209, DOI 10.1109/iThings/CPSCom.2011.48
   Direito A, 2015, BMC PUBLIC HEALTH, V15, DOI 10.1186/s12889-015-1968-y
   Donggil Song, 2011, 2011 International Conference on e-Education, Entertainment and e-Management (ICEEE 2011), P234, DOI 10.1109/ICeEEM.2011.6137794
   Dores AR, 2011, LECT NOTES COMPUT SC, V6944, P95, DOI 10.1007/978-3-642-23834-5_9
   Dyck J, 2003, PROC GRAPH INTERF, P237
   Ebner M, 2007, COMPUT EDUC, V49, P873, DOI 10.1016/j.compedu.2005.11.026
   El-Tayeh A, 2008, RES ENG DES, V19, P29, DOI [10.1007/s00163-007-0037-7, 10.1007/sOO163-007-0037-7]
   Eladhari MR, 2012, SIMULAT GAMING, V43, P391, DOI 10.1177/1046878111434255
   Fabricatore C, 2002, HUM-COMPUT INTERACT, V17, P311, DOI 10.1207/S15327051HCI1704_1
   Ferracani A, 2014, Univ Access Inf Soc, P1
   Ferraz M, 2010, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENTERTAINMENT TECHNOLOGY (ACE 2010), P7
   Ferrer V., 2013, IEEE, P1
   Fitzgerald D, 2008, IEEE ENG MED BIO, P4194, DOI 10.1109/IEMBS.2008.4650134
   Franck Linda S, 2003, J Child Health Care, V7, P41, DOI 10.1177/1367493503007001686
   Frutos-Pascual M, 2014, INT J ENV RES PUB HE, V11, P749, DOI 10.3390/ijerph110100749
   Fullerton Tracy, 2004, GAM DES WORKSH DES P
   Furió D, 2015, J COMPUT ASSIST LEAR, V31, P189, DOI 10.1111/jcal.12071
   Furió D, 2013, COMPUT EDUC, V64, P1, DOI 10.1016/j.compedu.2012.12.001
   Ganesan S., 2012, Proceedings of the 2012 ACM annual conference extended abstracts on Human Factors in Computing Systems Extended Abstracts. ACM, P2297, DOI DOI 10.1145/2212776.2223792
   Gerling K., 2011, MINDTREK 11, P83, DOI DOI 10.1145/2181037.2181052
   Gilleade K.M., 2004, Proceedings of the 2004 ACM SIGCHI International Conference on Advances in Computer Entertainment Technology, P228, DOI [10.1145/1067343.1067372, DOI 10.1145/1067343.1067372]
   Goncalves Duarte., 2008, ACE'08: Proceedings of the 2008 International Conference on Advances in Computer Entertainment Technology, Yokohama, Japan, P259
   Goodman D, 2006, J ADOLESCENCE, V29, P351, DOI 10.1016/j.adolescence.2005.07.004
   Guidali M, 2011, MED BIOL ENG COMPUT, V49, P1213, DOI 10.1007/s11517-011-0809-0
   Gürkök H, 2011, LECT NOTES COMPUT SC, V6972, P77, DOI 10.1007/978-3-642-24500-8_9
   Ha Ji Min, 2013, Architectural Research, V15, P175, DOI 10.5659/AIKAR.2013.15.4.175
   Hannig A, 2012, BMC MED EDUC, V12, DOI 10.1186/1472-6920-12-104
   Hart P, 2014, IEEE ENG MED BIO, P5908, DOI 10.1109/EMBC.2014.6944973
   HART S G, 1988, P139
   Heo J, 2009, INTERACT COMPUT, V21, P263, DOI 10.1016/j.intcom.2009.05.006
   Hertzum M, 2001, INT J HUM-COMPUT INT, V13, P421, DOI 10.1207/S15327590IJHC1304_05
   Hou HT, 2014, COMPUT HUM BEHAV, V30, P29, DOI 10.1016/j.chb.2013.07.052
   Hoysniemi Johanna., 2004, P 3 NORDIC C HUMAN C, P389, DOI 10.1145/1028014.1028077
   Hwang MY, 2009, LECT NOTES COMPUT SC, V5670, P464, DOI 10.1007/978-3-642-03364-3_55
   Hwang W, 2010, COMMUN ACM, V53, P130, DOI 10.1145/1735223.1735255
   Infante C, 2010, INTERACT LEARN ENVIR, V18, P177, DOI 10.1080/10494820802489339
   Isleyen F, 2014, STUD HEALTH TECHNOL, V205, P662, DOI 10.3233/978-1-61499-432-9-662
   Ismail Marina, 2011, 2011 International Symposium on Humanities, Science and Engineering Research (SHUSER 2011), P56, DOI 10.1109/SHUSER.2011.6008500
   Istance H, 2009, LECT NOTES COMPUT SC, V5726, P314, DOI 10.1007/978-3-642-03655-2_36
   Ivory MY, 2001, ACM COMPUT SURV, V33, P470, DOI 10.1145/503112.503114
   Jett J, 2016, J ASSOC INF SCI TECH, V67, P505, DOI 10.1002/asi.23409
   Jimenez-Diaz G, 2012, SOFTWARE PRACT EXPER, V42, P235, DOI 10.1002/spe.1071
   Jorgensen AnkerHelms., 2004, Proceedings of the Third Nordic Conference on Human-computer Interaction, P393
   Ju E, 1997, DATA BASE ADV INF SY, V28, P78
   Karat J., 1997, Handbook of Human-Computer Interaction, V2nd, P689
   Khan Danish U., 2012, 2012 6th International Conference on Pervasive Computing Technologies for Healthcare, P57, DOI 10.4108/icst.pervasivehealth.2012.248692
   Kim SL, 2014, 2014 IEEE WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P21, DOI 10.1109/WF-IoT.2014.6803110
   Kim YS, 2013, 2013 WORLD HAPTICS CONFERENCE (WHC), P559, DOI 10.1109/WHC.2013.6548469
   Kitchenham B, 2013, INFORM SOFTWARE TECH, V55, P2049, DOI 10.1016/j.infsof.2013.07.010
   Klisch Y, 2012, J SCI EDUC TECHNOL, V21, P295, DOI 10.1007/s10956-011-9319-y
   Klisch Y, 2012, CBE-LIFE SCI EDUC, V11, P94, DOI 10.1187/cbe.11-04-0040
   Konstantinidis EI, 2016, IEEE J BIOMED HEALTH, V20, P189, DOI 10.1109/JBHI.2014.2378814
   Korhonen H., 2006, P 8 C HUMAN COMPUTER, P9, DOI [DOI 10.1145/1152215.1152218, 10.1145/1152215.1152218, DOI 10.1145/1306813.1306828]
   Korhonen Hannu, 2010, P 3 INT C FUN GAM, P18, DOI [10.1145/1823818.1823820, DOI 10.1145/1823818.1823820]
   Koster Raph, 2013, Theory of fun for game design
   Kothandapani S., 2012, Proceedings of the 2012 32nd International Conference on Distributed Computing Systems Workshops (ICDCS Workshops), P75, DOI 10.1109/ICDCSW.2012.44
   Krebs P, 2013, JMIR RES PROTOC, V2, DOI 10.2196/resprot.2416
   Laine TH, 2010, IEEE T LEARN TECHNOL, V3, P294, DOI 10.1109/TLT.2010.16
   Laitinen S, 2006, J USABILITY STUD, V1, P64
   Lange B, 2010, TOP STROKE REHABIL, V17, P345, DOI 10.1310/tsr1705-345
   Lee P.-W., 2015, Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems, P73
   Lewis C., 1990, SIGCHI Bulletin, P235
   LEWIS JR, 1995, INT J HUM-COMPUT INT, V7, P57, DOI 10.1080/10447319509526110
   Liao LD, 2012, J NEUROENG REHABIL, V9, DOI 10.1186/1743-0003-9-5
   Lin HCK, 2011, TURK ONLINE J EDUC T, V10, P181
   Llorens Roberto, 2013, 2013 International Conference on Virtual Rehabilitation (ICVR), P134, DOI 10.1109/ICVR.2013.6662064
   Lu Z., 2013, Proceedings of the 21st ACM international conference on Multimedia, P621, DOI DOI 10.1145/2502081.2502163
   Lugrin J.-L., 2013, PROCEEDSING ACM INT, P7, DOI [10.1145/2512142, DOI 10.1145/2512142]
   Luojus Petri., 2013, Proceedings of the 2nd ACM International Symposium on Pervasive Displays, P109
   Malone T.W., 1982, P 1982 C HUM FACT CO, P63, DOI DOI 10.1145/800049.801756
   Marco J, 2013, J UNIVERS COMPUT SCI, V19, P2266
   Marco J, 2013, PERS UBIQUIT COMPUT, V17, P1577, DOI 10.1007/s00779-012-0522-5
   Martins T., 2008, Proceedings of the 2008 International Conference on Advances in Computer Entertainment Technology, P26
   Miller LM, 2011, COMPUT EDUC, V57, P1425, DOI 10.1016/j.compedu.2011.01.016
   Morón MJ, 2014, 2014 IEEE-EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL AND HEALTH INFORMATICS (BHI), P302, DOI 10.1109/BHI.2014.6864363
   Moustakas K, 2009, LECT NOTES COMPUT SC, V5616, P226, DOI 10.1007/978-3-642-02713-0_24
   Nam CS, 2009, INT J IND ERGONOM, V39, P192, DOI 10.1016/j.ergon.2008.08.008
   Nielsen J, 1997, IEEE SOFTWARE, V14, P94, DOI 10.1109/52.566434
   Nielsen J., 1994, Heuristic evaluation. Usability inspection methods, V17, P25
   Nielsen J., 2002, P 2 NORD C HUM COMP, P101, DOI DOI 10.1145/572020.572033
   Nielsen Jakob, 1994, USABILITY INSPECTION, P413, DOI [10.1145/259963.260531, DOI 10.1145/259963.260531]
   Nielsen Jakob, 2000, WHY YOU ONLY NEED TE
   Nijenhuis SM, 2015, J NEUROENG REHABIL, V12, DOI 10.1186/s12984-015-0080-y
   Novick D, 2014, LECT NOTES COMPUT SC, V8518, P720, DOI 10.1007/978-3-319-07626-3_68
   Ntoa S, 2011, LECT NOTES COMPUT SC, V6766, P342, DOI 10.1007/978-3-642-21663-3_37
   Nystrom D, 2012, 2012 INT GAMES INNOV, P1
   Olsen T, 2011, LECT NOTES COMPUT SC, V6770, P625, DOI 10.1007/978-3-642-21708-1_70
   Suarez CO, 2011, LECT NOTES COMPUT SC, V6949, P495, DOI 10.1007/978-3-642-23768-3_66
   Pagulayan R.J., 2003, HUM FAC ER, P883
   Paliokas I., 2011, Proceedings of the 2011 3rd International Conference on Games and Virtual Worlds for Serious Applications (VS-GAMES 2011), P24, DOI 10.1109/VS-GAMES.2011.10
   Papaloukas Spyridon, 2010, Proceedings of the 14th Panhellenic Conference on Informatics (PCI 2010), P209, DOI 10.1109/PCI.2010.11
   Pastor I, 2012, IEEE ENG MED BIO, P1286, DOI 10.1109/EMBC.2012.6346173
   Pierotti D., 1995, HEURISTIC EVALUATION
   Pinelle D, 2009, GROUP 2009 PROCEEDINGS, P169
   Pinelle D, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1453
   Plow M, 2014, OCCUP THER INT, V21, P21, DOI 10.1002/oti.1345
   POLSON PG, 1992, INT J MAN MACH STUD, V36, P741, DOI 10.1016/0020-7373(92)90039-N
   Pranantha D., 2012, 2012 IEEE 12th International Conference on Advanced Learning Technologies (ICALT), P13, DOI 10.1109/ICALT.2012.52
   Proctor MD, 2004, INT J AVIAT PSYCHOL, V14, P191, DOI 10.1207/s15327108ijap1402_5
   Raisamo R, 2006, IEEE MULTIMEDIA, V13, P70, DOI 10.1109/MMUL.2006.68
   Rand Debbie, 2008, J Neurol Phys Ther, V32, P155, DOI 10.1097/NPT.0b013e31818ee779
   Raybourn E.M., 2005, CHI '05 Extended Abstracts on Human Factors in Computing Systems (Portland, OR, USA, April 02 - 07, P2049, DOI DOI 10.1145/1056808.1057094
   Rebin M, 2007, LECT NOTES COMPUT SC, V4471, P37
   Rebolledo-Mendez G, 2009, LECT NOTES COMPUT SC, V5610, P149, DOI 10.1007/978-3-642-02574-7_17
   Regenbrecht H., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P219, DOI 10.1109/ISMAR.2011.6092389
   Regenbrecht H, 2012, COMPUT GRAPH-UK, V36, P819, DOI 10.1016/j.cag.2012.04.012
   Rehm M, 2012, MULTIMEDIA SYST, V18, P33, DOI 10.1007/s00530-011-0239-8
   Reichlin L, 2011, J MED INTERNET RES, V13, P188, DOI 10.2196/jmir.1519
   Rias R. M., 2011, 2011 3rd International Congress on Engineering Education, P169, DOI 10.1109/ICEED.2011.6235383
   Rogers K, 2015, 2015 INTERNATIONAL CONFERENCE ON INTELLIGENT ENVIRONMENTS IE 2015, P172, DOI 10.1109/IE.2015.37
   Romero Margarida, 2012, Serious Games Development and Applications. Proceedings Third International Conference, SGDA 2012, P59, DOI 10.1007/978-3-642-33687-4_5
   Rouanet P, 2011, ACMIEEE INT CONF HUM, P313, DOI 10.1145/1957656.1957782
   Rouse R., 2010, GAME DESIGN THEORY P
   Ballester BR, 2012, PRESENCE-TELEOP VIRT, V21, P490, DOI 10.1162/PRES_a_00129
   Salvador-Herranz G, 2013, P ANN HICSS, P31, DOI 10.1109/HICSS.2013.390
   Sanchez J., 2008, CHI 08 HUM FACT COMP, P3201, DOI DOI 10.1145/1358628.1358831
   Sánchez J, 2007, LECT NOTES COMPUT SC, V4553, P322
   Sánchez J, 2007, IEEE T NEUR SYS REH, V15, P16, DOI 10.1109/TNSRE.2007.891404
   Sánchez J, 2006, BEHAV INFORM TECHNOL, V25, P367, DOI 10.1080/01449290600636660
   Sánchez J, 2012, PROCEDIA COMPUT SCI, V14, DOI 10.1016/j.procs.2012.10.012
   Sánchez J, 2011, ASSETS 11: PROCEEDINGS OF THE 13TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P227
   Santos Bruno, 2013, Advances in Computer Entertainment. 10th International Conference, ACE 2013. Proceedings: LNCS 8253, P380, DOI 10.1007/978-3-319-03161-3_28
   Scardovelli TA, 2015, COMPUT METH PROG BIO, V118, P44, DOI 10.1016/j.cmpb.2014.10.002
   Scheible J., 2007, P 6 INT C MOBILE UBI, P139
   Schell Jesse, 2008, The Art of Game Design
   Schmitz B., 2012, 2012 IEEE 12th International Conference on Advanced Learning Technologies (ICALT), P223, DOI 10.1109/ICALT.2012.138
   Schwebel DC, 2014, VIRTUAL REAL-LONDON, V18, P5, DOI 10.1007/s10055-013-0238-5
   Shegog R, 2007, STUD HEALTH TECHNOL, V129, P983
   Shepherd A., 1989, TASK ANAL HUMAN COMP, P15
   Shin JH, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-32
   Squire K., 2005, Journal of online education, V1, P1
   Sunwoo J., 2010, Proceedings of the 11th International Conference of the NZ Chapter of the ACM Special Interest Group on Human-Computer Interaction on ZZZ - CHINZ'10, P73, DOI DOI 10.1145/1832838.1832851
   Susaeta H, 2010, EDUC TECHNOL SOC, V13, P257
   Susi T., 2007, SERIOUS GAMES OVERVI
   Sutcliffe A, 2012, INT J HUM-COMPUT ST, V70, P508, DOI 10.1016/j.ijhcs.2012.01.005
   Tadayon Ramin, 2014, 2014 IEEE International Symposium on Haptic, Audio and Visual Environments and Games (HAVE). Proceedings, P59, DOI 10.1109/HAVE.2014.6954332
   Tan JL, 2013, COMPUT EDUC, V64, P70, DOI 10.1016/j.compedu.2013.01.006
   Thiele S, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P67, DOI 10.1109/3DUI.2013.6550199
   Tolentino G. P., 2011, Proceedings of the 2011 3rd International Conference on Games and Virtual Worlds for Serious Applications (VS-GAMES 2011), P172, DOI 10.1109/VS-GAMES.2011.33
   Tong T, 2014, PROCEEDINGS OF CHINESE CHI 2014: SECOND INTERNATIONAL SYMPOSIUM OF CHINESE CHI (CHINESE CHI 2014), P70, DOI 10.1145/2592235.2592246
   Tullis T.S., 2004, Usability professional association conference, V1, DOI 10.1.1.396.3677
   Valdés BA, 2014, IEEE ENG MED BIO, P3602, DOI 10.1109/EMBC.2014.6944402
   van de Pol MHJ, 2014, J AM GERIATR SOC, V62, P1943, DOI 10.1111/jgs.13024
   Villalta M, 2011, COMPUT EDUC, V57, P2039, DOI 10.1016/j.compedu.2011.05.003
   Virvou M, 2008, COMPUT EDUC, V50, P154, DOI 10.1016/j.compedu.2006.04.004
   VIRZI RA, 1992, HUM FACTORS, V34, P457, DOI 10.1177/001872089203400407
   Wallner Gunter, 2011, P 2011 SIGCHI INT C
   Wang AI, 2008, CONF SOFTW ENG EDUC, P197, DOI 10.1109/CSEET.2008.15
   Weightman APH, 2010, J ENG DESIGN, V21, P579, DOI 10.1080/09544820802441092
   Wise K, 2015, J NEUROSCI METH, V249, P1, DOI 10.1016/j.jneumeth.2015.04.002
   Wronska N, 2015, INT J ENV RES PUB HE, V12, P6261, DOI 10.3390/ijerph120606261
   Yam San Chee, 2010, Proceedings of the 6th IEEE International Conference on Wireless, Mobile and Ubiquitous Technologies in Education (WMUTE 2010), P222, DOI 10.1109/WMUTE.2010.16
   Yamabe T, 2011, IEEE INT CONF EMBED, P126, DOI 10.1109/RTCSA.2011.27
   Gómez RY, 2014, SCI WORLD J, DOI 10.1155/2014/434326
   Yang HC, 2010, COMPUT ASSIST LANG L, V23, P395, DOI 10.1080/09588221.2010.520274
   Yoon JW, 2012, EXPERT SYST APPL, V39, P4898, DOI 10.1016/j.eswa.2011.10.030
   Yun C, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2195
   Zhang MM, 2012, COMPUT GRAPH-UK, V36, P185, DOI 10.1016/j.cag.2012.01.006
   Zin NAM, 2008, THIRD 2008 INTERNATIONAL CONFERENCE ON CONVERGENCE AND HYBRID INFORMATION TECHNOLOGY, VOL 1, PROCEEDINGS, P315, DOI 10.1109/ICCIT.2008.368
NR 257
TC 38
Z9 41
U1 2
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5755
EP 5784
DI 10.1007/s11042-016-3845-9
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500046
DA 2024-07-18
ER

PT J
AU Yin, ZX
   Abel, A
   Tang, J
   Zhang, XP
   Luo, B
AF Yin, Zhaoxia
   Abel, Andrew
   Tang, Jin
   Zhang, Xinpeng
   Luo, Bin
TI Reversible data hiding in encrypted images based on multi-level
   encryption and block histogram modification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Signal processing in encrypted domain (SPED); Reversible data hiding in
   encrypted images (RDH EI); Privacy protection
ID MULTIPLE WATERMARKING; DIFFERENCE; ROBUST
AB In recent years there has been significant interest in reversible data hiding, and also in particular, reversible data hiding in encrypted images (RDH-EI). This means that additional data can be embedded into a previously encrypted image with no knowledge of the original image content. According to the held keys, legal receivers can get the embedded data or an image very similar to the original one, or, both the embedded data and an image exactly as the original one. In this paper, we propose and evaluate a RDH-EI framework. Firstly, we propose a multi-level encryption (MLE) scheme using both Josephus traversal based multi-granular encryption and a stream cipher. To reduce the quantity of side information required to embed into images together with additional data, we also present a block histogram modification (BHM) approach with self-hidden peak pixels to perform reversible data embedding and a location map marking scheme to perform histogram contraction and recovery. The experimental results demonstrate that, in comparison with other similar methods, the proposed framework achieves improvements in terms of the embedding payload, the decrypted image quality and the accuracy of image restoration.
C1 [Yin, Zhaoxia; Zhang, Xinpeng] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200072, Peoples R China.
   [Yin, Zhaoxia; Tang, Jin; Luo, Bin] Anhui Univ, Minist Educ, Key Lab Intelligent Comp & Signal Proc, Hefei 230601, Peoples R China.
   [Abel, Andrew] Univ Stirling, Comp Sci & Math, Stirling, Scotland.
C3 Shanghai University; Anhui University; University of Stirling
RP Zhang, XP (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200072, Peoples R China.
EM yinzhaoxia@ahu.edu.cn; aka@cs.stir.ac.uk; xzhang@shu.edu.cn
RI Abel, Andrew/H-6337-2019; lu, bin/HPE-4790-2023; Yin,
   Zhaoxia/HRD-7425-2023; LUO, BIN/Y-1233-2018
OI Yin, Zhaoxia/0000-0003-0387-4806; LUO, BIN/0000-0001-5948-5055
FU National Science Foundation of China [61502009, 61525203, 61472235];
   China Postdoctoral Science Foundation [2016 M591650]; "Shu Guang"
   project - Shanghai Municipal Education Commission; Shanghai Education
   Development Foundation; Natural Science Foundation of Anhui Province
   (CN) [1508085SQF216]; Key Program for Excellent Young Talents in
   Colleges and Universities of Anhui Province [gxyqZD2016011]; "Sino-UK"
   Higher Education Research Partnership for PhD studies" joint-project -
   British Council China and the China Scholarship Council (CSC)
FX This research work is supported by National Science Foundation of China
   (61502009, 61525203, 61472235), China Postdoctoral Science Foundation
   (2016 M591650), "Shu Guang" project supported by Shanghai Municipal
   Education Commission and Shanghai Education Development Foundation,
   Natural Science Foundation of Anhui Province (CN) (1508085SQF216), Key
   Program for Excellent Young Talents in Colleges and Universities of
   Anhui Province (gxyqZD2016011), and the "Sino-UK" Higher Education
   Research Partnership for PhD studies" joint-project (2013-2015) funded
   by the British Council China and the China Scholarship Council (CSC).
CR Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Erkin Z., 2007, EURASIP Journal on Information Security, V7, P1
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li X, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2014.2372473
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2015, 2015 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING, P831, DOI 10.1109/ChinaSIP.2015.7230521
   Pandey R, 2016, MULTIMED TOOLS APPL, V75, P14381, DOI 10.1007/s11042-016-3536-6
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh AK, 2014, P NATL A SCI INDIA A, V84, P345, DOI 10.1007/s40010-014-0140-x
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang Jenn-hwan., 2015, Border Crossing in Greater China: Production, Community and Identity, P1
   Wang JW, 2015, MULTIMEDIA SYST, V21, P345, DOI 10.1007/s00530-013-0338-9
   Wien Hong, 2013, Advances in Swarm Intelligence. 4th International Conference, ICSI 2013. Proceedings, P208, DOI 10.1007/978-3-642-38715-9_25
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   [向德生 Xiang Desheng], 2005, [计算机工程与应用, Computer Engineering and Application], V41, P44
   Yin ZX, 2014, SCI WORLD J, DOI 10.1155/2014/604876
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 37
TC 32
Z9 32
U1 0
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3899
EP 3920
DI 10.1007/s11042-016-4049-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200035
DA 2024-07-18
ER

PT J
AU Antony, A
   Sreelekha, G
AF Antony, Abhilash
   Sreelekha, G.
TI HEVC-based lossless intra coding for efficient still image compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Intra prediction; Quadtree decomposition; Prediction residual;
   ISAP
ID PARALLEL FRAMEWORK
AB Latest advancements in capture and display technologies demand better compression techniques for the storage and transmission of still images and video. High efficiency video coding (HEVC) is the latest video compression standard developed by the joint collaborative team on video coding (JCTVC) with this objective. Although the main design goal of HEVC is the compression of high resolution video, its performance in still image compression is at par with state-of-the-art still image compression standards. This work explores the possibility of incorporating the efficient intra prediction techniques employed in HEVC into the compression of high resolution still images. In the lossless coding mode of HEVC, sample- based angular intra prediction (SAP) methods have shown better prediction accuracy compared to the conventional block-based prediction (BP). In this paper, we propose an improved sample-based angular intra prediction (ISAP), which enhances the accuracy of the highly crucial intra prediction within HEVC. The experimental results show that ISAP in lossless compression of still images outclasses archival tools, state-of-the-art image compression standards and other HEVC-based lossless image compression codecs.
C1 [Antony, Abhilash; Sreelekha, G.] Natl Inst Technol, Dept Elect & Commun Engn, Calicut 673601, Kerala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Calicut
RP Antony, A (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Calicut 673601, Kerala, India.
EM abhilash_phd11@nitc.ac.in; lekha@nitc.ac.in
RI Antony, Abhilash/I-9692-2019
OI Antony, Abhilash/0000-0001-7974-2733
CR Alzahir S, 2015, IEEE T IMAGE PROCESS, V24, P44, DOI 10.1109/TIP.2014.2363411
   [Anonymous], METHOD FRAME BASED L
   [Anonymous], T 835 INF TECHN
   [Anonymous], 2014, HIGH EFFICIENCY VIDE
   [Anonymous], 2010, The H.264 Advanced Video Compression Standard
   [Anonymous], SAMPLE BASED ANGULAR
   [Anonymous], OPENJPEG VER 2 1 0
   [Anonymous], ASIA PACIFIC SIGNAL
   [Anonymous], 2013, Common test conditions and software reference configuration
   Bross Benjamin, 2012, 2012 IEEE Second International Conference on Consumer Electronics - Berlin (ICCE-Berlin), P26, DOI 10.1109/ICCE-Berlin.2012.6336460
   Bross B., 2013, High Efficiency Video Coding (HEVC) Text Specification Draft 10
   Budagavi M, 2013, IEEE J-STSP, V7, P1029, DOI 10.1109/JSTSP.2013.2270429
   David Salomon., 2007, Data Compression: The Complete Reference
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Li F, 2011, IEEE IMAGE PROC, P373
   Martchenko A, 2013, IEEE T IMAGE PROCESS, V22, P5263, DOI 10.1109/TIP.2013.2284067
   OwenZhao X, 2010, IEEE SIGNAL PROC LET, V17, P383, DOI 10.1109/LSP.2010.2040925
   Pourazad MT, 2012, IEEE CONSUM ELECTR M, V1, P36, DOI 10.1109/MCE.2012.2192754
   Sanchez Victor, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6622, DOI 10.1109/ICASSP.2014.6854881
   Sole J, 2012, IEEE T CIRC SYST VID, V22, P1765, DOI 10.1109/TCSVT.2012.2223055
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Wige E, 2013, PICT COD SYMP, P305, DOI 10.1109/PCS.2013.6737744
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yao YB, 2016, MULTIMED TOOLS APPL, V75, P1963, DOI 10.1007/s11042-014-2382-7
   Zhou MH, 2012, IEEE T CIRC SYST VID, V22, P1839, DOI 10.1109/TCSVT.2012.2221524
NR 27
TC 12
Z9 13
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 1639
EP 1658
DI 10.1007/s11042-015-3138-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000002
DA 2024-07-18
ER

PT J
AU Chen, L
   Hu, RM
   Liang, C
   Li, Q
   Han, Z
AF Chen, Liang
   Hu, Ruimin
   Liang, Chao
   Li, Qing
   Han, Zhen
TI A novel face super resolution approach for noisy images using contour
   feature and standard deviation prior
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face super resolution; Joint learning; Noise scenario; Contour feature;
   Facial standard deviation
ID HALLUCINATION APPROACH; MANIFOLD ANALYSIS; SUPERRESOLUTION;
   RECONSTRUCTION; LIMITS
AB Face Super Resolution (FSR) is to infer high resolution (HR) face images from given low resolution (LR) face images with the help of HR/LR training examples. The most representative FSR is NE methods, which are based on the consistency assumption that the HR/LR patch pairs form similar local geometric structures. But NE methods have difficulty in dealing with noisy facial images. The reason lies in the wrong neighborhood relationship caused by low quality scenarios that even two distinct patches have similar relation in local geometry. Therefore, the consistency assumption is not well held anymore. This paper presents a novel FSR approach suitable for noisy facial images. Our work are twofold. Firstly, different from the existing methods which directly enhance the noisy input image in intensity feature space, the proposed method introduces a contour feature which is robust to noise. By applying the contour feature as constraint, the noise effects can be effectively suppressed. Secondly, different from the existing methods which directly constrain the noisy input image with low quality contour feature, a standard deviation prior is proposed to enhance the low quality contour feature. Through enhancing the contour feature into high quality, the FSR reconstruction can be better constrained. Both simulation and the real-world scenario experiments demonstrate that the proposed approach outperforms most classic methods both quantitatively and qualitatively.
C1 [Chen, Liang; Hu, Ruimin; Liang, Chao; Han, Zhen] Wuhan Univ, Sch Comp, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.
   [Chen, Liang; Li, Qing] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
C3 Wuhan University; City University of Hong Kong
RP Hu, RM (corresponding author), Wuhan Univ, Sch Comp, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.
EM cl_0827@126.com; hurm1964@gmail.com; cliang@whu.edu.cn;
   itqli@cityu.edu.hk
RI Li, Qing/JMH-1365-2023
OI Li, Qing/0000-0003-3370-471X
FU National Nature Science Foundation of China [61231015, 61172173,
   61201247, U1404618, 61303114]; National High Technology Research and
   Development Program of China (863 Program); Technology Research Program
   of Ministry of Public Security [2014JSYJA016]; Guangdong-Hongkong Key
   Domain Breakthrough Project of China [2012A090200007]; major Science and
   Technology Innovation Plan of Hubei Province [2013AAA020]; China
   Postdoctoral Science Foundation [2013M530350]; Specialized Research Fund
   for the Doctoral Program of Higher Education [20130141120024]; Key
   Technology RD Program of Wuhan [2013030409020109]
FX The research is supported by the National Nature Science Foundation of
   China (No. 61231015, 61172173, 61201247, U1404618, 61303114), the
   National High Technology Research and Development Program of China (863
   Program), Technology Research Program of Ministry of Public Security
   (No. 2014JSYJA016), Guangdong-Hongkong Key Domain Breakthrough Project
   of China (No. 2012A090200007), The major Science and Technology
   Innovation Plan of Hubei Province(No. 2013AAA020), China Postdoctoral
   Science Foundation funded project (2013M530350), Specialized Research
   Fund for the Doctoral Program of Higher Education (No. 20130141120024),
   Key Technology RD Program of Wuhan(2013030409020109).
CR Baker S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P83, DOI 10.1109/AFGR.2000.840616
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chakrabarti A, 2007, IEEE T MULTIMEDIA, V9, P888, DOI 10.1109/TMM.2007.893346
   Chan TM, 2009, PATTERN RECOGN LETT, V30, P494, DOI 10.1016/j.patrec.2008.11.008
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chang KI, 2005, IEEE T PATTERN ANAL, V27, P619, DOI 10.1109/TPAMI.2005.70
   Chen L, 2013, IEEE IMAGE PROC, P972, DOI 10.1109/ICIP.2013.6738201
   Chen L, 2014, IEEE INT SYMP CIRC S, P2057, DOI 10.1109/ISCAS.2014.6865570
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Huang H, 2011, IEEE T CIRC SYST VID, V21, P1363, DOI 10.1109/TCSVT.2011.2163461
   Jiang JJ, 2016, IEEE T CIRC SYST VID, V26, P1674, DOI 10.1109/TCSVT.2015.2433538
   Jiang JJ, 2016, SIGNAL PROCESS, V124, P162, DOI 10.1016/j.sigpro.2015.09.026
   Jiang JJ, 2015, IEEE PHOTONICS J, V7
   Jiang JJ, 2014, IEEE T MULTIMEDIA, V16, P1268, DOI 10.1109/TMM.2014.2311320
   Jiang JJ, 2014, SIGNAL PROCESS, V103, P168, DOI 10.1016/j.sigpro.2014.02.014
   Kolouri S, 2015, PROC CVPR IEEE, P4876, DOI 10.1109/CVPR.2015.7299121
   Lan C, 2010, P INT C MULT, P883
   Li B, 2009, IEEE SIGNAL PROC LET, V16, P957, DOI 10.1109/LSP.2009.2027657
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081
   Liu C, 2001, PROC CVPR IEEE, P192
   Liu SF, 2014, IEEE IMAGE PROC, P4032, DOI 10.1109/ICIP.2014.7025819
   Ma X, 2009, IEEE INT CON MULTI, P290, DOI 10.1109/ICME.2009.5202492
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Park SW, 2007, INT CONF ACOUST SPEE, P573
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Shao L, 2008, IEEE T IMAGE PROCESS, V17, P1772, DOI 10.1109/TIP.2008.2002162
   Shao L, 2014, IEEE T CYBERNETICS, V44, P1001, DOI 10.1109/TCYB.2013.2278548
   Sun J, 2003, PROC CVPR IEEE, P729
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Vezzetti E, 2013, COMPUT IND, V64, P1326, DOI 10.1016/j.compind.2013.04.006
   Vezzetti E, 2010, J PLAST RECONSTR AES, V63, P218, DOI 10.1016/j.bjps.2008.09.031
   Wang XG, 2005, IEEE T SYST MAN CY C, V35, P425, DOI 10.1109/TSMCC.2005.848171
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiaohui Dong, 2014, Advances in Multimedia Information Processing - PCM 2014. 15th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8879, P183, DOI 10.1007/978-3-319-13168-9_19
   Yan RM, 2013, IEEE T IMAGE PROCESS, V22, P4689, DOI 10.1109/TIP.2013.2277813
   Yang CY, 2013, PROC CVPR IEEE, P1099, DOI 10.1109/CVPR.2013.146
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
NR 42
TC 9
Z9 9
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2467
EP 2493
DI 10.1007/s11042-015-3145-9
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000038
DA 2024-07-18
ER

PT J
AU Leng, L
   Li, M
   Kim, C
   Bi, X
AF Leng, Lu
   Li, Ming
   Kim, Cheonshik
   Bi, Xue
TI Dual-source discrimination power analysis for multi-instance contactless
   palmprint recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric fusion systems; Dual-source discrimination power analysis;
   Multi-instance contactless palmprint recognition; Feature level fusion;
   Two-dimensional discrete cosine transform
ID DISCRETE COSINE TRANSFORM; FEATURE-LEVEL FUSION; FACE RECOGNITION;
   GEOMETRICAL DESCRIPTORS; PERSONAL IDENTIFICATION; FEATURE-EXTRACTION;
   FEATURES; 3D; VERIFICATION; REPRESENTATION
AB Due to the benefits of palmprint recognition and the advantages of biometric fusion systems, it is necessary to study multi-source palmprint fusion systems. Unfortunately, the research on multi-instance palmprint feature fusion is absent until now. In this paper, we extract the features of left and right palmprints with two-dimensional discrete cosine transform (2DDCT) to constitute a dual-source space. Normalization is utilized in dual-source space to avoid the disturbance caused by the coefficients with large absolute values. Thus complicated pre-masking is needless and arbitrary removing of discriminative coefficients is avoided. Since more discriminative coefficients can be preserved and retrieved with discrimination power analysis (DPA) from dual-source space, the accuracy performance is improved. The experiments performed on contactless palmprint database confirm that dual-source DPA, which is designed for multi-instance palmprint feature fusion recognition, outperforms single-source DPA.
C1 [Leng, Lu; Li, Ming] Nanchang Hangkong Univ, Sch Software, Nanchang 330063, Jiangxi, Peoples R China.
   [Leng, Lu] West Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA.
   [Kim, Cheonshik] Anyang Univ, Dept Digital Media Engn, Anyang, South Korea.
   [Bi, Xue] Xihua Univ, Chengdu 610039, Peoples R China.
C3 Nanchang Hangkong University; West Virginia University; Anyang
   University; Xihua University
RP Kim, C (corresponding author), Anyang Univ, Dept Digital Media Engn, Anyang, South Korea.
EM lenglu@126.com; liming@nchu.edu.cn; mipsan@paran.com;
   bisnowhappy@163.com
RI Bi, Xue/AAF-7425-2020
OI , Xue/0000-0003-3620-1675
FU National Natural Science Foundation of China [61305010, 61262019];
   Voyage Project of Jiangxi Province [201450]; Doctoral Initiating
   Foundation of Nanchang Hangkong University [EA201308058]; Foundation of
   Sichuan Development Research Center of Cultural Industries [WHCY2014A9];
   Key Foundation of Xihua University; Basic Science Research Program
   Through the National Research Foundation of Korea (NRF) by the Ministry
   of Education, Science Technology [20120192]
FX The authors would also like to thank Multimedia University in Malaysia
   for providing us with the palmprint database. This work was supported by
   National Natural Science Foundation of China (61305010, 61262019),
   Voyage Project of Jiangxi Province (201450), Doctoral Initiating
   Foundation of Nanchang Hangkong University (EA201308058), Foundation of
   Sichuan Development Research Center of Cultural Industries (WHCY2014A9),
   Key Foundation of Xihua University, and Basic Science Research Program
   Through the National Research Foundation of Korea (NRF) by the Ministry
   of Education, Science & Technology (20120192).
CR [Anonymous], 2015, P IEEE T IMAGE PROCE
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Chin YJ, 2014, INFORM FUSION, V18, P161, DOI 10.1016/j.inffus.2013.09.001
   Cui JR, 2015, MULTIMED TOOLS APPL, V74, P10989, DOI 10.1007/s11042-014-1887-4
   Dabbaghchian S, 2010, PATTERN RECOGN, V43, P1431, DOI 10.1016/j.patcog.2009.11.001
   Dai JF, 2012, IEEE T PATTERN ANAL, V34, P1618, DOI 10.1109/TPAMI.2011.237
   Delac K, 2009, IMAGE VISION COMPUT, V27, P1108, DOI 10.1016/j.imavis.2008.10.007
   Er MJ, 2005, IEEE T NEURAL NETWOR, V16, P679, DOI 10.1109/TNN.2005.844909
   Guo ZH, 2009, PATTERN RECOGN LETT, V30, P1219, DOI 10.1016/j.patrec.2009.05.010
   Hammami M, 2014, MULTIMED TOOLS APPL, V68, P1023, DOI 10.1007/s11042-012-1109-x
   Jing XY, 2004, IEEE T SYST MAN CY B, V34, P2405, DOI 10.1109/TSMCB.2004.837586
   Kong A, 2006, PATTERN RECOGN, V39, P478, DOI 10.1016/j.patcog.2005.08.014
   Kong A, 2009, PATTERN RECOGN, V42, P1408, DOI 10.1016/j.patcog.2009.01.018
   Kong AWK, 2004, INT C PATT RECOG, P520, DOI 10.1109/ICPR.2004.1334184
   Kumar A, 2005, PATTERN RECOGN, V38, P1695, DOI 10.1016/j.patcog.2005.03.012
   Leng L, 2014, 2014 11TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS (ITNG), P523, DOI 10.1109/ITNG.2014.18
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Li HJ, 2014, MULTIMED TOOLS APPL, V70, P2331, DOI 10.1007/s11042-012-1240-8
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Meraoumia A, 2015, MULTIMED TOOLS APPL, V74, P955, DOI 10.1007/s11042-013-1706-3
   Michael GKO, 2012, J VIS COMMUN IMAGE R, V23, P1068, DOI 10.1016/j.jvcir.2012.07.004
   Monro DM, 2007, IEEE T PATTERN ANAL, V29, P586, DOI 10.1109/TPAMI.2007.1002
   Mu MR, 2011, INT J PATTERN RECOGN, V25, P513, DOI 10.1142/S0218001411008737
   Mu MR, 2011, INT J PATTERN RECOGN, V25, P491, DOI 10.1142/S0218001411008750
   Michael GKO, 2010, PATTERN RECOGN LETT, V31, P1708, DOI 10.1016/j.patrec.2010.05.021
   Peng JL, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.2.023001
   Raghavendra R, 2014, PATTERN RECOGN, V47, P2205, DOI 10.1016/j.patcog.2013.12.011
   Rodrigues RN, 2009, J VISUAL LANG COMPUT, V20, P169, DOI 10.1016/j.jvlc.2009.01.010
   Shekhar S, 2014, IEEE T PATTERN ANAL, V36, P113, DOI 10.1109/TPAMI.2013.109
   Sun ZN, 2005, PROC CVPR IEEE, P279
   Tamrakar D, 2016, MULTIMED TOOLS APPL, V75, P5777, DOI 10.1007/s11042-015-2541-5
   Teoh ABJ, 2014, PALMPRINT MATCHING, P1
   Vezzetti E, 2014, ROBOT AUTON SYST, V62, P1768, DOI 10.1016/j.robot.2014.07.009
   Vezzetti E, 2012, IMAGE VISION COMPUT, V30, P698, DOI 10.1016/j.imavis.2012.02.007
   Vezzetti E, 2012, ROBOT AUTON SYST, V60, P928, DOI 10.1016/j.robot.2012.01.003
   Vishwakarma VP, 2007, ADCOM 2007: PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATIONS, P535, DOI 10.1109/ADCOM.2007.12
   Wu XQ, 2003, PATTERN RECOGN LETT, V24, P2829, DOI 10.1016/S0167-8655(03)00141-7
   Yang B, 2012, SENSORS-BASEL, V12, P5246, DOI 10.3390/s120505246
   Yoon S, 2005, LECT NOTES COMPUT SC, V3656, P1118, DOI 10.1007/11559573_135
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang D, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071391
   Zhang D, 2010, IEEE T INSTRUM MEAS, V59, P480, DOI 10.1109/TIM.2009.2028772
   Zhang D, 2010, PATTERN RECOGN, V43, P358, DOI 10.1016/j.patcog.2009.04.026
   Zhang L, 2012, IEEE SIGNAL PROC LET, V19, P663, DOI 10.1109/LSP.2012.2211589
   Zhang N, 2012, PATTERN RECOGN LETT, V33, P1689, DOI 10.1016/j.patrec.2012.05.020
NR 45
TC 210
Z9 210
U1 3
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 333
EP 354
DI 10.1007/s11042-015-3058-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000015
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Chi, HY
   Chen, CC
   Cheng, WH
   Chen, MS
AF Chi, Heng-Yu
   Chen, Chun-Chieh
   Cheng, Wen-Huang
   Chen, Ming-Syan
TI UbiShop: Commercial item recommendation using visual part-based object
   representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Commercial item recommendation; User preference; Visual part-based
   object representation (VPOR)
ID SYSTEM; RECOGNITION; DISCOVERY; SEARCH
AB With the popularity of online shopping, people have used to shop commercial items on the online shopping websites for convenience. However, based on traditional text search methods, people usually can not find the interesting commercial item they want if they do not know its detailed information, e.g., the name and the seller. Therefore, a more convenient method to help people find the commercial item they want is desired. In this work, we develop a practical system, UbiShop, on mobile phones, whereby users can timely get the related information of interesting commercial items by taking pictures of them. Users can also obtain recommendations on visually similar commercial items to help their buying selections. With the observation that people's preferences on commercial items usually simply depend on their partial visual styles, we propose a novel representation, Visual Part-based Object Representation (VPOR), for commercial item images. The concept of VPOR is to decompose an item image into a set of disjointed partitions, with each of them represents a meaningful semantic parts. User can thus assign non-uniform preferences on the different parts of the commercial item to obtain a personalized recommended results. The experimental results verify our observation and show that the proposed VPOR based commercial item recommendation can achieve better performance than existing text-based and visual-based methods according to the user study.
C1 [Chi, Heng-Yu; Cheng, Wen-Huang; Chen, Ming-Syan] Acad Sinica, Res Ctr Informat Technol Innovat CITI, 128 Sect 2,Acad Rd, Taipei 11529, Taiwan.
   [Chi, Heng-Yu; Chen, Ming-Syan] Natl Taiwan Univ, Dept Elect Engn, 1 Sec 4,Roosevelt Rd, Taipei 10617, Taiwan.
   [Chen, Chun-Chieh] Natl Taiwan Univ, Grad Inst Networking & Multimedia, 1 Sec 4,Roosevelt Rd, Taipei 10617, Taiwan.
C3 Academia Sinica - Taiwan; National Taiwan University; National Taiwan
   University
RP Cheng, WH (corresponding author), Acad Sinica, Res Ctr Informat Technol Innovat CITI, 128 Sect 2,Acad Rd, Taipei 11529, Taiwan.
EM henrychi@arbor.ee.ntu.edu.tw; ccchen@arbor.ee.ntu.edu.tw;
   whcheng@citi.sinica.edu.tw; netdb@ntu.edu.tw
RI Cheng, Wen-Huang/AAK-2774-2020
OI Chen, Ming-Syan/0000-0002-0711-8197
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Ali Eslami S.M., 2012, Advances in NIPS 25, P100
   [Anonymous], 1994, P INT C VERY LARGE D
   [Anonymous], 1999, P 1 ACM C EL COMM
   [Anonymous], 2014, PROC IEEE C COMPUTER, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]
   Arbeláez P, 2012, PROC CVPR IEEE, P3378, DOI 10.1109/CVPR.2012.6248077
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Berg TL, 2010, LECT NOTES COMPUT SC, V6311, P663, DOI 10.1007/978-3-642-15549-9_48
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen YX, 2013, IEEE T KNOWL DATA EN, V25, P2257, DOI 10.1109/TKDE.2012.192
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Creusen MEH, 2005, J PROD INNOVAT MANAG, V22, P63, DOI 10.1111/j.0737-6782.2005.00103.x
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   De Borobia R, 2008, CONSUMER BEHAV PRODU
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Gong B., 2013, NIPS, P1286
   Gonzalez R E Woods R. C., 2009, Digital Image Processing
   Gorelick L, 2006, IEEE T PATTERN ANAL, V28, P1991, DOI 10.1109/TPAMI.2006.253
   Heng-Yu Chi, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P207, DOI 10.1007/978-3-319-04114-8_18
   Hu YQ, 2004, LECT NOTES COMPUT SC, V3332, P993
   Huang J-W, 2011, P 15 PAC AS C KNOWL
   Huang JW, 2011, IEEE SYS MAN CYBERN, P1442, DOI 10.1109/ICSMC.2011.6083873
   Jégou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2
   Kim KJ, 2008, EXPERT SYST APPL, V34, P1200, DOI 10.1016/j.eswa.2006.12.025
   Kim YS, 2005, EXPERT SYST APPL, V28, P381, DOI 10.1016/j.eswa.2004.10.017
   Kraft DH, 2007, TEXT INFORM RETRIEVA
   Kuo YH, 2012, IEEE T MULTIMEDIA, V14, P1079, DOI 10.1109/TMM.2012.2190386
   Kuo YH, 2011, PROC CVPR IEEE, P905, DOI 10.1109/CVPR.2011.5995639
   Li H, 2011, P 3 NT C INT MULT CO, P5
   Ma H., 2011, Proceedings of the 4th ACM International Conference on Web Search and Data Mining, P287
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Meng H, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS I-V, CONFERENCE PROCEEDINGS, P88, DOI 10.1109/ICMA.2007.4303521
   Nister David, 2006, CVPR
   Norman D.A., 2007, EMOTIONAL DESIGN WHY
   Opelt A, 2006, LECT NOTES COMPUT SC, V3952, P575
   Park JS, 1995, EFFECTIVE HASH BASED
   Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111
   Soh PH, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P197
   Soille P., 2013, MORPHOLOGICAL IMAGE
   Tang XO, 2012, IEEE T PATTERN ANAL, V34, P1342, DOI 10.1109/TPAMI.2011.242
   Tsai TH, 2014, IEEE T IMAGE PROCESS, V23, P1047, DOI 10.1109/TIP.2014.2298982
   Wang Xianwang., 2011, Proceedings of the 19th ACM International Conference on Multimedia, MM'11, P1353
   Xiao W, 2012, INTERACTIVE PRODUCT
   YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068
   Yu A, 2014, PROC CVPR IEEE, P192, DOI 10.1109/CVPR.2014.32
   Zhao B, 2010, LECT NOTES COMPUT SC, V6315, P785, DOI 10.1007/978-3-642-15555-0_57
   Zheng ZB, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES, VOLS 1 AND 2, P437, DOI 10.1109/ICWS.2009.30
NR 48
TC 10
Z9 10
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16093
EP 16115
DI 10.1007/s11042-015-2916-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700055
DA 2024-07-18
ER

PT J
AU Chun, J
   Kim, W
AF Chun, Junchul
   Kim, Wonggi
TI 3D face pose estimation by a robust real time tracking of facial
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Head pose estimation; Haar-like feature detection; Optical flow;
   AdaBoost learning algorithm; Template matching
AB In this paper, we present a new 3D head pose estimating approach based on real-time facial feature tracking and facial feature recovering method which copes with the surrounding light variation and various occlusion. The major facial features are obtained by Haar-like feature detection along with AdaBoost learning from an input video image. The detected facial features are robustly tracked by optical flow with a template matching scheme which continuously compensates for losing track of the initially detected features in a sequence of input images. The head pose of an input face image can be obtained by evaluating 3D information of facial features from the detected 2D eye-points, nose and lip. From the experiments, the proposed method shows effectiveness in tracking and recovering facial features and produces reliable result in head pose estimation.
C1 [Chun, Junchul; Kim, Wonggi] Kyonggi Univ, Dept Comp Sci, San 94-6 Yiui Dong, Suwon, South Korea.
C3 Kyonggi University
RP Chun, J (corresponding author), Kyonggi Univ, Dept Comp Sci, San 94-6 Yiui Dong, Suwon, South Korea.
EM jcchun@kgu.ac.kr
FU Kyonggi University
FX This work was supported by Kyonggi University Research Grant 2013.
CR Akhtar H., 2012, HUMAN CTR COMPUTING, V2, DOI 10.1186/2192-1962-2-14
   Andrew G, 1992, IEEE INT C COMP VIS, P758
   [Anonymous], 2011, Wireless Communications and Signal Processing (WCSP), 2011 International Conference on
   Chun J, 2008, KSII T INTERNET INF, V2, P120, DOI 10.3837/tiis.2008.02.004
   Fanelli Gabriele, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P101, DOI 10.1007/978-3-642-23123-0_11
   Ghimire D, 2013, J INF PROCESS SYST, V9, P141, DOI 10.3745/JIPS.2013.9.1.141
   Linda G.C. S., 2001, Computer Vision
   Lucas B., 1981, Proc. DARPA Image Understanding Workshop, P121
   Min K, 2005, LECT NOTES COMPUT SC, V3480, P1135
   Min K, 2004, LECT NOTES COMPUT SC, V3320, P116
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Sung J, 2008, INT J COMPUT VISION, V80, P260, DOI 10.1007/s11263-007-0125-1
   Valenti R, 2012, IEEE T IMAGE PROCESS, V21, P802, DOI 10.1109/TIP.2011.2162740
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Xiao J, 2003, INT J IMAG SYST TECH, V13, P85, DOI 10.1002/ima.10048
   Yang X., 2013, J CONVERG, V4, P11
NR 17
TC 2
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15693
EP 15708
DI 10.1007/s11042-014-2356-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700036
DA 2024-07-18
ER

PT J
AU Li, Q
   Sun, ZX
   Chen, SL
   Xia, SM
AF Li, Qian
   Sun, Zhengxing
   Chen, Songle
   Xia, Shiming
TI Dynamic node selection in camera networks based on approximate
   reinforcement learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camera selection; Approximate reinforcement learning; Gaussian mixture
   model (GMM); Video analysis; Camera networks
ID VIDEO; TRACKING
AB In camera networks, dynamic node selection is an effective technique that enables video stream transmission with constrained network bandwidth, more economical node cooperation for nodes with constrained power supplies, and optimal use of a limited number of display terminals, particularly for applications that need to obtain high-quality video of specific targets. However, the nearest camera in a network cannot be identified by directional measurements alone. Furthermore, errors are introduced into computer vision algorithms by complex background, illumination, and other factors, causing unstable and jittery processing results. Consequently, in selecting camera network nodes, two issues must be addressed: First, a dynamic selection mechanism that can choose the most appropriate node is needed. Second, metrics to evaluate the visual information in a video stream must be modeled and adapted to various camera parameters, backgrounds, and scenes. This paper proposes a node selection method based on approximate reinforcement learning in which nodes are selected to obtain the maximum expected reward using approximate Q-learning. The Q-function is approximated by a Gaussian Mixture Model with parameters that are sequentially updated by a mini-batch stepwise Expectation-Maximization algorithm. To determine the most informative camera node dynamically, the immediate reward in Q-learning integrates the visibility, orientation, and image clarity of the object in view. Experimental results show that the proposed visual evaluation metrics can effectively capture the motion state of objects, and that the selection method reduces camera switching and related errors compared with state-of-the art methods.
C1 [Li, Qian; Sun, Zhengxing; Chen, Songle] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Jiangsu, Peoples R China.
   [Li, Qian; Xia, Shiming] PLA Univ Sci & Technol, Coll Meteorol & Oceanog, Nanjing 211101, Jiangsu, Peoples R China.
C3 Nanjing University; Army Engineering University of PLA
RP Sun, ZX (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Jiangsu, Peoples R China.
EM public_liqian@163.com; szx@nju.edu.cn; chensongle@hotmail.com;
   15295753714@163.com
RI Sun, Zhengxing/A-7411-2011
OI Qian, Li/0000-0002-9530-4925; Sun, Zhengxing/0000-0001-7137-6169
FU National Natural Science Foundation of China [61272219, 61100110,
   41305138, 61473310, 61321491]; Program for New Century Excellent Talents
   of Ministry of Education of China [NCET-04-0460]; Science and Technology
   Plan of Jiangsu Province [BE2010072, BE2011058, BY2012190,
   BY2013072-04]; Innovation Foundation of State Key Lab for Novel Software
   Technology of China [ZZKT2013A12]
FX This work is supported by the National Natural Science Foundation of
   China (61272219, 61100110, 41305138, 61473310 and 61321491), Program for
   New Century Excellent Talents of Ministry of Education of China
   (NCET-04-0460), Science and Technology Plan of Jiangsu Province
   (BE2010072, BE2011058, BY2012190, and BY2013072-04), and Innovation
   Foundation of State Key Lab for Novel Software Technology of China
   (ZZKT2013A12).
CR Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21
   Agostini A., 2010, IJCNN, P1
   [Anonymous], 1998, REINFORCEMENT LEARNI, DOI [DOI 10.1109/TNN.1998.712192, 10.1109/TNN.1998.712192]
   [Anonymous], P 26 AAAI C ART INT
   [Anonymous], 2009, P HUMAN LANGUAGE TEC
   [Anonymous], AUTOM CONTROL ENG SE
   Botvinick MM, 2009, COGNITION, V113, P262, DOI 10.1016/j.cognition.2008.08.011
   Changsong Shen, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P193
   Charfi Y, 2009, IEEE WIREL COMMUN, V16, P44, DOI 10.1109/MWC.2009.4907559
   Cohn DA, 1996, J ARTIF INTELL RES, V4, P129, DOI 10.1613/jair.295
   Daniyal F, 2010, MULTIMED TOOLS APPL, V46, P235, DOI 10.1007/s11042-009-0355-z
   Fu YW, 2010, IEEE T MULTIMEDIA, V12, P717, DOI 10.1109/TMM.2010.2052025
   Gupta A, 2007, IEEE I CONF COMP VIS, P118
   Han B, 2011, INT J COMPUT VISION, V91, P45, DOI 10.1007/s11263-010-0373-3
   Huber MF, 2012, IEEE T AUTOMAT CONTR, V57, P1338, DOI 10.1109/TAC.2011.2175070
   Javed O, 2000, WORKSHOP ON HUMAN MOTION, PROCEEDINGS, P113, DOI 10.1109/HUMO.2000.897380
   Jiang H, 2008, IEEE T MULTIMEDIA, V10, P997, DOI 10.1109/TMM.2008.2001379
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li Q, 2013, P AMER CONTR CONF, P3833
   Li W, 2012, IET WIREL SENS SYST, V2, P293, DOI 10.1049/iet-wss.2012.0033
   Li YM, 2011, IEEE SENS J, V11, P676, DOI 10.1109/JSEN.2010.2051148
   McLachlan G., 2000, WILEY SER PROB STAT, DOI 10.1002/0471721182
   Mo YL, 2011, AUTOMATICA, V47, P1330, DOI 10.1016/j.automatica.2011.02.001
   Monari E, 2009, 3 ACM IEEE INT C DIS, DOI [10.1109/ICDSC.2009.5289400, DOI 10.1109/ICDSC.2009.5289400]
   Park J, 2006, IEEE WORKSH DISTR SM
   Rudoy D, 2012, INT J COMPUT VISION, V97, P243, DOI 10.1007/s11263-011-0484-5
   Sato M, 2000, NEURAL COMPUT, V12, P407, DOI 10.1162/089976600300015853
   Singh S. P., 1995, Advances in Neural Information Processing Systems 7, P361
   Soro S, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P81, DOI 10.1109/AVSS.2007.4425290
   Soro S, 2009, ADV MULTIMED, V2009, DOI 10.1155/2009/640386
   Spaan M, 2009, ICAPS, P1
   Tessens L., 2008, P 2 ACMIEEE INT C DI, P1, DOI [10.1109/ICDSC.2008.4635699, DOI 10.1109/ICDSC.2008.4635699]
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
NR 33
TC 2
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17393
EP 17419
DI 10.1007/s11042-015-3003-9
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600029
DA 2024-07-18
ER

PT J
AU Walia, GS
   Kapoor, R
AF Walia, Gurjit Singh
   Kapoor, Rajiv
TI Robust object tracking based upon adaptive multi-cue integration for
   video surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; DSmT; Multi-Cue; Data fusion; Particle filter
ID VISUAL TRACKING; FUSION
AB It was well argued in literature that integrating multi-cue increases accuracy and robustness of visual tracking. Although, multi-cues object tracking using singlemodal or multimodal was explored by some of researchers, it still remains an open challenge to fuse multi-cue from different modularity under dynamic environment conditions. The aim of this research paper is to introduce a novel multi-cue object tracking framework using particle filter. In particle filter framework, our approach integrates cues while evaluating each particle instead of primitive approach of deciding cues performance in current frame based upon either a few present particles or previous state particles. First, we model our multi-cue tracking framework using Shafer's model and multi-cue data is combined using Conjunctive combination rules. The partial and total conflict among cues at particle level is redistributed efficiently using Proportional Conflict Redistribution (PCR-5) rules. In proposed model, automatic suppression/boosting of particles along with online conflict resolving facilitate resampling process for efficiently handling of particle degeneracy. Most importantly, compared to other state-of-art trackers, our proposed algorithm can handle more efficiently various dynamic environments conditions such as partial or full occlusion, illumination changes, weather, and visibility. In this manuscript, we demonstrate our proposed adaptive multi-cue fusion model on challenging benchmark video and thermal sequences and compare tracking results of our tracker with state-of- art trackers.
C1 [Walia, Gurjit Singh] Minist Def, SAG, Def Res & Dev Org, Delhi, India.
   [Kapoor, Rajiv] Delhi Technol Univ, Dept Elect & Commun, Delhi, India.
C3 Defence Research & Development Organisation (DRDO); Scientific Analysis
   Group (SAG); Delhi Technological University
RP Kapoor, R (corresponding author), Delhi Technol Univ, Dept Elect & Commun, Delhi, India.
EM rajivkapoor.dtu@gmail.com
RI Kapoor, Rajiv/AAA-2011-2022
OI Kapoor, Rajiv/0000-0003-3020-1455
CR Airouche M, 2012, MACH VISION APPL, V23, P999, DOI 10.1007/s00138-011-0342-z
   [Anonymous], INT J ADV ROBOT SYST
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Bhattacharyya Anil, 1943, B CALCUTTA MATH SOC, V35, P99
   Bower TGR, PERCEPTION ESSAYS HO, P141
   Brasnett P, 2007, IMAGE VISION COMPUT, V25, P1217, DOI 10.1016/j.imavis.2006.07.017
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Davis JW, 2007, COMPUT VIS IMAGE UND, V106, P162, DOI 10.1016/j.cviu.2006.06.010
   Dou JF, 2014, OPTIK, V125, P1680, DOI 10.1016/j.ijleo.2013.10.007
   Erdem E, 2012, PATTERN RECOGN, V45, P1948, DOI 10.1016/j.patcog.2011.10.028
   GORDON NJ, 1993, IEE PROC-F, V140, P107, DOI 10.1049/ip-f-2.1993.0015
   Lazarevic-McManus N, 2008, COMPUT VIS IMAGE UND, V111, P74, DOI 10.1016/j.cviu.2007.07.007
   Li PH, 2004, LECT NOTES COMPUT SC, V3179, P99
   Murphy RR, 1996, IEEE T SYST MAN CY A, V26, P42, DOI 10.1109/3468.477859
   Pérez P, 2004, P IEEE, V92, P495, DOI 10.1109/JPROC.2003.823147
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   SMARANDACHE F, 2005, P 8 INT C INF FUS PH
   Smarandache F., 2009, APPL ADV DSMT INFORM, V3
   SMARANDACHE F, 2006, APPL ADV DSMT INFORM, V2
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Spengler M, 2003, MACH VISION APPL, V14, P50, DOI 10.1007/s00138-002-0095-9
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sun Y, 2010, J MATH IMAGING VIS, V36, P159, DOI 10.1007/s10851-009-0178-6
   Walia GS, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414550040
   Walia GS, 2014, EXPERT SYST APPL, V41, P6315, DOI 10.1016/j.eswa.2014.03.012
   Walia GS, 2013, IEEE INT ADV COMPUT, P918
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yin MH, 2011, EXPERT SYST APPL, V38, P6313, DOI 10.1016/j.eswa.2010.11.111
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
   Zhang MH, 2013, NEUROCOMPUTING, V122, P163, DOI 10.1016/j.neucom.2013.05.041
   Zhou HY, 2014, PATTERN RECOGN, V47, P3552, DOI 10.1016/j.patcog.2014.05.006
NR 33
TC 17
Z9 18
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15821
EP 15847
DI 10.1007/s11042-015-2890-0
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700042
DA 2024-07-18
ER

PT J
AU Wang, WJ
   Huang, CT
   Tsuei, SR
   WANG, SJ
AF Wang, Wei-Jen
   Huang, Cheng-Ta
   Tsuei, Shiau-Rung
   Wang, Shiuh-Jeng
TI A greedy steganographic SMVQ approach of greedy-USBIRDS using secret
   bits for image-block repairing based on differences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information hiding; Steganography; Side-match vector quantization (SMVQ)
ID SIDE MATCH; WATERMARKING
AB Steganography conceals the secret data into cover media to avoid detection, such that no one suspects the existence of the embedded secret data. The existing VQ-based and SMVQ-based steganographic methods can only provide the same level of visual quality of what the VQ/SMVQ compression method can offer. In this study, we present the idea of using secret bits to repair SMVQ-compressed images. The idea can be viewed as the optimization problem of Using Secret Bits for Image-block Repairing based on Differences under SMVQ (USBIRDS). We propose a novel approach named Greedy-USBIRDS to find a near optimal solution for the USBIRDS problem. The experimental results show that, the proposed method provides excellent stego-image quality and large embedding capacity, in particular for complex cover images such as Baboon. While compared with Chen and Lin's steganographic method, which is the known best method based on VQ/SMVQ, the proposed method achieves about 53 % more dB of PSNR of the stego-image quality and about 4.2 % more bits of the embedding capacity on average. All the experimental results indicate that, this study makes significant contributions to the area of VQ-based and SMVQ-based steganography, especially for its excellent stego-image quality and its ability to handle complex cover images very well.
C1 [Wang, Wei-Jen; Tsuei, Shiau-Rung] Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan 320, Taiwan.
   [Huang, Cheng-Ta] Natl Taiwan Univ Sci & Technol, Grad Inst Biomed Engn, Taipei 106, Taiwan.
   [Wang, Shiuh-Jeng] Cent Police Univ, Dept Informat Management, Taoyuan 333, Taiwan.
C3 National Central University; National Taiwan University of Science &
   Technology
RP WANG, SJ (corresponding author), Cent Police Univ, Dept Informat Management, Taoyuan 333, Taiwan.
EM sjwang@mail.cpu.edu.tw
RI Wang, Suhang/AAH-1378-2019
FU Ministry of Science and Technology of the Republic of China [NSC
   102-2221-E-015-001-, MOST 103-2221-E-015-002-, MOST 103-2221-E-008-089-]
FX This research was partially supported by the Ministry of Science and
   Technology of the Republic of China under the Grant NSC
   102-2221-E-015-001-, MOST 103-2221-E-015-002- and MOST
   103-2221-E-008-089-.
CR Chan YK, 2009, J SYST SOFTWARE, V82, P411, DOI 10.1016/j.jss.2008.07.008
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chang CC, 2006, IEEE T INF FOREN SEC, V1, P493, DOI 10.1109/TIFS.2006.885034
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chen LST, 2010, OPT ENG, V49, DOI 10.1117/1.3366654
   Chen WM, 2011, IET IMAGE PROCESS, V5, P349, DOI 10.1049/iet-ipr.2009.0362
   Cogranne R, 2013, IEEE T INF FOREN SEC, V8, P464, DOI 10.1109/TIFS.2013.2238232
   Guillermito, 2004, STEG FEW TOOLS DISC
   Keyvanpour MR, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2010.12.040
   Kim TJ, 1992, IEEE T IMAGE PROCESS, V1, P170, DOI 10.1109/83.136594
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Lou DC, 2012, INFORM SCIENCES, V188, P346, DOI 10.1016/j.ins.2011.06.003
   Lu ZM, 2009, J SYST SOFTWARE, V82, P1016, DOI 10.1016/j.jss.2009.01.010
   Noda H, 2006, PATTERN RECOGN LETT, V27, P455, DOI 10.1016/j.patrec.2005.09.008
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Phadikar A, 2011, COMPUT ELECTR ENG, V37, P339, DOI 10.1016/j.compeleceng.2011.02.002
   Phan RCW, 2008, PATTERN RECOGN, V41, P3493, DOI 10.1016/j.patcog.2008.05.009
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Tsai P, 2009, IET IMAGE PROCESS, V3, P100, DOI 10.1049/iet-ipr.2007.0220
   Tsai YS, 2011, INFORM SCIENCES, V181, P3188, DOI 10.1016/j.ins.2011.03.017
   Wang JX, 2009, INFORM SCIENCES, V179, P3332, DOI 10.1016/j.ins.2009.05.021
   Wang WJ, 2011, IEEE SYST J, V5, P528, DOI 10.1109/JSYST.2011.2165603
   Xu H, 2010, INFORM SCIENCES, V180, P1201, DOI 10.1016/j.ins.2009.12.027
   Yang CH, 2011, INFORM SCIENCES, V181, P2218, DOI 10.1016/j.ins.2011.01.015
   Yang CH, 2010, J SYST SOFTWARE, V83, P1635, DOI 10.1016/j.jss.2010.03.081
   Yang CH, 2010, J VIS COMMUN IMAGE R, V21, P334, DOI 10.1016/j.jvcir.2010.02.008
   Zhang T, 2010, INFORM SCIENCES, V180, P4685, DOI 10.1016/j.ins.2010.07.037
NR 28
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14895
EP 14916
DI 10.1007/s11042-015-2761-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500052
DA 2024-07-18
ER

PT J
AU Wu, SL
   Chen, HD
   Bai, Y
   Zhu, GK
AF Wu, Shulei
   Chen, Huandong
   Bai, Yong
   Zhu, Guokang
TI A remote sensing image classification method based on sparse
   representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Sparse representation; Image reconstruction;
   Remote sensing
ID HYPERSPECTRAL DATA; NEURAL-NETWORK; SVM; FEATURES
AB With the development of remote sensing image applications, sparse-based representation classification approaches have been investigated for better classification accuracy. This paper introduces an improved classification method based on sparse representation by representing the test samples through a dictionary. The key components of our proposed method rely on the feature dictionary construction, sparse representation and image reconstruction. The dictionary is obtained by training samples according to their class for a sparse linear combination. The sparse representation for the image is expressed as sparse coefficients by solving an optimization problem. We describe the method of constructing a dictionary by computing a best matrix to represent all data vectors. We also describe the algorithm used to solve for the sparse representation. Finally, we discuss the way of using the sparse vector to reconstruct the image for classification. In the experiments, the proposed method is applied to two real high spatial resolution images for the classification in comparison to Backpropagation Neural Network, Support Vector Machine, Classification and Regression Trees and K-means. The experimental results show that the proposed method performs better than the benchmark methods in terms of classification accuracy.
C1 [Wu, Shulei; Bai, Yong] Hainan Univ, Coll Informat Sci & Technol, 58 Renming Rd, Haikou 570228, Peoples R China.
   [Wu, Shulei; Chen, Huandong] Hainan Normal Univ, Coll Informat Sci & Technol, 99 South Longkun Rd, Haikou 571158, Peoples R China.
   [Zhu, Guokang] Shanghai Univ Elect Power, Coll Comp Sci & Technol, 2588 Changyang Rd, Shanghai 200090, Peoples R China.
C3 Hainan University; Hainan Normal University; Shanghai University of
   Electric Power
RP Bai, Y (corresponding author), Hainan Univ, Coll Informat Sci & Technol, 58 Renming Rd, Haikou 570228, Peoples R China.
EM baiyonghnu@163.com
FU National Natural Science Foundation of China [61163042, 61503235,
   41272359]; Discipline (Cartography and Geographic Information System of
   Hainan Normal University)
FX This work was supported by the National Natural Science Foundation of
   China (No. 61163042 61503235 and 41272359), and funded by Key Discipline
   (Cartography and Geographic Information System of Hainan Normal
   University).
CR Agüera F, 2008, ISPRS J PHOTOGRAMM, V63, P635, DOI 10.1016/j.isprsjprs.2008.03.003
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   BISCHOF H, 1992, IEEE T GEOSCI REMOTE, V30, P482, DOI 10.1109/36.142926
   Bruzzone L, 2006, IEEE T GEOSCI REMOTE, V44, P3363, DOI 10.1109/TGRS.2006.877950
   Bruzzone L, 2006, IEEE T GEOSCI REMOTE, V44, P2587, DOI 10.1109/TGRS.2006.875360
   CHEN SB, 1994, CONF REC ASILOMAR C, P41, DOI 10.1109/ACSSC.1994.471413
   CHOU PA, 1991, IEEE T PATTERN ANAL, V13, P340, DOI 10.1109/34.88569
   Cotter SF, 2005, IEEE T SIGNAL PROCES, V53, P2477, DOI 10.1109/TSP.2005.849172
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Dópido I, 2013, IEEE T GEOSCI REMOTE, V51, P4032, DOI 10.1109/TGRS.2012.2228275
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fauvel M, 2012, PATTERN RECOGN, V45, P381, DOI 10.1016/j.patcog.2011.03.035
   Giacinto G, 2001, IMAGE VISION COMPUT, V19, P699, DOI 10.1016/S0262-8856(01)00045-2
   Goel PK, 2003, COMPUT ELECTRON AGR, V39, P67, DOI 10.1016/S0168-1699(03)00020-6
   HEERMANN PD, 1992, IEEE T GEOSCI REMOTE, V30, P81, DOI 10.1109/36.124218
   Huang X, 2007, IEEE GEOSCI REMOTE S, V4, P260, DOI 10.1109/LGRS.2006.890540
   Huang X, 2013, IEEE T GEOSCI REMOTE, V51, P257, DOI 10.1109/TGRS.2012.2202912
   Inglada J, 2007, ISPRS J PHOTOGRAMM, V62, P236, DOI 10.1016/j.isprsjprs.2007.05.011
   Jiang LH, 2011, IFIP ADV INF COMM TE, V344, P353
   Li JY, 2015, IEEE J-STARS, V8, P2523, DOI 10.1109/JSTARS.2015.2437073
   Li JY, 2015, IEEE T GEOSCI REMOTE, V53, P5338, DOI 10.1109/TGRS.2015.2421638
   Luo M, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P738
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Moody DI, 2014, J APPL REMOTE SENS, V8
   Moser G, 2013, P IEEE, V101, P631, DOI 10.1109/JPROC.2012.2211551
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Ouma YO, 2008, ISPRS J PHOTOGRAMM, V63, P333, DOI 10.1016/j.isprsjprs.2007.10.006
   Palmason J. A., 2005, P 2005 INT C GEOSC R, P25
   PAOLA JD, 1995, IEEE T GEOSCI REMOTE, V33, P981, DOI 10.1109/36.406684
   Pingel TJ, 2013, ISPRS J PHOTOGRAMM, V77, P21, DOI 10.1016/j.isprsjprs.2012.12.002
   Rakotomamonjy A, 2011, SIGNAL PROCESS, V91, P1505, DOI 10.1016/j.sigpro.2011.01.012
   Ray S., 1999, PROC 4 INT C ADV PAT, P137, DOI DOI 10.1109/TKDE.2008.158
   Reis S, 2011, ISPRS J PHOTOGRAMM, V66, P652, DOI 10.1016/j.isprsjprs.2011.04.006
   Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551
   Stoeva S, 2000, FUZZY SET SYST, V112, P27, DOI 10.1016/S0165-0114(98)00079-7
   Tropp JA, 2006, SIGNAL PROCESS, V86, P572, DOI 10.1016/j.sigpro.2005.05.030
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Tropp JA, 2010, P IEEE, V98, P948, DOI 10.1109/JPROC.2010.2044010
   Tuia D, 2011, J SIGNAL PROCESS SYS, V65, P301, DOI 10.1007/s11265-010-0483-8
   Tuia D, 2010, IEEE GEOSCI REMOTE S, V7, P88, DOI 10.1109/LGRS.2009.2015341
   Yang J, 2010, INT J ADV INF TECHNO, V4, P89
   Yu XC, 2011, CHINESE J GEOPHYS-CH, V54, P1672, DOI 10.3969/j.issn.0001-5733.2011.06.027
   [余先川 YU Xian-chuan], 2009, [地球物理学进展, Progress in Geophysiscs], V24, P2274
   Zhang HY, 2014, IEEE J-STARS, V7, P2056, DOI 10.1109/JSTARS.2013.2264720
NR 46
TC 6
Z9 6
U1 0
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 12137
EP 12154
DI 10.1007/s11042-016-3320-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200031
DA 2024-07-18
ER

PT J
AU Huang, C
   Luo, W
AF Huang, Chao
   Luo, Wang
TI Scene classification using class-supervised local-space-constraint
   latent Dirichlet allocation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Topic model; Classification; LSC-LDA; Location
ID ANNOTATION; PATTERNS; MODEL
AB This paper proposes a graphical model termed as Local-Space-Constraint LDA (LSC-LDA) for image classification. The existing LDA based methods using the Bag-of-Words (BoW) representation ignore the spatial information of the image. To address this problem, the image is partitioned into several regions and a latent variable is assigned to each region. We construct the supervised LSC-LDA termed as Class-Supervised LSC-LDA (CS-LSC-LDA) to learn class-specific topics. During the parameter learning step, the variational inference is employed to approximate the proposed model. The maximum a posterior probability (MAP) measure is used to compute the parameters. The effectiveness of the proposed model is demonstrated through the extensive evaluations in three well-known datasets. It observes that our model outperforms the existing LDA based models.
C1 [Huang, Chao] Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu, Peoples R China.
   [Luo, Wang] NARI Grp Corp, Nanjing, Jiangsu, Peoples R China.
C3 University of Electronic Science & Technology of China; Nari Group Corp
RP Huang, C (corresponding author), Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu, Peoples R China.
EM huangchao_uestc@aliyun.com; luowang@sgepri.sgcc.com.cn
RI Huang, Chao/L-1445-2019; Huang, Chao/JJD-0553-2023
OI Huang, Chao/0000-0001-8775-3192
FU program for Science and Technology Innovative Research Team for Young
   Scholars in Sichuan Province, China [2014TD0006]; Jiangsu Provincial
   Natural Science Foundation [BK20130107]
FX This work was supported in part by the program for Science and
   Technology Innovative Research Team for Young Scholars in Sichuan
   Province, China (No. 2014TD0006) and by Jiangsu Provincial Natural
   Science Foundation (No. BK20130107).
CR [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2012, LIBSVM LIB SUPPORT V
   [Anonymous], 2006, PATTERN RECOGN, DOI DOI 10.1117/1.2819119
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2008, Advances in Neural Information Processing Systems
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2008, P ADV NEURAL INFORM
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Huang C, 2014, J VIS COMMUN IMAGE R, V25, P1299, DOI 10.1016/j.jvcir.2014.05.002
   Kobayashi T, 2013, PROC CVPR IEEE, P747, DOI 10.1109/CVPR.2013.102
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li L. J., 2007, IEEE INT C COMPUTER, P1
   Li LJ, 2009, PROC CVPR IEEE, P2036, DOI 10.1109/CVPRW.2009.5206718
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Luo W, 2014, IEEE T GEOSCI REMOTE, V52, P1356, DOI 10.1109/TGRS.2013.2250978
   Meng H, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS I-V, CONFERENCE PROCEEDINGS, P88, DOI 10.1109/ICMA.2007.4303521
   Neal RM, 2000, J COMPUT GRAPH STAT, V9, P249, DOI 10.2307/1390653
   Niu ZX, 2012, PROC CVPR IEEE, P2743, DOI 10.1109/CVPR.2012.6247997
   Niu ZX, 2011, PROC CVPR IEEE, P1769, DOI 10.1109/CVPR.2011.5995426
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Qian XM, 2011, PATTERN RECOGN, V44, P2502, DOI 10.1016/j.patcog.2011.03.029
   Rasiwasia N, 2013, IEEE T PATTERN ANAL, V35, P2665, DOI 10.1109/TPAMI.2013.69
   Song TC, 2015, PATTERN RECOGN, V48, P2621, DOI 10.1016/j.patcog.2015.03.003
   Song TC, 2014, IEEE SIGNAL PROC LET, V21, P93, DOI 10.1109/LSP.2013.2293335
   Song TC, 2013, PATTERN RECOGN LETT, V34, P1323, DOI 10.1016/j.patrec.2013.04.020
   Doan TN, 2015, MULTIMED TOOLS APPL, V74, P1199, DOI 10.1007/s11042-014-2049-4
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Winn J, 2005, J MACH LEARN RES, V6, P661
   Zhu J., 2009, Proceedings of the 26th Annual International Conference on Machine Learning, ICML '09, P1257, DOI DOI 10.1145/1553374.1553535
NR 36
TC 2
Z9 2
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10227
EP 10240
DI 10.1007/s11042-015-3024-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800007
DA 2024-07-18
ER

PT J
AU Jarraya, SK
   Hammami, M
   Ben-Abdallah, H
AF Jarraya, Salma Kammoun
   Hammami, Mohamed
   Ben-Abdallah, Hanene
TI Adaptive moving shadow detection and removal by new semi-supervised
   learning technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shadow detection; Cast shadow removal; Foreground segmentation;
   Semi-supervised learning; Co-training technique
ID SEGMENTATION
AB The efficient application of current methods of shadow detection in video is hindered by the difficulty in defining their parameters or models and/or their application domain dependence. This paper presents a new shadow detection and removal method that aims to overcome these inefficiencies. It proposes a semi-supervised learning rule using a new variant of co-training technique for shadow detection and removal in uncontrolled scenes. The new variant both reduces the run-time through a periodical execution of a co-training process according to a novel temporal framework, and generates a more generic prediction model for an accurate classification. The efficiency of the proposed method is shown experimentally on a testbed of videos that were recorded by a static camera and that included several constraints, e.g., dynamic changes in the natural scene and various visual shadow features. The conducted experimental study produced quantitative and qualitative results that highlighted the robustness of our shadow detection method and its accuracy in removing cast shadows. In addition, the practical usefulness of the proposed method was evaluated by integrating it in a Highway Control and Management System software called RoadGuard.
C1 [Jarraya, Salma Kammoun] King Abdulaziz Univ, Fac Comp & Informat Technol, CS Dept, Jeddah, Saudi Arabia.
   [Jarraya, Salma Kammoun; Hammami, Mohamed] Univ Sfax, Mir Cl Lab, Sfax, Tunisia.
   [Hammami, Mohamed] Sfax Univ, Fac Sci, Dept Comp Sci, Sfax, Tunisia.
   [Ben-Abdallah, Hanene] King Abdulaziz Univ, Fac Comp & Informat Technol, IS Dept, Jeddah, Saudi Arabia.
C3 King Abdulaziz University; Universite de Sfax; Universite de Sfax;
   Faculty of Sciences Sfax; King Abdulaziz University
RP Jarraya, SK (corresponding author), King Abdulaziz Univ, Fac Comp & Informat Technol, CS Dept, Jeddah, Saudi Arabia.; Jarraya, SK (corresponding author), Univ Sfax, Mir Cl Lab, Sfax, Tunisia.
EM smohamad1@kau.edu.sa; Mohamed.Hammami@fss.rnu.tn;
   HBenAbdallah@kau.edu.sa
RI Kammoun, Salma/N-9090-2014; Ben-Abdallah, Hanene/L-1239-2014
OI Kammoun, Salma/0000-0003-1086-6599; Ben-Abdallah,
   Hanene/0000-0001-9215-4661; Hammami, Mohamed/0000-0003-3580-0473
FU Deanship of Scientific Research (DSR), King Abdulaziz University, Jeddah
   [611-975-D1435]; DSR
FX This work was supported by the Deanship of Scientific Research (DSR),
   King Abdulaziz University, Jeddah, under grant No (611-975-D1435). The
   authors, therefore, gratefully acknowledge the DSR technical and
   financial support.
CR [Anonymous], 1999, P IEEE C COMPUTER VI
   [Anonymous], 2015, COMPUT SCI INF TECHN, DOI DOI 10.13189/CSIT.2015.030303
   Bennett KP, 1999, ADV NEUR IN, V11, P368
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Chapelle O, 2008, J MACH LEARN RES, V9, P203
   Chun-Ting Chen, 2010, 2010 International Conference on Green Circuits and Systems (ICGCS 2010), P679, DOI 10.1109/ICGCS.2010.5542975
   Cucchiara R, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P360, DOI 10.1109/ICIAP.2001.957036
   Deb K, 2015, SMART COMPUT REV, V5, P38
   Dong X, 2005, PATTERN RECOGN LETT, V26, P91, DOI 10.1016/j.patrec.2004.09.005
   Finlayson G.D., 2002, ISTSID 10 COLOR IMAG, P73
   Fujino A., 2005, PROC NATL CONF ARTIF, V20, P764
   Grest D, 2003, VISION, MODELING, AND VISUALIZATION 2003, P253
   Guan YP, 2010, IET COMPUT VIS, V4, P50, DOI 10.1049/iet-cvi.2008.0016
   Guggenberger A, 2008, TECHNICAL REPORT
   Hammami M, 2006, IEEE T KNOWL DATA EN, V18, P272, DOI 10.1109/TKDE.2006.34
   Hammami M, 2013, MULTIMED TOOLS APPL, V63, P899, DOI 10.1007/s11042-011-0935-6
   Herodotou N, 1998, 1998 IEEE SYMPOSIUM ON ADVANCES IN DIGITAL FILTERING AND SIGNAL PROCESSING, P25, DOI 10.1109/ADFSP.1998.685688
   Hui Liu, 2009, 2009 2nd International Conference on Power Electronics and Intelligent Transportation System (PEITS 2009), P286, DOI 10.1109/PEITS.2009.5407014
   Jacques JCS, 2005, SIBGRAPI 2005: XVIII BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, CONFERENCE PROCEEDINGS, P189
   Jarraya SK, 2011, VISAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, P632
   Joshi AJ, 2008, IEEE T PATTERN ANAL, V30, P2055, DOI 10.1109/TPAMI.2008.150
   Joshi AJ, 2007, IEEE INT CONF ROBOT, P4827, DOI 10.1109/ROBOT.2007.364223
   KIRA K, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P129
   KOLLER D, 1993, INT J COMPUT VISION, V10, P257, DOI 10.1007/BF01539538
   Kononenko I., 1994, Machine Learning: ECML-94. European Conference on Machine Learning. Proceedings, P171
   Lewin M, 2002, P 2 INT S SMART GRAP, P124
   Liang Zhang, 2010, Proceedings of the 2010 WASE International Conference on Information Engineering (ICIE 2010), P216, DOI 10.1109/ICIE.2010.58
   Liu ZG, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P6282, DOI 10.1109/WCICA.2010.5554373
   Marcialis GL, 2008, LECT NOTES COMPUT SC, V5342, P684, DOI 10.1007/978-3-540-89689-0_72
   Martel-Brisson N, 2005, PROC CVPR IEEE, P643
   Mikic I, 2000, INT C PATT RECOG, P321, DOI 10.1109/ICPR.2000.905341
   Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Roli F, 2006, LECT NOTES COMPUT SC, V4109, P560
   Romain G, 2012, THESIS
   Rosin PL, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P347
   Schohn Greg, 2000, P 17 INT C MACH LEAR, P839
   Schreer O, 2002, PROCEEDINGS VIPROMCOM-2002, P371, DOI 10.1109/VIPROM.2002.1026685
   Shoaib M, 2009, INT CONF ACOUST SPEE, P773, DOI 10.1109/ICASSP.2009.4959698
   Tianzhu Z, 2008, 8 INT WORKSH VIS SUR
   Tsai DM, 2003, PATTERN RECOGN LETT, V24, P2625, DOI 10.1016/S0167-8655(03)00106-5
   Wang CX, 2009, 2009 ASIA-PACIFIC CONFERENCE ON INFORMATION PROCESSING (APCIP 2009), VOL 2, PROCEEDINGS, P422, DOI 10.1109/APCIP.2009.240
   Wang D, 2006, RES MIXTRUE GAUSSIAN
   Wang J. M., 2004, 2004 IEEE International Conference on Networking, Sensing and Control (IEEE Cat. No.04EX761), P649
   Wang J, 2014, COMP BIOCHEM PHYS D, V11, P1, DOI 10.1016/j.cbd.2014.05.001
   Wang Y.Q., 2008, The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, VXXXVII
   Wu YM, 2002, IEEE VTS VEH TECHNOL, P303
   Xiao M, 2007, INT J AUTOM COMPUT, V4, P38, DOI 10.1007/s11633-007-0038-z
   Xiaojin Z, 2008, TECHNICAL REPORT
   Yongquan Xia, 2010, 2010 2nd International Conference on Industrial Mechatronics and Automation (ICIMA 2010), P122, DOI 10.1109/ICINDMA.2010.5538075
   Zhao J, 2011, CHIN CONT DECIS CONF, P1672, DOI 10.1109/CCDC.2011.5968463
NR 51
TC 4
Z9 6
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 10949
EP 10977
DI 10.1007/s11042-015-2818-8
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900007
DA 2024-07-18
ER

PT J
AU Chang, YT
   Lin, YC
AF Chang, Yao-Tang
   Lin, Yih-Chuan
TI Dynamic reconfigurable encryption and decryption with chaos/M-sequence
   mapping algorithm for secure H.264/AVC video streaming over OCDMA
   passive optical network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic reconfigurable encryption-decryption; Optical code-division
   multiple-access (OCDMA); Passive optical network (PON); Chaos/M-sequence
   mapping algorithm(CMmA); H,264/AVC streaming; Scrambling encryption
ID PERFORMANCE; CDMA; PON
AB To enhance the security of H.264/AVC streaming, such as that for Internet protocol television, over a passive optical network (PON), a dynamic reconfigurable coding-decoding scheme, based on a chaotic sequence, was demonstrated and characterised by pseudo randomness and a maximal period. Compared with conventional optical code-division multiple-access (OCDMA) PONs, without providing a dynamic reconfigurable mechanism and trigger timing, a secure mechanism was generated using a proposed chaos/maximal length sequence (M-sequence) mapping algorithm and embedded in a codebook to control an electrical controller (register). Because the state of the electrical controller (register) is used by the chaos/M-sequence mapping time sequence pattern to trigger a switch matrix and then vary the M-sequence signature address code for each authorised user, the scrambling and interleaving function of the encryption scheme was implemented in the OCDMA-PON physical layer for various M-sequence signature address codes to carry individual H.264/AVC transmissions of the same channel. The proposed chaos/M-sequence mapping algorithm provided similar pseudo randomness and higher variance effectiveness compared with a general uniform distribution of the pseudo-random, autocorrelation, and cross-correlation properties of the proposed time sequence. In addition, the scrambling and interleaving efficiency was determined to be sufficiently high by the reduced peak signal-to-noise ratio of encrypted videos and the produced unidentifiable videos for unauthorised users.
C1 [Chang, Yao-Tang] Kao Yuan Univ, Dept Informat Technol, Kaohsiung 82151, Taiwan.
   [Lin, Yih-Chuan] Natl Formosa Univ, Dept Comp Sci & Informat Engn, Yunlin 63201, Taiwan.
C3 National Formosa University
RP Lin, YC (corresponding author), Natl Formosa Univ, Dept Comp Sci & Informat Engn, Yunlin 63201, Taiwan.
EM lyc@nfu.edu.tw
CR [Anonymous], 2003, DIXIT S IP WDM BUILD
   Borujeni S.E., 2015, APPL MATH, V6, P773, DOI [10.4236/am.2015.65073, DOI 10.4236/am.2015.65073]
   Chang YT, 2007, J LIGHTWAVE TECHNOL, V25, P1931, DOI 10.1109/JLT.2007.901333
   Cheng H, 2000, IEEE T SIGNAL PROCES, V48, P2439, DOI 10.1109/78.852023
   Devaney RL., 1989, An introduction to chaotic dynamical systems, V2
   Dufaux F, 2008, IEEE T CIRC SYST VID, V18, P1168, DOI 10.1109/TCSVT.2008.928225
   FREY DR, 1993, IEEE T CIRCUITS-II, V40, P660, DOI 10.1109/82.246168
   Karafolas N., 1996, Optical Fiber Technology: Materials, Devices and Systems, V2, P149, DOI 10.1006/ofte.1996.0017
   KAVEHRAD M, 1995, J LIGHTWAVE TECHNOL, V13, P534, DOI 10.1109/50.372451
   Kim KS, 2003, INFORM SCIENCES, V149, P21, DOI 10.1016/S0020-0255(02)00241-4
   Kitayama K, 2006, J LIGHTWAVE TECHNOL, V24, P1654, DOI 10.1109/JLT.2006.871030
   Kocarev L, 2011, STUD COMPUT INTELL, V354, P1, DOI 10.1007/978-3-642-20542-2
   Kramer G, 2002, IEEE COMMUN MAG, V40, P66, DOI 10.1109/35.983910
   L-f H, 2010, IEEE ICCA SM C, V8
   LI TY, 1975, AM MATH MON, V82, P985, DOI 10.2307/2318254
   MARIC SV, 1993, IEEE T COMMUN, V41, P1217, DOI 10.1109/26.231965
   Massoudi A, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/179290
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   SALEHI JA, 1989, IEEE T COMMUN, V37, P824, DOI 10.1109/26.31181
   Shake TH, 2005, J LIGHTWAVE TECHNOL, V23, P1652, DOI 10.1109/JLT.2005.844504
   Shake TH, 2005, J LIGHTWAVE TECHNOL, V23, P655, DOI 10.1109/JLT.2004.838844
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yuhuan Chen, 2011, Proceedings of the 2011 International Symposium on Information Technology in Medicine and Education (ITME 2011), P276, DOI 10.1109/ITiME.2011.6130832
NR 24
TC 12
Z9 12
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9837
EP 9859
DI 10.1007/s11042-015-2784-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500019
DA 2024-07-18
ER

PT J
AU Narducci, F
   Ricciardi, S
   Vertucci, R
AF Narducci, F.
   Ricciardi, S.
   Vertucci, R.
TI Enabling consistent hand-based interaction in mixed reality by
   occlusions handling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mixed reality; Hand occlusion; Disparity map
ID AUGMENTED REALITY; PARADIGM
AB A mixed reality environment, namely the space resulting from displaying virtual contents co-registered to the real space, represents an effective paradigm for applying the potential of virtual reality in the everyday life instead of having it confined within a computer screen. In this context, gesture-based interaction seems to be the most suited approach for human-machine interfacing. However, in order that interaction to be visually consistent, the tridimensional composition of the virtual objects onto the real background should be per-formed respecting the distance of each rendered pixel according to the user viewpoint. This paper describes a simple yet effective hand/finger-based interaction system and a virtual-to-real occlusion-handling approach, able to process in real time the stereoscopic video see-through stream to achieve pixel-wise z-order info, crucial to evaluating whether each rendered pixel should be displayed. The experiments confirm the efficacy of the proposed method in a simulation context.
C1 [Narducci, F.; Ricciardi, S.] Univ Salerno, VRLab, Salerno, Italy.
   [Vertucci, R.] Selex Elect Syst, CTO Capabil Support & Serv Solut Line Business, Naples, Italy.
   [Vertucci, R.] Selex Elect Syst, Land & Naval Syst Div, Naples, Italy.
C3 University of Salerno
RP Narducci, F (corresponding author), Univ Salerno, VRLab, Salerno, Italy.
EM fnarducci@unisa.it; sricciardi@unisa.it; raffaele.vertucci@selex-es.com
RI Narducci, Fabio/R-5833-2017; Ricciardi, Stefano/R-4359-2016
OI Narducci, Fabio/0000-0003-4879-7138; Ricciardi,
   Stefano/0000-0003-2123-452X
CR Abate Andrea F., 2014, Virtual, Augmented and Mixed Reality. Designing and Developing Virtual and Augmented Environments. 6th International Conference, VAMR 2014, Held as Part of HCI International 2014. Proceedings: LNCS 8525, P319, DOI 10.1007/978-3-319-07458-0_30
   [Anonymous], BRIT MACH VIS C
   Bernardet U, 2010, HUM-COMPUT INT-SPRIN, P357, DOI 10.1007/978-1-84882-733-2_18
   Bichlmeier C, 2009, IEEE T MED IMAGING, V28, P1498, DOI 10.1109/TMI.2009.2018622
   Buchmann V., 2004, Proc. 2nd Intl Conf. on Computer Graphics Interactive Techniques in Australasia South East Asia (GRAPHITE), P212
   Caggianese G, 2014, LECT NOTES COMPUT SC, V8853, P267, DOI 10.1007/978-3-319-13969-2_20
   Corbett-Davies S, 2013, P IEEE VIRT REAL ANN, P19, DOI 10.1109/VR.2013.6549351
   Cosco F, 2013, IEEE T VIS COMPUT GR, V19, P159, DOI 10.1109/TVCG.2012.107
   Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4
   Fischer J., 2004, Proceedings of the ACM symposium on Virtual reality software and technology, P174
   Furmanski C, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P215, DOI 10.1109/ISMAR.2002.1115091
   Gordon G, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P14, DOI 10.1109/ISMAR.2002.1115063
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Humenberger M, 2010, COMPUT VIS IMAGE UND, V114, P1180, DOI 10.1016/j.cviu.2010.03.012
   KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690
   Kantonen T, 2010, P IEEE VIRT REAL ANN, P179, DOI 10.1109/VR.2010.5444792
   Lee W, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P106
   Liu C, 2012, CHI 12 30 INT C HUM
   Malkawi AM, 2005, AUTOMAT CONSTR, V14, P71, DOI 10.1016/j.autcon.2004.08.001
   Medioni G, 1985, COMPUT VIS GRAPH IMA, P2
   Mistry P, 2009, P SIGGRAPH AS 2009 S
   Piumsomboon T, 2013, LECT NOTES COMPUT SC, V8118, P282
   SEKULER AB, 1992, J EXP PSYCHOL GEN, V121, P95, DOI 10.1037/0096-3445.121.1.95
   Seo DW, 2013, EXPERT SYST APPL, V40, P3784, DOI 10.1016/j.eswa.2012.12.091
   Shah M. M., 2012, Proceedings of the 2012 8th International Conference on Information Science and Digital Content Technology (ICIS and IDCTA), P372
   van Krevelen D. W. F., 2010, INT J VIRTUAL REALIT, V9, P1, DOI DOI 10.1016/J.SUR0NC.2011.07.002
   Walairacht S, 2002, PRESENCE-TELEOP VIRT, P134
   Wang RY, 2009, J ACM T GRAPH TOG, V28
   Wei W, 2011, AUGMENTED REALITY AP, V6874, P154
   Weichert F, 2013, SENSORS-BASEL, V13, P6380, DOI 10.3390/s130506380
   Xu Gang., 1996, Epipolar Geometry in Stereo, Motion and Object Recognition, V6
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 32
TC 8
Z9 9
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9549
EP 9562
DI 10.1007/s11042-016-3276-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500003
DA 2024-07-18
ER

PT J
AU Zhao, YY
   Qin, B
   Liu, T
   Tang, DY
AF Zhao, Yanyan
   Qin, Bing
   Liu, Ting
   Tang, Duyu
TI Social sentiment sensor: a visualization system for topic detection and
   topic sentiment analysis on microblog
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; Social media; Topic detection; Microblogging;
   Opinion mining
AB As a new form of social media, microblogging provides platform sharing, wherein users can share their feelings and ideas on certain topics. Bursty topics from microblogs are the results of the emerging issues that instantly attract more followers and more attention online, which provide a unique opportunity to gauge the relation between expressed public sentiment and hot topics. This paper presents a Social Sentiment Sensor (SSS) system on Sina Weibo to detect daily hot topics and analyze the sentiment distributions toward these topics. SSS includes two main techniques, namely, hot topic detection and topic-oriented sentiment analysis. Hot topic detection aims to detect the most popular topics online based on the following steps, topic detection, topic clustering, and topic popularity ranking. We extracted topics from the hashtags using a hashtag filtering model because they can cover almost all the topics. Then, we cluster the topics that describe the same issue, and rank the topic clusters via their popularity to exploit the final hot topics. Topic-oriented sentiment analysis aims to analyze public opinions toward the hot topics. After retrieving the topic-related messages, we recognize sentiment for each message using a state-of-the-art SVM (Support Vector Machine) sentiment classifier. Then, we summarize the sentiments for the hot topic to achieve topic sentiment distribution. Based on the above framework and algorithms, SSS produces a real-time visualization system to monitor social sentiments, which is offering the public a new and timely perspective on the dynamics of the social topics.
C1 [Zhao, Yanyan] Harbin Inst Technol, Dept Media Technol & Art, Harbin, Peoples R China.
   [Qin, Bing; Liu, Ting; Tang, Duyu] Harbin Inst Technol, Dept Comp Sci & Technol, Harbin, Peoples R China.
C3 Harbin Institute of Technology; Harbin Institute of Technology
RP Zhao, YY (corresponding author), Harbin Inst Technol, Dept Media Technol & Art, Harbin, Peoples R China.
EM zyyster@gmail.com; bqin@ir.hit.edu.cn; tliu@ir.hit.edu.cn;
   dytang@ir.hit.edu.cn
RI zhao, yanyan/AIC-1784-2022; liu, ting/GZM-3326-2022
OI Zhao, Yanyan/0000-0001-5852-7962
FU National Natural Science Foundation of China (NSFC) [2014CB340506,
   61300113, 61273321]; Ministry of Education Research of Social Sciences
   Youth [12YJCZH304]
FX We thank the anonymous reviewers for their helpful comments. This work
   was supported by National Natural Science Foundation of China (NSFC) via
   grant 2014CB340506, 61300113 and 61273321, and the Ministry of Education
   Research of Social Sciences Youth funded projects via grant 12YJCZH304.
CR Allan J., 1998, P DARPA BROADC NEWS
   Allan J., 2002, INTRO TOPIC DETECTIO
   [Anonymous], 2014, P INT C MULT RETR
   [Anonymous], 2013, ARXIV13086242
   [Anonymous], 2010, HLT 10
   [Anonymous], 2012, SENTIMENT ANAL OPINI
   Asur S., 2010, Proceedings 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology (WI-IAT), P492, DOI 10.1109/WI-IAT.2010.63
   Barbosa L., 2010, P 23 INT C COMP LING, V2, P36
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Cataldi M., 2010, P 10 INT WORKSHOP MU, P1, DOI DOI 10.1145/1814245.1814249
   Ciot Morgane, 2013, Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, P1136
   Diao Q., 2012, Proceedings of the 50th Annual Meeting of the Association for Computational Lin- guistics, P536
   Diao Qiming., 2013, P 18 C EMPIRICAL MET, P1869
   El Rahman SA, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P336, DOI 10.1109/iccisci.2019.8716464
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Johansson Richard., 2011, P 49 ANN M ASS COMPU, P101
   Joshi A, 2011, P 49 ANN M ASS COMP, P127
   Kleinberg J., 2002, P 8 ACM SIGKDD INT C
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   Si J., 2013, Short Papers, V2, P24
   Tang DY, 2013, COMM COM INF SC, V400, P212
   Weng J., 2011, EVENT DETECTION TWIT
   Wiebe Janyce., 2005, Language Resources and Evaluation, V1, P0
   Williams J, 2012, P 50 ANN M ASS COMP, V2, P223
   Yang Y., 1998, P 21 ANN INT ACM SIG, P28, DOI DOI 10.1145/290941.290953
   Zhao Jichang., 2012, Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining, P1528
NR 27
TC 28
Z9 29
U1 3
U2 77
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 8843
EP 8860
DI 10.1007/s11042-014-2184-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500002
DA 2024-07-18
ER

PT J
AU Zhu, SH
   Hu, JJ
   Shi, Z
AF Zhu, Songhao
   Hu, Juanjuan
   Shi, Zhe
TI Local abnormal behavior detection based on optical flow and
   spatio-temporal gradient
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Abnormal behavior; Semi-parametric model; Optical flow energy; Local
   nearest descriptor
ID REPRESENTATION
AB To improve the accuracy of the detection of local abnormal behavior, a novel method is here proposed. The main idea of the proposed method is described as follows: firstly, a video sequence is divided into spatio-temporal blobs; then, a statistical method based on the semiparametric model is adopted to detect these blobs where abnormal behaviors most likely to appear; finally, maximum optical flow energy and local nearest descriptor are utilized to determinate whether these suspicious blobs really contain abnormal behaviors. The experimental results conducted on several benchmarks ademonstrate the effectiveness of the proposed method.
C1 [Zhu, Songhao; Hu, Juanjuan; Shi, Zhe] Nanjing Univ Posts & Telecommun, Sch Automat, Nanjing 210023, Jiangsu, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Zhu, SH (corresponding author), Nanjing Univ Posts & Telecommun, Sch Automat, Nanjing 210023, Jiangsu, Peoples R China.
EM zhush@njupt.edu.cn
FU Postdoctoral Foundation of China [2014 M550297]; Postdoctoral Foundation
   of Jiangsu Province [1302087B]; Graduate Education Reform Research and
   Practice Program of Jiangsu Province [JGZZ13_041, JGLX15_055]; Graduate
   Research and Innovation Program of Jiangsu [KYLX15_0854, SJZZ15_0105]
FX This work is supported by Postdoctoral Foundation of China under No.
   2014 M550297, Postdoctoral Foundation of Jiangsu Province under No.
   1302087B, Graduate Education Reform Research and Practice Program of
   Jiangsu Province under No. JGZZ13_041 and JGLX15_055, Graduate Research
   and Innovation Program of Jiangsu under No. KYLX15_0854 and No.
   SJZZ15_0105.
CR A-Lin Hou, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P643, DOI 10.1109/ICIG.2013.134
   Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   [Anonymous], P ACM INT C IM VID R
   [Anonymous], P AS C COMP VIS
   [Anonymous], 2010, J NANOMATER
   Breitenstein M, 2009, IEEE C VIS SURVEILL, V2009, P76
   Cheng KF, 2004, BERNOULLI, V10, P583, DOI 10.3150/bj/1093265631
   Dee H., 2004, Proc. of British Machine Vision Conf, P477
   Kim J, 2009, PROC CVPR IEEE, P2913
   Lee DG, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P325, DOI 10.1109/AVSS.2014.6918689
   Li C, 2013, NEUROCOMPUTING, V119, P94, DOI 10.1016/j.neucom.2012.03.040
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mehran R, 2010, LECT NOTES COMPUT SC, V6313, P439
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Nie LQ, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P695
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Palmer J. A., 2005, P 18 INT C NEUR INF, P1059
   Shan HH, 2011, DATA MIN KNOWL DISC, V23, P1, DOI 10.1007/s10618-010-0198-2
   Shet VD, 2006, LECT NOTES COMPUT SC, V3954, P119
   Wallach H.M., 2006, Proc. 23rd Int. Conf. Mach. Learn, P977984
   Xinyi Cui, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3161, DOI 10.1109/CVPR.2011.5995558
   Yan Y, 2013, IEEE INT C COMPUT VI, V2013, P1174
   Yan Y, 2016, IEEE T PATTERN ANAL, V38, P1070, DOI 10.1109/TPAMI.2015.2477843
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhu XB, 2014, PATTERN RECOGN, V47, P1791, DOI 10.1016/j.patcog.2013.11.018
NR 28
TC 16
Z9 16
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 9445
EP 9459
DI 10.1007/s11042-015-3122-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500033
DA 2024-07-18
ER

PT J
AU Bashir, T
   Usman, I
   Rehman, JU
AF Bashir, Tariq
   Usman, Imran
   Rehman, Junaid Ur
TI Secure digital watermarking using optimized improved spread spectrum and
   BCH coding for DIBR 3D-TV system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optimized Improved Spread Spectrum (OISS); Depth image based rendering
   (DIBR); Bose-Chadhuri-Hocquenghem (BCH)
ID ROBUST
AB Constantly decreasing cost and enhanced depth perception in 3D-TV technology makes it more popular in multimedia consumer market. With the widespread of 3D content, copyright protection is becoming a serious concern for maximizing the profits and preventing illegitimate acquisition and distribution of the 3D media content. Digital watermarking is one such promising technique to tackle this problem. This work provides a robust watermarking technique for 3D-TV. The proposed technique is based upon intelligent parameter selection using Genetic Algorithm in an improved spread spectrum based watermarking system. In order to enhance robustness, another layer of security of the watermark is added using Bose-Chadhuri-Hocquenghem (BCH) coding. Experimental results and comparison with state of the art technique demonstrate the effectiveness of the proposed technique to structure the watermark for high robustness in the presence of a number of hostile attacks.
C1 [Bashir, Tariq] COMSATS Inst Informat Technol, Dept Elect Engn, Islamabad, Pakistan.
   [Usman, Imran] Saudi Elect Univ, Coll Comp & Informat, Riyadh, Saudi Arabia.
   [Rehman, Junaid Ur] COMSATS Inst Informat Technol, Ctr Adv Studies Telecommun, Islamabad, Pakistan.
   [Rehman, Junaid Ur] Kyung Hee Univ, Elect & Radio Engn Departmentepartment, Coding & Commun Theory Lab CCTLab, Seoul, South Korea.
C3 COMSATS University Islamabad (CUI); Saudi Electronic University; COMSATS
   University Islamabad (CUI); Kyung Hee University
RP Usman, I (corresponding author), Saudi Elect Univ, Coll Comp & Informat, Riyadh, Saudi Arabia.
EM imran.usman@gmail.com
RI Ur Rehman, Junaid/JPY-0078-2023; Rehman, Junaid ur/AAD-1175-2020;
   Bashir, Tariq/AAC-8823-2019
OI Rehman, Junaid ur/0000-0002-2933-8609; Bashir, Tariq/0000-0002-8014-7816
CR Alghoniemy M, 2004, IEEE T IMAGE PROCESS, V13, P145, DOI 10.1109/TIP.2004.823831
   Barni M, 2005, IEEE SIGNAL PROC LET, V12, P158, DOI 10.1109/LSP.2004.840872
   Bas P, 2002, IEEE T IMAGE PROCESS, V11, P1014, DOI 10.1109/TIP.2002.801587
   Bose R. C., 1960, Inf. Control, V3, P79, DOI DOI 10.1016/S0019-9958(60)90287-4
   Bose R. C., 1960, Inform. and Control, V3, P279
   Caner G, 2006, IEEE T IMAGE PROCESS, V15, P3053, DOI 10.1109/TIP.2006.877514
   Chammem A, 2011, P SPIE
   Deng C, 2009, SIGNAL PROCESS, V89, P1531, DOI 10.1016/j.sigpro.2009.02.005
   Dugelay JL, 2006, IEEE T IMAGE PROCESS, V15, P2831, DOI 10.1109/TIP.2006.877311
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Halici E, 2009, IEEE IMAGE PROC, P4217, DOI 10.1109/ICIP.2009.5413525
   Hartung F., 1999, P SPIE, V3657
   Hwang DC, 2004, PROC SPIE, V5208, P196, DOI 10.1117/12.506616
   Kim HD, 2012, IEEE T BROADCAST, V58, P533, DOI 10.1109/TBC.2012.2206851
   Koz A, 2010, IEEE T IMAGE PROCESS, V19, P1785, DOI 10.1109/TIP.2010.2045024
   Lin YH, 2011, IEEE T BROADCAST, V57, P602, DOI 10.1109/TBC.2011.2131470
   Malvar HS, 2003, IEEE T SIGNAL PROCES, V51, P898, DOI 10.1109/TSP.2003.809385
   *MATHWORKS, GEN ALG DIR SEARCH T
   Scharstein D, MIDDLEBURY COMPUTER
   Sklar B., 2003, DIGITAL COMMUNICATIO, V2nd
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
   Zheng D, 2009, IEEE T IMAGE PROCESS, V18, P1055, DOI 10.1109/TIP.2009.2014807
   Zhu C., 2013, 3D-TV System with Depth-Image-Based Rendering - Architectures, Techniques and Challenges
   Zhu N, 2008, ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, PROCEEDINGS, P3, DOI 10.1109/ISDA.2008.157
NR 24
TC 3
Z9 3
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7697
EP 7713
DI 10.1007/s11042-015-2689-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600012
DA 2024-07-18
ER

PT J
AU Gao, M
   Wang, Q
   Zhao, DB
   Gao, W
AF Gao, Min
   Wang, Qiang
   Zhao, Debin
   Gao, Wen
TI Arithmetic coding using hierarchical dependency context model for
   H.264/AVC video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arithmetic coding; Context modeling; DCT coefficient coding; H.264/AVC
ID IMAGE COMPRESSION; LOSSLESS COMPRESSION; STANDARD; HEVC; QUANTIZATION;
   CABAC
AB In this paper, a hierarchical dependency context model (HDCM) is firstly proposed to exploit the statistical correlations of DCT (Discrete Cosine Transform) coefficients in H.264/AVC video coding standard, in which the number of non-zero coefficients in a DCT block and the scanned position are used to capture the magnitude varying tendency of DCT coefficients. Then a new binary arithmetic coding using hierarchical dependency context model (HDCMBAC) is proposed. HDCMBAC associates HDCM with binary arithmetic coding to code the syntax elements for a DCT block, which consist of the number of non-zero coefficients, significant flag and level information. Experimental results demonstrate that HDCMBAC can achieve similar coding performance as CABAC at low and high QPs (quantization parameter). Meanwhile the context modeling and the arithmetic decoding in HDCMBAC can be carried out in parallel, since the context dependency only exists among different parts of basic syntax elements in HDCM.
C1 [Gao, Min; Wang, Qiang; Zhao, Debin; Gao, Wen] Harbin Inst Technol, Dept Comp Sci & Technol, Harbin 150006, Peoples R China.
C3 Harbin Institute of Technology
RP Gao, M (corresponding author), Harbin Inst Technol, Dept Comp Sci & Technol, Harbin 150006, Peoples R China.
EM mgao@hit.edu.cn; qwanghitcs@gmail.com; dbzhao@hit.edu.cn; wgao@jdl.ac.cn
RI Zhao, Debin/JEP-0204-2023; Li, Yan/JUU-5189-2023
FU Major State Basic Research Development Program of China (973 Program)
   [2015CB351804]; National Science Foundation of China (NSFC) [61272386]
FX This work was supported in part by the Major State Basic Research
   Development Program of China (973 Program 2015CB351804) and the National
   Science Foundation of China (NSFC) under grant 61272386.
CR Bjontegaard G, 2002, DOC JOINT TEAM ISO I
   Bjontegaard G, 2001, VECEGM33 ITUT
   Chen SG, 2010, IEEE T CIRC SYST VID, V20, P920, DOI 10.1109/TCSVT.2010.2045831
   Francesc A, 2014, IEEE T IMAGE PROCESS, V24, P1778
   Gao M, 2011, PARALLEL CONTEXT MOD
   Kim WJ, 2011, IEEE T CONSUM ELECTR, V57, P897, DOI 10.1109/TCE.2011.5955238
   Lam EY, 2000, IEEE T IMAGE PROCESS, V9, P1661, DOI 10.1109/83.869177
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Marpe D, 2010, P PICT COD S
   Moffat A, 1995, IEEE INT C DAT COMPR
   RISSANEN J, 1983, IEEE T INFORM THEORY, V29, P656, DOI 10.1109/TIT.1983.1056741
   Sole J, 2012, IEEE T CIRC SYST VID, V22, P1765, DOI 10.1109/TCSVT.2012.2223055
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Sze V, 2008, P IEEE INT C IM PROC
   Sze V, 2012, IEEE T CIRC SYST VID, V22, P1778, DOI 10.1109/TCSVT.2012.2221526
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Wang Q, 2005, PAC  RIM C MULT
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Weinberger MJ, 1996, IEEE T IMAGE PROCESS, V5, P575, DOI 10.1109/83.491334
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu JJ, 2013, SIGNAL PROCESS-IMAGE, V28, P727, DOI 10.1016/j.image.2013.04.004
   Wu XL, 1997, IEEE T IMAGE PROCESS, V6, P656, DOI 10.1109/83.568923
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Xu MT, 2006, IEEE T IMAGE PROCESS, V15, P169, DOI 10.1109/TIP.2005.860357
   Yu L, 2009, SIGNAL PROCESS-IMAGE, V24, P247, DOI 10.1016/j.image.2009.02.003
   Zhang L, 2009, SIGNAL PROCESS-IMAGE, V24, P263, DOI 10.1016/j.image.2008.12.001
NR 27
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 7351
EP 7370
DI 10.1007/s11042-015-2651-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400030
DA 2024-07-18
ER

PT J
AU Tang, C
   Hou, CP
   Wang, PC
   Song, ZJ
AF Tang, Chang
   Hou, Chunping
   Wang, Pichao
   Song, Zhanjie
TI Salient object detection using color spatial distribution and minimum
   spanning tree weight
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object detection; Minimum spanning tree; Color spatial
   distribution; Image segmentation
ID VISUAL-ATTENTION; REGION DETECTION; FEATURES; MODEL
AB Salient object detection is very useful in many computer vision applications such as image segmentation, content-based image editing and object recognition. In this paper, we present a salient object detection algorithm by using color spatial distribution (CSD) and minimum spanning tree weight (MSTW). We first use a segmentation algorithm to decompose an image into superpixel-level elements, then use these elements as nodes to construct a minimum spanning tree (MST), each connected edge weight is the mean color difference between two nodes. CSD of each element can be computed by integrating color, spatial distance and MSTW. Note that if the color of one element is the most widely distributed over the entire image, it should have the biggest CSD value, we regard this element as a background node (BG Node). Then we use the MSTW between other element and BG node to generate a MSTW map. The superpixel-level saliency map can be obtained by combining the CSD map and MSTW map. Finally, we use a guided filter to get the pixel-level saliency map. Experimental results on two databases demonstrate that our proposed method outperforms other previous state-of-the-art approaches.
C1 [Tang, Chang; Hou, Chunping] Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
   [Wang, Pichao] Univ Wollongong, Sch Comp Sci & Software Engn, Wollongong, NSW 2522, Australia.
   [Song, Zhanjie] Tianjin Univ, Sch Sci, Tianjin 300072, Peoples R China.
   [Song, Zhanjie] Tianjin Univ, SKL, HESS, Tianjin 300072, Peoples R China.
C3 Tianjin University; University of Wollongong; Tianjin University;
   Tianjin University
RP Song, ZJ (corresponding author), Tianjin Univ, Sch Sci, Tianjin 300072, Peoples R China.; Song, ZJ (corresponding author), Tianjin Univ, SKL, HESS, Tianjin 300072, Peoples R China.
EM tangchang@tju.edu.cn; hcp@tju.edu.cn; pw212@uowmail.edu.au;
   zhanjiesong@tju.edu.cn
RI Tang, Chang/AAU-8995-2020
OI Tang, Chang/0000-0002-6515-7696
FU 863 Program of China [2012AA03A301]; NSFC [61201179, 91320201]; Ph.D.
   Pro-grams Foundation of the Ministry of Education of China
   [20130032110010]
FX This work is funded by the 863 Program of China (2012AA03A301), NSFC
   (61201179 and 91320201), Ph.D. Pro-grams Foundation of the Ministry of
   Education of China (20130032110010).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Chen T, 2013, IEEE T VIS COMPUT GR, V19, P824, DOI 10.1109/TVCG.2012.148
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Nguyen DT, 2013, PATTERN RECOGN, V46, P1485, DOI 10.1016/j.patcog.2012.10.024
   Elder, 2010, P IEEE C COMP VIS PA, P49, DOI [10.1109/CVPRW.2010.5543739, DOI 10.1109/CVPRW.2010.5543739]
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Foncubierta-Rodriguez A, 2013, SPIE MED IMAGING
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He K., 2010, Eccv, P1
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jing HY, 2014, NEUROCOMPUTING, V124, P57, DOI 10.1016/j.neucom.2013.07.043
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Liang ZJ, 2014, MULTIMED TOOLS APPL, V68, P517, DOI 10.1007/s11042-012-1040-1
   Liu Q, 2013, MULTIMED TOOLS APPL, V67, P231, DOI 10.1007/s11042-012-1077-1
   Liu SW, 2012, IEEE SIGNAL PROC LET, V19, P207, DOI 10.1109/LSP.2012.2187782
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Y, 2012, MAR BIOTECHNOL, P1
   Liu Z, 2013, OPT LETT, V38, P700, DOI 10.1364/OL.38.000700
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Navalpakkam Vidhya, 2006, Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, V2, P2049, DOI DOI 10.1109/CVPR.2006.54
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Rutishauser U., 2004, P IEEE COMP SOC C CO, DOI DOI 10.1109/CVPR.2004.1315142
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Tong N, 2014, IEEE SIGNAL PROC LET, V21, P1035, DOI 10.1109/LSP.2014.2323407
   Veksler Olga, 2010, Computer Vision-ECCV 2010, P211, DOI [10.1007/978-3-642-15555-0_16, DOI 10.1007/978-3-642-15555-0_16]
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Wu HS, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866185
   Yang QX, 2015, IEEE T PATTERN ANAL, V37, P834, DOI 10.1109/TPAMI.2014.2353642
   Yu JG, 2012, OPT LETT, V37, P4994, DOI 10.1364/OL.37.004994
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 37
TC 9
Z9 9
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 6963
EP 6978
DI 10.1007/s11042-015-2622-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400014
DA 2024-07-18
ER

PT J
AU Wu, CH
   Chen, WL
   Lin, CH
AF Wu, Chih-Hung
   Chen, Wei-Lun
   Lin, Chang Hong
TI Depth-based hand gesture recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth cameras; Static hand posture recognition; Dynamic hand gesture
   recognition; Support vector machine
AB In this article, a dynamic gesture recognition system with the depth information is proposed. The proposed system consists of three main components: preprocessing, static posture recognition and dynamic gesture recognition. In the first component, the background subtraction is used to exclude invalid gestures that is not generated by the main user, and then to detect and track the hand. Second, the region of hand is extracted using an adaptive square. Once the region of hand is obtained, the features of hand are extracted and the static hand posture are classified using the support vector machine (SVM). Finally, nine commonly used dynamic hand gestures can be detected using different methods. In the experiments, the static hand posture classification was evaluated in different postures and the performance of dynamic gesture recognition is verified by two different persons at 4 different position with 2 different depths. The experiment results show that the proposed system can accurately detect the dynamic hand gestures with an average recognition rate of 87.6 %, which is good for controlling the embedded systems, such as home appliances.
C1 [Wu, Chih-Hung; Chen, Wei-Lun; Lin, Chang Hong] Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology
RP Lin, CH (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, Taipei, Taiwan.
EM chlin@mail.ntust.edu.tw
RI Lin, Chang Hong/GRE-7807-2022
OI Lin, Chang Hong/0000-0003-3646-3261
CR Altmayer KS, 2013, IEEE INT SYMP POWER
   Barkoky A, 2011, INT C MULT TECHN ICM
   Bradski G., 2008, Learning OpenCV: Computer Vision with the OpenCV Library, V1
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen C-P, 2011, IEEE VISUAL COMMUNIC
   Choi J, 2011, IEEE IMAGE PROC
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Graham R. L., 1972, Information Processing Letters, V1, P132, DOI 10.1016/0020-0190(72)90045-2
   HOMMA K, 1985, J NUCL MED, V26, P1472
   Huang D.-Y., 2009, 5 INT C INT INF HID
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Keskin C, 2012, IEEE COMP SOC C COMP
   Kurakin A, 2012, EUR SIGNAL PR CONF, P1975
   Li WQ, 2008, IEEE T CIRC SYST VID, V18, P1499, DOI 10.1109/TCSVT.2008.2005597
   Liu Y, 2012, 4 INT C INT HUM MACH
   Minnen D, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Oprisescu S, 2012, P 20 EUR SIGN PROC C
   Prime Sense, 2010, PRIM SENS XTIONS HAR
   Raheja J. L., 2011, 3 INT C COMP INT MOD
   Ren Z., 2011, P 19 ACM INT C MULTI, P1093
   Senanayake R, 2012, IEEE INT C SIGN PROC
   Shrivastava R, 2013, IEEE 3 INT ADV COMP
   Suryanarayan P, 2010, 20 INT C PATT REC IC
   Wachs JP, 2011, COMMUN ACM, V54, P60, DOI 10.1145/1897816.1897838
   Yang Z., 2012, 7 INT C COMP SCI ED
   Zhu X, 2012, 21 INT C PATT REC IC
NR 26
TC 12
Z9 14
U1 3
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 7065
EP 7086
DI 10.1007/s11042-015-2632-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400019
DA 2024-07-18
ER

PT J
AU Kim, K
   Cho, BY
   Ro, WW
AF Kim, Keunsoo
   Cho, Benjamin Y.
   Ro, Won Woo
TI Server side, play buffer based quality control for adaptive media
   streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive streaming; Quality control; Media streaming; Server side
AB Existing media streaming protocols provide bandwidth adaptation features in order to deliver seamless video streams in an abrupt bandwidth shortage on the networks. For instance, popular HTTP streaming protocols such as HTTP Live Streaming (HLS) and MPEG-DASH are designed to select the most appropriate streaming quality based on client side bandwidth estimation. Unfortunately, controlling the quality at the client side means the effectiveness of the adaptive streaming is not controlled by service providers, and it harms the consistency in quality-of-service. In addition, recent studies show that selecting media quality based on bandwidth estimation may exhibit unstable behavior in certain network conditions. In this paper, we demonstrate that the drawbacks of existing protocols can be overcome with a server side, buffer based quality control scheme. Server side quality control solves the service quality problem by eliminating client assistance. Buffer based control scheme eliminates the side effects of bandwidth based stream selection. We achieve this without client assistance by designing a play buffer estimation algorithm. We prototyped the proposed scheme in our streaming service testbed which supports pre-transcoding and live-transcoding of the source media file. Our evaluation results show that the proposed quality control performs very well both in simulated and real environments.
C1 [Kim, Keunsoo; Cho, Benjamin Y.; Ro, Won Woo] Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea.
C3 Yonsei University
RP Ro, WW (corresponding author), Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea.
EM keunsoo.kim@yonsei.ac.kr; youngjcho@yonsei.ac.kr; wro@yonsei.ac.kr
FU MKE (The Ministry of Knowledge Economy); NHN Corp., under IT/SW Creative
   research program [NIPA-2012-H0505-12-1011]; ICT R&D program of MSIP/IITP
   [2014(10041971)]
FX This research was supported in part by the MKE (The Ministry of
   Knowledge Economy) and NHN Corp., under IT/SW Creative research program
   supervised by the NIPA (National IT Industry Promotion Agency)
   (NIPA-2012-H0505-12-1011), and in part by the ICT R&D program of
   MSIP/IITP [2014(10041971), Development of Power-efficient
   High-performance Multimedia Contents Service Technology using
   Context-adapting Distributed Transcoding]. Won Woo Ro is the
   corresponding author.
CR [Anonymous], 2011, Proc. second annu. acm conf. multimed. syst.-mmsys'11, DOI DOI 10.1145/1943552.1943574
   [Anonymous], P 4 WORKSH MOB VID C
   Dai H., 2011, Acta Horticulturae, P169, DOI 10.1145/1943552.1943575
   De Cicco L., 2011, P 2 ANN ACM C MULTIM, P145
   Huang T.Y., 2012, P 2012 ACM C INT MEA, P225, DOI 10.1145/2398776.2398800
   Huang YS, 2009, IEEE T MULTIMEDIA, V11, P1072, DOI 10.1109/TMM.2009.2026085
   Ma SW, 2005, IEEE T CIRC SYST VID, V15, P1533, DOI 10.1109/TCSVT.2005.857300
   Mehrotra S., 2012, GLOBECOM 2012 - 2012 IEEE Global Communications Conference, P1901, DOI 10.1109/GLOCOM.2012.6503393
   Pantos R, 2013, HTTP LIVE S IN PRESS
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Stockhammer T., 2011, P 2 ANN ACM C MULTIM, P133
   Tan WL, 2008, IEEE T MOBILE COMPUT, V7, P737, DOI 10.1109/TMC.2007.70788
NR 12
TC 0
Z9 0
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5397
EP 5415
DI 10.1007/s11042-015-2509-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600002
DA 2024-07-18
ER

PT J
AU Wei, JG
   Fang, Q
   Zheng, XY
   Lu, WH
   He, YQ
   Dang, JW
AF Wei, Jianguo
   Fang, Qiang
   Zheng, Xinyuan
   Lu, Wenhuan
   He, Yuqing
   Dang, Jianwu
TI Mapping ultrasound-based articulatory images and vowel sounds with a
   deep neural network framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Articulatory Data; Restricted boltzmann machine; Deep denoising
   autoencoders; DNN
ID UNCERTAINTY; ACOUSTICS; MOVEMENTS
AB Constructing a mapping between articulatory movements and corresponding speech could significantly facilitate speech training and the development of speech aids for voice disorder patients. In this paper, we propose a novel deep learning framework for the creation of a bidirectional mapping between articulatory information and synchronized speech recorded using an ultrasound system. We created a dataset comprising six Chinese vowels and employed the Bimodal Deep Autoencoders algorithm based on the Restricted Boltzmann Machine (RBM) to learn the correlation between speech and ultrasound images of the tongue and the weight matrices of the data representations obtained. Speech and ultrasound images were then reconstructed from the extracted features. The reconstruction error of the ultrasound images created with our method was found to be less than that of the approach based on Principal Components Analysis (PCA). Further, the reconstructed speech approximated the original as the mean formants error (MFE) was small. Following acquisition of their shared representations using the RBM-based deep autoencoder, we carried out mapping between ultrasound images of the tongue and corresponding acoustics signals with a Deep Neural Network (DNN) framework using the revised Deep Denoising Autoencoders. The results obtained indicate that the performance of our proposed method is better than that of a Gaussian Mixture Model (GMM)-based method to which it was compared.
C1 [Wei, Jianguo; Lu, Wenhuan] Tianjin Univ, Sch Comp Software, Tianjin 300072, Peoples R China.
   [Fang, Qiang] Chinese Acad Social Sci, Beijing, Peoples R China.
   [Wei, Jianguo; Zheng, Xinyuan; Dang, Jianwu] Tianjin Univ, Tianjin Key Lab Cognit Computat & Applicat, Tianjin 300072, Peoples R China.
   [He, Yuqing] Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
   [Dang, Jianwu] Japan Adv Inst Sci & Technol, Nomi, Japan.
C3 Tianjin University; Chinese Academy of Social Sciences; Tianjin
   University; Tianjin University; Japan Advanced Institute of Science &
   Technology (JAIST)
RP Lu, WH (corresponding author), Tianjin Univ, Sch Comp Software, Tianjin 300072, Peoples R China.
EM Jianguo@tju.edu.cn; Wenhuan@tju.edu.cn; Dangjianwu@tju.edu.cn
RI Wei, Jianguo/KBA-3200-2024
OI Wei, Jianguo/0000-0002-8964-9759
FU National Basic Research Program of China [2013CB329305]; National
   Natural Science Foundation of China [61175016, 61304250]; Grants-in-Aid
   for Scientific Research [25240026] Funding Source: KAKEN
FX This work was supported in part by the National Basic Research Program
   of China (No. 2013CB329305), and in part by grants from the National
   Natural Science Foundation of China (No. 61175016, No. 61304250).
CR [Anonymous], 2011, P ICML
   [Anonymous], 2010, MOMENTUM
   Badino L, 2012, IEEE W SP LANG TECH, P370, DOI 10.1109/SLT.2012.6424252
   Ben-Youssef Atef, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4573, DOI 10.1109/ICASSP.2014.6854468
   Ghosh PK, 2011, INT CONF ACOUST SPEE, P4624
   Glass J. R, 2004, P 6 INT C MULT INT A, P152, DOI DOI 10.1145/1027933.1027960
   Hiroya S, 2004, IEEE T SPEECH AUDI P, V12, P175, DOI 10.1109/TSA.2003.822636
   Hogden J, 2001, IEEE IMTC P, P1105, DOI 10.1109/IMTC.2001.928251
   Hogden J, 1996, J ACOUST SOC AM, V100, P1819, DOI 10.1121/1.416001
   Huang J, 2013, INT CONF ACOUST SPEE, P7596, DOI 10.1109/ICASSP.2013.6639140
   Kello CT, 2004, J ACOUST SOC AM, V116, P2354, DOI 10.1121/1.1715112
   LADEFOGED P, 1980, LANGUAGE, V56, P485, DOI 10.2307/414446
   Livescu K, 2007, INT CONF ACOUST SPEE, P621
   Nakamura Kenichi, 2006, AC SPEECH SIGN PROC, V1
   Nefian AV, 2002, AC SPEECH SIGN PROC, V2, pII
   Papandreou G, 2009, IEEE T AUDIO SPEECH, V17, P423, DOI 10.1109/TASL.2008.2011515
   Richmond K, 2003, COMPUT SPEECH LANG, V17, P153, DOI 10.1016/S0885-2308(03)00005-6
   Richmond K, 2006, TRAJECTORY MIXTURE D
   Schroeter J., 1992, ADV SPEECH SIGNAL PR, P231
   Schroeter J, 1994, IEEE T SPEECH AUDI P, V2, P133, DOI 10.1109/89.260356
   Simko J, 2009, SEQUENCING EMBODIED
   Suzuki S., 1998, ICSLP
   Toda T, 2008, SPEECH COMMUN, V50, P215, DOI 10.1016/j.specom.2007.09.001
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang LJ, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P446
   Xie L, 2007, IEEE T MULTIMEDIA, V9, P500, DOI 10.1109/TMM.2006.888009
NR 26
TC 7
Z9 7
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 5223
EP 5245
DI 10.1007/s11042-015-3038-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700023
DA 2024-07-18
ER

PT J
AU Zarka, M
   Ben Ammar, A
   Alimi, AM
AF Zarka, Mohamed
   Ben Ammar, Anis
   Alimi, Adel M.
TI Fuzzy reasoning framework to improve semantic video interpretation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia retrieval; Ontology; Video indexing
ID KNOWLEDGE REPRESENTATION; INFORMATION EXTRACTION; ONTOLOGY; CONTEXT;
   RETRIEVAL; IMAGE; RECOGNITION; ANNOTATION
AB A video retrieval system user hopes to find relevant information when the proposed queries are ambiguous. The retrieval process based on detecting concepts remains ineffective in such a situation. Potential relationships between concepts have been shown as a valuable knowledge resource that can enhance the retrieval effectiveness, even for ambiguous queries. Recent researches in multimedia retrieval have focused on ontology modeling as a common framework to manage knowledge. Handling these ontologies has to cope with issues related to generic knowledge management and processing scalability. Considering these issues, we suggest a context-based fuzzy ontology framework for video content analysis and indexing. In this paper, we focused on the way in which we modeled our fuzzy ontology: First, we populate automatically the generated ontology by gathering various available video annotation datasets. Then, the ontology content was used to infer enhanced video semantic interpretation. Finally, considering user feedback, the content of the ontology was improved. Experimental results showed that our approach achieves the goal of scalability while at the same time allowing better video content semantic interpretation.
C1 [Zarka, Mohamed; Ben Ammar, Anis; Alimi, Adel M.] Univ Sfax, REGIM Reaserch Grp Intelligent Machines, ENIS, BP 1173, Sfax 3038, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Zarka, M (corresponding author), Univ Sfax, REGIM Reaserch Grp Intelligent Machines, ENIS, BP 1173, Sfax 3038, Tunisia.
EM mohamed.ezzarka@ieee.org; anis.benammar.tn@ieee.org; adel.alimi@ieee.org
RI Zarka, Mohamed/HRB-5854-2023; Alimi, Adel M./A-5697-2012
OI Zarka, Mohamed/0000-0003-2624-0400; Alimi, Adel M./0000-0002-0642-3384
FU General Direction of Scientific Research (DGRST), Tunisia, under the
   ARUB program
FX The authors would like to acknowledge the financial support of this work
   by grants from General Direction of Scientific Research (DGRST),
   Tunisia, under the ARUB program.
CR Adami N, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P607, DOI 10.1109/MMSP.2001.962799
   [Anonymous], INT J ADV RES COMPUT
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], K SPAC PHD STUD WORK
   [Anonymous], INT ENCY STAT SCI
   [Anonymous], 2006, LSCOM LEXICON DEFINI
   [Anonymous], P TRECVID 2013
   [Anonymous], 2011, TOIS
   [Anonymous], VLDB DOCT WORKSH SIN
   Ayache S, 2007, THESIS I NATL POLYTE
   Ayache S, 2008, LECT NOTES COMPUT SC, V4956, P187
   Baader F., 2003, DESCRIPTION LOGIC HD
   Baghdadi S, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P677, DOI 10.1109/ICME.2008.4607525
   Bannour H., 2013, MULTIMED TOOLS APPL, P1
   Benitez A, 2003, 2003 ICIP 2003 P 200, V2
   Benitez A, 2003, 2003 ICIP 2003 P 200, V3
   Bobillo F, 2012, JOINING GODEL ZADEH, V20
   Brilhault A, 2009, INDEXTATION RECHEROC
   Calegari S, 2007, LECT NOTES ARTIF INT, V4578, P118
   Chattopadhyay C, 2013, INT J MULTIMED INF R, V2, P289, DOI 10.1007/s13735-013-0034-8
   Cheng Y, 2012, ADV MULTIMEDIA SOFTW, V1, P271
   Dasiopoulou S, 2011, LECT NOTES ARTIF INT, V6050, P196, DOI 10.1007/978-3-642-20795-2_8
   Dean J., 2009, WSDM 09 P 2 ACM INT, V10, DOI [10.1145/1498759.1498761.No.1498759.1498761, DOI 10.1145/1498759.1498761, 10.1145/1498759.1498761]
   DeMenthon D., 2002, LAMPTR090 U MAR
   Dentler K, 2011, SEMANT WEB, V2, P71, DOI 10.3233/SW-2011-0034
   Du YT, 2006, LECT NOTES COMPUT SC, V4261, P185
   Elleuch N., 2011, MDMKDD, V11
   Elleuch N, 2010, 2010 5 INT S 1 5 COM
   Elleuch N, 2010, REGIMVID TRECVID 201
   Fang W, 2008, INT FED INFO PROC, V254, P293
   Faria C, 2011, ADV INTEL SOFT COMPU, V87, P319
   Fellbaum C, 2010, THEORY AND APPLICATIONS OF ONTOLOGY: COMPUTER APPLICATIONS, P231, DOI 10.1007/978-90-481-8847-5_10
   Fernndez-Lopez M, 1999, P IJCAI 99 WORKSH ON
   Fu GH, 2005, LECT NOTES COMPUT SC, V3761, P1466
   Gargouri F., 2010, Ontology theory, management and design
   Horrocks I, 2012, J ZHEJIANG U-SCI C, V13, P241, DOI 10.1631/jzus.C1101001
   Jiang YG, 2009, IEEE I CONF COMP VIS, P1420, DOI 10.1109/ICCV.2009.5459295
   Kara S, 2010, THESIS MIDDLE E TU
   KOSKO B, 1990, INT J GEN SYST, V17, P211, DOI 10.1080/03081079008935108
   Ksentini N, 2012, 10 INT WORKSH CONT B, P1
   Ksibi A, 2014, INT J MULTIMED INF R, V3, P29, DOI 10.1007/s13735-013-0045-5
   Ksibi A, 2012, INT CONF IMAG PROC, P377, DOI 10.1109/IPTA.2012.6469550
   Leite MAA, 2008, LECT NOTES COMPUT SC, V5290, P292, DOI 10.1007/978-3-540-88309-8_30
   Li ZJ, 2007, AI EDAM, V21, P137, DOI 10.1017/S0890060407070199
   Mukesh R, 2013, ADV COMPUTING COMMUN, V361, P181
   Muneesawang P, 2014, MULTIMEDIA DATABASE, P247
   Mustafa J, 2008, 2008 IS 08, V3
   Mylonas P, 2008, MULTIMED TOOLS APPL, V39, P293, DOI 10.1007/s11042-007-0161-4
   Mylonas P, 2009, IEEE T MULTIMEDIA, V11, P229, DOI 10.1109/TMM.2008.2009681
   Nikolopoulos S, 2011, IEEE T SYST MAN CY B, V41, P1366, DOI 10.1109/TSMCB.2011.2147781
   Nikolopoulos S, 2009, LECT NOTES ARTIF INT, V5632, P525, DOI 10.1007/978-3-642-03070-3_40
   Noy N. F., 2001, Ontology development 101: A guide to creating your first ontology
   Paliouras G, 2011, LECT NOTES ARTIF INT, V6050, P1, DOI 10.1007/978-3-642-20795-2
   Paliouras G, 2011, LECT NOTES COMPUT SC, V6050
   Paliouras G, 2011, LECT NOTES ARTIF INT, V6050, P1, DOI 10.1007/978-3-642-20795-2_1
   Park S, 2004, MULTIMEDIA SYST, V10, P164, DOI 10.1007/s00530-004-0148-1
   Petasis G, 2011, ONTOLOGYP OPULATION
   Petersohn C., 2004, TREC VIDEO RETRIEVAL
   Petridis K, 2006, IEE P-VIS IMAGE SIGN, V153, P255, DOI 10.1049/ip-vis:20050059
   Rodriguez-Garcia M. A., 2012, LECT NOTES COMPUTER, P163
   Romero AnaArmas., 2013, Informal Proceedings of the 2nd International Workshop on OWL Reasoner Evaluation, V1015, P61
   Rozilawati binti D, 2011, INT J DATA ENG, V2
   Sanjaa B, 2007, IFOST: 2007 INTERNATIONAL FORUM ON STRATEGIC TECHNOLOGY, P141, DOI 10.1109/IFOST.2007.4798542
   Sari Riri Fitri, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P34, DOI 10.4304/jetwi.2.1.34-41
   Singh P., 2012, INT J COMPUTER APPL, V14, P14
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   Staab Steffen., 2010, HDB ONTOLOGIES
   STOILOS G, 2005, INT WORKSH UNC REAS
   Thomee B., 2012, CLEF
   Vallet D, 2007, IEEE T CIRC SYST VID, V17, P336, DOI 10.1109/TCSVT.2007.890633
   Wu J, 2012, IEEE T MULTIMEDIA, V14, P291, DOI 10.1109/TMM.2011.2174969
   Yin-Fu Huang, 2012, Active Media Technology. 8th International Conference, AMT 2012. Proceedings, P1, DOI 10.1007/978-3-642-35236-2_1
   Zarka M, 2011, IEEE S SER COMP INT
   Zhai J, 2012, ADV INTEL SOFT COMPU, V137, P661
NR 74
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5719
EP 5750
DI 10.1007/s11042-015-2537-1
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600018
DA 2024-07-18
ER

PT J
AU Makantasis, K
   Doulamis, A
   Doulamis, N
   Ioannides, M
AF Makantasis, Konstantinos
   Doulamis, Anastasios
   Doulamis, Nikolaos
   Ioannides, Marinos
TI In the wild image retrieval and clustering for 3D cultural heritage
   landmarks reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based filtering; Image matching/clustering; Outliers removal;
   Cultural heritage objects; 3D reconstruction
ID RELEVANCE FEEDBACK; ALGORITHMS
AB One of the main characteristics of Internet era is the free and online availability of extremely large collections of images located on distributed and heterogeneous platforms over the web. The proliferation of millions of shared photographs spurred the emergence of new image retrieval techniques based not only on images' visual information, but on geo-location tags and camera exif data. These huge visual collections provide a unique opportunity for cultural heritage documentation and 3D reconstruction. The main difficulty, however, is that the internet image datasets are unstructured containing many outliers. For this reason, in this paper a new content-based image filtering is proposed to discard image outliers that either confuse or significantly delay the followed e-documentation tools, such as 3D reconstruction of a cultural heritage object. The presented approach exploits and fuses two unsupervised clustering techniques: DBSCAN and spectral clustering. DBSCAN algorithm is used to remove outliers from the initially retrieved dataset and spectral clustering discriminate the noise free image dataset into different categories each representing characteristic geometric views of cultural heritage objects. To discard the image outliers, we consider images as points onto a multi-dimensional manifold and the multi-dimensional scaling algorithm is adopted to relate the space of the image distances with the space of Gram matrices through which we are able to compute the image coordinates. Finally, structure from motion is utilized for 3D reconstruction of cultural heritage landmarks. Evaluation on a dataset of about 31,000 cultural heritage images being retrieved from internet collections with many outliers indicate the robustness and cost effectiveness of the proposed method towards a reliable and just-in-time 3D reconstruction than existing state-of-the-art techniques.
C1 [Makantasis, Konstantinos; Doulamis, Anastasios] Tech Univ Crete, Comp Vis & Decis Support Lab, Univ Campus, Kounoupidianachania 73100, Greece.
   [Doulamis, Nikolaos; Ioannides, Marinos] Cyprus Univ Technol, Dept Elect & Comp Engn, 30 Archbishop, CY-3036 Kyprianou, Lemesos, Cyprus.
C3 Cyprus University of Technology
RP Makantasis, K (corresponding author), Tech Univ Crete, Comp Vis & Decis Support Lab, Univ Campus, Kounoupidianachania 73100, Greece.
EM konst.makantasis@gmail.com
RI IOANNIDES, Marinos/ADZ-0030-2022; Makantasis, Konstantinos/Q-4475-2018;
   Doulamis, Anastasios/AAL-5972-2021
OI Makantasis, Konstantinos/0000-0002-0889-2766; 
FU Marie Curie IAPP project 4D-CH-World: Four Dimensional Cultural Heritage
   World [324523]
FX The research leading to these results has been supported by Marie Curie
   IAPP project 4D-CH-World: Four Dimensional Cultural Heritage World.
   Grant agreement number324523.
CR Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148
   Arampatzis A, 2013, INFORM PROCESS MANAG, V49, P274, DOI 10.1016/j.ipm.2012.03.005
   Bach FR, 2003, LEARING SPECTRAL CLU
   Barone S., 2012, 2012 18th International Conference on Virtual Systems and Multimedia (VSMM 2012). Proceedings, P259, DOI 10.1109/VSMM.2012.6365933
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bunsch E., 2012, 2012 18th International Conference on Virtual Systems and Multimedia (VSMM 2012). Proceedings, P633, DOI 10.1109/VSMM.2012.6365995
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Cayton L, 2006, CS20080923 U CAL
   Changchang Wu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3057, DOI 10.1109/CVPR.2011.5995552
   Changchang Wu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3113, DOI 10.1109/CVPR.2011.5995551
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Cox T. F., 2000, Multidimensional scaling
   Doulamis AD, 2000, SIGNAL PROCESS, V80, P1049, DOI 10.1016/S0165-1684(00)00019-0
   Doulamis AD, 2004, IEEE T CIRC SYST VID, V14, P656, DOI 10.1109/TCSVT.2004.826752
   Doulamis ND, 2003, IEEE MULTIMEDIA, V10, P38, DOI 10.1109/MMUL.2003.1237549
   Doulamis N, 2006, SIGNAL PROCESS-IMAGE, V21, P334, DOI 10.1016/j.image.2005.11.006
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   FAN K, 1951, P NATL ACAD SCI USA, V37, P760, DOI 10.1073/pnas.37.11.760
   Halkos D, 2009, MULTIMED TOOLS APPL, V42, P343, DOI 10.1007/s11042-008-0234-z
   Ioannides M., 2013, ISPRS Annals of the Photogrammetry, Remote Sensing and Saptial Information Sciences, VII-5 W, P169
   Karaszewski M, 2012, ROBOT AUTON SYST, V60, P1205, DOI 10.1016/j.robot.2012.05.005
   Kekre D. H. B., 2011, THINKQUEST 2010, P143, DOI DOI 10.1007/978-81-8489-989-4
   Kosmopoulos DI, 2009, SIGNAL PROCESS-IMAGE, V24, P158, DOI 10.1016/j.image.2008.12.010
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lv Q, 2007, P 33 INT C VER LARG, P950
   Min R, 2009, PATTERN RECOGN, V42, P147, DOI 10.1016/j.patcog.2008.07.001
   Murthy V. S. V. S., 2010, INT J ENG SCI TECHNO, V2
   Ntalianis KS, 2010, MULTIMED TOOLS APPL, V50, P199, DOI 10.1007/s11042-009-0369-6
   Papadakis N, 2008, MULTIMED TOOLS APPL, V38, P147, DOI 10.1007/s11042-007-0153-4
   Papadopoulos S, 2010, IEEE MULTIMED
   Rosin PL, 1999, COMPUT VIS IMAGE UND, V73, P291, DOI 10.1006/cviu.1998.0719
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Satopaa V., 2011, Proceedings of the 2011 31st International Conference on Distributed Computing Systems Workshops (ICDCS Workshops), P166, DOI 10.1109/ICDCSW.2011.20
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Simon I, 2007, IEEE I CONF COMP VIS, P274
   Sitnik R, 2010, LECT NOTES COMPUT SC, V6436, P28
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Wu CC, 2012, PROC CVPR IEEE, P1498, DOI 10.1109/CVPR.2012.6247839
   Yu SX, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P313, DOI 10.1109/iccv.2003.1238361
   Zheng YT, 2009, PROC CVPR IEEE, P1085, DOI 10.1109/CVPRW.2009.5206749
NR 41
TC 43
Z9 45
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 3593
EP 3629
DI 10.1007/s11042-014-2191-z
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200003
DA 2024-07-18
ER

PT J
AU Saleh, B
   Abe, K
   Arora, RS
   Elgammal, A
AF Saleh, Babak
   Abe, Kanako
   Arora, Ravneet Singh
   Elgammal, Ahmed
TI Toward automated discovery of artistic influence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital humanity; Automated artistic-influence discovery; Painting style
   classification; Knowledge discovery; Unsupervised learning; Image
   similarity; Content-based image retrieval
AB Considering the huge amount of art pieces that exist, there is valuable information to be discovered. Examining a painting, an expert can determine its style, genre, and the time period that the painting belongs. One important task for art historians is to find influences and connections between artists. Is influence a task that a computer can measure? The contribution of this paper is in exploring the problem of computer-automated suggestion of influences between artists, a problem that was not addressed before in a general setting. We first present a comparative study of different classification methodologies for the task of fine-art style classification. A two-level comparative study is performed for this classification problem. The first level reviews the performance of discriminative vs. generative models, while the second level touches the features aspect of the paintings and compares semantic-level features vs. low-level and intermediate-level features present in the painting. Then, we investigate the question "Who influenced this artist?" by looking at his masterpieces and comparing them to others. We pose this interesting question as a knowledge discovery problem. For this purpose, we investigated several painting-similarity and artist-similarity measures. As a result, we provide a visualization of artists (Map of Artists) based on the similarity between their works.
C1 [Saleh, Babak; Abe, Kanako; Arora, Ravneet Singh; Elgammal, Ahmed] Rutgers State Univ, Dept Comp Sci, 110 Frelinghuysen Rd, Piscataway, NJ 08854 USA.
C3 Rutgers University System; Rutgers University New Brunswick
RP Saleh, B (corresponding author), Rutgers State Univ, Dept Comp Sci, 110 Frelinghuysen Rd, Piscataway, NJ 08854 USA.
EM babaks@cs.rutgers.edu; kanakoabe@cs.rutgers.edu; rsingh@cs.rutgers.edu;
   elgammal@cs.rutgers.edu
OI Elgammal, Ahmed/0000-0003-2761-4822
CR [Anonymous], 2006, P IEEE COMPUTER SOC, DOI DOI 10.1109/CVPR.2006.95
   [Anonymous], ICPR
   [Anonymous], 2004, Int. J. Comput. Vis., DOI [DOI 10.1023/B:VISI.0000029664.99615.94, 10.1023/B:VISI.0000029664.99615.94]
   [Anonymous], 2007, P INT WORKSH WORKSH
   [Anonymous], AAI3189084 ETD COLL
   Arora R. S., 2012, ICPR
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Borg I., 2005, MODERN MULTIDIMENSIO, DOI DOI 10.18637/JSS.V014.B04
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Cabral R.S., 2011, SPIE Electronic Imaging, Computer Vision and Image Analysis of Art II
   Carneiro G., 2011, ICMR
   Carneiro G, 2012, LECT NOTES COMPUT SC, V7575, P143, DOI 10.1007/978-3-642-33765-9_11
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dubuisson M-P, 1994, PATTERN RECOGNITION
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Fichner-Rathus Lois., 2008, FDN ART DESIGN, V1st
   Gevers Koen T, 2010, IEEE T PATTERN ANAL
   Graham D, 2010, MAPPING SIMILARITY S
   Khan F.S., 2010, 2010 CREATE Conference, P329
   Li J., 2012, IEEE Trans. Pattern Anal. Mach. Intell
   Ng AndrewY., 2001, On discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Polatkan G, 2009, IEEE IMAGE PROC, P2921, DOI 10.1109/ICIP.2009.5413338
   Sablatnig R, 1998, P SPIE SCI DETECTION
   Shi F, 2009, LECT NOTES COMPUTER
   Sivic J, 2005, IEEE I CONF COMP VIS, P370
   Sivic J., 2009, PAMI
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Toldo R, 2009, P 4 INT C COMP VIS C
   Torresani L, 2010, LECT NOTES COMPUT SC, V6311, P776, DOI 10.1007/978-3-642-15549-9_56
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Weinberger K. Q., 2004, P 21 INT C MACH LEAR, P106
   Widjaja I, 2003, ICIP
NR 36
TC 37
Z9 43
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 3565
EP 3591
DI 10.1007/s11042-014-2193-x
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200002
DA 2024-07-18
ER

PT J
AU Wang, XG
AF Wang, Xue-Guang
TI A new algorithm for the influence maximization problem in dynamic
   networks or traffic sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heuristic algorithm; Dynamic network; Information diffusion model;
   Influence maximization
AB Influence spread is one of the key problems in complex networks, and the results of influence maximization problem (IMP) based on dynamic networks are less. In this paper, we discuss the dynamic IMP and describe the dynamic independent cascade model (DICM) and the dynamic linear threshold model (DLTM). We also conclude that IMP based on DICM and DLTM is NP-Hard. To solve the IMP, we present an improved greedy algorithm that is validated based on four datasets with different sizes. Our findings indicate that, compared with the HT algorithm, the size of the influence spread of our algorithm has an obvious advantage, and time efficiency is better than that of the HT algorithm.
C1 [Wang, Xue-Guang] East China Univ Polit Sci & Law, Dept Comp Sci, Shanghai 201620, Peoples R China.
   [Wang, Xue-Guang] UCL, Dept Comp Sci, Mortimer St, London WC1E 6BT, England.
C3 East China University Political Science & Law; University of London;
   University College London
RP Wang, XG (corresponding author), East China Univ Polit Sci & Law, Dept Comp Sci, Shanghai 201620, Peoples R China.; Wang, XG (corresponding author), UCL, Dept Comp Sci, Mortimer St, London WC1E 6BT, England.
EM wangxueguang@ecupl.edu.cn
FU National Social Science Foundation of China [11BF-X125]; PuJiang Talent
   Project; Peak of law subject construction; Public Security Discipline
   Construction Foundation
FX This work is supported by National Social Science Foundation of China
   (No. 11BF-X125), PuJiang Talent Project, Peak of law subject
   construction and Public Security Discipline Construction Foundation.
CR [Anonymous], TELECOMMUNICATION SY
   Chen W., 2010, ACM SIGKDD INT C KNO, P1029, DOI DOI 10.1145/1835804.1835934
   Chen W, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P199, DOI 10.1145/1557019.1557047
   Domingos P., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P57, DOI 10.1145/502512.502525
   Even-Dar E, 2007, LECT NOTES COMPUT SC, V4858, P281
   Fu C, 2015, MULTIMEDIA TOOLS APP
   Goldenberg J, 2001, MARKET LETT, V12, P211, DOI 10.1023/A:1011122126881
   GRANOVETTER M, 1978, AM J SOCIOL, V83, P1420, DOI 10.1086/226707
   Gu W, 2017, MULTIMED TOOLS APPL, V76, P17719, DOI 10.1007/s11042-015-2960-3
   Habiba TB-W, 2007, 20 DIMACS
   Habiba YuY, 2008, 2 SNA KDD WORKSH LAS
   Jiang CR, 2010, INT ASIA CONF INFORM, P88, DOI 10.1109/CAR.2010.5456772
   Jiang D, 2015, J COMMUNICATIONS NET
   Jiang DD, 2016, WIRELESS PERS COMMUN, V86, P901, DOI 10.1007/s11277-015-2961-6
   Kempe D, 2003, P 9 ACM SIGKDD INT C, P137, DOI DOI 10.1145/956750.956769
   Lahiri M, 2010, AAAI CONF ARTIF INTE, P494
   Leskovec J, 2008, SYNAMICS LARGE NETWO
   Leskovec J, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P420
   Li X, 2015, MULTIMEDIA TOOLS APP
   Lin YC, 2015, SENSORS-BASEL, V15, P20925, DOI 10.3390/s150820925
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   NEMHAUSER GL, 1978, MATH PROGRAM, V14, P265, DOI 10.1007/BF01588971
   Richardson M., 2002, P 8 ACM SIGKDD INT C, P61, DOI DOI 10.1145/775047.775057
   Tengfei Yin, 2011, Journal of Networks, V6, P990, DOI 10.4304/jnw.6.7.990-998
   Wang K, 2014, IEEE INT CONF BIG DA, P119, DOI 10.1109/BigData.2014.7004220
NR 25
TC 6
Z9 6
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4833
EP 4844
DI 10.1007/s11042-016-3266-9
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700032
DA 2024-07-18
ER

PT J
AU Choi, MK
   Wang, ZY
   Lee, HG
   Lee, SC
AF Choi, Min-Kook
   Wang, Ziyu
   Lee, Hyun-Gyu
   Lee, Sang-Chul
TI A bag-of-regions representation for video classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video segmentation; Region tracking; Bag-of-regions; Video
   classification
AB A bag-of-regions (BoR) representation of a video sequence is a spatio-temporal tessellation for use in high-level applications such as video classifications and action recognitions. We obtain a BoR representation of a video sequence by extracting regions that exist in the majority of its frames and largely correspond to a single object. First, the significant regions are obtained using unsupervised frame segmentation based on the JSEG method. A tracking algorithm for splitting and merging the regions is then used to generate a relational graph of all regions in the segmented sequence. Finally, we perform a connectivity analysis on this graph to select the most significant regions, which are then used to create a high-level representation of the video sequence. We evaluated our representation using a SVM classifier for the video classification and achieved about 85 % average precision using the UCF50 dataset.
C1 [Choi, Min-Kook; Wang, Ziyu; Lee, Hyun-Gyu; Lee, Sang-Chul] Inha Univ, Dept Comp & Informat Engn, 100 Inha Ro, Inchon, South Korea.
C3 Inha University
RP Lee, SC (corresponding author), Inha Univ, Dept Comp & Informat Engn, 100 Inha Ro, Inchon, South Korea.
EM mkchoi@inha.edu; sclee@inha.edu
RI Choi, Min-Kook/ABE-2827-2020
OI Choi, Min-Kook/0000-0001-7610-631X; Lee, Sang-Chul/0000-0002-6973-2416
FU Next-Generation Information Computing Development Program through the
   National Research Foundation of Korea (NRF) - Ministry of Science, ICT &
   Future Planning [2012M3C4A7032781]; ICT R&D program of MSIP/IITP
   [2014(10047078)]; INHA UNIVERSITY Research Grant
FX This work was supported by (1) Next-Generation Information Computing
   Development Program through the National Research Foundation of Korea
   (NRF) funded by the Ministry of Science, ICT & Future Planning
   (2012M3C4A7032781), (2) the ICT R&D program of MSIP/IITP.
   [2014(10047078), 3D reconstruction technology development for scene of
   car accident using multi view black box image], and (3) INHA UNIVERSITY
   Research Grant.
CR Abd-Almageed W, 2008, P INT C IM PROC
   [Anonymous], P INT C COMP VIS
   [Anonymous], P INT C COMP VIS
   [Anonymous], P COMP VIS PATT REC
   [Anonymous], 2011, P INT C COMP VIS
   Bandla S, 2013, P INT C COMP VIS
   Banerjee P, 2008, IEEE WORKSH MOT VID
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Black M, 2005, P INT C COMP VIS
   Blilen H, 2011, IEEE WORKSH APPL COM
   Bojanowski P, 2013, P COMP VIS PATT REC
   Brendal W, 2009, P INT C COMP VIS
   Chakraborty B, 2012, COMPUT VIS IMAGE UND, V116, P396, DOI 10.1016/j.cviu.2011.09.010
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Choi J, 2013, COMPUT VIS IMAGE UND, V117, P660, DOI 10.1016/j.cviu.2013.02.003
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Dalal N, 2006, P COMP VIS PATT REC
   Demir G, 2007, P COMP VIS PATT REC
   Deng Y, 2011, IEEE T PATTERN ANAL, V23, P800
   Gonzalez RC., Digital image processing third edition Pearson international edition prepared by Pearson Education
   Jhuang H, 2013, P INT C COMP VIS
   Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68
   Ke Y, 2004, PROC CVPR IEEE, P506
   Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881
   Kuehne H., 2011, P INT C COMP VIS
   Laptev I, 2005, INT J COMPUT VISION, V108, P207
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   LI LJ, 2007, P INT C COMP VIS
   Lowe DG, 2005, P INT C COMP VIS
   Luo Y, 2003, COMPUT VIS IMAGE UND, V92, P196, DOI 10.1016/j.cviu.2003.08.001
   Makadia A, 2010, LECT NOTES COMPUT SC, V6315, P310, DOI 10.1007/978-3-642-15555-0_23
   Marszalek M, 2009, P COMP VIS PATT REC
   Masoud O, 2001, IEEE T VEH TECHNOL, V50, P1267, DOI 10.1109/25.950328
   McCandless T, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.30
   Niebles J, 2010, P EUR C COMP VIS
   Pirsiavash H., 2012, P COMP VIS PATT REC
   Raptis M, 2013, P COMP VIS PATT REC
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sivic J, 2006, INT J COMPUT VISION, V67, P189, DOI 10.1007/s11263-005-4264-y
   Turcot Panu, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P2109, DOI 10.1109/ICCVW.2009.5457541
   Ullah MM, 2012, IEEE IMAGE PROC, P777, DOI 10.1109/ICIP.2012.6466975
   Umamakeswari A., 2007, Journal of Computer Sciences, V3, P818, DOI 10.3844/jcssp.2007.818.822
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Wang H., 2009, BMVC
   Weinland D, 2007, IEEE I CONF COMP VIS, P170
NR 45
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2453
EP 2472
DI 10.1007/s11042-015-2876-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000004
DA 2024-07-18
ER

PT J
AU Zhang, XP
   Fan, X
   Wang, JY
   Zhao, ZM
AF Zhang, Xuanping
   Fan, Xing
   Wang, Jiayin
   Zhao, Zhongmeng
TI A chaos-based image encryption scheme using 2D rectangular transform and
   dependent substitution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaos; Rectangular mapping; Permutation; Substitution
ID ONLY MULTIMEDIA CIPHERS; S-BOX; QUANTITATIVE CRYPTANALYSIS; BLOCK
   CIPHER; ALGORITHM; PERMUTATION; MAP
AB Chaos-based image cryptosystems usually adopt the traditional confusion-diffusion architecture which is considered insecure against known/chosen plaintext attacks. To overcome this drawback, this paper proposes a novel chaos-based image encryption scheme, in which the two-dimensional rectangular transform is employed to directly scramble the image of any rectangular size, and the dependent substitution is introduced to substitute for each pixel according to the image pixels. This scheme comprises two stages of encryption processes. Each stage provides the confusion and diffusion simultaneously in one traverse of image pixels. As a result, the proposed scheme has high speed and achieves a satisfactory security performance. Experimental results and various types of security analysis indicate that this scheme is efficient and secure enough to be used for practical image encryption and transmission.
C1 [Zhang, Xuanping; Fan, Xing; Zhao, Zhongmeng] Xi An Jiao Tong Univ, Dept Comp Sci & Technol, Xian 710049, Peoples R China.
   [Wang, Jiayin] Washington Univ, Genome Inst, St Louis, MO 63108 USA.
C3 Xi'an Jiaotong University; Washington University (WUSTL)
RP Zhang, XP (corresponding author), Xi An Jiao Tong Univ, Dept Comp Sci & Technol, Xian 710049, Peoples R China.
EM zxp@mail.xjtu.edu.cn
RI Wang, Jiayin/HJP-0287-2023
FU National Natural Science Foundation of China [61100239]; Ph.D. Programs
   Foundation of Ministry of Education of China [20100201110063]; Shaanxi
   Provincial Natural Science Foundation of China [2014JM8322, 2014JM8350]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No: 61100239), the Ph.D. Programs Foundation of Ministry of
   Education of China (Grant No: 20100201110063), the Shaanxi Provincial
   Natural Science Foundation of China (Grant No: 2014JM8322, 2014JM8350).
CR Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Arroyo D, 2009, CHAOS SOLITON FRACT, V41, P2613, DOI 10.1016/j.chaos.2008.09.051
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen G, 2007, CHAOS SOLITON FRACT, V31, P571, DOI 10.1016/j.chaos.2005.10.022
   Fouda JSAE, 2014, COMMUN NONLINEAR SCI, V19, P578, DOI 10.1016/j.cnsns.2013.07.016
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fu C, 2012, OPT EXPRESS, V20, P2363, DOI 10.1364/OE.20.002363
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Hussain I, 2013, MATH COMPUT MODEL, V57, P2576, DOI 10.1016/j.mcm.2013.01.009
   Hussain I, 2012, OPT COMMUN, V285, P4887, DOI 10.1016/j.optcom.2012.06.011
   Jolfaei A., 2011, COMPUT INFORM SCI, V4, P172
   Khan M, 2013, NONLINEAR DYNAM, V71, P489, DOI 10.1007/s11071-012-0675-9
   Kumar A, 2011, COMMUN NONLINEAR SCI, V16, P372, DOI 10.1016/j.cnsns.2010.04.010
   Li CQ, 2011, SIGNAL PROCESS, V91, P949, DOI 10.1016/j.sigpro.2010.09.014
   Li HJ, 2013, OPT LASER ENG, V51, P1327, DOI 10.1016/j.optlaseng.2013.05.011
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   Liu H, 2014, OPT LASER TECHNOL, V56, P313, DOI 10.1016/j.optlastec.2013.09.012
   Liu HJ, 2013, J SYST SOFTWARE, V86, P826, DOI 10.1016/j.jss.2012.11.026
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Norouzi B, 2015, MULTIMED TOOLS APPL, V74, P781, DOI 10.1007/s11042-013-1699-y
   Özkaynak F, 2010, PHYS LETT A, V374, P3733, DOI 10.1016/j.physleta.2010.07.019
   Shao Liping, 2009, Journal of Computer Aided Design & Computer Graphics, V21, P1025
   Tang ZJ, 2015, MULTIMED TOOLS APPL, V74, P5429, DOI 10.1007/s11042-014-1861-1
   Wang XY, 2014, NONLINEAR DYNAM, V75, P567, DOI 10.1007/s11071-013-1086-2
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wang Y, 2012, PHYS LETT A, V376, P827, DOI 10.1016/j.physleta.2012.01.009
   Wang Y, 2009, COMMUN NONLINEAR SCI, V14, P3089, DOI 10.1016/j.cnsns.2008.12.005
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Zhang Q, 2014, AEU-INT J ELECTRON C, V68, P186, DOI 10.1016/j.aeue.2013.08.007
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P2066, DOI 10.1016/j.cnsns.2012.12.012
   Zhang XP, 2014, COMPUT ELECTR ENG, V40, P931, DOI 10.1016/j.compeleceng.2013.08.008
   Zhang XP, 2014, NONLINEAR DYNAM, V75, P319, DOI 10.1007/s11071-013-1068-4
   Zhang YS, 2013, NONLINEAR DYNAM, V72, P751, DOI 10.1007/s11071-013-0750-x
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 35
TC 26
Z9 27
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 1745
EP 1763
DI 10.1007/s11042-014-2372-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000001
DA 2024-07-18
ER

PT J
AU Bellil, W
   Brahim, H
   Ben Amar, C
AF Bellil, Wajdi
   Brahim, Hajer
   Ben Amar, Chokri
TI Gappy wavelet neural network for 3D occluded faces: detection and
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D face recognition; Wavelets; Wavelet neural network; Gappy data;
   Occlusion detection
AB The first handicap in 3D faces recognizing under unconstrained problem is the largest variability of the visual aspect when we use various sources. This great variability complicates the task of identifying persons from their 3D facial scans and it is the most reason that bring to face detection and recognition of the major problems in pattern recognition fields, biometrics and computer vision. We propose a new 3D face identification and recognition method based on Gappy Wavelet Neural Network (GWNN) that is able to provide better accuracy in the presence of facial occlusions. The proposed approach consists of three steps: the first step is face detection. The second step is to identify and remove occlusions. Occluded regions detection is done by considering that occlusions can be defined as local face deformations. These deformations are detected by a comparison between the input facial test wavelet coefficients and wavelet coefficients of generic face model formed by the mean data base faces. They are beneficial for neighborhood relationships between pixels rotation, dilation and translation invariant. Then, occluded regions are refined by removing wavelet coefficient above a certain threshold. Finally, the last stage of processing and retrieving is made based on wavelet neural network to recognize and to restore 3D occluded regions that gathers the most. The experimental results on this challenging database demonstrate that the proposed approach improves recognition rate performance from 93.57 to 99.45 % which represents a competitive result compared to the state of the art.
C1 [Bellil, Wajdi; Brahim, Hajer; Ben Amar, Chokri] Univ Sfax, Natl Engn Sch Sfax ENIS, REGIM Res Grp Intelligent Machines, Sfax, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Bellil, W (corresponding author), Univ Sfax, Natl Engn Sch Sfax ENIS, REGIM Res Grp Intelligent Machines, Sfax, Tunisia.
EM wajdi.bellil@ieee.org; hajer.brahim@gmail.com; chokri.benamar@ieee.org
RI Chokri, BEN AMAR/K-5237-2012
FU General Direction of Scientific Research (DGRST), Tunisia, under the
   ARUB program
FX The authors would like to acknowledge the financial support of this work
   by grants from General Direction of Scientific Research (DGRST),
   Tunisia, under the ARUB program.
CR Alyuz N, 2008, 2 IEEE INT C BIOM TH
   [Anonymous], 2011 4 INT C MOD SIM
   Bellil W, 2007, INT REV COMPUTERS SO, V2, P520
   Bellil W, 2008, ADV ROBOTICS AUTOMAT, P199
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Chang KI, 2006, IEEE T PATTERN ANAL, V28, P1695, DOI 10.1109/TPAMI.2006.210
   Colombo A, 2006, PATTERN RECOGN, V39, P444, DOI 10.1016/j.patcog.2005.09.009
   Colombo A, 2009, J MATH IMAGING VISIO, V35
   Colombo A, 2010, 3 DIMENSIONAL OCCLUS
   Colombo A, 2011, IT COMP VIS WORKSH I
   Colombo A, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P393, DOI 10.1109/ICIAP.2007.4362810
   Colombo A, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1541, DOI 10.1109/ICME.2006.262837
   Drira H, 2012, NOUVELLE APPROCHE RE
   Faltemier T, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P318
   Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017
   Kim J, 2005, IEEE T PATTERN ANAL, V27, P1977, DOI 10.1109/TPAMI.2005.242
   MARTINEZ AM, 2002, RECOGNIZING IMPRECIS
   Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105
   Nesterov Yu. E., 1983, Doklady Akademii Nauk SSSR, V269, P543
   Othmani M, 2010, INT J WAVELETS MULTI, V8, P149, DOI 10.1142/S0219691310003353
   Phillips J.P., 2007, FRVT 2006 and ICE 2006 large-scale results
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Soatto S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P974
   Tarrés F, 2005, PROCEEDINGS ELMAR-2005, P163
   Z-m Wang, 2010, J COMPUTER RES DEV
NR 26
TC 9
Z9 9
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 365
EP 380
DI 10.1007/s11042-014-2294-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500018
DA 2024-07-18
ER

PT J
AU Huang, YS
   Chieu, BC
AF Huang, Yung-Sung
   Chieu, Bin-Chang
TI A video decoding optimization for heterogeneous dual-core platforms
   architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Task scheduling; Video decoding
AB Digital signal processors (DSPs), with their powerful computing abilities, are commonly used for multimedia coding/decoding processes. Therefore, the SOC (System on Chip) industry integrates DSP with ARM (Advanced RISC Machine) for input/output processing, saving power, and building up a multi-core platform used in handheld devices. The computing ability of ARM has been substantially improved with some state of the art technique. The industry currently has regarded the integration of ARM and DSP into SOC as two independent cores to enhance the efficiency. Since one algorithm is added to process the distributed computing work of the dual cores, the efficiency must be doubled. The system will assign the work to the core with higher processing efficiency. Instead of the traditional Static task scheduling, this article proposed a new approach called Dynamic task scheduling, providing 29.88 % higher efficiency than that of Static task scheduling. The reason is that the static partition will finally send the heavy load of computing to DSP; therefore, it is not possible to achieve the enhanced efficiency of the multi-core. However, the dynamic task scheduling will consider the actual loading of each core for computing and communicate with each other; furthermore, it can share the work to assist the process of each core. Besides, the Direct Memory Access is integrated with the multi-core platform to reduce the time-consumption resulted from the communication between the dual cores. The experimental result shows that the dynamic partition operated by the heterogeneous dual core system can use 192 MHz pulse to decode the CIF video signal that the decoding speed can reach 30fps and the efficiency is improved 50 % with DMA (Direct Memory Access) technology incorporated.
C1 [Huang, Yung-Sung; Chieu, Bin-Chang] Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology
RP Huang, YS (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, Taipei, Taiwan.
EM d9502205@mail.ntust.edu.tw; chu@mail.ntust.edu.tw
CR Beitollahi H, 2006, 12TH PACIFIC RIM INTERNATIONAL SYMPOSIUM ON DEPENDABLE COMPUTING, PROCEEDINGS, P296
   CASAVANT TL, 1988, IEEE T SOFTWARE ENG, V14, P141, DOI 10.1109/32.4634
   Cederman D., 2008, P 23 ACM SIGGRAPH EU, P57
   Chiu CN, 2005, IEEE INT SYMP CIRC S, P2132
   Choi Byeong-Doo, 2003, IEEE INT C CONS EL I
   Heirich A, 1998, J SUPERCOMPUT, V12, P57, DOI 10.1023/A:1007977326603
   Koziri M, 2011, IEEE T CONSUM ELECTR, V57, P673, DOI 10.1109/TCE.2011.5955207
   Lee JY, 2010, IET CIRC DEVICE SYST, V4, P147, DOI 10.1049/iet-cds.2009.0038
   Lee Kyu Ha, 2001, IEEE T CONSUMER ELEC
   Lin YH, 2009, IEEE INT CONF EMBED, P69, DOI 10.1109/RTCSA.2009.14
   Liu T., 2004, Proceedings. IEEE Sixth International Symposium on Multimedia Software, P458
   Rader Sheila, MOBILE ETREME CONVER
   Song FG, 2009, PROCEEDINGS OF THE CONFERENCE ON HIGH PERFORMANCE COMPUTING NETWORKING, STORAGE AND ANALYSIS
NR 13
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 627
EP 646
DI 10.1007/s11042-014-2312-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500028
DA 2024-07-18
ER

PT J
AU Siddiqi, MH
   Ali, R
   Idris, M
   Khan, AM
   Kim, ES
   Whang, MC
   Lee, S
AF Siddiqi, Muhammad Hameed
   Ali, Rahman
   Idris, Muhammad
   Khan, Adil Mehmood
   Kim, Eun Soo
   Whang, Min Cheol
   Lee, Sungyoung
TI Human facial expression recognition using curvelet feature extraction
   and normalized mutual information feature selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial Expressions; Curvelet Transform; Mutual Information; Minimal
   Redundancy; Maximal Relevance
ID FACE RECOGNITION; MODELS
AB To recognize expressions accurately, facial expression systems require robust feature extraction and feature selection methods. In this paper, a normalized mutual information based feature selection technique is proposed for FER systems. The technique is derived from an existing method, that is, the max-relevance and min-redundancy (mRMR) method. We, however, propose to normalize the mutual information used in this method so that the domination of the relevance or of the redundancy can be eliminated. For feature extraction, curvelet transform is used. After the feature extraction and selection the feature space is reduced by employing linear discriminant analysis (LDA). Finally, hidden Markov model (HMM) is used to recognize the expressions. The proposed FER system (CNF-FER) is validated using four publicly available standard datasets. For each dataset, 10-fold cross validation scheme is utilized. CNF-FER outperformed the existing well-known statistical and state-of-the-art methods by achieving a weighted average recognition rate of 99 % across all the datasets.
C1 [Siddiqi, Muhammad Hameed; Ali, Rahman; Idris, Muhammad; Lee, Sungyoung] Kyung Hee Univ, Dept Comp Engn, Suwon 446701, South Korea.
   [Khan, Adil Mehmood] Ajou Univ, Div Informat & Comp Engn, Suwon 443749, South Korea.
   [Kim, Eun Soo] Kwangwoon Univ, Dept Elect Engn, Seoul 139701, South Korea.
   [Whang, Min Cheol] Sang Myung Univ, Div Digital Media Engn, Suwon 110809, South Korea.
C3 Kyung Hee University; Ajou University; Kwangwoon University; Sangmyung
   University
RP Lee, S (corresponding author), Kyung Hee Univ, Dept Comp Engn, Suwon 446701, South Korea.
EM sylee@oslab.khu.ac.kr
RI Siddiqi, Muhammad Hameed/ADU-4375-2022; Khan, Adil/L-2210-2017; Lee,
   Sungyoung/AAK-7257-2020; Ali, Dr. Rahman/ADR-1711-2022
OI Siddiqi, Muhammad Hameed/0000-0002-4370-8012; Ali, Dr.
   Rahman/0000-0002-9171-8573; Idris, Muhammad/0000-0001-9764-2322
FU National Research Foundation of Korea (NRF) grant - Korea government
   (MSIP) [2013-067321]; MSIP (Ministry of Science, ICT & Future Planning),
   Korea under ITRC (Information Technology Research Center)
   [NIPA-2014-(H0301-14-1003]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIP) (No. 2013-067321)).;
   This research was also supported by the MSIP (Ministry of Science, ICT &
   Future Planning), Korea, under the ITRC (Information Technology Research
   Center) support program supervised by the NIPA (National IT Industry
   Promotion Agency) (NIPA-2014-(H0301-14-1003).
CR Abd El Meguid MK, 2014, IEEE T AFFECT COMPUT, V5, P141, DOI 10.1109/TAFFC.2014.2317711
   BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224
   Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980
   Baum L. E., 1972, Inequalities, V3, P1
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   BETTADAPURA V, 2012, COMPUTER SCI
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Dash M., 1997, Intelligent Data Analysis, V1
   Estévez PA, 2009, IEEE T NEURAL NETWOR, V20, P189, DOI 10.1109/TNN.2008.2005601
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Filko D, 2013, AUTOMATIKA-UK, V54, P263, DOI 10.7305/automatika.54-2.73
   Fodor I. K, 2002, SURVEY DIMENSION RED
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Ghimire D, 2013, SENSORS-BASEL, V13, P7714, DOI 10.3390/s130607714
   Hall M. A., 1999, Proceedings of the Twelfth International Florida AI Research Society Conference, P235
   Hossain MA, 2012, INT J ADV INF TECHNO, V2, P37, DOI [DOI 10.5121/IJAIT.2012.2504.37, 10.5121/ijait.2012.2504.37]
   Kamimura R, 2011, APPL INTELL, V34, P102, DOI 10.1007/s10489-009-0183-x
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Kashyap KL, 2012, INT J IMAGE PROCESS, V1, P29
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Kwak N, 2002, IEEE T NEURAL NETWOR, V13, P143, DOI 10.1109/72.977291
   Liu M, 2014, IEEE COMP SOC C COMP
   Liu P, 2014, IEEE COMP SOC C COMP
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Mika S, 2002, THESIS UNIVERSITATSB
   Mika S., 1999, NNSP, V1999, P41, DOI DOI 10.1109/NNSP.1999.788121
   Pagariya RR, 2013, FACIAL EMOTION RECOG, V3, P111
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Piatkowska E, HYBRID ARTIFICIAL IN
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Ramírez-Gutiérrez K, 2010, INT CONF APPL COMPUT, P85
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   Samaria F., 1994, THESIS U CAMBRIDGE
   Schels Martin, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4251, DOI 10.1109/ICPR.2010.1033
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shan He, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P760, DOI 10.1109/ICIG.2011.91
   Siddiqi MH, 2014, MULTIMEDIA SYSTEMS
   Siddiqi MH, 2013, SENSORS-BASEL, V13, P16682, DOI 10.3390/s131216682
   Smith BM, 2014, NONPARAMETRIC CONTEX
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Tang M, 2013, OPTIK, V124, P5401, DOI 10.1016/j.ijleo.2013.03.116
   Uddin MZ, 2009, IEEE T CONSUM ELECTR, V55, P2216, DOI 10.1109/TCE.2009.5373791
   Wang SF, 2010, IEEE T MULTIMEDIA, V12, P682, DOI 10.1109/TMM.2010.2060716
   Zhang SQ, 2012, SENSORS-BASEL, V12, P3747, DOI 10.3390/s120303747
   Zhao XM, 2011, SENSORS-BASEL, V11, P9573, DOI 10.3390/s111009573
NR 46
TC 20
Z9 21
U1 0
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 935
EP 959
DI 10.1007/s11042-014-2333-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700012
DA 2024-07-18
ER

PT J
AU Yan, LY
   Ling, HF
   Zou, FH
   Liu, C
AF Yan, Lingyu
   Ling, Hefei
   Zou, Fuhao
   Liu, Cong
TI Iterated local search optimized hashing for image copy detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based image copy detection; Robust hashing; Iterated local
   search; Image fingerprinting
ID QUANTIZATION; SCHEME; GRAPH
AB Currently, researches on content based image copy detection mainly focus on robust feature extraction. However, due to the exponential growth of online images, it is necessary to consider searching among large number of images, which is very time-consuming and unscalable. Hence, we need to pay much attention to the efficiency of image detection. Although many hashing methods has been proposed, they did not show excellent performance in decreasing semantic loss during the process of hashing. In this paper, we propose a hashing based method for image copy detection, which not only generates compact fingerprint for image representation, but also prevents huge semantic loss during the process of hashing. To generate the fingerprint, an objective function of semantic loss is constructed and minimized, which combine the influence of both the neighborhood structure of feature data and mapping error. To minimize the objective function, we first calculate an approximate solution through trace optimization, and then optimize the solution through Iterated Local Search(ILS) to further decrease semantic loss. Experimental results show that our approach significantly outperforms state-of-art methods.
C1 [Yan, Lingyu; Ling, Hefei; Zou, Fuhao; Liu, Cong] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Ling, HF (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM yanranyaya@hust.edu.cn; lheifei@hust.edu.cn; fuhao_zou@hust.edu.cn;
   liucongwust@hust.edu.cn
FU NSF of China [61272409]; Fundamental Research Funds for Central
   Universities; Wuhan Youth Science and Technology Chenguang Program
FX This work is supported by the NSF of China under Grant No. 61272409, the
   Fundamental Research Funds for the Central Universities and Wuhan Youth
   Science and Technology Chenguang Program. The authors appreciate the
   valuable suggestions from the anonymous reviewers and the Editors.
CR Ahmed F, 2010, SIGNAL PROCESS, V90, P1456, DOI 10.1016/j.sigpro.2009.05.024
   [Anonymous], 2008, Proceedings of the 21st International Conference on Neural Information Processing Systems
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   BERRANI S.-A., 2003, Proceedings of the 1st ACM international workshop on Multimedia databases, P70, DOI DOI 10.1145/951676.951690
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   Hawkins DM, 2003, J CHEM INF COMP SCI, V43, P579, DOI 10.1021/ci025626i
   He KM, 2013, PROC CVPR IEEE, P2938, DOI 10.1109/CVPR.2013.378
   Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024
   Hoos H H, 2004, COMBINATORIAL FUSION
   Joachims T, 2004, P 12 ACM SIGKDD INT, P217
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Lai HJ, 2013, IEEE T COMPUT, V62, P1221, DOI 10.1109/TC.2012.62
   Lei YQ, 2011, SIGNAL PROCESS-IMAGE, V26, P280, DOI 10.1016/j.image.2011.04.007
   Li P, 2013, IEEE T MULTIMEDIA, V15, P141, DOI 10.1109/TMM.2012.2199970
   Lin LA, 2010, IEEE T PATTERN ANAL, V32, P1426, DOI 10.1109/TPAMI.2009.150
   Lin L, 2009, PATTERN RECOGN, V42, P1297, DOI 10.1016/j.patcog.2008.10.033
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Lü ZP, 2009, LECT NOTES COMPUT SC, V5482, P1
   Lv Q., 2007, P 33 INT C VER LARG, P950
   Lv XD, 2012, IEEE T INF FOREN SEC, V7, P1081, DOI 10.1109/TIFS.2012.2190594
   Meng Y, 2003, PROC CVPR IEEE, P416
   Norouzi M.E., 2011, ICML
   Perronnin F, 2012, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2012.6248090
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750
   Song J., 2011, P 19 ACM INT C MULT, P423, DOI DOI 10.1145/2072298.2072354
   Tang ZJ, 2011, MULTIMED TOOLS APPL, V52, P325, DOI 10.1007/s11042-009-0437-y
   Tang Zhenjun., 2008, Journal of ubiquitous convergence technology, V2, P18, DOI DOI 10.1109/INF0P.2015.7489395
   Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994
   Yang Y, 2008, IEEE T MULTIMEDIA, V10, P437, DOI 10.1109/TMM.2008.917359
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Zhang D, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P18
   Zou FH, 2013, SIGNAL PROCESS, V93, P2265, DOI 10.1016/j.sigpro.2012.05.033
NR 35
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9729
EP 9746
DI 10.1007/s11042-014-2148-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200031
DA 2024-07-18
ER

PT J
AU Jiang, GY
   Zhou, JM
   Yu, M
   Zhang, Y
   Shao, F
   Peng, ZJ
AF Jiang, Gangyi
   Zhou, Junming
   Yu, Mei
   Zhang, Yun
   Shao, Feng
   Peng, Zongju
TI Binocular vision based objective quality assessment method for
   stereoscopic images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereoscopic image; Objective quality assessment; Human visual system;
   Binocular fusion; Binocular suppression
ID SINGLE VISION; VIDEO
AB Human visual system (HVS) can perceive the difference between two retinal images to create a mental image with depth perception, which is the result of two binocular interactions, i.e., binocular fusion and suppression. According to perceptual attributes of binocular interactions, in this paper, a full-reference stereoscopic image quality assessment (SIQA) method is proposed based on the mechanisms of binocular fusion and suppression. There are two kinds of information in stereoscopic images: monocular information which is visible in only one view, and binocular information which is visible in two views. HVS adopts two ways to deal with the binocular information, one is binocular fusion which deals with the information with similar content and small disparity, the other is binocular suppression which deals with the information with dissimilar content or large disparity. Therefore, the proposed method firstly divides a distorted stereoscopic image into occluded, pseudo-binocular fusion and pseudo-binocular suppression regions. Then three methods are respectively adopted to assess the quality of the three regions and the three quality indices combine into one to represent the overall quality of the distorted stereoscopic image. Finally, the predictive performance of the proposed method is evaluated and compared with existing methods in terms of consistency, cross-image and cross-distortion, and robustness. Experimental results show that the proposed SIQA method outperforms other methods and can predict human visual perception of stereoscopic image more accurately.
C1 [Jiang, Gangyi; Zhou, Junming; Yu, Mei; Shao, Feng; Peng, Zongju] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
   [Jiang, Gangyi; Zhou, Junming] Chinese Acad Sci, Inst Comp Technol, Beijing 100080, Peoples R China.
   [Zhang, Yun] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
C3 Ningbo University; Chinese Academy of Sciences; Institute of Computing
   Technology, CAS; Chinese Academy of Sciences; Shenzhen Institute of
   Advanced Technology, CAS
RP Jiang, GY (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
EM jianggangyi@126.com
RI Zhang, Yun/V-7261-2019; Peng, Zongju/AAA-2914-2020; jiang,
   gang/KII-8233-2024
OI Zhang, Yun/0000-0001-9457-7801; Peng, Zongju/0000-0001-8286-538X; 
FU Natural Science Foundation of China [U1301257, 61271270, 61171163,
   61271021]; K. C. Wong Magna Fund in Ningbo University
FX This work was supported by the Natural Science Foundation of China
   (grant U1301257, 61271270, 61171163, 61271021) and the K. C. Wong Magna
   Fund in Ningbo University.
CR [Anonymous], 2002, METH SUBJ EV QUAL TE
   [Anonymous], 2011, 2011 IEEE INT INSTRU, DOI DOI 10.1109/IMTC.2011.5944170
   [Anonymous], 2000, SUBJ ASS STER TEL PI
   Benoit A, 2008, IEEE IMAGE PROC, P389, DOI 10.1109/ICIP.2008.4711773
   BLAKE R, 1981, PERCEPT PSYCHOPHYS, V30, P266, DOI 10.3758/BF03214282
   Boev A., 2008, CLASSIFICATION STERE
   BRADDICK OJ, 1979, PROC R SOC SER B-BIO, V204, P503, DOI 10.1098/rspb.1979.0043
   Domanski M, 2013, IEEE T IMAGE PROCESS, V22, P3517, DOI 10.1109/TIP.2013.2266580
   IJsselsteijn WA, 2000, IEEE T CIRC SYST VID, V10, P225, DOI 10.1109/76.825722
   ITU-T, 2008, ITU T P910 SUBJECTIV
   Kang MK, 2012, IEEE T MULTIMEDIA, V14, P121, DOI 10.1109/TMM.2011.2169238
   Kooi FL, 2004, DISPLAYS, V25, P99, DOI 10.1016/j.displa.2004.07.004
   Lee J, 2013, IEEE T BROADCAST, V59, P281, DOI 10.1109/TBC.2013.2256678
   ONO H, 1977, PERCEPT PSYCHOPHYS, V21, P513, DOI 10.3758/BF03198731
   Peinsipp-Byma E., 2009, P SOC PHOTO-OPT INS
   Sazzad ZMP, 2009, INT WORK QUAL MULTIM, P180, DOI 10.1109/QOMEX.2009.5246956
   Serrano-Pedraza I, 2009, J VIS, V9, P11
   Serrano-Pedraza I, 2009, J VISION, V9, DOI 10.1167/9.4.3
   Shao F, 2013, IEEE T MULTIMEDIA, V15, P1843, DOI 10.1109/TMM.2013.2269897
   Shao F, 2013, IEEE T IMAGE PROCESS, V22, P1940, DOI 10.1109/TIP.2013.2240003
   Shnayderman A, 2006, IEEE T IMAGE PROCESS, V15, P422, DOI 10.1109/TIP.2005.860605
   Steinman SB., 2000, Foundations of Binocular Vision
   Tam W. J., 2007, JVTW094
   Vetro A, 2011, IEEE T BROADCAST, V57, P384, DOI 10.1109/TBC.2010.2102950
   Wang X, 2009, P SOC PHOTO-OPT INS, V725501
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Yang J.-C., 2009, 3DTV Conference: The True Vision- Capture, Transmission and Display of 3D Video, P1
   Yasakethu SLP, 2009, IEEE T CONSUM ELECTR, V55, P864, DOI 10.1109/TCE.2009.5174467
   Yasakethu SLP, 2008, IEEE T CONSUM ELECTR, V54, P1969, DOI 10.1109/TCE.2008.4711260
   You JY, 2010, SIGNALS COMMUN TECHN, P51, DOI 10.1007/978-3-642-12802-8_3
   Zhang Y, 2010, INT CONF SIGN PROCES, P1044, DOI 10.1109/ICOSP.2010.5655900
   Zhang Y, 2010, J VIS COMMUN IMAGE R, V21, P498, DOI 10.1016/j.jvcir.2010.03.002
   Zinger S, 2012, 3D RES, V3, DOI 10.1007/3DRes.01(2012)4
NR 34
TC 6
Z9 7
U1 2
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 8197
EP 8218
DI 10.1007/s11042-014-2051-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200035
DA 2024-07-18
ER

PT J
AU Zhang, H
   Wang, RL
   Liu, WJ
   Rong, MT
AF Zhang, Hao
   Wang, Ruolin
   Liu, Wenjiang
   Rong, Mengtian
TI Fusion-based edge-sensitive interpolation method for deinterlacing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intra-field deinterlacing; Region classification; Edge preservation;
   Data fusion
ID ALGORITHM; DIRECTION
AB This paper proposes a fusion-based edge-sensitive interpolation method (FEID) for intra-field deinterlacing. The proposed FEID is composed of three steps: (1) region classification by a gradient-based region selection approach, (2) pre-interpolation by a 6-tap fixed coefficient Wiener filter, (3) data fusion by the linear minimum mean square-error estimation (LMMSE) technique. Specifically, three directional neighboring pixel sets are defined in three directions (45A degrees, 90A degrees, and 135A degrees) for every missing pixel. And each set produces an estimate of the pixel to be interpolated with a Wiener filter. With the information that gathered from the three directional neighboring pixel sets, a more robust estimate is obtained by fusing these directional estimates with the LMMSE technique. For fast implementation, we propose a gradient-based region selection approach that classifies a local region into two different classes, Region 1 and Region 2. The LMMSE-based data fusion method is used in Region 1; a fast deinterlacing algorithm is used in Region 2 to reduce the computational complexity. Compared with existing deinterlacing methods, the proposed method FEID improves the visual quality of the interpolated edges while maintaining a higher peak signal-to-noise-ratio (PSNR) level.
C1 [Zhang, Hao; Wang, Ruolin; Liu, Wenjiang; Rong, Mengtian] Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai 200030, Peoples R China.
C3 Shanghai Jiao Tong University
RP Zhang, H (corresponding author), Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai 200030, Peoples R China.
EM zhanghao0953@sjtu.edu.cn
RI zhu, yujie/KBC-4009-2024
FU National Science Foundation of China [61234001]
FX The authors would like to thank the reviewers for their insightful and
   constructive comments that help improve this paper. This work was
   supported by the National Science Foundation of China (61234001).
CR [Anonymous], DEINTERLACING KEY TE
   Chen PY, 2007, IEICE T INF SYST, VE90D, P606, DOI 10.1093/ietisy/e90-d.2.606
   Chen T, 2000, OPT ENG, V39, P2101, DOI 10.1117/1.1305262
   Chen X, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.10.107402
   Choi H, 2011, IEEE T CIRC SYST VID, V21, P844, DOI 10.1109/TCSVT.2011.2129190
   De Haan G, 1998, P IEEE, V86, P1839, DOI 10.1109/5.705528
   de Haan G, 2007, IEEE ICCE, P53
   EI-Khamy SE, 2005, DIGIT SIGNAL PROCESS, V15, P137, DOI 10.1016/j.dsp.2004.10.003
   El-Khamy SE, 2004, IEEE MEDITERR ELECT, P247, DOI 10.1109/MELCON.2004.1347057
   Fan YC, 2008, J DISP TECHNOL, V4, P218, DOI 10.1109/JDT.2007.909372
   Karmen E.W., 1999, Introduction to Optimal Estimation
   Kim W, 2007, IEEE T CONSUM ELECTR, V53, P1036, DOI 10.1109/TCE.2007.4341583
   Michaud F, 1997, IEEE T CIRC SYST VID, V7, P539, DOI 10.1109/76.585932
   Park MK, 2003, IEEE T CONSUM ELECTR, V49, P1508, DOI 10.1109/TCE.2003.1261260
   Park SJ, 2011, OPT ENG, V50, DOI 10.1117/1.3593162
   Park SJ, 2011, OPT ENG, V50, DOI 10.1117/1.3533027
   Park SJ, 2010, OPT ENG, V49, DOI 10.1117/1.3431711
   Poor H. Vincent, 1994, An introduction to signal detection and estimation
   Trocan M, 2012, MULTIMED TOOLS APPL, V61, P819, DOI 10.1007/s11042-011-0845-7
   Wang DM, 2005, IEEE T CIRC SYST VID, V15, P1019, DOI 10.1109/TCSVT.2005.852414
   Wang J, 2013, IEEE T CIRC SYST VID, V23, P912, DOI 10.1109/TCSVT.2013.2240914
   Wang J, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.1.017003
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yoo H, 2002, IEEE T CONSUM ELECTR, V48, P954, DOI 10.1109/TCE.2003.1196426
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhu Y, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P840, DOI 10.1109/ICIP.2001.958251
NR 26
TC 1
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7643
EP 7659
DI 10.1007/s11042-014-1997-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200011
DA 2024-07-18
ER

PT J
AU Chen, XY
   Sun, XM
   Sun, HY
   Xiang, LY
   Yang, B
AF Chen, Xianyi
   Sun, Xingming
   Sun, Huiyu
   Xiang, Lingyun
   Yang, Bin
TI Histogram shifting based reversible data hiding method using
   directed-prediction scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Directed-prediction scheme; Gradient-adjusted
   predictor (GAP); Asymmetric-histogram shifting; Prediction errors
ID DIFFERENCE EXPANSION; WATERMARKING; ERRORS
AB This paper aims at reducing the shifting distortion of histogram shifting reversible data hiding method. Instead of calculating symmetrically the prediction value as were done in other schemes, based on the gradient-adjusted predictor (GAP), a directed-prediction scheme, which includes two asymmetric predictors-the right and left GAPs, is designed to predict asymmetrically pixel value. Then two asymmetric error histograms, with right and left-skewness, are constructed by gathering the directed prediction errors, which effectively reduces the amount of pixels on the shifted side of the error histograms. Moreover, the optimal embedding points and thresholds are calculated by defining an evaluation index of the shifting distortion. Experimental results validate the effectiveness of the proposed method and demonstrate that it outperforms several previous methods in terms of payload and image quality.
C1 [Chen, Xianyi; Sun, Xingming; Xiang, Lingyun; Yang, Bin] Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
   [Sun, Xingming] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
   [Sun, Huiyu] Univ Bath, Dept Math Sci, Bath BA2 7AY, Avon, England.
C3 Hunan University; Nanjing University of Information Science &
   Technology; University of Bath
RP Sun, XM (corresponding author), Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
EM 0204622@163.com; sunnudt@163.com; huiyu.sun@yahoo.co.uk;
   suhong210@yahoo.com.cn; yewind2002@163.com
RI Sun, Xingming/AAD-1866-2019
FU National Natural Science Foundation of China [61232016, 61173141,
   61173142, 61173136, 61103215, 61373132, 61373133]; Priority Academic
   Program Development of Jiangsu Higher Education Institutions (PAPD
   fund);  [GYHY201206033];  [2013DFG12860];  [201301030];  [BC2013012]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61232016, 61173141, 61173142, 61173136, 61103215, 61373132
   and 61373133), GYHY201206033, 2013DFG12860, 201301030, BC2013012 and
   Priority Academic Program Development of Jiangsu Higher Education
   Institutions (PAPD fund).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Chen XY, 2013, J SYST SOFTWARE, V86, P2620, DOI 10.1016/j.jss.2013.04.086
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Fallahpour M, 2011, MULTIMED TOOLS APPL, V52, P513, DOI 10.1007/s11042-010-0486-2
   Fan W, 2012, MULTIMED TOOLS APPL, V57, P477, DOI 10.1007/s11042-010-0641-9
   Hong W, 2010, J SYST SOFTW, V22, P131
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
NR 20
TC 17
Z9 18
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5747
EP 5765
DI 10.1007/s11042-014-1881-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100018
DA 2024-07-18
ER

PT J
AU Jeong, HY
   Hong, BH
   Park, JH
AF Jeong, Hwa-Young
   Hong, Bong Hwa
   Park, Jong Hyuk
TI User tailored cloud-learning system using SNS and learning resources
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia based learning; Multimedia resource; U-learning system; User
   tailored learning
AB Computing technology has improved recently in various ways, and computing services are expected to be a promising medium for use of information and computing resources in our emerging ubiquitous network society and cloud computing environments. Learning system is necessary to make the learning process more efficient for users. Ubiquitous based learning (U-learning) is a state-of-the-art mechanism in the education area, applying many types of multimedia resources and network technology today. However, U-learning is not enough to provide information and learning course process to users about sharing the learning resources and collaborating between user and teacher. In this paper, we propose a learning system in cloud computing environment that allows sharing the learning multimedia resources with users and collaboration on discussion processes about learning contents using SNS. It also provides user oriented learning processes through each learning unit.
C1 [Jeong, Hwa-Young] Kyung Hee Univ, Humanitas Coll, Seoul, South Korea.
   [Hong, Bong Hwa] Kyung Hee Cyber Univ, Dept Digital & Media Engn, Seoul, South Korea.
   [Park, Jong Hyuk] Seoul Natl Univ Sci & Technol, Dept Comp Sci & Engn, Seoul, South Korea.
C3 Kyung Hee University; Seoul National University of Science & Technology
RP Hong, BH (corresponding author), Kyung Hee Cyber Univ, Dept Digital & Media Engn, Seoul, South Korea.
EM hyjeong@khu.ac.kr; bhhong@khcu.ac.kr; parkjonghyuk1@hotmail.com
OI Jeong, Hwa-Young/0000-0002-5017-934X
CR Chamorro-Premuzic T, 2007, LEARN INDIVID DIFFER, V17, P241, DOI 10.1016/j.lindif.2006.12.001
   Chao RJ, 2009, EXPERT SYST APPL, V36, P10657, DOI 10.1016/j.eswa.2009.02.047
   Chen GD, 2008, COMPUT EDUC, V50, P77, DOI 10.1016/j.compedu.2006.03.004
   Conole G., 1998, ALT J, V6, P4
   Huang YM, 2011, COMPUT EDUC, V57, P2291, DOI 10.1016/j.compedu.2011.05.023
   Jeong HY, 2013, MULTIMED TOOLS APPL, V64, P491, DOI 10.1007/s11042-012-1026-z
   Jia HY, 2011, EXPERT SYST APPL, V38, P3372, DOI 10.1016/j.eswa.2010.08.122
   Joseph Kee-Yin N, 2012, J CONVERG, V3, P15
   Kuyucu ADH, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2010.12.077
   Oommen BJ, 2012, J INF PROCESS SYST, V8, P191, DOI 10.3745/JIPS.2012.8.2.191
   Phobun P, 2010, PROCD SOC BEHV, V2, P4064, DOI 10.1016/j.sbspro.2010.03.641
   Saba T, 2012, HUM-CENT COMPUT INFO, V2, DOI 10.1186/2192-1962-2-6
   Schiaffino S, 2008, COMPUT EDUC, V51, P1744, DOI 10.1016/j.compedu.2008.05.008
   Traud AL, 2012, PHYSICA A, V391, P4165, DOI 10.1016/j.physa.2011.12.021
   Tsai PS, 2011, INTERNET HIGH EDUC, V14, P137, DOI 10.1016/j.iheduc.2011.01.004
   Villegas D, 2012, J COMPUT SYST SCI, V78, P1330, DOI 10.1016/j.jcss.2011.12.017
   Zhang LX, 2010, MATH COMPUT MODEL, V51, P1428, DOI 10.1016/j.mcm.2009.11.013
NR 17
TC 3
Z9 5
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 14
BP 5073
EP 5084
DI 10.1007/s11042-013-1717-0
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA CN1XU
UT WOS:000358214900006
DA 2024-07-18
ER

PT J
AU Tang, ZJ
   Zhang, XQ
   Lan, WW
AF Tang, Zhenjun
   Zhang, Xianquan
   Lan, Weiwei
TI Efficient image encryption with block shuffling and chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Image scrambling; Arnold transform; Block shuffling;
   Chaoticmap; Skew tent map
ID SCHEME
AB Image encryption is a useful technique for many applications, such as image content protection, image authentication, pay-TV and data hiding. In this paper, we propose an efficient image encryption algorithm with block shuffling and chaotic map. The proposed algorithm divides an input image into overlapping blocks, shuffles image blocks to make initial encryption, exploits a chaotic map and Arnold transform to generate secret matrices, and achieves final encryption by conducting exclusive OR operations between corresponding elements of each block and a random secret matrix. Many experiments are done to validate efficiency and advantages of the proposed algorithm.
C1 [Tang, Zhenjun; Zhang, Xianquan; Lan, Weiwei] Guangxi Normal Univ, Dept Comp Sci, Guilin 541004, Peoples R China.
   [Zhang, Xianquan] Guilin Univ Elect Technol, Guangxi Expt Ctr Informat Sci, Guilin 541004, Peoples R China.
   [Zhang, Xianquan] Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Guilin 541004, Peoples R China.
C3 Guangxi Normal University; Guilin University of Electronic Technology;
   Guilin University of Electronic Technology
RP Tang, ZJ (corresponding author), Guangxi Normal Univ, Dept Comp Sci, 15 Yucai Rd, Guilin 541004, Peoples R China.
EM tangzj230@163.com; zxq6622@163.com; 12729352@qq.com
FU Natural Science Foundation of China [61300109, 61363034]; Guangxi
   Natural Science Foundation [2012GXNSFBA053166, 2012GXNSFGA060004,
   2011GXNSFD018026]; Training Project for Excellent Middle-aged/Young
   Teachers in Guangxi Higher Education Institutions; Project of the
   Guangxi Experiment Center of Information Science [20130204]; Guangxi Key
   Laboratory of Trusted Software [kx201327]; Scientific and Technological
   Research Projects of Chongqing's Education Commission [KJ121310];
   Scientific and Technological Program of Fuling District of Chongqing
   [FLKJ,2012ABA1056]
FX This work was partially supported by the Natural Science Foundation of
   China (61300109, 61363034), the Guangxi Natural Science Foundation
   (2012GXNSFBA053166, 2012GXNSFGA060004, 2011GXNSFD018026), the Guangxi
   "Bagui" Teams for Innovation and Research, the Training Project for
   Excellent Middle-aged/Young Teachers in Guangxi Higher Education
   Institutions, the Project of the Guangxi Experiment Center of
   Information Science (20130204), the Guangxi Key Laboratory of Trusted
   Software (kx201327), the Scientific and Technological Research Projects
   of Chongqing's Education Commission (KJ121310), and the Scientific and
   Technological Program of Fuling District of Chongqing
   (FLKJ,2012ABA1056).
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Ginesu G, 2006, P INT C AC SPEECH SI, P313
   Hermassi H, 2014, MULTIMED TOOLS APPL, V72, P2211, DOI 10.1007/s11042-013-1533-6
   Monga V, 2006, IEEE T IMAGE PROCESS, V15, P3452, DOI 10.1109/TIP.2006.881948
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Patidar V, 2011, OPT COMMUN, V284, P4331, DOI 10.1016/j.optcom.2011.05.028
   Qi Dongxu, 1999, J NO POLYTECHNIC U, V11, P24
   Qin C, 2012, FUND INFORM, V120, P59, DOI 10.3233/FI-2012-749
   Shang ZW, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P2942, DOI 10.1109/ICYCS.2008.99
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Sun FY, 2010, OPT COMMUN, V283, P2066, DOI 10.1016/j.optcom.2010.01.028
   TANG Z, 2011, ICIC EXPRESS LETT B, V2, P1297
   Tang Z., 2012, INT J DIGITAL CONTEN, V3, P39, DOI DOI 10.4156/JDCTA.V0L6.ISSUE23.5
   Tang ZJ, 2013, IMAGING SCI J, V61, P241, DOI 10.1179/1743131X11Y.0000000039
   Tang Zhenjun., 2008, Journal of ubiquitous convergence technology, V2, P18, DOI DOI 10.1109/INF0P.2015.7489395
   Van de Ville D, 2004, IEEE T CIRC SYST VID, V14, P892, DOI 10.1109/TCSVT.2004.828325
   Venkatesan R, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P664, DOI 10.1109/ICIP.2000.899541
   Wang Q, 2012, OPT COMMUN, V285, P4317, DOI 10.1016/j.optcom.2012.07.033
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watanabe O, 2004, IEEE IMAGE PROC, P3435
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Xiang S, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P121
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhenjun Tang, 2011, Journal of Multimedia, V6, P202, DOI 10.4304/jmm.6.2.202-206
   Zhou YC, 2012, OPT COMMUN, V285, P594, DOI 10.1016/j.optcom.2011.11.044
   Zhu LH, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P601
NR 26
TC 72
Z9 74
U1 3
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5429
EP 5448
DI 10.1007/s11042-014-1861-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100003
DA 2024-07-18
ER

PT J
AU Zhang, R
   Wang, RD
AF Zhang, Rong
   Wang, Rang-Ding
TI In-camera JPEG compression detection for doubly compressed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image forensics; In-camera compression; Double JPEG compression
   detection; Quantization tables
AB An illicit photography work can be exposed by its unusual compression history. Our work aims at revealing the primary JPEG compression of a camera image especially when it has undergone an out-camera JPEG compression. The proposed method runs a recompression operator on a given image using a chosen software tool (MATLAB). We measure the JPEG error between the given image and the recompressed version in the Y, Cb and Cr color channels. The in-camera compression can be easily identified by drawing the JPEG error curves. In this paper a simple and high effective method is presented for automatically detecting the compression history of an image. For a doubly compressed image, the proposed method can give the historical compression sequence with the corresponding quality factors and determine whether the first compression is the in-camera compression. Experimental results, carried out on two datasets, show that the proposed method can yield satisfactory detection accuracy, over 96 % accuracy rate for in-camera compression and no false positives with a block size of 512 x 512. The proposed method has universality. It can be applied to multi-compression detection and is robust to different sources of out-camera compression, e.g. Adobe Photoshop. This makes it more practical compared to the previous methods of double compression.
C1 [Zhang, Rong; Wang, Rang-Ding] Ningbo Univ, Ningbo 315211, Zhejiang, Peoples R China.
C3 Ningbo University
RP Zhang, R (corresponding author), Ningbo Univ, 818 Fenghua Rd, Ningbo 315211, Zhejiang, Peoples R China.
EM zhangrong@nbu.edu.cn
FU National Natural Science Foundation of China [NSFC: 61170137, 61175026];
   Doctoral Fund of Ministry of Education of China [20103305 110002];
   Zhejiang Province Technology Innovation Team of China (New Generation of
   Mobile Internet Client Software) [2010R50009]; Open Research Fund of
   Zhejiang First-foremost Key Subject-Information and Communications
   Engineering of China [XKXL1316]; K.C. Wong Magna Fund in Ningbo
   University
FX This work was supported in part by the National Natural Science
   Foundation of China (NSFC: 61170137, 61175026), Doctoral Fund of
   Ministry of Education of China (20103305 110002), Zhejiang Province
   Technology Innovation Team of China (New Generation of Mobile Internet
   Client Software, 2010R50009), Open Research Fund of Zhejiang
   First-foremost Key Subject-Information and Communications Engineering of
   China(XKXL1316). Also, this work is sponsored by K.C. Wong Magna Fund in
   Ningbo University.
CR [Anonymous], P SPIE ELECT IMAGING
   [Anonymous], 2003, P DIG FOR RES WORKSH
   [Anonymous], DIGITAL WATERMARKING
   [Anonymous], IEEE T INF FORENSIC
   [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], GEN BENFORDS LAW JPE
   [Anonymous], 2011, P 13 INF HID C PRAG
   [Anonymous], 2000, Digital Watermarking
   Chen SYC, 2008, INT C PATTERN RECOGN, P1
   Fan ZG, 2003, IEEE T IMAGE PROCESS, V12, P230, DOI 10.1109/TIP.2002.807361
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Fridrich J, 2003, LECT NOTES COMPUT SC, V2578, P310
   Hamdy S, 2010, INT J ADV COMPUT SC, V1, P17
   Hamilton E., 2004, JPEG File Interchange Format
   He JF, 2006, LECT NOTES COMPUT SC, V3953, P423
   Huang FJ, 2010, IEEE T INF FOREN SEC, V5, P848, DOI 10.1109/TIFS.2010.2072921
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Kornblum JD, 2008, DIGIT INVEST, V5, pS21, DOI 10.1016/j.diin.2008.05.004
   Lin C., 2011, IEEE/ASME Transactions on Mechatronics, V99, P1
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P480, DOI 10.1109/TIFS.2010.2051426
   Ng T. T., 2004, IEEE INT C IM PROC I
   Popescu A.C., 2005, Information Hiding, volume 3200 of Lecture Notes in Computer Science, V3200, P395
   Robertson MA, 2005, IEEE T CIRC SYST VID, V15, P27, DOI 10.1109/TCSVT.2004.839995
   Sutthiwan P, 2011, LECT NOTES COMPUT SC, V6730, P1, DOI 10.1007/978-3-642-24556-5_1
   Wang JY, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P433
   Ye SM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P12
NR 27
TC 5
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5557
EP 5575
DI 10.1007/s11042-014-1868-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100009
DA 2024-07-18
ER

PT J
AU Hu, CL
   Gong, LY
   Wang, TJ
   Feng, Q
AF Hu, Chunlong
   Gong, Liyu
   Wang, Tianjiang
   Feng, Qi
TI Effective human age estimation using a two-stage approach based on Lie
   Algebrized Gaussians feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human age estimation; Manifold learning; Gaussian mixture models; Lie
   Algebrized Gaussians; Regression and classification
ID CLASSIFICATION
AB Automatically and effectively estimating human ages via facial images has lots of practical applications, such as security surveillance, electronic customer relationship management and entertainment. Motivated by the fact that feature representation and recognition are two key problems in facial image based human age estimation, in this paper, we propose to employ a novel discriminative feature called Lie Algebrized Gaussians (LAG) for the representation of age images and design a two-stage approach for learning and predicting human ages. LAG is built on Gaussian Mixture Models (GMM) and is able to capture the aging manifold of the age image by preserving the Lie group manifold structure information embedded in the feature space. Given the LAG feature for each image, we estimate the human age using a two-stage approach in a coarse-to-fine fashion. In the first stage, an adaptive age group for each input image is obtained by selecting a number of neighboring age labels around the output of a global regressor. In the second stage, a local classifier is learned from the selected age classes to determine the final age of the input image. The effectiveness of our approach is evaluated on both FG-NET and MORPH benchmarks, extensive experimental results and comparisons with the state-of-the-art algorithms demonstrate the superiority of our approach for the human age estimation task.
C1 [Hu, Chunlong; Wang, Tianjiang; Feng, Qi] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Gong, Liyu] Eedoo Inc, Beijing 100085, Peoples R China.
C3 Huazhong University of Science & Technology
RP Feng, Q (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM fengqi@hust.edu.cn
FU National Natural Science Foundation of China [61073094, U1233119]
FX Thank the editors and the anonymous referees for their valuable
   comments. This work was supported by the National Natural Science
   Foundation of China under grant number 61073094 and U1233119.
CR [Anonymous], IEEE COMPUTER VISION
   [Anonymous], 2008, IEEE C COMP VIS PATT
   [Anonymous], P 7 INT C VIRT SYST
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2009, 2009 IEEE 3 INT C BI, DOI DOI 10.1109/BTAS.2009.5339053
   [Anonymous], IEEE INT C AUT FAC G
   [Anonymous], 2005, P 12 INT C NEUR INF
   [Anonymous], IEEE INT C PATT REC
   [Anonymous], 2006, P 14 ANN ACM INT C M
   Bishop Christopher M, 2006, PATTERN RECOGNITION, DOI DOI 10.1117/1.2819119
   Bo L, 2009, ANN C NEUR INF PROC
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   CHEN K, 2013, PROC CVPR IEEE, P2467, DOI [DOI 10.1109/CVPR.2013.319, 10.1109/CVPR.2013.319]
   Choi SE, 2011, PATTERN RECOGN, V44, P1262, DOI 10.1016/j.patcog.2010.12.005
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Gong L, 2013, ARXIV13040823
   Guo G, 2009, IEEE C COMP VIS ICCV
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   Hatch A, 2006, P ICSLP INT
   He X., 2003, ADV NEURAL INFORM PR, P153
   Kai-Yueh Chang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2129, DOI 10.1109/CVPR.2011.5995415
   Kanno T, 2001, IEICE T INF SYST, VE84D, P1094
   Kwon YH, 1999, COMPUT VIS IMAGE UND, V74, P1, DOI 10.1006/cviu.1997.0549
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Liyu Gong, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2366, DOI 10.1109/CVPRW.2009.5206506
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   Tao Qin, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P279, DOI 10.1145/1277741.1277791
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Weisberg S, 2014, APPL LINEAR REGRESSI
   Yan S, 2007, IEEE C COMP VIS ICCV
   Yang P, 2010, IEEE INT C PATT REC
   Zhou X, 2009, IEEE I CONF COMP VIS, P1971, DOI 10.1109/ICCV.2009.5459435
NR 37
TC 5
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 4139
EP 4159
DI 10.1007/s11042-013-1815-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800024
DA 2024-07-18
ER

PT J
AU Marzec, M
   Koprowski, R
   Wróbel, Z
   Kleszcz, A
   Wilczynski, S
AF Marzec, Mariusz
   Koprowski, Robert
   Wrobel, Zygmunt
   Kleszcz, Agnieszka
   Wilczynski, Slawomir
TI Automatic method for detection of characteristic areas in thermal face
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial features; Image analysis; Segmentation; Thermograms; Thermovision
ID HOUGH-TRANSFORM; RECOGNITION; EXTRACTION
AB The use of thermal images of a selected area of the head in screening systems, which perform fast and accurate analysis of the temperature distribution of individual areas, requires the use of profiled image analysis methods. There exist methods for automated face analysis which are used at airports or train stations and are designed to detect people with fever. However, they do not enable automatic separation of specific areas of the face. This paper presents an algorithm for image analysis which enables localization of characteristic areas of the face in thermograms. The algorithm is resistant to subjects' variability and also to changes in the position and orientation of the head. In addition, an attempt was made to eliminate the impact of background and interference caused by hair and hairline. The algorithm automatically adjusts its operation parameters to suit the prevailing room conditions. Compared to previous studies (Marzec et al., J Med Inform Tech 16:151-159, 2010), the set of thermal images was expanded by 34 images. As a result, the research material was a total of 125 patients' thermograms performed in the Department of Pediatrics and Child and Adolescent Neurology in Katowice, Poland. The images were taken interchangeably with several thermal cameras: AGEMA 590 PAL (sensitivity of 0.1 A degrees C), ThermaCam S65 (sensitivity of 0.08 A degrees C), A310 (sensitivity of 0.05 A degrees C), T335 (sensitivity of 0.05 A degrees C) with a 320 x 240 pixel optical resolution of detectors, maintaining the principles related to taking thermal images for medical thermography. In comparison to (Marzec et al., J Med Inform Tech 16:151-159, 2010), the approach presented there has been extended and modified. Based on the comparison with other methods presented in the literature, it was demonstrated that this method is more complex as it enables to determine the approximate areas of selected parts of the face including anthropometry. As a result of this comparison, better results were obtained in terms of localization accuracy of the center of the eye sockets and nostrils, giving an accuracy of 87 % for the eyes and 93 % for the nostrils.
C1 [Marzec, Mariusz; Koprowski, Robert; Wrobel, Zygmunt] Univ Silesia, Inst Comp Sci, Dept Comp Biomed Syst, PL-41200 Sosnowiec, Poland.
   [Kleszcz, Agnieszka] AGH Univ Sci & Technol, Fac Min Surveying & Environm Engn, PL-30059 Krakow, Poland.
   [Wilczynski, Slawomir] Med Univ Silesia, Sch Pharm, Dept Biophys, PL-41200 Sosnowiec, Poland.
C3 University of Silesia in Katowice; AGH University of Krakow; Medical
   University Silesia
RP Marzec, M (corresponding author), Univ Silesia, Inst Comp Sci, Dept Comp Biomed Syst, Ul Bedzinska 39, PL-41200 Sosnowiec, Poland.
EM mariusz.marzec@us.edu.pl
RI Marzec, Mariusz/AAU-2791-2020; Koprowski, Robert/H-3300-2013;
   Wilczynski, Slawomir/HNB-4625-2023
OI Marzec, Mariusz/0000-0002-6244-5588; Wrobel,
   Zygmunt/0000-0002-0636-1769; Wilczynski, Slawomir/0000-0002-6066-3127;
   Koprowski, Robert/0000-0001-7015-7984
FU European Union, Innovative Economy Programme, European Fund for Regional
   Development "Intelligent Information System for Global Monitoring,
   Detection and Threat Identification" [POIG 01.01.02-00-062/09-00]
FX This work was supported by the European Union, Innovative Economy
   Programme, European Fund for Regional Development "Intelligent
   Information System for Global Monitoring, Detection and Threat
   Identification", Project number: POIG 01.01.02-00-062/09-00.
CR [Anonymous], SPRINGER LECT NOTES
   [Anonymous], 2010, J MED INFORM TECHNOL
   Arandjelovic O., 2006, International Conference on Video and Signal Based Surveillance, page, P50
   Bauer J, 2006, INZYNIERIA BIOMEDYCZ, V12, P85
   Chan YH, 2004, I C COMP GRAPH IM VI, P153, DOI 10.1109/CGIV.2004.1323977
   Chen X, 2005, COMPUT VIS IMAGE UND, V99, P332, DOI 10.1016/j.cviu.2005.03.001
   Diakides NA, 2006, ADV MED INFRARED IMA
   Eveland CK, 2003, IMAGE VISION COMPUT, V21, P579, DOI 10.1016/S0262-8856(03)00056-8
   Filipe S, 2013, LNCS
   Guangda H, 2003, FEATURE POINTS EXTRA, P154
   Hanif M, 2007, P 9 INT C INF FUS FL, P1
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Heo J., 2003, FUSION VISUAL THERMA
   Hjelmås E, 2001, COMPUT VIS IMAGE UND, V83, P236, DOI 10.1006/cviu.2001.0921
   Hu HF, 2008, PATTERN RECOGN, V41, P2045, DOI 10.1016/j.patcog.2007.10.029
   Ji Z, 2009, INTEH, V2009, P215
   Kawaguchi T, 2005, ELECTRON COMM JPN 2, V88, P29, DOI 10.1002/ecjb.20178
   Kobel J, 2002, OPT APPL, V32, P653
   Kong SG, 2005, COMPUT VIS IMAGE UND, V97, P103, DOI 10.1016/j.cviu.2004.04.001
   Koprowski Robert, 2007, Machine Graphics & Vision, V16, P251
   Krotosky SJ, 2004, ITSC 2004: 7TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, PROCEEDINGS, P17, DOI 10.1109/ITSC.2004.1398865
   Liu QS, 2006, IEEE T NEURAL NETWOR, V17, P1081, DOI 10.1109/TNN.2006.875970
   Martinez Brais., 2010, 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops, CVPRW 2010, P48
   Mekyska J, 2010, IEEE 44 INT CARN C S
   NG EYK, 2010, 7 WSEAS INT C MATH B, P190
   Nguyen AV, 2010, EMERG INFECT DIS, V16, P1710, DOI 10.3201/eid1611.100703
   Nowakowski AZ, 2006, 8 INT C QIRT PAD
   Rajpathak T., 2009, PROC FLORIDA C RECEN, P1
   Ring EFJ, 2004, P ANN INT IEEE EMBS, V26, P1183
   Rizon M., 2005, American Journal of Applied Sciences, V2, P1606
   Socolinsky DA, 2004, PROC CVPR IEEE, P1012
   Szlavik Z., 2004, Proceedings IEEE International Workshop on Cellular Neural Networks and Their Applications (CNNA 2004), P190
   Toennies K, 2002, INT C PATT RECOG, P1053, DOI 10.1109/ICPR.2002.1048486
   Trujillo L., 2005, 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P14
   Wang JG, 2007, IEEE T INSTRUM MEAS, V56, P2057, DOI 10.1109/TIM.2007.904567
   Yacoob Y, 2005, IEEE I CONF COMP VIS, P741
   Yuan-Tsung Chen, 2002, Journal of Medical and Biological Engineering, V22, P97
   Zhu Z, 2007, P ANN INT IEEE EMBS, P243, DOI 10.1109/IEMBS.2007.4352269
NR 38
TC 21
Z9 22
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 12
BP 4351
EP 4368
DI 10.1007/s11042-013-1745-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CK4CW
UT WOS:000356168600010
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Dooms, S
   De Pessemier, T
   Martens, L
AF Dooms, Simon
   De Pessemier, Toon
   Martens, Luc
TI Offline optimization for user-specific hybrid recommender systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender systems; Hybrid; Algorithms; RMSE; Optimization
AB Massive availability of multimedia content has given rise to numerous recommendation algorithms that tackle the associated information overload problem. Because of their growing popularity, selecting the best one is becoming an overload problem in itself. Hybrid algorithms, combining multiple individual algorithms, offer a solution, but often require manual configuration and power only a few individual recommendation algorithms. In this work, we regard the problem of configuring hybrid recommenders as an optimization problem that can be trained in an offline context. Focusing on the switching and weighted hybridization techniques, we compare and evaluate the resulting performance boosts for hybrid configurations of up to 10 individual algorithms. Results showed significant improvement and robustness for the weighted hybridization strategy which seems promising for future self-adapting, user-specific hybrid recommender systems.
C1 [Dooms, Simon; De Pessemier, Toon; Martens, Luc] iMinds Ghent Univ, Wica, B-9050 Ghent, Belgium.
C3 IMEC; Ghent University
RP Dooms, S (corresponding author), iMinds Ghent Univ, Wica, G Crommenlaan 8 Box 201, B-9050 Ghent, Belgium.
EM simon.dooms@intec.ugent.be; toon.depessemier@intec.ugent.be;
   luc.martens@intec.ugent.be
FU Ghent University; Hercules Foundation; Flemish Government - Department
   EWI
FX The described research activities were funded by a PhD grant to Simon
   Dooms of the Agency for Innovation by Science and Technology (IWT
   Vlaanderen). This work was carried out using the Stevin Supercomputer
   Infrastructure at Ghent University, funded by Ghent University, the
   Hercules Foundation and the Flemish Government - Department EWI.
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Adomavicius G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P217, DOI 10.1007/978-0-387-85820-3_7
   Aksel F., 2010, INT WORKSHOP HANDLIN, P49
   [Anonymous], 2009, ARXIV09110460
   Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124
   Bao Xinlong., 2009, Proceedings of the 3rd ACM Conference on Recommender Systems, P109
   Bellogin A., 2011, Proceedings of the fifth ACM conference on Recommender systems, P371, DOI DOI 10.1145/2043932.2044009
   Bellogin Alejandro, 2012, THESIS U AUTONOMA MA
   Bobadilla J, 2010, KNOWL-BASED SYST, V23, P520, DOI 10.1016/j.knosys.2010.03.009
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   Dooms S., 2011, P WORKSHOP HUMAN DEC, P67
   Ekstrand Michael, 2012, P 6 ACM C RECOMMENDE, P233, DOI [DOI 10.1145/2365952.2366002, 10.1145/2365952.2366002]
   Ekstrand Michael D, 2011, P 5 ACM C REC SYST, P133, DOI DOI 10.1145/2043932.2043958
   Gantner Z., 2011, P 5 ACM C REC SYST
   Han Eui-Hong., 2005, CIKM 05, P446
   Hussein T, 2012, USER MODEL USER-ADAP, P1
   Kille B., 2012, P ACM RECSYS 2012 WO, P30
   Knijnenburg BP, 2012, USER MODEL USER-ADAP, V22, P441, DOI 10.1007/s11257-011-9118-4
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Koren Yehuda., 2009, Net ix prize documen-tation, V81, P1
   Lemire D, 2005, SIAM PROC S, P471
   Lommatzsch A., 2013, P 10 C OP RES AR INF, P217
   McNee SM, 2006, CHI 06 HUM FACT COMP, P1097, DOI DOI 10.1145/1125451.1125659
   Pazzani MJ, 1999, ARTIF INTELL REV, V13, P393, DOI 10.1023/A:1006544522159
   Peralta V., 2007, Extraction and Integration of Movielens and Imdb Data
   Piotte Matrin., 2009, The Pragmatic Theory solution to the Netflix Grand Prize
   Pu Pearl, 2011, P 5 ACM C RECOMMENDE, P157, DOI 10.1145/2043932.2043962
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Salehi M, 2013, EGYPT INFORM J
   Song Y, 2011, ACM T WEB, V5, DOI 10.1145/1921591.1921595
   Toscher A., 2009, Netflix Prize Documentation
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
NR 32
TC 6
Z9 6
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 9
BP 3053
EP 3076
DI 10.1007/s11042-013-1768-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CF7NI
UT WOS:000352742800010
OA Green Published
DA 2024-07-18
ER

PT J
AU Park, SSH
   Song, JJ
   Lee, JJH
   Lee, W
   Ree, S
AF Park, Simon Soon-Hyoung
   Song, Justin JongSu
   Lee, James Jung-Hoon
   Lee, Wookey
   Ree, Sangbok
TI How to measure similarity for multiple categorical data sets?
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Similarity; Categorical data; Distance measure; Multiple categories
ID K-MEANS; ALGORITHM; DISTANCE
AB How to measure similarity or distance for multiple categorical data? It is an important step for Data Mining and Knowledge Management process to measure similarity or distance between objects appropriately. Measurements for continuous data have been well-defined and relatively easy to be calculated. However, the notion of similarity for categorical data is not simple, since categorical data usually is not simply translated into the numerical format, and they also have their own priority with structures and data distribution. In this paper, we propose a new measure for multiple categorical data sets using data distribution. Our new measure, MCSM (Multiple Categorical Similarity Measure), can solve conventional drawbacks of multiple categorical data sets successfully in which we prove the verification of our measure with mathematical proofs and experimentation. The experimental result shows that our measure is powerful for multiple categorical data sets with proper data distributions.
C1 [Park, Simon Soon-Hyoung; Song, Justin JongSu; Lee, James Jung-Hoon; Lee, Wookey] Inha Univ, Dept Ind Engn, Inchon, South Korea.
   [Ree, Sangbok] Seokyeong Univ, Dept Ind Engn, Seoul, South Korea.
C3 Inha University; Seokyeong University
RP Lee, W (corresponding author), Inha Univ, Dept Ind Engn, Inchon, South Korea.
EM fgm0626@inha.edu; Jaegal83@inha.edu; bigjameslee@inha.ac.kr;
   trinity@inha.ac.kr; sbree@skuniv.ac.kr
FU Inha University; Seokyeong University; National Research Foundation of
   Korea(NRF) - Korean Government(MOE) [NRF-2013R1A1A2012887]
FX This work was supported by Inha University, Seokyeong University and the
   National Research Foundation of Korea(NRF) Grant funded by the Korean
   Government(MOE) (NRF-2013R1A1A2012887)
CR Ahmad A, 2007, PATTERN RECOGN LETT, V28, P110, DOI 10.1016/j.patrec.2006.06.006
   [Anonymous], 2010, MULTIMED TOOLS APPL, DOI DOI 10.1007/s11042-009-0339-z
   [Anonymous], 1988, Machine Learning Proceedings 1988
   [Anonymous], 1999, P 5 ACM SIGKDD INT C, DOI [10.1145/312129.312201, DOI 10.1145/312129.312201]
   Arora NR, 2013, NEW GENERAT COMPUT, V31, P115, DOI 10.1007/s00354-013-0203-6
   *ASS COMP MACH, 1998 ACM COMP CLASS
   Atrey PK, 2012, MULTIMED TOOLS APPL, V60, P69, DOI 10.1007/s11042-011-0798-x
   Bhaduri K., 2011, Proceedings of the 17th ACM SIGKDD international conference on Knowledge Discovery and Data Mining, P859, DOI [DOI 10.1145/2020408.2020554, 10.1145/2020408.2020554]
   Boriah S., 2008, P 8 SIAM INT C DAT M, P243, DOI DOI 10.1137/1.9781611972788.22
   COX TF, 1993, PATTERN RECOGN, V26, P145, DOI 10.1016/0031-3203(93)90096-F
   Das G, 2000, LECT NOTES COMPUT<D>, V1910, P201
   Dzogang F, 2012, IEEE DATA MINING, P221, DOI 10.1109/ICDM.2012.126
   Gibson D, 2000, VLDB J, V8, P222, DOI 10.1007/s007780050005
   GOODALL DW, 1966, BIOMETRICS, V22, P882, DOI 10.2307/2528080
   Gou JP, 2012, COMPUT J, V55, P1058, DOI 10.1093/comjnl/bxr131
   Guha S, 2000, INFORM SYST, V25, P345, DOI 10.1016/S0306-4379(00)00022-3
   Hashem T, 2013, INFORM SYST, V38, P430, DOI 10.1016/j.is.2012.07.001
   Huang Y-P, 2012, J CONVERG, V3, P1
   Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641
   Huang ZX, 1999, IEEE T FUZZY SYST, V7, P446, DOI 10.1109/91.784206
   Hwang SW, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P441, DOI 10.1145/1244002.1244103
   JONES WP, 1987, J AM SOC INFORM SCI, V38, P420, DOI 10.1002/(SICI)1097-4571(198711)38:6<420::AID-ASI3>3.0.CO;2-S
   Kaufman L., 2009, FINDING GROUPS DATA
   Kuo HC, 2012, J CONVERG, V3, P9
   Le SQ, 2005, PATTERN RECOGN LETT
   Lee W, 2012, COMPUT IND ENG, V62, P732, DOI 10.1016/j.cie.2011.11.013
   Lee W, 2011, LECT NOTES COMPUT SC, V6612, P181, DOI 10.1007/978-3-642-20291-9_19
   Lee W, 2011, IEEE T IND ELECTRON, V58, P2154, DOI 10.1109/TIE.2010.2050292
   Li Wen-Syan., 2001, WWW, P230
   Lin D., 1998, Proceedings of ICML, P296
   Mekouar L, 2012, MULTIMED TOOLS APPL, V60, P277, DOI 10.1007/s11042-010-0612-1
   Nagpal G, 2012, J INF PROCESS SYST, V8, P621, DOI 10.3745/JIPS.2012.8.4.621
   Noreault Terry., 1981, Proceedings of the 3rd annual ACMconference on Research and development in information retrieval, SIGIR '80, P57
   Orair GH, 2010, PROC VLDB ENDOW, V3, P1469, DOI 10.14778/1920841.1921021
   Palmer CR, 2003, LECT NOTES ARTIF INT, V2637, P486
   PAPPIS CP, 1993, FUZZY SET SYST, V56, P171, DOI 10.1016/0165-0114(93)90141-4
   Perkiö J, 2012, MULTIMED TOOLS APPL, V57, P5, DOI 10.1007/s11042-010-0562-7
   Santos PS, 2013, INFORM SYST, V38, P690, DOI 10.1016/j.is.2012.09.004
   Spanakis G, 2012, COMPUT J, V55, P299, DOI 10.1093/comjnl/bxr024
   Stull R. B., 1988, INTRO BOUNDARY LAYER, DOI DOI 10.1007/978-94-009-3027-8
   Torra V, 2012, INFORM SCIENCES, V190, P56, DOI 10.1016/j.ins.2011.12.005
   WANG XZ, 1995, FUZZY SET SYST, V73, P259, DOI 10.1016/0165-0114(94)00308-T
   Wong WK, 2009, ACM SIGMOD/PODS 2009 CONFERENCE, P139
   WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P133
   Yang Y., 2002, P 8 ACM SIGKDD INT C, P682, DOI DOI 10.1145/775047.775149
   Yu H., 2011, P ACM SIGMOD INT C M, P709
   Zhang ZJ, 2010, VLDB J, V19, P181, DOI 10.1007/s00778-009-0148-z
   Zwick R., 1987, International Journal of Approximate Reasoning, V1, P221, DOI 10.1016/0888-613X(87)90015-6
NR 48
TC 2
Z9 2
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 10
BP 3489
EP 3505
DI 10.1007/s11042-014-1914-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI1GY
UT WOS:000354493000017
DA 2024-07-18
ER

PT J
AU Zhang, ZZ
   Qi, QQ
   Kumar, N
   Chilamkurti, N
   Jeong, HY
AF Zhang, Zezhong
   Qi, Qingqing
   Kumar, Neeraj
   Chilamkurti, Naveen
   Jeong, Hwa-Young
TI A secure authentication scheme with anonymity for session initiation
   protocol using elliptic curve cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication scheme; Anonymity; Elliptic curve cryptography; Session
   initiation protocol
ID KEY AGREEMENT
AB As a signaling protocol for controlling communication on the internet, establishing, maintaining, and terminating the sessions, the Session Initiation Protocol (SIP) is widely used in the world of multimedia communication. To ensure communication security, many authentication schemes for the SIP have been proposed. However, those schemes cannot ensure user privacy since they cannot provide user anonymity. To overcome weaknesses in those authentication schemes with anonymity for SIP, we propose an authentication scheme with anonymity using elliptic curve cryptograph. By a sophisticated analysis of the security of the proposed protocol, we show that the proposed scheme not only overcomes weaknesses in previous schemes but also is very efficient. Therefore, it is suitable for applications with higher security requirements.
C1 [Zhang, Zezhong; Qi, Qingqing] North China Univ Water Conservancy & Elect Power, Zhengzhou, Peoples R China.
   [Kumar, Neeraj] Thapar Univ, Dept Comp Sci & Engn, Patiala 147004, Punjab, India.
   [Chilamkurti, Naveen] La Trobe Univ, Dept Comp Sci & Comp Engn, Melbourne, Vic, Australia.
   [Jeong, Hwa-Young] Kyung Hee Univ, Humanitas Coll, Seoul, South Korea.
C3 North China University of Water Resources & Electric Power; Thapar
   Institute of Engineering & Technology; La Trobe University; Kyung Hee
   University
RP Chilamkurti, N (corresponding author), La Trobe Univ, Dept Comp Sci & Comp Engn, Melbourne, Vic, Australia.
EM zezhongzhang@126.com; nehra04@yahoo.co.in; n.chilamkurti@latrobe.edu.au;
   hyjeong@khu.ac.kr
RI Chilamkurti, Naveen/S-9636-2019; Kumar, Neeraj/J-4123-2017; Kumar,
   Neeraj/L-3500-2016
OI Chilamkurti, Naveen/0000-0002-5396-8897; Kumar,
   Neeraj/0000-0002-3020-3947; Jeong, Hwa-Young/0000-0002-5017-934X
FU National Natural Science Foundation of China [51190093, 51309098,
   200926]
FX The authors thank the editors and the anonymous reviewers for their
   valuable comments. This research was supported by National Natural
   Science Foundation of China (Nos. 51190093, 51309098, 200926).
CR [Anonymous], 2009, INT J NETW SECUR
   [Anonymous], RFC2617 IETF
   Arshad R, 2013, MULTIMED TOOLS APPL, V66, P165, DOI 10.1007/s11042-011-0787-0
   Chen TH, 2010, COMM COM INF SC, V119, P46
   Durlanik A, 2005, PROC WRLD ACAD SCI E, V8, P350
   Farash MS, 2013, INF TECHNOL CONTROL, V42, P333, DOI 10.5755/j01.itc.42.4.2496
   He DB, 2012, SECUR COMMUN NETW, V5, P1423, DOI 10.1002/sec.506
   He DB, 2012, J MED SYST, V36, P1989, DOI 10.1007/s10916-011-9658-5
   He DB, 2012, INFORM FUSION, V13, P223, DOI 10.1016/j.inffus.2011.01.001
   Heasuk Jo, 2009, Proceedings of the 2009 Fifth International Joint Conference on INC, IMS and IDC, P618, DOI 10.1109/NCM.2009.251
   Huang HF, 2006, 9 JOINT C INF SCI
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   Liu F, 2011, LECT NOTES COMPUT SC, V7025, P134, DOI 10.1007/978-3-642-24712-5_11
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   Tang H, 2013, MULTIMED TOOLS APPL, V65, P165
   Xie Q, 2012, INT J COMMUN SYST, V25, P47, DOI 10.1002/dac.1286
   Yang CC, 2005, COMPUT SECUR, V24, P381, DOI 10.1016/j.cose.2004.10.007
   Yoon EJ, 2010, IETE TECH REV, V27, P203, DOI 10.4103/0256-4602.62780
   Yoon EJ, 2009, 2009 INTERNATIONAL CONFERENCE ON NEW TRENDS IN INFORMATION AND SERVICE SCIENCE (NISS 2009), VOLS 1 AND 2, P642, DOI 10.1109/NISS.2009.137
   Yoon EJ, 2009, CISIS: 2009 INTERNATIONAL CONFERENCE ON COMPLEX, INTELLIGENT AND SOFTWARE INTENSIVE SYSTEMS, VOLS 1 AND 2, P549, DOI 10.1109/CISIS.2009.93
NR 20
TC 50
Z9 54
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 10
BP 3477
EP 3488
DI 10.1007/s11042-014-1885-6
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI1GY
UT WOS:000354493000016
DA 2024-07-18
ER

PT J
AU Kim, MU
   Yoon, K
AF Kim, Min-Uk
   Yoon, Kyoungro
TI Performance evaluation of large-scale object recognition system using
   bag-of-visual words model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object recognition; Bag-of-visual words; Sift; Vocabulary tree; CDVS;
   Standard
ID IMAGE RETRIEVAL
AB Object recognition technology is usually used for recognizing specific objects, such as book covers, landmarks, vehicles, etc. This technology is supported by multi-dimensional local image descriptors in most situations. These descriptors are designed to be robust to the environmental changes, such as illumination change, view angle change, scale change, etc. If there are many target objects in your database, object recognition using large scale local image descriptor database may not be a trivial task, because of the high dimensionality of the local image descriptors. For consistent responses from a large-scale database with a reasonable time delay, we need to have a proper data structure which supports the indexing and querying functionality. A vocabulary tree is a data structure based on local image descriptors, and this data structure is commonly used to cope with massive databases containing local image descriptors. By using a vocabulary tree, a local image descriptor can be mapped to a vocabulary tree's leaf node ID, constructing a visual word for object recognition. Visual words are then effectively exploited by a traditional text retrieval engine. In this study, we built a large-scale object recognition system using a vocabulary tree that had leaf nodes of 1 million Scale-Invariant Feature Transform (SIFT) descriptors, which is the most promising local image descriptor in terms of precision. We implement proposed system using publicly available software so that further enhancements and/or reproducibility would be easily accomplished. We then compared and evaluated the proposed system's performance with the current MPEG CDVS (Compact Descriptors for Visual Search) standard using a database containing two dimensional planar object datasets of three categories with one million distracter images. In addition to these datasets, which are equivalent to those of CDVS, we add a new dataset which are made to mimic realistic occlusion and clutter effects. Experimental results show that our proposed system's performance is comparable to that of the CDVS achieving 90 % precision at 5 s retrieval time. We also find characteristics of vocabulary tree limiting adaptation to a specific application domain.
C1 [Kim, Min-Uk; Yoon, Kyoungro] Konkuk Univ, Sch Comp Sci & Engn, Seoul 143701, South Korea.
C3 Konkuk University
RP Yoon, K (corresponding author), Konkuk Univ, Sch Comp Sci & Engn, Seoul 143701, South Korea.
EM minuk@konkuk.ac.kr; yoonk@konkuk.ac.kr
RI Yoon, Kyoungro/E-1043-2011
OI Yoon, Kyoungro/0000-0002-1153-4038
FU Basic Science Research Program of the National Research Foundation of
   Korea (NRF) - Ministry of Science, ICT & Future Planning [2012006817]
FX This research was supported by the Basic Science Research Program of the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Science, ICT & Future Planning (Grant no. 2012006817).
CR [Anonymous], 15938 ISOIEC
   [Anonymous], 2011, P IEEE INT C MULT EX
   [Anonymous], 2007, MIR
   [Anonymous], 2010, N11531 ISOIEC JTC1 S
   [Anonymous], 15938 ISOIEC 13
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Crow FC, 1984, ACM SIGGRAPH COMPUTE
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Francini G, 2013, SIGNAL PROCESS-IMAGE, V28, P311, DOI 10.1016/j.image.2012.11.002
   Fraundorfer F, 2008, VISUAL WORD BASED LO
   Heinly J, 2012, LECT NOTES COMPUT SC, V7573, P759, DOI 10.1007/978-3-642-33709-3_54
   Huiskes MJ, 2010, NEW TRENDS IDEAS VIS, P527
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Newman MEJ, 2005, CONTEMP PHYS, V46, P323, DOI 10.1080/00107510500052444
   Nister David, 2006, CVPR
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Tian Q, 2011, MULTIMED TOOLS APPL, V51, P441, DOI 10.1007/s11042-010-0636-6
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   Tsai SS, 2010, IEEE IMAGE PROC, P1029, DOI 10.1109/ICIP.2010.5648942
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Vedaldi A., 2010, VLFeat: An open and portable library of computer vision algorithms, P1469
   Zhengs Q-F, 2006, EFFECTIVE EFFICIENT, P77
NR 28
TC 7
Z9 8
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 7
BP 2499
EP 2517
DI 10.1007/s11042-014-2152-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE0TU
UT WOS:000351520200020
DA 2024-07-18
ER

PT J
AU Jung, KH
   Yoo, KY
AF Jung, Ki-Hyun
   Yoo, Kee-Young
TI High-capacity index based data hiding method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Steganography; Watermarking; Pixel-value differencing;
   Four-pixel differencing
ID STEGANOGRAPHIC METHOD; IMAGES; SUBSTITUTION
AB In this paper, a high-capacity data hiding method based on the index function is presented. The cover image is divided into non-overlapping sub-blocks, and the basis pixel is calculated by the index function. Difference values with other pixel-pairs are referenced to decide the number of embedding secret bits with the range table. The experimental results demonstrate that the proposed method could embed 2.45 bpp on average without distortion to the human visual system. We showed that the embedding capacity of the proposed method is 214,227 bits, 213,879 bits, 9,445 bits, 12,240 bits, and 109,253 bits larger than previous works on average for 12 test images.
C1 [Jung, Ki-Hyun] Yeungjin Coll, Sch Comp Informat, Daegu 702721, South Korea.
   [Yoo, Kee-Young] Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu 702701, South Korea.
C3 Kyungpook National University
RP Yoo, KY (corresponding author), Kyungpook Natl Univ, Sch Comp Sci & Engn, 80 Daehak Ro, Daegu 702701, South Korea.
EM hyunny.jung@gmail.com; yook@knu.ac.kr
CR Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2002, INT J PATTERN RECOGN, V16, P399, DOI 10.1142/S0218001402001770
   Chang K.-C., 2007, Systems, Man and Cybernetics, P1165
   CHANG KC, 2007, INTELLIGENT INFORM H, P449
   Hsiao JY, 2009, SIGNAL PROCESS, V89, P556, DOI 10.1016/j.sigpro.2008.10.018
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Khodaei M, 2012, IET IMAGE PROCESS, V6, P677, DOI 10.1049/iet-ipr.2011.0059
   Lee YP, 2012, INFORM SCIENCES, V191, P214, DOI 10.1016/j.ins.2012.01.002
   Liao X, 2011, J VIS COMMUN IMAGE R, V22, P1, DOI 10.1016/j.jvcir.2010.08.007
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Wang CM, 2008, J SYST SOFTWARE, V81, P150, DOI 10.1016/j.jss.2007.01.049
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Wu NI, 2012, APPL SOFT COMPUT, V12, P942, DOI 10.1016/j.asoc.2011.09.002
   Yang C.H., 2006, P INT COMP S TAIP TA, P831
NR 16
TC 23
Z9 24
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 6
BP 2179
EP 2193
DI 10.1007/s11042-014-2081-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CD9CN
UT WOS:000351394500023
DA 2024-07-18
ER

PT J
AU Midya, A
   Sengupta, S
AF Midya, Abhishek
   Sengupta, Somnath
TI Switchable video error concealment using encoder driven scene transition
   detection and edge preserving SEC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene transition; Scene and illumination change index; Error
   concealment; Spatial error concealment; DEBSEC; H.264/AVC
ID SHOT-BOUNDARY DETECTION; QUALITY ASSESSMENT
AB Error concealment, a decoder based technique, attempts to reconstruct the corrupted regions of a video frame, using spatial and/or temporal correlation. For sequences with high temporal correlations, the performance of Temporal Error Concealment (TEC) techniques are better than Spatial Error Concealment (SEC) techniques in terms of PSNR of the reconstructed frames. However, the performance of TECs deteriorate drastically at the scene boundary due to low temporal correlation with the reference frame. In this paper, we propose a novel encoder controlled transition detection scheme which would facilitate selection of concealment strategy, that makes a choice between our newly proposed edge-direction based SEC technique and a TEC scheme. Exploiting Motion Vector (MV), Sum of Absolute Difference (SAD), and Motion Compensated Histogram Difference (MCHD), scene transition is detected at the encoder. A single bit transition status flag per frame is then sent to the decoder as a part of the header information to select the concealment policy between TEC and SEC. The present work also proposes a new edge-directed spatial error concealment, termed as "Directional Edge Based Spatial Error Concealment" (DEBSEC), which outperforms existing techniques in terms of PSNR and SSIM of the concealed frame.
C1 [Midya, Abhishek] Indian Inst Technol, Dept Elect & Elect Commun Engn, Comp Vis Lab, Kharagpur 721302, W Bengal, India.
   [Sengupta, Somnath] Indian Inst Technol, Dept Elect & Elect Commun Engn, Kharagpur 721302, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Kharagpur
RP Midya, A (corresponding author), Indian Inst Technol, Dept Elect & Elect Commun Engn, Comp Vis Lab, Kharagpur 721302, W Bengal, India.
EM abhishek.midya@gmail.com; ssg@ece.iitkgp.ernet.in
RI Midya, Abhishek/K-7603-2015
CR [Anonymous], 1995, P ACM MULT, DOI DOI 10.1145/217279.215266
   [Anonymous], 1991, P VDB
   Asheri H, 2012, IEEE T CONSUM ELECTR, V58, P880, DOI 10.1109/TCE.2012.6311331
   Bouthemy P, 1999, IEEE T CIRC SYST VID, V9, P1030, DOI 10.1109/76.795057
   Carnec M, 2003, P INT C IM PROC ICIP, V3
   Chen Y, 2008, IEEE T MULTIMEDIA, V10, P2, DOI 10.1109/TMM.2007.911223
   Chowdhury MU, 2007, 6TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE, PROCEEDINGS, P229, DOI 10.1109/ICIS.2007.99
   Chung MG, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P933, DOI 10.1109/ICIP.2000.899610
   DIMOU A, 2005, P 5 EURASIP C SPEECH
   Feng Jie, 2008, 2008 Pacific-Asia Workshop on Computational Intelligence and Industrial Application. PACIIA 2008, P712, DOI 10.1109/PACIIA.2008.246
   Gharavi H, 2008, P IEEE ICASSP C LAS
   Guimaraes SJF, 2003, PATTERN RECOGN LETT, V24, P947, DOI 10.1016/S0167-8655(02)00218-0
   Hanjalic A, 2002, IEEE T CIRC SYST VID, V12, P90, DOI 10.1109/76.988656
   Kang SJ, 2013, IEEE ICCE, P332, DOI 10.1109/ICCE.2013.6486916
   Kim W, 2006, IEEE T CONSUM ELECTR, V52, P1050, DOI 10.1109/TCE.2006.1706506
   Kumwilaisak W, 2011, J VIS COMMUN IMAGE R, V22, P164, DOI 10.1016/j.jvcir.2010.12.002
   Kung WY, 2006, IEEE T CIRC SYST VID, V16, P789, DOI 10.1109/TCSVT.2006.877391
   Li YN, 2009, IET IMAGE PROCESS, V3, P121, DOI 10.1049/iet-ipr.2007.0193
   Lo CC, 2001, 10TH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P920, DOI 10.1109/FUZZ.2001.1009106
   Ma MY, 2010, IEEE T CIRC SYST VID, V20, P382, DOI 10.1109/TCSVT.2009.2035839
   Midya A, 2011, P IEEE PACRIM 11 VIC
   Ngo CW, 2001, IEEE T CIRC SYST VID, V11, P941, DOI 10.1109/76.937435
   Pei SC, 2004, IEEE T MULTIMEDIA, V6, P158, DOI 10.1109/TMM.2003.819749
   Pei SC, 1999, IEEE T MULTIMEDIA, V1, P321, DOI 10.1109/6046.807952
   Pyun JY, 2008, IEEE T CONSUM ELECTR, V54, P1705, DOI 10.1109/TCE.2008.4711224
   Qaratlu MM, 2011, SIGNAL PROCESS-IMAGE, V26, P304, DOI 10.1016/j.image.2011.04.004
   Tan YP, 2003, ELECTRON LETT, V39, P1313, DOI 10.1049/el:20030859
   Taniguchi Y, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P427
   Tonomura Y., 1990, Journal of Visual Languages and Computing, V1, P183, DOI 10.1016/S1045-926X(05)80015-1
   Valente S, 2001, IEEE T CONSUM ELECTR, V47, P568, DOI 10.1109/30.964147
   WANG Y, 1993, IEEE T COMMUN, V41, P1544, DOI 10.1109/26.237889
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wang YK, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P729
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yan B, 2010, IEEE T IMAGE PROCESS, V19, P98, DOI 10.1109/TIP.2009.2032311
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
   Yoo HW, 2006, MULTIMED TOOLS APPL, V28, P283, DOI 10.1007/s11042-006-7715-8
   Zeng WJ, 1999, IEEE T CIRC SYST VID, V9, P648, DOI 10.1109/76.767129
   Zhao Y, 2011, IEEE T CIRC SYST VID, V21, P1890, DOI 10.1109/TCSVT.2011.2157189
   Zhu L, 2010, IEEE SOUTHEASTCON, P151, DOI 10.1109/SECON.2010.5453813
NR 41
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 6
BP 2033
EP 2054
DI 10.1007/s11042-013-1739-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CD9CN
UT WOS:000351394500016
DA 2024-07-18
ER

PT J
AU Shen, HQ
   Yan, Y
   Xu, SC
   Ballas, N
   Chen, WZ
AF Shen, Haoquan
   Yan, Yan
   Xu, Shicheng
   Ballas, Nicolas
   Chen, Wenzhi
TI Evaluation of semi-supervised learning method on action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semi-supervised learning; Multi-feature fusion; Second order pooling;
   Video concept annotation; Action recognition
ID MULTIMEDIA; RETRIEVAL
AB Action recognition is one of the most difficult problems in computer vision and multimedia areas, since both spatial information and spatiotemporal semantic meaning should be taken into consideration. Moreover, the noisy and weakly annotated information make this task even harder. Nowadays, instead of the traditional features and classifiers, a lot of new attempts have made the task of action recognition promising. Noticing that there is no work on comparison of different combination of pooling and semi-supervised learning method under the same experiment setting, it would be interesting to apply different combination of pooling and semi-supervised learning method on both the synthetic and realistic action recognition datasets to see which combination or method performs better. In summary, we can obtain the following conclusions based on our experiments. Firstly, Second Order Pooling (Carreira et al. 2012) is worse than the traditional Bag of Words (Schmid and Mohr 1997; Dance et al. 2004) regarding to the overall performance in some dataset, but is a good way to speed up the coding stage of video classification with little sacrifice of performance. Secondly, Semi-supervised Hierarchical Regression Algorithm (MLHR) and Manifold Regularized Least Square Regression (MRLS) (Belkin et al. J Mach Learn Res 12:2399-2434, 2006) is better than some of the supervised learning methods (chi(2)-SVM, SVM-2K ( Farquhar et al. 2006)) in the real world action recognition problems which shares little available annotated information. Thirdly, for KTH, UCF50 and HMDB dataset, late fusion doesn't necessarily improve the performance. In comparison, MLHR, SVM-2K and Multi-kernel Learning is a more natural way to deal with multi-feature problems.
C1 [Shen, Haoquan; Xu, Shicheng; Chen, Wenzhi] Zhejiang Univ, Dept Comp Sci, Zhejiang, Peoples R China.
   [Yan, Yan] Univ Trento, Dept Informat Engn & Comp Sci, Trento, Italy.
   [Ballas, Nicolas] CEA, Paris, France.
   [Ballas, Nicolas] Mines ParisTech, Paris, France.
C3 Zhejiang University; University of Trento; CEA; Universite PSL; MINES
   ParisTech
RP Shen, HQ (corresponding author), Zhejiang Univ, Dept Comp Sci, Zhejiang, Peoples R China.
EM shq422@zju.edu.cn; yan@disi.unitn.it; lightxuzju@gmail.com;
   ballas.n@gmail.com; chenwz@cs.zju.edu.cn
RI 陳, 文誌/AAI-6255-2021
CR [Anonymous], ACM MM
   [Anonymous], 2012, ECCV
   [Anonymous], 2009, MOSIFT RECOGNIZING H
   [Anonymous], 2004, ICPR
   [Anonymous], 2006, Advances in Neural Information Processing Systems (NIPS)
   [Anonymous], ICCV
   [Anonymous], MVAP
   [Anonymous], 2011, ICCV
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Dance C., 2004, ECCV SLCV WORKSH
   Han Y., 2013, AAAI
   Han YH, 2014, IEEE T MULTIMEDIA, V16, P1115, DOI 10.1109/TMM.2014.2306092
   Han YH, 2013, SIGNAL PROCESS, V93, P2169, DOI 10.1016/j.sigpro.2012.05.036
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Lan Z, 2012, ACM MM
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1662, DOI 10.1109/TMM.2012.2199293
   SCHMID C, 1997, TPAMI
   Snoek C. G. M., 2005, ACM MM
   Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531
   Vinokourov A, 2002, INFERRING SEMANTIC R
   Wang H., 2011, CVPR
   YAN R, 2006, P 29 ANN INT ACM SIG, P324
   Yan Y., 2013, ACM MM
   Yang Y., 2009, ACM MM
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P321
   Yang Y, 2008, IEEE T MULTIMEDIA, V10, P437, DOI 10.1109/TMM.2008.917359
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P572, DOI 10.1109/TMM.2012.2234731
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Zhan Y, 2014, MULTIMED TOOLS APPL
   Zhou DY, 2004, ADV NEUR IN, V16, P321
NR 31
TC 9
Z9 9
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 2
BP 523
EP 542
DI 10.1007/s11042-014-1936-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ8DP
UT WOS:000348445300012
DA 2024-07-18
ER

PT J
AU Yeo, SS
   Chen, K
   Liu, HH
AF Yeo, Sang-Soo
   Chen, Ken
   Liu, Honghai
TI Pattern recognition technologies for multimedia information processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
AB Advanced algorithms based on pattern recognition for segmentation, recognition, and indexing of image, video, speech and audio data have been investigated and developed to analyze multimedia information, recently. Pattern recognition algorithms generally aim to provide a reasonable answer for all possible inputs and to perform most likely matching of the inputs, taking into account their statistical variation. Theses algorithms have been widely used in many applications to recognize what people understand such as objects, faces, human actions, and so on. Although there has been a great progress in fields of image and speech processing, virtual and augmented reality, human-computer interaction, and so on, we still have the difficulties of implementing general models that are robust to real-world variations. In this special issue, our goal is to consolidate the recent research achievements that include diverse pattern recognition based information processing for multimedia applications.
C1 [Yeo, Sang-Soo] Mokwon Univ, Div Convergence Comp & Media Engn, Taejon, South Korea.
   [Chen, Ken] Tsinghua Univ, Inst Mfg Engn, Beijing 100084, Peoples R China.
   [Liu, Honghai] Univ Portsmouth, Portsmouth, Hants, England.
   [Liu, Honghai] Univ Portsmouth, Intelligent Syst & Biomed Robot Grp, Portsmouth, Hants, England.
C3 Mokwon University; Tsinghua University; University of Portsmouth;
   University of Portsmouth
RP Yeo, SS (corresponding author), Mokwon Univ, Div Convergence Comp & Media Engn, Taejon, South Korea.
EM sangsooyeo@gmail.com; kenchen@tsinghua.edu.cn; honghai.liu@port.ac.uk
RI Yeo, Sang-Soo/D-3216-2016; Yeo, Sang-Soo/AAD-6176-2020
OI Yeo, Sang-Soo/0000-0002-0224-0150; 
CR Choi JW, 2015, MULTIMED TOOLS APPL, V74, P199, DOI 10.1007/s11042-013-1756-6
   Jo A, 2015, MULTIMED TOOLS APPL, V74, P227, DOI 10.1007/s11042-013-1846-5
   Jun S, 2015, MULTIMED TOOLS APPL, V74, P287, DOI 10.1007/s11042-013-1761-9
   Kang D, 2015, MULTIMED TOOLS APPL, V74, P245, DOI 10.1007/s11042-013-1759-3
   Kang JH, 2015, MULTIMED TOOLS APPL, V74, P259, DOI 10.1007/s11042-013-1758-4
   Khil AR, 2015, MULTIMED TOOLS APPL, V74, P185, DOI 10.1007/s11042-013-1843-8
   Park S, 2015, MULTIMED TOOLS APPL, V74, P271, DOI 10.1007/s11042-013-1760-x
   Soh J, 2015, MULTIMED TOOLS APPL, V74, P211, DOI 10.1007/s11042-013-1757-5
   Yoo H, 2014, MULTIMED TO IN PRESS, V2014
NR 9
TC 2
Z9 2
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 1
BP 179
EP 183
DI 10.1007/s11042-014-2113-0
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ6UP
UT WOS:000348356300011
OA Bronze
DA 2024-07-18
ER

PT J
AU Cho, WS
   Lam, KM
AF Cho, Wai-Shing
   Lam, Kin-Man
TI Image classification without segmentation using a hybrid pyramid kernel
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Un-segmented image classification; Bag-of-features; Spatial-pyramid
   match; Feature-space pyramid representation; Hybrid kernel; Relevance
   feedback; Point-of-Interest
AB Image classification usually requires complicated segmentation to separate foreground objects from the background scene. However, the statistical content of a background scene can actually provide very useful information for classification. In this paper, we propose a new hybrid pyramid kernel which incorporates local features extracted from both dense regular grids and interest points for image classification, without requiring segmentation. Features extracted from dense regular grids can better capture information about the background scene, while interest points detected at corners and edges can better capture information about the salient objects. In our algorithm, these two local features are combined in both the spatial and the feature-space domains, and are organized into pyramid representations. In order to obtain better classification accuracy, we fine-tune the parameters involved in the similarity measure, and we determine discriminative regions by means of relevance feedback. From the experimental results, we observe that our algorithm can achieve a 6.37 % increase in performance as compared to other pyramid-representation-based methods. To evaluate the applicability of the proposed hybrid kernel to large-scale databases, we have performed a cross-dataset experiment and investigated the effect of foreground/background features on each of the kernels. In particular, the proposed hybrid kernel has been proven to satisfy Mercer's condition and is efficient in measuring the similarity between image features. For instance, the computational complexity of the proposed hybrid kernel is proportional to the number of features.
C1 [Cho, Wai-Shing; Lam, Kin-Man] Hong Kong Polytech Univ, Dept Elect & Informat Engn, Ctr Signal Proc, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Lam, KM (corresponding author), Hong Kong Polytech Univ, Dept Elect & Informat Engn, Ctr Signal Proc, Kowloon, Hong Kong, Peoples R China.
EM enkmlam@polyu.edu.hk
CR [Anonymous], 2005, RR5737 INRIA
   [Anonymous], 2005, P ICCV
   [Anonymous], P ICCV
   [Anonymous], 2006, IEEE COMP SOC C COMP
   [Anonymous], 2005, P CVPR
   [Anonymous], 2006, CVPR
   [Anonymous], P IEEE COMP VIS PATT
   [Anonymous], NIPS
   [Anonymous], P ICCV
   Ardizzoni S., 1999, Proceedings. Tenth International Workshop on Database and Expert Systems Applications. DEXA 99, P167, DOI 10.1109/DEXA.1999.795161
   Bartolini I, 2010, KNOWL INF SYST, V25, P389, DOI 10.1007/s10115-009-0257-4
   Boughhorbel S, 2004, BRIT MACH VIS C SEPT
   Cho WS, 2013, ICSAI 2012, P2153
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Fergus R., 2003, P CVPR
   Flitton G., 2010, P BRIT MACH VIS C, P111
   GORKANI MM, 1994, INT C PATT RECOG, P459, DOI 10.1109/ICPR.1994.576325
   Kovashka A, 2013, P CVPR
   Lazebnik S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P649
   Li FX, 2010, PROC CVPR IEEE, P1712, DOI 10.1109/CVPR.2010.5539839
   Lin YQ, 2011, PROC CVPR IEEE, P1689, DOI 10.1109/CVPR.2011.5995477
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lowe DG, 2000, LECT NOTES COMPUT SC, V1811, P20
   Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800
   Niebles JC, 2007, P IEEE COMP VIS PATT
   Qu YY, 2014, MULTIMED TOOLS APPL, V70, P605, DOI 10.1007/s11042-012-1107-z
   Rubner Y, 2000, INT J COMPUTER VISIO, V40
   Shawe-Taylor J., 2004, KERNEL METHODS PATTE
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Squire D.M., 1999, Scandinavian Conference on Image Analysis, P143
   Szummer M, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P42, DOI 10.1109/CAIVD.1998.646032
   TONG S, 2001, P 9 ACM C MULT OTT C
   WALLRAVEN C, 2003, P IEEE INT C COMP VI
   Wang XY, 2014, MULTIMED TOOLS APPL, V68, P545, DOI 10.1007/s11042-012-1055-7
   Wolf L, 2004, J MACH LEARN RES, V4, P913, DOI 10.1162/1532443041827934
   Yu SX, 2004, IEEE T PATTERN ANAL, V26, P173, DOI 10.1109/TPAMI.2004.1262179
   [No title captured]
NR 39
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1195
EP 1224
DI 10.1007/s11042-013-1569-7
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200007
DA 2024-07-18
ER

PT J
AU Jiang, W
   Chen, YW
   Tian, X
AF Jiang, Wei
   Chen, Yaowu
   Tian, Xiang
TI Fast transcoding from H.264 to HEVC based on region feature analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; H.264; Transcoding; Region feature; Coding bits; Motion vector
ID VIDEO TRANSCODER; COMPLEXITY
AB The new video coding standard, High Efficiency Video Coding (HEVC), achieves much higher coding efficiency than the state-of-the-art H.264. Transcoding H.264 video to HEVC video is important to enable gradual migration to HEVC. Therefore, a fast H.264 to HEVC transcoding algorithm based on region feature analysis is proposed. First, each frame is segmented into three regions in units of coding tree unit (CTU) based on the correlation between image coding complexities and coding bits of the H.264 source stream. Then the searching depth range of each CTU is adaptively decided according to the region type. After that, motion vectors are de-noise filtered and clustered in order to analyze the region features of coding unit (CU). Based on the analysis results, the minimum searching depth of CU and partitions of prediction unit (PU) are optimally selected, and the motion vector predictor and search window size of motion estimation are also optimally decided for further reduction of the computational complexity. Experimental results show that the proposed algorithm achieves a significant improvement on transcoding speed, while maintaining high Rate-Distortion performance.
C1 [Jiang, Wei; Chen, Yaowu; Tian, Xiang] Zhejiang Univ, Inst Adv Digital Technol & Instrument, Hangzhou 310003, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Jiang, W (corresponding author), Zhejiang Univ, Inst Adv Digital Technol & Instrument, Hangzhou 310003, Zhejiang, Peoples R China.
EM jason_jiang@zju.edu.cn; cyw@mail.bme.zju.edu.cn;
   tianx@mail.bme.zju.edu.cn
FU National Natural Science Foundation [40927001]; Program for Zhejiang
   Leading Team of ST Innovation [2011R09021-02]; Fundamental Research
   Funds for the Central Universities, China
FX The authors would like to thank the journal reviewers for their valuable
   suggestions. This work was supported in part by National Natural Science
   Foundation (grant 40927001), Program for Zhejiang Leading Team of S&T
   Innovation (grant 2011R09021-02), and Fundamental Research Funds for the
   Central Universities, China.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2008, 35 VCEG M BERL GERM
   [Anonymous], 2012, ITUTSG16 WP3
   Bialkowski J, 2007, MULTIMED TOOLS APPL, V35, P127, DOI 10.1007/s11042-007-0126-7
   Bjork N, 1998, IEEE T CONSUM ELECTR, V44, P88, DOI 10.1109/30.663734
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Corrêa G, 2012, IEEE T CIRC SYST VID, V22, P1899, DOI 10.1109/TCSVT.2012.2223411
   Fernández-Escribano G, 2010, IEEE T CIRC SYST VID, V20, P763, DOI 10.1109/TCSVT.2010.2045914
   Fernández-Escribano G, 2008, IEEE T MULTIMEDIA, V10, P286, DOI 10.1109/TMM.2007.911838
   JCT-VC, 2012, JCTVCJ1100
   Kim I.-K., 2012, JCTVCJ1002
   Lee YK, 2007, MULTIMED TOOLS APPL, V35, P147, DOI 10.1007/s11042-007-0123-x
   Li B, 2012, JCTVCJ0236
   Martínez JL, 2009, IEEE T CONSUM ELECTR, V55, P1453, DOI 10.1109/TCE.2009.5278013
   Peixoto E, 2012, IEEE IMAGE PROC, P737, DOI 10.1109/ICIP.2012.6466965
   Shanableh T, 2013, IEEE T CIRC SYST VID, V23, P1191, DOI 10.1109/TCSVT.2013.2241352
   SHEN T, 2013, DAT COMPR C DCC 2013, P241, DOI DOI 10.1109/DCC.2013.32
   Su CJ, 2010, IET IMAGE PROCESS, V4, P494, DOI 10.1049/iet-ipr.2009.0427
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Vanne J, 2012, IEEE T CIRC SYST VID, V22, P1885, DOI 10.1109/TCSVT.2012.2223013
   Wang H., 2012, IEEE INT S BROADB MU, P1
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 22
TC 13
Z9 17
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 2179
EP 2200
DI 10.1007/s11042-013-1675-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200048
DA 2024-07-18
ER

PT J
AU Lin, JC
   Sun, Q
   Li, GL
   He, Y
AF Lin, Juncong
   Sun, Qian
   Li, Guilin
   He, Ying
TI SnapBlocks: a snapping interface for assembling toy blocks with XBOX
   Kinect
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Toy Blocks; Kinect; Snapping interface
AB Toy blocks can help the children develop various skills, such as spatial, mathematical, creative problem solving etc. In this paper, we developed a computer aided system for child to play blocks with a computer in a natural and intuitive way using the Kinect. We design a set of intuitive body gestures that allow the user to naturally control and navigate 3D toy blocks in a virtual environment. To conquer the imprecise interaction with Kinect, we propose a snapping interface, which automatically computes the optimal location and orientation of the to-be-assembled block. This interface can significantly reduce the user's burden for fine tuning the blocks at the desired locations, which is often tedious and time consuming. As a result, the user can fully immerse him/herself in the game and construct a complicated structure easily. The experimental results and positive feedback from users demonstrate the efficacy of our approach to virtual assembly of building blocks.
C1 [Lin, Juncong; Li, Guilin] Xiamen Univ, Software Sch, Xiamen, Peoples R China.
   [Sun, Qian; He, Ying] Nanyang Technol Univ, Sch Comp Engn, Nanyang, Singapore.
C3 Xiamen University; Nanyang Technological University
RP Lin, JC (corresponding author), Xiamen Univ, Software Sch, Xiamen, Peoples R China.
EM JuncongLin@gmail.com; SUNQ0004@ntu.edu.sg; glli@xmu.edu.cn;
   yhe@ntu.edu.sg
RI sun, qian/JMQ-8920-2023; He, Ying/A-3708-2011
OI He, Ying/0000-0002-6749-4485
FU National Natural Science Foundation of China [61202142, 61100032]; Joint
   Funds of the Ministry of Education of China and China Mobile
   [MCM20122081]; National Key Technology R&D Program Foundation of China
   [2013BAH44F00]; Open Project Program of the State Key Lab of CAD&CG
   Zhejiang University [A1205]; Fundamental Research Funds for the Central
   Universities [2010121072, 2013121030]; Singapore NRF Interactive Digital
   Media RD Program [NRF2008IDM-IDM004-006]; AcRF [69/07]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61202142, No. 61100032), Joint Funds of the Ministry of
   Education of China and China Mobile (No. MCM20122081), the National Key
   Technology R&D Program Foundation of China (No. 2013BAH44F00), the Open
   Project Program of the State Key Lab of CAD&CG Zhejiang University (No.
   A1205) and the Fundamental Research Funds for the Central Universities
   (No. 2010121072, No. 2013121030). AcRF 69/07, Singapore NRF Interactive
   Digital Media R&D Program under research grant NRF2008IDM-IDM004-006.
CR Chao-Hui Shen, 2012, ACM Transactions on Graphics, V31, DOI 10.1145/2366145.2366199
   Fisher D, 2011, ACM SIGCHI
   HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.1093/biomet/57.1.97
   Kim YM, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366157
   Kin K, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1343
   Li X-Y, 2011, ACM T GRAPHIC, V29
   Merrell P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964982
   Merrell P, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866203
   METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114
   Mitani J, 2004, ACM T GRAPHIC, V23, P259, DOI 10.1145/1015706.1015711
   Mitra NJ, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778795
   Mitra NJ, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618502
   Mori Y, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239496
   Nan LL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366156
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Preece J., 2002, INTERACTION DESIGN H
   Provenzo EF, 1984, COMPLETE BLOCK BOOK
   Shao TJ, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366155
   Shon YG, 2004, IEEE COMPUT GRAPH, V24, P40, DOI 10.1109/MCG.2004.49
   Tong J, 2012, IEEE T VIS COMPUT GR, V18, P643, DOI 10.1109/TVCG.2012.56
   Ware C., 1999, ACM Transactions on Computer-Human Interaction, V6, P162, DOI 10.1145/319091.319102
   Weise T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964972
   Weiss A, 2011, IEEE I CONF COMP VIS, P1951, DOI 10.1109/ICCV.2011.6126465
   Wilson A.D., 2010, ACM International Conference on Interactive Tabletops and Surfaces, P69, DOI DOI 10.1145/1936652.1936665
   Wright TP, 1936, J. Astronaut. Sci., V3, P122, DOI [10.2514/8.155, DOI 10.2514/8.155]
   Xin SQ, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964992
   Yu LF, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964981
NR 27
TC 5
Z9 5
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 2009
EP 2032
DI 10.1007/s11042-013-1690-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200041
DA 2024-07-18
ER

PT J
AU Sun, YF
   Jia, HJ
   Hu, YL
   Yin, BC
AF Sun, Yanfeng
   Jia, Huajie
   Hu, Yongli
   Yin, Baocai
TI Color face recognition based on color image correlation similarity
   discriminant model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color face representation; Color face recognition; Color component
   combination coefficient; Correlation; Similarity discriminant analysis
AB The focus of face recognition is a classifying problem based on similarity measurement. This paper presents a color image correlation similarity discriminant (CICSD) model after defining within-class correlation and between-class correlation for color face recognition. The CICSD model unifies the color face image representation and recognition into one framework. Thus classifying performance while representing a color face image can be considered. Therefore, the present model involves in two sets of variables: the color component combination coefficients for color face image presentation and the projection basis vectors for color face recognition. An iterative CICSD algorithm is designed to find the optimal color component combination coefficients and the optimal projection basis vectors. Experimental results on the FERET and AR color face database show the effectiveness of the present model and algorithm.
C1 [Sun, Yanfeng; Jia, Huajie; Hu, Yongli; Yin, Baocai] Beijing Univ Technol, Coll Comp Sci & Technol, Beijing Municipal Key Lab Multimedia & Intelligen, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Sun, YF (corresponding author), Beijing Univ Technol, Coll Comp Sci & Technol, Beijing Municipal Key Lab Multimedia & Intelligen, Beijing 100124, Peoples R China.
EM yfsun@bjut.edu.cn
OI Hu, Yongli/0000-0003-0440-438X
FU National Natural Science Foundation of China [61133003, 61171169];
   Beijing Natural Science Foundation [4132013, kz201310005006]
FX This work has been granted by the National Natural Science Foundation of
   China (No. 61133003, 61171169) and Beijing Natural Science
   Foundation(No. 4132013, kz201310005006).
CR Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Diplaros A, 2006, IEEE T IMAGE PROCESS, V15, P1, DOI 10.1109/TIP.2005.860320
   Gevers T, 2004, IEEE T PATTERN ANAL, V26, P113, DOI 10.1109/TPAMI.2004.1261083
   HAM JH, 2003, P ICML 2003 WORKSH C, P34
   Jin LL, 2007, PR IEEE COMP DESIGN, P114
   Jones CF, 2004, EURASIP J APPL SIG P, V2004, P522, DOI 10.1155/S1110865704401073
   Lang Fang-Nian, 2008, Acta Automatica Sinica, V34, P121, DOI 10.3724/SP.J.1004.2008.00121
   Li X, 2008, INT C PATT RECOG, P18
   Liu ZM, 2010, IEEE T IMAGE PROCESS, V19, P2502, DOI 10.1109/TIP.2010.2048963
   Martinez A., 1998, AR FACE DATABASE
   Phillips PJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P15
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Saul LK, 2004, J MACH LEARN RES, V4, P119, DOI 10.1162/153244304322972667
   Seung HS, 2000, SCIENCE, V290, P2268, DOI 10.1126/science.290.5500.2268
   Sun YF, 2011, PATTERN RECOGN LETT, V32, P597, DOI 10.1016/j.patrec.2010.11.004
   Torres L., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P627, DOI 10.1109/ICIP.1999.817191
   Wang SJ, 2012, IEEE T NEUR NET LEAR, V23, P876, DOI 10.1109/TNNLS.2012.2191620
   Wang SJ, 2011, IEEE T IMAGE PROCESS, V20, P2490, DOI 10.1109/TIP.2011.2121084
   Xie CY, 2005, PROC SPIE, V5681, P486, DOI 10.1117/12.585986
   Yang J, 2008, IEEE T NEURAL NETWOR, V19, P2088, DOI 10.1109/TNN.2008.2003187
   Yip AW, 2002, PERCEPTION, V31, P995, DOI 10.1068/p3376
   Zhang TP, 2009, FEATURE EXTRACTION M
NR 23
TC 7
Z9 8
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 2063
EP 2079
DI 10.1007/s11042-013-1638-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200043
DA 2024-07-18
ER

PT J
AU Zhang, YS
   Xiao, D
   Wen, WY
   Li, M
AF Zhang, Yushu
   Xiao, Di
   Wen, Wenying
   Li, Ming
TI Cryptanalyzing a novel image cipher based on mixed transformed logistic
   maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptanalysis; Image encryption; Chosen plaintext attack; Chaos
ID ONLY MULTIMEDIA CIPHERS; QUANTITATIVE CRYPTANALYSIS; PLAINTEXT ATTACKS;
   STANDARD MAP; ENCRYPTION
AB Recently, a novel image cipher [Multimed Tools Appl (2012) 56: 315-330] was proposed based on mixed transformed logistic maps. The cipher includes three parts: initial permutation of all the pixels with six odd keys, nonlinear diffusion using the first chaotic keystream and xoring the second chaotic keystream with the resultant values, and Zig-Zag diffusion with the third chaotic keystream. It was claimed that the nonlinear diffusion using the first chaotic map, xoring with the second chaotic map and the Zig-Zag diffusion with the third chaotic map are done to improve the security against the known/ chosen plaintext attack. However, the cipher is insecure against chosen plaintext attack. In this paper, we analyze the security weakness of the cipher. As for different images, three chaotic keys keep unchanged so that three chaotic keystreams are also fixed. Our target is to reveal six odd integer keys and three chaotic keystreams equivalent to three chaotic keys. By applying chosen plaintext attack, we can reveal them through two different methods. Experimental results also verify our assertion.
C1 [Zhang, Yushu; Xiao, Di; Li, Ming] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
   [Wen, Wenying] Jiangxi Univ Finance & Econ, Sch Informat Technol, Nanchang 330013, Peoples R China.
C3 Chongqing University; Jiangxi University of Finance & Economics
RP Xiao, D (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
EM xiaodi_cqu@hotmail.com
RI Li, Ming/Q-6532-2016
OI Li, Ming/0000-0003-3385-8364
FU Natural Science Foundation Project of CQ CSTC [2011jjjq40001]
FX The work was funded by the Natural Science Foundation Project of CQ CSTC
   (Grant No. 2011jjjq40001).
CR Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Arroyo D, 2013, SIGNAL PROCESS, V93, P1358, DOI 10.1016/j.sigpro.2012.11.019
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Li CQ, 2011, SIGNAL PROCESS, V91, P949, DOI 10.1016/j.sigpro.2010.09.014
   Li SS, 2013, MULTIMED TOOLS APPL, V66, P573, DOI 10.1007/s11042-012-1281-z
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Sam IS, 2012, MULTIMED TOOLS APPL, V56, P315, DOI 10.1007/s11042-010-0652-6
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Xiao D, 2010, OPT COMMUN, V283, P3030, DOI 10.1016/j.optcom.2010.03.063
   Xiao D, 2009, CHAOS SOLITON FRACT, V40, P2191, DOI 10.1016/j.chaos.2007.10.009
   Zhang YS, 2013, SIGNAL PROCESS-IMAGE, V28, P292, DOI 10.1016/j.image.2012.12.009
   Zhang YS, 2013, NONLINEAR DYNAM, V72, P751, DOI 10.1007/s11071-013-0750-x
   Zhang YS, 2013, OPT LASER ENG, V51, P472, DOI 10.1016/j.optlaseng.2012.11.001
NR 14
TC 25
Z9 26
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1885
EP 1896
DI 10.1007/s11042-013-1684-5
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200035
DA 2024-07-18
ER

PT J
AU Bouchrika, T
   Zaied, M
   Jemai, O
   Ben Amar, C
AF Bouchrika, Tahani
   Zaied, Mourad
   Jemai, Olfa
   Ben Amar, Chokri
TI Neural solutions to interact with computers by hand gesture recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Hand detection; Hand tracking; Hand gestures
   recognition; Wavelet network classifier; Neural network classifier
ID FAST LEARNING ALGORITHM; WAVELET; TRACKING
AB This paper attempts to present a vision-based interface which interacts with computers by hand gesture recognition. This work aims at creating a natural and intuitive application employing both static and dynamic hand gestures. The proposed application can be summarized in three main steps: hands detection in a video, hands tracking and converting hand shapes or trajectories into computer commands. To accomplish this application, a classification phase is paramount whether at the part of hand detection, or at the phase of "commanding computers". For this reason, we have proposed to use a wavelet network classifier (WNC) learnt by fast wavelet transform (FWT). To emphasize the robustness of this classifier, we have used a neural network classifier (NNC) version in order to compare the two classifiers' performances aiming at proving the strength of our proposed one. Global rates given by experimental results show the effectiveness of our proposed approaches of hand detection, hand tracking and hand gesture recognition. The comparison of the two classifier's result helps to choose the best classifier, which can improve the performances of our application.
C1 [Bouchrika, Tahani; Zaied, Mourad; Jemai, Olfa; Ben Amar, Chokri] Univ Sfax, Natl Engn Sch Sfax ENIS, REGIM Res Grp Intelligent Machines, Sfax 3038, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Bouchrika, T (corresponding author), Univ Sfax, Natl Engn Sch Sfax ENIS, REGIM Res Grp Intelligent Machines, BP 1173, Sfax 3038, Tunisia.
EM tahani.bouchrika@gmail.com; mourad.zaied@ieee.org; olfa.jemai@ieee.org;
   chokri.benamar@ieee.org
RI Chokri, BEN AMAR/K-5237-2012
OI Jemai, Olfa/0009-0000-9037-4169
FU General Direction of Scientific Research (DGRST), Tunisia, under the
   ARUB program
FX The authors would like to acknowledge the financial support of this work
   by grants from General Direction of Scientific Research (DGRST),
   Tunisia, under the ARUB program.
CR [Anonymous], 2008, IPTA IMAGE PROCESSIN
   [Anonymous], 2013, 5 INT C WEB INF TECH
   [Anonymous], 2010 IEEE WORKSH C C
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Ben Gharat I, 2013, 5 INT C WEB INF TECH
   Bencheriet Ch., 2007, SETIT 2007 4 INT C S
   Bouchrika T., 2012, INT C COMM COMP CONT, P36
   Burrus C. S., 2015, Introduction to wavelets and wavelet transforms. A primer
   Chen FS, 2003, IMAGE VISION COMPUT, V21, P745, DOI 10.1016/S0262-8856(03)00070-2
   COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098
   Daubechies I., 1992, 10 LECT WAVELETS
   Ejbali R, 2010, INT J SPEECH TECHNOL, V13, P163, DOI 10.1007/s10772-010-9076-y
   EL ADEL A., 2011, 2011 INT C COMM COMP
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Feng ZQ, 2011, PATTERN RECOGN, V44, P1089, DOI 10.1016/j.patcog.2010.08.007
   Guedri Boulbaba, 2011, 2011 International Conference on High Performance Computing & Simulation, P369
   Han JW, 2009, PATTERN RECOGN LETT, V30, P623, DOI 10.1016/j.patrec.2008.12.010
   Holzinger A, 2010, COMPUT INFORM, V29, P601
   Jemai O, 2011, INT J PATTERN RECOGN, V25, P1297, DOI 10.1142/S0218001411009111
   Jemai O, 2011, INT J WAVELETS MULTI, V9, P111, DOI 10.1142/S0219691311003967
   Jemai Olfa, 2010, APPRENTISSAGE AUTOMA
   Kao C. Y, 2011, PROCEDIA ENG, V15, P3739
   Kelly D, 2010, PATTERN RECOGN LETT, V31, P1359, DOI 10.1016/j.patrec.2010.02.004
   Li H, 2011, PATTERN RECOGN, V44, P1614, DOI 10.1016/j.patcog.2010.12.014
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P277
   Ng CW, 2002, IMAGE VISION COMPUT, V20, P993, DOI 10.1016/S0262-8856(02)00113-0
   Oz C, 2011, ENG APPL ARTIF INTEL, V24, P1204, DOI 10.1016/j.engappai.2011.06.015
   Stephan J.J., 2010, International Journal of Advancements in Computing Technology, V2, P30
   Stergiopoulou E, 2009, ENG APPL ARTIF INTEL, V22, P1141, DOI 10.1016/j.engappai.2009.03.008
   Venkatesh YV, 2003, PATTERN RECOGN, V36, P2161, DOI 10.1016/S0031-3203(03)00013-X
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zaied M, 2008, TOOLS APPL IPTA 2008, P6
   Zaied M, 2011, INT J WAVELETS MULTI, V9, P923, DOI 10.1142/S0219691311004389
   ZHANG QG, 1992, IEEE T NEURAL NETWOR, V3, P889, DOI 10.1109/72.165591
   Zhao ZY, 2012, PROCEDIA ENGINEER, V29, P3065, DOI 10.1016/j.proeng.2012.01.441
NR 35
TC 31
Z9 33
U1 0
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2949
EP 2975
DI 10.1007/s11042-013-1557-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300037
DA 2024-07-18
ER

PT J
AU Eslami, Z
   Kazemnasabhaji, M
   Mirehi, N
AF Eslami, Ziba
   Kazemnasabhaji, Mohammad
   Mirehi, Narges
TI Proxy signatures and buyer-seller watermarking protocols for the
   protection of multimedia content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Buyer-seller watermarking; Buyer anonymity; Conspiracy; Digital rights;
   Proxy signature
ID SIGNIFICANT DIFFERENCE; EFFICIENT; SCHEME
AB Watermarking techniques are developed to deal with multimedia distribution, authentication and copyright protection. It is usually the seller who embeds a watermark in multimedia content to identify the buyer. The embedded watermark can then be used to trace the traitors identity if unauthorized copies are found. However, repudiation and framing issues might arise in this approach. To solve these problems, buyer-seller watermarking protocols have been proposed based on watermarking in the encrypted domain. Such watermarks combine encryption, digital watermarking, and fingerprinting to preserve digital rights of both the buyer and the seller. Unfortunately, most existing watermarking techniques do not provide convincing proofs to ensure that they achieve the claimed level of security and informal proofs abound in the literature. In this paper, we propose a buyer-seller watermarking protocol based on proxy signatures and homomorphic encryption. Formal proofs are provided to show that in the proposed protocol, watermarks are generated such that the seller is unable to fabricate piracy, but he can trace copyright violators. The protocol further protects anonymity of the buyer until he is adjudicated to be guilty. Moreover, we solve the conspiracy problem without imposing any unrealistic assumptions about thrust-worthiness of the parties involved.
C1 [Eslami, Ziba; Kazemnasabhaji, Mohammad; Mirehi, Narges] Shahid Beheshti Univ, Dept Comp Sci, GC, Tehran, Iran.
C3 Shahid Beheshti University
RP Eslami, Z (corresponding author), Shahid Beheshti Univ, Dept Comp Sci, GC, Tehran, Iran.
EM z_eslami@sbu.ac.ir
OI Eslami, Ziba/0000-0002-9818-3911
CR Benhocine A., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P9
   Boneh D, 1995, LECT NOTES COMPUT SC, V963, P452
   Chang CC, 2010, COMPUT SECUR, V29, P269, DOI 10.1016/j.cose.2009.08.008
   Choi JG, 2003, LECT NOTES COMPUT SC, V2846, P265
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Damgård I, 2001, LECT NOTES COMPUT SC, V1992, P119
   Deng M, 2008, IEEE C INT WEB APPL
   Fan CI, 2007, IEEE C MULT UB ENG
   Goi BM, 2004, LECT NOTES COMPUT SC, V3089, P369
   Haji Mohammad Kazem Nasab, 2011, 2011 8th International ISC Conference on Information Security and Cryptology, P73, DOI 10.1109/ISCISC.2011.6062333
   Hu XM, 2007, COMPUT STAND INTER, V29, P191, DOI 10.1016/j.csi.2006.03.005
   Huang XY, 2005, LECT NOTES COMPUT SC, V3823, P480
   Hwang MS, 2004, COMPUT STAND INTER, V26, P73, DOI 10.1016/S0920-5489(03)00075-8
   Ju HS, 2002, LECT NOTES COMPUT SC, V2587, P421
   Katzenbeisser S, 2008, IEEE T INF FOREN SEC, V3, P783, DOI 10.1109/TIFS.2008.2002939
   Kim S., 1997, Information and Communications Security. First International Conference, ICIS '97. Proceedings, P223, DOI 10.1007/BFb0028478
   LAI CC, 2011, J DIGIT SIGNAL PROCE, V21, P522
   Lee B, 2001, LECT NOTES COMPUT SC, V2119, P474
   Lei CL, 2004, IEEE T IMAGE PROCESS, V13, P1618, DOI 10.1109/TIP.2004.837553
   Lian SG, 2012, MULTIMED TOOLS APPL, V57, P49, DOI 10.1007/s11042-010-0521-3
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Loukhaoukha K., 2012, J INF HIDING MULTIME, V3, P135
   Mambo M, 1996, IEICE T FUND ELECTR, VE79A, P1338
   Meerwald P, 2009, IEEE T MULTIMEDIA, V11, P1037, DOI 10.1109/TMM.2009.2021793
   Memon N, 2001, IEEE T IMAGE PROCESS, V10, P643, DOI 10.1109/83.913598
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Poon HT, 2009, MULTIMED TOOLS APPL, V42, P161, DOI 10.1007/s11042-008-0232-1
   Raphael CWP, 2011, WIRELESS PERS COMMUN, V56, P73
   Rosenberg B, 2010, HDB FINANCIAL CRYPTO, P427
   Schaathun HG, 2008, MULTIMEDIA SYST, V13, P331, DOI 10.1007/s00530-007-0096-7
   Shao MH, 2007, LECT NOTES COMPUT SC, V4657, P44
   Stinson D. R., 2018, Cryptography Theory and Practice
   Subramanyam AV, 2012, IEEE T MULTIMEDIA, V14, P703, DOI 10.1109/TMM.2011.2181342
   Wang YR, 2011, EXPERT SYST APPL, V38, P8024, DOI 10.1016/j.eswa.2010.12.129
   Yu Y, 2009, COMPUT STAND INTER, V31, P348, DOI 10.1016/j.csi.2008.05.003
   Zhang J., 2006, IEE Proceedings-Information Security, V153, P15, DOI 10.1049/ip-ifs:20055069
NR 37
TC 5
Z9 5
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2723
EP 2740
DI 10.1007/s11042-013-1555-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300029
DA 2024-07-18
ER

PT J
AU Han, JW
   Xu, M
   Li, X
   Guo, L
   Liu, TM
AF Han, Junwei
   Xu, Ming
   Li, Xin
   Guo, Lei
   Liu, Tianming
TI Interactive object-based image retrieval and annotation on iPad
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object Retrieval and Annotation; iPad; Multi-Touch; Spatial Context;
   Visual Bag-of-Words
ID EFFICIENT VISUAL-SEARCH; WEB; FEATURES; VIDEO
AB Apple iPad is a portable tablet computer that offers users a generic platform for consumer media including games, books, and movies. Though iPad is gaining popularity very quickly, its application in content-based image retrieval and annotation is still in its infancy. This paper aims to develop an interactive system to efficiently retrieve and annotate image objects on iPad, which mainly consists of two components of the front-end GUI (graphical user interface) and the back-end retrieval model. In the first component, an iPad-based GUI is implemented, which can provide users with an efficient way to select query objects and facilitate annotations. In the second component, we propose an object-based image retrieval algorithm that combines a novel feature descriptor based on context-preserving bags-of-words (BoW) and a two-stage re-ranking technique to measure the similarity between the query image and each image in the database. The retrieval results are returned and visualized on the iPad-based GUI, and annotations offered by users can be propagated among them. The communication between the front-end GUI and the back-end module is through the use of wireless networks. Comprehensive experiments on several benchmark datasets demonstrated the effectiveness of the proposed framework.
C1 [Han, Junwei; Xu, Ming; Guo, Lei] Northwestern Polytech Univ, Sch Automat, Xian 710072, Peoples R China.
   [Li, Xin; Liu, Tianming] Univ Georgia, Dept Comp Sci, Athens, GA 30602 USA.
C3 Northwestern Polytechnical University; University System of Georgia;
   University of Georgia
RP Han, JW (corresponding author), Northwestern Polytech Univ, Sch Automat, Xian 710072, Peoples R China.
EM junweihan2010@gmail.com; tliu@cs.uga.edu
RI Liu, Tianming/AAA-4602-2022
FU National Science Foundation of China [61005018, 91120005]; Program for
   New Century Excellent Talents in University [NCET-10-0079]; 
   [NPU-FFR-JC20120237]
FX This work was supported by the National Science Foundation of China
   under Grant 61005018 and 91120005, NPU-FFR-JC20120237, and Program for
   New Century Excellent Talents in University under grant NCET-10-0079.
CR Abramson Y, 2005, IEEE C COMP VIS PATT
   [Anonymous], 2006, P IEEE C COMPUTER VI
   [Anonymous], 2014, CHIN J WOMEN CHILD H
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Cao Y, 2010, PROC CVPR IEEE, P3352, DOI 10.1109/CVPR.2010.5540021
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P2089, DOI 10.1109/TPAMI.2007.1126
   Chandrasekhar V, 2010, IEEE IMAGE PROC, P3885, DOI 10.1109/ICIP.2010.5649937
   Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Erol B., 2008, P 16 ACM INT C MULTI, P399
   Ferrari V, 2010, INT J COMPUT VISION, V87, P284, DOI 10.1007/s11263-009-0270-9
   Han DF, 2008, MULTIMED TOOLS APPL, V39, P169, DOI 10.1007/s11042-008-0203-6
   Han DF, 2009, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2009.5459380
   Han JG, 2011, IEEE MULTIMEDIA, V18, P72, DOI 10.1109/MMUL.2010.24
   Jamieson M, 2010, IEEE T PATTERN ANAL, V32, P148, DOI 10.1109/TPAMI.2008.283
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Leibe B, 2004, LECT NOTES COMPUT SC, V3175, P145
   Liu X, 2010, IEEE C COMP VIS PATT
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Opelt A, 2006, LECT NOTES COMPUT SC, V3952, P575
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Sadun Erica, 2009, IPHONE DEV COOKBOOK
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sivic J, 2006, LECT NOTES COMPUT SC, V4170, P127
   Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111
   Takacs G., 2008, MIR 08, P427, DOI DOI 10.1145/1460096.1460165
   TSAI S.S., 2011, Proceedings of the 19th ACM international conference on Multimedia, P1029
   von Ahn Luis., 2004, CHI, DOI DOI 10.1145/985692.985733
   Wagner D, 2008, INT SYM MIX AUGMENT, P125, DOI 10.1109/ISMAR.2008.4637338
   Wu Z, 2009, PROC CVPR IEEE, P25, DOI 10.1109/CVPRW.2009.5206566
   Yeh T, 2004, PROC CVPR IEEE, P76
   Zhang Shiliang., 2009, MM 09 P 17 ACM INT C, P75, DOI DOI 10.1145/1631272.1631285
NR 32
TC 8
Z9 9
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2275
EP 2297
DI 10.1007/s11042-013-1509-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300011
DA 2024-07-18
ER

PT J
AU Jiang, JJ
   Hu, RM
   Han, Z
   Lu, T
AF Jiang, Junjun
   Hu, Ruimin
   Han, Zhen
   Lu, Tao
TI Efficient single image super-resolution via graph-constrained least
   squares regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Graph embedding; Manifold learning; Local geometric
   structure
ID RECONSTRUCTION; LIMITS; SPARSE
AB We explore in this paper an efficient algorithmic solution to single image super-resolution (SR). We propose the gCLSR, namely graph-Constrained Least Squares Regression, to super-resolve a high-resolution (HR) image from a single low-resolution (LR) observation. The basic idea of gCLSR is to learn a projection matrix mapping the LR image patch to the HR image patch space while preserving the intrinsic geometric structure of the original HR image patch manifold. Even if gCLSR resembles other manifold learning-based SR methods in preserving the local geometric structure of HR and LR image patch manifolds, the innovation of gCLSR lies in that it preserves the intrinsic geometric structure of the original HR image patch manifold rather than the LR image patch manifold, which may be contaminated by image degeneration (e.g., blurring, down-sampling and noise). Upon acquiring the projection matrix, the target HR image can be simply super-resolved from a single LR image without the need of HR-LR training pairs, which favors resource-limited applications. Experiments on images from the public database show that gCLSR method can achieve competitive quality as state-of-the-art methods, while gCLSR is much more efficient in computation than some state-of-the-art methods.
C1 [Jiang, Junjun; Hu, Ruimin; Han, Zhen; Lu, Tao] Wuhan Univ, Sch Comp, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.
   [Hu, Ruimin] Wuhan Univ, Fac Informat, Wuhan 430072, Peoples R China.
C3 Wuhan University; Wuhan University
RP Hu, RM (corresponding author), Wuhan Univ, Fac Informat, Room 603,Acad Lab Bldg, Wuhan 430072, Peoples R China.
EM junjun0595@163.com; hurm1964@gmail.com; hanzhen@whu.edu.cn;
   lut@whu.edu.cn
RI Jiang, Junjun/L-7087-2019
OI Jiang, Junjun/0000-0002-5694-505X
FU major national science and technology [2010ZX03004-003-03,
   2010ZX03004-001-03]; National Basic Research Program of China (973
   Program) [2009CB320906]; National Natural Science Foundation of China
   [61231015, 61172173, 61003184, 61070080, 61170023]
FX The research was supported by the major national science and technology
   special projects (2010ZX03004-003-03, 2010ZX03004-001-03), the National
   Basic Research Program of China (973 Program) (2009CB320906), the
   National Natural Science Foundation of China (61231015, 61172173,
   61003184, 61070080, 61170023).
CR [Anonymous], NATURE
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], SOLVING LEAST SQUARE
   [Anonymous], AMS
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Belkin M., 2003, Problems of Learning on Manifolds
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Bevilacqua M, 2012, INT CONF ACOUST SPEE, P1289, DOI 10.1109/ICASSP.2012.6288125
   Chan TM, 2009, PATTERN RECOGN LETT, V30, P494, DOI 10.1016/j.patrec.2008.11.008
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chopra A, 2010, PATTERN RECOGN, V43, P2609, DOI 10.1016/j.patcog.2010.03.022
   Ding C, 2010, IEEE T PATTERN ANAL, V32, P45, DOI 10.1109/TPAMI.2008.277
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   FanW Yeung DY, 2007, IEEE INT C COMPUTER, P1
   Farsiu S, 2006, IEEE T IMAGE PROCESS, V15, P141, DOI 10.1109/TIP.2005.860336
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P469, DOI 10.1109/TIP.2011.2161482
   Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Robinson M. D., 2010, Super-Resolution Imaging, P384
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Tikhonov N., 1977, Solutions of Ill-Posed Problems
   Tsai R.Y., 1984, Proc. Inst Elect Eng, V1, P317
   van Ouwerkerk JD, 2006, IMAGE VISION COMPUT, V24, P1039, DOI 10.1016/j.imavis.2006.02.026
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhang KB, 2011, IEEE J-STSP, V5, P230, DOI 10.1109/JSTSP.2010.2048606
   Zibetti MVW, 2011, PATTERN RECOGN LETT, V32, P69, DOI 10.1016/j.patrec.2009.12.009
NR 30
TC 24
Z9 25
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2573
EP 2596
DI 10.1007/s11042-013-1567-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300022
DA 2024-07-18
ER

PT J
AU Yi, XW
   Zheng, G
   Li, MY
   Ma, HT
   Zheng, CW
AF Yi, Xiaowei
   Zheng, Gang
   Li, Mingyu
   Ma, Hengtai
   Zheng, Changwen
TI Efficient authentication of scalable media streams over wireless
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stream authentication; Digital signatures; End-to-end media quality;
   Rate-distortion optimization; Transcoding
AB Media authentication of wireless transmission is becoming an increasingly important issue. Authenticated media content is constantly required to be transcoded at intermediates to accommodate heterogeneous applications. In this paper, a general and efficient authentication approach is proposed for scalable lossy media streams. Firstly, a joint coding and stream authentication (JCSA) media transmission system is described in a heterogeneous wireless network. For the JCSA system, a novel structure-maintained packetization is designed to realize flexible transcoding. Secondly, to obtain the optimal end-to-end quality and minimize the authentication overhead, a quality-optimized stream authentication (QOSA) framework is proposed for authenticating media content. Finally, an implementation of the proposed QOSA optimization framework on the consultative committee for space data systems image data compression (CCSDS IDC) coder is presented by combining graph-based and error-correction coding based (ECC-based) approaches. Experimental results demonstrate that our scheme can achieve the desired goal that it provides high robustness against packet-loss at the cost of a very low overhead.
C1 [Yi, Xiaowei; Zheng, Gang; Li, Mingyu; Ma, Hengtai; Zheng, Changwen] Chinese Acad Sci, Inst Software, Natl Key Lab Integrated Informat Syst Technol, Beijing, Peoples R China.
   [Yi, Xiaowei; Li, Mingyu] Chinese Acad Sci, Grad Univ, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy
   of Sciences; University of Chinese Academy of Sciences, CAS
RP Yi, XW (corresponding author), Chinese Acad Sci, Inst Software, Natl Key Lab Integrated Informat Syst Technol, Beijing, Peoples R China.
EM xiaove2008@163.com; zhenggang@iscas.ac.cn; mingyu.li.cn@gmail.com;
   hengtai@iscas.ac.cn; changwen@iscas.ac.cn
RI zheng, gang/KMX-5568-2024; yi, xiao/JHT-3220-2023
CR [Anonymous], 2008, REC SPAC DAT SYST ST
   [Anonymous], 2003, NDSS
   [Anonymous], 2007, REP SPAC DAT SYST ST
   Chandrasekhar S, 2012, IEEE T DEPEND SECURE, V9, P699, DOI 10.1109/TDSC.2012.48
   Gennaro R, 1997, LECT NOTES COMPUT SC, V1294, P180
   Golle P., 2001, Proceedings of the 8th Annual Network and Distributed Systems Security Symposium (NDSS), P13
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   Hefeeda M, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1671954.1671960
   Hosseini M, 2007, IEEE COMMUN SURV TUT, V9, P58, DOI 10.1109/COMST.2007.4317616
   Jung Min Park, 2003, ACM Transactions on Information and Systems Security, V6, P258, DOI 10.1145/762476.762480
   Lian SG, 2012, MULTIMED TOOLS APPL, V57, P49, DOI 10.1007/s11042-010-0521-3
   Lian SG, 2010, TELECOMMUN SYST, V45, P21, DOI 10.1007/s11235-009-9233-2
   MERKLE RC, 1990, LECT NOTES COMPUT SC, V435, P218, DOI 10.1007/0-387-34805-0_21
   Palau CE, 2011, MULTIMED TOOLS APPL, V53, P591, DOI 10.1007/s11042-010-0516-0
   Perrig A, 2000, P IEEE S SECUR PRIV, P56, DOI 10.1109/SECPRI.2000.848446
   RABIN MO, 1989, J ACM, V36, P335, DOI 10.1145/62044.62050
   Seo D, 2011, MULTIMED TOOLS APPL, V51, P897, DOI 10.1007/s11042-009-0421-6
   Stardust.com, 2000, MCAST 2000 WHITE PAP
   Sun QB, 2008, P IEEE, V96, P97, DOI 10.1109/JPROC.2007.909926
   Wang HG, 2013, MULTIMED TOOLS APPL, V67, P119, DOI 10.1007/s11042-011-0928-5
   Wong CK, 1998, SIXTH INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P198, DOI 10.1109/ICNP.1998.723740
   Yeh PS, 2005, AEROSP CONF PROC, P4138
   Zhang ZS, 2007, IEEE T MULTIMEDIA, V9, P320, DOI 10.1109/TMM.2006.886281
   Zhang ZS, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P784
   Zhou L, 2011, IEEE J SEL AREA COMM, V29, P1358, DOI 10.1109/JSAC.2011.110803
NR 25
TC 2
Z9 3
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1913
EP 1935
DI 10.1007/s11042-012-1324-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000042
DA 2024-07-18
ER

PT J
AU Liu, ZH
   Wang, HX
AF Liu, Zheng Hui
   Wang, Hong Xia
TI Pseudo-zernike moments-based audio content authentication algorithm
   robust against feature-analysed substitution attack
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio content authentication; Pseudo-Zernike moments; Synchronization
   code; Tamper localization
ID WATERMARKING
AB Content-based audio content authentication algorithms provide a method to solve the veracity and integrity of audio content. On the basic of pseudo-Zernike moments, an audio content authentication algorithm robust against feature-analysed substitution attack is proposed, which is aimed at some insecure issues in the existing content-based audio content authentication schemes. Firstly, the audio signal is cut into non-overlapping frames and each frame is divided into two segments, and each segment is scrambled. Then, synchronization codes generated by pseudo random sequence and watermark bits generated by pseudo-Zernike moments are embedded in the first and second segment, respectively, which are completed by quantizing the modulus of pseudo-Zernike moments. The scrambled segments used to generate and extract watermark are unknown to attackers. So, it is difficult for attackers to get the watermark generated and extracted to perform feature-analysed substitution attack. The synchronization code and watermark embedding method proposed is inaudible and has excellent ability to tolerance against common signal processing operations. Compared with the existing audio watermark algorithms based on pseudo-Zernike moments, the algorithm increases the embedding capacity and improves the security of the watermarking system.
C1 [Liu, Zheng Hui; Wang, Hong Xia] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.
C3 Southwest Jiaotong University
RP Liu, ZH (corresponding author), Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.
EM zhenghui.liu@163.com; hxwang@swjtu.edu.cn
RI Wang, Hongxia/AAE-2135-2022
FU National Natural Science Foundation of China [61170226, 60970122];
   Fundamental Research Funds for the Central Universities [SWJTU11CX047,
   SWJTU12ZT02]; Young Innovative Research Team of Sichuan Province
   [2011JTD0007]
FX This paper is supported by the National Natural Science Foundation of
   China (grant Nos. 61170226, 60970122), the Fundamental Research Funds
   for the Central Universities (grant Nos. SWJTU11CX047, SWJTU12ZT02), and
   the Young Innovative Research Team of Sichuan Province (grant No.
   2011JTD0007).
CR Bhat KV, 2011, CIRC SYST SIGNAL PR, V30, P915, DOI 10.1007/s00034-010-9255-8
   CHEN N, 2008, IEEE INT C MULT EXP, P221
   Chen Z, 2010, IEEE T IMAGE PROCESS, V19, P205, DOI 10.1109/TIP.2009.2032890
   Jiang Wei-zhen, 2010, 2010 International Conference on Intelligent Computing and Integrated Systems (ICISS 2010), P83, DOI 10.1109/ICISS.2010.5655023
   Kim HS, 2003, IEEE T CIRC SYST VID, V13, P766, DOI 10.1109/TCSVT.2003.815955
   Lei BY, 2011, SIGNAL PROCESS, V91, P1973, DOI 10.1016/j.sigpro.2011.03.001
   Li J, 2010, IEEE INT C SIGN PROC, P644
   Li S, 2009, IEEE T SYST MAN CY A, V39, P227, DOI 10.1109/TSMCA.2008.2007988
   Ma ZY, 2010, LECT NOTES COMPUT SC, V6146, P149
   Revaud J, 2009, IEEE T PATTERN ANAL, V31, P627, DOI 10.1109/TPAMI.2008.115
   Wang HX, 2010, SCI CHINA INFORM SCI, V53, P619, DOI 10.1007/s11432-010-0058-0
   Wang XY, 2011, COMPUT ELECTR ENG, V37, P425, DOI 10.1016/j.compeleceng.2011.05.011
   Wang XY, 2009, IEEE MULTIMEDIA, V16, P60, DOI 10.1109/MMUL.2009.44
   Xiang SJ, 2006, LECT NOTES COMPUT SC, V4283, P226
NR 14
TC 7
Z9 8
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 2271
EP 2291
DI 10.1007/s11042-012-1235-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500040
DA 2024-07-18
ER

PT J
AU Fajardo, JO
   Taboada, I
   Liberal, F
AF Oscar Fajardo, Jose
   Taboada, Ianire
   Liberal, Fidel
TI QoE-driven and network-aware adaptation capabilities in mobile
   multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile multimedia; Quality of experience; Adaptation; Network
   degradation
ID QUALITY; VIDEO
AB This paper deals with the analysis of mobile multimedia services, with special focus on current media resolutions for mobile handsets. Since variable network conditions entail variable quality levels, nowadays several applications implement some kind of dynamic service adaptation in order to mitigate these effects. This paper analyzes the service performance from an end-to-end perspective, taking into account the several agents involved in the service provision. From a detailed study, the different possible sources of degradations are identified as well as their impact into the expected quality as perceived by end users. Based on the obtained results, the possible effects of different adaptation capabilities are discussed. The identification of the main source of degradations at the destination endpoint improves the adaptation capabilities and enhances the service performance in terms of perceived quality.
C1 [Oscar Fajardo, Jose; Taboada, Ianire; Liberal, Fidel] Univ Basque Country, Bilbao, Spain.
C3 University of Basque Country
RP Fajardo, JO (corresponding author), Univ Basque Country, Bilbao, Spain.
EM joseoscar.fajardo@ehu.es; ianire.taboada@ehu.es; fidel.liberal@ehu.es
RI Fajardo, Jose Oscar/L-2477-2013; Liberal, Fidel/B-2597-2010
OI Fajardo, Jose Oscar/0000-0003-1525-9114; Taboada,
   Ianire/0000-0002-2772-4143; Liberal, Fidel/0000-0002-9840-4294
FU European Community [214751/ /ICT-ADAMANTIUM/]
FX The research leading to these results has received funding from the
   European Community's Seventh Framework Programme FP7/2007-2013 under
   grant agreement num. 214751/ /ICT-ADAMANTIUM/.
CR [Anonymous], 2008, 25993 3GPP UTRA
   Barreto PS, 2008, LECT NOTES COMPUT SC, V5297, P31, DOI 10.1007/978-3-540-88623-5_4
   Barreto PS, 2008, 2008 22ND INTERNATIONAL WORKSHOPS ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOLS 1-3, P80, DOI 10.1109/WAINA.2008.187
   Boyaci O, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P213, DOI 10.1109/ISM.2009.45
   BRUNNSTROM K, 2008, FINAL REPORT VIDEO Q
   Cermak G, 2009, P 1 INT WORKSH QUAL
   Chua TK, 2006, IEEE NETWORK, V20, P14, DOI 10.1109/MNET.2006.273116
   De Simone F, 2009, INT WORK QUAL MULTIM, P204, DOI 10.1109/QOMEX.2009.5246952
   Fajardo J. O., 2009, P 6 INT C BROADB COM
   HANDS D, 2008, MULTIMEDIA GROUP TES
   Hillestad O. I., 2006, Journal of Zhejiang University (Science), V7, P19, DOI 10.1631/jzus.2006.AS0019
   HO HH, 2007, 3 INT WORKSH VID PRO
   Hohlfeld Oliver, 2009, PIK J, V32.1, P53
   Jumisko-Pyykko S., 2005, 13th Annual ACM International Conference on Multimedia, P535, DOI 10.1145/1101149.1101270
   Jumisko-Pyykko Satu., 2008, P 10 INT C HUMAN COM, P63, DOI DOI 10.1145/1409240.1409248
   Kamer W, 2007, ETRI J, V29, P569, DOI 10.4218/etrij.07.0107.0102
   Karner W, 2005, P 12 INT C TEL
   Khan A, 2010, P IEE ICC 2010
   Knoche H, 2009, ACM T MULTIM COMPUT, V5, DOI 10.1145/1556134.1556137
   Korhonen J, 2010, P 2 INT WORKSH QUAL
   Koumaras H, 2010, J VIS COMMUN IMAGE R, V21, P139, DOI 10.1016/j.jvcir.2009.07.005
   Liu T, 2009, P 1 INT WORKSH QUAL
   Raghuveera T., 2010, International Journal of Computer Science & Information Technology, V2, P51, DOI 10.5121/ijcsit.2010.2205
   Reljin I, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/75217
   Ries Michal, 2008, Journal of Communications, V3, P41, DOI 10.4304/jcm.3.1.41-50
   SHU T, 2005, INT WORKSH NETW OP S
   Staelens N., 2009, P 4 INT WORKSH VID P P 4 INT WORKSH VID P
   Undheim A, 2008, P 18 ITC SPEC SEM, P153
   Undheim A, 2009, P 21 ITC 2009
   Vukadinovic V, 2008, 2008 3RD INTERNATIONAL SYMPOSIUM ON WIRELESS PERVASIVE COMPUTING, VOLS 1-2, P468, DOI 10.1109/ISWPC.2008.4556252
   You JY, 2010, SIGNAL PROCESS-IMAGE, V25, P482, DOI 10.1016/j.image.2010.02.002
   [No title captured]
NR 32
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 1
BP 311
EP 332
DI 10.1007/s11042-011-0825-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI4AK
UT WOS:000336807300014
DA 2024-07-18
ER

PT J
AU Qian, XM
   Guo, DP
   Hou, XS
   Li, Z
   Wang, H
   Liu, GZ
   Wang, Z
AF Qian, Xueming
   Guo, Danping
   Hou, Xingsong
   Li, Zhi
   Wang, Huan
   Liu, Guizhong
   Wang, Zhe
TI HWVP: hierarchical wavelet packet descriptors and their applications in
   scene categorization and semantic concept retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene categorization; Wavelet packet; TRECVID; Concept retrieval; SVM
ID CLASSIFICATION
AB Wavelet packet transform is an effective texture analysis approach by sub-band filtering. Different texture patterns have distinctive responses to the sub-bands of wavelet packets. The responses are valuable for texture description. Utilizing all the responses of the sub-bands of different resolutions can improve texture pattern discrimination power. In this paper, effective texture descriptors based on hierarchical wavelet packet (HWVP) transform are proposed. The subtle sub-bands of wavelet packet transform improve the discrimination power of HWVP descriptors for the images in different categories. Scene categorization performances of the HWVP descriptors under various decomposition levels and wavelet bases are discussed. Performances of HWVP descriptors of global and local images with different partition patterns are also analyzed. The advantages of HWVP descriptors attribute to the following two aspects. Firstly sub-band filtering is helpful for improving the discrimination power of HWVP descriptors to capture the subtle differences of texture patterns. Secondly hierarchical feature representation makes the HWVP descriptors robust to resolution variations. Comparisons are made with some existing robust descriptors on scene categorization and semantic concept retrieval. Experimental results on the widely used OT, Scene-13, Sport Event, and TRECVID 2007 datasets show the effectiveness of the proposed HWVP descriptors.
C1 [Qian, Xueming; Guo, Danping; Hou, Xingsong; Li, Zhi; Wang, Huan; Liu, Guizhong; Wang, Zhe] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Qian, XM (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM qianxm@mail.xjtu.edu.cn; houxs@mail.xjtu.edu.cn
RI Qian, Xueming/E-9867-2015
FU National Natural Science Foundation of China (NSFC) [60903121,
   61173109]; Foundations of Microsoft Research Asia
FX This work is supported in part by the National Natural Science
   Foundation of China (NSFC) Project No. 60903121, No. 61173109, and
   Foundations of Microsoft Research Asia
CR [Anonymous], P ECCV
   [Anonymous], P ICCV
   [Anonymous], 2006, IEEE COMP SOC C COMP
   [Anonymous], 2004, Proceedings of the 12th ACM International Conference on Multimedia, DOI DOI 10.1145/1027527.1027747
   [Anonymous], P CVPR
   [Anonymous], 2008, P CVPR
   [Anonymous], P ICCV
   [Anonymous], 2007, P CIVR
   [Anonymous], 2005, P CVPR
   [Anonymous], 2006, J AM STAT ASS
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Campbell M, 2007, NIST TRECVID WORKSH
   Chang C. C., 2008, LIBSVM LIB SUPPORT V
   Fidler S., 2008, P CVPR
   Freud Y, 1996, MACH LEARN P 13 INT
   Garcia C, 2000, IMAGE VISION COMPUT, V18, P289, DOI 10.1016/S0262-8856(99)00056-6
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Holub A, 2005, P ICCV
   LAINE A, 1993, IEEE T PATTERN ANAL, V15, P1186, DOI 10.1109/34.244679
   Larlus D, 2008, P CVPR
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li Li-Jia., 2007, P ICCV
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MUTCH J, 2006, P CVPR
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Qian XM, 2011, LECT NOTES COMPUT SC, V6523, P413
   Qian XM, 2011, PATTERN RECOGN, V44, P2502, DOI 10.1016/j.patcog.2011.03.029
   Qian XM, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P44, DOI 10.1109/ISM.2009.14
   Quattoni A., 2004, NIPS
   Rabinovich Andrew., 2007, P ICCV
   Ro YM, 2001, ETRI J, V23, P41, DOI 10.4218/etrij.01.0101.0201
   Serre T, 2005, P CVPR
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Sudderth E., 2005, NIPS
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Wu L, 2009, IEEE T MULTIMEDIA, V11, P286, DOI 10.1109/TMM.2008.2009692
   Yuan J, 2007, P CVPR
   ZHANG H, 2006, P CVPR
   Zhang J, 2007, INT J COMPUT VIS
   Zhou X., 2007, PROC 6 ACM INT C IMA, P25
NR 41
TC 14
Z9 16
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 897
EP 920
DI 10.1007/s11042-012-1151-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300016
DA 2024-07-18
ER

PT J
AU Ge, YM
   Chen, M
   Sun, Y
   Li, ZC
   Wang, Y
   Dutkiewicz, E
AF Ge, Yuming
   Chen, Min
   Sun, Yi
   Li, Zhongcheng
   Wang, Ying
   Dutkiewicz, Eryk
TI QoS provisioning wireless multimedia transmission over cognitive radio
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless multimedia transmission; Cognitive radio networks; Dynamic
   spectrum allocation; Quality of service; Spectrum handoff rate
AB The rapid growing of wireless multimedia applications increases the needs of spectrum resources, but today's spectrum resources have become more and more scarce and large part of the assigned spectrum is in an inefficiency usage. Cognitive Radio (CR) technologies are proposed to solve current spectrum inefficiency problems and offer users a ubiquitous wireless accessing environment, relying on dynamic spectrum allocation. However, there are two unsolved problems in previous work: 1) based on the simplified Quality of Service (QoS) uniform assumption, specific requirements of different wireless multimedia applications cannot be satisfied; 2) aiming at single-objective optimization of spectrum utilization or handoff rate, the co-optimization of these two necessary objectives in CR networks has not been achieved. In this paper, we propose a Two-tier Cooperative Spectrum Allocation method (TCSA) to solve these two problems. TCSA consists of two functional parts: one is a Spectrum Adjacency Ranking algorithm implemented at the secondary users' terminals to satisfy the QoS requirements for different wireless multimedia applications; and the other is a Max Hyper-weight Matching algorithm implemented at the cognitive engines of CR networks to co-optimize spectrum utilization and secondary users' spectrum handoff rate. Simulation results show that, compared with the other Random matching algorithm and Cost minimized algorithm, TCSA can significantly improve the performance of CR networks in terms of secondary users' throughput and spectrum handoff rate.
C1 [Ge, Yuming; Sun, Yi; Li, Zhongcheng] Chinese Acad Sci, Inst Comp Technol, Beijing 100190, Peoples R China.
   [Ge, Yuming] Chinese Acad Sci, Grad Univ, Beijing 100049, Peoples R China.
   [Chen, Min] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Wang, Ying] Beijing Univ Posts & Telecommun, Wireless Technol Innovat Inst, Beijing 100876, Peoples R China.
   [Dutkiewicz, Eryk] Macquarie Univ, Sydney, NSW 2109, Australia.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Huazhong University of Science & Technology; Beijing University of
   Posts & Telecommunications; Macquarie University
RP Chen, M (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM geyuming@ict.ac.cn; minchen@ieee.org; sunyi@ict.ac.cn; zcli@ict.ac.cn;
   wangying@bupt.edu.cn; eryk.dutkiewicz@mq.edu.au
RI Chen, Min/N-9350-2015; Sun, Yi/KJM-4280-2024
OI Chen, Min/0000-0002-0960-4447; Dutkiewicz, Eryk/0000-0002-4268-9286
FU National Basic Research Program of China [2012CB315802]; Natural Science
   Fundation of China [61100177]; Program for New Century Excellent Talents
   in University (NCET); National Research Foundation of Korea (NRF);
   Korean government (MEST) [2011-0009454]
FX This work is supported by the National Basic Research Program of China
   (2012CB315802) and the Natural Science Fundation of China (61100177).
   The work of M. Chen was supported in part by the Program for New Century
   Excellent Talents in University (NCET), and through the National
   Research Foundation of Korea (NRF) grant funded by the Korean government
   (MEST) (No. 2011-0009454).
CR Akyildiz IF, 2006, COMPUT NETW, V50, P2127, DOI 10.1016/j.comnet.2006.05.001
   [Anonymous], COGNITIVE RADIO BACK
   [Anonymous], P IEEE GLOBECOM
   [Anonymous], SURVEY GREEN MOBILE
   [Anonymous], IEEE ACM T NETWORKIN
   [Anonymous], P IEEE CMC 2009
   [Anonymous], AD HOC NETWORKS ELSE
   [Anonymous], ACM J WIRELESS NETWO
   [Anonymous], MULTIUSER MULTIMEDIA
   Cao LL, 2008, IEEE J SEL AREA COMM, V26, P130, DOI 10.1109/JSAC.2008.080112
   Chen Y, 2010, INT CONF ACOUST SPEE, P2350, DOI 10.1109/ICASSP.2010.5496095
   Cordeiro C, 2005, 2005 1st IEEE International Symposium on New Frontiers in Dynamic Spectrum Access Networks, Conference Record, P328
   Deng H, 2000, COMPUT OPER RES, V27, P963, DOI 10.1016/S0305-0548(99)00069-6
   Jo O, 2007, 2007 2ND INTERNATIONAL CONFERENCE ON COGNITIVE RADIO ORIENTED WIRELESS NETWORKS AND COMMUNICATIONS, P530, DOI 10.1109/CROWNCOM.2007.4549856
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Kushwaha H, 2008, P IEEE, V96, P155, DOI 10.1109/JPROC.2007.909917
   KwangSik Kim, 2010, Journal of Computing Science and Engineering, V4, P153
   Liu X, 2010, IEEE T CONSUM ELECTR, V56, P987, DOI 10.1109/TCE.2010.5506030
   Minkyu Lee, 2011, Journal of Computing Science and Engineering, V5, P141, DOI 10.5626/JCSE.2011.5.2.141
   Mitola J, 2001, MOBILE NETW APPL, V6, P435, DOI 10.1023/A:1011426600077
   Nie N, 2005, 2005 1ST IEEE INTERNATIONAL SYMPOSIUM ON NEW FRONTIERS IN DYNAMIC SPECTRUM ACCESS NETWORKS, CONFERENCE RECORD, P269
   Ohyun J., 2008, Proc. WTS, P230
   Shiang HP, 2008, IEEE T MULTIMEDIA, V10, P896, DOI 10.1109/TMM.2008.922851
   Shiang HP, 2009, IEEE T VEH TECHNOL, V58, P941, DOI 10.1109/TVT.2008.925308
   Swami S, 2008, IEEE IPCCC, P354, DOI 10.1109/PCCC.2008.4745077
   Yuan Y, 2007, MOBIHOC'07: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL SYMPOSIUM ON MOBILE AD HOC NETWORKING AND COMPUTING, P130
   Zhao Q, 2007, IEEE SIGNAL PROC MAG, V24, P79, DOI 10.1109/MSP.2007.361604
   Zheng HT, 2005, 2005 1st IEEE International Symposium on New Frontiers in Dynamic Spectrum Access Networks, Conference Record, P56
NR 28
TC 8
Z9 10
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 1
BP 213
EP 229
DI 10.1007/s11042-011-0937-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 196PN
UT WOS:000322787800011
DA 2024-07-18
ER

PT J
AU Hossain, MA
   Shirehjini, AAN
   Alghamdi, AS
   El Saddik, A
AF Hossain, M. Anwar
   Shirehjini, Ali Asghar Nazari
   Alghamdi, Abdullah S.
   El Saddik, Abdulmotaleb
TI Adaptive interaction support in ambient-aware environments based on
   quality of context information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human environment interaction; Ambient-aware environment; Quality of
   context information; Media services; User satisfaction; Trust
ID USER
AB Ambient-aware environments are technologically augmented with myriad sensors, devices and other emerging services in order to support users. However, users find it complex in interacting with such environments due to the presence of numerous devices and services. In this situation, providing context-aware implicit or automatic interaction support may help reducing the cognitive load of the users and facilitate easy access of the available devices and services. However, due to the imprecision in context information, implicit interactions performed by the environment often leads to mis-automation. The result of such impaired implicitness causes distrust and dissatisfaction to the user. In order to address this issue, we propose a system that considers quality of information to dynamically adjust the level of implicit interaction and allows a system to operate in different modes such as full-automation, action suggestion, simple notification, or null action. We conduct experiment in a smart home scenario in order to elicit users' acceptance and trust regarding the proposed system. Our experiment shows that dynamic and alternative mode of interaction not only increases the satisfaction of users but also helps to avoid distrust in automated actions carried out by the environment under varying contexts.
C1 [Hossain, M. Anwar; Alghamdi, Abdullah S.] King Saud Univ, CCIS, Riyadh, Saudi Arabia.
   [Shirehjini, Ali Asghar Nazari] Univ Ottawa, Distributed & Collaborat Virtual Environm Res Lab, Ottawa, ON K1N 6N5, Canada.
   [El Saddik, Abdulmotaleb] Univ Ottawa, Multimedia Commun Res Lab MCRLab, Ottawa, ON K1N 6N5, Canada.
C3 King Saud University; University of Ottawa; University of Ottawa
RP Hossain, MA (corresponding author), King Saud Univ, CCIS, Riyadh, Saudi Arabia.
EM mahossain@ksu.edu.sa; ali.nazari@discover.uottawa.ca; ghamdi@ksu.edu.sa;
   abed@mcrlab.uottawa.ca
RI Nazari Shirehjini, Ali Asghar/I-9374-2017; Hossain, M.
   Anwar/J-9601-2013; /D-4159-2009
OI Nazari Shirehjini, Ali Asghar/0000-0001-6674-0739; /0000-0002-7690-8547
FU King Saud University [RGP-VPP-049]
FX The authors extend their appreciation to the Deanship of Scientific
   Research at King Saud University for funding this work through the
   research group project No RGP-VPP-049.
CR Aarts E, 2004, IEEE MULTIMEDIA, V11, P12, DOI 10.1109/MMUL.2004.1261101
   Aarts E, 2009, J AMB INTEL SMART EN, V1, P5, DOI 10.3233/AIS-2009-0001
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], X10 IND STAND
   [Anonymous], CHI 99
   [Anonymous], 2007, User control in ubiquitous computing: Design alternatives and user acceptance
   [Anonymous], P 1 IEEE INT C PERV
   [Anonymous], INT J COGN ERGON
   [Anonymous], ADV PERVASIVE COMPUT
   [Anonymous], THESIS TU DARMSTADT
   Barkhuus L, 2003, LECT NOTES COMPUT SC, V2864, P149
   Brumitt B, 2000, LECT NOTES COMPUT SC, V1927, P12
   Buchholz T., 2003, Workshop of the HP OpenView University Association (HPOVUA), P11
   Damián-Reyes P, 2011, WIRELESS PERS COMMUN, V56, P37, DOI 10.1007/s11277-009-9882-1
   de Vries P, 2003, INT J HUM-COMPUT ST, V58, P719, DOI 10.1016/S1071-5819(03)00039-9
   Dey A. K., 2005, ACM Transactions on Computer-Human Interaction, V12, P53, DOI 10.1145/1057237.1057241
   Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019
   Dey AK, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P859
   Encarnaçao JL, 2007, LECT NOTES COMPUT SC, V4557, P623
   Endsley MR, 1996, HUM FAC TRANSP, P163
   Hearst M, 1999, IEEE INTELL SYST APP, V14, P14, DOI 10.1109/5254.796083
   Hossain MA, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/1870121.1870124
   Hossain MA, 2009, MULTIMED TOOLS APPL, V44, P407, DOI 10.1007/s11042-009-0285-9
   Hossain MA, 2011, IEEE ICME WORKSHOP A, P1
   Lim BY, 2011, UBICOMP'11: PROCEEDINGS OF THE 2011 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P415
   Manzoor A, 2009, LECT NOTES COMPUT SC, V5786, P144, DOI 10.1007/978-3-642-04559-2_13
   Nakamura EF, 2007, ACM COMPUT SURV, V39, DOI 10.1145/1267070.1267073
   Parasuraman R, 2000, IEEE T SYST MAN CY A, V30, P286, DOI 10.1109/3468.844354
   Qin WJ, 2008, LECT NOTES COMPUT SC, V5061, P187
   Ranganathan A, 2004, IEEE PERVAS COMPUT, V3, P62, DOI 10.1109/MPRV.2004.1316821
   Schmidt A, 1999, COMPUT GRAPH-UK, V23, P893, DOI 10.1016/S0097-8493(99)00120-X
   Schmidt A., 2000, Personal Technologies, V4, P191, DOI 10.1007/BF01324126
   Shafer SAN, 2001, HUM-COMPUT INTERACT, V16, P363, DOI 10.1207/S15327051HCI16234_16
   Sheikh Kamran, 2008, Journal of Software, V3, P83, DOI 10.4304/jsw.3.3.83-93
   Sheridan TB., 2002, Humans and automation: System design and research issues
   Shirehjini AAN, 2004, COMPUT GRAPH-UK, V28, P667, DOI 10.1016/j.cag.2004.06.006
   Villar N., 2005, IEE Seminar on Intelligent Building Environments, P173
   Yu ZW, 2006, IEEE PERVAS COMPUT, V5, P68, DOI 10.1109/MPRV.2006.61
NR 38
TC 10
Z9 11
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 2
BP 409
EP 432
DI 10.1007/s11042-012-1008-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 205HY
UT WOS:000323435800005
DA 2024-07-18
ER

PT J
AU Hsu, KS
   Peng, LM
   Yu, C
AF Hsu, Kuei-Shu
   Peng, Limei
   Yu, Chen
TI Design and application of the stereo vision manipulator with novel
   scheduling policies control
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image tracking system; Scheduling police; Image processing
ID SYSTEM; NAVIGATION
AB This main purpose of this paper is to promote the efficiency of a control system using a scheduling policies control design. In this system, the management of a computer's input and output information is handled appropriately by the program language. The scheduling policies control design is used in the robotic arm's tracking system. The advantage of this control design is to activate each procedure running simultaneously when the transient overload of the information's input and output in the control system occurs. Therefore, the time run in the scheduling policies control system will be shorter than that of a traditional control system in which each procedure is lined up for running. In this paper, case studies of the scheduling police control application used in image tracking vision control are introduced. The results reveal that the speed of the tracking system can be improved by using the scheduling police technique under an immediate procedure plan.
C1 [Hsu, Kuei-Shu] Chia Nan Univ Pharm & Sci, Dept Appl Geoinformat, Tainan 701, Taiwan.
   [Peng, Limei] Soochow Univ, Sch Elect & Informat Engn, Suzhou 215006, Peoples R China.
   [Yu, Chen] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Serv Comp Technol & Syst Lab, Cluster & Grid Comp Lab, Wuhan 430074, Peoples R China.
C3 Chia Nan University of Pharmacy & Science; Soochow University - China;
   Huazhong University of Science & Technology
RP Hsu, KS (corresponding author), Chia Nan Univ Pharm & Sci, Dept Appl Geoinformat, Tainan 701, Taiwan.
EM kshsu888@mail.chna.edu.tw; auroraplm@suda.edu.cn; yuchen@hust.edu.cn
RI Yu, Chen/AAI-6384-2020
OI Yu, Chen/0000-0003-0782-0450
CR Barnard ST, 1980, IEEE T PAMI, V2, P330, DOI [10.1109/TPAMI.1980.4767032, DOI 10.1109/TPAMI.1980.4767032]
   Bertozzi M, 1998, IEEE T IMAGE PROCESS, V7, P62, DOI 10.1109/83.650851
   HAN SH, 1999, P IEEE RSJ INT C INT, P1762, DOI DOI 10.1109/IR0S.1999.811733
   Hu B, 1999, IEEE T AUTOMAT CONTR, V44, P765, DOI 10.1109/9.754814
   John M, 2003, ROBUST 3 D LANDMARK, P221, DOI [10.1117/12.463730, DOI 10.1117/12.463730]
   Kidono K, 2002, ROBOT AUTON SYST, V40, P121, DOI 10.1016/S0921-8890(02)00237-3
   Kuo HC, 2002, J MATER PROCESS TECH, V120, P169, DOI 10.1016/S0924-0136(01)01155-4
   Lobo J, 2003, ROBOT AUTON SYST, V44, P69, DOI 10.1016/S0921-8890(03)00011-3
   MOHAN R, 1989, IEEE T PATTERN ANAL, V11, P1121, DOI 10.1109/34.42852
   MURRAY D, 1997, P IEEE INT C ROB AUT, V2, P1694, DOI DOI 10.1109/R0B0T.1997.614387
   Ohya A, 1998, IEEE T ROBOTIC AUTOM, V14, P969, DOI 10.1109/70.736780
   Olson CF, 1997, IEEE T IMAGE PROCESS, V6, P103, DOI 10.1109/83.552100
   Palopoli L, 2002, CONTROL ENG PRACT, V10, P1091, DOI 10.1016/S0967-0661(02)00054-0
   Seara JF, 2004, ROBOT AUTON SYST, V48, P231, DOI [10.1016/j.robots.2004.07.003, 10.1016/j.robot.2004.07.003]
   Starck JL, 2003, IEEE T IMAGE PROCESS, V12, P706, DOI 10.1109/TIP.2003.813140
   Winters N, 2002, ROBOT AUTON SYST, V41, P145, DOI 10.1016/S0921-8890(02)00278-6
NR 16
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 1
BP 249
EP 268
DI 10.1007/s11042-011-0867-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 196PN
UT WOS:000322787800013
DA 2024-07-18
ER

PT J
AU Yang, J
   Sun, Y
   Zhou, YM
   Sun, SX
AF Yang, Jin
   Sun, Yu
   Zhou, Yimin
   Sun, Shixin
TI Incremental rate control for H.264 AVC scalable extension
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rate control; Scalable Video Coding (SVC); H.264 compression standard;
   Quantization Parameter
AB The emerging H.264 Scalable Video Coding (H.264/SVC) requires the rate control algorithm to regulate the output bit rate of all the coarse-grain-scalability, temporal, spatial and combined enhancement layers. In order to address this topic, in this research, we propose an incremental rate control algorithm for H.264/SVC to control each layer's encoding rate close to the target bit rate. The proposed algorithm introduces a number of efficient methods. First, based on our previous work on H.264/AVC rate control, a Rate-Complexity-Quantization (R-C-Q) model is extended in scalable video coding. Second, a complexity measure for Intra-frames based on their gradient and histogram information is used to precisely determine Quantization Parameters (QPs) for Intra-frames using the R-C-Q model. Third, we adopt an incremental approach to compute QPs of inter-frames. Fourth, a Proportional + Integral + Derivative (PID) buffer controller is presented to provide robust buffer control for each layer of H.264/SVC bitstream. Finally the QPs for hierarchical B-frames are adaptively decided by their neighbor inter-frames. Our extensive simulation results demonstrate that, our algorithm outperforms JVT-W043 rate control algorithm, adopted in the H.264/SVC reference software, by providing more accurate output bit rate for each layer, maintaining stable buffer fullness, reducing frame skipping finally, improving the overall coding quality.
C1 [Yang, Jin; Zhou, Yimin; Sun, Shixin] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 610054, Sichuan, Peoples R China.
   [Sun, Yu] Univ Cent Arkansas, Dept Comp Sci, Conway, AR 72034 USA.
C3 University of Electronic Science & Technology of China; University of
   Central Arkansas
RP Sun, Y (corresponding author), Univ Cent Arkansas, Dept Comp Sci, 201 Donaghey Ave, Conway, AR 72034 USA.
EM yusun@uca.edu
OI Zhou, Yimin/0000-0001-8692-9635
CR [Anonymous], 2008, JSVM9 16 SOFTW PACK
   Anselmo T, 2007, P PICT COD S 2007 LI
   Cho YJ, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P387
   *ISO IEC, 1993, JTC1SC29WG1193400 IS
   ITU-T VCEG ISO/IEC MPEG Joint Video Team (JVT), 2007, 1449610 ISOIEC ITUTV
   Lee HJ, 2000, IEEE T CIRC SYST VID, V10, P878, DOI 10.1109/76.867926
   Leontaris A, 2007, 24 M SAN JOS PATT US
   LI ZG, 2003, 7 M PATT 2 THAIL 7 1
   Liu Y, 2007, IEEE INT SYMP CIRC S, P1746, DOI 10.1109/ISCAS.2007.378009
   REICHEL J, 2007, 24 M GEN CH 29 JUN 5
   Ribas-Corbera J, 1999, IEEE T CIRC SYST VID, V9, P172, DOI 10.1109/76.744284
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Sun Y, 2009, IET IMAGE PROCESS, V3, P286, DOI 10.1049/iet-ipr.2009.0037
   Sun Y, 2008, P IEEE INT C IM PROC, P534
   Xu L, 2007, PICT COD S PCS 2007
   Yang L, 2008, IEEE T CIRCUITS SYST, V18, P398
   ZHOU Y, 2008, P IEEE INT C MULT EX, P699
   Zhou YM, 2009, SIGNAL PROCESS-IMAGE, V24, P345, DOI 10.1016/j.image.2009.02.014
NR 18
TC 5
Z9 6
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2013
VL 64
IS 3
BP 581
EP 598
DI 10.1007/s11042-011-0967-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126IV
UT WOS:000317608600004
DA 2024-07-18
ER

PT J
AU Janowski, L
   Romaniak, P
   Papir, Z
AF Janowski, Lucjan
   Romaniak, Piotr
   Papir, Zdzislaw
TI Content driven QoE assessment for video frame rate and frame resolution
   reduction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video QoE; FPS; Resolution; No-reference quality metric
ID QUALITY
AB Video bit rate reduction is very important for all video streaming applications. One possibility involves quantization domain and the majority of the work devoted to bit rate reduction focuses on this aspect only. The other possibility is to modify a video in time or space domain i.e. change the frames per second FPS rate or frame resolution FR. In this paper we present two no reference metrics mapping FPS rate and FR into MOS (Mean Opinion Scale). The performance of both models is significantly improved by incorporating content characteristics such as spatial information SI and temporal information TI. The impact on Quality of Experience (QoE) of both content characteristics is discussed with relation to the FPS rate and FR changes and general conclusions are drawn. The models were estimated and verified upon results of subjective experiments performed using video sequences of diverse spatial and temporal variability. The considered FPS rate was changed from 5 to 30 and the considered FR was changed from SQCIF to SD.
C1 [Janowski, Lucjan; Romaniak, Piotr; Papir, Zdzislaw] AGH Univ Sci & Technol, Dept Telecommun, Krakow, Poland.
C3 AGH University of Krakow
RP Romaniak, P (corresponding author), AGH Univ Sci & Technol, Dept Telecommun, Krakow, Poland.
EM janowski@kt.agh.edu.pl; romaniak@agh.edu.pl; papir@kt.agh.edu.pl
RI Romaniak, Piotr/C-7763-2011; Janowski, Lucjan/B-2264-2013
OI Janowski, Lucjan/0000-0002-3151-2944
FU Polish Ministry of Science and Higher Education under the European
   Regional Development Fund [POIG.01.01.02-00-045/09-00]; European
   Regional Development Fund within INSIGMA project
   [POIG.01.01.02-00-062/09]
FX The presented work was supported by the Polish Ministry of Science and
   Higher Education under the European Regional Development Fund, Grant No.
   POIG.01.01.02-00-045/09-00 Future Internet Engineering. Subjective tests
   were supported by European Regional Development Fund within INSIGMA
   project no. POIG.01.01.02-00-062/09.
CR Armstrong M, 2008, 169 WHP BBC
   BROWNLOW K, 1980, SIGHT SOUND, V49, P164
   Chen JYC, 2007, IEEE T SYST MAN CY A, V37, P1063, DOI 10.1109/TSMCA.2007.904779
   FENIMORE C, 1998, 140 SMPTE TECHN C PA, P28
   Inazumi Y, 2003, ELECTRON COMM JPN 1, V86, P54, DOI 10.1002/ecja.10102
   International Telecommunications Union-Telecommunication Sector, 1999, SUBJ VID QUAL ASS ME
   Janowski L, 2009, INT WORK QUAL MULTIM, P35, DOI 10.1109/QOMEX.2009.5246979
   Leszczuk M, 2011, COMM COM INF SC, V149, P10
   McCullagh P, 2009, GEN LINEAR MODELS
   Ou YF, 2008, IEEE IMAGE PROC, P689, DOI 10.1109/ICIP.2008.4711848
   Teahyung L, 2010, 5 INT WORKSH VID PRO
   VQEG, 2009, PLAN EV VID QUAL MOD
   Zhongkang Lu, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P433
NR 13
TC 9
Z9 11
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2012
VL 61
IS 3
BP 769
EP 786
DI 10.1007/s11042-011-0932-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 021CA
UT WOS:000309861700013
DA 2024-07-18
ER

PT J
AU Schnitzer, D
   Flexer, A
   Widmer, G
AF Schnitzer, Dominik
   Flexer, Arthur
   Widmer, Gerhard
TI A fast audio similarity retrieval method for millions of music tracks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio; Indexing; Music recommendation
ID NEAREST-NEIGHBOR
AB We present a filter-and-refine method to speed up nearest neighbor searches with the Kullback-Leibler divergence for multivariate Gaussians. This combination of features and similarity estimation is of special interest in the field of automatic music recommendation as it is widely used to compute music similarity. However, the non-vectorial features and a non-metric divergence make using it with large corpora difficult, as standard indexing algorithms can not be used. This paper proposes a method for fast nearest neighbor retrieval in large databases which relies on the above approach. In its core the method rescales the divergence and uses a modified FastMap implementation to speed up nearest-neighbor queries. Overall the method accelerates the search for similar music pieces by a factor of 10-30 and yields high recall values of 95-99% compared to a standard linear search.
C1 [Schnitzer, Dominik; Flexer, Arthur] Austrian Res Inst Artificial Intelligence OFAI, Vienna, Austria.
   [Widmer, Gerhard] Johannes Kepler Univ Linz, Dept Computat Percept, A-4040 Linz, Austria.
C3 Johannes Kepler University Linz
RP Schnitzer, D (corresponding author), Austrian Res Inst Artificial Intelligence OFAI, Freyung 6-6, Vienna, Austria.
EM dominik.schnitzer@ofai.at; arthur.flexer@ofai.at; gerhard.widmer@jku.at
RI ; Widmer, Gerhard/B-8218-2017
OI Flexer, Arthur/0000-0002-1691-737X; Widmer, Gerhard/0000-0003-3531-1282
FU Austrian Research Fund (FWF) [L511-N15]; Austrian Research Promotion
   Agency (FFG) [815474-BRIDGE]
FX This research is supported by the Austrian Research Fund (FWF) under
   grant L511-N15, and by the Austrian Research Promotion Agency (FFG)
   under project number 815474-BRIDGE.
CR Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   [Anonymous], 2006, ISMIR
   [Anonymous], 2006, THESIS VIENNA U TECH
   [Anonymous], P 6 INT C MUS INF RE
   [Anonymous], 2001, MULTIDIMENSIONAL SCA
   Athitsos V, 2004, P 2004 IEEE COMP SOC, V2
   Athitsos V, 2008, PROC INT CONF DATA, P327, DOI 10.1109/ICDE.2008.4497441
   Bentley J., 1975, MULTIDIMENSIONAL BIN
   Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217
   Burges CJC, 2003, IEEE T SPEECH AUDI P, V11, P165, DOI 10.1109/TSA.2003.811538
   Cai R., 2007, P 15 ACM INT C MULT, P1065
   Cano P., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, DOI 10.1145/1076034.1076185
   Cano P, 2002, 3 INT C MUS INF RETR, P275
   Downie JS, 2008, ACOUST SCI TECHNOL, V29, P247, DOI 10.1250/ast.29.247
   Endres DM, 2003, IEEE T INFORM THEORY, V49, P1858, DOI 10.1109/TIT.2003.813506
   Faloutsos C., 1995, SIGMOD Record, V24, P163, DOI 10.1145/568271.223812
   Fastl H., 2007, Psychoacoustics: Facts and Models, P247
   Flexer A, 2007, P INT S MUS INF RETR
   Flexer A, 2010, COMPUT MUSIC J, V34, P20, DOI 10.1162/COMJ_a_00004
   Garcia Vincent, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563100
   Homburg Helge., 2005, ISMIR, P528
   Jensen JH, 2009, IEEE T AUDIO SPEECH, V17, P693, DOI 10.1109/TASL.2008.2012314
   Levy M., 2006, P 1 ACM WORKSH AUD M, P27
   Mandel M, 2007, P INT S MUS INF RETR
   Pampalk E., 2002, Proceedings of the tenth ACM international conference on Multimedia, P570, DOI DOI 10.1145/641007.641121
   Penny W.D., 2001, Kl-divergences of normal, gamma, dirichlet and wishart densities
   Pohle T, 2007, 4 ANN MUS INF RETR E
   Rafailidis D, 2009, MULTIMED TOOLS APPL, P1
   Roy P, 2005, P 6 INT C MUS INF RE
   Schnitzer D, 2007, THESIS VIENNA U TECH
   Wang JTL, 2005, IEEE T SYST MAN CY B, V35, P973, DOI 10.1109/TSMCB.2005.848489
   YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311
NR 32
TC 15
Z9 15
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2012
VL 58
IS 1
BP 23
EP 40
DI 10.1007/s11042-010-0679-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 917BS
UT WOS:000302147600002
DA 2024-07-18
ER

PT J
AU Xiang, SJ
AF Xiang, Shijun
TI On invariance analysis of Zernike moments in the presence of rotation
   with crop and loose modes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image; Loose rotation; Crop rotation; Zernike moments
ID COMPUTATION; ACCURACY
AB Zernike moments are widely applied in digital image processing fields based on many desirable properties, such as rotational invariance, noise robust and efficient representation of pattern. On the computational analysis of Zernike moment is challenging issue. From an algorithmic aspect, in this paper we investigate the effect of image rotation (including crop rotation and loose rotation) operations on Zernike moments in both theoretical and experimental ways. For the crop rotation, we suggest to extract the Zernike moments by mapping the image over a disc instead of inside a circle since the outside of an image after the crop rotation will be distorted. Referring to the loose rotation, we propose a preprocessing step (which is called image size normalization) to embed an image and its rotated versions into a predefined size of zero-value image in such a way that the effect of image size change due to loose rotation can be eliminated. By incorporating the proposed image size normalization operation, we introduce an effective extraction method of image Zernike moments against loose rotation operation. Experimental results show the validity of the proposed extraction method.
C1 Jinan Univ, Sch Informat Sci & Technol, Dept Elect Engn, Guangzhou 510632, Guangdong, Peoples R China.
C3 Jinan University
RP Xiang, SJ (corresponding author), Jinan Univ, Sch Informat Sci & Technol, Dept Elect Engn, Guangzhou 510632, Guangdong, Peoples R China.
EM xiangshijun@gmail.com
FU NSFC [60903177]; Ph.D. Programs Foundation of Ministry of Education of
   China [200805581048]; Fundamental Research Funds for the Central
   Universities [21609412]; SRF for ROCS, SEM [[2008]890]
FX This work was supported in part by NSFC (No. 60903177), in part
   supported by Ph.D. Programs Foundation of Ministry of Education of China
   (No. 200805581048), the Fundamental Research Funds for the Central
   Universities (No. 21609412), and the Project-sponsored by SRF for ROCS,
   SEM (No. [2008]890). The author appreciates the anonymous reviewers for
   their valuable comments.
CR ABDALLAH S, 2000, THESIS U SYDNEY
   Al-Rawi M, 2008, J REAL-TIME IMAGE PR, V3, P89, DOI 10.1007/s11554-007-0069-2
   [Anonymous], IMAGE PROCESSING TOO
   [Anonymous], Standard Test Images
   Chong CW, 2003, PATTERN ANAL APPL, V6, P176, DOI 10.1007/s10044-002-0183-5
   Chong CW, 2003, PATTERN RECOGN, V36, P1765, DOI 10.1016/S0031-3203(02)00353-9
   Farzam M, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P529, DOI 10.1109/MMSP.2001.962787
   Hosny KM, 2008, J REAL-TIME IMAGE PR, V3, P97, DOI 10.1007/s11554-007-0058-5
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kim HS, 2003, IEEE T CIRC SYST VID, V13, P766, DOI 10.1109/TCSVT.2003.815955
   Kim WY, 2000, SIGNAL PROCESS-IMAGE, V16, P95, DOI 10.1016/S0923-5965(00)00019-9
   Kotoulas L, 2005, IEEE T CIRC SYST VID, V15, P801, DOI 10.1109/TCSVT.2005.848302
   Lefèvre S, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P1109, DOI 10.1109/ICDSP.2002.1028286
   Liao SX, 1998, IEEE T PATTERN ANAL, V20, P1358, DOI 10.1109/34.735809
   Padilla-Vivanco A, 2004, P SOC PHOTO-OPT INS, V5237, P281, DOI 10.1117/12.514248
   Palaniappan R, 2000, PATTERN ANAL APPL, V3, P78, DOI 10.1007/s100440070014
   Rodtook S, 2005, IMAGE VISION COMPUT, V23, P577, DOI 10.1016/j.imavis.2005.02.001
   Singhal N, 2009, J VIS COMMUN IMAGE R, V20, P408, DOI 10.1016/j.jvcir.2009.04.002
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Wee CY, 2007, IMAGE VISION COMPUT, V25, P967, DOI 10.1016/j.imavis.2006.07.010
   Xin YQ, 2007, PATTERN RECOGN, V40, P3740, DOI 10.1016/j.patcog.2007.05.004
   Xin YQ, 2004, INT C PATT RECOG, P861, DOI 10.1109/ICPR.2004.1333908
   Ye B, 2002, J OPT A-PURE APPL OP, V4, P606, DOI 10.1088/1464-4258/4/6/304
NR 23
TC 1
Z9 1
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2012
VL 57
IS 1
BP 29
EP 48
DI 10.1007/s11042-010-0539-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 898YR
UT WOS:000300778800003
DA 2024-07-18
ER

PT J
AU Arantes, M
   Gonzaga, A
AF Arantes, Milene
   Gonzaga, Adilson
TI Human gait recognition using extraction and fusion of global motion
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human gait; Gait recognition; Gait analysis; Biometry; Fusion of
   characteristics; Global motion
AB This paper proposes a novel computer vision approach that processes video sequences of people walking and then recognises those people by their gait. Human motion carries different information that can be analysed in various ways. The skeleton carries motion information about human joints, and the silhouette carries information about boundary motion of the human body. Moreover, binary and gray-level images contain different information about human movements. This work proposes to recover these different kinds of information to interpret the global motion of the human body based on four different segmented image models, using a fusion model to improve classification. Our proposed method considers the set of the segmented frames of each individual as a distinct class and each frame as an object of this class. The methodology applies background extraction using the Gaussian Mixture Model (GMM), a scale reduction based on the Wavelet Transform (WT) and feature extraction by Principal Component Analysis (PCA). We propose four new schemas for motion information capture: the Silhouette-Gray-Wavelet model (SGW) captures motion based on grey level variations; the Silhouette-Binary-Wavelet model (SBW) captures motion based on binary information; the Silhouette-Edge-Binary model (SEW) captures motion based on edge information and the Silhouette Skeleton Wavelet model (SSW) captures motion based on skeleton movement. The classification rates obtained separately from these four different models are then merged using a new proposed fusion technique. The results suggest excellent performance in terms of recognising people by their gait.
C1 [Gonzaga, Adilson] Univ Sao Paulo, Sch Engn Sao Carlos, Dept Elect Engn, Sao Carlos, SP, Brazil.
C3 Universidade de Sao Paulo
RP Gonzaga, A (corresponding author), Univ Sao Paulo, Sch Engn Sao Carlos, Dept Elect Engn, Sao Carlos, SP, Brazil.
EM milenea@gmail.com; agonzaga@sc.usp.br
RI Gonzaga, Adilson/B-4883-2010
OI Gonzaga, Adilson/0000-0003-2193-9394
FU Sao Paulo State Foundation
FX The authors would like to thank the Sao Paulo State Foundation for
   Supporting Research (FAPESP) for their financial support of this
   research.
CR [Anonymous], Open Source Computer Vision Library - v2.4.9
   [Anonymous], 1991, P 1991 IEEE COMP SOC, DOI DOI 10.1109/CVPR.1991.139758
   BenAbdelkader C, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P267, DOI 10.1109/AFGR.2002.1004165
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   BOULGOURIS NV, 2007, IEEE T IMAGE PROCESS, DOI DOI 10.1109/ICIP.2006.313058
   Burrus S., 1998, Introduction to Wavelets and Wavelet Transformations: A Primer
   CHELLAPPA R, 2003, IEEE INT C IM PROC, DOI DOI 10.1109/ICIP.2003.1247165
   COLLINS RT, 2002, P INT C AUT FAC GEST, DOI DOI 10.1109/AFGR.2002.1004181
   Havasi L, 2007, IEEE T IMAGE PROCESS, V16, P503, DOI 10.1109/TIP.2006.888339
   HONG L, 1999, P AUTOID 99
   HONG S, 2007, 2 IEEE C ICIEA APPL, DOI DOI 10.1109/ICIEA.2007.4318491
   Kale A., 2003, GAIT ANAL HUMAN IDEN
   KAWTRAKULLPONG P, 2001, P 2 EUR WORKSH ADV V
   LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346
   LEE L, 2002, IEEE C FAC GEST REC, DOI DOI 10.1109/AFGR.2002.1004148
   Liu J, 2007, IEEE CONF WIREL MOB
   LIU Z, 2006, IEEE T PATTERN ANAL, DOI DOI 10.1109/ICBBE.2007.142
   Murase H, 1996, PATTERN RECOGN LETT, V17, P155, DOI 10.1016/0167-8655(95)00109-3
   NIYOGI SA, 1994, P CVPR, DOI DOI 10.1109/CVPR.1994.323868
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   PHILLIPS PJ, 2002, P IEEE INT C AUT FAC, DOI DOI 10.1109/AFGR.2002.1004145
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Winter DA., 1991, WATERLOO BIOMECHANIC
   YANG J, 2006, ICSP P, DOI DOI 10.1109/ICOSP.2006.345931
   DATA BASE CASIA GAIT
NR 27
TC 13
Z9 14
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2011
VL 55
IS 3
BP 655
EP 675
DI 10.1007/s11042-010-0587-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 815CV
UT WOS:000294504600013
DA 2024-07-18
ER

PT J
AU Ghinea, G
   Ademoye, OA
AF Ghinea, Gheorghita
   Ademoye, Oluwakemi A.
TI Olfaction-enhanced multimedia: perspectives and challenges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Olfaction; Multimedia; Applications; Virtual reality; State-of-the-art;
   Review
ID SMELL IDENTIFICATION TEST; ODOR IDENTIFICATION; WINE EXPERTISE;
   PERCEPTION; MEMORY; DISCRIMINATION; RECOGNITION; INFORMATION;
   SENSITIVITY; ADAPTATION
AB Olfaction-or smell-is one of the last challenges which multimedia and multimodal applications have to conquer. Enhancing such applications with olfactory stimuli has the potential to create a more complex-and richer-user multimedia experience, by heightening the sense of reality and diversifying user interaction modalities. Nonetheless, olfaction-enhanced multimedia still remains a challenging research area. More recently, however, there have been initial signs of olfactory-enhanced applications in multimedia, with olfaction being used towards a variety of goals, including notification alerts, enhancing the sense of reality in immersive applications, and branding, to name but a few. However, as the goal of a multimedia application is to inform and/or entertain users, achieving quality olfaction-enhanced multimedia applications from the users' perspective is vital to the success and continuity of these applications. Accordingly, in this paper we have focused on investigating the user perceived experience of olfaction-enhanced multimedia applications, with the aim of discovering the quality evaluation factors that are important from a user's perspective of these applications, and consequently ensure the continued advancement and success of olfaction-enhanced multimedia applications.
C1 [Ghinea, Gheorghita; Ademoye, Oluwakemi A.] Brunel Univ, Dept Informat Syst Comp & Math, Uxbridge UB8 3PH, Middx, England.
C3 Brunel University
RP Ghinea, G (corresponding author), Brunel Univ, Dept Informat Syst Comp & Math, Kingston Lane, Uxbridge UB8 3PH, Middx, England.
EM george.ghinea@brunel.ac.uk
RI Ghinea, Gheorghita/AAG-6770-2020
OI Ghinea, Gheorghita/0000-0003-2578-5580; Ademoye,
   Kemi/0000-0001-9597-4497
CR ADEMOYE OA, 2007, MMCN 07 14 ANN MULT, V6504
   Ademoye OA, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1425, DOI 10.1109/ICME.2008.4607712
   [Anonymous], 1995, NUTR FOOD SCI, V5, P24, DOI DOI 10.1108/00346659510094008
   [Anonymous], 2006, BBC
   [Anonymous], 1999, ABC News
   Ayabe-Kanamura S, 1998, ANN NY ACAD SCI, V855, P694, DOI 10.1111/j.1749-6632.1998.tb10647.x
   BEGLUND B, 1986, EXPERIENTIA, V42, P280
   Bodnar A., 2004, ICMI 04, P183
   Boyd-Davis S., 2006, P HUM FACT ERG SOC 2, P25
   Brewster S. A., 2006, Conference on Human Factors in Computing Systems. CHI2006, P653
   CAIN WS, 1992, CHEM SENSES, V17, P481, DOI 10.1093/chemse/17.5.481
   Callegari P, 1997, CHEM SENSES, V22, P1, DOI 10.1093/chemse/22.1.1
   Chastrette M, 2002, OLFACTION, TASTE, AND COGNITION, P100, DOI 10.1017/CBO9780511546389.012
   Chrea C, 2005, CHEM SENSES, V30, P37, DOI 10.1093/chemse/bjh255
   Chrea C, 2004, FOOD QUAL PREFER, V15, P669, DOI 10.1016/j.foodqual.2003.10.005
   CHRISTENSEN B, 2006, REAL ICT SCENT COLLA
   COLMAN AM, 2001, HENNINGS PRISM
   COLMAN AM, 2001, ZWAARDEMAKER SMELL S
   COLMAN AM, 2001, CROCKER HENDERSON SY
   Dalton P, 2000, CHEM SENSES, V25, P487, DOI 10.1093/chemse/25.4.487
   Davide F., 2001, EMERG COMMUNICAT, P193
   Dinh HQ, 1999, P IEEE VIRT REAL ANN, P222, DOI 10.1109/VR.1999.756955
   DOTY RL, 1984, SCIENCE, V226, P1441, DOI 10.1126/science.6505700
   Dubois D, 2002, OLFACTION, TASTE, AND COGNITION, P47, DOI 10.1017/CBO9780511546389.009
   Elsner RJF, 2001, ARCH GERONTOL GERIAT, V33, P81, DOI 10.1016/S0167-4943(01)00175-3
   FOX K, 2007, SMELL REPORT HUMAN S
   Frank RA, 2004, PHYSIOL BEHAV, V81, P475, DOI 10.1016/j.physbeh.2004.02.020
   GARDINER MB, 2004, HHMI B, V17, P4
   GULLIVER SR, 2004, THESIS BRUNEL U UK
   Gulliver SR, 2006, ACM T MULTIM COMPUT, V2, P241, DOI 10.1145/1201730.1201731
   Harel D, 2003, COMPUT BIOL CHEM, V27, P121, DOI 10.1016/S1476-9271(02)00092-0
   HAREL D, 2001, ALGORITHMIC APPROACH
   HERITAGE S, 2006, NEW COLIN FARRELL MO
   Herz RS, 2002, OLFACTION, TASTE, AND COGNITION, P160, DOI 10.1017/CBO9780511546389.016
   Hudson R, 2002, OLFACTION, TASTE, AND COGNITION, P408, DOI 10.1017/CBO9780511546389.034
   Hummel T, 1997, CHEM SENSES, V22, P39, DOI 10.1093/chemse/22.1.39
   Hummel T, 2002, OLFACTION, TASTE, AND COGNITION, P441, DOI 10.1017/CBO9780511546389.036
   *I CREAT TECHN ANT, SCENT COLL
   Issanchou S, 2002, OLFACTION, TASTE, AND COGNITION, P211, DOI 10.1017/CBO9780511546389.020
   *IVRC, 2003, FRAGR INT OLF GAM SY
   JACOB T, TUTORIAL SENSE SMELL
   Jones L, 2004, HUMAN PERFORMANCE, SITUATION AWARENESS AND AUTOMATION: CURRENT RESEARCH AND TRENDS, VOL 2, P282
   Kaye J."J."., 2004, INTERACTIONS, V11, P48, DOI DOI 10.1145/962342.964333
   KAYE JN, 2001, THESIS MIT MASSACHUS
   Keller A, 2004, CURR BIOL, V14, pR875, DOI 10.1016/j.cub.2004.09.066
   Kiger P. J., 2006, LOS ANGELES TIMES
   Kim DW, 2006, LECT NOTES ARTIF INT, V4253, P859
   KOBAL G, 1991, CELL MOL LIFE SCI CM, V47, P712
   Köster EP, 2002, OLFACTION, TASTE, AND COGNITION, P27, DOI 10.1017/CBO9780511546389.007
   LAING DG, 1983, PERCEPTION, V12, P99, DOI 10.1068/p120099
   Larsson M, 2000, J GERONTOL B-PSYCHOL, V55, pP304, DOI 10.1093/geronb/55.5.P304
   Larsson M, 2002, OLFACTION, TASTE, AND COGNITION, P231, DOI 10.1017/CBO9780511546389.021
   LEFEOWITZ E, SENSORAMAS PREVIRTUA
   Lehrner J, 2002, OLFACTION, TASTE, AND COGNITION, P278, DOI 10.1017/CBO9780511546389.024
   Lundström JN, 2006, BIOL PSYCHOL, V71, P244, DOI 10.1016/j.biopsycho.2005.07.001
   MAIR RG, 1978, SENS PROCESS, V2, P90
   Matsukura H, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P295, DOI 10.1109/VR.2009.4811062
   Matsukura H, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P255, DOI 10.1109/VR.2009.4811042
   MAUTNER J, 2006, MAKING DOLLARS SCENT
   Mizuno K, 2004, EARLY HUM DEV, V76, P83, DOI 10.1016/j.earlhumdev.2003.10.003
   MOCHIZUKI A, 2004, SIGGRAPH 04 ACM SIGG, P123
   Morrot G, 2001, BRAIN LANG, V79, P309, DOI 10.1006/brln.2001.2493
   MOSKOWITZ HR, 1974, CHEM SENS FLAV, V1, P235, DOI 10.1093/chemse/1.2.235
   Nagle HT, 1998, IEEE SPECTRUM, V35, P22, DOI 10.1109/6.715180
   Nakalzumi F, 2006, P IEEE VIRT REAL ANN, P207, DOI 10.1109/VR.2006.122
   Nakamoto T, 2005, SENSOR LETT, V3, P136, DOI 10.1166/sl.2005.018
   Nakamoto T, 2005, SENSOR MATER, V17, P365
   NAKAMOTO T, COOKING GAME SCENTS
   Nakamoto T, 2008, IEEE COMPUT GRAPH, V28, P75, DOI 10.1109/MCG.2008.3
   Nakamoto T, 2006, IEICE T FUND ELECTR, VE89A, P3327, DOI 10.1093/ietfec/e89-a.l 1.3327
   Nakamoto T, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P159, DOI 10.1109/VR.2009.4811016
   *NOB ORG, 2004, NOB PRIZ PHYS MED 20
   *NTT COMM, 2006, MOV ENH INT BAS FRAG
   *OLF RES FUND LTD, AG WELL YOUR SENS SM
   Olofsson JK, 2004, CHEM SENSES, V29, P629, DOI 10.1093/chemse/bjh066
   OSBORNE G, 2001, COMMUNICATIONS
   Parr WV, 2004, FOOD QUAL PREFER, V15, P411, DOI 10.1016/j.foodqual.2003.07.002
   Parr WV, 2002, CHEM SENSES, V27, P747, DOI 10.1093/chemse/27.8.747
   PINES M, 2007, MYSTERY SMELL VIVID
   Platt C., 1999, WIRED MAGAZINE, V7
   Pornpanomchai C, 2009, LECT NOTES COMPUT SC, V5414, P462, DOI 10.1007/978-3-540-92957-4_40
   Saito S, 2006, CHEM SENSES, V31, P379, DOI 10.1093/chemse/bjj042
   SAKAI N, 2005, CHEM SENSES S1, V30
   SALTUS R, 2007, HHMI B, V20, P3
   Sarter NB, 2006, INT J IND ERGONOM, V36, P439, DOI 10.1016/j.ergon.2006.01.007
   Schaal B, 2002, OLFACTION, TASTE, AND COGNITION, P421, DOI 10.1017/CBO9780511546389.035
   SCHAAL B, 1980, REPROD NUTR DEV, V20, P843, DOI 10.1051/rnd:19800510
   Spencer BS, 2006, IEEE T INF TECHNOL B, V10, P168, DOI 10.1109/TITB.2005.856851
   Stevenson RJ, 2007, DEV PSYCHOL, V43, P253, DOI 10.1037/0012-1649.43.1.253
   Stevenson RJ, 2005, PSYCHON B REV, V12, P244, DOI 10.3758/BF03196369
   TODRANK J, 1991, CHEM SENSES, V16, P467, DOI 10.1093/chemse/16.5.467
   TOLEDANO A, 2004, OTOLARYNGOL HEAD NEC, V131, pP55
   TORTELL R, 2007, VIRTUAL REALITY
   VAFAI S, DOES OLFACTORY ACUIT
   VAFAI S, DO MEN WOMEN DIFFER
   *VAR STAFF, 2001, VAR REV SCENT MYST
   Varendi H, 1997, ACTA PAEDIATR, V86, P985, DOI 10.1111/j.1651-2227.1997.tb15184.x
   Ward P, 2007, SERV BUS, V1, P295, DOI 10.1007/s11628-006-0018-3
   Washburn DA, 2004, COMPUT SCI ENG, V6, P80, DOI 10.1109/MCSE.2004.66
   WASHBURN DA, 2007, MODELLING SIMULATION, V2
   Watanabe K, 2002, JPN J PHYSIOL, V52, P353, DOI 10.2170/jjphysiol.52.353
   Yanagida Yasuyuki., 2003, ACM SIGGRAPH 2003 SK, P1
   Yanagida Yasuyuki, 2003, CHI 03 EXTENDED ABST, P988, DOI [10.1145/765891.766109, DOI 10.1145/765891.766109]
   1996, OLFACTORY TYPES
   2004, WELL GOOD
   2001, HHMI NEWS
   FLAVOUR WHEEL
   FLAVOUR WHEEL MAPLE
NR 108
TC 62
Z9 65
U1 2
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2011
VL 55
IS 3
BP 601
EP 626
DI 10.1007/s11042-010-0581-4
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 815CV
UT WOS:000294504600011
DA 2024-07-18
ER

PT J
AU Zhang, F
   Zhu, QD
AF Zhang, Fan
   Zhu, Qi-dan
TI On improved calibration method for the catadioptric omnidirectional
   vision with a single viewpoint
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Congress on Image and Signal Processing
CY OCT 17-19, 2009
CL Tianjin, PEOPLES R CHINA
SP Tianjin Univ Technol, IEEE Engn Med & Biol Soc (EMBS)
DE Catadioptric omnidirectional vision; Single viewpoint constraint;
   Perspective projection; Neural network
AB The single viewpoint constraint is a principal optical characteristic for most catadioptric omnidirectional vision. Single viewpoint catadioptric omnidirectional vision is very useful because it allows the generation of geometrically correct perspective images from one omnidirectional image. Therefore precise calibration for single viewpoint constraint is needed during system assembling. However, in most image detection based calibration methods, the nonlinear optical distortion brought by lens is often neglected. Hence the calibration precision is poor. In this paper, a new calibration method of single viewpoint constraint for the catadioptric omni-directional vision is proposed. Firstly, an image correction algorithm is obtained by training a neural network. Then, according to characteristics of the space circular perspective projection, the corrected image of the mirror boundary is used to estimate its position and attitude relative to the camera to guide the calibration. Since the estimate is conducted based on actual imaging model rather than the simplified model, the estimate error is largely reduced, and the calibration accuracy is significantly improved. Experiments are conducted on simulated images and real images to show the accuracy and the effectiveness of the proposed method.
C1 [Zhang, Fan; Zhu, Qi-dan] Harbin Engn Univ, Coll Automat, Harbin 150001, Heilongjiang Pr, Peoples R China.
C3 Harbin Engineering University
RP Zhang, F (corresponding author), Harbin Engn Univ, Coll Automat, Harbin 150001, Heilongjiang Pr, Peoples R China.
EM zhangfan@hrbeu.edu.cn
RI Zhu, Qidan/ABG-2126-2021
CR Aliaga DG, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P127, DOI 10.1109/ICCV.2001.937508
   Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364
   Barreto JP, 2005, IEEE T PATTERN ANAL, V27, P1327, DOI 10.1109/TPAMI.2005.163
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Deng Xiao-Ming, 2007, Acta Automatica Sinica, V33, P801, DOI 10.1360/aas-007-0801
   GEYERE C, 2001, STRUCTURE MOTION UNC, V1, P279
   Ishiguro H, 2003, MACH VISION APPL, V14, P94, DOI 10.1007/s00138-002-0103-0
   Jeng SW, 2008, IMAGE VISION COMPUT, V26, P690, DOI 10.1016/j.imavis.2007.08.005
   Kang SB, 2000, PROC CVPR IEEE, P201, DOI 10.1109/CVPR.2000.855820
   Mashita T, 2006, IEICE T INF SYST, VE89D, P1984, DOI 10.1093/ietisy/e89-d.7.1984
   Nagahara H, 2003, IEEE T SYST MAN CY B, V33, P607, DOI 10.1109/TSMCB.2003.814285
   Scaramuzza D, 2006, P IEEE INT C VIS SYS
   Spacek L, 2007, ROBOT AUTON SYST, V55, P667, DOI 10.1016/j.robot.2007.05.009
   YAGI Y, 1994, IEEE T ROBOTIC AUTOM, V10, P11, DOI 10.1109/70.285581
NR 14
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2011
VL 52
IS 1
BP 77
EP 89
DI 10.1007/s11042-009-0453-y
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 716RF
UT WOS:000286990500007
DA 2024-07-18
ER

PT J
AU Adzic, V
   Kalva, H
   Furht, B
AF Adzic, Velibor
   Kalva, Hari
   Furht, Borko
TI A survey of multimedia content adaptation for mobile devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content adaptation; Mobile devices; Video adaptation; Content semantics
AB With continued increase in the use of smartphones, user expectations of content access have also increased. Most of the content that exists today is not designed for mobile devices. Mobile devices cannot directly access most of the content due to the mismatch in device capability and content playback requirements. Content adaptation is an essential tool that bridges the gap between device capabilities and content formats. In this paper we present an overview of content adaptation and survey recent papers on content adaptation for mobile devices. We introduce the when, where, and what of content adaptation to help classify the content adaptation techniques and to select the appropriate techniques for a given content delivery environment.
C1 [Adzic, Velibor; Kalva, Hari; Furht, Borko] Florida Atlantic Univ, Dept Comp & Elect Engn & Comp Sci, Boca Raton, FL 33431 USA.
C3 State University System of Florida; Florida Atlantic University
RP Kalva, H (corresponding author), Florida Atlantic Univ, Dept Comp & Elect Engn & Comp Sci, Boca Raton, FL 33431 USA.
EM hari@cse.fau.edu
OI Kalva, Hari/0000-0002-7165-5499
CR Ahmadi Hamed., 2008, P WORKING C ADV VISU, P23, DOI 10.1145/1385569.1385576
   Bellinzona D, 2008, INT WORKSHOP DATABAS, P716, DOI 10.1109/DEXA.2008.127
   Blekas A., 2006, INT CROSS DISCIPLINA, P79
   DAVIS S, 2010, QUAL MULT EXP QOMEX, P170
   GUPTA A, 2007, MOB 07 P 4 INT C MOB, P599
   HUTTER A, 2005, IM PROC 2005 ICIP 20, V3
   Kim Svetlana, 2008, GPC Workshops - 2008 3rd International Conference on Grid and Pervasive Computing Workshops, P201, DOI 10.1109/GPC.WORKSHOPS.2008.63
   KIM W, 2007, SITIS 07 3 INT IEEE, P402
   Lam Heidi., 2005, P SIGCHI C HUMAN FAC, P681
   Lee E, 2008, ALPIT 2008: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCED LANGUAGE PROCESSING AND WEB INFORMATION TECHNOLOGY, PROCEEDINGS, P575, DOI 10.1109/ALPIT.2008.79
   Lee E, 2006, 2006 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, (WI 2006 MAIN CONFERENCE PROCEEDINGS), P845, DOI 10.1109/WI.2006.172
   LEHTONEN T, 2006, AAA IDEA 06 P 2 INT
   Rong LT, 2006, AXMEDIS 2006: SECOND INTERNATIONAL CONFERENCE ON AUTOMATED PRODUCTION OF CROSS MEDIA CONTENT FOR MULTI-CHANNEL DISTRIBUTION, PROCEEDINGS, P105
   ROTO V, 2006, CHI 06, P35
   Xiao L, 2008, I C WIREL COMM NETW, P1
   Yang SJH, 2005, CEC 2005: SEVENTH IEEE INTERNATIONAL CONFERENCE ON E-COMMERCE TECHNOLOGY, PROCEEDINGS, P523, DOI 10.1109/ICECT.2005.65
   Yin X., 2004, PROC INT WORLD WIDE, P338, DOI DOI 10.1145/988672.988718
   ZUFFEREY M, 2006, MULT SIGN PROC COMM, P319
NR 18
TC 33
Z9 38
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 1
BP 379
EP 396
DI 10.1007/s11042-010-0669-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 705BO
UT WOS:000286103800014
DA 2024-07-18
ER

PT J
AU Tian, Q
   Zhang, SL
   Zhou, WG
   Ji, RR
   Ni, BB
   Sebe, N
AF Tian, Qi
   Zhang, Shiliang
   Zhou, Wengang
   Ji, Rongrong
   Ni, Bingbing
   Sebe, Nicu
TI Building descriptive and discriminative visual codebook for large-scale
   image applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual vocabulary; Large-scale image retrieval; Image search re-ranking;
   Feature space quantization
AB Inspired by the success of textual words in large-scale textual information processing, researchers are trying to extract visual words from images which function similar as textual words. Visual words are commonly generated by clustering a large amount of image local features and the cluster centers are taken as visual words. This approach is simple and scalable, but results in noisy visual words. Lots of works are reported trying to improve the descriptive and discriminative ability of visual words. This paper gives a comprehensive survey on visual vocabulary and details several state-of-the-art algorithms. A comprehensive review and summarization of the related works on visual vocabulary is first presented. Then, we introduce our recent algorithms on descriptive and discriminative visual word generation, i.e., latent visual context analysis for descriptive visual word identification [74], descriptive visual words and visual phrases generation [68], contextual visual vocabulary which combines both semantic contexts and spatial contexts [69], and visual vocabulary hierarchy optimization [18]. Additionally, we introduce two interesting post processing strategies to further improve the performance of visual vocabulary, i.e., spatial coding [73] is proposed to efficiently remove the mismatched visual words between images for more reasonable image similarity computation; user preference based visual word weighting [44] is developed to make the image similarity computed based on visual words more consistent with users' preferences or habits.
C1 [Tian, Qi] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA.
   [Zhang, Shiliang] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
   [Zhou, Wengang] Univ Sci & Technol China, EEIS Dept, Hefei 230027, Peoples R China.
   [Ji, Rongrong] Harbin Inst Technol, Harbin 150001, Heilongjiang, Peoples R China.
   [Ni, Bingbing] Natl Univ Singapore, Singapore 117576, Singapore.
   [Sebe, Nicu] Univ Trent, Dept Informat Engn & Comp Sci, I-38100 Trento, Italy.
C3 University of Texas System; University of Texas at San Antonio (UTSA);
   Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Harbin Institute of Technology; National University of
   Singapore; University of Trento
RP Tian, Q (corresponding author), Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA.
EM qitian@cs.utsa.edu; slzhang@jdl.ac.cn; zhwg@mail.ustc.edu.cn;
   rrji@hit.edu.cn; g0501096@nus.edu.sg; sebe@disi.unitn.it
RI Sebe, Niculae/KEC-2000-2024
OI Sebe, Niculae/0000-0002-6597-7248
FU NSF [IIS 1052851]; Akiira Media Systems, Inc.; FIRB SPATTERN project;
   FP7 IP GLOCAL European project
FX This work is supported in part by NSF IIS 1052851 and by Akiira Media
   Systems, Inc. The work of Nicu Sebe has been supported by the FP7 IP
   GLOCAL European project and by the FIRB S-PATTERN project.
CR Agarwal S., 2002, ECCV
   [Anonymous], QUERY LOG AWAR UNPUB
   [Anonymous], 2008, 2008 2 INT S SYSTEMS
   [Anonymous], 2007, ICCV
   [Anonymous], ICASSP
   [Anonymous], 2007, CVPR
   [Anonymous], 2000, Springer Series in Information Sciences
   [Anonymous], 2007, CVPR
   [Anonymous], 2007, IJCV
   [Anonymous], 2007, CVPR
   [Anonymous], ACM WORKSH LSMRM
   [Anonymous], T PAMI
   [Anonymous], ICASSP
   [Anonymous], TKKFA601 HELS I TECH
   [Anonymous], 2009, WWW
   [Anonymous], ICCV
   [Anonymous], 2009, CVPR
   [Anonymous], 2008, CVPR
   [Anonymous], ACM INT C IM VID RET
   [Anonymous], ACM WORKSH LSMRM
   [Anonymous], ICASSP
   [Anonymous], 2009, CVPR
   [Anonymous], 2008, NIPS
   [Anonymous], CVPR
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], 2007, CVPR
   [Anonymous], 2007, CVPR
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], CVPR
   [Anonymous], ICME
   [Anonymous], ACM SIGIR
   [Anonymous], 2005, ICCV
   [Anonymous], ICCV
   [Anonymous], 2001, IJCV
   [Anonymous], 1983, INTRO MODERN INFORM
   [Anonymous], CVPR
   [Anonymous], ECCV
   [Anonymous], 2009, LECT NOTES COMPUT SC
   [Anonymous], CVPR
   [Anonymous], S THEOR COMP
   [Anonymous], 2008, CVPR
   [Anonymous], 2008, ECCV
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Brin S., 1998, WWW
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Duygulu Pinar., 2002, ECCV
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Globerson A., 2006, ADV NEURAL INFORM PR, P451
   Grauman K., 2007, NIPS
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   Kim Gunhee., 2008, ACM MIR
   Lazebnik S, 2009, IEEE T PATTERN ANAL, V31, P1294, DOI 10.1109/TPAMI.2008.138
   Leibe B., 2004, ECCV
   Liu C., 2009, CVPR
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J., 2002, BMVC
   Moosmann F., 2006, NIPS
   Moosmann F, 2008, IEEE T PATTERN ANAL, V30, P1632, DOI 10.1109/TPAMI.2007.70822
   Nister David, 2006, CVPR
   Perronnin F, 2008, IEEE T PATTERN ANAL, V30, P1243, DOI 10.1109/TPAMI.2007.70755
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Savarese S., 2006, P 2006 IEEE COMPUTER, V2, P2033, DOI DOI 10.1109/CVPR.2006.102
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Wang F, 2008, ADVANCES IN MATRIX THEORY AND ITS APPLICATIONS, VOL 1, P238
   Xu D, 2008, IEEE T PATTERN ANAL, V30, P1985, DOI 10.1109/TPAMI.2008.129
   Yates R. B., 1999, MODERN INFORM RETRIE
   Yuan J, 2007, PROC CVPR IEEE, P1930, DOI 10.1109/CVPR.2007.383222
   Zhang S., 2010, ACM Multimedia
   Zheng Y, 2008, CVPR, P1
   Zhou W., 2010, ACM MULTIMEDIA
NR 74
TC 13
Z9 20
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 2
SI SI
BP 441
EP 477
DI 10.1007/s11042-010-0636-6
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 709WO
UT WOS:000286472300003
DA 2024-07-18
ER

PT J
AU Goffredo, M
   Bouchrika, I
   Carter, JN
   Nixon, MS
AF Goffredo, Michela
   Bouchrika, Imed
   Carter, John N.
   Nixon, Mark S.
TI Performance analysis for automated gait extraction and recognition in
   multi-camera surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait analysis; Gait recognition; Biometrics; Multi-view; Surveillance;
   Object handover
AB Many studies have confirmed that gait analysis can be used as a new biometrics. In this research, gait analysis is deployed for people identification in multi-camera surveillance scenarios. We present a new method for viewpoint independent markerless gait analysis that does not require camera calibration and works with a wide range of walking directions. These properties make the proposed method particularly suitable for gait identification in real surveillance scenarios where people and their behaviour need to be tracked across a set of cameras. Tests on 300 synthetic and real video sequences, with subjects walking freely along different walking directions, have been performed. Since the choice of the cameras' characteristics is a key-point for the development of a smart surveillance system, the performance of the proposed approach is measured with respect to different video properties: spatial resolution, frame-rate, data compression and image quality. The obtained results show that markerless gait analysis can be achieved without any knowledge of camera's position and subject's pose. The extracted gait parameters allow recognition of people walking from different views with a mean recognition rate of 92.2% and confirm that gait can be effectively used for subjects' identification in a multi-camera surveillance scenario.
C1 [Goffredo, Michela; Bouchrika, Imed; Carter, John N.; Nixon, Mark S.] Univ Southampton, Sch Elect & Comp Sci, Southampton SO17 1BJ, Hants, England.
C3 University of Southampton
RP Bouchrika, I (corresponding author), Univ Southampton, Sch Elect & Comp Sci, Southampton SO17 1BJ, Hants, England.
EM mg2@ecs.soton.ac.uk; ib04r@ecs.soton.ac.uk; jnc@ecs.soton.ac.uk;
   msn@ecs.soton.ac.uk
RI Goffredo, Michela/AAC-3464-2019; Nixon, Mark S/F-7406-2014; Goffredo,
   Michela/K-8805-2016; Bouchrika, Imed/F-1105-2015
OI Goffredo, Michela/0000-0002-2651-8479; Nixon, Mark/0000-0002-9174-5934;
   Bouchrika, Imed/0000-0001-6285-9361
FU European Union [ICT FP7-216465]
FX This research is supported by the SCOVIS project (ICT FP7-216465) funded
   by European Union under the seventh research program.
CR [Anonymous], P IEEE C SOC C COMP
   [Anonymous], 2006, CASIA gait database
   BenAbdelkader C, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P267, DOI 10.1109/AFGR.2002.1004165
   Bhanu B, 2003, LECT NOTES COMPUT SC, V2688, P600
   Black J, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P169, DOI 10.1109/MOTION.2002.1182230
   BOUCHRIKA I, 2007, INT C COMP VIS SYST
   BOUCHRIKA I, 2007, LNCS, V4418
   CAI Y, 2007, ACCV 1, P843
   Chau T, 2001, GAIT POSTURE, V13, P49, DOI 10.1016/S0966-6362(00)00094-1
   CHILGUNDE A, 2004, BRIT MACH VIS C
   Collins RT, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P366, DOI 10.1109/AFGR.2002.1004181
   CUTTING JE, 1977, B PSYCHONOMIC SOC, V9, P353, DOI 10.3758/BF03337021
   DEMPSTER WT, 1967, AM J ANAT, V120, P33, DOI 10.1002/aja.1001200104
   FISHER R, 2002, SELF ORG RANDOMLY PL, P146
   GILBERT A, 2006, TRACKING OBJECTS CAM, P125
   GOFFREDO M, 2007, LNCS, V4778
   GOFFREDO M, 2008, P IEEE C AUT FAC GES
   GROSS R, 2001, CMUR1TR0118
   Haralick R. M., 1992, COMPUTER ROBOT VISIO, V1
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Huang PS, 1999, ARTIF INTELL ENG, V13, P359, DOI 10.1016/S0954-1810(99)00008-4
   Huang T, 1997, INT JOINT CONF ARTIF, P1276
   Ilie A, 2005, IEEE I CONF COMP VIS, P1268, DOI 10.1109/ICCV.2005.88
   Javed O, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P952
   Kale A, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P143, DOI 10.1109/AVSS.2003.1217914
   KANG S, 2001, SPIE, P27, DOI DOI 10.1117/12.424949
   Khan S, 2003, IEEE T PATTERN ANAL, V25, P1355, DOI 10.1109/TPAMI.2003.1233912
   Makris D, 2004, PROC CVPR IEEE, P205
   Middleton L, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P723, DOI 10.1109/IROS.2006.282619
   MURRAY MP, 1964, J BONE JOINT SURG AM, V46, P335, DOI 10.2106/00004623-196446020-00009
   Niu CW, 2006, INT C PATT RECOG, P944
   Nixon M., 2007, FEATURE EXTRACTION I
   Nixon MS, 2006, P IEEE, V94, P2013, DOI 10.1109/JPROC.2006.886018
   Orrite-Uruñuela C, 2004, INT C PATT RECOG, P244, DOI 10.1109/ICPR.2004.1333749
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 2002, INT C PATT RECOG, P385, DOI 10.1109/ICPR.2002.1044731
   Rahimi A, 2004, PROC CVPR IEEE, P187
   SARDIS M, 2009, 5 C ART INT APPL INN
   Shutler J.D., 2002, 4th International Conference on Recent Advances in Soft Computing, P66
   Stillman S., 2001, Proceedings of the 2001 Workshop on Perceptive User Interfaces, PUI'01, (New York, NY, USA), P1
   Tieu K, 2005, IEEE I CONF COMP VIS, P1842
   Veres GV, 2004, PROC CVPR IEEE, P776
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wang L, 2003, IEEE T IMAGE PROCESS, V12, P1120, DOI 10.1109/TIP.2003.815251
   Yamada Y., 1999, Proceedings IEEE 33rd Annual 1999 International Carnahan Conference on Security Technology (Cat. No.99CH36303), P440, DOI 10.1109/CCST.1999.797952
   Zhang R, 2007, IMAGE VISION COMPUT, V25, P321, DOI 10.1016/j.imavis.2005.10.007
NR 46
TC 35
Z9 40
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2010
VL 50
IS 1
SI SI
BP 75
EP 94
DI 10.1007/s11042-009-0378-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 616HE
UT WOS:000279198900005
DA 2024-07-18
ER

PT J
AU Glantz, A
   Krutz, A
   Sikora, T
   Nunes, P
   Pereira, F
AF Glantz, Alexander
   Krutz, Andreas
   Sikora, Thomas
   Nunes, Paulo
   Pereira, Fernando
TI Automatic MPEG-4 sprite coding-Comparison of integrated object
   segmentation algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MPEG-4 Visual; Global motion estimation; Background modeling; Object
   segmentation; Sprite coding
ID GLOBAL MOTION ESTIMATION; VIDEO; IMAGE
C1 [Glantz, Alexander; Krutz, Andreas; Sikora, Thomas] Tech Univ Berlin, Commun Syst Grp, Berlin, Germany.
   [Nunes, Paulo] Inst Super Ciencias Trabalho & Empresa, Inst Telecommun, Lisbon, Portugal.
   [Pereira, Fernando] Inst Super Tecn, Inst Telecommun, Lisbon, Portugal.
C3 Technical University of Berlin; Universidade de Lisboa; Instituto
   Universitario de Lisboa; Instituto de Telecomunicacoes; Universidade de
   Lisboa; Instituto de Telecomunicacoes
RP Glantz, A (corresponding author), Tech Univ Berlin, Commun Syst Grp, Berlin, Germany.
EM glantz@nue.tu-berlin.de; krutz@nue.tu-berlin.de;
   sikora@nue.tu-berlin.de; paulo.nunes@lx.it.pt; fp@lx.it.pt
RI Glantz, Alexander/B-1209-2010; Pereira, Fernando/K-4046-2012; Nunes,
   Paulo/AAG-7212-2020; Pereira, Fernando/HNR-7786-2023
OI Nunes, Paulo/0000-0003-3982-5723; Bernardo Pereira, Fernando
   Manuel/0000-0001-6100-947X
CR [Anonymous], THESIS EINDHOVEN U T
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Baker S, 2001, PROC CVPR IEEE, P1090
   Calderbank AR, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P596, DOI 10.1109/ICIP.1997.647983
   Dufaux F, 2000, IEEE T IMAGE PROCESS, V9, P497, DOI 10.1109/83.826785
   FARIN D, 2004, SPIE VISUAL COMMUNIC
   FARIN D, 2004, MULTIMEDIA EXPO 2004, V1, P343
   Farin D, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P67
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Haller M, 2009, 2009 10TH INTERNATIONAL WORKSHOP ON IMAGE ANALYSIS FOR MULTIMEDIA INTERACTIVE SERVICES, P49, DOI 10.1109/WIAMIS.2009.5031429
   KRUTZ A, 2008, 50 INT S ELMAR 2008, V2, P459
   KRUTZ A, 2009, P IEEE INT C AC SPEE
   KRUTZ A, 2007, P 8 INT WORKSH IM AN, P35
   KRUTZ A, 2008, INT WORKSH LOC NONL
   KRUTZ A, 2007, PICT COD S LISB PORT
   Krutz A, 2006, IEEE IMAGE PROC, P353, DOI 10.1109/ICIP.2006.313166
   Kunter M., 2008, THESIS TU BERLIN
   KUNTER M, 2007, IEEE INT C IM PROC I
   Kunter M, 2007, PROC SPIE, V6508, DOI 10.1117/12.704145
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   MECH R, 1997, P ICASSP 97, V4, P2657
   Pereira F., 2002, IMSC Press multimedia series
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Sikora T, 2005, P IEEE, V93, P6, DOI 10.1109/JPROC.2004.839601
   Sikora T, 1997, IEEE T CIRC SYST VID, V7, P19, DOI 10.1109/76.554415
   Smolic A, 1999, IEEE T CIRC SYST VID, V9, P1227, DOI 10.1109/76.809158
   Ten Daubechies I., 1992, lecture on wavelets
   Tomasi C, 1991, DETECTION TRACKING P
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 31
TC 8
Z9 9
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2010
VL 49
IS 3
SI SI
BP 483
EP 512
DI 10.1007/s11042-010-0469-3
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 608ZF
UT WOS:000278623800006
DA 2024-07-18
ER

PT J
AU Tagliasacchi, M
   Valenzise, G
   Naccari, M
   Tubaro, S
AF Tagliasacchi, Marco
   Valenzise, Giuseppe
   Naccari, Matteo
   Tubaro, Stefano
TI A reduced-reference structural similarity approximation for videos
   corrupted by channel errors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reduced reference video quality assessment; Distributed source coding
ID QUALITY ASSESSMENT
AB In this paper we propose a reduced-reference quality assessment algorithm which computes an approximation of the Structural SIMilarity (SSIM) metrics exploiting coding tools provided by the distributed source coding theory. The algorithm has been tested to evaluate the quality of decoded video bitstreams after transmission over error-prone networks. We evaluate the accuracy of the proposed quality assessment algorithm by measuring the Pearson's correlation coefficient between the structural similarity metrics computed in full-reference mode and the one provided by the proposed reduced-reference algorithm. The proposed reduced-reference algorithm achieves good correlation values (higher than 0.85 with packet loss rate equal up to 2.5%).
C1 [Tagliasacchi, Marco; Valenzise, Giuseppe; Naccari, Matteo; Tubaro, Stefano] Politecn Milan, Dipartimento Elettron & Informat, I-20133 Milan, Italy.
C3 Polytechnic University of Milan
RP Tagliasacchi, M (corresponding author), Politecn Milan, Dipartimento Elettron & Informat, P Zza Leonardo da Vinci,32, I-20133 Milan, Italy.
EM tagliasa@elet.polimi.it; valenzise@elet.polimi.it;
   matteo.naccari@polimi.it; tubaro@elet.polimi.it
FU European Commission
FX This work was presented in part in reference [22] and has been developed
   within VISNET II, a European Network of Excellence
   (http://www.visnet-noe.org), funded under the European Commission IST
   FP6 programme.
CR [Anonymous], 1449610 ITUT ISOIEC
   Bernardini R, 2008, SIGNAL PROCESS-IMAGE, V23, P391, DOI 10.1016/j.image.2008.04.004
   Caviedes J, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P53, DOI 10.1109/ICIP.2002.1038901
   CHONO K, 2008, IEEE INT C MULT EXP
   Chua TK, 2006, IEEE NETWORK, V20, P14, DOI 10.1109/MNET.2006.273116
   Corriveau P., 2003, FINAL REPORT VIDEO Q
   FARBER N, 1999, IEEE INT C IM PROC K
   Farias MCQ, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P469, DOI 10.1109/ICIP.2002.1039007
   GILBERT EN, 1960, BELL SYST TECH J, V39, P1253, DOI 10.1002/j.1538-7305.1960.tb03959.x
   Girod B, 1999, P IEEE, V87, P1707, DOI 10.1109/5.790632
   Girod Bernd, 1993, P207
   LIU H, 2008, P INT C AC SPEECH SI
   Marziliano P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P57, DOI 10.1109/ICIP.2002.1038902
   Masry M, 2006, IEEE T CIRC SYST VID, V16, P260, DOI 10.1109/TCSVT.2005.861946
   PINSON M, 2005, 1 INT WORKSH VID PRO
   Reibman AR, 2004, IEEE T MULTIMEDIA, V6, P327, DOI 10.1109/TMM.2003.822785
   Richardson I.E. G., 2002, VIDEO CODEC DESIGN
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   Sugimoto O., 2000, Proceedings of the SPIE - The International Society for Optical Engineering, V4310, P932, DOI 10.1117/12.411876
   SULLIVAN GJ, 2003, JVT1049
   VALENZISE G, 2008, P ACM INT C MULT VAN
   Varodayan D, 2006, SIGNAL PROCESS, V86, P3123, DOI 10.1016/j.sigpro.2006.03.012
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WANG Z, 2005, HUM VIS EL IM 10 C S, P17
   WANG Z, 2000, BLIND MEASUREMENT BL, V3
   Wang Z., 2003, Objective video quality assessment, P1041
   WEBSTER AA, 1993, P SOC PHOTO-OPT INS, V1913, P15, DOI 10.1117/12.152700
   Wolf S, 1999, P SOC PHOTO-OPT INS, V3845, P266, DOI 10.1117/12.371210
   Wu HR, 1997, IEEE SIGNAL PROC LET, V4, P317, DOI 10.1109/97.641398
   YAMADA T, 2007, IEEE PACKET VIDEO
   YAMADA T, 2007, 3 INT WORKSH VID PRO
NR 32
TC 16
Z9 20
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2010
VL 48
IS 3
SI SI
BP 471
EP 492
DI 10.1007/s11042-010-0473-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 587VP
UT WOS:000277023100007
DA 2024-07-18
ER

PT J
AU Ballan, L
   Bertini, M
   Del Bimbo, A
   Serra, G
AF Ballan, Lamberto
   Bertini, Marco
   Del Bimbo, Alberto
   Serra, Giuseppe
TI Semantic annotation of soccer videos by visual instance clustering and
   spatial/temporal reasoning in ontologies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic video annotation; Dynamic pictorial ontology; Content
   descriptor matching; Ontology reasoning; Sports video analysis
ID SPORTS VIDEO; KNOWLEDGE; FRAMEWORK
AB In this paper we present a framework for semantic annotation of soccer videos that exploits an ontology model referred to as Dynamic Pictorially Enriched Ontology, where the ontology, defined using OWL, includes both schema and data. Visual instances are used as matching references for the visual descriptors of the entities to be annotated. Three mechanisms are included to support effective annotation: visual instance clustering-to cluster instances of similar patterns, prototype selection-to select one or more visual representatives of each cluster, dynamic cluster updating-to update clusters and prototypes whenever new knowledge is presented to the ontology. Experimental results show the capability of performing semantic annotation of entities that exhibit a variety of complex changes in visual appearance or of events that show complex motion patterns in the same shot. SWRL rules are used to perform rule-based reasoning over both concepts and concept instances, to improve the quality of the annotation.
C1 [Ballan, Lamberto; Bertini, Marco; Del Bimbo, Alberto; Serra, Giuseppe] Univ Florence, Media Integrat & Commun Ctr, Florence, Italy.
C3 University of Florence
RP Bertini, M (corresponding author), Univ Florence, Media Integrat & Commun Ctr, Florence, Italy.
EM ballan@dsi.unifi.it; bertini@dsi.unifi.it; delbimbo@dsi.unifi.it;
   serra@dsi.unifi.it
RI Ballan, Lamberto/B-3450-2008; Bertini, Marco/X-1325-2019; Serra,
   Giuseppe/M-3572-2015
OI Ballan, Lamberto/0000-0003-0819-851X; Bertini,
   Marco/0000-0002-1364-218X; Serra, Giuseppe/0000-0002-4269-4501; DEL
   BIMBO, ALBERTO/0000-0002-1052-8322
FU European Commission [G038-507618]; VidiVideo [FP6-045547]
FX The authors are grateful to Sport System Europe s.r.l., Bologna, Italy,
   for having provided the large set of sports video used for the
   experimental validation of this research. This work was partially
   supported by the Information Society Technologies (IST) Program of the
   European Commission DELOS Network of Excellence on Digital Libraries
   (Contract G038-507618) and by the VidiVideo Project (Contract
   FP6-045547).
CR [Anonymous], P 15 ACM C MULT
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], 2006, 2006 Fifa World Cup Germany
   [Anonymous], P INT WORKSH MULT IN
   [Anonymous], 1990, Building Large Knowledge-Based Systems: Representation and Inference in the CYC Project
   Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004
   ASSFALG J, 2002, P IEEE C MULT EXP IC
   BAGDANOV AD, 2007, P ACM INT WORKSH MUL
   Bagdanov AD, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P218, DOI 10.1109/AVSS.2007.4425313
   Bai L, 2007, P INT WORKSH IM AN M
   Bai L, 2007, IMVIP 2007: INTERNATIONAL MACHINE VISION AND IMAGE PROCESSING CONFERENCE, PROCEEDINGS, P117, DOI 10.1109/IMVIP.2007.13
   BALLAN L, 2007, P ACM INT C IM VID R
   Bertini M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1429
   BERTINI M, 2006, P ACM MM 06 SANT BAR, P663
   BLOEHDORN S, 2004, P EWIMT LOND
   Buitelaar P., 2006, P INT C LANG RES EV
   Dasiopoulou S, 2005, IEEE T CIRC SYST VID, V15, P1210, DOI 10.1109/TCSVT.2005.854238
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   François ARJ, 2005, IEEE MULTIMEDIA, V12, P76, DOI 10.1109/MMUL.2005.87
   Grana C, 2007, IEEE T CIRC SYST VID, V17, P483, DOI 10.1109/TCSVT.2006.888818
   HAUBOLD A, 2007, P INT C IM VID RETR, P178
   HAUPTMANN A, 2007, P IEEE INT C SEM COM, P79
   Huang CL, 2006, IEEE T MULTIMEDIA, V8, P749, DOI 10.1109/TMM.2006.876289
   KASUTANI E, 2001, P IEEE INT C IM PROC
   Kokaram A, 2006, IEEE SIGNAL PROC MAG, V23, P47, DOI 10.1109/MSP.2006.1621448
   Leonardi R, 2002, IEEE MULTIMEDIA, V9, P44, DOI 10.1109/93.998057
   Liu J, 2009, PATTERN RECOGN LETT, V30, P103, DOI 10.1016/j.patrec.2008.02.011
   Luo M, 2003, P ICICS PCM
   Masolo C., 2002, The wonderweb library of foundational ontologies
   Mei T, 2008, MULTIMED TOOLS APPL, V40, P89, DOI 10.1007/s11042-007-0186-8
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Neumann B, 2006, LECT NOTES COMPUT SC, V3948, P247, DOI 10.1007/11414353_15
   Peraldi SE, 2007, PROCEEDINGS OF THE IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, P374, DOI 10.1109/WI.2007.106
   QASEMIZADEH B, 2006, P SEM KNOWL GRID GUI
   Sadlier DA, 2005, IEEE T CIRC SYST VID, V15, P1225, DOI 10.1109/TCSVT.2005.854237
   Sedgewick R., 1983, ALGORITHMS
   Shyu ML, 2008, IEEE T MULTIMEDIA, V10, P252, DOI 10.1109/TMM.2007.911830
   Simou N, 2006, LECT NOTES COMPUT SC, V3893, P51
   Snoek CGM, 2007, IEEE T MULTIMEDIA, V9, P975, DOI 10.1109/TMM.2007.900156
   Snoek CGM, 2005, IEEE T MULTIMEDIA, V7, P638, DOI 10.1109/TMM.2005.850966
   Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5
   Tsinaraki C, 2005, MULTIMED TOOLS APPL, V26, P299, DOI 10.1007/s11042-005-0894-x
   UTSUMI O, 2002, P IEEE INT C MULT EX
   Watve A, 2008, PATTERN RECOGN LETT, V29, P994, DOI 10.1016/j.patrec.2008.01.022
   WEI X, 2007, P ACM MULT
   WU Y, 2004, P IEEE INT C MULT EX
   Xie LX, 2004, PATTERN RECOGN LETT, V25, P767, DOI 10.1016/j.patrec.2004.01.005
   Xu CS, 2008, IEEE T MULTIMEDIA, V10, P421, DOI 10.1109/TMM.2008.917346
   XU P, 2001, P IEEE INT C MULT EX
   YANG Y, 2008, P IEEE INT S CIRC SY
   YE Q, 2005, P VIS COMM IM PROC V
   YU X, 2005, P IEEE ICME
NR 53
TC 23
Z9 24
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2010
VL 48
IS 2
BP 313
EP 337
DI 10.1007/s11042-009-0342-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 584AY
UT WOS:000276723600005
DA 2024-07-18
ER

PT J
AU Huang, SY
   Lee, YK
   Bell, G
   Ou, ZH
AF Huang, Shih-Yu
   Lee, Yeuan-Kuen
   Bell, Graeme
   Ou, Zhan-he
TI An efficient segmentation algorithm for CAPTCHAs with line cluttering
   and character warping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CAPTCHA; Segmentation; Recognition; Turing test
AB A CAPTCHA is a test designed to distinguish computer programs from human beings, in order to prevent the abuse of networked resources. Academic research into CAPTCHAs includes designing friendly and secure CAPTCHA systems and defeating existing CAPTCHA systems. Traditionally, defeating a CAPTCHA test requires two procedures: segmentation and recognition. Recent research shows that the problem of segmentation is much harder than recognition. In this paper, two new segmentation techniques called projection and middle-axis point separation are proposed for CAPTCHAs with line cluttering and character warping. Experimental results show the proposed techniques can achieve segmentation rates of about 75%.
C1 [Huang, Shih-Yu; Lee, Yeuan-Kuen; Bell, Graeme; Ou, Zhan-he] Ming Chuan Univ, Dept Comp Sci & Informat Engn, Taipei 333, Taiwan.
C3 Ming Chuan University
RP Huang, SY (corresponding author), Ming Chuan Univ, Dept Comp Sci & Informat Engn, 5 Teh Ming Rd, Taipei 333, Taiwan.
EM syhuang@mcu.edu.tw
CR [Anonymous], P 15 ACM C COMP COMM
   Baird HS, 2005, PROC SPIE, V5676, P191, DOI 10.1117/12.590944
   BLUM M, 2000, COMMUNICATION
   Chellapilla K., 2005, ADV NEURAL INF PROCE, V17, P265
   CHELLAPILLA K, 2005, P 3 C E MAIL ANT
   Coates AL, 2001, PROC INT CONF DOC, P1154, DOI 10.1109/ICDAR.2001.953966
   Hoque ME, 2006, PROCEEDINGS OF THE IEEE SOUTHEASTCON 2006, P165, DOI 10.1109/second.2006.1629343
   HUANG SY, 2008, P 2008 INT C SIGN IM
   MISRA D, 2006, P ADV INT C TEL INT, P122
   Mori G, 2003, PROC CVPR IEEE, P134
   Moy G, 2004, PROC CVPR IEEE, P23
   Shirali-Shahreza M, 2006, ITI 2006: PROCEEDINGS OF THE 28TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY INTERFACES, P475, DOI 10.1109/ITI.2006.1708527
NR 12
TC 21
Z9 25
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2010
VL 48
IS 2
BP 267
EP 289
DI 10.1007/s11042-009-0341-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 584AY
UT WOS:000276723600003
DA 2024-07-18
ER

PT J
AU Schaefer, G
AF Schaefer, Gerald
TI A next generation browsing environment for large image repositories
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image databases; Content-based image retrieval; Image database browsing;
   Hue sphere
AB Next generation environments will change the way people work and live as they will provide new advances in areas ranging from remote work and education, e-commerce, gaming to information-on-demand. In many of these applications intelligent interpretation of multimedia data such as image, video and audio resources is necessary. In this paper we present an effective approach to handling image repositories providing the user with an intuitive interface of visualising and browsing large collections of pictures. Based on the idea of similarity-based organisation of images where images that are visually similar are located close to each other in visualisation space, images are projected onto a sphere with which the user can interact. Rotating the sphere reveals images of different colours while tilting operations focus on brighter or darker images. Large image collections are handled through a hierarchical approach that brings up similar, previously hidden, images when zooming in on an area. Furthermore, the way images are organised can be interactively changed by the user. Our next generation browsing environment has been successfully tested on a large database of several thousand images.
C1 Univ Loughborough, Dept Comp Sci, Loughborough, Leics, England.
C3 Loughborough University
RP Schaefer, G (corresponding author), Univ Loughborough, Dept Comp Sci, Loughborough, Leics, England.
EM g.schaefer@lboro.ac.uk
CR Bartolini I, 2006, MULTIMED TOOLS APPL, V31, P269, DOI 10.1007/s11042-006-0044-0
   CHEN C, 2000, INT C INT INF PROC, P206
   Chen C., 2004, INFORM VISUALIZATION, V2nd
   Chen JY, 2000, IEEE T IMAGE PROCESS, V9, P442, DOI 10.1109/83.826781
   CHEN Y, 2008, INT S SMART GRAPH, P224
   *CIE, 1989, CIE PUBL
   Dontcheva M., 2005, 18 ANN ACM S US INT
   Gomi A, 2008, IEEE INT CONF INF VI, P82, DOI 10.1109/IV.2008.8
   Heesch D, 2004, LECT NOTES COMPUT SC, V2997, P253
   Heesch D, 2008, MULTIMED TOOLS APPL, V40, P261, DOI 10.1007/s11042-008-0207-2
   Keller I, 2001, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P102, DOI 10.1109/IVL.2001.990863
   Krishnamachari S, 1999, IEEE SYMP COMP COMMU, P301, DOI 10.1109/ISCC.1999.780837
   Kruskal JB, 1978, MULTIDIMENSIONAL SCA
   Moghaddam B, 2004, INT J COMPUT VISION, V56, P109, DOI 10.1023/B:VISI.0000004834.62090.74
   Moving Picture Experts Group, 1999, ISOIECJTC1SC29WG11N2
   NAKANO K, 2001, CRYSTENGCOMM, V3, P44
   Nguyen GP, 2008, J VISUAL LANG COMPUT, V19, P203, DOI 10.1016/j.jvlc.2006.09.002
   PLANT W, 2009, C IM PROC COMP VIS P, V1, P248
   PLATT JC, 2002, PHOTOTOC AUTOMATIC C
   RODDEN K, 1999, IEEE S INF VIS, P36
   Rodden K., 2003, P SIGCHI C HUMAN FAC, P409, DOI DOI 10.1145/642611.642682
   Rodden Kerry, 2000, CHALLENGE IMAGE RETR
   RUBNER Y, 1997, IM UND WORKSH, P661
   Ruszala S., 2004, IR MACH VIS IM PROC, P186
   SANGWINE J, 1998, COLOUR IMAGE PROCESS
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   SCHAEFER G, 2005, SPRINGER LECT NOTES, V3804, P279
   Schaefer G, 2006, LECT NOTES COMPUT SC, V4292, P814
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   STRICKER M, 1995, P SOC PHOTO-OPT INS, V2420, P381
   WORRING M, 2007, INT WORKSH MULT INF, P307
NR 31
TC 45
Z9 46
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2010
VL 47
IS 1
BP 105
EP 120
DI 10.1007/s11042-009-0409-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 554LV
UT WOS:000274437400007
DA 2024-07-18
ER

PT J
AU Furini, M
   Geraci, F
   Montangero, M
   Pellegrini, M
AF Furini, Marco
   Geraci, Filippo
   Montangero, Manuela
   Pellegrini, Marco
TI STIMO: STIll and MOving video storyboard for the web scenario
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summary; Video browsing; Clustering; Storyboards
AB In the current Web scenario a video browsing tool that produces on-the-fly storyboards is more and more a need. Video summary techniques can be helpful but, due to their long processing time, they are usually unsuitable for on-the-fly usage. Therefore, it is common to produce storyboards in advance, penalizing users customization. The lack of customization is more and more critical, as users have different demands and might access the Web with several different networking and device technologies. In this paper we propose STIMO, a summarization technique designed to produce on-the-fly video storyboards. STIMO produces still and moving storyboards and allows advanced users customization (e.g., users can select the storyboard length and the maximum time they are willing to wait to get the storyboard). STIMO is based on a fast clustering algorithm that selects the most representative video contents using HSV frame color distribution. Experimental results show that STIMO produces storyboards with good quality and in a time that makes on-the-fly usage possible.
C1 [Furini, Marco] Univ Modena & Reggio Emilia, Reggio Emilia, Italy.
   [Geraci, Filippo; Pellegrini, Marco] IIT CNR Inst, Pisa, Italy.
   [Montangero, Manuela] Univ Modena & Reggio Emilia, Modena, Italy.
C3 Universita di Modena e Reggio Emilia; Consiglio Nazionale delle Ricerche
   (CNR); Istituto di Informatica e Telematica (IIT-CNR); Universita di
   Modena e Reggio Emilia
RP Furini, M (corresponding author), Univ Modena & Reggio Emilia, Reggio Emilia, Italy.
EM marco.furini@unimore.it; filippo.geraci@iit.cnr.it;
   montangero.manuela@unimo.it; marco.pellegrini@iit.cnr.it
RI Geraci, Filippo/IVU-7201-2023; Pellegrini, Marco/AAX-9568-2020;
   MONTANGERO, Manuela/O-2400-2016; Furini, Marco/O-2867-2016
OI MONTANGERO, Manuela/0000-0001-8827-5495; Pellegrini,
   Marco/0000-0003-3151-9481; Furini, Marco/0000-0003-1094-6521; GERACI,
   FILIPPO/0000-0001-6993-6761
CR Bouch A., 2000, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P297, DOI DOI 10.1145/332040.332447
   Charikar Moses S., 2002, P 34 ANN ACM S THEOR, P380, DOI DOI 10.1145/509907.509965
   Feder T., 1988, Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing, P434, DOI 10.1145/62212.62255
   Ferman AM, 2003, IEEE T MULTIMEDIA, V5, P244, DOI 10.1109/TMM.2003.811617
   FURINI M, 2008, P IEEE CONS COMM NET
   FURINI M, 2007, P IEEE INT C COMM IC
   Furini M, 2007, P 6 ACM INT C IM VID, P635
   Gao Y, 2008, P 2008 ACM INT C CON, P135, DOI [10.1145/1386352.1386375, DOI 10.1145/1386352.1386375]
   Geraci F, 2006, INTERNET MATH, V3, P413, DOI 10.1080/15427951.2006.10129133
   Girgensohn A, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P77
   Gong YH, 2003, MULTIMEDIA SYST, V9, P157, DOI 10.1007/s00530-003-0086-3
   GONZALEZ TF, 1985, THEOR COMPUT SCI, V38, P293, DOI 10.1016/0304-3975(85)90224-5
   HADI Y, 2006, P ACM S APPL COMP, P1400
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P1280, DOI 10.1109/76.809162
   HOCHBAUM DS, 1985, MATH OPER RES, V10, P180, DOI 10.1287/moor.10.2.180
   INDYK S, 1999, P ACM S THEOR COMP, P428
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   NAM J, 1999, IEEE 3 WORKSH MULT S, P117
   Phillips SJ, 2002, LECT NOTES COMPUT SC, V2409, P166
   Ren J., 2008, Proceedings of the TRECVID BBC Rushes Summarization Workshop (TVS 2008) at ACM Multimedia, P26, DOI DOI 10.1145/1463563.1463566
   SHAHRARAY B, 1995, P SOC PHOTO-OPT INS, V2417, P512, DOI 10.1117/12.206078
   Tan YP, 2003, ELECTRON LETT, V39, P841, DOI 10.1049/el:20030536
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   VANDENEIJKEL GC, 2000, MOVING STORYBOARDS N
   Xie XN, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P203, DOI 10.1109/ISECS.2008.118
   ZHU L, 2008, P 2 ACM TRECVID VID, P21
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 28
TC 169
Z9 193
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2010
VL 46
IS 1
BP 47
EP 69
DI 10.1007/s11042-009-0307-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 537DQ
UT WOS:000273093600003
DA 2024-07-18
ER

PT J
AU Lin, L
   Wang, YT
   Liu, Y
   Xiong, CM
   Zeng, K
AF Lin, Liang
   Wang, Yongtian
   Liu, Yue
   Xiong, Caiming
   Zeng, Kun
TI Marker-less registration based on template tracking for augmented
   reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Marker-less registration; Virtual tracking; Motion
   estimation
ID VISION
AB Accurate 3D registration is a key issue in the Augmented Reality (AR) applications, particularly where are no markers placed manually. In this paper, an efficient markerless registration algorithm is presented for both outdoor and indoor AR system. This algorithm first calculates the correspondences among frames using fixed region tracking, and then estimates the motion parameters on projective transformation following the homography of the tracked region. To achieve the illumination insensitive tracking, the illumination parameters are solved jointly with motion parameters in each step. Based on the perspective motion parameters of the tracked region, the 3D registration, the camera's pose and position, can be calculated with calibrated intrinsic parameters. A marker-less AR system is described using this algorithm, and the system architecture and working flow are also proposed. Experimental results with comparison quantitatively demonstrate the correctness of the theoretical analysis and the robustness of the registration algorithm.
C1 [Lin, Liang; Wang, Yongtian; Liu, Yue] Beijing Inst Technol, Sch Informat Sci & Technol, Beijing 100081, Peoples R China.
   [Xiong, Caiming; Zeng, Kun] Huazhong Univ Sci & Technol, Inst Pattern Recognit & Artificial Intelligence, Wuhan 430074, Peoples R China.
C3 Beijing Institute of Technology; Huazhong University of Science &
   Technology
RP Lin, L (corresponding author), Beijing Inst Technol, Sch Informat Sci & Technol, Beijing 100081, Peoples R China.
EM linliang@bit.edu.cn; wyt@bit.edu.cn; bithxm@bit.edu.cn;
   Cmxiong.lhi@gmail.com; zengkun@gmail.com
FU National Basic Research Program of China [2006AA01Z339]; National
   Natural Science Foundation of China [60673198]; China Postdoctoral
   Science Foundation [20080430313]
FX This project is supported by National Basic Research Program of China
   (National 863 Program, Grant No. 2006AA01Z339), National Natural Science
   Foundation of China (Grant No. 60673198), and China Postdoctoral Science
   Foundation funded project (Grant No. 20080430313). The author would like
   to thank Ke Yang for contributive comments and assistance in
   experiments.
CR Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma R, 1999, P IEEE VIRT REAL ANN, P252, DOI 10.1109/VR.1999.756959
   BAJURA M, 1992, COMP GRAPH, V26, P203, DOI 10.1145/142920.134061
   Behringer R, 1999, P IEEE VIRT REAL ANN, P244, DOI 10.1109/VR.1999.756958
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   BOBICK AF, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P382
   Chen BC, 2001, FINITE ELEM ANAL DES, V37, P57, DOI 10.1016/S0168-874X(00)00021-4
   Darrell T, 1996, PROC CVPR IEEE, P67, DOI 10.1109/CVPR.1996.517055
   Dorfmüller K, 1999, COMPUT GRAPH-UK, V23, P795, DOI 10.1016/S0097-8493(99)00105-3
   Hager GD, 1996, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.1996.517104
   HU X, 2005, P IEEE ACM INT S MIX, V1, P182
   Hutchinson S, 1996, IEEE T ROBOTIC AUTOM, V12, P651, DOI 10.1109/70.538972
   Jafari S., 2005, INT J HYBRID INTELLI, V2, P269
   Kutulakos KN, 1998, IEEE T VIS COMPUT GR, V4, P1, DOI 10.1109/2945.675647
   La Cascia M, 2000, IEEE T PATTERN ANAL, V22, P322, DOI 10.1109/34.845375
   Li XW, 2005, LECT NOTES COMPUT SC, V3482, P266
   Li Y, 2007, J COMPUT SCI TECH-CH, V22, P890, DOI 10.1007/s11390-007-9100-0
   Lin L, 2006, IEE P-VIS IMAGE SIGN, V153, P57, DOI 10.1049/ip-vis:20045181
   OKUMA T, 2000, P INT C PATT REC, V4, P4482
   Ribo M, 2001, IEEE IMTC P, P1932, DOI 10.1109/IMTC.2001.929537
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Tang SL, 1998, IEEE ENG MED BIOL, V17, P49, DOI 10.1109/51.677169
   UENOHARA M, 1995, COMPUT BIOL MED, V25, P249, DOI 10.1016/0010-4825(94)00045-R
   You SY, 2001, P IEEE VIRT REAL ANN, P71, DOI 10.1109/VR.2001.913772
   ZAGORANSKI S, 2003, EUROCON 2003 COMPUTE, V2, P339
NR 25
TC 18
Z9 19
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2009
VL 41
IS 2
BP 235
EP 252
DI 10.1007/s11042-008-0227-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 387NI
UT WOS:000261958500004
DA 2024-07-18
ER

PT J
AU You, SD
   Chen, WK
AF You, Shingchern D.
   Chen, Woei-Kae
TI Efficient quantization algorithm for real-time MP-3 encoders
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MP-3; Real-time encoder; Quantization; Digital signal processor; ODG
ID LONG WINDOWS
AB This paper reports an efficient quantization algorithm for the implementation of a real-time MP-3 encoder based on a low-cost digital signal processor. Unlike the well-known nested-loop quantization algorithm, which requires a large and unpredictable amount of iterations, the proposed algorithm uses a single loop with only three iterations to reduce the computational complexity. Since most of the existing quantization algorithms reported in the literature require peak number of iterations higher than three, our approach can effectively reduce the peak computing demand for a real-time encoder. We conduct several experiments (including the ODG rating) to validate the performance of the proposed algorithm, and the results are acceptable. We implement the proposed algorithm on a 16-bit fixed-point digital signal processor, and the encoder requires 35 MIPS of computation for encoding stereo music at 128 kbps.
C1 [You, Shingchern D.; Chen, Woei-Kae] Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan.
C3 National Taipei University of Technology
RP You, SD (corresponding author), Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan.
EM scyou@ntut.edu.tw; wkchen@ntut.edu.tw
RI You, Shingchern/AAG-6401-2020
CR [Anonymous], P IEEE INT C AC SPEE
   Chang FM, 2004, LECT NOTES COMPUT SC, V3333, P151
   *EBU, 2006, 300401 EBU ETSI EN
   *EBU, 2005, 101154 EBU ETSI TR
   *ISO IEC, 1993, 111723 ISOIEC IS
   *ISO IEC, 1998, 138183 ISO IEC IS
   *ITU R, BS1387 ITUR
   *LAME, 2003, LAME VERS 3 97B2
   Oh HO, 2001, IEEE T CONSUM ELECTR, V47, P613, DOI 10.1109/30.964154
   Painter T, 2000, P IEEE, V88, P451, DOI 10.1109/5.842996
   *TEX INSTR, 1993, 25473019721 TEX INST
   Venkataramani B, 2002, DIGITAL SIGNAL PROCE
   WANG X, 2002, SINO EXPOSITIONS, V2, P918
   YANG CK, 2003, P INT C MULT EXP, V1
   Yen CH, 2007, MULTIMED TOOLS APPL, V35, P335, DOI 10.1007/s11042-007-0110-2
   Yu CH, 2002, LECT NOTES COMPUT SC, V2532, P663
NR 16
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2008
VL 40
IS 3
BP 341
EP 359
DI 10.1007/s11042-008-0210-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 360PD
UT WOS:000260068700002
DA 2024-07-18
ER

PT J
AU Yang, CK
   Chiang, WT
AF Yang, Chuan-Kai
   Chiang, Wei-Ting
TI An interactive facial expression generation system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE facial expression generation; active contour; image morphing; music
   analysis
AB How to generate vivid facial expressions by computers has been an interesting and challenging problem for a long time. Some research adopts an anatomical approach by studying the relationships between the expressions and the underlying bones and muscles. On the other hand, MPEG4's SNHC (synthetic/natural hybrid coding) provides mechanisms which allow detailed descriptions of facial expressions and animations. Unlike most existing approaches that ask a user to provide 3D head models, a set of reference images, detailed information of facial feature markers, numerous associated parameters, and/or even non-trivial user assistance, our proposed approach is simple, intuitive and interactive, and most importantly, it is still capable of generating vivid 2D facial expressions. With our system, a user is only required to give a single photo and spend a couple of seconds to roughly mark the positions of eyes, eyebrows and mouth in the photo, and then our system could trace more accurately the contours of these facial features through the technique of active contour. Different expressions can then be generated and morphed via the mesh warping algorithm. Another innovation of this paper is to propose a simple music emotion analysis algorithm, which is coupled with our system to further demonstrate the effectiveness of our facial expression generation. Through such an integration, our system could identify the emotions of a music piece, and display the corresponding emotions via aforementioned synthesized facial expressions. Experimental results show that in general the end-to-end facial generation time, from the time an input photo is given, to the time the final facial expressions are generated, is about 1 min.
C1 [Yang, Chuan-Kai; Chiang, Wei-Ting] Natl Taiwan Univ Sci & Technol, Dept Informat Management, Taipei 106, Taiwan.
C3 National Taiwan University of Science & Technology
RP Yang, CK (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Informat Management, 43 Sec 4,Keelung Rd, Taipei 106, Taiwan.
EM ckyang@cs.ntust.edu.tw
CR [Anonymous], 1998, Proc. SIGGRAPH, DOI 10.1145/280814.280820
   [Anonymous], 1999, THESIS U NEW S WALES
   [Anonymous], 2002, NUMERICAL RECIPES C
   BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003
   Ekman P, 1978, FACIAL ACTION CODING
   FOURNIER A, 1984, ACM T GRAPHIC, V3, P153, DOI 10.1145/357337.357341
   Han X, 2003, IEEE T PATTERN ANAL, V25, P755, DOI 10.1109/TPAMI.2003.1201824
   KARPOUZIS K, 2000, SPIE ELECT IMAGING 2, P443
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   LISCHINSKI D, 2006, SELECTED TOPICS COMP
   Liu ZC, 2001, COMP GRAPH, P271
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Parke F., 1996, COMPUTER FACIAL ANIM
   PARKE FI, 1972, P ANN ACM C
   PIGHIN F, 1998, SIGGRAPH P, P75
   RAOUZAIOU A, 2002, EURASIP J APPL SIG P, P1021
   SCHUBERT E, 2004, P ICAD 04
   Sethian A.J., 1999, Level Set Methods and Fast Marching Methods
   SHUGRINA M, 2006, NPAR 2006, P87
   Smythe D.B., 1990, 1030 ILM COMP GRAPH
   TERZOPOULOS D, 1993, IEEE T PATTERN ANAL, V15, P569, DOI 10.1109/34.216726
   Wang HC, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P958, DOI 10.1109/ICCV.2003.1238452
   Wang MY, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P1352
   Waters K., 1987, ACM SIGGRAPH Comput. Graph., V21, P17
   WILLIAMS DJ, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P592
   Wolberg G., 1990, Digital image warping
   Zhang QS, 2006, IEEE T VIS COMPUT GR, V12, P48, DOI 10.1109/TVCG.2006.9
   Zhang Y, 2003, COMPUT GRAPH FORUM, V22, P159, DOI 10.1111/1467-8659.t01-1-00657
   Zhou C, 2005, PATTERN RECOGN LETT, V26, P2611, DOI 10.1016/j.patrec.2005.06.007
NR 29
TC 14
Z9 14
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2008
VL 40
IS 1
BP 41
EP 60
DI 10.1007/s11042-007-0184-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 339KO
UT WOS:000258576700003
DA 2024-07-18
ER

PT J
AU Sparacino, F
AF Sparacino, Flavia
TI Natural interaction in intelligent spaces: Designing for architecture
   and entertainment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT Workshop on Natural Interaction
CY APR, 2004
CL Florence, ITALY
DE ambient intelligence; intelligent architecture; interactive spaces;
   interactive entertainment
AB The rapid evolution of computers' processing power, progress in projection and display technology, and their low cost, accompanied by recent advances in mathematical modeling, make available to space designers today sophisticated technologies which were once accessible only to research institutions or large companies. Thanks to wireless sensing techniques it is possible to endow a space with perceptual intelligence, and make it aware of how people use it, move in it, or react to it. Intelligent Spaces are relevant for several applications or tasks which range from surveillance to entertainment, from medical rehabilitation to artistic performance, from museum exhibit design to commerce. The author's work focuses on Narrative Spaces which are storytellers, able to articulate an informative or entertaining audio-visual narration for people interactively. Narrative Spaces communicate by use of large scale coordinated projections, sounds and displays whose contents are choreographed by the natural body movements or physical gestures of the people in them. This paper describes the guiding principles and modeling approaches that, according to the author, enable a robust modeling of user input and communication strategies for digital content presentation in Intelligent Narrative Spaces. It then provides examples of applications built according to the specified criteria.
C1 [Sparacino, Flavia] Sensing Places, Santa Monica, CA USA.
   [Sparacino, Flavia] MIT, Santa Monica, CA USA.
C3 Massachusetts Institute of Technology (MIT)
RP Sparacino, F (corresponding author), Sensing Places, Santa Monica, CA USA.
EM flavia@sensingplaces.com
CR ALBRECHT DW, 1997, P 6 INT C US MOD, P365
   [Anonymous], STANCS1316
   [Anonymous], 1995, P INT WORKSH AUT FAC
   AZARBAYEJANI A, 1996, P 13 ICPR VIENN AUST
   AZARBAYEJANI A, 1996, P IMAGE COM 96 BORD
   Brainard DH, 1997, J OPT SOC AM A, V14, P1393, DOI 10.1364/JOSAA.14.001393
   Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450
   Brooks RA, 1997, SECOND INTERNATIONAL CONFERENCE ON COGNITIVE TECHNOLOGY, PROCEEDINGS, P271, DOI 10.1109/CT.1997.617707
   Brumitt B., 2000, P 2 INT S HANDH UB C
   CAMPBELL LW, 1996, P IEEE INT C AUT FAC
   COHEN M, 1998, P 15 NAT C ART INT A
   CONATI C, 1997, P 6 INT C US MOD UM9
   Emiliani PL, 2005, IBM SYST J, V44, P605, DOI 10.1147/sj.443.0605
   HANSSENS N, 2005, P 3 INT C INT COMP, P675
   HOWARD RA, 1981, APPLICATIONS DECISIO, V2, P721
   Jameson A, 1995, USER MODEL USER-ADAP, V5, P193, DOI 10.1007/BF01126111
   JEBARA T, 1998, IEEE WORKSH INT VIS
   Jensen F. V., 2007, Bayesian networks and decision graphs
   Jensen FV, 1996, INTRO BAYESIAN NETWO
   JOHANSON B, 2002, IEEE PERV COMPUT APR, V1
   JOJIC N, 2000, P 4 IEEE INT C AUT F
   Jordan Michael Irwin, 1999, LEARNING GRAPHICAL M
   Kidd C.y D., 1999, P 2 INT WORKSH COOP
   KOLLER D, 1998, P 15 NAT C ART INT M
   Krumm J., 2001, WORKSH SENS PERC UB
   NEFIAN A, 2002, EURASIP J APPL SIG P, V11, P1
   PAVLOVIC V, 1999, P INT C COMP VIS ICC
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Pearl J., 1988, PROBABILISTIC REASON
   PENTLAND A, 1998, P 14 INT C PATT REC
   PYNADATH DV, 1995, P 11 C UNC ART INT, P472
   Rabiner L. R., 1986, IEEE ASSP MAGAZI JAN, P4
   SMYTH P, 1998, BELIEF NETWORKS HIDD
   Sparacino F, 2000, IBM SYST J, V39, P479, DOI 10.1147/sj.393.0479
   SPARACINO F, 2004, P ICHIM 2004 BERL GE
   SPARACINO F, 2002, P MUS WEB MW2002 APR
   SPARACINO F, 1999, P INT C HYP INT MUS
   SPARACINO F, 1995, IJCAI 95 WORKSH ENT
   SPARACINO F, 2001, INTERFACE BODY BOUND
   SPARACINO F, 2002, P 3DPVT 1 INT S 3D D
   SPARACINO F, 1997, P ARS EL FEST LINZ A
   SPARACINO F, 2003, P UB 5 INT C UB COMP
   Starner T, 1997, PRESENCE-VIRTUAL AUG, V6, P386, DOI 10.1162/pres.1997.6.4.386
   WREN C, 1999, MAN INT SMART ENV MA
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   WREN CR, 1996, APPL ARTIF INTEL JUN
   WU Y, 2001, IEEE SIGNAL PROC MAY
   Young S.J., 1993, HTK HIDDEN MARKOV MO
NR 48
TC 7
Z9 10
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2008
VL 38
IS 3
BP 307
EP 335
DI 10.1007/s11042-007-0193-9
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 300ZV
UT WOS:000255866300003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Franco, A
   Lumini, A
AF Franco, Annalisa
   Lumini, Alessandra
TI Mixture of KL subspaces for relevance feedback
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE relevance feedback; image retrieval; MKL transform; long term learning
ID IMAGE RETRIEVAL
AB Relevance feedback has recently emerged as a solution to the problem of improving the retrieval performance of an image retrieval system based on low-level information such as color, texture and shape features. Most of the relevance feedback approaches limit the utilization of the user's feedback to a single search session, performing a short-term learning. In this paper we present a novel approach for short and long term learning, based on the definition of an adaptive similarity metric and of a high level representation of the images. For short-term learning, the relevant and non-relevant information given by the user during the feedback process is employed to create a positive and a negative subspace of the feature space. For long-term learning, the feedback history of all the users is exploited to create and update a representation of the images which is adopted for improving retrieval performance and progressively reducing the semantic gap between low-level features and high-level semantic concepts. The experimental results prove that the proposed method outperforms many other state of art methods in the short-term learning, and demonstrate the efficacy of the representation adopted for the long-term learning.
C1 [Franco, Annalisa; Lumini, Alessandra] Univ Bologna, I-47023 Cesena, Italy.
C3 University of Bologna
RP Franco, A (corresponding author), Univ Bologna, Via Sacchi 3, I-47023 Cesena, Italy.
EM franco@csr.unibo.it
RI Lumini, Alessandra/AAF-2975-2020; Franco, Annalisa/L-9090-2019; Lumini,
   Alessandra/B-6100-2013
OI Lumini, Alessandra/0000-0003-0290-7354; Franco,
   Annalisa/0000-0002-6625-6442; Lumini, Alessandra/0000-0003-0290-7354
CR [Anonymous], 2003, PROC ACM SPECIAL INT, DOI [10.1145/872757.872829, DOI 10.1145/872757.872829]
   [Anonymous], 1990, STAT PATTERN RECOGNI
   ASHWIN TV, 2001, P IEEE INT C AC SPEE, P2437
   Cappelli R, 2001, IEEE T PATTERN ANAL, V23, P977, DOI 10.1109/34.955111
   CAPPELLI R, 2002, P DEXA2002 AIX PROV, P914
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   DIERABA C, 2003, IEEE T KNOWL DATA EN, V15, P118
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Franco A, 2004, INT C PATT RECOG, P905, DOI 10.1109/ICPR.2004.1333919
   Franco A, 2002, INT C PATT RECOG, P156, DOI 10.1109/ICPR.2002.1048261
   ISHIKAWA Y, 1998, MINDREADER QUERY DAT, P218
   JARDINE N, 1971, INFORM STORAGE RET, V7, P217, DOI 10.1016/0020-0271(71)90051-9
   Kherfi ML, 2002, INT C PATT RECOG, P933, DOI 10.1109/ICPR.2002.1048458
   Koskela M., 2003, P 3 INT WORKSH PATT, P72
   LEW M, 2006, ACM T MULTIMEDIA COM
   Li MJ, 2002, PATTERN RECOGN, V35, P2687, DOI 10.1016/S0031-3203(01)00249-7
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   MONGY S, 2000, ANAL USERS BEHAV VID
   MULLER H, 2000, P INT WORKSH MULT DA, P67
   Nakazato M, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P599
   Nastar C, 1998, PROC CVPR IEEE, P547, DOI 10.1109/CVPR.1998.698659
   Peng J, 2003, COMPUT VIS IMAGE UND, V90, P42, DOI 10.1016/S1077-3142(03)00013-4
   Porkaew K, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P235, DOI 10.1145/319463.319613
   Rocchio J., 1971, SMART RETRIEVAL SYST, P313
   Rui Y, 1997, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P82, DOI 10.1109/IVL.1997.629724
   Rui Y, 2000, PROC CVPR IEEE, P236, DOI 10.1109/CVPR.2000.855825
   RUI Y, 1997, P IEEE INT C IM PROC, P68
   Su Z, 2003, IEEE T IMAGE PROCESS, V12, P924, DOI 10.1109/TIP.2003.815254
   Tieu K, 2004, INT J COMPUT VISION, V56, P17, DOI 10.1023/B:VISI.0000004830.93820.78
   Vasconcelos N, 2000, ADV NEUR IN, V12, P977
   Yin PY, 2002, INT C PATT RECOG, P533, DOI 10.1109/ICPR.2002.1047994
   Zhou X.S., 2001, P ACM INT C MULTIMED, P137
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 33
TC 6
Z9 6
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2008
VL 37
IS 2
BP 189
EP 209
DI 10.1007/s11042-007-0139-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 267PV
UT WOS:000253522600005
DA 2024-07-18
ER

PT J
AU Hadar, O
   Greenberg, S
   Segal, M
AF Hadar, Ofer
   Greenberg, Shlomo
   Segal, Michael
TI EPCRTT-based smoothing and multiplexing of VBR video traffic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video rate smoothing; admission control; statistical multiplexing gain;
   network utilization; QoS
ID BANDWIDTH ALLOCATION
AB Applying video smoothing techniques to real-time video transmission can significantly reduce the peak rate and rate variability of compressed video streams. Moreover, statistical multiplexing of the smoothed traffic can substantially improve network utilization. In this paper we propose a new smoothing scheme, which exploits statistical multiplexing gain that can be obtained after smoothing of individual video streams. We present a new bandwidth allocation algorithm that allows for responsive interactivity. The local re-smoothing algorithm is carried out using an iterative process. In the proposed scheme the smoothed video streams are divided into fixed intervals and then a new transmission schedule for each interval is calculated. The problem of applying an optimal transmission schedule for aggregated smoothing video streams is shown to be NP-hard problem. Partitioning the whole stream into sections enables parallel processing of the smoothing algorithm in real-time before transmission. This approach allows partial transmission of the multiplexed stream while smoothing other intervals. The simulation results show a significant reduction in peak rate and rate variability of the aggregated stream, compared to the non-smoothing case. Therefore the proposed scheme allows us to increase the number of simultanusally-served video streams.
C1 [Hadar, Ofer; Greenberg, Shlomo; Segal, Michael] Ben Gurion Univ Negev, Commun Syst Engn Dept, IL-84105 Beer Sheva, Israel.
   [Greenberg, Shlomo] Freescale Semicond Israel, Herzliyya, Israel.
C3 Ben Gurion University; NXP Semiconductors; Freescale Semiconductor
RP Greenberg, S (corresponding author), Ben Gurion Univ Negev, Commun Syst Engn Dept, IL-84105 Beer Sheva, Israel.
EM shlomog@ee.bgu.ac.il
RI Greenberg, Shlomo/AAO-5229-2020; GREENBERG, SHLOMO/F-1759-2012;
   Greenberg, Shlomo/AAU-7667-2021; SEGAL, MICHAEL/F-2259-2012; HADAR,
   OFER/F-2051-2012
OI SEGAL, MICHAEL/0000-0001-7606-6522; Hadar, Ofer/0000-0002-6089-8401
CR Anastasiadis SV, 2005, IEEE T COMPUT, V54, P398, DOI 10.1109/TC.2005.67
   CHAO HC, 2002, INT J NETW MANAG, V12, P179
   FENG W, 1995, P IASTED ISMM INT C
   FENG W, 1997, P IEEE INFOCOM KOB J, P58
   FENG W, 1995, P IS T SPIE S MULT C, P234
   FENG WC, 1995, COMPUT COMMUN, V18, P709, DOI 10.1016/0140-3664(95)98484-M
   Grossglauser M, 1997, IEEE ACM T NETWORK, V5, P741, DOI 10.1109/90.650136
   Hadar O, 2001, REAL-TIME IMAGING, V7, P301, DOI 10.1006/rtim.2001.0229
   HADAR O, 1999, SPIE S VOIC VID DAT
   Johnson D.S., 1973, Ph.D. thesis
   KANG S, 2000, INT C INF NETW ICOIN
   Kang SY, 1999, COMPUT COMMUN, V22, P173, DOI 10.1016/S0140-3664(98)00250-3
   Knightly EW, 1997, IEEE ACM T NETWORK, V5, P219, DOI 10.1109/90.588085
   Mansell J, 2004, J APPL RES INTELLECT, V17, P1, DOI 10.1111/j.1468-3148.2004.00175.x
   Reisslein M, 1998, IEEE NETWORK, V12, P46, DOI 10.1109/65.752644
   SALEHI J, 1996, P ACM SIGMETRICS 96, P222
   Salehi JD, 1998, IEEE ACM T NETWORK, V6, P397, DOI [10.1109/90.720873, 10.1142/S0218213097000219]
   Sen S., 1997, SPIE S VOIC VID DAT
   Ye DJ, 2004, IEEE T MULTIMEDIA, V6, P611, DOI 10.1109/tmm.2004.830817
   [No title captured]
NR 20
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2008
VL 36
IS 3
BP 203
EP 219
DI 10.1007/s11042-007-0132-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 249TV
UT WOS:000252253600002
DA 2024-07-18
ER

PT J
AU Wang, J
   Pouwelse, J
   Fokker, J
   de Vries, AP
   Reinders, MJT
AF Wang, Jun
   Pouwelse, Johan
   Fokker, Jenneke
   de Vries, Arjen P.
   Reinders, Marcel J. T.
TI Personalization on a peer-to-peer television system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tribler; BuddyCast; peer-to-peer (P2P) television system;
   personalization; collaborative filtering; recommender system
AB We introduce personalization on Tribler, a peer-to-peer (P2P) television system. Personalization allows users to browse programs much more efficiently according to their taste. It also enables to build social networks that can improve the performance of current P2P systems considerably, by increasing content availability, trust and the realization of proper incentives to exchange content. This paper presents a novel scheme, called BuddyCast, that builds such a social network for a user by exchanging user interest profiles using exploitation and exploration principles. Additionally, we show how the interest of a user in TV programs can be predicted from the zapping behavior by the introduced user-item relevance models, thereby avoiding the explicit rating of TV programs. Further, we present how the social network of a user can be used to realize a truly distributed recommendation of TV programs. Finally, we demonstrate a novel user interface for the personalized peer-to-peer television system that encompasses a personalized tag-based navigation to browse the available distributed content. The user interface also visualizes the social network of a user, thereby increasing community feeling which increases trust amongst users and within available content and creates incentives of to exchange content within the community.
C1 [Wang, Jun; Pouwelse, Johan; Reinders, Marcel J. T.] Delft Univ Technol, Fac Elect Engn Math & Comp Sci, Delft, Netherlands.
   [Fokker, Jenneke] Delft Univ Technol, Fac Ind Design Engn, Delft, Netherlands.
   [de Vries, Arjen P.] CWI, NL-1009 AB Amsterdam, Netherlands.
C3 Delft University of Technology; Delft University of Technology
RP Wang, J (corresponding author), Delft Univ Technol, Fac Elect Engn Math & Comp Sci, Delft, Netherlands.
EM jun.wang@tudelft.nl; j.e.fokker@tudelft.nl; arjen@acm.org
RI de Vries, Arjen P./AAX-4970-2020; Tavares, António JV/A-7115-2008
OI de Vries, Arjen P./0000-0002-2888-4202; pouwelse, Prof. Dr.
   johan/0000-0002-9882-1506
CR ALI K, 2004, INT ACM SIGKDD C KNO
   [Anonymous], 2003, AMAZON COM RECOMMEND
   ARDISSONO L, 2004, PERSONALIZED DIGITAL
   BREESE JS, 1998, C UNC ART INT
   CANNY J, 1999, P 25 ANN INT ACM SIG
   CLAYPOOL M, 2001, INT C INT US INT
   Deshpande MKarypis., 2004, Item-based top-n recommendation algorithms
   EUGSTER PT, 2004, IEEE COMPUT, V21, P341
   EYHERAMENDY S, 2003, P ART INT STAT
   FOKKER JE, 2005, TECHNICAL REPORT HUM
   Herlocker J. L., 1999, INT ACM SIGIR C RES
   Hofmann T, 2004, LATENT SEMANTIC MODE
   HULL D, 1993, INT ACM SIGIR C RES
   JELASITY M, 2002, IR503 VRIJ U DEP COM
   LAFFERTY J, 2003, LANGUAGE MODELLING I
   Marlin Benjamin, 2004, Collaborative filtering: A machine learning perspective
   Miller B.N., 2004, POCKETLENS PERSONAL
   Nichols DavidM., 1998, P 5 DELOS WORKSHOP F, P31
   PENNOCK D, 2000, UAI, P437
   POUWELSE JA, 2006, INT WORKSH PEER TO P
   Sarwar B., 2001, INT WORLD WID WEB C
   WANG J, 2006, EUR C INF RETR
   WANG J, 2006, INT ACM SIGIR C RES
   Wang J, 2006, ACM S APPL COMP
   XUE G, 2005, INT ACM SIGIR C RES
   ZHAI C, 2001, INT ACM SIGIR C RES
NR 26
TC 13
Z9 14
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2008
VL 36
IS 1-2
BP 89
EP 113
DI 10.1007/s11042-006-0075-6
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 241LT
UT WOS:000251658600006
DA 2024-07-18
ER

PT J
AU Koumaras, H
   Kourtis, A
   Martakos, D
   Lauterjung, J
AF Koumaras, H.
   Kourtis, A.
   Martakos, D.
   Lauterjung, J.
TI Quantified PQoS assessment based on fast estimation of the spatial and
   temporal activity level
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Perceived Quality of Service (PQoS); Mean Perceived Quality of Service
   (MPQoS); benefit function; objective measurement of PQoS
ID MODEL
AB This paper presents a novel method for fast and quantified estimation of the Perceived Quality of Service (PQoS) for MPEG-4 video content, encoded at constant bit-rates. Taking into account the instant PQoS variation due to the Spatial and Temporal (S-T) activity within a given MPEG-4 encoded content, this paper introduces the Mean PQoS (MPQoS) as a function of the video encoding rate and the picture resolution, and exploits it as a metric for objective video quality assessment. The validity of this metric is assessed by comparing PQoS experimental curves to the theoretical benefit functions vs. allocated resources. Based on the proposed metric, and taking into account the qualitative similarity between theoretical and experimental curves, the paper presents a prototype method for pre-encoding PQoS assessment based on the fast estimation of the S-T activity level of a video signal.
C1 Inst Informat & Telecommun NCSR DEMOKRITOS, Athens 15310, Greece.
   Univ Athens, Informat & Telecommun Dept, Athens 15789, Greece.
   Rohde & Schwarz Corp, Munich, Germany.
C3 National Centre of Scientific Research "Demokritos"; National &
   Kapodistrian University of Athens; Rohde & Schwarz GmbH & Co KG
RP Koumaras, H (corresponding author), Inst Informat & Telecommun NCSR DEMOKRITOS, Patriarchou Gregoriou Str,Agia Paraskevi, Athens 15310, Greece.
EM koumaras@iit.demokritos.gr; kourtis@iit.demokritos.gr;
   martakos@di.uoa.gr; Juergen.Lauterjung@rohde-schwarz.com
OI Kourtis, Anastasios/0000-0003-3047-4568; Koumaras,
   Harilaos/0000-0003-0486-2700
CR ALPERT T, 1997, DSCQE EXPT EVALUATIO
   Bradley AP, 1999, IEEE T IMAGE PROCESS, V8, P717, DOI 10.1109/83.760338
   BUXTON B, 1995, GRAPH INTER, P239
   DALY S, 1992, P SOC PHOTO-OPT INS, V1666, P2, DOI 10.1117/12.135952
   GUAWAN IP, 2003, LONDON COMMUNICATION
   Lai YK, 2000, J VIS COMMUN IMAGE R, V11, P17, DOI 10.1006/jvci.1999.0433
   LAUTERJUNG J, 1998, P INT BROADC CONV IB, P413
   Lee C, 2006, OPT ENG, V45, DOI 10.1117/1.2160515
   Lee W, 2001, MULTIMED TOOLS APPL, V13, P197, DOI 10.1023/A:1009645328053
   LU L, 2002, IEEE INT C MULT
   MULLIN J, 2001, 3 INT WORKSH HUM COM
   OLSON J, 1994, P CSCW 94 WORKSH VID
   Pereira F, 1997, IEEE T CIRC SYST VID, V7, P32, DOI 10.1109/76.554416
   RICHARDSON IG, 2003, J 264 MPEG 4 VIDEO C
   SABATA B, 1998, INT C IM PROC CHIC O
   SEELING P, 2004, IEEE COMMUNICATION S, V6
   Tan KT, 2000, IEEE T CIRC SYST VID, V10, P1208, DOI 10.1109/76.875525
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   VORAN S, 2000, 2 QUAL SERV WORKSH H
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, INT CONF ACOUST SPEE, P3313
   Watson AB, 2001, J ELECTRON IMAGING, V10, P20, DOI 10.1117/1.1329896
   WOLF S, 1999, SPIE INT S VOIC DAT, P11
NR 24
TC 21
Z9 25
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2007
VL 34
IS 3
BP 355
EP 374
DI 10.1007/s11042-007-0111-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 189SJ
UT WOS:000248008500005
DA 2024-07-18
ER

PT J
AU Liu, Y
   Zheng, D
   Zhao, JY
AF Liu, Yan
   Zheng, Dong
   Zhao, Jiying
TI An image rectification scheme and its applications in RST invariant
   digital image watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE digital image watermarking; log-polar mapping; phase-only filtering; RST
   invariant
ID SCALE
AB This paper presents an image rectification scheme that can be used by any image watermarking algorithm to provide robustness against rotation, scaling and translation (RST) transformations. Rotation and scaling transformations in the spatial domain result in cyclically translational shifts in the log-polar mapping (LPM) of the magnitude of the Fourier transform spectrum of an image. We cut a small block from the LPM domain as a matching template. A new filtering method is proposed to compute the cross-correlation between this template and the magnitude of the LPM of the image having undergone RST transformations to detect the rotation and scaling parameters. We employ the same strategy in the spatial domain to detect the translational parameters in the spatial domain. The scheme can also be used to detect image flipping. The cost of the templates is low and the templates can even be compressed. The detection accuracy for rotation, scaling and translation is also presented. We compare the matching results for the different filters and their performance by the three criteria: signal-to-noise ratio (SNR), peak-to-correlation energy (PCE), and Horner efficiency. We demonstrate that our phase-only filtering method is the only one that can be used in the LPM domain. We also introduce three applications for this rectification scheme and give their experimental results.
C1 Univ Ottawa, Sch Informat Technol & Engn, Multimedia Commun Res Lab, Ottawa, ON K1N 6N5, Canada.
C3 University of Ottawa
RP Zhao, JY (corresponding author), Univ Ottawa, Sch Informat Technol & Engn, Multimedia Commun Res Lab, 800 King Edward Ave, Ottawa, ON K1N 6N5, Canada.
EM yliu028@site.uottawa.ca; dzheng@site.uottawa.ca; jyzhao@site.uottawa.ca
RI Zheng, Dong/G-9278-2012
CR [Anonymous], 2002, FOURIER TRANSFORM IT
   BRWON LG, 1992, ACM COMPUT SURV, V24, P325
   Depovere G, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P430, DOI 10.1109/ICIP.1998.723517
   FLANNERY DL, 1989, P IEEE 10, V77
   Herrigel A, 2001, P SOC PHOTO-OPT INS, V4314, P394, DOI 10.1117/12.435423
   HILL L, 1999, C PUBLICATION IEEE, V465
   HORNER JL, 1984, APPL OPTICS, V23, P812, DOI 10.1364/AO.23.000812
   Kim BS, 2004, LECT NOTES COMPUT SC, V2939, P370
   Lin CY, 2001, IEEE T IMAGE PROCESS, V10, P767, DOI 10.1109/83.918569
   Linnartz J., 1997, Proc. of IEEE Fifth Symposium on Communication and Vehicular Technology, P202
   Liu Y, 2003, 2ND IEEE INTERNATIONAL WORKSHOP ON HAPTIC, AUDIO AND VISUAL ENVIRONMENTS AND THEIR APPLICATIONS - HAVE 2003, P101
   Maes M, 2000, IEEE SIGNAL PROC MAG, V17, P47, DOI 10.1109/79.879338
   MOULIN P, 2002, ICASSP TOT ORL FL
   O'Ruanaidh J., 1998, Signal Processing, V66, P303, DOI DOI 10.1016/S0165-1684(98)00012-7
   Pereira S, 2000, IEEE T IMAGE PROCESS, V9, P1123, DOI 10.1109/83.846253
   Reddy BS, 1996, IEEE T IMAGE PROCESS, V5, P1266, DOI 10.1109/83.506761
   REFREGIER P, 1991, OPT LETT, V16, P829, DOI 10.1364/OL.16.000829
   Simitopoulos D, 2003, IEEE T CIRC SYST VID, V13, P732, DOI 10.1109/TCSVT.2003.815947
   Yao JP, 1998, OPT COMMUN, V145, P213, DOI 10.1016/S0030-4018(97)00400-8
   Zheng D, 2003, IEEE T CIRC SYST VID, V13, P753, DOI 10.1109/TCSVT.2003.815959
NR 20
TC 21
Z9 22
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2007
VL 34
IS 1
BP 57
EP 84
DI 10.1007/s11042-006-0072-9
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 169VE
UT WOS:000246619400003
DA 2024-07-18
ER

PT J
AU Liu, JC
   Zhou, M
AF Liu, Jiangchuan
   Zhou, Ming
TI Tree-assisted gossiping for overlay video distribution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE overlay networks; video-on-demand; multicast tree; gossip protocol
ID MULTICAST
AB Given its readily deployable nature and broad applications for digital entertainment, video streaming through overlay networks has received much attention recently. While a tree topology is often advocated due to its scalability, it suffers from discontinuous playback under highly dynamic network environments. For on-demand streaming, the asynchronicity among client requests further aggravates the problem. On the other hand, gossip protocols using random message dissemination, though robust, fail to meet the real-time constraints for streaming applications. In this paper, we propose TAG, a Tree-Assisted Gossip protocol that addresses the above issues. TAG adopts a tree structure with time indexing to accommodate asynchronous requests, and an efficient pull-based gossip algorithm to mitigate the impact of network dynamicity. It seamlessly integrates these two approaches and realizes their best features, namely, low delay with a regular tree topology, and robust delivery with smart switching among multiple paths, thus making effective use of the available bandwidth in the network. We evaluate the performance of TAG under various settings, and the results demonstrate that it is quite robust in the presence of local and global bandwidth fluctuations. As compared to pure tree-based overlay VOD system, it achieves much lower and stable segment missing rates, even under highly dynamic network conditions.
C1 Simon Fraser Univ, Sch Comp Sci, Burnaby, BC, Canada.
C3 Simon Fraser University
RP Liu, JC (corresponding author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC, Canada.
EM jcliu@cs.sfu.ca; jmzhou@cs.sfu.ca
CR BANERJEE S, 2003, P ACM SIGMETRICS 03
   BANERJEE S, 2002, P ACM SIGCOMM 02 PIT
   CASTRO M, 2003, P ACM SOSP 03 NEW YO
   Chu Y., 2000, P ACM SIGMETRICS 00
   CHU Y, 2004, P USENIX ANN TECHN C
   Cormen Thomas H., 2001, INTRO ALGORITHMS
   Cui Y, 2004, IEEE J SEL AREA COMM, V22, P91, DOI 10.1109/JSAC.2003.818799
   CUI Y, 2003, P NOSSDAV 03 MONT CA
   Deshpande H., 2001, STREAMING LIVE MEDIA
   DO T, 2004, P IEEE ICC 04 PAR FR
   Eugster PT, 2004, COMPUTER, V37, P60, DOI 10.1109/MC.2004.1297243
   GUO L, 2004, P IEEE ICDCS 04 TOK
   GUO Y, 2003, P WWW 03 BUD HUNG
   GUO Y, 2003, P IEEE ICME 03 BALT
   HEFEEDA M, 2003, P IEEE FTDCS 03 SAN
   HEFFEEDA M, 2003, P ACM MULT MM 03 BER
   JIN S, 2002, P INT WORKSH NETW GR
   Kermarrec AM, 2003, IEEE T PARALL DISTR, V14, P248, DOI 10.1109/TPDS.2003.1189583
   KOSTIC D, 2003, P ACM SOSP 03 NEW YO
   Liu JC, 2003, IEEE MULTIMEDIA, V10, P22, DOI 10.1109/MMUL.2003.1167919
   PADAMANABHAN VN, 2002, P NOSSDAV 02 US
   REJAIE R, 2003, P NOSSDAV 03 MONT CA
   SHEN S, 1997, P IEEE ICMCS 97 OTT
   SRIPANIDKULCHAI K, 2004, P ACM SIGCOMM 04 POR
   Tran DA, 2004, IEEE J SEL AREA COMM, V22, P121, DOI 10.1109/JSAC.2003.818803
   XU D, 2002, P IEEE ICDCS 02 WIEN
   YANG M, 2004, P IEEE INFOCOM 04 HO
   ZEGURA E, 1996, P IEEE INFOCOMM SAN
   ZHANG X, 2005, P IEEE INFOCOM 05 MI
   ZHUANG SQ, 2001, P NOSSDAV 01 NEW YOR
NR 30
TC 26
Z9 29
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2006
VL 29
IS 3
BP 211
EP 232
DI 10.1007/s11042-006-0013-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 070XJ
UT WOS:000239559600002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chang, FCI
AF Chang, FCI
TI Quantitative analysis of distance learning courseware
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE distance learning; influence diagram; conceptual graph; automatic
   assessment; courseware diagram; virtual university
AB Web-based courseware are widely developed for distance learning programs in continue education, employee training center, and e-learning portals. Usually, a Web-based courseware contains course contents and on-line tests. However, most Web document development tools are not incorporated with a strategic evaluation mechanism, to allow a quantitative analysis of distance learning courseware. We propose an evaluation mechanism and a multimedia tool, based on our Courseware Diagram, to allow a quantitative justification of courseware. Courseware produced by our development system allows an instructor to choose different instruction sequences based on the outcomes of an exam. Alternatively, the courseware may allow self-guided study in a Web-based distance learning program. This paper explains the courseware diagram, the evaluation algorithm, and the design of our courseware development system.
C1 Tamkang Univ, Grad Inst Educ Policy & Leadership, Tamsui, Taiwan.
C3 Tamkang University
RP Tamkang Univ, Grad Inst Educ Policy & Leadership, Tamsui, Taiwan.
CR Aguilar A., 1997, Proceeding IEEE(Institute of Electrical and Electronics Engineers) Southeastcon '97. Engineering New Century, P202
   BOWEN B, 1993, P ICCS 93 CAN, P106
   CADOLINI P, 1996, P GLOB TEL C GLOBECO, P63
   Chang SK, 1998, IEEE MULTIMEDIA, V5, P60, DOI 10.1109/93.713305
   Cheng C.Y.Y., 1998, P 31 ANN HAW INT C S
   CHOU C, 1996, IEEE T PROFESSIONAL, V39, P205
   Chou S.W., 1999, P SOFTW ENG MULT APP, VI, P71
   DASAI T, 1997, P 1997 IEEE PAC RIM, V1, P398
   DAVIES G, 1998, P FRONT ED C FIE 98, V2, P705
   HOWER SM, 1994, P 10 INT C DIG SAT C, V2, P532
   HWANG JN, 1998, P 1998 IEEE INT S CI, V3, P611
   KHADER M, 1996, P FRONT ED C FIE 96, V1, P55
   KUMAR A, 1998, P FRONT ED C FIE 98, V2, P711
   Ma J.H., 1998, P 5 INT WORKSH DISTR, P175
   TAYLOR KD, 1996, P FRONT ED C FIE 96, V1, P44
   Yazdani M, 1997, SECOND INTERNATIONAL CONFERENCE ON COGNITIVE TECHNOLOGY, PROCEEDINGS, P251, DOI 10.1109/CT.1997.617704
NR 16
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2003
VL 20
IS 1
BP 51
EP 65
DI 10.1023/A:1023470400109
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 671JW
UT WOS:000182462500004
DA 2024-07-18
ER

PT J
AU Leung, WH
   Chen, TS
AF Leung, WH
   Chen, TS
TI A multi-user 3-D virtual environment with interactive collaboration and
   shared whiteboard technologies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3-D virtual environment; shared whiteboard; avatar; transparent
   communication; interactive collaboration
AB A multi-user 3-D virtual environment allows remote participants to have a transparent communication as if they are communicating face-to-face. The sense of presence in such an environment can be established by representing each participant with a vivid human-like character called an avatar. We review several immersive technologies, including directional sound, eye gaze, hand gestures, lip synchronization and facial expressions, that facilitates multimodal interaction among participants in the virtual environment using speech processing and animation techniques. Interactive collaboration can be further encouraged with the ability to share and manipulate 3-D objects in the virtual environment. A shared whiteboard makes it easy for participants in the virtual environment to convey their ideas graphically. We survey various kinds of capture devices used for providing the input for the shared whiteboard. Efficient storage of the whiteboard session and precise archival at a later time bring up interesting research topics in information retrieval.
C1 Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA.
C3 Carnegie Mellon University
RP Leung, WH (corresponding author), Carnegie Mellon Univ, Dept Elect & Comp Engn, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.
OI LEUNG, Wing Ho Howard/0000-0002-2633-2965; Chen,
   Tsuhan/0000-0003-3951-7931
CR ESCHER M, 1998, P COMP AN 98
   Foley J.D., 1990, Computer graphics: Principles and practice
   FUA P, 1998, P CAPTECH 98, P214
   Gardner W. G., 1995, TRANSAURAL 3D AUDIO
   GARDNER WG, 1995, J ACOUST SOC, V97
   GARDNER WG, 1999, 3 D AUDIO ACOUSTIC E
   KURIHARA T, 1991, P COMP AN 91, P45
   LEUNG WH, 2001, IEEE SIGNAL PROC MAY
   LEUNG WH, 2002, ICIP2002 ROCH NEW YO
   LEUNG WH, 2002, ICASSP2002 ORL FLOR
   LEUNG WH, 1998, IEEE WORKSH MULT SIG
   LEUNG WH, 2002, ICME2002 LAUS SWITZ
   LEUNG WH, 2000, IEEE INT C MULT EXP
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   *MICR, NETM 3 VID SOFTW
   *NTT SOFTW CORP, INT 3 D VIRT ENV
   OKUDA M, 2000, IEEE INT C IM PROC V
   Parke F., 1996, COMPUTER FACIAL ANIM
   PIGHIN F, 1998, SIGGRAPH 98
   *SEIK INSTR US INC, SMARTP
   Tang J. C., 1993, Computer Supported Cooperative Work (CSCW), V1, P163, DOI 10.1007/BF00752437
   TSENG B, 2001, IEEE INT C MULT EXP
   *WACOM TECHN CO, GRAPH TABL
   Waters K., 1987, ACM SIGGRAPH Comput. Graph., V21, P17
   *WEB3D CONS, VRML WEB3D REP
   VIDEOCONFERENCING SO
NR 26
TC 5
Z9 5
U1 0
U2 7
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2003
VL 20
IS 1
BP 7
EP 23
DI 10.1023/A:1023466231968
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 671JW
UT WOS:000182462500002
DA 2024-07-18
ER

PT J
AU Praveen, PN
   Menaka, D
AF Praveen, P. N.
   Menaka, D.
TI A dual-axis solar tracking system with minimized tracking error through
   optimization technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Artificial neural network; Particle swarm optimization; Solar tracking;
   Solar energy
AB Monitoring the energy generated by a solar system based on various weather conditions requires an accurate forecast algorithm. In this research, a new deep learning method called Dual-Axis Solar Tracking System (DA-STS) is presented to increase the hourly energy provided by four dual-axis solar trackers' real-time forecast accuracy. A novel Artificial Neural Network (ANN) model and a recently developed Particle Swarm Optimisation (PSO) technique known as the randomly occurring dispersed delaying particle swarm optimization method are combined in this framework. This approach is used to broaden the search area and improve the training of the ANN system by lowering the danger of becoming stuck in local optima. Additionally, the hourly measurements of seven meteorological variables, including temporal variables, taken between 2014 and 2015 in Alice Springs, Australia, are utilized to create the ANN system. This model has new two hidden layers, the first of which is a layer of selection depending on the selection of daylight and nighttime data. To identify the most pertinent inputs for precise predictions, the second method is known as automated inputs relevancy assessment. The findings show how the DA-STS method and two innovative hidden layers work well together to greatly increase forecasting accuracy compared to the criteria set by the existing research.
C1 [Praveen, P. N.; Menaka, D.] Noorul Islam Ctr Higher Educ, Dept EIE, Kanyakumari, India.
RP Praveen, PN (corresponding author), Noorul Islam Ctr Higher Educ, Dept EIE, Kanyakumari, India.
EM praveenpnambissan@gmail.com
RI P N, PRAVEEN/JZJ-0726-2024
OI P N, PRAVEEN/0000-0002-4539-6323
CR Abo-Khalil AG, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13052656
   Al-Rousan N., 2020, Journal of King Saud University-Engineering Sciences, V32, P459, DOI [10.1016/j.jksues.2020.04.004, DOI 10.1016/J.JKSUES.2020.04.004]
   Al-Shahri OA, 2021, J CLEAN PROD, V284, DOI 10.1016/j.jclepro.2020.125465
   Arrif T, 2021, INT J AMBIENT ENERGY, V42, P65, DOI 10.1080/01430750.2018.1525581
   Awasthi A, 2020, ENERGY REP, V6, P392, DOI 10.1016/j.egyr.2020.02.004
   Carballo JA, 2019, RENEW ENERG, V133, P1158, DOI 10.1016/j.renene.2018.08.101
   Chowdhury MEH, 2019, J SENSORS, V2019, DOI 10.1155/2019/3681031
   Fernández-Ahumada LM, 2020, SOL ENERGY, V208, P89, DOI 10.1016/j.solener.2020.07.063
   Garud KS, 2021, INT J ENERG RES, V45, P6, DOI 10.1002/er.5608
   Gong JL, 2019, CHEM SOC REV, V48, P1862, DOI 10.1039/c9cs90020a
   Gupta AK, 2021, IETE J RES, V67, P15, DOI 10.1080/03772063.2018.1530617
   Gurulakshmi A. B., 2023, IoT Based Control Networks and Intelligent Systems: Proceedings of 3rd ICICNIS 2022. Lecture Notes in Networks and Systems (528), P265, DOI 10.1007/978-981-19-5845-8_19
   Haddad A, 2020, INT J HYDROGEN ENERG, V45, P13564, DOI 10.1016/j.ijhydene.2018.06.019
   Jallal MA, 2020, RENEW ENERG, V149, P1182, DOI 10.1016/j.renene.2019.10.117
   Jamroen C, 2020, SUSTAIN ENERGY TECHN, V37, DOI 10.1016/j.seta.2019.100618
   Kamadinata JO, 2019, RENEW ENERG, V134, P837, DOI 10.1016/j.renene.2018.11.056
   Kang H, 2019, ENERG BUILDINGS, V193, P1, DOI 10.1016/j.enbuild.2019.03.042
   Khosravi A, 2019, GEOTHERMICS, V80, P138, DOI 10.1016/j.geothermics.2019.03.003
   Krishnan GS, 2020, IET RENEW POWER GEN, V14, P1105, DOI 10.1049/iet-rpg.2019.0875
   Liu HD, 2022, PROCESSES, V10, DOI 10.3390/pr10081452
   Pazikadin AR, 2020, SCI TOTAL ENVIRON, V715, DOI 10.1016/j.scitotenv.2020.136848
   Podder AK, 2019, IET RENEW POWER GEN, V13, P1615, DOI 10.1049/iet-rpg.2018.5946
   Singh SC, 2020, NAT SUSTAIN, V3, P938, DOI 10.1038/s41893-020-0566-x
   Yang JW, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10162960
   Yap KY, 2020, J MOD POWER SYST CLE, V8, P1043, DOI 10.35833/MPCE.2020.000159
   Zhu YQ, 2020, APPL ENERG, V264, DOI 10.1016/j.apenergy.2020.114647
NR 26
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 28
PY 2023
DI 10.1007/s11042-023-17698-4
EA DEC 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL0A9
UT WOS:001132069200001
DA 2024-07-18
ER

PT J
AU Sankari, M
   Vanathi, M
AF Sankari, M.
   Vanathi, M.
TI A novel and Fast hybrid design of cryptosystems for Image via 5-D chaos
   based random keys and DNA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deoxyribonucleic acid (DNA); Image Encryption; 5D chaotic map; Huffman
   Compression; Scrambling; Robustness
ID ENCRYPTION
AB The greatest issue in the age of information technology is safeguarding the real-time colour digital image. In this work, a colour image encryption system is introduced that is based on the compression-then-encryption approach to safeguarding digital images. The proposed method is a hybrid combination of the 5D hyper-chaotic techniques to generate multiple keys, Huffman Encoding for lossless compression and avoiding colour decomposition; scrambling for more confusion; and deoxyribonucleic acid (DNA) encoding for reducing storage size. To enhance security, scrambled data is converted to the DNA sequence, an addition (ADD) operation is performed, and complementary rules are applied to attain the cipher image. Various experimental results of all tested colour images, such as UACI (Unified Average Changing Intensity), which is closer to 33.67%, NPCR (Number of Pixel Changes), which is closer to 99.78%, and correlation coefficients, are relatively closer to zero. Entropy is relatively equal to 8, as measured. The above results are not only proven by the above factors but should also be proven by fast execution time with a combination of DNA, compression techniques, efficient chaos, and a high level of security against various attacks such as brute force attacks, malicious attacks, differential attacks, and statistical attacks. Furthermore, the results show that the proposed work is compared with many existing colour or grey image encryption schemes to prove its efficiency.
C1 [Sankari, M.; Vanathi, M.] Sathyabama Inst Sci & Technol, Dept Comp Sci & Engn, Chennai 600119, Tamilnadu, India.
C3 Sathyabama Institute of Science & Technology
RP Sankari, M (corresponding author), Sathyabama Inst Sci & Technol, Dept Comp Sci & Engn, Chennai 600119, Tamilnadu, India.
EM sankariphd2021@gmail.com
CR Ahamad Md. M., 2016, Rajshahi Univ. j. sci. eng., V44, P131, DOI [10.3329/rujse.v44i0.30398, DOI 10.3329/RUJSE.V44I0.30398]
   Ahuja B, 2023, CONNECT SCI, V35, DOI 10.1080/09540091.2023.2175792
   Alsarhan A., 2019, J Inform Sec App, V49, P2214
   Bahrami M, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, NETWORKING AND COMMUNICATIONS (ICNC)
   Bahrami M, 2015, IEEE INT CONF MOB CL, P189, DOI 10.1109/MobileCloud.2015.36
   Brindha M, 2016, APPL SOFT COMPUT, V40, P379, DOI 10.1016/j.asoc.2015.09.055
   Chai XL, 2017, INT J MOD PHYS C, V28, DOI 10.1142/S0129183117500693
   Fang PF, 2023, VISUAL COMPUT, V39, P1975, DOI 10.1007/s00371-022-02459-5
   Gao XY, 2022, NONLINEAR DYNAM, V108, P613, DOI 10.1007/s11071-021-07192-7
   Holt N, 2017, Chaotic cryptography: applications of chaos theory to cryptography
   Hua ZY, 2017, INFORM SCIENCES, V396, P97, DOI 10.1016/j.ins.2017.02.036
   Kumar V., 2015, Int J Inform Commun Technol, V4, P29
   Lai Q, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.118845
   Li TY, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030319
   Liu Q, 2014, INFORM SCIENCES, V258, P355, DOI 10.1016/j.ins.2012.09.034
   M Sankari, 2023, ITM Web of Conferences, DOI 10.1051/itmconf/20235606001
   Mansoor S., 2023, Multimed Tools App, V82, P1
   Modak Prarthana Madan, 2015, International Journal of Science and Research (IJSR), P813
   Mondal B, 2017, J KING SAUD UNIV-COM, V29, P499, DOI 10.1016/j.jksuci.2016.02.003
   Mondal M., 2019, Review on DNA Cryptography
   Ravichandran D, 2016, COMPUT BIOL MED, V72, P170, DOI 10.1016/j.compbiomed.2016.03.020
   Rezaei B, 2023, J REAL-TIME IMAGE PR, V20, DOI 10.1007/s11554-023-01289-5
   Samiullah M, 2020, IEEE ACCESS, V8, P25650, DOI 10.1109/ACCESS.2020.2970981
   Sankari M., 2019, Int J Eng Technol (UAE), V7, P368, DOI [10.14419/ijet.v7i4.36.23806, DOI 10.14419/IJET.V7I4.36.23806]
   Sankari M., 2018, Privacy-Preserving light weight image Encryption in mobile cloud, in Advances in Intelligent Systems and Computing, P404
   Sankari M, 2022, 2022 1 INT C ELECT E, P1, DOI [10.1109/ICEEICT53079.2022.9768562, DOI 10.1109/ICEEICT53079.2022.9768562]
   Singh Gurpreet., 2013, INT J COMPUTER APPL, V67, P33, DOI DOI 10.5120/11507-7224
   Sun SL, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2018.2817550
   Swathi S., 2016, Int J Adv Res Comput Sci Technol, V4, P2
   Valandar MY, 2019, OPTIK, V193, DOI 10.1016/j.ijleo.2019.06.021
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wu J, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22010005
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yousif SF, 2022, MULTIMED TOOLS APPL, V81, P27453, DOI 10.1007/s11042-022-12762-x
   Yuan HM, 2017, SIGNAL PROCESS-IMAGE, V52, P87, DOI 10.1016/j.image.2017.01.002
   Zhang BW, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11112585
   Zhao JF, 2023, INFORMATION, V14, DOI 10.3390/info14030150
   [朱从旭 Zhu Congxu], 2012, [电子与信息学报, Journal of Electronics & Information Technology], V34, P1735
NR 39
TC 0
Z9 0
U1 15
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 22
PY 2023
DI 10.1007/s11042-023-17742-3
EA DEC 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB8U4
UT WOS:001129672000004
DA 2024-07-18
ER

PT J
AU Kumar, L
   Singh, DK
AF Kumar, Lalit
   Singh, Dushyant Kumar
TI Pose image generation for video content creation using controlled human
   pose image generation GAN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image generation; Pose image generation; Generative adversarial network;
   U-Net architecture; Siamese networks with alignment loss
AB Human pose image generation is a challenging task in computer vision with applications in animation, gaming, and virtual reality. This paper presents a novel approach for Human pose image generation GAN using a combination of U-Net architecture, Decomposed Component encoder, Laplacian image enhancement technique in the generator, and Siamese Networks with Alignment Loss in the discriminator. The generator network leverages the U-Net architecture to capture and reconstruct intricate details of human poses. Additionally, a Decomposed Component encoder is incorporated to learn disentangled representations of pose attributes, such as body position, joint angles, and limb orientations. Furthermore, a Laplacian image enhancement technique is applied to enhance the visual quality and sharpness of the generated pose images. To ensure the alignment and similarity of the generated pose images with real poses, Siamese Networks with Alignment Loss are integrated into the discriminator. The Siamese Networks enable pairwise comparison between generated and real poses, guiding the discriminator to learn features that capture the alignment relationship. The alignment loss is computed based on the similarity of feature representations extracted by the Siamese Networks. This proposed model focuses on enhancing the level of detail and realism in the pose representation rather than improving the resolution or sharpness of the image itself so the U-Net architecture and image sharpening algorithm helps the proposed model to generate more realistic images in comparison to the other state-of-art approaches. This manuscript also contains a comparative analysis of experimental results on various physical conditions with the previously existing state-of-the-art approaches. This analysis shows that the proposed algorithm generates 15-20% more realistic images in comparison to other state-of-the-art approaches.
C1 [Kumar, Lalit; Singh, Dushyant Kumar] MNNIT Allahabad, CSED, Allahabad, UP, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Kumar, L (corresponding author), MNNIT Allahabad, CSED, Allahabad, UP, India.
EM lalitkmr170@gmail.com; dushyant@mnnit.ac.in
RI Kumar, Lalit/ABX-0228-2022; Singh, Dushyant Kumar/AAD-8512-2021
OI Kumar, Lalit/0000-0002-8441-1696; 
CR Cao J, 2023, COMPUT VIS MEDIA, V9, P367, DOI 10.1007/s41095-022-0283-7
   Cao XA, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23010374
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen L, 2022, P 28 ACM SIGKDD C KN
   Deng Y, 2022, P IEEECVF C COMPUTER
   Esser P, 2018, PROC CVPR IEEE, P8857, DOI 10.1109/CVPR.2018.00923
   Fa T, 2019, APPL OPTICS, V58, P5516, DOI 10.1364/AO.58.005516
   Gatys LA, 2015, ADV NEUR IN, V28
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hai J, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2022.103712
   Ikhlasa TN., 2023, IJIET (Int J Indonesian Educ Teach), V7, P33, DOI [10.24071/ijiet.v7i1.5315, DOI 10.24071/IJIET.V7I1.5315]
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Karras T, 2018, Arxiv, DOI [arXiv:1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Kumar L, 2023, 2023 INT C COMP EL E
   Kumar L, 2023, MULTIMED TOOLS APPL, V82, P40585, DOI 10.1007/s11042-023-15138-x
   Li TJ, 2021, IEEE T IMAGE PROCESS, V30, P7677, DOI 10.1109/TIP.2021.3104183
   Liu Z, 2016, P IEEE C COMPUTER VI
   Neverova N, 2018, LECT NOTES COMPUT SC, V11207, P128, DOI 10.1007/978-3-030-01219-9_8
   Pumarola A, 2018, PROC CVPR IEEE, P8620, DOI 10.1109/CVPR.2018.00899
   Siarohin A, 2018, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2018.00359
   Stefanidis K, 2008, P 11 INT C EXT DAT T
   Xiang HY, 2023, PATTERN RECOGN, V134, DOI 10.1016/j.patcog.2022.109046
   Xu QT, 2018, Arxiv, DOI arXiv:1806.07755
   Yoon JS, 2021, PROC CVPR IEEE, P15034, DOI 10.1109/CVPR46437.2021.01479
   Zhu Z, 2019, PROC CVPR IEEE, P2342, DOI 10.1109/CVPR.2019.00245
NR 25
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 21
PY 2023
DI 10.1007/s11042-023-17856-8
EA DEC 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5U7
UT WOS:001129334000008
DA 2024-07-18
ER

PT J
AU Sharma, N
   Jindal, N
AF Sharma, Neha
   Jindal, Neeru
TI Emerging artificial intelligence applications: metaverse, IoT,
   cybersecurity, healthcare - an overview
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Artificial intelligence; Metaverse; Cyber security; Blockchain;
   Healthcare; IoT; Deep learning; Machine learning; Emerging technologies
ID DEEP; BLOCKCHAIN; AI
AB The term "artificial intelligence" (AI) refers to "smart" high-tech that is mindful of and able to learn from its surroundings. It is the most revolutionary technology that humans have ever created. Common AI approaches involving machine learning and deep learning techniques can be effectively applied to resolve today's various cybersecurity issues. Furthermore, the metaverse is all about how people communicate and engage with one another through technology. This survey explores the role of AI with its emerging applications and their various technologies, such as the metaverse, healthcare, IoT, gaming, and many more. To determine the strengths, flaws, opportunities, and risks that are inherent in artificial intelligence technologies, using an extensive literature survey, the SWOT (Strengths, Weaknesses, Opportunities, and Threats) assessments have been undertaken in this survey paper. Finally, the survey paper summarises the current state of knowledge of AI applications and discusses the findings present in recent research to ensure a favourable change in artificial intelligence advances and applications. Some technical AI challenges, like high-speed, high-performance hardware and reducing the amount of training data, etc., are also discussed with future scope.
C1 [Sharma, Neha] Chitkara Univ, Inst Engn & Technol, Dept Comp Sci & Engn, Rajpura 140401, Punjab, India.
   [Jindal, Neeru] Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala 147004, Punjab, India.
C3 Chitkara University, Punjab; Thapar Institute of Engineering &
   Technology
RP Sharma, N (corresponding author), Chitkara Univ, Inst Engn & Technol, Dept Comp Sci & Engn, Rajpura 140401, Punjab, India.
EM neha.1129@chitkara.edu.in; neeru.jindal@thapar.edu
OI Sharma, Dr. Neha/0000-0001-5103-6570
CR Abbasi NI, 2022, 2022 31ST IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (IEEE RO-MAN 2022), P1459, DOI 10.1109/RO-MAN53752.2022.9900843
   Akinrinmade A, 2021, arXiv, DOI [10.48550/arXiv.2101.11501, DOI 10.48550/ARXIV.2101.11501]
   Ali A., 2021, Foundation University Journal of Engineering and Applied Sciences (HEC Recognized Y Category, V2, P20, DOI 10.33897/fujeas.v2i1.380
   Apoorva R., 2018, Int J Eng Res Technol (IJERT), P1, DOI [10.17577/IJERTCONV6IS13220, DOI 10.17577/IJERTCONV6IS13220]
   Barriga NA, 2019, IEEE COMPUT INTELL M, V14, P8, DOI 10.1109/MCI.2019.2919363
   Batarseh FA, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00445-7
   Beck J, 2019, TOUR REV, V74, P586, DOI 10.1108/TR-03-2017-0049
   Bhat SA, 2021, IEEE ACCESS, V9, P110209, DOI 10.1109/ACCESS.2021.3102227
   Bobrow D. G., 1974, Computing Surveys, V6, P153, DOI 10.1145/356631.356632
   Brocke J.vom., 2009, P EUR C INF SYST
   Brundage M, 2018, Arxiv, DOI [arXiv:1802.07228, DOI 10.48550/ARXIV.1802.07228]
   Chen HT, 2020, PROC CVPR IEEE, P1465, DOI 10.1109/CVPR42600.2020.00154
   Chen Ting, 2019, 25 AMERICAS C INFORM
   Chollet F, 2019, Arxiv, DOI [arXiv:1911.01547, DOI 10.48550/ARXIV.1911.01547]
   Choudhury S, 2022, NAT MACH INTELL, V4, P710, DOI 10.1038/s42256-022-00519-y
   Chowdhury M, 2012, Artificial Intelligence Applications to Critical Transportation Issues, V6, P360
   Churcher A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020446
   Ciancarini P, 2023, COMPUT SCI REV, V47, DOI 10.1016/j.cosrev.2022.100517
   Davenport T.H., 2002, Harvard Business Review
   Davenport Thomas, 2019, Future Healthc J, V6, P94, DOI 10.7861/futurehosp.6-2-94
   de Vries K, 2020, INFORM COMMUN SOC, V23, P2110, DOI 10.1080/1369118X.2020.1754877
   López-Cózar ED, 2019, SPRINGER HBK, P95, DOI 10.1007/978-3-030-02511-3_4
   Dhiman P, 2023, 2023 INT C ARTIFICIA, P858, DOI [10.1109/AISC56616.2023.10085519, DOI 10.1109/AISC56616.2023.10085519]
   Dosilovic FK, 2018, 2018 41ST INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P210, DOI 10.23919/MIPRO.2018.8400040
   Dybå T, 2008, ESEM'08: PROCEEDINGS OF THE 2008 ACM-IEEE INTERNATIONAL SYMPOSIUM ON EMPIRICAL SOFTWARE ENGINEERING AND MEASUREMENT, P178
   Economist, 2018, The challenger: technoplotics
   Ellis K, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-32012-w
   Epstein Z, 2020, ISCIENCE, V23, DOI 10.1016/j.isci.2020.101515
   Glaese A., 2022, arXiv
   Goyal D, 2020, 2020 INT C EMERGING, P1, DOI [10.1109/ic-ETITE47903.2020.316, DOI 10.1109/IC-ETITE47903.2020.316]
   Grace K, 2018, J ARTIF INTELL RES, V62, P729, DOI 10.1613/jair.1.11222
   Guo SN, 2019, IEEE T INTELL TRANSP, V20, P3913, DOI 10.1109/TITS.2019.2906365
   Gusenbauer M, 2020, RES SYNTH METHODS, V11, P181, DOI 10.1002/jrsm.1378
   Haenlein M, 2019, CALIF MANAGE REV, V61, P5, DOI 10.1177/0008125619864925
   Hausladen MM, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2201776119
   Hayashi H, 2019, KNOWL-BASED SYST, V186, DOI 10.1016/j.knosys.2019.104927
   Hess P, 2022, NAT MACH INTELL, V4, P828, DOI 10.1038/s42256-022-00540-1
   Huang H, 2022, COMPUT EDUC, V189, DOI 10.1016/j.compedu.2022.104593
   Huang J., 2022, arXiv
   Huynh-The T, 2022, Arxiv, DOI [arXiv:2202.10336, 10.48550/arXiv.2202.10336]
   Jeong JH, 2020, IEEE T NEUR SYS REH, V28, P1226, DOI 10.1109/TNSRE.2020.2981659
   Jiang AQ, 2022, Arxiv, DOI [arXiv:2210.12283, DOI 10.48550/ARXIV.2210.12283]
   Joji LE, 2022, P NATL C EMERGING CO, V4, P89
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Kim SW, 2020, PROC CVPR IEEE, P1228, DOI 10.1109/CVPR42600.2020.00131
   Kitchenham B., 2004, PROCEDURES PERFORMIN, V33, P1
   Kitchenham B. A., 2012, P 2 INT WORKSH EV AS, P1, DOI [10.1145/2372233.2372235, DOI 10.1145/2372233.2372235]
   Koizumi Y, 2022, Arxiv, DOI [arXiv:2210.01029, 10.48550/arXiv.2210.01029]
   Kreuzberger D, 2022, Arxiv, DOI [arXiv:2205.02302, DOI 10.1109/ACCESS.2023.3262138]
   Kumari S, 2013, Int J Mech Eng Comput Appl (IJMCA), V1, P5
   Kuzlu M., 2021, Discov. Internet Things, V1, P1, DOI DOI 10.1007/S43926-020-00001-4
   Leidner DE, 2006, MIS QUART, V30, P357
   Levy Y., 2006, INFORM SCI INT J EME, V9, P181, DOI [DOI 10.28945/479, 10.28945/479, 10.1049/cp.2009.0961, DOI 10.1049/CP.2009.0961]
   Lewis S, 2022, arXiv
   Lin J, 2024, Arxiv, DOI arXiv:2206.15472
   Lin TY, 2021, Arxiv, DOI arXiv:2106.04554
   Liu H, 2021, IEEE T VEH TECHNOL, V70, P6073, DOI 10.1109/TVT.2021.3076780
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Ma YF, 2020, IEEE-CAA J AUTOMATIC, V7, P315, DOI 10.1109/JAS.2020.1003021
   Maharana A, 2022, Arxiv, DOI [arXiv:2209.06192, 10.48550/arXiv.2209.06192]
   Martín-Martín A, 2021, SCIENTOMETRICS, V126, P871, DOI 10.1007/s11192-020-03690-4
   Mijwil MM, 2015, History of Artificial Intelligence, P1, DOI DOI 10.13140/RG.2.2.16418.15046
   Mohammed Ishaq Azhar, 2020, Int J Innov Eng Res Technol (IJIERT), V7, P172
   Okoli C, 2015, COMMUN ASSOC INF SYS, V37, P879
   Oskouei R., 2014, International Journal of Electronics Communication and Computer Engineering (2278-4209), V5, P790, DOI [10.1080/10798587.2016.1186429, DOI 10.1080/10798587.2016.1186429]
   Pandi A, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-31245-z
   Park S, 2019, IEEE ACCESS, V7, P163604, DOI 10.1109/ACCESS.2019.2952613
   Paul J, 2023, J DECIS SYST, DOI 10.1080/12460125.2023.2197700
   Pereira FA, 2023, QUANT SCI STUD, V4, P233, DOI 10.1162/qss_a_00231
   Prabha C., 2022, AIoT technologies and applications for smart environments, DOI [10.1049/PBPC057E, DOI 10.1049/PBPC057E]
   Qi HK, 2021, IEEE T MED IMAGING, V40, P444, DOI 10.1109/TMI.2020.3029205
   Radford A, 2022, OPENAI BLOG
   Ramesh A., 2022, arXiv, DOI 10.48550/arXiv.2204.06125
   Sharma R, 2020, NEURAL COMPUT APPL, V32, P16191, DOI 10.1007/s00521-020-04881-z
   Shwartz-Ziv R, 2022, INFORM FUSION, V81, P84, DOI 10.1016/j.inffus.2021.11.011
   Singer U, 2022, Arxiv, DOI arXiv:2209.14792
   Sriram GK, 2022, Int Res J Modern Eng Technol Sci, V4, P776
   Szczepanski Marcin, 2020, Is data the new oil? Competition issues in the digital economy
   Tanwar S, 2020, IEEE ACCESS, V8, P474, DOI 10.1109/ACCESS.2019.2961372
   Thambawita V, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-01295-2
   Utermohlen K., 2018, Medium
    VV, 2019, Arxiv, DOI [arXiv:1904.03620, DOI 10.48550/ARXIV.1904.03620, 10.48550/arXiv.1904.03620]
   Wang XT, 2021, PROC CVPR IEEE, P9164, DOI 10.1109/CVPR46437.2021.00905
   Wani SUD, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10040608
   Witowski J, 2022, SCI TRANSL MED, V14, DOI 10.1126/scitranslmed.abo4802
   Wu P, 2019, IEEE IMAGE PROC, P3187, DOI [10.1109/icip.2019.8803023, 10.1109/ICIP.2019.8803023]
   Xu YJ, 2021, INNOVATION-AMSTERDAM, V2, DOI 10.1016/j.xinn.2021.100179
   Yang KV, 2022, Arxiv, DOI arXiv:2210.06774
   Ye H, 2019, IEEE T VEH TECHNOL, V68, P3163, DOI 10.1109/TVT.2019.2897134
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Yu J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10196791
   Zgank A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030676
   Zhang ZC, 2022, Arxiv, DOI [arXiv:2209.03665, 10.48550/arXiv.2209.03665]
NR 93
TC 0
Z9 0
U1 13
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 19
PY 2023
DI 10.1007/s11042-023-17890-6
EA DEC 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7T2
UT WOS:001126521200002
DA 2024-07-18
ER

PT J
AU Zheng, RD
   Jiang, XH
   Zhang, JQ
   Yu, HL
AF Zheng, Ruidi
   Jiang, Xiuhua
   Zhang, Jiaqi
   Yu, Hualong
TI Blind visual quality assessment for super-resolution images: database
   and model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image super-resolution; Image database; Blind image quality assessment;
   Siamese network training
ID GRADIENT MAGNITUDE; SIMILARITY; STATISTICS; RESOLUTION
AB Image super-resolution (SR) algorithms are placed on high hope to reconstruct ultra-high-definition (UHD) videos from existing low-resolution videos. Efficient image quality assessment (IQA) methods could not only evaluate the performances of SR algorithms but also provide reliable feedback for algorithm optimization. However, only a few IQA databases and metrics have been specially designed for SR images. In this paper, we propose a database SR4KIQA containing 4K pristine images and super-resolution 4K distorted images with mean opinion score (MOS) labels. Distorted SR images are generated by five classic interpolation methods and seven typical DNN-based super-resolution algorithms. Then, a large-scale database SR4K298 owning 16688 pairs of SR distorted images is designed to support the training process of the ranking-based blind image quality assessment (BIQA) metric we proposed. SROCC of our metric Rank-SR has already reached 0.87 on the SR4KIQA database before the fine-tuning, which outperforms the state-of-art IQA metrics. As one of the very first IQA databases for 4K SR images artifacts, our database SR4KIQA has been publicly available on http://www.dx.doi.org/10.11922/sciencedb.00806 to encourage the further study of the research community.
C1 [Zheng, Ruidi; Jiang, Xiuhua] Commun Univ China, Sch Informat & Commun Engn, Beijing 100024, Peoples R China.
   [Zheng, Ruidi] NRTA, Acad Broadcasting Sci, Beijing 100866, Peoples R China.
   [Zhang, Jiaqi] Zhejiang Univ, Hangzhou 310007, Peoples R China.
   [Yu, Hualong] Zhejiang Univ, Ningbo Res Inst, Ningbo 315615, Peoples R China.
C3 Communication University of China; Zhejiang University; Zhejiang
   University
RP Zheng, RD (corresponding author), Commun Univ China, Sch Informat & Commun Engn, Beijing 100024, Peoples R China.; Zheng, RD (corresponding author), NRTA, Acad Broadcasting Sci, Beijing 100866, Peoples R China.
EM zhengruidi@abs.ac.cn; jiangxiuhua@cuc.edu.cn; jiaqi.zhang@zju.edu.cn;
   yuhualong@zju.edu.cn
RI zhang, jiaqi/JNR-7443-2023
OI zhang, jiaqi/0000-0001-8888-9542
FU National Key R&D Program of China [2019YFB1405900]
FX This work was supported by National Key R&D Program of China (No.
   2019YFB1405900).
CR Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   BT RI-R, 2002, Methodology for the subjective assessment of the quality of television pictures
   Cao Jiezhang, 2021, Video super-resolution transformer
   Cheon M, 2021, IEEE COMPUT SOC CONF, P433, DOI 10.1109/CVPRW53098.2021.00054
   Ding KY, 2020, Arxiv, DOI arXiv:2004.07728
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fang YM, 2018, MULTIMED TOOLS APPL, V77, P29829, DOI 10.1007/s11042-018-5805-z
   Ghadiyaram D, 2017, J VISION, V17, DOI 10.1167/17.1.32
   Giachetti A, 2011, IEEE T IMAGE PROCESS, V20, P2760, DOI 10.1109/TIP.2011.2136352
   Gu Jinjin, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P633, DOI 10.1007/978-3-030-58621-8_37
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hosu V, 2020, IEEE T IMAGE PROCESS, V29, P4041, DOI 10.1109/TIP.2020.2967829
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   ITU-TRECOMMENDATION P, 1999, Subjective video quality assessment methods for multimedia applications
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Ke JJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5128, DOI 10.1109/ICCV48922.2021.00510
   Korhonen J, 2019, IEEE T IMAGE PROCESS, V28, P5923, DOI 10.1109/TIP.2019.2923051
   Kundu D, 2017, IEEE T IMAGE PROCESS, V26, P2957, DOI 10.1109/TIP.2017.2685941
   Lao S, 2022, arXiv
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li DQ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P789, DOI 10.1145/3394171.3413804
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu X., 2016, THESIS U AUTONOMA BA
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma C, 2017, COMPUT VIS IMAGE UND, V158, P1, DOI 10.1016/j.cviu.2016.12.009
   Ma KD, 2015, IEEE T IMAGE PROCESS, V24, P3086, DOI [10.1109/TIP.2015.2436340, 10.1109/TIP.2015.2456638]
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Rassool R, 2017, IEEE INT SYM BROADB, P351
   Reibman AR, 2006, IEEE IMAGE PROC, P2017, DOI 10.1109/ICIP.2006.312895
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tu ZZ, 2021, IEEE T IMAGE PROCESS, V30, P4449, DOI 10.1109/TIP.2021.3072221
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Wang GC, 2017, IEEE IMAGE PROC, P3145, DOI 10.1109/ICIP.2017.8296862
   Wang J., 2023, P AAAI C ARTIFICIAL, V37, P2555
   Wang XT, 2019, IEEE COMPUT SOC CONF, P1954, DOI 10.1109/CVPRW.2019.00247
   Wang XT, 2019, LECT NOTES COMPUT SC, V11133, P63, DOI 10.1007/978-3-030-11021-5_5
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yamanaka Jin, 2017, Neural Information Processing. 24th International Conference, ICONIP 2017. Proceedings: LNCS 10635, P217, DOI 10.1007/978-3-319-70096-0_23
   Zhang K, 2019, PROC CVPR IEEE, P1671, DOI 10.1109/CVPR.2019.00177
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhao TS, 2021, IEEE T MULTIMEDIA, V24, P3570, DOI 10.1109/TMM.2021.3102401
   Zhou F, 2019, IEEE Trans Image Process, V1-1
   Zhou Wei, 2022, MM '22: Proceedings of the 30th ACM International Conference on Multimedia, P934, DOI 10.1145/3503161.3547899
   Zhou W, 2021, INT WORK QUAL MULTIM, P61, DOI 10.1109/QoMEX51781.2021.9465479
NR 54
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 19
PY 2023
DI 10.1007/s11042-023-17026-w
EA DEC 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7T2
UT WOS:001126521200011
DA 2024-07-18
ER

PT J
AU Parvaz, R
AF Parvaz, Reza
TI Poissonian blurred image deconvolution by framelet-based local minimal
   prior
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deblurring; Framelet; Poissonian noise; Medical images; Fractional
   calculation
ID TOTAL VARIATION REGULARIZATION; ALGORITHM
AB Image production tools do not always create a clear image, noisy and blurry images are sometimes created. Among these cases, Poissonian noise is one of the most famous noises that appear in medical images and images taken in astronomy. In recent years, various methods have been proposed to improve the quality of the image that has been lost due to this noise. For example, we can refer to methods that use fractional-order and second-order total variation priors or proximal thresholding. In this paper, in the first step, based on framelet transform, a local minimal prior is introduced, and in the next step, this tool together with fractional calculation is used for Poissonian blurred image deconvolution. The framelet transform domain of images usually have sparse representations. It is also well known that the use of framelet transfer has a proper effect on the edges of the restored image. Also, In this study, both blind and nonblind problems are considered. To evaluate the performance of the presented model, several images such as real images have been investigated. Various tools are used to study the efficiency of the proposed method such as PSNR and SSIM. The proposed method is compared with the existing methods such as fractional - order and second-order total variation. The simulation results show the appropriate representation of the proposed method in solving this type of problem.
C1 [Parvaz, Reza] Univ Mohaghegh Ardabili, Dept Math, Ardebil 56199 11367, Iran.
C3 University of Mohaghegh Ardabili
RP Parvaz, R (corresponding author), Univ Mohaghegh Ardabili, Dept Math, Ardebil 56199 11367, Iran.
EM rparvaz@uma.ac.ir
CR Averbuch AZ., 2014, Spline and spline wavelet methods with applications to signal and image processing, DOI [10.1007/978-94-017-8926-4, DOI 10.1007/978-94-017-8926-4]
   Azzari L, 2017, I S BIOMED IMAGING, P728, DOI 10.1109/ISBI.2017.7950622
   Cafagna D, 2007, IEE IND ELECTRON M, V1, P35, DOI 10.1109/MIE.2007.901479
   Chen G, 2020, IEEE T GEOSCI REMOTE, V58, P2056, DOI 10.1109/TGRS.2019.2952662
   Chen YP, 2022, IET IMAGE PROCESS, V16, P1846, DOI 10.1049/ipr2.12451
   Chowdhury MR, 2020, J MATH IMAGING VIS, V62, P1238, DOI 10.1007/s10851-020-00987-0
   Thanh DNH, 2019, INFORM-INT J COMPUT, V43, P151, DOI 10.31449/inf.v43i2.2179
   De Bruijne M, 2021, 24 INT C, V12903
   Dey N, 2006, MICROSC RES TECHNIQ, V69, P260, DOI 10.1002/jemt.20294
   Dupé FX, 2008, INT CONF ACOUST SPEE, P761, DOI 10.1109/ICASSP.2008.4517721
   ECKSTEIN J, 1992, MATH PROGRAM, V55, P293, DOI 10.1007/BF01581204
   Feng Y, 2020, Math Probl Eng, V2020
   Gabay D., 1976, Computers & Mathematics with Applications, V2, P17, DOI 10.1016/0898-1221(76)90003-1
   Gendler R, 2013, Lessons from the masters: current concepts in astronomical image processing (the patrick moore practical astronomy series, V179
   GLOWINSKI R, 1975, REV FR AUTOMAT INFOR, V9, P41
   Guo ZC, 2019, INVERSE PROBL IMAG, V13, P1161, DOI 10.3934/ipi.2019052
   Han, 2017, FRAMELETS WAVELETS A, DOI 10.1007/978-3-319-68530-4
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Huang J, 2019, J COMPUT APPL MATH, V352, P181, DOI 10.1016/j.cam.2018.11.028
   Javaran TA, 2019, MULTIMED TOOLS APPL, V78, P22555, DOI 10.1007/s11042-019-7402-1
   Jon K, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0250260
   Landi G, 2012, COMPUT MED IMAG GRAP, V36, P38, DOI 10.1016/j.compmedimag.2011.07.002
   Langer A, 2017, J MATH IMAGING VIS, V57, P239, DOI 10.1007/s10851-016-0676-2
   Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815
   Liu J, 2022, MULTIMED TOOLS APPL, V81, P39121, DOI 10.1007/s11042-022-13010-y
   Liu JJ, 2020, INVERSE PROBL, V36, DOI 10.1088/1361-6420/ab6df0
   Liu RT, 2008, IEEE IMAGE PROC, P505, DOI 10.1109/ICIP.2008.4711802
   Ma CC, 2018, MULTIMED TOOLS APPL, V77, P28077, DOI 10.1007/s11042-018-6009-2
   Madhura J, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIVE MECHANISMS FOR INDUSTRY APPLICATIONS (ICIMIA), P637, DOI 10.1109/ICIMIA.2017.7975539
   Naga Srinivasu P, 2021, BIOINSPIRED NEUROCOM, V903, DOI [10.1007/978-981-15-5495-7_1, DOI 10.1007/978-981-15-5495-7_1]
   Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180
   Parvaz R, 2023, VISUAL COMPUT, V39, P2653, DOI 10.1007/s00371-022-02484-4
   Qi Q, 2021, MULTIMED TOOLS APPL, V80, P2975, DOI 10.1007/s11042-020-09460-x
   Ren ZM, 2013, SIGNAL PROCESS, V93, P2408, DOI 10.1016/j.sigpro.2013.02.015
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shi Y, 2017, COMPUT ELECTR ENG, V62, P319, DOI 10.1016/j.compeleceng.2016.09.032
   Shukla AK, 2020, MULTIMED TOOLS APPL, V79, P14201, DOI 10.1007/s11042-020-08641-y
   Sikula J, 2004, Advanced experimental methods for noise research in nanoscale electronic devices, V151
   Wen F, 2021, IEEE T CIRC SYST VID, V31, P2923, DOI 10.1109/TCSVT.2020.3034137
   Wen YW, 2012, IEEE T IMAGE PROCESS, V21, P1770, DOI 10.1109/TIP.2011.2181401
   Yang X.J., 2019, General Fractional Derivatives: Theory, Methods and Applications, DOI [10.1201/9780429284083, DOI 10.1201/9780429284083]
   Zhang FJ, 2018, MULTIMED TOOLS APPL, V77, P26239, DOI 10.1007/s11042-018-5847-2
NR 42
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 8
PY 2023
DI 10.1007/s11042-023-17733-4
EA DEC 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AE1J4
UT WOS:001116691800004
DA 2024-07-18
ER

PT J
AU Shaliyar, M
   Mustafa, K
AF Shaliyar, Mohd
   Mustafa, Khurram
TI Watermarking approach for source authentication of web content in online
   social media: a systematic literature review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Systematic literature review; Source; Authentication; Identification;
   Watermarking; Online social media
ID IMAGE QUALITY ASSESSMENT; FOURIER-TRANSFORM; MULTIPLE WATERMARKING;
   ROBUST WATERMARKING; WAVELET TRANSFORM; DIGITAL IMAGES; SCHEME; SVD;
   DWT; PROTECTION
AB Online Social Media (OSM) enables users to create a powerful virtual bond that facilitates global forwarding/sharing of messages, decision-making, analysis, or voting. Along with the ease of internet services, one may easily forward/share web content over OSM such as WhatsApp, Facebook, Twitter, or Instagram, to name a few. The practice of forwarding these web contents without verifying the source's authenticity could have serious political, social, or financial consequences for society. Thus, it is significant to know about the epicenter of the misinformation or disinformation spread over social media. In this research article, through a Systematic Literature Review (SLR), we analyze various watermarking techniques along with their performance metrics for source authentication of web content in OSM. Based on several inclusion and exclusion criteria, this study critically analyses the findings of 82 selected research papers published between 2016 to 2022. As a result of SLR, we have explored and analyzed a total of 18 various watermarking techniques in spatial and transform domains with their properties and 22 performance metrics. Finally, the research questions are answered, and conclusive trends are reported.
C1 [Shaliyar, Mohd; Mustafa, Khurram] Jamia Millia Islamia, Dept Comp Sci, New Delhi 110025, India.
C3 Jamia Millia Islamia
RP Shaliyar, M (corresponding author), Jamia Millia Islamia, Dept Comp Sci, New Delhi 110025, India.
EM mohdshaliyar@yahoo.com
CR Abdelhakim AM, 2018, MULTIMED TOOLS APPL, V77, P27895, DOI 10.1007/s11042-018-6014-5
   Agarwal N, 2019, MULTIMED TOOLS APPL, V78, P8603, DOI 10.1007/s11042-018-7128-5
   Al-Haj A, 2017, J DIGIT IMAGING, V30, P26, DOI 10.1007/s10278-016-9901-1
   Al-Haj A, 2014, J DIGIT IMAGING, V27, P737, DOI 10.1007/s10278-014-9709-9
   AlShehri L, 2020, MULTIMED TOOLS APPL, V79, P29199, DOI 10.1007/s11042-020-09441-0
   Altay SY, 2021, MULTIMED TOOLS APPL, V80, P23457, DOI 10.1007/s11042-020-10251-7
   Alzahrani A, 2022, APPL BIONICS BIOMECH, V2022, DOI 10.1155/2022/5271600
   AlZubi S, 2011, INT J BIOMED IMAGING, V2011, DOI 10.1155/2011/136034
   Anand A, 2021, MULTIMED TOOLS APPL, V80, P30165, DOI 10.1007/s11042-020-08801-0
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   [Anonymous], NUMBER SOCIAL MEDIA
   Ansari IA, 2018, ARAB J SCI ENG, V43, P4085, DOI 10.1007/s13369-017-2777-7
   Ansari IA, 2016, ADV INTELL SYST COMP, V437, P411, DOI 10.1007/978-981-10-0451-3_38
   Ansari IA, 2016, OPTIK, V127, P5711, DOI 10.1016/j.ijleo.2016.03.070
   Ansari IA, 2016, ENG APPL ARTIF INTEL, V49, P114, DOI 10.1016/j.engappai.2015.12.004
   Ansari IA, 2016, INT J MACH LEARN CYB, V7, P1225, DOI 10.1007/s13042-015-0455-1
   Ansari IA, 2017, PATTERN RECOGN LETT, V94, P228, DOI 10.1016/j.patrec.2016.12.010
   Araghi TK, 2019, FUTURE GENER COMP SY, V101, P1223, DOI 10.1016/j.future.2019.07.064
   Bakhsh FY, 2018, J INF SECUR APPL, V41, P12, DOI 10.1016/j.jisa.2018.05.003
   Balasamy K, 2021, MULTIMED TOOLS APPL, V80, P7167, DOI 10.1007/s11042-020-09981-5
   Balasamy K, 2019, CLUSTER COMPUT, V22, pS4431, DOI 10.1007/s10586-018-1991-8
   Baluja S, 2020, IEEE T PATTERN ANAL, V42, P1685, DOI 10.1109/TPAMI.2019.2901877
   Bamal R, 2018, MULTIMED TOOLS APPL, V77, P12493, DOI 10.1007/s11042-017-4898-0
   Banaji S., 2019, WHATSAPP VIGILANTES
   Bhalerao S, 2021, J AMB INTEL HUM COMP, V12, P1057, DOI 10.1007/s12652-020-02135-3
   Bhalerao S, 2019, PATTERN RECOGN LETT, V125, P463, DOI 10.1016/j.patrec.2019.06.004
   bin Jeffry MAF, 2017, 2017 IEEE CONFERENCE ON APPLICATION, INFORMATION AND NETWORK SECURITY (AINS), P118, DOI 10.1109/AINS.2017.8270435
   Candès EJ, 1999, PHILOS T R SOC A, V357, P2495, DOI 10.1098/rsta.1999.0444
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Chauhan DS, 2019, MULTIMED TOOLS APPL, V78, P3911, DOI 10.1007/s11042-017-4886-4
   Chen F, 2017, MULTIMED TOOLS APPL, V76, P9681, DOI 10.1007/s11042-016-3574-0
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Dagadu JC, 2018, MULTIMED TOOLS APPL, V77, P24289, DOI 10.1007/s11042-018-5725-y
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   Dappuri B, 2020, MULTIMED TOOLS APPL, V79, P31103, DOI 10.1007/s11042-020-09433-0
   Darwish SM, 2020, MULTIMED TOOLS APPL, V79, P6503, DOI 10.1007/s11042-019-08290-w
   Ding WJ, 2019, MULTIMED TOOLS APPL, V78, P5305, DOI 10.1007/s11042-018-5732-z
   Donoho DL, 2001, J APPROX THEORY, V111, P143, DOI 10.1006/jath.2001.3568
   Draganic A, 2017, 2017 40TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1227, DOI 10.23919/MIPRO.2017.7973611
   Elhoseny HM, 2016, OPTIK, V127, P315, DOI 10.1016/j.ijleo.2015.08.152
   Evsutin O, 2020, IEEE ACCESS, V8, P166589, DOI 10.1109/ACCESS.2020.3022779
   Fan MQ, 2018, SIGNAL PROCESS-IMAGE, V66, P19, DOI 10.1016/j.image.2018.04.003
   Fares K, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2020.102403
   Fowler JE, 2005, IEEE SIGNAL PROC LET, V12, P629, DOI 10.1109/LSP.2005.853048
   Gao H, 2021, OPTIK, V242, DOI 10.1016/j.ijleo.2021.166954
   Garg P, 2020, MULTIMED TOOLS APPL, V79, P25921, DOI 10.1007/s11042-020-09262-1
   Giri Kaiser J., 2018, International Journal of Information Technology, V10, P139, DOI 10.1007/s41870-017-0075-y
   Giri KJ, 2020, MULTIMED TOOLS APPL, V79, P32881, DOI 10.1007/s11042-020-09716-6
   Gupta G, 2018, IEEE INT C POWER CON, P447, DOI [10.1109/ICPCSI.2017.8392335, DOI 10.1109/ICPCSI.2017.8392335]
   Gupta R, 2018, MULTIMED TOOLS APPL, V77, P19235, DOI 10.1007/s11042-017-5351-0
   Kahlessenane F, 2021, CLUSTER COMPUT, V24, P2069, DOI 10.1007/s10586-020-03215-x
   Khor HL, 2017, J DIGIT IMAGING, V30, P328, DOI 10.1007/s10278-016-9930-9
   Kitchenham, 2007, GUID PERF SYST LIT R
   Koley S, 2021, MULTIMED TOOLS APPL, V80, P6755, DOI 10.1007/s11042-020-09918-y
   Korus P, 2017, DIGIT SIGNAL PROCESS, V71, P1, DOI 10.1016/j.dsp.2017.08.009
   Kumar C, 2020, MULTIMED TOOLS APPL, V79, P7339, DOI 10.1007/s11042-019-08314-5
   Kumar C, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4912
   Laishram D, 2021, MULTIMED TOOLS APPL, V80, P23815, DOI 10.1007/s11042-020-10389-4
   Laouamer L, 2013, Life Science Journal, V10, P2591
   Lei BY, 2019, MULTIMED TOOLS APPL, V78, P27085, DOI 10.1007/s11042-017-4743-5
   Liu H, 2016, SIGNAL PROCESS-IMAGE, V45, P41, DOI 10.1016/j.image.2016.04.002
   Liu L, 2014, IEEE T IMAGE PROCESS, V23, P3071, DOI 10.1109/TIP.2014.2325777
   Liu Y, 2018, EXPERT SYST APPL, V97, P95, DOI 10.1016/j.eswa.2017.12.003
   Maitra M, 2006, BIOMED SIGNAL PROCES, V1, P299, DOI 10.1016/j.bspc.2006.12.001
   Makbol NM, 2017, INFORM SCIENCES, V417, P381, DOI 10.1016/j.ins.2017.07.026
   Mohan A, 2021, COMPUT ELECTR ENG, V95, DOI 10.1016/j.compeleceng.2021.107385
   Mohan B. C., 2011, IJCA P INT C VLSI CO, V14, P25
   NAMIAS V, 1980, J I MATH APPL, V25, P241
   Nguyen TS, 2021, MULTIMED TOOLS APPL, V80, P25107, DOI 10.1007/s11042-021-10879-z
   Parah SA, 2018, NONLINEAR DYNAM, V93, P1933, DOI 10.1007/s11071-018-4299-6
   Pei SC, 1998, SIGNAL PROCESS, V67, P99, DOI 10.1016/S0165-1684(98)00024-3
   Perwej Y., 2012, Int J Multimed Its Appl, V4, P21, DOI [10.5121/ijma.2012.4202, DOI 10.5121/IJMA.2012.4202]
   Prasad S, 2020, IJST-T ELECTR ENG, V44, P703, DOI 10.1007/s40998-019-00275-7
   Qasim AF, 2018, COMPUT SCI REV, V27, P45, DOI 10.1016/j.cosrev.2017.11.003
   Rakhmawati L, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0462-3
   Ray A, 2020, INT J MULTIMED INF R, V9, P249, DOI 10.1007/s13735-020-00197-9
   Rayachoti E, 2020, CLUSTER COMPUT, V23, P3175, DOI 10.1007/s10586-020-03078-2
   Salomon D., 2007, A concise introduction to data compression
   Sanivarapu PV, 2022, MULTIMED TOOLS APPL, V81, P11605, DOI 10.1007/s11042-022-12273-9
   Selesnick IW, 1999, IEEE T SIGNAL PROCES, V47, P1304, DOI 10.1109/78.757218
   Sharma A, 2017, WIRELESS PERS COMMUN, V92, P1611, DOI 10.1007/s11277-016-3625-x
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shen JJ, 2020, MULTIMED TOOLS APPL, V79, P25969, DOI 10.1007/s11042-020-09254-1
   Shi J, 2020, IEEE T SIGNAL PROCES, V68, P3280, DOI 10.1109/TSP.2020.2992865
   Shih FY, 2018, MULTIMED TOOLS APPL, V77, P1623, DOI 10.1007/s11042-017-4367-9
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Singh AK, 2018, FUTURE GENER COMP SY, V86, P926, DOI 10.1016/j.future.2016.11.023
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh OP, 2023, CONCURR COMP-PRACT E, V35, DOI 10.1002/cpe.6251
   Singh P., 2013, INT J ENG INNOV TECH, V2, P165
   Sinhal R, 2022, CIRC SYST SIGNAL PR, V41, P3199, DOI 10.1007/s00034-021-01926-z
   Sinhal R, 2021, PATTERN RECOGN LETT, V145, P171, DOI 10.1016/j.patrec.2021.02.011
   Sinhal R, 2020, IEEE ACCESS, V8, P200157, DOI 10.1109/ACCESS.2020.3035428
   Sinhal R, 2020, J REAL-TIME IMAGE PR, V17, P2077, DOI 10.1007/s11554-019-00937-z
   Sinhal R, 2020, INT J SYST ASSUR ENG, V11, P274, DOI 10.1007/s13198-019-00855-0
   Srivastava R, 2018, MULTIMED TOOLS APPL, V77, P16447, DOI 10.1007/s11042-017-5214-8
   Su QT, 2020, MULTIMED TOOLS APPL, V79, P30023, DOI 10.1007/s11042-020-09436-x
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Swaraja K, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101665
   Tarhouni N, 2020, CIRC SYST SIGNAL PR, V39, P5059, DOI 10.1007/s00034-020-01401-1
   Tayan O, 2014, 2014 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES (ISBAST), P304, DOI 10.1109/ISBAST.2014.7013139
   Thabit R, 2017, MULTIMED TOOLS APPL, V76, P309, DOI 10.1007/s11042-015-3055-x
   Thakur S, 2020, MULTIMED TOOLS APPL, V79, P4263, DOI 10.1007/s11042-018-6691-0
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Thanki R, 2021, MULTIMED TOOLS APPL, V80, P27593, DOI 10.1007/s11042-021-11064-y
   Thanki R, 2021, MULTIMED TOOLS APPL, V80, P4307, DOI 10.1007/s11042-020-09941-z
   Thanki R, 2017, ENG SCI TECHNOL, V20, P1366, DOI 10.1016/j.jestch.2017.06.001
   timesofindia.indiatimes, Muzaffarnagar riots: International help sought to nail fake video sharers on Facebook | India News-Times of India
   Tiwari A, 2012, J Inst Eng (India): Ser B, V93, P185, DOI [10.1007/s40031-012-0021-0, DOI 10.1007/S40031-012-0021-0]
   Tsolis DK, 2010, MULTIMED TOOLS APPL, V47, P581, DOI 10.1007/s11042-009-0338-0
   Tuncer T, 2018, MULTIMED TOOLS APPL, V77, P21463, DOI 10.1007/s11042-017-5569-x
   Juarez-Sandoval OU, 2018, MULTIMED TOOLS APPL, V77, P26601, DOI 10.1007/s11042-018-5881-0
   Ustubioglu A, 2019, MULTIMED TOOLS APPL, V78, P22269, DOI 10.1007/s11042-019-7529-0
   Vaidya SP, 2018, MULTIMED TOOLS APPL, V77, P5609, DOI 10.1007/s11042-017-4476-5
   Vaidya SP, 2023, VISUAL COMPUT, V39, P2245, DOI 10.1007/s00371-022-02406-4
   Veni M, 2019, MULTIMED TOOLS APPL, V78, P27491, DOI 10.1007/s11042-019-7650-0
   Wang KS, 2022, MULTIMED TOOLS APPL, V81, P6159, DOI 10.1007/s11042-021-11725-y
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   wikipedia, Indian WhatsApp lynchings-Wikipedia
   Wohlin C., 2014, INT C EVALUATION ASS, P1
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zermi N, 2021, MULTIMED TOOLS APPL, V80, P24823, DOI 10.1007/s11042-021-10712-7
   Zermi N, 2021, FORENSIC SCI INT, V320, DOI 10.1016/j.forsciint.2021.110691
   Zhang ZW, 2017, EURASIP J ADV SIG PR, DOI 10.1186/s13634-017-0450-7
   Zhu T, 2022, J SUPERCOMPUT, V78, P222, DOI 10.1007/s11227-021-03886-2
NR 127
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 30
PY 2023
DI 10.1007/s11042-023-17559-0
EA NOV 2023
PG 53
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z2YV8
UT WOS:001110791700006
DA 2024-07-18
ER

PT J
AU Telli, M
   Othmani, M
   Ltifi, H
AF Telli, Mounir
   Othmani, Mohamed
   Ltifi, Hela
TI A new approach to video steganography models with 3D deep CNN
   autoencoders
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Steganography; Video; Spatio-temporal; Deep CNN; Auto-encoder
AB This paper deciphers the sail on a proposition of a video steganography model with the use of a 3D DeepCNN- grounded autoencoder which allows extracting spatiotemporal features from still frames. It tends to hide frames of one video in another video taking into consideration equivalency in terms of size. For the phase of training the model, we've employed a UCF101 dataset containing 101 classes of action recognition videos (13320 videos). The quantitative benefaction of this model was arranged using varied quantitative indexes (SSIM, APD, and PSNR), and the qualitative benefaction was evaluated against the existing approaches.
C1 [Telli, Mounir] Univ Sfax, Natl Engn Sch Sfax, Route Soukra, Sfax 1173, Tunisia.
   [Telli, Mounir] Univ Gafsa, Fac Sci Gafsa, Res Lab Technol Energy & Innovat Mat Lab, Gafsa, Tunisia.
   [Othmani, Mohamed] Univ Gafsa, Fac Sci Gafsa, Gafsa, Tunisia.
   [Othmani, Mohamed] Qassim Univ, Appl Coll, Buraydah, Saudi Arabia.
   [Ltifi, Hela] Univ Kairouan, Fac Sci & Tech Sidi Bouzid, Comp Sci & Math Dept, Kairouan, Tunisia.
   [Ltifi, Hela] Univ Sfax, Natl Sch Engineers ENIS, REs Grp Intelligent Machines, BP 1173, Sfax, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite de Gafsa; Universite de Gafsa; Qassim University; Universite
   de Kairouan; Universite de Sfax; Ecole Nationale dIngenieurs de Sfax
   (ENIS)
RP Telli, M (corresponding author), Univ Sfax, Natl Engn Sch Sfax, Route Soukra, Sfax 1173, Tunisia.; Telli, M (corresponding author), Univ Gafsa, Fac Sci Gafsa, Res Lab Technol Energy & Innovat Mat Lab, Gafsa, Tunisia.
EM telli.mounir@yahoo.fr; mohamed.othmani@yahoo.fr; hela.ltifi@ieee.org
RI LTIFI, Hela/K-5469-2012
OI telli, Mounir/0000-0002-3183-5487
FU The authors are greatly indebted to the editor and the referee for many
   valuable comments and suggestions which improved the initial draft of
   this paper.
FX The authors are greatly indebted to the editor and the referee for many
   valuable comments and suggestions which improved the initial draft of
   this paper.
CR Abdolmohammadi M, 2020, COMM COM INF SC, V1144, P149, DOI 10.1007/978-3-030-37548-5_12
   Abood O.G., 2018, Information Securityand Computer Fraud, V8, P495
   Baldi P., 2012, P ICML WORKSH UNS TR, P37, DOI [10.5555/3045796.3045801., DOI 10.1561/2200000006, 10.1561/2200000006]
   Baluja S, 2017, ADV NEUR IN, V30
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Duan XT, 2019, IEEE ACCESS, V7, P9314, DOI 10.1109/ACCESS.2019.2891247
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Jaiswal A, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206921
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Li Q, 2021, CHINESE PHYS B, V30, DOI 10.1088/1674-1056/abfa01
   Li Q, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107618
   Li Q, 2021, NEURAL PROCESS LETT, V53, P4037, DOI 10.1007/s11063-021-10582-y
   Li Q, 2021, INFORM SCIENCES, V553, P19, DOI 10.1016/j.ins.2020.12.002
   Liu YX, 2019, NEUROCOMPUTING, V335, P238, DOI 10.1016/j.neucom.2018.09.091
   Mishra A., 2019, BMVC, P274
   Mohammed HA, 2021, MATER TODAY-PROC, DOI [10.1016/j.matpr.2021.07.182, DOI 10.1016/J.MATPR.2021.07.182]
   Neeta D, 2006, 2006 1ST INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT, P173
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Obaid ZK, 2021, International Journal of Electrical and Computer Engineering, V11, P1293, DOI [10.11591/ijece.v11i2.pp1293-1302, DOI 10.11591/IJECE.V11I2.PP1293-1302]
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sharma DK, 2022, MATER TODAY-PROC, V51, P104, DOI 10.1016/j.matpr.2021.04.583
   Singh L, 2020, MULTIMED TOOLS APPL, V79, P15901, DOI 10.1007/s11042-018-6407-5
   Subramanian N, 2021, IEEE ACCESS, V9, P23409, DOI 10.1109/ACCESS.2021.3053998
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang XY, 2021, IEEE SIGNAL PROC LET, V28, P1125, DOI 10.1109/LSP.2021.3080181
   Wang XY, 2021, INFORM SCIENCES, V569, P217, DOI 10.1016/j.ins.2021.04.013
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Zhu JR, 2018, Arxiv, DOI arXiv:1807.09937
NR 32
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 11
PY 2023
DI 10.1007/s11042-023-17358-7
EA NOV 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Y0ZQ9
UT WOS:001102641900009
DA 2024-07-18
ER

PT J
AU Kumar, A
   Shukla, P
   Kushwaha, V
   Nandi, GC
AF Kumar, Ankit
   Shukla, Priya
   Kushwaha, Vandana
   Nandi, Gora Chand
TI Context-aware 6D pose estimation of known objects using RGB-D data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE RGB-D; Deep learning; Iterative refinement; 6D pose estimation
ID RECOGNITION
AB In the realm of computer vision and robotics, the pursuit of intelligent robotic grasping and accurate 6D object pose estimation has been a focal point of research. Many modern-world applications, such as robot grasping, manipulation, and palletizing, require the correct pose of objects present in a scene to perform their specific tasks. The estimation of a 6D object pose becomes even more challenging due to inherent complexities, especially when dealing with objects positioned within cluttered scenes and subjected to high levels of occlusion. While prior endeavors have made strides in addressing this issue, their accuracy falls short of the reliability demanded by real-world applications. In this research, we present an architecture that, unlike prior works, incorporates contextual awareness. This novel approach capitalizes on the contextual information attainable about the objects in question. The framework we propose takes a dissection approach, discerning objects by their intrinsic characteristics, namely whether they are symmetric or non-symmetric. Notably, our methodology employs a more profound estimator and refiner network tandem for non-symmetric objects, in contrast to symmetric ones. This distinction acknowledges the inherent dissimilarities between the two object types, thereby enhancing performance. Through experiments conducted on the LineMOD dataset, widely regarded as a benchmark for pose estimation in occluded and cluttered scenes, we demonstrate a notable improvement in accuracy of approximately 3.2% compared to the previous state-of-the-art method, DenseFusion. Moreover, our results indicate that the achieved inference time is sufficient for real-time usage. Overall, our proposed architecture leverages contextual information and tailors the pose estimation process based on object types, leading to enhanced accuracy and real-time performance in challenging scenarios. Code is available at GitHub link
C1 [Kumar, Ankit; Shukla, Priya; Kushwaha, Vandana; Nandi, Gora Chand] Indian Inst Informat Technol Allahabad, Ctr Intelligent Robot, Prayagraj 211015, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Kushwaha, V (corresponding author), Indian Inst Informat Technol Allahabad, Ctr Intelligent Robot, Prayagraj 211015, Uttar Pradesh, India.
EM ramuk.tikna10@gmail.com; priyashuklalko@gmail.com; kush.vandu@gmail.com;
   gcnandi@iiita.ac.in
OI Kushwaha, Vanadana/0000-0001-8071-3585
FU The present research is partially funded by the I-Hub Foundation for
   Cobotics (Technology Innovation Hub of IIT-Delhi set up by the
   Department of Science and Technology, Govt. of India).; I-Hub Foundation
   for Cobotics; Department of Science and Technology
FX The present research is partially funded by the I-Hub Foundation for
   Cobotics (Technology Innovation Hub of IIT-Delhi set up by the
   Department of Science and Technology, Govt. of India).
CR Aubry M, 2014, PROC CVPR IEEE, P3762, DOI 10.1109/CVPR.2014.487
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Ferrari V, 2006, INT J COMPUT VISION, V67, P159, DOI 10.1007/s11263-005-3964-7
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Hinterstoisser S, 2011, IEEE I CONF COMP VIS, P858, DOI 10.1109/ICCV.2011.6126326
   Hinterstoisser V., 2012, P COMP VIS ACCV 2012, P548
   Kehl W, 2016, LECT NOTES COMPUT SC, V9907, P205, DOI 10.1007/978-3-319-46487-9_13
   Li C, 2018, LECT NOTES COMPUT SC, V11220, P263, DOI 10.1007/978-3-030-01270-0_16
   Li YW, 2018, LECT NOTES COMPUT SC, V11210, P520, DOI 10.1007/978-3-030-01231-1_32
   Mousavian A, 2017, P IEEE C COMPUTER VI, ppp7074
   Pavlakos G., 2017, P IEEE C COMPUTER VI, P2011, DOI DOI 10.1109/CVPR.2017.139
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Rios-Cabrera R, 2013, IEEE I CONF COMP VIS, P2048, DOI 10.1109/ICCV.2013.256
   Rothganger F, 2006, INT J COMPUT VISION, V66, P231, DOI 10.1007/s11263-005-3674-1
   Schwarz M, 2015, IEEE INT CONF ROBOT, P1329, DOI 10.1109/ICRA.2015.7139363
   Shukla P, 2023, arXiv
   Song SR, 2016, PROC CVPR IEEE, P808, DOI 10.1109/CVPR.2016.94
   Song SR, 2014, LECT NOTES COMPUT SC, V8694, P634, DOI 10.1007/978-3-319-10599-4_41
   Sundermeyer M, 2018, LECT NOTES COMPUT SC, V11210, P712, DOI 10.1007/978-3-030-01231-1_43
   Suwajanakorn S, 2018, ADV NEUR IN, V31
   Tejani A, 2014, LECT NOTES COMPUT SC, V8694, P462, DOI 10.1007/978-3-319-10599-4_30
   Tekin B, 2018, PROC CVPR IEEE, P292, DOI 10.1109/CVPR.2018.00038
   Tremblay J, 2018, Arxiv, DOI arXiv:1809.10790
   Wang C, 2019, PROC CVPR IEEE, P3338, DOI 10.1109/CVPR.2019.00346
   Wohlhart P, 2015, PROC CVPR IEEE, P3109, DOI 10.1109/CVPR.2015.7298930
   Xiang Y, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Xiang Y, 2017, IEEE WINT CONF APPL, P924, DOI 10.1109/WACV.2017.108
   Xiang Y, 2015, PROC CVPR IEEE, P1903, DOI 10.1109/CVPR.2015.7298800
   Xu DF, 2018, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2018.00033
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
   Zhu M, 2014, Single image 3d object detection and pose estimation for grasping, P3936, DOI [10.1109/ICRA.2014.6907430, DOI 10.1109/ICRA.2014.6907430]
NR 33
TC 0
Z9 0
U1 11
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 7
PY 2023
DI 10.1007/s11042-023-17524-x
EA NOV 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3TF7
UT WOS:001097705200011
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chakravarthy, GK
   Suchithra, M
   Thatavarti, S
AF Chakravarthy, G. Kalyana
   Suchithra, M.
   Thatavarti, Satish
TI EEG-based multimodal emotion recognition with optimal trained hybrid
   classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Emotion recognition; EEG; CNN; Optimal Training
ID FEATURES; NETWORK
AB The ability of EEG signals to identify changes in human brain states has made researchers analyze the emotion with this signal. However, only limited research has been done on multimodal information. This paper carries out research on multimodal emotion recognition with an optimization-assisted hybrid model. The main procedures followed in the suggested framework are preprocessing, feature extraction, improved feature level fusion, and emotion recognition. In a preprocessing step, the two inputs are processed: the EEG signal is preprocessed using the Weiner filtering method and the video is preprocessed by converting it into frames. Subsequent to the preprocessing, extraction of features takes place, where EGG-filtered signal-based features and text-based features are extracted. Afterwards, an improved feature-level fusion is done by combining the extracted features of two modalities. Finally, hybrid classification is performed by combining models like CNN and Deep Maxout classifiers. To ensure betterment in the recognition performance, the training of the model is performed by a newly proposed Combined Arithmetic and Pelican with hybrid exploration (CAPHE) algorithm. Finally, the performance of the suggested CAPHE model is evaluated over traditional models such as DEEP_MAXOUT, Bi-GRU, CNN, AOA, BES, EHO, WOA, RSOA, GWO and POA with regards to various measures. The proposed model yields maximum accuracy of 90.84% while other models receive lower accuracy such as DEEP_MAXOUT = 88.65%, Bi-GRU = 84.23%, CNN = 80.16%, AOA = 88.79%, BES = 87.74%, EHO = 78.49%, WOA = 82.56% RSOA = 85.2%, GWO = 83.51%, and POA = 81.65%, respectively.
C1 [Chakravarthy, G. Kalyana; Suchithra, M.] SRM Inst Sci & Technol, Dept Computat Technol, Kattankulathur 603203, Tamil Nadu, India.
   [Thatavarti, Satish] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram 522502, Andhra Pradesh, India.
C3 SRM Institute of Science & Technology Chennai; Koneru Lakshmaiah
   Education Foundation (K L Deemed to be University)
RP Chakravarthy, GK (corresponding author), SRM Inst Sci & Technol, Dept Computat Technol, Kattankulathur 603203, Tamil Nadu, India.
EM kalyana7288@gmail.com
RI Thaatavarti, Satish/HMO-9967-2023
OI Thaatavarti, Satish/0000-0002-5646-3448
FU I would like to address my sincere gratitude to the co-authors of this
   publication for their insightful advice and support throughout the
   conception and planning of this research project.
FX I would like to address my sincere gratitude to the co-authors of this
   publication for their insightful advice and support throughout the
   conception and planning of this research project.
CR An Y, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102743
   Arano KA, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115507
   Chen GH, 2021, IEEE SIGNAL PROC LET, V28, P533, DOI 10.1109/LSP.2021.3055755
   Chen Y, 2013, IEEE Signal Process Lett, V20
   Falahzadeh MR, 2023, CIRC SYST SIGNAL PR, V42, P449, DOI 10.1007/s00034-022-02130-3
   Goodfellow I., 2013, P 30 INT C MACH LEAR, P1319
   Huan RH, 2021, MULTIMED TOOLS APPL, V80, P8213, DOI 10.1007/s11042-020-10030-4
   Islam MR, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104757
   Kareem HH., 2016, J Babylon Univ/Pure Appl Sci, V24, P9
   Kaveh A., 2021, International Journal of Civil Engineering, V11, P663
   Kumari A, 2018, COMPUT ELECTR ENG, V72, P1, DOI 10.1016/j.compeleceng.2018.08.015
   Lee S, 2021, IEEE ACCESS, V9, P94557, DOI 10.1109/ACCESS.2021.3092735
   Li Y, 2021, NEUROCOMPUTING, V447, P92, DOI 10.1016/j.neucom.2021.02.048
   Liu D, 2021, J GRID COMPUT, V19, DOI 10.1007/s10723-021-09564-0
   Liu YS, 2021, FUTURE GENER COMP SY, V119, P1, DOI 10.1016/j.future.2021.01.010
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Ren MJ, 2021, IEEE SIGNAL PROC LET, V28, P1046, DOI 10.1109/LSP.2021.3078698
   Sarma P, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.102991
   Singh P, 2021, KNOWL-BASED SYST, V229, DOI 10.1016/j.knosys.2021.107316
   Tan C, 2021, NEUROCOMPUTING, V434, P137, DOI 10.1016/j.neucom.2020.12.098
   Tan Y, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.103029
   Tanwar S, 2020, IEEE ACCESS, V8, P474, DOI 10.1109/ACCESS.2019.2961372
   Tripathi Amrendra, 2023, Revue d'Intelligence Artificielle, P281, DOI 10.18280/ria.370205
   Tuerxun W, 2022, MACHINES, V10, DOI 10.3390/machines10050407
   Wu D, 2020, IEEE ACCESS, V8, P133180, DOI 10.1109/ACCESS.2020.3010311
   Zhang G, 2020, IEEE ACCESS, V8, P55688, DOI 10.1109/ACCESS.2020.2981760
   Zhang HL, 2020, IEEE ACCESS, V8, P164130, DOI 10.1109/ACCESS.2020.3021994
   Zhang SQ, 2021, SPEECH COMMUN, V127, P73, DOI 10.1016/j.specom.2020.12.009
   Zhang XW, 2021, IEEE T CYBERNETICS, V51, P4386, DOI 10.1109/TCYB.2020.2987575
   Zhang Y, 2021, IEEE ACCESS, V9, P7943, DOI 10.1109/ACCESS.2021.3049516
NR 30
TC 0
Z9 0
U1 6
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 4
PY 2023
DI 10.1007/s11042-023-17489-x
EA NOV 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3ZW2
UT WOS:001097880200014
DA 2024-07-18
ER

PT J
AU Su, PX
   Shen, XJ
   Chen, HP
   Gai, D
   Liu, Y
AF Su, Pengxiang
   Shen, Xuanjing
   Chen, Haipeng
   Gai, Di
   Liu, Yu
TI M-AResNet: a novel multi-scale attention residual network for melting
   curve image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Convolutional neural networks; Multi-scale feature
   learning; Attentional mechanism; Melting curve dataset
ID MACHINE
AB Melting curve image is a hallmark of quantitative polymerase chain reaction and is a crucial indicator for the validity of the cycle threshold. Current mainstream methods concentrate on analyzing the melting curve images via artificial process. Therefore, we design a novel multi-scale attention residual network, leveraging various levels space features for accurately classifying the melting curve images. Two modular components are designed in our algorithm. A multi-scale feature extraction module that consists of multi-parallel attention resnet units to selectively capture close related information from various scale feature maps while a series of adaptive multi-scale fusion modules to complete cross-subnet fusion of information. In addition, we also collect massive fluorescence signal data to draw melting curve images for constructing a novel dataset. Our method is evaluated on 3 different benchmark datasets including the self-constructed melting curve image dataset, heartbeat signal dataset and natural color image dataset, a significant highlight is that it achieves a 2.0% accuracy improvement over state-of-the-art in average.
C1 [Su, Pengxiang] Nanchang Univ, Sch Software, Nanjingdong St, Nanchang 33000, Jiangxi, Peoples R China.
   [Su, Pengxiang; Shen, Xuanjing; Chen, Haipeng; Liu, Yu] Jilin Univ, Coll Comp Sci & Technol, Qianjin St, Changchun 130000, Jilin, Peoples R China.
   [Gai, Di] Nanchang Univ, Sch Math & Comp Sci, Xuefu St, Nanchang, Jiangxi, Peoples R China.
C3 Nanchang University; Jilin University; Nanchang University
RP Chen, HP (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Qianjin St, Changchun 130000, Jilin, Peoples R China.
EM supengxiang@ncu.edu.cn; xjshen@jlu.edu.cn; chenhp@jlu.edu.cn;
   gaidi@ncu.edu.cn; yul20@mails.jlu.edu.cn
OI Su, Pengxiang/0009-0008-0257-0900
FU National Natural Science Foundation of China [61876070]
FX This research is supported by the National Natural Science Foundation of
   China (61876070).
CR Burger B, 2020, NATURE, V583, P237, DOI 10.1038/s41586-020-2442-2
   Chakraborty C, 2022, IEEE T COMPUT SOC SY, V9, P1613, DOI 10.1109/TCSS.2022.3170375
   Chakraborty C, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107778
   Chen XJ, 2021, COMPUT METH PROG BIO, V202, DOI 10.1016/j.cmpb.2021.106009
   Chen YK, 2019, EARTH SPACE SCI, V6, P1244, DOI 10.1029/2018EA000466
   Coffey KR, 2019, NEUROPSYCHOPHARMACOL, V44, P859, DOI 10.1038/s41386-018-0303-6
   Darmawahyuni A., 2020, Inform. Med. Unlocked, V21, P100441, DOI DOI 10.1016/J.IMU.2020.100441
   Dawodi M, 2020, 2020 IEEE INTERNATIONAL IOT, ELECTRONICS AND MECHATRONICS CONFERENCE (IEMTRONICS 2020), P110
   Divya BS, 2020, IETE J RES, V66, P30, DOI 10.1080/03772063.2018.1474810
   Duta IC, 2021, INT C PATT RECOG, P9415, DOI 10.1109/ICPR48806.2021.9412193
   Fki Zeineb, 2021, arXiv, DOI [10.48550/ARXIV.2112.06024, DOI 10.48550/ARXIV.2112.06024]
   Fu Q, 2022, J PLANT BIOCHEM BIOT, V31, P678, DOI 10.1007/s13562-021-00763-0
   Gong ZQ, 2019, IEEE T GEOSCI REMOTE, V57, P3599, DOI 10.1109/TGRS.2018.2886022
   Guo Q, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11040540
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou CY, 2021, J VIROL METHODS, V293, DOI 10.1016/j.jviromet.2021.114152
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hua WQ, 2022, IEEE J-STARS, V15, P2759, DOI 10.1109/JSTARS.2022.3162953
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jia ZY, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1324
   Kishor A, 2022, WIRELESS PERS COMMUN, V127, P1615, DOI 10.1007/s11277-021-08708-5
   Kishor A, 2021, INT J ENG SYST MODEL, V12, P188, DOI 10.1504/IJESMS.2021.115533
   Kishor A, 2021, MULTIMED TOOLS APPL, V80, P23983, DOI 10.1007/s11042-021-10840-0
   Lab S, 2021, Heartbeat signal dataset
   [李永平 Li Yongping], 2021, [核农学报, Journal of Nuclear Agricultural Sciences], V35, P60
   Lynn HM, 2019, IEEE ACCESS, V7, P145395, DOI 10.1109/ACCESS.2019.2939947
   Mhathesh T. S. R., 2021, Intelligence in Big Data Technologies-Beyond the Hype. Proceedings of ICBDCC 2019. Advances in Intelligent Systems and Computing (AISC 1167), P419, DOI 10.1007/978-981-15-5285-4_42
   Mustak IB, 2021, Etlik Veteriner Mikrobiyoloji Dergisi, V32, P40, DOI [10.35864/evmd.874707, DOI 10.35864/EVMD.874707]
   Iandola FN, 2016, Arxiv, DOI arXiv:1602.07360
   Giuste FO, 2020, Arxiv, DOI arXiv:2002.03846
   Patel H, 2022, MULTIMED TOOLS APPL, V81, P695, DOI 10.1007/s11042-021-11422-w
   Pereira-Gómez M, 2021, J VIROL METHODS, V289, DOI 10.1016/j.jviromet.2020.114035
   Qiu T, 2019, ENERGIES, V12, DOI 10.3390/en12132585
   Ruijter JM, 2021, CLIN CHEM, V67, P829, DOI 10.1093/clinchem/hvab052
   Sarwinda D, 2021, PROCEDIA COMPUT SCI, V179, P423, DOI 10.1016/j.procs.2021.01.025
   Shang RH, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105542
   Sharma M, 2024, EXPERT SYST, V41, DOI 10.1111/exsy.12939
   Shi YK, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12094179
   Simonyan K, 2018, Int Conf Learning Representations, V75, P398
   Sun CL, 2020, IEEE J BIOMED HEALTH, V24, P1351, DOI 10.1109/JBHI.2019.2937558
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Teguh Sulistyono M. Y., 2021, 2021 International Seminar on Intelligent Technology and Its Applications (ISITIA), P67, DOI 10.1109/ISITIA52817.2021.9502250
   Wang XB, 2020, IET RADAR SONAR NAV, V14, P728, DOI 10.1049/iet-rsn.2019.0456
   Xiong ZH, 2018, PHYSIOL MEAS, V39, DOI 10.1088/1361-6579/aad9ed
   Yang MD, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12142327
   Yang Y, 2022, IEEE T CYBERNETICS, V52, P9194, DOI 10.1109/TCYB.2021.3061147
   Yi Xiao-Zhe, 2022, Zhongguo Zhong Yao Za Zhi, V47, P659, DOI 10.19540/j.cnki.cjcmm.20210919.101
   Yin BJ, 2021, NAT MACH INTELL, V3, P905, DOI 10.1038/s42256-021-00397-w
   Yu CY, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3058549
   Yu HL, 2019, IEEE T FUZZY SYST, V27, P2353, DOI 10.1109/TFUZZ.2019.2898371
   Zhang GY, 2020, GEOPHYSICS, V85, pWA227, DOI [10.1190/GEO2019-0267.1, 10.1190/geo2019-0267.1]
   Zhang JM, 2017, IEEE T BIOMED CIRC S, V11, P1097, DOI 10.1109/TBCAS.2017.2719631
NR 54
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42961
EP 42976
DI 10.1007/s11042-023-14694-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LE2S7
UT WOS:001185044900001
DA 2024-07-18
ER

PT J
AU Slimene, I
   Messaoudi, I
   Oueslati, AE
   Lachiri, Z
AF Slimene, Ines
   Messaoudi, Imen
   Oueslati, Afef Elloumi
   Lachiri, Zied
TI Human disease prediction based on deep and machine learning
   classification of genes with miRNA binding sites
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE MicroRNA; gene; cancer disease; FCGR; Machine learning; Deep Learning
AB Within a gene, some nucleotides may be missing, extra nucleotides copies may be present, or certain parts may be deleted; which can cause diseases such as cardiovascular, alzheimer, cancer, etc. Nevertheless, In the one hand, identifying patients' disease from their gene structure remains a challenge since we cannot find associations between a given disease and genetic alteration. However, despite the biological research advances, we still have problems on large data analysis. In view of these factors, we thought about developing a new disease prediction algorithm based on a combination between features extraction and deep or machine learning techniques. To meet this goal, we took into account the fact that the complementarity between micro RiboNucleic Acid (miRNAs) and Messenger RiboNucleic Acid (mRNAs) target sites is critical for genes regulation. For this, we consider protein-coding genes whose expression is modified by abnormal miRNAs as preliminary data. The gene's Frequency Chaos Game Representation (FCGR), which gives the frequency words occurrence in the DNAsequences is then used to define the genes features. Afterwards, we apply and compare a classifier of each of deep andmachine learning to predict altered genes. In terms of identifying altered genes, we demonstrate throughout the proposed study that residual neural network (ResNet) with 152 layers outperforms the Support Vectors Machine (SVM) with a sigmoid kernel as well as the deep Convolutional Neural Network (CNN) with three convolution layers. Indeed, we achieved an accuracy of 98% with FCGR(4) as an independent dataset against an accuracy of 90.69% and 96.88% for respectively SVM and CNN.
C1 [Slimene, Ines; Messaoudi, Imen; Oueslati, Afef Elloumi; Lachiri, Zied] Univ Tunis El Manar, Natl Sch Engineers Tunis, Elect Engn Dept, Tunis, Tunisia.
   [Messaoudi, Imen] Univ Carthage, Higher Inst Informat Technol & Commun, Ind Comp Dept, Tunis, Tunisia.
   [Oueslati, Afef Elloumi] Univ Carthage, Natl Sch Engineers Carthage, Elect Engn Dept, Tunis, Tunisia.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT); Universite de Carthage; Universite de Carthage
RP Slimene, I (corresponding author), Univ Tunis El Manar, Natl Sch Engineers Tunis, Elect Engn Dept, Tunis, Tunisia.
EM ines.slimene@enit.utm.tn; imen.messaoudi@enit.rnu.tn;
   afef.Elloumi@enit.utm.tn; zied.lachiri@enit.rnu.tn
CR Afonso-Grunz F, 2015, CELL MOL LIFE SCI, V72, P3127, DOI 10.1007/s00018-015-1922-2
   Capriotti E, 2011, GENOMICS, V98, P310, DOI 10.1016/j.ygeno.2011.06.010
   D'Onofrio G, 2007, FEBS LETT, V581, P5819, DOI 10.1016/j.febslet.2007.11.052
   Le DH, 2020, BRIEF FUNCT GENOMICS, V19, P350, DOI 10.1093/bfgp/elaa013
   Gavhane Aditi, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P1275, DOI 10.1109/ICECA.2018.8474922
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang DW, 2009, NAT PROTOC, V4, P44, DOI 10.1038/nprot.2008.211
   Islam MM, 2018, Artificial Intelligence-Emerging Trends and Applications, DOI [10.5772/intechopen.75311, DOI 10.5772/INTECHOPEN.75311]
   JEFFREY HJ, 1990, NUCLEIC ACIDS RES, V18, P2163, DOI 10.1093/nar/18.8.2163
   Kim P., 2017, MATLAB DEEP LEARNING, P121, DOI DOI 10.1007/978-1-4842-2845-6
   Li ZW, 2022, IEEE T NEUR NET LEAR, V33, P6999, DOI 10.1109/TNNLS.2021.3084827
   Mahmood A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020447
   Mostavi M, 2020, BMC MED GENOMICS, V13, DOI 10.1186/s12920-020-0677-2
   Öztürk S, 2020, MULTIMED TOOLS APPL, V79, P28825, DOI 10.1007/s11042-020-09468-3
   Palanichamy JK, 2014, FRONT GENET, V5, DOI 10.3389/fgene.2014.00054
   Pasha Syed Nawaz, 2020, IOP Conference Series: Materials Science and Engineering, V981, DOI 10.1088/1757-899X/981/2/022006
   Patle A, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN TECHNOLOGY AND ENGINEERING (ICATE)
   Rukhsar L, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12041850
   Sherman BT, 2022, NUCLEIC ACIDS RES, V50, pW216, DOI 10.1093/nar/gkac194
   Syarif I., 2016, TELKOMNIKA, V14, P1502, DOI [DOI 10.12928/TELKOMNIKA.V14I4.3956, 10.12928/telkomnika.v14i4.3956]
   Vapnik VN., 2000, NATURE STAT LEARNING, P1, DOI [DOI 10.1007/978-1-4757-3264-1, 10.1007/978-1-4757-3264-1]
   Varshni D., 2019 IEEE INT C EL C, DOI DOI 10.1109/ICECCT.2019.8869364
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   Wu CC, 2019, COMPUT METH PROG BIO, V170, P23, DOI 10.1016/j.cmpb.2018.12.032
   Wu JD, 2021, J PERS MED, V11, DOI 10.3390/jpm11020061
NR 25
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 31
PY 2023
DI 10.1007/s11042-023-17457-5
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XH9
UT WOS:001090305500009
DA 2024-07-18
ER

PT J
AU Gündogan, E
   Kaya, M
AF Gundogan, Esra
   Kaya, Mehmet
TI Automatically organizing papers in conference sessions using deep
   learning and network modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Document similarity; Community discovery; Topic modeling;
   Organizing conference sessions
AB Thousands of papers are published at conferences every year. Conference organizers manually assign accepted papers to the sessions according to the title and keywords given by the author. Then organizer names each session, based on his/her experience. These are complex and time-consuming processes and often fail to collect papers on a similar topic in content. This often causes the participant to exit the session after listening to the presentation of one or two papers, because the session name does not fully represent the papers in the session and the papers in the session are not close in content. As a solution to these problems, this paper proposes a method for automatically organizing conference sessions. The method first introduces a network created with a deep learning-based document similarity. Then, sessions are determined with a community discovery method specific to this network, and finally, session titles are extracted with a topic modeling approach. To the best of our knowledge, this paper is the first effort in this direction. Experiments conducted on sessions of three real conferences show that the proposed method is able to create up to 21% better similar sessions, and session names better represent the papers in that session.
C1 [Gundogan, Esra; Kaya, Mehmet] Firat Univ, Dept Comp Engn, Elazig 23119, Turkiye.
C3 Firat University
RP Kaya, M (corresponding author), Firat Univ, Dept Comp Engn, Elazig 23119, Turkiye.
EM egundogan@firat.edu.tr; kaya@firat.edu.tr
RI GÜNDOĞAN, ESRA/W-5137-2018; Kaya, Mehmet/D-4459-2013
OI Kaya, Mehmet/0000-0003-2995-8282
FU Scientific Research Projects Coordination Unit of Firat University
   [MF.20.09]
FX This work was supported by Scientific Research Projects Coordination
   Unit of Firat University under Grant No: MF.20.09.
CR Alghamdi R, 2015, INT J ADV COMPUT SC, V6, P147
   Ashari Ahmad, 2017, International Journal of Intelligent Systems and Applications, V9, P26, DOI 10.5815/ijisa.2017.11.04
   ASONAM, 2019, 2019 IEEE ACM INT C
   FedCSIS, 2019, FED C COMP SCI INF S
   Fortunato S, 2018, SCIENCE, V359, DOI 10.1126/science.aao0185
   Gargiulo F., 2018, INT C INTELLIGENT IN, P471, DOI DOI 10.1007/978-3-319-59480-447
   Gundogan Esra, 2020, 2020 International Conference on Decision Aid Sciences and Application (DASA), P1032, DOI 10.1109/DASA51403.2020.9317101
   Gundogan E, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103107
   ICTAI, 2019, INT C TOOLS ART INT
   Javed MA, 2018, J NETW COMPUT APPL, V108, P87, DOI 10.1016/j.jnca.2018.02.011
   Khan S, 2016, Arxiv, DOI arXiv:1606.01808
   Kherwa P, 2020, Smart Innovation, Systems and Technologies book series (SIST, V76, P1
   Kim D, 2019, INFORM SCIENCES, V477, P15, DOI 10.1016/j.ins.2018.10.006
   Le Quoc V., 2014, P INT C MACH LEARN I
   Li D., 2010, P ACL 2010 C SHORT P, P296
   Liu M, 2017, TSINGHUA SCI TECHNOL, V22, P619, DOI 10.23919/TST.2017.8195345
   Pan XW, 2022, BMC BIOINFORMATICS, V23, DOI 10.1186/s12859-022-04578-1
   Skvorc T, 2022, IEEE ACCESS, V10, P10880, DOI 10.1109/ACCESS.2022.3144932
   Vallejo-Huanga D, 2017, PROCEDIA COMPUT SCI, V108, P325, DOI 10.1016/j.procs.2017.05.206
   Wei C, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146672
   Wu ZD, 2017, EXPERT SYST APPL, V84, P12, DOI 10.1016/j.eswa.2017.04.054
   Yau CK, 2014, SCIENTOMETRICS, V100, P767, DOI 10.1007/s11192-014-1321-8
   Zhang LL, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/874217
   Zhang Y, 2017, FUTURE GENER COMP SY, V66, P30, DOI 10.1016/j.future.2015.12.001
   Zhou L, 2015, SciTech Information Development & Economy, V25, P145
NR 25
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 21
PY 2023
DI 10.1007/s11042-023-17460-w
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W1VN4
UT WOS:001089581100006
DA 2024-07-18
ER

PT J
AU Kumar, S
   Bathla, G
AF Kumar, Sumit
   Bathla, Gourav
TI An efficient fuzzy hyper-edge clustering and popularity-based caching
   scheme for CCN-enabled IoT networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Content-Centric Networking (CCN); Internet-of-Things (IoT); CCN-enabled
   IoT networks; Fog computing; Caching; Fuzzy hyper-edge clustering
ID INTERNET; THINGS; FOG; ICN
AB Content-Centric Networking (CCN) has emerged as the most convenient architecture for efficient traffic management in contrast to the IP-based Internet. The in-network caching characteristic of CCN reduces server load and traffic in the network. Furthermore, it enhances end-user Quality-of-Service (QoS) by reducing content retrieval delay. Towards this, the proposed research focuses on the in-network caching capability of CCN-enabled IoT networks to improve content distribution and reduction of load from servers. In CCN-enabled IoT networks, content caching can be performed in any node of the fog layer that exists between the cloud server and IoT devices. To effectively utilize the available caching resources, it is crucial to determine the suitable fog node during content placement decisions. In this direction, a novel fuzzy hyper-edge clustering and content popularity-based caching scheme is proposed for CCN-based IoT networks. The proposed fuzzy clustering scheme dynamically partitions the network into overlapping clusters based on node connectivity. The proposed scheme overcomes the limitations of existing techniques where the number of clusters needs to be fixed initially. The proposed scheme considers the cluster information and content access frequency parameters for content placement decisions. Using the proposed heuristics, the scheme cooperatively caches the popular contents in the fog nodes near IoT devices. The performance of the proposed strategy is examined using extensive simulations on a realistic network configuration. Experiments are performed on the standard Abilene topology, and performance is measured using metrics such as cache hit ratio, average network hop count, and average network delay on cache sizes 50 and 100. The simulation results are recorded at 1, 250, 500, 750, 1000, 1250, 1500, 1750, and 2000 Simulation Time Units (STU). The results show that the proposed caching solution outperforms recent state-of-the-art techniques such as LCE, PDC, CPNDD, HPHC, and CSDD, making it suitable for CCN-enabled IoT networks.
C1 [Kumar, Sumit] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
   [Bathla, Gourav] GLA Univ, Dept Comp Engn & Applicat, Mathura, UP, India.
C3 Thapar Institute of Engineering & Technology; GLA University
RP Bathla, G (corresponding author), GLA Univ, Dept Comp Engn & Applicat, Mathura, UP, India.
EM sumitaggarwal001@gmail.com; gouravbathla@gmail.com
RI Bathla, Gourav/HQZ-2734-2023
OI Bathla, Gourav/0000-0003-4198-9647
CR Al-Omaisi H, 2021, VEH COMMUN, V30, DOI 10.1016/j.vehcom.2021.100353
   Alderson D, 2005, IEEE ACM T NETWORK, V13, P1205, DOI 10.1109/TNET.2005.861250
   [Anonymous], 2007, Content-Centric Networking, whitepaper describing future assurable global networks
   Arshad S, 2019, IEEE INTERNET THINGS, V6, P2128, DOI 10.1109/JIOT.2018.2873343
   Banerjee B, 2017, 2017 IFIP NETWORKING CONFERENCE (IFIP NETWORKING) AND WORKSHOPS
   Bathla G., 2018, Int J Electr Comput Eng (IJECE), V8, P1711, DOI [10.11591/ijece.v8i3.pp1711-1719, DOI 10.11591/IJECE.V8I3.PP1711-1719]
   Chen S., 2017, IEEE INTERNET COMPUT, V21, P4, DOI [10.1109/MIC.2017.39, DOI 10.1109/MIC.2017.39]
   Chiang M, 2016, IEEE INTERNET THINGS, V3, P854, DOI 10.1109/JIOT.2016.2584538
   Dehghan M, 2017, IEEE ACM T NETWORK, V25, P1635, DOI 10.1109/TNET.2016.2636843
   deSena YAB, 2020, 2020 IEEE LAT AM C C, P1
   Djama A, 2020, COMPUT COMMUN, V159, P37, DOI 10.1016/j.comcom.2020.05.003
   Dutta N, 2022, APPL ARTIF INTELL, V36, DOI 10.1080/08839514.2021.2020488
   Gao S, 2016, MOB INF SYST, V2016, DOI 10.1155/2016/3127029
   Hasan K, 2018, INT CONF UBIQ FUTUR, P891, DOI 10.1109/ICUFN.2018.8436804
   Herzog M.H., 2019, Understanding Statistics and Experimental Design
   Hua YN, 2020, FUTURE GENER COMP SY, V111, P82, DOI 10.1016/j.future.2020.04.040
   Jaber G, 2020, COMPUT COMMUN, V159, P60, DOI 10.1016/j.comcom.2020.05.018
   Karatas F, 2019, FUTURE GENER COMP SY, V93, P156, DOI 10.1016/j.future.2018.10.039
   Khan JA, 2019, IEEE COMMUN MAG, V57, P27, DOI 10.1109/MCOM.2019.1800764
   Khan JA, 2018, INT CONF COMPUT NETW, P554, DOI 10.1109/ICCNC.2018.8390396
   Khodaparas S, 2020, COMPUT COMMUN, V158, P178, DOI 10.1016/j.comcom.2020.05.002
   Koek I, 2022, PERVASIVE MOB COMPUT, V85, DOI 10.1016/j.pmcj.2022.101654
   Kumar S, 2021, J Ambient Intell Humaniz Comput, P1
   Kumar S, 2021, ENG SCI TECHNOL, V24, P829, DOI 10.1016/j.jestch.2020.12.018
   Kumar S, 2021, CLUSTER COMPUT, V24, P1277, DOI 10.1007/s10586-020-03185-0
   Lal KN, 2018, MULTIMED TOOLS APPL, V77, P17625, DOI 10.1007/s11042-017-5183-y
   Laoutaris N, 2006, PERFORM EVALUATION, V63, P609, DOI 10.1016/j.peva.2005.05.003
   Li CM, 2014, INT J COMPUT SCI NET, V14, P1
   Mastorakis S., 2016, Technical Report NDN-0028
   Nour B, 2019, COMPUT COMMUN, V142, P95, DOI 10.1016/j.comcom.2019.05.010
   Ong M.D., 2014, P 17 ACM INT C MODEL, P295
   Ortiz AM, 2014, IEEE INTERNET THINGS, V1, P206, DOI 10.1109/JIOT.2014.2318835
   Oteafy SMA, 2018, IEEE COMMUN MAG, V56, P157, DOI 10.1109/MCOM.2018.1700299
   Pfender J, 2018, PROCEEDINGS OF THE 5TH ACM CONFERENCE ON INFORMATION-CENTRIC NETWORKING (ICN'18), P43, DOI 10.1145/3267955.3267966
   Plass M.F., 2009, P 5 INT C EMERGING N, P1, DOI [10.1145/1658939.1658941, DOI 10.1145/1658939.1658941]
   Psaras I, 2014, IEEE T PARALL DISTR, V25, P2920, DOI 10.1109/TPDS.2013.304
   Qin Wang, 2019, 2019 IEEE 19th International Conference on Communication Technology (ICCT), P1342, DOI 10.1109/ICCT46805.2019.8947001
   Rossi D, 2012, IEEE CONF COMPUT, P280, DOI 10.1109/INFCOMW.2012.6193506
   Sampath V, 2021, WIRELESS PERS COMMUN, V117, P2955, DOI 10.1007/s11277-020-07208-2
   Sangaiah AK, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020539
   Song F, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112512
   Statista, 2012, Iot: Number of connected devices worldwide 2012-2025
   Udugama A, 2014, IEEE IFIP NETW OPER
   Wang S, 2016, IEEE ACM T NETWORK, V24, P2774, DOI 10.1109/TNET.2015.2480093
   Wang YG, 2016, IEEE T COMPUT, V65, P95, DOI 10.1109/TC.2015.2409848
   Yan H, 2017, IEEE ACCESS, V5, P8433, DOI 10.1109/ACCESS.2017.2694045
   Yan H, 2016, IEEE INT CONF COMMUN
   Yao L, 2022, IEEE T INTELL TRANSP
   Yousefpour A, 2019, J SYST ARCHITECT, V98, P289, DOI 10.1016/j.sysarc.2019.02.009
   Zahedinia MS, 2022, COMPUT NETW, V213, DOI 10.1016/j.comnet.2022.109082
NR 50
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 19
PY 2023
DI 10.1007/s11042-023-17284-8
EA OCT 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6OE7
UT WOS:001085969000004
DA 2024-07-18
ER

PT J
AU Sarzo-Wabi, I
   Galindo-Lazo, DA
   Rosas-Romero, R
AF Sarzo-Wabi, Isabel
   Galindo-Lazo, Daniel-Alejandro
   Rosas-Romero, Roberto
TI Feature extraction and classification of static spiral tests to assist
   the detection of Parkinson's disease
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Parkinson's disease; Static spiral test; Image processing; Feature
   extraction; Classifiers
ID POSITRON-EMISSION-TOMOGRAPHY; DIAGNOSIS
AB Analyses of spiral drawings have been carried out in clinics to study and assist the diagnosis of Parkinson's Disease (PD), the second most common neuro-degenerative disorder in people at their 60's. The purpose of this research is to propose an approach to classify static spiral drawings, as an assisting tool for PD diagnosis using a simple data set obtained from a balanced population of patients with PD and controls. In this study, analyses were conducted on pictures of drawings, an affordable technological application, specially in small clinics where neither resources, such as tablets, nor specialists are available. The most significant contribution of this work lies on the extraction and selection of features. Five feature groups are used to characterize the natural process of tracing a spiral for both PD patients and controls. These groups convey information related to the trace movement on the plane, trace pressure, texture, frequency content, and morphology. Furthermore, the number of features is reduced by searching for the best feature subset. Three classifiers are used: k-nearest neighbors, multi-layer perceptron, and support vector machine. The best detection performance achieved is 86.67% of accuracy, 80.00% of sensitivity, 100% of specificity, 100% of positive predictive value, and 82.35% of negative predictive value.
C1 [Sarzo-Wabi, Isabel; Galindo-Lazo, Daniel-Alejandro; Rosas-Romero, Roberto] Univ Americas Puebla, Dept Elect & Comp Engn, Cholula 72810, Puebla, Mexico.
C3 Universidad Americas Puebla (UDLAP)
RP Rosas-Romero, R (corresponding author), Univ Americas Puebla, Dept Elect & Comp Engn, Cholula 72810, Puebla, Mexico.
EM isabel.sarzowi@udlap.mx; daniel.galindolo@udlap.mx;
   roberto.rosas@udlap.mx
FU The authors would like to acknowledge the support of the National
   Council for Research and Technology (CONACYT) in Mexico
   (<italic>National Scholarship</italic> 937004 and <italic>National
   System of Researchers</italic> stimulus 68150). [937004, stimulus
   68150]; National Council for Research and Technology (CONACYT) in Mexico
FX The authors would like to acknowledge the support of the National
   Council for Research and Technology (CONACYT) in Mexico
   (<ITALIC>National Scholarship</ITALIC> 937004 and <ITALIC>National
   System of Researchers</ITALIC> stimulus 68150).
CR Abu-Aisheh Z, 2020, PATTERN RECOGN LETT, V134, P77, DOI 10.1016/j.patrec.2018.05.001
   Aghanavesi S, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102341
   Almeida KJ, 2022, CLIN NEUROL NEUROSUR, V220, DOI 10.1016/j.clineuro.2022.107333
   Andrade AO, 2019, INT WORKSH ASS TECHN, DOI [10.5281/zenodo.3559199, DOI 10.5281/ZENODO.3559199]
   Bellows S, 2022, J NEUROL SCI, V433, DOI 10.1016/j.jns.2021.120018
   Brynolfsson P, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04151-4
   Chougar L, 2020, FRONT NEUROL, V11, DOI 10.3389/fneur.2020.00665
   CONTRERASVIDAL JL, 1995, LIFE SCI, V58, P165, DOI 10.1016/0024-3205(95)02237-6
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dissopa J, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13112089
   Doepp F, 2008, MOVEMENT DISORD, V23, P405, DOI 10.1002/mds.21861
   Drotár P, 2015, IEEE T NEUR SYS REH, V23, P508, DOI 10.1109/TNSRE.2014.2359997
   Gil-Martín M, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8080907
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Impedovo D, 2018, INFORMATION, V9, DOI 10.3390/info9100247
   Impedovo D, 2019, IEEE REV BIOMED ENG, V12, P209, DOI 10.1109/RBME.2018.2840679
   Isenkul M, 2014, 2 INT C E HLTH TEL, ppp171
   Jankovic J, 2020, J NEUROL NEUROSUR PS, V91, P795, DOI 10.1136/jnnp-2019-322338
   Kamble M., 2021, Measurement: Sensors, V16, DOI [10.1016/j.measen.2021.100047, DOI 10.1016/J.MEASEN.2021.100047]
   Lang AE, 1998, NEW ENGL J MED, V339, P1130, DOI 10.1056/NEJM199810153391607
   Loane C, 2011, AM J TRANSL RES, V3, P323
   Löfstedt T, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212110
   Louverdis G, 2002, PATTERN RECOGN, V35, P1733, DOI 10.1016/S0031-3203(01)00166-2
   Luciano MS, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162799
   Murtagh F., 1991, NEUROCOMPUTING, V2, P183
   Pagán FL, 2012, AM J MANAG CARE, V18, pS176
   Pyatigorskaya N, 2014, THER ADV NEUROL DISO, V7, P12, DOI 10.1177/1756285613511507
   Rinne JO, 2009, J MOV DISORD, V2, P53, DOI 10.14802/jmd.09015
   Shi DF, 2022, FRONT AGING NEUROSCI, V14, DOI 10.3389/fnagi.2022.806828
   Sonne J, 2023, Neuroanatomy, Substantia Nigra
   Sulzer D, 2018, NPJ PARKINSON DIS, V4, DOI 10.1038/s41531-018-0047-3
   Tysnes OB, 2017, J NEURAL TRANSM, V124, P901, DOI 10.1007/s00702-017-1686-y
   Verger A, 2021, ANN NEUROL, V90, P711, DOI 10.1002/ana.26187
   Wang L, 2012, Biomed Res Int., DOI [10.1155/2012/412486, DOI 10.1155/2012/412486]
   Yao NT, 2020, CHINESE MED J-PEKING, V133, P1448, DOI 10.1097/CM9.0000000000000836
   Zatcepin A, 2023, Z MED PHYS, V33, P4, DOI 10.1016/j.zemedi.2022.08.004
   Zham P, 2017, FRONT NEUROL, V8, DOI 10.3389/fneur.2017.00435
NR 37
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 18
PY 2023
DI 10.1007/s11042-023-17385-4
EA OCT 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6VJ6
UT WOS:001086159600013
DA 2024-07-18
ER

PT J
AU Sayah, MM
   Narima, Z
   Amine, K
   Redouane, KM
AF Sayah, Moad Med
   Narima, Zermi
   Amine, Khaldi
   Redouane, Kafi Med
TI Medical image protection using a data-hiding technique based on integer
   wavelets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Medical image; Digital watermarking; Integer wavelet transform; Singular
   value decomposition; QR code
ID WATERMARKING SCHEME; BLIND; ENCRYPTION; TRANSFORM; CAPACITY; LSB; SVD
AB Maintaining the secrecy of sensitive data transferred over the Internet while restricting access to approved information is a significant security and protection challenge in telemedicine today. In this work, we present a trustworthy and blind watermarking approach for medical photographs using the Integer Wavelet Transform (IWT) and Singular Value Decomposition (SVD) to preserve the privacy of such information. The embedding capacity of contemporary integer wavelet transform (IWT) based watermarking systems may be constrained. To overcome this specific issue, the study offers an IWT-based secure big capacity watermarking method. According to experiment results on imperceptibility and resilience, the suggested technique efficiently preserves a significant amount of quality in watermarked images, and the watermark is resistant to the most common attacks in watermarking.
C1 [Sayah, Moad Med; Redouane, Kafi Med] Univ Kasdi Merbah, Fac Sci & Technol, Dept Elect, Elect Engn Lab, Ouargla 30000, Algeria.
   [Narima, Zermi] Badji Mokhtar Annaba Univ, Fac Engn Sci, Elect Dept, Labs Automation & Signals Annaba LASA, Annaba 23000, Algeria.
   [Amine, Khaldi] Univ Kasdi Merbah, Fac Sci & Technol, Comp Sci Dept, Artificial Intelligence & Informat Technol Lab LI, Ouargla 30000, Algeria.
C3 Universite Kasdi Merbah Ouargla; Universite Badji Mokhtar - Annaba;
   Universite Kasdi Merbah Ouargla
RP Amine, K (corresponding author), Univ Kasdi Merbah, Fac Sci & Technol, Comp Sci Dept, Artificial Intelligence & Informat Technol Lab LI, Ouargla 30000, Algeria.
EM Sayah.Moad@univ-ouargla.dz; Zermi.Narima@univ-annaba.dz;
   Khaldi.Amine@univ-ouargla.dz; Kafi.Redouane@univ-ouargla.dz
RI Khaldi, Amine/AAV-1266-2020; Kafi, Mohamed Redouane/AAT-2301-2021
OI Khaldi, Amine/0000-0002-1637-9129; Kafi, Mohamed
   Redouane/0000-0002-5500-0943
FU " La Direction Generale de la Recherche Scientifique et du Developpement
   Technologique (DGRSDT)" of Algeria
FX This work was supported by " La Direction Generale de la Recherche
   Scientifique et du Developpement Technologique (DGRSDT)" of Algeria.
CR Aggarwal AK., 2014, J BIOMEDICAL ENG MED, V1, P24, DOI [10.14738/jbemi.14.395, DOI 10.14738/JBEMI.14.395]
   Alshoura WH, 2020, IEEE ACCESS, V8, P43391, DOI 10.1109/ACCESS.2020.2978186
   Amine K, 2023, MULTIMED TOOLS APPL, V82, P35401, DOI 10.1007/s11042-023-14792-5
   Amine K, 2023, MULTIMED TOOLS APPL, V82, P7901, DOI 10.1007/s11042-022-13649-7
   Amine K, 2022, CIRC SYST SIGNAL PR, V41, P5856, DOI 10.1007/s00034-022-02063-x
   Amine K, 2022, J CIRCUIT SYST COMP, V31, DOI 10.1142/S0218126622500979
   Ayubi P, 2021, ARTIF INTELL REV, V54, P1237, DOI 10.1007/s10462-020-09877-8
   Barani MJ, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102509
   Barani MJ, 2019, OPTIK, V187, P205, DOI 10.1016/j.ijleo.2019.04.074
   Borra Surekha, 2019, Smart Health, V12, P35, DOI 10.1016/j.smhl.2018.02.001
   Borra S, 2019, INT J DIGIT CRIME FO, V11, P13, DOI 10.4018/IJDCF.2019040102
   Chauhan S, 2023, SOFT COMPUT, V27, P9565, DOI 10.1007/s00500-023-08090-3
   Chauhan S, 2023, ENG APPL ARTIF INTEL, V119, DOI 10.1016/j.engappai.2022.105803
   Fares K, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2020.102403
   Fares K, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2020.164562
   Gulve AK, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/684824
   Hooda A, 2022, MOL CRYST LIQ CRYST, V726, P90, DOI 10.1080/15421406.2021.1935162
   Hosny KM, 2021, IEEE ACCESS, V9, P47425, DOI 10.1109/ACCESS.2021.3068211
   Hu Q, 2013, LECT NOTES COMPUT SC, V8150, P436, DOI 10.1007/978-3-642-40763-5_54
   Barani MJ, 2020, MULTIMED TOOLS APPL, V79, P2127, DOI 10.1007/s11042-019-08225-5
   Kahlessenane F, 2021, OPT QUANT ELECTRON, V53, DOI 10.1007/s11082-021-02793-3
   Kahlessenane F, 2021, MULTIMED TOOLS APPL, V80, P19827, DOI 10.1007/s11042-021-10713-6
   Kahlessenane F, 2021, CLUSTER COMPUT, V24, P2069, DOI 10.1007/s10586-020-03215-x
   Kahlessenane F, 2021, J AMB INTEL HUM COMP, V12, P2931, DOI 10.1007/s12652-020-02450-9
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Khaldi Amine, 2023, Journal of Ambient Intelligence and Humanized Computing, P13901, DOI 10.1007/s12652-022-04101-7
   Khaldi A, 2023, MULTIMED TOOLS APPL, V82, P12211, DOI 10.1007/s11042-022-13724-z
   Khaldi A, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103540
   Kumar Adesh, 2021, International Journal of Organizational and Collective Intelligence, V11, P1, DOI 10.4018/IJOCI.2021070105
   Kumar A., 2013, C ADV COMM CONTR SYS, P429
   Kumar A, 2023, MULTIMED TOOLS APPL, V82, P7117, DOI 10.1007/s11042-022-13636-y
   Kumar A, 2015, PROCEDIA COMPUT SCI, V57, P1015, DOI 10.1016/j.procs.2015.07.512
   Mandal PC, 2021, OPTIK, V247, DOI 10.1016/j.ijleo.2021.167804
   Moad MS, 2023, CYBERNET SYST, DOI 10.1080/01969722.2023.2166253
   Moad MS, 2022, MULTIMED TOOLS APPL, V81, P44087, DOI 10.1007/s11042-022-12004-0
   Moad MS, 2022, MICROPROCESS MICROSY, V90, DOI 10.1016/j.micpro.2022.104490
   Moad MS, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103114
   Publication, 2015, IAEME PUBLICATION
   Sahu AK, 2019, SENS IMAGING, V21, DOI 10.1007/s11220-019-0262-y
   Sahu AK, 2019, INT J ELECTRON SECUR, V11, P458, DOI 10.1504/IJESDF.2019.102567
   Sahu AK, 2019, WIRELESS PERS COMMUN, V108, P159, DOI 10.1007/s11277-019-06393-z
   Sahu AK, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0188-5
   Sahu AK, 2018, CYBERN INF TECHNOL, V18, P69, DOI 10.2478/cait-2018-0006
   Sahu M, 2021, SENS IMAGING, V22, DOI 10.1007/s11220-020-00328-w
   Sajasi S, 2015, APPL SOFT COMPUT, V30, P375, DOI 10.1016/j.asoc.2015.01.032
   Salah E, 2021, J CIRCUIT SYST COMP, V30, DOI 10.1142/S0218126621502108
   Salah E, 2021, APPL ACOUST, V172, DOI 10.1016/j.apacoust.2020.107652
   Sayah Moad Med, 2023, Research on Biomedical Engineering, P167, DOI 10.1007/s42600-023-00261-3
   Sayah MM, 2022, MULTIMED TOOLS APPL, V81, P43613, DOI 10.1007/s11042-021-11791-2
   Thabit R, 2015, DIGIT SIGNAL PROCESS, V38, P77, DOI 10.1016/j.dsp.2014.12.005
   Thanki R, 2019, MULTIMED TOOLS APPL, V78, P13905, DOI 10.1007/s11042-018-6746-2
   Thanki R, 2019, J INF SECUR APPL, V46, P231, DOI 10.1016/j.jisa.2019.03.017
   Thanki R, 2017, IMAGING SCI J, V65, P457, DOI 10.1080/13682199.2017.1367129
   Valandar MY, 2020, SOFT COMPUT, V24, P771, DOI 10.1007/s00500-019-04524-z
   Valandar MY, 2019, MULTIMED TOOLS APPL, V78, P9971, DOI 10.1007/s11042-018-6584-2
   Valandar MY, 2017, J INF SECUR APPL, V34, P142, DOI 10.1016/j.jisa.2017.04.004
   Wen Quan, 2003, Acta Electronica Sinica, V31, P214
   Xiao M, 2015, High capacity image steganography method based on framelet and compressive sensing, V9811, DOI [10.1117/12.2205279, DOI 10.1117/12.2205279]
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zermi N, 2022, CYBERNET SYST, V53, P282, DOI 10.1080/01969722.2021.1983700
   Zermi N, 2021, MICROPROCESS MICROSY, V84, DOI 10.1016/j.micpro.2021.104134
   Zermi N, 2021, MULTIMED TOOLS APPL, V80, P24823, DOI 10.1007/s11042-021-10712-7
   Zermi N, 2021, FORENSIC SCI INT, V320, DOI 10.1016/j.forsciint.2021.110691
NR 63
TC 0
Z9 0
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 18
PY 2023
DI 10.1007/s11042-023-16771-2
EA OCT 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6VJ6
UT WOS:001086159600002
DA 2024-07-18
ER

PT J
AU Deshpande, KV
   Singh, J
AF Deshpande, Kirti V.
   Singh, Jaibir
TI Weighted transformer neural network for web attack detection using
   request URL
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Optimization; Neural network; Intrusion detection; Web attacks; Cookie
   analysis; Uniform Resource Locator addresses; Generalized adversarial
   neural network
AB Web application firewalls (WAFs) and other Intrusion Detection Systems (IDS) techniques are employed to defend the network against web attacks. Even so, attacks may succeed since most WAFs demand extensive configuration expertise that depends on filters. Despite notable successes, deep information has been utilized in varied applications. Still, it's crucial to have a reliable method for detecting the attack due to the attacker's various ways of concealment of the URLs. Several methods were introduced for detecting the attacks in web applications; still, the accuracy of detection and the computation burden are challenging aspects. Hence, a web attack detection mechanism is introduced in this research using the deep learning framework using the URL request. The proposed method utilizes a three-fold attack detection strategy to detect the attack with minimal computation complexity. Initially, the profile is checked to determine the genuinity of a user, and then, the bot scanners are identified using the generalized adversarial network (GAN). Finally, the attack detection is employed using the transformer neural network, wherein the adjustable parameters are modified using the weighted mean of vectors (INFO) optimization technique. The performance of a proposed method is evaluated based on various assessment measures like Accuracy, Precision, Recall, F-Measure, TPR, FPR, FNR and TNR and acquired the values of 99.97%, 99.96%, 99.97%, 99.97%, 99.97%, 0.03%, 0.03%, and 99.97% respectively.
C1 [Deshpande, Kirti V.; Singh, Jaibir] Om Parkash Jogender Singh Univ, Dept Comp Sci & Engn, Churu 331303, Rajasthan, India.
RP Deshpande, KV (corresponding author), Om Parkash Jogender Singh Univ, Dept Comp Sci & Engn, Churu 331303, Rajasthan, India.
EM kirtivdeshpande@gmail.com
RI Deshpande, kirti/AAB-8140-2022
OI Deshpande, kirti/0000-0003-2418-2788; Singh, Dr.
   Jaibir/0009-0006-4231-0834
CR Ahmadianfar I, 2022, EXPERT SYST APPL, V195, DOI 10.1016/j.eswa.2022.116516
   Alaoui RL, 2022, FUTURE INTERNET, V14, DOI 10.3390/fi14040118
   Alidoosti M, 2020, ETRI J, V42, P433
   Asharf J, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9071177
   Bin Shahid W, 2022, J NETW COMPUT APPL, V198, DOI 10.1016/j.jnca.2021.103270
   Bout E, 2022, IEEE COMMUN SURV TUT, V24, P248, DOI 10.1109/COMST.2021.3127267
   Bozic J, 2020, SOFTWARE QUAL J, V28, P307, DOI 10.1007/s11219-019-09469-y
   Breve B, 2020, ITASEC, P71
   Breve B, 2019, IEEE INT CON INF VIS, P255, DOI 10.1109/IV.2019.00050
   Ch R, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12104087
   Chakir O, 2023, J KING SAUD UNIV-COM, V35, P103, DOI 10.1016/j.jksuci.2023.02.009
   Cirillo S, 2023, JOINT P WORKSH 9 INT, V3408
   Diaba SY, 2023, NEURAL NETWORKS, V165, P321, DOI 10.1016/j.neunet.2023.05.047
   Diro AA, 2018, FUTURE GENER COMP SY, V82, P761, DOI 10.1016/j.future.2017.08.043
   Gong XY, 2021, J SIGNAL PROCESS SYS, V93, P187, DOI 10.1007/s11265-019-01494-1
   Inayat U, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11091502
   Kaggle, 2023, CSIC web application attack detection dataset
   Liu TL, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4725
   Luo CC, 2021, IEEE T IND INFORM, V17, P5810, DOI 10.1109/TII.2020.3038761
   Mahmoud MS, 2019, NEUROCOMPUTING, V338, P101, DOI 10.1016/j.neucom.2019.01.099
   Mokbal FMM, 2019, IEEE ACCESS, V7, P100567, DOI 10.1109/ACCESS.2019.2927417
   Pan Y, 2019, J INTERNET SERV APPL, V10, DOI 10.1186/s13174-019-0115-x
   Ramotsoela DT, 2023, J SENS ACTUAT NETW, V12, DOI 10.3390/jsan12010007
   Sadqi Y, 2022, INF SECUR J, V31, P1, DOI 10.1080/19393555.2020.1853855
   Seyyar YE, 2022, IEEE ACCESS, V10, P68633, DOI 10.1109/ACCESS.2022.3185748
   Shaukat K, 2020, IEEE ACCESS, V8, P222310, DOI 10.1109/ACCESS.2020.3041951
   Sikder MNK, 2023, J WATER PROCESS ENG, V52, DOI 10.1016/j.jwpe.2023.103568
   Tekerek A, 2021, COMPUT SECUR, V100, DOI 10.1016/j.cose.2020.102096
   Tian ZH, 2020, IEEE T IND INFORM, V16, P1963, DOI 10.1109/TII.2019.2938778
   Ustebay S, 2019, COMM COM INF SC, V1039, P144, DOI 10.1007/978-3-030-21952-9_11
   Wankhede S, 2018, 2018 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION (ICCUBEA)
   Wu YR, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/8872923
NR 32
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 17
PY 2023
DI 10.1007/s11042-023-17356-9
EA OCT 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U5AL0
UT WOS:001084922000005
DA 2024-07-18
ER

PT J
AU Abhisheka, B
   Biswas, SK
   Purkayastha, B
   Das, D
   Escargueil, A
AF Abhisheka, Barsha
   Biswas, Saroj Kumar
   Purkayastha, Biswajit
   Das, Dolly
   Escargueil, Alexandre
TI Recent trend in medical imaging modalities and their applications in
   disease diagnosis: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Medical Imaging (MI) Modalities; Medical Image Processing (MIP); Deep
   Convolutional Neural Network (DCNN); Medical Imaging Informatics (MII);
   Disease Diagnosis Techniques
ID AUTOMATIC DETECTION; BREAST-CANCER; DEEP; IMAGES; PET; SEGMENTATION;
   PROGRESS; CLASSIFICATION; METASTASES; CHALLENGES
AB Medical Imaging (MI) plays a crucial role in healthcare, including disease diagnosis, treatment, and continuous monitoring. The integration of non-invasive techniques such as X-ray, Positron Emission Tomography (PET) scan, Computed Tomography (CT) scan, Magnetic Resonance Imaging (MRI), and Ultrasound, has significantly enhanced medical treatment. MI enables visualization of internal structures without invasive procedures, aiding in the diagnosis of various diseases. The introduction of Medical Image Processing (MIP) has further improved disease prediction, detection, analysis, and evaluation. MIP data is utilized in Machine Learning (ML) and Deep Learning (DL) models to develop intelligent systems that enhance medical assistance and better recognition, because human interpretation of medical images is error prone and exhaustive. However, accuracy is crucial for the provision of high-quality healthcare. This has motivated various works on MI using MIP therefore, this paper emphasizes how these imaging modalities can be used to analyze, model, and manipulate data in order to achieve maximum treatment outcome. Moreover, a comprehensive literature survey is conducted to provide a detailed analysis of the working principles, benefits, and limitations of diverse imaging modalities. It explores state-of-the-art methodologies rooted in MI approaches and highlights potential future developments, challenges, trends, observations, and significant improvements in the field.
C1 [Abhisheka, Barsha; Biswas, Saroj Kumar; Purkayastha, Biswajit; Das, Dolly] Natl Inst Technol Silchar, Silchar, India.
   [Escargueil, Alexandre] Sorbonne Univ, Paris, France.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar; Sorbonne Universite
RP Abhisheka, B (corresponding author), Natl Inst Technol Silchar, Silchar, India.
EM barsha21_rs@cse.nits.ac.in; saroj@cse.nits.ac.in; biswajit@nits.ac.in;
   dolly_rs@cse.nits.ac.in; alexander.escargeuil@inserm.fr
OI Escargueil, Alexandre/0000-0002-7419-7518
CR Abhisheka B, 2023, ARCH COMPUT METHOD E, V30, P5023, DOI 10.1007/s11831-023-09968-z
   Akcay S, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108245
   Alessio AM, 2004, RADIOL CLIN N AM, V42, P1017, DOI 10.1016/j.rcl.2004.08.001
   Altaf F, 2019, IEEE ACCESS, V7, P99540, DOI 10.1109/ACCESS.2019.2929365
   Anand S S, 2009, Med J Armed Forces India, V65, P353, DOI 10.1016/S0377-1237(09)80099-3
   Arya C, 2016, INT CONF COMP COMMUN
   Balaha HM, 2022, NEURAL COMPUT APPL, V34, P8671, DOI 10.1007/s00521-021-06851-5
   Basu A, 2022, EXPERT SYST APPL, V193, DOI 10.1016/j.eswa.2021.116377
   Carovac Aladin, 2011, Acta Inform Med, V19, P168, DOI 10.5455/aim.2011.19.168-171
   Chandra TB, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113909
   Charron O, 2018, COMPUT BIOL MED, V95, P43, DOI 10.1016/j.compbiomed.2018.02.004
   Chen ZX, 2022, IEEE T BIO-MED ENG, V69, P3689, DOI 10.1109/TBME.2022.3176097
   Claux F, 2023, J NEURORADIOLOGY, V50, P9, DOI 10.1016/j.neurad.2022.03.005
   Cosmus TC, 2011, IEEE T APPL SUPERCON, V21, P2104, DOI 10.1109/TASC.2010.2084981
   Cruz-Martinez C, 2022, COMPUT METH PROG BIO, V213, DOI 10.1016/j.cmpb.2021.106509
   Czerwinski RN, 1999, IEEE T MED IMAGING, V18, P126, DOI 10.1109/42.759114
   da Cruz LB, 2022, EXPERT SYST APPL, V192, DOI 10.1016/j.eswa.2021.116270
   Das D, 2022, MULTIMED TOOLS APPL, V81, P25613, DOI 10.1007/s11042-022-12642-4
   Das D, 2022, MULTIMED TOOLS APPL, V81, P21471, DOI 10.1007/s11042-022-11913-4
   Dewangan KK, 2022, MULTIMED TOOLS APPL, V81, P13935, DOI 10.1007/s11042-022-12385-2
   Domingues I, 2020, ARTIF INTELL REV, V53, P4093, DOI 10.1007/s10462-019-09788-3
   Duncan JS, 2000, IEEE T PATTERN ANAL, V22, P85, DOI 10.1109/34.824822
   El-Askary NS, 2022, EXPERT SYST APPL, V193, DOI 10.1016/j.eswa.2021.116489
   Faragallah OS, 2021, IEEE ACCESS, V9, P11358, DOI 10.1109/ACCESS.2020.3048315
   Garg V, 2022, EXPERT SYST APPL, V202, DOI 10.1016/j.eswa.2022.117282
   Geis JR, 2007, J DIGIT IMAGING, V20, P99, DOI 10.1007/s10278-007-9010-2
   Gu J, 2016, SCI REP-UK, V6, DOI 10.1038/srep34795
   Guan B, 2022, COMPUT VIS IMAGE UND, V216, DOI 10.1016/j.cviu.2021.103345
   Han ZM, 2022, KNOWL-BASED SYST, V253, DOI 10.1016/j.knosys.2022.109512
   Hashimoto F, 2022, IEEE T RADIAT PLASMA, V6, P841, DOI 10.1109/TRPMS.2022.3161569
   Hu MJ, 2020, IEEE ACCESS, V8, P37265, DOI 10.1109/ACCESS.2020.2974242
   Huang YC, 2021, COMPUT METH PROG BIO, V208, DOI 10.1016/j.cmpb.2021.106271
   Jian MW, 2023, CMES-COMP MODEL ENG, V137, P705, DOI 10.32604/cmes.2023.027425
   Jian MW, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12102333
   Jian MW, 2023, COMPUT BIOL MED, V155, DOI 10.1016/j.compbiomed.2023.106631
   Jian MW, 2021, INFORM SCIENCES, V576, P819, DOI 10.1016/j.ins.2021.08.069
   Jian MW, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114219
   Jin JM, 1998, IEEE ANTENNAS PROPAG, V40, P7, DOI 10.1109/74.739187
   Kashyap S, 2018, IEEE T MED IMAGING, V37, P1103, DOI 10.1109/TMI.2017.2781541
   Kawaji K, 2022, J Nucl Med, V63, P2975
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Khan SH, 2016, INDIAN J NUCL MED, V31, P251, DOI 10.4103/0972-3919.190804
   Kim HY, 2021, IEEE ACCESS, V9, P135256, DOI 10.1109/ACCESS.2021.3116255
   Kumar Raman, 2018, J Family Med Prim Care, V7, P841, DOI 10.4103/jfmpc.jfmpc_218_18
   Leighton TG, 2007, PROG BIOPHYS MOL BIO, V93, P3, DOI 10.1016/j.pbiomolbio.2006.07.026
   Loued-Khenissi L, 2019, ORGAN RES METHODS, V22, P17, DOI 10.1177/1094428118802631
   Lu DH, 2018, MED IMAGE ANAL, V46, P26, DOI 10.1016/j.media.2018.02.002
   Lu XW, 2022, MULTIMEDIA SYST, V28, P1689, DOI 10.1007/s00530-022-00940-8
   Lubell DL, 2005, TEX HEART I J, V32, P250
   Luo YM, 2022, MED IMAGE ANAL, V77, DOI 10.1016/j.media.2021.102335
   Luo YZ, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108427
   Marathe K, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105504
   Milosevic D, 2022, EXPERT SYST APPL, V189, DOI 10.1016/j.eswa.2021.116038
   Momose A, 2005, JPN J APPL PHYS 1, V44, P6355, DOI 10.1143/JJAP.44.6355
   Moon WK, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105361
   MOULD RF, 1995, PHYS MED BIOL, V40, P1741, DOI 10.1088/0031-9155/40/11/001
   Murtaza G, 2020, ARTIF INTELL REV, V53, P1655, DOI 10.1007/s10462-019-09716-5
   Musallam AS, 2022, IEEE ACCESS, V10, P2775, DOI 10.1109/ACCESS.2022.3140289
   Neethi AS, 2022, BIOMED SIGNAL PROCES, V76, DOI 10.1016/j.bspc.2022.103720
   Nikolaou K, 2004, INT J CARDIOVAS IMAG, V20, P535, DOI 10.1007/s10554-004-7015-1
   Ovalle-Magallanes E, 2022, EXPERT SYST APPL, V189, DOI 10.1016/j.eswa.2021.116112
   Pontoriero AD, 2021, COMPUT METH PROG BIO, V208, DOI 10.1016/j.cmpb.2021.106239
   Potter IY, 2023, J DIGIT IMAGING, V36, P869, DOI 10.1007/s10278-022-00771-z
   Qi XF, 2022, NEUROCOMPUTING, V472, P152, DOI 10.1016/j.neucom.2021.11.047
   Qiao XY, 2022, IEEE J BIOMED HEALTH, V26, P3261, DOI 10.1109/JBHI.2022.3164570
   Rizwan M, 2022, IEEE ACCESS, V10, P29731, DOI 10.1109/ACCESS.2022.3153108
   Routh H, 1996, IEEE ENG MED BIOL, V15, P31, DOI 10.1109/51.544510
   Saber A, 2021, IEEE ACCESS, V9, P71194, DOI 10.1109/ACCESS.2021.3079204
   Salama WM, 2021, ALEX ENG J, V60, P4701, DOI 10.1016/j.aej.2021.03.048
   Slomka PJ, 2016, SEMIN NUCL MED, V46, P5, DOI 10.1053/j.semnuclmed.2015.09.006
   Sluimer I, 2006, IEEE T MED IMAGING, V25, P385, DOI 10.1109/TMI.2005.862753
   Song D, 2022, COMPUT METH PROG BIO, V215, DOI 10.1016/j.cmpb.2022.106634
   Song TA, 2020, IEEE T COMPUT IMAG, V6, P518, DOI [10.1109/TCI.2020.2964229, 10.1109/tci.2020.2964229]
   Soulami KB, 2022, BIOMED SIGNAL PROCES, V76, DOI 10.1016/j.bspc.2022.103696
   Spiro SG, 2008, LUNG CANCER, V59, P48, DOI 10.1016/j.lungcan.2007.07.026
   Sun L, 2023, FRONT ONCOL, V13, DOI 10.3389/fonc.2023.1107850
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Talo M, 2019, COMPUT MED IMAG GRAP, V78, DOI 10.1016/j.compmedimag.2019.101673
   Tiwari S, 2022, EXPERT SYST APPL, V203, DOI 10.1016/j.eswa.2022.117592
   Tripathi PC, 2022, COMPUT METH PROG BIO, V215, DOI 10.1016/j.cmpb.2021.106597
   Turkoglu I, 2002, EXPERT SYST APPL, V23, P229, DOI 10.1016/S0957-4174(02)00042-8
   Vagenas TP, 2023, IEEE J BIOMED HEALTH, V27, P1397, DOI 10.1109/JBHI.2022.3230060
   Velichko E, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105172
   Vrbancic G, 2022, EXPERT SYST APPL, V187, DOI 10.1016/j.eswa.2021.115834
   Wang GB, 2019, IEEE T MED IMAGING, V38, P664, DOI 10.1109/TMI.2018.2869868
   Wang XH, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105058
   Wang Z, 2022, EXPERT SYST APPL, V194, DOI 10.1016/j.eswa.2022.116519
   Wijdicks EFM, 2018, NEUROCRIT CARE, V28, P273, DOI 10.1007/s12028-017-0495-3
   Yan Y, 2022, BIOMED SIGNAL PROCES, V72, DOI 10.1016/j.bspc.2021.103299
   Yang X, 2022, COMPUT MATH METHOD M, V2022, DOI 10.1155/2022/3452176
   Yang X, 2019, IEEE T MED IMAGING, V38, P180, DOI 10.1109/TMI.2018.2858779
   Yaqub M, 2022, COMPUT MATH METHOD M, V2022, DOI 10.1155/2022/8750648
   Yi X, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101552
   Yin WT, 2022, NEUROCOMPUTING, V469, P332, DOI 10.1016/j.neucom.2020.05.113
   Yin YC, 2023, COMPUT BIOL MED, V162, DOI 10.1016/j.compbiomed.2023.107120
   Zhang L, 2021, ALEX ENG J, V60, P897, DOI 10.1016/j.aej.2020.10.018
   Zhou SK, 2021, P IEEE, V109, P820, DOI 10.1109/JPROC.2021.3054390
NR 97
TC 1
Z9 1
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17326-1
EA OCT 2023
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400004
DA 2024-07-18
ER

PT J
AU Purbey, S
   Sharma, R
   Khandelwal, B
AF Purbey, Suniti
   Sharma, Rika
   Khandelwal, Brijesh
TI Design of an efficient low-complexity bioinspired blockchain-based
   semantic medical-event analysis & reporting model via deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Blockchain; PoAT; Consensus; QoS; GWO; LSTM; GRU; Word2Vec; Clinical;
   Diseases; Alerts; Bioinspired; Blockchain-based; Semantic-powered;
   Medical-event analysis; Deep learning; Process
ID SMART HEALTH-CARE; ECG CLASSIFICATION-SYSTEM; ARTIFICIAL-INTELLIGENCE;
   DIGITAL TWIN; INTERNET; ARCHITECTURE; MOVEMENT; ENSEMBLE; FEATURES;
   NETWORK
AB Analysis of medical reports & their accurate reporting involves design of efficient data mining processes that can be scaled for multiple scenarios. Modern day reports consist of both numerical & textual data samples, thus semantic analysis is also a big challenge that must be tackled via language processing operations. Existing deep learning solutions for this model involve use of context-specific Bidirectional Encoder Representation from Transformers (BERT), which are highly complex, and cannot be scaled for clinical use cases. Simpler solutions that use document frequencies showcase low accuracy, which limits their applicability to real-time clinical scenarios. To overcome these issues while incorporating security, this text proposes design of an efficient low-complexity bioinspired blockchain-based semantic-powered medical-event analysis & reporting model via deep learning operations. The proposed model initially collects large-scale medical datasets and converts them into numerical sets via extraction of Word2Vec features. These feature sets are combined with numerical report data and given to a fusion of Long-Short-Term Memory (LSTM) & Gated Recurrent Unit (GRU) for identification of high-density features. The identified features are represented into multiple domains including Wavelet, Gabor, Frequency, and Cosine, which assists the correlation-based Convolutional Neural Network (CNN) classifier to estimate probability of different disease types. These probabilities are stored on a Grey Wolf Optimized (GWO) blockchain that uses Proof-of-Alert Trust (PoAT) consensus. This consensus model identifies a set of high-trust nodes that can alert medical experts with high Quality of Service (QoS) while maintaining transparency, traceability, distributed computing & immutability characteristics. Due to which, the proposed model is able to mitigate multiple attacks, and maintain low communication delay, low energy consumption, and high throughput levels. The model was also able to achieve 8.5% higher alert identification accuracy, 3.9% higher alert precision, and 4.5% higher alert recall when compared with standard alerting models under clinical scenarios.
C1 [Purbey, Suniti; Sharma, Rika] Amity Univ Chhattisgarh, Amity Sch Engn & Technol, Raipur, India.
   [Purbey, Suniti] GMR Inst Technol, Dept CSE, Rajam, Andhra Pradesh, India.
   [Khandelwal, Brijesh] SGT Univ, Gurugram, Haryana, India.
C3 GMR Institute of Technology
RP Purbey, S (corresponding author), Amity Univ Chhattisgarh, Amity Sch Engn & Technol, Raipur, India.; Purbey, S (corresponding author), GMR Inst Technol, Dept CSE, Rajam, Andhra Pradesh, India.
EM sunitynu@gmail.com; rsharma1@rpr.amity.edu.in; bbrijeshlko@yahoo.com
OI Sharma, Dr. Rika/0000-0002-4390-6967
CR Abbas SA, 2020, IEEE ACCESS, V8, P102146, DOI 10.1109/ACCESS.2020.2999899
   Al-Dhief FT, 2021, IEEE ACCESS, V9, P77293, DOI 10.1109/ACCESS.2021.3082565
   Alhassan AM, 2021, IEEE ACCESS, V9, P87310, DOI 10.1109/ACCESS.2021.3088613
   Alkhodari M, 2021, IEEE J BIOMED HEALTH, V25, P746, DOI 10.1109/JBHI.2020.3002336
   Amin SU, 2021, IEEE ACCESS, V9, P45, DOI 10.1109/ACCESS.2020.3045115
   Ariyanti W, 2021, IEEE SENSOR LETT, V5, P1, DOI 10.1109/LSENS.2021.3091141
   Chen YY, 2021, IEEE ACM T COMPUT BI, V18, P902, DOI 10.1109/TCBB.2019.2903804
   Dai D, 2021, IEEE T CYBERNETICS, V51, P2019, DOI 10.1109/TCYB.2019.2916580
   Elayan H, 2021, IEEE INTERNET THINGS, V8, P16749, DOI 10.1109/JIOT.2021.3051158
   Fan F., 2021, arXiv
   Fu RQ, 2022, IEEE T NEUR SYS REH, V30, P1384, DOI 10.1109/TNSRE.2022.3174821
   Goyal M, 2020, IEEE TETCI, V4, P728, DOI 10.1109/TETCI.2018.2866254
   Habib M, 2022, IEEE J BIOMED HEALTH, V26, P2008, DOI 10.1109/JBHI.2022.3140433
   Hajjej F, 2022, IEEE ACCESS, V10, P116527, DOI 10.1109/ACCESS.2022.3214986
   Hu SP, 2020, IEEE ACCESS, V8, P118869, DOI 10.1109/ACCESS.2020.3005510
   Huang Y, 2022, IEEE J BIOMED HEALTH, V26, P5394, DOI 10.1109/JBHI.2022.3199377
   Jia GY, 2020, IEEE T NEUR SYS REH, V28, P1428, DOI 10.1109/TNSRE.2020.2986884
   Kalendralis P, 2022, IEEE T RADIAT PLASMA, V6, P200, DOI 10.1109/TRPMS.2021.3070656
   Khan N, 2022, IEEE T IND INFORM, V18, P8924, DOI 10.1109/TII.2022.3159710
   Khan P, 2022, IEEE T COMPUT SOC SY, V9, P1495, DOI 10.1109/TCSS.2021.3116428
   Kumar PM, 2022, IEEE J BIOMED HEALTH, V26, P973, DOI 10.1109/JBHI.2021.3106387
   Kung BH, 2021, IEEE J BIOMED HEALTH, V25, P1904, DOI 10.1109/JBHI.2020.3035191
   Li JP, 2020, IEEE ACCESS, V8, P107562, DOI 10.1109/ACCESS.2020.3001149
   Lu JH, 2021, IEEE T CIRCUITS-I, V68, P2976, DOI 10.1109/TCSI.2021.3072622
   Mahiddin N, 2022, IEEE ACCESS, V10, P31660, DOI 10.1109/ACCESS.2022.3160725
   Maji P, 2021, IEEE T CONSUM ELECTR, V67, P235, DOI 10.1109/TCE.2021.3129316
   Mansour RF, 2021, IEEE ACCESS, V9, P45137, DOI 10.1109/ACCESS.2021.3066365
   Matloob I, 2020, IEEE ACCESS, V8, P143256, DOI 10.1109/ACCESS.2020.3013962
   Maweu BM, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3077049
   Meng LW, 2020, IEEE J BIOMED HEALTH, V24, P3576, DOI 10.1109/JBHI.2020.3034296
   Miranda D, 2022, IEEE T ULTRASON FERR, V69, P2663, DOI 10.1109/TUFFC.2022.3195477
   Muhammad G, 2021, IEEE ACCESS, V9, P89198, DOI 10.1109/ACCESS.2021.3090317
   Muhammad K, 2021, IEEE T NEUR NET LEAR, V32, P507, DOI 10.1109/TNNLS.2020.2995800
   Newrzella SR, 2021, IEEE ACCESS, V9, P131306, DOI 10.1109/ACCESS.2021.3115055
   Persson A, 2021, IEEE T INTELL TRANSP, V22, P3316, DOI 10.1109/TITS.2020.2981941
   Piri J, 2022, IEEE ACCESS, V10, P1756, DOI 10.1109/ACCESS.2021.3138403
   Purbey S, 2023, SIGNAL IMAGE VIDEO P, V17, P3515, DOI 10.1007/s11760-023-02576-1
   Qiao XS, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3105124
   Rahman MA, 2021, IEEE INTERNET THINGS, V8, P15847, DOI 10.1109/JIOT.2021.3051080
   Ramasamy MD, 2021, IEEE ACCESS, V9, P112624, DOI 10.1109/ACCESS.2021.3103746
   Saeed U, 2021, IEEE SENS J, V21, P23518, DOI 10.1109/JSEN.2021.3110367
   Salahuddin Z, 2022, COMPUT BIOL MED, V140, DOI 10.1016/j.compbiomed.2021.105111
   Saraswat D, 2022, IEEE ACCESS, V10, P84486, DOI 10.1109/ACCESS.2022.3197671
   Shen B, 2021, IEEE T AUTOM SCI ENG, V18, P1998, DOI 10.1109/TASE.2020.3029028
   Subramanian B, 2022, IEEE ACCESS, V10, P81155, DOI 10.1109/ACCESS.2022.3193941
   Sun L, 2022, IEEE INTERNET THINGS, V9, P7178, DOI 10.1109/JIOT.2021.3108792
   Sun YG, 2020, IEEE ACCESS, V8, P191942, DOI 10.1109/ACCESS.2020.3031603
   Tao Y, 2022, IEEE T NEUR SYS REH, V30, P2754, DOI 10.1109/TNSRE.2022.3208710
   Teng F, 2020, IEEE J BIOMED HEALTH, V24, P2506, DOI 10.1109/JBHI.2020.2996937
   Ul Haq A, 2022, IEEE J BIOMED HEALTH, V26, P5004, DOI 10.1109/JBHI.2022.3171663
   Usharani AV, 2022, IEEE ACCESS, V10, P34404, DOI 10.1109/ACCESS.2022.3161439
   Wang CR, 2021, IEEE T IMAGE PROCESS, V30, P7980, DOI 10.1109/TIP.2021.3112053
   Wang L, 2020, IEEE ROBOT AUTOM LET, V5, P1970, DOI 10.1109/LRA.2020.2970656
   Wang WG, 2022, Arxiv, DOI arXiv:2209.07383
   Xing WC, 2020, IEEE ACCESS, V8, P28808, DOI 10.1109/ACCESS.2019.2955754
   Yu HQ, 2021, IEEE ACCESS, V9, P50244, DOI 10.1109/ACCESS.2021.3069024
   Zhou XK, 2020, IEEE INTERNET THINGS, V7, P6429, DOI 10.1109/JIOT.2020.2985082
NR 57
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17238-0
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400021
DA 2024-07-18
ER

PT J
AU Purwar, A
   Chawla, I
AF Purwar, Archana
   Chawla, Indu
TI A systematic review on fall detection systems for elderly healthcare
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fall Detection systems; Elderly Healthcare; Machine learning; IoT;
   Segmentation; Wearable; Non-wearable; Sensors
ID VIDEO SURVEILLANCE; GAIT SPEED; RECOGNITION; SENSORS; PEOPLE; ROBUST;
   FLOOR; FRAMEWORK; INTERNET; FUSION
AB To ensure healthy lives and promoting well-being for all in the society at all ages is one of the goals of United Nations. Specially, health of elderly people plays an important factor in productivity and prosperity of any country. According to reports, there will be over two billion elderly people worldwide by 2050. Most of elderly people live independently and need some system to protect them from any kind of fall. As old people are highly susceptible to fall due to weak body structure as well as some external conditions, researchers from academia and industries are developing fall detections systems (FDS) or devices to prevent them from fall. Hence, this paper majorly aims to review the papers on fall detection systems (FDS) to protect elderly people from any kind of fall. Papers selected for this study spans from 2017- 2023. FDS will be helpful to sustain the health of elderly persons. In view of strengthening research in this domain, this study gives an integrated and a critical review of work done in this area for both wearable, non-wearable systems and hybrid systems with research directions as the advent of new technologies like deep learning, computer vision, Internet of Things (IoT) and big data may improve the existing approaches/systems.
C1 [Purwar, Archana; Chawla, Indu] Jaypee Inst Informat Technol, Dept Comp Sci & Engn & Informat Technol, Noida, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Purwar, A (corresponding author), Jaypee Inst Informat Technol, Dept Comp Sci & Engn & Informat Technol, Noida, India.
EM archana.purwar@gmail.com; indu.chawla@jiit.ac.in
CR Alam E, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105626
   Alanazi T, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13126916
   Alharthi AS, 2021, IEEE SENS J, V21, P16904, DOI 10.1109/JSEN.2021.3078336
   Alwan M., 2006, 2 INFORM COMMUNICATI, P1003, DOI DOI 10.1109/ICTTA.2006.1684511
   Alzahrani MS, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS (SITIS), P327, DOI 10.1109/SITIS.2017.61
   [Anonymous], Fall detection dataset
   Ben-Sadoun G, 2022, CLIN INTERV AGING, V17, P35, DOI 10.2147/CIA.S329668
   Biswas S., 2018, 2018 INT C WIR COMM
   Butt A, 2022, WIRELESS PERS COMMUN, V126, P1733, DOI 10.1007/s11277-022-09819-3
   Casilari E, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040649
   Casilari-Pérez E, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.07.028
   Chaccour K, 2015, IEEE CONF WIREL MOB, P225, DOI 10.1109/WiMOB.2015.7347965
   Charfi I, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P218, DOI 10.1109/SITIS.2012.155
   Chen XS, 2020, IEEE SENSOR, DOI 10.1109/sensors47125.2020.9278625
   Cippitelli Enea, 2016, IEEE DataPort, DOI 10.21227/H2VC7J
   de Miguel K, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122864
   de Quadros T, 2018, IEEE SENS J, V18, P5082, DOI 10.1109/JSEN.2018.2829815
   Deepika S., 2022, 2022 6 INT C TRENDS, P573
   Desai Kimaya, 2020, 2020 IEEE International Conference on Computing, Power and Communication Technologies (GUCON), P502, DOI 10.1109/GUCON48875.2020.9231114
   Ding WP, 2018, IEEE-RAS INT C HUMAN, P827
   Diraco G, 2010, DES AUT TEST EUROPE, P1536
   Dogan JC, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP 2019), P434, DOI 10.1109/SMARTCOMP.2019.00083
   Eltahir MM, 2023, Comput Mater Contin, V75
   Gutiérrez J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030947
   Hamm J, 2016, J BIOMED INFORM, V59, P319, DOI 10.1016/j.jbi.2015.12.013
   Harris E, 2023, JAMA
   Hassan MM, 2019, IEEE NETWORK, V33, P58, DOI 10.1109/MNET.001.1900100
   He CH, 2023, MICROMACHINES-BASEL, V14, DOI 10.3390/mi14010130
   Nguyen HG, 2018, IEEE INT C ENG COMP, P1, DOI [10.1109/ICOPS35962.2018.9575287, 10.1109/ICECCS2018.2018.00009]
   Le HL, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11071030
   Honore JT., 2022, International Conference on ICT for Health, Accessibility and Wellbeing, P3
   Hsu YW, 2015, 2015 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P433, DOI 10.1109/SII.2015.7405018
   Hu Z., 2023, J Eng Fibers Fabr, V18, P155
   Hussain F, 2019, IEEE SENS J, V19, P4528, DOI 10.1109/JSEN.2019.2898891
   Inturi AR, 2023, ARAB J SCI ENG, V48, P1143, DOI 10.1007/s13369-022-06684-x
   Islam MM, 2023, INFORM FUSION, V94, P17, DOI 10.1016/j.inffus.2023.01.015
   Jain R, 2022, IEEE SENS J, V22, P22943, DOI 10.1109/JSEN.2022.3213814
   Jokanovic B, 2018, IEEE T AERO ELEC SYS, V54, P180, DOI 10.1109/TAES.2017.2740098
   Kepski M, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P640
   Keskes O, 2021, IEEE ACCESS, V9, P28224, DOI 10.1109/ACCESS.2021.3058219
   Khan MS, 2015, SIGNAL PROCESS, V110, P199, DOI 10.1016/j.sigpro.2014.08.021
   Khojasteh SB, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051350
   Klack L, 2011, L N INST COMP SCI SO, V55, P211
   Kosarava K., 2021, A simple indoor fall control system for the elderly based on the analysis of object bounding box parameters
   Kulurkar P., 2023, Meas: Sensors, V25
   Kurita K., 2012, SENSORS, 2012 IEEE, P1
   Kwolek B, 2014, COMPUT METH PROG BIO, V117, P489, DOI 10.1016/j.cmpb.2014.09.005
   Lee JS, 2019, IEEE SENS J, V19, P8293, DOI 10.1109/JSEN.2019.2918690
   Lezzar Fouzi, 2020, Applied Medical Informatics, V42, P169
   Li JJ, 2023, INT J MACH LEARN CYB, V14, P1831, DOI 10.1007/s13042-022-01730-4
   Liu KC, 2020, IEEE SENS J, V20, P3303, DOI 10.1109/JSEN.2019.2955141
   Liu KC, 2018, IEEE SENS J, V18, P9882, DOI 10.1109/JSEN.2018.2872835
   Luna-Perejón F, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19224885
   Maldonado-Bascón S, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8090915
   Martínez-Villaseñor L, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19091988
   Mehmood A, 2019, HEALTH TECHNOL-GER, V9, P631, DOI 10.1007/s12553-019-00298-4
   Montero-Odasso M, 2022, AGE AGEING, V51, DOI 10.1093/ageing/afac205
   Muheidat F, 2020, IEEE ACCESS, V8, P178627, DOI 10.1109/ACCESS.2020.3027535
   Muro-de-la-Herran A, 2014, SENSORS-BASEL, V14, P3362, DOI 10.3390/s140203362
   Al Nahian MJ, 2021, IEEE ACCESS, V9, P39413, DOI 10.1109/ACCESS.2021.3056441
   Nakamura T, 2020, IEEE GLOB COMM CONF, DOI 10.1109/GLOBECOM42002.2020.9322323
   Ng YJ., 2021, Int J Human Technol Interact (IJHaTI), V5, P37
   Oh-Park M, 2021, AM J PHYS MED REHAB, V100, P92, DOI 10.1097/PHM.0000000000001554
   Orr R. J., 2000, CHI 00 EXTENDED ABST, P275, DOI [DOI 10.1145/633292.633453, 10.1145/633451.633453]
   Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1016/j.ijsu.2021.105906, 10.1136/bmj.n160]
   Pal D, 2018, IEEE ACCESS, V6, P10483, DOI 10.1109/ACCESS.2018.2808472
   Palmerini L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20226479
   Pech M, 2021, JMIR AGING, V4, DOI 10.2196/29744
   Peel NM, 2013, J GERONTOL A-BIOL, V68, P39, DOI 10.1093/gerona/gls174
   Principi E, 2016, EXPERT SYST APPL, V60, P51, DOI 10.1016/j.eswa.2016.04.007
   Qian ZQ, 2022, IEEE INTERNET THINGS, V9, P21999, DOI 10.1109/JIOT.2022.3181701
   Ramachandran A, 2020, BIOMED RES INT-UK, V2020, DOI 10.1155/2020/2167160
   Rochat S, 2010, ARCH PHYS MED REHAB, V91, P879, DOI 10.1016/j.apmr.2010.03.005
   Rougier C, 2011, IEEE T CIRC SYST VID, V21, P611, DOI 10.1109/TCSVT.2011.2129370
   Saleh M, 2019, IEEE SENS J, V19, P3156, DOI 10.1109/JSEN.2019.2891128
   Semwal V.B., 2023, MACHINE LEARNING IMA, P815
   Shahiduzzaman KM, 2019, IEEE INT C ELECTR TA, DOI 10.1109/icce-tw46550.2019.8991972
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Sheikh SY, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03279-6
   Shi GY, 2009, IEEE SENS J, V9, P495, DOI 10.1109/JSEN.2008.2012212
   Shu F, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-81115-9
   Singh A, 2020, IEEE SENS J, V20, P6889, DOI 10.1109/JSEN.2020.2976554
   Somkunwar R.K., 2023, J. Data Acquisition Processing, V38, P3985
   Soni P.K., 2019, 2019 Second International Conference on Advanced Computational and Communication Paradigms (ICACCP), P1
   Stone EE, 2012, IEEE ENG MED BIO, P5106, DOI 10.1109/EMBC.2012.6347142
   Sundaram B. Meenakshi, 2023, 2023 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE), P554, DOI 10.1109/IITCEE57236.2023.10090887
   Taylor ME, 2012, AGE AGEING, V41, P665, DOI 10.1093/ageing/afs057
   Torres-Guzman RA, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23031323
   Turan MS, 2022, DIGIT SIGNAL PROCESS, V125, DOI 10.1016/j.dsp.2021.103129
   Usmani S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21155134
   Valero CI, 2021, COMPUT COMMUN, V177, P96, DOI 10.1016/j.comcom.2021.06.010
   van Kan GA, 2009, J NUTR HEALTH AGING, V13, P881
   VandeWeerd C, 2020, HEALTH TECHNOL-GER, V10, P1291, DOI 10.1007/s12553-019-00404-6
   Viccaro LJ, 2011, J AM GERIATR SOC, V59, P887, DOI 10.1111/j.1532-5415.2011.03336.x
   Waheed M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062006
   Wang XY, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00071
   who, About us
   Wu L, 2023, NEURAL NETWORKS, V163, P286, DOI 10.1016/j.neunet.2023.03.042
   Xiaojie Lv, 2020, 2020 6th International Conference on Big Data and Information Analytics (BigDIA), P386, DOI 10.1109/BigDIA51454.2020.00069
   Yacchirema D, 2018, PROCEDIA COMPUT SCI, V130, P603, DOI 10.1016/j.procs.2018.04.110
   Yergaliyev Z., 2022, Human activity recognition and fall detection using video and inertial sensors
   Youngkong P, 2021, 2021 SECOND INTERNATIONAL SYMPOSIUM ON INSTRUMENTATION, CONTROL, ARTIFICIAL INTELLIGENCE, AND ROBOTICS (ICA-SYMP), P39, DOI 10.1109/ICA-SYMP50206.2021.9358439
   Younis B, 2021, 2021 4TH INTERNATIONAL SYMPOSIUM ON ADVANCED ELECTRICAL AND COMMUNICATION TECHNOLOGIES (ISAECT), DOI 10.1109/ISAECT53699.2021.9668520
   Zhao ZX, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22155482
NR 104
TC 1
Z9 1
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17190-z
EA OCT 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400010
DA 2024-07-18
ER

PT J
AU Dachraoui, C
   Mouelhi, A
   Mosbeh, A
   Sliti, W
   Drissi, C
   Solaiman, B
   Labidi, S
AF Dachraoui, Chaima
   Mouelhi, Aymen
   Mosbeh, Amine
   Sliti, Wassim
   Drissi, Cyrine
   Solaiman, Basel
   Labidi, Salam
TI A machine learning approach for multiple sclerosis diagnosis through
   Detecron Architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE MRI; 3D FLAIR; Multiple sclerosis; Diagnosis; Detecron-2; Detection
ID LESION SEGMENTATION; MRI
AB Multiple sclerosis is a prevalent inflammatory disease affecting the central nervous system, leading to demyelination. Neuroradiology relies on accurate analysis of white matter lesions for diagnosis and prognosis. Automated methods for segmenting lesions in MRI scans offer crucial benefits of objectivity and efficiency, making them particularly valuable for analyzing large datasets. In contrast, manual delineation of MRI lesions is both time-consuming and prone to subjective bias. To overcome these issues, this paper proposes and develops an automated diagnosis approach using the Detecron-2 architecture. The method utilizes a fully modified Convolutional Neural Network on 3D FLAIR-weighted Magnetic Resonance Images.The approach is trained and validated on a dataset of 3000 images acquired from a Siemens 3Tesla MRI machine at the National Institute of Neurology Mongi Ben Hmida in Tunisia, using technical metrics. Comparisons with recent achievements demonstrate promising results. By addressing challenges in data augmentation and deep learning configurations, the proposed model effectively mitigates issues as overfitting. Notably, it achieves an impressive average detection accuracy of 87%, specificity (= 80,19%), precision (= 80%), sensitivity (= 76,1%) and intersection over Union (= 87,9%) when assessing healthy and pathological images. Additionally, the study recognizes the manual monitoring of multiple sclerosis plaques as a time-consuming and challenging task for clinicians. It highlights the importance of lesion segmentation for quantitative analysis of disease progression. As a second focus, the research aims to develop an automated segmentation to enhance the accuracy and efficiency of lesion identification, addressing the inconsistencies and variations observed among different observers.
C1 [Dachraoui, Chaima; Labidi, Salam] Univ Tunis El Manar, Higher Inst Med Technol Tunis, Res Lab Biophys & Med Technol LR13ES07, Tunis, Tunisia.
   [Mouelhi, Aymen] Univ Tunis, Natl Engn Sch Tunis, Lab Signal Image & Energy Mastery LR13ES03, Tunis, Tunisia.
   [Mosbeh, Amine; Sliti, Wassim] Tunisia Mil Acad FondekJdid, Natl Sch Vet Med Sidi Thabet, Comp Sci Dept, Tunis, Tunisia.
   [Drissi, Cyrine] Univ Tunis El Manar, Natl Inst Neurol Mongi Ben Hmida, Fac Med Tunisia, Tunis, Tunisia.
   [Solaiman, Basel] UBL, LaTIM UMR 1101, IMT Atlantique, Brest, France.
C3 Universite de Tunis-El-Manar; Universite de Tunis-El-Manar; Ecole
   Nationale d'Ingenieurs de Tunis (ENIT); Universite de Tunis; Universite
   de Tunis-El-Manar; Institut National de la Sante et de la Recherche
   Medicale (Inserm); IMT - Institut Mines-Telecom; IMT Atlantique
RP Dachraoui, C (corresponding author), Univ Tunis El Manar, Higher Inst Med Technol Tunis, Res Lab Biophys & Med Technol LR13ES07, Tunis, Tunisia.
EM chaima.dachraoui@istmt.utm.tn; aymen_mouelhi@yahoo.fr;
   aminemosbah@hotmail.com; wassimsliti1998@gmail.com;
   cyrine.drissi@fmt.utm.tn; basel.solaiman@imt-atlantique.fr;
   salam.labidi@istmt.utm.tn
OI Labidi, Salam/0000-0001-8535-9749
CR Afzal HMR, 2021, CMC-COMPUT MATER CON, V66, P977, DOI 10.32604/cmc.2020.012448
   Ansari SU, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/4138137
   Antonelli M, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30695-9
   Berger C, 2022, FORENSIC SCI INT, V341, DOI 10.1016/j.forsciint.2022.111494
   Boesen MS, 2022, MULT SCLER RELAT DIS, V62, DOI 10.1016/j.msard.2022.103738
   Eliezer M, 2022, DIAGN INTERV IMAG, V103, P13, DOI 10.1016/j.diii.2021.09.004
   Filippi M, 2023, J NEUROL, V270, P1286, DOI 10.1007/s00415-022-11488-y
   Filippi M, 2022, NEUROLOGY, V98, pE1, DOI 10.1212/WNL.0000000000013016
   Freund M, 2022, FRONT NEUROL, V13, DOI 10.3389/fneur.2022.856240
   Hashemi M, 2022, COMPUT BIOL MED, V145, DOI 10.1016/j.compbiomed.2022.105402
   Jimeno MM, 2022, MAGN RESON IMAGING, V89, P42, DOI 10.1016/j.mri.2022.02.002
   Kats E., 2019, Comput Sci, DOI [10.48550/arXiv.1901.09263, DOI 10.48550/ARXIV.1901.09263]
   Krishnan AP, 2022, RADIOLOGY, V302, P662, DOI 10.1148/radiol.211528
   Krüger J, 2020, NEUROIMAGE-CLIN, V28, DOI 10.1016/j.nicl.2020.102445
   Kuhlmann T, 2023, LANCET NEUROL, V22, P78, DOI 10.1016/S1474-4422(22)00289-7
   La Rosa F, 2020, NEUROIMAGE-CLIN, V27, DOI 10.1016/j.nicl.2020.102335
   La Rosa F, 2019, LECT NOTES COMPUT SC, V11383, P142, DOI 10.1007/978-3-030-11723-8_14
   Liang S, 2021, FRONT NEUROINFORM, V15, DOI 10.3389/fninf.2021.622951
   Martins T, 2024, MULTIMED TOOLS APPL, V83, P12035, DOI 10.1007/s11042-023-16051-z
   McKinley R, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-79925-4
   Mendelsohn Z, 2023, NEURORADIOLOGY, V65, P5, DOI 10.1007/s00234-022-03074-w
   Motovilova E, 2022, FRONT PHYS-LAUSANNE, V10, DOI 10.3389/fphy.2022.907619
   Okaz A, 2023, Al-Azhar Int Med J, V4, DOI [10.58675/2682-339X.1631, DOI 10.58675/2682-339X.1631]
   Pozzilli C, 2023, EUR J NEUROL, V30, P9, DOI 10.1111/ene.15593
   Murúa SR, 2022, ANNU REV PATHOL-MECH, V17, P121, DOI 10.1146/annurev-pathol-052920-040318
   Roozpeykar S, 2022, AM J NUCL MED MOLEC, V12, P63
   Sadeghibakhi M, 2022, IEEE J TRANSL ENG HE, V10, DOI 10.1109/JTEHM.2022.3172025
   Sahu S, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03681-0
   Sarica B, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.912000
   Siger M, 2022, CLIN NEURORADIOL, V32, P625, DOI 10.1007/s00062-022-01144-3
   Thakur SP, 2022, FRONT MED-LAUSANNE, V9, DOI 10.3389/fmed.2022.797586
   Tomassini V, 2020, J NEUROL, V267, P2917, DOI 10.1007/s00415-020-09930-0
   Valverde S, 2017, NEUROIMAGE, V155, P159, DOI 10.1016/j.neuroimage.2017.04.034
   Yahya N, 2023, 2023 2 INT C VIS EM, P1, DOI [10.1109/ViTECoN58111.2023.10157177, DOI 10.1109/VITECON58111.2023.10157177]
   Zamzam AEA, 2022, EGYPT J RADIOL NUC M, V53, DOI 10.1186/s43055-022-00795-z
   Zhang L, 2023, PATTERN RECOGN, V138, DOI 10.1016/j.patcog.2023.109400
   Zhao XD, 2023, INT J MOL SCI, V24, DOI 10.3390/ijms24076373
NR 37
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17055-5
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800017
DA 2024-07-18
ER

PT J
AU Kamala, C
   Shivaram, JM
AF Kamala, C.
   Shivaram, Joshi Manisha
TI Segmentation of ovarian cyst using improved U-NET and hybrid deep
   learning model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Ovarian cancer; Ultrasound detection; Deep learning model; Image
   enhancement; Cystic ovary; Segmentation; U-Net model; Seagull
   optimization algorithm; Bilateral filter
AB The female reproductive system relies on the ovaries to produce eggs, but ovarian cysts can lead to complications such as torsion, infertility, and cancer, making it essential to diagnose them quickly. Ultrasound images are commonly used to detect ovarian cysts, but segmenting cyst regions from the surrounding tissue poses a challenge due to complex patterns and similar intensities. Few methods use the background's texture information to facilitate foreground segmentation. Ultrasound images include characters like speckle noise, low contrast appearance, and blurry boundaries that further complicate the task. Lesion shape and position variations exacerbate these challenges. This study proposes an improved deep learning-based segmentation technique using a database of ovarian ultrasound cyst images to overcome these issues. At the outset, the input has undergone pre-processing using non-sub-sampled contourlet domain-based cross-guided bilateral filtering (CGBF) and improved U-Net (IU-NET) for image segmentation. The presented architecture involved reducing the intricacy of U-Net through the alleviation of certain parameters. This resulted in a substantial acceleration of the learning process, by a factor of 100. To optimize the improved U-Net model, the Seagull Optimization Algorithm (SOA) was used. The algorithm helped to fine-tune the hyper-parameters of the U-Net architecture, including the batch size, learning rate, and epoch count, to achieve optimal performance. The optimization was performed by solving an objective function, which involved determining the dice loss coefficient (DLC) and weight cross-entropy (WCE). A numerical analysis was conducted, which demonstrated that the proposed methodology outperforms existing methods in terms of segmentation accuracy. The proposed model achieved a pixel accuracy of 99.36%, which was significantly higher than that achieved by existing methods.
C1 [Kamala, C.] Dr Ambedkar Inst Technol, Dept Med Elect, Bengaluru 560056, Karnataka, India.
   [Shivaram, Joshi Manisha] BMS Coll Engn, Dept Med Elect, Bengaluru 560019, Karnataka, India.
C3 BMS College of Engineering
RP Kamala, C (corresponding author), Dr Ambedkar Inst Technol, Dept Med Elect, Bengaluru 560056, Karnataka, India.
EM kamala.ml@drait.edu.in; msj.ml@bmsce.ac.in
CR Aggarwal S., 2021, Recent Patents Eng, V15, P53, DOI [10.2174/1872212115999201224130204, DOI 10.2174/1872212115999201224130204]
   Azli SNBB, 2022, IEOM Soc Int, P1842
   Chen Z, 2022, FRONT REPROD HEALTH, V4, DOI 10.3389/frph.2022.877216
   Mehr HD, 2022, HEALTH TECHNOL-GER, V12, P137, DOI 10.1007/s12553-021-00613-y
   Dhiman G, 2019, KNOWL-BASED SYST, V165, P169, DOI 10.1016/j.knosys.2018.11.024
   Fischer-Holzhausen S, 2022, Curr Opin Endocr Metab Res, V2022
   Gopalakrishnan C, 2021, INT J SYST ASSUR ENG, DOI 10.1007/s13198-021-01203-x
   Hema LK, 2022, CONTRAST MEDIA MOL I, V2022, DOI 10.1155/2022/5968939
   Hsu ST, 2022, BMC MED INFORM DECIS, V22, DOI 10.1186/s12911-022-02047-6
   Jin JB, 2021, FRONT ONCOL, V10, DOI 10.3389/fonc.2020.614201
   Jubairahmed L, 2019, CLUSTER COMPUT, V22, P11237, DOI 10.1007/s10586-017-1370-x
   Jung Y, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-20653-2
   Karthiga R, 2021, PATTERN ANAL APPL, V24, P981, DOI 10.1007/s10044-021-00963-3
   Kiruthika V., 2020, Int J Adv Mechatronic Syst, V8, P75, DOI [10.1504/IJAMECHS.2020.111306, DOI 10.1504/IJAMECHS.2020.111306]
   Kodipalli A, 2023, INT J E-HEALTH MED C, V14, DOI 10.4018/IJEHMC.321149
   Kumar V, 2020, IEEE ACCESS, V8, P63482, DOI [10.1109/ACCESS.2020.2982390, 10.1109/access.2020.2982390]
   Li HM, 2020, IEEE J BIOMED HEALTH, V24, P974, DOI 10.1109/JBHI.2019.2946092
   Liu ZH, 2022, NEUROCOMPUTING, V512, P398, DOI 10.1016/j.neucom.2022.09.093
   Mahanty Mohan, 2021, Smart Technologies in Data Science and Communication. Proceedings of SMART-DSC 2021. Lecture Notes in Networks and Systems (LNNS 210), P337, DOI 10.1007/978-981-16-1773-7_27
   Marques S, 2019, IEEE INT ULTRA SYM, P1485, DOI [10.1109/ultsym.2019.8925948, 10.1109/ULTSYM.2019.8925948]
   Mondal D., 2021, Machine Learning Applications in Engineering Education and Management, V1, P7
   Nagarajan Pillai Honey, 2021, Revue d'Intelligence Artificielle, V35, P273, DOI 10.18280/ria.350401
   Potocnik B, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031246
   Potocnik B, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105621
   Rachana B., 2021, Glob Transit Proc, V2, P304, DOI [10.1016/j.gltp.2021.08.010, DOI 10.1016/J.GLTP.2021.08.010]
   Saeedzarandi M, 2020, CIRC SYST SIGNAL PR, V39, P2968, DOI 10.1007/s00034-019-01291-y
   Sheela S., 2020, Indian J Sci Technol, V13, P4142, DOI [10.17485/IJST/v13i39.1602, DOI 10.17485/IJST/v13i39.1602]
   Smith AG, 2020, PLANT METHODS, V16, DOI 10.1186/s13007-020-0563-0
   Soni P., 2019, Int J Comput Sci Eng, V7, P534
   Srivastava S., 2020, SN Comput Sci, V1, P1, DOI [10.1007/s42979-020-0109-6, DOI 10.1007/S42979-020-0109-6]
   Suha SA, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-21724-0
   Uplaonkar D S., 2021, Eng. Sci, V16, P354, DOI DOI 10.30919/ES8D594
   Wadhwa G., 2021, Ann. Rom. Soc. Cell Biol, V25, P4449
   Wanderley Diego, 2022, Procedia Computer Science, P542, DOI 10.1016/j.procs.2021.12.047
   Yang X, 2021, MED IMAGE ANAL, V73, DOI 10.1016/j.media.2021.102134
   Zhang Y., 2022, Journal of Healthcare Engineering, V2022
   Zhang Z, 2020, IEEE ACCESS, V8, P44999, DOI 10.1109/ACCESS.2020.2977962
   Zhou MY, 2020, IEEE ACCESS, V8, P132253, DOI 10.1109/ACCESS.2020.3008473
   Zulkarnain N., 2022, J Pharm Negat Results, V13, P659, DOI [10.47750/pnr.2022.13.04.088, DOI 10.47750/PNR.2022.13.04.088]
NR 39
TC 0
Z9 0
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-16998-z
EA OCT 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800021
DA 2024-07-18
ER

PT J
AU Saini, P
   Nagpal, B
AF Saini, Preeti
   Nagpal, Bharti
TI Analysis of missing data and comparing the accuracy of imputation
   methods using wheat crop data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Missing Data; Imputation; Multiple Regression; MissForest; MICE
ID MULTIPLE IMPUTATION; CHAINED EQUATIONS; VALUES; CLASSIFIER
AB In a realistic scenario, the dataset has missing values encountered during the data collection. To effectively build the prediction model, the missingness of the attributes that impact crop growth needs to be appropriately handled in the crop dataset. The study aims to impute missing data in the Wheat crop yield Dataset, consisting of climatic parameters and historical data of 370 districts of Major Wheat Producer states of India. This study plays a vital role in crop estimation or forecasting of production at regular intervals. The imputation techniques that replace missing data have been categorized into Statistical and Machine Learning based Methods. We explored the performance of popular Techniques such as Arithmetic Average Replacement, Median Imputation, Linear Interpolation, Average Imputation by Nearby Districts, K-Nearest Neighbour, Miss Forest, Regression, and MICE. We have also evaluated these methods on the UCI machine learning repository's Bias and Steel energy consumption datasets. These imputed results were fed to the multiple regression prediction models to evaluate the efficiency of the imputation approaches qualitatively. The results conclude that the Arithmetic Average Replacement method provides good results among the statistical methods (R2 = 0.83; RMSE = 0.47; MAE = 0.372; MSE = 0.229), whereas in Machine Learning based methods, Miss Forest Random Forest-based method, and MICE performed well (R2 = 0.80; MAE = 0.3825; MSE = 0.249; RMSE = 0.499) to impute the missing data. We hope our results help the researchers to select the appropriate pre-processing strategies and improve the data quality.
C1 [Saini, Preeti] Guru Gobind Singh Indraprastha Univ, AIACTR, USICT, NSUT, East Campus, Delhi, India.
   [Saini, Preeti] Delhi Skill & Entrepreneurship Univ, Dept Comp Engn, Guru Nanak Dev, Rohini Campus, Delhi, India.
   [Nagpal, Bharti] NSUT, Dept Comp Sci & Engn, AIACTR, East Campus, Delhi, India.
C3 Netaji Subhas University of Technology; Netaji Subhas University of
   Technology (East Campus); GGS Indraprastha University; Netaji Subhas
   University of Technology; Netaji Subhas University of Technology (East
   Campus)
RP Saini, P (corresponding author), Guru Gobind Singh Indraprastha Univ, AIACTR, USICT, NSUT, East Campus, Delhi, India.; Saini, P (corresponding author), Delhi Skill & Entrepreneurship Univ, Dept Comp Engn, Guru Nanak Dev, Rohini Campus, Delhi, India.
EM preeti.saini@dseu.ac.in
CR Acuña E, 2004, ST CLASS DAT ANAL, P639
   Adam M.B., 2021, AIP Conf. Proc, V2355, P040006, DOI DOI 10.1063/5.0053286
   Alexopoulos EC, 2010, HIPPOKRATIA, V14, P23
   Amirteimoori A, 2010, OPTIMIZATION, V59, P985, DOI 10.1080/02331930902878333
   [Anonymous], 2020, UCI Machine Learning Repository, DOI [10.24432/C59K76, DOI 10.24432/C59K76]
   aps.dac.gov.in, Crop production statistics by directorate of economics and statistics, ministry of agriculture, and farmers welfare
   Arciniegas-Alarcón S, 2016, CROP BREED APPL BIOT, V16, P77, DOI 10.1590/1984-70332016v16n2a13
   Azur MJ, 2011, INT J METH PSYCH RES, V20, P40, DOI 10.1002/mpr.329
   Badr W, 2023, Towards Data Science
   Bennett DA, 2001, AUST NZ J PUBL HEAL, V25, P464, DOI 10.1111/j.1467-842X.2001.tb00294.x
   Beretta L, 2016, BMC MED INFORM DECIS, V16, DOI 10.1186/s12911-016-0318-z
   Bici R, 2023, INT J COMPUT ECON EC, V13, P216, DOI 10.1504/IJCEE.2023.129986
   Biessmann F, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2017, DOI 10.1145/3269206.3272005
   Cao J, 2023, SPE J, V28, P1895
   Chen YC, 2020, Arxiv, DOI [arXiv:2004.00744, 10.48550/arXiv.2004.00744, DOI 10.48550/ARXIV.2004.00744]
   Chhabra G., 2019, J Dyn Control Syst, V11, P312, DOI 10.1088/1742-6596/892/1/012004
   Turrado CC, 2014, SENSORS-BASEL, V14, P20382, DOI 10.3390/s141120382
   Curley C, 2019, URBAN AFF REV, V55, P591, DOI 10.1177/1078087417726394
   Dantan E., 2008, INT J BIOSTAT, V4, DOI DOI 10.2202/1557-4679.1088
   de Silva H, 2016, INT CONF ADV ICT, P141, DOI 10.1109/ICTER.2016.7829911
   Demirtas H., 2018, J. Stat. Softw, V85, P1, DOI [10.18637/jss.v085.b04, DOI 10.18637/JSS.V085.B04]
   Donders ART, 2006, J CLIN EPIDEMIOL, V59, P1087, DOI 10.1016/j.jclinepi.2006.01.014
   Dumedah G, 2011, J HYDROL, V400, P95, DOI 10.1016/j.jhydrol.2011.01.028
   Emmanuel T, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00516-9
   Feng HH, 2005, LECT NOTES ARTIF INT, V3683, P581
   Fu YP, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11080727
   Gabr MI, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010055
   Gedikoglu H., 2012, Agricultural & Applied Economics Association's 2012 AAEA Annual Meeting, P12
   Gorard S, 2020, INT J SOC RES METHOD, V23, P651, DOI 10.1080/13645579.2020.1729974
   Graham J.W., 2012, Missing data: analysis and design pp, P47, DOI 10.1007/978-1-4614-4018-5_2
   He Y., 2016, IAENG Int J Comput Sci, V43, P1
   Hong SZ, 2020, BMC MED RES METHODOL, V20, DOI 10.1186/s12874-020-01080-1
   Hoque G., 2021, Data Sci
   Jadhav A, 2019, APPL ARTIF INTELL, V33, P913, DOI 10.1080/08839514.2019.1637138
   Jahan F, 2019, THEOR APPL CLIMATOL, V136, P1115, DOI 10.1007/s00704-018-2537-y
   Jiang C, 2015, LECT NOTES ARTIF INT, V9227, P441, DOI 10.1007/978-3-319-22053-6_47
   Jinubala V., 2016, Int j Sci Appl Inf Technol, V5, P1
   Kang H, 2013, KOREAN J ANESTHESIOL, V64, P402, DOI 10.4097/kjae.2013.64.5.402
   Khan SI, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00313-w
   Kwak SK, 2017, KOREAN J ANESTHESIOL, V70, P407, DOI 10.4097/kjae.2017.70.4.407
   Lin WC, 2020, ARTIF INTELL REV, V53, P1487, DOI 10.1007/s10462-019-09709-4
   Little R. J., 2019, Statistical Analysis with Missing Data, DOI DOI 10.1002/9781119482260
   Lokupitiya RS, 2006, ENVIRONMETRICS, V17, P339, DOI 10.1002/env.773
   Luo Y, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab489
   Maillo J, 2017, KNOWL-BASED SYST, V117, P3, DOI 10.1016/j.knosys.2016.06.012
   MALHOTRA NK, 1987, J MARKETING RES, V24, P74, DOI 10.2307/3151755
   Meggiorin M, 2023, WATER-SUI, V15, DOI 10.3390/w15040801
   Miao XY, 2023, IEEE T KNOWL DATA EN, V35, P6630, DOI 10.1109/TKDE.2022.3186498
   Nikfalazar S, 2020, KNOWL INF SYST, V62, P2419, DOI 10.1007/s10115-019-01427-1
   Pan S, 2023, INT J ENV RES PUB HE, V20, DOI 10.3390/ijerph20021524
   Pelckmans K, 2005, NEURAL NETWORKS, V18, P684, DOI 10.1016/j.neunet.2005.06.025
   Poulos J, 2018, APPL ARTIF INTELL, V32, P186, DOI 10.1080/08839514.2018.1448143
   power.larc.nasa.gov, Data Access Viewer
   Qinbao Song, 2007, International Journal of Business Intelligence and Data Mining, V2, P261, DOI 10.1504/IJBIDM.2007.015485
   RAYMOND MR, 1986, EVAL HEALTH PROF, V9, P395, DOI 10.1177/016327878600900401
   RUBIN DB, 1976, BIOMETRIKA, V63, P581, DOI 10.2307/2335739
   Sathishkumar VE., 2023, UCI Mach Learn Repos, DOI [10.24432/C52G8C, DOI 10.24432/C52G8C]
   Sattari MT, 2017, HYDROL RES, V48, P1032, DOI 10.2166/nh.2016.364
   Scharfstein Daniel O, 2012, J Bone Joint Surg Am, V94 Suppl 1, P80, DOI 10.2106/JBJS.L.00273
   Solfanelli Francesco, 2019, Organic Agriculture, V9, P295, DOI 10.1007/s13165-018-0228-8
   Stekhoven DJ, 2012, BIOINFORMATICS, V28, P112, DOI 10.1093/bioinformatics/btr597
   Sun B, 2017, CHIN AUTOM CONGR, P7346, DOI 10.1109/CAC.2017.8244105
   Tabachnick B.G., 2001, Using Multivariate Statistics
   Tang F, 2017, STAT ANAL DATA MIN, V10, P363, DOI 10.1002/sam.11348
   Tsikriktsis N, 2005, J OPER MANAG, V24, P53, DOI 10.1016/j.jom.2005.03.001
   van Buuren S, 2011, J STAT SOFTW, V45, P1
   Wafaa H, 2023, UHD J Sci Technol, V7, P72, DOI [10.21928/uhdjst.v7n1y2023.pp72-81, DOI 10.21928/UHDJST.V7N1Y2023.PP72-81]
   Warnes Z, 2021, Towards Data Science
   Ye A., 2020, Data Sci
   Yu LL, 2020, STAT METHODS MED RES, V29, P2647, DOI 10.1177/0962280220908613
   Zhang YF, 2022, FUTURE GENER COMP SY, V128, P63, DOI 10.1016/j.future.2021.09.033
   Zhang ZH, 2016, ANN TRANSL MED, V4, DOI 10.3978/j.issn.2305-5839.2015.12.63
   Zhang ZH, 2015, ANN TRANSL MED, V3, DOI 10.3978/j.issn.2305-5839.2015.12.11
NR 73
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 9
PY 2023
DI 10.1007/s11042-023-17178-9
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2OJ4
UT WOS:001083245400002
DA 2024-07-18
ER

PT J
AU Guo, X
   Yang, WQ
   Zhang, LK
   Shi, YF
   Li, J
   Sun, JD
   Wan, WB
AF Guo, Xin
   Yang, Wenqing
   Zhang, Likun
   Shi, Yufeng
   Li, Jing
   Sun, Jiande
   Wan, Wenbo
TI Deep image watermarking with loss-driven modification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Blind watermarking; Convolutional neural network; Residual network;
   Watermarking robustness
ID NEURAL-NETWORKS; DOMAIN; INDEX
AB Conventional watermarking algorithms are based on handcrafted features or their fusion. However, how to design and fuse these features efficiently for the performance of watermarking mainly depends on experience. In addition, the embedding is also restricted by a certain predefined function according to prior experiences. In order to improve the performance of watermarking by optimizing these two factors, a novel learning-based blind watermarking algorithm is proposed, motivated by the self-adjustment of deep learning. In the proposed method, the extraction of watermarks is modeled as block classification, which is implemented by a modified convolutional neural network (CNN). And the cross-entropy function is set as the loss function of this CNN to bridge the performance of watermarking, feature extraction, and embedding, which overcomes the problems brought about by the predefined modification criterion. Furthermore, in the modified CNN, a residual module is constructed with fewer batch normalizations, which can efficiently reduce the time of the watermarking process. Experimental results show that the proposed algorithm can achieve robustness against common signal processing attacks.
C1 [Guo, Xin; Shi, Yufeng] Shandong Univ, Inst Financial Studies, Jinan 250100, Peoples R China.
   [Guo, Xin; Shi, Yufeng] Shandong Big Data Res Assoc, Jinan 250100, Peoples R China.
   [Guo, Xin; Zhang, Likun] Shandong Haiyi Digital Technol Co Ltd, Jinan 250100, Peoples R China.
   [Yang, Wenqing] Univ Aberdeen, Business Sch, Aberdeen AB24 3FX, Scotland.
   [Shi, Yufeng] Shandong Univ, Sch Math, Jinan 250100, Peoples R China.
   [Li, Jing] Shandong Normal Univ, Sch Journalism & Commun, Jinan 250358, Peoples R China.
   [Sun, Jiande; Wan, Wenbo] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250358, Peoples R China.
C3 Shandong University; University of Aberdeen; Shandong University;
   Shandong Normal University; Shandong Normal University
RP Shi, YF (corresponding author), Shandong Univ, Inst Financial Studies, Jinan 250100, Peoples R China.; Shi, YF (corresponding author), Shandong Big Data Res Assoc, Jinan 250100, Peoples R China.; Shi, YF (corresponding author), Shandong Univ, Sch Math, Jinan 250100, Peoples R China.; Wan, WB (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250358, Peoples R China.
EM yfshi@sdu.edu.cn; wanwenbo@sdnu.edu.cn
RI Zhang, Likun/A-2742-2011; Yang, Wenqing/F-7026-2011; Zhang,
   Yuchen/GYI-8858-2022
FU This work is partially supported by the Natural Science Foundation of
   China (61601268), Joint Project for Smart Computing of Shandong Natural
   Science Foundation (ZR2020LZH015) and Joint Project for Development
   Innovation of Shandong Natural Science Foundat [61601268]; Natural
   Science Foundation of China [ZR2020LZH015]; Joint Project for Smart
   Computing of Shandong Natural Science Foundation [ZR2022LZH012]; Joint
   Project for Development Innovation of Shandong Natural Science
   Foundation
FX This work is partially supported by the Natural Science Foundation of
   China (61601268), Joint Project for Smart Computing of Shandong Natural
   Science Foundation (ZR2020LZH015) and Joint Project for Development
   Innovation of Shandong Natural Science Foundation (ZR2022LZH012).
CR Ahmadi M, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2019.113157
   Bamatraf A., 2010, 2010 International Conference on Computer Applications and Industrial Electronics (ICCAIE), P155, DOI 10.1109/ICCAIE.2010.5735066
   Banerjee Shubhendu, 2015, International Journal of Image, Graphics and Signal Processing, V7, P1, DOI 10.5815/ijigsp.2015.03.01
   Borra S., 2018, DIGITAL IMAGE WATERM, DOI DOI 10.1201/9780429423291
   Borra S, 2017, FRONT ARTIF INTEL AP, V296, P450, DOI 10.3233/978-1-61499-785-6-450
   Dehkordi AminBanitalebi, 2011, 2011 19 IR C EL ENG, P1
   Dey N, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN TECHNOLOGY AND ENGINEERING (ICATE)
   Gu K, 2017, IEEE T IMAGE PROCESS, V26, P4005, DOI 10.1109/TIP.2017.2711279
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jun Z, 2002, PROC INT C TOOLS ART, P477, DOI 10.1109/TAI.2002.1180841
   Kandi H, 2017, COMPUT SECUR, V65, P247, DOI 10.1016/j.cose.2016.11.016
   Lee GJ, 2008, INTERNATIONAL SYMPOSIUM ON UBIQUITOUS MULTIMEDIA COMPUTING, PROCEEDINGS, P130, DOI 10.1109/UMC.2008.33
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Li Qiao., 2007, Improve spread transform dither modulation by using a perceptual model to provide resistance to amplitude scaling and jpeg compression
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Y, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1509, DOI 10.1145/3343031.3351025
   Mahto DK, 2021, COMPUT ELECTR ENG, V93, DOI 10.1016/j.compeleceng.2021.107255
   Mun SM, 2017, Arxiv, DOI arXiv:1704.03248
   Mun SM, 2019, NEUROCOMPUTING, V337, P191, DOI 10.1016/j.neucom.2019.01.067
   Nafchi HZ, 2016, IEEE ACCESS, V4, P5579, DOI 10.1109/ACCESS.2016.2604042
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Nilanjan Dey VSanthi, 2017, Intelligent techniques in signal processing for multimedia security
   Ouyang JL, 2015, COMPUT ELECTR ENG, V46, P419, DOI 10.1016/j.compeleceng.2015.03.004
   Piva A, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P520, DOI 10.1109/ICIP.1997.647964
   Pradhan Chittaranjan, 2018, Handbook of research on information security in biomedical signal processing
   Sujatha C. N., 2019, Information and Communication Technology for Intelligent Systems. Proceedings of ICTIS 2018. Smart Innovation, Systems and Technologies (SIST 106), P621, DOI 10.1007/978-981-13-1742-2_62
   Szankin M., 2022, Int J Netw Dyn Intell, V1, P48
   Thanki R, 2018, L N COMPUT VIS BIOME, V26, P3, DOI 10.1007/978-3-319-65981-7_1
   University of granada computer vision group, 2017, cvgugr image database
   VANSCHYNDELL RG, 1994, IEEE IMAGE PROC, P86, DOI 10.1109/ICIP.1994.413536
   Wan W., 2022, NEUROCOMPUTING
   Wan WB, 2020, MULTIMED TOOLS APPL, V79, P4907, DOI 10.1007/s11042-018-6860-1
   Wan WB, 2019, IEEE ACCESS, V7, P39826, DOI 10.1109/ACCESS.2019.2906912
   Wan WB, 2020, PATTERN RECOGN LETT, V130, P157, DOI 10.1016/j.patrec.2018.08.009
   Wan WB, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.2.023002
   Wang J, 2020, MULTIMED TOOLS APPL, V79, P24057, DOI 10.1007/s11042-020-09102-2
   Wang J, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112868
   Wolfgang RB, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P219, DOI 10.1109/ICIP.1996.560423
   Yadav B., 2018, Adv. Intell. Syst. Comput, V583, P25
   Yu N., 2022, Int. J. Netw. Dyn. Intell, V1, P73, DOI [DOI 10.53941/IJNDI0101007, 10.53941/ijndi0101007]
   Yu PT, 2001, SIGNAL PROCESS, V81, P663, DOI 10.1016/S0165-1684(00)00239-5
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang Yanhong., 2009, Wseas Trans Comput, V8, P174
   Zheng WB, 2018, C IND ELECT APPL, P1233, DOI 10.1109/ICIEA.2018.8397898
   Zhu JR, 2018, LECT NOTES COMPUT SC, V11219, P682, DOI 10.1007/978-3-030-01267-0_40
NR 51
TC 0
Z9 0
U1 5
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 2
PY 2023
DI 10.1007/s11042-023-16809-5
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S7YP2
UT WOS:001073290700001
DA 2024-07-18
ER

PT J
AU Kumar, RN
AF Kumar, R. Naveen
TI An efficient image compression using modified embedded zero tree coding
   with SVD
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image compression; singular value decomposition (SVD); modified embedded
   zero-tree wavelet (MEZTW)
ID SINGULAR-VALUE DECOMPOSITION; WAVELET DOMAIN
AB The fast-growing web technology is more focused on developing optimized image compression tools to increase the efficiency of search engines and data validation. The wavelet-based progressive image compression is a more popular compression technique used in standard JPEG 2000 codec design for multimedia image applications. The embedded zero tree wavelet coding (EZTW) is one of the lossy wavelet-based image compression which produces a high compression rate by neglecting redundant coefficients during encoding. However, singular value decomposition (SVD) is a lossless image compression, where high energy compaction and adaptability for local variance made its reconstruction quality high with a shortcoming compression ratio. In this proposed hybrid technique, the mean extracted image is segmented into blocks were subjected to SVD and modified EZTW compression. In addition, adaptive thresholding and rank selections by using an optimizer algorithm help in scoring high compression rates and effective edge reconstruction. The comparative study of the proposed technique with the art of work shows an enhancement in PSNR scores, significantly obtained at 24.64 dB even at high compression rates (90:1) for boat images.
C1 [Kumar, R. Naveen] M S Ramaiah Coll Arts Sci & Commerce, Dept Elect, Bengaluru 560054, Karnataka, India.
RP Kumar, RN (corresponding author), M S Ramaiah Coll Arts Sci & Commerce, Dept Elect, Bengaluru 560054, Karnataka, India.
EM nkr.hsd@gmail.com
CR Ahmadi K, 2015, SIGNAL PROCESS-IMAGE, V32, P33, DOI 10.1016/j.image.2015.01.001
   ANDREWS HC, 1976, IEEE T ACOUST SPEECH, V24, P26, DOI 10.1109/TASSP.1976.1162766
   Baker CG, 2012, LINEAR ALGEBRA APPL, V436, P2866, DOI 10.1016/j.laa.2011.07.018
   Bhardwaj D, 2018, SIGNAL PROCESS-IMAGE, V68, P155, DOI 10.1016/j.image.2018.07.011
   Boujelbene R, 2019, IET IMAGE PROCESS, V13, P1364, DOI 10.1049/iet-ipr.2018.6052
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chen J., 2000, ECS 29K, Scientific computation
   Dua Y, 2021, J PARALLEL DISTR COM, V150, P60, DOI 10.1016/j.jpdc.2020.12.004
   Guangjun Tian, 2015, Applied Mechanics and Materials, V740, P639, DOI 10.4028/www.scientific.net/AMM.740.639
   Gupta P, 2022, INDIAN PEDIATR, V59, P235, DOI 10.1007/s13312-022-2477-6
   Hou ZJ, 2003, PATTERN RECOGN, V36, P1747, DOI 10.1016/S0031-3203(02)00323-0
   internetworldstats, 2022, Internet usage statistics-The Internet Big Picture2023
   Kiwon Y, 2011, IEEE INT C MULTIMED, P1
   Kumar M, 2016, An efficient compression of encrypted images using WDR coding, P729
   Kumar R, 2016, COMPUT METH PROG BIO, V129, P135, DOI 10.1016/j.cmpb.2016.01.006
   Li DQ, 2019, IEEE ACCESS, V7, P18915, DOI 10.1109/ACCESS.2019.2896653
   Liu XX, 2022, MULTIMED TOOLS APPL, V81, P4781, DOI 10.1007/s11042-021-11017-5
   Mishra D, 2022, SIGNAL PROCESS, V191, DOI 10.1016/j.sigpro.2021.108346
   Rasti P., 2015, Resolution Enhancement Based Image Compression Technique using Singular Value Decomposition and Wavelet Transforms, P36
   Rufai AM, 2014, DIGIT SIGNAL PROCESS, V24, P117, DOI 10.1016/j.dsp.2013.09.008
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Sengupta A, 2018, IEEE CONSUM ELECTR M, V7, P119, DOI 10.1109/MCE.2017.2743239
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Walker J.S., 2001, INT C IM PROC IEEE P, P22
   Wang Y, 2022, COMPUT APPL MATH, V41, DOI 10.1007/s40314-022-02107-7
   Wen JM, 2017, IEEE T SIGNAL PROCES, V65, P5347, DOI 10.1109/TSP.2017.2728502
   Wu SH, 2017, MOB INF SYST, V2017, DOI 10.1155/2017/2314062
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
NR 29
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 2
PY 2023
DI 10.1007/s11042-023-16725-8
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U1KJ9
UT WOS:001082459100013
DA 2024-07-18
ER

PT J
AU Tang, JJ
   Luo, QF
   Zhou, YQ
AF Tang, Jiaju
   Luo, Qifang
   Zhou, Yongquan
TI Discrete artificial ecosystem-based optimization for spherical
   capacitated vehicle routing problem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Capacitated vehicle routing problem; artificial ecosystem-based
   optimization; Local search operators; 2-opt algorithm; Spherical CVRP
ID ANT COLONY OPTIMIZATION; SWARM OPTIMIZATION; SEARCH ALGORITHM; HYBRID;
   POWER
AB The capacity constrained vehicle routing problem (CVRP) is one of the most well-known combinatorial optimization problems. Many studies have proposed various methods to solve the two-dimensional CVRP problem. In this paper, we firstly extend the CVRP problem to a three-dimensional space, called SCVRP, where all customers are distributed on a sphere. Secondly, a discrete artificial ecosystem-based optimization algorithm (DAEO) is proposed to solve the SCVRP problem. DAEO uses five local search operators to discretize the position update formula of the original AEO algorithm and introduces the 2-opt algorithm to simulate the mutation mechanism of organisms in the ecosystem. Furthermore, to evaluate the performance of the proposed algorithm, 32 test instances are designed, having 25-400 customers. These instances take into account factors such as customer position and demand distribution to be closer to the actual situation. The experimental results show that the proposed algorithm has good feasibility and competitiveness in solving the SCVRP problem, and can obtain better solutions than other intelligent algorithms.
C1 [Luo, Qifang; Zhou, Yongquan] Guangxi Univ Nationalities, Coll Artificial Intelligence, Nanning 530006, Peoples R China.
   [Luo, Qifang; Zhou, Yongquan] Guangxi Univ Nationalities, Xiangsihu Coll, Nanning 530225, Peoples R China.
   [Zhou, Yongquan] Guangxi Key Labs Hybrid Computat & IC Design Anal, Nanning 530006, Peoples R China.
C3 Guangxi Minzu University; Guangxi Minzu University
RP Luo, QF (corresponding author), Guangxi Univ Nationalities, Coll Artificial Intelligence, Nanning 530006, Peoples R China.; Luo, QF (corresponding author), Guangxi Univ Nationalities, Xiangsihu Coll, Nanning 530225, Peoples R China.
EM l.qf@163.com
RI Zhou, Yongquan/AAI-3982-2021
OI Zhou, Yongquan/0000-0001-6945-4922; zhou, yongquan/0000-0003-4404-952X
FU This work is supported by the National Natural Science Foundation of
   China under Grant No. 62066005, U21A20464. [62066005, U21A20464];
   National Natural Science Foundation of China
FX This work is supported by the National Natural Science Foundation of
   China under Grant No. 62066005, U21A20464.
CR Altabeeb AM, 2021, APPL SOFT COMPUT, V108, DOI 10.1016/j.asoc.2021.107403
   Altabeeb AM, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105728
   [Anonymous], 2004, Electronic Notes in Discrete Mathematics, DOI DOI 10.1016/J.ENDM.2004.06.029
   Augerat P, 1998, EUR J OPER RES, V106, P546, DOI 10.1016/S0377-2217(97)00290-7
   Azi N, 2007, EUR J OPER RES, V178, P755, DOI 10.1016/j.ejor.2006.02.019
   Barnhart C, 1998, OPER RES, V46, P316, DOI 10.1287/opre.46.3.316
   Barshandeh S, 2022, ENG COMPUT-GERMANY, V38, P1581, DOI 10.1007/s00366-020-01120-w
   Bi J, 2022, INT J COMPUT INT SYS, V15, DOI 10.1007/s44196-021-00059-0
   Bi J, 2022, APPL INTELL, V52, P195, DOI 10.1007/s10489-021-02415-1
   Braekers K, 2016, COMPUT IND ENG, V99, P300, DOI 10.1016/j.cie.2015.12.007
   Calasan M, 2020, INT J ELEC ENG EDUC, DOI 10.1177/0020720920940605
   Chen Ai-ling, 2006, Journal of Zhejiang University (Science), V7, P607, DOI 10.1631/jzus.2006.A0607
   Chen X, 2017, APPL SOFT COMPUT, V58, P104, DOI 10.1016/j.asoc.2017.04.057
   CROES GA, 1958, OPER RES, V6, P791, DOI 10.1287/opre.6.6.791
   Daneshzand F, 2011, ELSEV INSIGHT, P127, DOI 10.1016/B978-0-12-385202-1.00008-6
   DANTZIG GB, 1959, MANAGE SCI, V6, P80, DOI 10.1287/mnsc.6.1.80
   Essa FA, 2020, PROCESS SAF ENVIRON, V144, P322, DOI 10.1016/j.psep.2020.07.044
   García S, 2009, J HEURISTICS, V15, P617, DOI 10.1007/s10732-008-9080-4
   Giannakos Michail N., 2016, Smart Learning Environments, V3, DOI 10.1186/s40561-016-0036-0
   Goel R, 2018, J COMPUT SCI-NETH, V25, P28, DOI 10.1016/j.jocs.2017.12.012
   Gülcü S, 2018, SOFT COMPUT, V22, P1669, DOI 10.1007/s00500-016-2432-3
   Ilhan I, 2021, SWARM EVOL COMPUT, V64, DOI 10.1016/j.swevo.2021.100911
   Izci D, 2022, ALEX ENG J, V61, P2030, DOI 10.1016/j.aej.2021.07.037
   Jin JY, 2014, COMPUT OPER RES, V44, P33, DOI 10.1016/j.cor.2013.10.004
   LAWLER EL, 1966, OPER RES, V14, P699, DOI 10.1287/opre.14.4.699
   Li J, 2019, APPL SOFT COMPUT, V81, DOI 10.1016/j.asoc.2019.04.030
   Lin SW, 2006, IEEE SYS MAN CYBERN, P639, DOI 10.1109/ICSMC.2006.384457
   Lin SW, 2009, EXPERT SYST APPL, V36, P1505, DOI 10.1016/j.eswa.2007.11.060
   Mahi M, 2015, APPL SOFT COMPUT, V30, P484, DOI 10.1016/j.asoc.2015.01.068
   Manfrin M, 2004, Diplome d'Etudes Approfondies en Sciences Appliquees
   Mouassa S, 2021, NEURAL COMPUT APPL, V33, P7467, DOI 10.1007/s00521-020-05496-0
   Niu YB, 2022, J SUPERCOMPUT, V78, P13040, DOI 10.1007/s11227-022-04367-w
   Niu YY, 2015, SOFT COMPUT, V19, P471, DOI 10.1007/s00500-014-1266-0
   Ouyang XX, 2013, APPL MATH INFORM SCI, V7, P777, DOI 10.12785/amis/070248
   Panwar K, 2021, APPL SOFT COMPUT, V105, DOI 10.1016/j.asoc.2021.107298
   Queiroga E, 2021, COMPUT OPER RES, V136, DOI 10.1016/j.cor.2021.105475
   Rizk-Allah RM, 2021, INT J HYDROGEN ENERG, V46, P37612, DOI 10.1016/j.ijhydene.2020.06.256
   Sbai I, 2022, OPER RES-GER, V22, P507, DOI 10.1007/s12351-019-00543-8
   Sevkli AZ, 2017, APPL SOFT COMPUT, V58, P128, DOI 10.1016/j.asoc.2017.04.045
   Szeto WY, 2011, EUR J OPER RES, V215, P126, DOI 10.1016/j.ejor.2011.06.006
   Takahashi S, 2002, ICONIP'02: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON NEURAL INFORMATION PROCESSING, P2552
   Tang CM, 2022, ENG COMPUT-GERMANY, V38, P1481, DOI 10.1007/s00366-021-01286-x
   Tao Y, 2015, COMPUT OPER RES, V55, P127, DOI 10.1016/j.cor.2013.10.017
   Uchoa E, 2017, EUR J OPER RES, V257, P845, DOI 10.1016/j.ejor.2016.08.012
   Ugur A, 2009, MATH COMPUT APPL, V14, P219
   Yang XS, 2020, J COMPUT SCI-NETH, V46, DOI 10.1016/j.jocs.2020.101104
   Yousri D, 2020, ENERG CONVERS MANAGE, V225, DOI 10.1016/j.enconman.2020.113385
   Yu VF, 2017, APPL SOFT COMPUT, V52, P657, DOI 10.1016/j.asoc.2016.10.006
   Zhao WG, 2020, NEURAL COMPUT APPL, V32, P9383, DOI 10.1007/s00521-019-04452-x
   Zhou YQ, 2019, NEURAL COMPUT APPL, V31, P2155, DOI 10.1007/s00521-017-3176-4
   ZIMMERMAN DW, 1993, J EXP EDUC, V62, P75, DOI 10.1080/00220973.1993.9943832
NR 51
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 30
PY 2023
DI 10.1007/s11042-023-16919-0
EA SEP 2023
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T4DY8
UT WOS:001077522300001
DA 2024-07-18
ER

PT J
AU Zhou, YJ
   Ahmed, AN
AF Zhou, Yangjing
   Ahmed, Ahmed Najat
TI Cryptocurrency and digital currency based on blockchain-enabled IoT: a
   bibliometric literature review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Blockchain; Cryptocurrency; Digital currency; IoT; Bibliometrics;
   Wireless
ID INTERNET; TECHNOLOGY; ARCHITECTURE; INTEGRATION; CHALLENGES; MANAGEMENT;
   FRAMEWORK; BITCOIN; SMART
AB Blockchain, the mechanism that powers the Bitcoin cryptocurrency, is seen to be both enticing and essential for providing improved security and privacy for a variety of applications in many different fields, including the Internet of Things (IoT) ecosystem. Blockchain has therefore been viewed as a potential technology for IoT since it offers important answers for the digital currency that can handle issues with high maintenance costs, trust and security, and other issues. However, as far as we are aware, no thorough bibliometric analysis has been done in this area. Therefore, this paper has performed a bibliometric analysis of digital currency based on blockchain-enabled IoT between 2015 and 2022 by 1332 articles selected. The Web of Science (WoS), one of the most esteemed databases, served as the study's primary data source. Besides, a network of country collaboration and a network of co-occurrences for co-word analysis was created using the VOSviewer tool. The results showed that the number of cryptocurrencies and cryptocurrency publications on the blockchain had been enhanced quickly since 2018. Computer science, engineering, telecommunications, commerce, economics, medicine, agriculture, and law were among the areas studied in the blockchain domain. Furthermore, China has surpassed the United States as the leading country in terms of total publications and financing for related-topic research. Regarding the total number of citations, 2016 is the most influential, and IEEE Access is the most significant and prolific journal in the number of citations and publications.
C1 [Zhou, Yangjing] Sichuan Vocat Coll Hlth & Rehabil, Sch Educ & Sports, Zigong 643000, Sichuan, Peoples R China.
   [Ahmed, Ahmed Najat] Lebanese French Univ, Coll Engn & Comp Sci, Dept Comp Engn, Erbil, Kurdistan Reg, Iraq.
RP Zhou, YJ (corresponding author), Sichuan Vocat Coll Hlth & Rehabil, Sch Educ & Sports, Zigong 643000, Sichuan, Peoples R China.
EM zyjx0149@svchr.edu.cn; A.afandy@lfu.edu.krd
CR Abdelmaboud A, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11040630
   Alam S, 2023, LIBR HI TECH, V41, P287, DOI 10.1108/LHT-07-2021-0244
   Almasoud AS, 2020, J NETW COMPUT APPL, V170, DOI 10.1016/j.jnca.2020.102814
   Altan A, 2019, CHAOS SOLITON FRACT, V126, P325, DOI 10.1016/j.chaos.2019.07.011
   Ande R, 2020, SUSTAIN CITIES SOC, V54, DOI 10.1016/j.scs.2019.101728
   Andoni M, 2019, RENEW SUST ENERG REV, V100, P143, DOI 10.1016/j.rser.2018.10.014
   Andrian HR, 2018, INT C INF TECH SYST, P370, DOI 10.1109/ICITSI.2018.8695939
   Arias-Oliva M, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00475
   Block JH, 2017, IND INNOV, V24, P61, DOI 10.1080/13662716.2016.1216397
   Boakye Elijah Asante, 2022, Journal of High Technology Management Research, DOI 10.1016/j.hitech.2022.100437
   Böhme R, 2015, J ECON PERSPECT, V29, P213, DOI 10.1257/jep.29.2.213
   Cao B, 2022, IEEE INTERNET THINGS, V9, P15030, DOI 10.1109/JIOT.2021.3104661
   Cao B, 2020, IEEE NETWORK, V34, P78, DOI 10.1109/MNET.011.1900536
   Cao KR, 2022, IEEE INTERNET THINGS, V9, P24669, DOI 10.1109/JIOT.2022.3193189
   Cheah ET, 2015, ECON LETT, V130, P32, DOI 10.1016/j.econlet.2015.02.029
   Chen JX, 2022, IEEE SYST J, V16, P4525, DOI 10.1109/JSYST.2021.3099103
   Chen P, 2022, COMPUT J, V65, P2909, DOI 10.1093/comjnl/bxac085
   Cheng B, 2017, IEEE ACM T NETWORK, V25, P2082, DOI 10.1109/TNET.2017.2705239
   Christidis K, 2016, IEEE ACCESS, V4, P2292, DOI 10.1109/ACCESS.2016.2566339
   Conoscenti M, 2016, I C COMP SYST APPLIC
   Corbet S, 2018, ECON LETT, V165, P28, DOI 10.1016/j.econlet.2018.01.004
   Dai XX, 2023, IEEE T IND INFORM, V19, P480, DOI 10.1109/TII.2022.3158974
   Darbandi M., 2017, Published by Journal of Computer Sciences and Applications, V5, P11, DOI DOI 10.12691/JCSA-5-1-2
   Darbandi M., 2017, HCTL International Journal of Technology Innovations and Research, V23, P10, DOI DOI 10.5281/ZENODO.345288
   Darbandi M., 2017, Published by HCTL, Int. J. Technol. Innov. Res, V24, P1, DOI DOI 10.5281/ZENODO.1034475
   de Haro Olmo F., 2020, Sensors, V20, p12/14
   DeVries Peter D., 2016, International Journal of Business Management and Commerce, V1, P1
   Elhayatmy G, 2018, STUD BIG DATA, V30, P3, DOI 10.1007/978-3-319-60435-0_1
   Feng X, 2024, LIBR HI TECH, V42, P284, DOI 10.1108/LHT-10-2022-0467
   Firdaus A, 2019, SCIENTOMETRICS, V120, P1289, DOI 10.1007/s11192-019-03170-4
   Gatteschi V, 2018, IT PROF, V20, P62, DOI 10.1109/MITP.2018.021921652
   Ghalwesh A., 2020, Int J Econ Financ Issues, V10, P166, DOI [10.32479/ijefi.9130, DOI 10.32479/IJEFI.9130]
   Ghosh A, 2020, J NETW COMPUT APPL, V163, DOI 10.1016/j.jnca.2020.102635
   Gourisetti SNG, 2020, IEEE T ENG MANAGE, V67, P1142, DOI 10.1109/TEM.2019.2928280
   Guo YM, 2021, FUTURE GENER COMP SY, V116, P316, DOI 10.1016/j.future.2020.10.023
   Han YH, 2023, ENG CONSTR ARCHIT MA, V30, P5160, DOI 10.1108/ECAM-07-2021-0668
   Hasan M, 2019, INTERNET THINGS-NETH, V7, DOI 10.1016/j.iot.2019.100059
   Herskind L., 2020, IEEE Access, VPP, P1
   ?iloglu T, 2019, INT J EBUS EGOV STUD, V11, P69, DOI DOI 10.34111/IJEBEG.20191115
   Jerbi W, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6794
   Jiang HB, 2022, IEEE T MOBILE COMPUT, V21, P31, DOI 10.1109/TMC.2020.3005908
   Kamran M, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106525
   Kandaswamy R., 2021, Blockchain-Based Transformation
   Kandi MA, 2022, COMPUT COMMUN, V191, P11, DOI 10.1016/j.comcom.2022.04.018
   Katsiampa P, 2017, ECON LETT, V158, P3, DOI 10.1016/j.econlet.2017.06.023
   Kshetri N, 2018, INT J INFORM MANAGE, V39, P80, DOI 10.1016/j.ijinfomgt.2017.12.005
   Kuzior A, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14138206
   Landström H, 2015, INT ENTREP MANAG J, V11, P493, DOI 10.1007/s11365-013-0282-3
   Li B, 2022, INFORM SCIENCES, V612, P384, DOI 10.1016/j.ins.2022.08.093
   Lipton A, 2018, ROY SOC OPEN SCI, V5, DOI 10.1098/rsos.180155
   Liu KQ, 2021, IEEE T COMMUN, V69, P6675, DOI 10.1109/TCOMM.2021.3094581
   Liu L, 2022, LAND-BASEL, V11, DOI 10.3390/land11040489
   Liu X, 2022, LAND USE POLICY, V123, DOI 10.1016/j.landusepol.2022.106430
   Liu Z., 2022, Ecofeminism Clim Change, V3, P81, DOI [10.26480/efcc.02.2022.81.84, DOI 10.26480/EFCC.02.2022.81.84]
   Lone AH, 2021, COMPUT SCI REV, V39, DOI 10.1016/j.cosrev.2020.100360
   Luo J, 2022, J SUPERCOMPUT, V78, P379, DOI 10.1007/s11227-021-03898-y
   Lv Z, 2021, IEEE NETWORK, V35, P44, DOI 10.1109/MNET.011.2000154
   Ma K, 2021, IEEE INTERNET THINGS, V8, P13343, DOI 10.1109/JIOT.2021.3065966
   Mahapatra SN, 2020, ARAB J SCI ENG, V45, P6211, DOI 10.1007/s13369-020-04461-2
   Manimuthu Arunmozhi, 2019, IEEE Engineering Management Review, V47, P28, DOI 10.1109/EMR.2019.2901431
   Mas'ud MZ, 2021, 2021 3RD INTERNATIONAL CYBER RESILIENCE CONFERENCE (CRC), P162, DOI 10.1109/CRC50527.2021.9392563
   Mercan S, 2022, IEEE CONSUM ELECTR M, V11, P97, DOI 10.1109/MCE.2021.3060720
   Miraz M.H., 2018, arXiv preprint arXiv:1801.03528, V2, P1
   Mirmohamadsadeghi S, 2021, RENEW SUST ENERG REV, V135, DOI 10.1016/j.rser.2020.110173
   Nakamoto S., 2008, DECENT BUS REV, V21260, DOI https://bitcoin.org/bitcoin.pdf
   Narayanan A, 2016, Bitcoin and cryptocurrency technologies: a comprehensive introduction, P1
   NARIN F, 1994, EVALUATION REV, V18, P65, DOI 10.1177/0193841X9401800107
   Oyelude Adetoun A., 2022, Library Hi Tech News, P1, DOI 10.1108/LHTN-04-2021-0018
   Pal S, 2022, J NETW COMPUT APPL, V203, DOI 10.1016/j.jnca.2022.103371
   Patil P, 2021, WIRELESS PERS COMMUN, V117, P1815, DOI 10.1007/s11277-020-07947-2
   Qiao GH, 2022, TOUR REV, V77, P713, DOI 10.1108/TR-12-2020-0619
   Qin XM, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11193022
   Qu ZG, 2023, INFORM SCIENCES, V637, DOI 10.1016/j.ins.2023.03.134
   Rahman A., 2019, Bus Manag, V18, P61
   Restuccia F, 2018, Present and Future, V1, P1, DOI [10.48550/arXiv.1903.07448, DOI 10.48550/ARXIV.1903.07448]
   Reyna A, 2018, FUTURE GENER COMP SY, V88, P173, DOI 10.1016/j.future.2018.05.046
   Rustem M, 2019, I C DEV ESYST ENG, P956, DOI 10.1109/DeSE.2019.00177
   Saida A., 2022, I J Edu Manag Eng, V2, P30, DOI [10.5815/ijeme.2022.02.04, DOI 10.5815/IJEME.2022.02.04]
   Sakho S, 2019, J INTELL FUZZY SYST, V37, P8029, DOI 10.3233/JIFS-190449
   Sas C, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6499, DOI 10.1145/3025453.3025886
   Savelyev A, 2018, COMPUT LAW SECUR REV, V34, P550, DOI 10.1016/j.clsr.2017.11.008
   Schneider S, 2020, IEEE T ENG MANAGE, V67, P1184, DOI 10.1109/TEM.2020.2972037
   Shammar EA, 2019, LIBR HI TECH, V38, P5, DOI 10.1108/LHT-12-2018-0200
   Sharma P., 2021, Wirel Pers Commun
   Singh S, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P463, DOI 10.1109/IC3I.2016.7918009
   Singh SK, 2021, Applications of Blockchain and Big IoT Systems, P3
   Soohoo S, 2020, Blockchain Solutions Will Continue to See Robust Investments, Led by Banking and Manufacturing, According to New IDC Spending Guide
   Torraco R. J., 2005, HUMAN RESOURCE DEV R, V4, P356, DOI [DOI 10.1177/1534484305278283, 10.1177/1534484305278283]
   Urquhart A, 2016, ECON LETT, V148, P80, DOI 10.1016/j.econlet.2016.09.019
   Vahdat S, 2022, KYBERNETES, V51, P2065, DOI 10.1108/K-04-2021-0333
   Vahdat S, 2020, INT J PREVENTIVE MED, V11, DOI 10.4103/ijpvm.IJPVM_54_19
   Vahdat Sahar, 2020, Proceedings of the Indian National Science Academy Part B Biological Sciences, V90, P911, DOI 10.1007/s40011-020-01172-4
   Valdeolmillos Diego, 2020, Blockchain and Applications. International Congress. Advances in Intelligent Systems and Computing (AISC 1010), P153, DOI 10.1007/978-3-030-23813-1_19
   van Eck NJ, 2010, J AM SOC INF SCI TEC, V61, P2405, DOI 10.1002/asi.21421
   van Eck NJ, 2010, SCIENTOMETRICS, V84, P523, DOI 10.1007/s11192-009-0146-3
   Wan Y, 2020, J COASTAL RES, P730, DOI 10.2112/SI103-150.1
   Wang S, 2018, IEEE T COMPUT SOC SY, V5, P942, DOI 10.1109/TCSS.2018.2865526
   Whitmore A, 2015, INFORM SYST FRONT, V17, P261, DOI 10.1007/s10796-014-9489-2
   Xia Q, 2017, IEEE ACCESS, V5, P14757, DOI 10.1109/ACCESS.2017.2730843
   Xiong ZH, 2020, IEEE NETWORK, V34, P166, DOI 10.1109/MNET.001.1900095
   Xuan Han, 2019, 2019 IEEE International Conference on Service Operations and Logistics, and Informatics (SOLI). Proceedings, P263, DOI 10.1109/SOLI48380.2019.8955032
   Yan L, 2021, IEEE ACCESS, V9, P123764, DOI 10.1109/ACCESS.2021.3108178
   Yaqoob I, 2017, IEEE WIREL COMMUN, V24, P10, DOI 10.1109/MWC.2017.1600421
   Ye C, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4177
   Yi HB, 2022, IEEE T NETW SCI ENG, V9, P950, DOI 10.1109/TNSE.2021.3095192
   Zhang GD, 2022, SUSTAIN CITIES SOC, V82, DOI 10.1016/j.scs.2022.103914
   Zhang H, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P310, DOI [10.1109/ITNEC48623.2020.9084997, 10.1109/itnec48623.2020.9084997]
   Zhang JL, 2023, IEEE T INF FOREN SEC, V18, P1667, DOI 10.1109/TIFS.2023.3246766
   Zhao S, 2021, IEEE T INF FOREN SEC, V16, P521, DOI 10.1109/TIFS.2020.3014487
   Zheng WF, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12084059
   Zheng WF, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12073416
   Zheng WF, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11031316
   Zheng XR, 2022, ENTERP INF SYST-UK, V16, DOI 10.1080/17517575.2021.1939895
   Zhou FL, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su142315918
NR 114
TC 0
Z9 0
U1 11
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
DI 10.1007/s11042-023-16726-7
EA SEP 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3XY3
UT WOS:001077361600008
DA 2024-07-18
ER

PT J
AU Caserman, P
   Baumgartner, KA
   Göbel, S
   Korn, O
AF Caserman, Polona
   Baumgartner, Kim Annabell
   Goebel, Stefan
   Korn, Oliver
TI A best practice for gamification in large companies: An extensive study
   focusing inter-generational acceptance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Gamification; Acceptance; Generations; Large-scale Evaluation
ID BUSINESS
AB Gamification is increasingly successful in the field of education and health. However, beyond call-centers and applications in human resources, its utilization within companies remains limited. In this paper, we examine the acceptance of gamification in a large company (with over 17,000 employees) across three generations, namely X, Y, and Z. Furthermore, we investigate which gamification elements are suited for business contexts, such as the dissemination of company principles and facts, or the organization of work tasks. To this end, we conducted focus group discussions, developed the prototype of a gamified company app, and performed a large-scale evaluation with 367 company employees. The results reveal statistically significant intergenerational disparities in the acceptance of gamification: younger employees, especially those belonging to Generation Z, enjoy gamification more than older employees and are most likely to engage with a gamified app in the workplace. The results further show a nuanced range of preferences regarding gamification elements: avatars are popular among all generations, badges are predominantly appreciated by Generations Z and Y, while leaderboards are solely liked by Generation Z. Drawing upon these insights, we provide recommendations for future gamification projects within business contexts. We hope that the results of our study regarding the preferences of the gamification elements and understanding generational differences in acceptance and usage of gamification will help to create more engaging and effective apps, especially within the corporate landscape.
C1 [Caserman, Polona; Goebel, Stefan] Tech Univ Darmstadt, Serious Games Res Grp, D-64283 Darmstadt, Germany.
   [Baumgartner, Kim Annabell] Durr Grp, D-74321 Bietigheim Bissingen, Germany.
   [Korn, Oliver] Offenburg Univ, D-77652 Offenburg, Germany.
C3 Technical University of Darmstadt; Hochschule Offenburg
RP Caserman, P (corresponding author), Tech Univ Darmstadt, Serious Games Res Grp, D-64283 Darmstadt, Germany.
EM polona.caserman@tu-darmstadt.de; kim.baumgartner@gmx.net;
   stefan_peter.goebel@tu-darmstadt.de; oliver.korn@hs-offenburg.de
RI Korn, Oliver/G-1798-2017
OI Korn, Oliver/0000-0002-2482-6945; Caserman, Polona/0000-0002-3252-4533
FU Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL.
CR 25 Gamification Statistics, 2023, Zippia.com
   Bartle R., 1996, J MUD Res, V1, P19, DOI DOI 10.1007/S00256-004-0875-6
   Birk MV, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2982, DOI 10.1145/2858036.2858062
   Cairns P, 2021, GAMES CULT, V16, P262, DOI 10.1177/1555412019893877
   Caserman P, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/19037
   Castellani S, 2013, CHI 13 P ACM SIGCHI
   Chou Y, 2022, The 10 best examples of using Gamification in an enterprise workplace
   Chou Y., 2019, Actionable gamification: Beyond points, badges, and leaderboards
   Cohen J., 1988, Statistical power analyses for behavioral sciences, V2nd, DOI [10.4324/9780203771587, DOI 10.4324/9780203771587]
   Deterding S., 2011, P 15 INT AC MINDTREK, P9, DOI [DOI 10.1145/2181037.2181040, 10.1145/2181037.2181040]
   Dorner R., 2016, Serious Games: Foundations, Concepts and Practice, DOI [10.1007/978-3-319-40612-1, DOI 10.1007/978-3-319-40612-1]
   Ducheneaut N, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1151
   Finley Klint., 2012, WIRED
   Funk M, 2015, 8TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2015), DOI 10.1145/2769493.2769496
   Funk M, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P185, DOI 10.1145/2700648.2809853
   game, Rund 8,2 Mio. Menschen in Deutschland zahlen sich zu Menschen mit Behinderung
   Grund Jonas, 2020, MuC'20: Proceedings of the Conference on Mensch und Computer, P491, DOI 10.1145/3404983.3410420
   Hamari J, 2014, P ANN HICSS, P3025, DOI 10.1109/HICSS.2014.377
   Harteveld C, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES (FDG'19), DOI 10.1145/3337722.3337731
   Heimburger L, 2020, ADV INTELL SYST COMP, V970, P3, DOI 10.1007/978-3-030-20145-6_1
   Huotari K., 2012, 16 MINDTREK, DOI 10.1145/2393132.2393137
   Jia Y, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2001, DOI 10.1145/2858036.2858515
   Kalafatoglu Y, 2020, EURAS STUD BUS ECON, V14, P53, DOI 10.1007/978-3-030-52294-0_4
   Korn O., 2012, Proceedings of the 4th ACM SIGCHI Symposium on Engineering Interactive Computing Systems (EICS '12), P313, DOI DOI 10.1145/2305484.2305539
   Korn O., 2014, P 7 INT C PERVASIVE, P1, DOI DOI 10.1145/2674396.2674406
   Korn O., 2017, Adv. Affect Pleasurable Des, P433, DOI [10.1007/978331941661842, DOI 10.1007/978331941661842]
   Korn O, 2017, P 2017 ACM WORKSH IN, P31, DOI [10.1145/3038535.3038538, DOI 10.1145/3038535.3038538]
   Korn O., 2016, P 2016 CHI C EXTENDE, P3114, DOI [https://doi.org/10.1145/2851581.2892283, DOI 10.1145/2851581.2892283]
   Korn O, 2018, ADV INTELL SYST, V601, P37, DOI 10.1007/978-3-319-60486-2_4
   Korn O, 2015, 8TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2015), DOI 10.1145/2769493.2769549
   Korn O, 2015, PROCEDIA MANUF, V3, P3424, DOI 10.1016/j.promfg.2015.07.616
   Koudal P., 2007, Managing the Talent Crisis in Global Manufacturing [internet]. Available from
   Kristof-Brown A.L., 2011, APA HDB IND ORG PSYC, V3, P3, DOI [10.1037/12171-001, DOI 10.1037/12171-001]
   Lee J., 2016, Advances in Ergonomics of Manufacturing: Managing the Enterprise of the Future, P305
   Lessel P, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2026, DOI 10.1145/2858036.2858463
   Marczewski A., 2015, Even Ninja Monkeys Like to Play: Gamification, Game Thinking and Motivational Design, V1st, P65
   Mayring P., 2000, ADVNCS MTHMTCS EDUC, V1, P20, DOI [10.17169/fqs-1.2.1089, DOI 10.1007/978-94-017-9181-613]
   Mazarakis Athanasios, 2021, i-com: Journal of Interactive Media, V20, P279, DOI 10.1515/icom-2021-0025
   Mazarakis A, 2023, INT J HUM-COMPUT INT, V39, P612, DOI 10.1080/10447318.2022.2041909
   McGonical Jane., 2011, REALITY IS BROKEN WH
   Mora A, 2015, 2015 IEEE 7TH INTERNATIONAL CONFERENCE ON GAMES AND VIRTUAL WORLDS FOR SERIOUS APPLICATIONS (VS-GAMES), P100
   Mozolevska V, 2022, Kevuru Games
   Seaborn K, 2015, INT J HUM-COMPUT ST, V74, P14, DOI 10.1016/j.ijhcs.2014.09.006
   Statista, Value of the Gamification Market Worldwide in 2016 and 2021
   Statista, Most Common Gamification Elements in Business in the United States as of 2019
   Thom J., 2012, Incentives, P1067, DOI DOI 10.1145/2145204.2145362
   Tondello GF, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P229, DOI 10.1145/2967934.2968082
   Tracey R, 2015, E-Learning Provocateur
   Wang I, 2020, PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (ACM IVA 2020), DOI 10.1145/3383652.3423887
   Werrlich S, 2018, SMARTOBJECTS 6 WORKS, P58
   Zichermann G., 2011, GAMIFICATION DESIGN
   Zuckerman O, 2014, PERS UBIQUIT COMPUT, V18, P1705, DOI 10.1007/s00779-014-0783-2
NR 52
TC 0
Z9 0
U1 6
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 28
PY 2023
DI 10.1007/s11042-023-16877-7
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM7
UT WOS:001076639200010
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Naderi, MR
   Givkashi, MH
   Karimi, N
   Shirani, S
   Samavi, S
AF Naderi, Mohammad Reza
   Givkashi, Mohammad Hossein
   Karimi, Nader
   Shirani, Shahram
   Samavi, Shadrokh
TI Aesthetic-aware image retargeting based on foreground-background
   separation and PSO optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Aesthetic quality assessment; Image retargeting; Particle swarm
   optimization
AB Image retargeting aims at altering images' size while preserving important content and minimizing noticeable distortions. The versatility of image retargeting is further highlighted, as it finds applications in various domains such as web design, mobile devices, and multimedia content adaptation. Previous image retargeting methods have employed various techniques such as seam carving, content-aware scaling, and energy-based approaches. However, these methods often produce outputs that suffer from noticeable artifacts, such as jagged edges or image distortions, which can degrade the overall visual quality. Additionally, a common characteristic of previous works is their attempt to retarget the background and foreground of the input image concurrently. While this approach aims to preserve the entire scene, it often leads to changes in the aspect ratios of individual objects within the image. As a result, the resized image may exhibit distorted proportions, affecting the content's overall visual coherence and perception. The change in the aspect ratio is specifically not desirable for human objects. We propose a retargeting method that overcomes these problems. The proposed approach consists of the following steps. Firstly, an inpainting method uses the input image and the binary mask of foreground objects to produce a background image without any foreground objects. Secondly, the seam carving method resizes the background image to the target size. Then, a super-resolution method increases the input image quality, and we then extract the foreground objects. Finally, the retargeted background and the extracted super-resolution objects are fed into a particle swarm optimization algorithm (PSO). The PSO algorithm uses aesthetic quality assessment as its objective function to identify the best location and size for the objects to be placed in the background. We have demonstrated commendable performance compared to prevalent image retargeting methodologies by utilizing image quality assessment (QA) and aesthetic quality assessment (AQA) metrics. We conducted a comparative analysis of our proposed method in relation to other approaches, utilizing various QA and AQA methods. The proposed method has achieved improvement percentages of 16.92%, 7.28%, 20.75%, and 4.7% respectively using the Pool-3FC, NRIQA, MANIQA, and HeperIQA methods.
C1 [Naderi, Mohammad Reza; Givkashi, Mohammad Hossein; Karimi, Nader; Samavi, Shadrokh] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
   [Shirani, Shahram; Samavi, Shadrokh] McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON, Canada.
C3 Isfahan University of Technology; McMaster University
RP Samavi, S (corresponding author), Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.; Samavi, S (corresponding author), McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON, Canada.
EM samavi@mcmaster.ca
RI Karimi, Nader/HWP-4206-2023; Givkashi, MohammadHossein/KDO-5431-2024;
   Samavi, Shadrokh/KPY-5766-2024
OI Karimi, Nader/0000-0001-8904-1607; Givkashi,
   MohammadHossein/0000-0002-8546-2700; Samavi,
   Shadrokh/0000-0003-3951-3770
CR Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Cho D, 2017, IEEE I CONF COMP VIS, P4568, DOI 10.1109/ICCV.2017.488
   Dorigo M, 2006, IEEE COMPUT INTELL M, V1, P28, DOI 10.1109/MCI.2006.329691
   Elnekave A, 2022, Arxiv, DOI arXiv:2203.11862
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Faheem M, 2019, T EMERG TELECOMMUN T, V30, DOI 10.1002/ett.3503
   Faheem M, 2018, APPL SOFT COMPUT, V68, P910, DOI 10.1016/j.asoc.2017.07.045
   Faheem M, 2017, INT J COMMUN SYST, V30, DOI 10.1002/dac.3257
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Granot N, 2022, PROC CVPR IEEE, P13450, DOI 10.1109/CVPR52688.2022.01310
   Ho Kei Cheng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8887, DOI 10.1109/CVPR42600.2020.00891
   Hongtao Yang, 2019, 2019 IEEE/ACIS 18th International Conference on Computer and Information Science (ICIS). Proceedings, P294
   Hosu V, 2019, PROC CVPR IEEE, P9367, DOI 10.1109/CVPR.2019.00960
   Hosu V, 2020, IEEE T IMAGE PROCESS, V29, P4041, DOI 10.1109/TIP.2020.2967829
   Ji XZ, 2020, IEEE COMPUT SOC CONF, P1914, DOI 10.1109/CVPRW50498.2020.00241
   Karaboga D, 2009, APPL MATH COMPUT, V214, P108, DOI 10.1016/j.amc.2009.03.090
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kim I, 2015, J SUPERCOMPUT, V71, P3500, DOI 10.1007/s11227-015-1446-4
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li J, 2021, PROC CVPR IEEE, P5085, DOI 10.1109/CVPR46437.2021.00505
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Mastan ID, 2020, IEEE WINT CONF APPL, P2355, DOI [10.1109/wacv45572.2020.9093637, 10.1109/WACV45572.2020.9093637]
   Mei Y, 2021, IEEE INT C MULT EXP, P1
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Shocher A, 2019, IEEE I CONF COMP VIS, P4491, DOI 10.1109/ICCV.2019.00459
   Su SL, 2020, PROC CVPR IEEE, P3664, DOI 10.1109/CVPR42600.2020.00372
   Suvorov R, 2022, IEEE WINT CONF APPL, P3172, DOI 10.1109/WACV51458.2022.00323
   Tan WM, 2020, IEEE T MULTIMEDIA, V22, P1730, DOI 10.1109/TMM.2019.2959925
   Valdez-Balderas D, 2021, IEEE IMAGE PROC, P1849, DOI 10.1109/ICIP42928.2021.9506584
   Wang XT, 2021, IEEE INT CONF COMP V, P1905, DOI 10.1109/ICCVW54120.2021.00217
   Yang SD, 2022, IEEE COMPUT SOC CONF, P1190, DOI 10.1109/CVPRW56347.2022.00126
   Zheng Chuanxia, 2021, arXiv
   Zhou Y, 2021, IEEE T CIRC SYST VID, V31, P126, DOI 10.1109/TCSVT.2020.2977943
   Zhou YQ, 2021, PROC CVPR IEEE, P2266, DOI 10.1109/CVPR46437.2021.00230
NR 35
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 28
PY 2023
DI 10.1007/s11042-023-16959-6
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM7
UT WOS:001076639200005
DA 2024-07-18
ER

PT J
AU Chang, JC
   Chen, SA
   Shen, VRL
AF Chang, Jen-Chun
   Chen, Si-Ann
   Shen, Victor R. L.
TI Smart bird identification system based on a hybrid approach: Petri nets,
   convolutional neural and deep residual networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Taiwan endemic birds; Petri nets; YOLOv5; ResNet-50; Object detection;
   Deep learning
AB Currently, most people mind the environmental ecology and animal protection. To maintain the ecology of wild animals, the relevant associations have been established. Taiwan is well known for a rich variety of bird species. Certain people love the bird watching activity most around the world. One of the precious wild animals is Taiwan endemic birds. To assist the public in identifying the 30 endemic birds of Taiwan, this study aims to combine Petri nets, You Only Look Once (YOLOv5) and Residual Network (ResNet-50) to develop a smart bird identification system. The identification process consists of three stages. At the first stage, Petri nets are used to model and analyze the system design process. At the second stage, YOLOv5 was used to precisely find the position of a bird in the image and to mark down the bounding box with object detection. At the third stage, ResNet-50 was used to train the classification model of the processed images, to compare the similarity of each image with others, to summarize the Top-5 similar category of each image, and to determine its maximum similarity as a final decision. Finally, the experimental results show that this hybrid approach can achieve an acceptable accuracy, 97.95%.
C1 [Chang, Jen-Chun; Chen, Si-Ann; Shen, Victor R. L.] Natl Taipei Univ, Dept Comp Sci & Informat Engn, 151 Univ Rd, New Taipei City 237, Taiwan.
   [Shen, Victor R. L.] Chaoyang Univ Technol, Dept Informat Management, Taichung, Taiwan.
C3 National Taipei University; Chaoyang University of Technology
RP Shen, VRL (corresponding author), Natl Taipei Univ, Dept Comp Sci & Informat Engn, 151 Univ Rd, New Taipei City 237, Taiwan.; Shen, VRL (corresponding author), Chaoyang Univ Technol, Dept Informat Management, Taichung, Taiwan.
EM jcchang@mail.ntpu.edu.tw; aocean713@gmail.com; rlshen@mail.ntpu.edu.tw
FU The authors are grateful to the anonymous reviewers for their
   constructive comments which have improved the quality of this paper.
   Also, this work was supported by the Ministry of Science and Technology,
   Taiwan, under grant MOST 110-2221-E-305-005-MY2. [MOST
   110-2221-E-305-005-MY2]; Ministry of Science and Technology, Taiwan
FX The authors are grateful to the anonymous reviewers for their
   constructive comments which have improved the quality of this paper.
   Also, this work was supported by the Ministry of Science and Technology,
   Taiwan, under grant MOST 110-2221-E-305-005-MY2.
CR Abeywardhana DL, 2022, MULTIMED TOOLS APPL, V81, P3223, DOI [10.1007/s11042-021-11693-3, 10.1007/s11042-021-11450-6]
   [Anonymous], 2020, Workflow Petri Net Designer
   Ashwani Kumar Aggarwal P.J., 2022, Int J Biol Biomed, V7, P40
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Chauhan S., 2021, P IEEE 2 INT C EL PO, P1
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Das N., 2020, Information Technology and Intelligent Transportation Systems, P117
   Datar P, 2018, 2018 4TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT)
   Ding TS, 2020, The 2020 TWBF Checklist of the Birds of Taiwan
   Garg M, 2023, MULTIMED TOOLS APPL, V82, P6271, DOI 10.1007/s11042-022-13596-3
   Hebert PDN, 2004, PLOS BIOL, V2, P1657, DOI 10.1371/journal.pbio.0020312
   Jocher G., 2020, YOLOv5
   Li J, 2014, 2014 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C 2014), P139, DOI 10.1109/IS3C.2014.47
   Liu ZH, 2022, MULTIMED TOOLS APPL, V81, P15469, DOI 10.1007/s11042-022-12570-3
   Naga Srinivasu P, 2021, Peer Journal Computer Science, P1
   Niemi J, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8112089
   Ou YQ, 2020, IEEE INT C ELECTR TA, DOI 10.1109/icce-taiwan49838.2020.9258061
   Petri Net, 2021, A Mathematical Model for Discrete Parallel Systems
   Thukral R, 2022, P INT C REC TRENDS C, P827, DOI DOI 10.1007/978-981-16-7118-0_70
   Thukral R, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT COMMUNICATION AND COMPUTATIONAL TECHNIQUES (ICCT), P161, DOI [10.1109/icct46177.2019.8969036, 10.1109/ICCT46177.2019.8969036]
   Vatsavayi VK, 2022, MULTIMED TOOLS APPL, V81, P33335, DOI 10.1007/s11042-022-12852-w
   Yan N, 2021, MULTIMED TOOLS APPL, V80, P36529, DOI 10.1007/s11042-021-11396-9
   Yang CY, 2023, APPL ARTIF INTELL, V37, DOI 10.1080/08839514.2023.2176607
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
NR 24
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 27
PY 2023
DI 10.1007/s11042-023-16390-x
EA SEP 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T1YW6
UT WOS:001076019000003
DA 2024-07-18
ER

PT J
AU Ouadil, KA
   Idbraim, S
   Bouhsine, T
   Bouaynaya, NC
   Alfergani, H
   Johnson, CC
AF Ait Ouadil, Kabira
   Idbraim, Soufiane
   Bouhsine, Taha
   Bouaynaya, Nidhal Carla
   Alfergani, Husam
   Johnson, Charles Cliff
TI Atmospheric visibility estimation: a review of deep learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Atmospheric visibility; Visibility estimation; Deep learning
ID NETWORK; RANGE
AB Estimating atmospheric visibility is a critical task in our current time, particularly in the safety of aviation, navigation, and highway traffic, because it measures the quality of the atmosphere's transparency. Poor visibility caused by climatic factors such as fog, haze, and clouds makes driving difficult and can lead to serious road accidents. Therefore, the researchers proposed several Deep Learning (DL) approaches to facilitate visibility estimation instead of using meteorological equipment, which is very expensive. This paper aims to give an overview of the DL systems used in previous studies to estimate atmospheric visibility. These systems are categorized based on the input data type, with some based on tabular data and others on image data. The methodologies, datasets, and Deep Neural Network (DNN) architectures used in the reviewed studies are thoroughly discussed. The evaluation metrics are also compared. Finally, the common limitations of the proposed approaches are highlighted, as well as potential future trends in this research field.
C1 [Ait Ouadil, Kabira; Idbraim, Soufiane; Bouhsine, Taha] Ibn Zohr Univ, IRF SIC Lab, Agadir, Morocco.
   [Bouhsine, Taha; Bouaynaya, Nidhal Carla; Alfergani, Husam] Rowan Univ, Dept Elect & Comp Engn, Glassboro, NJ USA.
   [Johnson, Charles Cliff] FAA, William J Hughes Tech Ctr, Atlantic City, NJ 08405 USA.
C3 Ibn Zohr University of Agadir; Rowan University
RP Ouadil, KA; Idbraim, S (corresponding author), Ibn Zohr Univ, IRF SIC Lab, Agadir, Morocco.
EM kabira.aitouadil@edu.uiz.ac.ma; s.idbraim@uiz.ac.ma;
   taha.bouhsine@edu.uiz.ac.ma; bouaynaya@rowan.edu; alferganh3@rowan.edu;
   Charles.C.Johnson@faa.gov
RI Bouhsine, Taha/KVB-4515-2024
OI Bouhsine, Taha/0000-0002-6564-4021; Ait Ouadil,
   Kabira/0009-0003-7173-1409
CR Atreya Y, 2021, 2021 2 GLOB C ADV TE, P1
   Babari R, 2011, ATMOS ENVIRON, V45, P5316, DOI 10.1016/j.atmosenv.2011.06.053
   Belaroussi R, 2014, IEEE INT VEH SYM, P1302, DOI 10.1109/IVS.2014.6856535
   Bilen Z, 2021, 29TH IEEE CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATIONS APPLICATIONS (SIU 2021), DOI 10.1109/SIU53274.2021.9477936
   Bouhsine T, 2022, 2022 9 INT C WIR NET, P1, DOI [10.1109/WINCOM55661.2022.9966454, DOI 10.1109/WINCOM55661.2022.9966454]
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chaabani H, 2018, PROCEDIA COMPUT SCI, V141, P478, DOI 10.1016/j.procs.2018.10.139
   Chaabani H, 2017, PROCEDIA COMPUT SCI, V113, P466, DOI 10.1016/j.procs.2017.08.304
   Chen J, 2023, IET SIGNAL PROCESS, V17, DOI 10.1049/sil2.12164
   Choi Y, 2018, J COASTAL RES, P881, DOI 10.2112/SI85-177.1
   Deng T, 2019, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE (ICAART), VOL 2, P466, DOI 10.5220/0007308204660473
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Giyenko A, 2018, 2018 32ND INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P875, DOI 10.1109/ICOIN.2018.8343247
   Gupta N, 2021, Conference Series, V1947
   Han Y, 2022, APPL ENERG, V312, DOI 10.1016/j.apenergy.2022.118777
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hess P, 2022, J ADV MODEL EARTH SY, V14, DOI 10.1029/2021MS002765
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   ICAO A, 2004, 3 ANN 3 CONV INT CIV
   Jonnalagadda J, 2020, 2020 IEEE 21ST INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION FOR DATA SCIENCE (IRI 2020), P209, DOI 10.1109/IRI49571.2020.00037
   Kim BY, 2022, AEROSOL AIR QUAL RES, V22, DOI 10.4209/aaqr.220125
   Kim BY, 2021, ATMOSPHERE-BASEL, V12, DOI 10.3390/atmos12050552
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li JP, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11030997
   Li Q, 2019, J ATMOS OCEAN TECH, V36, P1945, DOI 10.1175/JTECH-D-19-0025.1
   Li Q, 2019, IEEE ACCESS, V7, P24430, DOI 10.1109/ACCESS.2019.2894658
   Liao Q, 2020, CURR POLLUT REP, V6, P399, DOI 10.1007/s40726-020-00159-z
   Lin T, 2022, AI Open
   Liu J, 2022, IEEE Access
   Liu J, 2023, Fgs-net: A visibility estimation method based on statistical feature stream in fog area
   Liu T, 2019, 2019 INT C MET OBS I, P1
   Liu Z, 2022, ATMOS ENVIRON, V278, DOI 10.1016/j.atmosenv.2022.119085
   Lo WL, 2021, ATMOSPHERE-BASEL, V12, DOI 10.3390/atmos12070828
   Lo WL, 2020, J ADV INFORM TECHNOL, V11, P40, DOI 10.12720/jait.11.2.40-47
   Lung CC, 2016, AEROSOL AIR QUAL RES, V16, P2237, DOI 10.4209/aaqr.2016.03.0111
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   o'g'Li PAA, 2018, JOINT INT CONF SOFT, P240, DOI 10.1109/SCIS-ISIS.2018.00050
   Ortega LC, 2022, Int J Forecast
   Outay F, 2021, PERS UBIQUIT COMPUT, V25, P51, DOI 10.1007/s00779-019-01334-w
   Palvanov A, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061343
   Pan HG, 2018, IEEE ANN INT CONF CY, P1421, DOI 10.1109/CYBER.2018.8688062
   Qin HS, 2022, IEEE ACCESS, V10, P25448, DOI 10.1109/ACCESS.2021.3101323
   Saha S, 2023, 2023 IEEE 13TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE, CCWC, P553, DOI 10.1109/CCWC57344.2023.10099100
   Shengyan Li, 2017, International Journal of Computer Theory and Engineering, V9, P455, DOI 10.7763/IJCTE.2017.V9.1186
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh A, 2020, ENVIRON RES LETT, V15, DOI 10.1088/1748-9326/ab8b12
   Song MF, 2021, J CLOUD COMPUT-ADV S, V10, DOI 10.1186/s13677-021-00261-7
   Tang R, 2022, J ATMOS OCEAN TECH, V39, P789, DOI 10.1175/JTECH-D-21-0170.1
   Tarel JP, 2010, IEEE INT VEH SYM, P478, DOI 10.1109/IVS.2010.5548128
   Uyanik T, 2021, APPL OCEAN RES, V112, DOI 10.1016/j.apor.2021.102693
   Vaibhav V, 2020, IEEE INT C INTELL TR, DOI 10.1109/itsc45102.2020.9294740
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H, 2020, IEEE ACCESS, V8, P217057, DOI 10.1109/ACCESS.2020.3031283
   Xin Y, Resnet-ca: A novel end-to-end visibility estimation method
   Xun LN, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22166227
   Yan M, 2022, 2 INT C APPL MATH MO, V12259, P1440
   You J, 2022, IEEE T INTELL TRANSP, V23, P22354, DOI 10.1109/TITS.2022.3180229
   You Y, 2019, IEEE T IMAGE PROCESS, V28, P45, DOI 10.1109/TIP.2018.2857219
   Zeng L, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7040314
   Zhang F, 2023, ATMOSPHERE-BASEL, V14, DOI 10.3390/atmos14010061
   Zou XG, 2021, ATMOSPHERE-BASEL, V12, DOI 10.3390/atmos12070869
NR 61
TC 0
Z9 0
U1 7
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 26
PY 2023
DI 10.1007/s11042-023-16855-z
EA SEP 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S8YJ1
UT WOS:001073965700012
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Hu, Q
   Li, DM
   Luo, H
   Li, WQ
AF Zhang, Yu
   Hu, Qing
   Li, Danmeng
   Luo, Han
   Li, Wenqiang
TI Texture feature-based local adaptive Otsu segmentation and Hough
   transform for sea-sky line detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Texture features; Adaptive Otsu segmentation; Adaptive Canny; Hough
   transform; Sea-sky line detection
ID HORIZON DETECTION; TRACKING
AB The sea-sky line is an important basis for marine unmanned equipment to perceive the sea environment. However, due to the interference of many external factors, such as sea fog, illumination, and sea target occlusion, sea-sky line detection is challenging. Therefore, we present a texture feature-based local adaptive Otsu segmentation and Hough transform for sea-sky line detection. In this method, image texture features and weighted texture quantization are used to determine the sea-sky area. Based on this sea-sky area, a longitudinal block strategy is introduced, and a new adaptive Otsu segmentation method is applied to obtain the binary image of the sea-sky area. The obtained binary image is then post-processed to enhance the sea-sky line edge information. On this basis, a new adaptive Canny edge detector is applied, and the sea-sky line is extracted by the Hough transform. The experimental results show that the proposed sea-sky line detection method has high accuracy and robustness when handling images of complex marine environments. Compared with other algorithms, the detection error and the error standard deviation of the proposed method are relatively small, indicating that this method is more stable and accurate than other algorithms.
C1 [Zhang, Yu; Hu, Qing; Li, Danmeng; Luo, Han; Li, Wenqiang] Dalian Maritime Univ, Coll Informat Sci & Technol, Dalian, Peoples R China.
C3 Dalian Maritime University
RP Hu, Q (corresponding author), Dalian Maritime Univ, Coll Informat Sci & Technol, Dalian, Peoples R China.
EM zydmu0810@163.com; hq0518@dlmu.edu.cn; dmuldm@dlmu.edu.cn;
   luohandmu@163.com; 13555828792@163.com
RI HU, Qing/GWQ-8711-2022; Hu, Qing/K-1400-2014
OI Hu, Qing/0000-0001-8569-044X
FU The authors would like to thank the anonymous reviewers for their
   valuable comments. And the authors would like to thank Kristan et al.
   for providing the data sets.
FX The authors would like to thank the anonymous reviewers for their
   valuable comments. And the authors would like to thank Kristan et al.
   for providing the data sets.
CR Ahmad T, 2015, 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P1095, DOI 10.1109/ICMLA.2015.67
   Boroujeni Nasim Sepehri, 2012, 2012 Canadian Conference on Computer and Robot Vision, P346, DOI 10.1109/CRV.2012.52
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Dai Y., 2018, Opto-Electron Eng, V45, P57, DOI [10.12086/oee.2018.180039, DOI 10.12086/OEE.2018.180039]
   Dumble SJ, 2012, J INTELL ROBOT SYST, V68, P339, DOI 10.1007/s10846-012-9684-7
   Ettinger SM, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P2134, DOI 10.1109/IRDS.2002.1041582
   Fefilatyev S, 2006, ICMLA 2006: 5TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P17
   Fefilatyev S, 2012, OCEAN ENG, V54, P1, DOI 10.1016/j.oceaneng.2012.06.028
   Ganbold U, 2020, 2020 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2020), P204, DOI [10.1109/CW49994.2020.00040, 10.1109/CW49994.2020.9247845]
   Gershikov E., 2013, Int. J. Adv. Intell. Syst, V6, P79, DOI DOI 10.1080/18756891.2013.756225
   Guo Y, 2022, CHIN CONTR CONF, P6321, DOI 10.23919/CCC55666.2022.9902568
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Hashmi MU, 2020, INNOV SMART GRID TEC, DOI 10.1109/isgt45199.2020.9087772
   Hong P, 2014, PROC SPIE, V9300, DOI 10.1117/12.2074406
   Huang Yingdong, 2008, Journal of Projectiles, Rockets, Missiles and Guidance, V28, P286
   Jiang CL, 2010, 2010 THIRD INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY AND SECURITY INFORMATICS (IITSI 2010), P740, DOI 10.1109/IITSI.2010.147
   Prasad DK, 2016, Arxiv, DOI arXiv:1608.01079
   Kristan M, 2016, IEEE T CYBERNETICS, V46, P641, DOI 10.1109/TCYB.2015.2412251
   Liang D, 2020, IEEE T INSTRUM MEAS, V69, P45, DOI 10.1109/TIM.2019.2893008
   Liang D, 2015, PR IEEE I C PROGR IN, P317, DOI 10.1109/PIC.2015.7489861
   Lin C, 2020, J MAR SCI ENG, V8, DOI 10.3390/jmse8100799
   Liu JY, 2021, MOBILE NETW APPL, V26, P1372, DOI 10.1007/s11036-021-01752-2
   [刘松涛 LIU Songtao], 2006, [光电工程, Opto-Electronic Engineering], V33, P5
   Liu XY, 2017, PROCEEDINGS OF 2017 13TH IEEE INTERNATIONAL CONFERENCE ON ELECTRONIC MEASUREMENT & INSTRUMENTS (ICEMI), VOL 1, P486, DOI 10.1109/ICEMI.2017.8265991
   Ma T, 2016, INT SYM COMPUT INTEL, P46, DOI [10.1109/ISCID.2016.1019, 10.1109/ISCID.2016.18]
   Truong MTN, 2018, SOFT COMPUT, V22, P4197, DOI 10.1007/s00500-017-2709-1
   Mo WY, 2023, VISUAL COMPUT, V39, P1915, DOI 10.1007/s00371-022-02455-9
   Ng HF, 2006, PATTERN RECOGN LETT, V27, P1644, DOI 10.1016/j.patrec.2006.03.009
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Prasad DK, 2017, IEEE T INTELL TRANSP, V18, P1993, DOI 10.1109/TITS.2016.2634580
   Prasad DK, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P1366, DOI 10.1109/TENCON.2016.7848237
   Prasad DK, 2016, J OPT SOC AM A, V33, P2491, DOI 10.1364/JOSAA.33.002491
   Schwendeman M, 2015, J ATMOS OCEAN TECH, V32, P164, DOI 10.1175/JTECH-D-14-00047.1
   Shi BH, 2023, J MAR SCI ENG, V11, DOI 10.3390/jmse11061130
   Shi GM, 2016, I C COMM SOFTW NET, P652, DOI 10.1109/ICCSN.2016.7586604
   Soille P, 2013, Springer Science & Business Media, P183, DOI [10.1007/978-3-662-03939-7, DOI 10.1007/978-3-662-03939-7]
   Song HF, 2021, J RUSS LASER RES, V42, P318, DOI 10.1007/s10946-021-09965-2
   Sun Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092825
   Tang D, 2013, PROC SPIE, V8907, DOI 10.1117/12.2033039
   Wei MQ, 2019, VISUAL COMPUT, V35, P797, DOI 10.1007/s00371-019-01688-5
   Xin ZH, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22072587
   [徐良玉 Xu Liangyu], 2017, [上海大学学报. 自然科学版, Journal of Shanghai University. Natural Science Edition], V23, P47
   Yiming Bai, 2021, 2021 6th International Conference on Automation, Control and Robotics Engineering (CACRE), P456, DOI 10.1109/CACRE52464.2021.9501336
   Yongqing Zhang, 2021, 2021 2nd International Conference on Electronics, Communications and Information Technology (CECIT), P48, DOI 10.1109/CECIT53797.2021.00016
   Zardoua Y, 2023, VISUAL COMPUT, V39, P197, DOI 10.1007/s00371-021-02321-0
   Zhang P., 2021, J Shenyang Inst Aeronaut Eng, V38, P58, DOI [10.3969/j.issn.2095-1248.2021.05.009, DOI 10.3969/J.ISSN.2095-1248.2021.05.009]
NR 46
TC 0
Z9 0
U1 11
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 26
PY 2023
DI 10.1007/s11042-023-17012-2
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S8YJ1
UT WOS:001073965700001
DA 2024-07-18
ER

PT J
AU Wang, YM
   Huang, Q
   Liu, JW
   Jiang, CX
   Shang, MZ
AF Wang, Yiming
   Huang, Qian
   Liu, Jiwen
   Jiang, Chuanxu
   Shang, Mingzhou
TI Adaptive video stabilization based on feature point detection and
   full-reference stability assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive video stabilization; Feature point detection; Camera trajectory
   optimization; Full-reference stability assessment
AB Video stabilization is an important video enhancement technique that removes shaky motion and produces stable videos with good visual quality. Previous feature point matching methods are proposed to estimate motion information. However, video stabilization based on feature points matching will decrease or fail to match feature for video sequences lacking feature point, which causes poor results. Also, there is not a recognized method to measure the performance of video stabilization. To solve these problems, we propose an adaptive video stabilization based on feature point detection and full-reference stability assessment. In the proposed method, appropriate video stabilization algorithms are firstly selected by detecting the number of feature points and camera trajectory optimization is used to retain original motion information. Secondly, we propose a full-reference stability assessment to measure video stabilization performance. Furthermore, video stabilization is assessed from three aspects on the video dataset DeepStab. Finally, experimental results demonstrate the promising performance of our proposed algorithm in terms of subjective and objective evaluations.
C1 [Wang, Yiming; Huang, Qian; Liu, Jiwen; Jiang, Chuanxu; Shang, Mingzhou] Hohai Univ, Sch Comp & Informat, Nanjing, Peoples R China.
   [Wang, Yiming; Huang, Qian; Liu, Jiwen; Jiang, Chuanxu; Shang, Mingzhou] Hohai Univ, Minist Water Resources, Key Lab Water Big Data Technol, Nanjing, Peoples R China.
C3 Hohai University; Hohai University
RP Huang, Q (corresponding author), Hohai Univ, Sch Comp & Informat, Nanjing, Peoples R China.; Huang, Q (corresponding author), Hohai Univ, Minist Water Resources, Key Lab Water Big Data Technol, Nanjing, Peoples R China.
EM isymwang@gmail.com; huangqian@hhu.edu.cn; liujiwen@hhu.edu.cn;
   jiangchuanxu@hhu.edu.cn; shangmingzhou@hhu.edu.cn
RI Huang, Qian/GPX-9181-2022
OI Huang, Qian/0000-0001-5625-0402; Wang, Yiming/0000-0001-5683-909X
FU the Fundamental Research Funds for the Central Universities
FX This work was supported in part by the Fundamental Research Funds for
   the Central Universities under Grant No.B230205048, the Postgraduate
   Research & Practice Innovation Program of Jiangsu Province under Grant
   (No.KYCX23_0685, No.SJCX22_0161), the Key Research and Development
   Program of Yunnan Province under grant No. 202203AA080009, the 14th
   Five-Year Plan for Educational Science of Jiangsu Province under grant
   No. D/2021/01/39, the Jiangsu Higher Education Reform Research Project
   under grant No.2021JSJG143, and the 2022 Undergraduate Practice Teaching
   Reform Research Project of Hohai University
CR Bai JM, 2014, COMPUT GRAPH FORUM, V33, P61, DOI 10.1111/cgf.12413
   Bell S, 2014, LECT NOTES COMPUT SC, V8692, P294, DOI 10.1007/978-3-319-10593-2_20
   Buehler C, 2001, PROC CVPR IEEE, P609
   Chi X, 2021, EXP TECHNIQUES, V45, P345, DOI 10.1007/s40799-020-00395-4
   Fang M, 2018, 2018 INT C COMPUTING, P1, DOI [10.1109/ICOMET.2018.8346332, DOI 10.1109/ICOMET.2018.8346332]
   Goldstein A, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2231816.2231824
   Grundmann M, 2013, IEEE INT CONF COMPUT
   Grundmann M, 2011, PROC CVPR IEEE, P225, DOI 10.1109/CVPR.2011.5995525
   Guilluy W, 2021, SIGNAL PROCESS-IMAGE, V90, DOI 10.1016/j.image.2020.116015
   Guo H, 2016, IEEE T IMAGE PROCESS, V25, P5491, DOI 10.1109/TIP.2016.2607419
   guthspot, Deshaker
   Hu WC, 2018, MULTIMED TOOLS APPL, V77, P5107, DOI 10.1007/s11042-017-4369-7
   Hu WC, 2018, MULTIMED TOOLS APPL, V77, P1237, DOI 10.1007/s11042-016-4291-4
   Huang H, 2019, IEEE T CIRC SYST VID, V29, P1503, DOI 10.1109/TCSVT.2018.2833476
   Jia S, 2018, MULTIMED TOOLS APPL, V77, P14859, DOI 10.1007/s11042-017-5070-6
   Karpenko A., 2011, CSTR, V1, P13
   Korhonen J, 2012, INT WORK QUAL MULTIM, P37, DOI 10.1109/QoMEX.2012.6263880
   Krishnakumar K, 2019, MULTIMED TOOLS APPL, V78, P1375, DOI 10.1007/s11042-018-6116-0
   Laboratories K, Multimedia: Use Image Stabilization
   Lee KY, 2009, IEEE I CONF COMP VIS, P1397
   Li SD, 2016, INT CONF 3D VISION, P314, DOI 10.1109/3DV.2016.40
   Lin SS, 2021, MULTIMED TOOLS APPL, V80, P1545, DOI 10.1007/s11042-020-09767-9
   Liu F, 2013, IEEE I CONF COMP VIS, P73, DOI 10.1109/ICCV.2013.16
   Liu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899408
   Liu F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531350
   Liu SC, 2017, IEEE T IMAGE PROCESS, V26, P3291, DOI 10.1109/TIP.2017.2697759
   Liu SC, 2016, LECT NOTES COMPUT SC, V9910, P800, DOI 10.1007/978-3-319-46466-4_48
   Liu SC, 2014, PROC CVPR IEEE, P4209, DOI 10.1109/CVPR.2014.536
   Liu S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461995
   Liu SC, 2012, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2012.6247662
   Liu YL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2279, DOI 10.1109/ICCV48922.2021.00230
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matsushita Y, 2006, IEEE T PATTERN ANAL, V28, P1150, DOI 10.1109/TPAMI.2006.141
   Morimoto C, 1998, INT CONF ACOUST SPEE, P2789, DOI 10.1109/ICASSP.1998.678102
   Niskanen M, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P405
   Ovrén H, 2015, IEEE INT CONF ROBOT, P2090, DOI 10.1109/ICRA.2015.7139474
   Prasertsakul P, 2020, MULTIMED TOOLS APPL, V79, P17403, DOI 10.1007/s11042-019-08378-3
   Qu H, 2013, IEEE IMAGE PROC, P29, DOI 10.1109/ICIP.2013.6738007
   Qu Hui, 2013, P VIS COMM IM PROC, P1, DOI DOI 10.1109/VCIP.2013.6706422
   Raj R, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103957
   Rawat P., 2011, INT J SIGNAL IMAGE P, V2, P159, DOI DOI 10.5121/sipij.2011.2213
   SATO K, 1993, IEEE T CONSUM ELECTR, V39, P461, DOI 10.1109/30.234621
   Smith BM, 2009, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2009.5459270
   Streijl RC, 2016, MULTIMEDIA SYST, V22, P213, DOI 10.1007/s00530-014-0446-1
   Subbarao R., 2006, P 2006 C COMPUTER VI, P101
   Valero MM, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030540
   Wang M, 2019, IEEE T IMAGE PROCESS, V28, P2283, DOI 10.1109/TIP.2018.2884280
   Wang YM, 2023, NEUROCOMPUTING, V516, P205, DOI 10.1016/j.neucom.2022.10.008
   Wang YS, 2013, IEEE T VIS COMPUT GR, V19, P1354, DOI 10.1109/TVCG.2013.11
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Wu RW, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21072505
   Xu YF, 2022, IEEE T IMAGE PROCESS, V31, P4306, DOI 10.1109/TIP.2022.3182887
   Yu JY, 2021, PROC CVPR IEEE, P12031, DOI 10.1109/CVPR46437.2021.01186
   Zhang L, 2017, IEEE T CIRC SYST VID, V27, P225, DOI 10.1109/TCSVT.2015.2501941
   Zhou ZH, 2013, PROC CVPR IEEE, P2299, DOI 10.1109/CVPR.2013.298
NR 56
TC 0
Z9 0
U1 15
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32497
EP 32524
DI 10.1007/s11042-023-16607-z
EA SEP 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069968300004
DA 2024-07-18
ER

PT J
AU Aurelia, S
   Thanuja, R
   Chowdhury, S
   Hu, YC
AF Aurelia, Sagaya
   Thanuja, R.
   Chowdhury, Subrata
   Hu, Yu-Chen
TI AI-based online proctoring: a review of the state-of-the-art techniques
   and open challenges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial intelligence; Machine learning; Covid-19; Online monitoring;
   Pandemic; Testers
AB So far, this pandemic has severely affected the education sector. As education undergoes a brilliant transformation with advancing technology, the digital acquisition of knowledge has yet to find widespread use - virtual exams. Faraway Proctoring offers several advantages of using manual and primarily based technology. Although this allows students to take an exam in any field with specific technical requirements, it eliminates the need for physical research centers. It is cost-effective and easy to plan, which can be challenging to manage, especially during aggressive trials. Finally, the paper discusses the performance characteristics of different styles of web-based inspection systems, along with their limitations and challenges.
C1 [Aurelia, Sagaya] CHRIST Deemed Univ, Dept Comp Sci, Bangalore, Karnataka, India.
   [Thanuja, R.] Sastra Deemed Univ, Dept CSE, SRC Campus, Kumbakonam, India.
   [Chowdhury, Subrata] Sreenivasa Inst Technol & Management Studies, Dept Comp Sci & Engn, Chittoor, Andra Pradesh, India.
   [Hu, Yu-Chen] Tunghai Univ, Dept Comp Sci, Taichung, Taiwan.
   [Hu, Yu-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taichung, Taiwan.
C3 Christ University; Shanmugha Arts, Science, Technology & Research
   Academy (SASTRA); Tunghai University; Providence University - Taiwan
RP Hu, YC (corresponding author), Tunghai Univ, Dept Comp Sci, Taichung, Taiwan.; Hu, YC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, Taichung, Taiwan.
EM sagaya.aurelia@christuniversity.in; thanuja.r@cse.sastra.edu;
   subrata895@gmail.com; ychu@pu.edu.tw
RI Chowdhury, Dr. Subrata/Y-5282-2018
OI Chowdhury, Dr. Subrata/0000-0001-5679-3140; Hu,
   Yu-Chen/0000-0002-5055-3645
CR Alessio HM, 2017, ONLINE LEARN, V21, P146
   Ali S, 2021, MULTIMED TOOLS APPL, V80, P33329, DOI 10.1007/s11042-021-11414-w
   [Anonymous], How AI-based Exams are Helping Universities Scale Online Examinations
   [Anonymous], It works!
   [Anonymous], Advanced Automated Cognitive Proctoring
   [Anonymous], 2017, Leveling the playing field for rural students
   [Anonymous], Online Exam Proctoring Services
   [Anonymous], Strengthen Exam Integrity with Digital Monitoring
   [Anonymous], State of The Art Remote Proctoring(RPASS) Powered By Ai
   [Anonymous], OPPORTUNITIES CHALLE
   Arora P, 2021, eLearning Industry
   Atoum Y, 2017, IEEE T MULTIMEDIA, V19, P1609, DOI 10.1109/TMM.2017.2656064
   Bawarith R, 2017, INT J ADV COMPUT SC, V8, P176
   Beulens AJW., 2020, Eur Urol Open Sci, Ve 21, pS26, DOI [10.1016/S2666-1683(20)35868-7, DOI 10.1016/S2666-1683(20)35868-7]
   Cerimagic S., 2019, J Educ Res, V7, P929
   Choi CR, 2019, MULTIMED TOOLS APPL, V78, P28853, DOI 10.1007/s11042-019-7351-8
   Dendir S, 2020, COMPUT HUM BEHAV REP, V2, DOI 10.1016/j.chbr.2020.100033
   F.A.Q, How Was GMAT Held Using AI Proctors? Can It Detect Cheating?
   González-González CS, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12083488
   Hollister KK, 2009, DECIS SCI-J INNOV ED, V7, P271, DOI 10.1111/j.1540-4609.2008.00220.x
   Hylton K, 2016, COMPUT EDUC, V92-93, P53, DOI 10.1016/j.compedu.2015.10.002
   Labayen M, 2021, IEEE ACCESS, V9, P72398, DOI 10.1109/ACCESS.2021.3079375
   Maniar S, 2021, 2021 INT C SYST COMP, P1
   Miller A, 2011, J EXP EDUC, V79, P169, DOI 10.1080/00220970903567830
   Milone AS, 2017, CURR PHARM TEACH LEA, V9, P108, DOI 10.1016/j.cptl.2016.08.037
   Nath L., 2009, COLL TEACH, V57, P3
   Ow Tiong L. C., 2021, arXiv
   Pimple O, 2021, The Med Bull
   Raj RSV, 2015, IEEE INT CONF ADV LE, P458, DOI 10.1109/ICALT.2015.127
   Rios JA, 2017, AM J DISTANCE EDUC, V31, P226, DOI 10.1080/08923647.2017.1258628
   Rodchua S., 2011, Journal of Industrial Technology, V27, P1
   Rowe NC, 2004, Online Journal of Distance Learning Administration, V7, P1
   Sarwar S, 2019, MULTIMED TOOLS APPL, V78, P34745, DOI 10.1007/s11042-019-08125-8
   Senbo Hu, 2018, 2018 10th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC). Proceedings, P88, DOI 10.1109/IHMSC.2018.10127
   Slusky L., 2020, J Int Technol Inf Manag, V29, P3
   Soman N, 2017, PROCEEDINGS OF THE 2017 IEEE SECOND INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND COMMUNICATION TECHNOLOGIES (ICECCT)
   Sridhar A., 2022, Journal of Artificial Intelligence, V4, P139
   Susithra V, 2021, 2021 INT C SYST COMP, P1
   Turani AA, 2020, 2020 EM TECHN COMP C, P1
   Usir E, 2017, INDIAN J PHARM EDUC, V51, P373, DOI 10.5530/ijper.51.3.63
   Vazquez JJ, 2021, J BEHAV EXP ECON, V90, DOI 10.1016/j.socec.2020.101653
   Your Exams, On Your Terms-Deploy Your Own Proctoring Staff
   US
NR 43
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31805
EP 31827
DI 10.1007/s11042-023-16714-x
EA SEP 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001067933300003
DA 2024-07-18
ER

PT J
AU Fotsing, J
   Kakmeni, JMM
   Tiedeu, A
   Fotsin, HB
AF Fotsing, J.
   Kakmeni, J. -M. Moukam
   Tiedeu, A.
   Fotsin, H. B.
TI Image encryption algorithm based on 2D logistic map system in IoHT using
   5G network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption; IoHT; 2D Logistic diffusion; 2D Logistic permutation; Images
AB In this paper, an image encryption technique is proposed to encrypt the images by using a 2D Logistic map with the SHA-256 sequence generator. The initial conditions and control parameters of the chaotic maps served as the key for the cryptosystem, and were made dependent on the plain image through the SHA-256 protocol. The internal loop of the proposed image encryption method is made of 2D logistic permutation, and 2D logistic diffusion. In order the proposed system performance, widely known and accepted metrics as keyspace, key sensitivity, histogram, correlation and entropy were computed. Experimental results showed that the proposed approach was highly key sensitive and exhibited a good resistance against brute-force and statistical attacks. The cryptosystem presented in this part was designed to ensure the safe exchange of medical images on the 5G telecommunication network using IoHT in the interconnexion of different hospital services.
C1 [Fotsing, J.; Kakmeni, J. -M. Moukam] Univ Buea, Dept Phys, Fac Sci, POB 63, Buea, Cameroon.
   [Tiedeu, A.] Univ Yaounde, Instrumentat Signal & Image Lab, Natl Adv Sch Engn Yaounde, POB 8390, Yaounde, Cameroon.
   [Fotsin, H. B.] Univ Dschang, Dept Phys, Fac Sci, POB 63, Dschang, Cameroon.
C3 University of Yaounde I; Universite de Dschang
RP Fotsing, J (corresponding author), Univ Buea, Dept Phys, Fac Sci, POB 63, Buea, Cameroon.
EM fotsing.janvier@ubuea.cm
OI FOTSING, Janvier/0000-0001-7997-0242
FU None
FX This work has benefit the support of the manager of "Club des Lecteurs"
   by offering books and papers need to build up this project.
CR Abanda Y, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6624890
   Abd El-Latif AA, 2020, PHYSICA A, V541, DOI 10.1016/j.physa.2019.123687
   Abd EL-Latif AA, 2020, OPT LASER TECHNOL, V124, DOI 10.1016/j.optlastec.2019.105942
   Al-Najjar HM, 2011, P COMPUTER SCI, P56
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Arroyo D, 2008, ACTAS X RECSI, P28
   Bali MS, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/4288663
   Banu SA, 2020, MED BIOL ENG COMPUT, V58, P1445, DOI 10.1007/s11517-020-02178-w
   Banu SA, 2020, MULTIMED TOOLS APPL, V79, P28807, DOI 10.1007/s11042-020-09501-5
   Baptista MS, 1998, PHYS LETT A, V240, P50, DOI 10.1016/S0375-9601(98)00086-3
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Belkhouche F, 2003, IEEE REGION 5 2003 ANNUAL TECHNICAL CONFERENCE, CONFERENCE RECORD, P39, DOI 10.1109/REG5.2003.1199708
   Ben Ammar M, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11030383
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Chai XL, 2020, NEURAL COMPUT APPL, V32, P4961, DOI 10.1007/s00521-018-3913-3
   Chen HK, 2004, CHAOS SOLITON FRACT, V21, P957, DOI 10.1016/j.chaos.2003.12.034
   Fu C, 2017, INT J NETW DISTRIB C, V5, P37, DOI 10.2991/ijndc.2017.5.1.4
   Ganesh Sekar J., 2020, J Crit Rev, V7, P1138
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Gu GS, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 1, PROCEEDINGS, P492
   Hamza R, 2020, INFORM SCIENCES, V527, P493, DOI 10.1016/j.ins.2019.01.070
   Hua ZY, 2019, IEEE T IND ELECTRON, V66, P1273, DOI 10.1109/TIE.2018.2833049
   Hua ZY, 2015, IEEE SYS MAN CYBERN, P1804, DOI 10.1109/SMC.2015.316
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Kitio GJ, 2023, BRAZ J PHYS, V53, DOI 10.1007/s13538-023-01268-y
   Jiang Delei, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P251, DOI 10.1109/CSSE.2008.1142
   Jolfaei Alireza, 2010, Journal of Theoretical and Applied Information Technology, V19, P117
   Jridi M, 2018, OPT LASER ENG, V102, P59, DOI 10.1016/j.optlaseng.2017.10.007
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   KANTZ H, 1994, PHYS LETT A, V185, P77, DOI 10.1016/0375-9601(94)90991-1
   Kengne J., 2018, Int. J. Dyn. Control, V6, P468
   Kengne LK, 2021, INT J CIRC THEOR APP, V49, P1470, DOI 10.1002/cta.2968
   Kocarev L, 2004, P 2004 INT S NONL TH, P609
   Lakhan A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062379
   Lakhan A, 2021, MATH BIOSCI ENG, V18, P7344, DOI 10.3934/mbe.2021363
   Leutcho GD, 2018, CHAOS SOLITON FRACT, V113, P275, DOI 10.1016/j.chaos.2018.05.017
   Lin CY, 2001, IEEE T IMAGE PROCESS, V10, P767, DOI 10.1109/83.918569
   Liu JZ, 2018, MULTIMED TOOLS APPL, V77, P22787, DOI 10.1007/s11042-017-5534-8
   Moysis L, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12050829
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Nematzadeh H, 2018, OPT LASER ENG, V110, P24, DOI 10.1016/j.optlaseng.2018.05.009
   Nkandeu YK, 2022, MULTIMED TOOLS APPL, V81, P17131, DOI 10.1007/s11042-022-12649-x
   Nkandeu YPK, 2020, SENS IMAGING, V21, DOI 10.1007/s11220-020-00318-y
   Pan HL, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0386-3
   Ramakrishnan B, 2022, MULTIMED TOOLS APPL, V81, P23819, DOI 10.1007/s11042-022-12400-6
   Ruggiero D, 2004, P RISP INT WORKSH NO, P77
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Stinson D. R., 2006, Cryptography Theory and Practice, V3rd
   Strogatz SH., 1994, NONLINEAR DYNAMICS C
   Telem ANK, 2021, MULTIMED TOOLS APPL, V80, P19011, DOI 10.1007/s11042-021-10549-0
   Tsafack N, 2020, IEEE ACCESS, V8, P137731, DOI 10.1109/ACCESS.2020.3010794
   Vaidyanathan S, 2018, EUR PHYS J PLUS, V133, DOI 10.1140/epjp/i2018-11872-8
   Wang Y, 2004, 2004 IEEE CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEMS, VOLS 1 AND 2, P1172
   WOLF A, 1985, PHYSICA D, V16, P285, DOI 10.1016/0167-2789(85)90011-9
   Wu GC, 2014, SIGNAL PROCESS, V102, P96, DOI 10.1016/j.sigpro.2014.02.022
   Wu XG, 2004, CHAOS SOLITON FRACT, V22, P359, DOI 10.1016/j.chaos.2004.02.008
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Xiao HP, 2006, PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P2707
   Yang FF, 2020, CHINA COMMUN, V17, P21, DOI 10.23919/JCC.2020.05.003
   Yang L, 2022, IEEE T IND INFORM, V18, P8864, DOI 10.1109/TII.2021.3128954
   Yepdia LMH, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6615708
   Yepdia LMH, 2021, SENS IMAGING, V22, DOI 10.1007/s11220-021-00340-8
   Zhou MJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107484
NR 63
TC 1
Z9 1
U1 5
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30819
EP 30845
DI 10.1007/s11042-023-16730-x
EA SEP 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001081631900011
DA 2024-07-18
ER

PT J
AU Trinh, T
   Le, H
   VuongThi, N
   HoangDuc, H
   VuThi, K
AF Thanh Trinh
   HoangAnh Le
   Nhung VuongThi
   Hai HoangDuc
   KieuAnh VuThi
TI A novel ensemble-based paradigm to process large-scale data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data; Large-scale data; Ensemble; Spark; Cluster; Classification
AB Big data analytics is an emerging topic in academic and industrial engineering fields, where the large-scale data issue is the most attractive challenge. It is crucial to design an effective large-scale data processing model to handle big data. In this paper, we aim to improve the accuracy of the classification task and reduce the execution time for large-scale data within a small cluster. In order to overcome these challenges, this paper presents a novel ensemble-based paradigm that consists of the procedure of splitting large-scale data files and developing ensemble models. Two different splitting methods are first developed to partition large-scale data into small data blocks without overlapping. Then we propose two ensemble-based methods with high accuracy and less execution time: bagging-based and boosting-based methods. Finally, the proposed paradigm can be implemented by four predictive models, which are combinations of two splitting methods and two ensemble-based methods. A series of persuasive experiments was conducted to evaluate the effectiveness of the proposed paradigm with four different combinations. Overall, the proposed paradigm with boosting-based is the best in terms of the accuracy metric compared with existing methods. In addition, boosting-based methods achieve 91.6% accuracy compared with 52% accuracy of base line model for a big data file with 10 million samples. However, the paradigm with bagging-based takes the least execution time to yield results. This paper also reveals the effectiveness of the computing Spark cluster for large-scale data and points out the weakness of RDD (Resilient Distributed dataset).
C1 [Thanh Trinh; HoangAnh Le; Hai HoangDuc; KieuAnh VuThi] Phenikaa Univ, Fac Comp Sci, Hanoi 12116, Vietnam.
   [Thanh Trinh] A&A Green Phoenix Grp JSC, Phenikaa Res & Technol Inst PRATI, 167 Hoang Ngan, Hanoi 11313, Vietnam.
   [HoangAnh Le; Hai HoangDuc] Phenikaa Univ, Informat Technol Ctr, Hanoi 12116, Vietnam.
   [HoangAnh Le] Phenikaa Univ, Phenikaa Inst Adv Study PIAS, Hanoi 12116, Vietnam.
   [Nhung VuongThi] Vietnam Natl Univ, Hanoi Sch Business & Management, Hanoi 11310, Vietnam.
C3 Vietnam National University Hanoi
RP Trinh, T (corresponding author), Phenikaa Univ, Fac Comp Sci, Hanoi 12116, Vietnam.; Trinh, T (corresponding author), A&A Green Phoenix Grp JSC, Phenikaa Res & Technol Inst PRATI, 167 Hoang Ngan, Hanoi 11313, Vietnam.
EM thanh.trinh@phenikaa-uni.edu.vn
OI Trinh, Thanh/0000-0002-6973-9749
CR Ahmed N, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00388-5
   Baldi P, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5308
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Breiman L., 2017, Classification and Regression Trees, DOI [10.1201/9781315139470-8, DOI 10.1201/9781315139470-8, DOI 10.1201/9781315139470]
   Chen X, 2021, Wiley StatsRef: Statistics Reference Online, P1, DOI [10.1002/9781118445112.stat08298, DOI 10.1002/9781118445112.STAT08298]
   Chen XY, 2014, STAT SINICA, V24, P1655, DOI 10.5705/ss.2013.088
   Cho W, 2017, Spatial Big Data Analysis System for Vehicle-Driving GPS Trajectory, P296, DOI [10.1007/978-981-10-5041-1_50, DOI 10.1007/978-981-10-5041-1_50]
   Choi TM, 2017, IEEE T CYBERNETICS, V47, P81, DOI 10.1109/TCYB.2015.2507599
   Dean J, 2004, OSDI, P137
   Dewitt D. J., 1986, Proceedings of Very Large Data Bases. Twelfth International Conference on Very Large Data Bases, P228
   Djouzi K, 2022, J COMPUT SCI-NETH, V61, DOI 10.1016/j.jocs.2022.101653
   Emara TZ, 2020, IEEE ACCESS, V8, P178526, DOI 10.1109/ACCESS.2020.3027675
   Emara TZ, 2019, J SYST SOFTWARE, V148, P105, DOI 10.1016/j.jss.2018.11.007
   Fernández A, 2017, COMPLEX INTELL SYST, V3, P105, DOI 10.1007/s40747-017-0037-9
   Hadoop, 2022, Apache Hadoop
   HOWARD JH, 1988, ACM T COMPUT SYST, V6, P51, DOI 10.1145/35037.35059
   Huang Weixin, 2022, Archit Intell, V1, P7, DOI 10.1007/s44223-022-00011-y
   Khan Mansoor, 2020, 2020 IEEE 8th International Conference on Photonics (ICP), P1, DOI 10.1109/ICP46580.2020.9206421
   Landset S., 2015, Journal of Big Data, V2, P1, DOI DOI 10.1186/S40537-015-0032-1
   Mahmud MS, 2023, IEEE T BIG DATA, V9, P1142, DOI 10.1109/TBDATA.2023.3255003
   Mahmud MS, 2023, J BIG DATA-GER, V10, DOI 10.1186/s40537-023-00709-4
   Mostajabi F, 2021, IEEE ACCESS, V9, P128889, DOI 10.1109/ACCESS.2021.3112880
   Qin WC, 2021, SOFT COMPUT, V25, P7119, DOI 10.1007/s00500-021-05671-y
   Rodrigues AP, 2022, EVOL INTELL, V15, P877, DOI 10.1007/s12065-019-00236-3
   Sabzevari M, 2022, INT J MACH LEARN CYB, V13, P551, DOI 10.1007/s13042-021-01442-1
   Salloum S, 2019, IEEE T IND INFORM, V15, P5846, DOI 10.1109/TII.2019.2912723
   Schapire RE, 2003, LECT NOTES STAT, V171, P149, DOI 10.1007/978-0-387-21579-2_9
   Shayaa S, 2018, IEEE ACCESS, V6, P37807, DOI 10.1109/ACCESS.2018.2851311
   SHEMER J, 1984, COMPUTER, V17, P42, DOI 10.1109/MC.1984.1658999
   Shvachko K., 2010, 2010 IEEE 26th Symposium on Mass Storage Systems and Technologies (MSST), P1
   Spark, 2022, ABOUT US
   Tang SJ, 2022, IEEE T KNOWL DATA EN, V34, P71, DOI 10.1109/TKDE.2020.2975652
   Trinh T, 2022, Lecture Notes on Data Engineering and Communications Technologies, V124, P253, DOI [10.1007/978-3-030-97610-1_21, DOI 10.1007/978-3-030-97610-1_21]
   Trinh T, 2021, MULTIMED TOOLS APPL, V80, P16599, DOI 10.1007/s11042-020-08884-9
   Wu ZM, 2017, IEEE INT C COMPUT, P531, DOI 10.1109/CSE-EUC.2017.99
   Zaharia M, 2016, COMMUN ACM, V59, P56, DOI 10.1145/2934664
   Zaharia Zaharia M. M., Login: The Usenix Magazine, V37 37, P45
NR 37
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26663
EP 26685
DI 10.1007/s11042-023-16624-y
EA SEP 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001057641700001
DA 2024-07-18
ER

PT J
AU Estevam, V
   Laroca, R
   Pedrini, H
   Menotti, D
AF Estevam, Valter
   Laroca, Rayson
   Pedrini, Helio
   Menotti, David
TI Tell me what you see: A zero-shot action recognition method based on
   natural language descriptions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-dataset learning; Paraphrase estimation; Video captioning;
   Zero-shot learning
AB This paper presents a novel approach to Zero-Shot Action Recognition. Recent works have explored the detection and classification of objects to obtain semantic information from videos with remarkable performance. Inspired by them, we propose using video captioning methods to extract semantic information about objects, scenes, humans, and their relationships. To the best of our knowledge, this is the first work to represent both videos and labels with descriptive sentences. More specifically, we represent videos using sentences generated via video captioning methods and classes using sentences extracted from documents acquired through search engines on the Internet. Using these representations, we build a shared semantic space employing BERT-based embedders pre-trained in the paraphrasing task on multiple text datasets. The projection of both visual and semantic information onto this space is straightforward, as they are sentences, enabling classification using the nearest neighbor rule. We demonstrate that representing videos and labels with sentences alleviates the domain adaptation problem. Additionally, we show that word vectors are unsuitable for building the semantic embedding space of our descriptions. Our method outperforms the state-of-the-art performance on the UCF101 dataset by 3.3 p.p. in accuracy under the TruZe protocol and achieves competitive results on both the UCF101 and HMDB51 datasets under the conventional protocol (0/50% - training/testing split). Our code is available at https://github.com/valterlej/zsarcap.
C1 [Estevam, Valter] Fed Inst Parana, BR-84500000 Irati, PR, Brazil.
   [Estevam, Valter; Laroca, Rayson; Menotti, David] Univ Fed Parana, Dept Informat, BR-81531970 Curitiba, PR, Brazil.
   [Pedrini, Helio] Univ Estadual Campinas, Inst Comp, BR-13083852 Campinas, SP, Brazil.
C3 Instituto Federal do Parana; Universidade Federal do Parana;
   Universidade Estadual de Campinas
RP Estevam, V (corresponding author), Fed Inst Parana, BR-84500000 Irati, PR, Brazil.; Estevam, V (corresponding author), Univ Fed Parana, Dept Informat, BR-81531970 Curitiba, PR, Brazil.
EM valter.junior@ifpr.edu.br; rblsantos@inf.ufpr.br; helio@ic.unicamp.br;
   menotti@inf.ufpr.br
RI Laroca, Rayson/D-5744-2018; Estevam, Valter/IZE-6853-2023; Menotti,
   David/M-6205-2014
OI Laroca, Rayson/0000-0003-1943-2711; Estevam, Valter/0000-0001-9491-5882;
   Menotti, David/0000-0003-2430-2030
FU Federal Institute of Parana, Federal University of Parana; National
   Council for Scientific and Technological Development (CNPq)
   [304836/2022-2, 308879/2020-1]
FX This work was supported by the Federal Institute of Parana, Federal
   University of Parana and by grants from the National Council for
   Scientific and Technological Development (CNPq) (grant numbers
   304836/2022-2 and 308879/2020-1). The Titan Xp GPU used for this
   research were donated by the NVIDIA Corporation.
CR Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   Banerjee S., 2005, P WORKSHOP INTRINSIC, P65
   Brattoli B, 2020, PROC CVPR IEEE, P4612, DOI 10.1109/CVPR42600.2020.00467
   Bretti C., 2021, BRIT MACHINE VISION, P1
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Carreira J., 2019, ARXIV
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575
   Chen SZ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13618, DOI 10.1109/ICCV48922.2021.01338
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Doshi K., 2022, ARXIV
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Estevam V, 2021, ARXIV PREPRINT ARXIV, P1
   Estevam V, 2021, NEUROCOMPUTING, V439, P159, DOI 10.1016/j.neucom.2021.01.036
   Gao JY, 2019, AAAI CONF ARTIF INTE, P8303
   Gemmeke JF, 2017, INT CONF ACOUST SPEE, P776, DOI 10.1109/ICASSP.2017.7952261
   Ghosh P, 2020, ARXIV PREPRINT ARXIV, P1
   Gowda, 2023, ARXIV
   Gowda SN, 2022, LECT NOTES COMPUT SC, V13680, P187, DOI 10.1007/978-3-031-20044-1_11
   Gowda SN, 2021, GER C PATTERN RECOGN, P1
   Guadarrama S, 2013, IEEE I CONF COMP VIS, P2712, DOI 10.1109/ICCV.2013.337
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Huang KQ, 2022, VISIGRAPP, P623, DOI 10.5220/0010903100003124
   Iashin V., 2020, BMVC
   Iashin V, 2020, IEEE COMPUT SOC CONF, P4117, DOI 10.1109/CVPRW50498.2020.00487
   Jain M, 2015, IEEE I CONF COMP VIS, P4588, DOI 10.1109/ICCV.2015.521
   Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353
   Kerrigan A., 2021, NeurIPS, V34, P25566
   Kim T., 2021, CYTOM PART B-CLIN CY, P1
   Kong Y, 2022, INT J COMPUT VISION, V130, P1366, DOI 10.1007/s11263-022-01594-9
   Krishna R, 2017, IEEE I CONF COMP VIS, P706, DOI 10.1109/ICCV.2017.83
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Lee J, 2021, NEUROCOMPUTING, V448, P313, DOI 10.1016/j.neucom.2021.03.070
   Liu Yinhan, 2019, ARXIV190711692
   Mandal D, 2019, PROC CVPR IEEE, P9977, DOI 10.1109/CVPR.2019.01022
   Mettes P, 2021, INT J COMPUT VISION, V129, P1954, DOI 10.1007/s11263-021-01454-y
   Mettes P, 2017, IEEE I CONF COMP VIS, P4453, DOI 10.1109/ICCV.2017.476
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Mohamed MA, 2012, LECT NOTES COMPUT SC, V7431, P482, DOI 10.1007/978-3-642-33179-4_46
   Pagliardini M., 2018, P C N AM CHAPT ASS C, P528, DOI [10.18653/v1/n18-1049, DOI 10.18653/V1/N18-1049]
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Piergiovanni AJ, 2020, IEEE WINT CONF APPL, P506, DOI [10.1109/wacv45572.2020.9093612, 10.1109/WACV45572.2020.9093612]
   Qin J, 2017, PROC CVPR IEEE, P1042, DOI 10.1109/CVPR.2017.117
   Reimers N, 2019, C EMPIR METHODS NAT
   Reimers N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4512
   Roitberg A, 2019, LECT NOTES COMPUT SC, V11132, P97, DOI 10.1007/978-3-030-11018-5_8
   Romera-Paredes Bernardino, 2015, ICML
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Speer R, 2017, AAAI CONF ARTIF INTE, P4444
   Sun B, 2022, PATTERN RECOGN, V126, DOI 10.1016/j.patcog.2022.108563
   Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang Q, 2017, LECT NOTES ARTIF INT, V10534, P87, DOI 10.1007/978-3-319-71249-9_6
   Wang Q, 2017, INT J COMPUT VISION, V124, P356, DOI 10.1007/s11263-017-1027-5
   Wang YD, 2020, MULTIMED TOOLS APPL, V79, P33689, DOI 10.1007/s11042-019-7689-y
   Wu ZX, 2016, PROC CVPR IEEE, P3112, DOI 10.1109/CVPR.2016.339
   Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581
   Xian YQ, 2016, PROC CVPR IEEE, P69, DOI 10.1109/CVPR.2016.15
   Xie YR, 2020, MULTIMED TOOLS APPL, V79, P27321, DOI 10.1007/s11042-020-09316-4
   Xu X, 2016, LECT NOTES COMPUT SC, V9906, P343, DOI 10.1007/978-3-319-46475-6_22
   Xu X, 2015, IEEE IMAGE PROC, P63, DOI 10.1109/ICIP.2015.7350760
   Zhang BW, 2018, LECT NOTES COMPUT SC, V11217, P385, DOI 10.1007/978-3-030-01261-8_23
   Zhu Y, 2018, PROC CVPR IEEE, P9436, DOI 10.1109/CVPR.2018.00983
NR 66
TC 0
Z9 0
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 28147
EP 28173
DI 10.1007/s11042-023-16566-5
EA SEP 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001059921400008
DA 2024-07-18
ER

PT J
AU Chen, JM
   Shao, ZC
   Cen, CC
   Li, JQ
AF Chen, Junming
   Shao, Zichun
   Cen, Caichun
   Li, Jiaqi
TI HyNet: A novel hybrid deep learning approach for efficient interior
   design texture retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interior design; Texture retrieval; Hybrid neural networks; Hand-crafted
   features; Deep learned features; Evaluation protocol
ID IMAGE RETRIEVAL; FEATURES; FUSION
AB Interior designers are suffering from a lack of intelligent design methods. This study aims to enhance the accuracy and efficiency of retrieval textures for interior design, which is a crucial step toward intelligent design. Currently, interior designers rely on repetitive tasks to obtain textures from websites, which is ineffective as a interior design often requires hundreds of textures. To address this issue, this study proposes a hybrid deep learning approach, HyNet, which boosts retrieval efficiency by recommending similar textures instead of blindly searching. Additionally, a new indoor texture dataset is created to support the application of artificial intelligence in this field. The results demonstrate that the proposed method's ten recommended images achieve a high accuracy rate of 91.41%. This is a significant improvement in efficiency, which can facilitate the design industry's progression towards intelligence. Overall, this study offers a promising solution to the challenges facing interior designers, and it has the potential to significantly enhance the industry's productivity and innovation.
C1 [Chen, Junming; Shao, Zichun; Cen, Caichun; Li, Jiaqi] Macau Univ Sci & Technol, Fac Humanities & Arts, Ave Wailong, Taipa 999078, Macau, Peoples R China.
C3 Macau University of Science & Technology
RP Li, JQ (corresponding author), Macau Univ Sci & Technol, Fac Humanities & Arts, Ave Wailong, Taipa 999078, Macau, Peoples R China.
EM jmchen@must.edu.mo; jiqli@must.edu.mo
RI li, jiaqi/AAX-6745-2020; shao, zichun/JJE-5514-2023; Chen,
   Junming/JGM-2773-2023
OI li, jiaqi/0000-0001-6076-4350; Chen, Junming/0000-0001-6406-0924; Shao,
   Zichun/0000-0002-7718-2792
FU Research Fund of Macao University of Science and Technology (FRG-MUST);
   National Social Science Foundation of China Key Project of Art Science
   [20AC003];  [FRG-23-021-FA]
FX This research work were funded by the project FRG-23-021-FA and granted
   by the Research Fund of Macao University of Science and Technology
   (FRG-MUST) and National Social Science Foundation of China Key Project
   of Art Science "Research on Chinese Animation Creation and a Theoretical
   Innovation under the Construction of National Cultural Image" (Grant No.
   20AC003).
CR Ahmed KT, 2019, INFORM FUSION, V51, P76, DOI 10.1016/j.inffus.2018.11.004
   Alzu'bi A, 2017, NEUROCOMPUTING, V249, P95, DOI 10.1016/j.neucom.2017.03.072
   [Anonymous], 2016, J Comput Sci, DOI DOI 10.3844/JCSSP.2016.213.222
   Arun KS, 2018, DATA SCI ENG, V3, P166, DOI 10.1007/s41019-018-0063-7
   Ayadi W, 2019, BIOMED SIGNAL PROCES, V48, P144, DOI 10.1016/j.bspc.2018.10.010
   Ayyachamy S, 2019, PROC SPIE, V10954, DOI 10.1117/12.2515588
   Deng YB, 2017, IEEE SIGNAL PROC MAG, V34, P80, DOI 10.1109/MSP.2017.2696576
   Desai P., 2021, SN Comput Sci, V2, P170, DOI [10.1007/s42979-021-00529-4, DOI 10.1007/S42979-021-00529-4]
   Devulapalli Sudheer, 2023, Materials Today: Proceedings, P983, DOI 10.1016/j.matpr.2021.04.326
   Fei Shen, 2019, 2019 IEEE 4th International Conference on Image, Vision and Computing (ICIVC), P247, DOI 10.1109/ICIVC47709.2019.8981065
   Fu H, 2021, INT J COMPUT VISION, V129, P3313, DOI 10.1007/s11263-021-01534-z
   Georgiou T, 2020, INT J MULTIMED INF R, V9, P135, DOI 10.1007/s13735-019-00183-w
   Gharaei NY, 2021, 2021 26TH INTERNATIONAL COMPUTER CONFERENCE, COMPUTER SOCIETY OF IRAN (CSICC), DOI 10.1109/CSICC52343.2021.9420544
   Ha I, 2018, BUILD ENVIRON, V140, P23, DOI 10.1016/j.buildenv.2018.05.026
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ho Y, 2020, IEEE ACCESS, V8, P4806, DOI 10.1109/ACCESS.2019.2962617
   Hong SA, 2023, MULTIMED TOOLS APPL, V82, P30807, DOI 10.1007/s11042-023-14748-9
   Hongtao Yang, 2019, 2019 IEEE/ACIS 18th International Conference on Computer and Information Science (ICIS). Proceedings, P294
   Kale M, 2022, MULTIMED TOOLS APPL, V81, P37263, DOI 10.1007/s11042-022-13529-0
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Kriznar A, 2012, ACTA ARTIS ACADEMICA 2012: KNOWLEDGE AND EXPERIENCE IN THE FINE ART, P25
   Lee JoonHyub., 2021, P S VLSI CIRC KYOT J, P1, DOI [DOI 10.23919/VLSICIRCUITS52068.2021.9492444, 10.23919/VLSICircuits 52068.2021.9492444]
   Li M, 2022, C INT C IMAGE PROCES, DOI [10.1109/ICIP46576.2022.9897943, DOI 10.1109/ICIP46576.2022.9897943]
   Li MY, 2022, IEEE IMAGE PROC, P1816, DOI 10.1109/ICIP46576.2022.9897943
   Liu B, 2019, ARXIV, DOI DOI 10.48550/ARXIV.1911.09299
   Liu XC, 2016, LECT NOTES COMPUT SC, V9906, P869, DOI 10.1007/978-3-319-46475-6_53
   Liu Y, 2019, WORLD WIDE WEB, V22, P1313, DOI 10.1007/s11280-018-0585-y
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Majhi M, 2021, MULTIMED TOOLS APPL, V80, P7271, DOI 10.1007/s11042-020-10005-5
   Mehmood Z, 2018, ARAB J SCI ENG, V43, P7265, DOI 10.1007/s13369-018-3062-0
   Mengke Jiang, 2019, 2019 IEEE 4th International Conference on Image, Vision and Computing (ICIVC), P460, DOI 10.1109/ICIVC47709.2019.8980977
   O'Mahony N, 2020, ADV INTELL SYST COMP, V943, P128, DOI 10.1007/978-3-030-17795-9_10
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Qiao C., 2022, 2022 IEEE 34 INT C T, ppp804
   Shen F, 2023, ARXIV, DOI DOI 10.48550/ARXIV.2301.09498
   Shen F., 2022, 2022 IEEE INT C MULT, P1, DOI DOI 10.1109/ICME52920.2022.9859883
   Shen F., 2023, P 31 ACM INT C MULT
   Shen F, 2023, IEEE T IMAGE PROCESS, V32, P1039, DOI 10.1109/TIP.2023.3238642
   Shen F, 2022, IEEE INTERNET THINGS, V9, P9049, DOI 10.1109/JIOT.2021.3119525
   Shen F, 2022, IEEE T INTELL TRANSP, V23, P8793, DOI 10.1109/TITS.2021.3086142
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang HB, 2022, MULTIMED TOOLS APPL, V81, P14081, DOI 10.1007/s11042-022-12449-3
   Wang ZG, 2022, P I MECH ENG D-J AUT, V236, P1607, DOI 10.1177/09544070211036311
   Wu S., 2016, P IEEE WINT C APPL C, P1, DOI [DOI 10.1080/10298436.2016.1248204, DOI 10.1109/WACV.2016.7477681]
   Xiong ZG, 2021, J SIGNAL PROCESS SYS, V93, P139, DOI 10.1007/s11265-019-01508-y
   Yan K, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P407, DOI 10.1145/2964284.2967252
   Yuan ZW, 2016, PROC SPIE, V10033, DOI 10.1117/12.2243849
   Zakira J, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9243162
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhong Z, 2017, P IEEE C COMP VIS PA, ppp1318, DOI [10.48550/arXiv.1701.08398, DOI 10.48550/ARXIV.1701.08398]
   Zhu B, 2021, PATTERN RECOGN LETT, V150, P94, DOI 10.1016/j.patrec.2021.06.031
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
   Zhuo W, 2022, MULTIMED TOOLS APPL, V81, P41527, DOI 10.1007/s11042-020-10499-z
NR 53
TC 2
Z9 2
U1 8
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 28125
EP 28145
DI 10.1007/s11042-023-16579-0
EA AUG 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001062556300013
OA hybrid
DA 2024-07-18
ER

PT J
AU Balakrishnan, S
   Kumar, KS
   Janet, J
   Babu, DV
   Lora, CP
AF Balakrishnan, S.
   Kumar, K. Suresh
   Janet, J.
   Babu, D. Vijendra
   Lora, Chandra Prakash
TI An emergence of technological aids using machine learning algorithms to
   curtail the mounting manifestation of dyspraxia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dyspraxia; Coordination disorder; Machine learning; Modified random
   forest
ID DEVELOPMENTAL COORDINATION DISORDER; CHILDREN; QUALITY; AUTISM; MOTOR
AB Dyslexia and Dyspraxia are prevalent learning disabilities that significantly impact individuals' abilities to read, write, and coordinate movements. Over the years, researchers have developed cognitive models to understand the underlying deficits in both conditions. Dyspraxia, categorized under Developmental Coordination Disorder (DCD), is particularly challenging as motor complications often persist from childhood into adulthood, affecting an individual's daily functioning. However, existing studies have predominantly focused on the perspectives of experts and parents, neglecting the valuable insights of affected teenagers. In India, Dyspraxia is still an emerging concern, with limited resources and infrastructures available for these special children. Additionally, Dyslexia affects approximately 15% of the population in the country, leading to significant learning difficulties. This research aims to harness technological advancements to address these challenges and empower individuals to cope with the demands of today's materialistic world. The proposed system targets various stakeholders, including parents, special school trainers, physiotherapists, occupational therapists, medical doctors, orthoptists, and speech and language therapists. A key feature of this system is the utilization of a modified Random Forest (RF) algorithm. This advanced machine learning approach plays a pivotal role in allocating characteristic significance and minimizing amplitude, enhancing the accuracy, precision, and recall of the algorithm to 78%, 0.85, and 0.71, respectively. By leveraging cutting-edge technology and machine learning techniques, this research endeavors to pave the way for improved understanding, early intervention, and customized support for individuals with Dyslexia and Dyspraxia in India. These technological aids hold the potential to positively impact the lives of those affected, facilitating better integration and enhanced quality of life in the face of these learning disabilities.
C1 [Balakrishnan, S.] Sri Krishna Coll Engn & Technol, Dept Comp Sci & Business Syst, Coimbatore, Tamil Nadu, India.
   [Kumar, K. Suresh] Saveetha Engn Coll, Dept Informat Technol, Chennai, Tamil Nadu, India.
   [Janet, J.] Sri Krishna Coll Engn & Technol, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
   [Babu, D. Vijendra] Vellore Inst Technol, Sch Elect Engn, Vellore, Tamil Nadu, India.
   [Lora, Chandra Prakash] Vivekananda Global Univ, Fac Basic & Appl Sci, Jaipur, Rajasthan, India.
C3 Sri Krishna College of Engineering & Technology; Sri Krishna College of
   Engineering & Technology; Vellore Institute of Technology (VIT); VIT
   Vellore; Vivekananda Global University
RP Balakrishnan, S (corresponding author), Sri Krishna Coll Engn & Technol, Dept Comp Sci & Business Syst, Coimbatore, Tamil Nadu, India.
EM balaktishnans@skcet.ac.in
RI K, Suresh Kumar/AAZ-7598-2021; D, Vijendra Babu/ABD-7722-2020
OI K, Suresh Kumar/0000-0002-3912-3687; D, Vijendra
   Babu/0000-0001-9925-979X; K, Suresh Kumar/0000-0002-0673-3331
CR Ahmed ST, 2022, MALAYS J COMPUT SCI, P53, DOI 10.22452/mjcs.sp2022no2.5
   Ahmed SST, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING TECHNOLOGIES AND INTELLIGENT DATA ENGINEERING (ICCTIDE'16)
   Bostan AC, 2013, TRENDS COGN SCI, V17, P241, DOI 10.1016/j.tics.2013.03.003
   COURCHESNE E, 1994, LANCET, V343, P63, DOI 10.1016/S0140-6736(94)90923-7
   Dewey Deborah, 2001, Physical and Occupational Therapy in Pediatrics, V20, P5, DOI 10.1300/J006v20n02_02
   Dhote SN., 2017, Int J Pharma Bio Sci, V8, pB222, DOI [10.22376/ijpbs.2017.8.3.b222-229, DOI 10.22376/IJPBS.2017.8.3.B222-229]
   Dixon W., 1990, BMDP Statistical Software Manual, P1
   Dyspraxia Foundation, 2014, So what is going on in the brain?
   Dziuk MA, 2007, DEV MED CHILD NEUROL, V49, P734, DOI 10.1111/j.1469-8749.2007.00734.x
   Fallang B, 2005, PEDIATR RES, V58, P347, DOI 10.1203/01.PDR.0000170898.60160.09
   Gibbs J, 2007, ARCH DIS CHILD, V92, P534, DOI 10.1136/adc.2005.088054
   Guptha NS, 2022, PATTERN RECOGN LETT, V159, P16, DOI 10.1016/j.patrec.2022.04.038
   Guptha NS, 2017, INT J SIGNAL IMAGING, V10, P39, DOI 10.1504/IJSISE.2017.084568
   Guptha NS., 2018, INT J INTELL ENG SYS, V11, P256, DOI [10.22266/ijies2018.0430.28, DOI 10.22266/IJIES2018.0430.28]
   HENDERSON L, 1992, J CHILD PSYCHOL PSYC, V33, P895, DOI 10.1111/j.1469-7610.1992.tb01963.x
   Just MA, 2007, CEREB CORTEX, V17, P951, DOI 10.1093/cercor/bhl006
   Kamalalochana S., 2019, INT J ENG ADV TECHNO, V8, P244, DOI DOI 10.35940/IJEAT.E1049.0585S19
   Karthick S, 2019, CURR MED IMAGING, V15, P911, DOI 10.2174/1573405614666180905094032
   Kirby A, 2010, J RES SPEC EDUC NEED, V10, P206, DOI 10.1111/j.1471-3802.2010.01158.x
   Lewis JD, 2013, HUM BRAIN MAPP, V34, P1685, DOI 10.1002/hbm.22018
   Molino P, 2022, COMMUN ACM, V65, P42, DOI 10.1145/3475167
   Nirmala SG., 2014, International Journal of Computer Networking, V4, P65
   Praveena HD, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/3297316
   Sankar G, 2011, Indian Journal of Physiotherapy and Occupational Therapy-An International Journal, V5, P63
   SCHOEMAKER MM, 1994, ADAPT PHYS ACT Q, V11, P130, DOI 10.1123/apaq.11.2.130
   Shriberg LD, 2003, CLIN LINGUIST PHONET, V17, P575, DOI 10.1080/0269920031000138141
   Stateczny A, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15082015
   Steinman KJ, 2010, J CHILD NEUROL, V25, P71, DOI 10.1177/0883073809342591
   Sundari SLK., 2019, INT J ENG ADV TECHNO, V8, P214, DOI DOI 10.35940/IJEAT.E1044.0585S19
   Weimer AK, 2001, J DEV BEHAV PEDIATR, V22, P92, DOI 10.1097/00004703-200104000-00002
NR 30
TC 0
Z9 0
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26089
EP 26105
DI 10.1007/s11042-023-16464-w
EA AUG 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060295500001
DA 2024-07-18
ER

PT J
AU Shereena, VB
   Raju, G
AF Shereena, V. B.
   Raju, G.
TI Medical ultrasound image segmentation using Multi-Residual U-Net
   architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ultrasound image Segmentation; Non-Local Means; Convolutional Neural
   Networks; Multi-Residual U-Net
ID TUMOR SEGMENTATION; ALGORITHM
AB Advances in medical imaging modalities facilitate the early and accurate detection of tumors of various types. A preferred imaging modality for diagnosis and identification of tumors is the B-mode ultrasound imaging, but due to the noise and artifacts present, correct interpretation of lesions region becomes a difficult task for an inexperienced radiologist. In this context, an efficient and reliable computer-aided segmentation system is preferred for extracting regions of interest. Recently, conventional methods of segmentation have been replaced by deep learning methods. In this article, a novel Multi-Residual U-Net model is proposed for the segmentation of ultrasound medical images. This architecture adopts residual blocks to improve the performance of deep convolutional networks and a loss function that addresses the class imbalance issue. To improve the quality and reduce Speckle noise, input images are pre-processed using an optimized Non-Local Means filter. Three benchmark B-mode Ultrasound image datasets of 200 Breast lesion images, 504 Skeletal images, and 647 Breast Lesion images are used for experimentation. Experimental results demonstrate that the proposed model performs more accurate segmentation in comparison to the five deep models chosen for the study.
C1 [Shereena, V. B.] MES Coll Marampally, Dept Comp Applicat, Kochi, Kerala, India.
   [Raju, G.] Alliance Univ, Dept Comp Sci & Engn, Bengaluru, India.
C3 Alliance University
RP Raju, G (corresponding author), Alliance Univ, Dept Comp Sci & Engn, Bengaluru, India.
EM shereenavb@gmail.com; kurupgraju@gmail.com
RI Kurup, Raju/T-9795-2019
OI Kurup, Raju/0000-0002-7871-1801
CR Abraham N, 2019, I S BIOMED IMAGING, P683, DOI 10.1109/ISBI.2019.8759329
   ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   Al-Dhabyani W, 2020, DATA BRIEF, V28, DOI 10.1016/j.dib.2019.104863
   Almajalid R, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P1103, DOI 10.1109/ICMLA.2018.00179
   Azad R, 2019, arXiv, DOI [DOI 10.48550/ARXIV.1909.00166, 10.48550/arXiv.1909.00166]
   Cao ZT, 2019, BMC MED IMAGING, V19, DOI 10.1186/s12880-019-0349-x
   Chan V, 2011, ATLAS OF ULTRASOUND-GUIDED PROCEDURES IN INTERVENTIONAL PAIN MANAGEMENT, P13, DOI 10.1007/978-1-4419-1681-5_2
   Chen XH, 2017, IET IMAGE PROCESS, V11, P860, DOI 10.1049/iet-ipr.2016.1070
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   CLARKE LP, 1995, MAGN RESON IMAGING, V13, P343, DOI 10.1016/0730-725X(94)00124-L
   Cunningham R, 2018, J IMAGING, V4, DOI 10.3390/jimaging4020029
   Dhanachandra N, 2015, PROCEDIA COMPUT SCI, V54, P764, DOI 10.1016/j.procs.2015.06.090
   Dokur Z, 2002, PATTERN RECOGN LETT, V23, P1825, DOI 10.1016/S0167-8655(02)00155-1
   Fourcade A, 2019, J STOMATOL ORAL MAXI, V120, P279, DOI 10.1016/j.jormas.2019.06.002
   Ghosh D, 2020, 2020 IEEE CALCUTTA CONFERENCE (CALCON), P318, DOI [10.1109/calcon49167.2020.9106568, 10.1109/CALCON49167.2020.9106568]
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Guo YJ, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0253202
   Han B, 2019, PATTERN RECOGN, V88, P715, DOI 10.1016/j.patcog.2018.12.028
   Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Isunuri BV, 2020, AUTOMATIKA-UK, V61, P352, DOI 10.1080/00051144.2020.1760590
   Jain N, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0623-1
   Kaltenbach TEM, 2016, ABDOM RADIOL, V41, P25, DOI 10.1007/s00261-015-0605-7
   Kerkeni A, 2016, COMPUT MED IMAG GRAP, V48, P49, DOI 10.1016/j.compmedimag.2015.12.004
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar D, 2019, MULTIMED TOOLS APPL, V78, P12663, DOI 10.1007/s11042-018-5954-0
   Kumar SN, 2018, BIOMED RES-TOKYO, pS75, DOI [10.4066/biomedicalresearch.29-16-1785, DOI 10.4066/BIOMEDICALRESEARCH.29-16-1785]
   Lee WL, 2013, APPL SOFT COMPUT, V13, P3683, DOI 10.1016/j.asoc.2013.03.009
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu GQ, 2018, J ELECTR COMPUT ENG, V2018, DOI 10.1155/2018/3493070
   Liu SF, 2019, ENGINEERING-PRC, V5, P261, DOI 10.1016/j.eng.2018.11.020
   Mehnert A, 1997, PATTERN RECOGN LETT, V18, P1065, DOI 10.1016/S0167-8655(97)00131-1
   Mishra D, 2019, IEEE T BIO-MED ENG, V66, P1637, DOI 10.1109/TBME.2018.2877577
   Piotrzkowska-Wróblewska H, 2017, MED PHYS, V44, P6105, DOI 10.1002/mp.12538
   Refaeilzadeh P, 2009, NARROWED EXTENDED XP, DOI [10.1007/978-0-387-39940-9_565, DOI 10.1007/978-0-387-39940-9_242, 10.1007/978-0-387-39940-9]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruan S, 2007, I S BIOMED IMAGING, P1236, DOI 10.1109/ISBI.2007.357082
   Santoro GA., 2004, Basic Principles of ultrasonography, DOI [10.1007/978-88-470-2129-7, DOI 10.1007/978-88-470-2129-7]
   Schindelin J, 2015, MOL REPROD DEV, V82, P518, DOI 10.1002/mrd.22489
   Shereena V.B., 2021, 2 C INT SYST CIS 202
   Sokolova M, 2006, LECT NOTES COMPUT SC, V4304, P1015
   Taha AA, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0068-x
   Targ S., 2016, ARXIV, DOI DOI 10.48550/ARXIV.1603.08029
   Thakur A., 2007, World Academy of Science, Engineering and Technology Int J Medical and Health Sciences, V1, P564
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Wang CM, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/290607
   Wu ZF, 2019, PATTERN RECOGN, V90, P119, DOI 10.1016/j.patcog.2019.01.006
   Yuan J., 2017, Advances in Intelligent Systems Research, DOI [10.2991/msam-17.2017.23, DOI 10.2991/MSAM-17.2017.23]
   Zheng YH, 2022, MULTIMED TOOLS APPL, V81, P13253, DOI 10.1007/s11042-021-10939-4
   Zhuang ZM, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0221535
NR 51
TC 0
Z9 1
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27067
EP 27088
DI 10.1007/s11042-023-16461-z
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001064537600002
DA 2024-07-18
ER

PT J
AU Baradaran, M
   Bergevin, R
AF Baradaran, Mohammad
   Bergevin, Robert
TI A critical study on the recent deep learning based semi-supervised video
   anomaly detection methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video anomaly detection; Spatio-temporal feature extraction; Deep
   learning; Semi-supervised; Proxy-task
ID EVENT DETECTION; LOCALIZATION; NETWORKS
AB Video anomaly detection (VAD) is currently a trending research area within computer vision, given that anomalies form a key detection objective in surveillance systems, often requiring immediate responses. The primary challenges associated with video anomaly detection tasks stem from the scarcity of anomaly samples and the context-dependent nature of anomaly definitions. In light of the limited availability of labeled data for training (specifically, a shortage of labeled data for abnormalities), there has been a growing interest in semi-supervised anomaly detection methods. These techniques work by identifying anomalies through the detection of deviations from normal patterns. This paper provides a new perspective to researchers in the field, by categorizing semi-supervised VAD methods according to the proxy task type they employ to model normal data and consequently to detect anomalies. It also reviews recent deep learning based semi-supervised VAD methods, emphasizing their common tactic of slightly overfitting their models on normal data using a proxy task to detect anomalies. Our goal is to help researchers develop more effective video anomaly detection methods. As the selection of a right Deep Neural Network (DNN) plays an important role in several parts of this task, a quick comparative review on DNNs is also included. Unlike previous surveys, DNNs are reviewed from a spatiotemporal feature extraction viewpoint, customized for video anomaly detection. This part of the review can help researchers select suitable networks for different parts of their methods. The review provides a novel and deep look at existing methods and results in stating the shortcomings of these approaches, which can be a hint for future works.
C1 [Baradaran, Mohammad; Bergevin, Robert] Univ Laval, Dept Elect & Comp Engn, 1065 Ave Medecine, Quebec City, PQ G1V 0A6, Canada.
C3 Laval University
RP Baradaran, M (corresponding author), Univ Laval, Dept Elect & Comp Engn, 1065 Ave Medecine, Quebec City, PQ G1V 0A6, Canada.
EM mohammad.baradaran.1@ulaval.ca; robert.bergevin@gel.ulaval.ca
OI Baradaran, Mohammad/0000-0003-0246-4370
FU National Sciences and Engineering Research Council of Canada (NSERC)
   [RGPIN-2016-05876]
FX AcknowledgementsThis work was supported by a Discovery Grant
   (RGPIN-2016-05876) from the National Sciences and Engineering Research
   Council of Canada (NSERC). Additionally, we would like to thank Annette
   Schwerdtfeger for proofreading the paper.
CR Abati D, 2019, PROC CVPR IEEE, P481, DOI 10.1109/CVPR.2019.00057
   Aburakhia Sulaiman, 2020, 2020 11th IEEE Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON), P0055, DOI 10.1109/IEMCON51383.2020.9284916
   Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Akçay S, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8851808
   Akcay S, 2019, LECT NOTES COMPUT SC, V11363, P622, DOI 10.1007/978-3-030-20893-6_39
   Alaslani Maram G., 2018, International Journal of Computer Science & Information Technology, V10, P65, DOI 10.5121/ijcsit.2018.10206
   Alkhayrat M, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-0286-0
   [Anonymous], 2021, UN CROWD ACT DAT U M
   [Anonymous], 2015, SIIM ACR PNEUM SEGM
   Arif S, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11020042
   Baradaran M, 2023, CVPRW VAND
   Baradaran M, 2022, 2022 19TH CONFERENCE ON ROBOTS AND VISION (CRV 2022), P90, DOI 10.1109/CRV55824.2022.00020
   Baur C, 2018, BRAINLESION GLIOMA M, V11383
   Bergmann P, 2020, PROC CVPR IEEE, P4182, DOI 10.1109/CVPR42600.2020.00424
   Biradar KM, 2019, IEEE COMPUTER VISION
   Bulusu S, 2020, IEEE ACCESS, V8, P132330, DOI 10.1109/ACCESS.2020.3010274
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chang XY, 2022, J VIS COMMUN IMAGE R, V87, DOI 10.1016/j.jvcir.2022.103547
   Chen C., 2020, ARXIV
   Chen DY, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103915
   Chen YP, 2018, LECT NOTES COMPUT SC, V11205, P364, DOI 10.1007/978-3-030-01246-5_22
   Chong YS., 2017, Advances in Neural Networks - ISNN 2017, V10262
   Chung J., 2014, NIPS 2014 WORKSH DEE, Vabs/1412.3555, P1, DOI DOI 10.48550/ARXIV.1412.3555
   Cinelli LP., 2017, 35 S BRAS TEL PROC S, DOI [10.14209/sbrt.2017.74, DOI 10.14209/SBRT.2017.74]
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Di MF, 2019, ARXIV
   Djuris J., 2013, COMPUTER AIDED APPL, DOI [10.1533/9781908818324.91, DOI 10.1533/9781908818324.91]
   Donahue J., 2017, ICLR, P1, DOI DOI 10.48550/ARXIV.1605.09782
   Doshi K, 2020, IEEE COMPUT SOC CONF, P4037, DOI 10.1109/CVPRW50498.2020.00475
   Dosovitskiy Alexey, 2021, ICLR
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Duman E, 2019, IEEE ACCESS, V7, P183914, DOI 10.1109/ACCESS.2019.2960654
   Dzmitry B, 2015, ICLR2015
   Fan Y, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2993148.2997632
   Fang ZW, 2021, IEEE T MULTIMEDIA, V23, P4106, DOI 10.1109/TMM.2020.3037538
   Feichtenhofer C., 2016, ADV NEURAL INFORM PR, P3468
   Feichtenhofer C, 2020, INT J COMPUT VISION, V128, P420, DOI 10.1007/s11263-019-01225-w
   Ganokratanaa T, 2020, IEEE ACCESS, V8, P50312, DOI 10.1109/ACCESS.2020.2979869
   Georgescu MI, 2021, PROC CVPR IEEE, P12737, DOI 10.1109/CVPR46437.2021.01255
   Getoor, 2011, P 28 INT C MACH LEAR, P833
   Gherbi E., 2019, PROC MACH LEARN RES, V101, P188
   Gondara L, 2016, INT CONF DAT MIN WOR, P241, DOI [10.1109/ICDMW.2016.102, 10.1109/ICDMW.2016.0041]
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hinami R, 2017, IEEE I CONF COMP VIS, P3639, DOI 10.1109/ICCV.2017.391
   Ho K., 2020, ARXIV
   Houssam Z, 2018, ARXIV
   Ionescu RT, 2019, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2019.00803
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   Kanojia G, 2019, COMPUTER VISION PATT, V1249, DOI [10.1007/978-981-15-8697-2-10, DOI 10.1007/978-981-15-8697-2-10]
   Khan A., 2019, arXiv
   Kimura M., 2018, COMPUTER VISION ACCV
   Kiran BR, 2018, J IMAGING, V4, DOI 10.3390/jimaging4020036
   Kurkova V, 2018, ICANN 2018 27 INT C
   Le Xuan-Hien., 2019, APPL LONG SHORT TERM
   Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295
   Lee J., 2022, arXiv
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Li ZY, 2020, IEEE ACCESS, V8, P25531, DOI 10.1109/ACCESS.2020.2970497
   Lis K, 2019, IEEE I CONF COMP VIS, P2152, DOI 10.1109/ICCV.2019.00224
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Liu ZA, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13568, DOI 10.1109/ICCV48922.2021.01333
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu YW, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2019.8909850
   Luo WX, 2022, IEEE T PATTERN ANAL, V44, P7505, DOI 10.1109/TPAMI.2021.3129349
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   Luong T., 2015, P 2015 C EMP METH NA, DOI [DOI 10.18653/V1/D15-1166, 10.18653/v1/D15-1166]
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Medel J. R., 2016, Anomaly detection in video using predictive convolutional long short-term memory networks
   Metais E, 2019, 24 INT C APPL NAT LA
   Minderer Matthias, 2019, NEURIPS, P2
   Morais R, 2019, PROC CVPR IEEE, P11988, DOI 10.1109/CVPR.2019.01227
   Narasimhan MG, 2018, MULTIMED TOOLS APPL, V77, P13173, DOI 10.1007/s11042-017-4940-2
   Nazare TS, 2018, ARXIV
   Park Hyunjong, 2020, IEEECVF C COMPUTER V, P2
   Pascanu R., 2013, INT C MACH LEARN, P1310
   Pathak D, 2017, PROC CVPR IEEE, P6024, DOI 10.1109/CVPR.2017.638
   Pihlgren GG, 2020, IMPROVING IMAGE AUTO
   Pinggera P, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1099, DOI 10.1109/IROS.2016.7759186
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Raghavendra C, 2019, ARXIV
   Ramachandra B, 2022, IEEE T PATTERN ANAL, V44, P2293, DOI 10.1109/TPAMI.2020.3040591
   Ramachandra B, 2020, IEEE WINT CONF APPL, P2558, DOI [10.1109/WACV45572.2020.9093457, 10.1109/wacv45572.2020.9093457]
   Ramaswamy A, 2020, CVPR WORKSH
   Rani BJB, 2020, INT CONF COMP COMMUN, P544, DOI 10.1109/iccci48352.2020.9104046
   Ravanbakhsh M, 2017, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2017.8296547
   Reiter W, 2020, BILDVERARBEITUNG MED
   Ren J, 2021, INT CONF DAT MIN WOR, P959, DOI 10.1109/ICDMW53433.2021.00125
   Ribeiro M, 2018, PATTERN RECOGN LETT, V105, P13, DOI 10.1016/j.patrec.2017.07.016
   Ristea NC, 2022, PROC CVPR IEEE, P13566, DOI 10.1109/CVPR52688.2022.01321
   Roka S, 2023, J ELECTRON IMAGING, V32, DOI 10.1117/1.JEI.32.4.042106
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy PR, 2020, 1 INT WORKSHOP DEEP
   Sabokrou M, 2018, LECT NOTES COMPUTER, V11366
   Sabokrou M, 2018, PROC CVPR IEEE, P3379, DOI 10.1109/CVPR.2018.00356
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Sellat H, 2019, ANOMALY DETECTION VI
   Sengupta S, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105596
   Shafkat I, 2019, INTUITIVELY UNDERSTA
   Shen GD, 2022, INT CONF ACOUST SPEE, P3728, DOI 10.1109/ICASSP43922.2022.9747376
   Shibin P, 2016, P SPIE, V9844
   Shine L., 2019, IEEE C COMPUTER VISI, P306
   Simonyan K, 2014, ADV NEUR IN, V27
   Singh H., 2019, THESIS U NEVADA RENO
   Smys S, 2019, COMPUTATIONAL VISION, V1108
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Tuan TX, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P138, DOI 10.1145/3109859.3109900
   Nguyen TN, 2019, IEEE I CONF COMP VIS, P1273, DOI 10.1109/ICCV.2019.00136
   Tuan HV., 2020, IMAGING COMPUT GRAPH, V5, P484, DOI [10.5220/0009146704840490, DOI 10.5220/0009146704840490]
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang BK, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22124647
   Wang L, 2018, IEEE IMAGE PROC, P2276, DOI 10.1109/ICIP.2018.8451070
   Wang SZ, 2022, IEEE T KNOWL DATA EN, V34, P3681, DOI 10.1109/TKDE.2020.3025580
   Wang YC, 2018, ENERGIES, V11, DOI 10.3390/en11030523
   Wei J, 2018, IEEE COMPUT SOC CONF, P129, DOI 10.1109/CVPRW.2018.00025
   Xu D, 2015, P BRIT MACHINE VISIO, P1
   Xu M, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163337
   Yadav RK, 2022, 2022 IEEE DELHI SECT, P1, DOI [10.1109/DELCON54057.2022.9753580, DOI 10.1109/DELCON54057.2022.9753580]
   Ye MC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1805, DOI 10.1145/3343031.3350899
   Ye W, 2019, IEEE ACCESS, V7, P67772, DOI 10.1109/ACCESS.2019.2918808
   Yiru Z, 2017, ACM MULT C
   Yuan HC, 2021, IEEE ACCESS, V9, P123977, DOI 10.1109/ACCESS.2021.3109102
   Zaheer MZ, 2022, PROC CVPR IEEE, P14724, DOI 10.1109/CVPR52688.2022.01433
   Zenati H, 2018, IEEE DATA MINING, P727, DOI 10.1109/ICDM.2018.00088
   Zhang C., 2020, ARXIV
   Zhang Y, 2021, IEEE T CIRC SYST VID, V31, P3694, DOI 10.1109/TCSVT.2020.3039798
   Zhao J, 2019, CVPR WORKSH
NR 133
TC 1
Z9 1
U1 6
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27761
EP 27807
DI 10.1007/s11042-023-16445-z
EA AUG 2023
PG 47
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001050733600005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Dutta, SB
   Vig, R
AF Dutta, Saloni Bhatia
   Vig, Rekha
TI Performance evaluation of Dictionary Learning and ICA on Parkinson's
   patients classification using Machine Learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE CanICA; Dictionary Learning; Feature Extraction; Functional
   Connectivity; Machine Learning
ID DIFFERENTIAL-DIAGNOSIS; DISEASE; MRI
AB Currently, extensive research is being conducted in the application of Machine Learning (ML) algorithms in the medical domain and one such area is classifying Parkinson's Patients. Feature extraction methods play a critical part in the use of ML techniques in providing better accuracies. The earlier studies have used various feature extraction techniques like Principal Component Analysis (PCA), Independent Component Analysis (ICA), Region of Interest (ROIs), etc. This paper deals with the use of two feature extraction techniques - Canonical Independent Component Analysis (CanICA) and Dictionary Learning (DL) for the Functional Magnetic Resonance Imaging (fMRI) modality. Region of Interest (ROI) extraction of connected components and dimensionality reduction algorithms further refine the features. The features extracted are then applied to the Machine Learning models for the classification of individuals suffering from Parkinson's disease. The methodology adopted in the research provided accuracy of 87.5% and 86.6% using the CanICA and DL techniques respectively. The accuracies obtained are found to be better than the other research conducted using ML algorithms for the MRI data.
C1 [Dutta, Saloni Bhatia] Northcap Univ, Gurgaon, Haryana, India.
   [Vig, Rekha] Northcap Univ, CSE Dept, Gurgaon, Haryana, India.
C3 The Northcap University; The Northcap University
RP Dutta, SB (corresponding author), Northcap Univ, Gurgaon, Haryana, India.
EM saloni19ecd001@ncuindia.edu; rekhavig@ncuindia.edu
OI Dutta, Saloni Bhatia/0000-0002-6540-0596
CR Abós A, 2017, SCI REP-UK, V7, DOI 10.1038/srep45347
   Adeli E, 2019, IEEE T PATTERN ANAL, V41, P515, DOI 10.1109/TPAMI.2018.2794470
   Adeli E, 2016, NEUROIMAGE, V141, P206, DOI 10.1016/j.neuroimage.2016.05.054
   Amirali K, 2017, ARTIF INTELL SIGNAL, DOI [10.1109/AISP.2017.8324124, DOI 10.1109/AISP.2017.8324124]
   apd, ABOUT US
   Archer DB, 2019, LANCET DIGIT HEALTH, V1, pE222, DOI 10.1016/S2589-7500(19)30105-0
   Baggioa HC, NEUROIMAGE-CLIN, V22, DOI [10.1016/j.nicl, DOI 10.1016/J.NICL]
   Chen YB, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124153
   Cigdem O, 2018, COMPUT BIOL MED, V99, P173, DOI 10.1016/j.compbiomed.2018.05.006
   Correia MM, 2020, BRAIN COMMUN, V2, DOI 10.1093/braincomms/fcaa051
   fMRI, TUTORIAL 3 LOOKING D
   Focke NK, 2011, HUM BRAIN MAPP, V32, P1905, DOI 10.1002/hbm.21161
   Gellerup D., 2016, THESIS
   Isin A, 2016, PROCEDIA COMPUT SCI, V102, P317, DOI 10.1016/j.procs.2016.09.407
   Jankovic J, 2008, J NEUROL NEUROSUR PS, V79, P368, DOI 10.1136/jnnp.2007.131045
   Karim AM, 2019, BIOCYBERN BIOMED ENG, V39, P148, DOI 10.1016/j.bbe.2018.11.004
   Long D, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0047714
   Mahlknecht P, 2010, NEURODEGENER DIS, V7, P300, DOI 10.1159/000314495
   Mei J, 2021, FRONT AGING NEUROSCI, V13, DOI 10.3389/fnagi.2021.633752
   Mohsen Heba, 2018, Future Computing and Informatics Journal, V3, P68, DOI 10.1016/j.fcij.2017.12.001
   Pang HZ, 2021, PARKINSONISM RELAT D, V90, P65, DOI 10.1016/j.parkreldis.2021.08.003
   ppmi, US
   researchgate, US
   Rubbert C, 2019, BRIT J RADIOL, V92, DOI 10.1259/bjr.20180886
   Salvatore C, 2014, J NEUROSCI METH, V222, P230, DOI 10.1016/j.jneumeth.2013.11.016
   Shi DF, 2022, FRONT AGING NEUROSCI, V14, DOI 10.3389/fnagi.2022.806828
   Shi D, 2021, FRONT AGING NEUROSCI, V13, DOI 10.3389/fnagi.2021.624731
   Skidmore F, 2011, NEUROSCI LETT, V499, P47, DOI 10.1016/j.neulet.2011.05.030
   Stoessl AJ, 2014, LANCET, V384, P532, DOI 10.1016/S0140-6736(14)60041-6
NR 29
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 17
PY 2023
DI 10.1007/s11042-023-16485-5
EA AUG 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P3YY0
UT WOS:001050048600003
DA 2024-07-18
ER

PT J
AU Mademlis, I
   Symeonidis, C
   Tefas, A
   Pitas, I
AF Mademlis, Ioannis
   Symeonidis, Charalampos
   Tefas, Anastasios
   Pitas, Ioannis
TI Vision-based drone control for autonomous UAV cinematography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE UAV cinematography; Intelligent shooting; Autonomous drones; PID
   control; Deep neural networks; Vision-based control; Mobile robotics;
   Object detection
ID CLASSIFICATION; SHOTS
AB One of the most important aesthetic concepts in autonomous Unmanned Aerial Vehicle (UAV) cinematography is the UAV/Camera Motion Type (CMT), describing the desired UAV trajectory relative to a (still or moving) physical target/subject being filmed. Usually, for the drone to autonomously execute such a CMT and capture the desired shot in footage, the 3D states (positions/poses within the world) of both the UAV/camera and the target are required as input. However, the target's 3D state is not typically known in non-staged settings. This paper proposes a novel framework for reformulating each desired CMT as a set of requirements that interrelate 2D visual information, UAV trajectory and camera orientation. Then, a set of CMT-specific vision-driven Proportional-Integral-Derivative (PID) UAV controllers can be implemented, by exploiting the above requirements to form suitable error signals. Such signals drive continuous adjustments to instant UAV motion parameters, separately at each captured video frame/time instance. The only inputs required for computing each error value are the current 2D pixel coordinates of the target's on-frame bounding box, detectable by an independent, off-the-shelf, real-time, deep neural 2D object detector/tracker vision subsystem. Importantly, neither UAV nor target 3D states are required ever to be known or estimated, while no depth maps, target 3D models or camera intrinsic parameters are necessary. The method was implemented and successfully evaluated in a robotics simulator, by properly reformulating a set of standard, formalized UAV CMTs.
C1 [Mademlis, Ioannis; Symeonidis, Charalampos; Tefas, Anastasios; Pitas, Ioannis] Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki, Greece.
C3 Aristotle University of Thessaloniki
RP Mademlis, I (corresponding author), Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki, Greece.
EM imademlis@csd.auth.gr; charsyme@csd.auth.gr; tefas@csd.auth.gr;
   pitas@csd.auth.gr
RI Mademlis, Ioannis/K-3673-2019
OI Mademlis, Ioannis/0000-0001-5479-0632
FU European Union [731667]
FX The research leading to these results has received funding from the
   European Union's European Union Horizon 2020 research and innovation
   programme under grant agreement No 731667 (MULTIDRONE). This publication
   reflects only the author's views. The European Union is not liable for
   any use that may be made of the information contained therein.
CR Alcántara A, 2021, ROBOT AUTON SYST, V140, DOI 10.1016/j.robot.2021.103778
   Alcántara A, 2020, IEEE ACCESS, V8, P201300, DOI 10.1109/ACCESS.2020.3036239
   Alexandrov AG, 2014, AUTOMAT REM CONTR+, V75, P188, DOI 10.1134/S0005117914020027
   Andrews A.P., 2007, Global Positioning Systems, Inertial Navigation, and Integration, DOI 10.1002/0470099720
   [Anonymous], 2018, P IEEE INT S CIRC SY
   Astrom K. J., 2006, Advanced PID Control
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bhattacharya S, 2014, IEEE T MULTIMEDIA, V16, P686, DOI 10.1109/TMM.2014.2300833
   Bonatti R, 2019, Arxiv, DOI arXiv:1904.02319
   Bradski G., 2005, Intel Technology Journal, V9, P119
   Cao ZA, 2021, IEEE INT C INT ROBOT, P3086, DOI 10.1109/IROS51168.2021.9636309
   Caraballo LE, 2020, P INT C INT ROB SYST
   Carrio A, 2017, J SENSORS, V2017, DOI 10.1155/2017/3296874
   Chen CL, 2019, IEEE T MULTIMEDIA, V21, P3205, DOI 10.1109/TMM.2019.2916104
   Devo A, 2021, ROBOT AUTON SYST, V142, DOI 10.1016/j.robot.2021.103799
   Fourati H., 2016, Multisensor Attitude Estimation: Fundamental Concepts and Applications, P1, DOI [10.1201/9781315368795, DOI 10.1201/9781315368795]
   Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599
   Gschwindt M, 2019, Arxiv, DOI arXiv:1904.02579
   Huang C., 2019, P IEEE C COMP VIS PA
   Huang C, 2019, IEEE INT CONF ROBOT, P1871, DOI [10.1109/icra.2019.8793915, 10.1109/ICRA.2019.8793915]
   Jocher Glenn, 2022, Zenodo
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Joubert N, 2016, Arxiv, DOI arXiv:1610.01691
   Kakaletsis E, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3472288
   Karakostas I, 2019, INT CONF ACOUST SPEE, P1937, DOI 10.1109/ICASSP.2019.8683014
   Karakostas I, 2018, IEEE IMAGE PROC, P76, DOI 10.1109/ICIP.2018.8451385
   Karakostas L, 2020, INFORM SCIENCES, V506, P273, DOI 10.1016/j.ins.2019.08.011
   Kelchtermans K, 2017, Arxiv, DOI arXiv:1702.07600
   Kim DK, 2015, Arxiv, DOI [arXiv:1511.04668, 10.48550/arXiv.1511.04668]
   Kuang Q, 2019, IEEE T MULTIMEDIA
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li GH, 2019, Arxiv, DOI arXiv:1803.01129
   Mademlis I, 2023, MULTIMED TOOLS APPL, V82, P1905, DOI 10.1007/s11042-022-13319-8
   Mademlis I, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3347713
   Mademlis I, 2019, IEEE T BROADCAST, V65, P627, DOI 10.1109/TBC.2019.2892585
   Mademlis I, 2018, IEEE INT CON MULTI
   Mademlis I, 2019, IEEE SIGNAL PROC MAG, V36, P147, DOI 10.1109/MSP.2018.2875190
   Meier L, 2011, IEEE INT CONF ROBOT
   Mur-Artal R, 2017, IEEE ROBOT AUTOM LET, V2, P796, DOI 10.1109/LRA.2017.2653359
   Nägeli T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073712
   Nägeli T, 2017, IEEE ROBOT AUTOM LET, V2, P1696, DOI 10.1109/LRA.2017.2665693
   Naseer T, 2013, IEEE INT C INT ROBOT, P624, DOI 10.1109/IROS.2013.6696416
   Nousi Paraskevi, 2019, 2019 IEEE International Conference on Real-time Computing and Robotics (RCAR). Proceedings, P708, DOI 10.1109/RCAR47638.2019.9043931
   Nousi P, 2018, IEEE IMAGE PROC, P321, DOI 10.1109/ICIP.2018.8451600
   Papaioannidis Christos, 2021, 2021 IEEE International Conference on Robotics and Automation (ICRA), P11074, DOI 10.1109/ICRA48506.2021.9560830
   Papaioannidis C, 2022, IEEE T CIRC SYST VID
   Passalis N, 2019, NEUROCOMPUTING, V335, P37, DOI 10.1016/j.neucom.2019.01.046
   Patrona F, 2020, P NO LIGHTS DEEP LEA
   Patrona F, 2019, IEEE IMAGE PROC, P4155, DOI [10.1109/ICIP.2019.8803630, 10.1109/icip.2019.8803630]
   Piao JC, 2019, IEEE T MULTIMEDIA, V21, P2827, DOI 10.1109/TMM.2019.2913324
   Quan HT, 2011, IEEE T BROADCAST, V57, P1, DOI 10.1109/TBC.2010.2086750
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Sadeghi F, 2017, Arxiv, DOI arXiv:1611.04201
   Serra P, 2016, IEEE T ROBOT, V32, P1524, DOI 10.1109/TRO.2016.2604495
   Shah S, 2017, P FIELD SERVICE ROBO
   Symeonidis C, 2019, IEEE INT WORKS MACH
   Teulière C, 2011, IEEE INT C INT ROBOT
   Teulière C, 2014, IEEE T ROBOT, V30, P1242, DOI 10.1109/TRO.2014.2325991
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Zhong Fangwei, 2018, P INT C LEARN REPR I
NR 60
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 15
PY 2023
DI 10.1007/s11042-023-15336-7
EA AUG 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P6LA0
UT WOS:001051759100002
DA 2024-07-18
ER

PT J
AU Lavín-Delgado, JE
   Gómez-Aguilar, JF
   Urueta-Hinojosa, DE
   Zamudio-Beltrán, Z
   Alanís-Navarro, JA
AF Lavin-Delgado, J. E.
   Gomez-Aguilar, J. F.
   Urueta-Hinojosa, D. E.
   Zamudio-Beltran, Z.
   Alanis-Navarro, J. A.
TI An efficient technique for object recognition using fractional
   Harris-Stephens corner detection algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fractional calculus; Corner detection; Fractional hessian matrix;
   Fractional gaussian filter; Harris-Stephens operator; Concrete crack
AB In this research, a fractional-order technique for corner detection and image matching based on the Harris-Stephens algorithm and the Caputo-Fabrizio and Atangana-Baleanu derivatives is proposed and experimentally tested. It focuses on three main ideas: 1) To suppress image noise more effectively while maintaining better image fidelity, a fractional Gaussian filter based on the Atangana-Baleanu derivative is designed. 2) The image derivatives and consequently the Hessian matrix are generalized through the Caputo-Fabrizio derivative, which has a high capability to preserve texture details in low-contrast regions. 3) An image-matching scheme that combines our fractional corner detector with the SURF algorithm is developed so that the corner extraction and the accuracy of matching images are improved. The proposed technique is compared experimentally with the conventional Harris-Stephens algorithm and some other methods reported in the literature. Experimental results on test images validated this approach in terms of more corners detected and matching accuracy improvement. In addition, the proposed operator is implemented for image processing of concrete structures images, i.e., for the identification and analysis of cracks in this kind of structure. Implementation results on images with different types of cracks prove the advantages of our operator over other methods since it can detect more pixels corresponding to cracks, improving their identification and the way they propagate, that is, their patterns of propagation.
C1 [Lavin-Delgado, J. E.; Urueta-Hinojosa, D. E.] Univ Politecn Estado Guerrero UPEGro, Direcc Ingn Redes & Telecomunicac, Carretera Fed Iguala Taxco KM 105, Taxco De Alarcon 40321, Guerrero, Mexico.
   [Gomez-Aguilar, J. F.] CONACyT TecNM, CENIDET, Interior Internado Palmira S N,Col Palmira, Cuernavaca 62490, Morelos, Mexico.
   [Zamudio-Beltran, Z.] Univ La Salle, Fac Ingn, Bejamin Franklin 45,Col Condesa, Ciudad De Mexico 06140, Mexico.
   [Alanis-Navarro, J. A.] Univ Politecn Estado Guerrero UPEGro, Direcc Ingn Energia & Tecnol Ambiental, Carretera Fed Iguala Taxco KM 105, Taxco De Alarcon 40321, Guerrero, Mexico.
RP Gómez-Aguilar, JF (corresponding author), CONACyT TecNM, CENIDET, Interior Internado Palmira S N,Col Palmira, Cuernavaca 62490, Morelos, Mexico.
RI Zamudio Beltrán, Zizilia/C-2774-2014; Navarro, José Andrés
   Alanís/ABH-7119-2020
OI Zamudio Beltrán, Zizilia/0000-0001-5001-8557; Navarro, José Andrés
   Alanís/0000-0003-3337-2380; Urueta H., Daniel E./0000-0002-8741-6978;
   Lavin Delgado, Jorge Enrique/0000-0003-3632-3373; Gomez-Aguilar,
   J.F./0000-0001-9403-3767
CR Adams M, 2019, LECT NOTES COMPUT SC, V11603, P3, DOI 10.1007/978-3-030-22368-7_1
   Alkahtani BST, 2016, CHAOS SOLITON FRACT, V89, P547, DOI 10.1016/j.chaos.2016.03.020
   An MS, 2022, J SUPERCOMPUT, V78, P12380, DOI 10.1007/s11227-022-04304-x
   ARORA AK, 1987, INDIAN J PURE AP MAT, V18, P931
   Arora S, 2022, NEUROCOMPUTING, V489, P407, DOI 10.1016/j.neucom.2021.10.122
   Artin E, 2015, The Gamma Function
   Atangana A, 2018, MATH MODEL NAT PHENO, V13, DOI 10.1051/mmnp/2018010
   Baleanu D., 2012, Fractional Calculus: Models and Numerical Methods
   Bao J., 2022, MULTIMED TOOLS APPL, V81, P1
   Basha Cmak Zeelan, 2020, 2020 Fourth International Conference on Computing Methodologies and Communication (ICCMC). Proceedings, P991, DOI 10.1109/ICCMC48092.2020.ICCMC-000184
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Burger W, 2022, DIGITAL IMAGE PROCES, P145
   Caputo M., 2015, PROGR FRACT DIFFER A, V1, P73, DOI [DOI 10.12785/PFDA/010201, 10.12785/pfda/010201]
   Cvisic I., 2021, 2021 EUROPEAN C MOBI, P1
   Debnath L, 2003, Int J Math Math Sci, V54, P3413, DOI 10.1155/S0161171203301486
   Dong Yunfei, 2022, 2022 7th International Conference on Intelligent Computing and Signal Processing (ICSP), P391, DOI 10.1109/ICSP54964.2022.9778780
   Dorrego G.A., 2012, Int J Contemp Math Sci, V7, P705
   George J, 2021, INT J INNOV TECHNOL, V8
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   He XC, 2004, INT C PATT RECOG, P791, DOI 10.1109/ICPR.2004.1334377
   He XC, 2008, OPT ENG, V47, DOI 10.1117/1.2931681
   Jie Chen, 2009, Journal of Multimedia, V4, P435, DOI 10.4304/jmm.4.6.435-441
   Jiwoo Kang, 2021, 2021 IEEE International Conference on Signal and Image Processing Applications (ICSIPA), P12, DOI 10.1109/ICSIPA52582.2021.9576808
   Kochubei A, 2019, BASIC THEORY
   Lee BY, 2013, STRUCT INFRASTRUCT E, V9, P567, DOI 10.1080/15732479.2011.593891
   Li CP, 2011, DISCRETE DYN NAT SOC, V2011, DOI 10.1155/2011/562494
   Loverro A., 2004, Fractional Calculus: History, Definitions and Applications for the Engineer
   Luo T, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020443
   Mohamed SAS, 2021, INT C PATT RECOG, P10465, DOI [10.1109/ICPR48806.2021.9412314, 10.1007/978-981-15-6619-6_51]
   Moravec H.P., 1980, OBSTACLE AVOIDANCE N
   Oliveira DS, 2019, ADV PURE APPL MATH, V10, P81, DOI 10.1515/apam-2017-0068
   Ostalczyk P, 2016, SER COMPUT VIS, P1, DOI 10.1142/9833
   Pan X, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102112
   Patel TP, 2014, INT J ENG DEV RES, V2, P3680
   Podlubny I, 1998, FRACTIONAL DIFFERENT
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Ruiying Luo, 2021, Advances in Wireless Communications and Applications. Smart Communications: Interactive Methods and Intelligent Algorithms. Proceedings of 3rd ICWCA 2019. Smart Innovation, Systems and Technologies (SIST 190), P93, DOI 10.1007/978-981-15-5697-5_11
   Sarwas G, 2017, SIG P ALGO ARCH ARR, P349, DOI 10.23919/SPA.2017.8166891
   Seada Noha A., 2019, International Journal of Medical Engineering and Informatics, V11, P86
   Sikka P, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103514
   Sikka Rishi, 2022, International Conference on Intelligent Emerging Methods of Artificial Intelligence & Cloud Computing: Proceedings of IEMAICLOUD 2021. Smart Innovation, Systems and Technologies (273), P164, DOI 10.1007/978-3-030-92905-3_20
   Solís-Pérez JE, 2019, BIOMED SIGNAL PROCES, V54, DOI 10.1016/j.bspc.2019.101584
   Suarez P., 2018, INT C INF TECHN SYST, P732
   Sun X, 2023, IEEE SIGNAL PROC LET, V30, P50, DOI 10.1109/LSP.2023.3240371
   Machado JAT, 2010, MATH PROBL ENG, V2010, DOI 10.1155/2010/639801
   Tissainayagam P, 2004, IMAGE VISION COMPUT, V22, P663, DOI 10.1016/j.imavis.2004.02.001
   Wang MZ, 2022, DIGIT SIGNAL PROCESS, V122, DOI 10.1016/j.dsp.2021.103364
   Wu XZ, 2017, SHOCK VIB, V2017, DOI 10.1155/2017/5497457
   Xueting Yue, 2021, Arabian Journal of Geosciences, V14, DOI 10.1007/s12517-021-07860-3
   Zhang C, 2019, COMPUT ASSIST SURG, V24, P79, DOI 10.1080/24699322.2019.1649077
NR 51
TC 1
Z9 1
U1 6
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 12
PY 2023
DI 10.1007/s11042-023-16428-0
EA AUG 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O9LJ2
UT WOS:001046958100005
DA 2024-07-18
ER

PT J
AU Zhou, XH
   Meng, XK
   Zheng, JB
   Fang, GF
   Guo, TJ
AF Zhou, Xiaohua
   Meng, Xinkai
   Zheng, Jianbin
   Fang, Gengfa
   Guo, Tongjian
TI Human body recognition based on the sparse point cloud data from MIMO
   millimeter-wave radar for smart home
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human body recognition; MIMO millimeter wave radar; Point cloud data;
   Clustering; Body track
ID MOTION RECOGNITION
AB Human body recognition is widely used in smart home. The current mainstream perception modalities, i.e., camera and wearable device, are vulnerable under challenging lighting conditions and poor convenience. On the other hand, Multi-human body recognition remains as one of the most challenging tasks in a dynamic and complex environment. In this work, we introduce the low-cost multiple-input-multiple-output (MIMO) millimeter-wave radar without exposing user's private information for human body recognition in smart home. We propose a human body recognition scheme with the clustering based on the human body tracking using the sparse point cloud data of MIMO millimeter-wave radar. Firstly, the possible position of human body is predicted based on Kalman filter. Then, the point cloud data is clustered based on the human body shape in the prediction range of the human position. Finally, label tags are used to mark the human body targets detected by each frame of the radar. We apply human body recognition to validate the effectiveness of the proposed scheme. It can achieve single-person and double-person recognition using the sparse point cloud data of MIMO millimeter-wave radar. The results show that our proposed scheme reduces the error probability by 23.4% for the single-person recognition and by 31.1% for the double-person recognition. Extensive evaluations on the application of human activity recognition well demonstrate the practicability of the proposed scheme.
C1 [Zhou, Xiaohua; Meng, Xinkai; Zheng, Jianbin] Jilin Univ, Coll Instrumentat & Elect Engn, Changchun, Peoples R China.
   [Fang, Gengfa] Univ Technol Sydney, Global Big Data Technol Ctr, Sydney, Australia.
   [Guo, Tongjian] Chinese Acad Sci, Changchun Inst Opt, Fine Mech & Phys, Changchun, Peoples R China.
C3 Jilin University; University of Technology Sydney; Chinese Academy of
   Sciences; Changchun Institute of Optics, Fine Mechanics & Physics, CAS
RP Guo, TJ (corresponding author), Chinese Acad Sci, Changchun Inst Opt, Fine Mech & Phys, Changchun, Peoples R China.
EM tjguo_ciomp@hotmail.com
FU Science and Technology Department of Jilin Province, China
   [20220101153JC]
FX This work is granted by the Science and Technology Department of Jilin
   Province, China [Grant No. 20220101153JC]. Some or all data during the
   study are available from the corresponding~author by request (Email:
   tjguo_ciomp@hotmail.com). Authors express their gratitude to IoT
   Innovation Lab at UTS in Australia for their generously provided the
   experimental equipment.~Authors would also like to thank anonymous
   reviewers and editors provided many helpful comments on the manuscript.
CR Abramovich YI, 2013, IEEE T AERO ELEC SYS, V49, P1839, DOI 10.1109/TAES.2013.6558024
   Banan A, 2020, AQUACULT ENG, V89, DOI 10.1016/j.aquaeng.2020.102053
   Chalabi NE, 2021, MULTIMED TOOLS APPL, V80, P33257, DOI 10.1007/s11042-021-11367-0
   Clemente C, 2015, IEEE T AERO ELEC SYS, V51, P417, DOI 10.1109/TAES.2014.130762
   Deng H, 2009, IEEE T ANTENN PROPAG, V57, P425, DOI 10.1109/TAP.2008.2011387
   Erol B, 2016, CONF REC ASILOMAR C, P1768, DOI 10.1109/ACSSC.2016.7869686
   Fan YW, 2019, IEEE GLOB COMM CONF, DOI 10.1109/globecom38437.2019.9013394
   Garcia L., 2018, Network Protocols and Algorithms, V10, P23, DOI DOI 10.5296/NPA.V10I1.12798
   García L, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P266, DOI 10.1109/ICACCI.2018.8554654
   Gurbuz SZ, 2017, IET RADAR SONAR NAV, V11, P107, DOI 10.1049/iet-rsn.2016.0055
   Ji XP, 2018, SIGNAL PROCESS, V143, P56, DOI 10.1016/j.sigpro.2017.08.016
   Ji YL, 2018, SIGNAL PROCESS, V143, P364, DOI 10.1016/j.sigpro.2017.06.001
   Jiang XR, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195466
   Jin F, 2020, 2020 IEEE INTERNATIONAL RADAR CONFERENCE (RADAR), P732, DOI [10.1109/radar42522.2020.9114662, 10.1109/RADAR42522.2020.9114662]
   Jokanovic B, 2018, IEEE T AERO ELEC SYS, V54, P180, DOI 10.1109/TAES.2017.2740098
   Liang Liu, 2011, 2011 5th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth 2011), P222, DOI 10.4108/icst.pervasivehealth.2011.245993
   Markopoulos PP, 2019, IEEE J ELECTROMAG RF, V3, P120, DOI 10.1109/JERM.2019.2893587
   Pham C, 2021, MULTIMED TOOLS APPL, V80, P28919, DOI 10.1007/s11042-021-11058-w
   Qian K, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3432221
   Ricci R, 2015, IET RADAR SONAR NAV, V9, P1216, DOI 10.1049/iet-rsn.2014.0551
   Schumann O, 2018, 2018 21ST INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P2179, DOI 10.23919/ICIF.2018.8455344
   Varshney N, 2022, MULTIMED TOOLS APPL, V81, P22307, DOI 10.1007/s11042-021-11131-4
   Wan EA, 2000, ADV NEUR IN, V12, P666
   Wang MY, 2019, DIGIT SIGNAL PROCESS, V87, P125, DOI 10.1016/j.dsp.2019.01.013
   Wang MY, 2018, IET RADAR SONAR NAV, V12, P1046, DOI 10.1049/iet-rsn.2018.5054
   Wei L, 2016, 2016 IEEE 13 INT C S
   Zhang Y, 2014, 2014 INT RAD C, P1
   Zhu S., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508443
NR 28
TC 0
Z9 0
U1 9
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 12
PY 2023
DI 10.1007/s11042-023-15700-7
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O9LJ2
UT WOS:001046958100006
DA 2024-07-18
ER

PT J
AU Ghandour, C
   El-Shafai, W
   El-Rabaie, S
   Abdelsalam, N
AF Ghandour, C.
   El-Shafai, Walid
   El-Rabaie, S.
   Abdelsalam, Nariman
TI Comprehensive performance analysis of different medical image fusion
   techniques for accurate healthcare diagnosis applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Medical image fusion; MIFB; CL; FACL; EM; PCA; Conv_SR; NSST_PA-PCCN;
   PSNR; and RMSE
AB The advancement of medical imaging has led to the acquisition of image data from multiple modalities, necessitating the development of robust algorithms for accurate and reliable fusion of such diverse image sets. Medical image fusion plays a crucial role in enhancing the clinical applicability of medical images by combining information from different modalities into a single fused image that provides comprehensive and instructive insights. In recent years, significant efforts have been devoted to expanding the repertoire of image fusion algorithms, particularly in the absence of standardized benchmarks and comprehensive code libraries that can support state-of-the-art techniques. This research presents a comprehensive performance analysis of different medical image fusion techniques applied to a wide range of medical images. To facilitate this analysis, we have curated a Medical Image Fusion Benchmark (MIFB) that incorporates a diverse set of evaluation metrics (EM) for quantitative assessment. Additionally, we have developed a Fusion Algorithms Code Library (FACL) that provides a comprehensive repository of fusion algorithms for easy access and comparative analysis. Through rigorous experiments conducted within this benchmarking framework, we aim to identify the most effective algorithms for achieving powerful image fusion, considering both quantitative and qualitative outcomes. Moreover, we offer insightful observations on the current state and future prospects of the field. To validate the effectiveness of our approach, we compare our results with previous related work in the field. Our comparative analysis reveals that Principal Component Analysis (PCA) demonstrates superior performance in fusing MRI and CT medical images, exhibiting a restoration quality with average PSNR values of 19.047 dB and RMSE of 6.1 x 10(-4). On the other hand, Convolutional Sparse Representation (Conv_SR) outperforms other techniques in fusing MRI and PET medical images, achieving average PSNR values of 19.073 dB and RMSE of 5.51 x 10(-4), indicating good restoration quality. Lastly, the Non-Subsampled Shearlet Transform_Parameter-Adaptive Pulse-Coupled Neural Network (NSST_PA-PCCN) attains impressive performance in fusing MRI and SPECT medical images, with average PSNR values of 19.101 dB and RMSE of 4.90382 x 10(-4), suggesting high-quality restoration. In conclusion, this research contributes to the comprehensive analysis and evaluation of various medical image fusion techniques for accurate healthcare diagnosis applications. By establishing the Medical Image Fusion Benchmark and Fusion Algorithms Code Library, we offer a valuable resource for researchers and practitioners in the field. Our findings highlight the superior performance of specific techniques, such as PCA, Conv_SR, and NSST_PA-PCCN, for fusing different medical image modalities and achieving excellent restoration quality. The insights gained from this study can guide the selection and implementation of appropriate image fusion algorithms in medical imaging applications, ultimately contributing to improved healthcare diagnostics.
C1 [Ghandour, C.; El-Shafai, Walid; El-Rabaie, S.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
   [Ghandour, C.] Int Acad Engn & Media Sci IAEMS, Fac Engn, Dept Elect & Elect Commun Engn, Cairo, Egypt.
   [El-Shafai, Walid] Prince Sultan Univ, Comp Sci Dept, Secur Engn Lab, Riyadh 11586, Saudi Arabia.
   [Abdelsalam, Nariman] Canadian Int Coll CIC, Fac Engn, Dept Elect & Elect Commun Engn, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Prince Sultan
   University; Canadian International College (CIC)
RP Ghandour, C (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.; Ghandour, C (corresponding author), Int Acad Engn & Media Sci IAEMS, Fac Engn, Dept Elect & Elect Commun Engn, Cairo, Egypt.
EM christena.zaki@gmail.com; eng.waled.elshafai@gmail.com;
   elsayedelrabaie@gmail.com; nariman_abdelsalam@cic-cairo.com
RI El-Shafai, Walid/AAG-4796-2021
OI El-Shafai, Walid/0000-0001-7509-2120
CR Agrawal C., 2022, SIMPLIFIED PARAMETER
   Arif M, 2020, SOFT COMPUT, V24, P1815, DOI 10.1007/s00500-019-04011-5
   Azam MA, 2022, COMPUT BIOL MED, V144, DOI 10.1016/j.compbiomed.2022.105253
   Badr IS, 2021, DIGIT SIGNAL PROCESS, V116, DOI 10.1016/j.dsp.2021.103103
   Bavirisetti DP, 2019, CIRC SYST SIGNAL PR, V38, P5576, DOI 10.1007/s00034-019-01131-z
   Benjamin JR, 2018, INT J COMPUT ASS RAD, V13, P229, DOI 10.1007/s11548-017-1692-4
   Dinh PH, 2023, BIOMED SIGNAL PROCES, V84, DOI 10.1016/j.bspc.2023.104740
   Dinh PH, 2021, APPL INTELL, V51, P8416, DOI 10.1007/s10489-021-02282-w
   Dinh PH, 2021, EXPERT SYST APPL, V171, DOI 10.1016/j.eswa.2021.114576
   Diwakar M, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13050820
   Diwakar M, 2021, MATER TODAY-PROC, V37, P3411, DOI 10.1016/j.matpr.2020.09.278
   Du J, 2020, INFORM SCIENCES, V525, P93, DOI 10.1016/j.ins.2020.03.051
   Duan JW, 2021, IEEE ACCESS, V9, P96353, DOI 10.1109/ACCESS.2021.3094972
   El-Hag NA, 2021, INT J NUMER METH BIO, V37, DOI 10.1002/cnm.3449
   El-Hoseny HM, 2019, INFRARED PHYS TECHN, V102, DOI 10.1016/j.infrared.2019.102975
   El-Hoseny HM, 2019, INT J IMAG SYST TECH, V29, P4, DOI 10.1002/ima.22289
   El-Shafai W., 2023, COMPUT MAT CONTINUA, V74, P2905, DOI [10.32604/cmc.2023.031936, DOI 10.32604/CMC.2023.031936]
   El-Shafai W, 2023, J OPT-INDIA, V52, P2253, DOI 10.1007/s12596-023-01123-y
   Faragallah OS, 2022, MULTIMED TOOLS APPL, V81, P14379, DOI 10.1007/s11042-022-12260-0
   Faragallah OS, 2021, IEEE ACCESS, V9, P11358, DOI 10.1109/ACCESS.2020.3048315
   Fu J, 2020, COMPUT BIOL MED, V126, DOI 10.1016/j.compbiomed.2020.104048
   Ganasala P, 2020, INT J IMAG SYST TECH, V30, P544, DOI 10.1002/ima.22393
   Ghandour C, 2023, J OPT-INDIA, V52, P1931, DOI 10.1007/s12596-022-01078-6
   Ghandour C, 2023, J OPT-INDIA, V52, P845, DOI 10.1007/s12596-022-01032-6
   Ghandour C., 2021, 2021 9th International Japan-Africa Conference on Electronics, Communications, and Computations (JAC-ECC), P159, DOI 10.1109/JAC-ECC54461.2021.9691453
   Ghandour C., 2021, 2021 9th International Japan-Africa Conference on Electronics, Communications, and Computations (JAC-ECC), P164, DOI 10.1109/JAC-ECC54461.2021.9691439
   Guo K, 2021, BMC MED IMAGING, V21, DOI 10.1186/s12880-021-00642-z
   He KJ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3066467
   Hermessi H, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108036
   Huang B, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/8279342
   Indhumathi R, 2022, MICROPROCESS MICROSY, V94, DOI 10.1016/j.micpro.2022.104665
   Kaur H, 2021, ARCH COMPUT METHOD E, V28, P4425, DOI 10.1007/s11831-021-09540-7
   Kaur M, 2021, J AMB INTEL HUM COMP, V12, P2483, DOI 10.1007/s12652-020-02386-0
   Lepcha DC, 2022, HUM-CENT COMPUT INFO, V12, DOI 10.22967/HCIS.2022.12.015
   Li LL, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23050591
   Li QQ, 2021, COMPUT BIOL MED, V131, DOI 10.1016/j.compbiomed.2021.104239
   Li W, 2021, INT J IMAG SYST TECH, V31, P204, DOI 10.1002/ima.22476
   Li XX, 2020, IEEE T INSTRUM MEAS, V69, P6880, DOI 10.1109/TIM.2020.2975405
   Li Y, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.638976
   Liu YY, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.101996
   Maqsood S, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101810
   Meng LY, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.04.013
   Mukherjee S, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113592
   Panigrahy C, 2023, BIOMED SIGNAL PROCES, V83, DOI 10.1016/j.bspc.2023.104659
   Panigrahy C, 2020, IEEE SIGNAL PROC LET, V27, P690, DOI 10.1109/LSP.2020.2989054
   Parvathy VS, 2020, HEALTH CARE MANAG SC, V23, P661, DOI 10.1007/s10729-019-09492-2
   Dinh PH, 2022, NEURAL COMPUT APPL, V34, P4367, DOI 10.1007/s00521-021-06577-4
   Dinh PH, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102696
   Shehanaz S, 2021, OPTIK, V231, DOI 10.1016/j.ijleo.2021.166413
   Smadi A. A., 2022, Procedia Comput. Sci, V198, P295
   Tan W, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102280
   Tan W, 2020, NEURAL COMPUT APPL, DOI 10.1007/s00521-020-05173-2
   Tang L, 2020, SIGNAL PROCESS-IMAGE, V85, DOI 10.1016/j.image.2020.115852
   Tawfik N, 2021, MULTIMED TOOLS APPL, V80, P6369, DOI 10.1007/s11042-020-08834-5
   Tirupal T., 2021, Current Signal Transduction Therapy, V16, P142, DOI 10.2174/1574362415666200226103116
   Ullah H, 2022, APPL INTELL, V52, P7965, DOI 10.1007/s10489-021-02834-0
   Vajpayee P, 2023, SIGNAL IMAGE VIDEO P, V17, P3565, DOI 10.1007/s11760-023-02581-4
   Wang GF, 2022, NEUROCOMPUTING, V480, P61, DOI 10.1016/j.neucom.2022.01.059
   Wang K, MULTIMODALITY MED IM, P1, DOI [10.3390/s20082169, DOI 10.3390/S20082169]
   Wang LF, 2021, IEEE ACCESS, V9, P67634, DOI 10.1109/ACCESS.2021.3075953
   Xia JM, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/3290136
   Xu WN, 2023, COMPUT METH PROG BIO, V229, DOI 10.1016/j.cmpb.2022.107304
   Yadav SP, 2020, MED BIOL ENG COMPUT, V58, P669, DOI 10.1007/s11517-020-02136-6
   Yin M, 2019, IEEE T INSTRUM MEAS, V68, P49, DOI 10.1109/TIM.2018.2838778
   Zhang H, 2021, INFORM FUSION, V76, P323, DOI 10.1016/j.inffus.2021.06.008
   Zhang X, 2020, MULTIFOCUS IMAGE FUS, VXX, P1
   Zhang XC, 2021, INFORM FUSION, V74, P111, DOI 10.1016/j.inffus.2021.02.005
   Zhang XC, 2020, IEEE COMPUT SOC CONF, P468, DOI 10.1109/CVPRW50498.2020.00060
NR 68
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 10
PY 2023
DI 10.1007/s11042-023-16334-5
EA AUG 2023
PG 60
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O8QT2
UT WOS:001046412000008
DA 2024-07-18
ER

PT J
AU Liu, YC
   Cheng, X
   Ikenaga, T
AF Liu, Yanchao
   Cheng, Xina
   Ikenaga, Takeshi
TI Motion-aware and data-independent model based multi-view 3D pose
   refinement for volleyball spike analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Data independence; Motion-aware model; 3D human pose refinement; Sports
   analysis in volleyball
AB In the volleyball game, estimating the 3D pose of the spiker is very valuable for training and analysis, because the spiker's technique level determines the scoring or not of a round. The development of computer vision provides the possibility for the acquisition of the 3D pose. Most conventional pose estimation works are data-dependent methods, which mainly focus on reaching a high level on the dataset with the controllable scene, but fail to get good results in the wild real volleyball competition scene because of the lack of large labelled data, abnormal pose, occlusion and overlap. To refine the inaccurate estimated pose, this paper proposes a motion-aware and data-independent method based on a calibrated multi-camera system for a real volleyball competition scene. The proposed methods consist of three key components: 1) By utilizing the relationship of multi-views, an irrelevant projection based potential joint restore approach is proposed, which refines the wrong pose of one view with the other three views projected information to reduce the influence of occlusion and overlap. 2) Instead of training with a large amount labelled data, the proposed motion-aware method utilizes the similarity of specific motion in sports to achieve construct a spike model. Based on the spike model, joint and trajectory matching is proposed for coarse refinement. 3) To finely refine, a point distribution based posterior decision network is proposed. While expanding the receptive field, the pose estimation task is decomposed into a classification decision problem, which greatly avoids the dependence on a large amount of labelled data. The experimental dataset videos with four synchronous camera views are from a real game, the Game of 2014 Japan Inter High School of Men Volleyball. The experiment result achieves 76.25%, 81.89%, and 86.13% success rate at the 30mm, 50mm, and 70mm error range, respectively. Since the proposed refinement framework is based on a real volleyball competition, it is expected to be applied in the volleyball analysis.
C1 [Liu, Yanchao; Ikenaga, Takeshi] Waseda Univ, Grad Sch Informat Prod & Syst, 2-7 Kitakyushu, Fukuoka 8080135, Japan.
   [Cheng, Xina] Xidian Univ, Sch Artificial Intelligence, 2 South Taibai Rd, Xian 710126, Shaanxi, Peoples R China.
C3 Waseda University; Xidian University
RP Liu, YC (corresponding author), Waseda Univ, Grad Sch Informat Prod & Syst, 2-7 Kitakyushu, Fukuoka 8080135, Japan.
EM liuyanchao@fuji.waseda.jp; xncheng@xidian.edu.cn; ikenaga@waseda.jp
RI LIU, Yanchao/HGC-6950-2022
FU KAKENHI [21K11816]
FX AcknowledgementsThis work has supported by KAKENHI(21K11816).
CR Artacho B, 2021, Arxiv, DOI arXiv:2103.10180
   Askari F, 2022, P IEEE CVF C COMP VI, P3580
   Bridgeman Lewis, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P2487, DOI 10.1109/CVPRW.2019.00304
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Cheng K, 2020, PROC CVPR IEEE, P180, DOI 10.1109/CVPR42600.2020.00026
   Cheng XN, 2020, IEICE T FUND ELECTR, VE103A, P1503, DOI 10.1587/transfun.2020SMP0010
   Chunluan Zhou, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P680, DOI 10.1007/978-3-030-58542-6_41
   D'Eusanio A., 2021, IEEE 25 INT CONFPATT
   Dittakavi B., 2022, P IEEECVF C COMPUTER, P3540
   Dong JT, 2019, PROC CVPR IEEE, P7784, DOI 10.1109/CVPR.2019.00798
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Fieraru M, 2018, IEEE COMPUT SOC CONF, P318, DOI 10.1109/CVPRW.2018.00058
   GOWER JC, 1975, PSYCHOMETRIKA, V40, P33, DOI 10.1007/BF02291478
   Guo H, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.1975
   Guo K, 2022, IEEE T MULTIMEDIA, DOI [10.1109/TMM.3168146, DOI 10.1109/TMM.3168146]
   Guo Kehua, 2022, IEEE/ACM Trans Comput Biol Bioinform, VPP, DOI 10.1109/TCBB.2022.3185395
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Iskakov K, 2019, IEEE I CONF COMP VIS, P7717, DOI 10.1109/ICCV.2019.00781
   Jen Jui Liu, 2020, Advances in Visual Computing. 15th International Symposium, ISVC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12509), P566, DOI 10.1007/978-3-030-64556-4_44
   Khan AA, 2022, IET IMAGE PROCESS, V16, P2854, DOI 10.1049/ipr2.12272
   Kocabas M, 2019, PROC CVPR IEEE, P1077, DOI 10.1109/CVPR.2019.00117
   Li Y, 2020, PROC CVPR IEEE, P906, DOI 10.1109/CVPR42600.2020.00099
   Li YJ, 2022, LECT NOTES COMPUT SC, V13666, P89, DOI 10.1007/978-3-031-20068-7_6
   Mei JR, 2019, INT CONF 3D VISION, P358, DOI 10.1109/3DV.2019.00047
   Moon G, 2019, PROC CVPR IEEE, P7765, DOI 10.1109/CVPR.2019.00796
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P18985, DOI 10.1007/s11042-017-4420-8
   Mukherjee S, 2020, MULTIMED TOOLS APPL, V79, P29951, DOI 10.1007/s11042-020-09522-0
   Napolitano S, 2017, GIORNALE ITALIANO ED, V1
   Pavlakos G, 2017, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2017.138
   Qiu HB, 2019, IEEE I CONF COMP VIS, P4341, DOI 10.1109/ICCV.2019.00444
   Shafiq M, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/8669348
   Shafiq M, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12188972
   Shafiq M, 2020, COMPUT SECUR, V94, DOI 10.1016/j.cose.2020.101863
   Shafiq M, 2020, FUTURE GENER COMP SY, V107, P433, DOI 10.1016/j.future.2020.02.017
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Sun X, 2018, LECT NOTES COMPUT SC, V11210, P536, DOI 10.1007/978-3-030-01231-1_33
   Tian LM, 2023, CURR PSYCHOL, V42, P25460, DOI 10.1007/s12144-022-03444-w
   Veges M., 2020, Neural Information Processing. 27th International Conference, ICONIP 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12532), P557, DOI 10.1007/978-3-030-63830-6_47
   Wang CY, 2019, AAAI CONF ARTIF INTE, P8925
   Wang JB, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P374, DOI 10.1145/3343031.3350910
   Yang CY, 2020, PROC CVPR IEEE, P588, DOI 10.1109/CVPR42600.2020.00067
   Zeng A., 2022, EUROPEAN C COMPUTER
   Zhang F, 2020, PROC CVPR IEEE, P7091, DOI 10.1109/CVPR42600.2020.00712
   Zhao H., 2020, P IEEE CVF C COMP VI, V2020, P10076, DOI 10.1109/CVPR42600.2020.01009
   Zhu K, 2022, IEEE COMPUT SOC CONF, P3588, DOI 10.1109/CVPRW56347.2022.00403
   Zou JQ, 2019, LECT NOTES ELECTR EN, V550, P593, DOI 10.1007/978-981-13-7123-3_69
NR 48
TC 0
Z9 0
U1 5
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 10
PY 2023
DI 10.1007/s11042-023-16369-8
EA AUG 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O8QT2
UT WOS:001046412000010
OA hybrid
DA 2024-07-18
ER

PT J
AU Tsai, YS
   Chen, ALP
AF Tsai, Yun Sheng
   Chen, Arbee L. P.
TI Suicide risk assessment using word-level model with dictionary-based
   risky posts selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media; Deep learning; Natural language processing; Suicide
   ideation; Reddit
ID IDEATION
AB Suicide is a serious issue around the world and is a leading cause of death in US. In the past 20 years, the suicide rate has seen a significant increase of 35%. With the rapid development of information technology, more and more people begin to use social media to share their inner feelings. It enables social media data to be widely used for research on suicide risk assessment. However, not all social media posts are suicide related. Previous research addressed this problem with post-level attention mechanism. However, post-level attention mechanism may not find relevant suicide posts. This problem becomes more serious in the feature-based post embeddings since each post is converted into a single vector to serve as the input of the model, resulting in the loss of word-level information during training. In this paper, we addressed this problem by introducing a novel word-level model including a post-selectin layer as a solution. Firstly, we utilize a suicide keyword dictionary to identify risky posts that may be missed by the post-level attention mechanism. We then convert the words in the risky posts into word embeddings and use self-attention to generate the post embeddings for the risky posts. Finally, we pass the post embeddings to a multilayer perceptron to classify the suicide risk. We also demonstrate that the FScore used in previous studies can be reduced to a function of accuracy, which does not reflect the model performance in predicting imbalanced datasets. Therefore, we additionally adopt macro F1 score as the evaluation function. Experiment results show that our model not only outperforms previous studies in FScore performance, but also achieves macro F1 Score a nearly 4% improvement compared to previous studies.
C1 [Tsai, Yun Sheng] Natl Tsing Hua Univ, Inst Informat Syst & Applicat, Hsinchu, Taiwan.
   [Chen, Arbee L. P.] Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
   [Chen, Arbee L. P.] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu, Taiwan.
C3 National Tsing Hua University; Asia University Taiwan; National Tsing
   Hua University
RP Chen, ALP (corresponding author), Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.; Chen, ALP (corresponding author), Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu, Taiwan.
EM asd7845121@gapp.nthu.edu.tw; arbee@asia.edu.tw
CR [Anonymous], 2022, Suicide Prevention
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Baytas IM, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P65, DOI 10.1145/3097983.3097997
   Beltagy Iz., 2020, ARXIV
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Cao L, 2019, ARXIV
   Choi KJ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-00622-x
   Coppersmith G, 2018, BIOMED INFORM INSIGH, V10, DOI 10.1177/1178222618792860
   De Choudhury M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2098, DOI 10.1145/2858036.2858207
   Domino G, 1996, PSYCHOL REP, V78, P1009, DOI 10.2466/pr0.1996.78.3.1009
   Gaur M, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P514, DOI 10.1145/3308558.3313698
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jashinsky J, 2014, CRISIS, V35, P51, DOI 10.1027/0227-5910/a000234
   Klonsky ED, 2015, INT J COGN THER, V8, P114, DOI 10.1521/ijct.2015.8.2.114
   Leavey G, 2017, BMC PSYCHIATRY, V17, DOI 10.1186/s12888-017-1508-7
   Lim M, 2014, INT J MENT HEALTH SY, V8, DOI 10.1186/1752-4458-8-54
   Loshchilov I., 2018, arXiv
   Masuda N, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0062262
   Matero M., 2019, P 6 WORKSH COMP LING, P39, DOI [DOI 10.18653/V1/W19-3005, 10.18653/v1/W19-3005]
   Mikolov T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P52
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Mishra R, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, P147
   Paszke A., 2019, ADV NEURAL INFORM PR, P8026, DOI DOI 10.48550/ARXIV.1912.01703
   Posner K., 2008, Columbia-suicide severity rating scale (C-SSRS), V10, DOI [DOI 10.1037/T52667-000, 10.1037/t52667-000]
   Reimers N, 2019, ARXIV
   Renberg ES, 2003, SUICIDE LIFE-THREAT, V33, P52, DOI 10.1521/suli.33.1.52.22784
   Roy A, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0287-6
   Sawhney R, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P22, DOI 10.1145/3437963.3441805
   Sawhney R, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7685
   Sawhney Ramit., 2018, P ACL 2018 STUDENT R, P91, DOI [DOI 10.18653/V1/P18-3013, 10.18653/v1/p18-3013]
   Sawhney R, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P628
   Shing H.-C., 2018, NAACL HLT, P25, DOI 10.18653/v1/W18-0603
   Shing H-C, 2020, P 58 ANN M ASS COMP, P8124
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Wang N, 2021, ARXIV
   Yang C., 2021, ARXIV
   Zirikly A., 2019, P 6 WORKSHOP COMPUTA, P24, DOI [DOI 10.18653/V1/W19-3003, 10.18653/V1/W19-3003, 10.18653/v1/ W19-3003]
NR 37
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21435
EP 21454
DI 10.1007/s11042-023-16361-2
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001042601200006
DA 2024-07-18
ER

PT J
AU Yan, XH
   Wang, GY
   Lin, P
   Zhang, JB
   Wang, YF
   Fu, XP
AF Yan, Xiaohong
   Wang, Guangyuan
   Lin, Peng
   Zhang, Junbo
   Wang, Yafei
   Fu, Xianping
TI Underwater image dehazing using a novel color channel based dual
   transmission map estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater image; Image dehazing; Color correction; Transmission map
   estimation
ID LOCAL CONTRAST; ENHANCEMENT; RESTORATION; ALGORITHM; FRAMEWORK;
   FEATURES; NETWORK; MODEL
AB Underwater images typically suffer from color distortion and low contrast, owing to the light absorption and scattering. To handle the visual manifestation of such degraded images, numerous underwater image dehazing algorithms have been presented. However, most of existing dehazing methods still have room for improvement in terms of preserving more details in the restored results. In this paper, we propose a simple yet effective dehazing method. The core idea is to produce the high-quality underwater images with rich detail information and vivid color. Firstly, an innovative color correction is designed to compensate the information of each color components. This operation is a pre-processing procedure, in which, selective absorption is fully considered. Then a dual transmission map-based haze removal method is introduced. Different from previous methods, a novel color channel with two terms is constructed to accurately estimate the transmission maps. The one is designed as the sharpened term to reveal more image detail and edges. The other is a difference of channel intensity prior term to remove the influence of light scattering. By using this strategy, our method can generate a natural appearance of the restored image with more detail information and higher color contrast. Experiments on representative images have proven that the performer of our method is 8.6% and 2.7% better than the second best on the average scores of patch-based contrast quality index (PCQI) and Entropy metrics, respectively.
C1 [Yan, Xiaohong; Wang, Guangyuan; Lin, Peng; Zhang, Junbo; Wang, Yafei; Fu, Xianping] Dalian Maritime Univ, Informat Sci & Technol Sch, Dalian 116026, Peoples R China.
   [Yan, Xiaohong] Dalian Jiaotong Univ, Sch Software, Dalian 116028, Peoples R China.
   [Fu, Xianping] Pengcheng Lab, Shenzhen 518055, Guangdong, Peoples R China.
C3 Dalian Maritime University; Dalian Jiaotong University
RP Fu, XP (corresponding author), Dalian Maritime Univ, Informat Sci & Technol Sch, Dalian 116026, Peoples R China.; Fu, XP (corresponding author), Pengcheng Lab, Shenzhen 518055, Guangdong, Peoples R China.
EM dl_yanxiaohong@163.com; fxp@dlmu.edu.cn
RI feng, feng/KBR-1814-2024; you, li/KHW-2201-2024; yi,
   zhang/KGL-4990-2024; yan, xu/KCY-8174-2024; YANG, DAN/KCL-5217-2024;
   yan, xiao/JVP-0766-2024; luo, Jing/KFT-0288-2024
FU National Natural Science Foundation of China [62176037, 62002043,
   61802043]; Liaoning Revitalization Talents Program [XLYC1908007];
   Foundation of Liaoning Key Research and Development Program [201801728];
   Dalian Science and Technology Innovation Fund [2018J12GX037,
   2019J11CY001, 2021JJ12GX028]
FX AcknowledgementsThe authors sincerely thank the editors and anonymous
   reviewers for the very helpful and kind comments to assist in improving
   the presentation of our paper. This work was supported in part by the
   National Natural Science Foundation of China under Grant 62176037, Grant
   62002043, and Grant 61802043, by the Liaoning Revitalization Talents
   Program under Grant XLYC1908007, by the Foundation of Liaoning Key
   Research and Development Program under Grant 201801728, by the Dalian
   Science and Technology Innovation Fund under Grant 2018J12GX037, Grant
   2019J11CY001, and Grant 2021JJ12GX028
CR Akkaynak D, 2018, PROC CVPR IEEE, P6723, DOI 10.1109/CVPR.2018.00703
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   Carlevaris-Bianco N, 2010, OCEANS-IEEE
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Ding X., 2021, DEPTH AWARE TOTAL VA, P98
   Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113
   Fabbri C, 2018, IEEE INT CONF ROBOT, P7159
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Finlayson GD, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P37
   Fu XP, 2020, OPT LASER ENG, V132, DOI 10.1016/j.optlaseng.2020.106115
   Fu XY, 2014, IEEE IMAGE PROC, P4572, DOI 10.1109/ICIP.2014.7025927
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Ghani ASA, 2015, APPL SOFT COMPUT, V37, P332, DOI 10.1016/j.asoc.2015.08.033
   Guo YC, 2020, IEEE J OCEANIC ENG, V45, P862, DOI 10.1109/JOE.2019.2911447
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang SC, 2014, IEEE T CIRC SYST VID, V24, P1814, DOI 10.1109/TCSVT.2014.2317854
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2021, IEEE T IMAGE PROCESS, V30, P4985, DOI 10.1109/TIP.2021.3076367
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li J, 2018, IEEE ROBOT AUTOM LET, V3, P387, DOI 10.1109/LRA.2017.2730363
   Li YJ, 2019, INT J COMPUT SCI ENG, V19, P562, DOI 10.1504/IJCSE.2019.101879
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Liu PC, 2018, NONLINEAR DYNAM, V94, P1803, DOI 10.1007/s11071-018-4458-9
   Liu RS, 2020, IEEE T CIRC SYST VID, V30, P4861, DOI 10.1109/TCSVT.2019.2963772
   Liu XD, 2021, NEUROCOMPUTING, V453, P538, DOI 10.1016/j.neucom.2020.07.130
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma XM, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.5.053033
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Peng YT, 2018, IEEE T IMAGE PROCESS, V27, P2856, DOI 10.1109/TIP.2018.2813092
   Sahu G., 2021, J VIS COMMUN, P74
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Shen JL, 2021, INFORM SCIENCES, V569, P469, DOI 10.1016/j.ins.2020.11.026
   Song W, 2018, LECT NOTES COMPUT SC, V11164, P678, DOI 10.1007/978-3-030-00776-8_62
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Ulutas G, 2021, MULTIMED TOOLS APPL, V80, P15067, DOI 10.1007/s11042-020-10426-2
   Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Wang SQ, 2015, IEEE SIGNAL PROC LET, V22, P2387, DOI 10.1109/LSP.2015.2487369
   Wang Y, 2018, IEEE T CIRCUITS-I, V65, P992, DOI 10.1109/TCSI.2017.2751671
   Wang YF, 2016, NEUROCOMPUTING, V177, P373, DOI 10.1016/j.neucom.2015.10.124
   Wang ZW, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3439723
   Wei X, 2017, MULTIMED TOOLS APPL, V76, P21547, DOI 10.1007/s11042-016-4073-z
   Yan XH, 2022, SIGNAL PROCESS-IMAGE, V104, DOI 10.1016/j.image.2022.116670
   Yan XH, 2022, MULTIMED TOOLS APPL, V81, P30051, DOI 10.1007/s11042-022-12267-7
   Yang KF, 2015, PROC CVPR IEEE, P2254, DOI 10.1109/CVPR.2015.7298838
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Yu HF, 2020, MULTIMED TOOLS APPL, V79, P20373, DOI 10.1007/s11042-020-08701-3
   Yuan F., 2021, IMAGE COMMUN SIGNAL, P91
   Zhang W, 2021, SIGNAL IMAGE VIDEO P
   Zhang WD, 2021, SIGNAL PROCESS-IMAGE, V90, DOI 10.1016/j.image.2020.116030
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhuang PX, 2020, MULTIMED TOOLS APPL, V79, P17257, DOI 10.1007/s11042-019-08404-4
NR 62
TC 3
Z9 3
U1 5
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20169
EP 20192
DI 10.1007/s11042-023-15708-z
EA JUL 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040925900012
DA 2024-07-18
ER

PT J
AU Jose, B
   Pushpalatha, KP
AF Jose, Bineesh
   Pushpalatha, K. P.
TI Classification of handwritten Malayalam characters using a HOG-DCNN
   model with multiview augmentation and inference fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Malayalam Handwriting Character Recognition (MHCR); Deep Convolutional
   Neural Networks (DCNN); Deep Learning (DL); Histogram of Oriented
   Gradients (HOG); Multiview Augmentation (MVA); Multiview Inference
   Fusion (MVIF)
AB Malayalam Handwriting Character Recognition(MHCR) is a challenging job because of its large number of similar or confusing characters. This is especially true in the case of Malayalam scripts with enormously large character sets with complex shapes. In this study, an in-depth integrated learning model is proposed that incorporates the use of the hand-crafted Histogram of Oriented Gradients(HOG) Feature Descriptor(FD), and the flexible learning features of Deep Convolutional Neural Networks(DCNN). An Malayalam character data set which divides Malayalam characters into Basic and Compound classes were used for training the proposed model with Multiview Augmentation(MVA). Highly perspective-dependent compound character images extracted through mobile phones and digital cameras can be correctly classified with MVA which generates more perspective view that avoid overfitting and makes the training more effective. Similarly high interclass similarities which lead to the misclassification can be addressed through Multiview Inference Fusion(MVIF) which is used to fuse the individual prediction generated from each view. The experimental results express that DCNN-only models achieve 95.07% and 94.57% testing accuracy on respective model implementations. Moreover, it is clear that the proposed system, which fuses HOG Feature Descriptor with a DCNN, attains over 97.79% and 97.09% test accuracy respectively on corresponding live models.
C1 [Jose, Bineesh; Pushpalatha, K. P.] MG Univ, Sch Comp Sci, Priyadharshini Hills, Kottayam 686560, Kerala, India.
C3 Mahatma Gandhi University, Kerala
RP Jose, B (corresponding author), MG Univ, Sch Comp Sci, Priyadharshini Hills, Kottayam 686560, Kerala, India.
EM bineeshjose@gmail.com; pushpalathakp@mgu.ac.in
RI K P, Pushpalatha/HKO-9544-2023
OI K P, Pushpalatha/0000-0002-0044-5507; JOSE, BINEESH/0000-0001-7201-3570
CR Akhand MAH., 2016, ICIEB, V1, P1
   Alex M, 2016, PROC TECH, V25, P224, DOI 10.1016/j.protcy.2016.08.101
   Chacko BP, 2012, INT J MACH LEARN CYB, V3, P149, DOI 10.1007/s13042-011-0049-5
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danisman T, 2016, MULTIMED TOOLS APPL, V75, P7799, DOI 10.1007/s11042-015-2699-x
   Das N, 2014, INT J DOC ANAL RECOG, V17, P413, DOI 10.1007/s10032-014-0222-y
   Jino PJ, 2019, OFFLINE HANDWRITTEN, P913
   John J., 2011, 2011 Proceedings of International Conference on Emerging Trends in Electrical and Computer Technology (ICETECT 2011), P736, DOI 10.1109/ICETECT.2011.5760215
   John J, 2012, PROCEDIA ENGINEER, V30, P598, DOI 10.1016/j.proeng.2012.01.904
   Jose Bineesh, 2023, 2023 International Conference on Advances in Intelligent Computing and Applications (AICAPS), P1, DOI 10.1109/AICAPS57044.2023.10074586
   Jose Bineesh, 2021, IOP Conference Series: Materials Science and Engineering, V1085, DOI 10.1088/1757-899X/1085/1/012022
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar K, 2021, MULTIMED TOOLS APPL, V80, P11079, DOI 10.1007/s11042-020-10157-4
   Li L, 2008, P 19 INT C PATT REC, P1
   Mishra A, 2020, ADV INTELLIGENT SYST, V1053
   Raisa JF, 2021, HANDWRITTEN BANGLA C, P89
   Raju G, 2014, SADHANA-ACAD P ENG S, V39, P1333, DOI 10.1007/s12046-014-0274-1
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Saha C., 2019, 2019 INT C ELECT COM, P1
   Sen Maitra D, 2015, PROC INT CONF DOC, P1021, DOI 10.1109/ICDAR.2015.7333916
   Sen S, 2018, ONLINE HANDWRITTEN M, V2018, P413
   Sharif S. M. A., 2018, Proceedings of the International Conference on Computing and Communication Systems. I3CS 2016. Lecture Notes in Networks and Systems (LNNS 24), P403, DOI 10.1007/978-981-10-6890-4_39
   Tao WJ, 2018, ENG APPL ARTIF INTEL, V76, P202, DOI 10.1016/j.engappai.2018.09.006
   Zeiler M. D., 2012, PREPRINT
NR 24
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19969
EP 19980
DI 10.1007/s11042-023-16154-7
EA JUL 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040015500001
DA 2024-07-18
ER

PT J
AU Peng, YL
   Zeng, S
   Luo, YC
   Yan, LY
   Yao, LM
AF Peng, Yu-lin
   Zeng, Shi
   Luo, Ying-chun
   Yan, Ling-yu
   Yao, Long-mei
TI Attention mechanism optimized neural network for automatic measurement
   of fetal anterior-neck-lower-jaw angle in nuchal translucency tests
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fetal head posture; Nuchal translucency; Anterior-neck-lower-jaw angle;
   Inception structure; Attention mechanism
ID ARTIFICIAL-INTELLIGENCE; POSITION
AB Nuchal translucency (NT) examination has become a standard item in early pregnancy tests because of its clinical value in detecting early gestational fetal abnormalities. Meanwhile, practitioners may sometimes have difficulty meeting the required criteria for NT measurement owing to their complexity or the exorbitant demand for NT tests. Thus, NT image quality control is critical, particularly for the frequently neglected criterion that the fetal head posture (FHP) shall be neither hyperextended nor hyperflexionated. The Nuchal Translucency Quality Review Program (NTQR) defines all FHPs quantitatively using the anterior-neck-lower-jaw angle (ANLJA), namely the angle between the fetal anterior neck and its lower jaw. According to NTQR's definitions, hyperflexion is defined as ANLJA close to 0(& LCIRC;); hyperextension, ANLJA greater than 90(& LCIRC;); and normal FHP, ANLJA between 0(& LCIRC;) and 90(& LCIRC;). Focusing on FHP classification, we proposed a novel algorithm combining an attention mechanism and a convolutional neural network to predict ANLJAs. The new approach integrated channel and spatial attention and was capable of swiftly locating regions of interest. It abstracted important image features based on the information weight and attenuated useless information. The manual method was traditionally regarded as the gold standard for ANLJA measurement. Our findings indicated that the proposed algorithm performed admirably in the ANLJA prediction. It surpassed all other comparison algorithms in terms of efficiency.
C1 [Peng, Yu-lin; Zeng, Shi; Yao, Long-mei] Cent South Univ, Xiangya Hosp 2, Dept Ultrasonog, 139 Renmin Middle Rd, Changsha 410028, Hunan, Peoples R China.
   [Peng, Yu-lin; Luo, Ying-chun] Hunan Prov Maternal & Child Hlth Care Hosp, Dept Ultrasonog, 53 Xiangchun Rd, Changsha 410008, Hunan, Peoples R China.
   [Yan, Ling-yu] Hubei Univ Technol, Sch Comp Sci, 28 Nanli Rd, Wuhan 430068, Hubei, Peoples R China.
C3 Central South University; Hubei University of Technology
RP Zeng, S (corresponding author), Cent South Univ, Xiangya Hosp 2, Dept Ultrasonog, 139 Renmin Middle Rd, Changsha 410028, Hunan, Peoples R China.
EM pengyulin2010@csu.edu.cn; shizeng@csu.edu.cn; 807859088@qq.com;
   yanranyaya@hust.edu.cn; yao_longmei@163.com
OI Peng, Yulin/0000-0002-1574-7241
CR Amisha, 2019, J FAM MED PRIM CARE, V8, P2328, DOI 10.4103/jfmpc.jfmpc_440_19
   B R, 2015, FUNDAMENTALS BIOSTAT
   Chang K, 2018, CLIN CANCER RES, V24, P1073, DOI 10.1158/1078-0432.CCR-17-2236
   Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077
   Choy G, 2018, RADIOLOGY, V288, P318, DOI 10.1148/radiol.2018171820
   Dash JK, 2021, MULTIMED TOOLS APPL, V80, P22589, DOI 10.1007/s11042-020-10173-4
   Deng L., 2014, FOND T SIGN PROC, V7, P197, DOI [10.1561/2000000039, DOI 10.1561/2000000039, 10.1561/]
   Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379
   EK J, 2018, DATA MINING ANAL RIS, DOI [10.33774/apsa-2019-fwthd-v3, DOI 10.33774/APSA-2019-FWTHD-V3]
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Hamet P, 2017, METABOLISM, V69, pS36, DOI 10.1016/j.metabol.2017.01.011
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jain D, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106198
   Kaul V, 2020, GASTROINTEST ENDOSC, V92, P807, DOI 10.1016/j.gie.2020.06.040
   Lakshmi PS, 2018, IEEE XPLORE, DOI [10.1109/ICACCI.2018.8554914, DOI 10.1109/ICACCI.2018.8554914]
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Lockwood CJ, 2020, US
   Malone FD, 2003, OBSTET GYNECOL, V102, P1066, DOI 10.1016/j.obstetgynecol.2003.08.004
   Maqueda AI, 2018, PROC CVPR IEEE, P5419, DOI 10.1109/CVPR.2018.00568
   Marini L, 2021, J CLIN PERIODONTOL, V48, P205, DOI 10.1111/jcpe.13406
   Mnih V, 2014, ADV NEUR IN, V27
   Nie SQ, 2017, IEEE ENG MED BIO, P3417, DOI 10.1109/EMBC.2017.8037590
   Nie SQ, 2017, ULTRASOUND MED BIOL, V43, P286, DOI 10.1016/j.ultrasmedbio.2016.08.034
   Nie SQ, 2016, COMPUT ASSIST SURG, V21, P84, DOI 10.1080/24699322.2016.1240317
   Nie SQ, 2014, 2014 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING (ICALIP), VOLS 1-2, P681, DOI 10.1109/ICALIP.2014.7009881
   PANDYA PP, 1995, ULTRASOUND OBST GYN, V5, P15, DOI 10.1046/j.1469-0705.1995.05010015.x
   Papadopoulos A, 2021, ADV NEURAL INF PROCE, P34
   Peek N, 2015, ARTIF INTELL MED, V65, P61, DOI 10.1016/j.artmed.2015.07.003
   Peng YL, 2022, EUR J PEDIATR, V181, P3645, DOI 10.1007/s00431-022-04547-z
   [彭昱霖 Peng Yulin], 2021, [中华围产医学杂志, Chinese Journal of Perinatal Medicine], V24, P141
   Ramesh AN, 2004, ANN ROY COLL SURG, V86, P334, DOI 10.1308/147870804290
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Schlemper J, 2018, ARXIV
   Shailesh K, 2013, J OBSTET GYN INDIA, V63, P244, DOI 10.1007/s13224-012-0341-7
   Shen JL, 2021, INFORM SCIENCES, V569, P469, DOI 10.1016/j.ins.2020.11.026
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Thamizhvani TR, 2021, MULTIMED TOOLS APPL, V80, P12117, DOI 10.1007/s11042-020-10459-7
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Wang Q, 2020 IEEE CVF C COMP
   Whitlow BJ, 1998, BRIT J OBSTET GYNAEC, V105, P872, DOI 10.1111/j.1471-0528.1998.tb10232.x
   Xiao Yang, 2020, Journal of Physics: Conference Series, V1693, DOI 10.1088/1742-6596/1693/1/012173
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
NR 44
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 15629
EP 15648
DI 10.1007/s11042-023-15491-x
EA JUL 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001031485100003
DA 2024-07-18
ER

PT J
AU Ben Hamida, S
   Ben Hamida, S
   Snoun, A
   Jemai, O
   Jemai, A
AF Ben Hamida, Sameh
   Ben Hamida, Sana
   Snoun, Ahmed
   Jemai, Olfa
   Jemai, Abderrazek
TI The influence of dropout and residual connection against membership
   inference attacks on transformer model: a neuro generative disease case
   study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ML; Security and privacy; Transformer; MIA; Alzheimer; Dropout; Residual
   connection
AB Alzheimer's patients necessitate consistent support from caregivers or family members, highlighting the urgency for advanced technologies to aid in their daily lives through early disease detection. Consequently, there has been substantial research and development of machine learning-based systems aimed at assisting Alzheimer's patients. However, ensuring the protection of the sensitive and personal data utilized in these systems remains a critical concern. In this context, Membership Inference Attack poses a severe threat to the privacy of targeted models. This research focuses on enhancing the preservation of data privacy during the training phase. We conducted vulnerability testing on a Transformer deep-learning model against Membership Inference Attack and developed a defense strategy to mitigate its impact. To achieve this objective, we evaluated the studied attack on Transformer model using two datasets: DemCare and Oasis. These datasets contain sensitive and personal information, underscoring the need for their utmost protection. Subsequently, we proposed a defense strategy based on dropout and residual connections. Through comparative experiments, our proposed strategy demonstrated significant improvements (i.e. 20.97% and 18.43%) over the previous model, providing efficient results. Thus, we can confidently conclude that our defense approach enhances data privacy and effectively mitigates the impact of the analyzed attack.
C1 [Ben Hamida, Sameh; Ben Hamida, Sana] Higher Inst Technol Studies Gabes, STIC Dept, Route Medenine, Gabes 6011, Tunisia.
   [Ben Hamida, Sameh; Ben Hamida, Sana; Snoun, Ahmed; Jemai, Olfa] Univ Gabes, Natl Engn Sch Gabes ENIG, Res Team Intelligent Machines RTIM, Gabes 6029, Tunisia.
   [Snoun, Ahmed] UPHF, CNRS, UMR 8201, LAMIH, F-59313 Valenciennes, France.
   [Jemai, Abderrazek] Carthage Univ, Tunisia Polytech Sch, SERCOM Lab, Tunis 1080, Tunisia.
   [Jemai, Abderrazek] INSAT, Ctr Urbain Nord BP 676, Tunis 1080, Tunisia.
C3 Universite de Gabes; Centre National de la Recherche Scientifique
   (CNRS); Universite Polytechnique Hauts-de-France; Universite de
   Carthage; Universite de Carthage
RP Ben Hamida, S (corresponding author), Higher Inst Technol Studies Gabes, STIC Dept, Route Medenine, Gabes 6011, Tunisia.; Ben Hamida, S (corresponding author), Univ Gabes, Natl Engn Sch Gabes ENIG, Res Team Intelligent Machines RTIM, Gabes 6029, Tunisia.
EM benhamida_sameh@yahoo.fr; sana_benhamida@yahoo.fr;
   ahmed.snoun.3@gmail.com; olfa.jemai@isimg.tn; abderrazekjemai@gmail.com
RI Ben Hamida, Sana/HJZ-4805-2023
OI Ben Hamida, Sana/0000-0002-8840-7379
CR [Anonymous], GUID AUC ROC CURV MA
   Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Ben Hamida S, 2022, COMM COM INF SC, V1653, P661, DOI 10.1007/978-3-031-16210-7_54
   Ben Hamida S, 2022, CMC-COMPUT MATER CON, V70, P4897, DOI 10.32604/cmc.2022.019709
   Bentley JW, 2020, ARXIV
   Caruccio L, 2022, INFORM SCIENCES, V613, P1, DOI 10.1016/j.ins.2022.09.004
   De Gregorio Giuseppe, 2021, Pattern Recognition. ICPR 2020 International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12661), P559, DOI 10.1007/978-3-030-68763-2_43
   Diogo VS, 2022, ALZHEIMERS RES THER, V14, DOI 10.1186/s13195-022-01047-y
   Luptáková ID, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22051911
   Duca AL, 2021, ADVERSARIAL MACHINE
   Dwork C, 2017, ANNU REV STAT APPL, V4, P61, DOI 10.1146/annurev-statistics-060116-054123
   Ganju K, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P619, DOI 10.1145/3243734.3243834
   Gong XL, 2020, IEEE COMMUN MAG, V58, P83, DOI 10.1109/MCOM.001.2000196
   Gupta U, 2021, PR MACH LEARN RES, V143, P228
   Hayes J., 2017, ARXIV
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hendrycks D., 2016, ARXIV
   Homer N, 2008, PLOS GENET, V4, DOI 10.1371/journal.pgen.1000167
   Hu HS, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3523273
   Jain P., 2015, ARXIV
   Jarray Rimeh, 2021, Hybrid Intelligent Systems. 20th International Conference on Hybrid Intelligent Systems (HIS 2020). Advances in Intelligent Systems and Computing (AISC 1375), P484, DOI 10.1007/978-3-030-73050-5_49
   Karakostas A, 2016, ARXIV
   Kaur P, 2020, MED SCI LAW, V60, P131, DOI 10.1177/0025802419893168
   Liu Q, 2018, IEEE ACCESS, V6, P12103, DOI 10.1109/ACCESS.2018.2805680
   Liu YG, 2022, PROCEEDINGS OF THE 31ST USENIX SECURITY SYMPOSIUM, P4525
   Marcus DS, 2010, J COGNITIVE NEUROSCI, V22, P2677, DOI 10.1162/jocn.2009.21407
   Nasr M, 2019, P IEEE S SECUR PRIV, P739, DOI 10.1109/SP.2019.00065
   Praveen SP, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-25089-2
   Rajasekar V, 2021, ACTA POLYTECH HUNG, V18, P87
   Salem A., 2018, arXiv
   Sarker Iqbal H, 2021, SN Comput Sci, V2, P420, DOI 10.1007/s42979-021-00815-1
   Shamshad F, 2023, MED IMAGE ANAL, V88, DOI 10.1016/j.media.2023.102802
   Shokri R, 2017, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2017.41
   Snoun A, 2022, LECT NOTES ARTIF INT, V13501, P534, DOI 10.1007/978-3-031-16014-1_42
   Snoun A, 2023, NEURAL COMPUT APPL, V35, P1777, DOI 10.1007/s00521-022-07883-1
   Snoun A, 2021, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS (ICPRAM), P706, DOI 10.5220/0010895300003122
   Snoun A, 2021, MULTIMED TOOLS APPL, V80, P29675, DOI 10.1007/s11042-021-11188-1
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Song CZ, 2020, CCS '20: PROCEEDINGS OF THE 2020 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P377, DOI 10.1145/3372297.3417270
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Truex S, 2021, IEEE T SERV COMPUT, V14, P2073, DOI 10.1109/TSC.2019.2897554
   Ulhaq Anwaar, 2022, arXiv
   Vaswani A, 2017, ADV NEUR IN, V30
   Xiong R., 2020, INT C MACHINE LEARNI, P10524
NR 45
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16231
EP 16253
DI 10.1007/s11042-023-16126-x
EA JUL 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001027492600010
DA 2024-07-18
ER

PT J
AU Gavas, RD
   Das, M
   Ghosh, SK
   Pal, A
AF Gavas, Rahul Dasharath
   Das, Monidipa
   Ghosh, Soumya Kanti
   Pal, Arpan
TI Spatial-SMOTE for handling imbalance in spatial regression tasks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatial-SMOTE; Regression; Imbalance
ID CHALLENGES
AB Class imbalance in classification tasks leads to biased learning in the model training phase. In case of regression, the presence of rare cases over the normal cases in the target variable, also culminates in data imbalance. Since, the target variable is continuous in nature, the handling of imbalance in regression tasks is not straightforward when compared to that of classification tasks. Synthetic minority over-sampling technique (SMOTE) and its variants have been explored in upsampling rare events in imbalanced regression. These approaches solely rely on amplitude values of features and their nearest neighbours during the upsampling process. However, geo-tagged spatial data comes with an additional location information, i.e. latitude and longitude. This information needs to be incorporated during upsampling process in order to retain the spatial dependencies in the underlying data. We thus propose a new pipeline named, 'Spatial-SMOTE for regression', which deals with upsampling the rare events by retaining the significance of the spatial distribution of data. The effectiveness of this process is shown on two geo-tagged regression datasets for predicting the normal and the rare cases of the target variable. The performance of this pipeline is compared against closely related state-of-the-art methods. The upsampling approaches are tested exhaustively using different classifiers. It is found that the proposed 'Spatial-SMOTE for regression' method performs better with improvements in F-score as high as 11.55% and 16.9% for the two datasets used for the study. Factors affecting the misclassification errors in case of the proposed study is analysed in detail.
C1 [Gavas, Rahul Dasharath; Ghosh, Soumya Kanti] Indian Inst Technol Kharagpur, Dept Comp Sci & Engn, Kharagpur, India.
   [Gavas, Rahul Dasharath; Pal, Arpan] TCS Res, Bengaluru, India.
   [Das, Monidipa] Indian Sch Mines Dhanbad, Indian Inst Technol, Dept Comp Sci & Engn, Dhanbad, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (Indian School of Mines) Dhanbad
RP Gavas, RD (corresponding author), Indian Inst Technol Kharagpur, Dept Comp Sci & Engn, Kharagpur, India.; Gavas, RD (corresponding author), TCS Res, Bengaluru, India.
EM rahulgavas@kgpian.iitkgp.ac.in; monidipa_t@isical.ac.in;
   skg@cse.iitkgp.ac.in; arpan.pal@tcs.com
OI Gavas, Rahul Dasharath/0000-0002-1104-3466
CR Bhattacharjee S., 2019, Semantic Kriging for Spatio-Temporal Prediction, P19, DOI [DOI 10.1007/978-981-13-8664-0_2, 10.1007/978-981-13-8664-0_2]
   Branco P., 2018, Proceedings of the Second International Workshop on Learning with Imbalanced Domains: Theory and Applications, P67
   Branco P, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2907070
   Branco Paula, 2017, Proceedings of the First International Workshop on Learning with Imbalanced Domains: Theory and Applications, P36
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Duarte D., 2020, ISPRS ANN PHOTOGRAMM, V3-2020, P439, DOI [DOI 10.5194/ISPRS-ANNALS-V, 10.5194/isprs-annals-V-3-2020-439-2020]
   Feng F, 2023, MULTIMED TOOLS APPL, V82, P3231, DOI 10.1007/s11042-022-13240-0
   Fernández A, 2018, J ARTIF INTELL RES, V61, P863, DOI 10.1613/jair.1.11192
   Gavas R, 2021, PREMI 2021
   Ghosh K, 2021, IEEE INT CONF BIG DA, P4859, DOI 10.1109/BigData52589.2021.9672056
   Gyódi K, 2021, TOURISM MANAGE, V86, DOI 10.1016/j.tourman.2021.104319
   Japkowicz N., 2002, Intelligent Data Analysis, V6, P429
   Klemmer K, 2019, ARXIV
   Krawczyk B, 2016, PROG ARTIF INTELL, V5, P221, DOI 10.1007/s13748-016-0094-0
   Lu J, 2021, GEOINFORMATICA, P1
   Puri A, 2022, MULTIMED TOOLS APPL, P1
   Steininger M, 2021, MACH LEARN, V110, P2187, DOI 10.1007/s10994-021-06023-5
   Torgo L, 2007, LECT NOTES ARTIF INT, V4702, P597
   Torgo L, 2013, LECT NOTES ARTIF INT, V8154, P378, DOI 10.1007/978-3-642-40669-0_33
   Torgo L, 2009, LECT NOTES ARTIF INT, V5808, P332, DOI 10.1007/978-3-642-04747-3_26
   Xu M, 2005, REMOTE SENS ENVIRON, V97, P322, DOI 10.1016/j.rse.2005.05.008
NR 22
TC 3
Z9 3
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14111
EP 14132
DI 10.1007/s11042-023-15919-4
EA JUL 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001028770200009
DA 2024-07-18
ER

PT J
AU Zhou, LM
   Zhou, DM
   Yang, H
   Yang, SL
AF Zhou, Lianmin
   Zhou, Dongming
   Yang, Hao
   Yang, Shaoliang
TI Two-subnet network for real-world image denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Real-world; Deep learning; Fusion mechanism; Transfer
   learning
AB Previous researches in synthetic noise image denoising have performed well. However, while these methods remove real-world noise, they result in loss of image detail. To solve the problem, this article proposes a two-subnet network for real-world image denoising (TSIDNet). The proposed TSIDNet consists of two subnets, each subnet is designed with independent purpose. The data processing subnet is used to fit the current training data for denoising. We design a cross fusion module in data processing subnet to fuse the encoder information well and then pass the fusion result to the decoder. To decode the context well, we also design a residual attention block based on polarized self-attention as the decoder. The feature extracting subnet based on transfer learning is used to obtain global robust features of the degraded images. By fusing the information from both subnets, high-quality noise-free images can be obtained. Quantitative and qualitative experimental results on four real-world noisy datasets demonstrate the excellent generalization and denoising performance of our method.
C1 [Zhou, Lianmin; Zhou, Dongming; Yang, Hao; Yang, Shaoliang] Yunnan Univ, Sch Informat Sci & Engn, Kunming 650504, Peoples R China.
C3 Yunnan University
RP Zhou, DM (corresponding author), Yunnan Univ, Sch Informat Sci & Engn, Kunming 650504, Peoples R China.
EM zhou_lianmin@mail.ynu.edu.cn; zhoudm@ynu.edu.cn
RI Yang, Shaoliang/KFA-6014-2024
FU National Natural Science Foundation of China [62066047, 61365001];
   Yunnan University Postgraduate Practice Innovation Project [2021Y186]
FX AcknowledgementsThis work was supported in part by the National Natural
   Science Foundation of China under Grant 62066047 and Grant 61365001, in
   part by the Yunnan University Postgraduate Practice Innovation Project
   under Grant 2021Y186.
CR Abdelhamed A, 2018, PROC CVPR IEEE, P1692, DOI 10.1109/CVPR.2018.00182
   Anwar S, 2019, IEEE I CONF COMP VIS, P3155, DOI 10.1109/ICCV.2019.00325
   Bedi AK, 2022, MULTIMED TOOLS APPL, V81, P7873, DOI 10.1007/s11042-022-12050-8
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Burger H., 2012, CVPR
   Chen R, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108349
   Chen X, 2022, IEEE ACCESS
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Fan ZK, 2022, KNOWL-BASED SYST, V239, DOI 10.1016/j.knosys.2021.107968
   Fu B, 2023, J BIOMAT SCI-POLYM E, V34, P89, DOI 10.1080/09205063.2022.2111651
   Fu B, 2022, GENE EXPR PATTERNS, V45, DOI 10.1016/j.gep.2022.119270
   Fu B, 2023, SIGNAL IMAGE VIDEO P, V17, P573, DOI 10.1007/s11760-022-02262-8
   Fu B, 2022, INT J IMAG SYST TECH, V32, P144, DOI 10.1002/ima.22658
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Guo S, 2019, PROC CVPR IEEE, P1712, DOI 10.1109/CVPR.2019.00181
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huo FC, 2021, MULTIMED TOOLS APPL, V80, P14101, DOI 10.1007/s11042-020-10428-0
   Incetas MO, 2022, MULTIMED TOOLS APPL, V81, P33291, DOI 10.1007/s11042-022-13096-4
   Jain V, 2007, IEEE I CONF COMP VIS, P636
   Jang G, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2330, DOI 10.1109/ICCV48922.2021.00235
   Kim Y, 2020, PROC CVPR IEEE, P3479, DOI 10.1109/CVPR42600.2020.00354
   Kumar S, 2022, J INF SECUR APPL, V64, DOI 10.1016/j.jisa.2021.103063
   Lebrun M, 2015, IMAGE PROCESS ON LIN, V5, P1, DOI 10.5201/ipol.2015.125
   Liu H, 2021, PHYS REV LETT, V126, DOI 10.1103/PhysRevLett.126.250502
   Liu YD, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3365, DOI 10.1145/3447548.3467149
   Liu Z., 2022, ARXIV
   Liu Zhe, 2022, MULTIMEDIA SYSTEMS, P2
   Mou C., 2021, IEEE T MULTIMEDIA
   Plötz T, 2017, PROC CVPR IEEE, P2750, DOI 10.1109/CVPR.2017.294
   Ren C, 2021, PROC CVPR IEEE, P8592, DOI 10.1109/CVPR46437.2021.00849
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Setiadi DIM, 2021, MULTIMED TOOLS APPL, V80, P8423, DOI 10.1007/s11042-020-10035-z
   Soh JW, 2021, INT C PATT RECOG, P747, DOI 10.1109/ICPR48806.2021.9412605
   Sun Y, 2022, SIGNAL IMAGE VIDEO, VP, P1
   Sun ZY, 2022, ISPRS INT J GEO-INF, V11, DOI 10.3390/ijgi11030165
   Vo DM, 2021, INFORM SCIENCES, V570, P225, DOI 10.1016/j.ins.2021.04.045
   Woo S., 2018, P EUR C COMP VIS ECC, DOI DOI 10.1007/978-3-030-01234-2_1
   Xie Junyuan, 2012, ADV NEURAL INFORM PR, P341, DOI [DOI 10.5555/2999134.2999173, DOI 10.1109/AGRO-GEOINFORMATICS.2012.6311605]
   Xu J, 2018, ARXIV
   Yan XY, 2022, IEEE WINT CONF APPL, P3270, DOI 10.1109/WACV51458.2022.00333
   Yu S, 2019, IEEE COMPUT SOC CONF, P2095, DOI 10.1109/CVPRW.2019.00262
   Yue ZS, 2019, ADV NEUR IN, V32
   Zaghloul R, 2022, MULTIMED TOOLS APPL, P1
   Zamir Syed Waqas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P492, DOI 10.1007/978-3-030-58595-2_30
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zongsheng Yue, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P41, DOI 10.1007/978-3-030-58607-2_3
NR 48
TC 1
Z9 1
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14757
EP 14773
DI 10.1007/s11042-023-16153-8
EA JUL 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001025717900001
DA 2024-07-18
ER

PT J
AU Mehmood, AB
   Taj, IA
   Ghafoor, M
AF Mehmood, Ahmed Bilal
   Taj, Imtiaz A. A.
   Ghafoor, Mubeen
TI Palmprint enhancement network (<i>PEN</i>) for robust identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Convolutional neural networks; Biometrics; Palmprints
ID FINGERPRINT; ALGORITHM
AB Despite being reliable, palmprints have not received as much attention as other biometrics such as fingerprints, face or iris. Amount of information provided by high resolution palmprints and the fact that they have huge forensic value makes them a preferred biometric choice for large scale identification systems. In palmprints, extraction of reliable features for identification is still a challenging task especially because most of palmprints found in the real world, e.g., in crime scenes, are of poor quality. This makes palmprint enhancement a crucial pre cursor to identification. Errors during enhancement result in extraction of un-reliable features which deteriorate identification accuracy. Recent works in palmprints have focused more on matching algorithms and limited novelty has been introduced in enhancement. Enhancement techniques used on high resolution palmprints recently are either borrowed from fingerprint techniques or are built on the high-risk assumption that palm ridge pattern is stationary or smooth in a local area. Large size and abruptly changing ridge pattern of palmprints dictates the need for a more robust enhancement scheme. This paper proposes a novel deep learning based high resolution palmprint enhancement approach that is able to process large areas of palmprint without making the assumption that underlying ridge pattern is stationary. We have tested proposed enhancement approach on a renowned high resolution palmprint dataset which shows that proposed technique performs favourably in comparison to state of the art.
C1 [Mehmood, Ahmed Bilal; Taj, Imtiaz A. A.] Capital Univ Sci & Technol, Elect Engn Dept, Islamabad, Pakistan.
   [Ghafoor, Mubeen] Univ Lincoln, Sch Comp Sci, Lincoln, England.
C3 Capital University of Science & Technology; University of Lincoln
RP Ghafoor, M (corresponding author), Univ Lincoln, Sch Comp Sci, Lincoln, England.
EM abm.1336@gmail.com; imtiaztaj@cust.edu.pk; mghafoor@lincoln.ac.uk
OI Taj, Imtiaz Ahmad/0000-0003-1813-5563
CR Ahmad MI, 2016, NEUROCOMPUTING, V177, P49, DOI 10.1016/j.neucom.2015.11.003
   Ahmadi M, 2019, ARXIV
   Attia A, 2022, MULTIMED TOOLS APPL, V81, P10961, DOI 10.1007/s11042-022-12384-3
   Badrinarayanan V., 2015, SEGNET DEEP CONVOLUT
   Barra S, 2019, MULTIMED TOOLS APPL, V78, P14045, DOI 10.1007/s11042-019-7156-9
   Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191
   Cao K, 2015, INT CONF BIOMETR, P349, DOI 10.1109/ICB.2015.7139060
   Cappelli R., 2012, PART B CYBERNETICS, V42, P956, DOI [10.1109/TSMCB.2012.2183635, DOI 10.1109/TSMCB.2012.2183635]
   Chikkerur S, 2007, PATTERN RECOGN, V40, P198, DOI 10.1016/j.patcog.2006.05.036
   Chou CR, 2013, COMPUT VIS IMAGE UND, V117, P1095, DOI 10.1016/j.cviu.2013.02.009
   Dai JF, 2012, IEEE T PATTERN ANAL, V34, P1618, DOI 10.1109/TPAMI.2011.237
   Dai JF, 2011, IEEE T PATTERN ANAL, V33, P945, DOI 10.1109/TPAMI.2010.164
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fahmy MF, 2013, IEEE INT S SIGN PROC
   Ghafoor M, 2020, IET IMAGE PROCESS, V14, P2333, DOI 10.1049/iet-ipr.2018.5736
   Ghafoor M, 2021, IEEE T CYBERNETICS, V51, P4515, DOI 10.1109/TCYB.2019.2957188
   Ghafoor M, 2016, IET COMPUT VIS, V10, P806, DOI 10.1049/iet-cvi.2016.0005
   Ghafoor M, 2014, IET IMAGE PROCESS, V8, P417, DOI 10.1049/iet-ipr.2013.0528
   Hao FC, 2020, MULTIMED TOOLS APPL, V79, P12915, DOI 10.1007/s11042-020-08625-y
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   Hussein IS, 2020, IEEE ACCESS, V8, P56113, DOI 10.1109/ACCESS.2020.2982048
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Jain AK, 2009, IEEE T PATTERN ANAL, V31, P1032, DOI 10.1109/TPAMI.2008.242
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Justina A, 2022, BIOMETRIC AUTHENTICA
   Khodadoust J, 2022, EXPERT SYST APPL, V206, DOI 10.1016/j.eswa.2022.117806
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li HJ, 2020, MULTIMED TOOLS APPL, V79, P11947, DOI 10.1007/s11042-019-08446-8
   Li J, 2018, SIGNAL PROCESS-IMAGE, V60, P52, DOI 10.1016/j.image.2017.08.010
   Liu B, 2021, NEUROCOMPUTING, V438, P1, DOI 10.1016/j.neucom.2021.01.049
   Liu XB, 2016, IEEE IMAGE PROC, P1289, DOI 10.1109/ICIP.2016.7532566
   Maltoni D., 2009, Handbook of fingerprint recognition, V2
   Mao XJ, 2016, ADV NEUR IN, V29
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   RATHA NK, 1995, PATTERN RECOGN, V28, P1657, DOI 10.1016/0031-3203(95)00039-3
   Researchnester, 2022, PALM REC BIOM MARK S
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Soleimani H, 2018, IET BIOMETRICS, V7, P573, DOI 10.1049/iet-bmt.2017.0128
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tariq SA, 2019, CLUSTER COMPUT, P1
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26, DOI DOI 10.1007/S12654-012-0173-1
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Wyzykowski ABV, 2021, INT C PATT RECOG, P9250, DOI 10.1109/ICPR48806.2021.9412304
   Wilson C. L., 1994, Journal of Artificial Neural Networks, V1, P203
   Wong WJ, 2020, PATTERN RECOGN, V101, DOI 10.1016/j.patcog.2020.107203
NR 48
TC 1
Z9 1
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14449
EP 14476
DI 10.1007/s11042-023-16043-z
EA JUL 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001021388000001
OA hybrid
DA 2024-07-18
ER

PT J
AU Lovanshi, M
   Tiwari, V
AF Lovanshi, Mayank
   Tiwari, Vivek
TI Human skeleton pose and spatio-temporal feature-based activity
   recognition using ST-GCN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Activity recognition; Pose estimation; ST-GCN; Spatio-temporal feature;
   Skeleton joints
ID SPATIAL-DISTRIBUTION; UNIFIED FRAMEWORK; GRADIENTS; MODEL
AB Skeleton-based Human Activity Recognition has recently sparked a lot of attention because skeleton data has proven resistant to changes in lighting, body sizes, dynamic camera perspectives, and complicated backgrounds. The Spatial-Temporal Graph Convolutional Networks (ST-GCN) model has been exposed to study spatial and temporal dependencies effectively from skeleton data. However, efficient use of 3D skeleton in-depth information remains a significant challenge, specifically for human joint motion patterns and linkages information. This study attempts a promising solution through a custom ST-GCN model and skeleton joints for human activity recognition. Special attention was given to spatial & temporal features, which were further fed to the classification model for better pose estimation. A comparative study is presented for activity recognition using large-scale databases such as NTU-RGB-D, Kinetics-Skeleton, and Florence 3D datasets. The Custom ST-GCN model outperforms (Top-1 accuracy) the state-of-the-art method on NTU-RGB-D, Kinetics-Skeleton & Florence 3D dataset with a higher margin by 0.7%, 1.25%, and 1.92%, respectively. Similarly, with Top-5 accuracy, the Custom ST-GCN model offers results hike by 0.5%, 0.73% & 1.52%, respectively. It shows that the presented graph-based topologies capture the changing aspects of a motion-based skeleton sequence better than some of the other approaches.
C1 [Lovanshi, Mayank; Tiwari, Vivek] Int Inst Informat Technol IIIT, Naya Raipur, India.
   [Tiwari, Vivek] ABV Indian Inst Informat Technol & Management, Gwalior, India.
C3 ABV-Indian Institute of Information Technology & Management, Gwalior
RP Tiwari, V (corresponding author), Int Inst Informat Technol IIIT, Naya Raipur, India.; Tiwari, V (corresponding author), ABV Indian Inst Informat Technol & Management, Gwalior, India.
EM viveknitbpl@gmail.com
OI Lovanshi, Mayank/0000-0002-3136-4873
CR Agahian S, 2020, ENG SCI TECHNOL, V23, P196, DOI 10.1016/j.jestch.2019.04.014
   Al-Janabi S, 2021, BIG DATA MIN ANAL, V4, P124, DOI 10.26599/BDMA.2020.9020022
   Avola D, 2019, J BIOMED INFORM, V89, P81, DOI 10.1016/j.jbi.2018.11.012
   Cao X, 2019, UBICOMP/ISWC'19 ADJUNCT: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2019 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P689, DOI 10.1145/3341162.3345581
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen X, 2015, NEUROCOMPUTING, V149, P387, DOI 10.1016/j.neucom.2013.10.046
   Chunduru V, 2021, 2021 IEEE 9 REGION 1, P1, DOI DOI 10.1109/R10-HTC53172.2021.9641587
   Devanne M, 2015, FGW, V7, P1
   Dhiman C, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3441628
   Dhiman C, 2020, IEEE T IMAGE PROCESS, V29, P3835, DOI 10.1109/TIP.2020.2965299
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176
   Hbali Y, 2018, IET COMPUT VIS, V12, P16, DOI 10.1049/iet-cvi.2017.0062
   Kay W., 2017, CORR ABS170506950
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Lea C, 2017, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2017.113
   Li CL, 2018, AAAI CONF ARTIF INTE, P3482
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Mukherjee S, 2020, MULTIMED TOOLS APPL, V79, P19787, DOI 10.1007/s11042-020-08747-3
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1969
   Patel AS, 2023, VISUAL COMPUT, V39, P2127, DOI 10.1007/s00371-022-02469-3
   Patnaik SK, 2021, BIG DATA MIN ANAL, V4, P279, DOI 10.26599/BDMA.2021.9020012
   Pawar K, 2019, ADV INTELL SYST, V841, P493, DOI 10.1007/978-981-13-2285-3_58
   Seidenari L, 2013, LECT NOTES COMPUT SC, V8158, P446, DOI 10.1007/978-3-642-41190-8_48
   Setiawan F, 2022, EXPERT SYST APPL, V195, DOI 10.1016/j.eswa.2022.116566
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Singh T, 2021, NEURAL COMPUT APPL, V33, P469, DOI 10.1007/s00521-020-05018-y
   Snoun A, 2021, MULTIMED TOOLS APPL, V80, P29675, DOI 10.1007/s11042-021-11188-1
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Tania S., 2016, INT J SIGNAL PROCESS, V9, P113, DOI [10.14257/ijsip.2016.9.3.10, DOI 10.14257/IJSIP.2016.9.3.10]
   Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Vishwakarma D., 2017, Int. J. Comput. Vis. Robot., V7, P454, DOI 10.1504/IJCVR.2017.084991
   Vishwakarma DK, 2016, AEU-INT J ELECTRON C, V70, P341, DOI 10.1016/j.aeue.2015.12.016
   Vishwakarma DK, 2015, ADV ROBOTICS, V29, DOI 10.1080/01691864.2015.1061701
   Vishwakarma DK, 2015, PROCEDIA COMPUT SCI, V57, P630, DOI 10.1016/j.procs.2015.07.425
   Vishwakarma DK, 2015, PROCEDIA COMPUT SCI, V57, P438, DOI 10.1016/j.procs.2015.07.515
   Vishwakarma D. K., 2012, 4 INT C INTELLIGENT, P1, DOI DOI 10.1109/IHCI.2012.6481804
   Vishwakarma DK, 2016, ROBOT AUTON SYST, V77, P25, DOI 10.1016/j.robot.2015.11.013
   Vishwakarma DK, 2022, ETRI J, V44, P286, DOI 10.4218/etrij.2020-0101
   Vishwakarma DK, 2019, VISUAL COMPUT, V35, P1595, DOI 10.1007/s00371-018-1560-4
   Vishwakarma DK, 2017, IEEE T COGN DEV SYST, V9, P316, DOI 10.1109/TCDS.2016.2577044
   Vrigkas M, 2015, FRONT ROBOT AI, DOI 10.3389/frobt.2015.00028
   Wan SH, 2020, MOBILE NETW APPL, V25, P743, DOI 10.1007/s11036-019-01445-x
   WANG QY, 2022, IEEE ACCESS, V10, P41403, DOI 10.1109/ACCESS.2022.3164711
   Wang X, 2021, 2021 IEEE GLOBAL COM, P1
   Yadav A, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106624
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang YH, 2017, IEEE T MULTIMEDIA, V19, P519, DOI 10.1109/TMM.2016.2626959
   Yin J, 2019, BIOMED CIRC SYST C, DOI 10.1109/biocas.2019.8919127
   Yu Guan, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3090076
   Yu Y, 2019, BIG DATA MIN ANAL, V2, P288, DOI 10.26599/BDMA.2019.9020007
NR 53
TC 2
Z9 2
U1 15
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 12705
EP 12730
DI 10.1007/s11042-023-16001-9
EA JUN 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001022083300002
DA 2024-07-18
ER

PT J
AU Gautam, V
   Ranjan, RK
   Dahiya, P
   Kumar, A
AF Gautam, Vinay
   Ranjan, Ranjeet Kumar
   Dahiya, Priyanka
   Kumar, Anil
TI ESDNN: A novel ensembled stack deep neural network for mango leaf
   disease classification and detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Convolutional Neural Network; Ensemble Learning; Image
   processing; Leaf disease detection
AB The mango crop production and quality are affected by several factors. Plant disease is one of the prime factors that impact crop yield. The disease impacts all parts of plants such as leaves, roots, and stems. Farmers waste most of their energy, time, and effort dealing with it manually and lead to heavy loss in the yield of the crops. Mango production is affected by several types of diseases. Prior recognition of disease would ease and reduce the diagnostic process that enhances the production of quality crops. A huge investigation has been carried out in the field of identifying and classifying leaf disease. Hence, an appropriate artificial intelligence (AI) based solution is needed to support farmers. The objective of the work is to provide an effective and efficient AI-based solution to detect and classify leaf disease earlier. Earlier disease detection in crops is the most prominent way to prevent loss of money and time. The plant leaf image is mainly used as a source to detect disease in the plant. This paper employs an ensemble stacked deep learning model to resolve the problem of automatic identification of mango-leaf diseases. In the proposed approach, initially, the images are segmented for the region of interest and input to a stack of various deep neural networks. The outcome of the deep neural network is aggregated with a machine learning model to identify leaf disease. This model is used to identify various mango leaf diseases such as Powdery mildew, Anthracnose, etc. In the experiment, the deep learning models are stacked and aggregated with machine learning to identify mango leaf diseases. The proposed model is compared with state-of-the-art models and outperforms with 98.57% accuracy.
C1 [Gautam, Vinay] Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
   [Ranjan, Ranjeet Kumar] Thapar Inst Engn & Technol, CSE Dept, Patiala, India.
   [Dahiya, Priyanka; Kumar, Anil] DIT Univ, Sch Comp, Data Sci Res Grp, Dehra Dun, India.
C3 Chitkara University, Punjab; Thapar Institute of Engineering &
   Technology; DIT University
RP Kumar, A (corresponding author), DIT Univ, Sch Comp, Data Sci Res Grp, Dehra Dun, India.
EM dahiyaanil@yahoo.com
RI Gautam, Vinay/ABF-6124-2020; Ranjan, Ranjeet Kumar/AAQ-4566-2021; Kumar,
   Anil/F-8777-2011; Kumar, Anil/AAX-3222-2020
OI Gautam, Vinay/0000-0002-0258-5132; Ranjan, Ranjeet
   Kumar/0000-0002-8796-4579; Kumar, Anil/0000-0003-4699-3178; Kumar,
   Anil/0000-0003-0982-9424
CR Abdulridha J, 2016, AGRICULTURE-BASEL, V6, DOI 10.3390/agriculture6040056
   Al Bashish Dheeb, 2011, Information Technology Journal, V10, P267, DOI 10.3923/itj.2011.267.275
   Anand R, 2016, INT CONF RECENT
   Arivazhagan S., 2013, Agricultural Engineering International: CIGR Journal, V15, P211
   Arivazhagan S., 2018, INT J PURE APPL MATH, V120, P11067
   Dhaware C. G., 2017, 2017 INT C COMP COMM, P1
   Esgario JGM, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2019.105162
   Francis J, 2016, 2016 CONFERENCE ON EMERGING DEVICES AND SMART SYSTEMS (ICEDSS), P161
   Ganatra N, 2020, APPL MULTICLASS CLAS
   Gautam V, 2022, MATER TODAY-PROC
   Gautam V, 2022, INTELL AUTOM SOFT CO, V34, P849, DOI 10.32604/iasc.2022.025113
   Geetha G., 2020, Journal of Physics: Conference Series, V1712, DOI 10.1088/1742-6596/1712/1/012012
   Gupta A, 2019, COMPUT SCI-AGH, V20, P389, DOI 10.7494/csci.2019.20.4.3163
   Jadhav Sachin B., 2021, International Journal of Information Technology, P2461, DOI 10.1007/s41870-020-00437-5
   Kajale RR., 2015, INT J ENGIN RES GEN, V3, P6
   Kaur Prabhjot, 2021, Proceedings of 3rd International Conference on Computing Informatics and Networks. ICCIN 2020. Lecture Notes in Networks and Systems (LNNS 167), P597, DOI 10.1007/978-981-15-9712-1_51
   Kaur P, 2021, COMP PERFORMANCE ANA
   Kaur P, 2021, MATER TODAY-PROC, V45, P4377, DOI 10.1016/j.matpr.2020.11.198
   Khirade SD, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P768, DOI 10.1109/ICCUBEA.2015.153
   Korkut UB, 2018, 2018 26 SIGNAL PROCE, P1, DOI DOI 10.1109/SIU.2018.8404692
   Krishnan M, 2013, 2013 IEEE MALAYSIA INTERNATIONAL CONFERENCE ON COMMUNICATIONS (MICC), P474, DOI 10.1109/MICC.2013.6805876
   Lawrence GW, 2004, NEMATOL MONOGR PERSP, V2, P13
   Li Bo Li Bo, 2009, Transactions of the Chinese Society of Agricultural Engineering, V25, P143
   Li G, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/9982305
   Ma JunCheng Ma JunCheng, 2019, Information Processing in Agriculture, V6, P216, DOI 10.1016/j.inpa.2018.08.010
   Maheshwari K, PERFORMANCE ANAL MAN
   Maheshwari K., 2020, REV MANGO LEAF DIS I
   Mia MR., 2020, IRAN J COMPUTER SCI, V3, P185, DOI DOI 10.1007/S42044-020-00057-Z
   Mishra S., 2021, ANN ROMANIAN SOC CEL, V25, P1982
   Mohanty S. P., 2016, Frontiers in Plant Science, V7, P1419
   Moshou D, 2004, COMPUT ELECTRON AGR, V44, P173, DOI 10.1016/j.compag.2004.04.003
   Mukhopadhyay S, 2021, MULTIMED TOOLS APPL, V80, P753, DOI 10.1007/s11042-020-09567-1
   Nazki H, 2020, COMPUT ELECTRON AGR, V168, DOI 10.1016/j.compag.2019.105117
   Nikam R, 2015, NATL C EMERGING TRAN
   Patidar S., 2020, MACHINE LEARNING IMA, V1240, P278, DOI 10.1007/978- 981-15- 6315-7_23
   Prabu M, 2022, NEURAL COMPUT APPL, V34, P7311, DOI 10.1007/s00521-021-06726-9
   Prakash RM, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN INFORMATION, EMBEDDED AND COMMUNICATION SYSTEMS (ICIIECS)
   Ranjan M., 2015, International journal of technical research and applications, V3, P331
   Rumpf T, 2010, COMPUT ELECTRON AGR, V74, P91, DOI 10.1016/j.compag.2010.06.009
   Samajpati BJ, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1015, DOI 10.1109/ICCSP.2016.7754302
   Sharath D. M., 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0645, DOI 10.1109/ICCSP.2019.8698007
   Sharma S., 2020, INT J INTELLIGENCE S, V1, P101
   Shergill D., 2015, INT J ENG SCI RES TE, V1, P135
   Singh UP, 2019, IEEE ACCESS, V7, P43721, DOI 10.1109/ACCESS.2019.2907383
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Suryanarayana G, 2021, IEEE ACCESS, V9, P71406, DOI 10.1109/ACCESS.2021.3077611
   Pham TN, 2020, IEEE ACCESS, V8, P189960, DOI 10.1109/ACCESS.2020.3031914
   Tlhobogang B, 2018, PROCEEDINGS OF 4TH IEEE INTERNATIONAL CONFERENCE ON APPLIED SYSTEM INNOVATION 2018 ( IEEE ICASI 2018 ), P158, DOI 10.1109/ICASI.2018.8394556
   Trivedi M., 2021, INT J APPL SCI ENG, V18, P1, DOI [DOI 10.6703/IJASE.202106_18(2).003, 10.6703/IJASE.202106_18(2).003]
   Trivedi NK, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21237987
   Ullagaddi S.B., 2017, 2017 4 INT C ADV COM, P1
   Vallova S, 2022, J THERM ANAL CALORIM, V147, P1973, DOI 10.1007/s10973-021-10591-y
   Velmurugan P., 2017, ARTIF INTELL SYST MA, V9, P8
   Warne PP., 2015, International Research Journal of Engineering and Technology (IRJET), V2, P425
NR 55
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10989
EP 11015
DI 10.1007/s11042-023-16012-6
EA JUN 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016469800002
DA 2024-07-18
ER

PT J
AU Ceyhan, M
   Kartal, Y
   Özkan, K
   Seke, E
AF Ceyhan, Merve
   Kartal, Yusuf
   Ozkan, Kemal
   Seke, Erol
TI Classification of wheat varieties with image-based deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hard-white wheat; Hard-red wheat; Reflectance; Near-infrared; NIR;
   classification
ID SPECTROSCOPY; IDENTIFICATION; ARCHITECTURE; REFLECTANCE; BRANCHES;
   KERNELS; MODELS; FRUIT
AB Wheat is an important grain in the food chain. It is important in terms of efficiency and economy to use wheat in the appropriate area according to its varieties. Breeding studies make varieties of wheat physically similar to each other and make it difficult to classify according to variety. An image-based deep learning approach is proposed to classify wheat accurately and reduce classification difficulties. Twenty-four varieties of wheat were used in the study and these varieties were harvested in five provinces of Turkey. The reflectance values of the wheat varieties were measured with a near-infrared spectrometer device and the measured reflectance values were used to create wheat images with a suggested method. With this method, low-dimensional images were created with reflection data that take up less space instead of a high-resolution image and a high-storage space requirement. With the classification processes, a 96.55% accuracy was obtained for the hard-white wheat class, 98.70% for the hard-red wheat class and 99.52% for all wheat varieties. The results show that the proposed image generation method with reflection data and the deep learning model is sufficient in classification. This method offers a new approach to the classification of wheat-like cereals. The proposed method can be considered an alternative classification method in the wheat production and trading sectors. It can also be used in the industry by integrating it into hardware with low memory/low processing power. This scenario can also be considered as a method for classifying grain groups other than wheat.
C1 [Ceyhan, Merve; Kartal, Yusuf; Ozkan, Kemal] Eskisehir Osmangazi Univ, Dept Comp Engn, Eskisehir, Turkiye.
   [Seke, Erol] Eskisehir Osmangazi Univ, Dept Elect & Elect Engn, Eskisehir, Turkiye.
C3 Eskisehir Osmangazi University; Eskisehir Osmangazi University
RP Ceyhan, M (corresponding author), Eskisehir Osmangazi Univ, Dept Comp Engn, Eskisehir, Turkiye.
EM mceyhan@ogu.edu.tr; ykartal@ogu.edu.tr; kozkan@ogu.edu.tr;
   eseke@ogu.edu.tr
OI ozkan, kemal/0000-0003-2252-2128; KARTAL, YUSUF/0000-0002-0402-1701;
   Seke, Erol/0000-0002-4860-7130; Ceyhan, Merve/0000-0003-0733-3652
FU TUBITAK [1200226]
FX AcknowledgementsThis project was financially supported by TUBITAK:
   Number 1200226.
CR Affonso C, 2017, EXPERT SYST APPL, V85, P114, DOI 10.1016/j.eswa.2017.05.039
   Ahmad S., 2014, International Journal of Science Inventions Today, V3, P169
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Amatya S, 2016, BIOSYST ENG, V146, P3, DOI 10.1016/j.biosystemseng.2015.10.003
   Ambati LS., 2019, J MIDWEST ASS INF SY, V2021, P49, DOI DOI 10.17705/3JMWA.000065
   [Anonymous], 2002, BREAD WHEAT IMPROVEM
   [Anonymous], 2023, UCI Machine Learning Repository
   Blanco M, 2002, TRAC-TREND ANAL CHEM, V21, P240, DOI 10.1016/S0165-9936(02)00404-1
   Bushuk W., 1997, Wheat: prospects for global improvement. Proceedings of the 5th International Wheat Conference, Ankara, Turkey, 10-14 June 1996., P203
   Cassells JA, 2007, J NEAR INFRARED SPEC, V15, P161, DOI 10.1255/jnirs.727
   Curtis BC, 2002, BREAD WHEAT WHEAT WO
   David E, 2020, PLANT PHENOMICS, V2020, DOI 10.34133/2020/3521852
   Deléglise H, 2022, EXPERT SYST APPL, V190, DOI 10.1016/j.eswa.2021.116189
   DLP NIRscan Nano, 2017, DLP NIRSCAN NAN US G
   Druzhkov P. N., 2016, Pattern Recognition and Image Analysis, V26, P9, DOI 10.1134/S1054661816010065
   Dziki D., 2005, Acta Agrophysica, V6, P59
   Ebrahimi MA, 2017, COMPUT ELECTRON AGR, V137, P52, DOI 10.1016/j.compag.2017.03.016
   Elmasry G, 2012, CRIT REV FOOD SCI, V52, P999, DOI 10.1080/10408398.2010.543495
   Feng Z, 2021, LIGHT-SCI APPL, V10, DOI 10.1038/s41377-021-00628-0
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Helguera M., 2020, Wheat Quality For Improving Processing And Human Health, P273, DOI 10.1007/978-3-030-34163-3_12
   Ichwana I, 2020, INMATEH-AGRIC ENG, V60, P233, DOI 10.35633/inmateh-60-26
   Isik S, 2022, IET IMAGE PROCESS, V16, P2834, DOI 10.1049/ipr2.12206
   Islam N, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11050387
   Jin XJ, 2022, PEST MANAG SCI, V78, P1861, DOI 10.1002/ps.6804
   Karaduman Y, 2020, RES J BIOL SCI, V13
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kujawa S, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11060497
   Lingwal S, 2021, MULTIMED TOOLS APPL, V80, P35441, DOI 10.1007/s11042-020-10174-3
   Liu JY, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/3769670
   Madhavan J., 2023, Materials Today: Proceedings, P341, DOI 10.1016/j.matpr.2021.03.226
   Mang Xu X, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2001.01306
   Nematzadeh S, 2022, COMPUT BIOL CHEM, V97, DOI 10.1016/j.compbiolchem.2021.107619
   Optics E, 2022, WHAT IS SWIR
   OZKAN K, 2019, SCI FOOD AGR, DOI DOI 10.1002/JSFA.9732
   Pantazi XE, 2017, PRECIS AGRIC, V18, P383, DOI 10.1007/s11119-017-9507-8
   Prajna U, 2021, Sparklinglight Transactions on Artificial Intelligence and Quantum Computing, V1, P41, DOI [10.55011/STAIQC.2021.1105, DOI 10.55011/STAIQC.2021.1105, 10.55011/staiqc.2021.1105]
   Rahman A., 2015, Pakistan Journal of Life and Social Sciences, V13, P1
   RAMLAKHAN S, 2022, MACHINE LEARNING DEE, V39, P380, DOI DOI 10.1136/EMERMED-2021-212068
   Ramos PJ, 2017, COMPUT ELECTRON AGR, V137, P9, DOI 10.1016/j.compag.2017.03.010
   Ridgway C, 1999, J NEAR INFRARED SPEC, V7, P213, DOI 10.1255/jnirs.251
   Rubinger L, 2023, INJURY, V54, pS69, DOI 10.1016/j.injury.2022.01.046
   Sabanci K, 2017, J SCI FOOD AGR, V97, P3994, DOI 10.1002/jsfa.8264
   Sabanci K, 2017, J SCI FOOD AGR, V97, P2588, DOI 10.1002/jsfa.8080
   Saleem MH, 2021, PRECIS AGRIC, V22, P2053, DOI 10.1007/s11119-021-09806-x
   Selvi MS, 2022, CYBER PHYS SYSTEMS I, P225
   Sengupta S, 2014, BIOSYST ENG, V117, P51, DOI 10.1016/j.biosystemseng.2013.07.007
   Senthilnath J, 2016, BIOSYST ENG, V146, P16, DOI 10.1016/j.biosystemseng.2015.12.003
   Sethy PK, 2022, MULTIMED TOOLS APPL, V81, P8309, DOI 10.1007/s11042-022-12286-4
   Shamtsyan M, 2022, ROBOTICS MACHINERY E
   Shewry PR, 2009, J EXP BOT, V60, P1537, DOI 10.1093/jxb/erp058
   Singh M, 2022, CURR SCI INDIA, V122, P1019, DOI 10.18520/cs/v122/i9/1019-1030
   Suprapto PK, 2022, INT J MULTIDISCIPLIN, V3, P571, DOI [10.11594/ijmaber, DOI 10.11594/IJMABER]
   Texas Instruments DLP&REG; NIRscan&TRADE, 2016, NAN MOD EVM OPT DES
   Vincent B., 2021, NEAR INFRARED SPECTR, P331, DOI [DOI 10.1007/978-981-15-8648-4_14, 10.1007/978-981-15-8648-414]
   Vinogradov AN, 2017, J OPT TECHNOL+, V84, P683, DOI 10.1364/JOT.84.000683
   Visual Geometry Group, 2023, U OXF
   Wang CY, 2021, ARTIF INTELL REV, V54, P5205, DOI 10.1007/s10462-021-10018-y
   Xia Y, 2019, IEEE ACCESS, V7, P179199, DOI 10.1109/ACCESS.2019.2959028
   Yang XJ, 2021, BIOSYST ENG, V208, P176, DOI 10.1016/j.biosystemseng.2021.05.016
   Zhang DY, 2020, SPECTROCHIM ACTA A, V236, DOI 10.1016/j.saa.2020.118344
   Zhang JY, 2021, INT J DISTRIB SENS N, V17, DOI 10.1177/15501477211007407
NR 62
TC 4
Z9 4
U1 7
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 9597
EP 9619
DI 10.1007/s11042-023-16075-5
EA JUN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001014722500008
DA 2024-07-18
ER

PT J
AU Gao, JQ
   Li, L
   Ren, XD
   Chen, Q
   Abdul-Abbass, YM
AF Gao, Jianqiang
   Li, Li
   Ren, Xiandong
   Chen, Qian
   Abdul-Abbass, Yahya Mourad
TI An effective method for salt and pepper noise removal based on algebra
   and fuzzy logic function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Filtering; Salt and pepper noise; Lukasicwicz algebra
   with square root
AB Image denoising techniques are very important in modern digital image processing. Many classical denoising algorithms have evolved over the years, such as Butterworth filter, Mean filter, Median filter, Laplacian filter, Multidimensional filter, Gaussian filter and Wiener filter. In this paper, a new method of removing high density salt and pepper noise is proposed via using Lukasicwicz algebra with square root (MV-algebra) and fuzzy logic function for digital images. In the proposed method, a new constructed fuzzy logic function in MV-algebra is used to remove the salt and pepper noise in contaminated images. The proposed method is called LASRNM, which has a strong mathematical foundation and strong robustness in removing salt and pepper noise. Therefore, experiments on five datasets illustrate that our proposed LASRNM method works the best in high density salt and pepper noise situation in terms of the peak signal noise ratio (PSNR), signal to noise ratio (SNR) and structural similarity (SSIM).
C1 [Gao, Jianqiang; Li, Li; Ren, Xiandong] Jining Med Univ, Sch Med Informat Engn, Rizhao 276826, Shandong, Peoples R China.
   [Chen, Qian] Univ Wisconsin Madison, Dept Civil & Environm Engn, Madison, WI 53706 USA.
   [Abdul-Abbass, Yahya Mourad] Univ Kufa, Fac Comp Sci & Math, Najaf, Iraq.
C3 Jining Medical University; University of Wisconsin System; University of
   Wisconsin Madison; University of Kufa
RP Li, L (corresponding author), Jining Med Univ, Sch Med Informat Engn, Rizhao 276826, Shandong, Peoples R China.
EM gaojianqiang@mail.jnmc.edu.cn; liliiot@163.com; qchen339@wisc.edu;
   yihiamor@yahoo.com
OI Gao, Jianqiang/0000-0002-1989-4943
FU Supporting Fund for Teachers' research of Jining Medical University
   [JYFC2019KJ014]; Doctoral Research Foundation of Jining Medical
   University [2018JYQD03]; Project of Shandong Province Higher Educational
   Science and Technology Program [J18KA217]
FX This work is partly supported by the Supporting Fund for Teachers'
   research of Jining Medical University under Grant No. JYFC2019KJ014, and
   the Doctoral Research Foundation of Jining Medical University under
   Grant No. 2018JYQD03, and a Project of Shandong Province Higher
   Educational Science and Technology Program under Grant No. J18KA217,
   China. In addition, we are particularly grateful to Professor Yufeng
   Wang for serving as a scientific adviser. And we are particularly
   grateful to Dan Xing for for collecting data and writing code.
CR Abbass HH., 2014, J BABYLON UNIVERSITY, V22, P1
   Adabi S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020245
   Anbarjafari G., 2014, J ADV ELECT COMPUTER, V1, P14
   Chang C. C., 1958, T AM MATH SOC, V88, P467, DOI [10.2307/1993227, DOI 10.1090/S0002-9947-1958-0094302-9]
   Chang Chen Chung, 1959, Transactions of the American Mathematical Society, V93, P74, DOI DOI 10.2307/1993423
   Cignoli R., 2000, Algebraic Foundations of Many-Valued Reasoning, DOI DOI 10.1007/978-94-015-9480-6
   Dawar V., 2012, INT J ENG ADV TECHNO, V2, P69
   Iglesias JE, 2015, MED IMAGE ANAL, V24, P205, DOI 10.1016/j.media.2015.06.012
   Gao JQ, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2019.164123
   Geoffrine JMC., 2011, SIGNAL IMAGE PROCESS, V2, P82
   Gokilavani C., 2016, MIDDLE-EAST J SCI RE, V24, P475, DOI [10.5829/idosi.mejsr.2016.24.02.22884, DOI 10.5829/IDOSI.MEJSR.2016.24.02.22884]
   Ilyas BR, 2020, 2019 6 INT C IM SIGN
   Karami AH, 2015, ENG APPL ARTIF INTEL, V37, P307, DOI 10.1016/j.engappai.2014.09.018
   Kazubek M, 2003, IEEE SIGNAL PROC LET, V10, P324, DOI 10.1109/LSP.2003.818225
   Li L, 2018, NEURAL COMPUT APPL, V29, P173, DOI 10.1007/s00521-016-2538-7
   Li QL, 2020, J INTELL TRANSPORT S, V24, P254, DOI 10.1080/15472450.2019.1643725
   Liu XM, 2014, IEEE T IMAGE PROCESS, V23, P1491, DOI 10.1109/TIP.2014.2303638
   Manglem Singh Kh., 2011, J INF HIDING MULTIME, V2, P108
   Nola AD, 2006, IEEE INT C FUZZY SYS, DOI [10.1109/FUZZY.2006.1681977, DOI 10.1109/FUZZY.2006.1681977]
   Paul R., 2018, INT J ENG APPL SCI I, V5, P51
   Pizurica A., 2017, Wiley Encyclopedia of Electrical and Electronics Engineering, P1, DOI DOI 10.1002/047134608X.W8344
   Portilla J, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P37, DOI 10.1109/ICIP.2001.958418
   Rakshit S, 2007, PATTERN RECOGN, V40, P890, DOI 10.1016/j.patcog.2006.02.008
   Rizi FY, 2011, IEEE ENG MED BIO, P3917, DOI 10.1109/IEMBS.2011.6090973
   Toh KKV, 2010, IEEE SIGNAL PROC LET, V17, P281, DOI 10.1109/LSP.2009.2038769
   Toh KKV, 2008, IEEE T CONSUM ELECTR, V54, P1956, DOI 10.1109/TCE.2008.4711258
   Tun NM, 2020, FACIAL IMAGE DENOISI
   Xie DR, 2015, IEEE SYS MAN CYBERN, P1821, DOI 10.1109/SMC.2015.319
NR 28
TC 3
Z9 3
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 9547
EP 9576
DI 10.1007/s11042-023-15469-9
EA JUN 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019116600014
DA 2024-07-18
ER

PT J
AU Fatty, A
   Li, AJ
   Yao, CY
AF Fatty, Abdoulie
   Li, An-Jui
   Yao, Chih-Yuan
TI Instance segmentation based building extraction in a dense urban area
   using multispectral aerial imagery data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Instance segmentation; Deep learning; Transfer learning; Building
   extraction; Aerial imagery
AB Fast and automatic extraction of buildings from aerial imagery is essential for various applications. However, it remains a challenge, mainly because it requires the accurate recovery of buildings from high-resolution aerial imagery data. The task is particularly challenging due to the distinct nature of building shapes. The extraction of buildings from aerial imagery is often manually conducted by humans, which makes the process very time-consuming and costly. Furthermore, it is especially challenging to automatically extract the footprints of closely spaced buildings in dense urban areas through traditional segmentation techniques. This study proposes an instance segmentation-based building extraction technique for effective building detection and segmentation. The proposed method combines transfer learning with Mask Regional Convolutional Neural Network (Mask R-CNN) integrated with PointRend to locate and generate high-quality segmentation masks for building instances. In addition, several data augmentation strategies are also implemented to enlarge the training dataset. Results indicate that the proposed instance segmentation-based method for building extraction is able to execute distinctly efficient and effective automatic segmentation of distinctive and complex-shaped buildings in a dense urban area.
C1 [Fatty, Abdoulie; Li, An-Jui] Natl Taiwan Univ Sci & Technol, Dept Civil & Construct Engn, Taipei 106335, Taiwan.
   [Yao, Chih-Yuan] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 106335, Taiwan.
C3 National Taiwan University of Science & Technology; National Taiwan
   University of Science & Technology
RP Fatty, A (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Civil & Construct Engn, Taipei 106335, Taiwan.
EM afatty13@gmail.com
OI Fatty, Abdoulie/0000-0002-8765-4220
CR Bischke B, 2019, IEEE IMAGE PROC, P1480, DOI [10.1109/ICIP.2019.8803050, 10.1109/icip.2019.8803050]
   Cheng LB, 2021, LANDSLIDES, V18, P2751, DOI 10.1007/s10346-021-01694-6
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ghanea M, 2016, INT J REMOTE SENS, V37, P5234, DOI 10.1080/01431161.2016.1230287
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Howard J, 2020, INFORMATION, V11, DOI 10.3390/info11020108
   Kirillov A., 2020, P IEEECVF C COMPUTER, P9799, DOI DOI 10.48550/ARXIV.1912.08193
   Li JC, 2017, INT CONF ACOUST SPEE, P126, DOI 10.1109/ICASSP.2017.7952131
   Li WJ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11040403
   Mathew A, 2017, PROCEDIA COMPUT SCI, V115, P251, DOI 10.1016/j.procs.2017.09.132
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saeedi P, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P623, DOI 10.1109/ICARCV.2008.4795590
   Shao ZF, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12061050
   Wu GM, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030407
   Yao XJ, 2022, MULTIMED TOOLS APPL, V81, P41361, DOI 10.1007/s11042-020-09634-7
   Zhang G, 2021, PROC CVPR IEEE, P6857, DOI 10.1109/CVPR46437.2021.00679
   Zhang QC, 2016, INT GEOSCI REMOTE SE, P661, DOI 10.1109/IGARSS.2016.7729166
   Zhang Y, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11161897
NR 22
TC 1
Z9 1
U1 7
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 17
PY 2023
DI 10.1007/s11042-023-15905-w
EA JUN 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA J9EI0
UT WOS:001012579700002
DA 2024-07-18
ER

EF