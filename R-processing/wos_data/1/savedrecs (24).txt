FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Dondi, P
   Lombardi, L
   Rocca, I
   Malagodi, M
   Licchelli, M
AF Dondi, Piercarlo
   Lombardi, Luca
   Rocca, Irene
   Malagodi, Marco
   Licchelli, Maurizio
TI Multimodal workflow for the creation of interactive presentations of 360
   spin images of historical violins
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Education; Gestural interfaces; Usability; Classification; UV
   fluorescence; Kinect; Historical violins
ID CULTURAL-HERITAGE
AB The adoption of multimedia and multimodal applications inside museums and exhibitions is becoming a common practice. These installations proved to be particularly effective to attract visitors, especially the younger ones, and teach them complex information about the exposed artworks. A similar approach can be useful also to explain scientific analyses conducted on artworks, that commonly involve the use of complex analytical techniques, difficult to understand for inexpert people. In this work, we describe a multimodal workflow for the creation of interactive presentations of 360 spin images of historical violins. The workflow involves the acquisition, classification and visualization of the data. In particular, an ad hoc photographic set was built to achieve a fast acquisition of images both under visible and UV illumination, with the aim to study the surface of the instruments. Acquired images are classified and labeled using UVAnalyzer, an interactive application that supplies a set of tools for the analysis of UV fluorescence (UVF) images. Finally, KVN (Kinect Violin Navigator), a Kinect-based application, provides comfortable visualization and navigation within the data. During the development, we adopted a user-driven approach: user studies and suggestions from experts in UVF analysis were taken into account to improve the usability of the various steps of the workflow; then, a qualitative evaluation of the produced presentation was conducted on 22 volunteers. As a test set, we used images of violins exposed in the "Museo del Violino" in Cremona (Italy).
C1 [Dondi, Piercarlo; Malagodi, Marco; Licchelli, Maurizio] Univ Pavia, CISRiC, Arvedi Lab Noninvas Diagnost, Via BellAspa 3, I-26100 Cremona, Italy.
   [Lombardi, Luca] Univ Pavia, Dept Elect Comp & Biomed Engn, Via Ferrata 5, I-27100 Pavia, Italy.
   [Rocca, Irene] Univ Pavia, Pavia, Italy.
   [Malagodi, Marco] Univ Pavia, Dept Musicol & Cultural Heritage, Corso Garibaldi 178, I-26100 Cremona, Italy.
   [Licchelli, Maurizio] Univ Pavia, Dept Chem, Via Taramelli 12, I-27100 Pavia, Italy.
C3 University of Pavia; University of Pavia; University of Pavia;
   University of Pavia; University of Pavia
RP Dondi, P (corresponding author), Univ Pavia, CISRiC, Arvedi Lab Noninvas Diagnost, Via BellAspa 3, I-26100 Cremona, Italy.
EM piercarlo.dondi@unipv.it; luca.lombardi@unipv.it;
   irene.rocca@universitadipavia.it; marco.malagodi@unipv.it;
   maurizio.licchelli@unipv.it
RI ROCCA, IRENE/HLH-1004-2023
OI LICCHELLI, MAURIZIO/0000-0002-9276-1530; Dondi,
   Piercarlo/0000-0002-0624-073X
CR [Anonymous], 1993, Usability Engineering
   [Anonymous], 2016, P 8 INT C GAM VIRT W, DOI DOI 10.1109/VS-GAMES.2016.7590371
   Bautista SusanaSmith., 2013, Museums in the Digital Age: Changing Meanings of Place, Community, and Culture
   Bitossi G, 2005, APPL SPECTROSC REV, V40, P187, DOI 10.1081/ASR-200054370
   Blanchard Emmanuel G., 2013, Artificial Intelligence in Education. Proceedings of 16th International Conference (AIED 2013): LNCS 7926, P649, DOI 10.1007/978-3-642-39112-5_80
   Brandmair B., 2010, STRADIVARI VARNISH S
   Bravo Pereira L, 2010, INT J CONSERV SCI, V1, P161
   Cantoni V, 2016, STUD COMPUT INTELL, V648, P77, DOI 10.1007/978-3-319-32207-0_6
   Chen CC, 2005, INT J DIGIT LIBRARIE, V5, P275, DOI 10.1007/s00799-004-0097-5
   Cosentino A, 2015, CONSERV PATRIM, P53, DOI 10.14568/cp2015006
   Din Herminia., 2014, Digital Heritage and Culture: Strategy and Implementation
   Dondi P, 2015, NEWTRENDS IMAGE ANAL, V9281
   Dondi P., 2017, ACTA IMEKO, V6, P29, DOI [10.21014/actaimeko.v6i3.455, DOI 10.21014/ACTAIMEKO.V6I3.455, 10.21014/acta_imeko.v6i3.455, DOI 10.21014/ACTA_IMEKO.V6I3.455]
   Dondi P, 2017, ACM J COMPUT CULT HE, V10, DOI 10.1145/3051472
   Dondi P, 2016, J CULT HERIT, V22, P968, DOI 10.1016/j.culher.2016.05.010
   Dondi P, 2016, COLOR RES APPL, V41, P313, DOI 10.1002/col.22012
   Dondi P, 2015, PROC SPIE, V9527, DOI 10.1117/12.2184744
   Fanini B, 2015, 2015 DIGITAL HERITAGE INTERNATIONAL CONGRESS, VOL 1: DIGITIZATION & ACQUISITION, COMPUTER GRAPHICS & INTERACTION, P263, DOI 10.1109/DigitalHeritage.2015.7413880
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Hsieh C.-K., 2014, ACM J COMPUT CULT HE, V7
   Invernizzi C, 2016, MICROCHEM J, V124, P743, DOI 10.1016/j.microc.2015.10.016
   Janssens K., 2004, Non-destructive Micro Analysis of Cultural Heritage Materials", VXLII
   Malagodi M, 2013, APPL PHYS A-MATER, V112, P225, DOI 10.1007/s00339-013-7792-2
   Microsoft, 2017, MEET KIN WIND
   Mortara M, 2014, J CULT HERIT, V15, P318, DOI 10.1016/j.culher.2013.04.004
   New Media Consortium, 2015, NMC HOR REP
   Ramos E, 2013, PROC TECH, V7, P344, DOI 10.1016/j.protcy.2013.04.043
   Sen F., 2012, 2012 18th International Conference on Virtual Systems and Multimedia (VSMM 2012). Proceedings, P323, DOI 10.1109/VSMM.2012.6365941
   Simpson RobertS., 2003, LIGHTING CONTROL TEC
   Soga A, 2015, 2015 INTERNATIONAL CONFERENCE ON CULTURE AND COMPUTING (CULTURE COMPUTING), P199, DOI 10.1109/Culture.and.Computing.2015.25
   Stuart Barbara., 2007, Analytical Techniques in Materials Conservation
   Sylaiou S, 2009, J CULT HERIT, V10, P520, DOI 10.1016/j.culher.2009.03.003
   Weede O., 2014, ACM INT C P SERIES, P167
   Yoshida R, 2015, I CONF SENS TECHNOL, P834, DOI 10.1109/ICSensT.2015.7438512
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 35
TC 9
Z9 9
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28309
EP 28332
DI 10.1007/s11042-018-6046-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500023
DA 2024-07-18
ER

PT J
AU Li, H
   Yang, HM
   Zhao, JP
   Chen, CY
   Hao, F
AF Li, Hua
   Yang, Huamin
   Zhao, Jianping
   Chen, Chunyi
   Hao, Fei
TI Simulation of water surface using current consumer-level graphics
   hardware
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Water surface visualization; Secondary distorted textures; Reflection;
   Octave
AB Water surface visualization is an important research topic in computer graphics. This paper presents a novel method of water surface simulation by Secondary Distorted Textures (SDT), which realistically simulates and visualizes the reflection and refraction of calm water in real-time using current consumer-level hardware. The proposed method renders water surface using two stages of texture maps. 1. The first texture map stores the 3D geometries' perspective reflection with respect to 3D perspective view; 2. The second texture map stores the distortion results of the first reflection map with lighting effects. Perlin noise is used to generate random height map. Reflection and refraction are obtained and stored in the secondary distorted texture map with Fresnel effects for each frame. At rendering pass, the SDT is directly tiled on water surface. This paper also discussed the rendering of transparent geometry, which have view-dependent of lighting effects features. Experimental results demonstrated that our method can render realistic geometry nearby dynamic water surface at the frame rates of 70-100 FPS by NVIDIA Quadro k5000 graphic card. The existing texture mapping and bump mapping methods were compared for illustrating that our method produced high realistic water surface without aliasing reflection.
C1 [Li, Hua; Yang, Huamin; Zhao, Jianping; Chen, Chunyi] Changchun Univ Sci & Technol, Sch Comp Sci & Technol, Changchun 130022, Jilin, Peoples R China.
   [Hao, Fei] Soonchunhyang Univ, Dept Comp Software Engn, Asan, South Korea.
C3 Changchun University of Science & Technology; Soonchunhyang University
RP Zhao, JP (corresponding author), Changchun Univ Sci & Technol, Sch Comp Sci & Technol, Changchun 130022, Jilin, Peoples R China.
EM custlihua@gmail.com; yhm@cust.edu.cn; custlihua@gmail.com;
   chenchunyi@cust.edu.cn; fhao@sch.ac.kr
RI CUI, XU/JYO-8134-2024
OI Hao, Fei/0000-0001-5288-5523
FU Science and technology project of the Jilin provincial education
   department project [JJKH20181136KJ]; development project of Jilin
   province science and technology [20140204009GX]; Subject guidance
   project of Jilin Natural Science Foundation [20170101005JC]; Jilin
   upgrade industrial innovation special fund projects [2016C091]; major
   scientific and technological plan of Changchun [14KG008]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments. This work was financially supported by Science and
   technology project of the Jilin provincial education department project
   (JJKH20181136KJ), development project of Jilin province science and
   technology (20140204009GX), Subject guidance project of Jilin Natural
   Science Foundation(20170101005JC), Jilin upgrade industrial innovation
   special fund projects (2016C091) and major scientific and technological
   plan of Changchun (14KG008).
CR [Anonymous], HUMAN CTR COMPUTING
   [Anonymous], 9 INT C COMP AID DES
   [Anonymous], J CONVERG
   Bridson R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276435, 10.1145/1239451.1239497]
   Bruneton E, 2010, COMPUT GRAPH FORUM, V29, P487, DOI 10.1111/j.1467-8659.2009.01618.x
   Chentanez Nuttapong., 2010, P 2010 ACM SIGGRAPH, P197
   Darles E, 2011, COMPUT GRAPH FORUM, V30, P43, DOI 10.1111/j.1467-8659.2010.01828.x
   Elliot English R., 2013, Proceedings of the 12th ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA'13, P85
   Fournier A., 1986, Computer Graphics, V20, P75, DOI 10.1145/15886.15894
   Hu YH, 2006, COMPUT ANIMAT VIRT W, V17, P59, DOI 10.1002/cav.74
   Jensen LS, 2001, GAM DEV C
   Jianming Liang, 2015, Annals of GIS, V21, P301, DOI 10.1080/19475683.2015.1050064
   Lagae A, 2010, COMPUT GRAPH FORUM, V29, P2579, DOI 10.1111/j.1467-8659.2010.01827.x
   Liu SG, 2013, VIRTUAL REAL-LONDON, V17, P77, DOI 10.1007/s10055-013-0222-0
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   Perlin K.H., 1989, 16 ANN C COMP GRAPH, P253, DOI 10.1145/74333.74359
   Saravanan V, 2015, HUM-CENTRIC COMPUT I, V5, DOI 10.1186/s13673-014-0016-8
   Schreiber M, 2010, THESIS
   Smelik RM, 2014, COMPUT GRAPH FORUM, V33, P31, DOI 10.1111/cgf.12276
   Truelsen R., 2007, REAL TIME SHALLOW WA
NR 20
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 30149
EP 30166
DI 10.1007/s11042-018-6454-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800056
DA 2024-07-18
ER

PT J
AU Liu, J
   Wang, X
   Zhang, XR
   Pan, Y
   Wang, XS
   Wang, JX
AF Liu, Jin
   Wang, Xiang
   Zhang, Xiangrong
   Pan, Yi
   Wang, Xiaosheng
   Wang, Jianxin
TI MMM: classification of schizophrenia using multi-modality multi-atlas
   feature representation and multi-kernel learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Schizophrenia; Multi-modality; Multi-atlas; Multi-kernel Learning;
   Classification
ID WHITE-MATTER; MRI; SELECTION; REGISTRATION; PARCELLATION; INFORMATION;
   FRAMEWORK; REGIONS
AB Schizophrenia (SZ) is a complex neuropsychiatric disorder that seriously affects the daily life of patients. Therefore, accurate diagnosis of SZ is essential for patient care. Several T1-weighted magnetic resonance imaging (MRI) and diffusion tensor imaging (DTI) markers (e.g., cortical thickness (CT), mean diffusivity (MD)) for SZ have been identified by using some existing brain atlases, and have been used successfully to discriminate patients with SZ from healthy controls (HCs). Currently, these markers have mainly been used separately. Thus, the full potential of T1-weighted MRI images and DTI images for SZ diagnosis might not yet have been used comprehensively. Furthermore, the extraction of these markers based on single brain atlas might not yet be able to use the full potential of these images. Therefore, in this study, we propose a multi-modality multi-atlas feature representation and a multi-kernel learning method (MMM) to perform SZ/HC classification. Firstly, we extract 8 feature sets from T1-weighted MRI images and DTI images via 4 existing brain atlases and 4 markers. Then, a two-step feature selection method is proposed to select the most discriminative features of each feature set for SZ/HC classification. Finally, a multiple feature sets based multi-kernel SVM learning method (MFMK-SVM) is proposed to combine all feature sets for SZ/HC classification. Experimental results show that our proposed method achieves an accuracy of 91.28%, a sensitivity of 90.85%, a specificity of 92.17% and an AUC of 0.9485 for SZ/HC classification. Experimental results illustrate that our proposed classification method is efficient and promising for clinical diagnosis of SZ.
C1 [Liu, Jin; Wang, Jianxin] Cent South Univ, Sch Informat Sci & Engn, Changsha 410083, Peoples R China.
   [Wang, Xiang] Cent South Univ, Inst Med Psychol, Xiangya Hosp 2, Changsha 410011, Hunan, Peoples R China.
   [Zhang, Xiangrong] Nanjing Med Univ, Dept Geriatr Psychiat, Affiliated Nanjing Brain Hosp, Nanjing 210029, Jiangsu, Peoples R China.
   [Pan, Yi] Georgia State Univ, Dept Comp Sci, Atlanta, GA 30302 USA.
   [Wang, Xiaosheng] Cent South Univ, Dept Human Anat & Neurobiol, Xiangya Sch Med, Changsha 410013, Hunan, Peoples R China.
C3 Central South University; Central South University; Nanjing Medical
   University; University System of Georgia; Georgia State University;
   Central South University
RP Wang, JX (corresponding author), Cent South Univ, Sch Informat Sci & Engn, Changsha 410083, Peoples R China.; Wang, XS (corresponding author), Cent South Univ, Dept Human Anat & Neurobiol, Xiangya Sch Med, Changsha 410013, Hunan, Peoples R China.
EM liujin06@csu.edu.cn; wang0916xia@gmail.com; drxrz@hotmail.com;
   yipan@gsu.edu; wxwang@csu.edu.cn; jxwang@mail.csu.edu.cn
RI wang, jian/GVS-0711-2022; yang, yijing/JWO-8234-2024; Liu,
   Jin/AAD-1439-2019; zhen, wang/KBA-3844-2024; Pan, Yi/AAJ-2341-2021;
   Wang, Jianxin/V-2800-2018
OI Pan, Yi/0000-0002-2766-3096; Wang, Jianxin/0000-0003-1516-0480
FU National Natural Science Foundation of China [61232001, 61420106009,
   61622213, 81371474]
FX The authors would like to express their gratitude for the support from
   the National Natural Science Foundation of China under Grant No.
   61232001, No. 61420106009, No. 61622213 and No.81371474.
CR Alchatzidis S, 2017, INT J COMPUT VISION, V121, P169, DOI 10.1007/s11263-016-0925-2
   Andersson JLR, 2016, NEUROIMAGE, V125, P1063, DOI 10.1016/j.neuroimage.2015.10.019
   Brown G, 2012, J MACH LEARN RES, V13, P27
   Carli AC, 2014, NEUROCOMPUTING, V123, P49, DOI 10.1016/j.neucom.2013.02.037
   Castellani U, 2012, J NEURAL TRANSM, V119, P395, DOI 10.1007/s00702-011-0693-7
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cui ZX, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00042
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   Destrieux C, 2010, NEUROIMAGE, V53, P1, DOI 10.1016/j.neuroimage.2010.06.010
   Iglesias JE, 2015, MED IMAGE ANAL, V24, P205, DOI 10.1016/j.media.2015.06.012
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Guo S, 2016, PSYCHOL MED, V46, P2201, DOI 10.1017/S0033291716000994
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hillel A.B., 2006, INT C MACH LEARN, P401
   Hsu C.-W., 2003, TECH REP, DOI [DOI 10.1177/02632760022050997, 10 . 1177 / 02632760022050997]
   Hu RY, 2017, NEUROCOMPUTING, V220, P130, DOI 10.1016/j.neucom.2016.05.081
   Hua K, 2008, NEUROIMAGE, V39, P336, DOI 10.1016/j.neuroimage.2007.07.053
   Janousova E, 2015, PSYCHIAT RES-NEUROIM, V232, P237, DOI 10.1016/j.pscychresns.2015.03.004
   Jorgensen KN, 2016, PSYCHOL MED, V46, P1971, DOI 10.1017/S0033291716000593
   Koikkalainen J, 2011, NEUROIMAGE, V56, P1134, DOI 10.1016/j.neuroimage.2011.03.029
   Lan W, 2018, IEEE ACM T COMPUT BI, V15, P1774, DOI 10.1109/TCBB.2016.2586190
   Lan W, 2017, BIOINFORMATICS, V33, P458, DOI 10.1093/bioinformatics/btw639
   Lan W, 2016, NEUROCOMPUTING, V206, P50, DOI 10.1016/j.neucom.2016.03.080
   Lee SH, 2013, SCHIZOPHR RES, V143, P231, DOI 10.1016/j.schres.2012.11.029
   Liu J, 2017, IEEE T NEUR NET LEAR, V99, P1, DOI DOI 10.1080/15623599.2017.1326299
   Liu J, 2017, COMPLEXITY, DOI 10.1155/2017/8362741
   Liu J, 2018, IEEE ACM T COMPUT BI, V15, P1649, DOI 10.1109/TCBB.2017.2731849
   Liu J, 2017, IEEE T NANOBIOSCI, V16, P600, DOI 10.1109/TNB.2017.2751074
   Liu J, 2018, IEEE ACM T COMPUT BI, V15, P624, DOI 10.1109/TCBB.2016.2635144
   Liu J, 2017, IEEE T NANOBIOSCI, V16, P428, DOI 10.1109/TNB.2017.2707139
   Liu J, 2014, TSINGHUA SCI TECHNOL, V19, P578, DOI 10.1109/TST.2014.6961028
   Lu XB, 2016, MEDICINE, V95, DOI 10.1097/MD.0000000000003973
   Min R, 2014, HUM BRAIN MAPP, V35, P5052, DOI 10.1002/hbm.22531
   Mori S., 2005, MRI ATLAS HUMAN WHIT
   Nazeri A, 2013, NEUROPSYCHOPHARMACOL, V38, P1954, DOI 10.1038/npp.2013.93
   Palaniyappan L, 2012, J PSYCHIATR NEUROSCI, V37, P399, DOI 10.1503/jpn.110119
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Reuter M, 2010, NEUROIMAGE, V53, P1181, DOI 10.1016/j.neuroimage.2010.07.020
   Roffo Giorgio, 2017, New Frontiers in Mining Complex Patterns. 5th International Workshop, NFMCP 2016, held in conjunction with ECML-PKDD 2016. Revised Selected Papers: LNAI 10312, P19, DOI 10.1007/978-3-319-61461-8_2
   Roffo G, 2015, IEEE I CONF COMP VIS, P4202, DOI 10.1109/ICCV.2015.478
   Ségonne F, 2004, NEUROIMAGE, V22, P1060, DOI 10.1016/j.neuroimage.2004.03.032
   Sled JG, 1998, IEEE T MED IMAGING, V17, P87, DOI 10.1109/42.668698
   Tschacher W, 2017, SCHIZOPHRENIA BULL, V43, P745, DOI 10.1093/schbul/sbw220
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Vita A, 2015, BIOL PSYCHIAT, V78, P403, DOI 10.1016/j.biopsych.2015.02.008
   Wakana S, 2007, NEUROIMAGE, V36, P630, DOI 10.1016/j.neuroimage.2007.02.049
   Zhang SC, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2990508
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
   Zhu XF, 2017, MED IMAGE ANAL, V38, P205, DOI 10.1016/j.media.2015.10.008
NR 51
TC 23
Z9 25
U1 4
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29651
EP 29667
DI 10.1007/s11042-017-5470-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800026
DA 2024-07-18
ER

PT J
AU Xiao, YM
   Drouin, S
   Gerard, IJ
   Fonov, V
   Aubert-Broche, B
   Ma, YH
   Kersten-Oertel, M
   Tampieri, D
   Collins, DL
AF Xiao, Yiming
   Drouin, Simon
   Gerard, Ian J.
   Fonov, Vladimir
   Aubert-Broche, Berengere
   Ma, Yuhan
   Kersten-Oertel, Marta
   Tampieri, Donatella
   Collins, D. Louis
TI An augmented-reality system prototype for guiding transcranial Doppler
   ultrasound examination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transcranial Doppler ultrasound; Brain atlas; Augmented-reality; MRI;
   Image guidance; Clinical training
ID IMAGE; REGISTRATION; FUSION
AB Ultrasound (US) is a popular medical imaging technique in the clinic due to its low cost, high portability, and real-time diagnostic value. A special type of ultrasound technique, transcranial Doppler (TCD) ultrasound can be used to measure blood flows in cerebral blood vessels through acoustic bone windows of the intact human skull. Although TCD ultrasound is commonly used to diagnose and monitor a range of neurovascular conditions, such as stroke, interpretation of the image content in the TCD scans and quick localization of the targeted blood vessels with it can be difficult due to inherent challenges of its unique image contrasts, relatively low image quality, and 2D nature of the technique in relation to the 3D brain anatomy that is invisible to the clinician. These drawbacks may hinder the efficiency and even accuracy of the TCS examinations, especially for novel users. To render the procedure more efficient and intuitive, we developed a prototype of augmented-reality system to guide the procedure by fusing a population-averaged probabilistic blood vessel atlas with camera footages of the patient. The system prototype was demonstrated with healthy subjects, and is expected to facility the clinical TCD examination, as well as to help in the educational context for new clinicians and clinical technicians.
C1 [Xiao, Yiming] Western Univ, Robarts Res Inst, 1151 Richmond St, London, ON N6A 5B7, Canada.
   [Drouin, Simon; Gerard, Ian J.; Fonov, Vladimir; Aubert-Broche, Berengere; Ma, Yuhan; Collins, D. Louis] McGill Univ, McConnell Brain Imaging Ctr, Montreal Neurol Inst, Montreal, PQ, Canada.
   [Kersten-Oertel, Marta] Concordia Univ, Dept Comp Sci & Software Engn, Montreal, PQ, Canada.
   [Tampieri, Donatella] Montreal Neurol Inst, Dept Diagnost & Intervent Neurol, Montreal, PQ, Canada.
C3 Western University (University of Western Ontario); McGill University;
   Concordia University - Canada; McGill University
RP Xiao, YM (corresponding author), Western Univ, Robarts Res Inst, 1151 Richmond St, London, ON N6A 5B7, Canada.
EM yxiao286@uwo.ca
RI Kersten-Oertel, Marta/AAC-5882-2019; Fonov, Vladimir/AAG-9572-2019; Ma,
   Yuhan/HMD-8720-2023; Drouin, Simon/O-1683-2019; Collins, D.
   Louis/ABD-7708-2021
OI Kersten-Oertel, Marta/0000-0002-9492-8402; Fonov,
   Vladimir/0000-0003-3402-7749; Drouin, Simon/0000-0002-7265-8747;
   Collins, D. Louis/0000-0002-8432-7021
CR [Anonymous], P 13 AAAI C ART INT
   Aubert-Broche B, 2006, IEEE T MED IMAGING, V25, P1410, DOI 10.1109/TMI.2006.883453
   Chang WM, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P1545
   De Nigris D, 2013, INT J COMPUT ASS RAD, V8, P649, DOI 10.1007/s11548-013-0826-6
   Drouin S, 2017, INT J COMPUT ASS RAD, V12, P363, DOI 10.1007/s11548-016-1478-0
   Drouin S, 2015, LECT NOTES COMPUT SC, V9365, P21, DOI 10.1007/978-3-319-24601-7_3
   EVANS AC, 1993, NUCLEAR SCIENCE SYMPOSIUM & MEDICAL IMAGING CONFERENCE, VOLS 1-3, P1813, DOI 10.1109/NSSMIC.1993.373602
   Fonov V, 2011, NEUROIMAGE, V54, P313, DOI 10.1016/j.neuroimage.2010.07.033
   Francesconi M, 2015, IEEE ENG MED BIO, P5098, DOI 10.1109/EMBC.2015.7319538
   Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195
   Gerard IanJ., 2016, WORKSHOP CLIN IMAGE, V9401, P28, DOI DOI 10.1007/978-3-319-31808-0_4
   Kersten-Oertel M, 2015, INT J COMPUT ASS RAD, V10, P1823, DOI 10.1007/s11548-015-1163-8
   Kersten-Oertel Marta, 2012, Stud Health Technol Inform, V173, P225
   Laganà MM, 2013, IEEE T MULTIMEDIA, V15, P1039, DOI 10.1109/TMM.2013.2244871
   Lerotic M, 2007, LECT NOTES COMPUT SC, V4792, P102
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Palmer CL, 2015, IEEE INT ULTRA SYM, DOI DOI 10.1109/ULTSYM.2015.0488
   Schreiber SJ, 2014, BIOMED ENG LETT, V4, P347, DOI 10.1007/s13534-014-0163-x
   State A, 1996, P 23 ANN C COMP GRAP
   Wolfsberger S, 2002, NEUROSURG REV, V25, P68, DOI 10.1007/s10143-001-0201-x
NR 20
TC 4
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 27789
EP 27805
DI 10.1007/s11042-018-5990-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500003
DA 2024-07-18
ER

PT J
AU Yan, LM
   Zheng, YH
   Cao, J
AF Yan, Leiming
   Zheng, Yuhui
   Cao, Jie
TI Few-shot learning for short text classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Deep learning; Few-shot learning; Text
   classification
ID SALIENCY; TWITTER
AB Due to the limited length and freely constructed sentence structures, it is a difficult classification task for short text classification. In this paper, a short text classification framework based on Siamese CNNs and few-shot learning is proposed. The Siamese CNNs will learn the discriminative text encoding so as to help classifiers distinguish those obscure or informal sentence. The different sentence structures and different descriptions of a topic are viewed as 'prototypes', which will be learned by few-shot learning strategy to improve the classifier's generalization. Our experimental results show that the proposed framework leads to better results in accuracies on twitter classifications and outperforms some popular traditional text classification methods and a few deep network approaches.
C1 [Yan, Leiming] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing, Jiangsu, Peoples R China.
   [Zheng, Yuhui] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.
   [Cao, Jie] Nanjing Univ Informat Sci & Technol, Sch Math & Stat, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; Nanjing University of
   Information Science & Technology
RP Yan, LM (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing, Jiangsu, Peoples R China.
EM lmyan@nuist.edu.cn; zhengyh@vip.126.com; cj@nuist.edu.cn
RI Zheng, Yuhui/AAF-2420-2019
FU Chinese National Natural Science Foundation (NSFC) [61772281, 61602254];
   National Social Science Foundation of China [16ZDA054]; Jiangsu
   Provincial 333 Project [BRA2017396]; Six Major Talents PeakProject of
   Jiangsu Province [XYDXXJS-CXTD-005]; Priority Academic Program
   Development of Jiangsu Higher Education Institutions (PAPD); Jiangsu
   Collaborative Innovation Center on Atmospheric Environment and Equipment
   Technology (CICAEET)
FX This work is supported by the Chinese National Natural Science
   Foundation (NSFC) [grant numbers 61772281, 61602254]; the National
   Social Science Foundation of China (No. 16ZDA054); Jiangsu Provincial
   333 Project (BRA2017396); Six Major Talents PeakProject of Jiangsu
   Province (XYDXXJS-CXTD-005); the Priority Academic Program Development
   of Jiangsu Higher Education Institutions (PAPD) and Jiangsu
   Collaborative Innovation Center on Atmospheric Environment and Equipment
   Technology (CICAEET).
CR [Anonymous], 2016, ARXIV160305106
   [Anonymous], J VIS COMMUN IMAGE R
   [Anonymous], 2013, EMOTION SENTIMENT SO
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], ARXIV170702610
   [Anonymous], UN NAM C PORTL US
   [Anonymous], 2017, ARXIV170305175
   [Anonymous], P ADV NEURAL INFORM
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2016, CORR
   Blaes S, 2017, NEURAL NETWORKS, V94, P159, DOI 10.1016/j.neunet.2017.07.001
   Cheng JJ, 2016, APPL INTELL, V45, P429, DOI 10.1007/s10489-016-0768-0
   Ding GG, 2017, NEUROCOMPUTING, V257, P24, DOI 10.1016/j.neucom.2017.01.055
   Ding GG, 2016, IEEE T IMAGE PROCESS, V25, P5427, DOI 10.1109/TIP.2016.2607421
   Fu ZJ, 2019, IEEE T SERV COMPUT, V12, P813, DOI 10.1109/TSC.2016.2622697
   Gu B., 2016, IEEE Transactions on Neural Networks and Learning Systems, DOI DOI 10.1109/TNNLS.2016.2527796
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P1344, DOI 10.1109/TIP.2017.2652730
   Guo Y, 2017, IEEE INT CONF SOFTW, P1, DOI 10.1109/ICST.2017.8
   Han JW, 2018, IEEE T CIRC SYST VID, V28, P2473, DOI 10.1109/TCSVT.2017.2706264
   Hecht T, 2016, LECT NOTES COMPUT SC, V9887, P121, DOI 10.1007/978-3-319-44781-0_15
   Jetley Saumya, 2015, ARXIV151201192
   Kim Y., 2014, P 2014 C EMPIRICAL M
   Koch G., 2015, P ICML DEEP LEARN WO, P1
   Lake B. M., 2013, Adv. Neural Inf. Proces. Syst., P2526, DOI DOI 10.5555/2999792.2999894
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Nakov P, 2016, LANG RESOUR EVAL, V50, P35, DOI 10.1007/s10579-015-9328-1
   Ravi Sachin, 2017, Conference Track Proceedings
   Socher R., 2011, PROC INT C MACH LEAR, P129
   Speriosu M., 2011, WORKSH UNS LEARN NLP, P53
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   Tang Duyu., 2014, International Workshop on Semantic Evaluation, P208
   Thelwall M, 2012, J AM SOC INF SCI TEC, V63, P163, DOI 10.1002/asi.21662
   Turney PD, 2010, J ARTIF INTELL RES, V37, P141, DOI 10.1613/jair.2934
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Yan LM, 2017, J INTERNET TECHNOL, V18, P1605, DOI 10.6138/JIT.2017.18.7.20170410
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Yao XW, 2016, IEEE T GEOSCI REMOTE, V54, P3660, DOI 10.1109/TGRS.2016.2523563
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2017, IEEE T IMAGE PROCESS, V26, P1746, DOI 10.1109/TIP.2017.2658957
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474
   Zhao Y, 2016, IEEE T ANTENN PROPAG, V64, P2410, DOI 10.1109/TAP.2016.2550058
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
   Zhou ZL, 2016, IEICE T INF SYST, VE99D, P1531, DOI 10.1587/transinf.2015EDP7341
NR 49
TC 55
Z9 60
U1 8
U2 90
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29799
EP 29810
DI 10.1007/s11042-018-5772-4
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800035
DA 2024-07-18
ER

PT J
AU Danelakis, A
   Theoharis, T
   Pratikakis, I
AF Danelakis, Antonios
   Theoharis, Theoharis
   Pratikakis, Ioannis
TI Action unit detection in 3<i>D</i> facial videos with application in
   facial expression retrieval and recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic 3D mesh sequence; Action unit detection; Facial expression
   retrieval; Facial expression recognition
ID REAL-TIME; SEQUENCES; FUSION
AB This work introduces a new scheme for action unit detection in 3D facial videos. Sets of features that define action unit activation in a robust manner are proposed. These features are computed based on eight detected facial landmarks on each facial mesh that involve angles, areas and distances. Support vector machine classifiers are then trained using the above features in order to perform action unit detection. The proposed AU detection scheme is used in a dynamic 3D facial expression retrieval and recognition pipeline, highlighting the most important AU s, in terms of providing facial expression information, and at the same time, resulting in better performance than state-of-the-art methodologies.
C1 [Danelakis, Antonios; Theoharis, Theoharis] Norwegian Univ Sci & Technol, Dept Comp & Informat Sci, N-7034 Trondheim, Norway.
   [Pratikakis, Ioannis] Democritus Univ Thrace, Dept Elect & Comp Engn, GR-67100 Xanthi, Greece.
C3 Norwegian University of Science & Technology (NTNU); Democritus
   University of Thrace
RP Danelakis, A (corresponding author), Norwegian Univ Sci & Technol, Dept Comp & Informat Sci, N-7034 Trondheim, Norway.
EM a.danelakis@gmail.com; theotheo@ntnu.no; ipratika@ee.duth.gr
RI Theoharis, Theoharis/AAN-2555-2020; PRATIKAKIS, IOANNIS/AAD-3387-2019
OI PRATIKAKIS, IOANNIS/0000-0002-4124-3688
CR [Anonymous], 2012, Computer Vision and Pattern Recognition Workshops CVPRW
   [Anonymous], ARXIV170204174
   [Anonymous], ARXIV161101872
   [Anonymous], INT J COMPUT VISION
   [Anonymous], 2013, INT CONF BIOMETR
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P 1 INT WORKSH DIFFE
   [Anonymous], P IEEE INT C AUT FAC
   [Anonymous], DENSE DEFORMATION FI
   [Anonymous], IEEE FG 13
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 2016, APPL COMP VIS WACV 2
   [Anonymous], P 2008 8 IEEE INT C, DOI DOI 10.1109/AFGR.2008.4813324
   Ashraf AB, 2009, IMAGE VISION COMPUT, V27, P1788, DOI 10.1016/j.imavis.2009.05.007
   Baltrusaitis T, 2015, IEEE INT CONF AUTOMA
   Bartlett MS, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P223, DOI 10.1109/fgr.2006.55
   Berretti S, 2013, VISUAL COMPUT, V29, P1333, DOI 10.1007/s00371-013-0869-2
   Bihan Jiang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P314, DOI 10.1109/FG.2011.5771416
   Chang Y, 2005, LECT NOTES COMPUT SC, V3723, P293
   Chen JX, 2013, PATTERN RECOGN LETT, V34, P1964, DOI 10.1016/j.patrec.2013.02.002
   Choi S.-S., 2010, Systemics, Cybernetics and Informatic, V8, P43
   Chu WS, 2013, PROC CVPR IEEE, P3515, DOI 10.1109/CVPR.2013.451
   Cosker D, 2011, IEEE I CONF COMP VIS, P2296, DOI 10.1109/ICCV.2011.6126510
   Dahmane M, 2014, IEEE T MULTIMEDIA, V16, P1574, DOI 10.1109/TMM.2014.2321113
   Danelakis A, 2014, P 7 EUR WORKSH 3D OB, P1
   Danelakis A, 2016, PATTERN RECOGN, V52, P174, DOI 10.1016/j.patcog.2015.10.012
   Devijver P. A., 1982, PATTERN RECOGNITION, V265
   Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905
   Ekman P, 1978, FACIAL ACTION CODING
   Fang TH, 2012, IMAGE VISION COMPUT, V30, P738, DOI 10.1016/j.imavis.2012.02.004
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Gao GY, 2016, IEEE T CIRC SYST VID, V26, P2299, DOI 10.1109/TCSVT.2015.2504738
   Gehrig T., 2011, IEEE Comput. Conf. Comput. Vision and Pattern Recogn. Workshops, P1
   Gudi A., 2015, 2015 11 IEEE INT C W, V6, P1
   Huang YZ, 2010, IEEE T MULTIMEDIA, V12, P536, DOI 10.1109/TMM.2010.2052792
   Jeni L.A., 2013, Proc. 10th IEEE Int. Conf. Workshops Autom. Face Gesture Recognit, P1
   Jeni LA, 2012, IMAGE VISION COMPUT, V30, P785, DOI 10.1016/j.imavis.2012.02.003
   Khademi M, 2014, IEEE WINT CONF APPL, P1090, DOI 10.1109/WACV.2014.6835983
   Kotsia I, 2008, PATTERN RECOGN, V41, P833, DOI 10.1016/j.patcog.2007.06.026
   Lien JJJ, 1998, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.1998.698704
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lucey P, 2011, IEEE T SYST MAN CY B, V41, P664, DOI 10.1109/TSMCB.2010.2082525
   Maalej Ahmed, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4129, DOI 10.1109/ICPR.2010.1003
   Maalej A, 2011, PATTERN RECOGN, V44, P1581, DOI 10.1016/j.patcog.2011.02.012
   Mahoor Mohammad H., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P336, DOI 10.1109/FG.2011.5771420
   Mao QR, 2017, IEEE T MULTIMEDIA, V19, P861, DOI 10.1109/TMM.2016.2629282
   Pantic M, 2004, IEEE T SYST MAN CY B, V34, P1449, DOI 10.1109/TSMCB.2004.825931
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075
   Perakis P, 2014, PATTERN RECOGN, V47, P2783, DOI 10.1016/j.patcog.2014.03.007
   Pinto SCD, 2011, IEEE IMAGE PROC, P1281, DOI 10.1109/ICIP.2011.6115668
   Kassim SRA, 2006, IEEE IMAGE PROC, P661
   Reale M, 2013, IEEE INT CONF AUTOMA
   Rosato M, 2008, IEEE INT C BIOMETRIC, P1
   Ruiz A, 2015, IEEE I CONF COMP VIS, P3703, DOI 10.1109/ICCV.2015.422
   Sandbach G, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.119
   Sandbach G, 2012, IEEE IMAGE PROC, P1813, DOI 10.1109/ICIP.2012.6467234
   Sandbach G, 2012, IMAGE VISION COMPUT, V30, P762, DOI 10.1016/j.imavis.2012.01.006
   Savran A., 2011, 2011 IEEE 19th Signal Processing and Communications Applications Conference (SIU 2011), P371, DOI 10.1109/SIU.2011.5929664
   Savran A., 2010, 2010 IEEE 18th Signal Processing and Communications Applications Conference (SIU 2010), P300, DOI 10.1109/SIU.2010.5651330
   Savran Arman, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1993, DOI 10.1109/ICCVW.2009.5457526
   Savran A, 2012, PATTERN RECOGN, V45, P767, DOI 10.1016/j.patcog.2011.07.022
   Senechal T., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P860, DOI 10.1109/FG.2011.5771363
   Senechal T, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P10, DOI 10.1109/ICCVW.2015.11
   Senechal T, 2014, PATTERN ANAL APPL, V17, P51, DOI 10.1007/s10044-012-0279-5
   Senechal T, 2012, IEEE T SYST MAN CY B, V42, P993, DOI 10.1109/TSMCB.2012.2193567
   Simon T, 2010, PROC CVPR IEEE, P2737, DOI 10.1109/CVPR.2010.5539998
   Song Yale, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163081
   Soyel H, 2010, TURK J ELECTR ENG CO, V18, P1031, DOI 10.3906/elk-0908-158
   Sun Y, 2008, LECT NOTES COMPUT SC, V5303, P58, DOI 10.1007/978-3-540-88688-4_5
   Sun Y, 2010, IEEE T SYST MAN CY A, V40, P461, DOI 10.1109/TSMCA.2010.2041659
   Sun YL, 2008, KEY ENG MATER, V359-360, P1, DOI 10.4028/www.scientific.net/KEM.359-360.1
   Tang H, 2008, 2008 8 IEEE INT C AU, P1
   Tao DC, 2008, IEEE T CIRC SYST VID, V18, P1397, DOI 10.1109/TCSVT.2008.2002825
   Tawari A, 2013, IEEE T MULTIMEDIA, V15, P1543, DOI 10.1109/TMM.2013.2266635
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094
   Tsalakanidou Filareti, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P4, DOI 10.1109/CVPR.2009.5204281
   Tsalakanidou F, 2010, PATTERN RECOGN, V43, P1763, DOI 10.1016/j.patcog.2009.12.009
   Valstar M., 2006, COMP VIS PATT REC WO, P149
   Valstar M.F., 2015, P 2015 IEEE INT C WO, P1
   van der Maaten L, 2012, COGN PROCESS, V13, P507, DOI 10.1007/s10339-011-0419-7
   Venkatesh Y. V., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3772, DOI 10.1109/ICPR.2010.919
   Vuong Le, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P414, DOI 10.1109/FG.2011.5771435
   Walecki Robert, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163137
   Wegrzyn M, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177239
   Wu CH, 2013, IEEE T MULTIMEDIA, V15, P1732, DOI 10.1109/TMM.2013.2272917
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Yan JJ, 2016, IEEE T MULTIMEDIA, V18, P1319, DOI 10.1109/TMM.2016.2557721
   Yeasin M, 2006, IEEE T MULTIMEDIA, V8, P500, DOI 10.1109/TMM.2006.870737
   Yin LJ, 2006, INT C PATT RECOG, P1248
   Yüce A, 2015, IEEE INT CONF AUTOMA
   Zafeiriou S, 2008, IEEE T MULTIMEDIA, V10, P1528, DOI 10.1109/TMM.2008.2007292
   Zen G, 2016, IEEE T MULTIMEDIA, V18, P775, DOI 10.1109/TMM.2016.2523421
   Zeng JB, 2015, IEEE I CONF COMP VIS, P3622, DOI 10.1109/ICCV.2015.413
   Zhang T, 2016, IEEE T MULTIMEDIA, V18, P2528, DOI 10.1109/TMM.2016.2598092
   Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002
   Zhao Kaili, 2015, IEEE C COMP VIS PATT
   Zhao X, 2013, IMAGE VISION COMPUT, V31, P231, DOI 10.1016/j.imavis.2012.10.001
   Zhao X, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL V, P1
   Zhen QK, 2016, IEEE T MULTIMEDIA, V18, P1438, DOI 10.1109/TMM.2016.2557063
   Zhu Y., 2007, INFORM FUSION 2007 1, P1
NR 103
TC 9
Z9 9
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 24813
EP 24841
DI 10.1007/s11042-018-5699-9
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400011
DA 2024-07-18
ER

PT J
AU Huang, X
   Zhu, YP
AF Huang, Xin
   Zhu, Yuanping
TI An entity based multi-direction cooperative deformation algorithm for
   generating personalized human shape
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personalized human shape; Human entities; Multi-direction cooperative
   deformation; Entity curve interpolation
ID HUMAN-BODY; TRY-ON; MODEL; RECONSTRUCTION; DESIGN
AB Personalized human shape plays an important role in system of virtual garment customization. In this paper, a new entity based multi-direction cooperative deformation algorithm (MDCD) is proposed to generate personalized human shape. We primarily extract the description parameters of entities using different direction sections based on unified division method. By introducing the entity curve interpolation and correspondence between elementary and target entities, the generated distortion of various human entities from simulated deformation function will be avoided. With the good capacity of accuracy and reusability of human entities, the MDCD algorithm can greatly improve the generation efficiency of personalized human shapes. The elementary entities on template model are firstly located using the division method of Poser, and description parameters on entities are then extracted based on the entity direction. Thus, shape characteristics can be represented by a set of direction curves on different angles by entity curve interpolation. Subsequently shape characteristics on personalized human body are generated by a comparison of direction curves of template and target entities. Finally, the MDCD algorithm is applied for generating personalized entities and shapes. Experiments show that compared with the existed algorithms, personalized human shapes generated by our method are smoother and more similar to the template model.
C1 [Huang, Xin; Zhu, Yuanping] Tianjin Normal Univ, Coll Comp & Informat Engn, Tianjin 300387, Peoples R China.
C3 Tianjin Normal University
RP Huang, X (corresponding author), Tianjin Normal Univ, Coll Comp & Informat Engn, Tianjin 300387, Peoples R China.
EM huxpiero@126.com
FU National Science Foundation of China [61703306]; Natural Science
   Foundation of Tianjin [16JCQNJC00600]; Doctoral Foundation of Tianjin
   Normal University [52XB1302]
FX This work was supported in part by the National Science Foundation of
   China (No. 61703306), the Natural Science Foundation of Tianjin (No.
   16JCQNJC00600), and the Doctoral Foundation of Tianjin Normal University
   (No. 52XB1302).
CR [Anonymous], MULTIMED TOOLS APPL
   Boisvert J, 2013, MACH VISION APPL, V24, P145, DOI 10.1007/s00138-011-0353-9
   Chaudhry E, 2013, COMPUT GRAPH-UK, V37, P638, DOI 10.1016/j.cag.2013.06.001
   Chen G, 2016, VIRTUAL REAL-LONDON, V20, P159, DOI 10.1007/s10055-016-0291-y
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Domingo J, 2014, EXPERT SYST APPL, V41, P6224, DOI 10.1016/j.eswa.2014.04.014
   Dong ZJ, 2015, INT J CLOTH SCI TECH, V27, P532, DOI 10.1108/IJCST-01-2014-0013
   Guo LX, 2016, INT J IND ERGONOM, V53, P319, DOI 10.1016/j.ergon.2016.03.004
   Han XG, 2016, IEEE COMPUT GRAPH, V36, P46, DOI 10.1109/MCG.2016.68
   Hauswiesner S, 2013, IEEE T VIS COMPUT GR, V19, P1552, DOI 10.1109/TVCG.2013.67
   Hosseini SJ, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0114-9
   Hsiao SW, 2013, COMPUT AIDED DESIGN, V45, P1426, DOI 10.1016/j.cad.2013.06.012
   Huang LC, 2016, VISUAL COMPUT, V32, P705, DOI 10.1007/s00371-016-1236-x
   Huang X, 2012, NEUROCOMPUTING, V87, P99, DOI 10.1016/j.neucom.2012.02.010
   Jang IY, 2012, MULTIMED TOOLS APPL, V58, P267, DOI 10.1007/s11042-010-0719-4
   Kocamaz MK, 2015, IMAGE VISION COMPUT, V40, P16, DOI 10.1016/j.imavis.2015.05.001
   Koo BY, 2015, COMPUT IND, V73, P23, DOI 10.1016/j.compind.2015.07.007
   Kumara WGCW, 2017, MULTIMED TOOLS APPL, V76, P11687, DOI 10.1007/s11042-016-3327-0
   Lee Y, 2013, COMPUT GRAPH-UK, V37, P911, DOI 10.1016/j.cag.2013.07.005
   Li J, 2015, MULTIMED TOOLS APPL, V74, P6951, DOI 10.1007/s11042-014-1947-9
   Li K, 2015, COMPUT AIDED DESIGN, V64, P33, DOI 10.1016/j.cad.2015.02.006
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Mao AH, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17051113
   Michael N, 2017, MULTIMED TOOLS APPL, V76, P14169, DOI 10.1007/s11042-016-3808-1
   Orban GA, 2011, ANNU REV NEUROSCI, V34, P361, DOI 10.1146/annurev-neuro-061010-113819
   Pickup D, 2016, INT J COMPUT VISION, V120, P169, DOI 10.1007/s11263-016-0903-8
   Pishchulin L, 2017, PATTERN RECOGN, V67, P276, DOI 10.1016/j.patcog.2017.02.018
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   Sabina O, 2014, PROCEDIA ENGINEER, V69, P555, DOI 10.1016/j.proeng.2014.03.026
   Shen Z, 2014, BIO-MED MATER ENG, V24, P2219, DOI 10.3233/BME-141034
   Shi XP, 2014, ADV INTELL SYST, V279, P537, DOI 10.1007/978-3-642-54927-4_51
   Soric J, 2015, T FAMENA, V39, P1
   Sun XY, 2013, ADV MATER RES-SWITZ, V753-755, P1409, DOI 10.4028/www.scientific.net/AMR.753-755.1409
   Wu WC, 2015, J SIGNAL PROCESS SYS, V78, P95, DOI 10.1007/s11265-014-0936-6
   Wuhrer S, 2014, COMPUT VIS IMAGE UND, V127, P31, DOI 10.1016/j.cviu.2014.06.012
   Yu Y, 2015, VISUAL COMPUT, V31, P19, DOI 10.1007/s00371-013-0901-6
   Yuan ML, 2013, IEEE T MULTIMEDIA, V15, P1958, DOI 10.1109/TMM.2013.2280560
   Zhang MM, 2015, MULTIMED TOOLS APPL, V74, P3137, DOI 10.1007/s11042-013-1774-4
NR 43
TC 3
Z9 3
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 24865
EP 24889
DI 10.1007/s11042-018-5711-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400013
DA 2024-07-18
ER

PT J
AU Niu, YZ
   Chen, JE
   Guo, WZ
AF Niu, Yuzhen
   Chen, Jianer
   Guo, Wenzhong
TI Meta-metric for saliency detection evaluation metrics based on
   application preference
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Traditional evaluation metrics; Image quality
   assessment; Content-based image retrieval
ID IMAGE QUALITY ASSESSMENT; OBJECT RECOGNITION
AB Existing saliency detection evaluation metrics often produce inconsistent evaluation results. Because of the widespread application of image saliency detection, we propose a meta-metric to evaluate the performance of these metrics based on the preference of an application that uses saliency maps as weighting maps. This study uses content-based image retrieval (CBIR) as the representative application. First, we perform CBIR using image features extracted from deep convolutional layers of convolutional neural networks as well as saliency maps computed by various saliency detection algorithms as the weighting maps over queries. Second, we establish the preference order of the saliency detection algorithms in the CBIR application by sorting the mean average precision. Third, we determine the preference order of these algorithms using existing saliency detection evaluation metrics. Finally, our meta-metric evaluates these metrics by correlating the preference order in the CBIR application with that determined by each evaluation metric. Experiments on three publicly available datasets show that, of 24 evaluation metrics, the traditional metric: area under receiver operating characteristic curve is the best metric for a CBIR application.
C1 [Niu, Yuzhen; Chen, Jianer; Guo, Wenzhong] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou, Fujian, Peoples R China.
   [Niu, Yuzhen; Guo, Wenzhong] Fuzhou Univ, Fujian Key Lab Network Comp & Intelligent Informa, Fuzhou, Fujian, Peoples R China.
   [Niu, Yuzhen; Guo, Wenzhong] Minist Educ, Key Lab Spatial Data Min & Informat Sharing, Fuzhou, Fujian, Peoples R China.
C3 Fuzhou University; Fuzhou University
RP Guo, WZ (corresponding author), Fuzhou Univ, Coll Math & Comp Sci, Fuzhou, Fujian, Peoples R China.; Guo, WZ (corresponding author), Fuzhou Univ, Fujian Key Lab Network Comp & Intelligent Informa, Fuzhou, Fujian, Peoples R China.; Guo, WZ (corresponding author), Minist Educ, Key Lab Spatial Data Min & Informat Sharing, Fuzhou, Fujian, Peoples R China.
EM fzugwz@163.com
FU National Natural Science Foundation of China [61672158, 61672159,
   61502105, 61300102]; Fujian Natural Science Funds for Distinguished
   Young Scholar [2015J06014]; Technology Guidance Project of Fujian
   Province [2017H0015]; Industry-Academy Cooperation Project [2017H6008];
   Fujian Collaborative Innovation Center for Big Data Application in
   Governments
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61672158, 61672159, 61502105, and
   61300102, in part by the Fujian Natural Science Funds for Distinguished
   Young Scholar under Grant 2015J06014, in part by the Technology Guidance
   Project of Fujian Province under Grant 2017H0015, in part by the
   Industry-Academy Cooperation Project under Grant 2017H6008, and the
   Fujian Collaborative Innovation Center for Big Data Application in
   Governments.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   An J, 2014, IEEE IMAGE PROC, P3042, DOI 10.1109/ICIP.2014.7025615
   [Anonymous], 2007, Paper presented at the third international workshop on video processing and quality metrics7, Scottsdale, Arizona
   [Anonymous], P 20 ACM INT C MULT
   Balanov A, 2015, IEEE IMAGE PROC, P2105, DOI 10.1109/ICIP.2015.7351172
   Chang HW, 2015, NEUROCOMPUTING, V151, P1142, DOI 10.1016/j.neucom.2014.04.081
   Chen TC, 2009, PROC EUR SOLID-STATE, P1
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Christian S, 2013, P IEEE COMP SOC C CO
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   Egiazarian K., 2006, proceedings of the second international workshop on video processing and quality metrics, P4
   Eric L, 2010, J ELECTRON IMAGING, V19
   Gao Y, 2015, IEEE T MULTIMEDIA, V17, P359, DOI 10.1109/TMM.2015.2389616
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hiremath, 2008, International Journal of Image Processing, V2, P10
   Hu SM, 2013, VISUAL COMPUT, V29, P393, DOI 10.1007/s00371-013-0792-6
   Juneja K, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P67, DOI 10.1109/CICT.2015.92
   Kanan C, 2010, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2010.5539947
   Lee D, 2015, IEEE T IMAGE PROCESS, V24, P3950, DOI 10.1109/TIP.2015.2456419
   Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Mitsa T., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P301, DOI 10.1109/ICASSP.1993.319807
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Ponomarenko N., 2011, 2011 11th International Conference The Experience of Designing and Application of CAD Systems in Microelectronics (CADSM 2011), P305
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Robertson S, 2009, EVALUATION INFORM RE
   Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Tu WC, 2016, PROC CVPR IEEE, P2334, DOI 10.1109/CVPR.2016.256
   Wang P, 2012, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2012.6248054
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wu HF, 2014, VISUAL COMPUT, V30, P229, DOI 10.1007/s00371-013-0823-3
   Wu RB, 2013, PROC CVPR IEEE, P867, DOI 10.1109/CVPR.2013.117
   Xu X, 2015, INT J PROD RES, V53, P7005, DOI 10.1080/00207543.2014.937013
   Yandex Artem Babenko, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1269, DOI 10.1109/ICCV.2015.150
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang YJ, 2016, INT CONF SOFTW ENG, P337, DOI 10.1109/ICSESS.2016.7883080
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zhu CB, 2017, IEEE INT CONF COMP V, P1509, DOI 10.1109/ICCVW.2017.178
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 48
TC 46
Z9 46
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26351
EP 26369
DI 10.1007/s11042-018-5863-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500008
DA 2024-07-18
ER

PT J
AU Pan, YS
   Xia, Y
   Song, Y
   Cai, WD
AF Pan, Yongsheng
   Xia, Yong
   Song, Yang
   Cai, Weidong
TI Locality constrained encoding of frequency and spatial information for
   image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Bag-of-features (BoF); Image decomposition;
   Wavelet transform; Spatial pyramid matching (SPM)
ID REPRESENTATION; RETRIEVAL; FEATURES; MODEL
AB The bag-of-feature (BoF) model provides a way to construct high-level representation for image classification. Although spatial pyramid matching (SPM) has been incorporated into many of its extensions, these models intrinsically lack the mechanism to utilize frequency domain information. In this paper, we propose the locality-constrained encoding of frequency and spatial information (LEFSI) algorithm, in which an image is decomposed into multiple frequency components and each component is further decomposed into subregions using SPM. The scale-invariant feature transform (SIFT) descriptors are first calculated in each subregion, and then converted into a global descriptor by using the codebook generated on a category-by-category basis and locality-constrained linear coding (LLC). The image feature is defined as the concatenation of global descriptors constructed in all subregions. We evaluated this algorithm against several state-of-the-art models on six benchmark datasets. Our results suggest that the proposed LEFSI algorithm can describe images more effectively and provide more accurate image classification.
C1 [Pan, Yongsheng; Xia, Yong] Northwestern Polytech Univ, Sch Comp Sci & Engn, Shaanxi Key Lab Speech & Image Informat Proc SAII, Xian 710072, Shaanxi, Peoples R China.
   [Xia, Yong] Northwestern Polytech Univ, Sch Comp Sci & Engn, CMCC, Xian 710072, Peoples R China.
   [Song, Yang; Cai, Weidong] Univ Sydney, Sch Informat Technol, Biomed & Multimedia Informat Technol BMIT Res Grp, Camperdown, NSW 2006, Australia.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University; University of Sydney
RP Xia, Y (corresponding author), Northwestern Polytech Univ, Sch Comp Sci & Engn, Shaanxi Key Lab Speech & Image Informat Proc SAII, Xian 710072, Shaanxi, Peoples R China.; Xia, Y (corresponding author), Northwestern Polytech Univ, Sch Comp Sci & Engn, CMCC, Xian 710072, Peoples R China.
EM yxia@nwpu.edu.cn
RI Song, Yangyi/HGU-4953-2022; Cai, Tingwei Bill/AAJ-8822-2020; Song,
   Yangyi/JBJ-7119-2023
OI Song, Yangyi/0000-0002-3649-014X; Song, Yangyi/0000-0002-3649-014X;
   Song, Yang/0000-0003-1283-1672; Pan, Yongsheng/0000-0002-8067-1132; Cai,
   Weidong/0000-0003-3706-8896
FU National Natural Science Foundation of China [61471297, 61771397];
   Innovation Foundation for Doctor Dissertation of Northwestern
   Polytechnical University; Australian Research Council (ARC)
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61471297 and 61771397, in part by
   Innovation Foundation for Doctor Dissertation of Northwestern
   Polytechnical University and in part by the Australian Research Council
   (ARC) Grants.
CR [Anonymous], 2013, Tech. rep.
   [Anonymous], 2011, Technical Report CNS-TR-2011-001
   [Anonymous], IEEE T AFFECT COMPUT
   [Anonymous], 2004, WORKSH STAT LEARN CO
   [Anonymous], 2004, P BRIT MACHINE VISIO
   [Anonymous], 2009, P ADV NEUR INF PROC
   Bo L., 2011, Neural Information Processing Systems, P2115
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963
   Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding GG, 2017, NEUROCOMPUTING, V257, P24, DOI 10.1016/j.neucom.2017.01.055
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Gao SH, 2010, LECT NOTES COMPUT SC, V6314, P1
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Griffin G., 2007, CALTECH 256 OB UNPUB
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hu WM, 2014, IEEE T PATTERN ANAL, V36, P2338, DOI 10.1109/TPAMI.2014.2327975
   Juneja M, 2013, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2013.124
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Larlus D, 2009, IMAGE VISION COMPUT, V27, P523, DOI 10.1016/j.imavis.2008.04.022
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li LJ, 2014, INT J COMPUT VISION, V107, P20, DOI 10.1007/s11263-013-0660-x
   Li T, 2016, NEUROCOMPUTING, V172, P281, DOI 10.1016/j.neucom.2014.10.101
   [李学龙 Li Xuelong], 2015, [中国科学. 信息科学, Scientia Sinica Informationis], V45, P827
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y.-S., 2015, Sci. World J, V2015, P2, DOI DOI 10.1016/J.LINDIF.2015.02.002
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Luo C, IEEE T MULTIMEDIA, V18, P40
   Luo Y, 2016, IEEE T IMAGE PROCESS, V25, P414, DOI 10.1109/TIP.2015.2495116
   Luo Y, 2015, IEEE T KNOWL DATA EN, V27, P3111, DOI 10.1109/TKDE.2015.2445757
   Nilsback M.E., 2006, IEEE C COMP VIS PATT, P1447, DOI DOI 10.1109/CVPR.2006.42
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   Quan YH, 2016, PATTERN RECOGN, V55, P247, DOI 10.1016/j.patcog.2016.01.028
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Sadeghi F, 2012, EUR C COMP VIS ECCV
   Shaban A, 2015, IEEE T IMAGE PROCESS, V24, P5074, DOI 10.1109/TIP.2015.2465171
   Shen XB, 2015, NEUROCOMPUTING, V148, P397, DOI 10.1016/j.neucom.2014.06.015
   Si ZZ, 2013, IEEE T PATTERN ANAL, V35, P2189, DOI 10.1109/TPAMI.2013.35
   Song XH, 2015, PROC CVPR IEEE, P1312, DOI 10.1109/CVPR.2015.7298736
   Thiagarajan JJ, 2014, IEEE T IMAGE PROCESS, V23, P2905, DOI 10.1109/TIP.2014.2322938
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang S, 2015, IEEE T PATTERN ANAL, V37, P2478, DOI 10.1109/TPAMI.2015.2424880
   Wang ZZ, 2008, IEEE T IMAGE PROCESS, V17, P1421, DOI 10.1109/TIP.2008.926150
   Xie LX, 2014, IEEE T IMAGE PROCESS, V23, P1994, DOI 10.1109/TIP.2014.2310117
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang L, 2016, IEEE T MULTIMEDIA, V18, P247, DOI 10.1109/TMM.2015.2510509
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zhu J, 2016, IEEE T IMAGE PROCESS, V25, P150, DOI 10.1109/TIP.2015.2498407
   Zou JY, 2016, INFORM SCIENCES, V348, P209, DOI 10.1016/j.ins.2016.02.021
NR 60
TC 7
Z9 7
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 24891
EP 24907
DI 10.1007/s11042-018-5712-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400014
DA 2024-07-18
ER

PT J
AU Savakar, DG
   Hosur, R
AF Savakar, Dayanand G.
   Hosur, Ravi
TI A relative 3D scan and construction for face using meshing algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D image; RealSense; Depth; Segmentation; Texture; Projection; Meshing;
   Point cloud
ID COMPRESSION; FEATURES
AB Three-dimensional object construction has seen a great deal of activity in the past decade, as has been pointed out in recent surveys, with the advancement of technology and easy availability of the depth sensors the 3D scanning technology has taken off. A wide range of commercial sensors such as Intel RealSense, Microsoft Kinect are being widely used for real time 3D capturing. Efficient 3D face scanning is one of the important areas of 3D scanning. 3D printer compatible texture supported scanning has a wide range of commercial applications. Such methods are also being used for 3D avatars and characterizations for games. Even though several commercial grade applications are available, most of the techniques suffer from background and light variations. Therefore an efficient face scanning technique is of extreme importance. In this paper we propose a 3D face scanning method based on Intel RealSense technology that combines 3D face detection, background segmentation and 3D mesh mapping to produce realistic 3D face model along with texture export. Further the models then can be manipulated using any 3D editing software along with texture and wireframe manipulation.
C1 [Savakar, Dayanand G.] Rani Channamma Univ, Dept Comp Sci, Dr P G Halakatti Post Grad Ctr, Vachana Sangama, Vijayapur 586108, Karnataka, India.
   [Hosur, Ravi] BLDEAs VP Dr PGH Coll Engn & Technol, Dept Comp Sci & Engn, Vijayapur 586103, Karnataka, India.
RP Savakar, DG (corresponding author), Rani Channamma Univ, Dept Comp Sci, Dr P G Halakatti Post Grad Ctr, Vachana Sangama, Vijayapur 586108, Karnataka, India.
EM dgsavakar@gmail.com; hosuravi@gmail.com
RI Hosur, Ravi/AAO-4446-2020
OI Hosur, Ravi/0000-0002-6578-9001; Savakar, Dayanand/0000-0001-5900-2594
CR Abd Manap N, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (IEEE ICSIPA 2013), P61, DOI 10.1109/ICSIPA.2013.6707978
   Alyuz SN, 2008, 1 COST 2101 WORKSH B
   [Anonymous], 3D IM IC3D 2013 INT
   Cheng SY, 2014, IEEE IMAGE PROC, P1425, DOI 10.1109/ICIP.2014.7025285
   Dame A, 2013, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2013.170
   Daribo I, 2014, IEEE T IMAGE PROCESS, V23, P4696, DOI 10.1109/TIP.2014.2353817
   DINCER S, 2014, PEGEM ATIF INDEKSI, P1, DOI DOI 10.14527/PEGEM.001
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Gadkari D., 2004, THESIS
   Herrera JL, 2015, IEEE 3DTV C TRUE VIS, P1
   Hwang J, 2012, SENSORS-BASEL, V12, P12870, DOI 10.3390/s121012870
   Ionescu D, 2013, IEEE IMTC P, P629
   Kaneko M, 2015, IEEE INT C INT ROBOT, P1314, DOI 10.1109/IROS.2015.7353538
   Kemelmacher-Shlizerman I, 2011, IEEE T PATTERN ANAL, V33, P394, DOI 10.1109/TPAMI.2010.63
   López-de-Teruel PE, 2006, INT C PATT RECOG, P143
   Park A, 2012, IEEE IMAGE PROC, P573, DOI 10.1109/ICIP.2012.6466924
   Poon Geoffery, 2014, 2014 International Conference on Smart Computing (SMARTCOMP), P150, DOI 10.1109/SMARTCOMP.2014.7043853
   Ranipa KR, 2011, MACH LEARN SIGN PROC, P1
   Wang D., 2012, Proceedings of the 12th ACM SIGMETRICS/PERFORMANCE joint international conference on Measurement and Modeling of Computer Systems, SIGMETRICS'12, P187, DOI DOI 10.1049/CP.2012.1749
   Wang Z, 2013, 2013 INT C 3DTV C
   Xiang-cheng C, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS I-V, CONFERENCE PROCEEDINGS, P2326, DOI 10.1109/ICMA.2007.4303916
   Xu XY, 2012, ADV INTEL SYS RES, V21, P84
   Xuyuan Xu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P544, DOI 10.1109/ICASSP.2014.6853655
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
   Zhang LZ, 2014, INT CONF SIGN PROCES, P816, DOI 10.1109/ICOSP.2014.7015117
   Zhongjun Wu, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163148
   Zhou Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P976, DOI 10.1109/ICInfA.2015.7279428
   Zujovic J, 2013, IEEE T IMAGE PROCESS, V22, P2545, DOI 10.1109/TIP.2013.2251645
NR 28
TC 0
Z9 0
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25253
EP 25273
DI 10.1007/s11042-018-5783-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400029
DA 2024-07-18
ER

PT J
AU Zhao, DN
   Wang, RK
   Lu, ZM
AF Zhao, Dong-Ning
   Wang, Ren-Kui
   Lu, Zhe-Ming
TI Inter-frame passive-blind forgery detection for video shot based on
   similarity analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital video forensics; Inter-frame forgery; Passive-blind forensics;
   HSV color histogram; SURF feature extraction; FLANN matching
AB Frame insertion, deletion and duplication are common inter-frame tampering operations in digital videos. In this paper, based on similarity analysis, a passive-blind forensics scheme for video shots is proposed to detect inter-frame forgeries. This method is composed of two parts: HSV (Hue-Saturation-Value) color histogram comparison and SURF (Speeded Up Robust Features) feature extraction together with FLANN (Fast Library for Approximate Nearest Neighbors) matching for double-checking. We mainly calculate H-S and S-V color histograms of every frame in a video shot and compare the similarity between histograms to detect and locate tampered frames in the shot. Then we utilize SURF feature extraction and FLANN matching to further confirm the forgery types in the tampered locations. Experimental results demonstrate that the proposed detection method is efficient and accurate in terms of forgery identification and localization. In contrast to other inter-frame forgery detection methods, our scheme can detect three kinds of forgery operations and has its own superiority and applicability as a passive-blind detection method.
C1 [Zhao, Dong-Ning] Shenzhen Univ, Coll Informat Engn, Shenzhen 518060, Peoples R China.
   [Zhao, Dong-Ning] Harbin Inst Technol Shenzhen, Shenzhen 518055, Peoples R China.
   [Wang, Ren-Kui; Lu, Zhe-Ming] Zhejiang Univ, Sch Aeronaut & Astronaut, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Shenzhen University; Harbin Institute of Technology; Zhejiang University
RP Lu, ZM (corresponding author), Zhejiang Univ, Sch Aeronaut & Astronaut, Hangzhou 310027, Zhejiang, Peoples R China.
EM zheminglu@zju.edu.cn
RI Zhao, Dongning/A-5836-2018
OI Lu, Zhe-Ming/0000-0003-1785-7847
FU Nature Science Foundation of Guangdong Province [2015A030310172];
   Science & Technology Plan Projects of Shenzhen [JCYJ20170302145623566]
FX The project is supported by the Nature Science Foundation of Guangdong
   Province (2015A030310172), the Science & Technology Plan Projects of
   Shenzhen (JCYJ20170302145623566).
CR Abdallah EE, 2007, LECT NOTES COMPUT SC, V4633, P772
   Al-Ayyoub M, 2016, MULTIMED TOOLS APP, P1
   Al-Qurishi M, 2017, FUTURE GENER COMP SY, P1
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Chen XF, 2015, IEEE T INF FOREN SEC, V10, P69, DOI 10.1109/TIFS.2014.2363765
   Elsheh E, 2011, EXPERT SYST APPL, V38, P13906, DOI 10.1016/j.eswa.2011.04.197
   Gong Y, 2013, J COMPUTATIONAL INFO, V9, P9927
   Grana C, 2007, 6 ACM INT C IM VID R, P302
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Hou ZJ, 2014, SENSORS TRANSDUCERS, V170, P281
   Huang ZA, 2017, INFORM SCIENCES, V412, P223, DOI 10.1016/j.ins.2017.05.031
   Hyun D-K, 2012, ERA INTERACTIVE MEDI, P25, DOI DOI 10.1007/978-1-4614-3501-3_3
   Li F., 2014, Proceedings of the 3rd International Conference on Multimedia Technology (ICMT 2013), P63
   Li L., 2013, Detecting removed object from video with stationary background Digital Forensics and Watermaking, P242
   Lin C-S., 2013, 2 INT C CYB SEC CYB, P107
   Lin CS, 2014, DIGIT INVEST, V11, P120, DOI 10.1016/j.diin.2014.03.016
   Lin GS, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412500176
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Qin Y, 2009, J COMPUTER RES DEV S, P227
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Subramanyam AV, 2013, INT CONF ACOUST SPEE, P3038, DOI 10.1109/ICASSP.2013.6638216
   Subramanyam AV, 2012, IEEE INT WORKSH MULT, P89, DOI 10.1109/MMSP.2012.6343421
   Sun TF, 2012, INT CONF ACOUST SPEE, P1389, DOI 10.1109/ICASSP.2012.6288150
   Wang Jenn-hwan., 2015, Border Crossing in Greater China: Production, Community and Identity, P1
   Wang WH, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P35
   Wang YR, 2014, ADV INTELL SYST, V277, P1085, DOI 10.1007/978-3-642-54924-3_103
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
   Yang JM, 2016, MULTIMED TOOLS APPL, V75, P1793, DOI 10.1007/s11042-014-2374-7
   Yuxing Wu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2674, DOI 10.1109/ICASSP.2014.6854085
   Zhenzhen Zhang, 2016, Digital Forensics and Watermarking. 14th International Workshop, IWDW 2015. Revised Selected Papers: LNCS 9569, P94, DOI 10.1007/978-3-319-31960-5_9
NR 30
TC 31
Z9 32
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25389
EP 25408
DI 10.1007/s11042-018-5791-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400036
DA 2024-07-18
ER

PT J
AU Cheng, XE
   Du, SS
   Li, HY
   Hu, JF
   Chen, ML
AF Cheng, Xi En
   Du, Shan Shan
   Li, Hui Ying
   Hu, Jing Fang
   Chen, Ming Lu
TI Obtaining three-dimensional trajectory of multiple fish in water tank
   via video tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fish school; Target tracking; Identity preserving; Master-slave
   paradigm; Convolutional neural network; Fish-head
ID SWIMMING BEHAVIOR; IMAGE; SYSTEM; CAMERA
AB Accurately and reliably obtaining the three-dimensional motion data of individuals in fish schools is not only valuable for fish behaviour analysis and hydrodynamics studies but also be helpful in areas such as bio-inspired robot design. Video tracking is the most effective gateway to obtain the quantitative motion data of continuously moving objects. In this paper we propose a method for obtaining the quantitative three-dimensional trajectory of individuals in fish schools. The proposed method works on videos captured by multiple synchronized cameras with the help of a suggested three-camera imaging system. The proposed method follows the master-slave paradigm in which it tracks fish in the master view with the help of the convolutional neural network in the first, and then associates each certain fish in the master view with detections in the slave view by formulating the cross-view data association as the moment-wise linear assignment problems. Experiments have conducted on public datasets to completely evaluate the performance. The proposed method outperforms other state-of-the-art methods.
C1 [Cheng, Xi En; Li, Hui Ying; Hu, Jing Fang; Chen, Ming Lu] Jingdezhen Ceram Inst, Jingdezhen, Peoples R China.
   [Cheng, Xi En] Fudan Univ, Sch Comp Sci, Shanghai, Peoples R China.
   [Du, Shan Shan] Fudan Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China.
C3 Jingdezhen Ceramic Institute; Fudan University; Fudan University
RP Cheng, XE (corresponding author), Jingdezhen Ceram Inst, Jingdezhen, Peoples R China.; Cheng, XE (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai, Peoples R China.
EM chengxien@jci.edu.cn
FU Educational Commission of Jiangxi Province, China [GJJ160911,
   GJJ160904]; Science and Technology Program of Jingdezhen City, China
   [2017GYZD016-02]
FX The research work presented in this paper is partly supported by
   Educational Commission of Jiangxi Province, China (Grant No. GJJ160911,
   GJJ160904) and partly supported by the Science and Technology Program of
   Jingdezhen City, China (Grant No. 2017GYZD016-02).
CR Andriyenko A, 2012, PROC CVPR IEEE, P1926, DOI 10.1109/CVPR.2012.6247893
   Andriyenko A, 2011, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2011.5995311
   [Anonymous], 2015, P 24 INT JOINT C
   [Anonymous], PATTERN RECOGN
   [Anonymous], SCI REP
   [Anonymous], 2015, ARXIV14124564CSCV
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 1999, Introduction to pattern recognition: Statistical, structural, neural, and fuzzy logic approaches
   Ardekani R, 2013, J R SOC INTERFACE, V10, DOI 10.1098/rsif.2012.0547
   Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21
   Butail S, 2012, J R SOC INTERFACE, V9, P77, DOI 10.1098/rsif.2011.0113
   Cheng X, 2016, 2016 IEEE 23RD INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), VOL 1, P13, DOI 10.1109/SANER.2016.20
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Delcourt J, 2006, BEHAV RES METHODS, V38, P704, DOI 10.3758/BF03193904
   Dell AI, 2014, TRENDS ECOL EVOL, V29, P417, DOI 10.1016/j.tree.2014.05.004
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   JONKER R, 1987, COMPUTING, V38, P325, DOI 10.1007/BF02278710
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu JD, 2010, J BIONIC ENG, V7, P35, DOI 10.1016/S1672-6529(09)60184-0
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Milan A, 2016, IEEE T PATTERN ANAL, V38, P2054, DOI 10.1109/TPAMI.2015.2505309
   Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103
   Milan A, 2013, PROC CVPR IEEE, P3682, DOI 10.1109/CVPR.2013.472
   Nimkerdphol K, 2008, J BIOSCI BIOENG, V105, P486, DOI 10.1263/jbb.105.486
   PEREIRA P, 1994, BEHAV RES METH INSTR, V26, P443, DOI 10.3758/BF03204663
   Pérez-Escudero A, 2014, NAT METHODS, V11, P743, DOI [10.1038/NMETH.2994, 10.1038/nmeth.2994]
   Pirsiavash H, 2011, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2011.5995604
   Qian ZM, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0106506
   Rosemberg DB, 2012, NEUROPHARMACOLOGY, V63, P613, DOI 10.1016/j.neuropharm.2012.05.009
   Rosenthal SB, 2015, P NATL ACAD SCI USA, V112, P4690, DOI 10.1073/pnas.1420068112
   Sakakibara J, 2004, EXP FLUIDS, V36, P282, DOI 10.1007/S00348-003-0720-Z
   Strandburg-Peshkin A, 2013, CURR BIOL, V23, pR709, DOI 10.1016/j.cub.2013.07.059
   Straw AD, 2011, J R SOC INTERFACE, V8, P395, DOI 10.1098/rsif.2010.0230
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   Voesenek CJ, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146682
   Wu Z., 2014, IEEE APSIPA ASC, P1, DOI 10.1109/APSIPA.2014.7041636
   Wu Z, 2009, IEEE I CONF COMP VIS, P1546
   Xiaoyuan Tu, 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P43
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Yuan Li, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2953, DOI 10.1109/CVPRW.2009.5206735
   Zhu LQ, 2007, PHYSIOL BEHAV, V91, P106, DOI 10.1016/j.physbeh.2007.01.023
NR 47
TC 13
Z9 13
U1 6
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24499
EP 24519
DI 10.1007/s11042-018-5755-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900063
DA 2024-07-18
ER

PT J
AU Liu, F
   Ma, LH
   Liu, C
   Lu, ZM
AF Liu, Feng
   Ma, Long-Hun
   Liu, Cong
   Lu, Zhe-Ming
TI Optimal blind watermarking for color images based on the U matrix of
   quaternion singular value decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Copyright protection; Quatemion singular value
   decomposition (QSVD); U matrix
ID MULTIMEDIA; SCHEME
AB In this paper, a new blind watermarking for copyright protection of color images based on the U matrix through Quatemion Singular Value Decomposition (QSVD) is proposed. The proposed method represents the color image with a quaternion matrix, so that it can deal with the multichannel information in a holistic way. Then the array of pure quaternion is divided into non-overlapping blocks and we perform QSVD on each block to get its U matrix. The watermark is inserted into the optimally selected coefficients of the quaternion elements in the first column of the U matrix. Besides, in the procedures of watermark insertion and extraction, ensuring higher fidelity and robustness to several possible image attacks have been considered. The experimental results show that the proposed method outperforms existing schemes in terms of robustness and invisibility.
C1 [Liu, Feng; Ma, Long-Hun; Liu, Cong; Lu, Zhe-Ming] Zhejiang Univ, Sch Informat Sci & Engn, Ningbo Inst Technol, Ningbo 315100, Zhejiang, Peoples R China.
   [Lu, Zhe-Ming] Zhejiang Univ, Sch Aeronaut & Astronaut, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Liu, F (corresponding author), Zhejiang Univ, Sch Informat Sci & Engn, Ningbo Inst Technol, Ningbo 315100, Zhejiang, Peoples R China.
EM lf_nit@sina.com
FU National Nature Science Foundation of China [61633019, 61272020];
   Zhejiang Provincial Natural Science Foundation of China [LZ15F030004];
   Ningbo Science & Technology Plan Project [2014B82015]; Natural Science
   Foundation of Ningbo City [2015A610134]; General project of Zhejiang
   Provincial Department of Education [Y201636899]
FX This work is supported by the National Nature Science Foundation of
   China under grant No. 61633019, 61272020 and the Zhejiang Provincial
   Natural Science Foundation of China under grant No. LZ15F030004 and
   Ningbo Science & Technology Plan Project under grant No.2014B82015 and
   the Natural Science Foundation of Ningbo City under Grants 2015A610134
   and the General project of Zhejiang Provincial Department of Education
   under grant No Y201636899.
CR Al-Otum HM, 2010, SIGNAL PROCESS, V90, P2498, DOI 10.1016/j.sigpro.2010.02.017
   Bao P, 2005, IEEE T CIRC SYST VID, V15, P96, DOI 10.1109/TCSVT.2004.836745
   Battiato S, 2012, IEEE MULTIMEDIA, V19, P17, DOI 10.1109/MMUL.2012.10
   Benhocine A., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P9
   Chandra DVS, 2002, 2002 45TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, CONFERENCE PROCEEDINGS, P264
   Chou CH, 2010, IEEE T IMAGE PROCESS, V19, P2966, DOI 10.1109/TIP.2010.2052261
   Deng C, 2009, SIGNAL PROCESS, V89, P1531, DOI 10.1016/j.sigpro.2009.02.005
   Fanzhi Kong, 2010, 2010 2nd International Conference on Industrial and Information Systems (IIS 2010), P464, DOI 10.1109/INDUSIS.2010.5565754
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P278, DOI 10.1109/TSMCC.2009.2037512
   Hamilton W., 1866, ELEMENTS QUATERNIONS
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Hsieh SL, 2005, PROC WRLD ACAD SCI E, V10, P17
   Hwang MS, 1999, IEEE T CONSUM ELECTR, V45, P286, DOI 10.1109/30.793411
   Lin PY, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2000486.2000489
   Moosazadeh M, 2017, OPTIK, V140, P975, DOI 10.1016/j.ijleo.2017.05.011
   Shang-Lin Hsieh, 2008, Journal of Multimedia, V3, P42
   Shi HQ, 2010, 2010 THIRD INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY AND SECURITY INFORMATICS (IITSI 2010), P781, DOI 10.1109/IITSI.2010.167
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Thien HT, 2016, EXPERT SYST APPL, V62, P177, DOI 10.1016/j.eswa.2016.06.015
   Tsai HH, 2007, INFORM SCIENCES, V177, P550, DOI 10.1016/j.ins.2006.05.002
   Tsougenis ED, 2014, EXPERT SYST APPL, V41, P6408, DOI 10.1016/j.eswa.2014.04.021
   Wang XY, 2013, J SYST SOFTWARE, V86, P255, DOI 10.1016/j.jss.2012.08.015
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2017, PROC IEEE MICR ELECT, P813, DOI 10.1109/MEMSYS.2017.7863532
   Xie X, 2016, PROC IEEE MICR ELECT, P75, DOI 10.1109/MEMSYS.2016.7421561
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
NR 26
TC 11
Z9 11
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23483
EP 23500
DI 10.1007/s11042-018-5652-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900019
DA 2024-07-18
ER

PT J
AU Muthukannan, K
   Latha, P
AF Muthukannan, Kanthan
   Latha, Pitchai
TI A GA_FFNN algorithm applied for classification in diseased plant leaf
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE PSO-based segmentation; Genetic algorithm; Weight optimization; Feed
   forward neural network; Leaf severity analysis
AB In order to solve the problems of conventional neural network when it is applied to the diseased plant leaf system such as making itself for better classification, Genetic algorithm-based feed forward neural network (GA_FFNN) hybrid technique is proposed. Besides, Particle swarm optimization (PSO)-based segmented hybrid features were used for the analysis of classification of diseased leaf and its severity. The main contribution of this paper incorporates Genetic weight optimization-based neural network systems of diseased plant leaf classification for better classification accuracy. Various diseased plant leaves such as bitter gourd (Brown Leaf Spot), beans (Pest leaf minor), chilly (Pest), Cotton (Mineral Deficiency), pigeon pea (Blight Leaf minor) and tomato (Leaf spot) were used. In the proposed work, attributes are combined as a single vector for hybrid features. Five attributes, namely contrast, correlation, energy, homogeneity and area of the leaf were used as features. Initially, the features were extracted from the segmented image after preprocessing. Genetic-based Feed Forward Neural network architecture is constructed for the classification of diseased plant leaf. The weight of the neural network is updated by Genetic algorithm for specified iterations. Finally, the performance is analyzed in different classes (class 2, class 3 and class 6) of diseased plant leaves using classification accuracy.
C1 [Muthukannan, Kanthan] Einstein Coll Engn, Dept ECE, Tirunelveli, Tamil Nadu, India.
   [Latha, Pitchai] Govt Coll Engn, Dept CSE, Tirunelveli, Tamil Nadu, India.
RP Muthukannan, K (corresponding author), Einstein Coll Engn, Dept ECE, Tirunelveli, Tamil Nadu, India.
EM maha_muthukannan@yahoo.com; plathamuthuraj@gmail.com
OI kannan, muthu/0000-0003-0857-030X
FU Tamilnadu Agricultural University
FX The authors would like to thank the reviewers for their valuable
   suggestions which have helped in improving the quality of this paper. We
   would like to thank the Tamilnadu Agricultural University for their
   continuous encouragement and support.
CR Abdullah N. E., 2007, 2007 5 STUD C RES DE
   Al-Hiary H., 2011, International Journal of Computer Applications, V17, P31, DOI [10.5120/2183-2754, DOI 10.5120/2183-2754]
   [Anonymous], ICASSP
   [Anonymous], 2010, J CONVERG INF TECHNO
   [Anonymous], 1995, Evolution and Optimum Seeking, Sixth-Generation Computer Technology Series
   Beichel R, 2006, LECT NOTES COMPUTER, V4241, P37
   FRASER A. S., 1957, AUSTRALIAN JOUR BIOL SCI, V10, P484
   Horn J., 1994, Proceedings of the First IEEE Conference on Evolutionary Computation. IEEE World Congress on Computational Intelligence (Cat. No.94TH0650-2), P82, DOI 10.1109/ICEC.1994.350037
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Huang CL, 2006, EXPERT SYST APPL, V31, P231, DOI 10.1016/j.eswa.2005.09.024
   Kutty SB, 2013, 2013 IEEE BUSINESS ENGINEERING AND INDUSTRIAL APPLICATIONS COLLOQUIUM (BEIAC 2013), P459
   Liu LC, 2016, INT C PATT RECOG, P1713, DOI 10.1109/ICPR.2016.7899883
   Liu LC, 2017, PATTERN RECOGN, V64, P314, DOI 10.1016/j.patcog.2016.10.034
   Muthukannan K, 2015, IMAGE ANAL STEREOL, V34, P209, DOI 10.5566/ias.1227
   Revathi P., 2014, International Journal of Engineering and Technology, V5, P4637
   Shi Z, 2009, NEURAL NETWORKS
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Song Kai, 2011, 2011 International Conference on Measuring Technology and Mechatronics Automation (ICMTMA), P246, DOI 10.1109/ICMTMA.2011.66
NR 18
TC 7
Z9 7
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24387
EP 24403
DI 10.1007/s11042-018-5710-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900058
DA 2024-07-18
ER

PT J
AU Yang, HH
   He, L
AF Yang, Honghong
   He, Li
TI Online multiple objects tracking with detection reliability prior
   constraint
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online multi-object tracking; Data association; Trajectory estimation;
   detection reliability; Local associated motion constraint
ID MULTIOBJECT TRACKING; MULTITARGET TRACKING; APPEARANCE
AB Multi-object tracking (MOT) is one popular topic in computer vision. It remains a challenging problem in complex scenes, especially of objects with similar appearance. In this case, many existing data association strategies, which link detections among consecutive frames according appearance and motion cues, may fail to track due to unreliable detections or confused appearance and motion. To solve this problem, this paper proposed a novel online multi-object tracking method with detection reliability prior constraint. Our method integrates the trajectory estimation and detection-prediction association into a unified framework. The detection reliability prior constraint is built with the Hankel matrix from object motion model. When we build the Hankel matrix, we adaptively select a set of previous frames to predict object states and calculate the associated weights between detections and candidate objects. Data association in MOT then is estimated by maximum a posteriori (MAP) in a Bayesian framework, accompanied with both previous trajectory and the current detection reliability. Experimental results using synthetic dataset and four public challenging datasets demonstrate that, the proposed method has a good tracking performance compared with the state-of-the-art multi-object trackers.
C1 [He, Li] Guangdong Univ Technol, Sch Electromech Engn, Guangzhou 510006, Guangdong, Peoples R China.
   [Yang, Honghong] Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada.
   [Yang, Honghong] Northwestern Polytech Univ, Dept Automat, Xian 710072, Shaanxi, Peoples R China.
C3 Guangdong University of Technology; University of Alberta; Northwestern
   Polytechnical University
RP He, L (corresponding author), Guangdong Univ Technol, Sch Electromech Engn, Guangzhou 510006, Guangdong, Peoples R China.
EM heli9903@mail.nwpu.edu.cn
RI He, Li/I-2951-2015
OI He, Li/0000-0003-0261-4068
FU National Natural Science Foundation of China [61673125, 61703115];
   Frontier and Key Technology Innovation Special Funds of Guangdong
   Province [2014B090919002, 2016B090910003, 2015B010917003]; Program of
   Foshan Innovation Team of Science and Technology [2015IT100072]
FX This work was supported in part by National Natural Science Foundation
   of China (Grant No. 61673125 and 61703115), in part by the Frontier and
   Key Technology Innovation Special Funds of Guangdong Province (Grant No.
   2014B090919002, 2016B090910003 and 2015B010917003) and Program of Foshan
   Innovation Team of Science and Technology (Grant No. 2015IT100072).
CR Andrikoula M, 2009, CLIMACTERIC, V12, P3, DOI 10.1080/13697130802556296
   Andriyenko A, 2012, PROC CVPR IEEE, P1926, DOI 10.1109/CVPR.2012.6247893
   [Anonymous], COMP VIS PATT REC CV
   [Anonymous], P C INF SCI SYST
   [Anonymous], 2010, Report Number 10 (26)
   [Anonymous], 2014, ARXIV14097618
   Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159
   Bae SH, 2014, IEEE T IMAGE PROCESS, V23, P2820, DOI 10.1109/TIP.2014.2320821
   Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232
   Brendel W, 2011, PROC CVPR IEEE, P1273, DOI 10.1109/CVPR.2011.5995395
   Chen ZC, 2017, IEEE T VEH TECHNOL, V66, P2144, DOI 10.1109/TVT.2016.2570816
   Chenouard N, 2013, IEEE T PATTERN ANAL, V35, P2736, DOI 10.1109/TPAMI.2013.97
   Collins RT, 2012, PROC CVPR IEEE, P1744, DOI 10.1109/CVPR.2012.6247870
   Dicle C, 2013, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2013.286
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Duan GQ, 2012, LECT NOTES COMPUT SC, V7574, P129, DOI 10.1007/978-3-642-33712-3_10
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jian-Yu Hsieh, 2007, Proceedings of the Fifth IASTED International Conference on Circuits, Signals, and Systems, P1, DOI 10.1145/1329125.1329139
   Kim C, 2015, IEEE I CONF COMP VIS, P4696, DOI 10.1109/ICCV.2015.533
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Kuo CH, 2011, PROC CVPR IEEE, P1217, DOI 10.1109/CVPR.2011.5995384
   Leibe B., 2007, COMPUTER VISION 2007, P1
   Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103
   Milan A, 2013, PROC CVPR IEEE, P3682, DOI 10.1109/CVPR.2013.472
   Oh S, 2009, IEEE T AUTOMAT CONTR, V54, P481, DOI 10.1109/TAC.2009.2012975
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Pirsiavash H, 2011, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2011.5995604
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177
   Rezatofighi SH, 2016, PROC CVPR IEEE, P136, DOI 10.1109/CVPR.2016.22
   Rezatofighi SH, 2015, IEEE I CONF COMP VIS, P3047, DOI 10.1109/ICCV.2015.349
   Wang B, 2017, IEEE T PATTERN ANAL, V39, P589, DOI 10.1109/TPAMI.2016.2551245
   Wang XY, 2013, IEEE I CONF COMP VIS, P17, DOI 10.1109/ICCV.2013.10
   Xiang Y, 2015, IEEE I CONF COMP VIS, P4705, DOI 10.1109/ICCV.2015.534
   Yang B, 2014, INT J COMPUT VISION, V107, P203, DOI 10.1007/s11263-013-0666-4
   Yang B, 2012, PROC CVPR IEEE, P1918, DOI 10.1109/CVPR.2012.6247892
   Yang M, 2015, LECT NOTES COMPUT SC, V9489, P623, DOI 10.1007/978-3-319-26532-2_69
   Yoon JH, 2016, PROC CVPR IEEE, P1392, DOI 10.1109/CVPR.2016.155
   Yoon JH, 2015, IEEE WINT CONF APPL, P33, DOI 10.1109/WACV.2015.12
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhao S, 2018, IEEE J BIOMED HEALTH, V22, P1571, DOI 10.1109/JBHI.2017.2776246
NR 46
TC 1
Z9 1
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23167
EP 23191
DI 10.1007/s11042-017-5530-z
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900005
DA 2024-07-18
ER

PT J
AU Yang, L
   Huang, XD
AF Yang, Lin
   Huang, Xiangdong
TI Harmonics extraction based speech recovery for underdetermined mixing
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underdetermined speech blind source separation; Spectrum correction;
   Single source component; Subspace projection
ID BLIND SOURCE SEPARATION; TIME-FREQUENCY DOMAIN; MIXTURES; ALGORITHM;
   SIGNALS; MODEL
AB It is an intractable task to achieve high-efficiency and high-quality speech recovery for the existing underdetermined systems. To solve this problem, this paper proposes a harmonics extraction based underdetermined speech recovery algorithm, which consists of 4 stages. In the 1st stage, spectrum correction technique is adopted to extract the harmonic components from the mixtures' short time Fourier transform (STFT); In the 2nd stage, a phase-coherence criterion is applied on these harmonic components to identify the single source components; In the 3rd stage, these single source patterns are further categorized into multiple groups by means of the adaptive k-means clustering, from which the mixing matrix is estimated; In the last stage, this estimated matrix is further combined with the subspace projection algorithm, which resultantly yields the final source recovery. The high efficiency lies in that the harmonics extraction is properly combined with single source component identification. The speech recovery experiment demonstrated that, compared to the original subspace projection algorithm, the proposed method can acquire a higher recovery quality, which presents a potential application in other harmonic related fields.
C1 [Yang, Lin; Huang, Xiangdong] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Huang, XD (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM xdhuang@tju.edu.cn
FU Qingdao National Laboratory for Marine Science and Technology
   [QNLM2016OPR0411]
FX This work was financially supported by Qingdao National Laboratory for
   Marine Science and Technology under Grant No. QNLM2016OPR0411.
CR Abrard F, 2005, SIGNAL PROCESS, V85, P1389, DOI 10.1016/j.sigpro.2005.02.010
   Aissa-El-Bey A, 2007, IEEE T SIGNAL PROCES, V55, P897, DOI 10.1109/TSP.2006.888877
   [Anonymous], 2008, ADV DIGITAL SIGNAL P
   Bofill P, 2001, SIGNAL PROCESS, V81, P2353, DOI 10.1016/S0165-1684(01)00120-7
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Erdogan AT, 2007, IEEE T SIGNAL PROCES, V55, P2182, DOI 10.1109/TSP.2007.893214
   Fu Wei-hong, 2014, Systems Engineering and Electronics, V36, P2143, DOI 10.3969/j.issn.1001-506X.2014.11.06
   Fu WH, 2017, IET SIGNAL PROCESS, V11, P877, DOI 10.1049/iet-spr.2015.0100
   [葛素楠 Ge Sunan], 2014, [电子学报, Acta Electronica Sinica], V42, P992
   Hild KE, 2008, IEEE T NEURAL NETWOR, V19, P508, DOI 10.1109/TNN.2007.914154
   Huang Z, 2014, SCI WORLD J, V2014, P1
   Hyvarinen A, 1997, NEURAL COMPUT, V9, P1483, DOI 10.1162/neco.1997.9.7.1483
   Liu BX, 2014, IEEE T SIGNAL PROCES, V62, P4947, DOI 10.1109/TSP.2014.2329646
   Ozerov A, 2010, IEEE T AUDIO SPEECH, V18, P550, DOI 10.1109/TASL.2009.2031510
   Qiao ZJ, 2017, MECH SYST SIGNAL PR, V84, P731, DOI 10.1016/j.ymssp.2016.08.030
   Sawada H, 2011, IEEE T AUDIO SPEECH, V19, P516, DOI 10.1109/TASL.2010.2051355
   SIEGEL LJ, 1982, IEEE T ACOUST SPEECH, V30, P451, DOI 10.1109/TASSP.1982.1163910
   [汤俊杰 Tang Junjie], 2014, [信号处理, Journal of Signal Processing], V30, P1321
   Wang X, 2014, J SYST ENG ELECTRON, V25, P17, DOI 10.1109/JSEE.2014.00003
   Xie SL, 2012, IEEE T NEUR NET LEAR, V23, P306, DOI 10.1109/TNNLS.2011.2177475
   Yilmaz Ö, 2004, IEEE T SIGNAL PROCES, V52, P1830, DOI 10.1109/TSP.2004.828896
   Yu JB, 2016, J SOUND VIB, V382, P340, DOI 10.1016/j.jsv.2016.06.046
   Zhang FS, 2001, IEEE T POWER DELIVER, V16, P160, DOI 10.1109/61.915476
   Zhou GX, 2011, IEEE T NEURAL NETWOR, V22, P211, DOI 10.1109/TNN.2010.2091427
NR 24
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22267
EP 22280
DI 10.1007/s11042-018-5919-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500029
DA 2024-07-18
ER

PT J
AU Ali, NA
   Cherradi, B
   El Abbassi, A
   Bouattane, O
   Youssfi, M
AF Ali, Noureddine Ait
   Cherradi, Bouchaib
   El Abbassi, Ahmed
   Bouattane, Omar
   Youssfi, Mohamed
TI GPU fuzzy c-means algorithm implementations: performance analysis on
   medical image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Fuzzy c-means algorithm; Parallel implementation;
   GPU
ID PARALLEL FRAMEWORK; HEVC
AB Image segmentation in the medical imagery such as MRI, is an essential step to the sensitive analysis of human tissues lesions with the objective to improve the partition of different parts of the image according to their specific characteristics. Fuzzy c-means (FCM) is one of the widely used algorithms in literature regarding image segmentation. Indeed, it offers performances to the precision level in many medical fields of applications. However, the main limitation of FCM algorithm is time consuming during the image segmentation by clustering. In order to improve and to reduce the time delay of image data processing, we implemented three methods inspired from the FCM on GPU GT 740 m by using the CUDA environment. This latter is well adapted to the new architectures of processing, and its sequential migration towards the parallel approach through the SIMD architecture as GPU cards solves this time constraint. Furthermore, we have improved, via the two current developed implementations methods, the speed up of the processing acquisition in comparison with the reference methods. The efficiency evaluation such as strengths and weaknesses of each implemented method will be evaluated on medical images segmentation according to the size of the modelled brain tumours.
C1 [Ali, Noureddine Ait; Cherradi, Bouchaib; Bouattane, Omar; Youssfi, Mohamed] Hassan 2 Univ Casablanca UH2C, ENSET, SSDIA Lab, Mohammadia, Morocco.
   [Cherradi, Bouchaib] Chouaib Doukkali Univ UCD, Fac Sci, CRMEF El Jadida, El Jadida, Morocco.
   [Cherradi, Bouchaib] Chouaib Doukkali Univ UCD, Fac Sci, LaROSERI Lab, El Jadida, Morocco.
   [El Abbassi, Ahmed] MIU, FST, EPIM Lab, Errachidia, Morocco.
C3 Hassan II University of Casablanca; Chouaib Doukkali University of El
   Jadida; Chouaib Doukkali University of El Jadida; Moulay Ismail
   University of Meknes
RP Cherradi, B (corresponding author), Hassan 2 Univ Casablanca UH2C, ENSET, SSDIA Lab, Mohammadia, Morocco.; Cherradi, B (corresponding author), Chouaib Doukkali Univ UCD, Fac Sci, CRMEF El Jadida, El Jadida, Morocco.; Cherradi, B (corresponding author), Chouaib Doukkali Univ UCD, Fac Sci, LaROSERI Lab, El Jadida, Morocco.
EM aitali_noureddine@yahoo.fr; bouchaib.cherradi@gmail.com;
   a.elabbassi@fste.umi.ac.ma; o.bouattane@gmail.com; med@youssfi.net
RI BOUATTANE, Omar/AAK-1235-2020; bouchaib, cherradi/J-2572-2016; Youssfi,
   Mohamed/IAP-5429-2023
OI bouchaib, cherradi/0000-0002-2016-8682; Youssfi,
   Mohamed/0000-0003-2842-9880; el abbassi, Ahmed/0000-0002-1149-0215;
   Omar, Bouattane/0000-0002-1207-2779
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Aitali N, 2016, COLLOQ INF SCI TECH, P460, DOI 10.1109/CIST.2016.7805092
   Aitali N, 2015, INT C MICROELECTRON, P118, DOI 10.1109/ICM.2015.7438002
   Aitali N, 2016, INT J ADV COMPUT SC, V7, P375
   Al-Ayyoub M, 2015, J SUPERCOMPUT, V71, P3149, DOI 10.1007/s11227-015-1431-y
   Alsmirat MA, 2017, MULTIMED TOOLS APPL, V76, P3537, DOI 10.1007/s11042-016-3884-2
   Anderson D, 2007, ADV SOFT COMP, V41, P128, DOI 10.1007/978-3-540-72432-2_14
   [Anonymous], THESIS
   [Anonymous], 2012, CUDA PROGRAMMING DEV
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Chuang KS, 2006, COMPUT MED IMAG GRAP, V30, P9, DOI 10.1016/j.compmedimag.2005.10.001
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Eklund A, 2013, MED IMAGE ANAL, V17, P1073, DOI 10.1016/j.media.2013.05.008
   Eschrich S, 2003, IEEE T FUZZY SYST, V11, P262, DOI 10.1109/TFUZZ.2003.809902
   Haiyang Li, 2014, Journal of Software, V9, P1985, DOI 10.4304/jsw.9.8.1985-1990
   Harris C, 2005, IEEE INT CONF FUZZY, P12
   Hwang C, 2007, IEEE T FUZZY SYST, V15, P107, DOI 10.1109/TFUZZ.2006.889763
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Pham DL, 1999, PATTERN RECOGN LETT, V20, P57, DOI 10.1016/S0167-8655(98)00121-4
   Pham DL, 2001, COMP MED SY, P127, DOI 10.1109/CBMS.2001.941709
   Pham DL, 1999, IEEE T MED IMAGING, V18, P737, DOI 10.1109/42.802752
   Pratx G, 2011, MED PHYS, V38, P2685, DOI 10.1118/1.3578605
   Rowinska Zdzislawa, 2012, Image processing & Communication, V17, P191, DOI 10.2478/v10248-012-0046-7
   Shalom S.A. A., 2008, AUSDM, V87, P179
   Shehab M, 2017, J SUPERCOMPUT, V73, P1929, DOI 10.1007/s11227-016-1897-2
   Smistad E, 2015, MED IMAGE ANAL, V20, P1, DOI 10.1016/j.media.2014.10.012
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhou S. K., 2015, Medical Image Recognition, Segmentation and Parsing: Machine Learning and Multiple Object Approaches
NR 31
TC 23
Z9 23
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21221
EP 21243
DI 10.1007/s11042-017-5589-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300040
DA 2024-07-18
ER

PT J
AU Du, GG
   Yin, CL
   Zhou, MQ
   Wu, ZK
   Duan, FQ
AF Du, Guoguang
   Yin, Congli
   Zhou, Mingquan
   Wu, Zhongke
   Duan, Fuqing
TI Part-in-whole matching of rigid 3D shapes using geodesic disk spectrum
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Part-in-whole matching; Geodesic disk; Shape index
ID FREE-FORM OBJECTS; SURFACE REGISTRATION; RETRIEVAL
AB Part-in-whole matching of rigid 3D shapes has attracted great interest in shape analysis and has various applications in computational archaeology. Rigid part-in-whole matching algorithms are mainly based on methods minimizing geometric distances and methods using local shape descriptors, which are challenging when the partial shapes are relatively small and smooth. This paper proposes a part-in-whole matching algorithm of rigid 3D shapes using geodesic disk spectrum (GDS), which achieves accurate matching results for partial shapes with arbitrary boundaries or smooth appearances. The largest enclosing geodesic disk of the partial shape and geodesic disks on the complete shape are extracted in the matching process. GDS is used as the matching descriptor, which is the distribution of shape index for enclosing points of the disk. The problem of matching partial surfaces with arbitrarily irregular boundaries to the complete shape is transformed into the matching of geodesic disks with the same radius using the proposed algorithm. GDS is discriminative, which can handle the situation when partial surfaces have few distinctive features. The proposed algorithm has been tested on various partial surfaces and obtained accurate matching results. A higher precision is achieved by comparing with existing part-in-whole matching algorithms, which proves the efficiency of the proposed algorithm.
C1 [Du, Guoguang; Yin, Congli; Zhou, Mingquan; Wu, Zhongke; Duan, Fuqing] Beijing Normal Univ, Coll Informat Sci & Technol, 19 XinJieKouWai ST, Beijing 100875, Peoples R China.
   [Du, Guoguang; Yin, Congli; Zhou, Mingquan; Wu, Zhongke; Duan, Fuqing] Key Lab Digital Protect & Virtual Real Cultural H, Beijing, Peoples R China.
C3 Beijing Normal University
RP Zhou, MQ (corresponding author), Beijing Normal Univ, Coll Informat Sci & Technol, 19 XinJieKouWai ST, Beijing 100875, Peoples R China.; Zhou, MQ (corresponding author), Key Lab Digital Protect & Virtual Real Cultural H, Beijing, Peoples R China.
EM mqzhou@bnu.edu.cn
RI Du, Guoguang/W-2156-2018
FU National Natural Science Foundation of China [61672103, 61572078,
   61402042, 61731015]
FX This research was carried out at Beijing Normal University, with the
   financial support of National Natural Science Foundation of China
   (61672103, 61572078, 61402042, and 61731015).
CR Aiger D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360684
   Albarelli A, 2015, PATTERN RECOGN, V48, P2209, DOI 10.1016/j.patcog.2015.01.020
   Attene M, 2011, VISUAL COMPUT, V27, P991, DOI 10.1007/s00371-011-0622-7
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Brown BJ, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276404, 10.1145/1239451.1239472]
   Castellani U, 2011, IEEE T PATTERN ANAL, V33, P2555, DOI 10.1109/TPAMI.2011.85
   Chen CS, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P242, DOI 10.1109/ICCV.1998.710725
   Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113
   Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1139, DOI 10.1109/34.625116
   Dubrovina A., 2010, P 5 INT S 3D DAT PRO, P1
   Faugeras O.D., 1983, P 8 INT JOINT C ARTI, V2, P996
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gal R, 2006, ACM T GRAPHIC, V25, P130, DOI 10.1145/1122501.1122507
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Hu JX, 2009, VISUAL COMPUT, V25, P667, DOI 10.1007/s00371-009-0340-6
   Itskovich A, 2011, COMPUT GRAPH-UK, V35, P334, DOI 10.1016/j.cag.2010.11.010
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Kazhdan M., 2003, Symposium on Geometry Processing, P156
   KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F
   Lavoue G., 2011, Eurographics Conference on 3D Object Retrieval, P41, DOI DOI 10.2312/3DOR/3DOR11/041-048
   Li WH, 2011, 2011 INTERNATIONAL CONFERENCE ON COMPUTER APPLICATION AND EDUCATION TECHNOLOGY (ICCAET 2011), P413, DOI 10.1109/3DIMPVT.2011.59
   Liu ZB, 2013, J COMPUT SCI TECH-CH, V28, P836, DOI 10.1007/s11390-013-1382-9
   Malassiotis S, 2007, IEEE T PATTERN ANAL, V29, P1285, DOI 10.1109/TPAMI.2007.1060
   Martinek M, 2015, VISUAL COMPUT, V31, P223, DOI 10.1007/s00371-014-1040-4
   Mellado N, 2014, COMPUT GRAPH FORUM, V33, P205, DOI 10.1111/cgf.12446
   MITCHELL JSB, 1987, SIAM J COMPUT, V16, P647, DOI 10.1137/0216045
   Mitra N.J., 2004, P 2004 EUROGRAPHICSA, P22, DOI 10.1145/1057432.1057435
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Rusinkiewicz S, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P486, DOI 10.1109/TDPVT.2004.1335277
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26
   Wu HY, 2010, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2010.5540180
   Xiao G, 2005, COMPUT VIS IMAGE UND, V98, P271, DOI 10.1016/j.cviu.2004.10.001
   Yu W, 2012, GRAPH MODELS, V74, P140, DOI 10.1016/j.gmod.2012.03.011
   Yu Zhong, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P689, DOI 10.1109/ICCVW.2009.5457637
   Zhang K, 2015, ACM SIGGRAPH POSTER
   Zhang K, 2015, IEEE I CONF COMP VIS, P2138, DOI 10.1109/ICCV.2015.247
NR 38
TC 3
Z9 5
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 18881
EP 18901
DI 10.1007/s11042-017-5315-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500001
DA 2024-07-18
ER

PT J
AU Jahid, T
   Hmimid, A
   Karmouni, H
   Sayyouri, M
   Qjidaa, H
   Rezzouk, A
AF Jahid, Tarik
   Hmimid, Abdeslam
   Karmouni, Hicham
   Sayyouri, Mhamed
   Qjidaa, Hassan
   Rezzouk, Abdellah
TI Image analysis by Meixner moments and a digital filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Meixner moments; Z-transform; digital filters; image slice
   representation
ID FAST COMPUTATION
AB In this paper, we propose a new method for the rapid calculation of Meixner's discrete orthogonal moments and its inverses. In this method, we have used the notion of digital filters based on the Z transform both to accelerate the computation time of Meixner and to reduce the reconstruction error of the images. To guarantee the numerical stability and robustness with respect to the noise, we propose two algorithms that treat the images as a set of blocks where each block will be treated independently. In fact, through the first algorithm, the moments of Meixner are computed from a set of geometric blocks of fixed size. On the other hand, in the second algorithm, the images are represented by a slice set where each slice contains several homogeneous blocks of different sizes. The moments of Meixner, in this case, are calculated from each block in each slice. The application of these two algorithms allowed us to deduce a significant reduction in processed information and image space, that permits the use of Meixner moments of low order for a better description of the fine details of the images. The performances of the proposed method are demonstrated through several simulations on different image bases.
C1 [Jahid, Tarik; Hmimid, Abdeslam; Karmouni, Hicham; Qjidaa, Hassan] Univ Sidi Mohamed Ben Abdellah Fez, Fac Sci Dhar El Mahrez, LESSI, CED ST,STIC, Fes, Morocco.
   [Sayyouri, Mhamed] Univ Choualb Doukkali, Ecole Natl Sci Appl El Jadida, Lab Sci Ingn Energie, BP 1166, El Jadida Plateau 24004, Morocco.
   [Rezzouk, Abdellah] Univ Sidi Mohamed Ben Abdellah Fez, Fac Sci Dhar El Mahrez, LPS, CED ST,SMPI, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Chouaib Doukkali University
   of El Jadida; Sidi Mohamed Ben Abdellah University of Fez
RP Jahid, T (corresponding author), Univ Sidi Mohamed Ben Abdellah Fez, Fac Sci Dhar El Mahrez, LESSI, CED ST,STIC, Fes, Morocco.
EM jahidtarik@gmail.com; abdeslam.hmimid@usmba.ac.ma;
   hicham.karmouni@usmba.ac.ma; mhamed.sayyouri@usmba.ac.ma;
   qjidah@yahoo.fr; rezzouk@yahoo.fr
RI Karmouni, Hicham/ACB-0232-2022; Sayyouri, Mhamed/AAB-5496-2020
OI Karmouni, Hicham/0000-0001-9225-8380; Sayyouri,
   Mhamed/0000-0002-1615-419X; Rezzouk, Abdellah/0000-0002-0682-1702;
   Hassan, qjidaa/0000-0003-4505-5243
CR Abu N. A., 2010, MAJLESI J ELECT ENG, V4, P037
   Asli BHS, 2014, INFORM SCIENCES, V288, P73, DOI 10.1016/j.ins.2014.07.046
   Asli BHS, 2013, DIGIT SIGNAL PROCESS, V23, P1738, DOI 10.1016/j.dsp.2013.05.004
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   El Fadili H, 2003, EURASIP J APPL SIG P, V2003, P902, DOI 10.1155/S1110865703305062
   Flusser J., 2009, Moments and Moment Invariants in Pattern Recognition
   HATAMIAN M, 1986, IEEE T ACOUST SPEECH, V34, P546, DOI 10.1109/TASSP.1986.1164853
   Hmimid A, 2015, PATTERN RECOGN, V48, P509, DOI 10.1016/j.patcog.2014.08.020
   Hmimid A, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.1.013026
   Honarvar B, 2014, J CIRCUIT SYST COMP, V23
   HSU HS, 1993, OPT ENG, V32, P1596, DOI 10.1117/12.139804
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Papakostas GA, 2010, IMAGE VISION COMPUT, V28, P414, DOI 10.1016/j.imavis.2009.06.011
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   Sayyouri M, 2013, MULTIMED TOOLS APPL, V75, P547
   Sayyouri M, 2015, CIRC SYST SIGNAL PR, V34, P875, DOI 10.1007/s00034-014-9881-7
   Spiliotis IM, 1998, IEEE T IMAGE PROCESS, V7, P1609, DOI 10.1109/83.725368
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Wang GB, 2006, PATTERN RECOGN, V39, P47, DOI 10.1016/j.patcog.2005.05.015
   Wang XY, 2014, INFORM SCIENCES, V277, P731, DOI 10.1016/j.ins.2014.02.158
   Wong WH, 1999, IEE P-VIS IMAGE SIGN, V146, P73, DOI 10.1049/ip-vis:19990158
   Yap PT, 2007, IEEE T PATTERN ANAL, V29, P2057, DOI 10.1109/TPAMI.2007.70709
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zhu H, 2010, IET IMAGE PROCESS, V4, P335, DOI 10.1049/iet-ipr.2009.0195
NR 28
TC 19
Z9 19
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19811
EP 19831
DI 10.1007/s11042-017-5371-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500042
DA 2024-07-18
ER

PT J
AU Wang, D
   Wang, B
   Zhao, SC
   Yao, HX
   Liu, H
AF Wang, Dong
   Wang, Bin
   Zhao, Sicheng
   Yao, Hongxun
   Liu, Hong
TI Off-the-shelf CNN features for 3D object retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D object retrieval; Deep learning; CNN; Autoencoder; Multigraph
   learning; Unseen objects
ID RECOGNITION
AB Effective feature representation is crucial to view-based 3D object retrieval (V3OR). Most previous works employed hand-crafted features to represent the views of each object. Although deep learning based methods has shown its excellent performance in many vision tasks, it is hard to get excellent performance for unsupervised 3D object retrieval. In this paper, we propose to combine the off-the-shelf deep model and graph model to retrieve unseen objects. By employing the powerful deep classification models which are trained from millions of images, we obtain significant improvements compared with state of the art methods. We validate the effectiveness of the ready CNN from other domains that can greatly facilitate the representative ability of objects' views. In addition, we analyze the representative abilities of different fully connected layers for V3OR, and propose to employ multigraph learning to fuse the deep features of different layers. The autoencoder is then explored to improve the retrieval speed to a large extent. Experiments on two popular datasets are carried out to demonstrate the effectiveness of the proposed method.
C1 [Wang, Dong; Zhao, Sicheng] Harbin Inst Technol, Harbin, Heilongjiang, Peoples R China.
   [Wang, Bin] Harbin Inst Technol, Dept Robot Res Inst, Harbin, Heilongjiang, Peoples R China.
   [Yao, Hongxun] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
   [Liu, Hong] Harbin Inst Technol, State Key Lab Robot & Syst, Harbin, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology; Harbin Institute of Technology; Harbin
   Institute of Technology; Harbin Institute of Technology
RP Wang, D (corresponding author), Harbin Inst Technol, Harbin, Heilongjiang, Peoples R China.
EM dwang89@hit.edu.cn
RI Wang, Bin/O-1322-2015
FU State Key Development Program of Basic Research of China (973 Program)
   [2013CB733105]; National Natural Science Foundation of China [61472103];
    [61133003]
FX This work is supported by State Key Development Program of Basic
   Research of China (973 Program) (No. 2013CB733105), the National Natural
   Science Foundation of China (No. 61472103) and Key Program (No.
   61133003).
CR [Anonymous], 2016, P EUR WORKSH 3D OBJ
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, P EUR WORKSH 3D OBJ
   [Anonymous], IEEE T MULTIMEDIA
   [Anonymous], P COMP VIS PATT REC
   [Anonymous], 2004, Guangdian Gongcheng
   [Anonymous], JLMH HEDGED DEEP TRA
   [Anonymous], 2009, P ACM INT C IM VID R, DOI DOI 10.1145/1646396.1646430
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Bai S, 2016, PROC CVPR IEEE, P5023, DOI 10.1109/CVPR.2016.543
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Daras P, 2010, INT J COMPUT VISION, V89, P229, DOI 10.1007/s11263-009-0277-2
   Gao Y, 2010, P ACM INT C MULT FIR, P955
   Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Gao Y, 2011, SIGNAL PROCESS-IMAGE, V26, P39, DOI 10.1016/j.image.2010.10.006
   Jayanti S, 2006, COMPUT AIDED DESIGN, V38, P939, DOI 10.1016/j.cad.2006.06.007
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Krause J, 2014, INT C PATT RECOG, P26, DOI 10.1109/ICPR.2014.15
   Leibe B, 2003, PROC CVPR IEEE, P409
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116
   Liu Q, 2012, IEEE SIGNAL PROC LET, V19, P295, DOI 10.1109/LSP.2012.2190060
   Liu Y, 2010, INT J COMPUT VISION, V89, P408, DOI 10.1007/s11263-009-0298-x
   Mahmoudi S, 2002, INT C PATT RECOG, P457, DOI 10.1109/ICPR.2002.1048337
   Massa F, 2016, PROC CVPR IEEE, P6024, DOI 10.1109/CVPR.2016.648
   Nie WZ, 2017, MULTIMEDIA SYST, V23, P325, DOI 10.1007/s00530-015-0485-2
   Ohbuchi R, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P93, DOI 10.1109/SMI.2008.4547955
   Papadakis P, 2010, INT J COMPUT VISION, V89, P177, DOI 10.1007/s11263-009-0281-6
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Simonyan K., 2014, 14091556 ARXIV
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
NR 40
TC 2
Z9 2
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19833
EP 19849
DI 10.1007/s11042-017-5413-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500043
DA 2024-07-18
ER

PT J
AU Abuein, QQ
   Shatnawi, MQ
   Yassein, MB
   Mahafza, R
AF Abuein, Qusai Q.
   Shatnawi, Mohammed Q.
   Yassein, Muneer Bani
   Mahafza, Reem
TI Intelligent system for visual web content analytics: A new approach and
   case study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text analysing; Visual data analytics; Artificial intelligence; Web
   content; Information retrieval; Search query
ID QUERIES
AB The accuracy of searches for visual data elements, as well as other types of information, depends on the terms used by the user in the input query to retrieve the relevant results and to reduce the irrelevant ones. Most of the results that are returned are relevant to the query terms, but not to their meaning. For example, certain types of web contents hold hidden information that traditional search engines are unable to retrieve. Searching for the mathematical construct of 1/x using Google will not result in the retrieval of the documents that contain the mathematically equivalent expressions (i.e. x(-1)). Because conventional search engines fall short of providing math-search capabilities. One of these capabilities is the ability of these search engines to detect the mathematical equivalence between users' quires and math contents. In addition, users sometimes need to use slang terms, either to retrieve slang-based visual data (e.g. social media content) or because they do not know how to write using classical form. To solve such a problem, this paper proposed an AI-based system for analysing multilingual slang web contents so as to allow a user to retrieve web slang contents that are relevant to the user's query. The proposed system presents an approach for visual data analytics, and it also enables users to analyse hundreds of potential search results/web pages by starting an informed friendly dialogue and presenting innovative answers.
C1 [Abuein, Qusai Q.; Shatnawi, Mohammed Q.; Yassein, Muneer Bani] Jordan Univ Sci & Technol, Fac Comp & Informat Technol, POB 3030, Irbid 22110, Jordan.
   [Mahafza, Reem] Shaqra Univ, Comp Sci Dept, Shaqra, Saudi Arabia.
C3 Jordan University of Science & Technology; Shaqra University
RP Shatnawi, MQ (corresponding author), Jordan Univ Sci & Technol, Fac Comp & Informat Technol, POB 3030, Irbid 22110, Jordan.
EM mshatnawi@just.edu.jo
RI Shatnawi, Mohammed/KIL-5364-2024
OI Abuein, Qusai/0009-0002-4323-4301; Bani Yassein,
   Muneer/0000-0001-5030-6196; Shatnawi, Mohammed/0000-0002-5560-3592
CR Abd Elraouf E, 2010, INT J COMPUT SCI NET, V10, P225
   Ahmed F, 2008, P INT MULT COMP SCI, P331
   Al-Kuyam F, 2009, THESIS
   Al-Rashdan B, 2008, JORDAN J MODERN LANG, V1, P61
   Al-Saidat Emad., 2010, European Journal of Social Sciences, V12, P397
   Al-Shalabi R, 2009, P INT C INF TECHN CE
   Clough P, 2013, EVALUATING PERFORMAN
   Drost I, 2005, P 22 CHAOS COMM C
   Elabd E, 2015, P INT ARAB J INFORM, V12, P3
   ElSayed Khaled Nasser, 2015, International Journal of Advanced Research in Artificial Intelligence, V4, P9
   Grehan M, 2003, SEARCH ENGINE MARKET
   Inamdar SA, 2008, RES REFLECTIONS INNO, P1062
   Kowalski J, 2000, INFORM STORAGE RETRI
   Luo G, 2009, PROC INT CONF DATA, P1379, DOI 10.1109/ICDE.2009.10
   Mahafza R., 2010, THESIS
   Nwesri A, 2008, THESIS
   Sanan M, 2008, P INF COMM TECHN THE, P1, DOI [10.1109/ICTTA.2008.4530003, DOI 10.1109/ICTTA.2008.4530003]
   Shaikh F, 2010, 2 IEEE INT C INF EM
   Shatnawi M, 2014, INT C COMP EXP SCI E
   Shatnawi M., 2007, Second IEEE International Conference on Digital Information Management (ICDIM), December 11-13, 2007, Lyon, France, P643, DOI [10 . 1109 / ICDIM.2007.4444297, DOI 10.1109/ICDIM.2007.4444297]
   Shatnawi MQ, 2014, J INF SCI, V40, P146, DOI 10.1177/0165551513508352
   Shatnawi MQ, 2012, INT J ADV COMPUT SC, V3, P78
   Shatnawi MQ, 2012, J INF SCI, V38, P350, DOI 10.1177/0165551512442480
   Sun L, 2009, THESIS
   Zhang H, 2009, INT WORKSH INF SEC A
NR 25
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 17557
EP 17571
DI 10.1007/s11042-017-4740-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900003
DA 2024-07-18
ER

PT J
AU Chebiyyam, M
   Reddy, RD
   Dogra, DP
   Bhaskar, H
   Mihaylova, L
AF Chebiyyam, Manaswi
   Reddy, Rohit Desam
   Dogra, Debi Prosad
   Bhaskar, Harish
   Mihaylova, Lyudmila
TI Motion anomaly detection and trajectory analysis in visual surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual surveillance; Anomalous activity detection; Abnormal behavior
   classification; Trajectory analysis
ID BLACKWELLIZED PARTICLE FILTER; OBJECT TRACKING; BEHAVIOR; ROBUST;
   RECOGNITION
AB Motion anomaly detection through video analysis is important for delivering autonomous situation awareness in public places. Surveillance scene segmentation and representation is the preliminary step to implementation anomaly detection. Surveillance scene can be represented using Region Association Graph (RAG), where nodes represent regions and edges denote connectivity among the regions. Existing RAG-based analysis algorithms assume simple anomalies such as moving objects visit statistically unimportant or abandoned regions. However, complex anomalies such as an object encircles within a particular region (Type-I) or within a set of regions (Type-II). In this paper, we extract statistical features from a given set of object trajectories and train multi-class support vector machines (SVM) to deal with each type of anomaly. In the testing phase, a given test trajectory is categorized as normal or anomalous with respect to the trained models. Performance evaluation of the proposed algorithm has been carried out on public as well as our own datasets. We have recorded sensitivity as high as 86% and fall-out rate as low as 9% in experimental evaluation of the proposed technique. We have carried out comparative analysis with state-of-the-art techniques to benchmark the method. It has been observed that the proposed model is consistent and highly accurate across challenging datasets.
C1 [Chebiyyam, Manaswi; Reddy, Rohit Desam; Dogra, Debi Prosad] IIT Bhubaneswar, Sch Elect Sci, Bhubaneswar, Odisha, India.
   [Bhaskar, Harish] Zero One Infin Consulting ZOIC Serv Ltd, Mississauga, ON, Canada.
   [Mihaylova, Lyudmila] Univ Sheffield, Dept Automat Control & Syst Engn, Sheffield, S Yorkshire, England.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Bhubaneswar; University of Sheffield
RP Dogra, DP (corresponding author), IIT Bhubaneswar, Sch Elect Sci, Bhubaneswar, Odisha, India.
EM mbc10@iitbbs.ac.in; rrd10@iitbbs.ac.in; dpdogra@iitbbs.ac.in;
   harish@zoiconsulting.ca; L.S.Mihaylova@sheffield.ac.uk
RI Mihaylova, Lyudmila/A-3512-2008
OI Mihaylova, Lyudmila/0000-0001-5856-2223
CR Abe Shigeo., 2005, Support vector machines for pattern classification, V53
   Alon N, 1997, ALGORITHMICA, V17, P209, DOI 10.1007/BF02523189
   [Anonymous], 2016, ARXIV161009462
   [Anonymous], 2008, INF FUS 2008 11 INT
   [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], 2015, PROC CVPR IEEE
   Antic B, 2011, IEEE I CONF COMP VIS, P2415, DOI 10.1109/ICCV.2011.6126525
   Batista J., 2006, P IEEE INT TRANSP SY, P528
   Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524
   Boers Y, 2006, IEE P-RADAR SON NAV, V153, P345, DOI 10.1049/ip-rsn:20050123
   Brasnett P, 2007, IMAGE VISION COMPUT, V25, P1217, DOI 10.1016/j.imavis.2006.07.017
   Brun L, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P405, DOI 10.1109/AVSS.2014.6918702
   Brun L, 2014, IEEE T CIRC SYST VID, V24, P1669, DOI 10.1109/TCSVT.2014.2302521
   Cong Y, 2013, IEEE T INF FOREN SEC, V8, P1590, DOI 10.1109/TIFS.2013.2272243
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Dogra D, 2015, 10 INT C COMP VIS TH, P31
   Dogra D, 2015, P INT C COMP VIS THE, P17
   Elhamod M, 2013, IEEE T INTELL TRANSP, V14, P688, DOI 10.1109/TITS.2012.2228640
   Flum J, 2004, SIAM J COMPUT, V33, P892, DOI 10.1137/S0097539703427203
   Gowsikhaa D, 2014, ARTIF INTELL REV, V42, P747, DOI 10.1007/s10462-012-9341-3
   Hamid R, 2005, PROC CVPR IEEE, P1031
   Han M, 2004, IEEE IMAGE PROC, P3065
   Hospedales TM, 2011, IEEE T PATTERN ANAL, V33, P2451, DOI 10.1109/TPAMI.2011.81
   Jiang ZD, 2010, CHIN CONT DECIS CONF, P517, DOI 10.1109/CCDC.2010.5499000
   Khan Z, 2004, PROC CVPR IEEE, P980
   Khan ZH, 2010, IEEE T INF FOREN SEC, V5, P591, DOI 10.1109/TIFS.2010.2050312
   Kiryati N, 2008, INT C PATT RECOG, P3015
   Ko T, 2008, IEEE APP IMG PAT, P84
   Krishna MV, 2014, IEEE WINT CONF APPL, P640, DOI 10.1109/WACV.2014.6836042
   Kuettel D, 2010, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2010.5539869
   Laxhammar R., 2014, CONFORMAL PREDICTION, P71, DOI [10.1016/B978-0-12-398537-8.00004-3, DOI 10.1016/B978-0-12-398537-8.00004-3]
   Laxhammar R, 2014, IEEE T PATTERN ANAL, V36, P1158, DOI 10.1109/TPAMI.2013.172
   Leyva R, 2014, IEEE INT WORKS INFOR, P209, DOI 10.1109/WIFS.2014.7084329
   Li NN, 2015, NEUROCOMPUTING, V155, P309, DOI 10.1016/j.neucom.2014.12.064
   Li X, 2007, P 4 EUR C VIS MED PR, P12
   Lin K, 2015, IEEE T INF FOREN SEC, V10, P1359, DOI 10.1109/TIFS.2015.2408263
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   MAHADEVAN V, 2010, PROC CVPR IEEE, P1975, DOI DOI 10.1109/CVPR.2010.5539872
   Mahesh Venkata Krishna, 2014, [Pattern Recognition and Image Analysis (Advances in Mathematical Theory and Applications), Pattern Recognition and Image Analysis. (Advances in Mathematical Theory and Applications)], V24, P243, DOI 10.1134/S1054661814020114
   Morris BT, 2008, IEEE T CIRC SYST VID, V18, P1114, DOI 10.1109/TCSVT.2008.927109
   Nater F, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.21
   Nayak NM, 2013, IEEE T INF FOREN SEC, V8, P1610, DOI 10.1109/TIFS.2013.2277669
   Niu W, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P719, DOI 10.1109/ICME.2004.1394293
   Oron S, 2012, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2012.6247895
   Ouivirach K, 2013, PATTERN RECOGN, V46, P671, DOI 10.1016/j.patcog.2012.10.008
   Pan J, 2008, IEEE T CIRC SYST VID, V18, P223, DOI 10.1109/TCSVT.2007.913975
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   Roshtkhari MJ, 2013, PROC CVPR IEEE, P2611, DOI 10.1109/CVPR.2013.337
   Saleh SAM, 2015, ENG APPL ARTIF INTEL, V41, P103, DOI 10.1016/j.engappai.2015.01.007
   Saligrama V, 2012, PROC CVPR IEEE, P2112, DOI 10.1109/CVPR.2012.6247917
   Särkkä S, 2007, INFORM FUSION, V8, P2, DOI 10.1016/j.inffus.2005.09.009
   Sebanja I., 2010, 2010 IEEE International Conference on Technologies for Homeland Security (HST 2010), P132, DOI 10.1109/THS.2010.5655078
   Silveira G, 2007, PROC CVPR IEEE, P186
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Takai M., 2010, 2010 Second World Congress on Nature and Biologically Inspired Computing (NaBIC 2011), P298, DOI 10.1109/NABIC.2010.5716350
   Tzanidou G, 2013, IEEE T INF FOREN SEC, V8, P1620, DOI 10.1109/TIFS.2013.2279797
   Veeraraghavan H, 2006, COMPUT VIS IMAGE UND, V103, P121, DOI 10.1016/j.cviu.2006.04.003
   Wang XG, 2008, PROC CVPR IEEE, P2932
   Wenger B., 2010, P IEEE AUTOTESTCON I, P1
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang J, 2008, 2008 INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, VOLS 1-4, P81, DOI 10.1109/ICINFA.2008.4607972
   Zhou BL, 2012, PROC CVPR IEEE, P2871, DOI 10.1109/CVPR.2012.6248013
NR 69
TC 4
Z9 5
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16223
EP 16248
DI 10.1007/s11042-017-5196-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300011
DA 2024-07-18
ER

PT J
AU Liu, X
   Wang, S
   Sang, JZ
   Zhang, WZ
AF Liu, Xin
   Wang, Shen
   Sang, Jianzhi
   Zhang, Weizhe
TI A novel lossless recovery algorithm for basic matrix-based VSS
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual secret sharing; Basic matrix; Addition; Lossless recovery
ID VISUAL CRYPTOGRAPHY; QUALITY
AB Lossless recovery is very important for visual secret share (VSS). In this paper, a novel lossless recovery algorithm for the basic matrix-based VSS is proposed. The algorithm has the merit of reconstructing secret image losslessly by using simple addition operation. The algorithm proves that the condition of lossless recovery of the secret image is xi 0 boolean AND xi 1 = empty set by analyzing the Hamming weight of adding all columns of basic matrixes. Simulations are conducted to evaluate the efficiency of the proposed scheme.
C1 [Liu, Xin; Wang, Shen; Sang, Jianzhi; Zhang, Weizhe] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Heilongjiang, Peoples R China.
   [Liu, Xin] Harbin Univ Sci & Technol, Modern Educ Technol Ctr, Harbin 150080, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology; Harbin University of Science &
   Technology
RP Liu, X; Wang, S (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Heilongjiang, Peoples R China.; Liu, X (corresponding author), Harbin Univ Sci & Technol, Modern Educ Technol Ctr, Harbin 150080, Heilongjiang, Peoples R China.
EM liuxin@hrbust.edu.cn; shen.wang@hit.edu.cn
FU National Natural Science Foundation of China [61471141, 61361166006,
   61301099, 61472108, 61672186, 61501148]; National Key Research and
   Development Program of China [2016YFB0800801]; Key Technology Program of
   Shenzhen, China [JSGG20160427185010977]; Basic Research Project of
   Shenzhen, China [JCYJ2015051351706561]
FX The authors would like to thank the anonymous reviewers for their
   valuable discussions and comments. This work is supported by the
   National Natural Science Foundation of China (Grant Number: 61471141,
   61361166006, 61301099, 61472108, 61672186, 61501148,), the National Key
   Research and Development Program of China (Grant Number:
   2016YFB0800801), Key Technology Program of Shenzhen, China (Grant
   Number: JSGG20160427185010977) and Basic Research Project of Shenzhen,
   China (Grant Number: JCYJ2015051351706561).
CR [Anonymous], 2017, J REAL-TIME IMAGE PR
   [Anonymous], DIGIT FORENS WATERMA
   [Anonymous], T DATA HID MULTIMED
   Cattaneo G, 2016, INFORM SCIENCES, V330, P342, DOI 10.1016/j.ins.2015.09.054
   Chao HC, 2017, SIGNAL PROCESS-IMAGE, V57, P60, DOI 10.1016/j.image.2017.05.005
   Chao HC, 2017, DISPLAYS, V49, P6, DOI 10.1016/j.displa.2017.05.004
   Chao HC, 2017, DIGIT SIGNAL PROCESS, V68, P69, DOI 10.1016/j.dsp.2017.05.009
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Cu DH, 2015, SIGNAL PROCESS, V108, P604, DOI 10.1016/j.sigpro.2014.10.011
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Faraoun KM, 2017, MULTIMED TOOLS APPL, V76, P6247, DOI 10.1007/s11042-016-3317-2
   Hou YC, 2011, IEEE T CIRC SYST VID, V21, P1760, DOI 10.1109/TCSVT.2011.2106291
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Li P, 2016, J REALTIME IMAGE PRO, P1
   Liu F, 2012, J VIS COMMUN IMAGE R, V23, P331, DOI 10.1016/j.jvcir.2011.11.003
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Wang XL, 2016, J ANAL METHODS CHEM, V2016, DOI 10.1155/2016/1435106
   Wu XT, 2013, SIGNAL PROCESS, V93, P977, DOI 10.1016/j.sigpro.2012.11.014
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P48, DOI 10.1016/j.jvcir.2012.11.001
   Xuehu Yan, 2018, Journal of Real-Time Image Processing, V14, P61, DOI 10.1007/s11554-015-0540-4
   Yan XH, 2015, MULTIMED TOOLS APPL, V74, P3231, DOI 10.1007/s11042-013-1784-2
   Yan XH, 2014, SIGNAL PROCESS, V105, P389, DOI 10.1016/j.sigpro.2014.06.011
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Yonggang Lu, 2017, Multimedia Tools and Applications, V76, P10701, DOI 10.1007/s11042-015-3188-y
NR 27
TC 7
Z9 8
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16461
EP 16476
DI 10.1007/s11042-017-5215-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300022
DA 2024-07-18
ER

PT J
AU Lopez-Fuentes, L
   van de Weijer, J
   González-Hidalgo, M
   Skinnemoen, H
   Bagdanov, AD
AF Lopez-Fuentes, Laura
   van de Weijer, Joost
   Gonzalez-Hidalgo, Manuel
   Skinnemoen, Harald
   Bagdanov, Andrew D.
TI Review on computer vision techniques in emergency situations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Emergency management; Computer vision; Decision makers; Situational
   awareness; Critical situation
ID FALL DETECTION SYSTEM; REAL-TIME; SMOKE DETECTION; FIRE-DETECTION; VIDEO
   FIRE; PEDESTRIAN DETECTION; INCIDENT DETECTION; TRACKING; FLAME;
   SURVEILLANCE
AB In emergency situations, actions that save lives and limit the impact of hazards are crucial. In order to act, situational awareness is needed to decide what to do. Geolocalized photos and video of the situations as they evolve can be crucial in better understanding them and making decisions faster. Cameras are almost everywhere these days, either in terms of smartphones, installed CCTV cameras, UAVs or others. However, this poses challenges in big data and information overflow. Moreover, most of the time there are no disasters at any given location, so humans aiming to detect sudden situations may not be as alert as needed at any point in time. Consequently, computer vision tools can be an excellent decision support. The number of emergencies where computer vision tools has been considered or used is very wide, and there is a great overlap across related emergency research. Researchers tend to focus on state-of-the-art systems that cover the same emergency as they are studying, obviating important research in other fields. In order to unveil this overlap, the survey is divided along four main axes: the types of emergencies that have been studied in computer vision, the objective that the algorithms can address, the type of hardware needed and the algorithms used. Therefore, this review provides a broad overview of the progress of computer vision covering all sorts of emergencies.
C1 [Lopez-Fuentes, Laura; Skinnemoen, Harald] AnsuR Technol AS, TM RCS Working Grp, Fornebu, Norway.
   [Lopez-Fuentes, Laura; Gonzalez-Hidalgo, Manuel] Univ Balearic Isl, Dept Math & Comp Sci, Crta Valldemossa Km 7-5, E-07122 Palma De Mallorca, Spain.
   [Lopez-Fuentes, Laura; van de Weijer, Joost] Univ Autonoma Barcelona, Comp Vis Ctr, E-08193 Barcelona, Spain.
   [Bagdanov, Andrew D.] Univ Florence, DINFO, Via Santa Marta 3, I-50139 Florence, Italy.
   [Lopez-Fuentes, Laura; Gonzalez-Hidalgo, Manuel] Balear Islands Hlth Res Inst IdISBa, Palma De Mallorca 07010, Spain.
C3 Universitat de les Illes Balears; Centre de Visio per Computador (CVC);
   Autonomous University of Barcelona; University of Florence; Institut
   Investigacio Sanitaria Illes Balears (IdISBa)
RP Lopez-Fuentes, L (corresponding author), AnsuR Technol AS, TM RCS Working Grp, Fornebu, Norway.; Lopez-Fuentes, L (corresponding author), Univ Balearic Isl, Dept Math & Comp Sci, Crta Valldemossa Km 7-5, E-07122 Palma De Mallorca, Spain.; Lopez-Fuentes, L (corresponding author), Univ Autonoma Barcelona, Comp Vis Ctr, E-08193 Barcelona, Spain.; Lopez-Fuentes, L (corresponding author), Balear Islands Hlth Res Inst IdISBa, Palma De Mallorca 07010, Spain.
EM l.lopez@uib.es; joost@cvc.uab.es; manuel.gonzalez@uib.es;
   harald@ansur.no; andrew.bagdanov@unifi.it
RI van de Weijer, Joost/A-1643-2009; Bagdanov, Andrew/K-3932-2014;
   Gonzalez-Hidalgo, Manuel/F-3152-2016
OI van de Weijer, Joost/0000-0002-9656-9706; Bagdanov,
   Andrew/0000-0001-6408-7043; Lopez-Fuentes, Laura/0000-0001-7850-4776;
   Gonzalez-Hidalgo, Manuel/0000-0003-4984-387X
FU AEI/FEDER, UE [TIN2016-75404-P]; European Commission H2020 I-REACT
   project [700256]; Norwegian Research Council [3114];  [TIN2014-52072-P];
    [TIN2013-42795-P]
FX This work was partially supported by the Spanish Grants TIN2016-75404-P
   AEI/FEDER, UE, TIN2014-52072-P, TIN2013-42795-P and the European
   Commission H2020 I-REACT project no. 700256. Laura Lopez-Fuentes
   benefits from the NAERINGSPHD fellowship of the Norwegian Research
   Council under the collaboration agreement Ref. 3114 with the UIB. We
   thank the NVIDIA Corporation for support in the form of GPU hardware.
CR Alhimale L, 2014, APPL SOFT COMPUT, V18, P59, DOI 10.1016/j.asoc.2014.01.024
   Anderson D, 2009, COMPUT VIS IMAGE UND, V113, P80, DOI 10.1016/j.cviu.2008.07.006
   Andrade E. L., 2006, Institution of Engineering and Technology Conference on Crime and Security, P528
   Andrade EL, 2006, INT C PATT RECOG, P460
   Andrade EL, 2006, INT C PATT RECOG, P175
   Andriluka M, 2010, IEEE INT C INT ROBOT, P1740, DOI 10.1109/IROS.2010.5649223
   [Anonymous], P CROAT COMP VIS WOR
   [Anonymous], GLOB STAT REP ROAD S
   [Anonymous], 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-41561-1_12
   [Anonymous], SENT 2 MISS DET
   [Anonymous], ARXIV170310729
   [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], PED DET
   [Anonymous], 2010, THESIS
   [Anonymous], PUBLIC HLTH GUIDE EM
   [Anonymous], 2001, Pyramidal implementation of the affine lucas kanade feature tracker description of the algorithm5.1-10
   [Anonymous], 2015, TRAFF SAF FACTS
   [Anonymous], VEH PED BIC PRES SEN
   [Anonymous], 2016, P 2016 INT FOR MAN E
   [Anonymous], 2008, IEEE AEROSP C PROC, DOI [DOI 10.1109/AERO.2008.4526558, DOI 10.1109/AERO.2008.4526559]
   [Anonymous], 2015, HDB UNMANNED AERIAL, DOI DOI 10.1007/978-90-481-9707-1122
   [Anonymous], 2008, P 19 INT C PATT REC
   [Anonymous], 2012, Color in Computer Vision: Fundamentals and Applications
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 245 MILL VID SURV CA
   [Anonymous], NEW FALL DET ARR THI
   [Anonymous], 2009, P INT C INT C INT HU, DOI DOI 10.1007/978-81-8489-203-1
   [Anonymous], 2007, P IFPA FIR SUPPR DET
   [Anonymous], 2016, ARXIV160900866
   [Anonymous], 2012, IEEE T GEOSCI REMOTE, DOI DOI 10.1109/TGRS.2011.2178030
   Barmpoutis P, 2014, EUR SIGNAL PR CONF, P1078
   Barth Alexander, 2010, 2010 13th International IEEE Conference on Intelligent Transportation Systems (ITSC 2010), P861, DOI 10.1109/ITSC.2010.5624969
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   Bejiga MB, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9020100
   Below R., 2009, DISASTER CATEGORY CL
   Benenson R, 2015, LECT NOTES COMPUT SC, V8926, P613, DOI 10.1007/978-3-319-16181-5_47
   Bertozzi M, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P24
   Borges PVK, 2010, IEEE T CIRC SYST VID, V20, P721, DOI 10.1109/TCSVT.2010.2045813
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Buch N, 2011, IEEE T INTELL TRANSP, V12, P920, DOI 10.1109/TITS.2011.2119372
   Calderara S, 2008, LECT NOTES COMPUT SC, V5008, P119
   Castillo C, 2005, 2005 IEEE INTERNATIONAL WORKSHOP ON SAFETY, SECURITY AND RESCUE ROBOTS, P201
   Celik T, 2010, ETRI J, V32, P881, DOI 10.4218/etrij.10.0109.0695
   Çelik T, 2009, FIRE SAFETY J, V44, P147, DOI 10.1016/j.firesaf.2008.05.005
   Çetin AE, 2013, DIGIT SIGNAL PROCESS, V23, P1827, DOI 10.1016/j.dsp.2013.07.003
   Chen J, 2005, P ANN INT IEEE EMBS, P3551, DOI 10.1109/IEMBS.2005.1617246
   Chen J, 2010, BUILD ENVIRON, V45, P1113, DOI 10.1016/j.buildenv.2009.10.017
   Chen TH, 2004, IEEE IMAGE PROC, P1707
   Choi IH, 2014, INT CONF BIG DATA, P241, DOI 10.1109/BIGCOMP.2014.6741444
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Chua JL, 2015, SIGNAL IMAGE VIDEO P, V9, P623, DOI 10.1007/s11760-013-0493-7
   Collins R., 2000, CMURITR0012
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danescu R, 2009, IEEE T INTELL TRANSP, V10, P272, DOI 10.1109/TITS.2009.2018328
   Diem Lukas, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P16, DOI 10.1007/978-3-319-27671-7_2
   Dios JRMD, 2008, IMAGE VISION COMPUT, V26, P550, DOI 10.1016/j.imavis.2007.07.002
   Doerr KU, 2005, P SOC PHOTO-OPT INS, V5758, P321, DOI 10.1117/12.597679
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Eng HL, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P532
   Forczmanski P, 2016, LECT NOTES COMPUT SC, V9972, P462, DOI 10.1007/978-3-319-46418-3_41
   Foroughi Homa, 2008, 2008 11th International Conference on Computer and Information Technology (ICCIT), P219, DOI 10.1109/ICCITECHN.2008.4803020
   Frizzi S, 2016, IEEE IND ELEC, P877, DOI 10.1109/IECON.2016.7793196
   Fu Qiang., 2012, SDM, P24, DOI [10.1137/1.9781611972825.3, DOI 10.1137/1.9781611972825.3]
   Gade R, 2014, MACH VISION APPL, V25, P245, DOI 10.1007/s00138-013-0570-5
   Garate Carolina., 2009, Performance Evaluation of Tracking and Surveillance (PETS- Winter), 2009 Twelfth IEEE International Workshop on, P1
   Gautama T, 2002, IEEE T NEURAL NETWOR, V13, P1127, DOI 10.1109/TNN.2002.1031944
   Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7
   Gerónimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122
   Gómez-Rodríguez F, 2003, P SOC PHOTO-OPT INS, V5094, P404, DOI 10.1117/12.487050
   Gonzalez-Gonzalez R, 2010, MIDWEST SYMP CIRCUIT, P383, DOI 10.1109/MWSCAS.2010.5548865
   Grabisch M., 2010, Fuzzy Measures and Integrals: Theory and Applications
   Gubbi J, 2009, FIRE SAFETY J, V44, P1110, DOI 10.1016/j.firesaf.2009.08.003
   Günay O, 2010, FIRE TECHNOL, V46, P551, DOI 10.1007/s10694-009-0106-8
   Guo CZ, 2012, IEEE T INTELL TRANSP, V13, P1338, DOI 10.1109/TITS.2012.2187896
   Haar A, 1910, MATH ANN, V69, P331, DOI 10.1007/BF01456326
   Hachisuka S, 2011, LECT NOTES ARTIF INT, V6781, P135, DOI 10.1007/978-3-642-21741-8_16
   Harris C., 1988, ALVEY VISION C, P147151
   Hassan-Esfahani L, 2015, REMOTE SENS-BASEL, V7, P2627, DOI 10.3390/rs70302627
   Hayashi T, 2009, IEEE INT VEH SYM, P869, DOI 10.1109/IVS.2009.5164394
   Hazelhoff L, 2008, LECT NOTES COMPUT SC, V5259, P298, DOI 10.1007/978-3-540-88458-3_27
   Houben S, 2013, IEEE INT C INTELL TR, P7, DOI 10.1109/ITSC.2013.6728595
   Hsi-Lin Chen, 2010, 2010 International Conference on Machine Learning and Cybernetics (ICMLC 2010), P2459, DOI 10.1109/ICMLC.2010.5580797
   Hu SY, 2009, EXPERT SYST APPL, V36, P7651, DOI 10.1016/j.eswa.2008.09.030
   Hu WM, 2006, IEEE T PATTERN ANAL, V28, P1450, DOI 10.1109/TPAMI.2006.176
   Huang H, 2014, IEEE J EM SEL TOP C, V4, P142, DOI 10.1109/JETCAS.2014.2298279
   Hutchinson TC, 2004, IEEE T INSTRUM MEAS, V53, P31, DOI 10.1109/TIM.2003.821481
   Ibraheem N.A., 2012, ARPN J. Sci. Technol., V2, P265
   Ihaddadene N, 2008, INT C PATT RECOG, P217
   Jiang F, 2011, COMPUT VIS IMAGE UND, V115, P323, DOI 10.1016/j.cviu.2010.10.008
   Jiang M., 2013, VISUAL COMMUN-US, P1
   Juang CF, 1998, IEEE T FUZZY SYST, V6, P12, DOI 10.1109/91.660805
   Juang CF, 2007, IEEE T SYST MAN CY A, V37, P984, DOI 10.1109/TSMCA.2007.897609
   Kam AH, 2002, LECT NOTES COMPUT SC, V2353, P297
   Kamijo S., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P108, DOI 10.1109/6979.880968
   Kang B, 2016, ICT EXPRESS, V2, P67, DOI 10.1016/j.icte.2016.05.001
   Ke SR, 2013, COMPUTERS, V2, P88, DOI 10.3390/computers2020088
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Kleiner Alexander, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3025, DOI 10.1109/IROS.2007.4399006
   Ko B, 2010, FIRE SAFETY J, V45, P262, DOI 10.1016/j.firesaf.2010.04.001
   Borges PVK, 2008, IEEE IMAGE PROC, P13, DOI 10.1109/ICIP.2008.4711679
   KOGAN FN, 1995, B AM METEOROL SOC, V76, P655, DOI 10.1175/1520-0477(1995)076<0655:DOTLIT>2.0.CO;2
   Kolesov I, 2010, IEEE IMAGE PROC, P761, DOI 10.1109/ICIP.2010.5652119
   Lagerstrom R, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00054
   Lai C.L., 2007, INSTRUMENTATION MEAS
   LeCun Y., 1990, NeurIPS, P396
   Lee BG, 2011, IET COMMUN, V5, P2461, DOI 10.1049/iet-com.2010.0925
   Lei F, 2009, IEEE I C EMBED SOFTW, P341, DOI 10.1109/ICESS.2009.35
   Leira FS, 2015, 2015 IEEE AEROSPACE CONFERENCE
   Li L., 2003, MULTIMEDIA 03 P 11 A, P2, DOI DOI 10.1145/957013.957017
   Liao YT, 2012, PATTERN RECOGN, V45, P24, DOI 10.1016/j.patcog.2011.04.017
   Lin CW, 2007, IEEE IC COMP COM NET, P1172
   Lopez-Fuentes L, 2017, IEEE WINT CONF APPL, P1197, DOI 10.1109/WACV.2017.138
   Lu WM, 2004, IEEE T CIRC SYST VID, V14, P159, DOI 10.1109/TCSVT.2003.821980
   Lu YM, 2007, IEEE T IMAGE PROCESS, V16, P918, DOI 10.1109/TIP.2007.891785
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Ma JQ, 2015, 2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P411, DOI 10.1109/SSCI.2015.68
   Maalel N, 2013, 2013 9TH IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING IN SENSOR SYSTEMS (IEEE DCOSS 2013), P361, DOI 10.1109/DCOSS.2013.40
   Maksymiv O, 2016, PROCEEDINGS OF THE 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON DATA STREAM MINING & PROCESSING (DSMP), P199, DOI 10.1109/DSMP.2016.7583540
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mason DC, 2010, IEEE T GEOSCI REMOTE, V48, P882, DOI 10.1109/TGRS.2009.2029236
   Medel J. R., 2016, Anomaly detection in video using predictive convolutional long short-term memory networks
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Mirmahboub B, 2013, IEEE T BIO-MED ENG, V60, P427, DOI 10.1109/TBME.2012.2228262
   Mogelmose A, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1394, DOI 10.1109/ITSC.2014.6957882
   Muscio A, 2004, IEEE T GEOSCI REMOTE, V42, P1955, DOI 10.1109/TGRS.2004.831443
   Nagatani K, 2013, J FIELD ROBOT, V30, P44, DOI 10.1002/rob.21439
   PETAK WJ, 1985, PUBLIC ADMIN REV, V45, P3, DOI 10.2307/3134992
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Piciarelli C, 2008, IEEE T CIRC SYST VID, V18, P1544, DOI 10.1109/TCSVT.2008.2005599
   Price J., 2004, Proceedings. 33rd Applied Imagery Pattern Recognition Workshop, P257
   Radianti J, 2013, P ANN HICSS, P156, DOI 10.1109/HICSS.2013.155
   REISINGER KS, 1980, PEDIATRICS, V65, P718
   Rinsurongkawong S, 2012, 2012 9 INT C EL ENG, P1, DOI DOI 10.1109/ECTICON.2012.6254144
   Rougier C, 2007, 21ST INTERNATIONAL CONFERENCE ON ADVANCED NETWORKING AND APPLICATIONS WORKSHOPS/SYMPOSIA, VOL 2, PROCEEDINGS, P875, DOI 10.1109/ainaw.2007.181
   Rougier C, 2011, LECT NOTES COMPUT SC, V6719, P121, DOI 10.1007/978-3-642-21535-3_16
   Sakour I, 2017, ROBOTICS, V6, DOI 10.3390/robotics6020008
   Saligrama V, 2012, PROC CVPR IEEE, P2112, DOI 10.1109/CVPR.2012.6247917
   Schoeffmann K, 2015, ACM COMPUT SURV, V48, DOI 10.1145/2808796
   Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI 10.1002/0471250953.bia03as18
   Shah B., 2004, J ROBOT SOC JPN, V22, P582
   Shieh WY, 2012, MED ENG PHYS, V34, P954, DOI 10.1016/j.medengphy.2011.10.016
   Siegel R, 2002, IEEE INSTRU MEAS MAG, V5, P22, DOI 10.1109/MIM.2002.1048979
   Sixsmith A, 2004, IEEE PERVAS COMPUT, V3, P42, DOI 10.1109/MPRV.2004.1316817
   Song Y, 2013, ENVIRON MONIT ASSESS, V185, P4117, DOI 10.1007/s10661-012-2854-z
   Soni B, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2012)
   Soni B, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P2142, DOI 10.1109/ROBIO.2013.6739786
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Suard F, 2006, 2006 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P207
   Sultani Waqas, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P324, DOI 10.1109/ICPR.2010.88
   Thome N, 2008, IEEE T CIRC SYST VID, V18, P1522, DOI 10.1109/TCSVT.2008.2005606
   Tian H, 2011, P IEEE INT WORKSH MU, P1, DOI DOI 10.1109/VETECF.2011.6092963
   Tompkin J, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185564
   Toreyin B. U., 2006, 2006 IEEE 14 SIGNAL, P1
   Töreyin BU, 2006, PATTERN RECOGN LETT, V27, P49, DOI 10.1016/j.patrec.2005.06.015
   Trivedi MM, 2007, IEEE T INTELL TRANSP, V8, P108, DOI 10.1109/TITS.2006.889442
   Truong TX, 2012, ENG APPL ARTIF INTEL, V25, P1365, DOI 10.1016/j.engappai.2012.05.007
   Utasi A., 2012, Proceedings of the 1st international workshop on visual interfaces for ground truth collection in computer vision applications, page, P3
   Van Hamme D, 2010, LECT NOTES COMPUT SC, V6475, P88, DOI 10.1007/978-3-642-17691-3_9
   Veeraraghavan H, 2003, IEEE T INTELL TRANSP, V4, P78, DOI 10.1109/TITS.2003.821212
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang HC, 2013, IEEE WORK APP COMP, P513, DOI 10.1109/WACV.2013.6475062
   Wang JT, 2012, PATTERN RECOGN LETT, V33, P775, DOI 10.1016/j.patrec.2011.12.011
   Wang SD, 2014, J INTELL FUZZY SYST, V26, P267, DOI 10.3233/IFS-120735
   Wang T, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P13, DOI 10.1109/AVSS.2012.39
   Wasaki K, 2001, MFI2001: INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS, P133, DOI 10.1109/MFI.2001.1013521
   Wen-Hui Chen, 2011, 2011 International Conference on Uncertainty Reasoning and Knowledge Engineering (URKE), P44, DOI 10.1109/URKE.2011.6007835
   Wojek C, 2009, PROC CVPR IEEE, P794, DOI 10.1109/CVPRW.2009.5206638
   Xu ZG, 2007, CIS WORKSHOPS 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY WORKSHOPS, P316, DOI 10.1109/CIS.Workshops.2007.5
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
   Yang L, 2013, TECHNOL FORECAST SOC, V80, P1854, DOI 10.1016/j.techfore.2012.07.011
   Ye W, 2015, FIRE SAFETY J, V73, P91, DOI 10.1016/j.firesaf.2015.03.001
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yu CY, 2013, PROCEDIA ENGINEER, V62, P891, DOI 10.1016/j.proeng.2013.08.140
   Yu CY, 2010, FIRE TECHNOL, V46, P651, DOI 10.1007/s10694-009-0110-z
   Yuan FN, 2011, FIRE SAFETY J, V46, P132, DOI 10.1016/j.firesaf.2011.01.001
   Yun KM, 2014, INT C PATT RECOG, P3062, DOI 10.1109/ICPR.2014.528
   ZADEH LA, 1973, IEEE T SYST MAN CYB, VSMC3, P28, DOI 10.1109/TSMC.1973.5408575
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zaklouta F, 2011, IEEE INT VEH SYM, P1019, DOI 10.1109/IVS.2011.5940454
   Zhang T, 2006, LECT NOTES CONTR INF, V345, P858
   Zhou SF, 2016, SIGNAL PROCESS-IMAGE, V47, P358, DOI 10.1016/j.image.2016.06.007
NR 182
TC 32
Z9 36
U1 5
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 17069
EP 17107
DI 10.1007/s11042-017-5276-7
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300049
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Aslani, R
   Hakami, V
   Dehghan, M
AF Aslani, Rojin
   Hakami, Vesal
   Dehghan, Mehdi
TI A token-based incentive mechanism for video streaming applications in
   peer-to-peer networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Peer-to-peer network; Video streaming; Incentive mechanism; Token;
   Q-learning
ID ALGORITHM
AB Free-riding is one of the main challenges of Peer-to-Peer (P2P) streaming systems which results in reduction in video streaming quality. Therefore, providing an incentive mechanism for stimulating cooperation is one of the essential requirements to maintain video Quality of Experience (QoE) in such systems. Among the existing mechanisms, payment-based schemes are most suitable for streaming applications due to their low overhead. However, to date, no dynamic payment mechanism has been proposed which can take the stochastic dynamics of the video streaming ecosystem (e.g., the request arrival, demand submission, bandwidth availability, etc.) into account. In this paper, we propose a dynamic token-based payment mechanism in which each peer earns tokens by admitting other peers' requests and spends tokens for submitting its demands to the others. This system allows the peers to dynamically adjust their income level in adaptation to changes in the system state. We propose a Constrained Markov Decision Process (CMDP) formulation in which the goal of each peer is to obtain a request admission policy which minimizes the expected cumulative cost of consumed bandwidth, while satisfying a long-term constraint on the Mean Opinion Score (MOS) of the users as the measure of QoE. The proposed admission policy is adaptive to the request arrival process, bandwidth state and the token bucket length of each peer. To make up for the lack of design-time knowledge of the system's statistics, each individual peer is equipped with a model-free algorithm to learn its optimal admission policy over the course of real-time interaction with the system. Simulation results are presented to compare the performance of the proposed algorithm against baseline schemes such as: random, token-threshold, bandwidth-threshold and myopic algorithms.
C1 [Aslani, Rojin; Dehghan, Mehdi] Amirkabir Univ Technol, Dept Comp Engn & IT, Tehran Polytech, 424 Hafez Ave, Tehran 158754413, Iran.
   [Hakami, Vesal] Iran Univ Sci & Technol, Dept Comp Engn, Tehran 1684613114, Iran.
C3 Amirkabir University of Technology; Iran University Science & Technology
RP Aslani, R (corresponding author), Amirkabir Univ Technol, Dept Comp Engn & IT, Tehran Polytech, 424 Hafez Ave, Tehran 158754413, Iran.
EM rojinaslani@aut.ac.ir; vhakami@iust.ac.ir; dehghan@aut.ac.ir
RI Hakami, Vesal/T-1426-2018; Aslani, Rojin/AAK-1405-2020; Dehghan,
   Maziar/F-8525-2013
OI Hakami, Vesal/0000-0002-0798-3981; Aslani, Rojin/0000-0003-2223-0790;
   Dehghan, Maziar/0000-0003-2106-6300; DehghanTakhtFooladi,
   Mehdi/0000-0002-3318-7313
CR ALTMAN E, 1999, STOCH MODEL SER, P1, DOI 10.1201/9781315140223
   [Anonymous], COH CONTR FOURW MIX
   [Anonymous], 7266 RFC
   [Anonymous], LEADER FOLLOWER MULT
   [Anonymous], NEURAL COMPUT APPL
   [Anonymous], MPEG FRAM LOSS RAT I, DOI DOI 10.1109/SAC0NET.2013.6654554
   [Anonymous], 3640 RFC IETF
   [Anonymous], INT J COMMUNICATION
   [Anonymous], P IFIP INT C NETW PA
   [Anonymous], 1 WORKSH EC NETW SYS
   [Anonymous], P IEEE 1 INT C PEER
   [Anonymous], P 24 ANN JOINT C IEE
   [Anonymous], P WORKSH IEEE INT C
   [Anonymous], P ACM SIGCOMM WORKSH
   [Anonymous], WORKSH EC PEER TO PE
   [Anonymous], P IEEE INT WORKSH PE
   [Anonymous], P 11 IEEE INT C NETW
   [Anonymous], 1998, REINFORCEMENT LEARNI
   [Anonymous], ARXIV11085871
   [Anonymous], MEAN OP SCOR MOS INT
   [Anonymous], PATT REC ICPR 23 INT
   [Anonymous], DECENTRALIZED REINFO
   [Anonymous], LEARNING COMPUTATION
   Bertsekas D. P., 1999, Nonlinear Program, V2nd
   Bertsekas DP, 1995, PROCEEDINGS OF THE 34TH IEEE CONFERENCE ON DECISION AND CONTROL, VOLS 1-4, P560, DOI 10.1109/CDC.1995.478953
   Bertsekas DP., 1996, NEURO DYNAMIC PROGRA
   Borkar Vivek S, 2008, Stochastic Approximation: A Dynamical Systems Viewpoint
   Borkar VS, 2005, SYST CONTROL LETT, V54, P207, DOI 10.1016/j.sysconle.2004.08.007
   Borkar VS, 1997, SYST CONTROL LETT, V29, P291, DOI 10.1016/S0167-6911(97)90015-3
   Buttyan L., 2001, Nuglets: a virtual currency to stimulate cooperation in self-organized mobile ad hoc networks
   Castro M, 2003, LECT NOTES COMPUT SC, V2735, P292
   Ciuffoletti A, 2010, FUTURE GENER COMP SY, V26, P1026, DOI 10.1016/j.future.2009.12.003
   Djonin DV, 2007, IEEE T SIGNAL PROCES, V55, P2170, DOI 10.1109/TSP.2007.893228
   Dolgov D. A., 2003, IJCAI, P1107
   Franklin M.K., 1997, Proceedings of the 4th ACM Conference on Computer and Communications Security, P1
   Habib A, 2006, IEEE T MULTIMEDIA, V8, P610, DOI 10.1109/TMM.2006.870724
   Kang X, 2015, IEEE T MOBILE COMPUT, V14, P1018, DOI 10.1109/TMC.2014.2343628
   Karakaya M, 2009, IEEE INTERNET COMPUT, V13, P92, DOI 10.1109/MIC.2009.33
   Landa R, 2008, IEEE INT CONF PEER, P12, DOI 10.1109/P2P.2008.32
   Li B, 2007, IEEE COMMUN MAG, V45, P94, DOI 10.1109/MCOM.2007.374425
   Liao WC, 2006, LECT NOTES COMPUT SC, V3976, P592
   Lin WS, 2008, INT CONF ACOUST SPEE, P2141, DOI 10.1109/ICASSP.2008.4518066
   Lin WS, 2009, IEEE T MULTIMEDIA, V11, P396, DOI 10.1109/TMM.2009.2012915
   Liu Y, 2008, PEER PEER NETW APPL, V1, P18, DOI 10.1007/s12083-007-0006-y
   Maani E, 2012, SIGNAL PROCESS-IMAGE, V27, P545, DOI 10.1016/j.image.2012.02.015
   Macone D, 2013, AD HOC NETW, V11, P861, DOI 10.1016/j.adhoc.2012.09.008
   Magharei N, 2009, IEEE ACM T NETWORK, V17, P1052, DOI 10.1109/TNET.2008.2007434
   Mastronarde N, 2016, IEEE T MOBILE COMPUT, V15, P1569, DOI 10.1109/TMC.2015.2465379
   Mitchell T. M., 1997, MACHINE LEARNING
   Montazeri A., 2011, 2011 International Symposium on Computer Networks and Distributed Systems (CNDS), P181, DOI 10.1109/CNDS.2011.5764569
   Montazeri A, 2012, PEER PEER NETW APPL, V5, P257, DOI 10.1007/s12083-011-0121-7
   Mostafavi S, 2016, MULTIMED TOOLS APPL, V75, P8545, DOI 10.1007/s11042-015-2771-6
   Nisan N, 2007, ALGORITHMIC GAME THEORY, P1, DOI 10.1017/CBO9780511800481
   Qiao L, 1998, COMPUT GRAPH, V22, P437, DOI 10.1016/S0097-8493(98)00033-8
   Salodkar N, 2008, IEEE J SEL AREA COMM, V26, P732, DOI 10.1109/JSAC.2008.080514
   Singh S, 2000, MACH LEARN, V38, P287, DOI 10.1023/A:1007678930559
   Tan G, 2008, IEEE T PARALL DISTR, V19, P940, DOI 10.1109/TPDS.2007.70778
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Xu J, 2013, IEEE T COMMUN, V61, P2924, DOI 10.1109/TCOMM.2013.061013.120777
NR 59
TC 11
Z9 12
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 14625
EP 14653
DI 10.1007/s11042-017-5051-9
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200007
DA 2024-07-18
ER

PT J
AU Han, F
   Liao, XF
   Yang, B
   Zhang, YS
AF Han, Fang
   Liao, Xiaofeng
   Yang, Bo
   Zhang, Yushu
TI A hybrid scheme for self-adaptive double color-image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Self-adaptive; Compressive sensing; Fractional random transform; Image
   encryption; Compound chaotic systems
ID FRACTIONAL FOURIER-TRANSFORM; CHAOS; ALGORITHM; RECOVERY
AB Most of existing optical color image encryption schemes have born security risks due to the adoption of linear transform, and data redundancy for the generation of complex image. To settle these problems effectively, a hybrid scheme for self-adaptive double color-image encryption is proposed in this paper. In this scheme, each RGB color component of two secret color images is first compressed and encrypted by 2-D compressive sensing (CS) in which measurement matrices are generated by 1-D compound chaotic systems and further are optimized by steepest descent algorithm to improve image reconstruction effect. Then, the two measured images are regarded as the real part and imaginary part to constitute a complex image, respectively. In the end, the complex image is reencrypted by self-adaptive random phase encoding and discrete fractional random transform (DFrRT) to obtain the final encrypted data. In the process of DFrRT and random phase encoding, the correlations between R, G, B components are adequately utilized. The production of key streams not only depends on the initial values of chaotic systems but also on plaintexts, and the three color components affect each other to enhance the ability against the known plaintext attack. The projection neural network algorithm is adopted to obtain the decryption images. Simulation results also verify the validity and security of the proposed method.
C1 [Han, Fang; Liao, Xiaofeng; Yang, Bo; Zhang, Yushu] Southwest Univ, Chongqing Key Lab Nonlinear Circuits & Intelligen, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
C3 Southwest University - China
RP Liao, XF (corresponding author), Southwest Univ, Chongqing Key Lab Nonlinear Circuits & Intelligen, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
EM xfliao@swu.edu.cn
RI Liao, Xiaofeng/HPD-6655-2023
FU National Key Research and Development Program of China [2016
   YFB0800601]; National Nature Science Foundation of China [61472331];
   Talents of Science and Technology promote plan, Chongqing Science &
   Technology Commission
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2016 YFB0800601, in part by the
   National Nature Science Foundation of China under Grant 61472331, in
   part by the Talents of Science and Technology promote plan, Chongqing
   Science & Technology Commission.
CR Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Chen F, 2014, THEOR COMPUT SCI, V552, P13, DOI 10.1016/j.tcs.2014.08.002
   Chen LF, 2006, OPT EXPRESS, V14, P8552, DOI 10.1364/OE.14.008552
   Chen W, 2009, OPT COMMUN, V282, P3680, DOI 10.1016/j.optcom.2009.06.014
   Deepan B, 2014, APPL OPTICS, V53, P4539, DOI 10.1364/AO.53.004539
   Huang R, 2014, MULTIMED TOOLS APPL, V72, P71, DOI 10.1007/s11042-012-1337-0
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Joshi M, 2007, OPT COMMUN, V279, P35, DOI 10.1016/j.optcom.2007.07.012
   Li CJ, 2016, IEEE T IND INFORM, V12, P1775, DOI 10.1109/TII.2015.2479558
   Li CJ, 2016, IEEE T NEUR NET LEAR, V27, P308, DOI 10.1109/TNNLS.2015.2496658
   Li CJ, 2014, NONLINEAR DYNAM, V78, P209, DOI 10.1007/s11071-014-1433-y
   Li CJ, 2011, INT J COMPUT MATH, V88, P3150, DOI 10.1080/00207160.2011.594884
   Li HJ, 2011, OPT LASER ENG, V49, P753, DOI 10.1016/j.optlaseng.2011.03.017
   Liang Y, 2015, MULTIMED TOOLS APPL, P1
   Lin QZ, 2013, J SYST SOFTWARE, V86, P1384, DOI 10.1016/j.jss.2013.01.012
   Liu H, 2015, OPTIK, V126, P2663, DOI 10.1016/j.ijleo.2015.06.079
   Liu QS, 2016, IEEE T NEUR NET LEAR, V27, P698, DOI 10.1109/TNNLS.2015.2481006
   Liu XB, 2014, J MOD OPTIC, V61, P1570, DOI 10.1080/09500340.2014.946565
   Liu ZJ, 2007, OPT COMMUN, V275, P324, DOI 10.1016/j.optcom.2007.03.039
   Liu ZJ, 2013, OPT LASER ENG, V51, P8, DOI 10.1016/j.optlaseng.2012.08.004
   Lui OY, 2012, APPL SOFT COMPUT, V12, P125, DOI 10.1016/j.asoc.2011.09.003
   Nishchal NK, 2004, OPT COMMUN, V235, P253, DOI 10.1016/j.optcom.2004.02.052
   Norouzi B, 2015, MULTIMED TOOLS APPL, V74, P781, DOI 10.1007/s11042-013-1699-y
   Rawat N, 2014, OPTIK, V125, P5414, DOI 10.1016/j.ijleo.2014.06.022
   Sato D, 2015, P IEICE, V115, P39
   Sui LS, 2014, OPT LASER ENG, V56, P1, DOI 10.1016/j.optlaseng.2013.12.001
   Tao R, 2008, OPT LETT, V33, P581, DOI 10.1364/OL.33.000581
   Wen J, 2016, IEEE T APPL SUPERCON
   Wen JM, 2015, APPL COMPUT HARMON A, V38, P161, DOI 10.1016/j.acha.2014.06.003
   Wen JM, 2013, ELECTRON LETT, V49, DOI 10.1049/el.2013.2222
   Zhang LH, 2005, CHAOS SOLITON FRACT, V24, P759, DOI 10.1016/j.chaos.2004.09.035
   Zhang S, 2016, MULTIMED TOOLS APPL, V75, P17157, DOI 10.1007/s11042-015-2982-x
   Zhang YS, 2016, IEEE ACCESS, V4, P2507, DOI 10.1109/ACCESS.2016.2569421
   Zhang YS, 2016, NEUROCOMPUTING, V205, P472, DOI 10.1016/j.neucom.2016.04.053
   Zhang YS, 2015, ELECTRON LETT, V51, P1572, DOI 10.1049/el.2015.0927
   Zhang YS, 2013, OPT LASER ENG, V51, P472, DOI 10.1016/j.optlaseng.2012.11.001
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 38
TC 12
Z9 12
U1 0
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 14285
EP 14304
DI 10.1007/s11042-017-5029-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900052
DA 2024-07-18
ER

PT J
AU Kumar, V
   Kumar, D
AF Kumar, Vijay
   Kumar, Dinesh
TI A modified DWT-based image steganography technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Discrete Wavelet Transform; Transform Domain
ID ALGORITHM
AB The main challenges of image steganography are imperceptibility of the cover image and no recoverability of the secret data. To deal with these challenges, a modified digital image steganography technique based on Discrete Wavelet Transform (DWT) is proposed. In proposed approach, two new concepts are being proposed to minimize the distortion in the cover image. The first one i.e. secret key computation concept is proposed to make it more robust and resistive towards steganalysis. The second one, known as blocking concept, is introduced to ensure least variation in the cover image. The proposed approach is tested over ten different cover images and two secret images. Its performance is compared with the six well-known steganography techniques. The experimental results reveal that the proposed approach performs better than the existing techniques in terms of imperceptibility, security and quality measures. The six image processing attacks are also applied on the stego-image to test the robustness of the proposed approach. The effects of compression, rotation, and application of different wavelets have also been investigated on the proposed approach. The results demonstrate the robustness of the proposed approach under different image processing attacks. Both stego-image and extracted secret images possess better visual quality.
C1 [Kumar, Vijay] Thapar Univ, Dept Comp Sci & Engn, Patiala, Punjab, India.
   [Kumar, Dinesh] Guru Jambheshwar Univ Sci & Technol, Dept Comp Sci & Engn, Hisar, Haryana, India.
C3 Thapar Institute of Engineering & Technology; Guru Jambheshwar
   University of Science & Technology
RP Kumar, V (corresponding author), Thapar Univ, Dept Comp Sci & Engn, Patiala, Punjab, India.
EM vijaykumarchahar@gmail.com; dinesh_chutani@yahoo.com
RI Kumar, Dinesh/K-9512-2017; KUMAR, DINESH/JTT-7703-2023; Chahar, Vijay
   Kumar/A-2782-2015
OI Kumar, Dinesh/0000-0003-3348-477X; Chahar, Vijay
   Kumar/0000-0002-3460-6989
CR Abdelwahab AA, 2008, P IEEE SWARM INT S, P1
   Al-Ataby A, 2010, INT ARAB J INF TECHN, V7, P358
   al-Shatanawi O.M., 2015, INT J NETWORK SECURI, V7, P37, DOI [DOI 10.5121/IJNSA.2015.7203, 10.5121/ijnsa.2015.7203]
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2011, P 13 INF HID C PRAG
   Baby D, 2015, PROCEDIA COMPUT SCI, V46, P612, DOI 10.1016/j.procs.2015.02.105
   Cachin C, 2004, INFORM COMPUT, V192, P41, DOI 10.1016/j.ic.2004.02.003
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen P.Y., 2009, INT J APPL SCI ENG, V7, P53
   Chen P.Y., 2006, INT J APPL SCI ENG, V4, P275, DOI DOI 10.6703/IJASE/2006.4(3).275
   Denemark T, 2016, IEEE T INF FOREN SEC, V11, P1747, DOI 10.1109/TIFS.2016.2555281
   El-Emam NN, 2013, J SYST SOFTWARE, V86, P1465, DOI 10.1016/j.jss.2012.12.006
   Ghazanfari K, 2011, 2011 IEEE REGION 10 CONFERENCE TENCON 2011, P364, DOI 10.1109/TENCON.2011.6129126
   Ghebleh M, 2014, COMMUN NONLINEAR SCI, V19, P1898, DOI 10.1016/j.cnsns.2013.10.014
   Guo LJ, 2012, IEEE INT WORKS INFOR, P169, DOI 10.1109/WIFS.2012.6412644
   Hemalatha S, 2015, PROCEDIA COMPUT SCI, V47, P272, DOI 10.1016/j.procs.2015.03.207
   Hemalatha S, 2013, INT J-TORONTO, V4, P83, DOI DOI 10.5121/SIPIJ.2013.4108
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Hussain M, 2017, SIGNAL PROCESS-IMAGE, V50, P44, DOI 10.1016/j.image.2016.10.005
   Ioannidou A, 2012, EXPERT SYST APPL, V39, P11517, DOI 10.1016/j.eswa.2012.02.106
   Johnson NF, 2000, ART H COMP SCI LIBR, P43
   Kumar V, 2010, DIGITAL IMAGE STEGAN
   Kumar V, 2010, 2010 IEEE 2ND INTERNATIONAL ADVANCE COMPUTING CONFERENCE, P223, DOI 10.1109/IADCC.2010.5423005
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Masaebi Saeed, 2012, INT J ELECT COMPUT E, V2, P699
   Mythreyi S, 2007, IETE J RES, V53, P103, DOI 10.1080/03772063.2007.10876126
   Narasimmalou T, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P88, DOI 10.1109/ICACCCT.2012.6320747
   Raftari N., 2012, 2012 4th International Conference on Computational Intelligence, Communication Systems and Networks (CICSyN 2012), P295, DOI 10.1109/CICSyN.2012.62
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Shuliang S, 2016, TELECOMMUN SCI, V32, P124
   Singh S, 2015, P INT S SIGN PROC IN, P593
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Wang MS, 2009, COMPUT STAND INTER, V31, P757, DOI 10.1016/j.csi.2008.09.003
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HT, 2008, LECT NOTES COMPUT SC, V5284, P236
NR 38
TC 48
Z9 49
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13279
EP 13308
DI 10.1007/s11042-017-4947-8
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900010
DA 2024-07-18
ER

PT J
AU Singh, S
   Kumar, P
AF Singh, Shirish
   Kumar, Praveen
TI User specific context construction for personalized multimedia retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Subjective context; Semantic gap; Context construction; Personalized
   retrieval; Context based image retrieval; Hashtags; Social network;
   Social media
ID IMAGE; CLIQUES; SYSTEM
AB The onset of Web 2.0 has given the freedom of tagging to the users. The popularization of social networking and the expansion of the smartphone market in the past decade has led to an increase of data being accumulated on the social media platforms, particularly images and videos. The exponential and ever increasing data have made information retrieval cumbersome, especially for the social network users, and this has turned out to be a huge challenge in the evolution of algorithms and technologies. In this paper, we present a novel framework and techniques for retrieving user's multimedia content like images from the user's profile using the context of the image/media file. We apply the Logical Itemset mining on the image Metadata consisting of the textual data (Hashtags, Caption, Date and Time) associated with the images. Through this work, we intend to bridge the semantic gap between the images and the data representation that the user associated with them. Our framework also addresses the paraphrase problem of variation in words (synonyms) used to describe a context of a media file. To evaluate the applicability of our framework, we performed tests on large Instagram image dataset extracted from various user profiles containing monolingual metadata, which show promising results for real-time applications. Furthermore, we compare and evaluate our framework with another context-based image retrieval framework, Krumbs.
C1 [Singh, Shirish] Johns Hopkins Univ, Informat Secur Inst, Baltimore, MD 21218 USA.
   [Kumar, Praveen] Visvesvaraya Natl Inst Technol, Nagpur, Maharashtra, India.
C3 Johns Hopkins University; National Institute of Technology (NIT System);
   Visvesvaraya National Institute of Technology, Nagpur
RP Singh, S (corresponding author), Johns Hopkins Univ, Informat Secur Inst, Baltimore, MD 21218 USA.
EM shirish@jhu.edu; praveen.kverma@gmail.com
RI Singh, Shirish/Y-8492-2019; Kumar, Praveen/AAA-8584-2022
OI Kumar, Praveen/0000-0003-4820-3088
CR [Anonymous], 2010, ACM Sigkdd Explorations Newsletter
   Bach J. R., 1996, STORAGE RETRIEVAL ST, V2670, P76
   Balík M, 2002, KYBERNETIKA, V38, P91
   Bianchi-Berthouze N, 2003, IEEE MULTIMEDIA, V10, P103, DOI 10.1109/MMUL.2003.1218262
   Bomze I. M., 1999, HDB COMBINATORIAL OP, P1, DOI DOI 10.1007/978-1-4757-3023-4_1
   BRON C, 1973, COMMUN ACM, V16, P575, DOI 10.1145/362342.362367
   Calzals F, 2008, THEOR COMPUT SCI, V407, P564, DOI 10.1016/j.tcs.2008.05.010
   Cambria E, 2012, COGN COMPUT, V4, P477, DOI 10.1007/s12559-012-9145-4
   Chandrashekar V, 2013, LECT NOTES COMPUTER, V8251, DOI [10.1007/978-3-642-45062-4_52, DOI 10.1007/978-3-642-45062-4_52]
   Chen J, 2016, PATTERN RECOGNITION
   Data Growth, BUS OPP IT IMP
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   He JR, 2006, IEEE T IMAGE PROCESS, V15, P3170, DOI 10.1109/TIP.2006.877491
   Heckner M, 2009, INT AAAI C WEB SOC M
   Jabeen F, 2016, MULTIMED TOOLS APPL, V75, P573, DOI 10.1007/s11042-014-2309-3
   Jing F, 2006, P ACM MULTIMEDIA
   Kumar S, 2012, INT CONF DAT MIN WOR, P603, DOI 10.1109/ICDMW.2012.85
   Lane N, 2010, 12 INT C UB COMP UB
   Lempel R, 2001, P OF WWW
   Li XH, 2008, IEEE T SIGNAL PROCES, V56, P675, DOI 10.1109/TSP.2007.907820
   Li YS, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090709
   Majid A, 2011, 2011 INT C COMP NETW
   Marlow C., 2006, P 17 C HYP HYPERTEXT, P31, DOI [https://doi.org/10.1145/1149941.1149949, DOI 10.1145/1149941.1149949]
   Mathes A., 2004, Computer Mediated Communication
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Nakazato M, 2002, LECT NOTES COMPUTER, V2314, P93
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   O'Hare N, 2006, LECT NOTES COMPUT SC, V4071, P529
   Oard D.W., 1996, TECHNICAL REPORT
   Pan XW, 2007, I C WIREL COMM NETW, P5427
   PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814
   Richards D, 2002, LECT NOTES ARTIF INT, V2557, P1
   Singh Sarman, 2015, Tuberc Res Treat, V2015, P957519, DOI 10.1155/2015/957519
   Smith J, 1997, S EL IM SCI TECHN
   Westerveld T., 2000, P CONTENT BASED MULT, P276
NR 35
TC 2
Z9 2
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13459
EP 13486
DI 10.1007/s11042-017-4961-x
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900018
DA 2024-07-18
ER

PT J
AU Zhao, ZZ
   Guan, QX
   Zhao, XF
   Yu, HB
   Liu, CJ
AF Zhao, Zengzhen
   Guan, Qingxiao
   Zhao, Xianfeng
   Yu, Haibo
   Liu, Changjun
TI Universal embedding strategy for batch adaptive steganography in both
   spatial and JPEG domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive steganography; Security; Embedding strategy; Batch
   steganography
ID STEGANALYSIS
AB In this paper, we present a universal embedding strategy for batch adaptive steganography in both spatial and JPEG domain. This strategy can make up for the problem when applying batch steganography to adaptive steganography in JPEG domain meanwhile improve the secure performance in spatial domain. When embedding, the strategy are employed to determine the sub-batch of cover images to carry the total message. To evaluate the feasibility of images selected as sub-batch, we calculate the histogram equilibrium for each image and the images with larger "size" and more equilibrated histogram are set a high priority when determining the sub-batch. The histogram equilibrium of images is the combination of entropy and standard deviation for the probability of histogram coefficients. We keep the repetitive information of using entropy and standard deviation to measure the histogram equilibrium. Experimental results show that histogram equilibriums vary according to images and employing images with larger "size" and more equilibrated histogram to carry the total message is a universal embedding strategy for both spatial and JPEG domain. Batch adaptive steganography with this embedding strategy can improve the secure performance effectively.
C1 [Zhao, Zengzhen; Guan, Qingxiao; Zhao, Xianfeng; Yu, Haibo; Liu, Changjun] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
   [Zhao, Zengzhen; Guan, Qingxiao; Zhao, Xianfeng; Yu, Haibo; Liu, Changjun] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100093, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Information Engineering, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Guan, QX (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.; Guan, QX (corresponding author), Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100093, Peoples R China.
EM guanqingxiao@iie.ac.cn
RI Zhao, Xianfeng/AAE-7278-2021
OI Zhao, Xianfeng/0000-0002-5617-8399
FU Natural Science Foundation of China [U1536105, U1636102]; National Key
   Technology RD Program [2014BAH41B01, 2016YFB0801003, 2016QY15Z2500]
FX This work was supported by the Natural Science Foundation of China under
   U1536105 and U1636102, and National Key Technology R&D Program under
   2014BAH41B01, 2016YFB0801003 and 2016QY15Z2500.
CR [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], ACM WORKSH INF HID M
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   [Anonymous], 2016, P 4 ACM WORKSH INF H, DOI DOI 10.1145/2909827.2930802
   [Anonymous], P 2 INT WORKSH DIG W
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Filler T, 2011, LNCS, V6958, P59
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J, 2005, IEEE T SIGNAL PROCES, V53, P3923, DOI 10.1109/TSP.2005.855393
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Guo LJ, 2012, IEEE INT WORKS INFOR, P169, DOI 10.1109/WIFS.2012.6412644
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Ker AD, 2012, P MULT SEC, P1
   Ker AD, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P107, DOI 10.1145/1411328.1411349
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Zhao Z, 2016, 15 INT WORKSH DIG FO
NR 20
TC 13
Z9 14
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 14093
EP 14113
DI 10.1007/s11042-017-5016-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900044
DA 2024-07-18
ER

PT J
AU Li, R
   He, W
   Liu, ZH
   Li, YL
   Fu, ZJ
AF Li, Ran
   He, Wei
   Liu, Zhenghui
   Li, Yanling
   Fu, Zhangjie
TI Saliency-based adaptive compressive sampling of images using measurement
   contrast
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressive sampling; Saliency detection; Measurement contrast; Adaptive
   sampling; Weighted global recovery
ID VISUAL-ATTENTION; RECONSTRUCTION; SIMILARITY; MODEL
AB Compressive Sampling (CS) achieves the sub-Nyquist image acquisition, which bringing about a rapid development of compressive imaging devices. In CS framework, the adaptive sampling scheme is an efficient approach to improving the rate-distortion performance of imaging system. However, the sampling allocation depends on the original sample image, which increases the cost and complexity of imaging system, thereby making CS lose its superiority. In this paper, we propose a saliency-based adaptive CS scheme that allocates more sampling resources to salient regions but fewer to non-salient regions. Its key idea is to extract the saliency information by using the contrast between CS measurements, thus avoiding the original sample image in the imaging system. The scheme is realized in practice without any changes of the architecture of compressive imaging device. To match our adaptive sampling scheme, we also propose a weighted global recovery model based on saliency information. This model can effectively suppress the blocking artifacts while improving the visual qualities of salient regions. Experimental results on natural images show that the proposed adaptive CS scheme improves the visual quality of reconstructed image, and has better rate-distortion performance than the existing adaptive CS schemes.
C1 [Li, Ran; He, Wei; Liu, Zhenghui; Li, Yanling] Xinyang Normal Univ, Sch Comp & Informat Technol, Xinyang 464000, Peoples R China.
   [Li, Ran; Fu, Zhangjie] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210003, Jiangsu, Peoples R China.
   [Liu, Zhenghui] Shenzhen Univ, Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.
C3 Xinyang Normal University; Nanjing University of Information Science &
   Technology; Shenzhen University
RP Li, R (corresponding author), Xinyang Normal Univ, Sch Comp & Informat Technol, Xinyang 464000, Peoples R China.; Li, R (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210003, Jiangsu, Peoples R China.
EM liran358@163.com
RI Li, Ran/N-3389-2013; li, yan/GTI-4638-2022; li, chunyuan/IQW-1618-2023
OI Li, Ran/0000-0001-7475-759X; He, Wei/0000-0003-2357-7673
FU National Natural Science Foundation of China [61501393, 61601396,
   61572417, 61502409]; Youth Sustentation Fund of Xinyang Normal
   University [2015-QN-043]; Key Scientific Research Project of Colleges
   and Universities in Henan Province of China [16A520069]
FX This work was supported in part by the National Natural Science
   Foundation of China, under Grants nos. 61501393, 61601396, 61572417 and
   61502409, in part by Youth Sustentation Fund of Xinyang Normal
   University, under Grant no. 2015-QN-043, in part by the Key Scientific
   Research Project of Colleges and Universities in Henan Province of
   China, under Grant no. 16A520069.
CR Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Chen YD, 2016, SCI CHINA INFORM SCI, V59, DOI 10.1007/s11432-015-0957-4
   Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Li R, 2013, CHINA COMMUN, V10, P58, DOI 10.1109/CC.2013.6674211
   Muhammad K, 2017, BIOMED SIGNAL PROCES, V33, P161, DOI 10.1016/j.bspc.2016.11.011
   Muhammad K, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3171-8
   Pan ZQ, 2016, J VIS COMMUN IMAGE R, V40, P516, DOI 10.1016/j.jvcir.2016.07.018
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Stankovic V, 2009, IEEE IMAGE PROC, P3037, DOI 10.1109/ICIP.2009.5414408
   Tan J, 2016, IEEE J-STSP, V10, P389, DOI 10.1109/JSTSP.2015.2500190
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu XL, 2012, IEEE T IMAGE PROCESS, V21, P451, DOI 10.1109/TIP.2011.2163520
   Yu Y, 2010, IEEE SIGNAL PROC LET, V17, P973, DOI 10.1109/LSP.2010.2080673
   Zhang J, 2014, IEEE T IMAGE PROCESS, V23, P3336, DOI 10.1109/TIP.2014.2323127
   Zhang JG, 2017, MULTIMED TOOLS APPL, V76, P4227, DOI 10.1007/s11042-016-3496-x
NR 20
TC 11
Z9 11
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12139
EP 12156
DI 10.1007/s11042-017-4862-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100024
DA 2024-07-18
ER

PT J
AU Li, W
   Li, KS
   Guo, LY
   Huang, Y
   Xue, Y
AF Li, Wei
   Li, Kangshun
   Guo, Luyan
   Huang, Ying
   Xue, Yu
TI A new validity index adapted to fuzzy clustering algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy C-means; Validity index; Membership matrix; Image classification
ID CLASSIFICATION; MACHINE
AB The fuzzy c-means clustering algorithm is the most common clustering algorithm. It solves the unrealistic nature of data by defining the membership matrix. As the fuzzy c-means clustering algorithm needs to set the number of classifications in advance, which is almost impossible in cases with no prior knowledge of the data set, some scholars put forward the concept of the validity index. Because the validity index is related to the distance relation between the membership matrix, the data point in the data set and the center of clustering, it is hoped that the feature weighting method can be used to evaluate all the characteristics of data in a data set to obtain the optimal classification number. Therefore, this paper presents an improved validity index for the comprehensive weight index, compactness index and separability index. This validity index first determines the relationship between the features of the data points and the data point itself. By defining the new compactness function and the separability function, the weight of each feature in the data set is obtained. and then the validity index is combined with the fuzzy c-means clustering algorithm to effectively determine the number of classes to be processed. The proposed algorithm is tested on two artificial data sets and real data sets; the experimental results demonstrated the advantages of this work in image processing and showed that it can effectively obtain reliable data classification results.
C1 [Li, Wei; Li, Kangshun; Guo, Luyan] South China Agr Univ, Coll Math & Informat, Guangzhou, Guangdong, Peoples R China.
   [Li, Wei] Jiangxi Univ Sci & Technol, Sch Informat Engn, Ganzhou, Jiangxi, Peoples R China.
   [Huang, Ying] Gannan Normal Univ, Inst Math & Comp Sci, Key Lab Jiangxi Prov Numer Simulat & Emulat Tech, Ganzhou, Peoples R China.
   [Xue, Yu] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.
C3 South China Agricultural University; Jiangxi University of Science &
   Technology; Gannan Normal University; Nanjing University of Information
   Science & Technology
RP Li, KS (corresponding author), South China Agr Univ, Coll Math & Informat, Guangzhou, Guangdong, Peoples R China.
EM nhwslw@gmail.com; likangshun@sina.com; 827063995@qq.com;
   nhwshy@whu.edu.cn; xueyu_123@nuaa.edu.cn
RI XUE, YU/KIB-5975-2024
FU National Natural Science Foundation of China [61573157, 61561024];
   Science and Technology Planning Project of Guangdong Province
   [2017A010101037]; Science and Technology Research Project of Jiangxi
   Province [GJJ160631, GJJ160930]; Science Foundation of Jiangxi
   University of Science and Technology [NSFJ2015-K13, NSFJ2014-K11]
FX This work was supported by the National Natural Science Foundation of
   China under Grant Nos. 61573157 and 61561024, the Science and Technology
   Planning Project of Guangdong Province with the Grant No.
   2017A010101037, the Science and Technology Research Project of Jiangxi
   Province under Grant Nos. GJJ160631 and GJJ160930, the Science
   Foundation of Jiangxi University of Science and Technology under the
   grant Nos. NSFJ2015-K13 and NSFJ2014-K11.
CR Al-Ayyoub M, 2018, MULTIMED TOOLS APPL, V77, P4939, DOI 10.1007/s11042-016-4218-0
   An WJ, 2013, NEUROCOMPUTING, V110, P101, DOI 10.1016/j.neucom.2012.11.023
   [Anonymous], P 23 INT C VER LARG
   [Anonymous], ARXIV13020629
   [Anonymous], 2014, SOFT COMPUTING PATTE
   [Anonymous], 1935, Bulletin of American Iris Society
   Bezdek J.C., 1973, Cluster validity with fuzzy sets, P58
   Bezdek James C., 1981, PATTERN RECOGN
   BEZDEK JC, 1974, J MATH BIOL, V1, P57, DOI 10.1007/BF02339490
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   CARAZO JM, 1990, J MICROSC-OXFORD, V157, P187, DOI 10.1111/j.1365-2818.1990.tb02958.x
   Fu ZJ, 2016, IEEE T INF FOREN SEC, V11, P2706, DOI 10.1109/TIFS.2016.2596138
   Fukuyama Y., 1989, Proceeding of fifth fuzzy Syst. Sympo, P247, DOI DOI 10.1016/S0167-8655(97)00168-2
   Gu B, 2017, IEEE T NEUR NET LEAR, V28, P1241, DOI 10.1109/TNNLS.2016.2527796
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Kira K, 1992, P 9 INT WORKSH MACH, P249
   Kononenko I., 1994, Machine Learning: ECML-94. European Conference on Machine Learning. Proceedings, P171
   Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, P98, DOI 10.1109/91.227387
   Kwon SH, 1998, ELECTRON LETT, V34, P2176, DOI 10.1049/el:19981523
   Li P, 2017, FUTURE GENER COMP SY, V74, P76, DOI 10.1016/j.future.2017.02.006
   Li P, 2018, CLUSTER COMPUT, V21, P277, DOI 10.1007/s10586-017-0849-9
   Liu C, 2013, IET COMPUT VIS, V7, P258, DOI 10.1049/iet-cvi.2012.0187
   PEDRYCZ W, 1985, PATTERN RECOGN LETT, V3, P13, DOI 10.1016/0167-8655(85)90037-6
   Rhazali Y, 2016, INT J CLOUD APPL COM, V6, P11, DOI 10.4018/IJCAC.2016040102
   Shieh SL, 2012, EXPERT SYST APPL, V39, P11924, DOI 10.1016/j.eswa.2012.02.181
   Skabar A, 2013, IEEE T KNOWL DATA EN, V25, P62, DOI 10.1109/TKDE.2011.205
   Vaidya J, 2013, 2013 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 1, P571, DOI 10.1109/WI-IAT.2013.80
   Wang F, 2017, SOFT COMPUT, V21, P3193, DOI 10.1007/s00500-015-2003-z
   Wu HR, 2017, APPL SOFT COMPUT, V61, P294, DOI 10.1016/j.asoc.2017.07.034
   Wu JS, 2016, IEEE SYST J, V10, P873, DOI 10.1109/JSYST.2016.2550538
   Wu JS, 2016, IEEE SYST J, V10, P888, DOI 10.1109/JSYST.2016.2550530
   XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677
   Xue Y, 2018, SOFT COMPUT, V22, P2935, DOI 10.1007/s00500-017-2547-1
   Yu ZW, 2014, IEEE ACM T COMPUT BI, V11, P727, DOI 10.1109/TCBB.2014.2315996
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhong Li, 2009, Proceedings of the 2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2009), P90, DOI 10.1109/FSKD.2009.180
NR 38
TC 3
Z9 3
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11339
EP 11361
DI 10.1007/s11042-017-5550-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900053
DA 2024-07-18
ER

PT J
AU Sedmidubsky, J
   Elias, P
   Zezula, P
AF Sedmidubsky, Jan
   Elias, Petr
   Zezula, Pavel
TI Effective and efficient similarity searching in motion capture data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion capture data retrieval; Effective similarity measure; Efficient
   indexing; k-NN query; Motion image; Convolutional neural network;
   Fixed-size motion feature
ID ACTION RECOGNITION; CLASSIFICATION; RETRIEVAL
AB Motion capture data describe human movements in the form of spatio-temporal trajectories of skeleton joints. Intelligent management of such complex data is a challenging task for computers which requires an effective concept of motion similarity. However, evaluating the pair-wise similarity is a difficult problem as a single action can be performed by various actors in different ways, speeds or starting positions. Recent methods usually model the motion similarity by comparing customized features using distance-based functions or specialized machine-learning classifiers. By combining both these approaches, we transform the problem of comparing motions of variable sizes into the problem of comparing fixed-size vectors. Specifically, each rather-short motion is encoded into a compact visual representation from which a highly descriptive 4,096-dimensional feature vector is extracted using a fine-tuned deep convolutional neural network. The advantage is that the fixed-size features are compared by the Euclidean distance which enables efficient motion indexing by any metric-based index structure. Another advantage of the proposed approach is its tolerance towards an imprecise action segmentation, the variance in movement speed, and a lower data quality. All these properties together bring new possibilities for effective and efficient large-scale retrieval.
C1 [Sedmidubsky, Jan; Zezula, Pavel] Masaryk Univ, Comp Sci, Brno, Czech Republic.
   [Elias, Petr] Masaryk Univ, Brno, Czech Republic.
C3 Masaryk University Brno; Masaryk University Brno
RP Sedmidubsky, J (corresponding author), Masaryk Univ, Comp Sci, Brno, Czech Republic.
EM xsedmid@fi.muni.cz
RI Sedmidubsky, Jan/J-3195-2013; Elias, Petr/ABE-6672-2020
OI Sedmidubsky, Jan/0000-0002-7668-8521; Elias, Petr/0000-0003-4558-6802
FU  [GBP103/12/G084]
FX This research was supported by GBP103/12/G084.
CR [Anonymous], CORR
   [Anonymous], 2009, P 2009 ACM SIGGRAPH
   [Anonymous], 15 ANN ACM INT S ADV
   [Anonymous], 2011, COMPUTER ANIMATION A
   [Anonymous], 2015, Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, MIG'15
   [Anonymous], 2010, SCA'10: proceedings of the 2010 ACM SIGGRAPH/Eurographics symposium on computer animation, DOI [10.2312/SCA/SCA10/001-010, DOI 10.2312/SCA/SCA10/001-010]
   [Anonymous], SEMANTIC SEGMENTATIO
   [Anonymous], 2004, P INT C VERY LARGE D
   [Anonymous], 2014, P 31 INT C INT C MAC
   [Anonymous], 2015, 2015 8 INT C ADV PAT
   [Anonymous], 2013, Proceedings of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games, I3D'13
   [Anonymous], 2006, ADV DATABASE SYSTEMS
   [Anonymous], 2014, P 2014 ACM SIGGRAPHE
   [Anonymous], 2007, Computer Graphics Technical Report CG-2007-2
   [Anonymous], 2014, 2014 INT C COMP GRAP
   Barnachon M, 2014, PATTERN RECOGN, V47, P238, DOI 10.1016/j.patcog.2013.06.020
   Barnachon M, 2013, PATTERN RECOGN LETT, V34, P1789, DOI 10.1016/j.patrec.2012.12.020
   Beecks C, 2015, IEEE INT SYM MULTIM, P148, DOI 10.1109/ISM.2015.86
   Cai ML, 2014, MULTIMED TOOLS APPL, V70, P1333, DOI 10.1007/s11042-013-1749-5
   Chaudhry R, 2013, IEEE COMPUT SOC CONF, P471, DOI 10.1109/CVPRW.2013.153
   Chen X, 2013, LECT NOTES COMPUT SC, V7944, P640
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Elias P, 2015, LECT NOTES COMPUT SC, V9371, P250, DOI 10.1007/978-3-319-25087-8_24
   Huynh DQ, 2009, J MATH IMAGING VIS, V35, P155, DOI 10.1007/s10851-009-0161-2
   Kadu H, 2014, IEEE T MULTIMEDIA, V16, P2191, DOI 10.1109/TMM.2014.2360793
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lan RY, 2015, VISUAL COMPUT, V31, P35, DOI 10.1007/s00371-013-0902-5
   Li M, 2016, MULTIMED TOOLS APPL, V75, P9205, DOI 10.1007/s11042-016-3480-5
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liang Y, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P185, DOI 10.1109/CIS.2014.82
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2016, Delving into transferable adversarial examples and black-box attacks"
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Lu Y., 2016, Sheet Met. Weld. Conf. XVII, P1, DOI DOI 10.1155/2016/8141269
   Milovanovic M, 2013, IEEE MULTIMEDIA, V20, P28, DOI 10.1109/MMUL.2013.16
   Müller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247
   Novak David, 2014, Database and Expert Systems Applications 25th International Conference (DEXA 2014). Proceedings: LNCS 8645, P42, DOI 10.1007/978-3-319-10085-2_4
   Ofli F, 2013, IEEE WORK APP COMP, P53, DOI 10.1109/WACV.2013.6474999
   Poppe R, 2014, BEHAV RES METHODS, V46, P625, DOI 10.3758/s13428-013-0398-y
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Sedmidubsky J, 2016, LECT NOTES COMPUT SC, V9939, P271, DOI 10.1007/978-3-319-46759-7_21
   Sedmidubsky J, 2013, LECT NOTES COMPUT SC, V8192, P669, DOI 10.1007/978-3-319-02895-8_60
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Valcik J, 2016, COMPUT ANIMAT VIRT W, V27, P484, DOI 10.1002/cav.1674
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang H., 2013, P 24 AUSTR DAT C, P13
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang JY, 2009, 2009 WRI WORLD CONGRESS ON SOFTWARE ENGINEERING, VOL 1, PROCEEDINGS, P234, DOI 10.1109/WCSE.2009.354
   Wang X, 2016, MULTIMED TOOLS APPL, V75, P11723, DOI 10.1007/s11042-015-2705-3
   Wu S., 2009, P 16 ACM S VIRTUAL R, P207
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
   Zhao XY, 2013, 2013 10TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P23, DOI 10.1109/FSKD.2013.6816160
NR 56
TC 40
Z9 40
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12073
EP 12094
DI 10.1007/s11042-017-4859-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100021
DA 2024-07-18
ER

PT J
AU Wang, D
   Yi, M
   Yang, F
   Blasch, E
   Sheaff, C
   Chen, GS
   Ling, HB
AF Wang, Dong
   Yi, Meng
   Yang, Fan
   Blasch, Erik
   Sheaff, Carolyn
   Chen, Genshe
   Ling, Haibin
TI Online single target tracking in WAMI: benchmark and evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online single target tracking; Wide area motion imagery; Benchmark
   evaluation; Baseline algorithm
ID VISUAL TRACKING; OBJECT TRACKING
AB Online single target tracking (OSTT) is a prominent topic in normal surveillance environments for security and transportation applications. However, OSTT comparative analysis is seriously under-investigated in the context of wide area motion imagery (WAMI) although its importance keeps rising with the popularity of the unmanned aerial vehicles. In this work, we make several efforts toward WAMI tracking analysis. First, we propose a new WAMI OSTT benchmark dataset, named WAMI-226, which consists of 100 image frames and 226 targets. This new benchmark dataset brings together research challenges including low frame rate, low resolution, and low contrast. Second, we evaluate 20 existing online trackers for WAMI tracking scenarios. Third, by combining the basic appearance model, background subtraction and high-order motion (HoM) affinity, we develop a novel normalized cross correlation HoM (NCC-HoM) tracking algorithm for WAMI OSTT. The experimental results show that the proposed NCC-HoM method achieves significant improvements for both target initialization and online tracking. Thus, NCC-HoM serves as a new baseline algorithm for the WAMI-226 benchmark.
C1 [Wang, Dong; Yi, Meng; Yang, Fan; Ling, Haibin] Temple Univ, Comp & Informat Sci Dept, Philadelphia, PA 19122 USA.
   [Blasch, Erik; Sheaff, Carolyn] Air Force Res Lab, Informat Directorate, Rome, NY USA.
   [Chen, Genshe] Intelligent Fus Technol Inc, Germantown, MD USA.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple
   University; Intelligent Fusion Technology
RP Wang, D (corresponding author), Temple Univ, Comp & Informat Sci Dept, Philadelphia, PA 19122 USA.
EM wangdong.ice@gmail.com; mengyi@temple.edu; tug13683@temple.edu;
   erik.blasch@us.af.mil; carolyn.sheaff@us.af.mil;
   gchen@intfusiontech.com; hbling@temple.edu
RI Yang, Fan/T-5515-2019
FU US NSF [1618398, IIS-1449860, IIS-1350521]
FX This work is supported in part by US NSF Grants 1618398, IIS-1449860 and
   IIS-1350521.
CR [Anonymous], P SPIE
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], THESIS
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], 2014, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2013.230
   [Anonymous], P ALV VIS C
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Chi ZZ, 2017, IEEE T IMAGE PROCESS, V26, P2005, DOI 10.1109/TIP.2017.2669880
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   He SF, 2013, PROC CVPR IEEE, P2427, DOI 10.1109/CVPR.2013.314
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li AN, 2016, IEEE T PATTERN ANAL, V38, P335, DOI 10.1109/TPAMI.2015.2417577
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Ling H., 2011, Information Fusion (FUSION), 2011 Proceedings of the 14th International Conference on, P1
   Liu ZH, 2017, LECT NOTES COMPUT SC, V10559, P335, DOI 10.1007/978-3-319-67777-4_29
   Lu Y, 2014, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2014.443
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Prokaj J., 2011, IEEE CVPRW WAVP, P37
   Prokaj J, 2014, PROC CVPR IEEE, P1186, DOI 10.1109/CVPR.2014.155
   Reilly V, 2010, LECT NOTES COMPUT SC, V6313, P186
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Saleemi I, 2013, INT J COMPUT VISION, V104, P198, DOI 10.1007/s11263-013-0624-1
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   Song SR, 2013, IEEE I CONF COMP VIS, P233, DOI 10.1109/ICCV.2013.36
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Uemura T, 2017, EAI INT C ROB SENS N
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang N., 2013, Advances in Neural Information Processing Systems, P809
   Wang NY, 2015, IEEE I CONF COMP VIS, P3101, DOI 10.1109/ICCV.2015.355
   Wang NY, 2013, IEEE I CONF COMP VIS, P657, DOI 10.1109/ICCV.2013.87
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 55
TC 6
Z9 7
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10939
EP 10960
DI 10.1007/s11042-018-5666-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900033
DA 2024-07-18
ER

PT J
AU Ghebleh, A
   Moghaddam, ME
AF Ghebleh, A.
   Moghaddam, M. Ebrahimi
TI Clothing-invariant human gait recognition using an adaptive outlier
   detection method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Clothing-invariant; Gait recognition; Outlier detection
ID EXTRACTION; IMAGE
AB Human gait as a behavioral biometric identifier has received much attention in recent years. But there are some challenges which hinder using this biometric in real applications. One of these challenges is clothing variations which complicates the recognition process. In this paper, we propose an adaptive outlier detection method to remove the effect of clothing on silhouettes. The proposed method detects the most similar parts of probe and each gallery sample independently and uses these parts to obtain a similarity measure. Towards this end, the distances of the probe and a gallery sample are calculated row by row which are then used to obtain an adaptive threshold to determine valid and invalid rows. The average distance per valid rows is then considered as dissimilarity measure of samples. Experimental results on OU-ISIR Gait Database, the Treadmill Dataset B and CASIA Gait Database, Dataset B, show that this method efficiently detects and removes the clothing effect on silhouettes and reaches about 82 and 84% successful recognition respectively.
C1 [Ghebleh, A.; Moghaddam, M. Ebrahimi] Shahid Beheshti Univ, Fac Comp Sci & Engn, Tehran, Iran.
C3 Shahid Beheshti University
RP Ghebleh, A (corresponding author), Shahid Beheshti Univ, Fac Comp Sci & Engn, Tehran, Iran.
EM a_ghebleh@sbu.ac.ir; m_moghadam@sbu.ac.ir
OI Ghebleh, Abbas/0000-0001-7486-1995
CR [Anonymous], MULTIMEDIA TOOLS APP
   Bashir K, 2008, ICASSP 2008 IEEE INT
   Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bobick AF, 2001, CVPR 2001 P IEEE COM
   Cunado D, 2003, COMPUT VIS IMAGE UND, V90, P1, DOI [10.1016/S1077-3142(03)00008-0, 10.1010/SI077-3142(03)00008-0]
   Dockstader SL, 2003, IEEE T IMAGE PROCESS, V12, P962, DOI 10.1109/TIP.2003.815259
   Guan Y, 2012, INT INF HID MULT SIG
   Haiping LP, 2008, EURASIP J ADV SIGN P
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hossain MA, 2010, PATTERN RECOGN, V43, P2281, DOI 10.1016/j.patcog.2009.12.020
   Lam THW, 2011, PATTERN RECOGN, V44, P973, DOI 10.1016/j.patcog.2010.10.011
   Lee S, 2007, COMP VIS PATT REC CV
   Li XL, 2008, IEEE T SYST MAN CY C, V38, P145, DOI 10.1109/TSMCC.2007.913886
   Liu J, 2007, MULT EXP IEEE INT C
   Makihara Yasushi, 2012, IPSJ Transactions on Computer Vision and Applications, V4, P42, DOI 10.2197/ipsjtcva.4.53
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   Piccardi M, 2004, SYST MAN CYB IEEE IN
   Rokanujjaman M, 2013, INF EL VIS ICIEV INT
   Rokanujjaman M, 2012, EL COMP ENG ICECE 20
   Wang L, 2004, IEEE T CIRC SYST VID, V14, P149, DOI 10.1109/TCSVT.2003.821972
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Whytock TP, 2013, LECT NOTES COMPUT SC, V8034, P523, DOI 10.1007/978-3-642-41939-3_51
   Xiaoxiang L I., 2013, Journal of Computational Information Systems, V9, P121
   Yang XC, 2008, SIGNAL PROCESS, V88, P2350, DOI 10.1016/j.sigpro.2008.03.006
   Yogarajah P, 2011, IM SIGN PROC AN ISPA
   Yu S, 2006, PATT REC ICPR 2006 1
   Zhang E, 2010, SIGNAL PROCESS, V90, P2295, DOI 10.1016/j.sigpro.2010.01.024
   Zhang R, 2007, IMAGE VISION COMPUT, V25, P321, DOI 10.1016/j.imavis.2005.10.007
NR 29
TC 12
Z9 12
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8237
EP 8257
DI 10.1007/s11042-017-4712-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800021
DA 2024-07-18
ER

PT J
AU Gogousis, V
   Tefas, A
AF Gogousis, Vlasis
   Tefas, Anastasios
TI Caricature generation utilizing the notion of anti-face
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Caricature generation; Automatic; Anti-face; Average face; Unbiased
   distortions; Face oddity; Beautification
ID AVERAGE
AB The production of caricatures is a particularly interesting field of art, because it aims to highlight the very essence of a given face. Caricature generation systems traditionally rely on two approaches: they either follow extracted rules through learning algorithms, or follow rules that were directly programmed by experts. This paper attempts to reduce the reliance on heuristic methods, by proposing a novel method that provides a set of well-defined rules, which can be put to use for the purpose of caricature generation. The method is based on the notion of anti-face in conjunction with unbiased distortions. In addition, we indicate the usefulness of the anti-face as a means to perceive, for our own sake, the degree to which our face seems peculiar to others. Finally, we deploy a reverse variant of the method in order to attain beautification.
C1 [Gogousis, Vlasis; Tefas, Anastasios] Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
C3 Aristotle University of Thessaloniki
RP Gogousis, V (corresponding author), Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
EM vgogousis@gmail.com; tefas@aiia.csd.auth.gr
RI Tefas, Anastasios/ABA-2328-2020; Tefas, Anastasios/F-1899-2010
OI Tefas, Anastasios/0000-0003-1288-3667
CR AKLEMAN E, 1997, P ACM SIGGRAPH 97, P145
   Brennan S. E., 1982, THESIS
   Chiang P-Y, 2004, 2004 AS C COMP VIS J
   Gooch B, 2004, ACM T GRAPHIC, V23, P27, DOI 10.1145/966131.966133
   Koshimizu H., 1999, P IEEE INT C SYST MA, P294
   LANGLOIS JH, 1990, PSYCHOL SCI, V1, P115, DOI 10.1111/j.1467-9280.1990.tb00079.x
   Lewis H., 1998, Elements of the Theory of Computation
   LIANG L, 2002, IEEE P 10 PAC C COMP
   Liu J., 2006, ELECT POWER CONSTRUC, V27, P14
   Liu JF, 2009, LECT NOTES COMPUT SC, V5371, P413
   Mo Z, 2004, P ACM SIGGRAPH C ABS
   Rhodes G, 2007, VISION RES, V47, P974, DOI 10.1016/j.visres.2006.12.010
   Tseng CC, 2007, LECT NOTES COMPUT SC, V4843, P314
   Xu GZ, 2004, P EL COMM JAP 3, V87
NR 14
TC 0
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8259
EP 8271
DI 10.1007/s11042-017-4713-y
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800022
DA 2024-07-18
ER

PT J
AU Koukiou, G
   Anastassopoulos, V
AF Koukiou, Georgia
   Anastassopoulos, Vassilis
TI Local difference patterns for drunk person identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Thermal infrared images; Intoxication detection; Drunk person
   identification; Local difference patterns
ID INFRARED-SPECTRUM; FACE RECOGNITION; CLASSIFICATION
AB In this work, facial thermal infrared images are employed for intoxicated person discrimination. Specifically, the region of the forehead of the face of the sober and the corresponding intoxicated person is used to test if the employed Local Difference Patterns (LDPs) constitute discriminative features. For an intoxicated person, vessels on the forehead become more active so that the intensity of the pixels in this region is affected accordingly. The LDPs employed ignore orientation of the pixels distribution and give emphasis on the first and second norms of the differences as well as the ordered values of the pixels in the employed kernels. The statistics of the LDPs for the drunk person are different from those of the sober one and accordingly drunkenness can be ascertained by comparing the thermal infrared image of the corresponding sober and intoxicated person. Six from the eight LDPs examined to be used as features for drunk identification were proved successful. Their classification success rate was over 73 and up to 85%. The proposed method can be incorporated into a non-invasive inspection commercial system to be used by the police as a first step for intoxicated person detection. Forty one participants in the experiment have contributed to the creation of the unique sober-drunk database which is available on the web and contains over 4.000 images.
C1 [Anastassopoulos, Vassilis] Univ Patras, Dept Phys, Elect Lab ELLAB, Patras, Greece.
   [Koukiou, Georgia] Univ Thessaly, Dept Comp Sci, Lamia, Greece.
C3 University of Patras
RP Koukiou, G (corresponding author), Univ Thessaly, Dept Comp Sci, Lamia, Greece.
EM gkoukiou@upatras.gr; vassilis@upatras.gr
OI Koukiou, Georgia/0000-0002-9314-8359
CR Andersson A, 2009, BMC PUBLIC HEALTH, V9, DOI 10.1186/1471-2458-9-229
   [Anonymous], 2010, ROAD SAFETY WEB PUBL
   [Anonymous], 1999, Biometrics: Personal Identification in Networked Society
   [Anonymous], J FORENSICS LEGAL ME
   [Anonymous], PHYSL THERMAL SIGNAL
   [Anonymous], 2012, INT J COMPUTER APPL
   [Anonymous], 2011, P 4 INT C IMAGING CR
   Benedikt L, 2010, IEEE T SYST MAN CY A, V40, P449, DOI 10.1109/TSMCA.2010.2041656
   Buddharaju P, 2007, IEEE T PATTERN ANAL, V29, P613, DOI 10.1109/TPAMI.2007.1007
   Choi JY, 2010, IEEE T CIRC SYST VID, V20, P1292, DOI 10.1109/TCSVT.2010.2058470
   Cowan JM, 1996, J ANAL TOXICOL, V20, P287, DOI 10.1093/jat/20.5.287
   De Marsico M, 2011, IEEE T SYST MAN CY C, V41, P481, DOI 10.1109/TSMCC.2010.2060326
   Khan MM, 2006, ACM T AUTON ADAP SYS, V1, P91, DOI 10.1145/1152934.1152939
   Koukiou G, 2016, AUST J FORENSIC SCI, V48, P326, DOI 10.1080/00450618.2015.1060522
   Koukiou G, 2016, J FORENSIC SCI, V61, P259, DOI 10.1111/1556-4029.12989
   Koukiou G, 2015, FORENSIC SCI INT, V252, P69, DOI 10.1016/j.forsciint.2015.04.022
   Koukiou G, 2012, INT J ELECTRON SECUR, V4, P229, DOI 10.1504/IJESDF.2012.049747
   Moore S, 2011, COMPUT VIS IMAGE UND, V115, P541, DOI 10.1016/j.cviu.2010.12.001
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Perham N, 2007, ADDICTION, V102, P377, DOI 10.1111/j.1360-0443.2006.01699.x
   Taylor L, 2006, DRUNK DRIVING DEFENC
   Tolba A. S., 2006, INT J SIGNAL PROCESS, V2, P88
   Wu Y, 2009, INT J HYDROGEN ENERG, V34, P5940, DOI 10.1016/j.ijhydene.2009.01.084
   Yoshitomi Y, 1997, RO-MAN '97 SENDAI: 6TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P380, DOI 10.1109/ROMAN.1997.647016
   Zhao SY, 2005, LECT NOTES ARTIF INT, V3587, P437
NR 25
TC 8
Z9 8
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9293
EP 9305
DI 10.1007/s11042-017-4892-6
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200007
DA 2024-07-18
ER

PT J
AU Singh, PK
   Sarkar, R
   Das, N
   Basu, S
   Kundu, M
   Nasipuri, M
AF Singh, Pawan Kumar
   Sarkar, Ram
   Das, Nibaran
   Basu, Subhadip
   Kundu, Mahantapas
   Nasipuri, Mita
TI Benchmark databases of handwritten <i>Bangla</i>-<i>Roman</i> and
   <i>Devanagari</i>-<i>Roman</i> mixed-script document images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Script identification; Handwritten text; Mixed-script documents; Optical
   character recognition; Modified log-Gabor filter; Transform; Statistical
   significance tests
ID INDIAN SCRIPTS; IDENTIFICATION; RECOGNITION; SYSTEM; CLASSIFIERS
AB Handwritten document image dataset is one of the basic necessities to conduct research on developing Optical Character Recognition (OCR) systems. In a multilingual country like India, handwritten documents often contain more than one script, leading to complex pattern analysis problems. In this paper, we highlight two such situations where Devanagari and Bangla scripts, two most widely used scripts in Indian sub-continent, are individually used along with Roman script in documents. We address three key challenges here: 1) collection, compilation and organization of benchmark databases of images of 150 Bangla-Roman and 150 Devanagari-Roman mixed-script handwritten document pages respectively, 2) script-level annotation of 18931 Bangla words, 15528 Devanagari words and 10331 Roman words in those 300 document pages, and 3) development of a bi-script and tri-script word-level script identification module using Modified log-Gabor filter as feature extractor. The technique is statistically validated using multiple classifiers and it is found that Multi-Layer Perceptron (MLP) classifier performs the best. Average word-level script identification accuracies of 92.32%, 95.30% and 93.78% are achieved using 3-fold cross validation for Bangla-Roman, Devanagari-Roman and Bangla-Devanagari-Roman databases respectively. Both the mixed-script document databases along with the script-level annotations and 44790 extracted word images of the three aforementioned scripts are available freely at https://code.google.com/p/cmaterdb/.
C1 [Singh, Pawan Kumar; Sarkar, Ram; Das, Nibaran; Basu, Subhadip; Kundu, Mahantapas; Nasipuri, Mita] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
C3 Jadavpur University
RP Sarkar, R (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
EM raamsarkar@gmail.com
RI Roy, Kaushik/O-7021-2019; Sarkar, Ram/AAX-3822-2020; SINGH, PAWAN
   KUMAR/E-3408-2013
OI Roy, Kaushik/0000-0002-3360-7576; Sarkar, Ram/0000-0001-8813-4086;
   SINGH, PAWAN KUMAR/0000-0002-9598-7981
FU University with Potential for Excellence (UPE), Phase-II, UGC,
   Government of India
FX The authors are thankful to the CMATER and Project on Storage Retrieval
   and Understanding of Video for Multimedia (SRUVM) of Computer Science
   and Engineering Department, Jadavpur University, for providing
   infrastructure facilities during progress of the work. The current work,
   reported here, has been partially funded by University with Potential
   for Excellence (UPE), Phase-II, UGC, Government of India. Also a lot of
   people helped us to make the database worthy to use. Authors are
   grateful to everyone who contributed with data to make this project
   successful.
CR Alaei A, 2011, PROC INT CONF DOC, P141, DOI 10.1109/ICDAR.2011.37
   [Anonymous], P INT WORKSH FRONT H
   [Anonymous], 2010, INT J SIGNAL PROCESS
   [Anonymous], 1995, 11 C UNC ART INT SAN, DOI DOI 10.1109/TGRS.2004.834800
   [Anonymous], 1992, R. woods digital image processing
   [Anonymous], 2007, ENCARTA ENCY
   [Anonymous], 2013, IOSR J, DOI DOI 10.9790/0661-12597102
   Basu S., 2005, P 2 IND INT C ART IN, P407
   Bhattacharya U, 2009, IEEE T PATTERN ANAL, V31, P444, DOI 10.1109/TPAMI.2008.88
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chanda Sukalpa, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P926, DOI 10.1109/ICDAR.2009.239
   Chanda S., 2005, P INT C COGN REC, P538
   Chanda S, 2008, INT C PATT RECOG, P2686
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chaudhari S, 2016, PROCEDIA COMPUT SCI, V79, P85, DOI 10.1016/j.procs.2016.03.012
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Dhandra BV, 2006, 2006 1ST INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT, P389
   Dhandra BV, 2006, INT C PATT RECOG, P950
   Dhanya D, 2002, SADHANA-ACAD P ENG S, V27, P73, DOI 10.1007/BF02703313
   DUNN OJ, 1961, J AM STAT ASSOC, V56, P52, DOI 10.2307/2282330
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hassan E., 2011, P 2011 JOINT WORKSH, P1
   Hiremath PS, 2008, PATTERN RECOGN LETT, V29, P1182, DOI 10.1016/j.patrec.2008.01.012
   Hiremath PS, 2010, 2010 IEEE 2ND INTERNATIONAL ADVANCE COMPUTING CONFERENCE, P110, DOI 10.1109/IADCC.2010.5423028
   IMAN RL, 1980, COMMUN STAT A-THEOR, V9, P571, DOI 10.1080/03610928008827904
   Jayadevan R, 2011, PROC INT CONF DOC, P304, DOI 10.1109/ICDAR.2011.69
   Joshi GD, 2006, LECT NOTES COMPUT SC, V3872, P255
   LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191
   Moravec H.P., 1980, Obstacle Avoidance and Navigation in the Real World by a Seeing Robot Rove
   Nemenyi P. B., 1963, doctoral dissertation
   Nethravathi B., 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P415, DOI 10.1109/ICFHR.2010.71
   Obaidullah SM, 2013, J PATTERN RECOGNIT R, V8, P1, DOI 10.13176/11.485
   Padma M. C., 2009, International Journal of Computer Science & Information Technology, V1, P64
   Padma M.C., 2010, International Journal of Computer Science and Applications, Technomathematics Research Foundation, V7, P16
   Padma M. C., 2010, INT J IMAGE PROCESSI, V4, P35
   Pal U, 2007, PROC INT CONF DOC, P749
   Pal U, 2003, PROC INT CONF DOC, P880
   Pal U, 1997, PROC INT CONF DOC, P576, DOI 10.1109/ICDAR.1997.620567
   Pardeshi R, 2014, INT CONF FRONT HAND, P375, DOI 10.1109/ICFHR.2014.69
   Pati PB, 2006, LECT NOTES COMPUT SC, V3872, P380
   Pati PB, 2008, PATTERN RECOGN LETT, V29, P1218, DOI 10.1016/j.patrec.2008.01.027
   Patil SB, 2002, SADHANA-ACAD P ENG S, V27, P83, DOI 10.1007/BF02703314
   Rish I., 2001, IJCAI 2001 WORKSH EM, P41
   Roy K., 2011, Proceedings of the 2011 Third National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG 2011), P66, DOI 10.1109/NCVPRIPG.2011.22
   Roy K., 2006, Procedings of 10th International Workshop on Frontiers in Handwriting Recognition, P521
   Sarkar R., 2010, J OF COMPUTING, V2, P103
   Sarkar R, 2012, INT J DOC ANAL RECOG, V15, P71, DOI 10.1007/s10032-011-0148-6
   Singh Pawan Kumar, 2013, Pattern Recognition and Machine Intelligence. 5th International Conference, PReMI 2013. Proceedings: LNCS 8251, P509, DOI 10.1007/978-3-642-45062-4_70
   Singh PK, 2017, ADV INTELL SYST, V458, P517, DOI 10.1007/978-981-10-2035-3_53
   Singh PK, 2015, 2015 IEEE 2ND INTERNATIONAL CONFERENCE ON RECENT TRENDS IN INFORMATION SYSTEMS (RETIS), P225, DOI 10.1109/ReTIS.2015.7232882
   Singh PK, 2015, COMPUT SCI REV, V15-16, P1, DOI 10.1016/j.cosrev.2014.12.001
   Singh PK, 2015, ADV INTELL SYST, V340, P285, DOI 10.1007/978-81-322-2247-7_30
   Singh PK, 2014, INT J APPL PATTERN R, V1, P152, DOI 10.1504/IJAPR.2014.063741
   SINGH PK, 2015, INT J SCI STUDY, V3, P1, DOI DOI 10.17354/ijss/2015/336
NR 59
TC 20
Z9 20
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8441
EP 8473
DI 10.1007/s11042-017-4745-3
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800030
DA 2024-07-18
ER

PT J
AU Vijayaraj, A
   Suresh, RM
   Poonkuzhali, S
AF Vijayaraj, A.
   Suresh, R. M.
   Poonkuzhali, S.
TI RETRACTED: Load balancing in wireless networks using reputation-ReDS in
   the magnified distributed hash table (Retracted article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Shared; DHTs; Lookup; RCVI; ReDS; Load imbalance; Noxious; Pointless;
   Radiance
AB In Peer to Peer systems (P2P); an only companion is connected to another associate in a different stockpiling framework. A different gathering of resolutions depicts disseminated hash tables outlines resources onto hubs in P2P system. It offers a "find - obtain" development where getting the advantages in the framework is available, and like this it can get back. DHT offers a liberal position of hubs and administrations yet don't protect adjacent to vindictive hub moving lookups (the movement used to arrange the benefits in the system). Malicious hubs on a look-up pathway can precisely undermine question. Frameworks like Halo (in light of the harmony) reduction such ambushes by utilizing pointless lookup inquiries. To supply better affirmation; Reputation for Directory administrations is an establishment for training so as to boost lookups in abundance DHT how well new hubs administration lookup wishes. ReDS technique can be executed too for all intents and purposes any abundance DHT containing corona. Additionally, it perceives shared acknowledgment and dispenses with of difficult lookup paths. This acknowledgment does not wager on the partitioning of notoriety numbers and isolating is helpless to assaults that make larger part use of ReDS unfit. Corona is a plan that deeds the deterministic arranging of access to hubs in the harmony to introduce a "high-affirmation situate" through pointless investigates. Radiance was proposed to contain dynamic lookups and can browse different ways. Partitioned notoriety technique for Halo, has deterministic finger gathering. In deciding notoriety organize; the holes of attackers are diminished by utilizing unique Reciprocal Channel Variation based Identification (RCVI) technique. Load imbalance issue emerges through this lookup activity. Each Peer handles the heap by contrasting its ability. ReDS creates accomplishment lookup rates for Halo, yet next to think assailant was trying to brandish their notoriety achieves and in the presence of hub twirl.
C1 [Vijayaraj, A.] Saveetha Engn Coll, Dept Informat Technol, Chennai, Tamil Nadu, India.
   [Suresh, R. M.] Sri Lakshmi Ammaal Engn Coll, Chennai, Tamil Nadu, India.
   [Poonkuzhali, S.] Rajalakshmi Engn Coll, Dept Informat Technol, Chennai 602105, Tamil Nadu, India.
C3 Rajalakshmi Engineering College
RP Vijayaraj, A (corresponding author), Saveetha Engn Coll, Dept Informat Technol, Chennai, Tamil Nadu, India.
EM satturvijay@yahoo.com; rmsuresh@hotmail.com;
   poonkuzhali.s@rajalakshmi.edu.in
RI S, Poonkuzhali/Z-2261-2019; M, Suresh R/J-4971-2015; Alwarsamy,
   Vijayaraj/KAL-8842-2024
OI S, Poonkuzhali/0000-0001-6220-973X; Alwarsamy,
   Vijayaraj/0000-0002-1942-3519
CR Akavipat R, 2008, P ACM WORKSH INS THR
   Akavipat R, 2014, IEEE T PARALL DISTR, V25, P321, DOI 10.1109/TPDS.2013.231
   [Anonymous], OSDI
   Antony I., 2001, LECT NOTES COMPUTER, P329, DOI DOI 10.1007/3-540-45518-3_18
   Artigas MS, 2005, P IEEE 5 INT C PEER
   Awerbuch B, 2006, P ACM 18 ANN S PAR A
   Bandara HMND, 2011, IEEE CONS COMM NETW
   Bandara HMSD, 2012, PEER TO PEER NETWORK
   Bianchi S, 2006, IEEE IC COMP COM NET, P411, DOI 10.1109/ICCCN.2006.286311
   DABEK F, 2001, P 8 IEEE WORKSH HOT, V8, P71
   Dabek R, 2003, LECT NOTES COMPUT SC, V2735, P33
   Efthymiopoulos N., 2006, IEEE GLOB TEL C GLOB, P1
   Gopalakrishnan V, 2004, INT CON DISTR COMP S, P360, DOI 10.1109/ICDCS.2004.1281601
   Hildrum K., 2002, P 14 ANN ACM S PARAL, P41
   Kapadia A, 2008, P 15 ANN NETW DISTR
   Kapadia A, 2008, P NETW DISTR SYST SE
   Mickens JW, 2007, I C DEPEND SYS NETWO, P225, DOI 10.1109/DSN.2007.27
   Nambiar A, 2006, COMPUTER COMMUNICATI
   NAOR M, 2003, P 2 INT WORKSH PEER
   Ratnasamy S., 2001, P ACM SIGCOMM SAN DI
   Rowstron A., 2001, Operating Systems Review, V35, P188, DOI 10.1145/502059.502053
   Stoica I, 2001, ACM SIGCOMM COMP COM, V31, P149, DOI 10.1145/964723.383071
   Stutzbach D, 2006, P INFOCOM
   Wang P, 2006, 200620 DTC U MINN
   Yin LZ, 2005, PROC INT CONF DATA, P258
NR 25
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 10347
EP 10364
DI 10.1007/s11042-018-5620-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200061
DA 2024-07-18
ER

PT J
AU Bouchrika, T
   Jemai, O
   Zaied, M
   Ben Amar, C
AF Bouchrika, Tahani
   Jemai, Olfa
   Zaied, Mourad
   Ben Amar, Chokri
TI Rapid and efficient hand gestures recognizer based on classes
   discriminator wavelet networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand gesture recognition; Separator wavelet networks; Cascaded wavelet
   networks
AB The vision based on hand gesture recognition is one of the key challenges in behavior understanding and computer vision. It offers to machines the possibility of identifying, recognizing and interpreting hand gestures in the aim of controlling certain devices, to monitor certain human activities or interacting with certain human machine interfaces (HMI). This paper aims at proposing a rapid and efficient hand gestures recognizer based on classes discriminator wavelet networks. In this work two main contributions were proposed: firstly, by enhancing previous works using wavelet networks (WN) in the classification field, specifically at the learning process of the latest version of WN classifier (WNC) by creating separator WNs discriminating classes (n - 1 WNs to classify n classes) as alternative of constructing a WN corresponding to each training image. This contribution, by minimizing the comparison number between test images WNs and training ones, makes quicker the test phase. Secondly, a new WN architecture based on the cascade notion was proposed, in which the WN is decomposed of a set of stages. The novel architecture aims not only at making recognitions robust and quick but also at rejecting from early stages, as fast as possible, gestures that must not be taken into consideration by the system (spontaneous gestures). To test this work, both proprietary and public hand posture datasets were used. Comparisons with other works are detailed and discussed. Given results showed that the novel hand gesture recognizer performances are comparable to already established ones.
C1 [Bouchrika, Tahani] Univ Gabes, Fac Sci Gabes, Gabes, Tunisia.
   [Jemai, Olfa; Zaied, Mourad] Univ Gabes, Natl Engn Sch Gabes ENIG, Gabes, Tunisia.
   [Ben Amar, Chokri] Univ Sfax, Natl Engn Sch Sfax ENIS, Gabes, Tunisia.
C3 Universite de Gabes; Universite de Gabes; Universite de Sfax; Ecole
   Nationale dIngenieurs de Sfax (ENIS)
RP Bouchrika, T (corresponding author), Univ Gabes, Fac Sci Gabes, Gabes, Tunisia.
EM tahani.bouchrika@ieee.org; olfa.jemai@ieee.org; mourad.zaied@ieee.org;
   chokri.benamar@ieee.org
RI Chokri, BEN AMAR/K-5237-2012; Jemai, Olfa/GZK-6566-2022
OI Jemai, Olfa/0009-0000-9037-4169
FU General Direction of Scientific Research (DGRST), Tunisia, under the
   ARUB program
FX The authors would like to acknowledge the financial support of this work
   by grants from General Direction of Scientific Research (DGRST),
   Tunisia, under the ARUB program.
CR [Anonymous], 2008, IPTA IMAGE PROCESSIN
   [Anonymous], 2010 IEEE WORKSH C C
   Ben Amar C, 2005, ADV ENG SOFTW, V36, P459, DOI 10.1016/j.advengsoft.2005.01.013
   Bouchrika T, 2012, INT C COMM COMP CONT, P1, DOI [10.1109/CCCA.2012.6417911, DOI 10.1109/CCCA.2012.6417911]
   Bouchrika T, 2015, PROC SPIE, V9875, DOI 10.1117/12.2228425
   Bouchrika T, 2015, PROC INT C TOOLS ART, P258, DOI 10.1109/ICTAI.2015.48
   Bouchrika T, 2014, IEEE SYS MAN CYBERN, P1360, DOI 10.1109/SMC.2014.6974104
   Bouchrika T, 2014, LECT NOTES COMPUT SC, V8669, P183, DOI 10.1007/978-3-319-10840-7_23
   Bouchrika T, 2014, MULTIMED TOOLS APPL, V72, P2949, DOI 10.1007/s11042-013-1557-y
   Cemil O, 2011, ENG APPL ARTIF INTEL, V24
   Chen FS, 2003, IMAGE VISION COMPUT, V21, P745, DOI 10.1016/S0262-8856(03)00070-2
   Delp D, 1989, SOMA ENG HUMAN BODY, V3, P17
   Fels S., 1994, THESIS
   Freeman T, 1994, TR9424 MITS EL RES L
   Han JW, 2009, PATTERN RECOGN LETT, V30, P623, DOI 10.1016/j.patrec.2008.12.010
   Jemai O, 2011, INT J PATTERN RECOGN, V25, P1297, DOI 10.1142/S0218001411009111
   Kao C. Y, 2011, PROCEDIA ENG, V15, P3739
   Kumar PP, 2010, INT J HUM ROBOT, V7, P331, DOI 10.1142/S0219843610002180
   Lee C, 1996, IEEE INT CONF ROBOT, P2982, DOI 10.1109/ROBOT.1996.509165
   Lv ZH, 2015, PERS UBIQUIT COMPUT, V19, P551, DOI 10.1007/s00779-015-0844-1
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Stephan J.J., 2010, International Journal of Advancements in Computing Technology, V2, P30
   Stergiopoulou E, 2009, ENG APPL ARTIF INTEL, V22, P1141, DOI 10.1016/j.engappai.2009.03.008
   Sushmita M, 2007, EEE T SYST MAN CYB C, V37
   Triesch J, HAND POSTURE GESTURE
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Zhou M, 2006, APPL COMP VIS 2006 W, P101
NR 28
TC 2
Z9 2
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5995
EP 6016
DI 10.1007/s11042-017-4510-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800039
DA 2024-07-18
ER

PT J
AU Diaz-Honrubia, AJ
   Martinez, JL
   Cuenca, P
AF Diaz-Honrubia, A. J.
   Martinez, J. L.
   Cuenca, P.
TI A fast intra H.264/AVC to HEVC transcoding system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; H.264/AVC; Transcoding; CTU splitting; Intra prediction
ID MODE DECISION ALGORITHM
AB The H.264/Advanced Video Coding (AVC) standard has been widely used in the last 10 years, and this has led to a large amount of legacy video being currently encoded in this format. However, the new High Efficiency Video Coding (HEVC) standard has recently been developed and it is thought that it will dominate the market in the next few years. These two facts make an efficient transcoding system between H.264/AVC and HEVC necessary. Moreover, it should be taken into account that intra sequences are commonly used in certain scenarios, such as video editing and post-production, making a migration of these intra contents from H.264/AVC to HEVC necessary. This paper proposes a fast intra H.264/AVC to HEVC transcoding system that is based on Bayesian classifiers and which outperforms other state-of-the-art algorithms, achieving a good complexity reduction with a negligible bit rate increase.
C1 [Diaz-Honrubia, A. J.; Martinez, J. L.; Cuenca, P.] Univ Castilla La Mancha, High Performance Networks & Architectures Lab, Albacete, Spain.
C3 Universidad de Castilla-La Mancha
RP Diaz-Honrubia, AJ (corresponding author), Univ Castilla La Mancha, High Performance Networks & Architectures Lab, Albacete, Spain.
EM Antonio.DHonrubia@uclm.es; JoseLuis.Martinez@uclm.es;
   Pedro.Cuenca@uclm.es
RI Cuenca, Pedro/P-7960-2019; Martinez, Jose Luis/ABA-2535-2021
OI Cuenca, Pedro/0000-0002-2791-0165; Martinez, Jose
   Luis/0000-0001-5119-2418; Diaz-Honrubia, Antonio
   Jesus/0000-0001-5464-0714
FU MINECO; European Commission (FEDER funds) [TIN2015-66972-C5-2-R];
   Spanish Education, Culture and Sports Ministry [FPU12/00994]
FX This work has been supported by the MINECO and European Commission
   (FEDER funds) under project TIN2015-66972-C5-2-R and by the Spanish
   Education, Culture and Sports Ministry under grant FPU12/00994.
CR [Anonymous], P910 ITUR
   [Anonymous], 2012, 1449610 ISOIEC
   [Anonymous], 1996, P800 ITUR
   [Anonymous], 2013, P 11 JCT VC M
   [Anonymous], P 8 JCT VC M SAN JOS
   [Anonymous], P 12 JCT VC M
   Bjontegaard G., 2008, VCEGAI11
   Cisco, 2016, VIS NETW IND FOR MET
   Daxin Guang, 2014, Advances in Multimedia Information Processing - PCM 2014. 15th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8879, P64, DOI 10.1007/978-3-319-13168-9_7
   Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464
   FAYYAD UM, 1993, IJCAI-93, VOLS 1 AND 2, P1022
   Fernández-Escribano G, 2008, IEEE T CIRC SYST VID, V18, P172, DOI 10.1109/TCSVT.2008.918115
   Garrido-Cantos R, 2011, IEEE T CONSUM ELECTR, V57, P239, DOI 10.1109/TCE.2011.5735508
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Díaz-Honrubia AJ, 2016, IEEE T CIRC SYST VID, V26, P154, DOI 10.1109/TCSVT.2015.2473299
   Díaz-Honrubia AJ, 2015, IEEE DATA COMPR CONF, P449, DOI 10.1109/DCC.2015.46
   MINSKY M, 1961, P IRE, V49, P8, DOI 10.1109/JRPROC.1961.287775
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Piao Y, 2010, P 3 JCT VC M
   Ruiz D, 2016, SIGNAL PROCESS-IMAGE, V44, P12, DOI 10.1016/j.image.2016.03.002
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Tan TK, 2016, IEEE T CIRC SYST VID, V26, P76, DOI 10.1109/TCSVT.2015.2477916
   Zhang D, 2012, IEEE INT C MULT EXP
NR 23
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 6367
EP 6384
DI 10.1007/s11042-017-4545-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800058
DA 2024-07-18
ER

PT J
AU Rodriguez-Gil, L
   Orduña, P
   García-Zubia, J
   López-de-Ipiña, D
AF Rodriguez-Gil, Luis
   Orduna, Pablo
   Garcia-Zubia, Javier
   Lopez-de-Ipina, Diego
TI Interactive live-streaming technologies and approaches for web-based
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Webcam; Live streaming; Remote laboratories; Online learning tools; Rich
   interactive applications
ID REMOTE; LABORATORIES; ARCHITECTURE
AB Interactive live streaming is a key feature of applications and platforms in which the actions of the viewers affect the content of the stream. In those, a minimal capture-display delay is critical. Though recent technological advances have certainly made it possible to provide web-based interactive live-streaming, little research is available that compares the real-world performance of the different web-based schemes. In this paper we use educational remote laboratories as a case study. We analyze the restrictions that web-based interactive live-streaming applications have, such as a low delay. We also consider additional characteristics that are often sought in production systems, such as universality and deployability behind institutional firewalls. The paper describes and experimentally compares the most relevant approaches for the study. With the provided descriptions and real-world experimental results, researchers, designers and developers can: a) select among the interactive live-streaming approaches which are available for their real-world systems, b) decide which one is most appropriate for their purpose, and c) know what performance and results they can expect.
C1 [Rodriguez-Gil, Luis; Orduna, Pablo; Garcia-Zubia, Javier; Lopez-de-Ipina, Diego] Univ Deusto, Fac Engn, Avda Univ 24, Bilbao 48007, Spain.
   [Rodriguez-Gil, Luis; Orduna, Pablo; Garcia-Zubia, Javier; Lopez-de-Ipina, Diego] DeustoTech Deusto Fdn, Avda Univ 24, Bilbao 48007, Spain.
C3 University of Deusto; University of Deusto
RP Rodriguez-Gil, L (corresponding author), Univ Deusto, Fac Engn, Avda Univ 24, Bilbao 48007, Spain.; Rodriguez-Gil, L (corresponding author), DeustoTech Deusto Fdn, Avda Univ 24, Bilbao 48007, Spain.
EM luis.rodriguezgil@deusto.es; pablo.orduna@deusto.es; zubia@deusto.es;
   dipina@deusto.es
RI Garcia, Javier/JWP-0036-2024; Orduna, Pablo/D-9282-2011; Rodriguez-Gil,
   Luis/AAN-8204-2020; López-de-Ipiña, Diego/A-9651-2012
OI Rodriguez-Gil, Luis/0000-0003-3611-1418; López-de-Ipiña,
   Diego/0000-0001-8055-6823; Orduna, Pablo/0000-0003-4024-3624
FU Department of Education, Language policy and Culture of the Basque
   Government
FX This work has received financial support by the Department of Education,
   Language policy and Culture of the Basque Government through a
   Predoctoral Scholarship granted to Luis Rodriguez-Gil.
CR [Anonymous], 2015, LAT LIV NETW VID SUR
   [Anonymous], P 1 ACM INT HLTH INF
   [Anonymous], RFC2326 IETF
   [Anonymous], 2011, Proc. second annu. acm conf. multimed. syst.-mmsys'11, DOI DOI 10.1145/1943552.1943574
   [Anonymous], 1993, Usability Engineering
   [Anonymous], 2016, HTML5 SPECIFICATION
   [Anonymous], 2015, TECH REP
   [Anonymous], 2016, YOUTUBE NOW DEFAULTS
   Bankoski J, 2011, TECH REP
   Claypool M., 2014, Network and Systems Support for Games (NetGames), 2014 13th Annual Workshop on, P1, DOI DOI 10.1109/NETGAMES.2014.7008964
   Cozzolino A, 2012, LECT NOTES COMPUT SC, V7517, P142, DOI 10.1007/978-3-642-33140-4_13
   de Jong T, 2013, SCIENCE, V340, P305, DOI 10.1126/science.1230579
   Deshpande H, 2001, TECH REP
   Fielding R., 1999, RFC2616
   Garcia-Zubia J, 2008, 8TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P620, DOI 10.1109/ICALT.2008.303
   García-Zubia J, 2009, IEEE T IND ELECTRON, V56, P4757, DOI 10.1109/TIE.2009.2026368
   Golparvar-Fard M, 2011, AUTOMAT CONSTR, V20, P1143, DOI 10.1016/j.autcon.2011.04.016
   Grange A., 2016, TECH REP
   Grois D, 2013, PICT COD SYMP, P394, DOI 10.1109/PCS.2013.6737766
   Harward VJ, 2008, P IEEE, V96, P931, DOI 10.1109/JPROC.2008.921607
   Hashemian R, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MICROELECTRONIC SYSTEMS EDUCATION, PROCEEDINGS, P139, DOI 10.1109/MSE.2007.43
   Hei XJ, 2007, IEEE T MULTIMEDIA, V9, P1672, DOI 10.1109/TMM.2007.907451
   International Organization for Standarization (ISO); International Electrotechnical Commission (IEC); Institute of Electrical and Electronics Engineers (IEEE), 2015, TECH REP
   ITU, 2016, ITU T RECOMMENDATION
   Jara CA, 2008, COMPUT-AIDED CHEM EN, V25, P1193
   Kim K, 2016, MOB INF SYST, V2016, P1, DOI 10.1155/2016/3727865
   Ma J, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1132960.1132961
   Martínez-Pieper G, 2016, INT CONF REMOT ENGIN, P159, DOI 10.1109/REV.2016.7444457
   Nedic Zorica, 2003, ASEE IEEE FRONT ED C, V33, P1, DOI DOI 10.1109/FIE.2003.1263343
   Nishantha D, 2004, 24TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, PROCEEDINGS, P64, DOI 10.1109/ICDCSW.2004.1284010
   Orduña P, 2014, COMPUT HUM BEHAV, V30, P389, DOI 10.1016/j.chb.2013.04.029
   Quax P, 2016, MULTIMED TOOLS APPL, V75, P4383, DOI 10.1007/s11042-015-2481-0
   Rodriguez-Gil L, 2014, INT CONF REMOT ENGIN, P163, DOI 10.1109/REV.2014.6784245
   Salkintzis AK, 2005, EMERGING WIRELESS MULTIMEDIA SERVICES AND TECHNOLOGIES, P1, DOI 10.1002/0470021519
   Schauer F., 2009, INNOVATIONS 2009 US, V2009, P109
   Schauer F, 2014, INT CONF REMOT ENGIN, P268, DOI 10.1109/REV.2014.6784273
   Shea R, 2013, IEEE NETWORK, V27, P16, DOI 10.1109/MNET.2013.6574660
   Soares J., 2011, 7 PORT M REC SYST, P95
   Sripanidkulchai K, 2004, ACM SIGCOMM COMP COM, V34, P107, DOI 10.1145/1030194.1015480
   Tan WL, 2008, IEEE T MOBILE COMPUT, V7, P737, DOI 10.1109/TMC.2007.70788
   Ueberheide M, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1031, DOI 10.1145/2733373.2806394
   Van Lancker W, 2012, MULTIMED TOOLS APPL, V57, P243, DOI 10.1007/s11042-011-0785-2
   Vargas H, 2013, INT J COMPUT COMMUN, V8, P622, DOI 10.15837/ijccc.2013.4.42
   Wang Bolun., 2016, Proceedings of the 2016 ACM on Internet Measurement Conference, P485
   Webgl specification, 2014, TECH REP
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yazidi A, 2011, IEEE T IND ELECTRON, V58, P4950, DOI 10.1109/TIE.2011.2109331
   Zhang C., 2015, ACM Workshop on Network and Operating Systems Support for Digital Audio and Video, P55, DOI DOI 10.1145/2736084.2736091
NR 48
TC 20
Z9 21
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6471
EP 6502
DI 10.1007/s11042-017-4556-6
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700003
DA 2024-07-18
ER

PT J
AU Kumar, M
   Tripathi, R
   Tiwari, S
AF Kumar, Manish
   Tripathi, Rajeev
   Tiwari, Sudarshan
TI QoS guarantee towards reliability and timeliness in industrial wireless
   sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Industrial wireless sensor networks; QoS; Real-time; Reliability;
   Routing protocol
ID ENERGY; PROTOCOL
AB Wireless Sensor Networks is a promising technology for industrial monitoring and process control. In industry the sensory measures should be delivered to control room in predefined deadline time. The reliable delivery of sensory measure degrades as the focus shift from wired domain to wireless domain. This happens due to unreliability of sensor node and communication link. Therefore, the adverse industrial environment condition posed great stress towards designing of an efficient and effective routing protocol that can ensure the quality of service by reliable and timeliness delivery of real-time data. This paper presents a new geographical routing protocol that works on the basis of two-hop neighbor information. This improves end-to-end packet delivery by minimizing the path setup and recovery latency to ensure the reliability and timeliness. It selects the reliable relay node by mapping packet deadline time to link velocity in such a way that the smaller deadline time packets follow the shorter path over the high speed, reliable links and larger deadline time packets follow path over energy efficient nodes. This process enhances the network life and maintains the shorter path for time critical data routing. This real-time data routing suffers when a forwarding node fails to access the potential relay node. Here, the transmission energy regulation mechanism support to accessing the potential relay node for improving the reliability and timeliness data delivery. The simulation results validate the claim that the proposed routing protocol achieves significant improvement in end-to-end deadline packet delivery ratio with the higher energy efficiency.
C1 [Kumar, Manish; Tripathi, Rajeev] MNNIT Allahabad, ECED, Allahabad, Uttar Pradesh, India.
   [Tiwari, Sudarshan] NIT Raipur, Raipur, Madhya Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology; National Institute of Technology (NIT System);
   National Institute of Technology Raipur
RP Kumar, M (corresponding author), MNNIT Allahabad, ECED, Allahabad, Uttar Pradesh, India.
EM rel1101@mnnit.ac.in; rt@mnnit.ac.in; stiwari@mnnit.ac.in
OI Tripathi, Rajeev/0000-0002-5929-095X; KUMAR, MANISH/0000-0002-5963-6594
CR Akkaya K., 2005, Ad Hoc Networks, V3, P325, DOI 10.1016/j.adhoc.2003.09.010
   Akkaya K, 2003, 23RD INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, P710
   Al-Rousan M, 2009, INT J DISTRIB SENS N, V5, P806, DOI 10.1080/15501320903048647
   Ammari H.M., 2005, PROC ACMIEEE MSWIM, P126
   [Anonymous], 2006, P802154AD4 IEEE IEEE
   [Anonymous], 2003, Proceedings of the 1st international conference on Embedded networked sensor systems, DOI DOI 10.1145/958491.958494
   Bao L., 2002, P MOBICOM, P48
   Boughanmi N, 2008, J SIGNAL PROCESS SYS, V51, P137, DOI 10.1007/s11265-007-0102-5
   Calinescu G, 2003, LECT NOTES COMPUT SC, V2865, P175
   Chipara O, 2006, INT WORKSH QUAL SERV, P83, DOI 10.1109/IWQOS.2006.250454
   Christin D, 2010, FUTURE INTERNET, V2, P96, DOI 10.3390/fi2020096
   Chung Shue Chen, 2008, 2008 Third International Conference on Communications and Networking in China (CHINACOM), P376, DOI 10.1109/CHINACOM.2008.4685045
   Ebeling C.E., 2004, INTRO RELIABILITY MA
   Felemban E, 2006, IEEE T MOBILE COMPUT, V5, P738, DOI 10.1109/TMC.2006.79
   Gungor VC, 2013, IND ELECTR SERIES, P1
   Gungor VC, 2009, IEEE T IND ELECTRON, V56, P4258, DOI 10.1109/TIE.2009.2015754
   He T, 2005, IEEE T PARALL DISTR, V16, P995, DOI 10.1109/TPDS.2005.116
   Heo J, 2006, LECT NOTES COMPUT SC, V3994, P946
   Jung JinWoo., 2010, Communications Workshops (ICC), 2010 IEEE International Conference on, P1
   Karp B., 2000, P 6 ANN INT C MOB CO
   Krogmann M., 2011, T ISRN COMMUNICATION, V2011, P1
   Kumar M., 2014, P 3 IEEE INT C POW C, P166
   Kumar M, 2013, 2013 4TH IEEE INTERNATIONAL CONFERENCE ON COMPUTER & COMMUNICATION TECHNOLOGY (ICCCT), P228, DOI 10.1109/ICCCT.2013.6749632
   Li YJ, 2009, IEEE T IND INFORM, V5, P113, DOI 10.1109/TII.2009.2017938
   Mahapatra A, 2006, COMPUT COMMUN, V29, P437, DOI 10.1016/j.comcom.2004.12.028
   Pham TAQ, 2012, IEEE T IND INFORM, V8, P61, DOI 10.1109/TII.2011.2174249
   Pister K., 2009, Industrial routing requirements in low-power and lossy networks
   Pöttner WB, 2014, ACM T SENSOR NETWORK, V10, DOI 10.1145/2494528
   Polastre J., 2004, SenSys '04, P95, DOI [DOI 10.1145/1031495.1031508, 10.1145/1031495.1031508]
   Stojmenovic I, 2005, WILEY SER PARA DIST, P1
   Surjeet A., 2013, COMMUNICATIONS NETWO, V5, P1
NR 31
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4491
EP 4508
DI 10.1007/s11042-017-4832-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500026
DA 2024-07-18
ER

PT J
AU Li, ZC
   Jia, R
   Gan, SY
AF Li, Zhichao
   Jia, Ru
   Gan, Siyun
TI Evolution of condensed subgroup of political participation based on
   mobile phone
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Political participation; Mobile phone; Cohesive subgroups; Evolution;
   Markov chain
ID SOCIAL NETWORKING; ONLINE WORLD; INTERNET; ASSOCIATIONS; EXPRESSION;
   BEHAVIOR; YOUTH
AB In this paper, a comprehensive numerical study that investigates the evolutionary process of condensed subgroup in political participation based on mobile phone was carried out, putting forward the conception of "condensed subgroup cardinality" considering that it is a finite Markov chain. Then a mathematical model was constructed which allows us to depict the evolutionary process of condensed subgroup and analyze a public media forum based on mobile phone with accuracy. The numerical result demonstrates the usability of this model in predicting the evolutionary process of virtual condensed subgroup based on mobile phone. Analyses on the evolutionary mechanism of condensed subgroup were also given and finally a preliminary stochastic differential equation was advanced to describe it.
C1 [Li, Zhichao; Jia, Ru; Gan, Siyun] Univ Elect Sci & Technol China, Sch Polit Sci & Publ Adm, Chengdu, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Li, ZC (corresponding author), Univ Elect Sci & Technol China, Sch Polit Sci & Publ Adm, Chengdu, Sichuan, Peoples R China.
EM yizhiqingcao@163.com; jiaru0131@163.com; cicigansiyun@sina.com
RI chellali, ryad/KLC-5875-2024
OI chellali, ryad/0000-0003-3395-2254
FU Key Research Bases Program of Social Science Research of Sichuan
   Province, China; Fundamental Research Funds for the Central Universities
   [ZYGX2014J110]
FX The work was supported by Key Research Bases Program of Social Science
   Research of Sichuan Province, China, and "the Fundamental Research Funds
   for the Central Universities" (No. ZYGX2014J110).
CR Bode L, 2014, J COMPUT-MEDIAT COMM, V19, P414, DOI 10.1111/jcc4.12048
   Chamak B, 2008, SOCIOL HEALTH ILL, V30, P76, DOI 10.1111/j.1467-9566.2007.01053.x
   Chi L, 2009, J ORG COMP ELECT COM, V19, P214, DOI 10.1080/10919390903041931
   Freelon DG, 2010, NEW MEDIA SOC, V12, P1172, DOI 10.1177/1461444809357927
   Garcia-Castañon M, 2011, J POLITICAL MARKETIN, V10, P115, DOI 10.1080/15377857.2011.540209
   de Zúñiga HG, 2014, J COMMUN, V64, P612, DOI 10.1111/jcom.12103
   Hyun KD, 2015, INFORM COMMUN SOC, V18, P766, DOI 10.1080/1369118X.2014.994543
   Kramer ADI, 2014, P NATL ACAD SCI USA, V111, P8788, DOI 10.1073/pnas.1320040111
   Krueger BS, 2006, AM POLIT RES, V34, P759, DOI 10.1177/1532673X06290911
   Liu FS, 2012, EUR J CULT STUD, V15, P53, DOI 10.1177/1367549411424950
   Marmura S, 2008, NEW MEDIA SOC, V10, P247, DOI 10.1177/1461444807086469
   Shen F, 2009, INT J PUBLIC OPIN R, V21, P451, DOI 10.1093/ijpor/edp046
   Szell M, 2010, P NATL ACAD SCI USA, V107, P13636, DOI 10.1073/pnas.1004008107
   Yang GB, 2007, CHINA QUART, P122, DOI 10.1017/S030574100600083X
   Zhang SJ, 2008, ASIA PAC J MANAG, V25, P615, DOI 10.1007/s10490-008-9090-7
   Zhang WW, 2010, SOC SCI COMPUT REV, V28, P75, DOI 10.1177/0894439309335162
NR 16
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4271
EP 4282
DI 10.1007/s11042-017-4735-5
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500012
DA 2024-07-18
ER

PT J
AU Rathore, MM
   Ahmad, A
   Paul, A
   Rho, S
AF Rathore, M. Mazhar
   Ahmad, Awais
   Paul, Anand
   Rho, Seungmin
TI Exploiting encrypted and tunneled multimedia calls in high-speed big
   data environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VoIP; Big data; Tunneling; Hadoop; Spark
ID INTERNET
AB Due to the rapid increase in the speed as well as the number of users over the Internet, the rate of data generation is enormously grown. In addition, at the same rate, the multimedia transmission especially the usage of VoIP calls is rapidly growing due to its cost effectiveness, dramatic functionality over the traditional telephone network and its compatibility with public switched telephone network (PSTN). In most of the developing countries, internet service providers (ISPs) and telecommunication authorities are concerned in detecting such calls to either block or prioritize commercial VoIP. Signature-based, port-based, and pattern-based detection techniques are inaccurate due to the complex and confidential security and tunneling mechanisms used by VoIP. Therefore, in this paper, we proposed a generic, robust, efficient statistical analysis-based solution to identify encrypted and tunneled voice media flows. We extracted six statistical parameters, which are extracted for each flow and compared with threshold values while generating a number of rules to identify VoIP media calls. The paper also offers a complete architecture that can efficiently process high-speed traffic in order to detect VoIP flows at real-time. The proposed system, including the architecture and the algorithm, can be practically implemented in a real environment, such as ISP or telecommunication authority's gateway. We implemented the system using the parallel environment of Hadoop ecosystem with Spark on the top of it to achieve the real-time processing. We evaluated the system by considering 1) the accuracy in terms of detection rate by computing the direct rate and false positive rate and 2) the efficiency in terms of processing power. The result shows that the system has 97.54% direct rate and .00015% false positive rate, which are quite high. The comparative study proved that the proposed system is more accurate than the existing techniques.
C1 [Rathore, M. Mazhar; Ahmad, Awais; Paul, Anand] Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu, South Korea.
   [Rho, Seungmin] Sungkyul Univ, Dept Media Software, Anyang, South Korea.
C3 Kyungpook National University; Sungkyul University
RP Paul, A (corresponding author), Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu, South Korea.
EM rathoremazhar@gmail.com; awais.ahmad@live.com; paul.editor@gmail.com;
   smrho@gmail.com
RI Ahmad, Awais/AAA-4504-2019; Paul, Anand/V-6724-2017; Rho,
   Seungmin/HTP-6683-2023
OI Paul, Anand/0000-0002-0737-2021; 
FU Brain Korea 21 Plus project (SW Human Resource Development Program for
   Supporting Smart Life) - Ministry of Education, School of Computer
   Science and Engineering, Kyungpook National University, Korea
   [21A20131600005]
FX This study was supported by the Brain Korea 21 Plus project (SW Human
   Resource Development Program for Supporting Smart Life) funded by
   Ministry of Education, School of Computer Science and Engineering,
   Kyungpook National University, Korea (21A20131600005).
CR Adami D, 2009, 9 INT C SMART SPAC N
   Alshammari R., 2010, 6th International Conference on Network and Service Management (CNSM 2010), P310, DOI 10.1109/CNSM.2010.5691210
   Alshammari R, 2011, COMPUT NETW, V55, P1326, DOI 10.1016/j.comnet.2010.12.002
   [Anonymous], THESIS
   [Anonymous], 2013, INT J COMPUT APPL
   Bandre SR, 2015, 2015 INT C PERV COMP, P1, DOI [10.1109/PERVASIVE.2015.7087201, DOI 10.1109/PERVASIVE.2015.7087201]
   Baset S., 2006, IEEE INT C COMPUTER, P1, DOI DOI 10.1109/INFOCOM.2006.312
   Birke R, 2010, INT J NETW MANAG, V20, P339, DOI 10.1002/nem.758
   BONFIGLIO D., 2008, INFOCOM, P261, DOI [DOI 10.1109/INF0C0M.2008.61, 10.1109/INFOCOM.2008.61, DOI 10.1109/INFOCOM.2008.61]
   Branch P, 2012, 37 IEEE C LOC COMP N
   Dusi M, 2009, COMPUT NETW, V53, P81, DOI 10.1016/j.comnet.2008.09.010
   Feng Lu, 2010, Proceedings of the 2010 International Conference on Electrical and Control Engineering (ICECE 2010), P2964, DOI 10.1109/iCECE.2010.723
   Freire Emanuel P., 2008, IEEE T NETW SERV MAN, V5, P210
   Frey CA, 2015, U.S. Patent No, Patent No. [9,014,034, 9014034]
   Fusco F., 2010, Proceedings of ACM Internet Measurement Conference, P218
   Github, 2016, HAD LIB READ PACK CA
   Idrees F, 2008, INT J COMPUT SCI NET, V8, P52
   Jeong H. J., 2012, 2012 15th International Conference on Network-Based Information Systems (NBiS 2012), P766, DOI 10.1109/NBiS.2012.139
   Jun L, 2007, CIS: 2007 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, PROCEEDINGS, P37, DOI 10.1109/CIS.2007.81
   Leung CM, 2007, WET ICE 2007: 16TH IEEE INTERNATIONAL WORKSHOPS ON ENABLING TECHNOLOGIES: INFRASTRUCTURE FOR COLLABORATIVE ENTERPRISES, PROCEEDINGS, P401
   Li B., 2010, JOURNAL OF NETWORK A, V19, P111
   Li Bing, 2010, 2010 INT C WIR COMM, P1
   Lin YD, 2009, J NETW COMPUT APPL, V32, P1023, DOI 10.1016/j.jnca.2009.03.001
   Maiolini G, 2009, J INF ASSUR SECUR, V4, P142
   Nguyen TTT, 2008, IEEE ICC, P5857, DOI 10.1109/ICC.2008.1095
   ofcom, 2016, COMM MARK REP 2016 B
   Okabe T, 2006, VOIP MASE 06: 1ST IEEE WORKSHOP ON VOIP MANAGEMENT AND SECURITY, P35
   Paul A, 2016, IEEE WIREL COMMUN, V23, P68, DOI 10.1109/MWC.2016.7721744
   Perenyi M., 2007, ValueTools '07: Proceedings of the 2nd international conference on Performance evaluation methodologies and tools, P1
   Rathore MM, 2016, J SUPERCOMPUT, V72, P3489, DOI 10.1007/s11227-015-1615-5
   Renals P, 2009, 42 ANN HAW INT C SYS
   Rossi D, 2008, P 7 INT C PEER TO PE
   Sagiroglu S, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS (CTS), P42
   Tstate, 2016, SKYP TRAC
   Wireshark, 2016, SAMPLECAPTURES
   Wu XD, 2014, IEEE T KNOWL DATA EN, V26, P97, DOI 10.1109/TKDE.2013.109
   Yildirim T, 2010, INT C EL INF ENG ICE
   Yildirim T, 2010, INT CONF ADV COMMUN, P1029
NR 38
TC 13
Z9 13
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4959
EP 4984
DI 10.1007/s11042-017-4393-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500049
DA 2024-07-18
ER

PT J
AU Rui, LL
   Yang, SJ
   Huang, HQ
AF Rui, Lanlan
   Yang, Suijia
   Huang, Haoqiu
TI A producer mobility support scheme for real-time multimedia delivery in
   named data networking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Named data networking; Producer mobility; Seamless delivery; Handover
ID PREDICTION
AB Named Data Networking (NDN) is a network architecture for the Future Internet, and can cooperate with the Internet of Things (IoT) to tackle problems existing in the current IP/TCP network architecture. Its consumer-driven paradigm and generic cache could optimize content distribution performance. However, there are still some problems to be dealt with, including mobility support of the producer. This paper proposes a producer mobility support scheme in NDN specifically for real-time multimedia delivery scenarios to reduce handover delay and to improve consumer experience with bounded overhead. Complementary components are designed based on forwarding information bases and packets in the original NDN. In particular, we categorize scenarios into two types according to cache state, and handle them with different strategies. Results of numerical analysis show that our scheme outperforms the original NDN and some typical solutions on delay with bounded overhead.
C1 [Rui, Lanlan; Yang, Suijia; Huang, Haoqiu] Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, 10 Xitucheng Rd, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Rui, LL (corresponding author), Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, 10 Xitucheng Rd, Beijing, Peoples R China.
EM llrui@bupt.edu.cn; yangsuijia@bupt.edu.cn; francesco@bupt.edu.cn
FU National Natural Science Foundation of China [61302078, 61372108]; 863
   Program [2011AA01A102]; National ST Major Project [2011ZX 03005-004-02];
   China Postdoctoral Science Foundation [2017 M610827]
FX The work presented in this paper was supported by the National Natural
   Science Foundation of China (61302078, 61372108), 863 Program
   (2011AA01A102), National S&T Major Project (2011ZX 03005-004-02), and
   China Postdoctoral Science Foundation funded Project 2017 M610827.
CR Abu-Ghazaleh H, 2010, IEEE T VEH TECHNOL, V59, P788, DOI 10.1109/TVT.2009.2037507
   [Anonymous], 2016, NDN0037
   [Anonymous], 2016, CISC VIS NETW IND GL
   De Brito Gabriel M., 2013, Information-centric Networks: A New Paradigm for the Internet
   Ge J., 2015, PEER TO PEER NETWORK, P1
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Hermans F., 2012, PROC 1 ACMWORKSHOP E, P13, DOI 10.1145/2248361.2248366
   Hermans F, 2011, P SNCNW 2011
   Kim DH, 2015, INT J COMMUN SYST, V28, P1151, DOI 10.1002/dac.2752
   Kim Do-hyung., 2012, Proceedings of the second edition of the ICN workshop on Information-centric networking, P13
   Lee J, 2012, IEEE COMMUN MAG, V50, P28, DOI 10.1109/MCOM.2012.6384448
   Rao Y, 2014, CHINA COMMUN, V11, P111, DOI 10.1109/CC.2014.6827573
   Samaan N, 2005, IEEE ICC, P1413
   Zhang L, 2010, TRANSPORT RES REC, V1892, P227
NR 14
TC 14
Z9 14
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4811
EP 4826
DI 10.1007/s11042-017-5601-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500041
DA 2024-07-18
ER

PT J
AU Yang, XJ
   Liu, G
   Yu, Q
   Wang, R
AF Yang, Xiaojun
   Liu, Gang
   Yu, Qiang
   Wang, Rong
TI Stable and orthogonal local discriminant embedding using trace ratio
   criterion for dimensionality reduction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Trace ratio criterion; Manifold learning; Dimensionality reduction;
   Diversity
ID PRESERVING PROJECTIONS
AB Stable orthogonal local discriminant embedding (SOLDE) is a recently proposed dimensionality reduction method, in which the similarity, diversity and interclass separability of the data samples are well utilized to obtain a set of orthogonal projection vectors. By combining multiple features of data, it outperforms many prevalent dimensionality reduction methods. However, the orthogonal projection vectors are obtained by a step-by-step procedure, which makes it computationally expensive. By generalizing the objective function of the SOLDE to a trace ratio problem, we propose a stable and orthogonal local discriminant embedding using trace ratio criterion (SOLDE-TR) for dimensionality reduction. An iterative procedure is provided to solve the trace ratio problem, due to which the SOLDE-TR method is always faster than the SOLDE. The projection vectors of the SOLDE-TR will always converge to a global solution, and the performances are always better than that of the SOLDE. Experimental results on two public image databases demonstrate the effectiveness and advantages of the proposed method.
C1 [Wang, Rong] NorthwesternW Polytech Univ, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China.
   [Yang, Xiaojun] Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Guangdong, Peoples R China.
   [Liu, Gang; Yu, Qiang] Xian Res Inst Hitech, Xian 710025, Shaanxi, Peoples R China.
C3 Guangdong University of Technology; Rocket Force University of
   Engineering
RP Wang, R (corresponding author), NorthwesternW Polytech Univ, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China.
EM wangrong07@tsinghua.org.cn
RI Liu, Gang/AAU-3119-2020; Lu, Rui/KCJ-8212-2024; Wang, Rong/JQI-7854-2023
OI Liu, Gang/0000-0002-0489-2638; Wang, Rong/0009-0009-5350-5743
FU National Natural Science Foundation of China [61401471, 61501471];
   General Financial from the China Postdoctoral Science Foundation
   [2014M552589]; Special Financial from the China Postdoctoral Science
   Foundation [2015T81114]
FX This paper is supported by National Natural Science Foundation of China
   (No. 61401471 and No. 61501471); General Financial from the China
   Postdoctoral Science Foundation (No. 2014M552589) and Special Financial
   from the China Postdoctoral Science Foundation (No. 2015T81114).
CR [Anonymous], AAAI
   [Anonymous], 2007, IJCAI
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Benmokhtar R, 2013, INT CONF ACOUST SPEE, P2425, DOI 10.1109/ICASSP.2013.6638090
   Boughnim N, 2013, INT CONF ACOUST SPEE, P1971, DOI 10.1109/ICASSP.2013.6637998
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   DUCHENE J, 1988, IEEE T PATTERN ANAL, V10, P978, DOI 10.1109/34.9121
   Gao QX, 2013, IEEE T IMAGE PROCESS, V22, P2521, DOI 10.1109/TIP.2013.2249077
   Guo YF, 2003, PATTERN RECOGN LETT, V24, P147, DOI 10.1016/S0167-8655(02)00207-6
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Jia YQ, 2009, IEEE T NEURAL NETWOR, V20, P729, DOI 10.1109/TNN.2009.2015760
   Li BN, 2016, IEEE T CYBERNETICS, V46, P2543, DOI 10.1109/TCYB.2015.2479645
   Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852
   Luo MN, 2018, IEEE T CYBERNETICS, V48, P648, DOI 10.1109/TCYB.2017.2647904
   Parisotto E, 2015, INT CONF ACOUST SPEE, P847, DOI 10.1109/ICASSP.2015.7178089
   Wang H., 2007, P 2007 IEEE C COMPUT, P1
   Wang HX, 2014, IEEE T CYBERNETICS, V44, P828, DOI 10.1109/TCYB.2013.2273355
   Wang R, 2017, IEEE T IMAGE PROCESS, V26, P5019, DOI 10.1109/TIP.2017.2726188
   Wang SJ, 2011, NEUROCOMPUTING, V74, P3654, DOI 10.1016/j.neucom.2011.07.007
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Zhang TH, 2010, IEEE T SYST MAN CY B, V40, P253, DOI 10.1109/TSMCB.2009.2027473
   Zoidi Olga, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6019, DOI 10.1109/ICASSP.2014.6854759
NR 26
TC 18
Z9 18
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3071
EP 3081
DI 10.1007/s11042-017-5022-1
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600009
DA 2024-07-18
ER

PT J
AU Amiri, SA
   Hassanpour, H
   Marouzi, OR
AF Amiri, Sekineh Asadi
   Hassanpour, Hamid
   Marouzi, Omid Reza
TI No-reference image quality assessment based on localized discrete cosine
   transform for JPEG compressed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE No-reference; Image quality assessment; Blockiness; Jpeg
ID NATURAL SCENE STATISTICS; BLOCKING ARTIFACTS; BLIND MEASUREMENT;
   INFORMATION
AB In this paper, we propose a new no-reference image quality assessment for JPEG compressed images. In contrast to the most existing approaches, the proposed method considers the compression processes for assessing the blocking effects in the JPEG compressed images. These images have blocking artifacts in high compression ratio. The quantization of the discrete cosine transform (DCT) coefficients is the main issue in JPEG algorithm to trade-off between image quality and compression ratio. When the compression ratio increases, DCT coefficients will be further decreased via quantization. The coarse quantization causes blocking effect in the compressed image. We propose to use the DCT coefficient values to score image quality in terms of blocking artifacts. An image may have uniform and non-uniform blocks, which are respectively associated with the low and high frequency information. Once an image is compressed using JPEG, inherent non-uniform blocks may become uniform due to quantization, whilst inherent uniform blocks stay uniform. In the proposed method for assessing the quality of an image, firstly, inherent non-uniform blocks are distinguished from inherent uniform blocks by using the sharpness map. If the DCT coefficients of the inherent non-uniform blocks are not significant, it indicates that the original block was quantized. Hence, the DCT coefficients of the inherent non-uniform blocks are used to assess the image quality. Experimental results on various image databases represent that the proposed blockiness metric is well correlated with the subjective metric and outperforms the existing metrics.
C1 [Amiri, Sekineh Asadi; Hassanpour, Hamid; Marouzi, Omid Reza] Shahrood Univ Technol, Fac Comp Engn & IT, Shahrood, Iran.
C3 Shahrood University of Technology
RP Hassanpour, H (corresponding author), Shahrood Univ Technol, Fac Comp Engn & IT, Shahrood, Iran.
EM h.hassanpour@shahroodut.ac.ir
RI Amiri, Sekineh Asadi/AAI-7676-2021; Hassanpour, Hamid/AAL-7271-2020
OI Hassanpour, Hamid/0000-0002-5513-9822
CR [Anonymous], 2005, SUBJECTIVE QUALITY A
   Bailey D., 2001, TYRRH INT WORKSH DIG, P237
   Bovik AC, 2001, INT CONF ACOUST SPEE, P1725, DOI 10.1109/ICASSP.2001.941272
   Chen CH, 2010, LECT NOTES COMPUT SC, V6297, P112, DOI 10.1007/978-3-642-15702-8_11
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Golestaneh S. Alireza, 2014, IEEE Signal Processing Letters, V21, P155, DOI 10.1109/LSP.2013.2296038
   Hassen R, 2010, INT CONF ACOUST SPEE, P2434, DOI 10.1109/ICASSP.2010.5496297
   Joshi P, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P755, DOI 10.1109/SPIN.2014.6777055
   Jridi M., 2013, REAL TIME IMAGE VIDE, V8656, P1
   Khosravi MH, 2017, MULTIMED TOOLS APPL, V76, P2733, DOI 10.1007/s11042-015-3149-5
   Larson C., 2009, CATEGORICAL IMAGE QU
   Liu DB, 2009, INT WORK QUAL MULTIM, P75, DOI 10.1109/QOMEX.2009.5246974
   Liu HT, 2010, IEEE T CIRC SYST VID, V20, P529, DOI 10.1109/TCSVT.2009.2035848
   Liu H, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/263540
   Manap RA, 2015, INFORM SCIENCES, V301, P141, DOI 10.1016/j.ins.2014.12.055
   Marziliano P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P57, DOI 10.1109/ICIP.2002.1038902
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Pan F, 2007, MULTIDIM SYST SIGN P, V18, P297, DOI 10.1007/s11045-006-0008-6
   Park CS, 2007, J MATH IMAGING VIS, V28, P279, DOI 10.1007/s10851-007-0019-4
   Perrier C, 2005, I C DIELECT LIQUIDS, P389
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Shaked D, 2005, IEEE IMAGE PROC, P841
   Sheikh H. R., 2004, IMAGE VIDEO QUALITY
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Singh J, 2011, AEU-INT J ELECTRON C, V65, P827, DOI 10.1016/j.aeue.2011.01.012
   Vu CT, 2012, IEEE T IMAGE PROCESS, V21, P934, DOI 10.1109/TIP.2011.2169974
   Wu QB, 2015, J VIS COMMUN IMAGE R, V32, P205, DOI 10.1016/j.jvcir.2015.08.009
   Yang JC, 2016, INFORM SCIENCES, V373, P251, DOI 10.1016/j.ins.2016.09.004
   Yang JC, 2015, NEURAL NETWORKS, V71, P45, DOI 10.1016/j.neunet.2015.07.011
   Zhai GT, 2013, PICT COD SYMP, P29, DOI 10.1109/PCS.2013.6737675
   Zhang H, 2008, IEEE WORKSH COMP INT, P1007
   Zhang YH, 2013, NEURAL COMPUT APPL, V22, P3, DOI 10.1007/s00521-011-0740-1
NR 34
TC 4
Z9 4
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 787
EP 803
DI 10.1007/s11042-016-4246-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400033
DA 2024-07-18
ER

PT J
AU Elayeb, B
   Ben Romdhane, W
   Ben Saoud, NB
AF Elayeb, Bilel
   Ben Romdhane, Wiem
   Ben Saoud, Narjes Bellamine
TI Towards a new possibilistic query translation tool for cross-language
   information retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-language information retrieval (CLIR); Query translation;
   Probabilistic model; Possibilistic model; Translation disambiguation
AB Approaches of query translation in Cross-Language Information Retrieval (CLIR) have frequently used dictionaries which suffer from translation ambiguity. Besides, a word-by-word query translation is not sufficient. In this paper, we propose, evaluate and compare a new possibilistic approach for query translation in order to improve the previous dictionary-based ones. This approach uses a probability-to-possibility transformation as a mean to introduce further tolerance in query translation process. Firstly, we identify noun phrases (NPs) in the source query and translate them as units using translation patterns and a language model. Secondly, source query terms which are not included in any selected NPs are translated word-by-word using our new possibilistic approach of single word translation. Indeed, we take into account all query words and their translations when we choose the suitable translation of a given word. We start from the idea that the correct suitable translations of query terms have a tendency to co-occur in the target language documents unlike unsuitable ones. Finally, to increase the coverage of the bilingual dictionary, additional words and their translations are automatically generated from a parallel bilingual corpus. We tested our approach using the French-English parallel text corpus Europarl and the CLEF-2003 French-English CLIR test collection. The reported experiments showed the performance of the probability-to-possibility transformation-based approach compared to the probabilistic one and to some state-of-the-art CLIR tools.
C1 [Elayeb, Bilel] Emirates Coll Technol, Comp Sci, POB 41009, Abu Dhabi, U Arab Emirates.
   [Elayeb, Bilel] Emirates Coll Technol, Coll Res Unit, POB 41009, Abu Dhabi, U Arab Emirates.
   [Elayeb, Bilel; Ben Romdhane, Wiem; Ben Saoud, Narjes Bellamine] Manouba Univ, ENSI, RIADI Res Lab, Manouba 2010, Tunisia.
C3 Universite de la Manouba
RP Elayeb, B (corresponding author), Emirates Coll Technol, Comp Sci, POB 41009, Abu Dhabi, U Arab Emirates.; Elayeb, B (corresponding author), Emirates Coll Technol, Coll Res Unit, POB 41009, Abu Dhabi, U Arab Emirates.; Elayeb, B (corresponding author), Manouba Univ, ENSI, RIADI Res Lab, Manouba 2010, Tunisia.
EM Bilel.Elayeb@riadi.rnu.tn; br.wiem@yahoo.fr;
   narjes.bellamine@ensi.rnu.tn
OI BELLAMINE BEN SAOUD, Narjes/0000-0002-8071-0189; elayeb,
   Bilel/0000-0002-5050-2522
CR Adriani M., 2000, Information Retrieval, V2, P69, DOI 10.1023/A:1009989801965
   Adriani M, 1999, LECT NOTES COMPUT SC, V1696, P311
   Ahmed F, 2012, INT ARAB J INF TECHN, V9, P479
   [Anonymous], THESIS
   [Anonymous], 2013, 2 JOINT C LEXICAL CO
   [Anonymous], P 2 INT C ISL APPL C
   [Anonymous], P CINQ JOURN FRANC O
   [Anonymous], INTELIGENCIA ARTIFIC
   [Anonymous], 2005, Proceedings of the SIGCHI conference on Human factors in computing systems
   [Anonymous], P NTCIR 7 WORKSH M
   [Anonymous], Fuzzy Sets Syst.
   [Anonymous], 2006, ACM TRANSACTION ASIA
   [Anonymous], 1993, FUZZY LOGIC
   [Anonymous], LNCS
   [Anonymous], 2013, P 26 INT FLOR ART IN
   [Anonymous], 2010, Proceedings of the 5th International Workshop on Semantic Evaluation, Association for Computational Linguistics
   Ayed R., 2012, Proceedings of the 2012 13th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel & Distributed Computing (SNPD 2012), P187, DOI 10.1109/SNPD.2012.21
   Ayed R., 2014, P TALN, P316
   Ayed R, 2012, LECT NOTES ARTIF INT, V7390, P274, DOI 10.1007/978-3-642-31576-3_36
   Ballesteros L, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P84, DOI 10.1145/278459.258540
   Ballesteros L, 1996, LECT NOTES COMPUT SC, V1134, P791, DOI 10.1007/BFb0034731
   Ballesteros L., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P64, DOI 10.1145/290941.290958
   Ben Amor N, 2002, INT J UNCERTAIN FUZZ, V10, P117, DOI 10.1142/S0218488502001387
   Ben Khiroun Oussama, 2014, 6th International Conference on Agents and Artificial Intelligence (ICAART 2014). Proceedings, P153
   Ben Khiroun Oussama, 2014, Natural Language Processing and Information Systems. 19th International Conference on Applications of Natural Language to Information Systems, NLDB 2014. Proceedings: LNCS 8455, P168
   Ben Khiroun O., 2012, P ROCLING, P261
   Ben Khiroun O, 2011, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON INTERNET TECHNOLOGIES AND APPLICATIONS (ITA 11), P308
   Ben Romdhane Wiem, 2013, Intelligent Computing Theories and Technology. 9th International Conference, ICIC 2013. Proceedings. LNCS 7996, P73, DOI 10.1007/978-3-642-39482-9_9
   Bounhas Ibrahim, 2011, International Journal of Metadata, Semantics and Ontologies, V6, P81, DOI 10.1504/IJMSO.2011.046578
   Bounhas I, 2015, DATA KNOWL ENG, V100, P240, DOI 10.1016/j.datak.2015.06.008
   Bounhas I, 2015, COMPUT SPEECH LANG, V33, P67, DOI 10.1016/j.csl.2014.12.005
   Bounhas I, 2014, LECT NOTES COMPUT SC, V8841, P792, DOI 10.1007/978-3-662-45563-0_51
   Bounhas I, 2011, KNOWL ORGAN, V38, P473
   Bounhas M, 2014, FUZZY SET SYST, V239, P137, DOI 10.1016/j.fss.2013.07.012
   Bounhas M, 2013, SOFT COMPUT, V17, P733, DOI 10.1007/s00500-012-0947-9
   Capstick J, 2000, INFORM PROCESS MANAG, V36, P275, DOI 10.1016/S0306-4573(99)00058-8
   Chinnakotla MK, 2007, CLEF 2007 WORKSH BUD
   Church K., 1991, Using statistics in lexical analysis, P115
   CIVANLAR MR, 1986, FUZZY SET SYST, V18, P1, DOI 10.1016/0165-0114(86)90024-2
   Clough P, 2004, LECT NOTES COMPUT SC, V2997, P327
   Daille Be<prime>atrice, 1994, THESIS
   Davis M.W., 1997, P 7 TEXT RETRIEVAL C, P385
   De Luca E.W., 2006, P COMB WORKSH LANG E, P17
   DELGADO M, 1987, FUZZY SET SYST, V21, P311, DOI 10.1016/0165-0114(87)90132-1
   DUBOIS D, 1983, FUZZY SET SYST, V10, P15, DOI 10.1016/S0165-0114(83)80099-2
   Dubois D., 2004, Reliable Computing, V10, P273, DOI 10.1023/B:REOM.0000032115.22510.b5
   DUBOIS D, 1992, FUZZY SET SYST, V49, P65, DOI 10.1016/0165-0114(92)90110-P
   Dubois D, 2000, HANDBOOK OF DEFEASIBLE REASONING AND UNCERTAINTY MANAGEMENT SYSTEMS, VOL 4, P231
   DUBOIS D, 1993, SECOND IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1 AND 2, P1059, DOI 10.1109/FUZZY.1993.327367
   DuBois D, 1998, HANDBOOK OF DEFEASIBLE REASONING AND UNCERTAINTY MANAGEMENT SYSTEMS, VOL 1, P169
   Dubois D, 2006, REPRESENTATIONS FORM, V2, P99
   Dubois D., 2009, Decision-Making Process, P85, DOI [DOI 10.1002/9780470611876.CH3, 10.1002/9780470611876.ch3]
   Dubois D, 1987, THEORIE POSSIBILITES
   DUBOIS D, 1994, POSSIBILITY THEORY A
   Dubois D, 2006, COMPUT STAT DATA AN, V51, P47, DOI 10.1016/j.csda.2006.04.015
   Dunning T., 1993, Computational Linguistics, V19, P61
   Elayeb B, 2016, ACM T ASIAN LOW-RESO, V15, DOI 10.1145/2789210
   Elayeb B, 2015, LECT NOTES ARTIF INT, V8946, P280, DOI 10.1007/978-3-319-25210-0_17
   Elayeb B, 2015, KNOWL INF SYST, V44, P91, DOI 10.1007/s10115-014-0753-z
   Elayeb B, 2011, INT J INTELL INF TEC, V7, P1, DOI 10.4018/jiit.2011100101
   Elayeb B, 2009, INTERACT TECHNOL SMA, V6, P40, DOI 10.1108/17415650910965191
   Haouari B, 2009, FUZZY SET SYST, V160, P3224, DOI 10.1016/j.fss.2009.01.009
   Hedlund T, 2004, INFORM RETRIEVAL, V7, P99, DOI 10.1023/B:INRT.0000009442.34054.55
   Hiemstra D, 1999, LECT NOTES COMPUT SC, V1696, P274
   Hull D., 1993, SIGIR Forum, P329
   Hull D. A, 1996, P 19 ANN INT ACM SIG, P46
   HULL D. A., 1997, AAAI S CROSS LANG TE, P84
   Jaynes E. T., 2003, Probability Theory
   Jianfeng Gao, 2001, SIGIR Forum, P96
   Kadri Y., 2004, Proceedings de la conference sur le Traitement Automatique des Langues Naturelles (TALN), P291
   Kadri Y., 2008, The Third International Joint Conference on Natural Language Processing, P181
   Kadri Y., 2007, Proceedings of the Ph.D. Workshop on Information and Knowledge Management (PIKM), P131, DOI DOI 10.1145/1316874.1316896
   Kadri Y., 2006, Conference on Information and Knowledge Management, P818, DOI DOI 10.1145/1183614.1183746
   Kadri Y, 2008, THESIS
   Kadri Youssef., 2006, The Challenge of Arabic for NLP/MT, P68
   Khemakhem Aida, 2013, Natural Language Processing and Information Systems. 18th International Conference on Applications of Natural Language to Information Systems, NLDB 2013. Proceedings: LNCS 7934, P328, DOI 10.1007/978-3-642-38824-8_33
   KLIR GJ, 1990, INT J GEN SYST, V17, P249, DOI 10.1080/03081079008935110
   Koehn Philipp, 2005, P MT SUMM, V5, P79
   Koeling Rob., 2005, Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, P419
   Kwok K.L., 2000, P 5 INT WORKSHOP INF, P173
   Lahbib W, 2014, LECT NOTES COMPUT SC, V8841, P745, DOI 10.1007/978-3-662-45563-0_46
   Levow GA, 2005, INFORM PROCESS MANAG, V41, P523, DOI 10.1016/j.ipm.2004.06.012
   López-Ostenero F, 2003, LECT NOTES COMPUT SC, V2785, P416
   Maisonnasse L, 2008, THESIS
   Nie J.-Y., 1999, P 8 TEXT RETRIEVAL C, P1
   Nie J.-Y., 1998, PROC 7 TEXT RETRIEVA, P482
   Oard DW, 2008, INFORM PROCESS MANAG, V44, P181, DOI 10.1016/j.ipm.2006.12.009
   Ogden C., 2000, P 33 HAW INT C SYST, V3, P3044
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Petrelli D, 2004, J AM SOC INF SCI TEC, V55, P923, DOI 10.1002/asi.20036
   Saad F, 2013, STUD COMPUT INTELL, V458, P219, DOI 10.1007/978-3-642-34399-5_12
   Shinnou H., 2003, P 7 C NAT LANG LEARN, V4, P41
   Smadja F, 1996, COMPUT LINGUIST, V22, P1
   Soudani N, 2014, P CINQ JOURN FRANC O, P309
   Soudani N, 2014, LECT NOTES COMPUT SC, V8842, P655, DOI 10.1007/978-3-662-45550-0_68
   Ture F., 2014, P 2014 C EMP METH NA, P589
   Vossen Piek., 1998, EuroWordNet: A Multilingual Database with Lexical Semantic Networks
   XU J, 2001, UN ARABIC ENGLISH PA
   Xu J., 2002, NIST SPECIAL PUBLICA, P68
   Xu JX, 2000, PROCEEDINGS OF THE 2000 JOINT SIGDAT CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND VERY LARGE CORPORA, P95
   Xun E, 1999, THESIS
   XUN E, 2000, P 38 ANN M ASS COMP
   Yamada K, 2001, JOINT 9TH IFSA WORLD CONGRESS AND 20TH NAFIPS INTERNATIONAL CONFERENCE, PROCEEDINGS, VOLS. 1-5, P70, DOI 10.1109/NAFIPS.2001.944229
   Zouaghi A, 2012, ARTIF INTELL REV, V38, P257, DOI 10.1007/s10462-011-9249-3
NR 104
TC 8
Z9 10
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2423
EP 2465
DI 10.1007/s11042-017-4398-2
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400040
DA 2024-07-18
ER

PT J
AU Jan, F
AF Jan, Farmanullah
TI Pupil localization in image data acquired with near-infrared or visible
   wavelength illumination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eye tracking; Gaze detection; Pupil localization; Iris biometric systems
ID IRIS LOCALIZATION; GAZE TRACKING; SEGMENTATION; EYE; RECOGNITION
AB Pupil localization in human face/eye images has numerous applications, e.g., eye tracking, iris recognition, cataract assessment and surgery, diabetic retinopathy screening, neuropsychiatric disorders diagnosing, and aliveness detection. In real scenario, the pupil localization task suffers from many complications such as pupil's constriction and dilation moments, light reflections, eyelids and eyelashes, and cataract disease. To resolve this issue, this study proposes an accurate and fast pupil localization scheme. It performs relatively well for eyeimages acquired either with the near infrared (NIR) or visible wavelength (VW) illumination. First, it effectively preprocesses the input eyeimage. Next, it coarsely marks pupil location using a scheme comprising an adaptive threshold and two-dimensional (2D) object properties. Then, it validates pupil location via an effective test involving global gray-level statistics. If it finds pupil location invalid, then it localizes pupil through a hybrid of the Hough transform and image global gray-level statistics. Finally, it localizes the fine pupillary boundary through a hybrid of the Fourier series and image's gradients. Its experimental results obtained on numerous publically available iris datasets demonstrate its superiority over most of the contemporary schemes.
C1 [Jan, Farmanullah] COMSATS Inst Informat Technol, Dept Phys, Pk Rd, Islamabad 44000, Pakistan.
C3 COMSATS University Islamabad (CUI)
RP Jan, F (corresponding author), COMSATS Inst Informat Technol, Dept Phys, Pk Rd, Islamabad 44000, Pakistan.
EM farmanullah_jan@comsats.edu.pk
OI Jan, Farmanullah/0000-0002-9118-3652
CR Abdullah Mohammed A. M., 2014, International Journal of Information and Electronics Engineering, V4, P418, DOI 10.7763/IJIEE.2014.V4.476
   Akinci G, 2013, TURK J ELECTR ENG CO, V21, P2367, DOI 10.3906/elk-1204-63
   [Anonymous], 2012, INT J COMPUT APPL
   [Anonymous], J INF HIDING MULTIME
   [Anonymous], 2014, INT J EMERG TECHNOL
   [Anonymous], 2011, INT J COMPUT APPL T
   [Anonymous], FRONT NEUROENG
   [Anonymous], P 19 INT C PATT REC
   [Anonymous], 2014, ADV SCI TECHNOL LETT
   [Anonymous], COMP GRAPH IM PROC S
   Azeem A, 2014, INT ARAB J INF TECHN, V11, P1
   Basit A, 2008, 2008 INTERNATIONAL CONFERENCE ON EMERGING TECHNOLOGIES, PROCEEDINGS, P228, DOI 10.1109/ICET.2008.4777505
   Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540
   Gonzalez R.C., 2018, DIGITAL IMAGE PROCES, V4th
   Jan F, 2017, SIGNAL PROCESS, V133, P192, DOI 10.1016/j.sigpro.2016.11.007
   Jan F, 2014, COMPUT ELECTR ENG, V40, P215, DOI 10.1016/j.compeleceng.2014.05.004
   Jan F, 2012, DIGIT SIGNAL PROCESS, V22, P971, DOI 10.1016/j.dsp.2012.06.001
   Jarjes AA, 2010, INT ASIA CONF INFORM, P349, DOI 10.1109/CAR.2010.5456828
   Krishnamoorthy R., 2013, International Journal of Computer Theory and Engineering, V5, P36, DOI 10.7763/IJCTE.2013.V5.642
   Laddi A, 2017, MULTIMED TOOLS APPL, V76, P7129, DOI 10.1007/s11042-016-3361-y
   Leo M, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.3.033033
   Lin T.C., 2007, International Journal of Computer Sciences and Engineering Systems, V1, P253
   Lin YT, 2013, MULTIMED TOOLS APPL, V65, P543, DOI 10.1007/s11042-012-1202-1
   Lin ZH, 2011, PROCEDIA ENVIRON SCI, V8, P352, DOI 10.1016/j.proenv.2011.10.055
   Marciniak T, 2014, MULTIMED TOOLS APPL, V68, P193, DOI 10.1007/s11042-012-1035-y
   Markus N, 2014, PATTERN RECOGN, V47, P578, DOI 10.1016/j.patcog.2013.08.008
   Masek L., 2003, THESIS CITESEER
   Mohammed GJ, 2010, COMPUT INFORM, V29, P663
   Morimoto CH, 2000, IMAGE VISION COMPUT, V18, P331, DOI 10.1016/S0262-8856(99)00053-0
   Puhan NB, 2011, SIGNAL IMAGE VIDEO P, V5, P105, DOI 10.1007/s11760-009-0146-z
   Radman A, 2013, IET IMAGE PROCESS, V7, P42, DOI 10.1049/iet-ipr.2012.0452
   Roig AB, 2012, OPTIK, V123, P11, DOI 10.1016/j.ijleo.2010.10.049
   Saad Iman A., 2014, Journal of Computer Science, V10, P305, DOI 10.3844/jcssp.2014.305.315
   Skodras E, 2015, SIGNAL PROCESS-IMAGE, V36, P29, DOI 10.1016/j.image.2015.05.007
   Talmi K, 1999, SIGNAL PROCESS-IMAGE, V14, P799, DOI 10.1016/S0923-5965(98)00044-7
   Teo CC, 2010, LECT NOTES COMPUT SC, V6443, P532, DOI 10.1007/978-3-642-17537-4_65
   Wang JZ, 2015, SENSORS-BASEL, V15, P30126, DOI 10.3390/s151229792
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Yuasa M, 2004, IEICE T INF SYST, VE87D, P105
   Zhu DJ, 1999, COMPUT METH PROG BIO, V59, P145, DOI 10.1016/S0169-2607(98)00105-9
NR 41
TC 10
Z9 10
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 1041
EP 1067
DI 10.1007/s11042-016-4334-x
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400044
DA 2024-07-18
ER

PT J
AU Qin, HF
   Chen, ZR
   He, XP
AF Qin, Huafeng
   Chen, Ziran
   He, Xiping
TI Finger-vein image quality evaluation based on the representation of
   grayscale and binary image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Finger-vein verification; Quality assessment; Radon
   transform
ID EXTRACTION
AB In this paper, we propose a novel quality assessment of finger-vein images for quality control in the enrollment and authentication of a finger-vein verification system. First, a Radon transform based model is employed to assess the quality of a finger-vein grayscale image. Second, to assess the quality of a finger-vein binary image, we further proposed three evaluation functions to measure the connectivity, smoothness and reliability of the binary version of the finger-vein image. Finally, the scores from the finer-vein binary images are fused with these from finger-vein grayscale images to improve the performance. Experimental results show that our approach can effectively identify the low quality finger-vein images, which is also helpful in improving the performance of the finger-vein verification system. We also show that instead of choosing the images with the highest quality as the enrollment templates, using the templates with the mid-range quality would achieve better performance with respect to improvement of varication accuracy.
C1 [Qin, Huafeng] Natl Res Base Intelligent Mfg Serv, Xue Fu Rd, Chongqing 400050, Peoples R China.
   [Qin, Huafeng; He, Xiping] Chongqing Technol & Business Univ, Sch Comp Sci & Informat Engn, Chongqing 400067, Peoples R China.
   [Chen, Ziran] Chongqing Univ Technol, Elect Informat & Automat, Chongqing 400050, Peoples R China.
C3 Chongqing Technology & Business University; Chongqing University of
   Technology
RP Qin, HF (corresponding author), Natl Res Base Intelligent Mfg Serv, Xue Fu Rd, Chongqing 400050, Peoples R China.; Qin, HF (corresponding author), Chongqing Technol & Business Univ, Sch Comp Sci & Informat Engn, Chongqing 400067, Peoples R China.
EM huafeng.qin@telecom-sudparise.eu
RI He, Xiping/V-6881-2019; qin, huafeng/AAR-9728-2021
OI He, Xiping/0000-0003-3922-3319; 
FU National Natural Science Foundation of China [61402063]; Natural Science
   Foundation Project of Chongqing [cstc2013kjrc-qnrc40013,
   cstc2014jcyjA1316]; Scientific Research Foundation of Chongqing
   Technology and Business University [1352019, 2013-56-04]
FX This work is supported by the National Natural Science Foundation of
   China(Grant No. 61402063), the Natural Science Foundation Project of
   Chongqing (Grant No. cstc2013kjrc-qnrc40013; Grant No.
   cstc2014jcyjA1316), and the Scientific Research Foundation of Chongqing
   Technology and Business University(Grant No. 1352019; Grant No.
   2013-56-04).
CR Abdel-Mottaleb M, 2007, IEEE COMPUT INTELL M, V2, P10, DOI 10.1109/MCI.2007.353416
   [Anonymous], ADV LARGE MARGIN CLA
   [Anonymous], OPT ENG
   [Anonymous], 1983, The Radon Transform and Some of Its Applications
   Belcher C, 2008, IEEE T INF FOREN SEC, V3, P572, DOI 10.1109/TIFS.2008.924606
   Chang C.C., LIBSVM
   CHEONG WF, 1990, IEEE J QUANTUM ELECT, V26, P2166, DOI 10.1109/3.64354
   Nguyen DT, 2013, KSII T INTERNET INF, V7, P347, DOI 10.3837/tiis.2013.02.010
   Fan H, 2016, MULTIMED TOOLS APPL, P1
   Fronthaler H, 2008, IEEE T INF FOREN SEC, V3, P331, DOI 10.1109/TIFS.2008.920725
   Grother P, 2007, IEEE T PATTERN ANAL, V29, P531, DOI 10.1109/TPAMI.2007.1019
   Hadizadeh H, 2016, IEEE SIGNAL PROC LET, V23, DOI 10.1109/LSP.2016.2617743
   Hashimoto J., 2006, S VLSI CIRC, P5, DOI DOI 10.1109/VLSIC.2006.1705285
   Huang B. N., 2010, 20 INT C PATT REC IC, V2010, P1269
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996
   Jiang XD, 2008, IEEE T PATTERN ANAL, V30, P383, DOI 10.1109/TPAMI.2007.70708
   Kalka ND, 2010, IEEE T SYST MAN CY A, V40, P509, DOI 10.1109/TSMCA.2010.2041658
   Kumar A, 2012, IEEE T IMAGE PROCESS, V21, P2228, DOI 10.1109/TIP.2011.2171697
   Lee EC, 2011, OPT LASER ENG, V49, P816, DOI 10.1016/j.optlaseng.2011.03.004
   Lee S, 2008, IEEE T INF FOREN SEC, V3, P792, DOI 10.1109/TIFS.2008.2007245
   Li C, 2015, NEUROCOMPUTING, V168, P119, DOI 10.1016/j.neucom.2015.06.008
   Li ShaoFei Li ShaoFei, 2011, Water Saving Irrigation, P1
   Li XL, 2016, IEEE T IMAGE PROCESS, V25, P3329, DOI 10.1109/TIP.2016.2568752
   Liu Y, 2016, SIGNAL PROCESS, V125, P237, DOI 10.1016/j.sigpro.2016.01.019
   Lv ZH, 2015, 2015 INTERNATIONAL CONFERENCE ON VIRTUAL REHABILITATION PROCEEDINGS (ICVR), P149, DOI 10.1109/ICVR.2015.7358623
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Lv ZH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057990
   Miura N, 2007, IEICE T INF SYST, VE90D, P1185, DOI 10.1093/ietisy/e90-d.8.1185
   Mulyono D, 2008, 2008 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES, P134
   Peng JL, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P239, DOI 10.1109/IIH-MSP.2014.66
   Proença H, 2011, IEEE T INF FOREN SEC, V6, P82, DOI 10.1109/TIFS.2010.2086446
   Shen L, 2001, LECT NOTES COMPUT SC, V2091, P266
   Yang JC, 2016, INFORM SCIENCES, V373, P251, DOI 10.1016/j.ins.2016.09.004
   Yang JF, 2014, INFORM SCIENCES, V268, P33, DOI 10.1016/j.ins.2013.10.009
   Yongkang Wong, 2011, 2011 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops 2011), P74, DOI 10.1109/CVPRW.2011.5981881
   Zhou YB, 2011, IEEE T INF FOREN SEC, V6, P1259, DOI 10.1109/TIFS.2011.2158423
NR 36
TC 8
Z9 9
U1 0
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2505
EP 2527
DI 10.1007/s11042-016-4317-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400043
DA 2024-07-18
ER

PT J
AU Raman, R
   Choudhury, SK
   Bakshi, S
AF Raman, Rahul
   Choudhury, Suman Kumar
   Bakshi, Sambit
TI Spatiotemporal optical blob reconstruction for object detection in
   grayscale videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Optical flow; Spatiotemporal blob; Optical flow;
   Moving object detection; Video motion analysis; Placodal cell migration
ID BACKGROUND SUBTRACTION; SEGMENTATION; FLOW; TRACKING
AB There has been a significant research devoted towards detection of a moving object in an image sequence. Detected moving objects usually contain some errors (some pixels belonging to the object are marked as non-objects and vice versa). To achieve a refined detection of moving object in the video, there is a need of post processing of the binary blobs detected as objects in every frame of the video. This article introduces a novel blob reconstruction method that overcomes the mentioned limitation through optical flow based nullification, bifurcation, and unification of detected blobs. To claim the performance of the proposed method, a comparison is made with ten widely used object detection methods on twenty four standard moving-object scene videos. Comparison is made based on standard parameters like accuracy, precision, recall, and F-measure. The results clearly indicates the efficacy of the proposed method. Following this, results on a priliminary case study on placodal cell migration during early development of ectodermal organ of human and mice has been made employing the proposed model which promisingly tracks the cell migration.
C1 [Raman, Rahul; Choudhury, Suman Kumar; Bakshi, Sambit] Natl Inst Technol Rourkela, Dept Comp Sci & Engn, Ctr Comp Vis & Pattern Recognit, Odisha 769008, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Bakshi, S (corresponding author), Natl Inst Technol Rourkela, Dept Comp Sci & Engn, Ctr Comp Vis & Pattern Recognit, Odisha 769008, India.
EM rahulraman2@gmail.com; sumanchoudhury.nitr@gmail.com;
   bakshisambit@nitrkl.ac.in
RI Bakshi, Sambit/I-5013-2018; raman, rahul/U-6778-2019; Bakshi,
   Sambit/JDC-3355-2023
OI Bakshi, Sambit/0000-0002-6107-114X; Bakshi, Sambit/0000-0002-6107-114X;
   Raman, Rahul/0000-0002-8714-7333
FU Fund for Improvement of S&T Infrastructure in Universities and Higher
   Educational Institutions (FIST) Program, Department of Science and
   Technology, Government of India [ETI/359/2014]
FX The work presented in this article is supported by Grant No.
   ETI/359/2014 by Fund for Improvement of S&T Infrastructure in
   Universities and Higher Educational Institutions (FIST) Program 2016,
   Department of Science and Technology, Government of India.
CR [Anonymous], P IEEE C COMPUTER VI
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Correia P, 2000, IEEE IMAGE PROC, P308, DOI 10.1109/ICIP.2000.900956
   El Baf F, 2008, IEEE INT CONF FUZZY, P1731
   Erdem ÇE, 2004, IEEE T IMAGE PROCESS, V13, P937, DOI 10.1109/TIP.2004.828427
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Haritaoglu I, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P222, DOI 10.1109/AFGR.1998.670952
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Jacques JCS, 2005, SIBGRAPI 2005: XVIII BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, CONFERENCE PROCEEDINGS, P189
   Jung CR, 2009, IEEE T MULTIMEDIA, V11, P571, DOI 10.1109/TMM.2009.2012924
   KaewTraKulPong P, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P135
   Kim W, 2012, IEEE SIGNAL PROC LET, V19, P127, DOI 10.1109/LSP.2011.2182648
   KOLLER D, 1994, INT C PATT RECOG, P126, DOI 10.1109/ICPR.1994.576243
   Li L, 2003, ICCAD-2003: IEEE/ACM DIGEST OF TECHNICAL PAPERS, P2
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   McKenna SJ, 1999, IMAGE VISION COMPUT, V17, P225, DOI 10.1016/S0262-8856(98)00104-8
   Nair D, 1998, IEEE T ROBOTIC AUTOM, V14, P404, DOI 10.1109/70.678450
   Reddy V, 2013, IEEE T CIRC SYST VID, V23, P83, DOI 10.1109/TCSVT.2012.2203199
   Rodríguez P, 2013, IEEE IMAGE PROC, P69, DOI 10.1109/ICIP.2013.6738015
   Seki M, 2000, FIFTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P207, DOI 10.1109/WACV.2000.895424
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   THOMPSON WB, 1985, IEEE T PATTERN ANAL, V7, P374, DOI 10.1109/TPAMI.1985.4767677
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Weickert J, 2001, J MATH IMAGING VIS, V14, P245, DOI 10.1023/A:1011286029287
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Yao Q, 2013, BIOSYST ENG, V114, P67, DOI 10.1016/j.biosystemseng.2012.11.008
   Zhou T., 2011, P 28 INT C MACHINE L, P33
NR 30
TC 6
Z9 6
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 741
EP 762
DI 10.1007/s11042-016-4234-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400031
DA 2024-07-18
ER

PT J
AU Wei, SK
   Zhao, Y
   Yang, T
   Zhou, ZL
   Ge, SM
AF Wei, Shikui
   Zhao, Yao
   Yang, Tao
   Zhou, Zhili
   Ge, Shiming
TI Enhancing heterogeneous similarity estimation via neighborhood
   reversibility
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neighbourhood reversibility verifying; Multi-modal retrieval; Adaptive
   strategy
ID IMAGE; CLASSIFICATION; FRAMEWORK; ALGORITHM
AB With the popularity of social networks, people can easily generate rich content with multiple modalities. How to effectively and simply estimate the similarity of multi-modal content is becoming more and more important for providing better information searching service of rich media. This work attempts to enhance the similarity estimation so as to improve the accuracy of multi-modal data searching. Toward this end, a novel multi-modal feature extraction approach, which involves the neighborhood reversibility verifying of information objects with different modalities, is proposed to build reliable similarity estimation among multimedia documents. By verifying the neighborhood reversibility in both single- and multi-modal instances, the reliability of multi-modal subspace can be remarkably improved. In addition, a new adaptive strategy, which fully employs the distance distribution of returned searching instances, is proposed to handle the neighbor selection problem. To further address the out-of-sample problem, a new prediction scheme is proposed to predict the multi-modal features for new coming instances, which is essentially to construct an over-complete set of bases. Extensive experiments demonstrate that introducing the neighborhood reversibility verifying can significantly improve the searching accuracy of multi-modal documents.
C1 [Wei, Shikui; Zhao, Yao; Yang, Tao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Zhou, Zhili] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.
   [Ge, Shiming] Chinese Acad Sci, Inst Informat Engn, Beijing 100093, Peoples R China.
C3 Beijing Jiaotong University; Nanjing University of Information Science &
   Technology; Chinese Academy of Sciences; Institute of Information
   Engineering, CAS
RP Wei, SK (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
EM shkwei@bjtu.edu.cn
FU National Natural Science Foundation of China [61572065, 61532005];
   Ministry of Education of China [MCM20160102]; China Mobile
   [MCM20160102]; Fundamental Research Funds for the Central Universities
   [2015JBM028, 2015JBZ002]
FX This work was supported in part by National Natural Science Foundation
   of China (No. 61572065, No. 61532005), Joint Fund of Ministry of
   Education of China and China Mobile (No. MCM20160102), and Fundamental
   Research Funds for the Central Universities (No. 2015JBM028, No.
   2015JBZ002).
CR [Anonymous], J NONNEWTONIAN FLUID
   Bokhari HU., 2013, International Journal of Computer Applications, V74, P9
   Borlund P, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL (CHIIR'16), P151, DOI 10.1145/2854946.2870648
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Daras P, 2012, IEEE T MULTIMEDIA, V14, P734, DOI 10.1109/TMM.2011.2181343
   Fan J, 2012, PROC VLDB ENDOW, V5, P824, DOI 10.14778/2311906.2311910
   Fu ZJ, 2015, IEICE T COMMUN, VE98B, P190, DOI 10.1587/transcom.E98.B.190
   Gu B, 2015, NEURAL NETWORKS, V67, P140, DOI 10.1016/j.neunet.2015.03.013
   Jegou H, 2010, IEEE T PATTERN ANAL, V32, P2, DOI 10.1109/TPAMI.2008.285
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Kalpathy-Cramer J, 2015, COMPUT MED IMAG GRAP, V39, P55, DOI 10.1016/j.compmedimag.2014.03.004
   Knight PA, 2008, SIAM J MATRIX ANAL A, V30, P261, DOI 10.1137/060659624
   Li YN, 2015, IEEE SIGNAL PROC LET, V22, P2396, DOI 10.1109/LSP.2015.2487824
   Li YJ, 2015, IEEE SIGNAL PROC LET, V22, P2214, DOI 10.1109/LSP.2015.2469297
   Mao X, P 21 ACM INT C MULT, P897
   Masci J, 2014, IEEE T PATTERN ANAL, V36, P824, DOI 10.1109/TPAMI.2013.225
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Ren JF, 2015, IEEE SIGNAL PROC LET, V22, P2373, DOI 10.1109/LSP.2015.2481435
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Shen L, 2015, IEEE T IMAGE PROCESS, V24, P3109, DOI 10.1109/TIP.2015.2438548
   Wang FQ, 2015, IEEE T NEUR NET LEAR, V26, P1950, DOI 10.1109/TNNLS.2014.2361142
   Wang HX, 2014, PROC INT C TOOLS ART, P853, DOI 10.1109/ICTAI.2014.131
   Wang J, ARXIV160406620
   Wang JB, 2015, IEEE SYS MAN CYBERN, P1882, DOI 10.1109/SMC.2015.329
   Wang M, 2009, IEEE T MULTIMEDIA, V11, P465, DOI 10.1109/TMM.2009.2012919
   Wei Y, ACM T INTELL SYST TE, V7, P1
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Wu F, 2006, IEEE IMAGE PROC, P1465, DOI 10.1109/ICIP.2006.312707
   Xia Z, IEEE T PARALLEL DIST
   Xia ZQ, 2015, NEUROCOMPUTING, V147, P500, DOI 10.1016/j.neucom.2014.06.028
   Yang Yi., 2009, Proceedings of the 17th ACM international conference on Multimedia, P175
   Zhang H, 2006, LECT NOTES COMPUT SC, V4261, P979
   Zhang ST, 2015, IEEE T PATTERN ANAL, V37, P803, DOI 10.1109/TPAMI.2014.2346201
   Zhou JL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 36
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 1437
EP 1452
DI 10.1007/s11042-017-4347-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400059
DA 2024-07-18
ER

PT J
AU Jifara, W
   Jiang, F
   Zhang, B
   Wang, HP
   Li, JS
   Grigorev, A
   Liu, SH
AF Jifara, Worku
   Jiang, Feng
   Zhang, Bing
   Wang, Huapeng
   Li, Jinsong
   Grigorev, Aleksei
   Liu, Shaohui
TI Hyperspectral image compression based on online learning spectral
   features dictionary
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral image; Online learning; Spectral clustering; Lossy
   compression; Spectral dictionary
ID LOSSLESS COMPRESSION; JPEG2000
AB This paper proposes a novel method of lossy hyperspectral image compression using online learning dictionary. Spectral dictionary that learned in sparse coding mode could be used to represent the corresponding material. From the perspective of sparse coding, learning a sparse dictionary could achieve a better result of data decorrelation. In order to compress the hyperspectral data, an online learning sparse coding dictionary which could describe the characteristics of spectral curve was created to represent and reconstruct hyperspectral data. In the online learning phase, effective clustering algorithm is applied to generate and update the dictionary more properly. Results indicate that dictionary achieved by our method could improve the compression quality of hyperspectral image observably.
C1 [Jifara, Worku; Jiang, Feng; Grigorev, Aleksei; Liu, Shaohui] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
   [Zhang, Bing] China Elect Technol Grp Corp, Inst 27, Zhengzhou 450000, Henan, Peoples R China.
   [Wang, Huapeng; Li, Jinsong] China Elect Power Res Inst, Beijing 100192, Peoples R China.
C3 Harbin Institute of Technology; China Electronics Technology Group
RP Jiang, F (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
EM fjiang@hit.edu.cn
RI Zhang, Bing/L-8698-2017; Sori, worku Jifara/L-7147-2019; Zhang,
   Hao/HHM-1940-2022; Liu, Shaohui/AAC-3092-2019; Liu,
   shaohui/HKE-1383-2023; li, jinsong/HJH-9559-2023; JIANG,
   Feng/HTP-2862-2023
OI Liu, Shaohui/0000-0002-1810-5412; Jiang, Feng/0000-0001-8342-1211; Sori,
   Worku Jifara/0000-0001-6658-5142
FU MOE-Microsoft Key Laboratory of Natural Language Processing and Speech,
   Harbin Institute of Technology; Major State Basic Research Development
   Program of China (973 Program) [2015CB351804]; National Natural Science
   Foundation of China [61572155, 61672188, 61272386]
FX This work is partially funded by the MOE-Microsoft Key Laboratory of
   Natural Language Processing and Speech, Harbin Institute of Technology,
   the Major State Basic Research Development Program of China (973 Program
   2015CB351804) and the National Natural Science Foundation of China under
   Grant No. 61572155, 61672188 and 61272386. We would also like to
   acknowledge NVIDIA Corporation who kindly provided two sets of GPU.
CR [Anonymous], 2015, HYPERSPECTRAL DATASE
   Bottou L., 2007, ADV NEURAL INFORM PR, V20
   Chen BW, 2013, IEEE T SYST MAN CY-S, V43, P1279, DOI 10.1109/TSMC.2013.2244211
   Chen BW, 2009, IEEE T MULTIMEDIA, V11, P295, DOI 10.1109/TMM.2008.2009703
   Cheng KJ, 2014, IEEE T GEOSCI REMOTE, V52, P5765, DOI 10.1109/TGRS.2013.2292366
   DRAGOTTI PL, 2000, IEEE T GEOSCIENCE RE, V38
   Du Q, 2007, IEEE GEOSCI REMOTE S, V4, P201, DOI 10.1109/LGRS.2006.888109
   Du Q, 2009, IEEE GEOSCI REMOTE S, V6, P713, DOI 10.1109/LGRS.2009.2024175
   Fry TW, 2001, THESIS
   HARSANYI JC, 1994, IEEE T GEOSCI REMOTE, V32, P779, DOI 10.1109/36.298007
   Hong RC, 2014, INFORM SCIENCES, V273, P196, DOI 10.1016/j.ins.2014.03.009
   Hong RC, 2014, IEEE T CYBERNETICS, V44, P669, DOI 10.1109/TCYB.2013.2265601
   Huo C, 2012, EV REM SENS WHISPERS, P1
   Kiely AB, 2009, IEEE T GEOSCI REMOTE, V47, P2672, DOI 10.1109/TGRS.2009.2015291
   Kim BJ, 1997, IEEE DATA COMPR CONF, P251, DOI 10.1109/DCC.1997.582048
   Magli E, 2009, IEEE T GEOSCI REMOTE, V47, P1168, DOI 10.1109/TGRS.2008.2009316
   MALLAT SG, 1989, IEEE T ACOUST SPEECH, V37, P2091, DOI 10.1109/29.45554
   Mielikainen J, 2008, IEEE GEOSCI REMOTE S, V5, P474, DOI 10.1109/LGRS.2008.917598
   Motta G, 2003, DAT COMPR C P DCC 20, P25
   Penna B, 2006, IEEE GEOSCI REMOTE S, V3, P125, DOI 10.1109/LGRS.2005.859942
   Penna B, 2007, IEEE T GEOSCI REMOTE, V45, P1408, DOI 10.1109/TGRS.2007.894565
   Pickering MR, 2001, IEEE T GEOSCI REMOTE, V39, P1536, DOI 10.1109/36.934084
   Rucker JT, 2005, INT GEOSCI REMOTE SE, P128
   Ryan MJ, 1997, IEEE T GEOSCI REMOTE, V35, P546, DOI 10.1109/36.581964
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Yanjun Gong, 2010, 2010 International Conference on Computer and Communication Technologies in Agriculture Engineering (CCTAE 2010), P460, DOI 10.1109/CCTAE.2010.5544324
   Ying H., 2008, NAFIPS 2008 2008 ANN, P1
NR 29
TC 12
Z9 12
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25003
EP 25014
DI 10.1007/s11042-017-4724-8
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300024
DA 2024-07-18
ER

PT J
AU Datta, D
   Singh, SK
   Chowdary, CR
AF Datta, Deepanwita
   Singh, Sanjay K.
   Chowdary, C. Ravindranath
TI Bridging the gap: effect of text query reformulation in multimodal
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal retrieval; Weight learning; Fisher-LDA; Topic model;
   Keyphrase extraction; Query reformulation
AB Multimodal Retrieval provides new paradigms and methods aimed at effectively searching through the enormous volume of data. Multimodal retrieval is a well studied problem often used in image retrieval. Most of the existing works in image retrieval under the pretext of multimodality stress on bridging the semantic gap by using both textual and visual features. In this paper, we use relevance feedback from the user-generated documents associated with the images for expanding textual query and study its effect on both image and text retrieval. We employ a topic decomposition based keyphrase extraction technique to expand the textual queries. Our results articulate the fact that an insightful textual query expansion always improves retrieval performance for both textual or image retrieval. Also, we adopt optimum weight learning scheme to combine the modalities in a privileged way. We perform a comparative study with two well established keyphrase extraction techniques which are used for textual query expansion. A detailed set of experiments on a standard real world dataset is also carried out for the same.
C1 [Datta, Deepanwita; Singh, Sanjay K.; Chowdary, C. Ravindranath] Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Datta, D (corresponding author), Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi, Uttar Pradesh, India.
EM ddatta.rs.cse13@iitbhu.ac.in; sks.cse@iitbhu.ac.in;
   rchowdary.cse@iitbhu.ac.in
RI Singh, Sanjay Kumar/AAC-2031-2022; Chowdary, Ravindranath/AAB-3122-2021;
   Singh, Sanjay Prithviraj/IQV-1492-2023; kumar, Sanjay/ITT-3680-2023;
   Datta, Deepanwita/N-4858-2017
OI Singh, Sanjay Kumar/0000-0002-9061-6313; Chowdary,
   Ravindranath/0000-0002-9590-8446; Singh, Sanjay
   Prithviraj/0000-0001-5043-8762; Datta, Deepanwita/0000-0003-2607-0931
CR [Anonymous], 2009, SEARCH USER INTERFAC, DOI DOI 10.1017/CBO9781139644082
   [Anonymous], P ACM INT C IM VID R
   [Anonymous], 1999, Visual Information Retrieval
   [Anonymous], 2003, P SIGIR
   [Anonymous], 1971, SMART RETRIEVAL SYST
   [Anonymous], 2008, INTRO INFORM RETRIEV, DOI DOI 10.1017/CBO9780511809071
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Buffoni D, 2012, MULTIMED TOOLS APPL, V60, P161, DOI 10.1007/s11042-011-0806-1
   Caicedo JC, 2010, P INT C MULT INF RET, P359
   Carpineto C, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071390
   Choi S, 2015, LECT NOTES COMPUT SC, V9059, P124, DOI 10.1007/978-3-319-24471-6_11
   Datta D, 2017, EXPERT SYST APPL, V68, P81, DOI 10.1016/j.eswa.2016.09.039
   Depeursinge A, 2010, INFORM RETRIEVAL SER, V32, P95, DOI 10.1007/978-3-642-15181-1_6
   Fakhari A, 2013, APPL SOFT COMPUT, V13, P1292, DOI 10.1016/j.asoc.2012.10.019
   Faro Alberto., 2010, Proceedings of the Symposium on Eye-Tracking Research Appli- cations (ETRA), P73, DOI [10.1145/1743666.1743684, DOI 10.1145/1743666.1743684]
   Grineva M., 2009, P 18 INT C WORLD WID, P661, DOI DOI 10.1145/1526709.1526798
   Hochmair H. H., 2006, ANGEW GEOINFORMATIK, V18, P236
   Hoi S. C., 2011, ACM MULTIMEDIA, P817, DOI 10.1145/2072298.2072474.
   Jiji GW, 2015, APPL SOFT COMPUT, V30, P650, DOI 10.1016/j.asoc.2015.01.058
   Joint M, 2004, P SOC PHOTO-OPT INS, V5298, P116, DOI 10.1117/12.525631
   Lisin D, 2005, 2005 IEEE COMP SOC C, P47, DOI [10.1109/CVPR.2005.433, 10/c3854f, DOI 10.1109/CVPR.2005.433]
   Liu Z., 2010, P 2010 C EMP METH NA, P366
   Mihalcea, 2004, P EMNLP, P401, DOI DOI 10.3115/1219044.1219064
   Mitra M., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P206, DOI 10.1145/290941.290995
   Moulin C, 2014, PATTERN RECOGN, V47, P260, DOI 10.1016/j.patcog.2013.06.003
   Myoupo D, 2010, LECT NOTES COMPUT SC, V6242, P177, DOI 10.1007/978-3-642-15751-6_20
   Peng Y, 2015, SCALABLE IMAGE RETRI
   Wang SX, 2015, MULTIMED TOOLS APPL, V74, P2009, DOI 10.1007/s11042-013-1737-9
   Welling M., 2005, Fisher linear discriminant analysis, P3
   Yagcioglu S, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P106
   Zellhofer D., 2012, P 4 INF INT CONT S I, P62, DOI [10.1145/2362724.2362739, DOI 10.1145/2362724.2362739]
   Zhai C, 2001, UNPUB
   Zhao R, 2002, IEEE T MULTIMEDIA, V4, P189, DOI 10.1109/TMM.2002.1017733
   Zhou XS, 2002, IEEE MULTIMEDIA, V9, P23, DOI 10.1109/93.998050
NR 34
TC 2
Z9 2
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22871
EP 22888
DI 10.1007/s11042-016-4262-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200050
DA 2024-07-18
ER

PT J
AU Duta, IC
   Uijlings, JRR
   Ionescu, B
   Aizawa, K
   Hauptmann, AG
   Sebe, N
AF Duta, Ionut C.
   Uijlings, Jasper R. R.
   Ionescu, Bogdan
   Aizawa, Kiyoharu
   Hauptmann, Alexander G.
   Sebe, Nicu
TI Efficient human action recognition using histograms of motion gradients
   and VLAD with descriptor shape information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video classification; Action recognition; Histograms of motion gradients
   (HMG); Shape difference VLAD (SD-VLAD); Computational efficiency;
   Real-time processing
AB Feature extraction and encoding represent two of the most crucial steps in an action recognition system. For building a powerful action recognition pipeline it is important that both steps are efficient and in the same time provide reliable performance. This work proposes a new approach for feature extraction and encoding that allows us to obtain real-time frame rate processing for an action recognition system. The motion information represents an important source of information within the video. The common approach to extract the motion information is to compute the optical flow. However, the estimation of optical flow is very demanding in terms of computational cost, in many cases being the most significant processing step within the overall pipeline of the target video analysis application. In this work we propose an efficient approach to capture the motion information within the video. Our proposed descriptor, Histograms of Motion Gradients (HMG), is based on a simple temporal and spatial derivation, which captures the changes between two consecutive frames. For the encoding step a widely adopted method is the Vector of Locally Aggregated Descriptors (VLAD), which is an efficient encoding method, however, it considers only the difference between local descriptors and their centroids. In this work we propose Shape Difference VLAD (SD-VLAD), an encoding method which brings complementary information by using the shape information within the encoding process. We validated our proposed pipeline for action recognition on three challenging datasets UCF50, UCF101 and HMDB51, and we propose also a real-time framework for action recognition.
C1 [Duta, Ionut C.; Sebe, Nicu] Univ Trento, Trento, Italy.
   [Uijlings, Jasper R. R.] Univ Edinburgh, Edinburgh, Midlothian, Scotland.
   [Ionescu, Bogdan] Univ Politehn Bucuresti, Bucharest, Romania.
   [Aizawa, Kiyoharu] Univ Tokyo, Tokyo, Japan.
   [Hauptmann, Alexander G.] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
C3 University of Trento; University of Edinburgh; National University of
   Science & Technology POLITEHNICA Bucharest; University of Tokyo;
   Carnegie Mellon University
RP Duta, IC (corresponding author), Univ Trento, Trento, Italy.
EM ionutcosmin.duta@unitn.it; jrr.uijlings@ed.ac.uk; bionescu@imag.pub.ro;
   aizawa@hal.t.u-tokyo.ac.jp; alex@cs.cmu.edu; niculae.sebe@unitn.it
RI Sebe, Niculae/KEC-2000-2024; Ionescu, Bogdan/IWU-7778-2023
OI Sebe, Niculae/0000-0002-6597-7248; 
FU project SPOTTER [PN-III-P2-2.1-PED-2016-1065, 30PED/2017]; National
   Science Foundation (NSF) [IIS-1251187]
FX Part of this work was funded under research grant
   PN-III-P2-2.1-PED-2016-1065, agreement 30PED/2017, project SPOTTER. This
   material is based in part on work supported by the National Science
   Foundation (NSF) under grant number IIS-1251187.
CR [Anonymous], 2015, IJCV
   [Anonymous], 2013, ICCV
   [Anonymous], ICCV
   [Anonymous], 2014, CoRR
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   BILEN H, 2016, PROC CVPR IEEE, P3034, DOI [10.1109/CVPR.2016.331, DOI 10.1109/CVPR.2016.331]
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   de Souza Cesar Roberto., 2016, ECCV
   Duta I. C., 2016, ICPR
   Duta I. C., 2016, CBMI
   Duta IC, 2017, MMM
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Horn B. K. P., 1981, Proceedings of the SPIE - The International Society for Optical Engineering, V281, P319, DOI 10.1117/12.965761
   Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   Kantorov V, 2014, PROC CVPR IEEE, P2593, DOI 10.1109/CVPR.2014.332
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kliper-Gross O, 2012, LECT NOTES COMPUT SC, V7577, P256, DOI 10.1007/978-3-642-33783-3_19
   Kuehne H., 2011, P INT C COMP VIS
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Mironica I, 2016, MULTIMED TOOLS APPL
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Park E., 2016, WACV
   Peng XJ, 2014, LECT NOTES COMPUT SC, V8691, P660, DOI 10.1007/978-3-319-10578-9_43
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Poularakis S, 2015, ICIP
   Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Solmaz B, 2013, MACH VIS APPL
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sun Ju., 2009, CVPR
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   Uijlings J., 2014, ICMR
   Uijlings JRR, 2010, IEEE T MULTIMEDIA, V12, P665, DOI 10.1109/TMM.2010.2052027
   Uijlings JRR, 2015, INT J MULTIMED INF R
   Vedaldi A., 2010, ACM Multimedia
   Wang H., 2013, ICCV WORKSH
   Wang H., 2009, BMVC
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11
NR 54
TC 18
Z9 20
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22445
EP 22472
DI 10.1007/s11042-017-4795-6
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200030
DA 2024-07-18
ER

PT J
AU Pimentel, CAF
   Bustos, B
   Araujo, AD
   Guimaraes, SJF
AF Fraga Pimentel Filho, Carlos Alberto
   Bustos, Benjamin
   Araujo, Arnaldo de Albuquerque
   Ferzoli Guimaraes, Silvio Jamil
TI Combining pixel domain and compressed domain index for sketch based
   image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sketch-based image retrieval; Multimedia indexing; Scalability
AB Sketch-based image retrieval (SBIR) lets one express a precise visual query with simple and widespread means. In the SBIR approaches, the challenge consists in representing the image dataset features in a structure that allows one to efficiently and effectively retrieve images in a scalable system. We put forward a sketch-based image retrieval solution where sketches and natural image contours are represented and compared, in both, the compressed-domain of wavelet and in the pixel domain. The query is efficiently performed in the wavelet domain, while effectiveness refinements are achieved using the pixel domain to verify the spatial consistency between the sketch strokes and the natural image contours. Also, we present an efficient scheme of inverted lists for sketch-based image retrieval using the compressed-domain of wavelets. Our proposal of indexing presents two main advantages, the amount of the data to compute the query is smaller than the traditional method while it presents a better effectiveness.
C1 [Fraga Pimentel Filho, Carlos Alberto; Ferzoli Guimaraes, Silvio Jamil] Pontif Catholic Univ Minas Gerais PUC Minas, VIPLAB, Dept Comp Sci, Belo Horizonte, MG, Brazil.
   [Bustos, Benjamin] Univ Chile, Dept Comp Sci, Santiago, Chile.
   [Fraga Pimentel Filho, Carlos Alberto; Araujo, Arnaldo de Albuquerque] Fed Univ Minas Gerais UFMG, Dept Comp Sci NPDI, Belo Horizonte, MG, Brazil.
C3 Pontificia Universidade Catolica de Minas Gerais; Universidad de Chile;
   Universidade Federal de Minas Gerais
RP Guimaraes, SJF (corresponding author), Pontif Catholic Univ Minas Gerais PUC Minas, VIPLAB, Dept Comp Sci, Belo Horizonte, MG, Brazil.
EM arnaldo@dcc.ufmg.br; sjamil@pucminas.br
RI Bustos, Benjamin/G-1170-2010; GUIMARAES, Silvio/C-7881-2014
OI Bustos, Benjamin/0000-0002-3955-361X; GUIMARAES,
   Silvio/0000-0001-8522-2056
FU CAPES/ COFECUB; FAPEMIG [PPM-006-16]; CNPq [307062/2016-3]; PUC Minas
FX The authors are grateful to CAPES/ COFECUB, FAPEMIG (PPM-006-16), CNPq
   (307062/2016-3) and PUC Minas for the financial support to this work.
CR [Anonymous], CVPR
   [Anonymous], 2012, P 20 ACM INT C MULT
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107
   Bui T, 2015, IEEE INT VAC ELECT C
   Cao Y, 2011, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2011.5995460
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Davis J., 2006, P 23 INT C MACH LEAR
   DelBimbo A, 1997, IEEE T PATTERN ANAL, V19, P121, DOI 10.1109/34.574790
   DEVORE RA, 1992, IEEE T INFORM THEORY, V38, P719, DOI 10.1109/18.119733
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Eitz M, 2011, IEEE T VIS COMPUT GR, V17, P1624, DOI 10.1109/TVCG.2010.266
   Filho Carlos A. F., 2013, 2013 XXVI Conference on Graphics, Patterns and Images (SIBGRAPI 2013), P234, DOI 10.1109/SIBGRAPI.2013.40
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Hu R, 2013, COMPUT VIS IMAGE UND, V117, P790, DOI 10.1016/j.cviu.2013.02.005
   Jacobs C. E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P277, DOI 10.1145/218380.218454
   Jain R, 2008, The art of computer systems performance analysis: techniques for experimental design, measurement, simulation, and modeling
   KATO T, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P530, DOI 10.1109/ICPR.1992.201616
   Lee YJ, 2009, PROC CVPR IEEE, P2254, DOI 10.1109/CVPRW.2009.5206698
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma C, 2016, IMAGE VISION COMPUT, V46, P64, DOI 10.1016/j.imavis.2015.11.007
   Polsley S, 2017, IEEE T HUM-MACH SYST, V47, P194, DOI 10.1109/THMS.2017.2649684
   Qi YG, 2016, IEEE IMAGE PROC, P2460, DOI 10.1109/ICIP.2016.7532801
   Qian XM, 2016, IEEE T IMAGE PROCESS, V25, P195, DOI 10.1109/TIP.2015.2497145
   Robertson S, 2004, J DOC, V60, P503, DOI 10.1108/00220410410560582
   Robertson S., 2004, P 13 ACM INT C INF K, P42
   Saavedra J. M., 2015, MULTIMED TOOLS APPL, P1
   Saavedra J.M., 2015, P BRIT MACH VIS C 20
   Saavedra JM, 2014, IEEE IMAGE PROC, P2998, DOI 10.1109/ICIP.2014.7025606
   Saavedra JM, 2010, LECT NOTES COMPUT SC, V6376, P432
   Salton G, 1986, Introduction to Modern Information Retrieval
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SRINIVAS M, 1994, IEEE T SYST MAN CYB, V24, P656, DOI 10.1109/21.286385
   Stenger BDR, 2004, MODEL BASED HAND TRA
   Sun Xinghai., 2013, Proceedings of the International Conference On Multimedia (MM), P233
   Venters CC, 2005, ENCY INFORM SCI TECH, P556
   Xiao CC, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P571, DOI 10.1145/2671188.2749360
NR 39
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22019
EP 22042
DI 10.1007/s11042-017-4758-y
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200009
DA 2024-07-18
ER

PT J
AU Gialampoukidis, I
   Moumtzidou, A
   Liparas, D
   Tsikrika, T
   Vrochidis, S
   Kompatsiaris, I
AF Gialampoukidis, Ilias
   Moumtzidou, Anastasia
   Liparas, Dimitris
   Tsikrika, Theodora
   Vrochidis, Stefanos
   Kompatsiaris, Ioannis
TI Multimedia retrieval based on non-linear graph-based fusion and partial
   least squares regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia retrieval; Non-linear fusion; Graph-based models
AB Heterogeneous sources of information, such as images, videos, text and metadata are often used to describe different or complementary views of the same multimedia object, especially in the online news domain and in large annotated image collections. The retrieval of multimedia objects, given a multimodal query, requires the combination of several sources of information in an efficient and scalable way. Towards this direction, we provide a novel unsupervised framework for multimodal fusion of visual and textual similarities, which are based on visual features, visual concepts and textual metadata, integrating non-linear graph-based fusion and Partial Least Squares Regression. The fusion strategy is based on the construction of a multimodal contextual similarity matrix and the non-linear combination of relevance scores from query-based similarity vectors. Our framework can employ more than two modalities and high-level information, without increase in memory complexity, when compared to state-of-the-art baseline methods. The experimental comparison is done in three public multimedia collections in the multimedia retrieval task. The results have shown that the proposed method outperforms the baseline methods, in terms of Mean Average Precision and Precision@20.
C1 [Gialampoukidis, Ilias; Moumtzidou, Anastasia; Liparas, Dimitris; Tsikrika, Theodora; Vrochidis, Stefanos; Kompatsiaris, Ioannis] Ctr Res & Technol Hellas, Informat Technol Inst, 6th Km Charilaou Thermi Rd, Thessaloniki 57001, Greece.
C3 Centre for Research & Technology Hellas
RP Gialampoukidis, I (corresponding author), Ctr Res & Technol Hellas, Informat Technol Inst, 6th Km Charilaou Thermi Rd, Thessaloniki 57001, Greece.
EM heliasgj@iti.gr; moumtzid@iti.gr; dliparas@iti.gr;
   theodora.tsikrika@iti.gr; stefanos@iti.gr; ikom@iti.gr
RI Gialampoukidis, Ilias/Y-2171-2019; Kompatsiaris, Ioannis/P-8594-2015;
   Moumtzidou, Anastasia/IXN-7950-2023
OI Kompatsiaris, Ioannis/0000-0001-6447-9020; Tsikrika,
   Theodora/0000-0003-4148-9028; Moumtzidou, Anastasia/0000-0001-7615-8400;
   Gialampoukidis, Ilias/0000-0002-5234-9795; Liparas,
   Dimitris/0000-0001-9968-725X; Vrochidis, Stefanos/0000-0002-2505-9178
FU European Commission by the project MULTISENSOR [FP7-610411]; European
   Commission by the project KRISTINA [H2020-645012]
FX This work was partially supported by the European Commission by the
   projects MULTISENSOR (FP7-610411) and KRISTINA (H2020-645012).
CR Ah-Pine J, 2015, ACM T INFORM SYST, V33, DOI 10.1145/2699668
   Ah-Pine J, 2009, MULTIMED TOOLS APPL, V42, P31, DOI 10.1007/s11042-008-0246-8
   [Anonymous], MEDIAEVAL
   [Anonymous], ACM INT C MULT RETR
   [Anonymous], IMAGEEVAL WORKSH CVI
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Caicedo JC, 2012, NEUROCOMPUTING, V76, P50, DOI 10.1016/j.neucom.2011.04.037
   Daiber J., 2013, P 9 INT C SEM SYST, P121, DOI [10.1145/2506182.2506198, DOI 10.1145/2506182.2506198]
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   Gialampoukidis I, 2016, 2016 11TH INTERNATIONAL WORKSHOP ON SEMANTIC AND SOCIAL MEDIA ADAPTATION AND PERSONALIZATION (SMAP), P1, DOI 10.1109/SMAP.2016.7753375
   Gialampoukidis I, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P359, DOI 10.1145/2911996.2912068
   Grubinger M., 2006, Language Resources and Evaluation, P13
   HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417
   Hsu WinstonH., 2007, ACM MM
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Kitanovski I, 2013, ADV INTELLIGENT SYST, P81
   Lan ZZ, 2014, MULTIMED TOOLS APPL, V71, P333, DOI 10.1007/s11042-013-1391-2
   Langville AN, 2005, SIAM REV, V47, P135, DOI 10.1137/S0036144503424786
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Magalhaes J, 2010, ACM T INFORM SYST, V28, DOI 10.1145/1852102.1852105
   Markatopoulou F, 2015, IEEE IMAGE PROC, P1786, DOI 10.1109/ICIP.2015.7351108
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Safadi Bahjat, 2014, ICMR 2014 P ACM INT, P265
   Sanderson C, 2004, DIGIT SIGNAL PROCESS, V14, P449, DOI 10.1016/j.dsp.2004.05.001
   Siddiquie Behjat., 2014, Proceedings of the International Conference on Multimedia Retrieval, page, P321
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tsikrika Theodora, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P372, DOI 10.1007/978-3-319-14445-0_32
   Tsikrika T, 2012, IEEE MULTIMEDIA, V19, P24, DOI 10.1109/MMUL.2012.17
   Tsikrika T, 2010, INFORM RETRIEVAL SER, V32, P163, DOI 10.1007/978-3-642-15181-1_9
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Wang J, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P347, DOI 10.1145/2671188.2749341
   Wang W, 2014, PROC VLDB ENDOW, V7, P649, DOI 10.14778/2732296.2732301
   Wang YF, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P307, DOI 10.1145/2647868.2654901
   Wang Y, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P805, DOI 10.1145/2505515.2505591
   Xu SC, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P675, DOI 10.1145/2671188.2749413
NR 35
TC 5
Z9 5
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22383
EP 22403
DI 10.1007/s11042-017-4797-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200027
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Hang, ST
   Aono, M
AF Hang, Siang Thye
   Aono, Masaki
TI Bi-linearly weighted fractional max pooling An extension to conventional
   max pooling for deep convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fractional max pooling; Convolutional neural network; Deep learning
AB In this paper, we propose to extend the flexibility of the commonly used 2 x 2 non-overlapping max pooling for Convolutional Neural Network. We name it as Bi-linearly Weighted Fractional Max-Pooling. This proposed method enables max pooling operation below stride size 2, and is computed based on four bi-linearly weighted neighboring input activations. Currently, in a 2 x 2 non-overlapping max pooling operation, as spatial size is halved in both x and y directions, three-quarter of activations in the feature maps are discarded. As such reduction is too abrupt, amount of said pooling operation within a Convolutional Neural Network is very limited: further increasing the number of pooling operation results in too little activation left for subsequent operations. Using our proposed pooling method, spatial size reduction can be more gradual and can be adjusted flexibly. We applied a few combinations of our proposed pooling method into 50-layered ResNet and 19-layered VGGNet with reduced number of filters, and experimented on FGVC-Aircraft, Oxford-IIIT Pet, STL-10 and CIFAR-100 datasets. Even with reduced memory usage, our proposed methods showed reasonable improvement in classification accuracy with 50-layered ResNet. Additionally, with flexibility of our proposed pooling method, we change the reduction rate dynamically every training iteration, and our evaluation results indicated potential regularization effect.
C1 [Hang, Siang Thye] Toyohashi Univ Technol, Dept Comp Sci & Engn, Toyohashi, Aichi, Japan.
   [Hang, Siang Thye] Toyohashi Univ Technol, Grad Sch Engn, Toyohashi, Aichi, Japan.
   [Aono, Masaki] Toyohashi Univ Technol, Comp Sci & Engn Dept, Grad Sch, Toyohashi, Aichi, Japan.
C3 Toyohashi University of Technology; Toyohashi University of Technology;
   Toyohashi University of Technology
RP Hang, ST (corresponding author), Toyohashi Univ Technol, Dept Comp Sci & Engn, Toyohashi, Aichi, Japan.; Hang, ST (corresponding author), Toyohashi Univ Technol, Grad Sch Engn, Toyohashi, Aichi, Japan.
EM hang@kde.cs.tut.ac.jp; aono@tut.jp
FU MEXT KAKENHI [15K12027]; Grants-in-Aid for Scientific Research
   [15K12027, 17H01746] Funding Source: KAKEN
FX We would like to thank MEXT KAKENHI, Grant-in-Aid for Challenging
   Exploratory Research, Grant Number 15K12027 for partial support of our
   work.
CR [Anonymous], 2013, P INT C LEARN REPR I
   [Anonymous], 2013, Tech. rep.
   [Anonymous], DEEP LEARN WORKSH IC
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], 2016 IEEE C COMP VIS
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2014, Arxiv
   [Anonymous], ARXIV161002915
   [Anonymous], AISTATS 2011
   [Anonymous], 2013, P INT C LEARN REPR I
   Glorot X., 2010, P INT C ART INT STAT, P249
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Parkhi OM, 2012, PROC CVPR IEEE, P3498, DOI 10.1109/CVPR.2012.6248092
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, IEEE INT C ICLR
   Spinoulas L, 2015, IEEE COMPUT SOC CONF
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 20
TC 18
Z9 20
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22095
EP 22117
DI 10.1007/s11042-017-4840-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200013
DA 2024-07-18
ER

PT J
AU Nguyen, VL
   Vu, NS
   Phan, HH
   Gosselin, PH
AF Vu-Lam Nguyen
   Ngoc-Son Vu
   Hai-Hong Phan
   Gosselin, Philippe-Henri
TI LBP-and-ScatNet-based combined features for efficient texture
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image texture; Image classification; Image texture analysis; Wavelet
   Transforms; Scattering Transforms
ID LOCAL BINARY PATTERNS; WAVELET; REPRESENTATION
AB In this paper, we propose a micro-macro feature combination approach for texture classification. The two disparate yet complementary categories of features are combined. By this way, Local Binary Pattern (LBP) plays the role of micro-structure feature extractor while the scattering transform captures macro-structure information. In fact, for extracting the macro-type features, coefficients are aggregated from three different layers of the scattering network. It is a handcrafted convolution network which is implemented by computing consecutively wavelet transforms and modulus non-linear operators. By contrast, in order to extract micro-structure features which are rotation-invariant, relatively robust to noise and illumination change, the completed LBP is utilized alongside the biologically-inspired filtering (BF) preprocessing technique. Overall, since the proposed framework can exploit the advantages of both feature types, its texture representation is not only invariant to rotation, scaling, illumination change but also highly discriminative. Intensive experiments conducted on many texture benchmarks such as CUReT, UIUC, KTH-TIPS-2b, and OUTEX show that our framework has a competitive classification accuracy.
C1 [Vu-Lam Nguyen; Ngoc-Son Vu; Hai-Hong Phan; Gosselin, Philippe-Henri] Univ Cergy Pontoise, Univ Paris Seine, ETIS, ENSEA,CNRS, F-95000 Cergy, France.
C3 Centre National de la Recherche Scientifique (CNRS); CY Cergy Paris
   Universite
RP Nguyen, VL (corresponding author), Univ Cergy Pontoise, Univ Paris Seine, ETIS, ENSEA,CNRS, F-95000 Cergy, France.
EM lam.nguyen@ensea.fr; son.vu@ensea.fr; thi-hai-hong.phan@ensea.fr;
   philippe-henri.gosselin@ensea.fr
RI Phan, Hai-Hong/ABH-2046-2021
OI Phan, Hai-Hong/0000-0002-7886-7128; Nguyen, Vu-Lam/0000-0001-6198-6596
CR [Anonymous], 2002, IEEE T PATTERN ANAL
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2001 IEEE COMP SOC C
   [Anonymous], 2015, P 23 ACM INT C MULT
   BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384
   Broadhurst R.E., 2005, Texture 2005 : Proceedings of the 4th International Workshop on Texture Analysis and Synthesis, P25
   Caputo B, 2010, IMAGE VISION COMPUT, V28, P150, DOI 10.1016/j.imavis.2009.05.005
   Charalampidis D, 2002, IEEE T IMAGE PROCESS, V11, P825, DOI 10.1109/TIP.2002.801117
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Cimpoi M, 2016, INT J COMPUT VISION, V118, P65, DOI 10.1007/s11263-015-0872-3
   Crosier M, 2010, INT J COMPUT VISION, V88, P447, DOI 10.1007/s11263-009-0315-0
   Cula OG, 2004, INT J COMPUT VISION, V59, P33, DOI 10.1023/B:VISI.0000020670.05764.55
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Fathi A, 2012, PATTERN RECOGN LETT, V33, P1093, DOI 10.1016/j.patrec.2012.01.017
   Guo YM, 2012, PATTERN RECOGN, V45, P3834, DOI 10.1016/j.patcog.2012.04.003
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Hafiane A, 2007, LECT NOTES COMPUT SC, V4633, P387
   Haley GM, 1999, IEEE T IMAGE PROCESS, V8, P255, DOI 10.1109/83.743859
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hong XP, 2014, IEEE T IMAGE PROCESS, V23, P2557, DOI 10.1109/TIP.2014.2316640
   LAINE A, 1993, IEEE T PATTERN ANAL, V15, P1186, DOI 10.1109/34.244679
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mallat S, 2012, COMMUN PUR APPL MATH, V65, P1331, DOI 10.1002/cpa.21413
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Vu NS, 2014, IMAGE VISION COMPUT, V32, P424, DOI 10.1016/j.imavis.2014.04.006
   Nguyen V-L, 2016, 14 INT WORKSH CONT B
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Porter R, 1997, IEE P-VIS IMAGE SIGN, V144, P180, DOI 10.1049/ip-vis:19971182
   Qi X, 2013, BRIT MACH VIS C
   Qi XB, 2014, IEEE T PATTERN ANAL, V36, P2199, DOI 10.1109/TPAMI.2014.2316826
   Qian XM, 2011, PATTERN RECOGN, V44, P2502, DOI 10.1016/j.patcog.2011.03.029
   Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976
   Sifre L, 2013, PROC CVPR IEEE, P1233, DOI 10.1109/CVPR.2013.163
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Nguyen VD, 2016, LECT NOTES ARTIF INT, V9621, P23, DOI 10.1007/978-3-662-49381-6_3
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Vedaldi A., 2010, VLFeat - an open and portable library of computer vision algorithms
   Xu Y, 2010, PROC CVPR IEEE, P161, DOI 10.1109/CVPR.2010.5540217
   Xu Y, 2009, PROC CVPR IEEE, P573, DOI 10.1109/CVPRW.2009.5206741
   Xu Y, 2009, INT J COMPUT VISION, V83, P85, DOI 10.1007/s11263-009-0220-6
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
NR 48
TC 2
Z9 3
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22425
EP 22444
DI 10.1007/s11042-017-4824-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200029
DA 2024-07-18
ER

PT J
AU Awwad, S
   Piccardi, M
AF Awwad, Sari
   Piccardi, Massimo
TI Prototype-based budget maintenance for tracking in depth videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth videos; Tracking; Struck tracker; Local depth patterns; Budget
   maintenance; Princeton tracking benchmark dataset
ID VISUAL TRACKING; OBJECT TRACKING
AB The use of conventional video tracking based on color or gray-level videos often raises concerns about the privacy of the tracked targets. To alleviate this issue, this paper presents a novel tracker that operates solely from depth data. The proposed tracker is designed as an extension of the popular Struck algorithm which leverages the effective framework of structural SVM. The main contributions of our paper are: i) a dedicated depth feature based on local depth patterns, ii) a heuristic for handling view occlusions in depth frames, and iii) a technique for keeping the number of the support vectors within a given "budget" so as to limit computational costs. Experimental results over the challenging Princeton Tracking Benchmark (PTB) dataset report a remarkable accuracy compared to the original Struck tracker and other state-of-the-art trackers using depth and RGB data.
C1 [Awwad, Sari; Piccardi, Massimo] Univ Technol Sydney, POB 123, Broadway, NSW, Australia.
C3 University of Technology Sydney
RP Piccardi, M (corresponding author), Univ Technol Sydney, POB 123, Broadway, NSW, Australia.
EM Sari.Awwad@student.uts.edu.au; Massimo.Piccardi@uts.edu.au
RI Awwad, Sari/ABG-1431-2021; Piccardi, Massimo/AAY-1323-2020
OI Awwad, Sari/0000-0002-6043-2409; Piccardi, Massimo/0000-0001-9250-6604
CR [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2010, 27 INT C MACHINE LEA
   [Anonymous], J NANOTECHNOL
   [Anonymous], 2014, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2013.230
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Awwad S, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1115, DOI 10.1145/2733373.2806295
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Basso F, 2013, ADV INTELL SYST COMP, V193, P265
   Bordes A., 2007, Proceedings of the Twentyfourth International Conference on Machine Learning (ICML'07), P89
   Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232
   Cavallanti G, 2007, MACH LEARN, V69, P143, DOI 10.1007/s10994-007-5003-0
   Crammer K, 2004, ADV NEUR IN, V16, P225
   Dekel O, 2008, SIAM J COMPUT, V37, P1342, DOI 10.1137/060666998
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Guo YW, 2014, COMPUT VIS IMAGE UND, V118, P128, DOI 10.1016/j.cviu.2013.09.007
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Lu CW, 2014, PROC CVPR IEEE, P772, DOI 10.1109/CVPR.2014.104
   Luber M, 2011, IEEE INT C INT ROBOT, P3844, DOI 10.1109/IROS.2011.6048836
   Munaro M, 2012, IEEE INT C INT ROBOT, P2101, DOI 10.1109/IROS.2012.6385772
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Riesen K., 2010, Graph classification and clustering based on vector space embedding
   Schuurmans Li., 2007, Advances in Neural Information Processing Systems 19: Proceedings of the 2006 Conference, V19, P249
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Song SR, 2013, IEEE I CONF COMP VIS, P233, DOI 10.1109/ICCV.2013.36
   Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453
   Vucetic Slobodan, 2009, 2009 Data Compression Conference. DCC 2009, P153, DOI 10.1109/DCC.2009.75
   Weston Jason., 2005, AISTATS, P413
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
NR 35
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21117
EP 21132
DI 10.1007/s11042-016-4053-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400035
DA 2024-07-18
ER

PT J
AU Cha, HJ
   Yang, HK
   Kim, JM
   Song, YJ
AF Cha, Hyun-Jong
   Yang, Ho-Kyung
   Kim, Jin-Mook
   Song, You-Jin
TI A Design of System using homomorphic encryption for multimedia data
   management
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia data management; Homomorphic encryption; Security
AB With the introduction of the concept of information warfare, the way military operations are done is changing quickly. Now, much more than it was in past, quick acquisition of information and effective decision making are crucial. Especially, these days the ratio of multimedia data is on the rise. A data management system has been put in place since the 1980s which encrypts information before storing it, and allowing only authorized users to gain access to it according to the proper procedures.
   In this paper, a secure and effective multimedia data management system that uses homomorphic operations is designed and implemented. By using homomorphic operations, it is able to quickly process stored ciphertext without a decryption process, allowing fast decision making after information gathering in a NCW environment. In order to assess the performance of the effective multimedia data management system implemented in this paper, it was compared to an ordinary system in which ciphertext has to be first decrypted before it can be modified. The secure and effective multimedia data management system for information warfare implemented in this study is highly versatile because any public encryption algorithm can be used, and has short response times thanks to the homomorphic algorithm which allows processing to be done directly on the ciphertext.
C1 [Cha, Hyun-Jong] Kwangwoon Univ, Dept Def Acquisit Program, 447-1 Wolgye Dong, Seoul 139701, South Korea.
   [Yang, Ho-Kyung; Kim, Jin-Mook] Sunmoon Univ, Div IT Educ, 70,221 Bun Gil 70,Sunmoon Ro, Asan 31460, Chungnam, South Korea.
   [Song, You-Jin] Dongguk Univ Gyeongju Campus, Dept Business Adm, 123 Dongdae Ro, Gyeongju Si 38066, Gyeonsangbuk Do, South Korea.
C3 Kwangwoon University; Sun Moon University; Dongguk University
RP Kim, JM (corresponding author), Sunmoon Univ, Div IT Educ, 70,221 Bun Gil 70,Sunmoon Ro, Asan 31460, Chungnam, South Korea.
EM chj826@kw.ac.kr; porori2000@nate.com; calf0425@sunmoon.ac.kr;
   song@dongguk.ac.kr
RI Cha, HyunJong/T-9784-2017
FU National Project of India; Department of Science and Technology,
   Government of India
FX Foundation item: The National Project of India (No.: xxx-xxxx). Authors
   are grateful to the Department of Science and Technology, Government of
   India for financial support to carry out this work.
CR Alabdulatif A, 2016, J KING SAUD UNIV-COM, V28, P27, DOI 10.1016/j.jksuci.2015.10.001
   [Anonymous], 2013, ARXIV13055886
   [Anonymous], INT J PHOTOENERGY, DOI DOI 10.1186/1476-511X-13-189
   Engouang Tristan Daladier, 2014, Applied Mechanics and Materials, V541-542, P3017, DOI 10.4028/www.scientific.net/AMM.543-547.3017
   ERTAUL L, 2015, INT J COMPUT SCI NET, V15, P1
   Hayward Ryan, 2015, J. appl. res. technol, V13, P245
   Hyun-Jong C, 2014, LIFE SCI J, V11
   Kim Hyun-Sung, 2013, [Journal of Security Engineering, 보안공학연구논문지], V10, P213
   Kim N, 2014, INT J SMART HOME, V8, P7
   Louk M, 2015, 2015 INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P493, DOI 10.1109/ICOIN.2015.7057954
   Schepens J, 2012, BILING-LANG COGN, V15, P157, DOI 10.1017/S1366728910000623
   Son SW, 2008, CRYPTOGRAPHY NETWORK, V2-7, P305
   Song YJ, 2009, C I ELECT ENG KOREA, V32, P423
   Song YJ, 2009, JOUNAL KOREA I INFOR, V19, P80
   Tirthani N, 2014, IACR CRYPTOLOGY EPRI
   Tyliszczak A, 2014, J COMPUT PHYS, V276, P438, DOI 10.1016/j.jcp.2014.07.043
   Yang J.S., 2015, Advanced Science and Technology Letters, V97, P94
NR 17
TC 0
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19897
EP 19912
DI 10.1007/s11042-016-3767-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500034
DA 2024-07-18
ER

PT J
AU Hasheminejad, M
   Farsi, H
AF Hasheminejad, Mohammad
   Farsi, Hassan
TI Frame level sparse representation classification for speaker
   verification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker recognition; Speaker verification; Sparse representation
   classification; Frame level sparse representation classification
ID VECTOR
AB In this paper, we analyze the application of the sparse representation of frames of the speech signal for the speaker verification. It is lately shown that Sparse Representation Classification (SRC), is promising for speaker recognition. We bring evidence that the frame level sparse representation classification resembles process of speech recognition in human sensory system. Since the recognition of different voices (noises) helps individuals to immediately distinguish between the noise and the original speech signal, a noise aware system was designed. As a principal in the sparse representation, we argued the mutual coherence of the dictionary columns, called dictionary atoms, which is not efficiently considered in the already published SRC base speaker verification researches. To suppress the mutual coherence, we use a dictionary learning method to construct a dictionary with effective atoms. Our proposed Frame Level Sparse Representation Classification (FSRC), provides new insights to the SRC based speaker verification. We demonstrate that, in the SRC based speaker verification, using a dictionary whose atoms are orthogonal can be more extensible than a dictionary whose atoms are highly correlated, and that the mutual coherence suppression is even more effective than imposing strong orthogonality on the dictionary atoms. We consider the performance of state-of-the-art speaker recognition systems and the proposed method on NIST SRE 2004 data. Experimental results show that in comparison to baseline methods, when we have enough amount of information in the registration of targets, the proposed method improves the performance of speaker verification system in noisy conditions.
C1 [Hasheminejad, Mohammad; Farsi, Hassan] Univ Birjand, Dept Elect & Comp Engn, Shahid Avini Highway, Birjand, Iran.
C3 University of Birjand
RP Farsi, H (corresponding author), Univ Birjand, Dept Elect & Comp Engn, Shahid Avini Highway, Birjand, Iran.
EM hfarsi@birjand.ac.ir
RI Hasheminejad, Mohammad/ABE-6315-2021; Farsi, hassan/AAF-5297-2021
OI Hasheminejad, Mohammad/0000-0001-9557-7563; 
CR [Anonymous], P OD
   [Anonymous], 2013, SPEECH LANG PROCESS
   Brummer N., 2014, ARXIV14022447
   Brummer N., 2010, THESIS
   Campbell WM, 2006, IEEE SIGNAL PROC LET, V13, P308, DOI 10.1109/LSP.2006.870086
   Chi YT, 2013, PROC CVPR IEEE, P377, DOI 10.1109/CVPR.2013.55
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Harandi M, 2013, IEEE I CONF COMP VIS, P3120, DOI 10.1109/ICCV.2013.387
   HARIS BC, 2012, INT CONF ACOUST SPEE, P4785
   Hautamäki V, 2008, IEEE SIGNAL PROC LET, V15, P162, DOI 10.1109/LSP.2007.914792
   Hautamäki V, 2013, IEEE T AUDIO SPEECH, V21, P1622, DOI 10.1109/TASL.2013.2256895
   Hurmalainen A, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P244
   Kim C, 2012, INT CONF ACOUST SPEE, P4101, DOI 10.1109/ICASSP.2012.6288820
   Kua JMK, 2013, SPEECH COMMUN, V55, P707, DOI 10.1016/j.specom.2013.01.005
   Labusch K, 2009, NEUROCOMPUTING, V72, P1547, DOI 10.1016/j.neucom.2008.11.027
   Li M, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P2740
   Nakagawa S, 2012, IEEE T AUDIO SPEECH, V20, P1085, DOI 10.1109/TASL.2011.2172422
   Naseem Imran, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4460, DOI 10.1109/ICPR.2010.1083
   Olshausen BA, 2004, CURR OPIN NEUROBIOL, V14, P481, DOI 10.1016/j.conb.2004.07.007
   Rajan P., 2009, P ANN C INT SPEECH C, P2355
   REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Roach P., 1991, English Phonetics and Phonology
   Solomonoff A., 2004, OD SPEAK LANG REC WO, P57
   Tzagkarakis C, 2013, SIGN PROC C EUSIPCO, P1
   Wang LB, 2010, IEICE T INF SYST, VE93D, P2397, DOI 10.1587/transinf.E93.D.2397
   Yaghoobi M, 2009, IEEE T SIGNAL PROCES, V57, P2178, DOI 10.1109/TSP.2009.2016257
NR 27
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21211
EP 21224
DI 10.1007/s11042-016-4071-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400040
DA 2024-07-18
ER

PT J
AU Joo, HJ
   Jeong, HY
AF Joo, Hae-Jong
   Jeong, Hwa-Young
TI Quality measurement system for a wireless network based on the
   multimedia-data service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data; Wireless network service (LTE-A . LTE . 3G . Wibro . WiFi);
   QoE; QoS
AB To catch up with the recent expansions of wireless platforms, the performance of quality management systems for wireless communication network services needs to be continuously improved; therefore, studies should be conducted on comprehensive quality indicators through the quality analyses that can represent the users' quality of experience (QoE) of multimedia-data based wireless network services. In this paper, subjecting the five wireless Internet services (broadband LTE, LTE-A, LTE3G, WiBro, and WiFi), reliability verifications of quality measurement system platforms, algorithms, and software (S/W) that can assess the qualities of network sections and of the whole stations of service providers were proposed. In addition, to conduct reliability verifications, vehicles were facilitated to travel to the assessment areas and to perform the measurements more than 100 times in each assessment area (over 50 times per terminal).
C1 [Joo, Hae-Jong] Dongguk Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Jeong, Hwa-Young] Kyung Hee Univ, Humanitas Coll, 26 Kyungheedae Ro, Seoul 02447, South Korea.
C3 Dongguk University; Kyung Hee University
RP Jeong, HY (corresponding author), Kyung Hee Univ, Humanitas Coll, 26 Kyungheedae Ro, Seoul 02447, South Korea.
EM hyjeong@khu.ac.kr
OI Jeong, Hwa-Young/0000-0002-5017-934X
CR [Anonymous], 2002, METH SUBJ ASS QUAL T
   [Anonymous], HURR WAN EM NETW SIM
   [Anonymous], 2000, J143 ITUT
   [Anonymous], 1999, SUBJ VID QUA ASS MET
   Daesun K, 2011, EVERYTHING WIRELESS
   Dai Q, 2010, IMPACT PACKET LOSS P
   Dunham MH, 1999, P INT WORKSH DAT ENG, P14
   Haejong J, 2013, LECT NOTES ELECT ENG
   Kim H, 2010, IEEE ICACT
   Maier G, 2010, LECT NOTES COMPUT SC, V6032, P161, DOI 10.1007/978-3-642-12334-4_17
   National IT Industry Promotion Agency, 2011, WEEKL TECHN TRENDS
   Sandvine Incorporated, 2011, GLOB INT PHEN REP 20
   Shmueli R, 2008, IEEE T BROADCAST, V54, P628, DOI 10.1109/TBC.2008.2001242
   Takahashi A, 2008, IEEE COMMUN MAG, V46, P78, DOI 10.1109/MCOM.2008.4473087
   Yamagishi K, 2008, IEEE ICC 2008
   주해종, 2005, [The KIPS Transactions : Part D, 정보처리학회논문지D], V12, P521
NR 16
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19795
EP 19807
DI 10.1007/s11042-016-3547-3
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500028
DA 2024-07-18
ER

PT J
AU Kang, YS
   Youm, S
AF Kang, Yongshin
   Youm, Sekyoung
TI Multimedia application to an extended public transportation network in
   South Korea: optimal path search in a multimodal transit network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Modified Dijkstra algorithm; Google android application; Public
   transportation; Multimodal transit network
ID SHORTEST; ALGORITHMS
AB Various traffic network usage formats have arisen along with the popularization of automobiles and the continued service extension of busses, subways, and other forms of public transportation. Due to various characteristics of public transportation networks, unlike general street networks, many issues can affect public transportation, and an optimal course search should be considered. Present research considers plans to improve the overall efficiency of public transportation systems with regard to destination, means, route, and other factors to be selected efficiently in this environment as public transportation usage increases. From this perspective, it suggests the characteristics that a multimodal transit network route search algorithm should have and a corrective algorithm that implements this in an applicable program. Implementation was done in Google android application which provides a simple user interface to find optimal routes in Google Map. The proposed application would enable overall quality-of-service improvement and balanced usage of public transportation, efficient traffic management, and other advantages.
C1 [Kang, Yongshin] Sungkyunkwan Univ, Dept Syst Management Engn, Gyeonggi Do, South Korea.
   [Youm, Sekyoung] Dongguk Univ, Dept Ind & Syst Engn, 82-1 Pil Dong, Seoul, South Korea.
C3 Sungkyunkwan University (SKKU); Dongguk University
RP Youm, S (corresponding author), Dongguk Univ, Dept Ind & Syst Engn, 82-1 Pil Dong, Seoul, South Korea.
EM yskang7867@skku.edu; sekyoungyoum@gmail.com
CR Ahuja R. K., 1993, Network flows: theory, algorithms, and applications
   AHUJA RK, 1990, J ACM, V37, P213, DOI 10.1145/77600.77615
   AHUJA RK, 1991, SIAM REV, V33, P175, DOI 10.1137/1033048
   BRUMBAUGHSMITH J, 1989, EUR J OPER RES, V43, P216, DOI 10.1016/0377-2217(89)90215-4
   Cherkassky BV, 1999, SIAM J COMPUT, V28, P1326, DOI 10.1137/S0097539796313490
   Choi KJ, 1998, J KOREA TRANSPORTATI, V16, P167
   CORLEY HW, 1985, J OPTIMIZ THEORY APP, V46, P79, DOI 10.1007/BF00938761
   Dijkstra EW., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   JOHNSON DB, 1973, J ACM, V20, P385, DOI 10.1145/321765.321768
   Kim HM, 1999, J KOREA TRANSPORTATI, V17, P87
   Lee M. M., 2004, THESIS
   Lee Mee-Young, 2008, [Korean Society of Transportation, 대한교통학회지], V26, P127
   Lee MY, 2005, J KOREAN SOC IT SERV, V4, P1
   Lozano A, 2001, TRANSPORT RES A-POL, V35, P225, DOI 10.1016/S0965-8564(99)00056-7
   MARTINS EQV, 1984, EUR J OPER RES, V16, P236, DOI 10.1016/0377-2217(84)90077-8
   Moore Edward F., 1959, P INT S SWITCH THEOR, P285
   Seung-Hoon Cheon, 2008, [Korean Society of Transportation, 대한교통학회지], V26, P233
   Shin Seongil, 2008, [Journal of the Korean Society of Civil Engineers D, 대한토목학회 논문집D], V28, P317
   Skriver AJV, 2000, COMPUT OPER RES, V27, P507, DOI 10.1016/S0305-0548(99)00037-4
   Yang R., 2008, 9 INT C YOUNG COMP S
   Zhan F.B., 1997, Journal of Geographic Information and Decision Analysis, V1, P70
NR 21
TC 5
Z9 5
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19945
EP 19957
DI 10.1007/s11042-016-4015-9
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500037
DA 2024-07-18
ER

PT J
AU Sodhro, AH
   Li, Y
   Shah, MA
AF Sodhro, Ali Hassan
   Li, Ye
   Shah, Madad Ali
TI Green and friendly media transmission algorithms for wireless body
   sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Green and friendly; WBSN; Sustainable; BSA; La
ID VIDEO TRANSMISSION; LIFETIME; MODEL
AB Video transmission is considered as a quite significant step towards health monitoring of the emergency patients during any critical incident. However, the energy hungry video transmission and slow progress in battery technologies have become a major and serious problem for the evolution of video technology in WBSNs. Therefore, the need arose to conduct research on sustainable, "Green", i.e., energy-efficient and "Friendly", i.e., battery-friendly technologies to cater the need of upcoming mobile and portable devices. The main challenge addressed in this research is how to increase the battery lifetime during on-demand Variable Bit Rate (VBR) video transmission from medical video server to base station in WBSNs. In order to overcome this problem, sustainable, Green and Friendly frame transmission algorithms are enunciated i.e. Lazy Algorithm (LA) and Battery-friendly Smoothing Algorithm (BSA) with analytical battery model. The proposed algorithms minimize transmission energy consumption, battery charge consumption and high current profile. These algorithms also prolongs the battery lifetime of those sensor nodes during video transmission. Experimental results demonstrates that BSA outperforms LA to minimize battery drain by improving its lifetime up to 19.8 %. However, the LA performs better than BSA in context of transmission energy saving up to 49.49 %. Furthermore, a video transmission framework of Remote Medical Education System (RMES) for elderly persons and infants is proposed to provide viable and sustainable battery solutions to serve the community.
C1 [Sodhro, Ali Hassan; Shah, Madad Ali] Sukkur Inst Business Adm, Sukkur, Sindh, Pakistan.
   [Sodhro, Ali Hassan; Li, Ye] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
   [Sodhro, Ali Hassan] SIAT CAS, Res Ctr Biomed Informat Technol, Shenzhen 518055, Peoples R China.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS
RP Sodhro, AH (corresponding author), Sukkur Inst Business Adm, Sukkur, Sindh, Pakistan.; Sodhro, AH (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.; Sodhro, AH (corresponding author), SIAT CAS, Res Ctr Biomed Informat Technol, Shenzhen 518055, Peoples R China.
EM ali.hassan@iba-suk.edu.pk; ye.li@siat.ac.cn; madad@iba-suk.edu.pk
RI li, ye/GWN-2672-2022; Li, Ye/JBS-2949-2023; Sodhro, Ali
   Hassan/AAE-9467-2021; Sodhro, Ali Hassan/ABE-1975-2021; Gupta,
   Brij/A-1155-2016
OI Sodhro, Ali Hassan/0000-0001-5502-530X; Sodhro, Ali
   Hassan/0000-0001-5502-530X; Gupta, Brij/0000-0003-4929-4698; yu,
   chuying/0000-0002-1279-6910; Li, Jianzhong/0000-0002-9580-206X
CR Aghdasi HS, 2008, MDPI SENSORS, V8, P194
   Alinejad A, 2012, IEEE T INF TECHNOL B, V16, P31, DOI 10.1109/TITB.2011.2154384
   Ameen MA, 2010, INT J DISTRIB SENS N, V2010, P252
   [Anonymous], 2013, E HLTH TELECOMMUNICA
   [Anonymous], 2012, 8021562012 IEEE
   [Anonymous], 2013, IFMBE C
   Damasevicius R, 2013, METROL MEAS SYST, V20, P419, DOI 10.2478/mms-2013-0036
   Detti A., 2012, Proc. WOWMOM, P1
   Devillers B, 2012, J COMMUN NETW-S KOR, V14, P130, DOI 10.1109/JCN.2012.6253061
   Duan C., 2013, P TRANSP EL C EXP IT, P1
   Gonzalez E, 2015, SENSORS-BASEL, V15, P11993, DOI 10.3390/s150511993
   Halgamuge M. N., 2009, Progress In Electromagnetics Research B, V12, P259, DOI 10.2528/PIERB08122303
   Heni M, 2012, INT J COMPUT NETW CO, V4, P207
   Ikram U, 2014, INT C WIR MOB COMM H, P211
   Jayashere S, 2008, P 10 INT C MC NETW, P360
   Jiang SL, 2012, CHIN CONT DECIS CONF, P3208, DOI 10.1109/CCDC.2012.6244507
   Jimenez-Marroquin MC, 2014, REV PANAM SALUD PUBL, V35, P329
   Kartsakli E, 2009, MOBILE NETW APPL, V14, P709, DOI 10.1007/s11036-008-0128-3
   Kim J, 2009, IEEE ENER CONV, P1726
   Li HG, 2013, IEEE SENS J, V13, P3548, DOI 10.1109/JSEN.2013.2276617
   Li J., 2012, THESIS
   Li Y, 2010, FRONT COMPUT SCI CHI, V4, P365, DOI 10.1007/s11704-010-0386-7
   Li Y, 2009, IEEE T VEH TECHNOL, V58, P1229, DOI 10.1109/TVT.2008.927720
   Ma C, 2008, MOBILE NETW APPL, V13, P228, DOI 10.1007/s11036-008-0032-x
   Misra S, 2008, IEEE COMMUN SURV TUT, V10, P18, DOI 10.1109/SURV.2008.080404
   Otal B, 2009, IEEE J SEL AREA COMM, V27, P553, DOI 10.1109/JSAC.2009.090516
   Rakhmatov D, 2003, IEEE T VLSI SYST, V11, P1019, DOI 10.1109/TVLSI.2003.819320
   Saeed U, 2011, MILCOMM C, P822
   Saraswat J., 2013, INT J COMPUTER NETWO, V5, P125
   Seema A, 2012, IEEE COMSOC MMTC E L, V7, P4
   Seema A, 2015, IEEE T BROADCAST, V61, P346, DOI 10.1109/TBC.2015.2400816
   Uysal-Biyikoglu E, 2002, IEEE ACM T NETWORK, V10, P487, DOI 10.1109/TNET.2002.801419
   Vallina-Rodriguez N, 2013, IEEE COMMUN SURV TUT, V15, P179, DOI 10.1109/SURV.2012.021312.00045
   Van der Auwera G, 2008, IEEE T BROADCAST, V54, P698, DOI 10.1109/TBC.2008.2000422
   Wei T., 2014, Proc. 51st Annu. Des. Autom. Conf. Des. Autom. Conf. - DAC, V14, P1
   Wu HM, 2014, LECT NOTES COMPUT SC, V8499, P61, DOI 10.1007/978-3-319-08219-6_5
   Zhang HT, 2012, COMPUT COMMUN, V35, P1983, DOI 10.1016/j.comcom.2012.06.009
   Zhang JC, 2010, APPL POWER ELECT CO, P672, DOI 10.1109/APEC.2010.5433597
NR 38
TC 103
Z9 107
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 20001
EP 20025
DI 10.1007/s11042-016-4084-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500040
DA 2024-07-18
ER

PT J
AU Wu, S
   Yang, H
   Zheng, SB
   Su, H
   Zhou, Q
   Lu, X
AF Wu, Shuang
   Yang, Hua
   Zheng, Shibao
   Su, Hang
   Zhou, Qin
   Lu, Xu
TI Motion sketch based crowd video retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd video retrieval; Sketch representation; Motion structure coding;
   Ranking SVM
ID BEHAVIOR; RANKING; SPACE; REPRESENTATION
AB Crowd video retrieval with desired motion flow segmentation is an important problem in surveillance video management, e.g., video indexing and browsing, especially in the age of big data. In this paper, we address this issue from the motion-level perspective by using hand-drawn sketches as queries. Motion sketch based crowd video retrieval naturally suffers from challenges in crowd motion representation and similarity measurement. To tackle them, we propose to (1) leverage the motion structure coding algorithm for motion-level video indexing and hand-drawn sketch representation and (2) exploit distance metric fusion strategy incorporated with Ranking SVM for measuring the relevant degree between a sketch query and crowd videos. Specifically, for video indexing, motion decomposition is utilized to separate sub-motion vector fields with typical patterns from a set of optical flows. Then, the motion-level descriptors of the vector fields are computed and stored in an index database. To represent motion sketches, we propose a mechanism by vectorizing the sketches followed by motion structure coding. In the retrieval stage, we first compute the pairwise distance with different metrics between a new sketch query and crowd videos, and then stack them into a feature vector as the input of the Ranking SVM algorithm. Finally, we use the learned retrieval model to predict the ranking score of each crowd video in the database. Experimental results on the publicly available crowd datasets show the robustness and effectiveness of the proposed sketch based crowd video retrieval system.
C1 [Wu, Shuang; Yang, Hua; Zheng, Shibao; Zhou, Qin; Lu, Xu] Shanghai Jiao Tong Univ, Inst Image Proc & Network Engn, Dept Elect Engn, Shanghai, Peoples R China.
   [Su, Hang] Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.
C3 Shanghai Jiao Tong University; Tsinghua University
RP Yang, H (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Network Engn, Dept Elect Engn, Shanghai, Peoples R China.
EM shuangwu@sjtu.edu.cn; hyang@sjtu.edu.cn; sbzh@sjtu.edu.cn;
   suhangss@mail.tsinghua.edu.cn; zhou.qin.190@sjtu.edu.cn;
   luxu_sjtu@sjtu.edu.cn
RI Wu, Shuang/KIH-6794-2024
FU National Natural Science Foundation of China (NSFC) [61671289, 61171172,
   61102099, 61571261, 61521062]; Science and Technology Commission of
   Shanghai Municipality (STCSM) [15DZ1207403, 12DZ2272600]
FX This work was supported in part by National Natural Science Foundation
   of China (NSFC, Grant Nos. 61671289, 61171172, 61102099, 61571261 and
   61521062) and Science and Technology Commission of Shanghai Municipality
   (STCSM, Grant Nos. 15DZ1207403 and 12DZ2272600).
CR Ali S, 2013, IEEE I CONF COMP VIS, P1097, DOI 10.1109/ICCV.2013.140
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2006, P ACMSIGKDD INT C KN
   [Anonymous], 2014, FULLY CONVOLUTIONAL
   [Anonymous], IEEE INT C IM PROC
   [Anonymous], INT J COMPUT VIS
   [Anonymous], IEEE C COMP VIS PATT
   Bai YC, 2012, PROC CVPR IEEE, P1854, DOI 10.1109/CVPR.2012.6247884
   Bashir FI, 2007, IEEE T MULTIMEDIA, V9, P58, DOI 10.1109/TMM.2006.886346
   Cao Z, 2007, LECT NOTES COMPUT SC, V4464, P129
   Chen X, 2010, INT CONF ACOUST SPEE, P5582, DOI 10.1109/ICASSP.2010.5495240
   Chen X, 2009, INT CONF ACOUST SPEE, P3545, DOI 10.1109/ICASSP.2009.4960391
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dyana A, 2010, IEEE T CIRC SYST VID, V20, P1080, DOI 10.1109/TCSVT.2010.2051367
   Feng BL, 2009, IEEE INT CON MULTI, P378, DOI 10.1109/ICME.2009.5202513
   Herbrich R, 2000, ADV NEUR IN, P115
   Hsieh JW, 2006, IEEE T CIRC SYST VID, V16, P396, DOI 10.1109/TCSVT.2006.869965
   Hu WM, 2007, IEEE T IMAGE PROCESS, V16, P1168, DOI 10.1109/TIP.2006.891352
   Hu WM, 2013, IEEE T PATTERN ANAL, V35, P1051, DOI 10.1109/TPAMI.2012.188
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Jiang X, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P756, DOI 10.1145/1571941.1572113
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Kratz L, 2012, IEEE T PATTERN ANAL, V34, P987, DOI 10.1109/TPAMI.2011.173
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lan T, 2012, LECT NOTES COMPUT SC, V7577, P129, DOI 10.1007/978-3-642-33783-3_10
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Lo Presti L, 2012, IEEE T MULTIMEDIA, V14, P346, DOI 10.1109/TMM.2011.2173323
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Mehran R, 2010, LECT NOTES COMPUT SC, V6313, P439
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Ng A. Y., 2002, Advances in Neural Information Processing Systems, P1473
   Qu W, 2005, IEEE IJCNN, P1800
   Shao J, 2015, PROC CVPR IEEE, P4657, DOI 10.1109/CVPR.2015.7299097
   Shao J, 2014, PROC CVPR IEEE, P2227, DOI 10.1109/CVPR.2014.285
   Solmaz B, 2012, IEEE T PATTERN ANAL, V34, P2064, DOI 10.1109/TPAMI.2012.123
   Su CW, 2007, IEEE T MULTIMEDIA, V9, P1193, DOI 10.1109/TMM.2007.902875
   Su H, 2013, IEEE T INF FOREN SEC, V8, P1575, DOI 10.1109/TIFS.2013.2277773
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Xu J, 2006, LECT NOTES COMPUT SC, V4212, P833
   Yunbo Cao, 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P186
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang YR, 2016, J STAT MECH-THEORY E, P1, DOI 10.1088/1742-5468/2016/11/113207
   Zhang ZM, 2011, PROC CVPR IEEE, P1497, DOI 10.1109/CVPR.2011.5995411
   Zhou BL, 2013, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR.2013.392
NR 45
TC 6
Z9 6
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 20167
EP 20195
DI 10.1007/s11042-017-4568-2
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500049
DA 2024-07-18
ER

PT J
AU Ansari, IA
   Pant, M
   Ahn, CW
AF Ansari, Irshad Ahmad
   Pant, Millie
   Ahn, Chang Wook
TI Artificial bee colony optimized robust-reversible image watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible watermarking; Slantlet Transform (SLT); Artificial bee
   colony; Medical image watermarking; Robustness
ID SCHEME; TRANSFORM; SVD; ALGORITHM
AB The ownership verification of digital images is possible by the help of image watermarking. Watermarking make the image secure towards unlawful use; but at the same time, it causes some information loss too. Medical and defense are few fields, where even a small change in data can be very problematic. So there is need of reliable and lossless watermarking schemes. The present study is focused on the development of lossless watermarking method that can fulfill five basic requirements (robustness, reversibility, invisibility, security and capacity) of ideal lossless watermarking scheme maximally. Arnold transformed watermark is embedded into the host to restrict any unauthorized access of watermark even after extraction. Slantlet transformed coefficients are known to be quite robust towards image processing attacks; so block wise Slantlet transform is employed to resist the maximum attacks and to ensure a decent capacity. Mean values of transformed coefficients are used for embedding to increase the robustness and imperceptibility. The spatial domain overflow/underflow (due to embedding) is taken care by a post processing to satisfy the reversibility requirements. The embedding strength of watermarking is controlled with the help of artificial bee colony (ABC) in order to get an optimal tradeoff between invisibility and robustness. The proposed scheme is applied to a range of images to show its applicability to different domains.
C1 [Ansari, Irshad Ahmad; Pant, Millie] Indian Inst Technol, Dept Appl Sci & Engn, Roorkee, Uttar Pradesh, India.
   [Ahn, Chang Wook] Sungkyunkwan Univ, Dept Comp Sci & Engn, 2066 Seobu Ro, Suwon 440746, South Korea.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Sungkyunkwan University (SKKU)
RP Ahn, CW (corresponding author), Sungkyunkwan Univ, Dept Comp Sci & Engn, 2066 Seobu Ro, Suwon 440746, South Korea.
EM 01.irshad@gmail.com; millifpt@iitr.ac.in; cwan@skku.edu
RI Pant, Millie/O-5740-2019; Ansari, Irshad Ahmad/AAT-2761-2020; PANT,
   Millie/C-9911-2018
OI Ansari, Irshad Ahmad/0000-0003-2991-0908; Ahn, Chang
   Wook/0000-0002-9902-5966
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Science, ICT & Future Planning
   [NRF-2015R1D1A1A02062017]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Science, ICT & Future Planning (NRF-2015R1D1A1A02062017).
CR Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   Ali M, 2014, SIGNAL PROCESS, V94, P545, DOI 10.1016/j.sigpro.2013.07.024
   An LL, 2012, IEEE T IMAGE PROCESS, V21, P3598, DOI 10.1109/TIP.2012.2191564
   An LL, 2012, NEUROCOMPUTING, V79, P1, DOI 10.1016/j.neucom.2011.08.019
   An LL, 2012, NEUROCOMPUTING, V77, P1, DOI 10.1016/j.neucom.2011.06.012
   [Anonymous], P 4 INT C SOFT COMP
   [Anonymous], INT J ADV RES COMPUT
   [Anonymous], 2014, P IEEE 80 VEH TECHN
   Ansari IA, 2016, ENG APPL ARTIF INTEL, V49, P114, DOI 10.1016/j.engappai.2015.12.004
   Ansari IA, 2016, INT J MACH LEARN CYB, V7, P1225, DOI 10.1007/s13042-015-0455-1
   Celebi ME, 2013, LECT NOTES COMPUT VI, V6
   De Vleeschouwer C, 2003, IEEE T MULTIMEDIA, V5, P97, DOI 10.1109/TMM.2003.809729
   De Vleeschouwer C, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P345, DOI 10.1109/MMSP.2001.962758
   Deng C, 2010, P 2 INT C INT MULT C, P57, DOI 10.1145/1937728.1937742
   Draa A, 2014, SWARM EVOL COMPUT, V16, P69, DOI 10.1016/j.swevo.2014.01.003
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Gao XB, 2009, SIGNAL PROCESS, V89, P2053, DOI 10.1016/j.sigpro.2009.04.015
   Hanbay K, 2014, APPL SOFT COMPUT, V21, P433, DOI 10.1016/j.asoc.2014.04.008
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   Karaboga D., 2005, Technical report-tr06
   Karaboga D, 2009, APPL MATH COMPUT, V214, P108, DOI 10.1016/j.amc.2009.03.090
   Lagzian S., 2011, International Journal of Intelligent Information Processing, V2, P22, DOI DOI 10.4156/IJIIP
   Li YC, 2010, DIGIT SIGNAL PROCESS, V20, P1116, DOI 10.1016/j.dsp.2009.10.025
   Lingling Wu, 2009, 2009 1st International Conference on Information Science and Engineering (ICISE 2009), P1164, DOI 10.1109/ICISE.2009.347
   Macq B., 2000, P EUSIPCO, P533
   Makbol NM, 2014, DIGIT SIGNAL PROCESS, V33, P134, DOI 10.1016/j.dsp.2014.06.012
   Ni ZC, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P2199, DOI 10.1109/ICME.2004.1394706
   Ni ZC, 2008, IEEE T CIRC SYST VID, V18, P497, DOI 10.1109/TCSVT.2008.918761
   Poljicak A, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3609010
   Potdar VA, 2005, 2005 3RD IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS (INDIN), P709
   Rawat S, 2011, AEU-INT J ELECTRON C, V65, P840, DOI 10.1016/j.aeue.2011.01.016
   Selesnick IW, 1998, PROCEEDINGS OF THE IEEE-SP INTERNATIONAL SYMPOSIUM ON TIME-FREQUENCY AND TIME-SCALE ANALYSIS, P53, DOI 10.1109/TFSA.1998.721359
   Selesnick IW, 1999, IEEE T SIGNAL PROCES, V47, P1304, DOI 10.1109/78.757218
   Sharma TK, 2013, 2013 IEEE SYMPOSIUM ON SWARM INTELLIGENCE (SIS), P95, DOI 10.1109/SIS.2013.6615165
   Thabit R, 2015, DIGIT SIGNAL PROCESS, V38, P77, DOI 10.1016/j.dsp.2014.12.005
   Thabit R, 2014, J SYST SOFTWARE, V88, P74, DOI 10.1016/j.jss.2013.09.033
   Wu SQ, 2011, STUD COMPUT INTELL, V346, P185
   Zou DK, 2006, IEEE T CIRC SYST VID, V16, P1294, DOI 10.1109/TCSVT.2006.881857
   Zou DK, 2004, 2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P195
NR 41
TC 26
Z9 26
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 18001
EP 18025
DI 10.1007/s11042-016-3680-z
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800024
DA 2024-07-18
ER

PT J
AU De, K
   Masilamani, V
AF De, Kanjar
   Masilamani, V.
TI No-reference image contrast measure using image statistics and random
   forest
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image quality assessment; Image contrast assessment; Random forests;
   L-moments; No-reference image quality assessment
ID REFERENCE QUALITY ASSESSMENT; NATURAL SCENE STATISTICS; BLUR ASSESSMENT;
   ENHANCEMENT
AB Image quality assessment is very crucial for certain image processing applications. Images can be distorted from multiple sources like a fault in sensors, camera shake, poor lighting, over-exposure etc. All these distortions reduce the visual quality of images. Assessing the quality of images can be done with the use of a reference image of the same scene or without it. Without the use of reference image, quality assessment is a very difficult task. Machine learning approaches are very common in no-reference image quality assessment. No reference strategies are very useful if the type of distortion is known. Contrast assessment is a very important application in image processing as poor contrast images are difficult for automated image processing. In this paper, we propose a no-reference image quality measure for images with respect to contrast using random forest regression and validate the results using standard datasets. Experimental results on standard datasets show that the proposed method demonstrates promising results when compared to existing no-reference techniques and the proposed method shows high correlation values with human opinion scores.
C1 [De, Kanjar; Masilamani, V.] IIITD&M Kancheepuram, Madras 600127, Tamil Nadu, India.
C3 Indian Institute of Information Technology, Design & Manufacturing,
   Kancheepuram
RP De, K (corresponding author), IIITD&M Kancheepuram, Madras 600127, Tamil Nadu, India.
EM kanjar.de@gmail.com; masila@iiitdm.ac.in
CR Ahumada A. J.  Jr., 1998, 1998 SID International Symposium. Digest of Technical Papers. Vol. 29, P1109
   [Anonymous], 1995, Studies in Optics
   [Anonymous], 2008, P C COL GRAPH IM VIS
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Boccignone G, 2001, IEEE T PATTERN ANAL, V23, P207, DOI 10.1109/34.908970
   Bong DBL, 2015, MULTIMED TOOLS APPL, V74, P7355, DOI 10.1007/s11042-014-1983-5
   Bong DBL, 2014, SIGNAL PROCESS-IMAGE, V29, P699, DOI 10.1016/j.image.2014.03.003
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Deng C, VISUAL SIGNAL QUALIT
   Du SL, 2016, DIGIT SIGNAL PROCESS, V55, P1, DOI 10.1016/j.dsp.2016.04.006
   Dziech A, 2014, MULTIMED TOOLS APPL, V68, P1, DOI 10.1007/s11042-013-1498-5
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   Ferraro M, 2004, REAL-TIME IMAGING, V10, P229, DOI 10.1016/j.rti.2004.05.004
   Flach P., 2012, Model ensembles,'' inMachine Learning: The Art and Scienceof Algorithms That Make Sense of Data
   Golestaneh S. Alireza, 2014, IEEE Signal Processing Letters, V21, P155, DOI 10.1109/LSP.2013.2296038
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Group VQE, 2000, VQEG FINAL REPORT VI
   Gu K, 2016, IEEE T CYBERNETICS, V46, P284, DOI 10.1109/TCYB.2015.2401732
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Hassen R, 2013, IEEE T IMAGE PROCESS, V22, P2798, DOI 10.1109/TIP.2013.2251643
   Hastie T., 2009, ELEMENTS STAT LEARNI
   Hastie T., 2001, Springer Series in Statistics, DOI [10.1007/978-0-387-84858-7, 10.1007/978-0-387-21606-5, DOI 10.1007/978-0-387-21606-5]
   HESS RF, 1983, PROC R SOC SER B-BIO, V217, P309, DOI 10.1098/rspb.1983.0012
   HOSKING JRM, 1992, AM STAT, V46, P186, DOI 10.2307/2685210
   Hosking JRM, 2006, J STAT PLAN INFER, V136, P193, DOI 10.1016/j.jspi.2004.06.004
   Jaiantilal A., 2009, Classification and regression by randomforest-matlab
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Leszczuk M, 2014, SIG PROCESS COMMUN, P2301, DOI 10.1109/SIU.2014.6830724
   Li CF, 2011, IEEE T NEURAL NETWOR, V22, P793, DOI 10.1109/TNN.2011.2120620
   Li LD, 2016, IEEE T CYBERNETICS, V46, P39, DOI 10.1109/TCYB.2015.2392129
   Li LD, 2014, IEEE SIGNAL PROC LET, V21, P122, DOI 10.1109/LSP.2013.2294333
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Liu TJ, 2015, PARABOOST METHOD IMA
   Liu XH, 2013, IEEE T IMAGE PROCESS, V22, P5226, DOI 10.1109/TIP.2013.2283400
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Narwaria M, 2010, IEEE T NEURAL NETWOR, V21, P515, DOI 10.1109/TNN.2010.2040192
   Pei SC, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440172
   PELI E, 1990, J OPT SOC AM A, V7, P2032, DOI 10.1364/JOSAA.7.002032
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   Pyatykh S, 2013, IEEE T IMAGE PROCESS, V22, P687, DOI 10.1109/TIP.2012.2221728
   Rizzi A, 2004, CGIV 2004: SECOND EUROPEAN CONFERENCE ON COLOR IN GRAPHICS, IMAGING, AND VISION - CONFERENCE PROCEEDINGS, P187
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Sheskin D.J., 2003, HDB PARAMETRIC NONPA, DOI [DOI 10.4324/9780203489536, 10.4324/9780203489536]
   Simone G, 2009, IS T SPIE ELECT IMAG
   Simone G, 2012, J VIS COMMUN IMAGE R, V23, P491, DOI 10.1016/j.jvcir.2012.01.008
   Tadmor Y, 2000, VISION RES, V40, P3145, DOI 10.1016/S0042-6989(00)00166-8
   Tremeau A, 2000, CIS P, P11
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Wang SQ, 2015, IEEE SIGNAL PROC LET, V22, P2387, DOI 10.1109/LSP.2015.2487369
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2006, Modern Image Quality Assessment, DOI 10.2200/S00010ED1V01Y200508IVM003
   Wu JJ, 2013, IEEE T IMAGE PROCESS, V22, P43, DOI 10.1109/TIP.2012.2214048
   Xu Long., 2015, Visual quality assessment by machine learning
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 63
TC 7
Z9 7
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18641
EP 18656
DI 10.1007/s11042-016-4335-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800024
DA 2024-07-18
ER

PT J
AU Kim, YK
   Lee, YH
   Moon, B
AF Kim, Young-Kyu
   Lee, Yong-Hwan
   Moon, Byungin
TI A study of partitioned DIMM tree management for multimedia server
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DIMM tree architecture; Multimedia server system; In-memory computing;
   Big memory server; Main memory
ID MEMORY; INTERCONNECT; PERFORMANCE
AB In-memory computing systems have been attracting considerable attention as a method for servicing high-quality multimedia contents. In-memory computing was intended to store entire data sets in the main memory of a computer to eliminate the need to access slow mechanical hard discs and increase the ability to process complex and large volumes of data. Prior studies have proposed a dual inline memory module (DIMM) tree architecture (DTA) as a new structure for implementing the in-memory computing system. The DTA can apply a partitioned DIMM tree policy to efficiently manage memory. However, the partitioned DIMM tree has several drawbacks, including hardware overhead resulting from additional fields in both the translation lookaside buffer (TLB) and the page table and the demand for an additional fast partition area for the fast partition page table (FPPT). To overcome these drawbacks, this paper proposes an advanced TLB management policy for the partitioned DIMM tree, DIMM tree TLB and two new partitioned DIMM tree management policies, fast-FPPT and slow-FPPT. We model the proposed policies using C language and verify them by special workloads in experiments employing a large-capacity memory system. The experimental results show how the proposed policies influence system performance and confirm that they overcome problems in the existing DTA. The simulations revealed a similarity between the performance of systems using the proposed policies and that of the existing DTA model. However, as the proposed policies demand a considerably lower hardware cost than the existing DTA model, the proposed policies are more practical.
C1 [Kim, Young-Kyu; Moon, Byungin] Kyungpook Natl Univ, Sch Elect Engn, Daegu, South Korea.
   [Lee, Yong-Hwan] Kumoh Natl Inst Technol, Sch Elect Engn, Gumi, South Korea.
C3 Kyungpook National University; Kumoh National University Technology
RP Moon, B (corresponding author), Kyungpook Natl Univ, Sch Elect Engn, Daegu, South Korea.
EM bihmoon@knu.ac.kr
RI Moon, Byungin/ACE-5308-2022
OI Moon, Byungin/0000-0002-8102-4818
FU Kyungpook National University; Samsung Electronics Co. Ltd.
FX This investigation was financially supported by Semiconductor Industry
   Collaborative Project between Kyungpook National University and Samsung
   Electronics Co. Ltd.
CR Al-Zoubi H., 2004, Proceedings of the 42nd annual Southeast regional conference, P267, DOI DOI 10.1145/986537.986601
   [Anonymous], 2009, TECH REP
   [Anonymous], 2012, INT WORKSHOP OPENMP
   Bhattacharjee A, 2009, INT CONFER PARA, P29, DOI 10.1109/PACT.2009.26
   Du Y, 2015, P HIGH PERF COMP ARC, P223
   Ganesh B, 2007, INT S HIGH PERF COMP, P109
   Jacob B, 1998, IEEE MICRO, V18, P60, DOI 10.1109/40.710872
   Jacob B, 2010, MEMORY SYSTEM CACHE
   Jaleel A, 2015, INT S HIGH PERF COMP, P343, DOI 10.1109/HPCA.2015.7056045
   Jang YJ, 2014, P 8 INT C ADV ENG CO, P86
   Jeddeloh J., 2012, 2012 IEEE Symposium on VLSI Technology, P87, DOI 10.1109/VLSIT.2012.6242474
   Kim G, 2013, INT CONFER PARA, P145, DOI 10.1109/PACT.2013.6618812
   Kim YK, 2015, INT J CONTROL AUTOM, V8, P43
   Kim YK, 2015, P INT C INT INF TECH, P29
   Loos P, 2011, BUS INFORM SYST ENG+, V3, P389, DOI 10.1007/s12599-011-0188-y
   Luk CK, 2005, ACM SIGPLAN NOTICES, V40, P190, DOI 10.1145/1064978.1065034
   Nieh J., 2000, Proceedings of the 10th International Workshop on Network and Operating System Support for Digital Audio and Video, P55
   Ousterhout J, 2011, COMMUN ACM, V54, P121, DOI 10.1145/1965724.1965751
   Pham B, 2014, P HIGH PERF COMP ARC, P15
   Qureshi MK, 2009, CONF PROC INT SYMP C, P24, DOI 10.1145/1555815.1555760
   Ramesh B., 2013, INT J COMPUT TECHNOL, V4, P97
   Saito H, 2003, INT J PARALLEL PROG, V31, P197, DOI 10.1023/A:1023086618401
   Sembrant A, 2013, P 46 ANN IEEE ACM IN, P49
   Sembrant A, 2014, CONF PROC INT SYMP C, P133, DOI 10.1109/ISCA.2014.6853203
   Shirale S, 2015, INT J COMPUT TECHNOL, V5, P21
   Shoro AG, 2015, SOFTW DATA ENG, V15, P7
   Silberschatz Abraham, 2012, OPERATING SYSTEM CON, V9th
   Therdsteerasukdi K, 2011, P 2011 IE 29 INT C C, P388
   Therdsteerasukdi K, 2012, IEEE J EM SEL TOP C, V2, P210, DOI 10.1109/JETCAS.2012.2193843
   Therdsteerasukdi K, 2012, ACM T ARCHIT CODE OP, V8, DOI 10.1145/2086696.2086730
   Vogt P., 2004, FULLY BUFFERED DIMM
   vom Brocke J, 2014, COMMUN ASSOC INF SYS, V34, P151
   Zhang H, 2015, IEEE T KNOWL DATA EN, V27, P1920, DOI 10.1109/TKDE.2015.2427795
   Zheng Y, 2004, P PERF AN SYST SOFTW, P86
NR 34
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 17937
EP 17954
DI 10.1007/s11042-016-3382-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800020
DA 2024-07-18
ER

PT J
AU Li, YL
   Bie, RF
   Zhang, CY
   Miao, ZJ
   Wang, YQ
   Wang, JJ
   Wu, H
AF Li, Yueli
   Bie, Rongfang
   Zhang, Chenyun
   Miao, Zhenjiang
   Wang, Yuqi
   Wang, Jiajing
   Wu, Hao
TI Optimized learning instance-based image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optimized learning instance; K-means clustering model; Spatial pyramid
   matching; Optimal instance distance
AB Image retrieval is a recognition technique in the field of computer vision. In most cases, high-quality retrieval is often supported by adequate learning instances. However, in the process of learning instance selection, some useless, repeated, invalid, and even mistaken learning instances are often selected. Low-quality instances not only add to the computing burden but also decrease the retrieval quality. In this study, we propose a learning instance optimization method. Initially, we classify the images into scene and object images by using the K-means clustering model. We use different methods to handle these two groups of images. For scene images, we use the Euclidean distance of the GIST descriptor to select the optimized learning instances. For object images, we use the improved spatial pyramid matching and optimal instance distance methods to select the optimized learning instances. Finally, we implement experiments using one large image database to check the effectiveness of our proposed algorithm. Results show that our method can not only improve retrieval quality but also decrease the number of learning instances.
C1 [Li, Yueli] Hebei Agr Univ, Coll Informat Sci & Technol, Baoding, Peoples R China.
   [Bie, Rongfang; Wu, Hao] Beijing Normal Univ, Coll Informat Sci & Technol, Beijing, Peoples R China.
   [Zhang, Chenyun] Stand & Metrol Res Inst CARS, Beijing, Peoples R China.
   [Miao, Zhenjiang; Wang, Yuqi; Wu, Hao] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
   [Wang, Jiajing] 1 Senior Middle Sch Wendeng Dist, Weihai, Peoples R China.
   [Wu, Hao] Lawrence Berkeley Natl Lab, Berkeley, CA 94720 USA.
C3 Hebei Agricultural University; Beijing Normal University; Beijing
   Jiaotong University; United States Department of Energy (DOE); Lawrence
   Berkeley National Laboratory
RP Wu, H (corresponding author), Beijing Normal Univ, Coll Informat Sci & Technol, Beijing, Peoples R China.; Wu, H (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.; Wu, H (corresponding author), Lawrence Berkeley Natl Lab, Berkeley, CA 94720 USA.
EM 10112056@bjtu.edu.cn
FU National Natural Science Foundation of China [61601033, 61371185,
   61401029, 61571049]; China Postdoctoral Science Foundation [212400201,
   2016M591109]; Fundamental Research Funds for the Central Universities
   [2014KJJCB32, 2013NT57, 2012LYB46]; SRF for ROCS, SEM [NSFC61273274,
   61370127, 61201158, NSFB4123104, FRFCU 2014JBZ004, Z131110001913143]; 
   [15ZR003]
FX This research is sponsored by National Natural Science Foundation of
   China (Nos.61601033,61371185, 61401029, 61571049), China Postdoctoral
   Science Foundation(212400201, 2016M591109), the Fundamental Research
   Funds for the Central Universities (Nos. 2014KJJCB32, 2013NT57,
   2012LYB46), Research Funds (15ZR003) and by SRF for ROCS, SEM,
   NSFC61273274, 61370127 and 61201158, NSFB4123104, FRFCU 2014JBZ004,
   Z131110001913143.
CR [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587658
   [Anonymous], 1977, Tech. rep.
   [Anonymous], 2009, Advances in neural information processing systems
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2015, ARXIV150102876
   [Anonymous], P INT C CONT BAS IM
   [Anonymous], 2011, IMAGE CLASSIFICATION
   [Anonymous], 1992, Active perception and robot vision, DOI [10.1007/978-3-642-77225-2_13, DOI 10.1007/978-3-642-77225-2_13]
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   [Anonymous], 2010, P 2010 ACM MULT WORK
   [Anonymous], 2014, Large scale object detection
   Bart E, 2008, COMPUTER VISION PATT, P1
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Carson C., 1999, Visual Information and Information Systems. Third International Conference, VISUAL'99. Proceedings (Lecture Notes in Computer Science Vol.1614), P509
   Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPR.2009.5206800, 10.1109/CVPRW.2009.5206800]
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Fergus R, 2010, LECT NOTES COMPUT SC, V6311, P762, DOI 10.1007/978-3-642-15549-9_55
   Fergus Rob, 2009, Advances in Neural Information Processing Systems, P522
   Griffin Gregory, 2007, CALTECH 256 OBJECT C
   Hays J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239455
   Ioffe S., 2015, P INT C MACH LEARN, VVolume 1, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Jaakkola TS, 1999, ADV NEUR IN, V11, P487
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Kanimozhi T, 2015, NEUROCOMPUTING, V151, P1099, DOI 10.1016/j.neucom.2014.07.078
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Lin YQ, 2011, PROC CVPR IEEE, P1689, DOI 10.1109/CVPR.2011.5995477
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maji S, 2009, IEEE I CONF COMP VIS, P40, DOI 10.1109/ICCV.2009.5459203
   Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Toyama K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P50, DOI 10.1109/ICCV.2001.937599
   Wu H, 2015, IET COMPUT VIS, V9, P419, DOI 10.1049/iet-cvi.2014.0094
   Wu H, 2015, NEUROCOMPUTING, V159, P157, DOI 10.1016/j.neucom.2014.12.088
   Wu H, 2015, VISUAL COMPUT, V31, P367, DOI 10.1007/s00371-014-0931-8
   Zha Z- J, 2008, COMPUTER VISION PATT, P1
   Zhang XF, 2015, IEEE T MED IMAGING, V34, P496, DOI 10.1109/TMI.2014.2361481
NR 45
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16749
EP 16766
DI 10.1007/s11042-016-3950-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100031
DA 2024-07-18
ER

PT J
AU Pellegrin, L
   Escalante, HJ
   Montes-y-Gómez, M
   González, FA
AF Pellegrin, Luis
   Jair Escalante, Hugo
   Montes-y-Gomez, Manuel
   Gonzalez, Fabio A.
TI Local and global approaches for unsupervised image annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised image annotation; Image annotation framework; Image
   annotation as AQE
AB Image annotation is the task of assigning keywords to images with the goal of facilitating their organization and accessibility options (e.g., searching by keywords). Traditional annotation methods are based on supervised learning. Although being very effective, these methods require of large amounts of manually labeled images, and are limited in the sense that images can only be labeled with concepts seen during the training phase. Unsupervised automatic image annotation (UAIA) methods, on the other hand, neglect strongly-labeled images and instead rely on huge collections of unstructured text containing images for the annotation. In addition to not requiring labeled images, unsupervised techniques are advantageous because they can assign (virtually) any concept to an image. Despite these benefits, unsupervised methods have not been widely studied in image annotation, a reason for this is the lack of a reference framework for UAIA. In this line, this paper introduces two effective methods for UAIA in the context of a common framework inspired in the way a query is expanded throughout Automatic Query Expansion (AQE) in information retrieval. On the one hand, we describe a local method that processes text information associated to images retrieved when using the image to annotate as query, several methods from the state of the art can be described under this formulation. On the other hand, we propose a global method that pre-process offline the reference collection to identify visual-textual associations that are later used for annotation. Both methods are extensively evaluated in benchmarks for large-scale UAIA. Experimental results show the competitiveness of both strategies when compared to the state of the art. We foresee the AQE-based framework will pave the way for the development of alternative and effective methods for UAIA.
C1 [Pellegrin, Luis; Jair Escalante, Hugo; Montes-y-Gomez, Manuel] Inst Nacl Astrofis Opt & Electr, Dept Comp Sci, Puebla, Mexico.
   [Gonzalez, Fabio A.] Univ Nacl Colombia, Bogota, Colombia.
C3 Instituto Nacional de Astrofisica, Optica y Electronica; Universidad
   Nacional de Colombia
RP Pellegrin, L (corresponding author), Inst Nacl Astrofis Opt & Electr, Dept Comp Sci, Puebla, Mexico.
EM luis.pellegrin@gmail.com; hugojair@inaoep.mx; mmontesg@inaoep.mx;
   fagonzalezo@unal.edu.co
RI Escalante, Hugo Jair/AEP-0896-2022; Gonzalez, Fabio A/B-9502-2008
OI Escalante, Hugo Jair/0000-0003-4603-3513; Luis Pellegrin,
   Luis/0000-0002-4898-1632
FU CONACYT [CB-2014-241306, 214764]; LACCIR programme [R1212LAC006]
FX This work was supported by CONACYT under project grant CB-2014-241306
   (Clasificacion y recuperacion de imagenes mediante tecnicas de mineria
   de textos). Also this work was partially supported by the LACCIR
   programme under project ID R1212LAC006 and supported by CONACyT under
   scholarship No. 214764. The authors would like to thank Jorge Vanegas
   and John Arevalo from UNAL for their support on the extraction of CNN
   visual features. The authors would like to thank Mauricio Villegas for
   his support on evaluation of considered datasets.
CR [Anonymous], 2012, CIRCULAR POLARIZATIO
   [Anonymous], 2014, P CLEF SHEFF UK
   [Anonymous], CLEF 2013 EV LAB WOR
   [Anonymous], CLEF 2014 EV LAB WOR
   [Anonymous], 2006, P IEEE COMPUTER SOC, DOI DOI 10.1109/CVPR.2006.95
   [Anonymous], CLEF 2012 EV LAB WOR
   [Anonymous], 2003, P 11 ACM INT C MULT
   [Anonymous], CLEF 2013 EV LAB WOR
   [Anonymous], INT C COMP VIS
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], CLEF 2013 EV LAB WOR
   [Anonymous], CLEF 2013 EV LAB WOR
   [Anonymous], 2014, TECH REP
   [Anonymous], CLEF 2014 EV LAB WOR
   [Anonymous], CEUR WS P
   [Anonymous], TMG MATLAB TOOLBOX G
   [Anonymous], CLEF 2013 C VAL SPAI
   [Anonymous], 2014, CLEF WORKING NOTES
   [Anonymous], 2008 IEEE COMP SOC C
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], ABS14094627 CORR
   [Anonymous], CLEF 2014 EV LAB WOR
   [Anonymous], UCI REPOSITORY MACHI
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Caicedo JC, 2012, NEUROCOMPUTING, V76, P50, DOI 10.1016/j.neucom.2011.04.037
   Carpineto C, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071390
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Divvala SK, 2014, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2014.412
   Escalante HJ, 2012, INFORM RETRIEVAL, V15, P1, DOI 10.1007/s10791-011-9170-z
   Feng Yansong., 2008, P ACL 08 HLT, P272
   Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559
   Guillaumin M, 2009, INT C COMP VIS ICCV
   Hanbury A, 2008, J VISUAL LANG COMPUT, V19, P617, DOI 10.1016/j.jvlc.2008.01.002
   Escalante HJ, 2012, COMPUT SIST, V16, P121
   Escalante HJ, 2011, COMPUT VIS IMAGE UND, V115, P787, DOI 10.1016/j.cviu.2011.02.002
   Jia Y., 2014, P 22 ACM INT C MULT, P675
   Joshi D, 2006, ACM T MULTIM COMPUT, V2, P68, DOI 10.1145/1126004.1126008
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Liu MF, 2016, NEUROCOMPUTING, V181, P64, DOI 10.1016/j.neucom.2015.06.099
   Liu M, 2016, CIVIL ENGINEERING AND URBAN PLANNING IV, P127
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo Y, 2015, IEEE T IMAGE PROCESS, V24, P2355, DOI 10.1109/TIP.2015.2421309
   Luo Y, 2013, IEEE T IMAGE PROCESS, V22, P523, DOI 10.1109/TIP.2012.2218825
   Makadia A, 2010, INT J COMPUT VISION, V90, P88, DOI 10.1007/s11263-010-0338-6
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Mitra M., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P206, DOI 10.1145/290941.290995
   Novak D, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1039, DOI 10.1145/2766462.2767868
   Pellegrin L, 2014, LECT NOTES ARTIF INT, V8856, P151, DOI 10.1007/978-3-319-13647-9_16
   Putthividhya D, 2010, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2010.5540000
   Reshma IA, 2014, 2014 INTERNATIONAL CONFERENCE OF ADVANCED INFORMATICS: CONCEPT, THEORY AND APPLICATION (ICAICTA), P226, DOI 10.1109/ICAICTA.2014.7005945
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sivic J, 2006, LECT NOTES COMPUT SC, V4170, P127
   Tao DP, 2013, IEEE T MULTIMEDIA, V15, P833, DOI 10.1109/TMM.2013.2238909
   Tuytelaars T., 2008, LOCAL INVARIANT FEAT
   Winn J., 2005, Int. Conf. on Computer Vision, P18001807
   Yonggang Qiu, 1993, SIGIR Forum, P160
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
NR 59
TC 9
Z9 9
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16389
EP 16414
DI 10.1007/s11042-016-3918-9
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100015
DA 2024-07-18
ER

PT J
AU Arbelaiz, A
   Moreno, A
   Kabongo, L
   Garcia-Alonso, A
AF Arbelaiz, Ander
   Moreno, Aitor
   Kabongo, Luis
   Garcia-Alonso, Alejandro
TI X3DOM volume rendering component for web content developers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Volume rendering; WebGL; Declarative 3D; X3DOM; X3D
AB We present a real-time volume rendering component for the Web, which provides a set of illustrative and non-photorealistic styles. Volume data is used in many scientific disciplines, requiring the visualization of the inner data, features for enhancing extracted characteristics or even coloring the volume. The Medical Working Group of X3D published a volume rendering specification. The next step is to build a component that realizes the functionalities defined by the specification. We have designed and built a volume rendering component integrated in the X3DOM framework. This component allows content developers to use the X3D specification. It combines and applies multiple rendering styles to several volume data types, offering a suitable tool for declarative volume rendering on the Web. As we show in the result section, the proposed component can be used in many fields that requires the visualization of multi-dimensional data, such as in medical and scientific fields. Our approach is based on WebGL and X3DOM, providing content developers with an easy and flexible declarative way of sharing and visualizing volumetric content over the Web.
C1 [Arbelaiz, Ander; Moreno, Aitor; Kabongo, Luis] Vicomtech IK4, Donostia San Sebastian 20009, Spain.
   [Kabongo, Luis] Biodonostia Hlth Res Inst, Donostia San Sebastian, Spain.
   [Garcia-Alonso, Alejandro] Univ Basque Country, Donostia San Sebastian, Spain.
C3 Instituto de Investigacion Sanitaria Biogipuzkoa; University of Basque
   Country
RP Arbelaiz, A (corresponding author), Vicomtech IK4, Donostia San Sebastian 20009, Spain.
EM aarbelaiz@vicomtech.org; amoreno@vicomtech.org; lkabongo@vicomtech.org;
   alex.galonso@ehu.es
OI Moreno, Aitor/0000-0002-9088-7332; Arbelaiz, Ander/0000-0002-1439-2178
CR [Anonymous], VOLUME RAY CASTING W, DOI [10.5772/34878, DOI 10.5772/34878]
   [Anonymous], IEEE VR WORKSH IMM V
   [Anonymous], FRONTIERS NEUROINFOR
   [Anonymous], OSG JS WEBGL FRAMEWO
   [Anonymous], EXT 3D X2D SPEC
   [Anonymous], 1177 VIG TECHN ADV R
   [Anonymous], COLL VOL DAT
   [Anonymous], EXT 3D X3D BAS EXAMP
   [Anonymous], SPIE MED IMAGING
   [Anonymous], X3DOM
   [Anonymous], 2014, 3 JS JAVASCRIPT 3D L
   [Anonymous], INDIAN J RADIOL IMAG
   [Anonymous], 1977, P 4 ANN C COMPUTER G, DOI DOI 10.1145/965141.563893
   [Anonymous], MATH VISUALIZATION
   [Anonymous], X3DOM GITHUB REPOSIT
   [Anonymous], P 14 IEEE VIS 2003 V
   Behr J., 2009, WEB3D 09 P 14 INT C, P127, DOI [DOI 10.1145/1559764.1559784, 10.1145/1559764.1559784]
   Bruckner S, 2007, COMPUT GRAPH FORUM, V26, P715, DOI 10.1111/j.1467-8659.2007.01095.x
   Catuhe D, 2014, Babylon. js a 3D engine based on webgl and javascript
   Congote J., 2011, P 16 INT C 3D WEB TE, P137, DOI [DOI 10.1145/2010425.2010449, 10.1145/2010425.2010449]
   Congote J, 2012, WEB3D 2012, P179
   Crassin C., 2009, P 2009 S INT 3D GRAP, P15, DOI [10.1145/1507149.1507152, DOI 10.1145/1507149.1507152]
   Decaudin Philippe, 1996, Research Report 2919
   Ebert D, 2000, IEEE VISUAL, P195, DOI 10.1109/VISUAL.2000.885694
   Gobbetti E, 2008, VISUAL COMPUT, V24, P797, DOI 10.1007/s00371-008-0261-9
   Gooch A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P447, DOI 10.1145/280814.280950
   KAJIYA JT, 1984, P SIGGRAPH 84, P165, DOI DOI 10.1145/800031.808594
   Kniss J, 2002, IEEE T VIS COMPUT GR, V8, P270, DOI 10.1109/TVCG.2002.1021579
   LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511
   Li W., 2003, VIS 03 P 14 IEEE VIS, P42
   Lu AD, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P211, DOI 10.1109/VISUAL.2002.1183777
   Lum E.B., 2002, P 2 INT S NONPHOTORE, P67
   Mobeen MM, 2012, IEEE I C EMBED SOFTW, P381, DOI 10.1109/HPCC.2012.58
   Movania MM, 2014, WIRELESS PERS COMMUN, V76, P795, DOI 10.1007/s11277-013-1354-y
   Noguera Jose M., 2012, Proceedings of the International Conference on Computer Graphics Theory and Applications (GRAPP 2012) and International Conference on Information Visualization Theory and Applications (IVAPP 2012), P447
   Noguera JM, 2012, WSCG'2012, CONFERENCE PROCEEDINGS, PTS I & II, P105
   Polys N, 2012, Issues in Information Systems, V13, P40
   Praun E, 2001, COMP GRAPH, P581, DOI 10.1145/383259.383328
   Stegmaier S, 2005, VOLUME GRAPHICS 2005, P187
   WALLIS JW, 1989, IEEE T MED IMAGING, V8, P297, DOI 10.1109/42.41482
   Wong PC, 2004, IEEE COMPUT GRAPH, V24, P20
   Yang F, 2015, MULTIMED TOOLS APPL, V74, P7621, DOI 10.1007/s11042-014-1994-2
   Zhou ZG, 2015, MULTIMED TOOLS APPL, V74, P10243, DOI 10.1007/s11042-014-2162-4
NR 43
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13425
EP 13454
DI 10.1007/s11042-016-3743-1
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900023
DA 2024-07-18
ER

PT J
AU Heydari, M
   Sadough, SMS
   Chaudhry, SA
   Farash, MS
   Mahmood, K
AF Heydari, Mohammad
   Sadough, Seyed Mohammad Sajad
   Chaudhry, Shehzad Ashraf
   Farash, Mohammad Sabzinejad
   Mahmood, Khalid
TI An improved one-to-many authentication scheme based on bilinear pairings
   with provable security for mobile pay-TV systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile pay-TV systems; Authentication scheme; Impersonation attack;
   Elliptic curves; Bilinear pairings; Provable security
ID KEY EXCHANGE PROTOCOL; ACCESS-CONTROL; NON-REPUDIATION; EFFICIENT;
   PRIVACY
AB In 2012, Wang and Qin proposed an authentication mechanism in order to get access control for mobile pay-TV organization to enhance the Sun and Leu's technique. Wang and Qin declared that their technique satisfies the security expectations or requirements intended for mobile pay-TV system. However, this work indicates that Wang and Qin's scheme suffers from a nontrivial weakness. Successful impersonation attack is easily possible from an adversary who can impersonate mobile set (MS) to cheat the head-end system (HS). An adversary does not even need secret information to do so. As a remedy, we proposed an enhanced authentication technique for mobile pay-TV systems by taking a slight change in Wang and Qin's scheme. The proposed scheme maintains the merits and covers the demerits of the previous schemes.
C1 [Farash, Mohammad Sabzinejad] Kharazmi Univ, Fac Math Sci & Comp, Tehran, Iran.
   [Chaudhry, Shehzad Ashraf; Mahmood, Khalid] Int Islamic Univ Islamabad, Dept Comp Sci & Software Engn, Islamabad, Pakistan.
   [Sadough, Seyed Mohammad Sajad] Shahid Beheshti Univ, Dept Elect Engn, GC, Tehran 1983963113, Iran.
C3 Kharazmi University; International Islamic University, Pakistan; Shahid
   Beheshti University
RP Farash, MS (corresponding author), Kharazmi Univ, Fac Math Sci & Comp, Tehran, Iran.
EM m_heydari@sbu.ac.ir; s_sadough@sbu.ac.ir; shahzad@iiu.edu.pk;
   sabzinejad@khu.ac.ir; khalid.phdcs74@iiu.edu.pk
RI heydari, mohammad/K-8170-2013; Farash, Mohammad sabzinejad/A-2667-2015;
   Mahmood, Khalid/AAE-9552-2020; Chaudhry, Shehzad/Y-3430-2019
OI Farash, Mohammad sabzinejad/0000-0001-5821-4237; Mahmood,
   Khalid/0000-0001-5046-7766; Chaudhry, Shehzad/0000-0002-9321-6956;
   Sadough, Seyed Mohammad Sajad/0000-0002-4386-9019; Heydari, Mohammad
   Hossein/0000-0001-6764-4394
CR [Anonymous], 1992, CONDITIONAL ACCESS B
   [Anonymous], ISC INT J INF SECUR
   Bayat M., 2010, Proceedings 2010 IEEE/IFIP 8th International Conference on Embedded and Ubiquitous Computing (EUC 2010), P578, DOI 10.1109/EUC.2010.93
   Chen TH, 2011, J NETW COMPUT APPL, V34, P1131, DOI 10.1016/j.jnca.2010.11.005
   COUTROT F, 1989, IEEE T CONSUM ELECTR, V35, P464, DOI 10.1109/30.44305
   Digital Video Broadcasting (DVB), 2007, 102474 ETSI TS
   Farash M.S., 2014, INT J NETW SECUR, V16, P143
   Farash M.S., 2012, IACSIT INT J ENG TEC, V4, P321
   Farash MS, 2014, J SUPERCOMPUT, V70, P1002, DOI 10.1007/s11227-014-1273-z
   Farash MS, 2014, J SUPERCOMPUT, V70, P987, DOI 10.1007/s11227-014-1272-0
   Farash MS, 2014, J SUPERCOMPUT, V69, P395, DOI 10.1007/s11227-014-1170-5
   Farash MS, 2014, INF TECHNOL CONTROL, V43, P143, DOI 10.5755/j01.itc.43.2.3790
   Farash MS, 2014, NONLINEAR DYNAM, V77, P399, DOI 10.1007/s11071-014-1304-6
   Farash MS, 2014, NONLINEAR DYNAM, V76, P1203, DOI 10.1007/s11071-013-1204-1
   Farash MS, 2013, INF TECHNOL CONTROL, V42, P333, DOI 10.5755/j01.itc.42.4.2496
   Farash MS, 2013, COMPUT ELECTR ENG, V39, P530, DOI 10.1016/j.compeleceng.2012.09.004
   Farash MS, 2011, COMPUT ELECTR ENG, V37, P199, DOI 10.1016/j.compeleceng.2011.02.007
   Huang XY, 2012, SECUR COMMUN NETW, V5, P1248, DOI 10.1002/sec.620
   Kilinc HH, 2014, IEEE COMMUN SURV TUT, V16, P1005, DOI 10.1109/SURV.2013.091513.00050
   Kim JY, 2010, IEEE T MULTIMEDIA, V12, P337, DOI 10.1109/TMM.2010.2046362
   Lee NY, 2000, IEEE T CONSUM ELECTR, V46, P20, DOI 10.1109/30.826376
   Liu XF, 2013, SECUR COMMUN NETW, V6, P361, DOI 10.1002/sec.584
   Pointcheval D, 1996, LECT NOTES COMPUT SC, V1070, P387
   Song R, 2003, IEEE T CONSUM ELECTR, V49, P408, DOI 10.1109/TCE.2003.1209533
   Sun HM, 2008, IEEE T MULTIMEDIA, V10, P1109, DOI 10.1109/TMM.2008.2001381
   Sun HM, 2009, IEEE T MULTIMEDIA, V11, P947, DOI 10.1109/TMM.2009.2021790
   Wang H, 2012, IET INFORM SECUR, V6, P281, DOI 10.1049/iet-ifs.2011.0281
   Wang SY, 2008, IEEE T MULTIMEDIA, V10, P480, DOI 10.1109/TMM.2008.917417
   Yang JH, 2009, COMPUT SECUR, V28, P138, DOI 10.1016/j.cose.2008.11.008
   Yeh LY, 2012, IEEE T MULTIMEDIA, V14, P1690, DOI 10.1109/TMM.2012.2199290
   Yeung SF, 2005, IEEE T MULTIMEDIA, V7, P330, DOI 10.1109/TMM.2005.843361
NR 31
TC 4
Z9 5
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 14225
EP 14245
DI 10.1007/s11042-016-3825-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800026
DA 2024-07-18
ER

PT J
AU Kao, CC
AF Kao, Chi-Chou
TI Stereoscopic image generation with depth image based rendering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image generation; 3D; DIBR; Pre-processing; Hole-filling
ID MULTIVIEW; ARCHITECTURE; 3DTV
AB In this paper, we proposed stereoscopic image generation methods of adjusting the depth value of edge pixels and improved hole filling procedures. For the conventional system, the smooth of depth map can reduce the incidence of image holes, but cause geometric distortions of the image depth. To solve the problems, the depth map is first expanded to refine the accuracy of image depth and the quality of images. Next, we derive a hardware-oriented method for 3D warping. Finally, appropriate blocks are searched to enhance the performance of image by improving hole-filling procedures. The experimental results demonstrate the proposed methods have great performance and practicability.
C1 [Kao, Chi-Chou] Natl Univ Tainan, Dept Comp Sci & Informat Engn, Tainan, Taiwan.
C3 National University Tainan
RP Kao, CC (corresponding author), Natl Univ Tainan, Dept Comp Sci & Informat Engn, Tainan, Taiwan.
EM cckao@mail.nutn.edu.tw
FU National Science Council, R.O.C. [MOST 104-2221-E-024-001]
FX This work was supported in part by the National Science Council, R.O.C.,
   under Grant MOST 104-2221-E-024-001
CR [Anonymous], 2010, THESIS
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Bosc E., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2597, DOI 10.1109/ICIP.2011.6116196
   Chen HJ, 2010, IEEE INT SYMP CIRC S, P1165, DOI 10.1109/ISCAS.2010.5537312
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Gortler S.J., 1996, ACM T GRAPH, V23, P43
   Kang SB, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P13, DOI 10.1109/ICIP.2000.899212
   Kubota A, 2007, IEEE SIGNAL PROC MAG, V24, P10, DOI 10.1109/MSP.2007.905873
   KwangHee Jung, 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P237
   Mark W. R., 1999, THESIS
   McMillan Leonard, 1997, THESIS
   Mori Y, 2009, SIGNAL PROCESS-IMAGE, V24, P65, DOI 10.1016/j.image.2008.10.013
   Müller K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/438148
   Ndjiki-Nya P, 2011, IEEE T MULTIMEDIA, V13, P453, DOI 10.1109/TMM.2011.2128862
   Oliveira M., 2000, THESIS
   Sharma M, 2014, J VIS COMMUN IMAGE R, V25, P599, DOI 10.1016/j.jvcir.2013.07.012
   Shum HY, 2000, PROC SPIE, V4067, P2, DOI 10.1117/12.386541
   Shum HY, 1999, COMP GRAPH, P299, DOI 10.1145/311535.311573
   Smolic A, 2008, IEEE IMAGE PROC, P2448, DOI 10.1109/ICIP.2008.4712288
   Solh M, 2012, IEEE J-STSP, V6, P495, DOI 10.1109/JSTSP.2012.2204723
   Sun SP, 2011, MULTIMED TOOLS APPL, V52, P5, DOI 10.1007/s11042-009-0454-x
   Tam WJ, 2004, PROC SPIE, V5599, P162, DOI 10.1117/12.583105
   Wang D, 2015, INT J ADV ROBOT SYST, V12, DOI 10.5772/60060
   Wang LH, 2015, MULTIMED TOOLS APPL, V74, P9529, DOI 10.1007/s11042-014-2133-9
   Xu XY, 2012, INT CONF ACOUST SPEE, P805, DOI 10.1109/ICASSP.2012.6288006
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
   Yang SB, 2012, INT J IMAGE GRAPH, V12, DOI 10.1142/S0219467812500131
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
   Zinger S, 2009, 17 INT C COMP GRAPH, P313
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 30
TC 10
Z9 11
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 12981
EP 12999
DI 10.1007/s11042-016-3733-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900001
DA 2024-07-18
ER

PT J
AU Li, F
   Jiao, DD
   Shi, GM
   Niu, Y
   Fan, CX
   Xie, XM
AF Li, Fu
   Jiao, Dandan
   Shi, Guangming
   Niu, Yi
   Fan, Chunxiao
   Xie, Xuemei
TI An AR based fast mode decision for H.265/HEVC intra coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Auto regression; Fastmode decision; H.265/HEVC; Intra coding
ID SIZE DECISION; ALGORITHM
AB As a critical technique to raise coding efficiency in H.265/HEVC (H.265/High Efficiency Video Coding), the number of prediction modes for intra coding is much larger than that in H.264/AVC. However, the large number of prediction modes also leads to high complexity. In this paper, an AR (Auto Regression) based fast mode decision method for H.265/HEVC intra coding is proposed, including an AR based fast mode selection and an MPM (Most Probable Mode) joint fast mode selection method. Considering the correlation between SATD (Sum of Absolute Transformed Differences) cost and RD (Rate-Distortion) cost, we establish a selective function controlled by an adaptive parameter which is acquired by an AR model. According to the distribution of the SATD cost, the selective function can decide which modes can be discarded and which modes can be used for the FMD (Fine Mode Decision). In addition, in order to further reduce the number of candidate modes for FMD, an MPM joint fast mode selection method is presented based on the relationship between MPMs and candidate modes. Experimental results show that just in PU layer, the proposed AR based fast intra mode decision method can save encoding time by 32 % with negligible coding loss in all-intra main configuration compared to the intra mode decision of HM13.0.
C1 [Li, Fu; Jiao, Dandan; Shi, Guangming; Niu, Yi; Fan, Chunxiao; Xie, Xuemei] Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Chinese Minist Educ, Sch Elect Engn, Xian, Peoples R China.
C3 Xidian University
RP Li, F (corresponding author), Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Chinese Minist Educ, Sch Elect Engn, Xian, Peoples R China.
EM fuli@mail.xidian.edu.cn
OI Xie, Xuemei/0000-0001-7857-0845
FU National Science Foundation of China [61100155, 61227004, 61301288];
   Fundamental Research Funds of the Central Universities of China
   [K5051302096, JB140207]; Natural Science Basic Research Plan in Shaanxi
   Province of China [2016ZDJC-08];  [50-Y20A08-0508-15/16]
FX This work was supported in part by the National Science Foundation of
   China under Grants (No. 61100155, 61227004 and 61301288), the
   Fundamental Research Funds of the Central Universities of China (No.
   K5051302096, JB140207), Natural Science Basic Research Plan in Shaanxi
   Province of China (Program No. 2016ZDJC-08), and project
   50-Y20A08-0508-15/16.
CR Alwani M, 2013, IEEE DATA COMPR CONF, P476, DOI 10.1109/DCC.2013.58
   [Anonymous], 2014, CONS EL ISCE 2014 18
   [Anonymous], JCTVCA205
   [Anonymous], JCTVCH0342
   [Anonymous], 2013, P 11 JCT VC M
   [Anonymous], ITU T VCEG 13 M
   Bossen F., 2013, JCTVCL1100
   Bross B., 2012, JCTVCH1003
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Chung B, 2014, PROC IEEE ISCE, P1
   Ding WP, 2014, INT C DIGITAL HOME, P70, DOI 10.1109/ICDH.2014.21
   Fang CM, 2013, I SYMP CONSUM ELECTR, P61
   Hu N, 2015, IEEE T CIRC SYST VID, V25, P1521, DOI 10.1109/TCSVT.2015.2395772
   Kim J, 2013, IEEE ICCE, P637, DOI 10.1109/ICCE.2013.6487050
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Min J., 2010, JCTVCB100
   Sangkwon Na, 2014, 2014 IEEE International Conference on Consumer Electronics (ICCE), P11, DOI 10.1109/ICCE.2014.6775887
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Shen XL, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-4
   Shen XL, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P453, DOI 10.1109/PCS.2012.6213252
   Shi YF, 2013, IEEE INT WORKSH MULT, P429, DOI 10.1109/MMSP.2013.6659327
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Wei Jiang, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1836, DOI 10.1109/CECNet.2012.6201851
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhang MM, 2012, IEEE IMAGE PROC, P221, DOI 10.1109/ICIP.2012.6466835
   Zhao WJ, 2015, IEEE T CIRC SYST VID, V25, P1651, DOI 10.1109/TCSVT.2015.2395751
NR 27
TC 4
Z9 4
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13107
EP 13125
DI 10.1007/s11042-016-3737-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900007
DA 2024-07-18
ER

PT J
AU Calisir, F
   Bastan, M
   Ulusoy, O
   Güdükbay, U
AF Calisir, Fatih
   Bastan, Muhammet
   Ulusoy, Ozgur
   Gudukbay, Ugur
TI Mobile multi-view object image search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile visual search; Multi-view search; Bag of visual words; Fusion
AB High user interaction capability of mobile devices can help improve the accuracy of mobile visual search systems. At query time, it is possible to capture multiple views of an object from different viewing angles and at different scales with the mobile device camera to obtain richer information about the object compared to a single view and hence return more accurate results. Motivated by this, we propose a new multi-view visual query model on multi-view object image databases for mobile visual search. Multi-view images of objects acquired by the mobile clients are processed and local features are sent to a server, which combines the query image representations with early/late fusion methods and returns the query results. We performed a comprehensive analysis of early and late fusion approaches using various similarity functions, on an existing single view and a new multi-view object image database. The experimental results show that multi-view search provides significantly better retrieval accuracy compared to traditional single view search.
C1 [Calisir, Fatih; Ulusoy, Ozgur; Gudukbay, Ugur] Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
   [Bastan, Muhammet] Turgut Ozal Univ, Dept Comp Engn, TR-06010 Ankara, Turkey.
C3 Ihsan Dogramaci Bilkent University; Turgut Ozal University
RP Güdükbay, U (corresponding author), Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
EM gudukbay@cs.bilkent.edu.tr
RI Gudukbay, Ugur/F-1012-2011; Ulusoy, Ozgur/KVY-4530-2024
OI Gudukbay, Ugur/0000-0003-2462-6959; Ulusoy, Ozgur/0000-0002-6887-3778
FU Scientific and Technological Research Council of Turkey (TUBITAK) [BIDEB
   2228-A]
FX The first author was supported by The Scientific and Technological
   Research Council of Turkey (TUBITAK) under BIDEB 2228-A Graduate
   Scholarship.
CR A9.com Inc., 2015, AM FLOW
   [Anonymous], 2015, COMPUTER SCI
   [Anonymous], 2011, INT J COMPUT APPL
   [Anonymous], INT C COMP VIS
   Arandjelovic R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.92
   Babenko A, 2015, AGGREGATING DEEP CON
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Cha S.-H., 2007, Int. J. Math. Models Methods Appl. Sci., V1, P300
   Chen DM, 2014, IEEE MULTIMEDIA, V21, P14, DOI 10.1109/MMUL.2013.46
   Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610
   Cummins M, 2015, PLINKART
   DigiMarc Co, 2015, DIG DISC
   Girod B, 2011, IEEE MULTIMEDIA, V18, P86, DOI 10.1109/MMUL.2011.48
   Girod B, 2011, IEEE SIGNAL PROC MAG, V28, P61, DOI 10.1109/MSP.2011.940881
   Google Inc, 2015, GOOGL GOGGL
   Griffin G., 2007, Tech. Rep.
   Guan T, 2014, IEEE MULTIMEDIA, V21, P32, DOI 10.1109/MMUL.2013.31
   Gunawardana A, 2009, J MACH LEARN RES, V10, P2935
   Itseez, 2015, OPENCV OP SOURC COMP
   Ji RR, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2348816.2348819
   Lampert CH, 2009, IEEE I CONF COMP VIS, P987, DOI 10.1109/ICCV.2009.5459359
   Lee C.-H., 2012, International Journal of Advanced Information Technologies, V5, P266
   Li D., 2015, Proceedings of the 6th ACM Multimedia Systems Conference, MMSys '15, P25
   Mazloom M., 2013, Proceedings of the ACM Multimedia Conference, MM'13, P609
   Min WQ, 2014, IEEE T MULTIMEDIA, V16, P623, DOI 10.1109/TMM.2014.2302744
   Moghaddam B, 2001, MULTIMED TOOLS APPL, V14, P201, DOI 10.1023/A:1011355417880
   Niaz U, 2013, INT WORKSH IM AUD AN
   Nokia, 2015, POINT AND FIND
   Qualcomm Connected Experiences Inc, 2015, KOOAB IM REC
   Shen XH, 2012, LECT NOTES COMPUT SC, V7575, P114, DOI 10.1007/978-3-642-33765-9_9
   Su Y., 2013, ACM Multimedia Conference, MM'13, Barcelona, Spain, October 21-25, 2013, P73
   Tang J, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 1, PROCEEDINGS, P193, DOI 10.1109/ISSPA.2003.1224673
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Wang YZ, 2011, BOUND VALUE PROBL, DOI 10.1186/1687-2770-2011-11
   Xue Y., 2013, PROC IEEE INT TEST C, P1
   Yu F.X., 2011, Proceedings_of_the_19th_ACM_International_Conference_on_Multimedia, MM'11, P3
   Zhang CC, 2007, IEEE INT SYM MULTIM, P83, DOI 10.1109/ISM.Workshops.2007.23
   Zhang N, 2015, J VIS COMMUN IMAGE R, V29, P114, DOI 10.1016/j.jvcir.2015.02.007
   Zhang ST, 2012, LECT NOTES COMPUT SC, V7573, P660, DOI 10.1007/978-3-642-33709-3_47
   Zhu L, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P697, DOI 10.1109/ICME.2000.871457
   Zhu L, 2015, IEEE T MULTIMEDIA, V17, P981, DOI 10.1109/TMM.2015.2431496
NR 41
TC 5
Z9 5
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12433
EP 12456
DI 10.1007/s11042-016-3659-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200012
DA 2024-07-18
ER

PT J
AU Kang, K
   Cao, Y
   Wang, ZF
AF Kang, Kai
   Cao, Yang
   Wang, Zengfu
TI Simultaneously retargeting and super-resolution for stereoscopic video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereoscopic video; Retargeting; Super-resolution
AB This paper presents a novel approach that is able to resize stereoscopic video to fit various display environments with different aspect-ratios, while preserving the prominent content, keeping temporally consistent, adapting depth, as well as increasing the resolution. Our proposed approach can deal with retargeting and super-resolution problems simultaneously via replacing the down-sampling matrix appearing in super-resolution algorithm with a novel one, named as content-aware-sampling matrix, derived from retargeting method. The new matrix can sample the image into any resolution while preserving its important information as much as possible. Our approach can be roughly subdivided into three steps. In the first step, we calculate the overall saliency map for a shot, while considering the conspicuous information such as motion, depth, and structures. In the second step, given a certain resolution, we compute the retargeting parameters by a global optimization and formulate them into a matrix. Finally, we substitute the matrix into the objective function of super-resolution to achieve high visual quality images with expected resolution. In addition, we propose a novel single image super-resolution method inspired by a blind image deblurring method. The experimental results based on user studies verify the effectiveness of our approach. And the comparisons with the-state-of-the-art single image super-resolution methods validate the potential of our super-resolution method.
C1 [Kang, Kai; Cao, Yang; Wang, Zengfu] Univ Sci & Technol China, Dept Automat, Hefei, Anhui, Peoples R China.
   [Wang, Zengfu] Chinese Acad Sci, Inst Intelligent Machines, Hefei, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; Hefei Institutes of Physical
   Science, CAS
RP Wang, ZF (corresponding author), Univ Sci & Technol China, Dept Automat, Hefei, Anhui, Peoples R China.; Wang, ZF (corresponding author), Chinese Acad Sci, Inst Intelligent Machines, Hefei, Anhui, Peoples R China.
EM zfwang@ustc.edu.cn
RI Cao, Yang/HGD-6463-2022
CR Almeida MSC, 2010, IEEE T IMAGE PROCESS, V19, P36, DOI 10.1109/TIP.2009.2031231
   Almeida MSC, 2011, IEEE STAT SIGN PROC
   Avidan S, 2007, ACM T GRAPHIC, P26
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Brust H, 2009, TECH REP
   Chang CH, 2011, IEEE T MULTIMEDIA, V13, P589, DOI 10.1109/TMM.2011.2116775
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Garcia DC, 2012, IEEE T CIRC SYST VID, V22, P1249, DOI 10.1109/TCSVT.2012.2198134
   Guthier B, 2013, 2013 IEEE 11TH IVMSP WORKSHOP: 3D IMAGE/VIDEO TECHNOLOGIES AND APPLICATIONS (IVMSP 2013)
   He L, 2013, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2013.51
   Kopf S, 2014, IEEE IMAGE PROC, P2898, DOI 10.1109/ICIP.2014.7025586
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Liu C, 2011, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.2011.5995614
   Liu Ce, 2009, THESIS
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Niu YZ, 2012, IEEE T MULTIMEDIA, V14, P783, DOI 10.1109/TMM.2012.2186122
   Rubinstein M, 2008, ACM T GRAPHIC, P27
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Utsugi K, 2010, 3DTV C TRU VIS CAPT
   Villena S, 2009, 2009 PROCEEDINGS OF 6TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS (ISPA 2009), P156
   Wang YS, 2008, ACM T GRAPHIC, P27
   Yang CY, 2013, IEEE I CONF COMP VIS, P561, DOI 10.1109/ICCV.2013.75
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yu J, 2015, IEEE T CYBERNETICS, V45, P977, DOI 10.1109/TCYB.2014.2341737
   Yu J, 2014, SCI CHINA INFORM SCI, V57, DOI 10.1007/s11432-013-5023-2
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang J, 2016, IEEE T CIRC SYST VID, V26, P479, DOI 10.1109/TCSVT.2014.2367356
   Zhang J, 2013, IEEE IMAGE PROC, P1346, DOI 10.1109/ICIP.2013.6738277
   Zhang J, 2014, MACH VISION APPL, V25, P1685, DOI 10.1007/s00138-013-0536-7
   Zhu Y, 2014, PROC CVPR IEEE, P2917, DOI 10.1109/CVPR.2014.373
NR 32
TC 1
Z9 1
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 11081
EP 11095
DI 10.1007/s11042-015-3226-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400044
DA 2024-07-18
ER

PT J
AU Wang, CC
   Yang, JF
   Wang, K
   Lai, SH
AF Wang, Congchao
   Yang, Jufeng
   Wang, Kai
   Lai, Shang-Hong
TI Multi-scale energy optimization for object proposal generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object proposal; Multi scales; Saliency; Superpixel merging
ID SALIENCY DETECTION; GRADIENTS
AB In this paper, we present an object proposal generation method by applying energy optimization into superpixel merging algorithms in a multiscale framework, which could generate possible object locations in one image. As images in object detection datasets always enjoy high diversity, we adopt two different energy functions with multi-scales. Thus, our method enjoys the strength of global search, which is strong in locating salient object by concerning the whole image at one merge iteration, as well as the strength of local search which is more likely to recall the un-salient instances. What's more, unlike most superpixel merging algorithms that are based on diversified segmentation results, our approach takes advantage of robust edge detection and segments each image only once, which greatly reduces the number of proposals. Experiments on PASCAL VOC 2007 test set show that the proposed method outperforms most previous superpixel merging based methods and also could compete with state-of-the-art proposal generators.
C1 [Wang, Congchao; Yang, Jufeng; Wang, Kai] Nankai Univ, Coll Comp & Control Engn, Tianjin, Peoples R China.
   [Lai, Shang-Hong] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu, Taiwan.
C3 Nankai University; National Tsing Hua University
RP Yang, JF (corresponding author), Nankai Univ, Coll Comp & Control Engn, Tianjin, Peoples R China.
EM yangjufeng@nankai.edu.cn
RI Lai, Shang-Hong/AAS-4002-2020
OI Lai, Shang-Hong/0000-0002-5092-993X
FU National Natural Science Foundation of China [61301238, 61201424]; China
   Scholarship Council [201506205024]; Natural Science Foundation of
   Tianjin, China [14ZCDZGX00831]
FX This work was supported by the National Natural Science Foundation of
   China(No. 61301238, 61201424), China Scholarship Council(No.
   201506205024) and the Natural Science Foundation of Tianjin, China(No.
   14ZCDZGX00831).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   [Anonymous], 2014, BMVC
   [Anonymous], 2014, SIMULTANEOUS DETECTI
   [Anonymous], 2012, GEODESIC SALIENCY US
   [Anonymous], ARXIV150306350
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Branson S, 2013, PROC CVPR IEEE, P1806, DOI 10.1109/CVPR.2013.236
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J., 2012, Imagenet large scale visual recognition competition 2012 (ILSVRC2012)
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Endres I, 2014, IEEE T PATTERN ANAL, V36, P222, DOI 10.1109/TPAMI.2013.122
   Endres I, 2010, LECT NOTES COMPUT SC, V6315, P575, DOI 10.1007/978-3-642-15555-0_42
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Fidler S, 2013, PROC CVPR IEEE, P3294, DOI 10.1109/CVPR.2013.423
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Gonzalez-Garcia A, 2015, PROC CVPR IEEE, P3022, DOI 10.1109/CVPR.2015.7298921
   Han JW, 2016, IEEE T CYBERNETICS, V46, P487, DOI 10.1109/TCYB.2015.2404432
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2013, IEEE T CIRC SYST VID, V23, P2009, DOI 10.1109/TCSVT.2013.2242594
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Hariharan B, 2012, LECT NOTES COMPUT SC, V7575, P459, DOI 10.1007/978-3-642-33765-9_33
   Hosang J, 2016, IEEE T PATTERN ANAL, V38, P814, DOI 10.1109/TPAMI.2015.2465908
   Humayun A, 2014, PROC CVPR IEEE, P336, DOI 10.1109/CVPR.2014.50
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Krahenbuhl P, 2014, GEODESIC OBJECT PROP, P725, DOI DOI 10.1007/978-3-319-10602-147
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229
   Manen S, 2013, IEEE I CONF COMP VIS, P2536, DOI 10.1109/ICCV.2013.315
   Rantalankila P, 2014, PROC CVPR IEEE, P2417, DOI 10.1109/CVPR.2014.310
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Valenti R, 2009, IEEE I CONF COMP VIS, P2185, DOI 10.1109/ICCV.2009.5459240
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhang ZM, 2011, PROC CVPR IEEE, P1497, DOI 10.1109/CVPR.2011.5995411
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 47
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10481
EP 10499
DI 10.1007/s11042-016-3616-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400011
DA 2024-07-18
ER

PT J
AU Zhang, MX
   Yang, Y
   Shen, FM
   Zhang, HW
   Wang, Y
AF Zhang, Mingxing
   Yang, Yang
   Shen, Fumin
   Zhang, Hanwang
   Wang, Yuan
TI Multi-view feature selection and classification for Alzheimer's Disease
   diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alzheimer's Disease (AD); Social health; Multi-view classification;
   l(2,p)-norm; l(2,l)-norm
ID MILD COGNITIVE IMPAIRMENT; IDENTIFICATION
AB In our present society, Alzheimer's disease (AD) is the most common dementia form in elderly people and has been a big social health problem worldwide. In this paper, we propose a novel multi-view classification method based on l (2,p) -norm regularization for Alzheimer's Disease (AD) diagnosis. Unlike the previous l (2,1) -norm regularized methods using concatenated multi-view features, we further consider the intra-structure and inter-structure relations between features of different views and use a more flexible l (2,p) -norm regularization in our objective function. We also proposed a more suitable loss function to measure the loss between labels and predicted values for classification task. It experimentally demonstrated that this method enhances the performance of disease status classification, comparing to the state-of-the-art methods.
C1 [Zhang, Mingxing; Yang, Yang; Shen, Fumin] Univ Elect Sci & Technol China, Chengdu, Peoples R China.
   [Zhang, Hanwang; Wang, Yuan] Natl Univ Singapore, Singapore, Singapore.
C3 University of Electronic Science & Technology of China; National
   University of Singapore
RP Yang, Y (corresponding author), Univ Elect Sci & Technol China, Chengdu, Peoples R China.
EM superstar_zhang@hotmail.com; dlyyang@gmail.com; fumin.shen@gmail.com;
   hanwangzhang@gmail.com; iseway@nus.edu.sg
RI Lang, Ming/HIK-0758-2022; yang, yang/HGT-7999-2022; yang,
   yang/GVT-5210-2022; Zhang, Ming-Xing/GQA-8033-2022
OI Zhang, Ming-Xing/0000-0001-8363-6968; Zhang, Hanwang/0000-0001-7374-8739
FU National Nature Science Foundation of China [61572108]
FX This work was supported in part by the National Nature Science
   Foundation of China under Project 61572108.
CR [Anonymous], PROC CVPR IEEE
   Brookmeyer R, 2007, ALZHEIMERS DEMENT, V3, P186, DOI 10.1016/j.jalz.2007.04.381
   Jie B, 2013, LECT NOTES COMPUT SC, V8149, P275, DOI 10.1007/978-3-642-40811-3_35
   Liu F, 2013, LECT NOTES COMPUT SC, V8150, P311, DOI 10.1007/978-3-642-40763-5_39
   Liu F, 2014, NEUROIMAGE, V84, P466, DOI 10.1016/j.neuroimage.2013.09.015
   Liu S, SUBJECT CTR MULTIVIE
   Liu SD, 2013, IEEE IMAGE PROC, P601, DOI 10.1109/ICIP.2013.6738124
   Nie L, 2014, P SIGIR WORKSH MED I
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Nie LQ, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1245, DOI 10.1145/2600428.2611176
   Petersen RC, 2001, ARCH NEUROL-CHICAGO, V58, P1985, DOI 10.1001/archneur.58.12.1985
   Shi YH, 2014, PROC CVPR IEEE, P2721, DOI 10.1109/CVPR.2014.354
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Wang H, 2011, LECT NOTES COMPUT SC, V6893, P115, DOI 10.1007/978-3-642-23626-6_15
   Yang Y, 2014, IEEE T MULTIMEDIA, V16, P1677, DOI 10.1109/TMM.2014.2323014
   Zhang DQ, 2012, NEUROIMAGE, V59, P895, DOI 10.1016/j.neuroimage.2011.09.069
   Zhang DQ, 2011, NEUROIMAGE, V55, P856, DOI 10.1016/j.neuroimage.2011.01.008
   Zhang M, 2015, NEUROCOMPUT IN PRESS
   Zhu XF, 2014, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2014.395
   Zhu XF, 2014, LECT NOTES COMPUT SC, V8674, P162, DOI 10.1007/978-3-319-10470-6_21
NR 20
TC 18
Z9 18
U1 4
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10761
EP 10775
DI 10.1007/s11042-015-3173-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400025
DA 2024-07-18
ER

PT J
AU Kim, WH
   Lee, JS
AF Kim, Won-Hee
   Lee, Jong-Seok
TI Blind single image super resolution with low computational complexity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image super resolution; Adaptive weighting; Image quality; Low
   computational complexity
ID INTERPOLATION; SUPERRESOLUTION; REPRESENTATION
AB This paper proposes a single image super resolution algorithm with the aim of satisfying three desirable characteristics, namely, high quality of the produced images, adaptability to image contents and unknown blurring conditions used to generate given input images, and low computational complexity. After the given input image is upscaled using a conventional reconstruction operator, the missing high frequency components estimated from lower resolution versions of the input image are added for improved quality and, moreover, the amount of the high frequency components to be added is adaptively determined. No computationally intensive operation is involved in the whole process, which makes the method computationally cheap. Experimental results show that the proposed method yields good subjective and objective image quality consistently across different blurring conditions and contents, and operates fast in comparison to existing state-of-the-art algorithms. In addition, it is also demonstrated that the proposed method can be used in combination with the existing algorithms in order to improve further their performance in terms of image quality.
C1 [Kim, Won-Hee; Lee, Jong-Seok] Yonsei Univ, Yonsei Inst Convergence Technol, 85 Songdogwahak Ro, Incheon, South Korea.
   [Lee, Jong-Seok] Yonsei Univ, Sch Integrated Technol, 85 Songdogwahak Ro, Incheon, South Korea.
C3 Yonsei University; Yonsei University
RP Lee, JS (corresponding author), Yonsei Univ, Yonsei Inst Convergence Technol, 85 Songdogwahak Ro, Incheon, South Korea.; Lee, JS (corresponding author), Yonsei Univ, Sch Integrated Technol, 85 Songdogwahak Ro, Incheon, South Korea.
EM wonheekim@yonsei.ac.kr; jong-seok.lee@yonsei.ac.kr
RI Lee, Jong-Seok/AAF-5197-2020
OI Lee, Jong-Seok/0000-0001-5255-4425
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under "IT
   Consilience Creative Program" [IITP-2015-R0346-15-1008]
FX This research was supported by the MSIP (Ministry of Science, ICT and
   Future Planning), Korea, under the "IT Consilience Creative Program"
   (IITP-2015-R0346-15-1008) supervised by the IITP ( Institute for
   Information & Communications Technology Promotion).
CR Allebach J, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P707, DOI 10.1109/ICIP.1996.560768
   Asuni N, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P58
   Chang J, 2011, ELECTRON LETT, V47, P1176, DOI 10.1049/el.2011.2496
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1382, DOI 10.1109/TIP.2012.2231086
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Giachetti A, 2011, IEEE T IMAGE PROCESS, V20, P2760, DOI 10.1109/TIP.2011.2136352
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim WH, 2015, ELECTRON LETT, V51, P42, DOI 10.1049/el.2014.2784
   Lee JH, 2010, IEEE T CONSUM ELECTR, V56, P1848, DOI 10.1109/TCE.2010.5606336
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Mallat S, 2010, IEEE T IMAGE PROCESS, V19, P2889, DOI 10.1109/TIP.2010.2049927
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Pratt W.K, 1978, DIGITAL IMAGE PROCES
   Tam WS, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3358372
   Tian J, 2011, SIGNAL IMAGE VIDEO P, V5, P329, DOI 10.1007/s11760-010-0204-6
   UNSER M, 1991, IEEE T PATTERN ANAL, V13, P277, DOI 10.1109/34.75515
   van Ouwerkerk JD, 2006, IMAGE VISION COMPUT, V24, P1039, DOI 10.1016/j.imavis.2006.02.026
   Vedadi F, 2014, IEEE T IMAGE PROCESS, V23, P424, DOI 10.1109/TIP.2013.2290586
   Vrcelj B, 2001, IEEE T IMAGE PROCESS, V10, P1639, DOI 10.1109/83.967392
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei Z, 2013, IEEE T IMAGE PROCESS, V22, P4271, DOI 10.1109/TIP.2013.2271849
   Wong CS, 2010, EUR SIGNAL PR CONF, P309
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
   Zhang XF, 2009, LECT NOTES COMPUT SC, V5879, P1197, DOI 10.1007/978-3-642-10467-1_121
   Zhou D, 2012, IET IMAGE PROCESS, V6, P627, DOI 10.1049/iet-ipr.2011.0534
   Zhou F, 2012, IEEE T CONSUM ELECTR, V58, P891, DOI 10.1109/TCE.2012.6311333
NR 31
TC 9
Z9 10
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7235
EP 7249
DI 10.1007/s11042-016-3396-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400050
DA 2024-07-18
ER

PT J
AU Lee, GC
   Yeh, FH
   Chen, YJ
   Chang, TK
AF Lee, Greg C.
   Yeh, Fu-Hao
   Chen, Ying-Ju
   Chang, Tao-Ku
TI Robust handwriting extraction and lecture video summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video segmentation; Video summarization; Notes extraction; Image
   processing
ID IMAGE
AB In e-Learning research, teachers can record lecture videos in e-class and upload these lecture videos to e-Learning system themselves. Once lecture videos and handouts can be generated automatically in traditional classroom, it can help students with self-learning and teacher with lecture content development for e-Learning services. This paper proposed a teaching assistant system based on computer vision that can help in content development for e-Learning services. Lecture videos are taken by using two cameras and merged on both sides so that students can see a clear and complete teaching content. The k-means segmentation is used to extract board area and then connected component technique helps refill the board area which is covered by lecturer's body. Then we use adaptive threshold to extract handwritings in various light conditions and time-series denoising technique is designed to reduce noise. According to extracted handwritings, the lecture videos can be automatically structured with high level of semantics. The lecture videos are segmented into video clips and all key-frames are integrated as handouts of the education videos.
C1 [Lee, Greg C.; Chen, Ying-Ju] Natl Taiwan Normal Univ, Dept Comp Sci & Informat Engn, 88,Sec 4,Tingzhou Rd, Taipei 116, Taiwan.
   [Yeh, Fu-Hao] Fooyin Univ, Program Informat Technol, 151 Chinhsueh Rd, Kaohsiung, Taiwan.
   [Chang, Tao-Ku] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien, Taiwan.
C3 National Taiwan Normal University; Fooyin University; National Dong Hwa
   University
RP Yeh, FH (corresponding author), Fooyin Univ, Program Informat Technol, 151 Chinhsueh Rd, Kaohsiung, Taiwan.
EM yehvolvo@gmail.com
RI chen, ying/HHS-8254-2022
CR [Anonymous], 1 INT WORKSH CAM BAS
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bhogal AK, 2010, COLOR IMAGE SEGMENTA, V1, P18
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Chang HS, 1999, IEEE T CIRC SYST VID, V9, P1269, DOI 10.1109/76.809161
   Choudary C, 2007, IEEE T MULTIMEDIA, V9, P1443, DOI 10.1109/TMM.2007.906602
   Ferman AM, 2002, IEEE T IMAGE PROCESS, V11, P497, DOI 10.1109/TIP.2002.1006397
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   He LW, 2007, IEEE T MULTIMEDIA, V9, P198, DOI 10.1109/TMM.2006.886385
   Hirzallah N, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING, VOLS 1-3, P195, DOI 10.1109/ICCCE.2008.4580595
   Imran A. S., 2012, 2012 IEEE Sixth International Conference on Semantic Computing (ICSC 2012), P117, DOI 10.1109/ICSC.2012.36
   Imran A. S., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2989, DOI 10.1109/ICIP.2011.6116290
   Imran AS, 2012, 5 INT S COMM CONTR S, P1, DOI DOI 10.1109/ISCCSP.2012.6217818
   Jain A., 1986, FUNDAMENTALS DIGITAL
   Lei ZB, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1527, DOI 10.1109/ICME.2000.871058
   Lin C, 2005, P INT C INF COMM SIG, P36
   Liu TC, 2006, IEEE IMAGE PROC, P149, DOI 10.1109/ICIP.2006.312381
   Okuni S, 2007, P INT C CONV INF TEC, P2437, DOI DOI 10.1109/ICCIT.2007.382
   Onishi M, 2000, INT C PATT RECOG, P615, DOI 10.1109/ICPR.2000.902994
   Sáez E, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P567, DOI 10.1109/ICME.2004.1394255
   Saund E, 1999, TECHNICAL REPORT
   Zhang D, 2001, LECT NOTES COMPUT SC, V2195, P63
   Zhang ZY, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P533
   Zhao L, 2001, INT CONF ACOUST SPEE, P1625, DOI 10.1109/ICASSP.2001.941247
   Zhou J, 2004, P 6 ACM SIGMM INT WO, P307
NR 26
TC 8
Z9 9
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7067
EP 7085
DI 10.1007/s11042-016-3353-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400042
DA 2024-07-18
ER

PT J
AU Wang, XY
   Yang, CG
   Ju, ZJ
   Ma, HB
   Fu, MY
AF Wang, Xinyu
   Yang, Chenguang
   Ju, Zhaojie
   Ma, Hongbin
   Fu, Mengyin
TI Robot manipulator self-identification for surrounding obstacle detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Manipulator self-identification; Superpixel; Collision prediction; Point
   cloud
AB Obstacle detection plays an important role for robot collision avoidance and motion planning. This paper focuses on the study of the collision prediction of a dual-arm robot based on a 3D point cloud. Firstly, a self-identification method is presented based on the over-segmentation approach and the forward kinematic model of the robot. Secondly, a simplified 3D model of the robot is generated using the segmented point cloud. Finally, a collision prediction algorithm is proposed to estimate the collision parameters in real-time. Experimental studies using the Kinect (R) sensor and the Baxter (R) robot have been performed to demonstrate the performance of the proposed algorithms.
C1 [Wang, Xinyu; Ma, Hongbin; Fu, Mengyin] Beijing Inst Technol, Sch Automat, Beijing 100081, Peoples R China.
   [Yang, Chenguang] Swansea Univ, Coll Engn, Swansea SA1 8EN, W Glam, Wales.
   [Wang, Xinyu; Ma, Hongbin; Fu, Mengyin] Beijing Inst Technol, State Key Lab Intelligent Control & Decis Complex, Beijing 100081, Peoples R China.
   [Ju, Zhaojie] Univ Portsmouth, Sch Comp, Portsmouth, Hants, England.
C3 Beijing Institute of Technology; Swansea University; Beijing Institute
   of Technology; University of Portsmouth
RP Yang, CG (corresponding author), Swansea Univ, Coll Engn, Swansea SA1 8EN, W Glam, Wales.
EM cyang@theiet.org
RI Ju, Zhaojie/AAA-5872-2019; WANG, Xinyu/C-8430-2014; Yang,
   Chenguang/AAJ-2509-2020; fu, meng/GZG-3120-2022
OI Ju, Zhaojie/0000-0002-9524-7609; Yang, Chenguang/0000-0001-5255-5559
FU EPSRC [EP/L026856/1, EP/J004561/1]; NSFC [61473038]; EPSRC
   [EP/L026856/1, EP/J004561/1] Funding Source: UKRI
FX This work was partially supported by EPSRC grants EP/L026856/1 and
   EP/J004561/1 (BABEL) as well as NSFC grant 61473038.
CR [Anonymous], 2015, IEEE J-STSP, DOI DOI 10.1109/JSTSP.2014.2381153
   [Anonymous], ROB ISR 2010 41 INT
   Belhadj H, 2013, 2013 INTERNATIONAL CONFERENCE ON INDIVIDUAL AND COLLECTIVE BEHAVIORS IN ROBOTICS (ICBR), P21, DOI 10.1109/ICBR.2013.6729264
   Ben-Tzvi P., 2010, IEEE INT WORKSHOP RO, P1
   Ho HT, 2009, IET COMPUT VIS, V3, P201, DOI 10.1049/iet-cvi.2009.0044
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Ju ZF, 2014, CHIN CONTR CONF, P8518, DOI 10.1109/ChiCC.2014.6896430
   Li-Chee-Ming J, 2009, IEEE TIC-STH 09: 2009 IEEE TORONTO INTERNATIONAL CONFERENCE: SCIENCE AND TECHNOLOGY FOR HUMANITY, P445, DOI 10.1109/TIC-STH.2009.5444457
   Luo RC, 2014, IEEE ASME INT C ADV, P1036, DOI 10.1109/AIM.2014.6878217
   Lyubova N, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1365, DOI 10.1109/ROBIO.2013.6739655
   MACIEJEWSKI AA, 1985, INT J ROBOT RES, V4, P109, DOI 10.1177/027836498500400308
   Michel P., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P2763
   Nakhaeinia D, 2013, IEEE INT SYMP SAFE
   Ohno K., 2011, 2011 IEEE International Conference on Robotics and Biomimetics (ROBIO), P1942, DOI 10.1109/ROBIO.2011.6181575
   Pan J, 2013, IEEE INT CONF ROBOT, P3593, DOI 10.1109/ICRA.2013.6631081
   Rakprayoon P., 2011, 2011 IEEE/SICE International Symposium on System Integration (SII 2011), P68, DOI 10.1109/SII.2011.6147421
   Reddivari H, 2014, PROCESSING OF 2014 INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INFORMATION INTEGRATION FOR INTELLIGENT SYSTEMS (MFI)
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Rottensteiner F, 2003, IEEE COMPUT GRAPH, V23, P42, DOI 10.1109/MCG.2003.1242381
   Saveriano M, 2013, IEEE INT C INT ROBOT, P5380, DOI 10.1109/IROS.2013.6697135
   Sukmanee W, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2012)
   Thumbunpeng P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P2166, DOI 10.1109/ROBIO.2013.6739790
   Tseng JL, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE OF COMPUTATIONAL SCIENCES AND ITS APPLICATIONS, P198, DOI 10.1109/ICCSA.2009.28
   Um D, 2013, IEEE INT C INT ROBOT, P5273, DOI 10.1109/IROS.2013.6697119
   Wang BC, 2012, PROCEEDINGS OF THE 10TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2012), P3903, DOI 10.1109/WCICA.2012.6359124
   Wang XY, 2015, IEEE INT C INT ROBOT, P4575, DOI 10.1109/IROS.2015.7354028
   Yaguchi H, 2013, 2013 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P759, DOI 10.1109/SII.2013.6776686
NR 27
TC 35
Z9 37
U1 5
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6495
EP 6520
DI 10.1007/s11042-016-3275-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400019
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Cai, ZY
   Han, JG
   Liu, L
   Shao, L
AF Cai, Ziyun
   Han, Jungong
   Liu, Li
   Shao, Ling
TI RGB-D datasets using microsoft kinect or similar sensors: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Microsoft Kinect sensor or similar devices; RGB-D dataset; Computer
   vision; Survey; Database
ID ACTION RECOGNITION; ACTIONLET ENSEMBLE; DEPTH INFORMATION; FALL
   DETECTION; SEGMENTATION; FRAMEWORK; DATABASE; FUSION; CAMERA; MAPS
AB RGB-D data has turned out to be a very useful representation of an indoor scene for solving fundamental computer vision problems. It takes the advantages of the color image that provides appearance information of an object and also the depth image that is immune to the variations in color, illumination, rotation angle and scale. With the invention of the low-cost Microsoft Kinect sensor, which was initially used for gaming and later became a popular device for computer vision, high quality RGB-D data can be acquired easily. In recent years, more and more RGB-D image/video datasets dedicated to various applications have become available, which are of great importance to benchmark the state-of-the-art. In this paper, we systematically survey popular RGB-D datasets for different applications including object recognition, scene classification, hand gesture recognition, 3D-simultaneous localization and mapping, and pose estimation. We provide the insights into the characteristics of each important dataset, and compare the popularity and the difficulty of those datasets. Overall, the main goal of this survey is to give a comprehensive description about the available RGB-D datasets and thus to guide researchers in the selection of suitable datasets for evaluating their algorithms.
C1 [Cai, Ziyun] Univ Sheffield, Dept Elect & Elect Engn, Mappin St, Sheffield S1 3JD, S Yorkshire, England.
   [Han, Jungong; Liu, Li; Shao, Ling] Northumbria Univ, Dept Comp Sci & Digital Technol, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England.
C3 University of Sheffield; Northumbria University
RP Shao, L (corresponding author), Northumbria Univ, Dept Comp Sci & Digital Technol, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England.
EM cziyun1@sheffield.ac.uk; jungong.han@northumbria.ac.uk;
   li2.liu@northumbria.ac.uk; ling.shao@northumbria.ac.uk
RI liu, li/ADL-2178-2022; Han, Jungong/ABE-6812-2020; Shao,
   Ling/D-3535-2011
OI liu, li/0000-0002-6669-9382; Shao, Ling/0000-0002-8264-6117
CR Abdallah D, 2015, INT C INT ROB SYST, P8
   Aldoma A, 2012, LECT NOTES COMPUT SC, V7574, P511, DOI 10.1007/978-3-642-33712-3_37
   [Anonymous], WORKSH COL DEPTH CAM
   [Anonymous], 2009, IMAGE CORRELATION SH, DOI DOI 10.1007/978-0-387-78747-3
   [Anonymous], P IEEE IEEE
   [Anonymous], 2013, Consumer Depth Cameras for Computer Vision, DOI DOI 10.1007/978-1-4471-4640-7_8
   [Anonymous], 2013, P 5 INT WORKSHOP MUL, DOI DOI 10.1145/2506023.2506031
   [Anonymous], 2013, Consumer Depth Cameras for Computer Vision, DOI DOI 10.1007/978-1-4471-4640-710
   [Anonymous], BRIT MACH VIS C
   [Anonymous], 2012, LECT NOTES COMPUT SC, DOI [10.1007/978-3-642-33715-4_54, DOI 10.1007/978-3-642-33715-4_54]
   [Anonymous], 2011, P ADV NEURAL INFORM
   Baltrusaitis T, 2012, PROC CVPR IEEE, P2610, DOI 10.1109/CVPR.2012.6247980
   Barbosa IB, 2012, LECT NOTES COMPUT SC, V7583, P433, DOI 10.1007/978-3-642-33863-2_43
   Berger K, ARXIV13102053
   Bo L., 2013, EXPT ROBOTICS VOLUME, P387, DOI DOI 10.1007/978-3-319-00065-7
   Bo LF, 2011, IEEE INT C INT ROBOT, P821, DOI 10.1109/IROS.2011.6048717
   Bo LF, 2011, PROC CVPR IEEE, P1729, DOI 10.1109/CVPR.2011.5995719
   Borràs R, 2012, LECT NOTES COMPUT SC, V7325, P98, DOI 10.1007/978-3-642-31298-4_12
   Bourke AK, 2007, GAIT POSTURE, V26, P194, DOI 10.1016/j.gaitpost.2006.09.012
   Brachmann E, 2014, LECT NOTES COMPUT SC, V8690, P536, DOI 10.1007/978-3-319-10605-2_35
   Chen C, REAL TIME HUMAN ACTI
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen C, 2015, IEEE T HUM-MACH SYST, V45, P51, DOI 10.1109/THMS.2014.2362520
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Chua CS, 2002, IMAGE VISION COMPUT, V20, P191, DOI 10.1016/S0262-8856(01)00094-4
   Cruz L., 2012, 2012 XXV SIBGRAPI Conference on Graphics, Patterns and Images Tutorials (SIBGRAPI-T), P36, DOI 10.1109/SIBGRAPI-T.2012.13
   Drouard V, 2015, INT C IM PROC
   Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7
   Endres F, 2014, IEEE T ROBOT, V30, P177, DOI 10.1109/TRO.2013.2279412
   Endres F, 2012, IEEE INT CONF ROBOT, P1691, DOI 10.1109/ICRA.2012.6225199
   Erdogmus N, 2013, SPOOFING 2D FACE REC, P1
   Fanelli G, 2013, INT J COMPUT VISION, V101, P437, DOI 10.1007/s11263-012-0549-0
   Fothergill S., 2012, P SIGCHI C HUM FACT, P1737, DOI DOI 10.1145/2207676.2208303
   Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13
   Garcia J., 2008, U.S. Patent 7 433 024, Patent No. [7 433 024, 7433024]
   Gasparrini S, SENSORS, V14, P2756
   Geng J, 2011, ADV OPT PHOTONICS, V3, P128, DOI 10.1364/AOP.3.000128
   Gossow D, 2012, INT C PATT RECOG, P2764
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Handa A, 2014, IEEE INT CONF ROBOT, P1524, DOI 10.1109/ICRA.2014.6907054
   Helmer S, 2011, LECT NOTES COMPUT SC, V6492, P464, DOI 10.1007/978-3-642-19315-6_36
   Hinterstoisser S, 2012, MODEL BASED TRAINING, P548
   Hinterstoisser S, 2012, IEEE T PATTERN ANAL, V34, P876, DOI 10.1109/TPAMI.2011.206
   Hornung A, 2013, AUTON ROBOT, V34, P189, DOI 10.1007/s10514-012-9321-0
   Hu G, 2012, IEEE INT C INT ROBOT, P1714, DOI 10.1109/IROS.2012.6386103
   Huynh O, 2015, IEEE WINT CONF APPL, P929, DOI 10.1109/WACV.2015.128
   Jhuo IH, UNSUPERVISED FEATURE
   Jin L, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P311, DOI 10.1109/ISM.2014.56
   Karpathy A, 2013, IEEE INT CONF ROBOT, P2088, DOI 10.1109/ICRA.2013.6630857
   Kepski M, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P640
   Kerl C, 2013, IEEE INT CONF ROBOT, P3748, DOI 10.1109/ICRA.2013.6631104
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Kumatani K, 2012, ASIAPAC SIGN INFO PR
   Kurakin A, 2012, EUR SIGNAL PR CONF, P1975
   Kwolek B, 2014, COMPUT METH PROG BIO, V117, P489, DOI 10.1016/j.cmpb.2014.09.005
   Lai K., 2013, Consumer Depth Cameras for Computer Vision: Research Topics and Applications, P167
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Lee TK, 2012, IEEE INT C INT ROBOT, P1727, DOI 10.1109/IROS.2012.6385909
   Leroy J, 2013, L N INST COMP SCI SO, V124, P55
   Liu K, 2014, IEEE SENS J, V14, P1898, DOI 10.1109/JSEN.2014.2306094
   Liu L., 2013, 23 INT JOINT C ART I
   Luber M, 2011, IEEE INT C INT ROBOT, P3844, DOI 10.1109/IROS.2011.6048836
   Mantecón T, 2014, IEEE IMAGE PROC, P293, DOI 10.1109/ICIP.2014.7025058
   Mason J, 2014, IEEE INT CONF ROBOT, P3074, DOI 10.1109/ICRA.2014.6907301
   Mason J, 2012, IEEE INT C INT ROBOT, P2836, DOI 10.1109/IROS.2012.6386219
   Min R, 2014, IEEE T SYST MAN CY-S, V44, P1534, DOI 10.1109/TSMC.2014.2331215
   Narayan KS, SENSORS, V32, P26
   Negin F, 2013, LECT NOTES COMPUT SC, V7950, P648, DOI 10.1007/978-3-642-39094-4_74
   Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101
   Pomerleau F, 2011, IEEE INT C INT ROBOT, P3824, DOI 10.1109/IROS.2011.6048545
   Rekik Ahmed, 2013, Proceedings of the 8th International Conference on Computer Vision Theory and Applications. VISAPP 2013, P223
   Richtsfeld A, 2014, J VIS COMMUN IMAGE R, V25, P64, DOI 10.1016/j.jvcir.2013.04.006
   Richtsfeld A, 2012, IEEE INT C INT ROBOT, P4791, DOI 10.1109/IROS.2012.6385661
   Salas-Moreno RF, 2014, INT SYM MIX AUGMENT, P157, DOI 10.1109/ISMAR.2014.6948422
   Satta R, 2013, THESIS
   Shao TJ, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366155
   Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377
   Silberman N., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P601, DOI 10.1109/ICCVW.2011.6130298
   Singh A, 2014, IEEE INT CONF ROBOT, P509, DOI 10.1109/ICRA.2014.6906903
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Song SR, 2013, IEEE I CONF COMP VIS, P233, DOI 10.1109/ICCV.2013.36
   Spinello L, 2011, IEEE INT C INT ROBOT, P3838, DOI 10.1109/IROS.2011.6048835
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Stein S, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P729, DOI 10.1145/2493432.2493482
   Steinbrucker F., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P719, DOI 10.1109/ICCVW.2011.6130321
   Sturm J., 2012, PROC WORKSHOP COLOR
   Sturm J, 2011, RGB D WORKSH ADV REA, V2
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Sun M, 2010, LECT NOTES COMPUT SC, V6315, P658, DOI 10.1007/978-3-642-15555-0_48
   Sung J, HUMAN ACTIVITY DETEC, P64
   Susanto W, 2012, LECT NOTES COMPUT SC, V7584, P93, DOI 10.1007/978-3-642-33868-7_10
   Tao D, INFORM SCI
   Tao DP, 2013, IEEE T CYBERNETICS, V43, P1406, DOI 10.1109/TCYB.2013.2264285
   Thomas A, 2007, IEEE I CONF COMP VIS, P23
   Vaufreydaz D, 2014, I C CONT AUTOMAT ROB, P1668, DOI 10.1109/ICARCV.2014.7064566
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wohlkinger W, 2012, IEEE INT CONF ROBOT, P5384, DOI 10.1109/ICRA.2012.6225116
   Wu D, 2014, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2014.98
   Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458
   Yang Y, 2014, MANIPULATION ACTION, P987
   Yu G, 2015, LECT NOTES COMPUT SC, V9007, P50, DOI 10.1007/978-3-319-16814-2_4
   Zhang QS, 2013, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2013.32
   Zhou QY, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461919
NR 105
TC 88
Z9 97
U1 2
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4313
EP 4355
DI 10.1007/s11042-016-3374-6
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200056
OA Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Lee, W
   Kim, H
   Lee, JY
   Kim, H
AF Lee, Woonghee
   Kim, Hyunsoon
   Lee, Joon Yeop
   Kim, Hwangnam
TI Improving quality of multimedia services through network performance
   isolation in a mobile device
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia services; Quality of service; Quality of experience; Network
   performance isolation; Mobile devices
ID RATE ADAPTATION; INTERNET; HTTP
AB Due to the advancement of hardware and software, today's mobile devices, such as smartphones, tablet PCs, and laptops, are capable of providing a wide range of services. Among various services, a lot of users use multimedia services on mobile devices, and the size of mobile multimedia traffic is constantly increasing. Especially, the growth of social networking services and content-sharing sites stimulates creating and sharing of multimedia contents. Such environment made it possible for today's mobile users to frequently download or upload multimedia data. Nowadays, smartphones allow users to multi-task between different services, so the multimedia service often coexists with background services in a mobile device at the same time. In these cases, the performance degradation of a multimedia service happens due to concurrently running background services in the device. In this paper, we propose MuSNet, a scheme for improving QoS and QoE of multimedia services through network performance isolation in a mobile device, which resolves the aforementioned problem by applying the concept of performance isolation to the multimedia services. MuSNet is the mobile device-based scheme without any modification on servers. Furthermore, unlike most performance isolation implemented by virtual machines, we suggest a scheme that does not require virtualization that might be heavy for mobile devices. The proposed scheme was implemented on a smartphone by modifying the kernel, and various experiments were conducted to evaluate the advanced system behavior of MuSNet.
C1 [Lee, Woonghee; Kim, Hyunsoon; Lee, Joon Yeop; Kim, Hwangnam] Korea Univ, Sch Elect Engn, Seoul, South Korea.
C3 Korea University
RP Lee, W (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM tgorevenge@korea.ac.kr; gustns2010@korea.ac.kr; charon7@korea.ac.kr;
   hnkim@korea.ac.kr
RI Lee, Woonghee/AAW-8903-2021
OI Lee, Woonghee/0000-0003-0856-6415; Kim, Hwangnam/0000-0003-4322-8518
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2015R1D1A1A01059151]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2015R1D1A1A01059151).
CR [Anonymous], 2016, MUSNET POSING PROBLE
   [Anonymous], 2016, MUSNET PERFORMANCE E
   [Anonymous], 2012, Int J Adv Res Comput Commun Eng
   [Anonymous], 2015, Ericsson Mobility Report
   Braden R., 1989, REQUEST FOR COMMENTS, P356, DOI 2.4.3.2,3.1.1,3.2.3,6.1
   Chen C, 2015, IEEE J-STSP, V9, DOI 10.1109/JSTSP.2014.2337277
   Chen J, 2008, AD HOC NETW, V6, P1098, DOI 10.1016/j.adhoc.2007.10.004
   Chen SY, 2013, 2013 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE (WCNC), P1291
   Chen YC, 2012, 22 U MASS AMH SCH CO
   Devkota Prajjwal, 2010, Proceedings 18th IEEE/ACM International Symposium on Modelling, Analysis & Simulation of Computer and Telecommunication Systems (MASCOTS 2010), P235, DOI 10.1109/MASCOTS.2010.32
   Dong YZ, 2012, J PARALLEL DISTR COM, V72, P1471, DOI 10.1016/j.jpdc.2012.01.020
   Etsion Y, 2006, ACM T MULTIM COMPUT, V2, P318, DOI 10.1145/1201730.1201734
   Fall Kevin R, 2011, TCP IP ILLUSTRATED, V1
   Greenberg A, 2009, ACM SIGCOMM COMP COM, V39, P68, DOI 10.1145/1496091.1496103
   Juluri P, 2015, IEEE INT CONF COMM, P1765, DOI 10.1109/ICCW.2015.7247436
   Kelly T, 2003, ACM SIGCOMM COMP COM, V33, P83, DOI 10.1145/956981.956989
   Khan A, 2012, IEEE COMMUN MAG, V50, P136, DOI 10.1109/MCOM.2012.6122544
   Kuschnig R., 2010, MMSYS, P157
   Lee D.J., 2010, INT J ADV SYST MEASU, V3, P3
   Lee W, 2015, PERF COMP COMM C IPC
   Li Z, 2014, IEEE J SEL AREA COMM, V32, P719, DOI 10.1109/JSAC.2014.140405
   Lim YK, 2013, IT CONVERGENCE SECUR, P727
   Liu CH, 2010, IEEE ICC
   Meng K, 2009, SECUR COMMUN NETW, V2, P654, DOI 10.1002/sec.107
   Mok R.K., 2011, PROC ACM SIGCOMM WOR, P31, DOI DOI 10.1145/2018602.2018611
   Mok R. K. P., 2011, 2011 IFIP/IEEE International Symposium on Integrated Network Management (IM 2011), P485, DOI 10.1109/INM.2011.5990550
   Petrangeli S, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2818361
   Semke J., 1998, Computer Communication Review, V28, P315, DOI 10.1145/285243.285292
   Shieh A., 2010, USENIX HotCloud
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Tappayuthpijarn K., 2009, Proceedings of the 2009 International Conference on Wireless Communications and Mobile Computing: Connecting the World Wirelessly, P1325
   Venkataramani A, 2002, USENIX ASSOCIATION PROCEEDINGS OF THE FIFTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P329, DOI 10.1145/1060289.1060320
   Zheng HQ, 2010, PERF E R SI, V38, P263, DOI 10.1145/1811099.1811069
   Zhu P, 2007, IEEE T MULTIMEDIA, V9, P366, DOI 10.1109/TMM.2006.886284
NR 34
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5317
EP 5346
DI 10.1007/s11042-016-3821-4
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500029
DA 2024-07-18
ER

PT J
AU Zhuang, CY
   Ma, Q
   Yoshikawa, M
AF Zhuang, Chenyi
   Ma, Qiang
   Yoshikawa, Masatoshi
TI SNS user classification and its application to obscure POI discovery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User profiling; Obscure points of interests; Probabilistic model; Social
   network
AB Technologies are increasingly taking advantage of the explosion of social media (e.g., web searches, ad targeting, personalized geo-social recommendations, urban computing). Estimating the characteristics of users, or user profiling, is one of the key challenges for such technologies. This paper focuses on the important problem of automatically estimating social networking service (SNS) user authority with a given city, which can significantly improve location-based services and systems. The "authority" in our work measures a user's familiarity with a particular city. By analyzing users' social, temporal, and spatial behavior, we respectively propose and compare three models for user authority: a social-network-driven model, time-driven model, and location-driven model. Furthermore, we discuss the integration of these three models. Finally, by using these user-profiling models, we propose a new application for geo-social recommendations. In contrast to related studies, which focus on popular and famous points of interests (POIs), our models help discover obscure POIs that are not well known. Experimental evaluations and analysis on a real dataset collected from three cities demonstrate the performance of the proposed user-profiling models. To verify the effect of discovering obscure POIs, the proposed application was implemented to discover and explore obscure POIs in Kyoto, Japan.
C1 [Zhuang, Chenyi; Ma, Qiang; Yoshikawa, Masatoshi] Kyoto Univ, Dept Social Informat, Sakyo Ku, Kyoto 6068501, Japan.
C3 Kyoto University
RP Zhuang, CY (corresponding author), Kyoto Univ, Dept Social Informat, Sakyo Ku, Kyoto 6068501, Japan.
EM zhuang@db.soc.i.kyoto-u.ac.jp; qiang@i.kyoto-u.ac.jp;
   yoshikawa@i.kyoto-u.ac.jp
RI Zhuang, Chenyi/N-8509-2019
OI Zhuang, Chenyi/0000-0003-1891-5666; Ma, Qiang/0000-0003-3430-9244
FU Grants-in-Aid for Scientific Research [16K12532, 25700033, 15J01402]
   Funding Source: KAKEN
CR [Anonymous], 2012, P 20 ACM INT C MULT
   Backstrom L., 2010, WWW 2010 RAL NC, DOI [10.1145/1772690.1772698, DOI 10.1145/1772690.1772698]
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chang HW, 2012, 2012 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P111, DOI 10.1109/ASONAM.2012.29
   Chen Wei-Chao., 2009, MM 09, P789
   Cho E., 2011, P 17 ACM SIGKDD INT, P1082, DOI DOI 10.1145/2020408.2020579
   Eisenstein J, 2010, P 2010 C EMP METH NA, P1277
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Gao H., 2012, ICWSM, P114
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Gyongyi Z., 2004, P 30 INT C VER LARG, DOI 10.1016/B978-012088469-8.50052-8
   Hao Q., 2010, P 19 INT C WORLD WID, P401, DOI [DOI 10.1145/1772690.1772732, 10.1145/1772690.1772732]
   Hasegawa Keisuke, 2012, Database and Expert Systems Applications. Proceedings of the 23rd International Conference, DEXA 2012, P141, DOI 10.1007/978-3-642-32597-7_13
   Hsu Chin-Wei, 2010, Technical Report
   Ji Rongrong., 2009, P 17 ASS COMP MACH I, P105, DOI DOI 10.1145/1631272.1631289
   Jimenez D, 1998, IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, P753, DOI 10.1109/IJCNN.1998.682375
   Lieberman M.D., 2009, P 3 INT AAAI C WEBLO, P106
   Luo JB, 2011, MULTIMED TOOLS APPL, V51, P187, DOI 10.1007/s11042-010-0623-y
   Pennacchiotti M, 2011, KDD '11, P430, DOI DOI 10.1145/2020408.2020477
   Popescu A., 2010, Proceedings of the Fourth International AAAI Conference on weblogs and Social Media, P307
   Pretto L., 2002, String Processing and Information Retrieval. 9th International Symposium, SPIRE 2002. Proceedings (Lecture Notes in Computer Science Vol.2476), P131
   Rao D., 2010, P 2 INT WORKSHOP SEA, P37, DOI DOI 10.1145/1871985.1871993
   Rokach L., 2010, Pattern Classification Using Ensemble Methods
   Xu DQ, 2014, INCOME DISPARITY IN CHINA: CRISIS WITHIN ECONOMIC MIRACLE, P1
   Zheng Y., 2009, WWW, P791, DOI [10.1145/1526709.1526816, DOI 10.1145/1526709.1526816]
   Zheng YT, 2011, MULTIMED TOOLS APPL, V51, P77, DOI 10.1007/s11042-010-0630-z
   Zheng Y, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1889681.1889683
   Zhu J, 2009, STAT INTERFACE, V2, P349
   Zhuang C, 2015, ASONAM, P1
   Zhuang J, 2014, INT CONF COMPUT INFO, P3, DOI 10.1109/CIT.2014.124
NR 31
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5461
EP 5487
DI 10.1007/s11042-016-4034-6
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500035
DA 2024-07-18
ER

PT J
AU Dash, JK
   Mukhopadhyay, S
   Das Gupta, R
AF Dash, Jatindra Kumar
   Mukhopadhyay, Sudipta
   Das Gupta, Rahul
TI Multiple classifier system using classification confidence for texture
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple classifier system; Classifier fusion; Decision fusion; Texture
   classification
ID FUSION
AB This paper proposes a simple yet effective novel classifier fusion strategy for multi-class texture classification. The resulting classification framework is named as Classification Confidence-based Multiple Classifier Approach (CCMCA). The proposed training based scheme fuses the decisions of two base classifiers (those constitute the classifier ensemble) using their classification confidence to enhance the final classification accuracy. 4-fold cross validation approach is followed to perform experiments on four different texture databases those vary in terms of orientation, number of texture classes and complexity. Apart from its simplicity, the proposed CCMCA method shows better and consistent performance with lowest standard deviation as compared to fixed rule and simple trainable fusion techniques irrespective of the feature set used across all the databases used in the experiment. The performance gain of the proposed CCMCA method over other competing methods is found to be statistically significant.
C1 [Dash, Jatindra Kumar; Mukhopadhyay, Sudipta; Das Gupta, Rahul] Indian Inst Technol Kharagpur, Kharagpur, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Dash, JK (corresponding author), Indian Inst Technol Kharagpur, Kharagpur, W Bengal, India.
EM jatinkdash@gmail.com; smukho@iitkgp.ac.in; rahulcsjuiitkgp@gmail.com
RI Dash, Jatindra/JNT-5949-2023
OI Mukhopadhyay, Sudipta/0000-0002-4719-2578; Dash, Jatindra
   Kumar/0000-0001-9067-8517
FU Ministry of Communications and Information Technology, Department of
   Electronics and Information Technology, Govt. of India [1(3)2009-METMD,
   1(2)2013-METMD/ESDA]; Indian Institute of Technology Kharagpur
FX This work has been supported by Ministry of Communications and
   Information Technology, Department of Electronics and Information
   Technology, Govt. of India, Grant number 1(3)2009-ME&TMD and
   1(2)2013-ME&TMD/ESDA. Thanks to Indian Institute of Technology Kharagpur
   for funding our research. Authors are thankful to National Institute of
   Science and Technology, Berhmapur, Odisha, India 761008 for extending
   its research facility.
CR [Anonymous], 2006, International Journal of Hybrid Intelligent Systems, DOI DOI 10.3233/HIS-2006-3104
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Brodatz P., 1966, Textures: a photographic album for artists and designers, V66
   Dash JK, 2015, IET IMAGE PROCESS, V9, P836, DOI 10.1049/iet-ipr.2014.0299
   Dash JK, 2014, IEEE STUDENT TECHNOL, P264, DOI 10.1109/TechSym.2014.6808058
   Dash JK, 2013, SPIE MED IMAGING
   Duda R. O., 2012, PATTERN CLASSIFICATI, DOI DOI 10.1007/978-3-319-57027-3_4
   FARRELL KR, 1995, INT CONF ACOUST SPEE, P349, DOI 10.1109/ICASSP.1995.479545
   Farrell KR, 1997, NEURAL NETWORKS FOR SIGNAL PROCESSING VII, P531, DOI 10.1109/NNSP.1997.622435
   Fumera G, 2005, IEEE T PATTERN ANAL, V27, P942, DOI 10.1109/TPAMI.2005.109
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015
   Huang Y. S., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P347, DOI 10.1109/CVPR.1993.1626170
   Huenupán F, 2008, PATTERN RECOGN LETT, V29, P957, DOI 10.1016/j.patrec.2008.01.015
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Kittler J, 2003, IEEE T PATTERN ANAL, V25, P110, DOI 10.1109/TPAMI.2003.1159950
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kuncheva L. I., 2004, COMBINING PATTERN CL, V390, P413
   Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006
   Kuncheva LI, 2001, PATTERN RECOGN, V34, P299, DOI 10.1016/S0031-3203(99)00223-X
   Lam L, 2000, LECT NOTES COMPUT SC, V1857, P77
   Ma L, 2014, SPIE MED IMAGING
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Maltoni D., 2009, HDB FINGERPRINT RECO
   Mi AZ, 2011, PROCEDIA ENGINEER, V23, DOI 10.1016/j.proeng.2011.11.2525
   MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5
   Mukhopadhyay S, 2013, PATTERN RECOGN LETT, V34, P646, DOI 10.1016/j.patrec.2013.01.001
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T., 2002, Proc. 2nd International Workshop on Texture Analysis and Synthesis, P99
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Quost B, 2011, INT J APPROX REASON, V52, P353, DOI 10.1016/j.ijar.2010.11.008
   Roli F, 2002, LECT NOTES COMPUT SC, V2364, P325
   Roli F, 2002, LECT NOTES COMPUT SC, V2364, P232
   Sinha A, 2008, NEUROCOMPUTING, V71, P2650, DOI 10.1016/j.neucom.2007.06.016
   University of Sourthern California Signal and Image Processing Institute, ROT TEXT
   Wozniak M, 2014, INFORM FUSION, V16, P3, DOI 10.1016/j.inffus.2013.04.006
   Xiang B, 2003, IEEE T SPEECH AUDI P, V11, P447, DOI 10.1109/TSA.2003.815822
   XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943
NR 37
TC 8
Z9 8
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2535
EP 2556
DI 10.1007/s11042-015-3231-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000041
DA 2024-07-18
ER

PT J
AU Kennel, P
   Puech, W
   Comby, F
AF Kennel, Pol
   Puech, William
   Comby, Frederic
TI Visualization framework of digital paintings based on visual saliency
   for cultural heritage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency map; Digital painting; Cultural heritage; Visualization system;
   Region of interest
ID IMAGE; ATTENTION; MODEL
AB In order to preserve cultural heritage, this paper proposes to develop a digital paintings visualization system. Our proposed system mainly consists of extracting regions of interest (ROI) from a digital painting to characterize them. These close-ups are then animated on the basis of the painting characteristics and the artist's or designer's aim. In order to obtain interesting results from short video clips, we developed a visual saliency map-based method by using the well-known Itti's saliency analysis which already proved its efficiency on paintings. The experimental results show the efficiency of our approach and an evaluation based on a Mean Opinion Score validates the proposed method. Eighteen volunters watched for a total of 216 views at 72 video clips build up from 6 paintings, and we found a significant difference between our saliency-based generated videos and random-based generated videos.
C1 [Kennel, Pol; Puech, William; Comby, Frederic] Univ Montpellier, CNRS, LIRMM, UMR 5506, Montpellier, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite
   Paul-Valery; Universite Perpignan Via Domitia; Universite de Montpellier
RP Puech, W (corresponding author), Univ Montpellier, CNRS, LIRMM, UMR 5506, Montpellier, France.
EM william.puech@lirmm.fr
OI Puech, William/0000-0001-9383-2401
CR [Anonymous], 2000, SUBJECTIVE VIDEO QUA
   [Anonymous], 2000, THESIS PASADENA CALI
   Aziz MZ, 2008, IEEE T IMAGE PROCESS, V17, P633, DOI 10.1109/TIP.2008.919365
   Condorovici RG, 2011, SPAMEC
   Gallo G., 2011, DIGITAL IMAGING CULT
   Giakoumis I, 2006, IEEE T IMAGE PROCESS, V15, P178, DOI 10.1109/TIP.2005.860311
   GREENSPAN H, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P222, DOI 10.1109/CVPR.1994.323833
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Ikewelugo C., 2012, OPEN J STAT, V12, P172, DOI [10.4236/ojs.2012.22019, DOI 10.4236/OJS.2012.22019]
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, J ELECTRON IMAGING, V10, P161, DOI 10.1117/1.1333677
   Khan FS, 2014, MACH VISION APPL, V25, P1385, DOI 10.1007/s00138-014-0621-6
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   McNamara Ann., 2012, P ACM S APPL PERCEPT, P63
   Niebur E., 2007, Scholarpedia, V2, P2675
   Pei SC, 2001, IEEE T SIGNAL PROCES, V49, P2783, DOI 10.1109/78.960426
   Pitzalis D., 2008, P EVA 08 FLOR EL IM
   Platia L., 2011, P IEEE ICIP 2011
   Quiroga RQ, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00098
   van der Maaten L, 2009, CISC VIS NETW IND GL
   Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411
   Wu B, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-16
   Xu LF, 2013, J VIS COMMUN IMAGE R, V24, P465, DOI 10.1016/j.jvcir.2013.02.007
   Zollner Frank., 1993, Gazette des Beaux-Arts, P115
NR 26
TC 2
Z9 2
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 561
EP 575
DI 10.1007/s11042-015-3013-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000025
DA 2024-07-18
ER

PT J
AU Lam, KY
   Tsang, NWH
   Han, S
   Zhang, WL
   Ng, JKY
   Nath, A
AF Lam, Kam-Yiu
   Tsang, Nelson Wai-Hung
   Han, Song
   Zhang, Wenlong
   Ng, Joseph Kee-Yin
   Nath, Ajit
TI Activity tracking and monitoring of patients with alzheimer's disease
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion detection; Pervasive computing; Health informatics Context-aware
   computing
ID FALL DETECTION
AB In this paper, by applying motion detection and machine learning technologies, we have designed and developed an activity tracking and monitoring system, called SmartMind, to help Alzheimer's Disease (AD) patients to live independently within their living rooms while providing emergency assistances and supports when necessary. Allowing AD patients to handle their daily activities not only can release the burdens on their families and caregivers, it is also highly important to help them regain confidence towards a healthy life. The daily activities of a patient captured from SmartMind can also serve as an important indicator to describe his/her normal living habit (NLH). By checking NLH, the patient's current health status can be estimated on a daily basis. In the testing experiments of SmartMind, we have demonstrated the accuracy of SmartMind in activity detection and investigated its performance when different machine learning algorithms were adopted for posture detection. The performance results indicate that both support vector machine (SVM) and naive bayes (NB) can achieve an accuracy of higher than 97 % while the random forrests (RF) only gives an accuracy of around 73 %.
C1 [Lam, Kam-Yiu; Tsang, Nelson Wai-Hung; Nath, Ajit] City Univ Hong Kong, Dept Comp Sci, Kowloon Tong, Hong Kong, Peoples R China.
   [Han, Song] Univ Connecticut, Dept Comp Sci & Engn, Storrs, CT USA.
   [Zhang, Wenlong] Arizona State Univ, Polytech Sch, Ira A Fulton Sch Engn, Tempe, AZ 85287 USA.
   [Ng, Joseph Kee-Yin] Baptist Univ Hong Kong, Dept Comp, Kowloon Tong, Hong Kong, Peoples R China.
C3 City University of Hong Kong; University of Connecticut; Arizona State
   University; Arizona State University-Tempe; Hong Kong Baptist University
RP Lam, KY (corresponding author), City Univ Hong Kong, Dept Comp Sci, Kowloon Tong, Hong Kong, Peoples R China.
EM cskylam@cityu.edu.hk; nelson.tsang@cityu.edu.hk; song@engr.uconn.edu;
   Wenlong.Zhang@asu.edu; jng@comp.hkbu.edu.hk
RI Lam, Kam Yiu/W-3711-2018
CR [Anonymous], 2013, WORKSH ASS SERV ROB
   Bardram JakobE., 2013, P SIGCHI C HUMAN FAC, P2627, DOI [DOI 10.1145/2470654.2481364, 10.1145/2470654.2481364]
   Bian Z-P, 2014, IEEE J BIOMED HLTH I, V19
   Bianchi F, 2010, IEEE T NEUR SYS REH, V18, P619, DOI 10.1109/TNSRE.2010.2070807
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Browning RC, 2006, J APPL PHYSIOL, V100, P390, DOI 10.1152/japplphysiol.00767.2005
   Chang C.C., LIBSVM: a library for support vector machines
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cottone P, 2014, IERI PROC, V7, P49, DOI 10.1016/j.ieri.2014.08.009
   Dawadi PN, 2013, IEEE T SYST MAN CY-S, V43, P1302, DOI 10.1109/TSMC.2013.2252338
   de Urturi Breton Zelai Saenz, 2012, 2012 IEEE 14th International Conference on e-Health Networking, Applications and Services (Healthcom 2012), P325, DOI 10.1109/HealthCom.2012.6379430
   Díaz-Ramírez A, 2013, 2013 9TH IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING IN SENSOR SYSTEMS (IEEE DCOSS 2013), P460, DOI 10.1109/DCOSS.2013.18
   Dickerson R.F., 2011, Wireless Health, P5, DOI DOI 10.1145/2077546.2077552
   Gaggioli A, 2013, PERS UBIQUIT COMPUT, V17, P241, DOI 10.1007/s00779-011-0465-2
   Hong Kong Hospital Authority, 2014, SMART PAT WEBS DEM H
   Khan WZ, 2013, IEEE COMMUN SURV TUT, V15, P402, DOI 10.1109/SURV.2012.031412.00077
   Lai CF, 2011, IEEE SENS J, V11, P763, DOI 10.1109/JSEN.2010.2062501
   Lane ND, 2010, IEEE COMMUN MAG, V48, P140, DOI 10.1109/MCOM.2010.5560598
   Lin Q, 2012, I C CONT AUTOMAT ROB, P672, DOI 10.1109/ICARCV.2012.6485238
   Lopez-de-Ipina K., 2013, 2013 IEEE 17th International Conference on Intelligent Engineering Systems (INES), P61, DOI 10.1109/INES.2013.6632783
   Low LSA, 2011, IEEE T BIO-MED ENG, V58, P574, DOI 10.1109/TBME.2010.2091640
   Mace N.L., 2012, The 36-hour day: A family guide to care for people who have Alzheimer's disease, related dementias, and memory loss, V2nd
   Microsoft Crop, 2014, KIN FOR WIND
   Mubashir M, 2013, NEUROCOMPUTING, V100, P144, DOI 10.1016/j.neucom.2011.09.037
   Naranjo-Hernández D, 2012, IEEE T BIO-MED ENG, V59, P3177, DOI 10.1109/TBME.2012.2206384
   Navarro RF, 2014, IEEE J BIOMED HEALTH, V18, P361, DOI 10.1109/JBHI.2013.2267542
   Newport MT, 2013, ALZHEIMERS DIS WHAT
   Norvig SJRP, 2003, ARTIFICIAL INTELLIGE
   Nyan M, 2008, J BIOMECH, V41
   Opperman C. A., 2011, Proceedings of the 2011 3rd International Workshop on Near Field Communication. NFC 2011, P44, DOI 10.1109/NFC.2011.11
   Poh MZ, 2012, IEEE PERVAS COMPUT, V11, P18, DOI 10.1109/MPRV.2010.91
   Rantz MJ, 2014, J GERONTOL NURS, V40, P13, DOI 10.3928/00989134-20131126-01
   Roark B, 2011, IEEE T AUDIO SPEECH, V19, P2081, DOI 10.1109/TASL.2011.2112351
   Rougier C, 2011, IEEE T CIRC SYST VID, V21, P611, DOI 10.1109/TCSVT.2011.2129370
   Scarff SK, 2012, DEMENTIA JOURNEY AHE
   Scully CG, 2012, IEEE T BIO-MED ENG, V59, P303, DOI 10.1109/TBME.2011.2163157
   Shi GY, 2009, IEEE SENS J, V9, P495, DOI 10.1109/JSEN.2008.2012212
   Simplicio MA, 2015, IEEE J BIOMED HEALTH, V19, P761, DOI 10.1109/JBHI.2014.2320444
   Stone E, 2011, J AMB INTEL SMART EN, V3, P349, DOI 10.3233/AIS-2011-0124
   Taub DM, 2011, IEEE PERVAS COMPUT, V10, P68, DOI 10.1109/MPRV.2010.44
   Yuanchao Ma, 2012, Proceedings of the 2012 Ninth International Conference on Wearable and Implantable Body Sensor Networks (BSN 2012), P142, DOI 10.1109/BSN.2012.3
   Zhifeng Xiao, 2013, International Journal of Security and Networks, V8, P40
   Zmily A., 2013, 7 INT C PERV COMP TE
NR 43
TC 18
Z9 18
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 489
EP 521
DI 10.1007/s11042-015-3047-x
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000022
DA 2024-07-18
ER

PT J
AU Lin, CC
   Huang, YH
   Tai, WL
AF Lin, Chia-Chen
   Huang, Yuehong
   Tai, Wei-Liang
TI A novel hybrid image authentication scheme based on absolute moment
   block truncation coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image authentication; Tamper detection; Absolute moment block truncation
   coding; Watermarking
ID COMPRESSION; WATERMARK
AB We propose a novel hybrid image authentication scheme to protect the integrity of images compressed by absolute moment block truncation coding (AMBTC). In this paper, we use a hybrid strategy to embed the authentication codes using AMBTC that at the same time improves the embedding efficiency. All blocks of a compressed image are classified into two groups, smooth and complex, which have different characteristics and may suit different embedding methods. For smooth blocks, the authentication code will be embedded into the bitmap (BM) of each block. For complex blocks, the authentication code will be embedded into quantization levels of each block according to a reference table. In contrast to the previous approach, the hybrid strategy allows for a high utilization of blocks that have high embedding efficiency for embedding, thus giving a significantly improved embedding capacity than the previous approach. The performance is evaluated experimentally to demonstrate that our proposed scheme provides improved image quality and is less vulnerable to tampering compared with existing methods.
C1 [Lin, Chia-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taichung, Taiwan.
   [Huang, Yuehong] Natl Chiao Tung Univ, Inst Comp Sci & Engn, Hsinchu, Taiwan.
   [Tai, Wei-Liang] Chinese Culture Univ, Dept Informat Commun, Taipei, Taiwan.
C3 Providence University - Taiwan; National Yang Ming Chiao Tung
   University; Chinese Culture University
RP Tai, WL (corresponding author), Chinese Culture Univ, Dept Informat Commun, Taipei, Taiwan.
EM ally.cclin@gmail.com; fulva.hyh@gmail.com; tai.wei.liang@gmail.com
RI Tai, Wei-Liang/V-2841-2019
OI Tai, Wei-Liang/0000-0001-7517-7570; Lin, Chia-Chen/0000-0003-4480-7351
FU Ministry of Science and Technology [MOST 103-2632-E-126-001-MY3]
FX This work was supported in part by Ministry of Science and Technology
   under the Grant MOST 103-2632-E-126-001-MY3.
CR Abdallah EE, 2006, INT C PATT RECOG, P673
   Abdallah EE, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2764466
   Ahmed F, 2010, SIGNAL PROCESS, V90, P1456, DOI 10.1016/j.sigpro.2009.05.024
   [Anonymous], 20492 NPL DITC
   [Anonymous], P ICIP 98 CHIC US
   [Anonymous], P SPIE SEC WAT MULT
   [Anonymous], P 6 IEEE INT WORKSH
   Blakley GR, 1979, RIVEST SHAMIR ADLEMA
   Chuang JC, 2011, J VIS COMMUN IMAGE R, V22, P440, DOI 10.1016/j.jvcir.2011.03.011
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   DIFFIE W, 1977, COMPUTER, V10, P74, DOI 10.1109/C-M.1977.217750
   FRANTI P, 1994, COMPUT J, V37, P308, DOI 10.1093/comjnl/37.4.308
   FRIEDMAN GL, 1993, IEEE T CONSUM ELECTR, V39, P905, DOI 10.1109/30.267415
   Goljan M., 2001, 4th Information Hiding Workshop, LNCS, V2137, P27, DOI DOI 10.1007/3-540-45496-9
   Haouzia A, 2007, METHODS IMAGE AUTHEN
   Hu YC, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013012
   Hui YC, 2013, INT J SECUR APPL, V7, P11
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Lie WN, 2006, IEEE T INF FOREN SEC, V1, P330, DOI 10.1109/TIFS.2006.879297
   Lin CY, 2001, IEEE T CIRC SYST VID, V11, P153, DOI 10.1109/76.905982
   Matsuo T, 2004, IEICE T FUND ELECTR, VE87A, P67
   Qi XJ, 2011, J VIS COMMUN IMAGE R, V22, P187, DOI 10.1016/j.jvcir.2010.12.005
   Rabbani M., 1991, DIGITAL IMAGE COMPRE
   Schneider M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P227, DOI 10.1109/ICIP.1996.560425
   van Leest A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P731
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Wong PW, 1998, P IS T PIC C PORTL
   Wong PW, 1998, P ICIP CHIC
NR 29
TC 32
Z9 32
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 463
EP 488
DI 10.1007/s11042-015-3059-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000021
DA 2024-07-18
ER

PT J
AU Lu, YR
   Li, LX
   Peng, HP
   Yang, YX
AF Lu, Yanrong
   Li, Lixiang
   Peng, Haipeng
   Yang, Yixian
TI An anonymous two-factor authenticated key agreement scheme for session
   initiation protocol using elliptic curve cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authenticated key agreement; Two-factor; Smart cards; Session initiation
   protocol
ID PRIVACY-PRESERVING AUTHENTICATION; SECURE AUTHENTICATION; EFFICIENT
AB The Session Initiation Protocol (SIP) is a signaling protocol widely applied in the world of multimedia communication. Numerous SIP authenticated key agreement schemes have been proposed with the purpose of ensuring security communication. Farash recently put forward an enhancement employing smart cards counted on Zhang et al.'s scheme. In this study, we observe that the enhanced scheme presented by Farash has also some security pitfalls, such as disclosure of user identity, lack of a pre-authentication in the smart card and vulnerability to key-compromise masquerading attack which results in an off-line guessing attack. We then propose an anonymous modified scheme with elliptic curve cryptography to eliminate the security leakages of the scheme proposed by Farash. We demonstrate that our scheme is immune to different kinds of attacks including attacks involved in Farash's scheme. We mention Burrows-Abadi-Needham logic for completeness of the proposed scheme. Also, we compare the performance of our scheme with its predecessor schemes and the comparative results shows that it perfectly satisfies the needs of SIP.
C1 [Lu, Yanrong; Li, Lixiang; Peng, Haipeng; Yang, Yixian] Beijing Univ Posts & Telecommun, Informat Secur Ctr, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
   [Lu, Yanrong; Li, Lixiang; Peng, Haipeng; Yang, Yixian] Beijing Univ Posts & Telecommun, Natl Engn Lab Disaster Backup & Recovery, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Beijing University of
   Posts & Telecommunications
RP Li, LX (corresponding author), Beijing Univ Posts & Telecommun, Informat Secur Ctr, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.; Li, LX (corresponding author), Beijing Univ Posts & Telecommun, Natl Engn Lab Disaster Backup & Recovery, Beijing 100876, Peoples R China.
EM li_lixiang2006@163.com
RI Li, lixiang/G-6222-2011
OI Lixiang, Li/0000-0001-9949-8731; Li, Lixiang/0000-0001-8541-308X
FU National Natural Science Foundation of China [61472045, 61573067]; Asia
   Foresight Program under NSFC [61411146001]; BUPT Excellent Ph.D.
   Students Foundation [CX2015310]; Beijing Natural Science Foundation
   [4142016]
FX The authors are grateful to all the anonymous reviewers for their
   valuable comments. This study is supported by the National Natural
   Science Foundation of China (Grant nos. 61472045, and 61573067), the
   Asia Foresight Program under NSFC Grant (Grant No. 61411146001), the
   BUPT Excellent Ph.D. Students Foundation (Grant No. CX2015310), and the
   Beijing Natural Science Foundation (Grant No. 4142016)
CR [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], ADV CRYPTOLOGY CRYPT
   [Anonymous], RFC2617 IETF
   [Anonymous], 3261 IETFRFC
   Arshad R, 2013, MULTIMED TOOLS APPL, V66, P165, DOI 10.1007/s11042-011-0787-0
   BURROWS M, 1990, ACM T COMPUT SYST, V8, P18, DOI [10.1145/77648.77649, 10.1145/74851.74852]
   Deebak BD, 2016, MULTIMED TOOLS APPL, V75, P5795, DOI 10.1007/s11042-015-2542-4
   Farash MS, 2017, INT J COMMUN SYST, V30, DOI 10.1002/dac.2879
   Farash MS, 2016, MULTIMED TOOLS APPL, V75, P4485, DOI 10.1007/s11042-015-2487-7
   Guo LK, 2014, IEEE T MOBILE COMPUT, V13, P1927, DOI 10.1109/TMC.2013.84
   Irshad A, 2015, MULTIMED TOOLS APPL, V74, P3967, DOI 10.1007/s11042-013-1807-z
   Jiang Q, 2015, INT J COMMUN SYST, V28, P1340, DOI 10.1002/dac.2767
   Jo HJ, 2014, IEEE T MOBILE COMPUT, V13, P1469, DOI 10.1109/TMC.2013.134
   Kilinc HH, 2014, IEEE COMMUN SURV TUT, V16, P1005, DOI 10.1109/SURV.2013.091513.00050
   Koblitz N, 2000, DESIGN CODE CRYPTOGR, V19, P173, DOI 10.1023/A:1008354106356
   Kolbitz N., 1987, MATH COMPUT, V48, P203
   Liu JW, 2014, IEEE T PARALL DISTR, V25, P332, DOI 10.1109/TPDS.2013.145
   Lu RX, 2012, IEEE T PARALL DISTR, V23, P32, DOI 10.1109/TPDS.2011.95
   Lu YR, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/894549
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   Qin ZG, 2014, INFORM SCIENCES, V268, P447, DOI 10.1016/j.ins.2013.11.015
   Song RG, 2010, COMPUT STAND INTER, V32, P321, DOI 10.1016/j.csi.2010.03.008
   Sun DZ, 2009, IEEE T IND ELECTRON, V56, P2284, DOI 10.1109/TIE.2009.2016508
   Tang HB, 2013, MULTIMED TOOLS APPL, V65, P321, DOI 10.1007/s11042-012-1001-8
   Tu H, 2014, PEER PEER NETW APPL, P1
   Turkanovic M, 2014, AD HOC NETW, V20, P96, DOI 10.1016/j.adhoc.2014.03.009
   Wang D, 2015, IEEE T DEPEND SECURE, V12, P428, DOI 10.1109/TDSC.2014.2355850
   Yang CC, 2005, COMPUT SECUR, V24, P381, DOI 10.1016/j.cose.2004.10.007
   Yeh HL, 2014, COMPUT STAND INTER, V36, P397, DOI 10.1016/j.csi.2013.08.010
   Zhang LP, 2014, SECUR COMMUN NETW, V7, P2405, DOI 10.1002/sec.951
   Zhang LP, 2014, INT J COMMUN SYST, V27, P2691, DOI 10.1002/dac.2499
   Zhu XY, 2014, IEEE T VEH TECHNOL, V63, P907, DOI 10.1109/TVT.2013.2294032
NR 32
TC 27
Z9 27
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 1801
EP 1815
DI 10.1007/s11042-015-3166-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000009
DA 2024-07-18
ER

PT J
AU Pirahandeh, M
   Kim, DH
AF Pirahandeh, Mehdi
   Kim, Deok-Hwan
TI Energy-aware and intelligent storage features for multimedia devices in
   smart classroom
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart classroom; Multimedia storage; Erasure coding; Chunking strategy;
   Energy consumption
ID ERASURE CODES
AB With the recent big-data processing in multimedia devices becoming a popular application, a fast and energy efficient storage area network system for smart classroom is required. Traditional storage management system for smart classroom show low performance when small read and write operations are executed. This paper proposes a smart classroom storage management system (SCSMS) which consists of new adaptive chunking and XOR reference matrix based erasure coding techniques for multimedia devices with higher input/output performance and low energy consumption. The SCSI initiator is installed in multimedia devices such as smart TVs, smart phones and personal computers. The proposed adaptive chunking and exclusive-or (XOR) reference matrix-redundant array of inexpensive disks (XRM-RAID)are provided at a target server based on flash array storage, respectively. Adaptive chunking differs from traditional chunking in that it reduces the number of read and write operations by merging small files into a united chunk. XRM-RAID differs from existing RAID in that it reduces the number of XOR operations to generate parity data in the RAID system. This paper provides web based monitoring application of the proposed SCSMS. Experimental results show that the energy consumption of the proposed SCSMS is improved by 32 %, 42 % and 58 % compared to Huang et al., Kim et al. and Scott et al. with respect to file size and buffer size. In terms of the average write throughput, the proposed SCSMS has higher performance by 22 %, 32 % and 56 % compared to Huang et al., Kim et al. and Scott et al. with respect to file size and buffer size.
C1 [Pirahandeh, Mehdi; Kim, Deok-Hwan] Inha Univ, Dept Elect Engn, Inchon 402751, South Korea.
C3 Inha University
RP Kim, DH (corresponding author), Inha Univ, Dept Elect Engn, Inchon 402751, South Korea.
EM deokhwan@inha.ac.kr
RI PIRAHANDEH, MEHDI/AAM-1196-2020
OI PIRAHANDEH, MEHDI/0000-0002-3644-3300
FU MSIP(Ministry of Science, ICT and Future Planning), Korea under ICT/SW
   Creative Research program [NIPA-2014-H0502-14-3002]; National Research
   Foundation of Korea(NRF) - Korean Government(MOE) [2013R1A1A2006912];
   Inha University
FX This work was supported in part by the MSIP(Ministry of Science, ICT and
   Future Planning), Korea, under the ICT/SW Creative Research program
   (NIPA-2014-H0502-14-3002) supervised by the NIPA(National IT Industry
   Promotion Agency) and in part by the National Research Foundation of
   Korea(NRF) Grant funded by the Korean Government(MOE) (2013R1A1A2006912)
   and in part by Inha University Research Grant.
CR Blaum M., 1995, IEEE T COMPUT, V44, P2
   Cooley JA, 2003, IEEE S MASS STOR SYS, P157, DOI 10.1109/MASS.2003.1194852
   Gill K, 2009, IEEE T CONSUM ELECTR, V55, P422, DOI 10.1109/TCE.2009.5174403
   Greenan K.M., 2010, IEEE 26 S MASS STORA, P1, DOI DOI 10.1109/MSST.2010.5496983
   Hafner JamesLee., 2005, P 4 C USENIX C FILE, V4, P16
   Hafner JL, 2005, USENIX ASSOCIATION PROCEEDINGS OF THE 4TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES, P183
   Han DM, 2010, IEEE T CONSUM ELECTR, V56, P1417, DOI 10.1109/TCE.2010.5606278
   Han DM, 2010, IEEE T CONSUM ELECTR, V56, P1403, DOI 10.1109/TCE.2010.5606276
   Huang TC, 2013, IEEE T CONSUM ELECTR, V59, P122, DOI 10.1109/TCE.2013.6490250
   Jiang S., 2005, P 4 C USENIX C FIL S, V4, P8
   Kenchammana D, 2005, P USENIX C FIL STOR, P261
   Khan O, 2012, P USENIX C FIL STOR
   Kim J, 2013, MOL CELL TOXICOL, V9, P9, DOI 10.1007/s13273-013-0002-7
   Luo JQ, 2009, I C DEPEND SYS NETWO, P504, DOI 10.1109/DSN.2009.5270300
   Pirahandeh M., 2012, ITC CSCC, P81
   Plank J.S., 2011, IEEE INFORM THEORY W, P529
   Scott K, 2010, IEEE T LEARN TECHNOL, V3, P214, DOI 10.1109/TLT.2010.12
   Svetlana K, 2011, IEEE SENS J, V11, P7835
   Won Y, 2007, ENERGY AWARE DISK SC, V13, P409
   Xie T, 2008, IEEE T COMPUT, V57, P748, DOI 10.1109/TC.2008.27
NR 20
TC 14
Z9 14
U1 0
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1139
EP 1157
DI 10.1007/s11042-015-3019-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000050
DA 2024-07-18
ER

PT J
AU Verma, GK
   Tiwary, US
AF Verma, Gyanendra K.
   Tiwary, Uma Shanker
TI Affect representation and recognition in 3D continuous
   valence-arousal-dominance space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affect representation; Emotion recognition; Valence; Arousal; Dominance;
   Physiological signals; EEG; Classification and clustering of emotions
ID EMOTION; INFORMATION
AB Currently, the focus of research on human affect recognition has shifted from six basic emotions to complex affect recognition in continuous two or three dimensional space due to the following challenges: (i) the difficulty in representing and analyzing large number of emotions in one framework, (ii) the problem of representing complex emotions in the framework, and (iii) the lack of validation of the framework through measured signals, and (iv) the lack of applicability of the selected framework to other aspects of affective computing. This paper presents a Valence - Arousal - Dominance framework to represent emotions. This framework is capable of representing complex emotions on continuous 3D space. To validate the model, an affect recognition technique has been proposed that analyses spontaneous physiological (EEG) and visual cues. The DEAP dataset is a multimodal emotion dataset which contains video and physiological signals as well as Valence, Arousal and Dominance values. This dataset has been used for multimodal analysis and recognition of human emotions. The results prove the correctness and sufficiency of the proposed framework. The model has also been compared with other two dimensional models and the capacity of the model to represent many more complex emotions has been discussed.
C1 [Verma, Gyanendra K.] Natl Inst Technol, Dept Comp Enggineering, Kurukshetra 136119, Haryana, India.
   [Tiwary, Uma Shanker] Indian Inst Informat Technol, Dept Informat Technol, Allahabad 211012, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra; Indian Institute of Information Technology
   Allahabad
RP Verma, GK (corresponding author), Natl Inst Technol, Dept Comp Enggineering, Kurukshetra 136119, Haryana, India.
EM gyanendra@nitkkr.ac.in; ust@iiita.ac.in
RI Verma, Gyanendra K/A-1013-2016
OI Tiwary, Uma Shanker/0000-0001-7206-9013
CR [Anonymous], P IEEE ASRU
   [Anonymous], THE
   [Anonymous], 2011, IEEE T AFFECTIVE COM
   [Anonymous], 2006, P 8 INT C MULT INT, DOI [10.1145/1180995.1181029, DOI 10.1145/1180995.1181029]
   Arifin S, 2008, IEEE T MULTIMEDIA, V10, P1325, DOI 10.1109/TMM.2008.2004911
   Chung SY, 2012, 2012 12TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS), P1768
   EKMAN P, 1987, J PERS SOC PSYCHOL, V53, P712, DOI 10.1037/0022-3514.53.4.712
   Fragopanagos N, 2005, NEURAL NETWORKS, V18, P389, DOI 10.1016/j.neunet.2005.03.006
   Glowinski D., 2008, PROC IEEE CS C COMPU, P1
   Gunes H, 2013, IMAGE VISION COMPUT, V31, P120, DOI 10.1016/j.imavis.2012.06.016
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Liu Y., 2013, T COMPUTATIONAL SCI, P101
   Mansoorizadeh M, 2010, MULTIMED TOOLS APPL, V49, P277, DOI 10.1007/s11042-009-0344-2
   Morris JD, 1995, J ADVERTISING RES, V35, P63
   Picard RW, 2003, INT J HUM-COMPUT ST, V59, P55, DOI 10.1016/S1071-5819(03)00052-1
   Saha A, 2010, INT CONF ACOUST SPEE, P2470, DOI 10.1109/ICASSP.2010.5494892
   Said CP, 2011, PHILOS T R SOC B, V366, P1660, DOI 10.1098/rstb.2010.0351
   SCHACHTER S, 1962, PSYCHOL REV, V69, P379, DOI 10.1037/h0046234
   Schuller B, 2011, IEEE T AFFECT COMPUT, V2, P192, DOI 10.1109/T-AFFC.2011.17
   Selenbas B, 2010, PROCEEDINGS OF THE ASME 10TH BIENNIAL CONFERENCE ON ENGINEERING SYSTEMS DESIGN AND ANALYSIS, 2010, VOL 3, P121
   SMITH CA, 1985, J PERS SOC PSYCHOL, V48, P813, DOI 10.1037/0022-3514.48.4.813
   Stickel C, 2007, UNIVERSAL ACCESS IN HUMAN-COMPUTER INTERACTION: APPLICATIONS AND SERVICES, PT 3, PROCEEDINGS, P813
   Sumana IJ, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P11, DOI 10.1109/MMSP.2008.4665041
   Verma GK, 2014, NEUROIMAGE, V102, P162, DOI 10.1016/j.neuroimage.2013.11.007
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang YJ, 2012, IEEE T MULTIMEDIA, V14, P597, DOI 10.1109/TMM.2012.2189550
   Wöllmer M, 2010, IEEE J-STSP, V4, P867, DOI 10.1109/JSTSP.2010.2057200
   Wu X, 2010, CHINESE-GERMAN JOINT SYMPOSIUM ON HYDRAULIC AND OCEAN ENGINEERING (CG JOINT 2010), P121
   Yoon HJ, 2013, COMPUT BIOL MED, V43, P2230, DOI 10.1016/j.compbiomed.2013.10.017
NR 29
TC 58
Z9 64
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2159
EP 2183
DI 10.1007/s11042-015-3119-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA VI3PJ
UT WOS:000474729700001
DA 2024-07-18
ER

PT J
AU Zhang, T
   Jia, WJ
   Yang, BQ
   Yang, J
   He, XJ
   Zheng, ZL
AF Zhang, Tao
   Jia, Wenjing
   Yang, Baoqing
   Yang, Jie
   He, Xiangjian
   Zheng, Zhonglong
TI MoWLD: a robust motion image descriptor for violence detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Violence detection; Surveillance systems; Motion weber local descriptors
   (MoWLD); Kernel density estimation (KDE); Sparse coding; Max pooling
ID KERNEL DENSITY-ESTIMATION; ACTION RECOGNITION; BEHAVIOR
AB Automatic violence detection from video is a hot topic for many video surveillance applications. However, there has been little success in designing an algorithm that can detect violence in surveillance videos with high performance. Existing methods typically apply the Bag-of-Words (BoW) model on local spatiotemporal descriptors. However, traditional spatiotemporal features are not discriminative enough, and also the BoW model roughly assigns each feature vector to only one visual word and therefore ignores the spatial relationships among the features. To tackle these problems, in this paper we propose a novel Motion Weber Local Descriptor (MoWLD) in the spirit of the well-known WLD and make it a powerful and robust descriptor for motion images. We extend the WLD spatial descriptions by adding a temporal component to the appearance descriptor, which implicitly captures local motion information as well as low-level image appear information. To eliminate redundant and irrelevant features, the non-parametric Kernel Density Estimation (KDE) is employed on the MoWLD descriptor. In order to obtain more discriminative features, we adopt the sparse coding and max pooling scheme to further process the selected MoWLDs. Experimental results on three benchmark datasets have demonstrated the superiority of the proposed approach over the state-of-the-arts.
C1 [Zhang, Tao; Yang, Baoqing; Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai, Peoples R China.
   [Jia, Wenjing; He, Xiangjian] Univ Technol Sydney, Fac Engn & Informat Technol, Ultimo, Australia.
   [Zheng, Zhonglong] Zhejiang Normal Univ, Dept Comp Sci, Jinhua, Peoples R China.
C3 Shanghai Jiao Tong University; University of Technology Sydney; Zhejiang
   Normal University
RP Yang, J (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai, Peoples R China.
EM zhb827@sjtu.edu.cn; Wenjing.Jia@uts.edu.au; yang_baoqing@sjtu.edu.cn;
   jieyang@sjtu.edu.cn; Xiangjian.He@uts.edu.au; zhonglong@zjnu.edu.cn
RI Jia, Weijia/W-6152-2019; Yang, Jie/JCD-9867-2023; He,
   Xiangjian/CAA-1461-2022
OI Jia, Wenjing/0000-0002-0940-3338; He, Xiangjian/0000-0001-8962-540X
FU NSFC, China [61273258, 61375048, 61170109]
FX This research was partly supported by NSFC, China (No: 61273258,
   61375048, 61170109).
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Andrade EL, 2006, INT C PATT RECOG, P175
   [Anonymous], 2015, BMVC
   [Anonymous], ADV ARTIFICIAL INTEL
   [Anonymous], 2010, P 27 INT C MACHINE L
   [Anonymous], 10 IEEE PAC RIM C MU
   [Anonymous], TECH REP
   [Anonymous], 2013, VIS COMPUT
   Baysal S, 2013, SIGNAL PROCESS-IMAGE, V28, P458, DOI 10.1016/j.image.2013.01.005
   Nievas EB, 2011, LECT NOTES COMPUT SC, V6855, P332, DOI 10.1007/978-3-642-23678-5_39
   Bertini M, 2012, COMPUT VIS IMAGE UND, V116, P320, DOI 10.1016/j.cviu.2011.09.009
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Botev ZI, 2010, ANN STAT, V38, P2916, DOI 10.1214/10-AOS799
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Chen M-y, 2009, Mosift: Recognizing human actions in surveillance videos, CMU-CS-09-161
   Cheng W.-H., 2003, P 5 ACM SIGMM INT WO, P109, DOI DOI 10.1145/973264.973282
   Cristani M, 2007, IEEE T MULTIMEDIA, V9, P257, DOI 10.1109/TMM.2006.886263
   Dai P, 2008, IEEE T SYST MAN CY B, V38, P275, DOI 10.1109/TSMCB.2007.909939
   Damen D, 2009, PROC CVPR IEEE, P927, DOI 10.1109/CVPRW.2009.5206636
   Datta A, 2002, INT C PATT RECOG, P433, DOI 10.1109/ICPR.2002.1044748
   de Souza F. D. M., 2010, Proceedings of the 23rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI 2010), P224, DOI 10.1109/SIBGRAPI.2010.38
   Gao LL, 2015, PROC CVPR IEEE, P4371, DOI 10.1109/CVPR.2015.7299066
   Geng XL, 2012, BIOMED SIGNAL PROCES, V7, P112, DOI 10.1016/j.bspc.2011.03.002
   Hassner T., 2012, 2012 IEEE COMP SOC C, P1, DOI [DOI 10.1109/CVPRW.2012.6239348, 10.1109/CVPRW.2012.6239348]
   Huesmann LR, 2003, DEV PSYCHOL, V39, P201, DOI 10.1037/0012-1649.39.2.201
   Li ST, 2013, NEUROCOMPUTING, V122, P272, DOI 10.1016/j.neucom.2013.05.038
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   Nam J, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P353, DOI 10.1109/ICIP.1998.723496
   Nguyen NT, 2005, PROC CVPR IEEE, P955
   Oikonomopoulos A, 2007, LECT NOTES COMPUT SC, V4451, P133
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   Roshtkhari MJ, 2013, PROC CVPR IEEE, P2611, DOI 10.1109/CVPR.2013.337
   Saghafi B, 2012, SIGNAL PROCESS-IMAGE, V27, P96, DOI 10.1016/j.image.2011.05.002
   Shi YF, 2004, PROC CVPR IEEE, P862
   Tran D, 2008, LECT NOTES COMPUT SC, V5302, P548, DOI 10.1007/978-3-540-88682-2_42
   Vishwakarma S., 2011, IEEE INT C SIGNAL PR, P1
   Wang B, 2011, IEEE SIGNAL PROC LET, V18, P462, DOI 10.1109/LSP.2011.2158998
   Yang JC, 2010, PROC CVPR IEEE, P3517, DOI 10.1109/CVPR.2010.5539958
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P572, DOI 10.1109/TMM.2012.2234731
   Zhang D, 2006, IEEE T MULTIMEDIA, V8, P509, DOI 10.1109/TMM.2006.870735
   Zhang T, 2016, MULTIMED TOOLS APPL, V75, P7327, DOI 10.1007/s11042-015-2648-8
   Zhou W, 2014, SIGNAL PROCESS-IMAGE, V29, P546, DOI 10.1016/j.image.2014.01.012
   Zhu Y, 2011, LECT NOTES COMPUT SC, V6493, P660
NR 46
TC 59
Z9 60
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1419
EP 1438
DI 10.1007/s11042-015-3133-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000062
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ciaramella, A
   Gianfico, M
   Giunta, G
AF Ciaramella, Angelo
   Gianfico, Marco
   Giunta, Giulio
TI Compressive sampling and adaptive dictionary learning for the packet
   loss recovery in audio multimedia streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressive sampling; Dictionary learning; Multimedia streaming;
   Interleaving
AB In this work, a scheme based on a compressive sampling technique and a fast dictionary learning approach for reconstructing audio content in multimedia streaming is introduced. Audio streaming data are encapsulated in different packets by means of an interleaving technique. The compressive sampling technique is used to reconstruct audio information in case of lost packets, with a sparsifying basis provided by a greedy adaptive dictionary learning algorithm. In order to assess the performance of the methodology, several experiments on speech and musical audio signals are presented.
C1 [Ciaramella, Angelo; Gianfico, Marco; Giunta, Giulio] Univ Naples Parthenope, Dept Sci & Technol, Ctr Direz Isola C4, I-80143 Naples, Italy.
C3 Parthenope University Naples
RP Ciaramella, A (corresponding author), Univ Naples Parthenope, Dept Sci & Technol, Ctr Direz Isola C4, I-80143 Naples, Italy.
EM angelo.ciaramella@uniparthenope.it;
   marco.gianfico@studenti.uniparthenope.it; giulio.giunta@uniparthenope.it
OI Giunta, Giulio/0000-0003-0101-6154; Ciaramella,
   Angelo/0000-0001-5592-7995
FU "Sostegno alla ricerca individuale per il triennio" project of the
   University of Naples "Parthenope"
FX This work was partially funded by the "Sostegno alla ricerca individuale
   per il triennio 2015-2017" project of the University of Naples
   "Parthenope".
CR Adler A, 2012, IEEE T AUDIO SPEECH, V20, P922, DOI 10.1109/TASL.2011.2168211
   [Anonymous], THEORY PRACTICE
   Bahat Y, 2015, SIGNAL PROCESS, V111, P61, DOI 10.1016/j.sigpro.2014.11.023
   Banu JF, 2013, INT J COMPUT SCI ELE, V1
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duric A, 2004, REAL TIME TRANSPORT
   Feamster N., 2002, 12 INT PACK VID WORK
   Fornasier M, 2008, APPL COMPUT HARMON A, V25, P187, DOI 10.1016/j.acha.2007.10.005
   Griffin A, 2011, IEEE T AUDIO SPEECH, V19, P1382, DOI 10.1109/TASL.2010.2090656
   Handley Mark, 1997, ISIRR97450
   Hovorka J, 2009, ADV MIL TECHNOL, V4
   Hu R., 2014, OPEN AUTOM CONTROL S, V6, P188, DOI [10.2174/1874444301406010188, DOI 10.2174/1874444301406010188]
   ITU, PERC EV SPEECH QUAL, P862
   Jafari MG, 2011, IEEE J-STSP, V5, P1025, DOI 10.1109/JSTSP.2011.2157892
   Jensen JR, 2009, IEEE SIGNAL PROC LET, V16, P1083, DOI 10.1109/LSP.2009.2030852
   Kabal P, 2011, TECHNICAL REPORT
   Kleijn WB, 2014, 2014 14TH INTERNATIONAL WORKSHOP ON ACOUSTIC SIGNAL ENHANCEMENT (IWAENC), P70, DOI 10.1109/IWAENC.2014.6953340
   Lindblom J, 2002, IEEE WORKSH P SPEECH
   Lu X., 2013, P 2 INT C COMP SCI E, P1526
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   MILLER GA, 1950, J ACOUST SOC AM, V22, P167, DOI 10.1121/1.1906584
   Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002
   Ofir H, 2006, P IEEE 24 C EL EL EN
   Perkins C, 1998, IEEE NETWORK, V12, P40, DOI 10.1109/65.730750
   Pozueco L, 2013, COMPUT ELECT ENG
   RAMSEY JL, 1970, IEEE T INFORM THEORY, V16, P338, DOI 10.1109/TIT.1970.1054443
   Rodbro CA, 2003, P IEEE INT C AC SPEE
   SCHULZRINNE H, 1996, 1889 RFC
   SUZUKI J, 1989, IEEE J SEL AREA COMM, V7, P707, DOI 10.1109/49.32334
   Toyoshima M, 2014, 2014 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS), P89, DOI 10.1109/APCCAS.2014.7032726
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
NR 32
TC 10
Z9 11
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17375
EP 17392
DI 10.1007/s11042-015-3002-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600028
DA 2024-07-18
ER

PT J
AU Oh, JM
   Hong, SJ
   Moon, N
AF Oh, Jung-Min
   Hong, Sangjin
   Moon, Nammee
TI Gaze behavior data profiling and analysis system platform based on
   visual content representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gaze behavior; Image representation; Correlated multiple image;
   Compressed annotation; Real time monitoring
AB This paper presents a real-time system platform for profiling and analyzing the gaze behavior based on visual contents. The proposed system captures the gaze information from multiple users and provides the ability to measure the degree of visual content perception by the users through statistical analysis. Visual content representation scheme is presented for capturing and annotating the gaze behavior effectively. Information correlation property among multiple image frames is defined for providing the ability to analyze the pattern of perception of user based on complex visual contents. In order to monitor the real time gaze behavior of the users, the monitoring rules are incorporated in to the representation template. The number of users and the duration of observation time may significantly increase the profile data size. To alleviate the problem, an adaptive data compression techniques is incorporated. The capabilities and functionalities of the proposed system are verified for multiple users with different gaze behavior on a sequence of commercial image data.
C1 [Oh, Jung-Min; Hong, Sangjin] SUNY Stony Brook, Dept Elect & Comp Engn, Stony Brook, NY 11794 USA.
   [Moon, Nammee] Hoseo Univ, Dept Comp Engn, Asan 336795, South Korea.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook; Hoseo University
RP Moon, N (corresponding author), Hoseo Univ, Dept Comp Engn, Asan 336795, South Korea.
EM jung.oh@stonybrook.edu; mnm@hoseo.edu
FU 'Cross-Ministry Giga KOREA Project' of the Ministry of Science, ICT and
   Future Planning, Republic of Korea (ROK) [GK14P0100]
FX This research was supported by the 'Cross-Ministry Giga KOREA Project'
   of the Ministry of Science, ICT and Future Planning, Republic of Korea
   (ROK).[GK14P0100, Development of Tele-Experience Service SW Platform
   based on Giga Media]. Also, this paper is extended and improved from
   accepted paper of KCIC-2013/FCC-2014 conferences.
CR Alt F, 2013, CHI 2013 CHANGING PE, P1709
   [Anonymous], J CONVERGENCE
   [Anonymous], J CONVERG
   [Anonymous], J CONVERGENCE
   Armato A, 2013, J REAL-TIME IMAGE PR, V8, P21, DOI 10.1007/s11554-011-0217-6
   Augusto Juan C, 2013, HUMAN CENTRIC COMPUT, P3
   Beymer David, 2005, CHI 05 EXTENDED ABST, P1913, DOI DOI 10.1145/1056808.1057055
   Bloehdorn S, 2005, LECT NOTES COMPUT SC, V3532, P592
   Buscher Georg., 2008, CHI '08 extended abstracts on Human factors in computing systems, P2991
   Castagnos S, 2010, CONSUMER DECISION PA, P1
   Chorianopoulos Konstantinos, 2013, COLLECTIVE INTELLIGE, P3
   Chua HF, 2005, P NATL ACAD SCI USA, V102, P12629, DOI 10.1073/pnas.0506162102
   El-Khoury Vanessa, 2012, MULTIMED TOOLS APPL, P1
   Howard Newton, 2013, HUMAN CTR COMPUTING, P3
   Manh HT, 2013, J INF PROCESS SYST, V9, P592, DOI 10.3745/JIPS.2013.9.4.592
   Jeon J., 2003, P 26 ANN INT ACM SIG
   Kim PS, 2013, J INF PROCESS SYST, V9, P425, DOI 10.3745/JIPS.2013.9.3.425
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Patil PB, 2013, J INF PROCESS SYST, V9, P349, DOI 10.3745/JIPS.2013.9.3.349
   Poole A., 2006, Encyclopedia of human computer interaction, P211, DOI [10.4018/978-1-59140-562-7.ch034, DOI 10.4018/978-1-59140-562-7.CH034]
   Rajashekar U, 2004, HUMAN VISION ELECT I, VIX, P1
   Rajashekar U, 2008, IEEE T IMAGE PROCESS, V17, P564, DOI 10.1109/TIP.2008.917218
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Smith TJ, 2013, J VISION, V13, DOI 10.1167/13.8.16
   Stephen R, 2004, IEEE T SYSTMESMAN A, V34, P472
   Yun K, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00917
   Zoric G, 2013, ACM SIGCHI C HUM FAC, P1
NR 27
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15211
EP 15227
DI 10.1007/s11042-014-2285-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700006
DA 2024-07-18
ER

PT J
AU Riaz, S
   Park, U
   Lee, SW
AF Riaz, Sidra
   Park, Unsang
   Lee, Sang-Woong
TI A photograph reconstruction by object retargeting for better composition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object retargeting; Photo composition; Compositional guidelines;
   Rule-of-thirds; Spectral matting
AB In digital photography, composition rules are essential for capturing highly aesthetic photographs. Aesthetic images create a response of visual appreciation to the viewers. Rule-of-thirds (RoT) is the most important and basic rule accepted by photographers for taking aesthetically pleasing shots. In this paper, a novel computational approach, "Retarget Object for Implementation of Rule-of-Thirds", (ROI-RT) is presented. The ROI-RT technique automatically improves the composition of the photographs according to the photo composition guidelines. For achieving the mentioned task, the key adopted steps are main object segmentation by alpha matting, texture synthesis for occluded background, features extraction for ROI-RT, and retargeting the main object on synthesized background to reproduce a photograph which respects the composition rule RoT, in photography. Experimental results performed on various sets of photographs achieve a compositional accuracy rate of 95 % by proposed approach. Aesthetic scores for the resultant reconstructed photographs are attained by average subjective rating (SR) of 30 people and also computed by online evaluation methods of OSCAR and ACQUINE. Statistical significant test is applied and obtained P-value = 0.0001 < 0.05 shows a promising performance of our ROI-RT compositional scheme. A comparison with existing photo composition techniques shows that ROI-RT provides us a better aesthetic photographic composition.
C1 [Riaz, Sidra; Park, Unsang] Comp Vision & Image Proc Lab, Dept Comp Engn, Seoul, South Korea.
   [Lee, Sang-Woong] Comp Vision & Multimedia Lab, Dept Comp Engn, Gwangju, South Korea.
RP Lee, SW (corresponding author), Comp Vision & Multimedia Lab, Dept Comp Engn, Gwangju, South Korea.
EM sidra@sogang.ac.kr; unsangpark@sogang.ac.kr; swlee@chosun.ac.kr
RI Lee, Sang-Woong/ABF-6191-2020
OI Lee, Sang-Woong/0000-0001-8117-6566; Riaz, Sidra/0000-0002-0216-416X
FU Chosun University
FX This study was supported by research fund from Chosun University, 2015.
CR [Anonymous], 2010, P ACM INT C MULT INF, DOI 10.1145/1743384.1743457
   Banerjee S, 2007, IEEE T IMAGE PROCESS, V16, P1807, DOI 10.1109/TIP.2007.898992
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Chang YY, 2009, IEEE I CONF COMP VIS, P2225, DOI 10.1109/ICCV.2009.5459470
   Levin A., 2007, COMPUTER VISION PATT, P1
   Liu LG, 2010, COMPUT GRAPH FORUM, V29, P469, DOI 10.1111/j.1467-8659.2009.01616.x
   Mai L, 2011, RULE 3 DETECTION PHO, P91
   Mansfield A, 2010, LECT NOTES COMPUT SC, V6311, P143, DOI 10.1007/978-3-642-15549-9_11
   MERRIS R, 1994, LINEAR ALGEBRA APPL, V198, P143
   Park J, 2012, IEEE IMAGE PROC, P2741, DOI 10.1109/ICIP.2012.6467466
   Ren TW, 2009, IEEE INT CON MULTI, P406, DOI 10.1109/ICME.2009.5202520
   Riaz S, 2012, MAIN OBJECT SEGMENTA, P103
   Riaz S, 2015, J CHIN INST ENG, V38, P437, DOI 10.1080/02533839.2014.998163
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Setlur Vidya., 2005, MUM, V154, P59, DOI DOI 10.1145/1149488.1149499
   Sun J, 2011, IEEE I CONF COMP VIS, P1511, DOI 10.1109/ICCV.2011.6126409
   Yao L, 2012, INT J COMPUT VISION, V96, P353, DOI 10.1007/s11263-011-0478-3
NR 17
TC 1
Z9 2
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16439
EP 16460
DI 10.1007/s11042-015-3037-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700069
DA 2024-07-18
ER

PT J
AU Yang, JC
   Xu, R
   Cui, J
   Ding, ZY
AF Yang, Jiachen
   Xu, Ru
   Cui, Jing
   Ding, Zhiyong
TI Robust visual tracking using adaptive local appearance model for smart
   transportation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart transportation; Road system management; Visual tracking; Car
   tracking; Appearance model; Sparse representation; Dictionary learning;
   Sparse coefficient quality
AB Smart transportation plays an important role in building smart cities. We can obtain mass data from multi-source and use it to manage transportation in an intelligent way. Images and videos can be easily obtained from various sensors in modern road system. They offer abundant information about the transportation. Therefore, visual analysis is a key point in smart transportation management. In this paper we propose a robust visual object tracking algorithm using adaptive local appearance model, which can be applied to transportation system. As the main challenge of tracking is to adapt to the target's appearance change, we build the model with a local patch dictionary which is composed of a static part and an online updated part. The updating scheme is important to determine the quality of tracking results. We propose a coefficient quality based on sparse representation as the sign of updating and introduce incremental learning to compute the new information to update the dictionary. This strategy adapts the templates to appearance change and helps reduce the drifting problem. Experimental results on several challenging benchmark image sequences demonstrate the proposed tracking algorithm achieves favorable performance when the target undergoes large occlusion, illumination change and scale variation.
C1 [Yang, Jiachen; Xu, Ru; Ding, Zhiyong] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
   [Xu, Ru] Tianjin Univ, Tianjin Int Engn Inst, Tianjin, Peoples R China.
   [Cui, Jing] Tianjin Nav Instrument Res Inst, 268 Dingzigu 1 St, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin University
RP Xu, R (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.; Xu, R (corresponding author), Tianjin Univ, Tianjin Int Engn Inst, Tianjin, Peoples R China.
EM yangjiachen@tju.edu.cn; xu_ru@tju.edu.cn; U_young@126.com;
   tjudzy@tju.edu.cn
RI Yang, Jiachen/ABH-5032-2020
OI Yang, Jiachen/0000-0003-2558-552X
FU National Natural Science Foundation of China [61471260, 61271324];
   Program for New Century Excellent Talents in University [NCET-12-0400]
FX This research is partially supported by the National Natural Science
   Foundation of China (No. 61471260 and No. 61271324) and Program for New
   Century Excellent Talents in University (NCET-12-0400).
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], ARXIV150406359
   [Anonymous], TELECOMMUNICATION SY
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Chen Z., 2017, Multimedia Tools and Applications, V76, P17669, DOI [DOI 10.1155/2015/749748, DOI 10.1186/S12929-015-0197-0, DOI 10.1007/S11042-015-2882-0]
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276
   Fu C, 2015, MULTIMEDIA TOOLS APP
   Gu W, 2017, MULTIMED TOOLS APPL, V76, P17719, DOI 10.1007/s11042-015-2960-3
   Hong S, 2014, LECT NOTES COMPUT SC, V8689, P1, DOI 10.1007/978-3-319-10590-1_1
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Jiang D, 2015, J COMMUNICATIONS NET
   Jiang DD, 2016, WIRELESS PERS COMMUN, V86, P901, DOI 10.1007/s11277-015-2961-6
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li X, 2015, MULTIMEDIA TOOLS APP
   Lin YC, 2015, SENSORS-BASEL, V15, P20925, DOI 10.3390/s150820925
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Lv ZY, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0061249
   Ma LY, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0070716
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Prokaj J, 2014, PROC CVPR IEEE, P1186, DOI 10.1109/CVPR.2014.155
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Su TY, 2016, COMPUT GRAPH-UK, V54, P65, DOI 10.1016/j.cag.2015.07.019
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu Y, 2011, IEEE I CONF COMP VIS, P1100, DOI 10.1109/ICCV.2011.6126357
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Yang JC, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.3.033001
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yao R, 2013, PROC CVPR IEEE, P2363, DOI 10.1109/CVPR.2013.306
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 36
TC 6
Z9 6
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17487
EP 17500
DI 10.1007/s11042-016-3285-6
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600034
DA 2024-07-18
ER

PT J
AU Zhang, YM
   Liu, GZ
AF Zhang, Yimin
   Liu, Guizhong
TI JCCA resource allocation for video transmission in relay-enhanced OFDMA
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE OFDMA; Relay; Resource allocation; Video transmission
ID COOPERATIVE DIVERSITY; WIRELESS; CHANNEL; H.264/AVC; OPTIMIZATION;
   VISIBILITY; MANAGEMENT; NETWORKS
AB Resulting from the rapid growth of wireless video services in the recent years, radio resource is often inadequate in the high data rate communication environment. Under the circumstance, it is important to make full use of limited resource for efficient video transmission. Hence, we propose a joint content and channel aware (JCCA) resource allocation algorithm in relay-enhanced OFDMA system. It can maximize accumulation of allocated subcarriers' contribution for transmitting video data so as to improve overall quality of users' received video under resource constrained conditions. As it is described in this work, the algorithm is implemented by packet scheduling, path selection and subcarrier allocation, in which time-varying data content and channel state are jointly considered at the same time. And the two implementation schemes, JCCAG and JCCAL, are designed for JCCA resource allocation algorithm. JCCAG is executed for allocating subcarriers through global search among all subcarriers' contribution. For reducing complexity of JCCAG, subcarriers are allocated according to the corresponding contribution towards each user on the basis of local search in JCCAL. In the simulation, we make comparison between the JCCA resource allocation algorithm and others for video transmission in relay-enhanced OFDMA system. And the comparison results are evaluated through objective and subjective criterion, respectively. It is demonstrated that the proposed algorithm can perform better in improving overall quality of users' received video.
C1 [Zhang, Yimin; Liu, Guizhong] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Zhang, YM (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM yimin.zhang@stu.xjtu.edu.cn; liugz@xjtu.edu.cn
CR Ahmad A., 2010, P IEEE WIR COMM NETW, P1
   Alam MS, 2013, IEEE T WIREL COMMUN, V12, P2193, DOI 10.1109/TWC.2013.032113.120652
   [Anonymous], 2010, document TR 36
   [Anonymous], P IEEE WCNC
   [Anonymous], IEEE T COMMUN
   Can B, 2008, IEEE WCNC, P36, DOI 10.1109/WCNC.2008.12
   CLARKE RH, 1968, AT&T TECH J, V47, P957, DOI 10.1002/j.1538-7305.1968.tb00069.x
   Dedu E, 2015, MULTIMED TOOLS APPL, V74, P2963, DOI 10.1007/s11042-013-1764-6
   Díaz C, 2011, IEEE T CONSUM ELECTR, V57, P523, DOI 10.1109/TCE.2011.5955188
   Ghandi MM, 2009, IET COMMUN, V3, P172, DOI 10.1049/iet-com:20080053
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hsiao YM, 2012, IEEE T CONSUM ELECTR, V58, P1314, DOI 10.1109/TCE.2012.6415001
   *IETF, 2003, RFC3550 IETF
   Joint Video Team (JVT), 2011, H 264 AVC REF SOFTW
   Kaneko M, 2009, IEEE T VEH TECHNOL, V58, P1951, DOI 10.1109/TVT.2008.2005058
   Laneman JN, 2004, IEEE T INFORM THEORY, V50, P3062, DOI 10.1109/TIT.2004.838089
   Lehmann EL., 1998, THEORY POINT ESTIMAT, DOI 10.1007/b98854
   Lin YB, 2009, IEEE T WIREL COMMUN, V8, P4066, DOI 10.1109/TWC.2009.080221
   Nazir S, 2015, MULTIMED TOOLS APPL, V74, P5787, DOI 10.1007/s11042-014-1883-8
   Pabst R, 2004, IEEE COMMUN MAG, V42, P80, DOI 10.1109/MCOM.2004.1336724
   Rappaport T.S., 2003, WIRELESS COMMUNICATI, V2nd
   Rappaport TS, 2002, IEEE COMMUN MAG, P148
   Rhee W, 2000, 2000 IEEE 51ST VEHICULAR TECHNOLOGY CONFERENCE, PROCEEDINGS, VOLS 1-3, P1085, DOI 10.1109/VETECS.2000.851292
   Sabir MF, 2009, IEEE T IMAGE PROCESS, V18, P90, DOI 10.1109/TIP.2008.2005819
   Salem M, 2010, IEEE COMMUN SURV TUT, V12, P422, DOI 10.1109/SURV.2010.032210.00071
   Salem M, 2010, IEEE T VEH TECHNOL, V59, P2496, DOI 10.1109/TVT.2010.2042736
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Stockhammer T, 2003, IEEE T CIRC SYST VID, V13, P657, DOI 10.1109/TCSVT.2003.815167
   Sullivan GJ, 2005, P IEEE, V93, P18, DOI 10.1109/JPROC.2004.839617
   Tang J, 2012, IEEE J SEL AREA COMM, V30, P1789, DOI 10.1109/JSAC.2012.121024
   Toni L, 2012, IEEE J SEL AREA COMM, V30, P1172, DOI 10.1109/JSAC.2012.120803
   Wang LF, 2009, 2009 IEEE BUCHAREST POWERTECH, VOLS 1-5, P725, DOI 10.1109/INFCOMW.2009.5072113
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xiaoyu Song, 2010, 2010 3rd International Conference on Advanced Computer Theory and Engineering (ICACTE 2010), P255, DOI 10.1109/ICACTE.2010.5579636
   Yang J, 2013, IEEE SIGNAL PROC LET, V20, P47, DOI 10.1109/LSP.2012.2227473
   Zhang Q, 2005, P IEEE, V93, P123, DOI 10.1109/JPROC.2004.839603
   Zhang SQ, 2008, IEEE T WIREL COMMUN, V7, P4534, DOI 10.1109/T-WC.2008.070154
   Zhang Y, 2007, IEEE T MULTIMEDIA, V9, P445, DOI 10.1109/TMM.2006.887989
NR 40
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15955
EP 15974
DI 10.1007/s11042-015-2908-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700048
DA 2024-07-18
ER

PT J
AU Yan, B
   Liu, XF
   Yang, HM
AF Yan, Bin
   Liu, Xiao-Feng
   Yang, Hong-Mei
TI Structure compliant local warping of images with applications to
   watermarking attack
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Local geometric attack; Displacement field; Directional
   smoothing; Multi-scale pyramid
ID MARKOV RANDOM-FIELD; GEOMETRIC ATTACKS; RESILIENT; ROBUST
AB Localized geometric warping of images is known to be one of the most effective attacks against image watermarking systems. However, the existing local geometrical attacks, when applied to images with regular structures, cause perceptible distortion because they are not adaptive to the content of the images. In this work, we present a multi-scale directional smoothing framework in which local displacement vectors are smoothed by locally adaptive directional kernels. Both the displacement vectors for large structures and those for fine structures are constrained by using a multi-scale pyramid. Subjective tests and objective metrics show that our proposed approach can effectively enhance the perceptual quality of the image after geometric attacks. The test of the attacking effects on two typical watermarking systems demonstrates that our approach does not degrade the attacking effects for Markov random field generated displacement field.
C1 [Yan, Bin] Shandong Univ Sci & Technol, Coll Elect Commun & Phys, Qingdao 266590, Peoples R China.
   [Liu, Xiao-Feng] Hohai Univ, Coll IoT Engn, Dept Telecommun, Changzhou 213022, Peoples R China.
   [Liu, Xiao-Feng] Changzhou Key Lab Robot & Intelligent Technol, Changzhou 213022, Peoples R China.
   [Yang, Hong-Mei] Shandong Univ Sci & Technol, Coll Informat Sci & Engn, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology; Hohai University; Shandong
   University of Science & Technology
RP Yan, B (corresponding author), Shandong Univ Sci & Technol, Coll Elect Commun & Phys, Qingdao 266590, Peoples R China.
EM yanbinhit@hotmail.com; xfliubme@gmail.com; yhm1998@163.com
RI Yan, Bin/Y-7642-2019; Liu, Xiaofeng/HHN-3239-2022; Liu,
   Xiaofeng/JCD-9463-2023
OI Liu, Xiaofeng/0000-0003-1310-6739; Liu, Xiaofeng/0000-0003-1310-6739;
   Yan, Bin/0000-0003-2929-464X
FU National Natural Science Foundation of China (NSFC) [61272432]; Shandong
   Provincial Natural Science Foundation [ZR2014JL044]; Fundamental
   Research Funds for the Central Universities [2011B11114, 2011B07314];
   National Basic Research Program of China (973 Program) [2010CB327902,
   2012CB316402]; Shandong Province Higher Educational Science and
   Technology Program [J10LG24]; Encouragement Foundation for Excellent
   Young and Middle-aged Scientists of Shandong Province [BS2010DX026]
FX The authors would like to thank Dr. Lawrence York for many useful
   suggestions. This work is supported by the National Natural Science
   Foundation of China (NSFC) under the project grant number: 61272432,
   Shandong Provincial Natural Science Foundation (No. ZR2014JL044), and
   the grant from the Fundamental Research Funds for the Central
   Universities (2011B11114, 2011B07314). This work is also supported in
   part by the National Basic Research Program of China (973 Program)(Grant
   no. 2010CB327902,2012CB316402).; The work of Hong-Mei Yang is supported
   by the project of Shandong Province Higher Educational Science and
   Technology Program (Grant No. J10LG24), Encouragement Foundation for
   Excellent Young and Middle-aged Scientists of Shandong Province (Grant
   No. BS2010DX026).
CR Alghoniemy M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1291, DOI 10.1109/ICME.2000.871003
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2001, COMP SCI W
   [Anonymous], 2011, P INT WORKSH DIG WAT
   Balado F, 2005, IEEE T SIGNAL PROCES, V53, P4006, DOI 10.1109/TSP.2005.855412
   Barni J., 2004, WATERMARKING SYSTEMS
   Bas P, 2002, IEEE T IMAGE PROCESS, V11, P1014, DOI 10.1109/TIP.2002.801587
   Bin Yan, 2010, Proceedings 2010 First International Conference on Pervasive Computing, Signal Processing and Applications (PCSPA 2010), P614, DOI 10.1109/PCSPA.2010.154
   Brox T, 2006, IMAGE VISION COMPUT, V24, P41, DOI 10.1016/j.imavis.2005.09.010
   Caldelli R, 2005, PROC SPIE, V5681, P164, DOI 10.1117/12.589106
   Caldelli R, 2012, P INT S COMM CONTR S
   Celik MU, 2004, IEEE SIGNAL PROC LET, V11, P831, DOI 10.1109/LSP.2004.835475
   Cover T. M., 1991, ELEMENTS INFORM THEO
   Cox IJ., 2007, DIGITAL WATERMARKING
   D'Angelo A, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/345184
   D'Angelo A, 2010, IEEE T IMAGE PROCESS, V19, P867, DOI 10.1109/TIP.2009.2035869
   DAngelo A., 2009, THESIS
   Dass SC, 2004, IEEE T IMAGE PROCESS, V13, P1358, DOI 10.1109/TIP.2004.834659
   DEGUILLAUME F, 2002, METHOD ESTIMATION RE
   Dong P, 2005, IEEE T IMAGE PROCESS, V14, P2140, DOI 10.1109/TIP.2005.857263
   Dugelay JL, 2006, IEEE T IMAGE PROCESS, V15, P2831, DOI 10.1109/TIP.2006.877311
   Feng XG, 2002, CONF REC ASILOMAR C, P478
   Grau V, 2006, IEEE T MED IMAGING, V25, P245, DOI 10.1109/TMI.2005.862743
   Jahne B., 2005, Digital Image Processing: Concepts, Algorithms, and Scientific Applications, Vsixth
   Kang XG, 2010, IEEE T INF FOREN SEC, V5, P1, DOI 10.1109/TIFS.2009.2039604
   Kato Z., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P137, DOI 10.1109/ICASSP.1993.319766
   Kutter M., 1998, Proceedings of SPIE, V3628, P423
   Kyprianidis JE, 2009, COMPUT GRAPH FORUM, V28, P1955, DOI 10.1111/j.1467-8659.2009.01574.x
   Licks V, 2005, IEEE MULTIMEDIA, V12, P68, DOI 10.1109/MMUL.2005.46
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu CS, 2006, IEEE T MULTIMEDIA, V8, P668, DOI 10.1109/TMM.2006.876300
   Meyr H., 1997, DIGITAL COMMUNICATIO
   ORuanaidh JJK, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P536, DOI 10.1109/ICIP.1997.647968
   Petitcolas FAP, 1998, LECT NOTES COMPUT SC, V1525, P218
   Roth S, 2007, SPRINGER TRAC MOD PH, V220, P1, DOI 10.1007/3-540-35165-5_1
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Voloshynovskiy S, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P999, DOI 10.1109/ICIP.2001.958294
   Weickert J, 1999, IMAGE VISION COMPUT, V17, P201, DOI 10.1016/S0262-8856(98)00102-4
   Willsky AS, 2002, P IEEE, V90, P1396, DOI 10.1109/JPROC.2002.800717
   Wolberg G., 1990, Digital image warping
NR 40
TC 3
Z9 3
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13451
EP 13479
DI 10.1007/s11042-015-2831-y
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800026
DA 2024-07-18
ER

PT J
AU Malik, KR
   Ahmad, T
   Farhan, M
   Aslam, M
   Jabbar, S
   Khalid, S
   Kim, M
AF Malik, Kaleem Razzaq
   Ahmad, Tauqir
   Farhan, Muhammad
   Aslam, Muhammad
   Jabbar, Sohail
   Khalid, Shehzad
   Kim, Mucheol
TI Big-data: transformation from heterogeneous data to
   semantically-enriched simplified data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Resource description framework schema (RDFS); Big data; Data
   representation
ID MANAGEMENT
AB In big data, data originates from many distributed and different sources in the shape of audio, video, text and sound on the bases of real time; which makes it massive and complex for traditional systems to handle. For this, data representation is required in the form of semantically-enriched for better utilization but keeping it simplified is essential. Such a representation is possible by using Resource Description Framework (RDF) introduced by World Wide Web Consortium (W3C). Bringing and transforming data from different sources in different formats into the RDF form having rapid ratio of increase is still an issue. This requires improvements to cover transition of information among all applications with induction of simplicity to reduce complexities of prominently storing data. With the improvements induced in the shape of big data representation for transformation of data to form into Extensible Markup Language (XML) and then into RDF triple as linked in real time. It is highly needed to make transformation more data friendly. We have worked on this study on developing a process which translates data in a way without any type of information loss. This requires to manage data and metadata in such a way so they may not improve complexity and keep the strong linkage among them. Metadata is being kept generalized to keep it more useful than being dedicated to specific types of data source. Which includes a model explaining its functionality and corresponding algorithms focusing how it gets implemented. A case study is used to show transformation of relational database textual data into RDF, and at end results are being discussed.
C1 [Malik, Kaleem Razzaq; Ahmad, Tauqir; Farhan, Muhammad; Aslam, Muhammad] Univ Engn & Technol, Dept Comp Sci & Engn, Lahore, Pakistan.
   [Farhan, Muhammad; Jabbar, Sohail] COMSATS Inst Informat Technol, Dept Comp Sci, Sahiwal, Pakistan.
   [Jabbar, Sohail; Khalid, Shehzad] Bahria Univ, Dept Comp Sci, Islamabad, Pakistan.
   [Kim, Mucheol] Sungkyul Univ, Dept Multimedia, Anyang Si 430742, South Korea.
C3 University of Engineering & Technology Lahore; COMSATS University
   Islamabad (CUI); Sungkyul University
RP Farhan, M (corresponding author), Univ Engn & Technol, Dept Comp Sci & Engn, Lahore, Pakistan.; Farhan, M (corresponding author), COMSATS Inst Informat Technol, Dept Comp Sci, Sahiwal, Pakistan.
EM krmalik@gmail.com; tauqir_ahmad@hotmail.com; farhansajid@gmail.com;
   maslam@uet.edu.pk; sjabbar.research@gmail.com;
   shehzad_khalid@hotmail.com; mucheol.kim@gmail.com
RI Farhan, Muhammad/F-8071-2011; Jabbar, Sohail/E-3052-2012; ASLAM,
   MUHAMMAD/AAB-9831-2020
OI Farhan, Muhammad/0000-0002-3649-5717; Jabbar,
   Sohail/0000-0002-2127-1235; Malik, Kaleem/0000-0003-4538-3095
CR Akerkar R., 2013, Big Data Computing
   [Anonymous], INFORM SYSTEMS FRONT
   Antezana E, 2009, BRIEF BIOINFORM, V10, P392, DOI 10.1093/bib/bbp024
   Auer S, 2013, LINKED DATA ENTERPRI, P169
   Bizer C, 2011, SIGMOD REC, V40, P56, DOI 10.1145/2094114.2094129
   Broekstra J, 2001, WWW01
   Christodoulou S, 2014, DATA INTENSIVENESS C, P17
   Cuzzocrea A, 2014, 2014 6TH INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION (SOCPAR), P459, DOI 10.1109/SOCPAR.2014.7008050
   de Diego R, 2014, ENERGIES, V7, P5953, DOI 10.3390/en7095953
   Eberhart A, 2003, ONTOLOGY BASED INFRA
   Frasincar Falvius, 2002, P 3 INT C WEB INF SY
   Frey JG, 2013, WIRES COMPUT MOL SCI, V3, P465, DOI 10.1002/wcms.1127
   Gentner D, 2012, COGNITIVE APPROACHES
   Haav H-M, 2013, SEMANTIC DATA INTERO, P245
   Herrmann-Krotz G, 2011, NEW REV HYPERMEDIA M, V20, P53
   Hert M., 2011, P 7 INT C SEMANTIC S, P25, DOI [10.1145/2063518.2063522, DOI 10.1145/2063518.2063522]
   Hitzler P, 2013, SEMANT WEB, V4, P233, DOI 10.3233/SW-130117
   Hsu PL, 2015, J WEB SEMANT, V31, P27, DOI 10.1016/j.websem.2014.11.004
   Hu CP, 2014, IEEE T EMERG TOP COM, V2, P376, DOI 10.1109/TETC.2014.2316525
   Jamil HM, 2014, 2014 IEEE 30TH INTERNATIONAL CONFERENCE ON DATA ENGINEERING WORKSHOPS (ICDEW), P62, DOI 10.1109/ICDEW.2014.6818304
   Khalili A, 2013, J WEB SEMANT, V22, P1, DOI 10.1016/j.websem.2013.08.004
   Kim Y, 2006, INDEX ORG RDF RDF SC
   Manola F, 2004, RDF PRIMER W3C RECOM, V10, P6
   Manuja M., 2011, International Journal of Engineering (IJE), V5, P268
   Margara A, 2014, J WEB SEMANT, V25, P24, DOI 10.1016/j.websem.2014.02.001
   Martens W, 2006, ACM T DATABASE SYST, V31, P770, DOI 10.1145/1166074.1166076
   Noori SRH, 2011, LARGE SCALE DISTRIBU
   Pileggi SF, 2015, STUD BIG DATA, V9, P351, DOI 10.1007/978-3-319-11056-1_12
   Riemer D, 2014, IEEE INT CONF SERV, P113, DOI 10.1109/SOCA.2014.52
   Rocha OR, 2014, CONTEXT AWARE SERVIC
   Sakka Mohamed Amin, 2012, Transactions on Large-Scale Data- and Knowledge-Centered Systems VII, P96, DOI 10.1007/978-3-642-35332-1_4
   Serrano-Alvarado P, 2013, AT PROT VIE PRIV APV
   Soussi R, 2012, QUERYING EXTRACTING
   Souza BFdF, 2013, INFORM QUALITY CRITE
   Spaniol M., 2014, FRAMEWORK TEMPORAL W
   Strohbach M, 2015, MODEL OPTIM SCI TECH, V4, P257, DOI 10.1007/978-3-319-09177-8_11
   THUY PTT, 2007, TRANSFORMING VALID X, P35, DOI DOI 10.1109/NWESP.2007.23
   Udayan JD, 2014, INT CONF BIG DATA, P235, DOI 10.1109/BIGCOMP.2014.6741443
   Wu XD, 2014, IEEE T KNOWL DATA EN, V26, P97, DOI 10.1109/TKDE.2013.109
   Zhao J, 2011, HANDBOOK OF SEMANTIC WEB TECHNOLOGIES: FOUNDATIONS AND TECHNOLOGIES, VOLS 1 AND 2, P701, DOI 10.1007/978-3-540-92913-0_17
NR 40
TC 24
Z9 26
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12727
EP 12747
DI 10.1007/s11042-015-2918-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700025
DA 2024-07-18
ER

PT J
AU Zhou, A
   Wang, SG
   Hsu, CH
   Sun, QB
   Yang, FC
AF Zhou, Ao
   Wang, Shangguang
   Hsu, Ching-Hsien
   Sun, Qibo
   Yang, Fangchun
TI Task rescheduling optimization to minimize network resource consumption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Reliability; Big data analysis; Resource consumption;
   Task rescheduling
AB An increasing number of big-data services are being deployed in a cloud computing environment, attracted by the on-demand service, rapid elasticity, and low maintenance costs. As a result, ensuring the quality of service has become an important research problem. Traditionally, task rescheduling is used to ensure a consistent quality of service in the event of failure of a virtual machine. However, the network resource consumption of different rescheduling methods varies. To address this problem, we propose a task rescheduling method that minimizes network resource consumption.The method includes three algorithms. The first obtains a set of good virtual machines from the large quantity of service-providing virtual machines using the skyline operation. A ranking algorithm then fuses the data size and the task emergency to identify significant tasks. Finally, we present an algorithm that automatically determines the optimal insertion point for each task. To verify the effectiveness of the proposed method, we extend the renowned simulator CloudSim and conduct a series of experiments. The results show that our method is more efficient than other methods in terms of network resource consumption.
C1 [Zhou, Ao; Wang, Shangguang; Sun, Qibo; Yang, Fangchun] Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
   [Hsu, Ching-Hsien] Chung Hua Univ, Dept Comp Sci & Informat Engn, Hsinchu 707, Taiwan.
C3 Beijing University of Posts & Telecommunications; Chung Hua University
RP Hsu, CH (corresponding author), Chung Hua Univ, Dept Comp Sci & Informat Engn, Hsinchu 707, Taiwan.
EM aozhou@bupt.edu.cn; sgwang@bupt.edu.cn; chh@chu.edu.tw;
   qsunfcyang@bupt.edu.cn; fcyang@bupt.edu.cn
RI Hsu, Ching-Hsien/AAE-6917-2020; Zhou, Xiangfeng/KDO-8724-2024; Zhou,
   Xiaofang/C-6169-2013
OI Zhou, Xiaofang/0000-0001-6343-1455; Wang, Shangguang/0000-0001-7245-1298
FU NSFC [61272521]; SRFDP [20110005130001]; Fundamental Research Funds for
   the Central Universities [2014RC1101]; Beijing Natural Science
   Foundation [4132048]
FX The work presented in this study is supported by NSFC (61272521); SRFDP
   (20110005130001); the Fundamental Research Funds for the Central
   Universities (2014RC1101); Beijing Natural Science Foundation (4132048).
CR Al-Fares M, 2008, ACM SIGCOMM COMP COM, V38, P63, DOI 10.1145/1402946.1402967
   Armbrust M, 2010, COMMUN ACM, V53, P50, DOI 10.1145/1721654.1721672
   Bauer E., 2012, RELIABILITY AVAILABI
   Börzsönyi S, 2001, PROC INT CONF DATA, P421, DOI 10.1109/ICDE.2001.914855
   Buyya R, 2009, FUTURE GENER COMP SY, V25, P599, DOI 10.1016/j.future.2008.12.001
   Calheiros RN, 2011, SOFTWARE PRACT EXPER, V41, P23, DOI 10.1002/spe.995
   Dai Yuan-Shun., 2009, Pacific Rim International Symposium on Dependable Computing, P1
   El-Sayed Nosayba, 2012, Performance Evaluation Review, V40, P163, DOI 10.1145/2318857.2254778
   Fox A, 2009, Rep. UCB/EECS 28 13, V28
   Guenter B, P IEEE INT C COMP CO, P1332
   Jung GY, 2010, I C DEPEND SYS NETWO, P497, DOI 10.1109/DSN.2010.5544273
   Liu ZP, 2014, COMPUT J, V57, P291, DOI 10.1093/comjnl/bxt009
   Longo F, 2011, I C DEPEND SYS NETWO, P335, DOI 10.1109/DSN.2011.5958247
   Machida F., 2010, PROC IEEE 2 INT WORK, P1, DOI DOI 10.1109/WOSAR.2010.5722098
   Marston S, 2011, DECIS SUPPORT SYST, V51, P176, DOI 10.1016/j.dss.2010.12.006
   Pham C, 2011, I C DEPEND SYS NETWO, P189, DOI 10.1109/DSN.2011.5958218
   Qiu WW, 2014, IEEE T SERV COMPUT, V7, P223, DOI 10.1109/TSC.2013.38
   Schwarzkopf M., 2012, P 4 USENIX C HOT TOP, P1
   Wang SG, 2014, J INTELL MANUF, V25, P283, DOI 10.1007/s10845-012-0661-6
   Zheng ZB, 2013, IEEE T PARALL DISTR, V24, P1213, DOI 10.1109/TPDS.2012.285
   Zibin Zheng, 2010, Proceedings of the 2010 IEEE 21st International Symposium on Software Reliability Engineering (ISSRE 2010), P398, DOI 10.1109/ISSRE.2010.28
NR 21
TC 6
Z9 7
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12901
EP 12917
DI 10.1007/s11042-015-2549-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700035
DA 2024-07-18
ER

PT J
AU Bobek, S
   Nalepa, GJ
   Ligeza, A
   Adrian, WT
   Kaczor, K
AF Bobek, Szymon
   Nalepa, Grzegorz J.
   Ligeza, Antoni
   Adrian, Weronika T.
   Kaczor, Krzysztof
TI Mobile context-based framework for threat monitoring in urban
   environment with social threat monitor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Context-awareness; Mobile computing; GIS; Knowledge management; INDECT
ID INFRASTRUCTURE; PROPOSAL; SAFETY
AB Engaging users in threat reporting is important in order to improve threat monitoring in urban environments. Today, mobile applications are mostly used to provide basic reporting interfaces. With a rapid evolution of mobile devices, the idea of context awareness has gained a remarkable popularity in recent years. Modern smartphones and tablets are equipped with a variety of sensors including accelerometers, gyroscopes, pressure gauges, light and GPS sensors. Additionally, the devices become computationally powerful which allows for real-time processing of data gathered by their sensors. Universal access to the Internet via WiFi hot-spots and GSM network makes mobile devices perfect platforms for ubiquitous computing. Although there exist numerous frameworks for context-aware systems, they are usually dedicated to static, centralized, client-server architectures. There is still space for research in the field of context modeling and reasoning for mobile devices. In this paper, we propose a lightweight context-aware framework for mobile devices that uses data gathered by mobile device sensors and performs on-line reasoning about possible threats based on the information provided by the Social Threat Monitor system developed in the INDECT project.
C1 [Bobek, Szymon; Nalepa, Grzegorz J.; Ligeza, Antoni; Adrian, Weronika T.; Kaczor, Krzysztof] AGH Univ Sci & Technol, Al Mickiewicza 30, PL-30059 Krakow, Poland.
C3 AGH University of Krakow
RP Bobek, S (corresponding author), AGH Univ Sci & Technol, Al Mickiewicza 30, PL-30059 Krakow, Poland.
EM szymon.bobek@agh.edu.pl; gjn@agh.edu.pl; wta@agh.edupl; kk@agh.edu.pl
RI Adrian, Weronika T./A-5613-2013; Nalepa, Grzegorz J./ABE-8339-2021;
   Bobek, Szymon/ACC-7884-2022; Kaczor, Krzysztof/J-9323-2012; Ligeza,
   Antoni/E-2422-2012
OI Adrian, Weronika T./0000-0002-1860-6989; Nalepa, Grzegorz
   J./0000-0002-8182-4225; Bobek, Szymon/0000-0002-6350-8405; Ligeza,
   Antoni/0000-0002-6573-4246
FU AGH UST Grant [11.11.120.859]
FX The research presented in this paper is carried out within the EU FP7
   INDECT Project: "Intelligent information system supporting observation,
   searching and detection for security of citizens in urban environment"
   (http://indect-project.eu). The paper is supported by the AGH UST Grant
   11.11.120.859.
CR Adrian WT, 2012, COMM COM INF SC, V287, P1
   Adrian WT, 2011, PROC INT C TOOLS ART, P438, DOI 10.1109/ICTAI.2011.71
   Adrian WT, 2012, AI4KM 2012 1 INT WOR, P63
   [Anonymous], 2013, THESIS
   Atzmueller M., 2013, P 4 INT WORKSH MOD S
   Bardram JE, 2005, LECT NOTES COMPUT SC, V3468, P98
   Bobek S, 2013, P COMMUNICATIONS COM, V368
   Bobek S, 2013, FED CONF COMPUT SCI, P993
   Bui HH, 2001, INT J PATTERN RECOGN, V15, P177, DOI 10.1142/S0218001401000782
   Chen H, 2004, PROCEEDINGS OF MOBIQUITOUS 2004, P258
   Chen H, 2004, SECOND IEEE ANNUAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS, PROCEEDINGS, P277, DOI 10.1109/PERCOM.2004.1276865
   Chronis I., 2009, P ICMI MLMI 2009 WOR
   Dey A. K., 2005, ACM Transactions on Computer-Human Interaction, V12, P53, DOI 10.1145/1057237.1057241
   Dey A.K., 2000, PROVIDING ARCHITECTU
   Dey AK, 2009, J AMB INTEL SMART EN, V1, P57, DOI 10.3233/AIS-2009-0008
   Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019
   Eagle N, 2006, PERS UBIQUIT COMPUT, V10, P255, DOI 10.1007/s00779-005-0046-3
   Gu Tao, 2004, P IEEE VEH TECHN C V
   Henricksen K, 2002, P 1 INT C PERV COMP
   Hu H., 2011, CONTEXTTORRENT CONTE
   Jaroucheh Z, 2011, J AMB INTEL HUM COMP, V2, P53, DOI 10.1007/s12652-010-0038-7
   Juan Ye, 2008, Revue d'Intelligence Artificielle, V22, P647, DOI 10.3166/ria.22.647-667
   Kluza K, 2011, STUD COMPUT INTELL, V382, P243
   Ligeza A, 2010, MCSS 2010, P152
   Ligeza A, 2012, 8 WORKSH KNOWL ENG S, P58
   Ligeza A, 2011, WIRES DATA MIN KNOWL, V1, P117, DOI 10.1002/widm.11
   Logan B, 2007, P 9 INT C UB COMP UB
   Loke SW, 2004, KNOWL ENG REV, V19, P213, DOI 10.1017/s0269888905000263
   Nalepa GJ, 2003, LECT NOTES ARTIF INT, V2663, P124
   Nalepa GJ, 2005, FRONT ARTIF INTEL AP, V130, P330
   Nalepa GJ, 2014, COMPUT SCI INF SYST, V11, P171, DOI 10.2298/CSIS130209002N
   Nalepa GJ, 2012, INT J SOFTW ENG KNOW, V22, P485, DOI 10.1142/S021819401250012X
   Nalepa GJ, 2011, INT J ARTIF INTELL T, V20, P1107, DOI 10.1142/S0218213011000541
   Nalepa GJ, 2011, LECT NOTES COMPUT SC, V6826, P305, DOI 10.1007/978-3-642-22546-8_24
   Nalepa GJ, 2011, LECT NOTES COMPUT SC, V6826, P337, DOI 10.1007/978-3-642-22546-8_27
   Nalepa GJ, 2010, LECT NOTES ARTIF INT, V6114, P598, DOI 10.1007/978-3-642-13232-2_73
   Nalepa GJ, 2009, LECT NOTES ARTIF INT, V5796, P345
   Nalepa GJ, 2007, NINTH INTERNATIONAL SYMPOSIUM ON SYMBOLIC AND NUMERIC ALGORITHMS FOR SCIENTIFIC COMPUTING, PROCEEDINGS, P500, DOI 10.1109/SYNASC.2007.58
   Olguin DO, 2009, IEEE T SYST MAN CY B, V39, P43, DOI 10.1109/TSMCB.2008.2006638
   Ranganathan A, 2003, KNOWL ENG REV, V18, P209, DOI 10.1017/S0269888904000037
   Ranganathan A, 2003, PERS UBIQUIT COMPUT, V7, P353, DOI 10.1007/s00779-003-0251-x
   van Wissen B., 2010, P PHONESENSE 2010
   Waliszko J, 2011, COMM COM INF SC, V149, P165
   Wang XH, 2004, SECOND IEEE ANNUAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS WORKSHOPS, PROCEEDINGS, P18
   Woensel W. V., 2009, FRAMEWORK DECENTRALI
   Ye JA, 2010, J AMB INTEL SMART EN, V2, P389, DOI 10.3233/AIS-2009-0082
NR 46
TC 4
Z9 4
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10595
EP 10616
DI 10.1007/s11042-014-2060-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800024
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, JN
   Wang, LH
   Li, Y
   Zhang, JF
   Li, DX
   Zhang, M
AF Li, Jia-Ning
   Wang, Liang-Hao
   Li, Yang
   Zhang, Jun-Fei
   Li, Dong-Xiao
   Zhang, Ming
TI Local optimized and scalable frame-to-model SLAM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dense frame-to-model SLAM; Volume shift; Motion prediction; Weighted
   ICP; Multi-modelframe estimation
ID TRACKING
AB In recent years, dense visual SLAM (Simultaneous Localization And Mapping) has been proved that it has lots of advantages on the accuracy of pose estimation compared to sparse features due to exploiting the more available information in image data. In this paper, we propose a scalable dense frame-to-model SLAM system based on KinectFusion algorithm. We design an effective active volume shift strategy to extend the tracking range without increment on storage resource. Furthermore, we propose three local optimization methods including motion predicting, weighted ICP (Iterative Closest Point) and multi-modelframe combined estimation to improve the tracking stability and decrease the accumulative error. Note that, as the basis of on-line augmented reality application, our work focus on local optimization rather than global closing loop optimization which is a classical problem in SLAM. At last, we evaluate our optimized approaches on publicly available benchmark datasets, and compare it with the original KinectFusion, a similar method and another two frame-to-frame RGBD SLAM methods. The results indicate our approaches yield a certain degree improvement on the performance of tracking accuracy.
C1 [Li, Jia-Ning; Wang, Liang-Hao; Li, Yang; Zhang, Jun-Fei; Li, Dong-Xiao; Zhang, Ming] Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou 310027, Peoples R China.
   [Li, Jia-Ning; Wang, Liang-Hao; Li, Yang; Zhang, Jun-Fei; Li, Dong-Xiao; Zhang, Ming] Zhejiang Prov Key Lab Informat Network Technol, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Wang, LH (corresponding author), Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou 310027, Peoples R China.; Wang, LH (corresponding author), Zhejiang Prov Key Lab Informat Network Technol, Hangzhou 310027, Peoples R China.
EM wang_sunsky@163.com
RI Li, Jianing/AAE-2394-2020
OI Li, Jianing/0000-0003-4887-2732
FU National Natural Science Foundation of China [61271338, 61401390];
   Zhejiang Provincial Natural Science Foundation of China [LQ14F010005];
   Open Projects Program of National Laboratory of Pattern Recognition of
   China [201306308]
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant No. 61271338, 61401390), the Zhejiang
   Provincial Natural Science Foundation of China (Grant No. LQ14F010005),
   and the Open Projects Program of National Laboratory of Pattern
   Recognition of China (Grant No. 201306308).
CR [Anonymous], 2021, P RGB D WORKSH 3D PE
   [Anonymous], P 24 ANN ACM S US IN
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Chiuso A., 2000, ECCV, P734
   Comport AI, 2007, IEEE INT CONF ROBOT, P40, DOI 10.1109/ROBOT.2007.363762
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Fiala M, 2005, PROC CVPR IEEE, P590
   Henry P., 2014, RGB-D Mapping: Using Depth Cameras for Dense 3D Modeling of Indoor Environments, P477, DOI [DOI 10.1007/978-3-642-28572-1_33, DOI 10.1007/978-3-642-28572-1, 10.1007/978-3-642-28572-133]
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Kerl C, 2013, IEEE INT C INT ROBOT, P2100, DOI 10.1109/IROS.2013.6696650
   Kerl C, 2013, IEEE INT CONF ROBOT, P3748, DOI 10.1109/ICRA.2013.6631104
   Klein George, 2007, P1
   Konolige K, 2007, INT S EXP ROB ISER, P179
   Li JY, 2013, INT J SURG ONCOL, V2013, DOI 10.1155/2013/875078
   Low KL, 2004, TR04004 U N C CHAP H
   Morency LP, 2002, INT C PATT RECOG, P367, DOI 10.1109/ICPR.2002.1047472
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Roth H, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.112
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Steinbrucker F., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P719, DOI 10.1109/ICCVW.2011.6130321
   Stuckler J., 2012, 2012 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2012), P162, DOI 10.1109/MFI.2012.6343050
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Tykkälä T, 2014, J VIS COMMUN IMAGE R, V25, P207, DOI 10.1016/j.jvcir.2013.02.009
   Whelan T, 2012, 3 RSS WORKSH RGB D A
   Zhang FZ, 1997, LINEAR ALGEBRA APPL, V251, P21, DOI 10.1016/0024-3795(95)00543-9
NR 27
TC 8
Z9 8
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8675
EP 8694
DI 10.1007/s11042-015-2780-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300025
DA 2024-07-18
ER

PT J
AU Kim, HI
   Choi, JY
   Lee, SH
   Ro, YM
AF Kim, Hyung-Il
   Choi, Jae Young
   Lee, Seung Ho
   Ro, Yong Man
TI Feature scalability for a low complexity face recognition with
   unconstrained spatial resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Feature scalability; Low-computing power; Face
   resolution; Mismatch; Recognition operation time
ID SUPERRESOLUTION
AB Automatic face recognition (FR) based applications in low computing power constrained systems, such as mobile and smart camera, have become particularly interesting topic in recent years. In this context, we present computationally efficient FR framework underpinning the so-called feature scalability algorithm. The proposed framework aims at implementing robust FR systems under low-computing power restriction and varying face resolution. Key beneficial property of our proposed FR framework based on feature scalability is to require low computational complexity without sacrificing a level of FR performance. To do this, using feature scalability algorithm enables to directly estimate the features (from pre-enrolled gallery images) that are well matched with the feature of an input probe image with different resolution (generally lower resolution) without any complex process. In addition, our method is helpful for relieving storage shortage problem as it does not require a large amount of training and gallery images with different face resolutions. Results show that our proposed feature scalability algorithm can be seamlessly embedded into state-of-the-art feature extraction methods extensively used for FR by achieving impressive recognition performance. Also, according to the results on computational complexity measurement, the proposed method is proven to be useful for substantially saving FR operation time.
C1 [Kim, Hyung-Il; Choi, Jae Young; Lee, Seung Ho; Ro, Yong Man] Korea Adv Inst Sci & Technol KAIST, Dept Elect Engn, Daejeon, South Korea.
   [Choi, Jae Young] Jungwon Univ, Dept Biomed Engn, 85 Munmu Ro Goesan Eup, Goesan Gun 367805, Chungcheongbuk, South Korea.
   [Choi, Jae Young] Jungwon Univ, Dept Biomed Engn, Chungcheongbuk Do, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Jungwon
   University; Jungwon University
RP Ro, YM (corresponding author), Korea Adv Inst Sci & Technol KAIST, Dept Elect Engn, Daejeon, South Korea.
EM hyungil.kim@kaist.ac.kr; jygchoi@kaist.ac.kr; leesh09@kaist.ac.kr;
   ymro@ee.kaist.ac.kr
RI Ro, Yong Man/C-1731-2011; Kim, Hyung-Il/AAU-4895-2021; Ro, Yong
   Man/ABF-6817-2020
OI Kim, Hyung-Il/0000-0001-6425-549X; Ro, Yong Man/0000-0001-5306-6853
FU ICT R&D program of MSIP/IITP [14-824-09-002]
FX This work was supported by the ICT R&D program of MSIP/IITP.
   [14-824-09-002, Development of global multi-target tracking and event
   prediction techniques based on real-time large-scale video analysis].
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2005, ELEMENTS INFORM THEO, DOI DOI 10.1002/047174882X
   [Anonymous], 2011, J APPL COMPUTER SCI
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Boom BJ, 2006, IEEE INT C CONTR AUT
   Cardinaux F, 2006, IEEE T SIGNAL PROCES, V54, P361, DOI 10.1109/TSP.2005.861075
   Choi JY, 2012, IEEE T IMAGE PROCESS, V21, P1366, DOI 10.1109/TIP.2011.2168413
   Choi JY, 2011, IEEE T MULTIMEDIA, V13, P14, DOI 10.1109/TMM.2010.2087320
   Choi JY, 2011, PATTERN RECOGN, V44, P412, DOI 10.1016/j.patcog.2010.08.020
   Choi JY, 2009, IEEE T SYST MAN CY B, V39, P1217, DOI 10.1109/TSMCB.2009.2014245
   Choi K, 2011, PATTERN RECOGN, V44, P386, DOI 10.1016/j.patcog.2010.08.009
   Duda R., 1973, Pattern Classification and Scene Analysis
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2
   Gunturk BK, 2003, IEEE T IMAGE PROCESS, V12, P597, DOI 10.1109/TIP.2003.811513
   Hadid A, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P813, DOI 10.1109/AFGR.2004.1301634
   Hua G, 2011, IEEE T PATTERN ANAL, V33, P1921, DOI 10.1109/TPAMI.2011.182
   Jeon HK, 2008, IEEE INT SYMP CIRC S, P157, DOI 10.1109/ISCAS.2008.4541378
   Jia YQ, 2012, PROC CVPR IEEE, P3370, DOI 10.1109/CVPR.2012.6248076
   Kim CH, 2003, IEEE T CIRC SYST VID, V13, P549, DOI 10.1109/TCSVT.2003.813431
   Lee SH, 2012, IEEE T IMAGE PROCESS, V21, P2347, DOI 10.1109/TIP.2011.2181526
   Li B, 2010, IEEE SIGNAL PROC LET, V17, P20, DOI 10.1109/LSP.2009.2031705
   Liu C, 2007, INT J COMPUT VISION, V75, P115, DOI 10.1007/s11263-006-0029-5
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Lu JW, 2005, PATTERN RECOGN LETT, V26, P181, DOI 10.1016/j.patrec.2004.09.014
   Martinez A. M., 1998, THE AR FACE DATABASE
   Mishra G, 2013, 2013 INTERNATIONAL SYMPOSIUM ON ELECTRONIC SYSTEM DESIGN (ISED), P98, DOI 10.1109/ISED.2013.26
   Oh J, 2012, IEEE MICRO, V32, P38, DOI 10.1109/MM.2012.90
   Reddy KRL, 2011, INT J SECUR APPL, V5, P23
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Su Y, 2009, IEEE T IMAGE PROCESS, V18, P1885, DOI 10.1109/TIP.2009.2021737
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Xie SF, 2010, IEEE T IMAGE PROCESS, V19, P1349, DOI 10.1109/TIP.2010.2041397
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zou J, 2007, IEEE T IMAGE PROCESS, V16, P2617, DOI 10.1109/TIP.2007.904421
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
NR 38
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 6887
EP 6908
DI 10.1007/s11042-015-2616-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400010
DA 2024-07-18
ER

PT J
AU Kim, D
   Nah, JH
   Park, WC
AF Kim, Dongseok
   Nah, Jae-Ho
   Park, Woo-Chan
TI Geometry transition method to improve ray-tracing precision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D graphics; Ray tracing; Rendering artifact; Floating-point arithmetic
AB We propose a method for moving the view position to the origin and moving the coordinates of primitives so that they are at the same distance in order to improve ray-tracing precision. This approach exploits the principle that a floating-point number provides higher precision near zero. In this way, we can significantly reduce the number of self-intersections occurring in ray tracing that are caused by limited floating-point precision. The experimental results show that the number of self-intersections is reduced by up to 84.6 %. We also propose a hardware approach to resolve the computational overhead in the proposed algorithm. Its contribution to the hardware size is very small in comparison with the size of the entire ray-tracing hardware.
C1 [Kim, Dongseok; Park, Woo-Chan] Sejong Univ, Dept Comp Engn, Seoul, South Korea.
   [Nah, Jae-Ho] LG Elect, Seoul, South Korea.
C3 Sejong University; LG Electronics
RP Park, WC (corresponding author), Sejong Univ, Dept Comp Engn, Seoul, South Korea.
EM dskim@rayman.sejong.ac.kr; nahjaeho@gmail.com; pwchan@sejong.ac.kr
OI Nah, Jae-Ho/0000-0001-7805-5333
FU National Research Foundation of Korea (NRF) - Ministry of Education,
   Science and Technology [NRF-2012R1A1A2004624]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (NRF-2012R1A1A2004624).
CR [Anonymous], 2014, P C HIGH PERF GRAPH
   *ANSI IEEE, 1985, 754 ANSIIEEE
   Dammertz H, 2006, RT 06: IEEE SYMPOSIUM ON INTERACTIVE RAY TRACING 2006, PROCEEDINGS, P25
   Glassner A. S., 1989, INTRO RAY TRACING
   GOLDBERG D, 1991, COMPUT SURV, V23, P5, DOI 10.1145/103162.103163
   Hanika J, 2007, THESIS ULM U
   Heinly Jared, 2009, Journal of Graphics Tools, V14, P31
   Ize T, 2013, J COMPUTER GRAPHICS, V2, P12
   Nah JH, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629634
   Park WC, 2008, RT08: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2008, PROCEEDINGS, P187, DOI 10.1109/RT.2008.4634650
   Pharr M., 2004, Physically Based Rendering: From Theory to Implementation
   Suffern K., 2007, Ray tracing from the ground up
   WALD I, 2004, THESIS SARRLAND U
   WHITTED T, 1980, COMMUN ACM, V23, P343, DOI 10.1145/358876.358882
NR 14
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5689
EP 5700
DI 10.1007/s11042-015-2534-4
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600016
DA 2024-07-18
ER

PT J
AU Xiong, H
   Wang, ZY
   He, RJ
   Feng, DG
AF Xiong, Hao
   Wang, Zhiyong
   He, Renjie
   Feng, Dagan
TI Robust foreground object segmentation from handheld camera videos with
   occlusion map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video object segmentation; Occlusion map; Shadow removal; Handheld
   camera
ID MOVING-OBJECTS; SHADOWS; REMOVAL
AB Extracting foreground objects from videos captured by a handheld camera has emerged as a new challenge. While existing approaches aim to exploit several clues such as depth and motion to extract the foreground layer, there are limitations in handling partial movement and cast shadow. In this paper, we bring a novel perspective to address these two issues by utilizing occlusion map introduced by object and camera motion and taking the advantage of interactive image segmentation methods. For partial movement, we treat each video frame as an image and synthesize "seeding" user interactions (i.e., user manually marking foreground and background) with both forward and backward occlusion maps to leverage the advances in high quality interactive image segmentation. For cast shadow, we utilize a paired region based shadow detection method to further refine initial segmentation results by removing detected shadow regions. Experimental results from both qualitative evaluation and quantitative evaluation on the Hopkins dataset demonstrate both the effectiveness and the efficiency of our proposed approach.
C1 [Xiong, Hao; Wang, Zhiyong; He, Renjie; Feng, Dagan] Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia.
   [He, Renjie] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China.
C3 University of Sydney; Northwestern Polytechnical University
RP Wang, ZY (corresponding author), Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia.
EM zhiyong.wang@sydney.edu.au
OI Feng, Dagan/0000-0002-3381-214X; Wang, Zhiyong/0000-0002-8043-0312
FU Australian Research Council (ARC)
FX This research was supported by the Australian Research Council (ARC)
   grants.
CR [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], EUR C COMP VIS
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   [Anonymous], IEEE INT C ROB AUT
   [Anonymous], INT C DIG IM COMP TE
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 2006, CVPR, DOI DOI 10.1109/CVPR.2006.69
   Ayvaci A, 2012, INT J COMPUT VISION, V97, P322, DOI 10.1007/s11263-011-0490-7
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y., 2001, International Conference on Computer Vision, V1, P105, DOI DOI 10.1109/ICCV.2001.937505
   Bugeau A, 2009, COMPUT VIS IMAGE UND, V113, P459, DOI 10.1016/j.cviu.2008.11.005
   Cheng FC, 2011, IEEE T SYST MAN CY C, V41, P589, DOI 10.1109/TSMCC.2010.2092425
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Finlayson GD, 2006, IEEE T PATTERN ANAL, V28, P59, DOI 10.1109/TPAMI.2006.18
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gulshan V, 2010, PROC CVPR IEEE, P3129, DOI 10.1109/CVPR.2010.5540073
   Guo RQ, 2011, PROC CVPR IEEE
   Jun Zhu, 2010, 2010 15th Asia and South Pacific Design Automation Conference (ASP-DAC 2010), P223, DOI 10.1109/ASPDAC.2010.5419892
   Kolmogorov V, 2005, PROC CVPR IEEE, P407
   Lalonde JF, 2010, LECT NOTES COMPUT SC, V6312, P322, DOI 10.1007/978-3-642-15552-9_24
   LEUNG MK, 1987, PATTERN RECOGN, V20, P55, DOI 10.1016/0031-3203(87)90017-3
   Li Y, 2005, ACM T GRAPHIC, V24, P595, DOI 10.1145/1073204.1073234
   Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112
   Mitzel D, 2010, LECT NOTES COMPUT SC, V6311, P397, DOI 10.1007/978-3-642-15549-9_29
   Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520
   Reddy V, 2013, IEEE T CIRC SYST VID, V23, P83, DOI 10.1109/TCSVT.2012.2203199
   Sanin A, 2012, PATTERN RECOGN, V45, P1684, DOI 10.1016/j.patcog.2011.10.001
   Sun J, 2006, LECT NOTES COMPUT SC, V3952, P628
   Nguyen TNA, 2012, IEEE T IMAGE PROCESS, V21, P3734, DOI 10.1109/TIP.2012.2191566
   Veksler O, 2008, LECT NOTES COMPUT SC, V5304, P454, DOI 10.1007/978-3-540-88690-7_34
   Wang WQ, 2008, IEEE T CIRC SYST VID, V18, P670, DOI 10.1109/TCSVT.2008.918800
   Yang QX, 2012, IEEE T IMAGE PROCESS, V21, P4361, DOI 10.1109/TIP.2012.2208976
   Zhang GF, 2011, IEEE T PATTERN ANAL, V33, P603, DOI 10.1109/TPAMI.2010.115
   Zhao T, 2008, IEEE T PATTERN ANAL, V30, P1198, DOI 10.1109/TPAMI.2007.70770
   Zhong J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P44, DOI 10.1109/ICCV.2003.1238312
NR 39
TC 0
Z9 0
U1 4
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5751
EP 5776
DI 10.1007/s11042-015-2538-0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600019
DA 2024-07-18
ER

PT J
AU Grana, C
   Serra, G
   Manfredi, M
   Coppi, D
   Cucchiara, R
AF Grana, Costantino
   Serra, Giuseppe
   Manfredi, Marco
   Coppi, Dalia
   Cucchiara, Rita
TI Layout analysis and content enrichment of digitized books
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Document layout analysis; Page segmentation; Content based retrieval
ID PAGE SEGMENTATION; DOCUMENT; CLASSIFICATION; FRAMEWORK
AB In this paper we describe a system for automatically analyzing old documents and creating hyper linking between different epochs, thus opening ancient documents to young people and to make them available on the web with old and current content. We propose a supervised learning approach to segment text and illustration of digitized old documents using a texture feature based on local correlation aimed at detecting the repeating patterns of text regions and differentiate them from pictorial elements. Moreover we present a solution to help the user in finding contemporary content connected to what is automatically extracted from the ancient documents.
C1 [Grana, Costantino; Serra, Giuseppe; Manfredi, Marco; Coppi, Dalia; Cucchiara, Rita] Univ Modena & Reggio Emilia, Dipartimento Ingn Enzo Ferrari, Modena, Italy.
C3 Universita di Modena e Reggio Emilia
RP Grana, C (corresponding author), Univ Modena & Reggio Emilia, Dipartimento Ingn Enzo Ferrari, Modena, Italy.
EM costantino.grana@unimore.it; giuseppe.serra@unimore.it;
   marco.manfredi@unimore.it; dalia.coppi@unimore.it;
   rita.cucchiara@unimore.it
RI Grana, Costantino/B-4555-2012; Serra, Giuseppe/M-3572-2015; Cucchiara,
   Rita/L-3006-2015
OI Grana, Costantino/0000-0002-4792-2358; 
CR Agrawal Mudit, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1011, DOI 10.1109/ICDAR.2009.270
   [Anonymous], 2007, INT C DOC AN REC ICD
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], TECHNICAL REPORT
   Appiani E., 2001, International Journal on Document Analysis and Recognition, V4, P69, DOI 10.1007/PL00010904
   Baldi S, 2003, PROC INT CONF DOC, P829
   Bao BK, 2013, IEEE T IMAGE PROCESS, V22, P860, DOI 10.1109/TIP.2012.2219543
   Cesarini F., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P1131, DOI 10.1109/ICDAR.2001.953962
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chavel I., 2006, RIEMANNIAN GEOMETRY, VVol. 98
   Chen K, 2013, PROC INT CONF DOC, P958, DOI 10.1109/ICDAR.2013.194
   Chen N, 2007, INT J DOC ANAL RECOG, V10, P1, DOI 10.1007/s10032-006-0020-2
   Clausner C, 2011, PROC INT CONF DOC, P48, DOI 10.1109/ICDAR.2011.19
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Diligenti M, 2003, IEEE T PATTERN ANAL, V25, P519, DOI 10.1109/TPAMI.2003.1190578
   Esposito F, 2000, J INTELL INF SYST, V14, P175, DOI 10.1023/A:1008735902918
   Jaekyu Ha, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P952, DOI 10.1109/ICDAR.1995.602059
   Journet N, 2008, INT J DOC ANAL RECOG, V11, P9, DOI 10.1007/s10032-008-0064-6
   Kise K, 1998, COMPUT VIS IMAGE UND, V70, P370, DOI 10.1006/cviu.1998.0684
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lazzara G, 2011, PROC INT CONF DOC, P252, DOI 10.1109/ICDAR.2011.59
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martelli S., 2010, 2010 21st International Conference on Database and Expert Systems Applications, P215, DOI 10.1109/DEXA.2010.56
   Meng GF, 2007, PROC INT CONF DOC, P143
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Pavlidis T, 1991, ICDAR, P945
   Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Philbin J., 2008, P CVPR, P1
   Safadi B, 2013, INT WORK CONTENT MUL, P65, DOI 10.1109/CBMI.2013.6576554
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Tuytelaars T, 2007, IEEE I CONF COMP VIS, P754
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   van Gemert Jan C., 2008, Computer Vision. Proceedings 10th European Conference on Computer Vision, ECCV 2008, P696, DOI 10.1007/978-3-540-88690-7_52
   Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153
   Wang YL, 2006, PATTERN RECOGN, V39, P57, DOI 10.1016/j.patcog.2005.06.009
   Winder A, 2011, PROC INT CONF DOC, P1245, DOI 10.1109/ICDAR.2011.251
NR 38
TC 6
Z9 8
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 3879
EP 3900
DI 10.1007/s11042-014-2360-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200015
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hu, WC
   Chen, WH
   Huang, DY
   Yang, CY
AF Hu, Wu-Chih
   Chen, Wei-Hao
   Huang, Deng-Yuan
   Yang, Ching-Yu
TI Effective image forgery detection of tampered foreground or background
   image based on image watermarking and alpha mattes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forgery; Image matting; Image watermarking; Alpha matte
ID SCHEME
AB This paper proposes an effective image forgery detection scheme that identifies a tampered foreground or background image using image watermarking and alpha mattes. In the proposed method, component-hue-difference-based spectral matting is used to obtain the foreground and background images based on the obtained alpha matte. Next, image watermarking based on the discrete wavelet transform, discrete cosine transform, and singular value decomposition is used to embed two different watermarks into the foreground and background images, respectively. Finally, the difference between the obtained singular values is used to detect tampering of foreground or background image. Experimental results show that the proposed method performs well in terms of image forgery detection.
C1 [Hu, Wu-Chih; Chen, Wei-Hao; Yang, Ching-Yu] Natl Penghu Univ Sci & Technol, Dept Comp Sci & Informat Engn, Magong 880, Penghu, Taiwan.
   [Huang, Deng-Yuan] Dayeh Univ, Dept Elect Engn, Changhua, Taiwan.
C3 National Penghu University of Science & Technology; Da Yeh University
RP Hu, WC (corresponding author), Natl Penghu Univ Sci & Technol, Dept Comp Sci & Informat Engn, Magong 880, Penghu, Taiwan.
EM wchu@npu.edu.tw; a6803072@hotmail.com; kevin@mail.dyu.edu.tw;
   chingyu@npu.edu.tw
FU National Science Council, Taiwan [NSC102-2221-E-346-007]
FX This paper has been supported by the National Science Council, Taiwan,
   under grant no. NSC102-2221-E-346-007. The authors wish to express the
   appreciation to Prof. Chih-Chin Lai and Prof. Zhouchen Lin for their
   help with the experiments. The authors also gratefully acknowledge the
   helpful comments and suggestions of reviewers, which have improved the
   quality and presentation.
CR Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Chang IC, 2013, IMAGE VISION COMPUT, V31, P57, DOI 10.1016/j.imavis.2012.09.002
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Guan Y, 2006, COMPUT GRAPH FORUM, V25, P567, DOI 10.1111/j.1467-8659.2006.00976.x
   Han Q, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2013), P33, DOI 10.1109/IIH-MSP.2013.17
   Hu WC, 2013, INT J COMPUT SCI ENG, V8, P297
   Hu WC, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.3.033005
   Hu WC, 2012, INT CONF GENET EVOL, P245, DOI 10.1109/ICGEC.2012.114
   Hu WC, 2013, PATTERN RECOGN, V46, P1183, DOI 10.1016/j.patcog.2012.10.012
   Hu WC, 2012, J VIS COMMUN IMAGE R, V23, P665, DOI 10.1016/j.jvcir.2012.03.003
   Huang D-Y, 2013, P 7 INT C GEN EV COM, P125
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Lai CC, 2011, DIGIT SIGNAL PROCESS, V21, P522, DOI 10.1016/j.dsp.2011.01.017
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P1699, DOI 10.1109/TPAMI.2008.168
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li L., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P46
   Lin GS, 2011, IEEE T CIRC SYST VID, V21, P421, DOI 10.1109/TCSVT.2011.2125370
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Liu KC, 2012, IET IMAGE PROCESS, V6, P445, DOI 10.1049/iet-ipr.2011.0574
   Loukhaoukha K, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3327935
   Mahdian B, 2009, IMAGE VISION COMPUT, V27, P1497, DOI 10.1016/j.imavis.2009.02.001
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Rykaczewski R, 2007, IEEE T MULTIMEDIA, V9, P421, DOI 10.1109/TMM.2006.886297
   Wang J, 2007, FOUND TRENDS COMPUT, V3, P97, DOI 10.1561/0600000019
   Zhang XP, 2005, IEEE T MULTIMEDIA, V7, P593, DOI 10.1109/TMM.2005.843357
NR 28
TC 27
Z9 28
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3495
EP 3516
DI 10.1007/s11042-015-2449-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600027
DA 2024-07-18
ER

PT J
AU Huang, Y
   Chen, X
   Ding, XH
AF Huang, Yue
   Chen, Xin
   Ding, Xinghao
TI A harmonic means pooling strategy for structural similarity index
   measurement in image quality assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image quality assessment; Full reference; Pooling strategy; Harmonic
   mean
AB Structural similarity index measurement (SSIM) is one of the most well known method in full reference image quality assessment metrics (FR-IQA). In this paper, a novel pooling strategy based on harmonic mean is proposed to enhance the performance of SSIM. Instead of arithmetic mean, the proposed pooling by harmonic mean tends to emphasize the contributions from the local severely distorted regions or pixels in the definition of assessment function using reciprocal transformation. The proposed object function has higher correlation with human perception, which is mostly affected with the regions having severely distorted points or regions. In addition, salience information is introduced to the object function for a better consideration of subject visual attention. The proposed pooling strategy is applied to classical SSIM and its variants, GSSIM and FSIM. The experimental results have demonstrated that the FR-IQA metrics with proposed pooling strategy have better performances compared to the standard versions, especially on the images with small but seriously distorted regions.
C1 [Huang, Yue; Chen, Xin; Ding, Xinghao] Coll Informat Sci & Engn, Fujian Key Lab Sensing & Comp Smart City, Xiamen 361005, Peoples R China.
RP Ding, XH (corresponding author), Coll Informat Sci & Engn, Fujian Key Lab Sensing & Comp Smart City, Xiamen 361005, Peoples R China.
EM dxh@xmu.edu.cn
FU National Natural Science Foundation of China [30900328, 61172179,
   61103121, 81301278]; National Key Technology RD Program [2012BAI07B06];
   Fundamental Research Funds for the Central Universities [2013121023];
   Research Fund for the Doctoral Program of Higher Education
   [20120121120043]
FX The project is supported by the National Natural Science Foundation of
   China (No. 30900328, 61172179, 61103121, 81301278), The National Key
   Technology R&D Program (2012BAI07B06), the Fundamental Research Funds
   for the Central Universities (No. 2013121023), Research Fund for the
   Doctoral Program of Higher Education under Grant 20120121120043.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Anan Guo, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3297, DOI 10.1109/ICIP.2011.6116375
   [Anonymous], 2013, International Scholarly Research Notices., DOI DOI 10.1155/2013/905685
   [Anonymous], ICIP
   Bondzulic BP, 2014, SIGNAL PROCESS, V97, P110, DOI 10.1016/j.sigpro.2013.10.020
   Charrier C, 2012, SIGNAL PROCESS-IMAGE, V27, P209, DOI 10.1016/j.image.2012.01.002
   Chen GH, 2006, 13 IEEE INT C IM PRO
   Gu K, 2012, MMSP 2012 IE 14 C, V2, P1308
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li CF, 2010, SIGNAL PROCESS-IMAGE, V25, P517, DOI 10.1016/j.image.2010.03.004
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Moorthy AK, 2009, IEEE J-STSP, V3, P193, DOI 10.1109/JSTSP.2009.2015374
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Rouse DM, 2008, IEEE IMAGE PROC, P1188, DOI 10.1109/ICIP.2008.4711973
   Saha A, 2012, IEEE INT CONF MULTI, P43, DOI 10.1109/ICMEW.2012.15
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang Z, The SSIM Index for Image Quality Assessment
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wu J, 2012, P IEEE T IM PROC
   Xue W., 2014, Gradient magnitude similarity deviation: A highly efficient perceptual image quality index
   Zhang L, 2012, IEEE IMAGE PROC, P1477, DOI 10.1109/ICIP.2012.6467150
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhu JY, 2012, IEEE T IMAGE PROCESS, V21, P919, DOI 10.1109/TIP.2011.2169971
NR 27
TC 8
Z9 10
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2769
EP 2780
DI 10.1007/s11042-015-2620-7
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000023
DA 2024-07-18
ER

PT J
AU Joshi, AM
   Mishra, V
   Patrikar, RM
AF Joshi, Amit M.
   Mishra, Vivekanand
   Patrikar, R. M.
TI FPGA prototyping of video watermarking for ownership verification based
   on H.264/AVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bit plane slicing; Digital watermarking; FPGA; H.264; Integer DCT; Scene
   change detection
ID VLSI ARCHITECTURE; COMPRESSED VIDEO; ALGORITHMS; MULTIMEDIA
AB Digital video watermarking has drawn the attention towards authentication and proof of ownership. Uncompressed domain watermarking has flourished over the years and related algorithms have been implemented on the software platform. Software watermarking algorithms work offline where videos are captured through device and embedding algorithms run on a PC that is used to embed the watermark in the original video content. It doesn't suffice real time requirements because of the delay that takes place between capturing and embedding the watermark. This delay involvement is more prone to attacks. Thus, it is essential to develop the system where the watermark gets embedded at the same time when video is being captured. In this paper, an efficient watermark embedding process has been portrayed which is suited to H.264/AVC standard. The proposed algorithm introduces the concept of scene change detection based on Integer Discrete Cosine Transform (Integer-DCT) using scene change detection. The different frames of a scene are embedded with different bit planes of the same watermark in order to improve the performance against temporal attacks. The algorithm is validated on the MATLAB platform and is prototyped on FPGA to show its feasibility for real-time application.
C1 [Joshi, Amit M.] Malaviya Natl Inst Technol, Jaipur 302017, Rajasthan, India.
   [Mishra, Vivekanand] Sardar Vallabhabhi Natl Inst Technol, Surat 395007, India.
   [Patrikar, R. M.] Visvesvaraya Natl Inst Technol, Nagpur 440010, Maharashtra, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur; National Institute of Technology (NIT
   System); Sardar Vallabhbhai National Institute of Technology; National
   Institute of Technology (NIT System); Visvesvaraya National Institute of
   Technology, Nagpur
RP Joshi, AM (corresponding author), Malaviya Natl Inst Technol, Jaipur 302017, Rajasthan, India.
EM amit_mjoshi@yahoo.co.in
RI Patrikar, Rajendra/R-4412-2019; Mishra, Vivekanand/AAA-1894-2019; Joshi,
   Amit/K-4819-2017
OI joshi, amit/0000-0001-7919-1652; mishra, vivekanand/0000-0001-8664-4699;
   Patrikar, Rajendra/0000-0002-9895-275X
FU MHRD
FX We are thankful to Mr. Anand Darji, coordinator of SMDP-II Lab for his
   support for the completion of the paper. Special thanks for MHRD funded
   SMDP-II Lab which provides me the platform to use different tools like
   Design architecture (Synopsys), Modelsim (Mentor Graphics) etc. for the
   simulation and synthesis. We thankful for each and every one who helps
   directly and indirectly to successful completion of the paper.
CR Alattar AM, 2003, IEEE T CIRC SYST VID, V13, P787, DOI 10.1109/TCSVT.2003.815958
   Amer I, 2006, J VIS COMMUN IMAGE R, V17, P533, DOI 10.1016/j.jvcir.2005.05.011
   Biswas S, 2005, IEEE T INSTRUM MEAS, V54, P1853, DOI 10.1109/TIM.2005.855084
   Brunton A, 2005, CAN C EL COMP ENG, P1312
   Chen YH, 2015, NEURAL COMPUT APPL, V26, P291, DOI 10.1007/s00521-014-1615-z
   Danial T, 2014, J INF HIDING MULTIME, V5, P90
   Doërr G, 2003, SIGNAL PROCESS-IMAGE, V18, P263, DOI 10.1016/S0923-5965(02)00144-3
   ElAraby WS, 2010, INT C MICROELECTRON, P463, DOI 10.1109/ICM.2010.5696189
   Gonzales C. A., 1990, Signal Processing: Image Communication, V2, P145, DOI 10.1016/0923-5965(90)90017-C
   Gujjunoori S, 2003, INFORM SECURITY TECH
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Hartung F, 1998, SIGNAL PROCESS, V66, P283, DOI 10.1016/S0165-1684(98)00011-5
   Heo J, 2008, INT CONF SYST SIGNAL, P307, DOI 10.1109/IWSSIP.2008.4604428
   Huang HC, 2007, CIRC SYST SIGNAL PR, V26, P671, DOI 10.1007/s00034-006-0104-z
   Huang K, 2013, J ZHEJIANG U-SCI C, V14, P449, DOI 10.1631/jzus.C1200250
   Jeong Y-J, 2008, C FUT GEN COMM NETW, P63
   Joshi A, 2012, REAL TIME IMPLEMENTA, V2, P65
   Kougianos E, 2009, COMPUT ELECTR ENG, V35, P339, DOI 10.1016/j.compeleceng.2008.06.002
   Küçüktunç O, 2010, COMPUT VIS IMAGE UND, V114, P125, DOI 10.1016/j.cviu.2009.09.008
   Li X, 2008, Int Book Ser Inf Sci Comput, P9
   Liao K, 2012, TELECOMMUN SYST, V49, P261, DOI 10.1007/s11235-010-9372-5
   Lin HY, 2008, IEEE T MULTIMEDIA, V10, P31, DOI 10.1109/TMM.2007.911299
   Ling HF, 2011, SIGNAL PROCESS, V91, P1863, DOI 10.1016/j.sigpro.2011.02.009
   Maes M, 2000, IEEE SIGNAL PROC MAG, V17, P47, DOI 10.1109/79.879338
   Malvar HS, 2003, IEEE T CIRC SYST VID, V13, P598, DOI 10.1109/TCSVT.2003.814964
   Mansouri A, 2010, IEEE T INF FOREN SEC, V5, P649, DOI 10.1109/TIFS.2010.2076280
   Mathai NJ, 2003, IEEE T SIGNAL PROCES, V51, P925, DOI 10.1109/TSP.2003.809382
   Mohanty SP, 2011, J SYST SOFTWARE, V84, P724, DOI 10.1016/j.jss.2010.12.012
   Nguyen NM, 2012, PROC INT CONF ADV, P158, DOI 10.1109/ATC.2012.6404250
   Pang C, 2012, SIGNAL PROCESS-IMAGE, V27, P737, DOI 10.1016/j.image.2012.03.007
   Patsakis Constantinos., 2014, Journal of Information Hiding and Multimedia Signal Processing, V5, P20
   Petitjean G, 2003, IEEE INT C MULTIMEDI, V1, P597
   Richardson Iain E, 2004, H. 264 and MPEG-4 Video Compression: Video Coding for Next-Generation Multimedia
   Roy SD, 2011, IEEE T CIRC SYST VID, V23, P289
   Shoshan Y., 2008, INT J INFORM TECHNOL, V2, P379
   VURAL S, 2005, P 13 EUR SIGN PROC C, P303
   Wang Y, 2004, PATTERN RECOGN, P1681
   Wu CH, 2011, AEU-INT J ELECTRON C, V65, P27, DOI 10.1016/j.aeue.2010.02.003
   Xu DW, 2012, J REAL-TIME IMAGE PR, V7, P205, DOI 10.1007/s11554-010-0175-4
   Zhang J, 2007, IEEE T CIRCUITS-II, V54, P205, DOI 10.1109/TCSII.2006.886247
   Zhang PM, 2012, ADV INTEL SOFT COMPU, V133, P859
NR 41
TC 22
Z9 22
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3121
EP 3144
DI 10.1007/s11042-014-2426-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600009
DA 2024-07-18
ER

PT J
AU Deebak, BD
   Muthaiah, R
   Thenmozhi, K
   Swaminathan, PI
AF Deebak, Bakkiam David
   Muthaiah, Rajappa
   Thenmozhi, Karuppuswamy
   Swaminathan, Pitchai Iyer
TI Analyzing secure key authentication and key agreement protocol for
   promising features of IP multimedia subsystem using IP multimedia
   server-client systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Session initiation protocol; Authentication and key agreement; IP
   multimedia subsystem; Context identity; Elliptic curve Diffie Hellman;
   Serving call session control function; Bandwidth consumption; Signalling
   congestion
ID 3GPP AUTHENTICATION; EXTENSION; SCHEME
AB Recently, Session Initiation Protocol (SIP) has become a prime signaling protocol for the multimedia communication systems, though none of the researchers have analyzed its promising features, namely access independence, authentication scheme verification, AKA (Authentication and Key Agreement) security properties, 3GPP security properties, signal congestion, bandwidth consumption and computation overhead using the physical multimedia server-client platform. To examine the issues realistically, the existing authentication schemes, such as UMTS AKA, EPS AKA, Cocktail AKA, S AKA, HL AKA and ZZ AKA were designed and developed in the multimedia server-client systems deployed on Linux platform. The cross-examination revealed that the existing schemes failed to satisfy the IMS (IP Multimedia Subsystem) promising features, like mutual authentication, session-key sharing, (perfect) forward secrecy and implicit-key authentication. Thus, this paper proposes a Secure-Key Authentication and Key Agreement protocol (SK AKA) to meet out the standard demands of IMS. To curtail its authentication steps, the secure authentication vector S (AV) computes and dispenses the generated vectors between the multimedia server-client systems in advance, through the serving call session control function S (CSCF) . As a result, the execution steps of UMTS AKA are annulled for the sake of accomplishment of the IMS features. In addition, the protocol of SK AKA integrates the strategies of Context Identity C (ID) and Elliptic Curve - Diffie Hellman (EC-DH) to resist most of the potential attacks like SIP flooding, forgery, man-in-the-middle, password guessing and key impersonation. To analyze the parameters, such as (SIP) Flooding Attack Detection Rate, End-To-End Delay of Multiple Voice Call Session, Call Success Rate, SIP Utilization, RTP Utilization, Call Response Time, Bandwidth Consumption and Signalling Congestion realistically, the proposed and existing authentication schemes have been coded and integrated in the real-time IMS client-server system. Above all, the thoroughgoing research has revealed that the proposed protocol of SK AKA accomplishes all the IMS challenges: 1. Adhere the promising features of IMS; 2. Attack resiliency; and 3. Fulfill the promising parameters of IMS, in comparison with the other existing schemes.
C1 [Deebak, Bakkiam David; Muthaiah, Rajappa; Swaminathan, Pitchai Iyer] SASTRA Univ, Sch Comp, Thanjavur 613401, TN, India.
   [Thenmozhi, Karuppuswamy] SASTRA Univ, Sch Elect & Elect, Thanjavur 613401, TN, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Deebak, BD (corresponding author), SASTRA Univ, Sch Comp, Thanjavur 613401, TN, India.
EM jrvd_deebak@ymail.com; sjamuthaiah@core.sastra.edu;
   kthenmozhi@ece.sastra.edu; deanpsw@sastra.edu
RI Deebak, B. D./AAJ-6133-2020; B D, Deebak/ABC-5122-2022
OI Deebak, B. D./0000-0002-4008-6350; Rajappa,
   Muthaiah/0000-0002-6659-1961; Karuppuswamy,
   Thenmozhi/0000-0001-9829-0189
FU SASTRA; Tata Consultancy Services
FX The corresponding author would like to SASTRA and Tata Consultancy
   Services for financial assistance under the scheme of Research Scholar
   Program (RSP).
CR Al-Saraireh Ja'afer, 2006, EURASIP J WIREL COMM, V2006, P19
   [Anonymous], 21133 3GPP TS
   [Anonymous], P 2003 ACM WORKSH WI
   [Anonymous], 2016, HDB APPL CRYPTOGRAPH
   [Anonymous], 2009, INT J NETW SECUR
   [Anonymous], 2002, CRYPTOGRAPHY THEORY
   [Anonymous], 2006, INT J NETWORK SECURI
   [Anonymous], 33401 3GPP TS
   Arapinis Myrto, 2012, ACM C COMPUTER COMMU, P205, DOI DOI 10.1145/2382196.2382221
   Boyd Colin., 2003, INF SECUR CRYTOGR
   Chang CC, 2005, COMPUT COMMUN, V28, P921, DOI 10.1016/j.comcom.2005.01.015
   Chang KD, 2012, KSII T INTERNET INF, V6, P305, DOI 10.3837/tiis.2012.01.017
   Chen CY, 2008, COMPUT COMMUN, V31, P4259, DOI 10.1016/j.comcom.2008.05.025
   Chen YW, 2012, WIRELESS PERS COMMUN, V62, P965, DOI 10.1007/s11277-010-0104-7
   CHOI Y, 2004, P WORKSH INF SEC APP, P14
   Dominguez A.P., 2006, INT J NETWORK SECURI, V3, P279
   Fadlullah ZM, 2010, IEEE ACM T NETWORK, V18, P1234, DOI 10.1109/TNET.2009.2039492
   Gardezi A., 2006, SECURITY WIRELESS CE
   Huang CM, 2005, 19TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1, PROCEEDINGS, P392
   Huang YL, 2011, IEEE T VEH TECHNOL, V60, P4509, DOI 10.1109/TVT.2011.2168247
   Juang W., 2007, WIR COMM NETW C MARC, P2720
   Lee CC, 2003, IEE P-COMMUN, V150, P91, DOI 10.1049/ip-com:20030290
   Lee CC, 2008, WIREL COMMUN MOB COM, V8, P661, DOI 10.1002/wcm.495
   Lee CC, 2006, IEEE T IND ELECTRON, V53, P1683, DOI 10.1109/TIE.2006.881998
   Lee CC, 2013, WIRELESS PERS COMMUN, V68, P861, DOI 10.1007/s11277-011-0486-1
   Liang XH, 2011, J COMMUN NETW-S KOR, V13, P102, DOI 10.1109/JCN.2011.6157409
   Lin YB, 2005, IEEE J SEL AREA COMM, V23, P1233, DOI 10.1109/JSAC.2005.845631
   Liu BY, 2014, IEEE T INF FOREN SEC, V9, P436, DOI 10.1109/TIFS.2013.2296437
   Mao W., 2004, Modern cryptography theory and practice
   Meyer U., 2004, P 3 ACM WORKSHOP WIR, P90, DOI DOI 10.1145/1023646.1023662
   Ntop, 2012, TRAFF AN TOOL
   Ou HH, 2010, J SYST SOFTWARE, V83, P316, DOI 10.1016/j.jss.2009.08.019
   Poikselka M., 2006, IMS IP MULTIMEDIA CO
   Rosenberg J, 2002, 3261 IETF RFC
   Shen J. J., 2005, INT J NETWORK SECURI, V1, P118
   SHNEIER B, 1996, APPL CRYPTOGRAPHY
   Wei LF, 2014, INFORM SCIENCES, V258, P371, DOI 10.1016/j.ins.2013.04.028
   Wei Lifei, 2014, P 2010 IE 30 INT C D, P52
   Wu SH, 2010, IEEE COMMUN LETT, V14, P366, DOI 10.1109/LCOMM.2010.04.092279
   Xiaohui Liang, 2012, IEEE International Conference on Communications (ICC 2012), P3451, DOI 10.1109/ICC.2012.6363888
   Yan Z, 2014, J NETW COMPUT APPL, V42, P120, DOI 10.1016/j.jnca.2014.01.014
   Yang HM, 2014, COMPUT NETW, V58, P29, DOI 10.1016/j.comnet.2013.08.020
   Zhang M, 2003, 2003092 VER COMM
   Zhang MX, 2005, IEEE T WIREL COMMUN, V4, P734, DOI 10.1109/TWC.2004.842941
   Zhang X, 2014, IEEE ACM T NETWORK, V22, P1218, DOI 10.1109/TNET.2013.2274662
   Zhang ZZ, 2015, MULTIMED TOOLS APPL, V74, P3477, DOI 10.1007/s11042-014-1885-6
   Zhu HJ, 2009, IEEE T VEH TECHNOL, V58, P2529, DOI 10.1109/TVT.2008.2007983
NR 47
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 2111
EP 2143
DI 10.1007/s11042-014-2397-0
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000018
DA 2024-07-18
ER

PT J
AU Lin, Z
   Yan, JW
   Yuan, Y
AF Lin, Zhe
   Yan, Jingwen
   Yuan, Ye
TI Target detection for SAR images based on beamlet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SAR; Target detection; Beamlet transform; Beamlet clustering
ID CFAR DETECTION; OBJECTS
AB Target detection for SAR images has many important applications; however there is a challenge that inherent speckle noise in SAR images may cause serious interference. Beamlet transform is a multi-scale image analysis method to extract line features in an image with strong anti-noise capacity. In this paper a method based on Beamlet transform is proposed for target detection for SAR images. It takes the advantage of Beamlet transform in feature extraction. Firstly Beamlet transform is applied on a SAR image to obtain Beamlet coefficients,which are then processed by a coefficient filtering algorithm to remove unreal Beamlet features caused by noise. The remained Beamlet features are fed to the BD-RDP (Beamlet-decorated recursive dyadic partition) algorithm for optimization and then clustered by NEC (Nearest Endpoint Clustering) algorithm to detect targets. The experimental results show that this method is able to detect target directly in a SAR image without pre-filtering. Further more, it still works well under the background of strong speckle noise.
C1 [Lin, Zhe] Shantou Polytech, Dept Comp, Shantou 515078, Guangdong, Peoples R China.
   [Yan, Jingwen] Guangdong Prov Key Lab Digital Signal & Image Pro, Shantou 515063, Guangdong, Peoples R China.
   [Yuan, Ye] Shantou Univ, Dept Elect Engn, Shantou 515063, Guangdong, Peoples R China.
C3 Shantou University
RP Yan, JW (corresponding author), Guangdong Prov Key Lab Digital Signal & Image Pro, Shantou 515063, Guangdong, Peoples R China.
EM gd1392@126.com; jwyan@stu.edu.cn; yuanye@stu.edu.cn
FU National Natural Science Foundation of China [40971206]
FX This paper was sponsored by the National Natural Science Foundation of
   China (No. 40971206)
CR Anastassipoulos V, 2005, IEEE T AES, V31, P52
   Anastassopoulos V, 1999, IEEE T AERO ELEC SYS, V35, P43, DOI 10.1109/7.745679
   ANASTASSOPOULOS V, 1992, IEEE T AERO ELEC SYS, V28, P420, DOI 10.1109/7.144568
   [Anonymous], LECT NOTES COMPUTATI
   Brunner D, 2012, IEEE GEOSCI REMOTE S, V9, P557
   di Bisceglie M, 2005, IEEE T GEOSCI REMOTE, V43, P833, DOI 10.1109/TGRS.2004.843190
   Donoho DL, 2000, P SOC PHOTO-OPT INS, V4119, P434, DOI 10.1117/12.408630
   Farrouki A, 2005, IEE P-RADAR SON NAV, V152, P43, DOI 10.1049/ip-rsn:20045006
   Gao G, 2011, IEEE GEOSCI REMOTE S, V8, P557, DOI 10.1109/LGRS.2010.2090492
   Han P, 2003, INT CONF ACOUST SPEE, P429
   Kaplan LM, 1999, PROC SPIE, V3721, P35, DOI 10.1117/12.357684
   Kaplan LM, 2001, IEEE T AERO ELEC SYS, V37, P436, DOI 10.1109/7.937460
   Na W, 2011, INT C INTELL COMP TE, P881
   NOVAK LM, 1994, PATTERN RECOGN, V27, P607, DOI 10.1016/0031-3203(94)90040-X
   Qin XX, 2013, IEEE GEOSCI REMOTE S, V10, P806, DOI 10.1109/LGRS.2012.2224317
   Salazar JS, 1998, INT C SIG IM P LAS E, P21
   Strickland RN, 1997, IEEE T IMAGE PROCESS, V6, P724, DOI 10.1109/83.568929
   Ying L., 2009, 2009 IEEE International Conference on Electro/Information Technology (EIT '09), P141, DOI 10.1109/EIT.2009.5189598
   Yuan Z, 2011, GEO-SPAT INF SCI, V14, P169, DOI 10.1007/s11806-011-0536-6
   Zhi-Guo Y, 2007, 2007 1ST ASIAN AND PACIFIC CONFERENCE ON SYNTHETIC APERTURE RADAR PROCEEDINGS, P457
   Zhou GY, 2011, IEEE T GEOSCI REMOTE, V49, P1453, DOI 10.1109/TGRS.2010.2081373
   Zhu YG, 2011, PROCEEDINGS OF THE ASME INTERNATIONAL MANUFACTURING SCIENCE AND ENGINEERING CONFERENCE 2010, VOL 2, P1, DOI 10.1109/CVPR.2011.5995650
NR 22
TC 5
Z9 5
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 2189
EP 2202
DI 10.1007/s11042-014-2401-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000021
DA 2024-07-18
ER

PT J
AU Liu, T
   Ding, X
   Chen, YH
   Chen, HC
   Guo, MS
AF Liu, Ting
   Ding, Xiao
   Chen, Yiheng
   Chen, Haochen
   Guo, Maosheng
TI Predicting movie Box-office revenues by exploiting large-scale social
   media content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Movie box-office revenue; Social media; Prediction; Purchase intention
   mining
ID REGULARIZATION; TWITTER
AB Predicting the box-office revenue of a movie before its theatrical release is an important but challenging problem that requires a high level of Artificial Intelligence. Nowadays, social media has shown its predictive power in various domains, which motivates us to exploit social media content to predict box-office revenues. In this study, we employ both linear and non-linear regression models, which are based on the crowd wisdom of social media, especially the posts of users, to predict movie box-office revenues. More specifically, the attention and popularity of the movie, purchase intention of users, and comments of users are automatically mined from social media data. In our model, the use of Linear Regression and Support Vector Regression in predicting the box-office revenue of a movie before its theatrical release is explored. To evaluate the effectiveness of the proposed approach, a cross-validation experiment is conducted. The experimental results show that large-scale social media content is correlated with movie box-office revenues and that the purchase intention of users can lead to more accurate movie box-office revenue predictions. Both the linear and non-linear prediction models have the advantage of predicting movie grosses in our experiments.
C1 [Liu, Ting; Ding, Xiao; Chen, Yiheng; Chen, Haochen; Guo, Maosheng] Harbin Inst Technol, Res Ctr Social Comp & Informat Retrieval, Harbin 150006, Peoples R China.
   [Ding, Xiao] Harbin Nangang Dist Jiaohua St 29,6th floor, Harbin 151000, Peoples R China.
C3 Harbin Institute of Technology
RP Ding, X (corresponding author), Harbin Nangang Dist Jiaohua St 29,6th floor, Harbin 151000, Peoples R China.
EM tliu@ir.hit.edu.cn; xding@ir.hit.edu.cn; yhchen@ir.hit.edu.cn;
   hcchen@ir.hit.edu.cn; msguo@ir.hit.edu.cn
RI liu, ting/GZM-3326-2022; Chen, Yiheng/AAC-9309-2019
OI Chen, Yiheng/0000-0002-9943-089X
CR [Anonymous], 1994, The Journal of Media Economics
   [Anonymous], 2010, Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT '10
   [Anonymous], 1999, REPOSIT TU DORTMUND, DOI DOI 10.17877/DE290R-5098
   [Anonymous], 2011, J COMPUT SCI-NETH, DOI DOI 10.1016/j.jocs.2010.12.007
   [Anonymous], 2011, ICWSM
   [Anonymous], 2005, Proceedings 11th International Conference Knowledge Discovery in Data Mining, DOI DOI 10.1145/1081870.1081883
   [Anonymous], 2006, AAAI Symposium on Computational Approaches to Analysing Weblogs (AAAI-CAAW)
   Asur S., 2010, Proceedings 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology (WI-IAT), P492, DOI 10.1109/WI-IAT.2010.63
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Bothos E., 2010, IEEE INTELLIGENT SYS, VPP
   Chaovalit P, 2005, SYST SCI 2005 HICSS, p112c
   Chen A., 2002, FORECASTING GROSS RE
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Ding X., 2008, P 2008 INT C WEB SEA, P231, DOI [DOI 10.1145/1341531.1341561, 10.1145/1341531.1341561]
   Drucker H, 1997, ADV NEUR IN, V9, P155
   Friedman J, 2010, J STAT SOFTW, V33, P1, DOI 10.18637/jss.v033.i01
   Jansen BJ, 2009, J AM SOC INF SCI TEC, V60, P2169, DOI 10.1002/asi.21149
   Jansen H J, 2006, CANADIAN J COMMUNICA, V30
   Jungherr A, 2012, SOC SCI COMPUT REV, V30, P229, DOI 10.1177/0894439311404119
   Lica Liviu, 2011, Informatica Economica, V15, P46
   Litman BarryR., 1989, J MEDIA ECON, V2, P35
   Metaxas P.T., 2011, 2011 IEEE 3 INT C PR, P165, DOI [10.1109/PASSAT/SocialCom.2011.98, DOI 10.1109/PASSAT/SOCIALCOM.2011.98]
   OConnor B, 2010, ICWSM, P122, DOI DOI 10.1609/ICWSM.V4I1.14031
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Ritterman J., 2009, 1 INT WORKSH MIN SOC, V9
   Sakaki T., 2010, P 19 INT C WORLD WID, P851
   Sawhney MS, 1996, MARKET SCI, V15, P113, DOI 10.1287/mksc.15.2.113
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Sharda R, 2006, EXPERT SYST APPL, V30, P243, DOI 10.1016/j.eswa.2005.07.018
   Sharda R., 2000, Proceedings of the International DSI Conference, P1
   Si J., 2008, P ANN M ASS COMP LIN, P24
   Simonoff J., 2000, Chance, V13, P15, DOI [DOI 10.1080/09332480.2000.10542216, 10.1080/09332480.2000.10542216]
   Skoric M., 2012, 2012 45th Hawaii International Conference on System Sciences (HICSS), P2583, DOI 10.1109/HICSS.2012.607
   Sysomos Inc, 2012, IN DEPTH LOOK INS TW
   Theil H., 1961, Economic Forecasts and Policy, V2
   Tumasjan A, 2010, 4 INT AAAI C WEBL SO, V10, P178, DOI 10.1074/jbc.M501708200
   UzZaman N, 2012, ARXIV12116496
   Vapnik VN, 2000, NATURE STAT LEARNING, DOI DOI 10.1007/978-1-4757-3264-1
   Williams C., 2008, What is a Social Network Worth? Facebook and Vote Share in the 2008 Presidential Primaries
   Zhang L, 2009, EXPERT SYST APPL, V36, P6580, DOI 10.1016/j.eswa.2008.07.064
   Zhang WB, 2009, 2009 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 1, P301
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 43
TC 46
Z9 56
U1 3
U2 86
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 3
BP 1509
EP 1528
DI 10.1007/s11042-014-2270-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA DF4HW
UT WOS:000371309600010
DA 2024-07-18
ER

PT J
AU Xia, L
   Sheng, B
   Wu, W
   Ma, LZ
   Li, P
AF Xia, Li
   Sheng, Bin
   Wu, Wen
   Ma, Lizhuang
   Li, Ping
TI Accurate gaze tracking from single camera using gabor corner detector
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gaze tracking; Corner detector; Pupil center estimation; Single camera
AB Most of the existing gaze tracking schemes with high accuracy and high speed depend on infra-red (IR) lights and multi-cameras, which leads to high complexity of apparatus and high cost. Besides, many proposed approaches hardly offer a full discussion and solution of eye blink issue. In this paper, we propose a novel gaze tracking scheme which is capable of tracking eye movements in high accuracy. Our scheme incorporates the eye corner information extracted using a novel eye corner detector. This detector is developed based on the Gabor Wavelet Transform and the Structure Tensor. Gabor Wavelet Transform decomposes an image in multi-scales and multi-orientations, thus is robust against lighting variation and tiny shift. We abstract the distribution statistics of the feature points in the eye region and re-express it as a connectivity graph. Based on such abstraction we propose a novel solution to the eye blink issue which obtains a high successful detection rate. After implementation, our scheme is proven to be accurate compared with the state of the art. Notably, only one web camera is employed in our scheme without any auxiliary light source or cameras.
C1 [Xia, Li; Sheng, Bin; Ma, Lizhuang] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China.
   [Wu, Wen] Univ Macau, Fac Sci & Technol, Dept Comp & Informat Sci, Macau, Peoples R China.
   [Li, Ping] Hong Kong Inst Educ, Dept Math & Informat Technol, Hong Kong, Hong Kong, Peoples R China.
   [Sheng, Bin] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
C3 Shanghai Jiao Tong University; University of Macau; Education University
   of Hong Kong (EdUHK); Chinese Academy of Sciences; Institute of
   Software, CAS
RP Sheng, B (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China.
EM shengbin@cs.sjtu.edu.cn
RI Li, Ping/AAO-2019-2020; Sun, Peng/KDO-4243-2024
OI Li, Ping/0000-0002-1503-0240; 
FU National Natural Science Foundation of China [61202154, 61133009];
   National Basic Research Project of China [2011CB302203]; Shanghai
   Pujiang Program [13PJ1404500]; Science and Technology Commission of
   Shanghai Municipality Program [13511505000]; Open Projects Program of
   National Laboratory of Pattern Recognition; Open Project Program of the
   State Key Lab of CADCG [A1401]; Zhejiang University; HKIEd-Internal
   Research Grant [RG 77/2013-2014R]; University of Macau [MYRG150
   (Y1-L2)-FST11-WW, MYRG2014-00139-FST]
FX The authors would like to thank all reviewers for their helpful
   suggestions and constructive comments. The work is supported by the
   National Natural Science Foundation of China (No.61202154, 61133009),
   the National Basic Research Project of China (No. 2011CB302203),
   Shanghai Pujiang Program (No.13PJ1404500), the Science and Technology
   Commission of Shanghai Municipality Program (No. 13511505000), the Open
   Projects Program of National Laboratory of Pattern Recognition, and the
   Open Project Program of the State Key Lab of CAD&CG (Grant No. A1401),
   Zhejiang University, the HKIEd-Internal Research Grant (ref. RG
   77/2013-2014R), the grant of University of Macau under Grant No. MYRG150
   (Y1-L2)-FST11-WW and MYRG2014-00139-FST.
CR [Anonymous], 2006, P S EYE TRACK RES AP, DOI DOI 10.1145/1117309.1117349
   Coutinho FL, 2006, SIBGRAPI, P171
   Dongheng L., 2005, 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, P79
   Gao XT, 2007, IEEE T CIRC SYST VID, V17, P868, DOI 10.1109/TCSVT.2007.897473
   Guestrin ED, 2006, IEEE T BIO-MED ENG, V53, P1124, DOI 10.1109/TBME.2005.863952
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Harris C., 1988, P ALV VIS C, P5210
   Kumar N, 2009, IEEE SYS MAN CYBERN, P1255, DOI 10.1109/ICSMC.2009.5345909
   Lee Tai S., 1996, PATTERN ANAL MACHINE, V18
   Li D., 2006, P 2006 S EYE TRACKIN, P95, DOI DOI 10.1145/1117309.1117350
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Ramanauskas N, 2008, LECT NOTES COMPUT SC, V5105, P1208, DOI 10.1007/978-3-540-70540-6_182
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Timm F, 2011, VISAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, P125
   Torricelli D, 2008, COMPUT METH PROG BIO, V92, P66, DOI 10.1016/j.cmpb.2008.06.008
   Valenti R, 2012, IEEE T IMAGE PROCESS, V21, P802, DOI 10.1109/TIP.2011.2162740
   Villanueva A, 2008, IEEE T SYST MAN CY B, V38, P1123, DOI 10.1109/TSMCB.2008.926606
   Yamazoe H, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P245, DOI 10.1145/1344471.1344527
   Zhu ZW, 2007, IEEE T BIO-MED ENG, V54, P2246, DOI 10.1109/TBME.2007.895750
NR 19
TC 12
Z9 15
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 221
EP 239
DI 10.1007/s11042-014-2288-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500012
DA 2024-07-18
ER

PT J
AU Yu, H
   Garrod, O
   Jack, R
   Schyns, P
AF Yu, Hui
   Garrod, Oliver
   Jack, Rachael
   Schyns, Philippe
TI A framework for automatic and perceptually valid facial expression
   generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression mapping; Facial animation; FACS; Psychophysical;
   Perceptually valid; Face dynamics
ID ANIMATION; MODELS
AB Facial expressions are facial movements reflecting the internal emotional states of a character or in response to social communications. Realistic facial animation should consider at least two factors: believable visual effect and valid facial movements. However, most research tends to separate these two issues. In this paper, we present a framework for generating 3D facial expressions considering both the visual the dynamics effect. A facial expression mapping approach based on local geometry encoding is proposed, which encodes deformation in the 1-ring vector. This method is capable of mapping subtle facial movements without considering those shape and topological constraints. Facial expression mapping is achieved through three steps: correspondence establishment, deviation transfer and movement mapping. Deviation is transferred to the conformal face space through minimizing the error function. This function is formed by the source neutral and the deformed face model related by those transformation matrices in 1-ring neighborhood. The transformation matrix in 1-ring neighborhood is independent of the face shape and the mesh topology. After the facial expression mapping, dynamic parameters are then integrated with facial expressions for generating valid facial expressions. The dynamic parameters were generated based on psychophysical methods. The efficiency and effectiveness of the proposed methods have been tested using various face models with different shapes and topological representations.
C1 [Yu, Hui] Univ Portsmouth, Portsmouth, Hants, England.
   [Garrod, Oliver; Jack, Rachael; Schyns, Philippe] Univ Glasgow, Glasgow, Lanark, Scotland.
C3 University of Portsmouth; University of Glasgow
RP Yu, H (corresponding author), Univ Portsmouth, Portsmouth, Hants, England.
EM hui.yu@port.ac.uk
RI Yu, Hui/G-1115-2018; Schyns, Philippe/AAT-6989-2020; Jack,
   Rachael/A-4692-2012
OI Yu, Hui/0000-0002-7655-9228; Schyns, Philippe/0000-0002-8542-7489
CR [Anonymous], COMPUT ANIMAT VIRTUA
   Asthana A, 2012, IEEE T VIS COMPUT GR, V18, P1511, DOI 10.1109/TVCG.2011.157
   Chin S, 2009, IEEE T SYST MAN CY C, V39, P315, DOI 10.1109/TSMCC.2008.2011283
   Choe B, 2001, J VISUAL COMP ANIMAT, V12, P67, DOI 10.1002/vis.246
   Cosker D, 2008, IET COMPUT VIS, V2, P129, DOI 10.1049/iet-cvi:20070041
   Curio C, 2007, P ACMAPGV, P59
   Deng Z., 2007, COMPUTER FACIAL ANIM, P1
   DO MP, 1976, DIFFERENTIAL GEOMETR
   Ekman P, 1978, FACIAL ACTION CODING
   Ersotelos N, 2008, VISUAL COMPUT, V24, P13, DOI 10.1007/s00371-007-0175-y
   Gao W, 2003, IEEE T CIRC SYST VID, V13, P1119, DOI 10.1109/TCSVT.2003.817629
   Hartley R., 2004, COMPUTER VISION
   Kalogerakis E., 2007, P EUROGRAPHICSSIGGRA, P13
   Kalra P., 1992, Computer Graphics Forum, V11, pC59, DOI 10.1111/1467-8659.1130059
   Lee IH, 2014, MULTIMED TOOLS APPL, V71, P247, DOI 10.1007/s11042-013-1433-9
   Meyer M., 2002, VISUALIZATION MATH, V6, P35, DOI DOI 10.1007/978-3-662-05105-4_2
   Noh JY, 2001, COMP GRAPH, P277, DOI 10.1145/383259.383290
   Parke F., 1996, COMPUTER FACIAL ANIM
   PARKE FI, 1982, IEEE COMPUT GRAPH, V2, P61
   Parke FrederickI., 1972, Proceedings of the ACM annual conference, V1, P451
   Popovic Z, 1999, COMP GRAPH, P11, DOI 10.1145/311535.311536
   Saracchini RFV, 2013, COMPUT IND, V64, P1399, DOI 10.1016/j.compind.2013.04.003
   Shin HJ, 2009, COMPUT GRAPH FORUM, V28, P1829, DOI 10.1111/j.1467-8659.2009.01560.x
   Sifakis E., 2006, ACM SIGGRAPHEUROGRAP, P261
   Sorkine O., 2004, P 2004 EUR ACM SIGGR, P179
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Sun Y, 2010, IEEE T SYST MAN CY A, V40, P461, DOI 10.1109/TSMCA.2010.2041659
   Taubin G, 2000, P EUR 2000 STAR STAT
   Terzopoulos D., 1990, Journal of Visualization and Computer Animation, V1, P73, DOI 10.1002/vis.4340010208
   Vezzetti F, 2013, MULTIMEDIA TOOLS APP
   Weng Y, 2006, 2D SHAPE DEFORMATION, V22
   Williams L., 1990, Computer Graphics, V24, P235, DOI 10.1145/97880.97906
   Ying SH, 2009, IEEE T AUTOM SCI ENG, V6, P559, DOI 10.1109/TASE.2009.2021337
   Yu H, 2012, COMPUT GRAPH-UK, V36, P152, DOI 10.1016/j.cag.2011.12.002
   Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759
   Zhang QS, 2006, IEEE T VIS COMPUT GR, V12, P48, DOI 10.1109/TVCG.2006.9
NR 36
TC 10
Z9 11
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9427
EP 9447
DI 10.1007/s11042-014-2125-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200017
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Sajjad, M
   Ejaz, N
   Mehmood, I
   Baik, SW
AF Sajjad, Muhammad
   Ejaz, Naveed
   Mehmood, Irfan
   Baik, Sung Wook
TI Digital image super-resolution using adaptive interpolation based on
   Gaussian function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image magnification; Super-resolution; Laplacian; Gaussian
   kernel; Gaussian sigma; Weighted interpolation; Human visual perception
ID VIDEO
AB This paper presents a new approach to digital image super-resolution (SR). Image SR is currently a very active area of research because it is used in various applications. The proposed technique uses Gaussian edge directed interpolation to determine the precise weights of the neighboring pixels. The standard deviation of the interpolation window determines the value of the sigma 'sigma' for generating Gaussian kernels. Therefore, the proposed scheme adaptively applies different Gaussian kernels according to the computed standard deviation of the interpolation window. Laplacian is applied to the image generated by the Gaussian kernels to enhance the visual quality of the output image. It has the significant benefit of being isotropic i.e. invariant to rotation. These features of being isotropic not only resemble human visual perception but also respond to intensity variations equally in all directions for any kind of kernel. It highlights the discontinuities of high frequencies in the image generated by the Gaussian kernel and deemphasizes the regions with slowly varying luminance levels. It also recovers the background missing features while preserving the sharpness of the output image. The proposed scheme preserves geometrical regularities across the boundaries and smoothes intensities inside the high frequencies. It also maintains the textures inside geometrical regularities. Therefore, high resolution (HR) images produced by the proposed scheme contain intensity information very close to the original details of the low-resolution (LR) image i.e. edges, smoothness and texture information. Various evaluation metrics have been applied to compute the validity of the proposed technique. Extensive experimental comparisons with state-of-the-art zooming schemes validate the claim of the proposed technique of being superior. It produces high quality at the cost of low time complexity.
C1 [Sajjad, Muhammad; Ejaz, Naveed; Mehmood, Irfan; Baik, Sung Wook] Sejong Univ, Coll Elect & Informat Engn, Seoul, South Korea.
C3 Sejong University
RP Baik, SW (corresponding author), Sejong Univ, Coll Elect & Informat Engn, Seoul, South Korea.
EM sajjad@sju.ac.kr; naveed@sju.ac.kr; irfanmehmood@sju.ac.kr;
   sbaik@sejong.ac.kr
RI Sajjad, Muhammad/GZL-4962-2022; Baik, Sung Wook/AAR-8236-2020; Ejaz,
   Naveed/HZL-7415-2023; Ejaz, Naveed/HZJ-6101-2023; Ejaz,
   Naveed/I-2891-2012; Sajjad, Muhammad/L-5269-2016
OI Sajjad, Muhammad/0000-0003-0006-1156; Ejaz, Naveed/0000-0003-1295-4787;
   Ejaz, Naveed/0000-0003-1295-4787; Sajjad, Muhammad/0000-0001-5646-0338;
   Mehmood, Irfan/0000-0001-7864-957X; Baik, Sung Wook/0000-0002-6678-7788
FU Basic Science Research Program through National Research Foundation of
   Korea (NRF) - Ministry of Education [2013R1A1A2012904]; Industrial
   Strategic technology development program by Ministry of Trade, Industry
   and Energy' (MOTIE) [10041772]
FX This research is supported by: (1) Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education (2013R1A1A2012904). (2) Industrial Strategic
   technology development program, 10041772, (The Development of an
   Adaptive Mixed-Reality Space based on Interactive Architecture) funded
   by the Ministry of Trade, Industry and Energy' (MOTIE).
CR Acharya T., 2007, UBIQUITY, V8, P1, DOI [10.1145/1322464.1317488, DOI 10.1145/1322464.1317488]
   Amanatiadis A, 2009, MEAS SCI TECHNOL, V20, DOI 10.1088/0957-0233/20/10/104015
   [Anonymous], 1982, Digital Picture Processing
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Battiato S, 2002, IMAGE VISION COMPUT, V20, P805, DOI 10.1016/S0262-8856(02)00089-6
   Ejaz N, 2012, J VIS COMMUN IMAGE R, V23, P1031, DOI 10.1016/j.jvcir.2012.06.013
   Gajjar PP, 2010, IEEE T IMAGE PROCESS, V19, P1201, DOI 10.1109/TIP.2010.2041408
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   He H, 2011, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2011.5995713
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   HUBEL DH, 1969, J PHYSIOL-LONDON, V202, P251, DOI 10.1113/jphysiol.1969.sp008808
   HUBEL DH, 1959, J PHYSIOL-LONDON, V147, P226, DOI 10.1113/jphysiol.1959.sp006238
   Hung KW, 2009, IEEE IMAGE PROC, P1193, DOI 10.1109/ICIP.2009.5413696
   Hwang JW, 2004, IEEE SIGNAL PROC LET, V11, P359, DOI 10.1109/LSP.2003.821718
   Irani M., 1993, Journal of Visual Communication and Image Representation, V4, P324, DOI 10.1006/jvci.1993.1030
   Jurio A, 2011, IEEE T IMAGE PROCESS, V20, P3112, DOI 10.1109/TIP.2011.2158227
   Kwon Y, 2008, 173 MAX PLANCK I
   Lee YJ, 2010, IEEE T IMAGE PROCESS, V19, P2682, DOI 10.1109/TIP.2010.2050108
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Mallat S, 2010, IEEE T IMAGE PROCESS, V19, P2889, DOI 10.1109/TIP.2010.2049927
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Ni KS, 2007, IEEE T IMAGE PROCESS, V16, P1596, DOI 10.1109/TIP.2007.896644
   Sajjad M, 2014, MULTIMED TOOLS APPL, V72, P2063, DOI 10.1007/s11042-012-1325-4
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409106
   Sheikh H. R., IMAGE VIDEO QUALITY
   Srinivasan U, 2005, MULTIMED TOOLS APPL, V27, P105, DOI 10.1007/s11042-005-2716-6
   Stockman George, 2001, Computer Vision
   Suzuki J, 2000, MULTIMED TOOLS APPL, V12, P7, DOI 10.1023/A:1009631927516
   Tam WS, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3358372
   Tian YS, 2012, MULTIMED TOOLS APPL, V60, P519, DOI 10.1007/s11042-011-0821-2
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wittman T., 2005, Mathematical techniques for image interpolation
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
NR 33
TC 11
Z9 16
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 8961
EP 8977
DI 10.1007/s11042-013-1570-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600019
DA 2024-07-18
ER

PT J
AU Bellini, P
   Nesi, P
   Serena, M
AF Bellini, Pierfrancesco
   Nesi, Paolo
   Serena, Marco
TI MyStoryPlayer: experiencing multiple audiovisual content for education
   and training
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audiovisual relations; Educational tools; Annotation tool; Multi video
   synchronization
ID MEDIA SYNCHRONIZATION; MULTIMEDIA; MODEL
AB There are several education and training cases where multi-camera view is a traditional way to work: performing arts and news, medical surgical actions, sport actions, instruments playing, speech training, etc. In most cases, users need to interact with multi camera and multi audiovisual to create among audiovisual segments their own relations and annotations with the purpose of: comparing actions, gesture and posture; explaining actions; providing alternatives, etc. Most of the present solutions are based on custom players and/or specific applications which force to create custom streams from server side, thus leading to restrictions on the user activity as to establishing dynamically additional relations. Web based solutions would be more appreciated and are complex to be realized for the problems related to the video desynchronization. In this paper, MyStoryPlayer/ECLAP solution is presented. The major contributions to the state of the art are related to: (i) the semantic model to formalize the relationships and play among audiovisual determining synchronizations, (ii) the model and modality to save and share user experiences in navigating among lessons including several related and connected audiovisual, (iii) the design and development of algorithm to shorten the production of relationships among media, (iv) the design and development of the whole system including its user interaction model, and (v) the solution and algorithm to keep the desynchronizations limited among media in the event of low network bandwidth. The proposed solution has been developed for and it is in use within ECLAP (European Collected Library of Performing Arts) for accessing and commenting performing arts training content. The paper also reports validation results about performance assessment and tuning, and about the usage of tools on ECLAP services. In ECLAP, users may navigate in the audiovisual relationships, thus creating and sharing experience paths. The resulting solution includes a uniform semantic model, a corresponding semantic database for the knowledge, a distribution server for semantic knowledge and media, and the MyStoryPlayer Client for web applications.
C1 [Bellini, Pierfrancesco; Nesi, Paolo; Serena, Marco] Univ Florence, Dept Informat Engn, Distributed Syst & Internet Technol Lab, I-50139 Florence, Italy.
C3 University of Florence
RP Nesi, P (corresponding author), Univ Florence, Dept Informat Engn, Distributed Syst & Internet Technol Lab, Via S Marta 3, I-50139 Florence, Italy.
EM paolo.nesi@unifi.it
RI Bellini, Pierfrancesco/D-5923-2015
OI Bellini, Pierfrancesco/0000-0002-8167-1003; nesi,
   paolo/0000-0003-1044-3107
FU European Commission [250481, CIP-ICT-PSP.2009.2.2]
FX The authors would like to express their thanks to Dario Fo, Franca Rame,
   Mariateresa Pizza of CTFR; Ferruccio Marotti, Raffaella Santucci of CTA
   UNIROMA, for their materials and support in tuning the solution with
   early test cases and trials. Sincere thanks to all the partners involved
   in ECLAP, and to the European Commission for funding ECLAP in the Theme
   CIP-ICT-PSP.2009.2.2, Grant Agreement No. 250481.
CR [Anonymous], P 7 IEEE INT S MULT
   [Anonymous], 2009, ITU T REC H 761 NEST
   [Anonymous], 2001, P WWW10 INT C HONG K
   AXMEDIS, FRAM TOOLS SPEC
   Bellini P, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P577, DOI 10.1109/ICME.2006.262474
   Bellini P., 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P210, DOI 10.1109/ISM.2011.41
   Bellini P, 2009, J SYST SOFTWARE, V82, P183, DOI 10.1016/j.jss.2008.06.041
   Bellini P., 2012, P KDIR 2012 PART IC3
   Bellini P., 2013, P ECLAP 2013 C 2 INT
   Bellini P, 2011, P 17 INT C DISTR MUL
   Bellini P, 2007, 13 INT C DISTR MULT
   Bellini P, 2011, INT J SOFTW ENG KNOW, V21, P3, DOI 10.1142/S0218194011005141
   Blakowski G, 1996, IEEE J SEL AREA COMM, V14, P5, DOI 10.1109/49.481691
   Boll S, 2001, IEEE T KNOWL DATA EN, V13, P361, DOI 10.1109/69.929895
   Boronat F, 2009, INFORM SYST, V34, P108, DOI 10.1016/j.is.2008.05.001
   Broekstra J, 2002, 1 INT SEM WEB C ISWC
   Bulterman DCA, 2009, SMIL3 0 INTERACTIVE
   Bulterman DCA, 2005, ACM T MULTIM COMPUT, V1, P89, DOI 10.1145/1047936.1047943
   Burnett IS, 2005, IEEE T MULTIMEDIA, V7, P400, DOI 10.1109/TMM.2005.846789
   Chilamkurti N, 2010, MULTIMED TOOLS APPL, V47, P189, DOI 10.1007/s11042-009-0413-6
   Clarke. E. M., 1982, LOGICS OF PROGRAMS, P52, DOI [10 . 1007 / BFb0025774, DOI 10.1007/BFB0025774]
   Dakss J, 1998, P SPIE MULTIMED SYST, V3528
   EDM Europena, 2010, TECHNICAL REPORT
   Gaggi O, 2011, P INT C DISTR MULT S, P114
   GAO B., 2011, P NOSSDAV, P105, DOI DOI 10.1145/1989240.1989266
   Hausenblas M, 2008, MULTIMEDIA SYST, V14, P405, DOI 10.1007/s00530-008-0131-3
   Klamma R., 2006, J UNIVERSAL KNOWLEDG, V1, P174
   Koivunen M, 2003, P KCAP 2003
   Layaïda N, 2002, MULTIMED TOOLS APPL, V18, P213, DOI 10.1023/A:1019944800320
   Lee I, 2010, MULTIMED TOOLS APPL, V47, P207, DOI 10.1007/s11042-009-0414-5
   Lombardo V, 2012, MULTIMED TOOLS APPL, V59, P407, DOI 10.1007/s11042-011-0813-2
   Mayer-Patel K, 2007, IEEE MULTIMEDIA, V14, P68, DOI 10.1109/MMUL.2007.63
   Meixner B., 2012, Proceedings of the 2012 ACM symposium on Document engineering, P49
   Meixner B, 2012, MULTIMEDIA TOOLS APP
   Neuschmied H, 2007, MPEG 7 VIDEO ANNOTAT, P5
   Pereira F., 2002, IMSC Press multimedia series
   RANGAN PV, 1995, COMPUT NETWORKS ISDN, V27, P549, DOI 10.1016/0169-7552(93)E0112-R
   Schroeter R, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P346, DOI 10.1109/MULMM.2004.1265006
   Schroeter R, 2003, P KNOWL MARK SEM ANN
   SCORM, 2003, ADV DISTR LEARN SHAR
   Shen EYT, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P809
   Shipman F, 2008, ACM T MULTIM COMPUT, V5, DOI 10.1145/1413862.1413868
   Smith JR, 2000, P SPIE PHOT E INT MU
   SPARQL, QUER LANG RDF
   Steves MP, 2000, P INT C SYST SCI SEP
   Tsai MF, 2010, MULTIMED TOOLS APPL, V47, P49, DOI 10.1007/s11042-009-0406-5
   Ursu Marian F, 2008, ACM T MULTIM COMPUT, V4
NR 47
TC 4
Z9 4
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 8219
EP 8259
DI 10.1007/s11042-014-2052-9
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200036
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Dahmane, M
   Cossette, S
   Meunier, J
AF Dahmane, Mohamed
   Cossette, Sylvie
   Meunier, Jean
TI Conditional Gabor phase-based disparity estimation applied to facial
   tracking for person-specific facial action recognition: a preliminary
   study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gabor wavelets; Feature extraction; Tracking; Facial expression
ID FACE RECOGNITION; WAVELETS; EXPRESSIONS
AB Within the affective computing research field, researchers are still facing a big challenge to establish automated systems to recognize human emotions from video sequences. Performances are quite dependent on facial feature localization and tracking. In this paper, we present a method based on a coarse-to-fine paradigm to characterize a set of facial fiducial points using a bank of Gabor filters. When the first face image is captured, the coarsest level is used to estimate a rough position for each facial feature. Afterward, a coarse-to-fine displacement refinement on an image pyramid is performed. The positions are then tracked over the subsequent frames using a modification of a fast Gabor-phase based technique. This includes a redefinition of the confidence measure and introduces an iterative conditional disparity estimation procedure. We used the proposed tracking process to implement a personalized feature-based facial action recognition framework, motivated by the fact that the same facial expression may vary differently across humans. Experimental results show that the facial feature points can be localized with high accuracy and tracked with sufficient precision leading to a better facial action recognition performance.
C1 [Dahmane, Mohamed; Meunier, Jean] Univ Montreal, Dept Comp & Operat Res, Montreal, PQ H3C 3J7, Canada.
   [Cossette, Sylvie] Fac Nursing, Montreal, PQ H3T 1A8, Canada.
C3 Universite de Montreal
RP Dahmane, M (corresponding author), Univ Montreal, Dept Comp & Operat Res, Pavillon Andre Aisenstadt,CP 6128 Succ Ctr Ville, Montreal, PQ H3C 3J7, Canada.
EM dahmanem@iro.umontreal.ca; sylvie.cossette.inf@umontreal.ca;
   meunier@iro.umontreal.ca
RI Cossette, Sylvie/AAV-3330-2021
FU Natural Sciences and Engineering Research Council of Canada (NSERC)
FX This work was supported by the Natural Sciences and Engineering Research
   Council of Canada (NSERC).
CR [Anonymous], P INT C IM PROC
   [Anonymous], 2014, VISAPP
   Bashyal S, 2008, ENG APPL ARTIF INTEL, V21, P1056, DOI 10.1016/j.engappai.2007.11.010
   Chuan-Yu Chang, 2009, 2009 Fourth International Conference on Innovative Computing, Information and Control (ICICIC 2009), P1164, DOI 10.1109/ICICIC.2009.294
   Cohn JF, 1999, PSYCHOPHYSIOLOGY, V36, P35, DOI 10.1017/S0048577299971184
   Cohn JF, 2001, P IEEE INT C MULT IN, P491
   Cottrell G.W., 2003, Computational, Geometric, and Process Perspectives on Facial Cognition: Contexts and Challenges
   Dahmane M, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P427
   Dahmane M, 2011, LECT NOTES COMPUT SC, V6754, P233, DOI 10.1007/978-3-642-21596-4_24
   Dantone M, 2012, PROC CVPR IEEE, P2578, DOI 10.1109/CVPR.2012.6247976
   Fasel B, 2002, INT C PATT RECOG, P40, DOI 10.1109/ICPR.2002.1048231
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Flaton K. A., 1989, IJCNN: International Joint Conference on Neural Networks (Cat. No.89CH2765-6), P313, DOI 10.1109/IJCNN.1989.118602
   FLEET DJ, 1993, IEEE T PATTERN ANAL, V15, P1253, DOI 10.1109/34.250844
   Hammal Z, 2007, INT J APPROX REASON, V46, P542, DOI 10.1016/j.ijar.2007.02.003
   Hong H, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P354, DOI 10.1109/AFGR.1998.670974
   Hu YX, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P651
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Kawulok M, 2012, IET IMAGE PROCESS, V6, P95, DOI 10.1049/iet-ipr.2010.0495
   Kim DJ, 2008, IEEE T FUZZY SYST, V16, P874, DOI 10.1109/TFUZZ.2008.924344
   Koelstra S, 2010, IEEE T PATTERN ANAL, V32, P1940, DOI 10.1109/TPAMI.2010.50
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   Liu CJ, 2003, IEEE T NEURAL NETWOR, V14, P919, DOI 10.1109/TNN.2003.813829
   Lucey S., 2007, FACE RECOGNITION BOO
   Maurer T, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P176, DOI 10.1109/AFGR.1996.557261
   McKenna SJ, 1997, LECT NOTES COMPUT SC, V1206, P35, DOI 10.1007/BFb0015977
   Michal U, 2012, DETECTOR FACIAL LAND, P547
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Pantic M., 2007, FACE RECOGNITION, P377
   Schuller B, 2011, LCNS
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shen LL, 2006, PATTERN ANAL APPL, V9, P273, DOI 10.1007/s10044-006-0033-y
   THEIMER WM, 1994, CVGIP-IMAG UNDERSTAN, V60, P343, DOI 10.1006/ciun.1994.1061
   Tian YL, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P229, DOI 10.1109/AFGR.2002.1004159
   Valstar M., 2006, COMP VIS PATT REC WO, P149
   Vezzetti E, 2012, MULTIMED TOOLS APPL
   Vezzetti E, 2012, COMPUT METH PROG BIO, V108, P1078, DOI 10.1016/j.cmpb.2012.07.008
   Wang J., 2006, P IEEE C COMPUTER VI, P1399
   Whitehill J, 2009, IEEE T PATTERN ANAL, V31, P2106, DOI 10.1109/TPAMI.2009.42
   Wiskott L, 1999, INT SER COMPUTAT INT, P355
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Young IT, 2002, IEEE T SIGNAL PROCES, V50, P2798, DOI 10.1109/TSP.2002.804095
   Zafeiriou S, 2008, IEEE T MULTIMEDIA, V10, P1528, DOI 10.1109/TMM.2008.2007292
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhao GY, 2009, PATTERN RECOGN LETT, V30, P1117, DOI 10.1016/j.patrec.2009.03.018
   Zhu ZW, 2006, INT C PATT RECOG, P1092
NR 46
TC 1
Z9 3
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 7111
EP 7130
DI 10.1007/s11042-014-1954-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800024
DA 2024-07-18
ER

PT J
AU Feng, H
   Gan, LX
   Ling, HF
   Zou, FH
   Lu, ZD
AF Feng, Hui
   Gan, Langxiong
   Ling, Hefei
   Zou, Fuhao
   Lu, Zhengding
TI A generic collusion attack optimization strategy for traditional
   spread-spectrum and quantization index modulation fingerprinting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital fingerprinting; Collusion attack; Optimization; Spread-spectrum;
   Quantization index modulation
ID DIGITAL WATERMARKING; MULTIMEDIA
AB Collusion attack is known to be a cost-effective attack against digital fingerprinting. Under the constraint that the fingerprint embedding algorithm and the host signal are unavailable to the adversaries, it is not very easy to perform efficient collusion attack. To solve this problem, we propose a generic collusion attack optimization (GCAO) strategy for traditional spread-spectrum (SS) and quantization index modulation (QIM) fingerprinting. First, we analyze the differential signal of two fingerprinted copies of the same content generated by popular fingerprint embedding algorithms, including both traditional SS-based embedder and QIM-based embedder. Based on the analysis of the differential signal, we construct a fingerprint forensic detector that identifies which embedder is applied and what the embedding parameters are adopted. Then, we improve the earlier proposed SANO collusion attack. Two components outlined above constitute a generic collusion attack optimization strategy. The simulation results show that the proposed forensic detector provides trustworthy performance: the detector can correctly identify the fingerprint embedding algorithm, and the probabilities of estimating the fingerprint length and position are higher than 86 % and 87 % for SS-based embedding and 84 % and 80 % for QIM-based embedding, respectively. The further experimental results illustrate that the proposed GCAO attack provides a better tradeoff between the probability of being undetected and the quality of the attacked copy.
C1 [Feng, Hui] Wuhan Univ Technol, Sch Transportat, Key Lab High Performance Ship Technol, Minist Educ, Wuhan 430070, Hubei, Peoples R China.
   [Gan, Langxiong] Wuhan Univ Technol, Sch Nav, Hubei Key Lab Inland Shipping Technol, Wuhan 430070, Hubei, Peoples R China.
   [Ling, Hefei; Zou, Fuhao; Lu, Zhengding] Huazhong Univ Sci & Technol, Coll Comp Sci, Wuhan 430074, Hubei, Peoples R China.
C3 Wuhan University of Technology; Wuhan University of Technology; Huazhong
   University of Science & Technology
RP Gan, LX (corresponding author), Wuhan Univ Technol, Sch Nav, Hubei Key Lab Inland Shipping Technol, Wuhan 430070, Hubei, Peoples R China.
EM wuyun8210@163.com; glx701227@163.com; lhefei@hotmail.com;
   fuhao_zou@hust.edu.cn; luzd@hust.edu.cn
RI feng, hui/I-8659-2018
OI feng, hui/0000-0001-6696-3094
FU NSF of China [61301279]; Fundamental Research Funds for the Central
   Universities [WUT:2013-IV-068]
FX The authors appreciate the anonymous reviewers and the Associate Editor.
   This work is supported by NSF of China Grants 61301279, the Fundamental
   Research Funds for the Central Universities(WUT:2013-IV-068).
CR [Anonymous], 1996, 96045 NEC RES I
   [Anonymous], P ACM INT C MULT MM
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P755, DOI 10.1109/83.918568
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1522, DOI 10.1109/83.862630
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen B, 1999, INT CONF ACOUST SPEE, P2061, DOI 10.1109/ICASSP.1999.758336
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Eggers JJ, 2001, SIGNAL PROCESS, V81, P239, DOI 10.1016/S0165-1684(00)00205-X
   Feng H, 2015, SECUR COMMUN NETW, V8, P2624, DOI 10.1002/sec.503
   Feng H, 2013, APPL SOFT COMPUT, V13, P3482, DOI 10.1016/j.asoc.2013.04.008
   Feng H, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2344436.2344442
   He S, 2005, LECT NOTES COMPUT SC, V3710, P84
   He S, 2006, IEEE T INF FOREN SEC, V1, P231, DOI 10.1109/TIFS.2006.873597
   Hsieh MS, 2001, IEEE T IND ELECTRON, V48, P875, DOI 10.1109/41.954550
   Kirovski D, 2005, INT CONF ACOUST SPEE, P1037
   Kiyavash N, 2006, 2006 40TH ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS, VOLS 1-4, P1170, DOI 10.1109/CISS.2006.286642
   Kiyavash N, 2009, IEEE T INF FOREN SEC, V4, P293, DOI 10.1109/TIFS.2009.2026462
   Kuribayashi M, 2010, IEEE T INF FOREN SEC, V5, P670, DOI 10.1109/TIFS.2010.2082535
   Li Q, 2007, IEEE T INF FOREN SEC, V2, P127, DOI 10.1109/TIFS.2007.897266
   Ling HF, 2011, LECT NOTES COMPUT SC, V6526, P224, DOI 10.1007/978-3-642-18405-5_19
   Qi XJ, 2008, IEEE IMAGE PROC, P421, DOI 10.1109/ICIP.2008.4711781
   Robertson MA, 2005, IEEE T CIRC SYST VID, V15, P27, DOI 10.1109/TCSVT.2004.839995
   SCHUCHMAN L, 1964, IEEE T COMMUN TECHN, VCO12, P162, DOI 10.1109/TCOM.1964.1088973
   Swaminathan A, 2006, P SOC PHOTO-OPT INS, V6072, P698
   Trappe W, 2003, IEEE T SIGNAL PROCES, V51, P1069, DOI 10.1109/TSP.2003.809378
   USC-SIPI, 2012, USC SIPI IMAGE DATAB
   Varna AL, 2009, IEEE T INF FOREN SEC, V4, P330, DOI 10.1109/TIFS.2009.2025860
   Wang ZJ, 2005, IEEE T IMAGE PROCESS, V14, P804, DOI 10.1109/TIP.2005.847284
   Wang ZJ, EURASIP J APPL SIGNA, V14, P2
   Wei ZH, 1998, IEEE T CONSUM ELECTR, V44, P1267, DOI 10.1109/30.735826
   Zhao HV, 2005, IEEE T IMAGE PROCESS, V14, P646, DOI 10.1109/TIP.2005.846035
NR 33
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 6967
EP 6988
DI 10.1007/s11042-014-1948-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800018
DA 2024-07-18
ER

PT J
AU Louafi, H
   Coulombe, S
   Chandra, U
AF Louafi, Habib
   Coulombe, Stephane
   Chandra, Umesh
TI Robust QoE-aware prediction-based dynamic content adaptation framework
   applied to slides documents in mobile Web conferencing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ubiquitous computing; Context-awareness; Mobile Web conferencing;
   Dynamic content adaptation; QoE; JPEG; XHTML
ID IMAGE QUALITY ASSESSMENT; SERVICES
AB In mobile Web conferencing, enterprise documents are generally adapted into JPEG-based Web pages to be visualized on mobile devices. Dynamically identifying the optimal adapted content is very challenging, as a compromise between high visual quality and small delivery time must be made. In this paper, we propose a robust prediction-based dynamic content adaptation framework for JPEG and XHTML formats that computes near-optimal transcoding parameters dynamically with very few computations. The proposed framework is comprised of five methods making different compromises between computational complexity and accuracy. For JPEG, the average deviation from optimality (exhaustive method) is 6 % and 3 % respectively for two of the proposed methods. For XHTML, the average deviation from optimality is 3 % and 1 % respectively using the same two methods. Moreover, the methods reached optimality 30 % and 59 % of the time on the tested documents for JPEG and XHTML respectively, which makes the proposed framework very appealing.
C1 [Louafi, Habib] Univ Quebec, Ecole Technol Super, Synchromedia Lab Multimedia Commun Telepresence, Montreal, PQ H3C 3P8, Canada.
   [Coulombe, Stephane] Univ Quebec, Ecole Technol Super, Dept Software & IT Engn, Montreal, PQ H3C 3P8, Canada.
   [Chandra, Umesh] Nokia Res Ctr, Palo Alto, CA USA.
C3 University of Quebec; Ecole de Technologie Superieure - Canada;
   University of Quebec Montreal; University of Quebec; University of
   Quebec Montreal; Ecole de Technologie Superieure - Canada; Nokia
   Corporation; Nokia Bell Labs
RP Louafi, H (corresponding author), Univ Quebec, Ecole Technol Super, Synchromedia Lab Multimedia Commun Telepresence, Montreal, PQ H3C 3P8, Canada.
EM habib.louafi.1@ens.etsmtl.ca; stephane.coulombe@etsmtl.ca;
   umesh.1.chandra@nokia.com
RI Coulombe, Stephane/G-3528-2019; Louafi, Habib/HNS-5825-2023
OI Coulombe, Stephane/0000-0003-4495-3906; 
CR Adobe Systems Incorporated, AD CONN WEB CONF ENT, P1012
   [Anonymous], ZOH MOB
   Chandra S, 1999, USENIX ASSOCIATION PROCEEDINGS OF THE 2ND USENIX SYMPOSIUM ON INTERNET TECHNOLOGIES AND SYSTEMS (USITS'99), P81
   Coulombe S, 2004, IEEE COMMUN MAG, V42, P120, DOI 10.1109/MCOM.2004.1316543
   Coulombe S, 2010, IEEE T IMAGE PROCESS, V19, P712, DOI 10.1109/TIP.2009.2036716
   Coulombe S, 2009, CIMSVP 2009: IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE FOR MULTIMEDIA SIGNAL AND VISION PROCESSING, P68
   Dieckmann A, 2009, JUDGM DECIS MAK, V4, P200
   Google Inc, 2011, ACC GOOGL DOCS MOB B
   Han R, 1998, IEEE PERS COMMUN, V5, P8, DOI 10.1109/98.736473
   Holzinger A., 2012, P 3 INT C OPT COMM S, P205
   Hwang YH, 2003, IEEE INTERNET COMPUT, V7, P14, DOI 10.1109/MIC.2003.1232513
   Jan RH, 2006, COMPUT NETW, V50, P953, DOI 10.1016/j.comnet.2005.06.006
   Kitayama F., 1999, Proceedings Sixth Asia Pacific Software Engineering Conference (ASPEC'99) (Cat. No.PR00509), P72, DOI 10.1109/APSEC.1999.809586
   Kleinberger Thomas, 2008, Universal Access in the Information Society, V7, P223, DOI 10.1007/s10209-008-0122-3
   Kuipers F, 2010, LECT NOTES COMPUT SC, V6074, P216
   Lee L., 2009, A Comparison of Compensatory and Non-Compensatory Decision Making Strategies in IT Project Portfolio Management
   Li D, 2008, INT S COLLAB TECHNOL, P295, DOI 10.1109/CTS.2008.4543943
   Louafi H, 2013, IEEE T MOBILE COMPUT, V12, P2024, DOI 10.1109/TMC.2012.173
   Louafi H, 2013, INT CON ADV INFO NET, P724, DOI 10.1109/AINA.2013.12
   Lum WaiYip., 2002, MOBICOM 02, P239
   Lum WY, 2005, 19TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1, PROCEEDINGS, P507
   Lum WY, 2003, IEEE T SOFTWARE ENG, V29, P1100, DOI 10.1109/TSE.2003.1265524
   Mohan R, 1999, IEEE T MULTIMEDIA, V1, P104, DOI 10.1109/6046.748175
   Nah FFH, 2004, BEHAV INFORM TECHNOL, V23, P153, DOI 10.1080/01449290410001669914
   Noble BD, 1995, 2 USENIX S MOB LOC I, V8, P57
   Pigeon S, 2008, 2008 24TH BIENNIAL SYMPOSIUM ON COMMUNICATIONS, P378, DOI 10.1109/BSC.2008.4563280
   PresenterNet, 2009, INT WEB PRES
   Ryan G, 2006, INFORM SYST J, V16, P181, DOI 10.1111/j.1365-2575.2006.00214.x
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Svoboda P., 2007, IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks, 2007, P1
   The MathWorks, 2012, Z SHAP BUILT IN MEMB
   USC-SIPI, 2012, USC SIPI IMAGE DATAB
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang Y, 2006, LECT NOTES COMPUT SC, V4138, P69
NR 34
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7883
EP 7920
DI 10.1007/s11042-014-2030-2
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200022
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Vodlan, T
   Tkalcic, M
   Kosir, A
AF Vodlan, Tomaz
   Tkalcic, Marko
   Kosir, Andrej
TI The impact of hesitation, a social signal, on a user's quality of
   experience in multimedia content retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social signals; Hesitation; Human-computer interaction; Video-on-demand;
   Recommender system
ID EMOTIONS; 5-POINT
AB The social signal (SS) of hesitation is commonly manifested through a multiplicity of nonverbal behavioural cues when a user is faced with a variety of decision choices. The aim of this study is to show that the utilization of the SS of hesitation in a conversational recommender system (RS) can improve the user quality of experience (QoE) when interacting with a video-on-demand system. An appropriate experimental design was modelled to detect the impact of the SS. The experimental scenario was a manual video-on-demand system with a conversational RS where the user selected one video clip among several presented on the screen. The system adjusted the list of the video items to be recommended according to the extracted SS class {hesitation, no hesitation}. To detect if the user was hesitating, we used hand movements, eye behaviour and time between two selections. Two user groups were tested to allow realistic estimation of the impact of the SS. In the user test group, the SS of hesitation was considered, while in the control group it was not. The evaluation of impact of the SS on QoE was based on pre- and post-interaction questionnaires. Our results showed a significant difference in user satisfaction with the system between those two groups, indicating that the use of SS of hesitation in conversational RS improves the QoE when the user interacts with a video-on-demand system.
C1 [Vodlan, Tomaz] Agila Doo, Ljubljana 1000, Slovenia.
   [Tkalcic, Marko] Johannes Kepler Univ Linz, A-4040 Linz, Austria.
   [Kosir, Andrej] Univ Ljubljana, Fac Elect Engn, Ljubljana, Slovenia.
C3 Johannes Kepler University Linz; University of Ljubljana
RP Vodlan, T (corresponding author), Agila Doo, Tehnol Pk 19, Ljubljana 1000, Slovenia.
EM tomaz.vodlan@gmail.com; marko.tkalcic@jku.at;
   andrej.kosir@ldos.fe.uni-lj.si
RI Tkalcic, Marko/L-9767-2016
OI Tkalcic, Marko/0000-0002-0831-5512; Kosir, Andrej/0000-0001-6938-221X
FU European Union, European Social Fund; EU Seventh Framework Programme
   through the project PHENICX [601166]
FX Operation partially financed by the European Union, European Social
   Fund. This work was supported by the EU Seventh Framework Programme FP7
   / 2007-2013 through the project PHENICX (grant no. 601166).
CR Aggarwall JK, 2011, ACM COMPUT SURV, V43, DOI [10.1145/1922649.1922649.1922653, DOI 10.1145/1922649.1922649.1922653]
   [Anonymous], 2010, P ACMMM, DOI DOI 10.1145/1873951.1874102
   [Anonymous], 2006, 100 STAT TESTS, DOI DOI 10.4135/9781849208499
   [Anonymous], 2009, DESIGN ANAL EXPT
   [Anonymous], MAKING DECISIONS PRI
   Bewick V, 2005, CRIT CARE, V9, P112, DOI 10.1186/cc3045
   Bousmalis K., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P746, DOI 10.1109/FG.2011.5771341
   Branco N, 2011, P INT C HUM FACT COM, P2299
   Brooke John., 1996, Usability evaluation in industry, V189, P4, DOI DOI 10.1201/9781498710411
   Bruzgiene R, 2013, ELEKTRON ELEKTROTECH, V19, P110, DOI 10.5755/j01.eee.19.7.5178
   COMMIT, 2011, SENS NAT INT
   Cronbach LJ, 1951, PSYCHOMETRIKA, V16, P297
   Dawes J, 2008, INT J MARKET RES, V50, P61, DOI 10.1177/147078530805000106
   Diefendorff JM, 2006, PERS PSYCHOL, V59, P365, DOI 10.1111/j.1744-6570.2006.00641.x
   Dim E, 2010, IUI 2010, P309
   Ferreira JoaoPedro., 2012, Proceedings of the 2012 ACM annual conference extended abstracts on Human Factors in Computing Systems Extended Abstracts - CHI EA '12. CHI EA '12, P171
   Field A., 2009, Discovering statistics with SPSS, V3rd
   Finstad K, 2010, J USABILITY STUD, V5, P104
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Gino F, 2008, J APPL PSYCHOL, V93, P1165, DOI 10.1037/0021-9010.93.5.1165
   Hakansson M, 2012, HUMAN COMPUTER INTER
   Hollnagel E, 2005, JOINT COGNITIVE SYST, P219
   Hu AL, 2001, IEEE INFOCOM SER, P508, DOI 10.1109/INFCOM.2001.916754
   IBM Corporation, 2021, IBM SPSS statistics for windows.Version 21.0
   IDRE-UCLA, 2012, WHAT IS DUMM COD
   International Telecommunication Union, 2007, 4 FG IPTV M BLED SLO
   Jokinen K, 2010, CULTURE COMPUTING CO
   Justin T, 2012, LECT NOTES COMPUT SC, V7499, P543, DOI 10.1007/978-3-642-32790-2_66
   Karam Maria, 2005, A Taxonomy of Gestures in Human Computer Interactions
   Knijnenburg Bart P., 2012, Experimental Materials Used in the Study on Inspectability and Control in Social Recommender Systems
   Kooij R, 2006, PROCEEDINGS OF THE FIFTH IASTED INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEMS AND NETWORKS, P155
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Kosir A, 2011, ELEKTROTEH VESTN, V78, P270
   Lerner JS, 2004, PSYCHOL SCI, V15, P337, DOI 10.1111/j.0956-7976.2004.00679.x
   Leung R, 2011, BEHAV INFORM TECHNOL, V30, P629, DOI 10.1080/01449290903171308
   Lew M, 2007, LECT NOTES COMPUT SC, V4796, P1
   Moon A., 2011, 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2011), P1994, DOI 10.1109/IROS.2011.6048228
   Moon A., 2010, Proceedings of the International Conference on Robotics and Automation (ICRA), P11
   Mu X, 2010, ADV COMPUTATION INTE
   Nicholas D, 2005, AGE IMPACTS WEBSITE
   Nielsen J, 1994, RESPONSE TIMES 3 IMP
   Nunnally JC, 1967, PSYCOHMETRIC THEORY
   Odic A, 2013, INTERACT COMPUT, V25, P74, DOI 10.1093/iwc/iws003
   Pantic Maja, 2008, International Journal of Automomous and Adaptive Communications Systems, V1, P168, DOI 10.1504/IJAACS.2008.019799
   Pentland A, 2007, IEEE SIGNAL PROC MAG, V24, P108, DOI 10.1109/MSP.2007.4286569
   Ranne R, 2008, SYSTEMS INTELLIGENCE, P141
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Sauro J, 2012, ASKING RIGHT USER EX
   Seow SC., 2008, DESIGNING ENG TIME P
   Song Y, 2012, ACM T INTERACT INTEL, V2, DOI 10.1145/2133366.2133371
   Sun X, 2012, P IEEE INT C COMP VI, P40
   Tkalcic M, 2013, IEEE T MULTIMEDIA, V15, P391, DOI 10.1109/TMM.2012.2229970
   Vinciarelli A., 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P42, DOI 10.1109/CVPR.2009.5204290
   Vinciarelli A., 2009, 2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops, P1
   Vinciarelli A, 2009, IMAGE VISION COMPUT, V27, P1743, DOI 10.1016/j.imavis.2008.11.007
   Vinciarelli A, 2012, IEEE T AFFECT COMPUT, V3, P69, DOI 10.1109/T-AFFC.2011.27
NR 56
TC 7
Z9 8
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 6871
EP 6896
DI 10.1007/s11042-014-1933-2
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800014
DA 2024-07-18
ER

PT J
AU Eun, SJ
   Kim, H
   Park, JW
   Whangbo, TK
AF Eun, Sung-Jong
   Kim, Hyeonjin
   Park, Jung-Wook
   Whangbo, Taeg-Keun
TI Effective object segmentation based on physical theory in an MR image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MR image; Object segmentation; R2 map; SWI; 3D region growing
ID BRAIN; CT; VENOGRAPHY; EXTRACTION; MAXIMUM
AB Object recognition is usually processed based on region segmentation algorithm. Region segmentation in the IT field is carried out by computerized processing of various input information such as brightness, shape, and pattern analysis. If the information mentioned does not make sense, however, many limitations could occur with region segmentation during computer processing. Therefore, this paper suggests effective object segmentation method based on R2 information within the magnetic resonance (MR) theory. In this study, the experiment had been conducted using images including the liver region and by setting up feature points of R2 map as seed points for region growing to enable region segmentation even when the border line was not clear. As a result, an average area difference of 7.5 %, which was higher than the accuracy of conventional region segmentation algorithm, was obtained.
C1 [Eun, Sung-Jong; Whangbo, Taeg-Keun] Gachon Univ, Dept Comp Sci, Songnam, Gyunggi Do, South Korea.
   [Kim, Hyeonjin] Seoul Natl Univ, Dept Med Sci, Seoul, South Korea.
   [Park, Jung-Wook] Yonsei Univ, Dept Comp Sci, Seoul 120749, South Korea.
C3 Gachon University; Seoul National University (SNU); Yonsei University
RP Whangbo, TK (corresponding author), Gachon Univ, Dept Comp Sci, Songnam, Gyunggi Do, South Korea.
EM asclephios@hotmail.com; hyeonjinkim@snu.ac.kr; pjppp@cs.yonsei.ac.kr;
   tkwhangbo@gachon.ac.kr
RI Kim, Hyeonjin/M-3761-2019; Park, Jungwook/KLF-6334-2024
OI Park, Jungwook/0000-0002-1387-8969
FU MSIP (the Ministry of Science, ICT and Future Planning), Korea under the
   IT-CRSP (IT Convergence Research Support Program)
   [NIPA-2013-H0401-13-1001]; Ministry of Health and Wealth of the Republic
   of Korea [A080369]
FX This research was supported by MSIP (the Ministry of Science, ICT and
   Future Planning), Korea, under the IT-CRSP (IT Convergence Research
   Support Program) (NIPA-2013-H0401-13-1001), supervised by the NIPA
   (National IT Industry Promotion Agency); and by a grant from the Korea
   Healthcare Technology R&D Project of the Ministry of Health and Wealth
   of the Republic of Korea (A080369).
CR Baba N, 1996, J ELECTRON MICROSC, V45, P298, DOI 10.1093/oxfordjournals.jmicro.a023446
   Bhalla M, 1996, RADIOLOGY, V200, P341, DOI 10.1148/radiology.200.2.8685323
   Calhoun PS, 1999, RADIOGRAPHICS, V19, P745, DOI 10.1148/radiographics.19.3.g99ma14745
   Catmull E, 1974, inCom-puter Aided Geometric Design, P317, DOI [DOI 10.1016/B978-0-12-079050-0.50020-5, 10.1016/B978-0-12-079050-0.50020-5]
   Chande B, 1988, SIGNAL PROCESSING, V15
   DAMADIAN R, 1971, SCIENCE, V171, P1151, DOI 10.1126/science.171.3976.1151
   de Graaf RA, 2006, MAGN RESON MED, V56, P386, DOI 10.1002/mrm.20946
   Drebin R. A., 1988, Computer Graphics, V22, P65, DOI 10.1145/378456.378484
   Fernández-Seara MA, 2006, MAGN RESON MED, V55, P967, DOI 10.1002/mrm.20892
   GAVRILA D, 1998, IEEE INT C PATT REC
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   Haacke E. M., 1999, MAGNETIC RESONANCE I, P129
   Haacke EM, 2007, J MAGN RESON IMAGING, V26, P256, DOI 10.1002/jmri.22987
   Haacke EM, 1997, HUM BRAIN MAPP, V5, P341, DOI 10.1002/(SICI)1097-0193(1997)5:5<341::AID-HBM2>3.0.CO;2-3
   Hanrahan P., 1990, Computer Graphics, V24, P71, DOI 10.1145/99308.99323
   Hemachander S, 2007, PATTERN RECOGN LETT, V28, P119, DOI 10.1016/j.patrec.2006.06.005
   Hu J, 2008, J MAGN RESON IMAGING, V28, P300, DOI 10.1002/jmri.21435
   Kang CC, 2007, PATTERN RECOGN, V40, P609, DOI 10.1016/j.patcog.2006.03.016
   Kang DJ, 1999, PATTERN RECOGN LETT, V20, P1069, DOI 10.1016/S0167-8655(99)00127-0
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KAUFMAN A, 1991, INTRO VOLUME VISUALI
   Kingsley PB, 1999, CONCEPT MAGNETIC RES, V11, P29, DOI 10.1002/(SICI)1099-0534(1999)11:1<29::AID-CMR2>3.3.CO;2-D
   Koopmans PJ, 2008, MAGN RESON MATER PHY, V21, P149, DOI 10.1007/s10334-007-0101-3
   LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511
   LI W, 2004, P 5 WORLD C INT CONT, P15
   Muerle J. L, 1968, EXPT EVALUATION TECH
   Murphy Thomas M., 2003, INT EEE EBMS CNECI, P16
   Ng EYK, 2006, J MECH MED BIOL, V6, P123, DOI 10.1142/S021951940600190X
   Orguner U, 2007, 2007 IEEE/SP 14TH WORKSHOP ON STATISTICAL SIGNAL PROCESSING, VOLS 1 AND 2, P571, DOI 10.1109/SSP.2007.4301323
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pizer S. M., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P337, DOI 10.1109/VBC.1990.109340
   Reichenbach JR, 1997, RADIOLOGY, V204, P272, DOI 10.1148/radiology.204.1.9205259
   RemyJardin M, 1996, RADIOLOGY, V200, P333, DOI 10.1148/radiology.200.2.8685322
   Rose JL, 2007, IEEE IMAGE PROC, P53
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shrager RI, 1998, NMR BIOMED, V11, P297, DOI 10.1002/(SICI)1099-1492(199810)11:6<297::AID-NBM531>3.0.CO;2-A
   Storey P, 2007, J MAGN RESON IMAGING, V25, P540, DOI 10.1002/jmri.20816
   UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936
   WILLIAMS DJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P14, DOI 10.1016/1049-9660(92)90003-L
   Zabih R, 2004, PROC CVPR IEEE, P437
NR 40
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6273
EP 6286
DI 10.1007/s11042-014-2089-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700010
DA 2024-07-18
ER

PT J
AU Lee, W
   Kim, S
   Kang, S
   Kim, T
   Kim, H
AF Lee, Wonhyuk
   Kim, Seunghae
   Kang, Sunyoung
   Kim, TaeYeon
   Kim, Hyuncheol
TI A virtualized network model for wellness information technology research
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual network; Distributed cloud computing; Resource provisioning;
   Smart internet
AB The explosive growth of Internet traffic has led to a dramatic increase in demand for data transmission capacity, which has spurred much research activities in real-time logical network construction methods. High-speed services and bulk transmission are now available, and various next-generation converged services are undergoing change as a result of demand by various services. There is also a perceived need now for video-conferencing to exchange know-how between hospitals and medical schools over cloud network. It is now time to elaborate a new wellness service incorporating diverse options. In this paper, we will examine the secure transfer of wellness information over distributed cloud network, especially medical data, and how such information should be disseminated to a network model.
C1 [Lee, Wonhyuk; Kim, Seunghae] Korea Inst Sci Technol Informat, Daejon, South Korea.
   [Kang, Sunyoung] Korea Univ, Dept Phys Sci, Seoul, South Korea.
   [Kim, TaeYeon] Elect & Telecommun Res Inst, Daejon, South Korea.
   [Kim, Hyuncheol] Namseoul Univ, Dept Comp Sci, Cheonan, South Korea.
C3 Korea Institute of Science & Technology Information (KISTI); Korea
   University; Electronics & Telecommunications Research Institute - Korea
   (ETRI); Namseoul University
RP Kim, H (corresponding author), Namseoul Univ, Dept Comp Sci, Cheonan, South Korea.
EM livezone@kisti.re.kr; shkim@kisti.re.kr; 1010kang@hanmail.net;
   tykim@etri.re.kr; hckim@nsu.ac.kr
RI Kim, Seunghae/AAE-9934-2020
OI Kim, Seunghae/0000-0002-8403-7577
FU ICT R&D program of MSIP/IITP; Namseoul university
FX This work was supported by the ICT R&D program of MSIP/IITP. [Smart
   Networking Core Technology Development]. This work was also supported by
   Namseoul university. We would also like to thank the reviewers for their
   valuable comments, questions, and suggestions.
CR Guo BL, 2014, J LIGHTWAVE TECHNOL, V32, P483, DOI 10.1109/JLT.2013.2293193
   Hassan MM, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE (CSCI), VOL 2, P107, DOI 10.1109/CSCI.2014.103
   Jie H, 2010, IC BNMT
   Lee D, 2014, INT CONF ADV COMMUN, P141, DOI 10.1109/ICACT.2014.6778937
   Molnár S, 2014, INT CONF COMPUT NETW, P462, DOI 10.1109/ICCNC.2014.6785379
   Nygren E., 2010, SIGOPS OPER SYST REV, V44, P2, DOI [10.1145/1842733.1842736, DOI 10.1145/1842733.1842736]
   Shen HY, 2014, IEEE T PARALL DISTR, V25, P862, DOI 10.1109/TPDS.2013.106
   Sitaraman R. K., 2013, 2013 Fifth International Conference on Communication Systems and Networks (COMSNETS), DOI 10.1109/COMSNETS.2013.6465563
   Yu HL, 2013, INT SYM COMPUT INTEL, P261, DOI 10.1109/ISCID.2013.72
NR 9
TC 0
Z9 0
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6531
EP 6539
DI 10.1007/s11042-014-2244-3
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700029
DA 2024-07-18
ER

PT J
AU Zhu, LW
   Zhang, Y
   Wang, X
   Kwong, S
AF Zhu, Linwei
   Zhang, Yun
   Wang, Xu
   Kwong, Sam
TI View synthesis distortion elimination filter for depth video coding in
   3D video broadcasting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D video; View synthesis; Depth image based rendering; Depth video
   coding
ID 3-D VIDEO; RECONSTRUCTION FILTER; BIT ALLOCATION; MODEL
AB Depth image based rendering (DIBR), which can generate synthesized images according to the users' demand, is a key technique for achieving 3D television. However, view synthesis by DIBR technique is very sensitive to depth coding distortion. Because depth distortion will lead to geometrical rendering position errors, and seriously affect the quality of synthesized images. In this paper, we propose an in-loop filter to minimize view synthesis distortion at the cost of transmitting extra filter parameters as supplementary information. And an adaptive parameter determination scheme is presented for the proposed filter. Then a good trade-off between bit rate and view synthesis distortion has been achieved by considering the spatial-temporal correlations of 3D video sequence. The simulation results reveal that the proposed view synthesis distortion elimination method can significantly improve the rate-distortion performance, which achieves Bjontegaard Delta Peak Signal-to-Noise Ratio (BDPSNR) gain from 0.41 to 1.09 dB compared with the benchmark.
C1 [Zhu, Linwei; Zhang, Yun] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
   [Zhang, Yun; Wang, Xu; Kwong, Sam] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
   [Wang, Xu; Kwong, Sam] City Univ Hong Kong, Shenzhen Res Inst, Shenzhen, Peoples R China.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; City University of Hong Kong; City University of Hong Kong;
   Shenzhen Research Institute, City University of Hong Kong
RP Zhang, Y (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
EM yun.zhang@siat.ac.cn
RI Kwong, Sam/C-9319-2012; Zhang, Yun/V-7261-2019
OI Kwong, Sam/0000-0001-7484-7261; Zhang, Yun/0000-0001-9457-7801; ,
   linwei/0000-0002-9385-9054
FU Natural Science Foundation of China 61102088 and 61272289 [61102088,
   61272289]; Shenzhen Emerging Industries of the Strategic Basic Research
   Project [JCYJ20120617151719115]; Guangdong Nature Science Foundation
   [S2012010008457]
FX This work was supported in part by the Natural Science Foundation of
   China under Grants 61102088 and 61272289, Shenzhen Emerging Industries
   of the Strategic Basic Research Project under Grant
   JCYJ20120617151719115, and the Guangdong Nature Science Foundation under
   Grant S2012010008457.
CR [Anonymous], JTC1SC29WG11 ISOIEC
   Bjontegaard G., 2001, M33 ITUT VCEG
   Chen Y., 2009, ITUTJVTAE207
   Domanski M, 2009, ISO/IEC JTC1/SC29/WG11 MPEG/M17050
   Feldmann I, 2008, JTC1SC29WG11 SOIEC
   Hu SD, 2013, IEEE T IMAGE PROCESS, V22, P585, DOI 10.1109/TIP.2012.2219549
   Liu SJ, 2011, IEEE T BROADCAST, V57, P551, DOI 10.1109/TBC.2011.2120750
   NYA PN, 2011, IEEE T MULTIMED, V13, P453
   Oh KJ, 2011, IEEE T CIRC SYST VID, V21, P350, DOI 10.1109/TCSVT.2011.2116590
   Oh KJ, 2009, IEEE SIGNAL PROC LET, V16, P747, DOI 10.1109/LSP.2009.2024112
   Tanimoto M, 2012, P IEEE, V100, P905, DOI 10.1109/JPROC.2011.2182101
   Nguyen VA, 2013, IEEE T CIRC SYST VID, V23, P189, DOI 10.1109/TCSVT.2012.2203212
   Yuan H, 2012, IEEE T BROADCAST, V58, P558, DOI 10.1109/TBC.2012.2187612
   Yuan H, 2011, IEEE T CIRC SYST VID, V21, P485, DOI 10.1109/TCSVT.2011.2125610
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
   Zhang Y, 2013, IEEE T IMAGE PROCESS, V22, P3497, DOI 10.1109/TIP.2013.2265883
   Zhang Y, 2009, ETRI J, V31, P151, DOI 10.4218/etrij.09.0108.0350
   Zhao Y, 2011, IEEE T IMAGE PROCESS, V20, P2221, DOI 10.1109/TIP.2011.2118218
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 19
TC 4
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5935
EP 5954
DI 10.1007/s11042-014-1898-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100028
DA 2024-07-18
ER

PT J
AU Chen, Q
   Fang, B
   Yu, YM
   Tang, Y
AF Chen, Qiang
   Fang, Bin
   Yu, Yong-Mei
   Tang, Yan
TI 3D CAD model retrieval based on the combination of features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature combination; 3D CAD model retrieval; Depth buffer image; Ray
   extent; Class information; Normal angle area
AB To improve the retrieval performance of 3D CAD model, we propose three combined feature descriptor and a class information based feature descriptor. First, we propose a novel feature descriptor Normal Angle Area (NAA) based on the 3D models surface and normals, and then we combined NAA with D2 and Bounding Box feature to form a more powerful feature DBNAA. Second, we combine DBNAA with Depth buffer images (DE), Ray extent (RE) to form DBNAA_DERE descriptor, and combine DBNAA with PANORAMA to form DBNAA_PANORAMA descriptor. Finally, we utilize the class information of dataset and propose a method called DBNAA_CBR which use a novel method to fuse class information into retrieval process. Experimental results on ESB dataset show that the results of DBNAA is similar to light field descriptors (LF) but with lower computational cost, DBNAA_DERE is better than DESIRE, DBNAA_PANORAMA performed better than all other non class information based methods. Further experiments showed that when we set an appropriate parameter for DBNAA_CBR it performs better than CBR-ZFDR.
C1 [Chen, Qiang; Fang, Bin] Chongqing Univ, Sch Comp Sci, Chongqing 400030, Peoples R China.
   [Chen, Qiang; Yu, Yong-Mei; Tang, Yan] Southwest Univ, Coll Comp & Informat Sci, Chongqing 400715, Peoples R China.
C3 Chongqing University; Southwest University - China
RP Fang, B (corresponding author), Chongqing Univ, Sch Comp Sci, Chongqing 400030, Peoples R China.
EM chenq@swu.edu.cn; fb@cqu.edu.cn; xiao8yan@126.com; ytang@swu.edu.cn
FU National Key Technology Research and Development Program of the Ministry
   of Science and Technology of China [2012BAD35B08]; National Key
   Technology R&D Program of China [2012BAI06B01]; Major Program of
   National Natural Science Foundation of China [61190122]; Fundamental
   Research Funds for the Central Universities [XDJK2012C066]
FX This work has been supported by National Key Technology Research and
   Development Program of the Ministry of Science and Technology of China
   (2012BAD35B08), National Key Technology R&D Program of China (No.
   2012BAI06B01), Major Program of National Natural Science Foundation of
   China (No. 61190122), and the Fundamental Research Funds for the Central
   Universities (XDJK2012C066). We would also like to thank the anonymous
   reviewers for providing valuable suggestions to improve this paper, and
   we would like to thank LiBo, Zhangkai-xing, Wu Yun-tao and Wang
   Hong-shen for resources and suggestions.
CR Atmosukarto I, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P334, DOI 10.1109/MMMC.2005.39
   Boyer E., 2011, Proceedings of the 4th Eurographics Conference on 3D Object Retrieval, P71
   Bustos B, 2012, MULTIMED TOOLS APPL, V58, P81, DOI 10.1007/s11042-010-0689-6
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Jayanti S, 2006, COMPUT AIDED DESIGN, V38, P939, DOI 10.1016/j.cad.2006.06.007
   Kalyanaraman Y., 2005, PRETR20052 PRECISE P
   Kazhdan M., 2003, P EUR ACM SIGGRAPH S, V6, P156
   Kobayashi J, 2007, DATABASE ADAPTIVE DI
   Li B, 2013, MULTIMED TOOLS APPL, V62, P821, DOI 10.1007/s11042-011-0873-3
   Ohbuchi R, 2006, P WSCG, V79
   Ohbuchi R, 2005, INT J COMPUT APPL T, V23, P70, DOI 10.1504/IJCAT.2005.006466
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Papadakis P, 2008, EUR WORKSH 3D OBJ RE
   Papadakis P, 2010, INT J COMPUT VISION, V89, P177, DOI 10.1007/s11263-009-0281-6
   Paquet E, 2000, SIGNAL PROCESS-IMAGE, V16, P103, DOI 10.1016/S0923-5965(00)00020-5
   Qiang Chen, 2013, Advanced Materials Research, V765-767, P316, DOI 10.4028/www.scientific.net/AMR.765-767.316
   SHIH JL, 2009, MULTIMED TOOLS APPL, V43, P45, DOI DOI 10.1007/S11042-008-0256-6
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Ullman D.G., 1997, MECH DESIGN PROCESS
   Vranic DV, 2004, THESIS U LEIPZIG GEM
   Wahl E, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P474, DOI 10.1109/IM.2003.1240284
   Wu YH, 2013, CHIN J MECH ENG-EN, V26, P248, DOI 10.3901/CJME.2013.02.248
   Zaharescu A, 2009, PROC CVPR IEEE, P373, DOI 10.1109/CVPRW.2009.5206748
   Zhang C, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P935, DOI 10.1109/ICIP.2001.958278
   Zobel V., 2011, GEN HEAT KERNEL SIGN
NR 26
TC 12
Z9 13
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4907
EP 4925
DI 10.1007/s11042-013-1850-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400022
DA 2024-07-18
ER

PT J
AU Remolar, I
   Garcés, A
   Rebollo, C
   Chover, M
   Quirós, R
   Gumbau, J
AF Remolar, Inmaculada
   Garces, Alejandro
   Rebollo, Cristina
   Chover, Miguel
   Quiros, Ricardo
   Gumbau, Jesus
TI Developing a virtual trade fair using an agent-oriented approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-agent systems; Business environment; Virtual trade fairs; Virtual
   worlds
AB Online virtual trade fairs are becoming a popular way of establishing economic trade relationships nowadays. In the current context of the world economy, new ways of creating virtual environments where suppliers can show their products to potential customers are increasingly in demand. Some people can be found in this kind of scenario representing a role such as, for example, the administrator, the customers or the suppliers. The interaction between them is one of the most important characteristics of these commercial environments. Taking all these concepts into account, this article presents a 3D virtual trade fair that has been defined using an agent-oriented approach. This approach makes it possible to model, understand and implement the virtual economic environment, where interaction is the norm. Moreover, it makes it easy to add new components and meet new requirements in order to develop an open architecture that continuously changes and evolves. In this virtual trade fair, the chosen methodology has been Gaia, widely used for agent-oriented analysis and design of multi-agent systems.
C1 [Remolar, Inmaculada; Garces, Alejandro; Rebollo, Cristina; Chover, Miguel; Quiros, Ricardo; Gumbau, Jesus] Univ Jaume 1, Inst New Imaging Technol, Castellon de La Plana 12006, Spain.
C3 Universitat Jaume I
RP Remolar, I (corresponding author), Univ Jaume 1, Inst New Imaging Technol, Castellon de La Plana 12006, Spain.
EM remolar@uji.es; agarces@uji.es; rebollo@uji.es; chover@uji.es;
   quiros@uji.es; jgumbau@uji.es
RI Chover Sellés, Miguel/P-9933-2018; Remolar Quintana,
   Inmaculada/T-1268-2017; Rebollo Santamaría, Cristina/T-1272-2017
OI Chover Sellés, Miguel/0000-0002-0525-7038; Remolar Quintana,
   Inmaculada/0000-0002-7743-2579; Rebollo Santamaría,
   Cristina/0000-0002-1328-2110
FU Spanish Ministry of Science and Technology [TIN2010-21089-C03-03]; Feder
   Funds
FX This work was supported by the Spanish Ministry of Science and
   Technology (Project TIN2010-21089-C03-03) and Feder Funds.
CR [Anonymous], 1998, BUSINESS VIRTUAL WOR
   [Anonymous], 2013, CO TURN VIRTUAL TRAD
   [Anonymous], 2000, 3D GAME ENGINE DESIG
   Argente E, 2011, KNOWL INF SYST, V29, P379, DOI 10.1007/s10115-010-0349-1
   Berger H., 2006, P 20 C COMPUTER HUMA, V206, P333, DOI [DOI 10.1145/1228175.1228237, 10.1145/1228175.1228237]
   Cernuzzi L, 2004, MU S ART SOC SIM ORG, P69, DOI 10.1007/1-4020-8058-1_6
   DUKE R, 2000, CORNERSTONES COMPUTI
   Garcés A, 2007, PROCEEDINGS OF THE IASTED INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, P37
   Garces A, 2010, INT J MULTIMED APPL, V2, P1
   Noh SS, 2006, ICAT 2006: 16th International Conference on Artificial Reality and Telexistence - Worshops, Proceedings, P246
   Prendinger H, 2011, IEEE T VIS COMPUT GR, V17, P655, DOI 10.1109/TVCG.2010.66
   Ranathunga S., 2011, P 10 INT C AUT AG MU, P1181
   Remolar I, 2011, LECT NOTES COMPUT SC, V6670, P118, DOI 10.1007/978-3-642-22336-5_7
   SHOHAM Y, 1993, ARTIF INTELL, V60, P51, DOI 10.1016/0004-3702(93)90034-9
   Smitht G, 2000, OBJECT Z SPECIFICATI
   Trenholme David, 2008, Virtual Reality, V12, P181, DOI 10.1007/s10055-008-0092-z
   Vijaykar S, 2009, 2009 6TH IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE, VOLS 1 AND 2, P186
   Vosinakis S, 2005, MULTIMED TOOLS APPL, V25, P253, DOI 10.1007/s11042-005-5607-y
   Wooldridge M., 2001, Agent-Oriented Software Engineering. First International Workshop, AOSE 2000. Revised Papers (Lecture Notes in Computer Science Vol.1957), P1
   Wooldridge M, 2000, AUTON AGENT MULTI-AG, V3, P285, DOI 10.1023/A:1010071910869
   Zambonelli F, 2003, ACM T SOFTW ENG METH, V12, P317, DOI 10.1145/958961.958963
NR 21
TC 8
Z9 9
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4561
EP 4582
DI 10.1007/s11042-013-1822-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400005
DA 2024-07-18
ER

PT J
AU Onkarappa, N
   Sappa, AD
AF Onkarappa, Naveen
   Sappa, Angel D.
TI Synthetic sequences and ground-truth flow field generation for algorithm
   validation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ground-truth optical flow; Synthetic sequence; Algorithm validation
AB Research in computer vision is advancing by the availability of good datasets that help to improve algorithms, validate results and obtain comparative analysis. The datasets can be real or synthetic. For some of the computer vision problems such as optical flow it is not possible to obtain ground-truth optical flow with high accuracy in natural outdoor real scenarios directly by any sensor, although it is possible to obtain ground-truth data of real scenarios in a laboratory setup with limited motion. In this difficult situation computer graphics offers a viable option for creating realistic virtual scenarios. In the current work we present a framework to design virtual scenes and generate sequences as well as ground-truth flow fields. Particularly, we generate a dataset containing sequences of driving scenarios. The sequences in the dataset vary in different speeds of the on-board vision system, different road textures, complex motion of vehicle and independent moving vehicles in the scene. This dataset enables analyzing and adaptation of existing optical flow methods, and leads to invention of new approaches particularly for driver assistance systems.
C1 [Onkarappa, Naveen] Autonomous Univ Barcelona, Comp Vis Ctr, E-08193 Barcelona, Spain.
   [Sappa, Angel D.] Comp Vis Ctr, Barcelona 08193, Spain.
C3 Centre de Visio per Computador (CVC); Autonomous University of
   Barcelona; Centre de Visio per Computador (CVC)
RP Onkarappa, N (corresponding author), Autonomous Univ Barcelona, Comp Vis Ctr, Campus UAB, E-08193 Barcelona, Spain.
EM naveen@cvc.uab.es; asappa@cvc.uab.es
OI Sappa, Angel/0000-0003-2468-0031
FU Spanish Government [TIN2011-25606]; Catalan Government through the
   Agency for Management of University and Research Grants (AGAUR)
FX This work was supported in part by the Spanish Government under Project
   TIN2011-25606. The work of N. Onkarappa was supported in part by the
   Catalan Government through the Agency for Management of University and
   Research Grants (AGAUR) under an FI Grant.
CR Adato Y, 2011, PROC CVPR IEEE, P1145, DOI 10.1109/CVPR.2011.5995419
   [Anonymous], 1981, P 7 INT JOINT C ART
   Baker Simon, 2007, 2007 11th IEEE International Conference on Computer Vision, P1
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Geiger A., 2012, CVPR
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Liu C, 2008, PROC CVPR IEEE, P3911
   Mac Aodha O, 2013, IEEE T PATTERN ANAL, V35, P1107, DOI 10.1109/TPAMI.2012.171
   McCane B, 2001, COMPUT VIS IMAGE UND, V84, P126, DOI 10.1006/cviu.2001.0930
   Meister S, 2011, 2011 14 ITG C EL MED, P1
   Otte M., 1994, Computer Vision - ECCV'94. Third European Conference on Computer Vision. Proceedings. Vol.I, P51
   Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939
   Vaudrey Tobi., 2008, 23 INT C IMAGE VISIO, P1
   Wedel A, 2009, LECT NOTES COMPUT SC, V5604, P23, DOI 10.1007/978-3-642-03061-1_2
   Xu L, 2012, IEEE T PATTERN ANAL, V34, P1744, DOI 10.1109/TPAMI.2011.236
NR 16
TC 9
Z9 9
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 9
BP 3121
EP 3135
DI 10.1007/s11042-013-1771-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CF7NI
UT WOS:000352742800013
DA 2024-07-18
ER

PT J
AU Jo, SM
   Chung, KY
AF Jo, Sun-Moon
   Chung, Kyung-Yong
TI Design of access control system for telemedicine secure XML documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE XML; Authorization; Policy; Access Control; Security; Telemedicine
AB XML can supply the standard data type in information exchange format on a lot of data generated in running database or applied programs for a company by using the advantage that it can describe meaningful information directly. Accordingly since there are increasing needs for the efficient management and telemedicine security of the massive volume of XML data, it is necessary to develop a secure access control mechanism for XML. The existing access control has not taken information structures and semantics into full consideration due to the fundamental limitations of HTML. In addition, access control for XML documents allows read operations only, and there are problems of slowing down the system performance due to the complex authorization evaluation process. To resolve this problem, this paper designs and builds a XACS (XML Access Control System), which is capable of making fined-grained access control. This only provides data corresponding to its users' authority levels by authorizing them to access only the specific items of XML documents when they are searching XML documents in telemedicine. To accomplish this, XACS eliminates certain parts of the documents that are inaccessible and transmits the parts accessible depending on the users' authority levels. In addition, it can be expanded to existing web servers because XML documents are used based on the normal web sites. The telemedicine secure and the guidelines are provided to enable quick and precise understanding of the information, and thus the safety enhancement gets improved. Ultimately, this paper suggests an empirical telemedicine application to confirm the adequacy and validity using the proposed method.
C1 [Jo, Sun-Moon] Paichai Univ, Dept Comp Informat Technol Educ, Taejon 302735, South Korea.
   [Chung, Kyung-Yong] Sangji Univ, Sch Comp Informat Engn, Wonju 220702, Gangwon Do, South Korea.
C3 Pai Chai University; Sangji University
RP Chung, KY (corresponding author), Sangji Univ, Sch Comp Informat Engn, Wonju 220702, Gangwon Do, South Korea.
EM sunmoon@pcu.ac.kr; dragonhci@hanmail.net
RI Chung, Kyungyong/JAC-2276-2023
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2013R1A1A2059964]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (2013R1A1A2059964).
CR ADLER S, 2001, EXTENSIBLE STYLESHEE
   Agostino Ardagna C, 2005, WEB SERVICE ARCHITEC
   [Anonymous], 2000, EXTENSIBLE MARKUP LA
   [Anonymous], 1998, Uniform Resource Identifiers (URI): Generic Syntax
   [Anonymous], XML SCHEMA 2
   [Anonymous], 2002, Document Object Model (DOM) Level 3 validation specification
   Apache Software Foundation, 2001, XAL J VERS 2 2 D14
   Baek SJ, 2013, WIRELESS PERS COMMUN, V73, P309, DOI 10.1007/s11277-013-1239-0
   BARTEL MB, 2002, XML SIGNATURE SYNTAX
   Bertino E., 2002, ACM Transactions on Information and Systems Security, V5, P290, DOI 10.1145/545186.545190
   Bertino E, 2001, IEEE INTERNET COMPUT, V5, P21, DOI 10.1109/4236.935172
   Bertino E, 2000, AUTHOR X JAVA UNPUB
   Boulmalf Mohammed, 2014, MULTIMEDIA TOOLS APP
   Chung KY, 2014, PERS UBIQUIT COMPUT, V18, P1291, DOI 10.1007/s00779-013-0743-2
   Chung KY, 2013, WIRELESS PERS COMMUN, V73, P243, DOI 10.1007/s11277-013-1234-5
   Content Guard, 2001, EXTENSIBLE RIGHTS MA
   Damiani E, 2000, P 9 INT WWW C AMST, P55
   DeRose S., 2001, XML LINKING LANGUAGE
   DEUTSCH A, 1999, INT C WORLD WID WEB
   DEUTSCH A, 2001, P 8 INT WORKSH KNOWL
   DEVANBU P, 2001, P 8 ACM C COMP COMM
   di Vimercati S. D. C., 2002, P 2002 ACM S APPL CO, P1088
   GABILLON A, 2001, P 15 ANN IFIP WG 11
   Hada S., 2002, XML ACCESS CONTROL L, P1
   Han JS, 2015, MULTIMED TOOLS APPL, V74, P9087, DOI 10.1007/s11042-013-1664-9
   Jo SM, 2011, LNEE, V120, P81
   Jung EY, 2013, WIRELESS PERS COMMUN, V73, P207, DOI 10.1007/s11277-013-1231-8
   Jung H, 2014, CLUSTER COMPUT, V17, P767, DOI 10.1007/s10586-013-0318-z
   조선문, 2009, [The Journal of the Korea Contents Association, 한국콘텐츠학회 논문지], V9, P113
   조선문, 2008, [The Journal of the Korea Contents Association, 한국콘텐츠학회 논문지], V8, P25
   Jung YG, 2011, INFORMATION-TOKYO, V14, P3791
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P873, DOI 10.1007/s11042-011-0919-6
   Kudoh M., 2005, S CRYPT INF SEC SCIS
   Lee KD, 2013, MULTIMED TOOLS APPL, V63, P27, DOI 10.1007/s11042-012-1020-5
   Lim HC, 2003, P 10 ACM WORKSH XML
   Mohan S., 2006, ACM J, V5, P1
   Murat M, 2006, J ACM T INF SYST SEC
   OASIS, 2002, 14 OASIS
   SCHMIDT A, 2001, INSR0103 CWI
   Yu T, 2004, ACM T DATABASE SYST, V29, P363, DOI 10.1145/1005566.1005570
   Zhang N, 2004, PROC INT CONF DATA, P54, DOI 10.1109/ICDE.2004.1319984
   [No title captured]
NR 42
TC 20
Z9 23
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 7
BP 2257
EP 2271
DI 10.1007/s11042-014-1938-x
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE0TU
UT WOS:000351520200005
DA 2024-07-18
ER

PT J
AU Liu, L
   Jones, A
   Antonopoulos, N
   Ding, ZJ
   Zhan, YZ
AF Liu, Lu
   Jones, Andrew
   Antonopoulos, Nick
   Ding, Zhijun
   Zhan, Yongzhao
TI Performance evaluation and simulation of peer-to-peer protocols for
   Massively Multiplayer Online Games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MMOG; P2P; Networking; Simulation
AB Massively Multiplayer Online Games are networked games that allow a large number of people to play together. Classically MMOG worlds are hosted on many powerful servers and players that move around the world are passed from server to server as they pass through the environment. Running a large number of servers can be challenging and there are many considerations for a developer who wants to create a game to enter the MMOG market. If it is possible to use a P2P network to host an MMOG successfully, the costs of running a server farm are taken out of the equation. This will allow for groups with small budgets to enter the MMOG market and help competition in the market place. In this paper, the methods for the design of P2P massively multiplayer game protocols have been presented. Performance bottlenecks have been evaluated and highlighted by using simulations. The business viability has also been discussed in this paper.
C1 [Liu, Lu; Jones, Andrew; Antonopoulos, Nick] Univ Derby, Sch Comp & Math, Derby DE22 1GB, Derby, England.
   [Ding, Zhijun] Tongji Univ, Dept Comp Sci & Technol, Shanghai 200092, Peoples R China.
   [Zhan, Yongzhao] Jiangsu Univ, Sch Comp Sci & Telecommun Engn, Zhenjiang, Jiangsu, Peoples R China.
C3 University of Derby; Tongji University; Jiangsu University
RP Liu, L (corresponding author), Univ Derby, Sch Comp & Math, Derby DE22 1GB, Derby, England.
EM l.liu@derby.ac.uk
RI lu, lu/HII-7530-2022; LU, LU/JEZ-4760-2023; lu, lu/HGA-0894-2022
OI Liu, Lu/0000-0003-1013-4507
FU Sino-UK Higher Education Research Partnership for PhD Studies; Natural
   Science Foundation of Jiangsu Province of China; RLTF e-learning Cloud
   Programme; National Natural Science Foundation of China [61272074];
   China 973 Fundamental RD Program [2011CB302600]; Tongji University
FX The work reported in this paper has been supported by the Sino-UK Higher
   Education Research Partnership for PhD Studies, Natural Science
   Foundation of Jiangsu Province of China, RLTF e-learning Cloud
   Programme, National Natural Science Foundation of China Program
   (61272074), China 973 Fundamental R&D Program (2011CB302600) and
   Visiting Research Fellow Program of Tongji University.
CR [Anonymous], 1996, Computer graphics: principles and practice
   [Anonymous], P 10 IEEE GLOB INT S
   Backhaus Helge, 2010, International Journal of Advanced Media and Communication, V4, P126, DOI 10.1504/IJAMC.2010.032139
   Baset S., 2006, IEEE INT C COMPUTER, P1, DOI DOI 10.1109/INFOCOM.2006.312
   Boulanger Jean-Sebastien., 2006, NETGAMES 06, P6, DOI [10.1145/1230040.1230069, DOI 10.1145/1230040.1230069]
   Dabek R, 2003, LECT NOTES COMPUT SC, V2735, P33
   Fischbach K, 2005, CORE CONCEPTS PEER T
   Fritsch Tobias., 2005, NETGAMES 05, P1
   García P, 2005, LECT NOTES COMPUT SC, V3437, P123
   GauthierDickey C., 2005, Proceedings of the 15th International Workshop on Network and Operating Systems Support for Digital Audio and Video. NOSSDAV 2005, P87, DOI 10.1145/1065983.1066005
   GUIBAS L, 1985, ACM T GRAPHIC, V4, P74, DOI 10.1145/282918.282923
   Li JY, 2005, IEEE INFOCOM SER, P225
   Liu L, 2007, FUTURE GENER COMP SY, V23, P921, DOI 10.1016/j.future.2007.03.002
   Liu L, 2009, CONCURR COMP-PRACT E, V21, P159, DOI 10.1002/cpe.1329
   Lu Fan, 2010, International Journal of Advanced Media and Communication, V4, P108, DOI 10.1504/IJAMC.2010.032138
   Naicken S., 2006, P 4 INT WORK C PERF
   Neumann C, 2007, ACM SIGCOMM COMP COM, V37, P79, DOI 10.1145/1198255.1198269
   Ofcom, 2011, AV BROADB SPEED IS S
   Riot Games, 2011, RIOT GAM CEL END LEA
   Schollmeier R., 2001, P 1 INT C PEER TO PE, P101
   Siebert M, 2006, IT-INF TECHNOL, V48, P253, DOI 10.1524/itit.2006.48.5.253
   Zhao S., 2006, 13 ANN MULT COMP NET, P1
NR 22
TC 5
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 8
BP 2763
EP 2780
DI 10.1007/s11042-013-1662-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE2ZL
UT WOS:000351692300011
DA 2024-07-18
ER

PT J
AU Nakayama, M
   Fujimoto, M
AF Nakayama, Minoru
   Fujimoto, Masashi
TI Features of Oculo-motors and their chronological changes in response to
   varying sizes of visual stimuli
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual object size viewed; Accommodation; Eye movement; Pupil; Visual
   Evoked Potential (VEP)
ID EYE-MOVEMENTS
AB The chronological process of eye accommodation used when viewing objects was analysed to predict the size of viewed objects. Viewer's visual evoked potentials (VEP), eye movements and pupil oscillations were measured while six sizes of Landolt circles were presented for 1s each. The significant features of the metrics were extracted to illustrate the perception process and the resulting sizes of visual stimuli. The stimulus sizes affect P1 and N1 delay times of VEP, means of eye movement lengths and pupil diameters and oscillations during the second 500 milliseconds of observation. The feasibility of prediction of stimulus sizes viewed was confirmed using the features of eye behaviour and support vector machines. Both indices of eye movements and pupil diameters were determined to be significant features for making predictions. The influences of the combination of features and viewer's individual factors were also confirmed. This result suggests that features of oculo-motor indices reflect the size of objects being viewed and that these viewing sizes can be predicted using the features.
C1 [Nakayama, Minoru] Tokyo Inst Technol, Human Syst Sci, Meguro Ku, Tokyo 1528552, Japan.
   [Fujimoto, Masashi] Tokyo Inst Technol, Tokyo 152, Japan.
C3 Tokyo Institute of Technology; Tokyo Institute of Technology
RP Nakayama, M (corresponding author), Tokyo Inst Technol, Human Syst Sci, Meguro Ku, Tokyo 1528552, Japan.
EM nakayama@cradle.titech.ac.jp
RI Nakayama, Minoru/GSD-2757-2022
OI Nakayama, Minoru/0000-0001-5563-6901
CR Abe H., 2006, Journal of the Institute of Image Information and Television Engineers, V60, P397, DOI 10.3169/itej.60.397
   [Anonymous], 2001, Proceedings of the 14th International Conference on Neural Information Processing Systems: Natural and Synthetic, NIPS'01, page
   [Anonymous], 2009, ESANN 2009 P
   Bacon-Macé N, 2007, J EXP PSYCHOL HUMAN, V33, P1013, DOI 10.1037/0096-1523.33.5.1013
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Crouzet SM, 2010, J VISION, V10, DOI 10.1167/10.4.16
   Duchowski A.T., 2006, CHI2006 WORKSH GETT
   Fujimoto Masashi, 2011, IEICE Transactions on Information and Systems (Japanese Edition), VJ94-D, P929
   Grainger J, 2009, BRAIN RES, V1270, P45, DOI 10.1016/j.brainres.2009.02.080
   Japan Society of Vision Science, 2001, HDB VIS INF PROC
   Kirchner H, 2006, VISION RES, V46, P1762, DOI 10.1016/j.visres.2005.10.002
   Maeda Y., 2007, IEICE T D, VJ90-D, P715
   Nakayama M., 2012, 2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom), P1513, DOI 10.1109/TrustCom.2012.104
   Nakayama M., 2011, Proceedings 2011 IEEE Symposium on Computational Intelligence for Multimedia, Signal and Vision Processing (CIMSIVP 2011), P98, DOI 10.1109/CIMSIVP.2011.5949240
   Niwa S, 1997, JISHO KANREN DENI
   Privitera CM, 2000, IEEE T PATTERN ANAL, V22, P970, DOI 10.1109/34.877520
   Rayner K, 1998, PSYCHOL BULL, V124, P372, DOI 10.1037/0033-2909.124.3.372
   Rugg MD, 1997, STUD COGNIT, P1
   Shiba Y, 1976, TOUKEITEKI HOUHOU 2
   Tatler BW, 2010, I-PERCEPTION, V1, P7, DOI 10.1068/i0382
NR 21
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 8
BP 2841
EP 2859
DI 10.1007/s11042-013-1824-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE2ZL
UT WOS:000351692300015
DA 2024-07-18
ER

PT J
AU Yu, ML
   Song, EM
   Jin, RC
   Liu, H
   Xu, XY
   Ma, GZ
AF Yu, Mali
   Song, Enmin
   Jin, Renchao
   Liu, Hong
   Xu, Xiangyang
   Ma, Guangzhi
TI A novel method for fusion of differently exposed images based on spatial
   distribution of intensity for ubiquitous multimedia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Exposure fusion; Spatial distribution of intensity; Background context;
   Local contrast enhancement
AB Exposure fusion is an efficient way to produce a high-quality image for common Low Dynamic Range (LDR) output devices from multiple differently exposed LDR images of the same scene, which has significant potential to be applied in the ubiquitous multimedia area. Generating the fused image with high local contrast from fewer exposed images is still a challenging task. A novel method is proposed in this paper to fuse two differently exposed images based on the spatial distribution of intensity, which consists of two steps. First, the weights are computed based on the background context of the average image for producing the initial fused image. Then, we propose to enhance the initial fused image through removing the background context and efficiently refuse them. So the proposed method improves the local contrast in the dark region and keeps the color in the bright region. Experimental results and comparisons with the existing exposure fusion methods demonstrate that the proposed method has better performance and is convenient for GPU realization.
C1 [Yu, Mali; Song, Enmin; Jin, Renchao; Liu, Hong; Xu, Xiangyang; Ma, Guangzhi] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
   [Yu, Mali; Song, Enmin; Jin, Renchao; Liu, Hong; Xu, Xiangyang; Ma, Guangzhi] Educ Minist Image Proc & Intelligent Control, Key Lab, Wuhan 430074, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology
RP Song, EM (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, 1037 Luoyu Rd, Wuhan 430074, Hubei, Peoples R China.
EM esong@hust.edu.cn
RI Jin, Renchao/F-4880-2018; Xu, Xiangyang/N-9292-2014
OI Jin, Renchao/0000-0002-1591-3510; Xu, Xiangyang/0000-0002-9713-0535
FU National Natural Science Foundation of China [61075010]; Fundamental
   Research Funds for the Central Universities [HUST: CXY12Q030, CXY12Q031]
FX The authors would like to thank Professor Geyong Min for valuable
   advice. This work has been partially supported by the National Natural
   Science Foundation of China (Grant No. 61075010), and by the Fundamental
   Research Funds for the Central Universities (HUST: CXY12Q030 and
   CXY12Q031).
CR Aydin TO, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360668
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Ferwerda JA, 2001, IEEE COMPUT GRAPH, V21, P22, DOI 10.1109/38.946628
   Goshtasby AA, 2005, IMAGE VISION COMPUT, V23, P611, DOI 10.1016/j.imavis.2005.02.004
   Hall R., 1989, ILLUMINATION COLOR C
   Hui LH, 2010, IEEE INT C MULT COMM, P222
   Jo KH, 2011, COMPUT HUM BEHAV, V27, P1507, DOI 10.1016/j.chb.2010.10.015
   Kakarala R, 2014, J REAL-TIME IMAGE PR, V9, P347, DOI 10.1007/s11554-011-0231-8
   Mertens T, 2009, COMPUT GRAPH FORUM, V28, P161, DOI 10.1111/j.1467-8659.2008.01171.x
   Mertens T, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P382, DOI 10.1109/PG.2007.17
   Seetzen H, 2004, ACM T GRAPHIC, V23, P760, DOI 10.1145/1015706.1015797
   Shen R, 2011, IEEE T IMAGE PROCESS, V20, P3634, DOI 10.1109/TIP.2011.2150235
   Song ML, 2012, IEEE T IMAGE PROCESS, V21, P341, DOI 10.1109/TIP.2011.2157514
   Vavilin A, 2008, IEEE INT C COMP GRAP, P23
   Wang JH, 2010, INT CONF SIGN PROCES, P1082, DOI 10.1109/ICOSP.2010.5655887
NR 15
TC 6
Z9 6
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 8
BP 2745
EP 2761
DI 10.1007/s11042-013-1660-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE2ZL
UT WOS:000351692300010
DA 2024-07-18
ER

PT J
AU Hsu, FH
   Wu, MH
   Chang, YW
   Wang, SJ
AF Hsu, Fu-Hau
   Wu, Min-Hao
   Chang, Yi-Wen
   Wang, Shiuh-Jeng
TI Web security in a windows system as PrivacyDefender in private browsing
   mode
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web security; Private browsing; Malicious; Anti-forensics
AB Recently, due to the advance and development of Internet technology and its development, web browsers have become essential applications. A web browser is not only used to surf the Internet, but also plays an important role as a portable operating system. For example, many users edit documents via an online editor and store the documents in an online storage repository. All those tasks are done with the help of a web browser. This results in a large number of attacks on web browsers. Therefore, the security of web browsers has become an increasingly important issue in recent years. Traditionally, when a user surfs on the Internet, his interaction with the browser is recorded. This scenario is called public browsing mode. Through attacking web browsers, attackers can obtain access to surfers' private information, including surfing habits and passwords. The attackers are able to do this as web browsers always leave cookies, browsing histories and caches on the users' computers. To avoid malicious attacks, many web browsers have developed private browsing mode mechanisms. In private browsing mode, a user's behavior is not traced and his private information is retained as well. However, these mechanisms still create files such as bookmarks. Most importantly, the files downloaded through a web browser will be saved to disk unless the user deletes them himself. This is an extremely serious threat to the private security of web users. We designed a mechanism in Windows XP that observes the behaviors and patterns related to the creation and deletion of files in Firefox while in private browsing mode. We then focused on the files which were not deleted, and cleared them by means of anti-forensics manners. In other words, the web browsers can be made comprehensively secure with our mechanism.
C1 [Hsu, Fu-Hau; Wu, Min-Hao; Chang, Yi-Wen] Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan 320, Taiwan.
   [Wang, Shiuh-Jeng] Cent Police Univ, Dept Informat Management, Taoyuan 333, Taiwan.
C3 National Central University
RP Wang, SJ (corresponding author), Cent Police Univ, Dept Informat Management, Taoyuan 333, Taiwan.
EM sjwang@mail.cpu.edu.tw
RI Wang, Suhang/AAH-1378-2019
FU National Science Council of the Republic of 518 China [NSC
   100-2221-E-015-001-MY2-, NSC 102-2221-E-015-001-, NSC 101-2221-E-008
   -028 -MY2, NSC 103-2623-E-008-003-D]
FX This research was partially supported by the National Science Council of
   the Republic of 518 China under the Grant NSC 100-2221-E-015-001-MY2-,
   NSC 102-2221-E-015-001-, NSC 101-2221-E-008 -028 -MY2 and NSC
   103-2623-E-008-003-D.
CR Aggarwal G., 2010, P 19 USENIX C SECURI, P6
   [Anonymous], 2000, P 7 ACM C COMPUTER C
   Barth A., 2010, 17 NETW DISTR SYST S
   Brand M, 2010, J DIGIT FORENSICS SE, V5, P31
   Christodorescu M, 2003, USENIX ASSOCIATION PROCEEDINGS OF THE 12TH USENIX SECURITY SYMPOSIUM, P169
   Egele M, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2089125.2089126
   Harris R, 2006, DIGIT INVESTIG, pS44, DOI 10.1016/j.diin.2006.06.005
   IBM X-Force, 2011, IBM X FORC 2011 MID
   Jana S, 2012, P IEEE S SECUR PRIV, P143, DOI 10.1109/SP.2012.19
   Malin C.H., 2008, Malware forensics: investigating and analyzing malicious code
   Mozilla Firefox, PRIV BROWS BROWS WEB
   Nielson C, 1999, PRINCIPLES PROGRAM A, P450
   Qualys Security Labs, MS11 077 PATCH PROOF
   Saint-Jean F, 2007, WPES'07: PROCEEDINGS OF THE 2007 ACM WORKSHOP ON PRIVACY IN ELECTRONIC SOCIETY, P84
   Schwartz EJ, 2010, P IEEE S SECUR PRIV, P317, DOI 10.1109/SP.2010.26
   Shankar U., 2006, P 13 ACM C COMPUTER, P154
   StatCounter, 2011, TOP 5 BROWS
NR 17
TC 2
Z9 2
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 5
BP 1667
EP 1688
DI 10.1007/s11042-014-2003-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CC7UC
UT WOS:000350572900009
DA 2024-07-18
ER

PT J
AU Kordumova, S
   Li, XR
   Snoek, CGM
AF Kordumova, Svetlana
   Li, Xirong
   Snoek, Cees G. M.
TI Best practices for learning video concept detectors from social media
   examples
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video retrieval; Concept Detection; Social media
ID TAGGED IMAGES
AB Learning video concept detectors from social media sources, such as Flickr images and YouTube videos, has the potential to address a wide variety of concept queries for video search. While the potential has been recognized by many, and progress on the topic has been impressive, we argue that key questions crucial to know how to learn effective video concept detectors from social media examples? remain open. As an initial attempt to answer these questions, we conduct an experimental study using a video search engine which is capable of learning concept detectors from social media examples, be it socially tagged videos or socially tagged images. Within the video search engine we investigate three strategies for positive example selection, three negative example selection strategies and three learning strategies. The performance is evaluated on the challenging TRECVID 2012 benchmark consisting of 600 h of Internet video. From the experiments we derive four best practices: (1) tagged images are a better source for learning video concepts than tagged videos, (2) selecting tag relevant positive training examples is always beneficial, (3) selecting relevant negative examples is advantageous and should be treated differently for video and image sources, and (4) learning concept detectors with selected relevant training data before learning is better then incorporating the relevance during the learning process. The best practices within our video search engine lead to state-of-the-art performance in the TRECVID 2013 benchmark for concept detection without manually provided annotations.
C1 [Kordumova, Svetlana; Snoek, Cees G. M.] Univ Amsterdam, Intelligent Syst Lab Amsterdam, NL-1098 XH Amsterdam, Netherlands.
   [Li, Xirong] Renmin Univ China, Key Lab Data Engn & Knowledge Engn, Beijing 100872, Peoples R China.
C3 University of Amsterdam; Renmin University of China
RP Li, XR (corresponding author), Renmin Univ China, Key Lab Data Engn & Knowledge Engn, 59 Zhongguancun St, Beijing 100872, Peoples R China.
EM s.kordumova@uva.nl; xirong@ruc.edu.cn; cgmsnoek@uva.nl
RI Li, Xirong/AAD-3347-2019
OI Li, Xirong/0000-0002-0220-8310
FU STW STORY project; Dutch national program COMMIT; Chinese NSFC
   [61303184]; SRFDP [20130004120006]; Fundamental Research Funds for the
   Central Universities; Research Funds of Renmin University of China
   [14XNLQ01]; Intelligence Advanced Research Projects Activity (IARPA) via
   Department of Interior National Business Center [D11PC20067]
FX This research is supported by the STW STORY project, the Dutch national
   program COMMIT, the Chinese NSFC (No. 61303184), SRFDP (No.
   20130004120006), the Fundamental Research Funds for the Central
   Universities, the Research Funds of Renmin University of China (No.
   14XNLQ01), and by the Intelligence Advanced Research Projects Activity
   (IARPA) via Department of Interior National Business Center contract
   number D11PC20067. The U.S. Government is authorized to reproduce and
   distribute reprints for Governmental purposes notwithstanding any
   copyright annotation thereon. Disclaimer: The views and conclusions
   contained herein are those of the authors and should not be interpreted
   as necessarily representing the official policies or endorsements,
   either expressed or implied, of IARPA, DoI/NBC, or the U.S. Government.
CR [Anonymous], MM
   [Anonymous], 2008, P 17 INT C WORLD WID
   [Anonymous], ICMR
   [Anonymous], INT C IM VID RETR
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], ICCV
   [Anonymous], P ACM MULT
   [Anonymous], ICME
   [Anonymous], 2005, P 22 INT C MACHINE L
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], P ACM MULT SCOTTSD A
   [Anonymous], CVPR
   [Anonymous], P INT C CONT BAS IM
   [Anonymous], ICMR, DOI [10.1145/2324796.2324827, DOI 10.1145/2324796.2324827]
   [Anonymous], MM
   [Anonymous], CVPR
   Chang S.-F., 2007, P INT WORKSHOP WORKS, P255, DOI DOI 10.1145/1290082.1290118
   Fan JP, 2010, PROC CVPR IEEE, P802, DOI 10.1109/CVPR.2010.5540135
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Hu Y, 2008, PROC CVPR IEEE, P85
   Hwang SJ, 2012, INT J COMPUT VISION, V100, P134, DOI 10.1007/s11263-011-0494-3
   Jain V., 2011, International Conference on World Wide Web, P277, DOI DOI 10.1145/1963405.1963447
   Jiang YG, 2010, IEEE T MULTIMEDIA, V12, P42, DOI 10.1109/TMM.2009.2036235
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Kennedy L.S., 2006, Proc. ACM Multimedia Information Retrieval, P249, DOI DOI 10.1145/1178677.1178712
   Kim J, 2012, INT C PATT RECOG, P1611
   Kordumova S, 2013, INT WORK CONTENT MUL, P91, DOI 10.1109/CBMI.2013.6576561
   Li MJ, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P508
   Li XR, 2013, IEEE T MULTIMEDIA, V15, P933, DOI 10.1109/TMM.2013.2238523
   Li XR, 2012, IEEE T MULTIMEDIA, V14, P1091, DOI 10.1109/TMM.2012.2191943
   Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598
   Li Xirong., 2010, Proceedings of the ACM International Conference on Image and Video Retrieval, CIVR '10, P10
   Liu Dong., 2009, P 18 INT C WORLD WID, P351
   Liu YM, 2011, IEEE T PATTERN ANAL, V33, P1022, DOI 10.1109/TPAMI.2010.142
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maji S., 2008, CVPR
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Settles B, 2008, ADV NEURAL INFORM PR, V21, P1289
   Setz AT, 2009, IEEE INT CON MULTI, P1460, DOI 10.1109/ICME.2009.5202778
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Ulges A, 2008, LECT NOTES COMPUT SC, V5008, P415
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Zhao WL, 2010, IEEE T MULTIMEDIA, V12, P448, DOI 10.1109/TMM.2010.2050651
   Zhu SA, 2012, IEEE T MULTIMEDIA, V14, P1068, DOI 10.1109/TMM.2012.2190387
NR 45
TC 8
Z9 8
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 4
BP 1291
EP 1315
DI 10.1007/s11042-014-2056-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZN
UT WOS:000349356300008
OA Green Published
DA 2024-07-18
ER

PT J
AU Milutinovic, M
   Labus, A
   Stojiljkovic, V
   Bogdanovic, Z
   Despotovic-Zrakic, M
AF Milutinovic, Milos
   Labus, Aleksandra
   Stojiljkovic, Vukasin
   Bogdanovic, Zorica
   Despotovic-Zrakic, Marijana
TI Designing a mobile language learning system based on lightweight
   learning objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Learning objects; Mobile assisted language learning; Multimedia
   applications; L2 Japanese learning
ID KNOWLEDGE
AB This paper investigates the possibilities in the area of application of mobile technologies for language learning. The primary goal is to design a mobile system for learning of the Japanese language with a clear separation of content and presentation, and to leverage the learners' interest in the Japanese language. Both the technical and the language learning perspectives are discussed. A reusable, lightweight model of learning objects with compact content and a reduced metadata set is presented. These objects are stored in a simple learning object repository that can deliver them to any client over the Internet. A mobile application is designed to use the learning object repository as its content provider, while defining its own method of presentation suitable for smaller screens of mobile devices. For the purpose of evaluation, an experiment was conducted within the e-learning system at the Faculty of Organizational Sciences, University of Belgrade. Research findings have indicated that the developed mobile application has a positive effect on the students' interest in the subject matter.
C1 [Milutinovic, Milos; Labus, Aleksandra; Bogdanovic, Zorica; Despotovic-Zrakic, Marijana] Univ Belgrade, Fac Org Sci, Belgrade 11000, Serbia.
   [Stojiljkovic, Vukasin] Serbian Acad Arts & Sci, Inst Serbian Language, Belgrade 11000, Serbia.
C3 University of Belgrade; Serbian Academy of Sciences & Arts
RP Milutinovic, M (corresponding author), Univ Belgrade, Fac Org Sci, Jove Ilica 154, Belgrade 11000, Serbia.
EM milosm@elab.rs; aleksandra@elab.rs; stefanvukasins@yahoo.com;
   zorica@elab.rs; maja@elab.rs
RI Labus, Aleksandra/AAH-1820-2019; Despotovic-Zrakic,
   Marijana/D-8617-2016; Bogdanović, Zorica/O-9131-2018
OI Labus, Aleksandra/0000-0002-7716-5845; Bogdanović,
   Zorica/0000-0003-4799-1588; Despotovic-Zrakic,
   Marijana/0000-0002-6458-1575
FU Ministry of Education, Science, and Technological Development of the
   Republic of Serbia [174031]
FX The authors are thankful to the Ministry of Education, Science, and
   Technological Development of the Republic of Serbia, Grant no. 174031.
CR Adzic V, 2011, MULTIMED TOOLS APPL, V51, P379, DOI 10.1007/s11042-010-0669-x
   Alexander P.A., 2003, Educational Researcher, V32, P10, DOI [10.3102/0013189x032008010, DOI 10.3102/0013189X032008010, 10.3102/0013189X032008010]
   [Anonymous], 2010, P USENIX ANN TECH C
   [Anonymous], P KEST
   Ardito L., 2013, ENERGY, P101
   Arnone MP, 2011, ETR&D-EDUC TECH RES, V59, P181, DOI 10.1007/s11423-011-9190-9
   Bogdanovic Z, 2014, BRIT J EDUC TECHNOL, V45, P231, DOI 10.1111/bjet.12015
   Bradley C, 2008, MOBILE LEARNING ED T, P158
   Cheng SC, 2010, EDUC TECHNOL SOC, V13, P93
   Chinnery GM, 2006, LANG LEARN TECHNOL, V10, P9
   Churchill D, 2011, EDUC TECHNOL SOC, V14, P203
   Cisco Systems, 1999, CISC SYST REUS INF O, P1
   de Jong T, 2010, EDUC TECHNOL SOC, V13, P110
   Despotovic-Zrakic M, 2012, EDUC TECHNOL SOC, V15, P326
   Fallahkhair S, 2007, J COMPUT ASSIST LEAR, V23, P312, DOI 10.1111/j.1365-2729.2007.00236.x
   Godwin-Jones R, 2011, LANG LEARN TECHNOL, V15, P2
   Gu X, 2011, J COMPUT ASSIST LEAR, V27, P204, DOI [10.1111/j.1365-2729.2010.00391.x, 10.1111/J.1365-2729.2010.00391.x]
   Hodgins H., 2004, 2002 ECI C E TECHN E
   Holzinger A, 2005, COMMUN ACM, V48, P71, DOI 10.1145/1039539.1039541
   Holzinger Andreas, 2012, Multidisciplinary Research and Practice for Information Systems. International Cross-Domain Conference and Workshop on Availability, Reliability and Security (CD-ARES 2012). Proceedings, P176, DOI 10.1007/978-3-642-32498-7_14
   Holzinger A, 2012, P INT C E BUS ICE B, P3
   Holzinger A, 2010, WIREL COMMUN MOB COM, V10, P1350, DOI 10.1002/wcm.715
   Hwang GJ, 2011, BRIT J EDUC TECHNOL, V42, pE65, DOI 10.1111/j.1467-8535.2011.01183.x
   IEEE Learning Technology Standards Committee, 2002, STAND LEARN IN PRESS, P1
   IEEE Learning Technology Standards Committee, 2005, IEEE STAND LEARN TEC
   Jospeh S., 2009, Research and Practice in Technology Enhanced Learning, V4, P7
   Klopfer E, 2012, J COMPUT ASSIST LEAR, V28, P465, DOI 10.1111/j.1365-2729.2011.00456.x
   Konstantinidis A, 2009, MULTIMED TOOLS APPL, V44, P279, DOI 10.1007/s11042-009-0289-5
   L'Allier J.J., 1997, Frame of Reference: NETg's Map to the Products, Their Structure and Core Beliefs
   Lawless KA, 2006, CONTEMP EDUC PSYCHOL, V31, P30, DOI 10.1016/j.cedpsych.2005.01.002
   Lawless KA, 2003, J LIT RES, V35, P911, DOI 10.1207/s15548430jlr3503_5
   Lindenberg J, 2021, 9th International Conference on Intelligent User Interfaces, ACM, V40, P1271, DOI 10.1145/964442.964512
   Longmire W., 2000, LEARNING CIRCUITS, P1
   Looi CK, 2010, BRIT J EDUC TECHNOL, V41, P154, DOI 10.1111/j.1467-8535.2008.00912.x
   Matsuo K, 2003, COGNITIVE BRAIN RES, V17, P263, DOI 10.1016/S0926-6410(03)00114-9
   McGreal R., 2004, International Journal of Instructional Technology and Distance Learning, V1, P21
   Moreno-Ger P, 2008, COMPUT HUM BEHAV, V24, P2530, DOI 10.1016/j.chb.2008.03.012
   Motschnig-Pitrik R., 2002, Educational Technology & Society, V5
   Mujacic S, 2012, MULTIMED TOOLS APPL, V58, P435, DOI 10.1007/s11042-010-0665-1
   Okan Z, 2003, BRIT J EDUC TECHNOL, V34, P255, DOI 10.1111/1467-8535.00325
   Palit R., 2011, Proceedings of the 6th International Workshop on Automation of Software Test, AST'11, P84
   Polsani P, 2003, J DIGIT INF, V3
   Sandberg J, 2011, COMPUT EDUC, V57, P1334, DOI 10.1016/j.compedu.2011.01.015
   Schandl B, 2012, MULTIMED TOOLS APPL, V59, P523, DOI 10.1007/s11042-011-0762-9
   Sha L, 2012, J COMPUT ASSIST LEAR, V28, P366, DOI 10.1111/j.1365-2729.2011.00461.x
   Stockwell G, 2010, LANG LEARN TECHNOL, V14, P95
   Tsai CH, 2012, LANG LEARN TECHNOL, V16, P110
   Vidas T, 2011, DIGIT INVEST, V8, pS14, DOI 10.1016/j.diin.2011.05.003
   Wang MJ, 2009, BRIT J EDUC TECHNOL, V40, P673, DOI 10.1111/j.1467-8535.2008.00846.x
   Wong LH, 2010, J COMPUT ASSIST LEAR, V26, P421, DOI 10.1111/j.1365-2729.2010.00357.x
NR 50
TC 18
Z9 21
U1 0
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 3
BP 903
EP 935
DI 10.1007/s11042-013-1704-5
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA CB0ZO
UT WOS:000349356400012
DA 2024-07-18
ER

PT J
AU Wang, GC
   Wang, N
   Yu, X
   Li, TS
   Zhang, ZZ
AF Wang, Gaocai
   Wang, Nao
   Yu, Xin
   Li, Taoshen
   Zhang, Zhenzhen
TI Performance analysis of opportunistic scheduling in wireless multimedia
   and data networks using stochastic network calculus
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless multimedia and data networks; Stochastic network calculus;
   Opportunistic scheduling; Performance analysis; MPF scheduling algorithm
ID DELAY
AB In this paper, performance of opportunistic scheduling (OS) in wireless multimedia and data networks is studied based on popular stochastic network calculus (SNC). For this purpose, we firstly bound traffic arrival process by using exponentially bounded burstiness (EBB) traffic model of SNC and establish stochastic arrival curve. Then we propose a new wireless opportunistic scheduling-Modified Proportional Fairness (MPF) scheduling algorithm which can provide better fairness for input traffic to guarantee quality of service (QoS) performance and obtain stochastic service curve. Compared with traditional Round-Robin (RR), Greedy (GY) and Proportional Fairness (PF) scheduling algorithms, MPF scheduling algorithm can get better equilibrium between delay and backlog. More specifically, our MPF scheduling algorithm can provide better fairness and QoS by introducing a weighted factor to identify user's priority. On the other hand, the framework based on SNC also provides higher utilization of network resource and statistical meanings for delay and backlog, so MPF can schedule input traffic effectively as long as the input traffic satisfies some bounded conditions. The numerical results show that our stochastic model and MPF scheduling algorithm can provide better QoS performance.
C1 [Wang, Gaocai; Wang, Nao; Yu, Xin; Li, Taoshen; Zhang, Zhenzhen] Guangxi Univ, Sch Comp & Elect Informat, Nanning 530004, Guangxi, Peoples R China.
C3 Guangxi University
RP Wang, GC (corresponding author), Guangxi Univ, Sch Comp & Elect Informat, Nanning 530004, Guangxi, Peoples R China.
EM wanggaocai@yahoo.com.cn; zhuowang@gxu.edu.cn; yuxin21@126.com;
   tshli@gxu.edu.cn; zzzh@gxu.edu.cn
RI Wang, Guojun/G-1674-2015
OI Yu, Xin/0000-0002-3651-4770
FU National Natural Science Foundation of China [61063045, 61262003,
   61103245]; Natural Science Foundation of Guangxi Province
   [2010GXNSFC013013]
FX The authors would like to thank the anonymous reviewers for the careful
   reading of the original manuscript. Their comments and suggestions have
   led to a much better presentation of the paper. This research is
   supported in part by the National Natural Science Foundation of China
   under Grant Nos. 61063045, 61262003 and 61103245, in part by the Natural
   Science Foundation of Guangxi Province under Grant No. 2010GXNSFC013013.
CR CHANG CS, 1994, IEEE T AUTOMAT CONTR, V39, P913, DOI 10.1109/9.284868
   CRUZ RL, 1991, IEEE T INFORM THEORY, V37, P132, DOI 10.1109/18.61110
   CRUZ RL, 1991, IEEE T INFORM THEORY, V37, P114, DOI 10.1109/18.61109
   Dianati M, 2007, IEEE T VEH TECHNOL, V56, P1749, DOI 10.1109/TVT.2007.897209
   *GPP2, 2002, CDMA 2000 HIGH RATE
   *GPPTS, 2001, 25848
   Jiang YM, 2006, ACM SIGCOMM COMP COM, V36, P123, DOI 10.1145/1151659.1159929
   Kavitha V, 2012, IEEE T INFORM THEORY, V58, P1757, DOI 10.1109/TIT.2011.2173630
   Li Y, 2012, IEEE T WIREL COMMUN, V11, P328, DOI 10.1109/TWC.2011.110811.110722
   Liu Y, 2007, PERFORM EVALUATION, V64, P547, DOI 10.1016/j.peva.2006.07.003
   Prakash R, 2007, IEEE T INFORM THEORY, V53, P695, DOI 10.1109/TIT.2006.889461
   Shakkottai S, 2008, IEEE T AUTOMAT CONTR, V53, P749, DOI 10.1109/TAC.2008.917736
   Starobinski D, 2000, IEEE T INFORM THEORY, V46, P206, DOI 10.1109/18.817518
   Wang GC, 2010, P ICCSE 2010, P1685
   Wang GC, 2012, LECT NOTES ELECT ENG, V143, P235
   Yaron O, 1993, IEEE ACM T NETWORK, V1, P372, DOI 10.1109/90.234858
   ZZBoorstyn RR, 2000, IEEE J SEL AREA COMM, V18, P2651
NR 17
TC 1
Z9 1
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 1
BP 25
EP 41
DI 10.1007/s11042-013-1448-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ6UP
UT WOS:000348356300003
DA 2024-07-18
ER

PT J
AU Horvat, M
   Bogunovic, N
   Cosic, K
AF Horvat, Marko
   Bogunovic, Nikola
   Cosic, Kresimir
TI STIMONT: a core ontology for multimedia stimuli description
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ontology; Multimedia; OWL; Emotion; Stimulus
ID MEASURING EMOTION; RETRIEVAL; TOOL
AB Affective multimedia documents such as images, sounds or videos elicit emotional responses in exposed human subjects. These stimuli are stored in affective multimedia databases and successfully used for a wide variety of research in psychology and neuroscience in areas related to attention and emotion processing. Although important all affective multimedia databases have numerous deficiencies which impair their applicability. These problems, which are brought forward in the paper, result in low recall and precision of multimedia stimuli retrieval which makes creating emotion elicitation procedures difficult and labor-intensive. To address these issues a new core ontology STIMONT is introduced. The STIMONT is written in OWL-DL formalism and extends W3C EmotionML format with an expressive and formal representation of affective concepts, high-level semantics, stimuli document metadata and the elicited physiology. The advantages of ontology in description of affective multimedia stimuli are demonstrated in a document retrieval experiment and compared against contemporary keyword-based querying methods. Also, a software tool Intelligent Stimulus Generator for retrieval of affective multimedia and construction of stimuli sequences is presented.
C1 [Horvat, Marko; Bogunovic, Nikola; Cosic, Kresimir] Univ Zagreb, Fac Elect Engn & Comp, HR-10000 Zagreb, Croatia.
C3 University of Zagreb
RP Horvat, M (corresponding author), Univ Zagreb, Fac Elect Engn & Comp, Unska 3, HR-10000 Zagreb, Croatia.
EM marko.horvat2@fer.hr
RI Horvat, Marko/AFU-9070-2022
OI Horvat, Marko/0000-0002-3439-7216
CR Agius H, 2010, EMOTION HCI DESIGNIN, V13
   [Anonymous], 2007, Technical report
   [Anonymous], 2002, AAAI 2002 WORKSH ONT
   [Anonymous], 2010, LREC 10
   Arndt R, 2007, LECT NOTES COMPUT SC, V4825, P30
   Baader F, 2003, DESCRIPTION LOGIC HANDBOOK: THEORY, IMPLEMENTATION AND APPLICATIONS, P43
   Bradley M., 2000, SER AFFECTIVE SCI, P242, DOI 10.1093/oso/9780195118889.003.0011
   Bradley M.M., 1999, PSYCHOLOGY
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Bradley MM., 2007, Technical report B-3
   Dan-Glauser ES, 2011, BEHAV RES METHODS, V43, P468, DOI 10.3758/s13428-011-0064-1
   EKMAN P, 1992, PSYCHOL REV, V99, P550, DOI 10.1037/0033-295X.99.3.550
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Gangemi A, 2002, LECT NOTES ARTIF INT, V2473, P166
   Grandjean D, 2008, CONSCIOUS COGN, V17, P484, DOI 10.1016/j.concog.2008.03.019
   Gray E.K., 2007, HDB EMOTION ELICITAT
   GROSS JJ, 1995, COGNITION EMOTION, V9, P87, DOI 10.1080/02699939508408966
   Gross Ralph., 2005, HDB FACE RECOGNITION
   Hauptmann A, 2007, IEEE T MULTIMEDIA, V9, P958, DOI 10.1109/TMM.2007.900150
   HILLMANN D., 2001, Using Dublin Core
   Hliaoutakis A, 2006, INT J SEMANT WEB INF, V2, P55, DOI 10.4018/jswis.2006070104
   Horrocks I, 2011, FOUNDATIONS FOR THE WEB OF INFORMATION AND SERVICES: A REVIEW OF 20 YEARS OF SEMANTIC WEB RESEARCH, P103, DOI 10.1007/978-3-642-19797-0_6
   HORVAT M, 2009, P 32 INT CONV MIPRO, P203
   Horvat M, 2013, STIMONT CORE ONTOLOG
   Horvat M, 2013, P 36 INT CO IN PRESS
   Horvat M, 2012, FRONT ARTIF INTEL AP, V243, P585, DOI 10.3233/978-1-61499-105-2-585
   Koelstra S, IEEE T AFF IN PRESS
   Lang P. J., 2005, A6 U FLOR CTR RES PS
   Libkuman TM, 2007, BEHAV RES METHODS, V39, P326, DOI 10.3758/BF03193164
   Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d
   Machajdik Jana., 2010, AFFECTIVE IMAGE CLAS, DOI 10.1145/1873951.1873965
   Marchewka A, 2013, INTRO NOVEL ST UNPUB
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   López JM, 2008, LECT NOTES ARTIF INT, V5288, P96, DOI 10.1007/978-3-540-87781-3_11
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Neumann B., 2008, SEMANTIC MULTIMEDIA
   Niles I, 2003, IKE'03: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE ENGINEERING, VOLS 1 AND 2, P412
   OConnor M., 2005, 8 INT PROT C PROT RU
   Peter C, 2006, INTERACT COMPUT, V18, P139, DOI 10.1016/j.intcom.2005.10.006
   Popovic S, 2009, STUD HEALTH TECHNOL, V144, P50, DOI 10.3233/978-1-60750-017-9-50
   Prud'hommeaux Eric., 2007, SPARQL QUERY LANGUAG
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Schröder M, 2011, LECT NOTES COMPUT SC, V6974, P316, DOI 10.1007/978-3-642-24600-5_35
   Sikora T, 2001, IEEE T CIRC SYST VID, V11, P696, DOI 10.1109/76.927422
   Staab Steffen., 2010, HDB ONTOLOGIES
   Stevenson RA, 2008, BEHAV RES METHODS, V40, P315, DOI 10.3758/BRM.40.1.315
   Stevenson RA, 2007, BEHAV RES METHODS, V39, P1020, DOI 10.3758/BF03192999
   Strapparava C., 2004, Lrec, Volume, V4, P1083
   Suarez-Figueroa MC, 2011, MULTIMED TOOLS APPL, V55
   Tottenham N, 2009, PSYCHIAT RES, V168, P242, DOI 10.1016/j.psychres.2008.05.006
   Villon O, 2007, COMP MED SY, P357, DOI 10.1109/CBMS.2007.112
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 52
TC 18
Z9 18
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1103
EP 1127
DI 10.1007/s11042-013-1624-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, ZK
   Yu, JQ
   He, YF
   Guan, T
AF Wang, Zengkai
   Yu, Junqing
   He, Yunfeng
   Guan, Tao
TI Affection arousal based highlight extraction for soccer video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affection arousal model; Highlight extraction; Soccer video analysis;
   Event detection
ID EVENT DETECTION; SPORTS; RETRIEVAL
AB Highlight extraction, as one of the key technologies in soccer video retrieval and summarization, has great academic and application value. According to the principle that the observer's affection state would fluctuate with the evolution of game process when watching soccer match video, a novel highlight extraction approach based on the improved affection arousal model is proposed. Compared with the existing works, our main contributions include the following. A novel feature - shot intensity is exploited to replace the motion activity, which greatly improves the computational performance of affection arousal model. Another helpful feature - replay factor is designed and successfully fused into the affection arousal model. This makes the affection arousal model reflect the variation of the true match process more accurately. In addition, event temporal transition pattern (ETTP) in soccer video is utilized to detect highlights boundaries effectively combined with the affection arousal curve. Experiments conducted on real-world soccer game videos have demonstrated the efficiency and effectiveness of the proposed approach.
C1 [Wang, Zengkai; Yu, Junqing; He, Yunfeng; Guan, Tao] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Guan, T (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM zengkai.w@gmail.com; yjqing@hust.edu.cn; yfhe@hust.edu.cn; qd_gt@126.com
RI he, yun/JMB-6362-2023
FU National Natural Science Foundation of China (NSFC) [61173114, 61202300]
FX This work is financially supported by the National Natural Science
   Foundation of China (NSFC) under Grant No. 61173114 and 61202300.
CR Assfalg J, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P825, DOI 10.1109/ICME.2002.1035909
   Bayar M, 2010, IEEE INT CON MULTI, P578, DOI 10.1109/ICME.2010.5583864
   Chen SC, 2006, IEEE INT SYM MULTIM, P193
   Dietz R, 1999, P 3 INT COGN TECHN C, P151
   Ekin A, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P169
   Halin AA, 2013, INT ARAB J INF TECHN, V10, P493
   Han YN, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P888, DOI 10.1109/ICARCV.2008.4795635
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P1114, DOI 10.1109/TMM.2005.858397
   Huang CL, 2006, IEEE T MULTIMEDIA, V8, P749, DOI 10.1109/TMM.2006.876289
   Huang Q, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1695
   Jain N, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P119, DOI 10.1109/ICVGIP.2008.71
   Kolekar MH, 2011, MULTIMED TOOLS APPL, V54, P27, DOI 10.1007/s11042-010-0544-9
   Kolekar Maheshkumar H, 2009, J Multimed, V4, P298, DOI 10.4304/jmm.4.5.298-312
   Li BX, 2004, J VIS COMMUN IMAGE R, V15, P393, DOI 10.1016/j.jvcir.2004.04.006
   Liang C, 2009, LECT NOTES COMPUT SC, V5879, P684, DOI 10.1007/978-3-642-10467-1_60
   Pan H, 2001, INT CONF ACOUST SPEE, P1649, DOI 10.1109/ICASSP.2001.941253
   Qian X, 2010, P 2 INT C INT MULT C
   Qian X, 2010, MULTIMED TOOLS APPL, V60, P1
   Snoek CGM, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P481
   Tjondronegoro DW, 2010, IEEE T SYST MAN CY A, V40, P1009, DOI 10.1109/TSMCA.2010.2046729
   Wang F, 2004, IEEE IMAGE PROC, P633
   Wang L., 2004, Proceedings of the 6th ACM SIGMM international workshop on Multimedia information retrieval, P259
   Wang T, 2006, P 2006 C COMP VIS PA
   Xie LX, 2002, INT CONF ACOUST SPEE, P4096
   Xu C., 2006, PROC 14 ANN ACM INT, P221, DOI DOI 10.1145/1180639.1180699
   Xu CS, 2008, IEEE T MULTIMEDIA, V10, P421, DOI 10.1109/TMM.2008.917346
   Xu HX, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1243
   Xu Peng., 2001, Proceedings of the 2001 IEEE International Conference on Multimedia and Expo (ICME), P721, DOI [10.1109/ICME.2001.1237822, DOI 10.1109/ICME.2001.1237822]
   Yang ZG, 2007, IEEE IMAGE PROC, P3001
   Yihong Gong, 1995, Proceedings of the International Conference on Multimedia Computing and Systems (Cat. No.95TH8066), P167, DOI 10.1109/MMCS.1995.484921
   Zawbaa HM, 2011, COMM COM INF SC, V263, P19
   Zhang Yu-zhen, 2009, Journal of Nanjing University of Science and Technology, V33, P432
NR 33
TC 22
Z9 22
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 519
EP 546
DI 10.1007/s11042-013-1619-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700025
DA 2024-07-18
ER

PT J
AU Kim, BS
   Moon, YS
   Choi, MJ
   Kim, J
AF Kim, Bum-Soo
   Moon, Yang-Sae
   Choi, Mi-Jung
   Kim, Jinho
TI Interactive noise-controlled boundary image matching using the
   time-series moving average transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Time-series databases; Data mining; Boundary image matching; Time-series
   matching; Moving average transform
AB In this paper we propose a time-series matching-based approach that provides the interactive boundary image matching with noise control for a large-scale image database. To achieve the noise reduction effect in boundary image matching, we exploit the moving average transform of time-series matching. We are motivated by a simple intuition that the moving average transform might reduce the noise of boundary images as well as that of time-series data. To confirm this intuition, we first propose a new notion of k-order image matching, which applies the moving average transform to boundary image matching. A boundary image can be represented as a sequence in the time-series domain, and our k-order image matching identifies similar boundary images in this time-series domain by comparing the k-moving average transformed sequences. We then propose an index-based method that efficiently performs k-order image matching on a large image database, and formally prove its correctness. We also formally analyze the relationship of orders and their matching results and present an interactive approach of controlling the noise reduction effect. Experimental results show that our k-order image matching exploits the noise reduction effect well, and our index-based method outperforms the sequential scan by one or two orders of magnitude. These results indicate that our k-order image matching and its index-based solution provide a very practical way of realizing the noise control boundary image matching. To our best knowledge, the proposed interactive approach for large-scale image databases is the first attempt to solve the noise control problem in the time-series domain rather than the image domain by exploiting the efficient time-series matching techniques. Thus, our approach can be widely used in removing other types of distortions in image matching areas.
C1 [Kim, Bum-Soo] Korea Adv Inst Sci & Technol, AITrc, Taejon 305701, South Korea.
   [Moon, Yang-Sae; Choi, Mi-Jung; Kim, Jinho] Kangwon Natl Univ, Dept Comp Sci, Chunchon 200701, Kangwon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Kangwon
   National University
RP Moon, YS (corresponding author), Kangwon Natl Univ, Dept Comp Sci, 192-1,Hyoja2 Dong, Chunchon 200701, Kangwon, South Korea.
EM bskim@mozart.kaist.ac.kr; ysmoon@kangwon.ac.kr; mjchoi@kangwon.ac.kr;
   jhkim@kangwon.ac.kr
FU Defense Acquisition Program Administration; Agency for Defense
   Development
FX This work was partially supported by Defense Acquisition Program
   Administration and Agency for Defense Development under the contract.
CR Agrawal R., 1994, P INT C FDN DATA ORG, P69
   [Anonymous], P 12 INT C DAT SYST
   [Anonymous], P INT C VER LARG DAT
   [Anonymous], PATTERN RECOGN
   [Anonymous], 1982, Digital Picture Processing
   [Anonymous], P ACM SIGMOD INT C M
   [Anonymous], IEEE T KNOWL DATA EN
   [Anonymous], 2004, ANAL TIME SERIES INT
   [Anonymous], 2002, P 2002 ACM SIGMOD IN, DOI DOI 10.1145/564691.564735
   [Anonymous], P INT C MAN DAT
   [Anonymous], ACM SIGMOD RECORD
   [Anonymous], P 18 IEEE INT C IM P
   BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93605.98741
   Belongie S, 2000, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P20, DOI 10.1109/IVL.2000.853834
   BROWNRIGG DRK, 1984, COMMUN ACM, V27, P807, DOI 10.1145/358198.358222
   Dong YS, 2011, IEEE SIGNAL PROC LET, V18, P247, DOI 10.1109/LSP.2011.2111369
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hajiaboli MR, 2011, INT J COMPUT VISION, V92, P177, DOI 10.1007/s11263-010-0330-1
   Han W.-S., 2007, VERY LARGE DATA BASE, P423
   Hildebrand F.B., 1987, Introduction to numerical analysis courier corporation
   Holte MB, 2010, COMPUT VIS IMAGE UND, V114, P1353, DOI 10.1016/j.cviu.2010.07.012
   Keogh E., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases, P406
   Keogh E, 2009, VLDB J, V18, P611, DOI 10.1007/s00778-008-0111-4
   Lee AJT, 2007, PATTERN RECOGN LETT, V28, P447, DOI 10.1016/j.patrec.2006.08.015
   Loh WK, 2004, DATA MIN KNOWL DISC, V9, P5, DOI 10.1023/B:DAMI.0000026902.89522.a3
   Loh WK, 2001, IEICE T INF SYST, VE84D, P76
   Loh WK, 2007, LECT NOTES COMPUT SC, V4587, P37
   Moon YS, 2007, INFORM SCIENCES, V177, P5415, DOI 10.1016/j.ins.2007.05.038
   Moon YS, 2010, DATA KNOWL ENG, V69, P1022, DOI 10.1016/j.datak.2010.07.001
   Moon YS, 2001, PROC INT CONF DATA, P263, DOI 10.1109/ICDE.2001.914837
   Mori G, 2002, LECT NOTES COMPUT SC, V2352, P666
   Pratt W., 2007, DIGITAL IMAGE PROCES, V4th
   Rafiei D, 1999, PROC INT CONF DATA, P410, DOI 10.1109/ICDE.1999.754957
   Rafiei D, 2000, IEEE T KNOWL DATA EN, V12, P675, DOI 10.1109/69.877502
   SUETENS P, 1992, COMPUT SURV, V24, P5, DOI 10.1145/128762.128763
   Vlachos M., 2005, PROC 14 ACM INT C IN, P131
   Wang ZY, 2000, LECT NOTES COMPUT SC, V1929, P477
   Yang SM, 2012, J VIS COMMUN IMAGE R, V23, P812, DOI 10.1016/j.jvcir.2012.04.007
NR 38
TC 7
Z9 8
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2543
EP 2571
DI 10.1007/s11042-013-1552-3
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300021
DA 2024-07-18
ER

PT J
AU Huang, F
AF Huang, Fay
TI Sensitivity analysis of pose recovery from multi-center panoramas
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Panoramic imaging; Pose estimation; Sensor-line camera
ID SENSORS; STEREO
AB A set of multi-view panoramas may consist of various types of panoramic images in cylindrical representation, such as single-center, multi-center, concentric, symmetric, or (after a transformation onto a cylinder) catadioptric panoramas. In comparison with single-center imaging models, there are fewer studies on multiple view geometry for the multi-center cases. A generalized epipolar curve equation has been derived in a book publication in 2008. This article extends such result and presents a cost function whose minimization solves the camera pose estimation problem. Due to the non-linearity of the multi-centered projection geometry, the modeling of sensor pose estimation typically results into non-linear and highly complicated forms which incur numerical instability. This article focuses on evaluating a method for solving the pose estimation problem under a minor geometrical constraint, namely leveled panoramas. Extensive synthetic and real experiments along with a formal sensitivity analysis are carried out to demonstrate the robustness of the proposed method.
C1 Natl Ilan Univ, CSIE, Yi Lan, Taiwan.
C3 National Ilan University
RP Huang, F (corresponding author), Natl Ilan Univ, CSIE, Yi Lan, Taiwan.
EM fay@niu.edu.tw
FU National Science Council of Taiwan, R.O.C. [NSC 99-2221-E-197 -024, NSC
   100-2221-E-197 -028]
FX This project was sponsored by the National Science Council of Taiwan,
   R.O.C. (NSC 99-2221-E-197 -024 and NSC 100-2221-E-197 -028). The author
   thanks Prof. Reinhard Klette for various valuable comments and Yun-Hao
   Xie and Yin-Wei Chang for help in performing some of the experiments.
CR Chen S. E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P29, DOI 10.1145/218380.218395
   Geyer C, 2000, Proc. European Conf. Computer Vision, P445, DOI [10.1007/3-540-45053-X_29, DOI 10.1007/3-540-45053-X_29]
   Hicks RA, 2000, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2000.855867
   Huang F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P560, DOI 10.1109/ICCV.2001.937566
   Huang F, 2009, P PSIVT09 TOK JAP, P60
   Huang F., 2008, PANORAMIC IMAGING SE
   Huang F, 2008, LECT NOTES COMPUT SC, V5197, P593, DOI 10.1007/978-3-540-85920-8_72
   Huang F, 2010, MULTIMED TOOLS APPL, V47, P353, DOI 10.1007/s11042-009-0328-2
   ISHIGURO H, 1992, IEEE T PATTERN ANAL, V14, P257, DOI 10.1109/34.121792
   Kang SB, 1997, INT J COMPUT VISION, V25, P167, DOI 10.1023/A:1007971901577
   Kang SB, 1998, GRAPHICS INTERFACE '98 - PROCEEDINGS, P223
   Klette R., 2004, DIGITAL GEOMETRY
   Li HF, 2008, CURR MED RES OPIN, V24, P1, DOI 10.1088/0256-307X/24/3/072
   Li Y, 2004, IEEE T PATTERN ANAL, V26, P45, DOI 10.1109/TPAMI.2004.1261078
   MURRAY DW, 1995, COMPUT VIS IMAGE UND, V61, P285, DOI 10.1006/cviu.1995.1021
   Nayar S, 1998, P CVPR97 SAN JAUN PU, P482
   Pajdla T, 2002, INT J COMPUT VISION, V47, P161, DOI 10.1023/A:1014593824520
   Peleg S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P395, DOI 10.1109/CVPR.1999.786969
   REULKE R, 1998, PHOTOGRAMM FERNERKUN, V3, P157
   Scheibe K, 2006, LECT NOTES COMPUT SC, V4319, P96
   Shum HY, 1999, COMP GRAPH, P299, DOI 10.1145/311535.311573
   Sturm P, 2005, PROC CVPR IEEE, P206
   Zomet A, 2003, IEEE T PATTERN ANAL, V25, P741, DOI 10.1109/TPAMI.2003.1201823
NR 23
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1193
EP 1213
DI 10.1007/s11042-013-1438-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300009
DA 2024-07-18
ER

PT J
AU Beecks, C
   Kirchhoff, S
   Seidl, T
AF Beecks, Christian
   Kirchhoff, Steffen
   Seidl, Thomas
TI On stability of signature-based similarity measures for content-based
   image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Feature signature; Distance-based
   similarity measure; Evaluation measure; Average precision stability
ID COLOR
AB Retrieving similar images from large image databases is a challenging task for today's content-based retrieval systems. Aiming at high retrieval performance, these systems frequently capture the user's notion of similarity through expressive image models and adaptive similarity measures. On the query side, image models can significantly differ in quality compared to those stored on the database side. Thus, similarity measures have to be robust against these individual quality changes in order to maintain high retrieval performance. In this paper, we investigate the robustness of the family of signature-based similarity measures in the context of content-based image retrieval. To this end, we introduce the generic concept of average precision stability, which measures the stability of a similarity measure with respect to changes in quality between the query and database side. In addition to the mathematical definition of average precision stability, we include a performance evaluation of the major signature-based similarity measures focusing on their stability with respect to querying image databases by examples of varying quality. Our performance evaluation on recent benchmark image databases reveals that the highest retrieval performance does not necessarily coincide with the highest stability.
C1 [Beecks, Christian; Kirchhoff, Steffen; Seidl, Thomas] Rhein Westfal TH Aachen, Data Management & Data Explorat Grp, Aachen, Germany.
C3 RWTH Aachen University
RP Beecks, C (corresponding author), Rhein Westfal TH Aachen, Data Management & Data Explorat Grp, Aachen, Germany.
EM beecks@cs.rwth-aachen.de; kirchhoff@cs.rwth-aachen.de;
   seidl@cs.rwth-aachen.de
RI Seidl, Thomas/AAY-1753-2020
OI Seidl, Thomas/0000-0002-4861-1412
FU Excellence Initiative of the German federal government; Excellence
   Initiative of the German state government; DFG [SE 1039/7-1]
FX This work is partially funded by the Excellence Initiative of the German
   federal and state governments and by DFG grant SE 1039/7-1.
CR [Anonymous], 2009, CIVR
   Beecks C, 2012, LECT NOTES COMPUT SC, V7131, P346
   Beecks C, 2010, IEEE INT CON MULTI, P1552, DOI 10.1109/ICME.2010.5582949
   Beecks Christian., 2010, ACM International Conference on Image and Video Retrieval, P438, DOI [10.1145/1816041.1816105, DOI 10.1145/1816041.1816105]
   Chávez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Hu R, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1365, DOI 10.1109/ICME.2008.4607697
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Huiskes MarkJ., 2010, Multimedia Information Retrieval, P527
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Kent Allen, 1955, American Documentation, V6, P93, DOI 10.1002/
   Leow WK, 2004, COMPUT VIS IMAGE UND, V94, P67, DOI 10.1016/j.cviu.2003.10.010
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Nister David, 2006, CVPR
   Park BG, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/263071
   Rubner Y, 2001, COMPUT VIS IMAGE UND, V84, P25, DOI 10.1006/cviu.2001.0934
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   van Rijsbergen C. J, 1979, Information Retrieval, V2nd
   Zezula P., 2005, Similarity Search: The Metric Space Approach
NR 26
TC 18
Z9 19
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 1
BP 349
EP 362
DI 10.1007/s11042-012-1334-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK0QX
UT WOS:000338120700021
DA 2024-07-18
ER

PT J
AU Liu, L
   Wang, RM
   Su, Z
   Luo, XN
   Gao, CY
AF Liu, Li
   Wang, Ruomei
   Su, Zhuo
   Luo, Xiaonan
   Gao, Chengying
TI Mesh-based anisotropic cloth deformation for virtual fitting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual fitting; Cloth deformation; Geometric energy; Nonlinear
   optimization; Anisotropic behavior
ID GARMENTS; MODEL
AB According to the anisotropic property in most real-world cloth for virtual fitting, this paper proposes a novel dynamic cloth simulation method via geometric deformation energy model that preserves geometric features well to achieve cloth behaviors with various material effects. We first construct an objective deformation energy with the terms including vertex position, edge length, dihedral angle, and gravitation, then we conduct a numerical solution in the least square sense. In order to establish the dynamic cloth deformation solution, we further analyze the corresponding relationship between different weights in front of geometric energy terms and material properties by comparison with the real photographs of typical real fabrics. Establishing a dynamic weight-regulation measure can model similar cloth anisotropic behaviors for virtual fitting applications in digital home. The experiments show that our approach effectively provide more rich cloth deformation results with distinctive material effects.
C1 [Liu, Li; Wang, Ruomei; Su, Zhuo; Luo, Xiaonan; Gao, Chengying] Sun Yat Sen Univ, Natl Engn Res Ctr Digital Life, State Prov Joint Lab Digital Home Interact Applic, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Liu, Li; Wang, Ruomei; Su, Zhuo; Luo, Xiaonan; Gao, Chengying] Sun Yat Sen Univ, Shenzhen Digital Home Key Technol Engn Lab, Res Inst, Shenzhen 518057, Peoples R China.
   [Liu, Li] Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Kunming 650500, Peoples R China.
   [Liu, Li] Comp Technol Applicat Key Lab Yunnan Prov, Kunming 650500, Peoples R China.
   [Gao, Chengying] Yat Sen Univ, Sch Software, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University; Kunming University of
   Science & Technology
RP Wang, RM (corresponding author), Sun Yat Sen Univ, Natl Engn Res Ctr Digital Life, State Prov Joint Lab Digital Home Interact Applic, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
EM isswrm@mail.sysu.edu.cn; suzhuoi@gmail.com
RI li, chunyuan/IQW-1618-2023; Su, Zhuo/AAO-4506-2020; Liu,
   Li/JAC-5598-2023
OI Su, Zhuo/0000-0002-6090-0110; Liu, Li/0000-0001-9685-6599
FU National Natural Science Foundation of China [61073131, 61272192,
   61100080]; NSFC-Guangdong Joint Fund [U1135003, U0935004]; National Key
   Technology RD Program [2011BAH27B01, 2011BHA16B08];
   Industry-academy-research Project of Guangdong [2011A091000032];
   Ministry of Education
FX This research is supported by the National Natural Science Foundation of
   China (61073131, 61272192, 61100080), NSFC-Guangdong Joint Fund (No.
   U1135003, U0935004), the National Key Technology R&D Program (No.
   2011BAH27B01, 2011BHA16B08), the Industry-academy-research Project of
   Guangdong (No. 2011A091000032), Scholarship Award for Excellent Doctoral
   Student Granted by Ministry of Education 2012.
CR Alexa M, 2003, VISUAL COMPUT, V19, P105, DOI 10.1007/s00371-002-0180-0
   [Anonymous], 2004, P 2004 EUR ACM SIGGR
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   BREEN DE, 1994, TEXT RES J, V64, P663, DOI 10.1177/004051759406401106
   Bridson R., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P28
   Chen M, 2010, VISUAL COMPUT, V26, P853, DOI 10.1007/s00371-010-0467-5
   De Aguiar E, 2010, ACM T GRAPHIC, V29
   Decaudin P, 2006, COMPUT GRAPH FORUM, V25, P625, DOI 10.1111/j.1467-8659.2006.00982.x
   Goldenthal R, 2009, ACM T GRAPHIC, P557
   Graphite, 2010, ALICE GEOM LIGHT, V2
   Hadap S., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P175, DOI 10.1109/VISUAL.1999.809885
   Hinds B. K., 1990, Visual Computer, V6, P53, DOI 10.1007/BF01901066
   Huang J, 2006, COMPUT ANIMAT VIRT W, V17, P383, DOI 10.1002/cav.141
   Huang J, 2006, ACM T GRAPHIC, V25, P1126, DOI 10.1145/1141911.1142003
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   Julius D, 2005, COMPUT GRAPH FORUM, V24, P581, DOI 10.1111/j.1467-8659.2005.00883.x
   Kang MK, 2007, COMPUT GRAPH-UK, V31, P271, DOI 10.1016/j.cag.2006.09.010
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Lipman Y, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P181, DOI 10.1109/SMI.2004.1314505
   Liu Y, 2006, ACM T GRAPHIC, V25, P681, DOI 10.1145/1141911.1141941
   MagnenatThalmann N, 2010, MODELING AND SIMULATING BODIES AND GARMENTS, P1
   Muller Matthias, 2010, Proceedings of the 2010 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P85, DOI [10.5555/1921427.19214412, DOI 10.5555/1921427.19214412]
   Popa T, 2009, COMPUT GRAPH FORUM, V28, P427, DOI 10.1111/j.1467-8659.2009.01382.x
   Popa T, 2006, SHAPE MODELING APPL, P1
   PROVOT X, 1995, GRAPH INTER, P147
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   Sorkine O., 2007, As-rigid-as-possible surface modeling, P109, DOI 10.1145/1281991.1282006
   Tang K, 2009, IEEE T VIS COMPUT GR, V15, P518, DOI 10.1109/TVCG.2008.192
   Thomaszewski B, 2009, COMPUT GRAPH FORUM, V28, P569, DOI 10.1111/j.1467-8659.2009.01397.x
   Wang H, 2010, ACM T GRAPHIC, V29
   Weil J., 1986, Computer Graphics, V20, P49, DOI 10.1145/15886.15891
   Xu W, 2007, ACM T GRAPHIC, V26
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
NR 33
TC 6
Z9 6
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 411
EP 433
DI 10.1007/s11042-013-1437-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400003
DA 2024-07-18
ER

PT J
AU Obal, D
   Stojmenova, E
AF Obal, Damjan
   Stojmenova, Emilija
TI Experience to understand: a methodology for integrating users into the
   design for kitchen interactions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kitchen; Interaction design; User research; User integration;
   Participatory design; Ubiquitous computing
ID SCIENCE
AB The kitchen is a place where many interactions happen every day. It is a place where new technologies and tradition meet. What makes a place a smart kitchen? This article describes our research over 29 months with a group representing typical users-we will call them the kitchen heroes. We involved them in a process of interaction design (IxD) for the kitchen following the tradition of participatory design (PD), to find out the potential of such a collaboration. We asked ourselves how could we, together with the intended users design for better, seamless interaction in the kitchen? Our research showed that designing for kitchen demands a high and consistent level of engagement of all the stakeholders if we are to design a truly smart and human-centred kitchen. How then, could we integrate them into the interaction design process? As an answer we developed a methodology for the integration of all the stakeholders into the whole design process. We focused on the early design phases and the ways to trigger engagement. The methodology we developed is named EPUI and consists of four parts: exploration, participation, understanding and integration. This article illustrates the EPUI methodology for successfully integrating kitchen users into the kitchen interaction design and fruitful participatory design. It is based on and combines benefits from methodologies such as PD, ADR, PADR, while in the article we explain how it also contributes to their flaws. Additionally, we present our lessons learned while implementing the EPUI methodology and offer tools to both seasoned and less-experienced researchers.
C1 [Obal, Damjan] Univ Maribor, SLO-2000 Maribor, Slovenia.
   [Stojmenova, Emilija] Iskratel Doo, Kranj 4000, Slovenia.
C3 University of Maribor
RP Obal, D (corresponding author), Univ Maribor, Slomskov Trg 15, SLO-2000 Maribor, Slovenia.
EM damjan.obal@uni-mb.si
FU European Union, European Social Fund; Ministry of Higher Education,
   Science and Technology of the Republic of Slovenia
FX Author thanks the participants who took part in the evaluation study.
   Operation leading to this paper is partially financed by the European
   Union, European Social Fund. The research and development work was
   carried out within the research program Algorithms and optimization
   methods in telecommunications, which is co-financed by the Ministry of
   Higher Education, Science and Technology of the Republic of Slovenia.
CR [Anonymous], 2011, ELEMENTS USER EXPERI
   [Anonymous], 2009, P 2 INT C PERV TECHN
   [Anonymous], 2005, Theory of fun for game design
   ARGYRIS C, 1989, AM BEHAV SCI, V32, P612, DOI 10.1177/0002764289032005008
   Baskerville R., 1999, Communications of the Association for Information Systems, V19
   Baskerville R, 2007, 2 INT C DES SCI RES
   Baskerville R., 2009, P 4 INT C DES SCI RE, P1
   Beyer H, 1999, INTERACTIONS, V6, P32, DOI DOI 10.1145/291224.291229
   Bilandzic M, 2011, J COMMUNITY INFORM R, V7
   Bodker S, 1996, HUM-COMPUT INTERACT, V11, P215, DOI 10.1207/s15327051hci1103_2
   Bonanni Leonardo., 2005, CHI '05 Extended Abstracts on Human Factors in Computing Systems. CHIEA '05, P1228, DOI DOI 10.1145/1056808.1056883
   Chen J.-hao, 2006, HUMAN FACTORS
   Cooper A., 2007, FACE 3 ESSENTIALS IN
   Davison R, 2004, INFORM SYST J, V14, P65, DOI 10.1111/j.1365-2575.2004.00162.x
   Diaz J, 2008, 1960 BRAUN PRODUCTS
   Genzuk M., 2003, SYNTHESIS ETHNOGRAPH
   Grudin J., 2002, PDC 2002. Proceedings of the Participatory Design Conference, P144
   Hevner AR, 2004, MIS QUART, V28, P75, DOI 10.2307/25148625
   Holzinger A, 2002, ICCHP 02
   Ju W., 2001, EXTENDED ABSTRACTS S, P269, DOI DOI 10.1145/634067.634227
   Kensing F, 1996, P 4 BIENN C PART DES
   Kolko J, 2007, THOGHTS INTERACTION
   Lee C.-H. J., 2006, 2006 International Conference on Intelligent User Interfaces, P348, DOI 10.1145/1111449.1111533
   Lowgren J., 2007, THOUGHTFUL INTERACTI
   Moggridge B., 2007, Designing Interactions
   Obal D, 2011, IGI GLOBAL IN PRESS
   Piller FT, 2005, TOOLKITS IDEA COMPET
   Pogorelc B, 2012, MULTIMED TOOLS APPL, V58, P333, DOI 10.1007/s11042-011-0786-1
   Sanders E, 2002, USER CTR PARTICIPATE
   Sanders E., 2008, CoDesign, V4, P5, DOI DOI 10.1080/15710880701875068
   Sein MK, 2011, MIS QUART, V35, P37
   SUSMAN GI, 1978, ADMIN SCI QUART, V23, P582, DOI 10.2307/2392581
   Von Hippel Eric, 2005, Democratizing Innovation
   Wagner J, 2011, P C PERV COMP TECHN
   Warren JY, 2008, HLTH CARE INFORM REV, V12, P2
NR 35
TC 4
Z9 6
U1 5
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 1
BP 97
EP 117
DI 10.1007/s11042-013-1500-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AK0QX
UT WOS:000338120700006
DA 2024-07-18
ER

PT J
AU Shim, JY
   Kim, SW
AF Shim, Jae-Youn
   Kim, Seong-Whan
TI Design of circular dot pattern code (CDPC) for maximum information
   capacity and robustness on geometric distortion/noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information hiding; Smart book; Information search; Geometric
   distortion; Code design; Context-aware computing; Pattern recognition
AB One dimensional or linear bar code has been used for distribution purposes such as product information and distribution channel identification. Those linear bar codes can support only one directional code layout and also support limited code error detection capability. Two dimensional bar codes (e.g., QR code) extending one dimensional bar codes were developed in database and index based types. Database type barcodes embed full information bits and show weak recognition rate with geometric distortion. Index-based embed only the index information and requires additional network servers to interpret the index information, which leads to limited information storage capacity. Instead of using visible bar codes, we propose CDPC (circular dot pattern code), which is a dot based codes which is more invisible than bar codes. We design CDPC to be more robust to geometric distortion and noise than previous coding schemes using circular template matching. To maximize the information capacity and robustness, we use a circular dot patterns which is more robust to affine transformation. Code can be easily extended according to the number of data circles. If the number of data circle is n, then we can embed data bits. In our experimentation, we set the number of circle to three, and resulting information capacity can be 42 bits per one code. To extract information from a CDPC codes, we perform (1) image capture, (2) identification of dots, (3) graph based topological analysis of dot patterns, (4) template matching between topological graphs using position symbols, and (5) information bit extraction with error correction capability. To evaluate information capacity under various geometric distortions, we experiment our CDPC with StirMark Benchmark's affine transformation (simulation of geometric and noise attacks) and with real cell phone image captures. Our experimental results also show that our CDPC scheme achieves more robust recognition performance than those proposed in previous research works including QR code.
C1 [Shim, Jae-Youn; Kim, Seong-Whan] Univ Seoul, Sch Comp Sci, Seoul 130743, South Korea.
C3 University of Seoul
RP Kim, SW (corresponding author), Univ Seoul, Sch Comp Sci, 13 Siripdae Gil, Seoul 130743, South Korea.
EM simpo@uos.ac.kr; swkim7@uos.ac.kr
FU Business for International Cooperative R&D between Industry, Academy,
   and Research Institute
FX This work was supported by Business for International Cooperative R&D
   between Industry, Academy, and Research Institute funded Korea Small and
   Medium Business Administration in 2010
CR [Anonymous], 2007, UCC SPEC V 6 0
   [Anonymous], 1978, COUNTEREXAMPLES TOPO, DOI DOI 10.1007/978-1-4612-6290-9
   Brown S.A., 1997, REVOLUTION CHECKOUT
   Bulan O, 2009, P SPIE MEDIA FORENSI, V7254
   Denso Wave Inc, 2011, QUICK RESP COD PRINT
   Duda R. O., 2000, PATTERN CLASSIFICATI
   FISHER R, 1997, HYPERMEDIA IMAGE PRO
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Grillo A., 2010, Proceedings 2010 International Multiconference on Computer Science and Information Technology (IMCSIT 2010), P709
   *INT ORG STAND, 2000, 18004 ISOIEC
   Kato H, 2007, TENCON IEEE REGION, P28
   Kato H, 2010, 2010 INT S INT SIGN
   López-De-Ipiña D, 2002, PERS UBIQUIT COMPUT, V6, P206, DOI 10.1007/s007790200020
   Madhavapeddy A, 2004, 6 INT C UB COMP UBIC
   Microsoft Research, 2007, HIGH CAP COL BARC
   PAVLIDIS T, 1990, COMPUTER, V23, P74, DOI 10.1109/2.55471
   Petitcolas FAP, 1998, LECT NOTES COMPUT SC, V1525, P218
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Querini M., 2011, Int. J. Comput. Sci. Appl., V8, P136
   Rohs M, 2005, LECT NOTES COMPUT SC, V3598, P74
   Sali E., 2006, U.S. Patent, Patent No. 7210631
   WEISER M, 1993, COMMUN ACM, V36, P75, DOI 10.1145/159544.159617
   Weiser M., 1991, COMPUTER 21 CENTURY
NR 23
TC 2
Z9 2
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1941
EP 1955
DI 10.1007/s11042-012-1222-x
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500025
DA 2024-07-18
ER

PT J
AU Cusano, C
   Santini, S
AF Cusano, Claudio
   Santini, Simone
TI With a little help from my friends Community-based assisted organization
   of personal photographs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personal photography; Automatic image annotation; Content-based image
   analysis; Social image retrieval
ID IMAGE CLASSIFICATION
AB In this paper, we propose a content-based method the for semi-automatic organization of photo albums based on the analysis of how different users organize their own pictures. The goal is to help the user in dividing his pictures into groups characterized by a similar semantic content. The method is semi-automatic: the user starts to assign labels to the pictures and unlabeled pictures are tagged with proposed labels. The user can accept the recommendation or made a correction. To formulate the suggestions is exploited the knowledge encoded in how other users have partitioned their images. The method is conceptually articulated in two parts. First, we use a suitable feature representation of the images to model the different classes that the users have collected, second, we look for correspondences between the criteria used by the different users. Boosting is used to integrate the information provided by the analysis of multiple users. A quantitative evaluation of the proposed approach is obtained by simulating the amount of user interaction needed to annotate the albums of a set of members of the flickr (R) photo-sharing community.
C1 [Cusano, Claudio] Univ Milano Bicocca, Dept Informat Syst & Commun DISCo, I-20126 Milan, Italy.
   [Santini, Simone] Univ Autonoma Madrid, Escuela Politecn Super, E-28049 Madrid, Spain.
C3 University of Milano-Bicocca; Autonomous University of Madrid
RP Cusano, C (corresponding author), Univ Milano Bicocca, Dept Informat Syst & Commun DISCo, Viale Sarca 336, I-20126 Milan, Italy.
EM claudio.cusano@disco.unimib.it; simone.santini@uam.es
RI Cusano, Claudio/AAH-1115-2019; Santini, Simone/B-7219-2014; Cusano,
   Claudio/T-2948-2019
OI Cusano, Claudio/0000-0001-9365-8167; 
FU Ministerio de Educacion y Ciencia [MEC TIN2008-06566-C04-02]
FX S. Santini was supported in part by the Ministerio de Educacion y
   Ciencia under the grant N. MEC TIN2008-06566-C04-02, Information
   Retrieval on different media based on multidimensional models:
   relevance, novelty, personalization and context.
CR [Anonymous], 2003, ACM Multimedia Conference
   Boutell M, 2004, PROC CVPR IEEE, P623
   Chen L, 2003, INT J IMAGE GRAPHICS
   Das M, 2003, IEEE SYS MAN CYBERN, P3726
   Furht B, 1998, HDB MULTIMEDIA COMPU
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Ivory MY, 2001, ACM COMPUT SURV, V33, P470, DOI 10.1145/503112.503114
   Jaimes A, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P528, DOI 10.1109/ICIP.2000.899485
   Li J, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P1536
   Li Xirong., 2008, Proceedings of the 1st ACM International Conference on Multimedia Information Retrieval, MIR '08, P180
   Loui AC, 2003, IEEE T MULTIMEDIA, V5, P390, DOI 10.1109/TMM.2003.814723
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mulhem P, 2003, P INT C IM VID RETR, P308
   Nister David, 2006, CVPR
   Obrador P., 2010, PROC 18 ACM INT C MU, P561
   Platt JC, 2000, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P96, DOI 10.1109/IVL.2000.853847
   Shevade B, 2003, P ACM SIGMM WORKSH E, P91
   Sun Y., 2002, Proceedings of the Tenth ACM International Conference on Multimedia, P81, DOI DOI 10.1145/641007.641022
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   Vailaya A, 1998, PATTERN RECOGN, V31, P1921, DOI 10.1016/S0031-3203(98)00079-X
   Vedaldi A., 2005, SIFT LIGHTWEIGHT C I
   Wallraven C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P257
   Wenyin L, 2000, P 8 ACM INT C MULT, P479
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhu J, 2005, D91 SECURESCM
NR 25
TC 1
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 1033
EP 1048
DI 10.1007/s11042-012-1096-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900020
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Vezzetti, E
   Marcolin, F
AF Vezzetti, Enrico
   Marcolin, Federica
TI Geometry-based 3D face morphology analysis: soft-tissue landmark
   formalization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D models; 3D scanners; Face morphology; Soft tissue landmarks
ID POINT LANDMARKS
AB The face is perhaps the most important human anatomical part, and its study is very important in many fields, such as the medical one and the identification one. Technical literature presents many works on this topic involving bi-dimensional solutions. Even if these solutions are able to provide interesting results, they are strongly subjected to images distortion. Thanks to the significant improvements obtained in the 3D scanner domain (photogrammetry for instance), today it is possible to replace the 2D images with more precise and complete 3D models (triangulated points clouds). Working on three-dimensional data, in fact, it is possible to obtain a more complete set of information about the face morphology. At present, even if it is possible to find interesting papers on this field, there is the lack of a complete protocol for converting the big amount of data coming from the three-dimensional point clouds in a reliable set of facial data, which could be employed for recognition and medical tasks. Starting from some anatomical human face concepts, it has been possible to understand that some soft-tissue landmarks could be the right data set for supporting many processes working on three-dimensional models. So, working in the Differential Geometry domain, through the Coefficients of the Fundamental Forms, the Principal Curvatures, Mean and Gaussian Curvatures and also with the derivatives and the Shape and Curvedness Indexes, the study has proposed a structured methodology for soft-tissue landmark formalization in order to provide a methodology for their automatic identification. The proposed methodology and its sensitivity have been tested with the involvement of a series of subjects acquired in different scenarios.
C1 [Vezzetti, Enrico; Marcolin, Federica] Politecn Torino, Dipartimento Ingn Gestionale & Prod, Turin, Italy.
C3 Polytechnic University of Turin
RP Vezzetti, E (corresponding author), Politecn Torino, Dipartimento Ingn Gestionale & Prod, Turin, Italy.
EM enrico.vezzetti@polito.it
OI VEZZETTI, Enrico/0000-0001-8910-7020; Marcolin,
   Federica/0000-0002-4360-6905
CR Alker M., 2001, Medical Image Computing and Computer-Assisted Intervention-MICCAI 2001, P582
   [Anonymous], CYB COL 3D DIG PROD
   [Anonymous], THESIS DEP PRODUCTIO
   [Anonymous], IEEE 3 INT C BIOM TH
   [Anonymous], 2006, INDIGENOUS LANGUAGE
   Ansari AN, 2005, PATTERN RECOGN, V38, P2549, DOI 10.1016/j.patcog.2005.04.016
   Berretti S, 2011, VISUAL COMPUT, V27, P1021, DOI 10.1007/s00371-011-0611-x
   Bichke B., 2008, P 2008 ACM SIGGRAPH
   Blanz V, 2008, P 26 ANN C COMP GRAP, P187
   D'Hose J., 2007, IEEE Conference on Biometrics: Theory, Applications and Systems, BTAS'07, P1
   Do Carmo M., 1976, Differential Geometry of Curves and Surfaces
   Frantz S, 2005, IMAGE VISION COMPUT, V23, P956, DOI 10.1016/j.imavis.2005.05.019
   Frantz S., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P687, DOI 10.1007/BFb0055698
   Frantz S, 2000, LECT NOTES COMPUT SC, V1935, P492
   Frantz S, 1999, LECT NOTES COMPUT SC, V1679, P253
   Gray A, 2006, MODERN DIFFERENTIAL
   KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F
   Mortara M, 2006, COMPUT GRAPH-UK, V30, P185, DOI 10.1016/j.cag.2006.01.024
   Romero M, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P73, DOI 10.1109/AVSS.2009.90
   Ruiz M. C., 2008, 5th International Conference on Visual Information Engineering, VIE 2008, P41, DOI 10.1049/cp:20080280
   Sang-Jun Park, 2008, 2008 International Conference on Control, Automation and Systems (ICCAS), P1881, DOI 10.1109/ICCAS.2008.4694404
   Wörz S, 2006, MED IMAGE ANAL, V10, P41, DOI 10.1016/j.media.2005.02.003
NR 22
TC 21
Z9 23
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 895
EP 929
DI 10.1007/s11042-012-1091-3
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000019
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, XY
   Zhang, BB
   Yang, HY
AF Wang, Xiang-Yang
   Zhang, Bei-Bei
   Yang, Hong-Ying
TI Content-based image retrieval by integrating color and texture features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Opponent chromaticity space;
   Pseudo-Zernike moments; Steerable pyramid decomposition
ID ROTATION-INVARIANT; HISTOGRAM
AB Content-based image retrieval (CBIR) has been an active research topic in the last decade. Feature extraction and representation is one of the most important issues in the CBIR. In this paper, we propose a content-based image retrieval method based on an efficient integration of color and texture features. As its color features, pseudo-Zernike chromaticity distribution moments in opponent chromaticity space are used. As its texture features, rotation-invariant and scale-invariant image descriptor in steerable pyramid domain are adopted, which offers an efficient and flexible approximation of early processing in the human visual system. The integration of color and texture information provides a robust feature set for color image retrieval. Experimental results show that the proposed method yields higher retrieval accuracy than some conventional methods even though its feature vector dimension is not higher than those of the latter for different test DBs.
C1 [Wang, Xiang-Yang; Zhang, Bei-Bei; Yang, Hong-Ying] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Wang, XY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com
RI Yang, Jing/JFK-4046-2023
OI Yang, Jing/0009-0004-8274-9863
FU National Natural Science Foundation of China [60773031, 60873222]; Open
   Foundation of State Key Laboratory of Information Security of China
   [04-06-1]; Open Foundation of Network and Data Security Key Laboratory
   of Sichuan Province; Open Foundation of Key Laboratory of Modern
   Acoustics Nanjing University [08-02]; Liaoning Research Project for
   Institutions of Higher Education of China [2008351, L2010230]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 60773031 & 60873222, the Open Foundation of State
   Key Laboratory of Information Security of China under Grant No. 04-06-1,
   the Open Foundation of Network and Data Security Key Laboratory of
   Sichuan Province, the Open Foundation of Key Laboratory of Modern
   Acoustics Nanjing University under Grant No. 08-02, and Liaoning
   Research Project for Institutions of Higher Education of China under
   Grant No. 2008351 & L2010230.
CR [Anonymous], 2009, ICIVR
   [Anonymous], 2010, 7 INT C INF TECHN NE, P200
   Aptoula E, 2009, IEEE T IMAGE PROCESS, V18, P2505, DOI 10.1109/TIP.2009.2027363
   Baaziz N, 2010, COMPUTER VISION PATT, DOI CoRRabs/1012.5208
   Balamurugan V., 2011, EUROPEAN J SCI RES, V48, P648
   Barla Sathya, 2010, NAT C COMM NCC, P1
   Benmokhtar R., 2008, ACM INT C MULT INF R, P336
   Penatti OAB, 2008, SIBGRAPI, P163, DOI 10.1109/SIBGRAPI.2008.20
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015
   He ZY, 2009, SIGNAL PROCESS, V89, P1501, DOI 10.1016/j.sigpro.2009.01.021
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kokare M, 2007, PATTERN RECOGN LETT, V28, P1240, DOI 10.1016/j.patrec.2007.02.006
   Lin Chuen-Horng, 2010, COMPUT J, V53, DOI [10.1093/comjnl/bxq066, DOI 10.1093/C0MJNL/BXQ066]
   Lu TC, 2007, INFORM PROCESS MANAG, V43, P461, DOI 10.1016/j.ipm.2006.07.014
   Luca C, 2010, P SPIE, P7535
   Min R, 2009, PATTERN RECOGN, V42, P147, DOI 10.1016/j.patcog.2008.07.001
   Monteith J., 2008, ENV PHYS, V3rd, P1
   Rasheed Waqas, 2008, 2008 Second Asia International Conference on Modeling & Simulation, P322, DOI 10.1109/AMS.2008.76
   Raziel A, 2007, ACCURATE COLOR CLASS
   Saykol E, 2005, IMAGE VISION COMPUT, V23, P1170, DOI 10.1016/j.imavis.2005.07.015
   Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444
   Syam B., 2010, 2010 2nd IEEE International Conference on Information Management and Engineering (ICIME 2010), P289, DOI 10.1109/ICIME.2010.5477856
   Tsai MH, 2009, MATH PROBL ENG, V2009, DOI 10.1155/2009/410243
   Tse-Wei Chen, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P854, DOI 10.1109/ICCVW.2009.5457612
   Tzagkarakis G, 2008, IEEE T IMAGE PROCESS, V17, P1212, DOI 10.1109/TIP.2008.924390
   Wang XY, 2011, COMPUT STAND INTER, V33, P59, DOI 10.1016/j.csi.2010.03.004
   [王向阳 Wang Xiangyang], 2010, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V23, P216
   Xia SX, 2011, APPL MECH MATER, V50-51, P639, DOI 10.4028/www.scientific.net/AMM.50-51.639
   Xu PF, 2010, P SPIE C VIS COMM IM
   Yang NC, 2008, J VIS COMMUN IMAGE R, V19, P92, DOI 10.1016/j.jvcir.2007.05.003
   Yap PT, 2006, IEE P-VIS IMAGE SIGN, V153, P17, DOI 10.1049/ip-vis:20045064
   Yue J, 2011, MATH COMPUT MODEL, V54, P1121, DOI 10.1016/j.mcm.2010.11.044
   Zhang J, 2010, COMPUT ELECTR ENG, V36, P691, DOI 10.1016/j.compeleceng.2008.11.001
NR 35
TC 75
Z9 80
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 545
EP 569
DI 10.1007/s11042-012-1055-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000003
DA 2024-07-18
ER

PT J
AU Marciniak, T
   Dabrowski, A
   Chmielewska, A
   Krzykowska, AA
AF Marciniak, Tomasz
   Dabrowski, Adam
   Chmielewska, Agata
   Krzykowska, Agnieszka Anna
TI Selection of parameters in iris recognition system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iris recognition; Biometric; CASIA; IrisBath
ID IMAGES
AB This paper presents the detailed analysis of implementation issues occurred during preparation of the novel iris recognition system. First, we shortly describe the currently available acquisition systems and databases of iris images, which were used for our tests. Next, we concentrate on the feature extraction and coding with the execution time analysis. Results of the average execution time of loading the image, segmentation, normalization, and feature encoding, are presented. Finally, DET plots illustrate the recognition accuracy for IrisBath database.
C1 [Marciniak, Tomasz; Dabrowski, Adam; Chmielewska, Agata; Krzykowska, Agnieszka Anna] Poznan Univ Tech, Chair Control & Syst Engn, Div Signal Proc & Elect Syst, PL-60965 Poznan, Poland.
C3 Poznan University of Technology
RP Krzykowska, AA (corresponding author), Poznan Univ Tech, Chair Control & Syst Engn, Div Signal Proc & Elect Syst, Ul Piotrowo 3A, PL-60965 Poznan, Poland.
EM tomasz.marciniak@put.poznan.pl; adam.dabrowski@put.poznan.pl;
   agata.chmielewska@put.poznan.pl; agnieszka.krzykowska@put.poznan.pl
RI Stankiewicz, Agnieszka/R-1919-2019; Dabrowski, Adam M./O-6053-2014;
   Marciniak, Tomasz/L-4702-2014
OI Stankiewicz, Agnieszka/0000-0002-2983-897X; Marciniak,
   Tomasz/0000-0001-6035-7325
CR [Anonymous], 2009, DESCRIPTION IRIS ACQ
   [Anonymous], 2011, IRIS MOVE SYSTEM
   [Anonymous], 2009, PAN IR READ BM ET330
   [Anonymous], 2006, IRIACCESS 4000 MAIN
   Boles WW, 1998, IEEE T SIGNAL PROCES, V46, P1185, DOI 10.1109/78.668573
   Chinese Academy of Sciences' Institute of Automation, 2010, CASIA IRISV3
   Dabrowski A, 2010, D7 3 BIOMETRIC FEATU
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Dobes M., 2003, IRIS DATABASE
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   International Organization for Standardization, 2005, 197946 ISOIEC
   Kaminski T, 2007, THESIS POZNAN U TECH
   Kovesi P, 2010, SOME MY MATLAB FUNCT
   Ma L, 2004, IEEE T IMAGE PROCESS, V13, P739, DOI 10.1109/TIP.2004.827237
   Ma L, 2003, IEEE T PATTERN ANAL, V25, P1519, DOI 10.1109/TPAMI.2003.1251145
   Masek L., 2003, THESIS U W AUSTR
   Monro DM, 2007, IEEE T PATTERN ANAL, V29, P586, DOI 10.1109/TPAMI.2007.1002
   Pereira MB, 2005, METHOD IMPROVING REL
   Poursaberi A, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/36751
   Poursaberi A., 2005, P ISDA
   Proenca H., 2009, IEEE T PATTERN ANAL, DOI [10.1016/j.imavis.2009.03.003, DOI 10.1016/J.IMAVIS.2009.03.003]
   Sanchez-Avila C, 2005, PATTERN RECOGN, V38, P231, DOI 10.1016/j.patcog.2004.07.004
   Signal and Image Processing Group (SIPG), 2007, U BATH IR IM DAT
   VATSA M, 2005, INT J SIGNAL PROCESS, V2, P66
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Yu L, 2005, PATTERN RECOGN, V38, P1791, DOI 10.1016/j.patcog.2005.03.015
NR 26
TC 13
Z9 13
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 1
BP 193
EP 208
DI 10.1007/s11042-012-1035-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 283JZ
UT WOS:000329243600012
OA hybrid
DA 2024-07-18
ER

PT J
AU Margetis, G
   Zabulis, X
   Koutlemanis, P
   Antona, M
   Stephanidis, C
AF Margetis, George
   Zabulis, Xenophon
   Koutlemanis, Panagiotis
   Antona, Margherita
   Stephanidis, Constantine
TI Augmented interaction with physical books in an Ambient Intelligence
   learning environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Augmented books; Page recognition; Gesture
   recognition; Pose estimation; Handwriting; Ambient intelligence
ID TECHNOLOGIES; REALITY
AB This paper presents an augmented reality environment for students' improved learning, which is based on unobtrusive monitoring of the natural reading and writing process. This environment, named SESIL, is able to perform recognition of book pages and of specific elements of interest within a page, as well as to perceive interaction with actual books and pens/pencils, without requiring any special interaction device. As a result, unobtrusive, context - aware student assistance can be provided. In this way, the learning process can be enhanced during reading with the retrieval and presentation of related material and, during writing, by the provision of assistance to accomplish writing tasks whenever appropriate. The SESIL environment is evaluated in terms of robustness, accuracy and usability.
C1 [Margetis, George; Zabulis, Xenophon; Koutlemanis, Panagiotis; Antona, Margherita; Stephanidis, Constantine] Fdn Res & Technol Hellas FORTH, Inst Comp Sci, GR-70013 Iraklion, Crete, Greece.
   [Stephanidis, Constantine] Univ Crete, Dept Comp Sci, Iraklion, Crete, Greece.
C3 University of Crete
RP Margetis, G (corresponding author), Fdn Res & Technol Hellas FORTH, Inst Comp Sci, GR-70013 Iraklion, Crete, Greece.
EM gmarget@ics.forth.gr; zabulis@ics.forth.gr; koutle@ics.forth.gr;
   antona@ics.forth.gr; cs@ics.forth.gr
RI Margetis, George/Y-1826-2019; Zabulis, Xenophon/D-6186-2011
OI Margetis, George/0000-0002-9101-6301; Zabulis,
   Xenophon/0000-0002-1520-4327; Antona, Margherita/0000-0003-3208-3755;
   Stephanidis, Constantine/0000-0003-3687-4220
FU Foundation for Research and Technology Hellas - Institute of Computer
   Science (FORTH-ICS) internal RTD Programme
FX This work is supported by the Foundation for Research and Technology
   Hellas - Institute of Computer Science (FORTH-ICS) internal RTD
   Programme 'Ambient Intelligence and Smart Environments' [15]. The
   authors would like to thank Mrs. Stavroula Ntoa for her contribution to
   the usability evaluation of SESIL.
CR Aarts E, 2008, CANADIAN J LEARNING
   ABRAMI PC, 2006, CANADIAN J LEARNING, V32
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], DICTIONARIES
   [Anonymous], ISO FDIS 9241 210 20
   [Anonymous], FORTH ICS AMBIENT IN
   Anoto, 2002, DEVELOPMENT GUIDE FO
   Antona M, 2010, P 2010 AHFE INT C 3
   Artifex Software Inc., MUPDF A LIGHTWEIGHT
   Ayache N., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P422
   Baillard C., 1999, Conference on Automatic Extraction of GIS Objects from Digital Imagery, IAPRS, V32, P69
   Billinghurst M, 2001, IEEE COMPUT GRAPH, V21, P6, DOI 10.1109/38.920621
   Bookstein F., 1997, MORPHOMETRIC TOOLS L
   Cook DJ, 2007, PERVASIVE MOB COMPUT, V3, P53, DOI 10.1016/j.pmcj.2006.12.001
   Cook DJ, 2009, PERVASIVE MOB COMPUT, V5, P277, DOI 10.1016/j.pmcj.2009.04.001
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Forsberg Andrew S., 1998, Proceedings of the Second International Immersive Projection Technology Workshop, P11
   Gelb A., 1989, Applied Optimal Estimation
   Grasset Raphael., 2007, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems Extended Abstracts (CHI EA'07), P1953, DOI DOI 10.1145/1240866.1240931
   Hile H, 2004, LECT NOTES COMPUT SC, V3001, P323
   IEEE LOM, 2002, IEEE 1484 12 1
   Ishii H., 1997, P ACM SIGCHI C HUM F, P234, DOI DOI 10.1145/258549.258715
   Kobayashi M, 1998, PHOTOSYNTHESIS: MECHANISMS AND EFFECTS, VOLS I-V, P57, DOI 10.1109/APCHI.1998.704149
   Law ELC, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P719
   Leonidis A, 2011, WORLD ACAD SCI ENG T, V66, P594
   Liao C, 2008, ACM T COMPUT-HUM INT, V14, DOI 10.1145/1314683.1314686
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lowe DG, 1987, ARTIF INTELL, V3, P355
   Luff P., 2004, Computer Supported Cooperative Work Conference Proceedings, P523, DOI 10.1145/1031607.1031695
   Mangen A, 2010, ADVANCES IN HAPTICS, P385
   Martinec D, 2003, PROC CVPR IEEE, P497
   Michel D, 2009, P IAPR C MACH VIS AP, P74
   Microsoft, MICROSOFT INK ANALYS
   Moons T., 1998, EUR C COMP VIS, P410
   Nickel K, 2007, IMAGE VISION COMPUT, V25, P1875, DOI 10.1016/j.imavis.2005.12.020
   Nielsen J., 1994, Usability inspection methods, P25, DOI [10.5555/189200.189209, DOI 10.5555/189200.189209, DOI 10.1089/TMJ.2010.0114]
   Quan L, 1997, IEEE T PATTERN ANAL, V19, P834, DOI 10.1109/34.608285
   Quesenbery W., 2003, Content and complexity: Information design in technical communication, P75
   Schmalstieg D, 2002, PRESENCE-VIRTUAL AUG, V11, P33, DOI 10.1162/105474602317343640
   Shi YC, 2003, IEEE PERVAS COMPUT, V2, P47, DOI 10.1109/MPRV.2003.1203753
   Simon A, 2005, LECT NOTES COMPUT SC, V3585, P364, DOI 10.1007/11555261_31
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Torr PHS, 1997, IMAGE VISION COMPUT, V15, P591, DOI 10.1016/S0262-8856(97)00010-3
   Wellner P., 1993, COMMUN ACM, V36, P87
   Woo DM, 2009, ICDIP 2009: INTERNATIONAL CONFERENCE ON DIGITAL IMAGE PROCESSING, PROCEEDINGS, P127, DOI 10.1109/ICDIP.2009.31
   Zabulis X., 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P104, DOI 10.1007/978-3-642-24031-7_11
   Zabulis X, 2010, LECT NOTES COMPUT SC, V6454, P584, DOI 10.1007/978-3-642-17274-8_57
NR 48
TC 25
Z9 28
U1 2
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 2
BP 473
EP 495
DI 10.1007/s11042-011-0976-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 205HY
UT WOS:000323435800008
DA 2024-07-18
ER

PT J
AU Verbist, F
   Deligiannis, N
   Jacobs, M
   Barbarien, J
   Schelkens, P
   Munteanu, A
   Cornelis, J
AF Verbist, Frederik
   Deligiannis, Nikos
   Jacobs, Marc
   Barbarien, Joeri
   Schelkens, Peter
   Munteanu, Adrian
   Cornelis, Jan
TI Probabilistic motion-compensated prediction in distributed video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wyner-Ziv coding; Distributed video coding; Hash-based side information
   generation; Probabilistic motion compensation
ID SIDE-INFORMATION
AB Distributed video coding (DVC) constitutes an original coding framework to meet the stringent requirements imposed by uplink-oriented and low-power mobile video applications. The quality of the side information available to the decoder and the efficiency of the employed channel codes are primary factors determining the success of a DVC system. This contribution introduces two novel techniques for probabilistic motion compensation in order to generate side information at the Wyner-Ziv decoder. The employed DVC scheme uses a base layer, serving as a hash to facilitate overlapped block motion estimation at the decoder side. On top of the base layer, a supplementary Wyner-Ziv layer is coded in the DCT domain. Both proposed probabilistic motion compensation techniques are driven by the actual correlation channel statistics and reuse information contained in the hash. Experimental results report significant rate savings caused by the novel side information generation methods compared to previous techniques. Moreover, the compression performance of the presented DVC architecture, featuring the proposed side-information generation techniques, delivers state-of-the-art compression performance.
C1 [Verbist, Frederik; Deligiannis, Nikos; Jacobs, Marc; Barbarien, Joeri; Schelkens, Peter; Munteanu, Adrian; Cornelis, Jan] Vrije Univ Brussel, Dept Elect & Informat ETRO, B-1050 Brussels, Belgium.
   [Verbist, Frederik; Deligiannis, Nikos; Jacobs, Marc; Barbarien, Joeri; Schelkens, Peter; Munteanu, Adrian] Interdisciplinary Inst Broadband Technol IBBT, B-9050 Ghent, Belgium.
C3 Vrije Universiteit Brussel
RP Verbist, F (corresponding author), Vrije Univ Brussel, Dept Elect & Informat ETRO, Pl Laan 2, B-1050 Brussels, Belgium.
EM fverbist@etro.vub.ac.be
RI Munteanu, Adrian/HKO-9955-2023; Cornelis, Jan/ABI-6396-2020; Schelkens,
   Peter/B-7831-2008; Jacobs, Marc/GYU-0672-2022; Jacobs,
   Marc/AAF-4693-2020; Deligiannis, Nikos/ABH-2381-2020
OI Munteanu, Adrian/0000-0001-7290-0428; Cornelis, Jan/0000-0002-1180-1968;
   Schelkens, Peter/0000-0003-0908-1655; Jacobs, Marc/0000-0003-4153-3930;
   Jacobs, Marc/0000-0002-5967-3053; Deligiannis, Nikos/0000-0001-9300-5860
FU Fund for Scientific Research (FWO) Flanders [G.0391.07]; Flemish
   Institute for the Promotion of Innovation by Science and Technology
   (IWT)
FX This work was supported by the Fund for Scientific Research (FWO)
   Flanders (i.e. the postdoctoral fellowship of Peter Schelkens and the
   project G.0391.07. - N. Deligiannis) and by the Flemish Institute for
   the Promotion of Innovation by Science and Technology (IWT) - PhD
   bursary Frederik Verbist.
CR Aaron A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P869
   AARON A, 2004, IEEE INT C IM PROC I
   Adikari ABB, 2006, ELECTRON LETT, V42, P398, DOI 10.1049/el:20060302
   [Anonymous], SPIE VIS COMM IM PRO
   [Anonymous], 2005, PROC 5 EURASIP C SPE
   Artigas X, 2007, PICT COD S PCS 2007
   ASCENSO J, 2006, IEEE INT C IM PROC A
   Ascenso J, 2009, MULTIMEDIA TOOLS APP
   Astély D, 2009, IEEE COMMUN MAG, V47, P44, DOI 10.1109/MCOM.2009.4907406
   Bjontegaard G., 2001, CALCULATION AVERAGE
   Brites C, 2008, SIGNAL PROCESS-IMAGE, V23, P269, DOI 10.1016/j.image.2008.03.002
   Ciobanu L, 2010, MULTIMED TOOLS APPL, V48, P411, DOI 10.1007/s11042-009-0315-7
   Deligiannis N., 2009, IEEE INT C DIG SIGN
   Deligiannis N, 2009, INT CONF ACOUST SPEE, P709, DOI 10.1109/ICASSP.2009.4959682
   Deligiannis N, 2009, IEEE SIGNAL PROC LET, V16, P743, DOI 10.1109/LSP.2009.2024111
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Guo X, 2008, IEEE T CIRC SYST VID, V18, P713, DOI 10.1109/TCSVT.2008.920970
   Khirallah C, 2009, SPRINGER MULTIMED TO, V48, P457
   Kubasov D, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P251, DOI 10.1109/MMSP.2007.4412865
   Martins R, 2009, IEEE T CIRC SYST VID, V19, P1327, DOI 10.1109/TCSVT.2009.2022783
   Mys S, 2010, SPRINGER MULTIMEDIA
   ORCHARD MT, 1994, IEEE T IMAGE PROCESS, V3, P693, DOI 10.1109/83.334974
   PEREIRA F, 2007, IEEE PAC RIM S IM VI
   Pradhan SS, 2003, IEEE T INFORM THEORY, V49, P1181, DOI 10.1109/TIT.2003.810622
   PURI R, 2002, 40 ALL C COMM CONTR
   Puri R, 2007, IEEE T IMAGE PROCESS, V16, P2436, DOI 10.1109/TIP.2007.904949
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Slowack J, 2011, IEEE T CIRC IN PRESS
   Varodayan D, 2006, SIGNAL PROCESS, V86, P3123, DOI 10.1016/j.sigpro.2006.03.012
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Xiong ZX, 2004, IEEE SIGNAL PROC MAG, V21, P80, DOI 10.1109/MSP.2004.1328091
   Xu Q, 2007, IEEE J SEL AREA COMM, V25, P851, DOI 10.1109/JSAC.2007.070520
   Zamir R, 1996, IEEE T INFORM THEORY, V42, P2073, DOI 10.1109/18.556597
   Zhang YX, 2008, IEEE T MULTIMEDIA, V10, P1648, DOI 10.1109/TMM.2008.2007324
NR 36
TC 3
Z9 5
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2013
VL 66
IS 3
BP 405
EP 430
DI 10.1007/s11042-012-1050-z
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 179TX
UT WOS:000321545300004
DA 2024-07-18
ER

PT J
AU Peiris, RL
   Tharakan, MJ
   Fernando, ONN
   Cheok, AD
AF Peiris, Roshan Lalintha
   Tharakan, Mili John
   Fernando, Owen Noel Newton
   Cheok, Adrian David
TI AmbiKraf
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Thermochromic; Peltier; Thermoelectric; Ambient; Textile; Ubiquitous;
   Fabric; Display; Wearable
ID SEMANTIC AMBIENT MEDIA
AB This paper presents, AmbiKraf, a non-emissive fabric display that subtly animates patterns on common fabrics. We use thermochromic inks and peltier semiconductor elements to achieve this technology. With this technology we have produced numerous prototypes from animated wall paintings to pixilated fabric displays. The ability of this technology to subtly and ubiquitously change the color of the fabric itself has made us able to merge different fields and technologies with AmbiKraf. In addition, with an animated room divider screen, Ambikraf merged its technology with Japanese Byobu art to tighten the gap between traditional arts and contemporary technologies. Through this AmbiKraf Byobu art installation and other installations, we discuss the impact of this technology as a ubiquitous fabric display. With focus to improvements of some limitations of the existing system, we present our future vision that enables us to merge this technology into more applications fields thus making this technology a platform for ubiquitous interactions on our daily peripherals.
C1 [Peiris, Roshan Lalintha] Natl Univ Singapore, NUS Grad Sch Integrat Sci & Engn, Keio NUS CUTE Ctr, Singapore 117548, Singapore.
   [Tharakan, Mili John; Fernando, Owen Noel Newton; Cheok, Adrian David] Natl Univ Singapore, Keio NUS CUTE Ctr, Singapore 117548, Singapore.
C3 National University of Singapore; National University of Singapore
RP Peiris, RL (corresponding author), Natl Univ Singapore, NUS Grad Sch Integrat Sci & Engn, Keio NUS CUTE Ctr, Singapore 117548, Singapore.
EM roshan@nus.edu.sg
RI Cheok, Adrian David/AAT-6141-2021
OI Cheok, Adrian David/0000-0001-6316-2339; Peiris, Roshan
   Lalintha/0000-0002-4191-3565; Fernando, Owen Noel
   Newton/0000-0003-1486-1314
CR Berzowska J., 2004, Proceedings SIGGRAPH '04 ACM SIGGRAPH 2004 Sketches, P34, DOI [10.1145/1186223.1186266, DOI 10.1145/1186223.1186266]
   Berzowska J., 2006, CHI 2006: Extended Abstracts on Human Factors in Computing Systems, P538
   Berzowska J, 2005, C C 05, P32
   Berzowska J, 2010, TEI 2010, P297
   Buechley L, 2009, PERS UBIQUIT COMPUT, V13, P133, DOI 10.1007/s00779-007-0181-0
   Lugmayr A, 2012, MULTIMED TOOLS APPL, V58, P289, DOI 10.1007/s11042-011-0899-6
   Maynard J., 2004, TRON GUY
   Melin L., 2001, CHI 01, P457
   Orth M., 2007, BULLSEYE
   Orth Maggie., 1998, CHI_98_Conference_Summary_on_Human_Factors_in_Computing_Systems, P331
   Perner-Wilson H, 2010, TEI 2010, P349
   PHILIPS, 2006, LUMALIVE
   Pogorelc B, 2012, MULTIMED TOOLS APPL, V58, P399, DOI 10.1007/s11042-011-0917-8
   SARL L., 2006, LUMIGRAM
   Suzanne Lee WdP, 2005, FASHIONING FUTURE TO
   Wakita Akira, 2006, P 2006 ACM SIGCHI IN
   Worbin MargotJacobs., 2005, CHI '05 extended abstracts on Human factors in computing systems (CHI '05), P1493, DOI [10.1145/1056808.1056949, DOI 10.1145/1056808.1056949]
NR 17
TC 1
Z9 1
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2013
VL 66
IS 1
BP 81
EP 94
DI 10.1007/s11042-012-1142-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 163DZ
UT WOS:000320317200005
DA 2024-07-18
ER

PT J
AU Montero, P
   Gulías, VM
   Taibo, J
   Rivas, S
AF Montero, Pablo
   Gulias, Victor M.
   Taibo, Javier
   Rivas, Samuel
TI Optimising lossless stages in a GPU-based MPEG encoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Zigzag scan; Huffman coding; GPU; Video compression; MPEG; Entropy
   coding
AB Modern GPUs excel in parallel computations, so they are an interesting target to perform matrix transformations such as the DCT, a fundamental part of MPEG video coding algorithms. Considering a system to encode synthetic video (e.g., computer-generated frames), this approach becomes even more appealing, since the images to encode are already in the GPU, eliminating the costs of transferring raw video from the CPU to the GPU. However, after a raw frame has been transformed and quantized by the GPU, the resulting coefficients must be reordered, entropy encoded and framed into the resulting MPEG bitstream. These last steps are essentially sequential and their straightforward GPU implementation is inefficient compared to CPU-based implementations. We present different approaches to implement part of these steps in GPU, aiming for a better usage of the memory bus, compensating the suboptimal use of the GPU with the gains in transfer time. We analyze three approaches to perform the zigzag scan and Huffman coding combining GPU and CPU, and two approaches to assemble the results to build the actual output bitstream both in GPU and CPU memory. Our experiments show that optimising the amount of data transferred from GPU to CPU implementing the last sequential compression steps in the GPU, and using a parallel fast scan implementation of the zigzag scanning improve the overall performance of the system. Savings in transfer time outweigh the extra cost incurred in the GPU.
C1 [Montero, Pablo; Gulias, Victor M.; Taibo, Javier; Rivas, Samuel] CITIC, MADS Grp, La Coruna 15008, Spain.
C3 Universidade da Coruna
RP Taibo, J (corresponding author), CITIC, MADS Grp, La Coruna 15008, Spain.
EM pmontm@gmail.com; gulias@udc.es; jtaibo@udc.es; samuelrivas@gmail.com
RI Taibo, Javier/D-1171-2010
OI Taibo, Javier/0000-0003-1309-7086
FU Xunta de Galicia [PGIDIT 07TIC005105PR, 09TIC015CT]; Spanish Ministry of
   Science and Innovation [TIN2010-20959]
FX This work was partly supported by Xunta de Galicia grants PGIDIT
   07TIC005105PR and 09TIC015CT and Spanish Ministry of Science and
   Innovation grant TIN2010-20959.
CR [Anonymous], 1995, 138182 ISOIEC
   [Anonymous], 2009, OPENCL SPEC VERS 1 0
   [Anonymous], 2007, CUDA PROGR GUID
   Aqrawi AA, 2010, PARA 2010 STATE ART
   Balevic A, 2010, LECT NOTES COMPUT SC, V6043, P26
   De Neve W., 2005, 13th Annual ACM International Conference on Multimedia, P447, DOI 10.1145/1101149.1101248
   Dotsenko Y, 2008, ICS'08: PROCEEDINGS OF THE 2008 ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING, P205
   Fung J, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P93
   Ho CW, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P2049, DOI 10.1109/ICME.2006.262617
   Kresch R, 1999, IEEE T IMAGE PROCESS, V8, P821, DOI 10.1109/83.766859
   Luebke D., 2006, Proceedings of the 2006 ACM/IEEE conference on Supercomputing
   Munshi A., 2008, OpenCL: Parallel Computing on the GPU and CPU, SIGGRAPH, Tutorial
   Nickolls John, 2008, ACM Queue, V6, DOI 10.1145/1365490.1365500
   Obukhov A., 2008, Discrete cosine transform for 8x8 blocks with cuda
   Ryoo S, 2008, PPOPP'08: PROCEEDINGS OF THE 2008 ACM SIGPLAN SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING, P73, DOI 10.1145/1345206.1345220
   Shen GB, 2005, IEEE T CIRC SYST VID, V15, P685, DOI 10.1109/TCSVT.2005.846440
   Strzodka R, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P545, DOI 10.1109/VISUAL.2004.88
NR 17
TC 1
Z9 1
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2013
VL 65
IS 3
BP 495
EP 520
DI 10.1007/s11042-012-1053-9
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 144EO
UT WOS:000318922600008
DA 2024-07-18
ER

PT J
AU Li, H
   Zhong, YC
AF Li, Heng
   Zhong, YanChun
TI Motion characteristic differentiated error concealment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Error concealment; Motion field transfer; Low motion; High motion
ID VIDEO COMMUNICATION; IMAGE
AB In this paper, we propose a brand-new motion characteristic differentiated error concealment (MDEC) method based on motion field transfer. Firstly, the FMO checkerboard pattern is used at the encoder, so as to prevent MBs of a large area getting lost. Then at the decoder, Greedy Spread Motion Region Extraction (GSMRE) method is used to distinguish low-motion region from high-motion region in each frame based on different motion characteristic, and apply different strategies to recover regions with different characteristics respectively. Simulation results show that the proposed algorithm reconstructs the lost frame with both a better visual quality and a higher PSNR, comparing to error concealment methods including Joint Model, boundary matching, inpainting, and block motion vector extrapolation as well. For example, the PSNR gain of our approach over boundary matching algorithm reached about 0.6 dB, and 1.4 dB when the packet loss rate is 3 and 7%, respectively, which demonstrates that our method has an good application within a wide scope of packet loss rate.
C1 [Li, Heng; Zhong, YanChun] BeiHang Univ, State Key Lab Software Dev Environm, Beijing 100191, Haidian, Peoples R China.
C3 Beihang University
RP Li, H (corresponding author), BeiHang Univ, State Key Lab Software Dev Environm, New Main Bldg, Beijing 100191, Haidian, Peoples R China.
EM liheng@nlsde.buaa.edu.cn; zhongyc@nlsde.buaa.edu.cn
FU National 973 Program of China [2005CB321901]
FX The research was supported by National 973 Program of China (Grant No.
   2005CB321901).
CR Agrafiotis D, 2006, SIGNAL PROCESS-IMAGE, V21, P130, DOI 10.1016/j.image.2005.08.002
   [Anonymous], 2009, Proceedings of the 17th ACM International Conference on Multimedia
   [Anonymous], 2011, JVT REFERENCE SOFTWA
   [Anonymous], 2011, OPEN COMPUTER VISION
   Belfiore S, 2003, P IEEE INT C AC SPEE, V5, P750
   Bertalmío M, 2001, PROC CVPR IEEE, P355
   Bolot J.-C., 1993, Journal of High Speed Networks, V2, P305
   Chen Y, 2008, IEEE T MULTIMEDIA, V10, P2, DOI 10.1109/TMM.2007.911223
   Chen YJ, 2004, PROCEEDINGS OF THE 2004 IEEE ASIA-PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, VOL 1 AND 2, P389
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Farnebäck G, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P171, DOI 10.1109/ICCV.2001.937514
   Hsia SC, 2005, IEEE T MULTIMEDIA, V7, P860, DOI 10.1109/TMM.2005.854432
   Huang YL, 2005, PROC SPIE, V5960, P992, DOI 10.1117/12.632565
   Hwang MC, 2008, IEEE T BROADCAST, V54, P198, DOI 10.1109/TBC.2008.917274
   JUNG B, 2004, P IEEE INT C IM PROC
   Kim D, 2008, ETRI J, V30, P526
   Kim M, 2008, IEEE T CONSUM ELECTR, V54, P1811, DOI 10.1109/TCE.2008.4711239
   Kim W, 2006, IEEE T CONSUM ELECTR, V52, P1050, DOI 10.1109/TCE.2006.1706506
   Lam W. M., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P417, DOI 10.1109/ICASSP.1993.319836
   Lee S, 2002, IEEE T MULTIMEDIA, V4, P129, DOI 10.1109/6046.985561
   Liu Y, 2007, IEEE T CIRC SYST VID, V17, P68, DOI 10.1109/TCSVT.2006.887081
   Luo ZY, 2010, OPT ENG, V49, DOI 10.1117/1.3381178
   Ma MY, 2010, IEEE T CIRC SYST VID, V20, P382, DOI 10.1109/TCSVT.2009.2035839
   Peng Q, 2002, 2002 INTERNATIONAL CONFERENCE ON COMMUNICATIONS, CIRCUITS AND SYSTEMS AND WEST SINO EXPOSITION PROCEEDINGS, VOLS 1-4, P10, DOI 10.1109/ICCCAS.2002.1180560
   Ranjbar M, 2009, COMPUT ELECTR ENG, V35, P536, DOI 10.1016/j.compeleceng.2008.08.002
   Shiratori T., 2006, Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P411
   Su CY, 2006, IEEE IMAGE PROC, P2221, DOI 10.1109/ICIP.2006.313011
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Tourapis A, 2007, 24 JVT M GEN SWITZ
   Venkatachalapathya K, 2004, J VIS COMMUN IMAGE R, V15, P203, DOI 10.1016/j.jvcir.2003.08.001
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Yan B, 2010, IEEE T IMAGE PROCESS, V19, P98, DOI 10.1109/TIP.2009.2032311
   Zeng WJ, 2005, J VIS COMMUN IMAGE R, V16, P499, DOI 10.1016/j.jvcir.2004.11.008
   Zhang J, 2000, IEEE T CIRC SYST VID, V10, P659, DOI 10.1109/76.845011
   Zhang RF, 2004, IEEE T CONSUM ELECTR, V50, P335, DOI 10.1109/TCE.2004.1277882
NR 35
TC 4
Z9 4
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2013
VL 65
IS 2
BP 297
EP 320
DI 10.1007/s11042-011-0811-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 141EJ
UT WOS:000318708100008
DA 2024-07-18
ER

PT J
AU Mianowska, B
   Nguyen, NT
AF Mianowska, Bernadetta
   Ngoc Thanh Nguyen
TI Tuning user profiles based on analyzing dynamic preference in document
   retrieval systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User modeling; User profile tuning; User behaviour simulation
ID INFORMATION; SYNCHRONIZATION
AB Modeling users' preferences and needs is one of the most important personalization tasks in information retrieval domain. In this paper a model for user profile tuning in document retrieval systems is considered. Methods for tuning the user profile based on analysis of user preferences dynamics are experimentally evaluated to check whether with growing history of user activity the created user profile can converge to his preferences. As the statistical analysis of series of simulations has shown, proposed methods of user profile actualization are effective in the sense that the distance between user preferences and his profile becomes smaller and smaller along with time.
C1 [Mianowska, Bernadetta; Ngoc Thanh Nguyen] Wroclaw Univ Technol, Inst Informat, PL-50370 Wroclaw, Poland.
C3 Wroclaw University of Science & Technology
RP Mianowska, B (corresponding author), Wroclaw Univ Technol, Inst Informat, Wybrzeze Wyspianskiego 27, PL-50370 Wroclaw, Poland.
EM Bernadetta.Mianowska@pwr.wroc.pl; Ngoc-Thanh.Nguyen@pwr.edu.pl
RI Nguyen, Ngoc Thanh/A-5855-2008; Nguyen, Ngoc/HHZ-0886-2022
OI Maleszka, Bernadetta/0000-0001-6370-2913
FU Polish Ministry of Science and Higher Education [N N519 407437]
FX This research was partially supported by Polish Ministry of Science and
   Higher Education under grant no. N N519 407437 (2009-2012).
CR [Anonymous], 2009, INTRO INFORM RETRIEV
   Arapakis I, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P371
   Bhogal J, 2007, INFORM PROCESS MANAG, V43, P866, DOI 10.1016/j.ipm.2006.09.003
   Clarke CLA, 2000, INFORM PROCESS MANAG, V36, P291, DOI 10.1016/S0306-4573(99)00017-5
   Duong TH, 2009, J UNIVERS COMPUT SCI, V15, P877
   Esposito F, 2003, P EWMF, V03, P130
   Godoy D, 2005, KNOWL ENG REV, V20, P329, DOI 10.1017/S0269888906000397
   Hider P, 2006, J INF SCI, V32, P352, DOI 10.1177/0165551506065811
   Indyka-Piasecka A, 2006, THESIS WROCLAW U TEC
   Jung JJ, 2008, KNOWL-BASED SYST, V21, P573, DOI 10.1016/j.knosys.2008.03.015
   Jung JJ, 2012, INFORM SCIENCES, V182, P30, DOI 10.1016/j.ins.2010.08.042
   Jung JJ, 2011, EXPERT SYST APPL, V38, P4809, DOI 10.1016/j.eswa.2010.09.165
   Mianowska B, 2012, 12012 SPR WROCL U TE
   Mianowska B, 2012, LECT NOTES ARTIF INT, V7267, P673, DOI 10.1007/978-3-642-29347-4_78
   Mianowska B, 2011, LECT NOTES COMPUT SC, V6910, P140
   Mianowska B, 2011, LECT NOTES ARTIF INT, V6682, P138, DOI 10.1007/978-3-642-22000-5_16
   Mianowska B, 2011, LECT NOTES ARTIF INT, V6592, P181, DOI 10.1007/978-3-642-20042-7_19
   Mostafa J, 1997, ACM T INFORM SYST, V15, P368, DOI 10.1145/263479.263481
   Nanas N, 2004, P 15 INT WORKSH DAT, P13
   Nguyen NT, 2006, LECT NOTES ARTIF INT, V4252, P267
   Nie J., 1988, P 11 ANN INT ACM SIG
   Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943
   Ren FJ, 2009, ELECTRON NOTES THEOR, V225, P303, DOI 10.1016/j.entcs.2008.12.082
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Shen Xuehua, 2005, CIKM '05, P824, DOI DOI 10.1145/1099554.1099747
   Sparck-Jones K, 1999, ARTIF INTELL, V114, P257, DOI 10.1016/S0004-3702(99)00075-2
   Stojanovic N., 2005, P 3 INT C KNOWL CAPT, P83
   Syed HH, 2007, DIT07060 U TRENT
   Tan AH, 1998, IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, P183, DOI 10.1109/IJCNN.1998.682259
   Tang J, 2010, ACM T KNOWL DISCOV D, V5, DOI 10.1145/1870096.1870098
   Vallet DJ, 2007, PERSONALIZED INFORM
   Van Rijsbergen C. J., 1979, Information Retrieval, V2nd
   Wang YD, 2008, J INF SCI, V34, P861, DOI 10.1177/0165551508091308
   Widyantoro DH, 1999, THESIS TEXAS M A U
NR 34
TC 20
Z9 21
U1 2
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2013
VL 65
IS 1
BP 93
EP 118
DI 10.1007/s11042-012-1145-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126OI
UT WOS:000317626800007
DA 2024-07-18
ER

PT J
AU Seo, S
   Ryoo, S
   Park, J
AF Seo, SangHyun
   Ryoo, SeungTaek
   Park, JinWann
TI Interactive painterly rendering with artistic error correction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-Photorealistic rendering; Painterly rendering; Abstraction
AB An artist's painting is affected by factors such as how he observes objects, his skill in using a brush and materials, and the experience that allows him to correctly apply his skills. The process inevitably results in mistakes contrary to the painter's original intention. This is a distinguishing factor between painting and photography, but this is the essence of the beauty of painting. The inadequacy of a human being to make a painting exactly as he pleases (as a photograph creates a direct representation of itself) is the starting point of creating a creative work. This paper explains the algorithm that reproduces human errors, as well as the stroke data collection method. Although the results of this research are mainly stylized renderings of modern oil paintings, they have unlimited scalability, in that they can play the role to perform a basic framework. These allow the experimentation with many painting styles through the modification of input data and error generation algorithms.
C1 [Seo, SangHyun; Park, JinWann] Chung Ang Univ, Seoul 156756, South Korea.
   [Ryoo, SeungTaek] HanShin Univ, Osan, South Korea.
C3 Chung Ang University; Hanshin University
RP Seo, S (corresponding author), Chung Ang Univ, Seoul 156756, South Korea.
EM shseo@cglab.cau.ac.kr; stryoo@hs.ac.kr; Jinpark@cau.ac.kr
RI Sanghyun, Seo/ADZ-4404-2022
OI Sanghyun, Seo/0000-0002-4824-3517
FU Postdoctoral Research Program of Chung-Ang University; Korean Science
   and Engineering Foundation (KOSEF); Korean government (MEST)
   [20100018445]
FX This work was supported by the Postdoctoral Research Program of
   Chung-Ang University 2010 year and the Korean Science and Engineering
   Foundation (KOSEF) grant funded by the Korean government (MEST)
   (No.20100018445).
CR Baxter William., 2004, Proceedings of the 3rd international symposium on Non-photorealistic animation and rendering, P45
   DeCarlo D, 2002, ACM T GRAPHIC, V21, P769, DOI 10.1145/566570.566650
   Gooch B., 2002, 2 INT S NONPHOTOREAL, P83
   Gooch B., 2001, Non-photorealistic rendering
   GROSSER M, 1951, PAINTERS EYE
   Haeberli P., 1990, Computer Graphics, V24, P207, DOI 10.1145/97880.97902
   Hays J., 2004, PROC NPAR 01, P113
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Hertzmann A., 2002, NPAR, P91, DOI 10.1145/508530.508546
   Hertzmann A., 2000, NPAR, P7
   Kasao A, 2006, VISUAL COMPUT, V22, P14, DOI 10.1007/s00371-005-0353-8
   Litwinowicz P., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P407, DOI 10.1145/258734.258893
   Nehab D, 2002, SIBGRAPI 2002: XV BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P244, DOI 10.1109/SIBGRA.2002.1167151
   Park Y, 2008, GRAPH MODELS, V70, P1, DOI 10.1016/j.gmod.2007.06.001
   Rewald J, 1990, HIST IMPRESSIONISM
   Salisbury M. P., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P401, DOI 10.1145/258734.258890
   Schlechtweg S., 2005, COMPUT GRAPH FORUM, V24, P283
   Seo S, 2010, VISUAL COMPUT, V26, P421, DOI 10.1007/s00371-010-0505-3
   SHIRAISHI M, 2000, P 1 INT S NONPH AN R, P53, DOI DOI 10.1145/340916.340923
   Strothotte T, 2002, NONPHOTOREALISTIC CO
   Tucker P, 1986, MONET ARGENTEUIL
NR 21
TC 10
Z9 10
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2013
VL 65
IS 2
BP 221
EP 237
DI 10.1007/s11042-011-0796-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 141EJ
UT WOS:000318708100004
DA 2024-07-18
ER

PT J
AU Calix, RA
   Knapp, GM
AF Calix, Ricardo A.
   Knapp, Gerald M.
TI Actor level emotion magnitude prediction in text and speech
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial intelligence; Natural language processing; Machine learning;
   Multimedia semantic analysis; Affect detection; Speech processing
ID RECOGNITION
AB The digital universe is expanding at very high rates. New ways of retrieving and enriching text and audio content are required. In this work, a methodology for actor level emotion magnitude prediction in text and speech is proposed. A model is trained to predict emotion magnitudes per actor at any point in a story using previous emotion magnitudes plus current text and speech features which act on the actor's emotional state. The methodology compares linear and non-linear regression techniques to determine the optimal model that fits the data. Results of the analysis show that non-linear regression models based on Support Vector Regression (SVR) using a Radial Basis Function (RBF) kernel provide the most accurate prediction model. An analysis of the contribution of the features for emotion magnitude prediction is performed.
C1 [Calix, Ricardo A.; Knapp, Gerald M.] Louisiana State Univ, Coll Engn, Baton Rouge, LA 70803 USA.
C3 Louisiana State University System; Louisiana State University
RP Knapp, GM (corresponding author), Louisiana State Univ, Coll Engn, Baton Rouge, LA 70803 USA.
EM rcalix1@lsu.edu; gknapp@lsu.edu
CR Alm CO, 2005, P C HUM LANG TECHN E, P579, DOI DOI 10.3115/1220575.1220648
   Alm CO, 2011, AFF DAT
   [Anonymous], 2018, Real-Time Rendering
   Bird S., 2009, NATURAL LANGUAGE PRO
   Boersma P., 2009, Praat: Doing Phonetics by Computer
   Burns B., 2003, WORKING NOTES ASS AD
   Busso C, 2009, IEEE T AUDIO SPEECH, V17, P582, DOI 10.1109/TASL.2008.2009578
   Calix RA, 2011, P 2 ACM MULT SYST MM
   Calix RA, 2010, IEEE T MULTIMEDIA, V12, P544, DOI 10.1109/TMM.2010.2052026
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   El-Nasr M. S., 1999, Proceedings of the Third International Conference on Autonomous Agents, P9, DOI 10.1145/301136.301150
   Gantz J.F., 2010, The Digital Universe Decade - Are You Ready?
   Grimm M, 2007, INT CONF ACOUST SPEE, P1085
   Jurafsky D., 2021, SPEECH LANGUAGE PROC
   Lu CY, 2006, 3 TAIW FRENCH C INF
   Luengo I, 2010, IEEE T MULTIMEDIA, V12, P490, DOI 10.1109/TMM.2010.2051872
   Mao Y, 2006, P INT C MACH LEARN I
   Moilanen K., 2007, P REC ADV NAT LANG P, P378
   Neviarouskaya A., 2009, Proceedings IADIS international conference on applied computing, VAC, P27
   Nuance, 2011, NAT SPEAK SOFTW
   Pang B., 2008, INFORM RETRIEVAL, V2, P1, DOI [10.1561/1500000011, DOI 10.1561/1500000011, https://doi.org/10.1561/1500000011]
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Tokuhisa R., 2008, P 22 INT C COMP LING, V1, P881, DOI DOI 10.3115/1599081.1599192
   Witten I. H., 2005, DATA MINING PRACTICA
NR 24
TC 4
Z9 4
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2013
VL 62
IS 2
BP 319
EP 332
DI 10.1007/s11042-011-0909-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 076OM
UT WOS:000313965900002
DA 2024-07-18
ER

PT J
AU Khemiri, H
   Chollet, G
   Petrovska-Delacrétaz, D
AF Khemiri, Houssemeddine
   Chollet, Gerard
   Petrovska-Delacretaz, Dijana
TI Automatic detection of known advertisements in radio broadcast with
   data-driven ALISP transcriptions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ALISP tools; Advertisement detection; Copy detection; Data-driven speech
   segmentation; HMM models
ID SPEECH
AB This paper presents an audio indexing system to search for known advertisements in radio broadcast streams, using automatically acquired segmental units. These units, called Automatic Language Independent Speech Processing (ALISP) units, are acquired using temporal decomposition and vector quantization and modeled by Hidden Markov Models (HMMs). To detect commercials, ALISP transcriptions of reference advertisements are compared to the transcriptions of the test radio stream using the Levenshtein distance. The system is described and evaluated on one day broadcast audio streams from 11 French radio stations containing 2070 advertisements. With a set of 2,172 reference advertisements we achieve a mean precision rate of 99% with the corresponding recall value of 96%. Moreover, this system allowed us to detect some annotation errors.
C1 [Khemiri, Houssemeddine; Chollet, Gerard] TELECOM ParisTech, Dept Signal & Image Proc, F-75014 Paris, France.
   [Khemiri, Houssemeddine] TELECOM SudParis, F-75014 Paris, France.
   [Petrovska-Delacretaz, Dijana] TELECOM SudParis, Elect & Phys Dept, F-91011 Evry, France.
C3 IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; Telecom
   Paris; IMT - Institut Mines-Telecom; Institut Polytechnique de Paris;
   Telecom SudParis; IMT - Institut Mines-Telecom; Institut Polytechnique
   de Paris; Telecom SudParis
RP Khemiri, H (corresponding author), TELECOM ParisTech, Dept Signal & Image Proc, 37-39 Rue Dareau, F-75014 Paris, France.
EM khemiri@telecom-paristech.fr; chollet@telecom-paristech.fr;
   dijana.petrovska@it-sudparis.eu
RI Delacrétaz, Dijana Petrovska/AAG-5952-2019
OI Chollet, Gerard/0000-0003-4245-146X; Petrovska Delacretaz,
   Dijana/0000-0001-6485-2972
FU ANR-SurfOnHertz project
FX Some of the programs used for this research were written by F. Bimbot,
   J. Cernocky, A. El Hannani, G. Aversano and members of the French
   SYMPATEX project. The first author is financially supported by the
   ANR-SurfOnHertz project. We would also like to thank the reviewers for
   having accepted to revise our paper and for their precious advices and
   comments that have greadly improved the quality of the paper.
CR Allamanche E, 2001, 110 C AES
   ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1016/S0022-2836(05)80360-2
   [Anonymous], ISMIR
   Atal B, 1983, ICASSP, P81
   BIMBOT F, 1990, EVALUATION TEMPORAL
   Cambridge University Engineering Department, HTK HIDD MARK MOD TO
   Cano P, 2005, J VLSI SIG PROC SYST, V41, P271, DOI 10.1007/s11265-005-4151-3
   Cano P, 2002, P 112 AES CONV AUD E
   Cardinal P, 2010, INTERSPEECH
   CERNOCKY J, 1998, THESIS U PARIS 11 OR
   Chollet G, 2005, LECT NOTES ARTIF INT, V3445, P164
   Chollet G, 1999, NATO ASI SER, P357
   Covell M, 2006, MMSP, P461
   El Hannani A, 2007, THESIS U FRIBOURG SW
   El Hannani A., 2009, GUIDE BIOMETRIC REFE
   Jang D, 2006, AES 29 INT C
   Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   MAKHOUL J, 1985, P IEEE, V73, P1551, DOI 10.1109/PROC.1985.13340
   Neves C., 2009, Proc. of the Conf. on Telecommunications, P481
   Padellini M, 2004, EUSIPCO
   Pinquier J, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL IV, PROCEEDINGS, P329
   Schwarz D, 2004, ACOUSTICS COMPUTER S
   Wang A, 2006, COMMUN ACM, V49, P44, DOI 10.1145/1145287.1145312
   Young S, 1989, TOKEN PASSING CONCEP
NR 25
TC 2
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2013
VL 62
IS 1
BP 35
EP 49
DI 10.1007/s11042-011-0914-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 076OL
UT WOS:000313965800003
OA hybrid
DA 2024-07-18
ER

PT J
AU dos Santos, JAF
   Muchaluat-Saade, DC
AF Ferreira dos Santos, Joel Andre
   Muchaluat-Saade, Debora Christina
TI XTemplate 3.0: spatio-temporal semantics and structure reuse for
   hypermedia compositions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hypermedia composite templates; Reuse; Spatio-temporal semantics;
   XTemplate; Interactive TV; NCL; Hypermedia authoring
AB The use of declarative languages in digital TV systems, as well as IPTV systems, facilitates the creation of interactive applications. However, when an application becomes more complex, with many user interactions, for example, the hypermedia document that describes that application becomes bigger, having many lines of XML code. Thus, specification reuse is crucial for an efficient application development process. This paper proposes the XTemplate 3.0 language, which allows the creation of NCL hypermedia composite templates. Templates define generic structures of nodes and links to be added to a document composition, providing spatio-temporal synchronization semantics to it. The use of hypermedia composite templates aims at facilitating the authoring work, allowing the reuse of hypermedia document common specifications. Using composite templates, hypermedia documents become simpler and easier to be created. The 3.0 version of XTemplate adds new facilities to the XTemplate language, such as the possibility of specifying presentation information, the attribution of values to variables and connector parameters during template processing time and the template ability to extend other templates. As an application of XTemplate, this work extends the NCL 3.0 declarative language with XTemplate, adding semantics to NCL contexts and providing document structure reuse. In addition, this paper also presents two authoring tools: the template processor and the wizard to create NCL documents using templates. The wizard tool allows the author to choose a template included in a template base and create an NCL document using that template. The template processor transforms an NCL document using templates into a standard NCL 3.0 document according to digital TV and IPTV standards.
C1 [Ferreira dos Santos, Joel Andre; Muchaluat-Saade, Debora Christina] Univ Fed Fluminense, Dept Comp Sci, MidiaCom Lab, Niteroi, RJ, Brazil.
C3 Universidade Federal Fluminense
RP dos Santos, JAF (corresponding author), Univ Fed Fluminense, Dept Comp Sci, MidiaCom Lab, Rua Passo Patria 156, Bloco E Sala 408, Niteroi, RJ, Brazil.
EM joel@midiacom.uff.br; debora@midiacom.uff.br
RI dos Santos, Joel A. F./O-6246-2016; Muchaluat-Saade, Débora
   Christina/E-7794-2014
OI dos Santos, Joel A. F./0000-0001-7234-613X; 
FU CNPq; FAPERJ; CAPES
FX This work was partially supported by CNPq, FAPERJ and CAPES.
CR ABNT, 2007, 1560622007 ABNT NBR
   ABNT, 2010, 1560642010 ABNT NBR
   [Anonymous], P 2006 ACM S DOC ENG
   [Anonymous], 2006, Lua 5.1 reference manual
   [Anonymous], 1999, XSL TRANSF XSLT VERS
   [Anonymous], 2009, NEST CONT LANG NCL G
   Beszteri I, 2005, P 2005 ACM S APPL CO, P769
   Bilasco I, 2005, MULTIMED TOOLS APPL, V25, P361, DOI 10.1007/s11042-005-6540-9
   Celentano A, 2003, INT J SOFTW ENG KNOW, V13, P419, DOI 10.1142/S0218194003001354
   Deitel H., 2003, JAVA PROGRAM, Vfifth
   dos Santos J.A.F., 2010, P 2010 ACM S APPL CO, P1892
   ETSI, 2006, 102812 ETSI TS
   Gaggi O, 2005, MULTIMED TOOLS APPL, V27, P53, DOI 10.1007/s11042-005-2714-8
   Gaggi O, 2002, FOURTH INTERNATIONAL SYMPOSIUM ON MULTIMEDIA SOFTWARE ENGINEERING, PROCEEDINGS, P206, DOI 10.1109/MMSE.2002.1181614
   *ISO IEC, 2005, 14496112005 ISOIEC
   Jansen J, 2009, MULTIMED TOOLS APPL, V43, P203, DOI 10.1007/s11042-009-0270-3
   Medvidovic N, 2000, IEEE T SOFTWARE ENG, V26, P70, DOI 10.1109/32.825767
   Muchaluat-Saade D. C., 2002, New Review of Hypermedia and Multimedia, V8, P139, DOI 10.1080/13614560208914739
   Sans V., 2006, Applied Computing 2006. 21st Annual ACM Symposium on Applied Computing, P1385, DOI 10.1145/1141277.1141597
   Scherp A., 2005, 13th Annual ACM International Conference on Multimedia, P802, DOI 10.1145/1101149.1101323
   Silva HVO, 2005, THESIS COMPUTER SCI
   Soares LFG, 2000, MULTIMEDIA SYST, V8, P118, DOI 10.1007/s005300050155
   Soares LFG, 2009, ACM SAC 09, P1821
   Soares LFG, 2010, MULTIMED TOOLS APPL, V50, P465, DOI 10.1007/s11042-010-0478-2
   Thompson S, 2007, DOCENG'07: PROCEEDINGS OF THE 2007 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P89
   W3C, 2008, Synchronized multimedia integration language (SMIL 3.0)
   *W3C, 2000, DOC OBJ MOD DOM LEV
   *W3C, 1999, XML PATH LANG XPATH
   World Wide Web Consortium (W3C), 2001, SEM WEB ACT
NR 29
TC 7
Z9 7
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2012
VL 61
IS 3
BP 645
EP 673
DI 10.1007/s11042-011-0732-2
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 021CA
UT WOS:000309861700007
DA 2024-07-18
ER

PT J
AU Bratsberg, SE
   Hetland, ML
AF Bratsberg, Svein Erik
   Hetland, Magnus Lie
TI Dynamic optimization of queries in pivot-based indexing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Similarity search; Pivot-based indexing; Database trees; Optimized query
   processing
AB This paper evaluates the use of standard database indexes and query processing as a way to do metric indexing in the LAESA approach. By utilizing B-trees and R-trees as pivot-based indexes, we may use well-known optimization techniques from the database field within metric indexing and search. The novelty of this paper is that we use a cost-based approach to dynamically evaluate which and how many pivots to use in the evaluation of each query. By a series of measurements using our database prototype we are able to evaluate the performance of this approach. Compared to using all available pivots for filtering, the optimized approach gives half the response times for main memory data, but much more varied results for disk resident data. However, by use of the cost model we are able to dynamically determine when to bypass the indexes and simply perform a sequential scan of the base data. The conclusion of this evaluation is that it is beneficial to create many pivots, but to use only the most selective ones during evaluation of each query. R-trees give better performance than B-trees when utilizing all pivots, but when being able to dynamically select the best pivots, B-trees often provide better performance.
C1 [Bratsberg, Svein Erik; Hetland, Magnus Lie] Norwegian Univ Sci & Technol, Dept Comp & Informat Sci, N-7491 Trondheim, Norway.
C3 Norwegian University of Science & Technology (NTNU)
RP Bratsberg, SE (corresponding author), Norwegian Univ Sci & Technol, Dept Comp & Informat Sci, N-7491 Trondheim, Norway.
EM sveinbra@idi.ntnu.no; mlh@idi.ntnu.no
CR [Anonymous], 1979, PROC ACM SIGMOD INT
   Baioco GB, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P527, DOI 10.1145/1244002.1244123
   Bernas T, 2008, CYTOM PART A, V73A, P715, DOI 10.1002/cyto.a.20586
   Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217
   Bustos B, 2003, PATTERN RECOGN LETT, V24, P2357, DOI 10.1016/S0167-8655(03)00065-5
   Bustos B, 2008, SISAP 2008: FIRST INTERNATIONAL WORKSHOP ON SIMILARITY SEARCH AND APPLICATIONS, PROCEEDINGS, P105, DOI 10.1109/SISAP.2008.12
   Chavez E., 1999, 6th International Symposium on String Processing and Information Retrieval. 5th International Workshop on Groupware (Cat. No.PR00268), P38, DOI 10.1109/SPIRE.1999.796576
   Chávez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808
   Ciaccia P., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, P59, DOI 10.1145/275487.275495
   Figueroa K, 2006, LECT NOTES COMPUT SC, V4007, P279
   Figuerora K, 2010, SISAP METRIC SPACE L
   Fredriksson K, 2007, PATTERN RECOGN LETT, V28, P75, DOI 10.1016/j.patrec.2006.06.012
   Hetland M., 2009, SWARM INTELLIGENCE M
   Ioannidis Y., 2003, VLDB
   Ishikawa M, 2000, LECT NOTES COMPUT SC, V1846, P356
   Jagadish HV, 2005, ACM T DATABASE SYST, V30, P364, DOI 10.1145/1071610.1071612
   Manolopoulos Y., 2005, R-trees: Theory and Applications
   MICO ML, 1994, PATTERN RECOGN LETT, V15, P9, DOI 10.1016/0167-8655(94)90095-7
   Pedreira O, 2007, LECT NOTES COMPUT SC, V4362, P434
   Piatetsky-Shapiro G., 1984, SIGMOD Record, V14, P256, DOI 10.1145/971697.602294
   RUIZ EV, 1986, PATTERN RECOGN LETT, V4, P145
   Traina C, 2002, IEEE T KNOWL DATA EN, V14, P244, DOI 10.1109/69.991715
   Traina C, 2007, VLDB J, V16, P483, DOI 10.1007/s00778-005-0178-0
   Zhang D, 2008, NEUSTORE SIMPLE JAVA
NR 24
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2012
VL 60
IS 2
BP 261
EP 275
DI 10.1007/s11042-010-0614-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 958YH
UT WOS:000305276400002
OA hybrid
DA 2024-07-18
ER

PT J
AU Yeguas, E
   Muñoz-Salinas, R
   Medina-Carnicer, R
AF Yeguas, Enrique
   Munoz-Salinas, Rafael
   Medina-Carnicer, Rafael
TI Example-based procedural modelling by geometric constraint solving
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Model synthesis; Procedural modelling; Example-based modelling;
   Geometric constraint solving; Mixture models
ID GENERATION; SPACE
AB A novel method for procedurally modelling large, complex three-dimensional scenes is presented. Our approach is general-purpose and takes as input any three-dimensional model intuitively provided by a user. The algorithm exploits the adjacency between shapes and objects in the input model and computes an output model that extracts these features (constraints and adjacencies) and models the input. There are two important differences between our method and existing general-purpose model synthesis algorithms. The first is the use of a distribution for the surface or terrain on which the new model is placed. The second difference is that we automatically generate example-inherent constraints to assist the adjacency-based construction using constructive geometric constraint solving.
C1 [Yeguas, Enrique; Munoz-Salinas, Rafael; Medina-Carnicer, Rafael] Univ Cordoba, Dept Informat & Anal Numer, Cordoba, Spain.
C3 Universidad de Cordoba
RP Yeguas, E (corresponding author), Univ Cordoba, Dept Informat & Anal Numer, Campus Rabanales,Edificio C3, Cordoba, Spain.
EM eyeguas@uco.es
RI Yeguas, Enrique/J-4184-2012; Muñoz-Salinas, Rafael/K-5999-2014;
   Medina-Carnicer, Rafael/G-3401-2015
OI Yeguas, Enrique/0000-0002-8153-5052; Muñoz-Salinas,
   Rafael/0000-0002-8773-8571; Medina-Carnicer, Rafael/0000-0003-4481-0614
FU Science and Technology Ministry of Spain [TIN2010-18119]
FX This work has been developed with the support of the Research Project
   'TIN2010-18119' financed by Science and Technology Ministry of Spain.
CR Aliaga DG, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409113
   [Anonymous], THESIS U POLITECNICA
   [Anonymous], 2009, EUROGRAPHICS 2009 ST
   Ault H.K., 1999, Journal for Geometry and Graphics, V3, P39
   Bartle R. A., 2004, DESIGNING VIRTUAL WO
   Blum C, 2003, ACM COMPUT SURV, V35, P268, DOI 10.1145/937503.937505
   Borcea C, 2004, DISCRETE COMPUT GEOM, V31, P287, DOI 10.1007/s00454-003-2902-0
   Cabral M, 2009, COMPUT GRAPH FORUM, V28, P469, DOI 10.1111/j.1467-8659.2009.01386.x
   Cutler B, 2002, ACM T GRAPHIC, V21, P302
   Desbenoit B, 2005, VISUAL COMPUT, V21, P717, DOI 10.1007/s00371-005-0317-z
   Desbenoit B, 2004, COMPUT GRAPH FORUM, V23, P341, DOI 10.1111/j.1467-8659.2004.00765.x
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Fudos I, 1997, ACM T GRAPHIC, V16, P179, DOI 10.1145/248210.248223
   Funkhouser T, 2004, ACM T GRAPHIC, V23, P652, DOI 10.1145/1015706.1015775
   Gal R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531339
   Galin E, 2010, COMPUT GRAPH FORUM, V29, P429, DOI 10.1111/j.1467-8659.2009.01612.x
   Hnaidi H, 2010, COMPUT GRAPH FORUM, V29, P2179, DOI 10.1111/j.1467-8659.2010.01806.x
   Hoffmann C. M., 2005, Computer-Aided Design and Applications, V2, P655
   Joan-Arinyo R, 2011, APPL SOFT COMPUT, V11, P754, DOI 10.1016/j.asoc.2009.12.037
   Joan-Arinyo R, 2001, SPRING CONFERENCE ON COMPUTER GRAPHICS, PROCEEDINGS, P49, DOI 10.1109/SCCG.2001.945336
   Joan-Arinyo R, 1999, ACM T GRAPHIC, V18, P35, DOI 10.1145/300776.300780
   Joan-Arinyo R, 2003, 8 S SOL MOD APPL, P33
   Joan-Arinyo R, 2002, 5 INT C COMP GRAPH A, P63
   Joan-Arinyo R, 2009, 2009 SIAM ACM JOINT, P113
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   Lipp M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360701
   Luzón MV, 2005, APPL INTELL, V22, P109, DOI 10.1007/s10489-005-5600-1
   Mandelbrot B. B., 1982, FRACTAL GEOMETRY NAT
   McLachlan G., 2000, WILEY SER PROB STAT, DOI 10.1002/0471721182
   Mech R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P397, DOI 10.1145/237170.237279
   Merrell P., 2009, 2009 SIAMACM JOINT C, P101
   Merrell P, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409111
   Merrell P, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P105
   Müller P, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276484, 10.1145/1239451.1239536]
   Müller P, 2006, ACM T GRAPHIC, V25, P614, DOI 10.1145/1141911.1141931
   Musgrave F. K., 1989, Computer Graphics, V23, P41, DOI 10.1145/74334.74337
   Ostaszewski A., 1990, ADV MATH METHODS
   Parish YIH, 2001, COMP GRAPH, P301, DOI 10.1145/383259.383292
   Peachey D. R., 1985, Computer Graphics, V19, P279, DOI 10.1145/325165.325246
   Peyrat A, 2008, VISUAL COMPUT, V24, P807, DOI 10.1007/s00371-008-0262-8
   Peytavie A, 2009, COMPUT GRAPH FORUM, V28, P1801, DOI 10.1111/j.1467-8659.2009.01557.x
   Peytavie A, 2009, COMPUT GRAPH FORUM, V28, P457, DOI 10.1111/j.1467-8659.2009.01385.x
   Prusinkiewicz P, 2001, COMP GRAPH, P289, DOI 10.1145/383259.383291
   Shental N., 2003, ADV NEURAL INFORM PR, V16
   Smith J, 2002, ACM T GRAPHIC, V21, P295, DOI 10.1145/566570.566580
   van Basten BJH, 2010, COMPUT ANIMAT VIRT W, V21, P433, DOI 10.1002/cav.342
   van den Bergen G, 2001, GAM DEV C, P821
   Whiting E, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618458
   Wonka P, 2003, ACM T GRAPHIC, V22, P669, DOI 10.1145/882262.882324
   Yeguas E, 2011, EVOL COMPUT, V19, P107, DOI 10.1162/EVCO_a_00017
NR 50
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2012
VL 60
IS 1
BP 1
EP 30
DI 10.1007/s11042-011-0795-0
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 951FY
UT WOS:000304707500001
DA 2024-07-18
ER

PT J
AU Taneja, N
   Raman, B
   Gupta, I
AF Taneja, Nidhi
   Raman, Balasubramanian
   Gupta, Indra
TI Combinational domain encryption for still visual data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arnold cat map; Combinational domain; Edge detection; Net pixel change
   ratio; Statistical analysis
ID SCHEME
AB Image data has distinct regions of different importance. This property of image data has extensively been used to develop partial encryption techniques, but it is still unnoticed for total encryption. Providing similar security level to data of varied significance consumes more computational resources. This necessitates the development of an encryption framework that considers data significance while implementing total encryption. This article proposes a new framework of combinational domain encryption that encrypts significant data in spatial domain and insignificant data in wavelet domain. Experiments have been performed to analyze the effect of proposed framework as compared to encryption technique in a single domain. Significant reduction in computational time has been observed without compromising on the security. Medical applications or security applications requiring fast computation would be benefitted by implementation of the proposed technique.
C1 [Taneja, Nidhi; Gupta, Indra] Indian Inst Technol, Dept Elect Engn, Roorkee 247667, Uttar Pradesh, India.
   [Raman, Balasubramanian] Indian Inst Technol, Dept Math, Roorkee 247667, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Roorkee
RP Taneja, N (corresponding author), Indian Inst Technol, Dept Elect Engn, Roorkee 247667, Uttar Pradesh, India.
EM nidhi.iitr@gmail.com; balarfma@iitr.ernet.in; indrafee@iitr.ernet.in
CR [Anonymous], 2002, P 5 NORD SIGN PROC S
   Behnia S, 2007, PHYS LETT A, V366, P391, DOI 10.1016/j.physleta.2007.01.081
   BOURBAKIS N, 1992, PATTERN RECOGN, V25, P567, DOI 10.1016/0031-3203(92)90074-S
   Chang HKC, 1997, SIGNAL PROCESS-IMAGE, V10, P279, DOI 10.1016/S0923-5965(96)00025-2
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Cheng H, 2000, IEEE T SIGNAL PROCES, V48, P2439, DOI 10.1109/78.852023
   Chuang T. J., 1999, Pattern Recognition and Image Analysis, V9, P431
   Dachselt F, 2001, IEEE T CIRCUITS-I, V48, P1498, DOI 10.1109/TCSI.2001.972857
   Engel D, 2007, P IEEE INT C IM PROC, P141
   Kulkarni NS, 2009, STUD COMPUT INTELL, V231, P417
   LEE JSJ, 1987, IEEE T ROBOTIC AUTOM, V3, P142, DOI 10.1109/JRA.1987.1087088
   Lian SG, 2004, I C CONT AUTOMAT ROB, P126
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Marion A., 1991, INTRO IMAGE PROCESSI
   Norcen R, 2004, IEEE IMAGE PROC, P3431
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Peterson G, 1997, ARNOLDS CAT MAP
   Rao YVS, 2006, LECT NOTES COMPUT SC, V4332, P315
   Schneier B., 2015, APPL CRYPTOGRAPHY, VSecond
   Seo Y-H, 2003, WORLD WID C 3G WIR S
   Taneja N, 2009, LECT NOTES COMPUT SC, V5909, P426, DOI 10.1007/978-3-642-11164-8_69
   Uhl A., 2005, ADV INFORM SECURITY, V15, P31
   Van Droogenbroeck M, 2002, advanced concepts for intelligent vision systems (ACIVS)
   Yang H, 2007, CHAOS SOLITON FRACT, V4, P2520
   Yekkala A, 2007, LECT NOTES COMPUT SC, V4815, P103
   Zeng WJ, 2003, IEEE T MULTIMEDIA, V5, P118, DOI 10.1109/TMM.2003.808817
NR 26
TC 64
Z9 64
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2012
VL 59
IS 3
BP 775
EP 793
DI 10.1007/s11042-011-0775-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 950AF
UT WOS:000304619900003
DA 2024-07-18
ER

PT J
AU De Pessemier, T
   Coppens, S
   Geebelen, K
   Vleugels, C
   Bannier, S
   Mannens, E
   Vanhecke, K
   Martens, L
AF De Pessemier, Toon
   Coppens, Sam
   Geebelen, Kristof
   Vleugels, Chris
   Bannier, Stijn
   Mannens, Erik
   Vanhecke, Kris
   Martens, Luc
TI Collaborative recommendations with content-based filters for cultural
   activities via a scalable event distribution platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender system; Personalization; Event modeling; Distributing event
   information
AB Nowadays, most people have limited leisure time and the offer of (cultural) activities to spend this time is enormous. Consequently, picking the most appropriate events becomes increasingly difficult for end-users. This complexity of choice reinforces the necessity of filtering systems that assist users in finding and selecting relevant events. Whereas traditional filtering tools enable e.g. the use of keyword-based or filtered searches, innovative recommender systems draw on user ratings, preferences, and metadata describing the events. Existing collaborative recommendation techniques, developed for suggesting web-shop products or audio-visual content, have difficulties with sparse rating data and can not cope at all with event-specific restrictions like availability, time, and location. Moreover, aggregating, enriching, and distributing these events are additional requisites for an optimal communication channel. In this paper, we propose a highly-scalable event recommendation platform which considers event-specific characteristics. Personal suggestions are generated by an advanced collaborative filtering algorithm, which is more robust on sparse data by extending user profiles with presumable future consumptions. The events, which are described using an RDF/OWL representation of the EventsML-G2 standard, are categorized and enriched via smart indexing and open linked data sets. This metadata model enables additional content-based filters, which consider event-specific characteristics, on the recommendation list. The integration of these different functionalities is realized by a scalable and extendable bus architecture. Finally, focus group conversations were organized with external experts, cultural mediators, and potential end-users to evaluate the event distribution platform and investigate the possible added value of recommendations for cultural participation.
C1 [De Pessemier, Toon; Vanhecke, Kris; Martens, Luc] Ghent Univ IBBT, INTEC WiCa, B-9050 Ghent, Belgium.
   [Coppens, Sam; Mannens, Erik] Ghent Univ IBBT, ELIS Multimedia Lab, B-9050 Ghent, Belgium.
   [Geebelen, Kristof] KU Leuven IBBT, Distrinet, B-3001 Louvain, Belgium.
   [Vleugels, Chris; Bannier, Stijn] VUB IBBT, SMIT, B-1050 Brussels, Belgium.
C3 Ghent University; Ghent University; KU Leuven
RP De Pessemier, T (corresponding author), Ghent Univ IBBT, INTEC WiCa, Gaston Crommenlaan 8,Box 201, B-9050 Ghent, Belgium.
EM toon.depessemier@ugent.be; sam.coppens@ugent.be;
   kristof.geebelen@cs.kuleuven.be; chris.vleugels@vub.ac.be;
   Stijn.Bannier@vub.ac.be; erik.mannens@ugent.be;
   Kris.Vanhecke@intec.ugent.be; Luc.Martens@intec.ugent.be
OI Mannens, Erik/0000-0001-7946-4884
FU Ghent University, K.U. Leuven; VUB; VRT-medialab; Interdisciplinary
   Institute for Broadband Technology (IBBT); Institute for the Promotion
   of Innovation by Science and Technology in Flanders (IWT); Fund for
   Scientific Research-Flanders (FWO-Flanders); European Union
FX The research activities that have been described in this paper were
   funded by Ghent University, K.U. Leuven, VUB, VRT-medialab,
   Interdisciplinary Institute for Broadband Technology (IBBT) through the
   CUPID project (50% co-funded by industrial partners), the Institute for
   the Promotion of Innovation by Science and Technology in Flanders (IWT),
   the Fund for Scientific Research-Flanders (FWO-Flanders), and the
   European Union.
CR [Anonymous], 2008, P 17 INT C WORLD WID, DOI DOI 10.1145/1367497.1367760
   [Anonymous], 2010, Proceedings of the 4th ACM conference on Recommender systems, DOI DOI 10.1145/1864708.1864756
   Beckett D, 2004, RDF XML SYNT SPEC RE
   Bray T., 2006, Extensible Markup Language (XML) 1.1 Specification, V2nd
   Breese J., 1998, P 14 C UNC ART INT, P43
   Brickley D., 2004, RDF VOCABULARY DESCR
   Campochiaro E, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS: WAINA, VOLS 1 AND 2, P648, DOI 10.1109/WAINA.2009.127
   Carmagnola F, 2006, MOBILE GUIDE 06
   Centre for Digital Music-University of London, 2007, EV ONT
   Cornelis C., 2005, Proceedings of the Second Indian International Conference on Artificial Intelligence (IICAI-05), Pune, INDIA, P2231
   Cornelis C, 2007, INFORM SCIENCES, V177, P4906, DOI 10.1016/j.ins.2007.07.001
   Davidson James, 2010, P 4 ACM C REC SYST, P293, DOI [DOI 10.1145/1864708.1864770, 10.1145/1864708]
   Hayes C, 2002, WORKSH PERS REC E CO
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Herlocker JL, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P230, DOI 10.1145/312624.312682
   Huang Z, 2004, ACM T INFORM SYST, V22, P116, DOI 10.1145/963770.963775
   Huang Z, 2004, AMCIS 2004 AM C INF
   Huang Z, 2007, IEEE INTELL SYST, V22, P68, DOI 10.1109/MIS.2007.4338497
   International Council of Museums / ICOMs International Committee for Documentation, 2009, DEF CID CONC REF MOD
   International Press Telecommunications Council, 2009, EVENTSML G2 SP VERS
   Internet Engineering Task Force, 2009, INT CAL SCHED COR OB
   Karypis G., 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P247, DOI 10.1145/502585.502627
   Kayaalp M, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING, P113, DOI 10.1109/ASONAM.2009.41
   Klamma R, 2009, L N INST COMP SCI SO, V4, P657
   Kurapati K, 2001, P 5 INT C US MOD WOR, P1
   Lee DH, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P311
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   LinkingOpenData (W3C SWEO Community Project)-Centre for Digital Music, 2007, LINKINGOPENDATA W3C
   Mannens E, 2009, EIMM 09, P33, DOI [10.1145/1631024.1631033, DOI 10.1145/1631024.1631033]
   Marshall A, 2016, 2016 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON EMOTION AWARENESS IN SOFTWARE ENGINEERING (SEMOTION), P6, DOI [10.1145/2897000.2897003, 10.1109/SEmotion.2016.011]
   McGuinness D. L., 2004, OWL WEB ONTOLOGY LAN, DOI DOI 10.2004-03
   McNee SM, 2006, CHI 06 HUM FACT COMP, P1097, DOI DOI 10.1145/1125451.1125659
   Morgan D.L., 1988, QUALITATIVE RES METH, V16
   Pemberton S, 2002, XHTML 1 0 EXTENSIBLE
   Prud'hommeaux Eric., 2007, SPARQL QUERY LANGUAG
   Segaran T., 2007, PROGRAMMING COLLECTI
   Shani G, 2010, RECSYS 2010, P1, DOI [10.1145/1864708.1864710, DOI 10.1145/1864708.1864710]
   Shaw R, 2009, P 4 INT AS SEM WEB C
   Wang J., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P501, DOI 10.1145/1148170.1148257
   Weng J, 2006, P 5 INT JOINT C AUT, P1260, DOI DOI 10.1145/1160633.1160860
   Yildirim H, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P131
NR 41
TC 8
Z9 8
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2012
VL 58
IS 1
BP 167
EP 213
DI 10.1007/s11042-010-0715-8
PG 47
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 917BS
UT WOS:000302147600008
DA 2024-07-18
ER

PT J
AU Avramova, ZK
   De Vleeschauwer, D
   Debevere, P
   Wittevrongel, S
   Lambert, P
   Van de Walle, R
   Bruneel, H
AF Avramova, Zlatka K.
   De Vleeschauwer, Danny
   Debevere, Pedro
   Wittevrongel, Sabine
   Lambert, Peter
   Van de Walle, Rik
   Bruneel, Herwig
TI On the performance of scalable video coding for VBR TV channels
   transport in multiple resolutions and qualities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264; SVC; Network design; Capacity estimation; TV; Multi-resolution
ID NETWORK
AB Video broadcast operators target a variety of receiving devices of different resolutions and processing capabilities. In such a heterogeneous TV network, the transport resource consumption is likely to increase. In this paper we estimate the required transport capacity for a broadcast TV network taking into account parameters as currently proposed in standardization bodies. We target constant video quality, hence the TV channel has variable bit rate (VBR). We consider a multicast-based transport system where only the required versions of a TV channel are transported; this leads to fluctuation of the consumed transport capacity over time. The main focus in this paper is on the comparison of a simulcast and a scalable video coding (SVC) transport scheme in several realistic examples with different encoding modes, including spatial and/or quality scalability. To estimate the required transport capacity for simulcast and SVC, we use a comprehensive toolkit based on a Gaussian approximation of the capacity demand. In order to obtain realistic input values for our calculation tools, we characterize the fluctuations of the bit rate associated with a TV channel by encoding a representative set of video clips. Based on the considered realistic examples, we explore under what conditions either the simulcast or the SVC transport scheme is more efficient.
C1 [Avramova, Zlatka K.; Wittevrongel, Sabine; Bruneel, Herwig] Univ Ghent, Fac Engn, SMACS Res Grp, TELIN, B-9000 Ghent, Belgium.
   [De Vleeschauwer, Danny] Bell Labs, B-2018 Antwerp, Belgium.
   [Debevere, Pedro; Van de Walle, Rik] Univ Ghent, Multimedia Lab, IBBT, Res Grp, B-9050 Ghent, Belgium.
C3 Ghent University; Ghent University
RP Avramova, ZK (corresponding author), Univ Ghent, Fac Engn, SMACS Res Grp, TELIN, St Pietersnieuwstr 41, B-9000 Ghent, Belgium.
EM zlatka.avramova@telin.ugent.be
RI De Vleeschauwer, Danny/J-6432-2019; Lambert, Peter/D-7776-2016
OI De Vleeschauwer, Danny/0000-0002-0718-8048; 
CR [Anonymous], P 16 INT PACK VID WO
   [Anonymous], 2007, H264 ITUT
   [Anonymous], JOINT SCALABLE VIDEO
   [Anonymous], 2007, CMAVC0128 DVBCMAVC
   Avramova Z, 2008, TELECOMMUN SYST, V39, P91, DOI 10.1007/s11235-008-9114-0
   Avramova Z, 2009, IEEE ICC, P1224
   Avramova Z, 2009, IEEE T MULTIMEDIA, V11, P918, DOI 10.1109/TMM.2009.2021806
   Jarnikov D, 2005, LECT NOTES COMPUT SC, V3824, P930
   Lotfallah OA, 2007, SIGNAL PROCESS-IMAGE, V22, P809, DOI 10.1016/j.image.2007.06.002
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   MCCANNE S, 1996, P ACM SIGCOMM 96 STA, P117
   SUN S, 2006, 18 M JOINT VID TEAM
   Zipf J. K., 1932, SELECTIVE STUDIES PR
   DESCRIPTION DVB H MO
NR 14
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2012
VL 57
IS 3
BP 605
EP 631
DI 10.1007/s11042-010-0661-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 904HS
UT WOS:000301185900008
OA Green Published
DA 2024-07-18
ER

PT J
AU Luo, XY
   Liu, FL
   Yang, CF
   Lian, SG
   Zeng, Y
AF Luo, Xiangyang
   Liu, Fenlin
   Yang, Chunfang
   Lian, Shiguo
   Zeng, Ying
TI Steganalysis of adaptive image steganography in multiple gray code
   bit-planes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Steganalysis; Adaptive steganography; Gray code;
   Bit-plane; Multiple bit-planes
ID LSB STEGANOGRAPHY; DIGITAL IMAGES
AB For detecting the MBPIS (multiple bit-planes image steganography), which embeds the messages into the multiple Gray code bit-planes, a steganalysis method is proposed to estimate the embedding ratios based on sample pairs analysis. The proposed method combines appropriate trace sets of a more elegant and pellucid sample pair analysis model to estimate the modification ratio of each natural binary bit-plane. Then the modification ratios in Gray code bit-planes are estimated from the modification ratios in natural binary bit-planes based on the relationship between natural binary bit-planes and Gray code bit-planes. Finally, considering the matrix encoding in MBPIS, the embedding ratios are obtained from the modification ratios in Gray code bit-planes. Experimental results show that compared with existing steganalysis methods, the proposed method can not only detect the stego images of MBPIS more reliably, but also estimate the embedding ratios of MBPIS with smaller errors. When the embedding ratio in the first Gray code bit-plane is not less than 0.1, the average absolute error of the proposed method will less than it of the ID3SPA by 0.04 at least.
C1 [Luo, Xiangyang; Liu, Fenlin; Yang, Chunfang; Zeng, Ying] Zhengzhou Informat Sci & Technol Inst, Zhengzhou 450002, Peoples R China.
   [Lian, Shiguo] France Telecom R&D Beijing, Beijing 100080, Peoples R China.
C3 PLA Information Engineering University
RP Luo, XY (corresponding author), Zhengzhou Informat Sci & Technol Inst, Zhengzhou 450002, Peoples R China.
EM xiangyangluo@126.com
FU National Natural Science Foundation of China [60970141, 60902102]; Found
   of Innovation Scientists and Technicians Outstanding Talents of Henan
   Province of China [094200510008]; Science-Technology Project of
   Zhengzhou City of China [083SGYG21125]; Information Science and
   Technology Institute [BSLWCX200804]
FX This work is supported by the National Natural Science Foundation of
   China (Grant Nos. 60970141 and 60902102), the Found of Innovation
   Scientists and Technicians Outstanding Talents of Henan Province of
   China (Grant No. 094200510008), the Science-Technology Project of
   Zhengzhou City of China (Grant No. 083SGYG21125), and the Doctoral
   Dissertation Innovation Fund of Information Science and Technology
   Institute (Grant No. BSLWCX200804).
CR [Anonymous], P SPIE MEDIA FORENSI
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   [Anonymous], P SPIE MULTIMEDIA SY
   Barbier J, 2008, LECT NOTES COMPUT SC, V5041, P99
   Böhme R, 2006, PROC SPIE, V6072, DOI 10.1117/12.643701
   Cachin C, 2004, INFORM COMPUT, V192, P41, DOI 10.1016/j.ic.2004.02.003
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Fridrich J, 2005, PROC SPIE, V5681, P631, DOI 10.1117/12.585987
   Fridrich J, 2004, PROC SPIE, V5306, P23, DOI 10.1117/12.521350
   Fridrich J, 2003, MULTIMEDIA SYST, V9, P288, DOI 10.1007/s00530-003-0100-9
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Fridrich J, 2002, PROC SPIE, V4675, P1, DOI 10.1117/12.465263
   Furuta T, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P970
   Ker AD, 2007, IEEE T INF FOREN SEC, V2, P46, DOI 10.1109/TIFS.2006.890519
   Ker AD, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P27, DOI 10.1145/1411328.1411335
   Kim C.H., 2003, PAC RIM WORKSH DIG S
   LIAN S, 2009, HDB RES SECURE MULTI
   Lian SG, 2009, INFORM-J COMPUT INFO, V33, P3
   Lopez-Hernandez J., 2008, P INT S INF THEOR AP, P1, DOI [10.1109/ISITA.2008.4895497, DOI 10.1109/ISITA.2008.4895497]
   Luo XY, 2010, SCI CHINA I IN PRESS, V53
   Nguyen BC, 2006, LECT NOTES COMPUT SC, V4283, P61
   Niimi M, 2004, IEEE IMAGE PROC, P733
   Noda H, 2002, IEEE SIGNAL PROC LET, V9, P410, DOI 10.1109/LSP.2002.806056
   Xiangyang Luo, 2007, Transactions on Data Hiding and Multimedia Security II. (Lecture Notes in Computer Science vol. 4499), P68
   Xiaoyi Yu, 2004, Proceedings. Third International Conference on Image and Graphics, P333
   Yang CF, 2008, IEEE T INF FOREN SEC, V3, P662, DOI 10.1109/TIFS.2008.2007240
   Yang CF, 2009, LECT NOTES COMPUT SC, V5806, P59, DOI 10.1007/978-3-642-04431-1_5
   YU X, 2005, P IEEE INT C IM PROC, V2, P1102
   Yu XY, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P1443
   Zhang T, 2003, SIGNAL PROCESS, V83, P2085, DOI 10.1016/S0165-1684(03)00169-5
   Zhang Xinpeng, 2005, Journal of Computer Aided Design & Computer Graphics, V17, P1625
   Zöllner J, 1998, LECT NOTES COMPUT SC, V1525, P344
NR 32
TC 8
Z9 9
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2012
VL 57
IS 3
BP 651
EP 667
DI 10.1007/s11042-010-0663-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 904HS
UT WOS:000301185900010
DA 2024-07-18
ER

PT J
AU De Pessemier, T
   De Moor, K
   Ketykó, I
   Joseph, W
   De Marez, L
   Martens, L
AF De Pessemier, Toon
   De Moor, Katrien
   Ketyko, Istvan
   Joseph, Wout
   De Marez, Lieven
   Martens, Luc
TI Investigating the influence of QoS on personal evaluation behaviour in a
   mobile context
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommendation; User feedback; Mobile; Quality of experience; User
   experience; Quality of service
ID VIDEO QUALITY; RECOMMENDATION
AB The efficiency of personal video suggestions generated by recommender systems is highly dependent on the quality of the obtained user feedback. This feedback has to reflect the personal interest in the content of the viewed video, to obtain accurate results. However, user feedback might undesirably be influenced by additional aspects such as the loading speed or the quality of the video. To date, this issue has received very little research attention. Therefore, this study investigates the direct influence of audio-visual quality parameters on explicit user feedback for the first time to our knowledge via a mobile, Living Lab experiment. This paper proposes a feedback model which takes the Quality of Service (QoS) parameters of the mobile network into account. This model can be used as an additional feedback filter for video recommendation systems that could help to eliminate the influences of QoS on explicit user feedback.
C1 [De Pessemier, Toon; Ketyko, Istvan; Joseph, Wout; Martens, Luc] Ghent Univ IBBT, INTEC WiCa, B-9050 Ghent, Belgium.
   [De Moor, Katrien; De Marez, Lieven] Ghent Univ IBBT, Dept Commun Sci, B-9000 Ghent, Belgium.
   [Joseph, Wout] Univ Ghent, Dept Informat Technol INTEC, Ghent, Belgium.
C3 Ghent University; Ghent University; Ghent University
RP De Pessemier, T (corresponding author), Ghent Univ IBBT, INTEC WiCa, Gaston Crommenlaan 8,Box 201, B-9050 Ghent, Belgium.
EM toon.depessemier@intec.ugent.be; katrienr.demoor@ugent.be;
   istvan.ketyko@intec.ugent.be; wout.joseph@intec.ugent.be;
   luc.martens@intec.ugent.be; lieven.demarez@ugent.be
OI Joseph, Wout/0000-0002-8807-0673; De Moor, Katrien/0000-0002-8752-3351;
   De Marez, Lieven/0000-0001-7716-4079; Ketyko, Istvan/0000-0003-4931-4580
FU IBBT / UGent (Interdisciplinary institute for BroadBand Technology /
   Ghent University) through the GR@SP
FX We would like to thank the Research Foundation-Flanders (FWO), for the
   research position of Toon De Pessemier (pre-doctoral fellow) and Wout
   Joseph (post-doctoral fellow). Besides, this work was supported by the
   IBBT / UGent (Interdisciplinary institute for BroadBand Technology /
   Ghent University) through the GR@SP-project.
CR Aljukhadar M, 2010, P ACM RECSYS 2010 WO
   [Anonymous], 1999, P ACM SIGIR WORKSH R
   Bell Robert M, 2007, Acm Sigkdd Explorations Newsletter, V9, P75, DOI [10.1145/1345448.1345465, DOI 10.1145/1345448.1345465]
   Breese J. S., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P43
   Cha M, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P1
   Chung ET, 2007, FINAL REPORT VIDEO Q
   De Moor K, 2010, MOBILE NETW APPL, V15, P378, DOI 10.1007/s11036-010-0223-0
   De Pessemier T, 2009, EUROITV'09: PROCEEDINGS OF THE SEVENTH EUROPEAN INTERACTIVE TELEVISION CONFERENCE, P133
   Folstad A., 2008, Electr. J. Organ. Virtual., V10, P99
   Good N, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P439
   Heckerman D, 2001, J MACH LEARN RES, V1, P49, DOI 10.1162/153244301753344614
   Jacobson V, 1989, TCPDUMP PACKET ANAL
   Jumisko SH, 2005, PROC SPIE, V5684, P243, DOI 10.1117/12.596503
   Jumisko-Pyykko S., 2005, 13th Annual ACM International Conference on Multimedia, P535, DOI 10.1145/1101149.1101270
   Jumisko-Pyykkö S, 2008, MULTIMED TOOLS APPL, V36, P167, DOI 10.1007/s11042-006-0080-9
   Karypis G., 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P247, DOI 10.1145/502585.502627
   Knoche H., 2005, 13th Annual ACM International Conference on Multimedia, P829, DOI 10.1145/1101149.1101331
   Korhonen Jari, 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P64, DOI 10.1109/QOMEX.2010.5518112
   Kortum P., 2004, P HUMAN FACTORS ERGO, P1910
   Kortum P, 2010, HUM FACTORS, V52, P105, DOI 10.1177/0018720810366020
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   Miller B. N., 2003, P 2003 C INT US INT
   Mooney R. J., 2000, ACM 2000. Digital Libraries. Proceedings of the Fifth ACM Conference on Digital Libraries, P195, DOI 10.1145/336597.336662
   Oard D.W., 1998, Implicit Feedback for Recommender Systems
   Pennock DM, 2001, PROBABILISTIC MODELS
   Pfeiffer S., 2000, MULTIMEDIA 00, P89, DOI DOI 10.1145/357744.357885
   Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121
   Sarwar B, 2000, APPL DIMENSIONALITY
   Schein A. I., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P253, DOI 10.1145/564376.564421
   Schumacher J., 2008, EUROPEAN LIVING LABS
   Schuurman D, 2009, EUROITV'09: PROCEEDINGS OF THE SEVENTH EUROPEAN INTERACTIVE TELEVISION CONFERENCE, P189
   Senter H.F., 2008, Journal of the American Statistical Association, V103, P880, DOI [10.1198/016214508000000300, DOI 10.1198/016214508000000300]
   Sullivan M., 2008, P 1 INT C DES INT US, P1
   Tseng BL, 2002, P SOC PHOTO-OPT INS, V4676, P359
   Ungar Lyle., 1998, CLUSTERING METHODS C
   Wang HC, 2007, EXPERT SYST APPL, V32, P571, DOI 10.1016/j.eswa.2006.01.034
   Yu ZW, 2007, 21ST INTERNATIONAL CONFERENCE ON ADVANCED NETWORKING AND APPLICATIONS, PROCEEDINGS, P604, DOI 10.1109/AINA.2007.73
   Yu ZW, 2006, USER MODEL USER-ADAP, V16, P63, DOI 10.1007/s11257-006-9005-6
   Yu ZW, 2004, IEEE T CONSUM ELECTR, V50, P393, DOI 10.1109/TCE.2004.1277889
   Zhang HG, 2005, IEEE T CONSUM ELECTR, V51, P731, DOI 10.1109/TCE.2005.1468026
NR 40
TC 6
Z9 6
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2012
VL 57
IS 2
BP 335
EP 358
DI 10.1007/s11042-010-0712-y
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 904HQ
UT WOS:000301185700006
OA Green Published
DA 2024-07-18
ER

PT J
AU Chou, JK
   Yang, CK
   Gong, SD
AF Chou, Jia-Kai
   Yang, Chuan-Kai
   Gong, Sing-Dong
TI Face-off: automatic alteration of facial features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Poisson image editing; Feature extraction; Active shape model; Facial
   feature alteration
AB Pursuing or maintaining beautifulness nowadays has become a trend in modern society, especially among the celebrity community. In some cases, one may choose to adopt drastic procedures to alter his or her facial or body features to achieve the desired beauty, thus the blossom of industry on cosmetic plastic surgeries. In addition, people whose faces got damaged due to accidental burns or wounds may also find these surgeries necessary. However, as performing the related surgeries are still considered intrusive and costly, it is better to "preview" the result before a surgery is actually carried out. As many believe that facial appearance matters most, we have developed a system that allows a user to input a photo and changes the associated individual facial feature in an automatic and user-friendly manner. Overall speaking, our system makes contributions in the following four aspects. First, our system not only offers the previewing functionality, but also allows users to interactively fine-tune the desired results, thus making it a useful companion tool for facial cosmetic surgeries. Second, instead of exchanging the overall look of a face, as being done by some existing approaches, our system offers much finer granularity by allowing each and every facial feature to be changed individually and independently, thus achieving higher face-off flexibility. Third, while existing tools generally entail manual effort to locate or align facial features, our system, through the help of Active Shape Model or ASM for short, characterized by a scheme of automatic feature extraction, eliminates most of the needs of user assistance. Finally, for convenience, we have constructed a database of facial features to facilitate the facial feature alteration process. To justify our claims, we have rendered results and compared them with those from existing approaches to demonstrate the effectiveness of our system. We have also conducted a user study to further confirm the usefulness of such a system.
C1 [Chou, Jia-Kai; Yang, Chuan-Kai; Gong, Sing-Dong] Natl Taiwan Univ Sci & Technol, Dept Informat Management, Taipei 106, Taiwan.
C3 National Taiwan University of Science & Technology
RP Yang, CK (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Informat Management, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
EM A9409004@mail.ntust.edu.tw; ckyang@cs.ntust.edu.tw; hgznrn@uj.com.tw
CR Adelson E. H., 1984, RCA engineer, V29, P33, DOI 10.1.1.59.9419.
   Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718
   [Anonymous], SIGGRAPH 2000
   [Anonymous], SIGGRAPH 1999
   Bitouk D, 2008, SIGGRAPH 2008
   Blanz V., 2004, EUROGRAPHICS 2004
   Bornard R., 2002, P ACM INT C MULTIMED, P355
   Boykov Y.Y., 2001, ICCV 2001
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, PROC SPIE, V4322, P236, DOI 10.1117/12.431093
   Efros A., 1999, ICCV 99
   Gu H, 2003, IM VIS COMP NZ
   Jia JY, 2006, ACM T GRAPHIC, V25, P631, DOI 10.1145/1141911.1141934
   Kjeldsen R, 1996, FG 96 2 INT C AUT FA
   Kwatra V., 2003, SIGGRAPH 2003
   Lalonde J, 2007, SIGGRAPH 2007
   Levin A, 2004, LECT NOTES COMPUT SC, V2034, P377
   Leyvand T, 2006, SIGGRAPH 2006 TECHN
   Leyvand T, 2008, SIGGRAPH 2008
   Mortensen E. N., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P191, DOI 10.1145/218380.218442
   Oliveira MM, 2001, VIIP INT C VIS IM IM
   PELEG S, 1981, C PATT REC IM PROC D, P426
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Sun J, 2005, ACM T GRAPHIC, V24, P861, DOI 10.1145/1073204.1073274
   Uyttendaele M, 2001, PROC CVPR IEEE, P509
   Wang J, 2007, SIGGRAPH 2007
   Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009
   Yang CK, 2008, MULTIMED TOOLS APPL, V40, P41, DOI 10.1007/s11042-007-0184-x
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
NR 29
TC 8
Z9 10
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2012
VL 56
IS 3
BP 569
EP 596
DI 10.1007/s11042-010-0624-x
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 891AX
UT WOS:000300189700009
DA 2024-07-18
ER

PT J
AU Leng, BA
   Xiong, Z
AF Leng, Biao
   Xiong, Zhang
TI ModelSeek: an effective 3D model retrieval system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model retrieval; Model descriptor; Relevance feedback; Mapping
   mechanism
ID RELEVANCE FEEDBACK; DIMENSIONALITY REDUCTION; IMAGE RETRIEVAL; SEARCH
   ENGINE
AB Since object similarity is a subjective matter, the gap between low-level feature representations and high-level semantic concepts is a major problem in the field of content-based 3D model retrieval. This paper presents a novel composite model descriptor, which takes into account both visual and geometric characteristics of 3D models. It also proposes an original mapping mechanism from low-level model features to high-level semantic concepts based on the user's retrieval history, and so this method belongs to long-term relevance feedback algorithms for 3D model retrieval. Finally, an effective 3D model retrieval system "ModelSeek" has been built, and implemented with the introduced model descriptor and mapping mechanism. The experimental results show that the approaches above not only have significantly improved the retrieval performance, but have also achieved better retrieval effectiveness than the state-of-the-art techniques on the publicly available 3D model criterion that Princeton Shape Benchmark (PSB) and several standard evaluation measures.
C1 [Leng, Biao; Xiong, Zhang] Beihang Univ, Sch Comp Sci & Engn, Beijing, Peoples R China.
C3 Beihang University
RP Leng, BA (corresponding author), Beihang Univ, Sch Comp Sci & Engn, Beijing, Peoples R China.
EM lengbiao@buaa.edu.cn
FU Key Projects in the National Science & Technology Pillar Program
   [2006BAB04A13]; National Natural Science Foundation of China [60803120]
FX The 3D model database PSB is from the Shape Retrieval and Analysis Group
   at the University of Princeton, United States. This work is supported by
   the Key Projects in the National Science & Technology Pillar Program
   during the Eleventh Five-Year Plan Period (No. 2006BAB04A13), and the
   National Natural Science Foundation of China (No. 60803120).
CR [Anonymous], THESIS U LEIPZIG LEI
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Atmosukarto I, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P334, DOI 10.1109/MMMC.2005.39
   Bang HY, 2002, IEEE IMAGE PROC, P968
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Borlund P, 2003, J AM SOC INF SCI TEC, V54, P913, DOI 10.1002/asi.10286
   Buckley C., 1994, P 3 TEXT RETRIEVAL C, P69
   BUCKLEY C, 1995, P 18 ANN INT ACM SIG, P351
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   Daras P, 2006, IEEE T MULTIMEDIA, V8, P101, DOI 10.1109/TMM.2005.861287
   Djeraba C, 2006, MULTIMED TOOLS APPL, V30, P221, DOI 10.1007/s11042-006-0025-3
   Elad M., 2001, PROC EG MULTIMEDIA, P97, DOI DOI 10.2312/EGMM/EGMM01/107-118
   Funkhouser T, 2005, COMMUN ACM, V48, P58, DOI 10.1145/1064830.1064859
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Guétat G, 2006, IEEE T INF TECHNOL B, V10, P362, DOI 10.1109/TITB.2005.863875
   HARTER SP, 1992, J AM SOC INFORM SCI, V43, P602, DOI 10.1002/(SICI)1097-4571(199210)43:9<602::AID-ASI3>3.0.CO;2-Q
   He XF, 2003, IEEE T CIRC SYST VID, V13, P39, DOI 10.1109/TCSVT.2002.808087
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Iyer N, 2005, COMPUT AIDED DESIGN, V37, P509, DOI 10.1016/j.cad.2004.07.002
   Kolonias I, 2005, IEEE T MULTIMEDIA, V7, P114, DOI 10.1109/TMM.2004.840605
   Leifman G, 2005, VISUAL COMPUT, V21, P865, DOI 10.1007/s00371-005-0341-z
   Leng B, 2008, MULTIMED TOOLS APPL, V40, P135, DOI 10.1007/s11042-007-0188-6
   Leng B, 2007, J ZHEJIANG UNIV-SC A, V8, P1953, DOI 10.1631/jzus.2007.A1953
   Mandel MI, 2006, MULTIMEDIA SYST, V12, P3, DOI 10.1007/s00530-006-0032-2
   NOVOTNI M, 2005, P 4 INT WORKSH CONT
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Papadakis P, 2007, PATTERN RECOGN, V40, P2437, DOI 10.1016/j.patcog.2006.12.026
   Pu JT, 2006, COMPUT AIDED DESIGN, V38, P249, DOI 10.1016/j.cad.2005.10.009
   Regli WC, 2000, COMPUT AIDED DESIGN, V32, P119, DOI 10.1016/S0010-4485(99)00095-0
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   SARACEVIC T, 1975, J AM SOC INFORM SCI, V26, P321, DOI 10.1002/asi.4630260604
   SCHAMBER L, 1990, INFORM PROCESS MANAG, V26, P755, DOI 10.1016/0306-4573(90)90050-C
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Shih JL, 2005, ELECTRON LETT, V41, P179, DOI 10.1049/el:20056916
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   SWANSON DR, 1986, LIBR QUART, V56, P389, DOI 10.1086/601800
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   Vranic DV, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P963
   Vranic DV, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P757
   Yeh JS, 2005, BIOINFORMATICS, V21, P3056, DOI 10.1093/bioinformatics/bti458
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 46
TC 32
Z9 32
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2011
VL 51
IS 3
BP 935
EP 962
DI 10.1007/s11042-009-0424-3
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 717XL
UT WOS:000287081100005
DA 2024-07-18
ER

PT J
AU Rafailidis, D
   Nanopoulos, A
   Manolopoulos, Y
AF Rafailidis, Dimitris
   Nanopoulos, Alexandros
   Manolopoulos, Yannis
TI Nonlinear dimensionality reduction for efficient and effective audio
   similarity searching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio similarity searching; Content based retrieval; Music database;
   Nonlinear dimensionality reduction
AB In this paper, we address the issue of nonlinear dimensionality reduction to efficiently index spectral audio similarity measures. We propose the embedding of the spectral similarity space to a low-dimensional Euclidean space. This guarantees the triangular inequality and allows the adoption of several indexing schemes. We enlighten the advantages of the proposed indexable method against recently proposed spectral similarity measures that are also indexable. Moreover, our method compares favorably to linear dimensionality reduction methods, like multidimensional scaling (MDS). The proposed method significantly reduces the computation time during the construction process compared to any audio measure and, simultaneously, minimizes the searching cost for similar songs. To the best of our knowledge, the important issue of audio similarity measures' scalability is addressed for the first time.
C1 [Rafailidis, Dimitris; Manolopoulos, Yannis] Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
   [Nanopoulos, Alexandros] Univ Hildesheim, Inst Comp Sci, D-31141 Hildesheim, Germany.
C3 Aristotle University of Thessaloniki; University of Hildesheim
RP Rafailidis, D (corresponding author), Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
EM draf@csd.auth.gr; nanopoulos@ismll.de; manolopo@csd.auth.gr
RI Manolopoulos, Yannis/AAI-7767-2020
OI Rafailidis, Dimitrios/0000-0002-7366-3716
CR [Anonymous], 2001, Proc. IEEE International Conference on Multimedia and Expo
   [Anonymous], 2004, Journal of negative results in speech and audio sciences
   Aucouturier J. -J., 2006, THESIS U PARIS 6 FRA
   BAUMANN S, 2005, TUT 6 INT S MUS INF
   Berenzweig A, 2004, COMPUT MUSIC J, V28, P63, DOI 10.1162/014892604323112257
   Borg I., 2005, Modern Multidimensional Scaling: Theory and Applications
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Chakrabarti K, 2002, ACM T DATABASE SYST, V27, P188, DOI 10.1145/568518.568520
   Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Guttman A., 1984, SIGMOD Record, V14, P47, DOI 10.1145/971697.602266
   Jensen JesperHojvang., 2007, Proceedings of the 8th International Conference on Music Information Retrieval, ISMIR, P107
   Keogh E., 2001, Knowledge and Information Systems, V3, P263, DOI 10.1007/PL00011669
   Kouropteva O, 2005, PATTERN RECOGN, V38, P1764, DOI 10.1016/j.patcog.2005.04.006
   Pampalk E., 2005, Proceedings of the International Conference on Music Information Retrieval, P628
   POHLE T, 2007, STRIVING IMPROVED AU
   Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining, P43
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Silva V., 2002, NIPS, P721
   Vu K., 2006, P ACM SIGMOD INT C M, P527, DOI DOI 10.1145/1142473.1142532
NR 20
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2011
VL 51
IS 3
BP 881
EP 895
DI 10.1007/s11042-009-0420-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 717XL
UT WOS:000287081100002
DA 2024-07-18
ER

PT J
AU Bai, L
   Hu, YL
   Lao, SY
   Smeaton, AF
   O'Connor, NE
AF Bai, Liang
   Hu, Yanli
   Lao, Songyang
   Smeaton, Alan F.
   O'Connor, Noel E.
TI Automatic summarization of rushes video using bipartite graphs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Evaluation
AB In this paper we present a new approach for automatic summarization of rushes, or unstructured video. Our approach is composed of three major steps. First, based on shot and sub-shot segmentations, we filter sub-shots with low information content not likely to be useful in a summary. Second, a method using maximal matching in a bipartite graph is adapted to measure similarity between the remaining shots and to minimize inter-shot redundancy by removing repetitive retake shots common in rushes video. Finally, the presence of faces and motion intensity are characterised in each sub-shot. A measure of how representative the sub-shot is in the context of the overall video is then proposed. Video summaries composed of keyframe slideshows are then generated. In order to evaluate the effectiveness of this approach we re-run the evaluation carried out by TRECVid, using the same dataset and evaluation metrics used in the TRECVid video summarization task in 2007 but with our own assessors. Results show that our approach leads to a significant improvement on our own work in terms of the fraction of the TRECVid summary ground truth included and is competitive with the best of other approaches in TRECVid 2007.
C1 [Bai, Liang; Smeaton, Alan F.; O'Connor, Noel E.] Dublin City Univ, CLARITY Ctr Sensor Web Technol, Dublin 9, Ireland.
   [Hu, Yanli; Lao, Songyang] Natl Univ Def Technol, Sch Informat Syst & Management, Changsha 410073, Hunan, Peoples R China.
C3 Dublin City University; National University of Defense Technology -
   China
RP Smeaton, AF (corresponding author), Dublin City Univ, CLARITY Ctr Sensor Web Technol, Dublin 9, Ireland.
EM Alan.Smeaton@DCU.ie; Noel.OConnor@DCU.ie
OI Smeaton, Alan F./0000-0003-1028-8389; O'Connor, Noel/0000-0002-4033-9135
FU National High Technology Development 863 Program of China
   [2006AA01Z316]; National Natural Science Foundation of China [60572137,
   60875048]; Science Foundation Ireland; CLARITY CSET [07/CE/I1147]
FX This work was funded by the National High Technology Development 863
   Program of China (2006AA01Z316), the National Natural Science Foundation
   of China (60572137 and 60875048) and by Science Foundation Ireland as
   part of the CLARITY CSET (07/CE/I1147). The authors thank the reviewers
   for their helpful and insightful feedback.
CR [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], P 14 ACM INT C MULT
   [Anonymous], 2 IEE EUR WORKSH INT
   BYRNE D, 2007, TVS 07, P35
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cooray S, 2005, AVSS 2005: Advanced Video and Signal Based Surveillance, Proceedings, P253
   DAI Y, 1995, GRAPH THEORY ALGEBRA, P89
   Ferman AM, 2003, IEEE T MULTIMEDIA, V5, P244, DOI 10.1109/TMM.2003.811617
   Liu CJ, 2003, IEEE T PATTERN ANAL, V25, P725, DOI 10.1109/TPAMI.2003.1201822
   Ma Y.-F., 2002, ACM MULTIMEDIA, P533
   OVER P, 2008, TVS 08, P1
   Over P., 2007, TVS '07: Proc. of the International Workshop on TRECVID Video Summarization, P1, DOI DOI 10.1145/1290031.1290032
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   Taskiran CM, 2006, IEEE T MULTIMEDIA, V8, P775, DOI 10.1109/TMM.2006.876282
NR 14
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2010
VL 49
IS 1
SI SI
BP 63
EP 80
DI 10.1007/s11042-009-0398-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 595WF
UT WOS:000277643600004
DA 2024-07-18
ER

PT J
AU Hirzallah, N
   AlBalawi, W
   Kayed, A
   Nusir, S
AF Hirzallah, Nael
   AlBalawi, Wafi
   Kayed, Ahmad
   Nusir, Sawsan
TI A simple algorithm to enrich eLectures with instructor notes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE eLearning; Multimedia education; eLectures
ID EDGE-DETECTION
AB One of the devices that may help in content development for eLearning services is an Electronic Copyboard (e-board). Once it is available in every classroom, it helps in extracting the lecturer notes in an electronic as-in-class format. This paper introduces an alternative solution to e-boards. The presented solution is much cheaper and much simpler to install if compared to that of the e-boards. It could be implemented using a web camera and a video processing algorithm to extract notes that were added or removed by the lecturer. The notes extracted along with the slides presented and the recorded lecturer voice may compose a complete as-in-class electronic form of the lecture (eLecture). This paper presents first the proposed Notes Extraction Algorithm and runs few experiments when the notes are added on a traditional white board under various scenarios. The algorithm takes into consideration the brightness variations of the video in detecting the notes especially since this is normal to occur due to for instant to the lecturer movements in front of the white board. Second, the paper presents an authoring tool that includes the proposed algorithm to extract notes and combines them along with video and slides, if exist, before generating eLectures that could be viewed using popular players.
C1 [Hirzallah, Nael] Fahad Bin Sultan Natl Univ, Coll Comp, Comp Engn Dept Chair, Tabuk, Saudi Arabia.
   [Nusir, Sawsan] Yarmouk Univ, Irbid, Jordan.
C3 Fahad Bin Sultan University; Yarmouk University
RP Hirzallah, N (corresponding author), Fahad Bin Sultan Natl Univ, Coll Comp, Comp Engn Dept Chair, Tabuk, Saudi Arabia.
EM Nhirzallah@fbsc.edu.sa; wafi@fbsc.edu.sa; kayed@fbsc.edu.sa;
   snusir@hotmail.com
RI Kayed, Ahmad/ABD-3249-2021
CR Abowd GD, 1999, IBM SYST J, V38, P508, DOI 10.1147/sj.384.0508
   CHERRI AK, 1989, APPL OPTICS, V28, P4644, DOI 10.1364/AO.28.004644
   Hirzallah Nael, 2007, American Journal of Applied Sciences, V4, P686, DOI 10.3844/ajassp.2007.686.692
   HRST W, 2004, P ICCE 2004 INT C CO
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   OTTMANN T, 2000, ACM SPRINGER MUULTIM, V8
   ZIEWER P, 2002, TRANSPARENT TELETEAC
NR 7
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2010
VL 49
IS 2
BP 259
EP 275
DI 10.1007/s11042-009-0343-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 604OB
UT WOS:000278287300001
DA 2024-07-18
ER

PT J
AU Pigeau, A
AF Pigeau, Antoine
TI MyOwnLife: incremental and hierarchical classification of a personal
   image collection on mobile devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia retrieval; Image collection management; Mobile device;
   Probabilistic modelling
AB Browsing multimedia collection on mobile devices raises the needs for new multimedia indexing solutions. In this paper, we focus on the management of personal image collections. We propose a method to simplify the browsing task on such a collection. The contributions reside in an incremental hierarchical algorithm, a method to provide a textual representation of the groups obtained and an algorithm to build a geo-temporal view of the collection. The proposed incremental hierarchical algorithm builds a temporal tree from the time stamp of each image. We opt here for a combination of a supervised clustering and an incremental algorithm based on mixture model. Good properties of the hierarchy are determined automatically thanks to the Integrated Likelihood Criterion (ICL). Based on the events obtained, a textual representation is proposed and then used to improve our temporal classification, combining geographical and temporal information. Results are validated on several real user collections with our prototype MyOwnLife.
C1 CNRS, LINA, UMR 6241, F-44322 Nantes 03, France.
C3 Centre National de la Recherche Scientifique (CNRS)
RP Pigeau, A (corresponding author), CNRS, LINA, UMR 6241, 2 Rue Houssiniere, F-44322 Nantes 03, France.
EM antoine.pigeau@univ-nantes.fr
CR [Anonymous], P 13 ANN ACM INT C M
   [Anonymous], MSRTR200217
   Biernacki C, 2000, IEEE T PATTERN ANAL, V22, P719, DOI 10.1109/34.865189
   Chen CF, 2006, LECT NOTES COMPUT SC, V3936, P362
   Chen CF, 2008, INT WORK CONTENT MUL, P518
   COOPER M, 2003, P 11 ACM INT C MULT, P364
   Cooper M, 2005, ACM T MULTIM COMPUT, V1
   Fraley C, 1998, SIAM J SCI COMPUT, V20, P270, DOI 10.1137/S1064827596311451
   Graham A., 2002, Proceedings of the second ACM/IEEE-CS joint conference on Digital libraries, P326
   Jaffe Alexander., 2006, P INT C WORLD WIDE W, P853
   Kennedy L., 2008, P 17 INT WORLD WID W
   Lacerda YA, 2008, IEEE INT SYM MULTIM, P258, DOI 10.1109/ISM.2008.81
   Naaman M, 2004, ACM-IEEE J CONF DIG, P53, DOI 10.1145/996350.996366
   NAAMAN M, 2004, INT WORLD WID WEB C, P244
   Nair R., 2005, P INT C ACM MULT, P222
   O'Hare Neil, 2005, 2nd European Workshop on the Integration of Knowledge, Semantics and Digital Media Technology (EWIMT 2005), P323, DOI 10.1049/ic.2005.0750
   SARVAS R, 2004, MOBILE SYSTEMS APPL
   Toyama Kentaro., 2003, P 11 ACM INT C MULTI, P156
   Ullas G, 2003, P 5 ACM SIGMM INT WO, P47
   VIANA W, 2008, LECT NOTES COMPUTER, P187
NR 20
TC 1
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2010
VL 46
IS 2-3
SI SI
BP 289
EP 306
DI 10.1007/s11042-009-0373-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 542GF
UT WOS:000273480300007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Shan, MK
   Chiu, SC
AF Shan, Man-Kwan
   Chiu, Shih-Chuan
TI Algorithmic compositions based on discovered musical patterns
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Algorithmic composition; Data mining; Music style; Repeating patterns
AB Computer music composition is the dream of computer music researchers. In this paper, a top-down approach is investigated to discover the rules of musical composition from given music objects and to create a new music object of which style is similar to the given music objects based on the discovered composition rules. The proposed approach utilizes the data mining techniques in order to discover the styled rules of music composition characterized by music structures, melody styles and motifs. A new music object is generated based on the discovered rules. To measure the effectiveness of the proposed approach in computer music composition, a method similar to the Turing test was adopted to test the differences between the machine-generated and human-composed music. Experimental results show that it is hard to distinguish between them. The other experiment showed that the style of generated music is similar to that of the given music objects.
C1 [Shan, Man-Kwan; Chiu, Shih-Chuan] Natl Chengchi Univ, Dept Comp Sci, Taipei 11623, Taiwan.
C3 National Chengchi University
RP Shan, MK (corresponding author), Natl Chengchi Univ, Dept Comp Sci, 64 Chihnan Rd,Sec 2 Wenshan, Taipei 11623, Taiwan.
EM mkshan@cs.nccu.edu.tw; scchiu@cs.nctu.edu.tw
CR Agrawal R., 1995, P IEEE INT C DAT ENG
   AGRAWAL R, 1994, P INT C VERY LARG DA, P8
   AME C, 1992, UNDERSTANDING MUSIC
   BEL B, 1998, COMPUT MUSIC J, V22
   BILES JA, 1994, P INT COMP MUS C ICM
   BLACKWELL TM, 2002, P C EV COMP CEC 02
   BROWN AR, 2002, P AUSTR COMP MUS C A
   Cambouropoulos E., 2001, P INT COMP MUS C ICM
   Chai W., 2001, P INT C ART INT ICAI
   CHEN CL, 2001, P INT JOINT C NEUR N
   CHEN HC, 2004, P IEEE INT C MULT EX
   Conklin D., 2003, P S ART INT CREAT AR
   COPE D, 1992, COMPUT MUSIC J, V16, P69, DOI 10.2307/3680717
   Cope D., 1996, EXPT MUSICAL INTELLI
   Cope D, 2000, ALGORITHMIC COMPOSER
   COPE D, 1991, IEEE COMPUTER, V24
   CORREA DC, 2008, P ACM S APPL COMP SA
   Dannenberg Roger B., 1997, P INT COMP MUS C ICM
   Davie CedricThorpe., 1966, MUSICAL STRUCTURE DE
   DUBNOV S, 2003, IEEE COMPUT, V36
   ESPI D, 2007, P INT WORKSH ART INT
   Farbood M. M., 2001, P INT COMP MUS C ICM
   GUERET C, 2004, P ANT COL OPT SWARM
   HO MC, 2007, IEEE MULTIMEDI UNPUB
   HSU JL, 2001, IEEE T MULTIMED, V3
   Jones NC., 2004, An introduction to bioinformatics algorithms
   Karydis I, 2007, MULTIMED TOOLS APPL, V32, P49, DOI 10.1007/s11042-006-0068-5
   LARTILLOT O, 2002, P INT C COMP MUS ICM
   Lo YL, 2008, MULTIMED TOOLS APPL, V37, P169, DOI 10.1007/s11042-007-0138-3
   McAlpine K, 1999, COMPUT MUSIC J, V23, P19, DOI 10.1162/014892699559733
   MELUCCI M, 2002, P INT S MUS INF RETR
   Miranda Eduardo, 2001, Composing music with computers, DOI DOI 10.4324/9780080502403
   MIURA T, 2006, P GERM WORKSH ART LI
   Muscutt K, 2007, COMPUT MUSIC J, V31, P10, DOI 10.1162/comj.2007.31.3.10
   PAPADOPOULOS G, 1998, P SOFTW TECHN ENG PR
   PEARCE M, 2001, P S ART INT CREAT AR
   de León PJP, 2007, IEEE T SYST MAN CY C, V37, P248, DOI 10.1109/TSMCC.2006.876045
   REAGAN P, 1999, THESIS CARNEGIE MELL
   SHAN MK, 2002, P IEEE INT C MULT EX
   SHAN MK, 2003, IEICE T INF SYST D, V86
   Sorensen A., 2000, P AUSTR COMP MUS C
   Stein Leon., 1979, STRUCTURE STYLE STUD
   TAKASU A, 1999, P EUR C RES ADV TECH
   TOMINAGA K, 2008, LECT NOTES COMPUT SC, V4976
   UITDENBOGERD AL, 1999, P ACM INT C MULT MM
   UTGOFF PE, 2006, P INT COMP MUS C ICM
   VANKRANENBURG P, 2004, P C INT MUS CIM 04
   VERBEURGT K, 2004, P INT C INN APPL ART
   WEYDE T, 2007, P INT S MUS INF RETR
   WIGGINS G, 1998, P ANT MUS COGN CASYS
   Witten I. H., 2005, DATA MINING PRACTICA
NR 51
TC 17
Z9 18
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2010
VL 46
IS 1
BP 1
EP 23
DI 10.1007/s11042-009-0303-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Engineering
GA 537DQ
UT WOS:000273093600001
DA 2024-07-18
ER

PT J
AU Belkhatir, M
AF Belkhatir, Mohammed
TI An operational model based on knowledge representation for querying the
   image content with concepts and relations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image indexing and retrieval; Semantic/Relational integration; Knowledge
   representation formalisms; Conceptual graphs; Precision/Recall
   validation
ID FRAMEWORK
AB In order to overcome the semantic gap (i.e. the gap between low-level extracted features and semantic description in state-of-the-art content-based image retrieval systems, a class of frameworks proposed within the framework of the European Fermi project, consisted of modeling the semantic content of images following a sharp process of human-assisted indexing. These approaches, based on expressive knowledge-based representation models provide satisfactory results in terms of retrieval quality but are not easily usable on large collections of images because of the necessary human intervention required for indexing. We propose in this paper to integrate the content-based and semantic-based solutions through a model featuring semantic and relational characterizations of the multimedia (image) content for automatic symbolic indexing and retrieval. Its instantiation as an image retrieval framework relies on a representation formalism handling high-level image descriptions and allowing to query with conceptual descriptors. Our approach complements content-based solutions through the mapping of low-level extracted features to semantic concepts and the manipulation of graph-based symbolic index and query structures; and extends the semantic-based solutions by considering automatically-extracted semantic and relational information. At the experimental level, we evaluate the retrieval performance of our system on queries coupling both semantic and relational characterizations through recall and precision indicators on a test collection of 2,500 color photographs and the TRECVID keyframe corpus.
C1 Monash Univ, Fac Informat Technol, Sunway 46150, Malaysia.
C3 Monash University; Monash University Malaysia
RP Belkhatir, M (corresponding author), Monash Univ, Fac Informat Technol, Sunway 46150, Malaysia.
EM Belkhatir.Mohammed@infotech.monash.edu
CR [Anonymous], 1984, Conceptual Structures: Information Processing in Mind and Machine
   BELKHATIR M, 2004, INTEGRATING PERCEPTU, P267
   BELKHATIR M, 2005, FULL TEXT FRAMEWORK, P113
   BOSCH P, 2001, EXACT MATCHING IMAGE
   BRADSHAW B, 2000, SEMANTIC BASED IMAGE, P167
   Carson C., 1999, BLOBWORLD SYSTEM REG, P509
   Cohn, 1997, GEOINFORMATICA, V1, P275, DOI [DOI 10.1023/A:1009712514511, 10.1023/a:1009712514511]
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   Di Sciascio E, 2002, PATTERN RECOGN LETT, V23, P1599, DOI 10.1016/S0167-8655(02)00124-1
   EGENHOFER MJ, 1991, REASONING BINARY TOP, P143
   Hollink L, 2004, INT J HUM-COMPUT ST, V61, P601, DOI 10.1016/j.ijhcs.2004.03.002
   IANEVA T, 2004, TREC VID RETR EV ONL
   Jeon J., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P119, DOI DOI 10.1145/860435.860459
   La Cascia M, 1998, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES - PROCEEDINGS, P24, DOI 10.1109/IVL.1998.694480
   LIM JH, 2000, EXPLICIT QUERY FORMU, P407
   LU Y, 2000, UNIFIED FRAMEWORK SE, P31
   MA W, 1997, NETRA TOOLBOX NAVIGA, P568
   MECHKOUR M, 1995, EMIR2 EXTENDED MODEL, P395
   Mittal A, 2003, MULTIMED TOOLS APPL, V20, P135, DOI 10.1023/A:1023627404478
   MOGHADDAM B, 1999, TR9910 MERL
   MOJSILOVIC A, 2001, CAPTURING IMAGE SEMA, P18
   MULHEM P, 2002, SYMBOLIC PHOTOGRAPH, P94
   Naphade MR, 2002, IEEE T CIRC SYST VID, V12, P40
   NIBLACK W, 1993, SPIE STORAGE RETRIEV, P40
   NIE J, 1988, OUTLINE GEN MODEL IN, P495
   OUNIS I, 1998, RELIEF COMBINING EXP, P266
   PENTLAND R, 1994, PHOTOBOOK TOOLS CONT, P34
   RUI Y., 1997, CONTENT BASED IMAGE, P815
   SMEULDERS AWM, 2000, CONTENT BASED IMAGE, V22, P1349
   TOWN CP, 2000, TR200014 AT T LABS C
   WESTERVELD T, 2003, P SIGIR MULT INF RET
   Zhou XM, 2001, PATTERN RECOGN LETT, V22, P469, DOI 10.1016/S0167-8655(00)00123-9
   Zhou XS, 2002, IEEE MULTIMEDIA, V9, P23, DOI 10.1109/93.998050
NR 33
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2009
VL 43
IS 1
BP 1
EP 23
DI 10.1007/s11042-008-0254-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 425HF
UT WOS:000264626900001
DA 2024-07-18
ER

PT J
AU Varadarajan, A
   Patel, N
   Maxim, B
   Grosky, WI
AF Varadarajan, Akila
   Patel, Nilesh
   Maxim, Bruce
   Grosky, William I.
TI Analyzing the efficacy of using digital ink devices in a learning
   environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE pen-based computing; digital ink; latent semantic indexing; information
   retrieval; document cross indexing
ID INFORMATION; RETRIEVAL; DESIGN
AB There has been increased interest on the impact of mobile devices such as PDAs and Tablet PCs in introducing new pedagogical approaches and active learning experiences. We propose an intelligent system that efficiently addresses the inherent subjectivity in student perception of note taking and information retrieval. We employ the idea of cross indexing the digital ink notes with matching electronic documents in the repository. Latent Semantic Indexing is used to perform document and page level indexing. Thus for each retrieved document, the user can go over to the relevant pages that match the query. Techniques to handle problems such as polysemy (multiple meanings of a word) in large databases, document folding and no match for query are discussed. We tested our system for its performance, usability and effectiveness in the learning process. The results from the exploratory studies reveal that the proposed system provides a highly enhanced student learning experience, thereby facilitating high test scores.
C1 [Varadarajan, Akila; Maxim, Bruce; Grosky, William I.] Univ Michigan, Dearborn, MI 48080 USA.
   [Patel, Nilesh] Oakland Univ, Rochester, MI 48063 USA.
C3 University of Michigan System; University of Michigan; Oakland
   University
RP Varadarajan, A (corresponding author), Univ Michigan, 4901 Evergreen Rd, Dearborn, MI 48080 USA.
EM akilav@umich.edu; npatel@oakland.edu; bmaxim@umich.edu;
   wgrosky@umich.edu
RI Maxim, Bruce/ISV-0470-2023; Maxim, Bruce/AAU-1200-2021
OI Maxim, Bruce/0000-0002-0979-7787
CR ABOWD G, 1999, P 1999 C COMP SUPP C
   ANDERSON R, 2007, 38 SIGCSE TECHN S CO, P69
   Anderson R, 2007, COMPUTER, V40, P56, DOI 10.1109/MC.2007.307
   [Anonymous], 1987, Term weighting approaches in automatic text retrieval
   BASSU D, 2003, TEXT MINING 2003
   Berque Dave., 2006, J COMPUT SMALL COLL, V21, P204
   BERRY MW, 1995, P 1995 ACM IEEE C SU
   CAIRNS P, 2004, 3 INT C MATH KNOWL M
   CUADRADO YC, 2002, PATTERNS UNSTRUCTURE
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Dieterle E., 2007, UBIQUITOUS PERVASIVE, P35
   DIETERLE E, 2006, 2006 AM ED RES ASS C
   DOWLING J, 2002, THESIS MONASH U
   DUMAIS ST, 1991, BEHAV RES METH INS C, V23, P229, DOI 10.3758/BF03203370
   DUMAIS ST, 1992, TMARH017527 BELL COM
   Dunning T., 1993, Computational Linguistics, V19, P61
   DURDLE K, 2004, THESIS U W ONTARIO
   EVANS C, 2006, INTERACTIVITY EFFECT
   Felder RM, 2005, J ENG EDUC, V94, P57, DOI 10.1002/j.2168-9830.2005.tb00829.x
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   GEORGIEV T, 2004, P 5 INT C COMP SYST
   HAUBOLD A, 2004, IEEE INT WORKSH MULT
   HEINES JM, 2007, SIGCSE 07
   Heisterkamp DR, 2002, INT C PATT RECOG, P134, DOI 10.1109/ICPR.2002.1047417
   Hinckley K, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P251
   Hwang WY, 2007, COMPUT EDUC, V48, P680, DOI 10.1016/j.compedu.2005.04.020
   Kise K, 2001, PROC INT CONF DOC, P592, DOI 10.1109/ICDAR.2001.953858
   Kolda TG, 1998, ACM T INFORM SYST, V16, P322, DOI 10.1145/291128.291131
   KRETSER O, 1999, SIGIR 99, P113
   Lin HX, 1997, BEHAV INFORM TECHNOL, V16, P267, DOI 10.1080/014492997119833
   LUCHINI K, 2003, CHI 2003 ACM APR 5 1, P321
   Macedo AA, 2005, THIRD LATIN AMERICAN WEB CONGRESS, PROCEEDINGS, P130
   Mayer R. E., 2020, Multimedia Learning, V3rd
   Nakabayashi K, 2007, 7TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P369, DOI 10.1109/ICALT.2007.114
   Norman D. A., 1986, USER CTR SYSTEM DESI, P32
   O'Brien G.W., 1994, INFORM MANAGEMENT TO
   Pask G., 1976, Conversation theory-Applications in education and epistemology
   PIMENTEL M, 2000, P 11 ACM HYP HYP SAN
   POON A, 1995, C HUM FACT COMP SYST, P252
   PRICE MN, 1998, LINKING LINKING TRAI, P30
   RIDLEY DS, 1991, J EXP EDUC, V60, P31
   SALTON G, 1990, J AM SOC INFORM SCI, V41, P288, DOI 10.1002/(SICI)1097-4571(199006)41:4<288::AID-ASI8>3.0.CO;2-H
   Salton G., 1971, SMART RETRIEVAL SYST
   Savery JR., 1995, Educational Technology, V35, P31
   Scott B., 2001, Cybernetics Human Knowing, V8, P1
   Sharples M, 2002, EUR J OPER RES, V136, P310, DOI 10.1016/S0377-2217(01)00118-7
   Sharples M, 2002, PERS UBIQUIT COMPUT, V6, P220, DOI 10.1007/s007790200021
   STAN D, 2000, PERCEPTUAL CONCEPTS
   Uchihashi S, 1999, INT CONF ACOUST SPEE, P3453, DOI 10.1109/ICASSP.1999.757585
   Wilcox Lynn D., 1997, Proceedings of the SIGCHI conference on Human factors in computing systems, P186, DOI DOI 10.1145/258549.258700
   WU X, 2004, THESIS U W ONT
   ZITTERBART M, 2003, MOBILE LEARNERS DSPA
NR 52
TC 2
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2008
VL 40
IS 2
BP 211
EP 239
DI 10.1007/s11042-008-0205-4
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 349CU
UT WOS:000259257200003
DA 2024-07-18
ER

PT J
AU Lo, YL
   Lee, WL
   Chang, LH
AF Lo, Yu-Lung
   Lee, Wen-Ling
   Chang, Lin-Huang
TI True suffix tree approach for discovering non-trivial repeating patterns
   in a music object
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE context-based retrieval; music databases; multimedia databases;
   non-trivial repeating pattern; suffix tree
ID CONSTRUCTION; RETRIEVAL; SEARCH
AB As the growing in Internet, database types and sizes are getting various and larger. The topic of finding out the significant information from a database at the shortest time is important. In the music databases, a repeating pattern is an important feature of music objects, which commonly used in analyzing the repeated part of music data and looking for themes. Most of the repeating patterns are key melodies or easy to familiarize and remember for people. Therefore, we can use the themes or the repeating patterns to construct indices that can speedup query execution for music retrievals. Nevertheless, non-trivial repeating patterns exclude those patterns, which are all contained in other longer patterns, such that they can reduce the redundancy of the repeating patterns and save the index space needed. Most of existing algorithms are time consuming for finding non-trivial repeating patterns in a music object. In this research, we aim to apply the true suffix tree approach to discover non-trivial repeating patterns for a music object, which can efficiently address the cost problems in processing time and memory space. In general case, our proposed scheme can extract non-trivial repeating patterns in a linear time.
C1 [Lo, Yu-Lung; Lee, Wen-Ling; Chang, Lin-Huang] Chaoyang Univ Technol, Dept Informat Management, Taichung 413, Taichung County, Taiwan.
C3 Chaoyang University of Technology
RP Lo, YL (corresponding author), Chaoyang Univ Technol, Dept Informat Management, Taichung 413, Taichung County, Taiwan.
EM yllo@cyut.edu.tw; s9214611@cyut.edu; lchang@cyut.edu.tw
CR [Anonymous], 1990, The Analysis and Cognition of Basic Melodic Structures: the Implication-realization Model
   [Anonymous], 1973, 14 ANN S SWITCHING A, DOI [DOI 10.1109/SWAT.1973.13, 10.1109/SWAT.1973.13]
   [Anonymous], 1997, ACM SIGACT NEWS
   Bakhmutova IV, 1997, COMPUT MUSIC J, V21, P58, DOI 10.2307/3681219
   Blackburn S., 1998, Proceedings ACM Multimedia 98, P361, DOI 10.1145/290747.290802
   Chen ALP, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P873, DOI 10.1109/ICME.2000.871498
   Chen JCC, 1998, EIGHTH INTERNATIONAL WORKSHOP ON RESEARCH ISSUES IN DATA ENGINEERING - CONTINUOUS-MEDIA DATABASES AND APPLICATIONS, PROCEEDINGS, P139, DOI 10.1109/RIDE.1998.658288
   Chou TC, 1996, INTERNATIONAL WORKSHOP ON MULTI-MEDIA DATABASE MANAGEMENT SYSTEMS, PROCEEDINGS, P46, DOI 10.1109/MMDBMS.1996.541853
   DAVENPORT G, 1991, IEEE COMPUT GRAPH, V11, P67, DOI 10.1109/38.126883
   DAY YF, 1995, PROC INT CONF DATA, P401, DOI 10.1109/ICDE.1995.380357
   DU Z, 2005, P 2005 INT C MACH LE, V3, P1806
   El-Kwae EA, 2000, ACM T INFORM SYST, V18, P171, DOI 10.1145/348751.348762
   Foote J, 1999, MULTIMEDIA SYST, V7, P2, DOI 10.1007/s005300050106
   GHIAS JL, 1995, P ACM MULT, P231
   Goh ST, 2000, DATA KNOWL ENG, V33, P219, DOI 10.1016/S0169-023X(00)00002-1
   Hawley M., 1990, Computing Systems, V3, P289
   Hjelsvold Rune., 1994, VLDB 94 P 20 INT C V, P686
   Hsu JL, 2001, IEEE T MULTIMEDIA, V3, P311, DOI 10.1109/6046.944475
   HSU JL, 1998, P ACM INT C INF KNOW, P281
   Hua KA, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P225, DOI 10.1145/319463.319610
   Iyer DS, 2004, CURR SCI INDIA, V87, P494
   KRUMHANSL CL, 1990, COGNITIVE FND MUSICA
   Lee W, 2000, PROC SPIE, V3972, P177
   Liu CC, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P451, DOI 10.1109/MMCS.1999.779244
   Liu CC, 2002, IEEE T KNOWL DATA EN, V14, P106, DOI 10.1109/69.979976
   Liu NH, 2005, LECT NOTES COMPUT SC, V3453, P240
   Lo YL, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P293, DOI 10.1109/ICME.2004.1394183
   LO YL, 2006, 5 IEEE ACIS INT C CO, V130
   Lu L., 2004, PROC ACM MULTIMEDIA, P275
   M T, 1985, Com binatorial algorithms on words, P97
   MCCREIGHT EM, 1976, J ACM, V23, P262, DOI 10.1145/321941.321946
   Nepal S, 1999, PROC INT CONF DATA, P22, DOI 10.1109/ICDE.1999.754894
   OH J, 2000, P 2000 ACM SIGMOD IN, P415
   OOMOTO E, 1993, IEEE T KNOWL DATA EN, V5, P629, DOI 10.1109/69.234775
   Pfeiffer S., 1996, Proceedings ACM Multimedia 96, P21, DOI 10.1145/244130.244139
   Pitkow J., 1999, P 2 USENIX S INTERNE, P13
   Smoliar S. W., 1994, IEEE Multimedia, V1, P62, DOI 10.1109/93.311653
   Sundberg Johan., 1991, REPRESENTING MUSICAL
   Tseng YH, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P176, DOI 10.1145/312624.312675
   Uitdenbogerd A, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P57, DOI 10.1145/319463.319470
   Uitdenbogerd A. L., 1998, Proceedings ACM Multimedia 98, P235, DOI 10.1145/290747.290776
   UKKONEN E, 1995, ALGORITHMICA, V14, P249, DOI 10.1007/BF01206331
   Ukkonen E., 1993, Combinatorial Pattern Matching. 4th Annual Symposium, CPM 93 Proceedings, P228, DOI 10.1007/BFb0029808
   Wang XD, 2004, EURASIP J APPL SIG P, V2004, P3, DOI 10.1155/S1110865704002756
   Wold E, 1996, IEEE MULTIMEDIA, V3, P27, DOI 10.1109/93.556537
   刘海燕, 1999, [新型炭材料, New Carbon Materials], V14, P21
NR 46
TC 10
Z9 11
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2008
VL 37
IS 2
BP 169
EP 187
DI 10.1007/s11042-007-0138-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 267PV
UT WOS:000253522600004
DA 2024-07-18
ER

PT J
AU Tsunoda, T
   Hoshino, M
AF Tsunoda, Tomohiro
   Hoshino, Masaaki
TI Automatic metadata expansion and indirect collaborative filtering for TV
   program recommendation system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE personalization; recommendation; metadata; user profile; EPG; VOD; IPTV;
   cross-domain; networked appliances
AB TV Program recommendation is a good example of a novel application of networked appliances using personalization technologies. The aim of this paper is to propose methods to improve the accuracy of TV program recommendation. Automatic metadata expansion (AME) is a method to enhance TV program metadata from electronic program guide (EPG) data, and indirect collaborative filtering (ICF) is a method to recommend non-persistent items such as TV programs based on the preferences of other members in a community. In this paper, the effectiveness of these methods is confirmed through experiments. This online TV recommendation system is currently being used by 230,000 members in Japan. The result of the actual operation is also discussed.
C1 [Tsunoda, Tomohiro; Hoshino, Masaaki] Sony Corp, Informat Technol Lab, Intelligent Syst Res Lab, PAO Grp, Tokyo, Japan.
C3 Sony Corporation
RP Tsunoda, T (corresponding author), Sony Corp, Informat Technol Lab, Intelligent Syst Res Lab, PAO Grp, Tokyo, Japan.
EM tsunoda@sm.sony.co.jp
CR [Anonymous], 2003, IEEE INTERNET COMPUT
   Ardissono L., 2004, USER MODELING RECOMM, P3
   GONNO Y, 2001, INTEGRATED BROADBAND, P546
   GONNO Y, 2000, ACM MULT WORKSH, P63
   Herlocker JL, 2000, P 2000 ACM C COMP SU, P241, DOI [10.1145/358916.358995, DOI 10.1145/358916.358995]
   Lee DL, 1997, IEEE SOFTWARE, V14, P67, DOI 10.1109/52.582976
   Resnick P., 1994, P ACM C COMP SUPP CO, P175
   Yamamoto N, 2005, CONSUM COMM NETWORK, P65
   ZIMMERMAN J, 2004, TV PERSONALIZATION S
NR 9
TC 17
Z9 18
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2008
VL 36
IS 1-2
BP 37
EP 54
DI 10.1007/s11042-006-0077-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 241LT
UT WOS:000251658600003
DA 2024-07-18
ER

PT J
AU Hsieh, MY
   Huang, YM
   Chiang, TC
AF Hsieh, Meng-Yen
   Huang, Yueh-Min
   Chiang, Tzu-Chinag
TI Transmission of layered video streaming via multi-path on ad hoc
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 4th International Conference on Intelligent Multimedia Computing and
   Networking
CY JUL, 2005
CL Salt Lake City, UT
DE quality of service; multicast routing; layered video streaming; ad hoc
   networks; multipath
ID STORAGE SERVER; SCHEME; PERMUTATION; DELIVERY; STRATEGY
AB Mobile ad hoc networks without centralized infrastructure change their topology rapidly because of node mobility, making multimedia applications difficult to run across wireless networks. Moreover, video transmission over ad hoc networks causes frequent transmission loss of video packets owing to end-to-end transmission with a number of wireless links, and requires essential bandwidth and restricted delay to provide quality-guaranteed display. This paper presents an architecture supporting transmission of multiple video streams in ad hoc networks by establishing multiple routing paths to provide extra video coding and transport schemes. This study also proposes an on-demand multicast routing protocol to transport layered video streams. The multicast routing protocol transmits layered video streaming based on a weight criterion, which is derived according to the number of receivers, delay and expiration time of a route. A simulation is performed herein to indicate the viability and performance of the proposed approach. The simulation results demonstrate that the proposed transport scheme is more effective than other video transport schemes with single or multiple paths.
C1 Natl Cheng Kung Univ, Dept Engn Sci, Tainan 70101, Taiwan.
C3 National Cheng Kung University
RP Huang, YM (corresponding author), Natl Cheng Kung Univ, Dept Engn Sci, Tainan 70101, Taiwan.
EM n9892111@mail.ncku.edu.tw; huang@mail.ncku.edu.tw;
   n98921056@ccmail.ncku.edu.tw
RI Huang, Yueh-Min/B-4563-2009
CR [Anonymous], YUV VIDEO SEQUENCES
   [Anonymous], NS 2 NETWORK SIMULAT
   APOSTOPOULOS JG, 2002, VIDEO STREAMING CONC
   Broch J., 1998, MobiCom'98. Proceedings of Fourth Annual ACM/IEEE International Conference on Mobile Computing and Networking, P85, DOI 10.1145/288235.288256
   CARVALHO M, 2004, MOBICOM
   CHAKARESKI J, 2003, ACM MULTIMEDIA   NOV
   CHIANG CC, 1998, CLUSTER COMPUT, V1, P187, DOI DOI 10.1023/A:1019037500012
   Choi W, 2002, IEEE INFOCOM SER, P1395, DOI 10.1109/INFCOM.2002.1019390
   Cox RV, 1996, IEEE COMMUN MAG, V34, P34, DOI 10.1109/35.556484
   Ding JW, 2003, MULTIMED TOOLS APPL, V21, P281, DOI 10.1023/A:1025727002272
   Ding JW, 2001, LECT NOTES COMPUT SC, V2195, P375
   Ding JW, 2003, MULTIMED TOOLS APPL, V19, P29, DOI 10.1023/A:1021164829330
   GHANBARI M, 1989, IEEE J SEL AREA COMM, V7, P771, DOI 10.1109/49.32340
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   Huang YM, 1999, VLDB J, V8, P44, DOI 10.1007/s007780050073
   Huang YM, 1997, IEEE T CONSUM ELECTR, V43, P69, DOI 10.1109/30.580387
   Jetcheva J., 2001, ACM MOBIHOC
   JOHNSON D, 1998, IN PRESS DYNAMIC SOU
   KANSARI M, 1996, IEEE T CAS VIDEO TEC
   Ke CH, 2005, IEEE COMMUN LETT, V9, P381, DOI 10.1109/LCOMM.2005.04005
   Khansari M, 1996, IEEE T CIRC SYST VID, V6, P1, DOI 10.1109/76.486415
   Kim S, 2003, LECT NOTES COMPUT SC, V2668, P664
   LEE JY, 1998, P ITC CSCC 98 JUL, P245
   Lee SJ, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-10, CONFERENCE RECORD, P3201, DOI 10.1109/ICC.2001.937262
   LEE SJ, 1999, P IEEE WCNC 99 NEW O
   LEE SJ, 2000, P IEEE WCNC 2000 CHI
   LEE SJ, 1999, P IEEE WCNC 99 NEW O, P1298
   LEE SJ, 2000, PERFORMANCE COMP STU
   LEE SJ, 2001, WIRELESS AD HOC MULT, P351
   Mao SW, 2004, FIRST INTERNATIONAL CONFERENCE ON BROADBAND NETWORKS, PROCEEDINGS, P671
   Mao SW, 2001, IEEE VTS VEH TECHNOL, P615, DOI 10.1109/VTC.2001.956843
   Nasipuri A, 2001, MOBILE NETW APPL, V6, P339, DOI 10.1023/A:1011426611520
   OGIER R, 1989, P IEEE INFOCOM
   Papadimitratos P., 2002, SECURING MOBILE AD H, P1
   Perkins CE, 1999, WMCSA '99, SECOND IEEE WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS, PROCEEDINGS, P90, DOI 10.1109/MCSA.1999.749281
   Ramanathan R, 2002, IEEE COMMUN MAG, P20
   Rijkse K, 1996, IEEE COMMUN MAG, V34, P42, DOI 10.1109/35.556485
   SIDHU D, 1991, P ACM SIGCOMM, P43
   SU W, 2002, INT J NETW MANAGE
   SURBALLE JW, 1974, NETWORKS, P125
   SURBALLE JW, 1984, NETWORKS
   Toh CK, 2000, IEEE VTS VEH TECHNOL, P987, DOI 10.1109/VETECF.2000.886259
   Tsao SL, 1998, IEEE T BROADCAST, V44, P300, DOI 10.1109/11.715316
   Tsao SL, 1998, IEEE T CONSUM ELECTR, V44, P27, DOI 10.1109/30.663727
   TSUCHIYA PF, 1987, MTR87W00152 MITRE CO
   WANG Y, 2002, P 2002 IEEE INT S CI
   Wei W, 2004, FIRST INTERNATIONAL CONFERENCE ON BROADBAND NETWORKS, PROCEEDINGS, P496, DOI 10.1109/BROADNETS.2004.48
   Wu C. W., 1999, MILCOM 1999. IEEE Military Communications. Conference Proceedings (Cat. No.99CH36341), P25, DOI 10.1109/MILCOM.1999.822636
   WU CW, 1998, IN PRESS AD HOC MULT
   Xie J, 2002, MOBILE NETW APPL, V7, P429, DOI 10.1023/A:1020748431138
   YI Y, 2003, IN PRESS ON DEMAND M
NR 51
TC 14
Z9 14
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2007
VL 34
IS 2
BP 155
EP 177
DI 10.1007/s11042-006-0086-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 178AX
UT WOS:000247194700003
DA 2024-07-18
ER

PT J
AU Veeravalli, B
   Chen, L
   Kwoon, HY
   Whee, GK
   Lai, SY
   Hian, LP
   Chow, HC
AF Veeravalli, B
   Chen, L
   Kwoon, HY
   Whee, GK
   Lai, SY
   Hian, LP
   Chow, HC
TI Design, analysis, and implementation of an agent driven pull-based
   distributed video-on-demand system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE agent driven; Jini service; video-on-demand; client-pull; retrieval
   strategy
ID MULTIMEDIA; REQUIREMENTS; ARCHITECTURE; SERVERS
AB The problem of employing multiple servers to serve a pool of clients on a network based multimedia service is addressed. We have designed and practically implemented a prototype system employing multiple servers to render a long duration movie to the customers. We have employed a multiple server retrieval strategy proposed in the literature [39] to realize this system. In the system, server coordination, client behavior and service facilities are completely controlled by an Agent based approach in which we have used the recent Jini technology. Several issues, ranging from data retrieval from individual server, behavior of the underlying network infrastructure, to client management and resource (client buffers) management, are considered in this implementation. We describe in detail our experiences in this complete design process of every module in the software architecture, its purpose, and working style. Further, the system is shown to be robust amidst unpredictable failures, i.e., in the event of server crashes. The load balancing capability is built-in as a safe guard measure to assure a continuous presentation. We present a comprehensive discussion on the software architecture to realize this working system and present our experiences. A system comprising a series of Pentium III PCs on a fast Ethernet network is built as a test-bed. Through this prototype, a wider scope of research challenges ahead are highlighted as possible extensions.
C1 Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore.
C3 National University of Singapore
RP Natl Univ Singapore, Dept Elect & Comp Engn, 4 Engn Dr 3, Singapore 117576, Singapore.
EM elebv@nus.edu.sg
RI Chen, Long/F-6578-2011
CR Aggarwal CC, 1999, MULTIMEDIA SYST, V7, P439, DOI 10.1007/s005300050144
   Aggarwal CC, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P253, DOI 10.1109/MMCS.1996.534983
   BERNHARDT C, 1995, P REALT SYST C PAR F, P63
   Bisdikian CC, 1996, IEEE MULTIMEDIA, V3, P62, DOI 10.1109/93.556540
   CAI Y, 1999, P SPIE ACM C MULT CO, P204
   Cohen A., 1995, Proceedings of the International Conference on Multimedia Computing and Systems (Cat. No.95TH8066), P312, DOI 10.1109/MMCS.1995.484941
   Dan A, 1996, MULTIMEDIA SYST, V4, P112, DOI 10.1007/s005300050016
   Dan A, 1997, MULTIMED TOOLS APPL, V4, P279, DOI 10.1023/A:1009637022889
   Dong LG, 2003, MULTIMED TOOLS APPL, V20, P99, DOI 10.1023/A:1023654818590
   Fahmi H, 1999, MULTIMED TOOLS APPL, V8, P91, DOI 10.1023/A:1009651431672
   GAO L, 1999, P 7 ACM INT C MULT 9, V1, P203
   Ghose D, 2000, MULTIMED TOOLS APPL, V11, P167, DOI 10.1023/A:1009681521536
   Golubchik L., 1995, Performance Evaluation Review, V23, P25, DOI 10.1145/223586.223590
   Golubchik L, 1996, MULTIMEDIA SYST, V4, P140, DOI 10.1007/s005300050019
   Hong S, 1998, TWELFTH INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN-12), PROCEEDINGS, P637
   Hua K., 1997, PROC SIGCOMM, P89
   Hua K. A., 1998, Proceedings ACM Multimedia 98, P191, DOI 10.1145/290747.290771
   Hua KA, 1998, IEEE IC COMP COM NET, P227, DOI 10.1109/ICCCN.1998.998781
   Jadav D, 1999, IEEE T KNOWL DATA EN, V11, P284, DOI 10.1109/69.761664
   KALOGERAKI V, 2000, P 33 HAW INT C SYST, V8
   Lee JYB, 1998, IEEE MULTIMEDIA, V5, P20, DOI 10.1109/93.682522
   Lee JYB, 2002, IEEE T MULTIMEDIA, V4, P38, DOI 10.1109/6046.985552
   Lee JYB, 2000, IEEE T PARALL DISTR, V11, P1217, DOI 10.1109/71.895790
   Lee JYB, 1999, IEEE T CIRC SYST VID, V9, P467, DOI 10.1109/76.754776
   LEE JYB, 1996, P INFOCOM 96, V1, P27
   LOUGHER P, 1994, IEE CONF PUBL, P140, DOI 10.1049/cp:19941148
   Ma HD, 2002, ACM SIGCOMM COMP COM, V32, P31, DOI 10.1145/510726.510729
   NUSSBAUMER JP, 1995, IEEE J SEL AREA COMM, V13, P779, DOI 10.1109/49.391753
   OZDEN B, 1995, INFORM SYST, V20, P465, DOI 10.1016/0306-4379(95)00025-Y
   PAPADIMITRIOU C, 1995, COMPUT COMMUN, V18, P204, DOI 10.1016/0140-3664(95)98543-E
   PING B, 2000, RETRIEVAL SCHEDULING, P146
   RANGAN PV, 1993, IEEE T KNOWL DATA EN, V5, P564, DOI 10.1109/69.234769
   Schmidt DC, 1998, COMPUT COMMUN, V21, P294, DOI 10.1016/S0140-3664(97)00165-5
   Sheu S, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P110, DOI 10.1109/MMCS.1997.609583
   SHEU S, 1997, P 5 INT C DAT SYST A, P481
   SISTLA AP, 1989, P 8 ACM S PRINC DIST, P223
   TANENBAUM AS, 1985, COMPUT SURV, V17, P419, DOI 10.1145/6041.6074
   Veeravalli B, 2000, MULTIMED TOOLS APPL, V12, P235, DOI 10.1023/A:1009623825393
   VIN HM, 1995, COMPUT COMMUN, V18, P192, DOI 10.1016/0140-3664(95)98542-D
   Viswanathan S, 1996, MULTIMEDIA SYST, V4, P197, DOI 10.1007/s005300050023
   Won Y, 2000, MULTIMEDIA SYST, V8, P105, DOI 10.1007/s005300050154
   Won YJ, 1999, MULTIMED TOOLS APPL, V8, P249, DOI 10.1023/A:1009690002658
   YUCEL S, 2001, IEEE GLOBECOM 2001, V4
NR 43
TC 6
Z9 6
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2006
VL 28
IS 1
BP 89
EP 118
DI 10.1007/s11042-006-5116-7
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 011ZR
UT WOS:000235308500005
DA 2024-07-18
ER

PT J
AU Petrovic, N
   Jojic, N
   Huang, TS
AF Petrovic, N
   Jojic, N
   Huang, TS
TI Adaptive video fast forward
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE content-based retrieval; generative models; video fast forward
AB We derive a statistical graphical model of video scenes with multiple, possibly occluded objects that can be efficiently used for tasks related to video search, browsing and retrieval. The model is trained on query (target) clip selected by the user. Shot retrieval process is based on the likelihood of a video frame under generative model. Instead of using a combination of weighted Euclidean distances as a shot similarity measure, the likelihood model automatically separates and balances various causes of variability in video, including occlusion, appearance change and motion. Thus, we overcome tedious and complex user interventions required in previous studies. We use the model in the adaptive video forward application that adapts video playback speed to the likelihood of the data. The similarity measure of each candidate clip to the target clip defines the playback speed. Given a query, the video is played at a higher speed as long as video content has low likelihood, and when frames similar to the query clip start to come in, the video playback rate drops. Set of experiments o12n typical home videos demonstrate performance, easiness and utility of our application.
C1 Univ Illinois, Beckman Inst, Urbana, IL 61801 USA.
   Microsoft Corp, Res, Redmond, WA 98052 USA.
C3 University of Illinois System; University of Illinois Urbana-Champaign;
   Microsoft
RP Univ Illinois, Beckman Inst, 405 N Mathews Ave, Urbana, IL 61801 USA.
EM nemanja@ifp.uiuc.edu; jojic@microsoft.com; huang@ifp.uiuc.edu
RI yan, shuicheng/HCH-9860-2022; yan, shuicheng/A-8531-2014
OI yan, shuicheng/0000-0003-4527-1018; yan, shuicheng/0000-0001-8906-3777
CR Chang SF, 1998, IEEE T CIRC SYST VID, V8, P602, DOI 10.1109/76.718507
   DEBONET JS, 1997, ADV NEURAL INFORMATI, V10
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Hadjidemetriou E, 2001, PROC CVPR IEEE, P702
   IRANI M, 1998, IEEE T PATTERN ANAL, V86
   JOJIC N, 2000, P IEEE C COMP VIS PA
   JOJIC N, 2001, P IEEE C COMP VIS PA
   JOJIC N, 2003, IN PRESS IEEE INT C
   Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178
   MARON O, 1998, P 15 INT C MACH LEAR, P341
   Naphade MR, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P536, DOI 10.1109/ICIP.1998.999041
   NGO CW, 2001, P ACM MULT
   Pearl J., 1988, PROBABILISTIC REASON
   PINGALI G, 2001, P ACM MULT
   SCHMID C, 2001, P IEEE C COMP VIS PA
   SPIEGELHALTER D, 1993, BUGS BAYESIAN INFERE
   STAUFFER C, 2001, ADV NEURAL INF PROC
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TIEU K, 2000, CPVR00, P228
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   ZELNIKMANOR L, 2001, CVPR
NR 21
TC 60
Z9 69
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2005
VL 26
IS 3
BP 327
EP 344
DI 10.1007/s11042-005-0895-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 942YO
UT WOS:000230319000005
DA 2024-07-18
ER

PT J
AU Yi, HR
   Rajan, D
   Chia, LT
AF Yi, HR
   Rajan, D
   Chia, LT
TI Automatic generation of MPEG-7 compliant XML document for motion
   trajectory descriptor in sports video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 1st ACM International Workshop on Multimedia Databases
CY NOV 07, 2003
CL New Orleans, LA
SP ACM
DE MPEG-7; XML; motion descriptors; motion trajectory
AB The MPEG-7 standard is a step towards standardizing the description of multimedia content so that quick and efficient identification of relevant content can be facilitated, together with efficient management of information. The description definition language (DDL) is a schema language to represent valid MPEG-7 descriptors and description schemes. MPEG-7 instances are XML documents that conform to a particular MPEG-7 schema, as expressed in the DDL and that describe audiovisual content. In this paper, we pick one of the visual descriptors related to motion in a video sequence, viz., motion trajectory. It describes the displacements of objects in time, where an object is defined as a spatiotemporal region or set of spatiotemporal regions. We present a method of automatically extracting trajectories from video sequences and generating an XML document that conforms to the MPEG-7 schema. We use sports videos in particular, because the trajectories are very random and the robustness of our algorithm can be demonstrated.
C1 Nanyang Technol Univ, Sch Comp Engn, Ctr Multimedia & Network Technol, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Yi, HR (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Ctr Multimedia & Network Technol, Singapore 639798, Singapore.
EM pg03763623@ntu.edu.sg; asdrajan@ntu.edu.sg; asltchia@ntu.edu.sg
RI Chia, Liang-Tien/A-9874-2008; Rajan, Deepu/A-3666-2011
CR [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   BASCLE B, 1995, P 5 INT C COMP VIS C
   CAVALLARO A, 2002, P 10 ACM INT C MULT, P523
   Chen YQ, 2001, PROC CVPR IEEE, P543
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   EKIN A, 2002, VISUAL COMMUNICATION
   Guéziec A, 2002, COMPUTER, V35, P38, DOI 10.1109/2.989928
   Intille SS, 2001, COMPUT VIS IMAGE UND, V81, P414, DOI 10.1006/cviu.2000.0896
   *ISO IEC, 2002, 1593882002 ISOIEC
   MILANESE R, 1997, SPIE P, V2, P3229
   Patel NV, 1997, PATTERN RECOGN, V30, P583, DOI 10.1016/S0031-3203(96)00114-8
   Pingali GS, 1998, PROC CVPR IEEE, P260, DOI 10.1109/CVPR.1998.698618
   Rafael C.Gonzalez., 1992, DIGITAL IMAGE PROCES, V2nd
   ROBERTSON G, 1991, P ACM SIGCHI C HUM F
   Tovinkere V, 2001, IEEE INT C MULT EXP
   XU P, 2001, IEEE C MULT EXP ICME
NR 17
TC 3
Z9 5
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2005
VL 26
IS 2
BP 191
EP 206
DI 10.1007/s11042-005-0450-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 931TJ
UT WOS:000229508100004
DA 2024-07-18
ER

PT J
AU Adali, S
   Bufi, C
   Sapino, ML
AF Adali, S
   Bufi, C
   Sapino, ML
TI Ranked relations: Query languages and query processing methods for
   multimedia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT Workshop on Multimedia Information Systems
CY 2003
CL Ischia, ITALY
DE information integration; meta-search; relational algebra; early returns
AB In this paper, we describe the notion of a ranked relation that incorporates to the relational data model the notion of rank, i.e. ordering among tuples or objects. The ordering of tuples may be based on a single rank information, or multiple ranks combined together. We show that such relations arise naturally in many applications, especially in applications that query outside sources and return ranked relations as answers to content based queries. We introduce an algebra for querying ranked relations and give examples of its use for various applications. We then prove various properties of the algebra with special emphasis on the preservation of the coherence property, which shows when different rank columns are guaranteed to induce the same ordering among tuples. We show how these properties can be used to produce approximate early returns. Finally, we give experimental results based on Internet search engines for our early returns method and show that our method provides meaningful and fast answers to the user.
C1 Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA.
   GE Global Res, Niskayuna, NY 12309 USA.
   Univ Turin, Dipartimento Informat, I-10149 Turin, Italy.
C3 Rensselaer Polytechnic Institute; General Electric; University of Turin
RP Rensselaer Polytech Inst, Dept Comp Sci, 110 8th St, Troy, NY 12180 USA.
EM sibel@cs.rpi.edu; bufi@research.ge.com; mlsapino@di.unito.it
RI Sapino, Maria Luisa/C-6257-2011
CR ADALI S, P 3 IFCIS C COOP INF, P341
   ADALI S, P SIGMOD, P402
   AGRAWAL R, 2000, P ACM SIGMOD INT C M, P297, DOI DOI 10.1145/342009.335423
   AROCENA GO, 1998, QUERY LANGUAGES WEB
   Bonatti P. A., 1997, Journal of Computer Security, V5, P3
   Bruno N, 2002, ACM T DATABASE SYST, V27, P153, DOI 10.1145/568518.568519
   CANDAN KS, SIMILARITY MEASURES
   Carey M. J., 1995, Proceedings RIDE-DOM '95. Fifth International Workshop on Research Issues in Data Engineering-Distributed Object Management (Cat.No.95TH8039), P124, DOI 10.1109/RIDE.1995.378736
   Cetintemel U., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), P622, DOI 10.1109/ICDE.2000.839477
   Chang CCK, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P335, DOI 10.1145/304181.304212
   Chang KevinChen-Chuan., 2002, P ACM INT C MANAGEME, P346
   CHAUDHURI S, P ACM SIGMOD SANT BA
   Donjerkovic D, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P411
   DWORK C, P INT WWW C, P613
   Fagin R, 1999, J COMPUT SYST SCI, V58, P83, DOI 10.1006/jcss.1998.1600
   FREUND Y, 1998, P 15 INT C
   Ilyas I., 2002, P VLDB
   Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140
   Levy AY, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P251
   Meng WY, 2002, ACM COMPUT SURV, V34, P48, DOI 10.1145/505282.505284
   SI L, 2002, P SIGIR C INF RETR
   TSAPARAS P, 2003, P ICDE
   Vassalos V, 2000, J LOGIC PROGRAM, V43, P75, DOI 10.1016/S0743-1066(99)00026-6
NR 23
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2004
VL 24
IS 3
BP 197
EP 214
DI 10.1023/B:MTAP.0000039387.14969.45
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 849CL
UT WOS:000223516200002
DA 2024-07-18
ER

PT J
AU Albanese, M
   Chianese, A
   Moscato, V
   Sansone, L
AF Albanese, M
   Chianese, A
   Moscato, V
   Sansone, L
TI A formal model for video shot segmentation and its application via
   animate vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT Workshop on Multimedia Information Systems
CY 2003
CL Ischia, ITALY
DE video indexing; video segmentation; shot transitions; animate vision
ID VISUAL-ATTENTION
AB The first step in a video indexing process is the segmentation of videos into meaningful parts called shots. In this paper we present a formal model of the video shot segmentation process. Starting from a mathematical characterization of the most common transition effects, a video segmentation algorithm capable to detect both abrupt and gradual transitions is proposed. The proposed algorithm is based on the computation of an arbitrary similarity measure between consecutive frames of a video. The algorithm has been tested adopting a similarity metric based on the Animate Vision theory and results have been reported.
C1 Univ Naples Federico II, Dipartimento Informat & Sistemist, Naples, Italy.
C3 University of Naples Federico II
RP Univ Naples Federico II, Dipartimento Informat & Sistemist, Naples, Italy.
EM malbanes@unina.it; angchian@unina.it; vmoscato@unina.it;
   sansone@unina.it
RI Albanese, Massimiliano/H-5093-2019; Moscato, Vincenzo/H-2526-2012;
   Sansone, Lucia/IAQ-9878-2023
OI Albanese, Massimiliano/0000-0002-2675-5810; Sansone,
   Lucia/0000-0003-2341-5228; Moscato, Vincenzo/0000-0002-0754-7696
CR ALBANESE M, 2002, P 8 WORKSH MULT INF, P66
   [Anonymous], 2008, A wavelet tour of signal processing: The sparse way
   [Anonymous], 1995, P ACM MULT, DOI DOI 10.1145/217279.215266
   BALLARD DH, 1991, ARTIF INTELL, V48, P57, DOI 10.1016/0004-3702(91)90080-4
   Bull D. R., 1999, IEEE INT C IM PROC, P299
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   FERNANDO WAC, 1999, P SPIE C STOR RETR I, P687
   FERNANDO WAC, 2000, IEEE T CONSUMER ELEC, V46
   FERNANDO WAC, 1999, P IEEE INT WORKSH MU, P259
   Gargi U, 2000, IEEE T CIRC SYST VID, V10, P1, DOI 10.1109/76.825852
   HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417
   Hanjalic A, 2002, IEEE T CIRC SYST VID, V12, P90, DOI 10.1109/76.988656
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Li ZN, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P295, DOI 10.1109/ICIP.2000.899362
   Lienhart R, 2001, PROC SPIE, V4315, P219, DOI 10.1117/12.410931
   MENG J, 1995, SPIE ALG TECH, V2419
   NAGASAKA A, 1992, IFIP TRANS A, V7, P113
   NAM J, 2000, IEEE INT C MUTL EXP
   NOTON D, 1990, VISUAL RES, P929
   Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4
   Philips M, 1998, TELECOMMUN SYST, V9, P393, DOI 10.1023/A:1019164327291
   RAO RPN, 1997, NEUR COMP, V9
   Su CW, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA225
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TSOTSOS JK, 1995, ARTIF INTELL, V78, P507, DOI 10.1016/0004-3702(95)00025-9
   WALKERSMITH GJ, 1977, PERCEPTION, V6, P313, DOI 10.1068/p060313
   Yarbus A. L., 1967, Eye Movements and Vision
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
   ZHANG HJ, 1993, ACM MULTIMEDIA SYSTE, V1, P10
   ZHANG HJ, 1994, P IS T SPIE C IM VID, V2
NR 32
TC 10
Z9 11
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2004
VL 24
IS 3
BP 253
EP 272
DI 10.1023/B:MTAP.0000039421.91449.10
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 849CL
UT WOS:000223516200005
DA 2024-07-18
ER

PT J
AU Berretti, S
   Del Bimbo, A
   Pala, P
AF Berretti, S
   Del Bimbo, A
   Pala, P
TI Merging results for distributed content based image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT Workshop on Multimedia Information Systems
CY 2003
CL Ischia, ITALY
DE digital libraries; collection fusion; distributed retrieval
AB Searching information through the Internet often requires users to separately contact several digital libraries, use each library interface to author the query, analyze retrieval results and merge them with results returned by other libraries. Such a solution could be simplified by using a centralized server that acts as a gateway between the user and several distributed repositories: The centralized server receives the user query, forwards the user query to federated repositories - possibly translating the query in the specific format required by each repository - and fuses retrieved documents for presentation to the user. To accomplish these tasks efficiently, the centralized server should perform some major operations such as: resource selection, query transformation and data fusion.
   In this paper we report on some aspects of MIND, a system for managing distributed, heterogeneous multimedia libraries ( MIND, 2001, http://www.mind-project.org). In particular, this paper focusses on the issue of fusing results returned by different image repositories. The proposed approach is based on normalization of matching scores assigned to retrieved images by individual libraries. Experimental results on a prototype system show the potential of the proposed approach with respect to traditional solutions.
C1 Univ Florence, Dipartimento Sistemi & Informat, I-50139 Florence, Italy.
C3 University of Florence
RP Berretti, S (corresponding author), Univ Florence, Dipartimento Sistemi & Informat, Via S Marta 3, I-50139 Florence, Italy.
EM berretti@dsi.unifi.it; delbimbo@dsi.unifi.it; pala@dsi.unifi.it
RI Pan, Chong/B-2996-2012; Berretti, Stefano/U-9004-2019
OI Berretti, Stefano/0000-0003-1219-4386; DEL BIMBO,
   ALBERTO/0000-0002-1052-8322; PALA, PIETRO/0000-0001-5670-3774
CR ADALI S, 1998, P 1998 ACM SIGMOD C, P402
   [Anonymous], 1995, P 1995 ACM SIGMOD IN, DOI DOI 10.1145/223784.223794
   BERRETTI S, 2002, P IEEE INT C MULT EX, V2, P197
   Callan J, 2001, ACM T INFORM SYST, V19, P97, DOI 10.1145/382979.383040
   CHANG W, 1997, P ACM MULT 97 SEATTL
   CHANG W, 1997, INT C MULT COMP SYST
   Ciaccia P., 1997, P INT C VER LARG DAT
   CODY WF, 1995, IFIP 2 6 3 WORK C VI, P17
   Fagin R, 2003, SIAM PROC S, P28
   Fuhr N., 1996, P SIGIR 96 WORKSH NE
   Gravano L., 1995, P 22TH INT C VERY LA, P78
   Ilyas I. F., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases, P950
   KIRSCH ST, 1999, Patent No. 5659732
   KWOK KL, 1995, P TREC 3, P247
   *MIND, RES SEL DAT FUS MULT
   Si L, 2003, ACM T INFORM SYST, V21, P457, DOI 10.1145/944012.944017
   SI L, 2002, P 25 ANN INT ACM SIG, P19
   Subrahmanian V.S., Hermes a heterogeneous reasoning and mediator system
   TOMASIC A, 1996, P INT C DISTR COMP S
   VORHEES E, 1995, P 18 INT C RES DEV I, P172
   VORHEES EM, 3 TEXT RETR C TREC 3
   [No title captured]
NR 22
TC 13
Z9 20
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2004
VL 24
IS 3
BP 215
EP 232
DI 10.1023/B:MTAP.0000039388.63801.67
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 849CL
UT WOS:000223516200003
DA 2024-07-18
ER

PT J
AU Mayer, CB
   Candan, KS
   Sangam, V
AF Mayer, CB
   Candan, KS
   Sangam, V
TI Effects of user request patterns on a multimedia delivery system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT Workshop on Multimedia Information Systems
CY 2003
CL Ischia, ITALY
DE user patterns; replication; delivery; multimedia
ID SERVERS; DESIGN
AB Because of their size, service times, and drain on server resources, multimedia objects require specialized replication systems in order to meet demand and ensure content availability. We present a novel method for creating replication systems where the replicated objects' sizes and/or per-object service times are large. Such replication systems are well-suited to delivering multimedia objects on the Internet. Assuming that user request patterns to the system are known, we show how to create replication systems that distribute read load to servers in proportion to their contribution to system capacity and experimentally show the positive load distribution properties of such systems. However, when user request patterns differ from what the system was designed for, system performance will be affected. Therefore, we also report on results that reveal ( i) how server loads are affected and (ii) the impact two system design parameters ( indicators of a system's load distribution qualities) have on server load when request patterns differ from that for which a system was designed.
C1 Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA.
C3 Arizona State University; Arizona State University-Tempe
RP Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA.
EM chris.mayer@asu.edu; candan@asu.edu; venkatesh.sangam@asu.edu
CR Almeida JM, 2001, PROC SPIE, V4312, P200
   Candan K. S., 2001, SIGMOD
   Cardellini V, 2000, 8TH INTERNATIONAL SYMPOSIUM ON MODELING, ANALYSIS AND SIMULATION OF COMPUTER AND TELECOMMUNICATION SYSTEMS, PROCEEDINGS, P20, DOI 10.1109/MASCOT.2000.876425
   Carter RL, 1999, COMPUT NETW, V31, P2529, DOI 10.1016/S1389-1286(99)00119-X
   Cidon I, 2001, IEEE INFOCOM SER, P1773, DOI 10.1109/INFCOM.2001.916675
   Colajanni M, 1998, INT CON DISTR COMP S, P295, DOI 10.1109/ICDCS.1998.679729
   GEMMELL DJ, 1995, COMPUTER, V28, P40, DOI 10.1109/2.384117
   Ghandeharizadeh SA, 1998, PARALLEL COMPUT, V24, P91, DOI 10.1016/S0167-8191(97)00118-X
   Guo K, 2001, P SOC PHOTO-OPT INS, V4526, P68, DOI 10.1117/12.434416
   Harizopoulos S, 2000, IEEE CONCURR, V8, P16, DOI 10.1109/4434.865888
   HUA KA, 1997, SIGCOMM 97, P89
   KANGASHARJU J, 2001, OBJECT REPLICATION S
   KORUPOLU M, 1999, WORKSH INT APPS, P62
   MAYER C, 2003, INT WORKSH MULT INF
   SANGAM V, 2003, WRSM, P871
   Sen S, 1999, IEEE INFOCOM SER, P1310, DOI 10.1109/INFCOM.1999.752149
   Shahabi C., 1997, Interactive Distributed Multimedia Systems and Telecommunication Services. 4th International Workshop, IDMS '97. Proceedings, P51, DOI 10.1007/BFb0000339
   Vassilakis C, 2000, MULTIMEDIA SYST, V8, P92, DOI 10.1007/s005300050153
   WANG B, 2002, INFOCOM
   Wu Kun-Lung., 2001, P 10 INT C WORLD WID, P36
NR 20
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2004
VL 24
IS 3
BP 233
EP 251
DI 10.1023/B:MTAP.0000039389.56384.be
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 849CL
UT WOS:000223516200004
DA 2024-07-18
ER

PT J
AU Ma, WH
   Du, DHC
AF Ma, WH
   Du, DHC
TI Frame selection for dynamic caching adjustment in video proxy servers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video caching; proxy server; frame selection; video streaming; video
   smoothing
AB By caching video data, a video proxy server close to the clients can be used to assist video delivery and alleviate the load of video servers. We assume a video can be partially cached and a certain number of video frames are stored in the proxy server. In our setting, the proxy server is allowed to cache the passing data from the video server. A video provides several options (levels) in terms of bandwidth requirement over the server-proxy path. For each video, the proxy server decides to cache a smaller amount of data at a lower level or to accumulate more data to reach a higher level. The proxy server can dynamically adjust the cached video data by choosing an appropriate level based on the network condition or the popularity of the video. We propose a frame selection scheme, Dynamic Chunk Algorithm, to determine which frames are to be cached in the proxy server for the dynamic caching adjustment scenario. The algorithm guarantees the rate constraint over the server-proxy path to be satisfied for each level. This approach also maintains the set of cached frames at a higher level as a superset of the cached frames at a lower level. Hence, it enforces the proxy server to simply cache more data without dropping frames when it intends to reduce network bandwidth consumption for a video and vice versa.
C1 Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.
C3 University of Minnesota System; University of Minnesota Twin Cities
RP Univ Minnesota, Dept Comp Sci & Engn, 200 Union St SE 4-192, Minneapolis, MN 55455 USA.
EM wma@cs.umn.edu; du@cs.umn.edu
CR AMIR E, 1995, P ACM MULT 95 NOV
   FENG W, 1997, P IEEE INFOCOM KOB J, P58
   Feng WC, 1997, MULTIMEDIA SYST, V5, P297, DOI 10.1007/s005300050062
   LIU JCL, 1995, COMPUT COMMUN, V18, P145, DOI 10.1016/0140-3664(95)98538-G
   MA W, 1993, PROXY ASSISTED VIDEO
   Ma WH, 2002, IEEE T MULTIMEDIA, V4, P539, DOI 10.1109/TMM.2002.806536
   McManus JM, 1996, IEEE J SEL AREA COMM, V14, P1087, DOI 10.1109/49.508280
   REJAIE R, 2000, P INFOCOM 2000 TEL A
   REJAIE R, 1999, P 4 WEB CACH WORKSH
   Rexford J, 1999, IEEE ACM T NETWORK, V7, P202, DOI 10.1109/90.769768
   REXFORD J, 1997, P INT WORKSH NETW OP, P249
   REXFORD J, 1999, P GLOB INT S DEC
   SALEHI J, 1996, P ACM SIGMETRICS 96, P222
   Sen S., 1999, P IEEE INFOCOM 99 NY
   Sen S., 1997, SPIE S VOIC VID DAT
   Tewari R., 1998, P SPIE ACM C MULT CO, P191
   WANG Y, 1998, P IEEE INFOCOM 98 AP
   [No title captured]
NR 18
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2004
VL 22
IS 1
BP 53
EP 73
DI 10.1023/B:MTAP.0000008659.52373.fc
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 754MK
UT WOS:000187320800003
DA 2024-07-18
ER

PT J
AU Hwang, E
   Prabhakaran, B
AF Hwang, E
   Prabhakaran, B
TI Application-layer protocol for collaborative multimedia presentations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia presentations; collaborative multimedia presentations;
   retrieval scheduling; application sub-layer; collaborative resource
   negotiation
ID SERVICES
AB Many multimedia presentation applications involve retrieval of objects from more than one collaborating server. Presentations of objects from different collaborating servers might be interdependent. For instance, we can consider distributed video servers where blocks of movies are distributed over a set of servers. Here, blocks of a movie from different video servers have to be retrieved and presented continuously without any gaps in the presentation. Such applications first need an estimate of the available network resources to each of the collaborating server in order to identify a schedule for retrieving the objects composing the presentation. A collaborating server can suggest modifications of the retrieval schedule depending on its load. These modifications can potentially affect the retrieval schedule for other collaborating applications. Hence, a sequence of negotiations have to be carried out with the collaborating servers in order to commit for a retrieval schedule of the objects composing the multimedia presentation. In this paper, we propose an application sub-layer protocol, Resource Lock Commit Protocol (RLCP), for handling the negotiation and commitment of the resources required for a collaborative multimedia presentation application.
C1 Ajou Univ, Coll Informat & Commun, Seoul, South Korea.
   Univ Texas, Dept Comp Sci, Richardson, TX 75083 USA.
C3 Ajou University; University of Texas System; University of Texas Dallas
RP Hwang, E (corresponding author), Ajou Univ, Coll Informat & Commun, Seoul, South Korea.
CR CANDAN KS, 1996, P ACM MULT 96 C BOST
   DELGROSSI L, 1995, INTERNET STREAM PROT
   Dermler G, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P113, DOI 10.1109/MMCS.1996.534962
   FERRARI D, 1990, IEEE COMMUN MAG, V28, P65, DOI 10.1109/35.60379
   FERRARI D, 1994, COMPUTER NETWORKS IS
   HWANG E, 1996, COMPUTER SCI TECHNIC
   LITTLE TDC, 1991, IEEE J SEL AREA COMM, V9, P1368, DOI 10.1109/49.108675
   NAHRSTEDT K, 1995, IEEE COMPUTER, V28
   NAHRSTEDT K, 1995, JIEEE MUJLTIMEDIA, V2, P53
   Raghavan SV, 1996, J HIGH SPEED NETW, V5, P277
   RAGHAVAN SV, 1994, P HIGH PERF NETW C H, P217
   RAGHAVAN SV, 1993, COMPUTER SCI TECHNIC
   ZHANG L, 1993, IEEE NETWORK     SEP, P8
   ZHAO W, 1996, 2 INT WORKSH MULT IN
NR 14
TC 1
Z9 1
U1 0
U2 0
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2003
VL 21
IS 2
BP 103
EP 123
DI 10.1023/A:1025502824502
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 718BJ
UT WOS:000185125000001
DA 2024-07-18
ER

PT J
AU Chen, XY
   Hu, ZH
   Lu, G
   Liu, JH
AF Chen, Xueyuan
   Hu, Zhihao
   Lu, Guo
   Liu, Jiaheng
TI A unified efficient deep image compression framework and its application
   on human-centric Task
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image compression; Neural network; Auto-encoder; Gaussian mixture model
AB Image compression is a widely used technique to reduce the spatial redundancy in images. Recently, learning based image compression has achieved significant progress by using the powerful representation ability from neural networks. However, the current learning based image compression methods suffer from the huge computational cost, which limits their capacity for practical applications. In this paper, we propose a unified framework called Efficient Deep Image Compression (EDIC) based on three new technologies, including a channel attention module, a Gaussian mixture model and a decoder-side enhancement module. Specifically, we design an auto-encoder style network for learning based image compression. To improve the coding efficiency, we exploit the channel relationship between latent representations by using the channel attention module. Besides, the Gaussian mixture model is introduced for the entropy model and improves the accuracy for bitrate estimation. Furthermore, we introduce the decoder-side enhancement module to further improve image compression performance. Our EDIC method can also be readily incorporated with the Deep Video Compression (DVC) framework (Lu et al. 2019) to further improve the video compression performance. Simultaneously, our EDIC method boosts the coding performance significantly while bringing slightly increased computational cost. More importantly, experimental results demonstrate that the proposed approach outperforms the current image compression methods and is up to more than 150 times faster in terms of decoding speed when compared with Minnen's method (Minnen et al. 2018). Moreover, we also evaluate the performance of the human-centric task (i.e., face recognition) by using different coding strategies.
C1 [Chen, Xueyuan; Hu, Zhihao; Liu, Jiaheng] Beihang Univ, Beijing, Peoples R China.
   [Lu, Guo] Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
C3 Beihang University; Shanghai Jiao Tong University
RP Liu, JH (corresponding author), Beihang Univ, Beijing, Peoples R China.
EM xueyuanchen@buaa.edu.cn; huzhihao@buaa.edu.cn; luguo2014@sjtu.edu.cn;
   liujiaheng@buaa.edu.cn
CR Agustsson E., 2018, arXiv
   Agustsson E, 2017, ADV NEUR IN, V30
   [Anonymous], 2017, NIPS
   Balle J, 2018, ICLR
   Balle J, 2017, 5 INT C LEARN REPR I
   Balle J, 2016, Arxiv, DOI arXiv:1511.06281
   Bellard Fabrice, 2018, Bpg image format
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chamain LD, 2021, IEEE DATA COMPR CONF, P163, DOI 10.1109/DCC50243.2021.00024
   Chen T., 2019, arXiv
   Cheng Z, 2020, arXiv
   Cheng ZX, 2019, PROC CVPR IEEE, P10063, DOI 10.1109/CVPR.2019.01031
   Choi Y, 2019, IEEE I CONF COMP VIS, P3146, DOI 10.1109/ICCV.2019.00324
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Djelouah A, 2019, IEEE I CONF COMP VIS, P6430, DOI 10.1109/ICCV.2019.00652
   Duan LY, 2020, IEEE T IMAGE PROCESS, V29, P8680, DOI 10.1109/TIP.2020.3016485
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   Habibian A, 2019, IEEE I CONF COMP VIS, P7032, DOI 10.1109/ICCV.2019.00713
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu Y, 2020, 2020 IEEE INT C MULT, P1
   Johnston N, 2018, PROC CVPR IEEE, P4385, DOI 10.1109/CVPR.2018.00461
   Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527
   Kingma D. P., 2014, arXiv
   kodak E, 2018, kodak lossless true color image suite (photocd pcd0992)
   Lee JY, 2019, Arxiv, DOI arXiv:1809.10452
   Lee JY, 2020, Arxiv, DOI arXiv:1912.12817
   Li MH, 2018, PROC CVPR IEEE, P6644, DOI 10.1109/CVPR.2018.00695
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu HJ, 2019, Arxiv, DOI arXiv:1904.09757
   Lu G, 2019, PROC CVPR IEEE, P10998, DOI 10.1109/CVPR.2019.01126
   Mentzer F, 2018, PROC CVPR IEEE, P4394, DOI 10.1109/CVPR.2018.00462
   Minnen D, 2018, ADV NEUR IN, V31
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Paszke A, 2019, ADV NEUR IN, V32
   Ranjan A, 2017, PROC CVPR IEEE, P2720, DOI 10.1109/CVPR.2017.291
   Rippel Oren, 2017, ICML
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Theis L., 2017, ICLR
   Toderici G., 2016, P INT C LEARN REPR I
   Toderici G, 2017, PROC CVPR IEEE, P5435, DOI 10.1109/CVPR.2017.577
   WALLACE GK, 1992, IEEE T CONSUM ELECTR, V38, pR18, DOI 10.1109/30.125072
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Webp, 2018, About us
   WITTEN IH, 1987, COMMUN ACM, V30, P520, DOI 10.1145/214762.214771
   Wu CY, 2018, LECT NOTES COMPUT SC, V11212, P425, DOI 10.1007/978-3-030-01237-3_26
   x264, 2018, the best h.264/avc encoder
   x265, 2018, hevc encoder / h.265 video codec
   Xue TF, 2019, INT J COMPUT VISION, V127, P1106, DOI 10.1007/s11263-018-01144-2
   Yang F, 2022, NEUROCOMPUTING, V508, P58, DOI 10.1016/j.neucom.2022.08.048
NR 52
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 15
PY 2023
DI 10.1007/s11042-023-17696-6
EA DEC 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY3H0
UT WOS:001142451400003
DA 2024-07-18
ER

PT J
AU Tamarana, P
   Kumari, AK
AF Tamarana, Pattalunaidu
   Kumari, A. Kamala
TI Floorplanning for optimizing area using sequence pair and hybrid
   optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Floor plan; SP method; Area; VLSI; IBE-SMO Algorithm
ID SIMULATED ANNEALING ALGORITHM; VLSI; MODEL; METHODOLOGY; POWER
AB Physical design is major key processes in integrating the circuit into the chip area in VLSI circuit design. A netlist is accepted as input by a floorplanning stage, provided by the physical design phase of splitting the circuits. The floor planner creates the best positions for the circuit module. The dimensions, size, and connectivity details of the modules are contained in the netlist. It is crucial to create an optimum floorplan by creating metaheuristic optimization algorithms to increase the circuit performance by reducing chip size, wire length, and peak temperature. This scheme always has a complexity to allocate the weights and might consequence in adverse bias with a specific intention. Here, the non-slicing floor plan is studied through the sequence pair (SP) method. SP is a method for packing the blocks using a pair of modules termed sequences. Consequently, optimal parameter (area and wire length) tuning is performed by a new hybrid Integrated Bald Eagle and SMO (IBE-SMO) scheme that combined the approaches such as BES and SMO for optimal FP by means of tuning the wire length and area, taking into consideration as multi-objective. This validates the optimization of wire length and area utilizing IBE-SMO to reduce the length, width and height of the floor plan area. The standard MCNC benchmark circuits were used to test the suggested technique, and the findings show that it decreases the area by 0.7 x 104, and wire length by 0.84 x 105, compared to the existing methods.
C1 [Tamarana, Pattalunaidu; Kumari, A. Kamala] Andhra Univ, Coll Engn, Dept Instrument Technol, Visakhapatnam 530003, Andhra Pradesh, India.
C3 Andhra University
RP Tamarana, P (corresponding author), Andhra Univ, Coll Engn, Dept Instrument Technol, Visakhapatnam 530003, Andhra Pradesh, India.
EM naidu.tamarana1@gmail.com
CR Ahmadi A, 2017, COMPUT IND ENG, V107, P158, DOI 10.1016/j.cie.2017.03.015
   Ahmed ST, 2022, MALAYS J COMPUT SCI, P53, DOI 10.22452/mjcs.sp2022no2.5
   Almashaqbeh M, 2021, J BUILD ENG, V39, DOI 10.1016/j.jobe.2021.102316
   Alsattar HA, 2020, ARTIF INTELL REV, V53, P2237, DOI 10.1007/s10462-019-09732-5
   Anand S, 2012, COMPUT OPTIM APPL, V52, P667, DOI 10.1007/s10589-011-9442-y
   Chen TC, 2008, IEEE T COMPUT AID D, V27, P286, DOI 10.1109/TCAD.2007.907065
   Chen YY, 2014, J INTELL MANUF, V25, P441, DOI 10.1007/s10845-012-0695-9
   Cheng MY, 2019, ENG COMPUT-GERMANY, V35, P703, DOI 10.1007/s00366-018-0628-0
   Chinnusamy GS, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03027-w
   Desai A, 2020, BIOSCI BIOTECH RES C, V13, P114, DOI 10.21786/bbrc/13.13/16
   Dewan MI, 2020, IEEE T COMPUT AID D, V39, P5111, DOI 10.1109/TCAD.2020.2966551
   Ding H, 2021, J PARALLEL DISTR COM, V158, P176, DOI 10.1016/j.jpdc.2021.08.005
   Guru RP, 2020, J COMPUT ELECTRON, V19, P1232, DOI 10.1007/s10825-020-01491-9
   Huang ZP, 2020, IEEE ACCESS, V8, P50911, DOI 10.1109/ACCESS.2020.2980135
   Jadav S, 2021, MICROELECTRON J, V107, DOI 10.1016/j.mejo.2020.104941
   Kang S, 2022, J SUPERCOMPUT, V78, P2724, DOI 10.1007/s11227-021-03952-9
   Karimullah S, 2022, WIRELESS PERS COMMUN, V127, P3041, DOI 10.1007/s11277-022-09909-2
   Karimullah S, 2022, APPL NANOSCI, DOI 10.1007/s13204-021-02173-z
   Karthick R, 2023, J CIRCUIT SYST COMP, V32, DOI 10.1142/S0218126623502730
   Kumar SBV, 2020, J KING SAUD UNIV-COM, V32, P1095, DOI 10.1016/j.jksuci.2018.01.001
   Kureichik VM, 2013, J COMPUT SYS SC INT+, V52, P80, DOI 10.1134/S1064230712060056
   Laignel G, 2021, AUTOMAT CONSTR, V123, DOI 10.1016/j.autcon.2020.103491
   Leno IJ, 2013, INT J ADV MANUF TECH, V66, P1573, DOI 10.1007/s00170-012-4441-4
   Mandloi A, 2020, MICROPROCESS MICROSY, V78, DOI 10.1016/j.micpro.2020.103266
   Ozer MA, 2016, EUR ARCH OTO-RHINO-L, V273, P2185, DOI 10.1007/s00405-015-3741-3
   Palchaudhuri A, 2021, J PARALLEL DISTR COM, V151, P13, DOI 10.1016/j.jpdc.2021.01.005
   Pothiraj S, 2021, WIRELESS PERS COMMUN, V118, P3007, DOI 10.1007/s11277-021-08166-z
   Prakash A, 2021, WIRELESS PERS COMMUN, V118, P323, DOI 10.1007/s11277-020-08015-5
   Praveena HD, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/3297316
   Razavi SM, 2020, INTEGRATION, V73, P77, DOI 10.1016/j.vlsi.2020.03.005
   Seeboo A, 2022, J CLEAN PROD, V332, DOI 10.1016/j.jclepro.2021.130006
   Sharma H, 2019, STUD COMPUT INTELL, V779, P43, DOI 10.1007/978-3-319-91341-4_4
   Shunmugathammal M, 2020, CIRC SYST SIGNAL PR, V39, P900, DOI 10.1007/s00034-019-01054-9
   Sivaranjani P, 2015, CIRC SYST SIGNAL PR, V34, P3521, DOI 10.1007/s00034-015-0020-x
   Srinivasan B, 2023, IEEE ACCESS, V11, P14677, DOI 10.1109/ACCESS.2023.3244346
   Srinivasan B, 2021, SOFT COMPUT, V25, P4159, DOI 10.1007/s00500-021-05591-x
   Stateczny A, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15082015
   Yang HY, 2021, INTEGRATION, V77, P96, DOI 10.1016/j.vlsi.2020.11.001
   Zawidzki M, 2020, ADV ENG SOFTW, V141, DOI 10.1016/j.advengsoft.2019.102766
   Zou DX, 2016, FRONT INFORM TECH EL, V17, P1228, DOI 10.1631/FITEE.1500386
NR 40
TC 1
Z9 1
U1 12
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 15
PY 2023
DI 10.1007/s11042-023-17575-0
EA DEC 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY3H0
UT WOS:001142451400005
DA 2024-07-18
ER

PT J
AU Lee, CY
   Khanum, A
   Kumar, PP
AF Lee, Chao-Yang
   Khanum, Abida
   Kumar, Pinninti Praneeth
TI Multi-food detection using a modified swin-transfomer with recursive
   feature pyramid network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Convolutional neural network; Swin-transformer; Recursive feature
   pyramid network; Food detection
ID OBJECT DETECTION; RECOGNITION
AB Humans need food, and the food detection system is a fascinating research topic and a complex weight loss mechanism. Eating healthy and balanced is crucial. Over the last few years, studies on food-related tasks have progressed, but the existing system deals only with single- and multi-food items by using convolution neural networks (CNN), and the recent development of Transformers in computer-vision has outperformed famous networks like ResNet 50, VGG 16, etc., but Transformer-based methods are limited in food-related tasks. For this issue, we improve Swin Transformer-based method by taking the dominance of transformer and CNN, we propose a novel multi-food detection utilizing a modified Swin-Transfomer and Recursive Feature Pyramid Network called (MFD-MST) and Swin-Transformer with spatial extraction block (STSE) as backbone to recognize multi-food item in images to improve local and structural information of image and RFP as neck to enhance This feature representation recognizes multi-food items. STSE solves transformer positional encoding, and RFP can look at feature map twice, helping the model build powerful representations. A prominent dataset, UEC-FOOD 100, Indian Food 28, UEC-FOOD 256 was widely tested to construct a detection system that can distinguish various objects in food photos and classify them into food categories. Our model's evaluation measures vary. MFD-MST outperforms Swin-Transformer by 2.7% at AP[0.50] and 3.3%, 1.4% on three food datasets respectively. Test results suggest that our system accurately detects food items.
C1 [Lee, Chao-Yang] Natl Yunlin Univ Sci & Technol, Dept Comp Sci & Informat Engn, Touliu, Yunlin, Taiwan.
   [Khanum, Abida] Natl Cheng Kung Univ, Dept Elect Engn, 1 Univ Rd, Tainan 701, Taiwan.
   [Kumar, Pinninti Praneeth] Natl Formosa Univ, Dept Aeronaut Engn, Huwei, Yunlin Country, Taiwan.
C3 National Yunlin University Science & Technology; National Cheng Kung
   University; National Formosa University
RP Lee, CY (corresponding author), Natl Yunlin Univ Sci & Technol, Dept Comp Sci & Informat Engn, Touliu, Yunlin, Taiwan.
EM chaoyang@yuntech.edu.tw; abida.gurman@gmail.com;
   pinnintipraneethkumar@gmail.com
OI Lee, Chao-Yang/0000-0003-3898-3551
FU Ministry of Science and Technology, Taiwan [MOST 112-2221-E-224-053];
   Ministry of Science and Technology
FX This work was financially supported in part by the Ministry of Science
   and Technology under grant MOST 112-2221-E-224-053.
CR Arslan Berker, 2022, IEEE Transactions on Artificial Intelligence, V3, P238, DOI 10.1109/TAI.2021.3108126
   Cai Q, 2019, INT CONF BIG DATA, P359, DOI 10.1109/bigcomp.2019.8678916
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cui Y., 2021, P IEEECVF INT C COMP, P8138
   Ilyas T, 2021, IEEE ACCESS, V9, P124491, DOI 10.1109/ACCESS.2021.3110978
   Jiang LD, 2020, IEEE ACCESS, V8, P47477, DOI 10.1109/ACCESS.2020.2973625
   Jiang SQ, 2020, IEEE T IMAGE PROCESS, V29, P265, DOI 10.1109/TIP.2019.2929447
   Lam MB, 2020, IEEE ACCESS, V8, P88360, DOI 10.1109/ACCESS.2020.2993053
   Li JH, 2021, IEEE ACCESS, V9, P125375, DOI 10.1109/ACCESS.2021.3108184
   Liang HZ, 2021, IEEE T MULTIMEDIA, V23, P3551, DOI 10.1109/TMM.2020.3028478
   Liang JM, 2023, Arxiv, DOI arXiv:2305.02187
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu CX, 2021, IEEE T CIRC SYST VID, V31, P2480, DOI 10.1109/TCSVT.2020.3020079
   Liu D., 2023, IEEE T IMAGE PROCESS
   Liu DF, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206716
   Liu DF, 2021, PROC CVPR IEEE, P9811, DOI 10.1109/CVPR46437.2021.00969
   Liu DF, 2021, AAAI CONF ARTIF INTE, V35, P6101
   Liu DF, 2020, NEUROCOMPUTING, V409, P1, DOI 10.1016/j.neucom.2020.05.027
   Liu YC, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11101626
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu ZH, 2020, IEEE ACCESS, V8, P2327, DOI 10.1109/ACCESS.2019.2962513
   Mandal B, 2019, IEEE SENSOR LETT, V3, DOI 10.1109/LSENS.2018.2886427
   Pandey D, 2022, I C DATA ENGIN WORKS, P101, DOI 10.1109/ICDEW55742.2022.00021
   Qi JT, 2022, COMPUT ELECTRON AGR, V194, DOI 10.1016/j.compag.2022.106780
   Qiao SY, 2021, PROC CVPR IEEE, P10208, DOI 10.1109/CVPR46437.2021.01008
   Rachakonda L, 2020, IEEE T CONSUM ELECTR, V66, P115, DOI 10.1109/TCE.2020.2976006
   Razali MN, 2021, INFORMATION, V12, DOI 10.3390/info12080322
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sainz-De-Abajo B, 2020, IEEE ACCESS, V8, P227915, DOI 10.1109/ACCESS.2020.3046031
   Song G, 2020, IEEE ACCESS, V8, P14893, DOI 10.1109/ACCESS.2020.2964836
   Tan RZ, 2020, IEEE ACCESS, V8, P111875, DOI 10.1109/ACCESS.2020.3003518
   Wang SQ, 2020, IEEE ACCESS, V8, P184841, DOI 10.1109/ACCESS.2020.3029857
   Wang W., 2022, Adv. Neural Inf. Process. Syst., V35, P12826
   Xiao GY, 2020, IEEE T IND INFORM, V16, P2290, DOI 10.1109/TII.2019.2931148
   Xu XM, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14215388
   Zhao H, 2020, IEEE J-STSP, V14, P665, DOI 10.1109/JSTSP.2020.2969328
   Zhou PF, 2022, IEEE INTERNET THINGS, V9, P6335, DOI 10.1109/JIOT.2020.2996009
   Zhu B, 2022, IEEE T MULTIMEDIA, V24, P1175, DOI 10.1109/TMM.2021.3123474
NR 38
TC 1
Z9 1
U1 11
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 12
PY 2023
DI 10.1007/s11042-023-17757-w
EA DEC 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CG2W2
UT WOS:001124043200009
DA 2024-07-18
ER

PT J
AU Shabari, NP
   Chouhan, R
AF Shabari, Nath P.
   Chouhan, Rajlaxmi
TI Quantifying image naturalness using transfer learning and fusion model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image quality assessment; Naturalness; Glossiness; Deep learning;
   Transfer learning
ID CUSTOMER CHURN PREDICTION; BIG DATA ANALYTICS; NETWORK; MANAGEMENT;
   ALGORITHM
AB Distinguishing a natural scene from artwork is a simple task for the human visual system, but a challenging one for machines due to the wide range of psychovisual features, illumination gamuts, and varied interpretations of glossiness. While state-of-the-art image quality metrics quantify overall visual quality to a remarkable degree of accuracy, quantification of 'glossiness' of a scene to represent its naturalness is still an emerging area. The rapid growth of deep learning methods and CNN-based architectures inspired us to explore the fusion of best performing CNN architectures in this paper for an image dataset specifically created to replicate unnaturalness of artwork or portrait-like images. Performance of four CNN networks was tested using transfer learning, selective retraining and optimizing initial learning rates on a dataset of about 8.5k images created to represent various degrees of glossiness. A fusion framework was then proposed using the top two architectures. In terms of eleven levels of naturalness (0 to 10), both quantitative and qualitative evaluation of the fusion frameworks was conducted. The framework resulting from fusion of GoogleNet and VGG16, referred to as GoogleVGG Fusion in this paper, is found to reach accuracies comparable to individual networks but with nearly half the computational cost. The proposed GoogleVGG Fusion model achieved an accuracy of 87.86% with the labelled scores and a Spearman's Rank Correlation (SROCC) of 0.9794. As expected, the accuracy of the proposed framework with the subjective scores in comparison with non-deep learning (DL) & DL-based methods is remarkably better.
C1 [Shabari, Nath P.; Chouhan, Rajlaxmi] Indian Inst Technol Jodhpur, Dept Elect Engn, Jodhpur, Rajasthan, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Jodhpur
RP Shabari, NP (corresponding author), Indian Inst Technol Jodhpur, Dept Elect Engn, Jodhpur, Rajasthan, India.
EM nath.1@iitj.ac.in; rajlaxmichouhan@iitj.ac.in
RI Chouhan, Rajlaxmi/E-2787-2016
CR [Anonymous], 2011, P ICML
   Au WH, 2003, IEEE T EVOLUT COMPUT, V7, P532, DOI 10.1109/TEVC.2003.819264
   Azeem M, 2017, TELECOMMUN SYST, V66, P603, DOI 10.1007/s11235-017-0310-7
   Cenggoro TW, 2021, PROCEDIA COMPUT SCI, V179, P624, DOI 10.1016/j.procs.2021.01.048
   Das T, 2023, NEUROCOMPUTING, V527, P184, DOI 10.1016/j.neucom.2023.01.061
   De Caigny A, 2018, EUR J OPER RES, V269, P760, DOI 10.1016/j.ejor.2018.02.009
   Demirer R, 2017, FINANC RES LETT, V22, P35, DOI 10.1016/j.frl.2016.12.032
   Dou ZY, 2022, PROC CVPR IEEE, P18145, DOI 10.1109/CVPR52688.2022.01763
   Duchemin R., 2021, J SUPPLY CHAIN MANAG, V2, P115, DOI DOI 10.18757/JSCMS.2021.6125
   Fujo S. W., 2022, Information Sciences Letters, V11, P24, DOI [10.18576/isl/110120, DOI 10.18576/ISL/110120]
   Gordon L, 2013, P SAS GLOB FOR SAN F
   Hossain NUI, 2019, COMPLEXITY, DOI 10.1155/2019/3518705
   Huang BQ, 2012, EXPERT SYST APPL, V39, P1414, DOI 10.1016/j.eswa.2011.08.024
   Hung SY, 2006, EXPERT SYST APPL, V31, P515, DOI 10.1016/j.eswa.2005.09.080
   Hwang H, 2004, EXPERT SYST APPL, V26, P181, DOI 10.1016/S0957-4174(03)00133-7
   Idris A, 2012, COMPUT ELECTR ENG, V38, P1808, DOI 10.1016/j.compeleceng.2012.09.001
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jayaswal P., 2016, International Journal of Database Theory and Application, V9, P211, DOI DOI 10.14257/IJDTA.2016.9.8.21
   [琚春华 Ju Chunhua], 2013, [系统工程理论与实践, Systems Engineering-Theory & Practice], V33, P141
   k S., 2015, Int J Eng Trends Tech (IJETT), V27, P238, DOI 10.14445/22315381/IJETT-V27P243
   Kisioglu P, 2011, EXPERT SYST APPL, V38, P7151, DOI 10.1016/j.eswa.2010.12.045
   Lalwani P, 2022, COMPUTING, V104, P271, DOI 10.1007/s00607-021-00908-y
   Lin CS, 2011, EXPERT SYST APPL, V38, P8, DOI 10.1016/j.eswa.2010.05.039
   Loria E, 2021, ELECTRON COMMER R A, V47, DOI 10.1016/j.elerap.2021.101057
   Miguéis VL, 2012, EXPERT SYST APPL, V39, P11250, DOI 10.1016/j.eswa.2012.03.073
   Mitrovic S, 2021, INFORM SCIENCES, V557, P270, DOI 10.1016/j.ins.2019.02.044
   Mozer MC, 2000, IEEE T NEURAL NETWOR, V11, P690, DOI 10.1109/72.846740
   Nie WZ, 2024, IEEE T MULTIMEDIA, V26, P514, DOI 10.1109/TMM.2023.3267295
   Nie WZ, 2021, IEEE T IMAGE PROCESS, V30, P4371, DOI 10.1109/TIP.2021.3071687
   Nie Weizhi, 2023, IEEE Trans. Multimedia
   Qi JY, 2009, ANN OPER RES, V168, P247, DOI 10.1007/s10479-008-0400-8
   Ren SJF, 2017, INT J PROD RES, V55, P5011, DOI 10.1080/00207543.2016.1154209
   Saradhi VV, 2011, EXPERT SYST APPL, V38, P1999, DOI 10.1016/j.eswa.2010.07.134
   Soleymani M, 2017, IMAGE VISION COMPUT, V65, P3, DOI 10.1016/j.imavis.2017.08.003
   Spanoudes P, 2017, Arxiv, DOI arXiv:1703.03869
   Torkzadeh G, 2006, DECIS SUPPORT SYST, V42, P1116, DOI 10.1016/j.dss.2005.10.003
   Pustokhina IV, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102706
   Valendin J, 2022, INT J RES MARK, V39, P988, DOI 10.1016/j.ijresmar.2022.02.007
   Vo NNY, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106586
   Wang G, 2016, INT J PROD ECON, V176, P98, DOI 10.1016/j.ijpe.2016.03.014
   Wei CP, 2002, EXPERT SYST APPL, V23, P103, DOI 10.1016/S0957-4174(02)00030-1
   Wu JY, 2023, NEUROCOMPUTING, V527, P119, DOI 10.1016/j.neucom.2023.01.024
   Wu ZY, 2022, ANN OPER RES, DOI 10.1007/s10479-022-04526-5
   Yan L, 2004, IEEE INTELL SYST, V19, P50, DOI 10.1109/MIS.2004.1274911
   Yu RY, 2018, NEURAL COMPUT APPL, V29, P707, DOI 10.1007/s00521-016-2477-3
   Yu XB, 2011, EXPERT SYST APPL, V38, P1425, DOI 10.1016/j.eswa.2010.07.049
   Zhang WJ, 2023, NEUROCOMPUTING, V536, P191, DOI 10.1016/j.neucom.2023.03.011
NR 47
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 11
PY 2023
DI 10.1007/s11042-023-17790-9
EA DEC 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ2A4
UT WOS:001122190800007
DA 2024-07-18
ER

PT J
AU Fang, SF
   Yang, ZY
   Chen, JH
AF Fang, Sifan
   Yang, Zuyuan
   Chen, Junhang
TI Incomplete multi-view clustering via diffusion completion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-view Learning; Diffusion models; View missing; Multi-view
   clustering
AB Incomplete multi-view clustering is a challenging and non-trivial task to provide effective data analysis for large amounts of unlabeled data in the real world. All incomplete multi-view clustering methods need to address the problem of how to reduce the impact of missing views. To address this issue, we propose diffusion completion to recover the missing views integrated into an incomplete multi-view clustering framework. Based on the observable views information, the diffusion model is used to recover the missing views, and then the consistency information of the multi-view data is learned by contrastive learning to improve the performance of multi-view clustering. To the best of our knowledge, this may be the first work to incorporate diffusion models into an incomplete multi-view clustering framework. Experimental results show that the proposed method performs well in recovering the missing views while achieving superior clustering performance compared to state-of-the-art methods.
C1 [Fang, Sifan; Yang, Zuyuan; Chen, Junhang] Guangdong Univ Technol, Guangzhou Higher Educ Mega Ctr, Sch Automat, 100 Waihuan West Rd, Guangzhou 510006, Guangdong, Peoples R China.
C3 Guangdong University of Technology
RP Yang, ZY (corresponding author), Guangdong Univ Technol, Guangzhou Higher Educ Mega Ctr, Sch Automat, 100 Waihuan West Rd, Guangzhou 510006, Guangdong, Peoples R China.
EM Sifan_Fang@outlook.com; zuyuangdut@aliyun.com; junhanggdgy@aliyun.com
RI wang, nan/KHW-4897-2024; LIU, LIYING/KAM-4121-2024; Liu,
   Joyce/KEI-8953-2024; Guo, Lin/KFS-9366-2024; Wang, YuHan/KGY-2933-2024;
   wang, haoyu/KHY-6295-2024; Lin, Xiaoqi/KFS-5750-2024; zhang,
   can/KHC-5357-2024; Zhang, Wenxiao/KCK-3295-2024; Li,
   Xintong/KHD-6915-2024
OI wang, haoyu/0009-0001-2467-5331; 
FU Basic and Applied Basic Research Foundation of Guangdong Province
FX No Statement Available
CR Brock A, 2019, Arxiv, DOI [arXiv:1809.11096, DOI 10.48550/ARXIV.1809.11096]
   Chen MS, 2020, AAAI CONF ARTIF INTE, V34, P3513
   Chen NX, 2020, Arxiv, DOI arXiv:2009.00713
   Dhariwal P, 2021, ADV NEUR IN, V34
   Esser P, 2021, PROC CVPR IEEE, P12868, DOI 10.1109/CVPR46437.2021.01268
   HaoChen Jeff Z, 2021, Advances in Neural Information Processing Systems, V34, P5000
   Ho J., 2020, Advances in neural information processing systems, V33, P6840
   Ho JAT, 2022, Arxiv, DOI arXiv:2207.12598
   Huang H, 2022, IEEE/CAA J Automatica Sinica
   Huang H, 2023, IEEE Trans Neural Networks and Learn Syst
   Kong Z., 2009, arXiv
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li HY, 2022, NEUROCOMPUTING, V479, P47, DOI 10.1016/j.neucom.2022.01.029
   Li SY, 2014, AAAI CONF ARTIF INTE, P1968
   Li YF, 2021, AAAI CONF ARTIF INTE, V35, P8547
   Liang NY, 2024, IEEE T BIG DATA, V10, P55, DOI 10.1109/TBDATA.2023.3319249
   Liang NY, 2023, IEEE T KNOWL DATA EN, V35, P6504, DOI 10.1109/TKDE.2022.3171911
   Lin YJ, 2021, PROC CVPR IEEE, P11169, DOI 10.1109/CVPR46437.2021.01102
   Liu, 2022, IEEE T PATTERN ANAL
   Liu KL, 2019, IEEE I CONF COMP VIS, P6391, DOI 10.1109/ICCV.2019.00648
   Liu XW, 2021, PR MACH LEARN RES, V139
   Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101
   Mukhopadhyay A., 2022, Lecture Notes in Computer Science, V13609, P117, DOI DOI 10.1007/978-3-031-18576-212
   Nene S. A., 1996, Tech. Rep. CUCS-005-96
   Nichol A, 2022, Arxiv, DOI [arXiv:2112.10741, DOI 10.48550/ARXIV.2112.10741]
   Pan EL, 2021, ADV NEUR IN, V34
   Peng X, 2019, PR MACH LEARN RES, V97
   Ramesh A., 2022, arXiv, DOI 10.48550/arXiv.2204.06125
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Saharia C, 2022, Arxiv, DOI arXiv:2205.11487
   Saharia C, 2023, IEEE T PATTERN ANAL, V45, P4713, DOI 10.1109/TPAMI.2022.3204461
   Saharia Chitwan, 2022, ACM SIGGRAPH 2022 C, P1
   Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256
   Song Y., 2019, Adv. Neural Inf. Process. Syst., V32
   Tang HY, 2022, 39 INT C MACHINE LEA
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Van Gansbeke Wouter, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P268, DOI 10.1007/978-3-030-58607-2_16
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Q, 2022, IEEE Trans neural Netw Learn Syst
   Wang QQ, 2021, IEEE T IMAGE PROCESS, V30, P1771, DOI 10.1109/TIP.2020.3048626
   Wang WR, 2015, PR MACH LEARN RES, V37, P1083
   Wen J, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P3538, DOI 10.1145/3459637.3482192
   Wen J, 2021, AAAI CONF ARTIF INTE, V35, P10273
   Wen J, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3230
   Xiao H, 2017, Arxiv, DOI [arXiv:1708.07747, DOI 10.48550/ARXIV.1708.07747]
   Xu C, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3933
   Xu J, 2022, AAAI CONF ARTIF INTE, P8761
   Xu J, 2022, PROC CVPR IEEE, P16030, DOI 10.1109/CVPR52688.2022.01558
   Xu J, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9214, DOI 10.1109/ICCV48922.2021.00910
   Zhang Y, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P2717, DOI 10.1145/3474085.3475204
   Zhao H., 2016, IJCAI, P2392
NR 51
TC 0
Z9 0
U1 13
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 2
PY 2023
DI 10.1007/s11042-023-17669-9
EA DEC 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AV0F5
UT WOS:001121103400001
DA 2024-07-18
ER

PT J
AU Lu, CT
   Shen, JH
   Castiglione, A
   Chung, CH
   Lu, YY
AF Lu, Ching-Ta
   Shen, Jun-Hong
   Castiglione, Aniello
   Chung, Cheng-Han
   Lu, Yen-Yu
TI A speech denoising demonstration system using multi-model deep-learning
   neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Speech denoising; Speech and noise separation; Multi-model deep-learning
   neural network; Harmonic convolutional neural network;
   Speech-deep-learning neural network
ID NOISE-REDUCTION; GAIN FACTOR; ENHANCEMENT; MASKING; SUBTRACTION;
   FRAMEWORK; SNR
AB Sound noise would interfere with speech signals in natural environments, causing speech quality deterioration. Speech denoising aims to denoise effectively with the preservation of speech components. Noise estimation is critical for speech denoising. Speech components distort when overestimating the noise spectral level. On the contrary, underestimating the noise's spectral level cannot remove noise effectively. Much residual noise exists in the denoised speech, resulting in low speech quality. This article presents a multi-model deep-learning neural network (MDNN) for speech enhancement. Firstly, a harmonic-convolutional neural network (harmonic-CNN) is utilized to classify speech and noise segments by spectrograms. The target is manually labeled according to harmonic properties. A speech-deep-learning neural network (speech-DNN) improves the harmonic-CNN's recognition accuracy. Some robust speech features, including energy variation and zero-crossing rate, are also applied to classify speech and noise segments by a speech-DNN. The noise level is overestimated in speech-pause parts to suppress noise spectra effectively in the enhanced speech. Conversely, the noise level is underestimated in speech-presence frames to reduce speech distortion. The experiment results reveal that the presented MDNN accurately classifies speech and noise segments, effectively reducing interference noise.
C1 [Lu, Ching-Ta] Feng Chia Univ, Dept Commun Engn, Taichung 407102, Taiwan.
   [Shen, Jun-Hong] Natl United Univ, Dept Informat Management, Miaoli Cty 360301, Taiwan.
   [Castiglione, Aniello] Univ Salerno, Dept Management & Innovat Syst, I-84084 Fisciano, SA, Italy.
   [Chung, Cheng-Han] Asia Univ, Dept Informat & Commun Engn, Taichung 41354, Taiwan.
   [Lu, Yen-Yu] Natl Chengchi Univ, Dept Comp Sci, Taipei City 11605, Taiwan.
C3 National United University; University of Salerno; Asia University
   Taiwan; National Chengchi University
RP Shen, JH (corresponding author), Natl United Univ, Dept Informat Management, Miaoli Cty 360301, Taiwan.
EM Lucas1@ms26.hinet.net; shenjh@nuu.edu.tw; castiglione@ieee.org;
   w4787829@gmail.com; lulujq0924@gmail.com
OI Shen, Jun-Hong/0000-0002-6220-096X
FU National Science and Technology Council
FX We thank the reviewers for their valuable comments, which have
   significantly improved the quality of this paper.
CR Bai HC, 2018, CHINA COMMUN, V15, P235, DOI 10.1109/CC.2018.8456465
   Chai L, 2021, IEEE-ACM T AUDIO SPE, V29, P106, DOI 10.1109/TASLP.2020.3036783
   Emani RPK, 2020, P INT C COMP COMM SI, P1, DOI [10.1109/ICCCSP49186.2020.9315269, DOI 10.1109/ICCCSP49186.2020.9315269]
   Garg A, 2020, PATTERN ANAL APPL, V23, P179, DOI 10.1007/s10044-018-00768-x
   Hasan MK, 2004, IEEE SIGNAL PROC LET, V11, P450, DOI 10.1109/LSP.2004.824017
   Islam MS, 2020, J SIGNAL PROCESS SYS, V92, P445, DOI 10.1007/s11265-019-01480-7
   Jadda A, 2023, MULTIMED TOOLS APPL, V82, P24101, DOI 10.1007/s11042-022-14180-5
   Jaiswal Rahul Kumar, 2022, International Journal of Speech Technology, P745, DOI 10.1007/s10772-022-09987-4
   Kavalekalam MS, 2019, IEEE-ACM T AUDIO SPE, V27, P99, DOI 10.1109/TASLP.2018.2872128
   Khanduzi R, 2023, J COMPUT SCI-NETH, V67, DOI 10.1016/j.jocs.2023.101970
   Khattak MI, 2022, COMPUT ELECTR ENG, V100, DOI 10.1016/j.compeleceng.2022.107887
   Koning R, 2018, IEEE T NEUR SYS REH, V26, P687, DOI 10.1109/TNSRE.2018.2794557
   Lavanya T, 2020, IEEE-ACM T AUDIO SPE, V28, P1315, DOI 10.1109/TASLP.2020.2986877
   Liu B, 2016, J SIGNAL PROCESS SYS, V82, P141, DOI 10.1007/s11265-015-1025-1
   Lu CT, 2017, NOISE CONTROL ENG J, V65, P509, DOI 10.3397/1/376565
   Lu CT, 2014, SPEECH COMMUN, V58, P35, DOI 10.1016/j.specom.2013.11.002
   Lu CT, 2014, APPL ACOUST, V76, P249, DOI 10.1016/j.apacoust.2013.08.015
   Lu CT, 2011, SPEECH COMMUN, V53, P495, DOI 10.1016/j.specom.2010.11.008
   Lu CT, 2010, COMPUT SPEECH LANG, V24, P632, DOI 10.1016/j.csl.2009.09.001
   Nicolson A, 2020, SPEECH COMMUN, V125, P80, DOI 10.1016/j.specom.2020.10.004
   Nisa R, 2023, EXPERT SYST APPL, V232, DOI 10.1016/j.eswa.2023.120746
   Plapous C, 2006, IEEE T AUDIO SPEECH, V14, P2098, DOI 10.1109/TASL.2006.872621
   Prasad N, 2020, PROCEEDINGS OF THE 2020 5TH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND SECURITY (ICCCS-2020), DOI 10.1109/icccs49678.2020.9277386
   Saleem N, 2021, J AMB INTEL HUM COMP, V12, P9037, DOI 10.1007/s12652-020-02598-4
   Stahl J, 2019, SPEECH COMMUN, V111, P1, DOI 10.1016/j.specom.2019.05.001
   Virag N, 1999, IEEE T SPEECH AUDI P, V7, P126, DOI 10.1109/89.748118
   Wang ZY, 2021, APPL ACOUST, V172, DOI 10.1016/j.apacoust.2020.107647
   Wei YG, 2022, J AMB INTEL HUM COMP, V13, P1525, DOI 10.1007/s12652-021-03022-1
   Wood SUN, 2019, IEEE-ACM T AUDIO SPE, V27, P2150, DOI 10.1109/TASLP.2019.2937174
   Yang F, 2020, SPEECH COMMUN, V118, P1, DOI 10.1016/j.specom.2020.02.001
   Yang TH, 2017, J AMB INTEL HUM COMP, V8, P895, DOI 10.1007/s12652-016-0395-y
   Yuan WH, 2020, SPEECH COMMUN, V124, P75, DOI 10.1016/j.specom.2020.09.002
   Zhang JM, 2022, APPL SOFT COMPUT, V118, DOI 10.1016/j.asoc.2022.108485
   Zheng NH, 2020, J SIGNAL PROCESS SYS, V92, P875, DOI 10.1007/s11265-020-01518-1
   Zhu YY, 2020, APPL ACOUST, V170, DOI 10.1016/j.apacoust.2020.107511
NR 35
TC 0
Z9 0
U1 19
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 21
PY 2023
DI 10.1007/s11042-023-17655-1
EA NOV 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Y6BH9
UT WOS:001106086000006
DA 2024-07-18
ER

PT J
AU Niu, D
   Yu, SS
   Xu, JL
   Wang, CL
   Li, RX
   Ding, XQ
AF Niu, Di
   Yu, Shusong
   Xu, Jiali
   Wang, Chenglong
   Li, Ruoxi
   Ding, Xiangqian
TI Unknown fault detection method for rolling bearings based on image and
   signal series feature fusion enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Novel class discovery; Intelligent fault diagnosis; Multimodal;
   Convolutional neural network
ID CONVOLUTIONAL NEURAL-NETWORK; DIAGNOSIS
AB This paper mainly studies the problem of finding new fault classes under different modes in the field of intelligent fault diagnosis, that is, in the case of some labeled faults, new classes are revealed in unlabeled fault samples. In this paper, we introduce a comprehensive multi-modal framework for novel fault discovery and explore the impact of different modalities on the task of identifying new fault classes. To enhance the robustness of feature representation in complex environments, We adopted the approach inspired by ChatGPT, wherein we conducted pre-training on a substantial amount of labeled data to learn general features, patterns, and representations of various fault types. During the pre-training process, we integrated multiple modalities of data to prevent the loss of information due to the absence of single-modal data, thereby enhancing the accuracy of clustering. Furthermore, we introduced a multi-modal fusion method based on saliency correlation to complementarily fuse the information from different modalities. This approach effectively eliminated data redundancy arising from diverse modalities. Adhering to the principle that improving the quality of pseudo-label generation during the new class discovery phase enhances the accuracy of clustering for new classes, we extend the multi-modal concept. We introduce a Discriminative Relationship Enhancement method that capitalizes on cross-validation of pseudo-label predictions from different modalities during the pseudo-label prediction phase. This augmentation enhances the precision of pseudo-labels during the new class discovery phase. We evaluated the effectiveness of our proposed framework on fault datasets CWRU and PU, achieving promising results.
C1 [Niu, Di; Yu, Shusong; Wang, Chenglong; Li, Ruoxi; Ding, Xiangqian] Ocean Univ China, Fac Informat Sci & Engn, Qingdao, Shandong, Peoples R China.
   [Xu, Jiali] QNLM, Laoshan Lab, Qingdao, Peoples R China.
C3 Ocean University of China; Laoshan Laboratory
RP Yu, SS (corresponding author), Ocean Univ China, Fac Informat Sci & Engn, Qingdao, Shandong, Peoples R China.; Xu, JL (corresponding author), QNLM, Laoshan Lab, Qingdao, Peoples R China.
EM niudi@stu.ouc.edu.cn; yushusong@ouc.edu.cn; jlxu@qnlm.ac;
   wangchenglong@stu.ouc.edu.cn; liruoxi@stu.ouc.edu.cn; dingxq@ouc.edu.cn
RI wang, chenglong/GQQ-2852-2022; Xu, jiali/GRS-1598-2022
OI wang, chenglong/0000-0002-3567-5759; 
FU National Key Research and Development Program of China [2020YFB1711700];
   National Key Research and Development Program of China [62072418,
   62172376]; National Natural Science Foundation of China
   [2019JZZY020705]; Major Scientific and Technological Innovation Project
   of Shandong [202042008]; Fundamental Research Funds for the Central
   Universities [21-1-2-18-xx]; Key Research and Development Program of
   Qingdao Science and Technology Plan
FX This work was supported in part by the National Key Research and
   Development Program of China (2020YFB1711700), the National Natural
   Science Foundation of China (62072418, 62172376), the Major Scientific
   and Technological Innovation Project of Shandong(2019JZZY020705), the
   Fundamental Research Funds for the Central Universities (202042008), and
   the Key Research and Development Program of Qingdao Science and
   Technology Plan (21-1-2-18-xx).
CR [Anonymous], 2009, Scholarpedia
   Arthur D, 2006, Stanford Infolab, V8090, P778
   Basu S., 2002, P ICML 2002
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Brown T., 2020, Advances in Neural Information Processing Systems, V33, P1877, DOI [DOI 10.48550/ARXIV.2005.14165, DOI 10.5555/3495724.3495883]
   Callut J, 2008, LECT NOTES ARTIF INT, V5211, P162, DOI 10.1007/978-3-540-87479-9_29
   Caron M., 2020, Advances in neural information processing systems, V33, P9912
   Chang JL, 2017, IEEE I CONF COMP VIS, P5880, DOI [10.1109/ICCV.2017.626, 10.1109/ICCV.2017.627]
   Chapelle O., 2006, SEMISUPERVISED LEARN
   Chen ZY, 2017, IEEE T INSTRUM MEAS, V66, P1693, DOI 10.1109/TIM.2017.2669947
   Dizaji KG, 2017, IEEE I CONF COMP VIS, P5747, DOI 10.1109/ICCV.2017.612
   Du WL, 2014, MECH SYST SIGNAL PR, V43, P57, DOI 10.1016/j.ymssp.2013.09.003
   Fini Enrico, 2021, P IEEE CVF INT C COM, P9284
   Gidaris S, 2018, Arxiv, DOI arXiv:1803.07728
   Guo Y, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING AND COMMUNICATIONS (BIGCOM), P226, DOI 10.1109/BIGCOM.2017.13
   Han K, 2020, Arxiv, DOI arXiv:2002.05714
   Han K, 2022, IEEE T PATTERN ANAL, V44, P6767, DOI 10.1109/TPAMI.2021.3091944
   Han K, 2019, IEEE I CONF COMP VIS, P8400, DOI 10.1109/ICCV.2019.00849
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hsu YC, 2018, Arxiv, DOI arXiv:1711.10125
   Hsu Z. Lv, 2019, arXiv
   Huang WY, 2019, NEUROCOMPUTING, V359, P77, DOI 10.1016/j.neucom.2019.05.052
   Janssens O, 2016, J SOUND VIB, V377, P331, DOI 10.1016/j.jsv.2016.05.027
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lu WN, 2017, IEEE T IND ELECTRON, V64, P2296, DOI 10.1109/TIE.2016.2627020
   Makhzani A, 2015, ADV NEUR IN, V28
   Mao WT, 2017, P I MECH ENG C-J MEC, V231, DOI 10.1177/0954406216675896
   Asano YM, 2020, Arxiv, DOI arXiv:1911.05371
   Mehrkanoon S, 2015, IEEE T NEUR NET LEAR, V26, P720, DOI 10.1109/TNNLS.2014.2322377
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Nie WZ, 2023, IEEE T MULTIMEDIA, V25, P9383, DOI 10.1109/TMM.2023.3251697
   Paderborn University, Mechanical Fault Diagnosis Dataset
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Radford A, Improving language understanding by generative pre-training
   Radford A., 2019, LANGUAGE MODELS ARE
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Salakhutdinov R., 2009, ARTIFICIAL INTELLIGE, V5, P448, DOI DOI 10.1109/CVPRW.2009.5206577
   Shao HD, 2018, KNOWL-BASED SYST, V140, P1, DOI 10.1016/j.knosys.2017.10.024
   Tang JX, 2016, IEEE T NEUR NET LEAR, V27, P809, DOI 10.1109/TNNLS.2015.2424995
   Troisemaine C, 2023, Arxiv, DOI arXiv:2302.12028
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Zhang W, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17020425
   Zhong Z, 2021, PROC CVPR IEEE, P10862, DOI 10.1109/CVPR46437.2021.01072
   Zhong Z, 2021, PROC CVPR IEEE, P9457, DOI 10.1109/CVPR46437.2021.00934
   Zhu HJ, 2015, PROCEEDINGS OF 2015 IEEE 12TH INTERNATIONAL CONFERENCE ON ELECTRONIC MEASUREMENT & INSTRUMENTS (ICEMI), VOL. 1, P58, DOI 10.1109/ICEMI.2015.7494195
NR 47
TC 0
Z9 0
U1 14
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 18
PY 2023
DI 10.1007/s11042-023-17557-2
EA NOV 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Y5JY5
UT WOS:001105630500001
DA 2024-07-18
ER

PT J
AU Agarwal, I
   Rana, D
   Panwala, K
   Shah, RJ
   Kathiriya, V
AF Agarwal, Isha
   Rana, Dipti
   Panwala, Kalp
   Shah, Raj
   Kathiriya, Viren
TI Analysis of contextual features' granularity for fake news detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE COVID-19; Fake news; Infodemic; Feature extraction; Classification
ID FIGHT; WEB
AB While the world is battling COVID-19 pandemic and its variants; netizens are combating Infodemic - "Proliferation of fake news online". Spread of fake news during this global pandemic COVID-19 has dangerous consequences. Precise automated fake news detection is the need of the hour. This is the driving force behind this study. Intrinsic quality of news data: precision and objectivity can be studied to detect the credibility. However, to gain the knowledge or inference from it further it is a challenge. To address this challenge, this work proposes derivation of features into two categories: intrinsic word level features (Fine-grained) and sentence level features (Coarse- grained).For experimentation, fine-grained features are learned from word vector representation of the news articles. Psycho-linguistic and sentiment level word level features are derived using Empath library. Coarse-grained features (sentence-level) comprise of vectors generated by Text summarization and DOC2Vec. Taking the advantages of existing approaches, this paper proposes a new framework Granularity based Fake news Detection (GRAFED) that explores fusion of fine and coarse-grained features. The fusion of feature set is more powerful than individual fine or coarse-grained feature sets as they can capture complex interdependence of words in the sentence along with the semantics. Exhaustive experimentation using traditional classifiers with hybrid granular feature vector of GRAFED outperformed the existing approaches for publicly available state-of-art LIAR dataset. Experimental results show that the hybrid feature set is superior to individual feature set and the results are promising when compared to the existing state-of-art approaches as analyzed in the comparative analysis section.
C1 [Agarwal, Isha; Rana, Dipti; Panwala, Kalp; Shah, Raj; Kathiriya, Viren] Sardar Vallabhbhai Natl Inst Technol, Dept Comp Sci & Engn, Surat 395007, Gujarat, India.
C3 National Institute of Technology (NIT System); Sardar Vallabhbhai
   National Institute of Technology
RP Agarwal, I (corresponding author), Sardar Vallabhbhai Natl Inst Technol, Dept Comp Sci & Engn, Surat 395007, Gujarat, India.
EM d17co004@coed.svnit.ac.in; dpr@coed.svnit.ac.in; kpanwala33@gmail.com;
   rajshah9914@gmail.com; virenkathiriya96@gmail.com
RI Rana, Dipti P/T-7819-2019
OI Rana, Dipti P/0000-0002-5058-1355; Agarwal, Isha/0000-0002-9094-9118
CR Agarwal I., 2020, J Adv Res Dyn Control Syst, V12, P1738, DOI [10.5373/JARDCS/V12SP7/20202283, DOI 10.5373/JARDCS/V12SP7/20202283]
   AGARWAL Isha, 2020, Mendeley Data, DOI 10.17632/B96V5HMFV6.3
   Ahmed H, 2018, SECUR PRIVACY, V1, DOI 10.1002/spy2.9
   Albulescu C., 2020, SSRN Electronic Journal
   Ali M, 2008, COMMUN REP, V21, P82, DOI 10.1080/08934210802381862
   Allahyari Mehdi., 2017, TEXT SUMMARIZATION T
   Anjali B., 2019, 2019 2nd International Conference on Intelligent Computing, Instrumentation and Control Technologies (ICICICT), P1382, DOI 10.1109/ICICICT46008.2019.8993330
   [Anonymous], 1947, The Psychology of Rumor
   Batchelor O, 2017, REF SERV REV, V45, P143, DOI 10.1108/RSR-03-2017-0006
   Benevenuto Fabricio., 2010, COLL EL MESS ANT SPA, V6, P12
   Castillo C., 2011, P 20 INT C WORLD WID, P675, DOI DOI 10.1145/1963405.1963500
   Chen Y., 2015, Proceedings of the 2015 ACM on Workshop on Multimodal Deception Detection, P15, DOI 10.1145/2823465.2823467
   Chen Y, 2017, P 45 ANN C CAN ASS I
   Chiu DKW, 2009, EXPERT SYST APPL, V36, P3293, DOI 10.1016/j.eswa.2008.01.055
   Cinelli M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-73510-5
   Dong LY, 2018, EXPERT SYST APPL, V114, P210, DOI 10.1016/j.eswa.2018.07.005
   Driscoll L.N., 1994, POLICE STUDIES, V27, P77
   Fast E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4647, DOI 10.1145/2858036.2858535
   Fuller CM, 2009, DECIS SUPPORT SYST, V46, P695, DOI 10.1016/j.dss.2008.11.001
   Galli A, 2022, J INTELL INF SYST, V59, P237, DOI 10.1007/s10844-021-00646-9
   Garg Sonal, 2020, Proceedings of the 2020 9th International Conference System Modeling and Advancement in Research Trends (SMART), P17, DOI 10.1109/SMART50582.2020.9337152
   Gormsen NJ, 2020, REV ASSET PRICING ST, V10, P574, DOI 10.1093/rapstu/raaa013
   Hong D, 2007, INFORM SYST FRONT, V9, P343, DOI 10.1007/s10796-007-9039-2
   Hung PCK, 2007, INFORM SYST FRONT, V9, P85, DOI 10.1007/s10796-006-9019-y
   Kerschberg L, 2014, INT J ARTIF INTELL T, V23, DOI 10.1142/S0218213014600227
   Kwon S, 2013, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2013.61
   Li LY, 2017, NEUROCOMPUTING, V254, P33, DOI 10.1016/j.neucom.2016.10.080
   Li YR, 2015, SUGAR TECH, V17, P1, DOI 10.1007/s12355-014-0342-1
   Lin Tian, 2020, Advances in Information Retrieval, 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12035), P575, DOI 10.1007/978-3-030-45439-5_38
   Liu JM, 2003, J INTELL INF SYST, V20, P5, DOI 10.1023/A:1020945620934
   Mhalla M., 2020, J ASIAN SCI RES, V10, P96, DOI [10.18488/journal.2.2020.102.96.104, DOI 10.18488/JOURNAL.2.2020.102.96.104]
   Nasir J.A., 2021, International Journal of Information Management Data Insights, V1, P100007, DOI [10.1016/j.jjimei.2020.100007, DOI 10.1016/J.JJIMEI.2020.100007]
   Pennebaker J.W., 2001, Linguistic inquiry and word count: LIWC 2001, V71, P1
   Qiu LQ, 2019, IEEE ACCESS, V7, P42052, DOI 10.1109/ACCESS.2019.2894155
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Ren YF, 2017, INFORM SCIENCES, V385, P213, DOI 10.1016/j.ins.2017.01.015
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Shao CC, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06930-7
   Shu K., 2017, ACM SIGKDD EXPLOR NE, V19, P22, DOI [DOI 10.1145/3137597.3137600, 10.1145/3137597.3137600]
   Sonntag D, 2004, Informatik 2004-Informatik verbindet, V1
   Su YS, 2020, LIBR HI TECH, V38, P420, DOI 10.1108/LHT-01-2019-0028
   Sukowski ukasz, 2020, J INTERCULTURAL MANA, V12, P1, DOI [10.2478/joim-2020-0029, DOI 10.2478/JOIM-2020-0029]
   Undeutsch U, 1984, Intern Rev Appl Psychol
   Vosoughi S, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3070644
   Wang WY, 2017, arXiv, DOI [10.48550/arXiv.1705.00648, DOI 10.48550/ARXIV.1705.00648]
   Wu D, 2020, LIBR HI TECH, V38, P701, DOI 10.1108/LHT-11-2020-280
   Wu TY, 2019, J CHIN INST ENG, V42, P20, DOI 10.1080/02533839.2018.1537807
   Zarocostas J, 2020, LANCET, V395, P676, DOI 10.1016/S0140-6736(20)30461-X
   Zhang DC, 2022, J INTELL INF SYST, V59, P173, DOI 10.1007/s10844-021-00678-1
   Zhou L, 2004, GROUP DECIS NEGOT, V13, P81, DOI 10.1023/B:GRUP.0000011944.62889.6f
   Zubiaga A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150989
NR 51
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 15
PY 2023
DI 10.1007/s11042-023-17465-5
EA NOV 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8YK4
UT WOS:001101241300003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, HY
   Chien, CW
   Tsai, MH
   Lin, IC
AF Wang, Hsin-Ying
   Chien, Chiu-Wei
   Tsai, Ming-Han
   Lin, I-Chen
TI Hairstyle-and-identity-aware facial image style transfer with
   region-guiding masks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Face style transfer; Hairstyle transfer; Face identity preservation;
   Regional masks
ID GENERATIVE ADVERSARIAL NETWORKS
AB Face style transfer aims to transfer parts of appearance features from a reference to a source face and to keep the important characteristics of the source as well. During face style transfer, hairstyle structure of the reference and personal identity of the source are two important appearance characteristics, but few existing models can maintain both of these features during the transfer process simultaneously. To concurrently retain the two important features, we propose a framework with two stages to deal with the two sub-tasks respectively. In the first stage, our model uses region-guiding masks and the modified cycle loss to generate an image where the hairstyle is transferred adequately. Based on the hairstyle-transferred face, we focus on preserving the identity with a face replacement procedure and refining the image quality in the second stage. In addition to hair-style-aware transfer, we also exhibit that this framework can be extended for other region-aware tasks, such as eyeglasses transfer. User evaluation and the application of face recognition as a metric demonstrated that our proposed framework can generate high-quality images with accurate hairstyle transfer from the reference image while preserving the identity of the source image.
C1 [Wang, Hsin-Ying; Chien, Chiu-Wei; Lin, I-Chen] Natl Yang Ming Chiao Tung Univ, Coll Comp Sci, Hsinchu 30010, Taiwan.
   [Tsai, Ming-Han] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
C3 National Yang Ming Chiao Tung University; Feng Chia University
RP Lin, IC (corresponding author), Natl Yang Ming Chiao Tung Univ, Coll Comp Sci, Hsinchu 30010, Taiwan.; Tsai, MH (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
EM singing9339@gmail.com; toculin38@gmail.com; minghtsai@fcu.edu.tw;
   ichenlin@cs.nycu.edu.tw
OI Lin, I-Chen/0000-0001-9924-4723
FU Ministry of Science and Technology, Taiwan [MOST 109-2221-E-009-122-MY3]
FX This work was partially supported by the Ministry of Science and
   Technology, Taiwan under grant no. MOST 109-2221-E-009-122-MY3.
CR Bacanin N, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09744-2
   Bhatti UA, 2020, IEEE ACCESS, V8, P155783, DOI 10.1109/ACCESS.2020.3018544
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chai CL, 2018, MULTIMED TOOLS APPL, V77, P22339, DOI 10.1007/s11042-018-5968-7
   Chen QF, 2017, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2017.168
   Chen SY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392386
   Chen Y, 2018, PROC CVPR IEEE, P9465, DOI 10.1109/CVPR.2018.00986
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Di YD, 2021, MULTIMED TOOLS APPL, V80, P35629, DOI 10.1007/s11042-021-10830-2
   Fatima A, 2021, MULTIMED TOOLS APPL, V80, P3775, DOI 10.1007/s11042-020-09861-y
   Gao GG, 2021, PROC CVPR IEEE, P3403, DOI 10.1109/CVPR46437.2021.00341
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He ZL, 2019, IEEE T IMAGE PROCESS, V28, P5464, DOI 10.1109/TIP.2019.2916751
   Huang SS, 2021, MULTIMED TOOLS APPL, V80, P26465, DOI 10.1007/s11042-021-10881-5
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kim Hyunsu, 2021, arXiv
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee CH, 2020, PROC CVPR IEEE, P5548, DOI 10.1109/CVPR42600.2020.00559
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Lee J, 2020, PROC CVPR IEEE, P5800, DOI 10.1109/CVPR42600.2020.00584
   Lee YH, 2018, COMPUT GRAPH FORUM, V37, P214, DOI 10.1111/cgf.13261
   Li LZ, 2020, Arxiv, DOI arXiv:1912.13457
   Li LZ, 2020, PROC CVPR IEEE, P5073, DOI 10.1109/CVPR42600.2020.00512
   Li MJ, 2018, LECT NOTES COMPUT SC, V11213, P186, DOI 10.1007/978-3-030-01240-3_12
   Li R, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107343
   Liu M, 2019, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2019.00379
   Liu YH, 2021, PROC CVPR IEEE, P10780, DOI 10.1109/CVPR46437.2021.01064
   Mao Q, 2019, PROC CVPR IEEE, P1429, DOI 10.1109/CVPR.2019.00152
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Portenier T, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201393
   Richardson E, 2021, PROC CVPR IEEE, P2287, DOI 10.1109/CVPR46437.2021.00232
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schroff F, 2015, Arxiv, DOI arXiv:1503.03832
   Shuyang Gu, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P3431, DOI 10.1109/CVPR.2019.00355
   Tomei M, 2019, PROC CVPR IEEE, P5842, DOI 10.1109/CVPR.2019.00600
   Tsai MH, 2014, MULTIMED TOOLS APPL, V72, P801, DOI 10.1007/s11042-013-1399-7
   Ulyanov D, 2017, Arxiv, DOI arXiv:1607.08022
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wu J, 2023, Multimed Tool Appl
   Wu PW, 2019, IEEE I CONF COMP VIS, P5913, DOI 10.1109/ICCV.2019.00601
   Wu Y, 2022, IEEE C COMP VIS PATT
   Xiao CF, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480502
   Yang B, 2023, IEEE CVF C COMP VIS
   Yazici Y, 2019, 7 INT C LEARN REPR I
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yunjey Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8185, DOI 10.1109/CVPR42600.2020.00821
   Zhang T, 2022, MULTIMED TOOLS APPL, V81, P6259, DOI 10.1007/s11042-021-11733-y
   Zheng J-W, 2023, IEEE Trans Visual Comput Graph
   Zhongyou Xu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9360, DOI 10.1109/CVPR42600.2020.00938
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu PH, 2020, PROC CVPR IEEE, P5103, DOI 10.1109/CVPR42600.2020.00515
NR 55
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 15
PY 2023
DI 10.1007/s11042-023-17298-2
EA NOV 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8YK4
UT WOS:001101241300001
DA 2024-07-18
ER

PT J
AU Abed, RQ
   Dikmen, M
   Aydemir, E
   Barua, PD
   Dogan, S
   Tuncer, T
   Palmer, EE
   Ciaccio, EJ
   Acharya, UR
AF Abed, Rusul Qasim
   Dikmen, Melih
   Aydemir, Emrah
   Barua, Prabal Datta
   Dogan, Sengul
   Tuncer, Turker
   Palmer, Elizabeth Emma
   Ciaccio, Edward J.
   Acharya, U. Rajendra
TI Automated reading level classification model based on improved orbital
   pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human-computer interface; Teaching/learning strategies; 21st-century
   abilities; Data science applications in education
ID FEATURE-SELECTION; RECOGNITION
AB Automatic reading level for detection and classification is a challenging problem in machine learning. A multilevel feature extraction-based self-organized model may be useful to overcome this hurdle without using deep learning, which requires an ultra-large sample size. In this work, a novel speech dataset was collected from 57 primary school students by reading a fixed paragraph, and experts labeled these speeches as good, moderate, or bad. We then developed a handcrafted, self-organized learning model. We constructed a novel method using a multilevel feature extraction method, termed improved orbital pattern (IOP) and wavelet packet decomposition (WPD). The proposed IOP generates textural features from the speeches and the used wavelet bands. These extracted features are input to neighborhood components analysis (NCA) to reduce feature dimension. Then the feature set is input to the support vector machine (SVM) classifier to obtain loss values. The output of ten feature vectors of the NCA and SVM classifiers are merged to provide the final feature vector. The most significant 512 features were selected using the NCA feature selection function. These 512 features are classified via the SVM classifier with tenfold cross-validation (CV) and leave-one-subject-out (LOSO) validation strategies. The proposed IOP and WPD-based model yielded an accuracy of 92.75% with a tenfold CV and a 76.18% accuracy using LOSO validation strategies in classifying bad, intermediate, and good reading levels. Our developed model is ready to be validated with more data before its actual usage in schools to aid the teachers.
C1 [Abed, Rusul Qasim] Kirsehir Ahievran Univ, Dept Comp Engn, Coll Engn, Kirsehir, Turkiye.
   [Dikmen, Melih] Firat Univ, Fac Educ, Elazig, Turkiye.
   [Aydemir, Emrah] Sakarya Univ, Management Fac, Dept Management Informat Syst, Sakarya, Turkiye.
   [Barua, Prabal Datta] Univ Southern Queensland, Sch Business Informat Syst, Toowoomba, Qld, Australia.
   [Dogan, Sengul; Tuncer, Turker] Firat Univ, Dept Digital Forens Engn, Coll Technol, Elazig, Turkiye.
   [Palmer, Elizabeth Emma] Sydney Childrens Hosp Network, Ctr Clin Genet, Randwick, NSW 2031, Australia.
   [Palmer, Elizabeth Emma] Univ New South Wales, Sch Womens & Childrens Hlth, Randwick, NSW 2031, Australia.
   [Ciaccio, Edward J.] Columbia Univ, Dept Med, Irving Med Ctr, New York, NY USA.
   [Acharya, U. Rajendra] Univ Southern Queensland, Sch Math Phys & Comp, Springfield, Australia.
C3 Firat University; Sakarya University; University of Southern Queensland;
   Firat University; NSW Health; Sydney Childrens Hospitals Network;
   University of New South Wales Sydney; NewYork-Presbyterian Hospital;
   Columbia University; University of Southern Queensland
RP Dogan, S (corresponding author), Firat Univ, Dept Digital Forens Engn, Coll Technol, Elazig, Turkiye.
EM rusol.kasem1190@gmail.com; mdikmen@firat.edu.tr;
   emrahaydemir@sakarya.edu.tr; Prabal.Barua@usq.edu.au;
   sdogan@firat.edu.tr; turkertuncer@firat.edu.tr;
   elizabeth.palmer@unsw.edu.au; ciaccio@columbia.edu;
   Rajendra.Acharya@usq.edu.au
CR Abo-Zahhad M, 2002, MED ENG PHYS, V24, P185, DOI 10.1016/S1350-4533(02)00004-8
   Ahmad F, 2020, CURR BIOINFORM, V15, P1056, DOI 10.2174/1574893615999200425225729
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Alam A., 2022, ADV COMPUTING INTELL, P395, DOI [DOI 10.1007/978-981-19-2980-9_32, 10.1007/978-981-19-2980-9_32]
   Babayigit O., 2018, Mehmet Akif Ersoy University Journal of Education Faculty, V46, P409, DOI [10.21764/maeuefd.330831, DOI 10.21764/MAEUEFD.330831]
   Ben Chaabane S, 2022, MULTIMED TOOLS APPL, V81, P8767, DOI 10.1007/s11042-021-11816-w
   Bolaños D, 2013, J EDUC PSYCHOL, V105, P1142, DOI 10.1037/a0031479
   Ecalle J, 2022, EUR J PSYCHOL EDUC, V37, P605, DOI 10.1007/s10212-021-00566-w
   Goldberger J., 2004, P 17 INT C NEUR INF, P513
   Gururaj N, 2023, MULTIMED TOOLS APPL, V82, P39525, DOI 10.1007/s11042-021-11616-2
   Hoskins WH, 2021, COMPUT HUM BEHAV REP, V4, DOI 10.1016/j.chbr.2021.100123
   Kaggle, 2021, Reading Sounds of According to Reading Levels
   Khan MT, 2022, P INT E C INT SYST S, P143, DOI [10.1007/978-981-16-2123-9_11, DOI 10.1007/978-981-16-2123-9_11]
   Khumsamart S., 2022, J Manag Bus Healthcare, Educ, V1, P1
   Kodan H., 2017, Universal Journal of Educational Research, V5, P1962
   Kononenko I., 1994, Machine Learning: ECML-94. European Conference on Machine Learning. Proceedings, P171
   Liu C, 2022, EDUC PSYCHOL-UK, V42, P530, DOI 10.1080/01443410.2022.2060497
   Liu H, 1995, PROC INT C TOOLS ART, P388, DOI 10.1109/TAI.1995.479783
   Loh HW, 2022, COMPUT METH PROG BIO, V226, DOI 10.1016/j.cmpb.2022.107161
   Luo QW, 2022, PATTERN RECOGN, V132, DOI 10.1016/j.patcog.2022.108901
   Middleton AE, 2022, J LEARN DISABIL-US, V55, P272, DOI 10.1177/00222194211047633
   Mustageem, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8122133
   Mustaqeem, 2021, APPL SOFT COMPUT, V102, DOI 10.1016/j.asoc.2021.107101
   Nayak SK, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122010371
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pae HK, 2022, J CULT COGN SCI, V6, P97, DOI 10.1007/s41809-022-00103-1
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Petersen SE, 2009, COMPUT SPEECH LANG, V23, P89, DOI 10.1016/j.csl.2008.04.003
   Raju G, 2008, ADCOM: 2008 16TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATIONS, P309, DOI 10.1109/ADCOM.2008.4760466
   Ribble M., 2022, DIGITAL CITIZENSHIP
   Shaikh AA, 2022, MATER TODAY-PROC, V56, P3211, DOI 10.1016/j.matpr.2021.09.368
   Sharma SK, 2022, MULTIMED TOOLS APPL, V81, P41785, DOI 10.1007/s11042-021-11653-x
   Tariq A, 2023, GEO-SPAT INF SCI, V26, P302, DOI 10.1080/10095020.2022.2100287
   Tuncer T, 2020, IEEE T INSTRUM MEAS, V69, P9441, DOI 10.1109/TIM.2020.3003395
   Uddin S, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-10358-x
   Ullah W, 2021, MULTIMED TOOLS APPL, V80, P30439, DOI 10.1007/s11042-021-10619-3
   Ulu Mustafa., 2017, J ED TRAINING STUDIE, V5, P44, DOI [10.11114/jets.v5i6.2391, DOI 10.11114/JETS.V5I6.2391]
   Wei JS, 2022, MULTIMED TOOLS APPL, V81, P20643, DOI 10.1007/s11042-022-12360-x
   Xiao Y, 2019, INT J ENGL LINGUIST, V9, P1, DOI 10.5539/ijel.v9n4p1
NR 39
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 14
PY 2023
DI 10.1007/s11042-023-17535-8
EA NOV 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JF3O4
UT WOS:001171713900008
DA 2024-07-18
ER

PT J
AU Kanagasankari, S
   Vallinayagi, V
AF Kanagasankari, S.
   Vallinayagi, V.
TI An efficient byzantine consensus mechanism based on healthcare sector in
   blockchain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Blockchain; Consensus; Hyperledger Fabric Platform; Electronic
   Healthcare Records; IPBFT; PBFT; RSA Cryptography
ID SECURE
AB A blockchain is a decentralized digital network system consisting of multiple blocks connected in a chain. Each block comprises multiple transactions and is linked to the previous block through its hash value. The hash values are calculated using the active transactions within each block and the hash value of the preceding block. A positive impact can be made by combining blockchain technology with the healthcare sector. The consensus mechanism is the key protocol for implementing agreements in the blockchain. This paper proposes a combined RSA (Rivest-Shamir-Adleman) cryptography algorithm with a novel consensus protocol IPBFT (Improved Practical Byzantine Fault Tolerance) in the Hyperledger Fabric platform, for a patient-centered approach using blockchain technology in the healthcare sector. It ensures the reliability and integrity of transactions and prevents malicious nodes from disrupting the network. The Hyperledger Fabric platform is used to provide transparency, security, and trust in the blockchain. Performance metrics such as latency, throughput, scalability, and comparative analysis for the proposed algorithm Improved Practical Byzantine Fault Tolerance (IPBFT) and existing Practical Byzantine Fault Tolerance (PBFT) algorithms have been evaluated to achieve enhanced results. The proposed algorithm solves many problems associated with existing Practical Byzantine Fault Tolerance solutions and improves efficiency and security in the healthcare sector.
C1 [Kanagasankari, S.; Vallinayagi, V.] Sri Sarada Coll Women Autonomous, Dept Comp Sci, Tirunelveli 627011, India.
   [Kanagasankari, S.; Vallinayagi, V.] Manonmaniam Sundaranar Univ, Tirunelveli 627012, India.
C3 Manonmaniam Sundaranar University
RP Kanagasankari, S (corresponding author), Sri Sarada Coll Women Autonomous, Dept Comp Sci, Tirunelveli 627011, India.; Kanagasankari, S (corresponding author), Manonmaniam Sundaranar Univ, Tirunelveli 627012, India.
EM kanagasankari1975@gmail.com; vallinayagimahesh@gmail.com
CR Akkaoui R, 2020, IEEE ACCESS, V8, P113467, DOI 10.1109/ACCESS.2020.3003575
   Ananth C., 2018, J Eng Technol, V6, P42
   Androulaki E, 2018, EUROSYS '18: PROCEEDINGS OF THE THIRTEENTH EUROSYS CONFERENCE, DOI 10.1145/3190508.3190538
   Antwi M, 2021, BLOCKCHAIN-RES APPL, V2, DOI 10.1016/j.bcra.2021.100012
   Attaran M, 2022, INT J HEALTHCARE MAN, V15, P70, DOI 10.1080/20479700.2020.1843887
   Chang SE, 2020, J MED INTERNET RES, V22, DOI 10.2196/19480
   Chen Y, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1121-4
   De Aguiar EJ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3376915
   Rossetto AGD, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22218292
   Dwivedi SK, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102554
   Farahat IS, 2023, INFORMATION, V14, DOI 10.3390/info14020080
   Nguyen GT, 2018, J INF PROCESS SYST, V14, P101, DOI 10.3745/JIPS.01.0024
   Hasselgren A, 2020, INT J MED INFORM, V134, DOI 10.1016/j.ijmedinf.2019.104040
   Hathaliya JJ, 2019, COMPUT ELECTR ENG, V76, P398, DOI 10.1016/j.compeleceng.2019.04.017
   Hölbl M, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10100470
   Iftekhar A, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23081054
   Ismail L, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12081200
   Ismail L, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101198
   Jin H, 2019, INT C PAR DISTRIB SY, P852, DOI 10.1109/ICPADS47876.2019.00126
   Kumar M, 2021, J NETW COMPUT APPL, V179, DOI 10.1016/j.jnca.2021.102975
   Lee YL, 2022, COMPUT METH PROG BIO, V215, DOI 10.1016/j.cmpb.2021.106595
   Madine MM, 2020, IEEE ACCESS, V8, P193102, DOI 10.1109/ACCESS.2020.3032553
   McGhin T, 2019, J NETW COMPUT APPL, V135, P62, DOI 10.1016/j.jnca.2019.02.027
   Meshcheryakov Y, 2021, IEEE ACCESS, V9, P80559, DOI 10.1109/ACCESS.2021.3085405
   Nakamoto S., 2008, DECENT BUS REV, V21260, DOI https://bitcoin.org/bitcoin.pdf
   Nguyen DC, 2019, IEEE ACCESS, V7, P66792, DOI 10.1109/ACCESS.2019.2917555
   Nisha Shireen, 2017, International Journal Of Scientific & Technology Research, V6
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Pandey AK, 2020, IEEE ACCESS, V8, P40612, DOI 10.1109/ACCESS.2020.2976687
   Ramani V., 2018, 2018 IEEE Global Communications Conference (GLOBECOM), P206, DOI [DOI 10.1109/GLOCOM.2018.8647221, 10.1109/GLOCOM.2018.8647221]
   Ray PP, 2021, IEEE SYST J, V15, P85, DOI 10.1109/JSYST.2020.2963840
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Salimitari M, 2020, INTERNET THINGS-NETH, V11, DOI 10.1016/j.iot.2020.100212
   Siyal AA, 2019, CRYPTOGRAPHY-BASEL, V3, DOI 10.3390/cryptography3010003
   Tanwar S, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102407
   Uddin M, 2021, CMC-COMPUT MATER CON, V68, P2377, DOI 10.32604/cmc.2021.015354
   Ugochukwu NA, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10244670
   Wu YQ, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/7270624
   Yuan X, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/9952218
   Zarour M, 2020, IEEE ACCESS, V8, P157959, DOI 10.1109/ACCESS.2020.3019829
   Zheng ZB, 2017, IEEE INT CONGR BIG, P557, DOI 10.1109/BigDataCongress.2017.85
NR 41
TC 0
Z9 0
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 9
PY 2023
DI 10.1007/s11042-023-17548-3
EA NOV 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9MX6
UT WOS:001101620700011
DA 2024-07-18
ER

PT J
AU Lanjewar, MG
   Morajkar, P
   Payaswini, P
AF Lanjewar, Madhusudan G.
   Morajkar, Pranay
   Payaswini, P.
TI Modified transfer learning frameworks to identify potato leaf diseases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE CNN; VGG19; NASNetMobile; DensNet169; Potato diseases; Plant disease
   detection
ID CLASSIFICATION
AB Potato diseases such as early and late blight are the most lethal diseases that can cause significant damage to potato production. Detecting these diseases early and making a precise diagnosis will help the farmers to manage the crop effectively and prevent disease spread. Due to its high accuracy, deep learning, specifically the Deep Convolutional Neural Network (DCNN) models, have gained popularity in image identification and classification. In this research, three transfer learning (TL) pre-trained models, namely VGG19, NASNetMobile, and DensNet169, were modified for detecting potato leaf disease. These models were selected based on their proven robust performance in various computer vision tasks. The performance of these pre-trained models was improved by introducing additional layers to their original architecture, thereby reducing trainable parameters. Furthermore, three state-of-the-art TL models, ResNet50V2, InceptionV3, and Xception, were also trained to detect potato disease and their performance compared with our three modified models. The experiment was conducted on a dataset collected from Kaggle, which was then divided into training, test, and validation sets. The performance of these models was tested with a confusion matrix, Matthew's correlation coefficient (MCC), Cohen's kappa coefficient (CKC), Area Under the Curve (AUC), and ROC (Receiver Operating Characteristics) curve. The modified DenseNet achieved an accuracy of 99%, MCC of 98.5%, CKC of 98.5%, and an AUC-ROC score of 0.990 for the test set, while an accuracy of 100%, MCC of 99.5%, CKC of 99.5%, and AUC-ROC score of 0.997 for the validation set. The modified NasNet and VGG19 achieved an accuracy of 98% and 94%, MCC of 97% and 90.7%, and CKC of 97% and 90.5% for the test set, while an accuracy of 95% and 96%, MCC of 92.7% and 93.6%, CKC of 92.5% and 93.5% for the validation set. The five fold cross-validation method was applied, and overall results showed that the modified DenseNet model outperformed the state-of-the-art TL models.
C1 [Lanjewar, Madhusudan G.] Goa Univ, Sch Phys & Appl Sci, Taleigao Plateau 403206, Goa, India.
   [Morajkar, Pranay] Goa Univ, Sch Chem Sci, Taleigao Plateau 403206, Goa, India.
   [Payaswini, P.] Goa Univ, Goa Business Sch, Comp Sci & Technol Discipline, Taleigao Plateau 403206, Goa, India.
C3 Goa University; Goa University; Goa University
RP Payaswini, P (corresponding author), Goa Univ, Goa Business Sch, Comp Sci & Technol Discipline, Taleigao Plateau 403206, Goa, India.
EM madhusudan@unigoa.ac.in; pranay@unigoa.ac.in; ppayaswini26@gmail.com
OI Lanjewar, Madhusudan/0000-0002-9670-3020
CR Afzaal H, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030411
   Al-Adhaileh MH, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11061516
   Arshaghi A, 2023, MULTIMED TOOLS APPL, V82, P5725, DOI 10.1007/s11042-022-13390-1
   Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412
   Barbedo JGA, 2016, BIOSYST ENG, V147, P104, DOI 10.1016/j.biosystemseng.2016.03.012
   Binyam Tsedaley Binyam Tsedaley, 2014, Journal of Biology, Agriculture and Healthcare, V4, P215
   Chakraborty KK, 2022, PHYSIOL MOL PLANT P, V117, DOI 10.1016/j.pmpp.2021.101781
   Chen WR, 2022, MULTIMED TOOLS APPL, V81, P20797, DOI 10.1007/s11042-022-12620-w
   Chicco D, 2020, BMC GENOMICS, V21, DOI 10.1186/s12864-019-6413-7
   Dai GW, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/6114061
   De Diego IM, 2022, APPL INTELL, V52, P12049, DOI 10.1007/s10489-021-03041-7
   Devaux A, 2022, POTATO RES, V65, P209, DOI 10.1007/s11540-021-09532-x
   Epstein GeraldA., 2005, Financialization and the World Economy, P3, DOI DOI 10.1016/B978-0-08-047378-9.50007-5
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Gikunda Patrick Kinyua, 2019, Intelligent Computing. Proceedings of the 2019 Computing Conference. Advances in Intelligent Systems and Computing (AISC 997), P763, DOI 10.1007/978-3-030-22871-2_53
   Grinblat GL, 2016, COMPUT ELECTRON AGR, V127, P418, DOI 10.1016/j.compag.2016.07.003
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Hassan SKM, 2021, AGRONOMY-BASEL, V11, DOI 10.3390/agronomy11122388
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou CJ, 2021, J AGR FOOD RES, V5, DOI 10.1016/j.jafr.2021.100154
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Islam MdA, 2022, J Adv Math Comput Sci, P143, DOI [10.9734/jamcs/2022/v37i121735, DOI 10.9734/JAMCS/2022/V37I121735]
   kaggle, Potato Leaf Disease Dataset
   Kang FL, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13031487
   Lanjewar MG, 2022, MULTIMED TOOLS APPL, V81, P10313, DOI 10.1007/s11042-022-12200-y
   Lanjewar MG, 2023, EXPERT SYST APPL, V224, DOI 10.1016/j.eswa.2023.119961
   Lanjewar MG, 2023, CLUSTER COMPUT, V26, P3657, DOI 10.1007/s10586-022-03752-7
   Lanjewar MG, 2023, NEURAL COMPUT APPL, V35, P2755, DOI 10.1007/s00521-022-07743-y
   Li LL, 2021, IEEE ACCESS, V9, P56683, DOI 10.1109/ACCESS.2021.3069646
   Liu J, 2021, PLANT METHODS, V17, DOI 10.1186/s13007-021-00722-9
   Mahum R, 2023, HUM ECOL RISK ASSESS, V29, P303, DOI 10.1080/10807039.2022.2064814
   Minhas A, 2022, Value of fresh and chilled potatoes exported from India between financial year 2016 and 2022
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Ngugi LC, 2021, INFORM PROCESS AGR, V8, P27, DOI 10.1016/j.inpa.2020.04.004
   Rashid J, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10172064
   Reddy BS, 2022, MULTIMED TOOLS APPL, V81, P24021, DOI 10.1007/s11042-022-12147-0
   Saleem MH, 2019, PLANTS-BASEL, V8, DOI 10.3390/plants8110468
   Sankaran S, 2010, COMPUT ELECTRON AGR, V72, P1, DOI 10.1016/j.compag.2010.02.007
   Sholihati Rizqi Amaliatus, 2020, 2020 International Electronics Symposium (IES), P392, DOI 10.1109/IES50839.2020.9231784
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh G, 2023, BIOCATAL AGR BIOTECH, V50, DOI 10.1016/j.bcab.2023.102726
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Vishnoi VK, 2022, MULTIMED TOOLS APPL, V81, P367, DOI 10.1007/s11042-021-11375-0
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 45
TC 2
Z9 2
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 6
PY 2023
DI 10.1007/s11042-023-17610-0
EA NOV 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X6AZ8
UT WOS:001099271500012
DA 2024-07-18
ER

PT J
AU Baldoni, S
   Assi, MSHS
   Carli, M
   Battisti, F
AF Baldoni, Sara
   assi, Mohamed Saifeddine Hadj S.
   Carli, Marco
   Battisti, Federica
TI Definition of guidelines for virtual reality application design based on
   visual attention
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Virtual reality; Attention-driven application design; Reaction time
AB In virtual reality applications, head-mounted displays allow users to explore virtual surroundings, thus creating a high sense of immersion. However, due to the novelty of the technology and the possibility of freely enjoying a 360 degrees virtual world, users can get distracted and divert their attention from the content of the application. In this work, we define a set of guidelines for the design of virtual reality applications for enhancing the users' attention. To the best of our knowledge, this is one of the first attempts to provide general guidelines for virtual application design based on visual attention. More specifically, we analyze the different categories of factors that contribute to the user's responsiveness and define a set of experiments for measuring the user's promptness with respect to visual stimuli with different features and in the presence of audio/visual distractions. Experimental tests have been carried out with 36 volunteers. The users' reaction time has been recorded and the performed analysis allowed the definition of a set of guidelines based on individual, operational, and technological factors for the design of virtual reality applications optimized in terms of user attention. In particular, statistical tests demonstrated that the presence of distractions leads to significantly different reaction times with respect to the case of no distractions, and that users belonging to different age intervals have significantly different behaviors. Moreover, the optimal placement of objects has been identified and the impact of cybersickness has been analyzed.
C1 [Baldoni, Sara; Battisti, Federica] Univ Padua, Dept Informat Engn, Via Gradenigo 6-b, I-35131 Padua, Italy.
   [assi, Mohamed Saifeddine Hadj S.; Carli, Marco] Roma Tre Univ, Dept Ind Elect & Mech Engn, Via Vito Volterra 62, I-00146 Rome, Italy.
C3 University of Padua; Roma Tre University
RP Baldoni, S (corresponding author), Univ Padua, Dept Informat Engn, Via Gradenigo 6-b, I-35131 Padua, Italy.
EM sara.baldoni@unipd.it; mohamedsaifeddine.hadjsassi@uniroma3.it;
   marco.carli@uniroma3.it; federica.battisti@unipd.it
OI Baldoni, Sara/0000-0001-5642-3430; HADJ SASSI, MOHAMED
   SAIFEDDINE/0000-0002-6147-6921
FU Universita degli Studi di Padova; European Union [764951]; European
   Union under the Italian National Recovery and Resilience Plan (NRRP) of
   NextGeneration EU, partnership on "Telecommunications of the Future"
   [PE0000001]
FX Open access funding provided by Universita degli Studi di Padova. This
   work was partially fundedby the European Union's Horizon 2020 research
   and innovation program under the Marie Sklodowska-Curie(grant agreement
   No 764951). In addition, it was partially supported by the European
   Union under the Italian National Recovery and Resilience Plan (NRRP) of
   NextGeneration EU, partnership on "Telecommunications of the Future"
   (PE0000001 - program "RESTART").
CR Anthes C., 2016, 2016 IEEE AEROSPACE, P1
   Ashtari N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376722
   Balk S., 2013, SIMULATOR SICKNESS Q, DOI DOI 10.17077/DRIVINGASSESSMENT.1498
   Binsch O, 2023, MULTIMED TOOLS APPL, V82, P17471, DOI 10.1007/s11042-022-14110-5
   Chen Y.C., 2011, BIO Web of Conferences, V1, P00016, DOI DOI 10.1051/BIOCONF/20110100016
   Cohen J., 1992, Psychological Bulletin, V112, P155, DOI [DOI 10.1037/0033-2909.112.1.155, 10.1037//0033-2909.112.1.155, DOI 10.1037//0033-2909.112.1.155, https://doi.org/10.1037/0033-2909.112.1.155]
   Cutting JE, 1997, BEHAV RES METH INS C, V29, P27, DOI 10.3758/BF03200563
   Garcia Fracaro S, 2021, EDUC CHEM ENG, V36, P12, DOI 10.1016/j.ece.2021.01.014
   Gattullo M, 2022, INT SYM MIX AUGMENT, P206, DOI 10.1109/ISMAR55827.2022.00035
   Hadnett-Hunter J, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3352763
   Halabi O, 2022, MULTIMED TOOLS APPL, V81, P32119, DOI 10.1007/s11042-022-12980-3
   Hettinger L J, 1990, Mil Psychol, V2, P171, DOI 10.1207/s15327876mp0203_4
   Hoeg ER, 2017, 2017 IEEE 3RD VR WORKSHOP ON SONIC INTERACTIONS FOR VIRTUAL ENVIRONMENTS (SIVE)
   Huang S, 2018, LECT NOTES COMPUT SC, V10918, P406, DOI 10.1007/978-3-319-91797-9_29
   Jonas M, 2019, CHI PLAY'19: EXTENDED ABSTRACTS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P437, DOI 10.1145/3341215.3356271
   Jones JA, 2013, IEEE T VIS COMPUT GR, V19, P701, DOI 10.1109/TVCG.2013.37
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kuang SB, 2017, COGN NEUROSCI-UK, V8, P126, DOI 10.1080/17588928.2016.1205575
   Langerman D, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286182
   Lee J, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9050078
   Lim PY, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17165989
   Lima ESD, 2022, ENTERTAIN COMPUT, V43, DOI 10.1016/j.entcom.2022.100515
   Matsushima T, 2021, J SOC INF DISPLAY, V29, P221, DOI 10.1002/jsid.980
   Mu M, 2022, MULTIMED TOOLS APPL, DOI 10.1007/s11042-022-13365-2
   NATO Science and Technology Office, 2021, Technical report, NATO. Peer-reviewed Final Report of the Human Factors and Medicine Panel/-Modeling & Simulations Group, Activity Number 323 (NATO STO-TR-HFM-MSG-323
   Oncioiu I, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14074191
   Ortega-Alvarez G, 2023, MULTIMED TOOLS APPL, V82, P573, DOI 10.1007/s11042-022-13271-7
   Owsley C, 2011, VISION RES, V51, P1610, DOI 10.1016/j.visres.2010.10.020
   Panero J., 1979, A Source Book of Design Reference Standards
   Pimentel K., 1994, Virtual reality: through the new looking glass
   Radianti J, 2020, COMPUT EDUC, V147, DOI 10.1016/j.compedu.2019.103778
   Chandra ARN, 2022, COMPUTERS, V11, DOI 10.3390/computers11040051
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Reigal RE, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02278
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Rojas-Sánchez MA, 2023, EDUC INF TECHNOL, V28, P155, DOI 10.1007/s10639-022-11167-5
   Schmidt SL, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02014
   Stauffert JP, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.582204
   Sun XT, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225160
   Swan JE, 2007, IEEE T VIS COMPUT GR, V13, P429, DOI 10.1109/TVCG.2007.1035
   Theodoropoulos A., 2023, Virtual Worlds, V2, P162, DOI [10.3390/virtualworlds2020010, DOI 10.3390/VIRTUALWORLDS2020010]
   Tomczak M., 2014, NEED REPORT EFFECT S, DOI DOI 10.1186/S13054-016-1208-6
   Tun HM, 2018, MOJ Proteom Bioinform, V7, DOI [10.15406/mojpb.2018.07.00223, DOI 10.15406/MOJPB.2018.07.00223]
   Vahle Nils M, 2021, Stud Health Technol Inform, V283, P139, DOI 10.3233/SHTI210552
   Viitanen M, 2018, INT CON DISTR COMP S, P1557, DOI 10.1109/ICDCS.2018.00168
   WENDT HW, 1972, EUR J SOC PSYCHOL, V2, P463, DOI 10.1002/ejsp.2420020412
   Yin J, 2019, INDOOR AIR, V29, P1028, DOI 10.1111/ina.12593
   Zhou XZ, 2023, MULTIMED TOOLS APPL, V82, P15903, DOI 10.1007/s11042-022-14038-w
   Zimmermann P, 2002, APPLIED NEUROPSYCHOLOGY OF ATTENTION: THEORY DIAGNOSIS AND REHABILITATION, P110
NR 49
TC 0
Z9 0
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17488-y
EA NOV 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500008
OA hybrid
DA 2024-07-18
ER

PT J
AU Derbissalova, G
   Shayakhmetova, A
   Avagimyan, A
   Pyanova, E
AF Derbissalova, Gulnaz
   Shayakhmetova, Aisulu
   Avagimyan, Anzhela
   Pyanova, Ekaterina
TI Multimedia applications in special education: new opportunities for the
   developing of cognitive processes of children with intellectual
   disabilities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Intellectual disability; Autism; Cognitive behavioral therapy;
   Multimedia tools; Full scale intelligence quotient test; Randomized
   study
ID SOCIAL-SKILLS; REALITY
AB The purpose of the research was to examine the effectiveness of multimedia tools in special education curriculum. A focus group of 21 children with intellectual disabilities aged 9-10 years was invited to participate in a randomized study. 21 students were selected for the control group, in which the training was carried out without changes. The experiment lasted six months. Prior to the integration of multimedia technologies into the pedagogical process, the learners took the Full-Scale Intelligence Quotient (FSIQ) test. In addition, the students were also tested in the middle and at the end of the study to assess the dynamics. The applications are multifunctional systems, which included cards for communication, various developmental tasks, an organizer and a messenger. After the first month of the experiment, the children's Verbal Comprehension Index (VCI) and Working Memory Index (WMI) indicators have increased by 10% and the Perceptual Reasoning Index (PRI) has improved by 5%. The results of the second month showed an increase in all the three areas by another 5%. Thus, it follows that the VCI and WMI test components have grown by 15% in total, and the PRI score has increased by 10% since the beginning of the experiment. Based on the data obtained in the experiment, it can be concluded that the multimedia resources have been successfully integrated into the education system. The findings can be used as a supplement to basic training of children with intellectual disabilities.
C1 [Derbissalova, Gulnaz] Abai Kazakh Natl Pedag Univ, Dept Profess Training Special Pedag, Alma Ata, Kazakhstan.
   [Shayakhmetova, Aisulu] Sh Ualikhanov Kokshetau Univ, Dept Social & Pedag, Kokshetau, Kazakhstan.
   [Avagimyan, Anzhela] IM Sechenov First Moscow State Med Univ, Dept Nursing Management & Social Work, Moscow, Russia.
   [Pyanova, Ekaterina] Kazan Fed Univ, Elabuga Inst, Dept Psychol, Yelabuga, Russia.
C3 Abai Kazakh National Pedagogical University; Sechenov First Moscow State
   Medical University; Kazan Federal University
RP Derbissalova, G (corresponding author), Abai Kazakh Natl Pedag Univ, Dept Profess Training Special Pedag, Alma Ata, Kazakhstan.
EM derbissalova@rambler.ru
FU Ekaterina Pyanova has been supported by the Kazan Federal University
   Strategic Academic Leadership Program.; Kazan Federal University
   Strategic Academic Leadership Program
FX Ekaterina Pyanova has been supported by the Kazan Federal University
   Strategic Academic Leadership Program.
CR Abakumova NN., 2019, Humanitarian Informatics, V16, P28
   Abd Aziz N, 2021, OCCUP THER HEALTH CA, V35, P227, DOI 10.1080/07380577.2021.1876967
   Abou El-Seoud MS, 2014, 2014 INTERNATIONAL CONFERENCE ON INTERACTIVE COLLABORATIVE LEARNING (ICL), P529, DOI 10.1109/ICL.2014.7017828
   Alemi M, 2019, ASIAN-PAC J SEC FOR, V4, DOI 10.1186/s40862-019-0075-5
   Bowling KM, 2017, GENOME MED, V9, DOI 10.1186/s13073-017-0433-1
   Bross LA, 2021, J SPEC EDUC TECHNOL, V36, P297, DOI 10.1177/0162643420924188
   Burt C, 2022, INT J DISABIL DEV ED, V69, P1273, DOI 10.1080/1034912X.2020.1776849
   Chiurazzi Pietro, 2020, Acta Biomed, V91, pe2020003, DOI 10.23750/abm.v91i13-S.10684
   Demily C, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00010
   Derks S, 2022, BEHAV INFORM TECHNOL, V41, P2988, DOI 10.1080/0144929X.2021.1968034
   des Portes Vincent, 2020, Handb Clin Neurol, V174, P113, DOI 10.1016/B978-0-444-64148-9.00009-0
   Douglas P, 2021, INT J INCLUSIVE EDUC, V25, P605, DOI 10.1080/13603116.2018.1563835
   Fteiha MA, 2017, INT J DEV DISABIL, V63, P36, DOI 10.1080/20473869.2015.1136129
   Grechanyi SV., 2019, Medicine: Theory Practice, V4, P163
   Harris J, 2022, INT J DISABIL DEV ED, V69, P1235, DOI 10.1080/1034912X.2020.1784555
   Jenni OG, 2015, DEV MED CHILD NEUROL, V57, P463, DOI 10.1111/dmcn.12620
   Kang YS, 2021, SYST PRACT ACT RES, V34, P127, DOI 10.1007/s11213-020-09519-8
   Koh C, 2022, INT J DISABIL DEV ED, V69, P919, DOI 10.1080/1034912X.2020.1746245
   Lorenzo G, 2019, EDUC INF TECHNOL, V24, P181, DOI 10.1007/s10639-018-9768-5
   Marrus N, 2017, CHILD ADOL PSYCH CL, V26, P539, DOI 10.1016/j.chc.2017.03.001
   Moskvina VI., 2019, Control Mod Syst, V2, P32
   Osadchaya IV., 2020, Problems Modern Teacher Education, V66, P152
   Ostrander Betsy, 2019, Handb Clin Neurol, V162, P133, DOI 10.1016/B978-0-444-64029-1.00006-0
   Rein B, 2020, NAT PROTOC, V15, P3464, DOI 10.1038/s41596-020-0382-9
   Almeida ICR, 2021, DISABIL REHABIL-ASSI, V16, P340, DOI 10.1080/17483107.2019.1680750
   Sigafoos J, 2021, Adaptive behavior strategies for individuals with intellectual and developmental disabilities, P73, DOI [10.1007/978-3-030-66441-1_4, DOI 10.1007/978-3-030-66441-1_4]
   Sng CY, 2022, INT J DISABIL DEV ED, V69, P415, DOI 10.1080/1034912X.2020.1719045
   Spector JM, 2019, SMART LEARN ENVIRON, V6, DOI 10.1186/s40561-019-0088-z
   Stathopoulou A, 2020, Evaluation of mobile apps effectiveness in children with autism social training via digital social stories
   Valencia K, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204485
   Vavilova OS., 2015, In Situ, V1, P107
   Virnes M, 2015, J SPEC EDUC TECHNOL, V30, P13, DOI 10.1177/016264341503000102
   Vostanis A, 2021, J BEHAV EDUC, V30, P513, DOI 10.1007/s10864-020-09394-2
   Xu WX, 2019, PSYCHIAT DANUB, V31, P340, DOI 10.24869/psyd.2019.340
   Yuan SNV, 2018, LONDON J PRIM CARE, V10, P110, DOI 10.1080/17571472.2018.1483000
   Zavadenko N. N., 2015, Rossiiskii Vestnik Perinatologii i Pediatrii, V60, P14
   Zhang SD, 2019, INT J DEV DISABIL, V65, P378, DOI 10.1080/20473869.2019.1656384
NR 37
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17512-1
EA NOV 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500016
DA 2024-07-18
ER

PT J
AU González-Santos, C
   Vega-Rodríguez, MA
   López-Munoz, JM
   Martínez-Sarriegui, I
   Pérez, CJ
AF Gonzalez-Santos, Carlos
   Vega-Rodriguez, Miguel A.
   Lopez-Munoz, Joaquin M.
   Martinez-Sarriegui, Inaki
   Perez, Carlos J.
TI Automatic assignment of microgenres to movies using a word
   embedding-based approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Movie microgenre; Word embedding; Semantic similarity; Clustering; Topic
   modeling; Activation function
AB Streaming services are increasingly leveraging Artificial Intelligence (AI) technologies for improved content cataloging, user experiences in content discovery, and personalization. A significant challenge in this domain is the automated assignment of microgenres to movies. This study introduces and evaluates approaches based on clustering, topic modeling, and word embedding to address this task. The evaluation employs a preprocessed dataset containing movie-related data-title tags, synopses, genres, and reviews-alongside a predefined microgenre list. Comparisons of three activation functions (binary step, ramp, and sigmoid) gauge their effectiveness in augmenting microgenre tags. Results demonstrate the superiority of the word embedding approach over clustering and topic modeling in terms of mean accuracy. Even more, the word embedding approach stands as the sole fully automated solution. Analysis indicates that incorporating review-based tags introduces noise and undermines accuracy. Besides, the word embedding approach yields optimal outcomes using the sigmoid function, effectively doubling assigned tags while maintaining matching quality. This sheds light on the potential of word embedding methods within the movie domain.
C1 [Gonzalez-Santos, Carlos; Perez, Carlos J.] Univ Extremadura, Dept Matemat, Campus Univ s-n, Caceres 10003, Spain.
   [Vega-Rodriguez, Miguel A.] Univ Extremadura, Dept Tecnol Comp & Comunicac, Campus Univ s-n, Caceres 10003, Spain.
   [Lopez-Munoz, Joaquin M.; Martinez-Sarriegui, Inaki] Consultora Telecomunicac Opt Media SL, Res & Innovat Area, Musgo 2-Edificio Europa 2, Madrid 28023, Spain.
   [Martinez-Sarriegui, Inaki] Metadatol SL, Res & Dev Dept, Santa Cristina 3-Edificio Garaje 2-0, Caceres 10195, Spain.
C3 Universidad de Extremadura; Universidad de Extremadura
RP Vega-Rodríguez, MA (corresponding author), Univ Extremadura, Dept Tecnol Comp & Comunicac, Campus Univ s-n, Caceres 10003, Spain.
EM carlosgs@unex.es; mavega@unex.es; joaquin.lopez@optivamedia.com;
   inaki.martinez@metadatol.com; carper@unex.es
RI Martínez-Sarriegui, Iñaki/AFE-2629-2022; Vega-Rodriguez, Miguel
   A./I-3626-2015
OI Martínez-Sarriegui, Iñaki/0000-0002-2298-1407; Vega-Rodriguez, Miguel
   A./0000-0002-3003-758X
FU We are thankful to Optiva Media and Metadatol for providing the data
   necessary to conduct this study. This research has been supported by
   Ministry of Science, Innovation, and Universities - Spain and State
   Research Agency - Spain (Projects PID2019-107299GB; Ministry of Science,
   Innovation; Universities - Spain [PID2019-107299GB-I00,
   PID2021-122209OB-C32, MCIN/AEI/10.13039/501100011033]; State Research
   Agency - Spain [IDA3-19-0001-3, GR21017, GR21057]; Junta de Extremadura
   - Spain; European Union (European Regional Development Fund)
FX We are thankful to Optiva Media and Metadatol for providing the data
   necessary to conduct this study. This research has been supported by
   Ministry of Science, Innovation, and Universities - Spain and State
   Research Agency - Spain (Projects PID2019-107299GB-I00 and
   PID2021-122209OB-C32 funded by MCIN/AEI/10.13039/501100011033), Junta de
   Extremadura - Spain (Projects IDA3-19-0001-3, GR21017, and GR21057), and
   European Union (European Regional Development Fund).
CR Abdelrazek A, 2023, INFORM SYST, V112, DOI 10.1016/j.is.2022.102131
   Ahmed MH, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13010342
   Ahmed M, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9081295
   Birunda S. Selva, 2021, Innovative Data Communication Technologies and Application. Proceedings of ICIDCA 2020. Lecture Notes on Data Engineering and Communications Technologies (LNDECT 59), P267, DOI 10.1007/978-981-15-9651-3_23
   Bizzocchi J, 2020, Dig Stud/Le champ, V10, DOI [10.16995/dscn.376, DOI 10.16995/DSCN.376]
   Chauhan U, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3462478
   Devine P, 2022, 2022 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON NATURAL LANGUAGE-BASED SOFTWARE ENGINEERING (NLBSE 2022), P1, DOI 10.1145/3528588.3528652
   Guehria S, 2020, INT C INT SYST DES A, P478, DOI [10.1007/978-3-030-71187-0_44, DOI 10.1007/978-3-030-71187-0_44]
   Khan UA, 2020, IEEE ACCESS, V8, P6071, DOI 10.1109/ACCESS.2019.2963535
   Kundalia K., 2020, AUGMENT HUM RES, V5, P11, DOI [DOI 10.1007/S41133-019-0029-Y, 10.1007/s41133-019-0029-y]
   Mangolin RB, 2022, MULTIMED TOOLS APPL, V81, P19071, DOI 10.1007/s11042-020-10086-2
   McCallum AK, 2021, MALLET: a machine learning for language toolkit
   Mikolov T, 2013, P WORKSHOP ICLR 2013
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Nomoto Tadashi, 2023, SN Comput Sci, V4, P92, DOI 10.1007/s42979-022-01481-7
   Quintanilla E, 2021, IEEE T MULTIMEDIA, V23, P1083, DOI 10.1109/TMM.2020.2992941
   Ramadhani Fanny, 2020, IOP Conference Series: Materials Science and Engineering, V725, DOI 10.1088/1757-899X/725/1/012090
   Stevens AH., 2020, Bloomsbury Academic, New York, DOI [10.5040/9781501345845, DOI 10.5040/9781501345845]
   Ullah I, 2023, MULTIMED TOOLS APPL, V82, P6431, DOI 10.1007/s11042-022-13417-7
   Wang B, 2019, APSIPA TRANS SIGNAL, V8, DOI 10.1017/ATSIP.2019.12
   Wang CT, 2021, IEEE ACCESS, V9, P66509, DOI 10.1109/ACCESS.2021.3077059
   Wu CR, 2020, MULTIMED TOOLS APPL, V79, P11399, DOI 10.1007/s11042-019-08513-0
   Xia CY, 2019, 2019 COMPANION OF THE 19TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, RELIABILITY AND SECURITY (QRS-C 2019), P354, DOI 10.1109/QRS-C.2019.00072
   Yu YT, 2021, MULTIMED TOOLS APPL, V80, P9749, DOI 10.1007/s11042-020-10125-y
   Zhang Y, 2020, 2020 3RD INTERNATIONAL CONFERENCE ON BIG DATA AND EDUCATION (ICBDE 2020), P37, DOI 10.1145/3396452.3396460
NR 25
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17442-y
EA NOV 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500003
OA hybrid
DA 2024-07-18
ER

PT J
AU Riaz, T
   Javed, A
   Alhazmi, M
   Tahir, A
   Ashraf, R
AF Riaz, Tanees
   Javed, Ali
   Alhazmi, Majed
   Tahir, Ali
   Ashraf, Rehan
TI Shuffle SwishNet-181: COVID-19 diagnostic framework using ECG images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE COVID-19 detection; Cardiovascular patients; ECG; Shuffle SwishNet-181
AB Early and precise detection of COVID-19 holds significant benefits, particularly in facilitating the prompt isolation of infected individuals and helping to control the spread of this disease as vaccinated persons also got infected from COVID-19. The research community has explored various COVID-19 diagnostic tools operated on different imaging modalities like X-rays and CT scans apart from conventional PCR testing which often takes several hours to get the results. Existing studies on ECG-based COVID-19 diagnostics are limited even though this modality is quickly available as compared to CT scans and X-rays. Moreover, our preliminary analysis suggests that ECG images can also be used to study the correlation of COVID-19 with cardio diseases, which is not possible in the case of X-rays and CT scans. Moreover, current ECG-based COVID-19 diagnostics approaches often report an issue of low detection accuracy and focus more on binary classification. To overcome these challenges, we developed an effective COVID-19 diagnostic tool by proposing a novel Shuffle SwishNet-181 deep learning-based model. During the pre-processing, the background is subtracted from the signals and combined these signals in a hexaxial way. Shuffle SwishNet-181 extracts the distinctive deep features and accurately classifies the ECG images into COVID-19, normal, myocardial infarction (MI), abnormal heartbeat patients (HB), and patients who have a history of myocardial infarction (PMI). Moreover, the Score-cam technique is employed to visualize the working of the proposed model by showing the top priority features extracted by the Shuffle SwishNet-181 model. The rigorous experimentation is performed on a publicly available ECG imaging dataset to demonstrate the effectiveness of the COVID-19 diagnostic framework. The proposed model achieved an accuracy of 99% in the case of COVID-19 vs. Normal, 99.4% in the case of COVID-19 vs. MI, 98.8% in the case of COVID-19 vs. HB, and 98.7% in the case of COVID-19 vs. PMI. For multiclass classification, the proposed model achieved 91.6% accuracy. Experimental results show the reliability of the method for binary and multi-class classification of COVID-19. Explainability analysis proved that the proposed model precisely focuses on salient features for classification.
C1 [Riaz, Tanees; Javed, Ali] Univ Engn & Technol, Dept Software Engn, Taxila 47050, Pakistan.
   [Alhazmi, Majed; Tahir, Ali] Jazan Univ, Coll Comp Sci & Informat Technol, Jazan 45142, Saudi Arabia.
   [Ashraf, Rehan] Natl Text Univ, Dept Comp Sci, Faisalabad, Pakistan.
C3 University of Engineering & Technology Taxila; Jazan University;
   National Textile University - Pakistan
RP Ashraf, R (corresponding author), Natl Text Univ, Dept Comp Sci, Faisalabad, Pakistan.
EM rehan@ntu.edu.pk
RI JAVED, ALI/X-3334-2019
OI Ashraf, Rehan/0000-0002-6627-9820
FU The authors would like to thank the Multimedia Signal Processing (MSP)
   research lab at UET-Taxila for providing the lab resources to conduct
   this research.
FX The authors would like to thank the Multimedia Signal Processing (MSP)
   research lab at UET-Taxila for providing the lab resources to conduct
   this research.
CR Acharya UR, 2019, APPL INTELL, V49, P16, DOI 10.1007/s10489-018-1179-1
   Amzat J, 2020, INT J INFECT DIS, V98, P218, DOI 10.1016/j.ijid.2020.06.067
   Angeli F, 2020, EUR J INTERN MED, V78, P101, DOI 10.1016/j.ejim.2020.06.015
   Anwar Talha, 2021, Proceedings of 2021 International Conference on Artificial Intelligence (ICAI), P182, DOI 10.1109/ICAI52203.2021.9445258
   Arias-Garzón D, 2021, MACH LEARN APPL, V6, DOI 10.1016/j.mlwa.2021.100138
   Attallah O, 2022, COMPUT BIOL MED, V142, DOI 10.1016/j.compbiomed.2022.105210
   Barman HA, 2021, AM J EMERG MED, V46, P317, DOI 10.1016/j.ajem.2020.10.005
   Chowdhury MR, 2021, J PURE APPL MICROBIO, V15, P500, DOI 10.22207/JPAM.15.2.14
   Crawford J., 2012, PRACTICAL ASPECTS EC
   López-Cabrera JD, 2021, HEALTH TECHNOL-GER, V11, P411, DOI 10.1007/s12553-021-00520-2
   Dey N., 2022, Comput Biol Med, V130
   Ece I, 2021, PEDIATR CARDIOL, V42, P264, DOI 10.1007/s00246-020-02474-0
   ECGwave.com, 2022, ECG and Echo learning
   Hussain E, 2021, CHAOS SOLITON FRACT, V142, DOI 10.1016/j.chaos.2020.110495
   Kaliyaperumal D, 2022, INDIAN J CRIT CARE M, V26, P43, DOI 10.5005/jp-journals-10071-24045
   Khan AH, 2021, DATA BRIEF, V34, DOI 10.1016/j.dib.2021.106762
   Li Y, 2020, ANN NONINVAS ELECTRO, V25, DOI 10.1111/anec.12805
   Mangal A, 2020, Arxiv, DOI arXiv:2004.09803
   Nate Hafer, 2021, The Conversation, V9, P8
   Ozdemir MA, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01521-x
   Pavri BB, 2020, HEART RHYTHM, V17, P1434, DOI 10.1016/j.hrthm.2020.06.009
   Rafie N., 2021, HEARTS, V2, P505, DOI [10.3390/hearts2040039, DOI 10.3390/HEARTS2040039]
   Rahman T, 2022, HEALTH INF SCI SYST, V10, DOI 10.1007/s13755-021-00169-1
   Sakr AS, 2023, INFORM SCIENCES, V619, P324, DOI 10.1016/j.ins.2022.11.069
   Struyf T, 2020, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD013665
   Wang LJ, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-61138-4
   Wong HYF, 2020, RADIOLOGY, V296, pE72, DOI 10.1148/radiol.2020201160
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao DH, 2020, CLIN INFECT DIS, V71, P756, DOI 10.1093/cid/ciaa247
NR 29
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 2
PY 2023
DI 10.1007/s11042-023-17579-w
EA NOV 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X1LQ6
UT WOS:001096134900007
DA 2024-07-18
ER

PT J
AU Demiroglu, U
   Senol, B
   Matusu, R
AF Demiroglu, Ugur
   Senol, Bilal
   Matusu, Radek
TI A fused electrocardiography arrhythmia detection method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE ECG; Biomedical signal processing and analysis; Arrhythmia detection;
   Hamsi-Pat; PSO; TQWT; INCA feature selection; Artificial intelligence;
   Machine learning
ID PARTICLE SWARM OPTIMIZATION; ECG BEAT CLASSIFICATION;
   FEATURE-EXTRACTION; WAVELET TRANSFORM; INTEGRATION
AB Recently, Electrocardiography (ECG) signals are commonly used in diagnosing the cardiac arrhythmia that shows up with the loss of the regular movement of the heart. Approximately 5% of the world population have cardio motor disorders. Therefore, usage of the ECG signals in biomedical signal processing algorithms and machine learning methods for automated diagnosis of this widespread health problem is a popular research topic. In this paper, the Particle Swarm Optimization (PSO) technique is implemented to tune the parameters of Tunable Q-Factor Wavelet Transform (TQWT) and the new generation feature generator Hamsi Hash Function (Hamsi-Pat) is used to obtain the characteristics of the signal. Sub-signals of 10 s obtained from the original ECG signal are divided into their sub-bands of 25 levels with PSO and TQWT. Each of these low pass filters generates 536 dimensional features by applying Hamsi-Pat and statistical methods. Then, all these features are combined and 536 x 25 = 13400-dimensional feature set is obtained. The features in the set are reduced and the best of them are selected by using the Iterative Neighborhood Component Analysis (INCA) method. Finally, the k-Nearest Neighbors (kNN) classification method is applied to the best features according to the City Block measurement criterion. All studies cited to compare the results in this paper also use the MIT-BIH Arrhythmia ECG database. Hence, the difference could be observed in the used techniques. In contrast to the existing studies, this study shows its superior performance by classifying all 17 classes simultaneously by applying a "fused" approach. The method in the paper reached 98.5% classification accuracy on the 17 classes of the MIT-BIH Arrhythmia ECG database. The results indicate that the proposed method showed better rates from the existing studies related to arrhythmia diagnosis using ECG signals in the literature.
C1 [Demiroglu, Ugur] Firat Univ, Tech Vocat Sch, Comp Sci Dept, Elazig, Turkiye.
   [Senol, Bilal] Aksaray Univ, Fac Engn, Software Engn Dept, Aksaray, Turkiye.
   [Matusu, Radek] Tomas Bata Univ Zlin, Fac Appl Informat, Ctr Secur Informat & Adv Technol CEBIA Tech, Zlin, Czech Republic.
C3 Firat University; Aksaray University; Tomas Bata University Zlin
RP Senol, B (corresponding author), Aksaray Univ, Fac Engn, Software Engn Dept, Aksaray, Turkiye.
EM bilal.senol@aksaray.edu.tr
RI Matušů, Radek/HPH-8692-2023; SENOL, Bilal/Y-5328-2018
OI SENOL, Bilal/0000-0002-3734-8807
CR Acharya UR, 2017, INFORM SCIENCES, V405, P81, DOI 10.1016/j.ins.2017.04.012
   Acir N, 2005, NEURAL COMPUT APPL, V14, P299, DOI 10.1007/s00521-005-0466-z
   Al Rahhal MM, 2016, INFORM SCIENCES, V345, P340, DOI 10.1016/j.ins.2016.01.082
   Alickovic E, 2015, CIRC SYST SIGNAL PR, V34, P513, DOI 10.1007/s00034-014-9864-8
   Alqudah AM, 2022, SOFT COMPUT, V26, P1123, DOI 10.1007/s00500-021-06555-x
   [Anonymous], 2011, J. Biomed. Sci. Eng.
   Benmessaoud AS, 2023, 2023 IEEE INT C OMN, P1, DOI [10.1109/COINS57856.2023.10189299, DOI 10.1109/COINS57856.2023.10189299]
   Bhukya R, 2023, INT J SYST ASSUR ENG, DOI 10.1007/s13198-023-02035-7
   Carrera D, 2019, PATTERN RECOGN, V88, P482, DOI 10.1016/j.patcog.2018.11.019
   del Valle Y, 2008, IEEE T EVOLUT COMPUT, V12, P171, DOI 10.1109/TEVC.2007.896686
   Hammad M, 2022, COMPUT ELECTR ENG, V100, DOI 10.1016/j.compeleceng.2022.108011
   Javadi M, 2013, BIOMED SIGNAL PROCES, V8, P289, DOI 10.1016/j.bspc.2012.10.005
   Karimifard S, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-22
   Kiranyaz S, 2016, IEEE T BIO-MED ENG, V63, P664, DOI 10.1109/TBME.2015.2468589
   Marini F, 2015, CHEMOMETR INTELL LAB, V149, P153, DOI 10.1016/j.chemolab.2015.08.020
   Martis RJ, 2011, IEEE ENG MED BIO, P1697, DOI 10.1109/IEMBS.2011.6090487
   Mi F, 2023, 2023 INT C INT SUP B, P72, DOI [10.1109/ISBP57705.2023.10061303, DOI 10.1109/ISBP57705.2023.10061303]
   Mohonta SC, 2022, SENS BIO-SENS RES, V37, DOI 10.1016/j.sbsr.2022.100502
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Osowski S, 2004, IEEE T BIO-MED ENG, V51, P582, DOI 10.1109/TBME.2004.824138
   Özbay Y, 2011, EXPERT SYST APPL, V38, P1004, DOI 10.1016/j.eswa.2010.07.118
   Plawiak P, 2020, NEURAL COMPUT APPL, V32, P11137, DOI 10.1007/s00521-018-03980-2
   Plawiak P, 2018, EXPERT SYST APPL, V92, P334, DOI 10.1016/j.eswa.2017.09.022
   Sahoo S, 2017, MEASUREMENT, V108, P55, DOI 10.1016/j.measurement.2017.05.022
   Sayadi O, 2010, IEEE T BIO-MED ENG, V57, P353, DOI 10.1109/TBME.2009.2031243
   Selesnick IW, 2011, IEEE T SIGNAL PROCES, V59, P3560, DOI 10.1109/TSP.2011.2143711
   Shen CP, 2012, EXPERT SYST APPL, V39, P7845, DOI 10.1016/j.eswa.2012.01.093
   Tufenkci S, 2019, 2019 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND DATA PROCESSING (IDAP 2019), DOI 10.1109/idap.2019.8875931
   Tuncer T, 2021, APPL ACOUST, V172, DOI 10.1016/j.apacoust.2020.107607
   Tuncer T, 2020, IEEE ACCESS, V8, P84532, DOI 10.1109/ACCESS.2020.2992641
   Tuncer T, 2019, KNOWL-BASED SYST, V186, DOI 10.1016/j.knosys.2019.104923
   Übeyli ED, 2009, EXPERT SYST APPL, V36, P8758, DOI 10.1016/j.eswa.2008.11.015
   Wang D, 2018, IEEE T NEUR NET LEAR, V29, P3140, DOI 10.1109/TNNLS.2017.2712823
   Wang HC, 2014, MECH SYST SIGNAL PR, V48, P103, DOI 10.1016/j.ymssp.2014.04.006
   Wang KK, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107211
   Yan W, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/1819112
   Yang JL, 2018, INT J MACH LEARN CYB, V9, P1733, DOI 10.1007/s13042-017-0677-5
   Yildirim Ö, 2018, COMPUT BIOL MED, V102, P411, DOI 10.1016/j.compbiomed.2018.09.009
   Yu SN, 2008, EXPERT SYST APPL, V34, P2841, DOI 10.1016/j.eswa.2007.05.006
   Zhang SC, 2020, NEUROCOMPUTING, V391, P234, DOI 10.1016/j.neucom.2018.11.101
   Zidelmal Z, 2013, COMPUT METH PROG BIO, V111, P570, DOI 10.1016/j.cmpb.2013.05.011
NR 41
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 27
PY 2023
DI 10.1007/s11042-023-17410-6
EA OCT 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0GO3
UT WOS:001088502300002
DA 2024-07-18
ER

PT J
AU Pandey, S
   Behl, R
   Sinha, A
AF Pandey, Sachi
   Behl, Ritin
   Sinha, Amit
TI Decentralized blockchain-based security enhancement with lamport merkle
   digital signature generation and optimized encryption in cloud
   environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Security; Decentralized Blockchain; Encryption; Decryption; Key
   generation; Optimization; Key exchange; Cloud environment
ID STORAGE
AB Nowadays, data storage in a cloud environment plays an important role in managing large scale information. However, the main problem with using a cloud environment is data security. Various encryption approaches are introduced in the existing works to provide security. However, the security issues are not resolved. This paper presented a good security enhancement with decentralized blockchain and enhanced encryption approaches. Initially, the Lamport Merkle Digital Signature Generation based blockchain approach was developed to authenticate the user data to prevent unauthorized access. This presented approach authenticates cloud users by constructing a tree, in which the leaves symbolize the hash function of sensitive user data. Then in the encryption phase, the original data is encrypted as ciphertext utilizing Optimized Elliptic curve cryptography. Here, the Collective Decision optimization approach is utilized for optimal key selection. Furthermore, the selected optimal secret key is exchanged securely utilizing the Improved Diffie-Hellman approach. The presented blockchain-based security scheme enhances data security and ensures confidential data sharing between users. The experimental results of the presented approach are examined in terms of different performance metrics. The performance analysis of the presented approach outperforms the different existing approaches.
C1 [Pandey, Sachi; Behl, Ritin] SRM Inst Sci & Technol, Dept Comp Sci & Engn, NCR Campus, Modinagar 201204, Uttar Pradesh, India.
   [Sinha, Amit] ABES Engn Coll, Dept Informat Technol, Ghaziabad 201009, Uttar Pradesh, India.
C3 SRM Institute of Science & Technology Delhi NCR (Ghaziabad)
RP Pandey, S (corresponding author), SRM Inst Sci & Technol, Dept Comp Sci & Engn, NCR Campus, Modinagar 201204, Uttar Pradesh, India.
EM sachipas@srmist.edu.in; rb1083@srmist.edu.in
CR Ahmed I., 2019, TELKOMNIKA, V17, P2812, DOI [DOI 10.12928/TELKOMNIKA.V17I6.12490, 10.12928/telkomnika.v17i6.12490]
   Bai CA, 2019, BUS STRATEG ENVIRON, DOI 10.1002/bse.2431
   Buyya R, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3241737
   Chaudhary S, 2020, Perfor Manag Integr Syst Applic Softw, P127
   Dubey SK, 2017, Cluster, grid, cloud and parallel distributed computing: an overview with comparison, V8, P152
   Eltayieb N, 2020, J SYST ARCHITECT, V102, DOI 10.1016/j.sysarc.2019.101653
   Indira N, 2021, J AMB INTEL HUM COMP, V12, P4643, DOI 10.1007/s12652-020-01860-z
   Kaur H., 2020, IJRAR-Int. J. Res. Anal. Rev. (IJRAR), V7, P916
   Kukreja S, 2018, ADV INTELL SYST COMP, V563, P593, DOI 10.1007/978-981-10-6872-0_57
   Kumar PR, 2018, PROCEDIA COMPUT SCI, V125, P691, DOI 10.1016/j.procs.2017.12.089
   Kumar Y. Kiran, 2020, Int J Electr Comput Eng, V10, P530
   Liu TL, 2023, CONCURR COMP-PRACT E, V35, DOI 10.1002/cpe.6383
   Malik A, 2020, INT J KNOWL SYST SCI, V11, P65, DOI 10.4018/IJKSS.2020100105
   Mansouri N, 2021, J SUPERCOMPUT, V77, P5882, DOI 10.1007/s11227-020-03497-3
   Murthy CVNUB, 2020, IEEE ACCESS, V8, P205190, DOI 10.1109/ACCESS.2020.3036812
   Rathee T, 2021, PEER PEER NETW APPL, V14, P3851, DOI 10.1007/s12083-021-01212-4
   Shen M, 2020, IEEE J SEL AREA COMM, V38, P1229, DOI 10.1109/JSAC.2020.2986619
   Shyla SI, 2022, J Ambient Intell Humanized Comput, P1
   Srivastava P., 2018, Int. J. Adv. Res. Comput. Sci. Softw. Eng, V8, P17, DOI [DOI 10.23956/IJARCSSE.V8I6.711, 10.23956/ijarcsse.v8i6.711]
   Subramanian N, 2018, COMPUT ELECTR ENG, V71, P28, DOI 10.1016/j.compeleceng.2018.06.006
   Sunyaev A., 2020, Cloud computing, P195, DOI DOI 10.1007/978-3-030-34957-8
   Tahir M, 2021, CLUSTER COMPUT, V24, P739, DOI 10.1007/s10586-020-03157-4
   Varghese B, 2018, FUTURE GENER COMP SY, V79, P849, DOI 10.1016/j.future.2017.09.020
   Velmurugadass P, 2021, MATER TODAY-PROC, V37, P2653, DOI 10.1016/j.matpr.2020.08.519
   Wang H, 2020, INFORM SCIENCES, V519, P348, DOI 10.1016/j.ins.2020.01.051
   [王继业 Wang Jiye], 2017, [计算机研究与发展, Journal of Computer Research and Development], V54, P742
   Yang Z, 2021, ADV COMPUT, V120, P195, DOI 10.1016/bs.adcom.2020.09.004
NR 27
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 26
PY 2023
DI 10.1007/s11042-023-17365-8
EA OCT 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2WU9
UT WOS:001090292500002
DA 2024-07-18
ER

PT J
AU Qi, PY
   Yin, GS
   Zhang, LG
AF Qi, Pengyuan
   Yin, Guisheng
   Zhang, Liguo
TI Underwater acoustic target recognition using RCRNN and wavelet-auditory
   feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Underwater acoustic; Neural network; Wavelet-auditory feature; ShipsEar
ID DEEP NEURAL-NETWORKS
AB Underwater acoustic target recognition plays an essential role in sonar signal processing. Despite numerous efforts in target recognition, it remains a challenging task due to the complex nature of the underwater environment. Specifically, the overlapping acoustic feature of different target classes, coupled with the temporal-spatial variation characteristic of the marine environment, results in reduced recognition performance. This paper introduces a novel approach to address these challenges, which emphasizes the acquisition of fine-grained feature parameters and achieving high-precision classification results. Firstly, we develop a wavelet-auditory feature that comprehensively represents the underwater acoustic signal. The feature describes the time-frequency auditory information and reduces the dimensionality of the original signal. Secondly, a convolutional recurrent neural network with residual blocks module is designed, which enables the extraction of more discriminative global deep features from the wavelet-auditory feature. The network addresses the effects of time-varying and time-dependent nonuniform underwater environments. Finally, we conduct experiments on the ShipsEar database to evaluate the proposed method. Experimental results demonstrate that our method outperforms other classification methods in terms of recognition accuracy. Furthermore, the efficacity of each method component has been demonstrated via ablation studies, demonstrating that the proposed method is a significant initiative and contribution to the underwater acoustic target recognition task.
C1 [Qi, Pengyuan; Yin, Guisheng; Zhang, Liguo] Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Peoples R China.
C3 Harbin Engineering University
RP Zhang, LG (corresponding author), Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Peoples R China.
EM zhangliguo@hrbeu.edu.cn
RI LIGUO, ZHANG/AAC-8765-2021
FU This work was supported by Science and Technology on Sonar Laboratory
   Fund "Intelligent underwater acoustic target recognition technology
   based on auditory perception characteristics" (6142109KF2206).
   [6142109KF2206]; Science and Technology on Sonar Laboratory Fund
FX This work was supported by Science and Technology on Sonar Laboratory
   Fund "Intelligent underwater acoustic target recognition technology
   based on auditory perception characteristics" (6142109KF2206).
CR Arveson PT, 2000, J ACOUST SOC AM, V107, P118, DOI 10.1121/1.428344
   Bahmei B, 2022, IEEE SIGNAL PROC LET, V29, P682, DOI 10.1109/LSP.2022.3150258
   Biernacki C, 2000, IEEE T PATTERN ANAL, V22, P719, DOI 10.1109/34.865189
   Biswas M, 2023, MULTIMED TOOLS APPL, V82, P9565, DOI 10.1007/s11042-021-11439-1
   Bonet-Solà D, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041274
   Çakir E, 2017, IEEE-ACM T AUDIO SPE, V25, P1291, DOI 10.1109/TASLP.2017.2690575
   DiMartino JC, 1996, PATTERN RECOGN LETT, V17, P37, DOI 10.1016/0167-8655(95)00088-7
   Fernandes RP, 2020, P S BRAS TEL PROC SI
   Filho WS, 2011, IET RADAR SONAR NAV, V5, P605, DOI 10.1049/iet-rsn.2010.0157
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hjelmervik KT, 2020, OCEANS-IEEE, DOI 10.1109/IEEECONF38699.2020.9389044
   Hong F, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11041442
   Jian L, 2014, ADV INTEL SYS RES, V113, P79
   KALAYCI T, 1995, IEEE ENG MED BIOL, V14, P160, DOI 10.1109/51.376754
   Kamal S, 2021, DEFENCE SCI J, V71, P117, DOI 10.14429/dsj.71.14929
   Khishe M, 2022, IEEE J OCEANIC ENG, V47, P1083, DOI 10.1109/JOE.2022.3180764
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li P, 2022, J MAR SCI ENG, V10, DOI 10.3390/jmse10101428
   Li SC, 2020, APPL ACOUST, V164, DOI 10.1016/j.apacoust.2020.107248
   Li XX, 2007, 2008 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND SIGNAL PROCESSING, VOLS 1 AND 2, P400
   Li YX, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/8092706
   Liu F, 2021, APPL ACOUST, V178, DOI 10.1016/j.apacoust.2021.107989
   Luo XW, 2021, J MAR SCI ENG, V9, DOI 10.3390/jmse9111246
   Luo XW, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185399
   Miao YC, 2021, IEEE J OCEANIC ENG, V46, P952, DOI 10.1109/JOE.2020.3039037
   Moniruzzaman M, 2017, LECT NOTES COMPUT SC, V10617, P150, DOI 10.1007/978-3-319-70353-4_13
   Najafzadeh M, 2015, OCEAN ENG, V99, P85, DOI 10.1016/j.oceaneng.2015.01.014
   Patnaik S, 2023, MULTIMED TOOLS APPL, V82, P11897, DOI 10.1007/s11042-022-13725-y
   Peng Yuan, 2006, Acta Acustica, V31, P146
   Perotin L, 2019, IEEE J-STSP, V13, P22, DOI 10.1109/JSTSP.2019.2900164
   Puttagunta M, 2021, MULTIMED TOOLS APPL, V80, P24365, DOI 10.1007/s11042-021-10707-4
   Qiao WB, 2021, OCEAN ENG, V219, DOI 10.1016/j.oceaneng.2020.108415
   Qingxin Meng, 2015, Journal of the Acoustical Society of America, V137, DOI 10.1121/1.4920186
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Santos-Domínguez D, 2016, APPL ACOUST, V113, P64, DOI 10.1016/j.apacoust.2016.06.008
   Shi GZ, 2008, 2008 INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, VOLS 1-4, P835, DOI 10.1109/ICINFA.2008.4608114
   Sildam J, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/298038
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun QG, 2022, J ACOUST SOC AM, V151, P2245, DOI 10.1121/10.0009852
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   TANSEL IN, 1995, INT J MACH TOOL MANU, V35, P1137
   Testolin A, 2022, IEEE T MOBILE COMPUT, V21, P2776, DOI 10.1109/TMC.2020.3044397
   Doan VS, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3029584
   Wang MF, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12105233
   Wang W, 2016, 2016 IEEE OES CHINA, P1
   Williams DP, 2021, IEEE J OCEANIC ENG, V46, P236, DOI 10.1109/JOE.2019.2963041
   Wu H, 2018, PROCEEDINGS OF 2018 THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ARTIFICIAL INTELLIGENCE (CSAI 2018) / 2018 THE 10TH INTERNATIONAL CONFERENCE ON INFORMATION AND MULTIMEDIA TECHNOLOGY (ICIMT 2018), P385, DOI 10.1145/3297156.3297180
   Wu Y, 2014, OCEANS 2014 TAIPEI, P1
   Xiaodong Sun, 2020, ICRAI 2020: 2020 6th International Conference on Robotics and Artificial Intelligence, P41, DOI 10.1145/3449301.3449309
   Yang HH, 2016, INT BHURBAN C APPL S, P522, DOI 10.1109/IBCAST.2016.7429928
   Zhang Q, 2021, APPL ACOUST, V182, DOI 10.1016/j.apacoust.2021.108261
   Zhang Wen, 2022, 2022 8th International Conference on Big Data and Information Analytics (BigDIA), P342, DOI 10.1109/BigDIA56350.2022.9874151
NR 54
TC 0
Z9 0
U1 17
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 26
PY 2023
DI 10.1007/s11042-023-17406-2
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2WU9
UT WOS:001090292500008
DA 2024-07-18
ER

PT J
AU Gheytasi, F
   Yaghoubyan, SH
   Rezaei, Z
   Bagherifard, K
   Parvin, H
AF Gheytasi, Farshad
   Yaghoubyan, S. Hadi
   Rezaei, Zahra
   Bagherifard, Karamollah
   Parvin, Hamid
TI Spectral clustering based on extended deep ensemble auto encoder with
   eagle strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Spectral Clustering; Deep Learning; Auto Encoder; Eagle Strategy
ID LARGE-SCALE; ALGORITHM
AB As an exploratory data analysis (EDA) process, spectral clustering (SC) reduces complex, multidimensional data sets to similar ones in rarer dimensions. Given the big challenges of high computational complexity and lack of accurate mapping in multidimensional data sets, it is essential to provide innovative solutions for SC. Against this background, the present study aims to propose a novel method based on extended Deep learning (DL), recruiting autoencoder (AE) ensembles. Here, the eagle strategy (ES) is further applied, rather than the anchor-based and landmark ones, to eliminate some complexities in SC and fill gaps in data training. As SC has a stochastic optimization structure, the ES may seem appropriate. The Fundamental Clustering and Projection Suite (FCPS) data set correspondingly represents that the proposed method has been able to surpass previous robust algorithms in terms of mean squared error (MSE), accuracy, adjusted random index (ARI), and normalized mutual information (NMI).
C1 [Gheytasi, Farshad; Yaghoubyan, S. Hadi; Bagherifard, Karamollah] Islamic Azad Univ, Dept Comp Engn, Yasooj Branch, Yasuj, Iran.
   [Yaghoubyan, S. Hadi; Bagherifard, Karamollah] Islamic Azad Univ, Young Researchers & Elite Club, Yasooj Branch, Yasuj, Iran.
   [Rezaei, Zahra] Islamic Azad Univ, Dept Comp Engn, Marvdasht Branch, Marvdasht, Iran.
   [Parvin, Hamid] Islamic Azad Univ, Dept Comp Engn, Nourabad Mamasani Branch, Nourabad Mamasani, Iran.
   [Parvin, Hamid] Islamic Azad Univ, Nourabad Mamasani Branch, Young Researchers & Elite Club, Nourabad Mamasani, Iran.
C3 Islamic Azad University; Islamic Azad University; Islamic Azad
   University; Islamic Azad University; Islamic Azad University
RP Yaghoubyan, SH (corresponding author), Islamic Azad Univ, Dept Comp Engn, Yasooj Branch, Yasuj, Iran.; Yaghoubyan, SH (corresponding author), Islamic Azad Univ, Young Researchers & Elite Club, Yasooj Branch, Yasuj, Iran.
EM farshad.gheytasi@gmail.com; yaghoobian.h@gmail.com; zrezaei@miau.ac.ir;
   ka.bagherifard@iau.ac.ir; parvin@iust.ac.ir
CR Affeldt S, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107522
   Allab K, 2018, IEEE T NEUR NET LEAR, V29, P6396, DOI 10.1109/TNNLS.2018.2815623
   Anne F, 2007, BMC Bioinf, V8, P1
   Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364
   Bengio Y., 2013, Advances in neural information processing systems, P26
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Berikov V, 2017, PATTERN RECOGN, V63, P427, DOI 10.1016/j.patcog.2016.10.017
   Biggs N., 1998, Bullet London Math Soc, V30, P196
   Cai D, 2015, IEEE T CYBERNETICS, V45, P1669, DOI 10.1109/TCYB.2014.2358564
   Chang H, 2008, PATTERN RECOGN, V41, P191, DOI 10.1016/j.patcog.2007.04.010
   Chen C., 2017, Big Data Analytics for Sensor-Network Collected Intelligence, P117, DOI DOI 10.1016/B978-0-12-809393-1.00006-4
   Chen MS., 2020, Proc AAAI Conf Artif Intell, V34, P04
   Chen WF, 2012, NEUROCOMPUTING, V77, P229, DOI 10.1016/j.neucom.2011.09.002
   Ding CHQ, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P107, DOI 10.1109/ICDM.2001.989507
   El Hajjar S, 2022, INFORM FUSION, V78, P209, DOI 10.1016/j.inffus.2021.09.009
   Fanti C, 2004, ADV NEUR IN, V16, P1603
   Favati P, 2023, EXPERT SYST APPL, V214, DOI 10.1016/j.eswa.2022.119099
   Fayyad U, 1996, AI MAG, V17, P37
   Fister I, 2013, 2013 INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL AND BUSINESS INTELLIGENCE (ISCBI), P88, DOI 10.1109/ISCBI.2013.25
   HAGEN L, 1992, IEEE T COMPUT AID D, V11, P1074, DOI 10.1109/43.159993
   He L, 2019, IEEE T CYBERNETICS, V49, P1058, DOI 10.1109/TCYB.2018.2794998
   Horie M, 2021, EUR SIGNAL PR CONF, P1472, DOI 10.23919/Eusipco47968.2020.9287516
   Hu ZX, 2020, NEUROCOMPUTING, V384, P1, DOI 10.1016/j.neucom.2019.12.004
   Hu ZX, 2020, INFORM FUSION, V55, P251, DOI 10.1016/j.inffus.2019.09.005
   Huang D, 2020, IEEE T KNOWL DATA EN, V32, P1212, DOI 10.1109/TKDE.2019.2903410
   Huang SD, 2019, PATTERN RECOGN, V88, P174, DOI 10.1016/j.patcog.2018.11.007
   Huang ST, 2019, IEEE T COMPUT SOC SY, V6, P749, DOI 10.1109/TCSS.2019.2926450
   Huo ZN, 2020, J PARALLEL DISTR COM, V138, P211, DOI 10.1016/j.jpdc.2020.01.003
   Jiang DX, 2004, IEEE T KNOWL DATA EN, V16, P1370, DOI 10.1109/TKDE.2004.68
   JOHNSON EL, 1993, MATH PROGRAM, V62, P133, DOI 10.1007/BF01585164
   Kang Z, 2020, KNOWL-BASED SYST, V189, DOI 10.1016/j.knosys.2019.105102
   Li XY, 2012, NEUROCOMPUTING, V97, P125, DOI 10.1016/j.neucom.2012.06.023
   Li YQ, 2015, AAAI CONF ARTIF INTE, P2750
   Li ZX, 2016, CHAOS SOLITON FRACT, V89, P27, DOI 10.1016/j.chaos.2015.09.023
   Liu, 2010, P 27 INT C MACH LEAR, P679, DOI DOI 10.1007/s11263-007-0090-8
   Liu J., 2013, IJCAI
   Liu TY, 2007, LECT NOTES COMPUT SC, V4425, P319
   Liu TL, 2017, IEEE T NEUR NET LEAR, V28, P2129, DOI 10.1109/TNNLS.2016.2574748
   Luo JJ, 2016, IEEE T EVOLUT COMPUT, V20, P418, DOI 10.1109/TEVC.2015.2476359
   Mohamad F, 2013, ARAB J SCI ENG, V38, P2205, DOI 10.1007/s13369-013-0579-0
   Mohar B., 1991, GRAPH THEORY COMBINA, V2, P871
   Monney A, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113570
   Ng A., 2001, and Y, P14
   Rajendran A, 2013, ARAB J SCI ENG, V38, P2375, DOI 10.1007/s13369-013-0559-4
   Rezaei Z, 2019, MULTIMED TOOLS APPL, V78, P21695, DOI 10.1007/s11042-019-7465-z
   Seuret M, 2017, PROC INT CONF DOC, P877, DOI 10.1109/ICDAR.2017.148
   Sharma KK, 2021, INFORM SCIENCES, V547, P723, DOI 10.1016/j.ins.2020.08.080
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shinnou H, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P201
   Tademir K, 2012, PATTERN RECOGN, V45, P3034, DOI 10.1016/j.patcog.2012.02.012
   Tian K, 2017, LECT NOTES ARTIF INT, V10535, P809, DOI 10.1007/978-3-319-71246-8_49
   Tong T, 2020, PATTERN RECOGN LETT, V135, P8, DOI 10.1016/j.patrec.2020.03.035
   Turkmen AC, 2015, Arxiv, DOI [arXiv:1507.03194, 10.48550/arxiv.1507.03194, DOI 10.48550/ARXIV.1507.03194]
   Vega-Pons S, 2011, INT J PATTERN RECOGN, V25, P337, DOI 10.1142/S0218001411008683
   Wang Q, 2019, IEEE T NEUR NET LEAR, V30, P1265, DOI 10.1109/TNNLS.2018.2861209
   Wang R, 2017, IEEE GEOSCI REMOTE S, V14, P2003, DOI 10.1109/LGRS.2017.2746625
   Wen GQ, 2020, NEUROCOMPUTING, V406, P361, DOI 10.1016/j.neucom.2019.09.108
   Witten I., 2002, ACM Sigmod Rec., V31, P76, DOI [10.1145/507338.507355, DOI 10.1145/507338.507355]
   Xie JY, 2016, PR MACH LEARN RES, V48
   Yan DH, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P907
   Yang B, 2017, PR MACH LEARN RES, V70
   Yang LF, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/9030565
   Yang P, 2011, KNOWL-BASED SYST, V24, P621, DOI 10.1016/j.knosys.2011.01.009
   Yang Y, 2015, IEEE T CYBERNETICS, V45, P1069, DOI 10.1109/TCYB.2014.2344015
   Yao P, 2023, OCEAN ENG, V275, DOI 10.1016/j.oceaneng.2023.114140
   Yapici H, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/1063045
   Yuan MS, 2020, IEEE ACCESS, V8, P67277, DOI 10.1109/ACCESS.2020.2985425
   Yue GL, 2023, INFORM SCIENCES, V633, P182, DOI 10.1016/j.ins.2023.03.067
   Zeng S, 2014, NEUROCOMPUTING, V144, P346, DOI 10.1016/j.neucom.2014.04.037
   Zhang XC, 2011, PATTERN RECOGN LETT, V32, P352, DOI 10.1016/j.patrec.2010.09.014
   Zhao Y, 2018, NEUROCOMPUTING, V318, P227, DOI 10.1016/j.neucom.2018.08.059
   Zhong G, 2023, PATTERN RECOGN, V138, DOI 10.1016/j.patcog.2023.109349
   Zhu WJ, 2020, KNOWL-BASED SYST, V204, DOI 10.1016/j.knosys.2020.106199
NR 73
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 25
PY 2023
DI 10.1007/s11042-023-17147-2
EA OCT 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U7WL5
UT WOS:001086870100001
DA 2024-07-18
ER

PT J
AU Yarava, A
   Bindu, CS
AF Yarava, Anitha
   Bindu, C. Shoba
TI Ring signature-based blockchain for guaranteeing privacy preservation in
   online social networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Ring signature; Blockchain; Online Social Networks (OSNs); Privacy
   Preservation; Elliptic Curve
ID PRESERVING FRAMEWORK; SECURE
AB Social network platform facilitates a potential environment in which huge amounts of information are derived from Social Networks (SNs) for attaining significant social targeting. Illegitimate disclosure of users' private data can introduce damaging consequences and may even cause threat to life of users. Majority of the existing privacy preserving research works only handle the issues of privacy but fails in concentrating on the process of facilitating services to normal SN users that includes data access, retrieval and sharing services. Guaranteeing sensitive data security and provisioning efficient social network services to users with privacy is a herculean task. In this paper, Ring Signature-based Blockchain Mechanism (RSBM) is proposed for guaranteeing privacy preservation in OSNs. RSBM is proposed as a reliable methodology for achieving SN services and securing sensitive data by integrating the merits of public-key cryptography technique and blockchain. It is proposed with the capability of preventing potential damage to users' interested data. RSBM is specifically proposed as a privacy preserving protocol that derives the characteristics of elliptical Curve-Inspired Ring Signature (CIRS) for ensuring complete anonymity for user identity. It specifically used consortium blockchain for recording and tracking the transactions that are carried by the users of the OSNs with maximized decentralization and reliability. The security analysis of the proposed RSBM confirms improved resistance to anonymity attacks that could be possibly launched over OSNs. It is also identified to include better advantage in concealing user identity and securing sensitive data.
C1 [Yarava, Anitha] Jawaharlal Nehru Technol Univ Anantapur, Ananthapuramu, Andhra Pradesh, India.
   [Bindu, C. Shoba] Jawaharlal Nehru Technol Univ Anantapur, Constituent Coll, JNTUA Coll Engn, Ananthapuramu, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Anantapur; Jawaharlal Nehru
   Technological University - Anantapur; JNTUA College of Engineering
   Anantapur
RP Yarava, A (corresponding author), Jawaharlal Nehru Technol Univ Anantapur, Ananthapuramu, Andhra Pradesh, India.
EM y.anitha125@gmail.com; shobabindhu.cse@jntua.ac.in
RI Bindu, C. Shoba/AAA-6302-2019
OI Bindu, C. Shoba/0000-0002-3637-507X
CR Arquam M, 2021, SOC NETW ANAL MIN, V11, DOI 10.1007/s13278-021-00754-y
   Bahri Leila, 2018, Online Social Networks and Media, V6, P18, DOI 10.1016/j.osnem.2018.02.001
   Boneh D, 2004, LECT NOTES COMPUT SC, V3027, P506
   Cao N, 2014, IEEE T PARALL DISTR, V25, P222, DOI 10.1109/TPDS.2013.45
   Chen LX, 2019, FUTURE GENER COMP SY, V95, P420, DOI 10.1016/j.future.2019.01.018
   Cheng Y, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P723
   Dagher GG, 2018, SUSTAIN CITIES SOC, V39, P283, DOI 10.1016/j.scs.2018.02.014
   Frimpong SA., 2022, RecGuard: An efficient privacy preservation blockchain-based system for online social network users
   He S, 2020, IEEE INTERNET THINGS, V7, P948, DOI 10.1109/JIOT.2019.2947339
   Hu SS, 2018, IEEE INFOCOM SER, P792, DOI 10.1109/INFOCOM.2018.8485890
   Jia N, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/8872853
   Lax G, 2021, INFORM SCIENCES, V557, P220, DOI 10.1016/j.ins.2021.01.004
   Li Feifei, 2006, ACM INT C MAN DAT SI, P121
   Li LC, 2016, IEEE INTERNET THINGS, V3, P206, DOI 10.1109/JIOT.2015.2469605
   Liang W, 2020, IEEE INTERNET THINGS, V7, P6392, DOI 10.1109/JIOT.2020.2974281
   Liang W, 2020, IEEE T IND INFORM, V16, P6543, DOI 10.1109/TII.2020.2966069
   Liang W, 2020, IEEE T IND INFORM, V16, P2063, DOI 10.1109/TII.2019.2946791
   Liang W, 2019, IEEE T IND INFORM, V15, P3582, DOI 10.1109/TII.2019.2907092
   Nakamoto S., 2008, DECENTRAL BUS REV
   Niranjanamurthy M, 2019, CLUSTER COMPUT, V22, P14743, DOI 10.1007/s10586-018-2387-5
   Pang HweeHwa., 2005, PROC ACM INTE C MANA, P407
   Shiwen Zhang, 2021, Connection Science, V33, P555, DOI 10.1080/09540091.2020.1854181
   Sirisala N, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.7153
   Song DXD, 2000, P IEEE S SECUR PRIV, P44, DOI 10.1109/SECPRI.2000.848445
   Sun JF, 2010, PROG ENERG COMBUST, V36, P677, DOI 10.1016/j.pecs.2010.02.004
   Sun WH, 2016, IEEE T PARALL DISTR, V27, P1187, DOI 10.1109/TPDS.2014.2355202
   Viswanath B, 2014, PROCEEDINGS OF THE 23RD USENIX SECURITY SYMPOSIUM, P223
   Wang GJ, 2013, IEEE INFOCOM SER, P2886
   Wood G., 2014, Ethereum project yellow paper, V151, P1
   Yi YQ, 2013, IEEE INFOCOM SER, P1950
   Zhang SW, 2020, IEEE ACCESS, V8, P154036, DOI 10.1109/ACCESS.2020.3018417
   Zhang SW, 2018, SUSTAIN CITIES SOC, V38, P275, DOI 10.1016/j.scs.2017.12.031
   Zhang SW, 2017, COMPUT COMMUN, V100, P65, DOI 10.1016/j.comcom.2017.01.011
NR 33
TC 2
Z9 2
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 25
PY 2023
DI 10.1007/s11042-023-17413-3
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U7WL5
UT WOS:001086870100007
DA 2024-07-18
ER

PT J
AU Barua, PD
   Tuncer, T
   Dogan, S
   Ooi, CP
   Acharya, RU
AF Barua, Prabal Datta
   Tuncer, Turker
   Dogan, Sengul
   Ooi, Chui Ping
   Acharya, Rajendra U.
TI Novel automated detection of sports activities using shadow videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sports activities detection using shadow; Video processing; Transfer
   learning; Chi2 feature selection; LOSO validation
ID PHYSICAL-ACTIVITY; CLASSIFICATION; EXERCISE; FITNESS; LIFE
AB The aim of this work is to investigate the use of shadow videos for daily sports activity detection and to contribute to the emerging field of shadow-based classification in machine learning. A novel deep feature engineering model is proposed, and a new shadow video dataset is collected to validate the proposed model. Furthermore, the use of shadow videos ensures privacy protection for individuals. To evaluate the proposed system, a dataset comprising five sports activities (i.e., squat, steady run, standing butterfly, overhead side bend, and knee lift) recorded from 33 participants is used. The proposed model works in the following way: (i) videos are divided into frames and aggregated into non-overlapping blocks of six frames to create images, (ii) deep features are extracted from three fully connected layers of the pre-trained AlexNet, resulting in 4096, 4096, and 1000 features from fc6, fc7, and fc8 layers, respectively. These three feature vectors are then merged to generate a final feature vector with a length of 9192 (= 4096 + 4096 + 1000). (iii) The Chi2 selector is employed to select the most distinctive 1000 features in the feature selection phase, and (iv) the support vector machine (SVM) with leave-one-subject-out (LOSO) validation is used to classify the five sports activities. The proposed deep features coupled with Chi2 based model achieved a classification accuracy of 88.49% using the SVM classifier with LOSO cross-validation (CV) on our collected dataset.
C1 [Barua, Prabal Datta] Cogninet Australia, Sydney, NSW 2010, Australia.
   [Barua, Prabal Datta] Univ Southern Queensland, Sch Business Informat Syst, Toowoomba, Australia.
   [Barua, Prabal Datta] Univ Technol Sydney, Fac Engn & Informat Technol, Sydney, NSW 2007, Australia.
   [Barua, Prabal Datta] Australian Int Inst Higher Educ, Sydney, NSW 2000, Australia.
   [Barua, Prabal Datta] Univ New England, Sch Sci & Technol, Armidale, Australia.
   [Barua, Prabal Datta] Taylors Univ, Sch Biosci, Subang Jaya, Malaysia.
   [Barua, Prabal Datta] SRM Inst Sci & Technol, Sch Comp, Kattankulathur, India.
   [Barua, Prabal Datta] Kumamoto Univ, Sch Sci & Technol, Kumamoto, Japan.
   [Barua, Prabal Datta] Univ Sydney, Sydney Sch Educ & Social Work, Sydney, Australia.
   [Tuncer, Turker; Dogan, Sengul] Firat Univ, Technol Fac, Dept Digital Forens Engn, Elazig, Turkiye.
   [Ooi, Chui Ping] Singapore Univ Social Sci, Sch Sci & Technol, Singapore 599494, Singapore.
   [Acharya, Rajendra U.] Univ Southern Queensland, Sch Math Phys & Comp, Springfield, Australia.
C3 University of Southern Queensland; University of Technology Sydney;
   University of New England; Taylor's University; SRM Institute of Science
   & Technology Chennai; Kumamoto University; University of Sydney; Firat
   University; Singapore University of Social Sciences (SUSS); University
   of Southern Queensland
RP Dogan, S (corresponding author), Firat Univ, Technol Fac, Dept Digital Forens Engn, Elazig, Turkiye.
EM prabal.barua@usq.edu.au; turkertuncer@firat.edu.tr; senguldgn@gmail.com;
   cpooi@suss.edu.sg; Rajendra.Acharya@usq.edu.au
RI DOGAN, Sengul/W-4854-2018
OI DOGAN, Sengul/0000-0001-9677-5684
FU Firat University [TEKF.22.06]
FX This study was supported by Firat University Scientific Research
   Projects with project number TEKF.22.06.
CR Abomhara M., 2015, J. Cybersecurity Mob., V4, P65, DOI DOI 10.13052/JCSM2245-1439.414
   Akter T, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0266024
   ALHAYANI B., 2021, MATER TODAY-PROC, DOI [10.1016/j.matpr.2021.02.531, DOI 10.1016/J.MATPR.2021.02.531]
   Altun K, 2010, LECT NOTES COMPUT SC, V6219, P38, DOI 10.1007/978-3-642-14715-9_5
   Altun K, 2010, PATTERN RECOGN, V43, P3605, DOI 10.1016/j.patcog.2010.04.019
   Ankita, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113845
   Avci A., 2010, 23 INT C ARCH COMP S, P1
   Barshan B, 2014, COMPUT J, V57, P1649, DOI 10.1093/comjnl/bxt075
   BECKER M, 1993, QUAL LIFE RES, V2, P239, DOI 10.1007/BF00434796
   Booth FW, 2012, COMPR PHYSIOL, V2, P1143, DOI 10.1002/cphy.c110025
   CASPERSEN CJ, 1985, PUBLIC HEALTH REP, V100, P126
   Cheng Yan, 2021, 2021 16th International Conference on Computer Science & Education (ICCSE), P653, DOI 10.1109/ICCSE51940.2021.9569708
   Dunn AL, 1998, AM J PREV MED, V15, P398, DOI 10.1016/S0749-3797(98)00084-1
   Ermes M, 2008, IEEE T INF TECHNOL B, V12, P20, DOI 10.1109/TITB.2007.899496
   HASKELL WL, 1985, PUBLIC HEALTH REP, V100, P202
   Host K, 2022, HELIYON, V8, DOI 10.1016/j.heliyon.2022.e09633
   Huszár VD, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21217339
   Ji R, 2020, IEEE ACCESS, V8, P138743, DOI 10.1109/ACCESS.2020.3012456
   Joshi K, 2020, PROCEDIA COMPUT SCI, V167, P2374, DOI 10.1016/j.procs.2020.03.290
   Knight JA, 2012, ANN CLIN LAB SCI, V42, P320
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuncan F, 2022, J SUPERCOMPUT, V78, P1048, DOI 10.1007/s11227-021-03921-2
   Lin B-Y, 2022, 2022 IEEE 4 GLOB C L, ppp308, DOI [10.1109/LifeTech53646.2022.9754929, DOI 10.1109/LIFETECH53646.2022.9754929]
   Liu H., 2015, J Cyber Secur Mobil, V4, P65
   Mofijur M, 2021, SUSTAIN PROD CONSUMP, V26, P343, DOI 10.1016/j.spc.2020.10.016
   Nadeem A, 2021, MULTIMED TOOLS APPL, V80, P21465, DOI 10.1007/s11042-021-10687-5
   Nieman DC, 2020, J SPORT HEALTH SCI, V9, P293, DOI 10.1016/j.jshs.2020.05.001
   Sestino A, 2022, TECHNOL ANAL STRATEG, V34, P16, DOI 10.1080/09537325.2021.1883583
   Shaheen M.Y., 2021, PREPRINT, DOI [10.14293/S2199-1006.1.SOR-.PPVRY8K.v1, DOI 10.14293/S2199-1006.1.SOR-.PPVRY8K.V1]
   Sharma P, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2310, DOI 10.1109/ICCV48922.2021.00233
   Taborri J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061461
   Taylor K, 2011, PROCEDIA ENGINEER, V13, P428, DOI 10.1016/j.proeng.2011.05.109
   Tiwari A, 2022, 2022 INT C ADV TECHN, ppp1, DOI [10.1109/ICONAT53423.2022.9726019, DOI 10.1109/ICONAT53423.2022.9726019]
   Tiwari A, 2022, EXPERT SYST APPL, V206, DOI 10.1016/j.eswa.2022.117757
   Tiwari A, 2023, MULTIMED TOOLS APPL, V82, P5405, DOI 10.1007/s11042-022-12795-2
   Tiwari A, 2022, EXPERT SYST APPL, V196, DOI 10.1016/j.eswa.2022.116621
   Tiwari A, 2021, IEEE ACCESS, V9, P126698, DOI 10.1109/ACCESS.2021.3110882
   Tiwari A, 2019, IEEE INT C INT ROBOT, P4169, DOI [10.1109/IROS40897.2019.8967868, 10.1109/iros40897.2019.8967868]
   Tuncer T, 2020, IEEE T INSTRUM MEAS, V69, P9441, DOI 10.1109/TIM.2020.3003395
   Vapnik V, 1998, NONLINEAR MODELING, P55
   Vapnik V, 2000, The Nature of Statistical Learning Theory, DOI [DOI 10.1007/978-1-4757-3264-1, DOI 10.1007/978-1-4757-2440-0]
   Verma P, 2022, VISUAL COMPUT, V38, P2417, DOI 10.1007/s00371-021-02120-7
   Verma P, 2021, COMP M BIO BIO E-IV, V9, P600, DOI 10.1080/21681163.2021.1902400
   Webber J, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11030392
   Willetts M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-26174-1
   Yang WR, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0409-8
   Zdravevski E, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184216
   Zeng B, 2023, ANN OPER RES, V326, P57, DOI 10.1007/s10479-021-04348-x
   Zhang L, 2017, COMPUT GRAPH FORUM, V36, P125, DOI 10.1111/cgf.13278
   Zhu S., 2012, EURASIP J Image Video Proc, V1, P1, DOI DOI 10.3109/19401736.2012.752469
NR 50
TC 0
Z9 0
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 19
PY 2023
DI 10.1007/s11042-023-17407-1
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6OE7
UT WOS:001085969000018
DA 2024-07-18
ER

PT J
AU Sajeer, M
   Mishra, A
AF Sajeer, M.
   Mishra, Ashutosh
TI A DCT-based robust and secured dual watermarking approach for color
   medical scans with joint permutation and diffusion encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Medical image watermarking; RPCA; DCT; RSVD; Arnold cat map; Joint
   permutation and diffusion encryption; Healthcare systems
ID IMAGE; TRANSFORM; SCHEME
AB Digital scans are extensively used in e-healthcare systems, necessitating increased authenticity and integrity of medical records due to security concerns during data transmission. This study presents a hybrid and robust watermarking solution for medical color scans, leveraging the RPCA-DCT-RSVD approach, which combines Robust Principal Component Analysis (RPCA), Discrete Cosine Transform (DCT), and Randomised Singular Value Decomposition (RSVD). The system incorporates invisible dual watermarking with a high embedding capacity and enhances security through Arnold Cat Map (ACM) and Joint Permutation and Diffusion (JPD). Various medical scans from different modalities were tested, and the system achieved an average peak signal-to-noise ratio (PSNR) of 51.90 dB, structural similarity index (SSIM) of 0.9991, normalized correlation (NC) of 1, and bit error rate (BER) of 0, with an embedding capacity of 5120 bits. Comparative analysis with existing methodologies demonstrates superior robustness, embedding capacity, and security performance. This proposed system offers an effective solution for ensuring the authenticity and integrity of medical records in e-healthcare systems.
C1 [Sajeer, M.; Mishra, Ashutosh] Natl Inst Technol, Dept ECE, Calicut, Kerala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Calicut
RP Mishra, A (corresponding author), Natl Inst Technol, Dept ECE, Calicut, Kerala, India.
EM sajeer@sctce.ac.in; ashutosh@nitc.ac.in
OI Mishra, Ashutosh/0000-0003-4366-7908
CR Ahmadi SBB, 2021, APPL INTELL, V51, P1701, DOI 10.1007/s10489-020-01903-0
   Arunkumar S, 2019, MEASUREMENT, V139, P426, DOI 10.1016/j.measurement.2019.02.069
   Awasthi D, 2023, Multimed Tools Appl, P1
   Basit A, 2022, Clust Comput, V10, P1
   Bhinder P, 2020, MULTIMED TOOLS APPL, V79, P183, DOI 10.1007/s11042-019-07941-2
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Haghighat MBA, 2011, COMPUT ELECTR ENG, V37, P789, DOI 10.1016/j.compeleceng.2011.04.016
   Hu FX, 2023, VISUAL COMPUT, V39, P4573, DOI 10.1007/s00371-022-02610-2
   Huang TY, 2023, BIOMED SIGNAL PROCES, V81, DOI 10.1016/j.bspc.2022.104478
   Johnson KA., The Whole Brain Atlas
   Koley S, 2022, J KING SAUD UNIV-COM, V34, P636, DOI 10.1016/j.jksuci.2019.03.002
   Kumar S, 2021, MULTIMED TOOLS APPL, V80, P15487, DOI 10.1007/s11042-020-10322-9
   Li DK, 2022, IET BIOMETRICS, V11, P534, DOI 10.1049/bme2.12102
   Li TY, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.1.013008
   Li TF, 2022, EURASIP J WIREL COMM, V2022, DOI 10.1186/s13638-022-02106-6
   Liu HJ, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501734
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Magdy M, 2022, IEEE ACCESS, V10, P38821, DOI 10.1109/ACCESS.2022.3165813
   Mata-Mendoza D, 2022, VISUAL COMPUT, V38, P2073, DOI 10.1007/s00371-021-02267-3
   Mokashi B, 2022, CONTRAST MEDIA MOL I, V2022, DOI 10.1155/2022/2918126
   Nie XX, 2021, NEUROCOMPUTING, V465, P93, DOI 10.1016/j.neucom.2021.08.109
   nlm, MedPix Database of medical images
   Pallaw VK, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12020334
   Sahu AK, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03365-9
   Salama AS, 2021, CMC-COMPUT MATER CON, V68, P431, DOI 10.32604/cmc.2021.016165
   Shen YX, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114414
   Singh KU, 2022, MULTIMED TOOLS APPL, V81, P39577, DOI 10.1007/s11042-022-12192-9
   Singh KU, 2022, TRAIT SIGNAL, V39, P265, DOI 10.18280/ts.390127
   Singh KU, 2022, CMC-COMPUT MATER CON, V70, P2525, DOI 10.32604/cmc.2022.019302
   Singh OP, 2022, COMPUT COMMUN, V191, P368, DOI 10.1016/j.comcom.2022.05.010
   Sun TK, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24060798
   Thanki R, 2021, MULTIMED TOOLS APPL, V80, P27593, DOI 10.1007/s11042-021-11064-y
   Vaidya SP, 2023, VISUAL COMPUT, V39, P2245, DOI 10.1007/s00371-022-02406-4
   Verma U, 2022, BIOMED SIGNAL PROCES, V76, DOI 10.1016/j.bspc.2022.103694
   Yan F, 2022, IEEE T IND INFORM, V18, P8885, DOI 10.1109/TII.2022.3159863
   Zeng C, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03539-5
NR 36
TC 1
Z9 1
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 17
PY 2023
DI 10.1007/s11042-023-17287-5
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U5AL0
UT WOS:001084922000002
DA 2024-07-18
ER

PT J
AU Aghaee, F
   Fazl-Ersi, E
   Noori, H
AF Aghaee, Fereshteh
   Fazl-Ersi, Ehsan
   Noori, Hamid
TI MDSSD-MobV2: An embedded deconvolutional multispectral pedestrian
   detection based on SSD-MobileNetV2
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multispectral network; Embedded systems; Pedestrian detection;
   Deconvolution; MobileNetV2
ID CNN
AB Multispectral pedestrian detection is known as a promising task in the field of computer vision and deep learning regarding its robustness in challenging conditions like adverse illumination, occlusion, and low-resolution imaging. Both the input data and the network layers can benefit from multispectral fusion. Due to the high computational cost of fusing visible and thermal modalities, it cannot be accomplished efficiently across many tasks in this domain, such as autonomous vehicles, robotic applications, security, and monitoring systems. Despite this fact, most recent efforts have focused on accuracy as a dominant parameter and have paid less attention to the importance of speed. As a solution, this paper proposes a fast Multispectral Deconvolutional MobileNetV2 based Single Shot Detector (MDSSD-MobV2) that effectively balances two crucial goals of accuracy and speed. This lightweight multispectral network is built upon the novel high-resolution MobileNetV2 followed by DSSD auxiliary layers, which fuse visible and thermal feature maps at multiple levels of the network architecture. This research is primarily dependent on developing a framework for a blind assistance detector that is light enough to run on embedded systems with low memory and processing power while still retaining the required accuracy. The evaluation results on the well-known KAIST benchmark show that this method attains sufficient speed on the Nvidia Jetson TX2 while still keeping up with recent solutions with a miss rate margin of less than 1%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\%$$\end{document} and improving their best speed by more than 3.5x on the non-embedded operating system of the GTX 1080Ti platform.
C1 [Aghaee, Fereshteh] Ferdowsi Univ Mashhad, Dept Elect Engn, Mashhad, Iran.
   [Fazl-Ersi, Ehsan; Noori, Hamid] Ferdowsi Univ Mashhad, Dept Comp Engn, Mashhad, Iran.
C3 Ferdowsi University Mashhad; Ferdowsi University Mashhad
RP Fazl-Ersi, E (corresponding author), Ferdowsi Univ Mashhad, Dept Comp Engn, Mashhad, Iran.
EM fereshteh.aghaee@mail.um.ac.ir; fazlersi@um.ac.ir; hnoori@um.ac.ir
RI Noori, Hamid/S-5150-2016
FU Not applicable
FX Not applicable
CR [Anonymous], 2017, 2017 IEEE INT C SIGN
   Brazil G, 2017, IEEE I CONF COMP VIS, P4960, DOI 10.1109/ICCV.2017.530
   Bucher M, 2016, LECT NOTES COMPUT SC, V9915, P524, DOI 10.1007/978-3-319-49409-8_45
   Burger W, 2022, Scale-invariant feature transform (SIFT), P709
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Cao YP, 2022, INFORM FUSION, V88, P1, DOI 10.1016/j.inffus.2022.06.008
   Chen Y, 2020, J OPT SOC AM A, V37, P768, DOI 10.1364/JOSAA.386410
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Du XZ, 2017, IEEE WINT CONF APPL, P953, DOI 10.1109/WACV.2017.111
   Esfandiari N, 2020, 2020 6TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS), DOI 10.1109/ICSPIS51611.2020.9349576
   Fu C.-Y., 2017, arXiv
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hosang J, 2017, PROC CVPR IEEE, P6469, DOI 10.1109/CVPR.2017.685
   Hosang J, 2015, PROC CVPR IEEE, P4073, DOI 10.1109/CVPR.2015.7299034
   Howard A., 2018, CVPR
   Hsu WY, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3142061
   Hwang S, 2015, PROC CVPR IEEE, P1037, DOI 10.1109/CVPR.2015.7298706
   Koenig D, 2017, IEEE COMPUT SOC CONF, P243, DOI 10.1109/CVPRW.2017.36
   Li C., 2018, BRIT MACH VIS C BMVC, P1
   Li CY, 2019, PATTERN RECOGN, V85, P161, DOI 10.1016/j.patcog.2018.08.005
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Li ZX, 2024, Arxiv, DOI arXiv:1712.00960
   Liu J., 2016, ARXIV161102644, P1, DOI DOI 10.5244/C.30.73
   Liu W, 2019, PROC CVPR IEEE, P5182, DOI 10.1109/CVPR.2019.00533
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Minoofam SAH, 2023, IEEE T NEUR NET LEAR, V34, P2480, DOI 10.1109/TNNLS.2021.3106705
   Modhej N, 2020, IEEE ACCESS, V8, P212803, DOI 10.1109/ACCESS.2020.3040298
   Nemati S, 2017, J Knowl-Based Eng Innov (JKBEI), P612
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Ouyang WL, 2012, PROC CVPR IEEE, P3258, DOI 10.1109/CVPR.2012.6248062
   Paszke A, 2019, ADV NEUR IN, V32
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salehifar H, 2011, IEEE ICSAP, P398
   Sha MZ, 2022, AD HOC NETW, V128, DOI 10.1016/j.adhoc.2022.102784
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Surasak T, 2018, PROCEEDINGS OF 2018 5TH INTERNATIONAL CONFERENCE ON BUSINESS AND INDUSTRIAL RESEARCH (ICBIR), P172, DOI 10.1109/ICBIR.2018.8391187
   Wang LM, 2021, PROC CVPR IEEE, P1895, DOI 10.1109/CVPR46437.2021.00193
   Wolpert A, 2020, Arxiv, DOI arXiv:2008.08418
   Zhang H, 2020, IEEE IMAGE PROC, P276, DOI [10.1109/ICIP40778.2020.9191080, 10.1109/icip40778.2020.9191080]
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
NR 47
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17188-7
EA OCT 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400029
DA 2024-07-18
ER

PT J
AU Mishra, A
   Bansal, M
   Sharma, A
AF Mishra, Anurag
   Bansal, Megha
   Sharma, Arpita
TI Video watermarking of live streamed MPEG-4 frames using ELM-Fuzzy-PSO
   hybrid scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fuzzy Inference Logic; AVC videos; Particle swarm optimization; MPEG-4
   videos; Normalized cross-correlation; Video watermarking
ID EXTREME LEARNING-MACHINE; DIGITAL IMAGE WATERMARKING; WAVELET TRANSFORM;
   DWT-SVD; ROBUST; SELECTION; DECOMPOSITION; REGRESSION; ALGORITHM; DCT
AB The widespread expansion of internet and digital sharing of multimedia content has led to a huge rise in security concerns like ownership, content authentication and copyright protection of the multimedia data. This paper presents a novel scheme for watermarking of MPEG-4 videos based on the Extreme Learning Machine (ELM) for frame selection task and hybridization of Fuzzy logic with Particle Swarm Optimization technique for watermark embedding and extraction process. The ELM is applied on the host video to select the relevant frames fit for watermarking process. The embedding step is carried out in DWT-SVD domain using Fuzzy-PSO technique. The proposed scheme is tested over five standard videos having advanced video coding (AVC) format. The robustness and visual quality testing post embedding is respectively carried out by computing Normalized Cross-Correlation (NC(W,W')) and Bit Error Rate (BER(W,W')) along with Average Peak-Signal-to-Noise Ratio (PSNRavg) parameters by applying eight different attacks. Our proposed scheme is tested and compared for its outcomes with those of different other standard schemes. It is found that our results are superior to all other frontline schemes.
C1 [Mishra, Anurag; Sharma, Arpita] Univ Delhi, Deen Dayal Upadhyaya Coll, New Delhi, India.
   [Bansal, Megha] Univ Delhi, Dept Comp Sci, New Delhi, India.
C3 Deen Dayal Upadhyaya College; University of Delhi; University of Delhi
RP Bansal, M (corresponding author), Univ Delhi, Dept Comp Sci, New Delhi, India.
EM anurag_cse2003@yahoo.com; megha.cs.du@gmail.com; asharma@ddu.du.ac.in
CR Agarwal C., 2014, Extreme learning machines 2013: Algorithms and Applications, P209, DOI [10.1007/978-3-319-04741-6_15, DOI 10.1007/978-3-319-04741-6_15]
   Agarwal C, 2015, EGYPT INFORM J, V16, P83, DOI 10.1016/j.eij.2015.01.002
   Agarwal C, 2013, J VIS COMMUN IMAGE R, V24, P1135, DOI 10.1016/j.jvcir.2013.07.007
   Agarwal C, 2011, CAN CON EL COMP EN, P822, DOI 10.1109/CCECE.2011.6030570
   Al-Taweel Sadik Ali M., 2009, Journal of Computer Sciences, V5, P536, DOI 10.3844/jcssp.2009.536.543
   Ali M, 2014, ENG APPL ARTIF INTEL, V31, P15, DOI 10.1016/j.engappai.2013.07.009
   Alonso S.K., eMathTeacher: Mamdani's Fuzzy Inference Method
   Asikuzzaman Md, 2014, IEEE Transactions on Information Forensics and Security, V9, P1502, DOI 10.1109/TIFS.2014.2338274
   Bansal M, 2021, 10 INT C SOFT COMPUT, P125
   Bansal M, 2022, MULTIMED TOOLS APPL, V81, P15219, DOI 10.1007/s11042-022-12526-7
   Bansal M, 2020, LECT NOTES COMPUT SC, V12254, P862, DOI 10.1007/978-3-030-58817-5_61
   Barni M, 2005, IEEE T MULTIMEDIA, V7, P23, DOI 10.1109/TMM.2004.840594
   Barni M, 2003, SIGNAL PROCESS, V83, P2069, DOI 10.1016/S0165-1684(03)00168-3
   Bhardwaj A, 2018, MULTIMED TOOLS APPL, V77, P19659, DOI 10.1007/s11042-017-5340-3
   Chaudhary V., 2012, Int J Mach Learn Comput, V2, P725, DOI [10.7763/IJMLC.2012.V2.223, DOI 10.7763/IJMLC.2012.V2.223]
   Chimienti A, 2002, IEEE T IMAGE PROCESS, V11, P387, DOI 10.1109/TIP.2002.999673
   Choi D, 2010, SIGNAL PROCESS, V90, P1327, DOI 10.1016/j.sigpro.2009.10.009
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Da-Wen X, 2007, CIS: 2007 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, PROCEEDINGS, P945, DOI 10.1109/CIS.2007.123
   Dang C, 2015, IEEE T IMAGE PROCESS, V24, P3742, DOI 10.1109/TIP.2015.2445572
   Deguillaume F, 1999, PROC SPIE, V3657, P113, DOI 10.1117/12.344662
   Dimou A., 2005, Proc of 5th EURASIP Conf on Speech and Image Process, P222
   Dutta T, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3002178
   Ejaz N., 2011, Int J Phys Sci, V6, P3377
   Ejima M, 2000, IEICE T FUND ELECTR, VE83A, P532
   Faragallah OS, 2013, AEU-INT J ELECTRON C, V67, P189, DOI 10.1016/j.aeue.2012.07.010
   Feng Jie, 2008, 2008 Pacific-Asia Workshop on Computational Intelligence and Industrial Application. PACIIA 2008, P712, DOI 10.1109/PACIIA.2008.246
   Hartung F, 1998, SIGNAL PROCESS, V66, P283, DOI 10.1016/S0165-1684(98)00011-5
   He YL, 2012, AEU-INT J ELECTRON C, V66, P305, DOI 10.1016/j.aeue.2011.08.007
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huang HY, 2010, IEEE T INF FOREN SEC, V5, P625, DOI 10.1109/TIFS.2010.2080675
   Inoue H, 2000, IEICE T FUND ELECTR, VE83A, P90
   Jagadeesh B, 2015, PROCEDIA COMPUT SCI, V46, P1618, DOI 10.1016/j.procs.2015.02.095
   Jayamalar T., 2010, International Journal of Engineering Science and Technology, V2, P6963
   Jiang M, 2011, PROCEDIA ENVIRON SCI, V10, P843, DOI 10.1016/j.proenv.2011.09.136
   Karmakar A, 2016, J KING SAUD UNIV-COM, V28, P199, DOI 10.1016/j.jksuci.2014.06.019
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khalilian H, 2013, IEEE T IMAGE PROCESS, V22, P4825, DOI 10.1109/TIP.2013.2278463
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Laxmanika, 2022, MULTIMED TOOLS APPL, V81, P22001, DOI 10.1007/s11042-021-11246-8
   Liu Y, 2010, SIGNAL PROCESS, V90, P626, DOI 10.1016/j.sigpro.2009.08.001
   Masoumi M, 2013, AEU-INT J ELECTRON C, V67, P528, DOI 10.1016/j.aeue.2012.11.009
   Meenakshi K., 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 900), P477, DOI 10.1007/978-981-13-3600-3_45
   Mishra A, 2016, BIO-INSPIRED COMPUTATION AND APPLICATIONS IN IMAGE PROCESSING, P131, DOI 10.1016/B978-0-12-804536-7.00007-7
   Mishra A, 2018, J INF SECUR APPL, V38, P71, DOI 10.1016/j.jisa.2017.11.008
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Motwani Mukesh, 2009, Proceedings of the 2009 International Conference on Image Processing, Computer Vision, & Pattern Recognition. IPCV 2009, P321
   Motwani MC, 2009, IEEE IMAGE PROC, P4261, DOI 10.1109/ICIP.2009.5413682
   Naved A., 2013, Int J Sci Res, V2, P249
   Nouioua I, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/6712065
   Oueslati S., 2010, Int J Image Process, V4, P218
   Ponni S, 2021, Fuzzy rule based video watermarking in DWT-SVD Domain, DOI [10.21203/rs.3.rs-482119/v1, DOI 10.21203/RS.3.RS-482119/V1]
   Preda RO, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3558734
   Preda RO, 2010, MEASUREMENT, V43, P1720, DOI 10.1016/j.measurement.2010.07.009
   Raghavendra K., 2010, IJCA, V4, P19, DOI [10.5120/863-1213, DOI 10.5120/863-1213]
   Rajab L., 2015, J Softw Eng Appl, V08, P224, DOI [10.4236/jsea.2015.84023, DOI 10.4236/JSEA.2015.84023]
   Rajab Lama., 2009, EUR J SCI RES, V30, P389
   Rajpal A., 2016, 2016 IEEE Int Conf Signal Process, Commun and Comput (ICSPCC), P1
   Rajpal A, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND SECURITY (ICCCS)
   Rajpal A, 2019, APPL SOFT COMPUT, V74, P603, DOI 10.1016/j.asoc.2018.10.043
   Rasti P, 2016, J VIS COMMUN IMAGE R, V38, P838, DOI 10.1016/j.jvcir.2016.05.001
   Reyes R, 2010, IEEE LAT AM T, V8, P304, DOI 10.1109/TLA.2010.5538406
   Sathya SPA, 2018, WIRELESS PERS COMMUN, V102, P2011, DOI 10.1007/s11277-018-5252-1
   Saxena N, 2018, Adv Intell Syst Comput, P343, DOI DOI 10.1007/978-981-10-3773-3_34
   Shen RM, 2005, J SYST SOFTWARE, V78, P1, DOI 10.1016/j.jss.2005.02.013
   Stütz T, 2014, IEEE T MULTIMEDIA, V16, P1337, DOI 10.1109/TMM.2014.2310595
   Su JK, 1998, COMPUT GRAPH-UK, V22, P687, DOI 10.1016/S0097-8493(98)00089-2
   Sun XC, 2021, MULTIMED TOOLS APPL, V80, P13491, DOI 10.1007/s11042-020-10392-9
   Swaraja K., 2011, 2011 Annual IEEE India Conference, P1
   Tabassum T, 2012, INT CONF COMPUT INFO, P101, DOI 10.1109/ICCITechn.2012.6509780
   Takore Tamirat Tagesse, 2018, International Journal of Intelligent Systems and Applications, V10, P50, DOI 10.5815/ijisa.2018.11.06
   Thind DK, 2015, PROCEDIA COMPUT SCI, V46, P1661, DOI 10.1016/j.procs.2015.02.104
   Tian LH, 2020, MULTIMED TOOLS APPL, V79, P1759, DOI 10.1007/s11042-019-08256-y
   Venugopala PS, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P3505
   Wang P, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P1555, DOI 10.1109/ICALIP.2008.4590271
   Wang YL, 2006, IEEE T IMAGE PROCESS, V15, P1536, DOI 10.1109/TIP.2006.873476
   Wu CH, 2011, AEU-INT J ELECTRON C, V65, P27, DOI 10.1016/j.aeue.2010.02.003
   Yang YM, 2012, IEEE T NEUR NET LEAR, V23, P1498, DOI 10.1109/TNNLS.2012.2202289
   Ye DP, 2007, APPL MATH COMPUT, V185, P907, DOI 10.1016/j.amc.2006.07.021
   Yen CT, 2016, MULTIMED TOOLS APPL, V75, P9745, DOI 10.1007/s11042-015-2718-y
   Youssef SM, 2014, MULTIMED TOOLS APPL, V73, P1545, DOI 10.1007/s11042-013-1515-8
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zheng ZG, 2018, FUTURE GENER COMP SY, V88, P92, DOI 10.1016/j.future.2018.05.027
NR 85
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-16994-3
EA OCT 2023
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY5Z5
UT WOS:001142522500003
DA 2024-07-18
ER

PT J
AU Sun, JY
   Cai, H
   Zhang, H
AF Sun, Jing-yu
   Cai, Hong
   Zhang, Hao
TI A novel image encryption algorithm combined complex order chaotic system
   and modified AES
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Modified AES; Complex-order chaos; S-box; Irregular image encryption
AB Aiming at the security of digital images, this paper proposes an image encryption algorithm based on a chaotic system of complex order and modified Advanced Encryption Standard (AES). A new complex order chaotic system is first proposed. The proposed encryption algorithm utilizes the chaotic system to generate dynamic s-boxes and keys associated with the plaintext, and dynamically introduces index values in each step of the AES, which increases the unpredictability and reduces the number of encryption rounds, leading to better encryption efficiency. Each round of encryption uses a different s-box for SubBytes operations. Each round of encryption is rotated, so the algorithm is suitable for the encryption of irregular images. Combining the advantages of complex-order chaos and improved AES, it has been proven that the proposed scheme has good properties through statistical analysis, differential analysis, correlation comparison, and other related experiments.
C1 [Sun, Jing-yu; Cai, Hong] Taiyuan Univ Technol, Coll Software, Jinzhong 030600, Peoples R China.
   [Zhang, Hao] Taiyuan Univ Technol, Coll Informat & Comp, Jinzhong 030600, Peoples R China.
C3 Taiyuan University of Technology; Taiyuan University of Technology
RP Zhang, H (corresponding author), Taiyuan Univ Technol, Coll Informat & Comp, Jinzhong 030600, Peoples R China.
EM zhangh545@126.com
OI Zhang, Hao/0000-0003-4281-1461
FU National Natural Science Foundation of China [61702356]; Project 1331 of
   Shanxi Province [SC9100026]
FX This research is supported by the National Natural Science Foundation of
   China (Nos: 61702356), Project 1331 of Shanxi Province (Nos: SC9100026).
CR Altigani A, 2021, IEEE ACCESS, V9, P20191, DOI 10.1109/ACCESS.2021.3051556
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Arab A, 2019, J SUPERCOMPUT, V75, P6663, DOI 10.1007/s11227-019-02878-7
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Ben Farah MA, 2020, MULTIMED TOOLS APPL, V79, P19129, DOI 10.1007/s11042-020-08718-8
   Brahim AH, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106489
   Çavusoglu Ü, 2017, CHAOS SOLITON FRACT, V95, P92, DOI 10.1016/j.chaos.2016.12.018
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Chen LP, 2020, NEURAL NETWORKS, V125, P174, DOI 10.1016/j.neunet.2020.02.008
   Choi US, 2020, MULTIMED TOOLS APPL, V79, P22825, DOI 10.1007/s11042-020-09033-y
   Dong YX, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6677325
   Fatima S., 2022, Eng Proceed, V20, P14
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gao XH, 2021, PHYS SCRIPTA, V96, DOI 10.1088/1402-4896/abed7d
   Hameed ME, 2020, FUTURE GENER COMP SY, V111, P829, DOI 10.1016/j.future.2019.10.010
   Jamal SS, 2019, CHINESE J PHYS, V60, P564, DOI 10.1016/j.cjph.2019.05.038
   Kamal FM, 2021, CHAOS SOLITON FRACT, V144, DOI 10.1016/j.chaos.2021.110686
   Lai Q, 2022, APPL INTELL, V52, P11448, DOI 10.1007/s10489-021-03071-1
   Li TY, 2017, COMPLEXITY, DOI 10.1155/2017/9010251
   Lin CH, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11031329
   Mahmoud GM, 2009, NONLINEAR DYNAM, V58, P725, DOI 10.1007/s11071-009-9513-0
   Naskar PK, 2020, NONLINEAR DYNAM, V100, P2877, DOI 10.1007/s11071-020-05625-3
   Pak C, 2019, MULTIMED TOOLS APPL, V78, P12027, DOI 10.1007/s11042-018-6739-1
   Shafique A, 2020, WIRELESS PERS COMMUN, V115, P2243, DOI 10.1007/s11277-020-07680-w
   Shafique A, 2020, EUR PHYS J PLUS, V135, DOI 10.1140/epjp/s13360-020-00187-0
   Shariatzadeh M, 2021, OPTIK, V246, DOI 10.1016/j.ijleo.2021.167779
   Siddiqui N, 2021, WIRELESS PERS COMMUN, V116, P3015, DOI 10.1007/s11277-020-07832-y
   SPROTT JC, 1994, PHYS REV E, V50, pR647, DOI 10.1103/PhysRevE.50.R647
   Wadi SM, 2013, PROC TECH, V11, P51, DOI 10.1016/j.protcy.2013.12.161
   Wang WT, 2023, MULTIMED TOOLS APPL, V82, P45233, DOI 10.1007/s11042-023-15420-y
   Xu QY, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106178
   Zhang XQ, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8091540
NR 33
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-17206-8
EA OCT 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW2V2
UT WOS:001155653100005
DA 2024-07-18
ER

PT J
AU Wang, BX
   Lan, JH
   Li, FF
AF Wang, Bingxu
   Lan, Jinhui
   Li, Feifan
TI MSG-Voxel-GAN: multi-scale gradient voxel GAN for 3D object generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Generative adversarial network; 3D object generation; Network training
AB The Generative Adversarial Network (GAN) has been the subject of significant attention since it was introduced. It has been widely used in the image domain. However, there has been less research conducted in three dimensions (3D). Moreover, further research in the field of 3D generation has focused on the direct processing of point clouds. Voxel-based methods for 3D object generation were introduced in the early years, but there have been rare subsequent studies. Current methods generate 3D objects of subpar quality. To improve the quality of generated 3D objects, the Multi-Scale Gradient Voxel GAN (MSG-Voxel-GAN) is proposed. Voxel-based methods have achieved promising results in 3D object detection for their fast computation speed and accurate feature description. Therefore, in this paper, we propose a 3D object classification method based on Voxel-RCNN and incorporate it into the discriminator of GAN to generate 3D objects. We apply the network architecture of Multi-Scale Gradient GAN (MSG-GAN) for stable training. Experimental results show that the voxel-based feature extraction method can accurately describe the features of 3D objects, leading to precise classification. The training process of the proposed method is stable, and the quality of generated 3D objects significantly exceeds that of other methods in both subjective visual and objective evaluation metrics. This method can facilitate the development of 3D generative techniques based on GAN.
C1 [Wang, Bingxu; Lan, Jinhui; Li, Feifan] Univ Sci & Technol Beijing, Sch Automat & Elect Engn, College Rd, Beijing 100083, Peoples R China.
   [Wang, Bingxu; Lan, Jinhui; Li, Feifan] Beijing Engn Res Ctr Ind Spectrum Imaging, Beijing 100083, Peoples R China.
C3 University of Science & Technology Beijing
RP Lan, JH (corresponding author), Univ Sci & Technol Beijing, Sch Automat & Elect Engn, College Rd, Beijing 100083, Peoples R China.; Lan, JH (corresponding author), Beijing Engn Res Ctr Ind Spectrum Imaging, Beijing 100083, Peoples R China.
EM b20190278@xs.ustb.edu.cn; lanjh@ustb.edu.cn; g20208658@xs.ustb.edu.cn
FU 13th Five-Year Plan Funding of China [41419029102, 41419020107]; 14th
   Five-Year Plan Funding of China [50916040401, 514010503-201]
FX This research was funded by the 13th Five-Year Plan Funding of China,
   the Funding 41419029102 and the Funding 41419020107, the 14th Five-Year
   Plan Funding of China, the Funding 50916040401 and the Funding
   514010503-201.
CR Arjovsky M, 2017, Arxiv, DOI [arXiv:1701.07875, DOI 10.48550/ARXIV.1701.07875]
   Chan ER, 2022, PROC CVPR IEEE, P16102, DOI 10.1109/CVPR52688.2022.01565
   Chen BJ, 2022, IEEE T CIRC SYST VID, V32, P3527, DOI 10.1109/TCSVT.2021.3116679
   Chen Y, 2023, IEEE T CIRCUITS SYST
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Deng JJ, 2021, AAAI CONF ARTIF INTE, V35, P1201
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Karnewar A, 2020, Arxiv, DOI arXiv:1903.06048
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2018, Arxiv, DOI [arXiv:1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298
   Li CL, 2018, Arxiv, DOI arXiv:1810.05795
   Liao K, 2020, IEEE T CIRC SYST VID, V30, P725, DOI 10.1109/TCSVT.2019.2897984
   Nash C, 2017, COMPUT GRAPH FORUM, V36, P1, DOI 10.1111/cgf.13240
   Radford A., 2015, ARXIV
   Ramasinghe S, 2020, IEEE INT C INT ROBOT, P8169, DOI 10.1109/IROS45743.2020.9341265
   Shaoshuai Shi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10526, DOI 10.1109/CVPR42600.2020.01054
   Valsesia D, 2021, IEEE T MULTIMEDIA, V23, P402, DOI 10.1109/TMM.2020.2976627
   Shu DW, 2019, Arxiv, DOI [arXiv:1905.06292, 10.48550/arXiv.1905.06292]
   Wu J, 2016, ADV NEUR IN, V29
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xie JW, 2021, Arxiv, DOI [arXiv:2004.01301, 10.48550/arXiv.2004.01301]
   Yan Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103337
   Yang SR, 2021, PROC CVPR IEEE, P6344, DOI 10.1109/CVPR46437.2021.00628
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 25
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17116-9
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800011
DA 2024-07-18
ER

PT J
AU Ahammad, SH
   Kalangi, RR
   Nagendram, S
   Inthiyaz, S
   Priya, PP
   Faragallah, OS
   Mohammad, A
   Eid, MMA
   Rashed, ANZ
AF Ahammad, Sk Hasane
   Kalangi, Ruth Ramya
   Nagendram, S.
   Inthiyaz, Syed
   Priya, P. Poorna
   Faragallah, Osama S.
   Mohammad, Alsharef
   Eid, Mahmoud M. A.
   Rashed, Ahmed Nabih Zaki
TI Improved neural machine translation using Natural Language Processing
   (NLP)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Encoding; Neural Machine Translation; Decoding; NLP; Natural Language
   Processing; MT
AB Deep Learning algorithms have made great significant progress. Many model designs and methodologies have been tested to improve presentation in various fields of Natural Language Processing (NLP). NLP includes the domain of translation through the state-of-art process of machine interpretation. Deep learning refers to the use of neural networks with multiple layers to model complex patterns in data. In the context of NMT, deep learning models can capture the complex relationships between source and target languages, leading to more accurate and fluent translations. The encoder-decoder system is a framework for NMT that uses two neural networks, an encoder and a decoder, to translate input sequences to output sequences. The encoder network processes the input sequence and creates a fixed-length representation of it, while the decoder network generates the output sequence from the encoder's representation. Through the speech/text content process, the computer realizes and resembles the individual intervention known as machine translation. Besides a prominent study area, numerous methods, such as rule-based, quantitative, and even excellent illustration of machine translation supervision, are being established. In machine translation, neural networks have achieved considerable advancements. We reviewed various strategies involved with Encoding-Decoding for the Neural Machine Translation scheme in this research (NMT). Most of the neural machine translation (NMT) prototypes has built at a sequential framework of encoder-decoder that does not employ syntactic information.
C1 [Ahammad, Sk Hasane; Kalangi, Ruth Ramya; Nagendram, S.; Inthiyaz, Syed] Koneru Lakshmaiah Educ Fdn, Dept ECE, Vaddeswaram 522302, India.
   [Priya, P. Poorna] Dadi Inst Engn & Technol, ECE Dept, Anakapalle, Visakhapatnam, India.
   [Faragallah, Osama S.] Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, POB 11099, Taif 21944, Saudi Arabia.
   [Mohammad, Alsharef; Eid, Mahmoud M. A.] Taif Univ, Coll Engn, Dept Elect Engn, POB 11099, Taif 21944, Saudi Arabia.
   [Rashed, Ahmed Nabih Zaki] Menoufia Univ, Fac Elect Engn, Elect & Elect Commun Engn Dept, Menoufia 32951, Egypt.
   [Rashed, Ahmed Nabih Zaki] SIMATS, Inst Elect & Commun Engn, Saveetha Sch Engn, Dept VLSI Microelect, Chennai 602105, Tamilnadu, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   Taif University; Taif University; Egyptian Knowledge Bank (EKB); Menofia
   University; Saveetha Institute of Medical & Technical Science; Saveetha
   School of Engineering
RP Rashed, ANZ (corresponding author), Menoufia Univ, Fac Elect Engn, Elect & Elect Commun Engn Dept, Menoufia 32951, Egypt.; Rashed, ANZ (corresponding author), SIMATS, Inst Elect & Commun Engn, Saveetha Sch Engn, Dept VLSI Microelect, Chennai 602105, Tamilnadu, India.
EM ahammadklu@gmail.com; ruthmoses.mathi@gmail.com;
   nagendram@kluniversity.in; syedinthiyaz@kluniversity.in;
   hodece@diet.edu.in; o.salah@tu.edu.sa; m.alsharef@tu.edu.sa;
   m.elfateh@tu.edu.sa; ahmed_733@yahoo.com
RI inthiyaz, syed/U-6723-2018; Rashed, Ahmed nabih zaki/AFB-6046-2022; ,
   hasane/R-4445-2019; Alsharef, Mohammad/JUH-2105-2023
OI inthiyaz, syed/0000-0003-1544-4862; Rashed, Ahmed nabih
   zaki/0000-0002-5338-1623; , hasane/0000-0002-2587-4164; 
FU The researchers would like to acknowledge Deanship of Scientific
   Research, Taif University for funding this work.; Deanship of Scientific
   Research, Taif University
FX The researchers would like to acknowledge Deanship of Scientific
   Research, Taif University for funding this work.
CR Ahammad Sk Hasane, Design And Analysis Of A Heavy Vehicle Chassis By Using E-Glass Epoxy & S-2 Glass Materials
   [Anonymous], 2004, P INT S MACH TRANSL
   [Anonymous], 2011, P ICON 2011 9 INT C
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Barone AVM, 2017, Arxiv, DOI arXiv:1707.07631
   Chatterji S, 2009, P ICON 2009 7 INT C
   HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871
   He D, 2016, ADV NEUR IN, V29
   Klimova B, 2023, EDUC INF TECHNOL, V28, P663, DOI 10.1007/s10639-022-11194-2
   Koehn P, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P127
   Law T, 1993, P 1993 INT C NEUR NE, V3
   Li Xiaoqing, 2016, arXiv
   Liu B., 2016, arXiv
   Liu L., 2016, arXiv, DOI [10.48550/ARXIV.1609.04186, DOI 10.48550/ARXIV.1609.04186]
   Michel P, 2018, Arxiv, DOI arXiv:1805.01817
   Nguyen QP, 2019, IEEE ACCESS, V7, P32602, DOI 10.1109/ACCESS.2019.2902270
   Rajan R, 2009, 2009 INT C ADV COMP
   Ramaiah M, 2023, Deep Learning Research Applications for Natural Language Processing, P65
   Ranathunga S, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3567592
   Sennrich R, 2016, Arxiv, DOI [arXiv:1511.06709, DOI 10.48550/ARXIV.1511.06709]
   Sin S, 2018, 2018 IEEE 7 GLOB C C
   Singh SP, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATIONS AND ELECTRONICS (COMPTELIX), P162, DOI 10.1109/COMPTELIX.2017.8003957
   Stahlberg F, 2020, J ARTIF INTELL RES, V69, P343, DOI 10.1613/jair.1.12007
   Sutskever I, 2014, ADV NEUR IN, V27
   Wang X, 2017, AAAI CONF ARTIF INTE, P3330
NR 25
TC 1
Z9 1
U1 11
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17207-7
EA OCT 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600027
DA 2024-07-18
ER

PT J
AU Akmal, M
   Abid, MI
   Bakr, MA
   Khan, MO
   Saeed, N
AF Akmal, Muhammad
   Abid, Muhammad Irfan
   Bakr, Muhammad Abu
   Khan, Muhammad Omer
   Saeed, Nasir
TI A fast convergent and robust classifier for multi-way corrupted eeg
   signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Classification; Electroencephalography; Missing data; Tensor
   factorization; Xavier initialization
ID TENSOR FACTORIZATION; IMPUTATION; NETWORK
AB The performance of the statistical classifiers being employed determines how precisely an electronic prosthesis moves its target. The performance of the classifier is correlated with the quality of the acquired data, and it degrades in the presence of incomplete data. Missing data must therefore be recovered in order to enhance classifier performance and subsequently regulate prosthesis performance. However, recovering lost data can be difficult. For the purpose of recovering missing data in electroencephalography (EEG) signals, a fast and accurate Xavier-initialized weighted canonical polyadic (X-WCP) based approach has been described in this study. In comparison to cutting-edge techniques, the Xavier-initialized weights converge quickly since they are close to the optimal solution. This research also shows the effectiveness of the proposed approach for enhancing classifier performance. For the method to be validated, three models are proposed. Classifiers are employed to complete EEG data in the first model, and the results are used as a benchmark. In the second and third models, classifiers are employed on partial and recovered signals. The results demonstrate that when recovered data is provided to classifiers instead of partially complete EEG data, where classification accuracy was 55%, classification accuracy is greatly enhanced (up to 70%). Classification accuracy at the benchmark level was 71%.
C1 [Akmal, Muhammad] Riphah Int Univ, Dept Biomed Engn, Lahore, Pakistan.
   [Abid, Muhammad Irfan; Khan, Muhammad Omer] Riphah Int Univ, Dept Elect Engn, Faisalabad, Pakistan.
   [Bakr, Muhammad Abu] Natl Univ Technol, Dept Elect Engn, Islamabad, Pakistan.
   [Saeed, Nasir] United Arab Emirates Univ UAEU, Dept Elect Engn, Al Ain, U Arab Emirates.
RP Saeed, N (corresponding author), United Arab Emirates Univ UAEU, Dept Elect Engn, Al Ain, U Arab Emirates.
EM muhammad.akmal@riphah.edu.pk; mirfanabid@riphahfsd.edu.pk;
   muhammadabubakr@nutech.edu.pk; omerkhan@riphahfsd.edu.pk;
   nasir.saeed@uaeu.ac.ae
RI Saeed, Nasir/Y-5724-2019
OI Saeed, Nasir/0000-0002-5123-5139
FU Research Start Up Grant at United Arab Emirates University (UAEU)
   [12N129]
FX This research was funded by the Research Start Up Grant at United Arab
   Emirates University (UAEU) under grant number 12N129.
CR Acar E, 2011, CHEMOMETR INTELL LAB, V106, P41, DOI 10.1016/j.chemolab.2010.08.004
   Akmal M, 2023, IEEE SENS J, V23, P1286, DOI 10.1109/JSEN.2022.3223338
   Akmal M, 2022, IEEE SENS J, V22, P651, DOI 10.1109/JSEN.2021.3129208
   Akmal M, 2021, IEEE ACCESS, V9, P41745, DOI 10.1109/ACCESS.2021.3063382
   Akmal M, 2019, IEEE ACCESS, V7, P104710, DOI 10.1109/ACCESS.2019.2931371
   Cao J, 2022, ACS Appl Mater Interfaces
   Cui GC, 2016, IEEE INT FUZZY SYST, P2170, DOI 10.1109/FUZZ-IEEE.2016.7737961
   Ding QC, 2015, IEEE T IND ELECTRON, V62, P4994, DOI 10.1109/TIE.2015.2403797
   Ding WJ, 2022, COMPUT ELECTR ENG, V97, DOI 10.1016/j.compeleceng.2021.107561
   Dutta A, 2021, J CONSTR ENG M, V147, DOI 10.1061/(ASCE)CO.1943-7862.0002106
   Dzulkalnine MF, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-0383-x
   García-Laencina PJ, 2015, COMPUT BIOL MED, V59, P125, DOI 10.1016/j.compbiomed.2015.02.006
   Luo Y, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab489
   Nesaragi N, 2022, MED ENG PHYS, V110, DOI 10.1016/j.medengphy.2022.103811
   Nijman SWJ, 2022, J CLIN EPIDEMIOL, V142, P218, DOI 10.1016/j.jclinepi.2021.11.023
   Nolde JM, 2022, COMPUT BIOL MED, V143, DOI 10.1016/j.compbiomed.2022.105294
   Nsugbe E., 2020, Engineering Proceedings, V2, P59, DOI [10.3390/ecsa-7-08169, DOI 10.3390/ECSA-7-08169]
   Shahnawazuddin S, 2020, INTERSPEECH, P4382, DOI 10.21437/Interspeech.2020-1112
   Solé-Casals J, 2018, COGN COMPUT, V10, P1062, DOI 10.1007/s12559-018-9574-9
   Tan Q, 2022, NEURAL COMPUT APPL, V34, P1307, DOI 10.1007/s00521-021-06474-w
   Vazifehdan M, 2019, J KING SAUD UNIV-COM, V31, P175, DOI 10.1016/j.jksuci.2018.01.002
   Verma H, 2019, ICDCN '19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING AND NETWORKING, P371, DOI 10.1145/3288599.3295580
   Walters M., 2021, Am J Med Res, V8, P37, DOI [10.22381/ajmr8220213, DOI 10.22381/AJMR8220213]
   Yoon J, 2019, IEEE T BIO-MED ENG, V66, P1477, DOI 10.1109/TBME.2018.2874712
   Zhang JY, 2019, IEEE INT C BIOINFORM, P760, DOI 10.1109/BIBM47256.2019.8982996
   Zhang SL, 2019, INT CONF ACOUST SPEE, P6570, DOI 10.1109/ICASSP.2019.8682566
NR 26
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17133-8
EA OCT 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600019
DA 2024-07-18
ER

PT J
AU Li, YS
   Guo, SS
   Fu, MX
AF Li, Yinsheng
   Guo, Shaoshuai
   Fu, Maixia
TI A new method of audio-visual environment emotion assessment based on
   range fusion decision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Audio-visual; Response-related time; Adaptive range fusion decision;
   Emotion; EEG
ID EEG; PERSPECTIVES; PERFORMANCE; CORTEX
AB Regarding the effect of vision and auditory on emotion, only one factor of vision or auditory is often focused on, while the synergistic influence among different factors is ignored. Besides, the effect of various factors on emotion is not studied quantitatively. Therefore, this paper proposes a range fusion decision model in a normal environment. First, the orthogonal table is used to design the experimental plan between different visual and auditory factors, and the corresponding EEG is collected through the portable EEG device. Then, EMD and Hilbert transform are used to calculate the response-related time, combined with the range fusion decision model to obtain the adaptive weight of each environmental factor, and the influence mechanism of different visual and auditory factors on EEG can be established to realize the brain emotion assessment in the different audio-visual environment. The experimental results show that the model effectively reveals the mechanism of the synergistic influence of various visual and auditory environmental factors on human emotion and provides essential practical guidance for ecological design.
C1 [Li, Yinsheng; Guo, Shaoshuai; Fu, Maixia] Henan Univ Technol, Key Lab Grain Informat Proc & Control, Minist Educ, Zhengzhou 450001, Henan, Peoples R China.
   [Li, Yinsheng; Guo, Shaoshuai; Fu, Maixia] Henan Univ Technol, Henan Key Lab Grain Photoelect Detect & Control, Zhengzhou 450001, Peoples R China.
   [Li, Yinsheng; Guo, Shaoshuai; Fu, Maixia] Henan Univ Technol, Coll Informat Sci & Engn, Zhengzhou 450001, Peoples R China.
C3 Henan University of Technology; Henan University of Technology; Henan
   University of Technology
RP Fu, MX (corresponding author), Henan Univ Technol, Key Lab Grain Informat Proc & Control, Minist Educ, Zhengzhou 450001, Henan, Peoples R China.; Fu, MX (corresponding author), Henan Univ Technol, Henan Key Lab Grain Photoelect Detect & Control, Zhengzhou 450001, Peoples R China.; Fu, MX (corresponding author), Henan Univ Technol, Coll Informat Sci & Engn, Zhengzhou 450001, Peoples R China.
EM lyswp009@126.com; guoshaoshuail@163.com; fumaixia@126.com
RI Li, Yinsheng/AAW-3650-2021
OI Li, Yinsheng/0000-0003-2629-7941
FU The authors would like to thank all the participants who participated in
   the experiment. The authors would like to acknowledge the support of the
   Open Project of Key Laboratory of Ministry of Education (No.
   KFJJ-2021-105), the Innovative Funds Plan of Hena [KFJJ-2021-105]; Open
   Project of Key Laboratory of Ministry of Education [2022ZKCJ15];
   Innovative Funds Plan of Henan University of Technology [31401524,
   31401523, 31401501]; Research Foundation for Advanced Talents of Henan
   University of Technology [232102211068, 232102220032]; Key Ramp;D and
   Promotion Special Project (Science and Technology Research) in Henan
   Province
FX The authors would like to thank all the participants who participated in
   the experiment. The authors would like to acknowledge the support of the
   Open Project of Key Laboratory of Ministry of Education (No.
   KFJJ-2021-105), the Innovative Funds Plan of Henan University of
   Technology (No. 2022ZKCJ15), the Research Foundation for Advanced
   Talents of Henan University of Technology (No. 31401524, No. 31401523
   and No. 31401501), and the Key R & D and Promotion Special Project
   (Science and Technology Research) in Henan Province (No. 232102211068
   and No. 232102220032).
CR Bell L, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01655
   Castiblanco Jimenez IA, 2023, advances on mechanics, design engineering and manufacturing, VIV, P318
   Jimenez IAC, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12010122
   Jimenez IAC, 2023, INT J INTERACT DES M, V17, P45, DOI 10.1007/s12008-022-01087-6
   Cegar DD, 2020, MULTIMED TOOLS APPL, V79, P19803, DOI 10.1007/s11042-020-08844-3
   Chai MT, 2019, FRONT NEUROINFORM, V13, DOI 10.3389/fninf.2019.00066
   Davidson RJ, 2000, PSYCHOL BULL, V126, P890, DOI 10.1037/0033-2909.126.6.890
   Davidson RJ, 2004, BIOL PSYCHOL, V67, P219, DOI 10.1016/j.biopsycho.2004.03.008
   Downing PE, 2001, SCIENCE, V293, P2470, DOI 10.1126/science.1063414
   Dufour B, 2018, NEUROSCIENCE, V385, P47, DOI 10.1016/j.neuroscience.2018.06.005
   Elliot AJ, 2007, J EXP PSYCHOL GEN, V136, P154, DOI 10.1037/0096-3445.136.1.154
   Fang WT, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.1032808
   Friman O, 2007, IEEE T BIO-MED ENG, V54, P742, DOI 10.1109/TBME.2006.889160
   Fuji H, 2023, TECH INNOV PATIENT S, V27, DOI 10.1016/j.tipsro.2023.100214
   Goldin PR, 2008, BIOL PSYCHIAT, V63, P577, DOI 10.1016/j.biopsych.2007.05.031
   Gruzelier JH, 1996, INT J PSYCHOPHYSIOL, V24, P1, DOI 10.1016/S0167-8760(96)00069-4
   Guo F, 2019, INT J IND ERGONOM, V71, P47, DOI 10.1016/j.ergon.2019.02.006
   Hamada M, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1020-8
   Herrington JD, 2005, EMOTION, V5, P200, DOI 10.1037/1528-3542.5.2.200
   Herrmann CS, 2001, EXP BRAIN RES, V137, P346, DOI 10.1007/s002210100682
   Jie X, 2014, BIO-MED MATER ENG, V24, P1185, DOI 10.3233/BME-130919
   Kim JS, 2019, INT J PSYCHOPHYSIOL, V142, P50, DOI 10.1016/j.ijpsycho.2019.06.008
   Koelsch S, 2014, NAT REV NEUROSCI, V15, P170, DOI 10.1038/nrn3666
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Light SN, 2009, CHILD DEV, V80, P1210, DOI 10.1111/j.1467-8624.2009.01326.x
   MAKEIG S, 1993, ELECTROEN CLIN NEURO, V86, P283, DOI 10.1016/0013-4694(93)90110-H
   Makowski D, 2019, COGN AFFECT BEHAV NE, V19, P877, DOI 10.3758/s13415-018-00681-0
   Miao YM, 2009, The experiment reseach of the automatic physiological responses affected by audio-visual stimulations
   Momennezhad A, 2018, MULTIMED TOOLS APPL, V77, P27089, DOI 10.1007/s11042-018-5906-8
   Münch M, 2014, NEUROIMAGE, V101, P547, DOI 10.1016/j.neuroimage.2014.06.071
   Neurosky I, 2020, Brain wave signal (EEG) of NeuroSky
   Nevin SM, 2022, EUR J PAEDIATR NEURO, V37, P129, DOI 10.1016/j.ejpn.2022.01.022
   Perera D, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22166230
   Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8
   Raheel A, 2019, MULTIMED TOOLS APPL, V78, P13971, DOI 10.1007/s11042-018-6907-3
   Ramirez R, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00254
   Roy S, 2021, COGN NEURODYNAMICS, V15, P1023, DOI 10.1007/s11571-021-09692-z
   Spreng RN, 2009, J COGNITIVE NEUROSCI, V21, P489, DOI 10.1162/jocn.2008.21029
   Teder-Sälejärvi WA, 2002, COGNITIVE BRAIN RES, V14, P106, DOI 10.1016/S0926-6410(02)00065-4
   Yokoyama H, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00259
   Yu K, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/4/046020
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 42
TC 0
Z9 0
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17182-z
EA OCT 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600011
DA 2024-07-18
ER

PT J
AU Khan, S
   Alqahtani, S
AF Khan, Shakir
   Alqahtani, Salihah
TI Hybrid machine learning models to detect signs of depression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sentiment analysis; Depression detection; Social network; Twitter data
   analysis
AB Depression is a prevalent mental illness that can only be diagnosed through self-reporting. Unfortunately, 70% of individuals do not seek medical help in the early stages of depression. With the increasing use of social media to share daily activities and emotions, it has become a valuable tool for identifying mental health issues. To this end, this paper proposes multiple hybrid machine-learning models for sentiment analysis to detect signs of depression by analyzing Twitter tweets. The study utilizes unsupervised approaches for feature extraction and supervised approaches as classifiers. The proposed models are evaluated on public sentiment tweets datasets using various performance metrics. The four modules proposed in this study can be used to detect signs of depression in text data. Module 1 uses BERT for feature extraction followed by an artificial neural network as a classification module. Module 2 involves data pre-processing followed by the TF-IDF feature extraction method and logistic regression as a classification algorithm. Module 3 also includes data pre-processing followed by the TF-IDF feature extraction method but uses a linear support vector machine as the classification algorithm. Finally, Module 4 uses the Spacy package with a small library as the feature extraction method and a linear support vector machine as the classification algorithm. Model 2 had the highest accuracy of 0.994, followed closely by model 3 with an accuracy of 0.992, while model 4 had a significantly lower accuracy of 0.868. Model 1 achieved an accuracy of 0.99.
C1 [Khan, Shakir; Alqahtani, Salihah] Imam Mohammad Ibn Saud Islamic Univ IMSIU, Coll Comp & Informat Sci, Riyadh 11432, Saudi Arabia.
C3 Imam Mohammad Ibn Saud Islamic University (IMSIU)
RP Khan, S (corresponding author), Imam Mohammad Ibn Saud Islamic Univ IMSIU, Coll Comp & Informat Sci, Riyadh 11432, Saudi Arabia.
EM sgkhan@imamu.edu.sa
RI Khan, Dr Shakir/O-8721-2014
OI Khan, Dr Shakir/0000-0002-7925-9191
FU The authors extend their appreciation to the Deanship of Scientific
   Research at Imam Mohammad Ibn Saud Islamic University for funding and
   supporting this work through grant number IMSIU-RG23056.
   [IMSIU-RG23056]; Deanship of Scientific Research at Imam Mohammad Ibn
   Saud Islamic University
FX The authors extend their appreciation to the Deanship of Scientific
   Research at Imam Mohammad Ibn Saud Islamic University for funding and
   supporting this work through grant number IMSIU-RG23056.
CR Arora P., 2019, 2019 INT C SIGN PROC
   Azam F., 2021, 2021 INT C ART INT I
   Chiu CY, 2021, J INTELL INF SYST, V56, P25, DOI 10.1007/s10844-020-00599-5
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Garg M, 2021, Kaggle
   Haq AU, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21248219
   Islam M. R., 2018, 2018 INT C COMP COMM, P1
   Kamite Sangeeta R., 2020, 2020 International Conference on Smart Innovations in Design, Environment, Management, Planning and Computing (ICSIDEMPC), P122, DOI 10.1109/ICSIDEMPC49020.2020.9299641
   Kamite SR., 2020, 2020 INT C SMART INN
   Khan S, 2022, IEEE ACCESS, V10, P7881, DOI 10.1109/ACCESS.2022.3143799
   Mirza AA, 2021, ADV MED EDUC PRACT, V12, P393, DOI 10.2147/AMEP.S302897
   Park M., 2021, P INT AAAI C WEB SOC, V7, P476, DOI DOI 10.1609/ICWSM.V7I1.14425
   Reece AG, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12961-9
   Rosa RL., 2016, 2016 IEEE INT C CONS
   Saha A., 2021, 2021 8 INT C COMP CO
   Spacy industrial-strength natural language processing in python, Industrial-strength Natural Language Processing in Python
   Stephen JJ., 2019, Int J Electr Comput Eng, V9, P3247
   Uddin AH., 2019, 2019 INT C COMP COMM
   Ul Hassan A, 2017, I C INF COMM TECH CO, P138
   Wankhade M, 2022, ARTIF INTELL REV, V55, P5731, DOI 10.1007/s10462-022-10144-1
   Zhao W, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1549
NR 21
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 6
PY 2023
DI 10.1007/s11042-023-16221-z
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX9N7
UT WOS:001142351700005
DA 2024-07-18
ER

PT J
AU Juneja, A
   Kumar, V
   Singla, SK
AF Juneja, Akshay
   Kumar, Vijay
   Singla, Sunil Kumar
TI Single Image Dehazing Using Hybrid Convolution Neural Network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image dehazing; Inverted wavelet transform; Multiscale convolution
   neural network; Retinex transform; Wavelet transform
AB Due to the dispersion of atmospheric particles, the quality of the image becomes inferior. The quality of the frames captured in poor weather conditions such as fog, smog, and haze declines as a result. These images are difficult to process using conventional visibility restoration algorithms. Several deep learning techniques have been proposed in order to resolve the aforementioned computer vision challenges. They are trained and tested on hazy dataset by designing and implementing a supervised learning-based convolutional neural network (CNN) or an unsupervised learning-based generative adversarial network (GAN). In this paper, a novel single image dehazing algorithm called hybrid CNN has been proposed that consists of wavelet and inverted wavelet-based multi-scale convolution neural network (WIW-MSCNN). Furthermore, the output of inverted wavelet transformed component has been processed using coarse scale network that generates an estimated transmission map; whereas, the output of the wavelet transformed component has been processed with the help of fine scale network along with the refinement of coarse transmission map. Images of various hazy datasets such as FRIDA, FRIDA2, RESIDE, NH-HAZE, O-HAZE, DENSE-HAZE, and HUDRS have been used for training and testing the architecture. The performance of the proposed model has been analyzed by comparing the generated results with existing dehazing techniques.
C1 [Juneja, Akshay; Singla, Sunil Kumar] Thapar Inst Engn & Technol, Dept Elect & Instrumentat Engn, Patiala, India.
   [Kumar, Vijay] Dr BR Ambedkar Natl Inst Technol, Dept Informat Technol, Jalandhar, India.
C3 Thapar Institute of Engineering & Technology; National Institute of
   Technology (NIT System); Dr B R Ambedkar National Institute of
   Technology Jalandhar
RP Juneja, A (corresponding author), Thapar Inst Engn & Technol, Dept Elect & Instrumentat Engn, Patiala, India.
EM ajuneja60_phd20@thapar.edu; vijaykumarchahar@gmail.com;
   ssingla@thapar.edu
RI Kumar, Vijay/A-2782-2015; Juneja, Dr. Akshay/KCK-0186-2024
OI Juneja, Dr. Akshay/0000-0002-0616-6613
FU Council of Scientific and Industrial Research (CSIR), India
FX No Statement Available
CR Ancuti CO, 2021, IEEE COMPUT SOC CONF, P627, DOI 10.1109/CVPRW53098.2021.00074
   Ancuti CO, 2020, IEEE COMPUT SOC CONF, P1798, DOI 10.1109/CVPRW50498.2020.00230
   Ancuti CO, 2019, IEEE IMAGE PROC, P1014, DOI [10.1109/icip.2019.8803046, 10.1109/ICIP.2019.8803046]
   Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Ancuti C, 2018, LECT NOTES COMPUT SC, V11182, P620, DOI 10.1007/978-3-030-01449-0_52
   Ancuti C, 2016, IEEE IMAGE PROC, P2226, DOI 10.1109/ICIP.2016.7532754
   [Anonymous], pix2pix dataset
   [Anonymous], Home-MatConvNet
   Barner KE, 1998, HANDB STAT, V17, P555, DOI 10.1016/S0169-7161(98)17023-2
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Bindal A, 2019, Normalization Techniques in Deep Neural Networks
   Brownlee J, 2019, MachineLearning Mastery
   Bui TM, 2018, IEEE T IMAGE PROCESS, V27, P999, DOI 10.1109/TIP.2017.2771158
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Choi LK, 2014, IEEE SW SYMP IMAG, P165, DOI 10.1109/SSIAI.2014.6806055
   Choi LK, 2014, PROC SPIE, V9014, DOI 10.1117/12.2036477
   Choi LK, 2015, FADE software release
   Ngo D, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194011
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dharejo FA, 2021, OPTIK, V231, DOI 10.1016/j.ijleo.2021.166462
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   Dudhane A, 2018, IEEE WINT CONF APPL, P1397, DOI 10.1109/WACV.2018.00157
   Fu MH, 2021, IEEE COMPUT SOC CONF, P203, DOI 10.1109/CVPRW53098.2021.00029
   Fu QT, 2018, IEEE ACCESS, V6, P61277, DOI 10.1109/ACCESS.2018.2870638
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hu Q, 2023, VISUAL COMPUT, V39, P997, DOI 10.1007/s00371-021-02380-3
   Huang LY, 2019, IEEE IMAGE PROC, P2741, DOI [10.1109/ICIP.2019.8803316, 10.1109/icip.2019.8803316]
   Hussain F, 2016, J SENSORS, V2016, DOI 10.1155/2016/3894832
   Juneja A, 2022, ARCH COMPUT METHOD E, V29, P1727, DOI 10.1007/s11831-021-09637-z
   Dhara SK, 2021, IEEE T CIRC SYST VID, V31, P2076, DOI 10.1109/TCSVT.2020.3007850
   Kratz L, 2009, IEEE I CONF COMP VIS, P1701, DOI 10.1109/ICCV.2009.5459382
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2021, INT J COMPUT VISION, V129, P1754, DOI 10.1007/s11263-021-01431-5
   Li CY, 2018, IEEE ACCESS, V6, P24877, DOI 10.1109/ACCESS.2018.2818882
   Li JJ, 2018, IEEE ACCESS, V6, P26831, DOI 10.1109/ACCESS.2018.2833888
   Li RD, 2018, PROC CVPR IEEE, P8202, DOI 10.1109/CVPR.2018.00856
   Li XL, 2023, VISUAL COMPUT, V39, P663, DOI 10.1007/s00371-021-02365-2
   Liu K, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082606
   Liu W, 2020, IEEE T IMAGE PROCESS, V29, P7819, DOI 10.1109/TIP.2020.3007844
   Ma KD, 2015, IEEE IMAGE PROC, P3600, DOI 10.1109/ICIP.2015.7351475
   Parihar AS, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INVENTIVE SYSTEMS AND CONTROL (ICISC 2018), P619, DOI 10.1109/ICISC.2018.8398874
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Raikwar SC, 2020, IEEE T IMAGE PROCESS, V29, P4832, DOI 10.1109/TIP.2020.2975909
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Sharma N, 2021, ARCH COMPUT METHOD E, V28, P4449, DOI 10.1007/s11831-021-09541-6
   Singh D, 2019, ARCH COMPUT METHOD E, V26, P1395, DOI 10.1007/s11831-018-9294-z
   Song YF, 2018, IEEE T MULTIMEDIA, V20, P1548, DOI 10.1109/TMM.2017.2771472
   Tarel JP, 2012, IEEE INTEL TRANSP SY, V4, P6, DOI 10.1109/MITS.2012.2189969
   Tarel JP, 2010, IEEE INT VEH SYM, P478, DOI 10.1109/IVS.2010.5548128
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Venkatanath N, 2015, NATL CONF COMMUN
   Wang AN, 2019, IEEE T IMAGE PROCESS, V28, P381, DOI 10.1109/TIP.2018.2868567
   Wang CL, 2011, ENTROPY-SWITZ, V13, P254, DOI 10.3390/e13010254
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HY, 2021, PROC CVPR IEEE, P10546, DOI 10.1109/CVPR46437.2021.01041
   Xiao JS, 2020, IEEE ACCESS, V8, P15883, DOI 10.1109/ACCESS.2019.2962784
   Yan JJ, 2020, IEEE ACCESS, V8, P25431, DOI 10.1109/ACCESS.2020.2971092
   Yeh CH, 2020, IEEE T IMAGE PROCESS, V29, P3153, DOI 10.1109/TIP.2019.2957929
   Zhang J, 2017, PROC CVPR IEEE, P7016, DOI 10.1109/CVPR.2017.742
   Zhang SD, 2023, VISUAL COMPUT, V39, P953, DOI 10.1007/s00371-021-02377-y
   Zhang WD, 2019, IEEE ACCESS, V7, P72492, DOI 10.1109/ACCESS.2019.2920403
   Zhang WL, 2014, INT CONF SIGN PROCES, P938, DOI 10.1109/ICOSP.2014.7015142
   Zhang YF, 2017, IEEE IMAGE PROC, P3205, DOI 10.1109/ICIP.2017.8296874
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu XZ, 2008, 2008 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND INFORMATION TECHNOLOGY, PROCEEDINGS, P326, DOI 10.1109/MMIT.2008.134
NR 71
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 5
PY 2023
DI 10.1007/s11042-023-17132-9
EA OCT 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ4I6
UT WOS:001156484900007
DA 2024-07-18
ER

PT J
AU MahaLakshmi, NV
   Rout, RK
AF MahaLakshmi, N. Venkata
   Rout, Ranjeet Kumar
TI An intelligence method for heart disease prediction using integrated
   filter-evolutionary search based feature selection and optimized
   ensemble classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Integrated filter-evolutionary; Evolutionary gravitational; Intelligent
   multi-Layer perceptron; Neural network based ensemble classifier; Fire
   fly-driven Multi-objective multi-verse optimizer
AB Heart disease is more difficult to detect due to certain risk factors such as diabetes, high blood pressure, abnormal heart rate, high cholesterol, etc. It is crucial to accurately predict heart disease before a heart attack occurs in order to treat cardiac patients efficiently. The goal can be achieved by using large-scale health data with a heart disease machine learning (ML) model. This work proposes a new intelligent approach using an integrated filter-evolutionary search-based feature selection (iFES-FS) and an optimized ensemble classifier for heart disease diagnosis. The proposed feature selection method selects the most informative features from the original feature set by integrating adaptive threshold information gain-based feature selection (aTIG-FS) and evolutionary gravity-search based feature selection (EGS-FS). The selected features mainly relate to the viable solution as the selected features are successfully used in the heart disease classification process. The classification is done by proposing a new intelligent multi-layer perceptron neural network-based ensemble classifier (IMLP-NN-EC). This method improves the performance of the ML technique by introducing a firefly-driven FF-MOMVO (Multi-Objective Multi-Verse Optimizer) algorithm to optimize the hyperparameters of the classifier. The experimental results are evaluated and compared to previous models regarding statistical measures related to the accuracy, precision, f-measure, specificity, sensitivity, accuracy vs. loss and ROC curve. The model also shows the best results when compared to existing methods.
C1 [MahaLakshmi, N. Venkata; Rout, Ranjeet Kumar] Natl Inst Technol, Dept Comp Sci & Engn, Srinagar 190006, Jammu & Kashmir, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Srinagar
RP MahaLakshmi, NV (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Srinagar 190006, Jammu & Kashmir, India.
EM mahalakshminit@gmail.com; ranjeetkumarrout@nitsri.in
CR Amma NB, 2012, 2012 INT C COMPUTING, P1
   Ayon SI, 2022, IETE J RES, V68, P2488, DOI 10.1080/03772063.2020.1713916
   Benjamins JW, 2019, NETH HEART J, V27, P392, DOI 10.1007/s12471-019-1286-6
   Chandralekha M., 2018, Applied Mathematics Information Sciences, V12, P217, DOI DOI 10.18576/AMIS/120121
   Di Angelantonio E, 2019, LANCET GLOB HEALTH, V7, pE1332, DOI 10.1016/S2214-109X(19)30318-3
   Dun B, 2016, Computer Science, V1, P1
   El-Shafiey MG, 2022, MULTIMED TOOLS APPL, V81, P18155, DOI 10.1007/s11042-022-12425-x
   Gavhane Aditi, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P1275, DOI 10.1109/ICECA.2018.8474922
   Gholi Z, 2016, J RES MED SCI, V21, P120, DOI 10.4103/1735-1995.179888
   Golafshani EM, 2021, CONSTR BUILD MATER, V291, DOI 10.1016/j.conbuildmat.2021.123314
   Gupta A, 2022, APPL INTELL, V52, P2436, DOI 10.1007/s10489-021-02467-3
   Hammad M, 2018, MEASUREMENT, V125, P634, DOI 10.1016/j.measurement.2018.05.033
   Hassan MM, 2020, INFORM SCIENCES, V513, P386, DOI 10.1016/j.ins.2019.10.069
   Hira Zena M., 2015, Advances in Bioinformatics, V2015, P198363, DOI 10.1155/2015/198363
   Hung CY, 2017, IEEE ENG MED BIO, P3110, DOI 10.1109/EMBC.2017.8037515
   Janosi A, 2021, Heart disease data set
   Javid I, 2020, INT J ADV COMPUT SC, V11, P540
   Kumar PR, 2022, J MECH MED BIOL, V22, DOI 10.1142/S0219519422500518
   Mehmood A, 2021, ARAB J SCI ENG, V46, P3409, DOI 10.1007/s13369-020-05105-1
   Mienye ID, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10192347
   Mohan AT, 2020, J TURBUL, V21, P484, DOI 10.1080/14685248.2020.1832230
   Mohan S, 2019, IEEE ACCESS, V7, P81542, DOI 10.1109/ACCESS.2019.2923707
   Musafer H, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020259
   Ng ACT, 2021, NAT REV CARDIOL, V18, P291, DOI 10.1038/s41569-020-00465-5
   Robinson S., 2021, Priorities for Health Promotion and Public Health Internet, P355, DOI DOI 10.4324/9780367823689-16/CARDIOVASCULAR-DISEASESALLY-ROBINSON
   Sani ZA, 2020, Z-Alizadeh Sani data set, 2020
   Sarfo FS, 2023, STROKE, V54, P407, DOI 10.1161/STROKEAHA.122.039567
   Shahid F, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110212
   Sharma S., 2020, Int J Innov Technol Exploring Eng (IJITEE), V9, P124, DOI DOI 10.35940/IJITEE.C9009.019320
   Shorewala V., 2021, Inform. Med., V26, DOI [10.1016/j.imu.2021.100655, DOI 10.1016/J.IMU.2021.100655]
   García-Ordás MT, 2023, MULTIMED TOOLS APPL, V82, P31759, DOI 10.1007/s11042-023-14817-z
   Terrada O., 2020, 2020 3 INT C ADV COM, P1
   Tiwari A, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105624
   Ul Haq A, 2018, MOB INF SYST, V2018, DOI 10.1155/2018/3860146
   Valarmathi R, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.103033
   Velusamy D, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105770
   Wang H, 2017, KNOWL-BASED SYST, V126, P8, DOI 10.1016/j.knosys.2017.04.004
   Yahaya L., 2020, American Journal of Artificial Intelligence, V4, P20, DOI [10.11648/j.ajai.20200401.12, DOI 10.11648/J.AJAI.20200401.12]
   Zebari R., 2020, Journal of Applied Science and Technology Trends, V1, P56, DOI [DOI 10.38094/JASTT1224, 10.38094/jastt1224]
NR 39
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 5
PY 2023
DI 10.1007/s11042-023-16924-3
EA OCT 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ4I6
UT WOS:001156484900012
DA 2024-07-18
ER

PT J
AU Yang, P
   Yu, DS
   Yang, GW
AF Yang, Peng
   Yu, Dashuai
   Yang, Guowei
TI Object detection in aerial remote sensing images using bidirectional
   enhancement FPN and attention module with data augmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Aerial remote sensing image; Object detection; Attention module; Data
   augmentation; Feature pyramid network
AB Object detection for aerial remote sensing images is a foundation task in earth observation community. However, various challenges still exist in this field, including the varied appearances of targets to be detected, the complexity of image background and the expensive manual annotation. To tackle these problems, we proposed a Faster R-CNN based framework with several elaborate designs. Our detector employs a bidirectional enhancement feature pyramid network into the framework, which can improve multi-scale feature extraction so as to effectively handle objects with different sizes. In the meantime, an attention module is present to further suppress noisy background. Moreover, we augment training sets by using a count-guided deep descriptor transforming (CG-DDT) algorithm, which can automatically generate coarse object bounding boxes for images with only class label and per-class object count. We have evaluated the proposed method on popular aerial remote sensing benchmarks, i.e., NWPU VHR-10 and DOTA, and the experimental results show that it can accurately detect targets while reducing the cost of manual annotations during training.
C1 [Yang, Peng; Yu, Dashuai; Yang, Guowei] Nanjing Audit Univ, Sch Informat Engn, Nanjing 211815, Peoples R China.
C3 Nanjing Audit University
RP Yang, GW (corresponding author), Nanjing Audit Univ, Sch Informat Engn, Nanjing 211815, Peoples R China.
EM 270293@nau.edu.cn
FU National Natural Science Foundation of China [62172229]; Natural Science
   Foundation of Jiangsu Province [BK20211294, BK20211295]; Postgraduate
   Research & Practice Innovation Program of Jiangsu Province [SJCX22_0996]
FX This work was supported by the National Natural Science Foundation of
   China (62172229), the Natural Science Foundation of Jiangsu Province
   (BK20211294, BK20211295), and the Postgraduate Research & Practice
   Innovation Program of Jiangsu Province (SJCX22_0996).
CR Azimi SM, 2019, LECT NOTES COMPUT SC, V11363, P150, DOI 10.1007/978-3-030-20893-6_10
   Chen SQ, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10060820
   Chen ST, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091356
   Cheng G, 2014, ISPRS J PHOTOGRAMM, V98, P119, DOI 10.1016/j.isprsjprs.2014.10.002
   Cheng X, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13193871
   Chu X, 2017, PROC CVPR IEEE, P5669, DOI 10.1109/CVPR.2017.601
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding K, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3035844
   Fu K, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11182095
   Guo W, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010131
   Han XB, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9070666
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hou J., 2020, J. Phys., Conf. Ser., V1544
   Hu Hu J. J., P IEEE C COMPUTER VI, P1
   Li CZ, 2019, IEEE IMAGE PROC, P3886, DOI [10.1109/icip.2019.8803521, 10.1109/ICIP.2019.8803521]
   Li K, 2020, ISPRS J PHOTOGRAMM, V159, P296, DOI 10.1016/j.isprsjprs.2019.11.023
   Li K, 2018, IEEE T GEOSCI REMOTE, V56, P2337, DOI 10.1109/TGRS.2017.2778300
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Qiu HQ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11131594
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren Y, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10091470
   Sun P, 2020, IEEE T GEOSCI REMOTE, V58, P7154, DOI 10.1109/TGRS.2020.2980023
   Wang JW, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11242930
   Wang PJ, 2020, IEEE T GEOSCI REMOTE, V58, P3377, DOI 10.1109/TGRS.2019.2954328
   Wang WH, 2019, IEEE I CONF COMP VIS, P8439, DOI 10.1109/ICCV.2019.00853
   Wei XS, 2019, PATTERN RECOGN, V88, P113, DOI 10.1016/j.patcog.2018.10.022
   Wei Y, 2018, P EUROPEAN C COMPUTE
   Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418
   Xu CY, 2020, IEEE T GEOSCI REMOTE, V58, P4353, DOI 10.1109/TGRS.2019.2963243
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu ZZ, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121312
   Yan DC, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13112052
   Yan JQ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030286
   Yang F, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061686
   Yang K, 2019, IEEE I CONF COMP VIS, P8371, DOI 10.1109/iccv.2019.00846
   Yang X, 2004, arXiv preprint arXiv 2020, P13316
   Yang X, 2019, IEEE I CONF COMP VIS, P8231, DOI 10.1109/ICCV.2019.00832
   Zhang GJ, 2019, IEEE T GEOSCI REMOTE, V57, P10015, DOI 10.1109/TGRS.2019.2930982
   Zhang XD, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11070755
   Zhao W, 2019, IEEE ACCESS, V7, P43607, DOI 10.1109/ACCESS.2019.2908016
   Zhu F, 2017, PROC CVPR IEEE, P2027, DOI 10.1109/CVPR.2017.219
NR 42
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 5
PY 2023
DI 10.1007/s11042-023-16973-8
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ4I6
UT WOS:001156484900002
DA 2024-07-18
ER

PT J
AU Kushwah, V
   Agrawal, P
AF Kushwah, Varsha
   Agrawal, Pragati
TI Decomposition techniques and long short term memory model with black
   widow optimization for stock price prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Time series; Stock market forecasting; LSTM model; Black widow
   optimization; Empirical mode decomposition; Local mode decomposition
ID HYBRID MODEL; ARIMA; ALGORITHM; MARKETS; SYSTEM
AB Accurate stock price prediction is a trivial task because of the highly non-linear nature of the time series of stock prices. Numerous time series decomposition methods are applied to manage the extensively non-linear nature of the time series data, which decomposes the non-linear time series into linear components. This paper decomposes non-linear and non-stationary time series data into linear components by the joint decomposition method, namely empirical mode decomposition and local mean decomposition. By using the joint decomposition technique, we can better address potential issues such as mode mixing or the loss of information that may arise when using individual EMD or LMD. This leads to a more accurate and reliable analysis of the signal, improving the quality of the results obtained. The empirical mode decomposition is applied to the initial stock price data to generate distinct intrinsic mode functions. The local mean decomposition is applied to each intrinsic mode function to find a series of the product of functions. The forecasting model, long short-term memory is used for each product of function along with weight optimization techniques to achieve precise predictions for the time series. For optimizing the weight of the LSTM model, the black widow optimization technique is used. The forecast series of each product of function is aggregated to obtain the final series. The efficiency of the proposed hybrid technique is evaluated through the mean absolute error, root mean square error, and mean absolute percentage error. Our results demonstrate the proposed model yields the best performance and outperforms the existing forecasting models with respect to accuracy and efficiency. The proposed model EMD-LMD-LSTM-BWO enhances the performance of the LSTM model. In comparison to the LSTM, LSTM-BWO, EMD-LSTM, EMD-LSTM-BWO, and EMD-LMD-LSTM models, the proposed model has a percentage improvement of 89.03, 88.06, 73.81, 73.01, and 15.78, respectively, when mean absolute error values are taken into account.
C1 [Kushwah, Varsha; Agrawal, Pragati] Maulana Azad Natl Inst Technol, Dept Comp Sci & Engn, Bhopal 462003, Madhya Pradesh, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal
RP Kushwah, V (corresponding author), Maulana Azad Natl Inst Technol, Dept Comp Sci & Engn, Bhopal 462003, Madhya Pradesh, India.
EM vk8415@gmail.com; pragati.a.in@ieee.org
RI kushwah, varsha/ACO-4898-2022
OI kushwah, varsha/0000-0002-0420-9931
CR Adebiyi AA, 2014, UKSIM INT CONF COMP, P106, DOI 10.1109/UKSim.2014.67
   Ali M, 2020, J HYDROL, V584, DOI 10.1016/j.jhydrol.2020.124647
   Ballings M, 2015, EXPERT SYST APPL, V42, P7046, DOI 10.1016/j.eswa.2015.05.013
   Bathla G, 2023, MULTIMED TOOLS APPL, V82, P9727, DOI 10.1007/s11042-022-12390-5
   Blau BM, 2017, J BANK FINANC, V76, P32, DOI 10.1016/j.jbankfin.2016.11.026
   Büyüksahin ÜÇ, 2019, NEUROCOMPUTING, V361, P151, DOI 10.1016/j.neucom.2019.05.099
   Chang TS, 2011, EXPERT SYST APPL, V38, P14846, DOI 10.1016/j.eswa.2011.05.063
   Chen XJ, 2021, RENEW ENERG, V165, P595, DOI 10.1016/j.renene.2020.11.038
   Cheng CH, 2018, NEUROCOMPUTING, V302, P33, DOI 10.1016/j.neucom.2018.04.014
   COLORNI A, 1992, FROM ANIM ANIMAT, P134
   Demirhan H, 2018, APPL ENERG, V225, P998, DOI 10.1016/j.apenergy.2018.05.054
   Dragomiretskiy K, 2014, IEEE T SIGNAL PROCES, V62, P531, DOI 10.1109/TSP.2013.2288675
   Fei SW, 2015, INT J ELEC POWER, V73, P625, DOI 10.1016/j.ijepes.2015.04.019
   Hayyolalam V, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103249
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Huang Shian-Chang, 2017, Global Business and Finance Review, V22, P32, DOI 10.17549/gbfr.2017.22.3.32
   Islam Md Saiful., 2020, Soft Computing Letters, page, P100009, DOI [10.1016/j.socl.2020.100009, DOI 10.1016/J.SOCL.2020.100009]
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Ji L, 2019, PROCEDIA COMPUT SCI, V162, P33, DOI 10.1016/j.procs.2019.11.254
   Jiang M, 2022, Ann Oper Res, P1
   Karaboga D., 2005, Technical Report-TR06
   Lee SW, 2020, EXPERT SYST APPL, V161, DOI 10.1016/j.eswa.2020.113704
   Liu H, 2020, DIGIT SIGNAL PROCESS, V102, DOI 10.1016/j.dsp.2020.102741
   Liu JNK, 2013, NEURAL COMPUT APPL, V22, pS143, DOI 10.1007/s00521-012-0969-3
   Liu M, 2021, EXPERT SYST APPL, V179, DOI 10.1016/j.eswa.2021.115078
   Luo LQ, 2021, APPL MATH MODEL, V89, P49, DOI 10.1016/j.apm.2020.07.019
   MCQUEEN G, 1991, J FINANC, V46, P239, DOI 10.2307/2328695
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Moghar A, 2020, PROCEDIA COMPUT SCI, V170, P1168, DOI 10.1016/j.procs.2020.03.049
   Narendra Babu C., 2015, Applied Computing and Informatics, V11, P130, DOI 10.1016/j.aci.2014.09.002
   Nayak SC, 2017, AIN SHAMS ENG J, V8, P371, DOI 10.1016/j.asej.2015.07.015
   Niu T, 2018, RENEW ENERG, V118, P213, DOI 10.1016/j.renene.2017.10.075
   Nourbakhsh Z, 2023, MULTIMED TOOLS APPL, V82, P17769, DOI 10.1007/s11042-022-13963-0
   Nyberg H, 2013, J BANK FINANC, V37, P3351, DOI 10.1016/j.jbankfin.2013.05.008
   Pyo S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0188107
   Rezaei H, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114332
   Sang C., 2019, The Journal of Finance and Data Science, V5, P1, DOI DOI 10.1016/J.JFDS.2018.10.003
   Sezer OB, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106181
   Sim N, 2015, J BANK FINANC, V55, P1, DOI 10.1016/j.jbankfin.2015.01.013
   Singh R, 2017, MULTIMED TOOLS APPL, V76, P18569, DOI 10.1007/s11042-016-4159-7
   Smith JS, 2005, J ROY SOC INTERFACE, V2, P443, DOI 10.1098/rsif.2005.0058
   Symitsi E, 2018, J BANK FINANC, V96, P153, DOI 10.1016/j.jbankfin.2018.08.013
   Talarposhti FM, 2016, INT J APPROX REASON, V70, P79, DOI 10.1016/j.ijar.2015.12.011
   Tian ZD, 2020, ENG APPL ARTIF INTEL, V91, DOI 10.1016/j.engappai.2020.103573
   Vanli ND, 2016, DIGIT SIGNAL PROCESS, V48, P226, DOI 10.1016/j.dsp.2015.08.009
   Vlasenko Alexander, 2020, 2020 IEEE Third International Conference on Data Stream Mining & Processing (DSMP), P112, DOI 10.1109/DSMP47368.2020.9204179
   Wang Y, 2020, CHINA COMMUN, V17, P205, DOI 10.23919/JCC.2020.03.017
   Wu JMT, 2023, MULTIMEDIA SYST, V29, P1751, DOI 10.1007/s00530-021-00758-w
   Yamaguchi K, 2008, ECOL ECON, V68, P345, DOI 10.1016/j.ecolecon.2008.04.004
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Yoon WJ, 2014, DIGIT SIGNAL PROCESS, V29, P35, DOI 10.1016/j.dsp.2013.09.011
   Zhang Y, 2020, IEEE ACCESS, V8, P19033, DOI 10.1109/ACCESS.2020.2966827
   Zhang YT, 2022, J CLEAN PROD, V354, DOI 10.1016/j.jclepro.2022.131724
   Zhang YA, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113609
NR 54
TC 0
Z9 0
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 30
PY 2023
DI 10.1007/s11042-023-17062-6
EA SEP 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T4DY8
UT WOS:001077522300009
DA 2024-07-18
ER

PT J
AU Yaghoubi, N
   Masumi, H
   Fatehi, MH
   Ashtari, F
   Kafieh, R
AF Yaghoubi, Neda
   Masumi, Hassan
   Fatehi, Mohammad Hossein
   Ashtari, Fereshteh
   Kafieh, Rahele
TI Deep learning and classic machine learning models in the automatic
   diagnosis of multiple sclerosis using retinal vessels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multiple sclerosis; Feature extraction; Scanning laser ophthalmoscopy;
   Transfer learning model; Vessel; Segmentation; Magnetic resonance
   imaging; Machine learning
ID OPTICAL COHERENCE TOMOGRAPHY
AB This study aims to automatically detect multiple sclerosis (MS) in terms of the changes in retinal vessels using Scanning laser ophthalmoscopy (SLO) images. Although much research has been done to diagnose MS patients, these diagnostic techniques have always been based on using Magnetic resonance imaging (MRI) images which cannot be a complete technique in diagnosing this disease. Using SLO images and examining the condition of its vessels using computer technology, biomarkers in the vessel can be identified to help diagnose MS patients. However, in the first step, the color images are converted to gray and after that are improved using a combination of algorithm Tylor Coye and DWT, then, the images are segmented and retinal vessels are extracted. Besides, two different techniques are used in classification stage. In the first technique, classic Machine learning different features are extracted from the resulting regions and entered into several multiple classifiers, the results of which give us an accuracy of 72%, moreover in the second technique segmented images enter the transfer learning model and ultimately lead us to 98% accuracy in the distinction between MS patients and Healthy Controls (HCs).
C1 [Yaghoubi, Neda; Masumi, Hassan] Islamic Azad Univ, Dept Biomed Engn, Kazerun Branch, Kazerun, Iran.
   [Fatehi, Mohammad Hossein] Islamic Azad Univ, Dept Elect Engn, Kazerun Branch, Kazerun, Iran.
   [Ashtari, Fereshteh] Isfahan Univ Med Sci, Isfahan Neurosci Res Ctr, Esfahan, Iran.
   [Kafieh, Rahele] Isfahan Univ Med Sci, Med Image & Signal Proc Res Ctr, Sch Adv Technol Med, Esfahan, Iran.
   [Kafieh, Rahele] Univ Durham, Dept Engn, South Rd, Durham DH1 3LE, England.
C3 Islamic Azad University; Islamic Azad University; Isfahan University
   Medical Science; Isfahan University Medical Science; Durham University
RP Kafieh, R (corresponding author), Isfahan Univ Med Sci, Med Image & Signal Proc Res Ctr, Sch Adv Technol Med, Esfahan, Iran.; Kafieh, R (corresponding author), Univ Durham, Dept Engn, South Rd, Durham DH1 3LE, England.
EM rkafeih@gmail.com
RI Yaghoubi, Neda/KIG-0860-2024; kafieh, rahele/E-6456-2012
OI Yaghoubi, Neda/0000-0002-1254-4780; Fatehi, Mohammad
   H./0000-0001-9100-3618; , Rahele/0009-0004-6316-9812; kafieh,
   rahele/0000-0003-0087-9476
FU Lastly, I would be remiss in not mentioning my family, especially my
   parents, spouse, and my kid. Their belief in me has kept my spirits and
   motivation high during this process.
FX Words cannot express my gratitude to my professors for their invaluable
   patience and feedback. I also could not have undertaken this journey,
   who generously provided knowledge and expertise.r Lastly, I would be
   remiss in not mentioning my family, especially my parents, spouse, and
   my kid. Their belief in me has kept my spirits and motivation high
   during this process.
CR Arsalan M, 2022, EXPERT SYST APPL, V200, DOI 10.1016/j.eswa.2022.117009
   Bartosik A., 2021, The Era of Artificial Intelligence, Machine Learning, and Data Science in the Pharmaceutical Industry-Chapter 7-Evaluating safety and toxicity, DOI [10.1016/B978-0-12-820045-2.00008-8, DOI 10.1016/B978-0-12-820045-2.00008-8]
   Bhaduri B, 2016, BIOMED OPT EXPRESS, V7, P2321, DOI 10.1364/BOE.7.002321
   Bhattacharya S, 2019, SCIENCE OF HORMESIS IN HEALTH AND LONGEVITY, P35, DOI [10.1016/B978-0-12-814253-0.00003-6, 10.1007/978-981-13-2414-7_4]
   Branco D, 2022, SOFT COMPUT, V26, P12041, DOI 10.1007/s00500-022-07503-z
   Cavaliere C, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235323
   Dash S, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101740
   Eslami M, 2022, BRAIN SCI, V12, DOI 10.3390/brainsci12091140
   Ettema AR, 2021, J BREATH RES, V15, DOI 10.1088/1752-7163/abd080
   Fiorini S, 2015, IEEE ENG MED BIO, P4443, DOI 10.1109/EMBC.2015.7319381
   Hastie T., 2009, ELEMENTS STAT LEARNI, P485, DOI DOI 10.1007/978-0-387-84858-7_7
   Hastie T., 2009, Springer Series in Statistics, P337, DOI DOI 10.1007/978-0-387-84858-7_10
   Hollemans M., 2018, MobileNet version 2
   ImageNet, ABOUT US
   Jiang H, 2020, AM J OPHTHALMOL, V213, P34, DOI 10.1016/j.ajo.2019.12.021
   K-Nearest Neighbor (KNN), Algorithm for Machine Learning
   Kawahara JG, 2013, Spinal cord segmentation and disability prediction in multiple sclerosis using novel optimization and machine learning methods
   Kenney R.C., 2022, Neurology, V99, P1100
   Khodabandeh Z, 2022, PREPRINT
   Kim JK, 1999, IEEE T MED IMAGING, V18, P231, DOI 10.1109/42.764896
   La Rosa F, 2019, LECT NOTES COMPUT SC, V11383, P142, DOI 10.1007/978-3-030-11723-8_14
   Lötsch J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-33077-8
   López-Dorado A, 2021, INFORM FUSION, V76, P157, DOI 10.1016/j.inffus.2021.05.006
   mathworks, MobileNet v2
   mathworks, dwt2
   Mazumder R, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0107620
   Mohseni E, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5430528
   Montolio A, 2022, ANN BIOMED ENG, V50, P507, DOI 10.1007/s10439-022-02930-3
   Olatunji Sunday O, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20054261
   Piryonesi SM, 2020, J INFRASTRUCT SYST, V26, DOI 10.1061/(ASCE)IS.1943-555X.0000512
   Princye PH, 2018, Biomed Res, P0970
   RIDLER TW, 1978, IEEE T SYST MAN CYB, V8, P630, DOI 10.1109/tsmc.1978.4310039
   Sarbaz Y, 2017, BIOMED ENG-APP BAS C, V29, DOI 10.4015/S1016237217500466
   Schwab P, 2021, IEEE J BIOMED HEALTH, V25, P1284, DOI 10.1109/JBHI.2020.3021143
   Setiawan W., 2016, Int J Adv Eng Manag Sci, V2, P1
   Sharp PF, 2004, PHYS MED BIOL, V49, P1085, DOI 10.1088/0031-9155/49/7/001
   Shi ZJ, 2021, INT J NUMER METH BIO, V37, DOI 10.1002/cnm.3460
   Singh A, 2019, Medium, Analytics Vidhya, V4
   Tyler C, 2016, MATLAB Cent. File Exch.
   Velázquez-Rodríguez C, 2023, SCI COMPUT PROGRAM, V227, DOI 10.1016/j.scico.2023.102941
   Wang XG, 2014, BRIT J OPHTHALMOL, V98, P1368, DOI 10.1136/bjophthalmol-2013-304547
   Wilhelm H, 2015, DTSCH ARZTEBL INT, V112, P616, DOI 10.3238/arztebl.2015.0616
   Wu XY, 2017, AER ADV ENG RES, V114, P50
   Zaki S.Z.M., 2020, IAES INT J ARTIF INT, V9, P290, DOI [DOI 10.11591/IJAI.V9.I2.PP290-296, 10.11591/ijai.v9.i2]
NR 44
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 30
PY 2023
DI 10.1007/s11042-023-16812-w
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T4DY8
UT WOS:001077522300007
DA 2024-07-18
ER

PT J
AU Malik, A
   Jadav, S
   Gupta, S
AF Malik, Anjali
   Jadav, Sunil
   Gupta, Shailender
TI A multilevel qubit encryption mechanism using SHA-512
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Bit plane Scrambling; Block Cipher; Confusion; Cryptanalysis;
   Cryptography; Diffusion; Encryption; Quantum Chaotic map; SHA-512
   (Secure Hash Algorithm-512)
ID IMAGE ENCRYPTION; SCHEME
AB One of the leading causes of concern with the advancement of cyber technologies is the increasing number of data and security breaches, especially given the amount of tools and information available at the disposal of anyone, let alone someone with malicious intent. This article presents a highly secure, secret, and robust data communication network mechanism. Confusion, diffusion mechanisms, and a key generation method are all components of a sound encryption scheme. All three of these factors are chosen carefully to maximise entropy, key space, execution speed, and resistance to differential and statistical attacks, as well as cryptographic analysis. The encryption approach used in the proposed work is a unique key generated using a high randomness and non-periodic quantum chaotic map in conjunction with hash function to ensure the key is unique. As a result, the mechanism is prone to resist differential attacks. Confusion is accomplished through the use of the Substitution process, permutation of bit values, and random bit plane scrambling. The substitution and bit permutation operations, both of which are matching, are chosen for their rapid speed of execution. Depending on the conditions, the folding technique is applied in two ways during the diffusion process, ensuring a high-security mechanism. The proposed mechanism is compared to state-of-the-art mechanisms, and it is argued that some outcomes are much improved over others, while others are comparable to other procedures.
C1 [Malik, Anjali; Jadav, Sunil; Gupta, Shailender] J C Bose Univ Sci & Technol, YMCA, Faridabad, Haryana, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Malik, A (corresponding author), J C Bose Univ Sci & Technol, YMCA, Faridabad, Haryana, India.
EM anjalimalik0611@gmail.com; suniljadav1@gmail.com; shailender81@gmail.com
RI gupta, shailender/Y-8231-2019
OI gupta, shailender/0000-0003-1383-7152; Jadav, Sunil/0000-0002-7833-4196
CR Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Ahmed HEDH, 2007, 2007 INT C EL ENG, P1
   Akhshani A, 2012, COMMUN NONLINEAR SCI, V17, P4653, DOI 10.1016/j.cnsns.2012.05.033
   Alexan W, 2023, IEEE ACCESS, V11, P11541, DOI 10.1109/ACCESS.2023.3242311
   Bansal R, 2017, MULTIMED TOOLS APPL, V76, P16529, DOI 10.1007/s11042-016-3926-9
   Barker E, 2017, NIST Special Publication (SP) 800-67 Rev. 2 (Draft))
   Basu Sandipan., 2011, Journal of global research in Computer Science, V2, P116
   Clement J., 2020, Cyber crime: number of breaches and records exposed 2005-2020
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Hanchinamani G, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0062-7
   Kester QA, 2013, Arxiv, DOI arXiv:1307.7786
   Kumari M, 2021, MULTIMED TOOLS APPL, V80, P33213, DOI 10.1007/s11042-021-11178-3
   Kumari M, 2020, MULTIMED TOOLS APPL, V79, P33161, DOI 10.1007/s11042-020-09627-6
   Kumari M, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0162-2
   Liu H, 2017, 3D RES, V8, DOI 10.1007/s13319-016-0114-7
   Liu XB, 2019, IEEE ACCESS, V7, P6937, DOI 10.1109/ACCESS.2018.2889896
   Malik A, 2021, MULTIMED TOOLS APPL, V80, P21521, DOI 10.1007/s11042-021-10670-0
   Malik A, 2021, MULTIMED TOOLS APPL, V80, P7911, DOI 10.1007/s11042-020-09973-5
   Mandal S., 2014, INT J INNOV RES ADV, V1, P102
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Mousa A., 2006, Int. J. Comput. Sci. Appl., V3, P44
   Rayarikar R., 2012, Int J Comput Appl, V50, P12
   Rivest R. L., 1994, INT WORKSH FAST SOFT, P86, DOI [10.1007/3-540-60590-8_7, DOI 10.1007/3-540-60590-8_7]
   Sam IS, 2012, NONLINEAR DYNAM, V69, P1995, DOI 10.1007/s11071-012-0402-6
   Sam IS, 2012, MULTIMED TOOLS APPL, V56, P315, DOI 10.1007/s11042-010-0652-6
   SCHNEIER B, 1994, DR DOBBS J, V19, P38
   Song YJ, 2019, IEEE ACCESS, V7, P84386, DOI 10.1109/ACCESS.2019.2923018
   Velmurugan T., 2020, J Comput Sci, V16, P1439, DOI [10.3844/jcssp.2020.1439.1450, DOI 10.3844/JCSSP.2020.1439.1450]
   Ye GD, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500104
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-1902-1
NR 30
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 28
PY 2023
DI 10.1007/s11042-023-16613-1
EA SEP 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM7
UT WOS:001076639200008
DA 2024-07-18
ER

PT J
AU Tuli, K
   Malhotra, M
AF Tuli, Krishan
   Malhotra, Manisha
TI Optimal Meta-Heuristic Elastic Scheduling (OMES) for VM selection and
   migration in cloud computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Artificial Bee Colony (ABC); Cloud computing; Energy consumption;
   Service Level Agreements (SLAs); Virtual Machine (VM)
ID VIRTUAL MACHINE CONSOLIDATION; ANT COLONY SYSTEM; DATA CENTERS;
   ENERGY-EFFICIENT; DYNAMIC CONSOLIDATION; PLACEMENT STRATEGY; AWARE;
   ALGORITHM; OPTIMIZATION; ALLOCATION
AB Virtualization is a powerful technique that allows numerous applications can execute on a single cloud server. The process is carried out by cramming software into Virtual Machines (VMs), so that many programs may execute in parallel which leads to an increase in speed. It reduces the overall cost of the cloud data centers by applying migration, and load balancing techniques on the virtual machines. However, the associated energy consumption and Service Level Agreement (SLA) breaches have been extremely high because of increased network traffic and the bandwidth requirements of the applications. To address this issue, the current study presented a novel approach based on the food selection technique used by honey bees to allocate and utilize resources to the VMs. The proposed Optimal Meta-Heuristic Elastic Scheduling (OMES) integrates the Artificial Bee Colony algorithm with flower pollination to select VMs for specific clusters. The simulation is applied on 1000 VMs and analyzed based on VM migration, energy consumption, and SLA violation performance metrics. The comparative analysis performed against existing studies demonstrates highest unit improvement of 0.47 for VM migrations, 0.485 for power consumption, and 0.305 for SLA-V.
C1 [Tuli, Krishan; Malhotra, Manisha] Chandigarh Univ, Univ Inst Comp, Mohali, Punjab, India.
C3 Chandigarh University
RP Tuli, K (corresponding author), Chandigarh Univ, Univ Inst Comp, Mohali, Punjab, India.
EM mca.krishantuli@gmail.com; mmanishamalhotra@gmail.com
CR Arroba P, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.4067
   Arshad U, 2022, RENEW SUST ENERG REV, V167, DOI 10.1016/j.rser.2022.112782
   Barthwal Varun, 2022, International Journal of Cloud Applications and Computing, V12, P1, DOI 10.4018/IJCAC.2022010103
   Beloglazov Anton, 2010, Proceedings 2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing (CCGrid), P826, DOI 10.1109/CCGRID.2010.46
   Beloglazov A, 2013, IEEE T PARALL DISTR, V24, P1366, DOI 10.1109/TPDS.2012.240
   Cho KM, 2015, NEURAL COMPUT APPL, V26, P1297, DOI 10.1007/s00521-014-1804-9
   Dashti SE, 2016, J EXP THEOR ARTIF IN, V28, P97, DOI 10.1080/0952813X.2015.1020519
   Ferdaus MH, 2014, LECT NOTES COMPUT SC, V8632, P306, DOI 10.1007/978-3-319-09873-9_26
   Ferreto TC, 2011, FUTURE GENER COMP SY, V27, P1027, DOI 10.1016/j.future.2011.04.016
   Gao YQ, 2013, J COMPUT SYST SCI, V79, P1230, DOI 10.1016/j.jcss.2013.02.004
   Guo LZ, 2012, COMM COM INF SC, V308, P119
   Haibo Mi, 2010, 2010 IEEE 7th International Conference on Services Computing (SCC 2010), P514, DOI 10.1109/SCC.2010.69
   Hwang I, 2013, IEEE INT CONF CLOUD, P196, DOI 10.1109/CLOUD.2013.79
   Jiang JH, 2017, FUTURE GENER COMP SY, V74, P132, DOI 10.1016/j.future.2016.05.013
   Jing Xu, 2010, Proceedings of the 2010 IEEE/ACM Int'l Conference on Green Computing and Communications (GreenCom) and Int'l Conference on Cyber, Physical and Social Computing (CPSCom), P179, DOI 10.1109/GreenCom-CPSCom.2010.137
   Kansal NJ, 2016, J GRID COMPUT, V14, P327, DOI 10.1007/s10723-016-9364-0
   Karthikeyan K, 2020, J SUPERCOMPUT, V76, P3374, DOI 10.1007/s11227-018-2583-3
   Kumar S, 2022, INT J INTELL SYST, V37, P11764, DOI 10.1002/int.23062
   Le Sueur Etienne, 2010, Proceedings of the 2010 international conference on Power aware computing and systems, HotPower'10, P1, DOI DOI 10.5555/1924920.1924921
   Li HJ, 2016, COMPUTING, V98, P303, DOI 10.1007/s00607-015-0467-4
   Li XK, 2015, 2015 12TH INTERNATIONAL COMPUTER CONFERENCE ON WAVELET ACTIVE MEDIA TECHNOLOGY AND INFORMATION PROCESSING (ICCWAMTIP), P61, DOI 10.1109/ICCWAMTIP.2015.7493907
   Li X, 2013, MATH COMPUT MODEL, V58, P1222, DOI 10.1016/j.mcm.2013.02.003
   Li ZH, 2018, FUTURE GENER COMP SY, V80, P139, DOI 10.1016/j.future.2017.09.075
   Liu C, 2014, 2014 5TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING AND SERVICE SCIENCE (ICSESS), P272, DOI 10.1109/ICSESS.2014.6933561
   Liu FG, 2020, IEEE ACCESS, V8, P53, DOI 10.1109/ACCESS.2019.2961786
   Malekloo MH, 2018, SUSTAIN COMPUT-INFOR, V17, P9, DOI 10.1016/j.suscom.2018.02.001
   Masdari M, 2020, CLUSTER COMPUT, V23, P2629, DOI 10.1007/s10586-019-03032-x
   Nashaat H, 2019, J SUPERCOMPUT, V75, P3842, DOI 10.1007/s11227-019-02748-2
   Perumal B, 2016, ADV FUZZY SYST, V2016, DOI 10.1155/2016/6734161
   Riahi M, 2018, J SUPERCOMPUT, V74, P2984, DOI 10.1007/s11227-018-2348-z
   Satpathy A, 2018, COMPUT ELECTR ENG, V69, P334, DOI 10.1016/j.compeleceng.2017.12.032
   Shi L, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P499
   Singh Geeta, 2022, International Journal of Cloud Applications and Computing, DOI [10.4018/IJCAC.297095, 10.4018/IJCAC.311504]
   Singh S, 2023, ICT EXPRESS, V9, P92, DOI 10.1016/j.icte.2022.02.003
   Sinong Wang, 2013, 2013 IEEE Eighth International Conference on Networking, Architecture and Storage (NAS), P331, DOI 10.1109/NAS.2013.54
   Sofia AS, 2018, J NETW SYST MANAG, V26, P463, DOI 10.1007/s10922-017-9425-0
   Song WJ, 2014, IEEE T COMPUT, V63, P2647, DOI 10.1109/TC.2013.148
   Sutar SG, 2020, INT J SPEECH TECHNOL, V23, P79, DOI 10.1007/s10772-020-09682-2
   Talwani S, 2022, CMC-COMPUT MATER CON, V70, P3349, DOI 10.32604/cmc.2022.020473
   Tan MZ, 2017, IIP'17: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION PROCESSING, DOI 10.1145/3144789.3144792
   Tuli K., 2023, Int. J. Eng. Trends Technol, V71, P436, DOI [10.14445/22315381/IJETT-V71I4P237, DOI 10.14445/22315381/IJETT-V71I4P237]
   Verma G, 2022, WIRELESS PERS COMMUN, V124, P75, DOI 10.1007/s11277-021-09319-w
   Wang SG, 2016, IEEE T EMERG TOP COM, V4, P290, DOI 10.1109/TETC.2015.2508383
   Wang XL, 2014, FUTURE GENER COMP SY, V36, P91, DOI 10.1016/j.future.2013.12.004
   Wei-Tao Wen, 2015, 2015 Ninth International Conference on Frontier of Computer Science and Technology (FCST). Proceedings, P364, DOI 10.1109/FCST.2015.41
   Xu B, 2015, SOFT COMPUT, V19, P2265, DOI 10.1007/s00500-014-1406-6
   Yavari M, 2019, J CLOUD COMPUT-ADV S, V8, DOI 10.1186/s13677-019-0136-9
   Yousefipour A, 2018, SOFTWARE PRACT EXPER, V48, P1758, DOI 10.1002/spe.2585
   Zhang F, 2018, IEEE COMMUN SURV TUT, V20, P1206, DOI 10.1109/COMST.2018.2794881
   Zhang JT, 2014, IEEE IPCCC
   Zhang JT, 2016, J NETW COMPUT APPL, V64, P23, DOI 10.1016/j.jnca.2015.12.018
   Zhang PY, 2020, IEEE T AUTOM SCI ENG, V17, P1725, DOI 10.1109/TASE.2020.2975225
NR 52
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 26
PY 2023
DI 10.1007/s11042-023-16820-w
EA SEP 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S5NV5
UT WOS:001071641500001
DA 2024-07-18
ER

PT J
AU Rashid, J
   Qaisar, BS
   Faheem, M
   Akram, A
   Amin, RU
   Hamid, M
AF Rashid, Javed
   Qaisar, Bilal Shabbir
   Faheem, Muhammad
   Akram, Arslan
   Amin, Riaz ul
   Hamid, Muhammad
TI Mouth and oral disease classification using InceptionResNetV2 method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE InceptionResNetV2; Mouth diseases; Mouth and oral diseases dataset; Oral
   diseases; Teeth diseases
ID CONVOLUTIONAL NEURAL-NETWORK; AUTOMATIC DETECTION; TEETH
AB Digital tools have greatly improved the detection and diagnosis of oral and dental disorders like cancer and gum disease. Lip or oral cavity cancer is more likely to develop in those with potentially malignant oral disorders. A potentially malignant disorder (PMD) and debilitating condition of the oral mucosa, oral submucous fibrosis (OSMF), can have devastating effects on one's quality of life. Incorporating deep learning into diagnosing conditions affecting the mouth and oral cavity is challenging. Mouth and Oral Diseases Classification using InceptionResNetV2 Method was established in the current study to identify diseases such as gangivostomatitis (Gum), canker sores (CaS), cold sores (CoS), oral lichen planus (OLP), oral thrush (OT), mouth cancer (MC), and oral cancer (OC). The new collection, termed "Mouth and Oral Diseases" (MOD), comprises seven distinct categories of data. Compared to state-of-the-art approaches, the proposed InceptionResNetV2 model's 99.51% accuracy is significantly higher.
C1 [Rashid, Javed] Univ Okara, Dept IT Serv, Okara 56310, Pakistan.
   [Qaisar, Bilal Shabbir] Islam Int Univ, Dept CS&SE, Islamabad 44000, Pakistan.
   [Rashid, Javed; Qaisar, Bilal Shabbir; Akram, Arslan; Amin, Riaz ul] MLC Lab, Meharban House,House 209, Okara 56300, Pakistan.
   [Qaisar, Bilal Shabbir; Amin, Riaz ul] Univ Okara, Dept CS, Okara 56310, Pakistan.
   [Faheem, Muhammad] Univ Vaasa, Sch Technol & Innovat, Vaasa 65200, Finland.
   [Akram, Arslan] Super Univ, Dept Comp Sci, Lahore 54000, Pakistan.
   [Hamid, Muhammad] Univ Veternary & Anim Sci, Dept Stat & Comp Sci, Lahore 54000, Pakistan.
C3 International Islamic University, Pakistan; University of Vaasa
RP Faheem, M (corresponding author), Univ Vaasa, Sch Technol & Innovat, Vaasa 65200, Finland.
EM muhammad.faheem@uwasa.fi
RI Hamid, Dr. Muhammad/AGI-5976-2022; Akram, Arslan/ACP-5597-2022; Rashid,
   Javed/ABD-1245-2022
OI Hamid, Dr. Muhammad/0000-0002-2440-6596; Akram,
   Arslan/0000-0001-9424-1697; Rashid, Javed/0000-0003-3416-9720; PhD,
   Muhammad Faheem,/0000-0003-4628-4486
FU University of Vaasa (UVA)
FX We acknowledge the assistance of MLC Lab, Okara, University of Okara,
   and the University of Vaasa without which this work could not have been
   completed and published.
CR Abdalla-Aslan R, 2020, OR SURG OR MED OR PA, V130, P593, DOI 10.1016/j.oooo.2020.05.012
   Aberin STA, 2018, I C HUMANOID NANOTEC, DOI 10.1109/HNICEM.2018.8666389
   Alalharith DM, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17228447
   Ali G, 2023, IEEE J TRANSL ENG HE, V11, P341, DOI 10.1109/JTEHM.2023.3282104
   Askar H, 2021, J DENT, V107, DOI 10.1016/j.jdent.2021.103615
   Balaei AT, 2017, IEEE ENG MED BIO, P3906, DOI 10.1109/EMBC.2017.8037710
   Becker AS, 2017, INVEST RADIOL, V52, P434, DOI 10.1097/RLI.0000000000000358
   Catharine, 2010, MED NEWS TOD
   Chan HF, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76763-2
   Chen H, 2021, INT J COMPUT ASS RAD, V16, P649, DOI 10.1007/s11548-021-02319-y
   Chen H, 2019, SCI REP-UK, V9, DOI [10.1038/s41598-018-36228-z, 10.1038/s41598-019-40414-y]
   Ekert T, 2019, J ENDODONT, V45, P917, DOI 10.1016/j.joen.2019.03.016
   Gezgin O, 2018, NIGER J CLIN PRACT, V21, P156, DOI 10.4103/njcp.njcp_399_16
   Gomes Rita Fabiane Teixeira, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20053894
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hefti AF, 1997, CRIT REV ORAL BIOL M, V8, P336, DOI 10.1177/10454411970080030601
   Jaiswal P, 2022, J ADV COMPUT SCI, VAppl13
   Khan AA., 2015, JPDA, V25, P1
   Khan HA, 2021, OR SURG OR MED OR PA, V131, P711, DOI 10.1016/j.oooo.2020.08.024
   Kuwana R, 2021, DENTOMAXILLOFAC RAD, V50, DOI 10.1259/dmfr.20200171
   Larissa Hirsch M, 2018, KIDSHEALTH PARENTS M
   Lee JH, 2018, J DENT, V77, P106, DOI 10.1016/j.jdent.2018.07.015
   Lee JH, 2018, J PERIODONTAL IMPLAN, V48, P114, DOI 10.5051/jpis.2018.48.2.114
   Li Z, 2019, INT J IMAG SYST TECH, V29, P577, DOI 10.1002/ima.22337
   Liu LZ, 2020, IEEE J BIOMED HEALTH, V24, P898, DOI 10.1109/JBHI.2019.2919916
   Mahdi FP, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-75887-9
   Martins JNR, 2018, QUINTESSENCE INT, V49, P103, DOI 10.3290/j.qi.a39508
   Mcdowell D, 2022, WAYZATA DENT
   OSBORN JB, 1992, J PERIODONTOL, V63, P283, DOI 10.1902/jop.1992.63.4.283
   Park S, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12071518
   Preshaw PM, 2015, BMC ORAL HEALTH, V15, DOI 10.1186/1472-6831-15-S1-S5
   Rana A, 2017, 2017 IEEE-NIH HEALTHCARE INNOVATIONS AND POINT OF CARE TECHNOLOGIES (HI-POCT), P144, DOI 10.1109/HIC.2017.8227605
   Rashid J, 2023, CMC-COMPUT MATER CON, V74, P1235, DOI 10.32604/cmc.2023.032005
   Rashid J, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10172064
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schwendicke F, 2019, J DENT, V91, DOI 10.1016/j.jdent.2019.103226
   Seirawan S, 2021, UNNUS
   Singha Deo B, 2022, MEDRXIV, P2022
   Sohail M, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12010088
   Sonavane Apurva, 2021, IOP Conference Series: Materials Science and Engineering, V1022, DOI 10.1088/1757-899X/1022/1/012116
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Watanabe H, 2021, ORAL RADIOL, V37, P487, DOI 10.1007/s11282-020-00485-4
   Xie HT, 2019, PATTERN RECOGN, V85, P109, DOI 10.1016/j.patcog.2018.07.031
NR 43
TC 4
Z9 4
U1 8
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33903
EP 33921
DI 10.1007/s11042-023-16776-x
EA SEP 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069514100013
OA hybrid
DA 2024-07-18
ER

PT J
AU Rajput, D
   Bejoy, BJ
AF Rajput, Darshana
   Bejoy, B. J.
TI Optimized deep maxout for breast cancer detection: consideration of
   pre-treatment and in-treatment aspect
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy filter; Smell indulged shuffled shepherd optimization (SSISSO);
   Hierarchical DBSCAN (density-based clustering algorithm); Shark
   optimized deep Maxout neural network; CT images
AB Breast cancer is one of the deadliest diseases, accounting for the second-highest rate of cancer mortality among females. Breast tissue begins to develop cancerous, malignant lumps as the disease progresses. Self-examinations and routine clinical checks aid in early diagnosis, which considerably increases the likelihood of survival. Because of this, we have created a revolutionary method for finding breast cancer that has the following four steps. Fuzzy filters are used in the initial pre-processing stage to reduce noise and improve outcomes from the incoming data. In the second stage, we have presented an Improved Hierarchical DBSCAN (Density-based clustering algorithm) for the segmentation of anomalous areas. Feature extraction will be carried out following segmentation. We have also developed a better kurtosis-based feature to complement traditional statistical and shape-based features and deliver better results. The Optimized Deep Maxout Neural Network is used for classification in the final step, with the suggested Shark Smell Indulged Shuffled Shepherd Optimization used to optimize the weight parameter (SSISSO). At 90% the learning percentage of the proposed model SSISSO model has achieved 0.984391 accuracy, which is superior to 22.54%, 28.46%, 17.44%, 17%, 15.04%, 13.28%, 29.45%, 28.59%, 21.58%, and 30.72% as compared to other methods like SVM-BS1, CNN-BS7, LSTM, NN, Bi-GRU, RNN, ARCHO, AOA, HGS, CMBO, SSOA, and SSO. Finally, the results of the proposed breast cancer detection technique are compared with conventional techniques.
C1 [Rajput, Darshana; Bejoy, B. J.] CHRIST Deemed Univ, Sch Engn & Technol, Dept Comp Sci & Engn, Bangalore 560074, India.
C3 Christ University
RP Rajput, D (corresponding author), CHRIST Deemed Univ, Sch Engn & Technol, Dept Comp Sci & Engn, Bangalore 560074, India.
EM darshanar473@gmail.com
CR Alzu'bi A, 2021, MULTIMED TOOLS APPL, V80, P13787, DOI 10.1007/s11042-020-10448-w
   Andre Zeiser F, EXP SYST APPL, V185
   Beeravolu AR, 2021, IEEE ACCESS, V9, P33438, DOI 10.1109/ACCESS.2021.3058773
   Campello Ricardo J. G. B., 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference (PAKDD 2013). Proceedings, P160, DOI 10.1007/978-3-642-37456-2_14
   Demir F, 2021, BIOCYBERN BIOMED ENG, V41, P1123, DOI 10.1016/j.bbe.2021.07.004
   Esmael B., 2012, International Journal of Computer Information Systems and Industrial Management Applications, V4, P100
   Ghasemzadeh A, 2019, INT J MACH LEARN CYB, V10, P1603, DOI 10.1007/s13042-018-0837-2
   Guancong L, 2021, BIOMED SIGNAL PROCES, V70
   Gupta V, 2021, BIOCYBERN BIOMED ENG, V41, P1272, DOI 10.1016/j.bbe.2021.08.011
   Houssein EH, 2022, NEURAL COMPUT APPL, V34, P18015, DOI 10.1007/s00521-022-07445-5
   Islam Md Milon, 2020, SN Comput Sci, V1, P274, DOI 10.1007/s42979-020-00300-1
   Ivaturi A., 2020, 2020 INT C INT ENG M, P437
   Karthiga R, 2022, MATH COMPUT SIMULAT, V202, P316, DOI 10.1016/j.matcom.2022.05.038
   Kosmia L, 2021, 2021 IEEE 18 INT S B
   Kwan Hon K, 2003, P 2003 INT S CIRC SY, V4
   Muduli D, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.102919
   Nanda G, 2021, MEASUREMENT, V178
   Othmane D, 2020, 2020 3 INT C ADV COM
   Rohan TI, 2019, 2019 INT C COMP COMM, P1, DOI [10.1109/IC4ME247184.2019.9036697, DOI 10.1109/IC4ME247184.2019.9036697]
   Roy BR, 2020, 2 ICAICT, P28
   Sharma A., 2022, Int. J. Ambient Energy, V43, P8438
   Shu X, 2020, IEEE T MED IMAGING, V39, P2246, DOI 10.1109/TMI.2020.2968397
   Vaka AR, 2020, ICT EXPRESS, V6, P320, DOI 10.1016/j.icte.2020.04.009
   Wirth M.A., 2001, Shape analysis and measurement, P6320
   Yadav Samir S, 2022, MULTIMED TOOLS APPL, P1
   Yang XF, 2012, MED PHYS, V39, P5732, DOI 10.1118/1.4747526
   Zheng J, 2020, IEEE ACCESS, V8, P96946, DOI 10.1109/ACCESS.2020.2993536
NR 27
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 31017
EP 31047
DI 10.1007/s11042-023-16505-4
EA SEP 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066065600006
DA 2024-07-18
ER

PT J
AU Singh, S
   Ramkumar, KR
   Kukkar, A
AF Singh, Soni
   Ramkumar, K. R.
   Kukkar, Ashima
TI Deep adaptive CHIONet: designing novel herd immunity prediction of
   COVID-19 pandemic using hybrid RNN with LSTM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Herd immunity prediction; Deep learning; Optimal feature selection;
   Recurrent neural network; Long-short term memory and ACHIO
ID INFECTION; NETWORK
AB The rapid spread of COVID-19 threatened the entire world because of its adverse effects and high mortality rate. The most effective method of disease prevention is immunisation and vaccination. The development of herd immunity against any deadly virus will stop the pandemic. The main goal of this research is to develop an enhanced herd immunity prediction model for the COVID-19 pandemic. To develop a prediction model, a hybrid RNN and LSTM are combined with the proposed ACHIO. Feature extraction and feature selection methods are used to select the most important features that enhance the model's performance. Once the features are extracted using statistical methods, the optimal feature selection is performed by ACHIO. The selected features are then fed into the RNN and LSTM, and the epoch and neuron count in the RNN and LSTM is optimised using ACHIO to improve model performance. The proposed model achieved 90.42% accuracy, 80% precision, 90.86% specificity, 89.53% sensitivity, 86.03% F1-Score, 17.20% FDR, 90.86% NPV, 10.47% FNR, and 9.14% FPR. Various deep learning models, including DNN, RNN, CNN, RBM, LSTM, and RNN + LSTM, are compared to evaluate the performance of the proposed model. The results indicate that the proposed model performs better than the existing standard.
C1 [Singh, Soni] Lovely Profess Univ, Dept Comp Sci & Engn, Phagwara, Punjab, India.
   [Ramkumar, K. R.; Kukkar, Ashima] Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
C3 Lovely Professional University; Chitkara University, Punjab
RP Singh, S (corresponding author), Lovely Profess Univ, Dept Comp Sci & Engn, Phagwara, Punjab, India.
EM soni.30409@lpu.co.in; k.ramkumar@chitkara.edu.in; ashima@chitkara.edu.in
RI singh, soni/KIA-5457-2024
CR Al-Betar MA, 2021, NEURAL COMPUT APPL, V33, P5011, DOI 10.1007/s00521-020-05296-6
   Alweshah M, 2022, KNOWL-BASED SYST, V235, DOI 10.1016/j.knosys.2021.107629
   Anderson RM, 2020, LANCET, V396, P1614, DOI 10.1016/S0140-6736(20)32318-7
   Bethune Z., 2020, VETTED REAL TIME PAP, V11, P1
   Bicher M, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-06771-x
   Brett TS, 2020, P NATL ACAD SCI USA, V117, P25897, DOI 10.1073/pnas.2008087117
   Briffoteaux, 2020, OPTIMISING SOCIAL MI, DOI [10.1101/2020.08.25.20182162, DOI 10.1101/2020.08.25.20182162]
   Britton T, 2020, SCIENCE, V369, P846, DOI 10.1126/science.abc6810
   Cho K, 2022, J HYDROL, V605, DOI 10.1016/j.jhydrol.2021.127297
   Cihan P, 2021, APPL SOFT COMPUT, V111, DOI 10.1016/j.asoc.2021.107708
   Dalbah LM, 2022, J KING SAUD UNIV-COM, V34, P4782, DOI 10.1016/j.jksuci.2021.06.013
   Dubey AK, 2021, EVOL INTELL, V14, P909, DOI 10.1007/s12065-020-00477-7
   FINE PEM, 1993, EPIDEMIOL REV, V15, P265, DOI 10.1093/oxfordjournals.epirev.a036121
   Fontanet A, 2020, NAT REV IMMUNOL, V20, P583, DOI 10.1038/s41577-020-00451-5
   Georgette NT, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004168
   Gomes MGM, 2022, J THEOR BIOL, V540, DOI 10.1016/j.jtbi.2022.111063
   Clemente-Suárez VJ, 2020, VACCINES-BASEL, V8, DOI 10.3390/vaccines8020236
   John TJ, 2000, EUR J EPIDEMIOL, V16, P601, DOI 10.1023/A:1007626510002
   Kato S, 2011, LANDSC ECOL ENG, V7, P275, DOI 10.1007/s11355-010-0135-y
   Kemp F, 2021, J THEOR BIOL, V530, DOI 10.1016/j.jtbi.2021.110874
   Kodera S, 2023, VACCINES-BASEL, V11, DOI 10.3390/vaccines11030633
   Li ML, 2023, OPER RES, V71, P184, DOI 10.1287/opre.2022.2306
   MacIntyre CR, 2022, VACCINE, V40, P2506, DOI 10.1016/j.vaccine.2021.04.042
   Mijwil MM, 2021, Iraqi J. Sci., P2099, DOI 10.24996/ijs.2021.62.6.35
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Naderipour A, 2022, EXPERT SYST APPL, V187, DOI 10.1016/j.eswa.2021.115914
   Ndondo AM, 2021, RESULTS PHYS, V24, DOI 10.1016/j.rinp.2021.104096
   Omer SB, 2020, JAMA-J AM MED ASSOC, V324, P2095, DOI 10.1001/jama.2020.20892
   Park H, 2020, ENVIRON RESOUR ECON, V76, P665, DOI 10.1007/s10640-020-00439-8
   Rao R., 2016, Int J Ind Eng Comput, V7, P19, DOI [DOI 10.5267/J.IJIEC.2015.8.004, 10.5267/j.ijiec.2015.8.004]
   Rashid H, 2012, CURR OPIN INFECT DIS, V25, P243, DOI 10.1097/QCO.0b013e328352f727
   Sadr H, 2020, IEEE ACCESS, V8, P86984, DOI 10.1109/ACCESS.2020.2992063
   Sher T, 2023, CMC-COMPUT MATER CON, V74, P1561, DOI 10.32604/cmc.2023.032020
   Tetteh JNA, 2021, J THEOR BIOL, V531, DOI 10.1016/j.jtbi.2021.110894
   Ustebay S, 2023, INTERN EMERG MED, V18, P229, DOI 10.1007/s11739-022-03101-x
   Vaisakh T., 2020, EVOL INTELL, V1, P1
   Wang XX, 2019, ARAB J SCI ENG, V44, P3043, DOI 10.1007/s13369-018-3390-0
   Zain ZM, 2021, J CONTROL SCI ENG, V2021, DOI 10.1155/2021/8785636
NR 38
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29583
EP 29615
DI 10.1007/s11042-023-16719-6
EA SEP 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001064737700001
DA 2024-07-18
ER

PT J
AU Zhao, R
   Yu, XY
   Rong, XW
AF Zhao, Rui
   Yu, Xiaoyan
   Rong, Xianwei
TI Position attention optimized deep semantic segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic segmentation; PADSS; Position Attention Block; Channel
   Attention Block
AB Semantic segmentation can be applied in various fields of computer vision such as scene understanding. In order to assist intelligent machines to detect and recognize the objects, an optimal model to realize accurate semantic segmentation is urgently needed. However, labelling semantic objects in a complex scene is a challenging task due to the lack of more discriminative features. In this work, we solve the semantic segmentation task by proposing a Position Attention Optimized Deep Semantic Segmentation (PADSS) framework in the popular Discriminative Feature Network (DFN), which comprises the Smooth Network (SN) and Border Network (BN). Considering that different levels of feature possess distinct discriminative power, our PADSS framework embeds two types of attention blocks in the smooth network to select more discriminative features. Specifically, in the low stage of the network, we introduce the Position Attention Block (PAB) to obtain more effective features and strengthen the dependencies among similar features. Moreover, in the high stage of the network, the Channel Attention Block (CAB) is leveraged to gain richer context information. We incorporate PAB with CAB to make the prediction of semantic labels more accurate. The proposed model is validated on the two public benchmark datasets and the experimental results show that our PADSS outperforms its competitors and achieves the state-of-the-art (SOTA) performance 87.8% Mean IOU on PASCAL VOC 2012 and 80.8% Mean IOU on Cityscapes dataset. Results suggest that the proposed PADSS is robust enough to learn a variety of discriminative features over various semantic segmentation tasks.
C1 [Zhao, Rui; Yu, Xiaoyan; Rong, Xianwei] Harbin Normal Univ, Sch Phys & Elect Engn, Harbin 150025, Peoples R China.
C3 Harbin Normal University
RP Rong, XW (corresponding author), Harbin Normal Univ, Sch Phys & Elect Engn, Harbin 150025, Peoples R China.
EM rongxianwei@hrbnu.edu.cn
RI Yu, Xiaoyan/HCI-6544-2022
FU This work was supported by the National Natural Science Foundation of
   China under Grant 61401127, Natural Science Foundation of Heilongjiang
   Province under Grant LH2022F038, Cultivation Project of National Natural
   Science Foundation under Grant XPPY202208 [61401127]; National Natural
   Science Foundation of China [LH2022F038]; Natural Science Foundation of
   Heilongjiang Province [XPPY202208]; Cultivation Project of National
   Natural Science Foundation [HSDSSCX2019-29]; Graduate Innovation Fund of
   Harbin Normal University
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61401127, Natural Science Foundation of Heilongjiang
   Province under Grant LH2022F038, Cultivation Project of National Natural
   Science Foundation under Grant XPPY202208 and Graduate Innovation Fund
   of Harbin Normal University under Grant HSDSSCX2019-29.
CR Ali H, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420540269
   CHEN LC, 2017, ARXIV PREPRINT ARXIV, V1706, P5587, DOI DOI 10.48550/ARXIV.1706.05587
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Ding HH, 2018, PROC CVPR IEEE, P2393, DOI 10.1109/CVPR.2018.00254
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Fu Jun, 2019, IEEE Trans Image Process, DOI 10.1109/TIP.2019.2895460
   Garcia-Garcia A, 2017, ARXIV, DOI [10.48550/arXiv.1704.06857, DOI 10.48550/ARXIV.1704.06857]
   Ghiasi G, 2016, LECT NOTES COMPUT SC, V9907, P519, DOI 10.1007/978-3-319-46487-9_32
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li C, 2020, COMPUT GRAPH-UK, V90, P11, DOI 10.1016/j.cag.2020.05.003
   Li X, 2019, IEEE I CONF COMP VIS, P9166, DOI 10.1109/ICCV.2019.00926
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Liu W, 2015, COMPUT SCI, DOI DOI 10.48550/ARXIV.1506.04579
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849
   Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo P, 2017, IEEE I CONF COMP VIS, P2737, DOI 10.1109/ICCV.2017.296
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Tang C, 2021, IEEE T MULTIMEDIA, V23, P624, DOI 10.1109/TMM.2020.2985541
   Tang C, 2022, IEEE T PATTERN ANAL, V44, P955, DOI 10.1109/TPAMI.2020.3014629
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Yu C, 2018, EUR C COMP VIS, P33
   Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199
   Yu ZD, 2017, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2017.191
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhang ZL, 2018, LECT NOTES COMPUT SC, V11214, P273, DOI 10.1007/978-3-030-01249-6_17
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
NR 37
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29531
EP 29545
DI 10.1007/s11042-023-16022-4
EA SEP 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001081631900001
DA 2024-07-18
ER

PT J
AU Kolipaka, VRR
   Namburu, A
AF Kolipaka, Venkata Rama Rao
   Namburu, Anupama
TI An automatic crop yield prediction framework designed with two-stage
   classifiers: a meta-heuristic approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Agriculture; Crop yield prediction; Improved correlation; Two-stage
   classifiers; DOSP
ID CORONAVIRUS DISEASE COVID-19; X-RAY; IMAGE SYNTHESIS; CHEST CT
AB Agriculture is the main source of income for 75% of the Indian people. Weather, climate, and other natural factors have a higher influence on agricultural productivity. Forecasting crop yields is a very challenging issue for global food security. Forecasting crop yield based on the soil, environment, water, as well as crop parameters, is an important research field. Recently, many existing methods are presented to solve crop yield prediction. But, the performances of those models are inaccurate and suffered from errors. Hence, in this article, a deep learning-based system for agricultural production prediction based on environmental data is established. This research includes three stages, like pre-processing, feature extraction, and as well as prediction. The obtained raw data (environmental data) is pre-processed using a data cleaning technique to improve data quality prediction performance. The most dependable properties, such as statistical features, improved correlation, and mutual information-based features, are then retrieved from the pre-processed data. The yield predictors in the yield prediction phase are trained using these characteristics. Two-stage classifiers, stage-1 pre-prediction, and stage-2 final classification are used to represent the yield prediction phase. "Deep Belief Networks (DBN), Long Short Term Memory Networks (LSTM), and Recurrent Neural Networks (RNN)" are all used in the pre-prediction stage. The DBN, LSTM, and RNN outputs are sent into the final classification step, and it contains an improved Convolutional Neural Network (CNN). The CNN's weight function is fine-tuned via the novel Dingo Optimized Sand Piper (DOSP) model as it makes final judgments about crop production. Eventually, the efficiency of the anticipated model (two-stage classifier with DOSP) is validated by a comparative examination in terms of various measures. This research showed the efficiency of the proposed work in different types of datasets. In particular, for dataset 1, the MAE of the developed method at the 70th training rate is 50%, 62.5%, 57.1%, and 40% improved over the existing SOA, DOX, BOA, BMVO, GWO and PRO, respectively. For dataset 2, the mean of the suggested work is 2.76%, 2.57%, 2.57%, and 2.85% better than existing SOA, DOX, BOA, BMVO, GWO and PRO, schemes respectively.
C1 [Kolipaka, Venkata Rama Rao; Namburu, Anupama] VIT AP Univ, Sch Comp Sci & Engn, Amaravati, Andhra Pradesh, India.
C3 VIT-AP University
RP Kolipaka, VRR (corresponding author), VIT AP Univ, Sch Comp Sci & Engn, Amaravati, Andhra Pradesh, India.
EM venkataramaraokolipaka7@gmail.com
RI Rama Rao, K V/JZT-0093-2024
CR Amaratunga V, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/8627824
   Anderson C, 2020, IEEE ROBOT AUTOM LET, V5, P6892, DOI 10.1109/LRA.2020.3023713
   Arami A, 2019, IEEE T NEUR SYS REH, V27, P1909, DOI 10.1109/TNSRE.2019.2933626
   Bairwa AK, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/2571863
   Bao SN, 2017, INT GEOSCI REMOTE SE, P6150, DOI 10.1109/IGARSS.2017.8128412
   Chu Z, 2020, COMPUT ELECTRON AGR, V174, DOI 10.1016/j.compag.2020.105471
   Coviello L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10144870
   Cui CF, 2020, IEEE T COMPUT AID D, V39, P4958, DOI 10.1109/TCAD.2020.2968582
   Das B, 2018, INT J BIOMETEOROL, V62, P1809, DOI 10.1007/s00484-018-1583-6
   Elavarasan D, 2021, NEURAL COMPUT APPL, V33, P13205, DOI 10.1007/s00521-021-05950-7
   Elavarasan D, 2021, J AMB INTEL HUM COMP, V12, P10009, DOI 10.1007/s12652-020-02752-y
   Elavarasan D, 2020, IEEE ACCESS, V8, P86886, DOI 10.1109/ACCESS.2020.2992480
   Goli A, 2019, INT J INTERACT MULTI, V5, P15, DOI 10.9781/ijimai.2019.03.003
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Guo YH, 2021, ECOL INDIC, V120, DOI 10.1016/j.ecolind.2020.106935
   Hans R, 2020, INT J INTERACT MULTI, V6, P91, DOI 10.9781/ijimai.2019.07.004
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ilyas QM, 2023, BIOENGINEERING-BASEL, V10, DOI 10.3390/bioengineering10020125
   Ishwarya R, 2022, Int Res J Moderniza Eng Technol Sci, V04
   Jadhav A. N., 2019, Multimedia Research, V2, P1, DOI DOI 10.46253/J.MR.V2I3.A1
   Jiang D, 2021, IEEE ACCESS, V9, P137655, DOI 10.1109/ACCESS.2021.3117576
   Jiang D, 2020, IEEE ACCESS, V8, P197885, DOI 10.1109/ACCESS.2020.3034680
   Jiang J, 2020, IEEE T NANOBIOSCI, V19, P142, DOI 10.1109/TNB.2019.2920419
   Jiang S, 2021, IEEE ACCESS, V9, P85071, DOI 10.1109/ACCESS.2021.3083838
   kaggle, US
   Kaur A, 2020, APPL INTELL, V50, P582, DOI 10.1007/s10489-019-01507-3
   Lin T, 2020, ENVIRON RES LETT, V15, DOI 10.1088/1748-9326/ab66cb
   Luciani R, 2019, IEEE J-STARS, V12, P2196, DOI 10.1109/JSTARS.2019.2921437
   Maimaitijiang M, 2020, REMOTE SENS ENVIRON, V237, DOI 10.1016/j.rse.2019.111599
   Mohan P, 2017, 2017 INT C EL EL COM
   Nandy A, 2021, BENCHMARKING, V28, P229, DOI 10.1108/BIJ-01-2020-0012
   Pantazi XE, 2016, COMPUT ELECTRON AGR, V121, P57, DOI 10.1016/j.compag.2015.11.018
   Qiao MJ, 2021, IEEE J-STARS, V14, P4476, DOI 10.1109/JSTARS.2021.3073149
   Rashid M, 2021, IEEE ACCESS, V9, P63406, DOI 10.1109/ACCESS.2021.3075159
   Salehinejad H, 2018, Arxiv, DOI arXiv:1801.01078
   Shahhosseini M, 2019, ENVIRON RES LETT, V14, DOI 10.1088/1748-9326/ab5268
   Shiu YS, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11020111
   Sun J, 2020, IEEE J-STARS, V13, P5048, DOI 10.1109/JSTARS.2020.3019046
   Wang XB, 2019, IEEE ACCESS, V7, P19738, DOI 10.1109/ACCESS.2019.2894462
   Wu SW, 2020, IEEE ACCESS, V8, P134124, DOI 10.1109/ACCESS.2020.3010506
   Yoon D, 2020, IEEE ACCESS, V8, P201555, DOI 10.1109/ACCESS.2020.3035498
   Yuan T, 2020, IEEE T RELIAB, V69, P510, DOI 10.1109/TR.2019.2943925
   Zhang JA, 2021, IEEE MICROW WIREL CO, V31, P333, DOI 10.1109/LMWC.2021.3059993
   Zhao SQ, 2019, COMPUT ELECTRON AGR, V162, P759, DOI 10.1016/j.compag.2019.05.020
NR 44
TC 2
Z9 2
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28969
EP 28992
DI 10.1007/s11042-023-16612-2
EA SEP 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001062311100003
DA 2024-07-18
ER

PT J
AU Hegde, SK
   Dharmalingam, R
   Kannan, S
AF Hegde, Sneha K.
   Dharmalingam, Ramalingam
   Kannan, Srividhya
TI Intelligent German traffic sign and road barrier assist for autonomous
   driving in smart cities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Autonomous driving; Extended traffic sign recognition; Object
   recognition; Classification; Tracking; yolov4; Single shot multibox
   detector
AB Smart cities are becoming an essential part in most of the countries. Safety also becomes important when such transformations occur. Safety can be achieved with the help of autonomous vehicles. Adoption of AI has provided practical solutions to most of the autonomous driving problems. Extended Traffic sign recognition is important for advanced driver assistance systems, autonomous vehicles, and mobile robots to inform the driver about the potential hazard ahead. Several research on traffic sign recognition has been carried out in the past, and most existing works were focused on traffic signs. Although research works have been done for detecting traffic signs, still there is a need for detection of small construction zone traffic signs and road barriers with better accuracy. This paper aims to showcase the results obtained using state of art deep networks, namely DSOD, a variant of SSD, YOLOV3, YOLOv4 for detection of construction zone traffic signs from the video sequences captured by a camera mounted on a car. Further, the classification of signs is carried out using CNN, which uses the detector feature as input. In addition to that, tracking is performed to include the missed detections and exclude the false positives arrived during detection. The proposed approach can achieve a maximum of 90% accuracy with 0.5 IOU for the detection of construction zone signs and road barriers.
C1 [Hegde, Sneha K.; Dharmalingam, Ramalingam; Kannan, Srividhya] Continental Automot, Bangalore, India.
RP Kannan, S (corresponding author), Continental Automot, Bangalore, India.
EM sneha.hegde.k@continental-corporation.com;
   ramalingam.dharmalingam@continental-corporation.com;
   srividhya.kannan@continental-corporation.com
OI kannan, srividhya/0000-0003-2930-6145; Hegde K,
   Sneha/0000-0002-0635-7866
CR [Anonymous], 2000, P 6 C ADV SCH IM COM
   [Anonymous], 2006, P MULT COMP ENG SYST
   Ardianto S, 2017, INT CONF SYST SIGNAL
   Atif M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22072683
   Bahlmann C, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P255
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Gadri Said, 2022, Intelligent Computing & Optimization: Proceedings of the 4th International Conference on Intelligent Computing and Optimization 2021 (ICO2021). Lecture Notes in Networks and Systems (371), P45, DOI 10.1007/978-3-030-93247-3_5
   Gudigar A, 2019, NEURAL COMPUT APPL, V31, P395, DOI 10.1007/s00521-017-3063-z
   Jain A, 2019, NEURAL PROCESS LETT, V50, P3019, DOI 10.1007/s11063-019-09991-x
   LeCun Y., 2019, TRANSPORTATION ENG, V47, P242
   Li HJ, 2015, NEUROCOMPUTING, V169, P77, DOI 10.1016/j.neucom.2014.12.111
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Loy G., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P70
   Manfreda A, 2021, INT J INFORM MANAGE, V58, DOI 10.1016/j.ijinfomgt.2019.102050
   Persaud P, 2017, PROC INT C TOOLS ART, P1008, DOI 10.1109/ICTAI.2017.00155
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Seuwou P., 2020, DIGITAL TWIN TECHNOL, P37, DOI DOI 10.1007/978-3-030-18732-3_3
   Shadeed WG, 2003, ICECS 2003: PROCEEDINGS OF THE 2003 10TH IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS, CIRCUITS AND SYSTEMS, VOLS 1-3, P890
   Shen Z., 2017, 2017 P IEEE INT C CO, P1919
   Soendoro WD, 2011, P 2011 INT C EL ENG
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Yang Y, 2016, IEEE T INTELL TRANSP, V17, P2022, DOI 10.1109/TITS.2015.2482461
   Zhang CW, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420550034
   Zhu YY, 2013, IEEE IMAGE PROC, P3755, DOI 10.1109/ICIP.2013.6738774
NR 24
TC 0
Z9 0
U1 5
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 7
PY 2023
DI 10.1007/s11042-023-16435-1
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q9PM3
UT WOS:001060763900015
DA 2024-07-18
ER

PT J
AU Ta, N
   Chen, HP
   Du, B
   Wang, X
   Shi, ZA
AF Ta, Na
   Chen, Haipeng
   Du, Bing
   Wang, Xue
   Shi, Zenan
TI Collaborative region-boundary interaction network for medical image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image segmentation; Multi-level adaptive feature learning;
   Collaborative interaction; Multi-step refinement; Iterative manner
ID ATTENTION; CONTEXT
AB Existing medical image segmentation methods achieve impressive progress but remain challenged by high diversity in region scales or capricious boundaries. Meanwhile, they usually ignore another favorable factor, i.e., correlations between region and boundary, resulting in limitations to performance improvement. In this paper, we propose a novel framework, aiming at accurate segmentation by collaborating region detection and boundary localization subtasks as well as interacting relations between them. In particular, we first put forward a novel multi-level adaptive feature learning module, which can select discriminative information from backbone features by constructing holistic adaptive weights. Then, a collaborative multi-step refinement module is designed to excavate the reciprocal benefits between two subtasks via reasoning their high correlations cues. Moreover, we propose parallel iterative decoders, i.e., region/boundary iterative decoder, each of which consists of attention-based dual iteration paths to effectively aggregate multi-scale features. By cooperating with these three creative parts, our method sets the new state-of-the-art segmentation performance on five polyp benchmarks, where it achieves a mean Dice score of 92.9% on CVC-ClinicDB dataset. Furthermore, we extensively evaluate our method on both skin lesion segmentation from ISIC 2018 and nuclei segmentation from 2018 Data Science Bowl dataset, demonstrating its excellent generalization ability.
C1 [Ta, Na; Chen, Haipeng; Wang, Xue; Shi, Zenan] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.
   [Ta, Na] Hulunbuir Univ, Coll Min, Hulunbuir 021008, Inner Mongolia, Peoples R China.
   [Ta, Na; Chen, Haipeng; Wang, Xue; Shi, Zenan] Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Jilin, Peoples R China.
   [Du, Bing] First Hosp Jilin Univ, Dept Cardiol, Changchun 130021, Jilin, Peoples R China.
C3 Jilin University; Jilin University; Jilin University
RP Du, B (corresponding author), First Hosp Jilin Univ, Dept Cardiol, Changchun 130021, Jilin, Peoples R China.
EM dubing@jlu.edu.cn
FU National Key Research and Development Program of China [2018YFB0804202,
   2018YFB0804203]; Regional Joint Fund of NSFC [U19A2057]; National
   Natural Science Foundation of China [61876070]; Jilin Province Science
   and Technology Development Plan Project [20190303134SF]; Jilin
   University Interdisciplinary Integration and Innovation Young Scholars
   Free Exploration Project [JLUXKJC2021QZ01]
FX This research is supported by the National Key Research and Development
   Program of China (2018YFB0804202, 2018YFB0804203), the Regional Joint
   Fund of NSFC (U19A2057), the National Natural Science Foundation of
   China (61876070), the Jilin Province Science and Technology Development
   Plan Project (20190303134SF), and Jilin University Interdisciplinary
   Integration and Innovation Young Scholars Free Exploration Project
   (JLUXKJC2021QZ01).
CR An FP, 2021, MULTIMED TOOLS APPL, V80, P15017, DOI 10.1007/s11042-021-10515-w
   Azad R, 2019, IEEE INT CONF COMP V, P406, DOI 10.1109/ICCVW.2019.00052
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Caicedo JC, 2019, NAT METHODS, V16, P1247, DOI 10.1038/s41592-019-0612-7
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen ZX, 2021, IEEE T IMAGE PROCESS, V30, P431, DOI 10.1109/TIP.2020.3037536
   Cheng MJ, 2021, LECT NOTES COMPUT SC, V12901, P720, DOI 10.1007/978-3-030-87193-2_68
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Dai YM, 2021, IEEE WINT CONF APPL, P3559, DOI 10.1109/WACV48630.2021.00360
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Feng SL, 2020, IEEE T MED IMAGING, V39, P3008, DOI 10.1109/TMI.2020.2983721
   Fu Jun, 2019, IEEE Trans Image Process, DOI 10.1109/TIP.2019.2895460
   Gu R, 2021, IEEE T MED IMAGING, V40, P699, DOI 10.1109/TMI.2020.3035253
   Guo F, 2021, MULTIMED TOOLS APPL, V80, P14767, DOI 10.1007/s11042-021-10580-1
   Gusi Te, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P258, DOI 10.1007/978-3-030-58610-2_16
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jiafu Zhong, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P285, DOI 10.1007/978-3-030-59725-2_28
   Jun Wei, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13022, DOI 10.1109/CVPR42600.2020.01304
   Kervadec H, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101851
   Lee HJ, 2020, PROC CVPR IEEE, P4816, DOI 10.1109/CVPR42600.2020.00487
   Li HC, 2019, PROC CVPR IEEE, P9514, DOI 10.1109/CVPR.2019.00975
   Li Y, 2022, IEEE T MED IMAGING, V41, P1975, DOI 10.1109/TMI.2022.3151666
   Liu LL, 2020, IEEE J BIOMED HEALTH, V24, P3215, DOI 10.1109/JBHI.2020.3016306
   Liu XW, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103165
   Liu YX, 2022, IEEE T MED IMAGING, V41, P1482, DOI 10.1109/TMI.2021.3140120
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Patel K, 2021, 2021 18TH CONFERENCE ON ROBOTS AND VISION (CRV 2021), P181, DOI [10.1109/CRV52889.2021.00032, 10.1109/crv52889.2021.00032]
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Srivastava A, 2022, IEEE J BIOMED HEALTH, V26, P2252, DOI 10.1109/JBHI.2021.3138024
   Sun Jesse, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P797, DOI 10.1007/978-3-030-59719-1_77
   Ta N, 2023, MULTIMEDIA SYST, V29, P3041, DOI 10.1007/s00530-022-00900-2
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Nguyen TC, 2021, LECT NOTES COMPUT SC, V12901, P633, DOI 10.1007/978-3-030-87193-2_60
   Tomar NK, 2023, IEEE T NEUR NET LEAR, V34, P9375, DOI 10.1109/TNNLS.2022.3159394
   Vázquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang JC, 2021, LECT NOTES COMPUT SC, V12901, P206, DOI 10.1007/978-3-030-87193-2_20
   Wang K, 2022, PATTERN RECOGN, V127, DOI 10.1016/j.patcog.2022.108636
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang RS, 2022, IET IMAGE PROCESS, V16, P1243, DOI 10.1049/ipr2.12419
   Wang Ruxin, 2022, Med Image Anal, V78, P102395, DOI 10.1016/j.media.2022.102395
   Wang S, 2021, IEEE T MED IMAGING, V40, P310, DOI 10.1109/TMI.2020.3025517
   Wang X, 2022, NEUROCOMPUTING, V486, P135, DOI 10.1016/j.neucom.2021.11.017
   Wei J, 2021, LECT NOTES COMPUT SC, V12901, P699, DOI 10.1007/978-3-030-87193-2_66
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wu HS, 2022, MED IMAGE ANAL, V76, DOI 10.1016/j.media.2021.102327
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xixi Jiang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P460, DOI 10.1007/978-3-030-59719-1_45
   Yin ZJ, 2022, I S BIOMED IMAGING, DOI 10.1109/ISBI52829.2022.9761402
   Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943
   Yue GH, 2022, IEEE J BIOMED HEALTH, V26, P4090, DOI 10.1109/JBHI.2022.3173948
   Zhao C, 2022, MULTIMED TOOLS APPL, V81, P8691, DOI 10.1007/s11042-022-12067-z
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou SP, 2021, IEEE T IMAGE PROCESS, V30, P1, DOI 10.1109/TIP.2020.3027992
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
NR 60
TC 0
Z9 0
U1 8
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30399
EP 30421
DI 10.1007/s11042-023-15505-8
EA SEP 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001060763900011
DA 2024-07-18
ER

PT J
AU Paidipati, KK
   Kurangi, C
   Uthayakumar, J
   Reddy, ASK
   Kadiravan, G
   Shah, NH
AF Paidipati, Kiran Kumar
   Kurangi, Chinnarao
   Uthayakumar, J.
   Reddy, A. Siva Krishna
   Kadiravan, G.
   Shah, Nusrat Hamid
TI Wireless sensor network assisted automated forest fire detection using
   deep learning and computer vision model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless sensor networks; Computer vision; Deep learning; Forest fire
   detection; Machine learning
AB Forest fires are still a huge problem in many countries because of the environmental, social, and economic damages affected. Applications connected to the prediction, management, and recognition of wildfires are enhanced recently. But, with utilize of technical solutions including the Internet of Things (IoT), artificial intelligence (AI), and wireless sensor networks (WSN), it can be feasible for developing early-warning methods with appropriate accuracy. With important sensors to measure variations in wind speed, temperature, and humidity, as well as for detecting the occurrence of fire and smoke, is a suitable manner for accomplishing this task, based on our view. Imaging sensors in WSN are utilized for collecting data in the target environment and deep learning (DL) approaches for forest fire detection (FFD) observe the attained images. With this motivation, this study develops a new DL model for forest fire detection named, the FFDNet technique. The presented FFDNet technique uses an emperor penguin optimizer with machine learning for forest fire detection in WSN. The goal of the FFDNet technique is to identify the occurrence of forest wire using sensors in WSN and DL models. Primarily, the sensor nodes transmit the images to the BS where the actual classification process takes place. In the presented FFDNet technique, the guided filtering (GF) technique is employed for the noise removal process. Besides, the presented FFDNet technique exploits a modified Xception network for a feature extraction process with root mean square propagation (RMSProp) optimizer. For the detection process, the kernel extreme learning machine (KELM) model is used in this study and the EPO algorithm can optimally choose its parameters. A wide range of experiments was performed by the FFDNet technique and the results are examined under diverse aspects. The simulation results reported the enhancements of the FFDNet technique over other DL models.
C1 [Paidipati, Kiran Kumar] Indian Inst Management Sirmaur, Area Decis Sci, Sirmaur 173025, HP, India.
   [Kurangi, Chinnarao] Gandhi Inst Technol & Management GITAM, Dept Comp Sci & Engn, Visakhapatnam, India.
   [Uthayakumar, J.] Genesys Acad Comp Sci, Pondicherry 605001, India.
   [Reddy, A. Siva Krishna] SR Univ, Sch CS & AI, Dept CS & AI, Hyderabad, Telangana, India.
   [Kadiravan, G.] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, AP, India.
   [Shah, Nusrat Hamid] Jazan Univ, Coll Comp Sci & Informat Technol, Dept Comp Sci, Jazan, Saudi Arabia.
C3 Indian Institute of Management (IIM System); Indian Institute of
   Management Sirmaur; Gandhi Institute of Technology & Management (GITAM);
   Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   Jazan University
RP Kadiravan, G (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, AP, India.
EM kkpaidipati@iimsirmaur.ac.in; kchinnarao142@gmail.com;
   uthayresearchscholar@gmail.com; reddyandluru@gmail.com;
   kathirkadir@gmail.com; nshah@jazanu.edu.sa
RI kadiravan, G/JAC-9364-2023; Paidipati, Kiran Kumar/F-2064-2016
OI kadiravan, G/0000-0001-7346-1324; Paidipati, Kiran
   Kumar/0000-0001-7648-1523; Shah, Nusrat/0000-0002-1022-4150
CR Abid F, 2021, FIRE TECHNOL, V57, P559, DOI 10.1007/s10694-020-01056-z
   Alkhatib AA., 2021, INT J ADV SOFT COMPU, V13, P82
   Dampage U, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-021-03882-9
   Dhiman G, 2021, KNOWL-BASED SYST, V211, DOI 10.1016/j.knosys.2020.106560
   Gupta N, 2021, INFORM-J COMPUT INFO, V9, P34
   Hu J, 2022, COMPUT BIOL MED, V142, DOI 10.1016/j.compbiomed.2021.105166
   Jeong M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195508
   Kaur H, 2019, J EXP THEOR ARTIF IN, V31, P599, DOI 10.1080/0952813X.2019.1591523
   Kizilkaya B, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3473037
   Kumar A, 2020, DEEP LEARNING TECHNI, P211, DOI [DOI 10.1007/978-3-030-33966-111, DOI 10.1007/978-3-030-33966-1_11]
   Li Y, 2022, 2022 5 INT S AUT SYS, P1
   Lu KJ, 2022, FORESTS, V13, DOI 10.3390/f13091448
   Lu X., 2022, J HEALTHC ENG, V2022, P1
   Moussa N, 2022, PEER PEER NETW APPL, V15, P2307, DOI 10.1007/s12083-022-01347-y
   Ning X., 2021, ASP Trans. Pattern Recognit. Intell. Syst, V1, P17, DOI [10.52810/TPRIS.2021.100012, DOI 10.52810/TPRIS.2021.100012]
   Park JH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092025
   Sadeq AA., 2022, INT J EMERGING TREND, V10, P420, DOI [10.30534/ijeter/2022/0110102022, DOI 10.30534/IJETER/2022/0110102022]
   Saeed F, 2020, MULTIMED TOOLS APPL, V79, P9083, DOI 10.1007/s11042-019-07785-w
   Sahoo Somya Ranjan, 2020, International Journal of Information and Computer Security, V12, P303
   Sahoo SR, 2019, COMPUT ELECTR ENG, V76, P65, DOI 10.1016/j.compeleceng.2019.03.003
   Sahoo SR, 2021, ADV INTELL SYST COMP, P149, DOI DOI 10.1007/978-981-15-1275-9_13
   Seydi ST, 2022, J SENSORS, V2022, DOI 10.1155/2022/8044390
   Sinha D, 2019, WIRELESS PERS COMMUN, V109, P2561, DOI 10.1007/s11277-019-06697-0
   Vikram R, 2020, WIREL NETW, V26, P5177, DOI 10.1007/s11276-020-02393-1
NR 24
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26733
EP 26750
DI 10.1007/s11042-023-16647-5
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001058323600004
DA 2024-07-18
ER

PT J
AU Urbieta, I
   Mujika, A
   Piérola, G
   Irigoyen, E
   Nieto, M
   Loyo, E
   Aginako, N
AF Urbieta, Itziar
   Mujika, Andoni
   Pierola, Gonzalo
   Irigoyen, Eider
   Nieto, Marcos
   Loyo, Estibaliz
   Aginako, Naiara
TI WebLabel: OpenLABEL-compliant multi-sensor labelling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE OpenLABEL; Ground truth; Video labelling; Point cloud; Tracking; 3D
AB Annotated datasets have become crucial for training Machine Learning (ML) models for developing Autonomous Vehicles (AVs) and their functions. Generating these datasets usually involves a complex coordination of automation and manual effort. Moreover, most available labelling tools focus on specific media types (e.g., images or video). Consequently, they cannot perform complex labelling tasks for multi-sensor setups. Recently, ASAM published OpenLABEL, a standard designed to specify an annotation format flexible enough to support the development of automated driving features and to guarantee interoperability among different systems and providers. In this work, we present WebLabel, the first multipurpose web application tool for labelling complex multi-sensor data that is fully compliant with OpenLABEL 1.0. The proposed work analyses several labelling use cases demonstrating the standard's benefits and the application's flexibility to cover various heterogeneous requirements: image labelling, multi-view video object annotation, point-cloud view-based labelling for 3D geometries and action recognition.
C1 [Urbieta, Itziar; Mujika, Andoni; Pierola, Gonzalo; Irigoyen, Eider; Nieto, Marcos; Loyo, Estibaliz] Vicomtech Fdn, Basque Res & Technol Alliance BRTA, Mikeletegi 57, Donostia San Sebastian 20009, Spain.
   [Urbieta, Itziar; Aginako, Naiara] Univ Basque Country EHU UPV, Donostia San Sebastian, Spain.
C3 University of Basque Country
RP Urbieta, I (corresponding author), Vicomtech Fdn, Basque Res & Technol Alliance BRTA, Mikeletegi 57, Donostia San Sebastian 20009, Spain.; Urbieta, I (corresponding author), Univ Basque Country EHU UPV, Donostia San Sebastian, Spain.
EM iurbieta@vicomtech.org
RI Nieto, Marcos/A-7786-2011
OI Nieto, Marcos/0000-0001-9879-0992; Urbieta Izquierdo,
   Itziar/0000-0001-7983-3651
FU European Union [101076754]; Horizon Europe - Pillar II [101076754]
   Funding Source: Horizon Europe - Pillar II
FX This work has received funding from the European Union's Horizon Europe
   Research and Innovation Programme under Grant Agreement No 101076754 -
   AIthena project.
CR Apellaniz JL, 2023, P IEEE INT TRANSP SY
   ASAM e.V, 2021, ASAM OPENODD CONC PR
   ASAM e.V, 2020, ASAM OPENLABEL CONC
   ASAM e.V, 2022, ASAM OPENSCENARIO US
   Buechel M, 2017, IEEE INT VEH SYM, P1471, DOI 10.1109/IVS.2017.7995917
   Deutsches Zentrum fur Schienenverkehrsforschung (DZSF), 2023, OP SENS DAT RAIL 202
   Doulamis ND, 2010, MULTIMED TOOLS APPL, V50, P173, DOI 10.1007/s11042-009-0370-0
   euroncap, 2020, EUR NCAP ASS DRIV TE
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Jain N, 2014, Journal of Global Research in Computer Science, V5, P17
   Kar A, 2021, TORONTO ANNOTATION S
   Kaur J, 2022, MULTIMED TOOLS APPL, V81, P38297, DOI 10.1007/s11042-022-13153-y
   labelGo Github., 2021, US
   Lin Q, 2022, P MACHINE LEARNING R, V164, P1789
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mujika A, 2019, WEB BASED VIDEO ASSI, DOI [10.1145/3329714.3338128, DOI 10.1145/3329714.3338128]
   Nieto M, 2021, SOFTWAREX, V13, DOI 10.1016/j.softx.2020.100653
   Ortega JD, 2020, ARXIV
   Pokhrel S., 2020, Image Data Labelling and Annotation - Everything you need to know
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Tagiew R., 2023, ARXIV
   The Khronos Group Inc, WEBGL
   threejs, 3 JS JAVASCRIPT 3 LI
   Tkachenko Maxim, 2022, Label studio: data labeling software
   Torralba A, 2010, P IEEE, V98, P1467, DOI 10.1109/JPROC.2010.2050290
   Urbieta I, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11177782
   Vicomtech, 2023, WEBLABEL GITH
   Vondrick C, 2010, LECT NOTES COMPUT SC, V6314, P610, DOI 10.1007/978-3-642-15561-1_44
   Zimmer W, 2019, ARXIV
NR 29
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26505
EP 26524
DI 10.1007/s11042-023-16664-4
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001061475000001
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, N
   Ma, RB
   Jiao, JC
   Qi, WJ
   Li, YX
AF Li, Ning
   Ma, Rubin
   Jiao, Jichao
   Qi, Wangjing
   Li, Yuxuan
TI Hyperspectral image super-resolution via double-flow pretreatment
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral images; Super-resolution; Deep learning; Pretreatment
AB The main objective of this paper is the super-resolution of hyperspectral images. In this paper, we propose a double-flow pretreatment network that aims to address the problem of hyperspectral images with low spatial resolution. First, a multi-scale feature extraction method for visible images is proposed in advance, so that no strict registration and no prior spectral response function is required between visible and hyperspectral images during fusion. Second, a preprocessing module is constructed to reconstruct the input hyperspectral image, which improves the consistency of the spectral information before and after reconstruction. Finally, an iterative fusion module is constructed to adapt spectral dimension features based on channel attention mechanism, which is more suitable for hyperspectral image processing. Compared with other state-of-the-art methods, the proposed method in this paper has advantages in four evaluation metrics.
C1 [Li, Ning; Ma, Rubin; Jiao, Jichao; Qi, Wangjing; Li, Yuxuan] Beijing Univ Posts & Telecommun, Sch Elect Engn, 10 Xitucheng Rd, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Ma, RB (corresponding author), Beijing Univ Posts & Telecommun, Sch Elect Engn, 10 Xitucheng Rd, Beijing 100876, Peoples R China.
EM lnmmdsy@sina.com; rubinma@bupt.edu.cn; jiaojichao@bupt.edu.cn;
   qiwangjing@bupt.edu.cn; li.yuxuan@bupt.edu.cn
RI Wang, Jinlong/KHC-3829-2024; Li, Zexi/KFA-6939-2024; chen,
   jiayi/KHV-5520-2024; zhang, yingying/KGM-8162-2024
OI zhang, yingying/0000-0001-7479-3398
CR [Anonymous], 2010, 2010 18 INT C GEOINF, DOI DOI 10.1109/GEOINFORMATICS.2010.5568105
   Chakrabarti A., 2011, PROC CVPR IEEE, P193, DOI [DOI 10.1109/CVPR.2011.5995660, 10.1109/CVPR.2011.5995660]
   Dian RW, 2018, IEEE T NEUR NET LEAR, V29, P5345, DOI 10.1109/TNNLS.2018.2798162
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong WS, 2016, IEEE T IMAGE PROCESS, V25, P2337, DOI 10.1109/TIP.2016.2542360
   Ghamisi P, 2017, IEEE GEOSC REM SEN M, V5, P37, DOI 10.1109/MGRS.2017.2762087
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jing Yao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12374), P208, DOI 10.1007/978-3-030-58526-6_13
   Kingma D. P., 2014, arXiv
   Lanaras C, 2016, HYPERSPECTRAL SUPER
   Loncan L, 2015, IEEE GEOSC REM SEN M, V3, P27, DOI 10.1109/MGRS.2015.2440094
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Vijayalakshmi D, 2020, SENS IMAGING, V21, DOI 10.1007/s11220-020-00305-3
   Wald L., 2000, 3 C FUS EARTH DAT ME, P99
   Wang W, 2019, IEEE I CONF COMP VIS, P4149, DOI 10.1109/ICCV.2019.00425
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie Q, 2022, IEEE T PATTERN ANAL, V44, P1457, DOI 10.1109/TPAMI.2020.3015691
   Yasuma F, 2010, IEEE T IMAGE PROCESS, V19, P2241, DOI 10.1109/TIP.2010.2046811
   Yuhas R.H., 1992, Discrimination Among Semi-arid Landscape Endmembers Using the Spectral Angle Mapper (SAM) Algorithm
   Zhang L, 2018, IEEE T IMAGE PROCESS, V27, P5969, DOI 10.1109/TIP.2018.2862629
   Zhang M., 2021, IEEE INT GEOSCI REMO, P4476
NR 21
TC 0
Z9 0
U1 6
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 28027
EP 28038
DI 10.1007/s11042-023-16335-4
EA AUG 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001062026900005
DA 2024-07-18
ER

PT J
AU Zhang, YW
   Wang, HW
   Zhao, JC
AF Zhang, Yanwen
   Wang, Huiwen
   Zhao, Jichang
TI Eliminating orthonormal constraints of SVD to guarantee full
   retrievability of blind watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Singular value decomposition; E-SVD; Blind image watermarking; Full
   retrievability; Robustness against attacks
ID SINGULAR-VALUE DECOMPOSITION; IMAGE WATERMARKING; ROBUST WATERMARKING;
   DWT-SVD; SCHEME; HYBRID; DOMAIN; ALGORITHM; DCT; VISIBILITY
AB Blind watermarking schemes based on Singular Value Decomposition (SVD), which decomposes a matrix into a product of two orthogonal matrices and a diagonal matrix in between them, typically manipulate orthonormal matrices to hide identity information. However, these manipulations can compromise orthonormality and result in incorrect and unstable watermark extraction, even in the absence of any attack. In this paper, we develop this idea by using an enhanced version of SVD called E-SVD, which releases all constraints on orthonormal matrices without information loss. By embedding watermarks freely while maintaining orthonormality, E-SVD theoretically guarantees the full retrievability of the watermark in the absence of an attack. We also derive the analytical relationship between the only parameter and imperceptibility, which facilitates the optimal trade-off between imperceptibility and robustness in the watermarking. To improve performance, a nonparametric extraction scheme is further leveraged. Experimental results demonstrate that our proposed scheme outperforms existing baselines and remains robust against various attacks, making it widely applicable in multiple scenarios. To the best of our knowledge, this is the first time that a theoretical guarantee for the full retrievability of SVD-based blind watermarking has been provided, which removes all restrictions imposed by orthonormality and paves the way for future innovations in blind watermarking.
C1 [Zhang, Yanwen; Wang, Huiwen; Zhao, Jichang] Beihang Univ, Sch Econ & Management, 37 Xueyuan Rd, Beijing 100191, Peoples R China.
   [Zhang, Yanwen] Beihang Univ, Shen Yuan Honors Coll, 37 Xueyuan Rd, Beijing 100191, Peoples R China.
   [Wang, Huiwen] Beihang Univ, Key Lab Complex Syst Anal Management & Decis, Minist Educ, Beijing, Peoples R China.
   [Zhao, Jichang] Beijing Key Lab Emergence Support Simulat Technol, Beijing, Peoples R China.
C3 Beihang University; Beihang University; Beihang University
RP Zhao, JC (corresponding author), Beihang Univ, Sch Econ & Management, 37 Xueyuan Rd, Beijing 100191, Peoples R China.; Zhao, JC (corresponding author), Beijing Key Lab Emergence Support Simulat Technol, Beijing, Peoples R China.
EM zhangyanwen@buaa.edu.cn; wanghw@vip.sina.com; jichang@buaa.du.cn
RI Zhang, Yanwen/JQJ-5919-2023; Wang, Huiwen/JED-3206-2023
OI Zhang, Yanwen/0000-0003-1107-2889
FU National Natural Science Foundation of China [72021001, 71871006]
FX AcknowledgementsThe authors are grateful for the financial support from
   the National Natural Science Foundation of China (Grant Nos. 72021001
   and 71871006).
CR Ahmadi SBB, 2020, MULTIMED TOOLS APPL, V79, P1075, DOI 10.1007/s11042-019-08197-6
   Ali M, 2015, INFORM SCIENCES, V301, P44, DOI 10.1016/j.ins.2014.12.042
   Ali M, 2014, SIGNAL PROCESS, V94, P545, DOI 10.1016/j.sigpro.2013.07.024
   Alshanbari HS, 2021, MULTIMED TOOLS APPL, V80, P16549, DOI 10.1007/s11042-020-08814-9
   Alzahrani A, 2021, IEEE ACCESS, V9, P113714, DOI 10.1109/ACCESS.2021.3104985
   Amiri SH, 2014, SIGNAL PROCESS-IMAGE, V29, P1181, DOI 10.1016/j.image.2014.07.004
   ANDREWS HC, 1976, IEEE T COMMUN, V24, P425, DOI 10.1109/TCOM.1976.1093309
   Bhatnagar G, 2013, ACM T MULTIM COMPUT, V10, DOI 10.1145/2542205.2542207
   Bhattacharyya Anil, 1943, B CALCUTTA MATH SOC, V35, P99
   Bhowmik D, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3357333
   Castleman K. R., 1996, Digital Image Processing
   Cedillo-Hernández M, 2014, SIGNAL IMAGE VIDEO P, V8, P49, DOI 10.1007/s11760-013-0459-9
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Chang TJ, 2019, MULTIMED TOOLS APPL, V78, P9169, DOI 10.1007/s11042-018-6505-4
   Choi HY, 2017, MULTIMED TOOLS APPL, V76, P26695, DOI 10.1007/s11042-016-4194-4
   Chu WC, 2003, IEEE T MULTIMEDIA, V5, P34, DOI 10.1109/TMM.2003.808816
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Cox IJ., 2007, DIGITAL WATERMARKING
   Dhar PK, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12030486
   Ernawan F, 2020, VISUAL COMPUT, V36, P19, DOI 10.1007/s00371-018-1567-x
   Fan MQ, 2008, APPL MATH COMPUT, V203, P926, DOI 10.1016/j.amc.2008.05.003
   Giri KJ, 2020, MULTIMED TOOLS APPL, V79, P32881, DOI 10.1007/s11042-020-09716-6
   Hemdan EE, 2021, MULTIMED TOOLS APPL, V80, P1749, DOI 10.1007/s11042-020-09769-7
   Hosny KM, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3325193
   Hu HT, 2020, INFORM SCIENCES, V519, P161, DOI 10.1016/j.ins.2020.01.019
   Imon M, 2015, IPSI BGD T ADV RES P
   Jang HU, 2018, MULTIMED TOOLS APPL, V77, P5685, DOI 10.1007/s11042-017-4483-6
   Kang XB, 2018, MULTIMED TOOLS APPL, V77, P13197, DOI 10.1007/s11042-017-4941-1
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Kumar S, 2021, MULTIMED TOOLS APPL, V80, P15487, DOI 10.1007/s11042-020-10322-9
   Lai CC, 2011, OPT COMMUN, V284, P938, DOI 10.1016/j.optcom.2010.10.047
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Luo AW, 2020, MULTIMED TOOLS APPL, V79, P243, DOI 10.1007/s11042-019-08074-2
   Moeinaddini E, 2019, SOFT COMPUT, V23, P9685, DOI 10.1007/s00500-018-3535-9
   Nasir I, 2010, SIGNAL IMAGE VIDEO P, V4, P145, DOI 10.1007/s11760-009-0106-7
   Natgunanathan I, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3492803
   Petitcolas FAP, 1998, LECT NOTES COMPUT SC, V1525, P218
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Podilchuk CI, 2001, IEEE SIGNAL PROC MAG, V18, P33, DOI 10.1109/79.939835
   Rizzo SG., 2019, EURASIP J INF SECUR, V1, P1
   Singh AK, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3382772
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Singh KN, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3498342
   Singh SP, 2020, J AMB INTEL HUM COMP, V11, P1869, DOI 10.1007/s12652-019-01296-0
   Singh S, 2017, MULTIMED TOOLS APPL, V76, P19113, DOI 10.1007/s11042-017-4570-8
   Song CL, 2012, J VIS COMMUN IMAGE R, V23, P549, DOI 10.1016/j.jvcir.2012.01.017
   Song CY, 2010, CONSUM COMM NETWORK, P807
   Su QT, 2022, INT J INTELL SYST, V37, P4747, DOI 10.1002/int.22738
   Su QT, 2020, SOFT COMPUT, V24, P445, DOI 10.1007/s00500-019-03924-5
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P24221, DOI 10.1007/s11042-016-4164-x
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Su QT, 2012, OPT COMMUN, V285, P1717, DOI 10.1016/j.optcom.2011.11.117
   Tsai HH, 2010, J SYST SOFTWARE, V83, P1015, DOI 10.1016/j.jss.2009.12.026
   Tsai HH, 2011, PATTERN RECOGN, V44, P751, DOI 10.1016/j.patcog.2010.10.004
   Vaidya SP, 2023, VISUAL COMPUT, V39, P2245, DOI 10.1007/s00371-022-02406-4
   Wang H, 2021, ARXIV
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang H, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9030045
   Zong TR, 2014, IEEE ICC, P878, DOI 10.1109/ICC.2014.6883430
NR 61
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25365
EP 25391
DI 10.1007/s11042-023-16004-6
EA AUG 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001050733600003
DA 2024-07-18
ER

PT J
AU Bodapati, JD
   Balaji, BB
AF Bodapati, Jyostna Devi
   Balaji, Bharadwaj Bagepalli
TI TumorAwareNet: Deep representation learning with attention based sparse
   convolutional denoising autoencoder for brain tumor recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Brain tumor recognition; Pre-trained Convolutional Neural Networks
   (CNNs); Sparse Convolutional Denoising Autoencoder (SCDA); Deep
   features; Spatial attention; Reconstruction convolutional auto-encoder;
   Convolutional support vector classifier
ID CLASSIFICATION; SEGMENTATION; FEATURES; MODELS
AB Learning discriminate representations from images plays crucial role in medical image analysis. The attention mechanism, on the other hand, leads to breakthrough results in the computer vision field by allowing models to provide varying levels of focus across image regions. In this work, we present Tumor Aware Net, an end-to-end trainable attention based Convolutional Neural Network that learns effective representations from Magnetic Resonance (MR) images suitable for effective tumor recognition. The proposed model employs a Sparse Convolutional Denoising Autoencoder (SCDA) to project the higher dimensional MR image representations to a lower dimensional space with improved discrimination. These lower dimensional descriptors are passed through an attention module, which prioritizes tumor descriptors over the rest. Furthermore, the proposed SCDA is trained jointly with the Neural induced Support Vector Classifier (NSVC) to achieve maximum margin separation. The proposed model has been validated on several publicly available benchmark datasets for tumor recognition. Based on the outcomes of the experimental studies, we claim that the proposed model favours stability and complements the learned representations when combined with attention. Despite its simplicity in terms of model parameters, the proposed model outperforms existing models for tumor type categorization.
C1 [Bodapati, Jyostna Devi] VFSTR Deemed be Univ, Guntur 522213, India.
C3 Vignan's Foundation for Science, Technology & Research (VFSTR)
RP Bodapati, JD (corresponding author), VFSTR Deemed be Univ, Guntur 522213, India.
EM jyostna.bodapati82@gmail.com
CR Abiwinanda N, 2019, IFMBE PROC, V68, P183, DOI 10.1007/978-981-10-9035-6_33
   Afshar P, 2018, IEEE IMAGE PROC, P3129, DOI 10.1109/ICIP.2018.8451379
   Anaraki AK, 2019, BIOCYBERN BIOMED ENG, V39, P63, DOI 10.1016/j.bbe.2018.10.004
   Arakeri MP, 2015, SIGNAL IMAGE VIDEO P, V9, P409, DOI 10.1007/s11760-013-0456-z
   Asif S, 2022, IEEE ACCESS, V10, P34716, DOI 10.1109/ACCESS.2022.3153306
   Badza MM, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10061999
   Bahdanau D., 2015, P INT C LEARN REPR
   Bingol H, 2021, TURK J SCI TECHNOL, V16, P137
   Bodapati Jyostna Devi, 2022, Journal of the Institution of Engineers (India): Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V103, P439, DOI 10.1007/s40031-021-00681-8
   Bodapati Jyostna Devi, 2022, Journal of the Institution of Engineers (India): Series B (Electrical, Electronics & Telecommunication and Computer Engineering), P1395, DOI 10.1007/s40031-022-00746-2
   Bodapati JD, 2021, SIVIP, P1
   Bodapati JD, 2021, MEASUREMENT
   Bodapati JD, 2020, ING NIERIE SYST MES, V25, P2
   Bodapati JD, 2022, MULTIMED TOOLS APPL, V81, P32033, DOI 10.1007/s11042-022-12811-5
   Bodapati JD, 2021, INT J PATTERN RECOGN, V35, DOI 10.1142/S0218001421570056
   Bodapati JD, 2021, SIGNAL IMAGE VIDEO P, V15, P923, DOI 10.1007/s11760-020-01816-y
   Bodapati JD, 2021, J AMB INTEL HUM COMP, V12, P9825, DOI 10.1007/s12652-020-02727-z
   Bodapati JD, 2021, SIGNAL IMAGE VIDEO P, V15, P753, DOI 10.1007/s11760-020-01793-2
   Bodapati JD, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060914
   Br35H, 2022, KAGGL DAT BRAIN TUM
   Cheng J, 2021, BRAIN TUMOR DATASET
   Cheng J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157112
   Cheng J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140381
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Deepak S, 2021, J AMB INTEL HUM COMP, V12, P8357, DOI 10.1007/s12652-020-02568-w
   Deepika K, 2019, LECT NOTE DATA ENG, V28, P163, DOI 10.1007/978-981-13-6459-4_17
   Ghaffari M, 2020, IEEE REV BIOMED ENG, V13, P156, DOI 10.1109/RBME.2019.2946868
   Halder Tanmoy Kanti, 2022, International Journal of Information Technology, V14, P1883, DOI 10.1007/s41870-022-00917-w
   Ismael MR, 2018, INT CONF ELECTRO INF, P252, DOI 10.1109/EIT.2018.8500308
   Khan MA, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10080565
   Kim Y, 2021, NEURAL NETWORKS, V138, P179, DOI 10.1016/j.neunet.2021.02.012
   Luong M.-T., 2015, P 2015 C EMPIRICAL M, DOI DOI 10.18653/V1/D15-1166
   Mehrotra R., 2020, MACH LEARN APPL, V2, P100003, DOI [10.1016/j.mlwa.2020.100003, DOI 10.1016/J.MLWA.2020.100003]
   Mohammed, 2022, KAGGL DAT BRAIN TUM
   Naoneel, 2021, KAGGL DAT BRAIN TUM
   Naralasetti V, 2021, TRAIT SIGNAL, V38, P903, DOI 10.18280/ts.380337
   Pashaei A, 2018, 2018 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P314, DOI 10.1109/ICCKE.2018.8566571
   Paul JS, 2017, PROC SPIE, V10137, DOI 10.1117/12.2254195
   Ranjbarzadeh R, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-90428-8
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Sasank VVS, 2021, MULTIMED TOOLS APPL, V80, P13513, DOI 10.1007/s11042-020-10423-5
   Sharif MI, 2020, PATTERN RECOGN LETT, V129, P181, DOI 10.1016/j.patrec.2019.11.019
   Swati ZNK, 2019, COMPUT MED IMAG GRAP, V75, P34, DOI 10.1016/j.compmedimag.2019.05.001
   Thayumanavan M, 2021, CONCURRENT ENG-RES A, V29, P266, DOI 10.1177/1063293X211010542
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang HY, 2023, NEURAL COMPUT APPL, V35, P11583, DOI 10.1007/s00521-021-06546-x
   Wang LB, 2019, FUTURE GENER COMP SY, V100, P316, DOI 10.1016/j.future.2019.05.035
   Xie XZ, 2018, J MED IMAG HEALTH IN, V8, P180, DOI 10.1166/jmihi.2018.2285
   Zhao Y, 2019, IEEE J BIOMED HEALTH, V23, P1363, DOI 10.1109/JBHI.2019.2891526
NR 49
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 15
PY 2023
DI 10.1007/s11042-023-15557-w
EA AUG 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P6LA0
UT WOS:001051759100007
DA 2024-07-18
ER

PT J
AU Tan, M
   Wang, RR
   Purwar, A
   Jin, T
   Yu, J
   Kot, AC
AF Tan, Min
   Wang, Ruirui
   Purwar, Ankur
   Jin, Tao
   Yu, Jun
   Kot, Alex C.
TI GTADT: Gated tone-sensitive acne grading via augmented domain transfer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Acne grading; Cross-domain augmentation; Domain transfer; Gate network;
   Skin tone
ID NETWORK
AB Automatic selfie facial acne grading plays a crucial role in treatment for facial care customers, and it attracts increasing attention with the revolution of telemedicine and virtual beauty. Unfortunately, the limited quantity and quality of the selfie facial dataset greatly challenge the learning of acne grading models. In this paper, we propose a Gated Tonesensitive Augmented Domain Transfer (GTADT) model to address the selfie facial acne grading problem. A "high-quality" clinical source domain and associated cross-domain data augmentation are introduced to generate sufficient data. Also, an aligned tone-sensitive model with multiple tone subnetworks is devised to bridge the domain gaps. In Addition, two gate networks are devised to capture the correlation between different tone subnetworks in both the label and feature spaces. We establish three selfie facial acne datasets which consist of people across different skin tones, ages, poses, etc. The experimental results on the newly established datasets demonstrate that: 1) both the cross-domain data augmentation, tone-sensitive module, and gate networks can enhance the performance; and 2) the proposed model performs favorably against state-of-the-art methods. We make both the code and datasets publicly available at https://github.com/ WRLH/GTADT.git.
C1 [Tan, Min; Wang, Ruirui; Jin, Tao; Yu, Jun] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Key Lab Complex Syst Modeling & Simulat, Xiasha Higher Educ Zone, Hangzhou 310018, Zhejiang, Peoples R China.
   [Purwar, Ankur] Procter & Gamble, 70 Biopolis St Singapore, Singapore 138547, Singapore.
   [Kot, Alex C.] Nanyang Technol Univ, Sch Elect & Elect Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
C3 Hangzhou Dianzi University; Procter & Gamble; Nanyang Technological
   University
RP Tan, M (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Key Lab Complex Syst Modeling & Simulat, Xiasha Higher Educ Zone, Hangzhou 310018, Zhejiang, Peoples R China.
EM tanmin@hdu.edu.cn; wrr2020@hdu.edu.cn; purwar.a@pg.com;
   taojin180@gmail.com; yujun@hdu.edu.cn; eackot@ntu.edu.sg
FU Zhejiang Provincial Natural Science Foundation of China [LZ23F020007];
   National Natural Science Foundation of China [61972119]; Rapid- Rich
   Object Search (ROSE) Lab, Nanyang Technological University (NTU),
   Singapore; A*STAR under it's A*STAR MBRC Strategic Positioning Fund
   (SPF) - ASTARP amp;G Collaboration [APG2013/113]
FX This work was supported by Zhejiang Provincial Natural Science
   Foundation of China (No.LZ23F020007), and National Natural Science
   Foundation of China (No. 61972119). This work was carried out at the
   Rapid- Rich Object Search (ROSE) Lab, Nanyang Technological University
   (NTU), Singapore. The research is supported in part by the A*STAR under
   it's A*STAR MBRC Strategic Positioning Fund (SPF) - ASTARP & G
   Collaboration (Award APG2013/113).
CR Bernardis E, 2020, JAMA DERMATOL, V156, P296, DOI 10.1001/jamadermatol.2019.4668
   Chen HT, 2021, PROC CVPR IEEE, P6424, DOI 10.1109/CVPR46437.2021.00636
   Chen YC, 2019, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2019.00189
   Ganeshkumar M, 2022, MULTIMED TOOLS APPL, V81, P36257, DOI 10.1007/s11042-021-11478-8
   Gao ZQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8917, DOI 10.1109/ICCV48922.2021.00881
   Harper JC, 2020, J AM ACAD DERMATOL, V82, P526, DOI 10.1016/j.jaad.2019.01.092
   Jain A, 2022, MULTIMED TOOLS APPL, P1
   Kang J, 2022, MULTIMED TOOLS APPL, V81, P22355, DOI 10.1007/s11042-021-11282-4
   Kang Q, 2021, IEEE T NEUR NET LEAR, V32, P3919, DOI 10.1109/TNNLS.2020.3016180
   Kim T, 2017, PR MACH LEARN RES, V70
   Krishnapriya KS, 2021, Arxiv, DOI arXiv:2104.14685
   Li N, 2022, J COSMET DERMATOL-US, V21, P2073, DOI 10.1111/jocd.14356
   Li PC, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2605, DOI 10.1145/3340531.3412713
   Lim ZV, 2020, SKIN RES TECHNOL, V26, P187, DOI 10.1111/srt.12794
   Lin Y., 2021, INT C BIOINFORMATICS, P2407, DOI 10.1109/BIBM52615.2021.9669431
   Lin Y, 2022, COMPUT METH PROG BIO, V221, DOI 10.1016/j.cmpb.2022.106911
   Lin ZR, 2022, MULTIMED TOOLS APPL, V81, P5989, DOI 10.1007/s11042-021-11814-y
   Liu Y, 2020, NAT MED, V26, P900, DOI 10.1038/s41591-020-0842-3
   Lu AD, 2021, IEEE T IMAGE PROCESS, V30, P5613, DOI 10.1109/TIP.2021.3087341
   Lu N, 2022, IEEE T CYBERNETICS, V52, P11927, DOI 10.1109/TCYB.2021.3085476
   Lullo JJ, 2020, J AM ACAD DERMATOL, V83, pAB15
   Mijwil MM, 2021, MULTIMED TOOLS APPL, V80, P26255, DOI 10.1007/s11042-021-10952-7
   Min KYS, 2021, Arxiv, DOI arXiv:2105.14891
   Mishra S, 2019, IEEE C COMP VIS PATT
   Morales A, 2021, IEEE T PATTERN ANAL, V43, P2158, DOI 10.1109/TPAMI.2020.3015420
   Nguyen A, 2021, LECT NOTES ARTIF INT, V12876, P599, DOI 10.1007/978-3-030-88081-1_45
   Pons G, 2022, IEEE T CYBERNETICS, V52, P4764, DOI 10.1109/TCYB.2020.3036935
   Salma W, 2022, MULTIMED TOOLS APPL, V81, P32643, DOI 10.1007/s11042-022-13081-x
   Samuels DV, 2020, J AM ACAD DERMATOL, V83, P532, DOI 10.1016/j.jaad.2020.02.040
   Shang JY, 2021, MULTIMED TOOLS APPL, V80, P6041, DOI 10.1007/s11042-020-09883-6
   Shaokai Ye, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13733, DOI 10.1109/CVPR42600.2020.01375
   Tan M, 2023, IEEE T GEOSCI REMOTE, V61, DOI 10.1109/TGRS.2023.3278349
   Tan M, 2019, IEEE T IMAGE PROCESS, V28, P6047, DOI 10.1109/TIP.2019.2921861
   Vandenhende S, 2022, IEEE T PATTERN ANAL, V44, P3614, DOI 10.1109/TPAMI.2021.3054719
   Verma A, 2021, IEEE T MULTIMEDIA
   Wang Q, 2022, MULTIMED TOOLS APPL, P1
   Wu XP, 2019, IEEE I CONF COMP VIS, P10641, DOI 10.1109/ICCV.2019.01074
   Xu GX, 2022, IEEE T MED IMAGING, V41, P88, DOI 10.1109/TMI.2021.3104474
   Yang Junchi, 2020, ADV NEURAL INFORM PR, V33, P1153
   Yang Y, 2021, DERMATOLOGY THER, V11, P1239, DOI 10.1007/s13555-021-00541-9
   Yao SY, 2023, IEEE T SYST MAN CY-S, V53, P1183, DOI 10.1109/TSMC.2022.3195239
   Yaqoob S, 2021, CLIN COSMET INV DERM, V14, P1427, DOI 10.2147/CCID.S333221
   Yu J, 2022, IEEE T PATTERN ANAL, V44, P563, DOI 10.1109/TPAMI.2019.2932058
   Zhao T, 2019, arXiv
   Zhu JY, 2017, IEEE GLOB COMM CONF
   Zhu YH, 2022, IEEE T NEUR NET LEAR, V33, P1228, DOI 10.1109/TNNLS.2020.3041469
NR 46
TC 0
Z9 0
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 15
PY 2023
DI 10.1007/s11042-023-16444-0
EA AUG 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P6LA0
UT WOS:001051759100005
DA 2024-07-18
ER

PT J
AU Li, XN
   Pan, C
   He, LM
   Li, XY
AF Li, Xiangning
   Pan, Chen
   He, Lingmin
   Li, Xinyu
TI Unsupervised Domain Adaptation for Cross-domain Histopathology Image
   Classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Domain adaptation; Medical image classification; Multi-source; Domain
   hybrid; Adversarial network
ID NETWORKS
AB Unsupervised domain adaptation (UDA) methods have made remarkable progress in histopathological image analysis and various cancer diagnosis domains. However, most cur-rent research focuses on transfer between single-source domains. The distribution of features between different cancer types is far away, and a well-trained model in one field may not be able to generalize well to data in other fields. To address the domain shift problem, this paper proposes a multi-source unsupervised domain adaptation method with domain mixing bridging. Using multiple source and target domains, feature representations of all domains are extracted, and latent relationships are captured. Afterward, the complementary information of the hybrid bridging intermediate domain is integrated to align the feature distribution. Addi-tionally, we introduce a domain adversarial adaptation module to generate domain invariant features. We experimented on three different cancer pathology image datasets and achieved an average accuracy of 92.94% classification performance. It is proved that compared with the existing deep transfer learning technology, the method in this paper has a better effect. Code will be available at: https://github.com/Ww994/MHDAN.
C1 [Li, Xiangning; Pan, Chen; He, Lingmin; Li, Xinyu] China JiLiang Univ, Hangzhou 310018, Zhejiang, Peoples R China.
C3 China Jiliang University
RP He, LM (corresponding author), China JiLiang Univ, Hangzhou 310018, Zhejiang, Peoples R China.
EM p21030854024@cjlu.edu.cn; pc916@cjlu.edu.cn; helm@cjlu.edu.cn;
   p20030854057@cjlu.edu.cn
CR Borkowski AA, 2019, Arxiv, DOI [arXiv:1912.12142, DOI 10.48550/ARXIV.1912.12142]
   Benhammou Y, 2020, NEUROCOMPUTING, V375, P9, DOI 10.1016/j.neucom.2019.09.044
   Chai JY, 2021, MACH LEARN APPL, V6, DOI 10.1016/j.mlwa.2021.100134
   Choudhary Anirudh, 2020, Yearb Med Inform, V29, P129, DOI 10.1055/s-0040-1702009
   Csurka G, 2017, Arxiv, DOI [arXiv:1702.05374, DOI 10.48550/ARXIV:1702.05374]
   Dou Q, 2018, Arxiv, DOI arXiv:1804.10916
   Falahkheirkhah K, 2023, Arxiv, DOI arXiv:2303.02241
   Figueira G, 2020, I S BIOMED IMAGING, P1284, DOI [10.1109/isbi45749.2020.9098699, 10.1109/ISBI45749.2020.9098699]
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Gu YY, 2020, IEEE J BIOMED HEALTH, V24, P1379, DOI 10.1109/JBHI.2019.2942429
   Guan H, 2022, IEEE T BIO-MED ENG, V69, P1173, DOI [10.1109/TBME.2021.3117407, 10.1145/3476779.3476780]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Iacono P, 2023, Arxiv, DOI [arXiv:2304.09164, DOI 10.48550/ARXIV.2304.09164]
   Jia X, 2020, IEEE ACCESS, V8, P64020, DOI 10.1109/ACCESS.2020.2984777
   Kang G., 2020, IEEE T PATTERN ANAL
   Karimpour M, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01093-2
   Dziugaite GK, 2015, Arxiv, DOI [arXiv:1505.03906, DOI 10.48550/ARXIV.1505.03906]
   Khan S, 2023, NEURAL PROCESS LETT, V55, P2063, DOI 10.1007/s11063-023-11167-7
   Kumagai A, 2019, AAAI CONF ARTIF INTE, P4106
   Kumar D, 2017, IEEE INT CONF BIG DA, P4035, DOI 10.1109/BigData.2017.8258419
   Long MS, 2016, ADV NEUR IN, V29
   Kouw WM, 2019, Arxiv, DOI arXiv:1812.11806
   Mahapatra D., 2022, EUROPEAN C COMPUTER, P735
   Mahapatra D, 2022, Arxiv, DOI arXiv:2206.13123
   Niu ST, 2020, IEEE INT CONF BIG DA, P5164, DOI 10.1109/BigData50022.2020.9378493
   Niu ST, 2021, IEEE J BIOMED HEALTH, V25, P3784, DOI 10.1109/JBHI.2021.3051470
   O'Mahony N, 2020, ADV INTELL SYST COMP, V943, P128, DOI 10.1007/978-3-030-17795-9_10
   Pei ZY, 2018, AAAI CONF ARTIF INTE, P3934
   Perone CS, 2019, NEUROIMAGE, V194, P1, DOI 10.1016/j.neuroimage.2019.03.026
   Romero M, 2020, MED PHYS, V47, P6246, DOI 10.1002/mp.14507
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Sun SL, 2015, INFORM FUSION, V24, P84, DOI 10.1016/j.inffus.2014.12.003
   Tan B, 2017, AAAI CONF ARTIF INTE, P2604
   Tzeng E, 2014, Arxiv, DOI [arXiv:1412.3474, 10.48550/arXiv.1412.3474, DOI 10.48550/ARXIV.1412.3474]
   Vahadane A, 2016, IEEE T MED IMAGING, V35, P1962, DOI 10.1109/TMI.2016.2529665
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Xie BH, 2022, AAAI CONF ARTIF INTE, P8708
   Zhang H., 2022, IEEE Journal of Biomedical and Health Informatics
   Zhao SC, 2020, Arxiv, DOI arXiv:2002.12169
   Zhao SC, 2022, IEEE T NEUR NET LEAR, V33, P473, DOI 10.1109/TNNLS.2020.3028503
   Zhu DD, 2023, Arxiv, DOI arXiv:2305.04466
   Zhu Y, 2023, FRONT COMPUT SCI-CHI, V17, DOI 10.1007/s11704-022-1349-5
   Zhu YC, 2021, IEEE T NEUR NET LEAR, V32, P1713, DOI 10.1109/TNNLS.2020.2988928
   Zhu YC, 2019, AAAI CONF ARTIF INTE, P5989
   Zhu YC, 2019, NEURAL NETWORKS, V119, P214, DOI 10.1016/j.neunet.2019.07.010
NR 47
TC 0
Z9 0
U1 5
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 14
PY 2023
DI 10.1007/s11042-023-16400-y
EA AUG 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P2HF6
UT WOS:001048894900008
DA 2024-07-18
ER

PT J
AU Zhang, XQ
   Liu, M
AF Zhang, Xiaoqiang
   Liu, Mi
TI Multiple-image encryption algorithm based on the stereo Zigzag
   transformation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image security; Multiple-image encryption; Henon map; Zigzag
   transformation
ID CHAOTIC SYSTEMS; CRYPTANALYSIS
AB With the rise of emerging technologies, the information security becomes particularly important. Digital images play an important role in network transmission. To prevent the image information about being stolen during network transmission, this paper established a stereo Zigzag transformation and proposed a new multiple-image encryption algorithm. Firstly, the original images make up a cube; secondly, Henon map is used to randomly select the starting point of the two-dimensional Zigzag transformation; thirdly, the scrambled images can be obtained by the stereo Zigzag transformation; finally, a chaotic sequence is used to randomly diffuse the scrambled images to get the encrypted images. Experimental analyses indicate that the proposed algorithm has the characteristic of high key sensitivity, large key space, high efficiency and resistance to plaintext attacks, statistical attacks, etc.
C1 [Zhang, Xiaoqiang; Liu, Mi] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Peoples R China.
C3 China University of Mining & Technology
RP Zhang, XQ (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Peoples R China.
EM grayqiang@163.com
CR Akraam M., 2022, MULTIMED TOOLS APPL, V10, P1
   Algredo-Badillo I, 2013, MICROPROCESS MICROSY, V37, P750, DOI 10.1016/j.micpro.2012.06.007
   Ametepe AFX, 2022, WIREL NETW, V28, P991, DOI 10.1007/s11276-022-02903-3
   Ayubi P, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102472
   Bakhshandeh A, 2013, OPT LASER ENG, V51, P665, DOI 10.1016/j.optlaseng.2013.01.001
   Bany D., 2019, INT J NETW SECUR APP, V11, P41
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chen SH, 2002, PHYS LETT A, V299, P353, DOI 10.1016/S0375-9601(02)00522-4
   Demirtas M, 2022, OPTIK, V266, DOI 10.1016/j.ijleo.2022.169624
   Fridrich J, 1997, IEEE SYS MAN CYBERN, P1105, DOI 10.1109/ICSMC.1997.638097
   HENON M, 1976, COMMUN MATH PHYS, V50, P69, DOI 10.1007/BF01608556
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Joshi AB, 2020, OPT LASER ENG, V133, DOI 10.1016/j.optlaseng.2020.106139
   KAY S, 1995, IEEE T SIGNAL PROCES, V43, P2013, DOI 10.1109/78.403367
   Laia O., 2021, Journal of Physics: Conference Series, V1898, DOI 10.1088/1742-6596/1898/1/012017
   Li CQ, 2014, NONLINEAR DYNAM, V78, P1545, DOI 10.1007/s11071-014-1533-8
   Li S., 2021, SECUR COMMUN NETW, V66, P27
   Li X., 2018, Int. J. Netw. Secur, V20, P110, DOI DOI 10.6633/IJNS.201801
   Ling C, 1999, IEEE T SIGNAL PROCES, V47, P1424, DOI 10.1109/78.757236
   Liu GZ, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24050608
   Maddodi G, 2018, MULTIMED TOOLS APPL, V77, P24701, DOI 10.1007/s11042-018-5669-2
   Naskar PK, 2021, NONLINEAR DYNAM, V105, P3673, DOI 10.1007/s11071-021-06761-0
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Patidar V, 2009, COMMUN NONLINEAR SCI, V14, P3056, DOI 10.1016/j.cnsns.2008.11.005
   Rani N, 2023, NONLINEAR DYNAM, V111, P2869, DOI 10.1007/s11071-022-07958-7
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Sha YW, 2022, EUR PHYS J-SPEC TOP, V231, P3249, DOI 10.1140/epjs/s11734-022-00566-x
   Sonam P, 2023, 2014 INT C REL OPT I, V5, P413
   Tanveer H., 2020, J INF SECUR APPL, V54, P592
   Tong LJ, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6650515
   Wang B, 2013, OPTIK, V124, P1773, DOI 10.1016/j.ijleo.2012.06.020
   Wang T, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106355
   Wang T, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24081053
   Wang X., 2021, SIGNAL PROCESS-IMAGE, V95, P333
   Wang XY, 2021, CHAOS SOLITON FRACT, V150, DOI 10.1016/j.chaos.2021.111117
   Wang XY, 2021, CHAOS SOLITON FRACT, V147, DOI 10.1016/j.chaos.2021.110962
   Wang XY, 2020, OPT LASER TECHNOL, V131, DOI 10.1016/j.optlastec.2020.106366
   Wang XY, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105581
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Xu QY, 2019, OPT LASER ENG, V121, P203, DOI 10.1016/j.optlaseng.2019.04.011
   Yap WS, 2016, WIRELESS PERS COMMUN, V88, P685, DOI 10.1007/s11277-016-3192-1
   Ye HS, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107652
   Zarebnia M, 2019, OPTIK, V179, P761, DOI 10.1016/j.ijleo.2018.10.025
   Zhang Q, 2014, AEU-INT J ELECTRON C, V68, P186, DOI 10.1016/j.aeue.2013.08.007
   Zhang XQ, 2022, MULTIMED TOOLS APPL, V81, P31753, DOI 10.1007/s11042-022-13003-x
   Zhang XQ, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11162512
   Zhang XQ, 2022, PHYS SCRIPTA, V97, DOI 10.1088/1402-4896/ac8840
   Zhang XQ, 2022, MULTIMED TOOLS APPL, V81, P20021, DOI 10.1007/s11042-022-12554-3
   Zhang XQ, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10151770
   Zhang XC, 2019, INT J OPT, V2019, DOI 10.1155/2019/3594534
   Zhao F., 2021, OPT LASER TECHNOL, V135, P1
   Zhao HJ, 2016, OPT ENG, V55, DOI 10.1117/1.OE.55.9.093109
   Zhao Y., 2023, OPTIK, V27, P1
   Zhou S, 2023, INFORM SCIENCES, V621, P782, DOI 10.1016/j.ins.2022.11.104
   Zhu CY, 2019, MICROSC MICROANAL, V25, P912, DOI 10.1017/S1431927619000710
   Zhu HG, 2021, MATH COMPUT SIMULAT, V185, P754, DOI 10.1016/j.matcom.2021.02.009
   Zhu SQ, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20090716
NR 59
TC 0
Z9 0
U1 17
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 8
PY 2023
DI 10.1007/s11042-023-16404-8
EA AUG 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O6EV9
UT WOS:001044727600003
DA 2024-07-18
ER

PT J
AU Thangaraj, R
   Pandiyan, P
   Anandamurugan, S
   Rajendar, S
AF Thangaraj, Rajasekaran
   Pandiyan, P.
   Anandamurugan, S.
   Rajendar, Sivaramakrishnan
TI A deep convolution neural network model based on feature concatenation
   approach for classification of tomato leaf disease
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Multi-level feature fusion; Tomato leaf disease
   classification; Transfer learning; Xception; Inception V3; MobileNet V1;
   MobileNet V2
ID DIAGNOSIS; VIRUSES; LEAVES
AB Plant diseases pose a significant threat to the agriculture sector, leading to a substantial decrease in yield and economic losses. Therefore, early and precise detection of plant diseases is crucial in the field of agriculture. Managing the spread of diseases across crops and minimizing production losses presents a considerable challenge. Deep Learning (DL) has emerged as a promising method for identifying plant diseases due to its impressive performance. In this paper, we propose a Modified-Xception based Multi-Level Feature Fusion (MX-MLF2) model. This model utilizes multi-level feature extraction and feature fusion techniques to classify tomato leaf diseases. Additionally, we employ a transfer learning and fine-tuning approach to enhance the prediction accuracy of tomato leaf diseases. To evaluate the performance of MX-MLF2, we compare it with other pre-trained deep learning models such as MobileNet V1, MobileNet V2, and Inception V3. The experimental results demonstrate that the MX-MLF2 model outperforms these pre-trained models, achieving a remarkable detection accuracy of 99.61%.
C1 [Thangaraj, Rajasekaran] KPR Inst Engn & Technol, Ctr IoT & AI, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
   [Pandiyan, P.] KPR Inst Engn & Technol, Dept Elect & Elect Engn, Coimbatore, Tamil Nadu, India.
   [Anandamurugan, S.] Kongu Engn Coll, Dept Informat Technol, Perundurai, Tamil Nadu, India.
   [Rajendar, Sivaramakrishnan] KPR Inst Engn & Technol, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
C3 Kongu Engineering College
RP Thangaraj, R (corresponding author), KPR Inst Engn & Technol, Ctr IoT & AI, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
EM rajasekaran30@gmail.com; pandyyan@gmail.com; dranandamurugan@gmail.com;
   sivaraamakrishnan2010@gmail.com
RI Thangaraj, Rajasekaran/HTM-9563-2023
OI Thangaraj, Rajasekaran/0000-0003-0874-7638
CR Agarwal M, 2020, PROCEDIA COMPUT SCI, V167, P293, DOI 10.1016/j.procs.2020.03.225
   Al-Hiary H., 2011, International Journal of Computer Applications, V17, P31, DOI [10.5120/2183-2754, DOI 10.5120/2183-2754]
   Annabel L. Sherly Puspha, 2019, 2019 Third International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P506, DOI 10.1109/I-SMAC47947.2019.9032621
   [Anonymous], 2009, J AGR MECH RES
   Brahimi M, 2017, APPL ARTIF INTELL, V31, P299, DOI 10.1080/08839514.2017.1315516
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Das Debasish, 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P1036, DOI 10.1109/ICCSP48568.2020.9182128
   Durmus H, 2017, INT CONF AGRO-GEOINF, P46
   Elhassouny A., 2019, INT C COMP SCI REN E, P1, DOI [DOI 10.1109/ICCSRE.2019.8807737, 10.1109/ICCSRE.2019.8807737]
   Fekri-Ershad S, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113509
   Foysal MFA, 2020, P INT JOINT C COMP I, P583, DOI DOI 10.1007/978-981-13-7564-4_49
   Fuentes A, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.01321
   Fuentes A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092022
   Fuentes AF, 2018, FRONT PLANT SCI, V9, DOI 10.3389/fpls.2018.01162
   Gilbertson RL, 2013, ACTA HORTIC, V971, P35, DOI 10.17660/ActaHortic.2013.971.2
   Hanssen IM, 2012, ADV VIRUS RES, V84, P31, DOI 10.1016/B978-0-12-394314-9.00002-6
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hlaing Chit Su, 2018, 2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS). Proceedings, P439, DOI 10.1109/ICIS.2018.8466483
   Hlaing Chit Su, 2017, 2017 18th International Conference on Parallel and Distributed Computing, Applications and Technologies (PDCAT). Proceedings, P223, DOI 10.1109/PDCAT.2017.00044
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hughes D., 2015, ABS151108060 CORR
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jia Shijie, 2017, 2017 Chinese Automation Congress (CAC). Proceedings, P3507, DOI 10.1109/CAC.2017.8243388
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Karthik R, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105933
   Kumar A, 2019, PHYS STATUS SOLIDI A, V216, DOI 10.1002/pssa.201800786
   Liu J, 2020, PLANT METHODS, V16, DOI 10.1186/s13007-020-00624-2
   Mishkin D, 2015, ARXIV
   Mokhtar U, 2015, 2015 11TH INTERNATIONAL COMPUTER ENGINEERING CONFERENCE (ICENCO), P246, DOI 10.1109/ICENCO.2015.7416356
   Mokhtar U, 2015, ADV INTELL SYST, V323, P641, DOI 10.1007/978-3-319-11310-4_55
   Mokhtar U, 2015, ADV INTELL SYST, V339, P771, DOI 10.1007/978-81-322-2250-7_77
   Nandhini S, 2021, MULTIMED TOOLS APPL, V80, P18583, DOI 10.1007/s11042-021-10599-4
   Noreen N, 2020, IEEE ACCESS, V8, P55135, DOI 10.1109/ACCESS.2020.2978629
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Prabhakar M, 2020, MULTIMED TOOLS APPL, V79, P28773, DOI 10.1007/s11042-020-09461-w
   Prajwala TM, 2018, INT CONF CONTEMP, P314
   Rangarajan AK, 2018, PROCEDIA COMPUT SCI, V133, P1040, DOI 10.1016/j.procs.2018.07.070
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Rubanga DP, 2020, ARXIV
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sabrol H, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1242, DOI 10.1109/ICCSP.2016.7754351
   Sabrol H., 2016, INT J COMPUT SCI INF, V14, P622
   Suryawati E, 2018, INT C ADV COMP SCI I, P385, DOI 10.1109/ICACSIS.2018.8618169
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Thangaraj R, 2021, J PLANT DIS PROTECT, V128, P73, DOI 10.1007/s41348-020-00403-0
   Wang X., 2021, FRONT PLANT SCI, V12, P533
   Wolfert S, 2017, AGR SYST, V153, P69, DOI 10.1016/j.agsy.2017.01.023
   Xie C, 2015, SCI REP-UK, V5, DOI 10.1038/srep08914
   Zhang KK, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/6710865
   Zhao Yu-xia, 2007, Computer Engineering and Applications, V43, P193
NR 51
TC 3
Z9 3
U1 8
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 18803
EP 18827
DI 10.1007/s11042-023-16347-0
EA AUG 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040960900001
DA 2024-07-18
ER

PT J
AU Ennaji, A
   El Khoukhi, H
   Sabri, MA
   Aarab, A
AF Ennaji, Asmae
   El Khoukhi, Hasnae
   Sabri, My Abdelouahed
   Aarab, Abdellah
TI Malignant melanoma detection using multi-scale image decomposition and a
   new ensemble-learning scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Melanoma diagnosis; Computer Aided Diagnosis (CAD) system; Dermoscopic
   images; Image decomposition; Machine learning; SVM; Ensemble learning;
   Voting classifier
ID SKIN-CANCER; CLASSIFICATION; RECOGNITION; DIAGNOSIS; LESIONS
AB Malignant melanoma is one of the most serious and deadly types of skin cancer, fortunately it is treatable if detected at an early stage. Many Computer-Aided Diagnosis (CAD) systems are proposed in the literature to assist in detecting this type of cancer. The vast majority of them are performed in four main steps, which are preprocessing, image segmentation, features extraction, and classification. In this paper, we propose a new ensemble-learning scheme that uses three classifiers each one based, separately, on a different type of features: color, texture, and shape. Moreover, in order to be able to efficiently identify the lesion and safe skin region and thus extract the features, we proposed using, as a preprocessing step, a multi-scale image decomposition based on Partial Differential Equations (PDE) that will allow us to isolate the object and the texture from the image. Color and texture features will be extracted from both, the safe skin and the extracted lesion, while shape features will be extracted from only the detected lesion. We proposed using the SVM algorithm for the design of each of the three classifiers and the final diagnostic decision is obtained by applying the majority voting approach. The proposed model was validated and tested on the public PH2 database, achieving a classification accuracy of 98%, rappel of 95%, and precision of 95%; we can conclude that the proposed approach is very promising.
C1 [Ennaji, Asmae; El Khoukhi, Hasnae; Sabri, My Abdelouahed; Aarab, Abdellah] USMBA, Fac Sci Dhar Mahraz FSDM, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP Ennaji, A (corresponding author), USMBA, Fac Sci Dhar Mahraz FSDM, Fes, Morocco.
EM asmae.ennaji@usmba.ac.ma
OI ennaji, asmae/0000-0002-0592-2376
CR Adegun AA, 2020, IEEE ACCESS, V8, P150377, DOI 10.1109/ACCESS.2020.3016651
   Al-masni MA, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105351
   Alfed N, 2017, EXPERT SYST APPL, V90, P101, DOI 10.1016/j.eswa.2017.08.010
   Almaraz-Damian JA, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22040484
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Bühlmann P, 2007, STAT SCI, V22, P477, DOI 10.1214/07-STS242
   Codella NCF, 2017, IBM J RES DEV, V61, DOI 10.1147/JRD.2017.2708299
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   El-Khatib H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061753
   Ennaji A., 2014, INT REV COMPUT SOFTW, V9, P1861, DOI [10.15866/irecos.v9i11.4046, DOI 10.15866/IRECOS.V9I11.4046]
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Filali Y, 2020, MULTIMED TOOLS APPL, V79, P31219, DOI 10.1007/s11042-020-09637-4
   Filali Y, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL AND INFORMATION TECHNOLOGIES (ICEIT 2017)
   Isasi AG, 2011, COMPUT BIOL MED, V41, P742, DOI 10.1016/j.compbiomed.2011.06.010
   Jayapriya K, 2020, INT J IMAG SYST TECH, V30, P348, DOI 10.1002/ima.22377
   Acosta MFJ, 2021, BMC MED IMAGING, V21, DOI 10.1186/s12880-020-00534-8
   Karabag C, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9183900
   Khan MQ, 2019, IEEE ACCESS, V7, P90132, DOI 10.1109/ACCESS.2019.2926837
   Kumar M, 2020, MOBILE NETW APPL, V25, P1319, DOI 10.1007/s11036-020-01550-2
   Tiwari AK, 2021, J MECH MED BIOL, V21, DOI 10.1142/S0219519421500299
   Mendonc T, 2013, 35 ANN INT C IEEE EM, P3
   Meyer Y., 2001, Memoirs of the American Mathematical Society
   Moradi N, 2019, COMPUT METH PROG BIO, V182, DOI 10.1016/j.cmpb.2019.105038
   Naeem A, 2020, IEEE ACCESS, V8, P110575, DOI 10.1109/ACCESS.2020.3001507
   Olivas-Padilla BE, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21072497
   Pourdarbani R, 2020, FOODS, V9, DOI 10.3390/foods9020113
   Sabri M A, 2021, INTELLIGENT SYSTEMS, V1344
   Sachdeva S, 2009, INDIAN J DERMATOL VE, V75, P93, DOI 10.4103/0378-6323.45238
   Tajeddin NZ, 2018, COMPUT METH PROG BIO, V163, P143, DOI 10.1016/j.cmpb.2018.05.005
   Tschandl P, 2019, LANCET ONCOL, V20, P938, DOI 10.1016/S1470-2045(19)30333-X
   Vapnik V., 1999, NATURE STAT LEARNING
   Vese LA, 2003, J SCI COMPUT, V19, P553, DOI 10.1023/A:1025384832106
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Xie FY, 2017, IEEE T MED IMAGING, V36, P849, DOI 10.1109/TMI.2016.2633551
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Zhu W., 2010, Northeast SAS Users Group 2010: Health Care and Life Sciences, P1
NR 36
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21213
EP 21228
DI 10.1007/s11042-023-16391-w
EA JUL 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040925900010
DA 2024-07-18
ER

PT J
AU Kalaivani, A
   Karpagavalli, S
AF Kalaivani, A.
   Karpagavalli, S.
TI Bootstrapping of fine-tuned segmentation and classification network for
   epidermis disorder categorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Epidermis infection; Deep transfer learning; F-SegClassNet; Imbalanced
   data; DCNN; Bootstrapping
AB As all people have been affected by various skin related illnesses, categorization of skin disorders has become prominent in recent healthcare system. To identify and categorize skin related syndromes, many transfer learning frameworks were used. Amongst, a Fine-tuned Segmentation and Classification Network (F-SegClassNet) achieved better efficacy by using the novel unified loss function. Nonetheless, it was not apt for the datasets that lack in training images. Hence in this article, Bootstrapping of F-SegClassNet (BF-SegClassNet) model is proposed which solves the imbalanced images in the training set via generating the group of pseudo balanced training batches relying on the properties of the considered skin image dataset. This model fits the distinct abilities of Deep Convolutional Neural Network (DCNN) classifier so that it is highly useful for classifying the skin disorder image dataset with a highly imbalanced image data distribution. According to the Bootstrpping, better tradeoff between simple and complex image samples is realized to make a network model that is suitable for automatic skin disorders classification. In this model, statistics across the complete training set is calculated and a new subset is produced that retains the most essential image samples. So, the skin images are segmented and categorized by this new model to identify the varieties of epidermis infections. At last, the testing outcomes exhibits BF-SegClassNet-model accomplishes the mean accuracy with 96.14% for HAM dataset which is compared to state-of-the-art models.
C1 [Kalaivani, A.; Karpagavalli, S.] PSGR Krishnammal Coll Women, Dept Comp Sci, Coimbatore, Tamilnadu, India.
RP Kalaivani, A (corresponding author), PSGR Krishnammal Coll Women, Dept Comp Sci, Coimbatore, Tamilnadu, India.
EM kalaivani20213@gmail.com
CR Al-masni MA, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105351
   Back S, 2021, IEEE ACCESS, V9, P20156, DOI 10.1109/ACCESS.2021.3054403
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Balaji VR, 2020, MEASUREMENT, V163, DOI 10.1016/j.measurement.2020.107922
   Bhaik A, 2022, INT J INTERACT MULTI, V7, P14, DOI 10.9781/ijimai.2021.09.003
   Chen K, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.04191
   Giesey RL, 2020, JAAD INT, V1, P3, DOI 10.1016/j.jdin.2020.03.002
   Goyal M, 2020, COMPUT BIOL MED, V127, DOI 10.1016/j.compbiomed.2020.104065
   Gu YY, 2020, IEEE J BIOMED HEALTH, V24, P1379, DOI 10.1109/JBHI.2019.2942429
   Hameed N, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112961
   Kalaivani A., 2021, TURK ONLINE J QUAL I, V12, P1675
   Kalaivani DS., 2021, LINGUISTICA ANTVERP, V15, P1
   Laishram A, 2022, INT J INTERACT MULTI, V7, P69, DOI 10.9781/ijimai.2021.10.009
   Lundervold AS, 2019, Z MED PHYS, V29, P102, DOI 10.1016/j.zemedi.2018.11.002
   Maron RC, 2019, EUR J CANCER, V119, P57, DOI 10.1016/j.ejca.2019.06.013
   Pham TC, 2020, IEEE ACCESS, V8, P150725, DOI 10.1109/ACCESS.2020.3016653
   Qiu S, 2022, EEG SIGNAL RECOGNITI, DOI [10.9781/ijimai.2022.07.001, DOI 10.9781/IJIMAI.2022.07.001]
   Serte S, 2019, COMPUT BIOL MED, V113, DOI 10.1016/j.compbiomed.2019.103423
   Tang P, 2020, IEEE J BIOMED HEALTH, V24, P2870, DOI 10.1109/JBHI.2020.2977013
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Yotsu RR, 2020, PLOS NEGLECT TROP D, V14, DOI 10.1371/journal.pntd.0008291
NR 21
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 18907
EP 18917
DI 10.1007/s11042-023-16255-3
EA JUL 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001036798900003
DA 2024-07-18
ER

PT J
AU Mittal, S
   Mishra, A
   Khatter, K
AF Mittal, Shashank
   Mishra, Atul
   Khatter, Kiran
TI Psquad: Plagiarism detection and document similarity of Hindi text
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Statistical; Document similarity; Plagiarism detection;
   Paraphrasing
ID ENGLISH
AB Plagiarism is a significant issue, especially among students, in the education field, where the internet has made a vast amount of information easily accessible. Although numerous plagiarism detection tools are available for English text, detecting plagiarism in low-resource languages such as Hindi remains a challenge. This study proposes a novel case-based approach to evaluate the effectiveness of various plagiarism detection tools on Hindi documents. The proposed approach maps similarities between Hindi documents at the word, phrase, and sentence levels, and generates diverse cases using stopword removal and stemming pre-processing techniques. The study calculates the similarity score between the original Hindi document and its paraphrased version at the word, sentence, and document levels. The results show that the proposed approach outperforms existing plagiarism detection tools for Hindi text, indicating its potential to enhance academic integrity and prevent plagiarism.
C1 [Mittal, Shashank; Mishra, Atul; Khatter, Kiran] BML Munjal Univ, Gurugram, India.
C3 BML Munjal University
RP Mishra, A (corresponding author), BML Munjal Univ, Gurugram, India.
EM shashank.mittal.16cse@bml.edu.in; atul.mishra@bmu.edu.in;
   kiran.khatter@bmu.edu.in
CR Agarwal B, 2023, BIG DATA, V11, P48, DOI 10.1089/big.2020.0243
   Agarwal B, 2019, J DISCRET MATH SCI C, V22, P679, DOI 10.1080/09720529.2019.1642626
   Ali W., 2018, 2018 24 INT C AUT CO, P1
   AlSallal M, 2019, FUTURE GENER COMP SY, V96, P700, DOI 10.1016/j.future.2017.11.023
   [Anonymous], PLAG CHECK X PRO
   [Anonymous], PLAG PLAG CHECK
   [Anonymous], 2020, PLAG CHECK 100 FREE
   Bhargava R., 2017, P 2017 IEEE ACM INT, P1152
   Bhattacharyya P, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3785
   Butakov Sergey, 2016, MOODLE PLUGINS DIREC
   Copyleaks, COP PLAG SOFTW DISC
   Garg U., 2016, INDIAN J SCI TECHNOL, V9, P1, DOI 10.17485/ijst/2016/v9i47/101745
   Gupta D, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2694, DOI 10.1109/ICACCI.2014.6968314
   Jha J, 2018, ONTOSENSENET VERB CE, DOI DOI 10.13140/RG.2.2.29641.03687
   Lamba H, 2017, INT J COMPUT APPL
   Ljubovic V, 2020, IEEE ACCESS, V8, P96505, DOI 10.1109/ACCESS.2020.2996146
   Mishra A, 2022, MULTIMED TOOLS APPL, V81, P35655, DOI 10.1007/s11042-021-11884-y
   Mogren O., 2015, Proceedings of Recent Advances in Natural Language Processing, P451
   Naik RR, 2019, SCHOLARLY ETHICS PUB, P473
   Ohala Manjari., 1994, J INT PHON ASSOC, V24, P35, DOI DOI 10.1017/S0025100300004990
   Quetext, OR WRIT MAD EAS QUET
   Shahmohammadi H, 2021, MULTIMED TOOLS APPL, V80, P6479, DOI 10.1007/s11042-020-09996-y
   Shang HF, 2019, J COMPUT HIGH EDUC, V31, P105, DOI 10.1007/s12528-018-9193-1
   Sneha B, 2016, ADV INTELL SYST, V408, P657, DOI 10.1007/978-981-10-0129-1_68
   Sonkar SK, 2021, ROLE TECHNOLOGY PREV
   TDIL-DC, ONL HIND WORDN
   Turnitin T, 2021, EMP STUD DO THEIR BE
   Ullah F, 2020, MULTIMED TOOLS APPL, V79, P8581, DOI 10.1007/s11042-018-5827-6
NR 28
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17299
EP 17326
DI 10.1007/s11042-023-15921-w
EA JUL 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001034665300008
DA 2024-07-18
ER

PT J
AU Zaman, MI
   Bajwa, UI
   Saleem, G
   Raza, RH
AF Zaman, Muhammad Imran
   Bajwa, Usama Ijaz
   Saleem, Gulshan
   Raza, Rana Hammad
TI A robust deep networks based multi-object multi-camera tracking system
   for city scale traffic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AI City Challange; Traffic monitoring; Object tracking; Multi-camera;
   Deep SORT
ID MULTITARGET
AB Vision sensors are becoming more important in Intelligent Transportation Systems (ITS) for traffic monitoring, management, and optimization as the number of network cameras continues to rise. However, manual object tracking and matching across multiple non-overlapping cameras pose significant challenges in city-scale urban traffic scenarios. These challenges include handling diverse vehicle attributes, occlusions, illumination variations, shadows, and varying video resolutions. To address these issues, we propose an efficient and cost-effective deep learning-based framework for Multi-Object Multi-Camera Tracking (MO-MCT). The proposed framework utilizes Mask R-CNN for object detection and employs Non-Maximum Suppression (NMS) to select target objects from overlapping detections. Transfer learning is employed for re-identification, enabling the association and generation of vehicle tracklets across multiple cameras. Moreover, we leverage appropriate loss functions and distance measures to handle occlusion, illumination, and shadow challenges. The final solution identification module performs feature extraction using ResNet-152 coupled with Deep SORT based vehicle tracking. The proposed framework is evaluated on the 5th AI City Challenge dataset (Track 3), comprising 46 camera feeds. Among these 46 camera streams, 40 are used for model training and validation, while the remaining six are utilized for model testing. The proposed framework achieves competitive performance with an IDF1 score of 0.8289, and precision and recall scores of 0.9026 and 0.8527 respectively, demonstrating its effectiveness in robust and accurate vehicle tracking.
C1 [Zaman, Muhammad Imran; Bajwa, Usama Ijaz; Saleem, Gulshan] COMSATS Univ Islamabad, Dept Comp Sci, Lahore Campus, Lahore, Pakistan.
   [Raza, Rana Hammad] Natl Univ Sci & Technol NUST, Pakistan Navy Engn Coll, Islamabad, Pakistan.
C3 COMSATS University Islamabad (CUI); National University of Sciences &
   Technology - Pakistan
RP Bajwa, UI (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Lahore Campus, Lahore, Pakistan.
EM imranzaman.ml@gmail.com; usamabajwa@cuilahore.edu.pk;
   gulshnsaleem26@gmail.com; hammad@pnec.nust.edu.pk
OI Bajwa, Usama/0000-0001-5755-1194
CR Ahmed N. K., 2019, Proceedings of the Tenth International Conference on Information and Communication Technologies and Development, P1, DOI [DOI 10.1145/3287098, 10.1016/B978-0-12-818023-5.00001-7]
   Ahmed N, 2022, SOFT COMPUT, V26, P7601, DOI 10.1007/s00500-021-06662-9
   Ahmed N, 2021, MULTIMED TOOLS APPL, V80, P15677, DOI 10.1007/s11042-020-10286-w
   Ahmed N, 2020, COMPUT INFORM, V39, P385, DOI 10.31577/cai_2020_3_385
   Amjoud Ayoub Benali, 2020, Image and Signal Processing. 9th International Conference, ICISP 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12119), P282, DOI 10.1007/978-3-030-51935-3_30
   Gou MR, 2017, IEEE COMPUT SOC CONF, P1425, DOI 10.1109/CVPRW.2017.185
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He YH, 2020, IEEE COMPUT SOC CONF, P2456, DOI 10.1109/CVPRW50498.2020.00296
   Hosang J, 2017, PROC CVPR IEEE, P6469, DOI 10.1109/CVPR.2017.685
   Kim SW, 2018, LECT NOTES COMPUT SC, V11209, P239, DOI 10.1007/978-3-030-01228-1_15
   Kohl P., 2020, P IEEECVF C COMPUTER, P1042
   Kulkarni P, 2019, LECT NOTES COMPUT SC, V11663, P208, DOI 10.1007/978-3-030-27272-2_18
   Kumar R, 2015, LECT NOTES COMPUT SC, V9006, P445, DOI 10.1007/978-3-319-16817-3_29
   Labbe Yann, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P574, DOI 10.1007/978-3-030-58520-4_34
   Li HZ, 2019, IEEE ANN INT CONF CY, P1, DOI 10.1109/CYBER46603.2019.9066601
   Li P., 2019, P CVPR WORKSH, P222
   Li Peiliang, 2019, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
   Liu C, 2021, IEEE COMPUT SOC CONF, P4124, DOI 10.1109/CVPRW53098.2021.00466
   Liu JQ, 2017, I C VIRTUAL REALITY, P1, DOI 10.1109/ICVRV.2017.00010
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lv ZH, 2021, IEEE T INTELL TRANSP, V22, P4579, DOI 10.1109/TITS.2020.3017183
   Ma C, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P253, DOI 10.1145/3323873.3325010
   Martinel N, 2020, IEEE T IMAGE PROCESS, V29, P7306, DOI 10.1109/TIP.2020.3000904
   Naphade M., 2019, CVPR WORKSH, V8, P2
   Naphade M, 2021, IEEE COMPUT SOC CONF, P4258, DOI 10.1109/CVPRW53098.2021.00482
   Ning X, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108873
   Peri N, 2020, IEEE COMPUT SOC CONF, P2648, DOI 10.1109/CVPRW50498.2020.00319
   Qian XL, 2017, IEEE I CONF COMP VIS, P5409, DOI 10.1109/ICCV.2017.577
   Qiu ZJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20154082
   Ren P., 2021, P IEEE CVF C COMP VI, P4213
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Saleem G., SURVEILIA ANOMALY ID
   Saleem G, 2023, NEURAL COMPUT APPL, V35, P4145, DOI 10.1007/s00521-022-07937-4
   Saleem M, 2022, EGYPT INFORM J, V23, P417, DOI 10.1016/j.eij.2022.03.003
   Schofield K., 1998, US Patent, Patent No. [5,786,772, 5786772]
   Sharma A, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.104022
   Shim K, 2021, IEEE COMPUT SOC CONF, P4188, DOI 10.1109/CVPRW53098.2021.00473
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Specker A, 2021, IEEECVF CVPR, P4173
   Sun H, 2019, IEEE I CONF COMP VIS, P6736, DOI 10.1109/ICCV.2019.00684
   Sun SJ, 2021, IEEE T PATTERN ANAL, V43, P104, DOI 10.1109/TPAMI.2019.2929520
   Tan L., 2018, 2018 11 INT C IM SIG, P1
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tan X., 2019, P IEEE C COMP VIS PA, P275
   Tang Siyu., 2015, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P5033
   Tesfaye YT, 2019, INT J COMPUT VISION, V127, P1303, DOI 10.1007/s11263-019-01180-6
   Voigtlaender P, 2019, PROC CVPR IEEE, P7934, DOI 10.1109/CVPR.2019.00813
   Wang CS, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3170493
   Wang C, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108498
   Wang Q., 2020, MTCNN KCF DEEPSORT D
   Wang QM, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3108540
   Wang Z., 2020, COMPUTER VISION ECCV, P107, DOI [10.1007/978-3-030-58621-8_7, DOI 10.1007/978-3-030-58621-8_7]
   Wen LY, 2020, COMPUT VIS IMAGE UND, V193, DOI 10.1016/j.cviu.2020.102907
   Wu MH, 2021, IEEE COMPUT SOC CONF, P4072, DOI 10.1109/CVPRW53098.2021.00460
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang KS, 2021, IEEE COMPUT SOC CONF, P3978, DOI 10.1109/CVPRW53098.2021.00449
   Ye J., 2021, P IEEE CVF C COMP VI, P4044
   Yoon K, 2020, IEEE ACCESS, V8, P38060, DOI 10.1109/ACCESS.2020.2975912
   Yuan Y, 2019, IEEE T IMAGE PROCESS, V28, P3423, DOI 10.1109/TIP.2019.2896952
   Zhang K, 2018, IEEE T CIRC SYST VID, V28, P1303, DOI 10.1109/TCSVT.2017.2654543
   Zhang Y, 2020, IEEE T IMAGE PROCESS, V29, P6694, DOI 10.1109/TIP.2020.2993073
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
NR 63
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17163
EP 17181
DI 10.1007/s11042-023-16243-7
EA JUL 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035582300002
DA 2024-07-18
ER

PT J
AU Sarkar, NK
   Singh, MM
   Nandi, U
AF Sarkar, Nayan Kumar
   Singh, Moirangthem Marjit
   Nandi, Utpal
TI A novel deep neural network model using network deconvolution with
   attention based activation for crop disease classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Crop disease; Convolutional neural network;
   Network deconvolution; Attention based activation
AB Accurate classification of crop diseases in its initial phase can help farmers to take necessary actions against the damage to their crops. The paper presents a Deep Learning (DL)-based crop disease classification approach that uses network deconvolution operation and attention-based activation function in each feature extraction layer. The existence of channel-wise and pixel-wise correlations in real-world images makes model training challenging. There is hardly any method available in the current literature that proposes the image correlation removal technique. The network deconvolution operation can efficiently remove both the correlations layer-wise. Hence, it is used in the proposed model. An attention-based activation function called AReLU is adopted in the model. The significance of AReLU activation function is to facilitate faster training. It can deal with gradient vanishing issue. The study considered Plant Village (PV), Tomato, and Grape datasets for performance evaluation. 80: 20 train-test split of the dataset was considered. The proposed model delivered significant results in comparison to other existing models, offering 100%, 99.27% and 99.10% classification accuracies and 99.88%, 99.06% and 99.01% F1-scores on Grape, PV and Tomato datasets respectively.
C1 [Sarkar, Nayan Kumar; Singh, Moirangthem Marjit] North Eastern Reg Inst Sci & Technol, Dept Comp Sci & Engn, Nirjuli, Arunachal Prade, India.
   [Nandi, Utpal] Vidyasagar Univ, Dept Comp Sci, Midnapore, West Bengal, India.
C3 North Eastern Regional Institute of Science & Technology (NERIST);
   Vidyasagar University
RP Singh, MM (corresponding author), North Eastern Reg Inst Sci & Technol, Dept Comp Sci & Engn, Nirjuli, Arunachal Prade, India.
EM nayankrsarkar@gmail.com; marjitm@gmail.com; nandi.3utpal@gmail.com
RI Singh, Moirangthem Marjit/KPA-8781-2024; Nandi, Utpal/AAW-9041-2021
OI Singh, Moirangthem Marjit/0000-0002-7314-9645; Nandi,
   Utpal/0000-0002-9638-1906; Sarkar, Nayan Kumar/0000-0002-5844-7978
CR Abou El-Maged Lobna M., 2020, Proceedings of the International Conference on Artificial Intelligence and Computer Vision (AICV2020). Advances in Intelligent Systems and Computing (AISC 1153), P3, DOI 10.1007/978-3-030-44289-7_1
   Agarwal M, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100407
   Albattah W, 2022, COMPLEX INTELL SYST, V8, P507, DOI 10.1007/s40747-021-00536-1
   Archana KS, 2022, J SUPERCOMPUT, V78, P8925, DOI 10.1007/s11227-021-04245-x
   Ashwinkumar S, 2022, MATER TODAY-PROC, V51, P480, DOI 10.1016/j.matpr.2021.05.584
   Bruinsma J., 2009, Proceedings of a Technical Meeting of Experts, Rome, Italy, 24-26 June 2009
   Chen D, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2006.13858
   Chen HC, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11060951
   Chen JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105393
   Durmus H, 2017, INT CONF AGRO-GEOINF, P46
   Elfatimi E, 2022, IEEE ACCESS, V10, P9471, DOI 10.1109/ACCESS.2022.3142817
   Fuentes A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092022
   Geetharamani G, 2019, COMPUT ELECTR ENG, V76, P323, DOI 10.1016/j.compeleceng.2019.04.011
   Hassan SM, 2022, IEEE ACCESS, V10, P5390, DOI 10.1109/ACCESS.2022.3141371
   Jaison Shaleena, 2019, 2019 IEEE 1st Global Conference on Life Sciences and Technologies (LifeTech), P1, DOI 10.1109/LifeTech.2019.8883974
   Karthik R, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105933
   Kaur Manveet, 2019, 2019 URSI Asia-Pacific Radio Science Conference (AP-RASC), DOI 10.23919/URSIAP-RASC.2019.8738576
   Khalifa N.E.M., 2021, Machine Learning and Big Data Analytics Paradigms: Analysis, Applications and Challenges, P63, DOI 10.1007/978-3-030-59338-4_4/COVER
   Li Y, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105803
   Liao YH, 2002, COMPUT SECUR, V21, P439, DOI 10.1016/S0167-4048(02)00514-X
   Miaomiao Ji, 2020, Information Processing in Agriculture, V7, P418, DOI 10.1016/j.inpa.2019.10.003
   Mohanty S. P., 2016, Frontiers in Plant Science, V7, P1419
   Pandian JA, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11081266
   Rangarajan AK, 2018, PROCEDIA COMPUT SCI, V133, P1040, DOI 10.1016/j.procs.2018.07.070
   Rashid J, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10172064
   Rokach L, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P165, DOI 10.1007/0-387-25465-X_9
   Saeed F, 2021, APPL SOFT COMPUT, V103, DOI 10.1016/j.asoc.2021.107164
   Scholkopf B., 1999, Making large scale svm learning practical, P41
   Syed-Ab-Rahman SF, 2022, APPL INTELL, V52, P927, DOI 10.1007/s10489-021-02452-w
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tang Z, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105735
   Thangaraj R, 2021, J PLANT DIS PROTECT, V128, P73, DOI 10.1007/s41348-020-00403-0
   Thenmozhi K, 2019, COMPUT ELECTRON AGR, V164, DOI 10.1016/j.compag.2019.104906
   Vedaldi A., 2016, VGG convolutional neural networks practical, V66
   Wu QF, 2020, IEEE ACCESS, V8, P98716, DOI 10.1109/ACCESS.2020.2997001
   Yang GF, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.600854
   Ye C, 2019, ARXIV, DOI DOI 10.48550/ARXIV.1905.11926
   Yuan Y, 2018, LECT NOTES COMPUT SC, V11257, P457, DOI 10.1007/978-3-030-03335-4_40
   Yuan ZW, 2016, PROC SPIE, V10033, DOI 10.1117/12.2243849
NR 39
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17025
EP 17045
DI 10.1007/s11042-023-16125-y
EA JUL 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001032628900002
DA 2024-07-18
ER

PT J
AU Afzal, H
   Rustam, F
   Aljedaani, W
   Siddique, MA
   Ullah, S
   Ashraf, I
AF Afzal, Hina
   Rustam, Furqan
   Aljedaani, Wajdi
   Siddique, Muhammad Abubakar
   Ullah, Saleem
   Ashraf, Imran
TI Identifying fake job posting using selective features and resampling
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fake job posts detection; Principal component analysis; Feature
   selection; Text classification
AB The fake job posting has emerged as an alarming cyber-crime during the last few years which affects both job seekers and companies alike. Fraudulent companies and individuals lure job-seekers using multifarious methods on digital media platforms. Although several machine learning-based approaches exist for the automatic detection of fake job posts, they lack high accuracy and show skewed performance on imbalanced data. In addition, the influence of feature selection is not very well studied. This study overcomes these limitations using selective features through Chi-square and principal component analysis (PCA). The influence of dataset imbalance is also investigated through the synthetic minority oversampling technique (SMOTE). The performance of the proposed model is compared with individual machine learning models, as well as, existing state-of-the-art models. Results indicate that using SMOTE with Chi-square-based selective features yields the best results with a 0.99 accuracy using the proposed model. K-fold cross-validation further corroborates these results.
C1 [Afzal, Hina; Ullah, Saleem] Khwaja Fareed Univ Engn & Informat Technol, Abu Dhabi Rd, Rahim Yar Khan, Punjab, Pakistan.
   [Rustam, Furqan] Univ Coll Dublin, Sch Comp Sci, Belfield, Dublin, Ireland.
   [Aljedaani, Wajdi] Univ North Texas, 155 Union Cir, Denton, TX 76203 USA.
   [Siddique, Muhammad Abubakar] Ghazi Univ, Dept Comp Sci & IT, Dera Ghazi Khan, Punjab, Pakistan.
   [Ashraf, Imran] Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan 38541, South Korea.
C3 Khwaja Fareed University of Engineering & Information Technology,
   Pakistan; University College Dublin; University of North Texas System;
   University of North Texas Denton; Yeungnam University
RP Rustam, F (corresponding author), Univ Coll Dublin, Sch Comp Sci, Belfield, Dublin, Ireland.; Ashraf, I (corresponding author), Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan 38541, South Korea.
EM hinaafzal770@gmail.com; furqan.rustam1@gmail.com;
   wajdialjedaani@my.unt.edu; abubakar.ahmadani@gmail.com;
   saleem.ullah@kfueit.edu.pk; imranashraf@ynu.ac.kr
RI Rustam, Furqan/ABE-4772-2020
OI Rustam, Furqan/0000-0001-8403-1047; Ashraf, Imran/0000-0002-8271-6496
FU MSIT(Ministry of Science and ICT), Korea, under the ITRC(Information
   Technology Research Center) support program [IITP-2021-2016-0-00313]
FX This research was supported by the MSIT(Ministry of Science and ICT),
   Korea, under the ITRC(Information Technology Research Center) support
   program(IITP-2021-2016-0-00313) supervised by the IITP(Institute for
   Information & communications Technology Planning & Evaluation)
CR Ablel-Rheem DM., 2020, INT J-TORONTO, V9, P4
   Agarwal B, 2014, ADV INTELL SYST, V236, P701, DOI 10.1007/978-81-322-1602-5_75
   Alghamdi B., 2019, Journal of Information Security, V10, P155
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Allas T., 2020, Covid-19 in the United Kingdom: Assessing jobs at risk and the impact on people and places
   Amaar A, 2022, NEURAL PROCESS LETT, V54, P2219, DOI 10.1007/s11063-021-10727-z
   Ashraf I, 2019, INT J COMMUN SYST, V32, DOI 10.1002/dac.4062
   Ashraf I, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112538
   Bahgat EM, 2018, AIN SHAMS ENG J, V9, P3259, DOI 10.1016/j.asej.2018.06.001
   Bansal S, 2020, REAL FAKE FAKE JOBPO
   Chiraratanasopha B, 2022, CURRENT APPL SCI TEC, P12
   Dutta S., 2020, INT J ENG TRENDS TEC, V68, P48, DOI [10.14445/22315381/IJETT-V68I4P209S, DOI 10.14445/22315381/IJETT-V68I4P209S]
   Hakak S, 2021, FUTURE GENER COMP SY, V117, P47, DOI 10.1016/j.future.2020.11.022
   Ho Chung Wu, 2008, ACM Transactions on Information Systems, V26
   Hossin M., 2015, INT J DATA MIN KNOWL, V5, P1, DOI DOI 10.5121/IJDKP.2015.5201
   Hug Nicolas, 2020, J OPEN SOURCE SOFTW, V5, DOI [10.21105/joss.02174, DOI 10.21105/JOSS.02174]
   Jamil R, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.645
   Kaur K., 2020, MATER TODAY-PROC, DOI 10.1016/j.matpr.2020.09.619
   Khalid M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082788
   Kynkaanniemi T, 2019, ARXIV
   Lal S., 2019, Twelfth International Conference on Contemporary Computing (IC3), P1, DOI DOI 10.1109/IC3.2019.8844879
   Liu B.F., 2013, SOCIAL MEDIA USE DIS
   Luo XY, 2021, ALEX ENG J, V60, P3401, DOI 10.1016/j.aej.2021.02.009
   Madani Y, 2021, RESULTS PHYS, V25, DOI 10.1016/j.rinp.2021.104266
   Mahbub Syed, 2018, Using contextual features for online recruitment fraud detection
   Nasser I, 2020, INT J ENG INFORM SYS, P6
   Novakovi J.D., 2017, Theory Appl. Math. Comput. Sci, V7, P39, DOI DOI 10.1007/978-3-319-58747-9_1
   Rodriguez-Galiano VF, 2012, ISPRS J PHOTOGRAMM, V67, P93, DOI 10.1016/j.isprsjprs.2011.11.002
   Rupapara V, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-04835-6
   Rupapara V, 2021, IEEE ACCESS, V9, P78621, DOI 10.1109/ACCESS.2021.3083638
   Rustam F, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0245909
   Rustam F, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21111078
   Sahoo SR, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106983
   Scanlon J. R., 2014, Security Informatics, V3, P1, DOI [10.1186/s13388-014-0005-5, DOI 10.1186/S13388-014-0005-5]
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Shah K., 2020, AUGMENT HUMAN RES, V5, P1, DOI DOI 10.1007/S41133-020-00032-0
   Shibly F, 2021, PERFORMANCE COMP 2 C
   Shushkevich E., 2018, Ibereval@ sepln, P255
   Srivastava R, 2022, EMIRATI J BUSINESS E
   Sur P, 2019, P NATL ACAD SCI USA, V116, P14516, DOI 10.1073/pnas.1810420116
   Vidros S, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9010006
   Vidros S, 2016, COMPUT FRAUD SECUR, P8, DOI 10.1016/S1361-3723(16)30025-2
   Xie W, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/2671792
   Xu S, 2018, J INF SCI, V44, P48, DOI 10.1177/0165551516677946
   Zhang Y, 2010, INT J MACH LEARN CYB, V1, P43, DOI 10.1007/s13042-010-0001-0
NR 48
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 15591
EP 15615
DI 10.1007/s11042-023-15173-8
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001029126000003
DA 2024-07-18
ER

PT J
AU Cai, ZH
   Ding, HW
   Wu, JL
   Xi, Y
   Wu, XM
   Cui, XH
AF Cai, Zihui
   Ding, Hongwei
   Wu, Jinlu
   Xi, Ying
   Wu, Xuemeng
   Cui, Xiaohui
TI Multi-label movie genre classification based on multimodal fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-label; Movie genre classification; Multimodal fusion; Deep
   learning
ID RECOGNITION; NETWORK
AB Determining the genre of a movie based on its relevant information is a challenging multi-label classification task. Previous studies tended to classify movies based on only one or two modalities, ignoring some valuable modalities. Considering this, we propose a multimodal movie genre classification framework which comprehensively considers the data from different modalities including the audio, poster, plot and frame sequences from video. To be specific, it processes the data from various modalities with the help of deep learning technologies, and fuses them in the way of decision-level fusion and intermediate fusion including concatenation and element-wise sum, which can improve the classification performance due to making full use of the information complementarity between multiple modalities. We train and evaluate the proposed framework on the LMTD-9 dataset. The results show that our best multimodal model outperforms state-of-the-art methods by 8.6% improvement in AU(PRC) and 5.3% improvement in AU(PRC)(w). It can be seen that the performance of movie genre classification can be effectively improved by means of multimodal fusion.
C1 [Cai, Zihui; Ding, Hongwei; Wu, Jinlu; Xi, Ying; Wu, Xuemeng; Cui, Xiaohui] Wuhan Univ, Minist Educ, Key Lab Aerosp Informat Secur & Trusted Comp, Sch Cyber Sci & Engn, Wuhan, Peoples R China.
C3 Wuhan University
RP Cui, XH (corresponding author), Wuhan Univ, Minist Educ, Key Lab Aerosp Informat Secur & Trusted Comp, Sch Cyber Sci & Engn, Wuhan, Peoples R China.
EM xcui@whu.edu.cn
FU Research and Application of Object detection based on Artificial
   Intelligence of Science and Technology Department of Yunnan Province
   [2022KZ00125]
FX The numerical calculations in this paper have been done on the
   supercomputing system in the Supercomputing Center of Wuhan University.
   This research was supported by Research and Application of Object
   detection based on Artificial Intelligence of Science and Technology
   Department of Yunnan Province (No.2022KZ00125).
CR Allwein EL, 2001, J MACH LEARN RES, V1, P113, DOI 10.1162/15324430152733133
   [Anonymous], 2010, Proceedings of the 18th International Conference on Multimedea, DOI [DOI 10.1145/1873951.1874068, 10.1145/1873951.1874068]
   [Anonymous], 2015, P 2015 C EMP METH NA, DOI [10.18653/v1/d15-1303, 10.18653/v1/D15-1303]
   Arevalo J, 2017, Arxiv, DOI arXiv:1702.01992
   Baevski A., 2020, ADV NEURAL INFORM PR, V33, P12449
   Bakkouri I, 2022, MULTIMED TOOLS APPL, V81, P10743, DOI 10.1007/s11042-022-12242-2
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Bi TY, 2021, INT C PATT RECOG, P9386, DOI 10.1109/ICPR48806.2021.9412480
   Braz L., 2021, 11 INT C PATT REC SY, V2021, P200
   Cao Y, 2014, CANCER INFORM, V13, P125, DOI 10.4137/CIN.S14053
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Ding HW, 2022, FUTURE GENER COMP SY, V131, P240, DOI 10.1016/j.future.2022.01.026
   Fukui A., 2016, arXiv
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Huang ZH, 2015, Arxiv, DOI arXiv:1508.01991
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jain A, 2016, IEEE INT CONF ROBOT, P3118, DOI 10.1109/ICRA.2016.7487478
   Kahou SE, 2016, J MULTIMODAL USER IN, V10, P99, DOI 10.1007/s12193-015-0195-2
   Liang MX, 2015, IEEE ACM T COMPUT BI, V12, P928, DOI 10.1109/TCBB.2014.2377729
   Liu XY, 2009, IEEE T SYST MAN CY B, V39, P539, DOI 10.1109/TSMCB.2008.2007853
   Napoles Courtney, 2012, P JOINT WORKSHOP AUT
   Pang L, 2016, AAAI CONF ARTIF INTE, P2793
   Paszke A, 2019, ADV NEUR IN, V32
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Ramachandram D, 2017, IEEE SIGNAL PROC MAG, V34, P96, DOI 10.1109/MSP.2017.2738401
   Simoes GS, 2016, IEEE IJCNN, P259, DOI 10.1109/IJCNN.2016.7727207
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Vaezi Joze Hamid Reza, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13286, DOI 10.1109/CVPR42600.2020.01330
   Vielzeuf V., 2018, P EUROPEAN C COMPUTE
   Wehrmann J., 2017, P S APPL COMP, P114
   Wehrmann J, 2017, APPL SOFT COMPUT, V61, P973, DOI 10.1016/j.asoc.2017.08.029
   Wehrmann J, 2016, PROCEEDINGS OF 2016 5TH BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS 2016), P1, DOI [10.1109/BRACIS.2016.012, 10.1109/BRACIS.2016.11]
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu AM, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1029
   Yadav A, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106624
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   Zhang YC, 2018, ICMLC 2020: 2020 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P145, DOI 10.1145/3383972.3383975
NR 41
TC 2
Z9 2
U1 6
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUL 15
PY 2023
DI 10.1007/s11042-023-16121-2
EA JUL 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M3HP8
UT WOS:001029126000001
DA 2024-07-18
ER

PT J
AU Çinarer, G
   Dogan, N
   Kiliç, K
   Dogan, C
AF Cinarer, Gokalp
   Dogan, Nurcan
   Kilic, Kazim
   Dogan, Cemhan
TI Rapid detection of adulteration in pistachio based on deep learning
   methodologies and affordable system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pistachio Adulteration; Deep Learning; CNN (Convolutional Neural
   Network); Transfer Learning; Image Processing
ID FOOD FRAUD; SPECTROSCOPY; OIL; CLASSIFICATION; COLOR; NUTS
AB The development of international trade has facilitated the global distribution of food. Ensuring the safety of food products is a crucial process that spans from production to sale. Mismanagement of this process can pose significant public health risks. The issue of food adulteration is increasingly prevalent, necessitating the development of fast and reliable methods for its detection. Deep learning, as an effective machine learning algorithm, has emerged as a new field in the food industry, offering rapid and accurate results in the identification of food adulteration. In this study, a digital image and deep learning-based method was developed to detect spinach adulteration in pistachios. A unique dataset with 6 classes was created in a laboratory environment for testing the method. The adulteration rates for each class were determined, and images were analyzed in various color spaces, including Red Green Blue (RGB), HSV (Hue Saturation Value), Y,u and v (YUV), and L, a, and b (LAB). Subsequently, Convolutional Neural Network (CNN) architectures, namely ResNet-50, VGGNet-19, and DenseNet201, were employed for classification. The accuracy of all color spaces and architectural combinations exceeded 90%. Notably, the VGGNet-19 architecture achieved a 100% success rate in classifying the LAB color space. Moreover, the YUV/ResNet-50 and HSV/VGGNet-19 combinations demonstrated over 98% success in detecting peanut adulteration. The utilization of deep learning-based architectures enables swift and effortless analysis of complex food samples, eliminating the challenges associated with analyzing large quantities of food and effectively preventing food adulteration.
C1 [Cinarer, Gokalp] Yozgat Bozok Univ, Fac Engn & Architecture, Dept Comp Engn, TR-66100 Yozgat, Turkiye.
   [Dogan, Nurcan; Dogan, Cemhan] Yozgat Bozok Univ, Bogazliyan Vocat Sch, Dept Food Technol, TR-66400 Yozgat, Turkiye.
   [Kilic, Kazim] Yozgat Bozok Univ, Yozgat Vocat Sch, Dept Comp Technol, TR-66100 Yozgat, Turkiye.
C3 Bozok University; Bozok University; Bozok University
RP Çinarer, G (corresponding author), Yozgat Bozok Univ, Fac Engn & Architecture, Dept Comp Engn, TR-66100 Yozgat, Turkiye.
EM gokalp.cinarer@bozok.edu.tr
RI DOĞAN, Nurcan/JZQ-3858-2024
OI DOĞAN, Nurcan/0000-0001-5414-1819; Cinarer, Gokalp/0000-0003-0818-6746
CR Abbaszadeh M, 2019, ARXIV, DOI DOI 10.48550/ARXIV.1906.11878
   Abideen AZ, 2021, LOGISTICS-BASEL, V5, DOI 10.3390/logistics5040083
   Ahmed MR, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20236753
   Al-Sarayreh M, 2018, J IMAGING, V4, DOI 10.3390/jimaging4050063
   Al-Tairi ZH, 2014, J INF PROCESS SYST, V10, P283, DOI 10.3745/JIPS.02.0002
   Alzubi OA, 2022, CLUSTER COMPUT, V25, P2369, DOI 10.1007/s10586-021-03459-1
   Arlorio M, 2010, FOOD ADDIT CONTAM A, V27, P11, DOI 10.1080/02652030903225799
   Ayari F, 2018, J FOOD PROCESS ENG, V41, DOI 10.1111/jfpe.12806
   Aykas DP, 2021, FOOD CONTROL, V121, DOI 10.1016/j.foodcont.2020.107670
   Ayustaningwarno F, 2021, FOOD RES INT, V143, DOI 10.1016/j.foodres.2021.110230
   Bai G, 2018, FRONT PLANT SCI, V9, DOI 10.3389/fpls.2018.01002
   Bakre SM, 2015, J FOOD SCI TECH MYS, V52, P3093, DOI 10.1007/s13197-014-1309-7
   Bandara WGC, 2020, J FOOD ENG, V266, DOI 10.1016/j.jfoodeng.2019.109700
   Castro W, 2019, IEEE ACCESS, V7, P27389, DOI 10.1109/ACCESS.2019.2898223
   Cavus F., 2018, J FOOD FEED SCI, V19, P34
   Souto UTDP, 2015, LWT-FOOD SCI TECHNOL, V63, P1037, DOI 10.1016/j.lwt.2015.04.003
   Diez Y, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13142837
   Dogan C, 2023, J FOOD MEAS CHARACT, V17, P1693, DOI 10.1007/s11694-022-01671-0
   Dreher ML, 2012, NUTR REV, V70, P234, DOI 10.1111/j.1753-4887.2011.00467.x
   Ferreiro-González M, 2018, TALANTA, V188, P288, DOI 10.1016/j.talanta.2018.05.095
   Genis HE, 2021, LWT-FOOD SCI TECHNOL, V136, DOI 10.1016/j.lwt.2020.110008
   Ghiasi S, 2021, J CHROMATOGR A, V1657, DOI 10.1016/j.chroma.2021.462587
   Goel N, 2015, APPL SOFT COMPUT, V36, P45, DOI 10.1016/j.asoc.2015.07.009
   Grace MH, 2016, FOOD CHEM, V210, P85, DOI 10.1016/j.foodchem.2016.04.088
   Green HS, 2020, FOOD CONTROL, V107, DOI 10.1016/j.foodcont.2019.106773
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hong E, 2017, J SCI FOOD AGR, V97, P3877, DOI 10.1002/jsfa.8364
   Horn B, 2018, FOOD CHEM, V257, P112, DOI 10.1016/j.foodchem.2018.03.007
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang M, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6060183
   Iymen G, 2020, INNOV FOOD SCI EMERG, V66, DOI 10.1016/j.ifset.2020.102527
   Izquierdo M, 2020, COMPUT ELECTRON AGR, V171, DOI 10.1016/j.compag.2020.105290
   Kaltenbrunner M, 2018, FOOD CHEM, V243, P82, DOI 10.1016/j.foodchem.2017.09.087
   Kamruzzaman M, 2012, INNOV FOOD SCI EMERG, V16, P316, DOI 10.1016/j.ifset.2012.07.007
   Karuppuswami S, 2017, IEEE SENS J, V17, P1706, DOI 10.1109/JSEN.2017.2656476
   Kaur S, 2023, VISION-INDIA, V27, P498, DOI 10.1177/09722629211015603
   Kavi Niranjana K., 2015, INT J ADV RES, V3, P8
   Kotha RR, 2021, ACS FOOD SCI TECHNOL, V1, P2174, DOI 10.1021/acsfoodscitech.1c00356
   Küçüköner E, 2003, EUR FOOD RES TECHNOL, V217, P308, DOI 10.1007/s00217-003-0763-7
   Ladha-Sabur A, 2019, TRENDS FOOD SCI TECH, V86, P270, DOI 10.1016/j.tifs.2019.02.034
   Lai JW, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/4625371
   de Lima TK, 2020, FOOD CHEM, V333, DOI 10.1016/j.foodchem.2020.127454
   Manning L, 2016, J FOOD SCI, V81, pR823, DOI 10.1111/1750-3841.13256
   Moore JC, 2012, J FOOD SCI, V77, pR118, DOI 10.1111/j.1750-3841.2012.02657.x
   Moreira G, 2022, AGRONOMY-BASEL, V12, DOI 10.3390/agronomy12020356
   Movassagh AA, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02623-6
   Pustjens AM, 2016, WOODHEAD PUBL FOOD S, V293, P3, DOI 10.1016/B978-1-78242-447-5.00001-0
   Qian GX, 2011, INT J SUST DEV WORLD, V18, P434, DOI 10.1080/13504509.2011.581710
   Rajkovic D, 2022, AGRONOMY-BASEL, V12, DOI 10.3390/agronomy12010058
   Ribeiro SS., 2016, INT J COMPUT APPL EN, V5, P359
   Satil F, 2003, CHEM NAT COMPD+, V39, P322, DOI 10.1023/B:CONC.0000003408.63300.b5
   Sezer B, 2019, J SCI FOOD AGR, V99, P2236, DOI 10.1002/jsfa.9418
   Shahbandeh M, 2021, PISTACHIOS GLOBAL PR
   Sharif MI, 2022, COMPLEX INTELL SYST, V8, P3007, DOI 10.1007/s40747-021-00321-0
   Silva AFS, 2020, FOOD CONTROL, V115, DOI 10.1016/j.foodcont.2020.107299
   Singh KR, 2020, COMPLEX INTELL SYST, V6, P321, DOI 10.1007/s40747-020-00132-9
   Song K, 2021, J FOOD MEAS CHARACT, V15, P4006, DOI 10.1007/s11694-021-00983-x
   Suman M, 2021, TRAC-TREND ANAL CHEM, V142, DOI 10.1016/j.trac.2021.116305
   Tamatjita EN., 2022, INFORM ENG EXPRESS, V8, P1, DOI [10.52731/iee.v8.i1.687, DOI 10.52731/IEE.V8.I1.687]
   Taylan O, 2021, J SCI FOOD AGR, V101, P1699, DOI 10.1002/jsfa.10845
   Tian LL, 2019, FOOD ANAL METHOD, V12, P2282, DOI 10.1007/s12161-019-01571-y
   Tomaino A, 2010, BIOCHIMIE, V92, P1115, DOI 10.1016/j.biochi.2010.03.027
   Vidyarthi SK, 2020, J FOOD PROCESS ENG, V43, DOI 10.1111/jfpe.13552
   Wang JN, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2881-2
   Xiao MY, 2020, LWT-FOOD SCI TECHNOL, V131, DOI 10.1016/j.lwt.2020.109679
   Yam KL, 2004, J FOOD ENG, V61, P137, DOI 10.1016/S0260-8774(03)00195-X
   Zhang XL, 2021, TRENDS FOOD SCI TECH, V112, P431, DOI 10.1016/j.tifs.2021.04.008
   Zhou L, 2019, COMPR REV FOOD SCI F, V18, P1793, DOI 10.1111/1541-4337.12492
   Zhu WR, 2017, FOOD CHEM, V216, P268, DOI 10.1016/j.foodchem.2016.08.051
NR 69
TC 0
Z9 0
U1 6
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14797
EP 14820
DI 10.1007/s11042-023-16172-5
EA JUL 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001026613700003
DA 2024-07-18
ER

PT J
AU Li, SF
   Cheng, Y
   Zhao, LY
   Wang, Y
AF Li, Shifeng
   Cheng, Yan
   Zhao, Liuyang
   Wang, Yue
TI Anomaly detection with multi-scale pyramid grid templates
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; Multi-scale; Pyramid grid template
ID ABNORMAL EVENT DETECTION
AB In this paper, we propose a method for abnormal event detection in videos based on Multi-scale Pyramid Grid Templates (MPGT). Unlike traditional methods that usually finish anomaly detection based on a single scale feature, we propose to detect anomalies with a designed multi-scale normalized motion feature in the framework of MPGT. In our work, two scene models are proposed, including a global model and an online model, because the anomalies often occur in regions with moving objects. In addition, we propose a fast method for computing high-scale motion features using a convolution operation based on the first scale feature, and design a scheme for combining the detection results at different scales using vote and pyramid strategies. Experiments on public datasets show that our method has a balanced performance on all the testing datasets.
C1 [Li, Shifeng; Cheng, Yan; Zhao, Liuyang; Wang, Yue] Bohai Univ, Sch Informat Sci & Technol, Sci & Technol Rd, Jinzhou 121000, Liaoning, Peoples R China.
C3 Bohai University
RP Li, SF (corresponding author), Bohai Univ, Sch Informat Sci & Technol, Sci & Technol Rd, Jinzhou 121000, Liaoning, Peoples R China.
EM lishifeng@qymail.bhu.edu.cn
RI Li, Shifeng/AGI-9852-2022
OI Zhao, Liuyang/0000-0003-2567-7715
FU National Natural Science Foundation of China [61402049]; Science and
   Technology Research Project of the Department of Education of Liaoning
   Province [LJKZ1019]; Social Science Planning Fund of Liaoning Province
   [L21BGL002]
FX AcknowledgementsThis work was jointly supported by the National Natural
   Science Foundation of China (61402049), Science and Technology Research
   Project of the Department of Education of Liaoning Province (LJKZ1019)
   and Social Science Planning Fund of Liaoning Province (L21BGL002).
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   [Anonymous], 2011, Proceedings of the 2011 joint ACM workshop on Modeling and representing events, J-MRE'11, (New York, NY, USA)
   Basharat A, 2008, PROC CVPR IEEE, P1301
   Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Cong Y, 2013, IEEE T INF FOREN SEC, V8, P1590, DOI 10.1109/TIFS.2013.2272243
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Del Giorno A, 2016, LECT NOTES COMPUT SC, V9909, P334, DOI 10.1007/978-3-319-46454-1_21
   Dutta JK, 2015, AAAI CONF ARTIF INTE, P3755
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Gandhi T, 2007, IEEE T INTELL TRANSP, V8, P413, DOI 10.1109/TITS.2007.903444
   Guansong Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12170, DOI 10.1109/CVPR42600.2020.01219
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   He CK, 2018, MULTIMED TOOLS APPL, V77, P29573, DOI 10.1007/s11042-017-5255-z
   Hu WM, 2006, IEEE T PATTERN ANAL, V28, P1450, DOI 10.1109/TPAMI.2006.176
   Hu X, 2019, IEEE T INF FOREN SEC, V14, P1007, DOI 10.1109/TIFS.2018.2868617
   Hu Y, 2013, IEEE COMPUT SOC CONF, P767, DOI 10.1109/CVPRW.2013.115
   Vu H, 2019, AAAI CONF ARTIF INTE, P5216
   Ionescu R. T., 2019, P IEEECVF C COMPUTER, P7842
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Johnson N, 1996, IMAGE VISION COMPUT, V14, P609, DOI 10.1016/0262-8856(96)01101-8
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li NJ, 2019, NEUROCOMPUTING, V369, P92, DOI 10.1016/j.neucom.2019.08.044
   Li NN, 2014, IEEE IMAGE PROC, P2363, DOI 10.1109/ICIP.2014.7025479
   Li SF, 2018, PATTERN RECOGN LETT, V107, P91, DOI 10.1016/j.patrec.2017.09.001
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu W, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3023
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Medioni G, 2001, IEEE T PATTERN ANAL, V23, P873, DOI 10.1109/34.946990
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Mo X, 2014, IEEE T CIRC SYST VID, V24, P631, DOI 10.1109/TCSVT.2013.2280061
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pang GS, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P353, DOI 10.1145/3292500.3330871
   Piciarelli C, 2008, IEEE T CIRC SYST VID, V18, P1544, DOI 10.1109/TCSVT.2008.2005599
   Reddy V., 2011, Computer Vision and Pattern Recognition Workshops (CVPRW), 2011 IEEE Computer Society Conference on, P55
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi XJ, 2015, ADV NEUR IN, V28
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Tran Hanh, 2017, P BRIT MACH VIS C
   Nguyen TN, 2019, IEEE I CONF COMP VIS, P1273, DOI 10.1109/ICCV.2019.00136
   Wang T, 2019, IEEE T INF FOREN SEC, V14, P1390, DOI 10.1109/TIFS.2018.2878538
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yu BS, 2017, IEEE T SYST MAN CY-S, V47, P704, DOI 10.1109/TSMC.2016.2638048
   Yuan Y, 2017, IEEE T CYBERNETICS, V47, P3597, DOI 10.1109/TCYB.2016.2572609
   Zhang H, 2019, IEEE T MULTIMEDIA, V21, P1450, DOI 10.1109/TMM.2018.2884478
   Zhang Y, 2016, PATTERN RECOGN, V51, P443, DOI 10.1016/j.patcog.2015.09.005
   Zhou JT, 2019, IEEE T INF FOREN SEC, V14, P2537, DOI 10.1109/TIFS.2019.2900907
NR 54
TC 1
Z9 1
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 9929
EP 9947
DI 10.1007/s11042-023-15569-6
EA JUN 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001022083300009
DA 2024-07-18
ER

PT J
AU Amalaman, PK
   Eick, CF
AF Amalaman, Paul. K. K.
   Eick, Christoph. F. F.
TI SHCF: A supervised hierarchical clustering approach to remove high
   density salt and pepper noise from black and white content digital
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Filter; Noise detection; Noise removal; Salt and pepper noise;
   Clustering; Supervised hierarchical clustering
ID IMPULSE NOISE; ALGORITHMS; FILTER
AB When a digital image with a lot of healthy salt and pepper (SP) pixels is corrupted by salt and pepper noises (SPNs) current solutions for SPN removal have difficulty distinguishing the healthy SP pixels from the noisy ones. Consequently, they often exhibit low performance when the original image contains patches of salt or/and pepper pixels. This paper introduces a new SPN removal approach called Supervised Hierarchical Clustering Filter (SHCF) capable of removing high density SP noises. SHCF first assigns a label to each pixel: W to white, B to black and N to the remaining pixels. Next, a supervised hierarchical clustering (SHC) approach is employed to build a tree of pixels called SHC-tree. SHC-trees are constructed maximizing cluster purities in the intermediate nodes. After the tree has been fully built, it is trimmed by extracting 100% purity clusters from the tree. Clusters with black or white pixels of size smaller than a user-defined minimum cluster size threshold are considered outliers and their pixels are marked as corrupted. The rest of the pixels in the image are marked as healthy. In its final step-unlike existing approaches-SHCF uses a replacement method that is order independent; that is, the order in which the corrupt pixels are replaced does not have any bearing on the final restoration result. We conducted experiments on images containing a lot of salt/pepper pixels as well as on standard test images. The results show that SHCF exhibits competitive performances compared to its direct competitors on standard test images. At high density noise level, it outperforms its competitors on average by 16% on images containing large amount of black and white pixels.
C1 [Amalaman, Paul. K. K.] Hitachi Energy, 3151 Briarpark Dr, Houston, TX 77042 USA.
   [Eick, Christoph. F. F.] Univ Houston, Dept Comp Sci, Houston, TX 77204 USA.
C3 University of Houston System; University of Houston
RP Amalaman, PK (corresponding author), Hitachi Energy, 3151 Briarpark Dr, Houston, TX 77042 USA.
EM paul.amalaman@hitachienergy.com; ceick@uh.edu
CR Abreu E, 1996, IEEE T IMAGE PROCESS, V5, P1012, DOI 10.1109/83.503916
   Amalaman PK, 2017, IEEE T KNOWL DATA EN, V29, P2040, DOI 10.1109/TKDE.2017.2698451
   [Anonymous], BLACK WHIT IM CHALL
   Bovik A.C., 2000, HDB IMAGE VIDEO PROC
   Chunwei Tian, 2019, Genetic and Evolutionary Computing. Proceedings of the Twelfth International Conference on Genetic and Evolutionary Computing. Advances in Intelligent Systems and Computing (AISC 834), P563, DOI 10.1007/978-981-13-5841-8_59
   Dong YQ, 2007, IEEE T IMAGE PROCESS, V16, P1112, DOI 10.1109/TIP.2006.891348
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Fu B, 2019, MULTIMED TOOLS APPL, V78, P30707, DOI 10.1007/s11042-018-6521-4
   Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Kishorebabu V, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0215-0
   Lehtinen J, 2018, PR MACH LEARN RES, V80
   Liang H, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13030515
   Pok G, 2003, IEEE T IMAGE PROCESS, V12, P85, DOI 10.1109/TIP.2002.804278
   Radlak K, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102782
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Sungmin C, 2021, 9 INT C LEARNING REP
   Toh KKV, 2010, IEEE SIGNAL PROC LET, V17, P281, DOI 10.1109/LSP.2009.2038769
   Toh KKV, 2008, IEEE T CONSUM ELECTR, V54, P1956, DOI 10.1109/TCE.2008.4711258
   Wang Y, 2016, IEEE SIGNAL PROC LET, V23, P1582, DOI 10.1109/LSP.2016.2607785
   Xing Y, 2019, IET IMAGE PROCESS, V13, P1550, DOI 10.1049/iet-ipr.2018.6004
   Zhang PX, 2014, IEEE SIGNAL PROC LET, V21, P1280, DOI 10.1109/LSP.2014.2333012
NR 22
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11529
EP 11556
DI 10.1007/s11042-023-15740-z
EA JUN 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001022136100011
DA 2024-07-18
ER

PT J
AU Patil, Y
   Shetty, A
   Kale, Y
   Patil, R
   Sharma, S
AF Patil, Yogeshwar
   Shetty, Ashish
   Kale, Yatharth
   Patil, Rajeshwar
   Sharma, Sanjeev
TI Multiple ocular disease detection using novel ensemble models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Transfer learning; Classification; Detection of diseases;
   Ensemble
AB Ocular diseases can progress slowly and are unaware of their progress until they are severe and untreatable. Regular checkups can prevent this, but these add to the workload of professionals and increase the time it takes to receive results. Therefore, an automated system based on deep learning could aid in early disease detection. The purpose of this paper is to provide a solution for the detection of multiple ocular diseases from fundus images. Stack ensemble models consisting of multiple singular disease models are proposed, namely faster ensembles and ensembles of ensembles. Both models are assembled using the stack ensembling technique. There are 5 types of disease classified by the models, namely Cataract, Pathological Myopia, Glaucoma, Diabetic Retinopathy, and None. Based on the combined dataset of ocular disease images, the faster ensemble model had an accuracy of 87%, while the ensemble of ensemble models had an accuracy of 88%.
C1 [Patil, Yogeshwar; Shetty, Ashish; Kale, Yatharth; Patil, Rajeshwar; Sharma, Sanjeev] Indian Inst Informat Technol Pune, Pune, India.
RP Patil, Y (corresponding author), Indian Inst Informat Technol Pune, Pune, India.
EM yogeshwarpatil19@cse.iiitp.ac.in; ashishshetty19@cse.iiitp.ac.in;
   yatharthkale19@cse.iiitp.ac.in; rajeshwarpatil19@cse.iiitp.ac.in;
   sanjeevsharma@iiitp.ac.in
OI sharma, Dr. Sanjeev/0000-0001-9598-242X
CR Agarwal H, 2020, Glaucomadataset
   Baid U, 2019, TENCON IEEE REGION, P1345, DOI [10.1109/tencon.2019.8929252, 10.1109/TENCON.2019.8929252]
   Bhlmann P., 2012, Handbook of Computational Statistics, P985, DOI [DOI 10.1007/978-3-642-21551-333, 10.1007/978-3-642-21551-3_33]
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Elangovan Poonguzhali, 2021, Detection of glaucoma from fundus image using pre-trained Densenet201 model
   Gour N, 2023, NEURAL COMPUT APPL, V35, P22887, DOI 10.1007/s00521-021-06770-5
   Gunes F., 2017, Stacked Ensemble Models for Improved Prediction Accuracy, P1
   HUANG D, 1991, SCIENCE, V254, P1178, DOI 10.1126/science.1957169
   Islam Md Tariqul, 2019, 2019 IEEE International Conference on Signal Processing, Information, Communication & Systems (SPICSCON), P59, DOI 10.1109/SPICSCON48833.2019.9065162
   Juneja M, 2020, MULTIMED TOOLS APPL, V79, P15531, DOI 10.1007/s11042-019-7460-4
   Khanna M, 2020, PAPER REV DENSENET D
   Lanjewar MG, 2023, MULTIMED TOOLS APPL, V82, P29883, DOI 10.1007/s11042-022-14232-w
   Larxel, 2020, OCULAR DIS RECOGNITI
   Li C, 2020, IEEE INT MEM WORKSH, P91, DOI 10.1109/imw48823.2020.9108112
   Li F, 2019, BIOMED OPT EXPRESS, V10, P6204, DOI 10.1364/BOE.10.006204
   Linchundan, 2019, 1000 FUNDUS IMAGES 3
   Mahdianpari M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071119
   Nair V, 2021, 2021 55 ANN C INF SC, P1
   Nandhini S, 2021, MULTIMED TOOLS APPL, V80, P18583, DOI 10.1007/s11042-021-10599-4
   Ning Li, 2021, Benchmarking, and Optimizing Measuring. Third BenchCouncil International Symposium, Bench 2020. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12614), P177, DOI 10.1007/978-3-030-71058-3_11
   Paul D, 2020, COMP MED SY, P526, DOI 10.1109/CBMS49503.2020.00105
   Prajna Y, 2022, J INTELL FUZZY SYST, P1, DOI DOI 10.3233/JIFS-211479
   Ram A, 2020, ARXIV
   Rath SR, 2020, DIABETIC RETINOPATHY
   Ravichandran G, 2019, INT J ELECTRON TELEC, V65, P519, DOI 10.24425/ijet.2019.129808
   Sanida T, 2022, MULTIMED TOOLS APPL, V81, P15041, DOI 10.1007/s11042-022-12461-7
   Sarki R, 2020, HEALTH INF SCI SYST, V8, DOI 10.1007/s13755-020-00125-5
   Srinivasan K, 2021, CMC-COMPUT MATER CON, V68, P4109, DOI 10.32604/cmc.2021.016736
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tsuji T, 2020, BMC OPHTHALMOL, V20, DOI 10.1186/s12886-020-01382-4
   Wang J, 2020, IEEE ACCESS, V8, P212499, DOI 10.1109/ACCESS.2020.3040275
   Yang JJ, 2016, COMPUT METH PROG BIO, V124, P45, DOI 10.1016/j.cmpb.2015.10.007
NR 32
TC 3
Z9 3
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11957
EP 11975
DI 10.1007/s11042-023-16000-w
EA JUN 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001022136100001
DA 2024-07-18
ER

PT J
AU Ghosh, M
   Dey, A
   Kahali, S
AF Ghosh, Manas
   Dey, Aniruddha
   Kahali, Sayan
TI A weighted fuzzy belief factor-based D-S evidence theory of sensor data
   fusion method and its application to face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Decision-level fusion; Fuzzy belief factor; Face recognition; Evidence
   theory; Vanish penalty weight
ID DEMPSTER-SHAFER THEORY; LEVEL FUSION; SCORE-LEVEL; INFORMATION FUSION;
   COMBINATION; SCHEME
AB Automatic Face Recognition (AFR) plays an important role in wide range of applications such as, smart cities, consumer-level and organizational-level applications. AFR is one of the formidable tasks because the face images are susceptible to various degradations by illumination, noise and pose variations. Significant efforts have been manifested in biometric (single/multiple) fusion methods. Prior works on Dempster-Shafer (D-S) evidence theory based fusion show encouraging results in biometric systems. However, most of them fails to handle the inherent uncertainty appropriately. To redress this shortcoming, a new fuzzy belief factor weighted evidence theory-based decision fusion (FBFEve) method is presented in this paper. Three feature extraction methods such as, FG-2DFLD, G2DLDA, Modular-LBP are employed to generate feature vector corresponding to a face image which are fed into the neural network to obtain belief factor. These belief factors based on different feature vectors are fused together to calculate a merit for each class. We have introduced a vanishing-penalty in terms of fuzzy weight, imposed on the missing winning class which is absent in the output set of anyone of three methods. These vanishing-penalty fuzzy weights are used in decision fusion-based face recognition. The proposed method is evaluated by means of two different classifiers namely, radial basis function (RBF) neural network, and support vector machines (SVM). We have validated our method on four benchmark datasets such as, AR, AT & T, FERET, and UMIST. The empirical results show that our FBFEve method attains superior recognition accuracy over some classical sensor-, evidence theory and other related fusion-based techniques.
C1 [Ghosh, Manas] RCCIIT, Dept Comp Applicat, Kolkata, India.
   [Dey, Aniruddha] MAKAUT, Dept Informat Technol, Kolkata, India.
   [Kahali, Sayan] Washington Univ St Louis, Dept Radiol, St Louis, MI USA.
C3 RCC Institute of Information Technology (RCCIIT); Maulana Abul Kalam
   Azad University of Technology; Washington University (WUSTL)
RP Dey, A (corresponding author), MAKAUT, Dept Informat Technol, Kolkata, India.
EM manas.ghosh@rcciit.org; anidey007@gmail.com; sayankahali@ieee.org
CR Abaza A., 2009, P 2009 3 INT C BIOME, P1, DOI [10.1109/BTAS.2009.5339081, DOI 10.1109/BTAS.2009.5339081]
   Abozaid A, 2019, MULTIMED TOOLS APPL, V78, P16345, DOI 10.1007/s11042-018-7012-3
   Ahmad S, 2022, MULTIMED TOOLS APPL, V81, P40931, DOI 10.1007/s11042-022-12688-4
   Benavente R, 1998, 24 COMP VIS CTR
   Chang LL, 2021, INFORM SCIENCES, V564, P220, DOI 10.1016/j.ins.2021.02.076
   Chang LL, 2022, IEEE T CYBERNETICS, V52, P10364, DOI 10.1109/TCYB.2021.3063285
   Chowdhury S, 2011, APPL SOFT COMPUT, V11, P4282, DOI 10.1016/j.asoc.2010.12.002
   DEMPSTER AP, 1967, ANN MATH STAT, V38, P325, DOI 10.1214/aoms/1177698950
   Dey Aniruddha, 2017, International Journal of Machine Learning and Computing, V7, P223, DOI 10.18178/ijmlc.2017.7.6.651
   Dey A., 2019, P IEMENTECH 2019, V2019, P1
   Dey A., 2020, INFORM SI, V44, P345
   Dey A., 2017, P ICRCICN 2017, V2017, P46
   Dey A, 2019, INFORM-J COMPUT INFO, V43, P535, DOI 10.31449/inf.v43i4.2117
   Dwivedi R, 2019, APPL INTELL, V49, P1016, DOI 10.1007/s10489-018-1311-2
   Feng J, 2021, INT J COMPUT INT SYS, V14, P965, DOI 10.2991/ijcis.d.210216.001
   Fu C, 2021, APPL SOFT COMPUT, V102, DOI 10.1016/j.asoc.2021.107109
   Fu C, 2020, KNOWL-BASED SYST, V199, DOI 10.1016/j.knosys.2020.105947
   Fu Q, 2020, SOFT COMPUT, V24, P7615, DOI 10.1007/s00500-019-04389-2
   Fuyuan Xiao, 2021, IEEE Transactions on Fuzzy Systems, V29, P186, DOI 10.1109/TFUZZ.2020.3002431
   Ghosh M, 2022, APPL SOFT COMPUT, V125, DOI 10.1016/j.asoc.2022.109179
   Ghosh M, 2023, MULTIMED TOOLS APPL, V82, P2689, DOI 10.1007/s11042-022-13328-7
   GRAHAM D., 1998, COMPUTER SYSTEMS SCI, V163, P446
   Guo K, 2021, KNOWL-BASED SYST, V227, DOI 10.1016/j.knosys.2021.107210
   Hamache A, 2022, MULTIMED TOOLS APPL, V81, P29587, DOI 10.1007/s11042-022-12086-w
   HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Kabir W, 2018, IEEE T INF FOREN SEC, V13, P1989, DOI 10.1109/TIFS.2018.2807790
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   Nguyen K, 2015, IEEE T HUM-MACH SYST, V45, P132, DOI 10.1109/THMS.2014.2361437
   Kumar A., 2010, IEEE T SYST MAN CYB, V41, P922
   Lai JW, 2020, INFORM FUSION, V63, P248, DOI 10.1016/j.inffus.2020.06.006
   Lu SF, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P1684, DOI [10.1109/ITNEC48623.2020.9084828, 10.1109/itnec48623.2020.9084828]
   Lumini A, 2017, INFORM FUSION, V33, P71, DOI 10.1016/j.inffus.2016.05.003
   Martinez A.M., 1998, AR FACE DATABASE
   Meng T, 2020, INFORM FUSION, V57, P115, DOI 10.1016/j.inffus.2019.12.001
   Mi XJ, 2020, COMPUT IND ENG, V148, DOI 10.1016/j.cie.2020.106685
   Monwar MM, 2009, IEEE T SYST MAN CY B, V39, P867, DOI 10.1109/TSMCB.2008.2009071
   Moral-García S, 2020, IEEE ACCESS, V8, P118017, DOI 10.1109/ACCESS.2020.3003715
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 1998, FACE RECOGNITION THE, V163, DOI [10.1007/978-3-642-72201-1_13, DOI 10.1007/978-3-642-72201-1]
   Qiu S, 2022, INFORM FUSION, V80, P241, DOI 10.1016/j.inffus.2021.11.006
   Rivadeneira L, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114400
   Sarangi PP, 2022, J AMB INTEL HUM COMP, V13, P1867, DOI 10.1007/s12652-021-02952-0
   Shafer G., 1976, A Mathematical Theory of Evidence, V1, DOI 10.1515/9780691214696
   Sing JK, 2019, INFORM FUSION, V47, P60, DOI 10.1016/j.inffus.2018.07.005
   Su XY, 2019, SOFT COMPUT, V23, P9793, DOI 10.1007/s00500-019-03804-y
   Szczuko P, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062356
   The ORL face database, US
   Tiong LCO, 2019, MULTIMED TOOLS APPL, V78, P22743, DOI 10.1007/s11042-019-7618-0
   Tong Z, 2021, NEUROCOMPUTING, V450, P275, DOI 10.1016/j.neucom.2021.03.066
   Walia GS, 2019, EXPERT SYST APPL, V116, P364, DOI 10.1016/j.eswa.2018.08.036
   Wang WX, 2022, MULTIMED TOOLS APPL, V81, P43657, DOI 10.1007/s11042-022-12994-x
   Xiao FY, 2021, IEEE T NEUR NET LEAR, V32, P1525, DOI 10.1109/TNNLS.2020.2984918
   Xiao FY, 2020, INFORM SCIENCES, V514, P462, DOI 10.1016/j.ins.2019.11.022
   Yin HF, 2022, NEURAL PROCESS LETT, V54, P657, DOI 10.1007/s11063-021-10650-3
   Zhou CY, 2020, MULTIMED TOOLS APPL, V79, P29021, DOI 10.1007/s11042-020-08914-6
   Zhou M, 2020, COMPUT IND ENG, V147, DOI 10.1016/j.cie.2020.106648
   Zhu CS, 2021, INFORM SCIENCES, V570, P306, DOI 10.1016/j.ins.2021.04.059
NR 58
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10637
EP 10659
DI 10.1007/s11042-023-16037-x
EA JUN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001014722500011
DA 2024-07-18
ER

PT J
AU Shukla, S
   Gupta, AK
   Gupta, P
AF Shukla, Sneha
   Gupta, Anup Kumar
   Gupta, Puneet
TI Exploring the feasibility of adversarial attacks on medical image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adversarial attack; Deep neural network; Medical image segmentation;
   Semantic segmentation; Surrogate loss function
ID ARCHITECTURE
AB Recent advancements in Deep Learning (DL) based medical image segmentation models have led to tremendous growth in healthcare applications. However, DL models can be easily compromised by intelligently engineered adversarial attacks, which pose a serious threat to the security of life-critical healthcare applications. Thus, understanding the generation of adversarial attacks is essential for designing robust and reliable DL based healthcare models. To this end, we explore adversarial attacks for medical image segmentation models in this paper. The adversarial attacks are performed by backpropagating the loss function, which minimises the error metrics. However, most of the medical image segmentation models utilise several non-differential loss functions, which obstruct the attack. Consequently, the attacks are performed by surrogate loss functions that are differentiable approximations of the original loss function. However, we observe that different surrogate loss functions behave differently for the same input. Hence, choosing the best surrogate loss function for a successful attack is crucial. Furthermore, these DL models contain non-differentiable layers that obfuscate gradients and obstruct the attack. To mitigate these issues, we introduce an attack, MedIS (Medical Image Segmentation), which utilises parallel fusion for selecting the best surrogate loss function with the least added perturbation. Moreover, our proposed MedIS attack also provides guidelines to tackle non-differentiable layers by replacing them with differentiable approximations. The experiments conducted on several well-known medical image segmentation models employing multiple surrogate loss functions reveal that MedIS outperforms existing attacks on medical image segmentation by providing a higher attack success rate.
C1 [Shukla, Sneha; Gupta, Anup Kumar; Gupta, Puneet] IIT Indore, Dept Comp Sci & Engn, Indore, Madhya Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Indore
RP Shukla, S (corresponding author), IIT Indore, Dept Comp Sci & Engn, Indore, Madhya Pradesh, India.
EM snehashukla@iiti.ac.in; deeplearning@iiti.ac.in;
   machineintelligence@iiti.ac.in
RI Gupta, Anup Kumar/ABC-8017-2021
OI Gupta, Anup Kumar/0000-0003-1090-6036; Shukla, Sneha/0000-0003-1861-8952
FU Prime Minister's Research Fellowship (PMRF), the Ministry of Education,
   Government of India [PMRF-2101306]
FX The work of Anup Kumar Gupta is partially supported by Prime Minister's
   Research Fellowship (PMRF), the Ministry of Education, Government of
   India (PMRF-2101306).
CR Aggarwal A, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/4096950
   Arnab A, 2018, PROC CVPR IEEE, P888, DOI 10.1109/CVPR.2018.00099
   Athalye A, 2018, PR MACH LEARN RES, V80
   Berman M, 2018, PROC CVPR IEEE, P4413, DOI 10.1109/CVPR.2018.00464
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Carrara F, 2019, MULTIMED TOOLS APPL, V78, P2815, DOI 10.1007/s11042-018-5853-4
   Chae SH, 2016, MULTIMED TOOLS APPL, V75, P15347, DOI 10.1007/s11042-014-2201-1
   Cisse M, 2017, ADV NEUR IN, V30
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Esteva A, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-020-00376-2
   Faisal A, 2020, J SCI APPL TECHNOL, V4, P1, DOI DOI 10.35472/JSAT.V4I1.262
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Gupta AK, 2022, APPL INTELL, V52, P9001, DOI 10.1007/s10489-021-02846-w
   Gupta P, 2019, LECT NOTES COMPUT SC, V11824, P401, DOI 10.1007/978-3-030-33676-9_28
   Jadon S, 2020, 2020 IEEE CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY (CIBCB), P115, DOI 10.1109/cibcb48159.2020.9277638
   Jang E., 2017, P ICLR, P1
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Klingner M, 2020, IEEE COMPUT SOC CONF, P1299, DOI 10.1109/CVPRW50498.2020.00168
   Kurakin Alexey, 2017, INT C LEARN REPR
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Lone TA, 2020, EURASIP J WIREL COMM, V2020, DOI 10.1186/s13638-020-01759-5
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma XJ, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107332
   Madry A., 2018, ARXIV
   Mishra S, 2021, KNOWL-BASED SYST, V232, DOI 10.1016/j.knosys.2021.107503
   Munusamy H, 2021, BIOCYBERN BIOMED ENG, V41, P1025, DOI 10.1016/j.bbe.2021.06.011
   Ozbulak U, 2019, LECT NOTES COMPUT SC, V11765, P300, DOI 10.1007/978-3-030-32245-8_34
   Paschali M, 2018, LECT NOTES COMPUT SC, V11070, P493, DOI 10.1007/978-3-030-00928-1_56
   Paul R, 2020, I S BIOMED IMAGING, P1517, DOI [10.1109/ISBI45749.2020.9098740, 10.1109/isbi45749.2020.9098740]
   Pervin M, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2105.12106
   Riba E, 2020, IEEE WINT CONF APPL, P3663, DOI 10.1109/WACV45572.2020.9093363
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Low WCS, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/5528144
   Setiawan Agung W., 2020, 2020 International Seminar on Intelligent Technology and Its Applications (ISITIA). Proceedings, P148, DOI 10.1109/ISITIA49792.2020.9163734
   Song J, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11041870
   Su J, 2021, KNOWL-BASED SYST, V232, DOI 10.1016/j.knosys.2021.107471
   Syed F, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4133
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Tomar NK, 2022, ARXIV, DOI DOI 10.48550/ARXIV.2205.04280
   Vazquez D, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1612.00799
   Wong KCL, 2018, LECT NOTES COMPUT SC, V11072, P612, DOI 10.1007/978-3-030-00931-1_70
   Xie CH, 2017, IEEE I CONF COMP VIS, P1378, DOI 10.1109/ICCV.2017.153
   Xu MT, 2021, MED IMAGE ANAL, V69, DOI 10.1016/j.media.2021.101977
   Yuan Y, 2017, ARXIV, DOI DOI 10.48550/ARXIV.1703.05165
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 46
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11745
EP 11768
DI 10.1007/s11042-023-15575-8
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001014467700002
DA 2024-07-18
ER

PT J
AU Garba, A
   Khalid, S
   Ullah, I
AF Garba, Adamu
   Khalid, Shah
   Ullah, Irfan
TI Understanding the impact of query expansion on federated search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed Information Retrieval; Federated Search; Results Merging;
   Query Expansion; Uncooperative Environments
ID COLLECTION SELECTION; RELEVANCE FEEDBACK
AB Query expansion (QE) has been studied extensively in traditional search settings due to its efficacy in improving retrieval performance. However, the level of performance achieved in the traditional settings has not been reported in the literature on the federated search. Some of the possible reasons include the lack of complete information regarding the corpus statistics of the databases and their diverse content. Nevertheless, several studies have experimented with different QE approaches and reported mixed results. This paper extends the findings of these publications by studying the impact of using a different source for selecting terms to be used in QE on the federated search. Specifically, the expansion terms are extracted from uniform resource locators (URLs) of the documents returned by each database. The retrieval experiments with TREC 2013 FedWeb dataset demonstrates that the expanded query using the proposed approach performs better in many instances than the unexpanded query.
C1 [Garba, Adamu] Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Peoples R China.
   [Khalid, Shah] Natl Univ Sci & Technol NUST, Dept Comp, Islamabad 44000, Pakistan.
   [Ullah, Irfan] Shaheed Benazir Bhutto Univ, Dept Comp Sci, Sheringal 18050, KP, Pakistan.
C3 Jiangsu University; National University of Sciences & Technology -
   Pakistan
RP Khalid, S (corresponding author), Natl Univ Sci & Technol NUST, Dept Comp, Islamabad 44000, Pakistan.
EM yakasai6@yahoo.com; shah.khalid@seecs.edu.pk; irfan@sbbu.edu.pk
RI Khalid, Shah/AAC-8325-2021
OI Khalid, Shah/0000-0001-5735-5863
CR Azad HK, 2019, INFORM SCIENCES, V492, P147, DOI 10.1016/j.ins.2019.04.019
   Baillie M, 2006, LECT NOTES COMPUT SC, V4209, P316
   Callan J, 2000, KLUW S INF, V7, P127
   Callan J, 2001, ACM T INFORM SYST, V19, P97, DOI 10.1145/382979.383040
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Clarke C. L., 2008, P 31 ANN INT ACM SIG, P659, DOI [DOI 10.1145/1390334.1390446, 10.1145/1390334.1390446]
   Cui H., 2002, Proceed- ings of the 11th International Conference on World Wide Web, P325
   Damas J, 2022, LECT NOTES ARTIF INT, V13566, P794, DOI 10.1007/978-3-031-16474-3_64
   Demeester T., 2014, OVERVIEW TREC 2014 F
   Diaz F, 2016, ARXIV
   Dragoni M, 2017, P S APPL COMP SAC 17, P303, DOI 10.1145/3019612.3019833
   Fernández-Reyes FC, 2018, INFORM PROCESS MANAG, V54, P1, DOI 10.1016/j.ipm.2017.09.001
   FURNAS GW, 1987, COMMUN ACM, V30, P964, DOI 10.1145/32206.32212
   Gallant M, 2019, P INT COMP SOFTW APP, P443, DOI 10.1109/COMPSAC.2019.00070
   Garba A, 2023, J INF SCI, DOI 10.1177/01655515221144864
   Garba A, 2020, DATA TECHNOL APPL, V54, P703, DOI 10.1108/DTA-01-2019-0005
   Ghansah B, 2015, CIT/IUCC/DASC/PICOM 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY - UBIQUITOUS COMPUTING AND COMMUNICATIONS - DEPENDABLE, AUTONOMIC AND SECURE COMPUTING - PERVASIVE INTELLIGENCE AND COMPUTING, P907, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.136
   Gong ZG, 2005, LECT NOTES COMPUT SC, V3588, P166
   Gravano L., 1997, SIGMOD Record, V26, P207, DOI 10.1145/253262.253299
   Han BL, 2018, INFORM PROCESS MANAG, V54, P116, DOI 10.1016/j.ipm.2017.10.002
   Hong D, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P821, DOI 10.1145/2348283.2348393
   Jinxi Xu, 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P112
   Keikha A, 2018, J INTELL INF SYST, V50, P455, DOI 10.1007/s10844-017-0466-3
   Khalid S, 2023, ARXIV, DOI DOI 10.48550/ARXIV.2301.11069
   Khalid S, 2020, ENG TECHNOL APPL SCI, V10, P6102
   Khalid S, 2021, J INF SCI, V47, P3, DOI 10.1177/0165551519863346
   Khalid S, 2018, MALAYS J COMPUT SCI, V31, P35, DOI 10.22452/mjcs.vol31no1.3
   Koutsomitropoulos D, 2017, J ENTERP INF MANAG, V30, P795, DOI 10.1108/JEIM-06-2016-0116
   Liang Li, 2018, Web Information Systems and Applications. 15th International Conference, WISA 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11242), P147, DOI 10.1007/978-3-030-02934-0_14
   Ogilvie P., 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P183, DOI 10.1145/502585.502617
   Paepcke A., 2000, D LIB MAGAZINE, V6, P5, DOI [10.1045/march2000-paepcke, DOI 10.1045/MARCH2000-PAEPCKE]
   Pal D, 2014, J ASSOC INF SCI TECH, V65, P2469, DOI 10.1002/asi.23143
   Palakodety S, 2014, QUERY TRANSFORMATION
   Parapar J, 2014, INFORM SCIENCES, V273, P171, DOI 10.1016/j.ins.2014.03.034
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Piedra N, 2014, OPEN PRAX, V6, P171, DOI 10.5944/openpraxis.6.2.122
   Rattinger A., 2018, P 7 INT WORKSHOP BIB, P46
   Robertson SE, 2000, INFORM PROCESS MANAG, V36, P95, DOI 10.1016/S0306-4573(99)00046-1
   Roy D, 2016, ARXIV
   Sellami S, 2022, INT J WEB INF SYST, V18, P453, DOI 10.1108/IJWIS-02-2022-0037
   Sharma DK, 2018, INT C ADV COMP DAT S, P336, DOI 10.1007/978-981-13-1813-9_34
   Shokouhi M, 2007, LECT NOTES COMPUT SC, V4425, P160
   Shokouhi M, 2011, FOUND TRENDS INF RET, V5, P1, DOI 10.1561/1500000010
   Shokouhi M, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P427, DOI 10.1145/1571941.1572015
   Singh J, 2017, NEURAL COMPUT APPL, V28, P2557, DOI 10.1007/s00521-016-2207-x
   Singh J, 2015, INT J INF RETR RES, V5, P31, DOI 10.4018/IJIRR.2015100103
   Ullah I, 2023, MULTIMED TOOLS APPL, V82, P6431, DOI 10.1007/s11042-022-13417-7
   Ullah I, 2020, MULTIMED TOOLS APPL, V79, P8011, DOI 10.1007/s11042-019-08591-0
   Urak G, 2018, 33RD ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, P720, DOI 10.1145/3167132.3167212
   Wang Q, 2014, RUC TREC 2014 SELECT
   Wu TF, 2019, LECT NOTES COMPUT SC, V11772, P52, DOI 10.1007/978-3-030-31624-2_5
NR 51
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10393
EP 10407
DI 10.1007/s11042-023-15831-x
EA JUN 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019116600006
DA 2024-07-18
ER

PT J
AU Middya, AI
   Kumar, S
   Roy, S
AF Middya, Asif Iqbal
   Kumar, Sarvajit
   Roy, Sarbani
TI Activity recognition based on smartphone sensor data using shallow and
   deep learning techniques: A Comparative Study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human activity recognition; Deep learning; Comparative study; Smartphone
   sensors
ID NEURAL-NETWORKS
AB Human activity recognition by the use of smartphone-equipped sensors has gotten a lot of interest in current times because of its large variety of applications.In this regard, this study provides a comprehensive comparative analysis of shallow and deep learning models for smartphone-based HARover high granular daily human activities. Moreover, A robust architecture for smartphone-based HAR is also provided, with stages ranging from data collection to data modelling. A total of seven best performing HAR models namely Decision Tree (DT), Random Forest(RF), DeepNeural Networks (DNN), Support Vector Machines (SVM), K-Nearest Neighbors (KNN), Gradient Boosting (GB) and Convolutional Neural Networks (CNN) are investigated. This research work is based on a real-world dataset of 95690 data samples collected from the smartphone sensors of 18 different subjects. The comparative study reveals that three models namely DNN, RF, and GB mostly dominated over the other models in terms of five performance metrics namely accuracy, recall, precision, F1-score, and AUC value.
C1 [Middya, Asif Iqbal; Kumar, Sarvajit; Roy, Sarbani] Jadavpur Univ, Dept Comp Sci & Engn, Jadavpur, India.
C3 Jadavpur University
RP Roy, S (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Jadavpur, India.
EM asifim.rs@jadavpuruniversity.in; sjsharma1415@gmail.com;
   sarbani.roy@jadavpuruniversity.in
RI Roy, Sarbani/J-1997-2018; Middya, Asif Iqbal/HSH-9366-2023
OI Roy, Sarbani/0000-0002-7598-8266; Middya, Asif Iqbal/0000-0001-6558-4930
FU UGC-NET Junior Research Fellowship by the University Grants Commission,
   Government of India [3684/(NET-JULY 2018)]
FX The research work of Asif Iqbal Middya is supported by UGC-NET Junior
   Research Fellowship (UGC-Ref. No.: 3684/(NET-JULY 2018)) provided by the
   University Grants Commission, Government of India.
CR Ahmed N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010317
   [Anonymous], AUC ROC SCOR
   [Anonymous], GRID SEARCH
   Azar SM, 2019, PROC CVPR IEEE, P7884, DOI 10.1109/CVPR.2019.00808
   Barua A, 2019, 2019 INT C EL COMP C, P1, DOI DOI 10.1109/ECACE.2019.8679226
   Bashar SK, 2020, IEEE ENG MED BIO, P5888, DOI 10.1109/EMBC44109.2020.9176239
   Bouchabou D, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21186037
   Branco P, 2017, LECT NOTES ARTIF INT, V10234, P698, DOI 10.1007/978-3-319-57454-7_54
   Bülbül E, 2018, 2018 2ND INTERNATIONAL SYMPOSIUM ON MULTIDISCIPLINARY STUDIES AND INNOVATIVE TECHNOLOGIES (ISMSIT), P57
   Catalbas Bu., 2017, 2017 25 SIGNAL PROCE, P1
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Chen BH, 2017, PROC CVPR IEEE, P4021, DOI 10.1109/CVPR.2017.428
   Chen YF, 2017, IEEE ACCESS, V5, P3095, DOI 10.1109/ACCESS.2017.2676168
   Chen ZH, 2020, IEEE T INSTRUM MEAS, V69, P3992, DOI 10.1109/TIM.2019.2945467
   Chen ZH, 2017, IEEE T IND INFORM, V13, P3070, DOI 10.1109/TII.2017.2712746
   Das Antar A, 2019, 2019 JOINT 8TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV) AND 2019 3RD INTERNATIONAL CONFERENCE ON IMAGING, VISION & PATTERN RECOGNITION (ICIVPR) WITH INTERNATIONAL CONFERENCE ON ACTIVITY AND BEHAVIOR COMPUTING (ABC), P134, DOI [10.1109/ICIEV.2019.8858508, 10.1109/iciev.2019.8858508]
   Du YG, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204474
   Tran DN, 2016, P INT CONF INTELL, P64, DOI 10.1109/ISMS.2016.51
   Erdas ÇB, 2021, NEURAL PROCESS LETT, V53, P1795, DOI 10.1007/s11063-021-10448-3
   Fan L, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCED CLOUD AND BIG DATA (CBD), P64, DOI 10.1109/CBD.2013.19
   Feng ZT, 2015, IEEE ENG MED BIO, P5074, DOI 10.1109/EMBC.2015.7319532
   Ferrari Anna, 2021, Journal of Reliable Intelligent Environments, V7, P189, DOI 10.1007/s40860-021-00147-0
   Fridriksdottir E, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20226424
   Ghate V, 2021, MULTIMED TOOLS APPL, V80, P35585, DOI 10.1007/s11042-020-10478-4
   Golestani N, 2020, PROC EUR CONF ANTENN
   Gopika N, 2018, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON COMMUNICATION AND ELECTRONICS SYSTEMS (ICCES 2018), P692, DOI 10.1109/CESYS.2018.8723980
   Grzeszick R, 2017, P 4 INT WORKSH SENS, P1, DOI DOI 10.1145/3134230.3134231
   Gupta A, 2016, INT CONF IND INF SYS, P457, DOI 10.1109/ICIINFS.2016.8262984
   Gusain K, 2018, ADV INTELL SYST COMP, V562, P41, DOI 10.1007/978-981-10-4603-2_5
   Harsha NCS, 2021, WIRELESS PERS COMMUN, V121, P381, DOI 10.1007/s11277-021-08641-7
   Hassan MM, 2021, J SUPERCOMPUT, V77, P2237, DOI 10.1007/s11227-020-03361-4
   Hassan MM, 2018, FUTURE GENER COMP SY, V81, P307, DOI 10.1016/j.future.2017.11.029
   Huang FL, 2009, 2009 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTATIONAL INTELLIGENCE, VOL III, PROCEEDINGS, P249, DOI 10.1109/AICI.2009.235
   Imran HA, 2020, INT SYM HIGH CAPAC, P24, DOI 10.1109/HONET50430.2020.9322655
   Ishimaru S, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC '17 ADJUNCT), P704, DOI 10.1145/3123024.3129271
   Kalimuthu Sivakumar, 2021, 2021 International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE), P815, DOI 10.1109/ICACITE51222.2021.9404753
   Khan A. M. A., 2010, P 5 INT C FUT INF TE, P1, DOI DOI 10.1109/FUTURETECH.2010.5482729
   Kim E, 2010, IEEE PERVAS COMPUT, V9, P48, DOI 10.1109/MPRV.2010.7
   Kingma D. P., 2014, arXiv
   Krishnan NC, 2008, INT CONF ACOUST SPEE, P3337, DOI 10.1109/ICASSP.2008.4518365
   Kwon MC, 2018, IEEE INT CONF BIG DA, P4948, DOI 10.1109/BigData.2018.8621893
   Lee SM, 2017, INT CONF BIG DATA, P131, DOI 10.1109/BIGCOMP.2017.7881728
   Li F, 2016, 2016 IEEE INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC), P761, DOI 10.1109/ITNEC.2016.7560464
   Li HB, 2017, IEEE SENSOR, P909
   Li X., 2016, Proceedings of the Eighth Wireless of the Students, by the Students, and for the Students Workshop, P24
   Liang Liu, 2012, 2012 IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI), P180, DOI 10.1109/BHI.2012.6211539
   Lima WS, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143213
   Liu CC, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P33, DOI 10.1109/SIPROCESS.2018.8600483
   Ma Y.Q., 2014, Support vector machines applications, DOI [10.1007/978-3-319-02300-7, DOI 10.1007/978-3-319-02300-7]
   Madeira R, 2016, 2016 ELEVENTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT (ICDIM 2016), P145, DOI 10.1109/ICDIM.2016.7829781
   Mandong A., 2018, Proceedings of the International Conference on Engineering Technologies, P26
   Masum Abdul Kadar Muhammad, 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P1332, DOI 10.1109/ICOEI.2019.8862610
   Mekruksavanich S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051636
   Mekruksavanich S, 2020, IEEE SENSOR, DOI 10.1109/sensors47125.2020.9278630
   Middya AI, 2021, NEURAL COMPUT APPL, V33, P17303, DOI 10.1007/s00521-021-06319-6
   Myung IJ, 1997, PSYCHON B REV, V4, P79, DOI 10.3758/BF03210778
   Narkhede Sarang, 2018, Towards Data Science, V26, P220
   Paul P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ENGINEERING AND TECHNOLOGY (ICETECH), P45
   Priyadarshini RK, 2019, P IEEE 2019 INT C AD, P1
   Python, US
   Rahman A, 2020, UBICOMP/ISWC '20 ADJUNCT: PROCEEDINGS OF THE 2020 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2020 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P419, DOI 10.1145/3410530.3414334
   Rasheed MB, 2015, INT CON ADV INFO NET, P163, DOI 10.1109/AINA.2015.181
   Reena J.K., 2019, 2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon), P446
   Ronao CA, 2015, LECT NOTES COMPUT SC, V9492, P46, DOI 10.1007/978-3-319-26561-2_6
   San-Segundo R, 2018, ENG APPL ARTIF INTEL, V72, P190, DOI 10.1016/j.engappai.2018.04.002
   Sekiguchi R, 2021, UBICOMP/ISWC '21 ADJUNCT: PROCEEDINGS OF THE 2021 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2021 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P396, DOI 10.1145/3460418.3479382
   Shan C.Y., 2020, 2020 8 INT C INF COM, P1
   Straczkiewicz M, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00514-4
   Szandala T., 2021, BIOINSPIRED NEUROCOM, V903, P203, DOI [DOI 10.1007/978-981-15-5495-711, 10.1007/978-981-15-5495-7_11, DOI 10.1007/978-981-15-5495-7_11]
   Uddin MZ, 2019, IEEE SENS J, V19, P8413, DOI 10.1109/JSEN.2018.2871203
   Ullah HA, 2021, IEEE ACCESS, V9, P126366, DOI 10.1109/ACCESS.2021.3110610
   Vesa AV, 2020, INT C INTELL COMP CO, P205, DOI [10.1109/ICCP51029.2020.9266158, 10.1109/iccp51029.2020.9266158]
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Wenfeng Hou, 2018, 2018 IEEE International Conference of Safety Produce Informatization (IICSPI). Proceedings, P902, DOI 10.1109/IICSPI.2018.8690508
   Yalcin M, 2018, 2018 26 SIGNAL PROCE, P1
   Zebin T, 2017, IEEE SENSOR, P1038
NR 76
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 9033
EP 9066
DI 10.1007/s11042-023-15751-w
EA JUN 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001010465000002
DA 2024-07-18
ER

PT J
AU Babu, BS
   Venkatanarayana, M
AF Babu, B. Suresh
   Venkatanarayana, M.
TI MRI and CT image fusion using cartoon-texture and QWT decomposition and
   cuckoo search-grey wolf optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CT; CSGWO; MRI; QWT; SSIM
ID TOTAL VARIATION MINIMIZATION; SCHEME
AB Multimodal image fusion is an essential technique in medical imaging that involves combining information from different imaging modalities to improve the overall quality of the resulting image. This paper, proposes a novel multimodal image fusion method with low frequency and high frequency weight for medical imaging (MRI, CT) using Cuckoo Search-Grey wolf optimization (CSGWO) algorithm. The proposed approach includes contrast enhancement on pre-processed images and performs cartoon-texture(CT) and quaternion wavelet transform (QWT) based decomposition to extract low frequency and high frequency components. The weights for these components are computed based on the image content. The CSGWO algorithm is used to optimize the fusion process for the low frequency and high frequency components separately. The optimized components are then combined using the computed weights to obtain the final fused image. The proposed method is evaluated using objective metrics such as fusion quality index, structural similarity index (SSIM) and mutual information (MI) and compared with other state-of-the-art image fusion techniques. The results show that the proposed method outperforms other techniques and is effective in improving the overall quality of medical images.
C1 [Babu, B. Suresh] Jawaharlal Nehru Technol Univ Ananthapur, Dept ECE, Ananthapuramu, Andhra Pradesh, India.
   [Babu, B. Suresh] Srinivasa Ramanujan Inst Technol, Dept ECE, Ananthapuramu, Andhra Pradesh, India.
   [Venkatanarayana, M.] Jawaharlal Nehru Technol Univ Anantapur, KSRM Coll Engn, Dept ECE & Dean, R&D Cell,KADAPA, Ananthapuramu, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Anantapur; Jawaharlal Nehru
   Technological University - Anantapur
RP Babu, BS (corresponding author), Jawaharlal Nehru Technol Univ Ananthapur, Dept ECE, Ananthapuramu, Andhra Pradesh, India.; Babu, BS (corresponding author), Srinivasa Ramanujan Inst Technol, Dept ECE, Ananthapuramu, Andhra Pradesh, India.
EM sureshdecs10@gmail.com
RI M, Venkatanarayana/JAC-5751-2023
OI M, Venkatanarayana/0000-0002-7750-9038
CR Agarwal M, 2018, PROCEDIA COMPUT SCI, V125, P149, DOI 10.1016/j.procs.2017.12.021
   Agrawal S, 2022, J KING SAUD UNIV-COM, V34, P1172, DOI 10.1016/j.jksuci.2019.05.010
   Almasri MM, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11142124
   Amini N., 2014, J ADV COMPUTER REASE, V5, P23
   Aujol JF, 2009, J MATH IMAGING VIS, V34, P307, DOI 10.1007/s10851-009-0149-y
   Banchhor C, 2020, DATA KNOWL ENG, V127, DOI 10.1016/j.datak.2019.101788
   Benjamin JR, 2018, INT J COMPUT ASS RAD, V13, P229, DOI 10.1007/s11548-017-1692-4
   Bhardwaj J, 2020, HELIX, V10, P7, DOI 10.29042/2020-10-1-07-12
   Bhateja V, 2018, REV SCI INSTRUM, V89, DOI 10.1063/1.5016947
   Chen JY, 2022, MED IMAGE ANAL, V82, DOI 10.1016/j.media.2022.102615
   Daniel E, 2018, IEEE SENS J, V18, P6804, DOI 10.1109/JSEN.2018.2822712
   Demircioglu A, 2022, EUR RADIOL EXP, V6, DOI 10.1186/s41747-022-00294-w
   Dinh PH, 2021, EXPERT SYST APPL, V171, DOI 10.1016/j.eswa.2021.114576
   Dutta Sayantan, 2020, 2020 2nd International Conference on Innovative Mechanisms for Industry Applications (ICIMIA). Proceedings, P284, DOI 10.1109/ICIMIA48430.2020.9074959
   El-Hoseny HM, 2018, INFRARED PHYS TECHN, V94, P223, DOI 10.1016/j.infrared.2018.09.003
   Faragallah OS, 2022, MULTIMED TOOLS APPL, V81, P14379, DOI 10.1007/s11042-022-12260-0
   Hermessi H, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108036
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Jebadass JR, 2022, SOFT COMPUT, V26, P4949, DOI 10.1007/s00500-021-06539-x
   Kaur H., 2021, J ARTIF INTELL SYST, V3, P68, DOI [10.33969/AIS.2021.31005, DOI 10.33969/AIS.2021.31005]
   Kumar Adesh, 2021, International Journal of Organizational and Collective Intelligence, V11, P1, DOI 10.4018/IJOCI.2021070105
   Kumar A, 2023, MULTIMED TOOLS APPL, V82, P7117, DOI 10.1007/s11042-022-13636-y
   Kumar A, 2015, PROCEDIA COMPUT SCI, V57, P1015, DOI 10.1016/j.procs.2015.07.512
   Kumari Taruna, 2021, 2021INTERNATIONAL C, P1, DOI [10.1109/CCGE50943.2021.9776407, DOI 10.1109/CCGE50943.2021.9776407]
   Li DS, 2019, MATH METHOD APPL SCI, V42, P4664, DOI 10.1002/mma.5668
   Liu XB, 2018, BIOMED SIGNAL PROCES, V40, P343, DOI 10.1016/j.bspc.2017.10.001
   Liu Y, 2020, INFORM FUSION, V64, P71, DOI 10.1016/j.inffus.2020.06.013
   Mergin AA, 2022, INT J IMAGE GRAPH, DOI 10.1142/S0219467823400053
   Mustafa HT, 2019, IMAGE VISION COMPUT, V85, P26, DOI 10.1016/j.imavis.2019.03.001
   Nian ZC, 2019, IEEE IMAGE PROC, P1044, DOI [10.1109/icip.2019.8803065, 10.1109/ICIP.2019.8803065]
   Osher S, 2003, MULTISCALE MODEL SIM, V1, P349, DOI 10.1137/S1540345902416247
   Padmavathi K, 2020, ENG SCI TECHNOL, V23, P225, DOI 10.1016/j.jestch.2019.03.008
   Padmavathi K., 2018, INT J ADV RES COMPUT, V9, P35, DOI [10.26483/ijarcs.v9i2.5425, DOI 10.26483/IJARCS.V9I2.5425]
   Prakash O, 2019, OPTIK, V182, P995, DOI 10.1016/j.ijleo.2018.12.028
   Singhal Ashutosh, 2018, Intelligent Computing and Information and Communication. Proceedings of 2nd International Conference, ICICC 2017. Advances in Intelligent Systems and Computing (AISC 673), P525, DOI 10.1007/978-981-10-7245-1_51
   Srivastava A, 2018, Handbook of Research on Advanced Concepts in Real-time Image and Video Processing, P281, DOI 10.4018/978-1-5225-2848-7.ch011
   Tawfik N, 2021, MULTIMED TOOLS APPL, V80, P6369, DOI 10.1007/s11042-020-08834-5
   Vese LA, 2003, J SCI COMPUT, V19, P553, DOI 10.1023/A:1025384832106
   Wang SY, 2020, IET IMAGE PROCESS, V14, P3188, DOI 10.1049/iet-ipr.2019.1319
   Wang ZB, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103823
   Xia JM, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/2806047
   Zhancheng Z, 2020, J ALGO COMPUT TECH, V14
   Zhang Bin, 2019, Journal of Computer Applications, V39, P2701, DOI 10.11772/j.issn.1001-9081.2019020302
   Zhang H, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/9821715
   Zhu XL, 2019, J INDIAN SOC REMOTE, V47, P413, DOI 10.1007/s12524-018-0930-8
NR 45
TC 1
Z9 1
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8797
EP 8835
DI 10.1007/s11042-023-15636-y
EA JUN 2023
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001004157400012
DA 2024-07-18
ER

PT J
AU Gokcay, E
AF Gokcay, Erhan
TI Entropy based streaming big-data reduction with adjustable compression
   ratio
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Entropy; Information theory; Instance reduction; Adjustable compression
ID INSTANCE SELECTION; DIMENSIONALITY REDUCTION; FRAMEWORK
AB The Internet of Things is a novel concept in which numerous physical devices are linked to the internet to collect, generate, and distribute data for processing. Data storage and processing become more challenging as the number of devices increases. One solution to the problem is to reduce the amount of stored data in such a way that processing accuracy does not suffer significantly. The reduction can be lossy or lossless, depending on the type of data. The article presents a novel lossy algorithm for reducing the amount of data stored in the system. The reduction process aims to reduce the volume of data while maintaining classification accuracy and properly adjusting the reduction ratio. A nonlinear cluster distance measure is used to create subgroups so that samples can be assigned to the correct clusters even though the cluster shape is nonlinear. Each sample is assumed to arrive one at a time during the reduction. As a result of this approach, the algorithm is suitable for streaming data. The user can adjust the degree of reduction, and the reduction algorithm strives to minimize classification error. The algorithm is not dependent on any particular classification technique. Subclusters are formed and readjusted after each sample during the calculation. To summarize the data from the subclusters, representative points are calculated. The data summary that is created can be saved and used for future processing. The accuracy difference between regular and reduced datasets is used to measure the effectiveness of the proposed method. Different classifiers are used to measure the accuracy difference. The results show that the nonlinear information-theoretic cluster distance measure improves the reduction rates with higher accuracy values compared to existing studies. At the same time, the reduction rate can be adjusted as desired, which is a lacking feature in the current methods. The characteristics are discussed, and the results are compared to previously published algorithms.
C1 [Gokcay, Erhan] Atilim Univ, Software Engn, TR-06830 Ankara, Turkiye.
C3 Atilim University
RP Gokcay, E (corresponding author), Atilim Univ, Software Engn, TR-06830 Ankara, Turkiye.
EM erhan.gokcay@atilim.edu.tr
RI Gokcay, Erhan/JOK-0734-2023
OI Gokcay, Erhan/0000-0002-4220-199X
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Amro A, 2021, J INTELL SYST, V30, P438, DOI 10.1515/jisys-2020-0061
   [Anonymous], 2023, DAT SKEL SOURC COD
   Bader J., 2019, 2019 IEEE MIT UND RE
   Barshan E, 2011, PATTERN RECOGN, V44, P1357, DOI 10.1016/j.patcog.2010.12.015
   Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878
   Carbonera JL, 2016, PROC INT C TOOLS ART, P549, DOI [10.1109/ICTAI.2016.87, 10.1109/ICTAI.2016.0090]
   Carbonera JL, 2015, PROC INT C TOOLS ART, P768, DOI 10.1109/ICTAI.2015.114
   Cavalcanti GDC, 2013, EXPERT SYST APPL, V40, P6894, DOI 10.1016/j.eswa.2013.06.053
   Chou CH, 2006, INT C PATT RECOG, P556
   Connor M, 2010, IEEE T VIS COMPUT GR, V16, P599, DOI 10.1109/TVCG.2010.9
   Czarnowski I, 2018, COMPLEXITY, DOI 10.1155/2018/7404627
   Dua D., 2017, UCI MACHINE LEARNING
   Fong YY, 2021, J COMPUT GRAPH STAT, V30, P519, DOI 10.1080/10618600.2020.1856119
   GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809
   Ge W, 2011, 2011 INT C EL INF CO, P5966
   Gisbrecht A, 2015, NEUROCOMPUTING, V147, P71, DOI 10.1016/j.neucom.2013.11.045
   Gokcay E, 2002, IEEE T PATTERN ANAL, V24, P158, DOI 10.1109/34.982897
   Gokcay E, 2020, INFORM SCIENCES, V536, P263, DOI 10.1016/j.ins.2020.05.031
   HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155
   He XF, 2004, ADV NEUR IN, V16, P153
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hout MC, 2013, WIRES COGN SCI, V4, P93, DOI 10.1002/wcs.1203
   Karimi AH, 2018, Arxiv, DOI arXiv:1811.03166
   Kecman V, 2005, STUD FUZZ SOFT COMP, V177, P1
   Krawczyk B, 2019, KNOWL INF SYST, V59, P601, DOI 10.1007/s10115-018-1220-z
   Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1393, DOI 10.1109/TPAMI.2006.184
   Leyva E, 2015, PATTERN RECOGN, V48, P1523, DOI 10.1016/j.patcog.2014.10.001
   Li B, 2009, NEUROCOMPUTING, V73, P191, DOI 10.1016/j.neucom.2008.09.030
   Mandal A, 2023, IEEE T CYBERNETICS, V53, P5497, DOI 10.1109/TCYB.2022.3155875
   Nikolaidis K, 2011, PATTERN RECOGN, V44, P704, DOI 10.1016/j.patcog.2010.08.014
   Nikolaidis K, 2012, IEEE T NEUR NET LEAR, V23, P1169, DOI 10.1109/TNNLS.2012.2198832
   Ran RS, 2021, J MATH IMAGING VIS, V63, P541, DOI 10.1007/s10851-020-01008-w
   Samko O, 2006, PATTERN RECOGN LETT, V27, P968, DOI 10.1016/j.patrec.2005.11.017
   Sarveniazi A., 2014, AM J COMPUT MATH, V04, P55, DOI DOI 10.4236/AJCM.2014.42006
   Siblini W, 2021, IEEE T KNOWL DATA EN, V33, P839, DOI 10.1109/TKDE.2019.2940014
   Van Der Maaten Laurens, 2009, Journal of Machine Learning Research, V10, P13
   Wang Q, 2021, IEEE T IND ELECTRON, V68, P1684, DOI 10.1109/TIE.2020.2969072
   WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137
   Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721
   Yang LJ, 2019, SOFT COMPUT, V23, P13235, DOI 10.1007/s00500-019-03865-z
   Zeng S, 2019, IEEE ACCESS, V7, P35418, DOI 10.1109/ACCESS.2019.2904037
   Zubaroglu A, 2021, ARTIF INTELL REV, V54, P1201, DOI 10.1007/s10462-020-09874-x
NR 43
TC 0
Z9 0
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 7
PY 2023
DI 10.1007/s11042-023-15897-7
EA JUN 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I6WB4
UT WOS:001004157400008
DA 2024-07-18
ER

PT J
AU Kim, YB
   Van Le, T
   Lee, JY
AF Kim, Young Beom
   Van Le, The
   Lee, Jin Young
TI Lightweight brain MR image super-resolution using 3D convolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain MR image; Deep learning; Magnetic resonance imaging (MRI);
   Super-resolution; 3D convolution
AB Magnetic resonance imaging (MRI) plays a very important role in a medical domain, such as image guided diagnostics and therapeutics. In particular, high resolution brain MRI has a great potential for preclinical and clinical procedures, because it is non-invasive imaging and shows a high level of anatomical detail. However, the high resolution MRI faces a number of challenges, such as long scan time, high magnetic field strength, and low signal to noise ratio. To solve these issues, deep learning based super-resolution networks, which provide high performance in various fields, can be employed in MRI. Since the super-resolution networks have been mainly developed to reconstruct high quality color images by using many parameters, they cannot be directly applied into MR scanners. Hence, this paper evaluates conventional networks with brain MR images, and then proposes a lightweight network employing 3D convolution, which consists of extraction, compression, and reconstruction parts. Experimental results show that the proposed network is very efficient, in terms of reconstruction quality and network complexity.
C1 [Kim, Young Beom] Samsung Elect, Seoul, South Korea.
   [Van Le, The; Lee, Jin Young] Sejong Univ, Dept Intelligent Mechatron Engn, Seoul, South Korea.
C3 Samsung Electronics; Samsung; Sejong University
RP Lee, JY (corresponding author), Sejong Univ, Dept Intelligent Mechatron Engn, Seoul, South Korea.
EM jinyounglee@sejong.ac.kr
RI Kim, Young Beom/HTM-3612-2023
OI Le, The/0000-0001-8568-4023
FU Institute of Information & communications Technology Planning &
   Evaluation (IITP) - Korea government (MSIT)
   [IITP-2023-RS-2022-00156345]; National Research Foundation of Korea
   (NRF) - Korea government (MSIT) [NRF-2021R1C1C1006459]
FX This work was supported in part by the Institute of Information &
   communications Technology Planning & Evaluation (IITP) grant funded by
   the Korea government (MSIT) (IITP-2023-RS-2022-00156345) and in part by
   the National Research Foundation of Korea (NRF) grant funded by the
   Korea government (MSIT) (NRF-2021R1C1C1006459).
CR Choi K, 2022, IEEE T CONSUM ELECTR, V68, P119, DOI 10.1109/TCE.2022.3145397
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Fessler JA, 2020, IEEE SIGNAL PROC MAG, V37, P33, DOI 10.1109/MSP.2019.2943645
   Glasser MF, 2013, NEUROIMAGE, V80, P105, DOI 10.1016/j.neuroimage.2013.04.127
   Griswold MA, 2002, MAGN RESON MED, V47, P1202, DOI 10.1002/mrm.10171
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kralik SF, 2017, AM J NEURORADIOL, V38, P807, DOI 10.3174/ajnr.A5093
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu RS, 2019, IEEE T IMAGE PROCESS, V28, P5013, DOI 10.1109/TIP.2019.2913536
   Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391
   Miller JH, 2010, AM J NEURORADIOL, V31, P430, DOI 10.3174/ajnr.A1866
   Pruessmann KP, 1999, MAGNET RESON MED, V42, P952, DOI 10.1002/(SICI)1522-2594(199911)42:5<952::AID-MRM16>3.0.CO;2-S
   Rosen AFG, 2018, NEUROIMAGE, V169, P407, DOI 10.1016/j.neuroimage.2017.12.059
   Rozovsky K, 2013, J CLIN NEUROSCI, V20, P400, DOI 10.1016/j.jocn.2012.02.048
   Sodickson DK, 1997, MAGNET RESON MED, V38, P591, DOI 10.1002/mrm.1910380414
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tohka J, 2014, WORLD J RADIOL, V6, P855, DOI 10.4329/wjr.v6.i11.855
   Van Essen DC, 2013, NEUROIMAGE, V80, P62, DOI 10.1016/j.neuroimage.2013.05.041
NR 20
TC 1
Z9 1
U1 8
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8785
EP 8795
DI 10.1007/s11042-023-15969-8
EA JUN 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001004157400003
DA 2024-07-18
ER

PT J
AU Clement, JC
   Sriharipriya, KC
   Prakasam, P
   Sekaran, DSC
AF Clement, J. Christopher
   Sriharipriya, K. C.
   Prakasam, P.
   Sekaran, D. S. Chandra
TI Throughput enhancement in a cognitive radio network using a
   reinforcement learning method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Spectrum sensing; Cognitive radio; Reinforcement learning; Throughput;
   Deep deterministic policy gradient
ID CHANNEL SELECTION; SPECTRUM; POLICY
AB As the demand for higher data rate is exponentially growing, spectral efficiency improving methods can be adopted in recent day's wireless communication systems. If the cognitive radio network can forecast the channel to be sensed, instead of sensing all channels sequentially, then reasonable increase in throughput can be achieved. In this research, we forecast not only the channel that can be sensed, but we also predict how long the channel remains usable for secondary users. This process can reduce the sensing time. We use a deep deterministic policy gradient method to optimally select the channel and also the duration for sensing. Doing this way, we can minimise the energy spent on sensing and make the cognitive radio energy efficient. Through simulation, we show that the number of operations invested on sensing is minimised. We also show in our result that the higher throughput is achieved.
C1 [Clement, J. Christopher; Sriharipriya, K. C.; Prakasam, P.; Sekaran, D. S. Chandra] Vellore Inst Technol, Vellore, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Clement, JC (corresponding author), Vellore Inst Technol, Vellore, India.
EM christopher.clement@vit.ac.in
RI Clement, J Christopher/N-1715-2019; PERIASAMY, PRAKASAM/B-3075-2016
OI Clement, J Christopher/0000-0002-5713-8938; PERIASAMY,
   PRAKASAM/0000-0002-2471-6375
CR Atapattu S, 2011, IEEE T WIREL COMMUN, V10, P1232, DOI 10.1109/TWC.2011.012411.100611
   Bilandi N, 2020, CAAI T INTELL TECHNO, V5, P222, DOI 10.1049/trit.2020.0059
   Chen XL, 2021, CAAI T INTELL TECHNO, V6, P347, DOI 10.1049/cit2.12011
   Claus C, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P746
   Clement JC, 2016, COMPUT ELECTR ENG, V52, P240, DOI 10.1016/j.compeleceng.2015.09.012
   Clement JC, 2016, CAN J ELECT COMPUT E, V39, P141, DOI 10.1109/CJECE.2016.2514363
   Clement JC, 2015, CIRC SYST SIGNAL PR, V34, P249, DOI 10.1007/s00034-014-9845-y
   Digham FF, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-5, P3575
   Faheem M, 2017, COMPUT STAND INTER, V53, P48, DOI 10.1016/j.csi.2017.03.003
   Gai Y., 2010, 2010 IEEE S NEW FRON, P1
   Guerrini M, 2013, IEEE INT WORK SIGN P, P115, DOI 10.1109/SPAWC.2013.6612023
   Gupta A, 2022, AUTOMAT SOFTW ENG, V29, DOI 10.1007/s10515-022-00332-2
   Hou FK, 2016, 2016 16TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), P655, DOI 10.1109/ISCIT.2016.7751715
   Karthik P, 2021, CAAI T INTELL TECHNO, V6, P147, DOI 10.1049/cit2.12041
   Kumari S, 2021, COMPUT COMMUN, V178, P161, DOI 10.1016/j.comcom.2021.07.023
   Kumari S, 2021, COMPUT COMMUN, V171, P10, DOI 10.1016/j.comcom.2021.02.004
   Li HS, 2009, IEEE SYS MAN CYBERN, P1893, DOI 10.1109/ICSMC.2009.5346172
   Liu KQ, 2010, INT CONF ACOUST SPEE, P3010, DOI 10.1109/ICASSP.2010.5496131
   Liu X, 2006, MOBILE NETW APPL, V11, P577, DOI 10.1007/s11036-006-7323-x
   Mitola J, 1999, IEEE PERS COMMUN, V6, P13, DOI 10.1109/98.788210
   Oksanen J, 2015, IEEE T SIGNAL PROCES, V63, P1214, DOI 10.1109/TSP.2015.2391072
   Pei Y, 2007, 2007 IEEE 18TH INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR AND MOBILE RADIO COMMUNICATIONS, VOLS 1-9, P2537
   Qiu CR, 2019, IEEE INTERNET THINGS, V6, P8577, DOI 10.1109/JIOT.2019.2921159
   Raj V, 2018, IEEE J-STSP, V12, P20, DOI 10.1109/JSTSP.2018.2798920
   Sengottuvelan S, 2017, IEEE T MOBILE COMPUT, V16, P1258, DOI 10.1109/TMC.2016.2592917
   Senthilmurugan S, 2017, IEEE T COGN COMMUN, V3, P26, DOI 10.1109/TCCN.2017.2669985
   Sriharipriya KC, 2018, CIRC SYST SIGNAL PR, V37, P1988, DOI 10.1007/s00034-017-0649-8
   Sriharipriya KC, 2014, CIRC SYST SIGNAL PR, V33, P2851, DOI 10.1007/s00034-014-9768-7
   Unnikrishnan J, 2010, IEEE T SIGNAL PROCES, V58, P750, DOI 10.1109/TSP.2009.2028970
   Xing XS, 2013, IEEE WIREL COMMUN, V20, P90, DOI 10.1109/MWC.2013.6507399
   Xu YH, 2013, IEEE COMMUN SURV TUT, V15, P1689, DOI 10.1109/SURV.2013.030713.00189
   Xu YH, 2012, IEEE J-STSP, V6, P180, DOI 10.1109/JSTSP.2011.2176916
   Yang J, 2015, IEEE COMMUN LETT, V19, P1738, DOI 10.1109/LCOMM.2015.2442571
   Zhao Q., 2007, Decentralized cognitive mac for opportunistic spectrum access in ad hoc networks: A pomdp framework
   Zhu J, 2016, IEEE ACCESS, V4, P4609, DOI 10.1109/ACCESS.2016.2600633
NR 35
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 2
PY 2023
DI 10.1007/s11042-023-15432-8
EA JUN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0KI8
UT WOS:000999746300005
DA 2024-07-18
ER

PT J
AU Li, HR
   Yao, HX
   Hou, YX
AF Li, Haoran
   Yao, Hongxun
   Hou, Yuxin
TI Hierarchical pose net: spatial hierarchical body tree driven
   multi-person pose estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-person pose estimation; Spatial hierarchical body tree; Shared
   filters spatial pyramid
AB In this paper, we explore multi-level semantic information of human body structure and propose a paradigm for bottom-up multi-person pose estimation. To represent the multi-level semantic body structure, we define a Spatial Hierarchical Body Tree (SHBT) that encodes the location and association information of the body center, parts, and joints for each human instance. This encoding approach assists in associating joints to each human instance, and the multi-level form is suitable for handling cases of partial human body occlusion. To apply the spatial hierarchical body tree to multi-person pose estimation, we build Hierarchical Pose Net(Heap-net) by inheriting the topology of the SHBT. This Heap-net explicitly defines the corresponding output order and the feature fusion aggregation. Furthermore, we propose a shared filters spatial pyramid module, which consists of a multi-branches dilation convolution module with shared filters and a max-out activation, to alleviate the effect of a wide range of human scale. To verify the effectiveness of our model, we conduct experiments on the MSCOCO keypoints detection validation and test set. The experimental results are comparable to the previous bottom-up multi-person pose estimation methods.
C1 [Li, Haoran; Yao, Hongxun; Hou, Yuxin] Harbin Inst Technol, Sch Comp Sci & Technol, Dept, Dazhi St West 92, Harbin 150006, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology
RP Li, HR (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Dept, Dazhi St West 92, Harbin 150006, Heilongjiang, Peoples R China.
EM haoran_li@hit.edu.cn; h.yao@hit.edu.cn; YuxinHou_054@outlook.com
RI Hou, Yuxin/J-3660-2019
OI Li, Haoran/0000-0002-9798-6480
FU National Key R&D Program of China [2021ZD0110901]
FX AcknowledgementsThis work is supported by the National Key R&D Program
   of China (No. 2021ZD0110901).
CR Cao Z, 2017, Arxiv, DOI [arXiv:1611.08050, DOI 10.48550/ARXIV.1611.08050, 10.48550/ARXIV.1611.08050]
   Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen YL, 2018, Arxiv, DOI [arXiv:1711.07319, DOI 10.1109/CVPR.2018.00742]
   Chu X, 2016, Arxiv, DOI arXiv:1603.09065
   Chu X, 2017, PROC CVPR IEEE, P5669, DOI 10.1109/CVPR.2017.601
   Contributors M., 2020, OpenMMLab Pose Estimation Toolbox and Benchmark
   Corona E, 2020, PROC CVPR IEEE, P6990, DOI 10.1109/CVPR42600.2020.00702
   Dai Jifeng, 2016, Advances in Neural Information Processing Systems, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075
   Dantone M, 2013, PROC CVPR IEEE, P3041, DOI 10.1109/CVPR.2013.391
   Deng JK, 2018, IEEE INT CONF AUTOMA, P399, DOI 10.1109/FG.2018.00064
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Fang HS, 2018, Arxiv, DOI arXiv:1710.06513
   Felzenszwalb P., 2008, 2008 IEEE C COMP VIS, DOI [10.1109/CVPR.2008.4587597, DOI 10.1109/CVPR.2008.4587597]
   FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602
   Han JG, 2012, IEEE T CONSUM ELECTR, V58, P255, DOI 10.1109/TCE.2012.6227420
   He KM, 2018, Arxiv, DOI [arXiv:1703.06870, 10.48550/arXiv.1703.06870, DOI 10.48550/ARXIV.1703.06870]
   Hsiao W-L, 2019, ARXIV
   Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3
   Kreiss S, 2019, Arxiv, DOI arXiv:1903.06593
   Lee HY, 2019, Arxiv, DOI arXiv:1911.02001
   Li C, 2022, IEEE T NEUR NET LEAR, V33, P4800, DOI 10.1109/TNNLS.2021.3061115
   Li JN, 2023, IEEE T IMAGE PROCESS, V32, P1108, DOI 10.1109/TIP.2023.3239192
   Li WB, 2019, Arxiv, DOI arXiv:1901.00148
   Lin TY, 2017, Arxiv, DOI [arXiv:1612.03144, DOI 10.48550/ARXIV.1612.03144]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2022, IEEE T PATTERN ANAL, V44, P3688, DOI 10.1109/TPAMI.2021.3053577
   Liu ZW, 2016, Arxiv, DOI arXiv:1608.03049
   Ma LQ, 2018, Arxiv, DOI arXiv:1705.09368
   Mao W, 2020, HIST REPEATS ITSELF, V16
   Newell A, 2016, Arxiv, DOI [arXiv:1603.06937, DOI 10.48550/ARXIV.1603.06937]
   Newell A, 2017, Arxiv, DOI arXiv:1611.05424
   Nie BX, 2015, PROC CVPR IEEE, P1293, DOI 10.1109/CVPR.2015.7298734
   Nie XC, 2019, Arxiv, DOI arXiv:1908.09220
   Papandreou G, 2018, Arxiv, DOI [arXiv:1803.08225, DOI 10.48550/ARXIV.1803.08225, 10.48550/ARXIV.1803.08225]
   Pfister T, 2015, IEEE I CONF COMP VIS, P1913, DOI 10.1109/ICCV.2015.222
   Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533
   Pishchulin L, 2013, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2013.82
   Qian XL, 2018, Arxiv, DOI [arXiv:1712.02225, 10.48550/arXiv.1712.02225]
   Raja K, 2011, IEEE IMAGE PROC, P25, DOI 10.1109/ICIP.2011.6116197
   Redmon J, 2016, Arxiv, DOI arXiv:1506.02640
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rothrock B, 2013, PROC CVPR IEEE, P3214, DOI 10.1109/CVPR.2013.413
   Shao Zhuang, 2022, IEEE Trans Neural Netw Learn Syst, VPP, DOI 10.1109/TNNLS.2022.3152990
   Shi DH, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3079, DOI 10.1145/3474085.3475447
   Siarohin A, 2018, Arxiv, DOI arXiv:1801.00055
   Sun K, 2019, Arxiv, DOI [arXiv:1902.09212, 10.48550/arXiv.1902.09212, DOI 10.48550/ARXIV.1902.09212]
   Sun M, 2011, IEEE I CONF COMP VIS, P723, DOI 10.1109/ICCV.2011.6126309
   Tian Yuandong, 2012, Proceedings of the European Conference on Computer Vision, P256
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Wang Y, 2008, LECT NOTES COMPUT SC, V5304, P710, DOI 10.1007/978-3-540-88690-7_53
   Wei SE, 2016, Arxiv, DOI arXiv:1602.00134
   Xiao B, 2018, Arxiv, DOI arXiv:1804.06208
   Yan SJ, 2018, Arxiv, DOI [arXiv:1801.07455, DOI 10.1609/AAAI.V32I1.12328, 10.48550/ARXIV.1801.07455]
   Yang S, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109232
   Zhang BC, 2017, IEEE T IMAGE PROCESS, V26, P4648, DOI 10.1109/TIP.2017.2718189
   Zhang H, 2019, Arxiv, DOI arXiv:1901.01760
   Zhang JB, 2019, Arxiv, DOI arXiv:1908.05593
   Zhou XY, 2019, Arxiv, DOI [arXiv:1904.07850, 10.48550/arXiv.1904.07850]
   Zhu Z, 2022, IEEE T PATTERN ANAL, V44, P4306, DOI 10.1109/TPAMI.2021.3068236
NR 61
TC 0
Z9 0
U1 5
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 29
PY 2023
DI 10.1007/s11042-023-15320-1
EA MAY 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H8LP5
UT WOS:000998414300001
DA 2024-07-18
ER

PT J
AU Naseer, A
   Tamoor, M
   Khan, A
   Akram, D
   Javaid, Z
AF Naseer, Asma
   Tamoor, Maria
   Khan, Ayesha
   Akram, Dawood
   Javaid, Zohaib
TI Occupancy detection via thermal sensors for energy consumption reduction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE HVAC System; Occupancy detection; Sensors; Demand control ventilation;
   Thermal
ID BUILDING ENERGY
AB With the emergence of Internet of Things (IoT), the usage of sensors for controlling and monitoring remote devices to achieve sustainability has gained researchers' interest. It has been observed that buildings are one of the largest consumers of energy hence, effective measures are required to achieve sustainability. In this sector, substantial amount of energy is used by HVAC (Heating, Ventilation and Air Conditioning) systems to offer ease for occupants. In most cases, HVAC systems of these buildings run on fixed schedules and do not provide any satisfactory control, based on detailed occupancy information. In this paper, a new solution is presented for estimating occupancy using network of thermal sensor arrays. The system provides near real time actionable information for controlling HVAC system and conditioning the rooms based on usage. The proposed system is a network of wired sensors, wireless sensors and gateway nodes, working together. Energy readings estimate the battery life of over two years, while working accurately. The system shows potential energy savings of 10% to 15%. Recurrent neural network are also used to train the model and compared with the proposed method. We conclude this new approach remarkably improves the results of occupancy detection using network of thermal sensor arrays.
C1 [Naseer, Asma] Natl Univ Comp & Emerging Sci, Lahore, Pakistan.
   [Tamoor, Maria; Khan, Ayesha] Forman Christian Coll, Lahore, Pakistan.
   [Akram, Dawood; Javaid, Zohaib] UMT, Lahore, Pakistan.
RP Tamoor, M (corresponding author), Forman Christian Coll, Lahore, Pakistan.
EM mariatamoor@fccollege.edu.pk
OI Khan, Ayesha/0009-0001-3160-1533
CR [Anonymous], 2020, OCCUPANCY DATASET
   Arvidsson S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041036
   Baroffio L, 2015, 2015 IEEE 2ND WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P745, DOI 10.1109/WF-IoT.2015.7389147
   Caicedo D, 2012, EUR SIGNAL PR CONF, P175
   D'Oca S, 2015, ENERG BUILDINGS, V88, P395, DOI 10.1016/j.enbuild.2014.11.065
   Dhuri V., 2021, 2021 International Conference on Advances in Electrical, Computing, Communication and Sustainable Technologies (ICAECT), P1, DOI [DOI 10.1109/ICAECT49130.2021.9392506, 10.1109/ICAECT49130. 2021.9392506]
   Diraco G, 2015, ENERG BUILDINGS, V92, P246, DOI 10.1016/j.enbuild.2015.01.043
   Dodier RH, 2006, ENERG BUILDINGS, V38, P1033, DOI 10.1016/j.enbuild.2005.12.001
   Domdouzis K, 2007, ADV ENG INFORM, V21, P350, DOI 10.1016/j.aei.2006.09.001
   Dong B, 2011, J BUILD PERFORM SIMU, V4, P359, DOI 10.1080/19401493.2011.577810
   Fatema N., 2021, Data-driven occupancy detection hybrid model using particle swarm optimization based artificial neural network, P283
   Federspiel CC, 1997, IEEE T CONTR SYST T, V5, P480, DOI 10.1109/87.623034
   Feng C, 2020, IEEE T SMART GRID, V11, P4490, DOI 10.1109/TSG.2020.2982351
   Gu YY, 2009, IEEE COMMUN SURV TUT, V11, P13, DOI 10.1109/SURV.2009.090103
   Gul MS, 2015, ENERG BUILDINGS, V87, P155, DOI 10.1016/j.enbuild.2014.11.027
   Hailemariam E, 2011, SYMPOSIUM ON SIMULATION FOR ARCHITECTURE AND URBAN DESIGN 2011 (SIMAUD 2011) - 2011 SPRING SIMULATION MULTICONFERENCE - BK 8 OF 8, P141
   Hallberg J, 2003, ICT'2003: 10TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS, VOLS I AND II, CONFERENCE PROCEEDINGS, P954
   Hallberg J., 2009, FINAL PROGR ABSTR B, P1, DOI DOI 10.1109/ITAB.2009.5394459
   Konis K, 2020, BUILD ENVIRON, V169, DOI 10.1016/j.buildenv.2019.106588
   Liu DX, 2013, MEAS SCI TECHNOL, V24, DOI 10.1088/0957-0233/24/7/074023
   Liu H, 2007, IEEE T SYST MAN CY C, V37, P1067, DOI 10.1109/TSMCC.2007.905750
   Naseer A, 2021, INT J BIOMED IMAGING, V2021, DOI 10.1155/2021/5513500
   Naseer A, 2019, COMPUT MATH ORGAN TH, V25, P165, DOI 10.1007/s10588-018-9265-9
   Naseer A, 2018, INT J ADV COMPUT SC, V9, P419
   Payne F W., 2012, Energy management and control systems handbook
   Platner BP., 1997, US PATENT, V5, P701
   Tamoor M, 2021, J XRAY SCI TECHNOL P, P1
   Wahl F, 2012, 2012 5TH EUROPEAN DSP EDUCATION AND RESEARCH CONFERENCE (EDERC), P203, DOI 10.1109/EDERC.2012.6532255
   Wang SW, 1999, INDOOR BUILT ENVIRON, V8, P377, DOI 10.1177/1420326X9900800605
NR 29
TC 0
Z9 0
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 29
PY 2023
DI 10.1007/s11042-023-15553-0
EA MAY 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H8LP5
UT WOS:000998414300007
DA 2024-07-18
ER

PT J
AU Mahato, S
   Paul, S
AF Mahato, Shalini
   Paul, Sanchita
TI Analysis of region of interest (RoI) of brain for detection of
   depression using EEG signal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Depression; Electroencephalography (EEG); Machine Learning; Bagging
ID APPROXIMATE ENTROPY; ARTIFACTS
AB Depression is a psychiatric disorder that has a negative impact on a person's development, such as how they think, feel, and behave. Electroencephalogram (EEG) signal can act as biomarker for detection of depression. In this study, analysis is carried out on EEG signals to identify in which region of the brain depression affects so that high accuracy with low number of EEG channels could be obtained.For this purpose the brain is divided basically into six regions. Four EEG band power features - delta, theta, alpha and beta band power and non-linear features - Approximate Entropy (ApEn), Sample Entropy (SampEn), Correlation Dimension (CD) and Detrended Fluctuation Analysis (DFA) are extracted from all the channels. Based on different regions of the brain and different features, classifiers - Linear Discriminant Analysis (LDA), Naive Bayesian (NB), Logistic Regression (LR), Decision Tree (DT), Support Vector Machine (SVM) and Bagging have been used.Results show non-linear feature SampEn and DFA showed comparatively higher accuracy compared to 4 EEG band power features, CD and ApEn. Highest classification accuracy of 95.23% was attained using SVM along with ReliefF. Results also show that depression effects the temporal region of the brain.Thus a portable device with lesser number of channels specifically placed in temporal region would be able to detect depression with high accuracy which could act as an adjunct tool for detection of depression.
C1 [Mahato, Shalini] Indian Inst Informat Technol IIIT, Dept Comp Sci & Engn, Ranchi, Jharkhand, India.
   [Paul, Sanchita] Birla Inst Technol, Dept Comp Sci & Engn, Ranchi, India.
C3 Indian Institute of Information Technology Allahabad; Birla Institute of
   Technology Mesra
RP Mahato, S (corresponding author), Indian Inst Informat Technol IIIT, Dept Comp Sci & Engn, Ranchi, Jharkhand, India.
EM swarup.shalini@gmail.com
OI mahato, shalini/0000-0001-8766-0340
CR American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders (DSM-5), V5th ed., DOI DOI 10.1176/APPI.BOOKS.9780890425596
   [Anonymous], 2017, Saudi. Med. J., V38, P444
   Asif R, 2020, IEEE ACCESS, V8, P65880, DOI 10.1109/ACCESS.2020.2983917
   Beck AT, 1967, DIAGN STAT MAN MENT, P339
   Bouallegue G, 2020, IEEE ACCESS, V8, P206992, DOI 10.1109/ACCESS.2020.3037995
   Cai HS, 2020, IEEE T AFFECT COMPUT, V11, P383, DOI 10.1109/TAFFC.2018.2801289
   Cai HS, 2018, COMPLEXITY, DOI 10.1155/2018/5238028
   Chen ZX, 2020, IEEE ACCESS, V8, P20080, DOI 10.1109/ACCESS.2020.2969055
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Delorme A, 2007, NEUROIMAGE, V34, P1443, DOI 10.1016/j.neuroimage.2006.11.004
   Dien J, 1998, BEHAV RES METH INS C, V30, P34, DOI 10.3758/BF03209414
   Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523, DOI 10.1109/CSB.2003.1227396
   figshare, About us
   Gandhi V, 2014, BRAIN-COMPUT INTERFA, P21
   GRASSBERGER P, 1983, PHYSICA D, V9, P189, DOI 10.1016/0167-2789(83)90298-1
   Han J, 2012, MOR KAUF D, P1
   Hasanzadeh F, 2021, IEEE ACCESS, V9, P3417, DOI 10.1109/ACCESS.2020.3046993
   Hosseinifard B., 2011, Conference: 19th Iranian Conference on Electrical Engineering, V109, P1, DOI [DOI 10.1016/J.CMPB.2012.10.008, 10.1016/j.cmpb.2012.10.008.]
   James G., 2017, INTRO STAT LEARNING, P138
   Jernajczyk W, 2017, ADV EXP MED BIOL, V968, P79, DOI 10.1007/5584_2016_180
   Jung TP, 2000, PSYCHOPHYSIOLOGY, V37, P163, DOI 10.1017/S0048577200980259
   Khan AI, 2022, ENG APPL ARTIF INTEL, V114, DOI 10.1016/j.engappai.2022.104996
   KIRA K, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P129
   Kononenko I., 1994, EUR C MACH LEARN, V94, P171, DOI DOI 10.1007/3-540-57868-4_57
   Kutner Michael H., Applied Linear Statistical models, P555
   LEVY WJ, 1987, ANESTHESIOLOGY, V66, P489, DOI 10.1097/00000542-198704000-00007
   Liao SC, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061385
   Mahato Shalini, 2019, Nanoelectronics, Circuits and Communication Systems. Proceeding of NCCS 2017. Lecture Notes in Electrical Engineering (LNEE 511), P323, DOI 10.1007/978-981-13-0776-8_30
   Mahato S, 2020, J MED SYST, V44, DOI 10.1007/s10916-019-1486-z
   Mahato S, 2019, MICROSYST TECHNOL, V25, P1065, DOI 10.1007/s00542-018-4075-z
   Mohammadi M, 2015, BMC MED INFORM DECIS, V15, DOI 10.1186/s12911-015-0227-6
   Mumtaz W, 2018, BRAIN TOPOGR, V31, P875, DOI 10.1007/s10548-018-0651-x
   Mumtaz W, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171409
   Myung IJ, 2003, J MATH PSYCHOL, V47, P90, DOI 10.1016/S0022-2496(02)00028-7
   Niemiec AJ, 2005, P ANN INT IEEE EMBS, P7517, DOI 10.1109/IEMBS.2005.1616251
   Paul J, 2014, WORLD ACAD SCI ENG T, V8
   PENG CK, 1995, CHAOS, V5, P82, DOI 10.1063/1.166141
   PINCUS SM, 1991, P NATL ACAD SCI USA, V88, P2297, DOI 10.1073/pnas.88.6.2297
   Richman JS, 2004, METHOD ENZYMOL, V384, P172
   Richman JS, 2000, AM J PHYSIOL-HEART C, V278, pH2039
   Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714
   Rodriguez-Bermudez G., 2015, Applied Mathematics and Information Science, V9, P2309, DOI DOI 10.12785/AMIS/090512
   Sarker IH, MOBILE NETW APPL
   Sternberg RJ., 2012, COGNITIVE PSYCHOL, V6, P52
   Tharwat A, 2021, APPL COMPUT INFORM, V17, P222, DOI 10.1016/j.aci.2018.08.006
   Tharwat A, 2016, INT J APPL PATTERN R, V3, P145, DOI 10.1504/IJAPR.2016.079050
   Theodoridis S., 2009, PATTERN RECOGN, V4, P215
   Tortora G.J., 2012, Principles of Anatomy and Physiology, V11th, P495
NR 49
TC 6
Z9 6
U1 10
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 23
PY 2023
DI 10.1007/s11042-023-15827-7
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H1DL6
UT WOS:000993432500002
DA 2024-07-18
ER

PT J
AU Tan, CQ
   Wu, C
   Wu, CJ
   Chen, H
AF Tan, Chaoqun
   Wu, Chong
   Wu, Chunjie
   Chen, Hu
TI Visual feature-based improved EfficientNet-GRU for <i>Fritillariae
   Cirrhosae Bulbus</i> identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE EfficientNet; Fritillariae Cirrhosae Bulbus; Gated recurrent unit;
   Identification; Image captioning
ID RAPID IDENTIFICATION; MASS-SPECTROMETRY; IMAGE; CLASSIFICATION;
   STRATEGY; MODEL; CNN
AB Fritillariae Cirrhosae Bulbus (FCB) as a well-known traditional Chinese Medicine (TCM), which is widely used for its ability of relieving cough and eliminating phlegm in cooking and treating. However, the adulteration by different species for economic profit has frequently been reported. Inspired by deep learning, a novel approach based on image captioning is proposed to achieve the accurate and fast identification of FCB: EGNet, via bridging between image visual features and word expression in Chinese Pharmacopoeia. In encoder module, Convolutional Block Attention Module (CBAM) and spatial attention module (SA) are introduced into EfficientNet-B0 to strengthen and focus on the unique features. For decoder module, due to the simpler structure and fewer parameters, gated recurrent unit (GRU) is applied for generating the correspondence and explanation with text descriptions. Simultaneously, the adaptive attention mechanism with a visual sentinel is inject into GRU for judging adaptively whether to rely on visual information or semantic information. Eventually, experiments confirm that the proposed EGNet outperforms competing methods. And it is superior in the highest identification accuracy of 99.0%, 99.3% and 99.4%, the best words matching completeness 91.1%, 92.2% and 91.6% for Lubei, Qingbei, and Songbei. This paper can significantly improve the accuracy of classification and the cost is low. It is proved to be an exceptional practice for the high-efficiency of TCM-discrimination and TCM-technology.
C1 [Tan, Chaoqun; Wu, Chong; Chen, Hu] Sichuan Univ, Coll Comp Sci, Natl Key Lab Fundamental Sci Synthet Vis, Chengdu 610065, Peoples R China.
   [Wu, Chunjie] Chengdu Univ Tradit Chinese Med, Coll Pharm, Chengdu 610075, Peoples R China.
C3 Sichuan University; Chengdu University of Traditional Chinese Medicine
RP Chen, H (corresponding author), Sichuan Univ, Coll Comp Sci, Natl Key Lab Fundamental Sci Synthet Vis, Chengdu 610065, Peoples R China.
EM huchen@scu.edu.cn
RI Tan, Chaoqun/S-5943-2019; zhang, zhang/KBQ-9978-2024
FU Project of State Administration of Traditional Chinese Medicine of
   Sichuan [2021MS012]; Research Promotion Plan for Xinglin Scholars in
   Chengdu University of Traditional Chinese Medicine [QNXZ2019018];
   Research on Informatization of Traditional Chinese Medicine in Chengdu
   University of Traditional Chinese Medicine [MIEC1803]
FX This study was funded by the Project of State Administration of
   Traditional Chinese Medicine of Sichuan (grant no. 2021MS012), Research
   Promotion Plan for Xinglin Scholars in Chengdu University of Traditional
   Chinese Medicine (No.QNXZ2019018), and Research on Informatization of
   Traditional Chinese Medicine in Chengdu University of Traditional
   Chinese Medicine (No.MIEC1803).
CR Al-Muzaini HA, 2018, INT J ADV COMPUT SC, V9, P67
   Azimi S, 2021, MEASUREMENT, V173, DOI 10.1016/j.measurement.2020.108650
   Bisen D, 2021, MULTIMED TOOLS APPL, V80, P6443, DOI 10.1007/s11042-020-10038-w
   Che WB, 2020, IEEE T MULTIMEDIA, V22, P2307, DOI 10.1109/TMM.2019.2954750
   Chen JB, 2018, J MOL STRUCT, V1155, P681, DOI 10.1016/j.molstruc.2017.11.013
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen Q, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0229181
   Chen XY, 2021, IEEE WINT CONF APPL, P545, DOI 10.1109/WACV48630.2021.00059
   China Pharmaceutical Technology Press, 2015, PHARMACOPOEIA PEOPLE, P36
   Chung Junyoung, 2014, ARXIV14123555
   Deng ZR, 2020, SIGNAL PROCESS-IMAGE, V85, DOI 10.1016/j.image.2020.115836
   Ding ST, 2020, NEUROCOMPUTING, V398, P520, DOI 10.1016/j.neucom.2019.04.095
   Diwakar M, 2020, MULTIMED TOOLS APPL, V79, P14449, DOI 10.1007/s11042-018-6897-1
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Fu K, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12111874
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Geetharamani G, 2019, COMPUT ELECTR ENG, V76, P323, DOI 10.1016/j.compeleceng.2019.04.011
   Guo LT, 2020, IEEE T MULTIMEDIA, V22, P2149, DOI 10.1109/TMM.2019.2951226
   Gupta K, 2020, INT J AGRIC ENVIRON, V11, P25, DOI 10.4018/IJAEIS.2020100102
   Hangzhou Jiaben Technology Co. Ltd, 2010, CHINESE HERBAL MED M
   Kassim YM, 2021, IEEE J BIOMED HEALTH, V25, P1735, DOI 10.1109/JBHI.2020.3034863
   Kuang HL, 2018, NEUROCOMPUTING, V283, P241, DOI 10.1016/j.neucom.2017.12.057
   Le THN, 2018, PATTERN RECOGN, V80, P32, DOI 10.1016/j.patcog.2018.01.005
   Li RF, 2020, NEUROCOMPUTING, V396, P92, DOI 10.1016/j.neucom.2020.02.041
   Li YZ, 2018, NEUROCOMPUTING, V314, P336, DOI 10.1016/j.neucom.2018.06.068
   Liu FJ, 2020, J CHROMATOGR A, V1612, DOI 10.1016/j.chroma.2019.460630
   Liu MF, 2022, IEEE T CYBERNETICS, V52, P1247, DOI 10.1109/TCYB.2020.2997034
   Lo FPW, 2020, IEEE J BIOMED HEALTH, V24, P1926, DOI 10.1109/JBHI.2020.2987943
   Loshchilov I., 2019, DECOUPLED WEIGHT DEC
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Luo DD, 2018, BIOCHEM SYST ECOL, V76, P46, DOI 10.1016/j.bse.2017.12.007
   Mahmoud MAB, 2020, MULTIMED TOOLS APPL, V79, P26245, DOI 10.1007/s11042-020-09239-0
   Minister of Health of the People's Republic of China, 2002, LIST IT CAN BE US HL
   Naqvi N, 2020, MULTIMED TOOLS APPL, V79, P24429, DOI 10.1007/s11042-020-09128-6
   Qiu DC, 2020, PLANET SPACE SCI, V188, DOI 10.1016/j.pss.2020.104943
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sharma Himanshu, 2021, Proceedings of International Conference on Communication and Artificial Intelligence. ICCAI 2020. Lecture Notes in Networks and Systems (LNNS 192), P483, DOI 10.1007/978-981-33-6546-9_46
   Shen XQ, 2020, MULTIMED TOOLS APPL, V79, P26661, DOI 10.1007/s11042-020-09294-7
   Spencer M, 2015, IEEE ACM T COMPUT BI, V12, P103, DOI 10.1109/TCBB.2014.2343960
   Su JS, 2019, NEUROCOMPUTING, V367, P144, DOI 10.1016/j.neucom.2019.08.012
   Sun X, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0156327
   Tan CQ, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0230287
   Tan M., 2019, arXiv
   Tanti M, 2018, 2018 EUR C COMP VIS, V11132, P114
   Thangaraj R, 2021, J PLANT DIS PROTECT, V128, P73, DOI 10.1007/s41348-020-00403-0
   Too EC, 2019, J INTELL FUZZY SYST, V37, P4003, DOI 10.3233/JIFS-190184
   Vellakani S, 2020, J X-RAY SCI TECHNOL, V28, P975, DOI 10.3233/XST-200697
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang CY, 2021, ARTIF INTELL REV, V54, P5205, DOI 10.1007/s10462-021-10018-y
   Wang HZ, 2020, NEUROCOMPUTING, V401, P249, DOI 10.1016/j.neucom.2020.03.087
   Wang L, 2017, ANAL CHIM ACTA, V977, P28, DOI 10.1016/j.aca.2017.04.023
   Wang TS, 2021, COMB CHEM HIGH T SCR, V24, P921, DOI 10.2174/1386207323666200715171334
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie ZW, 2020, PATTERN RECOGN LETT, V133, P70, DOI 10.1016/j.patrec.2019.03.003
   Xin GZ, 2014, ANAL CHIM ACTA, V820, P84, DOI 10.1016/j.aca.2014.02.039
   Xin GZ, 2014, MOLECULES, V19, P3450, DOI 10.3390/molecules19033450
   Xiong JB, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10010081
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yan Tang, 2021, 2021 IEEE 4th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC), P574, DOI 10.1109/IMCEC51613.2021.9482214
   Yang M, 2020, IEEE T IMAGE PROCESS, V29, P9627, DOI 10.1109/TIP.2020.3028651
   Yang SL, 2015, ANAL METHODS-UK, V7, P943, DOI [10.1039/C4AY02230K, 10.1039/c4ay02230k]
   Yap MH, 2018, IEEE J BIOMED HEALTH, V22, P1218, DOI 10.1109/JBHI.2017.2731873
   Zhang XD, 2020, NEUROCOMPUTING, V395, P212, DOI 10.1016/j.neucom.2018.02.112
   Zhao QQ, 2019, ACTA PHARM SIN B, V9, P1241, DOI 10.1016/j.apsb.2019.04.004
   Zhong YC, 2019, MOLECULES, V24, DOI 10.3390/molecules24183269
   Zhou CL, 2021, 2021 2 INT WORKSH EL
   Zilong Zhong, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13062, DOI 10.1109/CVPR42600.2020.01308
NR 67
TC 0
Z9 0
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 20
PY 2023
DI 10.1007/s11042-023-15497-5
EA MAY 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H0OU4
UT WOS:000993050400005
DA 2024-07-18
ER

PT J
AU Abeje, BT
   Salau, AO
   Gela, BM
   Mengistu, AD
AF Abeje, Bekalu Tadele
   Salau, Ayodeji Oalelan
   Gela, Belsti Mulualem
   Mengistu, Abrham Debasu
TI Soil type identification model using a hybrid computer vision and
   machine learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Soil type identification; CNN; PCA; SVM
AB Computer vision and its technologies are being used in the area of agricultural automation to identify, locate, and track targets for further image processing. Mostly, agricultural production has been highly dependent on natural resources like soil, water, and other related natural minerals from the soil. Soil classification is a way of arranging soils that have similar characteristics into groups. Identifying and classifying soils has a great role to play in agricultural productivity as it helps to provide relevant information which aids agricultural experts to recommend the type of crop best suited for a specific type of soil. This study mainly concentrated on classifying soil types such as clay soil, loam soil, sandy soil, peat soil, silt soil, and chalk soil. The soil images were collected from Amhara region at different locations by using a sony digital camera. To reduce image noise due to handshake we used a camera stand or arm to avoid other types of noises like environmental lighting effects and shadow. Once the dataset was collected, preprocessing such as resizing and gamma correction was performed to remove noise from the images, and contrast adjustment was also performed. Experimental research was applied as a general methodology and the experiment was conducted based on two approaches. The first approach used CNN as an end-to-end classifier and the second used a hybrid approach which used CNN as a feature extractor and SVM as a classifier. When CNN was used as an end-to-end classifier, a classification accuracy of 88% was achieved, whereas when the hybrid approach which used CNN as feature extractor and SVM as classifier was employed, a classification accuracy of 95% was achieved. Finally, we conclude that the hybrid approach is better than that of the End-to-End classification using our proposed model.
C1 [Abeje, Bekalu Tadele] Haramaya Univ, Dept Informat Technol, Dire Dawa, Ethiopia.
   [Salau, Ayodeji Oalelan] Afe Babalola Univ, Dept Elect Elect & Comp Engn, Ado Ekiti, Nigeria.
   [Salau, Ayodeji Oalelan] Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Chennai, India.
   [Gela, Belsti Mulualem] Bahir Dar Univ Inst Technol, Bahir Dar, Ethiopia.
   [Mengistu, Abrham Debasu] Bahir Dar Univ, Inst Technol, Dept Comp Sci, Bahir Dar, Ethiopia.
C3 Haramaya University; Saveetha Institute of Medical & Technical Science;
   Saveetha School of Engineering; Bahir Dar University
RP Salau, AO (corresponding author), Afe Babalola Univ, Dept Elect Elect & Comp Engn, Ado Ekiti, Nigeria.; Salau, AO (corresponding author), Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Chennai, India.
EM bekalutadele@gmail.com; ayodejisalau98@gmail.com; belistym@gmail.com;
   Abitiy@gmail.com
RI salau, ayodeji Olalekan/C-1016-2018
OI salau, ayodeji Olalekan/0000-0002-6264-9783
CR Albawi S, 2017, I C ENG TECHNOL
   Archana Reddy AKM, 2020, INT J RES APPL SCI E, V8, P1625, DOI [10.22214/ijraset.2020.30611, DOI 10.22214/IJRASET.2020.30611]
   Barman Utpal, 2020, Information Processing in Agriculture, V7, P318, DOI 10.1016/j.inpa.2019.08.001
   Bhargavi P., 2010, International Journal of Computer Science & Information Technology, V2, P184, DOI 10.5121/ijcsit.2010.2514
   Gao X, 2014, 2014 IEEE 7TH JOINT INTERNATIONAL INFORMATION TECHNOLOGY AND ARTIFICIAL INTELLIGENCE CONFERENCE (ITAIC), P432, DOI 10.1109/ITAIC.2014.7065086
   Getahun M, 2015, CHARACTERISATION AGR, P172
   Harlianto PA, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON SCIENCE AND TECHNOLOGY - COMPUTER (ICST), P7, DOI 10.1109/ICSTC.2017.8011843
   Mengistu A. D., 2018, Int J Electr Comput Eng, V8, P989, DOI 10.11591/ijece.v8i2.pp989-995
   Mesfin Kebede Mesfin Kebede, 2017, Journal of Soil Science and Environmental Management, V8, P61, DOI 10.5897/jssem2015.0498
   Mitra KC, 2020, SOIL CLASSIFICATION, DOI [10.1109/ICCITECHN.2018.8631943, DOI 10.1109/ICCITECHN.2018.8631943]
   Nikiforova AA., 2019, IEEE, V46, P467
   Salau Ayodeji Olalekan, 2019, 2019 International Conference on Signal Processing and Communication (ICSC), P158
   Satalino G, 2012, INT GEOSCI REMOTE SE, P5701, DOI 10.1109/IGARSS.2012.6352317
   Xie HT, 2015, SCI REP-UK, V5, DOI 10.1038/srep10930
   Zebire Degife Asefa, 2019, Journal of Ecology and Environment, V43, P15, DOI 10.1186/s41610-019-0104-9
NR 15
TC 1
Z9 1
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 19
PY 2023
DI 10.1007/s11042-023-15692-4
EA MAY 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G6US0
UT WOS:000990491400002
DA 2024-07-18
ER

PT J
AU Eltokhy, MAR
   Abdel-Hady, M
   Haggag, A
   El-Bendary, MAM
   Ali, H
   Hosny, T
AF Eltokhy, Mostafa A. R.
   Abdel-Hady, Mohamed
   Haggag, Ayman
   El-Bendary, Mohsen A. M.
   Ali, Hisham
   Hosny, Tarek
TI Audio SIMO system based on visible light communication using cavity LEDs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optical Wireless Communication (OWC); Visible Light Communication (VLC);
   Li-Fi; Data communication; Audio signals transfer; Light Emitting Diode
   (LED)
AB The necessity for access to a high data rate has been the motivation behind expanding new technologies. The increasing of wireless devices has caused the radio wave spectrum to become congested. Additionally, radio waves cannot be used in EMI-vulnerable places. Hence, the interest in visible light communication (VLC) offers real alternatives to radio-based communications. This paper focuses on the use of visible light as a data communication medium and introduces a designed audio SIMO (Single-Input-Multi-Output) data transmission system from point to multipoint to demonstrate the functionality of the VLC system in audio transmission through modulated LEDs light. The system is made up of the transmitting unit and multi-receiving units. The transmitting unit consists of three stages: audio in, preamplifier, and white LEDs array that transmits the data using the ON-OFF keying (OOK) modulation technique to all receivers. On the other hand, the receiving unit consists of three receivers that have different photodetectors aspects with fixed distances separation between them. The line of sight (LOS) communication between transmitter and receivers for the purpose to transfer audio data has been employed. Based on the LOS link, simulation and experimental analysis have been done in multiple semi-angles for studying the output performance of receivers and the characteristics of the white LEDs such as luminous intensity and received power at 20,45 and 70 semi-angle at half-power through MATLAB (R) software.
C1 [Eltokhy, Mostafa A. R.; Abdel-Hady, Mohamed; Haggag, Ayman; El-Bendary, Mohsen A. M.; Ali, Hisham] Helwan Univ, Fac Technol & Educ, Elect Technol Dept, Cairo, Egypt.
   [Hosny, Tarek] High Minist Educ, Commun Engn Dept, Al Safwa High Inst Engn, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Helwan University; Ministry of Education
   & Technical Education - Egypt
RP Eltokhy, MAR (corresponding author), Helwan Univ, Fac Technol & Educ, Elect Technol Dept, Cairo, Egypt.
EM mostafaeltokhy2717@yahoo.com
RI Abdel-Hady, Mohamed/IQW-2637-2023
OI Abdel-Hady, Mohamed/0009-0003-8266-6059; A. Hamad,
   Hisham/0000-0002-0784-7859
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB). The authors did not receive support from any organization for the
   submitted work
CR Al Hwaitat AK., 2020, INT J ADV TRENDS COM, V9, P225, DOI DOI 10.30534/IJATCSE/2020/34912020
   Baklanov A, 2019, IEEE INT SIBER CONF, DOI 10.1109/sibcon.2019.8729564
   Bin Taufik JT., 2019, INT J SCI RES PUB IJ, V9, P432, DOI [10.29322/ijsrp.9.01.2019.p8556, DOI 10.29322/IJSRP.9.01.2019.P8556]
   Chaurasia Akshit, 2020, Journal of Physics: Conference Series, V1706, DOI 10.1088/1742-6596/1706/1/012067
   Eltokhy MAR., 2020, GRAPH VIS IMAG PROC, V20, P45
   Gismalla MSM., 2019, J COMMUN, V14, P64, DOI [10.12720/jcm.14.1.64-69, DOI 10.12720/JCM.14.1.64-69]
   Grigoryev E.A., 2020, INT CONF SEMINAR, P221, DOI [10.1109/EDM49804.2020.9153488, DOI 10.1109/edm49804.2020.9153488]
   Grigoryeva S, 2021, ACTA POLYTECH HUNG, V18, P7
   Ibhaze Augustus Ehiremen, 2020, Journal of Electronic Science and Technology, P1, DOI 10.1016/j.jnlest.2020.100055
   Ismail S.N., 2020, AIP Conf. Proc., V2213, DOI [10.1063/5.0000109, DOI 10.1063/5.0000109]
   Li W., 2021, SID S DIG TECH PAP, V52, P621, DOI [10.1002/sdtp.14574, DOI 10.1002/SDTP.14574]
   Mapunda GA, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8881305
   Mohanna M., 2018, INT J ENG RESCOMPUT, V5, P76
   Mongwewarona W., 2020, PR IEEE COMP DESIGN, V8, P1, DOI [10.30918/AJER.81.19.036, DOI 10.30918/AJER.81.19.036]
   Ndjiongue AR, 2020, IEEE NETWORK, V34, P158, DOI 10.1109/MNET.001.1900428
   Orike S., 2020, J ELECT ENG ELECT CO, V6, P15
   Qasim AA, 2020, 2 INT C INF SCI COMM, P1, DOI [10.1109/ICISCT49550.2020.9079946, DOI 10.1109/ICISCT49550.2020.9079946]
   Siddique I.A., 2019, International Journal of Scientific Research in Computer Science, Engineering and Information Technology, P30, DOI DOI 10.32628/CSEIT1838108
NR 18
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46371
EP 46385
DI 10.1007/s11042-023-15680-8
EA MAY 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000985244300004
OA hybrid
DA 2024-07-18
ER

PT J
AU Pang, L
   Zhou, JC
   Zhang, WS
AF Pang, Lei
   Zhou, Jingchun
   Zhang, Weishi
TI Underwater image enhancement via variable contrast and saturation
   enhancement model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater images; White balance; Variational model; Contrast
   enhancement; Local contrast correction
ID COLOR CORRECTION; QUALITY; LIGHT
AB Since underwater optical imaging is affected by underwater light absorption and attenuation, the pixels of images distribute unevenly, and image structures are damaged to different degrees, leading to problems such as color distortion, low contrast, and blurred details. A single-color correction method cannot improve the contrast and details of images, and a single contrast enhancement method will cause image color distortion and local contrast over-enhanced and weak-enhanced. To deal with the problems simultaneously, this paper proposes an underwater image enhancement method based on variable contrast and saturation enhancement model and local contrast correction. Firstly, we design a white balance method based on pixel transformation to adjust the pixel distribution and further work out color distortion; Moreover, a variable contrast and saturation enhancement model is designed to recover the image structure and statistical characteristics effectively and further promote global contrast; Ultimately, contrast limited histogram equalization is adopted to perform local contrast correction, and then solve the over-enhanced and weak-enhanced. The enhancement results based on the synthetic and real underwater image data sets show that the proposed method is superior to some advanced qualitative and quantitative evaluation methods and effectively elevates visual effects.
C1 [Pang, Lei; Zhou, Jingchun; Zhang, Weishi] Dalian Maritime Univ, Coll Informat Sci & Technol, Dalian 116026, Peoples R China.
   [Zhou, Jingchun] No Arizona Univ, Coll Comp Informat Technol, Flagstaff, AZ 86001 USA.
C3 Dalian Maritime University; Northern Arizona University
RP Zhou, JC (corresponding author), Dalian Maritime Univ, Coll Informat Sci & Technol, Dalian 116026, Peoples R China.; Zhou, JC (corresponding author), No Arizona Univ, Coll Comp Informat Technol, Flagstaff, AZ 86001 USA.
EM zhoujingchun@dlmu.edu.cn; teesiv@dlmu.edu.cn
RI Zhou, Jingchun/AAF-6817-2019
OI Zhou, Jingchun/0000-0002-4111-6240
FU National Natural Science Foundation of China [61702074]; Liaoning
   Provincial Natural Science Foundation of China [20170520196];
   Fundamental Research Funds for the Central Universities [3132019205,
   3132019354]
FX National Natural Science Foundation of China (No. 61702074); the
   Liaoning Provincial Natural Science Foundation of China (No.
   20170520196); the Fundamental Research Funds for the Central
   Universities (Nos.3132019205 and 3132019354).
CR Al Sobbahi R, 2022, SIGNAL PROCESS-IMAGE, V100, DOI 10.1016/j.image.2021.116527
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Anwar S, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115978
   Bertalmío M, 2007, IEEE T IMAGE PROCESS, V16, P1058, DOI 10.1109/TIP.2007.891777
   Cao KM, 2018, IEEE SW SYMP IMAG, P1, DOI 10.1109/SSIAI.2018.8470347
   DING X, 2017, OCEANS-IEEE, P1, DOI DOI 10.1109/OCEANSE.2017.8084665
   Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113
   Fabbri C, 2018, IEEE INT CONF ROBOT, P7159
   Fu XY, 2014, IEEE IMAGE PROC, P4572, DOI 10.1109/ICIP.2014.7025927
   Ghani ASA, 2015, APPL SOFT COMPUT, V37, P332, DOI 10.1016/j.asoc.2015.08.033
   Guo YC, 2020, IEEE J OCEANIC ENG, V45, P862, DOI 10.1109/JOE.2019.2911447
   Han M, 2020, IEEE T SYST MAN CY-S, V50, P1820, DOI 10.1109/TSMC.2017.2788902
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hou MJ, 2018, IEEE IMAGE PROC, P4043, DOI 10.1109/ICIP.2018.8451209
   Huang DM, 2018, LECT NOTES COMPUT SC, V10704, P453, DOI 10.1007/978-3-319-73603-7_37
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Khan A, 2016, 2016 IEEE 6TH INTERNATIONAL CONFERENCE ON UNDERWATER SYSTEM TECHNOLOGY: THEORY AND APPLICATIONS, P83, DOI 10.1109/USYS.2016.7893927
   Lee HS, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12081220
   Li CY, 2021, IEEE T IMAGE PROCESS, V30, P4985, DOI 10.1109/TIP.2021.3076367
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li CY, 2018, IEEE SIGNAL PROC LET, V25, P323, DOI 10.1109/LSP.2018.2792050
   Li HY, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116248
   Li TY, 2022, OPT EXPRESS, V30, P6216, DOI 10.1364/OE.449930
   Li XJ, 2020, IEEE ACCESS, V8, P197448, DOI 10.1109/ACCESS.2020.3034275
   Liu RS, 2020, IEEE T CIRC SYST VID, V30, P4861, DOI 10.1109/TCSVT.2019.2963772
   Liu RW, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1433, DOI 10.1109/ICASSP.2018.8462394
   Liu X, 2017, COMPUT VIS IMAGE UND, V162, P23, DOI 10.1016/j.cviu.2017.08.002
   Panetta K, 2018, IEEE ACCESS, V6, P10979, DOI 10.1109/ACCESS.2018.2804901
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Prabhakar C. J., 2010, 2010 International Conference on Signal and Image Processing (ICSIP 2010), P322, DOI 10.1109/ICSIP.2010.5697491
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Song W, 2018, LECT NOTES COMPUT SC, V11164, P678, DOI 10.1007/978-3-030-00776-8_62
   Wang SQ, 2015, IEEE SIGNAL PROC LET, V22, P2387, DOI 10.1109/LSP.2015.2487369
   Wang Y, 2017, IEEE IMAGE PROC, P1382, DOI 10.1109/ICIP.2017.8296508
   Wang Z, 2018, IET COMPUT VIS, V12, P393, DOI 10.1049/iet-cvi.2017.0318
   Weng CC, 2005, IEEE INT SYMP CIRC S, P3801
   Xu Y, 2016, IEEE ACCESS, V4, P165, DOI 10.1109/ACCESS.2015.2511558
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Zhou JC, 2020, FRONT INFORM TECH EL, V21, P1745, DOI 10.1631/FITEE.2000190
   Zhou JC, 2023, APPL INTELL, V53, P3594, DOI 10.1007/s10489-022-03767-y
   Zhou JC, 2022, ENG APPL ARTIF INTEL, V111, DOI 10.1016/j.engappai.2022.104785
   Zhou JC, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3170702
   Zhou JC, 2022, APPL INTELL, V52, P16435, DOI 10.1007/s10489-022-03275-z
   Zhou JC, 2021, MEAS SCI TECHNOL, V32, DOI 10.1088/1361-6501/ac16ef
   Zhou JC, 2021, MULTIMED TOOLS APPL, V80, P17515, DOI 10.1007/s11042-020-10273-1
   Zhuang PX, 2022, IEEE T IMAGE PROCESS, V31, P5442, DOI 10.1109/TIP.2022.3196546
   Zhuang PX, 2021, ENG APPL ARTIF INTEL, V101, DOI 10.1016/j.engappai.2021.104171
NR 49
TC 2
Z9 2
U1 10
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47495
EP 47516
DI 10.1007/s11042-023-15419-5
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000982729800003
DA 2024-07-18
ER

PT J
AU Belagur, H
   Reddy, NS
   Krishna, PR
   Tumuluri, R
AF Belagur, Harshith
   Reddy, N. Saketh
   Krishna, P. Radha
   Tumuluri, Raj
TI Cross-modal multi-headed attention for long multimodal conversations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Conversational AI; Multimodality; Natural Language Processing; Computer
   Vision; Deep Learning; Fashion Domain
AB Most Conversational AI agents in today's marketplace are unimodal in which only text is exchanged between the user and the bot. However, employing additional modes (e.g., image) in the interaction improves customer experience, potentially increasing efficiency and profits in applications such as online shopping. Most of the existing techniques have used feature extraction from the multimodal inputs, but very few works used multi-headed attention from transformers conversational AI. In this work, we propose a novel architecture called Cross-modal Multi-headed Hierarchical Encoder-Decoder with Sentence Embeddings (CMHRED-SE) to enhance the quality of natural language response by better understanding features such as color, sentence structure, and continuity of the conversation. CMHRED-SE uses multi-headed attention and image representations from VGGNet19 and ResNet50 architectures to improve the effectiveness in fashion domain-specific conversations. The results of CMHRED-SE are compared with two other similar models, namely M-HRED and MHRED-attn, and the quality of answers returned by the models are evaluated using BLEU-4, ROUGE-L, and the Cosine scores. The evaluation results show an improvement of 5% for Cosine similarity, 9% for ROUGE-L F1 score, and 11% for the BLEU-4 score over the scores returned by the baseline models. The results also show that our approach better understands and generates clearer textual responses leveraging the sentence embeddings.
C1 [Belagur, Harshith; Reddy, N. Saketh; Krishna, P. Radha] Natl Inst Technol Warangal, Dept Comp Sci & Engn, Warangal, India.
   [Tumuluri, Raj] Openstream Inc, Somerset, NJ USA.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Warangal
RP Krishna, PR (corresponding author), Natl Inst Technol Warangal, Dept Comp Sci & Engn, Warangal, India.
EM hbelagur@student.nitw.ac.in; nsaketh@student.nitw.ac.in;
   prkrishna@nitw.ac.in; raj@openstream.ai
CR Agarwal Shubham, 2018, P 11 INT C NAT LANG, P129
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Bell S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766959
   Bojanowski P., 2016, VALENCIA SPAIN ACL, V2, P427
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Chauhan H, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5437
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen W, 2021, NEUROCOMPUTING, V426, P195, DOI 10.1016/j.neucom.2020.10.042
   Cho K., 2019, 2019 C EMP METH NAT
   Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121
   de Vries H, 2017, PROC CVPR IEEE, P4466, DOI 10.1109/CVPR.2017.475
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Fatigante M, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.664747
   Griol D, 2014, ADCAIJ-ADV DISTRIB C, V3, P13, DOI 10.14201/ADCAIJ2014381326
   Han XT, 2017, IEEE I CONF COMP VIS, P1472, DOI 10.1109/ICCV.2017.163
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hsiao JH, 2014, IEEE IMAGE PROC, P3038, DOI 10.1109/ICIP.2014.7025614
   Jiang Shaojie, 2018, P 2018 EMNLP WORKSH, P81
   Kerly A, 2007, KNOWL-BASED SYST, V20, P177, DOI 10.1016/j.knosys.2006.11.014
   Kingma D. P., 2014, arXiv
   Laenen K, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P342, DOI 10.1145/3159652.3159716
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Mostafazadeh N., 2017, P 8 INT JOINT C NAT
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Paranjape A, 2020, ARXIV
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Rajpurkar P., 2016, P 2016 C EMP METH NA, V2016, P2383
   Roccetti Marco, 2017, JMIR Public Health Surveill, V3, pe51, DOI 10.2196/publichealth.7004
   Saha A, 2018, AAAI CONF ARTIF INTE, P696
   Sapna, 2019, PROCEEDINGS OF THE 6TH ACM IKDD CODS AND 24TH COMAD, P256, DOI 10.1145/3297001.3297035
   Schaack S, 2019, PROCEEDINGS OF THE 10TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE 2019 (AH2019), DOI 10.1145/3311823.3311840
   Serban IV, 2017, AAAI CONF ARTIF INTE, P3295
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tao CY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4418
   Thomas NT, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2740, DOI 10.1109/ICACCI.2016.7732476
   Vaswani A, 2017, ADV NEUR IN, V30
   Xu AB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3506, DOI 10.1145/3025453.3025496
   Zhao B, 2017, PROC CVPR IEEE, P6156, DOI 10.1109/CVPR.2017.652
   Zoghbi Susana, 2016, International Journal of Computer and Electrical Engineering, V8, P31, DOI 10.17706/ijcee.2016.8.1.31-43
NR 39
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45679
EP 45697
DI 10.1007/s11042-023-15606-4
EA MAY 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000983013200001
DA 2024-07-18
ER

PT J
AU Sheikh, BU
   Zafar, A
AF Sheikh, Burhan Ul haque
   Zafar, Aasim
TI Untargeted white-box adversarial attack to break into deep leaning based
   COVID-19 monitoring face mask detection system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE COVID-19; Adversarial example; Face mask recognition; Adversarial
   attacks; Deep learning; Robustness
ID RECOGNITION
AB The face mask detection system has been a valuable tool to combat COVID-19 by preventing its rapid transmission. This article demonstrated that the present deep learning-based face mask detection systems are vulnerable to adversarial attacks. We proposed a framework for a robust face mask detection system that is resistant to adversarial attacks. We first developed a face mask detection system by fine-tuning the MobileNetv2 model and training it on the custom-built dataset. The model performed exceptionally well, achieving 95.83% of accuracy on test data. Then, the model's performance is assessed using adversarial images calculated by the fast gradient sign method (FGSM). The FGSM attack reduced the model's classification accuracy from 95.83% to 14.53%, indicating that the adversarial attack on the proposed model severely damaged its performance. Finally, we illustrated that the proposed robust framework enhanced the model's resistance to adversarial attacks. Although there was a notable drop in the accuracy of the robust model on unseen clean data from 95.83% to 92.79%, the model performed exceptionally well, improving the accuracy from 14.53% to 92% on adversarial data. We expect our research to heighten awareness of adversarial attacks on COVID-19 monitoring systems and inspire others to protect healthcare systems from similar attacks.
C1 [Sheikh, Burhan Ul haque; Zafar, Aasim] Aligarh Muslim Univ, Dept Comp Sci, Aligarh 202002, Uttar Pradesh, India.
C3 Aligarh Muslim University
RP Sheikh, BU (corresponding author), Aligarh Muslim Univ, Dept Comp Sci, Aligarh 202002, Uttar Pradesh, India.
EM sbuhaque@myamu.ac.in; azafar.cs@amu.ac.in
RI Zafar, Aasim/J-2471-2013
OI Zafar, Aasim/0000-0003-1331-014X; Sheikh, Burhan Ul
   Haque/0000-0003-3306-5671
CR Agarwal Charu, 2023, Artificial Intelligence on Medical Data: Proceedings of International Symposium, ISCMM 2021. Lecture Notes in Computational Vision and Biomechanics (37), P419, DOI 10.1007/978-981-19-0151-5_35
   [Anonymous], 2021, LARX FAC MASK DET DA
   Brown TB, 2018, Arxiv, DOI arXiv:1809.08352
   Bu W, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEMS (CIS) AND IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS (RAM), P458, DOI 10.1109/ICCIS.2017.8274819
   C, 2022, CHANDR FAC MASK DET
   Chae S, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15081596
   Chen XY, 2017, Arxiv, DOI arXiv:1712.05526
   Co KT, 2019, PROCEEDINGS OF THE 2019 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'19), P275, DOI 10.1145/3319535.3345660
   Deng J, 2021 IEEE INT C COMP, P4342
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ejaz M.S., 2019, 2019 1 INT C ADV SCI, P1
   Ellis R, 2020, WHO Changes stance says public should wear masks
   Fei JW, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-0490-z
   Ganin Y, 2017, ADV COMPUT VIS PATT, P189, DOI 10.1007/978-3-319-58347-1_10
   Ge S., 2017, IEEE C COMPUT VIS PA, P2682, DOI DOI 10.1109/CVPR.2017.53
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hirano H, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0243963
   Huang BJ, 2023, IEEE T NEUR NET LEAR, V34, P10875, DOI 10.1109/TNNLS.2022.3171604
   Huang BJ, 2021, IEEE INT CONF COMP V, P1487, DOI 10.1109/ICCVW54120.2021.00172
   Huang G.B., 2008, PROC WORKSHOP FACES
   Hussain S.A., 2020, J. Phys.: Conf. Series, V1432, DOI DOI 10.1088/1742-6596/1432/1/012087
   Inamdar M., 2020, SSRN Electronic Journal, DOI DOI 10.2139/SSRN.3663305
   Goodfellow IJ, 2015, Arxiv, DOI [arXiv:1412.6572, DOI 10.48550/ARXIV.1412.6572]
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jain V., 2010, UMass Amherst technical report, V2
   Jamshidi MB, 2020, IEEE ACCESS, V8, P109581, DOI 10.1109/ACCESS.2020.3001973
   Ji YJ, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P349, DOI 10.1145/3243734.3243757
   Jignesh Chowdary G., 2020, Big Data Analytics. 8th International Conference, BDA 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12581), P81, DOI 10.1007/978-3-030-66665-1_6
   Kakizaki K, 2020, Arxiv, DOI arXiv:1905.03421
   Khosravy M, 2021, KSII T INTERNET INF, V15, P1100, DOI 10.3837/tiis.2021.03.015
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kurakin A., 2018, ARTIF INTELL, P99
   Li C, 2019, COMMUNICATION DEVICE, P277, DOI [10.1007/978-981-13-9406-5_34, DOI 10.1007/978-981-13-9406-5_34]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Loey M, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102600
   Loey M, 2021, MEASUREMENT, V167, DOI 10.1016/j.measurement.2020.108288
   Lu JJ, 2017, IEEE I CONF COMP VIS, P446, DOI 10.1109/ICCV.2017.56
   Mijwil MM, 2021, Iraqi J. Sci., P2099, DOI 10.24996/ijs.2021.62.6.35
   Militante SV, 2020, 2020 11TH IEEE CONTROL AND SYSTEM GRADUATE RESEARCH COLLOQUIUM (ICSGRC), P106, DOI [10.1109/icsgrc49013.2020.9232610, 10.1109/ICSGRC49013.2020.9232610]
   Moosavi-Dezfooli SM, 2017, PROC CVPR IEEE, P86, DOI 10.1109/CVPR.2017.17
   Nagrath P, 2021, SUSTAIN CITIES SOC, V66, DOI 10.1016/j.scs.2020.102692
   Nieto-Rodríguez A, 2015, LECT NOTES COMPUT SC, V9117, P138, DOI 10.1007/978-3-319-19390-8_16
   Pal B, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11094233
   Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Qin BS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185236
   Rahman MA, 2021, IEEE INTERNET THINGS, V8, P9603, DOI 10.1109/JIOT.2020.3013710
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren K, 2020, ENGINEERING-PRC, V6, P346, DOI 10.1016/j.eng.2019.12.012
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sheikh Burhan Ul Haque, 2023, SN Comput Sci, V4, P288, DOI 10.1007/s42979-023-01738-9
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   Wang YQ, 2014, IMAGE PROCESS ON LIN, V4, P128, DOI 10.5201/ipol.2014.104
   World Health Organization, 2020, ADV US MASKS CONT CO
   Xie W, 2021, 2021 IEEE INT C COMP, P8828
   Yang S, 2016, PROC CVPR IEEE, P5525, DOI 10.1109/CVPR.2016.596
   Ye QW, 2013, J COMPUT THEOR NANOS, V10, P2872, DOI 10.1166/jctn.2013.3293
NR 62
TC 9
Z9 9
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 5
PY 2023
DI 10.1007/s11042-023-15405-x
EA MAY 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F5VE6
UT WOS:000983013200008
PM 37362697
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Cao, C
   Song, J
   Su, R
   Wu, XW
   Wang, Z
   Hou, MZ
AF Cao, Cong
   Song, Jian
   Su, Ri
   Wu, Xuewen
   Wang, Zheng
   Hou, Muzhou
TI Structure-constrained deep feature fusion for chronic otitis media and
   cholesteatoma identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Structure-constrained deep feature fusion; Middle ear structure;
   Computed tomography; Chronic suppurative otitis media; Cholesteatoma and
   normal (CSOMCN)
ID MIDDLE-EAR CHOLESTEATOMA; SENSORINEURAL HEARING-LOSS; TYMPANIC MEMBRANE;
   NETWORK; CLASSIFICATION; METAANALYSIS; MANAGEMENT; DEAFNESS
AB Chronic suppurative otitis media (CSOM) and middle ear cholesteatoma (MEC) were two most common chronic middle ear disease(MED) clinically. Accurate differential diagnosis between these two diseases is of high clinical importance given the difference in etiologies, lesion manifestations and treatments. The high-resolution computed tomography (CT) scanning of the temporal bone presents a better view of auditory structures, which is currently regarded as the first-line diagnostic imaging modality in the case of MED. In this paper, we first used a region-of-interest (ROI) network to find the area of the middle ear in the entire temporal bone CT image and segment it to a size of 100*100 pixels. Then, we used a structure-constrained deep feature fusion algorithm to convert different characteristic features of the middle ear in three groups as suppurative otitis media (CSOM), middle ear cholesteatoma (MEC) and normal patches. To fuse structure information, we introduced a graph isomorphism network that implements a feature vector from neighbourhoods and the coordinate distance between vertices. Finally, we construct a classifier named the "otitis media, cholesteatoma and normal identification classifier" (OMCNIC). The experimental results achieved by the graph isomorphism network revealed a 96.36% accuracy in all CSOM and MEC classifications. The experimental results indicate that our structure-constrained deep feature fusion algorithm can quickly and effectively classify CSOM and MEC. It will help otologist in the selection of the most appropriate treatment, and the complications can also be reduced.
C1 [Cao, Cong; Su, Ri; Hou, Muzhou] Cent South Univ, Sch Math & Stat, Changsha 410083, Peoples R China.
   [Song, Jian; Wu, Xuewen] Cent South Univ, Dept Otorhinolaryngol, Xiangya Hosp, Changsha 410008, Peoples R China.
   [Song, Jian; Wu, Xuewen] Key Lab Otolaryngol Major Dis Res Hunan Prov, Changsha 410008, Peoples R China.
   [Song, Jian; Wu, Xuewen] Cent South Univ, Xiangya Hosp, Natl Clin Res Ctr Geriatr Disorders, Dept Geriatr, Changsha 410008, Peoples R China.
   [Wang, Zheng] Hunan First Normal Univ, Sch Comp Sci, Changsha 410205, Peoples R China.
C3 Central South University; Central South University; Central South
   University; Hunan First Normal University
RP Hou, MZ (corresponding author), Cent South Univ, Sch Math & Stat, Changsha 410083, Peoples R China.; Wang, Z (corresponding author), Hunan First Normal Univ, Sch Comp Sci, Changsha 410205, Peoples R China.
EM w8614@hotmail.com; houmuzhou@sina.com
RI Cao, Cong/GSD-8213-2022; , houmuzhou/N-2357-2019; wu,
   xuewen/A-7449-2017; Wang, Zheng/GXA-0956-2022
OI Cao, Cong/0000-0002-6853-6421; , houmuzhou/0000-0001-6658-2187; wu,
   xuewen/0000-0002-2607-8717; Wang, Zheng/0000-0002-1343-5199
FU Hunan Province Natural Science Foundation [2021JJ41017]; Teaching Reform
   Research Project of Universities in Hunan Province; Hunan Provincial
   Natural Science Foundation of China [2022GK3003]; Foundation of
   Department of Science and Technology of Hunan Province [2020GJZ18];
   Foundation of Changsha Intellectual Property Office [2018234-201835];
   Foundation of Department of Transportation of Hunan Province
   [HNJG-2021-1120];  [2022JJ30189]
FX This work was supported by the Hunan Province Natural Science Foundation
   (grant number 2022JJ30673), the Teaching Reform Research Project of
   Universities in Hunan Province (under grant HNJG-2021-1120)the Hunan
   Provincial Natural Science Foundation of China (under grant
   2022JJ30189), the Hunan Province Natural Science Foundation (Grant No.
   2021JJ41017), Foundation of Department of Science and Technology of
   Hunan Province (grant number 2022GK3003), Foundation of Changsha
   Intellectual Property Office (grant number 2020GJZ18), Foundation of
   Department of Transportation of Hunan Province (grant number
   2018234-201835).
CR Aggarwal AK, 2020, UNMANNED AERIAL VEHICLE: APPLICATIONS IN AGRICULTURE AND ENVIRONMENT, P159, DOI 10.1007/978-3-030-27157-2_12
   Ars B., 1994, Acta Oto-Rhino-Laryngologica Belgica, V48, P339
   Babai L., 1979, 20th Annual Symposium of Foundations of Computer Science, P39, DOI 10.1109/SFCS.1979.8
   Castle JT, 2018, HEAD NECK PATHOL, V12, P419, DOI 10.1007/s12105-018-0915-5
   Cha D, 2019, EBIOMEDICINE, V45, P606, DOI 10.1016/j.ebiom.2019.06.050
   Ciano G, 2022, IEEE T PATTERN ANAL, V44, P758, DOI 10.1109/TPAMI.2021.3054304
   Colozza P, 2009, SAO PAULO MED J, V127, P61, DOI 10.1590/S1516-31802009000200002
   Cömert Z, 2020, BIOCYBERN BIOMED ENG, V40, P40, DOI 10.1016/j.bbe.2019.11.001
   Cunningham LL, 2017, NEW ENGL J MED, V377, P2465, DOI 10.1056/NEJMra1616601
   Garg M, 2023, MULTIMED TOOLS APPL, V82, P6271, DOI 10.1007/s11042-022-13596-3
   Gers FA, 2003, J MACH LEARN RES, V3, P115, DOI 10.1162/153244303768966139
   Gilberto N, 2020, EUR ARCH OTO-RHINO-L, V277, P987, DOI 10.1007/s00405-020-05792-4
   Gioacchini FM, 2018, AURIS NASUS LARYNX, V45, P903, DOI 10.1016/j.anl.2018.03.006
   Habib AR, 2020, J LARYNGOL OTOL, V134, P311, DOI 10.1017/S0022215120000717
   Jiang XD, 2023, IEEE T PATTERN ANAL, V45, P7075, DOI 10.1109/TPAMI.2020.3029762
   Joulin Armand, 2017, P ICML, P1302
   Kaspar A, 2018, INT J PEDIATR OTORHI, V111, P21, DOI 10.1016/j.ijporl.2018.05.021
   Keeler JA, 2016, LARYNGOSCOPE, V126, P1499, DOI 10.1002/lary.25385
   Khan MA, 2020, NEURAL NETWORKS, V126, P384, DOI 10.1016/j.neunet.2020.03.023
   Kingma D. P., 2014, arXiv
   Kipf TN, 2016, ARXIV
   Lieberthal AS, 2004, PEDIATRICS, V113, P1451, DOI 10.1542/peds.113.5.1451
   Lingam RK, 2017, OTOL NEUROTOL, V38, P521, DOI 10.1097/MAO.0000000000001353
   Liu WY, 2016, PR MACH LEARN RES, V48
   Luers JC, 2016, J ANAT, V228, P338, DOI 10.1111/joa.12389
   Majithia A, 2012, CLIN OTOLARYNGOL, V37, P325, DOI 10.1111/j.1749-4486.2012.02502.x
   Marom T, 2019, OTOLARYNG HEAD NECK, V160, P447, DOI 10.1177/0194599818809337
   Mason MJ, 2016, J ANAT, V228, P300, DOI 10.1111/joa.12316
   MCCABE BF, 1979, ANN OTO RHINOL LARYN, V88, P585, DOI 10.1177/000348947908800501
   Mittal R, 2015, J MED MICROBIOL, V64, P1103, DOI 10.1099/jmm.0.000155
   Morita Y, 2019, AURIS NASUS LARYNX, V46, P346, DOI 10.1016/j.anl.2018.10.015
   Mustafa A, 2008, EUR ARCH OTO-RHINO-L, V265, P1477, DOI 10.1007/s00405-008-0707-8
   Nielsen M. A., 2015, NEURAL NETWORKS DEEP, DOI DOI 10.1145/2939672.2945397
   Park M, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0125905
   Parvaze PS, 2023, NMR BIOMED, V36, DOI 10.1002/nbm.4884
   Parvaze S, 2023, EUR J RADIOL, V159, DOI 10.1016/j.ejrad.2022.110655
   Peng YZ, 2020, IEEE ACCESS, V8, P168344, DOI 10.1109/ACCESS.2020.3022850
   Prasad SC, 2014, ACTA OTORHINOLARYNGO, V34, P354
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rosito LS, 2016, JAMA OTOLARYNGOL, V142, P168, DOI 10.1001/jamaoto.2015.3148
   Shah-Becker S, 2018, INT J PEDIATR OTORHI, V113, P19, DOI 10.1016/j.ijporl.2018.06.036
   Shew M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-40192-7
   Siddique N, 2021, IEEE ACCESS, V9, P82031, DOI 10.1109/ACCESS.2021.3086020
   Srivastava A, 2018, Handbook of Research on Advanced Concepts in Real-time Image and Video Processing, P281, DOI 10.4018/978-1-5225-2848-7.ch011
   Tatlipinar A, 2012, EUR ARCH OTO-RHINO-L, V269, P33, DOI 10.1007/s00405-011-1577-z
   Ubhi JS, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103483
   VELDMAN JE, 1993, ACTA OTO-LARYNGOL, V113, P303, DOI 10.3109/00016489309135813
   Velickovic Petar, 2018, INT C LEARN REPR
   Wang P, 2017, INTERDISCIP SCI, V9, P419, DOI 10.1007/s12539-016-0196-1
   Wang SH, 2021, INFORM FUSION, V67, P208, DOI 10.1016/j.inffus.2020.10.004
   Wang WQ, 2004, ACTA OTO-LARYNGOL, V124, P1141, DOI 10.1080/00016480410022921
   Wang YM, 2020, EAR HEARING, V41, P669, DOI 10.1097/AUD.0000000000000794
   Wang Z, 2022, EXPERT SYST APPL, V194, DOI 10.1016/j.eswa.2022.116519
   Wang Z, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107613
   Wang Z, 2020, ANN BIOMED ENG, V48, P312, DOI 10.1007/s10439-019-02349-3
   Weisfeiler B., 1968, Nauchno-Technicheskaya Informatsiya, V2, P12
   Wisotzky EL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185334
   Xu K, 2019, IEEE VTS VEH TECHNOL, DOI [10.1109/vtcfall.2019.8891597, 10.1109/biocas.2019.8918711]
NR 58
TC 0
Z9 0
U1 7
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45869
EP 45889
DI 10.1007/s11042-023-15425-7
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000981387900013
PM 37362730
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Zha, WT
   Hu, LW
   Sun, YL
   Li, YL
AF Zha, Wenting
   Hu, Longwei
   Sun, Yalu
   Li, Yalong
TI ENGD-BiFPN: a remote sensing object detection model based on grouped
   deformable convolution for power transmission towers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Satellite remote sensing image; Transmission tower detection; Grouped
   deformable convolution; Lightweight network; Deep learning
AB The object detection of transmission towers is of great significance for transmission and transformation channel monitoring, engineering evaluation, operation and maintenance management. This paper aims to detect different types of transmission towers in satellite remote sensing images according to the characteristics of transmission tower shadow. However, different shooting angles lead to great changes in the shape of the tower shadow. At the same time, the shadows of different types of towers may be very similar. In order to further improve the accuracy of object detection, we first conduct the image preprocessing and image enhancement. Then, the deformable convolution is introduced to better extract the features of transmission tower shadow. At the same time, in order to neutralize the influence of the increase of model parameters caused by deformable convolution, this paper introduces the idea of grouped convolution and proposes a modified bi-directional feature pyramid network (GD-BiFPN) based on the grouped deformable convolution (GDConv). Finally, a lightweight satellite remote sensing object detection model for transmission towers with accuracy up to 96% is implemented with EfficientNet as the backbone and GD-BiFPN as the enhanced feature extraction network. Through ablation and comparison experiments, the effectiveness and advancement of the proposed model in transmission tower remote sensing object detection are verified.
C1 [Zha, Wenting; Hu, Longwei; Li, Yalong] China Univ Min & Technol Beijing, Sch Mech Elect & Informat Engn, Beijing 100083, Peoples R China.
   [Sun, Yalu] State Grid Gansu Econ Res Inst, Lanzhou 730050, Peoples R China.
C3 China University of Mining & Technology
RP Zha, WT (corresponding author), China Univ Min & Technol Beijing, Sch Mech Elect & Informat Engn, Beijing 100083, Peoples R China.
EM zhawenting619@gmail.com
FU National Natural Science Foundation (NNSF) of China [61703405]; Yue Qi
   Young Scholar Project of China University of Mining and Technology
   (Beijing)
FX This work is supported by National Natural Science Foundation (NNSF) of
   China under Grant 61703405 and the Yue Qi Young Scholar Project of China
   University of Mining and Technology (Beijing).
CR Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Cetin B, 2009, PROCEEDINGS OF THE IEEE SOUTHEASTCON 2009, TECHNICAL PROCEEDINGS, P44
   Chen JY, 2022, MULTIMED TOOLS APPL, V81, P12093, DOI 10.1007/s11042-021-10833-z
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dai Jifeng, 2016, Advances in Neural Information Processing Systems, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075
   Dutta T, 2015, LECT NOTES COMPUT SC
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gu K, 2016, IEEE T CYBERNETICS, V46, P284, DOI 10.1109/TCYB.2015.2401732
   Gu K, 2015, IEEE T CIRC SYST VID, V25, P1480, DOI 10.1109/TCSVT.2014.2372392
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Jin J, 2015, 3 INT C LEARNING REP
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lei Xie, 2014, 2014 Third International Workshop on Earth Observation and Remote Sensing Applications Proceedings of (EORSA), P353, DOI 10.1109/EORSA.2014.6927911
   Li K, 2020, ISPRS J PHOTOGRAMM, V159, P296, DOI 10.1016/j.isprsjprs.2019.11.023
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Lin YD, 2017, MULTIMED TOOLS APPL, V76, P14461, DOI 10.1007/s11042-016-3857-5
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Pang YW, 2018, IEEE T NEUR NET LEAR, V29, P1587, DOI 10.1109/TNNLS.2017.2676130
   Paszke A, 2019, ADV NEUR IN, V32
   Qiao SJ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12111857
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tian G, 2020, Journal of physics: conference series
   Tragulnuch P, 2018, 2018 INTERNATIONAL CONFERENCE ON EMBEDDED SYSTEMS AND INTELLIGENT TECHNOLOGY & INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY FOR EMBEDDED SYSTEMS (ICESIT-ICICTES)
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang H, 2019, CHIN CONTR CONF, P8750, DOI [10.23919/chicc.2019.8866322, 10.23919/ChiCC.2019.8866322]
   Wang W, PVTV2 IMPROVED BASEL
   Wang YH, 2019, IEEE ICC
   Xiao YZ, 2020, MULTIMED TOOLS APPL, V79, P23729, DOI 10.1007/s11042-020-08976-6
   Yu F., 2015, ARXIV
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094
NR 42
TC 3
Z9 3
U1 5
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45585
EP 45604
DI 10.1007/s11042-023-15584-7
EA MAY 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000981387900002
DA 2024-07-18
ER

PT J
AU Xia, DW
   Geng, J
   Shen, BQ
   Bai, DW
   Zhang, WY
   Hu, Y
   Li, YT
   Li, HQ
AF Xia, Dawen
   Geng, Jian
   Shen, Bingqi
   Bai, Dewei
   Zhang, Wenyong
   Hu, Yang
   Li, Yantao
   Li, Huaqing
TI An A<SUP>2</SUP>-Gurobi algorithm for route recommendation with big taxi
   trajectory data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data analytics; Image processing; Route recommendation; Gurobi; A*;
   Big taxi trajectory data
ID SYSTEM
AB To address the problems of high fuel consumption and severe traffic congestion caused by blindly cruising, we propose a Gurobi optimization algorithm combined with an A ngle and an A* algorithm (A(2)-Gurobi) to recommend the optimal taxi route based on big taxi trajectory data in the complex urban road network. Specifically, a r oad n etwork n ode e xtraction method (RNNE) based on the GPS direction of taxis is put forward to solve the difficulty of extracting road network nodes from the big Taxi GPS trajectory data. Next, an a ngle-based s harp p oint e limination approach (ASPE) is constructed to optimize the searching capability of the Gurobi algorithm to find the shortest path. Then, a Gurobi optimization algorithm (A-Gurobi) based on the A* algorithm is designed, which uses the heuristic function of the A* algorithm to enhance the ability of fast guidance from the origin to the destination, thereby improving the execution efficiency of the Gurobi algorithm. Finally, the A(2)-Gurobi algorithm is successfully applied to the optimal taxi route recommendation with real-world taxi trajectory big data. Compared with Gurobi, Dijkstra, Floyd, A*, Bi-A*-ACO, Bellman-Ford, BFS, Acyclic, and AC on the taxi trajectory data sets composed of 10, 20, 30, 40, and 50 nodes, the experimental results indicate that the distance of the A(2)-Gurobi algorithm for taxi route recommendation is 19.06%, 20.97%, 3.03%, 15.07%, 15.07%, and 3.85% shorter than that of Gurobi, A*, Bi-A*-ACO, BFS, Acyclic, and AC on average, respectively, and it also achieves the same distance as other algorithms. In terms of execution efficiency, our A(2)-Gurobi algorithm outperforms the baselines mentioned above by 38.56%, 96.63%, 66.66%, 66.66%, 90.87%, 97.60%, 97.27%, 97.21%, and 99.27%, respectively.
C1 [Xia, Dawen; Geng, Jian; Shen, Bingqi; Bai, Dewei; Zhang, Wenyong] Guizhou Minzu Univ, Coll Data Sci & Informat Engn, Guiyang 550025, Peoples R China.
   [Hu, Yang] Guizhou Traff Technician & Transportat Coll, Dept Automot Engn, Guiyang 550008, Peoples R China.
   [Li, Yantao] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
   [Li, Huaqing] Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
C3 Guizhou Minzu University; Chongqing University; Southwest University -
   China
RP Xia, DW (corresponding author), Guizhou Minzu Univ, Coll Data Sci & Informat Engn, Guiyang 550025, Peoples R China.
EM dwxia@gzmu.edu.cn; huaqingli@swu.edu.cn
RI li, Shang/KHU-3233-2024; tong, li/KDO-7821-2024; CHEN,
   MINGWEI/KHT-6744-2024; Chen, YiJun/KFS-9282-2024; zhao,
   wei/JZD-4475-2024
OI Xia, Dawen/0000-0002-0151-9643
FU National Natural Science Foundation of China [62162012, 62173278,
   62072061]; Science and Technology Support Program of Guizhou Province
   [QKHZC2021YB531]; Natural Science Research Project of Department of
   Education of Guizhou Province [QJJ2022015]; Scientific Research Platform
   Project of Guizhou Minzu University [[2021]04]
FX AcknowledgementsThis work described in this paper was supported in part
   by the National Natural Science Foundation of China (Grant nos.
   62162012, 62173278, and 62072061), the Science and Technology Support
   Program of Guizhou Province (Grant no. QKHZC2021YB531), the Natural
   Science Research Project of Department of Education of Guizhou Province
   (Grant no. QJJ2022015), and the Scientific Research Platform Project of
   Guizhou Minzu University (Grant no. GZMUSYS[2021]04).
CR Bouzid Y, 2019, J INTELL ROBOT SYST, V95, P707, DOI 10.1007/s10846-018-0914-5
   Brito J, 2015, APPL SOFT COMPUT, V32, P154, DOI 10.1016/j.asoc.2015.03.026
   Calabrò G, 2020, EUR TRANSP RES REV, V12, DOI 10.1186/s12544-020-00409-7
   Dijkstra E., 1959, NUMER MATH, V1, P269, DOI [DOI 10.1007/BF01386390, 10.1007/bf01386390]
   Feng LB, 2016, DIGIT COMMUN NETW, V2, P151, DOI 10.1016/j.dcan.2016.07.002
   Gang Pan, 2013, IEEE Communications Magazine, V51, P108, DOI 10.1109/MCOM.2013.6525604
   Garrote L, 2020, INT J SOC ROBOT, V12, P689, DOI 10.1007/s12369-019-00585-0
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   Hou PQ, 2017, INT J MODEL SIMUL SC, V8, DOI 10.1142/S1793962317500465
   Hu WC, 2020, J INTERNET TECHNOL, V21, P757, DOI 10.3966/160792642020052103013
   Huang RX, 2021, MULTIMED TOOLS APPL, V80, P28975, DOI 10.1007/s11042-021-11142-1
   Kavraki LE, 1996, IEEE T ROBOTIC AUTOM, V12, P566, DOI 10.1109/70.508439
   Laarabi MH, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCED LOGISTICS & TRANSPORT (ICALT 2014), P78, DOI 10.1109/ICAdLT.2014.6864086
   LaValle SM, 2001, ALGORITHMIC AND COMPUTATIONAL ROBOTICS: NEW DIRECTIONS, P293
   Lee DH, 2021, IEEE T IND ELECTRON, V68, P9998, DOI 10.1109/TIE.2020.3020024
   Lengauer T., 1979, ACM Transactions on Programming Languages and Systems, V1, P121, DOI 10.1145/357062.357071
   Liang CL, 2021, APPL OCEAN RES, V113, DOI 10.1016/j.apor.2021.102755
   Noreen I, 2016, INT J ADV COMPUT SC, V7, P97
   Orozco-Rosas U, 2019, APPL SOFT COMPUT, V77, P236, DOI 10.1016/j.asoc.2019.01.036
   Qin GY, 2017, TRANSPORT RES C-EMER, V79, P103, DOI 10.1016/j.trc.2017.03.013
   Shao S, 2018, IET INTELL TRANSP SY, V12, P202, DOI 10.1049/iet-its.2017.0008
   Sheng WT, 2021, IEEE ACCESS, V9, P102801, DOI 10.1109/ACCESS.2021.3098676
   Wang PW, 2019, ENERGIES, V12, DOI 10.3390/en12122342
   Xia DW, 2022, MULTIMED TOOLS APPL, V81, P27523, DOI 10.1007/s11042-022-12077-x
   Xia DW, 2022, MULTIMED TOOLS APPL, V81, P4015, DOI 10.1007/s11042-021-11639-9
   Xia DW, 2021, PHYSICA A, V578, DOI 10.1016/j.physa.2021.126056
   Xia DW, 2021, NEURAL COMPUT APPL, V33, P2393, DOI 10.1007/s00521-020-05076-2
   Xia DW, 2016, NEUROCOMPUTING, V179, P246, DOI 10.1016/j.neucom.2015.12.013
   Xiang XS, 2020, ENG APPL ARTIF INTEL, V91, DOI 10.1016/j.engappai.2020.103582
   Xu P., 2019, MULTIMED TOOLS APPL, P1
   Yang SM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.601109
   Yu LY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9235016
   Yuan CC, 2020, INT J ADV ROBOT SYST, V17, DOI 10.1177/1729881420911232
   Yuan ZH, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091351
   Zeng DQ, 2021, P I MECH ENG D-J AUT, V235, P975, DOI 10.1177/0954407020969992
   Zhang JD, 2016, IET INTELL TRANSP SY, V10, P495, DOI 10.1049/iet-its.2015.0168
   Zhang Y, 2023, INT C INT THINGS SER, P276
   Zhang ZJ, 2022, IEEE T NEUR NET LEAR, V33, P6856, DOI 10.1109/TNNLS.2021.3083710
   Zheng Y, 2017, FRONT COMPUT SCI-CHI, V11, P1, DOI 10.1007/s11704-016-6907-2
   Zheng Y, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2743025
   Zhou ZY, 2018, OPTIK, V158, P639, DOI 10.1016/j.ijleo.2017.12.169
NR 41
TC 0
Z9 0
U1 11
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46547
EP 46575
DI 10.1007/s11042-023-15058-w
EA MAY 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000979973000002
DA 2024-07-18
ER

PT J
AU Rezk, NG
   Hemdan, EE
   Attia, AF
   El-Sayed, A
   El-Rashidy, MA
AF Rezk, Nermeen Gamal
   Hemdan, Ezz El-Din
   Attia, Abdel-Fattah
   El-Sayed, Ayman
   El-Rashidy, Mohamed A.
TI An efficient IoT based framework for detecting rice disease in smart
   farming system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart Farming; Machine Learning; Deep Learning; Rice Leaf Disease; Image
   Classification; and Image Segmentation
AB In recent days, Farmers and agriculture experts face several enduring agricultural challenges such as early detection of crop diseases like rice leaf diseases. However, severe rice diseases may lead to no grain harvest. This leads researchers to think about fast, automatic, the most effective, inexpensive, and accurate ways to detect the type of rice diseases using modern technologies such as the Internet of Things (IoT) and Artificial Intelligence (AI). Rice leaf disease prediction plays important role in early warning of the disease to mitigate its effects on disease prediction research objectives in the smart agriculture field. Recently, the identification and detection of diseases in rice crops become profoundly significant, as it is very natural that plants in the fields are attacked by certain specific bacterial or fungal diseases Therefore, this paper recommends and suggests an effective IoT-based rice disease detection and forecasting framework using machine learning and deep learning techniques for superlative decision-making in smart farming systems with proposing an IoT framework aimed to detect pest infestation for rice cultivation. The experimental results revealed that the proposed framework is accurate and particular to classifying, and efficiently predicting rice disease type. From the obtained results, the proposed framework demonstrated to be professionally disease prediction with achieving reasonable outcomes compared to the current utmost benchmark algorithms. It was gained up to 87.97% and 97.27% with machine learning and deep learning models. Similarly, the proposed framework surpassed contemporary algorithms based on evaluation metrics such as Accuracy, Precision, Recall, and F1- Score for efficient rice disease detection.
C1 [Rezk, Nermeen Gamal; Attia, Abdel-Fattah] Kafrelsheikh Univ, Fac Engn, Dept Comp & Syst, Kafrelsheikh, Egypt.
   [Hemdan, Ezz El-Din; El-Sayed, Ayman; El-Rashidy, Mohamed A.] Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia, Egypt.
C3 Egyptian Knowledge Bank (EKB); Kafrelsheikh University; Egyptian
   Knowledge Bank (EKB); Menofia University
RP Hemdan, EE (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia, Egypt.
EM nermeenbarakaa@yahoo.com; ezzvip@yahoo.com; aheliel@eng.kfs.edu.eg;
   ayman.elsayed@el-eng.menofia.edu.eg;
   mohamed.elrashedy@el-eng.menofia.edu.eg
RI EL-SAYED, Ayman E./AFM-8547-2022
OI EL-SAYED, Ayman E./0000-0002-4437-259X; Elrashidy,
   Mohamed/0000-0002-4699-4077
CR [Anonymous], 2012, Int. J. Comput. Sci. Telecommun
   Azim MA., 2021, Telecommun. Comput. Electronics Control TELKOMNIKA, V19, P463, DOI [10.12928/telkomnika.v19i2.16488, DOI 10.12928/TELKOMNIKA.V19I2.16488]
   Ben-Bassat M., 1982, Handbook of statistics, V2, P773, DOI DOI 10.1016/S0169-7161(82)02038-0
   Biswas M, 2019, NOVEL INSPECTION PAD
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5
   Chen JD, 2021, IET IMAGE PROCESS, V15, P1115, DOI 10.1049/ipr2.12090
   Chen JD, 2020, J SCI FOOD AGR, V100, P3246, DOI 10.1002/jsfa.10365
   Chen Matthew, 2019, PREDICTING PRICE CHA
   Chen WL, 2020, IEEE INTERNET THINGS, V7, P1001, DOI 10.1109/JIOT.2019.2947624
   Dhingra G, 2018, MULTIMED TOOLS APPL, V77, P19951, DOI 10.1007/s11042-017-5445-8
   Fathima SJ., 2017, NUTRIENT DELIVERY
   Gunawan P. A., 2021, J PHYS CONF SER, V1722
   Gunawan PA, 2021, J PHYS C SERIES, V172, P1
   Iorkyase Ephraim Tersoo, 2019, IEEE T POWER DELIVER
   Islam MA, 2021, AUTOMATED CONVOLUTIO
   Ismail N, INFORM PROCESSING AG
   kaggle, US
   Kinderis M, 2018, BITCOIN CURRENCY FLU
   Li DS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030578
   McHugh DJ, 2021, CANCERS, V13, DOI 10.3390/cancers13020240
   Mohameth F., 2020, Journal of Computer and Communications, V8, P10, DOI DOI 10.4236/JCC.2020.86002
   Nanehkaran YA, 2021, J SUPERCOMPUT, V77, P3193, DOI 10.1007/s11227-020-03388-7
   Nettleton DF, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-3065-1
   Pedrycz W., 2020, Deep Learning: Algorithms and Applications, V1
   Poornappriya, 2022, RICE PLANT DIS IDENT
   Pothen ME, 2020, 2020 4 INT C COMPUTI
   Seelam V, 2021, MATER TODAY-PROC
   Sethy PK, 2018, SPRINGERBR APPL SCI, P1, DOI 10.1007/978-981-10-6698-6_1
   Shrivastava Vimal K., 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P1023, DOI 10.1109/ICAIS50930.2021.9395813
   Shrivastava VK, 2021, J PLANT PATHOL, V103, P17, DOI 10.1007/s42161-020-00683-3
   Singh Jay Prakash, 2020, Machine Learning and Information Processing. Proceedings of ICMLIP 2019. Advances in Intelligent Systems and Computing (AISC 1101), P161, DOI 10.1007/978-981-15-1884-3_15
   Tang Nguyen T., 2020, arXiv
   Tassinari P, 2021, COMPUT ELECTRON AGR, V182, DOI 10.1016/j.compag.2021.106030
   Thevenoux R, 2021, COMPUT ELECTRON AGR, V186, DOI 10.1016/j.compag.2021.106058
   Tosawadi Teepakom, 2021, 2021 18th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON), P900, DOI 10.1109/ECTI-CON51831.2021.9454737
   Wikipedia, LIST RIC LEAF DIS
   Zhang SW, 2020, MULTIMED TOOLS APPL, V79, P30905, DOI 10.1007/s11042-020-09577-z
   Zhu YL, 2012, PHYSCS PROC, V25, P609, DOI 10.1016/j.phpro.2012.03.133
NR 39
TC 2
Z9 2
U1 9
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45259
EP 45292
DI 10.1007/s11042-023-15470-2
EA APR 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000977296200001
DA 2024-07-18
ER

PT J
AU Ma, YJ
   Altenbek, G
   Wu, XL
AF Ma, Yajing
   Altenbek, Gulila
   Wu, Xiaolong
TI Knowledge graph embedding via entity and relationship attributes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Knowledge embedding; Entity attributes; Relationship attributes; Triple
   classification; Link prediction
AB The translation rule-based TransE model is considered the most promising method due to its low complexity and high computational efficiency. However, there are limitations in dealing with complex relationships such as reflexive, 1-to-N, N-to-1, and N-to-N. Therefore, we propose a knowledge graph embedding model TransP based on entity and relationship attributes. We introduce the idea of hyperplane projection to map the head entity and tail entity to the plane of a specific relationship to enhance the model's ability to handle complex relationships. Furthermore, we propose the strategy of using the attribute characteristics of entities and relationships to improve distinction between different entities or relationships. Finally, we conduct link prediction and triple classification experiments on WN11, WN18, FB13 and FB15K datasets. Experimental results verify that the proposed method outperforms the baseline models and achieves the best results.
C1 [Ma, Yajing; Altenbek, Gulila; Wu, Xiaolong] Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830017, Xinjiang, Peoples R China.
   [Ma, Yajing; Altenbek, Gulila] Base Kazakh & Kirghiz Language Natl Language Resou, Urumqi, Peoples R China.
   [Ma, Yajing; Altenbek, Gulila] Xinjiang Lab Multilanguage Informat Technol, Urumqi, Peoples R China.
C3 Xinjiang University
RP Altenbek, G (corresponding author), Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830017, Xinjiang, Peoples R China.; Altenbek, G (corresponding author), Base Kazakh & Kirghiz Language Natl Language Resou, Urumqi, Peoples R China.; Altenbek, G (corresponding author), Xinjiang Lab Multilanguage Informat Technol, Urumqi, Peoples R China.
EM gla@xju.edu.cn
FU National Natural Science Foundation of China [62062062]
FX AcknowledgementsThe authors thank all reviewers for their constructive
   comments. This research is supported by the National Natural Science
   Foundation of China (62062062).
CR Mosa MA, 2021, APPL ARTIF INTELL, V35, P933, DOI 10.1080/08839514.2021.1966883
   Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52
   Banerjee Pratyay, 2021, ACM Transactions on Computing for Healthcare, V2, P1
   Bo AN., 2016, J CHIN INF PROCESS, V30, P84
   Bollacker K., 2008, P 2008 ACM SIGMOD IN, P1247, DOI 10.1145/1376616.1376746
   Bordes A, 2011, 25 AAAI C ART INT
   Bordes A., 2012, Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics, PMLR, V22, P127
   Bordes A., 2013, P 26 INT C NEURAL IN, P2787
   Bordes A, 2014, MACH LEARN, V94, P233, DOI 10.1007/s10994-013-5363-6
   CALLEJA P, 2018, INT C WEB ENG, P206
   Carlson A, 2010, AAAI CONF ARTIF INTE, P1306
   [陈文杰 Chen Wenjie], 2020, [计算机工程, Computer Engineering], V46, P63
   Chen XJ, 2019, COMPUT SCI
   Dinghe Xiao, 2020, Chinese Computational Linguistics. 19th China National Conference, CCL 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12522), P159, DOI 10.1007/978-3-030-63031-7_12
   Fan M., 2014, P 28 PACIFIC ASIA C, P328
   Hoffart J, 2013, ARTIF INTELL, V194, P28, DOI 10.1016/j.artint.2012.06.001
   Jenatton R., 2012, Adv. Neural Inf. Process. Syst., V25
   Ji GL, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P687
   Lappas PZ, 2021, APPL SOFT COMPUT, V107, DOI 10.1016/j.asoc.2021.107391
   Lei ZF, 2020, FUTURE GENER COMP SY, V102, P534, DOI 10.1016/j.future.2019.08.030
   Li LF, 2020, ARTIF INTELL MED, V103, DOI 10.1016/j.artmed.2020.101817
   [李鑫超 Li Xinchao], 2020, [计算机科学, Computer Science], V47, P189
   Li Y, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P1261, DOI 10.1145/2872427.2883068
   Lin YK, 2015, AAAI CONF ARTIF INTE, P2181
   Mahdisoltani F., 2014, 7 BIENN C INN DAT SY
   Miao QL, 2015, IEEE INT C SEMANT CO, P153, DOI 10.1109/ICOSC.2015.7050795
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Socher R., 2013, ADV NEURAL INFORM PR, V26, P1
   Suchanek F.M., 2007, P 16 INT C WORLD WID, DOI [10.1145/1242572.1242667, DOI 10.1145/1242572.1242667]
   Wang Z, 2014, AAAI CONF ARTIF INTE, P1112
   Zhang LH, 2021, COMPUT SPEECH LANG, V66, DOI 10.1016/j.csl.2020.101167
   Zhang W., 2019, ADV MULTIMEDIA UBIQU, P20
   Zhang ZY, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03182-0
   Zhao MX, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132720
   Zhao WX, 2019, LECT NOTES ARTIF INT, V11440, P16, DOI 10.1007/978-3-030-16145-3_2
   Zhu QN, 2019, J COMPUT SCI-NETH, V30, P108, DOI 10.1016/j.jocs.2018.11.004
NR 37
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44071
EP 44086
DI 10.1007/s11042-023-15070-0
EA APR 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000977607300001
DA 2024-07-18
ER

PT J
AU Gaikwad, S
   Nalbalwar, S
   Nandgaonkar, A
AF Gaikwad, Snehal
   Nalbalwar, Sanjay
   Nandgaonkar, Anil
TI Recognition of offline handwritten Devanagari characters using new
   mask-based approach, histogram of oriented gradients and AdaBoost
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Handwritten Devanagari characters; Mask; Histogram of oriented
   gradients; Spearman's correlation coefficient; AdaBoost
AB The world is growing with the new technologies for machine learning. Day by day there are incredible developments in the area of pattern recognition for the applications such as institutional record keeping, ancient documents preservation, postal address sorting, signature verification, etc. Handwritten character recognition is one such application grabbing lot of attention for the machines to learn. Handwritten Devanagari script is used in the proposed work which is very difficult to understand by the machines due to many similar shapes incorporated with it. So, pre-processing before extracting the features from the character plays very important role in increasing the accuracy. By keeping this in mind, a new framework for handwritten Devanagari character recognition is proposed where entropy -based skew correction is used to correct the skew of the characters and Mask-based approach is used which efficiently removes the header line and returns the header free character. The histograms of oriented gradients (HOG) features are extracted from the header free characters and provided for non-parametric dimensionality reduction. These features are further classified using AdaBoost ensemble boosting method and achieved a very good recognition accuracy of 98.43% and 98.68% on V2DMDCHAR and ISIDCHAR databases respectively.
C1 [Gaikwad, Snehal; Nalbalwar, Sanjay; Nandgaonkar, Anil] Dr Babasaheb Ambedkar Technol Univ, Raigad 402103, India.
C3 Dr. Babasaheb Ambedkar Technological University
RP Gaikwad, S (corresponding author), Dr Babasaheb Ambedkar Technol Univ, Raigad 402103, India.
EM snehalg14@gmail.com; nalbalwar_sanjayan@yahoo.com;
   abnandgaonkar@gmail.com
RI Gaikwad, Snehal/ABC-8168-2021
OI Gaikwad, Snehal/0000-0003-2271-5501
CR Arica N, 2001, IEEE T SYST MAN CY C, V31, P216, DOI 10.1109/5326.941845
   Arvind KR, 2007, LECT NOTES COMPUT SC, V4815, P495
   Battacharya U, 2005, PROC INT CONF DOC, P789
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deore Shalaka P., 2019, Revue d'Intelligence Artificielle, V33, P441, DOI 10.18280/ria.330606
   Dongre VJ, 2012, APPL COMPUT INTELL S, V2012, DOI 10.1155/2012/871834
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Fu Q, 2008, INT C FRONTIERS HAND
   Gaikwad SS., 2020, INT J ADV SCI TECHNO, V29, P7888
   Guha R, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420520096
   Jangid M, 2018, J IMAGING, V4, DOI 10.3390/jimaging4020041
   Jayadevan R, 2011, IEEE T SYST MAN CY C, V41, P782, DOI 10.1109/TSMCC.2010.2095841
   Jha V., 2019, Int J Sci Technol Res, V8, P1188
   Jindal T, 2013, P 4 INT WORKSH MULT, P1
   Kamble PM, 2015, PROCEDIA COMPUT SCI, V45, P266, DOI 10.1016/j.procs.2015.03.137
   Kaur S, 2019, J DISCRET MATH SCI C, V22, P1365, DOI 10.1080/09720529.2019.1692445
   Khuman YLK, 2021, MATER TODAY-PROC, V37, P2666, DOI 10.1016/j.matpr.2020.08.522
   Kim K, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0189-y
   Narang SR, 2020, P NATL A SCI INDIA A, V90, P717, DOI 10.1007/s40010-019-00627-2
   Narang SR, 2019, SOFT COMPUT, V23, P13603, DOI 10.1007/s00500-019-03897-5
   Opitz D., 1999, J ARTIF INTELL RES, V11, P169, DOI DOI 10.1613/JAIR.614
   Sahare P, 2018, IEEE ACCESS, V6, P10603, DOI 10.1109/ACCESS.2018.2795104
   Schober P, 2018, ANESTH ANALG, V126, P1763, DOI 10.1213/ANE.0000000000002864
   Setumin S, 2018, IEEE ACCESS, V6, P39344, DOI 10.1109/ACCESS.2018.2855208
   Spearman C, 1904, AM J PSYCHOL, V15, P72, DOI 10.2307/1412159
   Thakur A, 2019, INT J SCI TECHNOL RE, V8, P1
   Zhou TF, 2022, IEEE T IMAGE PROCESS, V31, P799, DOI 10.1109/TIP.2021.3132834
   Zhou TF, 2022, IEEE T PATTERN ANAL, V44, P2827, DOI 10.1109/TPAMI.2021.3049156
   Zhou TF, 2020, IEEE T IMAGE PROCESS, V29, P8326, DOI 10.1109/TIP.2020.3013162
   Zhou W, 2020, IEEE T CIRCUITS-II, V67, P946, DOI 10.1109/TCSII.2020.2980557
NR 30
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43883
EP 43902
DI 10.1007/s11042-023-15424-8
EA APR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000976628900002
DA 2024-07-18
ER

PT J
AU Kumar, A
   Agrawal, RK
   Joseph, L
AF Kumar, Ashish
   Agrawal, R. K.
   Joseph, Leve
TI IterMiUnet: A lightweight architecture for automatic blood vessel
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinal Vessel Segmentation; Deep Learning; Fundus Imaging;
   Convolutional Neural Networks; Semantic Segmentation
ID RETINAL IMAGES
AB The automatic segmentation of blood vessels in fundus images can help analyze the condition of retinal vasculature, which is crucial for identifying various systemic diseases like hypertension, diabetes, etc. Despite the success of Deep Learning-based models in this segmentation task, most of them are heavily parametrized and thus have limited use in practical applications. This paper proposes IterMiUnet, a new lightweight convolution-based segmentation model that requires significantly fewer parameters and yet delivers performance similar to existing models. The model makes use of the excellent segmentation capabilities of Iternet (Li et al (2020)) architecture but overcomes its heavily parametrized nature by incorporating the encoder-decoder structure of MiUnet (Hu et al. (2019) IEEE Access 7:174167-174177) model within it. Thus, the new model reduces parameters without any compromise with the network's depth, which is necessary to learn abstract hierarchical concepts in deep models. This lightweight segmentation model speeds up training and inference time and is potentially helpful in the medical domain where data is scarce and, therefore, heavily parametrized models tend to overfit. The proposed model was evaluated on three publicly available datasets: DRIVE, STARE, and CHASE-DB1. Further cross-training and inter-rater variability evaluations have also been performed. The proposed model has a lot of potential to be utilized as a tool for the early diagnosis of many diseases.
C1 [Kumar, Ashish; Agrawal, R. K.] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi, India.
   [Joseph, Leve] All India Inst Med Sci, New Delhi, India.
C3 Jawaharlal Nehru University, New Delhi; All India Institute of Medical
   Sciences (AIIMS) New Delhi
RP Kumar, A (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi, India.
EM ashish47_scs@jnu.ac.in
OI , Ashish Kumar/0000-0002-1786-760X; Agrawal, Ramesh
   kumar/0000-0003-3122-5096
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Abramoff Michael D, 2010, IEEE Rev Biomed Eng, V3, P169, DOI 10.1109/RBME.2010.2084567
   Alom MZ, 2018, arXiv
   Azzopardi G, 2015, MED IMAGE ANAL, V19, P46, DOI 10.1016/j.media.2014.08.002
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chanwimaluang T, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL V, P21
   Chatziralli IP, 2012, OPEN OPHTHALMOL J, V6, P4, DOI 10.2174/1874364101206010004
   Dai JF, 2015, IEEE I CONF COMP VIS, P1635, DOI 10.1109/ICCV.2015.191
   Fan Z, 2019, IEEE T IMAGE PROCESS, V28, P2367, DOI 10.1109/TIP.2018.2885495
   Fraz MM, 2012, COMPUT METH PROG BIO, V108, P600, DOI 10.1016/j.cmpb.2011.08.009
   Fraz MM, 2012, IEEE T BIO-MED ENG, V59, P2538, DOI 10.1109/TBME.2012.2205687
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Hu JF, 2019, IEEE ACCESS, V7, P174167, DOI 10.1109/ACCESS.2019.2940476
   Jin QG, 2019, KNOWL-BASED SYST, V178, P149, DOI 10.1016/j.knosys.2019.04.025
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lam BSY, 2010, IEEE T MED IMAGING, V29, P1369, DOI 10.1109/TMI.2010.2043259
   LeCun Y., 1990, ADV NEURAL INFORM PR, P396
   Li LZ, 2020, IEEE WINT CONF APPL, P3645, DOI 10.1109/WACV45572.2020.9093621
   Li QL, 2016, IEEE T MED IMAGING, V35, P109, DOI 10.1109/TMI.2015.2457891
   Liskowski P, 2016, IEEE T MED IMAGING, V35, P2369, DOI 10.1109/TMI.2016.2546227
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Marín D, 2011, IEEE T MED IMAGING, V30, P146, DOI 10.1109/TMI.2010.2064333
   Martinez-Perez ME, 2007, MED IMAGE ANAL, V11, P47, DOI 10.1016/j.media.2006.11.004
   Mou L, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101874
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Oliveira A, 2018, EXPERT SYST APPL, V112, P229, DOI 10.1016/j.eswa.2018.06.034
   Owen CG, 2009, INVEST OPHTH VIS SCI, V50, P2004, DOI 10.1167/iovs.08-3018
   Patton N, 2006, PROG RETIN EYE RES, V25, P99, DOI 10.1016/j.preteyeres.2005.07.001
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Ricci E, 2007, IEEE T MED IMAGING, V26, P1357, DOI 10.1109/TMI.2007.898551
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roychowdhury S, 2015, IEEE T BIO-MED ENG, V62, P1738, DOI 10.1109/TBME.2015.2403295
   Roychowdhury S, 2015, IEEE J BIOMED HEALTH, V19, P1118, DOI 10.1109/JBHI.2014.2335617
   Sasaki Y., 2007, Teach Tutor Mater, V1, P1
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Tian F, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/4761517
   Uysal E, 2021, MULTIMED TOOLS APPL, V80, P3505, DOI 10.1007/s11042-020-09372-w
   Yan ZQ, 2019, IEEE J BIOMED HEALTH, V23, P1427, DOI 10.1109/JBHI.2018.2872813
   Yan ZQ, 2018, IEEE T BIO-MED ENG, V65, P1912, DOI 10.1109/TBME.2018.2828137
   Zhang Y, 2022, EXPERT SYST APPL, V195, DOI 10.1016/j.eswa.2022.116526
NR 42
TC 2
Z9 2
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43207
EP 43231
DI 10.1007/s11042-023-15433-7
EA APR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:001066758900008
DA 2024-07-18
ER

PT J
AU Sharifi, O
AF Sharifi, Omid
TI Two-stage morph detection scheme for face and iris biometrics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Face morph detection; Iris morph detection; Information
   fusion; Deep learning
ID DATABASE; SYSTEMS
AB Morphing attacks presented by image and/or feature information of more than one individual are a major concern of biometric systems. Penetrating the morphed biometric information to biometric recognition systems may cause successful verification of all presented individuals to the morphed image against a registered template. Therefore, designing a robust biometric system to detect this kind of attack is necessary. This paper aims to implement a novel solution for distinguishing the morph and bona fide identities using a hybrid detection system for face-iris biometrics. The anti-morphing pipeline concentrates on two steps of detection using handcrafted and deep-learning techniques. Firstly, the detection is done according to the texture information of images and then the morphing attack detection framework is applied once more for images recognized as bona fide using deep learning technique to boost the reliability of the face-iris biometric systems. The effectiveness of proposed morph detection method is examined on FERET, FRGC, and FRLL morph datasets using three different morphing algorithms for face biometric. In order to testify the robustness of proposed anti-morphing technique, CASIAv4-Interval database is used on one morphing algorithm for iris biometric. Demonstration of results clarifies the robustness of the proposed solution for morph detection.
C1 [Sharifi, Omid] Toros Univ, Engn Fac, Dept Software Engn, Mersin, Turkiye.
C3 Toros University
RP Sharifi, O (corresponding author), Toros Univ, Engn Fac, Dept Software Engn, Mersin, Turkiye.
EM omid.sharifi@toros.edu.tr
RI SHARIFI, OMID/KGL-1899-2024; Om, Omid/KFT-3078-2024; SHARIFI,
   OMID/JMB-9180-2023
OI SHARIFI, OMID/0000-0003-4887-5618; SHARIFI, OMID/0000-0003-4887-5618
CR Agarwal A, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.643424
   Agarwal A, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P659, DOI 10.1109/BTAS.2017.8272754
   [Anonymous], 2016, LearnOpenCV
   [Anonymous], 2018, CIPS 2018 10 INT C I
   [Anonymous], 2003, Matlab source code for a biometric identification system based on iris patterns
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chinese Academy of Sciences' Institute of Automation, CASIA IR IM DAT V4 0
   Damer N., 2019, 2019 22 INT C INFORM
   Damer N, 2021, LECT NOTES COMPUT SC, V13017, P291, DOI 10.1007/978-3-030-90439-5_23
   Damer N, 2018, INT CONF BIOMETR THE
   Debiasi L, 2019, LECT NOTES COMPUT SC, V11752, P345, DOI 10.1007/978-3-030-30645-8_32
   Debiasi L, 2018, I W BIOMETRIC FORENS
   Debiasi L, 2018, INT CONF BIOMETR THE
   Elaggoune H, 2022, MULTIMED TOOLS APPL, V81, P9403, DOI 10.1007/s11042-021-11849-1
   Eskandari M, 2019, IET BIOMETRICS, V8, P243, DOI 10.1049/iet-bmt.2018.5134
   Eskandari M, 2017, IET BIOMETRICS, V6, P334, DOI 10.1049/iet-bmt.2016.0060
   Eskandari M, 2015, COMPUT VIS IMAGE UND, V137, P63, DOI 10.1016/j.cviu.2015.02.011
   Fang ML, 2021, IMAGE VISION COMPUT, V105, DOI 10.1016/j.imavis.2020.104057
   Ferrara M, 2019, ARXIV
   Ferrara M, 2019, LECT NOTE INFORM, VP-296
   Hamza M, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122412545
   Jassim S, 2018, EUR SIGNAL PR CONF, P1007, DOI 10.23919/EUSIPCO.2018.8553317
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Korshunov P, 2019, ARXIV
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Phillips PJ, 2005, 2005 IEEE COMP SOC C, V1
   Quek Alyssa, 2019, Facemorpher
   Raghavendra R, 2016, INT CONF BIOMETR THE
   Raghavendra R, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P555, DOI 10.1109/BTAS.2017.8272742
   Raghavendra R, 2017, IEEE COMPUT SOC CONF, P1822, DOI 10.1109/CVPRW.2017.228
   Raja K, 2022, IMAGE VISION COMPUT, V126, DOI 10.1016/j.imavis.2022.104535
   Ramachandra R, 2019, 2019 IEEE 5 INT C ID
   Rathgeb C, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P152, DOI 10.1109/BTAS.2017.8272693
   Salih Zahraa Aqeel, 2022, 2022 International Conference on Information Technology Systems and Innovation (ICITSI), P189, DOI 10.1109/ICITSI56531.2022.9970797
   Sarkar E, 2021, ARXIV
   Scherhag Ulrich, 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P302, DOI 10.1109/TBIOM.2019.2942395
   Scherhag U, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P187, DOI 10.1109/DAS.2018.11
   Scherhag U, 2020, IET BIOMETRICS, V9, P278, DOI 10.1049/iet-bmt.2019.0206
   Scherhag U, 2017, I W BIOMETRIC FORENS
   Scherhag U, 2019, IEEE ACCESS, V7, P23012, DOI 10.1109/ACCESS.2019.2899367
   Seibold C, 2017, INT WOKSH DIG WAT
   Seibold C, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102526
   Seibold C, 2018, EUR SIGNAL PR CONF, P1022, DOI 10.23919/EUSIPCO.2018.8553116
   Sharifi O, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P12, DOI 10.1109/UBMK.2017.8093508
   Sharma R, 2021, 2021 IEEE INT C IM P
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Spreeuwers L, 2018, EUR SIGNAL PR CONF, P1027, DOI 10.23919/EUSIPCO.2018.8553018
   Szymkowski M, 2021, INNOV SYST SOFTW ENG, V17, P309, DOI 10.1007/s11334-021-00392-9
   Tapia JE, 2015, LECT NOTES COMPUT SC, V8926, P751, DOI 10.1007/978-3-319-16181-5_57
   Wandzik L, 2018, EUR SIGNAL PR CONF, P1012, DOI 10.23919/EUSIPCO.2018.8553375
   Yildiz MC, 2016, P INT C COMPUTER VIS
   Zhang LB, 2018, IEEE INT CON MULTI
NR 53
TC 1
Z9 1
U1 6
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 43013
EP 43028
DI 10.1007/s11042-023-15375-0
EA APR 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000974364100007
DA 2024-07-18
ER

PT J
AU Tsai, TH
   Lin, XH
AF Tsai, Tsung-Han
   Lin, Xin-Hui
TI Speech densely connected convolutional networks for small-footprint
   keyword spotting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Keyword spotting; DenseNet; Group convolution; Depthwise separable
   convolution; SENet
AB Keyword spotting is an important task for human-computer interaction (HCI). For high privacy, the identification task needs to be performed at the edge, so the purpose of this task is to improve the accuracy as much as possible within the limited cost. This paper proposes a new keyword spotting technique by the convolutional neural network (CNN) method. It is based on the application of densely connected convolutional networks (DenseNet). To make the model smaller, we replace the normal convolution with group convolution and depthwise separable convolution. We add squeeze-and-excitation networks (SENet) to enhance the weight of important features to increase the accuracy. To investigate the effect of different convolutions on DenseNet, we built two models: SpDenseNet and SpDenseNet-L. we validated the network using the Google speech commands dataset. Our proposed network had better accuracy than the other networks even with a fewer number of parameters and floating-point operations (FLOPs). SpDenseNet could achieve an accuracy of 96.3% with 122.63 K trainable parameters and 142.7 M FLOPs. Compared to the benchmark works, only about 52% of the number of parameters and about 12% of the FLOPs are used. In addition, we varied the depth and width of the network to build a compact variant. It also outperforms other compact variants, where SpDenseNet-L-narrow could achieve an accuracy of 93.6% withiri: An On-device DNN-powere 9.27 K trainable parameters and 3.47 M FLOPs. Compared to the benchmark works, the accuracy on SpDenseNet-L-narrow is improved by 3.5%. It only uses only about 47% of the number of parameters and about 48% of the FLOPS.
C1 [Tsai, Tsung-Han; Lin, Xin-Hui] Natl Cent Univ, Dept Elect Engn, 300 Jung Da Rd, Jung Li City 320, Taiwan.
C3 National Central University
RP Tsai, TH (corresponding author), Natl Cent Univ, Dept Elect Engn, 300 Jung Da Rd, Jung Li City 320, Taiwan.
EM han@ee.ncu.edu.tw; ccindyleotw@dsp.ee.ncu.edu.tw
CR Andra MB, 2017, INT C ADV COMP SCI I, P198, DOI 10.1109/ICACSIS.2017.8355033
   [Anonymous], 2017, Launching the speech commands dataset
   [Anonymous], 2010, J COMPUT
   Apple Machine Learning Blog, 2017, HEY SIR ON DEV DNN P
   Arik SÖ, 2017, INTERSPEECH, P1606, DOI 10.21437/Interspeech.2017-1737
   Bai Y, 2016, AER ADV ENG RES, V60, P1, DOI 10.1109/CPEM.2016.7540519
   Choi J, 2018, 2018 INT C COMPUTATI, P1452, DOI DOI 10.1109/CSCI46756.2018.00286
   Coimbra De Andrade Douglas, 2018, ARXIV180808929
   Edu JS, 2021, ACM COMPUT SURV, V53, DOI 10.1145/3412383
   Fukuda T, 2018, INTERSPEECH, P2409, DOI 10.21437/Interspeech.2018-1211
   Hölzke F, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS WORKSHOPS AND OTHER AFFILIATED EVENTS (PERCOM WORKSHOPS), P167, DOI [10.1109/PerComWorkshops51409.2021.9430865, 10.1109/PERCOMWORKSHOPS51409.2021.9430865]
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ko T, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3586
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li B, 2017, INTERSPEECH, P399, DOI 10.21437/Interspeech.2017-234
   Lin J, 2020, INT CONF ACOUST SPEE, P7474, DOI [10.1109/ICASSP40776.2020.9053193, 10.1109/icassp40776.2020.9053193]
   Liu L, 2018, PATTERN RECOGN, V81, P545, DOI 10.1016/j.patcog.2018.04.022
   Mo T, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2106.02738
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Rybakov O, 2020, INTERSPEECH, P2277, DOI 10.21437/Interspeech.2020-1003
   Sainath TN, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1478
   Sinha D, 2019, 2019 IEEE 10TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P280, DOI 10.1109/uemcon47517.2019.8993089
   So X, 2015, AUDIO MANIPULATION T
   statista, NUMBER DIGITAL VOICE
   Sun M, 2016, IEEE W SP LANG TECH, P474, DOI 10.1109/SLT.2016.7846306
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tang R, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5484, DOI 10.1109/ICASSP.2018.8462688
   Totsuka N, 2014, 2014 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING (ICALIP), VOLS 1-2, P887, DOI 10.1109/ICALIP.2014.7009922
   Wang D, 2018, LECT NOTES COMPUT SC, V10861, P669, DOI 10.1007/978-3-319-93701-4_53
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yan ZC, 2015, IEEE I CONF COMP VIS, P2740, DOI 10.1109/ICCV.2015.314
   Zeng MJ, 2019, IEEE ACCESS, V7, P10767, DOI 10.1109/ACCESS.2019.2891838
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang Y., 2017, ARXIV171107128
NR 38
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39119
EP 39137
DI 10.1007/s11042-023-14617-5
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000983783100004
DA 2024-07-18
ER

PT J
AU Yu, JW
   Yu, XY
   Zhang, LW
   Xie, W
AF Yu, Jinwei
   Yu, Xiaoyuan
   Zhang, Langwen
   Xie, Wei
TI A two-stage chaotic encryption algorithm for color face image based on
   circular diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face image encryption; Chaotic system; Plaintext-related cryptosystem;
   Circular diffusion
ID LEVEL PERMUTATION; SYSTEM; PROTECTION; MAP; TRANSFORM
AB In information security, image encryption is widely used to protect private information. However, most encryption algorithms encrypt the whole image without considering the different importance of different regions in an image, which leads to inefficiency and waste of computational power. This paper proposes a novel two-stage chaotic encryption algorithm for color face image based on circular diffusion cryptosystem. First, CenterFace is used to extract the face region in the plain image. Then the face region is dislocated, diffused and permuted using chaotic sequences generated by a two-stage plaintext-related chaotic system. The encrypted face region and the non-face areas are then merged. Finally, the face position is embedded into the cipher image using digital watermarking technology. Selective encryption of face regions allows the method to have high efficiency and real-time performance. The experimental results show that the number of pixels change rate and the unified average changing intensity are 99.6084% and 33.4687% respectively, and the information entropy of the cipher image reaches 7.9972. Besides, security analyses indicate that our proposed encryption algorithm has strong resistance to various attacks.
C1 [Yu, Jinwei; Zhang, Langwen; Xie, Wei] South China Univ Technol, Sch Automat Sci & Engn, Guangzhou 510641, Peoples R China.
   [Yu, Xiaoyuan] South China Normal Univ, Sch Phys & Telecommun Engn, Guangzhou 510006, Peoples R China.
C3 South China University of Technology; South China Normal University
RP Xie, W (corresponding author), South China Univ Technol, Sch Automat Sci & Engn, Guangzhou 510641, Peoples R China.
EM yujinwei1995@163.com; xiaoyuanyu@scnu.edu.cn; aulwzhang@scut.edu.cn;
   weixie@scut.edu.cn
RI yu, callen/GXH-0587-2022
OI Yu, Jinwei/0000-0002-9969-2697
FU Key-Area Research and Development Program of Guangdong Province
   [2018B010108001]; GuangDong Basic and Applied Basic Research Foundation
   [2022A1515110119]; Science and Technology Plan Project of Jiangmen
   [2020030103080008999]
FX AcknowledgementsThis work is supported by Key-Area Research and
   Development Program of Guangdong Province under the grant
   (2018B010108001), GuangDong Basic and Applied Basic Research Foundation
   under grant (2022A1515110119) and Science and Technology Plan Project of
   Jiangmen (2020030103080008999).
CR Abd El-Latif AA, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58636-w
   Abd EL-Latif AA, 2020, OPT LASER TECHNOL, V124, DOI 10.1016/j.optlastec.2019.105942
   Akhshani A, 2012, COMMUN NONLINEAR SCI, V17, P4653, DOI 10.1016/j.cnsns.2012.05.033
   Amina Souyah, 2018, Communications in Nonlinear Science and Numerical Simulation, V60, P12, DOI 10.1016/j.cnsns.2017.12.017
   Asgari-Chenaghlu M, 2021, INFORM SCIENCES, V542, P212, DOI 10.1016/j.ins.2020.07.007
   Asgari-Chenaghlu M, 2019, SIGNAL PROCESS, V157, P1, DOI 10.1016/j.sigpro.2018.11.010
   Barni M, 2015, IEEE SIGNAL PROC MAG, V32, P66, DOI 10.1109/MSP.2015.2438131
   Chai XL, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108041
   Chen XD, 2019, OPT LASER ENG, V121, P143, DOI 10.1016/j.optlaseng.2019.04.004
   Dwivedi R, 2019, J AMB INTEL HUM COMP, P1
   Gomez-Barrero M, 2018, INFORM FUSION, V42, P37, DOI 10.1016/j.inffus.2017.10.003
   Gomez-Barrero M, 2017, PATTERN RECOGN, V67, P149, DOI 10.1016/j.patcog.2017.01.024
   Huang G.B., 2008, WORKSH FAC REAL LIF
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Kadir A, 2017, OPTIK, V129, P231, DOI 10.1016/j.ijleo.2016.10.036
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Kang XJ, 2019, IEEE T CIRC SYST VID, V29, P1595, DOI 10.1109/TCSVT.2018.2851983
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Kumar S, 2018, MULTIMED TOOLS APPL, V77, P11017, DOI 10.1007/s11042-017-4966-5
   Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170
   Li Q, 2021, IEEE T CIRCUITS SYST
   Li YX, 2005, INT J BIFURCAT CHAOS, V15, P3367, DOI 10.1142/S0218127405013988
   [梁颖 Liang Ying], 2018, [中国图象图形学报, Journal of Image and Graphics], V23, P814
   Liu HJ, 2015, SIGNAL PROCESS, V113, P104, DOI 10.1016/j.sigpro.2015.01.016
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Luo YL, 2019, SIGNAL PROCESS, V161, P227, DOI 10.1016/j.sigpro.2019.03.022
   Merhav N, 2019, IEEE T INFORM THEORY, V65, P2477, DOI 10.1109/TIT.2018.2873132
   Morampudi MK, 2020, MULTIMED TOOLS APPL, V79, P19215, DOI 10.1007/s11042-020-08680-5
   Naskar PK, 2020, NONLINEAR DYNAM, V100, P2877, DOI 10.1007/s11071-020-05625-3
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   Sambas A, 2020, IEEE ACCESS, V8, P137116, DOI 10.1109/ACCESS.2020.3011724
   Shah D, 2020, MULTIMED TOOLS APPL, V79, P28023, DOI 10.1007/s11042-020-09182-0
   Valandar MY, 2019, OPTIK, V193, DOI 10.1016/j.ijleo.2019.06.021
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wang KS, 2021, MULTIMED TOOLS APPL, V80, P18875, DOI 10.1007/s11042-021-10511-0
   Wang X, 2021, IEEE T CIRCUITS SYST
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2021, INFORM SCIENCES, V579, P128, DOI 10.1016/j.ins.2021.07.096
   Wang XY, 2021, INFORM SCIENCES, V569, P217, DOI 10.1016/j.ins.2021.04.013
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Xian Y, 2021, IEEE T CIRCUITS SYST
   Xu QY, 2019, OPT LASER ENG, V121, P203, DOI 10.1016/j.optlaseng.2019.04.011
   Xu Y, 2019, SCI PROGRAMMING-NETH
   Xue HW, 2018, OPT LASER TECHNOL, V106, P506, DOI 10.1016/j.optlastec.2018.04.030
   Yao LL, 2017, OPT LASER ENG, V89, P72, DOI 10.1016/j.optlaseng.2016.06.006
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang D, 2018, MULTIMED TOOLS APPL, V77, P2191, DOI 10.1007/s11042-017-4370-1
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhou KL, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105769
   Zhu CJ, 2020, MULTIMED TOOLS APPL, V79, P7227, DOI 10.1007/s11042-019-08226-4
NR 58
TC 2
Z9 2
U1 14
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40009
EP 40038
DI 10.1007/s11042-023-14804-4
EA MAR 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000983783100005
DA 2024-07-18
ER

PT J
AU Duan, XY
   Liu, H
   Liang, JZ
AF Duan, Xinyi
   Liu, Hao
   Liang, Jiuzhen
TI DIQA-FF:dual image quality assessment for face frontalization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face frontalization; Dual image quality assessment; The Gaussian mixture
   model; The cosine similarity
AB Face frontalization is a process of synthesizing a realistic and identity-preserving face view from different face pose images. It is an essential preprocessing step for face recognition. As Generative Adversarial Networks (GANs) are applied to face frontalization tasks, the synthesized high-quality frontal faces are required to be more realistic and highly recognizable. To increase the authenticity and recognizability of generated frontal face images, we propose a face frontalization algorithm with dual image quality assessment (DIQA-FF) in this study. This approach assesses the generated images' quality from the discriminator and the generator. We use the Gaussian mixture model (GMM) in the discriminator to give the generated images a probability distribution that is more similar to the authentic images, increasing the images' authenticity. To improve the recognizability of the images, we caculate the similarity of the authentic images and the generated images and maximize the resemblance between them in the generator. The results of the experiments demonstrate that our method can transform the side face image into a complete and accurate front face image. Additionally, the generated frontal faces perform better for face recognition. Quantitative and qualitative evaluations on both controlled and in-the-wild databases show that our frontalization approach not only outperforms the state of-the-art in terms of authenticity but also in terms of recognizability.
C1 [Duan, Xinyi; Liu, Hao; Liang, Jiuzhen] Changzhou Univ, Sch Informat & Engn, Changzhou 213164, Peoples R China.
C3 Changzhou University
RP Liu, H (corresponding author), Changzhou Univ, Sch Informat & Engn, Changzhou 213164, Peoples R China.
EM S21150858010@smail.cczu.edu.cn; helenliuhao@cczu.edu.cn;
   jzliang@cczu.edu.cn
FU Universities in Jiangsu Province [22KJB520011]
FX The research leading to these results received funding from the Basic
   Science (Natural Science) Research Projects of Universities in Jiangsu
   Province under Grant Agreement No[22KJB520011].
CR Ajagbe S, 2021, INT J ADV COMPUT RES, V11, P51, DOI [10.19101/IJACR.2021.1152001, DOI 10.19101/IJACR.2021.1152001, 10.3390/electronics12030676]
   Ajagbe SA, 2022, 2022 INT C ELECT COM, P1, DOI [10.1109/ICECET55527.2022.9872568, DOI 10.1109/ICECET55527.2022.9872568]
   Alhlffee MHB, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.897
   Alonso-Fernandez F, 2012, IEEE SECUR PRIV, V10, P52, DOI 10.1109/MSP.2011.178
   Boutros F, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2112.06592
   Cao J, 2018, ADV NEUR IN, V31
   Deng JK, 2022, IEEE T PATTERN ANAL, V44, P5962, DOI 10.1109/TPAMI.2021.3087709
   Ou FZ, 2021, PROC CVPR IEEE, P7666, DOI 10.1109/CVPR46437.2021.00758
   Gecer B, 2021, PROC CVPR IEEE, P7624, DOI 10.1109/CVPR46437.2021.00754
   Graedel N, 2021, NEUROIMAGE, V118, P674
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Gu S, 2020, ARXIV200616990, P1, DOI [10.48550/arXiv.2006.16990, DOI 10.48550/ARXIV.2006.16990]
   He HJ, 2023, APPL INTELL, V53, P16648, DOI 10.1007/s10489-022-04336-z
   Hernandez-Carlon J., 2022, 2022 IEEE 95th Vehicular Technology Conference:(VTC2022-Spring), P1
   Hu YB, 2018, PROC CVPR IEEE, P8398, DOI 10.1109/CVPR.2018.00876
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Huang R, 2017, IEEE I CONF COMP VIS, P2458, DOI 10.1109/ICCV.2017.267
   Ju YJ, 2022, IEEE WINT CONF APPL, P1173, DOI 10.1109/WACV51458.2022.00124
   Kang Z, 2022, ARXIV, DOI DOI 10.48550/ARXIV.2204.02810
   Li PP, 2019, IEEE I CONF COMP VIS, P10042, DOI 10.1109/ICCV.2019.01014
   Li XY, 2021, PROC CVPR IEEE, P8635, DOI 10.1109/CVPR46437.2021.00853
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Meng Q, 2021, PROC CVPR IEEE, P14220, DOI 10.1109/CVPR46437.2021.01400
   Mostofa M, 2022, 2022 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), DOI 10.1109/IJCB54206.2022.10007935
   Qian YC, 2019, PROC CVPR IEEE, P9843, DOI 10.1109/CVPR.2019.01008
   Radford A., 2016, ARXIV, DOI [10.48550/ARXIV.1511.06434, DOI 10.48550/ARXIV.1511.06434]
   Richardson E, 2018, ADV NEURAL INF PROCE, V31, P1, DOI DOI 10.48550/ARXIV.1805.12462
   Sengupta S., 2016, 2016 IEEE WINT C APP, P1, DOI [DOI 10.1109/WACV.2016.7477558, 10.1109/WACV.2016.7477558]
   Shuyang Gu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P369, DOI 10.1007/978-3-030-58621-8_22
   Tian Y., 2022, arXiv preprint arXiv:2203.01923, P1
   Tian Y., 2018, ACTA GEOTECH, P1, DOI [10.48550/arXiv.1806.11191, DOI 10.48550/ARXIV.1806.11191]
   Tran L, 2017, PROC CVPR IEEE, P1283, DOI 10.1109/CVPR.2017.141
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang HP, 2021, PROC CVPR IEEE, P7868, DOI 10.1109/CVPR46437.2021.00778
   Wang X, P IEEE CVF C COMP VI, P9168, DOI [10.48550/arXiv.2101.04061, DOI 10.48550/ARXIV.2101.04061]
   Yin XX, 2017, HEALTH INFOR SCI, P1, DOI [10.1109/ICCV.2017.430, 10.1007/978-3-319-57027-3_1]
   Yin Y, 2020, IEEE INT CONF AUTOMA, P249, DOI 10.1109/FG47880.2020.00004
   Yuxiang Wei, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P558, DOI 10.1007/978-3-030-58610-2_33
   Zeng XX, 2022, COMPUT VIS MEDIA, V8, P239, DOI 10.1007/s41095-021-0238-4
   Zhang ZH, 2019, IEEE T IMAGE PROCESS, V28, P2187, DOI 10.1109/TIP.2018.2883554
   Zhao J, 2018, PROC CVPR IEEE, P2207, DOI 10.1109/CVPR.2018.00235
   Zhou H, 2020, PROC CVPR IEEE, P5910, DOI 10.1109/CVPR42600.2020.00595
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu XY, 2019, IEEE T PATTERN ANAL, V41, P78, DOI 10.1109/TPAMI.2017.2778152
   Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679
NR 46
TC 1
Z9 1
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39503
EP 39522
DI 10.1007/s11042-023-15084-8
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000960423600004
DA 2024-07-18
ER

PT J
AU Zeng, L
   Tang, HZ
   Wang, W
   Xie, MJ
   Ai, ZY
   Chen, L
   Wu, YJ
AF Zeng, Li
   Tang, Hongzhong
   Wang, Wei
   Xie, Mingjian
   Ai, Zhaoyang
   Chen, Lei
   Wu, Yongjun
TI MAMC-Net: an effective deep learning framework for whole-slide image
   tumor segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Histopathological image segmentation; Multi-resolution attention module;
   Multi-scale convolution module; Conditional Random Field
AB Segmenting histopathological image automatically is an important task in computer-aided pathology analysis. However, it is challenging to segment and analyze digitalized histopathology images due to the large size of WSI, diversity and complexity of features. In this paper, we propose a multi-resolution attention and multi-scale convolution network (MAMC-Net) for the automatic tumor segmentation of WSI. First, the proposed MAMC-Net design the multi-resolution attention module that utilizes multi-resolution images as the pyramid inputs to generate a wider range feature information and richer details. Specifically, we employ an attention mechanism at each level to capture discriminative features related with the segmentation task. Furthermore, a multi-scale convolution module is designed to multi-scale feature representation by aggregating intact semantic information from the deep layer of encoder and high-resolution details from the final layer of decoder. To further obtain the accurate segmentation results, we adopt a fully connected Conditional Random Field (CRF) to splice the overlapping maps to avoid discontinuities and inconsistencies of cancer boundaries. Finally, we demonstrate the effectiveness of our framework on open-source datasets, including CAME-LYON17 (breast cancer metastases) and BOT (gastric cancer) datasets. The experimental results show that our proposed MAMC-Net obtains superior performance compared with other state-of-the-art methods, such as a Dice coefficient (DSC) of 0.929, an IOU score of 0.867, recall of 0.933 on the breast cancer dataset, a Dice coefficient (DSC) of 0.89, an IOU score of 0.802, recall of 0.903 on the gastric cancer dataset.
C1 [Zeng, Li; Tang, Hongzhong; Wang, Wei; Xie, Mingjian] Xiangtan Univ, Coll Automat & Elect Informat, Xiangtan 411105, Hunan, Peoples R China.
   [Tang, Hongzhong] Xiangtan Univ, Key Lab Intelligent Comp & Informat Proc, Minist Educ, Xiangtan 411105, Hunan, Peoples R China.
   [Ai, Zhaoyang] Hunan Univ, Coll Foreign Languages, Changsha 410082, Hunan, Peoples R China.
   [Ai, Zhaoyang] Hunan Univ, Interdisciplinary Res Ctr Language Intelligence &, Changsha 410082, Hunan, Peoples R China.
   [Chen, Lei] Hunan Univ Sci & Technol, Sch Informat & Elect Engn, Xiangtan 411201, Hunan, Peoples R China.
   [Wu, Yongjun] First Peoples Hosp Xiangtan City, Xiangtan 411101, Hunan, Peoples R China.
C3 Xiangtan University; Xiangtan University; Hunan University; Hunan
   University; Hunan University of Science & Technology
RP Tang, HZ (corresponding author), Xiangtan Univ, Coll Automat & Elect Informat, Xiangtan 411105, Hunan, Peoples R China.; Tang, HZ (corresponding author), Xiangtan Univ, Key Lab Intelligent Comp & Informat Proc, Minist Educ, Xiangtan 411105, Hunan, Peoples R China.
EM zl1997mojie@163.com; hongzhongtang@xtu.edu.cn; 1365287417@qq.com
RI Ai, Zhaoyang/G-4823-2016
OI Ai, Zhaoyang/0000-0002-3066-7733
FU Natural Science Foundation of Hunan Province in China [2020JJ4588,
   2020JJ4090]; Joint Fund for Regional Innovation and Development of
   National Natural Science Foundation in China [U19A2083]; Open Project of
   Key Laboratory of Intelligent Computing and Information Processing of
   Ministry of Education, Xiangtan University [2020ICIP06]
FX AcknowledgementsThis article was supported by Natural Science Foundation
   of Hunan Province in China (2020JJ4588, 2020JJ4090), Joint Fund for
   Regional Innovation and Development of National Natural Science
   Foundation in China (U19A2083), and Open Project of Key Laboratory of
   Intelligent Computing and Information Processing of Ministry of
   Education, Xiangtan University (2020ICIP06). We would especially like to
   thank Associate Professor Chaoyang Ai for his contributions to the
   English revision of this manuscript.
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Bullock J, 2019, PROC SPIE, V10953, DOI 10.1117/12.2512451
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Chen PJ, 2021, NEUROCOMPUTING, V453, P312, DOI 10.1016/j.neucom.2020.04.153
   Cho S, 2021, I S BIOMED IMAGING, P761, DOI 10.1109/ISBI48211.2021.9434105
   Coudray N, 2018, NAT MED, V24, P1559, DOI 10.1038/s41591-018-0177-5
   Das A, 2020, J DIGIT IMAGING, V33, P1091, DOI 10.1007/s10278-019-00295-z
   Feng RW, 2021, IEEE J BIOMED HEALTH, V25, P3700, DOI 10.1109/JBHI.2020.3040269
   Gu F, 2018, LECT NOTES COMPUT SC, V11039, P11, DOI 10.1007/978-3-030-00949-6_2
   Guo ZC, 2019, SCI REP-UK, V9, DOI [10.1038/s41598-018-37492-9, 10.1038/s41598-019-38952-6]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Khened M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-90444-8
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Lee H, 2020, IEEE T ULTRASON FERR, V67, P1344, DOI 10.1109/TUFFC.2020.2972573
   Li C. L., 2021, ARXIV
   Li ZQ, 2021, INT C PATT RECOG, P1918, DOI 10.1109/ICPR48806.2021.9412546
   Lin H, 2018, IEEE WINT CONF APPL, P539, DOI 10.1109/WACV.2018.00065
   Liu JH, 2020, NEUROCOMPUTING, V411, P139, DOI 10.1016/j.neucom.2020.06.017
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34
   Mehta S, 2018, LECT NOTES COMPUT SC, V11071, P893, DOI 10.1007/978-3-030-00934-2_99
   Mehta S, 2018, IEEE WINT CONF APPL, P663, DOI 10.1109/WACV.2018.00078
   Mills S., 2019, Histology for pathologists, V5th
   Nguyen C., 2021, ARXIV
   Pan Y, 2020, CLIN TRANSL MED, V10, DOI 10.1002/ctm2.129
   Rastogi P, 2022, NEURAL COMPUT APPL, V34, P5383, DOI 10.1007/s00521-021-06687-z
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schmitz R, 2021, MED IMAGE ANAL, V70, DOI 10.1016/j.media.2021.101996
   Sinha A, 2021, IEEE J BIOMED HEALTH, V25, P121, DOI 10.1109/JBHI.2020.2986926
   Spanhol FA, 2016, IEEE IJCNN, P2560, DOI 10.1109/IJCNN.2016.7727519
   Stoean R, 2020, NEURAL COMPUT APPL, V32, P313, DOI 10.1007/s00521-018-3709-5
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tao S, 2019, INT WORKSHOP HLTH IN, P149
   Teng L, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/8597606
   Tokunaga H, 2019, PROC CVPR IEEE, P12589, DOI 10.1109/CVPR.2019.01288
   van Rijthoven M, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101890
   Veta M, 2014, IEEE T BIO-MED ENG, V61, P1400, DOI 10.1109/TBME.2014.2303852
   Vidyarthi A, 2021, NEURAL COMPUT APPL, V33, P12989, DOI 10.1007/s00521-021-05947-2
   Wang D., 2016, arXiv
   Wang Y, 2018, LECT NOTES COMPUT SC, V11073, P523, DOI 10.1007/978-3-030-00937-3_60
   Zhang J, 2018, ARXIV
   Zhang JP, 2019, MED IMAGE ANAL, V54, P10, DOI 10.1016/j.media.2019.02.010
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng YS, 2021, IEEE T MED IMAGING, V40, P1090, DOI 10.1109/TMI.2020.3046636
NR 46
TC 1
Z9 1
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39349
EP 39369
DI 10.1007/s11042-023-15065-x
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000958668000005
DA 2024-07-18
ER

PT J
AU Jiang, HY
   Lyu, C
   Gao, YX
   Zhuang, YL
   Du, SJ
AF Jiang, Huaiying
   Lyu, Chen
   Gao, Yuexiu
   Zhuang, Yunliang
   Du, Sanjun
TI ADGSC: video anomaly detection algorithm based on graph structure change
   detection in public places
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph structure; DTW; Video anomaly detection; Median graph
AB In real life, the types of anomalous events are diverse and low-frequency, and the collection and labeling of training data is complex. However, most detection algorithms are based on training data and test data, which are difficult to adapt to various monitoring scenarios. In this paper, we propose a video A nomaly D etection algorithm based on G raph S tructure C hange detection, which we call ADGSC. Firstly, we use key frame technique to pre-process the video and enhance the pseudo-periodicity of the video data. Second, our approach proposes an improved DTW algorithm for pseudo-periodicity estimation, which transforms periodicity estimation into a global matching growth rate optimization problem. Thus, the periodicity calculation no longer requires a priori knowledge or parameter settings and can be automatically computed in practical applications. Then, we stitch the normalized HSV histogram and HOG feature descriptors into feature vectors following the period obtained in the previous step for feature extraction of key frames. Further, a sliding window is used to build a graph model to measure the temporal variation of the video data, and median plot denoising is used to reduce the errors caused by feature extraction and metric methods, reduce background, blur and other noise interference, and improve the detection effect. Finally, we use box-line plots and box-line graphs to make decisions. Since we do not use deep learning methods, the evaluation metrics AUC and ROC applied for deep learning are no longer applicable to this method. Instead, our experiments use precision, recall, and F-value, which are commonly used in anomaly detection, to measure the effectiveness of our method. Experiment results show that our algorithm outperforms other current algorithms with unsupervised, adaptive, fault-tolerant, and real-time performance.
C1 [Jiang, Huaiying; Lyu, Chen; Gao, Yuexiu; Zhuang, Yunliang] Shandong Normal Univ, Sch Informat Sci & Engn, Shandong Prov Key Lab Distributed Comp Software No, Jinan 250014, Peoples R China.
   [Du, Sanjun] Hisense TransTech Co Ltd, Hisense Tower,17 Donghai Xi Rd, Qingdao 266071, Peoples R China.
C3 Shandong Normal University; Hisense
RP Lyu, C (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Shandong Prov Key Lab Distributed Comp Software No, Jinan 250014, Peoples R China.
EM lvchen@sdnu.edu.cn
RI Wang, Yibin/KEZ-9645-2024; li, xinyi/KEI-6391-2024; Ma,
   Wei/JXY-5019-2024; yu, hui/KDO-3946-2024
OI Ma, Wei/0000-0002-7344-998X; 
CR Benvenuto D, 2020, DATA BRIEF, V29, DOI 10.1016/j.dib.2020.105340
   Chatfield C., 1978, Journal of the Royal Statistical Society: Series C (Applied Statistics), V27, P264, DOI 10.2307/2347162
   Chen TT, 2022, IEEE J BIOMED HEALTH, V26, P1411, DOI 10.1109/JBHI.2021.3100367
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Contreras J, 2003, IEEE T POWER SYST, V18, P1014, DOI 10.1109/TPWRS.2002.804943
   Cui XY, 2011, PROC CVPR IEEE
   Dan Xu, 2015, ARXIV
   Dehmer M, 2011, INFORM SCIENCES, V181, P57, DOI 10.1016/j.ins.2010.08.041
   Feixiang Gong, 2020, 2020 Asia Energy and Electrical Engineering Symposium (AEEES), P1002, DOI 10.1109/AEEES48850.2020.9121548
   Gandhi T, 2007, IEEE T INTELL TRANSP, V8, P413, DOI 10.1109/TITS.2007.903444
   Gao HH, 2023, IEEE T NETW SCI ENG, V10, P2978, DOI 10.1109/TNSE.2022.3163144
   Gao HH, 2024, IEEE T NEUR NET LEAR, V35, P4826, DOI 10.1109/TNNLS.2022.3155486
   Gao HH, 2022, IEEE T COMPUT SOC SY, V9, P336, DOI 10.1109/TCSS.2021.3102591
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hu Y, 2013, IEEE COMPUT SOC CONF, P767, DOI 10.1109/CVPRW.2013.115
   Huang KQ, 2010, PATTERN RECOGN LETT, V31, P2265, DOI 10.1016/j.patrec.2010.05.029
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Jian MW, 2021, INFORM SCIENCES, V576, P819, DOI 10.1016/j.ins.2021.08.069
   Jian MW, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114219
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P29099, DOI 10.1007/s11042-018-6122-2
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jiang XY, 2001, IEEE T PATTERN ANAL, V23, P1144
   Jordan MI, 2004, STAT SCI, V19, P140, DOI 10.1214/088342304000000026
   KRUBSACK DA, 1991, IEEE T SIGNAL PROCES, V39, P319, DOI 10.1109/78.80814
   Li HL, 2021, INFORM SCIENCES, V547, P592, DOI 10.1016/j.ins.2020.08.089
   [柳晶晶 Liu Jingjing], 2016, [信号处理, Journal of Signal Processing], V32, P1
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Lu GL, 2018, MECH SYST SIGNAL PR, V99, P73, DOI 10.1016/j.ymssp.2017.06.003
   Lu X., 2020, ECCV, V12348, P661, DOI DOI 10.1007/978-3-030-58580-8_39
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Mohamed AA, 2022, IMAGE VISION COMPUT, V124, DOI 10.1016/j.imavis.2022.104488
   Mubashir M, 2013, NEUROCOMPUTING, V100, P144, DOI 10.1016/j.neucom.2011.09.037
   Muller M., 2007, Information retrieval for music and motion, P69, DOI [10.1007/978-3-540-74048-3_4, DOI 10.1007/978-3-540-74048-3_4]
   Noureen S, 2019, MIDWEST SYMP CIRCUIT, P521, DOI [10.1109/MWSCAS.2019.8885349, 10.1109/mwscas.2019.8885349]
   Ribeiro RCM., 2019, INT J INNOV ED RES, V7, P119, DOI [10.31686/ijier.vol7.iss6.1559, DOI 10.31686/IJIER.VOL7.ISS6.1559]
   Sodemann AA, 2012, IEEE T SYST MAN CY C, V42, P1257, DOI 10.1109/TSMCC.2012.2215319
   Spielman DA, 2007, ANN IEEE SYMP FOUND, P29, DOI 10.1109/FOCS.2007.56
   Tae HK, 2016, ARXIV
   Taylor SJ, 2018, AM STAT, V72, P37, DOI 10.1080/00031305.2017.1380080
   Teh Yee Whye., 2003, Bethe Free Energy and Contrastive Divergence Approximations for Undirected Graphical Models
   Thirumalai C, 2017, 2017 INTERNATIONAL CONFERENCE OF ELECTRONICS, COMMUNICATION AND AEROSPACE TECHNOLOGY (ICECA), VOL 2, P598, DOI 10.1109/ICECA.2017.8212735
   Tirkes G, 2017, TEH VJESN, V24, P503, DOI 10.17559/TV-20160615204011
   Trull O, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8020268
   Ullah Habib, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12664), P131, DOI 10.1007/978-3-030-68799-1_10
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Xiao JS, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3419842
   Zhang YH, 2012, IEEE IMAGE PROC, P2689, DOI 10.1109/ICIP.2012.6467453
NR 48
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38923
EP 38945
DI 10.1007/s11042-023-15009-5
EA MAR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000983485500016
DA 2024-07-18
ER

PT J
AU Ingaleshwar, SS
   Jayadevappa, D
   Dharwadkar, NV
AF Ingaleshwar, Subodh S.
   Jayadevappa, D.
   Dharwadkar, Nagaraj V.
TI Sine cosine bird swarm algorithm-based deep convolution neural network
   for reversible medical video watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Privacy; Data embedding; Extraction process; Video watermarking;
   Multimedia; Compression; Information hiding
ID HVS
AB Recently, advancements in multimedia have made a huge impact on watermarking technologies. The digital video watermarking is the process of embedding the data in the video. One of the major concerns in digital video watermarking is maintaining the quality of video besides preserving the privacy of the data. The aim of the research is to develop a reversible medical video watermarking using Sine Cosine Bird Swarm Algorithm-based Deep Convolutional Neural Network (SCBSA-based Deep CNN) for embedding the secret message in video frames. The development methodology is explained as follows. The SCBSA is developed by integrating Sine Cosine Algorithm (SCA) with the Bird Swarm Algorithm (BSA). The key frames are extracted from the input video using Minkowski distance and Wavelet distance. The features, like Neighborhood-based features, Convolutional Neural Network (CNN) features, Local Optimal Oriented Pattern (LOOP), and histogram features are obtained from the key frames. The interesting region is identified using DCNN, which is trained using the developed SCBSA. The secret message is embedded in the video in the embedding phase, whereas the embedded secret message is extracted in the extraction phase. The embedding and extracting process are carried out through two level decompositions using wavelet transform and inverse wavelet transform. The developed SCBSA-based Deep CNN uses the metrics, such as correlation coefficient, Mean Square Error and Peak signal-to-noise ratio (PSNR) for evaluating the performance. The developed SCBSA method is evaluated using the Mean Square Error, Correlation Coefficient and PSNR with Gaussian noise, Impulse noise, Salt and Pepper noise and in the absence of noise. The developed SCBSA method obtained a maximum correlation coefficient of 0.8990, minimum Mean Square Error of 0.0215 and maximum PSNR of 35.19, respectively while comparing with the existing reversible medical video watermarking methods.
C1 [Ingaleshwar, Subodh S.; Jayadevappa, D.] Visvesvaraya Technol Univ, JSS Acad Tech Educ, Dept Elect & Instrumentat Engn, Bengaluru 560060, India.
   [Dharwadkar, Nagaraj V.] Shivaji Univ, Rajarambapu Inst Technol, Dept Comp Sci & Engn, Sakharale 415414, Maharashtra, India.
C3 Visvesvaraya Technological University; Shivaji University
RP Ingaleshwar, SS (corresponding author), Visvesvaraya Technol Univ, JSS Acad Tech Educ, Dept Elect & Instrumentat Engn, Bengaluru 560060, India.
EM subodh.ingleshwar@gmail.com; devappa22@gmail.com;
   nagaraj.dharwadkar@gmail.com
RI Dharwadkar, Nagaraj V./AGQ-4597-2022
OI Dharwadkar, Nagaraj V./0000-0003-3017-0011; Ingaleshwar,
   Subodh/0000-0002-4425-1317
CR Agarwal H., 2019, INT C ADV COMPUTING, P655
   Zhang KA, 2019, Arxiv, DOI arXiv:1909.01285
   [Anonymous], NBI INFFRAMES DATASE
   Asikuzzaman M, 2018, IEEE T CIRC SYST VID, V28, P2131, DOI 10.1109/TCSVT.2017.2712162
   Ayubi P, 2021, ARTIF INTELL REV, V54, P1237, DOI 10.1007/s10462-020-09877-8
   Bagheri M., 2020, ADAPTIVE CONTROL EMB
   Bahrami Z, 2018, MULTIMED TOOLS APPL, V77, P327, DOI 10.1007/s11042-016-4226-0
   Barati M, 2015, INT C ULTRA MOD TELE, P1, DOI 10.1109/ICUMT.2015.7382395
   Boisvert J, 2015, PATTERN RECOGN, V48, P720, DOI 10.1016/j.patcog.2014.06.001
   Caragata D, 2016, AEU-INT J ELECTRON C, V70, P777, DOI 10.1016/j.aeue.2016.03.001
   Chakraborti T, 2017, LOOP DESCRIPTOR LOCA, P1
   Chan ADC, 2008, IEEE T INSTRUM MEAS, V57, P248, DOI 10.1109/TIM.2007.909996
   Das S, 2020, MICROPROCESS MICROSY, V76, DOI 10.1016/j.micpro.2020.103092
   Ding H, 2021, IEEE ACCESS, V9, P35324, DOI 10.1109/ACCESS.2021.3062468
   Esfahani R, 2019, MULTIMED TOOLS APPL, V78, P16159, DOI 10.1007/s11042-018-6892-6
   Fadoua S., 2020, 2020 1 INT C INNOVAT, P1
   He DJ, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, P814
   Ingaleshwar S, 2023, MULTIMED TOOLS APPL, V82, P21957, DOI 10.1007/s11042-020-10498-0
   Juneja K., 2019, International Journal of Computing, V18, P207
   Kuraparthi S, 2019, TRAIT SIGNAL, V36, P565, DOI 10.18280/ts.360612
   Li Z, 2019, IEEE ACCESS, V7, P84020, DOI 10.1109/ACCESS.2019.2899378
   Lin ET, 2004, IEEE T SIGNAL PROCES, V52, P3007, DOI 10.1109/TSP.2004.833866
   Loganathan A, 2016, EXPERT SYST APPL, V63, P412, DOI 10.1016/j.eswa.2016.05.019
   Meng XB, 2016, J EXP THEOR ARTIF IN, V28, P673, DOI 10.1080/0952813X.2015.1042530
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Rouhani B.D., 2018, DeepSigns: a generic watermarking framework for protecting the ownership of deep learning models
   Sakib MN, 2020, INT J IMAGE GRAPH, V20, DOI 10.1142/S0219467820500047
   Sharma VK, 2022, J KING SAUD UNIV-COM, V34, P615, DOI 10.1016/j.jksuci.2019.03.009
   Tian LH, 2020, MULTIMED TOOLS APPL, V79, P1759, DOI 10.1007/s11042-019-08256-y
   Tu FB, 2017, IEEE T VLSI SYST, V25, P2220, DOI 10.1109/TVLSI.2017.2688340
   Wagdarikar AMU, 2019, J INF SECUR APPL, V49, DOI 10.1016/j.jisa.2019.102393
   Yoo J, 2014, PATTERN RECOGN, V47, P3006, DOI 10.1016/j.patcog.2014.02.016
   Zhang LN, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107421
NR 33
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 18
PY 2023
DI 10.1007/s11042-023-14495-x
EA MAR 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A0QJ4
UT WOS:000952258900005
DA 2024-07-18
ER

PT J
AU Dwivedy, V
   Roy, PK
AF Dwivedy, Vishwajeet
   Roy, Pradeep Kumar
TI Deep feature fusion for hate speech detection: a transfer learning
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hate speech; Multimodal; Feature fusion; Social network; Deep learning;
   Machine learning
AB Social platforms are receiving many posts from the hate speech category. These social posts affect societal order and impact the reader's mental and emotional state, sometimes even leading to suicide. Hence, detecting hate speech posts from social media at the right time plays a crucial role in restraining the spread of hate speech. This paper presents a multimodal architecture consisting of a concatenated transfer learning model and LSTM based model to classify social media posts into hate speech and non-hate speech. The proposed model simultaneously considers text and images to understand their context and intent to predict hate in the post. The image and text features were fused to create a multimodal architecture to predict hate or non-hate speech from social media posts. Separate models for the text and image were also investigated and found the fusion of image and text information provided promising prediction outcomes by outperforming the base model.
C1 [Dwivedy, Vishwajeet; Roy, Pradeep Kumar] Indian Inst Informat Technol, Surat, Gujarat, India.
RP Roy, PK (corresponding author), Indian Inst Informat Technol, Surat, Gujarat, India.
EM vdwivedy.17sep2000@gmail.com; pkroynitp@gmail.com
RI Roy, Pradeep/W-8259-2018
CR Al-Zoubi AM, 2018, KNOWL-BASED SYST, V153, P91, DOI 10.1016/j.knosys.2018.04.025
   Almeida TA, 2016, KNOWL-BASED SYST, V108, P25, DOI 10.1016/j.knosys.2016.05.001
   Aroyehun S.T., 2018, Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC-2018), P90
   Arroyo-Fernandez I., 2018, Proceedings of the first workshop on trolling, aggression and cyberbullying (TRAC-2018), P140
   Ayo FE, 2021, EXPERT SYST APPL, V173, DOI 10.1016/j.eswa.2021.114762
   Campbell M.A., 2005, Australian Journal of Guidance and Counselling, V15, P68, DOI [10.1375/ajgc.15.1.68, DOI 10.1375/AJGC.15.1.68]
   Chatzakou D, 2017, PROCEEDINGS OF THE 2017 ACM WEB SCIENCE CONFERENCE (WEBSCI '17), P13, DOI 10.1145/3091478.3091487
   Chen JK, 2018, NANO ENERGY, V51, P1, DOI 10.1016/j.nanoen.2018.06.029
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Cohen Y, 2018, KNOWL-BASED SYST, V142, P241, DOI 10.1016/j.knosys.2017.11.040
   Davidson T., 2017, 11 INT AAAI C WEB SO
   Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379
   Gao Lei, 2017, ARXIV171007395
   Gomez R, 2020, IEEE WINT CONF APPL, P1459, DOI 10.1109/WACV45572.2020.9093414
   Griffin Christopher, 2016, P 25 INT JOINT C ART, P3952
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hosseinmardi H., 2015, ARXIV
   Hosseinmardi H, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P186, DOI 10.1109/ASONAM.2016.7752233
   Kapil P, 2020, KNOWL-BASED SYST, V210, DOI 10.1016/j.knosys.2020.106458
   Kumar A, 2021, TOP ORGANOMETAL CHEM, V68, P1, DOI 10.1007/3418_2020_67
   Kumar R, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON VISION, IMAGE AND SIGNAL PROCESSING (ICVISP 2018), DOI 10.1145/3271553.3271617
   Kumari K, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3907
   Kumari K, 2020, SOFT COMPUT, V24, P11059, DOI 10.1007/s00500-019-04550-x
   Lu D, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1990
   Plaza-del-Arco FM, 2021, EXPERT SYST APPL, V166, DOI 10.1016/j.eswa.2020.114120
   Modha S., 2018, P 1 WORKSH TROLL AGG, P199
   Modha S, 2020, EXPERT SYST APPL, V161, DOI 10.1016/j.eswa.2020.113725
   Nikhil N., 2018, P 1 WORKSH TROLL AGG, P52
   Nobata C, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P145, DOI 10.1145/2872427.2883062
   Pamungkas EW, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, P363
   Park J.H., 2017, arXiv
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Raiyani Kashyap., 2018, Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC-2018), P28
   Risch J., 2018, Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC-2018), P150
   Roy PK, 2020, IEEE ACCESS, V8, P204951, DOI 10.1109/ACCESS.2020.3037073
   Roy PK, 2020, FUTURE GENER COMP SY, V102, P524, DOI 10.1016/j.future.2019.09.001
   Samghabadi NS, 2018, ARXIV
   Schmidt A., 2017, P 5 INT WORKSH NAT L, P1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh Vivek K., 2017, P 2017 CHI C HUM FAC, P2090
   Srivastava S., 2018, P 1 WORKSHOP TROLLIN, P98
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan M., 2020, INT C MACH LEARN, DOI DOI 10.48550/ARXIV.1905.11946
   Vijayaraghavan P, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P478, DOI 10.18653/v1/P17-2076
   Wang LW, 2019, IEEE T PATTERN ANAL, V41, P394, DOI 10.1109/TPAMI.2018.2797921
   Wang Q, 2021, PROBIOTICS ANTIMICRO, V13, P1093, DOI 10.1007/s12602-021-09743-1
   Wang Q, 2018, IEEE T INTELL TRANSP, V19, P1457, DOI 10.1109/TITS.2017.2726546
   Waseem D., 2016, P NAACL STUD RES WOR, P88, DOI [DOI 10.18653/V1/N16-2013, DOI 10.18653/V1/N16]
   Waseem Zeerak, 2016, P 1 WORKSHOP NLP COM, P138, DOI DOI 10.18653/V1/W16-5618
   Williams ML, 2020, BRIT J CRIMINOL, V60, P93, DOI 10.1093/bjc/azz049
   Yang F, 2019, THIRD WORKSHOP ON ABUSIVE LANGUAGE ONLINE, P11
   Yu DG, 2017, KNOWL-BASED SYST, V125, P64, DOI 10.1016/j.knosys.2017.03.025
   Zhang W., 2020, arXiv
   Zhang ZQ, 2019, SEMANT WEB, V10, P925, DOI 10.3233/SW-180338
   Zhang ZQ, 2018, LECT NOTES COMPUT SC, V10843, P745, DOI 10.1007/978-3-319-93417-4_48
   Zhao R, 2017, IEEE T AFFECT COMPUT, V8, P328, DOI 10.1109/TAFFC.2016.2531682
   Zhou Y, 2022, PREP BIOCHEM BIOTECH, V52, P681, DOI 10.1080/10826068.2021.1986720
NR 59
TC 3
Z9 3
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36279
EP 36301
DI 10.1007/s11042-023-14850-y
EA MAR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000953336200014
DA 2024-07-18
ER

PT J
AU Khurana, K
   Deshpande, U
AF Khurana, Khushboo
   Deshpande, Umesh
TI Two stream multi-layer convolutional network for keyframe-based video
   summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Deep learning; Video summarization; Keyframe
   extraction; Two-stream network; Multi-layer features
ID ONLINE
AB In this paper, we propose an unsupervised static video summarization method that extracts keyframes representing the entire video. A two-stream method is presented, that extracts motion and visual features from the video. Features are also considered from different levels of abstraction for the visual stream by performing multi-level feature extraction and fusion. The utilization of features from different layers facilitates better frame representation by focusing on both coarse and fine-grained details of the frames. Neighborhood peak detection and redundancy removal algorithms are then applied to the fused features to produce the final keyframes representing the video summary. The proposed method particularly aims towards the summarization of industrial surveillance videos. Extensive experimentation is performed on both domain-specific as well as domain-independent datasets, to demonstrate the wide applicability of the proposed model. Results of the experimentation on publicly available benchmark datasets namely, OVP and YouTube, show an increase in the F-score as compared to other unsupervised methods. We also report results on a new dataset that we created from the CCTV footage of an industry. The results show that the proposed method outperforms the existing methods by about 10% in terms of the F-score.
C1 [Khurana, Khushboo] Shri Ramdeobaba Coll Engn & Management, Dept Comp Sci & Engn, Nagpur, Maharashtra, India.
   [Deshpande, Umesh] Visvesvaraya Natl Inst Technol VNIT, Dept Comp Sci & Engn, Nagpur, Maharashtra, India.
C3 Rashtrasant Tukadoji Maharaj Nagpur University; Shri Ramdeobaba College
   of Engineering & Management; National Institute of Technology (NIT
   System); Visvesvaraya National Institute of Technology, Nagpur
RP Khurana, K (corresponding author), Shri Ramdeobaba Coll Engn & Management, Dept Comp Sci & Engn, Nagpur, Maharashtra, India.
EM khuranakpk@gmail.com; uadeshpande@cse.vnit.ac.in
RI Deshpande, Umesh/AAW-1163-2020; Khurana, Khushboo/AAE-5452-2020
OI Khurana, Khushboo/0000-0002-4751-1778
CR Abd-Almageed W, 2008, IEEE IMAGE PROC, P3200, DOI 10.1109/ICIP.2008.4712476
   Almeida J, 2012, PATTERN RECOGN LETT, V33, P397, DOI 10.1016/j.patrec.2011.08.007
   Asim M., 2018, 2018 COL VIS COMP S, P1, DOI [10.1109/CVCS.2018.8496473, DOI 10.1109/CVCS.2018.8496473]
   Chatfield K., 2014, ARXIV
   Cong Y, 2017, IEEE T IMAGE PROCESS, V26, P185, DOI 10.1109/TIP.2016.2619260
   Datt M, 2018, IEEE IMAGE PROC, P1268, DOI 10.1109/ICIP.2018.8451282
   DeMenthon D., 1998, Proceedings ACM Multimedia 98, P211, DOI 10.1145/290747.290773
   Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Fu TJ, 2019, IEEE WINT CONF APPL, P1579, DOI 10.1109/WACV.2019.00173
   Furini M, 2007, P 6 ACM INT C IM VID, P635
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Gong BQ, 2014, ADV NEUR IN, V27
   GOODALE MA, 1992, TRENDS NEUROSCI, V15, P20, DOI 10.1016/0166-2236(92)90344-8
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He XF, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2296, DOI 10.1145/3343031.3351056
   Herranz L, 2009, IEEE INT CON MULTI, P654, DOI 10.1109/ICME.2009.5202581
   Huang C, 2020, IEEE T CIRC SYST VID, V30, P577, DOI 10.1109/TCSVT.2019.2890899
   Jadon Shruti, 2020, 2020 IEEE 5th International Conference on Computing Communication and Automation (ICCCA), P140, DOI 10.1109/ICCCA49541.2020.9250764
   Ji Z, 2020, IEEE T CIRC SYST VID, V30, P1709, DOI 10.1109/TCSVT.2019.2904996
   Jiang YD, 2019, IEEE INT CONF COMP V, P1562, DOI 10.1109/ICCVW.2019.00195
   Jung Y, 2019, AAAI CONF ARTIF INTE, P8537
   Kang H.-W., 2006, P IEEE C COMP VIS PA, P1331, DOI [DOI 10.1109/CVPR.2006.284, 10.1109/cvpr.2006.2842, DOI 10.1109/CVPR.2006.2842, 10.1109/cvpr.2006.284]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuanar SK, 2013, J VIS COMMUN IMAGE R, V24, P1212, DOI 10.1016/j.jvcir.2013.08.003
   Kwon H, 2019, IEEE INT CONF COMP V, P0
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Li EZ, 2017, IEEE T GEOSCI REMOTE, V55, P5653, DOI 10.1109/TGRS.2017.2711275
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Ma CH, 2019, IEEE ACCESS, V7, P121685, DOI 10.1109/ACCESS.2019.2936215
   Mahasseni B, 2017, PROC CVPR IEEE, P2077, DOI 10.1109/CVPR.2017.224
   Martins GB, 2014, LECT NOTES COMPUT SC, V8827, P893, DOI 10.1007/978-3-319-12568-8_108
   Martins GB, 2016, SIBGRAPI, P335, DOI [10.1109/SIBGRAPI.2016.50, 10.1109/SIBGRAPI.2016.053]
   Mathews RP, 2021, ARXIV
   Muhammad K, 2020, IEEE T IND INFORM, V16, P5938, DOI 10.1109/TII.2019.2960536
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Niu YL, 2019, IEEE T IMAGE PROCESS, V28, P1720, DOI 10.1109/TIP.2018.2881928
   Open Video Project, 2021, ABOUT US
   Pass G., 1996, P 4 ACM INT C MULT, V96, P65, DOI DOI 10.1145/244130.244148
   Pritch Y, 2008, IEEE T PATTERN ANAL, V30, P1971, DOI 10.1109/TPAMI.2008.29
   Rochan M, 2018, LECT NOTES COMPUT SC, V11216, P358, DOI 10.1007/978-3-030-01258-8_22
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sugano M, 2002, IEEE IMAGE PROC, P956
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Takahashi Y, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1171
   Tiwari V, 2021, MULTIMED TOOLS APPL, V80, P27187, DOI 10.1007/s11042-021-10977-y
   Wang M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356520
   Wang WZ, 2017, IEEE IMAGE PROC, P2408, DOI 10.1109/ICIP.2017.8296714
   Wei HW, 2018, AAAI CONF ARTIF INTE, P216
   Wu JX, 2017, MULTIMED TOOLS APPL, V76, P9625, DOI 10.1007/s11042-016-3569-x
   Yan X., 2018, ARXIV
   Yang H, 2015, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2015.526
   Yao Ting, 2016, PROC CVPR IEEE, P982, DOI DOI 10.1109/CVPR.2016.112
   Zhang K, 2016, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2016.120
   Zhang K, 2016, LECT NOTES COMPUT SC, V9911, P766, DOI 10.1007/978-3-319-46478-7_47
   Zhang Y, 2019, P ACM TURING CELEBRA, P1
   Zhang YJ, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040750
   Zhao Y, 2020, MULTIMED TOOLS APPL, V79, P33417, DOI 10.1007/s11042-019-7582-8
   Zhou KY, 2018, AAAI CONF ARTIF INTE, P7582
NR 64
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38467
EP 38508
DI 10.1007/s11042-023-14665-x
EA MAR 2023
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000950429600003
DA 2024-07-18
ER

PT J
AU Yildirim, S
   Chimeumanu, MS
   Rana, ZA
AF Yildirim, Suleyman
   Chimeumanu, Meshack Sandra
   Rana, Zeeshan A.
TI The influence of micro-expressions on deception detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Micro-expressions; Deception detection; Machine learning
ID FACIAL EXPRESSION; RECOGNITION; ACCURACY; BELIEFS; CUES; LIE
AB Facial micro-expressions are universal symbols of emotions that provide cohesion to interpersonal communication. At the same time, the changes in micro-expressions are considered to be the most important hints in the psychology of emotion. Furthermore, analysis and recognition of these micro-expressions have pervaded in various areas such as security and psychology. In security-related matters, micro-expressions are widely used to detect deception. In this research, a deep learning model that interprets the changes in the face into meaningful information has been trained using The Facial Expression Recognition 2013 dataset. Necessary data is also obtained through live stream or video stream by detecting via computer vision and evaluating with the trained model. Finally, the data obtained is transformed into graphic and interpreted to determine whether the people are trying to deceive or not. The deception classification accuracy of the custom trained model is 74.17% and the detection of the face with high precision using the computer vision methods increased the accuracy of the obtained data and provided it to be interpreted correctly. In this respect, the study differs from other studies using the same dataset. In addition, it is aimed to facilitate the deception detection which is performed in a complex and expensive way, by making it simple and understandable.
C1 [Yildirim, Suleyman] Cranfield Univ, Digital Aviat Res & Technol Ctr DARTeC, Cranfield MK43 0AL, England.
   [Chimeumanu, Meshack Sandra] Cranfield Univ, Sch Aerosp Transport & Mfg SATM, Cranfield MK43 0AL, England.
   [Rana, Zeeshan A.] Cranfield Univ, Ctr Aeronaut, Cranfield MK43 0AL, England.
C3 Cranfield University; Cranfield University; Cranfield University
RP Yildirim, S (corresponding author), Cranfield Univ, Digital Aviat Res & Technol Ctr DARTeC, Cranfield MK43 0AL, England.
EM suleyman.yildirim@cranfield.ac.uk; meshacksandra@gmail.com;
   zeeshan.rana@cranfield.ac.uk
RI YILDIRIM, Suleyman/IXW-5480-2023; Rana, Zeeshan/G-6758-2011
OI YILDIRIM, Suleyman/0000-0001-7094-2130; Rana,
   Zeeshan/0000-0001-7839-3949
FU Republic of Turkey; Ministry of National Education and Niger Delta
   Development Commission; Federal Republic of Nigeria through grants
FX Cranfield University's High Performance Technical Computing (HPC) system
   where the computation of the model was run. This project was supported
   by Republic of Turkey, Ministry of National Education and Niger Delta
   Development Commission, Federal Republic of Nigeria through grants
   awarded to the first and second authors respectively.
CR Al-modwahi AAM, 2012, P WORLD C COMP SCI C
   Alvino C, 2007, J NEUROSCI METH, V163, P350, DOI 10.1016/j.jneumeth.2007.03.002
   [Anonymous], 2000, Detecting lies and deceit: the psychology of lying and implications for professional practice
   [Anonymous], 2014, INT J COMPUT APPL
   Baltrusaitis T, 2016, IEEE WINT CONF APPL
   Bengio Y., 2013, Fer-2013 face database
   Bond CF, 2006, PERS SOC PSYCHOL REV, V10, P214, DOI 10.1207/s15327957pspr1003_2
   Butalia A., 2012, International Journal of Modern Engineering Research, P1449
   Chebbi S, 2023, MULTIMED TOOLS APPL, V82, P13073, DOI 10.1007/s11042-021-11148-9
   Crockett K, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207684
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Darwin C., 1872, P374
   Delmas H, 2019, J NONVERBAL BEHAV, V43, P59, DOI 10.1007/s10919-018-0285-4
   DePaulo BM, 2003, PSYCHOL BULL, V129, P74, DOI 10.1037//0033-2909.129.1.74
   Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905
   Ekman P., 2009, Telling lies: Clues to deceit in the marketplace, politics, and marriage
   Ekman P., 1982, HDB METHODS NONVERBA, P45, DOI DOI 10.1017/S0142716400004641
   Ekman P., 1978, Facial action coding system
   Eyben F., 2015, ACM SIGMULTIMEDIA RE, V6, P4, DOI [10.1145/2729095.2729097, DOI 10.1145/2729095.2729097]
   Feng S., 2012, P 50 ANN M ASS COMP, V2, P171
   FORKOSCH MD, 1975, OKLA LAW REV, V28, P288
   Frank MG, 2001, J PERS SOC PSYCHOL, V80, P75, DOI 10.1037/0022-3514.80.1.75
   GAEBEL W, 1992, EUR ARCH PSY CLIN N, V242, P46, DOI 10.1007/BF02190342
   Gannon TA, 2009, RISK ASSESSMENT POLY, P129
   Gogate M, 2017, 2017 IEEE S SERIES C, P1, DOI [DOI 10.1109/SSCI.2017.8285382, 10.1109/SSCI.2017.8285382]
   Granhag P.A., 2004, DETECTION DECEPTION
   Guanming Lu, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P756, DOI 10.1109/CSSE.2008.1321
   Guanming Lu, 2008, 2008 International Conference on Neural Networks and Signal Processing, P456, DOI 10.1109/ICNNSP.2008.4590392
   Gupte A., 2016, INT J ADV ENG RES SC, V3, DOI 10.22161/ijaers/3.9.30
   Hachisuka S, 2013, 2013 INTERNATIONAL CONFERENCE ON BIOMETRICS AND KANSEI ENGINEERING (ICBAKE), P320, DOI 10.1109/ICBAKE.2013.89
   Hartwig M, 2006, LAW HUMAN BEHAV, V30, P603, DOI 10.1007/s10979-006-9053-9
   Hill ML, 2004, CLIN J PAIN, V20, P415, DOI 10.1097/00002508-200411000-00006
   Hirschberg J., 2005, INTERSPEECH 2005 LIS, P1833, DOI DOI 10.1159/.8634
   Jabon ME, 2011, IEEE PERVAS COMPUT, V10, P84, DOI 10.1109/MPRV.2010.46
   Jaiswal M, 2016, INT CONF DAT MIN WOR, P938, DOI [10.1109/ICDMW.2016.0137, 10.1109/ICDMW.2016.156]
   Karimi H, 2018, IEEE INT CONF BIG DA, P1278, DOI 10.1109/BigData.2018.8621909
   Lv XQ, 2007, 2007 INTERNATIONAL CONFERENCE ON INFORMATION ACQUISITION, VOLS 1 AND 2, P4, DOI 10.1109/ICIA.2007.4295687
   MEHRABIA.A, 1969, BEHAV RES METH INSTR, V1, P203
   Newman ML, 2003, PERS SOC PSYCHOL B, V29, P665, DOI 10.1177/0146167203029005010
   Owayjan M, 2012, 2012 2ND INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTATIONAL TOOLS FOR ENGINEERING APPLICATIONS (ACTEA), P33, DOI 10.1109/ICTEA.2012.6462897
   Pérez-Rosas V, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P59, DOI 10.1145/2818346.2820758
   Perez-Rosas Veronica., 2015, Proceedings of the 2015 conference on empirical methods in natural language processing, P2336
   Porter S, 2012, J NONVERBAL BEHAV, V36, P23, DOI 10.1007/s10919-011-0120-7
   Porter S, 2010, LEGAL CRIMINOL PSYCH, V15, P57, DOI 10.1348/135532509X433151
   RUSSELL JA, 1994, PSYCHOL BULL, V115, P102, DOI 10.1037/0033-2909.115.1.102
   Su L, 2016, COMPUT VIS IMAGE UND, V147, P52, DOI 10.1016/j.cviu.2016.01.009
   Su L, 2014, INT C PATT RECOG, P2519, DOI 10.1109/ICPR.2014.435
   Thannoon HH., 2019, Journal of Engineering and Applied Sciences, V14, P5002, DOI DOI 10.36478/JEASCI.2019.5002.5011
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   Vrij A, 2000, J NONVERBAL BEHAV, V24, P239, DOI 10.1023/A:1006610329284
   Vrij A, 1996, J NONVERBAL BEHAV, V20, P65, DOI 10.1007/BF02248715
   Yacoob Y, 1996, IEEE T PATTERN ANAL, V18, P636, DOI 10.1109/34.506414
   Zhang ZY, 1999, INT J PATTERN RECOGN, V13, P893, DOI 10.1142/S0218001499000495
NR 53
TC 1
Z9 1
U1 7
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29115
EP 29133
DI 10.1007/s11042-023-14551-6
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000950119900002
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Qian, K
   Li, YH
   Xu, H
   Xu, XG
   Zhang, JL
   Dong, KM
   Li, H
AF Qian, Kun
   Li, Yinghua
   Xu, Hao
   Xu, Xinggui
   Zhang, Jialing
   Dong, Keming
   Li, Hong
TI Normal mapping and normal transfer for geometric dynamic models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Normal mapping; Parameterization; Surface registration; Dynamic normal
   information
ID OPTIMAL MASS-TRANSPORT
AB Normal mapping is one of the most important realistic rendering techniques that preserve geometric attribute values on the simplified model. There are many normal mapping methods that address static objects, but few about dynamic objects. In this work, we introduce a dynamic normal mapping technique that relies on an efficient area-preserving parameterization and registration method. This method is based on variational approach theory with a solid theoretical foundation. Our method provides an alternative solution to display dynamic models with fine visualization, and the experimental results suggest that this method can reduce the calculation time effectively while maintaining the geometric details of the dynamic model than a state-of-the-art algorithm.
C1 [Qian, Kun; Xu, Hao; Xu, Xinggui; Dong, Keming; Li, Hong] Yunnan Univ Finance & Econ, Sch Informat, 355 Longquan Rd, Kunming 650224, Peoples R China.
   [Li, Yinghua] Huizhou Univ, Sch Math & Stat, 46 Yanda Rd, Huizhou 516007, Peoples R China.
   [Zhang, Jialing] Kunming Univ Sci & Technol, Fac Sci, 727 South Jingming Rd, Kunming 650500, Peoples R China.
C3 Yunnan University of Finance & Economics; Huizhou University; Kunming
   University of Science & Technology
RP Li, YH (corresponding author), Huizhou Univ, Sch Math & Stat, 46 Yanda Rd, Huizhou 516007, Peoples R China.
EM yinghli@gmail.com
RI Li, Yinghua/AAU-7351-2021
FU Yunnan Fundamental Research Projects [:202201AT070166]; Scientific
   Research Foundation of Yunnan Provincial Department of Education
   [:2022J0475]; National Natural Science Foundation of China [62166045,
   62161051]; Scientific Research Foundation of Yunnan University of
   Finance and Economics [2020B10]
FX AcknowledgementsThis work was supported by the Yunnan Fundamental
   Research Projects (Project Number:202201AT070166), Scientific Research
   Foundation of Yunnan Provincial Department of Education (Project
   Number:2022J0475), National Natural Science Foundation of China (Project
   Number: 62166045, 62161051) and the Scientific Research Foundation of
   Yunnan University of Finance and Economics (Project Number: 2020B10).
CR Alexandrov AD., 2005, CONVEX POLYHEDRA
   [Anonymous], 1948, CR (Doklady) Acad. Sci. URSS (NS), DOI [DOI 10.1007/S10958-006-0050-9, 10.1007/s10958-006-0050-9]
   Aurenhammer F, 1998, ALGORITHMICA, V20, P61, DOI 10.1007/PL00009187
   AURENHAMMER F, 1987, SIAM J COMPUT, V16, P78, DOI 10.1137/0216006
   Benamou JD, 2000, NUMER MATH, V84, P375, DOI 10.1007/s002119900117
   Blinn J., 1978, Proceedings of the 5th annual conference on Computer graphics and interactive techniques-SIGGRAPH'78, V12, P286
   BRENIER Y, 1991, COMMUN PUR APPL MATH, V44, P375, DOI 10.1002/cpa.3160440402
   Catmull Edwin Earl, 1974, A Subdivision Algorithm for Computer Display of Curved Surfaces
   Cignoni P, 1998, VISUALIZATION '98, PROCEEDINGS, P59, DOI 10.1109/VISUAL.1998.745285
   Cohen J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P115, DOI 10.1145/280814.280832
   Cook R. L., 1984, Computers & Graphics, V18, P223
   de Goes F, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366190
   de Goes F, 2011, COMPUT GRAPH FORUM, V30, P1593, DOI 10.1111/j.1467-8659.2011.02033.x
   Deng BL, 2022, COMPUT GRAPH FORUM, V41, P559, DOI 10.1111/cgf.14502
   Dominitz A, 2010, IEEE T VIS COMPUT GR, V16, P419, DOI 10.1109/TVCG.2009.64
   Floater MS, 1997, COMPUT AIDED GEOM D, V14, P231, DOI 10.1016/S0167-8396(96)00031-3
   Gehling MB, 2007, VISUAL COMPUT, V23, P897, DOI 10.1007/s00371-007-0132-9
   Gu X., 2003, P 2003 EUROGRAPHICSA, P127
   Gu XF, 2004, IEEE T MED IMAGING, V23, P949, DOI 10.1109/TMI.2004.831226
   Gu XF, 2016, ASIAN J MATH, V20, P383
   Haker S, 2004, INT J COMPUT VISION, V60, P225, DOI 10.1023/B:VISI.0000036836.66311.97
   Hirose O, 2021, IEEE T PATTERN ANAL, V43, P2269, DOI 10.1109/TPAMI.2020.2971687
   Jin M, 2008, IEEE T VIS COMPUT GR, V14, P1030, DOI 10.1109/TVCG.2008.57
   Krishnamurthy V., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P313, DOI 10.1145/237170.237270
   Lévy B, 2002, ACM T GRAPHIC, V21, P362, DOI 10.1145/566570.566590
   Liu LG, 2008, COMPUT GRAPH FORUM, V27, P1495, DOI 10.1111/j.1467-8659.2008.01290.x
   Ma M, 2019, VISUAL COMPUT, V35, P1311, DOI 10.1007/s00371-018-1543-5
   Mérigot Q, 2011, COMPUT GRAPH FORUM, V30, P1583, DOI 10.1111/j.1467-8659.2011.02032.x
   Monge G, 1781, MEMOIRE THEORIE DEBL
   Myronenko A., 2006, Advances in Neural Information Processing Systems 19
   Policarpo F., 2005, Proceedings of the 2005 symposium on Interactive 3D graphics and games, P155, DOI DOI 10.1145/1053427.1053453
   Rehman TU, 2009, MED IMAGE ANAL, V13, P931, DOI 10.1016/j.media.2008.10.008
   Sheffer A, 2005, ACM T GRAPHIC, V24, P311, DOI 10.1145/1061347.1061354
   Shi R, 2013, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2013.327
   Solomon J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766963
   Solomon J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601175
   Su KH, 2017, COMPUT AIDED DESIGN, V82, P42, DOI 10.1016/j.cad.2016.05.020
   Wang LF, 2003, ACM T GRAPHIC, V22, P334, DOI 10.1145/882262.882272
   Wang Y, 2008, INT J COMPUT VISION, V76, P283, DOI 10.1007/s11263-007-0063-y
   Zhao JL, 2019, IEEE I CONF COMP VIS, P431, DOI 10.1109/ICCV.2019.00052
   Zhao X, 2013, IEEE T VIS COMPUT GR, V19, P2838, DOI 10.1109/TVCG.2013.135
   Zheng Y, 2019, COMPUT AIDED DESIGN, V114, P28, DOI 10.1016/j.cad.2019.04.008
NR 42
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29077
EP 29094
DI 10.1007/s11042-023-14776-5
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000948470800001
DA 2024-07-18
ER

PT J
AU Gupta, N
   Sardana, G
AF Gupta, Neetu
   Sardana, Gunjan
TI Anomaly detection in video frames: hybrid gain optimized Kalman filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; Video frames; Object tracking; Kalman filter;
   Optimization
AB Even though there are exist numerous studies that aim at anomaly detection under object tracking, such techniques are not very practicable in crowded areas since motions are not completely enclosed in a single frame. This research work concerns on introducing a new model that detects anomalies in video frames, which is performed under three stages such as, (i) motion estimation (ii) object tracking and (iii) Anomaly detection. At first, motion detection is done that intends to discover the movements of objects in the frames. Consequently, object tracking (second phase) is performed to track the moving objects by means of Extended Kalman Filter (EKF). After the tracking of object, anomaly detection (third phase) is carried out, which detects the presence of anomalies in the video. Moreover, it is very important to track the objects more precisely for identifying the presence of anomalies in the video scene. For attaining the precise tracking, this paper intends to tune the Kalman gain optimally, thus making the anomaly detection more precise. For the achievement of optimal gain, this paper introduces a new algorithm, termed as Wolf Updated-Whale Optimization Algorithm model (WU-WOA). At last, the effectiveness of adopted scheme is confirmed by evaluating over existing schemes. The precision of the adopted model is 54.76%, 54.76%, 58.54%, and 54.76% better than FF, PSO, GWO, and WOA methods.
C1 [Gupta, Neetu; Sardana, Gunjan] JC Bose Univ Sci & Technol YMCA, Elect Engn, Faridabad, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Gupta, N (corresponding author), JC Bose Univ Sci & Technol YMCA, Elect Engn, Faridabad, India.
EM neetugupta10013@gmail.com
OI Gupta, Neetu/0000-0003-4220-7053
CR Al-Ayyoub M, 2018, MULTIMED TOOLS APPL, V77, P4939, DOI 10.1007/s11042-016-4218-0
   Al-Mnayyis A., 2020, INT J EL COMP ENG SY, V10-4, P4101, DOI DOI 10.11591/IJECE.V10I4.PP4101-4108
   Al-Zu'bi S, 2021, MULTIMED TOOLS APPL, V80, P16887, DOI 10.1007/s11042-020-09160-6
   AlZu'bi S, 2020, 2020 FIFTH INTERNATIONAL CONFERENCE ON FOG AND MOBILE EDGE COMPUTING (FMEC), P306, DOI [10.1109/FMEC49853.2020.9144916, 10.1109/fmec49853.2020.9144916]
   AlZu'bi S, 2019, MULTIMED TOOLS APPL, V78, P24223, DOI 10.1007/s11042-018-7003-4
   Asad M, 2022, APPL INTELL, V52, P1126, DOI 10.1007/s10489-021-02356-9
   Aziz ZFR, 2021, MULTIMED TOOLS APPL, V80, P25875, DOI 10.1007/s11042-021-10921-0
   Chriki A, 2021, MULTIMED TOOLS APPL, V80, P2599, DOI 10.1007/s11042-020-09774-w
   Chu WQ, 2019, IEEE T MULTIMEDIA, V21, P246, DOI 10.1109/TMM.2018.2846411
   Deepak K, 2021, CIRC SYST SIGNAL PR, V40, P1333, DOI 10.1007/s00034-020-01522-7
   Deepak K, 2021, SIGNAL IMAGE VIDEO P, V15, P215, DOI 10.1007/s11760-020-01740-1
   dos Santos FP, 2019, J VIS COMMUN IMAGE R, V60, P407, DOI 10.1016/j.jvcir.2019.02.035
   Fathima MD, 2021, INT J INTERACT MULTI
   Fister I, 2013, SWARM EVOL COMPUT, V13, P34, DOI 10.1016/j.swevo.2013.06.001
   Ghaith Iyad H., 2021, 2021 International Conference on Information Technology (ICIT), P714, DOI 10.1109/ICIT52682.2021.9491721
   Hu X, 2019, IEEE T INF FOREN SEC, V14, P1007, DOI 10.1109/TIFS.2018.2868617
   Ilyas Z, 2021, MULTIMED TOOLS APPL, V80, P24053, DOI 10.1007/s11042-021-10785-4
   Khan MUK, 2019, IEEE T INF FOREN SEC, V14, P541, DOI 10.1109/TIFS.2018.2856189
   Kodali SK, 2015, OBJECT TRACKING USIN
   Leyva R, 2017, IEEE T IMAGE PROCESS, V26, P3463, DOI 10.1109/TIP.2017.2695105
   Li YS, 2018, IEEE ACCESS, V6, P40281, DOI 10.1109/ACCESS.2018.2851747
   Lin Y, 2010, SIGNAL PROCESSING SY, V1, P331
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Nasaruddin N, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00365-y
   Pakrashi A, 2019, INFORM SCIENCES, V485, P456, DOI 10.1016/j.ins.2019.02.017
   Panakkal VP, 2010, P IEEE AER C MAR, P1
   Rajinikanth V, 2021, INT J INTERACT MULTI, V7, P163, DOI 10.9781/ijimai.2021.11.008
   Ramachandra B, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-021-01187-5
   Ramchandran A, 2020, MULTIMED TOOLS APPL, V79, P35275, DOI 10.1007/s11042-019-7702-5
   Rezaee H., 2011, 2011 IEEE GCC Conference and Exhibition (GCC), P397, DOI 10.1109/IEEEGCC.2011.5752541
   Ribeiro M, 2018, PATTERN RECOGN LETT, V105, P13, DOI 10.1016/j.patrec.2017.07.016
   Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006
   Thomaz LA, 2018, IEEE T CIRCUITS-I, V65, P1003, DOI 10.1109/TCSI.2017.2758379
   Ullah W, 2021, MULTIMED TOOLS APPL, V80, P16979, DOI 10.1007/s11042-020-09406-3
   Venubabu V., 2013, INT J ELECT ELECT DA, V1, P2320
   Wang J, 2022, J AMB INTEL HUM COMP, V13, P1293, DOI 10.1007/s12652-020-02574-y
   Wang SQ, 2018, NEUROCOMPUTING, V277, P161, DOI 10.1016/j.neucom.2016.08.156
   Wang T, 2019, IEEE T INF FOREN SEC, V14, P1390, DOI 10.1109/TIFS.2018.2878538
   Wang T, 2018, OPTIK, V152, P50, DOI 10.1016/j.ijleo.2017.07.064
   Zhang JH, 2017, J SOUND VIB, V389, P153, DOI 10.1016/j.jsv.2016.11.006
   US
NR 42
TC 0
Z9 0
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 33961
EP 33982
DI 10.1007/s11042-023-14827-x
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000946890000005
DA 2024-07-18
ER

PT J
AU Xu, ZW
   Zou, BJ
   Liu, Q
AF Xu, Ziwen
   Zou, Beiji
   Liu, Qing
TI A deep retinal image quality assessment network with salient structure
   priors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution neural network; Optic disc; Retinal image quality
   assessment; Vessels
ID CONVOLUTIONAL NEURAL-NETWORK
AB Retinal image quality assessment is an essential prerequisite for diagnosis of retinal diseases. Its goal is to identify high quality retinal images in which anatomic structures and lesions attracting ophthalmologists'attention most are exhibited clearly and definitely while reject poor quality images. Motivated by this, we mimic the way that ophthalmologists assess the quality of retinal images and propose a method termed SalStructuIQA. First, two salient structures are detected for retinal quality assessment. One is large-size salient structures including optic disc and exudates in large-size. The other is tiny-size salient structures mainly including vessels. Then the proposed two salient structure priors are incorporated with deep convolutional neural network (CNN) to enforce CNN pay attention to these salient structures. Accordingly, two CNN architectures named Dual-branch SalStructIQA and Single-branch SalStructIQA are designed for the incorporation, respectively. Experimental results show that the F-score of our proposed Dual-branch SalStructIQA and Single-branch SalStructIQA are 0.8723 and 0.8662 respectively on the public Eye-Quality dataset, which demonstrates the effectiveness of our methods.
C1 [Xu, Ziwen; Zou, Beiji; Liu, Qing] Cent South Univ, Sch Comp Sci & Engn, Lushan South Rd, Changsha 410083, Hunan, Peoples R China.
   [Zou, Beiji] Hunan Prov Engn Technol Res Ctr Comp Vis & Intelli, Changsha, Peoples R China.
C3 Central South University
RP Liu, Q (corresponding author), Cent South Univ, Sch Comp Sci & Engn, Lushan South Rd, Changsha 410083, Hunan, Peoples R China.
EM csuwenwen@gmail.com; bjzou@csu.edu.cn; qing.liu.411@gmail.com
OI Liu, Qing/0000-0002-5797-8179
FU National Key R&D Program of China [2018AAA0102100]; National Natural
   Science Foundation of China [62006249]; Changsha Municipal Natural
   Science Foundation [kq2014135]; High Performance Computing Center of
   Central South University
FX AcknowledgementsThis work of Prof. Beiji Zou is partially supported by
   the National Key R&D Program of China (NO. 2018AAA0102100); Dr. Qing Liu
   is partially supported by the National Natural Science Foundation of
   China (No. 62006249) and Changsha Municipal Natural Science Foundation
   (kq2014135). This work was supported in part by the High Performance
   Computing Center of Central South University.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2016, OPHTHALMIC MEDICAL I, DOI [10.17077/omia.1054, DOI 10.17077/OMIA.1054]
   Burges Chris, 2005, P 22 INT C MACH LEAR, P89, DOI DOI 10.1145/1102351.1102363
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Davis H, 2009, 22nd IEEE International Symposium on Computer-Based Medical Systems, P1, DOI [10.1109/CBMS.2009.5255437, DOI 10.1109/CBMS.2009.5255437]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fu HZ, 2019, LECT NOTES COMPUT SC, V11764, P48, DOI 10.1007/978-3-030-32239-7_6
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hunter A, 2011, IEEE ENG MED BIO, P5955, DOI 10.1109/IEMBS.2011.6091472
   Jia S, 2018, MULTIMED TOOLS APPL, V77, P14859, DOI 10.1007/s11042-017-5070-6
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Köhler T, 2013, COMP MED SY, P95, DOI 10.1109/CBMS.2013.6627771
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, P1097
   Lalonde M., 2001, Proceedings of Vision Interface, P259
   Lee SC, 1999, P SOC PHOTO-OPT INS, V3661, P1581, DOI 10.1117/12.348562
   Li QH, 2019, NEUROCOMPUTING, V331, P189, DOI 10.1016/j.neucom.2018.11.015
   Li XM, 2021, IEEE T MED IMAGING, V40, P2284, DOI 10.1109/TMI.2021.3075244
   Liu XL, 2017, IEEE I CONF COMP VIS, P1040, DOI 10.1109/ICCV.2017.118
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P3951, DOI 10.1109/TIP.2017.2708503
   MacGillivray TJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0127914
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Muddamsetty SM, 2021, VISAPP: PROCEEDINGS OF THE 16TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL. 4: VISAPP, P661, DOI 10.5220/0010250506610668
   Nguyen UTV, 2013, PATTERN RECOGN, V46, P703, DOI 10.1016/j.patcog.2012.08.009
   Niu YH, 2022, IEEE J BIOMED HEALTH, V26, P44, DOI 10.1109/JBHI.2021.3110593
   Ou FZ, 2019, IEEE IMAGE PROC, P1004, DOI [10.1109/icip.2019.8803047, 10.1109/ICIP.2019.8803047]
   Pachade S, 2021, DATA-BASEL, V6, DOI 10.3390/data6020014
   Parashar D, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3071223
   Dias JMP, 2014, INFORM FUSION, V19, P73, DOI 10.1016/j.inffus.2012.08.001
   Raj A, 2020, IEEE ACCESS, V8, P57810, DOI 10.1109/ACCESS.2020.2982588
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Saha SK, 2018, J DIGIT IMAGING, V31, P869, DOI 10.1007/s10278-018-0084-9
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shen YX, 2020, MED IMAGE ANAL, V61, DOI 10.1016/j.media.2020.101654
   Shen YX, 2018, LECT NOTES COMPUT SC, V11046, P28, DOI 10.1007/978-3-030-00919-9_4
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Usher D, 2003, P MEDICAL IMAGE UNDE, P81
   Wang SZ, 2016, IEEE T MED IMAGING, V35, P1046, DOI 10.1109/TMI.2015.2506902
   Wang Z., 2006, Modern Image Quality Assessment, DOI 10.2200/S00010ED1V01Y200508IVM003
   Yan QS, 2019, IEEE T IMAGE PROCESS, V28, P2200, DOI 10.1109/TIP.2018.2883741
   Yang S, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1383, DOI 10.1145/3343031.3350990
   Yang XH, 2020, NEUROCOMPUTING, V401, P209, DOI 10.1016/j.neucom.2020.03.072
   Yu FL, 2017, IEEE ENG MED BIO, P664, DOI 10.1109/EMBC.2017.8036912
   Zago GT, 2018, COMPUT BIOL MED, V103, P64, DOI 10.1016/j.compbiomed.2018.10.004
NR 49
TC 0
Z9 0
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34005
EP 34028
DI 10.1007/s11042-023-14805-3
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000946890000003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Alanazi, AS
   Munir, N
   Khan, M
   Hussain, I
AF Alanazi, Ammar S.
   Munir, Noor
   Khan, Majid
   Hussain, Iqtadar
TI A novel design of audio signals encryption with substitution permutation
   network based on the Genesio-Tesi chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio encryption; Chaotic system; Spectrogram
AB The concept of encryption is as old as the reality that confidential information has been interchanging among people. The art of transferring secret information between two parties or groups is known as cryptography. It contains the algorithms, key exchange protocols, and approaches to consistently and securely avoid unauthorized access to confidential information. Nowadays information is in digital form, therefore this factor necessitates some cryptographic algorithms for secure data transmission. In this work, we have designed a new approach for audio encryption to securely store and transfer audio signals. The suggested encryption algorithm is primarily based on Gensio-Tesi chaotic map. Substitution and permutation networks are engendered by the Gensio-Tesi chaotic system for the encryption of signals. The other important feature discussed here is the performance of offered algorithm which is ascertained by some extensive audio analysis. Experimental results reveal that the designed scheme has an essential level of security.
C1 [Alanazi, Ammar S.] King Abdulaziz City Sci & Technol, Jeddah, Saudi Arabia.
   [Munir, Noor] Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
   [Khan, Majid] Prince Sattam bin Abdulaziz Univ, Coll Sci & Humanities Al Kharj, Dept Math, Al Kharj 11942, Saudi Arabia.
   [Hussain, Iqtadar] Qatar Univ, Coll Arts & Sci, Dept Math Stat & Phys, Math Program, Doha 2713, Qatar.
   [Hussain, Iqtadar] Qatar Univ, Coll Arts & Sci, Stat Consulting Unit, Doha, Qatar.
C3 King Abdulaziz City for Science & Technology; Prince Sattam Bin
   Abdulaziz University; Qatar University; Qatar University
RP Khan, M (corresponding author), Prince Sattam bin Abdulaziz Univ, Coll Sci & Humanities Al Kharj, Dept Math, Al Kharj 11942, Saudi Arabia.
EM mk.cfd1@gmail.com
RI Khan, Majid/T-9408-2019
OI Khan, Majid/0000-0001-5454-3770
CR Abdelfatah RI, 2020, IEEE ACCESS, V8, P69894, DOI 10.1109/ACCESS.2020.2987197
   Advanced Encryption Standard (AES), 2001, FED INF PROC STAND, DOI [10.6028/NIST.FIPS.197.197, DOI 10.6028/NIST.FIPS.197.197]
   Al-Hazaimeh O. M., 2022, Indonesian Journal of Electrical Engineering and Computer Science, V25, P1103, DOI [10.11591/ijeecs.v25.i2.pp1103-1114, DOI 10.11591/IJEECS.V25.I2.PP1103-1114]
   Basu Sandipan., 2011, Journal of global research in Computer Science, V2, P116
   Farsana FJ, 2023, APPL COMPUT INFORM, V19, P239, DOI 10.1016/j.aci.2019.10.001
   GENESIO R, 1992, AUTOMATICA, V28, P531, DOI 10.1016/0005-1098(92)90177-H
   Hassan NF., 2022, IRAQI J SCI, V63, P830, DOI [10.24996/ijs.2022.63.2.36, DOI 10.24996/IJS.2022.63.2.36]
   Hato E., 2015, INT J COMPUT APPL, V128
   Kordov K, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8050530
   Lima JB, 2016, MULTIMED TOOLS APPL, V75, P8403, DOI 10.1007/s11042-015-2755-6
   Lin CH, 2022, MULTIMEDIA SYST, V28, P1793, DOI 10.1007/s00530-022-00950-6
   Liu HJ, 2016, OPTIK, V127, P7431, DOI 10.1016/j.ijleo.2016.05.073
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   S A., 2022, P 2022 INT C COMP CO, P1, DOI [10.1109/ICCCI54379.2022.9740761, DOI 10.1109/ICCCI54379.2022.9740761]
   Sarker IH, 2023, MOBILE NETW APPL, V28, P296, DOI 10.1007/s11036-022-01937-3
   Sarker IH, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12050754
   Sathiyamurthi P, 2022, MULTIMED TOOLS APPL, V81, P6331, DOI 10.1007/s11042-021-11757-4
   Sathiyamurthi P, 2017, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-017-0118-0
   Schneier B., 1994, Fast Software Encryption. Cambridge Security Workshop Proceedings, P191
   Shah D, 2021, MULTIMED TOOLS APPL, V80, P22251, DOI 10.1007/s11042-021-10697-3
   Shah DW, 2020, MULTIMEDIA SYST, V26, P235, DOI 10.1007/s00530-019-00640-w
   Tamimi AA, 2014, P WORLD C ENG COMPUT, V1
   Tuchman W, 1997, INTERNET BESIEGED CO, P275
NR 23
TC 6
Z9 6
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26577
EP 26593
DI 10.1007/s11042-023-14964-3
EA MAR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000946494700017
DA 2024-07-18
ER

PT J
AU Jun, C
   Lei, C
   Wei, L
   Yang, Y
AF Jun, Chen
   Lei, Cai
   Wei, Liu
   Yang, Yu
TI Fusion of near-infrared and visible images based on saliency-map-guided
   multi-scale transformation decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Near-infrared; Color distortion; Saliency map
ID NETWORK
AB In this research, we propose a near-infrared (NIR) and visible (VIS) image fusion method based on saliency-map-guided multi-scale transform decomposition (SMG-MST) to solve the problem of color distortion. Although the existing NIR and VIS image fusion methods can enhance the texture information of the fused image, they cannot control the scattering of light from objects in the fused image resulting in color distortion. The color distortion region usually has good saliency, so using saliency map to solve the above problem is a good choice. In this paper, a visible image guided by saliency map is introduced in the low frequency part, which can weaken the scattering of too much light from objects in the image. In addition, the local entropy of the NIR is used to guide the visible photon images, so the results contain more details. Both qualitative and quantitative experiments demonstrate the effectiveness of our algorithm, and the comparison of algorithm running times shows the high efficiency of our method.
C1 [Jun, Chen; Lei, Cai; Wei, Liu] China Univ Geosci, Sch Automat, Wuhan 430074, Peoples R China.
   [Jun, Chen; Lei, Cai; Wei, Liu] Hubei Key Lab Adv Control & Intelligent Automat, Wuhan, Peoples R China.
   [Jun, Chen; Lei, Cai; Wei, Liu] Minist Educ, Engn Res Ctr Intelligent Technol Geoexplorat, Wuhan, Peoples R China.
   [Yang, Yu] Chinese Acad Sci, Shanghai Inst Tech Phys, Shanghai 200083, Peoples R China.
   [Yang, Yu] Chinese Acad Sci, Key Lab Infrared Syst Detecting & Imaging Technol, Shanghai 200083, Peoples R China.
C3 China University of Geosciences; Shanghai Institute of Technical
   Physics, CAS; Chinese Academy of Sciences; Chinese Academy of Sciences
RP Jun, C (corresponding author), China Univ Geosci, Sch Automat, Wuhan 430074, Peoples R China.; Jun, C (corresponding author), Hubei Key Lab Adv Control & Intelligent Automat, Wuhan, Peoples R China.; Jun, C (corresponding author), Minist Educ, Engn Res Ctr Intelligent Technol Geoexplorat, Wuhan, Peoples R China.
EM chenjun71983@163.com
RI JIANG, Peng/KGL-3427-2024
OI Chen, Jun/0000-0001-9005-6849
FU National Natural Science Foundation of China [62073304, 41977242,
   61973283]
FX AcknowledgementsThis work was supported by the National Natural Science
   Foundation of China nos. 62073304, 41977242 and 61973283.
CR Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Ancuti C, 2014, IEEE GEOSCI REMOTE S, V11, P1871, DOI 10.1109/LGRS.2014.2312314
   [Anonymous], EPFL DATABASE
   Bernal EA, 2017, IEEE ANN C N AM FUZZ, P1
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chen J, 2020, INFORM SCIENCES, V508, P64, DOI 10.1016/j.ins.2019.08.066
   Chen QD, 2019, IEEE ACCESS, V7, P24333, DOI 10.1109/ACCESS.2019.2897213
   Colvero CP, 2005, MICROW OPT TECHN LET, V46, P319, DOI 10.1002/mop.20976
   Cui GM, 2015, OPT COMMUN, V341, P199, DOI 10.1016/j.optcom.2014.12.032
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Feng C, 2013, IEEE IMAGE PROC, P2363, DOI 10.1109/ICIP.2013.6738487
   Fernandez-Beltran R, 2018, IEEE J-STARS, V11, P4982, DOI 10.1109/JSTARS.2018.2881342
   Fredembach C., 2008, COL IM C, P176
   Gijsenij A, 2011, IEEE T IMAGE PROCESS, V20, P2475, DOI 10.1109/TIP.2011.2118224
   Jang DW, 2017, IET IMAGE PROCESS, V11, P587, DOI 10.1049/iet-ipr.2017.0192
   Jiang JH, 2019, IEEE ACCESS, V7, P20607, DOI 10.1109/ACCESS.2019.2896128
   Lan X, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-86
   Li H, 2019, IEEE T IMAGE PROCESS, V28, P2614, DOI 10.1109/TIP.2018.2887342
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li Z, 2021, IEEE T MULTIMEDIA, V23, P306, DOI 10.1109/TMM.2020.2978640
   Ma JY, 2022, IEEE-CAA J AUTOMATIC, V9, P1200, DOI 10.1109/JAS.2022.105686
   Ma JY, 2020, IEEE T IMAGE PROCESS, V29, P4980, DOI 10.1109/TIP.2020.2977573
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Mertens T, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P382, DOI 10.1109/PG.2007.17
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Prabhakar KR, 2017, IEEE I CONF COMP VIS, P4724, DOI 10.1109/ICCV.2017.505
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Sappa AD, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060861
   Schaul L, 2009, IEEE IMAGE PROC, P1629, DOI 10.1109/ICIP.2009.5413700
   Sulami M, 2014, IEEE INT CONF COMPUT
   Tang LF, 2022, IEEE-CAA J AUTOMATIC, V9, P2121, DOI 10.1109/JAS.2022.106082
   Tang LF, 2022, INFORM FUSION, V82, P28, DOI 10.1016/j.inffus.2021.12.004
   Vanmali A. V., 2015, 2015 5 NAT C COMP VI, P1, DOI DOI 10.1109/NCVPRIPG.2015.7489945
   Vanmali AV, 2017, SADHANA-ACAD P ENG S, V42, P1063, DOI 10.1007/s12046-017-0673-1
   Wesley RJ, 2008, J Appl Remote Sens, V2, P1
   Xu H, 2022, IEEE T PATTERN ANAL, V44, P502, DOI 10.1109/TPAMI.2020.3012548
   Xu H, 2020, IEEE T IMAGE PROCESS, V29, P7203, DOI 10.1109/TIP.2020.2999855
   Zhang H, 2021, INT J COMPUT VISION, V129, P2761, DOI 10.1007/s11263-021-01501-8
   Zhang X, 2008, PROC CVPR IEEE, P117
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 43
TC 1
Z9 1
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34631
EP 34651
DI 10.1007/s11042-023-14709-2
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000946494700006
DA 2024-07-18
ER

PT J
AU Aziz, R
   Wagan, AI
   Islam, N
AF Aziz, Roohan
   Wagan, Asim Imdad
   Islam, Noman
TI Block based learned image compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Learned image compression; Deep neural networks; Autoencoders;
   zGenerative adversarial network
AB Efficient image compression is very important for storage, retrieval, processing and transmission of image contents. The objective is to find a striking balance between compression ratio and the distortion in image. Recently, there has been a rise in interest on lossy neural network based compression algorithms. Specifically, autoencoder based compression schemes have shown great potential in learned image compression domain. This paper proposes a new algorithm for learned image compression using block based Generative Adversarial Networks. The adversarial network was trained on the blocks derived from a large image data-set. The compressed images were compared against standard compression schemes such as JPEG, PNG to show the comparative strength of block based learned compression algorithms. It has been found that performance of algorithm drops significantly at low bits per pixel. So, the paper compares the algorithm performance at various bpp values.
C1 [Aziz, Roohan; Islam, Noman] Karachi Inst Econ & Technol, Karachi, Pakistan.
   [Wagan, Asim Imdad] Muhammad Ali Jinnah Univ, Karachi, Pakistan.
RP Islam, N (corresponding author), Karachi Inst Econ & Technol, Karachi, Pakistan.
EM noman.islam@gmail.com
RI Aziz, Eng. Roohan/AHC-2288-2022
OI Aziz, Eng. Roohan/0000-0002-9134-6992; Islam, Noman/0000-0002-2092-0379
CR Agustsson E, 2019, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2019.00031
   AlirezaMakhzani BF, 2017, P 31 C NEUR INF PROC
   [Anonymous], WORKSH CHALL LEARN I
   [Anonymous], 2017, STAT PORTAL
   [Anonymous], 2018, GAN WAYS IMPROVE GAN
   Atienza R., 2017, GAN EXAMPLE USING KE
   Chollet F, 2016, KERAS BLOGS
   Constine J., 2012, TECHCRUNCH
   Dhawan S., 2011, Int. J. Electron. Commun. Technol, V2, P22
   DL4J, 2017, GAN BEGG GUID GEN AD
   Galteri L, 2017, IEEE I CONF COMP VIS, P4836, DOI 10.1109/ICCV.2017.517
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goodfellow I., 2016, arXiv
   Guido RC, 2018, INFORM FUSION, V41, P161, DOI 10.1016/j.inffus.2017.09.006
   Khalil M. I., 2010, International Journal of Computer Theory and Engineering, V2010, P39, DOI [10.7763/ijcte.2010.v2.114, DOI 10.7763/IJCTE.2010.V2.114]
   Khedr WM, 2016, INT J ADV COMPUT SC, V137, P11
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Liu MY, 2021, P IEEE, V109, P839, DOI 10.1109/JPROC.2021.3049196
   Liu Z, 2018, DES AUT CON, DOI 10.1145/3195970.3196022
   Makhzani A., 2015, ARXIV
   Minnen D, 2018, ADV NEUR IN, V31
   Qureshi M., 2020, INT J INTERACT MOB T, V4, P46, DOI 10.3991/ijim.v14i10.15057
   Santurkar S, 2018, PICT COD SYMP, P258, DOI 10.1109/PCS.2018.8456298
   Saxena D, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3446374
   Turner Vernon., 2014, IDC REPORT
   Wu L., 2020, P IEEE CVF WINT C AP, P2334
   Zhengxue Cheng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7936, DOI 10.1109/CVPR42600.2020.00796
NR 27
TC 0
Z9 0
U1 4
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26495
EP 26509
DI 10.1007/s11042-023-14975-0
EA MAR 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000943966200002
DA 2024-07-18
ER

PT J
AU Niu, WH
   Huang, XF
   Yin, HB
   Lu, Y
   Zhou, Y
   Yan, CG
AF Niu, Weihong
   Huang, Xiaofeng
   Yin, Haibing
   Lu, Yu
   Zhou, Yang
   Yan, Chenggang
TI Fast all zero block detection algorithm for versatile video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VVC; All zero block; Quantization; Machine learning; Fully connected
   neural network
ID QUANTIZED DCT COEFFICIENTS
AB The new generation versatile video coding (VVC) standard brings extremely high compression efficiency. Meanwhile, the complexity of the encoder is also greatly increased. In view of this, this paper proposes a fast algorithm for all zero block detection to speed up the quantization process, thereby reducing the complexity of the encoder. The method proposed in this paper consists of three parts. Firstly, genuine all zero blocks are detected based on a fixed threshold which is derived by hard decision quantization formula. Secondly, parts of pseudo all zero blocks are detected based on an adaptive threshold which is derived by analyzing the positions of transform coefficients under a certain condition. Finally, for the remaining pseudo all zero blocks, machine learning is introduced and the decision is made through the fully connected neural network. Experimental results show that the proposed fast algorithm achieves up to 7.505% and 7.049% coding time saving under Low Delay B and Random Access configurations with only 0.470% and 0.578% performance loss on average, respectively.
C1 [Niu, Weihong; Huang, Xiaofeng; Yin, Haibing; Lu, Yu; Zhou, Yang] Hangzhou Dianzi Univ, Sch Commun Engn, Hangzhou 310018, Peoples R China.
   [Yan, Chenggang] Hangzhou Dianzi Univ, Sch Automat, Hangzhou 310018, Peoples R China.
C3 Hangzhou Dianzi University; Hangzhou Dianzi University
RP Huang, XF (corresponding author), Hangzhou Dianzi Univ, Sch Commun Engn, Hangzhou 310018, Peoples R China.
EM wh_niu@hdu.edu.cn; xfhuang@hdu.edu.cn; haibingyin@163.com;
   y_lu@hdu.edu.cn; zhouyang@hdu.edu.cn; cgyan@hdu.edu.cn
OI huang, xiaofeng/0000-0002-8479-6960
FU National Key R&D Program of China [2021ZD0109802]; National Natural
   Science Foundation of China [61901150, 61931008, 61972123]
FX AcknowledgementsThis work was supported in part by the National Key R&D
   Program of China (2021ZD0109802), and by the National Natural Science
   Foundation of China under Grant 61901150, 61931008, and 61972123.
CR [Anonymous], 2020, VVC SOFTWARE VTM 100
   [Anonymous], 2008, ITU T SG
   Bjotegaard G., 2001, VCEGM33
   Bossen F, 2020, JVETS2002
   Bossen F, 2019, JVET N1010 JVET COMM
   Bross B., 2020, JVET-S2001
   Bross B, 2021, IEEE T CIRC SYST VID, V31, P3736, DOI 10.1109/TCSVT.2021.3101953
   Chen JL, 2020, IEEE T CIRC SYST VID, V30, P1208, DOI 10.1109/TCSVT.2019.2945830
   Cui J, 2018, IEEE T IMAGE PROCESS, V27, P4987, DOI 10.1109/TIP.2018.2837351
   Cui J, 2017, IEEE T IMAGE PROCESS, V26, P3802, DOI 10.1109/TIP.2017.2703112
   EVERETT H, 1963, OPER RES, V11, P399, DOI 10.1287/opre.11.3.399
   Fan HF, 2016, IEEE T MULTIMEDIA, V18, P537, DOI 10.1109/TMM.2016.2515365
   Fu T, 2019, IEEE INT CON MULTI, P61, DOI 10.1109/ICME.2019.00019
   Kingma D. P., 2014, arXiv
   Lee B, 2016, IEEE T MULTIMEDIA, V18, P1257, DOI 10.1109/TMM.2016.2557075
   Lee H, 2016, IEEE T CIRC SYST VID, V26, P107, DOI 10.1109/TCSVT.2015.2450151
   Lee K, 2013, IEEE J-STSP, V7, P1124, DOI 10.1109/JSTSP.2013.2272772
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Pfaff J, 2020, IEEE T CIRC SYST VID, V30, P1281, DOI 10.1109/TCSVT.2019.2945918
   Schwarz H, 2019, IEEE IMAGE PROC, P1183, DOI [10.1109/icip.2019.8803768, 10.1109/ICIP.2019.8803768]
   Schwarz H, 2019, IEEE DATA COMPR CONF, P182, DOI 10.1109/DCC.2019.00026
   Schwing AG, 2015, ARXIV
   Sullivan G, 2005, JVTN011 ISOIEC MPEG
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Wang HL, 2008, IEEE T CIRC SYST VID, V18, P510, DOI 10.1109/TCSVT.2008.918553
   Wang J., 2016, BROADB MULT SYST BRO, P1
   Wang M, 2017, 2017 IEEE THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2017), P90, DOI 10.1109/BigMM.2017.27
   Wang MS, 2017, DES AUT CON, DOI 10.1145/3061639.3062234
   Wen JT, 2000, IEEE T IMAGE PROCESS, V9, P1431, DOI 10.1109/83.855437
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xie ZG, 2007, IEEE T CIRC SYST VID, V17, P237, DOI 10.1109/TCSVT.2006.888812
   Xu MT, 2020, IEEE T BROADCAST, V66, P88, DOI 10.1109/TBC.2019.2941063
   Xu M, 2018, IEEE INT SYM BROADB
   Yang EH, 2009, IEEE T CIRC SYST VID, V19, P122, DOI 10.1109/TCSVT.2008.2009260
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
   Yin HB, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102945
   Yin HB, 2018, SIGNAL PROCESS-IMAGE, V60, P79, DOI 10.1016/j.image.2017.09.004
   Yong Zhao, 2010, Proceedings of the 2010 6th International Conference on Digital Content, Multimedia Technology and its Applications (IDC 2010), P183
   Zhang MJ, 2009, IEEE T CIRC SYST VID, V19, P103, DOI 10.1109/TCSVT.2008.2009239
   Zhang ZB, 2019, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2019.00014
   Zhu Hong, 2019, 2019 International Conference on Artificial Intelligence and Advanced Manufacturing (AIAM). Proceedings, P148, DOI 10.1109/AIAM48774.2019.00037
NR 42
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 33693
EP 33718
DI 10.1007/s11042-023-14579-8
EA MAR 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000945313000015
DA 2024-07-18
ER

PT J
AU Rani, S
   Lakhwani, K
   Kumar, S
AF Rani, Shilpa
   Lakhwani, Kamlesh
   Kumar, Sandeep
TI Knowledge vector representation of three-dimensional convex polyhedrons
   and reconstruction of medical images using knowledge vector
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Construction; Reconstruction; 3D medical images; Syntactic grammar;
   Knowledge vector
ID TRANSPARENT
AB Three-dimensional image construction and reconstruction plays an important role in various applications of the real world in the field of computer vision. In the last three decades, researchers are continually working in this area because construction and reconstruction is an important approach in medical imaging. Reconstruction of the 3D image allows us to find the lesion information of the patients which could offer a new and accurate approach for the diagnosis of the disease and it adds a clinical value. Considering this, a novel approach is proposed for the construction and reconstruction of the image. First, a syntactic pattern recognition-based algorithm is implemented to extract the features from the 2D image. The proposed algorithm takes an input image and extracts the features from the image and these features (Knowledge vector) consist of direction code and length. In addition, a unique and novel algorithm is developed that can rebuild an image using a knowledge vector. Reconstruction allows us to investigate the interior details of 3D images, such as the object's size, form, and structure. The proposed algorithm performance is assessed on a medical imaging dataset, and the findings are outperformed. Performances of the proposed algorithms are evaluated on Kaggle brain MRI dataset and Medical MRI datasets which is collected from Pentagram research institute, Hyderabad. As per the experimental analysis, the proposed method gives 93.89% of accuracy on Kaggle brain MRI dataset and 97.24% on Medical MRI dataset which is better than exiting state of art methods.
C1 [Rani, Shilpa] Lovely Profess Univ, Phagwara, Punjab, India.
   [Rani, Shilpa] NGIT, CSE Dept, Hyderabad, India.
   [Lakhwani, Kamlesh] JECRC Univ, Jaipur, India.
   [Kumar, Sandeep] Koneru Lakshmaiah Educ Fdn, Dept CSE, Vaddeswaram, Andhra Pradesh, India.
C3 Lovely Professional University; Koneru Lakshmaiah Education Foundation
   (K L Deemed to be University)
RP Rani, S (corresponding author), Lovely Profess Univ, Phagwara, Punjab, India.; Rani, S (corresponding author), NGIT, CSE Dept, Hyderabad, India.
EM shilpachoudhary2020@gmail.com; kamlesh.lakhwani@gmail.com
RI choudhary, shilpa/HKV-1084-2023; Kumar, Sandeep/ADM-4627-2022
OI choudhary, shilpa/0000-0001-5809-6269; Kumar,
   Sandeep/0000-0002-4752-7884; Lakhwani, Kamlesh/0000-0002-4731-5179
CR [Anonymous], 2015, INT J APPL ENG RES
   Benalcazar DP, 2019, IEEE ACCESS, V7, P61461, DOI 10.1109/ACCESS.2019.2915786
   Bustin A, 2018, IEEE T MED IMAGING, V37, P1932, DOI 10.1109/TMI.2018.2807451
   Chakrabarty N, 2019, Brain MRI Images for Brain Tumor Detection
   Chen J, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105878
   Ding L, 2017, IEEE T MED IMAGING, V36, P1858, DOI 10.1109/TMI.2017.2704019
   Djelouah A, 2012, LECT NOTES COMPUT SC, V7576, P818, DOI 10.1007/978-3-642-33715-4_59
   Duda R. O., 2001, PATTERN CLASSIFICATI
   Fan BJ, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P521, DOI 10.1109/ICIVC.2017.7984610
   Fitzgibbon A. W., 1998, 3D Structure from Multiple Images of Large-Scale Environments. European Workshop, SMILE'98. Proceedings, P155
   Franco J.S., 2003, P 14 BRIT MACHINE VI, P329, DOI [10.5244/C.17.32, DOI 10.5244/C.17.32]
   Fu K.S., 1982, SYNTACTIC PATTERN RE, Vsecond
   Fukunaga K., 2009, INTRO STAT PATTERN R
   Furukawa Y, 2009, INT J COMPUT VISION, V81, P53, DOI 10.1007/s11263-008-0134-8
   Gonzalez R.C., 1978, SYNTACTIC PATTERN RE
   Guo YH, 2017, IEEE J-STSP, V11, P1034, DOI 10.1109/JSTSP.2017.2731742
   Han XF, 2015, PROC CVPR IEEE, P3279, DOI 10.1109/CVPR.2015.7298948
   Hou B, 2018, IEEE T MED IMAGING, V37, P1737, DOI 10.1109/TMI.2018.2798801
   Ihrke I, 2010, COMPUT GRAPH FORUM, V29, P2400, DOI 10.1111/j.1467-8659.2010.01753.x
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954
   Lazebnik S, 2007, INT J COMPUT VISION, V74, P137, DOI 10.1007/s11263-006-0008-x
   Li B, 2020, IEEE ACCESS, V8, P83782, DOI 10.1109/ACCESS.2020.2992554
   Li YS, 2019, IEEE T MED IMAGING, V38, P337, DOI 10.1109/TMI.2018.2864944
   Liu D, 2014, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2014.90
   Pavlidis T., 1977, STRUCTURAL PATTERN R, DOI DOI 10.1007/978-3-642-88304-0
   Qian YM, 2016, PROC CVPR IEEE, P4369, DOI 10.1109/CVPR.2016.473
   Rani S., 2022, Climate Change: Impacts, Responses and Sustainability in the Indian Himalaya, P1, DOI [10.1007/978-3-030-92782-0_1, DOI 10.1007/978-3-030-92782-0_1]
   Rani S, J INF SECUR APPL, P8
   Rani S., 2020, INT C SOFT COMP PATT, P196
   Rani S, 2022, MULTIMED TOOLS APPL, V81, P42183, DOI 10.1007/s11042-021-11446-2
   Rani S, 2022, MULTIMED TOOLS APPL, V81, P17303, DOI 10.1007/s11042-022-12412-2
   Rani Shilpa, 2022, Journal of Information Technology Management, P235
   Savinov N, 2016, PROC CVPR IEEE
   Seitz S.M., 2006, 2006 IEEE COMP SOC C, V1, P519, DOI https://doi.org/10.1109/CVPR.2006.19
   Zbontar J, 2016, J MACH LEARN RES, V17
   Zhang C, 2019, IEEE ACCESS, V7, P49882, DOI 10.1109/ACCESS.2019.2911119
   Zheng XH, 2018, IEEE T MED IMAGING, V37, P1498, DOI 10.1109/TMI.2018.2832007
NR 38
TC 0
Z9 0
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36449
EP 36477
DI 10.1007/s11042-023-14894-0
EA MAR 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000943970200019
DA 2024-07-18
ER

PT J
AU Ashiba, HI
   Ashiba, MI
AF Ashiba, Huda I. I.
   Ashiba, Mabrouka I. I.
TI Novel proposed technique for automatic fabric defect detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clothing; Fabric defects; AH; Pre-processing; AT; OT; FDD; CLAHE;
   Segmentation; FE and classification
ID DIAGNOSIS
AB Texture analysis plays an important role in many image processing applications to describe the objects. On the other hand, visual Fabric Defect Detection (FDD) is a highly research field in the computer vision. Surface defect refers to abnormalities in the texture of the surface. So, in this paper a dual purpose benchmark dataset is proposed for texture image analysis and surface defect detection. The first framework is based Segmentation with Contrast Limited Histogram Equalization (CLAHE) and finally FE for Classification (SCFC). The SCFC depends on improvement using CLAHE in addition to pre-processing followed by segmentation by OT and finally FE for classification task. The second scheme is relied on merging the features of A Trous Algorithm with Homomorphic Method (HM) (AH) following by Segmentation and Feature Extraction (FE) for Classification (AHSFC). The AHSFC depends on enhancement using AH in addition to pre-processing followed by segmentation using Optimum Global Thresholding (OT) and finally FE for the detection or classification task. The performance quality metrics for the suggested techniques are entropy, average gradient, contrast, Sobel edge magnitude, sensitivity, specificity, precision, accuracy and identification time.Simulation results prove that the success of both techniques in detecting the FDD. By comparing the first and the second presented algorithms, it is clear that the second suggested technique gives superior for the FDD the clothing.
C1 [Ashiba, Huda I. I.] Bilbis Higher Inst Engn, Dept Elect & Elect Commun Engn, Sharqia, Egypt.
   [Ashiba, Mabrouka I. I.] Bilbis Higher Inst Engn, Dept Basic Sci, Sharqia, Egypt.
RP Ashiba, MI (corresponding author), Bilbis Higher Inst Engn, Dept Basic Sci, Sharqia, Egypt.
EM hudaashiba@gmail.com; drmabroukaashiba@gmail.com
RI ashiba, mabrouka/IUN-1855-2023
OI ashiba, mabrouka/0000-0002-3353-8363
CR [Anonymous], 2010, v7.10.0 (R2010a)
   Ashiba HI, 2019, MULTIMED TOOLS APPL, V78, P11277, DOI 10.1007/s11042-018-6545-9
   Ashiba HI, 2018, WIRELESS PERS COMMUN, V99, P619, DOI 10.1007/s11277-017-4958-9
   Ashiba H. I., 2008, Progress In Electromagnetics Research C, V1, P123, DOI 10.2528/PIERC08012301
   Brzozowski K, 2011, EUR J RADIOL, V80, pE401, DOI 10.1016/j.ejrad.2010.12.019
   Fan JF, 2019, COMPUT METH PROG BIO, V175, P233, DOI 10.1016/j.cmpb.2019.04.006
   Gonzalez RC, 2008, DIGITAL IMAGEPROCESS
   Jin R, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/7321394
   Jin SF, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091346
   Jin SF, 2020, ELEKTRON ELEKTROTECH, V26, P58, DOI 10.5755/j01.eie.26.1.24221
   Jin SF, 2018, INSIGHT, V60, P270, DOI 10.1784/insi.2018.60.5.270
   Jing JF, 2020, J ENG FIBER FABR, V15, DOI 10.1177/1558925020908268
   Kumbhar U., 2013, INT J ENG RES TECHNO, V2, P2278
   Kuznetsova Anna, 2020, Advances in Neural Networks - ISNN 2020. 17th International Symposium on Neural Networks, ISNN 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12557), P233, DOI 10.1007/978-3-030-64221-1_20
   Latha R, 2010, PROCEDIA COMPUT SCI, V2, P303, DOI 10.1016/j.procs.2010.11.039
   Lim J.S., 1990, Two-dimensional Signal and Image Processing
   Rajalingam B., 2017, INT J ENGIN MANUFACT, V7, P2249
   Rajalingam B., 2017, INT J PURE APPL MATH, V117, P599
   Singh B.B., 2017, INT J COMPUT APPL, V167, P0975
   Wang X, 2010, INT J CLOTH SCI TECH, V22, P285, DOI 10.1108/09556221011048303
   Wildner P, 2020, MULT SCLER RELAT DIS, V37, DOI 10.1016/j.msard.2019.101452
   [吴志洋 Wu Zhiyang], 2018, [计算机辅助设计与图形学学报, Journal of Computer-Aided Design & Computer Graphics], V30, P2262
NR 22
TC 1
Z9 1
U1 5
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30783
EP 30806
DI 10.1007/s11042-023-14368-3
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000941926100003
DA 2024-07-18
ER

PT J
AU Su, L
   Chen, YS
   Song, H
   Li, WY
AF Su, Li
   Chen, Yusheng
   Song, Hao
   Li, Wanyi
TI A survey of maritime vision datasets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Maritime perception; Maritime ship dataset; Ship
   intellectualization
ID OBJECT DETECTION
AB The field of computer vision has been applied in many topics and scenes, especially in the shipping business which occupies a large position in the world trade. With the development of ship intellectualization, the task of detection, tracking, segmentation and classification of interested targets become more and more important. Publicly available dataset is the foundation to promote research in shipping. Based on this intention, we systematically present a review of maritime datasets on maritime perception. In this paper, comparison is made in terms of data type, environment, ground authenticity, and applicable research directions. The aim of writing this paper is to help researchers quickly identify the most suitable dataset for their work.
C1 [Su, Li; Chen, Yusheng; Song, Hao] Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Harbin 150001, Peoples R China.
   [Su, Li] Harbin Engn Univ, Key Lab Intelligent Technol & Applicat Marine Equi, Minist Educ, Harbin 150001, Peoples R China.
   [Li, Wanyi] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
C3 Harbin Engineering University; Harbin Engineering University; Chinese
   Academy of Sciences; Institute of Automation, CAS
RP Chen, YS (corresponding author), Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Harbin 150001, Peoples R China.
EM chenyusheng@hrbeu.edu.cn
RI 丽, 苏/JVO-8581-2024
FU Project of Intelligent Situation Awareness System for Smart Ship
   [MC-201920-X01, MC-201905-C03]; Special Funds for Basic Scientific
   Research Business Expenses of Central Universities - Doctoral Research
   Innovation Fund Project Funding; National Natural Science Foundation of
   China [U1613213, 91748131, 61771471]
FX This work was supported in part by the Project of Intelligent Situation
   Awareness System for Smart Ship (MC-201920-X01), in part by the Project
   of Research on Intelligent Ship Testing and Verification
   (MC-201905-C03), in part by the Special Funds for Basic Scientific
   Research Business Expenses of Central Universities - Doctoral Research
   Innovation Fund Project Funding, and in part by the National Natural
   Science Foundation of China under Grants (U1613213, 91748131, 61771471).
   Thanks to Dr. Yuxin Sun. The revision of the paper was mainly done by
   Dr. Yuxin Sun, who made outstanding contributions in the revision
   process, including additional experiments and paper writing.
CR [Anonymous], 2017, MARITIME ROBOTX CHAL
   [Anonymous], 2010, 2010 International WaterSide Security Conference, DOI DOI 10.1109/WSSC.2010.5730254
   [Anonymous], 2015, Proceedings of the Sixth International Symposium on Information and Communication Technology
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bloisi D, 2009, INT J PATTERN RECOGN, V23, P1477, DOI 10.1142/S0218001409007594
   Bloisi DD, 2015, 2015 12TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Bovcon B., 2019, PROC 24 COMPUT VIS W, P1
   Bovcon B, 2019, IEEE INT C INT ROBOT, P3431, DOI [10.1109/IROS40897.2019.8967909, 10.1109/iros40897.2019.8967909]
   Bovcon B, 2018, IEEE INT C INT ROBOT, P5807, DOI 10.1109/IROS.2018.8594238
   Bovcon B, 2018, ROBOT AUTON SYST, V104, P1, DOI 10.1016/j.robot.2018.02.017
   Bovcon B, 2017, INT SYMP IMAGE SIG, P1, DOI 10.1109/ISPA.2017.8073559
   Burke A., 2010, Int. Adv. Mobil. Forum, V16, P1, DOI [10.1109/WSSC.2010.5730231, DOI 10.1109/WSSC.2010.5730231]
   Cane T, 2019, 2018 15 IEEE INT C A
   Carthel C, 2007, 2007 PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION, VOLS 1-4, P447
   Chen L.C., 2018, P EUR C COMP VIS ECC, P801, DOI [DOI 10.1007/978-3-030-01234-2_49, DOI 10.48550/ARXIV.1802.02611]
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Da Silva Moreira R., 2014, IJRRAS, V20, P37
   Dong Jiankang, 2013, Journal of Computer Aided Design & Computer Graphics, V25, P397
   Farahnakian F, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P971, DOI 10.1109/ICMLA.2018.00158
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Fefilatyev Sergiy, 2009, Proceedings of the SPIE - The International Society for Optical Engineering, V7317, DOI 10.1117/12.818693
   Fefilatyev S, 2012, OCEAN ENG, V54, P1, DOI 10.1016/j.oceaneng.2012.06.028
   FleetMon, 2018, VESS PHOT DAT
   Gallego AJ, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10040511
   Haghbayan MH, 2018, IEEE INT C INTELL TR, P2163, DOI 10.1109/ITSC.2018.8569890
   Hartemink M, 2012, THESIS FACULTY ELECT
   IHS Markit, 2018, HIS MAR WORLD REG SH
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Kristan M, 2016, IEEE T CYBERNETICS, V46, P641, DOI 10.1109/TCYB.2015.2412251
   Kunz Gerard J., 2005, Proceedings of the SPIE - The International Society for Optical Engineering, V5885, p58850F, DOI 10.1117/12.614914
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Leclerc M, 2018, 2018 21ST INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P737, DOI 10.23919/ICIF.2018.8455679
   Liu H, 2020, NEURAL PROCESS LETT, V52, P977, DOI 10.1007/s11063-019-09998-4
   Maresca S., 2010, 2010 2nd International Workshop on Cognitive Information Processing (CIP 2010), P40, DOI 10.1109/CIP.2010.5604209
   MaritimeTraffic, 2018, VES PHOT
   PATINO L, 2016, IEEE COMPUT SOC CONF, P1
   Pires N., 2010, Navigation, V58, P1
   Prasad DK, 2017, IEEE T INTELL TRANSP, V18, P1993, DOI 10.1109/TITS.2016.2634580
   Prasad DK, 2016, INT C CONNECTED VEHI
   Quigley M, 2009, IEEE INT CONF ROBOT, P3604
   Ribeiro R, 2019, IEEE T CIRC SYST VID, V29, P2720, DOI 10.1109/TCSVT.2017.2775524
   Shao ZF, 2018, IEEE T MULTIMEDIA, V20, P2593, DOI 10.1109/TMM.2018.2865686
   Shi QQ, 2018, IEEE ACCESS, V6, P38656, DOI 10.1109/ACCESS.2018.2853620
   Shipspotting, 2015, SHIP PHOT SHIPP NEWS
   SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5
   Stanislas L, 2019, IEEE J OCEANIC ENG, V44, P343, DOI 10.1109/JOE.2018.2868488
   Sun YX, 2022, IEEE T CIRC SYST VID, V32, P6029, DOI 10.1109/TCSVT.2022.3155182
   Sun YX, 2022, NEUROCOMPUTING, V480, P257, DOI 10.1016/j.neucom.2022.01.017
   Sun YY, 2013, IEEE INT CONF ROBOT, P2096, DOI 10.1109/ICRA.2013.6630858
   T'Jampens R., 2016, 2016 Sixth International Conference on Image Processing Theory, Tools and Applications (IPTA), P1, DOI DOI 10.1109/IPTA.2016.7821031
   Teutsch M., 2010, P 2010 INT WATERSIDE, P1, DOI DOI 10.1109/WSSC.2010.5730289
   Thompson DJ, 2017, THESIS, P377
   Vessel Finder, 2018, USER CONTR SHIP PHOT
   Wang Q, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01365-4
   Wang Q, 2019, PROC CVPR IEEE, P8190, DOI 10.1109/CVPR.2019.00839
   Wang Q, 2018, PATTERN RECOGN, V75, P272, DOI 10.1016/j.patcog.2017.03.030
   Withagen P, 1999, P SOC PHOTO-OPT INS, V3720, P180, DOI 10.1117/12.357157
   Yaman C, 2007, 2007 3RD INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN SPACE TECHNOLOGIES, VOLS 1 AND 2, P304, DOI 10.1109/RAST.2007.4284001
   Yang CS, 2016, IGARSS 2016 2016 IEE
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Zhang Mabel M., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P10, DOI 10.1109/CVPRW.2015.7301291
   Zhang W, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.11.002
   Zhang XF, 2016, PROC CVPR IEEE, P1114, DOI 10.1109/CVPR.2016.126
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 64
TC 4
Z9 4
U1 8
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 28873
EP 28893
DI 10.1007/s11042-023-14756-9
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000941926100011
DA 2024-07-18
ER

PT J
AU Faragallah, OS
   Sallam, AI
   Alajmi, M
   El-sayed, HS
AF Faragallah, Osama S. S.
   Sallam, Ahmed I. I.
   Alajmi, Masoud
   El-sayed, Hala S. S.
TI Efficient selective chaotic video stream cipher for SHVC bitstream
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SHVC; SE; DCT; MVD; SAO; CAM; AES
ID SCALABLE EXTENSIONS; ENCRYPTION; HEVC; H.264/AVC; SYSTEM; SCHEME; RC6
AB This paper presents a chaotic Arnold map (CAM)-based selective encryption (SE) bitstream cipher for the scalable High-Efficiency Video Coding (SHVC). The proposed CAM-based SHVC-SE bitstream cipher employs the CAM for ciphering the coefficients sign bits of Discrete Cosine Transform (DCT), the Motion Vector Difference (MVD) and Sample Adaptive Offset (SAO). The proposed CAM-based SHVC-SE bitstream cipher is designed with the potential of encrypting the SHVC mostly sensitive information bits while preserving the video format compliance characteristic. The performance of the proposed CAM-based SHVC-SE bitstream cipher is compared to with the AES-based SHVC SE in CFB operation mode. The achieved outcomes demonstrates the advantage of employing the CAM in the proposed CAM-based SHVC-SE bitstream cipher that results in decreasing the encoding time for the proposed CAM-based SHVC-SE bitstream cipher compared with the AES-based SHVC SE in in CFB operation mode. Security tests on the proposed CAM-based SHVC-SE bitstream cipher are carried out for testing the robustness of the proposed CAM-based SHVC-SE bitstream cipher against attacks. The results of security tests demonstrated and confirmed the efficiency of the proposed CAM-based SHVC-SE bitstream cipher.
C1 [Faragallah, Osama S. S.] Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, POB 11099, Taif 21944, Saudi Arabia.
   [Sallam, Ahmed I. I.] Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia 32952, Egypt.
   [Alajmi, Masoud] Taif Univ, Coll Comp & Informat Technol, Dept Comp Engn, POB 11099, Taif 21944, Saudi Arabia.
   [El-sayed, Hala S. S.] Menoufia Univ, Fac Engn, Dept Elect Engn, Shibin Al Kawm 32511, Egypt.
C3 Taif University; Egyptian Knowledge Bank (EKB); Menofia University; Taif
   University; Egyptian Knowledge Bank (EKB); Menofia University
RP Faragallah, OS (corresponding author), Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, POB 11099, Taif 21944, Saudi Arabia.
EM o.salah@tu.edu.sa
RI El-Sayed, Hala S./GXG-7641-2022; Faragallah, Osama S./AHB-8031-2022
OI El-Sayed, Hala S./0000-0002-2776-783X; Faragallah, Osama
   S./0000-0003-1982-335X
FU Deanship of Scientific Research, Taif University Researchers, Taif
   University, Taif, Saudi Arabia [TURSP-2020/08]
FX This work was supported by the Deanship of Scientific Research, Taif
   University Researchers Supporting Project number (TURSP-2020/08), Taif
   University, Taif, Saudi Arabia.
CR AlZain MA, 2022, INTELL AUTOM SOFT CO, V31, P1627, DOI 10.32604/iasc.2022.020137
   [Anonymous], 2020, MEDIA
   [Anonymous], 2020, bbc
   Asghar MN, 2017, J VIS COMMUN IMAGE R, V45, P122, DOI 10.1016/j.jvcir.2017.02.017
   Boyadjis B, 2017, IEEE T CIRC SYST VID, V27, P892, DOI 10.1109/TCSVT.2015.2511879
   Boyadjis B, 2014, IEEE IMAGE PROC, P3432, DOI 10.1109/ICIP.2014.7025697
   Boyce JM, 2016, IEEE T CIRC SYST VID, V26, P20, DOI 10.1109/TCSVT.2015.2461951
   Chen J, 2014, JCTVCR1008
   Correa G, 2015, IEEE T CIRC SYST VID, V25, P660, DOI 10.1109/TCSVT.2014.2363753
   de Souza DF, 2017, IEEE T MULTIMEDIA, V19, P459, DOI 10.1109/TMM.2016.2625261
   Faragallah OS, 2022, CMC-COMPUT MATER CON, V70, P831, DOI 10.32604/cmc.2022.019151
   Faragallah OS, 2022, INTELL AUTOM SOFT CO, V31, P177, DOI 10.32604/iasc.2022.019348
   Faragallah OS, 2022, J AMB INTEL HUM COMP, V13, P1215, DOI 10.1007/s12652-020-02832-z
   Farajallah M, 2015, IEEE IMAGE PROC, P3096, DOI 10.1109/ICIP.2015.7351373
   Goswami K, 2016, INFORM SCIENCES, V364, P72, DOI 10.1016/j.ins.2016.05.018
   Guan B, 2020, IEEE ACCESS, V8, P60232, DOI 10.1109/ACCESS.2020.2983330
   Hamidouche W, 2017, SIGNAL PROCESS-IMAGE, V58, P73, DOI 10.1016/j.image.2017.06.007
   Hofbauer H, 2014, INT CONF ACOUST SPEE
   Hua ZY, 2021, INFORM SCIENCES, V546, P1063, DOI 10.1016/j.ins.2020.09.032
   Hua ZY, 2020, IEEE T SIGNAL PROCES, V68, P1937, DOI 10.1109/TSP.2020.2979596
   Li JJ, 2018, MULTIMED TOOLS APPL, V77, P12837, DOI 10.1007/s11042-017-4916-2
   Lui OY, 2013, J SYST SOFTWARE, V86, P3183, DOI 10.1016/j.jss.2013.07.054
   Misra K, 2013, IEEE J-STSP, V7, P969, DOI 10.1109/JSTSP.2013.2271451
   MSU Graphics and Media Lab Video Group, 2020, MSU COD
   Nithin M, 2017, P IEEE INT C IMAG PR, P85
   Peng F, 2020, IEEE T CIRC SYST VID, V30, P2765, DOI 10.1109/TCSVT.2019.2924910
   Saleh MA., 2018, J THEORETICAL APPL I, V96, P6807
   Sallam AI, 2018, MULTIMED TOOLS APPL, V77, P28395, DOI 10.1007/s11042-018-5994-5
   Sallam AI, 2018, MULTIMEDIA SYST, V24, P419, DOI 10.1007/s00530-017-0568-3
   Sallam AI, 2018, IEEE T MULTIMEDIA, V20, P1636, DOI 10.1109/TMM.2017.2777470
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shahid Z, 2014, IEEE T MULTIMEDIA, V16, P24, DOI 10.1109/TMM.2013.2281029
   SHVC, 2020, REF SOFTW MOD SHM
   Socek D, 2006, LECT NOTES COMPUT SC, V4141, P547
   Stütz T, 2008, IEEE INT SYM MULTIM, P446, DOI 10.1109/ISM.2008.52
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tew Y, 2018, MULTIMED TOOLS APPL, V77, P24165, DOI 10.1007/s11042-018-5611-7
   Tew Y, 2015, ASIAPAC SIGN INFO PR, P963, DOI 10.1109/APSIPA.2015.7415415
   Van Wallendael G, 2013, IEEE T CONSUM ELECTR, V59, P634, DOI 10.1109/TCE.2013.6626250
   Wang MH, 2014, IEEE T MULTIMEDIA, V16, P933, DOI 10.1109/TMM.2014.2305579
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wien M., 2015, SIGNALS COMMUNICATIO, DOI 10.1007/978-3-662-44276-0
   Xu DW, 2017, J VIS COMMUN IMAGE R, V45, P34, DOI 10.1016/j.jvcir.2017.02.008
   Xu DW, 2016, J VIS COMMUN IMAGE R, V36, P229, DOI 10.1016/j.jvcir.2016.02.002
   Yang MX, 2015, PR IEEE I C PROGR IN, P374, DOI 10.1109/PIC.2015.7489872
   Yao YZ, 2016, SIGNAL PROCESS, V128, P531, DOI 10.1016/j.sigpro.2016.05.004
   Ye Y, 2014, IEEE MULTIMEDIA, V21, P58, DOI 10.1109/MMUL.2014.47
   Zhou JT, 2014, IEEE T INF FOREN SEC, V9, P39, DOI 10.1109/TIFS.2013.2291625
NR 50
TC 2
Z9 2
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30689
EP 30708
DI 10.1007/s11042-023-14517-8
EA FEB 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000940729500004
DA 2024-07-18
ER

PT J
AU Shantkumari, M
   Uma, SV
AF Shantkumari, M.
   Uma, S. V.
TI Machine learning techniques implementation for detection of grape leaf
   disease
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; IKNN model; Grape leaf disease; Histogram gradient
   feature; Feature extraction; Convolutional neural network (CNN)
ID NEURAL-NETWORK; IDENTIFICATION; CLASSIFICATION
AB Grape leaf diseases like Black Rot, Eska measles, Leaf Spot and Healthy are among the most common disease types of the grape crop. Accurate detection of grape leaf diseases in the initial stages can control the disease spread significantly and guarantee progressive development of the grape crop industry. The existing research provides several complex image processing algorithms and cannot assure high classification accuracy. Therefore, machine learning techniques are presented in this article to enhance leaf disease classification accuracy for efficiently detecting grape leaf diseases. Moreover, two classification models are introduced in which the simple Convolutional Neural Network based Classification (CNNC) Model is detailed. Then the improvised K-Nearest Neighbour (IKNN) model for precisely detecting grape leaf diseases is detailed. Moreover, pixel encoding methods are presented to obtain a histogram representation of extracted features. Training of simple CNNC and the proposed IKNN model is conducted on Plant-Village Dataset. Additionally, mathematical modeling is presented to formulate the problem in the feature extraction process. Moreover, Confined Intensity Directional Order Relation (CIDOR) operation ensures low dimensionality of histogram representation in the multiscale domain. Furthermore, Global Pixel Order Relation (GPOR) focuses on setting up a communication with long-reach pixels of an image outside of the central pixel neighborhood. Compared to the simple CNNC, the proposed IKNN model outperforms all the traditional leaf disease classification algorithms in terms of classification accuracy. However, the IKNN model provides superior results than CNNC comparatively in terms of classification accuracy.
C1 [Shantkumari, M.] Visvesvaraya Technol Univ, Dept CSE, RRC, Belagavi, Karnataka, India.
   [Uma, S. V.] R N Shetty Inst Technol, Dept ECE, Bangalore, Karnataka, India.
C3 Visvesvaraya Technological University
RP Shantkumari, M (corresponding author), Visvesvaraya Technol Univ, Dept CSE, RRC, Belagavi, Karnataka, India.
EM shantkumarim@rediffmail.com; umakeshav2000@gmail.com
RI V, Uma S/AAE-8882-2021
OI V, Uma S/0000-0002-2389-011X
CR Adeel A, 2019, SUSTAIN COMPUT-INFOR, V24, DOI 10.1016/j.suscom.2019.08.002
   Amara J., 2017, DEEP LEARNING BASED, P79
   [Anonymous], Plant Village Dataset for plant disease
   [Anonymous], 2000, REPORT EXPERT CONSUL, V2000
   Burrell J, 2004, IEEE PERVAS COMPUT, V3, P38, DOI 10.1109/MPRV.2004.1269130
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Chouhan SS, 2018, IEEE ACCESS, V6, P8852, DOI 10.1109/ACCESS.2018.2800685
   Colomina I, 2014, ISPRS J PHOTOGRAMM, V92, P79, DOI 10.1016/j.isprsjprs.2014.02.013
   Dai Q, 2020, IEEE ACCESS, V8, P55724, DOI 10.1109/ACCESS.2020.2982055
   El Massi I, 2021, SIGNAL IMAGE VIDEO P, V15, P789, DOI 10.1007/s11760-020-01797-y
   Golhani Kamlesh, 2018, Information Processing in Agriculture, V5, P354, DOI 10.1016/j.inpa.2018.05.002
   Hall A, 2002, AUST J GRAPE WINE R, V8, P36, DOI 10.1111/j.1755-0238.2002.tb00209.x
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   International Organization of Vine and Wine (OIV), 2009, BAL OIV SIT
   Jia S, 2018, MULTIMED TOOLS APPL, V77, P14859, DOI 10.1007/s11042-017-5070-6
   Jiang P, 2019, IEEE ACCESS, V7, P59069, DOI 10.1109/ACCESS.2019.2914929
   Jogekar R, 2020, PROCEEDINGS OF THE 2020 FOURTH WORLD CONFERENCE ON SMART TRENDS IN SYSTEMS, SECURITY AND SUSTAINABILITY (WORLDS4 2020), P745, DOI [10.1109/WorldS450073.2020.9210401, 10.1109/worlds450073.2020.9210401]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu B, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.01082
   Liu B, 2020, IEEE ACCESS, V8, P102188, DOI 10.1109/ACCESS.2020.2998839
   Liu B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010011
   Liu L, 2019, INT WORKSH QUAL SERV, DOI 10.1145/3326285.3329061
   Miaomiao Ji, 2020, Information Processing in Agriculture, V7, P418, DOI 10.1016/j.inpa.2019.10.003
   Mohammed KK., 2021, ARTIF INTELL
   Ngugi LC, 2021, INFORM PROCESS AGR, V8, P27, DOI 10.1016/j.inpa.2020.04.004
   Padol PB, 2016, 2016 CONFERENCE ON ADVANCES IN SIGNAL PROCESSING (CASP), P175
   Pereira CS, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19224850
   Ruiz-Garcia L, 2009, SENSORS-BASEL, V9, P4728, DOI 10.3390/s90604728
   Sanath Rao U, 2021, GLOB T PROC, V2
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sinha A, 2020, IET IMAGE PROCESS, V14, P1427, DOI 10.1049/iet-ipr.2018.6210
   Tan MX, 2019, PR MACH LEARN RES, V97
   Pham TN, 2020, IEEE ACCESS, V8, P189960, DOI 10.1109/ACCESS.2020.3031914
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xie XY, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.00751
   Zeng QM, 2020, IEEE ACCESS, V8, P172882, DOI 10.1109/ACCESS.2020.3025196
   Zhaohua Huang, 2020, 2020 International Conferences on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData) and IEEE Congress on Cybermatics (Cybermatics), P870, DOI 10.1109/iThings-GreenCom-CPSCom-SmartData-Cybermatics50389.2020.00150
   Zhu JH, 2020, MULTIMED TOOLS APPL, V79, P14539, DOI 10.1007/s11042-018-7092-0
NR 39
TC 1
Z9 1
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30709
EP 30731
DI 10.1007/s11042-023-14441-x
EA FEB 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000940729500001
DA 2024-07-18
ER

PT J
AU Samal, S
   Nayak, R
   Jena, S
   Balabantaray, BK
AF Samal, Sonali
   Nayak, Rajashree
   Jena, Swastik
   Balabantaray, Bunil Ku.
TI Obscene image detection using transfer learning and feature fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; TL; FFP; Pix-2-Pix GAN; Obscene detection
ID PORNOGRAPHY DETECTION
AB Deep learning-based methods have been proven excellent performance in detecting pornographic images/videos flooded on social media. However, in a dearth of huge yet well-labeled datasets, these methods may suffer from under/overfitting problems and may exhibit unstable output responses in the classification process. To deal with the issue we have suggested an automatic pornographic image detection method by utilizing transfer learning (TL) and feature fusion. The novelty of our proposed work is TL based feature fusion process (FFP) which enables the removal of hyper-parameter tuning, improves model performance, and lowers the computational burden of the desired model. FFP fuses low-level and mid-level features of the outperforming pre-trained models followed by transferring the learned knowledge to control the classification process. Key contributions of our proposed method are i) generation of a well-labeled obscene image dataset GGOI via Pix-2-Pix GAN architecture for the training of deep learning models ii) modification of model architectures by integrating batch normalization and mixed pooling strategy to obtain training stability (iii) selection of outperforming models to be integrated with the FFP by performing end-to-end detection of obscene images and iv) design of TL based obscene image detection method by retraining the last layer of the fused model. Extensive experimental analyses are performed on benchmark datasets i.e., NPDI, Pornography 2k, and generated GGOI dataset. The proposed TL model with fused MobileNet V2 + DenseNet169 network performs as the state-of-the-art model compared to existing methods and provides average classification accuracy, sensitivity, and F1 score of 98.50%, 98.46% and 98.49% respectively.
C1 [Samal, Sonali; Jena, Swastik] Natl Inst Technol Meghalaya, Shillong, Meghalaya, India.
   [Nayak, Rajashree] JISU Kolkata, JIS Inst Adv Studies & Res, Kolkata 700091, West Bengal, India.
   [Balabantaray, Bunil Ku.] Natl Inst Technol Meghalaya, Comp Sci & Engn, Shillong 793003, Meghalaya, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Meghalaya; National Institute of Technology (NIT System);
   National Institute of Technology Meghalaya
RP Nayak, R (corresponding author), JISU Kolkata, JIS Inst Adv Studies & Res, Kolkata 700091, West Bengal, India.
EM ps20.cs.002@nitm.ac.in; rajashree@jisiasr.org; b19cs033@nitm.ac.in;
   bunil@nitm.ac.in
RI Samal, Sonali/HCH-5561-2022; Balabantaray, Bunil/M-9711-2013
OI Samal, Sonali/0000-0002-9551-2169; Jena, Swastik/0009-0004-0241-4378
FU BPR&D, Ministry of Home Affairs, Govt. of India
FX This work is performed under the project entitled "Design and
   Development of Intelligent Algorithms for Analysis and Detection of
   Obscene Content and Forgery in the Images Available in Social Media
   Platform" funded by BPR&D, Ministry of Home Affairs, Govt. of India.
CR AGASTYA IMA, 2018, 2018 4 INT C ADV COM, P1, DOI DOI 10.1109/ICACCAF.2018.8776843
   [Anonymous], NUDE PHOTOS INTIMATE
   [Anonymous], LIST SOCIAL MEDIA SI
   Avila S, 2018, NPDI PORN DATASET
   Avila S, 2013, COMPUT VIS IMAGE UND, V117, P453, DOI 10.1016/j.cviu.2012.09.007
   Awad AM, 2020, INT C INNOVATIVE TEC, P39
   Basilio J.A.M., 2011, International Conference on Applied Mathematics on Computer Engineering and Applications, P123
   Bhatti AQ, 2018, APPL COMPUT INTELL S, V2018, DOI 10.1155/2018/1463546
   Caetano C, 2014, EUR SIGNAL PR CONF, P1681
   Cheng F, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106983
   Da Silva Eleuterio PM, 2012, P 7 INT C FOR COMP S, P12, DOI DOI 10.5769/C2012002
   Gangwar A, 2021, NEUROCOMPUTING, V445, P81, DOI 10.1016/j.neucom.2021.02.056
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jansohn C., 2009, PROC 17 ACM INT C MU, P601, DOI [DOI 10.1145/1631272.1631366, 10.1145/1631272.1631366]
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P26635, DOI 10.1007/s11042-018-5882-z
   Kumar K, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P119, DOI 10.1109/SITIS.2016.27
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Lee CY, 2016, JMLR WORKSH CONF PRO, V51, P464
   Lin Y.C., 2003, International Conference on Computer Vision, Graphics and Image Processing, P123
   Liu YZ, 2020, MULTIMED TOOLS APPL, V79, P4729, DOI 10.1007/s11042-019-7576-6
   Mao XL, 2018, J CENT SOUTH UNIV, V25, P1651, DOI 10.1007/s11771-018-3857-x
   Math Suresh Bada, 2014, Indian J Psychol Med, V36, P147, DOI 10.4103/0253-7176.130976
   Moreira D, 2016, FORENSIC SCI INT, V268, P46, DOI 10.1016/j.forsciint.2016.09.010
   Moustafa M, 2015, ARXIV
   Nurhadiyatna A, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P106, DOI 10.1109/IC3INA.2017.8251749
   Papadamou K., 2020, P INT AAAI C WEB SOC, V14, P522, DOI [https://doi.org/10.1609/icwsm.v14i1.7320, DOI 10.1609/ICWSM.V14I1.7320]
   Perez M, 2017, NEUROCOMPUTING, V230, P279, DOI 10.1016/j.neucom.2016.12.017
   Sharma S, 2019, FOUND COMPUT DECIS S, V44, P303, DOI 10.2478/fcds-2019-0016
   Song K, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082943
   Tripathi S, 2008, IEEE INT SYM BROADB, P161
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wehrmann J, 2018, NEUROCOMPUTING, V272, P432, DOI 10.1016/j.neucom.2017.07.012
   Zhou KL, 2016, 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P206, DOI 10.1109/BigMM.2016.29
NR 33
TC 5
Z9 5
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 28739
EP 28767
DI 10.1007/s11042-023-14437-7
EA FEB 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000936195100015
PM 36846526
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Macías-Macías, M
   Sánchez-Santamaria, H
   Orellana, CGJ
   González-Velasco, HM
   Gallardo-Caballero, R
   García-Manso, A
AF Macias-Macias, Miguel
   Sanchez-Santamaria, Hector
   Garcia Orellana, Carlos J.
   Gonzalez-Velasco, Horacio M.
   Gallardo-Caballero, Ramon
   Garcia-Manso, Antonio
TI Mask R-CNN for quality control of table olives
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Mask-RCNN; Deep-learning; Table olives
ID CLASSIFICATION; FRUIT
AB In this paper we propose an object detector based on deep learning for scanning samples of table olives. For the construction of the system we have used a Mask R-CNN neural network. This network is able to segment the image providing a mask for each of the olives in the sample from which we can obtain the calibre of the object. In addition, the system is able to measure the degree of ripeness of the olives classifying them as green, semi-ripe and ripe, and identifying those fruits that are defective due to disease or damage caused by the harvesting process. The proposed system achieves success rates of 99.8% in the detection of olive fruits in photograms, 93.5% in the classification of fruit by ripeness and close to 80% in the detection of defects.
C1 [Macias-Macias, Miguel; Garcia Orellana, Carlos J.; Gonzalez-Velasco, Horacio M.; Gallardo-Caballero, Ramon; Garcia-Manso, Antonio] Univ Extremadura, Inst Comp Cient Avanzada ICCAEx, Badajoz 06006, Spain.
   [Sanchez-Santamaria, Hector] Univ Extremadura, Ctr Univ Merida CUMe, Merida 06800, Spain.
C3 Universidad de Extremadura; Universidad de Extremadura
RP Macías-Macías, M (corresponding author), Univ Extremadura, Inst Comp Cient Avanzada ICCAEx, Badajoz 06006, Spain.
EM mmacias@unex.es; sasah@unex.es; cjgarcia@unex.es; hmgvelas@unex.es;
   rgallardo@unex.es; agmanso@unex.es
RI Gallardo-Caballero, Ramón/D-4600-2011; Macias, Miguel/F-7640-2016;
   Garcia-Manso, Antonio/F-8515-2016; Sanchez, Hector/A-3469-2012
OI Gallardo-Caballero, Ramón/0000-0001-9203-7289; Macias,
   Miguel/0000-0002-2013-4204; Garcia-Manso, Antonio/0000-0003-3294-3890;
   Sanchez, Hector/0000-0001-7862-2991
FU CRUE-CSIC agreement with Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature.
CR Adelson E. H., 1984, PYRAMID METHODS IMAG
   Aquino A, 2020, COMPUT ELECTRON AGR, V176, DOI 10.1016/j.compag.2020.105616
   Blasco J, 2017, ADV BIOCHEM ENG BIOT, V161, P71, DOI 10.1007/10_2016_51
   Braverman V., 2016, Encyclopedia of algorithms, P2006, DOI [DOI 10.1007/978-1-4939-2864-4_797, 10.1007/978-1-4939-2864-4\_797]
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Gallardo-Caballero R, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19163583
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guzmán E, 2015, J FOOD SCI TECH MYS, V52, P1462, DOI 10.1007/s13197-013-1123-7
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jia S, 2018, MULTIMED TOOLS APPL, V77, P14859, DOI 10.1007/s11042-017-5070-6
   Kaur H, 2018, J FOOD SCI TECH MYS, V55, P3008, DOI 10.1007/s13197-018-3220-0
   Koirala A, 2019, COMPUT ELECTRON AGR, V162, P219, DOI 10.1016/j.compag.2019.04.017
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ponce JM, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092930
   Munera S, 2019, POSTHARVEST BIOL TEC, V156, DOI 10.1016/j.postharvbio.2019.110936
   Piedad EJ, 2018, POSTHARVEST BIOL TEC, V145, P93, DOI 10.1016/j.postharvbio.2018.06.004
   Ramos PJ, 2018, COMPUT IND, V99, P83, DOI 10.1016/j.compind.2018.03.024
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rejano L, 2010, OLIVES AND OLIVE OIL IN HEALTH AND DISEASE PREVENTION, P5, DOI 10.1016/B978-0-12-374420-3.00001-2
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Riquelme MT, 2008, J FOOD ENG, V87, P371, DOI 10.1016/j.jfoodeng.2007.12.018
   Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Waleed A, 2017, GITHUB REPOSITORY
NR 28
TC 3
Z9 3
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21657
EP 21671
DI 10.1007/s11042-023-14668-8
EA FEB 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000934850300007
OA hybrid
DA 2024-07-18
ER

PT J
AU Vensila, C
   Wesley, AB
AF Vensila, C.
   Wesley, A. Boyed
TI Authentication-based multimodal biometric system using exponential water
   wave optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric recognition; Multimodal biometric; Fingerprint; Finger vein;
   Water wave optimization (WWO)
ID FINGERPRINT; FUSION
AB The biometric system relies on a single biometric identifier which could not meet the desired performance required for personal identification. Hence, identification based on the multimodal biometric system is emerged in the research community to achieve the personal identification process more effective. Owing to the strong binding among user identity and biometric template, the user privacy is revealed and hence the security resulted in a major requirement in the biometric system. An authentication based multimodal biometric system is developed in this research by considering different modalities, such as fingerprint, finger vein, and face. Here, the bit string is generated from the biometric sample in such a way that the bit strings are fused by employing the proposed Exponential Water Wave Optimization (EWWO) algorithm based on the involvement of logic operations. However, the process of fusion is accomplished in such a way that it depends on the random selection of two logic operators by the developed optimization approach. Accordingly, the developed EWWO is derived by the combination of Exponentially Weighted Moving Average (EWMA) and Water Wave Optimization (WWO) respectively. The authentication mechanism is achieved by employing the biometric template with the encoder and decoder operation. Moreover, the proposed method achieved the performance for Equal Error rate (EER), False Acceptance Rate (FAR), and False Rejection Rate (FRR) with the value of 0.0717, 0.0745, and 0.0689, respectively.
C1 [Vensila, C.] Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
   [Wesley, A. Boyed] Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept PG Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University; Manonmaniam Sundaranar University
RP Vensila, C (corresponding author), Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
EM vensila.c@gmail.com; abwesley2003@gmail.com
CR Alonso-Fernandez F, 2010, IEEE T SYST MAN CY A, V40, P1168, DOI 10.1109/TSMCA.2010.2047498
   [Anonymous], 2021, BIOMETRICS IDEAL TES
   [Anonymous], 2021, FINGER VEIN SDUMLA H
   Bami M, 2019, IET BIOMETRICS, V8, P411, DOI 10.1049/iet-bmt.2018.5138
   Canuto AMP, 2013, EXPERT SYST APPL, V40, P1971, DOI 10.1016/j.eswa.2012.10.002
   Chakraborti T, 2018, IEEE SIGNAL PROC LET, V25, P635, DOI 10.1109/LSP.2018.2817176
   Chugh T, 2018, IEEE T INF FOREN SEC, V13, P2190, DOI 10.1109/TIFS.2018.2812193
   Computer Vision Laboratory, 2021, FAC HTML
   Galbally J, 2014, IEEE ACCESS, V2, P1530, DOI 10.1109/ACCESS.2014.2381273
   Gautam AK, 2021, TURKISH J COMPUTER M, V12, P241
   Harikrishnan D, 2019, INT J ELEC ENG EDUC, DOI 10.1177/0020720919883803
   Jain AK, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/579416
   Jin ATB, 2004, PATTERN RECOGN, V37, P2245, DOI 10.1016/j.patcog.2004.04.011
   Jin Z, 2012, EXPERT SYST APPL, V39, P6157, DOI 10.1016/j.eswa.2011.11.091
   Kaur H, 2019, IEEE T INF FOREN SEC, V14, P709, DOI 10.1109/TIFS.2018.2855669
   Kumar T, 2021, INT J ADV COMPUT SC, V12, P664
   Lakshmi Priya B, 2020, INT J RECENT TECHNOL, P2277, DOI [10.35940/ijrte.E6805.038620, DOI 10.35940/IJRTE.E6805.038620]
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2011, J NETW COMPUT APPL, V34, P1979, DOI 10.1016/j.jnca.2011.07.003
   Mustafa A. J., 2020, Int. J. Adv. Sci. Technol., V29, P7423
   Poh N, 2010, IEEE T SYST MAN CY A, V40, P539, DOI 10.1109/TSMCA.2010.2041660
   Purohit H, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-020-01146-6
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Rathgeb C., 2013, P ICB, P1, DOI DOI 10.1109/ICB.2013.6612976
   SACCUCCI MS, 1992, COMMUN STAT SIMULAT, V21, P627, DOI 10.1080/03610919208813040
   Sadhya D, 2018, IET BIOMETRICS, V7, P251, DOI 10.1049/iet-bmt.2017.0049
   Sultana M, 2018, IEEE T SYST MAN CY-S, V48, P2176, DOI 10.1109/TSMC.2017.2690321
   Tomar Peeyush, 2021, Macromolecular Symposia, V397, DOI 10.1002/masy.202000271
   Veluchamy S, 2017, IET BIOMETRICS, V6, P232, DOI 10.1049/iet-bmt.2016.0112
   Vhaduri S, 2019, IEEE T INF FOREN SEC, V14, P3116, DOI 10.1109/TIFS.2019.2911170
   Walia GS, 2020, IEEE T INF FOREN SEC, V15, P1945, DOI 10.1109/TIFS.2019.2954779
   Walia GS, 2019, IET BIOMETRICS, V8, P231, DOI 10.1049/iet-bmt.2018.5018
   Xin Y, 2018, IEEE ACCESS, V6, P21418, DOI 10.1109/ACCESS.2018.2815540
   Xiong Q, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10020217
   Yang WC, 2018, PATTERN RECOGN, V78, P242, DOI 10.1016/j.patcog.2018.01.026
   Zheng YJ, 2015, COMPUT OPER RES, V55, P1, DOI 10.1016/j.cor.2014.10.008
   Zhong DX, 2019, IEEE T INF FOREN SEC, V14, P3140, DOI 10.1109/TIFS.2019.2912552
NR 42
TC 3
Z9 3
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30275
EP 30307
DI 10.1007/s11042-023-14498-8
EA FEB 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000937944300001
DA 2024-07-18
ER

PT J
AU Lv, ZH
   Zhu, SH
   Wang, DS
   Liang, ZW
AF Lv, Zhihan
   Zhu, Songhao
   Wang, Dongsheng
   Liang, Zhiwei
TI Infrared-visible person re-identification via Dual-Channel attention
   mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Cross-modality; Attention mechanism; Dual-path
AB Infrared-Visible person re-identification (IV-ReID) is really a challenging task, which aims to match pedestrian images captured by visible and thermal cameras. There exists differences in appearance between visible and infrared images caused by viewpoint changes, pose variations and deformations, and additional cross-modality gap caused by different camera spectrums. These discrepancy make IV-ReID difficult to be addressed. In order to solve this problem, we propose a dual-path network with an attention mechanism called Convolutional Block Attention Module (CBAM) to learn the discriminative feature representations, and a modified Batch Norm Neck (BNNeck) module fuses the feature representation of cross-modality to improve the identity recognition accuracy. Specifically, the proposed method firstly constructs two independent networks to learn modality-specific feature representation, next the feature representation is split into several stripes by a conventional average pooling layer, then a shared layer is introduced to project feature representation from cross-modality into the same embedding space. Finally, we fuse heterogeneous loss function and cross entropy loss function to measure the feature similarity to improve the performance. The experimental results on two public cross-modality person re-identification datasets (SYSU-MM01 and RegDB) demonstrate that the proposed method can significantly improve the performance of IV-ReID.
C1 [Lv, Zhihan; Zhu, Songhao; Wang, Dongsheng; Liang, Zhiwei] Nanjing Univ Posts & Telecommun, Coll Automation & Artificial Intelligence, Nanjing, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Zhu, SH (corresponding author), Nanjing Univ Posts & Telecommun, Coll Automation & Artificial Intelligence, Nanjing, Peoples R China.
EM zhush@njupt.edu.cn
RI Lyu, Zhihan/I-3187-2014; wang, dongsheng/A-6078-2017
OI Lyu, Zhihan/0000-0003-2525-3074; 
FU Natural Science Foundation of Nanjing University of Posts and
   Telecommunications [NY221077]; National Natural Science Foundation of
   China [52170001]
FX This work is supported by Natural Science Foundation of Nanjing
   University of Posts and Telecommunications under No. NY221077, and
   National Natural Science Foundation of China under No. 52170001.
CR Aich A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P152, DOI 10.1109/ICCV48922.2021.00022
   [Anonymous], 2016, ARXIV
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   Chen DP, 2018, LECT NOTES COMPUT SC, V11220, P56, DOI 10.1007/978-3-030-01270-0_4
   Chen YHS, 2021, PROC CVPR IEEE, P587, DOI 10.1109/CVPR46437.2021.00065
   Dai PY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P677
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fan GF, 2022, INT J ELEC POWER, V139, DOI 10.1016/j.ijepes.2022.108073
   Feng ZX, 2020, IEEE T IMAGE PROCESS, V29, P579, DOI 10.1109/TIP.2019.2928126
   Hermans A, 2017, CORR ABS, V1703
   Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Li DG, 2020, AAAI CONF ARTIF INTE, V34, P4610
   Li S, 2017, PROC CVPR IEEE, P5187, DOI 10.1109/CVPR.2017.551
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin W, ARXIV
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Lv JM, 2018, PROC CVPR IEEE, P7948, DOI 10.1109/CVPR.2018.00829
   Ma BP, 2014, IMAGE VISION COMPUT, V32, P379, DOI 10.1016/j.imavis.2014.04.002
   Nguyen DT, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030605
   Park H, 2020, AAAI CONF ARTIF INTE, V34, P11839
   Seokeon Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10254, DOI 10.1109/CVPR42600.2020.01027
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Wang GA, 2019, IEEE I CONF COMP VIS, P3622, DOI 10.1109/ICCV.2019.00372
   Wang Z, 2016, IEEE T MULTIMEDIA, V18, P260, DOI 10.1109/TMM.2015.2505083
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu AC, 2017, IEEE I CONF COMP VIS, P5390, DOI 10.1109/ICCV.2017.575
   Wu AC, 2017, IEEE T IMAGE PROCESS, V26, P2588, DOI 10.1109/TIP.2017.2675201
   Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393
   Xiang XZ, 2019, IEEE SENS J, V19, P11706, DOI 10.1109/JSEN.2019.2936916
   Xu XY, 2020, INT J ARTIF INTELL T, V29, DOI 10.1142/S0218213020500049
   Yan Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13376, DOI 10.1109/CVPR42600.2020.01339
   Ye M., 2020, CORR ABS, V2007, P09314
   Ye M, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1092
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Ye M, 2020, IEEE T IMAGE PROCESS, V29, P9387, DOI 10.1109/TIP.2020.2998275
   Ye M, 2020, IEEE T INF FOREN SEC, V15, P407, DOI 10.1109/TIFS.2019.2921454
   Ye M, 2016, IEEE T MULTIMEDIA, V18, P2553, DOI 10.1109/TMM.2016.2605058
   Zajdel W, 2005, IEEE INT CONF ROBOT, P2081
   Zhang SZ, 2021, IEEE T IMAGE PROCESS, V30, P8861, DOI 10.1109/TIP.2021.3120881
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zhu XT, 2018, IEEE T IMAGE PROCESS, V27, P2286, DOI 10.1109/TIP.2017.2740564
   Zhu Y, 2019, CORRABS, V1910
NR 47
TC 0
Z9 0
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22631
EP 22649
DI 10.1007/s11042-023-14486-y
EA FEB 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000926356600001
DA 2024-07-18
ER

PT J
AU Thota, C
   Mavromoustakis, CX
   Mastorakis, G
AF Thota, Chandu
   Mavromoustakis, Constandinos X.
   Mastorakis, George
TI RDSF-Responsive Data-Sharing Framework for User-Centric Internet of
   Vehicles Assisted Healthcare Systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Data Classification; Data Sharing; Healthcare Systems; Internet of
   Vehicles (IoV); K-Means Clustering
ID IOT; CLOUD
AB Internet of Vehicles (IoV) assisted healthcare systems are designed for providing reliable and dynamic medical assistance for the connected users/ patients. The healthcare systems inherit the intelligent computing models in Internet of Vehicles (IoV) for processing user requests and allocating medical data. In this manuscript, the problem is due to stagnancy in request processing and latency in response dissemination, which is addressed using a responsive data-sharing framework (RDSF). This framework is designed for addressing the afore-mentioned issues in healthcare data searching and allocation. The proposed framework performs searching, organizing, and data allocation without stagnancy in request processing. In this processing, K-means clustering is deployed to differentiate and classify the allocation and searching instances and interrupt in different time intervals. The proposed framework identifies the interrupting instances for improving the response allocation ratio. The linearization of the classification and allocation of the clustering process reduces the complexity in handling healthcare data. The proposed framework's performance shows that it is capable of improving data handling rate by reducing complexity, latency, and request failures. The proposed EDSF increases data response by 12.8%, reduces response latency and interrupt complexity by 7.65% and 10.55% respectively.
C1 [Thota, Chandu; Mavromoustakis, Constandinos X.] Univ Nicosia, Dept Comp Sci, CY-1700 Nicosia, Cyprus.
   [Mastorakis, George] Hellen Mediterranean Univ, Dept Management Sci & Technol, Iraklion 71500, Crete, Greece.
C3 University of Nicosia; Hellenic Mediterranean University
RP Thota, C (corresponding author), Univ Nicosia, Dept Comp Sci, CY-1700 Nicosia, Cyprus.
EM thota.c@live.unic.ac.cy; mavromoustakis.c@unic.ac.cy; gmastorakis@hmu.gr
RI Mavromoustakis, Constandinos/M-8305-2014
OI Mavromoustakis, Constandinos/0000-0003-0333-8034
CR Cai Q, 2019, IEEE ACCESS, V7, P133583, DOI 10.1109/ACCESS.2019.2941419
   Chen L, 2021, WORK, V68, P945, DOI 10.3233/WOR-203428
   Elhoseny M, 2018, FUTURE GENER COMP SY, V86, P1383, DOI 10.1016/j.future.2018.03.005
   Fouad H, 2020, COMPUT COMMUN, V151, P257, DOI 10.1016/j.comcom.2020.01.020
   Gan CQ, 2021, MULTIMED TOOLS APPL, V80, P30605, DOI 10.1007/s11042-020-09322-6
   Gavrilovic N, 2021, J AMB INTEL HUM COMP, V12, P1315, DOI 10.1007/s12652-020-02197-3
   Gong XY, 2019, IEEE ACCESS, V7, P137560, DOI 10.1109/ACCESS.2018.2881020
   Guo XC, 2020, FUTURE GENER COMP SY, V113, P407, DOI 10.1016/j.future.2020.07.023
   Huang Y, 2021, J SEP SCI, DOI 10.1002/jssc.202001079
   Kadhim KT, 2020, WIRELESS PERS COMMUN, V114, P2235, DOI 10.1007/s11277-020-07474-0
   Kumar PM, 2018, FUTURE GENER COMP SY, V86, P527, DOI 10.1016/j.future.2018.04.036
   Latif G, 2020, WIREL NETW, V26, P2375, DOI 10.1007/s11276-019-02165-6
   Li W, 2020, COMPUT METH PROG BIO, V186, DOI 10.1016/j.cmpb.2019.105189
   Li XF, 2019, IEEE ACCESS, V7, P141319, DOI 10.1109/ACCESS.2019.2943817
   Moghadas E, 2020, INTERNET THINGS-NETH, V11, DOI 10.1016/j.iot.2020.100251
   Muthu B, 2020, PEER PEER NETW APPL, V13, P2123, DOI 10.1007/s12083-019-00823-2
   Nazir S, 2020, IEEE ACCESS, V8, P95714, DOI 10.1109/ACCESS.2020.2995572
   Pasluosta CF, 2015, IEEE J BIOMED HEALTH, V19, P1873, DOI 10.1109/JBHI.2015.2461555
   Qiu YH, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.4258
   Rahmani AM, 2021, CLUSTER COMPUT, V24, P1347, DOI 10.1007/s10586-020-03189-w
   Santamaria AF, 2018, COMPUT COMMUN, V128, P60, DOI 10.1016/j.comcom.2018.06.010
   Spagnuelo D, 2020, COMPUT SECUR, V91, DOI 10.1016/j.cose.2020.101717
   Sun JF, 2019, IEEE ACCESS, V7, P101969, DOI 10.1109/ACCESS.2019.2928441
   Sun LF, 2020, IEEE ACCESS, V8, P101079, DOI 10.1109/ACCESS.2020.2997831
   Tantoso E, 2019, ASIAN BIOETHICS REV, V11, P189, DOI 10.1007/s41649-019-00085-3
   Uddin MA, 2020, INTERNET THINGS-NETH, V9, DOI 10.1016/j.iot.2020.100159
   Wang K, 2020, IEEE T NETW SCI ENG, V7, P263, DOI 10.1109/TNSE.2018.2859307
   Wang XN, 2020, IEEE INTERNET THINGS, V7, P3453, DOI 10.1109/JIOT.2020.2971009
   Xu GW, 2019, IEEE ACCESS, V7, P173866, DOI 10.1109/ACCESS.2019.2957149
   Yacchirema D, 2018, PERVASIVE MOB COMPUT, V50, P25, DOI 10.1016/j.pmcj.2018.07.007
   Yang Y, 2019, IEEE ACCESS, V7, P156077, DOI 10.1109/ACCESS.2019.2949879
   Zgheib R, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02136-2
   Zhang QG, 2020, IEEE ACCESS, V8, P165010, DOI 10.1109/ACCESS.2020.3023332
   Zhu SY, 2020, ELECTRON LIBR, V38, P979, DOI 10.1108/EL-07-2020-0219
NR 34
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JAN 23
PY 2023
DI 10.1007/s11042-023-14387-0
EA JAN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8F5IZ
UT WOS:000919698400002
DA 2024-07-18
ER

PT J
AU El-Bendary, MAM
   Faragallah, OS
   Nassar, SS
AF El-Bendary, Mohsen A. M.
   Faragallah, Osama S.
   Nassar, Sabry S.
TI An efficient hidden marking approach for forensic and contents
   verification of digital images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data integrity; Hidden mark; Image verification; DCT; DWT; DFT; MSE;
   PSNR; Correlation; Image attacks
ID MEDICAL IMAGES; WATERMARKING; ALGORITHM; SECURE; SCHEME
AB Recently, forensic tools have been presented for detecting the forged image and illegal image manipulations. This paper presents an efficient and simple image contents verifying approach acting as a forensic technique. The presented approach mechanism is built by adding a hidden mark in a secret images, this mark achieves image integrity verification and detecting the tampering or forgery in the secret/authentic images. The secret/authentic/authentic image is divided to two main partitions, each portion is segmented to small blocks. These blocks in one partition are used to mark the blocks of the second partition using data transform technique. Firstly, the sensitive image is marked according to a self-embedding method. Then, a transform domain is utilized in order to embed a block-based signature into another block of the same image. Common discrete transform domains like DWT, DCT, and DFT are examined individually. Different analyses and comparison measurements are employed. The DCT is proved to be the most suitable and efficient transform domain to be used with the proposed scheme. At the receiver side, the reverse process is performed to verify image integrity. As proved from the experiments, this mark-algorithm is not visible or observable and robust against various attacks.
C1 [El-Bendary, Mohsen A. M.] Helwan Univ, Fac Technol & Educ, Cairo, Egypt.
   [Faragallah, Osama S.] Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, Al Hawiya 21974, Saudi Arabia.
   [Faragallah, Osama S.] Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia 32952, Egypt.
   [Nassar, Sabry S.] Atom Energy Author Egypt, Nucl Res Ctr, Nasr City, Egypt.
C3 Egyptian Knowledge Bank (EKB); Helwan University; Taif University;
   Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Egyptian Atomic Energy Authority (EAEA)
RP El-Bendary, MAM (corresponding author), Helwan Univ, Fac Technol & Educ, Cairo, Egypt.
EM engmohsen2004@yahoo.com
RI El-Bendary, Mohsen A. M./P-8567-2019; Faragallah, Osama S./AHB-8031-2022
OI El-Bendary, Mohsen A. M./0000-0002-2425-4967; Faragallah, Osama
   S./0000-0003-1982-335X
FU The Science, Technology & Innovation Funding Authority (STDF); The
   Egyptian Knowledge Bank (EKB)
FX Funding Open access funding provided by The Science, Technology &
   Innovation Funding Authority (STDF) in cooperation with The Egyptian
   Knowledge Bank (EKB).
CR ABOUELFADL AA, 2014, LIFE SCI J, V11, P342
   Alshanbari HS, 2021, MULTIMED TOOLS APPL, V80, P16549, DOI 10.1007/s11042-020-08814-9
   Ariatmanto D, 2020, MULTIMED TOOLS APPL, V79, P12041, DOI 10.1007/s11042-019-08338-x
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Benrhouma O, 2015, NONLINEAR DYNAM, V79, P1817, DOI 10.1007/s11071-014-1777-3
   Bhalerao S, 2021, J AMB INTEL HUM COMP, V12, P1057, DOI 10.1007/s12652-020-02135-3
   Bianchi T, 2013, IEEE SIGNAL PROC MAG, V30, P87, DOI 10.1109/MSP.2012.2228342
   Botta M, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2568224
   Bouslimi D, 2012, COMPUT METH PROG BIO, V106, P47, DOI 10.1016/j.cmpb.2011.09.015
   Dorgham O, 2018, INT J CLOUD APPL COM, V8, P154, DOI 10.4018/IJCAC.2018010108
   El-Bendary MAM, 2020, MULTIMED TOOLS APPL, V79, P24507, DOI 10.1007/s11042-020-08926-2
   El-Bendary MAM, 2019, MULTIMED TOOLS APPL, V78, P16633, DOI 10.1007/s11042-018-6843-2
   El-Bendary MAM, 2017, MULTIMED TOOLS APPL, V76, P26463, DOI 10.1007/s11042-016-4177-5
   El-Bendary MAMM, 2012, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2012-4
   El-Gohary N., 2016, Journal of Wireless Networking and Communications, V6, P10, DOI DOI 10.5923/J.JWNC.20160601.02
   Geng LF, 2020, J REAL-TIME IMAGE PR, V17, P631, DOI 10.1007/s11554-020-00941-8
   Georgiou T, 2020, INT J MULTIMED INF R, V9, P135, DOI 10.1007/s13735-019-00183-w
   Goebel M., 2019, ELECT IMAGING, V2019, p530, DOI [10.2352/ISSN.2470-1173.2019.5.MWSF-530, DOI 10.2352/ISSN.2470-1173.2019.5.MWSF-530]
   Gupta B., 2016, HDB RES MODERN CRYPT, DOI [10.4018/978-1-5225-0105-3, DOI 10.4018/978-1-5225-0105-3]
   Hasan S M Kamrul, 2018, Brain Inform, V5, P8, DOI 10.1186/s40708-018-0086-x
   Jararweh Y, 2019, MULTIMED TOOLS APPL, V78, P3961, DOI 10.1007/s11042-017-5092-0
   Kasban H, 2022, IET COMMUN, V16, P2479, DOI 10.1049/cmu2.12503
   Kasban H, 2021, ANALOG INTEGR CIRC S, V108, P125, DOI 10.1007/s10470-021-01854-7
   Kasban H, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106728
   Kasban H, 2016, WIRELESS PERS COMMUN, P1
   Kaur R, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106770
   Kazemi MF, 2020, COMPLEX INTELL SYST, V6, P213, DOI 10.1007/s40747-020-00129-4
   Korus P, 2017, DIGIT SIGNAL PROCESS, V71, P1, DOI 10.1016/j.dsp.2017.08.009
   Kumar A, 2019, INT J CLOUD APPL COM, V9, P22, DOI 10.4018/IJCAC.2019070102
   Laouamer L, 2015, ARAB J SCI ENG, V40, P1097, DOI 10.1007/s13369-015-1596-y
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu JE, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/7607612
   Mahmoud MEA, 2014, SECURITY MULTIHOP WI, DOI [10.1007/978-3-319-04603-7, DOI 10.1007/978-3-319-04603-7]
   Mamta, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5291
   Mu Y., 2019, INT J HIGH PERFORM C, V14, P333, DOI [10.1504/IJHPCN.2019.102133, DOI 10.1504/IJHPCN.2019.102133]
   Nassar SS, 2022, MULTIMED TOOLS APPL, V81, P25707, DOI 10.1007/s11042-022-12297-1
   Nassar SS, 2021, WIRELESS PERS COMMUN, V119, P37, DOI 10.1007/s11277-021-08176-x
   Nassar SS, 2016, WIRELESS PERS COMMUN, V88, P479, DOI 10.1007/s11277-015-3142-3
   Nassar SS, 2016, INT J SPEECH TECHNOL, V19, P1, DOI 10.1007/s10772-015-9312-6
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Pourhadi A, 2020, MULTIMED TOOLS APPL, V79, P21653, DOI 10.1007/s11042-020-08960-0
   Robert L., 2009, International Journal of Recent Trends in Engineering, V1, P223
   Shih FY., 2017, DIGITAL WATERMARKING, P292, DOI [10.1201/9781315121109, DOI 10.1201/9781315121109]
   Sultana F, 2013, INT J COMPUT SCI NET, V13, P41
   Tsougenis ED, 2012, J SYST SOFTWARE, V85, P1864, DOI 10.1016/j.jss.2012.02.045
   Urvoy M, 2014, IEEE T INF FOREN SEC, V9, P1108, DOI 10.1109/TIFS.2014.2322497
   von Solms R, 2013, COMPUT SECUR, V38, P97, DOI 10.1016/j.cose.2013.04.004
   Xu GW, 2018, EURASIP J INF SECUR, DOI 10.1186/s13635-018-0083-x
   Xu H, 2020, INT J AUTOM COMPUT, V17, P151, DOI 10.1007/s11633-019-1211-x
   Yang L, 2021, MULTIMED TOOLS APPL, V80, P855, DOI 10.1007/s11042-020-09604-z
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
NR 53
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 25527
EP 25558
DI 10.1007/s11042-022-14104-3
EA JAN 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000926801100003
OA hybrid
DA 2024-07-18
ER

PT J
AU Ashrafi, SS
   Shokouhi, SB
   Ayatollahi, A
AF Ashrafi, Seyed Sajad
   Shokouhi, Shahriar B.
   Ayatollahi, Ahmad
TI Still image action recognition based on interactions between joints and
   objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Still image-based action recognition; Self-attention; Cross-attention;
   Convolutional neural networks (CNN); Atrous spatial pyramid pooling
   (ASPP)
AB Still image-based action recognition is a challenging area in which recognition is performed based on only a single input image. Utilizing auxiliary information such as pose, object, or background is one of the common techniques in this field. However, the simultaneous use of several auxiliary components and their optimal combinations is less studied. In this study, two cues of body joints and objects have been employed simultaneously, and an attention module is proposed to combine the features of these two components. The attention module consists of two self-attentions and a cross-attention, which are designed to account for the interaction between the objects, between the joints, and between the joints and objects, respectively. In addition, the Multi-scale Atrous Spatial Pyramid Pooling (MASPP) module is proposed to reduce the number of parameters of the proposed method and at the same time, combine the features obtained from different levels of the backbone. The Joint Object Pooling (JOPool) module is proposed to extract local features from joints and objects regions. ResNets are used as the backbone, and the stride of the last two layers is changed. Experimental results on different datasets show that the combination of several auxiliary components can be effective in increasing the mean Average Precision (mAP) of recognition. The proposed method is evaluated on three important datasets: Stanford-40, PASCAL VOC 2012, and BU101PLUS resulting in 94.84%, 93.20%, and 91.25% mAPs, respectively. The obtained mAPs are higher than the best preceding proposed methods.
C1 [Ashrafi, Seyed Sajad; Shokouhi, Shahriar B.; Ayatollahi, Ahmad] Iran Univ Sci & Technol IUST, Elect Engn Dept, Tehran, Iran.
C3 Iran University Science & Technology
RP Shokouhi, SB (corresponding author), Iran Univ Sci & Technol IUST, Elect Engn Dept, Tehran, Iran.
EM s_ashrafi@elec.iust.ac.ir; bshokouhi@iust.ac.ir; ayatollahi@iust.ac.ir
CR Akti S, 2021, PROC 2022 IEEECVF WI, P550, DOI [10.48550/arxiv.2111.08370, DOI 10.48550/ARXIV.2111.08370]
   Ashrafi SS, 2021, MULTIMED TOOLS APPL, V80, P32567, DOI 10.1007/s11042-021-11215-1
   Beddiar DR, 2020, MULTIMED TOOLS APPL, V79, P30509, DOI 10.1007/s11042-020-09004-3
   Cao Y, 2021, MULTIMED TOOLS APPL, V80, P29139, DOI 10.1007/s11042-021-11136-z
   Chakraborty S, 2021, MULTIMED TOOLS APPL, V80, P20547, DOI 10.1007/s11042-021-10753-y
   Chapariniya Masoumeh, 2020, Proceedings of the 10th International Conference on Computer and Knowledge Engineering (ICCKE 2020), P274, DOI 10.1109/ICCKE50421.2020.9303716
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Dean J., 2015, NIPS DEEP LEARNING R
   Dehkordi Hojat Asgarian, 2021, 2021 7th International Conference on Web Research (ICWR), P125, DOI 10.1109/ICWR51868.2021.9443021
   Dehkordi HA, 2022, KNOWL-BASED SYST, V250, DOI 10.1016/j.knosys.2022.109091
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Gkioxari G, 2015, IEEE I CONF COMP VIS, P1080, DOI 10.1109/ICCV.2015.129
   Guo GD, 2014, PATTERN RECOGN, V47, P3343, DOI 10.1016/j.patcog.2014.04.018
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Hu T, 2019, MULTIMED TOOLS APPL, V78, P28515, DOI 10.1007/s11042-017-5496-x
   Kim S, 2019, IEEE WINT CONF APPL, P61, DOI 10.1109/WACV.2019.00014
   Kipf TN, 2017, INT C LEARN REPR
   Li Y, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107341
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liu L, 2019, LECT NOTES COMPUT SC, V11365, P152, DOI 10.1007/978-3-030-20873-8_10
   Ludl D, 2019, IEEE INT C INTELL TR, P581, DOI 10.1109/ITSC.2019.8917128
   Ma SG, 2017, PATTERN RECOGN, V68, P334, DOI 10.1016/j.patcog.2017.01.027
   Ma WT, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102933
   Maji S, ACTION RECOGNITION D
   McAuley J, 2012, LECT NOTES COMPUT SC, V7575, P828, DOI 10.1007/978-3-642-33765-9_59
   Mi SY, 2022, APPL INTELL, V52, P6760, DOI 10.1007/s10489-021-02760-1
   Mohammadi S, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE 2019), P315, DOI [10.1109/ICCKE48569.2019.8965014, 10.1109/iccke48569.2019.8965014]
   Procesi C, 2007, LIE GROUPS APPROACH, P596
   Qi TQ, 2017, NEUROCOMPUTING, V267, P475, DOI 10.1016/j.neucom.2017.06.041
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren ZL, 2021, MULTIMED TOOLS APPL, V80, P16185, DOI 10.1007/s11042-019-08576-z
   Simonyan K, 2014, ADV NEUR IN, V27
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Wang C, 2016, IEEE IJCNN, P1924, DOI 10.1109/IJCNN.2016.7727435
   Wang J, 2022, POSE ENHANCED RELATI, P154, DOI [10.1007/978-3-030-98358-1_13, DOI 10.1007/978-3-030-98358-1_13]
   Wang XF, 2020, MULTIMED TOOLS APPL, V79, P7413, DOI 10.1007/s11042-019-08535-8
   Xin M, 2019, IEEE INT CON MULTI, P1042, DOI 10.1109/ICME.2019.00183
   Xu Y, 2019, MULTIMED TOOLS APPL, V78, P25063, DOI 10.1007/s11042-019-7593-5
   Yan SY, 2018, IEEE T COGN DEV SYST, V10, P1116, DOI 10.1109/TCDS.2017.2783944
   Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386
   Zeng HL, 2007, ADV INTEL SYS RES, DOI 10.2991/iske.2007.2
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
   Zhao ZC, 2017, IEEE I CONF COMP VIS, P3411, DOI 10.1109/ICCV.2017.367
   Zheng YP, 2020, NEUROCOMPUTING, V413, P383, DOI 10.1016/j.neucom.2020.07.016
   Zhu Y, 2020, ARXIV
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 54
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 25945
EP 25971
DI 10.1007/s11042-023-14350-z
EA JAN 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000911268400003
DA 2024-07-18
ER

PT J
AU Singh, V
   Agrawal, P
   Sharma, T
   Verma, NK
AF Singh, Vikas
   Agrawal, Pooja
   Sharma, Teena
   Verma, Nishchal K.
TI Improved adaptive type-2 fuzzy filter with exclusively two fuzzy
   membership function for filtering salt and pepper noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salt and pepper noise; Fuzzy set; PSNR; Structural similarity index;
   Statistical test; Type-1; Type-2 fuzzy set
ID SWITCHING MEDIAN FILTER; REMOVAL; SYSTEM; RECOGNITION; IMAGES
AB Image denoising is one of the preliminary steps in image processing methods in which the presence of noise can deteriorate image quality. This paper presents an improved two-stage fuzzy filter for filtering salt and pepper noise from the images to enhance the image quality. In the first stage, the pixels in the image are categorized as good or noisy based on adaptive thresholding using type-2 fuzzy logic with exclusively two different membership functions in the filter window. In the second stage, the noisy pixels are denoised using modified ordinary fuzzy logic in the respective filter window. The proposed filter is validated on standard images with various noise levels. The proposed filter removes the noise and preserves beneficial image characteristics, i.e., edges and corners at higher noise levels. The performance of the proposed filter is compared with the various state-of-the-art methods in terms of peak signal-to-noise ratio and computation time. The average PSNR values for the noise percentage 20%, 50% and 80% are the 37%, 31% and 27%. To show the effectiveness of statistical filter tests, i.e., the Friedman test and Bonferroni-Dunn (BD) test are also carried out, which ascertain that the proposed filter outperforms in comparison to various filtering approaches.
C1 [Singh, Vikas; Agrawal, Pooja; Sharma, Teena; Verma, Nishchal K.] Indian Inst Technol Kanpur, Kanpur, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kanpur
RP Singh, V (corresponding author), Indian Inst Technol Kanpur, Kanpur, India.
EM vikkyk@iitk.ac.in; pooja.iitd@gmail.com; teenashr@iitk.ac.in;
   nishchal@iitk.ac.in
CR Ahmed F, 2014, IEEE T FUZZY SYST, V22, P1352, DOI 10.1109/TFUZZ.2013.2286634
   Astola J., 1997, Fundamentals of nonlinear digital filtering, DOI DOI 10.1201/9781003067832
   Bakkouri I, 2022, MULTIMED TOOLS APPL, V81, P10743, DOI 10.1007/s11042-022-12242-2
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Bharadhwaj Homanga, 2019, Computational Intelligence: Theories, Applications and Future Directions - Volume I. ICCI-2017. Advances in Intelligent Systems and Computing (AISC 798), P359, DOI 10.1007/978-981-13-1132-1_28
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   BROWNRIGG DRK, 1984, COMMUN ACM, V27, P807, DOI 10.1145/358198.358222
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Chen CLP, 2015, IEEE T IMAGE PROCESS, V24, P4014, DOI 10.1109/TIP.2015.2456432
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Crnojevic V, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/830702
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Dubois D.J., 1980, Fuzzy Sets and Systems: Theory and Applications, V144
   Erkan U, 2018, COMPUT ELECTR ENG, V70, P789, DOI 10.1016/j.compeleceng.2018.01.019
   Etoundi CML, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14030493
   Ghanekar U, 2010, IEEE SIGNAL PROC LET, V17, P1, DOI 10.1109/LSP.2009.2032479
   González-Hidalgo M, 2018, APPL SOFT COMPUT, V63, P167, DOI 10.1016/j.asoc.2017.11.030
   Karnik NN, 1999, IEEE T FUZZY SYST, V7, P643, DOI 10.1109/91.811231
   Khanesar MA, 2011, IEEE T SYST MAN CY B, V41, P1395, DOI 10.1109/TSMCB.2011.2148173
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   Lee C.-S., 2000, Fuzzy Techniques in Image Processing, P172
   Lee CS, 1997, FUZZY SET SYST, V89, P157, DOI 10.1016/S0165-0114(96)00075-9
   Liang QL, 2000, IEEE T FUZZY SYST, V8, P551, DOI 10.1109/91.873578
   Liu LC, 2018, IEEE T CIRC SYST VID, V28, P2177, DOI 10.1109/TCSVT.2017.2722232
   Lu L, 2015, IEEE SIGNAL PROC LET, V22, P833, DOI 10.1109/LSP.2014.2371332
   Mélange T, 2011, IEEE T IMAGE PROCESS, V20, P959, DOI 10.1109/TIP.2010.2077305
   Melin P., 2005, STUD FUZZ SOFT COMP, P1
   Mendel JM, 2002, IEEE T FUZZY SYST, V10, P117, DOI 10.1109/91.995115
   Ng PE, 2006, IEEE T IMAGE PROCESS, V15, P1506, DOI 10.1109/TIP.2005.871129
   Pitas I., 1990, NONLINEAR DIGITAL FI
   Rajurkar S, 2017, IEEE INT CONF FUZZY
   Rojas R, 2011, EUR SIGNAL PR CONF, P278
   Roy A, 2018, IEEE T IND ELECTRON, V65, P7268, DOI 10.1109/TIE.2018.2793225
   Roy A, 2016, APPL SOFT COMPUT, V46, P816, DOI 10.1016/j.asoc.2015.09.032
   Schuster T, 2017, SOFT COMPUT, V21, P3659, DOI 10.1007/s00500-017-2669-5
   Sevakula RK, 2017, IEEE T FUZZY SYST, V25, P1446, DOI 10.1109/TFUZZ.2017.2722421
   Sheskin J, 2003, HDB PARAMETRIC NONPA
   Sing V, 2019, IEEE T NANOBIOSCI, V18, P482, DOI 10.1109/TNB.2019.2917814
   Singh V, 2018, IEEE POW ENER SOC GE, P1, DOI DOI 10.1109/CCAA.2018.8777341
   Singh V, 2018, IEEE T FUZZY SYST, V26, P3170, DOI 10.1109/TFUZZ.2018.2805289
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Toh KKV, 2010, IEEE SIGNAL PROC LET, V17, P281, DOI 10.1109/LSP.2009.2038769
   Verma Nishchal K., 2019, Computational Intelligence: Theories, Applications and Future Directions - Volume I. ICCI-2017. Advances in Intelligent Systems and Computing (AISC 798), P375, DOI 10.1007/978-981-13-1132-1_29
   Verma NK, 2007, IEEE T FUZZY SYST, V15, P809, DOI 10.1109/TFUZZ.2006.889821
   Verma NK, 2010, IEEE T FUZZY SYST, V18, P40, DOI 10.1109/TFUZZ.2009.2034532
   Wang Y, 2016, IEEE SIGNAL PROC LET, V23, P1582, DOI 10.1109/LSP.2016.2607785
   Weber A. G., 1997, USC-SIPI Report, V315
   Yildirim MT, 2008, IEEE T FUZZY SYST, V16, P920, DOI 10.1109/TFUZZ.2008.924358
   Yüksel ME, 2012, IEEE COMPUT INTELL M, V7, P25, DOI 10.1109/MCI.2012.2200624
   ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90046-8
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhai DY, 2012, INT J UNCERTAIN FUZZ, V20, P207, DOI 10.1142/S0218488512400211
   Zhang PX, 2014, IEEE SIGNAL PROC LET, V21, P1280, DOI 10.1109/LSP.2014.2333012
   Zhou Z, 2012, IEEE T IMAGE PROCESS, V21, P3157, DOI 10.1109/TIP.2012.2189577
NR 56
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20015
EP 20037
DI 10.1007/s11042-022-14248-2
EA DEC 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000893056800008
DA 2024-07-18
ER

PT J
AU Wu, YR
   Shen, XJ
   Abhadiomhen, SE
   Yang, Y
   Gu, JN
AF Wu, YuRen
   Shen, Xiang-Jun
   Abhadiomhen, Stanley Ebhohimhen
   Yang, Yang
   Gu, Ji-Nan
TI Kernel ensemble support vector machine with integrated loss in shared
   parameters space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kernel classification; Multiple kernel learning; Ensemble model; Shared
   parameters
ID FRAMEWORK; MATRIX
AB In this paper, we propose a kernel ensemble SVM with integrated loss in shared parameters space. Different from the traditional multiple kernel learning methods of seeking linear combinations of basis kernels as a unified kernel, the proposed method aims to find multiple solutions in corresponding Reproducing Kernel Hilbert Spaces (RKHSs) simultaneously. To achieve this goal, we draw on the idea of multi-view data processing, and the individual kernel gram matrix is considered as one view of the data. We, therefore, propose an ensemble idea to combine those multiple individual kernel losses into a whole one through an integrated loss design. Therefore, each model can co-optimize to learn its optimal parameters by minimizing the integrated loss in multiple RKHSs. Besides, another feature of our method is the introduction of shared and specific parameters in multiple RKHSs for learning. In this manner, the proposed model can learn the common and individual structures of the data from its parameters space, thereby improving the accuracy of the classification task and further enhancing the robustness of the proposed ensemble model. Experimental results on several UCI classification and image datasets demonstrate that our method performs best among state-of-the-art MKL methods, such as SimpleMKL, EasyMKL, MREKLM, and MRMKL.
C1 [Wu, YuRen; Shen, Xiang-Jun; Abhadiomhen, Stanley Ebhohimhen; Yang, Yang] JiangSu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Abhadiomhen, Stanley Ebhohimhen] Univ Nigeria, Dept Comp Sci, Nsukka, Nigeria.
   [Gu, Ji-Nan] JiangSu Univ, Sch Mech Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
C3 Jiangsu University; University of Nigeria; Jiangsu University
RP Shen, XJ (corresponding author), JiangSu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
EM xjshen@ujs.edu.cn
RI Abhadiomhen, Stanley Ebhohimhen/AAH-5788-2021
OI Abhadiomhen, Stanley Ebhohimhen/0000-0002-9509-1915
FU Graduate Research and Innovation Projects of Jiangsu Province
   [SJCX211694]; Science and Technology Planning Social Development Project
   of Zhenjiang City [SH2021006]
FX This work was funded in part by the Graduate Research and Innovation
   Projects of Jiangsu Province (No.SJCX211694) and the Science and
   Technology Planning Social Development Project of Zhenjiang City
   (No.SH2021006).
CR Aiolli F, 2015, NEUROCOMPUTING, V169, P215, DOI 10.1016/j.neucom.2014.11.078
   [Anonymous], 2006, Adv Neural Inf Process Syst
   Anstreicher KM, 2012, MATH PROGRAM, V136, P233, DOI 10.1007/s10107-012-0602-3
   Bach F. R., 2005, ADV NEURAL INFORM PR, P73
   Bach Francis R, 2004, P 21 INT C MACH LEAR, P6, DOI 10.1145/1015330.1015424
   Cortes C, 2012, J MACH LEARN RES, V13, P795
   Crammer K., 2002, ADV NEURAL INF PROCE, V15, P553
   Cristianini N., 2000, An Introduction to Support Vector Machines and Other Kernel-Based Learning Methods, DOI [10.1017/CBO9780511801389, DOI 10.1017/CBO9780511801389]
   Fan Q, 2017, PATTERN RECOGN, V61, P197, DOI 10.1016/j.patcog.2016.07.027
   Gonen M., 2013, PMLR, P864
   Gönen M, 2011, J MACH LEARN RES, V12, P2211
   Han YN, 2018, IEEE T NEUR NET LEAR, V29, P4997, DOI 10.1109/TNNLS.2017.2785329
   Han YN, 2018, IEEE T NEUR NET LEAR, V29, P486, DOI 10.1109/TNNLS.2016.2635151
   Hinrichs Chris., 2012, Advances in neural information processing systems, P1421
   Hu MQ, 2009, IEEE T NEURAL NETWOR, V20, P827, DOI 10.1109/TNN.2009.2014229
   Kim TK, 2015, KOREAN J ANESTHESIOL, V68, P540, DOI 10.4097/kjae.2015.68.6.540
   KIMELDORF G, 1971, J MATH ANAL APPL, V33, P82, DOI 10.1016/0022-247X(71)90184-3
   Kloft M, 2011, J MACH LEARN RES, V12, P953
   Kwok JTY, 2004, IEEE T NEURAL NETWOR, V15, P1517, DOI 10.1109/TNN.2004.837781
   Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27
   Lanckriet GRG, 2004, BIOINFORMATICS, V20, P2626, DOI 10.1093/bioinformatics/bth294
   Li JX, 2021, INFORM FUSION, V65, P108, DOI 10.1016/j.inffus.2020.08.020
   Li ZQ, 2017, PROC IEEE INT CONF S, P91, DOI 10.1109/ICSME.2017.19
   Liu H., 2019, P 2019 IEEE 8 DATA D, P18, DOI [10.1109/DDCLS.2019.8908926, DOI 10.1109/DDCLS.2019.8908926]
   Liu JM, 2014, IEEE T IMAGE PROCESS, V23, P4022, DOI 10.1109/TIP.2014.2343458
   Mao Q, 2015, IEEE T NEUR NET LEAR, V26, P1134, DOI 10.1109/TNNLS.2014.2334137
   Margineantu D.D., 1997, ICML, V97, P211
   Ong CS, 2022, LEARNING KERNEL HYPE
   Qi CM, 2016, 2016 INT IEEE CONFERENCES ON UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING AND COMMUNICATIONS, CLOUD AND BIG DATA COMPUTING, INTERNET OF PEOPLE, AND SMART WORLD CONGRESS (UIC/ATC/SCALCOM/CBDCOM/IOP/SMARTWORLD), P456, DOI [10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0082, 10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.72]
   Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491
   Recht B, 2022, ARXIV
   Scholkopf B., 2002, Learning with Kernels
   Shen XJ, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107587
   Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Sun T, 2013, PATTERN RECOGN, V46, P3081, DOI 10.1016/j.patcog.2013.04.003
   Varma M., 2009, Proceedings of the 26th Annual International Conference on Machine Learning, P1065, DOI DOI 10.1145/1553374.1553510
   Vishwanathan S, 2002, IEEE IJCNN, P2393, DOI 10.1109/IJCNN.2002.1007516
   Wang Q., 2020, arXiv
   Wu D, 2020, IEEE T SMART GRID, V11, P1183, DOI 10.1109/TSG.2019.2933413
   Wu Zheng-Peng, 2011, Acta Automatica Sinica, V37, P693, DOI 10.3724/SP.J.1004.2011.00693
   Xia H, 2013, IEEE T KNOWL DATA EN, V25, P1574, DOI 10.1109/TKDE.2012.89
   Xu XX, 2013, IEEE T NEUR NET LEAR, V24, P749, DOI 10.1109/TNNLS.2012.2237183
   Ye JP, 2008, J MACH LEARN RES, V9, P719
   Zhou JJ, 2015, 2015 CONFERENCE ON TECHNOLOGIES AND APPLICATIONS OF ARTIFICIAL INTELLIGENCE (TAAI), P273, DOI 10.1109/TAAI.2015.7407123
   Zhou J, 2021, IEEE T SYST MAN CY-S, V51, P6015, DOI 10.1109/TSMC.2019.2958647
NR 46
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18077
EP 18096
DI 10.1007/s11042-022-14226-8
EA DEC 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000893056800001
DA 2024-07-18
ER

PT J
AU Sahoo, M
   Patani, A
   Makwana, B
AF Sahoo, Madhusmita
   Patani, Aswin
   Makwana, Balvant
TI A review on Di-electrical resonant antenna based on the performance of
   gain and bandwidth
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Dielectric resonator antenna; Cylindrical DRA (C-DRA); Rectangular DRA
   (R-DRA); Coplanar wave guide; Circular polarization (CP)
ID PARASITIC ARRAY; SLOT ANTENNA; COMPACT; ENHANCEMENT; SIZE; DRA;
   POLARIZATION; REDUCTION; DESIGN; KU
AB This article presents a historical overview of research focused on dielectric resonator antennas (DRAs) over the past few decades. The dielectric resonators (DR) provide the most attractive features as antenna elements, including high radiation efficiency, large bandwidth, small size, most accessible coupling schemes, etc. The essential characteristics of DRAs are described in detail by reviewing the most potent methods for antenna feeding and size reduction. Moreover, recent design solutions for improving the realized gain of particular DRAs are analyzed. Numerous application-oriented DRAs are discussed in this article which helps to make the survey more effective. The DR antenna was utilized in various applications because of the low cost, enlarged design flexibility, and reduced loss. The requirement of 5G communication is fulfilled by using the appropriate antenna with enhanced bandwidth. For 5G communications, a microstrip patch antenna (MSA) is considered a better choice. Also, a low profile wide band hybrid stacked DRA can be utilized for Ku and K band applications. In millimetre wave application, the reduction of ohmic losses is considered the primary goal. Thus, the millimetre wave applications select the DRAs with minimum ohmic losses. Also, the gain enhancement of DRA through different shapes, feed coupling schemes, and various modes are discussed. Finally, the simulation results of several existing approaches are analyzed in terms of gain, radiation pattern, reflection coefficient, radiation efficiency, and return loss.
C1 [Sahoo, Madhusmita; Patani, Aswin] Indus Univ, Elect & Commun, Ahmadabad 382115, Gujarat, India.
   [Makwana, Balvant] Govt Engn Coll, Elect & Commun, Rajkot 360005, Gujarat, India.
RP Sahoo, M (corresponding author), Indus Univ, Elect & Commun, Ahmadabad 382115, Gujarat, India.
EM madhus.biet@gmail.com
CR Abedian M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-86381-1
   Abirami R, 2020, 2020 INT C SYSTEM CO, P1, DOI DOI 10.1109/ICSCAN49426.2020.9262349
   Addepalli T, 2020, AEU-INT J ELECTRON C, V114, DOI 10.1016/j.aeue.2019.153016
   Ahmad Z, 2018, IEEE ANTENN WIREL PR, V17, P1769, DOI 10.1109/LAWP.2018.2865453
   Al-Alem Y, 2019, IEEE ANTENN WIREL PR, V18, P2711, DOI 10.1109/LAWP.2019.2949947
   Al-Gburi AJA, 2020, IEEE ACCESS, V8, P92697, DOI 10.1109/ACCESS.2020.2995069
   Ali I., 2019, TELKOMNIKA TELECOMMU, V17, P1670, DOI DOI 10.12928/TELKOMNIKA.V17I4.12770
   Ali I, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030675
   [Anonymous], 2011, INT J ENG SCI TECHNO
   Anuar SU, 2020, AEU-INT J ELECTRON C, V118, DOI 10.1016/j.aeue.2020.153172
   Bahreini B, 2019, IEEE ANTENN WIREL PR, V18, P1410, DOI 10.1109/LAWP.2019.2918154
   Bahreini B, 2018, IEEE ANTENN WIREL PR, V17, P1802, DOI 10.1109/LAWP.2018.2865682
   Bai H, 2020, AEU-INT J ELECTRON C, V126, DOI 10.1016/j.aeue.2020.153402
   Baldazzi E, 2020, IEEE ANTENN WIREL PR, V19, P949, DOI 10.1109/LAWP.2020.2984565
   Bernard T.St., 2015, 2015 IEEE International Ultrasonics Symposium (IUS), IEEE, P1
   Chauhan M, 2019, MICROW OPT TECHN LET, V61, P2268, DOI 10.1002/mop.31887
   Chen HN, 2019, IEEE ACCESS, V7, P140889, DOI 10.1109/ACCESS.2019.2943880
   Chen Q, 2018, IEEE ANTENN WIREL PR, V17, P1411, DOI 10.1109/LAWP.2018.2848639
   Chen Z, 2018, IEEE T ANTENN PROPAG, V66, P444, DOI 10.1109/TAP.2017.2762005
   Chen Z, 2017, IEEE T ANTENN PROPAG, V65, P2157, DOI 10.1109/TAP.2017.2676767
   Chen ZJ, 2020, IEEE T ANTENN PROPAG, V68, P3271, DOI 10.1109/TAP.2019.2950101
   Chietera FP, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11010064
   Chowdhury R, 2018, IEEE ANTENN WIREL PR, V17, P1727, DOI 10.1109/LAWP.2018.2864819
   Dadgarpour A, 2017, IEEE ANTENN WIREL PR, V16, P477, DOI 10.1109/LAWP.2016.2585127
   Das S, 2018, IEEE T ANTENN PROPAG, V66, P4309, DOI 10.1109/TAP.2018.2836463
   Dash SKK, 2018, INT J RF MICROW C E, V28, DOI 10.1002/mmce.21270
   Dash SKK, 2016, J MICROWAVE POWER EE, V50, P269, DOI 10.1080/08327823.2016.1260677
   Dhar S, 2018, IET MICROW ANTENNA P, V12, P895, DOI 10.1049/iet-map.2017.0864
   Elajoumi S., 2019, TELKOMNIKA Telecommunication, Computing, Electronics and Control, V17, P1559, DOI [10.12928/telkomnika.v17i3.9184, DOI 10.12928/TELKOMNIKA.V17I3.9184]
   Feng LY, 2017, IEEE T ANTENN PROPAG, V65, P3308, DOI 10.1109/TAP.2017.2700225
   Gaya A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082694
   Ghimire J, 2019, INT J ANTENN PROPAG, V2019, DOI 10.1155/2019/8945386
   Gupta S, 2019, FREQUENZ, V73, P227, DOI 10.1515/freq-2018-0215
   Harnsoongnoen S, 2017, IEEE SENS J, V17, P1635, DOI 10.1109/JSEN.2017.2652121
   Jaiverdhan, 2020, INT J RF MICROW C E, V30, DOI 10.1002/mmce.22142
   Jamaluddin Mohd Haizal, 2016, 2016 IEEE Asia-Pacific Conference on Applied Electromagnetics (APACE). Proceedings, P286, DOI 10.1109/APACE.2016.7916443
   Kerketta SR, 2019, INT J RF MICROW C E, V29, DOI 10.1002/mmce.21868
   Keyrouz S, 2016, INT J ANTENN PROPAG, V2016, DOI 10.1155/2016/6075680
   Krishna C. Murali, 2019, Microelectronics, Electromagnetics and Telecommunications. Proceedings of the Fourth ICMEET 2018. Lecture Notes in Electrical Engineering (LNEE 521), P299, DOI 10.1007/978-981-13-1906-8_31
   Kumar J, 2014, WIRELESS PERS COMMUN, V75, P1029, DOI 10.1007/s11277-013-1406-3
   Kumar R, 2019, MICROW OPT TECHN LET, V61, P1863, DOI 10.1002/mop.31808
   Lavuri NR, 2021, INT J SPEECH TECHNOL, V24, P737, DOI 10.1007/s10772-021-09841-z
   Leung KW, 2012, P IEEE, V100, P2181, DOI 10.1109/JPROC.2012.2187872
   Li CH, 2019, IEEE ACCESS, V7, P7737, DOI 10.1109/ACCESS.2018.2890678
   Li XH, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030876
   Lim EH, 2008, IEEE T ANTENN PROPAG, V56, P5, DOI 10.1109/TAP.2007.913152
   Liu NW, 2019, IET MICROW ANTENNA P, V13, P1969, DOI 10.1049/iet-map.2018.6110
   Liu SB, 2019, INT J RF MICROW C E, V29, DOI 10.1002/mmce.21613
   Long S.A., 2007, 2007 INT C ELECTROMA, P872
   Low JH, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-72021-7
   Luo SY, 2019, APPL COMPUT ELECTROM, V34, P411
   Marrocco V, 2019, PR ELECTROMAGN RES S, P174, DOI [10.1109/piers-spring46901.2019.9017673, 10.1109/PIERS-Spring46901.2019.9017673]
   Meher PR, 2020, INT J RF MICROW C E, V30, DOI 10.1002/mmce.22221
   Meher PR, 2021, INT J RF MICROW C E, V31, DOI 10.1002/mmce.22589
   Mishra R., 2020, EAI ENDORSED T ENERG, V8
   Mneesy TS, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10134546
   Mohanty S., 2021, TURK J COMPUT MATH E, V12, P3809
   Movahedinia R, 2018, IEEE T ANTENN PROPAG, V66, P721, DOI 10.1109/TAP.2017.2780895
   Mrnka M, 2016, IEEE ANTENN WIREL PR, V15, P710, DOI 10.1109/LAWP.2015.2470099
   Mukherjee B, 2020, J ELECTROMAGNET WAVE, V34, P1095, DOI 10.1080/09205071.2020.1744484
   Muntoni G, 2020, IEEE ANTENN WIREL PR, V19, P1118, DOI 10.1109/LAWP.2020.2990944
   Musselman RL, 2019, APPL COMPUT ELECTROM, V34, P288
   Nalanagula R, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21124100
   Nasir J, 2015, INT J RF MICROW C E, V25, P495, DOI 10.1002/mmce.20884
   Nawaz H, 2016, MICROW OPT TECHN LET, V58, P1651, DOI 10.1002/mop.29876
   Panda RA, 2020, MATER TODAY-PROC, V26, P439, DOI 10.1016/j.matpr.2019.12.078
   Patel, 2015, INT J RES DEV TECHNO, V4, P2349
   Petosa A, 2010, IEEE ANTENN PROPAG M, V52, P91, DOI 10.1109/MAP.2010.5687510
   Rana B, 2016, J ELECTROMAGNET WAVE, V30, P1521, DOI 10.1080/09205071.2016.1202148
   Roy A.K., 2019, J. Electron. Sci. Technol., V17, P90
   Sahoo AK, 2018, IET MICROW ANTENNA P, V12, P1514, DOI 10.1049/iet-map.2017.1159
   Sharma D, 2020, INT J RES APPL SCI E, V8
   Singh G, 2019, J ELECTROMAGNET WAVE, V33, P2096, DOI 10.1080/09205071.2019.1663274
   Singhwal SS, 2020, J ELECTROMAGNET WAVE, V34, P1180, DOI 10.1080/09205071.2020.1730984
   Sun WJ, 2019, INT J RF MICROW C E, V29, DOI 10.1002/mmce.21897
   Tirado-Mendez JA, 2019, INT J ANTENN PROPAG, V2019, DOI 10.1155/2019/6393401
   Tong CW, 2019, IEEE ANTENN WIREL PR, V18, P786, DOI 10.1109/LAWP.2019.2903143
   Tubbal F, 2019, ANN TELECOMMUN, V74, P223, DOI 10.1007/s12243-018-0674-z
   Ullah U, 2017, CHINA COMMUN, V14, P65, DOI 10.1109/CC.2017.7961364
   Varshney G, 2019, IET MICROW ANTENNA P, V13, P2193, DOI 10.1049/iet-map.2018.5799
   Varshney G, 2018, IEEE T ANTENN PROPAG, V66, P2067, DOI 10.1109/TAP.2018.2800799
   Viswanadha K, 2021, INT J ELECTRON, V108, P647, DOI 10.1080/00207217.2020.1793411
   Wang XY, 2020, IEEE ANTENN WIREL PR, V19, P502, DOI 10.1109/LAWP.2020.2964569
   Xia ZX, 2019, IEEE ANTENN WIREL PR, V18, P2110, DOI 10.1109/LAWP.2019.2938009
   Xu ZQ, 2019, AEU-INT J ELECTRON C, V98, P68, DOI 10.1016/j.aeue.2018.10.039
   Yang N, 2020, IEEE T ANTENN PROPAG, V68, P3248, DOI 10.1109/TAP.2019.2944532
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850945
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Yu Y, 2021, IEICE ELECTRON EXPR, V18, DOI 10.1587/elex.18.20200418
   Zainud-Deen SH, 2019, PLASMONICS, V14, P1321, DOI 10.1007/s11468-019-00996-9
   Zhu HL, 2013, IEEE T ANTENN PROPAG, V61, P4615, DOI 10.1109/TAP.2013.2267712
   Zhu SS, 2018, IEEE ANTENN WIREL PR, V17, P776, DOI 10.1109/LAWP.2018.2816038
   Zubir IA, 2020, IEEE ACCESS, V8, P151219, DOI 10.1109/ACCESS.2020.3016432
NR 93
TC 1
Z9 1
U1 4
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24645
EP 24679
DI 10.1007/s11042-022-14243-7
EA NOV 2022
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000889032600003
DA 2024-07-18
ER

PT J
AU Ayubi, J
   Amirani, MC
   Valizadeh, M
AF Ayubi, Jila
   Amirani, Mehdi Chehel
   Valizadeh, Morteza
TI A New Seam Carving Method for Image Resizing Based on Entropy Energy and
   Lyapunov Exponent
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image resizing; Seam-carving; Entropy; Lyapunov exponent
ID VISUAL-ATTENTION; DEPTH; MODEL
AB One of the most popular techniques in the field of image retargeting or content-aware resizing a digital image is the seam-carving technique. The performance of image resizing algorithms based on seam-carving indicates that these algorithms are highly dependent on the extraction of importance map techniques. So far, various algorithms have been proposed to extract the importance map. In this paper, a new method based on information entropy is proposed to extract of importance map. Also, a new method for selecting the most optimal seam based on the calculation of the Lyapunov exponents is presented. In simulating the proposed method, two datasets MSRA and RetargetMe have been used, which use two statistical opinions criteria and aspect ratio similarity (ARS) to evaluate the performance of the proposed method. Simulation results based on dynamical systems analysis showed that the proposed algorithm performs better than the classical seam-carving and generalized seam-carving algorithms.
C1 [Ayubi, Jila; Amirani, Mehdi Chehel; Valizadeh, Morteza] Urmia Univ, Dept Elect Engn, Orumiyeh, Iran.
C3 Urmia University
RP Ayubi, J (corresponding author), Urmia Univ, Dept Elect Engn, Orumiyeh, Iran.
EM jila.ayubi@gmail.com
RI Chehel Amirani, Mehdi/AGL-1681-2022; Ayubi, Jila/AAQ-6045-2020
OI Ayubi, Jila/0000-0002-0885-0742
CR Abebe MA, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS), P174, DOI 10.1109/SITIS.2018.00035
   Achanta R, 2009, IEEE IMAGE PROC, P1005, DOI 10.1109/ICIP.2009.5413815
   [Anonymous], 2005, P 18 ANN ACM S US IN
   [Anonymous], RETARGETME DATASET
   [Anonymous], MSRA10K SALIENT OBJE
   Arar M, ARXIV
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Ayubi P, 2021, ARTIF INTELL REV, V54, P1237, DOI 10.1007/s10462-020-09877-8
   Ayubi P, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102472
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Barani MJ, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102509
   Battiato S, 2014, IEEE T IMAGE PROCESS, V23, P2081, DOI 10.1109/TIP.2014.2312649
   Chen LQ, 2003, MULTIMEDIA SYST, V9, P353, DOI 10.1007/s00530-003-0105-4
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Cho D, 2017, IEEE I CONF COMP VIS, P4568, DOI 10.1109/ICCV.2017.488
   Choi J, 2016, J SIGNAL PROCESS SYS, V85, P275, DOI 10.1007/s11265-015-1084-3
   Cui J, 2020, SIGNAL PROCESS, V166, DOI 10.1016/j.sigpro.2019.107242
   Farrell E, 2022, J LARYNGOL OTOL, V136, P632, DOI 10.1017/S0022215121004424
   Gal R., 2006, RENDERING TECHNIQUES, V2006, P2
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Guo DG, 2015, MULTIMEDIA SYST, V21, P603, DOI 10.1007/s00530-014-0425-6
   Guo YW, 2009, IEEE T MULTIMEDIA, V11, P856, DOI 10.1109/TMM.2009.2021781
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Gupta S, 2019, MULTIMED TOOLS APPL, V78, P34157, DOI 10.1007/s11042-019-08232-6
   Han DF, 2010, VISUAL COMPUT, V26, P749, DOI 10.1007/s00371-010-0480-8
   Hashemzadeh M, 2019, SIGNAL PROCESS, V155, P233, DOI 10.1016/j.sigpro.2018.09.037
   Irani BY, 2019, NONLINEAR DYNAM, V97, P2693, DOI 10.1007/s11071-019-05157-5
   Ito I, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0130-9
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jin Y, 2010, VISUAL COMPUT, V26, P769, DOI 10.1007/s00371-010-0472-8
   KANTZ H, 1994, PHYS LETT A, V185, P77, DOI 10.1016/0375-9601(94)90991-1
   Kantz H., 2004, NONLINEAR TIME SERIE
   Krähenbühl P, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1616452.1618472, 10.1145/1618452.1618472]
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Li X, 2009, IEEE INT CON MULTI, P558, DOI 10.1109/ICME.2009.5202557
   Li YN, 2020, J INF SECUR APPL, V51, DOI 10.1016/j.jisa.2020.102459
   Lin JX, 2019, IEEE INT CONF MULTI, P54, DOI 10.1109/ICMEW.2019.0-111
   Luo Y, 2011, IEEE T CIRC SYST VID, V21, P1822, DOI 10.1109/TCSVT.2011.2147230
   Nishiyama M., 2009, P 17 ACM INT C MULTI, P669
   Niu YZ, 2012, MULTIMED TOOLS APPL, V56, P485, DOI 10.1007/s11042-010-0613-0
   Pritch Y, 2009, IEEE I CONF COMP VIS, P151, DOI 10.1109/ICCV.2009.5459159
   ROSENSTEIN MT, 1993, PHYSICA D, V65, P117, DOI 10.1016/0167-2789(93)90009-P
   RUBINSTEIN M, 2010, ACM SIGGRAPH ASIA 20, P1
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Santella A., 2006, Conference on Human Factors in Computing Systems. CHI2006, P771
   Shafieyan F, 2017, SIGNAL PROCESS-IMAGE, V50, P34, DOI 10.1016/j.image.2016.10.006
   Shamir A, 2009, COMMUN ACM, V52, P77, DOI 10.1145/1435417.1435437
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Song E, 2019, IEEE ACCESS, V7, P284, DOI 10.1109/ACCESS.2018.2885347
   Suh Bongwon, 2003, P ACM S US INT SOFTW, P95, DOI DOI 10.1145/964696.964707
   Tan WM, 2020, IEEE T MULTIMEDIA, V22, P1730, DOI 10.1109/TMM.2019.2959925
   Tu C, 2021, SIG PROCESS IMAGE CO
   Valandar MY, 2022, J INF SECUR APPL, V66, DOI 10.1016/j.jisa.2022.103160
   Wang J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330512
   WOLF A, 1985, PHYSICA D, V16, P285, DOI 10.1016/0167-2789(85)90011-9
   Wu CM, 2021, DIGIT SIGNAL PROCESS, V110, DOI 10.1016/j.dsp.2020.102905
   Xie Junyuan, 2012, ADV NEURAL INFORM PR, P341, DOI [DOI 10.5555/2999134.2999173, DOI 10.1109/AGRO-GEOINFORMATICS.2012.6311605]
   Xu L, 2014, ADV NEUR IN, V27
   Xu N, 2017, PROC CVPR IEEE, P311, DOI 10.1109/CVPR.2017.41
   Ye JY, 2017, J INF SECUR APPL, V35, P13, DOI 10.1016/j.jisa.2017.04.003
   Yin T, 2015, COMPUT SECUR, V55, P130, DOI 10.1016/j.cose.2015.09.003
   Zhang DY, 2017, J INF SECUR APPL, V36, P135, DOI 10.1016/j.jisa.2017.09.003
   Zhang GX, 2009, COMPUT GRAPH FORUM, V28, P1897, DOI 10.1111/j.1467-8659.2009.01568.x
   Zhang LX, 2017, SOFT COMPUT, V21, P447, DOI 10.1007/s00500-015-1795-1
   Zhang MJ, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P438
   Zhang YB, 2016, INT CONF ACOUST SPEE, P1080, DOI 10.1109/ICASSP.2016.7471842
NR 69
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19417
EP 19440
DI 10.1007/s11042-022-13823-x
EA NOV 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000887890500001
DA 2024-07-18
ER

PT J
AU Zafar, A
   Alanazi, AS
   Khan, M
   Hussain, I
AF Zafar, Amna
   Alanazi, Ammar S.
   Khan, Majid
   Hussain, Iqtadar
TI New image confidentiality mechanism based on Arneodos chaotic dynamical
   system and quadratic congruential generator
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaotic map; Congruential generators; S-box; Arneodos
   chaotic map; Chaotic shuffling
ID ENCRYPTION; FRACTALS; MAP
AB A new encryption scheme is developed by employing congruential generators and Arneodos chaotic dynamical system. In the offered work we have applied a chaotic map for shuffling and a quadratic congruential generator for substitution. The objective of this work is to offer a robust image encryption technique that satisfies the security criteria. Moreover, the cryptanalysis of this scheme is difficult because we have performed a combination of chaotic shuffling and substitution boxes.
C1 [Zafar, Amna; Khan, Majid] Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
   [Alanazi, Ammar S.] King Abdulaziz City Sci & Technol, Riyadh, Saudi Arabia.
   [Hussain, Iqtadar] Qatar Univ, Coll Arts & Sci, Dept Math Stat & Phys, Math Program, Doha 2713, Qatar.
   [Hussain, Iqtadar] Qatar Univ, Coll Arts & Sci, Dept Math Stat & Phys, Stat Consulting Unit, Doha, Qatar.
C3 King Abdulaziz City for Science & Technology; Qatar University; Qatar
   University
RP Khan, M (corresponding author), Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
EM mk.cfd1@gmail.com
RI Khan, Majid/T-9408-2019
OI Khan, Majid/0000-0001-5454-3770
CR Alanazi AS, 2021, IEEE ACCESS, V9, P93795, DOI 10.1109/ACCESS.2021.3092512
   Apdilah D, 2018, J PHYS CONF SER, V1007, DOI 10.1088/1742-6596/1007/1/012006
   Arshad U, 2020, PHYSICA A, V546, DOI 10.1016/j.physa.2019.123458
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Hua ZY, 2022, IEEE T SYST MAN CY-S, V52, P4402, DOI 10.1109/TSMC.2021.3096967
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P807, DOI 10.1007/s11071-021-06308-3
   Khairina N, 2019, J PHYS C SERIES, V1361
   Khan M, 2020, NEURAL COMPUT APPL, V32, P11837, DOI 10.1007/s00521-019-04667-y
   Khan M, 2019, WIRELESS PERS COMMUN, V109, P849, DOI 10.1007/s11277-019-06594-6
   Li SJ, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P708
   Munir N, 2021, MATH COMPUT SIMULAT, V190, P826, DOI 10.1016/j.matcom.2021.06.008
   Norouzi B, 2015, MULTIMED TOOLS APPL, V74, P781, DOI 10.1007/s11042-013-1699-y
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Sahari ML, 2018, NONLINEAR DYNAM, V94, P723, DOI 10.1007/s11071-018-4390-z
   Scharinger J, 1998, J ELECTRON IMAGING, V7, P318, DOI 10.1117/1.482647
   Seyedzadeh SM, 2015, NONLINEAR DYNAM, V81, P511, DOI 10.1007/s11071-015-2008-2
   Stoyanov B, 2015, ENTROPY-SWITZ, V17, P2117, DOI 10.3390/e17042117
   Tchahou Tchendjeu RTHBFAE, 2018, FPGA IMPL LIN CONGR, V27
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Waseem HM, 2019, APPL PHYS B-LASERS O, V125, DOI 10.1007/s00340-019-7142-y
   Waseem HM, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.6.063022
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
NR 22
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17263
EP 17281
DI 10.1007/s11042-022-14215-x
EA NOV 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000884893600004
DA 2024-07-18
ER

PT J
AU Vittorini, P
   Galassi, A
AF Vittorini, Pierpaolo
   Galassi, Alessandra
TI rDSA : an intelligent tool for data science assignments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive learning environments; Automated feedback generation;
   Computer-assisted instruction; Automated assessment systems; Intelligent
   tutoring systems; Technology-enhanced learning
ID FEEDBACK
AB Tools supporting the teaching and learning of programming may help professors in correcting assignments and students in receiving immediate feedback, thus improving the solution before the final submission. This paper describes the rDSA tool, which was designed, developed, and evaluated to support students in completing assignments concerning (i) the execution of statistical analyses in the R language and (ii) commenting on the results in natural language. The paper focuses on the feedback provided by the tool to students and how it was designed/evaluated/improved over the years. The paper also presents the results of two studies that indicate the advantages of using the tool in terms of engagement and learning outcomes. To conclude, we provide a discussion on the characteristics of the tool, its use in similar courses, and the scope for future work.
C1 [Vittorini, Pierpaolo; Galassi, Alessandra] Univ Aquila, Dept Life Hlth & Environm Sci, Ple S Tommasi 1, I-67100 Laquila, Italy.
C3 University of L'Aquila
RP Vittorini, P (corresponding author), Univ Aquila, Dept Life Hlth & Environm Sci, Ple S Tommasi 1, I-67100 Laquila, Italy.
EM pierpaolo.vittorini@univaq.it; alexandra2g2016@gmail.com
RI VITTORINI, Pierpaolo/HJP-5306-2023
OI VITTORINI, Pierpaolo/0000-0002-6975-8958
FU Universita degli Studi dell'Aquila within the CRUI-CARE Agreement
FX Open access funding provided by Universita degli Studi dell'Aquila
   within the CRUI-CARE Agreement.
CR Albert W., 2003, P USABILITY PROFESSI
   Angelone AM, 2019, P 9 INT C METH INT S
   Angelone AM, 2021, METHODOLOGIES INTELL, P12
   Angelone AM, 2019, COMM COM INF SC, V1011, P439, DOI 10.1007/978-3-030-20798-4_38
   Bartholomew D, 2015, GETTING STARTED MARI
   Bell P., 2004, Internet environments of science education, P73
   Bernardi A, 2019, ADV INTELL SYST, V804, P190, DOI 10.1007/978-3-319-98872-6_23
   Boud David, 2012, FEEDBACK HIGHER PROF
   Burrows S, 2015, INT J ARTIF INTELL E, V25, P60, DOI 10.1007/s40593-014-0026-8
   Core R, 2018, US
   Croft D, 2020, PROCEEDINGS OF THE 4TH CONFERENCE ON COMPUTING EDUCATION PRACTICE, CEP 2020, DOI 10.1145/3372356.3372357
   De Gasperis G, 2019, LNCS
   DeVellis RF, 2006, MED CARE, V44, pS50, DOI 10.1097/01.mlr.0000245426.10853.30
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Douce Christopher, 2005, Journal on Educational Resources in Computing (JERIC), V5, DOI [10.1145/1163405.1163409, DOI 10.1145/1163405.1163409]
   Erhel S, 2013, COMPUT EDUC, V67, P156, DOI 10.1016/j.compedu.2013.02.019
   Galassi A, 2021, PROCEEDINGS OF THE 14TH BIANNUAL CONFERENCE OF THE ITALIAN SIGCHI CHAPTER (CHIITALY 2021), DOI 10.1145/3464385.3464387
   Gerdes A., 2012, Proceedings of the 17th ACM annual conference on Innovation and technology in computer science education, P250, DOI DOI 10.1145/2325296.2325356
   Gil, 2021, ADV INTELLIGENT SYST, V1236, P296, DOI DOI 10.1007/978-3-030-52287-2_31
   Harlen W., 1997, ASSESS EDUC, V4, P365, DOI DOI 10.1080/0969594970040304
   Hattie J, 2007, REV EDUC RES, V77, P81, DOI 10.3102/003465430298487
   HOLLINGSWORTH J, 1960, COMMUN ACM, V3, P528, DOI 10.1145/367415.367422
   Keith M., 2018, JAVA EE 8 IN DEPTH G, V3rd, P101
   Kelleher C, 2005, ACM COMPUT SURV, V37, P83, DOI 10.1145/1089733.1089734
   Keuning H, 2019, ACM T COMPUT EDUC, V19, DOI 10.1145/3231711
   Knutas A, 2019, P 19 KOLI CALLING IN
   LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845
   Liu TQ, 2019, LECT NOTES ARTIF INT, V11626, P169, DOI 10.1007/978-3-030-23207-8_32
   Magooda A. E., 2016, 29 INT FLAIRS C
   Malmi L, 2004, IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P186, DOI 10.1109/ICALT.2004.1357400
   Mohler M., 2011, P 49 ANN M ASS COMPU, P752
   Nkambou R., 2010, Advances in Intelligent Tutoring Sytems
   Odekirk-Hash E, 2001, SIGCSE BULL, V33, P55, DOI 10.1145/366413.364537
   Poulos A, 2008, ASSESS EVAL HIGH EDU, V33, P143, DOI 10.1080/02602930601127869
   Riffenburgh RH., 2012, Statistics in medicine
   Rivers K., 2013, 1 WORKSH AI SUPP ED, P50
   Scholtz B, 2018, DEFINITIVE GUIDE JSF
   Souza DM, 2016, CONF SOFTW ENG EDUC, P147, DOI 10.1109/CSEET.2016.48
   Sultan Md Arafat, 2016, P 2016 C N AM CHAPTE, P1070
   Sung C, 2019, LECT NOTES ARTIF INT, V11625, P469, DOI 10.1007/978-3-030-23204-7_39
   Sykes E. R., 2004, Learning, V1, DOI [10.2316/Journal.208.2004.1.202-1454, DOI 10.2316/JOURNAL.208.2004.1.202-1454]
   Thanaki J., 2017, Python natural language processing
   Urquiza-Fuentes J, 2013, COMPUT EDUC, V67, P178, DOI 10.1016/j.compedu.2013.02.013
   VanLehn K, 2011, EDUC PSYCHOL-US, V46, P197, DOI 10.1080/00461520.2011.611369
   Vittorini P, 2021, INT J ARTIF INTELL E, V31, P159, DOI 10.1007/s40593-020-00230-2
   Wainer H., 2000, Computerized adaptive testing: A primer, DOI DOI 10.1002/9780470479216.CORPSY0213
NR 46
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 12879
EP 12905
DI 10.1007/s11042-022-14053-x
EA NOV 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000878962500003
PM 36373073
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Khanbebin, SN
   Mehrdad, V
AF Khanbebin, Saeed Najafi
   Mehrdad, Vahid
TI Improved convolutional neural network-based approach using hand-crafted
   features for facial expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; VGG; DAISY descriptor; Random Forest
   classifier
ID DEEP; FUSION
AB Facial expression recognition is still one of the most attractive and challenging problems. This study designed a facial expression recognition approach based on the feature fusion strategy. In this proposed approach, two types of features are used to classify the facial expressions. The first type is deep learned features obtained from the CNN layers, and the other is hand-crafted features in which a geometric approach called DAISY is used to have a more discriminative model. The DAISY descriptor is used to extract the features because of its efficiency and performance in many problems like object detection, image classification, etc. Besides, the Convolutional Neural Network (CNN) layers are used in both standard and custom structures. A robust and highly distinguishing feature vector is conducted when these two types of features are concatenated. This feature vector helps CNN s work in an enhanced manner. The extra information provided by DAISY made it easy for the resulting model to make decisions because this feature descriptor does not require much data to work precisely. Finally, we used the Random Forest classifier for the classification task to make the proposed pipeline complete. To validate the efficiency of the proposed approach, two well-known facial expression datasets, CK+ and FER2013 are used. The proposed feature fusion-based method's accuracy is 98.48% in the CK+ dataset and 70% in FER2013. The results are compared with some newly proposed approaches in this field to validate our strategy. Since this performance is in the range of state-of-the-art systems, the proposed strategy that enhances the CNN features by hand-crafted techniques can be presented as a suitable FER method.
C1 [Khanbebin, Saeed Najafi; Mehrdad, Vahid] Lorestan Univ, Fac Engn, Dept Elect & Elect Engn, Khorramabad, Iran.
C3 Lorestan University
RP Mehrdad, V (corresponding author), Lorestan Univ, Fac Engn, Dept Elect & Elect Engn, Khorramabad, Iran.
EM najafi.sa@fe.lu.ac.ir; Mehrdad.v@lu.ac.ir
OI Najafi Khanbebin, Saeed/0000-0002-2937-6330
CR Agrawal A, 2020, VISUAL COMPUT, V36, P405, DOI 10.1007/s00371-019-01630-9
   [Anonymous], 2011, 2011 IEEE INT C MULT
   [Anonymous], 2005, Int. J. Inf. Technol.
   Barman A, 2019, APPL SOFT COMPUT, V77, P88, DOI 10.1016/j.asoc.2019.01.011
   Benitez-Quiroz F, 2019, IEEE T PATTERN ANAL, V41, P2835, DOI 10.1109/TPAMI.2018.2868952
   Boughrara H, 2016, MULTIMED TOOLS APPL, V75, P709, DOI 10.1007/s11042-014-2322-6
   Bridge J, 2020, COMMUN COMPUT PHYS
   Cao XC, 2014, MACH VISION APPL, V25, P159, DOI 10.1007/s00138-013-0545-6
   Chakraborty N, 2021, MULTIMED TOOLS APPL, V80, P323, DOI 10.1007/s11042-020-09728-2
   Chatterjee A, 2018, PROC INT CONF EMERG
   Chen JK, 2018, IEEE T AFFECT COMPUT, V9, P38, DOI 10.1109/TAFFC.2016.2593719
   Dash M., 1997, Intelligent Data Analysis, V1
   Fei ZX, 2020, NEUROCOMPUTING, V388, P212, DOI 10.1016/j.neucom.2020.01.034
   García M, 2020, IEEE LAT AM T, V18, P1311, DOI 10.1109/TLA.2020.9099774
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Guo JM, 2013, EXPERT SYST APPL, V40, P707, DOI 10.1016/j.eswa.2012.08.002
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   He Y, 2020, IEEE ACCESS, V8, P190184, DOI 10.1109/ACCESS.2020.3032406
   Hosseini S.A., 2018, ARXIV
   Hosseini S, 2019, IEEE INT CONF AUTOMA, P161
   Hua WT, 2019, IEEE ACCESS, V7, P24321, DOI 10.1109/ACCESS.2019.2900231
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Liu C, 2021, IEEE ACCESS, V9, P18876, DOI 10.1109/ACCESS.2021.3054332
   Liu J, 2019, MULTIMED TOOLS APPL, V78, P18735, DOI 10.1007/s11042-018-7095-x
   Liu MY, 2015, NEUROCOMPUTING, V159, P126, DOI 10.1016/j.neucom.2015.02.011
   Liu P, 2022, IEEE T CYBERNETICS, V52, P12649, DOI 10.1109/TCYB.2021.3085744
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Malakar S, 2020, MULTIMED TOOLS APPL, V79, P32011, DOI 10.1007/s11042-020-09638-3
   Meena HK, 2020, SIGNAL IMAGE VIDEO P, V14, P241, DOI 10.1007/s11760-019-01547-9
   Khanbebin SN, 2020, IET IMAGE PROCESS, V14, P3742, DOI 10.1049/iet-ipr.2020.0394
   Khanbebin SN, 2021, NEURAL COMPUT APPL, V33, P7691, DOI 10.1007/s00521-020-05512-3
   Noshad Z, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071568
   Ortac G, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115280
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pons G, 2018, IEEE T AFFECT COMPUT, V9, P343, DOI 10.1109/TAFFC.2017.2753235
   Reddy GV, 2020, COGN SYST RES, V62, P23, DOI 10.1016/j.cogsys.2020.03.002
   Reddy K. Srinivasa, 2015, International Journal of Image, Graphics and Signal Processing, V7, P37, DOI 10.5815/ijigsp.2015.10.05
   Ruan DL, 2021, PROC CVPR IEEE, P7656, DOI 10.1109/CVPR46437.2021.00757
   Sheykhmousa M, 2020, IEEE J-STARS, V13, P6308, DOI 10.1109/JSTARS.2020.3026724
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su R, 2020, NEUROCOMPUTING, V385, P300, DOI 10.1016/j.neucom.2019.12.083
   Sun N, 2019, PATTERN RECOGN LETT, V119, P49, DOI 10.1016/j.patrec.2017.10.022
   Sun X, 2019, COGN COMPUT, V11, P587, DOI 10.1007/s12559-019-09654-y
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Vicnesh J, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1285-6
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang B, 2018, IEEE T INTELL TRANSP, V19, P1547, DOI 10.1109/TITS.2017.2723523
   Wang FY, 2019, J VIS COMMUN IMAGE R, V59, P84, DOI 10.1016/j.jvcir.2018.11.010
   Wang ZN, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107694
   Zhang HF, 2020, IEEE ACCESS, V8, P37976, DOI 10.1109/ACCESS.2020.2975913
   Zhu XL, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041350
NR 52
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11489
EP 11505
DI 10.1007/s11042-022-14122-1
EA NOV 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000877999600001
DA 2024-07-18
ER

PT J
AU Catala, A
   Gijlers, H
   Visser, I
AF Catala, Alejandro
   Gijlers, Hannie
   Visser, Iris
TI Guidance in storytelling tables supports emotional development in
   kindergartners
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Technology enhanced storytelling; Emotional development; Guidance;
   Instruction method; Kindergartners; Robot
ID SOCIAL COMPETENCE; CHILDREN
AB Promoting the social-emotional development of kindergartners is of special relevance as will lay the foundations for emotion regulation in later childhood and adulthood stages. Considering that tangible storytelling tables are already used for language and literacy skills in kindergarten, we addressed the problem of designing a storytelling intervention aimed at social-emotional development suitable in such a context by using an emotional laden story as content and embedding a guidance method that can be implemented with either a human or robot guide to enhance the learning setting. The study considered two guided storytelling activities (one traditional guided by the teacher, and one in which guidance was provided by a robot) and a control condition without additional guidance. The three conditions were compared in terms of kindergartners' enactment process, an emotion recognition test and a story recall test. The results show that the guidance method properly supported emotion naming, children involvement and goal completion during the storytelling activity whereas the intervention supported the learning gain on emotion recognition. The study revealed that both robot and human guidance did not differ significantly in the performance tests but did outperform the control. In view of the results, this research is helpful for researchers and teachers to create in an informed way a range of environments in the kindergarten class based on storytelling tables, either with or without guidance, and with or without robot support. Future work may further investigate how specific interaction issues concerning robot embodiment (e.g., voice and behavioral cues to direct children's attention) might enhance or not the children's performance.
C1 [Catala, Alejandro] Univ Santiago Compostela, Ctr Singular Invest Tecnoloxias Intelixentes CiTI, Dept Elect & Comp, Santiago De Compostela, Spain.
   [Gijlers, Hannie] Univ Twente, Fac Behav Management & Social Sci BMS, Dept Instruct Technol, Enschede, Netherlands.
   [Visser, Iris] Univ Twente, Enschede, Netherlands.
C3 Universidade de Santiago de Compostela; University of Twente; University
   of Twente
RP Catala, A (corresponding author), Univ Santiago Compostela, Ctr Singular Invest Tecnoloxias Intelixentes CiTI, Dept Elect & Comp, Santiago De Compostela, Spain.
EM alejandro.catala@use.ac; a.h.gijlers@utwente.nl; i.e.visser@outlook.com
OI Catala, Alejandro/0000-0002-3677-672X
FU CRUE-CSIC; Springer Nature; Spanish Ministry of Science, Innovation and
   Universities [IJC2018-037522-I]; Conselleria de Educacion, Universidade
   e Formacion Profesional [2019-2022 ED431G-2019/04, ED431C2022/19];
   European Regional Development Fund (ERDF)
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This work has partially been funded by the Spanish
   Ministry of Science, Innovation and Universities under Juan de la Cierva
   programme (IJC2018-037522-I). The writing of this work has received
   financial support from the Conselleria de Educacion, Universidade e
   Formacion Profesional (accreditation 2019-2022 ED431G-2019/04, reference
   ED431C2022/19) and the European Regional Development Fund (ERDF).
CR [Anonymous], 2009, WERKEN KWALITEIT VAN
   Aram D, 2008, EARLY EDUC DEV, V19, P1, DOI 10.1080/10409280701838421
   Azevedo J, 2018, LECT NOTES COMPUT SC, V11243, P282, DOI 10.1007/978-3-030-02762-9_30
   Bai Z, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1035, DOI 10.1145/2702123.2702250
   Bateman A, 2020, TEXT TALK, V40, P643, DOI 10.1515/text-2020-2077
   Berenst J., 2007, TOEGEPASTE TAALWETEN, V78, P85, DOI [10.1075/ttwia.78.08ber, DOI 10.1075/TTWIA.78.08BER]
   Blair C, 2008, DEV PSYCHOPATHOL, V20, P899, DOI 10.1017/S0954579408000436
   BRATITSIS Tharrenos, 2016, 7 INT C SOFTW DEV TE, P301, DOI [10.1145/3019943.3019987, DOI 10.1145/3019943.3019987]
   Brunetti, 2021, CEUR WORKSHOP P 2817
   Catala, 2018, IROS 2018 2 WORKSHOP
   Catala A, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON CREATIVITY AND COGNITION (C&C 2017), P237
   Daniela C, 2017, ACMIEEE INT CONF HUM, P97, DOI 10.1145/3029798.3038359
   Denham SA, 2010, EARLY EDUC DEV, V21, P652, DOI 10.1080/10409289.2010.497450
   Durlak JA, 2011, CHILD DEV, V82, P405, DOI 10.1111/j.1467-8624.2010.01564.x
   Ebbeck M, 2020, J EARLY CHILD TEACH, V41, P223, DOI 10.1080/10901027.2019.1617808
   Farkas C, 2020, INFANT BEHAV DEV, V59, DOI 10.1016/j.infbeh.2020.101443
   Field A., 2013, DISCOVERING STAT USI
   Fridin M, 2014, COMPUT EDUC, V70, P53, DOI 10.1016/j.compedu.2013.07.043
   Heckman JJ, 2012, LABOUR ECON, V19, P451, DOI 10.1016/j.labeco.2012.05.014
   Hoffman G, 2008, 2008 17TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1 AND 2, P354, DOI 10.1109/ROMAN.2008.4600691
   Jones DE, 2015, AM J PUBLIC HEALTH, V105, P2283, DOI 10.2105/AJPH.2015.302630
   Kelleher C, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1455
   Kim Y, 2006, ETR&D-EDUC TECH RES, V54, P569, DOI 10.1007/s11423-006-0637-3
   Kocaman-Karoglu A, 2015, EDUC MEDIA INT, V52, P340, DOI 10.1080/09523987.2015.1100391
   Kory-Westlund JM, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00054
   Kuo I. H., 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P214, DOI 10.1109/ROMAN.2009.5326292
   Kurki K, 2017, EARLY CHILD RES Q, V41, P50, DOI 10.1016/j.ecresq.2017.06.002
   Kwant, 2011, PROEFSCHRIFT
   Kwant, 2007, TAAL LEZEN PRIMAIR, V22, P1
   Leite I, 2015, ACMIEEE INT CONF HUM, P75, DOI 10.1145/2696454.2696481
   Ligthart MEU, 2020, ACMIEEE INT CONF HUM, P409, DOI 10.1145/3319502.3374826
   Marshall P., 2002, SIGGROUP Bulletin, V23, P14
   Martins J., 2014, A Plataforma Continental Algarvia como arquivo de Paleoambientes e Paleoclimas Holocenicos. O papel do 14C no seu estudo, P1
   McCabe PC, 2006, TOP EARLY CHILD SPEC, V26, P234, DOI 10.1177/02711214060260040401
   Muravevskaia E, 2017, EXTENDED ABSTRACTS PUBLICATION OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY'17 EXTENDED ABSTRACTS), P715, DOI 10.1145/3130859.3133229
   Nijmeijer H., 2014, P 2014 C INT DES CHI, P261
   Nikolajeva M, 2013, READ TEACH, V67, P249, DOI 10.1002/trtr.1229
   Palaigeorgiou G, 2021, ADV INTELL SYST COMP, V1192, P457, DOI 10.1007/978-3-030-49932-7_44
   Paley VG., 2004, CHILDS WORK IMPORTAN, DOI [10.7208/chicago/9780226644981.001.0001, DOI 10.7208/CHICAGO/9780226644981.001.0001]
   Pont, 2013, JACOBUS
   Ratri, 2017, P 11 INT C UB INF MA, P1
   Raver C.C., 2002, SOCIAL POLICY REPORT, V16, P3, DOI [https://doi.org/10.1002/j.2379-3988.2002.tb00041.x, 10.1002/j.2379-3988.2002.tb00041.x, DOI 10.1002/J.2379-3988.2002.TB00041.X]
   Ryokai K, 2012, PROCEEDINGS OF IDC 2012: THE 11TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN, P125
   Ryu SJ, 2021, IDC '21: PROCEEDINGS OF INTERACTION DESIGN AND CHILDREN 2021, P568, DOI 10.1145/3459990.3465198
   Schoenau-Fog Henrik, 2011, Interactive Storytelling. Proceedings 4th International Conference on Interactive Digital Storytelling, ICIDS 2011, P219, DOI 10.1007/978-3-642-25289-1_24
   Schultz D., 1998, Assessment of Children's Emotion Skills (ACES)
   Silva V, 2020, ADV INTELL SYST, V1026, P293, DOI 10.1007/978-3-030-27928-8_44
   Stal Silke ter, 2020, Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering), P601, DOI [10.1007/978-3-030-53294-9_44, DOI 10.1007/978-3-030-53294-9_44]
   Steinfeld A, 2009, P 4 ACM IEEE INT C H, P101, DOI [DOI 10.1145/1514095.1514115, 10.1145/1514095.1514115]
   Stern SE, 2008, J LANG SOC PSYCHOL, V27, P254, DOI 10.1177/0261927X08318035
   Sun M, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P205, DOI 10.1145/3078072.3079714
   Sylla C, 2022, LITERACY, V56, P3, DOI 10.1111/lit.12263
   Sylla C, 2019, PROCEEDINGS OF THE 2019 ON CREATIVITY AND COGNITION - C&C 19, P396, DOI 10.1145/3325480.3325501
   Tielman M, 2014, ACMIEEE INT CONF HUM, P407, DOI 10.1145/2559636.2559663
   Torres PE., 2021, International Journal of Child-Computer Interaction, V30, P100323, DOI DOI 10.1016/J.IJCCI.2021.100323
   van der Bolt, 2000, ACAS PROEFSCHRIFT
   Verhoeven Gijs, 2019, Interactivity, Game Creation, Design, Learning, and Innovation. 7th EAI International Conference, ArtsIT 2018, and 3rd EAI International Conference, DLI 2018, ICTCC 2018. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 265), P385, DOI 10.1007/978-3-030-06134-0_42
   VYGOTSKY LS, 1967, SOV PSYCHOL-USSR, V5, P6, DOI 10.2753/RPO1061-040505036
   Wallbaum T, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P10, DOI 10.1145/3126686.3126702
   Westlund JMK, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00295
   Westlund JK., 2015, Proceedings of the tenth annual ACM/IEEE international conference on human-robot interaction extended abstracts, P65, DOI DOI 10.1145/2701973.2701989
   Zancanaro M, 2020, BEHAV INFORM TECHNOL, V39, P1022, DOI 10.1080/0144929X.2019.1637940
NR 62
TC 3
Z9 3
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 12907
EP 12937
DI 10.1007/s11042-022-14049-7
EA OCT 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000876660900002
OA hybrid
DA 2024-07-18
ER

PT J
AU Lebal, A
   Moussaoui, A
   Rezgui, A
AF Lebal, Abdelhamid
   Moussaoui, Abdelouahab
   Rezgui, Abdelmounaam
TI Epilepsy-Net: attention-based 1D-inception network model for epilepsy
   detection using one-channel and multi-channel EEG signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional block attention module; Epileptic seizures; EEG signal;
   Gated recurrent unit; Residual network
ID SEIZURE DETECTION; RECOMMENDATION SYSTEM; FEATURE-EXTRACTION;
   CLASSIFICATION; RECOGNITION; FILTERS; DOMAIN
AB In this paper, we propose and evaluate Epilepsy-Net, a collection of deep learning EEG signal processing tools to detect epileptic seizures against non-epileptic seizures without any handcrafted features extraction. In the Epilepsy-Net model, the 1D-convolutional neural networks (CNN), the recurrent neural network (RNN) and the attention mechanism are combined, where each algorithm is represented by the ResNet and Inception, the gated recurrent unit and the convolutional block attention module respectively; without any handcrafted features. To the best of our knowledge, Epilepsy-Net is the first EEG signal processing work to detect epileptic seizures by combining the attention mechanism with the Inception deep network algorithm.We validate our Epilepsy-Net through several large public EEG signal datasets. The results of our experiments show that the proposed attention deep learning approach is an effective tool for epilepsy detection using EEG signals with high accuracy of 100%, 99.05% and 98.22% for the Bonn EEG dataset, variant of the Bonn EEG dataset, and CHB-MIT dataset, respectively.
C1 [Lebal, Abdelhamid] Amar Telidji Univ, Math & Comp Sci Dept, Laghoaut 03000, Algeria.
   [Lebal, Abdelhamid; Rezgui, Abdelmounaam] Illinois State Univ, Sch Informat Technol, Campus Box 5150, Normal, IL 61761 USA.
   [Moussaoui, Abdelouahab] Ferhat Abbes Univ, Comp Sci Dept, Setif 19000, Algeria.
C3 Universite Amar Telidji de Laghouat; Illinois State University;
   Universite Ferhat Abbas Setif
RP Lebal, A (corresponding author), Amar Telidji Univ, Math & Comp Sci Dept, Laghoaut 03000, Algeria.; Lebal, A (corresponding author), Illinois State Univ, Sch Informat Technol, Campus Box 5150, Normal, IL 61761 USA.
EM lebalabdelhamid@gmail.com; moussaoui.abdel@gmail.com; arezgui@ilstu.edu
RI Moussaoui, Abdelouahab/AGP-6115-2022; LEBAL, Abdelhamid/GZG-8260-2022
OI Abdelhamid, LEBAL/0000-0003-0624-9213
CR Acharya UR, 2018, COMPUT BIOL MED, V100, P270, DOI 10.1016/j.compbiomed.2017.09.017
   Acharya UR, 2013, INT J NEURAL SYST, V23, DOI 10.1142/S0129065713500093
   Acharya UR, 2012, INT J NEURAL SYST, V22, DOI 10.1142/S0129065712500116
   Acharya UR, 2011, INT J NEURAL SYST, V21, P199, DOI 10.1142/S0129065711002808
   Ahmadlou M, 2010, J CLIN NEUROPHYSIOL, V27, P328, DOI 10.1097/WNP.0b013e3181f40dc8
   Ahmedt-Aristizabal D, 2018, IEEE ENG MED BIO, P332, DOI 10.1109/EMBC.2018.8512249
   Al-Qazzaz NK, 2018, MED BIOL ENG COMPUT, V56, P137, DOI 10.1007/s11517-017-1734-7
   Andrzejak RG, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.061907
   Asif U, 2020, LECT NOTES COMPUT SC, V12449, P77, DOI 10.1007/978-3-030-66843-3_8
   Attia A, 2021, EVOL SYST-GER, V12, P827, DOI 10.1007/s12530-019-09319-z
   Avcu MT, 2019, INT CONF ACOUST SPEE, P1120, DOI [10.1109/icassp.2019.8683229, 10.1109/ICASSP.2019.8683229]
   Bairagi Vinayak, 2018, International Journal of Information Technology, V10, P403, DOI 10.1007/s41870-018-0165-5
   Begley CE, 2015, EPILEPSIA, V56, P1376, DOI 10.1111/epi.13084
   Behara DST, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P2539
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Bin Heyat MB, 2019, IEEE ACCESS, V7, P102542, DOI 10.1109/ACCESS.2019.2928020
   Bizopoulos P, 2019, IEEE ENG MED BIO, P702, DOI [10.1109/EMBC.2019.8856620, 10.1109/embc.2019.8856620]
   Chatzichristos C, 2020, IEEE SIG PROC MED, DOI 10.1109/SPMB50085.2020.9353630
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Chorowski J. K., 2015, ARXIV
   Chua K. C., 2009, Journal of Medical Engineering & Technology, V33, P42, DOI 10.1080/03091900701559408
   Dash DP, 2020, J BIOMED RES, V34, P170, DOI 10.7555/JBR.34.20190006
   de Cheveigné A, 2019, NEURON, V102, P280, DOI 10.1016/j.neuron.2019.02.039
   Elsayed N., 2017, International Journal of Computer Applications, V169, P12, DOI DOI 10.5120/IJCA2017914621
   Fu K, 2015, BIOMED SIGNAL PROCES, V18, P179, DOI 10.1016/j.bspc.2015.01.002
   Golmohammadi M, 2017, ROUTL STUD NEW MEDIA
   Golmohammadi M, 2017, ARXIV
   Gupta S, 2020, IEEE I C ELECT CIRC, DOI 10.1109/icecs49266.2020.9294790
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hu DC, 2020, ADV INTELL SYST COMP, V1038, P432, DOI 10.1007/978-3-030-29513-4_31
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Hussein R, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2546, DOI 10.1109/ICASSP.2018.8462029
   Hussein R, 2018, EXPERT SYST APPL, V104, P153, DOI 10.1016/j.eswa.2018.03.022
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Islam MR, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104757
   Islam MR, 2021, IEEE ACCESS, V9, P94601, DOI 10.1109/ACCESS.2021.3091487
   Jaafar S.T., 2019, UHD J Sci Technol, V3, P41, DOI DOI 10.21928/UHDJST.V3N2Y2019.PP41-50
   Kane N, 2017, CLIN NEUROPHYS PRACT, V2, P170, DOI 10.1016/j.cnp.2017.07.002
   Khorshidtalab A, 2013, PHYSIOL MEAS, V34, P1563, DOI 10.1088/0967-3334/34/11/1563
   Kumar Y, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03612-z
   Lee DY, 2020, I WINT C BRAIN-COMP, P227, DOI 10.1109/bci48061.2020.9061671
   Ma M., 2021, IEEE ACCESS
   Mardi Zahra, 2011, J Med Signals Sens, V1, P130
   2012, EPILEPSY SPECTRUM PR
   Obeid I, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00196
   Oh SL, 2020, NEURAL COMPUT APPL, V32, P10927, DOI 10.1007/s00521-018-3689-5
   Park C., 2018, P INT C EL INF COMM, P1, DOI DOI 10.23919/ELINFOCOM.2018.8330671
   Park J., 2018, ARXIV
   Patel A, 2020, J PEDIATR EPILEPSY, V09, P143, DOI 10.1055/s-0040-1716913
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saa J. F. D., 2010, Eighth Latin American and Caribbean Conference for Engineering and Technology, P1
   Samiee K, 2015, IEEE T BIO-MED ENG, V62, P541, DOI 10.1109/TBME.2014.2360101
   Serna JAD, 2020, IEEE SENS J, V20, P6542, DOI 10.1109/JSEN.2020.2976519
   Shalbaf A, 2020, PHYS ENG SCI MED, V43, P1229, DOI 10.1007/s13246-020-00925-9
   Sharanreddy M., 2013, Int J Biol Med Res, V4, P2855
   Sharmila A, 2016, IEEE ACCESS, V4, P7716, DOI 10.1109/ACCESS.2016.2585661
   Shi QW, 2011, J EXP THEOR ARTIF IN, V23, P97, DOI 10.1080/0952813X.2010.506289
   Shoeb A, 2004, EPILEPSY BEHAV, V5, P483, DOI 10.1016/j.yebeh.2004.05.005
   Shoeb A.H., 2009, Application of Machine Learning to Epileptic Seizure Onset Detection and Treatment, DOI DOI 10.1016/J.BSPC.2020.101856
   Singh K, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P249, DOI 10.1109/ICSCCC.2018.8703357
   Singh V, 2016, INT J BIOMED ENG TEC, V22, P250, DOI 10.1504/IJBET.2016.079488
   Siuly S, 2016, HEALTH INFOR SCI, P3, DOI 10.1007/978-3-319-47653-7_1
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   TAHERISADR M, 2019, 2019 IEEE 29 INT WOR, P1
   Taqi Arwa M., 2017, 2017 International Conference on Current Research in Computer Science and Information Technology (ICCIT), P86, DOI 10.1109/CRCSIT.2017.7965539
   Vaswani A, 2017, ADV NEUR IN, V30
   Vidyaratne L, 2016, IEEE IJCNN, P1202, DOI 10.1109/IJCNN.2016.7727334
   Vijayarangan S, 2020, IEEE ENG MED BIO, P345, DOI 10.1109/EMBC44109.2020.9176084
   Vimala V, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1146-8
   Wang F., 2016, ARXIV
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu GW, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.578126
   Yao X., 2019, ARXIV
   Zhang T, 2017, BIOMED SIGNAL PROCES, V31, P550, DOI 10.1016/j.bspc.2016.10.001
   Zhao W, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/9689821
NR 77
TC 10
Z9 10
U1 19
U2 60
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17391
EP 17413
DI 10.1007/s11042-022-13947-0
EA OCT 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000871515900001
DA 2024-07-18
ER

PT J
AU Sekkate, S
   Khalil, M
   Adib, A
AF Sekkate, Sara
   Khalil, Mohammed
   Adib, Abdellah
TI A statistical feature extraction for deep speech emotion recognition in
   a bilingual scenario
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech emotion recognition; Deep learning; Convolutional neural network;
   Statistical-based modeling; MFCC; Speech signal processing
ID NEURAL-NETWORKS; MODEL; SPECTROGRAM
AB Previously and currently, most of literature works on Speech Emotion Recognition (SER) have been orientated towards a monolingual approach. The current study extends monolingual SER to a bilingual setting. However, in order to construct a generalized emotion recognition system for different languages, selecting a proper feature extraction and classification methods remains a topic of discussion. To address this issue, a promising method is proposed and evaluated. On the one hand, the proposed method is based on a statistical-based parameterization framework for representing the speech through a fixed-length vector. On the other hand, we propose a deep learning approach that combines three convolutional neural networks architectures. Based on these, monolingual and bilingual emotion recognition experiments have been conducted using the English RAVDESS and Italian EMOVO corpora. The effectiveness of the suggested SER model is proved from the experimentations when compared to state-of-the-art monolingual methods, with an average achieve of 87.08% and 83.90% in terms of accuracy over RAVDESS and EMOVO datasets, respectively.
C1 [Sekkate, Sara] Hassan II Univ Casablanca, Higher Natl Sch Arts & Crafts Casablanca, Casablanca, Morocco.
   [Khalil, Mohammed; Adib, Abdellah] Hassan II Univ Casablanca, Fac Sci & Technol Mohammedia, Mohammadia, Morocco.
C3 Hassan II University of Casablanca; Hassan II University of Casablanca
RP Sekkate, S (corresponding author), Hassan II Univ Casablanca, Higher Natl Sch Arts & Crafts Casablanca, Casablanca, Morocco.
EM sarasekkate@gmail.com; medkhalil87@gmail.com; abdellah.adib@fstm.ac.ma
RI ADIB, Abdellah/HTQ-2801-2023; sekkate, Sara/JHS-5051-2023
OI ADIB, Abdellah/0000-0002-0670-7221; 
FU Ministry of Higher Education, Scientific Research and Innovation;
   Digital Development Agency (ADA); CNRST of Morocco
   [Alkhawarizmi/2020/01]
FX The research presented in this paper was supported by the Ministry of
   Higher Education, Scientific Research and Innovation, the Digital
   Development Agency (ADA) and the CNRST of Morocco
   (Alkhawarizmi/2020/01).
CR Aggarwal C.C., 2018, NEURAL NETWORKS DEEP, DOI DOI 10.1007/978-3-319-94463-0
   Ancilin J, 2021, APPL ACOUST, V179, DOI 10.1016/j.apacoust.2021.108046
   [Anonymous], 2010, P SPEECH PROS
   [Anonymous], 2006, Speech Prosody
   Badshah AM, 2017, 2017 INTERNATIONAL CONFERENCE ON PLATFORM TECHNOLOGY AND SERVICE (PLATCON), P125
   Bensalah N, 2020, SOCPAR, P156
   Bhavan A, 2019, KNOWL-BASED SYST, V184, DOI 10.1016/j.knosys.2019.104886
   Braga D, 2019, ENG APPL ARTIF INTEL, V77, P148, DOI 10.1016/j.engappai.2018.09.018
   Chen MY, 2018, IEEE SIGNAL PROC LET, V25, P1440, DOI 10.1109/LSP.2018.2860246
   Christy A, 2020, INT J SPEECH TECHNOL, V23, P381, DOI 10.1007/s10772-020-09713-y
   Costantini G, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3501
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   EKMAN P, 1992, PSYCHOL REV, V99, P550, DOI 10.1037/0033-295X.99.3.550
   El Bouny L, 2020, NEUROCOMPUTING, V417, P187, DOI 10.1016/j.neucom.2020.07.056
   El Bouny L, 2020, INT CONF ACOUST SPEE, P3212, DOI [10.1109/ICASSP40776.2020.9054749, 10.1109/icassp40776.2020.9054749]
   Elangovan P, 2021, SN Comput Sci, V2, P380
   Han K, 2014, INTERSPEECH, P223
   Heracleous P, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0220386
   Hifny Y, 2019, INT CONF ACOUST SPEE, P6710, DOI 10.1109/ICASSP.2019.8683632
   Huang YM, 2019, J AMB INTEL HUM COMP, V10, P1787, DOI 10.1007/s12652-017-0644-8
   Huang ZW, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P801, DOI 10.1145/2647868.2654984
   Issa D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101894
   Kar MK, 2021, SN COMPUTER SCI, V2
   Kerkeni L, 2019, SPEECH COMMUN, V114, P22, DOI 10.1016/j.specom.2019.09.002
   Khan S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-017-18734-8
   Kim J, 2007, Robust Speech Recognition and Understanding, V265, P280, DOI DOI 10.5772/4754
   Kim JW, 2018, INTERSPEECH, P937, DOI 10.21437/Interspeech.2018-1132
   Kim J, 2008, IEEE T PATTERN ANAL, V30, P2067, DOI 10.1109/TPAMI.2008.26
   Kim Y, 2021, ENG GEOL, V288, DOI 10.1016/j.enggeo.2021.106142
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Lakomkin E, 2018, IEEE INT C INT ROBOT, P854, DOI 10.1109/IROS.2018.8593571
   Lalitha S, 2020, APPL ACOUST, V170, DOI 10.1016/j.apacoust.2020.107519
   LANG PJ, 1995, AM PSYCHOL, V50, P372, DOI 10.1037/0003-066X.50.5.372
   Lella KK, 2021, AIMS PUBLIC HEALTH, V8, P240, DOI 10.3934/publichealth.2021019
   Livi S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193508
   Lopez-Moreno Ignacio, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5337, DOI 10.1109/ICASSP.2014.6854622
   Mansouri-Benssassi E., 2019, IEEE IJCNN, P1, DOI [DOI 10.1109/IJCNN.2019.8852473, DOI 10.1109/ijcnn.2019.8852473]
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   McFee B., 2015, P 14 PYTH SCI C, P18, DOI [DOI 10.25080/MAJORA-7B98E3ED-003, 10.25080/Majora-7b98e3ed-003]
   Meftah A, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Mustaqeem, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010183
   Nagarajan S, 2020, DIGIT SIGNAL PROCESS, V104, DOI 10.1016/j.dsp.2020.102763
   Neumann M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5769, DOI 10.1109/ICASSP.2018.8462162
   ORTONY A, 1990, PSYCHOL REV, V97, P315, DOI 10.1037/0033-295X.97.3.315
   Özseven T, 2019, APPL ACOUST, V146, P320, DOI 10.1016/j.apacoust.2018.11.028
   Palo HK, 2018, AIN SHAMS ENG J, V9, P1799, DOI 10.1016/j.asej.2016.11.001
   Pandey SK, 2019, TENCON IEEE REGION, P1292, DOI [10.1109/tencon.2019.8929257, 10.1109/TENCON.2019.8929257]
   PICONE JW, 1993, P IEEE, V81, P1215, DOI 10.1109/5.237532
   Popova AS, 2018, STUD COMPUT INTELL, V736, P117, DOI 10.1007/978-3-319-66604-4_18
   Riyad Mouad, 2020, Image and Signal Processing. 9th International Conference, ICISP 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12119), P103, DOI 10.1007/978-3-030-51935-3_11
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Schuller B, 2011, SELECTING TRAINING D
   Sefara T. J., 2019, 2019 INT MULT INF TE, P1, DOI DOI 10.1109/IMITEC45504.2019.9015895
   Sekkate S, 2020, INT C INTELLIGENT SY
   Sekkate S, 2019, COMPUTERS, V8, DOI 10.3390/computers8040091
   Sekkate S, 2019, CIRC SYST SIGNAL PR, V38, P3743, DOI 10.1007/s00034-019-01026-z
   Sekkate S, 2019, LECT NOTES COMPUT SC, V11557, P96, DOI 10.1007/978-3-030-22885-9_10
   Settle S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4819, DOI 10.1109/ICASSP.2018.8461893
   Sönmez YU, 2020, IEEE ACCESS, V8, P190784, DOI 10.1109/ACCESS.2020.3031763
   Srinivas NSS, 2019, CIRC SYST SIGNAL PR, V38, P5018, DOI 10.1007/s00034-019-01100-6
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sugan N., 2018, 2018 International CET Conference on Control, Communication, and Computing (IC4), P266, DOI 10.1109/CETIC4.2018.8531065
   THOITS PA, 1989, ANNU REV SOCIOL, V15, P317
   Trigeorgis G, 2016, INT CONF ACOUST SPEE, P5200, DOI 10.1109/ICASSP.2016.7472669
   Yang B, 2010, SIGNAL PROCESS, V90, P1415, DOI 10.1016/j.sigpro.2009.09.009
   Yenigalla P, 2018, INTERSPEECH, P3688, DOI 10.21437/Interspeech.2018-1811
   Zeng YN, 2019, MULTIMED TOOLS APPL, V78, P3705, DOI 10.1007/s11042-017-5539-3
NR 67
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11443
EP 11460
DI 10.1007/s11042-022-14051-z
EA OCT 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000870644300001
DA 2024-07-18
ER

PT J
AU Jiji, GW
   Rajesh, A
   Lakshmi, MM
AF Jiji, G. Wiselin
   Rajesh, A.
   Lakshmi, M. Maha
TI Diagnosis of Parkinson's disease using EEG and fMRI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parkinson's disease (PD); Healthy Control (HC); Functional connectome;
   Network; Features
ID CLASSIFICATION
AB Parkinson's disease (PD) is a brain disorder that leads to shaking, stiffness, and difficulty with walking, balance, and coordination. Parkinson's symptoms usually begin gradually and get worse over time. We have developed a framework to find solution for early diagnose of PD by investigating the topological properties of functional brain networks within fMRI and EEG Signals. After the construction partial correlation matrices of 160 regions from Dosenbach brain from fMRI image, six features were extracted. As well as extracted five features from EEG signals and these 11 inputs were given as input to adaboost classifier. This system has produced 93.45% accuracy and the outcome is significantly higher accuracy when compared to earlier works.
C1 [Jiji, G. Wiselin] Dr Sivanthi Aditanar Coll Engn, Dept Comp Sci & Engn, Tiruchendur, India.
   [Rajesh, A.] Indian Space Res Org, Vikram Sarabhai Space Ctr, Thiruvananthapuram 695022, Kerala, India.
   [Lakshmi, M. Maha] Dr Sivanthi Aditanar Coll Engn, Tiruchendur, India.
C3 Department of Space (DoS), Government of India; Indian Space Research
   Organisation (ISRO); Vikram Sarabhai Space Center (VSSC)
RP Jiji, GW (corresponding author), Dr Sivanthi Aditanar Coll Engn, Dept Comp Sci & Engn, Tiruchendur, India.
EM jijivevin@yahoo.co.in
CR Artusi R, 2002, INT J BIOL MARKER, V17, P148, DOI 10.1177/172460080201700213
   Baggio HC, 2014, HUM BRAIN MAPP, V35, P4620, DOI 10.1002/hbm.22499
   Barth J, 2012, IEEE ENG MED BIO, P5122, DOI 10.1109/EMBC.2012.6347146
   Calimeri F, 2021, THEOR PRACT LOG PROG, V21, P80, DOI 10.1017/S1471068419000449
   Chen YB, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124153
   Cheung, 2016, PARKINSONS DIS SEGME
   CHUANG TY, 1982, ANN INTERN MED, V97, P672, DOI 10.7326/0003-4819-97-5-672
   Dorsey ER, 2018, LANCET NEUROL, V17, P939, DOI 10.1016/S1474-4422(18)30295-3
   Douglas PK, 2011, NEUROIMAGE, V56, P544, DOI 10.1016/j.neuroimage.2010.11.002
   Doyle M, 1796, J CLIN CHIROPR PEDIA
   Drotar P, 2015, IEEE INT SYM MED MEA, P344, DOI 10.1109/MeMeA.2015.7145225
   ESPIR MLE, 1966, J NEUROL NEUROSUR PS, V29, P323, DOI 10.1136/jnnp.29.4.323
   Frid A, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE SCIENCE, TECHNOLOGY AND ENGINEERING (SWSTE), P50, DOI 10.1109/SWSTE.2014.17
   Gautam, 2021, ANAL PARKINSONS DIS
   Göttlich M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0077336
   Handojoseno AMA, 2013, IEEE ENG MED BIO, P4263, DOI 10.1109/EMBC.2013.6610487
   Mao L, 2020, JAMA NEUROL, V77, P683, DOI 10.1001/jamaneurol.2020.1127
   Mostafa SA, 2019, COGN SYST RES, V54, P90, DOI 10.1016/j.cogsys.2018.12.004
   Passos LA, 2018, 2018 IEEE 12TH INTERNATIONAL SYMPOSIUM ON APPLIED COMPUTATIONAL INTELLIGENCE AND INFORMATICS (SACI), P325, DOI 10.1109/SACI.2018.8441012
   Patel S, 2009, IEEE T INF TECHNOL B, V13, P864, DOI 10.1109/TITB.2009.2033471
   Pereira CR, 2016, COMPUT METH PROG BIO, V136, P79, DOI 10.1016/j.cmpb.2016.08.005
   Prajapati R, 2021, INT J NEUROSCI, V131, P105, DOI 10.1080/00207454.2020.1733559
   RAZDAN S, 1994, NEUROEPIDEMIOLOGY, V13, P113, DOI 10.1159/000110368
   Rumman M, 2018, 2018 JOINT 7TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV) AND 2018 2ND INTERNATIONAL CONFERENCE ON IMAGING, VISION & PATTERN RECOGNITION (ICIVPR), P256, DOI 10.1109/ICIEV.2018.8641081
   Saikia, 2019, INT J EMERG TECHNOL, V10, P166
   Samà A, 2012, IEEE ENG MED BIO, P1194, DOI 10.1109/EMBC.2012.6346150
   Selvaraj S, 2019, GENES DIS, V6, P120, DOI 10.1016/j.gendis.2019.01.004
   Shagam Janet Yagoda, 2008, Radiol Technol, V79, P227
   Sinen O, 2021, INT J NEUROSCI, V131, P765, DOI 10.1080/00207454.2020.1754213
   Singhal B, 2003, PARKINSONISM RELAT D, V9, pS105, DOI 10.1016/S1353-8020(03)00024-5
   Tsanas A, 2012, IEEE T BIO-MED ENG, V59, P1264, DOI 10.1109/TBME.2012.2183367
   Valli A., 2014, INT J COMPUT SCI APP, V4, P55
   Wang JH, 2015, FRONT HUM NEUROSCI, V9, DOI [10.3389/fnhum.2015.00386, 10.3389/fnhum.2015.00458]
   Wroge TJ, 2018, IEEE SIG PROC MED, DOI 10.1109/SPMB.2018.8615607
   Yuvaraj R, 2018, NEURAL COMPUT APPL, V30, P1225, DOI 10.1007/s00521-016-2756-z
   Zhang DL, 2015, FRONT AGING NEUROSCI, V7, DOI 10.3389/fnagi.2015.00006
NR 36
TC 4
Z9 4
U1 8
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14915
EP 14928
DI 10.1007/s11042-022-14042-0
EA OCT 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000869194800003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ghosal, S
   Jain, A
AF Ghosal, Sayani
   Jain, Amita
TI Weighted aspect based sentiment analysis using extended OWA operators
   and Word2Vec for tourism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aspect based sentiment analysis; Aspect rating; OWA operator; Neural
   network; Word embedding; Natural language processing
ID ASPECT EXTRACTION; REVIEWS; OPINION; BACKPROPAGATION
AB The tourism industry stimulates business revenues and economic activities across the globe. Effective analysis of enormous tourism reviews boosts both service quality and growth of industries. Aspect-based sentiment analysis (ABSA) has shown a prominent role in the aspect segmentation and sentiment ratings that obtains overall feedbacks and individual aspect feedback. In this regard, researchers are using Artificial Neural Network (ANN) for ABSA model learning. In addition to ANN, the state-of-the-art sentiment rating models adopted arithmetic mean (AM) of word embedding vectors and considered equal weightage to all aspects and reviews. But in real-world circumstances, these aspects and aspect reviews do not exhibit equal importance. They may vary from user to user and cannot be given equal weights. This is the first sentiment aggregation research that considers overall sentiment rating is consensus value from sentiment of its aspects and each aspect sentiment is the majority's opinion associated sentences and their words. The proposed multi-layer knowledge representation architecture addresses this concept by using Word2Vec and extended families of the Ordered Weighted Average (OWA) operators. The novel approach signifies the weighted degree of importance for opinions and aspects using majority additive OWA (MAOWA), selective majority additive OWA (SMAOWA), and weighted selective aggregated majority OWA (WSAMOWA) operators. In addition to this, the proposed model also considers explicit and implicit aspect segmentation for review files, incorporates the meaning of slang internet words, and location-based geospatial rating analysis. Experimentation and evaluation conducted on TripAdvisor, Booking.com, Datafiniti tourism datasets show improvement in RMSE 14.68%, 59.03% and 12.97% and in Pearson correlation 30.63%, 23.34% and 32.61% respectively.
C1 [Ghosal, Sayani] Guru Gobind Singh Indraprastha Univ, NSUT East Campus Erstwhile AIACTR, Delhi, India.
   [Jain, Amita] Netaji Subhas Univ Technol, Delhi, India.
C3 GGS Indraprastha University; Netaji Subhas University of Technology
RP Jain, A (corresponding author), Netaji Subhas Univ Technol, Delhi, India.
EM sayanighosal@gmail.com; amita.jain@nsut.ac.in
RI Ghosal, Sayani/AEC-1435-2022
OI Ghosal, Sayani/0000-0002-0979-0788
CR Abbasimehr H, 2019, 2019 5TH INTERNATIONAL CONFERENCE ON WEB RESEARCH (ICWR), P1, DOI [10.1109/ICWR.2019.8765285, 10.1109/icwr.2019.8765285]
   Aftab H, 2021, INT WIREL COMMUN, P2038, DOI 10.1109/IWCMC51323.2021.9498609
   AMARI S, 1993, NEUROCOMPUTING, V5, P185, DOI 10.1016/0925-2312(93)90006-O
   [Anonymous], 2022, UNWTO World Tourism Barometer
   Anselin L, 2006, GEOGR ANAL, V38, P5, DOI 10.1111/j.0016-7363.2005.00671.x
   Cambria E, 2017, SOCIO AFFECT COMPUT, V5, P1, DOI 10.1007/978-3-319-55394-8_1
   Chang V, 2023, EXPERT SYST, V40, DOI 10.1111/exsy.12580
   Chang YC, 2020, TOURISM MANAGE, V80, DOI 10.1016/j.tourman.2020.104129
   Chang YC, 2019, INT J INFORM MANAGE, V48, P263, DOI 10.1016/j.ijinfomgt.2017.11.001
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Cheng ZY, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P639, DOI 10.1145/3178876.3186145
   cloud5, 2022, 5 HOSP TRENDS Q1 202
   Cotter A, 2011, ARXIV, DOI DOI 10.48550/ARXIV.1106.4574
   Pham DH, 2018, DATA KNOWL ENG, V114, P26, DOI 10.1016/j.datak.2017.06.001
   Pham DH, 2016, LECT NOTES COMPUT SC, V9795, P309, DOI 10.1007/978-3-319-42345-6_27
   Ganganwar V, 2019, PROCEDIA COMPUT SCI, V165, P485, DOI 10.1016/j.procs.2020.01.010
   Gaxiola F, 2015, INFORM SCIENCES, V325, P159, DOI 10.1016/j.ins.2015.07.020
   Ghosal S, 2021, PROG ARTIF INTELL, V10, P505, DOI 10.1007/s13748-021-00252-4
   Godil DI, 2020, ENVIRON SCI POLLUT R, V27, P40109, DOI 10.1007/s11356-020-09937-0
   Gupta A, 2019, PROG ARTIF INTELL, V8, P111, DOI 10.1007/s13748-018-0159-3
   Hai Z, 2011, LECT NOTES COMPUT SC, V6608, P393, DOI 10.1007/978-3-642-19400-9_31
   Hermann K M, 2014, ARXIV, DOI DOI 10.48550/ARXIV.1404.4641
   Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P755
   Jermsittiparsert K., 2019, BEHAV TOURISM IND SI
   Jerripothula KR, 2020, IEEE T COMPUT SOC SY, V7, P1210, DOI 10.1109/TCSS.2020.3010807
   Jin L, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P916, DOI 10.1145/3394171.3414022
   Karanik M, 2016, EUR J OPER RES, V250, P816, DOI 10.1016/j.ejor.2015.10.011
   Lee KH, 2005, 1 COURSE FUZZY THEOR, DOI [10.1007/3-540-32366-X, DOI 10.1007/3-540-32366-X]
   Li Yu, 2021, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/1995/1/012040
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Luo Y, 2019, INT J HOSP MANAG, V80, P144, DOI 10.1016/j.ijhm.2019.02.008
   Mariani MM, 2018, TOURISM MANAGE, V66, P47, DOI 10.1016/j.tourman.2017.11.006
   Nazir A, 2022, IEEE T AFFECT COMPUT, V13, P845, DOI 10.1109/TAFFC.2020.2970399
   Ozyurt B, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114231
   Pang B, 2002, ARXIV, DOI [10.48550/arXiv.cs/0205070, DOI 10.48550/ARXIV.CS/0205070]
   Peláez JI, 2016, SOFT COMPUT, V20, P1047, DOI 10.1007/s00500-014-1564-6
   Peláez JI, 2003, INT J INTELL SYST, V18, P469, DOI 10.1002/int.10096
   Peng ZM, 2019, IEEE I CONF COMP VIS, P441, DOI 10.1109/ICCV.2019.00053
   Poria S, 2016, KNOWL-BASED SYST, V108, P42, DOI 10.1016/j.knosys.2016.06.009
   Prasojo R E, 2015, P 24 ACM INT C INF K, P233, DOI [10.1145/2806416.2806576, DOI 10.1145/2806416.2806576]
   Rana TA, 2016, ARTIF INTELL REV, V46, P459, DOI 10.1007/s10462-016-9472-z
   Razzaq A, 2021, SUSTAIN DEV, V29, P176, DOI 10.1002/sd.2139
   Sarlis S., 2020, IAICT, P409, DOI [10.1007/978-3-030-49161-1_34, DOI 10.1007/978-3-030-49161-1]
   Serrano-Guerrero J, 2020, IEEE INT CONF FUZZY, DOI 10.1109/fuzz48607.2020.9177614
   Serrano-Guerrero J, 2019, ATL STUD UNCER MODEL, V1, P452
   Serrano-Guerrero J, 2020, KNOWL-BASED SYST, V189, DOI 10.1016/j.knosys.2019.105131
   Shuja J, 2021, IEEE SENS J, V21, P25114, DOI 10.1109/JSEN.2021.3060953
   Thelwall M., 2019, Big data and innovation in tourism, travel, and hospitality, P87, DOI DOI 10.1007/978-981-13-6339-9_6
   Toutanova K, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P252, DOI 10.3115/1073445.1073478
   UNWTO, 2021, UNWTO
   Wang H., 2011, P 17 ACM SIGKDD INT, P618, DOI DOI 10.1145/2020408.2020505
   Wang H, 2010, Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P783, DOI [DOI 10.1145/1835804.1835903, 10.1145/1835804.1835903]
   Xing SN, 2019, NEUROCOMPUTING, V332, P417, DOI 10.1016/j.neucom.2018.12.027
   Yadav ML, 2019, INT J HOSP MANAG, V80, P155, DOI 10.1016/j.ijhm.2019.02.002
   YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068
   Ye Q, 2009, EXPERT SYST APPL, V36, P6527, DOI 10.1016/j.eswa.2008.07.035
   Yen J., 1995, IND APPL FUZZY LOGIC
   Yusoff B, 2018, INT J INTELL SYST, V33, P1929, DOI 10.1002/int.22004
   Zhang WH, 2012, EXPERT SYST APPL, V39, P10283, DOI 10.1016/j.eswa.2012.02.166
NR 59
TC 5
Z9 5
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18353
EP 18380
DI 10.1007/s11042-022-13800-4
EA OCT 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000866314400005
DA 2024-07-18
ER

PT J
AU Singh, OD
   Dhall, S
   Malik, A
   Gupta, S
AF Singh, Om Dev
   Dhall, Sangeeta
   Malik, Anjali
   Gupta, Shailender
TI A robust and secure immensely random GAN based image encryption
   mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Generative adversarial network (GAN); Unsupervised
   learning; Deep learning; Logistic maps; Pseudo random number generator
   (PRNG)
ID CHAOTIC MAP; SCHEME
AB Protection of information (data/images) is crucial in the colossal and ever-expanding domain of digital transfer. Cryptography is one of the well-known admired solutions to preserve images' confidentiality over highly unreliable and unrestricted public media. Researchers propose numerous techniques to accomplish the ever-growing need for security. In continuation, this paper aims to develop a robust image encryption scheme that accomplishes the task of protection by employing a series of specially designed substitution box, permutation box and diffusion box by taking encryption keys as input which is consequently generated from a Generative Adversarial Network (GAN), an unsupervised deep learning algorithm trained on the Logistic Maps. The substitution box performs byte-level substitution using two different schemes, and the other two perform encryption at both bit-level and byte-level, which helps it withstand a wide range of attacks. A dataset with 789 standard images is taken for experimentation, partitioned into three sets according to size (128, 256, and 512). The projected scheme outperforms state-of-the-art methods with better performance since the trained generator passed the comprehensive tests; it also withstands most of the probable attacks available in the literature. GAN was subjected to the chi-square test, runs test, and NIST test suite to check the randomness of the Pseudo-Random Number Generator. The projected algorithm offers promising visual, statistical, robustness, and quantitative analysis results.
C1 [Singh, Om Dev; Dhall, Sangeeta; Malik, Anjali; Gupta, Shailender] JC Bose Univ Sci & Technol, YMCA, Faridabad, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Dhall, S (corresponding author), JC Bose Univ Sci & Technol, YMCA, Faridabad, India.
EM devsingh640@gmail.com; Sangeeta_dhall@yahoo.co.in;
   anjalimalik0611@gmail.com; Shailender81@gmail.com
RI gupta, shailender/Y-8231-2019
OI gupta, shailender/0000-0003-1383-7152; Malik, Anjali/0009-0006-9598-3522
CR Abadi Martin, 2016, arXiv
   Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Akhshani A, 2014, COMMUN NONLINEAR SCI, V19, P101, DOI 10.1016/j.cnsns.2013.06.017
   Akhshani A, 2012, COMMUN NONLINEAR SCI, V17, P4653, DOI 10.1016/j.cnsns.2012.05.033
   Alkhelaiwi M, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13112221
   Appel AW, 2015, ACM T PROGR LANG SYS, V37, DOI 10.1145/2701415
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bansal R, 2017, MULTIMED TOOLS APPL, V76, P16529, DOI 10.1007/s11042-016-3926-9
   Bassham L. E., 2010, SPECIAL PUBLICATION
   Bernardi Marcello, 2019, ECML PKDD 2018 Workshops. Nemesis 2018, UrbReas 2018, SoGood 2018 IWAISe 2018, and Green Data Mining 2018. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11329), P191, DOI 10.1007/978-3-030-13453-2_15
   Brock A., 2018, PREPRINT
   Brunet D, 2012, IEEE T IMAGE PROCESS, V21, P1488, DOI 10.1109/TIP.2011.2173206
   Cao Y, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/4316163
   Chopra A, 2020, MULTIMED TOOLS APPL, V79, P501, DOI 10.1007/s11042-019-08087-x
   Ding Y, 2021, IEEE INTERNET THINGS, V8, P1504, DOI 10.1109/JIOT.2020.3012452
   Dosselmann R, 2011, SIGNAL IMAGE VIDEO P, V5, P81, DOI 10.1007/s11760-009-0144-1
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hanchinamani G, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0062-7
   Hars L, 2012, EURASIP J EMBED SYST, DOI 10.1186/1687-3963-2012-1
   He C, 2019, DEEP LEARNING BASED
   Hu F, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/3675459
   Kumari M, 2020, MULTIMED TOOLS APPL, V79, P33161, DOI 10.1007/s11042-020-09627-6
   Kumari M, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0162-2
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501734
   Liu HJ, 2020, OPTIK, V216, DOI 10.1016/j.ijleo.2020.164925
   Liu H, 2017, 3D RES, V8, DOI 10.1007/s13319-016-0114-7
   Liu XB, 2019, IEEE ACCESS, V7, P6937, DOI 10.1109/ACCESS.2018.2889896
   Malik A, 2021, MULTIMED TOOLS APPL, V80, P21521, DOI 10.1007/s11042-021-10670-0
   Man ZL, 2021, MULTIMED TOOLS APPL, V80, P27445, DOI 10.1007/s11042-021-10979-w
   Martino Raffaele, 2020, Internet of Things, V11, P143, DOI 10.1016/j.iot.2020.100254
   Mendel F, 2006, LECT NOTES COMPUT SC, V4047, P126
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Padhee Malhar., 2017, 2017 North American Power Symposium (NAPS), P1, DOI DOI 10.1109/ISED.2017.8303943
   SaberiKamarposhti M, 2014, NONLINEAR DYNAM, V75, P407, DOI 10.1007/s11071-013-0819-6
   Sam IS, 2012, NONLINEAR DYNAM, V69, P1995, DOI 10.1007/s11071-012-0402-6
   Sam IS, 2012, MULTIMED TOOLS APPL, V56, P315, DOI 10.1007/s11042-010-0652-6
   Wang J, 2020, IEEE ACCESS, V8, P8459, DOI 10.1109/ACCESS.2019.2963478
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Ye GD, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500104
   Ye GD, 2012, NONLINEAR DYNAM, V69, P2079, DOI 10.1007/s11071-012-0409-z
   Zhang XC, 2019, INT J OPT, V2019, DOI 10.1155/2019/3594534
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-1902-1
NR 47
TC 3
Z9 3
U1 4
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19693
EP 19743
DI 10.1007/s11042-022-14000-w
EA OCT 2022
PG 51
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000864589600004
DA 2024-07-18
ER

PT J
AU Satyanath, G
   Sahoo, JK
   Roul, RK
AF Satyanath, Gaurav
   Sahoo, Jajati Keshari
   Roul, Rajendra Kumar
TI Smart parking space detection under hazy conditions using convolutional
   neural networks: a novel approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Computer vision; Convolutional neural networks; Deep
   learning; Hazy parking; Image Dehazing; IoT; Smart parking system
ID VEHICLE; VISION
AB Limited urban parking space combined with urbanization has necessitated the development of smart parking systems that can communicate the availability of parking slots to the end-users. Towards this, various deep learning based solutions using convolutional neural networks have been proposed for parking space occupation detection. Though these approaches are robust to partial obstructions and lighting conditions, their performance is found to degrade in the presence of haze conditions. Looking in this direction, this paper investigates the use of dehazing networks that improves the performance of parking space occupancy classifier under hazy conditions. Additionally, training procedures are proposed for dehazing networks to maximize the performance of the system under both hazy and non-hazy conditions. The proposed system is deployable as part of existing smart parking systems, where a limited number of cameras are used to monitor hundreds of parking spaces. To validate our approach, we have developed a custom hazy parking system dataset from real-world task-driven test set of RESIDE-beta dataset. The proposed approach is tested against existing state-of-the-art parking space detectors on CNRPark-EXT and hazy parking system datasets. Experimental results indicate a significant accuracy improvement of the proposed approach on the hazy parking system dataset.
C1 [Satyanath, Gaurav] Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA.
   [Sahoo, Jajati Keshari] BITS Pilani, Dept Math, KK Birla Goa Campus, Sancoale, Goa, India.
   [Roul, Rajendra Kumar] Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.
C3 Carnegie Mellon University; Birla Institute of Technology & Science
   Pilani (BITS Pilani); Thapar Institute of Engineering & Technology
RP Satyanath, G (corresponding author), Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA.
EM gsatyana@andrew.cmu.edu; jksahoo@goa.bits-pilani.ac.in;
   raj.roul@thapar.edu
RI Sahoo, Jajati Keshari/ABA-6992-2021
OI Sahoo, Jajati Keshari/0000-0001-6104-5171; Satyanath,
   Gaurav/0000-0001-9047-1583
CR Ajchariyavanich C, 2019, IEEE INT SM C CONF, P729, DOI [10.1109/ISC246665.2019.9071721, 10.1109/isc246665.2019.9071721]
   Akhtar ZU, 2020, NEUROCOMPUTING, V405, P12, DOI 10.1016/j.neucom.2020.04.133
   Al-Turjman F, 2019, SUSTAIN CITIES SOC, V49, DOI 10.1016/j.scs.2019.101608
   Ali G, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9101696
   Almeida P, 2013, IEEE SYS MAN CYBERN, P3603, DOI 10.1109/SMC.2013.614
   Alshdadi AA, 2021, SOFT COMPUT, V25, P12261, DOI 10.1007/s00500-021-05908-w
   Amato G, 2017, EXPERT SYST APPL, V72, P327, DOI 10.1016/j.eswa.2016.10.055
   Amato G, 2016, 2016 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATION (ISCC), P1212, DOI 10.1109/ISCC.2016.7543901
   Anagnostopoulos T, 2020, NEURAL COMPUT APPL, V32, P10783, DOI 10.1007/s00521-019-04613-y
   [Anonymous], 2007, VACANT PARKING SPACE
   Barriga JJ, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9214569
   Bura H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON COGNITIVE COMPUTING (ICCC), P17, DOI 10.1109/ICCC.2018.00010
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen C, 2021, IEEE T INTELL TRANSP, V22, P1840, DOI 10.1109/TITS.2020.3025687
   Chippalkatti P, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMMUNICATION AND COMPUTING TECHNOLOGY (ICACCT), P473, DOI 10.1109/ICACCT.2018.8529541
   Choi J, 2015, MULTIMED TOOLS APPL, V74, P3277, DOI 10.1007/s11042-014-1862-0
   Cueva-Fernandez G, 2015, APPL SOFT COMPUT, V35, P708, DOI 10.1016/j.asoc.2015.01.066
   de Almeida PRL, 2015, EXPERT SYST APPL, V42, P4937, DOI 10.1016/j.eswa.2015.02.009
   Dhillon A, 2020, PROG ARTIF INTELL, V9, P85, DOI 10.1007/s13748-019-00203-0
   Ogás MGD, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10113872
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Giuffrè T, 2012, PROCD SOC BEHV, V53, P16, DOI 10.1016/j.sbspro.2012.09.856
   Gkolias K, 2019, IEEE T INTELL TRANSP, V20, P4318, DOI 10.1109/TITS.2018.2882439
   Gonzalez-Lozoya SM, 2020, MULTIMED TOOLS APPL, V79, P13987, DOI 10.1007/s11042-020-08681-4
   Guo YM, 2018, MULTIMED TOOLS APPL, V77, P10251, DOI 10.1007/s11042-017-5443-x
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Huang FH, 2020, FUTURE GENER COMP SY, V111, P271, DOI 10.1016/j.future.2020.04.047
   Idris M. Y. I., 2009, Information Technology Journal, V8, P138, DOI 10.3923/itj.2009.138.146
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Khalid M, 2021, J NETW COMPUT APPL, V175, DOI 10.1016/j.jnca.2020.102935
   Khanna A, 2016, 2016 INTERNATIONAL CONFERENCE ON INTERNET OF THINGS AND APPLICATIONS (IOTA), P266, DOI 10.1109/IOTA.2016.7562735
   Kianpisheh A., 2012, INT J SOFTWARE ENG I, V6, P51
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y., 2015, Lenet-5, convolutional neural networks
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Lin T, 2017, IEEE T INTELL TRANSP, V18, P3229, DOI 10.1109/TITS.2017.2685143
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu JJ, 2021, SOFT COMPUT, V25, P12017, DOI 10.1007/s00500-021-05696-3
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Mago N, 2022, INT J FUZZY SYST, V24, P2560, DOI 10.1007/s40815-021-01212-9
   Mármol E, 2016, MULTIMED TOOLS APPL, V75, P17711, DOI 10.1007/s11042-016-3773-8
   McCartney E. J., 1976, Optics of the atmosphere. Scattering by molecules and particles
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Naufal A., 2020, INT J INTELL ENG SYS, V13, P255, DOI DOI 10.22266/IJIES2020.1231.23
   Nurullayev S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020277
   Nyambal J, 2017, 2017 PATTERN RECOGNITION ASSOCIATION OF SOUTH AFRICA AND ROBOTICS AND MECHATRONICS (PRASA-ROBMECH), P1, DOI 10.1109/RoboMech.2017.8261114
   Rahman MM, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1682-y
   Ramasamy M, 2018, 2018 IEEE 4TH INTERNATIONAL SYMPOSIUM IN ROBOTICS AND MANUFACTURING AUTOMATION (ROMA)
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Ren ZG, 2021, NEUROCOMPUTING, V443, P329, DOI 10.1016/j.neucom.2021.02.034
   Saharan S, 2020, FUTURE GENER COMP SY, V106, P622, DOI 10.1016/j.future.2020.01.031
   Scekic Z., 2022, 2022 26 INT C INFORM, P1, DOI 10.1109/IT54280.2022.9743533
   Shoup DC, 2006, TRANSPORT POLICY, V13, P479, DOI 10.1016/j.tranpol.2006.05.005
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Targ S., 2016, ARXIV
   Wang ZY, 2022, NEURAL COMPUT APPL, V34, P3513, DOI 10.1007/s00521-021-05870-6
   Wang ZY, 2016, LECT NOTES COMPUT SC, V9912, P533, DOI 10.1007/978-3-319-46484-8_32
   Wu H, 2018, APPL SOFT COMPUT, V71, P538, DOI 10.1016/j.asoc.2018.07.008
   Xiang XZ, 2017, IEEE SENS J, V17, P6360, DOI 10.1109/JSEN.2017.2741722
   Xu YJ, 2021, FUTURE GENER COMP SY, V117, P138, DOI 10.1016/j.future.2020.11.005
   Zhu L, 2019, IEEE T INTELL TRANSP, V20, P383, DOI 10.1109/TITS.2018.2815678
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 66
TC 3
Z9 3
U1 4
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15415
EP 15438
DI 10.1007/s11042-022-13958-x
EA OCT 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000863811400006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, Q
AF Zhang, Qiang
TI Multi-object trajectory extraction based on YOLOv3-DeepSort for
   pedestrian-vehicle interaction behavior analysis at non-signalized
   intersections
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Trajectory extraction; YOLOv3; DeepSort; Interaction behavior;
   Non-signalized intersection
ID RECOMMENDATION SYSTEM; MULTITARGET TRACKING; RISK-FACTORS; SAFETY;
   CROSSWALK; RECOGNITION; APPEARANCE; SEVERITY; INJURY; MODEL
AB Pedestrian-vehicle interaction behavior analysis at non-signalized intersections has become the important content of traffic safety research. In this paper, we focus on presenting a processing framework for the analysis of pedestrian-vehicle interaction behavior based on YOLOv3-DeepSort. Comparative experiments are done for verifying the performance of the presented framework. The presented YOLOv3-DeepSort can achieve the results that the ML value is 14.10% and the IDs value is 382 on the MOT16 dataset. And YOLOv3-416 can achieve the efficiency of 29 ms. Results show that the presented framework has excellent performance for trajectory extraction. Furthermore, the methodology is confirmed by the presented case. And we found that the studies on exit interactions can provide theoretical evidences for presenting some protective measures, to ensure the safety of pedestrians and vehicles at non-signalized intersections.
C1 [Zhang, Qiang] Southeast Univ, Sch Transportat, Southeast Univ Rd 2, Nanjing 211189, Peoples R China.
C3 Southeast University - China
RP Zhang, Q (corresponding author), Southeast Univ, Sch Transportat, Southeast Univ Rd 2, Nanjing 211189, Peoples R China.
EM mrzhang0536@foxmail.com
CR Ackermann C, 2019, TRANSPORT RES F-TRAF, V62, P757, DOI 10.1016/j.trf.2019.03.006
   Ahmad T, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/8403262
   Alsaleh R, 2018, TRANSPORT RES REC, V2672, P46, DOI 10.1177/0361198118780708
   Bennett MK, 2016, TRANSPORT RES REC, P100, DOI 10.3141/2586-11
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2022, ENVIRON SCI POLLUT R, V29, P14780, DOI 10.1007/s11356-021-16627-y
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Bloemendal P, 2013, STICHTING WETENSCHAP
   Cai YF, 2022, IEEE T INTELL TRANSP, V23, P5298, DOI 10.1109/TITS.2021.3052908
   Chen C, 2021, IEEE T INTELL TRANSP, V22, P1840, DOI 10.1109/TITS.2020.3025687
   Cheng RQ, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.5.053025
   Cho HK, Smart crosswalk traffic safety system useful for visualizing pedestrians crosswalk use state information comprises camera that is installed adjacent to crosswalk for photographing crosswalk and surrounding areas of crosswalk, Patent No. [KR2021065219-A, 2021065219]
   Chu Q, 2017, IEEE I CONF COMP VIS, P4846, DOI 10.1109/ICCV.2017.518
   Coifman B, 1998, TRANSPORT RES C-EMER, V6, P271, DOI 10.1016/S0968-090X(98)00019-9
   Dai JF, 2016, ADV NEUR IN, V29
   Dewan MC, 2019, J NEUROSURG, V130, P1080, DOI 10.3171/2017.10.JNS17352
   Dey D, 2019, TRANSPORT RES F-TRAF, V65, P191, DOI 10.1016/j.trf.2019.07.027
   Dingus TA, 2016, P NATL ACAD SCI USA, V113, P2636, DOI 10.1073/pnas.1513271113
   Dinno A, 2015, STATA J, V15, P292, DOI 10.1177/1536867X1501500117
   Eluru N, 2008, ACCIDENT ANAL PREV, V40, P1033, DOI 10.1016/j.aap.2007.11.010
   Fang K, 2018, IEEE WINT CONF APPL, P466, DOI 10.1109/WACV.2018.00057
   Fang YX, 2022, MULTIMED TOOLS APPL, V81, P16863, DOI 10.1007/s11042-022-12592-x
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Fu T, 2019, TRANSPORT RES C-EMER, V105, P222, DOI 10.1016/j.trc.2019.06.001
   Fu T, 2018, ACCIDENT ANAL PREV, V111, P23, DOI 10.1016/j.aap.2017.11.015
   Fu T, 2016, TRANSPORT RES REC, P90, DOI 10.3141/2586-10
   Gorrini A, 2018, TRANSPORT RES F-TRAF, V59, P269, DOI 10.1016/j.trf.2018.09.016
   Guo YY, 2018, ACCIDENT ANAL PREV, V115, P118, DOI 10.1016/j.aap.2018.03.006
   Hacohen S, 2018, TRANSPORT RES C-EMER, V86, P78, DOI 10.1016/j.trc.2017.10.024
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Iasmin H, 2016, IATSS RES, V40, P47, DOI 10.1016/j.iatssr.2016.04.001
   Jinlong Peng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P145, DOI 10.1007/978-3-030-58548-8_9
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Khasnabis S, 1982, TRANSP RES REC
   Kim H, 2022, J AMB INTEL HUM COMP, V13, P1603, DOI 10.1007/s12652-019-01429-5
   Kirchner A, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.056122
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Laureshyn A, 2010, ACCIDENT ANAL PREV, V42, P1637, DOI 10.1016/j.aap.2010.03.021
   Li GF, 2020, IEEE T IND ELECTRON, V67, P8889, DOI 10.1109/TIE.2019.2945295
   Li T, 2022, EURASIP J WIREL COMM, V25
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Loukaitou-Sideris A, 2007, J PLAN EDUC RES, V26, P338, DOI 10.1177/0739456X06297008
   Madigan R, 2019, TRANSPORT RES F-TRAF, V66, P196, DOI 10.1016/j.trf.2019.09.006
   Mahmoudi N, 2019, MULTIMED TOOLS APPL, V78, P7077, DOI 10.1007/s11042-018-6467-6
   McCall JC, 2006, IEEE T INTELL TRANSP, V7, P20, DOI 10.1109/TITS.2006.869595
   Nantulya VM, 2002, BRIT MED J, V324, P1139, DOI 10.1136/bmj.324.7346.1139
   Nawaz SA, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256971
   Olszewski P, 2020, TRANSPORT RES F-TRAF, V70, P25, DOI 10.1016/j.trf.2020.02.011
   Organization World Health., 2013, Global Status Report on Road Safety 2013
   Osama A, 2017, CAN J CIVIL ENG, V44, P1036, DOI 10.1139/cjce-2017-0145
   Pang B, 2020, PROC CVPR IEEE, P6307, DOI 10.1109/CVPR42600.2020.00634
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roudsari Bahman, 2006, Traffic Inj Prev, V7, P283, DOI 10.1080/15389580600660153
   Sanchez-Matilla R, 2016, LECT NOTES COMPUT SC, V9914, P84, DOI 10.1007/978-3-319-48881-3_7
   Sedgwick P, 2014, BMJ-BRIT MED J, V348, DOI 10.1136/bmj.g1072
   Sheykhfard A, 2020, ACCIDENT ANAL PREV, V144, DOI 10.1016/j.aap.2020.105661
   Takala J, 2014, J OCCUP ENVIRON HYG, V11, P326, DOI 10.1080/15459624.2013.863131
   Tang SY, 2016, LECT NOTES COMPUT SC, V9914, P100, DOI 10.1007/978-3-319-48881-3_8
   Tian SS, 2021, IEEE T NEUR SYS REH, V29, P1478, DOI 10.1109/TNSRE.2021.3096379
   Trivedi MM, 2007, IEEE T INTELL TRANSP, V8, P108, DOI 10.1109/TITS.2006.889442
   van Haperen W, 2019, ACCIDENT ANAL PREV, V123, P211, DOI 10.1016/j.aap.2018.11.021
   Veeramani B, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2267-2
   Wan XY, 2018, IEEE IMAGE PROC, P788, DOI 10.1109/ICIP.2018.8451174
   Wang YJ, 2021, ACCIDENT ANAL PREV, V161, DOI 10.1016/j.aap.2021.106381
   Wanvik PO, 2009, ACCIDENT ANAL PREV, V41, P123, DOI 10.1016/j.aap.2008.10.003
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Xing Y, 2019, IEEE T VEH TECHNOL, V68, P5379, DOI 10.1109/TVT.2019.2908425
   Yan FF, 2016, ACCIDENT ANAL PREV, V95, P381, DOI 10.1016/j.aap.2015.06.006
   Yu FW, 2016, LECT NOTES COMPUT SC, V9914, P36, DOI 10.1007/978-3-319-48881-3_3
   Yu KP, 2021, IEEE T INTELL TRANSP, V22, P4337, DOI 10.1109/TITS.2020.3042504
   Zhang GN, 2013, ACCIDENT ANAL PREV, V59, P18, DOI 10.1016/j.aap.2013.05.004
   Zhang JM, 2017, ALGORITHMS, V10, DOI 10.3390/a10040127
   Zhang X, 2019, PROC SPIE
   Zhang YF, 2021, INT J COMPUT VISION, V129, P3069, DOI 10.1007/s11263-021-01513-4
   Zhongdao Wang, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P107, DOI 10.1007/978-3-030-58621-8_7
   Zhou ZW, 2018, INT C PATT RECOG, P1809, DOI 10.1109/ICPR.2018.8545450
NR 85
TC 3
Z9 3
U1 21
U2 83
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15223
EP 15245
DI 10.1007/s11042-022-13805-z
EA SEP 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000862219700010
DA 2024-07-18
ER

PT J
AU Turenne, N
AF Turenne, Nicolas
TI Net activism and whistleblowing on YouTube: a text mining analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media; Text mining; Net activism; Computational social science;
   Natural language processing; Machine learning
ID SOCIAL MEDIA; CONSTRUCTION; TWITTER; VIDEOS; HEALTH
AB Social media is more and more dominant in everyday life for people around the world. YouTube content is a resource that may be useful, in social computational science, for understanding key questions about society. Using this resource, we performed web scraping to create a dataset of 644,575 video transcriptions concerning net activism and whistleblowing. We automatically performed linguistic feature extraction to capture a representation of each video using its title, description and transcription (downloaded metadata). The next step was to clean the dataset using automatic clustering with linguistic representation to identify unmatched videos and noisy keywords. Using these keywords to exclude videos, we finally obtained a dataset that was reduced by 95%, i.e., it contained 35,730 video transcriptions. Then, we again automatically clustered the videos using a lexical representation and split the dataset into subsets, leading to hundreds of clusters that we interpreted manually to identify a hierarchy of topics of interest concerning whistleblowing. We used the dataset to learn a lexical representation for a specific topic and to detect unknown whistleblowing videos for this topic; the accuracy of this detection is 57.4%. We also used the dataset to identify interesting context linguistic markers around the names of whistleblowers. From a given list of names, we automatically extracted all 5-g word sequences from the dataset and identified interesting markers in the left and right contexts for each name by manual interpretation. The results of our study are the following: a dataset (raw and cleaned collections) concerning whistleblowing, a hierarchy of topics about whistleblowing, the automatic prediction of whistleblowing and the semi-automatic semantic analysis of markers around whistleblower names. This text mining analysis can be exploited for digital sociology and e-democracy studies.
C1 [Turenne, Nicolas] Guangdong Univ Foreign Studies GDUFS, Guangzhou, Peoples R China.
C3 Guangdong University of Foreign Studies
RP Turenne, N (corresponding author), Guangdong Univ Foreign Studies GDUFS, Guangzhou, Peoples R China.
EM nturenne@gdufs.edu.cn
OI turenne, nicolas/0000-0003-1229-5590
FU CNRS (French National Institute of Scientific Research) [UPEM-PEPS-2015]
FX The CNRS (French National Institute of Scientific Research) provided a
   PEPS (exploratory project) grant entitled EXIA (information extraction
   and applications) (grant number UPEM-PEPS-2015).
CR Aal Konstantin., 2019, INFORM TECHNOLOGY PE, P383, DOI DOI 10.1007/978-3-658-25652-4_18
   Agarwal S, 2015, LECT NOTES COMPUT SC, V8999, P133, DOI 10.1007/978-3-319-16313-0_10
   Agarwal Swati., 2014, P 25 ACM C HYPERTEXT, P294
   Aggarwal N, 2014, ANN CONF PRIV SECUR, P84, DOI 10.1109/PST.2014.6890927
   Ahmed-Rengers M, 2019, NSPW'19: PROCEEDINGS OF THE NEW SECURITY PARADIGMS WORKSHOP, P68, DOI 10.1145/3368860.3368866
   ALGUR SP, 2016, INT J COMPUTER SCI E, V4, P6
   Andre V, 2014, ISLAM CHRIST-MUSLIM, V25, P335, DOI 10.1080/09596410.2014.900948
   Askanius Tina, 2011, International Journal of Electronic Governance, V4, P69, DOI 10.1504/IJEG.2011.041708
   Askanius T., 2012, MEDIATION PROTEST MO
   Baratz M, 2009, TWITTER YOUTUBE NEW
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boltanski Luc., 1991, JUSTIFICATION
   Bosch T., 2012, Slate
   Bourigault D, 1999, NINTH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS, P15
   Brbic M., 2012, 2012 35th International Convention on Information and Communication Technology, Electronics and Microelectronics, P1775
   Chateauraynaud Francis Didier Torny., 1999, Les sombres precurseurs: une sociologie pragmatique de l'alerte et du risque
   Chowdury R, 2013, 8 INT C DIGITAL INFO
   Conway M, 2008, LECT NOTES COMPUT SC, V5376, P108, DOI 10.1007/978-3-540-89900-6_13
   Domingos P, 1999, DATA MIN KNOWL DISC, V3, P409, DOI 10.1023/A:1009868929893
   Dubisar AM, 2015, RHETOR REV, V34, P56, DOI 10.1080/07350198.2015.976305
   Effing R, 2011, LECT NOTES COMPUT SC, V6847, P25, DOI 10.1007/978-3-642-23333-3_3
   Eltahawy Mona., 2010, Washington Post
   Fernando, 2009, COMMUN WORLD
   Garimella K, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16), P33
   Githens-Mazer J., 2010, The Guardian
   Hall W, 2018, COMPUTER, V51, P18, DOI 10.1109/MC.2018.1151005
   Halpern D, 2013, COMPUT HUM BEHAV, V29, P1159, DOI 10.1016/j.chb.2012.10.008
   Jang M, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2069, DOI 10.1145/2983323.2983911
   Kavada Anastasia., 2012, MEDIEKULTUR J MEDIA, V52, P28, DOI DOI 10.7146/MEDIEKULTUR.V28I52.5486
   Khan ML, 2017, COMPUT HUM BEHAV, V66, P236, DOI 10.1016/j.chb.2016.09.024
   Klausen Jytte., 2012, Perspectives on Terrorism, V6, P36
   Konapure R. C., 2021, Journal of Physics: Conference Series, V1854, DOI 10.1088/1742-6596/1854/1/012025
   Konstantinidis S, 2013, METHOD INFORM MED, V52, P168, DOI 10.3414/ME12-02-0005
   Laine M.S. Stanley., 2011, Proceedings of the 2011 44th Hawaii International Conference on System Sciences, P1, DOI [DOI 10.1109/HICSS.2011.472, 10.1109/HICSS.2011.472]
   Lebart L., 1998, EXPLORING TEXTUAL DA, DOI [10.1007/978-94-017-1525-6, DOI 10.1007/978-94-017-1525-6]
   Liao H, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P368, DOI 10.1109/ASRU.2013.6707758
   Liikkanen, 2013, ABS13125547 CORR
   Liu JT, 2017, LECT NOTES ELECTR EN, V424, P451, DOI 10.1007/978-981-10-4154-9_52
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Magdy Walid, 2015, P INT AAAI C WEB SOC, V9, P638
   Mahmood S, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY, P574, DOI 10.1109/THS.2012.6459912
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Marwick AE, 2007, RHETORICS INTERNET D
   Mekaru SR, 2014, REV SCI TECH OIE, V33, P629, DOI 10.20506/rst.33.2.2306
   Mosemghvdlishvili L, 2013, NEW MEDIA SOC, V15, P482, DOI 10.1177/1461444812457326
   Puente SN, 2015, EUR J WOMENS STUD, V22, P319, DOI 10.1177/1350506814567002
   O'Callaghan D., 2012, ARXIV12013783
   Oh S, 2015, J ASSOC INF SCI TECH, V66, P2045, DOI 10.1002/asi.23320
   Poell T, 2012, JOURNALISM, V13, P695, DOI 10.1177/1464884911431533
   Ramos-Munoz JJ, 2014, IEEE WIREL COMMUN, V21, P18, DOI 10.1109/MWC.2014.6757893
   Riloff E, 1996, ARTIF INTELL, V85, P101, DOI 10.1016/0004-3702(95)00123-9
   Rodriguez-Fuentes L, 2014, 9 INT C LANGUAGE RES
   Sandoval-Almazan R, 2013, P ANN HICSS, P1704, DOI 10.1109/HICSS.2013.161
   Trottier D., 2015, Social Media, Politics and the State. Protests, Revolutions, Riots, Crime and Policing in the Age of Facebook
   Uldam J, 2013, INT J COMMUN-US, V7, P1185
   Ungerleider Neal, 2011, MASSIVE EGYPTIAN PRO
   Ushkin SG, 2014, SOTSIOL ISSLED+, P127
   Vergani M, 2015, ASIAN STUD REV, V39, P1, DOI 10.1080/10357823.2014.976171
   Vergani M, 2011, J CONTEMP CHINA, V20, P205, DOI 10.1080/10670564.2011.541628
NR 59
TC 1
Z9 1
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9201
EP 9221
DI 10.1007/s11042-022-13777-0
EA SEP 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000863188000001
PM 36193288
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Zhang, HL
   Du, QF
   Qi, QY
   Zhang, J
   Wang, FX
   Gao, M
AF Zhang, Huanlong
   Du, Qifan
   Qi, Qiye
   Zhang, Jie
   Wang, Fengxian
   Gao, Miao
TI A recursive attention-enhanced bidirectional feature pyramid network for
   small object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Small object detection; A-BiFPN; The recursive structure
AB Single Shot MultiBox Detector (SSD) method shows outstanding performance by using multiscale feature maps in object detection task. However, the SSD method exhibits low accuracy in small object detection. In this paper, A Recursive Attention-Enhanced Bidirectional Feature Pyramid Network (RA-BiFPN) is proposed. Firstly, we designed the attention-enhanced bidirectional feature pyramid network (A-BiFPN) to improve the detection accuracy of the small object. The A-BiFPN is composed of bidirectional feature pyramid network (BiFPN) and the coordinate attention. Among them, the BiFPN employs top-down and bottom-up paths to aggregate features at different scales so that features at all scales contain rich semantic and detailed information. These features help coordinate attention that embeds positional information into channel attention so that the network can easily focus on the channels and locations related to the object in the feature map. Secondly, in order to enhance the ability of the A-BiFPN to characterize small targets, we adopted the recursive structure to feed back the output feature of the A-BiFPN into the backbone network. In this way, the recursive structure goes through the bottom-up backbone repeatedly to enrich the representation power of the A-BiFPN. The experimental results show that the detection accuracy of our method in PASCAL VOC, NWPU VHR-10 , KITTI and RSOD dataset is improved by 2.65%, 7.98% ,7.02% and 5.63% respectively compared to the original SSD.
C1 [Zhang, Huanlong; Du, Qifan; Qi, Qiye; Zhang, Jie; Wang, Fengxian] Zhengzhou Univ Light Ind, Coll Elect & Informat Engn, Dongfeng Rd, Zhengzhou 450002, Henan, Peoples R China.
   [Gao, Miao] China Tobacco Henan Ind CO LTD, Zhengzhou, Henan, Peoples R China.
C3 Zhengzhou University of Light Industry; China National Tobacco
   Corporation
RP Zhang, HL (corresponding author), Zhengzhou Univ Light Ind, Coll Elect & Informat Engn, Dongfeng Rd, Zhengzhou 450002, Henan, Peoples R China.
EM zhl_lit@163.com; 2807134091@qq.com; 319195921@qq.com;
   2018007@zzuli.edu.cn; 2019031@zzuli.edu.cn; tomcat0@163.com
FU National Natural Science Foundation of China [61873246, 62072416,
   62006213, 62102373]; Program for Science & Technology Innovation Talents
   in Universities of Henan Province [21HASTIT028]; Natural Science
   Foundation of Henan [202300410495]; Key Scientific Research Projects of
   Colleges and Universities in Henan Province [21A120010]
FX This work is supported by the National Natural Science Foundation of
   China under Grant (61873246, 62072416, 62006213, 62102373), Program for
   Science & Technology Innovation Talents in Universities of Henan
   Province (21HASTIT028), Natural Science Foundation of Henan
   (202300410495), Key Scientific Research Projects of Colleges and
   Universities in Henan Province (21A120010).
CR Benenson R, 2015, LECT NOTES COMPUT SC, V8926, P613, DOI 10.1007/978-3-319-16181-5_47
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Cao CS, 2015, IEEE I CONF COMP VIS, P2956, DOI 10.1109/ICCV.2015.338
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Choi HT, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082842
   Feng D., 2020, ARXIV
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guo GD, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102805
   Guo W, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010131
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hou QB, 2020, PROC CVPR IEEE, P4002, DOI 10.1109/CVPR42600.2020.00406
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hwang YJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20133630
   Jiang D, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091536
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar K, 2021, MULTIMED TOOLS APPL, V80, P11079, DOI 10.1007/s11042-020-10157-4
   Kumar K, 2019, J VIS COMMUN IMAGE R, V58, P345, DOI 10.1016/j.jvcir.2018.12.009
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P26635, DOI 10.1007/s11042-018-5882-z
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P7383, DOI 10.1007/s11042-017-4642-9
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kumar K, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P119, DOI 10.1109/SITIS.2016.27
   Li C, 2021, IEEE J BIOMED HEALTH, V25, P1429, DOI 10.1109/JBHI.2020.3037031
   Li K, 2018, IEEE T GEOSCI REMOTE, V56, P2337, DOI 10.1109/TGRS.2017.2778300
   Li YY, 2020, IEEE ACCESS, V8, P63121, DOI 10.1109/ACCESS.2020.2984310
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mao JY, 2017, PROC CVPR IEEE, P6034, DOI 10.1109/CVPR.2017.639
   Pan HD, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115987
   Parkhi OM, 2015, Proceedings of the British Machine Vision Conference, DOI DOI 10.5244/C.29.41
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Solanki Akshay, 2020, Soft Computing: Theories and Applications. Proceedings of SoCTA 2018. Advances in Intelligent Systems and Computing (AISC 1053), P905, DOI 10.1007/978-981-15-0751-9_83
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Uçar A, 2017, SIMUL-T SOC MOD SIM, V93, P759, DOI 10.1177/0037549717709932
   Wang L, 2017, LECT NOTES COMPUT SC, V10132, P576, DOI 10.1007/978-3-319-51811-4_47
   Wang YB, 2022, CCS CHEM, V4, P2959, DOI 10.31635/ccschem.022.202101706
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiong SZ, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13101925
   Yin QJ, 2021, SIGNAL PROCESS-IMAGE, V98, DOI 10.1016/j.image.2021.116402
   Yin RH, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20226530
   Zaidi S. S. A., 2021, arXiv
   Zhai SP, 2020, IEEE ACCESS, V8, P24344, DOI 10.1109/ACCESS.2020.2971026
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhou P, 2018, PROC CVPR IEEE, P528, DOI 10.1109/CVPR.2018.00062
   Zhou TF, 2022, IEEE T IMAGE PROCESS, V31, P799, DOI 10.1109/TIP.2021.3132834
   Zhou TF, 2022, IEEE T PATTERN ANAL, V44, P2827, DOI 10.1109/TPAMI.2021.3049156
   Zhou TF, 2020, AAAI CONF ARTIF INTE, V34, P13066
   Zhou X., 2019, arXiv
NR 55
TC 5
Z9 5
U1 30
U2 128
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13999
EP 14018
DI 10.1007/s11042-022-13951-4
EA SEP 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000859866500002
DA 2024-07-18
ER

PT J
AU Mukherje, D
   Anand, A
AF Mukherje, Dhritiman
   Anand, Aman
TI On edge deep learning implementation: approach to achieve 5G
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 5G; Fog computing; Edge computing; Deep learning
AB Through 5G networks, mobile edge computing (MEC) brings the power of cloud computing, storage, and analysis closer to the end user. Innovative inventions in the domain of multimedia and others such as connected cars, large-scale IoT, video streaming, and industry robotics are made possible by improved speeds and reduced delays. On the other hand, in mobile edge computing, machine learning (ML) is leveraged to predict demand changes based on cultural events, natural disasters, or daily travel patterns, and it prepares the network by automatically scaling up network resources as required. Mobile edge computing and ML together allow seamless network management automation to decrease operating costs and boost user experience. In this paper, we discuss the state of art with in mobile edge computing with deep learning to server low-latency, real time application by providing application specific resource allocation. The experimental results have indicated significant amount of improvement in respond time while executing in low latency.
C1 [Mukherje, Dhritiman; Anand, Aman] Amity Univ, Dept Comp Sci & Engn, 24PGS N, Kolkata 700135, W Bengal, India.
RP Mukherje, D (corresponding author), Amity Univ, Dept Comp Sci & Engn, 24PGS N, Kolkata 700135, W Bengal, India.
EM dmukherjee3@kol.amity.edu; amananand972@gmail.com
OI Mukherjee, Dhritiman/0000-0003-0419-6437
CR [Anonymous], CONVERTING TRAINED M
   Butler B., 2017, Network World
   Chen YK, 2013, IEEE J EM SEL TOP C, V3, P1, DOI 10.1109/JETCAS.2013.2244771
   Habibzadeh M, 2018, PROC SPIE, V10696, DOI 10.1117/12.2311282
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Iorga Michaela, 2018, NIST Special Publication, DOI [10.6028/NIST.SP.500-325, DOI 10.6028/NIST.SP.500-325]
   Li WJ, 2020, IEEE INTERNET THINGS, V7, P5882, DOI 10.1109/JIOT.2019.2949352
   Mahdavinejad MS, 2018, DIGIT COMMUN NETW, V4, P161, DOI 10.1016/j.dcan.2017.10.002
   Manyika J, 2015, INTERNET THINGS MAPP, V6
   McClellan M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10144735
   Quattoni A, 2008, PROC CVPR IEEE, P2300
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rothe R, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P252, DOI 10.1109/ICCVW.2015.41
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh S, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719844159
   Singh S, 2016, J NETW COMPUT APPL, V75, P200, DOI 10.1016/j.jnca.2016.09.002
   Wichrowska O, 2017, PR MACH LEARN RES, V70
   Wood, 2019, 5G OPTIMIZATION MOBI
   Yosinski J, 2014, ARXIV
NR 19
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12229
EP 12243
DI 10.1007/s11042-022-13712-3
EA SEP 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000859342300003
DA 2024-07-18
ER

PT J
AU Ragendhu, SP
   Thomas, T
AF Ragendhu, S. P.
   Thomas, Tony
TI Cancelable biometric scheme based on dynamic salting of random patches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Template security; Cancelable biometrics; Patch level distortion;
   Voronoi patches
ID TEMPLATE PROTECTION; FINGERPRINT; IMAGE; RECOGNITION; PRIVACY; FACE
AB The idea of cancelable biometrics was proposed to ensure the privacy and security of user's original biometric data, which is collected for recognition by storing only transformed template in the database after applying irreversible operations. State of the art cancelable schemes use either biometric salting or non-linear transformations for generating protected template. However, biometric salting techniques suffer from the threat of unauthorized access to user specific key; whereas non-linear transformation based schemes have the inherent issue of performance degradation due to information loss. In order to overcome these limitations of the existing techniques, this work proposes a patch level distortion based cancelable scheme which can be applied for multiple modalities. In the proposed method, biometric images are divided into Voronoi patches and log Gabor feature vector of each patch is distorted by combining it with a function of difference vectors of other patches. Proposed scheme is able to eliminate the need of security critical user specific key and many to one transformations. Irreversibility is assured as the function of difference vectors of patches used as noise in distortion process is random enough and unpredictable for an intruder. Cancelability and non-linkability can be ensured by changing the number and location of seed points. Superior performance compared to state of the art techniques is obtained in distorted domain when experiments were conducted on CASIA face database.
C1 [Ragendhu, S. P.] Cochin Univ Sci & Technol, Indian Inst Informat Technol & Management Kerala, Res Ctr, Kochi, Kerala, India.
   [Thomas, Tony] Kerala Univ Digital Sci Innovat & Technol, Kochi, Kerala, India.
C3 Kerala University of Digital Sciences, Innovation & Technology (Digital
   University Kerala); Cochin University Science & Technology; Kerala
   University of Digital Sciences, Innovation & Technology (Digital
   University Kerala)
RP Ragendhu, SP (corresponding author), Cochin Univ Sci & Technol, Indian Inst Informat Technol & Management Kerala, Res Ctr, Kochi, Kerala, India.
EM ragendhu.res15@iiitmk.ac.in; tony.thomas@duk.ac.in
OI Thomas, Tony/0000-0002-9323-6607; S P, Ragendhu/0000-0002-7207-8718
CR Ali SS, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104004
   [Anonymous], PETERKOVESI WHAT ARE
   [Anonymous], MATLAB and Octave functions for computer vision and image processing
   [Anonymous], CASIA FACEV5 CASIA F
   Barrero MG., 2016, THESIS U AUTONOMA MA
   Bhattacharyya S., 2014, International Journal of Advanced Research in Computer Science and Software Engineering, V4, P209
   Canuto AMP, 2013, EXPERT SYST APPL, V40, P1971, DOI 10.1016/j.eswa.2012.10.002
   Du Q, 1999, SIAM REV, V41, P637, DOI 10.1137/S0036144599352836
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Fischer S., 2009, CONSTRUCT LOG GABOR
   Gomez-Barrero M, 2013, IB C PATT REC, P358
   Gomez-Barrero M, 2018, IEEE T INF FOREN SEC, V13, P1406, DOI 10.1109/TIFS.2017.2788000
   Gomez-Barrero M, 2014, PATTERN RECOGN LETT, V36, P243, DOI 10.1016/j.patrec.2013.04.029
   Grother P, 2003, LECT NOTES COMPUT SC, V2688, P937
   Gupta K, 2021, VISUAL COMPUT, V37, P1401, DOI 10.1007/s00371-020-01873-x
   Hämmerle-Uhl J, 2009, LECT NOTES COMPUT SC, V5735, P135, DOI 10.1007/978-3-642-04474-8_11
   Hilhorst HJ, 2008, EUR PHYS J B, V64, P437, DOI 10.1140/epjb/e2008-00003-7
   Jain Anil K., 2005, 2005 13th European Signal Processing Conference, P1
   Jain AK, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/579416
   Jin ATB, 2004, PATTERN RECOGN, V37, P2245, DOI 10.1016/j.patcog.2004.04.011
   Jin Teoh AndrewBeng., 2006, 9th International Conference on Control, Automation, Robotics and Vision, (ICARCV'06), P1, DOI DOI 10.1109/ICARCV.2006.345404
   Kaur H, 2020, MULTIMED TOOLS APPL, V79, P20729, DOI 10.1007/s11042-020-08734-8
   Kaur H, 2019, PATTERN RECOGN LETT, V126, P31, DOI 10.1016/j.patrec.2018.02.016
   Kaur H, 2019, IEEE T INF FOREN SEC, V14, P709, DOI 10.1109/TIFS.2018.2855669
   Kaur H, 2017, MULTIMED TOOLS APPL, V76, P4673, DOI 10.1007/s11042-016-3652-3
   Kirchgasser S, 2020, IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2020)
   Kumar N, 2020, APPL ECON, V52, P1031, DOI 10.1080/00036846.2019.1646887
   Kumar N, 2020, MULTIMED TOOLS APPL, V79, P2363, DOI 10.1007/s11042-019-08228-2
   Maiorana E, 2011, ANN IEEE SYST CONF, P495
   Meng QX, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10110618
   Nagar A, 2008, INT C PATT RECOG, P822
   Nandakumar K., 2008, Ph.D. thesis
   Nandakumar K, 2008, 2008 IEEE SECOND INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS), P129
   Nayar GR, 2021, J INF SECUR APPL, V62, DOI 10.1016/j.jisa.2021.102991
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P54, DOI 10.1109/MSP.2015.2434151
   Ragendhu SP, 2021, LECT NOTE NETW SYST, V187, P27, DOI 10.1007/978-981-33-6173-7_3
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Rathgeb C., 2012, Trends and Developments in Biometrics, P173
   Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3
   Rathgeb C, 2009, LECT NOTES COMPUT SC, V5558, P940, DOI 10.1007/978-3-642-01793-3_95
   Ross Arun, 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P1221
   Ross A, 2007, IEEE T PATTERN ANAL, V29, P544, DOI 10.1109/TPAMI.2007.1018
   Rozsa Andras, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P100, DOI 10.1109/CVPRW.2015.7301325
   Sandhya M, 2017, SIGNAL PROC SEC TEC, P323, DOI 10.1007/978-3-319-47301-7_14
   Sandhya M, 2016, IET BIOMETRICS, V5, P131, DOI 10.1049/iet-bmt.2015.0034
   Sarkar A, 2020, MULTIMED TOOLS APPL, V79, P27721, DOI 10.1007/s11042-020-09197-7
   Snelick R., 2003, Proceedings of the 5th International Conference on Multimodal Interfaces, P68, DOI DOI 10.1145/958432.958447
   Stokkenes M., 2016, 2016 6 INT C IM PROC, P1, DOI DOI 10.1109/IPTA.2016.7820972
   Teoh ABJ, 2007, IEEE T SYST MAN CY B, V37, P1096, DOI 10.1109/TSMCB.2007.903538
   Walia GS, 2020, IEEE T INF FOREN SEC, V15, P1945, DOI 10.1109/TIFS.2019.2954779
   Wang W, 2008, PATTERN RECOGN LETT, V29, P301, DOI 10.1016/j.patrec.2007.10.004
   Wang XY, 2012, COMPUT STAND INTER, V34, P31, DOI 10.1016/j.csi.2011.05.001
   Wang XY, 2022, IEEE T CIRCUITS-I, V69, P1291, DOI 10.1109/TCSI.2021.3133318
   Wang XY, 2014, PATTERN RECOGN, V47, P3293, DOI 10.1016/j.patcog.2014.04.020
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Wang Y, 2010, IEEE T SYST MAN CY B, V40, P1280, DOI 10.1109/TSMCB.2009.2037131
   Xian YJ, 2022, IEEE T CIRC SYST VID, V32, P4028, DOI 10.1109/TCSVT.2021.3108767
   Yang GH, 2010, INT CONF SMART GRID, P1, DOI 10.1109/SMARTGRID.2010.5622001
   Yang WC, 2018, PATTERN RECOGN, V78, P242, DOI 10.1016/j.patcog.2018.01.026
   Yao P, 2006, INT C PATT RECOG, P461
   Zuo JY, 2008, INT C PATT RECOG, P2925
NR 62
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14337
EP 14366
DI 10.1007/s11042-022-13764-5
EA SEP 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000854695000006
DA 2024-07-18
ER

PT J
AU Juang, LH
AF Juang, Li-Hong
TI Humanoid robot runs up-down stairs using zero-moment with supporting
   polygons control
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE NAO robot; Joint freedom; Gait planning; Stairs; Walking patterns;
   Inverted pendulum
AB The humanoid robots have similar human feet, but due to the limitations of joint freedom, they are difficult to walk on the special ground like humans, so planning an effective walking method applies on these special grounds becomes of critical importance. As a typical example of a special ground, this paper proposes a dynamic planning method for the gait planning problem of the humanoid robot NAO climbing and down stairs. Firstly, the NAO robot is modeled by the kinematics; then it can be understood the humanoid robot itself after the gait characteristics and human walking patterns according to the characteristics of the stairs, and the geometric constraints of the robot's walking gaits on the stairs are analyzed; further then the robot's lateral gait is planned through a first-order linear inverted pendulum model, and the variable length model is used. The inverted pendulum model is used to plan the forward gait of the robot, and then the start and stop gaits of the robot are planned respectively and meanwhile we proposed the zero-moment point stability judgment and the supporting polygons control to determine whether the robot is in a stable state. In the three-dimensional stairs, the visual system of the NAO robot was used to perceive its surrounding environment, and then the image processing technology was used to identify the position of the stairs. Finally, the correctness of the gait planning is verified by the Webots Platform for NAO simulation and its real operation. The experimental results show that the gait planning method used in this paper is highly feasible.
C1 [Juang, Li-Hong] Lunghwa Univ Sci & Technol, Dept Elect Engn, 300,Sec 1,Wanshou Rd, Taoyuan 333326, Taiwan.
RP Juang, LH (corresponding author), Lunghwa Univ Sci & Technol, Dept Elect Engn, 300,Sec 1,Wanshou Rd, Taoyuan 333326, Taiwan.
EM lipuu@qq.com
CR Aldebaran Robotics, NAO SOFTW DOC EB OL
   Alexiadis DS, 2013, IEEE T MULTIMEDIA, V15, P339, DOI 10.1109/TMM.2012.2229264
   Alsharif MH, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010088
   Armesto L., 2009, P IEEE C EM TECHN FA, P1, DOI DOI 10.1109/ETFA.2009.5347051
   Bharati P, 2019, DEEP LEARNING TECHNI, P657
   Bi ZM, 2007, ROBOT CIM-INT MANUF, V23, P553, DOI 10.1016/j.rcim.2006.02.014
   Chen G., 2014, IFAC P, V47, P2165, DOI DOI 10.3182/20140824-6-ZA-1003.02341
   Deng C, 2018, 2018 3 INT C ADV ROB, P18
   Hirai K, 1998, IEEE INT CONF ROBOT, P1321, DOI 10.1109/ROBOT.1998.677288
   Kalita Dhruba Jyoti, 2020, Social Networking and Computational Intelligence. Proceedings of SCI-2018. Lecture Notes in Networks and Systems (LNNS 100), P243, DOI 10.1007/978-981-15-2071-6_20
   Lin H., 2012, MANUF AUTOM, V34, P80
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Martínez S, 2007, IEEE CONTR SYST MAG, V27, P75, DOI 10.1109/MCS.2007.384124
   Morrison JG, 2016, IEEE CONTR SYST MAG, V36, P75, DOI 10.1109/MCS.2015.2512032
   Nasrinahar Amir, 2018, Journal on Vehicle Routing Algorithms, V1, P89, DOI 10.1007/s41604-018-0007-4
   Olszewska JI, 2016, INT C INN TECHN APPL, P237
   Olszewska JI, 2020, J INTELL ROBOT SYST, V98, P119, DOI 10.1007/s10846-019-01107-w
   ORIOLO G, 1995, IEEE INT CONF ROBOT, P2900, DOI 10.1109/ROBOT.1995.525695
   Powell MJ, 2012, IEEE INT CONF ROBOT, P543, DOI 10.1109/ICRA.2012.6225344
   Rincon JA, 2016, LECT NOTES ARTIF INT, V9662, P286, DOI 10.1007/978-3-319-39324-7_32
   Ryberg A, 2006, 2006 IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS, VOLS 1-7, P2798, DOI 10.1109/ISIE.2006.296058
   Sari MP, 2019, 2019 INT ELECT S IES, P27
   Wang J. X., 2016, 2016 Tsinghua University-IET Electrical Engineering Academic Forum, P12
   Xu C., 2017, Transactions of the Chinese Society of Agricultural Engineering, V33, P49
   Zhang L, 2018, J INTERNET TECHNOL, V19, P1879, DOI 10.3966/160792642018111906023
   Zhang Q, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P1069, DOI 10.1109/ICMA.2013.6618063
NR 26
TC 0
Z9 0
U1 4
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13275
EP 13305
DI 10.1007/s11042-022-13723-0
EA SEP 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000852138100004
DA 2024-07-18
ER

PT J
AU Bulkan, U
   Dagiuklas, T
   Iqbal, M
AF Bulkan, Utku
   Dagiuklas, Tasos
   Iqbal, Muddesar
TI Supereye: smart advertisement insertion for online video streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online video streaming; Advertisement insertion; Object detection;
   Object recognition; Behavior detection; Quality of experience;
   Artificial intelligence
ID CHALLENGES; EXPERIENCE; QUALITY
AB Without any doubt, state of art advertisement insertion mechanisms along with the requested video content has emerged to be the most crucial part of online video delivery ecosystems. There are several widely deployed methods which have been used since the first days of video streaming such as tag word matching between video content versus advertisement content along with manual matching-based approaches. Conventional but non-scalable and context independent methods cannot fulfil the requirements of an online video platform when there are several millions of user generated videos along with premium content and advertisement of varying production quality. In such environment, a content aware advertisement insertion framework is required based on object recognition, machine learning and artificial intelligence to understand the context of the video and match appropriate advertisement and stitch the advertisement at the most convenient moment of the target video content. In this paper, SuperEye; a deployment ready, content aware, scalable, distributed advertisement insertion framework for a 5G oriented online video platform is designed and developed. The foundational object analyzing mechanism of the underlying system examine each particular context that is part of the wider video and advertisement catalogue using object recognition while generating a time-lapse map of all objects that are detected through the video. Based upon this information, the framework matches the most significant object that is detected for a particular interval and associates the advertisement with similar properties. Additionally, this novel technique does not require any watch history or personalized data related to the user, but primarily interested in only the current requested content information. Therefore, this framework can work along with any type of recommendation engine or rank based association algorithm. The proposed framework is independent of the user information and regarding the subjective user results collected, successful video to ad match ratios of SuperEye significantly exceed the current implementations of YouTube, Vimeo and DailyMotion.
C1 [Bulkan, Utku; Dagiuklas, Tasos; Iqbal, Muddesar] London South Bank Univ, Sch Engn, London, England.
C3 London South Bank University
RP Bulkan, U (corresponding author), London South Bank Univ, Sch Engn, London, England.
EM bulkanu@lsbu.ac.uk; tdagiuldas@lsbu.ac.uk; m.iqbal@lsbu.ac.uk
RI Iqbal, Muddesar/JJC-7510-2023
OI Iqbal, Muddesar/0000-0002-8438-6726; Bulkan, Utku/0000-0003-1177-0660
CR Ahad MA, 2019, ADV INTELL SYST, V758, P653, DOI 10.1007/978-981-13-0514-6_62
   Apatean, 2016, ACTA TECHNICA NAPOCE, V57
   Bouraqia K, 2020, IEEE ACCESS, V8, P13341, DOI 10.1109/ACCESS.2020.2965099
   Bryan RN, 2020, ACAD RADIOL, V27, P76, DOI 10.1016/j.acra.2019.09.011
   Bulkan U, 2020, IEEE T BROADCAST
   Çambay VY, 2019, 2019 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND DATA PROCESSING (IDAP 2019), DOI 10.1109/idap.2019.8875870
   Checkley G, 2020, patent, Patent No. [US10387431B2, 10387431]
   Dharavath R, 2020, LECT NOTE DATA ENG, V37, P3, DOI 10.1007/978-981-15-0978-0_1
   Duan, 2019, IGTA IMAGE GRAPHICS, P300
   Dutta Sayan, 2020, Emerging Technology in Modelling and Graphics. Proceedings of IEM Graph 2018. Advances in Intelligent Systems and Computing (AISC 937), P721, DOI 10.1007/978-981-13-7403-6_63
   Eldering CA, 2020, patent, Patent No. [US6704930B1, 6704930]
   Fiedler M, 2010, IEEE NETWORK, V24, P36, DOI 10.1109/MNET.2010.5430142
   Foulsham Mark, 2019, Financial Compliance Issues, Concerns and Future Directions, P115
   Fu J, 2020, PATTERN RECOGN, V101, DOI 10.1016/j.patcog.2019.107152
   Gong, 2019, IEEE 18 EUROPEAN CON
   Guo SQ, 2020, LECT NOTES ELECTR EN, V621, P269, DOI 10.1007/978-981-15-1465-4_28
   Harijanto B, 2020, IOP C SERIES MAT SCI
   Hayakawa, 2020, DEEP LEARNING NEURAL
   Hossfeld Tobias, 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P494, DOI 10.1109/ISM.2011.87
   Isaak J, 2018, IEEE COMPUTER
   ITU-T Telecommunication Standardization Sector OF ITU P.912, 2016, SER P TERM SUBJ OBJ
   Ketyko I., 2010, P 3 WORKSH MOB VID D
   Khan UA, 2020, IEEE ACCESS
   Kustikova V, 2019, LECT NOTES COMPUT SC, V11832, P11, DOI 10.1007/978-3-030-37334-4_2
   Leon V, 2020, MOCAST MODERN CIRCUI
   Zhaoping L, 2020, NEURON, V105, P413, DOI 10.1016/j.neuron.2020.01.014
   Licciardello M, 2020, LECT NOTES COMPUT SC, V12048, P298, DOI 10.1007/978-3-030-44081-7_18
   Liss B, 2020, patent, Patent No. [10514823B1, 10514823]
   Marthews A, 2019, EC STUDIES BROOKINGS
   Mohamed K.S., 2020, Neuromorphic Computing and Beyond: Parallel, Approximation, near Memory, and Quantum
   Osterle H, 2020, SPRINGER NATURE LIFE
   Pathan M, 2008, LECT NOTES ELECTR EN, V9, P3
   Qian XL, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12010143
   Susmitha AVV, 2020, SPRINGER INTERNET TH, P137
   Urban T, 2019, LECT NOTES COMPUT SC, V11737, P61, DOI 10.1007/978-3-030-31500-9_5
   Wamser F., 2012, 24 INT TELETRAFFIC C, V24, P288
   Wang X, 2020, MACHINE LEARNING BAS
   Wen LY, 2020, COMPUT VIS IMAGE UND, V193, DOI 10.1016/j.cviu.2020.102907
   Wu X, 2020, ROBOT CIM-INT MANUF, V61, DOI 10.1016/j.rcim.2019.101856
NR 39
TC 1
Z9 1
U1 5
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9361
EP 9379
DI 10.1007/s11042-022-13469-9
EA SEP 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000849487500003
DA 2024-07-18
ER

PT J
AU Omranpour, H
   Ledari, ZM
   Taheri, M
AF Omranpour, Hesam
   Ledari, Zeynab Mohammadi
   Taheri, Masoumeh
TI Presentation of encryption method for RGB images based on an
   evolutionary algorithm using chaos functions and hash tables
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Evolutionary algorithm; DNA encoding; Logistic mapping
   function; Hash function
ID HYBRID GENETIC ALGORITHM; SCHEME
AB In this study, a new method based on chaos functions, and the evolutionary algorithm is proposed for image encryption. Chaos functions are used in this method because of the random occurrence and the sensitivity to the initial values to make the encryption method as secure as possible. Also to enhance the entropy of the image, an evolutionary algorithm is used to select the best layout and mapping. For this purpose, the image is decomposed first. The image components are then disrupted using the evolutionary algorithm, coding rules, and logistic mapping whose initial value is obtained from a hash function. The results show that the proposed method has good speed due to the use of simple operators such as Addition and XOR. Also, since a 256-bit hash function is used in this case and a high search space is generated for the evolutionary algorithm, the algorithm shows good resistance to the types of attacks. Moreover, due to the uncertainty of the decryption algorithm and the generation of a single-use code for each execution of the algorithm, the proposed encryption algorithm offers high security and resistance against differential attacks and plaintext attacks.
C1 [Omranpour, Hesam; Ledari, Zeynab Mohammadi; Taheri, Masoumeh] Babol Noshirvani Univ Technol, Dept Elect & Comp Engn, Babol 4714871167, Iran.
C3 Babol Noshirvani University of Technology
RP Omranpour, H (corresponding author), Babol Noshirvani Univ Technol, Dept Elect & Comp Engn, Babol 4714871167, Iran.
EM H.omranpour@nit.ac.ir
OI Mohammadi Ledari, Zeynab/0000-0003-1012-3162
CR Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Akkasaligar PT, 2020, INF SECUR J, V29, P91, DOI 10.1080/19393555.2020.1718248
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Chang WL, 2011, J SUPERCOMPUT, V56, P129, DOI 10.1007/s11227-009-0347-9
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Enayatifar R, 2013, OPT LASER ENG, V51, P1066, DOI 10.1016/j.optlaseng.2013.03.010
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Gupta A, 2020, J AMB INTEL HUM COMP, V11, P1309, DOI 10.1007/s12652-019-01493-x
   Huo DM, 2019, PHYS LETT A, V383, P915, DOI 10.1016/j.physleta.2018.12.011
   Laptyeva TV, 2011, EPL-EUROPHYS LETT, V95, DOI 10.1209/0295-5075/95/50007
   Li SJ, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P708
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Mahmud M, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105818
   Mendel F, 2006, LECT NOTES COMPUT SC, V4047, P126
   Nematzadeh H, 2020, OPTIK, V202, DOI 10.1016/j.ijleo.2019.163505
   Patro KAK, 2019, J INF SECUR APPL, V46, P23, DOI 10.1016/j.jisa.2019.02.006
   Shuhong Jiao, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P2166, DOI 10.1109/ICOSP.2008.4697576
   Sneha PS, 2020, J AMB INTEL HUM COMP, V11, P1289, DOI 10.1007/s12652-019-01385-0
   Wang JC, 2020, FUTURE GENER COMP SY, V110, P57, DOI 10.1016/j.future.2020.04.002
   Wang XY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-66486-9
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, IETE TECH REV, V36, P39, DOI 10.1080/02564602.2017.1393352
   Xiao GZ, 2006, CHINESE SCI BULL, V51, P1413, DOI 10.1007/s11434-006-2012-5
   Yadollahi M, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102505
   Zefreh EZ, 2020, MULTIMED TOOLS APPL, V79, P24993, DOI 10.1007/s11042-020-09111-1
NR 26
TC 0
Z9 0
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9343
EP 9360
DI 10.1007/s11042-022-13734-x
EA SEP 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000847985700002
DA 2024-07-18
ER

PT J
AU Khan, S
   Alam, M
AF Khan, Samiya
   Alam, Mansaf
TI Preprocessing framework for scholarly big data management
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning applications; Preprocessing pipeline; Scholarly big data;
   Scholarly data applications; Spark ML
AB Big data technologies have found applications in disparate domains. One of the largest sources of textual big data is scientific documents and papers. Scholarly big data has been used in numerous ways to develop innovative applications such as collaborator discovery, expert finding and research management systems. With the evolution of machine and deep learning techniques, the efficacy of such applications has risen manifold. However, the biggest challenge in the development of deep learning models for scholarly applications in cloud-based environment is the under-utilization of resources because of the excessive time required for textual preprocessing. This paper presents a preprocessing pipeline that uses Spark for data ingestion and Spark ML for performing preprocessing tasks. The proposed approach is evaluated with the help of a case study, which uses LSTM-based text summarization to generate title or summaries from abstracts of scholarly articles. Results indicate a substantial reduction in ingestion, preprocessing and cumulative time for the proposed approach, which shall manifest reduction in development time and costs as well.
C1 [Khan, Samiya; Alam, Mansaf] Jamia Millia Islamia, New Delhi, India.
RP Khan, S (corresponding author), Jamia Millia Islamia, New Delhi, India.
EM samiyashaukat@yahoo.com; malam2@jmi.ac.in
RI Alam, Prof. Mansaf/A-3734-2016; Khan, Samiya/AAA-7806-2019
OI Alam, Prof. Mansaf/0000-0002-6293-7005; Khan, Samiya/0000-0003-0837-5125
CR Al-Zaidy RA, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2551, DOI 10.1145/3308558.3313642
   Armbrust M, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1383, DOI 10.1145/2723372.2742797
   Beel J, 2016, INT J DIGIT LIBRARIE, V17, P305, DOI 10.1007/s00799-015-0156-0
   Chen DanielY., 2017, Pandas for everyone: Python data analysis
   Chen JQ, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.4261
   Duari S, 2019, INFORM SCIENCES, V477, P100, DOI 10.1016/j.ins.2018.10.034
   Eisenstein J, 2019, ADAPT COMPUT MACH LE, P1
   Fang CJ, 2017, EXPERT SYST APPL, V72, P189, DOI 10.1016/j.eswa.2016.12.021
   Feng XY, 2019, J MED INTERNET RES, V21, DOI 10.2196/12957
   Florescu C, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1105, DOI 10.18653/v1/P17-1102
   Frank MR, 2019, NAT MACH INTELL, V1, P79, DOI 10.1038/s42256-019-0024-5
   Gandomi A, 2015, INT J INFORM MANAGE, V35, P137, DOI 10.1016/j.ijinfomgt.2014.10.007
   Ganegedara, 2019, KERAS LAYER IMPLEMEN
   He K., IEEE I CONF COMP VIS
   Jinseok Kim, 2014, 2014 IEEE International Conference on Big Data (Big Data), P1, DOI 10.1109/BigData.2014.7004345
   Khan Samiya, 2016, 2016 2nd International Conference on Contemporary Computing and Informatics (IC3I). Proceedings, P29, DOI 10.1109/IC3I.2016.7917930
   Khan S, 2017, INFORM PROCESS MANAG, V53, P923, DOI 10.1016/j.ipm.2017.03.006
   Liu JY, 2018, IEEE ACCESS, V6, P19205, DOI 10.1109/ACCESS.2018.2815030
   Liu P, 2016, ARXIV160505101
   Maake BM, 2019, RES DATA ACCESS MANA, P119, DOI DOI 10.4018/978-1-5225-8437-7.CH006
   Meng R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P582, DOI 10.18653/v1/P17-1054
   Meng XR, 2016, J MACH LEARN RES, V17
   Mishra, 2019, PYSPARK SQL RECIPES
   Nallapati R., 2016, P 20 SIGNLL C COMP N, P280, DOI DOI 10.18653/V1/K16-1028
   Ororbia AG, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P597, DOI 10.1145/2740908.2741736
   Pai, 2019, HOW TO BUILD OWN TEX
   Pérez J, 2006, LECT NOTES COMPUT SC, V4273, P30
   Siddiqi S., 2015, International Journal of Computer Applications, V109, P18, DOI [https://doi.org/10.5120/19161-0607, DOI 10.5120/19161-0607, 10.5120/19161-0607]
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Tang Duyu, 2015, P 2015 C EMPIRICAL M, P1422
   Tanijiri J, 2016, P 2016 ACM S DOC ENG, P135
   Tiwana A, 2004, IEEE SOFTWARE, V21, P51, DOI 10.1109/MS.2004.1331302
   Tkaczyk D, 2015, INT J DOC ANAL RECOG, V18, P317, DOI 10.1007/s10032-015-0249-8
   Tuarob S, 2013, PROC INT CONF DOC, P738, DOI 10.1109/ICDAR.2013.151
   Wang DH, 2018, KNOWL-BASED SYST, V157, P1, DOI 10.1016/j.knosys.2018.05.001
   West Jevin D., 2016, IEEE Transactions on Big Data, V2, P113, DOI 10.1109/TBDATA.2016.2541167
   Wu ZH, 2014, ACM-IEEE J CONF DIG, P117, DOI 10.1109/JCDL.2014.6970157
   Yang Z., 2016, P 2016 C N AM CHAPT, P1480, DOI [DOI 10.18653/V1/N16-1174, 10.18653/v1/n16-1174]
   Yu DJ, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187164
   Zaharia Matei, 2010, 2 USENIX WORKSHOP HO
   Zhang QC, 2018, INFORM FUSION, V42, P146, DOI 10.1016/j.inffus.2017.10.006
   Zhou, 2016, INT C COMPUT LINGUIS, P2912
NR 42
TC 0
Z9 0
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39719
EP 39743
DI 10.1007/s11042-022-13513-8
EA AUG 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000840056800001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Sattarpour, S
AF Sattarpour, Shiva
TI Robust optimal image watermarking using graph-based and discrete wavelet
   transforms, and whale optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Whale optimization algorithm (WOA); Wavelet domain;
   Graph-based transform (GBT); Singular value decomposition (SVD);
   Discrete wavelet transform (DWT)
ID SCHEME
AB As digital content can be copied easily, Copyright infringement has become a concern nowadays. Providing a solution to prevent the abuse of such content is necessary. One of the most common methods to solve this problem is watermarking. In this method, a logo belongs to the owner of the media is embedded in the media. So, the owner can prove the originality or ownership of the media content. Images are one of the most important digital media. Therefore, in this study, a method for digital image watermarking is proposed. The proposed method is based on Graph-based Transform (GBT), Singular Value Decomposition (SVD), and Discrete Wavelet Transform (DWT) which uses a Whale Optimization Algorithm (WOA) to find the best values for the embedding parameters. The cover image is first transformed using the DWT and GBT. Then the watermark logo is embedded onto the singular values of the cover image. The defined objective function for the optimization is based on the parameters PSNR and NC, in the presence of different attacks. Experimental results clearly show a high robustness of the proposed method compared to other similar methods.
C1 [Sattarpour, Shiva] Islamic Azad Univ, Comp Fac, Dezfoul Branch, Dezfoul, Khuzestan, Iran.
C3 Islamic Azad University
RP Sattarpour, S (corresponding author), Islamic Azad Univ, Comp Fac, Dezfoul Branch, Dezfoul, Khuzestan, Iran.
EM sattarpour@iaud.ac.ir
OI Sattarpour, Shiva/0000-0003-2714-121X
CR Ali M, 2018, INT J SYST ASSUR ENG, V9, P602, DOI 10.1007/s13198-014-0288-4
   Ali M, 2015, INFORM SCIENCES, V301, P44, DOI 10.1016/j.ins.2014.12.042
   [Anonymous], DATASET STANDARD 512
   Ariatmanto D, 2020, MULTIMED TOOLS APPL, V79, P12041, DOI 10.1007/s11042-019-08338-x
   Cox I. J., 2002, Digital Watermarking
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Farzaneh M, 2020, 2020 10TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P137, DOI 10.1109/IST50524.2020.9345876
   Farzaneh M, 2018, 2018 9TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P410, DOI 10.1109/ISTEL.2018.8661027
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   Hemalatha T, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN RECENT TECHNOLOGIES IN COMMUNICATION AND COMPUTING (ARTCOM 2009), P360, DOI 10.1109/ARTCom.2009.195
   Kamble S., 2012, INT J INF TECHNOLO K, V5, P101
   Lang J, 2014, OPT LASER ENG, V53, P112, DOI 10.1016/j.optlaseng.2013.08.021
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Patel R., 2015, INT J COMPUTER APPL, V110, P10
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Sahraee M, 2013, SIGNAL IMAGE VIDEO P, V7, P799, DOI 10.1007/s11760-011-0269-x
   Saxena S, 2019, AIP CONF PROC, V2061, DOI 10.1063/1.5086656
   Seitz J., 2005, DIGITAL WATERMARKING
   Sheth RK, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATION AND AUTOMATION (ICACCA 2016), P59
   Singh S, 2018, STUD BIG DATA, V33, P467, DOI 10.1007/978-3-319-63639-9_20
   Sivaprakash A, 2019, CURR MED IMAGING, V15, P802, DOI 10.2174/1573405615666190408115158
   SONG L, 2012, PROCEDIA ENG, V29, P1602, DOI DOI 10.1016/J.PROENG.2012.01.180
   Wei Q, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/8869096
   Zhang LN, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107421
   Zheng P., 2020, MULTIMED TOOLS APPL, V79, P1, DOI [10.1007/s11042-019-7523-6, DOI 10.1007/S11042-019-7523-6]
   ZHOU X, 2018, SYMMETRY-BASEL, V10
NR 27
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6667
EP 6685
DI 10.1007/s11042-022-13639-9
EA AUG 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000837590100010
DA 2024-07-18
ER

PT J
AU Sharma, DK
   Sinha, U
   Gupta, A
   Khari, M
AF Sharma, Deepak Kumar
   Sinha, Utsha
   Gupta, Aditi
   Khari, Manju
TI Modified minimum spanning tree based vertical fragmentation, allocation
   and replication approach in distributed multimedia databases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Allocation; CRUD; Distributed multimedia database management system
   (DMDBMS); Distributed multimedia database system (DMDBS); Fragmentation;
   Minimum spanning tree; Replication; Vertical fragmentation
AB Distributed Multimedia Database Systems have become an indispensable part of modern world organizations that increased demand for reliable, scalable, and expeditiously accessible information processing systems, data has evolved in multiple media forms having found many application areas across industries that calls for optimal storage, processing and retrieval methodologies in a distributed fashion. The solution mainly relies on the optimization of database design structure in which data fragmentation, allocation and replication play eminent roles. The presented scheme employs a method of vertical fragmentation using enhanced CRUD matrix and Fibonacci heap to efficiently fragment the database into clusters. The fragments are then allocated and replicated at different network nodes depending on the manipulates and reads operation at respective sites, taking into consideration the cost factor. With the use of Fibonacci heap, the amortized complexity of the proposed algorithm has come down to O(E + V log V ) in contrast to the previous works of enhanced Prims algorithm in vertical fragmentation which offered a complexity of O(E log V ) where E denotes the number of edges and V, the number of vertices. This approach generates all the fragments at once and without the use of any predetermined parameters and does not involve the use of a query log. The proposed approach also considers communication and site storage costs for optimal allocation and replication thus minimizing the overall system costs.
C1 [Sharma, Deepak Kumar] Indira Gandhi Delhi Tech Univ Women, Dept Informat Technol, Delhi, India.
   [Sinha, Utsha; Gupta, Aditi] Netaji Subhas Univ Technol, Dept Informat Technol, New Delhi, India.
   [Khari, Manju] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi 110067, India.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW); Netaji
   Subhas University of Technology; Jawaharlal Nehru University, New Delhi
RP Sharma, DK (corresponding author), Indira Gandhi Delhi Tech Univ Women, Dept Informat Technol, Delhi, India.
EM dk.sharma1982@yahoo.com; utsha.sinha1510@gnail.com;
   dikshadha68@gmail.com; manjukhari@yahoo.co.in
RI Khari, Manju/B-6040-2017
OI Sharma, Deepak Kumar/0000-0001-6117-3464
CR Abuelyaman ES, 2008, INT J COMPUT SCI NET, V8, P310
   bcanotes, US
   Ceri Stefano., 1982, P 1982 ACM SIGMOD IN, P128, DOI DOI 10.1145/582353.582376
   Ezechiel Katembo, 2019, J THEOR APPL INF TEC, V96
   Gertz M., 2004, DISTRIBUTED XML REPO
   Getahun F, 2007, P 1 ACM WORKSHOP MAN
   NAVATHE S, 1984, ACM T DATABASE SYST, V9, P680, DOI 10.1145/1994.2209
   Navathe S. B., 1995, Journal of Computer and Software Engineering, V3, P395
   NAVATHE SB, 1989, SIGMOD REC, V18, P440, DOI 10.1145/66926.66966
   Ng V., 2003, P 2003 ACM S APPL CO, P544, DOI 10.1145/952532.952639
   Pinnecke Marcus, 2020, Datenbank-Spektrum, V20, P43, DOI 10.1007/s13222-019-00330-x
   Raouf AEA, IEEE 7 ICICIS 15
   Raouf AEA, 2016, INTERNATIONAL CONFERENCE ON INFORMATICS AND SYSTEMS (INFOS 2016), P146, DOI 10.1145/2908446.2908480
   Rodiguez-Mazahua L., 2014, LECT NOTES COMPUTER, DOI [10.1007/978-3-319-13650-9, DOI 10.1007/978-3-319-13650-9]
   Singh N., 2014, INTELLIGENT COMPUTIN, P101, DOI DOI 10.1007/978-81-322-1665-0_10
   Song SK, 2000, COMPUT J, V43, P81, DOI 10.1093/comjnl/43.1.81
   Sub C, 2001, GRUNDLAGEN DATENBANK, P98
   Tutorials, ABOUT US
   ul Zuhra S, 2019, IEEE T VEH TECHNOL, V68, P12239, DOI 10.1109/TVT.2019.2945987
   Vogt M, 2018, IEEE INT CONF BIG DA, P3364, DOI 10.1109/BigData.2018.8622353
   Wiese L, 2014, J CLOUD COMPUT-ADV S, V3, DOI 10.1186/s13677-014-0018-0
NR 21
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37101
EP 37118
DI 10.1007/s11042-022-13541-4
EA AUG 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000836525000007
DA 2024-07-18
ER

PT J
AU Hasan, N
   Chaudhary, K
   Alam, M
AF Hasan, Nabeela
   Chaudhary, Kiran
   Alam, Mansaf
TI A novel blockchain federated safety-as-a-service scheme for industrial
   IoT using machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; IoT; Security of information; Machine learning; Blockchain
   technology; Cloud storage; Industry 4; 0
ID RESEARCH ISSUES; TECHNOLOGY; INTERNET; OPTIMIZATION; NETWORKS; THINGS
AB Blockchains are costly in terms of computing and involve high overhead bandwidth and delays that are not suitable for smart appliances. Enhancing the precision of output, quality, and delivery of data is particularly critical in Machine Learning. The combination of Machine Learning and Blockchain technologies may create accurate results. The Industrial IoT (IIoT), has quickly been established and is getting huge attention in educational areas and manufacturing, but IoT solitude danger and privacy exposures are developing by lack of important security technology. Because blockchain technique's regionalization and information revelation were planned as a decentralized and distributed method to give assurance security and motivate the development of the IoT and IIoT. The Blockchain Driven Cyber-Physical system (BDCPS) is supported by IoT and cloud services. BDCPS will confirm the statement utilizing the Intelligent Agreements functionality and the trust-less peer-to-peer centrally controlled database showcase by a tiny-scale real-life Blockchain to the IoT system. In this study, a private Blockchain can be run on a separate board system and paralleled to a microcontroller with Smart devices. The suggested system uses blockchain technology to resolve issues such as lightweight, evaporation, warehousing transactions, and shipment time. The data flow of Blockchain is intended to demonstrate the application of machine learning to food traceability. Finally, to extend shelf life, a supply chain employs dependable and accurate data. This paper shows a relevant blockchain and machine learning research that identifies numerous key elements of combining the two technologies such as Blockchain and Machine Learning, including an overview, benefits, and applications.
C1 [Hasan, Nabeela; Alam, Mansaf] Jamia Millia Islamia, Dept Comp Sci, New Delhi, India.
   [Chaudhary, Kiran] Univ Delhi, Shivaji Coll, Dept Commerce, New Delhi, India.
C3 Jamia Millia Islamia; University of Delhi
RP Hasan, N (corresponding author), Jamia Millia Islamia, Dept Comp Sci, New Delhi, India.
EM nabeela1910394@st.jmi.ac.in; kchaudhary1@gmail.com; malam2@jmi.ac.in
RI Alam, Prof. Mansaf/A-3734-2016
OI Alam, Prof. Mansaf/0000-0002-6293-7005; Hasan,
   Nabeela/0000-0003-3081-9941; Chaudhary, Kiran/0000-0003-1109-8165
CR Abu Alsheikh M, 2014, IEEE COMMUN SURV TUT, V16, P1996, DOI 10.1109/COMST.2014.2320099
   Al-Jaroodi J, 2019, IEEE ACCESS, V7, P36500, DOI 10.1109/ACCESS.2019.2903554
   Ali MS, 2019, IEEE COMMUN SURV TUT, V21, P1676, DOI 10.1109/COMST.2018.2886932
   Bahga A., 2016, J Softw Eng Appl, V9, P533, DOI [DOI 10.4236/JSEA.2016.910036, 10.4236/jsea.2016.910036]
   Bahga A., 2014, Internet of Things: A Hands-On Approach
   Benattia A., 2008, P IEEE INT C APPL EL, P9
   Betarte G, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P779, DOI 10.1109/ICMLA.2018.00124
   Bkassiny M, 2013, IEEE COMMUN SURV TUT, V15, P1136, DOI 10.1109/SURV.2012.100412.00017
   Brody P, 2014, DEVICE DEMOCRACY SAV, V1, P15
   Cai XJ, 2021, IEEE T IND INFORM, V17, P7650, DOI 10.1109/TII.2021.3051607
   Casino F, 2019, TELEMAT INFORM, V36, P55, DOI 10.1016/j.tele.2018.11.006
   Chaudhary K, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00466-2
   Chen XW, 2020, IEEE ACCESS, V8, P71497, DOI 10.1109/ACCESS.2020.2984329
   Colombo A. W., 2014, The IMC-AESOP Approach, V22, P4, DOI [10.1007/978-3-319-05624-1, DOI 10.1007/978-3-319-05624-1, 10.1007/978-3-319-11620-4, DOI 10.1007/978-3-319-11620-4]
   Conti M, 2018, IEEE COMMUN SURV TUT, V20, P3416, DOI 10.1109/COMST.2018.2842460
   Feki MA, 2013, COMPUTER, V46, P24, DOI 10.1109/MC.2013.63
   Feng Tian, 2016, 2016 13th International Conference on Service Systems and Service Management (ICSSSM), P1, DOI 10.1109/ICSSSM.2016.7538424
   Jameel F, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12125161
   Khurshid Ahmed., 2013, P 10 USENIX C NETWOR, P15
   Konakovic-Lukovic M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201373
   Krit SD, 2017, 2017 INTERNATIONAL CONFERENCE ON ENGINEERING & MIS (ICEMIS)
   Kumari A, 2019, IEEE WIREL COMMUN, V26, P47, DOI 10.1109/MWC.2019.1800356
   Kuzmin Alexander, 2018, 2018 IEEE International Conference on Service Operations and Logistics, and Informatics (SOLI), P32, DOI 10.1109/SOLI.2018.8476785
   Latif S, 2021, J IND INF INTEGR, V21, DOI 10.1016/j.jii.2020.100190
   Lin QJ, 2019, IEEE ACCESS, V7, P20698, DOI 10.1109/ACCESS.2019.2897792
   Malik S, 2018, 2018 IEEE 17TH INTERNATIONAL SYMPOSIUM ON NETWORK COMPUTING AND APPLICATIONS (NCA)
   Mao Q, 2018, IEEE COMMUN SURV TUT, V20, P2595, DOI 10.1109/COMST.2018.2846401
   Marcos E, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00631
   Mazzei D, 2020, FUTURE GENER COMP SY, V105, P432, DOI 10.1016/j.future.2019.12.020
   Meng WZ, 2018, IEEE ACCESS, V6, P10179, DOI 10.1109/ACCESS.2018.2799854
   Mohammadi M, 2018, IEEE COMMUN SURV TUT, V20, P2923, DOI 10.1109/COMST.2018.2844341
   Mrugalska B, 2017, PROCEDIA ENGINEER, V182, P466, DOI 10.1016/j.proeng.2017.03.135
   Musumeci F, 2019, IEEE COMMUN SURV TUT, V21, P1383, DOI 10.1109/COMST.2018.2880039
   Nakamoto S., 2008, DECENT BUS REV, V21260, DOI https://bitcoin.org/bitcoin.pdf
   Namanya AP, 2018, 2018 IEEE 6TH INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD (FICLOUD 2018), P420, DOI 10.1109/FiCloud.2018.00067
   Pop C, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010162
   Porras P., 2012, Proceedings of the first workshop on Hot topics in software defined networks, ACM, P121, DOI DOI 10.1145/2342441.2342466
   Qin J, 2016, PROC CIRP, V52, P173, DOI 10.1016/j.procir.2016.08.005
   RAHOUTI M, 1989, APPL ENVIRON MICROB, V55, P2391, DOI 10.1128/AEM.55.9.2391-2398.1989
   Saini, TRUST BASED BLOCKCHA
   Salah K, 2019, IEEE ACCESS, V7, P73295, DOI 10.1109/ACCESS.2019.2918000
   Salah K, 2019, IEEE ACCESS, V7, P10127, DOI 10.1109/ACCESS.2018.2890507
   Salman T, 2019, IEEE COMMUN SURV TUT, V21, P858, DOI 10.1109/COMST.2018.2863956
   Shen M, 2020, IEEE J SEL AREA COMM, V38, P942, DOI 10.1109/JSAC.2020.2980916
   Siano P, 2019, IEEE SYST J, V13, P3454, DOI 10.1109/JSYST.2019.2903172
   Tanwar S, 2017, 2017 3 INT C ADV COM
   Tsolakis AC, 2018, 2018 INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA)
   Ucci D, 2019, COMPUT SECUR, V81, P123, DOI 10.1016/j.cose.2018.11.001
   Vora J, 2018, INT CONF COMP INFO, P177
   Welter F, 2017, ENTREP THEORY PRACT, V41, P311, DOI 10.1111/etap.12258
   Wu DZ, 2015, COMPUT AIDED DESIGN, V59, P1, DOI 10.1016/j.cad.2014.07.006
   Xie JF, 2019, IEEE COMMUN SURV TUT, V21, P2794, DOI 10.1109/COMST.2019.2899617
   Xie JF, 2019, IEEE COMMUN SURV TUT, V21, P393, DOI 10.1109/COMST.2018.2866942
   Xu X, 2012, ROBOT CIM-INT MANUF, V28, P75, DOI 10.1016/j.rcim.2011.07.002
   Zhang CH, 2017, ENRGY PROCED, V105, P2563, DOI 10.1016/j.egypro.2017.03.737
NR 55
TC 4
Z9 4
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36751
EP 36780
DI 10.1007/s11042-022-13503-w
EA AUG 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000836366300003
DA 2024-07-18
ER

PT J
AU Fahim, A
   Tan, QM
   Bhatti, UA
   Nizamani, MM
   Nawaz, SA
AF Fahim, Asmaa
   Tan, Qingmei
   Bhatti, Uzair Aslam
   Nizamani, Mir Muhammad
   Nawaz, Saqib Ali
TI The nexus between higher education and economic growth in Morocco: an
   empirical investigation using VaR model and VECM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Educational funds; Economic growth; Higher education; Sustainable
   development; VECM
AB Educational economics focuses on the relationship between economics and education, which is key to the development of modern society. Generally speaking, the greater an economy is developed, a higher level of education for its residents is produced, and more education is developed (significantly higher education). As an essential channel for cultivating national human resources, higher education has become a crucial avenue for a country to achieve sustainable development. The value measures the risk of investment at risk (VaR). The probability of a group of investments losing a certain amount during a given period (a day, a month, and a year) is estimated. This article investigates the relationship between Morocco's economic growth and higher education investments, developing VaR and vector error correction (VEC) models using Moroccan economic data from a time series spanning 2001 to 2018. There is a positive relationship between investment in higher education and economic growth in Morocco and a stable relationship between staffing and the economy's growth. However, it also shows that economic growth has played a limited role in promoting investments in higher education. This paper, therefore, provides some suggestions based on the guiding ideology and objectives of Morocco's education reform and development plan.
C1 [Fahim, Asmaa; Tan, Qingmei] Nanjing Univ Aeronaut & Astronaut, Coll Econ & Management, Nanjing 211106, Peoples R China.
   [Bhatti, Uzair Aslam] Nanjing Normal Univ, Sch Geog, Nanjing, Peoples R China.
   [Bhatti, Uzair Aslam; Nawaz, Saqib Ali] Hainan Univ, Coll Informat & Commun Engn, Haikou 570208, Hainan, Peoples R China.
   [Nizamani, Mir Muhammad] Hainan Univ, Coll Biol, Inst Trop Agr & Forestry, Haikou 570208, Hainan, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Nanjing Normal
   University; Hainan University; Hainan University
RP Fahim, A (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Econ & Management, Nanjing 211106, Peoples R China.
EM fahim.asmaa@nuaa.edu.cn; uzairaslambhatti@hotmail.com
RI Nizamani, Mir Muhammad/AAC-4663-2020
OI Nizamani, Mir Muhammad/0000-0002-8709-9212; Nawaz, Saqib
   Ali/0000-0002-3342-7874
CR Agasisti T, 2022, SOCIO-ECON PLAN SCI, V81, DOI 10.1016/j.seps.2020.100940
   Ashton D., 2005, Education and training for development in East Asia: The political economy of skill formation in newly industrialised economies
   Becker GS, 1967, HUMAN CAPITAL PERSON, P94
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Chattopadhyay S, 2023, MULTIMED TOOLS APPL, V82, P9693, DOI 10.1007/s11042-021-11839-3
   Chattopadhyay S, 2022, INT J INTELL SYST, V37, P3777, DOI 10.1002/int.22703
   Davidson J., 2000, ECONOMET THEOR
   Dey S, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104585
   Dima AM, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10061706
   Fahim A, 2021, IEEE ACCESS, V9, P76991, DOI 10.1109/ACCESS.2021.3082144
   Gylfason T., 2006, Economic liberalization and integration policy, P201
   Hanushek E., 2020, The economics of education
   Hanushek EA, 2013, ECON EDUC REV, V37, P204, DOI 10.1016/j.econedurev.2013.04.005
   Jednak S., 2015, Manag. - J. Theory Pract. Manag, V20, P01
   JOHANSEN S, 1991, ECONOMETRICA, V59, P1551, DOI 10.2307/2938278
   Johansen S., 1995, Likelihoodbased inference in cointegrated vector autoregressive models
   Khan AH, 2022, EXP TECHNIQUES, V46, P335, DOI 10.1007/s40799-021-00470-4
   Kundu R, 2021, COMPUT BIOL MED, V138, DOI 10.1016/j.compbiomed.2021.104895
   [Кузьминов Ярослав Kuzminov Yaroslav], 2019, [Форсайт, Forsait], V13, DOI 10.17323/2500-2597.2019.2.19.41
   Lelis M.T. C., 2018, EconomiA, V19, P38, DOI DOI 10.1016/J.ECON.2017.06.002
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Lu ZN, 2017, J CLEAN PROD, V166, P134, DOI 10.1016/j.jclepro.2017.08.010
   Maneejuk P, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13020520
   Marginson S, 2019, STUD HIGH EDUC, V44, P287, DOI 10.1080/03075079.2017.1359823
   Ouyang YF, 2018, ENERG ECON, V71, P238, DOI 10.1016/j.eneco.2018.02.015
   Schultz T.W., 1993, EDUC ECON, V1, P13, DOI [DOI 10.1080/09645299300000003, 10.1080/09645299300000003]
   Shuai S, 2020, J ENVIRON MANAGE, V261, DOI 10.1016/j.jenvman.2020.110227
   Sinakou E, 2019, ENVIRON DEV SUSTAIN, V21, P1, DOI 10.1007/s10668-017-0032-8
   Sira E., 2014, CER COMP EUROPEAN RE, P25
   Stoica O, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12031186
   Tsaurai K., 2020, Int. J. Energy Econ. Pol., V10, P26, DOI [10.32479/ijeep.8497, DOI 10.32479/IJEEP.8497]
   Vîlcu GE, 2011, APPL MATH LETT, V24, P777, DOI 10.1016/j.aml.2010.12.038
   [Wang Yajun 王雅俊], 2021, [Journal of Resources and Ecology, 资源与生态学报], V12, P68
   Wu N, 2021, TECHNOL FORECAST SOC, V162, DOI 10.1016/j.techfore.2020.120400
   Xu HY, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12062515
NR 39
TC 3
Z9 3
U1 4
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5709
EP 5723
DI 10.1007/s11042-022-13471-1
EA JUL 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000833514100001
DA 2024-07-18
ER

PT J
AU Choi, Y
   Park, H
AF Choi, Yoonsil
   Park, Hanhoon
TI Improving ESRGAN with an additional image quality loss
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Perceptual image super-resolution; Generative adversarial network;
   ESRGAN; Additional perceptual loss; PieAPP-based image quality
   assessment; Multiscale discriminator; ReLU activation
AB ESRGAN is a generative adversarial network that produces visually pleasing super-resolution (SR) images with high perceptual quality from low-resolution images. However, it frequently fails to recover local details, resulting in blurry or unnatural visual artifacts. To address this problem, we propose using an additional perceptual loss (computed using the pretrained PieAPP network) for training the generator, adding skip connections to the discriminator to use a combination of features with different scales, and replacing the Leaky ReLU activation functions in the discriminator with the ReLU ones. Through x4 SR experiments utilizing real and computer-generated image benchmark datasets, it is demonstrated that the proposed method can produce SR images with significantly higher perceptual quality than ESRGAN and other ESRGAN enhancements. Specifically, when compared to ESRGAN, the proposed method resulted in 5.95 higher DMOS values, 0.46 lower PI values, and 0.01 lower LPIPS values. The source code is accessible at https://github.com/cyun-404/PieESRGAN.
C1 [Choi, Yoonsil] Pukyong Natl Univ, Dept Comp Engn, Busan 48513, South Korea.
   [Park, Hanhoon] Pukyong Natl Univ, Dept Elect Engn, Busan 48513, South Korea.
C3 Pukyong National University; Pukyong National University
RP Park, H (corresponding author), Pukyong Natl Univ, Dept Elect Engn, Busan 48513, South Korea.
EM cys201203@pukyong.ac.kr; hanhoon.park@pknu.ac.kr
OI Park, Hanhoon/0000-0002-6968-4565
FU Ministry of Trade, Industry, and Energy (MOTIE), Korea, under the
   "Regional Innovation Cluster Development Program [P0004797]; Korea
   Evaluation Institute of Industrial Technology (KEIT) [P0004797] Funding
   Source: Korea Institute of Science & Technology Information (KISTI),
   National Science & Technology Information Service (NTIS)
FX This research was financially supported by the Ministry of Trade,
   Industry, and Energy (MOTIE), Korea, under the "Regional Innovation
   Cluster Development Program (R&D, P0004797)" supervised by the Korea
   Institute for Advancement of Technology (KIAT).
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Blau Y, 2019, LECT NOTES COMPUT SC, V11133, P334, DOI 10.1007/978-3-030-11021-5_21
   Cheon M, 2019, LECT NOTES COMPUT SC, V11133, P51, DOI 10.1007/978-3-030-11021-5_4
   Chudasama V, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.2.021003
   Chudasama V, 2020, MACH VISION APPL, V32, DOI 10.1007/s00138-020-01135-9
   design, LEVEL DESIGN
   github, NCARRAZESRGANPLUS
   github, PYTORCH IMPLEMENTION
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   google, About us
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hosu V, 2020, IEEE T IMAGE PROCESS, V29, P4041, DOI 10.1109/TIP.2020.2967829
   Hui Z, 2021, INFORM SCIENCES, V546, P769, DOI 10.1016/j.ins.2020.08.114
   Jo Y, 2020, IEEE COMPUT SOC CONF, P1705, DOI 10.1109/CVPRW50498.2020.00220
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Prashnani E, 2018, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2018.00194
   Rakotonirina NC, 2020, INT CONF ACOUST SPEE, P3637, DOI 10.1109/ICASSP40776.2020.9054071
   Roziere B, 2020, ARXIV
   Saha Sajib, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P245
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Shang TZ, 2020, IEEE COMPUT SOC CONF, P1778, DOI 10.1109/CVPRW50498.2020.00228
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song J, 2022, ARXIV
   Tai YW, 2010, PROC CVPR IEEE, P2400, DOI 10.1109/CVPR.2010.5539933
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Wu Q, 2020, MULTIMED TOOLS APPL, V79, P21265, DOI 10.1007/s11042-020-08878-7
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhu XN, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/5217429
NR 36
TC 1
Z9 1
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 3123
EP 3137
AR s11042-022-13452-4
DI 10.1007/s11042-022-13452-4
EA JUL 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000832844000002
DA 2024-07-18
ER

PT J
AU Bellver, M
   Ventura, C
   Silberer, C
   Kazakos, I
   Torres, J
   Giro-i-Nieto, X
AF Bellver, Miriam
   Ventura, Carles
   Silberer, Carina
   Kazakos, Ioannis
   Torres, Jordi
   Giro-i-Nieto, Xavier
TI A closer look at referring expressions for video object segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Referring expressions; Video object segmentation; Vision and language
AB The task of Language-guided Video Object Segmentation (LVOS) aims at generating binary masks for an object referred by a linguistic expression. When this expression unambiguously describes an object in the scene, it is named referring expression (RE). Our work argues that existing benchmarks used for LVOS are mainly composed of trivial cases, in which referents can be identified with simple phrases. Our analysis relies on a new categorization of the referring expressions in the DAVIS-2017 and Actor-Action datasets into trivial and non-trivial REs, where the non-trivial REs are further annotated with seven RE semantic categories. We leverage these data to analyze the performance of RefVOS, a novel neural network that obtains competitive results for the task of language-guided image segmentation and state of the art results for LVOS. Our study indicates that the major challenges for the task are related to understanding motion and static actions.
C1 [Bellver, Miriam; Torres, Jordi] Barcelona Supercomp Ctr BSC, Barcelona, Spain.
   [Ventura, Carles] Univ Oberta Catalunya UOC, Barcelona, Spain.
   [Silberer, Carina] Univ Stuttgart, Inst NLP, Stuttgart, Germany.
   [Kazakos, Ioannis] Natl Tech Univ Athens, Athens, Greece.
   [Giro-i-Nieto, Xavier] Univ Politecn Catalunya UPC, Barcelona, Catalonia, Spain.
   [Giro-i-Nieto, Xavier] CSIC UPC, Inst Robot & Informat Ind, Barcelona, Catalonia, Spain.
C3 Universitat Politecnica de Catalunya; Barcelona Supercomputer Center
   (BSC-CNS); UOC Universitat Oberta de Catalunya; University of Stuttgart;
   National Technical University of Athens; Universitat Politecnica de
   Catalunya; Universitat Politecnica de Catalunya; Consejo Superior de
   Investigaciones Cientificas (CSIC); CSIC - Institut de Robotica i
   Informatica Industrial (IRII)
RP Ventura, C (corresponding author), Univ Oberta Catalunya UOC, Barcelona, Spain.
EM miriam.bellver@bsc.es; cventuraroy@uoc.edu;
   carina.silberer@ims.uni-stuttgart.de; edem010@mail.ntua.gr;
   jordi.torres@bsc.es; xavier.giro@upc.edu
FU MCIN/AEI [PID2019-107255GB-C22, PID2020-117142GB-I00]; Government of
   Catalonia [2017-SGR-1414]; Spanish Ministry of Science, Innovation and
   Universities [RTI2018-095232-B-C22]
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This work was partially supported by the projects
   PID2019-107255GB-C22 and PID2020-117142GB-I00 funded by
   MCIN/AEI/10.13039/501100011033 Spanish Ministry of Science, and the
   grant 2017-SGR-1414 of the Government of Catalonia. This work was also
   partially supported by the project RTI2018-095232-B-C22 funded by the
   Spanish Ministry of Science, Innovation and Universities.
CR Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen DJ, 2019, IEEE I CONF COMP VIS, P7453, DOI 10.1109/ICCV.2019.00755
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen X, 2018, ARXIV
   Chen Yi-Wen, 2019, ARXIV191004748
   Cirik V, 2018, USING SYNTAX GROUND
   DAVIES M, 1982, BIOMETRICS, V38, P1047, DOI 10.2307/2529886
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Feng Q, 2020, IEEE WINT CONF APPL, P689, DOI [10.1109/WACV45572.2020.9093425, 10.1109/wacv45572.2020.9093425]
   Gavrilyuk K, 2018, PROC CVPR IEEE, P5958, DOI 10.1109/CVPR.2018.00624
   Hamp B., 1997, AUTOMATIC INFORM EXT
   Han Bohyung, 2020, ECCV
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hervas R, 2010, P 48 ANN M ASS COMP, P49
   Hu RH, 2016, LECT NOTES COMPUT SC, V9905, P108, DOI 10.1007/978-3-319-46448-0_7
   Hu ZW, 2020, PROC CVPR IEEE, P4423, DOI 10.1109/CVPR42600.2020.00448
   Huang S., 2020, 2020 IEEE CVF C COMP, P10485, DOI [DOI 10.1109/CVPR42600.2020.01050, 10.1109/CVPR42600.2020.01050]
   Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215
   Kalkan S., 2019, P BRIT MACHINE VISIO, P272
   Kazemzadeh S., 2014, EMNLP, P787, DOI DOI 10.3115/V1/D14-1086
   Khoreva A, 2019, LECT NOTES COMPUT SC, V11364, P123, DOI 10.1007/978-3-030-20870-7_8
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Levelt W., 1989, Speaking-from intention to articulation
   Li ZY, 2017, PROC CVPR IEEE, P7350, DOI 10.1109/CVPR.2017.777
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu CX, 2017, IEEE I CONF COMP VIS, P1280, DOI 10.1109/ICCV.2017.143
   Liu DQ, 2019, IEEE I CONF COMP VIS, P4672, DOI 10.1109/ICCV.2019.00477
   Liu JY, 2017, IEEE I CONF COMP VIS, P4866, DOI 10.1109/ICCV.2017.520
   Liu RT, 2019, PROC CVPR IEEE, P4180, DOI 10.1109/CVPR.2019.00431
   Mao JH, 2016, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2016.9
   Nagaraja VK, 2016, LECT NOTES COMPUT SC, V9908, P792, DOI 10.1007/978-3-319-46493-0_48
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Pont-Tuset J., 2017, ARXIV
   Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3
   Reiter Ehud., 1992, Proceedings of the 14th conference on Computational linguistics-Volume 1, V1, P232
   Rubio-Fernández P, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00153
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang H, 2019, IEEE I CONF COMP VIS, P3938, DOI 10.1109/ICCV.2019.00404
   Wang P, 2019, PROC CVPR IEEE, P1960, DOI 10.1109/CVPR.2019.00206
   Xie E., 2021, ADV NEURAL INFORM PR, V34, P12077, DOI [10.48550/arXiv.2105.15203, DOI 10.48550/ARXIV.2105.15203]
   Xu CL, 2015, PROC CVPR IEEE, P2264, DOI 10.1109/CVPR.2015.7298839
   Xu N, 2018, LECT NOTES COMPUT SC, V11209, P603, DOI 10.1007/978-3-030-01228-1_36
   Yang SB, 2019, IEEE I CONF COMP VIS, P4643, DOI 10.1109/ICCV.2019.00474
   Ye LW, 2019, PROC CVPR IEEE, P10494, DOI 10.1109/CVPR.2019.01075
   Yi K., 2019, INT C LEARN REPR
   Yu LC, 2018, PROC CVPR IEEE, P1307, DOI 10.1109/CVPR.2018.00142
   Yu LC, 2017, PROC CVPR IEEE, P3521, DOI 10.1109/CVPR.2017.375
   Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5
   Zhang C, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1258, DOI 10.1145/3343031.3351063
   Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11
NR 52
TC 3
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4419
EP 4438
DI 10.1007/s11042-022-13413-x
EA JUL 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000830967300005
OA hybrid
DA 2024-07-18
ER

PT J
AU Dangi, D
   Dixit, DK
   Bhagat, A
AF Dangi, Dharmendra
   Dixit, Dheeraj K.
   Bhagat, Amit
TI Sentiment analysis of COVID-19 social media data through machine
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Logistic regression; Random forest; Multinomial Naive Bayes; Support
   vector machine; Decision tree; COVID-19
ID ALGORITHM; TWITTER; USAGE
AB Pandemics are a severe threat to lives in the universe and our universe encounters several pandemics till now. COVID-19 is one of them, which is a viral infectious disease that increased morbidity and mortality worldwide. This has a negative impact on countries' economies, as well as social and political concerns throughout the world. The growths of social media have witnessed much pandemic-related news and are shared by many groups of people. This social media news was also helpful to analyze the effects of the pandemic clearly. Twitter is one of the social media networks where people shared COVID-19 related news in a wider range. Meanwhile, several approaches have been proposed to analyze the COVID-19 related sentimental analysis. To enhance the accuracy of sentimental analysis, we have proposed a novel approach known as Sentimental Analysis of Twitter social media Data (SATD). Our proposed method is based on five different machine learning models such as Logistic Regression, Random Forest Classifier, Multinomial NB Classifier, Support Vector Machine, and Decision Tree Classifier. These five classifiers possess various advantages and hence the proposed approach effectively classifies the tweets from the Twint. Experimental analyses are made and these classifier models are used to calculate different values such as precision, recall, f1-score, and support. Moreover, the results are also represented as a confusion matrix, accuracy, precision, and receiver operating characteristic (ROC) graphs. From the experimental and discussion section, it is obtained that the accuracy of our proposed classifier model is high.
C1 [Dangi, Dharmendra; Dixit, Dheeraj K.; Bhagat, Amit] Maulana Azad Natl Inst Technol, Dept Math Bioinformat & Comp Applicat, Bhopal, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal
RP Dangi, D (corresponding author), Maulana Azad Natl Inst Technol, Dept Math Bioinformat & Comp Applicat, Bhopal, India.
EM dangi28dharmendra06@gmail.com
RI Bhagat, Amit/P-1870-2016; DANGI, DHARMENDRA/HNR-0714-2023; Dixit,
   Dheeraj/GRJ-9811-2022
OI Bhagat, Amit/0000-0003-3704-2469; DANGI, DHARMENDRA/0000-0003-1531-024X;
   Dixit, Dheeraj/0000-0002-2628-8116
CR Alam MMG, 2019, KNOWL INF SYST, V60, P971, DOI 10.1007/s10115-018-1263-1
   Alam MMG, 2019, SOFT COMPUT, V23, P1079, DOI 10.1007/s00500-018-3124-y
   [Anonymous], 2020, CHINA CDC WEEKLY, V2, P113, DOI DOI 10.3760/CMA.J.ISSN.0254-6450.2020.02.003
   Ansari GJ, 2018, FUTURE GENER COMP SY, V87, P328, DOI 10.1016/j.future.2018.04.074
   Basha Syed Muzamil, 2019, International Journal of Business Innovation and Research, V20, P375
   Basha Syed Muzamil, 2018, International Journal of Metadata, Semantics and Ontologies, V13, P33
   Basha SM., 2018, Recent Patents on Computer Science, V11, P62, DOI [10.2174/2213275911666180531112306, DOI 10.2174/2213275911666180531112306]
   Basha SM, 2019, MULTIMED TOOLS APPL, V78, P29463, DOI 10.1007/s11042-018-7093-z
   Basha SM, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY (ICIT 2017), P96, DOI 10.1145/3176653.3176665
   Dubosson F, 2016, INT CON ADV INFO NET, P987, DOI 10.1109/AINA.2016.160
   Fu KW, 2016, AM J INFECT CONTROL, V44, P1700, DOI 10.1016/j.ajic.2016.04.253
   Gal-Oz N, 2019, COMPUT SECUR, V82, P296, DOI 10.1016/j.cose.2019.01.005
   Gui Xinning, 2017, AMIA Annu Symp Proc, V2017, P820
   Haseena KS., 2014, INT J INNOV SCI ENG, V6, P430
   Hassan BA, 2021, COMPLEX INTELL SYST, V7, P2383, DOI 10.1007/s40747-021-00422-w
   Hassan BA, 2021, NEURAL COMPUT APPL, V33, P7011, DOI 10.1007/s00521-020-05474-6
   Hassan BA, 2020, DATA BRIEF, V28, DOI 10.1016/j.dib.2019.105046
   Hoek L. van der, 2004, Nature Medicine, V10, P368, DOI 10.1038/nm1024
   Ibrahim MNM, 2015, 2015 IEEE CONFERENCE ON E-LEARNING, E-MANAGEMENT AND E-SERVICES (IC3E), P187, DOI 10.1109/IC3e.2015.7403510
   Ji X, 2015, SOC NETW ANAL MIN, V5, DOI 10.1007/s13278-015-0253-5
   Kavitha D, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4132
   Kucukyilmaz T, 2017, INFORM PROCESS MANAG, V53, P834, DOI 10.1016/j.ipm.2017.02.006
   Kumar SJN, 2020, CMES-COMP MODEL ENG, V125, P671, DOI 10.32604/cmes.2020.09361
   LAPUERTA P, 1995, COMPUT BIOMED RES, V28, P38, DOI 10.1006/cbmr.1995.1004
   Li LF, 2020, IEEE T COMPUT SOC SY, V7, P556, DOI 10.1109/TCSS.2020.2980007
   Li SJ, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17062032
   Nair MR, 2017, PROCEDIA COMPUT SCI, V115, P350, DOI 10.1016/j.procs.2017.09.089
   Nanda C, 2018, PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P1069, DOI 10.1109/ICCSP.2018.8524223
   Narendra B., 2016, International Journal of Intelligent Systems and Applications, V8, P66, DOI 10.5815/ijisa.2016.08.08
   Ndaïroua F, 2020, CHAOS SOLITON FRACT, V135, DOI 10.1016/j.chaos.2020.109846
   Nengroo AS, 2018, FUTURE GENER COMP SY, V89, P68, DOI 10.1016/j.future.2018.06.028
   Nisha S., 2016, INT J EMERG TECHNOL, V22, P45
   pypi, 2020, CODY ZACHARIAS
   Raghavendra T. S., 2019, Procedia Computer Science, V152, P230, DOI 10.1016/j.procs.2019.05.047
   Ravikumar S, 2021, J AMB INTEL HUM COMP, V12, P7475, DOI 10.1007/s12652-020-02424-x
   Rejeesh MR, 2019, MULTIMED TOOLS APPL, V78, P22691, DOI 10.1007/s11042-019-7577-5
   Rustam F, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0245909
   Soriano CR, 2016, PHILIPP POLIT SCI J, V37, P6, DOI 10.1080/01154451.2016.1146486
   Sahoo K., 2019, Int. J. Innovative Technol. Explor. Eng., V8, P4727, DOI [DOI 10.35940/IJITEE.L3591.1081219, 10.35940/ijitee.L3591.1081219]
   Saif H, 2016, INFORM PROCESS MANAG, V52, P5, DOI 10.1016/j.ipm.2015.01.005
   Sajib MI, 2019, 2019 22 INT C COMPUT, P1
   Sear RF, 2020, IEEE ACCESS, V8, P91886, DOI 10.1109/ACCESS.2020.2993967
   Singh J, 2017, HUM-CENT COMPUT INFO, V7, DOI 10.1186/s13673-017-0116-3
   Sundararaj, 2016, INT J INTELL ENG SYS, V9, P117, DOI [10.22266/ijies2016.0930.12, DOI 10.22266/IJIES2016.0930.12]
   Sundararaj V, 2020, PROG PHOTOVOLTAICS, V28, P1128, DOI 10.1002/pip.3315
   Sundararaj V, 2019, INT J BIOMED ENG TEC, V31, P325, DOI 10.1504/IJBET.2019.103242
   Sundararaj V, 2018, COMPUT SECUR, V77, P277, DOI 10.1016/j.cose.2018.04.009
   Tripathy A, 2017, KNOWL INF SYST, V53, P805, DOI 10.1007/s10115-017-1055-z
   van Lent LGG, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7219
   Zaib NAM, 2017, 2017 6TH ICT INTERNATIONAL STUDENT PROJECT CONFERENCE (ICT-ISPC)
   Zhang XL, 2020, CHAOS SOLITON FRACT, V135, DOI 10.1016/j.chaos.2020.109829
NR 51
TC 10
Z9 10
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42261
EP 42283
DI 10.1007/s11042-022-13492-w
EA JUL 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000830853600004
PM 35912062
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Fan, XD
   Wang, Y
   Wang, CZ
   Chen, XY
AF Fan, Xiaodong
   Wang, Yang
   Wang, Changzhong
   Chen, Xiangyue
TI Multiscale convolutional neural network for no-reference image quality
   assessment with saliency detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; No-reference image quality assessment;
   Human visual system; Saliency detection; Multiscale network
AB In recent years, Convolutional Neural Network (CNN) has been gradually applied to Image Quality Assessment (IQA). Most CNNs segment the image into patches for training, which lead to increase of data and affect calculation speed of the model. Meanwhile, the parameters of CNN usually reach millions, which is the root cause of overfitting. In this paper, a multiscale CNN for NR-IQA is established to solve these problems. Since IQA simulates the perception of Human Visual System (HVS) on image quality, salient areas are more valuable for reference. Therefore a patch sampling method was designed based on saliency detection. Firstly, patches with salient values between given thresholds are retained as training data. Secondly, the sampled patches are fed into multiscale CNN. The network consists of three branches with multiscale convolutional kernels. Finally, the weighted average of the quality scores from the salient patches is the final score. The CNN was trained on LIVE dataset and cross-validated on CSIQ dataset. The experimental results show that the proposed method can achieve better performance with fewer parameters compared with state-of-the-art NR-IQA algorithms.
C1 [Fan, Xiaodong; Wang, Yang; Wang, Changzhong; Chen, Xiangyue] Bohai Univ, Coll Math Sci, Jinzhou 121000, Liaoning, Peoples R China.
C3 Bohai University
RP Fan, XD (corresponding author), Bohai Univ, Coll Math Sci, Jinzhou 121000, Liaoning, Peoples R China.
EM bhdxfxd@163.com
RI wang, changzhong/A-8274-2015
FU National Natural, Science Foundation of China [61976027]; Liaoning
   Provincial Department of Education [LJ2019011, LJKZ1026]; Liaoning
   Natural Foundation Guidance Plan [2019-ZD-0502]; Liaoning Revitalization
   Talents Program [XLYC2008002]
FX This work was supported by the National Natural, Science Foundation of
   China under Grant 61976027, Liaoning Provincial Department of Education
   under Grant LJ2019011, LJKZ1026, Liaoning Natural Foundation Guidance
   Plan under Grant 2019-ZD-0502, and Liaoning Revitalization Talents
   Program under Grant XLYC2008002.
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2016, P VISUAL COMMUNICATI
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Bosse S, 2016, IEEE IMAGE PROC, P3773, DOI 10.1109/ICIP.2016.7533065
   Cenhui Pan, 2016, 2016 Visual Communications and Image Processing (VCIP), DOI 10.1109/VCIP.2016.7805524
   Feng TP, 2016, INT J ADV ROBOT SYST, V13, DOI 10.1177/1729881416669486
   Gu K, 2015, IEEE SIGNAL PROC LET, V22, P1552, DOI 10.1109/LSP.2015.2413944
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jia S, 2018, MULTIMED TOOLS APPL, V77, P14859, DOI 10.1007/s11042-017-5070-6
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li J, 2017, LECT NOTES COMPUT SC, V10639, P550, DOI 10.1007/978-3-319-70136-3_58
   Li J, 2016, SIGNAL IMAGE VIDEO P, V10, P609, DOI 10.1007/s11760-015-0784-2
   Li YM, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P685, DOI 10.1109/ICDSP.2016.7868646
   Ma JP, 2021, IEEE T IMAGE PROCESS, V30, P3650, DOI 10.1109/TIP.2021.3064195
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Po LM, 2019, IEEE T CIRC SYST VID, V29, P1223, DOI 10.1109/TCSVT.2019.2891159
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang L, 2013, IEEE IMAGE PROC, P171, DOI 10.1109/ICIP.2013.6738036
   Zhang P, 2015, PROC CVPR IEEE, P2394, DOI 10.1109/CVPR.2015.7298853
   Zhou ZN, 2021, J INTELL FUZZY SYST, V41, P1115, DOI 10.3233/JIFS-210063
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 27
TC 1
Z9 1
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42607
EP 42619
DI 10.1007/s11042-022-13477-9
EA JUL 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000830853600002
DA 2024-07-18
ER

PT J
AU Li, YS
   Zheng, W
AF Li, Yinsheng
   Zheng, Wei
TI EEG processing in emotion recognition: inspired from a musical staff
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Musical staff; Emotion recognition; EEG reconstruction; Emotion mapping
   library; EEG music
ID BRAIN ELECTRICAL-ACTIVITY; ASYMMETRY; PERSPECTIVES
AB Common electroencephalograph (EEG) features have problems such as poor intrinsic correlation between characteristic quantities, low signal reproducibility and large data storage capacity, which lead to poor emotion recognition. To solve this problem, this paper proposes an EEG music model based on a musical staff. Firstly, this paper constructs a multi-channel EEG sensor network to measure the EEG of an individual under different emotional states, and establishes an EEG-Emotion mapping library for the individual. Then, the EEG is transformed by adaptive segmentation of the time-domain EEG signal using a musical staff model. The time-frequency characteristics of EEG, such as amplitude, contour and signal frequency, are expressed quantitatively in a standardized musical space. The results show that, while retaining the time-frequency features of EEG, the model has an average similarity of 0.9769 before and after reconstruction, a compression rate of 57.18%, and an emotional state recognition rate that is 10.1% higher than traditional features. The brain wave music generated by the model, as a media, provides reference for people to understand the change of emotional state, and also provides a new technical idea for the subsequent use of EEG music for emotional induction.
C1 [Li, Yinsheng; Zheng, Wei] Chongqing Univ, Coll Optoelect Engn, Key Lab Optoelect Technol & Syst, Educ Minist China, 174 Shazhengjie, Chongqing 400044, Peoples R China.
   [Li, Yinsheng] Henan Univ Technol, Coll Informat Sci & Engn, Zhengzhou 450001, Peoples R China.
C3 Chongqing University; Henan University of Technology
RP Zheng, W (corresponding author), Chongqing Univ, Coll Optoelect Engn, Key Lab Optoelect Technol & Syst, Educ Minist China, 174 Shazhengjie, Chongqing 400044, Peoples R China.
EM lyswp009@126.com; zw3475@163.com
RI Li, Yinsheng/AAW-3650-2021
OI Li, Yinsheng/0000-0003-2629-7941
FU national natural science foundation of China [61573073]
FX Thanks for the project supported by the national natural science
   foundation of China (grant no. 61573073).
CR AL-Salman W, 2019, NEUROSCIENCE, V422, P119, DOI 10.1016/j.neuroscience.2019.10.034
   Aldridge A, 2019, 2019 29TH INTERNATIONAL CONFERENCE RADIOELEKTRONIKA (RADIOELEKTRONIKA), P222, DOI 10.1109/RADIOELEK.2019.8733482
   Allman JM, 2001, ANN NY ACAD SCI, V935, P107, DOI 10.1111/j.1749-6632.2001.tb03476.x
   Anaya B, 2021, BIOL PSYCHOL, V159, DOI 10.1016/j.biopsycho.2021.108018
   Bablani A, 2020, CLIN EPIDEMIOL GLOB, V8, P718, DOI 10.1016/j.cegh.2020.01.008
   Bai JJ, 2017, 2017 IEEE 16TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC), P121, DOI 10.1109/ICCI-CC.2017.8109740
   Balasubramanian G, 2018, BIOMED SIGNAL PROCES, V42, P115, DOI 10.1016/j.bspc.2018.01.015
   Nguyen B, 2017, IEEE IJCNN, P3153, DOI 10.1109/IJCNN.2017.7966249
   Blanchette I, 2006, MEM COGNITION, V34, P1112, DOI 10.3758/BF03193257
   Cai HS, 2018, COMPLEXITY, DOI 10.1155/2018/5238028
   Cegar DD, 2020, MULTIMED TOOLS APPL, V79, P19803, DOI 10.1007/s11042-020-08844-3
   Choi S, 2008, EXPERT SYST APPL, V34, P1056, DOI 10.1016/j.eswa.2006.12.015
   Davidson RJ, 2000, PSYCHOL BULL, V126, P890, DOI 10.1037/0033-2909.126.6.890
   Davidson RJ, 2004, BIOL PSYCHOL, V67, P219, DOI 10.1016/j.biopsycho.2004.03.008
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Fdez J, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.626277
   Geethanjali B, 2019, IEEE SENS J, V19, P1499, DOI 10.1109/JSEN.2018.2873402
   Hamada M, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1020-8
   Herrington JD, 2005, EMOTION, V5, P200, DOI 10.1037/1528-3542.5.2.200
   Jatupaiboon N, 2013, SCI WORLD J, DOI 10.1155/2013/618649
   Jie X, 2014, BIO-MED MATER ENG, V24, P1185, DOI 10.3233/BME-130919
   JIRAYUCHAROENSA.S, 2014, SCI WORLD J, V2014, P1, DOI DOI 10.1155/2014/627892
   Katsigiannis S, 2018, IEEE J BIOMED HEALTH, V22, P98, DOI 10.1109/JBHI.2017.2688239
   Khezri M, 2015, COMPUT METH PROG BIO, V122, P149, DOI 10.1016/j.cmpb.2015.07.006
   Khosrowabadi R, 2014, IEEE T NEUR NET LEAR, V25, P609, DOI 10.1109/TNNLS.2013.2280271
   Koelsch S, 2014, NAT REV NEUROSCI, V15, P170, DOI 10.1038/nrn3666
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kong R, 2019, CEREB CORTEX, V29, P2533, DOI 10.1093/cercor/bhy123
   Kumar HIK, 2019, INT J INTERACT MULTI, V5, P109, DOI 10.9781/ijimai.2018.12.005
   Light SN, 2009, CHILD DEV, V80, P1210, DOI 10.1111/j.1467-8624.2009.01326.x
   Lin YP, 2010, IEEE T BIO-MED ENG, V57, P1798, DOI 10.1109/TBME.2010.2048568
   Liu YJ, 2018, IEEE T AFFECT COMPUT, V9, P550, DOI 10.1109/TAFFC.2017.2660485
   Moharreri S, 2018, BIOCYBERN BIOMED ENG, V38, P794, DOI 10.1016/j.bbe.2018.07.001
   Momennezhad A, 2018, MULTIMED TOOLS APPL, V77, P27089, DOI 10.1007/s11042-018-5906-8
   Naji M, 2015, SIGNAL IMAGE VIDEO P, V9, P1365, DOI 10.1007/s11760-013-0591-6
   Nawaz R, 2020, BIOCYBERN BIOMED ENG, V40, P910, DOI 10.1016/j.bbe.2020.04.005
   Petrantonakis PC, 2010, IEEE T INF TECHNOL B, V14, P186, DOI 10.1109/TITB.2009.2034649
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   Raheel A, 2019, MULTIMED TOOLS APPL, V78, P13971, DOI 10.1007/s11042-018-6907-3
   Ramirez R, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00254
   Schmidt LA, 2001, COGNITION EMOTION, V15, P487, DOI 10.1080/0269993004200187
   Seth AK, 2016, PHILOS T R SOC B, V371, DOI 10.1098/rstb.2016.0007
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Srinivasan K, 2013, IEEE J BIOMED HEALTH, V17, P113, DOI 10.1109/TITB.2012.2194298
   Turabzadeh S, 2018, TECHNOLOGIES, V6, DOI 10.3390/technologies6010017
   Xia M, 2019, IEEE T IND INFORM, V15, P3703, DOI 10.1109/TII.2018.2868687
   Yuvaraj R, 2016, COGN NEURODYNAMICS, V10, P225, DOI 10.1007/s11571-016-9375-3
NR 47
TC 1
Z9 1
U1 5
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4161
EP 4180
DI 10.1007/s11042-022-13405-x
EA JUL 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000828935900003
DA 2024-07-18
ER

PT J
AU Kumar, V
   Gaur, M
   Kansal, V
AF Kumar, Vinay
   Gaur, Manish
   Kansal, Vineet
TI Deep feature based forgery detection in video using parallel
   convolutional neural network: VFID-Net
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video forensics; Interframe video forgery; Correlation coefficient;
   Convolutional neural network
ID FRAME; LOCALIZATION
AB It has become easy to alter and tamper the video content flawlessly by using easily available editing software in today's era. Thus, the authenticity of media resources is at high risk. Therefore, one must verify the video to detect the originality of that video content. If the originality and authenticity of the video are compromised, it can change the viewers' perception. This work presents an automatic forgery detection tool that can help to identify the frame insertion type forgery and its location in a video. The deep features are a significant feature in recognizing the forgery and abnormal variations in the video in this work. Based on a parallel CNN model, the proposed method extracts deep features. It also calculates the distance of the correlation coefficient from the deep features, which helps to find the disassociation between the adjacent frames to identify video forgery. The VIFFD and SULFA standard datasets are used to validate the proposed method. It shows that the proposed method is beneficial in differentiating original & insertion type forged videos. The total accuracy of 99.96% achieved in frame-level forgery detection. On video-level forgery detection, 86.5% & 92% accuracy has been achieved in VIFFD & SULFA dataset, respectively. This work also helps to find the inserted frame's location, which benefits in regenerating the original video from the forged video. The proposed method is non-invasive, efficient, robust, and has low time complexity making it suitable for real applications.
C1 [Kumar, Vinay; Gaur, Manish] AKTU, Ctr Adv Studies, Lucknow, Uttar Pradesh, India.
   [Kansal, Vineet] AKTU, Inst Engn & Technol, Lucknow, Uttar Pradesh, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Centre for Advanced
   Studies (CAS, AKTU); Dr. A.P.J. Abdul Kalam Technical University (AKTU);
   Institute of Engineering & Technology Lucknow
RP Kumar, V (corresponding author), AKTU, Ctr Adv Studies, Lucknow, Uttar Pradesh, India.
EM vinay.kumar@cas.res.in; manish.gaur@ietlucknow.ac.in;
   vineetkansal@ietlucknow.ac.in
OI kumar, vinay/0000-0001-7060-7586; Gaur, Manish/0000-0002-4161-2789
CR Aghamaleki JA, 2016, SIGNAL PROCESS-IMAGE, V47, P289, DOI 10.1016/j.image.2016.07.001
   Baghel N, 2020, ARXIV PREPRINT
   Bakas Jamimamul, 2021, Computers & Electrical Engineering, V89, DOI 10.1016/j.compeleceng.2020.106929
   Bakas J, 2019, MULTIMED TOOLS APPL, V78, P4905, DOI 10.1007/s11042-018-6570-8
   Bakas J, 2018, LECT NOTES COMPUT SC, V11281, P304, DOI 10.1007/978-3-030-05171-6_16
   Fadl S, 2021, SIGNAL PROCESS-IMAGE, V90, DOI 10.1016/j.image.2020.116066
   Fadl S, 2019, LECT NOTES COMPUT SC, V11378, P337, DOI 10.1007/978-3-030-11389-6_25
   Guo-Shiang Lin, 2011, 2011 6th International Conference on Computer Science & Education (ICCSE 2011), P1396, DOI 10.1109/ICCSE.2011.6028891
   He PS, 2017, J VIS COMMUN IMAGE R, V48, P149, DOI 10.1016/j.jvcir.2017.06.010
   Kaur H, 2020, WIRELESS PERS COMMUN, V112, P1763, DOI 10.1007/s11277-020-07126-3
   Kingra S, 2017, MULTIMED TOOLS APPL, V76, P25767, DOI 10.1007/s11042-017-4762-2
   Kumar V, 2020, P INT C INNOVATIVE C
   Kumar V., 2014, International Journal of Computational Vision and Robotics, P349
   Kumar V., 2021, RECENT STUDIES COMPU
   Liu YQ, 2017, MULTIMEDIA SYST, V23, P223, DOI [10.1007/s00530-015-0478-1, 10.1007/s00530-015-0461-x]
   Long C., 2019, CVPR WORKSHOPS, P1
   Long CJ, 2017, IEEE COMPUT SOC CONF, P1898, DOI 10.1109/CVPRW.2017.237
   Nguyen X.H., 2020, Int. J. Image, V3, P1
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Qadir Ghulam, 2012, Surrey university library for forensic analysis (SULFA) of video content, P121
   Singh Alpna, 2020, 2020 International Conference on Contemporary Computing and Applications (IC3A), P187, DOI 10.1109/IC3A48958.2020.233294
   Singh RD, 2018, MULTIMEDIA SYST, V24, P211, DOI 10.1007/s00530-017-0538-9
   Sitara K, 2018, FORENSIC SCI INT, V289, P186, DOI 10.1016/j.forsciint.2018.04.056
   Sitara K, 2017, 2017 IEEE 13TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA), P73, DOI 10.1109/CSPA.2017.8064927
   Subramanyam AV, 2012, IEEE INT WORKSH MULT, P89, DOI 10.1109/MMSP.2012.6343421
   Wang Q., 2014, J. Comput. Commun, V2, P51, DOI [DOI 10.4236/jcc.2014.24008, 10.4236/jcc.2014.24008, DOI 10.4236/JCC.2014.24008]
   Wang WH, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P35
   Xu JW, 2016, 2016 30TH ANNIVERSARY OF VISUAL COMMUNICATION AND IMAGE PROCESSING (VCIP)
   Yang JM, 2016, MULTIMED TOOLS APPL, V75, P1793, DOI 10.1007/s11042-014-2374-7
   Zampoglou M, 2019, LECT NOTES COMPUT SC, V11295, P374, DOI 10.1007/978-3-030-05710-7_31
   Zhang ZZ, 2015, SECUR COMMUN NETW, V8, P311, DOI 10.1002/sec.981
   Zhao DN, 2018, MULTIMED TOOLS APPL, V77, P25389, DOI 10.1007/s11042-018-5791-1
NR 32
TC 5
Z9 5
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42223
EP 42240
DI 10.1007/s11042-021-11448-0
EA JUL 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000825246000004
DA 2024-07-18
ER

PT J
AU Ghosh, M
   Dey, A
AF Ghosh, Manas
   Dey, Aniruddha
TI Fractional-weighted entropy-based fuzzy G-2DLDA algorithm: a new facial
   feature extraction method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Entropy; FkNN; Weighting fraction; EnFFG-2DLDA; Membership grade matrix
ID LINEAR DISCRIMINANT-ANALYSIS; PRESERVING PROJECTIONS; RECOGNITION
AB This paper presents a new facial feature extraction method on entropy based fractional fuzzy generalized two-dimensional linear discriminant analysis (EnFFG-2DLDA) where the concept of class uncertainty is incorporated within the generalized two-dimensional linear discriminant analysis. The EnFFG-2DLDA achieves the optimal projection matrix (in both directions) by maximizing the entropy and fuzzy membership value, based on inter-class similarity, while minimizing intra-class discrepancy by integrating weight function. This method ameliorates the shortcomings of 2DLDA method, which fails in case of many real-world situations as it focuses on the global relationship of data, and relies on Gaussian distributed data. Our EnFFG-2DLDA method does not depend on the assumptions that the data distributions and it exploits the intrinsic local structure of the data. Moreover, the FkNN has been incorporated into G-2DLDA algorithm to highlight distinguishable features by redefining the intra- (within) and inter- (between) class scatter matrices along horizontal (row) and vertical (column) directions. The global and per-class mean training vectors are regenerated by combining the fuzzy membership values. The weighting function is associated into inter class scatter matrix, in both direction, to solve contour based problem. Finally, Entropy membership values are specifically used for measuring uncertainty in the special variation in a facial image. Therefore, more significant feature information have been distilled out by combining FkNN, weight function and entropy with the G-2DLDA method, which solves the multi-classification problem. The feasibility of fractional fuzzy G-2DLDA with entropy membership value has been validated over frontal, occluded, and rotationally- angled images with four public standard face databases using RBF neural network. The investigational results demonstrate the substantial accuracy of 99.06% (k = 6) for ORL, 97.81% (k = 10) for UMIST and 66.04 (k = 4) for FERET dataset in terms of average recognition accuracy.
C1 [Ghosh, Manas] RCCIIT, Dept Comp Applicat, Kolkata, India.
   [Dey, Aniruddha] MAKAUT, Dept Informat Technol, Kolkata, India.
C3 RCC Institute of Information Technology (RCCIIT); Maulana Abul Kalam
   Azad University of Technology
RP Dey, A (corresponding author), MAKAUT, Dept Informat Technol, Kolkata, India.
EM manas.ghosh@rcciit.org.in; anidey007@gmail.com
OI Ghosh, Manas/0000-0002-1898-9764
CR Ahmadi S, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107545
   Ali W, 2021, MULTIMED TOOLS APPL, V80, P4825, DOI 10.1007/s11042-020-09850-1
   Alvarado GJ, 2006, MACH VISION APPL, V17, P68, DOI 10.1007/s00138-006-0016-4
   Ayesha S, 2020, INFORM FUSION, V59, P44, DOI 10.1016/j.inffus.2020.01.005
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Bastanfard A, 2001, ITE TECHNICAL REPORT, P65
   Bekhouche SE, 2017, EXPERT SYST APPL, V80, P297, DOI 10.1016/j.eswa.2017.03.030
   Benavente R, 1998, 24 COMP VIS CTR
   Benouareth A, 2021, MULTIMED TOOLS APPL, V80, P1457, DOI 10.1007/s11042-020-09527-9
   Chowdhury S, 2011, APPL SOFT COMPUT, V11, P4282, DOI 10.1016/j.asoc.2010.12.002
   cl, ORL FACE DATABASE
   Dehshibi MM, 2010, SIGNAL PROCESS, V90, P2431, DOI 10.1016/j.sigpro.2010.02.015
   Dey Aniruddha, 2017, International Journal of Machine Learning and Computing, V7, P223, DOI 10.18178/ijmlc.2017.7.6.651
   Dey A, 2018, ADV INTELL SYST, V706, P553, DOI 10.1007/978-981-10-8237-5_54
   Dey A, 2019, INFORM-J COMPUT INFO, V43, P535, DOI 10.31449/inf.v43i4.2117
   Diaz-Chito K, 2018, KNOWL-BASED SYST, V145, P219, DOI 10.1016/j.knosys.2018.01.020
   Du YJ, 2018, INTELL DATA ANAL, V22, P675, DOI 10.3233/IDA-173365
   Gao JQ, 2020, NEURAL PROCESS LETT, V51, P473, DOI 10.1007/s11063-019-10100-1
   Graham Daniel B, 1998, CHARACTERISING VIRTU, P446
   Gurubelli Y, 2019, COMPUT ELECTRON AGR, V162, P95, DOI 10.1016/j.compag.2019.03.036
   He R, 2011, IEEE T IMAGE PROCESS, V20, P1485, DOI 10.1109/TIP.2010.2103949
   He R, 2011, IEEE T PATTERN ANAL, V33, P1561, DOI 10.1109/TPAMI.2010.220
   Huang P, 2017, IEEE ACCESS, V5, P4340, DOI 10.1109/ACCESS.2017.2680437
   Huang P, 2015, COMPUT ELECTR ENG, V46, P231, DOI 10.1016/j.compeleceng.2015.03.013
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   Kwak KC, 2005, PATTERN RECOGN, V38, P1717, DOI 10.1016/j.patcog.2005.01.018
   Li CN, 2019, KNOWL-BASED SYST, V183, DOI 10.1016/j.knosys.2019.07.029
   Li Q, 2019, MULTIMED TOOLS APPL, V78, P30397, DOI 10.1007/s11042-019-07861-1
   Li XD, 2014, J ELECTR COMPUT ENG, V2014, DOI 10.1155/2014/919041
   Liu Y, 2018, IEEE ACCESS, V6, P40723, DOI 10.1109/ACCESS.2018.2859299
   Lotlikar R, 2000, IEEE T PATTERN ANAL, V22, P623, DOI 10.1109/34.862200
   Lu GF, 2018, MULTIMED TOOLS APPL, V77, P16155, DOI 10.1007/s11042-017-5193-9
   Lu GF, 2018, NEURAL NETWORKS, V97, P127, DOI 10.1016/j.neunet.2017.09.014
   Lu GF, 2017, MULTIMED TOOLS APPL, V76, P15801, DOI 10.1007/s11042-016-3870-8
   Lu GF, 2012, PATTERN RECOGN, V45, P2510, DOI 10.1016/j.patcog.2012.01.018
   Luo TJ, 2019, IEEE T CYBERNETICS, V49, P933, DOI 10.1109/TCYB.2018.2789524
   Martinez A.M., 1998, AR FACE DATABASE
   Modhej N, 2020, IEEE ACCESS, V8, P212803, DOI 10.1109/ACCESS.2020.3040298
   Oloyede MO, 2020, MULTIMED TOOLS APPL, V79, P27891, DOI 10.1007/s11042-020-09261-2
   Park S, 2018, PATTERN RECOGN, V76, P752, DOI 10.1016/j.patcog.2017.10.006
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ., 2004, The facial recognition technology (feret) database
   Poon B, 2011, INT J MACH LEARN CYB, V2, P245, DOI 10.1007/s13042-011-0023-2
   Qi YD, 2019, MULTIMED TOOLS APPL, V78, P24249, DOI 10.1007/s11042-018-6994-1
   Rui T, 2018, MULTIMED TOOLS APPL, V77, P10635, DOI 10.1007/s11042-017-4684-z
   Sahoo TK, 2021, MULTIMED TOOLS APPL, V80, P24491, DOI 10.1007/s11042-021-10535-6
   Sing JK, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS, VISION AND INFORMATION SECURITY (CGVIS), P258, DOI 10.1109/CGVIS.2015.7449933
   Tang WJ, 2017, MULTIMED TOOLS APPL, V76, P22725, DOI 10.1007/s11042-017-4343-4
   Wan H, 2020, MULTIMED TOOLS APPL, V79, P29327, DOI 10.1007/s11042-020-09238-1
   Wang JG, 2013, NEURAL COMPUT APPL, V23, P957, DOI 10.1007/s00521-012-1020-4
   Wang Q, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2929
   Xu J, 2016, NEURAL PROCESS LETT, V44, P701, DOI 10.1007/s11063-015-9489-3
   Yan LY, 2019, MULTIMED TOOLS APPL, V78, P15101, DOI 10.1007/s11042-018-6855-y
   Ye QL, 2018, NEURAL NETWORKS, V105, P393, DOI 10.1016/j.neunet.2018.05.020
   Yu WK, 2018, IEEE T IND ELECTRON, V65, P5931, DOI 10.1109/TIE.2017.2782232
   Yuan S, 2018, MULTIMED TOOLS APPL, V77, P21671, DOI 10.1007/s11042-018-5608-2
   Zaatour R, 2019, MULTIMED TOOLS APPL, V78, P17113, DOI 10.1007/s11042-018-6887-3
   Zhao MB, 2012, SOFT COMPUT, V16, P1393, DOI 10.1007/s00500-012-0843-3
   Zheng N, 2014, J VIS COMMUN IMAGE R, V25, P1460, DOI 10.1016/j.jvcir.2014.04.009
   Zhong FJ, 2018, NEUROCOMPUTING, V316, P399, DOI 10.1016/j.neucom.2018.08.026
NR 61
TC 2
Z9 2
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2689
EP 2707
DI 10.1007/s11042-022-13328-7
EA JUL 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000819704300001
DA 2024-07-18
ER

PT J
AU Saremi, M
   Yaghmaee, F
AF Saremi, Mehrin
   Yaghmaee, Farzin
TI Improved use of descriptors for early recognition of actions in video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Early action recognition; Bag-of-words; Descriptor; Pattern
AB Action recognition is a popular research topic in the computer vision community. A new trend has emerged in this field which seeks to recognise the action with as few frames as possible, called early action recognition. Visual bag-of-words methods that rely on local descriptors and visual words are one of the tools that have been used in both offline and early action recognition. In this paper, we propose an improvement to bag-of-words approaches by means of what we name patterns, i.e. co-occurrences of visual words. We compare our method with basic bag-of-words. Experiments on benchmark datasets suggest that our method achieves better accuracy than simple bag-of-words. Also, our method performs better than some of the state of the art methods at some observation ratios. Furthermore, some methods proposed in the literature require segments or video partitions as their working unit. Our method, however, is more granular and can update its prediction as soon as a new descriptor arrives.
C1 [Saremi, Mehrin; Yaghmaee, Farzin] Semnan Univ, Elect & Comp Engn Dept, Semnan 1911135131, Iran.
C3 Semnan University
RP Yaghmaee, F (corresponding author), Semnan Univ, Elect & Comp Engn Dept, Semnan 1911135131, Iran.
EM m.saremi@semnan.ac.ir; f_yaghmaee@semnan.ac.ir
RI Saremi, Mehrin/HTM-6225-2023
OI Yaghmaee, Farzin/0000-0001-7430-542X; Saremi, Mehrin/0000-0001-6557-9656
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.214
   Cao Y, 2013, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2013.343
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Dollar P., 2005, VISUAL SURVEILLANCE, V14, P65, DOI DOI 10.1109/VSPETS.2005.1570899
   Hassan M, 2015, LECT NOTES COMPUT SC, V8456, P207, DOI 10.1007/978-3-319-14424-5_22
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Kantorov V, 2014, PROC CVPR IEEE, P2593, DOI 10.1109/CVPR.2014.332
   Khan MA, 2024, MULTIMED TOOLS APPL, V83, P14885, DOI 10.1007/s11042-020-08806-9
   Khan MA, 2020, APPL SOFT COMPUT, V87, DOI 10.1016/j.asoc.2019.105986
   Kong Y, 2017, PROC CVPR IEEE, P3662, DOI 10.1109/CVPR.2017.390
   Kong Y, 2016, IEEE T PATTERN ANAL, V38, P1844, DOI 10.1109/TPAMI.2015.2491928
   Kong Y, 2014, LECT NOTES COMPUT SC, V8693, P596, DOI 10.1007/978-3-319-10602-1_39
   Kong Y, 2012, LECT NOTES COMPUT SC, V7572, P300, DOI 10.1007/978-3-642-33718-5_22
   Lai SF, 2018, IEEE T IMAGE PROCESS, V27, P2272, DOI 10.1109/TIP.2017.2751145
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Li K, 2014, IEEE T PATTERN ANAL, V36, P1644, DOI 10.1109/TPAMI.2013.2297321
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P1453, DOI 10.1109/TPAMI.2019.2898954
   Liu J, 2018, PROC CVPR IEEE, P8349, DOI 10.1109/CVPR.2018.00871
   Rana AJ, 2020, APPL SCI, V10
   Rasouli Amir, 2020, P 30 BRIT MACH VIS C
   Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349
   Sanderson M, 2010, NAT LANG ENG, V16, P100, DOI 10.1017/S1351324909005129
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Sharif M, 2020, PATTERN ANAL APPL, V23, P281, DOI 10.1007/s10044-019-00789-0
   Soomro K., 2014, COMPUTER VISION SPOR, V71, P181, DOI [DOI 10.1007/978-3-319-09396-3_9, DOI 10.1007/978-3-319-09396-39]
   TRAN DP, 2018, LECT NOTES COMPUTER, V752
   Vondrick C, 2016, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.2016.18
   Wang HR, 2017, NEUROCOMPUTING, V225, P139, DOI 10.1016/j.neucom.2016.11.004
   Wang H, 2016, INT J COMPUT VISION, V119, P219, DOI 10.1007/s11263-015-0846-5
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang XH, 2019, PROC CVPR IEEE, P3551, DOI 10.1109/CVPR.2019.00367
NR 35
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2617
EP 2633
DI 10.1007/s11042-022-13316-x
EA JUL 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000819704400001
DA 2024-07-18
ER

PT J
AU Fateh, A
   Rezvani, M
   Tajary, A
   Fateh, M
AF Fateh, Amirreza
   Rezvani, Mohsen
   Tajary, Alireza
   Fateh, Mansoor
TI Persian printed text line detection based on font size
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Line detection; Font size; Persian printed; Connected component
ID DOCUMENT IMAGES; SEGMENTATION; RECOGNITION; SYSTEM; SELECTION
AB Text line segmentation is an essential step in the process of converting document images into text. In OCR systems, text line segmentation affects the character segmentation stage that has a direct effect on the recognition rate of the system. In scanned images, some lines are skew or curl, and the correct recognition of these lines is another challenge in this field. Also, in some languages like Persian, some of the words have diacritic. In this paper, we introduce a novel text line segmentation method based on the final font size for Persian printed document images to solve these problems. In this method, by finding a specific size, the Connected-Components in a line are glued together. To this end, the pre-processing step of the proposed method removes every small object from the input image using a de-noising method. In the next step, the method measures the diameter of each connected component (CC) in the image to detects the final font size. In the last step, the method finds all CCs that horizontally are in the same direction and then connects them. Due to the lack of a Persian OCR dataset, we created such a dataset. The experimental results are executed on this dataset, and the proposed method reached 99.3% accuracy. It is important to note that this dataset has some curved lines, which increases the challenges in the dataset.
C1 [Fateh, Amirreza; Rezvani, Mohsen; Tajary, Alireza; Fateh, Mansoor] Shahrood Univ Technol, Fac Comp Engn, Shahrood, Iran.
C3 Shahrood University of Technology
RP Fateh, M (corresponding author), Shahrood Univ Technol, Fac Comp Engn, Shahrood, Iran.
EM mansoor_fateh@shahroodut.ac.ir
RI Fateh, Amirreza/GOV-3273-2022
OI Fateh, Amirreza/0000-0001-9894-9131
CR Ahmad I, 2017, IEEE ACCESS, V5, P10924, DOI 10.1109/ACCESS.2017.2703155
   Alaei A, 2011, PATTERN ANAL APPL, V14, P381, DOI 10.1007/s10044-011-0226-x
   Aljarrah I, 2012, 3 INT C INF COMM SYS, P1
   [Anonymous], 2017, LAST RELEASE OCROPUS
   [Anonymous], 2021, LAST RELEASE KRAKEN
   Ayesh M., 2017, Electron Imaging, V2017, P42
   Banumathi KL, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER AND OPTIMIZATION TECHNIQUES (ICEECCOT), P196, DOI 10.1109/ICEECCOT.2016.7955214
   Breuel TM, 2008, PROC SPIE, V6815, DOI 10.1117/12.783598
   Brodic D, 2013, J ELECTR ENG-SLOVAK, V64, P238, DOI 10.2478/jee-2013-0034
   Brown MS, 2004, IEEE T PATTERN ANAL, V26, P1295, DOI 10.1109/TPAMI.2004.87
   Bukhari Syed Saqib, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P61, DOI 10.1109/ICDAR.2009.204
   Bukhari SS, 2013, INT J DOC ANAL RECOG, V16, P33, DOI 10.1007/s10032-011-0176-2
   Bukhari SS, 2009, J UNIVERS COMPUT SCI, V15, P3343
   Bukhari SS, 2009, LECT NOTES COMPUT SC, V5702, P173, DOI 10.1007/978-3-642-03767-2_21
   Bustacara-Medina C., 2020, J. Electr. Electron. Eng, V8, P109, DOI [10.11648/j.jeee.20200804.11, DOI 10.11648/J.JEEE.20200804.11]
   Changhua Wu, 2002, Structural, Syntactic, and Statistical Pattern Recognition. Joint IAPR International Workshops SSPR 2002 and SPR 2002 (Lecture Notes in Computer Science Vol. 2396), P348
   Cheng Q, 2020, MULTIMED TOOLS APPL, V79, P29225, DOI 10.1007/s11042-020-09440-1
   Chernyshova YS, 2020, IEEE ACCESS, V8, P32587, DOI 10.1109/ACCESS.2020.2974051
   Cheung A, 2001, PATTERN RECOGN, V34, P215, DOI 10.1016/S0031-3203(99)00227-7
   Diem M, 2013, PROC INT CONF DOC, P743, DOI 10.1109/ICDAR.2013.152
   El Bahi H, 2019, MULTIMED TOOLS APPL, V78, P26453, DOI 10.1007/s11042-019-07855-z
   Ezaki H, 2005, PROC INT CONF DOC, P302, DOI 10.1109/ICDAR.2005.87
   Fakhari A, 2021, MULTIMED TOOLS APPL, V80, P2047, DOI 10.1007/s11042-020-09685-w
   Fateh A, 2021, PERSIAN DATASET SCAN
   Fateh A, 2021, PERSIAN DATASET DIFF
   Forczmanski P, 2016, MACH VISION APPL, V27, P1243, DOI 10.1007/s00138-016-0803-5
   Garg B, 2020, SIGNAL IMAGE VIDEO P, V14, P1555, DOI 10.1007/s11760-020-01695-3
   Garg R, 2014, NEW APPROACH LINE SE
   Gatos B, 2007, PROC INT CONF DOC, P989
   Grana C, 2016, MULTIMED TOOLS APPL, V75, P3879, DOI 10.1007/s11042-014-2360-0
   Grüning T, 2019, INT J DOC ANAL RECOG, V22, P285, DOI 10.1007/s10032-019-00332-1
   Guo D, 2014, ADV MULTIMED, V2014, DOI 10.1155/2014/682747
   Guo YD, 2015, PROC SPIE, V9395, DOI 10.1117/12.2083709
   Gupta N, 2019, MULTIMED TOOLS APPL, V78, P10821, DOI 10.1007/s11042-018-6613-1
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11
   Hussain S, 2015, INT J DOC ANAL RECOG, V18, P357, DOI 10.1007/s10032-015-0250-2
   Jo J, 2020, MULTIMED TOOLS APPL, V79, P32137, DOI 10.1007/s11042-020-09624-9
   Kaur RP, 2020, MULTIMED TOOLS APPL, V79, P7435, DOI 10.1007/s11042-019-08365-8
   Kchaou MG, 2012, INT CONF FRONT HAND, P274, DOI 10.1109/ICFHR.2012.266
   Kise K, 1998, COMPUT VIS IMAGE UND, V70, P370, DOI 10.1006/cviu.1998.0684
   Koo HI, 2016, IEEE T IMAGE PROCESS, V25, P5358, DOI 10.1109/TIP.2016.2607418
   Lavialle O, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P748, DOI 10.1109/ICIP.2001.958227
   Lyu B, 2019, INT C ADV MECH SYST, P299, DOI [10.1109/ICAMechS.2019.8861597, 10.1109/icamechs.2019.8861597]
   Mahmood A, 2018, P 15 INT S WIR COMM, P1, DOI DOI 10.1109/ISWCS.2018.8491188
   Malakar S, 2012, PROCEEDINGS OF THE 2012 INTERNATIONAL CONFERENCE ON COMMUNICATIONS, DEVICES AND INTELLIGENT SYSTEMS (CODLS), P616, DOI 10.1109/CODIS.2012.6422278
   NAGY G, 1992, COMPUTER, V25, P10, DOI 10.1109/2.144436
   OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Paul S, 2019, MULTIMED TOOLS APPL, V78, P18017, DOI 10.1007/s11042-019-7178-3
   Rahmati M, 2020, IET IMAGE PROCESS, V14, P3920, DOI 10.1049/iet-ipr.2019.0728
   Rais M, 2011, LECT NOTES COMPUT SC, V7042, P149, DOI 10.1007/978-3-642-25085-9_17
   Seuret M., 2017, P 4 INT WORKSH HIST, P71, DOI [10.1145/3151509.3151521, DOI 10.1145/3151509.3151521]
   Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296
   Sheikh N.A., 2009, Australian Journal of Basic and Applied Science, V3, P4160
   Soni R, 2019, MULTIMED TOOLS APPL, V78, P31757, DOI 10.1007/s11042-019-07998-z
   Soujanya P, 2010, COMP STUDY TEXT LINE
   Tan CL, 2006, IEEE T PATTERN ANAL, V28, P195, DOI 10.1109/TPAMI.2006.40
   Thuy Tuong Nguyen, 2008, 2008 6th IEEE International Conference on Industrial Informatics (INDIN), P1528, DOI 10.1109/INDIN.2008.4618347
   Ulges A, 2005, PROC INT CONF DOC, P1001, DOI 10.1109/ICDAR.2005.90
   Wang XB, 2017, MULTIMED TOOLS APPL, V76, P26201, DOI 10.1007/s11042-016-4099-2
   Yin XC, 2016, IEEE T IMAGE PROCESS, V25, P2752, DOI 10.1109/TIP.2016.2554321
   Youssef, 2020, ARABIC DATASET OCR
   Zeki, 2013, TECHNOLOGY DIFFUSION, P251
   Zhang Z, 2003, PROC INT CONF DOC, P589
NR 64
TC 6
Z9 6
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2393
EP 2418
DI 10.1007/s11042-022-13243-x
EA JUN 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000814956000002
DA 2024-07-18
ER

PT J
AU Chen, Z
   Feng, YJ
   Ren, Y
AF Chen, Zan
   Feng, Yuanjing
   Ren, Yi
TI Deep 2nd-order residual block for image denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Deep neural network; Taylor's expansion
ID SPARSE
AB Deep convolutional neural networks (CNNs) play an important role in learning image prior information for image denoising in recent years. However, the current plain networks suffer from feature extraction of weak textures, leading to the loss of image detail. In this paper, inspired by the insights in the connections of the classical deep residual block design and Taylor's expansion, we propose a deep 2nd-order residual block to enhance the feature extraction ability. The proposed deep 2nd-order residual block combines the dilated convolution, the channel attention mechanism, and the self-ensemble strategy together to improve the denoising performance. Extensive experiments demonstrate that our deep 2nd-order residual block outperforms state-of-the-art image-denoising methods, while also serving as an excellent plug-and-play prior.
C1 [Chen, Zan; Feng, Yuanjing] Zhejiang Univ Technol, Coll Informat Engn, Hangzhou, Peoples R China.
   [Ren, Yi] Univ East Anglia, Sch Comp Sci, Norwich, Norfolk, England.
C3 Zhejiang University of Technology; University of East Anglia
RP Chen, Z (corresponding author), Zhejiang Univ Technol, Coll Informat Engn, Hangzhou, Peoples R China.
EM zanchen2@zjut.edu.cn
FU National Natural Science Foundation of China [62002327, 61976190];
   Natural Science Foundation of Zhejiang Province [Q21F020057]; Key
   Research and Development Program of Zhejiang Province [2020C03070]
FX This research was sponsored in part by the National Natural Science
   Foundation of China (Grant No. 62002327, 61976190), Natural Science
   Foundation of Zhejiang Province (Grant No. Q21F020057), and Key Research
   and Development Program of Zhejiang Province (Grant No. 2020C03070).
CR Cao FL, 2019, NEUROCOMPUTING, V358, P424, DOI 10.1016/j.neucom.2019.05.066
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P2645, DOI 10.1109/TVCG.2019.2892415
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P3618, DOI 10.1109/TIP.2014.2329449
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Donoho DL, 2009, P NATL ACAD SCI USA, V106, P18914, DOI 10.1073/pnas.0909892106
   Dumoulin V, 2018, Arxiv, DOI [arXiv:1603.07285, DOI 10.48550/ARXIV.1603.07285]
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fang FM, 2021, IEEE T NEUR NET LEAR, V32, P3956, DOI 10.1109/TNNLS.2020.3016321
   Franzen R, 1999, Kodak lossless true color image suite
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou XX, 2019, IEEE COMPUT SOC CONF, P1738, DOI 10.1109/CVPRW.2019.00224
   HUANG JB, 2015, PROC CVPR IEEE, P5197, DOI DOI 10.1109/CVPR.2015.7299156
   Jia XX, 2019, PROC CVPR IEEE, P6047, DOI 10.1109/CVPR.2019.00621
   Jian Zhang, 2013, 2013 IEEE International Symposium on Circuits and Systems (ISCAS 2013), P2836, DOI 10.1109/ISCAS.2013.6572469
   Kim DG, 2018, NEUROCOMPUTING, V293, P1, DOI 10.1016/j.neucom.2018.02.063
   Liu D, 2018, ADV NEUR IN, V31
   Lu XQ, 2013, NEUROCOMPUTING, V106, P12, DOI 10.1016/j.neucom.2012.09.014
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Metzler CA, 2017, ADV NEUR IN, V30
   Metzler CA, 2016, IEEE T INFORM THEORY, V62, P5117, DOI 10.1109/TIT.2016.2556683
   Mun S, 2009, IEEE IMAGE PROC, P3021, DOI 10.1109/ICIP.2009.5414429
   Pang ZF, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107325
   Peng YL, 2019, NEUROCOMPUTING, V345, P67, DOI 10.1016/j.neucom.2018.12.075
   Tan J, 2015, IEEE T SIGNAL PROCES, V63, P2085, DOI 10.1109/TSP.2015.2408558
   Thakur RS, 2019, IET IMAGE PROCESS, V13, P2367, DOI 10.1049/iet-ipr.2019.0157
   Tian CW, 2021, KNOWL-BASED SYST, V226, DOI 10.1016/j.knosys.2021.106949
   Tian CW, 2020, NEURAL NETWORKS, V124, P117, DOI 10.1016/j.neunet.2019.12.024
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Timofte R, 2016, PROC CVPR IEEE, P1865, DOI 10.1109/CVPR.2016.206
   Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Xu J, 2019, ARXIV 190606878
   Zhang K., 2017, PROC CVPR IEEE, P3929, DOI [DOI 10.1109/CVPR.2017.300, 10.1109/CVPR.2017.300]
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
NR 40
TC 1
Z9 1
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2101
EP 2119
DI 10.1007/s11042-022-13241-z
EA JUN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000812444900001
DA 2024-07-18
ER

PT J
AU Wei, XQ
   Shi, Y
   Gong, WY
   Guan, YY
AF Wei, Xuqin
   Shi, Yun
   Gong, Weiyin
   Guan, Yanyun
TI Improved image representation and sparse representation for face
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse representation; Face recognition; Image representation; Weight
   fusion
ID K-SVD; DICTIONARY; ROBUST; CLASSIFICATION; GRAPH
AB Sparse representation is of great significance to the research of face recognition. Due to factors such as illumination, angle, and facial features, different face images of the same subject have great differences under different conditions, which will cause great difficulties in image classification. To solve this problem, this paper proposes a novel image classification algorithm. The algorithm uses an improved image representation method to generate virtual samples that not only better preserve the large-scale information and global features of the original training samples, but can also be regarded as another representation of objects. Combining multiple representations of images can effectively improve the accuracy of image classification. Moreover, this paper designs a simple and efficient weight fusion scheme to fuse the original training samples and virtual samples and obtain the final classification distance of the test sample. Experimental results on multiple face databases show that the proposed algorithm has higher classification accuracy than other state-of-the-art algorithms.
C1 [Wei, Xuqin; Shi, Yun; Gong, Weiyin; Guan, Yanyun] Liupanshui Normal Univ, Coll Math & Comp Sci, Liupanshui, Peoples R China.
RP Wei, XQ (corresponding author), Liupanshui Normal Univ, Coll Math & Comp Sci, Liupanshui, Peoples R China.
EM xuqinwei@126.com; shiyunzhou2004@163.com; Gw-Yin@hotmail.com;
   guanyanyun2021@126.com
RI xuqin, wei/GLN-7719-2022
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Deng WH, 2018, IEEE T PATTERN ANAL, V40, P2513, DOI 10.1109/TPAMI.2017.2757923
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Ding CX, 2015, IEEE T IMAGE PROCESS, V24, P980, DOI 10.1109/TIP.2015.2390959
   Fan ZZ, 2020, MULTIMED TOOLS APPL, V79, P7319, DOI 10.1007/s11042-019-08211-x
   Fang XZ, 2015, IEEE T IMAGE PROCESS, V24, P2760, DOI 10.1109/TIP.2015.2425545
   Gao Y, 2017, IEEE T IMAGE PROCESS, V26, P2545, DOI 10.1109/TIP.2017.2675341
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Kafai M, 2014, IEEE T INF FOREN SEC, V9, P2132, DOI 10.1109/TIFS.2014.2359548
   Keinert F, 2019, IEEE T IMAGE PROCESS, V28, P2785, DOI 10.1109/TIP.2018.2890312
   Li ZM, 2017, IEEE T NEUR NET LEAR, V28, P278, DOI 10.1109/TNNLS.2015.2508025
   Liao MM, 2020, NEUROCOMPUTING, V373, P35, DOI 10.1016/j.neucom.2019.09.025
   Lin GJ, 2018, PATTERN RECOGN, V81, P341, DOI 10.1016/j.patcog.2018.03.021
   Lin GJ, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318400040
   Luo XL, 2019, PATTERN RECOGN, V93, P283, DOI 10.1016/j.patcog.2019.04.027
   Ma X, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-016-9009-6
   Moeini A, 2015, IEEE T INF FOREN SEC, V10, P969, DOI 10.1109/TIFS.2015.2393553
   Qian RD, 2018, MULTIMED TOOLS APPL, V77, P28441, DOI 10.1007/s11042-018-5987-4
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Shrivastava A, 2015, PATTERN RECOGN, V48, P3283, DOI 10.1016/j.patcog.2014.07.031
   Tan J, 2021, IMAGE VISION COMPUT, V112, DOI 10.1016/j.imavis.2021.104212
   Wen J, 2019, IEEE T CIRC SYST VID, V29, P390, DOI 10.1109/TCSVT.2018.2799214
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu MN, 2021, APPL INTELL, V51, P8349, DOI 10.1007/s10489-021-02338-x
   Xu Y, 2019, PATTERN RECOGN LETT, V128, P131, DOI 10.1016/j.patrec.2019.08.022
   Xu Y, 2017, IEEE T NEUR NET LEAR, V28, P2233, DOI 10.1109/TNNLS.2016.2580572
   Xu Y, 2015, PATTERN RECOGN LETT, V68, P9, DOI 10.1016/j.patrec.2015.07.032
   Xu Y, 2014, IEEE T CYBERNETICS, V44, P1738, DOI 10.1109/TCYB.2013.2293391
   Xu Y, 2014, NEUROCOMPUTING, V131, P191, DOI 10.1016/j.neucom.2013.10.025
   Xu Y, 2013, PATTERN RECOGN, V46, P1151, DOI 10.1016/j.patcog.2012.11.003
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Yang J, 2017, IEEE T PATTERN ANAL, V39, P156, DOI 10.1109/TPAMI.2016.2535218
   Ye MJ, 2021, MULTIMED TOOLS APPL, V80, P3251, DOI 10.1007/s11042-020-09855-w
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang PY, 2016, PATTERN RECOGN, V52, P249, DOI 10.1016/j.patcog.2015.09.024
   Zhang Q.Z.Q., 2010, PROC CVPR IEEE, DOI [10.1109/CVPR.2010.5539989, DOI 10.1109/CVPR.2010.5539989]
   Zhang YJ, 2021, SIGNAL IMAGE VIDEO P, V15, P307, DOI 10.1007/s11760-020-01755-8
   Zhang Z, 2018, IEEE T NEUR NET LEAR, V29, P3111, DOI 10.1109/TNNLS.2017.2712801
   Zheng SJ, 2020, APPL INTELL, V50, P1687, DOI 10.1007/s10489-019-01612-3
NR 39
TC 5
Z9 5
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 44247
EP 44261
DI 10.1007/s11042-022-13203-5
EA JUN 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000805063200001
DA 2024-07-18
ER

PT J
AU Sharkas, M
AF Sharkas, Maha
TI Ear recognition with ensemble classifiers; A deep learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Ear recognition; Ensemble classifiers; Deep learning
ID BIOMETRICS; FACE
AB Biometrics has emerged as a major domain for security systems. Ear as a biometric has many distinctive features which makes it promising for personal identification systems. In this paper, two tracks for classification of ear images are implemented and tested. The first employs a classical machine learning technique based on extracting features from the discrete curvelet transform and passing the extracted features to a classifier. Image preprocessing is needed for enhancement and segmentation. Ear region is first selected from the background then the curvelet transform via wrapping is applied on the segmented ear images. Different levels are investigated. The coarse image is divided into blocks and the mean, variance and entropy are calculated for each block and concatenated with the same calculated statistical features from the subimages at different levels forming the feature vector. The feature vector is passed to a classifier for ear recognition and the only classifier that provided comparative results was the ensemble classifiers. In the second track, deep learning methods are employed. Different end-to-end networks are used for classifying ear images. Features are then extracted from each network and fed to a shallow classifier for ear classification. Principal component analysis is used for feature reduction. Different classifiers are again investigated and the only classifiers which succeeded to give superior results are the Ensemble classifiers. The achieved classification rate showed improved results compared to the published methods that proves the superiority of the Ensemble classifiers for correctly classifying ear images.
C1 [Sharkas, Maha] Arab Acad Sci & Technol, Elect & Commun Engn Dept, Alexandria, Egypt.
C3 Egyptian Knowledge Bank (EKB); Arab Academy for Science, Technology &
   Maritime Transport
RP Sharkas, M (corresponding author), Arab Acad Sci & Technol, Elect & Commun Engn Dept, Alexandria, Egypt.
OI sharkas, maha/0000-0003-4132-3984
FU Science, Technology AMP; Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Priyadharshini RA, 2021, APPL INTELL, V51, P2161, DOI 10.1007/s10489-020-01995-8
   Alberink I, 2007, FORENSIC SCI INT, V166, P145, DOI 10.1016/j.forsciint.2006.05.001
   Alqaralleh E, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418560098
   Alshazly H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19194139
   Basit A, 2014, INT J COMPUT MATH, V91, P616, DOI 10.1080/00207160.2013.800194
   Benzaoui A, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.5.053008
   Burge M., 1998, BIOMETRICS, P273
   Bustard JD, 2010, IEEE T SYST MAN CY A, V40, P486, DOI 10.1109/TSMCA.2010.2041652
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Cands, 1999, CURVE SURFACE FITTIN
   Chang K, 2003, IEEE T PATTERN ANAL, V25, P1160, DOI 10.1109/TPAMI.2003.1227990
   Dodge S, 2018, IET BIOMETRICS, V7, P207, DOI 10.1049/iet-bmt.2017.0208
   Eyiokur FI, 2018, IET BIOMETRICS, V7, P199, DOI 10.1049/iet-bmt.2017.0209
   Hansley EE, 2018, IET BIOMETRICS, V7, P215, DOI 10.1049/iet-bmt.2017.0210
   Hassaballah M, 2019, EXPERT SYST APPL, V118, P182, DOI 10.1016/j.eswa.2018.10.007
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hurley DJ, 2005, LECT NOTES COMPUT SC, V3546, P386
   Hurley DJ, 2000, P C VIS BIOM, P71
   Kacar U, 2019, IET BIOMETRICS, V8, P109, DOI 10.1049/iet-bmt.2018.5065
   Khaldi Y, 2021, EVOL SYST-GER, V12, P923, DOI 10.1007/s12530-020-09346-1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2012, PATTERN RECOGN, V45, P956, DOI 10.1016/j.patcog.2011.06.005
   Kumar A, 2007, PROC SPIE, V6539, DOI 10.1117/12.720244
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Moreno B, 1999, P INT CARN C SEC TEC
   Nosrati MS, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS, P616
   Olanrewaju L, 2020, SIGNAL IMAGE VIDEO P, V14, P847, DOI 10.1007/s11760-019-01609-y
   Omara I, 2018, IET BIOMETRICS, V7, P557, DOI 10.1049/iet-bmt.2017.0087
   Pflug A, 2014, P INT JOINT C BIOMET, P18
   Pflug A, 2014, INT CARN CONF SECU
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Rahman A, 2014, INT J COMPUT TRENDS, V10
   Sharma S, 2022, IETE J RES, V68, P3798, DOI 10.1080/03772063.2020.1780164
   Sumana IJ, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P11, DOI 10.1109/MMSP.2008.4665041
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Victor B, 2002, INT C PATT RECOG, P429, DOI 10.1109/ICPR.2002.1044746
   Wang Z-Q, 2011, P INT C EL INF CONTR
   Yuan L, 2006, INT C PATT RECOG, P501
   Zhang Y, 2018, IET BIOMETRICS, V7, P185, DOI 10.1049/iet-bmt.2017.0176
NR 39
TC 11
Z9 11
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43919
EP 43945
DI 10.1007/s11042-022-13252-w
EA MAY 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000802892700003
OA hybrid
DA 2024-07-18
ER

PT J
AU Ashiba, MI
   Youness, HA
   Ashiba, HI
AF Ashiba, M. I.
   Youness, Hassan A.
   Ashiba, H. I.
TI Suggested wavelet transform for cancelable face recognition system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cancelable biometrics; Biometric templates; The HFM; AT; Template
   protection
ID FINGERPRINT; BIOMETRICS; SECURE
AB Cancelable biometrics is a method to incorporate protection and the replacement features into biometrics to create a more secure system. The purpose of this research to protect the biometric system against imposter attack and making biometric system more secure. This framework suggests novel two presented cancellable biometric realization algorithms recognition and template protection. The first scheme is based on encrypted with Homomorphic Filtering Masking (HFM) method for cancelable face recognition. In this scheme, the HFM algorithm is applied on the face images. The resultant map is encrypted, to the second HFM utilized in the HFM is produced from the image. In the second suggested scheme, A Trous Transform (AT) algorithm is applied on the face images. Then the AT divides the image into seven sub bands. The resultant map is encrypted with HFM encoding algorithm is utilized for cancelable face recognition system. Then the second HFM utilized is produced from the image. Simulation results are evaluated by False Positive Rate (FPR), False Negative Rate (FNR), Equal Error Rate (EER), Receiver Operating Characteristic (ROC), Area under ROC (AROC) and decidability metrics. The obtained results prove that the first schem is better than the second technique EER point view. On the other hand the second technique is the best with comparing the other approaches performance metrics point view. The two techniques have succeded in cancelable face recognition system. These schemes can be utilized to advance a frequency domain procedure for making this model for biometric template protection.
C1 [Ashiba, M. I.; Youness, Hassan A.] Minia Univ, Fac Engn, Dept Comp & Syst Engn, Al Minya, Egypt.
   [Ashiba, H. I.] Bilbis Higher Inst Engn, Dept Elect & Elect Commun, Bilbis, Sharqia, Egypt.
C3 Egyptian Knowledge Bank (EKB); Minia University
RP Ashiba, MI (corresponding author), Minia Univ, Fac Engn, Dept Comp & Syst Engn, Al Minya, Egypt.
EM engashiba@gmail.com
CR Akdogan D, 2018, COMPUT NETW, V142, P33, DOI 10.1016/j.comnet.2018.06.001
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Ashiba HI, 2020, MULTIMED TOOLS APPL, V79, P2543, DOI 10.1007/s11042-019-08154-3
   Ashiba HI, 2019, MULTIMED TOOLS APPL, V78, P11277, DOI 10.1007/s11042-018-6545-9
   Ashiba H. I., 2008, Progress In Electromagnetics Research C, V1, P123, DOI 10.2528/PIERC08012301
   Barra S, 2019, FUTURE GENER COMP SY, V101, P534, DOI 10.1016/j.future.2019.06.019
   Brigham E.O., 2002, The Fast Fourier Transform
   Buolamwini J., 2020, Facial Recognition Technologies: A Primer
   Das S, 2019, PATTERN RECOGN LETT, V126, P102, DOI 10.1016/j.patrec.2018.06.026
   Davis L.S., 1975, Comput. Graph. Image Process, V4, P248, DOI DOI 10.1016/0146-664X(75)90012-X
   Dwivedi R, 2019, PATTERN RECOGN LETT, V126, P58, DOI 10.1016/j.patrec.2018.04.022
   Evelyn Brindha V., 2012, J. Biom. Biostat, V3, P100
   Feng YC, 2010, IEEE T INF FOREN SEC, V5, P103, DOI 10.1109/TIFS.2009.2038760
   Hassanein AS., 2015, IJCSI INT J COMPUT S, V12, P2
   Hengjian Li, 2012, Journal of Software, V7, P1827, DOI 10.4304/jsw.7.8.1827-1834
   Jing W, 2019, INT J HIGH PERFORMAN, V13
   Kaur H., 2018, PATTERN RECOGN LETT, V126, P1
   Kaur H, 2020, FUTURE GENER COMP SY, V102, P30, DOI 10.1016/j.future.2019.07.023
   Kaur H, 2015, PROCEDIA COMPUT SCI, V54, P661, DOI 10.1016/j.procs.2015.06.077
   Kho JB, 2019, PATTERN RECOGN, V91, P245, DOI 10.1016/j.patcog.2019.01.039
   Li HJ, 2020, MULTIMED TOOLS APPL, V79, P11947, DOI 10.1007/s11042-019-08446-8
   Li HJ, 2012, PROCEDIA ENGINEER, V29, P1239, DOI 10.1016/j.proeng.2012.01.120
   Li Y, 2019, INT J ORAL SCI, V11, DOI 10.1038/s41368-019-0045-2
   Maiorana E, 2010, EXPERT SYST APPL, V37, P3454, DOI 10.1016/j.eswa.2009.10.043
   Oh BS, 2012, PATTERN RECOGN, V45, P3288, DOI 10.1016/j.patcog.2012.02.027
   Pang Y., 2007, INT J COMPUT ELECT A, V1, P9
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Rathgeb C, 2014, COMPUT SECUR, V42, P1, DOI 10.1016/j.cose.2013.12.005
   Saini N, 2010, OPT COMMUN, V283, P894, DOI 10.1016/j.optcom.2009.11.003
   Savvides M, 2004, INT C PATT RECOG, P922, DOI 10.1109/ICPR.2004.1334679
   Senthilkumaran N., 2009, International Journal of Recent Trends in Engineering, V1, P250
   Sunaryono D, 2021, J KING SAUD UNIV-COM, V33, P304, DOI 10.1016/j.jksuci.2019.01.006
   Taheri M, 2015, J OPT SOC AM A, V32, P1772, DOI 10.1364/JOSAA.32.001772
   Teoh ABJ, 2005, PATTERN RECOGN LETT, V26, P1454, DOI 10.1016/j.patrec.2004.11.021
   Trivedi AK, 2020, COMPUT SECUR, V90, DOI 10.1016/j.cose.2019.101690
   Umer S, 2017, INFORM SCIENCES, V406, P102, DOI 10.1016/j.ins.2017.04.026
   Verma G, 2019, OPT LASER ENG, V123, P28, DOI 10.1016/j.optlaseng.2019.06.028
   Verma G, 2016, J OPTICS-UK, V18, DOI 10.1088/2040-8978/18/5/055705
   Wang S, 2016, PATTERN RECOGN, V54, P14, DOI 10.1016/j.patcog.2016.01.001
   Xu Y, 2020, SOFT COMPUT, V24, P5971, DOI 10.1007/s00500-019-04530-1
   Yang WC, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11020141
   Yang WC, 2018, PATTERN RECOGN, V78, P242, DOI 10.1016/j.patcog.2018.01.026
   Zhou K, 2018, IEEE T INF FOREN SEC, V13, P3050, DOI 10.1109/TIFS.2018.2838540
NR 43
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43701
EP 43726
DI 10.1007/s11042-022-13070-0
EA MAY 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000800436600003
DA 2024-07-18
ER

PT J
AU Viacheslav, K
   Kovtun, O
AF Viacheslav, Kovtun
   Kovtun, Oksana
TI System of methods of automated cognitive linguistic analysis of speech
   signals with noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computational linguistics; Cognitive linguistic analysis; Information
   technology; Speech signal processing
AB For the first time, the article presents a system of methods for automated cognitive linguistic analysis of speech signals with noise, in which, unlike existing ones, the latter is represented by a sequence of phoneme and morpheme codes identified by the criterion of the minimum of functional of relative entropy, the set of values of which is formed as a result of sequential comparison of the results of automated transcribing the studied signal with the reference phonetic alphabet of the target language. The presented system of methods made it possible, in particular, to substantiate the process of phonetic coding of language units through the analytical generalization of the results of automated transcribing of speech signals, to formalize the process of estimation of the degree of phonation variability of language units within the framework of the proposed system of methods, to formalize the interpretation of the concept of cognitive linguistic analysis of speech signals with noise in the frequency space, to propose an applied use of the obtained system of methods of cognitive linguistic analysis, for purification the speech signal from Gaussian noise. The adequacy of the theoretical apparatus and the functionality of the methods presented in the article has been proven empirically.
C1 [Viacheslav, Kovtun] Vinnytsia Natl Tech Univ, Khmelnitske Shose St 95, Vinnytsia, Ukraine.
   [Kovtun, Oksana] Vasyl Stus Donetsk Natl Univ, 600 Richchya St,21, Vinnytsia, Ukraine.
C3 Ministry of Education & Science of Ukraine; Vinnytsia National Technical
   University; Ministry of Education & Science of Ukraine; Vasyl Stus
   Donetsk National University
RP Viacheslav, K (corresponding author), Vinnytsia Natl Tech Univ, Khmelnitske Shose St 95, Vinnytsia, Ukraine.
EM kovtun_v_v@vntu.edu.ua; o.kovtun@donnu.edu.ua
RI Kovtun, Viacheslav V./M-9043-2019
OI Kovtun, Viacheslav V./0000-0002-7624-7072; Kovtun,
   Oksana/0000-0002-9139-8987
CR Abu-Shareha AA., 2009, TENCON 2009 2009 IEE, P1, DOI [10.1109/TENCON.2009.5396028, DOI 10.1109/TENCON.2009.5396028]
   Al-Radhi MS, 2021, MULTIMED TOOLS APPL, V80, P1969, DOI 10.1007/s11042-020-09783-9
   Alishahi A., 2010, COMPUTATIONAL MODELI
   Asano Y., 2011, 2011 IEEE International Conference on Granular Computing, P60, DOI 10.1109/GRC.2011.6122568
   Bajwa IS, 2012, J KING SAUD UNIV-COM, V24, P117, DOI 10.1016/j.jksuci.2011.12.003
   Ben Cheikh Imen, 2010, Proceedings International Conference on Machine and Web Intelligence (ICMWI 2010), P108, DOI 10.1109/ICMWI.2010.5648124
   Benesty Jacob., 2009, Journal of the Acoustical Society of America, V126, P2130, DOI DOI 10.1121/1.3203918
   Bin Li, 2011, Proceedings of the 2011 Seventh International Conference on Computational Intelligence and Security (CIS 2011), P1100, DOI 10.1109/CIS.2011.244
   Bisikalo OV, 2018, RADIO ELECTRON COMPU, P71, DOI 10.15588/1607-3274-2018-4-7
   Biswas M, 2023, MULTIMED TOOLS APPL, V82, P9565, DOI 10.1007/s11042-021-11439-1
   Choi J, 2018, 2018 INT C COMPUTATI, P1452, DOI DOI 10.1109/CSCI46756.2018.00286
   Gaspers Judith, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3201, DOI 10.1109/ICASSP.2014.6854191
   Jian-fang C., 2010, 2010 2 IEEE INT C IN, P352, DOI [10.1109/ICIME.2010.5477992, DOI 10.1109/ICIME.2010.5477992]
   Jiang Bing, 2012, 2012 International Conference on Audio, Language and Image Processing (ICALIP 2012). Proceedings, P1005, DOI 10.1109/ICALIP.2012.6376762
   Kaliyev A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE QUALITY MANAGEMENT, TRANSPORT AND INFORMATION SECURITY, INFORMATION TECHNOLOGIES (IT&QM&IS), P653, DOI 10.1109/ITMQIS.2018.8525072
   Kiss G, 2013, INT CONF COGN INFO, P579, DOI 10.1109/CogInfoCom.2013.6719169
   Kovtun VV, 2019, PRZ ELEKTROTECHNICZN, V95, P176, DOI 10.15199/48.2019.04.32
   Kung FJ, 2015, INT CONF SPEECH DATA, P53, DOI 10.1109/ICSDA.2015.7357864
   Laleye FAA, 2017, MULTIMED TOOLS APPL, V76, P16347, DOI 10.1007/s11042-016-3911-3
   Lei Wang, 2010, 2010 International Conference on Asian Language Processing (IALP 2010), P241, DOI 10.1109/IALP.2010.28
   Leoshchenko S, 2017, 2017 4TH INTERNATIONAL SCIENTIFIC-PRACTICAL CONFERENCE PROBLEMS OF INFOCOMMUNICATIONS-SCIENCE AND TECHNOLOGY (PIC S&T), P7, DOI 10.1109/INFOCOMMST.2017.8246137
   Liu Y, 2012, 2012 INTERNATIONAL CONFERENCE ON INDUSTRIAL CONTROL AND ELECTRONICS ENGINEERING (ICICEE), P254, DOI 10.1109/ICICEE.2012.74
   Malhotra Puru, 2020, 2020 12th International Conference on Computational Intelligence and Communication Networks (CICN), P466, DOI 10.1109/CICN49253.2020.9242554
   Malik M, 2021, MULTIMED TOOLS APPL, V80, P9411, DOI 10.1007/s11042-020-10073-7
   Maouene Josita, 2010, 2010 IEEE 9th International Conference on Development and Learning (ICDL 2010), P88, DOI 10.1109/DEVLRN.2010.5578861
   Middlestead R.W., 2017, Digital Communications with Emphasis on Data Modems: Theory, Analysis, Design, Simulation, Testing, and Applications
   Revathi A, 2021, MULTIMED TOOLS APPL, V80, P18301, DOI 10.1007/s11042-021-10639-z
   Saggion H., 2017, Automatic Text Simplification, DOI 10.2200/S00700ED1V01Y201602HLT032
   Sheela A. C. Santha, 2019, 2019 Fifth International Conference on Science Technology Engineering and Mathematics (ICONSTEM), P1, DOI 10.1109/ICONSTEM.2019.8918837
   Siivola V., 2007, 8 ANN C INT SPEECH C, P1549, DOI DOI 10.21437/INTERSPEECH.2007-446
   Spolaôr N, 2021, MULTIMED TOOLS APPL, V80, P33971, DOI 10.1007/s11042-021-11401-1
   Supap W, 2009, IEEE TIC-STH 09: 2009 IEEE TORONTO INTERNATIONAL CONFERENCE: SCIENCE AND TECHNOLOGY FOR HUMANITY, P49, DOI 10.1109/TIC-STH.2009.5444447
   Terbeh N, 2018, MULTIMED TOOLS APPL, V77, P17779, DOI 10.1007/s11042-017-5447-6
   Thirumuru R, 2018, MULTIMED TOOLS APPL, V77, P4753, DOI 10.1007/s11042-017-5044-8
   Tripathi K, 2021, MULTIMED TOOLS APPL, V80, P13615, DOI 10.1007/s11042-020-10394-7
   Umber A., 2011, 2011 Sixth International Conference on Digital Information Management, P102, DOI 10.1109/ICDIM.2011.6093363
   Wang XD, 2017, MULTIMED TOOLS APPL, V76, P20359, DOI 10.1007/s11042-017-4714-x
NR 37
TC 2
Z9 2
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43391
EP 43410
DI 10.1007/s11042-022-13249-5
EA MAY 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000800967800001
DA 2024-07-18
ER

PT J
AU Liu, LS
   Meng, LZ
   Wang, XL
   Peng, YJ
AF Liu, Lianshan
   Meng, Lingzhuang
   Wang, Xiaoli
   Peng, Yanjun
TI An image steganography scheme based on ResNet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Deep learning; High capacity; Neural network;
   Residual network
AB In recent years, deep learning has been used in steganography scheme, and the implemented solution had a large hidden capacity. In order to further study the effect of basic deep learning network on image steganography, a deep learning image steganography scheme based on ResNet was proposed in this paper, which applied the idea of residual blocks in ResNet to the field of image steganography. Image hiding and image extraction were realized by encoder network and decoder network. In the proposed scheme, by setting the balance parameter during training, different hiding and extraction qualities could be obtained for different scenarios. At the same time, a new performance analysis method was proposed for the field of deep steganography: the scatter plots of PSNR and SSIM. For a test set with a large amount of data, it could clearly reflect the performance of the solution, and it had a certain degree of application value in the field of deep steganography. The experimental results showed that the scheme had better invisibility when hiding, high data accuracy when extracting, and had certain advantages compared with the existing scheme. And it performed better when detected by steganalysis tools.
C1 [Liu, Lianshan; Meng, Lingzhuang; Peng, Yanjun] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
   [Wang, Xiaoli] Shandong Univ Sci & Technol, Off Network Secur & Informatizat, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Liu, LS (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
EM lshliu6042@163.com; lzhmeng1688@163.com; wangxiaoli6093@163.com;
   pengyanjuncn@163.com
RI wang, xu/IAN-4886-2023; wang, xiao/HGB-7081-2022; wang,
   xiao/HZI-9156-2023; meng, lingzhuang/IQR-7631-2023
OI wang, xiao/0000-0002-4088-3341; meng, lingzhuang/0000-0002-6549-6989;
   liu, lianshan/0000-0003-4400-6490
FU National Natural Science Foundation of China [61976126]; Shandong
   Natural Science Foundation [ZR2019MF003]
FX This work was supported in part by National Natural Science Foundation
   of China (No. 61976126), Shandong Natural Science Foundation (No.
   ZR2019MF003).
CR Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Abdulla AA, 2013, IEEE INT SYM MULTIM, P287, DOI 10.1109/ISM.2013.55
   Baluja S, 2017, ADV NEUR IN, V30
   Boehm, 2014, STEGEXPOSE A TOOL DE, DOI [10.48550/arXiv.1410.6656, DOI 10.48550/ARXIV.1410.6656]
   Chen BJ, 2020, KSII T INTERNET INF, V14, P366, DOI 10.3837/tiis.2020.01.020
   Duan XT, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20247253
   Duan XT, 2020, IEEE ACCESS, V8, P195253, DOI 10.1109/ACCESS.2020.3033895
   Duan XT, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22101140
   Duan XT, 2021, IETE TECH REV, V38, P172, DOI 10.1080/02564602.2020.1808097
   Duan XT, 2020, IEEE ACCESS, V8, P25777, DOI 10.1109/ACCESS.2020.2971528
   Duan XT, 2019, IEEE ACCESS, V7, P9314, DOI 10.1109/ACCESS.2019.2891247
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Gao GY, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107817
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Li CL, 2018, CMC-COMPUT MATER CON, V56, P313, DOI 10.3970/cmc.2018.03950
   Li Q, 2020, IEEE ACCESS, V8, P168166, DOI 10.1109/ACCESS.2020.3021103
   Liu B, 2019, KNOWL-BASED SYST, V164, P235, DOI 10.1016/j.knosys.2018.10.044
   Liu Q, 2020, KNOWL-BASED SYST, V192, DOI 10.1016/j.knosys.2019.105375
   Meng LZ, 2021, MULTIMED TOOLS APPL, V80, P711, DOI 10.1007/s11042-020-09686-9
   Meng RH, 2018, CMC-COMPUT MATER CON, V55, P1, DOI 10.3970/cmc.2018.055.001
   Naito H, 2019, INT CONF AWARE SCI, P495, DOI 10.1109/icawst.2019.8923579
   Ouahabi A, 2021, PATTERN RECOGN LETT, V144, P27, DOI 10.1016/j.patrec.2021.01.010
   Rehman AU, 2019, LECT NOTES COMPUT SC, V11132, P723, DOI 10.1007/978-3-030-11018-5_64
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Wang HQ, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00518-2
   Wu P, 2018, LECT NOTES COMPUT SC, V11165, P792, DOI 10.1007/978-3-030-00767-6_73
   Yedroudj M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2092, DOI 10.1109/ICASSP.2018.8461438
   Yu C, 2020, AAAI CONF ARTIF INTE, V34, P1120
   Zhu JR, 2018, LECT NOTES COMPUT SC, V11219, P682, DOI 10.1007/978-3-030-01267-0_40
NR 34
TC 5
Z9 5
U1 6
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39803
EP 39820
DI 10.1007/s11042-022-13206-2
EA MAY 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000797298300003
DA 2024-07-18
ER

PT J
AU Deng, HY
   Meng, XZ
   Feng, L
AF Deng, Huiyuan
   Meng, Xiangzhu
   Feng, Lin
TI Multimodal-aware weakly supervised metric learning with self-weighting
   triplet loss
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Weakly supervised metric learning; Riemannian metric; Similarity
   measures
ID OPTIMIZATION; SIMILARITY
AB In recent years, we have witnessed a surge of interests in learning distance metrics from various data mining tasks. Most existing methods aim to pull all the similar samples closer while push the dissimilar ones as far as possible. However, when some classes of the dataset exhibit multimodal distribution, these goals conflict and thus can hardly be concurrently satisfied. Additionally, to ensure a valid metric, many methods require a repeated eigenvalue decomposition process, which is time-consuming and numerically unstable. Therefore, how to effectively learn an appropriate distance metric from weakly supervised data remains an open but challenging problem. To address this issue, in this paper, we propose a novel weakly supervised metric learning algorithm, named MultimoDal aware weakly supervised Metric Learning (MDaML). MDaML partitions training data into several clusters and allocates the local cluster center and weight for each sample. Then, combining it with the weighted triplet loss can further enhance the local separability, which encourages local dissimilar samples to keep a large distance from local similar samples. Meanwhile, MDaML casts the metric learning problem into an unconstrained optimization on SPD manifold, which can be efficiently solved by Riemannian Conjugate Gradient Descent (RCGD). Extensive experiments conducted on 13 datasets validate the superiority of the proposed method.
C1 [Deng, Huiyuan; Meng, Xiangzhu; Feng, Lin] Dalian Univ Technol, Sch Comp Sci & Technol, Dalian, Peoples R China.
C3 Dalian University of Technology
RP Feng, L (corresponding author), Dalian Univ Technol, Sch Comp Sci & Technol, Dalian, Peoples R China.
EM dhytorres@mail.dlut.edu.cn; xiangzhu_meng@mail.dlut.edu.cn;
   fenglin@dlut.edu.cn
RI Meng, Xiangzhu/KEI-2033-2024; deng, huiyuan/HLG-2046-2023
OI Meng, Xiangzhu/0000-0003-3892-4092; deng, huiyuan/0000-0003-2715-0351
FU National Natural Science Foundation of PR China [61972064]; LiaoNing
   Revitalization Talents Program [XLYC1806006]
FX The authors would like to thank the anonymous reviewers for their
   insightful comments and the suggestions to significantly improve the
   quality of this paper. This work was supported by National Natural
   Science Foundation of PR China(61972064) and LiaoNing Revitalization
   Talents Program(XLYC1806006).
CR Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   Nguyen B, 2018, PATTERN RECOGN, V81, P562, DOI 10.1016/j.patcog.2018.04.024
   Nguyen B, 2017, PATTERN RECOGN, V64, P215, DOI 10.1016/j.patcog.2016.11.010
   Bache K, 2013, UCI machine learning repository
   Bellet A, 2013, ARXIV 13066709
   Boothby W.M., 1986, An Introduction to Differentiable Manifolds and Riemannian Geometry
   Boumal N, 2014, J MACH LEARN RES, V15, P1455
   Chang XY, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107569
   Davis J. V., 2007, ICML, P209
   Dong XP, 2019, IEEE T IMAGE PROCESS, V28, P3516, DOI 10.1109/TIP.2019.2898567
   Dong YN, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10091415
   Fukunaga K., 2013, INTRO STAT PATTERN R
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Harandi M, 2017, PR MACH LEARN RES, V70
   He XF, 2004, ADV NEUR IN, V16, P153
   Hu JL, 2018, IEEE T CIRC SYST VID, V28, P1875, DOI 10.1109/TCSVT.2017.2691801
   Huo ZY, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1605, DOI 10.1145/2939672.2939853
   Jun Wang, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P223, DOI 10.1007/978-3-642-33460-3_20
   Kato T, 2010, BIOINFORMATICS, V26, P2698, DOI 10.1093/bioinformatics/btq519
   KRIEBEL ME, 1974, J GEN PHYSIOL, V64, P85, DOI 10.1085/jgp.64.1.85
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Law MT, 2014, PROC CVPR IEEE, P1051, DOI 10.1109/CVPR.2014.138
   Law MT, 2013, IEEE I CONF COMP VIS, P249, DOI 10.1109/ICCV.2013.38
   Lee J, 2019, ARXIV 190611768
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin WY, 2020, PROC CVPR IEEE, P4173, DOI 10.1109/CVPR42600.2020.00423
   Liu H, 2019, ADV NEUR IN, V32
   McFee B, 2010, P 27 INT C MACH LEAR
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Mishra B, 2014, COMPUTATION STAT, V29, P591, DOI 10.1007/s00180-013-0464-z
   Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281
   Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z
   Qian Q, 2015, PROC CVPR IEEE, P3716, DOI 10.1109/CVPR.2015.7298995
   Resnik P, 1999, J ARTIF INTELL RES, V11, P95, DOI 10.1613/jair.514
   Reynolds D., 2015, ENCY BIOMETRICS, P827, DOI 10.1007/978-1-4899-7488-4_196
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shalit U, 2012, J MACH LEARN RES, V13, P429
   Sun YF, 2020, PROC CVPR IEEE, P6397, DOI 10.1109/CVPR42600.2020.00643
   Taheri M, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106994
   Wang H, 2021, 2021 IEEE INT C MULT
   Wang HB, 2021, IEEE T MULTIMEDIA, V23, P3828, DOI 10.1109/TMM.2020.3032023
   Wang HB, 2020, IEEE MULTIMEDIA, V27, P112, DOI 10.1109/MMUL.2020.2999464
   Wang HB, 2020, IEEE T VEH TECHNOL, V69, P10484, DOI 10.1109/TVT.2020.3009162
   Wang HB, 2016, IEEE T MULTIMEDIA, V18, P1579, DOI 10.1109/TMM.2016.2569412
   Wang J, 2012, ARXIV 12093056
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Xing EP, 2003, ADV NEURAL INFORM PR
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Yang L, 2006, AAAI, V2
   Yang L., 2006, Michigan State Universiy
   Yang Q, 2017, IEEE T CYBERNETICS, V47, P636, DOI 10.1109/TCYB.2016.2523000
   Ye HJ, 2019, IEEE T PATTERN ANAL, V41, P1257, DOI 10.1109/TPAMI.2018.2829192
   Ying YM, 2012, J MACH LEARN RES, V13, P1
   Yue JC, 2005, COMMUN STAT-THEOR M, V34, P2123, DOI 10.1080/STA-200066418
   Zadeh PH, 2016, PR MACH LEARN RES, V48
   Zhang J, 2017, AAAI CONF ARTIF INTE, P933
   Zhang J, 2013, RENEW ENERG, V51, P436, DOI 10.1016/j.renene.2012.09.026
   Zhu YQ, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P2069, DOI 10.1145/3442381.3449802
NR 61
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 41151
EP 41173
DI 10.1007/s11042-022-12053-5
EA MAY 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000797297600003
DA 2024-07-18
ER

PT J
AU Wu, H
   Liu, GZ
AF Wu, Han
   Liu, Guizhong
TI Split-merge-excitation: a robust channel-wise feature attention
   mechanism applied to MDNet tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Deep learning; Feature attention; Representation
   learning
ID OBJECT TRACKING
AB Object tracking is a fundamental problem of computer vision. Although being studied for decades, the single object tracking problem has not been completely solved, since there exist various challenges in the real physical world, such as object deformation, complex background and imperfect imaging, which make tracking difficult. For these challenges, we design a robust feature extraction network. Specifically, we propose a novel channel-wise feature attention mechanism, which is integrated into the pipeline of a well-known convolutional neural network based visual tracking algorithm. It is crucial to represent the object robustly. Due to the representative feature, the tracking performance is improved. In experiments, we test the proposed tracking algorithm in OTB100, VOT2018, VOT2020 and VOT-TIR datasets. Compared to the baseline algorithm, our proposed algorithm obtains consistent performance improvement for different benchmarks with absolute increase of tracking success score in OTB100 up to 0.6, and absolute increase of EAO up to 0.022, 0.007, and 0.008 in VOT2018, VOT2020, VOT-TIR2015 respectively. The source codes are publicly available.
C1 [Wu, Han; Liu, Guizhong] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian, Peoples R China.
C3 Xi'an Jiaotong University
RP Liu, GZ (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian, Peoples R China.
EM xjtuwh@stu.xjtu.edu.cn; liugz@xjtu.edu.cn
RI Wu, Han/IAR-7651-2023
OI Wu, Han/0000-0003-0008-7081
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Cao Y., 2019, CORR, P1, DOI [DOI 10.1109/ICCVW.2019.00246, 10.1109/ICCVW.2019.00246]
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Danelljan M, 2020, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR42600.2020.00721
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Fan H, 2021, INT J COMPUT VISION, V129, P439, DOI 10.1007/s11263-020-01387-y
   Felsberg M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P639, DOI 10.1109/ICCVW.2015.86
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Gao JY, 2019, PROC CVPR IEEE, P4644, DOI 10.1109/CVPR.2019.00478
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Jiang FL, 2021, COGN COMPUT, V13, P69, DOI 10.1007/s12559-020-09724-6
   Kristan M., 2020, COMPUTER VISION ECCV, P547
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li, 2020, LECT NOTES COMPUTER, V12362, DOI [10.1007/978-3-030-58520-4_5, DOI 10.1007/978-3-030-58520-4_5]
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Müller M, 2018, LECT NOTES COMPUT SC, V11205, P310, DOI 10.1007/978-3-030-01246-5_19
   Park E, 2018, LECT NOTES COMPUT SC, V11207, P587, DOI 10.1007/978-3-030-01219-9_35
   Peng, 2020, LECT NOTES COMPUTER, V12366, DOI [10.1007/978-3-030-58589-1_46, DOI 10.1007/978-3-030-58589-1_46]
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang Q, 2018, PROC CVPR IEEE, P4854, DOI 10.1109/CVPR.2018.00510
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Woo S., 2018, P EUR C COMP VIS ECC, DOI DOI 10.1007/978-3-030-01234-2_1
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xu YK, 2019, IET COMPUT VIS, V13, P355, DOI 10.1049/iet-cvi.2018.5598
   Zhao H., 2020, P IEEE CVF C COMP VI, V2020, P10076, DOI 10.1109/CVPR42600.2020.01009
   Zhou X, 2014, 2014 IEEE INT C IMAG, DOI 10.1109/ICIP.2014.7025169
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
   Zhu Z, 2018, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2018.00064
NR 46
TC 1
Z9 1
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40737
EP 40754
DI 10.1007/s11042-022-12752-z
EA MAY 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000795177900012
DA 2024-07-18
ER

PT J
AU Trifa, A
   Hedhili, A
   Chaari, WL
AF Trifa, Amal
   Hedhili, Aroua
   Chaari, Wided Lejouad
TI Adaptive architecture based on agents for assessing a web application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cognitive agents; Social agents; Assessing; Comparison; Reference;
   Personalization
ID E-LEARNING SYSTEM; PERSONALIZATION; ACCURACY; QUALITY
AB The personalization presents a key factor in the majority of web application. It improves the user experience by serving each user according to his desires and intentions. To ensure a good personalization process, the evaluation should be considered. However, in the literature, assessing this process is considered as a secondary purpose and treated as a lowcost test before the final deployment of a web application. Besides, the majority of assessments are domain dependent. They also report performance for a short time period and for specific users. Thus, we propose a solution, called RPMAS, designed with an adaptive architecture, based on agents. It is a reference system that attempts to personalize the same services offered by the assessed web application. Then, a comparison is performed to evaluate the results of the concerned web application. Following this comparison, RPMAS proposes improvements to the evaluated web application, or makes a self-evaluation to treat its proper weaknesses. In this article, we expose the detailed architecture of the proposed solution. Indeed, our solution is composed of three layers: the Observation Layer, the Modeling and Data Processing Layer and the Prediction, Recommendation and Evaluation Layer. Each layer has several intelligent and adaptive agents. We underline the various RPMAS advantages, compared to the state of the art. Then, we provide the proof of the efficiency of our contribution when evaluating different web applications. Finally, we developed a first scenario which illustrates the assessment made by our RPMAS regarding an online library. Also, we deploy a second scenario to assess an intelligent tutoring application. Regarding the accuracy measure, the gap between RPMAS and the first application is 17.316%. For the second scenario, using the AUC measure, the gap indicates 13.09%.
C1 [Trifa, Amal; Hedhili, Aroua; Chaari, Wided Lejouad] Natl Sch Comp Sci Tunisia, LARIA Lab, Manouba, Tunisia.
C3 Universite de la Manouba
RP Trifa, A (corresponding author), Natl Sch Comp Sci Tunisia, LARIA Lab, Manouba, Tunisia.
EM amal.tarifa@ensi-uma.tn
RI Trifa, Amal/N-5252-2018
OI Trifa, Amal/0000-0001-6330-4499
CR Ai QY, 2019, PROCEEDINGS OF THE 2019 ACM SIGIR INTERNATIONAL CONFERENCE ON THEORY OF INFORMATION RETRIEVAL (ICTIR'19), P84, DOI 10.1145/3341981.3344218
   Aissaoui O. E., 2020, 1 INT C INN RES APPL, P1
   [Anonymous], 2017, P S APPL COMP
   Belarbi N, 2019, INT J EMERGING TECHN, V14
   Castells P, 2005, LECT NOTES COMPUT SC, V3762, P977
   Chen CM, 2005, COMPUT EDUC, V44, P237, DOI 10.1016/j.compedu.2004.01.006
   Chen Y, 2021, ARXIV
   DIEBOLD FX, 1995, J BUS ECON STAT, V13, P253, DOI 10.2307/1392185
   Dou Zhicheng, 2007, P WWW, P581, DOI DOI 10.1145/1242572.1242651
   Dreyfus H. L., 1992, What Computers Still Cant Do: a Critique of Artificial Reason
   Garrido A, 2014, IEEE REV IBEROAM TEC, V9, P1, DOI 10.1109/RITA.2014.2301886
   Gertler PJ, 2011, IMPACT EVALUATION IN PRACTICE, P1, DOI 10.1596/978-0-8213-8541-8
   Guo QL, 2009, KNOWL-BASED SYST, V22, P439, DOI 10.1016/j.knosys.2009.06.001
   Guo WW, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2509, DOI 10.1145/3340531.3412699
   Hussain MT, 2019, ARTIF INTELL REV, V52, P381, DOI 10.1007/s10462-018-9620-8
   Jerez JM, 2010, ARTIF INTELL MED, V50, P105, DOI 10.1016/j.artmed.2010.05.002
   Kasiri LA, 2017, J RETAIL CONSUM SERV, V35, P91, DOI 10.1016/j.jretconser.2016.11.007
   Katarya R, 2020, MULTIMED TOOLS APPL, V79, P35927, DOI 10.1007/s11042-020-09199-5
   Kiseleva J, 2016, P 39 INT ACM SIGIR C, P4554
   Labidi S, 1993, THESIS INRIA
   Li FW., 2009, Advances in Web Based Learning-ICWL 2009
   Malik B.H., 2019, INT J ADV COMPUT SC, V10
   Malik Zeeshan Khawar, 2012, Journal of Emerging Technologies in Web Intelligence, V4, P285, DOI 10.4304/jetwi.4.3.285-296
   Mandryk RL, 2007, INT J HUM-COMPUT ST, V65, P329, DOI 10.1016/j.ijhcs.2006.11.011
   Mobasher B., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P90
   Mobasher B, 2000, COMMUN ACM, V43, P142, DOI 10.1145/345124.345169
   Moukas A., 1998, Autonomous agents and multiagent systems, V1, P59
   Rani M, 2015, KNOWL-BASED SYST, V90, P33, DOI 10.1016/j.knosys.2015.10.002
   Rekik R, 2018, INT J INFORM MANAGE, V38, P201, DOI 10.1016/j.ijinfomgt.2017.06.007
   Riemer K., 2003, CUSTOMER CENTRIC ENT, P35
   Salonen V, 2016, TELEMAT INFORM, V33, P1088, DOI 10.1016/j.tele.2016.03.004
   Shang J, 2019, P AAAI C ARTIFICIAL, V33
   Shi DQ, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105618
   Shin K, 2021, ARXIV
   Soui M., 2011, 2011 4th International Conference on Logistics (LOGISTIQUA), P68, DOI 10.1109/LOGISTIQUA.2011.5939405
   Trifa A, 2019, EDUC INF TECHNOL, V24, P711, DOI 10.1007/s10639-018-9792-5
   Trifa A, 2017, PROCEDIA COMPUT SCI, V112, P249, DOI 10.1016/j.procs.2017.08.239
   Trifa A, 2017, 2017 IEEE 26TH INTERNATIONAL CONFERENCE ON ENABLING TECHNOLOGIES - INFRASTRUCTURE FOR COLLABORATIVE ENTERPRISES (WETICE), P18, DOI 10.1109/WETICE.2017.14
   Wiedemann G, 2019, ARXIV
NR 39
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40581
EP 40607
DI 10.1007/s11042-022-13059-9
EA MAY 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000793651500002
DA 2024-07-18
ER

PT J
AU Yang, XF
   Zhou, ZH
   Wang, QS
   Wang, ZW
   Li, X
   Li, HF
AF Yang, Xiaofeng
   Zhou, Zihao
   Wang, Qianshan
   Wang, Zhiwei
   Li, Xi
   Li, Haifang
TI Cross-domain unsupervised pedestrian re-identification based on
   multi-view decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian re-identification; Lightweight capsule network; Multi-view;
   Feature decomposition; Domain-invariant
ID PERSON REIDENTIFICATION; ADAPTATION
AB Great improvement has been made in pedestrian re-identification, but the test results in unknown domain are not satisfactory. This is because the pedestrian Re-ID model does not learn good common features between different domains. We found that view-angle related features are invariant in different domains. Based on this, we develop a cross-domain Re-ID method. Specifically, any pedestrian image is decomposed under the constraints of multiple view angles and the pedestrian multi-view features are generated. We propose an improved lightweight capsule network as the multi-view decomposition. The experimental results showed that our method can effectively improve the cross-domain performance of Re-ID.
C1 [Yang, Xiaofeng; Wang, Qianshan; Li, Haifang] Taiyuan Univ Technol, Coll Informat & Comp, Yuci 030600, Peoples R China.
   [Yang, Xiaofeng] Shanxi Vocat Univ Engn Sci & Technol, Coll Comp Engn, Yuci 030600, Peoples R China.
   [Zhou, Zihao] Taiyuan Univ Technol, Coll Math, Yuci 030600, Peoples R China.
   [Wang, Zhiwei] Shanxi Climat Ctr, Taiyuan 03006, Peoples R China.
   [Li, Xi] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310007, Peoples R China.
C3 Taiyuan University of Technology; Shanxi Vocational University of
   Engineering Science & Technology; Taiyuan University of Technology;
   Zhejiang University
RP Li, HF (corresponding author), Taiyuan Univ Technol, Coll Informat & Comp, Yuci 030600, Peoples R China.
EM lihaifang@tyut.edu.cn
RI zhou, zihao/IZD-6452-2023; xiaofeng, yang/CAH-7085-2022
FU Natural Science Foundation of China [61873178, 61976150]; Natural
   Science Foundation of Shanxi Province [201901D111091]; Key Research And
   Development Projects of Shanxi Province [201803D31038]; Key Research And
   Development Projects of Jinzhong City [Y192006]; CERNET Next Generation
   Internet Technology Innovation Project [NGII20181206]; Domestic and
   Foreign Crop Yield Meteorology Forecast Special Project [RH19100004]
FX Natural Science Foundation of China(61873178, 61976150), Natural Science
   Foundation of Shanxi Province (201901D111091), Key Research And
   Development Projects of Shanxi Province(201803D31038), Key Research And
   Development Projects of Jinzhong City(Y192006), CERNET Next Generation
   Internet Technology Innovation Project(NGII20181206), Domestic and
   Foreign Crop Yield Meteorology Forecast Special Project(RH19100004).
CR [Anonymous], 2013, Cognitive Neuroscience: The Biology of the Mind
   [Anonymous], 2017, Capsule Network Performance on Complex Data
   Bak S, 2018, LECT NOTES COMPUT SC, V11217, P193, DOI 10.1007/978-3-030-01261-8_12
   Busto PP, 2017, IEEE I CONF COMP VIS, P754, DOI 10.1109/ICCV.2017.88
   Chen Peixian, 2020, ARXIV200713249
   Chen TY, 2019, MEASUREMENT, V148, DOI 10.1016/j.measurement.2019.106857
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen YB, 2019, IEEE I CONF COMP VIS, P232, DOI 10.1109/ICCV.2019.00032
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Chuanchen Luo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P224, DOI 10.1007/978-3-030-58555-6_14
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Fang C, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-34114-2
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Fu Y, 2019, IEEE I CONF COMP VIS, P6111, DOI 10.1109/ICCV.2019.00621
   Hinton G.E., 2018, INT C LEARN REPR
   Hospedales Timothy M, 2019, BMVC
   Kodirov E, 2015, BMVC2015
   Kodirov E, 2016, LECT NOTES COMPUT SC, V9905, P178, DOI 10.1007/978-3-319-46448-0_11
   Kosiorek A. R., 2019, Adv. Neural Inf. Process Syst, P15486
   Liang W., 2018, ARXIV181103768
   Lin CS, 2021, INT C PATT RECOG, P6758, DOI 10.1109/ICPR48806.2021.9413013
   Lin Shan, 2018, 2018 IEEE 36 VLSI TE
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Ma AJ, 2015, IEEE T IMAGE PROCESS, V24, P1599, DOI 10.1109/TIP.2015.2395715
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Qin C, 2015, NEUROCOMPUTING, V168, P609, DOI 10.1016/j.neucom.2015.05.064
   Rajasegaran J, 2019, PROC CVPR IEEE, P10717, DOI 10.1109/CVPR.2019.01098
   Sabour S, 2017, ADV NEUR IN, V30
   Sadreazami H, 2019, IEEE ACCESS, V7, P55336, DOI 10.1109/ACCESS.2019.2907925
   Saito K, 2018, LECT NOTES COMPUT SC, V11209, P156, DOI 10.1007/978-3-030-01228-1_10
   Song JF, 2019, PROC CVPR IEEE, P719, DOI 10.1109/CVPR.2019.00081
   Su C, 2016, LECT NOTES COMPUT SC, V9906, P475, DOI 10.1007/978-3-319-46475-6_30
   Tamura M, 2020, BMVC2020, P1
   Wang H., 2014, IEEE PES TD Conference and Exposition, P1, DOI DOI 10.5244/C.28.48
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Yang M, 2019, NEURAL NETWORKS, V118, P247, DOI 10.1016/j.neunet.2019.06.014
   Ye J., 2007, 2007 IEEE C COMP VIS, P1, DOI DOI 10.1109/CVPR.2007.383103
   Yin HX, 2019, IEEE ACCESS, V7, P153171, DOI 10.1109/ACCESS.2019.2948628
   Yu HX, 2017, IEEE I CONF COMP VIS, P994, DOI 10.1109/ICCV.2017.113
   Yunpeng Zhai, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9018, DOI 10.1109/CVPR42600.2020.00904
   Zhang BW, 2018, IEEE ACCESS, V6, P58284, DOI 10.1109/ACCESS.2018.2874623
   Zhang S., 2018, INT S ART INT ROB, P301
   Zhang XY, 2019, IEEE I CONF COMP VIS, P8221, DOI 10.1109/ICCV.2019.00831
   Zhao R, 2017, IEEE T PATTERN ANAL, V39, P356, DOI 10.1109/TPAMI.2016.2544310
   Zhao W, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3110
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11
NR 49
TC 0
Z9 0
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39387
EP 39408
DI 10.1007/s11042-021-11797-w
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000788980000003
DA 2024-07-18
ER

PT J
AU Liu, J
   Tan, JQ
   Zhang, L
   Zhu, XC
   Ge, XY
AF Liu, Jing
   Tan, Jieqing
   Zhang, Li
   Zhu, Xingchen
   Ge, Xianyu
TI Blind image deblurring via <i>L</i><sub>1</sub>-regularized second-order
   gradient prior
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image deblurring; Image restoration; Deconvolution; Kernel estimation;
   The second-order gradient prior
ID SHAKEN
AB The blind image deblurring is to find the underlying true image and the blur kernel from a blurred observation. This is a well-known ill-conditional problem in image processing field. To obtain a pleasant deblurred result, additional assumptions and prior knowledge are required. Proposed in this work is a simple and efficient blind image deblurring method which utilizes L-1-regularized second-order gradient prior. The inspiration for this work comes from the fact that the absolute values of the second-order gradient elements decrease with motion blur. This change is an essential feature of the motion blur process, and we demonstrate it mathematically in this paper. By enforcing the L-1 norm constraint to the term involving second-order gradients and incorporating it into the traditional deblurring framework, an effective optimization scheme is explored. The half-quadratic splitting technique is adopted to handle the non-convex minimum problem. Experimental results illustrate that our algorithm outperforms the state-of-art image deblurring algorithms in both benchmark datasets and ground-truth scenes. Besides, this algorithm is simple since it does not require any heuristic edge selection steps or involves too many nonlinear operators.
C1 [Liu, Jing; Tan, Jieqing; Ge, Xianyu] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Peoples R China.
   [Zhang, Li] Hefei Univ Technol, Sch Math, Hefei 230009, Peoples R China.
   [Zhu, Xingchen] Nanjing Marine Radar Inst, Nanjing 210000, Peoples R China.
C3 Hefei University of Technology; Hefei University of Technology
RP Tan, JQ (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Peoples R China.
EM jieqingtan@hfut.edu.cn
RI Tan, Jie/IVV-5250-2023
FU National Natural Science Foundation of China [62172135]
FX We would like to thank the reviewers for their helpful comments and
   suggestions which greatly improve the quality of the paper. This work
   was supported by the National Natural Science Foundation of China under
   Grant 62172135.
CR Banham MR, 1997, IEEE SIGNAL PROC MAG, V14, P24, DOI 10.1109/79.581363
   Bao JQ, 2021, MULTIMED TOOLS APPL, V80, P3489, DOI 10.1007/s11042-020-09821-6
   Campisi P., 2017, BLIND IMAGE DECONVOL
   CANNON M, 1976, IEEE T ACOUST SPEECH, V24, P58, DOI 10.1109/TASSP.1976.1162770
   Cao XC, 2015, IEEE T IMAGE PROCESS, V24, P1302, DOI 10.1109/TIP.2015.2400217
   Chakrabarti A., 2016, P EUROPEAN C COMPUTE
   Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187
   Chen L, 2019, PROC CVPR IEEE, P1742, DOI 10.1109/CVPR.2019.00184
   Cho H, 2012, EUROPEAN C COMPUTER, P524537
   Cho S, 2011, IEEE INT C COMPUTER
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Hirsch M, 2011, IEEE INT C COMPUTER
   Hu Z, 2016, PROC CVPR IEEE, P1855, DOI 10.1109/CVPR.2016.205
   Hu Z, 2014, PROC CVPR IEEE, P3382, DOI 10.1109/CVPR.2014.432
   Javaran TA, 2017, MACH VISION APPL, V28, P431, DOI 10.1007/s00138-017-0824-8
   Jia JY, 2007, PROC CVPR IEEE, P453
   Joshi N, 2008, IEEE C COMPUTER VISI, P18
   Khler R, 2012, EUROPEAN C COMPUTER, P2740
   Krishnan D, 2011, IEEE C COMPUTER VISI
   Krishnan D, 2009, ADV NEURAL INFORM PR, P22
   Lai W S, 2016, P IEEE C COMPUTER VI
   Lee H, 2019, IEEE T IMAGE PROCESS, V29
   Levin A, 2009, IEEE C COMPUTER VISI
   Levin A, 2011, IEEE C COMPUTER VISI, P26572664
   Li LRH, 2019, INT J COMPUT VISION, V127, P1025, DOI 10.1007/s11263-018-01146-0
   Li T, 2002, ACM T GRAPHIC, P847858
   Li TH, 2002, IEEE T IMAGE PROCESS, V11, P847, DOI 10.1109/TIP.2002.801127
   LUCY LB, 1974, ASTRON J, V79, P745, DOI 10.1086/111605
   Lucy LB., 1997, ASTRON J, V79, P754
   Michaeli T, 2014, LECT NOTES COMPUT SC, V8691, P783, DOI 10.1007/978-3-319-10578-9_51
   Nah S, 2017, IEEE C COMPUTER VISI
   Pan J, 2016, IEEE C COMPUTER VISI
   Pan J, 2014, EUR C COMPUT VIS, P4762
   Pan JS, 2017, IEEE T PATTERN ANAL, V39, P342, DOI 10.1109/TPAMI.2016.2551244
   Ren DW, 2020, PROC CVPR IEEE, P3338, DOI 10.1109/CVPR42600.2020.00340
   Ren WQ, 2016, IEEE T IMAGE PROCESS, V25, P3426, DOI 10.1109/TIP.2016.2571062
   Schuler CJ, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481418
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Shao WZ, 2020, NEUROCOMPUTING, V413, P305, DOI 10.1016/j.neucom.2020.06.093
   STOCKHAM TG, 1975, P IEEE, V63, P678, DOI 10.1109/PROC.1975.9800
   Sun J, 2015, P IEEE C COMPUTER VI
   Sun L., 2013, IEEE INT C COMPUTATI, P1, DOI [10.1109/ICCPhot.2013.6528301, DOI 10.1109/ICCPHOT.2013.6528301]
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Whyte O, 2014, INT J COMPUT VISION, V110, P185, DOI 10.1007/s11263-014-0727-3
   Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7
   Wiener N., 1949, EXTRAPOLATION INTERP, DOI DOI 10.7551/MITPRESS/2946.001.0001
   Xu L, 2013, P IEEE C COMPUTER VI
   Xu L, 2010, IEEE INT C COMPUTER
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yan RM, 2016, IEEE T IMAGE PROCESS, V25, P1910, DOI 10.1109/TIP.2016.2535273
   Yan YY, 2017, PROC CVPR IEEE, P6978, DOI 10.1109/CVPR.2017.738
   Yasarla R, 2020, IEEE T IMAGE PROCESS, V29, P6251, DOI 10.1109/TIP.2020.2990354
   Zedong Chen, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9917, P296, DOI 10.1007/978-3-319-48896-7_29
NR 56
TC 2
Z9 2
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39121
EP 39144
DI 10.1007/s11042-022-13010-y
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000794850800001
DA 2024-07-18
ER

PT J
AU Kaur, N
   Jindal, N
   Singh, K
AF Kaur, Navneet
   Jindal, Neeru
   Singh, Kulbir
TI An improved approach for single and multiple copy-move forgery detection
   and localization in digital images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move; Image forgery; Geometrical attacks; Precision
ID NETWORK
AB With the expeditious advancement in digital technology and image editing software, it has become easy to manipulate digital images. Copy-move is a common type of image forgery, which threatens the authenticity of digital images by copying and pasting a certain part of the image within the same image. The main focus of this paper is to detect single as well as multiple copy-move forgeries efficiently by combining block-based and keypoint-based detection approaches. The fusion of block-based detection techniques i.e. adaptive over-segmentation (AS) and keypoint-based detection techniques i.e. accelerated KAZE (AKAZE) and scale-invariant feature transform (SIFT) makes the proposed scheme robust against various geometrical attacks as well as less computationally expensive. Moreover, the input image is converted into the different color channels and then, C-r channel is used for further processing because it detects the tampering artifacts left in the image which cannot be observed by human eyes. Also, the copy-move forgery is detected more precisely even in smooth regions due to the extraction of an adequate number of key points. The experimental results are executed on MICC-F220, IMD, GRIP, and COVERAGE datasets, and various performance metrics like precision, recall, F-1 score, and F-2 score are evaluated. The experimental results show that the proposed technique is robust against various geometrical attacks i.e. rotation, scaling, JPEG compression, and noise addition, and proved better when compared with the other existing techniques. Moreover, to ensure the robustness of the proposed approach, the statistical analysis test using ANOVA and cross-dataset performance is evaluated.
C1 [Kaur, Navneet; Jindal, Neeru; Singh, Kulbir] Thapar Inst Engn & Technol, Elect & Commun Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Singh, K (corresponding author), Thapar Inst Engn & Technol, Elect & Commun Engn Dept, Patiala, Punjab, India.
EM ksingh@thapar.edu
RI KAUR, NAVNEET/HMP-0723-2023; Singh, Kulbir/T-7453-2019
OI Singh, Kulbir/0000-0001-8070-3395; , Navneet Kaur/0000-0001-9575-2982
CR Abd El-Latif EI, 2020, ARAB J SCI ENG, V45, P3379, DOI 10.1007/s13369-020-04401-0
   Abd Warif NB, 2016, J NETW COMPUT APPL, V75, P259, DOI 10.1016/j.jnca.2016.09.008
   Abdiansah A., 2015, INT J COMPUT APPL, V128, P28
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alcantarilla PF, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.13
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Asghar K, 2019, MACH VISION APPL, V30, P1243, DOI 10.1007/s00138-019-01048-2
   Bilal M, 2020, ARAB J SCI ENG, V45, P2975, DOI 10.1007/s13369-019-04238-2
   Birajdar GK, 2018, ARAB J SCI ENG, V43, P555, DOI 10.1007/s13369-017-2671-3
   Bravo-Solorio S, 2011, INT CONF ACOUST SPEE, P1880
   Chen HP, 2020, IEEE ACCESS, V8, P36863, DOI 10.1109/ACCESS.2020.2974804
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Dhivya S, 2020, SOFT COMPUT, V24, P14429, DOI 10.1007/s00500-020-04795-x
   El-Alfy ESM, 2017, MULTIMED TOOLS APPL, V76, P14535, DOI 10.1007/s11042-016-3855-7
   Goel N, 2021, IET IMAGE PROCESS, V15, P656, DOI 10.1049/ipr2.12051
   Huang HY, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0469-9
   Kaur N, 2021, TURK J ELECTR ENG CO, V29, P561, DOI 10.3906/elk-2001-138
   Kaur N, 2020, MULTIMED TOOLS APPL, V79, P32037, DOI 10.1007/s11042-020-09275-w
   Kumar A, 2021, IEEE ACCESS, V9, P4364, DOI 10.1109/ACCESS.2020.3048246
   Li YM, 2019, IEEE T INF FOREN SEC, V14, P1307, DOI 10.1109/TIFS.2018.2876837
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manikandan J, 2011, MICROPROCESS MICROSY, V35, P568, DOI 10.1016/j.micpro.2011.06.002
   Meena KB, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102481
   Meena KB, 2020, MULTIMED TOOLS APPL, V79, P8197, DOI 10.1007/s11042-019-08343-0
   Niyishaka P, 2020, MULTIMED TOOLS APPL, V79, P26045, DOI 10.1007/s11042-020-09225-6
   Ojeniyi Joseph A., 2018, International Journal of Image, Graphics and Signal Processing, V10, P22, DOI 10.5815/ijigsp.2018.04.03
   Ouyang JL, 2019, MULTIMED TOOLS APPL, V78, P10207, DOI 10.1007/s11042-018-6605-1
   Ozturk Saban, 2018, Procedia Computer Science, V132, P40, DOI 10.1016/j.procs.2018.05.057
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Prakash CS, 2019, MULTIMED TOOLS APPL, V78, P23535, DOI 10.1007/s11042-019-7629-x
   Priyanka, 2020, MULTIMED TOOLS APPL, V79, P13011, DOI 10.1007/s11042-019-08354-x
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Raschka S., STAT 479: Machine Learning Lecture Notes
   Seong H, 2018, ISARC P INT S AUT RO, P1
   Singh G, 2017, FORENSIC SCI INT, V277, P133, DOI 10.1016/j.forsciint.2017.06.003
   Sun Y, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/1301290
   Sundararajan D., 2011, Fundamentals of the discrete haar wavelet transform
   Tahaoglu G, 2021, MULTIMED TOOLS APPL, V80, P23419, DOI 10.1007/s11042-020-10241-9
   Teerakanok S, 2019, IEEE ACCESS, V7, P40550, DOI 10.1109/ACCESS.2019.2907316
   Tian XX, 2020, IET IMAGE PROCESS, V14, P2092, DOI 10.1049/iet-ipr.2019.1145
   Tinnathi S, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102966
   Wang CY, 2019, IEEE ACCESS, V7, P170032, DOI 10.1109/ACCESS.2019.2955308
   Wang CY, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10120706
   Wen BH, 2016, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2016.7532339
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Zhong JL, 2020, IEEE T INF FOREN SEC, V15, P2134, DOI 10.1109/TIFS.2019.2957693
   Zhu Y, 2020, IEEE T IND INFORM, V16, P6714, DOI 10.1109/TII.2020.2982705
NR 49
TC 3
Z9 3
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38817
EP 38847
DI 10.1007/s11042-022-13105-6
EA APR 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000787666500002
DA 2024-07-18
ER

PT J
AU Ghosh, R
   Kumar, A
AF Ghosh, Rajib
   Kumar, Anupam
TI A hybrid deep learning model by combining convolutional neural network
   and recurrent neural network to detect forest fire
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Forest fire; Deep learning; Convolutional neural network; Recurrent
   neural network
ID REAL-TIME FIRE; FLAME DETECTION; COLOR; RECOGNITION
AB Forest fire poses a serious threat to wildlife, environment, and all mankind. This threat has prompted the development of various intelligent and computer vision based systems to detect forest fire. This article proposes a novel hybrid deep learning model to detect forest fire. This model uses a combination of convolutional neural network (CNN) and recurrent neural network (RNN) for feature extraction and two fully connected layers for final classification. The final feature map obtained from the CNN has been flattened and then fed as an input to the RNN. CNN extracts various low level as well as high level features, whereas RNN extracts various dependent and sequential features. The use of both CNN and RNN for feature extraction is proposed in this article for the first time in the literature of forest fire detection. The performance of the proposed system has been evaluated on two publicly available fire datasets-Mivia lab dataset and Kaggle fire dataset. Experimental results demonstrate that the proposed model is able to achieve very high classification accuracy and outperforms the existing state-of-the-art results in this regard.
C1 [Ghosh, Rajib; Kumar, Anupam] Natl Inst Technol Patna, Dept CSE, Patna, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Ghosh, R (corresponding author), Natl Inst Technol Patna, Dept CSE, Patna, Bihar, India.
EM rajib.ghosh@nitp.ac.in
RI GHOSH, RAJIB/C-9927-2017
OI GHOSH, RAJIB/0000-0002-8553-8656
CR [Anonymous], 2015, P ICLR
   Barmpoutis P, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12193177
   Borges PVK, 2010, IEEE T CIRC SYST VID, V20, P721, DOI 10.1109/TCSVT.2010.2045813
   Celik T, 2007, J VIS COMMUN IMAGE R, V18, P176, DOI 10.1016/j.jvcir.2006.12.003
   Cruz H, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060893
   Du WB, 2018, IEEE T IMAGE PROCESS, V27, P1347, DOI 10.1109/TIP.2017.2778563
   Foggia A, 2015, MIVIA LAB DATASET
   Foggia P, 2015, IEEE T CIRC SYST VID, V25, P1545, DOI 10.1109/TCSVT.2015.2392531
   Ghosh R, 2019, PATTERN RECOGN, V92, P203, DOI 10.1016/j.patcog.2019.03.030
   Gomes P, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/58821
   Gong YJ, 2016, IEEE T CYBERNETICS, V46, P2277, DOI 10.1109/TCYB.2015.2475174
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   Ho CC, 2009, MEAS SCI TECHNOL, V20, DOI 10.1088/0957-0233/20/4/045502
   Khatami A, 2017, EXPERT SYST APPL, V68, P69, DOI 10.1016/j.eswa.2016.09.021
   Kim YH, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/923609
   Kingma D. P., 2014, arXiv
   Larsen A, 2021, J EXPO SCI ENV EPID, V31, P170, DOI 10.1038/s41370-020-0246-y
   Li ZL, 2018, IEEE T IND INFORM, V14, P1146, DOI 10.1109/TII.2017.2768530
   Liu CB, 2004, INT C PATT RECOG, P134, DOI 10.1109/HPD.2004.1346686
   Mahmoud MAI, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/7612487
   Muhammad K, 2019, IEEE T SYST MAN CY-S, V49, P1419, DOI 10.1109/TSMC.2018.2830099
   Park M, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12223715
   Saied A., 2018, FIRE DATASET
   Saripalli S, 2003, IEEE T ROBOTIC AUTOM, V19, P371, DOI 10.1109/TRA.2003.810239
   Sousa MJ., 2020, EXPERT SYST APPL, V11, P142
   Sudhakar S, 2020, COMPUT COMMUN, V149, P1, DOI 10.1016/j.comcom.2019.10.007
   Sun ZW, 2018, J NETW COMPUT APPL, V112, P29, DOI 10.1016/j.jnca.2018.03.023
   Töreyin BU, 2006, PATTERN RECOGN LETT, V27, P49, DOI 10.1016/j.patrec.2005.06.015
   Yuan C, 2016, INT CONF UNMAN AIRCR, P1200, DOI 10.1109/ICUAS.2016.7502546
   Zhang QJ, 2016, ADV SOC SCI EDUC HUM, V47, P568
   Zhao Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030712
NR 31
TC 21
Z9 21
U1 4
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38643
EP 38660
DI 10.1007/s11042-022-13068-8
EA APR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000787139200002
DA 2024-07-18
ER

PT J
AU Pan, JS
   Wei, ZQ
   Zhao, YH
   Zhou, Y
   Lin, XY
   Zhang, W
   Tang, C
AF Pan, Jingshan
   Wei, Zhiqiang
   Zhao, Yuhan
   Zhou, Yan
   Lin, Xunyu
   Zhang, Wei
   Tang, Chang
TI Enhanced FCN for farmland extraction from remote sensing image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE FCN; U-Net; K-Means; DeepLab V3; Semantic segmentation; Farmland
   recognition; Neural networks
ID SUPPORT VECTOR MACHINES; FOOD SECURITY; CLASSIFICATION; AGRICULTURE;
   WATER
AB As farmland being the foundation of national agribusiness, it is of paramount significance to obtain data more efficiently about the distribution of farmland for further agricultural resource monitoring. Through classification of Remote Sensing (RS) images combined with deep learning approaches, however, previous studies did not attach enough attention to boundary ambiguity, thus achieving relatively low accuracy and demands artificial refinements in farmland extraction. To remedy flaws in current approaches and improve overall accuracy, our work reviewed relevant literature and utilized K-Means model, U-Net model and DeelLabV3 model respectively, to refine and make adjustments to farmland extraction model of RS image afterwards. After model training and parameter tuning, the final result of the classification model reached 95.76% in terms of overall accuracy, and the average cross-comparison ratio in farmland recognition rate reached 85.44%. We closed our paper with future directions and possible improvements to our work.
C1 [Pan, Jingshan; Wei, Zhiqiang] Ocean Univ China, Coll Informat Sci & Engn, Qingdao, Peoples R China.
   [Pan, Jingshan; Zhao, Yuhan; Zhou, Yan; Lin, Xunyu; Zhang, Wei] Qilu Univ Technol, Shandong Prov Key Lab Comp Networks, Shandong Comp Sci Ctr, Natl Supercomp Ctr Jinan,Shandong Acad Sci, Jinan, Peoples R China.
   [Tang, Chang] China Univ Geosci, Sch Comp Sci, Wuhan, Peoples R China.
C3 Ocean University of China; Qilu University of Technology; China
   University of Geosciences
RP Wei, ZQ (corresponding author), Ocean Univ China, Coll Informat Sci & Engn, Qingdao, Peoples R China.; Zhao, YH (corresponding author), Qilu Univ Technol, Shandong Prov Key Lab Comp Networks, Shandong Comp Sci Ctr, Natl Supercomp Ctr Jinan,Shandong Acad Sci, Jinan, Peoples R China.
EM weizhiqiang@ouc.edu.cn; yhzhao@sdas.org
RI wei, zhiqiang/M-8868-2013; Tang, Chang/AAU-8995-2020
OI Tang, Chang/0000-0002-6515-7696; Zhao, Yuhan/0000-0003-4792-0464; Pan,
   Jingshan/0009-0002-0968-0658
FU National Natural Science Foundation of China [61802233]; Natural Science
   Foundation of Shandong Province [ZR2019LZH013, ZR2020LZH010]
FX This work was supported by the National Natural Science Foundation of
   China (No.61802233) and Natural Science Foundation of Shandong Province
   (No.ZR2019LZH013 and ZR2020LZH010). Thanks to Qilu University of
   Technology (Shandong Academy of Sciences) Science, Education and
   Industry Integration Innovation Pilot Project "Supercomputer Internet
   Key Technology Research and Application Demonstration". Zhiqiang Wei and
   Yuhan Zhao are the corresponding authors.
CR Addo KA, 2010, REMOTE SENS-BASEL, V2, P497, DOI 10.3390/rs2020497
   Agarap A. F., 2018, ARXIV
   Alshehhi R, 2017, ISPRS J PHOTOGRAMM, V130, P139, DOI 10.1016/j.isprsjprs.2017.05.002
   [Anonymous], 2015, CVPR, DOI DOI 10.1109/CVPR.2015.7298642
   Atzberger C, 2013, REMOTE SENS-BASEL, V5, P949, DOI 10.3390/rs5020949
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Barbedo, 2018, EMBRAPA DOCUMENT SER, V156, P1
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Bulat A, 2016, LECT NOTES COMPUT SC, V9911, P717, DOI 10.1007/978-3-319-46478-7_44
   Buslaev A, 2018, IEEE COMPUT SOC CONF, P197, DOI 10.1109/CVPRW.2018.00035
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Drozdzal M, 2016, LECT NOTES COMPUT SC, V10008, P179, DOI 10.1007/978-3-319-46976-8_19
   Dumoulin V., 2016, A guide to convolution arithmetic for deep learning[J
   Fan EG, 2000, PHYS LETT A, V277, P212, DOI 10.1016/S0375-9601(00)00725-8
   Foody GM, 2004, IEEE T GEOSCI REMOTE, V42, P1335, DOI 10.1109/TGRS.2004.827257
   Gualtieri JA, 1999, P SOC PHOTO-OPT INS, V3584, P221, DOI 10.1117/12.339824
   Han J, 1995, LECT NOTES COMPUT SC, V930, P195
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Honari S, 2016, PROC CVPR IEEE, P5743, DOI 10.1109/CVPR.2016.619
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang C, 2002, INT J REMOTE SENS, V23, P725, DOI 10.1080/01431160110040323
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liang L, 2019, INT J REMOTE SENS, V40, P7252, DOI 10.1080/01431161.2019.1601286
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Maggiori E, 2016, INT GEOSCI REMOTE SE, P5071, DOI 10.1109/IGARSS.2016.7730322
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Nagi J., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P342, DOI 10.1109/ICSIPA.2011.6144164
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi W., 2016, ARXIV PREPRINT ARXIV
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun K., 2019, arXiv:1904.04514
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Thenkabail P., 2009, REMOTE SENSING GLOBA
   Thenkabail PS, 2012, REMOTE SENS-BASEL, V4, P2890, DOI 10.3390/rs4102890
   Thenkabail PS, 2012, PHOTOGRAMM ENG REM S, V78, P773
   Thenkabail PS, 2010, REMOTE SENS-BASEL, V2, P2305, DOI 10.3390/rs2092305
   Thenkabail PS, 2009, INT J REMOTE SENS, V30, P3679, DOI 10.1080/01431160802698919
   Thyagharajan KK, 2019, ARCH COMPUT METHOD E, V26, P275, DOI 10.1007/s11831-017-9239-y
   Valle R, 2018, LECT NOTES COMPUT SC, V11218, P609, DOI 10.1007/978-3-030-01264-9_36
   Vignesh T, 2017, 2017 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES)
   Vignesh T., 2021, PROC INT C COMPUT CO, P1
   Vigneshl T., 2014, Int Conf Sci Eng Manag, P1, DOI DOI 10.1109/ICSEMR.2014.7043591
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Xu L, 2014, ADV NEUR IN, V27
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang ZL, 2018, ADV NEUR IN, V31
   Zhao WQ, 2019, IEEE T SYST MAN CY-S, V49, P1254, DOI 10.1109/TSMC.2017.2724440
NR 55
TC 4
Z9 4
U1 5
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 38123
EP 38150
DI 10.1007/s11042-022-12141-6
EA APR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000785933700002
DA 2024-07-18
ER

PT J
AU Fouda, JSAE
   Koepf, W
AF Fouda, J. S. Armand Eyebe
   Koepf, Wolfram
TI An 8-bit precision cipher for fast image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Multimedia encryption; Information security
ID CHAOTIC BLOCK CIPHER; ARNOLD CAT MAP; PERIOD DISTRIBUTION; DYNAMICAL
   DEGRADATION; SCHEME
AB Implementing chaos based ciphers usually involves 32-bit floating-point arithmetics that is hardware resources costly. The limitation of the computational precision is hardware imposed and transforms chaotic orbits into limit cycles with short periods, hence alters their randomness. In cryptographic applications, short period dynamics and weak randomness result in security issues. In order to address this concern, we propose an 8-bit precision cipher that can be implemented with low-end microprocessors running 8-bit integer arithmetics. The cipher includes a quantized pseudo-random number generator (QPRNG) based on a 16-dimensional quantized Arnold's cat map (QACM). We used entropy measure, statistical, sensitivity and key space analyses to evaluate its security level under limited computational precision. Simulation results attest that it is as highly secure as those involving real-number arithmetics, even for only 8-bit precision. We also showed that the period of the proposed QACM can be chosen such that T-x > 10(27), which is very large as compared to existing QACM. Such a large period implies a high randomness of the derived QPRNG that is confirmed by statistical NIST tests. Contrary to existing ciphers that include other chaotic systems than the QACM for strengthening the security level, ours is exclusively based on the QACM and is fast, despite the included high-dimensional QACM.
C1 [Fouda, J. S. Armand Eyebe] Univ Yaounde I, Fac Sci, Dept Phys, POB 812, Yaounde, Cameroon.
   [Fouda, J. S. Armand Eyebe; Koepf, Wolfram] Univ Kassel, Inst Math, Heinrich Plett Str 40, D-34132 Kassel, Germany.
C3 University of Yaounde I; Universitat Kassel
RP Fouda, JSAE (corresponding author), Univ Yaounde I, Fac Sci, Dept Phys, POB 812, Yaounde, Cameroon.; Fouda, JSAE (corresponding author), Univ Kassel, Inst Math, Heinrich Plett Str 40, D-34132 Kassel, Germany.
EM fouda@mathematik.uni-kassel.de; koepf@mathematik.uni-kassel.de
OI EYEBE FOUDA, Jean Sire Armand/0000-0003-1114-6366
FU Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL.
CR Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   [Anonymous], 1992, NUMERICAL RECIPES C
   Bao JH, 2012, NONLINEAR DYNAM, V70, P1365, DOI 10.1007/s11071-012-0539-3
   BERRY MV, 1987, PROC R SOC LON SER-A, V413, P183, DOI 10.1098/rspa.1987.0109
   BINDER PM, 1986, PHYS REV A, V34, P4460, DOI 10.1103/PhysRevA.34.4460
   Bisht A, 2020, J INTELL SYST, V29, P1246, DOI 10.1515/jisys-2018-0365
   Cai GQ., 2000, J INFORM ENG U, V1, P19
   Chen F, 2014, THEOR COMPUT SCI, V552, P13, DOI 10.1016/j.tcs.2014.08.002
   Chen F, 2013, IEEE T INFORM THEORY, V59, P3249, DOI 10.1109/TIT.2012.2235907
   Chen F, 2012, IEEE T INFORM THEORY, V58, P445, DOI 10.1109/TIT.2011.2171534
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Deng YS, 2015, INFORM SCIENCES, V305, P146, DOI 10.1016/j.ins.2015.01.028
   DYSON FJ, 1992, AM MATH MON, V99, P603, DOI 10.2307/2324989
   Fan CL, 2019, COMPLEXITY, DOI 10.1155/2019/3510985
   Fouda JSAE, 2014, APPL SOFT COMPUT, V25, P435, DOI 10.1016/j.asoc.2014.08.059
   Fouda JSAE, 2014, COMMUN NONLINEAR SCI, V19, P578, DOI 10.1016/j.cnsns.2013.07.016
   Ganesan K, 2014, EUR PHYS J-SPEC TOP, V223, P1611, DOI 10.1140/epjst/e2014-02123-1
   Gu GS, 2014, OPTIK, V125, P4700, DOI 10.1016/j.ijleo.2014.05.023
   Hu HP, 2008, CHAOS SOLITON FRACT, V38, P439, DOI 10.1016/j.chaos.2006.11.027
   Hu HP, 2014, COMMUN NONLINEAR SCI, V19, P1970, DOI 10.1016/j.cnsns.2013.10.031
   Kang S, 2019, MULTIMED TOOLS APPL, V78, P738
   Kassem A, 2014, DIGIT SIGNAL PROCESS, V25, P266, DOI 10.1016/j.dsp.2013.11.004
   Keating JP, 2000, NONLINEARITY, V13, P747, DOI 10.1088/0951-7715/13/3/313
   Kocarev L, 2004, CHAOS, V14, P1078, DOI 10.1063/1.1821671
   Kumar A, 2011, COMMUN NONLINEAR SCI, V16, P372, DOI 10.1016/j.cnsns.2010.04.010
   Li C.J, 2017, GRAPH STRUCTURE GEN, P1
   Li SJ, 2005, INT J BIFURCAT CHAOS, V15, P3119, DOI 10.1142/S0218127405014052
   Liu LF, 2017, INFORM SCIENCES, V396, P1, DOI 10.1016/j.ins.2017.02.031
   Lou DC, 2004, IEEE T MULTIMEDIA, V6, P501, DOI 10.1109/TMM.2004.827493
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Musanna F, 2019, MULTIMED TOOLS APPL, V78, P14867, DOI 10.1007/s11042-018-6827-2
   Nagaraj N, 2008, EUR PHYS J-SPEC TOP, V165, P73, DOI 10.1140/epjst/e2008-00850-4
   Nkandeu YPK, 2019, MULTIMED TOOLS APPL, V78, P10013, DOI 10.1007/s11042-018-6612-2
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Persohn KJ, 2012, CHAOS SOLITON FRACT, V45, P238, DOI 10.1016/j.chaos.2011.12.006
   Sayed WS, 2017, COMPLEXITY, DOI 10.1155/2017/8692046
   Sze, 2007, THESIS CITY U HONG K
   Hue TTK, 2017, EUR PHYS J-SPEC TOP, V226, P2263, DOI 10.1140/epjst/e2016-60401-7
   Zhu HG, 2014, OPTIK, V125, P6672, DOI 10.1016/j.ijleo.2014.06.149
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 40
TC 2
Z9 2
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 34027
EP 34046
DI 10.1007/s11042-022-12368-3
EA APR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784679300019
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Kushwah, AK
   Wadhvani, R
AF Kushwah, Anil Kumar
   Wadhvani, Rajesh
TI Trend triplet based data clustering for eliminating nonlinear trend
   components of wind time series to improve the performance of statistical
   forecasting models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ARIMA model; GAS model; SARIMA model; LSTM model; Trend component; Time
   series data clustering; Wind speed forecasting
ID FEATURE-SELECTION; SPEED; OPTIMIZATION; ALGORITHM
AB Time series forecasting techniques suffer from various issues. One of the significant issues that affect the performance of the forecasting model is the variability present in the components of the time series. The conventional forecasting techniques reduce the nonlinearity by eliminating its non-stationary components. However, improvements in results are often not significant. This paper proposes a wind speed forecasting approach capable of handling the variability present in wind time series components. In this approach, first, nonlinearity in wind time series is eliminated using trend-based clustering, and then statistical methods are applied to develop the forecasting models. The classical time-series data clustering techniques build a small number of clusters based on the distance metric for data values. As time-series data exhibits a serial correlation between subsequent observations, the distance metric cannot group similar data without affecting serial correlation. The proposed method presents novel time-series clustering techniques applied on wind data using triplet (Growing, Decline, and Identical) analysis of trend components to identify similar trend shapes. Once the clusters of identical trend shapes are generated, a cluster is selected based on the Pearson Correlation Coefficient. After that, statistical models (ARIMA, SARIMA, GAS) and the neural network-based model (LSTM) are applied to forecast the selected cluster. The proposed models have superior prediction accuracy than the existing forecasting model, as evidenced by the comparison result curve between actual and forecasted wind speed, the histogram of Friedman ANOVA mean ranks, and the performance measuring indices. The proposed models (C-ARIMA, C-GAS, C-SARIMA, and C-LSTM) enhance the performance of ARIMA, SARIMA, GAS, and LSTM models, and the percentage improvement is 39.66%, 24.16%, 21.02%, and 54.38%, respectively.
C1 [Kushwah, Anil Kumar; Wadhvani, Rajesh] Maulana Azad Natl Inst Technol, Dept Comp Sci & Engn, Bhopal, Madhya Pradesh, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal
RP Kushwah, AK (corresponding author), Maulana Azad Natl Inst Technol, Dept Comp Sci & Engn, Bhopal, Madhya Pradesh, India.
EM akushwah190@gmail.com
RI Wadhvani, Rajesh/C-1966-2017
OI Wadhvani, Rajesh/0000-0002-2048-997X; kushwah, anil/0000-0002-4754-975X
CR Abdoos AA, 2016, NEUROCOMPUTING, V203, P111, DOI 10.1016/j.neucom.2016.03.054
   Brahma B, 2022, MULTIMED TOOLS APPL, V81, P9015, DOI 10.1007/s11042-021-11025-5
   Cadenas E, 2010, RENEW ENERG, V35, P2732, DOI 10.1016/j.renene.2010.04.022
   Chang, 2014, J POWER ENERGY ENG, V2, P161, DOI 10.4236/jpee.2014.24023
   Creal D, 2013, J APPL ECONOMET, V28, P777, DOI 10.1002/jae.1279
   Erdem E, 2011, APPL ENERG, V88, P1405, DOI 10.1016/j.apenergy.2010.10.031
   Farsi M, 2021, ALEX ENG J, V60, P1299, DOI 10.1016/j.aej.2020.10.052
   Guo ZH, 2012, RENEW ENERG, V37, P241, DOI 10.1016/j.renene.2011.06.023
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jie Xu, 2011, 2011 International Conference on Multimedia Technology, P2658
   Kushwah AK, 2019, SADHANA-ACAD P ENG S, V44, DOI 10.1007/s12046-019-1145-6
   Li L, 2013, J HYDRODYN, V25, P56, DOI 10.1016/S1001-6058(13)60338-8
   LI Y, 2021, MULTIMED TOOLS APPL
   Lim BY, 2018, J BANK FINANC, V97, P283, DOI 10.1016/j.jbankfin.2018.10.010
   Ma L, 2009, RENEW SUST ENERG REV, V13, P915, DOI 10.1016/j.rser.2008.02.002
   Mnasri Z, 2022, MULTIMED TOOLS APPL, V81, P5537, DOI 10.1007/s11042-021-11817-9
   Okumus I, 2016, ENERG CONVERS MANAGE, V123, P362, DOI 10.1016/j.enconman.2016.06.053
   Patel Eva, 2020, Procedia Computer Science, V171, P158, DOI 10.1016/j.procs.2020.04.017
   Pinto T, 2014, 2014 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN DYNAMIC AND UNCERTAIN ENVIRONMENTS (CIDUE), P40, DOI 10.1109/CIDUE.2014.7007865
   Salcedo-Sanz S, 2014, ENERG CONVERS MANAGE, V87, P10, DOI 10.1016/j.enconman.2014.06.041
   Santamaría-Bonfil G, 2016, RENEW ENERG, V85, P790, DOI 10.1016/j.renene.2015.07.004
   Shukur OB, 2015, RENEW ENERG, V76, P637, DOI 10.1016/j.renene.2014.11.084
   Su ZY, 2014, ENERG CONVERS MANAGE, V85, P443, DOI 10.1016/j.enconman.2014.05.058
   Torres JL, 2005, SOL ENERGY, V79, P65, DOI 10.1016/j.solener.2004.09.013
   Wang Y, 2018, IEEE T SUSTAIN ENERG, V9, P199, DOI 10.1109/TSTE.2017.2723907
   Xiao LY, 2016, APPL ENERG, V180, P213, DOI 10.1016/j.apenergy.2016.07.113
   Xie, 2011, DYNAMIC VS STATIC AU, DOI 10.2139/ssrn.1268910
   Yang DZ, 2015, ENERGY, V81, P111, DOI 10.1016/j.energy.2014.11.082
   Zhang C, 2017, ENERG CONVERS MANAGE, V143, P360, DOI 10.1016/j.enconman.2017.04.007
   Zhao XY, 2018, ENERG CONVERS MANAGE, V164, P560, DOI 10.1016/j.enconman.2018.03.030
   Zhu EZ, 2019, NEUROCOMPUTING, V363, P149, DOI 10.1016/j.neucom.2019.07.048
NR 31
TC 1
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33927
EP 33953
DI 10.1007/s11042-022-12992-z
EA APR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784679300008
DA 2024-07-18
ER

PT J
AU Zhang, D
   Zhou, ZL
   Han, SY
   Gong, H
   Zou, TY
   Luo, J
AF Zhang, Di
   Zhou, Zhongli
   Han, Suyue
   Gong, Hao
   Zou, Tianyi
   Luo, Jie
TI Deep Metallogenic prediction model construction of the Xiongcun no. II
   orebody based on the DNN algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Xiongcun no; II orebody; Deep learning; DNN; Deep metallogenic
   prediction
ID MAPPING MINERAL PROSPECTIVITY; PORPHYRY COPPER BELT; ARTIFICIAL
   NEURAL-NETWORKS; BIG DATA ANALYTICS; GEOCHEMICAL ANOMALIES; DISTRICT;
   CU; DEPOSITS; MINERALIZATIONS; PROVINCE
AB With the continuous mining and gradual reduction of shallow deposits, deep prospecting has become a new global prospecting trend. In addition, with the development of artificial intelligence, deep learning provides a favorable means for geological big data analysis. This paper, researches the No. II Orebody of the Xiongcun deposit. First, based on previous research results and metallogenic regularity, prospecting information, namely, lithology, Au-Ag-Cu chemical elements and wall rock alteration is extracted, and the block model is established by combining the Kriging interpolation structure. Second, the datasets are divided into dataset I and dataset II according to "randomness" and "depth". Third, deep prospecting prediction models based on deep neural networks (DNN) and the convolutional neural networks (CNN) is constructed, and the model parameters are optimized. Finally, the models are applied to the deep prediction of the Xiongcun No. II Orebody. The results show that the accuracy rate and recall rate of the prediction model based on the DNN algorithm are 96.15% and 89.23%, respectively, and the AUC is 96.39%, which are higher values than those of the CNN algorithm, indicating that the performance of the prediction model based on the DNN algorithm is better. The accuracy of prediction model based on dataset I is higher than that of dataset II. The accuracy of deep metallogenic prediction based on the DNN algorithm is approximately 89%, that based on the CNN is approximately 87%, and that based on prospecting information method is approximately 61.27%. The prediction results of the DNN algorithm are relatively consistent in the spatial location and scale of the orebody. Therefore, based on the work done in this paper, it is feasible to use a deep learning method to carry out deep mineral prediction.
C1 [Zhang, Di; Zhou, Zhongli; Han, Suyue; Gong, Hao; Zou, Tianyi; Luo, Jie] Chengdu Univ Technol, Coll Management Sci, Chengdu 610059, Peoples R China.
   [Zhou, Zhongli; Han, Suyue] Chengdu Univ Technol, Geomath Key Lab Sichuan Prov, Chengdu 610059, Peoples R China.
C3 Chengdu University of Technology; Chengdu University of Technology
RP Zhou, ZL (corresponding author), Chengdu Univ Technol, Coll Management Sci, Chengdu 610059, Peoples R China.; Zhou, ZL (corresponding author), Chengdu Univ Technol, Geomath Key Lab Sichuan Prov, Chengdu 610059, Peoples R China.
EM zzl@cdut.edu.cn
FU National Key R&D Program of China [2018YFC0604105]; National Natural
   Science Foundation of China [42072322]; Chengdu University of Technology
   Development Funding Program for Young and Middle-aged Key Teachers
   [10912-JXGG2020-06251]
FX National Key R&D Program of China (2018YFC0604105); National Natural
   Science Foundation of China (42072322); Chengdu University of Technology
   Development Funding Program for Young and Middle-aged Key Teachers
   (10912-JXGG2020-06251).
CR Amit SNKB, 2017, 2017 INTERNATIONAL ELECTRONICS SYMPOSIUM ON KNOWLEDGE CREATION AND INTELLIGENT COMPUTING (IES-KCIC), P239, DOI 10.1109/KCIC.2017.8228593
   Bang, 2002, GEOLOGY PROSPECTING
   Bianco S, 2017, NEUROCOMPUTING, V245, P23, DOI 10.1016/j.neucom.2017.03.051
   Brown WM, 2000, AUST J EARTH SCI, V47, P757, DOI 10.1046/j.1440-0952.2000.00807.x
   Carranza EJM, 2015, COMPUT GEOSCI-UK, V74, P60, DOI 10.1016/j.cageo.2014.10.004
   Chen YL, 2015, ORE GEOL REV, V71, P749, DOI 10.1016/j.oregeorev.2014.08.012
   Cheng QM, 2012, J GEOCHEM EXPLOR, V122, P55, DOI 10.1016/j.gexplo.2012.07.007
   [邓浩 Deng Hao], 2020, [地球学报, Acta Geoscientia Sinica], V41, P157
   Fallara F., 2006, Exploration and Mining Geology, V15, P27, DOI [10.2113/gsemg.15.1-2.27, DOI 10.2113/GSEMG.15.1-2.27]
   Fan YC, 2015, INT CONF ACOUST SPEE, P4475, DOI 10.1109/ICASSP.2015.7178817
   Gao Y, 2016, ORE GEOL REV, V75, P16, DOI 10.1016/j.oregeorev.2015.12.005
   Guang ZR, 2019, B MINERALOGY PETROLO
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hu WJ, 2016, 2016 IEEE 8TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P667, DOI 10.1109/IS.2016.7737499
   Imamverdiyev Y, 2019, J PETROL SCI ENG, V174, P216, DOI 10.1016/j.petrol.2018.11.023
   Keiller N, 2017, IEEE GEOSCI REMOTE S
   Khare N, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040692
   Kim S, 2016, MATH PROGRAM, V156, P161, DOI 10.1007/s10107-015-0874-5
   Kingma D. P., 2015, PROC INT C LEARN REP, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Lang XH, 2014, J ASIAN EARTH SCI, V79, P608, DOI 10.1016/j.jseaes.2013.08.009
   Leite EP, 2009, GEOPHYS PROSPECT, V57, P1049, DOI 10.1111/j.1365-2478.2008.00779.x
   [李伟 Li Wei], 2020, [地球学报, Acta Geoscientia Sinica], V41, P144
   Li YY, 2018, IEEE ACCESS, V6, P47943, DOI 10.1109/ACCESS.2018.2867435
   Lou DB, 2019, ACTA PETROL SIN, V35, P3407, DOI 10.18654/1000-0569/2019.11.10
   Maas AL, 2017, COMPUT SPEECH LANG, V41, P195, DOI 10.1016/j.csl.2016.06.007
   Martin L, 2007, P EXPL 07 5 DEC INT, P543
   Maskey M, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042608
   Pan M, 2009, ACTA GEOL SIN-ENGL, V83, P655, DOI 10.1111/j.1755-6724.2009.00064.x
   Pan Y, 2018, 3 DIMENSIONAL POSITI
   Porwal A, 2010, ORE GEOL REV, V38, P184, DOI 10.1016/j.oregeorev.2010.04.002
   Priya RMS, 2020, COMPUT COMMUN, V160, P139, DOI 10.1016/j.comcom.2020.05.048
   Ravuri S, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P37, DOI 10.1109/ASRU.2015.7404771
   Ross ZE, 2018, J GEOPHYS RES-SOL EA, V123, P5120, DOI 10.1029/2017JB015251
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saljoughi BS, 2018, APPL GEOMAT, V10, P229, DOI 10.1007/s12518-018-0229-z
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Singer DA, 1996, MATH GEOL, V28, P1017, DOI 10.1007/BF02068587
   SOMAYAJI SRK, 2020, IEEE GLOBE WORK
   Sprague K, 2006, COMPUT GEOSCI-UK, V32, P396, DOI 10.1016/j.cageo.2005.07.008
   Sun T, 2020, MINERALS-BASEL, V10, DOI 10.3390/min10020102
   Tang JX, 2015, ORE GEOL REV, V70, P438, DOI 10.1016/j.oregeorev.2015.02.008
   [王登红 Wang Denghong], 2015, [矿床地质, Mineral Deposits], V34, P1143
   Wang GW, 2011, COMPUT GEOSCI-UK, V37, P1976, DOI 10.1016/j.cageo.2011.05.007
   Wang LQ, 2018, ECOL INDIC, V94, P312, DOI 10.1016/j.ecolind.2018.07.005
   Wang T, 2019, NAT MACH INTELL, V1, P347, DOI 10.1038/s42256-019-0075-7
   Xie FW, 2018, ORE GEOL REV, V96, P98, DOI 10.1016/j.oregeorev.2018.04.013
   Xiong YH, 2018, ORE GEOL REV, V102, P811, DOI 10.1016/j.oregeorev.2018.10.006
   Xu Y, 2014, IEEE SIGNAL PROC LET, V21, P65, DOI 10.1109/LSP.2013.2291240
   Yousefi M, 2017, NAT RESOUR RES, V26, P429, DOI 10.1007/s11053-017-9334-7
   Yu H, 2018, IEEE T NEUR NET LEAR, V29, P4633, DOI 10.1109/TNNLS.2017.2771947
   Zeng GX, 2019, NAT MACH INTELL, V1, P364, DOI 10.1038/s42256-019-0080-x
   Zhang XL, 2013, IEEE T AUDIO SPEECH, V21, P697, DOI 10.1109/TASL.2012.2229986
   Zhang ZJ, 2016, SCI CHINA EARTH SCI, V59, P556, DOI 10.1007/s11430-015-5178-3
   [左仁广 Zuo Renguang], 2021, [地球科学, Earth Science], V46, P350
   Zuo RG, 2019, EARTH-SCI REV, V192, P1, DOI 10.1016/j.earscirev.2019.02.023
   Zuo RG, 2018, NAT RESOUR RES, V27, P5, DOI 10.1007/s11053-017-9357-0
   Zuo RG, 2017, NAT RESOUR RES, V26, P457, DOI 10.1007/s11053-017-9345-4
   Zuo RG, 2011, COMPUT GEOSCI-UK, V37, P1967, DOI 10.1016/j.cageo.2010.09.014
   Zuo RG, 2019, B MINERAL PETROL GEO
NR 61
TC 0
Z9 0
U1 11
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33185
EP 33203
DI 10.1007/s11042-022-13143-0
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784122800004
DA 2024-07-18
ER

PT J
AU Pan, CY
   Huang, J
   Gong, JX
   Hao, JG
AF Pan, Chongyu
   Huang, Jian
   Gong, Jianxing
   Hao, Jianguo
TI Few-shot learning with hierarchical pooling induction network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Few-shot learning; Transfer learning; Hierarchical pooling induction;
   Remote sensing image scene classification
AB Learning to recognize new concepts from few-shot examples is a long-standing challenge in modern computer vision. Metric based few-shot learning is a prevalent way towards this goal where new query instances are classified to the support classes by comparing the query instance with each class prototype. To this end, a representative and discriminative class prototype should necessarily be induced from several support example features. In this work, we propose a simple but effective hierarchical pooling induction method to learn such generalized class-level representations, by concatenating the max pooling and mean pooling operations. The proposed induction method could form a representative prototype for given few-shot samples, enhancing both the discrimination of the intermediate features and the final classification performance. The benchmark miniImageNet dataset and some other practical Remote Sensing Image Scene Classification (RESISC) datasets are employed for generalization investigation and it shows that the proposed induction module could improve the performance of state-of-the-art method and outperforms other alternative induction methods. Qualitative visualization and quantitative analysis are also provided to demonstrate the effectiveness and robustness of the proposed method.
C1 [Pan, Chongyu; Huang, Jian; Gong, Jianxing; Hao, Jianguo] Natl Univ Def Technol, Changsha, Peoples R China.
C3 National University of Defense Technology - China
RP Huang, J (corresponding author), Natl Univ Def Technol, Changsha, Peoples R China.
EM 13548971657@163.com; nudtjHuang@hotmail.com
CR [Anonymous], 2017, Meta networks
   Battaglia, 2018, ARXIV180601261
   Cai Q, 2018, PROC CVPR IEEE, P4080, DOI 10.1109/CVPR.2018.00429
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Finn C, 2017, PR MACH LEARN RES, V70
   Gao H., 2018, P ADV NEURAL INFORM
   Garcia V., 2017, Few-shot learning with graph neural networks
   Geng R, 2019, FEW SHOT TEXT CLASSI
   Grant E., 2018, 6 INT C LEARN REPR
   Hariharan B, 2017, IEEE I CONF COMP VIS, P3037, DOI 10.1109/ICCV.2017.328
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Iyyer M, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1681
   Joulin A., 2017, P 15 C EUR CHAPT ASS, P427, DOI DOI 10.18653/V1/E17-2068
   Kaiser Lukasz, 2017, ICLR
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Lee Y, 2018, PR MACH LEARN RES, V80
   Li Z., 2017, Meta-sgd: Learning to learn quickly for few-shot learning
   Liu YH, 2019, INT J PSYCHIAT CLIN, V23, P164, DOI 10.1080/13651501.2019.1569238
   Luca B, 2016, NEURAL INFORM PROCES
   Ravi S., 2016, INT C LEARNING REPRE
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Rusu A. A., 2019, INT C LEARN REPR
   Sabour S, 2017, ADV NEUR IN, V30
   Salvaris M, 2018, GENERATIVE ADVERSARI, P187
   Santoro A, 2016, PR MACH LEARN RES, V48
   Schwartz E., 2018, Delta-encoder: an effective sample synthesis method for few-shot object recognition
   Shen DH, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P440
   Snell J, 2017, ADV NEUR IN, V30
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Thomas E, 2020, COMPUT VIS PATTERN R, P12362
   Tyler R S, 2018, NEURAL INFORM PROCES
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wang YX, 2018, PROC CVPR IEEE, P7278, DOI 10.1109/CVPR.2018.00760
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Yan SP, 2019, AAAI CONF ARTIF INTE, P9079
   Yoon SW, 2019, PR MACH LEARN RES, V97
NR 38
TC 0
Z9 0
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 32937
EP 32952
DI 10.1007/s11042-022-11999-w
EA APR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000782717900003
DA 2024-07-18
ER

PT J
AU Li, GD
   Xu, XL
   Zhong, HY
AF Li, Guodong
   Xu, Xiangliang
   Zhong, Huiyan
TI A image encryption algorithm based on coexisting multi-attractors in a
   spherical chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spherical chaotic systems; Dynamical properties; Image encryption; DCT
   transform; Security
AB In recent years, chaotic systems have been widely used in several engineering fields. In this paper, an image encryption algorithm for multi-attractor coexistence-spherical chaotic systems is proposed. Various dynamics of the spherical chaotic system are analyzed in detail to ensure that the system can produce a high complexity mask block with optimal parameters. The encryption algorithm consists of three main phases, image reconstruction, confusion and diffusion. In the reconstruction phase, the two-dimensional (2D) discrete cosine transform (DCT) is used to compress and reconstruct the image efficiently and eliminate image redundancy. In the obfuscation phase, use Logistic map to shuffle the image pixels of arbitrary size. In the diffusion stage, a mask sequence with high complexity is randomly selected based on the image information and the encryption date, and the scrambled image is subjected to add-and-take mode and cyclic shift diffusion operations. The experimental results and several security analyses show that the algorithm has a large enough key space. The ciphertext adjacent pixel correlation is almost zero. The number of pixel change rate (NPCR) is 99.6123% and the uniform average change intensity (UACI) is 33.4638%, which basically close to the theoretical values. The encryption speed is 30.327 ms and execution time is 69.151Mbps. The key sensitivity is strong, and the algorithm can effectively resist known plaintext and selective plaintext attacks, as well as shear and noise attacks. The encryption scheme has good encryption effect in terms of security and efficiency, and is very suitable for practical application.
C1 [Li, Guodong; Xu, Xiangliang; Zhong, Huiyan] Guilin Univ Elect Technol Guilin, Sch Math & Computat Sci, Guilin 541004, Guangxi, Peoples R China.
   [Xu, Xiangliang] Univ Elect Sci & Technol China, Sch Informat & Software Engn, Chengdu 610054, Peoples R China.
   [Li, Guodong] Guilin Univ Elect Technol, Guangxi Collages & Univ Key Lab Data Anal & Compu, Guilin 541004, Peoples R China.
C3 University of Electronic Science & Technology of China; Guilin
   University of Electronic Technology
RP Li, GD (corresponding author), Guilin Univ Elect Technol Guilin, Sch Math & Computat Sci, Guilin 541004, Guangxi, Peoples R China.; Li, GD (corresponding author), Guilin Univ Elect Technol, Guangxi Collages & Univ Key Lab Data Anal & Compu, Guilin 541004, Peoples R China.
EM lgdzhy@126.com; xd160622@126.com
RI Zhong, Huiyan/GQQ-9903-2022; Xu, Xiang-Liang/GVS-0257-2022; Li,
   Guodong/JDX-1233-2023
OI Zhong, Huiyan/0000-0002-6102-3148; Xu, Xiang-Liang/0000-0002-7675-113X;
   Li, Guodong/0000-0003-1275-2982
FU Natural Science Foundation of Guangxi province; Guilin University of
   Electronic Technology Fund [C21YJM00QX99]; Innovation Project of GUET
   Graduate Education [2021YCXS119, 2022YCX139]; Data Analysis and
   Computing Laboratory of Guangxi University Key Laboratory
FX This work was funded by Natural Science Foundation of Guangxi province
   (The image encryption model design based on cellular neural network and
   generalized chaotic synchronization theory), Guilin University of
   Electronic Technology Fund (No. C21YJM00QX99), the Innovation Project of
   GUET Graduate Education (No.2021YCXS119, No.2022YCX139) and supported by
   Data Analysis and Computing Laboratory of Guangxi University Key
   Laboratory.
CR Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Bandt C, 2002, PHYS REV LETT, V88, DOI 10.1103/PhysRevLett.88.174102
   Bentoutou Y, 2020, ADV SPACE RES, V66, P176, DOI 10.1016/j.asr.2019.09.027
   Chen AM, 2006, PHYSICA A, V364, P103, DOI 10.1016/j.physa.2005.09.039
   Chen C, 2020, SIGNAL PROCESS, V168, DOI 10.1016/j.sigpro.2019.107340
   Chen GR, 1999, INT J BIFURCAT CHAOS, V9, P1465, DOI 10.1142/S0218127499001024
   Chen JX, 2015, NONLINEAR DYNAM, V81, P1151, DOI 10.1007/s11071-015-2057-6
   CHUA LO, 1986, IEEE T CIRCUITS SYST, V33, P1072, DOI 10.1109/TCS.1986.1085869
   Dai WY, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14010017
   Elgendy F, 2016, MULTIMED TOOLS APPL, V75, P11529, DOI 10.1007/s11042-015-2883-z
   Elwakil AS, 2002, IEEE T CIRCUITS-I, V49, P527, DOI 10.1109/81.995671
   Elwakil AS, 2001, IEEE T CIRCUITS-I, V48, P289, DOI 10.1109/81.915386
   Jinhui Z., 2011, INFORM NETWORK SECUR, V05, P37
   Lin Y, 2016, PRAMANA-J PHYS, V86, P801, DOI 10.1007/s12043-015-1118-1
   Liu HJ, 2019, OPT LASER ENG, V122, P123, DOI 10.1016/j.optlaseng.2019.05.027
   Liu TM, 2021, CHAOS SOLITON FRACT, V145, DOI 10.1016/j.chaos.2021.110791
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Lü JH, 2002, INT J BIFURCAT CHAOS, V12, P659, DOI 10.1142/S0218127402004620
   Mahmoud EE, 2012, MATH COMPUT MODEL, V55, P1951, DOI 10.1016/j.mcm.2011.11.053
   Murillo-Escobar MA, 2015, EXPERT SYST APPL, V42, P8198, DOI 10.1016/j.eswa.2015.06.035
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Patel R, 2021, MULTIMEDIA SYST, V27, P985, DOI 10.1007/s00530-021-00763-z
   Patel R, 2021, MATH METHOD APPL SCI, DOI 10.1002/mma.7681
   Song XM, 2021, J WEB ENG, V20, P1115, DOI 10.13052/jwe1540-9589.20410
   SPROTT JC, 1994, PHYS REV E, V50, pR647, DOI 10.1103/PhysRevE.50.R647
   Sprott JC, 2000, PHYS LETT A, V266, P19, DOI 10.1016/S0375-9601(00)00026-8
   Sprott JC, 2000, AM J PHYS, V68, P758, DOI 10.1119/1.19538
   Sun KH, 2013, ACTA PHYS SIN-CH ED, V62, DOI 10.7498/aps.62.010501
   Wang SC, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2019.105995
   Wang XY, 2020, OPT LASER ENG, V125, DOI 10.1016/j.optlaseng.2019.105851
   Wang XY, 2016, NONLINEAR DYNAM, V83, P333, DOI 10.1007/s11071-015-2330-8
   Xie Shuangjian, 2011, COMPUTER TECHNOLOGY, P164
   Xu XL, 2021, FRACTALS, V29, DOI 10.1142/S0218348X21502455
   Yan MX, 2020, EUR PHYS J PLUS, V135, DOI 10.1140/epjp/s13360-020-00456-y
   Ye GD, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107563
   Yu Y, 2021, MICROMACHINES-BASEL, V12, DOI 10.3390/mi12111418
   Zhong HY, 2022, MULTIMED TOOLS APPL, V81, P24757, DOI 10.1007/s11042-022-12479-x
   Zhu SQ, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22070772
NR 38
TC 18
Z9 18
U1 5
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32005
EP 32031
DI 10.1007/s11042-022-12853-9
EA APR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781124000004
DA 2024-07-18
ER

PT J
AU Kumar, SS
   Kumar, KS
   Nagarajan, D
AF Kumar, S. Sasi
   Kumar, K. Siva
   Nagarajan, D.
TI Video compression using MPEG 7-MBBMC: techniques for communication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Communication Discrete Wavelet Transform (DWT); Modified block based
   motion compensated (MBBMC); Forward Error correction (FEC); Channel
   Pattern Integration (CPI)
AB Communication is termed as exchanging the information (audio, video, text and image) from one end (transmitter) to another end (receiver). When video data are compressed and transmitted to another side, compression reduces the bandwidth size and memory required to transmit the video. Some traditional techniques are used in video transmission but it includes drawbacks, such as more compression time and low quality due to compression. To overcome these drawbacks the MPEG7-MBBMC (Modified Block Based Motion Compensated) technique is developed. Here the input video signals are collected from the dataset and the signals are splitted into three bands. Discrete Wavelet Transform (DWT) is applied for each band and quantization process occurs. The DWT and quantization process are applied in the MPEG7 compression, which offers high compression factors. Next, encoder is applied to convert the packets into small packets by using modified block based motion compensated (MBBMC) technique. The Motion compensation establishes a correspondence between elements of nearby images in the video sequence. The Forward Error Correction (FEC) is used to reduce the distortion in the encoder video packet. Then the Channel Pattern Integration (CPI) is applied to find the best available channel. The encoded video packets are transmitted by the best available channel. In receiver side the error correction code is applied to decode the video packets and reconstructs the decoded packet by decompression. It improves the quality of the video and in future it will help for much development in the field of multimedia.
C1 [Kumar, S. Sasi] Hindustan Inst Technol & Sci, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
   [Kumar, K. Siva] Roever Engn Coll, Dept Comp Sci & Engn, Perambalur, Tamil Nadu, India.
   [Nagarajan, D.] Rajalakshmi Inst Technol, Dept Math, Chennai, Tamil Nadu, India.
C3 Hindustan Institute of Technology & Science
RP Nagarajan, D (corresponding author), Rajalakshmi Inst Technol, Dept Math, Chennai, Tamil Nadu, India.
EM drssk75@gmail.com; sivakumarame2004@gmail.com; dnrmsu2002@yahoo.com
RI DEIVANAYAGAMPILLAI, NAGARAJAN/P-4665-2014; s, sasikumar/AAG-1209-2021
OI DEIVANAYAGAMPILLAI, NAGARAJAN/0000-0003-1411-532X; s,
   sasikumar/0000-0001-9732-3268
CR Anagnostopoulos N, 2014, SEARCHING IMAGES MPE
   Bachu S, 2018, J KING SAUD UNIV-COM, V30, P249, DOI 10.1016/j.jksuci.2016.07.002
   Camargo L. H., 2013, DIAGN PATHOL, V8, pS38
   Chen ZB, 2020, IEEE T CIRC SYST VID, V30, P566, DOI 10.1109/TCSVT.2019.2892608
   Choi Young-Ju, 2019, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V22, P770, DOI 10.9717/kmms.2019.22.7.770
   HoangVan X, 2017, IEEE T CIRC SYST VID, V27, P1761, DOI 10.1109/TCSVT.2016.2543120
   Huo YK, 2013, IEEE T CIRC SYST VID, V23, P1622, DOI 10.1109/TCSVT.2013.2254911
   Jha MK, 2018, MULTIMEDIA SYST, V24, P271, DOI 10.1007/s00530-017-0543-z
   Kamble SD, 2017, INT J INTERACT MULTI, V4, P27, DOI 10.9781/ijimai.2017.444
   Kumar K, 2016, INT J COMPUT APPL, V137
   Kumar MPH, 2017, SURVEY CONTENT BASED, V4, P22
   Muhammad G, 2014, BIOMED SIGNAL PROCES, V11, P1, DOI 10.1016/j.bspc.2014.02.001
   Shih CH, 2016, COMPUT NETW, V105, P89, DOI 10.1016/j.comnet.2016.05.016
   Wu JY, 2015, MULTIMED TOOLS APPL, V74, P4117, DOI 10.1007/s11042-013-1813-1
   Xing M, 2014, IEEE J SEL AREA COMM, V32, P795, DOI 10.1109/JSAC.2014.140411
NR 15
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31421
EP 31441
DI 10.1007/s11042-022-12528-5
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781336100003
DA 2024-07-18
ER

PT J
AU Chia, TL
   Chen, HJ
   Huang, PS
AF Chia, Tsorng-Lin
   Chen, Hsiang-Ju
   Huang, Ping-Sheng
TI Anamorphic imaging system for the moving viewer by projecting onto two
   orthogonal planes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anamorphosis; Stereoscopic images; Perspective projection; Projector
AB The demands for stereoscopic images are rapidly growing in recent years. However, complicated system installation and expensive devices are usually required for those applications. Also, the restrictions of visual angles and the problem of slowly displaying the contents still exist. Furthermore, the traditional applications of anamorphosis are confined to fixed viewing positions with static content. Motivated by solving those problems, this paper presents an imaging system using one projector and perspective projection to generate static and dynamic anamorphic images. Then 3D images can be superimposed and displayed above two orthogonal planes. Furthermore, not only the images can be watched at a fixed position, but the function of demonstrating anamorphic images to viewers standing at different positions can also be achieved. Experimental results have shown that the proposed algorithms can successfully fulfil those two requirements. By using perspective projection to produce static and dynamic anamorphic images, this system can diversify the usage of stereoscopic images, provide high-quality images, and enhance the 3D visual effect. Also, those functions can increase the system variety in different applications of object demonstration.
C1 [Chia, Tsorng-Lin; Chen, Hsiang-Ju] Ming Chuan Univ, Dept Comp & Commun Engn, Taoyuan, Taiwan.
   [Huang, Ping-Sheng] Ming Chuan Univ, Dept Elect Engn, Taoyuan 333, Taiwan.
C3 Ming Chuan University; Ming Chuan University
RP Huang, PS (corresponding author), Ming Chuan Univ, Dept Elect Engn, Taoyuan 333, Taiwan.
EM tlchia@mail.mcu.edu.tw; never_changing03@yahoo.com.tw;
   pshuang@mail.mcu.edu.tw
CR Beever J, 2020, JULIAN BEEVER PAVEME
   Benk MP, 2016, J MICRO-NANOLITH MEM, V15, DOI 10.1117/1.JMM.15.3.033501
   Chris SBS, 2019, PROCEDIA COMPUT SCI, V165, P774, DOI 10.1016/j.procs.2020.01.012
   De Comite F, 2015, SIGGRAPH ASIA 2015 A, P1
   Hansford D, 2007, COMPUTING, V79, P211, DOI 10.1007/s00607-006-0199-6
   Hsu CH, 2017, MULTIMED TOOLS APPL, V76, P9245, DOI 10.1007/s11042-016-3531-y
   Hunt JL, 2000, AM J PHYS, V68, P232, DOI 10.1119/1.19406
   Kent P., 2020, Art of Anamorphosis
   Lhachemi H, 2019, IEEE ACCESS, V7, P50119, DOI 10.1109/ACCESS.2019.2907287
   MAJUMDER A, 2002, P ACM VIRT REAL SOFT, P147
   Murra D, 2014, APPL PHYS B-LASERS O, V117, P145, DOI 10.1007/s00340-014-5814-1
   Sukthankar R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P247, DOI 10.1109/ICCV.2001.937525
   Szeliski R, 2011, TEXTS COMPUT SCI, P181, DOI 10.1007/978-1-84882-935-0_4
   Zdziarski A., 2017, TECHNICAL T 2020, V1, P25, DOI DOI 10.4467/2353737XCT.17.002.6099
   Zdziarski A., 2015, TECHNICAL T ARCHITEC, V10, P97
NR 15
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 15389
EP 15412
DI 10.1007/s11042-021-11875-z
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000781336500002
DA 2024-07-18
ER

PT J
AU Luo, YH
   Cao, X
   Zhang, JT
   Guo, JJ
   Shen, HB
   Wang, TJ
   Feng, Q
AF Luo, Yihao
   Cao, Xiang
   Zhang, Juntao
   Guo, Jingjuan
   Shen, Haibo
   Wang, Tianjiang
   Feng, Qi
TI CE-FPN: enhancing channel information for object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Feature pyramid network; Channel enhancement;
   Sub-pixel convolution
ID DEEP
AB Feature pyramid network (FPN) has been an efficient framework to extract multi-scale features in object detection. However, current FPN-based methods mostly suffer from the intrinsic flaw of channel reduction, which brings about the loss of semantical information. And the miscellaneous feature maps may cause serious aliasing effects. In this paper, we present a novel channel enhancement feature pyramid network (CE-FPN) to alleviate these problems. Specifically, inspired by sub-pixel convolution, we propose sub-pixel skip fusion (SSF) to perform both channel enhancement and upsampling. Instead of the original 1 x 1 convolution and linear upsampling, it mitigates the information loss due to channel reduction. Then we propose sub-pixel context enhancement (SCE) for extracting stronger feature representations, which is superior to other context methods due to the utilization of rich channel information by sub-pixel convolution. Furthermore, we introduce a channel attention guided module (CAG) to optimize the final integrated features on each level. It alleviates the aliasing effect only with a few computational burdens. We evaluate our approaches on Pascal VOC and MS COCO benchmark. Extensive experiments show that CE-FPN achieves competitive performance and is more lightweight compared to state-of-the-art FPN-based detectors.
C1 [Luo, Yihao; Cao, Xiang; Zhang, Juntao; Shen, Haibo; Wang, Tianjiang; Feng, Qi] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Guo, Jingjuan] Jiujiang Univ, Sch Informat Sci & Technol, Jiujiang 332005, Peoples R China.
C3 Huazhong University of Science & Technology; Jiujiang University
RP Feng, Q (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM luoyihao@hust.edu.cn; caoxiang112@hust.edu.cn; zhangjt0902@hust.edu.cn;
   jingjuan_guo@163.com; d202081088@hust.edu.cn; tjwang@hust.edu.cn;
   fengqi@hust.edu.cn
RI Cao, Xiang/ACT-7733-2022
OI Cao, Xiang/0000-0002-8813-9669; Zhang, Juntao/0000-0001-8174-5378
FU National Natural Science Foundation of China [61572214]; Seed Foundation
   of Huazhong University of Science and Technology [2020kfyXGYJ114]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61572214, and Seed Foundation of
   Huazhong University of Science and Technology (2020kfyXGYJ114).
CR Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Cao J., 2020, Attention-guided Context Feature Pyramid Network for Object Detection, DOI 10.48550/arXiv.2005.11475
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Chaoxu Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12592, DOI 10.1109/CVPR42600.2020.01261
   Chen K, 2021, ARXIV210704191
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Chen Z, 2018, LECT NOTES COMPUT SC, V11212, P74, DOI 10.1007/978-3-030-01237-3_5
   Chen ZJ, 2020, SAFETY SCI, V130, DOI 10.1016/j.ssci.2020.104812
   Chen ZJ, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.06.041
   Chen ZJ, 2019, IEEE INTEL TRANSP SY, V11, P41, DOI 10.1109/MITS.2019.2903525
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Feng P, 2018, NEUROCOMPUTING, V308, P245, DOI 10.1016/j.neucom.2018.05.007
   Ge HL, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12030434
   Ge Z, 2021, NEUROCOMPUTING, V425, P107, DOI 10.1016/j.neucom.2020.10.098
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Guo JJ, 2020, MULTIMED TOOLS APPL, V79, P29551, DOI 10.1007/s11042-020-09500-6
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Juocas L, 2019, INT J ADV MANUF TECH, V102, P3217, DOI 10.1007/s00170-019-03407-9
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li HY, 2019, INT J COMPUT VISION, V127, P225, DOI 10.1007/s11263-018-1101-7
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YD, 2020, AAAI CONF ARTIF INTE, V34, P11653
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Pang YW, 2021, IEEE T IMAGE PROCESS, V30, P207, DOI 10.1109/TIP.2020.3034487
   Paszke A, 2019, ADV NEUR IN, V32
   Qin Z, 2019, IEEE I CONF COMP VIS, P6717, DOI 10.1109/ICCV.2019.00682
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang JQ, 2019, IEEE I CONF COMP VIS, P3007, DOI 10.1109/ICCV.2019.00310
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   YANG S, 2016, PROC CVPR IEEE, P5525, DOI DOI 10.1109/CVPR.2016.596
   Yu XY, 2017, PROC CVPR IEEE, P67, DOI 10.1109/CVPR.2017.15
   Yuan CH, 2019, MULTIMED TOOLS APPL, V78, P21145, DOI 10.1007/s11042-019-7446-2
   Zaidi SSA, 2021, ARXIV210411892
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhou B, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19224855
   Zhu YS, 2019, IEEE T IMAGE PROCESS, V28, P113, DOI 10.1109/TIP.2018.2865280
NR 55
TC 58
Z9 62
U1 9
U2 65
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30685
EP 30704
DI 10.1007/s11042-022-11940-1
EA APR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779233200004
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Fu, T
   Xia, M
   Yang, GB
AF Fu, Tao
   Xia, Ming
   Yang, Gaobo
TI Detecting GAN-generated face images via hybrid texture and sensor noise
   based features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE GAN; Face synthesis; Image forensics; handcrafted features
ID NETWORKS
AB Recent advances in Generative Adversarial Network (GAN) have made it considerably easy to generate photo-realistic images. However, when GAN-synthesized face images are used maliciously, they will lead to severe moral, ethical, and legal issues. To expose GAN-generated face images, most existing works rely heavily on deep models, which are costly and time-consuming. In this work, we propose a blind approach to detect GAN-generated face images by handcrafted features. Due to the differences of the inherent formation mechanism, nature and GAN-generated face images exhibit different texture and sensor noises, which are exploited as the clues to expose the GAN-generated face images. Specifically, uniform local binary pattern (LBP) features from real face and generated face images, and extract subtractive pixel adjacency matrix (SPAM) features in their sensor noises. Both features are fed to support vector machine (SVM) classifier to verify the authenticity of the face images. The result shows that our proposed approach can successfully detect GAN-generated fake face images with an accuracy up to 97.60%. Furthermore, it can distinguishing the fake face images generated by different GANs.
C1 [Fu, Tao; Xia, Ming; Yang, Gaobo] Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
C3 Hunan University
RP Yang, GB (corresponding author), Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
EM yanggaobo@hnu.edu.cn
RI Bueno, Regis Cortez/AAG-3852-2020
OI Bueno, Regis Cortez/0000-0002-2923-4930; Yang, Gaobo/0000-0003-2734-659X
FU National Natural Science Foundation of China [61972143, 61972142];
   Natural Science Foundation of Hunan Province, China [2020JJ4626];
   Scientific Research Foundation of Hunan Provincial Education Department
   of China [19B004]
FX This work is supported in part by the National Natural Science
   Foundation of China (61972143, 61972142), the Natural Science Foundation
   of Hunan Province, China (2020JJ4626) and the Scientific Research
   Foundation of Hunan Provincial Education Department of China (19B004).
CR Afchar D, 2018, IEEE INT WORKS INFOR
   [Anonymous], 2020, FORENSICS FACE DETEC
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Dang LM, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122610
   Dirik AE, 2007, IEEE IMAGE PROC, P2129
   Dirik AE, 2003, P CVPR WORKSH, P94
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hsu CC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010370
   Hsu CC, 2018, INT SYMP COMP CONS, P388, DOI 10.1109/IS3C.2018.00104
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Karras T, 2018, P INT C LEARN REPR I
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Korshunov P, 2020, ARXIV181208685
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li YJ, 2017, PROC CVPR IEEE, P5892, DOI 10.1109/CVPR.2017.624
   Li Z., 2013, INT WORKSHOP DIGITAL, P228, DOI 10.1007/978-3-642-40099-519
   Li ZH, 2014, SECUR COMMUN NETW, V7, P2153, DOI 10.1002/sec.929
   Marra F, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P384, DOI 10.1109/MIPR.2018.00084
   McCloskey S, 2020, ARXIV181208247
   Mo HX, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P43, DOI 10.1145/3206004.3206009
   Nataraj L, 2020, ARXIV190306836
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Peng F., 2014, Transportation Electrification Conference and Expo (ITEC), P1
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Quan WZ, 2018, IEEE T INF FOREN SEC, V13, P2772, DOI 10.1109/TIFS.2018.2834147
   Radford A., 2015, ARXIV
   Rao Y, 2016, IEEE INT WORKS INFOR
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sonderby K., 2020, ARXIV161004490
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Xuan X, 2020, ARXIV190211153
   Yang X, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P113, DOI 10.1145/3335203.3335724
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Zhang X, 2020, ARXIV190706515
   Zhang Y, 2016, CRYPTOL INF SEC SER, V14, P1, DOI 10.3233/978-1-61499-617-0-1
   Zhu J-Y, 2020, ARXIV171111586
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 43
TC 5
Z9 5
U1 3
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26345
EP 26359
DI 10.1007/s11042-022-12661-1
EA MAR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000773205900001
DA 2024-07-18
ER

PT J
AU Gupta, S
   Shekhar, S
   Karpe, K
   Ghosh, A
   Gautham, JS
   Srinivas, P
   Kumar, M
   Sharma, P
   Sinha, A
   Singh, K
   Ramamoorthy, K
   Dhanalakshmi, S
AF Gupta, Shreshtha
   Shekhar, Shashank
   Karpe, Kedar
   Ghosh, Aninda
   Gautham, J. S.
   Srinivas, Pranav
   Kumar, Mayank
   Sharma, Preshit
   Sinha, Avinash
   Singh, Kushagra
   Ramamoorthy, Kumar
   Dhanalakshmi, Samiappan
TI LOGISWARM: A low-cost multi-robot testbed for cooperative transport
   research
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LOGISWARM; Multi-robot testbed; Automated guided vehicles; BudgeBOT
ID VEHICLES; SWARM
AB An increased demand in the market for various commodities, especially FMCGs (Fast Moving Consumer Goods) requires warehouses to stock up an increased number of items which keep renewing rapidly. Conventional methods of warehouse logistics employ mixed use of human labor and Automated Guided Vehicles (AGVs) which involve a lot of cost for running and maintenance, and come with a number of limitations. Hence, technological innovations such as a group of robots, can be used to assist warehouse logistics in a novel and efficient manner. This paper presents a low-cost multi-robot testbed - LOGISWARM, a model which can be used to study how a group of robots can be employed for warehouse logistics and related applications. Each robot in the system is called a BudgeBOT, which is a two-wheeled differential drive robot. A feedback system consisting of overhead camera(s) is also used to constantly monitor and correct error(s) which arise during the transportation of payload. LOGISWARM can act as a research platform which can be used to develop and study multi-robot cooperative transport mechanisms and their behavior for different payload form factors, robot configurations, and applications; alongside being inexpensive, easy to develop and resistant to overall system failure.
C1 [Gupta, Shreshtha; Shekhar, Shashank; Karpe, Kedar; Gautham, J. S.; Srinivas, Pranav; Kumar, Mayank; Sharma, Preshit; Sinha, Avinash; Ramamoorthy, Kumar; Dhanalakshmi, Samiappan] SRM Inst Sci & Technol, Dept Elect & Commun Engn, Kattankulathur, India.
   [Ghosh, Aninda; Singh, Kushagra] SRM Inst Sci & Technol, Dept Comp Sci Engn, Kattankulathur, India.
C3 SRM Institute of Science & Technology Chennai; SRM Institute of Science
   & Technology Chennai
RP Ramamoorthy, K (corresponding author), SRM Inst Sci & Technol, Dept Elect & Commun Engn, Kattankulathur, India.
EM sr1606@srmist.edu.in; ss9535@srmist.edu.in;
   kedarprasad_pra@srmuniv.edu.in; aa5842@srmist.edu.in;
   gj8938@srmist.edu.in; pm4456@srmist.edu.in; mn4715@srmist.edu.in;
   ps6198@srmist.edu.in; aa9691@srmist.edu.in; ks8313@srmist.edu.in;
   kumarr@srmist.edu.in; dhanalas@srmist.edu.in
RI Dhanalakshmi, S./J-2073-2018
OI Dhanalakshmi, S./0000-0002-6970-2719
FU SRM Institute of Science and Technology
FX The authors would like to thank SRM Institute of Science and Technology
   for funding this project. We are also thankful to our teammates at
   Beeclust Multi-Robot Systems lab for their constant support.
CR Beinschob P, 2017, ROBOT AUTON SYST, V87, P281, DOI 10.1016/j.robot.2016.10.018
   Cardarelli E, 2017, MECHATRONICS, V45, P1, DOI 10.1016/j.mechatronics.2017.04.005
   Cashmore M, 2015, P I C AUTOMAT PLAN S, P333
   Chen JN, 2015, IEEE T ROBOT, V31, P307, DOI 10.1109/TRO.2015.2400731
   Dudek G., 2010, Computational Principles of Mobile Robotics", V2, DOI DOI 10.1017/CBO9780511780929
   Egerstedt M, 2012, IEEE CONTR SYST MAG, V32, P66, DOI 10.1109/MCS.2012.2195411
   Fan Zhang, 2010, Proceedings 2010 First International Conference on Pervasive Computing, Signal Processing and Applications (PCSPA 2010), P216, DOI 10.1109/PCSPA.2010.60
   Parra-González EF, 2009, CERMA: 2009 ELECTRONICS ROBOTICS AND AUTOMOTIVE MECHANICS CONFERENCE, P119, DOI 10.1109/CERMA.2009.54
   Hwang K. S., 2014, 2014 IEEE International Conference on Automation Science and Engineering (CASE), P1182, DOI 10.1109/CoASE.2014.6899476
   Karpe K, 2019, 2019 19TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P733, DOI [10.1109/ICAR46387.2019.8981621, 10.1109/icar46387.2019.8981621]
   Khan D, 2018, IEEE ACCESS, V6, P22421, DOI 10.1109/ACCESS.2018.2801028
   Krogius M, 2019, IEEE INT C INT ROBOT, P1898, DOI [10.1109/iros40897.2019.8967787, 10.1109/IROS40897.2019.8967787]
   Lightbody P, 2017, APPL COMPUT REV, V17, P28, DOI 10.1145/3161534.3161537
   Medina O, 2020, IEEE ACCESS, V8, P53141, DOI 10.1109/ACCESS.2020.2979929
   Mehami J, 2018, PROCEDIA MANUF, V26, P1077, DOI 10.1016/j.promfg.2018.07.144
   Mondada F., 2009, P 9 C AUT ROB SYST C
   Pickem D, 2015, IEEE INT CONF ROBOT, P4062, DOI 10.1109/ICRA.2015.7139767
   Qin JH, 2019, IEEE T NEUR NET LEAR, V30, P85, DOI 10.1109/TNNLS.2018.2832025
   Rubenstein M, 2012, IEEE INT CONF ROBOT, P3293, DOI 10.1109/ICRA.2012.6224638
   Sagitov A, 2017, ICINCO: PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS - VOL 2, P182, DOI 10.5220/0006478901820191
   Satoshi Makita, 2018, SURVEY ROBOTIC CAGIN, V36, P316, DOI [10.7210/jrsj.36.316, DOI 10.7210/JRSJ.36.316]
   Wang J, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4193, DOI 10.1109/IROS.2016.7759617
   Wang Y, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P3694, DOI 10.1109/IROS.2006.281729
   Wurman PR, 2008, AI MAG, V29, P9
NR 24
TC 2
Z9 2
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27339
EP 27362
DI 10.1007/s11042-022-12689-3
EA MAR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000773205900002
DA 2024-07-18
ER

PT J
AU Saddal, M
   Rashid, U
   Khattak, AS
   Farooq, G
AF Saddal, Maha
   Rashid, Umer
   Khattak, Akmal Saeed
   Farooq, Ghazanfar
TI ISRE-Framework: nonlinear and multimodal exploration of image search
   result spaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Browsing and visualization; Empirical; usability evaluation;
   Exploration; Framework; Image search result space; Multimedia retrieval;
   Reachability and navigation; Web
ID RETRIEVAL
AB The extensive information delivery power and an immense volume of image objects make them frequently use multimedia content over the web. However, access to desired image objects to satisfy visual information needs by employing primitive exploration paradigms is difficult. Traditionally, the linear presentation of web image results often leads to reachability and navigation issues. Alternatively, nonlinear approaches provide navigation in web image results. The in-depth browsing to access particular web image results is challenging. In this research, we proposed an exploration framework to browse and explore web image results. We addressed the associated exploration issues, i.e., reachability and navigation in browsing and visualization. The framework enables the nonlinear and multimodal exploration of web image results by representing them in a graph-cluster data model and enabling an interactive exploration mechanism. The graph-cluster data model mainly employs and modifies Zahn's method and particular algorithms to transform the web image results into specific nonlinear and multimodal search results spaces. The exploration mechanism enables reachability, navigation, browsing, and visualization of web image results in an integrated way. We instantiated the proposed framework over a real dataset of image objects and employed empirical, usability, and comparison tests to evaluate the proposed exploration framework.
C1 [Saddal, Maha; Rashid, Umer; Khattak, Akmal Saeed; Farooq, Ghazanfar] Quaid I Azam Univ, Comp Sci, Islamabad, Pakistan.
C3 Quaid I Azam University
RP Rashid, U (corresponding author), Quaid I Azam Univ, Comp Sci, Islamabad, Pakistan.
EM m.saddal@cs.qau.edu.pk; umerrashid@qau.edu.pk; akmalsaeed@qau.edu.pk;
   ghazanfar@qau.edu.pk
RI Rashid, Umer/AGW-1380-2022
OI Rashid, Umer/0000-0002-2419-3172; Rashid, Umer/0000-0002-3453-7979
CR Ahn JW, 2013, INFORM PROCESS MANAG, V49, P1139, DOI 10.1016/j.ipm.2013.01.007
   Ahrens J, 2014, INT CONF HIGH PERFOR, P424, DOI 10.1109/SC.2014.40
   André P, 2009, LECT NOTES COMPUT SC, V5727, P340, DOI 10.1007/978-3-642-03658-3_40
   [Anonymous], 2010, P INT C MULT INF RET
   [Anonymous], 2009, SEARCH USER INTERFAC, DOI DOI 10.1017/CBO9781139644082
   [Anonymous], 1988, Proceedings of the SIGCHI conference on Human factors in computing systems-CHI, DOI DOI 10.1145/57167.57203
   Axenopoulos Apostolos., 2012, The Future Internet, P130
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Belo LD, 2016, NEUROCOMPUTING, V173, P1001, DOI 10.1016/j.neucom.2015.08.057
   Chagas GO, 2019, APPL SOFT COMPUT, V81, DOI 10.1016/j.asoc.2019.105482
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Chatzichristofis SA, 2010, INT J PATTERN RECOGN, V24, P207, DOI 10.1142/S0218001410007890
   Chaudhary C, 2019, MULTIMED TOOLS APPL, V78, P17623, DOI 10.1007/s11042-018-7131-x
   Chen J.-C., 2019, 2019 4 IEEE INT C, P1
   Clough P, 2007, LECT NOTES COMPUT SC, V4730, P579
   Di Sciascio C, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/3009976
   Dimitrov D, 2018, WEBSCI'18: PROCEEDINGS OF THE 10TH ACM CONFERENCE ON WEB SCIENCE, P371, DOI 10.1145/3201064.3201092
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Garces E, 2017, MULTIMED TOOLS APPL, V76, P13067, DOI 10.1007/s11042-016-3702-x
   Gormley C., 2015, ELASTICSEARCH DEFINI
   Hay L, 2020, J ENG DESIGN, V31, P127, DOI 10.1080/09544828.2019.1662381
   Hearst MA, 2006, COMMUN ACM, V49, P59, DOI 10.1145/1121949.1121983
   Hoque E., 2011, 2011 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies, P130, DOI 10.1109/WI-IAT.2011.11
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Kaki M., 2005, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P131
   Kennedy L.S., 2008, P ACM INT C WORLD WI, P297
   Kherfi Mohammed Lamine, 2008, Advances in Human Computer Interaction, P215
   Kogge PM, 2016, IEEE SYM PARA DISTR, P921, DOI 10.1109/IPDPSW.2016.208
   Lewis EC., 2011, IMAGE REPRESENTATION
   Ma KL, 1999, IEEE
   Marchionini G, 2006, COMMUN ACM, V49, P41, DOI 10.1145/1121949.1121979
   Mourchid Y, 2019, MULTIMED TOOLS APPL, V78, P20191, DOI 10.1007/s11042-019-7304-2
   Mu C., 2018, ARXIV180608896
   Palagi E., 2017, P 2017 ACM WORKSH EX, P3, DOI DOI 10.1145/3038462.3038465
   Park JY, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P985, DOI 10.1145/2702123.2702527
   Petkos G, 2017, MULTIMED TOOLS APPL, V76, P7897, DOI 10.1007/s11042-016-3378-2
   Pienta Robert S., 2017, P 2017 SIAM INT C DA, P597, DOI DOI 10.1137/1.9781611974973.67
   Pinto-Caceres Sheila M., 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P335, DOI 10.1007/978-3-319-14445-0_29
   Rafailidis D, 2013, PATTERN RECOGN, V46, P3358, DOI 10.1016/j.patcog.2013.05.023
   Rashid U, 2017, MULTIMED TOOLS APPL, V76, P25787, DOI 10.1007/s11042-017-4769-8
   Rashid U, 2016, INFORM SCIENCES, V370, P303, DOI 10.1016/j.ins.2016.07.072
   Rashid U, 2016, ADV INTELL SYST, V400, P271, DOI 10.1007/978-3-319-26154-6_21
   Rashid U, 2010, ADVANCES TECHNIQUES IN COMPUTING SCIENCES AND SOFTWARE ENGINEERING, P575, DOI 10.1007/978-90-481-3660-5_98
   Richards M, 2015, Software Architecture Patterns
   Sabetghadam Serwah, 2015, Advances in Information Retrieval. 37th European Conference on IR Research (ECIR 2015). Proceedings: LNCS 9022, P370, DOI 10.1007/978-3-319-16354-3_41
   Sabetghadam S, 2018, INT J MULTIMED INF R, V7, P157, DOI 10.1007/s13735-017-0145-8
   Saddal M, 2019, 22 INT MULT C INMIC, P1
   Saglam A, 2017, PATTERN RECOGN LETT, V87, P155, DOI 10.1016/j.patrec.2016.06.001
   Sarrafzadeh B, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P145, DOI 10.1145/3077136.3080829
   Schinas M, 2016, INT J MULTIMED INF R, V5, P51, DOI 10.1007/s13735-015-0089-9
   Shrivastav S, 2017, MULTIMED TOOLS APPL, V76, P18657, DOI 10.1007/s11042-017-4350-5
   Smeaton AF, 2005, LECT NOTES COMPUT SC, V3568, P11
   Tullis T.S., 2004, Usability professional association conference, V1, DOI 10.1.1.396.3677
   van Zwol R., 2010, P 19 INT C WORLD WID, P961
   Wang Jianguo., 2014, TOIS, V32, P1
   Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397
   White RW., 2009, SYNTHESIS LECT INFOR, DOI [10.2200/S00174ED1V01Y200901ICR003, DOI 10.2200/S00174ED1V01Y200901ICR003]
   Wilson T D., 2009, REV MORVILLE PETER C
   Xie XH, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2103, DOI 10.1145/3308558.3313514
   ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083
   Zhu L, 2015, IEEE T CYBERNETICS, V45, P2756, DOI 10.1109/TCYB.2014.2383389
NR 62
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27275
EP 27308
DI 10.1007/s11042-022-12561-4
EA MAR 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000773206100002
DA 2024-07-18
ER

PT J
AU Daoui, A
   Karmouni, H
   Sayyouri, M
   Qjidaa, H
AF Daoui, Achraf
   Karmouni, Hicham
   Sayyouri, Mhamed
   Qjidaa, Hassan
TI Robust 2D and 3D images zero - watermarking using dual Hahn moment
   invariants and Sine Cosine Algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image reconstruction; 2D and 3D image zero-watermarking; Discrete
   orthogonal moments; Dual - Hahn moment invariants; Sine cosine
   algorithm; Numerical stability
ID FAST COMPUTATION; MEIXNER MOMENTS; CLASSIFICATION; SCHEME
AB In this paper, we initially provide significant improvements on the computational aspects of dual Hahn moment invariants (DHMIs) in both 2D and 3D domains. These improvements ensure the numerical stability of DHMIs for large-size images. Then, we propose an efficient method for optimizing the local parameters of dual Hahn polynomials (DHPs) when computing DHMIs using the Sine-Cosine Algorithm (SCA). DHMIs optimized via SCA are used to propose new and robust zero-watermarking scheme applied to both 2D and 3D images. On one hand, the simulation results confirm the efficiency of the proposed computation of 2D and 3D DHMIs regarding the numerical stability and invariability. Indeed, the proposed computation method of 2D DHMIs allows to reach a relative error (RE) of the order approximate to 10(-10) for images of size 1024 x 1024 with an execution time improvement ratio exceeds 70% (ETIR >= 70%), which validates the efficiently of the proposed computation method. On the other hand, the simulation and comparison outcomes clearly demonstrate the robustness of the proposed zero-watermarking scheme against various geometric attacks (translation, rotation, scaling and combined transformations), as well as against other common 2D and 3D image processing attacks (compression, filtering, noise addition, etc.).
C1 [Daoui, Achraf; Sayyouri, Mhamed] Sidi Mohamed Ben Abdellah Fez Univ, Natl Sch Appl Sci, Lab Engn Syst & Applicat, Fes, Morocco.
   [Karmouni, Hicham; Qjidaa, Hassan] Sidi Mohamed Ben Abdellah Fez Univ, Fac Sci, Lab Elect Signals & Syst Informat, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Daoui, A (corresponding author), Sidi Mohamed Ben Abdellah Fez Univ, Natl Sch Appl Sci, Lab Engn Syst & Applicat, Fes, Morocco.
EM achraf.daoui@usmba.ac.ma; hicham.karmouni@usmba.ac.ma;
   mhamed.sayyouri@usmba.ac.ma; qjidah@yahoo.fr
RI Karmouni, Hicham/ACB-0232-2022; Sayyouri, Mhamed/AAB-5496-2020
OI Karmouni, Hicham/0000-0001-9225-8380; Sayyouri,
   Mhamed/0000-0002-1615-419X; DAOUI, Achraf/0000-0002-2326-9550
CR Ali Z, 2018, FUTURE GENER COMP SY, V88, P400, DOI 10.1016/j.future.2018.05.058
   Benouini R, 2019, PATTERN RECOGN, V91, P100, DOI 10.1016/j.patcog.2019.02.014
   Benouini R, 2019, PATTERN RECOGN LETT, V123, P39, DOI 10.1016/j.patrec.2019.03.001
   Benouini R, 2019, PATTERN RECOGN, V86, P332, DOI 10.1016/j.patcog.2018.10.001
   Bocci C, 2016, J ALGEBRA, V448, P595, DOI 10.1016/j.jalgebra.2015.10.008
   Camacho-Bello C, 2018, PATTERN RECOGN LETT, V112, P332, DOI 10.1016/j.patrec.2018.08.020
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Daoui A., 2020, Embedded Systems and Artificial Intelligence. Proceedings of ESAI 2019. Advances in Intelligent Systems and Computing (AISC 1076), P369, DOI 10.1007/978-981-15-0947-6_35
   Daoui A., 2020, 2020 INT C INT SYST, P1, DOI DOI 10.1109/ISCV49265.2020.9204132
   Daoui A, 2021, EXPERT SYST APPL, V177, DOI 10.1016/j.eswa.2021.114978
   Daoui A, 2022, CIRC SYST SIGNAL PR, V41, P166, DOI 10.1007/s00034-021-01764-z
   Daoui A, 2021, SIGNAL PROCESS, V180, DOI 10.1016/j.sigpro.2020.107854
   Daoui A, 2021, MULTIMED TOOLS APPL, V80, P1641, DOI 10.1007/s11042-020-09739-z
   Daoui A, 2020, CIRC SYST SIGNAL PR, V39, P4552, DOI 10.1007/s00034-020-01384-z
   Daoui A, 2020, INFORM SCIENCES, V521, P251, DOI 10.1016/j.ins.2020.02.019
   Du Shun ZY, 2013, J COMPUTER AIDED DES, V5
   El Ogri O, 2020, MULTIMED TOOLS APPL, V79, P23261, DOI 10.1007/s11042-020-09084-1
   Flusser J., 2016, 2D and 3D image analysis by moments, P1, DOI 10.1002/9781119039402
   Hmimid A, 2018, MULTIMED TOOLS APPL, V77, P23607, DOI 10.1007/s11042-018-5623-3
   Hosny KM, 2008, J REAL-TIME IMAGE PR, V3, P97, DOI 10.1007/s11554-007-0058-5
   Hosny KM, 2020, Pattern Recognition, Patent No. 107324
   Jahid T, 2018, MULTIMED TOOLS APPL, V77, P19811, DOI 10.1007/s11042-017-5371-9
   Jiang FF, 2020, MULTIMED TOOLS APPL, V79, P7599, DOI 10.1007/s11042-019-08459-3
   Kang XB, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2020.102804
   Karakasis EG, 2013, PATTERN RECOGN, V46, P1998, DOI 10.1016/j.patcog.2013.01.008
   Karmouni H, 2020, MULTIMED TOOLS APPL, V79, P29121, DOI 10.1007/s11042-020-09351-1
   Karmouni H, 2019, MULTIMED TOOLS APPL, V78, P31245, DOI 10.1007/s11042-019-07961-y
   Karmouni H, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P99
   Koekoek R, 2010, SPRINGER MONOGR MATH, P1, DOI 10.1007/978-3-642-05014-5_1
   Lee J, 2021, MAGN RESON MED, V86, P1077, DOI 10.1002/mrm.28719
   Liu G, 2021, NEUROCOMPUTING, V421, P39
   Mesbah A, 2017, 3D RES, V8, DOI 10.1007/s13319-016-0113-8
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Peng C, 2019, FRONT OPTOELECTRON, V12, P413, DOI 10.1007/s12200-019-0862-0
   Satoh S, 2011, PATTERN RECOGN LETT, V32, P1902, DOI 10.1016/j.patrec.2011.07.027
   Sayyouri M, 2013, J OPT SOC AM A, V30, P2381, DOI 10.1364/JOSAA.30.002381
   Sayyouri M, 2012, PROCEEDINGS OF 2012 INTERNATIONAL CONFERENCE ON COMPLEX SYSTEMS (ICCS12), P289
   Sayyouri M, 2012, COLLOQ INF SCI TECH, P101, DOI 10.1109/CIST.2012.6388071
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Wang X, 2019, MULTIMED TOOLS APPL, V78, P27001, DOI 10.1007/s11042-017-4666-1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen Q., 2001, 3 CHINA INFORM HIDIN
   Xia ZQ, 2021, DIGIT SIGNAL PROCESS, V116, DOI 10.1016/j.dsp.2021.103130
   Xia ZQ, 2022, APPL INTELL, V52, P607, DOI 10.1007/s10489-021-02476-2
   Xia ZQ, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2020.106568
   Xu T., 2009, J IMAGE GRAPHICS, V14, P1818
   Yamni M, 2021, MULTIMED TOOLS APPL, V80, P21679, DOI 10.1007/s11042-021-10717-2
   Yamni M, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107509
   Yang HY, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115747
   Zhang C, 2020, IEEE T GEOSCI REMOTE
   Zhu HQ, 2007, PATTERN RECOGN LETT, V28, P1688, DOI 10.1016/j.patrec.2007.04.013
   Zhu HQ, 2007, SIGNAL PROCESS, V87, P687, DOI 10.1016/j.sigpro.2006.07.007
NR 52
TC 2
Z9 2
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25581
EP 25611
DI 10.1007/s11042-022-12298-0
EA MAR 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000772288200008
PM 35345547
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Kuila, S
   Dhanda, N
   Joardar, S
AF Kuila, Sumanta
   Dhanda, Namrata
   Joardar, Subhankar
TI ECG signal classification and arrhythmia detection using ELM-RNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Electrocardiogram; Extreme learning machine; Recurrent
   neural networks; Hidden layer; MIT BIH arrhythmia database
ID EXTREME LEARNING-MACHINE
AB Arrhythmia is a unique type of heart disease which produces inefficient and irregular heartbeat. This is a cardiac disease which is diagnosed through electrocardiogram (ECG) procedure. Several studies have been focused on the speed and accuracy on the learning algorithm by applying pattern recognition, artificial intelligence in the classification algorithm. In this work a novel classification algorithm is planned based on ELM (Extreme Learning Machine) with Recurrent Neural Network (RNN) by using morphological filtering. The popular publicly available ECG arrhythmia database (MIT-BIH arrhythmia DB) is used to express the performance of the proposed algorithm where the level of accuracy is compared with the existing similar types of work. The comparative study shows that performance of our proposed model is much faster than the models working with RBFN (radial basis function network), BPBB(back propagation neural network) and Support Vector Machine. The experimental result with the MIT BIH database with hidden neurons of ELM with RNN, the accuracy is 96.41%, sensitivity 93.62% and specificity 92.66%. The classification methodology follows main four steps the heart beat detection, the ECG feature extraction, feature selection and the construction of the proposed classifier.
C1 [Kuila, Sumanta; Dhanda, Namrata; Joardar, Subhankar] Amity Univ Uttar Pradesh, Amity Sch Engn & Technol, Lucknow, Uttar Pradesh, India.
RP Kuila, S (corresponding author), Amity Univ Uttar Pradesh, Amity Sch Engn & Technol, Lucknow, Uttar Pradesh, India.
EM sumanta.kuila@gmail.com; ndhanda510@gmail.com;
   subhankarranchi@yahoo.co.in
RI Joardar, subhankar/AAD-5396-2022; Dhanda, Namrata/JZT-2012-2024; Kuila,
   Sumanta/GRX-8509-2022
OI Joardar, subhankar/0000-0002-1542-3757; Kuila,
   Sumanta/0000-0002-6088-6806; Dhanda, Namrata/0000-0003-0395-0696
CR a A Shahbahrami MKS., 2012, International journal of Computer Science, Engineering and Application (IJCSEA), V12, P1, DOI [DOI 10.5121/IJCSEA.2012.2101, 10.5121/ijcsea.2012.2101]
   Acharya UR, 2017, INFORM SCIENCES, V415, P190, DOI 10.1016/j.ins.2017.06.027
   Andersen RS, 2019, EXPERT SYST APPL, V115, P465, DOI 10.1016/j.eswa.2018.08.011
   [Anonymous], 2018, Int J Adv Soft Comput Appl
   [Anonymous], 2011, Int J Inf Technol Knowl Manag
   Anwar SM, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/1380348
   Atal DK, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105607
   Chen TH, 2013, IEEE J EM SEL TOP C, V3, P75, DOI 10.1109/JETCAS.2013.2242772
   Duan LJ, 2014, COGN COMPUT, V6, P477, DOI 10.1007/s12559-014-9264-1
   Ertam F, 2017, MEASUREMENT, V95, P135, DOI 10.1016/j.measurement.2016.10.001
   Fan XM, 2018, IEEE J BIOMED HEALTH, V22, P1744, DOI 10.1109/JBHI.2018.2858789
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Jemilehin T., 2016, DESIGN SIMULATION EL, V1, P155
   Kachuee M, 2018, IEEE INT CONF HEALT, P443, DOI 10.1109/ICHI.2018.00092
   Kim J, 2009, BIOMED ENG ONLINE, V8, DOI 10.1186/1475-925X-8-31
   Kiranyaz S, 2016, IEEE T BIO-MED ENG, V63, P664, DOI 10.1109/TBME.2015.2468589
   Kuila S, 2020, LECT NOTES ELECTR EN, V602, P417, DOI 10.1007/978-981-15-0829-5_41
   LI CW, 1995, IEEE T BIO-MED ENG, V42, P21, DOI 10.1109/10.362922
   Li W, 2019, IEEE ACCESS, V7, P25627, DOI 10.1109/ACCESS.2018.2877793
   Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583
   Mar T, 2011, IEEE T BIO-MED ENG, V58, DOI 10.1109/TBME.2011.2113395
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Oh SL, 2019, COMPUT BIOL MED, V105, P92, DOI 10.1016/j.compbiomed.2018.12.012
   Ortín S, 2015, SCI REP-UK, V5, DOI 10.1038/srep14945
   Pandey SK, 2020, PROCEDIA COMPUT SCI, V167, P2181, DOI 10.1016/j.procs.2020.03.269
   Prasad GK, 2003, TENCON IEEE REGION, P227, DOI 10.1109/TENCON.2003.1273320
   Qin C, 2019, IEEE T MED IMAGING, V38, P280, DOI 10.1109/TMI.2018.2863670
   Rajpurkar Pranav, 2017, ARXIV170701836
   Saadatnejad S, 2020, IEEE J BIOMED HEALTH, V24, P515, DOI 10.1109/JBHI.2019.2911367
   Singh J. P., 2016, International Journal of Plant Protection, V9, P1
   Yildirim Ö, 2018, COMPUT BIOL MED, V102, P411, DOI 10.1016/j.compbiomed.2018.09.009
   Yu Sung-Nien, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P3090
   Zhang J, 2018, NEUROCOMPUTING, V311, P126, DOI 10.1016/j.neucom.2018.05.057
   Zhang YH, 2009, APPL POWER ELECT CO, P128, DOI 10.1109/APEC.2009.4802644
   Zong WW, 2013, NEUROCOMPUTING, V101, P229, DOI 10.1016/j.neucom.2012.08.010
NR 35
TC 12
Z9 12
U1 4
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25233
EP 25249
DI 10.1007/s11042-022-11957-6
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000771882300017
DA 2024-07-18
ER

PT J
AU Kari, AP
   Navin, AH
   Bidgoli, AM
   Mirnia, M
AF Kari, Ahmad Pourjabbar
   Navin, Ahmad Habibizad
   Bidgoli, Amir Massoud
   Mirnia, Mirkamal
TI Image cryptosystem based on plain image correlation rate and selective
   chaotic maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaotic maps; Differential attack; Correlation;
   Diffusion; Confusion
ID ENCRYPTION SCHEME; ALGORITHM; PERMUTATION; CRYPTANALYSIS; EFFICIENT;
   SEQUENCES; SYSTEM
AB In this paper, a new image encryption algorithm is introduced for encrypting grayscale digital images of any size. To improve the encryption evaluation parameters, we suggested that the value of the plain image correlation coefficient be effective in the cryptographic process, so plain images with different properties and correlation coefficient rates are encrypted in different ways. According to the average absolute value of correlation coefficient of plain image, Logistic or Tent maps is selected to generate chaotic sequences to expand plain image matrix. As the first step of the diffusion phase, the plain image matrix is developed with larger size by proper selected chaotic sequences, and simultaneously a chaotic matrix with the same size is generated by chaotic Sine map sequences. In confusion phase, the modified Lorenz map changes pixel locations of new developed matrix by means of certain equations. Then bitwise XOR is applied between developed matrix include plain image and Sine map chaotic matrix, as second step of diffusion phase. Finally, encrypted image is generated after applying exchange operations on the content of pixels, as third step of diffusion phase. Experimental results and comparisons with some of the existing methods, show that the proposed image cryptosystem is able to resist common cryptanalytic attacks and can be used as a secure method for encrypting digital images.
C1 [Kari, Ahmad Pourjabbar; Bidgoli, Amir Massoud] Islamic Azad Univ, Dept Comp Engn, North Tehran Branch, Tehran, Iran.
   [Navin, Ahmad Habibizad] Islamic Azad Univ, Dept Comp Engn, Tabriz Branch, Tabriz, Iran.
   [Mirnia, Mirkamal] Univ Tabriz, Dept Math & Comp Sci, Tabriz, Iran.
C3 Islamic Azad University; Islamic Azad University; University of Tabriz
RP Bidgoli, AM (corresponding author), Islamic Azad Univ, Dept Comp Engn, North Tehran Branch, Tehran, Iran.
EM a.pourjabar@gmail.com; a.habibizad@srbiau.ac.ir;
   am_bidgoli@iau-tnb.ac.ir; mimia-kam@tabrizu.ac.ir
CR Abbas NA, 2016, EGYPT INFORM J, V17, P139, DOI 10.1016/j.eij.2015.10.001
   Al-Maadeed TA, 2021, MULTIMED TOOLS APPL, V80, P24801, DOI 10.1007/s11042-021-10695-5
   ALOTHMANI A, 2012, IJCSI INT J COMPUTER, V9, P30
   Amina S, 2018, COMMUN NONLINEAR SCI, V60, P12, DOI 10.1016/j.cnsns.2017.12.017
   Bakhshandeh A, 2013, OPT LASER ENG, V51, P665, DOI 10.1016/j.optlaseng.2013.01.001
   Bouteghrine B, 2021, MULTIMED TOOLS APPL, V80, P25583, DOI 10.1007/s11042-021-10773-8
   Chapaneri S, 2014, 2014 INTERNATIONAL CONFERENCE ON CIRCUITS, SYSTEMS, COMMUNICATION AND INFORMATION TECHNOLOGY APPLICATIONS (CSCITA), P59, DOI 10.1109/CSCITA.2014.6839235
   Chen JX, 2015, COMMUN NONLINEAR SCI, V23, P294, DOI 10.1016/j.cnsns.2014.11.021
   Chen JX, 2015, OPT LASER ENG, V67, P191, DOI 10.1016/j.optlaseng.2014.11.017
   Chen JX, 2015, COMMUN NONLINEAR SCI, V20, P846, DOI 10.1016/j.cnsns.2014.06.032
   Cheng GF, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419501153
   Chhikara S, 2021, MULTIMED TOOLS APPL, V80, P31865, DOI 10.1007/s11042-021-11118-1
   Darwis D, 2021, CYBERN INF TECHNOL, V21, P89, DOI 10.2478/cait-2021-0021
   Deng J, 2021, MULTIMED TOOLS APPL, V80, P13821, DOI 10.1007/s11042-020-10429-z
   Dhall S, 2018, SIGNAL PROCESS, V146, P22, DOI 10.1016/j.sigpro.2017.12.021
   Dou YQ, 2021, MULTIMED TOOLS APPL, V80, P24437, DOI 10.1007/s11042-021-10850-y
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   Francois M, 1910, APPL MATH, V3
   Fu C, 2013, COMPUT BIOL MED, V43, P1000, DOI 10.1016/j.compbiomed.2013.05.005
   Gong LH, 2019, OPT LASER TECHNOL, V115, P257, DOI 10.1016/j.optlastec.2019.01.039
   Gribermans D, 2016, APPL COMPUT SYST, V20, P40, DOI 10.1515/acss-2016-0014
   He Y, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-85377-1
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Huang X., 2018, MULTIMED TOOLS APPL, V72, P70
   Huang ZJ, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105821
   Khanzadi H, 2014, ARAB J SCI ENG, V39, P1039, DOI 10.1007/s13369-013-0713-z
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Li Q, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107618
   Li T, 2020, IEEE ACCESS, V8, P13792, DOI 10.1109/ACCESS.2020.2966264
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Liu HJ, 2013, J SYST SOFTWARE, V86, P826, DOI 10.1016/j.jss.2012.11.026
   Liu YS, 2016, NONLINEAR DYNAM, V84, P2241, DOI 10.1007/s11071-016-2642-3
   Maddodi G, 2018, MULTIMED TOOLS APPL, V77, P24701, DOI 10.1007/s11042-018-5669-2
   Mansouri A, 2021, MULTIMED TOOLS APPL, V80, P21955, DOI 10.1007/s11042-021-10757-8
   del Rey AM, 2015, LOG J IGPL, V23, P485, DOI 10.1093/jigpal/jzv013
   Mohamed FK, 2014, ENG SCI TECHNOL, V17, P85, DOI 10.1016/j.jestch.2014.04.001
   Munir N, 2021, MATH COMPUT SIMULAT, V190, P826, DOI 10.1016/j.matcom.2021.06.008
   Norouzi B, 2015, MULTIMED TOOLS APPL, V74, P781, DOI 10.1007/s11042-013-1699-y
   Pak C, 2021, MULTIMED TOOLS APPL, V80, P25367, DOI 10.1007/s11042-021-10660-2
   Kari AP, 2021, MULTIMED TOOLS APPL, V80, P2753, DOI 10.1007/s11042-020-09648-1
   Ran J, 2008, J ZUNYI NORMAL U, V20, P99
   Rathore V, 2021, MULTIMED TOOLS APPL, V80, P22275, DOI 10.1007/s11042-021-10719-0
   Rim Z, 2021, MULTIMED TOOLS APPL, V80, P15173, DOI 10.1007/s11042-020-10263-3
   Roy M, 2021, MULTIMED TOOLS APPL, V80, P24069, DOI 10.1007/s11042-021-10839-7
   Shakiba A, 2021, MULTIMED TOOLS APPL, V80, P17983, DOI 10.1007/s11042-021-10584-x
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Song CY, 2013, OPTIK, V124, P3329, DOI 10.1016/j.ijleo.2012.11.002
   Souyah A, 2016, NONLINEAR DYNAM, V86, P639, DOI 10.1007/s11071-016-2912-0
   Toughi S, 2017, SIGNAL PROCESS, V141, P217, DOI 10.1016/j.sigpro.2017.06.010
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wang XY, 2014, NONLINEAR DYNAM, V76, P1943, DOI 10.1007/s11071-014-1259-7
   Wang XY, 2014, NONLINEAR DYNAM, V75, P345, DOI 10.1007/s11071-013-1070-x
   Wang XY., 2019, OPT LASERS ENG, V73, P61
   Wu JH, 2018, SIGNAL PROCESS, V142, P292, DOI 10.1016/j.sigpro.2017.06.014
   Wu JH, 2017, SIGNAL PROCESS, V141, P109, DOI 10.1016/j.sigpro.2017.04.006
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Wu XL, 2017, IEEE ACCESS, V5, P6429, DOI 10.1109/ACCESS.2017.2692043
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Xiang HY, 2021, MULTIMED TOOLS APPL, V80, P22135, DOI 10.1007/s11042-021-10807-1
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Yavuz E, 2015, COMPUT ELECTR ENG
   Yu F, 2019, DISCRETE DYN NAT SOC, V2019, DOI 10.1155/2019/2545123
   Yu SS, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105816
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang LY, 2018, INFORM SCIENCES, V430, P228, DOI 10.1016/j.ins.2017.11.021
   Zhang Q., 2020, OPTIK INT J LIGHT EL, V124, P3002
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P584, DOI 10.1016/j.cnsns.2012.08.010
   Zhang XP, 2014, NONLINEAR DYNAM, V75, P319, DOI 10.1007/s11071-013-1068-4
   Zhang YS, 2014, NONLINEAR DYNAM, V78, P235, DOI 10.1007/s11071-014-1435-9
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-2104-6
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 75
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20483
EP 20508
DI 10.1007/s11042-022-12071-3
EA MAR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767748600016
DA 2024-07-18
ER

PT J
AU Mahapatra, SN
   Singh, BK
   Kumar, V
AF Mahapatra, Surya Narayan
   Singh, Binod Kumar
   Kumar, Vinay
TI A secure multi-hop relay node selection scheme based data transmission
   in wireless ad-hoc network via block chain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Cluster; Routing; Wireless network; Relay node; Wireless
   ad-hoc network
ID COOPERATIVE MAC PROTOCOL; MULTIPATH ROUTING PROTOCOL; ENERGY-AWARE;
   ALGORITHM; DIVERSITY; INTERNET; CLUSTER
AB In today's scenario, data transmission is established through the single or multi-hop relay nodes in Wireless Ad-Hoc Networks (WANET). Traditional relay node selection techniques undergo collusion attacks, increased energy consumption, delay, and reduced network lifetime. To cope with these problems, we propose a Quantum Atom Search Optimization coupled with Blockchain aided Data Transmission (QASO-BDT) scheme for a relay node selection with security aided data transmission. This approach comprises three phases such as registration, clustering, and transmission. Initially, in the node registration phase every sensor node gets registered in the blockchain network through Capillary Gateway (CG). Next, in the clustering phase, a CH is selected and an enhanced multi-view clustering model is used to cluster the nodes into several clusters. Finally, the multi-hop transmission phase assists in best relay node selection for multi-hop transmission using QASO, and the blockchain-based transaction is carried out to ensure security in the system. The proposed scheme is simulated in the MATLAB platform and achieves a result of 91.5% throughput, the reduced energy value of 40%, end to end delay of 20.6%, and the exhaustion of node is 1% which results in an increased lifetime of the nodes. Also, security is evaluated in comparison with other traditional methods.
C1 [Mahapatra, Surya Narayan; Singh, Binod Kumar; Kumar, Vinay] Natl Inst Technol, Dept Comp Sci & Engn, Jamshedpur 831014, Jharkhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur
RP Mahapatra, SN (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Jamshedpur 831014, Jharkhand, India.
EM snmahapatra0205@gmail.com; bksingh.cse@nitjsr.ac.in;
   vkumar.cse@nitjsr.ac.in
RI Mahapatra, Surya Narayan/GNW-4825-2022; Singh, Binod/AAB-8663-2019
OI Mahapatra, Surya Narayan/0000-0001-6239-5704; Singh,
   Binod/0000-0002-2697-8918
CR Abuashour A, 2017, IEEE ACCESS, V5, P15354, DOI 10.1109/ACCESS.2017.2733380
   Aftab F, 2019, IEEE ACCESS, V7, P56217, DOI 10.1109/ACCESS.2019.2913912
   Almazyad AS, 2018, NEURAL COMPUT APPL, V29, P597, DOI 10.1007/s00521-016-2555-6
   Antonopoulos A, 2013, AD HOC NETW, V11, P190, DOI 10.1016/j.adhoc.2012.05.003
   Cao B, 2017, IEEE T VEH TECHNOL, V66, P4287, DOI 10.1109/TVT.2016.2602501
   Cao B, 2014, IEEE T VEH TECHNOL, V63, P252, DOI 10.1109/TVT.2012.2226485
   Chavan AA, 2016, PROCEDIA COMPUT SCI, V79, P835, DOI 10.1016/j.procs.2016.03.108
   Choi HH, 2014, IEICE T INF SYST, VE97D, P335, DOI 10.1587/transinf.E97.D.335
   Fotue D, 2012, 2012 IEEE 23RD INTERNATIONAL SYMPOSIUM ON PERSONAL INDOOR AND MOBILE RADIO COMMUNICATIONS (PIMRC), P758, DOI 10.1109/PIMRC.2012.6362885
   Gkantsidis C, 2005, IEEE INFOCOM SER, P2235
   Gómez-Cuba F, 2012, IEEE COMMUN SURV TUT, V14, P822, DOI 10.1109/SURV.2011.082611.00047
   Jibukumar MG, 2010, WIREL NETW, V16, P1865, DOI 10.1007/s11276-009-0232-8
   Jin Y, 2013, INT J DISTRIB SENS N, DOI 10.1155/2013/216478
   Khalid M, 2011, IEEE T VEH TECHNOL, V60, P3361, DOI 10.1109/TVT.2011.2159872
   Khalid U, 2020, CLUSTER COMPUT, V23, P2067, DOI 10.1007/s10586-020-03058-6
   Kiskani MK, 2017, IEEE T VEH TECHNOL, V66, P10249, DOI 10.1109/TVT.2017.2756623
   Ladas A, 2018, AD HOC NETW, V77, P95, DOI 10.1016/j.adhoc.2018.04.013
   Laneman JN, 2004, IEEE T INFORM THEORY, V50, P3062, DOI 10.1109/TIT.2004.838089
   Lei K, 2019, IEEE COMMUN MAG, V57, P26, DOI 10.1109/MCOM.2019.1800722
   Li Q, 2011, IEEE T INFORM THEORY, V57, P5794, DOI 10.1109/TIT.2011.2161925
   Li XL, 2019, IEEE ACCESS, V7, P113182, DOI 10.1109/ACCESS.2019.2934889
   Li YY, 2013, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2013-264
   Li ZT, 2018, IEEE T IND INFORM, V14, P3690, DOI 10.1109/TII.2017.2786307
   Liang GQ, 2019, IEEE T SMART GRID, V10, P3162, DOI 10.1109/TSG.2018.2819663
   Liang W, 2019, IEEE T IND INFORM, V15, P3582, DOI 10.1109/TII.2019.2907092
   Lin J, 2017, IEEE INTERNET THINGS, V4, P1125, DOI 10.1109/JIOT.2017.2683200
   Liu K, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16101630
   Liu K, 2015, COMPUT NETW, V91, P262, DOI 10.1016/j.comnet.2015.08.020
   Liu P, 2005, IEEE ICC, P2962
   Lu T, 2018, WIREL NETW, V24, P611, DOI 10.1007/s11276-016-1360-6
   Niu H, 2016, WIREL NETW, V22, P1513, DOI 10.1007/s11276-015-1044-7
   Nomikos N, 2016, IEEE COMMUN SURV TUT, V18, P1073, DOI 10.1109/COMST.2015.2512441
   Oubabas S, 2018, VEH COMMUN, V13, P128, DOI 10.1016/j.vehcom.2018.08.001
   Pal R, 2018, WIRELESS PERS COMMUN, V98, P1155, DOI 10.1007/s11277-017-4913-9
   Pathak K., 2017, J COMMUN INF NETW, V2, P123, DOI DOI 10.1007/S41650-017-0012-Z
   Saranya V, 2018, WIRELESS PERS COMMUN, V100, P1553, DOI 10.1007/s11277-018-5653-1
   Srivastava V, 2020, J AMB INTEL HUM COMP, V11, P1325, DOI 10.1007/s12652-019-01449-1
   Taha A, 2017, IEEE ACCESS, V5, P10369, DOI 10.1109/ACCESS.2017.2707537
   Thangaramya K, 2019, COMPUT NETW, V151, P211, DOI 10.1016/j.comnet.2019.01.024
   Wang HM, 2018, IEEE T COMMUN, V66, P4666, DOI 10.1109/TCOMM.2018.2835478
   Wang W, 2013, INFORM SCIENCES, V220, P580, DOI 10.1016/j.ins.2012.07.036
   Wang YD, 2018, IEEE ACCESS, V6, P75086, DOI 10.1109/ACCESS.2018.2883143
   Xu Y, 2017, COMPUT NETW, V123, P77, DOI 10.1016/j.comnet.2017.05.012
   Zareei M, 2018, J NETW COMPUT APPL, V104, P21, DOI 10.1016/j.jnca.2017.12.009
   Zhang DG, 2019, IEEE T INTELL TRANSP, V20, P1517, DOI 10.1109/TITS.2018.2853165
   Zhao QY, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102355
   Zlatanov N, 2014, IEEE COMMUN MAG, V52, P146, DOI 10.1109/MCOM.2014.6807959
NR 47
TC 2
Z9 2
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18343
EP 18373
DI 10.1007/s11042-022-12283-7
EA MAR 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766438300001
DA 2024-07-18
ER

PT J
AU Singh, A
   Singh, J
AF Singh, Amanjot
   Singh, Jagroop
TI Content adaptive deblocking of artifacts for highly compressed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blocking artifacts; Compression; De-blocking; Filtering; Multimedia
ID POST-PROCESSING TECHNIQUE; BLOCKING ARTIFACTS; TRANSFORM; REDUCTION;
   REMOVAL; ACCURATE; FILTER
AB In this paper, a spatial technique for the reduction of blocking artifacts existing within the highly compressed reconstructed images, has been presented. Blocking artifacts is a kind of noise, present in images. If images are highly compressed with 'BDCT' based standards, then there is a possibility that some artificial boundary like artifacts may appear on reconstructed images. Removal or reduction of this type of artifacts is always desirable in image processing applications. Therefore, to remove all these artifacts, a post-deblocking method is required. In this work, to remove blocking artifacts a content-adaptive method for the deblocking has been proposed. The simulation results have been compared with other methods based on quality metrics like PSNR, MSSIM and SF where the proposed deblocking method has performed better than other methods.
C1 [Singh, Amanjot] IKG Punjab Tech Univ, Kapurthala 144603, Punjab, India.
   [Singh, Amanjot] Lovely Profess Univ, Sch Elect & Elect Engn, Phagwara 144411, Punjab, India.
   [Singh, Jagroop] DAVIET, Dept Elect & Commun Engn, Jalandhar 144008, Punjab, India.
C3 I. K. Gujral Punjab Technical University; Lovely Professional
   University; DAV Institute of Engineering & Technology
RP Singh, A (corresponding author), IKG Punjab Tech Univ, Kapurthala 144603, Punjab, India.; Singh, A (corresponding author), Lovely Profess Univ, Sch Elect & Elect Engn, Phagwara 144411, Punjab, India.
EM er.ajotsingh@gmail.com; roopasidhu@yahoo.com
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   [Anonymous], 2014, 2014 IEEE INT C MULT
   Averbuch AZ, 2005, IEEE T IMAGE PROCESS, V14, P200, DOI 10.1109/TIP.2004.840688
   Bhagat A. P., 2012, 2012 International Conference on Devices, Circuits and Systems (ICDCS 2012), P172, DOI 10.1109/ICDCSyst.2012.6188698
   Chen T, 2001, IEEE T CIRC SYST VID, V11, P594, DOI 10.1109/76.920189
   Chen YY, 2008, J VIS COMMUN IMAGE R, V19, P231, DOI 10.1016/j.jvcir.2008.02.001
   Gamit A, 2017, INT RES J ENG TECHNO, V04
   Golestaneh SA, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.1.013018
   GOPINATH RA, 1994, IEEE IMAGE PROC, P913, DOI 10.1109/ICIP.1994.413488
   Goto T, 2011, IEEE T CONSUM ELECTR, V57, P253, DOI 10.1109/TCE.2011.5735510
   Kaur A., 2019, INT J COMPUT APPL, V43, P501
   Khan SS, 2020, MULTIMED TOOLS APPL, V79, P32791, DOI 10.1007/s11042-020-09682-z
   Kim J, 2011, IEEE T CONSUM ELECTR, V57, P1944, DOI 10.1109/TCE.2011.6131175
   Kim J, 2009, IEEE T CONSUM ELECTR, V55, P933, DOI 10.1109/TCE.2009.5174477
   Kim NC, 1998, IEEE T CIRC SYST VID, V8, P253, DOI 10.1109/76.678618
   Kim Y, 2003, IEEE T CONSUM ELECTR, V49, P1438, DOI 10.1109/TCE.2003.1261252
   Lee YL, 1998, IEEE T IMAGE PROCESS, V7, P229, DOI 10.1109/83.661000
   Liew AWC, 2004, IEEE T CIRC SYST VID, V14, P450, DOI 10.1109/TCSVT.2004.825555
   List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175
   Luo Y, 2003, IEEE T IMAGE PROCESS, V12, P838, DOI 10.1109/TIP.2003.814252
   MINAMI S, 1995, IEEE T CIRC SYST VID, V5, P74, DOI 10.1109/76.388056
   Nath VK., 2010, P INT C SPCOM, V6, P243
   Nath VK., 2012, INT J MULTIMEDIA APP, V4, P39
   Paek H, 1998, IEEE T CIRC SYST VID, V8, P358, DOI 10.1109/76.678636
   Paek H, 2000, IEEE T CIRC SYST VID, V10, P36, DOI 10.1109/76.825856
   Pennebaker W. B., 1993, JPEG: Still image data compression standard
   Shashidhar TM., 2019, ARTIF INTELL
   Singh J, 2011, AEU-INT J ELECTRON C, V65, P827, DOI 10.1016/j.aeue.2011.01.012
   Singh S, 2007, DIGIT SIGNAL PROCESS, V17, P225, DOI 10.1016/j.dsp.2005.08.003
   Sun DQ, 2007, IEEE T IMAGE PROCESS, V16, P2743, DOI 10.1109/TIP.2007.904969
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang C, 2013, SIGNAL PROCESS-IMAGE, V28, P522, DOI 10.1016/j.image.2013.01.006
   Wang J, 2015, DIGIT SIGNAL PROCESS, V42, P80, DOI 10.1016/j.dsp.2015.03.009
   Wang XY, 2014, ACTA PHYS SIN-CH ED, V63, DOI 10.7498/aps.63.020701
   Wang XY, 2014, ACTA PHYS SIN-CH ED, V63, DOI 10.7498/aps.63.210701
   Wang XY, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.3.033012
   Wang XY, 2013, NONLINEAR DYNAM, V73, P1945, DOI 10.1007/s11071-013-0915-7
   Wu SH, 2001, IEEE T CIRC SYST VID, V11, P1193, DOI 10.1109/76.964789
   Xia ZQ, 2019, SIGNAL PROCESS, V157, P108, DOI 10.1016/j.sigpro.2018.11.011
   Xia ZQ, 2018, J MED IMAG HEALTH IN, V8, P925, DOI 10.1166/jmihi.2018.2390
   Xu J, 2006, OPT ENG, V45, DOI 10.1117/1.2280609
   YANG YY, 1995, IEEE T IMAGE PROCESS, V4, P896, DOI 10.1109/83.392332
   Yang YY, 1997, IEEE T IMAGE PROCESS, V6, P1345, DOI 10.1109/83.624945
   Zakhor A, 1992, IEEE T CIRC SYST VID, V2, P91, DOI 10.1109/76.134377
   Zhang M, 2009, VISUAL COMMUN IMAGE, V7257
   Zhao C, 2017, IEEE T CIRC SYST VID, V27, P2057, DOI 10.1109/TCSVT.2016.2580399
   Zhao ZS, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0465-0
NR 49
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18375
EP 18396
DI 10.1007/s11042-022-12549-0
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766430800012
DA 2024-07-18
ER

PT J
AU Wang, Y
   Chen, LQ
   Yu, KL
   Lu, TY
AF Wang, Yu
   Chen, Liquan
   Yu, Kunliang
   Lu, Tianyu
TI Image encryption algorithm based on lattice hash function and privacy
   protection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Homomorphic encryption; Chaos theory; Image encryption; Paillier
   cryptosystem; Cloud platform; Ciphertext retrieval
ID SYSTEM; MAP
AB To solve the problem of lack of trust in cloud platforms, we propose an image encryption algorithm based on the Lattice Hash function and privacy protection in this paper. A new chaotic system using Tent Map and Sine Map is designed in our proposed scheme, which does not have a period window. Meanwhile, our algorithm uses a new chaos system to provide random matrices F for Lattice Hash functions. The image feature vector and the initial key are also employed to obtain the security key, which can be used as input to the Lattice Hash. Besides, our algorithm utilizes the Paillier cryptosystem to encrypt the feature vector as the ciphertext image index for higher security. In addition, the 2D-Line map is improved and applied as a function for scrambling pixel positions to avoid the problem of storing pixel subscripts. Simulation experiments and security analysis shows that our proposed algorithm can resist differential attacks, statistical attacks, brutal attacks. Therefore, our scheme has good security performance and allows precise search over the ciphertext.
C1 [Wang, Yu; Chen, Liquan; Yu, Kunliang; Lu, Tianyu] Southeast Univ, Sch Cyber Sci & Engn, Nanjing 210000, Peoples R China.
   [Chen, Liquan] Purple Mt Labs Network & Commun Secur, Nanjing 211111, Peoples R China.
C3 Southeast University - China
RP Chen, LQ (corresponding author), Southeast Univ, Sch Cyber Sci & Engn, Nanjing 210000, Peoples R China.; Chen, LQ (corresponding author), Purple Mt Labs Network & Commun Secur, Nanjing 211111, Peoples R China.
EM Lqchen@seu.edu.cn
RI lu, Tianyu/ACZ-1638-2022
OI lu, Tianyu/0000-0002-7958-1594; Wang, Yu/0000-0003-1563-7306
FU National Key Research and Development Program of China [2020YFE0200600];
   National Natural Science Foundation of China [62002058]
FX This research is supported by the National Key Research and Development
   Program of China (No. 2020YFE0200600), and National Natural Science
   Foundation of China (No. 62002058).
CR Ahmad J, 2016, MULTIMED TOOLS APPL, V75, P12669, DOI 10.1007/s11042-016-3436-9
   Ahmed F, 2014, WIRELESS PERS COMMUN, V77, P2771, DOI 10.1007/s11277-014-1667-5
   Ali DS, 2019, AIP CONF PROC, V2183, DOI 10.1063/1.5136200
   Babaei M, 2013, NAT COMPUT, V12, P101, DOI 10.1007/s11047-012-9334-9
   Bianchi T, 2010, IEEE T INF FOREN SEC, V5, P180, DOI 10.1109/TIFS.2009.2036230
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Cao N, 2011, INT CON DISTR COMP S, P393, DOI 10.1109/ICDCS.2011.84
   Cheon JH, 2013, LECT NOTES COMPUT SC, V7881, P315, DOI 10.1007/978-3-642-38348-9_20
   Choi US, 2020, MULTIMED TOOLS APPL, V79, P22825, DOI 10.1007/s11042-020-09033-y
   Feng Y, 2006, ISSCAA 2006: 1ST INTERNATIONAL SYMPOSIUM ON SYSTEMS AND CONTROL IN AEROSPACE AND ASTRONAUTICS, VOLS 1AND 2, P1362
   Ferreira B, 2019, IEEE T CLOUD COMPUT, V7, P784, DOI 10.1109/TCC.2017.2669999
   Gentry C, 2010, COMMUN ACM, V53, P97, DOI 10.1145/1666420.1666444
   Guesmi R, 2016, MULTIMED TOOLS APPL, V75, P4753, DOI 10.1007/s11042-015-2501-0
   Hailing Huang, 2008, 2008 Pacific-Asia Workshop on Computational Intelligence and Industrial Application. PACIIA 2008, P272, DOI 10.1109/PACIIA.2008.240
   Halevi Oded GoldreichShafi GoldwasserShai, 1996, STUDIES COMPLEXITY C, P30
   He D, 2000, TENCON IEEE REGION, pB95
   Hsu CY, 2012, IEEE T IMAGE PROCESS, V21, P4593, DOI 10.1109/TIP.2012.2204272
   Hua Z., 2013, DIGIT SIGNAL PROCESS, V1, P118
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Huang X., 2020, J NETW INTELL, V5, P10
   Kumar P, 2009, NAT PROTOC, V4, P1073, DOI 10.1038/nprot.2009.86
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu WJ, 2009, INT CONF ACOUST SPEE, P1533, DOI 10.1109/ICASSP.2009.4959888
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Patel, 2018, SURVEY MULTIPLE IMAG, V4, P43
   Qin Z, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P497, DOI 10.1145/2647868.2654941
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Tian CW, 2021, IEEE T MULTIMEDIA, V23, P1489, DOI 10.1109/TMM.2020.2999182
   Tian CW, 2020, NEURAL NETWORKS, V124, P117, DOI 10.1016/j.neunet.2019.12.024
   Wang K, 2005, PHYS LETT A, V343, P432, DOI 10.1016/j.physleta.2005.05.040
   Wang MX, 2019, OPT LASER ENG, V121, P479, DOI 10.1016/j.optlaseng.2019.05.013
   Wang MX, 2018, OPT LASER TECHNOL, V108, P558, DOI 10.1016/j.optlastec.2018.07.052
   Wang XY, 2019, OPT LASER ENG, V122, P335, DOI 10.1016/j.optlaseng.2019.06.015
   Wang XY, 2020, OPT LASER ENG, V125, DOI 10.1016/j.optlaseng.2019.105851
   Wang XY, 2018, OPT LASER ENG, V107, P370, DOI 10.1016/j.optlaseng.2017.06.015
   Wang XY, 2018, OPT LASER ENG, V103, P1, DOI 10.1016/j.optlaseng.2017.11.009
   Wang XY, 2015, NONLINEAR DYNAM, V79, P1141, DOI 10.1007/s11071-014-1729-y
   Wu T.Y., 2018, J INF HIDING MULTIM, V9, P1050
   Xuelong Hu, 2008, 2008 International Conference on Neural Networks and Signal Processing, P412, DOI 10.1109/ICNNSP.2008.4590383
   Zhang YQ, 2016, OPT LASER ENG, V82, P95, DOI 10.1016/j.optlaseng.2016.02.002
   Zhu J. H., 2019, J. Inf. Hiding Multimedia Signal Process., V10, P278
NR 42
TC 6
Z9 6
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18251
EP 18277
DI 10.1007/s11042-022-12714-5
EA MAR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766063900002
DA 2024-07-18
ER

PT J
AU Rana, A
   Singh, H
   Mavuduru, R
   Pattanaik, S
   Rana, PS
AF Rana, Ashish
   Singh, Harpreet
   Mavuduru, Ravimohan
   Pattanaik, Smita
   Rana, Prashant Singh
TI Quantifying prognosis severity of COVID-19 patients from deep learning
   based analysis of CT chest images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19 detection; COVID-19 prognosis; Single shot detection network;
   Siamese neural network
ID DISEASE 2019 COVID-19; DIAGNOSIS
AB The COVID-19 pandemic has affected all the countries in the world with its droplet spread mode. The colossal amount of cases has strained all the healthcare systems due to the serious nature of infections especially for people with comorbidities. A very high specificity Reverse Transcriptase-Polymerase Chain Reaction (RT-PCR) test is the principal technique in use for diagnosing the COVID-19 patients. Also, CT scans have helped medical professionals in patient severity estimation & progression tracking of COVID-19 virus. In study we present our own extensible COVID-19 viral infection tracking prognosis technique. It uses annotated dataset of CT chest scan slice images created with the help of medical professionals. The annotated dataset contains bounding box coordinates of different features for COVID-19 detection like ground glass opacities, crazy paving pattern, consolidations, lesions etc. We qualitatively identify the severity of the patient for later prognosis stages in our study to assist medical staff for patient prioritization. First we detected COVID-19 positive patients with pre-trained Siamese Neural Network (SNN) which obtained 87.6% accuracy, 87.1% F1-Score & 95.1% AUC scores. These metrics were achieved after removal of 40% quantitatively highly similar images from the COVID-CT dataset. This reduced dataset was further medically annotated with COVID-19 features for bounding box detection. After this we assigned severity scores to detected COVID-19 features and calculated the cumulative severity score for COVID-19 patients. For qualitative patient prioritization with prognosis clinical assistance information, we finally converted this score into a multi-classification problem which obtained 47% weighted-average F1-score.
C1 [Rana, Ashish; Singh, Harpreet; Rana, Prashant Singh] TIET, Dept Comp Sci & Engn, Patiala, Punjab, India.
   [Mavuduru, Ravimohan; Pattanaik, Smita] PGIMER, Dept Urol & Pharmacol, Chandigarh, India.
C3 Thapar Institute of Engineering & Technology; Post Graduate Institute of
   Medical Education & Research (PGIMER), Chandigarh
RP Singh, H (corresponding author), TIET, Dept Comp Sci & Engn, Patiala, Punjab, India.
EM arana_be15@thapar.edu; akalharpreet@gmail.com; ravismi2003@yahoo.com;
   drs_pattanaik@yahoo.com; psrana@gmail.com
RI Rana, Ashish pramod/JMP-6567-2023; Rana, Prashant Singh/AAE-1784-2019
OI Rana, Ashish pramod/0009-0009-7358-1954; Rana, Prashant
   Singh/0000-0002-0142-7925
CR Appalaraju S., 2017, ARXIV170908761
   Azhar EI, 2019, INFECT DIS CLIN N AM, V33, P891, DOI 10.1016/j.idc.2019.08.001
   Bai Y, 2020, JAMA-J AM MED ASSOC, V323, P1406, DOI 10.1001/jama.2020.2565
   Bressem KK, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-57859-1
   Burlacu A, 2020, CURBING AI INDUCED E, DOI [10.1101/2020.04.28.20082776., DOI 10.1101/2020.04.28.20082776]
   Chaudhary PK, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104454
   Chaudhary PK, 2020, IEEE INT C BIOINFORM, P2257, DOI 10.1109/BIBM49941.2020.9313252
   Chauhan GS, 2020, EXPERT SYST APPL, V161, DOI 10.1016/j.eswa.2020.113673
   Chung MS, 2020, EUR RADIOL, V30, P2182, DOI [10.1148/radiol.2020200230, 10.1007/s00330-019-06574-1]
   Ewen N, 2021, I S BIOMED IMAGING, P1481, DOI 10.1109/ISBI48211.2021.9434047
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Grant MC, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0234765
   Gupta A, 2021, INT J UNCERTAIN FUZZ
   He X. etal, 2020, medRxiv
   Hoang A, 2020, ECLINICALMEDICINE, V24, DOI 10.1016/j.eclinm.2020.100433
   Holschneider M, 1990, Wavelets, P286, DOI DOI 10.1007/978-3-642-75988-828
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Ieracitano C, 2021, IEEE-CAA J AUTOMATIC, V8, P64, DOI 10.1109/JAS.2020.1003387
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Lam Christopher W K, 2004, Clin Biochem Rev, V25, P121
   Li JH, 2020, INFECT IMMUN, V88, DOI 10.1128/IAI.00754-19
   Li Y, 2020, AM J ROENTGENOL, V214, P1280, DOI 10.2214/AJR.20.22954
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mei XY, 2020, NAT MED, V26, P1224, DOI [10.1038/s41591-020-0931-3, 10.1101/2020.04.12.20062661]
   Mobiny A., 2020, ARXIV PREPRINT ARXIV
   Nayak SR, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102365
   Sakagianni A, 2020, STUD HEALTH TECHNOL, V272, P13, DOI 10.3233/SHTI200481
   Salehi S, 2020, AM J ROENTGENOL, V215, P87, DOI 10.2214/AJR.20.23034
   Santos MS, 2018, IEEE COMPUT INTELL M, V13, P59, DOI 10.1109/MCI.2018.2866730
   Shi F, 2021, IEEE REV BIOMED ENG, V14, P4, DOI 10.1109/RBME.2020.2987975
   Silva Pedro, 2020, Inform Med Unlocked, V20, P100427, DOI 10.1016/j.imu.2020.100427
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Snoek J., 2012, Advances in Neural Information Processing Systems, V25, DOI DOI 10.48550/ARXIV.1206.2944
   Tahamtan A, 2020, EXPERT REV MOL DIAGN, V20, P453, DOI 10.1080/14737159.2020.1757437
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Xu XW, 2020, ENGINEERING-PRC, V6, P1122, DOI 10.1016/j.eng.2020.04.010
   Yang R, 2020, RADIOL-CARDIOTHORAC, V2, DOI 10.1148/ryct.2020200047
   Zhao J., 2020, ARXIV PREPRINT ARXIV
   Zhou F, 2020, LANCET, V395, P1054, DOI 10.1016/S0140-6736(20)30566-3
   Zhu N, 2020, NEW ENGL J MED, V382, P727, DOI [10.1056/NEJMoa2001017, 10.1172/JCI89857]
   Zou LR, 2020, NEW ENGL J MED, V382, P1177, DOI [10.1056/NEJMc2001737, 10.1148/radiol.2020200463]
NR 41
TC 6
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18129
EP 18153
DI 10.1007/s11042-022-12214-6
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766064000003
PM 35282403
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Singh, M
   Mehtre, BM
   Sangeetha, S
AF Singh, Malvika
   Mehtre, B. M.
   Sangeetha, S.
TI User behavior based Insider Threat Detection using a Multi Fuzzy
   Classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User Behavior Analysis; Insider Threat Detection; Isometric Feature
   Mapping; Emperor Penguin Algorithm; Term Frequency-Inverse Document
   Frequency; Multi Fuzzy Classifier
AB Insider threats are a significant source of security breaches in organizations. They are often identified using machine and deep learning methods. These methods rely on predefined rules, require explicit feature engineering, and also give rise to more false positives. To overcome these limitations, the proposed work focus on introducing an enhanced insider threat detection method based on user behavior analysis. It leads to fewer false positives, faster threat detection, and significantly higher classifier accuracy. This enhancement is achieved due to: use of data pre-processing steps for removal of noise; use of isometric feature mapping to minimize information loss while extracting the features from a high dimensional space; use of content based features to enhance the feature set for final classification; use of emperor penguin algorithm due to its effective exploitation and exploration for optimum feature selection; and, use of multi fuzzy classifier to parallelly handle variety of features for fast processing. The proposed method is tested on CMU-CERT v4.2 dataset using eight different performance evaluation metrics. Our test results show that the proposed method outperforms the existing methods.
C1 [Singh, Malvika; Mehtre, B. M.] Established Reserve Bank India, Inst Dev & Res Banking Technol, Ctr Excellence Cyber Secur, Hyderabad, India.
   [Singh, Malvika; Sangeetha, S.] Natl Inst Technol, Dept Comp Applicat, Tiruchirappalli, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Singh, M (corresponding author), Established Reserve Bank India, Inst Dev & Res Banking Technol, Ctr Excellence Cyber Secur, Hyderabad, India.; Singh, M (corresponding author), Natl Inst Technol, Dept Comp Applicat, Tiruchirappalli, Tamil Nadu, India.
EM singh23malvika23@gmail.com; bmmehtre@gmail.com; sangeetha@nitt.edu
RI S, Sangeetha/V-3705-2017; Singh, Malvika/IYS-1555-2023
OI S, Sangeetha/0000-0001-6630-1664; Singh, Malvika/0000-0003-4313-4239
CR Almehmadi A, 2018, IEEE ACCESS, V6, P40626, DOI 10.1109/ACCESS.2018.2857450
   [Anonymous], INS THREAT SURV REP
   Bin Ahmad M, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/179109
   Böse B, 2017, IEEE SYST J, V11, P471, DOI 10.1109/JSYST.2016.2558507
   Cao N, 2016, IEEE T VIS COMPUT GR, V22, P280, DOI 10.1109/TVCG.2015.2467196
   Chapman P., 2000, SPSS INC, V9, P13
   Chattopadhyay P, 2018, IEEE T COMPUT SOC SY, V5, P660, DOI 10.1109/TCSS.2018.2857473
   Dhiman G, 2018, KNOWL-BASED SYST, V159, P20, DOI 10.1016/j.knosys.2018.06.001
   Fanzhi Meng, 2018, 2018 IEEE Third International Conference on Data Science in Cyberspace (DSC). Proceedings, P576, DOI 10.1109/DSC.2018.00092
   Iranmanesh SM, 2011, COMM COM INF SC, V164, P46
   Izquierdo SS, 2018, JASSS-J ARTIF SOC S, V21, DOI 10.18564/jasss.3660
   Kott A., 2015, Cyber defense and situational awareness, V62
   Law MHC, 2006, IEEE T PATTERN ANAL, V28, P377, DOI 10.1109/TPAMI.2006.56
   Le DC, 2018, GECCO'18: PROCEEDINGS OF THE 2018 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P1286, DOI 10.1145/3205455.3205612
   Leslie NO, 2018, J DEF MODEL SIMUL-AP, V15, P49, DOI 10.1177/1548512917715342
   Liu L, 2018, INT CONF DAT MIN WOR, P39, DOI 10.1109/ICDMW.2018.00014
   Lo O, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/5906368
   Lu JM, 2019, PROCEEDINGS OF THE AUSTRALASIAN COMPUTER SCIENCE WEEK MULTICONFERENCE (ACSW 2019), DOI 10.1145/3290688.3290692
   May C, 2017, INSIGHT INSIDERS SUR
   Ramos J, 2003, P 1 INSTRUCTIONAL C, V242, P29
   Sen Sevil., 2015, BIOINSPIRED COMPUTAT, P73
   Shearer C., 2000, J. Data Warehous, V5, P13
   Singh M., 2020, MACHINE LEARNING IMA, P559
   Singleton Matthew, 2019, 2019 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2019.8873118
   Willett P, 2006, PROGRAM-ELECTRON LIB, V40, P219, DOI 10.1108/00330330610681295
   Xin Y, 2018, IEEE ACCESS, V6, P35365, DOI 10.1109/ACCESS.2018.2836950
   Yamin MM, 2018, FUTURE INFORM COMMUN, P801
   Zaytsev AS, 2017, AUTOM CONTROL COMPUT, V51, P860, DOI 10.3103/S0146411617080259
   Zhan ZX, 2015, IEEE T INF FOREN SEC, V10, P1666, DOI 10.1109/TIFS.2015.2422261
   Zheng KM, 2009, 2009 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTATIONAL INTELLIGENCE, VOL III, PROCEEDINGS, P235, DOI 10.1109/AICI.2009.242
NR 30
TC 8
Z9 8
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22953
EP 22983
DI 10.1007/s11042-022-12173-y
EA MAR 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000764960200001
DA 2024-07-18
ER

PT J
AU Alam, I
   Kumar, M
AF Alam, Irfan
   Kumar, Manoj
TI A novel protocol for efficient authentication in cloud-based IoT devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; Protocol; ECC; Attacks; XOR; AVISPA
ID KEY AGREEMENT SCHEME; USER AUTHENTICATION; PROVABLY SECURE; INTERNET
AB The Internet of Things (IoT) has emerged as one of the most revolutionary technological innovations with the proliferation of applications within almost all fields of the human race. A cloud environment is the main component of IoT infrastructure to make IoT devices efficient, safe, reliable, usable, and autonomous. Reduction in infrastructure cost and demand accessibility of shared resources are essential parts of cloud-based IoT (CIoT) infrastructure. Information leakage in cloud-assisted IoT devices may invite dangerous activities and phenomena. Various cloud-based systems store IoT sensor data and later on access it accordingly. Some of them are public, and some of them are private. Private cloud services must be secured from external as well as internal adversaries. Hence, there must be a robust mechanism to prevent unauthorized access to devices. This paper proposes a novel and efficient protocol based on the Elliptic Curve property known as Elliptic Curve Discrete Logarithm Problem (ECDLP) with hash and XOR functions for the authentication in cloud-based IoT devices. In comparison to the existing protocols, the proposed protocol is resistant to attacks and other security vulnerabilities. The one-way hash function and XOR function effectively ensure a reduction in computation cost. AVISPA and BAN logic have been used for formal analysis of the proposed protocol. As per the performance analysis results, it is clear that the proposed protocol is efficiently suitable for cloud-assisted IoT devices.
C1 [Alam, Irfan; Kumar, Manoj] Delhi Technol Univ, Dept Comp Sci & Engn, New Delhi 110042, India.
C3 Delhi Technological University
RP Alam, I (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, New Delhi 110042, India.
EM irfanrmamu@gmail.com
RI ALAM, IRFAN/ADM-1817-2022; Pachariya, Manoj/A-9646-2016
OI ALAM, IRFAN/0000-0001-8596-907X; 
CR Almuhaideb AM, 2021, ARAB J SCI ENG, V46, P8189, DOI 10.1007/s13369-021-05442-9
   Alzahrani BA, 2021, ARAB J SCI ENG, V46, P3017, DOI 10.1007/s13369-020-04905-9
   Amin R, 2018, FUTURE GENER COMP SY, V78, P1005, DOI 10.1016/j.future.2016.12.028
   Amin R, 2016, AD HOC NETW, V36, P58, DOI 10.1016/j.adhoc.2015.05.020
   Armando A, 2005, LECT NOTES COMPUT SC, V3576, P281
   Armando Alessandro, 2001, HIGH LEVEL PROTOCOL
   Bae W, 2020, MULTIMED TOOLS APPL, V79, P15793, DOI 10.1007/s11042-017-5548-2
   Banerjee S, 2019, IEEE INTERNET THINGS, V6, P8739, DOI 10.1109/JIOT.2019.2923373
   BURROWS M, 1990, ACM T COMPUT SYST, V8, P18, DOI [10.1145/77648.77649, 10.1145/74851.74852]
   Challa S, 2020, FUTURE GENER COMP SY, V108, P1267, DOI 10.1016/j.future.2018.04.019
   Chang CC, 2016, IEEE T WIREL COMMUN, V15, P357, DOI 10.1109/TWC.2015.2473165
   Chen FL, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/5580939
   Chevalier Y, 2006, HIGH LEVEL PROTOCOL
   Chintala RR, 2021, IMPLEMENTING SECURIT
   Do Xuan C, 2020, J INTELL FUZZY SYST, V39, P4785, DOI 10.3233/JIFS-200694
   DOLEV D, 1983, IEEE T INFORM THEORY, V29, P198, DOI 10.1109/TIT.1983.1056650
   Gadicha AB, 2021, MULTIMODE APPROACH D, P99
   Haack C, 2008, WHAT IS BAN LOGIC VE
   Hankerson D., 2011, Encyclopedia of Cryptography and Security, P397, DOI [10.1007/978-1-4419-5906-5_245, DOI 10.1007/978-1-4419-5906-5_245, DOI 10.1007/978-1-4419-5906-5246]
   IARC Working Group on the Evaluation of Carcinogenic Risks to Humans, 2006, IARC Monogr Eval Carcinog Risks Hum, V88, P1
   Iqbal W, 2020, IEEE INTERNET THINGS, V7, P10250, DOI 10.1109/JIOT.2020.2997651
   Irshad A, 2016, KSII T INTERNET INF, V10, P5572, DOI 10.3837/tiis.2016.12.023
   Islam SKH, 2012, PROCEDIA ENGINEER, V30, P499, DOI 10.1016/j.proeng.2012.01.890
   Kim H, 2019, MULTIMED TOOLS APPL, V78, P3107, DOI 10.1007/s11042-018-5630-4
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   Koppanati RK, 2021, IEEE CONSUM ELECTR M, V10, P41, DOI 10.1109/MCE.2020.3003127
   Kumar K, 2016, IEEE CONF CLOUD COMP, P95, DOI [10.1109/CCEM.2016.025, 10.1109/CCEM.2016.24]
   Kumari S, 2018, J AMB INTEL HUM COMP, V9, P643, DOI 10.1007/s12652-017-0460-1
   LAMPORT L, 1981, COMMUN ACM, V24, P770, DOI 10.1145/358790.358797
   Li HX, 2015, KSII T INTERNET INF, V9, P2719
   Manupriya P, 2017, 2017 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT), DOI 10.1109/INFOCOMTECH.2017.8340639
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   Muhammad G, 2022, IEEE CONSUM ELECTR M, V11, P49, DOI 10.1109/MCE.2021.3089880
   Nandy T, 2019, IEEE ACCESS, V7, P151054, DOI 10.1109/ACCESS.2019.2947723
   Naseer O, 2021, ARAB J SCI ENG, V46, P8233, DOI 10.1007/s13369-021-05446-5
   Pete P, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P322, DOI 10.1109/ICSCCC.2018.8703358
   Rangwani D, 2021, ARAB J SCI ENG, V46, P3865, DOI 10.1007/s13369-020-05276-x
   Ray Partha Pratim, 2016, Future Computing and Informatics Journal, V1, P35, DOI 10.1016/j.fcij.2017.02.001
   Sharma Shikhar, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 703), P51, DOI 10.1007/978-981-10-7895-8_5
   Sierra JM, 2004, LECT NOTES COMPUT SC, V3043, P851
   Sun HY, 2013, APPL MATH INFORM SCI, V7, P1365, DOI 10.12785/amis/070414
   Syverson P, 2001, LOGIC AUTHENTICATION, P63
   Team A, 2006, INF TECHNOL SOLUT, P1
   Team A, 2006, INF SOC TECHN, V1, P1
   Tsai JL, 2015, IEEE SYST J, V9, P805, DOI 10.1109/JSYST.2014.2322973
   Wazid M, 2020, J NETW COMPUT APPL, V150, DOI 10.1016/j.jnca.2019.102496
   Wazid M, 2019, J SYST ARCHITECT, V97, P185, DOI 10.1016/j.sysarc.2018.12.005
   Wazid M, 2016, SECUR COMMUN NETW, V9, P4103, DOI 10.1002/sec.1591
   Wessels J, 2001, APPL BAN LOGIC
   Wu F, 2018, IEEE CONSUM ELECTR M, V7, P38, DOI 10.1109/MCE.2018.2851744
   Wu TY, 2020, IEEE ACCESS, V8, P28096, DOI 10.1109/ACCESS.2020.2969986
   Xue KP, 2014, J COMPUT SYST SCI, V80, P195, DOI 10.1016/j.jcss.2013.07.004
   Yang S, 2011, SOCIAL COMPUTING BEH
NR 54
TC 9
Z9 9
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13823
EP 13843
DI 10.1007/s11042-022-11927-y
EA FEB 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761891100001
DA 2024-07-18
ER

PT J
AU Qjidaa, M
   Ben-Fares, A
   Amakdouf, H
   El Mallahi, M
   Alami, BE
   Maaroufi, M
   Lakhssassi, A
   Qjidaa, H
AF Qjidaa, Mamoun
   Ben-Fares, Anass
   Amakdouf, Hicham
   El Mallahi, Mostafa
   Alami, Badre-eddine
   Maaroufi, Mustapha
   Lakhssassi, Ahmed
   Qjidaa, Hassan
TI Recognizing COVID-19 from chest X-ray images for people in rural and
   remote areas based on deep transfer learning model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Deep transfer learning; CNN; X-ray images; Convolutional
   neural networks
ID INVARIANT
AB In this article, we propose Deep Transfer Learning (DTL) Model for recognizing covid-19 from chest x-ray images. The latter is less expensive, easily accessible to populations in rural and remote areas. In addition, the device for acquiring these images is easy to disinfect, clean and maintain. The main challenge is the lack of labeled training data needed to train convolutional neural networks. To overcome this issue, we propose to leverage Deep Transfer Learning architecture pre-trained on ImageNet dataset and trained Fine-Tuning on a dataset prepared by collecting normal, COVID-19, and other chest pneumonia X-ray images from different available databases. We take the weights of the layers of each network already pre-trained to our model and we only train the last layers of the network on our collected COVID-19 image dataset. In this way, we will ensure a fast and precise convergence of our model despite the small number of COVID-19 images collected. In addition, for improving the accuracy of our global model will only predict at the output the prediction having obtained a maximum score among the predictions of the seven pre-trained CNNs. The proposed model will address a three-class classification problem: COVID-19 class, pneumonia class, and normal class. To show the location of the important regions of the image which strongly participated in the prediction of the considered class, we will use the Gradient Weighted Class Activation Mapping (Grad-CAM) approach. A comparative study was carried out to show the robustness of the prediction of our model compared to the visual prediction of radiologists. The proposed model is more efficient with a test accuracy of 98%, an f1 score of 98.33%, an accuracy of 98.66% and a sensitivity of 98.33% at the time when the prediction by renowned radiologists could not exceed an accuracy of 63.34% with a sensitivity of 70% and an f1 score of 66.67%.
C1 [Qjidaa, Mamoun; Alami, Badre-eddine; Maaroufi, Mustapha] Sidi Mohamed Ben Abdellah Univ, Fac Med & Pharm, Dept Radiol, Fes, Morocco.
   [Ben-Fares, Anass; Amakdouf, Hicham; Qjidaa, Hassan] Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar El Mahraz, Lab Comp Sci Signals Automat & Cognitivism, Fes, Morocco.
   [El Mallahi, Mostafa] Sidi Mohamed Ben Abdellah Univ, High Normal Sch, Math & Comp Sci Dept, Lab Comp Sci & Interdisciplinary Phys, Fes, Morocco.
   [Lakhssassi, Ahmed] Univ Quebec Outaouais, Lab Engn & Adv Micro Syst, Gatineau, PQ, Canada.
C3 Sidi Mohamed Ben Abdellah University of Fez; Hassan II University
   Hospital Center of Fez; Sidi Mohamed Ben Abdellah University of Fez;
   Sidi Mohamed Ben Abdellah University of Fez; University of Quebec;
   University Quebec Outaouais
RP El Mallahi, M (corresponding author), Sidi Mohamed Ben Abdellah Univ, Fac Med & Pharm, Dept Radiol, Fes, Morocco.
EM mostafa.elmallahi@hotmail.com
OI Ben-Fares, Anass/0000-0002-2061-1058; El Mallahi,
   Mostafa/0000-0001-9735-6799
CR Ai T, 2020, RADIOLOGY, V296, pE32, DOI 10.1148/radiol.2020200642
   Amakdouf H, 2021, MULTIMED TOOLS APPL, V80, P3173, DOI 10.1007/s11042-020-09781-x
   Amakdouf H, 2020, MULTIMED TOOLS APPL, V79, P26571, DOI 10.1007/s11042-020-09120-0
   Amakdouf H, 2018, PROCEDIA COMPUT SCI, V127, P226, DOI 10.1016/j.procs.2018.01.118
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Bhatia Y., 2019, 12 INT C CONT COMP I, P1, DOI DOI 10.1109/IC3.2019.8844921
   Choe J, 2019, RADIOLOGY, V292, P365, DOI 10.1148/radiol.2019181960
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Chu DKW, 2020, CLIN CHEM, V66, P549, DOI 10.1093/clinchem/hvaa029
   Chung MS, 2020, EUR RADIOL, V30, P2182, DOI [10.1148/radiol.2020200230, 10.1007/s00330-019-06574-1]
   Cohen JP, 2020, COVID 19 IMAGE DATA, DOI 10.59275/j.melba.2020-48g7
   Corman VM, 2020, EUROSURVEILLANCE, V25, P23, DOI 10.2807/1560-7917.ES.2020.25.3.2000045
   Dai W., 2008, NIPS, P353, DOI DOI 10.5555/2981780.2981825
   Dhama K, 2020, CLIN MICROBIOL REV, V33, DOI 10.1128/CMR.00028-20
   El Mallahi, 2017, INT C MULT COMP SYST
   El Mallahi M., 2017, Pattern Recognition and Image Analysis, V27, P810
   El Mallahi M, 2018, NEURAL COMPUT APPL, V30, P2283, DOI 10.1007/s00521-016-2782-x
   El Mallahi M, 2018, INT J AUTOM COMPUT, V15, P277, DOI 10.1007/s11633-017-1071-1
   El Mallahi M, 2018, MULTIMED TOOLS APPL, V77, P6583, DOI 10.1007/s11042-017-4573-5
   El Mallahi M, 2017, 2017 INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV)
   Gavai NR, 2017, 2017 INTERNATIONAL CONFERENCE ON BIG DATA, IOT AND DATA SCIENCE (BID), P154, DOI 10.1109/BID.2017.8336590
   Gómez P, 2019, MED BIOL ENG COMPUT, V57, P1451, DOI 10.1007/s11517-019-01965-4
   Hemdan E. E.- D., 2020, . arXiv preprint arXiv:2003.11055
   Huang CL, 2020, LANCET, V395, P497, DOI [10.1016/S0140-6736(20)30183-5, 10.1016/S0140-6736(20)30211-7]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Khan AI, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105581
   Machhour, 2019 IM CLASS US LEG, P305
   Machhour A., 2020, EMBEDDED SYSTEMS ART, DOI [10.1007/978-981-15-0947-6_29, DOI 10.1007/978-981-15-0947-6_29]
   Machhour A, 2020, ADV SMART TECHNOLOGI, V684, DOI [10.1007/978-3-030-53187-4_18, DOI 10.1007/978-3-030-53187-4_18]
   Mahmood S, 2020, JMIR PUBLIC HLTH SUR, V6, P226, DOI 10.2196/18980
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Ravishankar H, 2016, LECT NOTES COMPUT SC, V10008, P188, DOI 10.1007/978-3-319-46976-8_20
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Sethy PK, 2020, INT J MATH ENG MANAG, V5, P643, DOI 10.33889/IJMEMS.2020.5.4.052
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sohrabi C, 2020, INT J SURG, V76, P71, DOI 10.1016/j.ijsu.2020.02.034
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Wang S, 2021, EUR RADIOL, V31, P6096, DOI [10.1080/1064119X.2021.1966557, 10.1079/9781789246070.0001, 10.1007/s00330-021-07715-1]
   Wang X., 2017, PROC CVPR IEEE, P2097, DOI [DOI 10.1109/CVPR.2017.369, 10.1109/CVPR.2017.369]
   Yang HN, 2020, CLIN CARDIOL, V43, P450, DOI 10.1002/clc.23341
   Zhang NR, 2020, J MED VIROL, V92, P408, DOI 10.1002/jmv.25674
   Zouhri A, 2020, PATTERN RECOGN IMAGE, V30, P87, DOI 10.1134/S1054661820010186
NR 43
TC 2
Z9 2
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 13115
EP 13135
DI 10.1007/s11042-022-12030-y
EA FEB 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000760059700005
PM 35221780
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Bhuvaneshwari, P
   Rao, AN
   Robinson, YH
   Thippeswamy, MN
AF Bhuvaneshwari, P.
   Rao, A. Nagaraja
   Robinson, Y. Harold
   Thippeswamy, M. N.
TI Sentiment analysis for user reviews using Bi-LSTM self-attention based
   CNN model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; Subjectivity classification; Bidirectional LSTM;
   Self-attention; Convolutional neural network
AB In this digital era, people are increasingly sharing their opinions in online review sites, and vast amounts of customer feedback are generated daily. Many customers make use of these unstructured text reviews feedback for their decision making. However, the customer feedback is exponentially huge, and reading all the reviews is tedious. Due to the maximum length of sentences, textual order changes, and logical complications, it is still a challenging area to predict the exact sentiment polarities of the user textual feedback reviews for a given entity. To address these problems, we introduce Bi-LSTM Self Attention based Convolutional Neural Network (BAC) model for subjectivity classification of reviews. In our approach, we employ pre-trained word embedding to reduce the dimension of the text representation, which avoids data sparsity issues. We also apply an attention mechanism to capture n-gram features and focus on the crucial information from the context by setting different weights between words and sentences. The proposed model uses CNN and Bi-LSTM to automatically learn classification features as well as capture the semantic and contextual information which is crucial in determining the sentiment polarities. To assess the performance of the proposed BAC model, it is compared with other baseline methods. The proposed model has achieved the accuracy of 89% and the F1-measure value of 91%.
C1 [Bhuvaneshwari, P.] MVJ Coll Engn, Dept Comp Sci & Engn, Bangalore, Karnataka, India.
   [Rao, A. Nagaraja] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
   [Robinson, Y. Harold] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
   [Thippeswamy, M. N.] Nitte Meenakshi Inst Technol, Dept Comp Sci & Engn, Bangalore, Karnataka, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of
   Technology (VIT); VIT Vellore; Nitte Meenakshi Institute of Technology
RP Robinson, YH (corresponding author), Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
EM thenameisbhuvanapatt@gmail.com; nagarajaraoa@vit.ac.in;
   yhrobinphd@gmail.com; thippeswamy.mn@nmit.ac.in
RI ; ROBINSON, HAROLD/A-1545-2016
OI Muddenahalli Nagendrappa, Thippeswamy/0000-0002-5626-5919; P, Dr
   Bhuvaneshwari/0000-0003-2938-9059; ROBINSON, HAROLD/0000-0002-4881-7103
CR [陈珂 Chen Ke], 2018, [计算机研究与发展, Journal of Computer Research and Development], V55, P945
   [陈钊 Chen Zhao], 2015, [中文信息学报, Journal of Chinese Information Processing], V29, P172
   De Mulder W, 2015, COMPUT SPEECH LANG, V30, P61, DOI 10.1016/j.csl.2014.09.005
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Dong L, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P49
   Geng ZQ, 2020, INFORM SCIENCES, V509, P183, DOI 10.1016/j.ins.2019.09.006
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Horrigan J., 2008, Online Shopping
   Johnson Rie, 2015, Adv Neural Inf Process Syst, V28, P919
   Li L, 2020, NEURAL COMPUT APPL, V32, P4387, DOI 10.1007/s00521-018-3865-7
   Li WJ, 2020, NEUROCOMPUTING, V387, P63, DOI 10.1016/j.neucom.2020.01.006
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Mikolov Tomas, 2013, EFFICIENT ESTIMATION
   Rathor Abhilasha Singh, 2018, Procedia Computer Science, V132, P1552, DOI 10.1016/j.procs.2018.05.119
   Tang DY, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1014
   Tang Duyu, 2015, P 2015 C EMPIRICAL M, P1422
   Wang P, 2021, DECIS SUPPORT SYST, V149, DOI 10.1016/j.dss.2021.113603
   Xie J, 2019, IEEE ACCESS, V7, P180558, DOI 10.1109/ACCESS.2019.2957510
   Yuan J., 2015, Multimedia Data Mining and Analytics, P31, DOI DOI 10.1007/978-3-319-14998-1_2
   Yue W, 2020, 2020 SEVENTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORK ANALYSIS, MANAGEMENT AND SECURITY (SNAMS), P35, DOI 10.1109/SNAMS52053.2020.9336549
NR 20
TC 24
Z9 25
U1 7
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12405
EP 12419
DI 10.1007/s11042-022-12410-4
EA FEB 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000758308400010
DA 2024-07-18
ER

PT J
AU Huang, CB
   Wan, MH
AF Huang, Chuanbo
   Wan, Minghua
TI Automated segmentation of brain tumor based on improved U-Net with
   residual units
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Residual units; Brain magnetic resonance imaging; Residual learning;
   Deep learning network
ID CONVOLUTIONAL NEURAL-NETWORKS; IMAGE
AB The study presents a new approach to automate segmentation of clinically significant brain tumor and, to a certain extent, addresses two major issues associated with brain tumor segmentation, namely, structural complexity and class imbalance. By combining the constructed new residual learning model and the structural advantages of U-Net convolutional neural network (CNN), a novel residual structural network was developed. First, the residual unit is constructed to further construct the entire network architecture, which can simplify the training process of the convolutional network and enrich the skip connections of the network to improve the feature extraction effect. Second, the fusion of basic classifiers dynamically trained with samples of different categories can achieve greater flexibility and higher accuracy. First, maximum pooling and batch normalization were employed to improve regularization; thus, the model includes fewer network parameters but exhibits superior performance. The method was subsequently verified on the BRATS 2018 database. For High Grade Gliomas (HGG) and Low Grade Gliomas (LGG) mixed data, the method achieved Dice coefficient metric of 95.36, 92.86, and 89.93; Recall metric of 95.14, 92.04, and 89.69; and Intersection over union metric of 91.17, 86.79, and 81.93 for the complete, core, and enhancing regions, respectively.
C1 [Huang, Chuanbo] Jining Univ, Dept Comp Sci, Qufu, Shandong, Peoples R China.
   [Wan, Minghua] Nanjing Audit Univ, Sch Informat Engn, Nanjing, Peoples R China.
C3 Jining University; Nanjing Audit University
RP Huang, CB (corresponding author), Jining Univ, Dept Comp Sci, Qufu, Shandong, Peoples R China.
EM huangchuanbocq@126.com; wmh36@sina.com
OI huang, chuanbo/0000-0002-2496-2410
FU National Natural Science Foundation of China [61876213]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61876213.
CR Akkus Z, 2017, J DIGIT IMAGING, V30, P449, DOI 10.1007/s10278-017-9983-4
   Beghdadi A, 2013, SIGNAL PROCESS-IMAGE, V28, P811, DOI 10.1016/j.image.2013.06.003
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Brosch T, 2016, IEEE T MED IMAGING, V35, P1229, DOI 10.1109/TMI.2016.2528821
   cicek Ozgtin, 2016, INT C MED IM COMP CO, P424, DOI DOI 10.1007/978-3-319-46723-8_49
   Despotovic I, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/450341
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Drozdzal M, 2016, LECT NOTES COMPUT SC, V10008, P179, DOI 10.1007/978-3-319-46976-8_19
   Ehrig M., 2005, INTEGRATING ONTOLOGI, P25
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Ghafoorian M, 2016, I S BIOMED IMAGING, P1414, DOI 10.1109/ISBI.2016.7493532
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Huang A, 2010, IEEE T IMAGE PROCESS, V19, P2737, DOI 10.1109/TIP.2010.2048965
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Isin A, 2016, PROCEDIA COMPUT SCI, V102, P317, DOI 10.1016/j.procs.2016.09.407
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Kermi A, 2019, LECT NOTES COMPUT SC, V11384, P37, DOI 10.1007/978-3-030-11726-9_4
   Kingma D. P., 2014, arXiv
   Kociolek M, 2020, COMPUT MED IMAG GRAP, V81, DOI [10.1016/j.compmedimg.2020.101716, 10.1016/j.compmedimag.2020.101716]
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu ZH, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105768
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mahmood Q, 2015, IRBM, V36, P185, DOI 10.1016/j.irbm.2015.01.007
   Materka A, 2013, SIG P ALGO ARCH ARR, P118
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nyúl LG, 1999, MAGNET RESON MED, V42, P1072, DOI 10.1002/(SICI)1522-2594(199912)42:6<1072::AID-MRM11>3.0.CO;2-M
   Nyúl LG, 2000, IEEE T MED IMAGING, V19, P143, DOI 10.1109/42.836373
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315
   Rahman Md Atiqur, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P234, DOI 10.1007/978-3-319-50835-1_22
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shehab LH., 2021, J KING SAUD U ENG SC, V33, P404, DOI [DOI 10.1016/J.JKSUES.2020.06.001, 10.1016/j.jksues.2020.06.001]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song YY, 2015, IEEE T BIO-MED ENG, V62, P2421, DOI 10.1109/TBME.2015.2430895
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tian GJ, 2011, IEEE T INF TECHNOL B, V15, P373, DOI 10.1109/TITB.2011.2106135
   Tustison NJ, 2010, IEEE T MED IMAGING, V29, P1310, DOI 10.1109/TMI.2010.2046908
   Van Leemput K, 2009, IEEE T MED IMAGING, V28, P822, DOI 10.1109/TMI.2008.2010434
   Wang CH, 2015, IEEE ENG MED BIO, P2415
   Yang W, 2017, MED IMAGE ANAL, V35, P421, DOI 10.1016/j.media.2016.08.004
   Zhang DW, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107562
   Zhang ZP, 2019, IEEE ACM T COMPUT BI, V16, P407, DOI 10.1109/TCBB.2017.2704587
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
NR 49
TC 5
Z9 5
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12543
EP 12566
DI 10.1007/s11042-022-12335-y
EA FEB 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000758308400005
DA 2024-07-18
ER

PT J
AU Hao, J
   Huang, FY
   Shen, X
   Jiang, CD
   Lin, XR
AF Hao, Jing
   Huang, Fuyu
   Shen, Xuejv
   Jiang, Chundong
   Lin, Xiaoran
TI An adaptive stochastic resonance detection method with a knowledge-based
   improved artificial fish swarm algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive stochastic resonance; Multifrequency weak signal; Artificial
   fish swarm algorithm; Parameter optimization
ID OPPOSITION; NOISE
AB The selection of the parameters plays a decisive role in the detection performance of parameter- tuning stochastic resonance (SR) system. In order to solve the problems that the existing adaptive stochastic resonance (ASR) system is easy to fall into local optimum and slow convergence rate in parameter optimization, an ASR detection method with knowledge-based improved artificial fish swarm algorithm (AFSA) is proposed. The lens based Opposition-based Learning strategy (lensOBL) is introduced into the AFSA, micro and macro adjustments can be made to enhance the global search ability, especially in the later stage of the algorithm. In addition, in order to speed up the convergence rate of the optimization, the relationship between the system structure parameters and the SR phenomenon produced is considered to guide the optimization process of the algorithm. Compared with the ASR methods based on the AFSA, the proposed method can obtain better parameters and improves the detection performance of the system. Additionally, to solve the problem of detecting multifrequency weak signals submerged in strong noise and many frequency bandwidths, firstly, the SR of the weak signal of large parameters is realized through adjusting the damping coefficient and the system shape parameters, which solves the problem that the traditional SR is only suitable for small parameter weak signal detection. Then, parallel ASR detection systems are designed based on the idea of the proposed method to identify multifrequency weak radio signals. Finally, simulation data and experimental analysis show that, compared with other adaptive parameter-tuning SR methods, the proposed method enhances the convergence speed and accuracy of optimization, has good robustness, and improves the diversity of fish swarm. It enables the optimal detection of multifrequency weak signal better in strong noise background, and broadens the potential applications of weak signal detection methods based on the principle of SR.
C1 [Hao, Jing; Lin, Xiaoran] Hebei Univ Econ & Business, Sch Informat Technol, Shijiazhuang, Hebei, Peoples R China.
   [Hao, Jing; Huang, Fuyu; Shen, Xuejv] Army Engn Univ, Dept Elect & Opt Engn, Shijiazhuang, Hebei, Peoples R China.
   [Jiang, Chundong] Hebei Univ Technol, Sch Artificial Intelligence, Tianjin, Peoples R China.
C3 Hebei University of Economics & Business; Army Engineering University of
   PLA; Hebei University of Technology
RP Hao, J (corresponding author), Hebei Univ Econ & Business, Sch Informat Technol, Shijiazhuang, Hebei, Peoples R China.; Hao, J (corresponding author), Army Engn Univ, Dept Elect & Opt Engn, Shijiazhuang, Hebei, Peoples R China.
EM haojingice@163.com; hfyoptics@163.com; chundong_j@163.com
FU National Natural Science Foundation of China [61801507]; Key Project of
   Education Department of Hebei Province [ZD2017216]; Research Foundation
   of Hebei University of Economics and Business [2019YB08, 2018QZ05];
   Science and Technology Research Project of Higher Education of Hebei
   Province [QN2019069]
FX This research was funded by the National Natural Science Foundation of
   China, grant number 61801507; This research was funded by the Key
   Project of Education Department of Hebei Province, grant number
   ZD2017216; This research was funded by the Research Foundation of Hebei
   University of Economics and Business, grant number 2019YB08, 2018QZ05;
   This research was funded by the Science and Technology Research Project
   of Higher Education of Hebei Province, grant number QN2019069.
CR Agarwal M, 2021, J AMB INTEL HUM COMP, V12, P9855, DOI 10.1007/s12652-020-02730-4
   ASDI AS, 1995, INT CONF ACOUST SPEE, P1332, DOI 10.1109/ICASSP.1995.480486
   BENZI R, 1981, J PHYS A-MATH GEN, V14, pL453, DOI 10.1088/0305-4470/14/11/006
   Bernardino EM, 2013, J NETW COMPUT APPL, V36, P504, DOI 10.1016/j.jnca.2012.04.005
   Carozzo S, 2021, IBRO NEUROSCI REP, V10, P191, DOI 10.1016/j.ibneur.2021.03.001
   Chen Fen, 2018, Journal of Data Acquisition and Processing, V33, P1013, DOI 10.16337/j.1004-9037.2018.06.009
   Choi TJ, 2021, SWARM EVOL COMPUT, V60, DOI 10.1016/j.swevo.2020.100768
   Fan J, 2014, ACTA PHYS SIN-CH ED, V63, DOI 10.7498/aps.63.110506
   Gao KP, 2021, MEASUREMENT, V178, DOI 10.1016/j.measurement.2021.109304
   Guo FD, 2022, INT J PAVEMENT ENG, V23, P2631, DOI 10.1080/10298436.2020.1867854
   Hao Jing, 2017, Journal of Zhejiang University (Engineering Science), V51, P2084, DOI 10.3785/j.issn.1008-973X.2017.10.025
   Hao Jing, 2016, Journal of Computer Applications, V36, P2374, DOI 10.11772/j.issn.1001-9081.2016.09.2374
   Ikemoto S, 2021, NEUROCOMPUTING, V448, P1, DOI 10.1016/j.neucom.2020.05.125
   Kim H, 2019, MECH SYST SIGNAL PR, V122, P769, DOI 10.1016/j.ymssp.2018.12.040
   Kumar A, 2020, PHYS COMMUN-AMST, V39, DOI 10.1016/j.phycom.2019.100995
   Leng YG, 2014, ACTA PHYS SIN-CH ED, V63, DOI 10.7498/aps.63.020502
   [李晓磊 Li Xiaolei], 2002, [系统工程理论与实践, Systems Engineering-Theory & Practice], V22, P32
   Li ZX, 2019, J SOUND VIB, V459, DOI 10.1016/j.jsv.2019.114862
   Liu, 2017, SPECTRUM ALLOCATION
   Mitaim S, 1998, P IEEE, V86, P2152, DOI 10.1109/5.726785
   Qiu YW, 2021, APPL ACOUST, V173, DOI 10.1016/j.apacoust.2020.107688
   Rahnamayan S, 2008, APPL SOFT COMPUT, V8, P906, DOI 10.1016/j.asoc.2007.07.010
   Rahnamayan S, 2008, IEEE T EVOLUT COMPUT, V12, P64, DOI 10.1109/TEVC.2007.894200
   Shao WH, 2018, SIGNAL PROCESS, V142, P96, DOI 10.1016/j.sigpro.2017.06.027
   [苏慧慧 Su Huihui], 2020, [应用科学学报, Journal of Applied Sciences], V38, P882
   Tizhoosh HR, 2006, INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING, CONTROL & AUTOMATION JOINTLY WITH INTERNATIONAL CONFERENCE ON INTELLIGENT AGENTS, WEB TECHNOLOGIES & INTERNET COMMERCE, VOL 1, PROCEEDINGS, P695, DOI 10.1109/cimca.2005.1631345
   Tong L, 2018, IEEE ACCESS, V6, P1167, DOI 10.1109/ACCESS.2017.2778022
   Wang Jing, 2010, Journal of Xi'an Jiaotong University, V44, P32
   Wang J, 2014, IEEE T WIREL COMMUN, V13, P4014, DOI 10.1109/TWC.2014.2317779
   [王培崇 Wang Peichong], 2015, [计算机应用研究, Application Research of Computers], V32, P1992
   Yang, 2004, METHODOLOGY APPL WEA
   [喻飞 Yu Fei], 2014, [电子学报, Acta Electronica Sinica], V42, P230
   [周凌云 Zhou Lingyun], 2017, [电子学报, Acta Electronica Sinica], V45, P2815
NR 33
TC 6
Z9 6
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11773
EP 11794
DI 10.1007/s11042-022-12076-y
EA FEB 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757777400002
DA 2024-07-18
ER

PT J
AU Guo, CS
   Cai, M
   Ying, N
   Chen, HH
   Zhang, JW
   Zhou, D
AF Guo, Chunsheng
   Cai, Meng
   Ying, Na
   Chen, HuaHua
   Zhang, Jianwu
   Zhou, Di
TI ANMS: attention-based non-maximum suppression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Non-maximum suppression; Attention map
ID MODEL
AB Non-Maximum Suppression (NMS) is an essential part of the object detection pipeline. However, due to the inconsistency between the classification confidence and the object localization, NMS may mistakenly eliminate the bounding boxes with low classification confidence and high localization accuracy. In this paper, we propose an attention-based non-maximum suppression (ANMS) algorithm. It reconstructs the attention map to obtain the object location information by backpropagating the top-level object classification semantic information. Furthermore, integrating the classification confidence and the attention map of the detection bounding boxes adjust the inconsistency between the classification confidence and the object localization. On the PASCAL VOC2007 and the PASCAL VOC2012 datasets, the proposed ANMS algorithm achieved 1.85 and 1.24 performance improvement over the NMS algorithm. On the MS COCO datasets, the proposed ANMS algorithm achieved 0.3 performance improvement, which proved the ANMS algorithm's effectiveness.
C1 [Guo, Chunsheng; Cai, Meng; Ying, Na; Chen, HuaHua; Zhang, Jianwu] Hangzhou Dianzi Univ, Coll Commun Engn, Hangzhou 310018, Peoples R China.
   [Zhou, Di] Zhejiang Uniview Technol Co Ltd, Hangzhou 310051, Peoples R China.
C3 Hangzhou Dianzi University
RP Guo, CS (corresponding author), Hangzhou Dianzi Univ, Coll Commun Engn, Hangzhou 310018, Peoples R China.
EM guo.chsh@gmail.com
RI Guo, Chunsheng/AAA-1181-2020
OI Guo, Chunsheng/0000-0003-1633-3507
CR [Anonymous], 2014, Advances in Neural Information Processing Systems
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Cao CS, 2015, IEEE I CONF COMP VIS, P2956, DOI 10.1109/ICCV.2015.338
   Chen YH, 2016, ENERGIES, V9, DOI 10.3390/en9020070
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Everingham M., 2007, The PASCAL Visual Object Classes Chal- lenge (VOC) Results, DOI 10.1007/s11263-009-0275-4
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan GF, 2013, ENERGIES, V6, P1887, DOI 10.3390/en6041887
   He Y., 2018, Softer-nms: Rethinking bounding box regression for accurate object detection
   He Y., 2017, ARXIV170508508
   Hosang J, 2017, PROC CVPR IEEE, P6469, DOI 10.1109/CVPR.2017.685
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Li MW, 2021, NONLINEAR DYNAM, V103, P1167, DOI 10.1007/s11071-020-06111-6
   Liang XD, 2018, LECT NOTES COMPUT SC, V11211, P604, DOI 10.1007/978-3-030-01234-2_36
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S, 2019, ADAPTIVE NMS REFININ
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Ning CC, 2017, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2017.8026312
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shrivastava A, 2016, LECT NOTES COMPUT SC, V9905, P330, DOI 10.1007/978-3-319-46448-0_20
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Zhang JM, 2018, INT J COMPUT VISION, V126, P1084, DOI 10.1007/s11263-017-1059-x
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
NR 26
TC 0
Z9 0
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11205
EP 11219
DI 10.1007/s11042-022-12142-5
EA FEB 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757168400009
DA 2024-07-18
ER

PT J
AU Basu, S
   Li, CX
   Cohen, F
AF Basu, Semanti
   Li, Chenxi
   Cohen, Fernand
TI Anthropometric salient points and convolutional neural network (CNN) for
   3D human body classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model classification; CNN; 3D reconstruction; Landmark detection
ID IMAGES; MODELS
AB In this paper, we introduce a 3D body shape biometric for recognizing a person as one of C possible individuals stored in a database in 3D free form (scatter of 3D data points) using a couple of canonical images (front and side) taken of that individual. The first step is to reconstruct the full body 3D shape model of the individual based on their frontal and profile silhouette images. This is done by using a 3D generic model that gets morphed in accordance with the canonical images of the individual. Starting with a small set of anthropometric interconnected ordered intrinsic control points residing on the silhouette boundary of the projections of the generic model onto the frontal and profile image spaces, corresponding control points on two canonical images of the person are automatically found. This imports equivalent saliency between the two sets. The positions of these control points on the canonical images are attained using deep convolutional neural networks (CNNs) that have been trained offline on a set of images of different individuals. Further equivalent saliencies between the projected points from the generic model and the canonical images are established through loop-subdivision. To personalize the generic model, points on the generic model are morphed to be consistent with their equivalent points on the canonical images. The 3D reconstruction yields sub-resolution errors when tested on the CAESAR data set with 700 different individuals. Classification based on the error between salient points with identical anthropometric meaning residing on nested sets of boundaries in the frontal and side projections, achieves an accuracy of 96%. This is to be compared to an accuracy of 72% when using KNN nearest distance point classification between test and base models.
C1 [Basu, Semanti; Li, Chenxi; Cohen, Fernand] Drexel Univ, Dept Elect & Comp Engn, Philadelphia, PA 19104 USA.
C3 Drexel University
RP Basu, S (corresponding author), Drexel Univ, Dept Elect & Comp Engn, Philadelphia, PA 19104 USA.
EM sb3533@drexel.edu; cl982@drexel.edu; fsc22@drexel.edu
OI Li, Chenxi/0000-0002-0963-4363; Basu, Semanti/0000-0002-3129-5265
CR Meda-Campaña JA, 2018, IEEE ACCESS, V6, P31968, DOI 10.1109/ACCESS.2018.2846483
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2010, BIOMETRICS THEORY AP
   Aquino G, 2020, IEEE ACCESS, V8, P46324, DOI 10.1109/ACCESS.2020.2979141
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bergeon Y., 2015, International Conference on Military Technologies (ICMT) 2015, Brno, P1, DOI [DOI 10.1109/MILTECHS.2015.7153749, 10.1109/MILTECHS.2015.7153749]
   BRUNELLI R, 1995, IEEE T PATTERN ANAL, V17, P955, DOI 10.1109/34.464560
   Bushaev V., 2018, MEDIUM 1024
   Chen YM, 2014, IEEE J-STARS, V7, P4081, DOI 10.1109/JSTARS.2014.2306003
   Chengze Yang, 2011, 2011 International Conference on Multimedia Technology, P6
   Chiang HS, 2019, IEEE ACCESS, V7, P103255, DOI 10.1109/ACCESS.2019.2929266
   Collins RT, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P366, DOI 10.1109/AFGR.2002.1004181
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cu L, 2008, LECT NOTES COMPUT SC, V5302, P413, DOI 10.1007/978-3-540-88682-2_32
   Rubio JD, 2009, IEEE T FUZZY SYST, V17, P1296, DOI 10.1109/TFUZZ.2009.2029569
   Elias I, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10124239
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Godil A, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P386, DOI 10.1109/IM.2003.1240273
   Green RD, 2004, IEEE T CIRC SYST VID, V14, P191, DOI 10.1109/TCSVT.2003.821977
   He ZL, 2017, IEEE INT CONF AUTOMA, P200, DOI 10.1109/FG.2017.33
   HERNANDEZ G, IN PRESS
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kim H, 2019, I C INF COMM TECH CO, P669, DOI 10.1109/ictc46691.2019.8939984
   Lanitis A, 2009, 2009 9TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND APPLICATIONS IN BIOMEDICINE, P107
   Lee B, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P4942
   Li C, 2020, J MULTIMEDIA TOOLS A, DOI 10.1007/s11042-020-09989
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lunscher N, 2018, IEEE COMPUT SOC CONF, P1208, DOI 10.1109/CVPRW.2018.00157
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Mebsout I., 2020, MEDIUM 1003
   Medioni G, 2009, IEEE T SYST MAN CY A, V39, P12, DOI 10.1109/TSMCA.2008.2007979
   Munaro M, 2014, ADV COMPUT VIS PATT, P161, DOI 10.1007/978-1-4471-6296-4_8
   Nishad G., 2019, MEDIUM 0324
   Pang H, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P979, DOI 10.1109/CISP.2015.7408021
   Pavlakos G, 2018, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2018.00055
   Shih-Chi Yang, 2017, 2017 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), P127, DOI 10.1109/ICCE-China.2017.7991028
   Smith BM, 2019, INT CONF 3D VISION, P279, DOI 10.1109/3DV.2019.00039
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Temiz H., 2019, INT CONF IMAG PROC, P1, DOI DOI 10.1109/ipta.2019.8936071
   Wang W-H A., 2010, 2010 IEEE 17th International Conference on Industrial Engineering and Engineering Management (IE&EM2010), P1877, DOI 10.1109/ICIEEM.2010.5645895
   Wang Z., 2010, 2010 International Conference on Multimedia Technology, Ningbo, P1, DOI DOI 10.1109/ICCW.2010.5503924
   Xiaozhi Li, 2010, Proceedings of the 2010 International Conference on Intelligent Computation Technology and Automation (ICICTA 2010), P441, DOI 10.1109/ICICTA.2010.849
   Yueh-Ling Lin, 2010, 2010 IEEE 17th International Conference on Industrial Engineering and Engineering Management (IE&EM2010), P1902, DOI 10.1109/ICIEEM.2010.5645897
   Zhang J, 2017, IEEE T IMAGE PROCESS, V26, P4753, DOI 10.1109/TIP.2017.2721106
   Zhong QB, 2014, PROCEEDINGS OF 2014 IEEE WORKSHOP ON ADVANCED RESEARCH AND TECHNOLOGY IN INDUSTRY APPLICATIONS (WARTIA), P976, DOI 10.1109/WARTIA.2014.6976437
NR 46
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10497
EP 10527
DI 10.1007/s11042-022-12284-6
EA FEB 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000756332700008
DA 2024-07-18
ER

PT J
AU Shi, KH
AF Shi, Kehan
TI A gray level indicator-based nonlinear diffusion equation for the
   removal of random-valued impulse noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Random-valued noise; Diffusion equation; Gray level
   indicator
ID WEIGHTED MEAN FILTER; MEDIAN FILTER; EDGE-DETECTION; ALGORITHM;
   RESTORATION; REDUCTION; DETECTOR
AB This paper proposes a nonlinear diffusion equation with two diffusivities to restore images corrupted by random-valued impulse noise. A Perona-Malik type diffusivity is utilized for anisotropic diffusion and a gray level based diffusivity called gray level indicator is proposed to estimate the amplitude of the noise. Then the proposed equation has a large diffusion coefficient for homogeneous regions and regions corrupted by large impulse noise. Conversely, it has a small diffusion coefficient for regions with edges, fine details, as well as regions corrupted by small impulse noise. The gray level indicator is constructed as the square of the difference between the noisy image and a reference image deduced from median-type filters. The new equation is able to remove small random-valued impulse noise that is difficult to be detected. A robust stopping criteria based on the complexity of the restored image and the noise level is proposed. Numerical experiments show that it outperforms PDE-based methods and nonlocal methods.
C1 [Shi, Kehan] China Jiliang Univ, Dept Math, Hangzhou 310018, Peoples R China.
C3 China Jiliang University
RP Shi, KH (corresponding author), China Jiliang Univ, Dept Math, Hangzhou 310018, Peoples R China.
EM kshi@cjlu.edu.cn
OI Shi, Kehan/0000-0003-0879-7766
FU National Natural Science Foundation of China [12001509]; Natural Science
   Foundation of Zhejiang Province [LQ21A010010]
FX The authors would like to thank Ming Yan for sharing his code of AOP
   with us and thank Yang Chen for sharing his code of SAFE with us. The
   author would also like to thank the referees for the valuable
   suggestions and comments. This work was supported by the National
   Natural Science Foundation of China (12001509) and the Natural Science
   Foundation of Zhejiang Province (LQ21A010010).
CR Adam T, 2021, MULTIMED TOOLS APPL, V80, P18503, DOI 10.1007/s11042-021-10583-y
   Andreadis I, 2004, IEEE T INSTRUM MEAS, V53, P798, DOI 10.1109/TIM.2004.827306
   [Anonymous], 2006, Mathematical problems in image processing: Partial differential equations and the calculus of variations
   Bresson X, 2008, INVERSE PROBL IMAG, V2, P455, DOI 10.3934/ipi.2008.2.455
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Chan TF, 2005, IMAGE PROCESSING AND ANALYSIS, P1
   Chen HC, 2009, FUZZY SET SYST, V160, P1841, DOI 10.1016/j.fss.2008.11.020
   Chen JY, 2019, IET IMAGE PROCESS, V13, P946, DOI 10.1049/iet-ipr.2018.6331
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   Chen Y, 2018, IEEE T CIRC SYST VID, V28, P414, DOI 10.1109/TCSVT.2016.2615444
   Dong YQ, 2007, IEEE T IMAGE PROCESS, V16, P1112, DOI 10.1109/TIP.2006.891348
   Goel N, 2020, MULTIMED TOOLS APPL, V79, P19739, DOI 10.1007/s11042-020-08687-y
   Gonzalez R.C., 2002, Digital image processing second edition, P455
   Guo ZC, 2012, IEEE T IMAGE PROCESS, V21, P958, DOI 10.1109/TIP.2011.2169272
   Hosseini H, 2015, IEEE SIGNAL PROC LET, V22, P1050, DOI 10.1109/LSP.2014.2381649
   Hosseini H, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-15
   Hsieh MH, 2013, ENG APPL ARTIF INTEL, V26, P1333, DOI 10.1016/j.engappai.2012.10.012
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Ibrahim H, 2008, IEEE T CONSUM ELECTR, V54, P1920, DOI 10.1109/TCE.2008.4711254
   Khan NU, 2020, MULTIMED TOOLS APPL, V79, P33811, DOI 10.1007/s11042-020-08707-x
   Lee CS, 1997, FUZZY SET SYST, V89, P157, DOI 10.1016/S0165-0114(96)00075-9
   Liu JJ, 2020, J COMPUT APPL MATH, V378, DOI 10.1016/j.cam.2020.112934
   Liu LC, 2015, INFORM SCIENCES, V315, P1, DOI 10.1016/j.ins.2015.03.067
   Luo WB, 2006, IEEE SIGNAL PROC LET, V13, P413, DOI 10.1109/LSP.2006.873144
   Luo WB, 2005, IEICE T FUND ELECTR, VE88A, P2579, DOI 10.1093/ietfec/e88-a.10.2579
   Meng XX, 2021, IET IMAGE PROCESS, V15, P228, DOI 10.1049/ipr2.12023
   Nikolova M, 2004, J MATH IMAGING VIS, V20, P99, DOI 10.1023/B:JMIV.0000011920.58935.9c
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Roy A, 2017, IET IMAGE PROCESS, V11, P352, DOI 10.1049/iet-ipr.2016.0320
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Schulte S, 2006, IEEE T IMAGE PROCESS, V15, P1153, DOI 10.1109/TIP.2005.864179
   Shi KH, 2020, COMPUT MATH APPL, V80, P2090, DOI 10.1016/j.camwa.2020.08.027
   Shi KH, 2016, NEUROCOMPUTING, V173, P659, DOI 10.1016/j.neucom.2015.08.012
   Shi KH, 2015, J MATH IMAGING VIS, V51, P400, DOI 10.1007/s10851-014-0531-2
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu J, 2014, SIGNAL IMAGE VIDEO P, V8, P349, DOI 10.1007/s11760-012-0297-1
   Wu J, 2011, IEEE T IMAGE PROCESS, V20, P2428, DOI 10.1109/TIP.2011.2131664
   Xiong B, 2012, IEEE T IMAGE PROCESS, V21, P1663, DOI 10.1109/TIP.2011.2172804
   Yan M, 2013, SIAM J IMAGING SCI, V6, P1227, DOI 10.1137/12087178X
   Yang JF, 2009, SIAM J SCI COMPUT, V31, P2842, DOI 10.1137/080732894
   Yuan GZ, 2019, IEEE T PATTERN ANAL, V41, P352, DOI 10.1109/TPAMI.2017.2783936
   Zhang B., 2020, SIGNAL PROCESS, P174
   Zhang XJ, 2017, SIAM J IMAGING SCI, V10, P1627, DOI 10.1137/16M1076034
   Zhang XM, 2009, IEEE SIGNAL PROC LET, V16, P295, DOI 10.1109/LSP.2009.2014293
   Zhou Z, 2012, IEEE T IMAGE PROCESS, V21, P3157, DOI 10.1109/TIP.2012.2189577
NR 47
TC 3
Z9 3
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10529
EP 10544
DI 10.1007/s11042-022-12255-x
EA FEB 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000756332700015
DA 2024-07-18
ER

PT J
AU Rezki, AM
   Serir, A
   Beghdadi, A
AF Rezki, Amine Mohamed
   Serir, Amina
   Beghdadi, Azeddine
TI Blind image inpainting quality assessment using local features
   continuity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Inpainting; Image quality assessment; Inpainting evaluation; Image
   modification
AB This paper deals with Blind Inpainted Image Quality Assessment BIIQA. Herein, we propose a new method that exploits the continuity of features around the boundaries of the retouched area. Indeed, we believe that the quality of inpainted images depends on how the edges and textures have been reproduced inside the hole. Besides, this concept has been formalized by the fact that features should be reproduced inside and outside the hole with respect to structures continuity. Furthermore, one could compare these features in terms of continuity and estimate the global quality of the inpainted image. And since the local structures are represented by patches, we proposed as a secondary contribution, an improvement of a patch classification algorithm. The strength of this metric unlike most existing IIQA metrics, is that it is completely blind and does not require any reference, making it well suited to the inpainting assessment, where reference is usually unavailable. The proposed BIIQA has been tested on TUM-IID database, where the results of four commonly used inpainting algorithms are provided and compared against IIQA state-of-the-art. The obtained results show clearly that our method outperforms the existing ones.
C1 [Rezki, Amine Mohamed; Serir, Amina] Univ Sci & Technol Houari Boumediene USTHB, Fac Elect & Comp Sci, Lab Image Proc & Radiat LTIR, Algiers, Algeria.
   [Beghdadi, Azeddine] Univ Sorbonne Paris Nord, Inst Galilee, Lab Informat Proc & Transmiss L2TI, F-93430 Villetaneuse, France.
C3 University Science & Technology Houari Boumediene
RP Rezki, AM (corresponding author), Univ Sci & Technol Houari Boumediene USTHB, Fac Elect & Comp Sci, Lab Image Proc & Radiat LTIR, Algiers, Algeria.
EM mrezki@usthb.dz
RI REZKI, Mohamed Amine/ABN-0041-2022; Beghdadi, Azeddine/ABF-9801-2022;
   SERIR, Amina/AIE-7078-2022
OI REZKI, Mohamed Amine/0000-0001-7269-1873; Beghdadi,
   Azeddine/0000-0002-5595-0615; SERIR, Amina/0000-0001-7716-1273
CR Ardis Paul A., 2009, Proceedings of the SPIE - The International Society for Optical Engineering, V7257, DOI 10.1117/12.808942
   Bugeau A, 2010, IEEE T IMAGE PROCESS, V19, P2634, DOI 10.1109/TIP.2010.2049240
   Getreuer P, 2012, IMAGE PROCESS ON LIN, V2, P147, DOI 10.5201/ipol.2012.g-tvi
   Gong H., 1994, SCENE ANAL DCT IMAGE, P425, DOI [10.1016/B978-0-444-81844-7.50052-8, DOI 10.1016/B978-0-444-81844-7.50052-8]
   Guillemot C, 2014, IEEE SIGNAL PROC MAG, V31, P127, DOI 10.1109/MSP.2013.2273004
   Herling J, 2012, INT SYM MIX AUGMENT, P141, DOI 10.1109/ISMAR.2012.6402551
   Hu WJ, 2019, J VIS COMMUN IMAGE R, V59, P292, DOI 10.1016/j.jvcir.2018.12.045
   Isogawa M, 2019, MULTIMED TOOLS APPL, V78, P1399, DOI 10.1007/s11042-018-6186-z
   Isogawa M, 2016, IEEE IMAGE PROC, P3538, DOI 10.1109/ICIP.2016.7533018
   Oncu AI, 2012, LECT NOTES COMPUT SC, V7583, P561, DOI 10.1007/978-3-642-33863-2_58
   Qureshi MA, 2017, J VIS COMMUN IMAGE R, V49, P177, DOI 10.1016/j.jvcir.2017.09.006
   Dang TT, 2013, 2013 COLOUR AND VISUAL COMPUTING SYMPOSIUM (CVCS)
   Tiefenbacher P, 2015, SUBJECTIVE OBJECTIVE
   Venkatesh MV, 2010, IEEE IMAGE PROC, P1109, DOI 10.1109/ICIP.2010.5653640
   Viacheslav V, 2014, INT CONF SIGN PROCES, P643, DOI 10.1109/ICOSP.2014.7015082
   Voronin VV, 2015, PROC SPIE, V9399, DOI 10.1117/12.2076507
   Wang S, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P786, DOI 10.1109/ICYCS.2008.461
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
NR 18
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9225
EP 9244
DI 10.1007/s11042-021-11872-2
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000755422300006
DA 2024-07-18
ER

PT J
AU Aranguren, I
   Valdivia, A
   Pérez-Cisneros, M
   Oliva, D
   Osuna-Enciso, V
AF Aranguren, Itzel
   Valdivia, Arturo
   Perez-Cisneros, Marco
   Oliva, Diego
   Osuna-Enciso, Valentin
TI Digital image thresholding by using a lateral inhibition 2D histogram
   and a Mutated Electromagnetic Field Optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electromagnetic Field Optimization; High Disruptive Polynomial Mutation;
   Image segmentation; Lateral inhibition; Renyi entropy; Two-dimensional
   histogram
ID SEMANTIC SEGMENTATION; ENTROPY; ALGORITHM
AB In this article is introduced an innovative segmentation methodology that is based on a two-dimensional (2D) histogram that permits to increase the quality of the segmented images. The 2D histogram is constructed using the Lateral Inhibition (LI) that helps maintain and remark different image features. To segment the image in the proposed approach, the 2D Renyi entropy is used, which is a multi-level thresholding technique. Since the complexity of the 2D Renyi entropy increases with the number of thresholds, it is necessary to use an efficient search mechanism. To perform this task, it is also proposed an improved version of the Electromagnetic Field Optimization (EFO) algorithm that employs the High Disruptive Polynomial Mutation (HDPM) to exploit the search space intensively. The proposed metaheuristic is called MEFO. In combination with the 2D Renyi entropy creates a robust mechanism able to find the optimal configuration of thresholds that permits an accurate classification of the information contained in the 2D histogram generated using the (LI). The performance of the MEFO is tested over the Berkeley Segmentation Dataset (BSDS100) that contains 100 images with different complexities. The experiments include quantitative, qualitative, and statistical tests that permit the MEFO's efficiency in both senses for image segmentation and for solving multidimensional real optimization problems. Moreover, different comparisons validate the capabilities of the proposed algorithms to segment the images properly.
C1 [Aranguren, Itzel; Valdivia, Arturo; Perez-Cisneros, Marco; Oliva, Diego; Osuna-Enciso, Valentin] Univ Guadalajara, Div Tecnol Integrac Ciber Humana, CUCEI, Av Revoluc 1500, Guadalajara 44430, Jalisco, Mexico.
C3 Universidad de Guadalajara
RP Pérez-Cisneros, M; Oliva, D (corresponding author), Univ Guadalajara, Div Tecnol Integrac Ciber Humana, CUCEI, Av Revoluc 1500, Guadalajara 44430, Jalisco, Mexico.
EM itzel.aranguren@academicos.udg.mx; arturo.valdivia@academicos.udg.mx;
   marco.perez@cucei.udg.mx; diego.oliva@cucei.udg.mx;
   valentin.osuna@cucei.udg.mx
RI Osuna-Enciso, Valentin/CAH-3472-2022; Valdivia G, Arturo/AFB-6578-2022;
   Oliva, Diego/A-3271-2016; Aranguren Navarro, Itzel
   Niasandiu/AAE-9127-2022; Osuna-Enciso, Valentín/AAD-7533-2019
OI Osuna-Enciso, Valentin/0000-0001-6844-9013; Valdivia G,
   Arturo/0000-0001-8472-1523; Oliva, Diego/0000-0001-8781-7993; Aranguren
   Navarro, Itzel Niasandiu/0000-0001-6573-2825; Osuna-Enciso,
   Valentín/0000-0001-6844-9013
CR Abed-alguni B, 2020, J INTELL SYST, V29, P1043, DOI 10.1515/jisys-2018-0331
   Abedinpourshotorban H, 2016, SWARM EVOL COMPUT, V26, P8, DOI 10.1016/j.swevo.2015.07.002
   ABUTALEB AS, 1989, COMPUT VISION GRAPH, V47, P22, DOI 10.1016/0734-189X(89)90051-0
   Aja-Fernández S, 2006, 2006 28TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOLS 1-15, P4053
   Anita, 2019, SWARM EVOL COMPUT, V48, P93, DOI 10.1016/j.swevo.2019.03.013
   Anitha J, 2021, EXPERT SYST APPL, V178, DOI 10.1016/j.eswa.2021.115003
   Askarzadeh A, 2016, COMPUT STRUCT, V169, P1, DOI 10.1016/j.compstruc.2016.03.001
   Avcibas I, 2002, J ELECTRON IMAGING, V11, P206, DOI 10.1117/1.1455011
   Bouchekara HREH, 2017, APPL SOFT COMPUT, V54, P267, DOI 10.1016/j.asoc.2017.01.037
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Cheng HD, 2000, IEEE T IMAGE PROCESS, V9, P732, DOI 10.1109/83.841949
   Cuevas A., 2021, Recent metaheuristicComput. Schemes Eng., P151
   Dai SS, 2015, INFRARED PHYS TECHN, V68, P10, DOI 10.1016/j.infrared.2014.09.042
   David G., 1989, GENETIC ALGORITHMS S
   de Albuquerque MP, 2004, PATTERN RECOGN LETT, V25, P1059, DOI 10.1016/j.patrec.2004.03.003
   De UC, 2021, MATER TODAY-PROC, DOI 10.1016/j.matpr.2021.02.195
   Deb K, 2008, EUR J OPER RES, V185, P1062, DOI 10.1016/j.ejor.2006.06.042
   Geem ZW, 2001, SIMULATION, V76, P60, DOI 10.1177/003754970107600201
   HARTLINE HK, 1956, J GEN PHYSIOL, V39, P651, DOI 10.1085/jgp.39.5.651
   He LF, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106063
   Jiang D, 2021, FUTURE GENER COMP SY, V123, P94, DOI 10.1016/j.future.2021.04.019
   Kalyani R, 2021, MULTIMED TOOLS APPL, V80, P27553, DOI 10.1007/s11042-021-10909-w
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kotaridis I, 2021, ISPRS J PHOTOGRAMM, V173, P309, DOI 10.1016/j.isprsjprs.2021.01.020
   Kucukoglu I, 2019, INT J PHOTOENERGY, V2019, DOI 10.1155/2019/4692108
   Lan JH, 2013, OPTIK, V124, P3756, DOI 10.1016/j.ijleo.2012.11.023
   Lei B, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105687
   LI CH, 1993, PATTERN RECOGN, V26, P617, DOI 10.1016/0031-3203(93)90115-D
   Li X-F., 2017, DESTECH T COMPUT SCI, DOI 10.12783/dtcse/aice-ncs2016/5692
   Livio M., 2003, The Golden Ratio: The Story of Phi, the World's Most Astonishing Number
   Marini F, 2015, CHEMOMETR INTELL LAB, V149, P153, DOI 10.1016/j.chemolab.2015.08.020
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Matajira-Rueda D, 2018, UIS ING, V17, P233, DOI 10.18273/revuin.v17n1-2018023
   Yan M, 2020, NEUROCOMPUTING, V386, P293, DOI 10.1016/j.neucom.2019.12.007
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mittal H, 2018, ENG APPL ARTIF INTEL, V71, P226, DOI 10.1016/j.engappai.2018.03.001
   Price Kenneth, 2006, NAT COMP SER, DOI 10.1007/3-540-31306-0
   Ray S, 2021, NEURAL COMPUT APPL, V33, P5917, DOI 10.1007/s00521-020-05368-7
   Reisenhofer R, 2018, SIGNAL PROCESS-IMAGE, V61, P33, DOI 10.1016/j.image.2017.11.001
   Sahoo PK, 2004, PATTERN RECOGN, V37, P1149, DOI 10.1016/j.patcog.2003.10.008
   Sarkar S, 2016, EXPERT SYST APPL, V50, P120, DOI 10.1016/j.eswa.2015.11.016
   Sathya PD., 2013, LECT NOTES ELECT ENG, P53
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Talebi B, 2018, EXPERT SYST APPL, V114, P155, DOI 10.1016/j.eswa.2018.07.031
   Jamal AT, 2023, MULTIMED TOOLS APPL, V82, P13167, DOI 10.1007/s11042-020-10235-7
   Upadhyay P, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2019.105522
   Vig Garima, 2021, Advances in Computational Intelligence and Communication Technology. Proceedings of CICT 2019. Advances in Intelligent Systems and Computing (AISC 1086), P563, DOI 10.1007/978-981-15-1275-9_46
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Wu J, 2016, ICSPCC 2016
   Xue-guang W., 2012, INF SCI LETT, V1, P77, DOI [10.12785/isl/010202, DOI 10.12785/ISL/010202]
   Yurtkuran A, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/6759106
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhao SW, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104427
   Zyczkowski K, 2003, OPEN SYST INF DYN, V10, P297, DOI 10.1023/A:1025128024427
NR 58
TC 6
Z9 6
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 10023
EP 10049
DI 10.1007/s11042-022-11959-4
EA FEB 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756497800027
DA 2024-07-18
ER

PT J
AU Chen, B
   Zhu, JN
   Dong, YZ
AF Chen, Bin
   Zhu, Jin-ning
   Dong, Yi-zhou
TI Expression recognition based on residual rectification convolution
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Controlled scene; Convolutional neural network; Residual rectification;
   Data enhancement; Excitation function; Expression recognition
AB In order to solve the problem of low face recognition rate in controlled scene, an expression recognition algorithm based on residual rectification intensive convolutional neural network is proposed. This method takes convolutional neural network as the prototype. In the process of training model, the idea of residual network is introduced to correct the difference between the effect of test set and the effect of training set. The linear rectification operation of the residual block by the excitation function embedded in the convolution layer helps to express complex features. At the same time, the data intensive method is used to suppress the fast fitting of the deep neural network model during the training process, to improve its generalization performance on a given recognition task, and then to improve the robustness of the model learning effect. In the experiment, the method is applied to simulate the online teaching environment, and get effective facial expression recognition result in controlled scene. According to the experimental data, this method can effectively classify the facial image input under controlled conditions, and the highest accuracy is up to 91.7%. This research is helpful to the development of facial expression recognition and human-computer interaction.
C1 [Chen, Bin; Zhu, Jin-ning; Dong, Yi-zhou] Nanjing Normal Univ, Informatizat Off, Nanjing 210023, Peoples R China.
C3 Nanjing Normal University
RP Chen, B (corresponding author), Nanjing Normal Univ, Informatizat Off, Nanjing 210023, Peoples R China.
EM 60167@njnu.edu.cn
RI Dong, Yizhou/O-9057-2015; chen, bin/H-5989-2012
FU Research on Intelligent Campus of Modern Educational Technology in
   Jiangsu Province [2021-R-96609]
FX Supported by Research on Intelligent Campus of Modern Educational
   Technology in Jiangsu Province (2021-R-96609).
CR [Anonymous], 1976, Pictures of facial affect
   Barnouti NH, 2016, INT J ADV COMPUT SC, V7, P371
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goyal SJ, 2018, SMART INNOV SYST TEC, V77, P311, DOI 10.1007/978-981-10-5544-7_31
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Gu WF, 2012, PATTERN RECOGN, V45, P80, DOI 10.1016/j.patcog.2011.05.006
   Gurovich Y, 2019, NAT MED, V25, P60, DOI 10.1038/s41591-018-0279-0
   Hongfei L., 2019, ACTA ELECT SIN, V47, P1643
   Jia Ming-xing, 2017, Journal of Northeastern University. Natural Science, V38, P310, DOI 10.3969/j.issn.1005-3026.2017.03.002
   Juan L., 2016, J ELEC MEASUR INSTRU, V30, P714
   Kaya H, 2017, IMAGE VISION COMPUT, V65, P66, DOI 10.1016/j.imavis.2017.01.012
   Lekdioui K, 2017, SIGNAL PROCESS-IMAGE, V58, P300, DOI 10.1016/j.image.2017.08.001
   [李勇 Li Yong], 2018, [自动化学报, Acta Automatica Sinica], V44, P176
   Liu YP, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040712
   Lucey P., 2010, ieee computer society conference on computer vision and pattern recognition-workshops, P94
   Mao QR, 2018, COMPUT J, V61, P1605, DOI 10.1093/comjnl/bxy016
   Qianlu H., 2019, COMPUTER ENG DESIGN, V31, P552
   Soyel H, 2012, COMPUT ELECTR ENG, V38, P1299, DOI 10.1016/j.compeleceng.2011.10.016
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   [孙晓 Sun Xiao], 2017, [电子学报, Acta Electronica Sinica], V45, P1189
   Tan XH, 2019, J ELECTRON INF TECHN, V41, P2752, DOI 10.11999/JEIT181088
   Wang XY, 2019, LASER OPTOELECTRON P, V56, DOI 10.3788/LOP56.131004
   [夏添 Xia Tian], 2019, [计算机辅助设计与图形学学报, Journal of Computer-Aided Design & Computer Graphics], V31, P552
   Xu Y., 2020, LASER OPTOELECTRON P, V57, DOI 10.3788/LOP57.141026
   Yao LS, 2020, LASER OPTOELECTRON P, V57, DOI 10.3788/LOP57.041513
   Yu, 2019, J ELECT MEAS INSTRUM, V33, P169
   Zhang FF., 2019, CHIN J COMP, V42, P1
   Zheng WM, 2006, IEEE T NEURAL NETWOR, V17, P233, DOI 10.1109/TNN.2005.860849
   Zhou HL, 2016, PATTERN RECOGN, V56, P88, DOI 10.1016/j.patcog.2016.03.002
NR 30
TC 0
Z9 0
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9671
EP 9683
DI 10.1007/s11042-022-12159-w
EA FEB 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000754371300002
DA 2024-07-18
ER

PT J
AU Lalitha, VP
   Rangaswamy, S
AF Lalitha, V. P.
   Rangaswamy, Shanta
TI Automatic object detection in aerial image using bent
   identity-convolutional neural network and fine tuning algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote sensing; Aerial image; Bent identity; Convolutional neural
   network; Fine tuning algorithm
ID CLASSIFICATION
AB In RS (Remote Sensing) imaging, one of the most important tasks is Object Detection (OD) which aims to extract the object location and class information. Object detection is termed the highly advanced approach, which is helpful in RS image analysis, scene and image content understanding. In recent years, the researchers have made extensive efforts to present an effective OD model with the limitation of detecting specific classes such as roads and buildings in the RS images. For capturing aerial images, satellite sensors are utilized, and these images are affected by various factors like background noise, variation of viewpoint and interferences etc. To provide accurate detection of objects, an effective method is needed in analysing aerial images. However, this work presents an automatic OD using BI-CNN_FTA (Bent Identity-Convolutional Neural Network Fine-Tuning Algorithm) to detect more object classes relating to urbanization applications. The overall framework of proposed method is divided into five phases-Pre-processing, Object Localization, Segmentation, Feature Extraction and Classification. The input image is pre-processed by Advanced Dual Domain (ADD) filtering. Next, the objects are localized with the help of Grid Guided Localization (GGL) which draw an imaginary box around each object in an image. The segmentation process is done with the help of an improved tree Markov (ITM) random field model. Further, various features like texture, geometric, color descriptors and Zernike moments are extracted. Finally, the object classification is performed by BI-CNN_FTA. During this stage, each object class are categorized based on urbanization applications and learning loss is optimized. The proposed method is executed in the PHYTON platform. It has obtained improved performance in terms of Mean Average Precision (mAP = 85.5%), F1-score (83.78%), Detection rate (97%) and Precision-Recall curve when compared with other deep learning networks on the DOTA dataset.
C1 [Lalitha, V. P.; Rangaswamy, Shanta] RV Coll Engn, Dept Comp Sci & Engn, Bengaluru, India.
C3 R.V. College of Engineering
RP Lalitha, VP (corresponding author), RV Coll Engn, Dept Comp Sci & Engn, Bengaluru, India.
EM lalithasravyasl@gmail.com
RI Rangaswamy, Shanta/O-7009-2016
OI Rangaswamy, Shanta/0000-0002-7559-1912
CR Alganci U, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030458
   Avtar R, 2020, REMOTE SENS APPL, V20, DOI 10.1016/j.rsase.2020.100402
   Ayush K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10161, DOI 10.1109/ICCV48922.2021.01002
   Azimi SM, 2019, LECT NOTES COMPUT SC, V11363, P150, DOI 10.1007/978-3-030-20893-6_10
   Bosquet B, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107929
   Campbell J. B., 2011, INTRO REMOTE SENSING
   Chen CY, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030339
   Chen RX, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030451
   Chen SQ, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10060820
   Fan QF, 2020, J APPL SCI ENG, V23, P547, DOI 10.6180/jase.202009_23(3).0019
   Grinias I, 2016, ISPRS J PHOTOGRAMM, V122, P145, DOI 10.1016/j.isprsjprs.2016.10.010
   Guo W, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010131
   Khoshelham K, 2010, ISPRS J PHOTOGRAMM, V65, P123, DOI 10.1016/j.isprsjprs.2009.09.005
   Li CL, 2020, IEEE COMPUT SOC CONF, P737, DOI 10.1109/CVPRW50498.2020.00103
   Li K, 2018, IEEE T GEOSCI REMOTE, V56, P2337, DOI 10.1109/TGRS.2017.2778300
   Li XH, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12010081
   Li YS, 2018, ISPRS J PHOTOGRAMM, V146, P182, DOI 10.1016/j.isprsjprs.2018.09.014
   Long Y, 2017, IEEE T GEOSCI REMOTE, V55, P2486, DOI 10.1109/TGRS.2016.2645610
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Mandal Murari, 2019, 2019 IEEE International Conference on Image Processing (ICIP). Proceedings, P3098, DOI 10.1109/ICIP.2019.8803262
   Mo N, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12162558
   Pi YL, 2020, ADV ENG INFORM, V43, DOI 10.1016/j.aei.2019.101009
   Rasti B, 2020, INFORM FUSION, V64, P121, DOI 10.1016/j.inffus.2020.07.002
   Samanta S, 2018, APPL WATER SCI, V8, DOI 10.1007/s13201-018-0710-1
   Sevo I, 2016, IEEE GEOSCI REMOTE S, V13, P740, DOI 10.1109/LGRS.2016.2542358
   Song YN, 2020, ROBOT CIM-INT MANUF, V65, DOI 10.1016/j.rcim.2020.101963
   Twumasi NYD, 2019, REMOTE SENSING GIS M
   Wellmann T, 2020, LANDSCAPE URBAN PLAN, V204, DOI 10.1016/j.landurbplan.2020.103921
   Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418
   Yan SY, 2020, FRONT EARTH SCI-PRC, V14, P1, DOI 10.1007/s11707-019-0757-9
   Yang F, 2019, IEEE I CONF COMP VIS, P8310, DOI 10.1109/ICCV.2019.00840
   Yi YN, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11151774
   Zhang CX, 2020, INT J APPL EARTH OBS, V88, DOI 10.1016/j.jag.2020.102086
   Zhang X, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030417
   Zhong YF, 2018, APPL SOFT COMPUT, V64, P75, DOI 10.1016/j.asoc.2017.11.045
   Zhou LM, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P468, DOI [10.1109/itnec48623.2020.9084975, 10.1109/ITNEC48623.2020.9084975]
NR 36
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9713
EP 9740
DI 10.1007/s11042-022-11948-7
EA FEB 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000754371300001
DA 2024-07-18
ER

PT J
AU Rong, WZ
   Han, J
   Liu, G
AF Rong, Wenzhong
   Han, Jin
   Liu, Gen
TI Instance-level Object relation module for one-stage Object Detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Contextual information; Feature fusion; Visual
   attention
ID CONTEXT
AB Leveraging the contextual information at instance-level can improve the accuracy in object detection. However, the-state-of-the-art object detection systems still detect each target individually without using contextual information. One reason is that contextual information is difficult to model. To solve this problem, the object relation module based on one-stage object detectors helps the object detectors learn the correlations between objects. It extracts and fuses the feature maps from various layers, including geometric features, categorical features, and appearance features, a transformation driven by visual attention mechanism are then performed to generate instance-level primary object relation features. Furthermore, a lightweight subnet is used to generate new feature prediction layer based on primary relation features and fused with the original detection layer to improve the detection ability. It does not require excessive amounts of computations and additional supervision and it can be easily ported to different one-stage object detection frameworks. The relation module is added to several one-stage object detectors (YOLO, Retinanet, and FCOS) as demonstrations and evaluate it on MS-COCO benchmark dataset after training. The results show that the relation module effectively improves the accuracy in one-stage object detection pipelines. Specifically, the relation module gives a 2.4 AP improvement for YOLOv3, 1.8 AP improvement for Retinanet and 1.6 AP improvement for FCOS.
C1 [Rong, Wenzhong; Han, Jin; Liu, Gen] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology
RP Han, J (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
EM shnk123@163.com
OI Han, Jin/0000-0002-9330-5019
CR Ba J, 2014, COMPUTERENCE
   Bochkovskiy A., 2020, PREPRINT
   Chen X., 2017, SPATIAL MEMORY CONTE, DOI [10.1109/ICCV.2017.440, DOI 10.1109/ICCV.2017.440]
   Divvala SK, 2009, PROC CVPR IEEE, P1271, DOI 10.1109/CVPRW.2009.5206532
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Galleguillos C, 2008, PROC CVPR IEEE, P3552
   Gao ZF, 2020, IEEE NETWORK, V34, P216, DOI 10.1109/MNET.001.1900260
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lee SJ, 2020, IEEE T CIRC SYST VID, V30, P4434, DOI 10.1109/TCSVT.2020.2981652
   Li JN, 2017, IEEE T MULTIMEDIA, V19, P944, DOI 10.1109/TMM.2016.2642789
   LI Y, 2017, PROC CVPR IEEE, P4438, DOI [DOI 10.1109/CVPR.2017.472, DOI 10.1109/CVPR.2017.199]
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Oliva A, 2003, IEEE IMAGE PROC, P253, DOI 10.1109/icip.2003.1246946
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shrivastava A., 2016, Beyond skip connections: Top-down modulation for object detection
   Stewart R, 2016, COMPUTER VISION PATT
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Torralba A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P273
   Tu ZW, 2008, PROC CVPR IEEE, P735
   Vaswani A, 2017, ADV NEUR IN, V30
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhou X, 2019, PSYCHOL HEALTH, V34, P811, DOI 10.1080/08870446.2019.1574348
   Zhu CC, 2019, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2019.00093
NR 45
TC 0
Z9 0
U1 4
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8617
EP 8632
DI 10.1007/s11042-022-12264-w
EA FEB 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000751246700010
DA 2024-07-18
ER

PT J
AU Soleymanifard, M
   Hamghalam, M
AF Soleymanifard, Mostafa
   Hamghalam, Mohammad
TI Multi-stage glioma segmentation for tumour grade classification based on
   multiscale fuzzy C-means
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Segmentation; Brain tumour; MRI; Neural network; Active contour; LPB
ID ATTENTION-GAN; BRAIN
AB Segmentation of the brain glioma tumour sub-regions is critical to diagnosis and prognosis in clinical applications. This paper proposes a three-stage model to segment automatically brain tumours and their internal tissue in multi-modal brain MRI images. In the first stage, we find the whole tumour (WT) tissue and initially segment it through our neural network model in the FALIR MR sequence. The initial segmentation is fed to the active contour model to segment the precise boundary of WT in the second stage. The combination of the active contour model and the neural network increases the WT segmentation performance significantly. The segmentation of critical internal parts of the tumour, i.e., enhancing tumours (ET), is performed with a fuzzy clustering-based approach in the last stage. Specifically, we apply a multiscale fuzzy C-means (MsFCM) classification method with 12 scales to detect ET in the cropped image of the preceding stage. After segmenting the WT, ET, and normal tissue, we classify input tumours to low-grade glioma (LGG) and high-grade glioma (HGG). For this aim, a local binary pattern algorithm (LBP) and gray-level co-occurrence matrix (GLCM) matrix are used to extract features from the segmented tissues. After creating the feature vectors, we employ the neural network classifier to determine the grade of input tumours in the MR image. The main contributions of the proposed method are: 1) our fuzzy model improved the segmentation accuracy through the designed multiple scales and classes, 2) using tumour edges instead of the entire image as well as utilizing the proposed training algorithm significantly increased the speed of learning and the segmentation accuracy. The experimental results in terms of DICE score indicate that the proposed model is highly competitive compared to state-of-the-art segmentation methods.
C1 [Soleymanifard, Mostafa; Hamghalam, Mohammad] Islamic Azad Univ, Fac Elect Biomed & Mechatron Engn, Qazvin Branch, Qazvin, Iran.
   [Hamghalam, Mohammad] Queens Univ, Sch Comp, Kingston, ON, Canada.
C3 Islamic Azad University; Queens University - Canada
RP Hamghalam, M (corresponding author), Islamic Azad Univ, Fac Elect Biomed & Mechatron Engn, Qazvin Branch, Qazvin, Iran.; Hamghalam, M (corresponding author), Queens Univ, Sch Comp, Kingston, ON, Canada.
EM mostafa.sol.f@gmail.com; m.hamghalam@queensu.ca
RI Hamghalam, Mohammad/X-7134-2019; Soleymanifard, Mostafa/AAE-1037-2022
OI Hamghalam, Mohammad/0000-0003-2543-0712; Soleymanifard,
   Mostafa/0000-0002-6366-8441
FU National Institutes of Health [R01CA233888]
FX This work was funded in part by National Institutes of Health
   R01CA233888.
CR Avital I, 2020, IEEE T MED IMAGING, V39, P1655, DOI 10.1109/TMI.2019.2954477
   Chen K, 2021, ARXIV PREPRINT ARXIV, P1, DOI DOI 10.1061/(ASCE)EY.1943-7897.0000804
   Cho HH, 2017, IEEE ENG MED BIO, P3081, DOI 10.1109/EMBC.2017.8037508
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Ghahremani M, 2021, MULTIMED TOOLS APPL, V80, P28245, DOI 10.1007/s11042-021-10895-z
   Hamghalam M, 2021, LECT NOTES COMPUT SC, V12907, P442, DOI 10.1007/978-3-030-87234-2_42
   Hamghalam M, 2020, AAAI CONF ARTIF INTE, V34, P4067
   Hamghalam M, 2020, NEURAL NETWORKS, V132, P43, DOI 10.1016/j.neunet.2020.08.014
   Hamghalam M, 2020, I S BIOMED IMAGING, P1499, DOI [10.1109/ISBI45749.2020.9098347, 10.1109/isbi45749.2020.9098347]
   Hamghalam M, 2020, LECT NOTES COMPUT SC, V11992, P3, DOI 10.1007/978-3-030-46640-4_1
   Hamghalam M, 2015, MULTIMED TOOLS APPL, V74, P3077, DOI 10.1007/s11042-013-1769-1
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Huang MY, 2014, IEEE T BIO-MED ENG, V61, P2633, DOI 10.1109/TBME.2014.2325410
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Ker J, 2019, J CLIN NEUROSCI, V66, P239, DOI 10.1016/j.jocn.2019.05.019
   Khosravanian A, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105809
   Lei XL, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114262
   Lin WW, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-94071-1
   Lv HL, 2017, IEEE ACCESS, V5, P7753, DOI 10.1109/ACCESS.2017.2697975
   Ma C, 2018, IEEE T MED IMAGING, V37, P1943, DOI 10.1109/TMI.2018.2805821
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Mzoughi H, 2020, J DIGIT IMAGING, V33, P903, DOI 10.1007/s10278-020-00347-9
   OZKAN M, 1993, IEEE T MED IMAGING, V12, P534, DOI 10.1109/42.241881
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9060690
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9070751
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Polly FP, 2018, 2018 32ND INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P813, DOI 10.1109/ICOIN.2018.8343231
   Soleimany S, 2017, 2017 ARTIFICIAL INTELLIGENCE AND ROBOTICS (IRANOPEN), P165, DOI 10.1109/RIOS.2017.7956461
   Soleymanifard M, 2019, 2019 IEEE 5TH CONFERENCE ON KNOWLEDGE BASED ENGINEERING AND INNOVATION (KBEI 2019), P739, DOI [10.1109/kbei.2019.8735050, 10.1109/KBEI.2019.8735050]
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Tamang J., 2021, DYNAMICAL PROPERTIES
   Wang XF, 2015, PATTERN RECOGN, V48, P189, DOI 10.1016/j.patcog.2014.07.008
   Zhang DW, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107562
   Zhang KH, 2016, IEEE T CYBERNETICS, V46, P546, DOI 10.1109/TCYB.2015.2409119
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
NR 35
TC 13
Z9 13
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8451
EP 8470
DI 10.1007/s11042-022-12326-z
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749966800012
DA 2024-07-18
ER

PT J
AU Zhang, CY
   Liang, JZ
   Li, X
   Xia, YF
   Di, L
   Hou, ZJ
   Huan, Z
AF Zhang, Chengyu
   Liang, Jiuzhen
   Li, Xing
   Xia, Yunfei
   Di, Lan
   Hou, Zhenjie
   Huan, Zhan
TI Human action recognition based on enhanced data guidance and key node
   spatial temporal graph convolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Key node; Graph convolutional networks; Enhanced
   data
AB Graph convolutional networks have achieved remarkable performance in action recognition from skeleton videos. However, most of the existing GCN-based methods improve performance by increasing model parameters, which require a high amount of data. This means that they usually perform poorly on small sample learning tasks. In this paper, we propose a novel enhanced data guidance algorithm to improve the performance of the GCN-based method on small sample datasets. These enhanced data perform coordinate transformation on the skeleton to obtain robustness to scale, rotation and translation. The proposed guidance algorithm allows the target model to learn the advantages of enhanced data and reduce the complexity of the task. We also propose a new key node method, which can select key joints and frames in the spatial and temporal dimensions respectively. This removes the redundant information of the skeleton sequence and significantly reduces the computational cost. Furthermore, the combination of key nodes and enhanced data can greatly reduce the demand for training data. The recognition accuracy rates of 94.81% and 94.19% have been achieved on the public MSR Action3D and UTD-MHAD datasets, respectively. This result proves that our method is significantly better than mainstream 3D action recognition methods.
C1 [Zhang, Chengyu; Liang, Jiuzhen; Hou, Zhenjie; Huan, Zhan] Changzhou Univ, Sch Comp Sci & Artificial Intelligence, Changzhou 213164, Peoples R China.
   [Li, Xing] Hohai Univ, Dept Comp Sci & Technol, Nanjing 210000, Jiangsu, Peoples R China.
   [Xia, Yunfei] Univ North Carolina Charlotte, Dept Math & Stat, Charlotten, NC 28213 USA.
   [Di, Lan] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Jiangsu, Peoples R China.
C3 Changzhou University; Hohai University; University of North Carolina;
   University of North Carolina Charlotte; Jiangnan University
RP Liang, JZ (corresponding author), Changzhou Univ, Sch Comp Sci & Artificial Intelligence, Changzhou 213164, Peoples R China.
EM jzliang@cczu.edu.cn
RI Xia, Yunfei/KIC-0347-2024; li, xing/GYA-4502-2022; Liang,
   Jiuzhen/HJG-9384-2022; Hou, Zhenjie/HKW-7644-2023
OI Lan, Di/0000-0001-8570-4450
CR Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Berthelot D, 2019, ADV NEUR IN, V32
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen C, 2015, IEEE T HUM-MACH SYST, V45, P51, DOI 10.1109/THMS.2014.2362520
   Cui R, 2019, IEEE ACCESS, V7, P8245, DOI 10.1109/ACCESS.2018.2889797
   Defferrard M., 2017, Convolutional neural networks on graphs with fast localized spectral filtering
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Gupta S, 2019, MULTIMED TOOLS APPL, V78, P34157, DOI 10.1007/s11042-019-08232-6
   Hussein M, 2013, HUMAN ACTION RECOGNI, P8
   Joan B., 2014, SPECTRAL NETWORKS LO
   Kipf TN, 2017, INT C LEARN REPR
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Lee D.-H., 2013, WORKSHOP CHALLENGES, V3, P896
   Lee H, 2020, SELF SUPERVISED LABE
   Lee I, 2017, IEEE I CONF COMP VIS, P1012, DOI 10.1109/ICCV.2017.115
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Li YT, 2019, IEEE INTERNET THINGS, V6, P628, DOI 10.1109/JIOT.2018.2851185
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Niepert M, 2016, PR MACH LEARN RES, V48
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Shuman DI, 2013, IEEE SIGNAL PROC MAG, V30, P83, DOI 10.1109/MSP.2012.2235192
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Simonyan K, 2014, ADV NEUR IN, V27
   Sohn Kihyuk, 2020, Advances in Neural Information Processing Systems, P596, DOI DOI 10.48550/ARXIV.2001.07685
   Thakkar K. C., 2018, PRAC BRIZ MACH VIS C, P270
   Tian D, 2020, MULTIMED TOOLS APPL, V79, P12679, DOI 10.1007/s11042-020-08611-4
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang L, 2020, IEEE T IMAGE PROCESS, V29, P15, DOI 10.1109/TIP.2019.2925285
   Wang PC, 2018, KNOWL-BASED SYST, V158, P43, DOI 10.1016/j.knosys.2018.05.029
   Wang XF, 2020, MULTIMED TOOLS APPL, V79, P7413, DOI 10.1007/s11042-019-08535-8
   Wei P, 2019, IEEE T MULTIMEDIA, V21, P2195, DOI 10.1109/TMM.2019.2897902
   Xie Q., 2020, Unsupervised data augmentation for consistency training, P6256
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yonghong Hou, 2018, IEEE Transactions on Circuits and Systems for Video Technology, V28, P807, DOI 10.1109/TCSVT.2016.2628339
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhou Y, 2014, IEEE INT CONGR BIG, P1, DOI 10.1109/BigData.Congress.2014.11
NR 37
TC 7
Z9 7
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8349
EP 8366
DI 10.1007/s11042-022-11947-8
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749966800020
DA 2024-07-18
ER

PT J
AU Madhumathy, P
   Pandey, D
AF Madhumathy, P.
   Pandey, Digvijay
TI Deep learning based photo acoustic imaging for non-invasive imaging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial intelligence; Machine learning; Deep learning; Medical
   imaging
ID ARTIFACTS
AB Biomedical image processing is a technique for graphically representing inside human organs and tissues in addition to assessing them clinically. Artificial Intelligence (AI) approaches are used as they are capable of extracting complex data from picture data and providing a quantitative evaluation of radiographic features. The objectives of this paper would be to use deep learning techniques to generate noise artefacts in a photo acoustic image dataset, train a convolution neural network to identify and classify artefacts in photo acoustic data, and deploy an effective artefact elimination strategy to collected data. Present technology can be used to achieve the desired outcome using state-of-the-art image and data processing technologies as elements of AI and ML approaches. These technologies have given rise to a range of instruments that aid in better knowledge of the human body and the development of new diagnostic and therapeutic procedures, such as remote patient monitoring and treatment outcomes analysis, in terms of improving living and saving lives. During the testing phase, the suggested model for adaptive segregation and differentiation of noise and relevant data performed well in methodically segregating and distinguishing between noise and important data. The stage of training the model and collecting data takes longer, since the model must be taught with a diverse dataset that includes artefacts with faults in order for the model to identify them. When the noise and extraneous data are removed, the model's time to detect the artefacts or features of an image with noise is 1.735 ms to 2 s per picture per dataset, which is roughly 1.375 ms to 1.26 s faster than the previously reported time.
C1 [Madhumathy, P.] RV Inst Technol & Management, Dept ECE, Bangalore, Karnataka, India.
   [Pandey, Digvijay] Dept Tech Educ, Dept Elect Engn, Kanpur, Uttar Pradesh, India.
   [Pandey, Digvijay] APJ Abdul Kalam Tech Univ, IET Lucknow, Lucknow, Uttar Pradesh, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Institute of
   Engineering & Technology Lucknow
RP Pandey, D (corresponding author), Dept Tech Educ, Dept Elect Engn, Kanpur, Uttar Pradesh, India.; Pandey, D (corresponding author), APJ Abdul Kalam Tech Univ, IET Lucknow, Lucknow, Uttar Pradesh, India.
EM digit11011989@gmail.com
OI PANDEY, DIGVIJAY/0000-0003-0353-174X
CR Agarwal G., 2021, EAI Endorsed Trans Ind Netw Intell Syst, V8, pe3, DOI 10.4108/eai.17-9-2021.170961
   [Anonymous], 2016, ARXIV160702444
   Cao M, 2017, IEEE T BIOMED CIRC S, V11, P411, DOI 10.1109/TBCAS.2016.2593470
   Cherry SR, 2018, J NUCL MED, V59, P3, DOI 10.2967/jnumed.116.184028
   de Montigny, PHOTOACOUSTIC TOMOGR
   Frijia EM, 2021, NEUROIMAGE, V225, DOI 10.1016/j.neuroimage.2020.117490
   Han M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194408
   Ji X, 2020, IEEE T MED IMAGING, V39, P3278, DOI 10.1109/TMI.2020.2990347
   Kim MW, 2020, IEEE T MED IMAGING, V39, P3379, DOI 10.1109/TMI.2020.2993835
   Li L, 2017, NAT BIOMED ENG, V1, DOI 10.1038/s41551-017-0071
   Li MC, 2020, IEEE T MED IMAGING, V39, P3343, DOI 10.1109/TMI.2020.2992244
   Li XP, 2020, IEEE T MED IMAGING, V39, P3463, DOI 10.1109/TMI.2020.2996240
   Mahmood F, 2020, IEEE T MED IMAGING, V39, P3257, DOI 10.1109/TMI.2019.2927182
   Nguyen HNY, 2020, BIOMED OPT EXPRESS, V11, P5745, DOI 10.1364/BOE.401375
   Nguyen HNY, 2019, BIOMED OPT EXPRESS, V10, P3124, DOI 10.1364/BOE.10.003124
   Pandey B. K., 2021, PROC MULTIDISCIP APP, P146
   Pandey BK., 2021, AUGMENTED HUMAN RES, V6, DOI [10.1007/s41133-021-00051-5, DOI 10.1007/S41133-021-00051-5]
   Pandey D, 2021, SOFT COMPUT, V25, P1563, DOI 10.1007/s00500-020-05245-4
   Peng YF, 2019, OPHTHALMOLOGY, V126, P565, DOI 10.1016/j.ophtha.2018.11.015
   Rejesh NA, 2013, J OPT SOC AM A, V30, P1994, DOI 10.1364/JOSAA.30.001994
   RIAD SM, 1986, P IEEE, V74, P82, DOI 10.1109/PROC.1986.13407
   Samieinasab M, 2020, IEEE T MED IMAGING, V39, P3475, DOI 10.1109/TMI.2020.2998066
   Shafiei S, 2020, IEEE T MED IMAGING, V39, P3355, DOI 10.1109/TMI.2020.2992108
   Syben C, 2020, IEEE T MED IMAGING, V39, P3488, DOI 10.1109/TMI.2020.2998179
   Wang J, 2018, BIOMED ENG ONLINE, V17, DOI 10.1186/s12938-018-0537-x
   Xu L., 2017, ADV NEURAL INFORM PR, P1790
   Zhai J, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00062
   Zhang C, 2020, IEEE T MED IMAGING, V39, P3309, DOI 10.1109/TMI.2020.2991266
   Zhang F, 2020, IEEE T MED IMAGING, V39, P3331, DOI 10.1109/TMI.2020.2990625
NR 29
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7501
EP 7518
DI 10.1007/s11042-022-11903-6
EA JAN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000750865600012
DA 2024-07-18
ER

PT J
AU Huang, SY
   Zhang, MQ
   Ke, Y
   Bi, XL
   Kong, YJ
AF Huang, Siyuan
   Zhang, Minqing
   Ke, Yan
   Bi, Xinliang
   Kong, Yongjun
TI Image steganalysis based on attention augmented convolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganalysis; Attention augmented convolution; Adaptive
   steganography; Deep learning
ID ADAPTIVE STEGANALYSIS; SELECTION
AB Steganalysis, as the opposite technique to steganography, has been applied to determine whether secret information is embedded in an image. The existing adaptive steganography methods embed secret information in different regions of an image with different probabilities. However, it is difficult for most steganalysis models to make a targeted attention of steganography regions of images, which reduces the detection accuracy of the steganalysis models when detecting the adaptive steganography methods. Aiming to detect the JPEG-based adaptive steganography, this paper proposes a model called Steganalysis Attention Augmented Network (SAANet). The proposed model uses attention augmented convolution instead of traditional convolution, so that the network assigns more learning weights to the steganographic area, and guides the network to better learn features that are beneficial to steganalysis. Thereby improving the learning ability and training effect of the model. As far as we know, we are the first to directly apply attention to the backbone structure of the network model to assist in image steganalysis. And our work improves the accuracy and operating efficiency of the steganalysis model. Experiments show that compared with the current steganalysis models, the model proposed in this paper obtains a competitive detection performance. The current adaptive steganography algorithm achieves a detection accuracy of up to 96.68%, while 95.22% under mismatch conditions, and the testing time is 28 s, indicating that the proposed model has a certain generalization performance and practicability.
C1 [Huang, Siyuan; Zhang, Minqing; Bi, Xinliang; Kong, Yongjun] Engn Univ PAP, Coll Cryptog Engn, Xian 710086, Peoples R China.
   [Huang, Siyuan; Zhang, Minqing; Ke, Yan; Bi, Xinliang; Kong, Yongjun] Engn Univ PAP, Key Lab Network & Informat Secur PAP, Xian 710086, Peoples R China.
   [Ke, Yan] Engn Univ PAP, Counterterrorism Command & Informat Engn Joint La, Urumqi Campus, Urumqi 830049, Peoples R China.
RP Huang, SY (corresponding author), Engn Univ PAP, Coll Cryptog Engn, Xian 710086, Peoples R China.; Huang, SY (corresponding author), Engn Univ PAP, Key Lab Network & Informat Secur PAP, Xian 710086, Peoples R China.
EM huangsiyuan828@163.com
RI Yan, Keyu/IXX-0343-2023; Ke, Yan/HTS-4679-2023
CR Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bas P., 2007, Bows-2
   Bello I, 2019, IEEE I CONF COMP VIS, P3285, DOI 10.1109/ICCV.2019.00338
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Chen JZ, 2016, PROCEEDINGS OF 2016 12TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P551, DOI [10.1109/CIS.2016.133, 10.1109/CIS.2016.0134]
   Chen M, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P75, DOI 10.1145/3082031.3083248
   Dalal M, 2021, MULTIMED TOOLS APPL, V80, P5723, DOI 10.1007/s11042-020-09929-9
   Denemark T, 2016, IEEE T INF FOREN SEC, V11, P1747, DOI 10.1109/TIFS.2016.2555281
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Guo LJ, 2015, IEEE T INF FOREN SEC, V10, P2669, DOI 10.1109/TIFS.2015.2473815
   Guo LJ, 2014, IEEE T INF FOREN SEC, V9, P814, DOI 10.1109/TIFS.2014.2312817
   Guttikonda JB, 2019, MULTIMED TOOLS APPL, V78, P21113, DOI 10.1007/s11042-019-7168-5
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Hu DH, 2019, IEEE ACCESS, V7, P25924, DOI 10.1109/ACCESS.2019.2900076
   Hu DH, 2017, SECUR COMMUN NETW, DOI 10.1155/2017/2314860
   Jung KH, 2010, IMAGING SCI J, V58, P213, DOI 10.1179/136821910X12651933390584
   Jung Kihyun, 2015, [Journal of the Institute of Electronics and Information Engineers, 전자공학회논문지], V52, P79
   Kaur G, 2021, ARCH COMPUT METHOD E, V28, P3517, DOI 10.1007/s11831-020-09512-3
   Ki-Hyun Jung, 2018, WSEAS Transactions on Systems and Control, V13, P103
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li SY, 2020, MULTIMED TOOLS APPL, V79, P4315, DOI 10.1007/s11042-018-7046-6
   Liao X, 2016, SECUR COMMUN NETW, V9, P5756, DOI 10.1002/sec.1734
   Parmar Niki, 2018, INT C MACH LEARN STO
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Rawat R, 2020, MULTIMED TOOLS APPL, V79, P1971, DOI 10.1007/s11042-019-08263-z
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Singh B, 2021, MULTIMED TOOLS APPL, V80, P4903, DOI 10.1007/s11042-020-09960-w
   Su A, 2020, MULTIMED TOOLS APPL, P1
   Su AT, 2021, MULTIMED TOOLS APPL, V80, P3349, DOI 10.1007/s11042-020-09350-2
   Tang WX, 2016, IEEE T INF FOREN SEC, V11, P734, DOI 10.1109/TIFS.2015.2507159
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Xu GS, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P67, DOI 10.1145/3082031.3083236
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Zhang H, 2019, PR MACH LEARN RES, V97
NR 43
TC 4
Z9 4
U1 1
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19471
EP 19490
DI 10.1007/s11042-021-11862-4
EA JAN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000746780700010
DA 2024-07-18
ER

PT J
AU Gao, L
   Xu, KL
   Wang, HM
   Peng, YX
AF Gao, Liang
   Xu, Kele
   Wang, Huaimin
   Peng, Yuxing
TI Multi-representation knowledge distillation for audio classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neural networks; Multiple representations; Acoustic classification;
   Knowledge distillation
ID ENSEMBLES
AB Audio classification aims to discriminate between different audio signal types, and it has received intensive attention due to its wide applications. In deep learning-based audio classification methods, researchers usually transform the raw signal of audios into different feature representations (such as Short Time Fourier Transform and Mel Frequency Cepstral Coefficients) as the inputs of networks. However, selecting the feature representation requires expert knowledge and extensive experimental verification. Besides, using a single type of feature representation may cause suboptimal results as the information implied in different kinds of feature representations may be complementary. Previous works show that ensembling the networks trained on different representations can greatly boost classification performance. However, making inferences using multiple networks is cumbersome and computation expensive. In this paper, we propose a novel end-to-end collaborative training framework for the audio classification task. The framework takes multiple representations as inputs to train the networks jointly with a knowledge distillation method. Consequently, our framework significantly promotes the performance of networks without increasing the computational overhead in the inference stage. Extensive experimental results demonstrate that the proposed approach improves classification performance and achieves competitive results on both acoustic scene classification tasks and general audio tagging tasks.
C1 [Gao, Liang; Xu, Kele; Wang, Huaimin; Peng, Yuxing] Natl Univ Def Technol, Coll Comp, Natl Key Lab Parallel & Distributed Proc, Changsha 410073, Peoples R China.
C3 National University of Defense Technology - China
RP Xu, KL (corresponding author), Natl Univ Def Technol, Coll Comp, Natl Key Lab Parallel & Distributed Proc, Changsha 410073, Peoples R China.
EM gaoliang13@nudt.edu.cn; whmnudt@163.com; pengyuhang@nudt.edu.cn
RI peng, yu/GXW-2071-2022
OI XU, KELE/0000-0001-5997-5169
FU major Science and Technology Innovation 2030 "New generation Artificial
   Intelligence'' project [2020AAA104803]
FX This paper is supported by the major Science and Technology Innovation
   2030 "New generation Artificial Intelligence'' project 2020AAA104803.
CR Anil R., 2018, Large scale distributed neural network training through online distillation
   [Anonymous], 2017, P SMC 2017 14 SOUND
   [Anonymous], 2017, P 18 ISMIR C SUZH CH, DOI DOI 10.5281/ZENODO.1417159
   [Anonymous], 2018, DCASE
   [Anonymous], 2018, Computational analysis of sound scenes and events, DOI DOI 10.1007/978-3-319-63450-0
   Batra T., 2017, ARXIV170505512
   Bucilua C., 2006, P 12 ACM SIGKDD INT, P535, DOI DOI 10.1145/1150402.1150464
   Dhanalakshmi P, 2009, EXPERT SYST APPL, V36, P6069, DOI 10.1016/j.eswa.2008.06.126
   Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941
   Fraile R, 2018, CLASSIFICATION ACOUS
   Guido RC, 2019, J FRANKLIN I, V356, P2346, DOI 10.1016/j.jfranklin.2018.12.007
   Guido RC, 2019, IEEE SIGNAL PROC MAG, V36, P154, DOI 10.1109/MSP.2018.2874549
   Hao W, 2018, DCASE 2018 TASK ACOU
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hinton G., 2015, arXiv preprint arXiv:1503.02531
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang YJ, 2019, IEEE T CIRC SYST VID, V29, P1038, DOI 10.1109/TCSVT.2018.2823360
   Jing LP, 2017, IEEE T MULTIMEDIA, V19, P2637, DOI 10.1109/TMM.2017.2703939
   Jun W, 2018, SELF ATTENTION MECHA
   Jung J, 2018, DNN BASED MULTI LEVE
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulkarni A, 2009, US Patent, Patent No. [7,490,044, 7490044]
   Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006
   Lan X., 2018, Advances in neural information processing systems, P7528
   Ma C, 2019, IEEE T MULTIMEDIA, V21, P1169, DOI 10.1109/TMM.2018.2875512
   Ma L., 2003, P EUROSPEECH 2003, P2237
   Mesaros A., 2018, P DET CLASS AC SCEN, P9
   Piczak KJ, 2015, IEEE INT WORKS MACH
   POGGIO T, 1990, SCIENCE, V247, P978, DOI 10.1126/science.247.4945.978
   Ren JF, 2017, IEEE T MULTIMEDIA, V19, P447, DOI 10.1109/TMM.2016.2618218
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Sercu T., 2016, COMPUT SCI, DOI DOI 10.48550/ARXIV.1611.09288
   Shan S, 2018, AUTOMATIC AUDIO TAGG
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun SZ, 2017, LECT NOTES ARTIF INT, V10534, P187, DOI 10.1007/978-3-319-71249-9_12
   Truc N., 2018, DCASE, P34
   Veredas FJ, 2020, NEURAL COMPUT APPL, V32, P323, DOI 10.1007/s00521-018-3655-2
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P911, DOI 10.1109/TGRS.2018.2862899
   Wei Q, 2018, REPORT ON AUDIO TAGG
   Xu KL, 2019, J ACOUST SOC AM, V145, pEL521, DOI 10.1121/1.5111059
   Xu Y, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P121, DOI 10.1109/ICASSP.2018.8461975
   Xu Z, 2018, AALTO SYSTEM BASED F
   Yang JH, 2018, SE RESNET GAN BASED
   Yin YF, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1892, DOI 10.1145/3240508.3240631
   Zhang CJ, 2018, IEEE T MULTIMEDIA, V20, P903, DOI 10.1109/TMM.2017.2759500
   Zhang Hongyi, 2018, MIXUP EMPIRICAL RISK, DOI DOI 10.48550/ARXIV.1710.09412
   Zhang SQ, 2018, IEEE T MULTIMEDIA, V20, P1576, DOI 10.1109/TMM.2017.2766843
   Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454
NR 48
TC 11
Z9 11
U1 7
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5089
EP 5112
DI 10.1007/s11042-021-11610-8
EA JAN 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000740429700004
DA 2024-07-18
ER

PT J
AU Rizwan, M
   Nadeem, A
   Sarwar, S
   Iqbal, M
   Safyan, M
   Ul Qayyum, Z
AF Rizwan, Muhammad
   Nadeem, Aamer
   Sarwar, Sohail
   Iqbal, Muddesar
   Safyan, Muhammad
   Ul Qayyum, Zia
TI EkmEx-an extended framework for labeling an unlabeled fault dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Expert opinion; Labeling datasets; Software fault proneness; Software
   metrics
ID DEFECT PREDICTION; CODE SMELLS; SOFTWARE; QUALITY; SYSTEM
AB Software fault prediction (SFP) is a quality assurance process that identifies if certain modules are fault-prone (FP) or not-fault-prone (NFP). Hence, it minimizes the testing efforts incurred in terms of cost and time. Supervised machine learning techniques have capacity to spot-out the FP modules. However, such techniques require fault information from previous versions of software product. Such information, accumulated over the life-cycle of software, may neither be readily available nor reliable. Currently, clustering with experts' opinions is a prudent choice for labeling the modules without any fault information. However, the asserted technique may not fully comprehend important aspects such as selection of experts, conflict in expert opinions, catering the diverse expertise of domain experts etc. In this paper, we propose a comprehensive framework named EkmEx that extends the conventional fault prediction approaches while providing mathematical foundation through aspects not addressed so far. The EkmEx guides in selection of experts, furnishes an objective solution for resolve of verdict-conflicts and manages the problem of diversity in expertise of domain experts. We performed expert-assisted module labeling through EkmEx and conventional clustering on seven public datasets of NASA. The empirical outcomes of research exhibit significant potential of the proposed framework in identifying FP modules across all seven datasets.
C1 [Rizwan, Muhammad; Nadeem, Aamer] Capital Univ Sci & Technol, Dept Comp Sci, Islamabad, Pakistan.
   [Sarwar, Sohail; Iqbal, Muddesar] London South Bank Univ, Dept Comp Sci, London, England.
   [Safyan, Muhammad] Govt Coll Univ, Dept Comp Sci, Lahore, Pakistan.
   [Ul Qayyum, Zia] Allama Iqbal Open Univ, Dept Comp Sci, Islamabad, Pakistan.
C3 Capital University of Science & Technology; London South Bank
   University; Government College University Lahore
RP Sarwar, S (corresponding author), London South Bank Univ, Dept Comp Sci, London, England.
EM sohail.sarwar@seecs.edu.pk
RI Iqbal, Muddesar/JJC-7510-2023; Sarwar, Sohail/KCJ-4936-2024; Nadeem,
   Aamer/F-7509-2011
OI Iqbal, Muddesar/0000-0002-8438-6726; Sarwar, Sohail/0000-0001-7565-439X;
   Nadeem, Aamer/0000-0002-8641-8795
CR AbuHassan A, 2021, J SOFTW-EVOL PROC, V33, DOI 10.1002/smr.2320
   Al-Shaaby A., 2020, Arab J Sci Eng, P1
   Alsghaier H, 2020, SOFTWARE PRACT EXPER, V50, P407, DOI 10.1002/spe.2784
   Amasaki S, 2020, EMPIR SOFTW ENG, V25, P1573, DOI 10.1007/s10664-019-09777-8
   [Anonymous], 2007, The promise repository of empirical software engineering data
   [Anonymous], 2015, ISO 9000:2015(en)
   Beecham S, 2010, SYSTEMATIC REV FAULT
   Bender R, 1999, BIOMETRICAL J, V41, P305, DOI 10.1002/(SICI)1521-4036(199906)41:3<305::AID-BIMJ305>3.0.CO;2-Y
   Bird C, 2009, 7TH JOINT MEETING OF THE EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND THE ACM SIGSOFT SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P121, DOI 10.1145/1595696.1595716
   Bishnu PS, 2012, IEEE T KNOWL DATA EN, V24, P1146, DOI 10.1109/TKDE.2011.163
   Black S., 2010, Technical report Lero-TR-2010-04
   Briand LC, 1998, FIFTH INTERNATIONAL SOFTWARE METRICS SYMPOSIUM - METRICS 1998, PROCEEDINGS, P246, DOI 10.1109/METRIC.1998.731251
   Catal C, 2009, LECT NOTES ENG COMP, P212
   Catal C, 2011, EXPERT SYST APPL, V38, P4626, DOI 10.1016/j.eswa.2010.10.024
   Catal C, 2009, PROCEEDINGS OF THE 2009 SIXTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, VOLS 1-3, P199, DOI 10.1109/ITNG.2009.12
   Catal C, 2009, EXPERT SYST APPL, V36, P7346, DOI 10.1016/j.eswa.2008.10.027
   Chappell T, 2017, 2017 IEEE INTERNATIONAL WORKSHOP ON MACHINE LEARNING TECHNIQUES FOR SOFTWARE QUALITY EVALUATION (MALTESQUE), P21, DOI 10.1109/MALTESQUE.2017.7882012
   El Emam K, 2001, J SYST SOFTWARE, V56, P63, DOI 10.1016/S0164-1212(00)00086-8
   el Emam K., 1999, A validation of object-oriented metrics"
   Fenton N., 2014, Software Metrics: A Rigorous and Practical Approach, V3rd, DOI DOI 10.1201/B17461
   Ghani I, 2014, Handbook of research on emerging advancements and technologies in software engineering
   Gondra I, 2008, J SYST SOFTWARE, V81, P186, DOI 10.1016/j.jss.2007.05.035
   Gupta R, 2020, PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING, P45, DOI [10.1109/confluence47617.2020.9058138, 10.1109/Confluence47617.2020.9058138]
   Hall T, 2014, ACM T SOFTW ENG METH, V23, DOI 10.1145/2629648
   Halstead M. H., 1977, ELEMENTS SOFTWARE SC
   Herbold S., 2013, P 9 INT C PREDICTIVE, P1
   Herzig K, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P392, DOI 10.1109/ICSE.2013.6606585
   Kotkova B., 2020, INT J POWER SYST, V5
   Son LH, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11020212
   Li K, 2020, ARXIV200203148
   Li W, 2007, J SYST SOFTWARE, V80, P1120, DOI 10.1016/j.jss.2006.10.018
   Li ZQ, 2018, IET SOFTW, V12, P161, DOI 10.1049/iet-sen.2017.0148
   Ma Y, 2012, INFORM SOFTWARE TECH, V54, P248, DOI 10.1016/j.infsof.2011.09.007
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Malhotra R, 2015, APPL SOFT COMPUT, V27, P504, DOI 10.1016/j.asoc.2014.11.023
   Marinescu R, 2004, PROC IEEE INT CONF S, P350, DOI 10.1109/ICSM.2004.1357820
   MARTINETZ TM, 1993, IEEE T NEURAL NETWOR, V4, P558, DOI 10.1109/72.238311
   McCabe T. J., 1976, IEEE Transactions on Software Engineering, VSE-2, P308, DOI 10.1109/TSE.1976.233837
   MCCABE TJ, 1989, COMMUN ACM, V32, P1415, DOI 10.1145/76380.76382
   Nam J, 2018, IEEE T SOFTWARE ENG, V44, P874, DOI 10.1109/TSE.2017.2720603
   Nam J, 2015, IEEE INT CONF AUTOM, P452, DOI 10.1109/ASE.2015.56
   Nam J, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P382, DOI 10.1109/ICSE.2013.6606584
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Olbrich S. M., 2010, 2010 IEEE 26th International Conference on Software Maintenance (ICSM 2010), DOI 10.1109/ICSM.2010.5609564
   Olbrich S, 2009, INT SYMP EMP SOFTWAR, P391
   Radjenovic D, 2013, INFORM SOFTWARE TECH, V55, P1397, DOI 10.1016/j.infsof.2013.02.009
   Rathore SS, 2017, COMPUTING, V99, P255, DOI 10.1007/s00607-016-0489-6
   Rodriguez D, 2013, INFORM SOFTWARE TECH, V55, P1810, DOI 10.1016/j.infsof.2013.05.002
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Seliya N, 2007, IEEE T SYST MAN CY A, V37, P201, DOI 10.1109/TSMCA.2006.889473
   Shepperd M, 2013, IEEE T SOFTWARE ENG, V39, P1208, DOI 10.1109/TSE.2013.11
   Sjoberg DIK, 2013, IEEE T SOFTWARE ENG, V39, P1144, DOI 10.1109/TSE.2012.89
   Turhan B, 2009, EMPIR SOFTW ENG, V14, P540, DOI 10.1007/s10664-008-9103-7
   Wahono R. S., 2015, Journal of Software Engineering, V1, P1
   Watanabe S., 2008, P 4 INT WORKSH PRED, P19
   Xu Z, 2019, J COMPUT SCI TECH-CH, V34, P1039, DOI 10.1007/s11390-019-1959-z
   Yan M, 2017, INT SYMP EMP SOFTWAR, P344, DOI 10.1109/ESEM.2017.48
   Yang J, 2016, PROCEEDINGS OF 2016 IEEE 18TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS; IEEE 14TH INTERNATIONAL CONFERENCE ON SMART CITY; IEEE 2ND INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P465, DOI [10.1109/HPCC-SmartCity-DSS.2016.87, 10.1109/HPCC-SmartCity-DSS.2016.0073]
   Yang YH, 2018, PROCEEDINGS OF 2018 TENTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P631, DOI 10.1109/ICACI.2018.8377533
   Yang YB, 2016, FSE'16: PROCEEDINGS OF THE 2016 24TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON FOUNDATIONS OF SOFTWARE ENGINEERING, P157, DOI 10.1145/2950290.2950353
   Yuan XH, 2000, 3RD IEEE SYMPOSIUM ON APPLICATION SPECIFIC SYSTEMS AND SOFTWARE ENGINEERING TECHNOLOGY, PROCEEDINGS, P85, DOI 10.1109/ASSET.2000.888052
   Zakari A, 2019, 2019 IEEE 15TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2019), P16, DOI [10.1109/CSPA.2019.8696018, 10.1109/cspa.2019.8696018]
   Zhang J, 2020, IEEE ACCESS, V8, P110059, DOI 10.1109/ACCESS.2020.3001440
   Zhong S, 2004, EIGHTH IEEE INTERNATIONAL SYMPOSIUM ON HIGH ASSURANCE SYSTEMS ENGINEERING, PROCEEDINGS, P149
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
   Zimmermann T, 2008, ICSE'08 PROCEEDINGS OF THE THIRTIETH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, P531, DOI 10.1145/1368088.1368161
NR 66
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12141
EP 12156
DI 10.1007/s11042-021-11441-7
EA JAN 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000740429700031
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Nirala, KK
   Singh, NK
   Purani, VS
AF Nirala, Krishna Kumar
   Singh, Nikhil Kumar
   Purani, Vinay Shivshanker
TI A survey on providing customer and public administration based services
   using AI: chatbot
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chatbot; Artificial Intelligence (AI); Natural Language Processing
   (NLP); Public administration; Neural network; Deep learning; Natural
   Language Understanding (NLU)
ID ARTIFICIAL NEURAL-NETWORK; COMPUTER
AB A chatbot is emerged as an effective tool to address the user queries in automated, most appropriate and accurate way. Depending upon the complexity of the subject domain, researchers are employing variety of soft-computing techniques to make the chatbot user-friendly. It is observed that chatbots have flooded the globe with wide range of services including ordering foods, suggesting products, advising for insurance policies, providing customer support, giving financial assistance, schedule meetings etc. However, public administration based services wherein chatbot intervention influence the most, is not explored yet. This paper discuses about artificial intelligence based chatbots including their applications, challenges, architecture and models. It also talks about evolution of chatbots starting from Turing Test and Rule-based chatbots to advanced Artificial Intelligence based Chatbots (AI-Chatbots). AI-Chatbots are providing much kind of services, which this paper outlines into two main aspects including customer based services and public administration based services. The purpose of this survey is to understand and explore the possibility of customer & public administration services based chatbot. The survey demonstrates that there exist an immense potential in the AI assisted chatbot system for providing customer services and providing better governance in public administration services.
C1 [Nirala, Krishna Kumar] Gujarat Technol Univ, Ahmadabad, Gujarat, India.
   [Singh, Nikhil Kumar] Govt Engn Coll, Gandhinagar, Gujarat, India.
   [Purani, Vinay Shivshanker] Govt Engn Coll, Valsad, Gujarat, India.
C3 Gujarat Technological University
RP Singh, NK (corresponding author), Govt Engn Coll, Gandhinagar, Gujarat, India.
EM kknirala100@gmail.com; nikhil.singh31@gmail.com; vinaypurani@yahoo.com
RI Pimentel, Luis/HGC-5838-2022
OI SINGH, NIKHIL/0000-0002-8668-1569
CR Abdul-Kader SA, 2017, PROCEEDINGS OF THE 2017 INTELLIGENT SYSTEMS CONFERENCE (INTELLISYS), P863, DOI 10.1109/IntelliSys.2017.8324231
   Ahmady SE, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2020), P177, DOI 10.1109/ICCCS49078.2020.9118510
   Al-Sahaf H, 2019, J ROY SOC NEW ZEAL, V49, P205, DOI 10.1080/03036758.2019.1609052
   Ali A., 2021, DATA AGGREGATION BAS, P1
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Ali B., 2021, INTELLIGENT DATA ENG, P301, DOI [10.1007/978-981-15-5679-1_28, DOI 10.1007/978-981-15-5679-1_28]
   Alsharif MH, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010088
   [Anonymous], 1950, MIND, DOI 10.1093/mind/LIX.236.433
   [Anonymous], 2012, P 2012 JOINT C EMPIR, DOI 10.5555/2390948.2391094
   [Anonymous], REGISTER ENTERPRISES
   [Anonymous], AMAZON LEX CONVERSAT
   Arsovski S, 2019, EXPERT SYST APPL, V137, P343, DOI 10.1016/j.eswa.2019.07.014
   Baby CJ, 2017, 2017 INNOVATIONS IN POWER AND ADVANCED COMPUTING TECHNOLOGIES (I-PACT)
   Barker S., 2017, MHD SUPPLY CHAIN SOL, V47, P30
   Bellini V, 2020, EAIS, P1
   Bhagwat V.A., 2018, Masters Thesis
   Bharati Puja, 2020, Computational Intelligence in Pattern Recognition. Proceedings of CIPR 2019. Advances in Intelligent Systems and Computing (AISC 999), P657, DOI 10.1007/978-981-13-9042-5_56
   Bradesko Luka, 2012, P SLOV LANG TECHN SO, V2, P34
   Chamberlain William., 1984, The Policeman's Beard Is Half-Constructed: Computer Prose and Poetry
   Chun A, 2007, P NAT C ART INT AAAI, V2, P1684
   Chung M, 2020, J BUS RES, V117, P587, DOI 10.1016/j.jbusres.2018.10.004
   Clark P, 2016, AI MAG, V37, P5, DOI 10.1609/aimag.v37i1.2636
   Csaky R, 2019, ARXIV PREPRINT ARXIV
   Devlin J., 2018, BERT PRE TRAINING DE
   Gal Y, 2016, PR MACH LEARN RES, V48
   Galitsky B, 2015, WORKSH 20 9 AAAI C A
   Galitsky B., 2019, Developing Enterprise Chatbots: Learning Linguistic Structures, P13
   Gambhir P, 2019, P ART INT SPEECH TEC
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gregori E, 2017, EVALUATION MODERN TO, P1
   Guzeldere G, 1995, Stanford Humanities Review, V4, P161
   Hardt M, 2016, ADV NEUR IN, V29
   Henman P, 2020, ASIA PAC J PUBLIC AM, V42, P209, DOI 10.1080/23276665.2020.1816188
   Hermann KM, 2015, ADV NEUR IN, V28
   Hongshen Chen, 2017, ACM SIGKDD Explorations Newsletter, V19, P25, DOI 10.1145/3166054.3166058
   Ina, 2021, HIST CHATBOTS FROM E
   Karia S., 2020, SSRN J, DOI [10.2139/ssrn.3747951, DOI 10.2139/SSRN.3747951]
   Kosugi M, 2019, INT CONF INFORM COMM, DOI 10.1109/ict-dm47966.2019.9032901
   Kouziokas GN., 2017, ARTIF INTELL, P361
   Kouziokas GN, 2017, P 6 INT S 28 NAT C O, P168
   Kuipers B., 1976, ACM SIGART Bulletin, P4, DOI DOI 10.1145/1045264.1045265
   Kuligowska K, 2015, Professionals Center for Business Research, V2, P1
   Kulkarni CS., 2017, International Research Journal of Engineering and Technology, V4, P2374
   Language Understanding (LUIS), MICROSOFT AZURE
   Lee CH, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P491, DOI 10.1109/IRI.2018.00078
   Liu H., 2017, ARXIVPREPRINT1711027, V1711, P02781
   Madhu D, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P243, DOI 10.1109/ICICCT.2017.7975195
   McLean G, 2019, TECHNOL FORECAST SOC, V146, P55, DOI 10.1016/j.techfore.2019.05.017
   Mehfooz Fahad, 2021, ICT Analysis and Applications. Proceedings of ICT4SD 2020. Lecture Notes in Networks and Systems (LNNS 154), P423, DOI 10.1007/978-981-15-8354-4_42
   Mehr Hila., 2017, ASH CENT DEMOCR GOV, P1
   Mohammady S, 2014, INT ARCH PHOTOGRAMM, V40, P203, DOI 10.5194/isprsarchives-XL-2-W3-203-2014
   Nay C., 2011, IBM Research_News
   Nuruzzaman M, 2018, INT CONF E BUS ENG, P54, DOI 10.1109/ICEBE.2018.00019
   O'Boyle B, 2020, WHAT IS ALEXA WHAT C
   O'Boyle B, 2020, WHAT IS SIRI DOES SI
   OECD, 2021, UNA THE 1 VIRT ASS P
   Okuda T, 2018, FUJITSU SCI TECH J, V54, P4
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Patel F, 2019, ANNU IEEE IND CONF, DOI 10.1109/indicon47234.2019.9030346
   Pichponreay L, 2016, INT CONF UBIQ FUTUR, P1002, DOI 10.1109/ICUFN.2016.7536948
   Ranoliya BR, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1525, DOI 10.1109/ICACCI.2017.8126057
   Richardson Matthew, 2013, P 2013 C EMP METH NA, P193
   Rodsawang C, 2020, OSIR J, V13, P71
   Russell-rose T, 2020, FRAMEWORK CHATBOT EV
   Shaikh A, 2016, INT J ENG SCI, V3117
   Shark Alan R, 2019, ARTIFICIAL INTELLIGE, P25
   Shivam K., 2018, INT J COMP TECHNOL, V5, P74
   Smith A, 2020, UNDERSTANDING ARCHIT
   Su MH, 2017, INT CONF ORANGE TECH, P70, DOI 10.1109/ICOT.2017.8336091
   Sutskever I, 2014, ADV NEUR IN, V27
   Walker MA, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P271
   Wallace Richard S., 2009, Parsing the Turing Test: Philosophical and Methodological Issues in the Quest for the Thinking Computer, P181, DOI [10.1007/978-1-4020-6710-5_13, DOI 10.1007/978-1-4020-6710-5_13]
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991
   Weston J., 2015, CoRR
   Worswick S, 2018, MITSUKU CHATBOT MITS
   WSA, 2021, WIENBOT A CHATB CIT
   Xu Z, 2016, LECT NOTES ELECTR EN, V375, P7, DOI 10.1007/978-981-10-0539-8_2
   Yan R, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P55, DOI 10.1145/2911451.2911542
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Yu S, 2021, FRONT APPL MATH STAT, V7, DOI 10.3389/fams.2021.604842
NR 80
TC 23
Z9 25
U1 22
U2 124
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22215
EP 22246
DI 10.1007/s11042-021-11458-y
EA JAN 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000737741900007
PM 35002470
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Gómez-Huélamo, C
   Del Egido, J
   Bergasa, LM
   Barea, R
   López-Guillén, E
   Arango, F
   Araluce, J
   López, J
AF Gomez-Huelamo, Carlos
   Del Egido, Javier
   Bergasa, Luis M.
   Barea, Rafael
   Lopez-Guillen, Elena
   Arango, Felipe
   Araluce, Javier
   Lopez, Joaquin
TI Train here, drive there: ROS based end-to-end autonomous-driving
   pipeline validation in CARLA simulator using the NHTSA typology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CARLA; Autonomous Driving; ROS; Simulation; Decision-Making; NHTSA
   typology
ID ENVIRONMENTS
AB Urban complex scenarios are the most challenging situations in the field of Autonomous Driving (AD). In that sense, an AD pipeline should be tested in countless environments and scenarios, escalating the cost and development time exponentially with a physical approach. In this paper we present a validation of our fully-autonomous driving architecture using the NHTSA (National Highway Traffic Safety Administration) protocol in the CARLA simulator, focusing on the analysis of our decision-making module, based on Hierarchical Interpreted Binary Petri Nets (HIBPN). First, the paper states the importance of using hyper-realistic simulators, as a preliminary help to real test, as well as an appropriate design of the traffic scenarios as the two current keys to build safe and robust AD technology. Second, our pipeline is introduced, which exploits the concepts of standard communication in robotics using the Robot Operating System (ROS) and the Docker approach to provide the system with isolation, flexibility and portability, describing the main modules and approaches to perform the navigation. Third, the CARLA simulator is described, outlining the steps carried out to merge our architecture with the simulator and the advantages to create ad-hoc driving scenarios for use cases validation instead of just modular evaluation. Finally, the architecture is validated using some challenging driving scenarios such as Pedestrian Crossing, Stop, Adaptive Cruise Control (ACC) and Unexpected Pedestrian. Some qualitative (video files: Simulation Use Cases) and quantitative (linear velocity and trajectory splitted in the corresponding HIBPN states) results are presented for each use case, as well as an analysis of the temporal graphs associated to the Vulnerable Road Users (VRU) cases, validating our architecture in simulation as a preliminary stage before implementing it in our real autonomous electric car.
C1 [Gomez-Huelamo, Carlos; Del Egido, Javier; Bergasa, Luis M.; Barea, Rafael; Lopez-Guillen, Elena; Arango, Felipe; Araluce, Javier] Univ Alcala UAH, Elect Dept, Madrid, Spain.
   [Lopez, Joaquin] Univ Vigo UVIGO, Dept Syst Engn & Automat, Pontevedra, Spain.
C3 Universidad de Alcala; Universidade de Vigo
RP Gómez-Huélamo, C (corresponding author), Univ Alcala UAH, Elect Dept, Madrid, Spain.
EM carlos.gomezh@edu.uah.es; javier.egido@edu.uah.es; luism.bergasa@uah.es;
   rafael.barea@uah.es; elena.lopezg@uah.es; juanfelipe.arango@edu.uah.es;
   javier.araluce@edu.uah.es; joaquin@uvigo.es
RI Bergasa, Luis M./H-9810-2013; Barea, Rafael/R-5760-2016; López,
   Joaquín/JDV-7766-2023; Fernández, Joaquín/JGM-0866-2023
OI Bergasa, Luis M./0000-0002-0087-3077; Araluce,
   Javier/0000-0001-5101-0485; Lopez-Guillen, Elena/0000-0002-8145-9045;
   Arango Vargas, Juan Felipe/0000-0003-4989-9443; Gomez-Huelamo,
   Carlos/0000-0002-3819-3747
FU Spanish MICINN/FEDER [RTI2018-099263-B-C21]; RoboCity2030-DIH-CM project
   by Programas de actividades I+D (CAM) [P2018/NMT-4331]; EU Structural
   Funds; CRUE-CSIC agreement; Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This work has been funded in part from the Spanish
   MICINN/FEDER through the Techs4AgeCar project (RTI2018-099263-B-C21) and
   from the RoboCity2030-DIH-CM project (P2018/NMT-4331), funded by
   Programas de actividades I+D (CAM) and cofunded by EU Structural Funds.
CR Althoff Matthias, 2018, 2018 IEEE International Conference on Service Operations and Logistics, and Informatics (SOLI), P157, DOI 10.1109/SOLI.2018.8476801
   [Anonymous], 2008, J PHYS AGENTS, DOI 10.14198/JoPha.2008.2.1.03
   [Anonymous], 2018, P 19 INT WORKSH PHYS
   Bast H, 2016, LECT NOTES COMPUT SC, V9220, P19, DOI 10.1007/978-3-319-49487-6_2
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   Bender P, 2014, IEEE INT VEH SYM, P420, DOI 10.1109/IVS.2014.6856487
   Benekohal Rahim F., 1988, Transportation research record, V1194, P99
   Bojarski M., 2016, ARXIV PREPRINT ARXIV
   Brandes U, 2001, J MATH SOCIOL, V25, P163, DOI 10.1080/0022250X.2001.9990249
   Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Davies Alex, 2016, Wired
   DelEgido J, 2020, WORKSH PHYS AG, P241
   DICKMANNS ED, 1990, IEEE T SYST MAN CYB, V20, P1273, DOI 10.1109/21.61200
   Dosovitskiy A., 2017, P 1 ANN C ROB LEARN, P1, DOI DOI 10.48550/ARXIV.1711.03938
   Dupuis M., 2010, P DRIV SIM C EUR, P231
   Fernández C, 2015, IEEE INT C INTELL TR, P719, DOI 10.1109/ITSC.2015.122
   Fernández JL, 2004, ROBOT AUTON SYST, V46, P205, DOI 10.1016/j.robot.2004.02.004
   Fernández JL, 2008, IEEE INT CONF ROBOT, P1372, DOI 10.1109/ROBOT.2008.4543394
   Geiger A., 2012, CVPR
   Gold C, 2016, HUM FACTORS, V58, P642, DOI 10.1177/0018720816634226
   Golinska P, 2012, SUSTAINABLE TRANSPOR, P3, DOI DOI 10.1007/978-3-642-23550-4_1
   Gomez-Huelamo C., 2020, WORKSH PHYS AG, P44
   Gómez-Huelamo C, 2019, IEEE INT C INTELL TR, P2305, DOI 10.1109/ITSC.2019.8917017
   Gomez-Saavedra CA, 2020, PROCEEDINGS OF THE XXII 2020 IEEE INTERNATIONAL AUTUMN MEETING ON POWER, ELECTRONICS AND COMPUTING (ROPEC 2020), VOL 4, DOI 10.1109/ropec50909.2020.9258688
   Guo K, 2017, SAE TECHNICAL PAPER, DOI [10.4271/2017-01-2009, DOI 10.4271/2017-01-2009]
   Haas J. K., 2014, A history of the unity game engine
   Haklay M, 2008, IEEE PERVAS COMPUT, V7, P12, DOI 10.1109/MPRV.2008.80
   Held D, 2013, IEEE INT CONF ROBOT, P1138, DOI 10.1109/ICRA.2013.6630715
   Ivanov A, 2021, IOP C SERIES MAT SCI, V1159
   Janai J, 2017, PROC CVPR IEEE, P1406, DOI 10.1109/CVPR.2017.154
   Jullien JM, 2009, ICALT: 2009 IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, P509, DOI 10.1109/ICALT.2009.24
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kaur P, 2021, ARXIV PREPRINT ARXIV
   Ko NY, 1998, 1998 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - PROCEEDINGS, VOLS 1-3, P1615, DOI 10.1109/IROS.1998.724829
   Koenig N., 2004, INT ROB SYST 2004 IR, V3, P2149, DOI [DOI 10.1109/IROS.2004.1389727, DOI 10.1109/IR0S.2004.1389727]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kurniawati H., 2008, ROBOTICS SCI SYSTEMS, V2008, DOI DOI 10.15607/RSS.2008.IV.009
   Lattarulo R, 2017, IFAC PAPERSONLINE, V50, P258, DOI 10.1016/j.ifacol.2017.08.043
   Levinson J, 2011, IEEE INT VEH SYM, P163, DOI 10.1109/IVS.2011.5940562
   Liu R, 2020, J NAVIGATION, V73, P324, DOI 10.1017/S0373463319000638
   López J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020449
   Matthaeia R., 2015, Autonomous Driving: Technical, Legal and Social Aspects
   Merat N, 2014, TRANSPORT RES F-TRAF, V27, P274, DOI 10.1016/j.trf.2014.09.005
   Merkel D., 2014, LINUX J, V2014, P2, DOI DOI 10.5555/2600239.2600241
   Michal DS, 2011, PROCEEDINGS OF THE 49TH ANNUAL ASSOCIATION FOR COMPUTING MACHINERY SOUTHEAST CONFERENCE (ACMSE '11), P60
   Montemerlo M, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2436
   Murciego E, 2018, WORKSH PHYS AG, P257
   Najm W. G., 2007, Pre-crash scenario typology for crash avoidance research
   Paden B, 2016, IEEE T INTELL VEHICL, V1, P33, DOI 10.1109/TIV.2016.2578706
   Park J., 2020, ARXIV200109683
   Quigley M, 2009, IEEE INT CONF ROBOT, P3604
   Rajamani R, 2012, MECH ENG SER, P1, DOI 10.1007/978-1-4614-1433-9_1
   Raju VM., 2019, 2019 IEEE 5th International Conference for Convergence in Technology (I2CT), P1
   Robotics C, 2015, V REP US MAN
   Rong GD, 2020, IEEE INT C INTELL TR, DOI 10.1109/itsc45102.2020.9294422
   Sanders A., 2016, INTRO UNREAL ENGINE
   Schoner, 2017, DRIV SIM C STUTTG
   Shah S, 2018, FIELD SERVICE ROBOTI, P621, DOI [10.1007/978-3-319-67361-5_40, DOI 10.1007/978-3-319-67361-5_40]
   Singh S., 2015, CRITICAL REASONS CRA
   Takács A, 2018, IEEE INT CONF INTELL, P185, DOI 10.1109/INES.2018.8523899
   Taxonomy S., 2016, Definitions for terms related to driving automation systems for on-road motor vehicles (j3016)
   Tian YC, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P303, DOI 10.1145/3180155.3180220
   Tideman M, 2013, IEEE INT VEH SYM, P713, DOI 10.1109/IVS.2013.6629551
   Urmson C, 2008, J FIELD ROBOT, V25, P425, DOI 10.1002/rob.20255
   van Ratingen M, 2016, CHIN J TRAUMATOL, V19, P63, DOI 10.1016/j.cjtee.2015.11.016
   Xu HZ, 2017, PROC CVPR IEEE, P3530, DOI 10.1109/CVPR.2017.376
   Yoon, 2020, ARXIV PREPRINT ARXIV
   Yurtsever E, 2020, IEEE ACCESS, V8, P58443, DOI 10.1109/ACCESS.2020.2983149
   Zhan W., 2019, arXiv preprint arXiv:1910.03088
NR 70
TC 6
Z9 6
U1 4
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 4213
EP 4240
DI 10.1007/s11042-021-11681-7
EA DEC 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000725909900003
OA hybrid
DA 2024-07-18
ER

PT J
AU Abeywardhana, DL
   Dangalle, CD
   Nugaliyadde, A
   Mallawarachchi, Y
AF Abeywardhana, D. L.
   Dangalle, C. D.
   Nugaliyadde, Anupiya
   Mallawarachchi, Yashas
TI An ultra-specific image dataset for automated insect identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automated insect identification; Limited data; Tiger beetles;
   Inter-class similarity
ID CONVOLUTIONAL NEURAL-NETWORKS; DEEP; RECOGNITION
AB Automated identification of insects is a tough task where many challenges like data limitation, imbalanced data count, and background noise needs to be overcome for better performance. This paper describes such an image dataset which consists of a limited, imbalanced number of images regarding six genera of subfamily Cicindelinae (tiger beetles) of order Coleoptera. The diversity of image collection is at a high level as the images were taken from different sources, angles and on different scales. Thus, the salient regions of the images have a large variation. Therefore, one of the main intentions in this process was to get an idea about the image dataset while comparing different unique patterns and features in images. The dataset was evaluated on different classification algorithms including deep learning models based on different approaches to provide a benchmark. The dynamic nature of the dataset poses a challenge to the image classification algorithms. However transfer learning models using softmax classifier performed well on the current dataset. The tiger beetle classification can be challenging even to a trained human eye, therefore, this dataset opens a new avenue for the classification algorithms to develop, to identify features which human eyes have not identified.
C1 [Abeywardhana, D. L.; Dangalle, C. D.] Univ Colombo, Colombo, Sri Lanka.
   [Nugaliyadde, Anupiya] Murdoch Univ, Perth, WA, Australia.
   [Mallawarachchi, Yashas] Sri Lanka Inst Informat Technol, Malabe, Sri Lanka.
C3 University of Colombo; Murdoch University; Sri Lanka Institute of
   Information Technology (SLIIT)
RP Abeywardhana, DL (corresponding author), Univ Colombo, Colombo, Sri Lanka.
EM lakminiab@stu.cmb.ac.lk
OI Abeywardhana, Lakmini/0000-0001-8971-9406
FU National Science Foundation of Sri Lanka [RG/2017/EB/01]
FX We would like to acknowledge Dr. Agasthya Thotagamuwa of Charles Sturt
   University, Australia for providing set of Tiger Beetle images required
   for the study. This work was funded by the National Science Foundation
   of Sri Lanka [Grant number RG/2017/EB/01].
CR Abeywardhana D.L., 2019, P ANN RES S U COLOMB, P78
   Abualigah L, 2021, ARCH COMPUT METHOD E, V28, P1397, DOI 10.1007/s11831-020-09420-6
   ACCIAVATTI R E, 1989, Annals of Carnegie Museum, V58, P77
   Ali H, 2017, COMPUT ELECTRON AGR, V138, P92, DOI 10.1016/j.compag.2017.04.008
   ALVAREZ AJ, 1993, WATER SCI TECHNOL, V27, P253, DOI 10.2166/wst.1993.0354
   Bloice M.D., 2017, ARXIV170804680, V2, P1, DOI DOI 10.21105/JOSS.00432
   Bouvrie J., 2006, Procedia Technology, P47, DOI DOI 10.1016/J.PROTCY.2014.09.007
   Caramazza P, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30390-0
   Cheng BW, 2018, LECT NOTES COMPUT SC, V11219, P473, DOI 10.1007/978-3-030-01267-0_28
   Dangalle CD., 2017, J BIOL NATURE, V7, P91
   Dangalle CD, 2018, J NATL SCI FOUND SRI, V46, P241, DOI 10.4038/jnsfsr.v46i3.8477
   Deng J, 2010, IMAGENET LARGE SCALE
   Englert B, 2011, CALTECH UCSD BIRDS 2, DOI [10.3182/20090902-3-US-2007.0059, DOI 10.3182/20090902-3-US-2007.0059]
   Evgeniou T., 2001, Machine learning and its applications. Advanced lectures, P249
   Fowler W. W., 1912, The Fauna of British India, Including Ceylon and Burma. Coleoptera. General Introduction and Cicindelidae and Paussidae
   Gebejes A., 2013, Databases, V9, P375
   Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3
   Google Colab, 2020, WELC COL COL GETT ST
   Grm K, 2018, IET BIOMETRICS, V7, P81, DOI 10.1049/iet-bmt.2017.0083
   Gutierrez A, 2019, J SENSORS, V2019, DOI 10.1155/2019/5219471
   Hamsher SE, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0073521
   Hansen OLP, 2020, ECOL EVOL, V10, P737, DOI 10.1002/ece3.5921
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Huh Minyoung, 2016, ABS160808614 CORR
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Ismail A., 2019, Malaysian Journal of Computing, V4, P225, DOI 10.24191/mjoc.v4i1.6095
   Jangblad M., 2018, OBJECT DETECTION INF
   Kamilaris A, 2018, J AGR SCI-CAMBRIDGE, V156, P312, DOI 10.1017/S0021859618000436
   Khosla A., 2011, P IEEE C COMP VIS PA, V2
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larios N, 2008, MACH VISION APPL, V19, P105, DOI 10.1007/s00138-007-0086-y
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lokanath M., 2017, IOP Conference Series: Materials Science and Engineering, V263
   MacLeod N., 2007, AUTOMATED TAXON IDEN, DOI [10.1201/9781420008074, DOI 10.1201/9781420008074]
   Mao W., 2012, New advances in intelligence and security informatics
   Marques ACR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0192011
   Mora C, 2011, PLOS BIOL, V9, DOI 10.1371/journal.pbio.1001127
   Naviaux R., 1991, PUBLICATIONS SOCI T, V60, P209, DOI [10.3406/linly.1991.10944, DOI 10.3406/LINLY.1991.10944]
   Olivas E. S., 2009, HDB RES MACHINE LEAR
   Pang HW, 2019, LECT NOTES COMPUT SC, V11901, P689, DOI 10.1007/978-3-030-34120-6_56
   Pass G, 1999, MULTIMEDIA SYST, V7, P234, DOI 10.1007/s005300050125
   PEARSON DL, 1988, ANNU REV ENTOMOL, V33, P123, DOI 10.1146/annurev.en.33.010188.001011
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Shu M., 2019, Creative Components, P14
   Sun J, 2016, IEEE ICCSS 2016 - 2016 3RD INTERNATIONAL CONFERENCE ON INFORMATIVE AND CYBERNETICS FOR COMPUTATIONAL SOCIAL SYSTEMS (ICCSS), P363, DOI 10.1109/ICCSS.2016.7586482
   Suthaharan S, 2016, INTEGR SER INFORM SY, V36, P1, DOI 10.1007/978-1-4899-7641-3
   Takefuji Y., EFFECTIVENESS ENSEMB
   Thotagamuwa A, 2018, THESIS U COLOMBO SRI
   Van Horn G, 2018, PROC CVPR IEEE, P8769, DOI 10.1109/CVPR.2018.00914
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Veronese E, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/867924
   Wang J, 2018, ENVIRON TECHNOL, V39, P3055, DOI 10.1080/09593330.2017.1371797
   Wang MW, 2019, IEEE ACCESS, V7, P61697, DOI 10.1109/ACCESS.2019.2915553
   Wu XP, 2019, PROC CVPR IEEE, P8779, DOI 10.1109/CVPR.2019.00899
   Yuan ZW, 2016, PROC SPIE, V10033, DOI 10.1117/12.2243849
   Zhu LQ, 2017, ORIENT INSECTS, V51, P79, DOI 10.1080/00305316.2016.1252805
NR 58
TC 5
Z9 5
U1 4
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3223
EP 3251
DI 10.1007/s11042-021-11693-3
EA NOV 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000716240000001
DA 2024-07-18
ER

PT J
AU Ayas, S
   Ayas, MS
AF Ayas, Selen
   Ayas, Mustafa Sinasi
TI A modified densenet approach with nearmiss for anomaly detection in
   industrial control systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; Cyber physical systems; DenseNet; NearMiss;
   Industrial applications; SWaT
AB The safety of Industrial Control Systems (ICSs) is of vital importance especially for critical infrastructures (CIs) that cause economic losses as well as adversely affecting human life when damaged. The cyber-attacks on CIs in the past years have revealed these negative effects. Moreover, the conclusion that ICSs are vulnerable to cyber-attacks and that prevention should be taken against possible new attacks. This paper presents a modified DenseNet approach with NearMiss (NM) undersampling technique to detect anomalies in a small-scale ICS commonly used to test anomaly detection approaches. The utilized small-scale ICS is known as Secure Water Treatment (SWaT) testbed. To deal with class imbalance problem of the SWaT dataset, NM undersampling technique is employed and samples in majority class are deleted. Several modified DenseNet architectures are evaluated using k-fold cross validation technique and comprehensive experiments are conducted on SWaT dataset. The performance of the proposed anomaly detection approach is compared to state-of-the-art studies. The experimental results show that the proposed modified DenseNet architecture has identified anomalies occured because of the injected attacks with less false positive rate and high precision score compared to previous studies. Moreover, the superiority of the proposed approach compared to the other state-of-the-art studies is that it detects all injected attack types with an improved precision, recall and F1-score rates of 1, 0.9997 and 0.9999, respectively.
C1 [Ayas, Selen] Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkey.
   [Ayas, Mustafa Sinasi] Karadeniz Tech Univ, Dept Elect & Elect Engn, TR-61080 Trabzon, Turkey.
C3 Karadeniz Technical University; Karadeniz Technical University
RP Ayas, S (corresponding author), Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkey.
EM selenguven@ktu.edu.tr
RI Ayas, Selen/AAJ-8030-2021; Ayas, Mustafa Sinasi/AAG-5553-2019
OI Ayas, Mustafa Sinasi/0000-0001-8113-4817; Ayas,
   Selen/0000-0002-8226-2359
CR Conti Juan Pablo, 2010, Engineering & Technology, V5, P46, DOI 10.1049/et.2010.0410
   Elnour M, 2020, IEEE ACCESS, V8, P36639, DOI 10.1109/ACCESS.2020.2975066
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Goh J, 2018, LECT NOTES COMPUT SC, V10242, P88, DOI 10.1007/978-3-319-71368-7_8
   Goh J, 2017, IEEE HI ASS SYS ENGR, P140, DOI 10.1109/HASE.2017.36
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Inoue J, 2017, INT CONF DAT MIN WOR, P1058, DOI 10.1109/ICDMW.2017.149
   Kang M, 2015, INFORM SCIENCES, V294, P423, DOI 10.1016/j.ins.2014.10.014
   Karnouskos S, 2011, IEEE IND ELEC, P4490
   Kim J, 2020, LECT NOTES COMPUT SC, V11980, P3, DOI 10.1007/978-3-030-42048-2_1
   Kim S, 2020, APPL SOFT COMPUT, V88, DOI 10.1016/j.asoc.2019.106017
   Kravchik M., 2019, ARXIV PREPRINT ARXIV
   Kravchik M, 2018, CPS-SPC'18: PROCEEDINGS OF THE 2018 WORKSHOP ON CYBER-PHYSICAL SYSTEMS SECURITY AND PRIVACY, P72, DOI 10.1145/3264888.3264896
   Kwon D, 2019, CLUSTER COMPUT, V22, P949, DOI 10.1007/s10586-017-1117-8
   Lee, 2016, ANAL CYBER ATTACK UK
   Li D., 2018, Anomaly detection with generative adversarial networks for multivariate time series
   Lin Q, 2018, PROCEEDINGS OF THE 2018 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIACCS'18), P525, DOI 10.1145/3196494.3196546
   Maglaras LA, 2018, ICT EXPRESS, V4, P42, DOI 10.1016/j.icte.2018.02.001
   Nader P, 2014, IEEE T IND INFORM, V10, P2308, DOI 10.1109/TII.2014.2330796
   Pang G, 2020, J COMPUT PHYS, V422, DOI 10.1016/j.jcp.2020.109760
   Poulsen Kevin., 2003, The Register, V20
   Priyanga S, 2020, IEEE T IND APPL, V56, P4394, DOI 10.1109/TIA.2020.2977872
   Raman MG, 2020, COMPUT SECUR, V99, DOI 10.1016/j.cose.2020.102055
   Richey D., 2010, 2010 ECRIME RES SUMM, P1, DOI DOI 10.1109/ECRIME.2010.5706699
   Selim GEI, 2021, MULTIMED TOOLS APPL, V80, P12619, DOI 10.1007/s11042-020-10354-1
   Slay J, 2008, INT FED INFO PROC, V253, P73, DOI 10.1007/978-0-387-75462-8_6
   Sullivan D, 2016, ADV INFORM SECUR, V63, P15, DOI 10.1007/978-3-319-32125-7_2
   Wei L, 2018, CHIN AUTOM CONGR, P2621, DOI 10.1109/CAC.2018.8623514
NR 29
TC 4
Z9 4
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22573
EP 22586
DI 10.1007/s11042-021-11618-0
EA OCT 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000708317700001
DA 2024-07-18
ER

PT J
AU Kang, SW
   Choi, US
   Cho, SJ
AF Kang, Sung Won
   Choi, Un Sook
   Cho, Sung Jin
TI Fast image encryption algorithm based on (<i>n</i>, <i>m</i>,
   <i>k</i>)-PCMLCA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fast image encryption; Image shuffling; Cellular automata; Programmable
   complemented MLCA; PRNG
ID OPERATION; SYSTEM
AB Cellular Automata (CA) can be implemented by hardware and processed in parallel unlike the conventional algorithm based on chaotic function. In this paper, we propose a fast encryption algorithm for color image using (n, m, k)-programmable complemented maximum length CA((n, m, k)-PCMLCA). This algorithm improves the speed of shuffling pixel positions in the color image encryption system. The encryption process of the proposed image encryption system consists of a substitution step and a shuffling step. In the substitution step, we design the (n, m, k)-PCMLCA which can generate nonlinear sequences whose lengths are longer than the lengths of sequences generated by complemented maximum length CA (C-MLCA), and use it as the key sequence generator. In the shuffling step, we improve the encryption/decryption speed by raising the domain processing the image to the row/column level rather than the pixel unit and processing the block unit using 1-D MLCA. With the advantage of these CA, we can improve the speed of encryption/decryption.
C1 [Kang, Sung Won] Pukyong Natl Univ, Dept Informat Secur, Busan, South Korea.
   [Choi, Un Sook] Tongmyong Univ, Dept Informat & Commun & Software Engn, Busan, South Korea.
   [Cho, Sung Jin] Pukyong Natl Univ, Dept Appl Math, Busan, South Korea.
C3 Pukyong National University; Tongmyong University; Pukyong National
   University
RP Choi, US (corresponding author), Tongmyong Univ, Dept Informat & Commun & Software Engn, Busan, South Korea.
EM choies@tu.ac.kr; jsm2371@hanmail.net
RI Kang, Sungwon/C-1765-2011
FU Tongmyong University [2018A046]
FX This paper is the revised and expanded version of a paper entitled "High
   Speed Color Image Encryption using Pixel Shuffling with 1-D MLCA
   presented at 2020 5th International Conference on Computer and
   Communication Systems(ICCCS), Shanghai, China, 15-18 May 2020. And this
   research was supported by the Tongmyong University Research Grants
   2018(2018A046).
CR Aboughalia RA, 2018, LIB INT C EL ENG TEC
   Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Bilan S., 2018, FORMATION METHODS MO, DOI [10.4018/978-1-5225-2773-2, DOI 10.4018/978-1-5225-2773-2]
   Cattell K, 1996, IEEE T COMPUT AID D, V15, P325, DOI 10.1109/43.489103
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chen CS, 2013, J SYST SOFTWARE, V86, P100, DOI 10.1016/j.jss.2012.07.020
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Cho SJ, 2007, IEEE T COMPUT AID D, V26, P1720, DOI 10.1109/TCAD.2007.895784
   Choi US, 2020, MULTIMED TOOLS APPL, V79, P22825, DOI 10.1007/s11042-020-09033-y
   Choi US, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2019), P272, DOI [10.1109/ccoms.2019.8821691, 10.1109/CCOMS.2019.8821691]
   Daemen Joan., 2002, The Design of Rijndael: AES - The Advanced Encryption Standard, DOI [10.1007/978-3-662-04722-4, DOI 10.1007/978-3-662-04722-4]
   DAS AK, 1993, IEEE T COMPUT, V42, P340, DOI 10.1109/12.210176
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Essaid M, 2018, PROCEDIA COMPUT SCI, V127, P539, DOI 10.1016/j.procs.2018.01.153
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gao SD, 2019, J REAL-TIME IMAGE PR, V16, P741, DOI 10.1007/s11554-019-00860-3
   Ghadirli HM, 2019, SIGNAL PROCESS, V164, P163, DOI 10.1016/j.sigpro.2019.06.010
   Guan SU, 2004, IEEE T COMPUT AID D, V23, P1095, DOI 10.1109/TCAD.2004.829808
   Hasheminejad A, 2019, OPTIK, V184, P205, DOI 10.1016/j.ijleo.2019.03.065
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Huang LQ, 2019, OPT LASER ENG, V115, P7, DOI 10.1016/j.optlaseng.2018.11.015
   Jeong HS, 2018, INT CONF UBIQ FUTUR, P795, DOI 10.1109/ICUFN.2018.8437025
   Jha DP, 2016, 2016 1ST INTERNATIONAL CONFERENCE ON INNOVATION AND CHALLENGES IN CYBER SECURITY (ICICCS 2016), P86, DOI 10.1109/ICICCS.2016.7542316
   Kohli R, 2013, INT J ADV RES COMPUT, V3
   Koppu S, 2017, MOD SIMUL ENG, V2017, DOI 10.1155/2017/7470204
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Nandi S, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICCICCT), P521, DOI 10.1109/ICCICCT.2014.6993017
   Patro KAK, 2018, J INF SECUR APPL, V40, P111, DOI 10.1016/j.jisa.2018.03.006
   Shuiping Zhang, 2012, Journal of Multimedia, V7, P66, DOI 10.4304/jmm.7.1.66-73
   Somaraj S, 2014, INT J COMP APP, V104, P30, DOI [10.1016/j.jss.2012.07.020, DOI 10.1016/J.JSS.2012.07.020]
   Tang ZJ, 2015, MULTIMED TOOLS APPL, V74, P5429, DOI 10.1007/s11042-014-1861-1
   Wang Y, 2018, NEUROCOMPUTING, V275, P1318, DOI 10.1016/j.neucom.2017.09.068
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Zhang W, 2015, OPT COMMUN, V338, P199, DOI 10.1016/j.optcom.2014.10.044
   Zhang XP, 2014, NONLINEAR DYNAM, V75, P319, DOI 10.1007/s11071-013-1068-4
   Zhang Y, 2019, IETE J RES, V65, P4, DOI 10.1080/03772063.2017.1400406
   Zhu CX, 2018, IEEE ACCESS, V6, P18759, DOI 10.1109/ACCESS.2018.2817600
NR 40
TC 12
Z9 12
U1 3
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 1209
EP 1235
DI 10.1007/s11042-021-11424-8
EA SEP 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000701004100002
DA 2024-07-18
ER

PT J
AU Islam, MS
   Bakhat, K
   Khan, R
   Islam, MM
   Ye, ZF
AF Islam, M. Shujah
   Bakhat, Khush
   Khan, Rashid
   Islam, M. Mattah
   Ye, ZhongFu
TI Single and two-person(s) pose estimation based on R-WAA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pose estimation; Human action recognition; R-WAA; Remarkable joint;
   K-nearest neighbor classifier
ID HUMAN ACTION RECOGNITION; MOTION
AB Human pose estimation methods have difficulties predicting the correct pose for persons due to challenges in scale variation. Existing works in this domain mainly focus on single-person pose estimation. To counter this challenge we have developed a system that can efficiently estimate both one and two individual poses. We termed remarkable joint based, Waveform, Angle, and Alpha characteristics, as R-WAA. R-WAA is a novel up-bottom human pose estimation method developed using two-dimensional body skeletal joint points. They are capturing all required spatial information using waveform characteristics, angle characteristics, and alpha characteristics. All pose estimator characteristics are developed using a remarkable joint, which is the origin of all poses. The proposed algorithm is evaluated for one and two individuals databases: KARD- Kinect Activity Recognition Dataset and SBU Kinect Interaction Dataset. The results of experiments validate that R-WAA outperforms state-of-the-art approaches.
C1 [Islam, M. Shujah; Khan, Rashid; Ye, ZhongFu] Univ Sci & Technol China, Hefei, Peoples R China.
   [Bakhat, Khush] Air Univ, Islamabad, Pakistan.
   [Islam, M. Mattah] Natl Univ Comp & Emerging Sci, Islamabad, Pakistan.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Air University Islamabad
RP Ye, ZF (corresponding author), Univ Sci & Technol China, Hefei, Peoples R China.
EM mshujahislam@mail.ustc.edu.cn; khush.bakhatawar@gmail.com;
   rashidkhan@mail.ustc.edu.cn; m.mattahislamsameem@gmail.com;
   yezf@ustc.edu.cn
RI khan, Rashid/HSF-9463-2023; KHAN, RASHID MUMTAZ/HHZ-3812-2022
OI khan, Rashid/0000-0002-2410-044X; KHAN, RASHID
   MUMTAZ/0000-0001-6097-098X; Sameem, M Shujah Islam/0000-0003-3768-6045
FU Fundamental Research Funds for the Central Universities [WK2350000002]
FX This work is supported by the Fundamental Research Funds for the Central
   Universities (Grant no. WK2350000002).
CR Aly S, 2019, MULTIMED TOOLS APPL, V78, P24923, DOI 10.1007/s11042-019-7674-5
   Ashwini K., 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P444, DOI 10.1109/ICCSP48568.2020.9182132
   Aydin R, 2014, IN C IND ENG ENG MAN, P1, DOI 10.1109/IEEM.2014.7058588
   Baradel F., 2017, Pose-conditioned Spatio-Temporal Attention for Human Action Recognition
   Bulbul MF, 2019, J INTELL FUZZY SYST, V36, P3385, DOI 10.3233/JIFS-181136
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen WM, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12050744
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Cheng BW, 2020, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR42600.2020.00543
   Cippitelli E, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/4351435
   Devanne M, 2015, IEEE T CYBERNETICS, V45, P1340, DOI 10.1109/TCYB.2014.2350774
   Du Y, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P579, DOI 10.1109/ACPR.2015.7486569
   Gaglio S, 2015, IEEE T HUM-MACH SYST, V45, P586, DOI 10.1109/THMS.2014.2377111
   Gori I, 2016, IEEE ROBOT AUTOM LET, V1, P593, DOI 10.1109/LRA.2016.2525002
   Gou J., 2012, J. Inf. Comput. Sci, V9, P1429
   Gu Y, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.10.004
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hu T, 2019, MULTIMED TOOLS APPL, V78, P28515, DOI 10.1007/s11042-017-5496-x
   Huang ZW, 2017, PROC CVPR IEEE, P1243, DOI 10.1109/CVPR.2017.137
   Islam MS, 2021, APPL INTELL, V51, P6001, DOI 10.1007/s10489-020-02176-3
   Islam MS, 2019, IET IMAGE PROCESS
   Jalal A, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22080817
   Janbu N., 1973, Slope Stability Computations
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Ke QH, 2017, IEEE SIGNAL PROC LET, V24, P731, DOI 10.1109/LSP.2017.2690339
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   Kendall A, 2017, 31 ANN C NEURAL INFO, V30
   Khowaja SA, 2020, INT J COMPUT VISION, V128, P393, DOI 10.1007/s11263-019-01248-3
   Kreiss S, 2019, PROC CVPR IEEE, P11969, DOI 10.1109/CVPR.2019.01225
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   Li C.-L., 2018, ARXIV PREPRINT ARXIV
   Liao YH, 2002, COMPUT SECUR, V21, P439, DOI 10.1016/S0167-4048(02)00514-X
   Liu J, 2017, PROC CVPR IEEE, P3671, DOI 10.1109/CVPR.2017.391
   Ma M, 2018, PATTERN RECOGN, V76, P506, DOI 10.1016/j.patcog.2017.11.026
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Newell A, 2017, ADV NEUR IN, V30
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1302
   Papadopoulos K, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19163503
   Papadopoulos K, 2017, IEEE IMAGE PROC, P1807, DOI 10.1109/ICIP.2017.8296593
   Papandreou G, 2018, LECT NOTES COMPUT SC, V11218, P282, DOI 10.1007/978-3-030-01264-9_17
   Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395
   Peterson L.E., 2009, Scholarpedia, V4, P1883, DOI [DOI 10.4249/SCHOLARPEDIA.1883, 10.4249/scholarpedia.1883]
   PROFFITT DR, 1989, J EXP PSYCHOL HUMAN, V15, P384, DOI 10.1037/0096-1523.15.2.384
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Suma EA, 2011, P IEEE VIRT REAL ANN, P247, DOI 10.1109/VR.2011.5759491
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Sun X, 2018, LECT NOTES COMPUT SC, V11210, P536, DOI 10.1007/978-3-030-01231-1_33
   Villaroman N., 2011, Proceedings of the conference on Information technology education, P227
   Wang JH, 2020, IEEE T CYBERNETICS, V50, P2971, DOI 10.1109/TCYB.2019.2891265
   Wang YS, 2020, INCLUSIVE PHYSICAL EDUCATION AROUND THE WORLD: ORIGINS, CULTURES, PRACTICES, P98
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   YOUDAS JW, 1992, PHYS THER, V72, P770, DOI 10.1093/ptj/72.11.770
   Yun K., 2012, 2012 IEEE COMP SOC C, P28, DOI DOI 10.1109/CVPRW.2012.6239234
NR 53
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 681
EP 694
DI 10.1007/s11042-021-11374-1
EA SEP 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000695787500002
DA 2024-07-18
ER

PT J
AU Alirr, OI
AF Alirr, Omar Ibrahim
TI Automatic deep learning system for COVID-19 infection quantification in
   chest CT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19 infection; Deep learning; Segmentation; Chest CT
ID NET
AB The paper proposes an automatic deep learning system for COVID-19 infection areas segmentation in chest CT scans. CT imaging proved its ability to detect the COVID-19 disease even for asymptotic patients, which make it a trustworthy alternative for PCR. Coronavirus disease spread globally and PCR screening is the adopted diagnostic testing method for COVID-19 detection. However, PCR is criticized due its low sensitivity ratios, also, it is time-consuming and manual complicated process. The proposed framework includes different steps; it starts to prepare the region of interest by segmenting the lung organ, which then undergoes edge enhancing diffusion filtering (EED) to improve the infection areas contrast and intensity homogeneity. The proposed FCN is implemented using U-net architecture with modified residual block to include concatenation skip connection. The block improves the learning of gradient values by forwarding the infection area features through the network. The proposed system is evaluated using different measures and achieved dice overlapping score of 0.961 and 0.780 for lung and infection areas segmentation, respectively. The proposed system is trained and tested using many 2D CT slices extracted from diverse datasets from different sources, which demonstrate the system generalization and effectiveness. The use of more datasets from different sources helps to enhance the system accuracy and generalization, which can be accomplished based on the data availability in in the future.
C1 [Alirr, Omar Ibrahim] Amer Univ Middle East, Coll Engn & Technol, Egaila, Kuwait.
C3 American University of the Middle East
RP Alirr, OI (corresponding author), Amer Univ Middle East, Coll Engn & Technol, Egaila, Kuwait.
EM omar.alirr@aum.edu.kw
RI ALIRR, OMAR/AAH-2286-2020; Alirr, Omar/KIK-2764-2024
OI ALIRR, OMAR/0000-0002-4978-5350; Alirr, Omar/0000-0002-4978-5350
CR Ai T, 2020, RADIOLOGY, V296, pE32, DOI 10.1148/radiol.2020200642
   Athanasios AV, 2021, THE 14TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS, PETRA 2021, P404, DOI 10.1145/3453892.3461322
   Bullock J, 2020, J ARTIF INTELL RES, V69, P807
   Chaganti S, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200048
   Ding X, 2020, EUR J RADIOL, V127, DOI 10.1016/j.ejrad.2020.109009
   Fan DP, 2020, IEEE T MED IMAGING, V39, P2626, DOI 10.1109/TMI.2020.2996645
   Fang YC, 2020, RADIOLOGY, V296, pE115, DOI 10.1148/radiol.2020200432
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Li L, 2020, RADIOLOGY, V296, pE65, DOI 10.1148/radiol.2020200905
   Li W., 2015, J COMPUT COMMUN, V3, P146, DOI DOI 10.4236/JCC.2015.311023
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma J., 2020, Towards efficient covid-19 ct annotation: A benchmark for lung and infection segmentation
   Mendrik AM, 2009, IEEE T MED IMAGING, V28, P1585, DOI 10.1109/TMI.2009.2022368
   Meng H, 2020, J INFECTION, V81, pE33, DOI 10.1016/j.jinf.2020.04.004
   Muller D., 2020, ARXIV PREPRINT ARXIV
   Ng MY, 2020, RADIOL-CARDIOTHORAC, V2, DOI 10.1148/ryct.2020200034
   Qiu Y., 2020, ARXIV PREPRINT ARXIV
   Rodriguez-Morales Alfonso J, 2020, Travel Med Infect Dis, V34, P101623, DOI 10.1016/j.tmaid.2020.101623
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rubin GD, 2020, RADIOLOGY, V296, P172, DOI [10.1016/j.chest.2020.04.003, 10.1148/radiol.2020201365]
   Shi F, 2021, IEEE REV BIOMED ENG, V14, P4, DOI 10.1109/RBME.2020.2987975
   Sohrabi C, 2020, INT J SURG, V76, P71, DOI 10.1016/j.ijsu.2020.02.034
   Song Y, 2020, GUT, V69, P1143, DOI 10.1136/gutjnl-2020-320891
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   Xu XW, 2020, ENGINEERING-PRC, V6, P1122, DOI 10.1016/j.eng.2020.04.010
   You Z, 2020, ARXIV PREPRINT ARXIV
   Zheng CM, 2021, IEEE T MULTIMEDIA, V23, P2520, DOI 10.1109/TMM.2020.3013398
NR 30
TC 7
Z9 7
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 527
EP 541
DI 10.1007/s11042-021-11299-9
EA SEP 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000695454400005
PM 34539221
OA Green Submitted, Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Sengül, G
   Ozcelik, E
   Misra, S
   Damasevicius, R
   Maskeliünas, R
AF Sengul, Gokhan
   Ozcelik, Erol
   Misra, Sanjay
   Damasevicius, Robertas
   Maskeliunas, Rytis
TI Fusion of smartphone sensor data for classification of daily user
   activities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human activity recognition; Wearable intelligence; Feature fusion
ID ACTIVITY RECOGNITION; PATTERN-RECOGNITION
AB New mobile applications need to estimate user activities by using sensor data provided by smart wearable devices and deliver context-aware solutions to users living in smart environments. We propose a novel hybrid data fusion method to estimate three types of daily user activities (being in a meeting, walking, and driving with a motorized vehicle) using the accelerometer and gyroscope data acquired from a smart watch using a mobile phone. The approach is based on the matrix time series method for feature fusion, and the modified Better-than-the-Best Fusion (BB-Fus) method with a stochastic gradient descent algorithm for construction of optimal decision trees for classification. For the estimation of user activities, we adopted a statistical pattern recognition approach and used the k-Nearest Neighbor (kNN) and Support Vector Machine (SVM) classifiers. We acquired and used our own dataset of 354 min of data from 20 subjects for this study. We report a classification performance of 98.32 % for SVM and 97.42 % for kNN.
C1 [Sengul, Gokhan; Misra, Sanjay] Atilim Univ, Dept Comp Engn, AnkaraKizilcasar Mah, Incek, Turkey.
   [Ozcelik, Erol] Cankaya Univ, Yukariyurtcu Mahallesi,Mimar Sinan Caddesi 4, TR-06790 Ankara, Turkey.
   [Misra, Sanjay] Covenant Univ, Dept Elect & Informat Engn, Ota 0123, Nigeria.
   [Damasevicius, Robertas] Silesian Tech Univ, Fac Appl Math, Kaszubska 23, PL-44100 Gliwice, Poland.
   [Maskeliunas, Rytis] Vytautas Magnus Univ, Dept Appl Informat, Vileikos 8, Kaunas, Lithuania.
C3 Atilim University; Cankaya University; Covenant University; Silesian
   University of Technology; Vytautas Magnus University
RP Damasevicius, R (corresponding author), Silesian Tech Univ, Fac Appl Math, Kaszubska 23, PL-44100 Gliwice, Poland.
EM gokhan.sengul@atilim.edu.tr; ozcelik@cankaya.edu.tr;
   sanjay.misra@covenantuniversity.edu.ng; robertas.damasevicius@polsl.pl;
   rytis.maskeliunas@vdu.lt
RI Maskeliunas, Rytis/J-7173-2017; Damaševičius, Robertas/E-1387-2017;
   Misra, Sanjay/K-2203-2014; Sengul, Gokhan/G-8213-2016; Şengül,
   Gökhan/AAA-2788-2022
OI Maskeliunas, Rytis/0000-0002-2809-2213; Damaševičius,
   Robertas/0000-0001-9990-1084; Misra, Sanjay/0000-0002-3556-9331; Şengül,
   Gökhan/0000-0003-2273-4411
CR Abd Rahim KNK, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124132
   Ahmed N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010317
   Alirezaie M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071586
   Ballesteros J, 2012, C LOCAL COMPUT NETW, P626, DOI 10.1109/LCN.2012.6423684
   Bayat A, 2014, PROCEDIA COMPUT SCI, V34, P450, DOI 10.1016/j.procs.2014.07.009
   Bikulciene L, 2009, ITI, P41, DOI 10.1109/ITI.2009.5196052
   Bragança H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071856
   Chen ZH, 2019, IEEE T IND INFORM, V15, P2691, DOI 10.1109/TII.2018.2869843
   Chen ZH, 2017, IEEE T IND INFORM, V13, P3070, DOI 10.1109/TII.2017.2712746
   Cvetkovic B, 2018, INFORM FUSION, V43, P77, DOI 10.1016/j.inffus.2017.05.004
   Damasevicius R, 2016, SYMMETRY-BASEL, V8, DOI 10.3390/sym8100100
   Damasevicius R, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/4073584
   De Paola A, 2016, LECT NOTES COMPUT SC, V10037, P377, DOI 10.1007/978-3-319-49130-1_28
   Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019
   Ei-Sheimy N, 2008, IEEE T INSTRUM MEAS, V57, P140, DOI 10.1109/TIM.2007.908635
   Ferrari A, 2020, IEEE ACCESS, V8, P32066, DOI 10.1109/ACCESS.2020.2973425
   Garcia-Ceja E, 2018, INFORM FUSION, V40, P45, DOI 10.1016/j.inffus.2017.06.004
   Garcia-Gonzalez D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082200
   Gjoreski M, 2020, INFORM FUSION, V62, P47, DOI 10.1016/j.inffus.2020.04.004
   Gravina R, 2017, INFORM FUSION, V35, P68, DOI 10.1016/j.inffus.2016.09.005
   Hassan MM, 2018, FUTURE GENER COMP SY, V81, P307, DOI 10.1016/j.future.2017.11.029
   He Jian, 2017, Sensors (Basel), V17, DOI 10.3390/s17061393
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jain A, 2018, IEEE SENS J, V18, P1169, DOI 10.1109/JSEN.2017.2782492
   Jansi R, 2019, MULTIMED TOOLS APPL, V78, P11027, DOI 10.1007/s11042-018-6662-5
   Kau LJ, 2015, IEEE J BIOMED HEALTH, V19, P44, DOI 10.1109/JBHI.2014.2328593
   Khan A. M. A., 2010, P 5 INT C FUT INF TE, P1, DOI DOI 10.1109/FUTURETECH.2010.5482729
   Kos A, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16040477
   Lauraitis A, 2019, IEEE J BIOMED HEALTH, V23, P1865, DOI 10.1109/JBHI.2019.2891729
   Li YT, 2020, ACM T SENSOR NETWORK, V16, DOI 10.1145/3397179
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P49, DOI 10.1109/MIC.2020.2971447
   Li YT, 2019, IEEE INTERNET THINGS, V6, P628, DOI 10.1109/JIOT.2018.2851185
   Liang YJ, 2014, MOBILE NETW APPL, V19, P303, DOI 10.1007/s11036-013-0448-9
   Lima WS, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143213
   Martín H, 2013, PERS UBIQUIT COMPUT, V17, P675, DOI 10.1007/s00779-012-0515-4
   Najjar N, 2015, PROC SPIE, V9498, DOI 10.1117/12.2177123
   Nguyen ND, 2017, PHYSIOL MEAS, V38, pL10, DOI 10.1088/1361-6579/aa7c10
   Noori FM, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3377882
   Norouzi M., 2015, ADV NEURAL INFORM PR, V28, P1729
   Nweke HF, 2019, INFORM FUSION, V46, P147, DOI 10.1016/j.inffus.2018.06.002
   Ofstad Andrew., 2008, Proceedings of the First ACM International Workshop on Mobile Entity Localization and Tracking in GPS-less Environments, MELT '08, P13
   Pires IM, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030509
   Qi W, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19173731
   Quaid MAK, 2020, MULTIMED TOOLS APPL, V79, P6061, DOI 10.1007/s11042-019-08463-7
   Reddy S, 2010, ACM T SENSOR NETWORK, V6, DOI 10.1145/1689239.1689243
   Shafique MA, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16050716
   Shdefat AY., 2018, Prim. Health Care Open Access, DOI [10.4172/2167-1079.1000289, DOI 10.4172/2167-1079.1000289]
   Shoaib M, 2015, SENSORS-BASEL, V15, P2059, DOI 10.3390/s150102059
   Sun L, 2010, LECT NOTES COMPUT SC, V6406, P548, DOI 10.1007/978-3-642-16355-5_42
   Talari S, 2017, ENERGIES, V10, DOI 10.3390/en10040421
   Wan SH, 2020, MOBILE NETW APPL, V25, P743, DOI 10.1007/s11036-019-01445-x
   Weiss J., 2012, P 26 WORKSH AAAI C A, P98
   Yang J., 2009, Proceedings of the 1st international workshop on Interactive multimedia for consumer electronics, P1
   Zheng Y, 2010, ACM T WEB, V4, DOI 10.1145/1658373.1658374
NR 54
TC 15
Z9 15
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 24
BP 33527
EP 33546
DI 10.1007/s11042-021-11105-6
EA AUG 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WJ3HO
UT WOS:000686840500002
OA hybrid
DA 2024-07-18
ER

PT J
AU Laxmanika
   Singh, PK
AF Laxmanika
   Singh, Pradeep Kumar
TI Robust and imperceptible image watermarking technique based on SVD, DCT,
   BEMD and PSO in wavelet domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; DWT; BEMD; Embedding and extraction; DCT; SVD; PSO;
   Watermarking
ID HYBRID TECHNIQUE; DWT; SCHEME; BLIND
AB This article introduces a robust image watermarking primarily founded on DWT (discrete wavelet transform), BEMD (bi-dimensional empirical mode decomposition), DCT (discrete cosine transform), PSO (particle swarm optimization), and SVD (singular value decomposition). During the process of embedding, 2nd level DWT is used to decompose the cover image into sub-bands. DWT is also used for the decomposition of images for watermarking. Further, BEMD decomposition runs to implement on the selected band of DWT. For optimization, PSO is used for complex and multidimensional searches. Further DCT as well as SVD applied to the selected band. The embedding and scaling factors are embedded with the help of a security key. Further, this method is followed by using the inverse of ISVD, IDCT, IDWT, and IBEMD. The Watermark image is extracted by the extraction process. Experimental results show that the suggested technique is robust compared to several geometrical and non-geometrical attacks. Therefore, this proposed technique provides better visible quality and robustness against numerous attacks like salt and pepper, Gaussian filter, rotation, median filter, speckle, gamma correction, scaling, and shearing for gray scale images and provides the watermarked image with good quality.
C1 [Laxmanika] Jaypee Univ Informat Technol JUIT, Dept Comp Sci & Engn, Solan, HP, India.
   [Singh, Pradeep Kumar] KET Grp Inst, Dept Comp Sci, Ghaziabad, UP, India.
C3 Jaypee University of Information Technology
RP Laxmanika (corresponding author), Jaypee Univ Informat Technol JUIT, Dept Comp Sci & Engn, Solan, HP, India.
EM laxmanika.singh81@gmail.com; pradeep_84cs@yahoo.com
RI Singh, Pradeep Kumar/M-4363-2016
OI Singh, Pradeep Kumar/0000-0002-7676-9014
CR Aarab, 2009, 5 INT C SCI EL TECH, P22
   Abbas NH, 2018, MULTIMED TOOLS APPL, V77, P24593, DOI 10.1007/s11042-017-5488-x
   Agrwal SL, 2016, INT CONF RELI INFO, P283, DOI 10.1109/ICRITO.2016.7784966
   [Anonymous], 2016, AL SAD INT C MULT IT, DOI DOI 10.1109/PIMRC.2016.7794827
   Ansari IA, 2019, INT J SYST ASSUR ENG
   Ansari IA, 2016, ADV INTELL SYST COMP, V437, P411, DOI 10.1007/978-981-10-0451-3_38
   Ansari IA, 2017, PATTERN RECOGN LETT, V94, P228, DOI 10.1016/j.patrec.2016.12.010
   Araghi TK, 2019, FUTURE GENER COMP SY, V101, P1223, DOI 10.1016/j.future.2019.07.064
   Chang BM, 2016, ENG APPL ARTIF INTEL, V52, P96, DOI 10.1016/j.engappai.2016.02.005
   Chung KL, 2007, APPL MATH COMPUT, V188, P54, DOI 10.1016/j.amc.2006.09.117
   Deng MH, 2011, ADV MATER RES-SWITZ, V204-210, P627, DOI 10.4028/www.scientific.net/AMR.204-210.627
   Deng MH, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P36, DOI 10.1109/ICCCS.2009.19
   Elbasi E., 2015, INT ARAB J INFORM TE, V12
   Hu WC, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.3.033005
   Jha CK, 2021, IRBM, V42, DOI 10.1016/j.irbm.2020.05.008
   Kamble S., 2012, INT J INF TECHNOLO K, V5, P101
   Kang XB, 2018, MULTIMED TOOLS APPL, V77, P13197, DOI 10.1007/s11042-017-4941-1
   Kang XB, 2020, SOFT COMPUT, V24, P10561, DOI 10.1007/s00500-019-04563-6
   Khan A, 2017, 2017 INTERNATIONAL CONFERENCE ON RECENT INNOVATIONS IN SIGNAL PROCESSING AND EMBEDDED SYSTEMS (RISE), P212, DOI 10.1109/RISE.2017.8378156
   Khare P, 2021, MULTIDIM SYST SIGN P, V32, P131, DOI 10.1007/s11045-020-00732-1
   Khedr WM, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE (CSCI 2019), P595, DOI 10.1109/CSCI49370.2019.00112
   Kumar C, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4912
   Laxmanika, 2020, LECT NOTES ELECTR EN, V605, P1041, DOI 10.1007/978-3-030-30577-2_92
   Lee Y, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P583, DOI 10.1109/ISM.2009.48
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Liu JX, 2019, IEEE ACCESS, V7, P80849, DOI 10.1109/ACCESS.2019.2915596
   Naik K, 2018, MULTIMED TOOLS APPL, V77, P13721, DOI 10.1007/s11042-017-4986-1
   Rani A, 2015, PROCEDIA COMPUT SCI, V70, P603, DOI 10.1016/j.procs.2015.10.046
   Rao VSV., 2012, IEEE STUD C EL EL CO, P1, DOI DOI 10.1109/SCEECS.2012.6184795
   Ravi P, 2019, NOVEL PSO ALGORITHM, V8, P33
   Savakar DG, 2019, ARAB J SCI ENG, V44, P3995, DOI 10.1007/s13369-019-03751-8
   Saxena N, 2018, Adv Intell Syst Comput, P343, DOI DOI 10.1007/978-981-10-3773-3_34
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Singh J., 2018, INT J INFORM SYSTEMS
   Srivastava A, 2015, 6TH INTERNATIONAL CONFERENCE ON COMPUTER & COMMUNICATION TECHNOLOGY (ICCCT-2015), P244, DOI 10.1145/2818567.2818651
   Su Q., 2020, OPTIK
   Sudibyo U, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, COMPUTER, AND ELECTRICAL ENGINEERING (ICITACEE), P208, DOI 10.1109/ICITACEE.2017.8257704
   Taghia J, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 5, PROCEEDINGS, P674, DOI 10.1109/CISP.2008.717
   Wang T, 2017, IEEE INT C COMPUT, P724, DOI 10.1109/CSE-EUC.2017.141
   Wang XC, 2020, VISUAL COMPUT, V36, P2201, DOI 10.1007/s00371-020-01909-2
   Yadav Neha, 2020, 2020 6th International Conference on Signal Processing and Communication (ICSC), P85, DOI 10.1109/ICSC48311.2020.9182716
   Yuan Z., 2020, VISUAL COMPUT, P1
   Yuqi He, 2018, 2018 2nd IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC). Proceedings, P1214, DOI 10.1109/IMCEC.2018.8469626
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang LN, 2019, MULTIMED TOOLS APPL, V78, P28003, DOI 10.1007/s11042-019-07902-9
   Zhong X., 2020, ARXIV PREPRINT ARXIV
NR 47
TC 9
Z9 10
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22001
EP 22026
DI 10.1007/s11042-021-11246-8
EA AUG 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000680314900001
DA 2024-07-18
ER

PT J
AU Wang, S
   Lv, LT
   Yang, HC
   Lu, D
AF Wang, Sheng
   Lv, Lin-Tao
   Yang, Hong-Cai
   Lu, Di
TI Zernike-CNNs for image preprocessing and classification in printed
   register detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Printed defective detection; Register measurement; Edge detection;
   Zernike moments (ZM; ZMs); Convolutional neural networks (CNN; CNNs);
   Pattern recognition and classification
ID CONVOLUTIONAL NEURAL-NETWORKS; FAST COMPUTATION; MACHINE
AB In the register detection of printing field, a new approach based on Zernike-CNNs is proposed. The edge feature of image is extracted by Zernike moments (ZMs), and a recursive algorithm of ZMs called Kintner method is derived. An improved convolutional neural networks (CNNs) are investigated to improve the accuracy of classification. Based on the classic convolutional neural network (CNN), the improved CNNs adopt parallel CNN to enhance local features, and adopt auxiliary classification part to modify classification layer weights. A printed image is trained with 7 x 400 samples and tested with 7 x 100 samples, and then the method in this paper is compared with other methods. In image processing, Zernike is compared with Sobel method, Laplacian of Gaussian (LoG) method, Smallest Univalue Segment Assimilating Nucleus (SUSAN) method, Finite Impusle Response (FIR) method, Multi-scale Morphological Gradient (MMG) method. In image classification, improved CNNs are compared with classical CNN. The experimental results show that Zernike-CNNs have the best performance, the mean square error (MSE) of the training samples reaches 0.0143, and the detection accuracy of training samples and test samples reached 91.43% and 94.85% respectively. The experiments reveal that Zernike-CNNs are a feasible approach for register detection.
C1 [Wang, Sheng; Lv, Lin-Tao; Yang, Hong-Cai] Xijing Univ, Xian 710123, Shaanxi, Peoples R China.
   [Lu, Di] Xian Univ Architecture & Technol, Xian 710055, Shaanxi, Peoples R China.
C3 Xijing University; Xi'an University of Architecture & Technology
RP Wang, S (corresponding author), Xijing Univ, Xian 710123, Shaanxi, Peoples R China.
EM ws5000@sina.com
RI Sheng, Wang/AAV-7706-2021; Sheng, Wang/JPC-7385-2023
OI Sheng, WANG/0000-0002-6458-803X
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Aggarwal A, 2016, APPL ARTIF INTELL, V30, P429, DOI 10.1080/08839514.2016.1185859
   Anand S., 2015, INT J COMPUT APPL, V119, P19
   Chen YF, 2019, OPT EXPRESS, V28
   Chen ZJ, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.06.041
   Chong CW, 2003, INT J PATTERN RECOGN, V17, P1011, DOI 10.1142/S0218001403002769
   Chong CW, 2003, PATTERN RECOGN, V36, P731, DOI 10.1016/S0031-3203(02)00091-2
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   [崔继文 CUI Jiwen], 2005, [光学技术, Optical Technology], V31, P779
   Diop ES, 2020, IET IMAGE PROCESS, V14, P1035, DOI 10.1049/iet-ipr.2019.0086
   Dixit R, 2017, IET IMAGE PROCESS, V11, P301, DOI 10.1049/iet-ipr.2016.0537
   Fairchild Mark D., 2013, COLOR APPEARANCE MOD, DOI [DOI 10.1002/9781118653128, 10.1002/9781118653128]
   Fernando M, 2015, NOVEL APPROACH USE H
   Firuzi K, 2019, IEEE T POWER DELIVER, V34, P542, DOI 10.1109/TPWRD.2018.2872820
   Kang H.R., 2006, SPIE PRESS MONOGRAPH
   Kang HK, 2010, J MECH SCI TECHNOL, V24, P391, DOI 10.1007/s12206-009-1110-0
   Kang H, 2013, CONTROL ENG PRACT, V21, P645, DOI 10.1016/j.conengprac.2012.09.012
   Kaur H, 2019, MOD PHYS LETT B, V33, DOI 10.1142/S0217984919502452
   Kim CH, 2012, P I MECH ENG C-J MEC, V226, P2726, DOI 10.1177/0954406211433247
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar BM, 2018, IMAGING SCI J, V66, P84, DOI 10.1080/13682199.2017.1378285
   Lee J, 2018, INT J ADV MANUF TECH, V98, P3155, DOI 10.1007/s00170-018-2465-0
   Lee J, 2016, APPL PHYS LETT, V109, DOI 10.1063/1.4964262
   Lee J, 2015, ROBOT CIM-INT MANUF, V35, P77, DOI 10.1016/j.rcim.2015.02.008
   Lee J, 2015, MECH SYST SIGNAL PR, V60-61, P706, DOI 10.1016/j.ymssp.2015.01.028
   Leng L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092644
   Li Yanjiao, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1745, DOI 10.1007/s12652-018-0994-x
   Luo J, 2003, J MATER PROCESS TECH, V139, P373, DOI 10.1016/S0924-0136(03)00534-X
   Lupek M, 2010, J RAMAN SPECTROSC, V38
   Müller O, 2018, ASTRON ASTROPHYS, V615, DOI 10.1051/0004-6361/201732455
   Nazarkevych M, 2020, APPROACH PROTECTION
   Schirrmeister RT, 2017, HUM BRAIN MAPP, V38, P5391, DOI 10.1002/hbm.23730
   Sugimoto, 2010, J PRINTING ENCE TECH, V24
   Verma OP, 2017, IEEE T FUZZY SYST, V25, P114, DOI 10.1109/TFUZZ.2016.2551289
   Vidic I, 2018, J MAGN RESON IMAGING, V47, P1205, DOI 10.1002/jmri.25873
   Wang Xue-lin, 2011, Computer Engineering, V37, P285, DOI 10.3969/j.issn.1000-3428.2011.13.094
   Wee CY, 2004, INFORM SCIENCES, V159, P203, DOI 10.1016/j.ins.2003.08.006
   Yasaka K, 2017, MEDICINE, V96, DOI 10.1097/MD.0000000000006993
   Yoshida T, 2008, Transactions of the Japan Society of Mechanical Engineers, V74, P1438
   Yoshida T., 2008, T JAPAN SOC MECH ENG, V74, P339, DOI [10.1299/kikaic.74.339, DOI 10.1299/KIKAIC.74.339]
NR 40
TC 1
Z9 1
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32409
EP 32421
DI 10.1007/s11042-021-10981-2
EA JUL 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000679762700005
DA 2024-07-18
ER

PT J
AU Fallucchi, F
   Di Stabile, R
   Purificato, E
   Giuliano, R
   De Luca, EW
AF Fallucchi, Francesca
   Di Stabile, Rosario
   Purificato, Erasmo
   Giuliano, Romeo
   De Luca, Ernesto William
TI Enriching videos with automatic place recognition in google maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Named entity recognition; Video retrieval; Enriching video; Geographic
   information retrieval; Education with media
ID NAMED ENTITY RECOGNITION
AB The availability of videos has grown rapidly in recent years. Finding and browsing relevant information to be automatically extracted from videos is not an easy task, but today it is an indispensable feature due to the immense number of digital products available. In this paper, we present a system which provides a process to automatically extract information from videos. We describe a system solution that uses a re-trained OpenNLP model to locate all the places and famous people included in a specific video. The system obtains information from the Google Knowledge Graph related to relevant named entities such as places or famous people. In this paper we will also present the Automatic Georeferencing Video (AGV) system developed by RAI (Radiotelevisione italiana, which is the national public broadcasting company of Italy, owned by the Ministry of Economy and Finance) Teche for the European Project "La Citta Educante" (The Educating City: teaching and learning processes in cross-media ecosystem) Our system contributes to The Educating City project by providing the technological environment to create statistical models for automatic named entity recognition (NER), and has been implemented in the field of education, in Italian initially. The system has been applied to the learning challenges facing the world of educational media and has demonstrated how beneficial combining topical news content with scientific content can be in education.
C1 [Fallucchi, Francesca; Giuliano, Romeo; De Luca, Ernesto William] Guglielmo Marconi Univ, Via Plinio 44, Rome, Italy.
   [Di Stabile, Rosario; De Luca, Ernesto William] RAI SpA, Viale Giuseppe Mazzini 14, Rome, Italy.
   [Purificato, Erasmo] Otto von Guericke Univ, Univ Pl 2, Magdeburg, Germany.
   [Fallucchi, Francesca; Purificato, Erasmo; De Luca, Ernesto William] Georg Eckert Inst, Celler Str 3, Braunschweig, Germany.
C3 Guglielmo Marconi University; Otto von Guericke University; Georg Eckert
   Institut
RP Fallucchi, F (corresponding author), Guglielmo Marconi Univ, Via Plinio 44, Rome, Italy.; Fallucchi, F (corresponding author), Georg Eckert Inst, Celler Str 3, Braunschweig, Germany.
EM f.fallucchi@unimarconi.it
RI Purificato, Erasmo/HKF-7484-2023
OI Purificato, Erasmo/0000-0002-5506-3020; Fallucchi,
   Francesca/0000-0002-3288-044X
CR [Anonymous], 2016, ARXIV160908124
   [Anonymous], 2011, P 49 ANN M ASS COMP
   [Anonymous], 2012, LBSN 12 P 5 ACM SIGS, DOI DOI 10.1145/2442796.2442805
   Basile P, 2016, 5 EV CAMP NAT LANG P, P40
   Ceccarelli M., 2008, IEEE International Geoscience and Remote Sensing Symposium (IGARSS), V5, P220
   Chiu CC, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4774, DOI 10.1109/ICASSP.2018.8462105
   Gaikwad SK., 2010, INT J COMPUT APPL, V10, P16, DOI DOI 10.5120/1462-1976
   Giuliano R, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9061055
   Golubovic, 2016, P 10 WORKSH GEOGR IN, P1
   Han, 2017, ARXIV PREPRINT ARXIV
   Hendricks LA, 2017, IEEE I CONF COMP VIS, P5804, DOI 10.1109/ICCV.2017.618
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Jung JJ, 2012, EXPERT SYST APPL, V39, P8066, DOI 10.1016/j.eswa.2012.01.136
   Kotelly, 2003, ART BUS SPEECH REC C, DOI 10.1145/777947.772545
   Larson RR, 1996, 1995 CLIN LIB APPL D
   Liu Y., 2019, ROBERTA ROBUSTLY OPT
   Messina A., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P219, DOI 10.1109/WIAMIS.2008.15
   Miech A, 2019, IEEE I CONF COMP VIS, P2630, DOI 10.1109/ICCV.2019.00272
   Mithun NC, 2019, PROC CVPR IEEE, P11584, DOI 10.1109/CVPR.2019.01186
   Mithun NC, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P19, DOI 10.1145/3206025.3206064
   Nadeau D, 2007, LINGUIST INVESTIG, V30, P3
   Nothman J, 2013, ARTIF INTELL, V194, P151, DOI 10.1016/j.artint.2012.03.006
   Patel BV., 2012, International Journal of UbiComp, V3, P13, DOI [DOI 10.5121/IJU.2012.3202, 10.5121/iju.2012.3202]
   Purificato E, 2018, MULTIMED TOOLS APPL, V77, P27447, DOI 10.1007/s11042-018-5931-7
   Purves RS, 2018, FOUND TRENDS INF RET, V12, P164, DOI 10.1561/1500000034
   Rae A, 2012, MEDIAEVAL 2012 WORK, P32
   Raju N., 2017, INT J APPL ENG RES, V12, P14750
   Ritter A., 2011, P EMNLP, P1524
   Sang Erik F. Tjong Kim, 2003, P 7 C NATURAL LANGUA, P142, DOI DOI 10.3115/1119176.1119195
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   Speranza Manuela, 2009, EVALITA 2009
   Sundheim Beth M., 1995, 6 MESS UND C MUC 6 P, DOI DOI 10.1145/1072399.1072402
   Ullo SL, 2020, IEEE ACCESS, V8, P124055, DOI 10.1109/ACCESS.2020.3006082
   Ullo SL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113113
   Veltkamp RC, 2013, STATE ART CONTENT BA, P22
   Wilhelm-Stein T, 2014, INFORM ACCESS EVALUA, P110
   Xu R, 2015, AAAI CONF ARTIF INTE, P2346
   Zheng YT, 2011, MULTIMED TOOLS APPL, V51, P77, DOI 10.1007/s11042-010-0630-z
NR 38
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 23105
EP 23121
DI 10.1007/s11042-021-11253-9
EA JUL 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000679293200001
DA 2024-07-18
ER

PT J
AU Park, JH
   Cho, SI
AF Park, Jae Hyeon
   Cho, Sung In
TI Flow analysis-based fast-moving flow calibration for a people-counting
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vision-based people-counting; Flow analysis; Foreground extraction;
   LOI-based people-counting
AB We propose a new vision-based people-counting method that uses flow analysis with the movement speed of a person to increase the accuracy of people-counting. The proposed method consists of two procedures: simple estimation of foreground movement speed and multiple people detection based on the flow analysis. First, we extract the flow that is generated by the movements of the foreground, and its volume that is calculated by accumulating the foreground pixels on a line of interest (LOI) while people enter and exit the target region. Second, the number of frames containing the foreground in the LOI for each entry and exit event is counted to estimate the speed of the flow cluster. Finally, the number of people is estimated from the flow volume (FV) and the number of frames. In the experimental results, the proposed method enhanced the average F1 score and accuracy by up to 25% and 9%, respectively, compared to existing people-counting methods. The results confirmed that the proposed method achieved substantial accuracy improvements over existing methods when the person passed the target region for various speed patterns.
C1 [Park, Jae Hyeon; Cho, Sung In] Dongguk Univ, Dept Multimedia Engn, Seoul 04620, South Korea.
C3 Dongguk University
RP Cho, SI (corresponding author), Dongguk Univ, Dept Multimedia Engn, Seoul 04620, South Korea.
EM pjh0011@dongguk.edu; csi2267@dongguk.edu
RI 박, 재현/HIZ-5997-2022
OI 박, 재현/0000-0002-6233-4394
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [2020R1C1C1009662]; NRF - Ministry of Education [NRF-2020X1A3A1093880]
FX This research was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (No.
   2020R1C1C1009662), and Basic Science Research Program through the NRF
   funded by Ministry of Education (No. NRF-2020X1A3A1093880).
CR [Anonymous], 2006, COMPUTER VISION PATT, DOI 10.1109/CVPR.2006.92
   Brostow G.J., 2006, CVPR, P594, DOI DOI 10.1109/CVPR.2006.320
   Chan AB, 2012, IEEE T IMAGE PROCESS, V21, P2160, DOI 10.1109/TIP.2011.2172800
   Chen TH, 2006, 2006 IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS, VOLS 1 AND 2, P97
   Chengbin Zeng, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2069, DOI 10.1109/ICPR.2010.509
   Cho SI, 2018, IEEE ACCESS, V6, P55264, DOI 10.1109/ACCESS.2018.2872684
   Cong Y, 2009, PROC CVPR IEEE, P1093, DOI 10.1109/CVPRW.2009.5206648
   García J, 2013, IEEE T IND ELECTRON, V60, P3991, DOI 10.1109/TIE.2012.2206330
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Huazhong Xu, 2010, 2010 International Conference on Computer Design and Applications (ICCDA 2010), P394, DOI 10.1109/ICCDA.2010.5540833
   Liu X, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P306
   Ma Z, 2016, IEEE T CIRC SYST VID, V26, P1955, DOI 10.1109/TCSVT.2015.2489418
   Ma Z, 2013, PROC CVPR IEEE, P2539, DOI 10.1109/CVPR.2013.328
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Subburaman VB, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P470, DOI 10.1109/AVSS.2012.87
   Yeh CH, 2017, IEEE T IND ELECTRON, V64, P4945, DOI 10.1109/TIE.2017.2669881
   Zhang Q, 2019, PROC CVPR IEEE, P8289, DOI 10.1109/CVPR.2019.00849
   Zhou BL, 2012, PROC CVPR IEEE, P2871, DOI 10.1109/CVPR.2012.6248013
NR 18
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 31671
EP 31685
DI 10.1007/s11042-021-11231-1
EA JUL 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000673731800003
DA 2024-07-18
ER

PT J
AU Sundararaj, V
   Selvi, M
AF Sundararaj, Vinu
   Selvi, M.
TI Opposition grasshopper optimizer based multimedia data distribution
   using user evaluation strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User experience; Content distribution; Integrated utility value;
   Opposition grasshopper optimizer; Multimedia content; Interest discovery
ID SCHEME; PLACEMENT; TRENDS
AB Multimedia services are offered to the demanding user by the multimedia cloud. By the fact, the sudden increase of network users has reduced the service receiving response time. Hence, it is impossible to achieve service satisfaction. Therefore, user experience based characteristic is a main role in the multimedia content acquisition, such as server distribution imbalance, huge user visits and limited bandwidth. In order to withstand these problems, a new multimedia cloud content distribution method is proposed based upon the integrated user utility and interest discovery. Initially, the interest features of users are extracted through applying an important feature extraction method. Subsequently, the separation of service and non-service users are formed through the development of a group depending on the categorization of same service interest and adjacent region included users. Followed with this, the integrated utility value is adopted to introduce user evaluation strategies. The integrated utility values are computed combining different user experience characteristics such as, user reputation, user selfish behaviours and user physical performance. However, the service user number evaluated by employing the Opposition Grasshopper Optimizer (OGHA) has minimized the content distribution time and user cost. Furthermore, the convergence profile and computational speed of standard GHA is enhanced by introducing the notion of opposition based population initialization in the proposed approach. Simulation outcomes have evidently proved the improvement of multimedia cloud users, minimizing the total cost of multimedia cloud users, and improvement of multimedia content utilization.
C1 [Sundararaj, Vinu] Anna Univ, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
   [Selvi, M.] Manonmaniam Sundaranar Univ, ST Hindu Coll, Dept Comp Sci, Tirunelveli, India.
C3 Anna University; Anna University Chennai; Manonmaniam Sundaranar
   University
RP Sundararaj, V (corresponding author), Anna Univ, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
EM vinovinu2020@gmail.com
RI Sundararaj, Vinu/AAX-1738-2021
OI Sundararaj, Vinu/0000-0003-4561-3815
CR Anandaraj M, 2020, J CIRCUIT SYST COMP, V29, DOI 10.1142/S0218126620501571
   Aygun B, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106870
   Bhattacharya P, 2020, INT J SOFTW SCI COMP, V12, P47, DOI 10.4018/IJSSCI.2020010104
   Coronado E, 2020, IEEE IFIP NETW OPER, DOI 10.1109/noms47738.2020.9110424
   Deane JK, 2012, INFORM TECHNOL MANAG, V13, P1, DOI 10.1007/s10799-011-0107-4
   Falkowski-Gilski P, 2020, COMPUT SCI REV, V37, DOI 10.1016/j.cosrev.2020.100268
   Bravo-Torres JF, 2015, J NETW COMPUT APPL, V51, P1, DOI 10.1016/j.jnca.2014.12.003
   Garg S, 2020, J PARALLEL DISTR COM, V135, P219, DOI 10.1016/j.jpdc.2019.09.013
   [胡海洋 Hu Haiyang], 2013, [计算机学报, Chinese Journal of Computers], V36, P613
   Hu Y, 2020, IEEE ACCESS, V8, P58959, DOI 10.1109/ACCESS.2020.2982322
   Jose J, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102480
   Krishna Priya, 2020, J CIRCUIT SYST COMP
   Li CL, 2017, COMPUT IND ENG, V109, P1, DOI 10.1016/j.cie.2017.03.033
   Li CL, 2017, KNOWL-BASED SYST, V124, P1, DOI 10.1016/j.knosys.2017.02.026
   Lu XJ, 2014, J NETW COMPUT APPL, V42, P197, DOI 10.1016/j.jnca.2014.01.015
   Patsakis C, 2014, COMPUT NETW, V75, P531, DOI 10.1016/j.comnet.2014.08.023
   Rana S, 2020, MULTIMED TOOLS APPL, V79, P20319, DOI 10.1007/s11042-020-08683-2
   Rejeesh MR, 2019, MULTIMED TOOLS APPL, V78, P22691, DOI 10.1007/s11042-019-7577-5
   Rosaci D, 2013, INFORM SYST, V38, P198, DOI 10.1016/j.is.2012.08.002
   Roy P, 2020, COMPUT NETW, V182, DOI 10.1016/j.comnet.2020.107573
   Sasikala, 2021, COMPUT J
   Shakkottai S, 2010, IEEE ACM T NETWORK, V18, P476, DOI 10.1109/TNET.2009.2035047
   Sundararaj, 2016, INT J INTELL ENG SYS, V9, P117, DOI [10.22266/ijies2016.0930.12, DOI 10.22266/IJIES2016.0930.12]
   Sundararaj V, 2020, PROG PHOTOVOLTAICS, V28, P1128, DOI 10.1002/pip.3315
   Sundararaj V, 2019, INT J BIOMED ENG TEC, V31, P325, DOI 10.1504/IJBET.2019.103242
   Sundararaj V, 2019, WIRELESS PERS COMMUN, V104, P173, DOI 10.1007/s11277-018-6014-9
   Sundararaj V, 2018, COMPUT SECUR, V77, P277, DOI 10.1016/j.cose.2018.04.009
   Xiang Z, 2004, IEEE T MULTIMED, V6
   Yang JC, 2017, FUTURE GENER COMP SY, V70, P94, DOI 10.1016/j.future.2016.06.015
   Zhou ZC, 2020, COMPUT COMMUN, V160, P326, DOI 10.1016/j.comcom.2020.06.015
NR 30
TC 71
Z9 71
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29875
EP 29891
DI 10.1007/s11042-021-11123-4
EA JUL 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000673928000003
DA 2024-07-18
ER

PT J
AU Francis, A
   Pandian, IA
AF Francis, Ambily
   Pandian, Immanuel Alex
CA Alzheimer's Dis Neuroimaging Init
TI Early detection of Alzheimer's disease using local binary pattern and
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alzheimer's disease; Mild cognitive impairment convertible; Mild
   cognitive impairment non-convertible; Fast Hessian matrix; Local binary
   pattern; Convolutional neural network
ID EARLY-DIAGNOSIS; CLASSIFICATION; SCALE
AB Alzheimer's disease, a progressive and irreversible abnormality of the human brain impairs memory and thinking skills. Gradually, it will damage the ability to carry out simple tasks. Even though the disease cannot be completely cured by medical specialists, the rate of brain damage can be pared if the disease is identified in its budding stage itself. Thus, victims and their relatives will get ample time to prepare themselves. Alzheimer's disease (AD), cognitively normal (CN), mild cognitive impairment convertible (MCIc), and mild cognitive impairment non-convertible (MCInc) are the different phases of cognition. The state of memory loss in aged people, which will not lead to AD, can be encountered as MCInc. The state-MCIc gradually leads to AD. The work is intended for the early detection of AD. Early detection can be claimed if and only if the state-MCIc is detected. But the clinical visual identification of state-MCIc from MRI scan is difficult. In this work, a novel local feature descriptor is proposed for the detection of state-MCIc. The proposed local feature descriptor combined strengths of fast Hessian detector and local binary pattern texture operator for the identification of key points and descriptions. A simple convolutional neural network is used for classification. The classification accuracy between MCIc and CN is obtained as 88.46% which is a pivotal result for early detection of AD. The classification accuracy between AD and CN is attained at 88.99%. The results indicate that the proposed system can contribute a colossal innovation in the early detection of AD.
C1 [Francis, Ambily; Pandian, Immanuel Alex] Karunya Inst Technol & Sci, Dept Elect & Commun, Coimbatore, Tamil Nadu, India.
   [Francis, Ambily] Sahrdaya Coll Engn & Technol, Dept Elect & Commun, Kodakara, Kerala, India.
C3 Karunya Institute of Technology & Sciences
RP Francis, A (corresponding author), Karunya Inst Technol & Sci, Dept Elect & Commun, Coimbatore, Tamil Nadu, India.; Francis, A (corresponding author), Sahrdaya Coll Engn & Technol, Dept Elect & Commun, Kodakara, Kerala, India.
EM ambily222000@gmail.com; immans@karunya.edu
RI Francis, Ambily/GYA-5325-2022
OI Francis, Ambily/0000-0001-9349-4094
CR Ahmad M., 2012, IOSR J COMPUTER ENG, V8, P25, DOI [10.9790/0661-0822531, DOI 10.9790/0661-0822531]
   ARSENAULT HH, 1986, APPL OPTICS, V25, P3225, DOI 10.1364/AO.25.003225
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Ben Ahmed O, 2015, MULTIMED TOOLS APPL, V74, P1249, DOI 10.1007/s11042-014-2123-y
   Castellani U, 2012, J NEURAL TRANSM, V119, P395, DOI 10.1007/s00702-011-0693-7
   Çevik A, 2017, ANN OPER RES, V258, P31, DOI 10.1007/s10479-017-2405-7
   Chang CW, 2012, FRONT SYST NEUROSCI, V6, DOI 10.3389/fnsys.2012.00066
   Chincarini A, 2014, ALZHEIMERS DEMENT, V10, P456, DOI 10.1016/j.jalz.2013.05.1774
   Ding Y, 2015, IEEE INT C BIOINFORM, P409, DOI 10.1109/BIBM.2015.7359716
   Francis Ambily, 2018, 2018 International Conference on Circuits and Systems in Digital Enterprise Technology (ICCSDET), DOI 10.1109/ICCSDET.2018.8821115
   Hannun AY, 2019, NAT MED, V25, P65, DOI 10.1038/s41591-018-0268-3
   Herrera LJ, 2013, 2013 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM), P846, DOI 10.1109/SocialCom.2013.127
   Lecron F, 2012, LECT NOTES COMPUT SC, V7325, P331, DOI 10.1007/978-3-642-31298-4_39
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luk Collin C, 2018, Alzheimers Dement (Amst), V10, P755, DOI 10.1016/j.dadm.2018.09.002
   Mahanand BS, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P1930, DOI 10.1109/IJCNN.2011.6033460
   Mahmood R, 2013, INT CONF SYST SIGNAL, P133, DOI 10.1109/IWSSIP.2013.6623471
   Mathew J., 2016, 2016 IEEE Annual India Conference, P1
   Mizotin M, 2012, IEEE IMAGE PROC, P1241, DOI 10.1109/ICIP.2012.6467091
   Mondal Prasenjit, 2014, 2014 International Conference on Medical Imaging, m-Health and Emerging Communication Systems (MedCom), P342, DOI 10.1109/MedCom.2014.7006030
   Nanni L, 2019, ARTIF INTELL MED, V97, P19, DOI 10.1016/j.artmed.2019.05.003
   Nanni L, 2010, ARTIF INTELL MED, V49, P117, DOI 10.1016/j.artmed.2010.02.006
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliver A, 2007, LECT NOTES COMPUT SC, V4791, P286
   Oppedal K, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P594, DOI 10.1109/ISBI.2012.6235618
   Pan D, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00259
   Peng L, 2021, MULTIMEDIA SYST, V27, P363, DOI 10.1007/s00530-020-00697-y
   Saraswathi S, 2013, PROCEEDINGS OF THE 2013 FOURTH INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE IN MEDICAL IMAGING (CIMI), P42, DOI 10.1109/CIMI.2013.6583856
   Sargent D., 2009, MED IMAGING 2009 IMA, V7259
   Sarwinda D, 2016, IEEE IJCNN, P5051, DOI 10.1109/IJCNN.2016.7727865
   Shao W, 2020, COMPUT MED IMAG GRAP, V80, DOI 10.1016/j.compmedimag.2019.101663
   Sorgi L., 2006, BMVC, P539, DOI [10.5244/C.20.56, DOI 10.5244/C.20.56]
   Sorokin DV, 2011, LECT NOTES COMPUT SC, V6753, P284, DOI 10.1007/978-3-642-21593-3_29
   Sweety ME, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P1305, DOI 10.1109/ICACCCT.2014.7019310
   Unay D, 2008, IEEE IMAGE PROC, P997, DOI 10.1109/ICIP.2008.4711925
   Yan SJ, 2019, J ENG-JOE, P530, DOI 10.1049/joe.2018.9412
   Yang MJ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.94
NR 39
TC 10
Z9 11
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29585
EP 29600
DI 10.1007/s11042-021-11161-y
EA JUL 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000669172500001
DA 2024-07-18
ER

PT J
AU Sonawane, B
   Sharma, P
AF Sonawane, Bhakti
   Sharma, Priyanka
TI Speech-based solution to Parkinson's disease management
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dysarthria detection; Deep learning; Convolutional neural network
AB Parkinson's disease (PD) is a neurological disorder marked by decreased dopamine levels in the brain. Persons suffering from PD, exhibits vocal symptoms such as dysphonia and dysarthria. Speech impairments in PD are grouped together and called as hypokinetic dysarthria. Traditional PD management is based on a patient's clinical history and through physical examination as there are currently no known biomarkers for its diagnosis. Automatic analysis techniques aid clinicians in diagnosis and monitoring patients using speech and provide frequent, cost effective and objective assessment. This paper presents pilot experiment to detect presence of dysarthria in speech and detect level of severity based on deep learning approach. Automated feature extraction and classification using convolutional neural network shows 77.48% accuracy on test samples of TORGO database with five fold validation. Using transfer learning, system performance is further analyzed for gender specific performance as well as in detection of severity of disease.
C1 [Sonawane, Bhakti] SAKEC, Mumbai, Maharashtra, India.
   [Sharma, Priyanka] Nirma Univ, Ahmadabad, Gujarat, India.
C3 Nirma University
RP Sonawane, B (corresponding author), SAKEC, Mumbai, Maharashtra, India.
EM 15extphde153@nirmauni.ac.in; Priyanka.sharma@nirmauni.ac.in
RI Sonawane, Bhakti/R-8759-2019; Sonawane, Bhakti/AAH-5333-2020; Sonawane,
   bhakti/T-8756-2019; Sonawane, Bhakti/KHT-4569-2024
OI Sonawane, bhakti/0000-0002-2154-9014; 
CR Al-Fatlawi AH, 2016, IEEE C EVOL COMPUTAT, P1324, DOI 10.1109/CEC.2016.7743941
   Ali H, 2018, NEURAL COMPUT APPL, V29, P13, DOI 10.1007/s00521-016-2501-7
   [Anonymous], 2014, J AM SCI
   Baghai-Ravary L., 2012, Automatic Speech Signal Analysis for Clinical Diagnosis and Assessment of Speech Disorders
   Berus L, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19010016
   Bologna M, 2013, J NEUROL NEUROSUR PS, V84, P681, DOI 10.1136/jnnp-2012-303993
   Vásquez-Correa JC, 2019, IEEE J BIOMED HEALTH, V23, P1618, DOI 10.1109/JBHI.2018.2866873
   Chen HL, 2013, EXPERT SYST APPL, V40, P263, DOI 10.1016/j.eswa.2012.07.014
   ENDERBY P, 1980, BRIT J DISORD COMMUN, V15, P165
   Gawehn E, 2016, MOL INFORM, V35, P3, DOI 10.1002/minf.201501008
   Goetz CG, 2007, MOVEMENT DISORD, V22, P41, DOI 10.1002/mds.21198
   Grover Srishti, 2018, Procedia Computer Science, V132, P1788, DOI 10.1016/j.procs.2018.05.154
   Han W, 2020, INTERSPEECH, P3610, DOI 10.21437/Interspeech.2020-2059
   Hazan, 2012, 2012 IEEE 27 CONV EL
   Hernandez A, 2020, INTERSPEECH, P2897, DOI 10.21437/Interspeech.2020-2354
   Hoehn MM, 1998, NEUROLOGY, V50, P318, DOI 10.1212/WNL.50.2.318
   Janbakhshi P., 2020, ARXIV201107545
   Kubota KJ, 2016, MOVEMENT DISORD, V31, P1314, DOI 10.1002/mds.26693
   Little M., 2008, Nat. Preced, V1, P1, DOI [DOI 10.1038/NPRE.2008.2298.1, 10.1038/npre.2008.2298.1]
   LOGEMANN JA, 1978, J SPEECH HEAR DISORD, V43, P47, DOI 10.1044/jshd.4301.47
   Millet, 2019, IEEE INT C AC SPEECH
   Narendra, 2020, COMPUT SPEECH LANG
   Nicolas G, 2015, 16 ANN C INT SPEECH
   Nilashi M, 2016, SCI REP-UK, V6, DOI 10.1038/srep34181
   Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565
   Orozco-Arroyave JR, 2016, J ACOUST SOC AM, V139, P481, DOI 10.1121/1.4939739
   OSullivan SB, 2019, Physical rehabilitation: FA Davis
   Pell MD, 2008, LANG LINGUIST COMPAS, V2, P739, DOI 10.1111/j.1749-818x.2008.00074.x
   Perez, 2016, J ALZHEIMERS DIS PAR, V6, P2161
   Peterson L.E., 2009, SCHOLARPEDIA, V4, P1883, DOI 10.4249/scholarpedia.1883
   Postuma RB, 2009, PARKINSONISM RELAT D, V15, pS105, DOI 10.1016/S1353-8020(09)70793-X
   Reher R, 2020, J AM CHEM SOC, V142, P4114, DOI 10.1021/jacs.9b13786
   Roccetti, 2020, MOB NETW APPL, P1
   Rudzicz F, 2012, LANG RESOUR EVAL, V46, P523, DOI 10.1007/s10579-011-9145-0
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Schrag A, 2000, J NEUROL NEUROSUR PS, V69, P308, DOI 10.1136/jnnp.69.3.308
   Schwab RS., 1969, 3 S PARKINSONS DIS, P152
   Shahbakhi Mohammad, 2014, Journal of Biomedical Science and Engineering, V7, P147, DOI DOI 10.4236/JBISE.2014.74019
   Sharma A., 2014, Int J Innov Technol Expl Eng, V4, P2278
   Sharma G, 2020, APPL ACOUST, V158, DOI 10.1016/j.apacoust.2019.107020
   Sonawane Bhakti., 2020, ENVIRONMENT, V7, P8
   Tickle-Degnen L, 2004, SOC SCI MED, V58, P603, DOI 10.1016/S0277-9536(03)00213-2
   Tripathi, 2020, IEEE INT C AC SPEECH
   Tsanas A, 2010, IEEE T BIO-MED ENG, V57, P884, DOI 10.1109/TBME.2009.2036000
   Vásquez-Correa JC, 2018, J COMMUN DISORD, V76, P21, DOI 10.1016/j.jcomdis.2018.08.002
   Zhang J, 2017, EXPLORING RISK FACTO
   Zhao S., 2014, 2014 IEEE INT C AC S
NR 47
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29437
EP 29451
DI 10.1007/s11042-021-11061-1
EA JUN 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000666841700001
DA 2024-07-18
ER

PT J
AU Brahma, B
   Wadhvani, R
AF Brahma, Banalaxmi
   Wadhvani, Rajesh
TI Visualizing solar irradiance data in ArcGIS and forecasting based on a
   novel deep neural network mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recurrent neural network; Convolutional neural network; Long short term
   memory; Gated recurrent unit; Attention mechanism; Forecast; Bias;
   Variance
ID GLOBAL HORIZONTAL IRRADIANCE; MODEL; LSTM; OPTIMIZATION
AB Solar power plants are growing tremendously to manage the ever-growing demand for power production and supply in a sustainable manner. Solar irradiance forecasting, being a time series problem, can aid in the planning and design of solar power plants. This work have developed a deep learning forecast model for accurately predicting future values of solar irradiance for given location. The locations have been selected with the help of visual information, which indicates the intensity of solar irradiance. This visual information has been provided by NASA's Prediction of Worldwide Energy Resources (POWER) project. The proposed model utilizes convolutional layers for extraction of internal representations of solar irradiance time-series data along with the attention-based LSTM network for the identification of temporal dependencies. The study is conducted on solar datasets from two locations for a period of 36 years taken from NASA's Prediction of Worldwide Energy Resource (POWER) project archive of Renewable Energy. Experiments were conducted with comparisons against various deep learning models. From the study conducted, we analyze the effect of different factors, such as model, optimizer, horizon, to decide upon the final forecast result. It has been observed that the proposed model performed with an R-2 score of more than 50 percent which indicate excellent forecast performance. Experimental analysis is also conducted for bias and variance as performance evaluators along with other indicators. The bias and variance components also show superior performance of the proposed model. The convolutional and the attention components enhance the performance of the LSTM model with the bias variance mechanism providing improved generalizability.
C1 [Brahma, Banalaxmi; Wadhvani, Rajesh] Maulana Azad Natl Inst Technol, Dept Comp Sci & Engn, Bhopal, Madhya Pradesh, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal
RP Brahma, B (corresponding author), Maulana Azad Natl Inst Technol, Dept Comp Sci & Engn, Bhopal, Madhya Pradesh, India.
EM banalaxmi.173112001@manit.ac.in
RI Brahma, Banalaxmi/HMD-6587-2023; Wadhvani, Rajesh/C-1966-2017
OI Brahma, Banalaxmi/0000-0002-0647-0359; Wadhvani,
   Rajesh/0000-0002-2048-997X
FU NASA Langley Research Center (LaRC) POWER Project through the NASA Earth
   Science/Applied Science Program; Madhya Pradesh Council of Science and
   Technology, Bhopal, India
FX The data used in the research were obtained from the NASA Langley
   Research Center (LaRC) POWER Project funded through the NASA Earth
   Science/Applied Science Program. The dataset is available at the website
   https://power.larc.nasa.gov/data-access-viewer/. We acknowledge to
   Madhya Pradesh Council of Science and Technology, Bhopal, India for
   research support.
CR Aburto L, 2007, APPL SOFT COMPUT, V7, P136, DOI 10.1016/j.asoc.2005.06.001
   Alex GravesGreg Wayne Ivo Danihelka., 2014, Neural turing machines
   Amrouche B, 2013, SOL ENERG MAT SOL C, V118, P124, DOI 10.1016/j.solmat.2013.08.010
   Amrouche B, 2014, APPL ENERG, V130, P333, DOI 10.1016/j.apenergy.2014.05.055
   [Anonymous], 2012, ARXIV PREPRINT ARXIV
   [Anonymous], 2018, P INT C LEARN REPR
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Ben Taieb S, 2016, IEEE T NEUR NET LEAR, V27, P62, DOI 10.1109/TNNLS.2015.2411629
   Berardi VL, 2003, IEEE T NEURAL NETWOR, V14, P668, DOI 10.1109/TNN.2003.810601
   Brahma B., 2020, SOLID STATE TECHNOL, V63, P1747
   Brahma B, 2021, WIND ENG, V45, P1422, DOI 10.1177/0309524X20981885
   Brahma B, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12111830
   Brockwell PJ, 2016, SPRINGER TEXTS STAT, P1, DOI 10.1007/978-3-319-29854-2
   Cho K., 2014, ARXIV14061078
   Creal D, 2013, J APPL ECONOMET, V28, P777, DOI 10.1002/jae.1279
   Dong N, 2020, INT J ELEC POWER, V114, DOI 10.1016/j.ijepes.2019.105411
   Dozat T., 2016, INT C LEARN REPR SAN
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Geron A., 2017, Hands-On Machine Learning With Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems
   GEURTS M, 1977, J MARKETING RES, V14, P269, DOI 10.2307/3150485
   Giebel G, 2017, WOODHEAD PUBL SER EN, P59, DOI 10.1016/B978-0-08-100504-0.00003-2
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Guermoui M, 2020, J CLEAN PROD, V258, DOI 10.1016/j.jclepro.2020.120357
   Heng JN, 2017, APPL ENERG, V208, P845, DOI 10.1016/j.apenergy.2017.09.063
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ilya S, 2014, SEQUENCE SEQUENCE LE
   Kim TY, 2019, ENERGY, V182, P72, DOI 10.1016/j.energy.2019.05.230
   Kingma D. P., 2014, arXiv
   LeCun Y, LECT NOTES COMPUTER
   Li TY, 2020, IEEE ACCESS, V8, P26933, DOI 10.1109/ACCESS.2020.2971348
   Li YT, 2014, RENEW ENERG, V66, P78, DOI 10.1016/j.renene.2013.11.067
   Loshchilov I., 2016, Learning
   Lubitz WD, 2011, APPL ENERG, V88, P1710, DOI 10.1016/j.apenergy.2010.11.008
   Mateo F, 2013, EXPERT SYST APPL, V40, P1061, DOI 10.1016/j.eswa.2012.08.030
   Neves C, 2017, INSUR MATH ECON, V75, P48, DOI 10.1016/j.insmatheco.2017.04.004
   Qing XY, 2018, ENERGY, V148, P461, DOI 10.1016/j.energy.2018.01.177
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Shih SY, 2019, MACH LEARN, V108, P1421, DOI 10.1007/s10994-019-05815-0
   Srivastava S, 2018, SOL ENERGY, V162, P232, DOI 10.1016/j.solener.2018.01.005
   Tsay R. S., 2005, ANAL FINANCIAL TIME, DOI DOI 10.1002/0471746193
   Wang CH, 2012, ENERGY, V41, P313, DOI 10.1016/j.energy.2012.03.011
   Wang Y, 2019, IEEE INTERNET THINGS, V6, P2933, DOI 10.1109/JIOT.2018.2877510
   YU XH, 1995, IEEE T NEURAL NETWOR, V6, P669, DOI 10.1109/72.377972
   Zang HX, 2020, RENEW ENERG, V160, P26, DOI 10.1016/j.renene.2020.05.150
   Zhang GP, 2003, NEUROCOMPUTING, V50, P159, DOI 10.1016/S0925-2312(01)00702-0
NR 46
TC 5
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9015
EP 9043
DI 10.1007/s11042-021-11025-5
EA JUN 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000658231800001
DA 2024-07-18
ER

PT J
AU Cheng, SL
   Wang, LJ
   Huang, G
   Du, AY
AF Cheng, Shu-Li
   Wang, Lie-Jun
   Huang, Gao
   Du, An-Yu
TI A privacy-preserving image retrieval scheme based secure kNN, DNA coding
   and deep hashing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 16th International Conference on Content-Based Multimedia Indexing
   (CBMI)
CY SEP 04-06, 2018
CL La Rochelle, FRANCE
SP IEEE, IEEE Signal Proc Soc, European Assoc Signal Proc, MIRES Res Federat, Nouvelle Aquitaine Reg, GDR ISIS, GDR MADICS, MAGELLIUM Co
DE Multimedia; Privacy protection; Deep hash; Cloud computing; Image
   encryption; Secure kNN
ID ENCRYPTION; ALGORITHM; EFFICIENT; CHAOS; PERMUTATION; MODEL
AB In recent years, information leakage incidents occur frequently. Ciphertext domain search has become a hot spot in multimedia technology and software engineering. Therefore, how to mine valuable information safely and effectively is very important. In this paper, we present the CBIR solution and complete the relevant software development. The proposed method not only outsources CBIR services but also avoids privacy leaks. Our main contributions are reflected in two aspects: improving search efficiency and protecting user privacy. For one thing, we propose a novel privacy protection algorithm to encrypt images. For the other thing, we propose an integrated deep hash algorithm to extract the high-level features of images. In the index encryption process, we use secure kNN to encrypt the index. Through experimental analysis and argumentation, the proposed privacy protection algorithm has a lower correlation coefficient and a better information entropy. It is secure enough and can resist common types of attacks encountered during data transmission. The proposed secure image retrieval algorithm is tested on two datasets. Compared with the same type of algorithm, the proposed algorithm has better retrieval performance. In short, the privacy reservation scheme guarantees the security and effectiveness of the system.
C1 [Cheng, Shu-Li; Wang, Lie-Jun; Du, An-Yu] Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830046, Peoples R China.
   [Huang, Gao] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
C3 Xinjiang University; Tsinghua University
RP Wang, LJ (corresponding author), Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830046, Peoples R China.
EM liejunnwang@163.com
CR Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Fan K, 2018, IEEE NETWORK, V32, P52, DOI 10.1109/MNET.2018.1700327
   Ferreira B, 2019, IEEE T CLOUD COMPUT, V7, P784, DOI 10.1109/TCC.2017.2669999
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Gu CS, 2014, SECUR COMMUN NETW, V7, P2432, DOI 10.1002/sec.954
   Gui J, 2018, IEEE T PATTERN ANAL, V40, P490, DOI 10.1109/TPAMI.2017.2678475
   Gupta R., 2018, INT J COMPUT APPL, V85, P27
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ibrahim A, 2014, COMPUT J, V57, P241, DOI 10.1093/comjnl/bxt045
   Kaur M, 2018, ELECTRON LETT, V54, P562, DOI 10.1049/el.2017.4426
   Khan JS, 2019, MULTIDIM SYST SIGN P, V30, P943, DOI 10.1007/s11045-018-0589-x
   Li X., 2018, COMPUT APPL SOFTW, V20, P110
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu LF, 2018, IET SIGNAL PROCESS, V12, P22, DOI 10.1049/iet-spr.2016.0584
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Niu HY, 2016, J ELECTR ENG-SLOVAK, V67, P78, DOI 10.1515/jee-2016-0012
   Pujari SK, 2018, PROCEDIA COMPUT SCI, V125, P165, DOI 10.1016/j.procs.2017.12.023
   Ravichandran D, 2016, COMPUT BIOL MED, V72, P170, DOI 10.1016/j.compbiomed.2016.03.020
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Shen J, 2018, IEEE T INF FOREN SEC, V13, P912, DOI 10.1109/TIFS.2017.2774439
   Simonyan K., 2014, CORR
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wang XY, 2015, NONLINEAR DYNAM, V79, P1141, DOI 10.1007/s11071-014-1729-y
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xia ZH, 2018, IEEE T CLOUD COMPUT, V6, P276, DOI 10.1109/TCC.2015.2491933
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Zhang L, 2015, PROC INT CONF PARAL, P949, DOI 10.1109/ICPP.2015.104
   Zhang Q, 2014, J SYST SOFTW, V85, P290
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P6647, DOI 10.1007/s11042-017-4577-1
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 35
TC 6
Z9 6
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22733
EP 22755
DI 10.1007/s11042-019-07753-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000669314100020
DA 2024-07-18
ER

PT J
AU Lau, SYJ
   Agius, H
AF Lau, Sum-Yuet Joyce
   Agius, Harry
TI A framework and immersive serious game for mild cognitive impairment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Serious games; Gamification; Gamefulness; Playfulness; Immersive
   environments; Mild cognitive impairment (MCI); Dementia; Framework;
   Survey; Interviews; Occupational therapy
ID PLAYFUL INTERACTIONS; ALZHEIMERS; DISEASE; MEMORY
AB Cognitive decline is common in the elderly. As a result, a range of cognitive rehabilitation games have been proposed to supplement or replace traditional rehabilitative training by offering benefits such as improved engagement. In this paper, we focus on mild cognitive impairment (MCI), an initial stage of cognitive decline that does not affect functioning in daily life, but which may progress towards more serious cognitive deteriorations, notably dementia. Unfortunately, while a variety of serious game frameworks and rehabilitative serious games have been proposed, there is a distinct lack of those which support the distinctive characteristics of MCI patients. Consequently, to optimise the advantages of serious games for MCI, we propose the MCI-GaTE (MCI-Game Therapy Experience) framework that may be used to develop serious games as effective cognitive and physical rehabilitation tools. The framework is derived from a combination of a survey of related research literature in the area, analysis of resident profiles from a nursing home, and in-depth interviews with occupational therapists (OTs) who work with MCI patients on a daily basis. The conceptual framework comprises four sectors that may be used to guide game design and development: an MCI player profile that represents the capabilities of a player with MCI, core gaming elements that support gameful and playful activities, therapeutic elements that support cognitive and physical rehabilitation through tasks and scenarios according to the player's abilities, and motivational elements to enhance the player's attitude towards the serious tasks. Together, they provide support for rehabilitation needs and may also serve as a set of comprehensive and established criteria by which an MCI serious game may be evaluated. To demonstrate the use of MCI-GaTE, we also present A-go!, an immersive gesture-based serious game that exploits the framework to enable MCI-diagnosed players to undertake therapeutic tasks supported by an assigned OT. Evaluation with OTs revealed that the immersive game potentially offers more effective support to MCI patients than traditional methods, contributing new possibilities for enhancing MCI rehabilitative training, while a comparative assessment of MCI-GaTE demonstrated that it provides a comprehensive approach not currently offered by state-of-the-art rehabilitative frameworks.
C1 [Lau, Sum-Yuet Joyce; Agius, Harry] Brunel Univ London, Coll Engn Design & Phys Sci, Brunel Design Sch, Digital Media, Kingston Lane, Uxbridge UB8 3PH, Middx, England.
C3 Brunel University
RP Agius, H (corresponding author), Brunel Univ London, Coll Engn Design & Phys Sci, Brunel Design Sch, Digital Media, Kingston Lane, Uxbridge UB8 3PH, Middx, England.
EM jlau.lsy@gmail.com; harry.agius@brunel.ac.uk
OI Agius, Harry/0000-0002-8818-2683; Lau, Joyce S. Y./0000-0002-0374-9485
FU GRACE Healthcare Ltd., Hong Kong
FX We are grateful to GRACE Healthcare Ltd., Hong Kong, and staff from the
   following healthcare organisations in Hong Kong for their support with
   this research: Kwai Chung Hospital HA, TWGHs Fung Yiu King Hospital HA,
   Hong Kong Caritas in Evergreen Home and Integrated Home Care Services,
   and TWGHs Jockey Club Rehabilitation Complex.
CR Afyouni I, 2017, USER MODEL USER-ADAP, V27, P215, DOI 10.1007/s11257-017-9191-4
   Alchalcabi A.E., 2017, 2017 IEEE 5th International Conference on Serious Games and Applications for Health (SeGAH), Perth, WA, Australia, P1
   Alimanova M, 2017, 2017 FIRST IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC), P336, DOI 10.1109/IRC.2017.76
   Allan LM, 2005, J AM GERIATR SOC, V53, P1681, DOI 10.1111/j.1532-5415.2005.53552.x
   Alcover EA, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0197383
   Pereira VFA, 2018, INT J HYPERTENS, V2018, DOI 10.1155/2018/6028534
   [Anonymous], 2020, ALZHEIMERS DEMENT, V16, P391, DOI 10.1002/alz.12068
   [Anonymous], 2017, P 2017 INT C INNOVAT, DOI DOI 10.1109/ICIIECS.2017.8275896
   [Anonymous], 2016, 2016 8 INT C GAM VIR
   [Anonymous], 2015, P 2015 ACM INT JOINT
   Avola D, 2019, J BIOMED INFORM, V89, P81, DOI 10.1016/j.jbi.2018.11.012
   Baranyi R., 2016, P IEEE INT C SER GAM, P1, DOI 10.1109/SeGAH.2016.7586283
   Blankevoort CG, 2010, DEMENT GERIATR COGN, V30, P392, DOI 10.1159/000321357
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Caracuel A, 2011, 2011 IEEE 1 INT C SE, P1, DOI [10.1109/SeGAH.2011.6165448, DOI 10.1109/SEGAH.2011.6165448]
   Chi HM, 2017, IEEE INT CONF SERIOU
   Csikszentmihalyi M., 1975, Beyond boredom and anxiety, DOI DOI 10.1037/10516-164
   Dan A, 2017, INT J PSYCHOPHYSIOL, V122, P75, DOI 10.1016/j.ijpsycho.2016.08.013
   Davis H, 2012, UNIVERSAL ACCESS INF, V11, P17, DOI 10.1007/s10209-011-0230-3
   Eriksson J., 2017, HUMAN ASPECTS IT AGE, P429, DOI [10.1007/978-3-319-58530-7_33, DOI 10.1007/978-3-319-58530-7_33]
   Eshkoor SA, 2015, CLIN INTERV AGING, V10, P687, DOI 10.2147/CIA.S73922
   Fernandez-Cervantes V, 2016, LECT NOTES COMPUT SC, V9926, P38, DOI 10.1007/978-3-319-46100-7_4
   Foletto AA, 2017, STUD HEALTH TECHNOL, V245, P74, DOI 10.3233/978-1-61499-830-3-74
   Gaugler Joseph E, 2007, BMC Geriatr, V7, P13, DOI 10.1186/1471-2318-7-13
   Gauthier S, 2006, LANCET, V367, P1262, DOI 10.1016/S0140-6736(06)68542-5
   Grau Sergi, 2010, 2010 2nd International Conference on Games and Virtual Worlds for Serious Applications (VS-GAMES 2010), P109, DOI 10.1109/VS-GAMES.2010.17
   Gutenschwager K, 2019, GLOB J AGING GERIATR, V1
   Holmes D, 2015, 2015 INTERNATIONAL CONFERENCE ON INTERACTIVE TECHNOLOGIES AND GAMES, P41, DOI 10.1109/iTAG.2015.11
   Hossain MS, 2016, MULTIMEDIA SYST, V22, P659, DOI 10.1007/s00530-015-0481-6
   Jacoby S, 2009, 2009 VIRTUAL REHABILITATION INTERNATIONAL CONFERENCE, P42, DOI 10.1109/ICVR.2009.5174203
   Jamshed Shazia, 2014, J Basic Clin Pharm, V5, P87, DOI 10.4103/0976-0105.141942
   Jessen JD, 2015, IEEE ASME INT C ADV, P311, DOI 10.1109/AIM.2015.7222550
   Jessen S, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/11579
   Jia-Kuan Lin, 2011, 2011 IEEE 13th International Conference on e-Health Networking, Applications and Services (Healthcom 2011), P197, DOI 10.1109/HEALTH.2011.6026743
   Laskowska I, 2013, BIO-ALGORITHMS MED-S, V9, P155, DOI 10.1515/bams-2013-0016
   Lee GY, 2013, CLIN INTERV AGING, V8, P623, DOI 10.2147/CIA.S45726
   Lee S, 2014, CLUSTER COMPUT, V17, P757, DOI 10.1007/s10586-013-0289-0
   Lek HC, 2017, IEEE ENG MED BIO, P275, DOI 10.1109/EMBC.2017.8036815
   Lund H. H., 2011, 2011 8th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI 2011), P253, DOI 10.1109/URAI.2011.6145971
   Madeira RN, 2014, INT CONF EXPO ELECTR, P612, DOI 10.1109/ICEPE.2014.6969982
   Marsh T, 2011, ENTERTAIN COMPUT, V2, P61, DOI 10.1016/j.entcom.2010.12.004
   Marti Patrizia., 2010, Proceedings of the 6th Nordic Conference on Human-Computer Interaction: Extending Boundaries, P851
   Mondéjar T, 2016, J BIOMED INFORM, V63, P131, DOI 10.1016/j.jbi.2016.08.006
   Moraiti A, 2016, 2016 11TH INTERNATIONAL WORKSHOP ON SEMANTIC AND SOCIAL MEDIA ADAPTATION AND PERSONALIZATION (SMAP), P139, DOI 10.1109/SMAP.2016.7753399
   Morales A., 2016, P 8 IEEE INT C BIOM, P1
   Palumbo V., 2020, P 13 ACM INT C PERVA, DOI [10.1145/3389189.3393739, DOI 10.1145/3389189.3393739]
   Pan TY, 2015, PROCEEDINGS OF 2015 INTERNATIONAL CONFERENCE ON ORANGE TECHNOLOGIES (ICOT), P71, DOI 10.1109/ICOT.2015.7498478
   Paraskevopoulos IT, 2016, INT CONF GAMES VIRTU
   Pasqual TB, 2016, P IEEE RAS-EMBS INT, P1007, DOI 10.1109/BIOROB.2016.7523762
   Perugia G, 2017, ACMIEEE INT CONF HUM, P257, DOI 10.1145/3029798.3038353
   Petersen RC, 2014, J INTERN MED, V275, P214, DOI 10.1111/joim.12190
   Pettersson AF, 2005, DEMENT GERIATR COGN, V19, P299, DOI 10.1159/000084555
   Peute LWP, 2015, J BIOMED INFORM, V55, P1, DOI 10.1016/j.jbi.2015.02.006
   Procci K, 2018, ENTERTAIN COMPUT, V27, P157, DOI 10.1016/j.entcom.2018.06.001
   Qian X, 2020, ONE INTELLIGENT FRAM, DOI [10.1049/joe.2019.1209, DOI 10.1049/JOE.2019.1209]
   Rego P, 2010, SISTEMAS Y TECNOLOGIAS DE INFORMACION, P349
   Roberts R, 2013, CLIN GERIATR MED, V29, P753, DOI 10.1016/j.cger.2013.07.003
   Rodriguez-Fortiz M.J., 2016, P IEEE INT C SERIOUS, P1
   Salah AA, 2014, J AMB INTEL SMART EN, V6, P259, DOI 10.3233/AIS-140261
   Savulich G, 2019, FRONT BEHAV NEUROSCI, V13, DOI 10.3389/fnbeh.2019.00002
   Shi YL, 2018, PROC CIRP, V78, P115, DOI 10.1016/j.procir.2018.08.311
   Sicart M, 2014, PLAYF THINK, P1
   Tieben R, 2014, J AMB INTEL SMART EN, V6, P341, DOI 10.3233/AIS-140265
   Tong T, 2015, PROCEDIA COMPUT SCI, V69, P125, DOI 10.1016/j.procs.2015.10.013
   Valladares-Rodriguez S, 2018, PEERJ, V6, DOI 10.7717/peerj.5478
   Valladares-Rodríguez S, 2016, J BIOMED INFORM, V64, P296, DOI 10.1016/j.jbi.2016.10.019
   Vallejo V, 2017, COMPUT HUM BEHAV, V70, P500, DOI 10.1016/j.chb.2017.01.021
   van der Kuil MNA, 2017, 2017 INTERNATIONAL CONFERENCE ON VIRTUAL REHABILITATION (ICVR)
   Vasileiou K, 2018, BMC MED RES METHODOL, V18, DOI 10.1186/s12874-018-0594-7
   Walz SP, 2014, GAMEFUL WORLD: APPROACHES, ISSUES, APPLICATIONS, P1
   Wang X, 2016, INT CONF SIGN PROCES, P983, DOI 10.1109/ICSP.2016.7877976
   West GL, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187779
   Wilson RS, 2012, PSYCHOL AGING, V27, P1008, DOI 10.1037/a0029857
   World Health Organization, 2017, GLOBAL ACTION PLAN P, V2
   Yang Qiu KM, 2017, 2017 IEEE 5 INT C SE, P1
   Zhao YN, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/16841
NR 76
TC 18
Z9 18
U1 11
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 31183
EP 31237
DI 10.1007/s11042-021-11042-4
EA MAY 2021
PG 55
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000656384900005
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Li, T
   Xie, JY
   Niu, HL
   Hao, SJ
AF Li, Teng
   Xie, Jianyu
   Niu, Hongliang
   Hao, Shijie
TI Enhancing pencil drawing patterns via using semantic information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pencil drawing; Semantic segmentation; Pencil lines; Tone rendering
ID IMAGE; SEGMENTATION; EXTRACTION
AB Pencil drawing is recognized as a typical non-photorealistic visual art form. It is attractive to automatically generate high-quality pencil drawings from real-world photographs. Traditional model-based methods are highlighted in their interpretability, but are limited in modeling scene semantics, leading to weak sketch lines or limited pencil tone rendering effects. To address this issue, we propose a novel pencil drawing generation method via explicitly leveraging image semantic information. Specifically, the sketch lines generated from the weak boundaries can be boosted by fusing the segmented boundaries. In addition, the segmentation mask provides the spatial guidance for diversifying the tone shading effects. By combining the enhanced pencil drawing patterns, the visual quality of the generated pencil drawings can be therefore strengthened. We conduct several experiments to validate the effectiveness of our method, including ablation studies and comparison with other methods, in which promising results can be obtained.
C1 [Li, Teng; Xie, Jianyu; Niu, Hongliang; Hao, Shijie] Hefei Univ Technol, Hefei 230009, Peoples R China.
C3 Hefei University of Technology
RP Hao, SJ (corresponding author), Hefei Univ Technol, Hefei 230009, Peoples R China.
EM tengli.terry@gmail.com; lxjzxjy@gmail.com; twlk139alien@gmail.com;
   hfut.hsj@gmail.com
OI Li, Teng/0000-0002-6235-327X
FU National Undergraduate Innovation and En-trepreneurship Training Program
   [202010359089]
FX The research was supported by the National Undergraduate Innovation and
   En-trepreneurship Training Program with Grant No. 202010359089.
CR Agrawal A, 2009, IEEE COMPUT GRAPH, V29, P81, DOI 10.1109/MCG.2009.61
   Al-nasrawi M, 2019, MULTIMED TOOLS APPL, V78, P6385, DOI 10.1007/s11042-018-6377-7
   Bychkovsky V, 2011, PROC CVPR IEEE, P97
   Chen L, 2019, IEEE T MULTIMEDIA, V21, P2664, DOI 10.1109/TMM.2019.2907052
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen ZY, 2008, LECT NOTES COMPUT SC, V5353, P931, DOI 10.1007/978-3-540-89796-5_117
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Ge QB, 2020, IEEE T SYST MAN CY-S, V50, P899, DOI 10.1109/TSMC.2017.2760900
   HAO S, 2020, IEEE ACCESS, V8
   Hao SJ, 2020, NEUROCOMPUTING, V406, P302, DOI 10.1016/j.neucom.2019.11.118
   Hao YB, 2020, IEEE T MULTIMEDIA, V22, P188, DOI 10.1109/TMM.2019.2923121
   Hong R, 2020, ARXIV200511034
   Inoue N, 2019, COMPUT GRAPH FORUM, V38, P69, DOI 10.1111/cgf.13817
   Kong Qunye, 2018, IEEE INT C MULT EXP, P1
   Lee H., 2006, NPAR 2006, P37, DOI [10. 1145/1124728. 1124735, DOI 10.1145/1124728.1124735]
   Li GB, 2017, IEEE COMPUT GRAPH, V37, P70, DOI 10.1109/MCG.2016.37
   Li H., 2019, P IEEE CVF C COMP VI, P9522, DOI [DOI 10.1109/CVPR.2019.00975, 10.1109/CVPR.2019.00975]
   Li YJ, 2019, PROC CVPR IEEE, P1525, DOI 10.1109/CVPR.2019.00162
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu Cewu., 2012, Proc. NPAR, P65
   Lu P, 2015, MULTIMED TOOLS APPL, V74, P9697, DOI 10.1007/s11042-014-2146-4
   Mao X, 2002, ACM SIGGRAPH 2002 C, P149, DOI DOI 10.1145/1242073.1242162
   Mukundan R, 2015, INT C WORKSH COMP CO, P1
   Ouhyoung M., 2009, J SYST SIMUL, V14, P1220
   Paszke A., 2016, ARXIV160602147
   Qiu JY, 2019, IEEE ACCESS, V7, P83543, DOI 10.1109/ACCESS.2019.2924658
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Son MJ, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P333, DOI 10.1109/PG.2007.63
   Winnemoller H., 2011, P ACM SIGGRAPH EUR S, P147
   Xiangtai Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P435, DOI 10.1007/978-3-030-58520-4_26
   Xie JY, 2020, PATTERN RECOGN LETT, V138, P308, DOI 10.1016/j.patrec.2020.07.041
   Yan DK, 2019, COMPUT GRAPH FORUM, V38, P91, DOI 10.1111/cgf.13819
   Yu J, 2018, SIGNAL PROCESS, V143, P346, DOI 10.1016/j.sigpro.2017.07.009
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng YP, 2019, IEEE ACCESS, V7, P184950, DOI 10.1109/ACCESS.2019.2960877
NR 38
TC 2
Z9 2
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34245
EP 34262
DI 10.1007/s11042-021-11028-2
EA MAY 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000655178800004
DA 2024-07-18
ER

PT J
AU Wu, HY
   Calabrèse, A
   Kornprobst, P
AF Wu, Hui-Yin
   Calabrese, Aurelie
   Kornprobst, Pierre
TI Towards accessible news reading design in virtual reality for low vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Accessible interfaces; Multimedia reading; Low vision; Virtual reality
ID TECHNOLOGY; PSYCHOPHYSICS; PERCEPTIONS; PERFORMANCE; IPAD; AIDS
AB Low-vision conditions resulting in partial loss of the central visual field strongly affect patients' daily tasks and routines, and none more prominently than the ability to access text. Though vision aids such as magnifiers, digital screens, and text-to-speech devices can improve overall accessibility to text, news media, which is non-linear and has complex and volatile formatting, is still inaccessible, barring low-vision patients from easy access to essential news content. This position paper proposes virtual reality as a promising solution towards accessible and enjoyable news reading for low vision. We first provide an extensive review into existing research on low-vision reading technologies and visual accessibility solutions for modern news media. From previous research and studies, we then conduct an analysis into the advantages of virtual reality for low-vision reading and propose comprehensive guidelines for visual accessibility design in virtual reality, with a focus on reading. This is coupled with a hands-on survey of eight reading applications in virtual reality to evaluate how accessibility design is currently implemented in existing products. Finally, we present an open toolbox using browser-based graphics (WebGL) that implements the design principles from our study. A proof-of-concept is created using this toolbox to demonstrate the feasibility of our proposal with modern virtual reality technology.
C1 [Wu, Hui-Yin; Calabrese, Aurelie; Kornprobst, Pierre] Univ Cote Azur, INRIA, 2004 Route Lucioles,BP 93, F-06902 Sophia Antipolis, France.
C3 Inria; Universite Cote d'Azur
RP Wu, HY (corresponding author), Univ Cote Azur, INRIA, 2004 Route Lucioles,BP 93, F-06902 Sophia Antipolis, France.
EM hui-yin.wu@inria.fr; aurelie.calabrese@inria.fr;
   pierre.kornprobst@inria.fr
OI Wu, Hui-Yin/0000-0001-7315-210X; Kornprobst, Pierre/0000-0003-4906-1368;
   Calabrese, Aurelie/0000-0002-7078-3595
FU French government, through the UCAJEDI Investments in the Future project
   [ANR-15-IDEX-01]
FX This work has been supported by the French government, through the
   UCAJEDI Investments in the Future project managed by the National
   Research Agency (ANR) with the reference number ANR-15-IDEX-01
CR AGUILAR C, 2017, PLOS ONE, V12
   Ajita M, 2015, MEDIUM
   Alhéritière H, 2017, PROC INT CONF DOC, P1126, DOI 10.1109/ICDAR.2017.186
   [Anonymous], 1999, PAPYRUS LHYPERTEXTE
   [Anonymous], 2013, P SIGCHI C HUMAN FAC
   Arleo, 2017, J AGING SCI, V6
   Beckmann PJ, 1996, VISION RES, V36, P3723, DOI 10.1016/0042-6989(96)00084-3
   Benoit M, 2015, NEUROPSYCH DIS TREAT, V11, P557, DOI 10.2147/NDT.S73179
   Bernard Jean-Baptiste, 2008, WORKSH COMP VIS APPL
   Boumenir Y, 2012, P 9 INT C DIS VIRT R, P111
   Bragg D, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P481, DOI 10.1145/3126594.3126660
   Calabrèse A, 2018, J VISION, V18, DOI 10.1167/18.1.8
   de Gelder B, 2018, BRIT J PSYCHOL, V109, P421, DOI 10.1111/bjop.12308
   Deemer AD, 2018, OPTOMETRY VISION SCI, V95, P694, DOI 10.1097/OPX.0000000000001278
   Everingham MR., 1998, INT J VIRTUAL REALIT, V3, P1, DOI [10.20870/IJVR.1998.3.4.2629, DOI 10.20870/IJVR.1998.3.4.2629]
   Frohlich DM, 2017, INT J HUM-COMPUT ST, V104, P36, DOI 10.1016/j.ijhcs.2017.03.002
   Gill K, 2013, EYE, V27, P639, DOI 10.1038/eye.2013.14
   Gutiérrez J, 2018, SIGNAL PROCESS-IMAGE, V69, P35, DOI 10.1016/j.image.2018.05.003
   Dai-Ton H, 2016, PATTERN RECOGN LETT, V80, P137, DOI 10.1016/j.patrec.2016.06.011
   Haji SA, 2015, CLIN OPHTHALMOL, V9, P17, DOI 10.2147/OPTH.S73193
   Harper R, 1999, BRIT J OPHTHALMOL, V83, P495, DOI 10.1136/bjo.83.4.495
   Heinz M, 2013, J GERONTOL NURS, V39, P42, DOI 10.3928/00989134-20121204-04
   Hersh M., 2010, Assistive technology for visually impaired and blind people
   Holmqvist K., 2005, LUND U COGNITIVE STU, V127, P1
   Huygelier H, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41200-6
   IHLSTROM C, 2004, P ICCC 8 INT C EL PU, P249
   Kjera, 2017, TEACH PEOPLE LOW VIS
   Knowles B, 2018, COMMUN ACM, V61, P72, DOI 10.1145/3179995
   Köpper M, 2016, ERGONOMICS, V59, P615, DOI 10.1080/00140139.2015.1100757
   Kornprobst, 2019, RR9281 UCA INR
   Latham K, 2018, VISION RES, V153, P47, DOI 10.1016/j.visres.2018.09.009
   LEGGE GE, 1989, OPTOMETRY VISION SCI, V66, P843, DOI 10.1097/00006324-198912000-00008
   Legge Gordon E, 2016, Visible Lang, V50, P102
   Legge GE, 2011, J VISION, V11, DOI 10.1167/11.5.8
   Maidenbaum S, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0072555
   Margrain TH, 2000, BRIT J OPHTHALMOL, V84, P919, DOI 10.1136/bjo.84.8.919
   McCrindle, 2017, J ALTERNAT MED RES, V9
   McGinley, 2016, DESIGN LOW VISION AI
   Mitchell Amy, 2018, Americans Still Prefer Watching to Reading the News-and Mostly Still through Television
   Mitchell PE, 2001, PROC INT CONF DOC, P1181, DOI 10.1109/ICDAR.2001.953971
   Moshtael H, 2016, SMART INNOV SYST TEC, V60, P71, DOI 10.1007/978-3-319-39687-3_7
   Moshtael H, 2015, TRANSL VIS SCI TECHN, V4, DOI 10.1167/tvst.4.4.6
   Peli E, 2007, SID INT SYMP DIG TEC, V38, P1074, DOI 10.1889/1.2785492
   Roussel, 2014, LOOKING FORWARD
   Strecker T, 2010, P 1 WORKSH SEM PERS, P8
   Syed-Abdul S, 2019, BMC GERIATR, V19, DOI 10.1186/s12877-019-1218-8
   Szpiro S, 2016, ASSETS'16: PROCEEDINGS OF THE 18TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P171, DOI 10.1145/2982142.2982168
   Takagi H., 2004, ASSETS 2004. The Sixth International ACM SIGACCESS Conference on Computers and Accessibility, P177
   TEOFILO M, 2018, IEEE ICCE
   Trauzettel-Klosinski S, 2012, INVEST OPHTH VIS SCI, V53, P5452, DOI 10.1167/iovs.11-8284
   Trewin S., 2008, P 10 INT ACM SIGACCE, P177, DOI [10.1145/1414471.1414504event-place, DOI 10.1145/1414471.1414504EVENT-PLACE, 10.1145/1414471.1414504, DOI 10.1145/1414471.1414504]
   Vaportzis E, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01687
   Walker R, 2016, OPHTHAL PHYSL OPT, V36, P459, DOI 10.1111/opo.12296
   Zambarbieri D, 2012, OPHTHAL PHYSL OPT, V32, P390, DOI 10.1111/j.1475-1313.2012.00930.x
   ZHAO YH, 2019, P ACM CHI C HUM FACT
NR 55
TC 2
Z9 2
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27259
EP 27278
DI 10.1007/s11042-021-10899-9
EA MAY 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000651019800001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Taha, M
   Ali, A
   Lloret, J
   Gondim, PRL
   Canovas, A
AF Taha, Miran
   Ali, Aree
   Lloret, Jaime
   Gondim, Paulo R. L.
   Canovas, Alejandro
TI An automated model for the assessment of QoE of adaptive video streaming
   over wireless networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HTTP adaptive streaming; Correlation coefficient; QoE; QoS; Subjective
   methodology
ID QUALITY ASSESSMENT; HTTP; EXPERIENCE
AB Nowadays, heterogeneous devices are widely utilizing Hypertext Transfer Protocol (HTTP) to transfer the data. Furthermore, HTTP adaptive video streaming (HAS) technology transmits the video data over wired and wireless networks. In adaptive technology services, a client's application receives a streaming video through the adaptation of its quality to the network condition. However, such a technology has increased the demand for Quality of Experience (QoE) in terms of prediction and assessment. It can also cause a challenging behavior regarding subjective and objective QoE evaluations of HTTP adaptive video over time since each Quality of Service (QoS) parameter affects the QoE of end-users separately. This paper introduces a methodology design for the evaluation of subjective QoE in adaptive video streaming over wireless networks. Besides, some parameters are considered such as video characteristics, segment length, initial delay, switch strategy, stalls, as well as QoS parameters. The experiment's evaluation demonstrated that objective metrics can be mapped to the most significant subjective parameters for user's experience. The automated model could function to demonstrate the importance of correlation for network behaviors' parameters. Consequently, it directly influences the satisfaction of the end-user's perceptual quality. In comparison with other recent related works, the model provided a positive Pearson Correlation value. Simulated results give a better performance between objective Structural Similarity (SSIM) and subjective Mean Opinion Score (MOS) evaluation metrics for all video test samples.
C1 [Taha, Miran; Ali, Aree] Univ Sulaimani, Dept Comp Sci, Sulaymaniyah, Iraq.
   [Taha, Miran; Lloret, Jaime; Gondim, Paulo R. L.; Canovas, Alejandro] Univ Politecn Valencia, Integrated Management Coastal Res Inst, Valencia, Spain.
   [Ali, Aree] Univ Halabja, Comp Dept, Coll Sci, Halabja, Iraq.
   [Gondim, Paulo R. L.] Univ Brasilia, Brasilia, DF, Brazil.
C3 University of Sulimanyah; Universitat Politecnica de Valencia;
   Universidade de Brasilia
RP Lloret, J (corresponding author), Univ Politecn Valencia, Integrated Management Coastal Res Inst, Valencia, Spain.
EM miran.abdullah@univsul.edu.iq; aree.ali@univsul.edu.iq;
   jlloret@dcom.upv.es; pgondim@unb.br; alcasol@upvnet.upv.es
RI Cánovas, Alejandro/HZI-5828-2023; Taha, Miran/L-6071-2019; DE LIRA
   GONDIM, PAULO ROBERTO/N-1847-2015; Lloret, Jaime/H-3994-2013
OI Taha, Miran/0000-0002-3501-6999; DE LIRA GONDIM, PAULO
   ROBERTO/0000-0002-7007-1969; Lloret, Jaime/0000-0002-0862-0533; Canovas
   Solbes, Alejandro/0000-0002-0422-0161
FU "Ministerio de Economia y Competitividad" in the "Programa Estatal de
   Fomento de la Investigacion Cientifica y Tecnica de Excelencia,
   Subprograma Estatal de Generacion de Conocimiento"
   [TIN2017-84802-C2-1-P]
FX This work has been partially supported by the "Ministerio de Economia y
   Competitividad" in the "Programa Estatal de Fomento de la Investigacion
   Cientifica y Tecnica de Excelencia, Subprograma Estatal de Generacion de
   Conocimiento" within the Project under Grant TIN2017-84802-C2-1-P. This
   study has been partially done in the computer science departments at the
   (University of Sulaimani and Halabja).
CR Abar T, 2018, 2018 32ND INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA), P258, DOI 10.1109/WAINA.2018.00095
   Abdullah M., 2016, Proceedings of the 9th EAI International Conference on Mobile Multimedia Communications, P65, DOI DOI 10.4108/EAI.18-62016.2264163
   [Anonymous], 2018, PROC 16 INT S MODEL
   [Anonymous], 2017, IEEE INT C COMM ICC, DOI DOI 10.1109/ICC.2017.7996499
   [Anonymous], 2017, PARAMETRIC BITSTREAM
   [Anonymous], 2012, ABSOLUTE CATEGORY RA
   Barman N, 2020, INT J NETW MANAG, V30, DOI 10.1002/nem.2054
   Barman N, 2019, IEEE ACCESS, V7, P74511, DOI 10.1109/ACCESS.2019.2920477
   Barman N, 2019, IEEE ACCESS, V7, P30831, DOI 10.1109/ACCESS.2019.2901778
   Bulkan U, 2019, MULTIMED TOOLS APPL, V78, P18787, DOI 10.1007/s11042-019-7164-9
   Chen YJ, 2015, IEEE COMMUN SURV TUT, V17, P1126, DOI 10.1109/COMST.2014.2363139
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Claeys M, 2014, IEEE COMMUN LETT, V18, P716, DOI 10.1109/LCOMM.2014.020414.132649
   Cofano G, 2016, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON MULTIMEDIA SYSTEMS (MMSYS'16), P24, DOI 10.1145/2910017.2910597
   Duanmu ZF, 2017, IEEE J-STSP, V11, P154, DOI 10.1109/JSTSP.2016.2608329
   Garcia B, 2019, J ELECT, V9, DOI [10.3390/electronics8080854, DOI 10.3390/ELECTRONICS8080854]
   García L, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1117, DOI 10.1109/ICACCI.2016.7732194
   Gutterman C, 2019, PROCEEDINGS OF THE 10TH ACM MULTIMEDIA SYSTEMS CONFERENCE (ACM MMSYS'19), P48, DOI 10.1145/3304109.3306226
   Hao Zeng, 2013, Advanced Materials Research, V756-759, P1748, DOI 10.4028/www.scientific.net/AMR.756-759.1748
   Juluri P, 2016, IEEE COMMUN SURV TUT, V18, P401, DOI 10.1109/COMST.2015.2401424
   Li MF, 2018, INT J DIGIT MULTIMED, V2018, DOI 10.1155/2018/2619438
   Li Wenjing, 2017, Journal of China Universities of Posts and Telecommunications, V24, P24, DOI 10.1016/S1005-8885(17)60208-5
   Liu XN, 2018, IEEE T VEH TECHNOL, V67, P12204, DOI 10.1109/TVT.2018.2874258
   Mok R.K., 2012, P 3 MULTIMEDIA SYSTE, P11
   Moorthy AK, 2010, IEEE T CIRC SYST VID, V20, P587, DOI 10.1109/TCSVT.2010.2041829
   Nam H, 2016, IEEE INFOCOM SER
   Nunome T., 2017, INT J COMPUT NETW CO, V9, P2, DOI [10.5121/ijcnc.2017.9201, DOI 10.5121/IJCNC.2017.9201]
   Nunome T, 2019, 2019 26TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (ICT), P149, DOI [10.1109/ICT.2019.8798643, 10.1109/ict.2019.8798643]
   Orsolic I, 2017, MULTIMED TOOLS APPL, V76, P22267, DOI 10.1007/s11042-017-4728-4
   Pal D, 2017, PROCEDIA COMPUT SCI, V111, P214, DOI 10.1016/j.procs.2017.06.056
   Petrangeli S, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3165266
   Rodrigues F, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/9736360
   Schatz R, 2017, INT WORK QUAL MULTIM
   Seufert M, 2015, IEEE COMMUN SURV TUT, V17, P469, DOI 10.1109/COMST.2014.2360940
   Singh S, 2012, IEEE J SEL AREA COMM, V30, P1259, DOI 10.1109/JSAC.2012.120811
   Stensen JMG, 2012, THESIS I TELEMATIKK, DOI [10.12142/ZTECOM.201901004, DOI 10.12142/ZTECOM.201901004]
   Streijl RC, 2016, MULTIMEDIA SYST, V22, P213, DOI 10.1007/s00530-014-0446-1
   Su GM, 2016, WIREL NETW, V22, P1571, DOI 10.1007/s11276-015-1028-7
   Taha M, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3551
   Timmerer C, 2019, ZTE COMMUNICATIONS, V17
   Trakas P., 2017, IEEE ICC COMM QOS RE
   Thang TC, 2013, J COMMUN NETW-S KOR, V15, P635, DOI 10.1109/JCN.2013.000112
   Villa BJ., 2012, INT J ADV NETWORKS S, V5, P4
   Wang QY, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1180-8
   Xu YD, 2014, IEEE T MOBILE COMPUT, V13, P2734, DOI 10.1109/TMC.2014.2307323
   Zhang WW, 2013, IEEE T MULTIMEDIA, V15, P1431, DOI 10.1109/TMM.2013.2247583
   Zhao TS, 2017, IEEE COMMUN SURV TUT, V19, P285, DOI 10.1109/COMST.2016.2619982
NR 47
TC 16
Z9 16
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26833
EP 26854
DI 10.1007/s11042-021-10934-9
EA MAY 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000648855400001
DA 2024-07-18
ER

PT J
AU Zou, GF
   Fu, GX
   Peng, X
   Liu, Y
   Gao, ML
   Liu, Z
AF Zou, Guofeng
   Fu, Guixia
   Peng, Xiang
   Liu, Yue
   Gao, Mingliang
   Liu, Zheng
TI Person re-identification based on metric learning: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distance metric; Classical metric learning; Deep metric learning;
   Re-ranking; Person re-identification; Survey
AB Person re-identification is a challenging research issue in computer vision and has a broad application prospect in intelligent security. In recent years, with the emergence of large-scale person datasets and the rapid development of deep learning, many outstanding results have been achieved in person re-identification researches, which mainly involves two critical technologies: feature extraction and distance metric. Among them, feature extraction has been well summarized in the current literature of person re-identification, but there is no systematic analysis of the distance metric method in the current review literature. However, effective and reliable distance metric is crucial to improve the accuracy of person re-identification. Therefore, it is necessary to systematically review and summarize the metric learning methods in person re-identification, so as to provide some references for the researchers of metric learning. In this paper, we make a comprehensive analysis of metric learning methods in the past five years, which can be summarized into three aspects: distance metric method, metric learning algorithm, and re-ranking for the metric results. Then, we compare the performance of some representative metric learning methods and discuss them in-depth. Finally, we make a prospect for the future research direction of metric learning in person re-identification.
C1 [Zou, Guofeng; Fu, Guixia; Liu, Yue; Gao, Mingliang] Shandong Univ Technol, Sch Elect & Elect Engn, Zibo 255049, Peoples R China.
   [Peng, Xiang; Liu, Zheng] Univ British Columbia, Sch Engn, Kelowna, BC V1V 1V7, Canada.
C3 Shandong University of Technology; University of British Columbia
RP Zou, GF (corresponding author), Shandong Univ Technol, Sch Elect & Elect Engn, Zibo 255049, Peoples R China.
EM gfzou@sdut.edu.cn
RI Gao, Mingliang/AEK-9687-2022; Liu, Zheng/D-8678-2016
OI Liu, Zheng/0000-0002-7241-3483; Zou, Guofeng/0000-0002-8023-0142
FU Visiting Project Funds of Shandong University of Technology; Integration
   Funds of Shandong University of Technology; National Natural Science
   Foundation of China [61601266, 61801272]; Natural Science Foundation of
   Shandong Province of China [ZR2015FL029, ZR2016FL14];  [118228]
FX This work was funded by the Visiting Project Funds of Shandong
   University of Technology, the Integration Funds of Shandong University
   of Technology and Zhangdian District (No.118228), the National Natural
   Science Foundation of China (No. 61601266, No.61801272), the Natural
   Science Foundation of Shandong Province of China (No. ZR2015FL029,
   ZR2016FL14).
CR Ali M, 2018, P EUROPEAN C COMPUTE, P122
   An L, 2016, NEUROCOMPUTING, V182, P247, DOI 10.1016/j.neucom.2015.12.029
   Arpan B, 2020, P IEEE INT C IM PROC, P2356, DOI [10.1109/ICIP40778.2020.9190744, DOI 10.1109/ICIP40778.2020.9190744]
   Barman A, 2017, 2017 IEEE INTERNATIONAL SYMPOSIUM ON TECHNOLOGIES FOR HOMELAND SECURITY (HST)
   Barman A, 2017, IEEE I CONF COMP VIS, P1124, DOI 10.1109/ICCV.2017.127
   Bedagkar-Gala A, 2014, IMAGE VISION COMPUT, V32, P270, DOI 10.1016/j.imavis.2014.02.001
   Borgia A, 2018, IEEE T IMAGE PROCESS, V27, P5338, DOI 10.1109/TIP.2018.2851098
   Cai, 2010, LECT NOTES COMPUT SC, P205
   Chen B, 2018, J ELECTRON INF TECHN, V40, P2381, DOI 10.11999/JEIT180184
   Chen DP, 2018, PROC CVPR IEEE, P8649, DOI 10.1109/CVPR.2018.00902
   Chen L, 2018, PATTERN RECOGN LETT, P1
   Chen SZ, 2016, IEEE T IMAGE PROCESS, V25, P2353, DOI 10.1109/TIP.2016.2545929
   Chen YC, 2017, IEEE T CIRC SYST VID, V27, P1661, DOI 10.1109/TCSVT.2016.2515309
   Cheng D, 2018, MULTIMED TOOLS APPL, V77, P3533, DOI 10.1007/s11042-017-5182-z
   Cho YJ, 2018, IEEE T IMAGE PROCESS, V27, P3739, DOI 10.1109/TIP.2018.2815840
   De Maesschalck R, 2000, CHEMOMETR INTELL LAB, V50, P1, DOI 10.1016/S0169-7439(99)00047-7
   Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI 10.1109/TP'AMI.2007.1115
   Dikmen M, 2011, LECT NOTES COMPUT SC, V6495, P501, DOI 10.1007/978-3-642-19282-1_40
   [丁宗元 Ding Zongyuan], 2017, [计算机研究与发展, Journal of Computer Research and Development], V54, P1785
   Dong HS, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3234929
   Dong HS, 2017, IET COMPUT VIS, V11, P455, DOI 10.1049/iet-cvi.2016.0265
   [杜宇宁 Du Yuning], 2016, [计算机学报, Chinese Journal of Computers], V39, P1639
   Feng YC, 2021, IEEE T CYBERNETICS, V51, P1849, DOI 10.1109/TCYB.2019.2909480
   Feng ZX, 2018, IEEE T IMAGE PROCESS, V27, P3472, DOI 10.1109/TIP.2018.2818438
   García J, 2017, IEEE T IMAGE PROCESS, V26, P1650, DOI 10.1109/TIP.2017.2652725
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   He BT, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.3.033005
   He ZP, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1957, DOI 10.1109/ICASSP.2018.8462118
   Hou RB, 2021, IEEE T NEUR NET LEAR, V32, P4460, DOI 10.1109/TNNLS.2020.3017939
   Jacques JCS Jr, 2018, IMAGE VISION COMPUT, V79, P76, DOI 10.1016/j.imavis.2018.08.001
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leng QM, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/3586191
   Leng QM, 2015, MULTIMED TOOLS APPL, V74, P6989, DOI 10.1007/s11042-014-1949-7
   Li K, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1492, DOI 10.1145/3240508.3240674
   Li W, 2015, NEUROCOMPUTING, V167, P280, DOI 10.1016/j.neucom.2015.04.068
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   [李幼蛟 Li Youjiao], 2018, [自动化学报, Acta Automatica Sinica], V44, P1554
   Li Z, 2018, ADV MULTIMED, V2018
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Ling HF, 2019, NEUROCOMPUTING, V347, P109, DOI 10.1016/j.neucom.2019.01.027
   Liu XK, 2016, IET COMPUT VIS, V10, P366, DOI 10.1049/iet-cvi.2014.0288
   Liu ZM, 2019, IEEE T NEUR NET LEAR, V30, P2999, DOI 10.1109/TNNLS.2018.2890289
   [罗浩 Luo Hao], 2019, [自动化学报, Acta Automatica Sinica], V45, P2032
   Ma AJ, 2015, IEEE T IMAGE PROCESS, V24, P1599, DOI 10.1109/TIP.2015.2395715
   McLaughlin N, 2017, IEEE T CIRC SYST VID, V27, P525, DOI 10.1109/TCSVT.2016.2619498
   Olszewska J.I., 2016, PATTERN RECOGN, P59
   Pang YW, 2019, IEEE T INF FOREN SEC, V14, P3322, DOI 10.1109/TIFS.2019.2916592
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Porikli F, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P133
   [齐美彬 Qi Meibin], 2016, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V29, P511
   [齐美彬 Qi Meibin], 2016, [自动化学报, Acta Automatica Sinica], V42, P299
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sikdar A, 2020, PATTERN RECOGN LETT, V129, P279, DOI 10.1016/j.patrec.2019.11.032
   Syed MA, 2016, IEEE IMAGE PROC, P784, DOI 10.1109/ICIP.2016.7532464
   Tan FG, 2017, CHINESE J ELECTRON, V26, P905, DOI 10.1049/cje.2016.08.007
   Tan SB, 2018, IEEE T CIRC SYST VID, V28, P356, DOI 10.1109/TCSVT.2016.2555739
   Tao DP, 2013, IEEE T CIRC SYST VID, V23, P1675, DOI 10.1109/TCSVT.2013.2255413
   Wang JY, 2018, PATTERN RECOGN, V74, P241, DOI 10.1016/j.patcog.2017.09.024
   Wang J, 2018, PATTERN RECOGN, V74, P38, DOI 10.1016/j.patcog.2017.09.014
   Wang J, 2017, IEEE T CIRC SYST VID, V27, P513, DOI 10.1109/TCSVT.2016.2586851
   Wang XJ, 2016, IEEE T CIRC SYST VID, V26, P1447, DOI 10.1109/TCSVT.2015.2450331
   Weinberger K.Q., 2008, Proceedings of the 25th international conference on Machine learning, P1160, DOI DOI 10.1145/1390156.1390302
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Xie Y, 2017, IEEE SIGNAL PROC LET, V24, P853, DOI 10.1109/LSP.2017.2679208
   Xie Y, 2016, ELECTRON LETT, V52, P1447, DOI 10.1049/el.2016.2109
   Yang X, 2019, IEEE T NEUR NET LEAR, V30, P2987, DOI [10.1109/TNNLS.2018.2861991, 10.1109/TNNLS.2018.2790479]
   Ye M, 2016, IEEE T MULTIMEDIA, V18, P2553, DOI 10.1109/TMM.2016.2605058
   Yu BZ, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.3.033033
   Yu HX, 2017, IEEE I CONF COMP VIS, P994, DOI 10.1109/ICCV.2017.113
   Yuan CH, 2019, MULTIMED TOOLS APPL, V78, P21145, DOI 10.1007/s11042-019-7446-2
   Zhang Z, 2018, IEEE INTERNET THINGS, V5, P3361, DOI 10.1109/JIOT.2017.2746901
   Zhang ZM, 2017, IEEE T CIRC SYST VID, V27, P499, DOI 10.1109/TCSVT.2016.2596159
   Zhao CR, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.107014
   Zhao XB, 2018, IEEE T NEUR NET LEAR, V29, P3701, DOI 10.1109/TNNLS.2017.2736640
   Zheng WS, 2016, IEEE T PATTERN ANAL, V38, P591, DOI 10.1109/TPAMI.2015.2453984
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
   Zhou JH, 2018, PROC CVPR IEEE, P5373, DOI 10.1109/CVPR.2018.00563
   Zhou Q, 2016, INT CONF ACOUST SPEE, P1546, DOI 10.1109/ICASSP.2016.7471936
   Zhou SP, 2018, IEEE T MULTIMEDIA, V20, P593, DOI 10.1109/TMM.2017.2755983
   Zhou ZH, 2019, J ELECTRON INF TECHN, V41, P477, DOI 10.11999/JEIT180336
   Zhu FQ, 2018, MULTIMED TOOLS APPL, V77, P3049, DOI 10.1007/s11042-017-5009-y
   Zhu JQ, 2018, IEEE T CIRC SYST VID, V28, P3183, DOI 10.1109/TCSVT.2017.2734740
NR 88
TC 22
Z9 23
U1 7
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26855
EP 26888
DI 10.1007/s11042-021-10953-6
EA MAY 2021
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000648855400002
DA 2024-07-18
ER

PT J
AU Sharma, N
   Sohi, PJS
   Garg, B
   Arya, KV
AF Sharma, Nikhil
   Sohi, Prateek Jeet Singh
   Garg, Bharat
   Arya, K., V
TI A novel multilayer decision based iterative filter for removal of salt
   and pepper noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salt and Pepper noise; Mean filter; Median filter; Combinational
   filtering; Image denoising; Decision based filtering
AB In this paper a novel decision based iterative filter for the detection and elimination of salt and pepper noise is proposed. Effective decisions based upon the noise density of the image are used to filter out noise while maintaining finer details in an image. A fixed size window is used at each step to maintain maximum correlation throughout the filtering process. Additional pre-edge and post-smoothing processing are also presented to further enhance the quality of image. Rigorous analysis over Kodak benchmark dataset containing 24 natural images indicates an exceptional performance boost for medium to extremely high noise density when compared with state of the art filtering techniques. The proposed filter is tested quantitatively and qualitatively using benchmark parameters including peak signal to noise ratio, image enhancement factor and visual representation. Even at noise density as high as 90% and 95%, the proposed filter outperforms the exiting filters providing better edge detail, less blurring and low streaking effects.
C1 [Sharma, Nikhil; Sohi, Prateek Jeet Singh; Garg, Bharat] Thapar Inst Engn & Technol, Patiala, Punjab, India.
   [Arya, K., V] ABV Indian Inst Informat Technol & Management Gwa, Gwalior, Madhya Pradesh, India.
C3 Thapar Institute of Engineering & Technology; ABV-Indian Institute of
   Information Technology & Management, Gwalior
RP Garg, B (corresponding author), Thapar Inst Engn & Technol, Patiala, Punjab, India.
EM bharat.garg@thapar.edu
RI Garg, Bharat/GPP-5755-2022
OI Garg, Bharat/0000-0002-2904-3720; Sharma, Nikhil/0000-0003-1681-7907
CR Enginoglu S, 2019, MULTIMED TOOLS APPL, V78, P35401, DOI 10.1007/s11042-019-08110-1
   Erkan U, 2018, COMPUT ELECTR ENG, V70, P789, DOI 10.1016/j.compeleceng.2018.01.019
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Garg B, 2020, SIGNAL IMAGE PROCESS
   Garg B, 2020, INT J AD HOC UBIQ CO, V35, P84, DOI 10.1504/IJAHUC.2020.109795
   Garg B, 2020, MULTIMED TOOLS APPL, V79, P32305, DOI 10.1007/s11042-020-09557-3
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Lu CT, 2016, PATTERN RECOGN LETT, V80, P188, DOI 10.1016/j.patrec.2016.06.026
   Meher SK, 2014, AEU-INT J ELECTRON C, V68, P1173, DOI 10.1016/j.aeue.2014.06.006
   Selvi AS, 2020, MULTIMED TOOLS APPL, V79, P4115, DOI 10.1007/s11042-019-7727-9
   Sohi P. J. S., 2020, INNOVATIONS COMPUTAT, P150
   Veerakumar T, 2014, SIGNAL IMAGE VIDEO P, V8, P159, DOI 10.1007/s11760-013-0517-3
   Vijaykumar VR, 2014, AEU-INT J ELECTRON C, V68, P1145, DOI 10.1016/j.aeue.2014.06.002
NR 14
TC 8
Z9 10
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26531
EP 26545
DI 10.1007/s11042-021-10958-1
EA MAY 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000646953200005
DA 2024-07-18
ER

PT J
AU Lee, JS
   Liu, C
   Chen, YC
   Hung, WC
   Li, B
AF Lee, Jung-San
   Liu, Chieh
   Chen, Ying-Chin
   Hung, Wei-Che
   Li, Bo
TI Robust 3D mesh zero-watermarking based on spherical coordinate and
   Skewness measurement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D mesh model; Zero-watermarking; Robustness; Spherical coordinate;
   Skewness
AB As the great advance in technology, 3D models are commonly used in multiple fields such as healthcare, filmdom, interactive entertainment, and construction industry. To prevent 3D data from unauthorized access and illegal tampering, we aim to propose a brand-new zero-watermarking technique based on the transformation of spherical coordinate and skewness of angle statistic. Without distorting the quality of 3D object, the main challenge in zero-watermarking is the robust feature selection and target construction. Since we have adopted the skewness measure of the spherical angle to be the resilient feature, the robustness can be highly enhanced. According to experimental results, the new method can stay stable under common signal processing operations such as translation, vertex reordering, uniform scaling, noise addition, smoothing, simplification, and cropping. This has demonstrated that the new method is suitable for the applications which need highly accurate 3D models.
C1 [Lee, Jung-San; Liu, Chieh; Chen, Ying-Chin; Hung, Wei-Che] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Li, Bo] Univ Illinois, Dept Comp Sci, Champaign, IL 61820 USA.
C3 Feng Chia University; University of Illinois System; University of
   Illinois Urbana-Champaign
RP Li, B (corresponding author), Univ Illinois, Dept Comp Sci, Champaign, IL 61820 USA.
EM leejs@fcu.edu.tw
OI Lee, Jung-San/0000-0001-7030-2985
CR Borah S, 2020, MULTIMED TOOLS APPL, V79, P11437, DOI 10.1007/s11042-019-08411-5
   Bors AG, 2013, IEEE T IMAGE PROCESS, V22, P1822, DOI 10.1109/TIP.2012.2236345
   Cho JW, 2007, IEEE T SIGNAL PROCES, V55, P142, DOI 10.1109/TSP.2006.882111
   Choi HY, 2017, MULTIMED TOOLS APPL, V76, P26695, DOI 10.1007/s11042-016-4194-4
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Kai Wang, 2010, Proceedings of the Shape Modeling International (SMI 2010), P231, DOI 10.1109/SMI.2010.33
   Kashida N, 2020, 35TH INTERNATIONAL TECHNICAL CONFERENCE ON CIRCUITS/SYSTEMS, COMPUTERS AND COMMUNICATIONS (ITC-CSCC 2020), P363
   Konstantinides JM, 2009, IEEE T MULTIMEDIA, V11, P23, DOI 10.1109/TMM.2008.2008913
   Liu J, 2017, NEUROCOMPUTING, V237, P304, DOI 10.1016/j.neucom.2016.12.065
   Liu Y, 2012, IEEE T INF FOREN SEC, V7, P1459, DOI 10.1109/TIFS.2012.2204251
   Medimegh N, 2015, INT J MULTIMEDIA, V1, P1, DOI DOI 10.16966/IJM.102
   Mouhamed M, 2019, 2019 9 INT C INT COM
   Narendra M, 2020, KSII T INTERNET INF, V14, P4042, DOI 10.3837/tiis.2020.10.007
   Ohbuchi R, 2002, COMPUT GRAPH FORUM, V21, P373, DOI 10.1111/1467-8659.t01-1-00597
   von Hippel P.T., 2005, J STAT ED, V13, DOI DOI 10.1080/10691898.2005.11910556
   Wang K, 2008, IEEE T MULTIMEDIA, V10, P1513, DOI 10.1109/TMM.2008.2007350
   Wang X, 2019, MULTIMED TOOLS APPL, V78, P27001, DOI 10.1007/s11042-017-4666-1
   Weisstein E.W., 2004, MATHWORLD
   Wen Quan, 2003, Acta Electronica Sinica, V31, P214
   Zhan YZ, 2014, J ZHEJIANG U-SCI C, V15, P351, DOI 10.1631/jzus.C1300306
NR 21
TC 6
Z9 7
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25757
EP 25772
DI 10.1007/s11042-021-10878-0
EA APR 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000642389300001
DA 2024-07-18
ER

PT J
AU Chakraborty, BK
   Bhuyan, MK
   MacDorman, KF
AF Chakraborty, Biplab Ketan
   Bhuyan, M. K.
   MacDorman, Karl F.
TI Skin detection in video under uncontrolled illumination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE First keyword; Second keyword; More
AB Many vision-based human-computer interaction (HCI) applications require skin detection. However, their performance relies on accuracy in detecting skin regions in video, which is difficult under uncontrolled illumination. The chromatic appearance of skin changes because of shading, often caused by body movement. To address this, we propose a dynamic adaptation method to detect skin regions affected by local color deformations. Static and dynamic skin regions are detected by a corresponding module. The static module includes a facial skin distribution model (FSDM) and a fusion-based background distribution model (FBDM). The FBDM is obtained from a local background distribution model (LBDM) and a global background distribution model (GBDM). The LBDM is obtained by comparing a frame pixel distribution model with the FSDM and GBDM. Next, the FBDM is derived from the LBDM and the GBDM. The dynamic module includes a moving skin distribution model (MSDM), derived from a set of moving skin samples. Initially, moving skin regions are detected using a modified double frame-difference method and then modeled using a Gaussian mixture model. To avoid misidentifying background regions as skin, the final MSDM is obtained by comparing the initial moving skin model to the FSDM and FBDM. Finally, the static and the dynamic models are fused by applying a maximization rule. Experimental results shows that the proposed method can detect skin regions more accurately than state-of-the-art methods.
C1 [Chakraborty, Biplab Ketan] Sankhyasutra Labs, Bengaluru, Karnataka, India.
   [Bhuyan, M. K.] IIT Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
   [MacDorman, Karl F.] Indiana Univ, Sch Informat & Comp, 535 West Michigan St, Indianapolis, IN 46202 USA.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati; Indiana University System; Indiana
   University Indianapolis
RP Bhuyan, MK (corresponding author), IIT Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
EM biplab.ketan@sankhyasutralabs.com; mkb@iitg.ernet.in
RI Bhuyan, Manoj Kumar/D-1562-2012
CR [Anonymous], 2018, 2018 4 INT C COMP CO
   [Anonymous], 2012, ARTIF INTELL REV, DOI DOI 10.1007/s10462-012-9356-9
   Avola D, 2019, IEEE T MULTIMEDIA, V21, P234, DOI 10.1109/TMM.2018.2856094
   Awad G, 2006, INT C PATT RECOG, P239
   Bhuyan M, 2020, MULTIMED TOOLS APPL, P1573
   Bianco S, 2015, IEEE T IMAGE PROCESS, V24, P4756, DOI 10.1109/TIP.2015.2467209
   Cao DY, 2018, CHIN CONT DECIS CONF, P5688, DOI 10.1109/CCDC.2018.8408124
   Carrara F, 2019, MULTIMED TOOLS APPL, V78, P27309, DOI 10.1007/s11042-019-07827-3
   Chakraborty BK, 2017, PATTERN RECOGN LETT, V88, P33, DOI 10.1016/j.patrec.2017.01.005
   CHUNG JK, 1989, J MATH ANAL APPL, V138, P280, DOI 10.1016/0022-247X(89)90335-1
   Chyad MA, 2019, IEEE ACCESS, V7, P106536, DOI 10.1109/ACCESS.2019.2924989
   Fouad RM, 2019, IEEE ACCESS, V7, P76513, DOI 10.1109/ACCESS.2019.2922304
   Garnavi R, 2017, DIG IM COMP 2017 INT, P1
   Habili N, 2004, IEEE T CIRC SYST VID, V14, P1086, DOI 10.1109/TCSVT.2004.831970
   Han J, 2009, IET COMPUT VIS, V3, P24, DOI 10.1049/iet-cvi:20080006
   Hettiarachchi R, 2016, J VIS COMMUN IMAGE R, V41, P123, DOI 10.1016/j.jvcir.2016.09.011
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Kameda Y., 1996, INT C VIRTUAL SYSTEM, P135
   Kawulok M, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553733
   Kawulok M, 2014, PATTERN RECOGN LETT, V41, P3, DOI 10.1016/j.patrec.2013.08.028
   Kawulok M, 2013, IEEE IMAGE PROC, P3720, DOI 10.1109/ICIP.2013.6738767
   Lei QJ, 2019, PROC SPIE, V11041, DOI 10.1117/12.2522962
   Lei Y, 2017, IEEE T MULTIMEDIA, V19, P740, DOI 10.1109/TMM.2016.2638204
   Liu LY, 2011, IEEE T CONSUM ELECTR, V57, P1295, DOI 10.1109/TCE.2011.6018887
   McBride TJ, 2019, 2019 SOUTHERN AFRICAN UNIVERSITIES POWER ENGINEERING CONFERENCE/ROBOTICS AND MECHATRONICS/PATTERN RECOGNITION ASSOCIATION OF SOUTH AFRICA (SAUPEC/ROBMECH/PRASA), P211, DOI [10.1109/RoboMech.2019.8704839, 10.1109/robomech.2019.8704839]
   Mo TP, 2020, SOFT COMPUT, V24, P5795, DOI 10.1007/s00500-019-04342-3
   Moreira DC, 2018, IEEE IJCNN
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pennisi A, 2016, COMPUT MED IMAG GRAP, V52, P89, DOI 10.1016/j.compmedimag.2016.05.002
   Phung SL, 2005, IEEE T PATTERN ANAL, V27, P148, DOI 10.1109/TPAMI.2005.17
   Ramasinghe S, 2019, IEEE T CIRC SYST VID, V29, P2693, DOI 10.1109/TCSVT.2017.2760858
   Sandbach G, 2012, IMAGE VISION COMPUT, V30, P683, DOI 10.1016/j.imavis.2012.06.005
   SanMiguel JC, 2013, PATTERN RECOGN LETT, V34, P2102, DOI 10.1016/j.patrec.2013.07.016
   Sigal L, 2004, IEEE T PATTERN ANAL, V26, P862, DOI 10.1109/TPAMI.2004.35
   Soriano M, 2003, PATTERN RECOGN, V36, P681, DOI 10.1016/S0031-3203(02)00089-4
   Tang CX, 2018, IEEE COMPUT SOC CONF, P1390, DOI 10.1109/CVPRW.2018.00178
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wachs JP, 2011, COMMUN ACM, V54, P60, DOI 10.1145/1897816.1897838
   Yang JC, 2018, IEEE CONSUM ELECTR M, V7, P64, DOI 10.1109/MCE.2017.2776500
   Zuo HQ, 2017, IEEE SIGNAL PROC LET, V24, P289, DOI 10.1109/LSP.2017.2654803
NR 40
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24319
EP 24341
DI 10.1007/s11042-021-10728-z
EA APR 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000636933000005
DA 2024-07-18
ER

PT J
AU Trivedi, N
   Alsadoon, A
   Prasad, PWC
   Abdullah, S
   Alrubaie, A
AF Trivedi, Niraj
   Alsadoon, Abeer
   Prasad, P. W. C.
   Abdullah, Salma
   Alrubaie, Ahmad
TI Enhanced classification loss functions and regularization loss function
   (ECLFaRLF) algorithm for bowel cancer feature classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Image recognition; Feature extraction; Neural network;
   Bowel cancer; Feature classification
AB Bowel cancer is one of the most common cancers as stated in the bowel cancer cases statistics. The proposed technique is to recognize the pattern of tissue affected by bowel cancer by using support vector machine (SVM) classification. This research aims to increase the accuracy of detecting and classifying bowel cancer with reduced processing time. The proposed method considered a feature extraction and image classification by Eenhanced Classification Loss Functions and Regularization Loss Function (ECLFaRLF) algorithm. This method allowed for more precise interpretations regarding the best associations for bowel cancer. The proposed was tested on colorectal images from different datasets commonly investigated in the proposed solution. The test was evaluated by applying 10-fold cross-validation method. All classification methods provide differentiation rate above processing time 0.413 s, and accuracy 95.67% for the state of the art solution, but by introducing SVM2 classification algorithm produce high accuracy rate with average accuracy is 97.02% over 95.67% and with processing time 0.359 s over 0.413 s. This reality shows the significance of the discriminating power of the SVM2 classifier. The proposed framework has presented an examination of feature extraction and classification techniques to help pathologists in the identifying of benign and malignant diagnosis of bowel cancer.
C1 [Trivedi, Niraj; Alsadoon, Abeer; Prasad, P. W. C.] Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.
   [Alsadoon, Abeer] Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Southern Cross Univ SCU, Sch Informat Technol, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Kent Inst Australia, Informat Technol Dept, Sydney, NSW, Australia.
   [Abdullah, Salma] Univ Technol Baghdad, Dept Comp Engn, Baghdad, Iraq.
   [Alrubaie, Ahmad] Univ New South Wales, Fac Med, Sydney, NSW, Australia.
C3 Charles Sturt University; Western Sydney University; Southern Cross
   University; University of Technology- Iraq; University of New South
   Wales Sydney
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.; Alsadoon, A (corresponding author), Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Southern Cross Univ SCU, Sch Informat Technol, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Informat Technol Dept, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Abdullah, Salma Hameedi/GRJ-1117-2022; Alsadoon, A/Prof.
   Abeer/AAU-1532-2021
OI Abdullah, Salma Hameedi/0000-0003-2087-0153; Alsadoon, A/Prof.
   Abeer/0000-0002-2309-3540; withana, chandana/0000-0002-3007-687X
CR Abdelsamea MM, 2019, EXPERT SYST APPL, V118, P539, DOI 10.1016/j.eswa.2018.10.030
   Alkadi R, 2018, DEEP LEARNING BASED, P1
   Diniz JOB, 2019, COMPUT METH PROG BIO, V170, P53, DOI 10.1016/j.cmpb.2019.01.005
   Charfi S, 2018, MULTIMED TOOLS APPL, V77, P4047, DOI 10.1007/s11042-017-4555-7
   Chisanga D, 2018, COMPUT ELECTR ENG, V67, P267, DOI 10.1016/j.compeleceng.2018.03.039
   Di Carlo M, 2018, CLIN RHEUMATOL, V37, P1037, DOI 10.1007/s10067-017-3937-6
   Graham S, 2019, MED IMAGE ANAL, V52, P199, DOI 10.1016/j.media.2018.12.001
   Hsieh M-H, 2018, J CLIN MED
   Kather Jakob Nikolas, 2016, SCI REPORTS
   Korsuk Sirinukunwattanaa JP-A, SCI DIRECT, V2, P489
   Lina Yu-Chuan, 2018, COMPLEMENT THERAPIES, P279
   Morkunas M, 2018, INFORMATICA, V29
   Mui M, 2018, INT J COLORECTAL DIS, V33, P219, DOI 10.1007/s00384-017-2941-2
   Ribeiro MG, 2018, SCI DIRECT, P262
   Sundaram PS, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1153-9
   Van Eycke YR, 2018, MED IMAGE ANAL, V49, P35, DOI 10.1016/j.media.2018.07.004
   Wang YY, 2019, INFORM SCIENCES, V474, P106, DOI 10.1016/j.ins.2018.09.046
   Yuan XH, 2018, PATTERN RECOGN, V77, P160, DOI 10.1016/j.patcog.2017.12.017
NR 18
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21561
EP 21578
DI 10.1007/s11042-021-10699-1
EA MAR 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000629494200001
DA 2024-07-18
ER

PT J
AU Tan, ZY
   Basah, SN
   Yazid, H
   Safar, MJA
AF Tan, Zheng Yu
   Basah, Shafriza Nisha
   Yazid, Haniza
   Safar, Muhammad Juhairi Aziz
TI Performance analysis of Otsu thresholding for sign language segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Otsu performance analysis; Sign language
   segmentation; Otsu consistency analysis; Otsu successful condition
   measurement
ID RECOGNITION; FEATURES
AB Sign language recognition system generally consists of three main processes, which are segmentation, modelling, and classification. Image segmentation plays a crucial role as the initial step in sign language recognition. Despite the many sign language recognition system algorithms proposed in the literature and their well-understood usage, their performance analyses are relatively limited. As such, the main motivation of this paper is to critically analyse the feasibility of successful sign language segmentation under variation of dynamic scene parameters such as noise, hand size, and intensity difference between hand and background. The focus is on image thresholding using Otsu technique, since it is the most commonly used in initial process of sign language segmentation. The analysis of this work was developed based on Monte Carlo statistical method, which showed that the success of sign language segmentation depends on hand size, hand background intensity difference, and noise measurement. The result showed that the sign alphabets with handheld shape like A, E, I, M, N, S, and T is easier to segment, while sign alphabets with finger-extend shape like C, D, F, G, H, K, L, P, R, U, V, W, and Y is harder to segment. Experiment using real images demonstrate the capability of the conditions to correctly predict the outcome of sign language segmentation using Otsu technique. In conclusion, the success of sign language segmentation could be predicted beforehand with obtainable scene parameters.
C1 [Tan, Zheng Yu; Basah, Shafriza Nisha; Yazid, Haniza; Safar, Muhammad Juhairi Aziz] Univ Malaysia Perlis, Fac Elect Engn Technol, Arau 02600, Perlis, Malaysia.
C3 Universiti Malaysia Perlis
RP Yazid, H (corresponding author), Univ Malaysia Perlis, Fac Elect Engn Technol, Arau 02600, Perlis, Malaysia.
EM zhengyu1108@hotmail.com; shafriza@unimap.edu.my;
   hanizayazid@unimap.edu.my; juhairi@unimap.edu.my
RI Yazid, Haniza/D-3830-2015
CR Ahmed MA, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072208
   [Anonymous], 2018, DEF SIGN LANG
   [Anonymous], 2011, ADV COMPUTING INT J
   [Anonymous], 2013, INT J ADV RES COMPUT
   [Anonymous], 2016, J PEDIAT
   Badi H, 2016, INT J DATA SCI ANAL, V1, P77, DOI DOI 10.1007/S41060-016-0008-Z
   Basah SN, 2009, LECT NOTES COMPUTER
   Basah SN, 2008, P DIG IM COMP TECHN
   Basah SN, 2014, IET COMPUT VIS
   Basah SN, 2009, IET COMPUT VIS
   Chen Y, 2020, J AMBIENT INTELL HUM
   Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   Dong C, 2015, AM SIGN LANGUAGE ALP, P44
   Goh TY, 2018, MEASUREMENT, V114, P298, DOI 10.1016/j.measurement.2017.09.052
   Hoseinnezhad R, 2010, J MATH IMAGING VIS
   Ibrahim NB, 2018, J KING SAUD UNIV-COM, V30, P470, DOI 10.1016/j.jksuci.2017.09.007
   Imagawa K, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P462, DOI 10.1109/AFGR.1998.670991
   Johnston T., 2007, AUSTR SIGN LANGUAGE
   Joshi A, 2017, 2017 IEEE COLOMBIAN CONFERENCE ON COMMUNICATIONS AND COMPUTING (COLCOM)
   Kakoty NM, 2018, PROCEDIA COMPUT SCI, V133, P55, DOI 10.1016/j.procs.2018.07.008
   Kang SK, 2008, ICHIT 2008: INTERNATIONAL CONFERENCE ON CONVERGENCE AND HYBRID INFORMATION TECHNOLOGY, PROCEEDINGS, P229, DOI 10.1109/ICHIT.2008.292
   Konwar A. Sharmila, 2014, 2014 International Conference on Communications and Signal Processing (ICCSP), P743, DOI 10.1109/ICCSP.2014.6949942
   Kumar P, 2017, PATTERN RECOGN LETT, V86, P1, DOI 10.1016/j.patrec.2016.12.004
   Ramirez-Cortes JM, 2009, J ELECTRON IMAGING, V18, DOI 10.1117/1.3099712
   Ogden SK, 2008, NATURE, V456, P967, DOI 10.1038/nature07459
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Oxford Dictionary, 2018, EF SIGN ENGL
   Pigou L, 2015, LECT NOTES COMPUTER
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290
   Quinn M, 2019, FED CONF COMPUT SCI, P81, DOI 10.15439/2019F274
   Ravikiran J, 2009, PROC, VI
   Rivera-Acosta M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102176
   Rojano-Caceres JR, 2016, PROCD SOC BEHV, V228, P575, DOI 10.1016/j.sbspro.2016.07.088
   Saini Sujata., 2014, INT J INFORM COMPUTA, V4, P1445
   Shah Pranit, 2019, INT J COMPUTER SCI E, V7, P281
   Sharma R, 2013, P WORLD C ENG JUL 3
   Shukor AZ, 2015, PROCEDIA COMPUT SCI, V76, P60, DOI 10.1016/j.procs.2015.12.276
   Tao WJ, 2018, ENG APPL ARTIF INTEL, V76, P202, DOI 10.1016/j.engappai.2018.09.006
   Thalange A, 2016, PROCEDIA COMPUT SCI, V92, P455, DOI 10.1016/j.procs.2016.07.367
   Tripathi K, 2015, PROCEDIA COMPUT SCI, V54, P523, DOI 10.1016/j.procs.2015.06.060
   Tubaiz N, 2015, IEEE T HUM-MACH SYST, V45, P526, DOI 10.1109/THMS.2015.2406692
   Yang HD, 2015, SENSORS-BASEL, V15, P135, DOI 10.3390/s150100135
   Yang HD, 2009, IEEE T PATTERN ANAL, V31, P1264, DOI 10.1109/TPAMI.2008.172
   Yang WW, 2016, PATTERN RECOGN LETT, V78, P28, DOI 10.1016/j.patrec.2016.03.030
   Yong Z, 2017, GRABCUT IMAGE SEGMEN, V43
   Zadghorban M, 2018, PATTERN ANAL APPL, V21, P323, DOI 10.1007/s10044-016-0579-2
   Zhang QY, 2008, IEEE I C EMBED SOFTW, P338, DOI 10.1109/ICESS.2008.23
NR 47
TC 7
Z9 7
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21499
EP 21520
DI 10.1007/s11042-021-10688-4
EA MAR 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000629494100008
DA 2024-07-18
ER

PT J
AU Lin, H
   Sheng, H
   Sun, GX
   Li, YH
   Xiao, MH
   Wang, XC
AF Lin, Hong
   Sheng, Hang
   Sun, Guoxiang
   Li, Yuhua
   Xiao, Maohua
   Wang, Xiaochan
TI Identification of pumpkin powdery mildew based on image processing PCA
   and machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Pattern recognition; Image processing; Feature
   extraction; Principal component analysis; Support vector machine
ID SUPPORT VECTOR MACHINE; SEGMENTATION; RECOGNITION
AB A method based on image processing, principal component analysis (PCA) and machine learning was proposed to identify pumpkin powdery mildew and improve the identification accuracy of pumpkin powdery mildew. The leaf-disease image was processed by the color feature compositing and detection method,in order to segment the lesion more accurately. Then 20 feature values are extracted, including the texture features, color features and morphological features of the segmented lesions, and the 20-dimensional original feature parameters were simplified to 3-dimensional feature parameters via the PCA method. Finally, three different SVM kernel functions are used to construct the classification model to compare the original feature parameters and principal component feature parameters separately. Experiment results show that the effect of illumination angle and intensity can be effectively eliminated after the super red feature calculation, and that the SVM model based on PCA and polynomial kernel function has a better recognition effect on pumpkin powdery mildew. The recognition rate is 97.3%, which is 3.15% higher than that of the traditional original characteristic parameters. Based on this finding, it can be concluded that this machine learning model can achieve accurate lesions identification.
C1 [Lin, Hong; Sheng, Hang; Sun, Guoxiang; Li, Yuhua; Xiao, Maohua; Wang, Xiaochan] Nanjing Agr Univ, Coll Engn, Nanjing 210031, Peoples R China.
C3 Nanjing Agricultural University
RP Wang, XC (corresponding author), Nanjing Agr Univ, Coll Engn, Nanjing 210031, Peoples R China.
EM wangxiaochan@njau.edu.cn
RI xiaochan, wang/JQX-2821-2023
OI Sun, Guoxiang/0000-0001-7470-5255; wang, xiaochan/0000-0003-0461-8417
FU Jiangsu Provincial Natural and Science Founding [BK20170727]; National
   Natural Science Foundation of China [61701242]; Special Plan for
   Innovation and Entrepreneurship Training for College Students of Nanjing
   Agricultural University [S20190036]
FX The research is funded by Jiangsu Provincial Natural and Science
   Founding (BK20170727), National Natural Science Foundation of China
   (61701242) and Special Plan for Innovation and Entrepreneurship Training
   for College Students of Nanjing Agricultural University(S20190036).
CR Bakhshipour A, 2018, COMPUT ELECTRON AGR, V145, P153, DOI 10.1016/j.compag.2017.12.032
   Ding WG, 2016, COMPUT ELECTRON AGR, V123, P17, DOI 10.1016/j.compag.2016.02.003
   Durbha SS, 2007, REMOTE SENS ENVIRON, V107, P348, DOI 10.1016/j.rse.2006.09.031
   Han DianYuan Han DianYuan, 2012, Transactions of the Chinese Society of Agricultural Engineering, V28, P179
   Han LX, 2015, 2015 SCIENCE AND INFORMATION CONFERENCE (SAI), P638, DOI 10.1109/SAI.2015.7237209
   Hernández-Hernández JL, 2016, COMPUT ELECTRON AGR, V122, P124, DOI 10.1016/j.compag.2016.01.020
   Jhuria M, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P521, DOI 10.1109/ICIIP.2013.6707647
   Kruse OMO, 2014, COMPUT ELECTRON AGR, V108, P155, DOI 10.1016/j.compag.2014.07.010
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Ma JC, 2017, COMPUT ELECTRON AGR, V142, P110, DOI 10.1016/j.compag.2017.08.023
   Meyer GE, 1999, PROC SPIE, V3543, P327, DOI 10.1117/12.336896
   Minervini M, 2014, ECOL INFORM, V23, P35, DOI 10.1016/j.ecoinf.2013.07.004
   Pujari JD, 2015, PROCEDIA COMPUT SCI, V46, P1802, DOI 10.1016/j.procs.2015.02.137
   [任守纲 Ren Shougang], 2016, [农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V47, P11
   Sankaran S, 2010, COMPUT ELECTRON AGR, V72, P1, DOI 10.1016/j.compag.2010.02.007
   Singh V, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENGINEERING AND APPLICATIONS (ICACEA), P1028, DOI 10.1109/ICACEA.2015.7164858
   Uzunbas MG, 2016, MED IMAGE ANAL, V27, P31, DOI 10.1016/j.media.2015.06.003
   Wang XY, 2012, NEURAL NETWORKS, V33, P148, DOI 10.1016/j.neunet.2012.04.012
   [王翔宇 Wang Xiangyu], 2016, [农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V47, P266
   Wei WH, 2019, BIORESOURCES, V14, P8678, DOI 10.15376/biores.14.4.8678-8688
   Wu DY, 2019, J JIANGNAN U NAT SCI, V8, P520
   Xu XM, 2017, ENG OPTIMIZ, V49, P1665, DOI 10.1080/0305215X.2016.1265304
   Xue ZJ, 2010, PATTERN RECOGN, V43, P2904, DOI 10.1016/j.patcog.2010.03.011
   [叶勤 Ye Qin], 2017, [农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V48, P164
   Zhang D. Y., 2016, International Agricultural Engineering Journal, V25, P197
   Zhang SW, 2018, OPTIK, V157, P866, DOI 10.1016/j.ijleo.2017.11.190
   Zhang SW, 2017, COMPUT ELECTRON AGR, V134, P135, DOI 10.1016/j.compag.2017.01.014
NR 27
TC 10
Z9 11
U1 4
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21085
EP 21099
DI 10.1007/s11042-020-10419-1
EA MAR 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000627670100001
DA 2024-07-18
ER

PT J
AU Deb, S
   Bhuyan, B
AF Deb, Subhrajyoti
   Bhuyan, Bubu
TI Chaos-based medical image encryption scheme using special nonlinear
   filtering function based LFSR
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image; Image encryption; Chaos; Security analysis; PRNG; LFSR;
   Stream cipher
ID ALGORITHM; SYSTEM; MAP; PERMUTATION; GENERATOR
AB In this paper, a new medical image encryption system is proposed using a special nonlinear filter function based linear feedback shift register (LFSR). This special nonlinear filter function based LFSR is used as a pseudo-random number generator (PRNG). In this generator, word-based effective operation has been applied to speed up the process of encryption and decryption. Firstly, the medical image is randomized by Logistic-Tent map and scrambled by Arnold transformation method. Next, the disordered image data is XORed with output sequences of specially designed PRNG to obtain cipher image. Our designed structure aims to provide high-level randomness in the cipher image content. Encryption decryption time requirements reveal the efficiency of the proposed system. Several performance measures are estimated to validate the resistance of the proposed scheme against statistical, differential, and a few common cryptanalytic attacks. The proposed encryption scheme compares favorably with several existing image encryption schemes.
C1 [Deb, Subhrajyoti; Bhuyan, Bubu] North Eastern Hill Univ, Dept Informat Technol, Shillong, Meghalaya, India.
C3 North Eastern Hill University
RP Deb, S (corresponding author), North Eastern Hill Univ, Dept Informat Technol, Shillong, Meghalaya, India.
EM subhrajyotideb1@gmail.com; b.bhuyan@gmail.com
RI Deb, Dr. Subhrajyoti/AAX-8520-2021
OI Deb, Dr. Subhrajyoti/0000-0001-6939-0113
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Bishoi SK, 2017, DISCRETE APPL MATH, V222, P67, DOI 10.1016/j.dam.2017.01.033
   Burnett Linda, 2004, Australas. J. Combin., V29, P231
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P9907, DOI 10.1007/s11042-016-3585-x
   Dagadu JC, 2019, WIRELESS PERS COMMUN, V108, P591, DOI 10.1007/s11277-019-06420-z
   Das P, 2015, PROCEDIA COMPUT SCI, V46, P604, DOI 10.1016/j.procs.2015.02.103
   Deb Subhrajyoti, 2018, Proceedings of the International Conference on Computing and Communication Systems. I3CS 2016. Lecture Notes in Networks and Systems (LNNS 24), P631, DOI 10.1007/978-981-10-6890-4_61
   Deb S, 2019, MULTIMED TOOLS APPL, V78, P34901, DOI 10.1007/s11042-019-08086-y
   Dong CE, 2015, OPTIK, V126, P2571, DOI 10.1016/j.ijleo.2015.06.035
   Fan HJ, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/8124912
   Filiol E, 1998, LECT NOTES COMPUT SC, V1403, P475, DOI 10.1007/BFb0054147
   Gan ZH, 2019, NEURAL COMPUT APPL, V31, P7111, DOI 10.1007/s00521-018-3541-y
   Murcia MDG, 2019, INTEGR COMPUT-AID E, V26, P197, DOI 10.3233/ICA-180591
   He K, 2007, HIGH EFFICIENCY FEED
   Jolfaei A, 2012, INT J ELECTRON SECUR, V4, P19, DOI 10.1504/IJESDF.2012.045388
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Khan M, 2014, NEURAL COMPUT APPL, V25, P1717, DOI 10.1007/s00521-014-1663-4
   Kumar P, 2016, OPTIK, V127, P2341, DOI 10.1016/j.ijleo.2015.11.188
   Kumar S, 2019, MED BIOL ENG COMPUT, V57, P2517, DOI 10.1007/s11517-019-02037-3
   Kumari M, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0162-2
   Laiphrakpam DS, 2018, MULTIMED TOOLS APPL, V77, P8629, DOI 10.1007/s11042-017-4755-1
   Laiphrakpam DS, 2017, OPTIK, V147, P88, DOI 10.1016/j.ijleo.2017.08.028
   Li B, 2019, NONLINEAR DYNAM, V95, P1781, DOI 10.1007/s11071-018-4659-2
   Liang YQ, 2020, INTEGR COMPUT-AID E, V27, P417, DOI 10.3233/ICA-200641
   Lima JB, 2015, SIGNAL PROCESS-IMAGE, V35, P1, DOI 10.1016/j.image.2015.03.005
   Liu HJ, 2015, SIGNAL PROCESS, V113, P104, DOI 10.1016/j.sigpro.2015.01.016
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Maddodi G, 2018, MULTIMED TOOLS APPL, V77, P24701, DOI 10.1007/s11042-018-5669-2
   Maitra S, 2011, BOOLEAN FUNCTIONS CR
   Maitra S, 2020, IEEE T INFORM THEORY, V66, P1219, DOI 10.1109/TIT.2019.2932739
   Mondal B, 2018, MULTIMED TOOLS APPL, V77, P31177, DOI 10.1007/s11042-018-6214-z
   Özkaynak F, 2019, NEURAL COMPUT APPL, V31, P3317, DOI 10.1007/s00521-017-3287-y
   Praveenkumar P, 2018, MULTIMED TOOLS APPL, V77, P8393, DOI 10.1007/s11042-017-4741-7
   Rukhin Andrew L., 2001, A statistical test suite for random and pseudorandom number generators for cryptographic applications, V22
   Shah T., 2011, STAT ANAL S BOX IMAG, V6, P4110
   Stalin S, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1389-z
   Ullah A, 2018, NONLINEAR DYNAM, V91, P359, DOI 10.1007/s11071-017-3874-6
   Wong K, 2019, IOP C SERES MAT SCI, P495
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Xia ZQ, 2019, SIGNAL PROCESS, V157, P108, DOI 10.1016/j.sigpro.2018.11.011
   Zhang XP, 2014, SIGNAL PROCESS-IMAGE, V29, P902, DOI 10.1016/j.image.2014.06.012
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 45
TC 26
Z9 26
U1 4
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19803
EP 19826
DI 10.1007/s11042-020-10308-7
EA MAR 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000624399500003
DA 2024-07-18
ER

PT J
AU Gopi, R
   Sathiyamoorthi, V
   Selvakumar, S
   Manikandan, R
   Chatterjee, P
   Jhanjhi, NZ
   Luhach, AK
AF Gopi, R.
   Sathiyamoorthi, V.
   Selvakumar, S.
   Manikandan, Ramasamy
   Chatterjee, Pushpita
   Jhanjhi, N. Z.
   Luhach, Ashish Kumar
TI Enhanced method of ANN based model for detection of DDoS attacks on
   multimedia internet of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ANN; DDoS attacks; Multimedia IoT; Network attacks; Training
ID INTRUSION DETECTION SYSTEM; IDS
AB Due to the huge flow of data and complications in mutable characteristics of the data, Distributed Denial of Services attacks existed in the Multimedia Internet of Things. Attacks over the IoT have become an increasing menace in recent time, which tries to hack or illegally tamper the streaming data available over the networks. On the other hand, there has been an increase in volume in research contributions to effectively counter these attacks and implement a strong defense mechanism. There have been numerous algorithms and frameworks implemented in recent times that are intelligent and soft computing-based. These evolution-based algorithms play a vital role in self-adapting the system under attack towards increasing and new types of attacks which are increasing day by day. One such area of soft computing algorithms investigated in this paper is the Artificial Neural Network or popularly known as ANNs. It works analogously to the biological neurons in the human body. In this paper, we systematically explain the ANN-based network model to counteract the DDoS attacks in the Multimedia Internet of Things, architecture, and implementation of ANNs, the experimental investigations and findings which help in drawing an inference of ANN-based defense models.
C1 [Gopi, R.; Selvakumar, S.] Dhanalakshmi Srinivasan Engn Coll, Dept Informat Technol, Perambalur, Tamil Nadu, India.
   [Sathiyamoorthi, V.] Sona Coll Technol, Dept CSE, Salem, India.
   [Manikandan, Ramasamy] VIT Bhopal Univ, Sch Comp Sci & Engn, Bhopal, India.
   [Chatterjee, Pushpita] Ton Duc Thang Univ, Future Networking Res Grp, Ho Chi Minh City, VA, Vietnam.
   [Jhanjhi, N. Z.] Taylors Univ, Sch Comp Sci & Engn SCE, Subang Jaya, Malaysia.
   [Luhach, Ashish Kumar] PNG Univ Technol, Dept Elect & Commun Engn, Lae, Papua N Guinea.
C3 Sona College of Technology; VIT Bhopal University; Ton Duc Thang
   University; Taylor's University
RP Chatterjee, P (corresponding author), Ton Duc Thang Univ, Future Networking Res Grp, Ho Chi Minh City, VA, Vietnam.; Jhanjhi, NZ (corresponding author), Taylors Univ, Sch Comp Sci & Engn SCE, Subang Jaya, Malaysia.
EM puspitachatterjee@tdtu.edu.vn; noorzaman.jhanjhi@taylors.edu.my
RI CHATTERJEE, PUSPITA/AAR-3862-2020; Luhach, Ashish Kumar/R-8756-2019;
   Jhanjhi, Prof Dr Noor Zaman/F-3051-2011
OI CHATTERJEE, PUSPITA/0000-0002-0775-5540; Luhach, Ashish
   Kumar/0000-0001-8759-0290; Jhanjhi, Prof Dr Noor
   Zaman/0000-0001-8116-4733; , GOPI/0000-0003-4957-1843; V,
   Sathiyamoorthi/0000-0002-7012-3941
CR Arivudainambi D, 2019, NEURAL COMPUT APPL, V31, P1491, DOI 10.1007/s00521-018-3383-7
   Chhaya L, 2017, ELECTRONICS-SWITZ, V6, DOI 10.3390/electronics6010005
   Duraipandian M, 2015, WIRELESS PERS COMMUN, V83, P2425, DOI 10.1007/s11277-015-2536-6
   Farris I, 2019, IEEE COMMUN SURV TUT, V21, P812, DOI 10.1109/COMST.2018.2862350
   Ferrag MA, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12030044
   Colom JF, 2018, J NETW COMPUT APPL, V108, P76, DOI 10.1016/j.jnca.2018.02.004
   Fu YL, 2017, MOB INF SYST, V2017, DOI 10.1155/2017/1750637
   Gandhi UD, 2018, WIRELESS PERS COMMUN, V103, P1179, DOI 10.1007/s11277-018-5307-3
   Gendreau AA, 2016, 2016 IEEE 4TH INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD (FICLOUD 2016), P84, DOI 10.1109/FiCloud.2016.20
   Golrang A, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040577
   Hassija V, 2019, IEEE ACCESS, V7, P82721, DOI 10.1109/ACCESS.2019.2924045
   Hussain F, 2020, IEEE COMMUN SURV TUT, V22, P1686, DOI 10.1109/COMST.2020.2986444
   Khan R, 2020, IEEE COMMUN SURV TUT, V22, P196, DOI 10.1109/COMST.2019.2933899
   Kim J, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060916
   Ksasy Mohamed Sherif, 2018, ICIC Express Letters, V12, P117
   Manimurugan S, 2020, IEEE ACCESS, V8, P77396, DOI 10.1109/ACCESS.2020.2986013
   Manso P, 2019, INFORMATION, V10, DOI 10.3390/info10030106
   Napiah MN, 2018, IEEE ACCESS, V6, P16623, DOI 10.1109/ACCESS.2018.2798626
   Pejic D, 2019, COMPUT COMMUN NETW S, P55, DOI 10.1007/978-3-030-13803-5_3
   Suratgar AA, 2005, PROCEEDINGS OF WORLD ACADEMY OF SCIENCE, ENGINEERING AND TECHNOLOGY, VOL 6, P46
NR 20
TC 17
Z9 17
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 26739
EP 26757
DI 10.1007/s11042-021-10640-6
EA FEB 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000621282300007
DA 2024-07-18
ER

PT J
AU Shi, X
   Chen, HJ
   Zhao, XQ
AF Shi, Xin
   Chen, Huijuan
   Zhao, Xueqing
TI REBOR: A new sketch-based 3d object retrieval framework using retina
   inspired features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE sketch-based object retrieval; Human visual system; Retina based feature
   extraction; SVM; Artificial bee colony algorithm
AB With the rapid development of data science and modeling engineering, the capacity of cyberspace has significantly expanded which enables the online storage of increasing number of 3D models. Hence, the development of effective and efficient approaches to search 3D models is becoming increasingly important and urgent. In this paper, we propose a new sketch-based 3D retrieval framework named REBOR under the inspiration of retina which is not only consistent with human perception sensitivity but also simplifies the requirement of retrieval query by enabling hand-drawn sketch. The feature extraction process incorporates human visual system by simulating the ganglion perceptive mechanism in retina. Support Vector Machine is used to classify the query sketches and is further optimized by means of an global optimization algorithm so as to acquire optimal results automatically. Experiments are done on the database generated by ourselves with 15 categories of 3D objects, and the results indicate the effectiveness of REBOR in terms of retrieval accuracy.
C1 [Shi, Xin; Chen, Huijuan; Zhao, Xueqing] Xian Polytech Univ, Sch Comp Sci, Xian, Shaanxi, Peoples R China.
   [Shi, Xin; Zhao, Xueqing] Xian Polytech Univ, Sch Comp Sci, Shaanxi Key Lab Clothing Intelligence, Xian 710048, Peoples R China.
   [Zhao, Xueqing] Xian Polytech Univ, Natl & Local Joint Engn Res Ctr Adv Networking &, Xian 710048, Peoples R China.
   [Zhao, Xueqing] Peking Univ, Sch Elect Engn & Comp Sci, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China.
C3 Xi'an Polytechnic University; Xi'an Polytechnic University; Xi'an
   Polytechnic University; Peking University
RP Zhao, XQ (corresponding author), Xian Polytech Univ, Sch Comp Sci, Xian, Shaanxi, Peoples R China.; Zhao, XQ (corresponding author), Xian Polytech Univ, Sch Comp Sci, Shaanxi Key Lab Clothing Intelligence, Xian 710048, Peoples R China.; Zhao, XQ (corresponding author), Xian Polytech Univ, Natl & Local Joint Engn Res Ctr Adv Networking &, Xian 710048, Peoples R China.; Zhao, XQ (corresponding author), Peking Univ, Sch Elect Engn & Comp Sci, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China.
EM shixin@xpu.edu.cn; chenhuijuan@xpu.edu.cn; zhaoxueqing@xpu.edu.cn
FU National Natural Science Foundation of China [61806160]; Shaanxi
   Association for Science and Technology of Colleges and Universities
   Youth Talent Development Program [20190112]; Youth Innovation Team of
   Shaanxi Universities and Shaanxi Province Technical Innovation
   Foundation [2020CGXNG-012]
FX This work is sponsored by the National Natural Science Foundation of
   China under Grant No.61806160 and Shaanxi Association for Science and
   Technology of Colleges and Universities Youth Talent Development
   Program, No. 20190112 and the Youth Innovation Team of Shaanxi
   Universities and Shaanxi Province Technical Innovation
   Foundation(2020CGXNG-012).
CR ALEXANDRE A, 2012, IEEE C COMP VIS PATT
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Das GP, 2019, NEUROCOMPUTING, V325, P101, DOI 10.1016/j.neucom.2018.10.004
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Duan LX, 2011, IEEE T IMAGE PROCESS, V20, P3280, DOI 10.1109/TIP.2011.2159227
   Gao RX, 2019, SCIENCE, V363, P245, DOI 10.1126/science.aau8302
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Kastner S, 2000, ANNU REV NEUROSCI, V23, P315, DOI 10.1146/annurev.neuro.23.1.315
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li B, 2017, MULTIMED TOOLS APPL, V76, P26603, DOI 10.1007/s11042-016-4187-3
   Li B, 2013, MULTIMED TOOLS APPL, V62, P821, DOI 10.1007/s11042-011-0873-3
   Li YL, 2015, NEUROCOMPUTING, V149, P736, DOI 10.1016/j.neucom.2014.08.003
   Li Y, 2018, NEUROCOMPUTING, V275, P1275, DOI 10.1016/j.neucom.2017.09.072
   Li YH, 2018, MULTIMED TOOLS APPL, V77, P2921, DOI 10.1007/s11042-017-4446-y
   Lowe DG, 1999, ICCV IEEE COMPUTER S, DOI 10.1109/ICCV.1999.790410
   Mair E, 2010, LECT NOTES COMPUT SC, V6312, P183, DOI 10.1007/978-3-642-15552-9_14
   Martin JH, 2017, NATURE, V549, P365, DOI 10.1038/nature23894
   Medathati NVK, 2016, COMPUT VIS IMAGE UND, V150, P1, DOI 10.1016/j.cviu.2016.04.009
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   STEFAN L, 2011, INT C COMP VIS
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   VanRullen R, 2002, VISION RES, V42, P2593, DOI 10.1016/S0042-6989(02)00298-5
   Wang D, 2017, NEUROCOMPUTING, V252, P58, DOI 10.1016/j.neucom.2016.06.095
   Weng DW, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2409739
   Wu L, 2013, IEEE T PATTERN ANAL, V35, P716, DOI 10.1109/TPAMI.2012.124
   Yang Y, 2019, IEEE T MULTIMEDIA, V21, P809, DOI 10.1109/TMM.2018.2867742
   Yao QQ, 2017, BIOMATERIALS, V115, P115, DOI 10.1016/j.biomaterials.2016.11.018
   Zhao X., 2017, EUROGRAPHICS WORKSHO
   Zhao XX, 2019, ADV MATER, V31, DOI 10.1002/adma.201900237
NR 33
TC 2
Z9 2
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23297
EP 23311
DI 10.1007/s11042-021-10618-4
EA FEB 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000621015900006
DA 2024-07-18
ER

PT J
AU Rawas, S
AF Rawas, Soha
TI Energy, network, and application-aware virtual machine placement model
   in SDN-enabled large scale cloud data centers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtualization; Cloud computing; Multi-tier application; Green
   computing; Knapsack problem; Genetic algorithm
AB Cloud computing has been considered a core model of elastic on-demand resource allocation using a pay-as-you go model. One of the big challenges of this environment is to provide high quality service (QoS) through efficient and stringent management of cloud data center resources. With the increasing demand for cloud based services, the traffic volume inside cloud data centers (DC) has been increased exponentially. Accordingly, and to provide high QoS, a proper scheduling mechanism has to be followed by the cloud service provider. Furthermore, accurate scheduling is necessary for advancing the problem of energy consumption and resource utilization. In this paper, we propose an optimal resource allocation and consolidation virtual machine (VM) placement model for multi-tier applications in modern large cloud DCs. The proposed model targets to optimize the DCs' energy and communication cost that influence the overall cloud performance through Software Defined Networking (SDN) control features. To solve the formulated multi-objective optimization problem, a novel adaptive genetic algorithm is proposed. The experimental results validate the efficacy of the proposed model through extensive simulations using synthetic and real workload traces. These results show that the proposed model jointly optimizes cloud QoS as well as energy consumption.
C1 [Rawas, Soha] Beirut Arab Univ, Dept Math & Comp Sci, Beirut, Lebanon.
C3 Beirut Arab University
RP Rawas, S (corresponding author), Beirut Arab Univ, Dept Math & Comp Sci, Beirut, Lebanon.
EM Soha.rawas2@bau.edu.lb
OI Rawas, Soha/0000-0001-5128-6529
CR Cao GY, 2019, SUSTAIN COMPUT-INFOR, V21, P179, DOI 10.1016/j.suscom.2019.01.004
   Cao GY, 2017, IEEE INT SYMP PARAL, P237, DOI 10.1109/ISPA/IUCC.2017.00042
   Cook Gary, 2015, Clicking clean: A guide to building the green Internet
   Costa LHM, 2012, GLOB INFORM INFRAS, P1
   Das More Swami, 2019, International Journal of Natural Computing Research, V8, P51, DOI 10.4018/IJNCR.2019040103
   Dayarathna M, 2016, IEEE COMMUN SURV TUT, V18, P732, DOI 10.1109/COMST.2015.2481183
   El Motaki S, 2019, J SUPERCOMPUT, V75, P6239, DOI 10.1007/s11227-019-02847-0
   Ghobaei-Arani M, 2019, IEEE ACCESS, V7, P106911, DOI 10.1109/ACCESS.2019.2932462
   Jatoth C, 2019, FUTURE GENER COMP SY, V94, P185, DOI 10.1016/j.future.2018.11.022
   Kaur K, 2018, DATA ENG INTELLIGENT, V542, P521, DOI [10.1007/978-981-10-3223-3_51, DOI 10.1007/978-981-10-3223-3_51]
   Kumar P, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3281010
   Mann ZA, 2015, ACM COMPUT SURV, V48, DOI 10.1145/2797211
   Peini Liu, 2019, Economics of Grids, Clouds, Systems, and Services. 16th International Conference, GECON 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11819), P71, DOI 10.1007/978-3-030-36027-6_7
   Rawas S., 2018, INT C CLOUD COMP SER, P1
   Rawas S, 2015, 2015 INTERNATIONAL CONFERENCE ON APPLIED RESEARCH IN COMPUTER SCIENCE AND ENGINEERING (ICAR)
   Rawat S, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI 10.14722/ndss.2017.23404
   Sarkar S, 2018, IEEE T CLOUD COMPUT, V6, P46, DOI 10.1109/TCC.2015.2485206
   Son J, 2017, IEEE T SUST COMPUT, V2, P76, DOI 10.1109/TSUSC.2017.2702164
   Son JM, 2015, IEEE ACM INT SYMP, P475, DOI 10.1109/CCGrid.2015.87
   Vicentini C, 2019, J NETW COMPUT APPL, V126, P133, DOI 10.1016/j.jnca.2018.11.005
   Wei WT, 2019, IEEE ACCESS, V7, P60617, DOI 10.1109/ACCESS.2019.2911914
   Yuan HT, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2773645
   Zekri A, 2018, JCS, V14, P334, DOI 10.3844/jcssp.2018.334.350
   Zhao DM, 2019, IEEE ACCESS, V7, P55659, DOI 10.1109/ACCESS.2019.2913175
NR 24
TC 15
Z9 17
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15541
EP 15562
DI 10.1007/s11042-021-10616-6
EA FEB 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000614681600001
DA 2024-07-18
ER

PT J
AU Farshi, TR
   Demirci, R
AF Rahkar Farshi, Taymaz
   Demirci, Recep
TI Multilevel image thresholding with multimodal optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Multilevel thresholding; Particle swarm
   optimization; Multimodal optimization; Peak detection
ID SEARCH ALGORITHM; SEGMENTATION; SELECTION; KAPURS
AB Thresholding method is one of the most popular approaches for image segmentation where an objective function is defined in terms of threshold numbers and their locations in a histogram. If only a single threshold is considered, a segmented image with two classes is achieved. On the other hand, multiple classes in the output image are created with multilevel thresholding. Otsu and Kapur's procedures have been conventional steps for defining objective functions. Nevertheless, the fundamental problem with thresholding techniques is the determination of threshold numbers, which must be selected by the user. In that respect, thresholding methods with both techniques are user-dependent, and may not be practical for real-time image processing applications. In this study, a novel thresholding algorithm without any objective function has been proposed. Histogram curve was considered as an objective function. The peaks and valley in histogram have been detected by means of multimodal particle swarm optimization algorithms. Accordingly, valleys between two peaks have been assigned as thresholds. Consequently, the developed scheme does not need any user intervention and finds the number of thresholds automatically. Furthermore, computation time is independent of the number of thresholds, whereas computation time in Otsu and Kapur procedures depends on the number of thresholds.
C1 [Rahkar Farshi, Taymaz] Ayvansaray Univ, Software Engn Dept, TR-34217 Istanbul, Turkey.
   [Demirci, Recep] Gazi Univ, Technol Fac, Comp Engn Dept, TR-06500 Ankara, Turkey.
C3 Istanbul Topkapi University; Gazi University
RP Farshi, TR (corresponding author), Ayvansaray Univ, Software Engn Dept, TR-34217 Istanbul, Turkey.
EM taymazfarshi@ayvansaray.edu.tr
RI Demirci, Recep/AFX-9559-2022; Akan, Taymaz/S-4564-2019
OI Akan, Taymaz/0000-0003-4070-1058; Demirci, Recep/0000-0002-3278-0078
CR Abd Elaziz M, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2020.113201
   Alihodzic A, 2014, SCI WORLD J, DOI 10.1155/2014/176718
   Arora S, 2008, PATTERN RECOGN LETT, V29, P119, DOI 10.1016/j.patrec.2007.09.005
   Barrera J, 2009, LECT NOTES ARTIF INT, V5845, P622, DOI 10.1007/978-3-642-05258-3_55
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P1573, DOI 10.1016/j.eswa.2014.09.049
   Bhandari AK, 2014, EXPERT SYST APPL, V41, P3538, DOI 10.1016/j.eswa.2013.10.059
   Brajevic Ivona., 2014, Cuckoo Search and Fire y Algorithm, P115, DOI DOI 10.1007/978-3-319-02141-6_6
   Chang WD, 2015, APPL SOFT COMPUT, V33, P170, DOI 10.1016/j.asoc.2015.04.002
   Diwakar M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101754
   Diwakar M, 2018, IET IMAGE PROCESS, V12, P708, DOI 10.1049/iet-ipr.2017.0639
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Epitropakis MG, 2013, 2013 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P79
   Farshi T.R., 2019, IRAN J COMPUTER SCI, V2, P9, DOI [10.1007/s42044-018-0022-5, DOI 10.1007/S42044-018-0022-5]
   Farshi TR, 2021, NEURAL COMPUT APPL, V33, P1139, DOI 10.1007/s00521-020-05004-4
   Farshi TR, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113233
   Farshi TR, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040296
   Horng M-H, 2010, 7 INT C AUT TRUST CO
   Horng MH, 2010, APPL MATH COMPUT, V215, P3302, DOI 10.1016/j.amc.2009.10.018
   Jacobson ML, 2001, P ANN INT IEEE EMBS, V23, P2194, DOI 10.1109/IEMBS.2001.1017206
   Jamal SB, 2019, 2019 42ND INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P71, DOI [10.1109/TSP.2019.8769093, 10.1109/tsp.2019.8769093]
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Khairuzzaman AKM, 2017, EXPERT SYST APPL, V86, P64, DOI 10.1016/j.eswa.2017.04.029
   Kumar M, 2019, J KING SAUD UNIV-COM, V31, P113, DOI 10.1016/j.jksuci.2016.12.002
   Lee CG, 1999, IEEE T MAGN, V35, P1722, DOI 10.1109/20.767361
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Oliva D, 2013, J APPL MATH, DOI 10.1155/2013/575414
   Orujpour M, 2020, NEURAL COMPUT APPL, V32, P6159, DOI 10.1007/s00521-019-04113-z
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Qu BY, 2012, IEEE T EVOLUT COMPUT, V16, P601, DOI 10.1109/TEVC.2011.2161873
   Qu BY, 2012, INFORM SCIENCES, V197, P131, DOI 10.1016/j.ins.2012.02.011
   Rahim AHMA, 2017, INT CONF ADV ELECTR, P1, DOI 10.1109/ICAEE.2017.8255316
   Rahkar Farshi Taymaz, 2019, International Journal of Information Technology, V11, P713, DOI 10.1007/s41870-019-00328-4
   Rahkar-Farshi T, 2016, INT J ADV COMPUT SC, V7, P134
   Raja NSM, 2014, MOD SIMUL ENG, V2014, DOI 10.1155/2014/794574
   ROSENFELD A, 1979, P IEEE, V67, P764, DOI 10.1109/PROC.1979.11326
   Sakthivel, 2020, ENG SCI TECHNOLOGY I
   Sathya PD, 2011, EXPERT SYST APPL, V38, P15549, DOI 10.1016/j.eswa.2011.06.004
   Sathya PD, 2011, ENG APPL ARTIF INTEL, V24, P595, DOI 10.1016/j.engappai.2010.12.001
   TSAI DM, 1995, PATTERN RECOGN LETT, V16, P653, DOI 10.1016/0167-8655(95)80011-H
   Wunnava A, 2020, ENG APPL ARTIF INTEL, V94, DOI 10.1016/j.engappai.2020.103836
   Yang XS, 2012, ENG COMPUTATION, V29, P464, DOI 10.1108/02644401211235834
   Yazdani S, 2014, SWARM EVOL COMPUT, V14, P1, DOI 10.1016/j.swevo.2013.08.001
   Yin C, 2017, ENRGY PROCED, V105, P2589, DOI 10.1016/j.egypro.2017.03.744
   Zhang Zaixi, 2020, ARXIV PREPRINT ARXIV
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
NR 47
TC 12
Z9 12
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15273
EP 15289
DI 10.1007/s11042-020-10432-4
EA FEB 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000613993900002
DA 2024-07-18
ER

PT J
AU Srivastava, P
   Shukla, A
   Bansal, A
AF Srivastava, Pallavi
   Shukla, Aasheesh
   Bansal, Atul
TI A comprehensive review on soil classification using deep learning and
   computer vision techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Soil classification; Deep learning; Convolutional neural network;
   Computer vision; Soil science
ID ARTIFICIAL NEURAL-NETWORK; QUANTIFICATION; FEATURES; TREE
AB Soil classification is one of the major affairs and emanating topics in a large number of countries. The population of the world is rising at a majorly rapid pace and along with the increase in population, the demand for food surges actively. Typical techniques employed by the farmers are not adequate enough to fulfill the increasing requirements and therefore they have to hinder the cultivating soil. For proper crop yield, farmers should be aware of the correct soil type for a particular crop, which affects the increased demand for food. There are various laboratory and field methods to classify soil, but these have limitations like time and labor-consuming. There is a requirement of computer-based soil classification techniques which will help farmers in the field and won't take a lot of time. This paper talks about different computer-based soil classification practices divided into two streams. First is image processing and computer vision-based soil classification approaches which include the conventional image processing algorithms and methods to classify soil using different features like texture, color, and particle size. Second is deep learning and machine learning-based soil classification approaches, such as CNN, which yields state-of-the-art results. Deep learning applications mostly diminish the dependency on spatial-form designs and preprocessing techniques by facilitating the end-to-end process. This paper also presents some databases created by the researchers according to the objective of the study. Databases are created under different environmental and illumination conditions, using different appliances such as digital cameras, digital camcorder, and a smartphone camera. Also, evaluation metrics are briefly discussed to layout some graded measures for differentiation. This review serves as a brief guide to new researchers in the field of soil classification, it provides fundamental understanding and general knowledge of the modern state-of-the-art researches, in addition to skillful researchers considering some dynamic trends for future work.
C1 [Srivastava, Pallavi; Shukla, Aasheesh; Bansal, Atul] GLA Univ, Dept Elect & Commun Engn, Mathura 281406, India.
C3 GLA University
RP Srivastava, P (corresponding author), GLA Univ, Dept Elect & Commun Engn, Mathura 281406, India.
EM pallavi.sr015@gmail.com
RI shukla, Aasheesh/W-7189-2018; srivastava, pallavi/JCS-4153-2023; Bansal,
   Atul/I-1823-2019
OI Bansal, Atul/0000-0002-8012-0349; srivastava,
   pallavi/0000-0002-0125-1018
CR Ajdadi FR, 2016, SOIL TILL RES, V162, P8, DOI 10.1016/j.still.2016.04.012
   Aydemir S, 2004, GEODERMA, V119, P1, DOI 10.1016/S0016-7061(03)00218-0
   Azizi A, 2020, SOIL TILL RES, V199, DOI 10.1016/j.still.2020.104586
   Barman Utpal, 2020, Information Processing in Agriculture, V7, P318, DOI 10.1016/j.inpa.2019.08.001
   Beham, 2016, MACHINE LEARN SOIL C, V4, P792
   Bogrekci I, 2007, BIOSYST ENG, V97, P323, DOI 10.1016/j.biosystemseng.2007.03.025
   Botelho Márcio Ramos, 2006, Cienc. Rural, V36, P1179, DOI 10.1590/S0103-84782006000400021
   Breul P, 2006, J GEOTECH GEOENVIRON, V132, P102, DOI 10.1061/(ASCE)1090-0241(2006)132:1(102)
   Brungard CW, 2015, GEODERMA, V239, P68, DOI 10.1016/j.geoderma.2014.09.019
   Chandan T.R., 2018, INT J COMPUT ENG, V8, P25
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Chung SO, 2012, J FAC AGR KYUSHU U, V57, P393
   Morais PAD, 2019, MICROCHEM J, V146, P455, DOI 10.1016/j.microc.2019.01.009
   Deshpande PP, 2017, SOIL CLASSIFICATION, P25
   Dornik A, 2018, PEDOSPHERE, V28, P913, DOI 10.1016/S1002-0160(17)60377-1
   Ehret B, 2010, GEODERMA, V160, P111, DOI 10.1016/j.geoderma.2009.09.008
   Guo PT, 2013, NUTR CYCL AGROECOSYS, V95, P333, DOI 10.1007/s10705-013-9566-9
   GurubasavaMahantesh SD, 2018, ANAL AGR SOIL PH USI, V6, P1812
   Han PC, 2016, COMPUT ELECTRON AGR, V123, P232, DOI 10.1016/j.compag.2016.02.024
   Heung B, 2016, GEODERMA, V265, P62, DOI 10.1016/j.geoderma.2015.11.014
   Ibrahim, 2016, INT J ADV RES COMPUT, V11, P51
   King, 2003, SOIL TEXTURE CLASSIF, P7929
   Kovacevic M, 2010, GEODERMA, V154, P340, DOI 10.1016/j.geoderma.2009.11.005
   KRISHNAM.GS, 1971, GEODERMA, V5, P243, DOI 10.1016/0016-7061(71)90013-9
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   Leng L, 2013, INT C IM SIGN PROC C, P705
   Leng L., 2012, P INT C WAV AN PATT, P164, DOI DOI 10.1109/ICWAPR.2012.6294772
   Leng L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092644
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2012, 2012 25TH IEEE CANADIAN CONFERENCE ON ELECTRICAL & COMPUTER ENGINEERING (CCECE)
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Liess M, 2012, GEODERMA, V170, P70, DOI 10.1016/j.geoderma.2011.10.010
   Maniyath Shima Ramesh, 2018, 2018 International Conference on Design Innovations for 3Cs Compute Communicate Control (ICDI3C). Proceedings, P52, DOI 10.1109/ICDI3C.2018.00019
   Mengistu A. D., 2018, Int J Electr Comput Eng, V8, P989, DOI 10.11591/ijece.v8i2.pp989-995
   O'Donnell TK, 2010, GEODERMA, V157, P86, DOI 10.1016/j.geoderma.2010.03.019
   PROTZ R, 1992, GEODERMA, V53, P275, DOI 10.1016/0016-7061(92)90059-G
   Rahman SA, 2018, INT CONF COMPUT INFO
   Ramar, 2014, INT J COMPUT APPL, V88, P8
   Sharma HK, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC 2018), P885, DOI 10.1109/ICCMC.2018.8488103
   Shenbagavalli R., 2011, Bonfring Int J Adv Image Process, V1, P15, DOI [10.9756/BIJAIP.1004, DOI 10.9756/BIJAIP.1004]
   Shukla G, 2018, INT J REMOTE SENS, V39, P2637, DOI 10.1080/01431161.2018.1430399
   Sneha Pethkar Sneha Pethkar, 2018, International Journal for Research in Applied Science and Engineering Technology, V6, P819
   Sofou A, 2005, IEEE GEOSCI REMOTE S, V2, P394, DOI 10.1109/LGRS.2005.851752
   Srunitha K., 2016, 2016 International Conference on Signal Processing, Communication, Power and Embedded System (SCOPES), P411, DOI 10.1109/SCOPES.2016.7955863
   Suchithra M.S., 2020, Information Processing in Agriculture, V7, P72, DOI 10.1016/j.inpa.2019.05.003
   Sudarsan B, 2018, COMPUT ELECTRON AGR, V148, P217, DOI 10.1016/j.compag.2018.03.019
   Taghizadeh-Mehrjardi R, 2015, GEODERMA, V253, P67, DOI 10.1016/j.geoderma.2015.04.008
   TERRIBILE F, 1992, GEODERMA, V55, P159, DOI 10.1016/0016-7061(92)90011-U
   Uddin, 2019, 6 INT C COMP SUST GL
   Utpal Barman Utpal Barman, 2018, Journal of Applied and Natural Science, V10, P805, DOI 10.31018/jans.v10i2.1701
   VandenBygaart AJ, 1999, GEODERMA, V89, P333, DOI 10.1016/S0016-7061(98)00089-5
   Wu W, 2018, COMPUT ELECTRON AGR, V144, P86, DOI 10.1016/j.compag.2017.11.037
   Yang ZY, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121464
   Yu Y, 2019, OPT EXPRESS, V27, P23029, DOI 10.1364/OE.27.023029
   Zádorová T, 2015, GEODERMA, V253, P122, DOI 10.1016/j.geoderma.2015.04.012
   Zhang Y, 2019, EUR J SOIL SCI, V70, P27, DOI 10.1111/ejss.12699
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
   Zhao ZY, 2009, COMPUT ELECTRON AGR, V65, P36, DOI 10.1016/j.compag.2008.07.008
NR 59
TC 30
Z9 34
U1 6
U2 81
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 14887
EP 14914
DI 10.1007/s11042-021-10544-5
EA JAN 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000613057400005
DA 2024-07-18
ER

PT J
AU Kannojia, SP
   Kumar, J
AF Kannojia, Suresh Prasad
   Kumar, Jasvant
TI XOR-based visual secret sharing scheme using pixel vectorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pixel vectorization; XOR; XOR-based visual cryptography; Security;
   Secret sharing; Visual cryptography; Visual secret sharing schemes
ID CHEATING PREVENTION; CRYPTOGRAPHY; STEGANOGRAPHY; ENCRYPTION; QUALITY
AB The XOR operation has improved the recovery effect of the visual secret sharing schemes. Various visual secret sharing schemes based on XOR operation are available in the literature with some limitations, e.g. direct non-applicability of the scheme to the gray-scale images and reduced quality of the reconstructed secret image. Many existing visual secret sharing schemes in the literature, firstly converts grayscale secret image into a halftone image then creates the shares. This paper proposes XOR-based (n,n) - VCSXOR visual secret sharing scheme using pixel vectorization. It diffuses and disguise secret information into multiple meaningless shares prior to allocating participants of the group having no clue about the secret information. The scheme also resolves various problems like pixel expansion, contrast-loss, explicit codebook requirement, limitation on number of participants and lossy recovery of the secret image. The proposed scheme makes use of implicit codebook and pixel vectorization to encode gray secret image directly without converting to halftone image, into multiple random looking shares. Also applicable to binary image. Reveal a secret image perfectly by XOR-ing all share. The efficacy of the proposed scheme is verified by numerical illustrations, experimental results and comparative analysis. We found that proposed scheme outperform in comparison to the state-of-the-art approaches.
C1 [Kannojia, Suresh Prasad] Univ Lucknow, Dept Comp Sci, Lucknow 226007, UP, India.
   [Kumar, Jasvant] Univ Lucknow, Dept Comp Sci, ICT Res Lab, Lucknow 226007, UP, India.
C3 Lucknow University; Lucknow University
RP Kumar, J (corresponding author), Univ Lucknow, Dept Comp Sci, ICT Res Lab, Lucknow 226007, UP, India.
EM spkannojia@gmail.com; er.jaswantsingh786@gmail.com
FU University Grant Commission, India (RGNF award)
   [F1-17.1/2014-15/RGNF-2014-15-SC-UTT-87345/(SA-III/Website)]; University
   of Lucknow, Lucknow
FX This work was supported by University Grant Commission, India (RGNF
   award No : F1-17.1/2014-15/RGNF-2014-15-SC-UTT-87345/(SA-III/Website))
   and University of Lucknow, Lucknow.
CR Blundo C, 2003, SIAM J DISCRETE MATH, V16, P224, DOI 10.1137/S0895480198336683
   Blundo C, 2001, DESIGN CODE CRYPTOGR, V24, P255, DOI 10.1023/A:1011271120274
   Chao HC, 2017, DISPLAYS, V49, P6, DOI 10.1016/j.displa.2017.05.004
   Chattopadhyay AK, 2021, MULTIMED TOOLS APPL, V80, P35051, DOI 10.1007/s11042-020-09174-0
   Chen TH, 2012, SIGNAL PROCESS, V92, P2229, DOI 10.1016/j.sigpro.2012.02.015
   Chen TH, 2012, INFORM SCIENCES, V189, P255, DOI 10.1016/j.ins.2011.11.026
   Chen TH, 2011, IEEE T CIRC SYST VID, V21, P1693, DOI 10.1109/TCSVT.2011.2133470
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chen YC, 2013, DIGIT SIGNAL PROCESS, V23, P1496, DOI 10.1016/j.dsp.2013.05.014
   Chen YC, 2012, IEEE T IMAGE PROCESS, V21, P3319, DOI 10.1109/TIP.2012.2190082
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Cu DH, 2015, SIGNAL PROCESS, V108, P604, DOI 10.1016/j.sigpro.2014.10.011
   Deshmukh M, 2018, MULTIMED TOOLS APPL, V77, P89, DOI 10.1007/s11042-016-4229-x
   Fu ZX, 2019, MULTIMED TOOLS APPL, V78, P2367, DOI 10.1007/s11042-018-6364-z
   Guo T, 2014, SIGNAL PROCESS, V94, P90, DOI 10.1016/j.sigpro.2013.06.003
   Hofmeister T, 2000, THEOR COMPUT SCI, V240, P471, DOI 10.1016/S0304-3975(99)00243-1
   Hu CM, 2007, IEEE T IMAGE PROCESS, V16, P36, DOI 10.1109/TIP.2006.884916
   Jia XX, 2019, MULTIMED TOOLS APPL, V78, P8207, DOI 10.1007/s11042-018-6779-6
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Koga H, 2006, DESIGN CODE CRYPTOGR, V40, P81, DOI 10.1007/s10623-005-6700-y
   Lee YS, 2012, SIGNAL PROCESS, V92, P727, DOI 10.1016/j.sigpro.2011.09.015
   Lian CF, 2015, COMPUT J, V58, P2426, DOI 10.1093/comjnl/bxu078
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin CH, 2015, J VIS COMMUN IMAGE R, V33, P31, DOI 10.1016/j.jvcir.2015.08.018
   Lin CH, 2014, J VIS COMMUN IMAGE R, V25, P1543, DOI 10.1016/j.jvcir.2014.06.011
   Lin SJ, 2012, IEEE T INF FOREN SEC, V7, P197, DOI 10.1109/TIFS.2011.2167229
   Liu F, 2014, INT WORKSH DIG WAT, P333
   Liu F, 2009, DESIGN CODE CRYPTOGR, V50, P215, DOI 10.1007/s10623-008-9225-3
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Pang LJ, 2016, SECUR COMMUN NETW, V9, P966, DOI 10.1002/sec.1392
   Praveen K, 2018, ADV INTELL SYST, V563, P257, DOI 10.1007/978-981-10-6872-0_24
   Salehi S, 2014, J INF SECUR APPL, V19, P245, DOI 10.1016/j.jisa.2014.05.003
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   Singh N, 2018, INT C INT SYST DES A, P203
   Singh P, 2018, SIGNAL PROCESS, V142, P301, DOI 10.1016/j.sigpro.2017.06.015
   Tan LD, 2020, MULTIMED TOOLS APPL, V79, P5719, DOI 10.1007/s11042-019-08351-0
   Thien CC, 2003, IEEE T CIRC SYST VID, V13, P1161, DOI 10.1109/TCSVT.2003.819176
   Tsai DS, 2007, PATTERN RECOGN, V40, P2356, DOI 10.1016/j.patcog.2007.01.013
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Tuyls P., 2002, IACR EPRINT ARCH
   Wu X., 2013, P 1 ACM WORKSH INF H, P181, DOI [10.1177/1753193413497191, DOI 10.1145/2482513.2482515]
   Wu XT, 2014, SIGNAL PROCESS, V97, P64, DOI 10.1016/j.sigpro.2013.10.023
   Wu XT, 2013, IEEE T INF FOREN SEC, V8, P1541, DOI 10.1109/TIFS.2013.2274955
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P552, DOI 10.1016/j.jvcir.2013.03.002
   Wu XT, 2013, SIGNAL PROCESS, V93, P977, DOI 10.1016/j.sigpro.2012.11.014
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P48, DOI 10.1016/j.jvcir.2012.11.001
   Wu XT, 2012, J SYST SOFTWARE, V85, P1852, DOI 10.1016/j.jss.2012.02.046
   Wu XT, 2012, J SYST SOFTWARE, V85, P1119, DOI 10.1016/j.jss.2011.12.041
   Yan XH, 2015, MULTIMED TOOLS APPL, V74, P9279, DOI 10.1007/s11042-014-2080-5
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 51
TC 10
Z9 10
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 14609
EP 14635
DI 10.1007/s11042-020-10352-3
EA JAN 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000612271000002
DA 2024-07-18
ER

PT J
AU Ashraf, A
   Naz, S
   Shirazi, SH
   Razzak, I
   Parsad, M
AF Ashraf, Abida
   Naz, Saeeda
   Shirazi, Syed Hamad
   Razzak, Imran
   Parsad, Mukesh
TI Deep transfer learning for alzheimer neurological disorder detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alzheimer disease; Deep transfer learning; ImageNet; ADNI dataset
ID DISEASE
AB Alzheimer's disease is becoming common in the world with the time. It is an irreversible and progressive brain disorder that slowly destroys the memory and thinking skills and, eventually, the ability to perform the simplest tasks. It becomes severe before the noticeable symptoms appear and causes brain disorder which cannot be cured by any medicines and therapies, however its progression can be slow down through early diagnosis. In this paper, we employed different CNN based transfer learning methods for Alzheimer disease classification. We have applied different parameters, and achieved remarkable accuracy on benchmark ADNI dataset. We have tested 13 differnt flavours of different pre-trained CNN models using a fine-tuned approach of transfer learning across two different domain on ADNI dataset (94 AD, 138 MCI and 146 NC). Comparatively, DenseNet showed better performance by achieving a maximal average accuracy of % 99.05. Significant improvement in accuracy has been observed as compared to previously reported works in terms of specificity, sensitivity and accuracy. The source code of propose framework is publicly available.
C1 [Ashraf, Abida; Naz, Saeeda] GGPGC 1, Abbottabad, Pakistan.
   [Shirazi, Syed Hamad] Hazara Univ, Dept IT, Mansehra, Pakistan.
   [Razzak, Imran] Deakin Univ, Geelong, Vic, Australia.
   [Parsad, Mukesh] Univ Technol, Sydney, NSW, Australia.
C3 Hazara University; Deakin University; University of Technology Sydney
RP Razzak, I (corresponding author), Deakin Univ, Geelong, Vic, Australia.
EM imran.razzak@ieee.org
RI Ashraf, Abida/JKJ-6850-2023; Razzak, Imran/AEW-5139-2022; Shirazi, Syed
   Hamad/GQI-1993-2022
OI Razzak, Imran/0000-0002-3930-6600; Shirazi, Syed
   Hamad/0000-0001-9534-4719; Prasad, Mukesh/0000-0002-7745-9667
CR Anand KS, 2012, ANN INDIAN ACAD NEUR, V15, P239, DOI 10.4103/0972-2327.104323
   [Anonymous], 2018, ARXIV180701013
   Asl EH, 2018, FRONT BIOSCI-LANDMRK, V23, P584, DOI 10.2741/4606
   Bäckström K, 2018, I S BIOMED IMAGING, P149, DOI 10.1109/ISBI.2018.8363543
   Ebrahimi-Ghahnavieh A, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INDUSTRY 4.0, ARTIFICIAL INTELLIGENCE, AND COMMUNICATIONS TECHNOLOGY (IAICT), P133, DOI [10.1109/iciaict.2019.8784845, 10.1109/ICIAICT.2019.8784845]
   Emmert-Streib F, 2020, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.00004
   Farooq A, 2017, IEEE CONF IMAGING SY, P111
   Gautam C, 2020, NEURAL NETWORKS, V123, P191, DOI 10.1016/j.neunet.2019.12.001
   Gerstner W, 1998, PULSED NEURAL NETWORKS, P353
   Gupta Ashish, 2013, INT C MACH LEARN, P987
   Harper L, 2014, J NEUROL NEUROSUR PS, V85, P692, DOI 10.1136/jnnp-2013-306285
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hosseini-Asl E, 2016, IEEE IMAGE PROC, P126, DOI 10.1109/ICIP.2016.7532332
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Hunsberger E., 2015, ARXIV151008829
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Ju RH, 2019, IEEE ACM T COMPUT BI, V16, P244, DOI 10.1109/TCBB.2017.2776910
   Kazemi Y, 2018, 2018 IEEE CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY (CIBCB), P154
   Khan RU, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12566
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu MH, 2020, NEUROIMAGE, V208, DOI 10.1016/j.neuroimage.2019.116459
   Mathew J., 2016, 2016 IEEE Annual India Conference, P1
   Naseer A, 2020, NEURAL COMPUT APPL, V32, P839, DOI 10.1007/s00521-019-04069-0
   Razzak MI, 2020, NEURAL COMPUT APPL, V32, P4417, DOI 10.1007/s00521-019-04095-y
   Razzak MI, 2018, L N COMPUT VIS BIOME, V26, P323, DOI 10.1007/978-3-319-65981-7_12
   Razzak MI, 2019, IEEE J BIOMED HEALTH, V23, P1911, DOI 10.1109/JBHI.2018.2874033
   Rehman A., 2020, MULTIMED SYST
   Rehman A, 2020, CIRC SYST SIGNAL PR, V39, P757, DOI 10.1007/s00034-019-01246-3
   Sandeep C., 2017, INT J ENG ADV TECHNO, V6, P38
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sarraf S, 2016, DEEPAD ALZHEIMERS DI, DOI DOI 10.1101/070441
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   TANVEER M, 2020, ACM T MULTIM COMPUT, V16
   Wang SQ, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P517, DOI 10.1109/ICMLA.2018.00083
   Wr┬u┬Ebel B, 2017, PROCEEDINGS OF THE 2, P1, DOI [10.1109/SSCI.2017.8285420, DOI 10.1109/SSCI.2017.8285420]
NR 40
TC 39
Z9 39
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30117
EP 30142
DI 10.1007/s11042-020-10331-8
EA JAN 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000611041300002
DA 2024-07-18
ER

PT J
AU Kumar, M
   Raju, KS
   Kumar, D
   Goyal, N
   Verma, S
   Singh, A
AF Kumar, Manish
   Raju, Kota Solomon
   Kumar, Dinesh
   Goyal, Nitin
   Verma, Sahil
   Singh, Aman
TI An efficient framework using visual recognition for IoT based smart city
   surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fast subspace decomposition; Local binary pattern; Feature reduction;
   Minimum error rate
AB Smart city surveillance systems are the battery operated light weight Internet of Things (IoT) devices. In such devices, automatic face recognition requires a low powered memory efficient visual computing system. For these real time applications in smart cities, efficient visual recognition systems are need of the hour. In this manuscript, efficient fast subspace decomposition over Chi Square transformation is proposed for IoT based on smart city surveillance systems. The proposed technique extracts the features for visual recognition using local binary pattern histogram. The redundant features are discarded by applying the fast subspace decomposition over the Gaussian distributed Local Binary Pattern (LBP) features. This redundancy is major contributor to memory and time consumption for battery based surveillance systems. The proposed technique is suitable for all visual recognition applications deployed in IoT based surveillance devices due to higher dimension reduction. The validation of proposed technique is proved on the basis of well-known databases. The technique shows significant results for all databases when implemented on Raspberry Pi. A comparison of the proposed technique with already existing/reported techniques for the similar applications has been provided. Least error rate is achieved by the proposed technique with maximum feature reduction in minimum time for all the standard databases. Therefore, the proposed algorithm is useful for real time visual recognition for smart city surveillance.
C1 [Kumar, Manish; Kumar, Dinesh] Kurukshetra Univ, Elect Sci Dept, Kurukshetra, Haryana, India.
   [Raju, Kota Solomon] CSIR, Cent Elect Engn Res Inst, Pilani, Rajasthan, India.
   [Goyal, Nitin] Chitkara Univ, Chitkara Univ Inst Engn & Technol, Rajpura, Punjab, India.
   [Verma, Sahil] Chandigarh Univ, Dept Comp Sci & Engn, Mohali 140413, Punjab, India.
   [Singh, Aman] Lovely Profess Univ, Dept Comp Sci & Engn, Phagwara, Punjab, India.
C3 Kurukshetra University; Council of Scientific & Industrial Research
   (CSIR) - India; CSIR - Central Electronics Engineering Research
   Institute (CEERI); Chitkara University, Punjab; Chandigarh University;
   Lovely Professional University
RP Singh, A (corresponding author), Lovely Profess Univ, Dept Comp Sci & Engn, Phagwara, Punjab, India.
EM ermanish205@gmail.com; kotasolomonceeri@gmail.com;
   dineshkumaresdkuk@email.com; nitin.goyal@chifkara.edu.in;
   sahilverma@ieee.org; amansingh.x@gmail.com
RI KUMAR, DINESH/JTT-7703-2023; Bajpai, Jitendra/AFE-9237-2022; Verma, Dr
   Sahil/AAO-3572-2020; goyal, nitin/N-3696-2018; University,
   Chitkara/AAZ-3040-2021; Singh, Aman/AAJ-3054-2021; Kalra, D/H-6661-2019
OI Verma, Dr Sahil/0000-0003-3136-4029; goyal, nitin/0000-0001-7878-363X;
   University, Chitkara/0000-0003-3776-7136; Singh,
   Aman/0000-0001-6571-327X; Kalra, D/0000-0001-5254-4067
CR Abozaid A, 2019, MULTIMED TOOLS APPL, V78, P16345, DOI 10.1007/s11042-018-7012-3
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Alrjebi MM, 2018, MULTIMED TOOLS APPL, V77, P25659, DOI 10.1007/s11042-018-5812-0
   Alwakeel M., 2010, EURO J SCI RES, V42, P25
   Barcelona, 1999, AR FACE DATABASE ABS, V24
   Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389
   Chen GY, 2019, MULTIMED TOOLS APPL, V78, P26615, DOI 10.1007/s11042-019-07810-y
   Chengbin Zeng, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2069, DOI 10.1109/ICPR.2010.509
   COMON P, 1990, P IEEE, V78, P1327, DOI 10.1109/5.58320
   Dahmouni A, 2018, MULTIMED TOOLS APPL, V77, P27471, DOI 10.1007/s11042-018-5932-6
   Ghanem B., 2010, LECT NOTES COMPUT SC, P223
   Gumus E, 2010, EXPERT SYST APPL, V37, P6404, DOI 10.1016/j.eswa.2010.02.079
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Huan EY, 2020, MULTIMED TOOLS APPL, V79, P11905, DOI 10.1007/s11042-019-08376-5
   Kas M, 2020, MULTIMED TOOLS APPL, V79, P375, DOI 10.1007/s11042-019-08049-3
   Khan SA, 2018, MULTIMED TOOLS APPL, V77, P1133, DOI 10.1007/s11042-016-4324-z
   Li LP, 2020, MULTIMED TOOLS APPL, V79, P23325, DOI 10.1007/s11042-020-08965-9
   Li Z, 2012, IEEE T IMAGE PROCESS, V21, P2130, DOI 10.1109/TIP.2011.2173697
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu SG, 2020, IEEE ACCESS, V8, P8668, DOI 10.1109/ACCESS.2019.2960928
   Péteri R, 2010, PATTERN RECOGN LETT, V31, P1627, DOI 10.1016/j.patrec.2010.05.009
   REILLY JP, 1987, P IEEE, V75, P1692, DOI 10.1109/PROC.1987.13939
   Ren JF, 2015, PATTERN RECOGN, V48, P3180, DOI 10.1016/j.patcog.2015.02.001
   Ren JF, 2015, IEEE T IMAGE PROCESS, V24, P1893, DOI 10.1109/TIP.2015.2409554
   Ren JF, 2013, INT CONF ACOUST SPEE, P2400, DOI 10.1109/ICASSP.2013.6638085
   Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976
   Ren JF, 2013, PATTERN RECOGN, V46, P45, DOI 10.1016/j.patcog.2012.06.013
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123
   Shao CB, 2018, J ENG-JOE, P1668, DOI 10.1049/joe.2018.8306
   Sharma S, 2020, MULTIMED TOOLS APPL, V79, P17303, DOI 10.1007/s11042-020-08688-x
   Shoba VBT, 2020, MULTIMED TOOLS APPL, V79, P22595, DOI 10.1007/s11042-020-08997-1
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tiong LCO, 2019, MULTIMED TOOLS APPL, V78, P22743, DOI 10.1007/s11042-019-7618-0
   Tufts D. W., 1985, ICASSP 85. Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No. 85CH2118-8), P320
   Wu JX, 2014, PROC CVPR IEEE, P2577, DOI 10.1109/CVPR.2014.330
   Wu JX, 2012, PROC CVPR IEEE, P2344, DOI 10.1109/CVPR.2012.6247946
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   XU GH, 1994, IEEE T SIGNAL PROCES, V42, P539, DOI 10.1109/78.277846
   XU GH, 1991, CONFERENCE RECORD OF THE TWENTY-FIFTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P908, DOI 10.1109/ACSSC.1991.186578
   Xu Y, 2011, IEEE I CONF COMP VIS, P1219, DOI 10.1109/ICCV.2011.6126372
   Zhang N., 2016, PATTERNS DETERMINANT, P1
   Zhang SW, 2018, MULTIMED TOOLS APPL, V77, P12331, DOI 10.1007/s11042-017-4884-6
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
   Zhou LJ, 2019, MULTIMED TOOLS APPL, V78, P14971, DOI 10.1007/s11042-018-6868-6
   Zou GF, 2020, MULTIMED TOOLS APPL, V79, P23571, DOI 10.1007/s11042-020-09076-1
NR 46
TC 19
Z9 19
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 31277
EP 31295
DI 10.1007/s11042-020-10471-x
EA JAN 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000609068600003
PM 33495686
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Deng, J
   Zhou, MJ
   Wang, CH
   Wang, SC
   Xu, C
AF Deng, Jie
   Zhou, Minjun
   Wang, Chunhua
   Wang, Sicheng
   Xu, Cong
TI Image segmentation encryption algorithm with chaotic sequence generation
   participated by cipher and multi-feedback loops
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic image encryption; Segmentation encryption; Hyperchaotic system;
   Ciphertext feedback; Closed-loop structure
AB The existing chaotic image encryption algorithms have common defects: (i) ciphertext does not participate in the generation processes of chaotic pseudo-random sequences and key sequences; (ii) the entire encryption process does not have a closed-loop structure. In order to solve above problems, in this paper, an image segmentation encryption algorithm based on hyperchaotic system is proposed. We decompose the scrambled sequence into three sequences of different lengths: S-1, S-2 and S-3. Then, the initial values of the chaotic system are updated by the sequences S-2 and S-3 and using the updated initial value iterates the chaotic system and generates the key sequence K-3, and the sequence S-1 is encrypted by the sequence K-3 to obtain the cipher sequence C-1, using the sequences C-1 and S-3 updates the initial value of the chaotic system, and using the updated initial value iterates the chaotic system and generates the key sequence K-4, and using the sequence K-4 encrypts the sequence S-2 to obtain the cipher sequence C-2. Thus, ciphertext participates in the generation processes of chaotic pseudo-random sequences and key sequences, and the entire encryption process has a closed-loop structure. The experimental results show that the encryption algorithm has high security and sensitivity.
C1 [Deng, Jie; Zhou, Minjun; Wang, Chunhua; Wang, Sicheng; Xu, Cong] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
C3 Hunan University
RP Wang, CH (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
EM wch1227164@hnu.edu.cn
RI Wang, Chunhua/HCH-5464-2022
OI Wang, Chunhua/0000-0001-6522-9795
FU National Natural Science Foundation of China [61971185]; Natural Science
   Foundation of Hunan Province [2020JJ4218]
FX This work is supported by the National Natural Science Foundation of
   China (No.61971185) and Natural Science Foundation of Hunan
   Province(2020JJ4218).
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Arroyo D, 2013, SIGNAL PROCESS, V93, P1358, DOI 10.1016/j.sigpro.2012.11.019
   Chai XL, 2016, CHINESE PHYS B, V25, DOI 10.1088/1674-1056/25/10/100503
   Cheng GF, 2020, MULTIMED TOOLS APPL, V79, P29243, DOI 10.1007/s11042-020-09542-w
   Deng QL, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420500868
   Ghebleh M, 2014, SIGNAL PROCESS-IMAGE, V29, P618, DOI 10.1016/j.image.2013.09.009
   Kaur M, 2018, ELECTRON LETT, V54, P562, DOI 10.1049/el.2017.4426
   Kwok HS, 2007, CHAOS SOLITON FRACT, V32, P1518, DOI 10.1016/j.chaos.2005.11.090
   Li CQ, 2017, IEEE MULTIMEDIA, V24, P64, DOI 10.1109/MMUL.2017.3051512
   Lin HR, 2020, COMMUN NONLINEAR SCI, V90, DOI 10.1016/j.cnsns.2020.105390
   Lin HR, 2020, NONLINEAR DYNAM, V99, P2369, DOI 10.1007/s11071-019-05408-5
   Liu HJ, 2013, OPTIK, V124, P3527, DOI 10.1016/j.ijleo.2012.10.068
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu MH, 2010, INT J BIFURCAT CHAOS, V20, P1201, DOI 10.1142/S021812741002640X
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Patidar V, 2009, COMMUN NONLINEAR SCI, V14, P3056, DOI 10.1016/j.cnsns.2008.11.005
   Rhouma R, 2010, COMMUN NONLINEAR SCI, V15, P1887, DOI 10.1016/j.cnsns.2009.07.007
   Wang CH, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S0218127417500912
   Wang SC, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2019.105995
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Xu C, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420500601
   Xu C, 2020, MULTIMED TOOLS APPL, V79, P5573, DOI 10.1007/s11042-019-08273-x
   Ye GD, 2017, NEUROCOMPUTING, V251, P45, DOI 10.1016/j.neucom.2017.04.016
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Yin Q, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500475
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zhou MJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107484
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
   Zhu MH, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501849
NR 29
TC 54
Z9 56
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13821
EP 13840
DI 10.1007/s11042-020-10429-z
EA JAN 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000608669300004
DA 2024-07-18
ER

PT J
AU Ali, Z
   Razzaq, A
   Ali, S
   Qadri, S
   Zia, A
AF Ali, Zulqurnain
   Razzaq, Abdul
   Ali, Sajid
   Qadri, Sulman
   Zia, Azam
TI Improving sentiment analysis efficacy through feature synchronization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text mining; Sentiment analysis; Sentiment polarity; KNN
ID FEATURE-SELECTION
AB Social media platforms are becoming a rich source of valuable information through sharing and publishing user generated reviews and comments. The identification and extraction of subjective information from a piece of text is a crucial challenge in sentiment analysis. Numerous techniques have been proposed that aimed to analyze the sentiments of the text. However, accuracy was compromised due to inadequate identification of intensity, sentiments shifter and negation of words as well as divergence between tweets and their associated labels. In this study, Prescriptive Sentiment Analysis (PSA) based on features synchronization has been introduced for increasing accuracy in text sentiment analysis. At first, pre-processing has been performed which includes removal of stop words and tokenizing the text into sentiment words, intensity words, sentiment shifters and negation words. Secondly; polarity of intensity words, clauses and sentiment shifters in the text are calculated. Identification and removal of ambiguity between extracted features and their associated labels have been accomplished through feature synchronization. The K-Nearest Neighbor (KNN) has been implemented to predict text trend based on synchronized features. The proposed approach has been evaluated on publicly available datasets of twitter and movie reviews. Experimental results show significant improvement in sentiment analysis efficiency as compared to other baseline methods.
C1 [Ali, Zulqurnain] IT Div NFC Inst Engn & Technol, Multan, Pakistan.
   [Razzaq, Abdul] MNS Univ Agr, Dept Comp Sci, Multan, Pakistan.
   [Ali, Sajid] Univ Educ, Dept Comp Sci, Lahore, Pakistan.
   [Qadri, Sulman] Islamia Univ, Dept Comp Sci & IT, Bahawalpur, Pakistan.
   [Zia, Azam] Univ Agr Faisalabad, Dept Comp Sci, Faisalabad, Pakistan.
C3 University of Agriculture Faisalabad
RP Razzaq, A (corresponding author), MNS Univ Agr, Dept Comp Sci, Multan, Pakistan.
EM abdul.ranag@mnsuam.edu.pk
RI Ali, Sk/JEO-9086-2023; Ali, Shujat/JJF-4668-2023; Ali,
   Sajid/IWD-7100-2023
OI Ali, Shujat/0000-0002-4467-6091; Ali, Sajid/0000-0002-1287-849X; Qadri,
   Salman/0000-0002-3503-6535; Razzaq, Abdul/0000-0003-4511-387X
CR Ahmed M, 2020, NEURAL COMPUT APPL, V32, P14719, DOI 10.1007/s00521-020-04824-8
   Alelyani S, 2014, CH CRC DATA MIN KNOW, P29
   [Anonymous], 2004, MERR WEBST COLL DICT
   Basant A, 2015, SENTIMENT ANAL USING
   Berka P, 2020, J INTELL INF SYST, V55, P51, DOI 10.1007/s10844-019-00591-8
   Chaovalit P., 2005, HAWAII INT C SYSTEM, V4, p112c, DOI DOI 10.1109/HICSS.2005.445
   da Silva NFF, 2014, DECIS SUPPORT SYST, V66, P170, DOI 10.1016/j.dss.2014.07.003
   Dang NC, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030483
   Elloumi S, 2020, NAT LANG ENG, V26, P221, DOI 10.1017/S1351324919000160
   Fei, 2015, P 28 INT FORART INT
   Gautam G, 2014, INT CONF CONTEMP, P437, DOI 10.1109/IC3.2014.6897213
   Go Alec., 2009, CS224N project report 1.12
   Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P755
   Huang MH, 2020, INFORM SCIENCES, V520, P389, DOI 10.1016/j.ins.2020.02.026
   Hussein Doaa Mohey El-Din Mohamed, 2018, Journal of King Saud University - Engineering Sciences, V30, P330, DOI 10.1016/j.jksues.2016.04.002
   Hutto C., 2014, P INT AAAI C WEB SOC, V8, P216, DOI [DOI 10.1609/ICWSM.V8I1.14550, 10.1609/icwsm.v8i1.14550]
   Jeyapriya A, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P548, DOI 10.1109/ECS.2015.7124967
   Jindal N., 2008, P WSDM, P219, DOI [DOI 10.1145/1341531.1341560, 10.1145/1341531.1341560]
   Khan FH, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATION SOCIETY (I-SOCIETY 2014), P291, DOI 10.1109/i-Society.2014.7009062
   Khan Jawad., 2016, P 6 INT C EMERGING D, P159
   Koehler Matthew., 2015, Proceedings of Society for Information Technology Teacher Education International Conference, P1348
   Konstantinos, 2011, WIMS 11 P INT C WEB
   Kumar A, 2019, MULTIMED TOOLS APPL, V78, P24103, DOI 10.1007/s11042-019-7390-1
   Lin KC, 2016, J SUPERCOMPUT, V72, P3210, DOI 10.1007/s11227-016-1631-0
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Liu LZ, 2014, CHINA COMMUN, V11, P154, DOI 10.1109/CC.2014.6825268
   Minaee S, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101794
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Sami, 2017, ESOLEC, P115
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Song Y, 2017, MULTIMED TOOLS APPL, V76, P11319, DOI 10.1007/s11042-016-3445-8
   Strapparava C, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P1556
   Tripathy A, 2015, PROCEDIA COMPUT SCI, V57, P821, DOI 10.1016/j.procs.2015.07.523
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   Xiang LY, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8091558
   Yadollahi A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3057270
   Yang BS, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P325
   Zhang ZF, 2014, LECT NOTES COMPUT SC, V8485, P711, DOI 10.1007/978-3-319-08010-9_77
   Zhao JQ, 2018, IEEE ACCESS, V6, P23253, DOI 10.1109/ACCESS.2017.2776930
   Zheng Fei., 2010, Encyclopedia of Machine Learning, P990
NR 40
TC 3
Z9 3
U1 3
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13325
EP 13338
DI 10.1007/s11042-020-10383-w
EA JAN 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607776300008
DA 2024-07-18
ER

PT J
AU Cheng, YH
   Wang, SA
   Yu, DH
AF Cheng, Yuanhao
   Wang, Sun'an
   Yu, Dehong
TI Improved fast compressive tracking for low-altitude flying target
   tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low-altitude flying target; Object tracking; Visual tracking; Improved
   fast compressive tracking
ID ROBUST OBJECT TRACKING; VISUAL TRACKING; SPARSE-REPRESENTATION; PARTICLE
   FILTER; UAV
AB Effective and efficient low-altitude flying target tracking in the field of visual tracking is challenging due to factors such as background interference, a small target imaging area, scale changes, and in-plane/out-of-plane rotation. Fast compressive tracking is an effective algorithm that combines compressive sensing theory and the naive Bayes classifier to track targets in real-time. Since the target motion information is not used in the tracking process and a fixed learning rate is adopted, the target may be lost during tracking, especially when the background interference is considerable or when in-plane/out-of-plane rotation exists. To solve this problem, first, target motion information was introduced to reduce the search area for predicting the target position. Then, the confidence calculation was optimized by comprehensively considering the posterior probability of the candidate region and the positive sample membership value. Finally, the learning rate was dynamically adjusted according to the target velocity and optimized confidence. Experimental results verified that the proposed method could effectively improve the efficiency, accuracy, and robustness of target tracking.
C1 [Cheng, Yuanhao; Wang, Sun'an; Yu, Dehong] Xi An Jiao Tong Univ, Sch Mech Engn, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Cheng, YH; Wang, SA (corresponding author), Xi An Jiao Tong Univ, Sch Mech Engn, Xian 710049, Peoples R China.
EM cyhv2006@126.com; sawang@xjtu.edu.cn
OI , Yuanhao/0000-0003-3102-3208
FU National Nature Science Foundation of China [51375368]; Shaanxi Key
   Research and Development Program of China [2018NY-111]
FX The authors appreciate the financial support from the National Nature
   Science Foundation of China under Grant No. 51375368, and the Shaanxi
   Key Research and Development Program of China under Grant No.
   2018NY-111. We also thank the anonymous reviewers for their critical
   comments and suggestions for improving the manuscript.
CR Abdelpakey MH, 2020, IEEE T IMAGE PROCESS, V29, P1479, DOI 10.1109/TIP.2019.2942506
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Badal T, 2018, MULTIMED TOOLS APPL, V77, P25199, DOI 10.1007/s11042-018-5781-3
   Chen JG, 2019, MULTIMED TOOLS APPL, V78, P22463, DOI 10.1007/s11042-019-7514-7
   Chen WS, 2019, AERONAUT J, V123, P191, DOI 10.1017/aer.2018.158
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Fu CH, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107324
   Fu WN, 2016, MULTIMED TOOLS APPL, V75, P15553, DOI 10.1007/s11042-015-2519-3
   Gao Y, 2015, IET COMPUT VIS, V9, P857, DOI 10.1049/iet-cvi.2014.0431
   Grabner H., 2006, BMVC, P47
   Han YM, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.107027
   Hardalaç F, 2018, MULTIMED TOOLS APPL, V77, P24059, DOI 10.1007/s11042-018-5661-x
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   He ZY, 2017, IEEE T CYBERNETICS, V47, P354, DOI 10.1109/TCYB.2016.2514714
   Huang W, 2019, MULTIMED TOOLS APPL, V78, P16011, DOI 10.1007/s11042-018-6956-7
   Jenkins MD, 2016, PATTERN RECOGN LETT, V69, P82, DOI 10.1016/j.patrec.2015.10.014
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Lukezic A, 2018, INT J COMPUT VISION, V126, P671, DOI 10.1007/s11263-017-1061-3
   Luo MQ, 2016, CHIN CONT DECIS CONF, P4627, DOI 10.1109/CCDC.2016.7531819
   Ma C, 2018, INT J COMPUT VISION, V126, P771, DOI 10.1007/s11263-018-1076-4
   Truong MTN, 2018, MULTIMED TOOLS APPL, V77, P30067, DOI 10.1007/s11042-018-6180-5
   Moudgil A, 2019, LECT NOTES COMPUT SC, V11362, P629, DOI 10.1007/978-3-030-20890-5_40
   Pan Z, 2017, MULTIMED TOOLS APPL, V76, P16989, DOI 10.1007/s11042-016-3647-0
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Shen MY, 2018, MULTIMED TOOLS APPL, V77, P25109, DOI 10.1007/s11042-018-5770-6
   Sliti O, 2019, MULTIMED TOOLS APPL, V78, P21759, DOI 10.1007/s11042-019-7439-1
   Wu YW, 2017, IEEE ACCESS, V5, P23969, DOI 10.1109/ACCESS.2017.2764419
   XIONG JT, 2016, MATEC WEB CONF, V59
   Xiong Z, 2016, 11 INT C WIR COMM NE
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang TZ, 2019, IEEE T PATTERN ANAL, V41, P365, DOI 10.1109/TPAMI.2018.2797062
   Zhang TZ, 2018, IEEE T IMAGE PROCESS, V27, P2676, DOI 10.1109/TIP.2017.2781304
   Zhang TZ, 2015, INT J COMPUT VISION, V111, P171, DOI 10.1007/s11263-014-0738-0
   Zhao JW, 2018, MULTIMED TOOLS APPL, V77, P30969, DOI 10.1007/s11042-018-6132-0
NR 39
TC 2
Z9 2
U1 2
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 11239
EP 11254
DI 10.1007/s11042-020-10343-4
EA JAN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000605119800002
DA 2024-07-18
ER

PT J
AU Sethi, S
AF Sethi, Shilpa
TI An optimized crawling technique for maintaining fresh repositories
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information retrieval; Search engine; Crawler; Web repository; Page
   freshness; Latest information
AB With the rapid increase in demand of digital information via internet, it becomes imperative for search engines to serve up to date information in response to user query. A web crawler plays a vital role in maintaining local cache of search engine. Today, the biggest challenge for web crawler is how to harness fresh information in its local cache of n constantly changing web pages. These web pages often possess dynamic creation and updation cycle. Moreover, the resources for downloading possible updates are limited. This problem is formulated as non-deterministic optimization problem. Many attempts had been made by researchers in past to solve it. But most of existing techniques work well for small value of n and often intractable for large corpus. The paper presents an optimal solution to deal with this non- deterministic problem for large data. The experimental results show that technique achieves promising results as compared to existing crawler.
C1 [Sethi, Shilpa] JC Bose Univ Sci & Technol, Dept Comp Applicat, Faridabad, Haryana, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Sethi, S (corresponding author), JC Bose Univ Sci & Technol, Dept Comp Applicat, Faridabad, Haryana, India.
EM munjal.shilpa@gmail.com
RI Sethi, Shilpa Sethi/Z-1669-2019
OI Sethi, Shilpa Sethi/0000-0001-9202-4234
CR [Anonymous], 2003, ACM Transactions on Internet Technology (TOIT), DOI DOI 10.1145/857166.857170
   [Anonymous], 2010, INT J ADV TECHNOL
   Avrachenkov KE, 2018, IEEE T CONTROL NETW, V5, P446, DOI 10.1109/TCNS.2016.2619066
   Azar Y, 2018, P NATL ACAD SCI USA, V115, P8099, DOI 10.1073/pnas.1801519115
   Bhatia S, 2016, INT J INF RETR RES, V6, P1, DOI 10.4018/IJIRR.2016040101
   Boldi P, 2018, ACM T WEB, V12, DOI 10.1145/3160017
   Dikaiakos MD, 2005, COMPUT COMMUN, V28, P880, DOI 10.1016/j.comcom.2005.01.003
   Dixit A., 2011, 2011 International Conference on Communication Systems and Network Technologies (CSNT), P634, DOI 10.1109/CSNT.2011.136
   Hasselquist D, 2019, IEEE ACCESS, V7, P155504, DOI 10.1109/ACCESS.2019.2948793
   Heydon A., 1999, World Wide Web, V2, P219, DOI 10.1023/A:1019213109274
   Kalyan R, 2015, IEEE MTTS INT MICRO, P169, DOI 10.1109/IMaRC.2015.7411429
   Kim K. S., 2012, 2012 International Conference on Information Networking (ICOIN 2012), P562, DOI 10.1109/ICOIN.2012.6164440
   Meusel Robert, 2014, P 23 ACM INT C INF K, P1039, DOI DOI 10.1145/2661829.2661902
   Mukhopadhyay D, 2019, WEB SEARCHING MINING, P85, DOI [10.1007/978-981-13-3053-7_7, DOI 10.1007/978-981-13-3053-7_7]
   Ntoulas A, 2005, ACM-IEEE J CONF DIG, P100, DOI 10.1145/1065385.1065407
   Radinsky Kira, 2013, P 6 ACM INT C WEB SE, P415
   Sethi S, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P1346
   Tarakeswar MK, 2011, J COMP APPL JCA, V4, P2011
   Umbrich Jurgen, 2015, DIACHRON WORKSHOP MA, P50
   Wills RS, 2006, MATH INTELL, V28, P6, DOI 10.1007/BF02984696
   Xu H, 2018, INT C APPL TECHN CYB, P1129
   Xuebo Liu, 2015, Advances in Web-Based Learning - ICWL 2015. 14th International Conference. Proceedings: LNCS 9412, P165, DOI 10.1007/978-3-319-25515-6_15
   Zhao F, 2016, IEEE T SERV COMPUT, V9, P608, DOI 10.1109/TSC.2015.2414931
   Zhu KP, 2008, LECT NOTES COMPUT SC, V4993, P478
NR 24
TC 4
Z9 4
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 11049
EP 11077
DI 10.1007/s11042-020-10250-8
EA JAN 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000604479100011
DA 2024-07-18
ER

PT J
AU Ji, YL
   Wang, WD
   Zhang, YH
AF Ji, Yanli
   Wang, Weidong
   Zhang, Yinghai
TI Periodic multimedia spectrum sensing method based on high-order
   anti-jamming mechanism in cognitive wireless networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cognitive radio; Spectrum resources; Spectrum allocation; Optimal
   matching
AB The cognitive radio network provides high bandwidth for mobile users to reconstruct wireless architecture and dynamic spectrum access technology. The spectrum allocation is the key to cognitive radio spectrum resources for the relative scarcity of radio spectrum resources. The spectrum allocation algorithm must have faster convergence speed to adapt to the time-varying characteristics of cognitive radio networks. In this paper, a spectrum sensing method is proposed based on high-order anti-jamming mechanism for cognitive radio spectrum allocation. Firstly, the combination of cognitive anti-jamming spectrum sensing, channel estimation, learning comprehension, time-hopping frequency hopping, spectrum access control and other technologies can improve the anti-jamming ability. Secondly, cognitive radio can effectively improve the utilization of spectrum resources according to the different benefits of different users on different channels, achieve the best matching between cognitive users and channels and flexible spectrum allocation. Finally, the effectiveness of the proposed algorithm is verified by simulation experiments.
C1 [Ji, Yanli] Beijing Univ Posts & Telecommun, Sch Network Educ, Beijing, Peoples R China.
   [Wang, Weidong; Zhang, Yinghai] Beijing Univ Posts & Telecommun, Informat & Elect Technol Lab, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Beijing University of
   Posts & Telecommunications
RP Ji, YL (corresponding author), Beijing Univ Posts & Telecommun, Sch Network Educ, Beijing, Peoples R China.
EM yangjie1al@163.com
RI Huang, Yu/KDM-9182-2024; chen, yanhong/JVE-0289-2024
CR Acharya UR, 2019, FUTURE GENER COMP SY, V91, P290, DOI 10.1016/j.future.2018.08.044
   Arunkumar N, 2019, SOFT COMPUT, V23, P9083, DOI 10.1007/s00500-018-3618-7
   Arunkumar N, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4962
   Bagyalakshmi G, 2018, IEEE ACCESS, V6, P57144, DOI 10.1109/ACCESS.2018.2872775
   Balogun V, 2013, 8 CYB SEC INF INT RE
   Balogun V., 2013, WIRELESS PERS COMMUN, V72, P2229, DOI [10.1007/s11277-013-1145-5, DOI 10.1007/S11277-013-1145-5]
   Cadeau W, 2012, INFORM SCI SYSTEMS
   Elamaran V, 2018, IEEE ACCESS, V6, P62874, DOI 10.1109/ACCESS.2018.2876119
   Elamaran V, 2018, IEEE ACCESS, V6, P59672, DOI 10.1109/ACCESS.2018.2870557
   Fang S, 2016, IEEE T DEPEND SECURE, V13, P394, DOI 10.1109/TDSC.2015.2399304
   Jafar Mohammadi, 2015, IEEE INT C COMM WORK
   Jiao DD, 2019, FUTURE GENER COMP SY, V92, P324, DOI 10.1016/j.future.2018.10.019
   Khamparia A, 2020, NEURAL COMPUT APPL, V32, P11083, DOI 10.1007/s00521-018-3896-0
   Lakshmanaprabu SK, 2019, FUTURE GENER COMP SY, V92, P374, DOI 10.1016/j.future.2018.10.009
   Li HY, 2019, FUTURE GENER COMP SY, V98, P69, DOI 10.1016/j.future.2018.12.001
   Liu JJ, 2018, IEEE ACCESS, V6, P61457, DOI 10.1109/ACCESS.2018.2876135
   Liu MY, 2009, INT C WIR COMM
   Lo BF, 2013, IEEE INT C COMM
   Machuzak S., 2016, P 2016 IEEE CIC INT
   Oh SL, 2020, NEURAL COMPUT APPL, V32, P10927, DOI 10.1007/s00521-018-3689-5
   Santamaria-Granados L, 2019, IEEE ACCESS, V7, P57, DOI 10.1109/ACCESS.2018.2883213
   Wang BB, 2011, IEEE J SEL AREA COMM, V29, P877, DOI 10.1109/JSAC.2011.110418
   Wang Q, 2016, IEEE T VEH TECHNOL, V65, P8331, DOI 10.1109/TVT.2015.2511071
   Wang Q, 2011, I C NETWORK PROTOCOL
   Wu ZC, 2019, FUTURE GENER COMP SY, V93, P170, DOI 10.1016/j.future.2018.10.018
   Zhang L, 2013, 8 INT C COMP INT SEC
NR 26
TC 0
Z9 0
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35171
EP 35182
DI 10.1007/s11042-019-7533-4
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900025
DA 2024-07-18
ER

PT J
AU Luo, HX
AF Luo, Hongxia
TI Multimedia Portfolio Behavior Analysis Based on Bayesian Game Algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bayesian; Game algorithms; Enterprise investment; Non-cooperation;
   Investment portfolio
AB A portfolio prediction model based on Bayesian game algorithm is proposed to improve the accuracy of correlation analysis model in portfolio application. Firstly, the portfolio problem is analyzed. The market value constraint and the upper bound constraint are combined considering the general portfolio model according to Markowitz theory, it improves the portfolio model and obtains the portfolio model with mixed constraints. Secondly, a probabilistic portfolio monitoring strategy based on incomplete information non-cooperative Bayesian game is proposed. The framework combines the enterprise investment behavior detection module with the specified rules to identify the portfolio pattern, the interaction between portfolio selection and monitored investment behavior is modeled as a two-person non-cooperative Bayesian game, which allows portfolio selection to adopt a probability monitoring strategy based on game Bayesian Nash equilibrium, thereby reducing the computational complexity of the portfolio approach introduced into the game algorithm. Finally, the effectiveness of the proposed algorithm is verified by simulation experiments.
C1 [Luo, Hongxia] Zhejiang Univ Finance & Econ, Sch Accounting, Hangzhou 310000, Peoples R China.
C3 Zhejiang University of Finance & Economics
RP Luo, HX (corresponding author), Zhejiang Univ Finance & Econ, Sch Accounting, Hangzhou 310000, Peoples R China.
EM zhwhongwz@163.com
CR Acharya UR, 2019, FUTURE GENER COMP SY, V91, P290, DOI 10.1016/j.future.2018.08.044
   Goswami M, 2016, INT J PROD RES, V54, P6997, DOI 10.1080/00207543.2016.1150614
   Guan DJ, 2014, INT C MAN SCI ENG
   Hill A., 2013, DRUG METAB REV, V39, P372, DOI [10.1134/S1087659613040184, DOI 10.1134/S1087659613040184]
   Hung JC, 2016, EVOL SYST-GER, V7, P145, DOI 10.1007/s12530-016-9154-8
   Peña D, 2006, J STAT PLAN INFER, V136, P1237, DOI 10.1016/j.jspi.2004.08.020
   Piotroski JD, 2012, REV FINANC STUD, V25, P2841, DOI 10.1093/rfs/hhs061
   Smith JE, 2006, MANAGE SCI, V52, P311, DOI 10.1287/mnsc.1050.0451
   Smith JE, 2004, MANAGE SCI, V50, P561, DOI 10.1287/mnsc.1040.0243
   STANHOUSE B, 1986, J FINANC, V41, P1103, DOI 10.2307/2328166
   Wang GG, 2004, ENG OPTIMIZ, V36, P313, DOI 10.1080/03052150310001639911
   Zhang C., 2014, Advances in Neural Information Processing Systems, P442
   Zhou XC, 2014, INT J FORECASTING, V30, P963, DOI 10.1016/j.ijforecast.2014.03.017
NR 13
TC 0
Z9 0
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35491
EP 35501
DI 10.1007/s11042-019-07954-x
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900043
DA 2024-07-18
ER

PT J
AU Valizadeh, S
   Nasiopoulos, P
   Ward, R
AF Valizadeh, Sima
   Nasiopoulos, Panos
   Ward, Rabab
TI Improving compression efficiency of HEVC using perceptual coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Perceptual video coding; Rate distortion optimization (RDO); Human
   visual system (HVS); PSNR-HVS; High efficiency video coding (HEVC);
   Coding unit structure; CU mode selection
ID RATE-DISTORTION OPTIMIZATION; VIDEO QUALITY; SSIM; ALLOCATION; PSNR
AB The introduction of the new coding tools in HEVC has brought significant bitrate savings compared to the previous standard, H.264/AVC. In both standards, the mean square error (MSE) is used for measuring distortion in the rate distortion optimization process of the coding unit structure and mode selection. However, MSE is not a good measure to use for measuring visual quality as it poorly correlates with human perception. Integration of a video quality metric based on the characteristics of the Human Visual System (HVS) inside the rate distortion optimization procedure is expected to improve the compression efficiency of video coding. In this paper, the PSNR-HVS measure is used in the rate distortion optimization process for the coding unit structure and mode selection. In the first step, we find the scaling factor for the Lagrangian multiplier based on the proposed perceptual approach. In the second step, we find optimal Lagrangian multiplier depending on the quantization parameter. The compression efficiency of the proposed approach is compared to that of HEVC. Simulations prove that the proposed approach yields higher compression efficiency.
C1 [Valizadeh, Sima; Nasiopoulos, Panos; Ward, Rabab] Univ British Columbia, Vancouver, BC, Canada.
C3 University of British Columbia
RP Valizadeh, S (corresponding author), Univ British Columbia, Vancouver, BC, Canada.
EM simav@ece.ubc.ca; panos@ece.ubc.ca; rababw@ece.ubc.ca
FU NPRP grant from the Qatar National Research Fund (Qatar Foundation)
   [NPRP 4-463-2-172]
FX This work was supported by the NPRP grant # NPRP 4-463-2-172 from the
   Qatar National Research Fund (a member of the Qatar Foundation). The
   statements made herein are solely the responsibility of the authors.
CR Ahn YJ, 2019, J REAL-TIME IMAGE PR, V16, P1927, DOI 10.1007/s11554-017-0694-3
   [Anonymous], 1988, Spatial Vision
   [Anonymous], 2013, JCTVCO1002
   [Anonymous], 2006, P IEEE INT C AC SPEE
   Aswathappa Babu Hemanth Kumar, 2010, 2010 42nd Southeastern Symposium on System Theory (SSST 2010), P367, DOI 10.1109/SSST.2010.5442789
   Bjotegaard G., 2001, VCEGM33
   Bossen F., 2012, JCTVCJ1100, P1
   Chen JW, 2007, IEEE T CONSUM ELECTR, V53, P775, DOI 10.1109/TCE.2007.381759
   Chen ZZ, 2010, IEEE T CIRC SYST VID, V20, P806, DOI 10.1109/TCSVT.2010.2045912
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   DAUGMAN JG, 1984, VISION RES, V24, P891, DOI 10.1016/0042-6989(84)90065-8
   Egiazarian K., 2006, proceedings of the second international workshop on video processing and quality metrics, P4
   EVERETT H, 1963, OPER RES, V11, P399, DOI 10.1287/opre.11.3.399
   Fu DH, 2019, IEEE ACCESS, V7, P186587, DOI 10.1109/ACCESS.2019.2960807
   Hamza R, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/1625678
   Harshalatha Y, 2018, MULTIMED TOOLS APPL, V77, P19051, DOI 10.1007/s11042-017-5327-0
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Lambrecht CJV, 1996, P SOC PHOTO-OPT INS, V2668, P450, DOI 10.1117/12.235440
   Lee C, 2003, OPT ENG, V42, P265, DOI 10.1117/1.1523420
   Liu ZY, 2017, MULTIMED TOOLS APPL, V76, P9051, DOI 10.1007/s11042-016-3530-z
   LUKAS FXJ, 1982, IEEE T COMMUN, V30, P1679, DOI 10.1109/TCOM.1982.1095616
   Mai ZY, 2005, IEEE SYS MAN CYBERN, P2673
   Mai ZY, 2005, LECT NOTES COMPUT SC, V3708, P435
   Ou TS, 2011, IEEE T CIRC SYST VID, V21, P682, DOI 10.1109/TCSVT.2011.2129890
   Quan HT, 2012, TELECOMMUN SYST, V49, P35, DOI 10.1007/s11235-010-9351-x
   Recommendation I, 2002, 500 11 METHODOLOGY S
   Rehman A., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P497, DOI 10.1109/ICME.2012.175
   Ruiz D, 2017, MULTIMED TOOLS APPL, V76, P861, DOI 10.1007/s11042-015-3014-6
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Sun XB, 2019, IEEE ACCESS, V7, P56308, DOI 10.1109/ACCESS.2019.2910245
   Sze V., 2014, HIGH EFFICIENCY VIDE, DOI [10.1007/978-3-319-06895-4, DOI 10.1007/978-3-319-06895-4]
   Valizadeh S, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, NETWORKING AND COMMUNICATIONS (ICNC)
   Valizadeh S, 2015, EUR SIGNAL PR CONF, P115, DOI 10.1109/EUSIPCO.2015.7362356
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wang G, 2018, MULTIMED TOOLS APPL, V77, P12777, DOI 10.1007/s11042-017-4914-4
   Wang SQ, 2013, IEEE T IMAGE PROCESS, V22, P1418, DOI 10.1109/TIP.2012.2231090
   Wang SQ, 2012, IEEE T CIRC SYST VID, V22, P516, DOI 10.1109/TCSVT.2011.2168269
   Watson AB, 2001, J ELECTRON IMAGING, V10, P20, DOI 10.1117/1.1329896
   Xiao Feng, 2000, EE392J, P769
   Yang CL, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 4, P291, DOI 10.1109/ICICISYS.2009.5357689
   Yang CL, 2007, ICSPC: 2007 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATIONS, VOLS 1-3, PROCEEDINGS, P340
   Yeo CH, 2013, IEEE T CIRC SYST VID, V23, P1170, DOI 10.1109/TCSVT.2013.2240918
   Zhao TS, 2013, CONF REC ASILOMAR C, P1107, DOI 10.1109/ACSSC.2013.6810465
NR 45
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10235
EP 10254
DI 10.1007/s11042-020-09442-z
EA NOV 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000590503300002
DA 2024-07-18
ER

PT J
AU Chen, YT
   Phonevilay, V
   Tao, JJ
   Chen, X
   Xia, RL
   Zhang, Q
   Yang, K
   Xiong, J
   Xie, JB
AF Chen, Yuantao
   Phonevilay, Volachith
   Tao, Jiajun
   Chen, Xi
   Xia, Runlong
   Zhang, Qian
   Yang, Kai
   Xiong, Jie
   Xie, Jingbo
TI The face image super-resolution algorithm based on combined
   representation learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Combined representation learning; Face image super-resolution; Image
   restoration; Attention mechanism; Deep learning
ID NETWORK
AB Face super-resolution reconstruction is the process of predicting high-resolution face images from one or more observed low-resolution face images, which is a typical pathological problem. As a domain-specific super-resolution task, we can use facial priori knowledge to improve the effect of super-resolution. We propose a method of face image super-resolution reconstruction based on combined representation learning method, using deep residual networks and deep neural networks as generators and discriminators, respectively. First, the model uses residual learning and symmetrical cross-layer connection to extract multilevel features. Local residual mapping improves the expressive capability of the network to enhance performance, solves gradient dissipation in network training, and reduces the number of convolution cores in the model through feature reuse. The feature expression of the face image at the high-dimensional visual level is obtained. The visual feature is sent to the decoder through the cross-layer connection structure. The deconvolution layer is used to restore the spatial dimension gradually and repair the details and texture features of the face. Finally, combine the attention block and the residual block reconstruction in the deep residual network to super-resolution face images that are highly similar to high-resolution images and difficult to be discriminated by the discriminator. On this basis, combined representation learning is conducted to obtain numerous realistic results of visual perception. The experimental results on the face datasets can show that the Peak Signal-to-Noise Ratio of the proposed method is improved.
C1 [Chen, Yuantao; Phonevilay, Volachith; Tao, Jiajun; Chen, Xi] Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410114, Hunan, Peoples R China.
   [Xia, Runlong; Xie, Jingbo] Hunan Inst Sci & Tech Informat, Changsha 411105, Hunan, Peoples R China.
   [Zhang, Qian; Yang, Kai] Hunan ZOOMLION Intelligent Technol Corp Ltd, Dept Elect Prod, Changsha 410005, Hunan, Peoples R China.
   [Xiong, Jie] Yangtze Univ, Elect & Informat Sch, Jingzhou 434023, Peoples R China.
C3 Changsha University of Science & Technology; Yangtze University
RP Chen, YT (corresponding author), Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410114, Hunan, Peoples R China.
EM chenyt@csust.edu.cn; pvolachith@yahoo.com; taojiajun@stu.csust.edu.cn;
   chentianjun@163.com; xiarunlong@vip.qq.com; zhangqian@zoomlion.com;
   yangkai@zoomlion.com; xiongjie@yangtzeu.edu.cn; xiejb@hnst.gov.cn
RI Tao, Jiajun/ISA-2359-2023; Chen, Yuantao/AAC-7165-2019
OI Tao, Jiajun/0000-0002-3201-3004; Chen, Yuantao/0000-0003-2277-1765
FU National Natural Science Foundation of China [61972056, 61772454,
   61402053, 61981340416]; Hunan Provincial Natural Science Foundation of
   China [2020JJ4623]; Scientific Research Fund of Hunan Provincial
   Education Department [17A007, 19C0028, 19B005]; Changsha Science and
   Technology Planning [KQ1703018, KQ1804023, KQ1902007]; Junior Faculty
   Development Program Project of Changsha University of Science and
   Technology [2019QJCZ011]; "Double First-class" International Cooperation
   and Development Scientific Research Project of Changsha University of
   Science and Technology [2019IC34]; Practical Innovation and
   Entrepreneurship Ability Improvement Plan for Professional Degree
   Postgraduate of Changsha University of Science and Technology
   [SJCX202072]; Postgraduate Training Innovation Base Construction Project
   of Hunan Province [2019-248-51, 2020-172-48]; Beidou Micro Project of
   Hunan Provincial Education Department [149, XJT[2020]]
FX This study was funded by the National Natural Science Foundation of
   China (Grant number 61972056, 61772454, 61402053, 61981340416), the
   Hunan Provincial Natural Science Foundation of China (Grant number
   2020JJ4623), the Scientific Research Fund of Hunan Provincial Education
   Department (Grant number 17A007, 19C0028, 19B005), the Changsha Science
   and Technology Planning (Grant number KQ1703018, KQ1804023, KQ1902007),
   the Junior Faculty Development Program Project of Changsha University of
   Science and Technology (Grant number 2019QJCZ011), the "Double
   First-class" International Cooperation and Development Scientific
   Research Project of Changsha University of Science and Technology (Grant
   number 2019IC34), the Practical Innovation and Entrepreneurship Ability
   Improvement Plan for Professional Degree Postgraduate of Changsha
   University of Science and Technology (Grant number SJCX202072), the
   Postgraduate Training Innovation Base Construction Project of Hunan
   Province (Grant number 2019-248-51, 2020-172-48), the Beidou Micro
   Project of Hunan Provincial Education Department (Grant number XJT[2020]
   No.149).
CR Caruana R., 1995, Advances in Neural Information Processing Systems 7, P657
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Chun MM, 2000, TRENDS COGN SCI, V4, P170, DOI 10.1016/S1364-6613(00)01476-5
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Goodfellow I, 2014, P ANN C NEUR INF PRO, P5672
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang KB, 2017, MULTIMED TOOLS APPL, V76, P3139, DOI 10.1007/s11042-015-3215-z
   Jiang J, 2018, LECT NOTES ARTIF INT, V10956, P1, DOI 10.1007/978-3-319-95957-3_1
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Le V., 2012, Proceedings of the Euporean Conference on Computer Vision, P679, DOI DOI 10.1007/978-3-642-33712-3_49
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu LC, 2018, IEEE T CYBERNETICS, V48, P1189, DOI 10.1109/TCYB.2017.2682853
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   METROPOLIS N, 1949, J AM STAT ASSOC, V44, P335, DOI 10.2307/2280232
   Rajput SS, 2020, MULTIMED TOOLS APPL, V79, P23909, DOI 10.1007/s11042-020-09072-5
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Xiang LY, 2020, MATH BIOSCI ENG, V17, P1041, DOI 10.3934/mbe.2020055
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhang H, 2018, ARXIV20181705, V1705
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
NR 32
TC 48
Z9 50
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30839
EP 30861
DI 10.1007/s11042-020-09969-1
EA NOV 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000590232700001
DA 2024-07-18
ER

PT J
AU Sharma, RP
   Dey, S
AF Sharma, Ram Prakash
   Dey, Somnath
TI A comparative study of handcrafted local texture descriptors for
   fingerprint liveness detection under real world scenarios
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Fingerprint security; Liveness detection; Texture
   descriptors
ID BINARY PATTERNS
AB Authentication using fingerprints is widely deployed in various applications to ensure a secure and efficient method for access control. However, fingerprint recognition systems can be deceived by spoofing attacks. Therefore, it is necessary to ensure the security of fingerprint-based recognition system using liveness detection. The work presented in this paper evaluates the potential of various handcrafted texture features under cross-dataset, cross-sensor, cross-material, unknown-material, and combined datasets experimental scenarios. We have considered Binarized Statistical Image Features (BSIF), Local Phase Quantization (LPQ), Weber Local Descriptor (WLD), Local Contrast Phase Descriptor (LCPD), and Rotation Invariant Co-occurrence among adjacent Local Binary Pattern (RicLBP) for liveness detection of fingerprint images. The performance of these descriptors against novel spoof materials, different sensors, and different acquisition environments reflect their robustness under real world attack scenarios. The experimental evaluations are performed on LivDet 2011, 2013, and 2015 databases using Support Vector Machine (SVM) classifier. The experimental evaluation shows that LCPD and WLD are the most effective descriptors for liveness detection under diverse testing conditions. The comparative performance evaluation of these handcrafted texture features with learning based features also indicate their effectiveness in real world attack scenarios. Experimental evaluation using the combination of best performing LCPD and WLD features further improve the performance of fingerprint liveness detection. The experimental outcome of the current research clearly indicates the superiority of handcrafted local texture descriptor in the real world presentation attack scenarios. Also, it is advantageous to use local texture descriptor as they provide a simple and faster approach for fingerprint liveness detection in real world applications of fingerprint recognition systems.
C1 [Sharma, Ram Prakash] LNM Inst Informat Technol, Jaipur, Rajasthan, India.
   [Dey, Somnath] Indian Inst Technol Indore, Indore, India.
C3 LNM Institute of Information Technology; Indian Institute of Technology
   System (IIT System); Indian Institute of Technology (IIT) - Indore
RP Sharma, RP (corresponding author), LNM Inst Informat Technol, Jaipur, Rajasthan, India.
EM ram.sharma@lnmiit.ac.in; somnathd@iiti.ac.in
RI Sharma, Ram Prakash/IAN-9085-2023
OI Sharma, Ram Prakash/0000-0002-1851-2325; Sharma, Ram
   Prakash/0000-0002-3364-2240
FU SERB [ECR/2017/000027]; Department of Science Technology
FX The authors would like to acknowledge SERB (ECR/2017/000027), Department
   of Science Technology, Govt. of India for providing financial support
   for this work.
CR [Anonymous], 2015, Biometrics Theory, Applications and Systems (BTAS), 2015 IEEE 7th International Conference on
   [Anonymous], 2013, C BIOMETRICS ICB 201
   [Anonymous], 2010, TECH REP
   Antonelli A, 2006, IEEE T INF FOREN SEC, V1, P360, DOI 10.1109/TIFS.2006.879289
   Baldisserra D, 2006, LECT NOTES COMPUT SC, V3832, P265
   Bian WX, 2019, IEEE ACCESS, V7, P32644, DOI 10.1109/ACCESS.2019.2903601
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Coli P, 2007, 2007 IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P169, DOI 10.1109/AUTOID.2007.380614
   Ghiani L, 2017, IET BIOMETRICS, V6, P224, DOI 10.1049/iet-bmt.2016.0007
   Ghiani L, 2013, INT CONF BIOMETR, DOI 10.1109/ICB.2013.6613027
   Ghiani L, 2012, INT C PATT RECOG, P537
   Ghiani L, 2012, LECT NOTES COMPUT SC, V7378, P210, DOI 10.1007/978-3-642-31567-1_21
   Gottschlich C, 2014, P IEEE INT JOINT C B, P1
   Gragnaniello D, 2014, ELECTRON LETT, V50, P439, DOI 10.1049/el.2013.4044
   Gragnaniello Diego, 2013, Proceedings of the 2013 IEEE Workshop on Biometric Measurements and Systems for Security and Medical Applications (BIOMS), P46, DOI 10.1109/BIOMS.2013.6656148
   Gragnaniello D, 2015, IEEE T INF FOREN SEC, V10, P849, DOI 10.1109/TIFS.2015.2404294
   Gragnaniello D, 2015, PATTERN RECOGN, V48, P1050, DOI 10.1016/j.patcog.2014.05.021
   Jia XF, 2014, INFORM SCIENCES, V268, P91, DOI 10.1016/j.ins.2013.06.041
   Kannala J, 2012, INT C PATT RECOG, P1363
   Kim W, 2016, ELECTRON LETT, V52, DOI 10.1049/el.2016.3371
   Kim W, 2017, IEEE SIGNAL PROC LET, V24, P51, DOI 10.1109/LSP.2016.2636158
   Kumpituck S, 2017, 8 INT C GRAPH IM PRO, V10225, P260
   Lapsley PD, 1998, US PATENT
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Mäenpää T, 2003, LECT NOTES COMPUT SC, V2749, P885
   Maenpaa T., 2004, The local binary pattern approach to texture analysis: Extensions and applications
   Marasco E, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2617756
   Marcel S, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6524-8
   Marcialis Gian Luca, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1289, DOI 10.1109/ICPR.2010.321
   Marcialis GL, 2009, LECT NOTES COMPUT SC, V5716, P12, DOI 10.1007/978-3-642-04146-4_4
   Mehboob R, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.053038
   Nikam Shankar Bhausaheb, 2008, 2008 1st International Conference on Emerging Trends in Engineering and Technology (ICETET), P675, DOI 10.1109/ICETET.2008.134
   Nikam SB, 2008, INT C WAVEL ANAL PAT, P717, DOI 10.1109/ICWAPR.2008.4635872
   Nikam SB, 2010, SIGNAL IMAGE VIDEO P, V4, P75, DOI 10.1007/s11760-008-0098-8
   Nogueira RF, 2016, IEEE T INF FOREN SEC, V11, P1206, DOI 10.1109/TIFS.2016.2520880
   Nosaka Ryusuke, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P15, DOI 10.1007/978-3-642-37410-4_2
   Nosaka R, 2011, LECT NOTES COMPUT SC, V7088, P82, DOI 10.1007/978-3-642-25346-1_8
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, INT C PATT RECOG, P3596
   Rahtu E, 2012, IMAGE VISION COMPUT, V30, P501, DOI 10.1016/j.imavis.2012.04.001
   Smola AJ, 1999, ADV NEUR IN, V11, P585
   Tan B., 2006, Computer Vision and Pattern Recognition Workshop, P26, DOI DOI 10.1109/CVPRW.2006.120
   Tan B, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2885133
   Wang CG, 2015, LECT NOTES COMPUT SC, V9428, P241, DOI 10.1007/978-3-319-25417-3_29
   Xia ZH, 2017, SIGNAL IMAGE VIDEO P, V11, P381, DOI 10.1007/s11760-016-0936-z
   Yambay D., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P208, DOI 10.1109/ICB.2012.6199810
NR 47
TC 8
Z9 8
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 9993
EP 10012
DI 10.1007/s11042-020-10136-9
EA NOV 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000589565300001
DA 2024-07-18
ER

PT J
AU Arsic, S
   Nikolic, D
   Jevtic, M
AF Arsic, Sanela
   Nikolic, Djordje
   Jevtic, Milena
TI An investigation of the usability of image-based CAPTCHAs using
   PROMETHEE-GAIA method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image-based CAPTCHA; Web security mechanism; PROMETHEE-GAIA method; AHP
   method; Shannon entropy method
ID MULTICRITERIA DECISION-MAKING; SECURITY; SELECTION
AB Today, it is difficult to find an adequate Web site with a registration form that is not protected with some automated human proof test. One of the oldest concepts in Artificial Intelligence as a security mechanism based on the Turing Test is CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart). This test was designed to make a difference between the real users and bots and provide security against malicious attacks. The PROMETHEE-GAIA method was employed for ranking different image-based CAPTCHAs according to their usability in this paper. The aim of this study is a comparative analysis of seven image-based CAPTCHAs based on three different criteria: time to find a solution, a number of attempts, and task difficulty. The weights of the considered criteria were calculated objectively by the entropy method, and for the subjective weights, Analytical Hierarchy Process (AHP) was used. A defined research model was applied through four phases. The survey included 320 randomly selected Internet users and experts in computer science who were familiar with CAPTCHA tests. The proposed model suggested which CAPTCHA offered better human accuracy and lower machine attack rates compared to the existing approaches. The obtained results were very helpful to the web administrators because they indicated that this approach could provide useful insights for the decision-makers about the appropriate mechanisms to protect users against cyber-criminal activities and Internet threats.
C1 [Arsic, Sanela; Nikolic, Djordje; Jevtic, Milena] Univ Belgrade, Tech Fac Bor, Engn Management Dept, Bor 19210, Serbia.
C3 University of Belgrade
RP Arsic, S (corresponding author), Univ Belgrade, Tech Fac Bor, Engn Management Dept, Bor 19210, Serbia.
EM saarsic@tfbor.bg.ac.rs
RI Arsić, Sanela/ABD-7128-2020
OI Arsić, Sanela/0000-0002-1957-566X; Gajic, Milena/0000-0001-7699-1101
CR Abdel-Basset M, 2019, COMPUT NETW, V157, P122, DOI 10.1016/j.comnet.2019.04.018
   Abdullah Lazim, 2019, Journal of Industrial Engineering International, V15, P271, DOI 10.1007/s40092-018-0289-z
   Agha Salah R., 2012, International Journal of Applied Management Science, V4, P385
   Aherwar A, 2019, MATERIALWISS WERKST, V50, P1232, DOI 10.1002/mawe.201800088
   Alqahtani FH, 2020, COMPUT SECUR, V88, DOI 10.1016/j.cose.2019.101635
   [Anonymous], 2012, P 2012 ACM WORKSH PR
   Beheshti SMRS, 2017, COMPUT SECUR, V70, P596, DOI 10.1016/j.cose.2017.08.006
   Behzadian M, 2010, EUR J OPER RES, V200, P198, DOI 10.1016/j.ejor.2009.01.021
   Belk M, 2015, INT J HUM-COMPUT ST, V84, P1, DOI 10.1016/j.ijhcs.2015.07.002
   Bennani A, 2017, INT J CIV ENG TECHNO, V8, P856
   Brans J.P., 1982, Laide a la Decision: Nature, Instruments et perspectives Davenir, P183
   Brans JP, 2005, INT SER OPER RES MAN, V78, P163, DOI 10.1007/b100605
   Brans JP., 1984, OPERATIONAL RES IFOR, P477
   Bursztein E, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2637, DOI 10.1145/2556288.2557322
   Bursztein E, 2010, P IEEE S SECUR PRIV, P399, DOI 10.1109/SP.2010.31
   Chandavale AA, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING (ICIP), P382, DOI 10.1109/INFOP.2015.7489412
   Cheriet M, 2009, PATTERN RECOGN, V42, P3129, DOI 10.1016/j.patcog.2009.03.013
   Christian AV., 2016, OPEN J BUS MANAG, V04, P238, DOI [10.4236/ojbm.2016.42025, DOI 10.4236/OJBM.2016.42025]
   D'Avignon G, 1983, TECHNICAL REPORT
   Dujardin M, 1984, 19 M EUR WORK GROUP
   Fidas CA, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2623
   Ghosh TK, 2012, 2012 2ND IEEE INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P419, DOI 10.1109/PDGC.2012.6449857
   Hidalgo JMG, 2011, ADV COMPUT, V83, P109, DOI 10.1016/B978-0-12-385510-7.00003-5
   Herngren L, 2006, ANAL CHIM ACTA, V571, P270, DOI 10.1016/j.aca.2006.04.064
   Hu ZH, 2008, PROCEEDINGS OF FIRST INTERNATIONAL CONFERENCE OF MODELLING AND SIMULATION, VOL IV, P44
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   KELLER HR, 1991, CHEMOMETR INTELL LAB, V11, P175, DOI 10.1016/0169-7439(91)80064-W
   Kluever K., 2008, THESIS
   Kluever K.A., 2009, P 5 S US PRIV SEC, P14
   Kocmanová A, 2013, IFIP ADV INF COMM TE, V413, P44
   Kwon S, 2017, INFORM PROCESS LETT, V128, P27, DOI 10.1016/j.ipl.2017.07.009
   Lee YL, 2011, DISPLAYS, V32, P81, DOI 10.1016/j.displa.2010.12.004
   Lopes APF, 2018, ANN TOURISM RES, V73, P1, DOI 10.1016/j.annals.2018.07.003
   Macharis C, 2004, EUR J OPER RES, V153, P307, DOI 10.1016/S0377-2217(03)00153-X
   Madathil K.C., 2010, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V54, P1249, DOI DOI 10.1177/154193121005401603
   Madathil KC, 2019, INT J IND ERGONOM, V69, P200, DOI 10.1016/j.ergon.2018.12.003
   Meutzner H., 2014, Proceedings of the 30th Annual Computer Security Applications Conference, P276
   Nikolic D, 2009, J ENVIRON MANAGE, V91, P509, DOI 10.1016/j.jenvman.2009.09.019
   Ostovare M, 2019, TOUR MANAG PERSPECT, V30, P107, DOI 10.1016/j.tmp.2019.02.013
   Peng B, 2021, JAMIA OPEN, V4, DOI [10.1093/jamiaopen/ooaa074, 10.1155/2014/139030, 10.1038/s41598-021-90564-1]
   PENNINGER S, 2012, LECT NOTES INFORM, V195, P199
   Plamondon R, 2018, PATTERN RECOGN, V81, P633, DOI 10.1016/j.patcog.2018.04.012
   Radulescu M, 2017, ACTA OECON, V67, P473, DOI 10.1556/032.2017.67.4.1
   Roshanbin N, 2016, FUTURE GENER COMP SY, V55, P289, DOI 10.1016/j.future.2014.11.004
   Saaty T. L., 1980, ANAL HIEARARCHY PROC
   Sauer H, 2008, P 4 S US PRIV SEC, P2
   Savic M, 2015, MIN PROC EXT MET REV, V36, P267, DOI 10.1080/08827508.2014.962135
   Schryen G, 2016, COMPUT SECUR, V60, P95, DOI 10.1016/j.cose.2016.03.007
   Shirali-Shahreza S., 2013, P SIGCHI C HUM FACT, P2147
   Starostenko O, 2015, PATTERN RECOGN, V48, P1101, DOI 10.1016/j.patcog.2014.09.006
   Thomas AO, 2009, PATTERN RECOGN, V42, P3365, DOI 10.1016/j.patcog.2008.12.018
   Trukenbrod AK, 2020, INT J HUM-COMPUT ST, V138, DOI 10.1016/j.ijhcs.2020.102399
   Vego G, 2008, WASTE MANAGE, V28, P2192, DOI 10.1016/j.wasman.2007.10.002
   Vikram S, 2011, 27TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2011), P237
   von Ahn L, 2003, LECT NOTES COMPUT SC, V2656, P294
   Wang Jian-jun, 2006, Journal of Dalian University of Technology, V46, P926
   Yan J, 2008, S US PRIV SEC PITTSB
   Yu XH, 2013, PROCEDIA COMPUT SCI, V17, P449, DOI 10.1016/j.procs.2013.05.058
   Zindani D, 2018, MATER TODAY-PROC, V5, P17533, DOI 10.1016/j.matpr.2018.06.069
   Zhi-Hong Z, 2006, J ENVIRON SCI, V18, P1020, DOI 10.1016/S1001-0742(06)60032-6
NR 60
TC 6
Z9 7
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9393
EP 9409
DI 10.1007/s11042-020-10054-w
EA NOV 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587972300001
DA 2024-07-18
ER

PT J
AU Malireddi, H
   Parwani, K
   Rajitha, B
AF Malireddi, Harshitha
   Parwani, Kiran
   Rajitha, B.
TI A novel background updation algorithm using fuzzy c-means clustering for
   pedestrian detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Histogram of gradients; Precision; Fuzzy clustering; Membership matrix
ID OBJECT DETECTION; MOVING-OBJECTS; SUBTRACTION; IMAGES
AB The task of pedestrian detection in video surveillance applications will face challenges like dynamic background changes, false human detection (shadow), and illumination variations. In literature, many approaches have been proposed to resolve these challenges. But their performance is not up to the mark. Thus this paper proposes efficient pedestrian detection including shadow removal and automatic dynamic background update. For this firstly, a background frame is initialized where no moving object is present. Then a background subtraction algorithm is applied to each of the key frames from the live video to detect the foreground objects (using fuzzy C means clustering followed by mean absolute difference). Later on this segmented foreground a contour is estimated and passed through the HOG classifier for pedestrian detection. The performance of the proposed approach has been compared using various datasets & state-of-the-art approaches and found to the best with an average precision of 98 %, unlike the others.
C1 [Malireddi, Harshitha; Parwani, Kiran; Rajitha, B.] Motilal Nehru Natl Inst Technol Allahabad, Allahabad, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Malireddi, H (corresponding author), Motilal Nehru Natl Inst Technol Allahabad, Allahabad, Uttar Pradesh, India.
EM harshithamalireddi999@gmail.com; kiranparwani36@gmail.com;
   rajitha@mnnit.ac.in
RI B, Rajitha/HHR-8738-2022
CR Arashloo SR, 2017, J VIS COMMUN IMAGE R, V43, P89, DOI 10.1016/j.jvcir.2016.12.015
   Baf FE, 2008, IEEE IMAGE PROC, P2648, DOI 10.1109/ICIP.2008.4712338
   Blaschko MB, 2008, PROC CVPR IEEE, P93, DOI 10.1109/CVPR.2008.4587353
   Bouwmans T, 2011, RECENT PATENTS COMPU, V3, P4
   Bouwmans T., 2008, Recent Patents Comput. Sci., V1, P219
   Chan AB, 2011, MACH VISION APPL, V22, P751, DOI 10.1007/s00138-010-0262-3
   Cheng EJ, 2020, MEASUREMENT, V151, DOI 10.1016/j.measurement.2019.107081
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Chiranjeevi P, 2014, IEEE T CYBERNETICS, V44, P870, DOI 10.1109/TCYB.2013.2274330
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Davis JJ., 2006, PROC INT C MACHINE L, DOI DOI 10.1145/1143844.1143874
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Elgammal A, 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48
   Gao DS, 2009, IEEE T PATTERN ANAL, V31, P989, DOI 10.1109/TPAMI.2009.27
   Gavrila D., 2000, PROC EUROPEAN C COMP, P37, DOI [DOI 10.1007/3-540-45053-X, 10.1007/3-540-45053-X-3., DOI 10.1007/3-540-45053-X-3]
   Goyal K, 2018, ARTIF INTELL REV, V50, P241, DOI 10.1007/s10462-017-9542-x
   Hati KK, 2013, IEEE SIGNAL PROC LET, V20, P759, DOI 10.1109/LSP.2013.2263800
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Hou Beiping, 2010, Chinese Journal of Scientific Instrument, V31, P1819
   Jiang Y, 2019, IEEE ACCESS, V7, P118310, DOI 10.1109/ACCESS.2019.2936454
   Li XP, 2019, J PHYS CONF SER, V1187, DOI 10.1088/1742-6596/1187/3/032082
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Mikolajczyk K, 2004, LECT NOTES COMPUT SC, V3021, P69
   Minematsu T, 2017, PATTERN RECOGN LETT, V96, P86, DOI 10.1016/j.patrec.2017.03.010
   Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571
   Montabone S, 2010, IMAGE VISION COMPUT, V28, P391, DOI 10.1016/j.imavis.2009.06.006
   Perko R, 2010, COMPUT VIS IMAGE UND, V114, P700, DOI 10.1016/j.cviu.2010.03.005
   Sanin A, 2012, PATTERN RECOGN, V45, P1684, DOI 10.1016/j.patcog.2011.10.001
   Wallach PJ, 2015, MATH CONT SOC
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Xu L, 2014, INT CONF ACOUST SPEE
   Yazdi M, 2018, COMPUT SCI REV, V28, P157, DOI 10.1016/j.cosrev.2018.03.001
   Yi KM, 2013, IEEE COMPUT SOC CONF, P27, DOI 10.1109/CVPRW.2013.9
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
NR 34
TC 1
Z9 1
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7637
EP 7651
DI 10.1007/s11042-020-09897-0
EA OCT 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000587058000018
DA 2024-07-18
ER

PT J
AU Cheng, H
   Long, W
   Li, YY
   Liu, HG
AF Cheng, Hong
   Long, Wei
   Li, Yanyan
   Liu, Huaguo
TI Two low illuminance image enhancement algorithms based on grey level
   mapping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contrast-enhanced; Dark image; Gamma correction; Mapping function;
   Self-adaption
ID HISTOGRAM EQUALIZATION; CONTRAST ENHANCEMENT; CLASSIFICATION;
   SEGMENTATION; DISEASES
AB Two image enhancement contrast methods are proposed in this paper for low-intensity images. The first method (LEAM) is a new greyscale mapping function, and it can be significantly enhanced in the low grey range and compressed slowly in the high grey range, which is beneficial for retaining more image details; the second method (LEAAM) is based on the data characteristics of a histogram combined with the first mapping function, which adaptively sets the gamma value to correct the image. The experimental results show that compared with a traditional mapping function, LEAM is more effective at enriching image details and enhancing visual effects, and LEAAM, compared with a recent low-illumination image enhancement algorithm, achieves good performance for average gradient, information entropy and contrast index; additionally, the overall visual effect is the best compared with other methods.
C1 [Cheng, Hong; Long, Wei; Li, Yanyan; Liu, Huaguo] Sichuan Univ, Coll Mech Engn, Chengdu, Peoples R China.
C3 Sichuan University
RP Cheng, H (corresponding author), Sichuan Univ, Coll Mech Engn, Chengdu, Peoples R China.
EM C_Hong1214@yeah.net
OI Chong, Hong/0000-0002-3212-1670
FU Ministry of human resources and social security [198606]; Science and
   Technology Department of Sichuan Province [2020JDRC0026]; special fund
   for central finance of universities [2018SCU12065]
FX The financial supports by the Ministry of human resources and social
   security (198606), Science and Technology Department of Sichuan Province
   (2020JDRC0026), as well as the special fund for central finance of
   universities (2018SCU12065).
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   Al Attar F.N.H., 2020, CURR MED IMAGING
   Al-Ameen Z, 2019, IET IMAGE PROCESS, V13, P1314, DOI 10.1049/iet-ipr.2018.6585
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Cai BL, 2017, IEEE I CONF COMP VIS, P4020, DOI 10.1109/ICCV.2017.431
   Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Chang YY, 2018, IEEE TOPIC CONF WIRE, P1, DOI 10.1109/WISNET.2018.8311548
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Dai Q, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11040574
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Guo X, 2016, LIME METHOD LOW LIGH
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Huang ZH, 2016, INFRARED PHYS TECHN, V79, P205, DOI 10.1016/j.infrared.2016.11.001
   Iqbal Z, 2018, COMPUT ELECTRON AGR, V153, P12, DOI 10.1016/j.compag.2018.07.032
   Jenifer S, 2016, APPL SOFT COMPUT, V42, P167, DOI 10.1016/j.asoc.2016.01.039
   Jin H, 2005, IEEE C ELEC DEVICES, P57
   Khan MA, 2020, MULTIMED TOOLS APPL, V79, P18627, DOI 10.1007/s11042-020-08726-8
   Khan MA, 2019, PATTERN ANAL APPL, V22, P1377, DOI 10.1007/s10044-018-0688-1
   Kim M, 2008, IEEE T CONSUM ELECTR, V54, P1389, DOI 10.1109/TCE.2008.4637632
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Li CY, 2018, PATTERN RECOGN LETT, V104, P15, DOI 10.1016/j.patrec.2018.01.010
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liaqat A, 2018, J MECH MED BIOL, V18, DOI 10.1142/S0219519418500380
   Liu CW, 2019, J MOD OPTIC, V66, P1590, DOI 10.1080/09500340.2019.1649482
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Moroney N, 2000, EIGHTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P108
   Nasir M, 2018, MICROSC RES TECHNIQ, V81, P528, DOI 10.1002/jemt.23009
   Ren YR, 2019, IEEE T CIRC SYST VID, V29, P968, DOI 10.1109/TCSVT.2018.2828141
   Salas JGG, 2011, IPOL J, V1
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Sheet D, 2010, IEEE T CONSUM ELECTR, V56, P2475, DOI 10.1109/TCE.2010.5681130
   Singh K, 2015, OPTIK, V126, P2619, DOI 10.1016/j.ijleo.2015.06.060
   Singh K, 2014, OPTIK, V125, P4646, DOI 10.1016/j.ijleo.2014.04.093
   Singh K, 2014, PATTERN RECOGN LETT, V36, P10, DOI 10.1016/j.patrec.2013.08.024
   Wang WC, 2019, INFORM SCIENCES, V496, P25, DOI 10.1016/j.ins.2019.05.015
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Ying ZQ, 2017, IEEE INT CONF COMP V, P3015, DOI 10.1109/ICCVW.2017.356
   Ying ZQ, 2017, LECT NOTES COMPUT SC, V10425, P36, DOI 10.1007/978-3-319-64698-5_4
   ZAHOOR S, 2020, CURR MED IMAGING REV
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 43
TC 8
Z9 9
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7205
EP 7228
DI 10.1007/s11042-020-09919-x
EA OCT 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000584568200005
DA 2024-07-18
ER

PT J
AU Shang, JY
   Niu, C
   Zhou, ZH
   Huang, JC
   Yang, ZW
   Li, XW
AF Shang, Junyuan
   Niu, Chang
   Zhou, Zhiheng
   Huang, Junchu
   Yang, Zhiwei
   Li, Xiangwei
TI Asymmetric alignment joint consistent regularization for multi-source
   domain adaptation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Subspace learning; Domain adaptation; Feature extraction; Image
   classification
ID ALGORITHM
AB Most existing methods of domain adaptation are proposed for single-source settings, where the source data come from a single domain. However, in practice, the available data generally come from multiple domains with different distributions. In this paper, we propose asymmetric alignment joint consistent regularization (AACR) for multi-source domain adaptation. As for asymmetric alignment, we propose to learn asymmetric projections, explicitly treating each domain differently to avoid the loss of shared information. Data from different domains are encoded into a common subspace by these asymmetric projections, where the encoded features are further aligned to promote knowledge transfer. Further, we propose consistent regularization to better learn shared information and filter out domain-specific information. We formulate the two parts into a unified framework, and derive its global optimal solution. Comprehensive experiments are conducted to evaluate AACR, and the results verify the effectiveness and robustness of our method.
C1 [Shang, Junyuan; Niu, Chang; Zhou, Zhiheng; Huang, Junchu] South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Peoples R China.
   [Yang, Zhiwei] China Informat & Commun Res Inst, Guangzhou, Peoples R China.
   [Li, Xiangwei] Lanzhou Inst Technol, Sch Comp & Artificial Intelligence, Lanzhou, Peoples R China.
C3 South China University of Technology; Lanzhou Institute of Technology
RP Zhou, ZH (corresponding author), South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Peoples R China.
EM zhouzh@scut.edu.cn
RI Zhou, zhiheng/HNC-4591-2023
FU National Key RAMP;D Program of China [2018YFC0309400]; National Natural
   Science Foundation of China [61871188]; Guangzhou city science and
   technology research projects [201902020008]
FX The work is supported by National Key R&D Program of China
   (2018YFC0309400), National Natural Science Foundation of China
   (61871188), Guangzhou city science and technology research
   projects(201902020008).
CR BARTELS RH, 1972, COMMUN ACM, V15, P820, DOI 10.1145/361573.361582
   Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57
   Chen Y, 2021, VIROL SIN, V36, P365, DOI 10.1007/s12250-020-00250-1
   Chen YC, 2018, IEEE T PATTERN ANAL, V40, P392, DOI 10.1109/TPAMI.2017.2666805
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02066-z
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112316
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Chung F. R., 1997, Spectral Graph Theory, V92, DOI DOI 10.1090/CBMS/092
   Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Griffin G., 2007, CALTECH 256 OBJECT C
   Gu Q., 2011, Proceedings of the Twenty-Second international joint conference on Artificial Intelligence, V2, P1294
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Hoffman J, 2012, LECT NOTES COMPUT SC, V7573, P702, DOI 10.1007/978-3-642-33709-3_50
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Huang JC, 2019, IET IMAGE PROCESS, V13, P804, DOI 10.1049/iet-ipr.2018.5871
   Jiang Jing, 2007, ANN M ASS COMP LING, P264, DOI DOI 10.1145/1273496.1273558
   Kodirov E, 2017, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2017.473
   Li JJ, 2019, IEEE T NEUR NET LEAR, V30, P1381, DOI 10.1109/TNNLS.2018.2868854
   Li JD, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3136625
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liu JY, 2018, NEUROCOMPUTING, V275, P247, DOI 10.1016/j.neucom.2017.06.051
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Long MS, 2014, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2014.183
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P53, DOI 10.1109/MSP.2014.2347059
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Shen Jian, 2017, 27 INT C FIELD PROGR, DOI [DOI 10.23919/FPL.2017.8056853, 10.23919/ FPL.2017.8056853]
   Si S, 2010, IEEE T KNOWL DATA EN, V22, P929, DOI 10.1109/TKDE.2009.126
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   TORRALBA A, 2011, PROC CVPR IEEE, P1521, DOI DOI 10.1109/CVPR.2011.5995347
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   van der Maaten L. J. P., 2008, Journal of Machine Learning Research, V9, P2579, DOI DOI 10.1007/S10479-011-0841-3
   Wang JD, 2017, IEEE DATA MINING, P1129, DOI 10.1109/ICDM.2017.150
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yu F, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/4047957
   Yu F, 2019, NEUROCOMPUTING, V350, P108, DOI 10.1016/j.neucom.2019.03.053
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhang J, 2017, PROC CVPR IEEE, P5150, DOI 10.1109/CVPR.2017.547
   Zhang YB, 2019, PROC CVPR IEEE, P5026, DOI 10.1109/CVPR.2019.00517
NR 49
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6041
EP 6064
DI 10.1007/s11042-020-09883-6
EA OCT 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000578564800007
DA 2024-07-18
ER

PT J
AU Yadav, S
   Yadav, R
   Kumar, A
   Kumar, M
AF Yadav, Suman
   Yadav, Richa
   Kumar, Ashwni
   Kumar, Manjeet
TI A novel approach to design optimal 2-D digital differentiator using
   vortex search optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital FIR 2-D differentiator; Vortex search algorithm; Optimization;
   Meta-heuristic algorithm
ID EMPIRICAL MODE DECOMPOSITION; SUPPORT VECTOR REGRESSION; CUCKOO-SEARCH;
   FIR FILTERS; SVR; PHASE
AB The designing of 2-D digital differentiator is multimodal and high dimensional problem which requires large number of differentiator coefficients to be optimized, hence conventional design techniques will not lead to optimal 2-D differentiator design. Metaheuristic approaches is a good approach to handle multimodal and high dimensional problem under consideration. In this paper, a novel method for the design of FIR two-dimensional (2-D) digital differentiator with quadrantally odd symmetric properties is proposed. The coefficients of 2-D digital differentiator are computed and optimized using vortex search optimization (VSO) algorithm with the support of L(1)error objective function. The unique combination of VSO and L(1)error fitness function aids in achieving flatter magnitude response in designing of 2-D differentiator. Further, some comparative analysis with the well-known established techniques like cuckoo search algorithm (CSA), particle swarm optimization (PSO) and real coded genetic algorithm (RCGA) methodology is reported over full frequency bands, in order to demonstrate the advantage of the proposed novel 2-D digital differentiator design approach. To measure the performance of proposed system, some parameters are selected for illustration such as absolute magnitude error, mean absolute error, standard deviation and execution time. The excellence of the proposed approach is observed in approximating the ideal response of 2-D differentiator in contrast to other algorithms and to provide global optimal solution.
C1 [Yadav, Suman] Bharati Vidyapeeth Coll Engn, Dept Elect & Commun Engn, New Delhi 110063, India.
   [Yadav, Suman; Yadav, Richa; Kumar, Ashwni] Indira Gandhi Delhi Tech Univ Women IGDTUW, Dept Elect & Commun Engn, New Delhi 110006, India.
   [Kumar, Manjeet] Delhi Technol Univ DTU, Dept Elect & Commun Engn, Delhi 110042, India.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW); Delhi
   Technological University
RP Kumar, M (corresponding author), Delhi Technol Univ DTU, Dept Elect & Commun Engn, Delhi 110042, India.
EM manjeetchhillar@gmail.com
RI Kumar, Manjeet/K-1325-2015
OI Kumar, Manjeet/0000-0001-6578-9741; Yadav, Richa/0000-0002-3196-3913
CR Aggarwal A, 2016, INT C SIGN PROC COMM, P19
   Aggarwal A, 2019, IET SIGNAL PROCESS, V13, P262, DOI 10.1049/iet-spr.2018.5353
   Aggarwal A, 2019, ARAB J SCI ENG, V44, P1917, DOI 10.1007/s13369-018-3188-0
   Aggarwal A, 2017, MULTIDIM SYST SIGN P, V28, P1569, DOI 10.1007/s11045-016-0433-0
   Aggarwal A, 2016, CIRC SYST SIGNAL PR, V35, P2213, DOI 10.1007/s00034-016-0283-x
   Ali TAA, 2019, KNOWL-BASED SYST, V182, DOI 10.1016/j.knosys.2019.07.005
   An Z., 2020, NEUROCOMPUTING
   [Anonymous], 2010, SIGNALS SYSTEMS
   Chang WD, 2009, DIGIT SIGNAL PROCESS, V19, P660, DOI 10.1016/j.dsp.2008.12.004
   Chien-Cheng Tseng, 2011, 2011 European Conference on Circuit Theory and Design (ECCTD 2011), P17, DOI 10.1109/ECCTD.2011.6043299
   Dogan B, 2015, AEU-INT J ELECTRON C, V69, P1243, DOI 10.1016/j.aeue.2015.05.005
   Dogan B, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2223-4
   Fan GF, 2016, NEUROCOMPUTING, V173, P958, DOI 10.1016/j.neucom.2015.08.051
   Garg K, 2017, RADIOENGINEERING, V26, P376, DOI 10.13164/re.2017.0376
   Gupta M, 2014, SCI WORLD J
   Han J, IEEE T IND ELECT, V56, P900
   Hong WC, 2013, INT J ELEC POWER, V44, P604, DOI 10.1016/j.ijepes.2012.08.010
   Hong WC, 2011, ENERGY, V36, P5568, DOI 10.1016/j.energy.2011.07.015
   Huang YJ, 2017, J MAR SCI TECH-JAPAN, V22, P403, DOI 10.1007/s00773-016-0419-5
   Khan IR, 1999, IEE P-VIS IMAGE SIGN, V146, P185, DOI 10.1049/ip-vis:19990380
   Kumar A, 2019, INT J CIRC THEOR APP, V47, P1459, DOI 10.1002/cta.2667
   Kumar A, 2018, ISA T, V80, P381, DOI 10.1016/j.isatra.2018.08.003
   Kumar A, 2018, ISA T, V79, P239, DOI 10.1016/j.isatra.2018.05.003
   Kumar Manjeet, 2014, WSEAS Transactions on Signal Processing, V10, P538
   Kumar M, 2015, PROCEDIA COMPUT SCI, V57, P368, DOI 10.1016/j.procs.2015.07.351
   Kuzma M, 2018, J BONE MINER METAB, V36, P580, DOI 10.1007/s00774-017-0864-1
   Li MW, 2019, NONLINEAR DYNAM, V97, P2579, DOI 10.1007/s11071-019-05149-5
   Liao X, 2020, IEEE J SELECTED TOPI
   Liao X., 2020, IEEE T DEPENDABLE SE
   Mahata S, 2018, SOFT COMPUT, V22, P3757, DOI 10.1007/s00500-017-2595-6
   Mahata S, 2017, INT J NUMER MODEL EL, V30, DOI 10.1002/jnm.2203
   Mcewan TE, 1994, Patent, V5, P361, Patent No. 19945361370
   Meel P, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P1, DOI 10.1109/SPIN.2019.8711722
   Mohan GK, 2019, INT J COMPUTERS APPL, P1
   Montoya O. D., 2019, IEEE T CIRCUITS SY 2
   Muthukrishnan R., 2011, International Journal of Computer Science & Information Technology, V3, P259, DOI 10.5121/ijcsit.2011.3620
   Rajeswari M, 2017, ADV APPL MATH SCI, V17, P95
   Singh S, 2019, APPL INTELL, V49, P1785, DOI 10.1007/s10489-018-1354-4
   Tseng CC, 2013, SIGNAL PROCESS, V93, P1141, DOI 10.1016/j.sigpro.2012.12.006
   Wulf Michael, 2016, Current Directions in Biomedical Engineering, V2, P215, DOI 10.1515/cdbme-2016-0048
   Yadav S, 2021, ISA T, V108, P196, DOI 10.1016/j.isatra.2020.08.032
   Yadav S, 2020, J CIRCUIT SYST COMP, V29, DOI 10.1142/S0218126620501558
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
   Zhang ZC, 2019, ENG APPL ARTIF INTEL, V85, P254, DOI 10.1016/j.engappai.2019.06.017
NR 44
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5901
EP 5916
DI 10.1007/s11042-020-10012-6
EA OCT 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000578564800002
DA 2024-07-18
ER

PT J
AU Singh, B
   Chhajed, M
   Sur, A
   Mitra, P
AF Singh, Brijesh
   Chhajed, Mohit
   Sur, Arijit
   Mitra, Pinaki
TI Steganalysis using learned denoising kernels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; Spatial domain steganalysis; Denoising kernels
ID IMAGE; STEGANOGRAPHY
AB Steganalysis is the science for detecting steganographic traces in innocent-looking digital media like images, videos, etc. In recent literature, it has been observed that state-of-the-art image steganographic techniques such as S-UNIWARD, HUGO, WOW, etc. still remain undetected even with considerable embedding payload. Recently, the deep learning framework has been hugely successful in different computer vision applications like object detection, image classification, event detection, etc. Some recent deep learning-based works also show promising results for image steganalysis and have opened a new avenue for research. The current literature reveals that the steganalytic detector becomes more precise if trained on the residual error (embedding noise) domain. To get an accurate noise residual, it is required to predict the cover image precisely from the corresponding stego image. In this work, a denoising kernel has been learned to obtain a more precise noise residual. After that, a CNN based steganalytic detector is devised, which is trained using the noise residual to get a more precise detection. Experimental results show that the proposed scheme outperforms the state-of-the-art steganalysis schemes against the state-of-the-art steganographic approaches.
C1 [Singh, Brijesh; Chhajed, Mohit; Sur, Arijit; Mitra, Pinaki] Indian Inst Technol, Dept CSE, Gauhati, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Singh, B (corresponding author), Indian Inst Technol, Dept CSE, Gauhati, India.
EM brijesh.singh@iitg.ac.in; m.chhajed@iitg.ac.in; arijit@iitg.ac.in;
   pinaki@iitg.ac.in
RI Mitra, Pinaki/AAD-6785-2020; Singh, Brijesh/AAB-7919-2021; Sur,
   Arijit/AAB-4216-2020
OI Singh, Brijesh/0000-0003-2661-6244; 
FU Ministry of Human Resource Development, Government of India
FX This work is supported by Ministry of Human Resource Development,
   Government of India.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2017, 31 AAAI C ART INT AA
   [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], 2014, Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2014 Asia-Pacific, DOI [10.1109/APSIPA.2014, 10.1109/APSIPA.2014.7041565]
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bas T., 2007, BOWS-2
   Bin Li, 2018, IEEE Signal Processing Letters, V25, P650, DOI 10.1109/LSP.2018.2816569
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Buko B., 2022, ABS151203385 CORR, V22, P8878
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Fridrich J, 2012, DIGITAL DATA EMBEDDI
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Goljan M, 2006, PROC SPIE, V6072, DOI 10.1117/12.643254
   Gul Gokhan, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P71, DOI 10.1007/978-3-642-24178-9_6
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li YM, 2020, THER CLIN RISK MANAG, V16, P1, DOI 10.2147/TCRM.S236498
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Lyu S, 2003, LECT NOTES COMPUT SC, V2578, P340
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Qian YL, 2016, IEEE IMAGE PROC, P2752, DOI 10.1109/ICIP.2016.7532860
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Rabevohitra Feno Heriniaina, 2019, 2019 IEEE 19th International Conference on Communication Technology (ICCT), P1704, DOI 10.1109/ICCT46805.2019.8947188
   Sadek MM, 2015, MULTIMED TOOLS APPL, V74, P7063, DOI 10.1007/s11042-014-1952-z
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   TONG YB, 2006, J IMAGE GR, V0012, P01758
   Wang PF, 2016, MULTIMED TOOLS APPL, V75, P2897, DOI 10.1007/s11042-015-2521-9
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
NR 45
TC 8
Z9 8
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 4903
EP 4917
DI 10.1007/s11042-020-09960-w
EA OCT 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000574727600009
DA 2024-07-18
ER

PT J
AU Zhang, L
   Chang, MH
AF Zhang, Lei
   Chang, Minhui
TI An image inpainting method for object removal based on difference degree
   constraint
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image inpainting; Object removal; Exemplar; Difference degree
ID ALGORITHM
AB In the inpainting method for object removal, SSD (Sum of Squared Differences) is commonly used to measure the degree of similarity between the exemplar patch and the target patch, which has a very important impact on the restoration results. Although the matching rule is relatively simple, it is likely to lead to the occurrence of mismatch error. Even worse, the error may be accumulated along with the process continues. Finally some unexpected objects may be introduced into the target region, making the result unable to meet the requirements of visual consistency. In view of these problems, we propose an inpainting method for object removal based on difference degree constraint. Firstly, we define the MSD (Mean of Squared Differences) and use it to measure the degree of differences between corresponding pixels at known positions in the target patch and the exemplar patch. Secondly, we define the SMD (Square of Mean Differences) and use it to measure the degree of differences between the pixels at known positions in the target patch and the pixels at unknown positions in the exemplar patch. Thirdly, based on MSD and SMD, we define a new matching rule and use it to find the most similar exemplar patch in the source region. Finally, we use the exemplar patch to restore the target patch. Experimental results show that the proposed method can effectively prevent the occurrence of mismatch error and improve the restoration effect.
C1 [Zhang, Lei; Chang, Minhui] Yuncheng Univ, Sch Math & Informat Technol, Yuncheng, Peoples R China.
C3 Yuncheng University
RP Zhang, L (corresponding author), Yuncheng Univ, Sch Math & Informat Technol, Yuncheng, Peoples R China.
EM zhanglei@ycu.edu.cn
FU National Natural Science Foundation of China [61703363]; Scientific and
   Technological Innovation Programs of Higher Education Institutions in
   Shanxi [2019L0855]; Scientific Research Project of Yuncheng University
   [YQ-2017027, XK-2018034, CY-2019025]
FX The research is supported in part by National Natural Science Foundation
   of China (Grant: 61703363), in part by Scientific and Technological
   Innovation Programs of Higher Education Institutions in Shanxi (Grant:
   2019L0855), in part by Scientific Research Project of Yuncheng
   University (Grant YQ-2017027, XK-2018034, CY-2019025). All of the
   authors would like to thank the anonymous referees for their valuable
   comments and suggestions.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bahat Y, 2015, SIGNAL PROCESS, V111, P61, DOI 10.1016/j.sigpro.2014.11.023
   Banday M., 2014, INT J CURRENT ENG TE, V4, P3532
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Chang IC, 2019, J COMPUT TAIWAN, V29, P121
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   DeelipWagh Priyanka, 2015, 2015 INT C PERV COMP, P1
   Deng LJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0141199
   Dong XH, 2019, IEEE T IND ELECTRON, V66, P4777, DOI 10.1109/TIE.2018.2866043
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Elad M, 2005, APPL COMPUT HARMON A, V19, P340, DOI 10.1016/j.acha.2005.03.005
   Gaonkar S.R., 2014, INT J COMPUT SCI ENG, V2, P176
   Ghorai M, 2018, IEEE T IMAGE PROCESS, V27, P556, DOI 10.1109/TIP.2017.2768180
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo Q, 2018, IEEE T VIS COMPUT GR, V24, P2023, DOI 10.1109/TVCG.2017.2702738
   Hu GL, 2017, 2017 IEEE THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2017), P389, DOI 10.1109/BigMM.2017.43
   Hu Wenjin, 2014, Journal of Computer Aided Design & Computer Graphics, V26, P1067
   Ishi M. S., 2013, IOSR J COMPUT ENG, V13, P8
   Isogawa M, 2018, IEEE ACCESS, V6, P69728, DOI 10.1109/ACCESS.2018.2877401
   Jiang Y, 2020, IEEE ACCESS, V8, P22884, DOI 10.1109/ACCESS.2020.2970169
   Kumar BVR, 2019, COMPUT APPL MATH, V38, DOI 10.1007/s40314-019-0768-x
   Lee HK, 2015, FRONT PHARMACOL, V6, DOI 10.3389/fphar.2015.00011
   Liu H, 2019, IEEE ACCESS, V7, P181767, DOI 10.1109/ACCESS.2019.2902411
   Liu Ye-fei, 2014, Journal of Chinese Computer Systems, V35, P2754
   Lu X, 2020, HOI LEARNING VIDEO O
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Mo JC, 2019, CLUSTER COMPUT, V22, pS7593, DOI 10.1007/s10586-018-2323-8
   Mousavi P, 2019, COMPUT APPL MATH, V38, DOI 10.1007/s40314-019-0761-4
   Nan AJ, 2014, 2014 7TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI 2014), P885, DOI 10.1109/BMEI.2014.7002897
   Ogawa T, 2017, INT CONF ACOUST SPEE, P1827, DOI 10.1109/ICASSP.2017.7952472
   Sagong MC, 2019, PROC CVPR IEEE, P11352, DOI 10.1109/CVPR.2019.01162
   Sangeetha K, 2013, 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND CONTROL (ISCO 2013), P276, DOI 10.1109/ISCO.2013.6481162
   Shen B, 2009, INT CONF ACOUST SPEE, P697, DOI 10.1109/ICASSP.2009.4959679
   Sridevi G, 2017, DEFENCE SCI J, V67, P308, DOI 10.14429/dsj.67.10665
   Theljani A, 2017, MATH METHOD APPL SCI, V40, P3637, DOI 10.1002/mma.4250
   Wong A, 2008, IEEE IMAGE PROC, P2600, DOI 10.1109/ICIP.2008.4712326
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
   Xue MX, 2016, RECENT ADV ELECTR EL, V9, P177, DOI 10.2174/2213111607666160923165141
   Yang XH, 2017, IET IMAGE PROCESS, V11, P734, DOI 10.1049/iet-ipr.2016.1004
   Yao F, 2019, CLUSTER COMPUT, V22, P13683, DOI 10.1007/s10586-018-2068-4
   Zeng YH, 2019, PROC CVPR IEEE, P1486, DOI 10.1109/CVPR.2019.00158
   Zhang L, 2016, INT J INNOV COMPUT I, V12, P113
   Zhang N, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0471-2
   Zhang Shenhua, 2014, Computer Engineering and Applications, V50, P127, DOI 10.3778/j.issn.1002-8331.1308-0414
NR 47
TC 3
Z9 4
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4607
EP 4626
DI 10.1007/s11042-020-09835-0
EA SEP 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000574101100004
OA hybrid
DA 2024-07-18
ER

PT J
AU Liu, Z
   Yang, K
   Fu, XY
   Zhang, MM
   Wang, Z
   Mao, FQ
AF Liu, Zhi
   Yang, Ke
   Fu, Xianya
   Zhang, Mengmeng
   Wang, Zhao
   Mao, Fuqi
TI Adaptive QP offset selection algorithm for virtual reality 360-degree
   video based on CTU complexity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; 360-degree video; QP offset selection; CTU complexity
ID QUANTIZATION
AB Virtual reality 360-degree video requires ultra-high resolution to provide realistic feeling and dynamic perspective. Huge data volume brings new challenges to coding and transmission. Quantization parameter (QP) is one of the key parameters to control output bitrate and reconstruction quality during coding process. Many QP offset selection algorithms designed for this kind of video are based on latitude or Equirectangular Projection (ERP) weight maps, which cannot adapt to the situation of the flat block in tropical area or the complex block in polar area. In this paper, a new metric to measure complexity of Coding Tree Unit (CTU) is designed, and an adaptive QP offset selection algorithm is proposed based on CTU complexity to improve the quantization process. Each CTU is classified into one of the five categories according to its complexity, and then different QP offset value is determined for each category. By improving the quality of the visually sensitive area and reducing the bitrate of the flat one, the efficiency of the encoder is improved. The experimental results show that, compared with the HM16.20, the WS-PSNR increases by 0.40 dB, the BD-rate reduces by 1.99%, and the quality of visually sensitive areas has improved significantly.
C1 [Liu, Zhi; Yang, Ke; Zhang, Mengmeng; Mao, Fuqi] North China Univ Technol, Sch Informat Sci & Technol, Beijing 100041, Peoples R China.
   [Fu, Xianya] Yi Xinda Beijing Technol Co Ltd, Beijing 100080, Peoples R China.
   [Wang, Zhao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
C3 North China University of Technology; Beijing Jiaotong University
RP Liu, Z; Zhang, MM (corresponding author), North China Univ Technol, Sch Informat Sci & Technol, Beijing 100041, Peoples R China.
EM lzliu@ncut.edu.cn; obtx7rw@163.com
FU Beijing Municipal Natural Science Foundation [4202018]; Great Wall
   Scholar Project of Beijing Municipal Education Commission
   [CITTCD20180304]; National Natural Science Foundation of China
   [61972023]
FX This work is supported by the Beijing Municipal Natural Science
   Foundation (No.4202018), Great Wall Scholar Project of Beijing Municipal
   Education Commission (CIT&TCD20180304), and the National Natural Science
   Foundation of China (No.61972023).
CR Abbas A, 2016, JOINT VID EXPL TEAM
   Alshina E, 2017, JOINT VIDEO EXPLORAT
   [Anonymous], 2017, 2017 IEEE INT S CIRC
   Asbun E, 2016, JOINT VID EXPL TEAM
   Bai HH, 2007, IEEE T CIRC SYST VID, V17, P912, DOI 10.1109/TCSVT.2007.898646
   Bai HH, 2014, IEEE T CIRC SYST VID, V24, P1390, DOI 10.1109/TCSVT.2014.2315770
   Chevallier O, 2019, NMR BIOMED, V32, DOI 10.1002/nbm.4155
   He Y., 2016, JOINT VIDEO EXPLORAT, P7
   He YS, 2019, IEEE T IMAGE PROCESS, V28, P1613, DOI 10.1109/TIP.2018.2880568
   Järvinen A, 2016, PROCEEDINGS OF 2016 FUTURE TECHNOLOGIES CONFERENCE (FTC), P1065, DOI 10.1109/FTC.2016.7821735
   Khalil JE, 2019, IEEE T CIRC SYST VID, V29, P2067, DOI 10.1109/TCSVT.2018.2860525
   Li YM, 2017, IEEE INT CON MULTI, P709, DOI 10.1109/ICME.2017.8019492
   Hoang ND, 2019, AUTOMAT CONSTR, V105, DOI 10.1016/j.autcon.2019.102843
   Papadopoulos MA, 2016, IEEE IMAGE PROC, P4220, DOI 10.1109/ICIP.2016.7533155
   Racape F, 2017, JOINT VIDEO EXPLORAT
   Schwarz S., 2016, JOINT VID EXPL TEAM
   Sun W., 2016, JOINT VID EXPL TEAM
   Sun Y., 2016, JOINT VID EXPL TEAM
   Sun YJ, 2019, INT J COAL PREP UTIL, V39, P302, DOI 10.1080/19392699.2017.1316717
   Tang CZ, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3211889
   Tran HTT, 2017, INT CONF UBIQ FUTUR, P7
   Xiang GQ, 2018, MULTIMED TOOLS APPL, V77, P14817, DOI 10.1007/s11042-017-5064-4
   Xu YW, 2019, IEEE ACCESS, V7, P76274, DOI 10.1109/ACCESS.2019.2922476
   Zhang MM, 2019, MULTIMED TOOLS APPL, V78, P1081, DOI 10.1007/s11042-018-6283-z
   Zhao TS, 2016, IEEE T IMAGE PROCESS, V25, P2997, DOI 10.1109/TIP.2016.2556941
   Zhou YM, 2020, IEEE J-STSP, V14, P118, DOI 10.1109/JSTSP.2019.2957952
NR 26
TC 3
Z9 3
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3951
EP 3967
DI 10.1007/s11042-020-09922-2
EA SEP 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572719800001
DA 2024-07-18
ER

PT J
AU Cao, DY
   Ma, JF
   Chen, ZX
AF Cao, Danyang
   Ma, Jinfeng
   Chen, Zhixin
TI Video object detection algorithm based on dynamic combination of sparse
   feature propagation and dense feature aggregation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Object detection; Sparse feature propagation; Intensive
   feature aggregation
AB In comparison with static image object detection, focusing on video objects has greater research significance in realizing intelligent monitoring and automatic anomaly detection. However, it may be challenging to apply the most advanced image recognition networks to video data, as the number of static frame files represented in a video is often huge, thereby causing the problem of the slow evaluation speed, in addition to other issues, such as motion blur, low resolution, occlusion, and object deformation. In the present study, to mitigate these deficiencies, we applied sparse feature propagation to improve the detection speed and dense feature aggregation to refine the detection accuracy. Moreover, we utilized the key frame scheduling strategy relying on the consistency of feature information. Implementing these technologies allowed steadily improving the detection speed and accuracy to achieve high performance. To verify the applicability of the optimized video detection strategy proposed in this paper, we selected the part of the video data in the ImageNet VID training dataset. Then, the other part of this dataset was used to conduct the experiments, including the calculation and comparison of mean average precision (MAP) and frames per second (FPS).
C1 [Cao, Danyang; Ma, Jinfeng; Chen, Zhixin] North China Univ Technol, Sch Informat Sci & Technol, 5 Jin Yuan Zhuang Rd, Beijing 100144, Peoples R China.
   [Cao, Danyang] Beijing Key Lab Integrat & Anal Large Scale Strea, Beijing 100144, Peoples R China.
C3 North China University of Technology
RP Cao, DY (corresponding author), North China Univ Technol, Sch Informat Sci & Technol, 5 Jin Yuan Zhuang Rd, Beijing 100144, Peoples R China.; Cao, DY (corresponding author), Beijing Key Lab Integrat & Anal Large Scale Strea, Beijing 100144, Peoples R China.
EM ufocdy@163.com
RI Ma, Jin/JQW-3525-2023; MA, Jin/AAG-3700-2021
FU Yuyou Talent Support Plan of North China University of Technology
   [107051360019XN132/017]; Fundamental Research Funds for Beijing
   Universities [110052971803/037]; Special Research Foundation of North
   China University of Technology [PXM2017_014212_000014]
FX This study was funded by Supported by Yuyou Talent Support Plan of North
   China University of Technology (grant number 107051360019XN132/017), The
   Fundamental Research Funds for Beijing Universities (grant number
   110052971803/037), and Special Research Foundation of North China
   University of Technology (grant number PXM2017_014212_000014).
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   [Anonymous], 2016, SEQ NMS VIDEO OBJECT
   Bertasius G, 2018, LECT NOTES COMPUT SC, V11216, P342, DOI 10.1007/978-3-030-01258-8_21
   Bhandari B, 2020, MULTIMED TOOLS APPL, V79, P27867, DOI 10.1007/s11042-020-09384-6
   Brazil G, 2019, IEEE I CONF COMP VIS, P9286, DOI 10.1109/ICCV.2019.00938
   Cai JC, 2019, IEEE INT CONF AUTOMA, P16, DOI 10.1109/fg.2019.8756607
   Dai JF, 2016, ADV NEUR IN, V29
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Fattal A, 2017, 2017 IEEE 20 INT C I, P1, DOI [10.1109/itsc.2017.8317756, DOI 10.1109/ITSC.2017.8317756]
   Feichtenhofer C, 2017, IEEE I CONF COMP VIS, P3057, DOI 10.1109/ICCV.2017.330
   Gao F, 2016, INTERNET THINGS, DOI [10.1109/WF-IoT.2016.7845407, DOI 10.1109/WF-I0T.2016.7845407]
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Guo CS, 2014, MULTIMED TOOLS APPL, V72, P2633, DOI 10.1007/s11042-013-1566-x
   Heravi EJ, 2017, PROC SPIE, V10341, DOI 10.1117/12.2268737
   Huang J, 2017, IEEE INT C INT ROBOT, P3296, DOI 10.1109/IROS.2017.8206166
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Kang K, 2018, IEEE T CIRC SYST VID, V28, P2896, DOI 10.1109/TCSVT.2017.2736553
   Kang K, 2016, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2016.95
   Konig D., 2017, P IEEE C COMPUTER VI
   Li KH, 2014, INT CONF ACOUST SPEE
   Li LH, 2019, IEEE T IMAGE PROCESS, V28, P2021, DOI 10.1109/TIP.2018.2882926
   Li QY, 2019, MULTIMED TOOLS APPL, V78, P29307, DOI 10.1007/s11042-018-6857-9
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Martin PE, 2019, IEEE IMAGE PROC, P554, DOI [10.1109/ICIP.2019.8803780, 10.1109/icip.2019.8803780]
   Meng B, 2018, MULTIMED TOOLS APPL, V77, P26901, DOI 10.1007/s11042-018-5893-9
   Ming Ji, 2011, DETECTING HUMAN ACTI
   Nadimi S, 2004, IEEE T PATTERN ANAL, V26, P1079, DOI 10.1109/TPAMI.2004.51
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang N, 2013, P ADV NEURAL INFORM
   Wang SY, 2018, LECT NOTES COMPUT SC, V11217, P557, DOI 10.1007/978-3-030-01261-8_33
   Wang X, 2018, LECT NOTES COMPUT SC, V11257, P99, DOI 10.1007/978-3-030-03335-4_9
   Woo S, 2018, IEEE WINT CONF APPL, P1093, DOI 10.1109/WACV.2018.00125
   Xiao FY, 2018, LECT NOTES COMPUT SC, V11212, P494, DOI 10.1007/978-3-030-01237-3_30
   Zhang R, 2020, LECT NOTES COMPUTER, V12047
   Zhao HY, 2016, 2016 SEVENTH INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL AND INFORMATION PROCESSING (ICICIP), P11, DOI 10.1109/ICICIP.2016.7885897
   Zhu XZ, 2018, PROC CVPR IEEE, P7210, DOI 10.1109/CVPR.2018.00753
   Zhu XZ, 2017, IEEE I CONF COMP VIS, P408, DOI 10.1109/ICCV.2017.52
   Zhu XZ, 2017, PROC CVPR IEEE, P4141, DOI 10.1109/CVPR.2017.441
NR 40
TC 1
Z9 1
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23275
EP 23295
DI 10.1007/s11042-020-09827-0
EA SEP 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000572335500004
DA 2024-07-18
ER

PT J
AU Wang, ZX
   Li, F
AF Wang, Zixi
   Li, Fan
TI Convolutional neural network based low complexity HEVC intra encoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High efficiency video coding; Complexity reduction; Convolutional neural
   network; Intra prediction
ID DEPTH DECISION
AB Video coding is one of the key technologies of visual sensors. As the state-of-art video coding standard, High Efficiency Video Coding (HEVC) achieves a significant high compression ratio for video. However, it also introduces heavy computational complexity, leading to challenges in application of visual sensors. To reduce the complexity of HEVC intra encoder, this paper proposed a one-stage decision method of CU/PU partition and prediction mode for intra coding. First, the potential factors that may related to the corresponding decisions in CU/PU are explored. Based on this, a one-stage decision network (OSDN) structure is specially designed to determine these decisions. Consequently, the complexity of HEVC intra coding can be drastically reduced by avoiding the brute-force search. Then, OSDN is embedded into the HEVC reference software HM 15.0. Thresholds are set to let the encoder switch between OSDN and the original implementation in HEVC to obtain the final decisions. The experimental results show that the proposed method can reduce 73.69% intra encoding time with 0.1673 dB BD-PSNR loss on average. In addition, the trade-off between RD performance degradation and complexity reduction can be controlled by thresholds.
C1 [Wang, Zixi; Li, Fan] Xi An Jiao Tong Univ, Sch Informat & Commun Engn, Xian 710049, Peoples R China.
   [Wang, Zixi; Li, Fan] Guangdong Xian Jiaotong Univ Acad, Foshan 528000, Peoples R China.
C3 Xi'an Jiaotong University
RP Li, F (corresponding author), Xi An Jiao Tong Univ, Sch Informat & Commun Engn, Xian 710049, Peoples R China.; Li, F (corresponding author), Guangdong Xian Jiaotong Univ Acad, Foshan 528000, Peoples R China.
EM wzx284788391@stu.xjtu.edu.cn; lifan@mail.xjtu.edu.cn
RI Wang, Zixi/JMP-7296-2023; Wang, Zixi/KEI-0077-2024
FU National Science Foundation of China [61671365]; Key Research and
   Development Program of Shaanxi Province [2020KW-009]
FX This research work was supported in part by the National Science
   Foundation of China (61671365), and the Key Research and Development
   Program of Shaanxi Province (2020KW-009).
CR [Anonymous], 2017, XIPH ORG VID TEST M
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Charfi Y, 2009, IEEE WIREL COMMUN, V16, P44, DOI 10.1109/MWC.2009.4907559
   Chen GX, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P124, DOI 10.1109/CISP-BMEI.2016.7852694
   Correa G, 2014, IEEE I C ELECT CIRC, P239, DOI 10.1109/ICECS.2014.7049966
   Corrêa G, 2012, IEEE T CIRC SYST VID, V22, P1899, DOI 10.1109/TCSVT.2012.2223411
   Feng ZQ, 2018, IEEE ACCESS, V6, P45262, DOI 10.1109/ACCESS.2018.2864881
   Gao LF, 2015, IEEE INT SYMP CIRC S, P517, DOI 10.1109/ISCAS.2015.7168684
   Abenza PPG, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18093107
   Gwon D, 2015, 2015 ASIA PACIFIC CONFERENCE ON MULTIMEDIA AND BROADCASTING, P74
   Hu YY, 2018, IEEE DATA COMPR CONF, P413, DOI 10.1109/DCC.2018.00066
   Jian X., 2019, SENSORS, V19, P1, DOI 10.3390/s190101222-s2.0-85059498466
   Katayama T, 2018, CONFERENCE PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON INFORMATION AND COMPUTER TECHNOLOGIES (ICICT), P115, DOI 10.1109/INFOCT.2018.8356852
   Kim K, 2019, IEEE T CIRC SYST VID, V29, P1462, DOI 10.1109/TCSVT.2018.2839113
   Kim YH, 2016, INT SOC DESIGN CONF, P331
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Laude T., 2016, IEEE PICT COD S PCS, P1
   Li F, 2018, IEEE T MULTIMEDIA, V20, P1154, DOI 10.1109/TMM.2017.2764329
   Li JH, 2018, IEEE T IMAGE PROCESS, V27, P3236, DOI 10.1109/TIP.2018.2817044
   Li Y, 2018, IEEE IMAGE PROC, P1797, DOI 10.1109/ICIP.2018.8451396
   Li YP, 2018, IEEE IMAGE PROC, P993, DOI 10.1109/ICIP.2018.8451290
   Liu ZY, 2016, IEEE T IMAGE PROCESS, V25, P5088, DOI 10.1109/TIP.2016.2601264
   Ruiz-Coll D, 2014, IEEE IMAGE PROC, P4112, DOI 10.1109/ICIP.2014.7025835
   Shan Y, 2017, INT CONF ACOUST SPEE, P2642, DOI 10.1109/ICASSP.2017.7952635
   Shang XW, 2015, IEEE IMAGE PROC, P1593, DOI 10.1109/ICIP.2015.7351069
   Song Y, 2017, MULTIMED TOOLS APPL, V76, P2001, DOI 10.1007/s11042-015-3155-7
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Wang TY, 2018, IEEE ACCESS, V6, P71279, DOI 10.1109/ACCESS.2018.2879867
   Wang XX, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/5284628
   Xu M, 2017, HEVC COMPLEXITY REDU
   Xu M, 2018, IEEE T IMAGE PROCESS, V27, P5044, DOI 10.1109/TIP.2018.2847035
   Yan N, 2019, IEEE T CIRC SYST VID, V29, P840, DOI 10.1109/TCSVT.2018.2816932
   Yan SQ, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P225, DOI 10.1109/SITIS.2012.41
   Yeh CH, 2018, IEEE ACCESS, V6, P50087, DOI 10.1109/ACCESS.2018.2867342
   Zhang H, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhao ZH, 2019, IEEE T CIRC SYST VID, V29, P3291, DOI 10.1109/TCSVT.2018.2876399
   Zhu LW, 2017, IEEE T BROADCAST, V63, P547, DOI 10.1109/TBC.2017.2711142
NR 38
TC 12
Z9 12
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2441
EP 2460
DI 10.1007/s11042-020-09231-8
EA SEP 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000569701000007
DA 2024-07-18
ER

PT J
AU Kola, DGR
   Samayamantula, SK
AF Kola, Durga Ganga Rao
   Samayamantula, Srinivas Kumar
TI A novel approach for facial expression recognition using local binary
   pattern with adaptive window
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive window; Facial expression recognition; Feature extraction;
   Local binary pattern; Support vector machine
AB Facial Expression Recognition (FER) is an important area in human computer interaction. FER has different applications such as analysis of student behaviour in virtual class room, driver mood detection, security systems, and medicine. The analysis of facial expressions is an interesting and exciting problem. Feature extraction plays important role in any FER system. Local Binary Pattern (LBP) and its variants are popular for feature extraction due to simplicity in computation and monotonic illumination invariant property. However, the performance of LBP is poor in the presence of noise. This work proposes a novel approach for feature extraction to improve the performance of the FER. In this approach, the LBP is calculated considering 4-neighbors and diagonal neighbours separately. Further, for affective feature description, the concept of adaptive window and averaging in radial directions is introduced. This approach reduces the length of the feature vector as well as immune to noise. Support Vector Machine (SVM) is considered for classification. Recognition rate and confusion matrix are used to assess the performance of the proposed algorithm. Extensive experimental results on JAFFE, CK, FERG and FEI face databases show significant improvement in recognition rate compared to the available techniques both in noise free and noisy conditions.
C1 [Kola, Durga Ganga Rao; Samayamantula, Srinivas Kumar] JNTUK, Dept ECE, UCEK, Kakinada 533003, India.
C3 Jawaharlal Nehru Technological University - Kakinada
RP Kola, DGR (corresponding author), JNTUK, Dept ECE, UCEK, Kakinada 533003, India.
EM ganga_408@yahoo.co.in; samayamantula1963@gmail.com
RI samayamantula, srinivas kumar/AAR-9833-2020
OI SRINIVAS KUMAR, S/0000-0003-3703-5429
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   An QH, 2018, I C CONT AUTOMAT ROB, P1929, DOI 10.1109/ICARCV.2018.8581104
   Aneja D, 2017, LECT NOTES COMPUT SC, V10112, P136, DOI 10.1007/978-3-319-54184-6_9
   Awad A. I., 2016, STUDIES COMPUTATIONA
   Bashyal S, 2008, ENG APPL ARTIF INTEL, V21, P1056, DOI 10.1016/j.engappai.2007.11.010
   Bellamkonda S, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P1463
   Bi HB, 2019, IEEE IMAGE PROC, P3876, DOI [10.1109/ICIP.2019.8803629, 10.1109/icip.2019.8803629]
   Chao WL, 2015, SIGNAL PROCESS, V117, P1, DOI 10.1016/j.sigpro.2015.04.007
   Chen A, 2020, IEEE ACCESS, V8, P49741, DOI 10.1109/ACCESS.2020.2980060
   CHEN K, 2019, 2019 IEEE 89 VEH TEC, P1
   Cho M., 2020, ARXIV200300697, V3, P7
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dan ZP, 2014, OPTIK, V125, P6320, DOI 10.1016/j.ijleo.2014.08.003
   Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905
   Ekweariri AN, 2017, INT CONF COMPUT INTE, P43, DOI [10.1109/CICN.2017.8319353, 10.1109/CICN.2017.12]
   Eng S. K., 2019, IOP Conference Series: Materials Science and Engineering, V705, DOI 10.1088/1757-899X/705/1/012031
   Fan DP, 2019, IEEE I CONF COMP VIS, P5611, DOI 10.1109/ICCV.2019.00571
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Farajzadeh N, 2018, INFORM SCIENCES, V460, P318, DOI 10.1016/j.ins.2018.05.057
   Hassaballah M, 2016, STUD COMPUT INTELL, V630, P1, DOI 10.1007/978-3-319-28854-3_1
   Holder RP, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0190-5
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Huang YG, 2020, PROC CVPR IEEE, P5900, DOI 10.1109/CVPR42600.2020.00594
   Huang Z, 2018, IEEE ANN INT CONF CY, P938, DOI 10.1109/CYBER.2018.8688313
   Jabid T, 2010, IEEE ICCE
   Jabid T, 2010, ETRI J, V32, P784, DOI 10.4218/etrij.10.1510.0132
   Jaiswal S, 2020, NEURAL COMPUT APPL, V32, P11253, DOI 10.1007/s00521-019-04564-4
   Jung H, 2015, KOR-JPN JT WORKS FR
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Kaplan K, 2020, APPL SOFT COMPUT, V87, DOI 10.1016/j.asoc.2019.106019
   Kaushik S, 2017, 2017 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND DATA SCIENCE (MLDS 2017), P120, DOI 10.1109/MLDS.2017.9
   Khan RA, 2013, PATTERN RECOGN LETT, V34, P1159, DOI 10.1016/j.patrec.2013.03.022
   Kim JH, 2019, IEEE ACCESS, V7, P41273, DOI 10.1109/ACCESS.2019.2907327
   Lekdioui K, 2017, SIGNAL PROCESS-IMAGE, V58, P300, DOI 10.1016/j.image.2017.08.001
   Li JX, 2017, PROCEDIA COMPUT SCI, V107, P135, DOI 10.1016/j.procs.2017.03.069
   Liliana D. Y., 2019, Journal of Physics: Conference Series, V1193, DOI 10.1088/1742-6596/1193/1/012004
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Mehta R, 2016, PATTERN RECOGN LETT, V71, P16, DOI 10.1016/j.patrec.2015.11.019
   Minaee S., 2019, Deep-emotion: Facial expression recognition using attentional convolutional network
   Nigam S, 2018, MULTIMED TOOLS APPL, V77, P28725, DOI 10.1007/s11042-018-6040-3
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan ZB, 2017, IEEE SIGNAL PROC LET, V24, P828, DOI 10.1109/LSP.2017.2694460
   Patil Mrinalini, 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0420, DOI 10.1109/ICCSP.2019.8698045
   Perez-Gaspar LA, 2016, EXPERT SYST APPL, V66, P42, DOI 10.1016/j.eswa.2016.08.047
   Pitaloka DA, 2017, PROCEDIA COMPUT SCI, V116, P523, DOI 10.1016/j.procs.2017.10.038
   Roy SD, 2016, PROCEDIA COMPUT SCI, V84, P99, DOI 10.1016/j.procs.2016.04.072
   Salahat E, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1059, DOI 10.1109/ICIT.2017.7915508
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shan CF, 2005, IEEE IMAGE PROC, P2225
   Shan K, 2017, 2017 IEEE/ACIS 15TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT AND APPLICATIONS (SERA), P123, DOI 10.1109/SERA.2017.7965717
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Tong Y, 2014, OPTIK, V125, P4186, DOI 10.1016/j.ijleo.2014.04.062
   Yang B, 2018, IEEE ACCESS, V6, P4630, DOI 10.1109/ACCESS.2017.2784096
   Yee S.Y., 2019, PERFORM EVAL, V10, DOI 10.14569/IJACSA.2019.0100446
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
   Zhang J, 2018, PROC CVPR IEEE, P9029, DOI 10.1109/CVPR.2018.00941
   Zhang Y, 2015, OPTIK, V126, P4501, DOI 10.1016/j.ijleo.2015.08.185
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
NR 59
TC 36
Z9 37
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2243
EP 2262
DI 10.1007/s11042-020-09663-2
EA SEP 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000569366600007
DA 2024-07-18
ER

PT J
AU Teo, TY
   Sutopo, R
   Lim, JMY
   Wong, K
AF Teo, Ting Yau
   Sutopo, Ricky
   Lim, Joanne Mun-Yee
   Wong, KokSheik
TI Innovative lane detection method to increase the accuracy of lane
   departure warning system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lane departure warning; ADAS; Gabor filter; Hough transformation;
   Real-time application
AB Lane departure warning is one important feature in Advanced Driver Assistance Systems (ADAS), which aims to improve overall safety on the road. However, challenges such as inconsistent shadows and fading lane markings often plague the road surface and cause the lane detection system to produce false warnings. Users are aggravated by the warning and tend to disable this safety feature. This paper proposes an efficient Gabor filtering-based lane detection method to overcome the aforementioned conditions and improves the accuracy of lane departure warning system. Furthermore, it serves as a cost-effective solution to a lane departure warning problem, allowing it to be widely deployed. It is heuristically found that lane marking has a general directional property, which can be further enhanced by Gabor filter while suppressing inconsistent road shadows and road markers. Enhanced lane markings are then subjected to adaptive canny edge detection to extract distinct edge markings. Lastly, Hough transformation is applied to label the correct lane candidates on the road surface. Furthermore, we generate a dataset of Malaysia road with various driving conditions. As a proof of concept, a lane departure warning system is built based on the proposed lane detection method, which is able to achieve an accuracy of 93.67% for lane detection and 95.24% for lane departure warning tested on our challenging dataset. The codes are implemented on Raspberry pi 3B and installed in a vehicle for real-time application. The codes are multithreaded and found to achieve a desirable frame speed of 20 fps at 75% CPU utilization.
C1 [Teo, Ting Yau; Sutopo, Ricky; Lim, Joanne Mun-Yee] Monash Univ Malaysia, Sch Engn, Jalan Lagoon Selatan,Bandar Sunway, Subang Jaya 47500, Selangor, Malaysia.
   [Wong, KokSheik] Monash Univ Malaysia, Sch Informat Technol, Jalan Lagoon Selatan,Bandar Sunway, Subang Jaya 47500, Selangor, Malaysia.
C3 Monash University; Monash University Malaysia; Monash University; Monash
   University Malaysia
RP Lim, JMY (corresponding author), Monash Univ Malaysia, Sch Engn, Jalan Lagoon Selatan,Bandar Sunway, Subang Jaya 47500, Selangor, Malaysia.
EM Joanne.Lim@monash.edu
RI Lim, Joanne Mun-Yee/D-7778-2014; Wong, KokSheik/B-9796-2011
OI Lim, Joanne Mun-Yee/0000-0002-1326-8634; Wong,
   KokSheik/0000-0002-4893-2291
FU School of Engineering, Monash University Malaysia; School of Information
   Technology, Monash University Malaysia
FX This research was supported by Y.
CR An Y, 2016, MULTIMED TOOLS APPL, V75, P12983, DOI 10.1007/s11042-016-3527-7
   Bhujbal PN, 2015, 2015 THIRD INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P370, DOI 10.1109/ICIIP.2015.7414798
   Borkar A, 2012, IEEE T INTELL TRANSP, V13, P365, DOI 10.1109/TITS.2011.2173196
   Chang-Kun Yao, 2012, 2012 12th International Conference on ITS Telecommunications (ITST 2012), P170, DOI 10.1109/ITST.2012.6425158
   Hsiao PY, 2009, IEEE T VEH TECHNOL, V58, P2089, DOI 10.1109/TVT.2008.2006618
   Hua R, 2019, 2019 IEEE HEALTHCARE INNOVATIONS AND POINT OF CARE TECHNOLOGIES (HI-POCT), P87, DOI [10.1109/HI-POCT45284.2019.8962654, 10.1109/hi-poct45284.2019.8962654]
   Jang Ho-Jin Seung-Hae, 2014, INT C CENTR EUR COMP, P83
   Lee YK, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCE ON TEACHING, ASSESSMENT, AND LEARNING FOR ENGINEERING (TALE), P190, DOI [10.1109/TALE.2016.7851793, 10.1109/ICCE-Berlin.2016.7684702]
   Low CY, 2014, INT CONF ADV ROBOT
   Madrid N, 2016, FUZZY SET SYST, V291, P144, DOI 10.1016/j.fss.2015.09.009
   Munajat E, 2015, INT C ADV COMP SCI I, P195, DOI 10.1109/ICACSIS.2015.7415163
   Oh AR, 2015, MULTIMED TOOLS APPL, V74, P8597, DOI 10.1007/s11042-014-2348-9
   Palach J, 2014, PARALLEL PROGRAMMING, P29
   Saba T, 2020, MULTIMED TOOLS APPL, V79, P341, DOI 10.1007/s11042-019-08084-0
   Suddamalla U, 2015, INT CONF IMAG PROC, P87, DOI 10.1109/IPTA.2015.7367103
   Wan L, 2019, MULTIMED TOOLS APPL, V78, P8861, DOI 10.1007/s11042-018-6519-y
   Wang Q, 2018, IEEE T INTELL TRANSP, V19, P230, DOI 10.1109/TITS.2017.2749964
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
   Zhao ZY, 2020, NEUROCOMPUTING, V413, P328, DOI 10.1016/j.neucom.2020.06.094
   Zhou SY, 2010, IEEE INT VEH SYM, P59, DOI 10.1109/IVS.2010.5548087
NR 21
TC 11
Z9 13
U1 2
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2063
EP 2080
DI 10.1007/s11042-020-09819-0
EA SEP 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568478700005
DA 2024-07-18
ER

PT J
AU Rositi, H
   Appadoo, OK
   Mestre, D
   Valarier, S
   Ombret, MC
   Gadea-Deschamps, E
   Barret-Grimault, C
   Lohou, C
AF Rositi, Hugo
   Appadoo, Owen Kevin
   Mestre, Daniel
   Valarier, Sylvie
   Ombret, Marie-Claire
   Gadea-Deschamps, Emilie
   Barret-Grimault, Christine
   Lohou, Christophe
TI Presentation of a mixed reality software with a HoloLens headset for a
   nutrition workshop
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mixed reality; HoloLens; Therapeutic education; Nutrition; Clinical
   study
ID EATING-DISORDERS; VISUALIZATION
AB Microsoft has recently released a mixed reality headset called HoloLens. This semi-transparent visor headset allows the user who wears it to view the projection of 3D virtual objects placed in its real environment. The user can also grasp these 3D objects, which can also interact with each other. The framework of this new technology taking into account this physical approach (interactions, collisions) is calledmixed reality. We had the opportunity to digitally transform a conventional nutrition workshop for patients waiting for bariatric surgery by designing a mixed reality software using the HoloLens headset. This software is called HOLO_NUTRI. In this paper, we present this software and its assessment (acceptance of this technology) by a cohort of thirty patients.
C1 [Rositi, Hugo; Appadoo, Owen Kevin; Lohou, Christophe] Univ Clermont Auvergne, Inst Pascal, SIGMA Clermont, CNRS, F-63000 Clermont Ferrand, France.
   [Rositi, Hugo] Univ Clermont Auvergne, IUT Clermont Ferrand Site Puy En Velay, Inst Pascal, 8 Rue Jean Baptiste Fabre CS 10219, F-43009 Le Puy En Velay, France.
   [Mestre, Daniel] Aix Marseille Univ, CNRS, ISM Inst Sci Mouvement CP910, F-13288 Marseille, France.
   [Valarier, Sylvie; Barret-Grimault, Christine] CH Emile Roux Puy En Velay, Serv Chirurg Bariat Nutr, 12 Blvd Docteur Chantemesse, F-43000 Le Puy En Velay, France.
   [Ombret, Marie-Claire] CH Emile Roux Puy En Velay, Unite Transversale Educ Patient, 12 Blvd Docteur Chantemesse, F-43000 Le Puy En Velay, France.
   [Gadea-Deschamps, Emilie] CH Emile Roux Puy En Velay, Unite Rech Clin, 12 Blvd Docteur Chantemesse, F-43000 Le Puy En Velay, France.
C3 Universite Clermont Auvergne (UCA); Centre National de la Recherche
   Scientifique (CNRS); Universite Clermont Auvergne (UCA); Centre National
   de la Recherche Scientifique (CNRS); Aix-Marseille Universite
RP Rositi, H (corresponding author), Univ Clermont Auvergne, Inst Pascal, SIGMA Clermont, CNRS, F-63000 Clermont Ferrand, France.; Rositi, H (corresponding author), Univ Clermont Auvergne, IUT Clermont Ferrand Site Puy En Velay, Inst Pascal, 8 Rue Jean Baptiste Fabre CS 10219, F-43009 Le Puy En Velay, France.
EM hugo.rositi@uca.fr; owen.appadoo@uca.fr; daniel.mestre@univ-amu.fr;
   sylvie.valarier@ch-lepuy.fr; marieclaire.ombret@ch-lepuy.fr;
   responsable.rechercheclinique@ch-lepuy.fr; christine.barret@ch-lepuy.fr;
   christophe.lohou@uca.fr
RI LOHOU, Christophe/C-8224-2018
OI LOHOU, Christophe/0000-0001-5352-8237; Rositi, Hugo/0000-0002-5264-2027
FU french national grant: PEPS INSIS CNRS "Sciences de l'Ingenierie pour la
   Sante pour accompagner des projets translationnels"; project AVACM
   (Assistance Visuelle Augmentee lors de Consultations Medicales)
FX Authors would like to thank Arthur Jacquin, student in DUT Informatique
   Graphique at IUT de Clermont-Ferrand, France (site Le Puy-en-Velay) for
   the software design. This project is funded by a french national grant:
   PEPS INSIS CNRS "Sciences de l'Ingenierie pour la Sante pour accompagner
   des projets translationnels", 2017, project AVACM (Assistance Visuelle
   Augmentee lors de Consultations Medicales).
CR Anima Res Gmbh, 2016, INS HEART APPL
   [Anonymous], 2020, UNREAL ENGINE
   [Anonymous], 2020, Microsoft hololens
   [Anonymous], 2020, SUBFIGURE2F K KOWALE
   [Anonymous], 2020, SUBFIGURE2E C HACKLE
   [Anonymous], 2020, OCULUS RIFT
   [Anonymous], 2020, SUBFIGURE2A ARTFULSP
   [Anonymous], 2020, Unity
   [Anonymous], 2020, SUBFIGURE2D R MASONE
   [Anonymous], 2019, Microsoft | Visual Studio
   [Anonymous], 2020, SUBFIGURE2C ARS ELEC
   [Anonymous], 2020, SUBFIGURE2B IAN TRUE
   [Anonymous], 2020, GAZE GESTURE VOICE
   [Anonymous], 2020, GOOGLE GLASS
   Appadoo OK, 2020, REVIEW
   Ashman A., 2017, Journal of Nutrition & Intermediary Metabolism, V8, P90, DOI 10.1016/j.jnim.2017.04.110
   Auriach J, 2017, REGIME FACON REALITE
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Barret-Grimault C, 2019, INNOVONS ETP GRACE C
   Bayu MZ, 2013, PROC TECH, V11, P396, DOI 10.1016/j.protcy.2013.12.208
   Blender software, 2020, BLENDER SOFTWARE
   Bremme L, 2017, HOLOLENS OPERATION C
   Campbell M, 2017, APPLE INVENTION USES
   Case Western Reserve University, 2016, HOLOANATOMY APPL
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Daigneault A, 2016, VIRTUAL EATING VIRTU
   El-Gayar Omar, 2013, J Diabetes Sci Technol, V7, P247
   ElSayed NAM, 2016, J VISUAL LANG COMPUT, V36, P13, DOI 10.1016/j.jvlc.2016.07.006
   Epson Moverio, 2020, EPSON MOVERIO
   Escárcega-Centeno D, 2015, PROCEDIA COMPUT SCI, V75, P275, DOI 10.1016/j.procs.2015.12.248
   Far application, 2020, FAR APPL
   Ferrer-García M, 2012, BODY IMAGE, V9, P1, DOI 10.1016/j.bodyim.2011.10.001
   García-Vázquez V, 2018, INNOV SURG SCI, V3, P167, DOI 10.1515/iss-2018-2001
   Hercberg S, 2004, ARCH INTERN MED, V164, P2335, DOI 10.1001/archinte.164.21.2335
   Hercberg S., 2002, Portions alimentaires: Manuel photos pour l'estimation des quantites
   HTC Vive headset, 2020, HTC VIVE HEADSET
   Igue D, 2017, IOS11ARKIT NOUVEL OS
   Jang J., 2018, PLOS ONE, V13, P1
   Kokiri Lab, 2014, PROJ NOUR GASTR VIRT
   Kuhlemann I, 2017, HEALTHC TECHNOL LETT, V4, P184, DOI 10.1049/htl.2017.0061
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Liu H, 2018, ANN BIOMED ENG, V46, P1595, DOI 10.1007/s10439-018-2055-1
   Lohou C, 2019, 20 INT C IM AN PROC
   Lohou C, 2020, DESIGN MIXED R UNPUB
   Lohou C, 2019, SURG RENNES FRANCE
   Meissner M, 2019, J BUS RES, V100, P445, DOI 10.1016/j.jbusres.2017.09.028
   Menet J, 2017, FOODTECH REALITE AUG
   Meta vision, 2019, METAVISION
   Microsoft HoloLens application, 2016, MICROSOFT HOLOLENS A
   Microsoft HoloToolKit, 2019, MICROSOFT HOLOTOOLKI
   Mira augmented reality, 2017, MIRA AUGMENTED REALI
   O'Leary F, 2017, BACK AWAY BURGER MIC
   Perpiñá C, 2016, COMPR PSYCHIAT, V67, P39, DOI 10.1016/j.comppsych.2016.02.012
   Persky S, 2018, APPETITE, V123, P201, DOI 10.1016/j.appet.2017.12.007
   Pratt P, 2018, EUR RADIOL EXP, V2, DOI 10.1186/s41747-017-0033-2
   Rivas F, 2017, STUDENTS LEARN VIRTU
   Robertson A, 2017, ATKINS MADE VIRTUAL
   Rollo M. E., 2017, Journal of Nutrition & Intermediary Metabolism, V8, P90, DOI 10.1016/j.jnim.2017.04.111
   Rollo ME, 2017, INT J BEHAV NUTR PHY, V14, DOI 10.1186/s12966-017-0516-9
   Rollo ME, 2016, DIABET METAB SYND OB, V9, P381, DOI 10.2147/DMSO.S95247
   Surur, 2017, SURUR
   Ung CY, 2018, FOOD QUAL PREFER, V63, P12, DOI 10.1016/j.foodqual.2017.07.007
   Vimedix AR ultrasound simulator, 2017, VIMEDIX AR ULTRASOUN
   Watson J, 2020, FOOTPRINTS FREE SPAC
   Wolcott RC, 2017, VIRTUAL REALITY SEX
NR 65
TC 4
Z9 4
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 1945
EP 1967
DI 10.1007/s11042-020-09687-8
EA SEP 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568184100015
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, XJ
   Wang, CY
   Cheng, L
   Jiang, SH
   Qi, JT
AF Zhang, Xiaojuan
   Wang, Changying
   Cheng, Li
   Jiang, Shuihan
   Qi, Junting
TI Single shot object detection with refined feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; SSD; Bounding box; Center map; Scale map
AB Object classification and localization are two significant aspects of object detector based on the Single Shot MultiBox Detector (SSD). In general, the more feature maps there are, the better the object classification performance will be. However, when the information of excessive feature maps are sparse and unnecessary, the performance of object detection is slightly improved or maybe precisely opposite, which is instead harmful to the production of object localization. The performance of object detectors is not only related to the number of feature maps but also relies partly on the bounding box regression and Non-Maximum Suppression (NMS). In this paper, a detector is constructed based on SSD, called Detection with Refined Feature (DRF), involving center map and scale map, the detection loss is reshaped. Our motivation is to improve the accuracy of classification and localization by searching for central points and predicting the scales of the object points. Center map is used to predict the Intersection over Union (IoU) between the prediction box and ground truth box, while scale map considers the relationships among the different scales. Experimental results on both Pascal VOC and MS COCO 2014 instance datasets demonstrate the effectiveness of DRF. Using Darknet53, we achieve an 86.4% mean Average Precision (mAP) on Pascal VOC2007 and an 87.4% mAP on Pascal VOC2007 and VOC2012. On MS COCO, the DRF with ResNet50 still achieves moderate improvement.
C1 [Zhang, Xiaojuan; Wang, Changying; Cheng, Li; Jiang, Shuihan; Qi, Junting] Fujian Agr & Forestry Univ, Coll Comp & Informat Sci, Fuzhou, Fujian, Peoples R China.
C3 Fujian Agriculture & Forestry University
RP Cheng, L (corresponding author), Fujian Agr & Forestry Univ, Coll Comp & Informat Sci, Fuzhou, Fujian, Peoples R China.
EM li.cheng@fafu.edu.cn
FU Research on Pixel Coordinate Calibration Method for Video by
   Multi-Mobile Terminal Collaboration
FX This research is supported by the Research on Pixel Coordinate
   Calibration Method for Video by Multi-Mobile Terminal Collaboration. We
   thank NVIDIA for providing great support with GPU clusters.
CR Abualigah L. M. Q., 2019, Feature selection and enhanced krill herd algorithm for text document clustering, DOI [DOI 10.1007/978-3-030-10674-4, 10.1007/978-3-030-10674-4]
   Abualigah LM, 2018, J COMPUT SCI-NETH, V25, P456, DOI 10.1016/j.jocs.2017.07.018
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Dong Z., 2020, P IEEE C COMP VIS PA, P10519, DOI DOI 10.1109/CVPR42600.2020.01053
   Everingham M., 2007, The PASCAL Visual Object Classes Chal- lenge (VOC) Results, DOI 10.1007/s11263-009-0275-4
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Hastie T., 2010, TECHNOMETRICS, V45, P267, DOI DOI 10.1198/TECH.2003.S770
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He YH, 2019, PROC CVPR IEEE, P2883, DOI 10.1109/CVPR.2019.00300
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZJ, 2019, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2019.00657
   Jang H-D, 2019, IEEE C COMP VIS PATT
   Jeong J, 2017, IEEE INT C COMP VIS, DOI 10.5244/C.31.76
   Jiang B, 2018, IEEE CONF COMM NETW
   Leng JX, 2019, NEURAL COMPUT APPL, V31, P6549, DOI 10.1007/s00521-018-3486-1
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Li MF, 2019, INT J PARALLEL PROG, V47, P467, DOI 10.1007/s10766-018-00623-w
   Li WH, 2019, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2019.00514
   Li Z., 2017, CORR
   Limaye A, 2020, IEEE C COMP VIS PATT
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu W, 2019, PROC CVPR IEEE, P5182, DOI 10.1109/CVPR.2019.00533
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mingxing Tan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10778, DOI 10.1109/CVPR42600.2020.01079
   Novak B, 2020, 2020 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P165, DOI [10.1109/zinc50678.2020.9161446, 10.1109/ZINC50678.2020.9161446]
   Perez-Rua Juan-Manuel, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13843, DOI 10.1109/CVPR42600.2020.01386
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Su MC, 2000, IEEE T NEURAL NETWOR, V11, P721, DOI 10.1109/72.846743
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Van Etten A, 2020, IEEE C COMP VIS PATT
   Wu X, 2019, ARXIV190803673
   Xuangeng Chu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12211, DOI 10.1109/CVPR42600.2020.01223
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
   Zhang Z, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Zhao ZQ, 2018, IEEE C COMP VIS PATT
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zhongzheng Ren, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10595, DOI 10.1109/CVPR42600.2020.01061
   Zhou W, 2019, IEEE C COMP VIS PATT
NR 46
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 737
EP 752
DI 10.1007/s11042-020-09483-4
EA SEP 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566043200001
DA 2024-07-18
ER

PT J
AU Zhang, ZN
   Li, ZC
   Han, M
   Su, ZY
   Li, WQ
   Pan, ZG
AF Zhang, Zhenning
   Li, Zichen
   Han, Meng
   Su, Zhiyong
   Li, Weiqing
   Pan, Zhigeng
TI An augmented reality-based multimedia environment for experimental
   education
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Experiential learning; Experimental education;
   Multimedia environment
AB Over the last few years, there has been a growing interest in augmented reality (AR) technology for education. However, current AR education applications are often used as a new type of knowledge display platform, and they cannot fully participate in educational activities to improve educational results. To enable AR technology to participate in educational activities more effectively, according to learning-by-doing theory, we explore the form of a future experimental course and propose a new AR-based multimedia environment for experimental education. The framework of the multimedia environment consists of three components: the AR experiment authoring tool, the AR experiment application, and the management application. In this AR-based multimedia environment, teachers can independently create AR experiments using the what you see is what you get (WYSIWYG) editing method. Students can manipulate the AR-based experimental object to complete the experiment in class. Moreover, teachers can observe students' experimental behaviour, obtain evaluations in real time, and even guide students remotely. We also present an application case of a chemistry experiment and obtain results of the usability test, demonstrating improvements in AR technology participation in educational activities.
C1 [Zhang, Zhenning; Li, Zichen; Han, Meng; Li, Weiqing; Pan, Zhigeng] Nanjing Univ Sci & Technol, Sch Engn & Comp Sci, Nanjing, Peoples R China.
   [Su, Zhiyong] Nanjing Univ Sci & Technol, Sch Automat, Nanjing, Peoples R China.
   [Pan, Zhigeng] Hangzhou Normal Univ, Digital Media & HCI Res Ctr, Hangzhou, Peoples R China.
C3 Nanjing University of Science & Technology; Nanjing University of
   Science & Technology; Hangzhou Normal University
RP Li, WQ (corresponding author), Nanjing Univ Sci & Technol, Sch Engn & Comp Sci, Nanjing, Peoples R China.
EM li_weiqing@njust.edu.cn
OI Zhang, Zhenning/0000-0001-5989-3593
FU National Key R&D Program of China [2018YFB1004904]; Pre-research Project
   of The 13th Five Year Plan [31511040202, 315050502, 61409230104]; Key
   R&D Plan of Jiangsu Province [BE2017031]; Fundamental Research Funds for
   the Central Universities [30918012203]
FX This work was supported by the National Key R&D Program of China (grant
   number: 2018YFB1004904), the Pre-research Project of The 13th Five Year
   Plan (grant/award numbers: 31511040202, 315050502 and 61409230104), and
   the Key R&D Plan of Jiangsu Province (grant/award number: BE2017031), in
   part by the Fundamental Research Funds for the Central Universities
   under Grant 30918012203.
CR Aguilar IA, 2019, MULTIMED TOOLS APPL, V78, P33899, DOI 10.1007/s11042-019-08064-4
   Akçayir M, 2017, EDUC RES REV-NETH, V20, P1, DOI 10.1016/j.edurev.2016.11.002
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Baloch S., 2018, International Journal of Electrical Engineering Emerging Technology, V1, P41
   Billinghurst M, 2012, COMPUTER, V45, P56, DOI 10.1109/MC.2012.111
   Challenor J, 2019, MULTIMODAL TECHNOLOG, V3, DOI 10.3390/mti3020039
   Mendes PRC, 2018, PROCEEDINGS OF THE ACM SYMPOSIUM ON DOCUMENT ENGINEERING (DOCENG 2018), DOI 10.1145/3209280.3209534
   Davis F. D., 1985, A technology acceptance model for empirically testing new end-user information systems: Theory and results, DOI DOI 10.1016/S0378-7206(01)00143-4
   Dede C, 2009, SCIENCE, V323, P66, DOI 10.1126/science.1167311
   Dickens K, 2014, CHRISTIAN TEACHERS J, V22.3, P18
   Dunleavy M, 2009, J SCI EDUC TECHNOL, V18, P7, DOI 10.1007/s10956-008-9119-1
   Girouard A, 2019, ACM T COMPUT-HUM INT, V26, DOI 10.1145/3319617
   Gonzalez ANV, 2019, 2019 IEEE C VIRT REA
   de Ravé EG, 2016, MULTIMED TOOLS APPL, V75, P9641, DOI 10.1007/s11042-016-3384-4
   Hwang GJ, 2016, INTERACT LEARN ENVIR, V24, P1895, DOI 10.1080/10494820.2015.1057747
   Ibáñez MB, 2018, COMPUT EDUC, V123, P109, DOI 10.1016/j.compedu.2018.05.002
   Jee HK, 2014, MULTIMED TOOLS APPL, V68, P225, DOI 10.1007/s11042-011-0880-4
   Kim K, 2018, IEEE T VIS COMPUT GR, V24, P2947, DOI 10.1109/TVCG.2018.2868591
   Mendes PRC, 2019, AN EST 25 S BRAS SIS
   Pan ZG, 2006, COMPUT GRAPH-UK, V30, P20, DOI 10.1016/j.cag.2005.10.004
   Satpute T, 2015, 2015 International Conference on Communication, Information & Computing Technology (ICCICT)
   Villanueva A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376146
   Wojciechowski R, 2013, COMPUT EDUC, V68, P570, DOI 10.1016/j.compedu.2013.02.014
NR 23
TC 29
Z9 30
U1 7
U2 76
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 575
EP 590
DI 10.1007/s11042-020-09684-x
EA SEP 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000565837600005
DA 2024-07-18
ER

PT J
AU Peng, JJ
   Hao, Y
   Xu, FQ
   Fu, XP
AF Peng, Jinjia
   Hao, Yun
   Xu, Fengqiang
   Fu, Xianping
TI Vehicle re-identification using multi-task deep learning network and
   spatio-temporal model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-task network; Spatial-temporal model; Vehicle re-identification
ID RECOGNITION
AB Vehicle re-identification (re-ID) plays an important role in the automatic analysis of the increasing urban surveillance videos and has become a hot topic in recent years. Vehicle re-ID aims at identifying vehicles across different cameras. However, it suffers from the difficulties caused by various viewpoint of vehicles, diversified illuminations, and complicated environments. In this paper, a two-stage vehicle re-ID framework is proposed to address these challenges, which contains a feature extraction module for achieving discriminative features and a spatial-temporal re-ranking module to improve the accuracy of vehicle re-ID task. Firstly, a multi-task deep network that integrates identity predicting network, attribute recognition network and verification network is adopted to learn discriminate features. Secondly, a spatio-temporal model is built to re-rank the appearance information measurement results, which utilizes the spatio-temporal relationship to increase constraints of the images. Moreover, to facilitate progressive vehicle re-ID research, experiments are conducted on both the VeRi-776 dataset and VehicleID dataset. Both the proposed multi-task feature extraction module and spatio-temporal model achieve considerable improvements.
C1 [Peng, Jinjia; Hao, Yun; Xu, Fengqiang; Fu, Xianping] Dalian Maritime Univ, Coll Informat & Sci Technol, Dalian 116021, Liaoning, Peoples R China.
   [Fu, Xianping] Pengcheng Lab, Shenzhen 518055, Guangdong, Peoples R China.
C3 Dalian Maritime University
RP Fu, XP (corresponding author), Dalian Maritime Univ, Coll Informat & Sci Technol, Dalian 116021, Liaoning, Peoples R China.; Fu, XP (corresponding author), Pengcheng Lab, Shenzhen 518055, Guangdong, Peoples R China.
EM jinjiapeng@dlmu.edu.cn; yunhao@dlmu.edu.cn; xfq@dlmu.edu.cn;
   fxp@dlmu.edu.cn
FU National Natural Science Foundation of China [61370142, 61272368];
   Fundamental Research Funds for the Central Universities [3132016352];
   Fundamental Research of Ministry of Transport of P. R. China
   [2015329225300]; Dalian Science and Technology Innovation Fund
   [2019J11CY001]; Dalian Leading talent Grant; Foundation of Liaoning Key
   Research and Development Program; China Postdoctoral Science Foundation
   [3620080307]; Liaoning Revitalization Talents Program [XLYC1908007]
FX This work was supported in part by the National Natural Science
   Foundation of China Grant 61370142 and Grant 61272368, by the
   Fundamental Research Funds for the Central Universities Grant
   3132016352, by the Fundamental Research of Ministry of Transport of P.
   R. China Grant 2015329225300, by the Dalian Science and Technology
   Innovation Fund 2019J11CY001 and Dalian Leading talent Grant, by the
   Foundation of Liaoning Key Research and Development Program, China
   Postdoctoral Science Foundation 3620080307, by Liaoning Revitalization
   Talents Program, XLYC1908007, by Dalian Science and Technology
   Innovation Fund 2019J11CY001, by the Fundamental Research Funds for the
   Central Universities Grant 3132016352.
CR Abdulhai B, 2003, TRANSPORT RES C-EMER, V11, P223, DOI 10.1016/S0968-090X(03)00024-X
   Ahmad J, 2018, FUTURE GENER COMP SY, V81, P314, DOI 10.1016/j.future.2017.11.002
   [Anonymous], 2017, ARXIV170802386
   Bai Y, 2017, IEEE INT CON MULTI, P1452, DOI 10.1109/ICME.2017.8019371
   Charbonnier S, 2012, IEEE IMTC P, P380, DOI 10.1109/I2MTC.2012.6229117
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Coifman B, 1998, TRANSPORT RES REC, P181
   Feris RS, 2012, IEEE T MULTIMEDIA, V14, P28, DOI 10.1109/TMM.2011.2170666
   Gou C, 2016, IEEE T INTELL TRANSP, V17, P1096, DOI 10.1109/TITS.2015.2496545
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kanaci A., 2017, P SUDD OAK DEATH 6 S, V2, P772
   Li X, 2017, IEEE INT C INT TRANS
   Li YQ, 2017, IEEE IMAGE PROC, P395, DOI 10.1109/ICIP.2017.8296310
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu XD, 2013, C IND ELECT APPL, P1221
   Liu XC, 2018, IEEE T MULTIMEDIA, V20, P645, DOI 10.1109/TMM.2017.2751966
   Sanchez R. O., 2011, 2011 IEEE International Conference on Vehicular Electronics and Safety (ICVES 2011), P226, DOI 10.1109/ICVES.2011.5983819
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shen YT, 2017, IEEE I CONF COMP VIS, P1918, DOI 10.1109/ICCV.2017.210
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tian Y, 2014, J ZHEJIANG U-SCI C, V15, P372, DOI 10.1631/jzus.C1300291
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wang ZD, 2017, IEEE I CONF COMP VIS, P379, DOI 10.1109/ICCV.2017.49
   Wu L, 2019, IEEE T NEURAL NETW L
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Yan K, 2017, IEEE I CONF COMP VIS, P562, DOI 10.1109/ICCV.2017.68
   Yu SY, 2015, PATTERN RECOGN, V48, P114, DOI 10.1016/j.patcog.2014.07.027
   Zapletal D, 2016, IEEE COMPUT SOC CONF, P1568, DOI 10.1109/CVPRW.2016.195
   Zhedong Zheng, 2017, ACM Transactions on Multimedia Computing, Communications and Applications, V14, DOI 10.1145/3159171
NR 31
TC 2
Z9 2
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32731
EP 32747
DI 10.1007/s11042-020-09356-w
EA AUG 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000563739900009
DA 2024-07-18
ER

PT J
AU AL-ardhi, S
   Thayananthan, V
   Basuhail, A
AF AL-ardhi, Saleh
   Thayananthan, Vijey
   Basuhail, Abdullah
TI A new vector map watermarking technique in frequency domain based on
   LCA-transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copyright protection; Vector map; Robust watermarking; Linear cellular
   automata transform (LCAT); Least significant bit (LSB)
AB Two-dimensional vector maps are vulnerable to issues related to copyright owner's protection, which have an impact on the vector-data usage in different applications. Watermarking schemes are required in order to prevent this type of attack rotation, uniform scaling and translation (RST), invariance property, embedding distortion control and a high level of capacity in their concealment of a digital vector map's information. This process typically involves transforming an original map and embedding the watermark. In this paper, a new approach to copyright protection for vector maps is proposed using a linear cellular automata (LCA) algorithm. The approach taken is as follows: (1) an original map, which is LCA-transformed, is obtained; (2) the watermark bit insertion process is conducted on the coefficient of the transformation result frequency into the LSB pattern; and (3) the inverse LCA transformation of the map is employed to obtain the watermarked map. Subsequent analysis has found that this approach provides desirable levels of fidelity, invisibility, capacity and computational complexity. It is also resistant to geometric and signal-operations attacks and provides multi-frequency domains for digital watermarking.
C1 [AL-ardhi, Saleh; Thayananthan, Vijey; Basuhail, Abdullah] King Abdulaziz Univ, Fac Comp & Informat Technol FCIT, Jeddah, Saudi Arabia.
C3 King Abdulaziz University
RP AL-ardhi, S; Thayananthan, V; Basuhail, A (corresponding author), King Abdulaziz Univ, Fac Comp & Informat Technol FCIT, Jeddah, Saudi Arabia.
EM s_ardhi@hotmail.com; vthayanathan@kau.edu.sa; abasuhail@kau.edu.sa
RI Thayananthan, Vijey/ABF-1260-2020; Basuhail, Abdullah/AEX-5987-2022
OI Thayananthan, Vijey/0000-0003-2399-352X; 
CR Abubahia A, 2017, MULTIMED TOOLS APPL, V76, P12205, DOI 10.1007/s11042-016-3441-z
   Al-ardhi S, 2019, INT J ADV COMPUT SCI, V10, DOI [10.14569/IJACSA.2019.0100651, DOI 10.14569/IJACSA.2019.0100651]
   Al-ardhi S, 2020, ADV COMPUTER VISION, V1
   Al-Haj A, 2011, INT ARAB J INF TECHN, V8, P326
   Ang SS, 2009, IEEE INT POWER ELEC, P1
   [Anonymous], 2008, REMOTE SENSING SPATI
   [Anonymous], 2008, GEOINF 2008 JOINT C
   [Anonymous], 2012, LNEE
   Bhat V, 2008, LECT NOTES COMPUT SC, V5352, P235, DOI 10.1007/978-3-540-89862-7_20
   Cao L, 2012, VISUAL COMPUT, V29, P231
   Chang K.T., 2012, Introduction to geographic information systems, V6th
   Dalhoum A. L. A., 2012, IEEE Multimedia, V19, P28, DOI 10.1109/MMUL.2011.54
   Deb K., 2012, INT J ADV SCI TECHNO, V47, P65
   Dhar PK, 2011, INT J SECUR APPL, V5, P33
   Gao H., 2013, TELKOMNIKA, V11, P3271
   Jianghua Li, 2014, IAES TELKOMNIKA Indonesian Journal of Electrical Engineering, V12, P693
   Jingwen Wu, 2013, Advances in Swarm Intelligence. 4th International Conference, ICSI 2013. Proceedings, P215, DOI 10.1007/978-3-642-38715-9_26
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Li A, 2008, Int Arch Photogram Rem Sens Spatial Inf Sci, V37, P1783
   Li X. W., 2012, INT J COMPUT THEORY, V4, P722
   Li XW, 2014, OPTIK, V125, P2983, DOI 10.1016/j.ijleo.2013.12.036
   Li XW, 2014, OPT COMMUN, V319, P45, DOI 10.1016/j.optcom.2013.12.089
   Li XW, 2014, MULTIDIM SYST SIGN P, V25, P405, DOI 10.1007/s11045-012-0203-6
   Li XW, 2017, IEEE J-STSP, V11, P1200, DOI 10.1109/JSTSP.2017.2714838
   Li Xiao-wei, 2011, Journal of Information and Communication Convergence Engineering, V9, P689
   Li Xiao-Wei, 2011, Journal of Information and Communication Convergence Engineering, V9, P212
   Li YT, 2019, MULTIMED TOOLS APPL, V78, P17973, DOI 10.1007/s11042-018-7122-y
   Liang B, 2010, ISPRS C, V38
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Ma C, 2013, TELKOMNIKA, V11, P6281
   Madain A, 2014, MULTIMED TOOLS APPL, V71, P1803, DOI 10.1007/s11042-012-1306-7
   del Rey AM, 2011, APPL MATH COMPUT, V217, P8360, DOI 10.1016/j.amc.2011.03.033
   NASA, GLOB CHANG MAST DIR
   Neyman S.N., 2014, Telecommun. Comput. Electron. Control, V12, P367
   PaperdJuly W., 1998, ESRI shapefile technical description, V16, P370
   Qiming Liu, 2013, IAES TELKOMNIKA Indonesian Journal of Electrical Engineering, V11, P302
   Shiba R, 2004, TENCON IEEE REGION, pA303
   Suryavanshi H. E., 2013, IAES International Journal of Electrical and Computer Engineering, V3, P1
   박영일, 2009, [Journal of the Korea Institute Of Information and Communication Engineering, 한국정보통신학회논문지], V13, P1767
   Tefas A, 2005, INT CONF ACOUST SPEE, P1049
   Wang CJ, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 2, PROCEEDINGS, P71, DOI 10.1109/MINES.2009.195
   Wang NN, 2014, COMPUT AIDED DESIGN, V47, P108, DOI 10.1016/j.cad.2013.10.005
   Xu Y, 2013, TELKOMNIKA, V11, P191
   Zhang YS, 2015, NONLINEAR DYNAM, V82, P1831, DOI 10.1007/s11071-015-2280-1
NR 49
TC 2
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32361
EP 32387
DI 10.1007/s11042-020-09422-3
EA AUG 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000564978000006
DA 2024-07-18
ER

PT J
AU Yan, ZP
   Zhang, JZ
   Tang, JL
AF Yan, Zheping
   Zhang, Jinzhong
   Tang, Jialing
TI Modified water wave optimization algorithm for underwater multilevel
   thresholding image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multilevel thresholding; Image segmentation; Water wave optimization;
   Elite opposition-based learning strategy; Ranking-based mutation
   operator; Kapur's entropy
ID PARTICLE SWARM OPTIMIZATION; CUCKOO SEARCH ALGORITHM; FEATURE-SELECTION;
   ENTROPY
AB Multilevel thresholding is a simple and important method for image segmentation in various applications that has drawn widespread attention in recent years. However, the computational complexity increases correspondingly when the threshold levels increase. To overcome this drawback, a modified water wave optimization (MWWO) algorithm with the elite opposition-based learning strategy and the ranking-based mutation operator for underwater image segmentation is proposed in this paper. The elite opposition-based learning strategy increases the diversity of the population and prevents the search from stagnating to improve the calculation accuracy. The ranking-based mutation operator increases the selection probability. MWWO can effectively balance exploration and exploitation to obtain the optimal solution in the search space. To objectively evaluate the overall performance of the proposed algorithm, MWWO is compared with six state-of-the-art meta-heuristic algorithms by maximizing the fitness value of Kapur's entropy method to obtain the optimal threshold through experiments on ten test images. The fitness value, the best threshold values, the execution time, the peak signal to noise ratio (PSNR), the structure similarity index (SSIM), and the Wilcoxon's rank-sum test are used as important metrics to evaluate the segmentation effect of underwater images. The experimental results show that MWWO has a better segmentation effect and stronger robustness compared with other algorithms and an effective and feasible method for solving underwater multilevel thresholding image segmentation.
C1 [Yan, Zheping; Zhang, Jinzhong; Tang, Jialing] Harbin Engn Univ, Coll Automat, Harbin 150001, Peoples R China.
C3 Harbin Engineering University
RP Zhang, JZ (corresponding author), Harbin Engn Univ, Coll Automat, Harbin 150001, Peoples R China.
EM zhangjinzhongz@126.com
RI zhang, jin/IXD-9872-2023; zhang, jin/GXV-9154-2022; Zhang,
   Jing/ISA-6627-2023
OI Zhang, Jing/0009-0003-5039-5688
FU National Nature Science Foundation of China [51679057]; Province Science
   Fund for Distinguished Young Scholars [J2016JQ0052]
FX This work was partially funded by the National Nature Science Foundation
   of China under Grant No. 51679057, and partly supported by the Province
   Science Fund for Distinguished Young Scholars under Grant No.
   J2016JQ0052.
CR Abd El Aziz M, 2017, EXPERT SYST APPL, V83, P242, DOI 10.1016/j.eswa.2017.04.023
   Abd Elaziz M, 2019, EXPERT SYST APPL, V125, P112, DOI 10.1016/j.eswa.2019.01.047
   Abualigah L, 2021, CLUSTER COMPUT, V24, P205, DOI 10.1007/s10586-020-03075-5
   Abualigah L, 2020, NEURAL COMPUT APPL, V32, P12381, DOI 10.1007/s00521-020-04839-1
   Abualigah LM, 2018, APPL INTELL, V48, P4047, DOI 10.1007/s10489-018-1190-6
   Abualigah LM, 2018, ENG APPL ARTIF INTEL, V73, P111, DOI 10.1016/j.engappai.2018.05.003
   Abualigah LM, 2018, J COMPUT SCI-NETH, V25, P456, DOI 10.1016/j.jocs.2017.07.018
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   Akay B, 2013, APPL SOFT COMPUT, V13, P3066, DOI 10.1016/j.asoc.2012.03.072
   Aldahdooh A, 2018, DIGIT SIGNAL PROCESS, V77, P195, DOI 10.1016/j.dsp.2017.09.013
   Bao XL, 2019, IEEE ACCESS, V7, P76529, DOI 10.1109/ACCESS.2019.2921545
   Bhandari AK, 2014, EXPERT SYST APPL, V41, P3538, DOI 10.1016/j.eswa.2013.10.059
   Bohat VK, 2019, EXPERT SYST APPL, V117, P176, DOI 10.1016/j.eswa.2018.08.045
   Breve F, 2019, EXPERT SYST APPL, V123, P18, DOI 10.1016/j.eswa.2019.01.031
   Chen WH, 2014, OPT LASER ENG, V55, P69, DOI 10.1016/j.optlaseng.2013.10.025
   Díaz-Cortés MA, 2018, INFRARED PHYS TECHN, V93, P346, DOI 10.1016/j.infrared.2018.08.007
   Emberton S, 2018, COMPUT VIS IMAGE UND, V168, P145, DOI 10.1016/j.cviu.2017.08.003
   FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Gao H, 2018, COMPUT ELECTR ENG, V70, P931, DOI 10.1016/j.compeleceng.2017.12.037
   Gong WY, 2013, IEEE T CYBERNETICS, V43, P2066, DOI 10.1109/TCYB.2013.2239988
   He LF, 2017, NEUROCOMPUTING, V240, P152, DOI 10.1016/j.neucom.2017.02.040
   Hinojosa S, 2018, NEUROCOMPUTING, V321, P201, DOI 10.1016/j.neucom.2018.09.034
   Hou GJ, 2019, NEUROCOMPUTING, V369, P106, DOI 10.1016/j.neucom.2019.08.041
   Ayala HVH, 2015, EXPERT SYST APPL, V42, P2136, DOI 10.1016/j.eswa.2014.09.043
   Jia HM, 2019, IEEE ACCESS, V7, P44097, DOI 10.1109/ACCESS.2019.2908718
   Kannan SS, 2010, KNOWL-BASED SYST, V23, P580, DOI 10.1016/j.knosys.2010.03.016
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Lee SH, 2010, PATTERN RECOGN LETT, V31, P2325, DOI 10.1016/j.patrec.2010.07.004
   Li X, 2016, FUTURE GENER COMP SY, V65, P90, DOI 10.1016/j.future.2016.03.004
   Li YY, 2017, APPL SOFT COMPUT, V56, P345, DOI 10.1016/j.asoc.2017.03.018
   Liu X, 2020, IEEE T IND INFORM, V16, P5379, DOI 10.1109/TII.2019.2947435
   Liu X, 2019, IEEE INTERNET THINGS, V6, P5962, DOI 10.1109/JIOT.2018.2847731
   Lu ZY, 2019, J VIS COMMUN IMAGE R, V58, P269, DOI 10.1016/j.jvcir.2018.11.045
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mohamed AA, 2017, ELECTR POW SYST RES, V142, P190, DOI 10.1016/j.epsr.2016.09.025
   Ouadfel S, 2016, EXPERT SYST APPL, V55, P566, DOI 10.1016/j.eswa.2016.02.024
   Pare S, 2018, COMPUT ELECTR ENG, V70, P476, DOI 10.1016/j.compeleceng.2017.08.008
   Pare S, 2017, APPL SOFT COMPUT, V61, P570, DOI 10.1016/j.asoc.2017.08.039
   Sambandam RK, 2018, J KING SAUD UNIV-COM, V30, P449, DOI 10.1016/j.jksuci.2016.11.002
   Satapathy SC, 2018, NEURAL COMPUT APPL, V29, P1285, DOI 10.1007/s00521-016-2645-5
   Shen L, 2018, IEEE ACCESS, V6, P30508, DOI 10.1109/ACCESS.2018.2837062
   Sun GY, 2016, APPL SOFT COMPUT, V46, P703, DOI 10.1016/j.asoc.2016.01.054
   Tang N, 2018, NEUROCOMPUTING, V318, P261, DOI 10.1016/j.neucom.2018.08.064
   van den Heuvel MP, 2017, NEUROIMAGE, V152, P437, DOI 10.1016/j.neuroimage.2017.02.005
   Vasamsetti S, 2017, OCEAN ENG, V141, P88, DOI 10.1016/j.oceaneng.2017.06.012
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Xin-She Yang, 2012, Unconventional Computation and Natural Computation. Proceedings of the 11th International Conference, UCNC 2012, P240, DOI 10.1007/978-3-642-32894-7_27
   Yang XS, 2013, INT J BIO-INSPIR COM, V5, P141, DOI 10.1504/IJBIC.2013.055093
   Zheng YJ, 2015, COMPUT OPER RES, V55, P1, DOI 10.1016/j.cor.2014.10.008
   Zhou YQ, 2018, MULTIMED TOOLS APPL, V77, P23699, DOI 10.1007/s11042-018-5637-x
   Zhou YQ, 2016, NEUROCOMPUTING, V188, P294, DOI 10.1016/j.neucom.2015.01.110
NR 54
TC 17
Z9 19
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32415
EP 32448
DI 10.1007/s11042-020-09664-1
EA AUG 2020
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000564978000005
DA 2024-07-18
ER

PT J
AU Salman, O
   Elhajj, IH
   Kayssi, A
   Chehab, A
AF Salman, Ola
   Elhajj, Imad H.
   Kayssi, Ayman
   Chehab, Ali
TI Data representation for CNN based internet traffic classification: a
   comparative study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Internet of things; Traffic classification; Data
   representation
ID NEURAL-NETWORKS; IDENTIFICATION; SELECTION
AB It has been well established that the Internet of Things will bring an expansion in traffic volume and types. This will bring new challenges in terms of Quality of Service (QoS) and security, requiring innovative traffic management techniques. Traffic classification is a main network function that helps in managing both QoS and security. Different machine learning based methods have been applied for this aim. However, traditional machine learning methods rely on hand crafted features, limiting the model ability to learn. Deep Learning (DL), a branch of machine learning, is characterized by its representation learning ability. In this paper, we analyse two methods of data representation for DL-based classification: a raw packet-based representation and a quasi-raw flow-based representation. Different tests are performed to evaluate the robustness of these data representation methods. The tests include features' importance, model robustness, and anonymization tests. The results show that raw data representation suffers from traffic anonymization and the fact that many packet fields are data-dependent. On the other hand, the flow-based representation is sensitive to the number of packets used for classification and to traffic obfuscation.
C1 [Salman, Ola; Elhajj, Imad H.; Kayssi, Ayman; Chehab, Ali] Amer Univ Beirut, Beirut 11072020, Lebanon.
C3 American University of Beirut
RP Salman, O (corresponding author), Amer Univ Beirut, Beirut 11072020, Lebanon.
EM oms15@mail.aub.edu; ie05@mail.aub.edu; ayman@mail.aub.edu;
   chehab@mail.aub.edu
RI Hajj, Ihab I. El/AAR-4490-2021
OI salman, ola/0000-0002-1011-8665; Chehab, Ali/0000-0002-1939-2740;
   Elhajj, Imad/0000-0002-6461-4699
FU AUB University Research Board; Lebanese National Council for Scientific
   Research; TELUS Corp., Canada
FX Research funded by the AUB University Research Board, the Lebanese
   National Council for Scientific Research, and TELUS Corp., Canada.
CR ACAR A, 2018, ARXIV180802741
   Aceto G, 2019, IEEE T NETW SERV MAN, V16, P445, DOI 10.1109/TNSM.2019.2899085
   Al Khater Noora, 2015, 2015 Tenth International Conference on Digital Information Management (ICDIM). Proceedings, P43, DOI 10.1109/ICDIM.2015.7381869
   Alizadeh H, 2016, SECUR COMMUN NETW, V9, P2557, DOI 10.1002/sec.1516
   Aureli D, 2020, IEEE IFIP NETW OPER, DOI 10.1109/noms47738.2020.9110430
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Biersack Ernst., 2013, Data traffic monitoring and analysis: from measurement, classification, and anomaly detection to quality of experience, V7754
   Cao J, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.287
   Chen ZY, 2016, IEEE TRUST, P301, DOI [10.1109/TrustCom.2016.0077, 10.1109/TrustCom.2016.76]
   Chen ZT, 2017, IEEE INT CONF BIG DA, P1271, DOI 10.1109/BigData.2017.8258054
   Chung JC, 2011, P 13 AS PAC NETW OP, V6, P1
   Conti M, 2016, IEEE T INF FOREN SEC, V11, P114, DOI 10.1109/TIFS.2015.2478741
   Dai SF, 2013, IEEE INFOCOM SER, P809
   Dainotti A, 2011, GLOB TELECOMM CONF
   Dainotti A, 2012, IEEE NETWORK, V26, P35, DOI 10.1109/MNET.2012.6135854
   Este A, 2009, COMPUT NETW, V53, P2476, DOI 10.1016/j.comnet.2009.05.003
   Fadlullah ZM, 2017, IEEE COMMUN SURV TUT, V19, P2432, DOI 10.1109/COMST.2017.2707140
   FILIPOSKA S, 2013, T NETWORKS COMMUNICA, V1, P14
   Fu YJ, 2016, IEEE T MOBILE COMPUT, V15, P2851, DOI 10.1109/TMC.2016.2516020
   GONZALEZ R, 2017, ARXIV170503881
   GOO YH, 2016, 2016 18 AS PAC NETW, P1, DOI DOI 10.1109/NOMS.2012.6212042
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   HAFFNER P., 2005, MINENET 05, P197, DOI DOI 10.1145/1080173.1080183
   Hu Y, 2008, INT WORKSH QUAL SERV, P239
   Huang H, 2018, INT J EMERG TECHNOL, V13, P4, DOI 10.3991/ijet.v13i04.8466
   HUR M, 2012, 2012 14 AS PAC NETW, P1
   Jaiganesh V., 2013, Intrusion Detection Systems: A Survey and Analysis of Classification Techniques, V2, P1629
   Karagiannis T, 2005, ACM SIGCOMM COMP COM, V35, P229, DOI 10.1145/1090191.1080119
   Karagiannis T, 2007, LECT NOTES COMPUT SC, V4427, P186
   Lee S, 2011, TRANSPORTMETRICA, V7, P443, DOI [10.1080/18128602.2010.498004, 10.1109/PLASMA.2011.5993279]
   Leroux S, 2018, IEEE IFIP NETW OPER
   Li ZP, 2017, LECT NOTES COMPUT SC, V10638, P858, DOI 10.1007/978-3-319-70139-4_87
   Liu Y, 2018, COMPLEXITY, DOI 10.1155/2018/5345241
   Liu Z, 2019, J NETW COMPUT APPL, V125, P190, DOI 10.1016/j.jnca.2018.10.018
   Lopez-Martin M, 2017, IEEE ACCESS, V5, P18042, DOI 10.1109/ACCESS.2017.2747560
   Lotfollahi M, 2020, SOFT COMPUT, V24, P1999, DOI 10.1007/s00500-019-04030-2
   Maier G, 2010, LECT NOTES COMPUT SC, V6032, P161, DOI 10.1007/978-3-642-12334-4_17
   Marnerides AK, 2014, COMPUT NETW, V73, P224, DOI 10.1016/j.comnet.2014.08.007
   Meiss M, 2011, ACM T INTERNET TECHN, V10, DOI 10.1145/1944339.1944342
   MICHAEL AKJ, 2017, TECHNICAL REPORT
   MITEVSKI B, 2013, INT C ICT INN, P291
   Mongkolluksamee S, 2015, P INT COMP SOFTW APP, P336, DOI 10.1109/COMPSAC.2015.50
   Mongkolluksamee Sophon., 2016, Journal of Information Processing, V24, P247
   Moore A., 2013, Discriminators for Use in Flowbased Classification
   Moore AW, 2005, LECT NOTES COMPUT SC, V3431, P41, DOI 10.1007/978-3-540-31966-5_4
   Murgia A, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP), P86
   Nowak J, 2018, LECT NOTES ARTIF INT, V10842, P734, DOI 10.1007/978-3-319-91262-2_64
   Okabe T, 2006, VOIP MASE 06: 1ST IEEE WORKSHOP ON VOIP MANAGEMENT AND SECURITY, P35
   Pacheco F, 2019, IEEE COMMUN SURV TUT, V21, P1988, DOI 10.1109/COMST.2018.2883147
   PARCHEKANI A, 2020, ARXIV200103665
   Qiang Xu, 2014, ACM SIGMETRICS Performance Evaluation Review, V42, P569
   Salman O, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.3743
   Salman O, 2020, ANN TELECOMMUN, V75, P673, DOI 10.1007/s12243-020-00770-7
   Salman O, 2018, INT CONF NETW FUT, P68, DOI 10.1109/NOF.2018.8598055
   Schmidt B, 2017, APPL SOFT COMPUT, V54, P1, DOI 10.1016/j.asoc.2017.01.016
   Shi HT, 2018, COMPUT NETW, V132, P81, DOI 10.1016/j.comnet.2018.01.007
   Tahaei H, 2020, J NETW COMPUT APPL, V154, DOI 10.1016/j.jnca.2020.102538
   Tongaonkar A., 2012, LEET
   Wang W, 2018, IEEE ACCESS, V6, P1792, DOI 10.1109/ACCESS.2017.2780250
   Wang W, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS (ISI), P43, DOI 10.1109/ISI.2017.8004872
   Wang W, 2017, 2017 31ST INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P712, DOI 10.1109/ICOIN.2017.7899588
   Wang Zhanyi., 2015, The applications of deep learning on traffic identification, P24
   Xu Q, 2015, IEEE INFOCOM SER
   Yu K, 2018, IEEE ACCESS, V6, P37568, DOI 10.1109/ACCESS.2018.2852008
   Zhang CY, 2019, IEEE COMMUN SURV TUT, V21, P2224, DOI 10.1109/COMST.2019.2904897
   Zhang J, 2015, IEEE ACM T NETWORK, V23, P1257, DOI 10.1109/TNET.2014.2320577
   Zhang Z, 2014, IEEE J SEL AREA COMM, V32, P1894, DOI 10.1109/JSAC.2014.2358857
NR 67
TC 10
Z9 10
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16951
EP 16977
DI 10.1007/s11042-020-09459-4
EA AUG 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000560998800006
DA 2024-07-18
ER

PT J
AU Ashiba, HI
   Abd El-Samie, FE
AF Ashiba, H. I.
   Abd El-Samie, F. E.
TI Implementation face based cancelable multi-biometric system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Cancelable biometric templates; Homomorphic approach;
   Template protection; SURF
ID SECURE; FUSION
AB This paper suggests novel two proposed cancellable biometric realization techniques recognition and template protection. In this paper, the Homomorphic Key (HK) encoding algorithm is utilized for cancelable face system. In the first suggested scheme, the HK algorithm is applied on the face images. The resultant map is encrypted, in order to the second HK utilized in the HK is produced from the image. This approach can be used to develop a frequency domain procedure for making this system for biometric template protection. The second algorithm presents a new approach to detect the features of face images depending the Speeded Up Robust Features (SURF) and Optimum Global Thresholding (OTSU) method. This algorithm is relied on scale space analysis with the number of SURF feature points as the key parameters for classification. Simulation results using evaluation metrics False Positive Rate (FPR), False Negative Rate (FNR), Equal Error Rate (EER), Receiver Operating Characteristic (ROC) and Area under ROC (AROC) prove that the first proposed cancelable biometric technique with the second key are best with comparing the other keys. The obtained results clear that the second suggested technique has sucesseded in detection the features of the skin, eyes, nose, hair, ears images and the face positions.
C1 [Ashiba, H. I.] Bilbis Higher Inst Engn, Dept Elect & Elect Commun, Bilbis, Sharqia, Egypt.
   [Abd El-Samie, F. E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Engn, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP Ashiba, HI (corresponding author), Bilbis Higher Inst Engn, Dept Elect & Elect Commun, Bilbis, Sharqia, Egypt.
EM eng_h_2006@yahoo.com
RI Sayed, Fathi/HRA-4752-2023; ashiba, huda/GQI-4310-2022
OI Sayed, Fathi/0000-0001-8749-9518; ashiba, huda/0000-0002-4926-8919
CR Akdogan D, 2018, COMPUT NETW, V142, P33, DOI 10.1016/j.comnet.2018.06.001
   Ashiba HI, 2019, MULTIMED TOOLS APPL, V78, P11277, DOI 10.1007/s11042-018-6545-9
   Ashiba H. I., 2008, Progress In Electromagnetics Research C, V1, P123, DOI 10.2528/PIERC08012301
   Barra S, 2019, FUTURE GENER COMP SY, V101, P534, DOI 10.1016/j.future.2019.06.019
   Ben Tarif E, 2018, MULTIMED TOOLS APPL, V77, P2485, DOI 10.1007/s11042-016-4280-7
   Canuto AMP, 2013, EXPERT SYST APPL, V40, P1971, DOI 10.1016/j.eswa.2012.10.002
   Das S, 2019, PATTERN RECOGN LETT, V126, P102, DOI 10.1016/j.patrec.2018.06.026
   Deepa S, 2013, J AUTOMAT ARTIF INTE, V1
   Deramgozin MM, 2016, 1 INT C NEW RES ACH
   Dwivedi A, 2011, INT J COMPUT APPL, V21
   Dwivedi R, 2019, PATTERN RECOGN LETT, V126, P58, DOI 10.1016/j.patrec.2018.04.022
   Fu J., 2013, COMMUN COMPUT PHYS, V320, P203
   Gaddam S. V. K., 2010, INT J NETW SECURITY, V11, P57
   Ghammam L, 2018, HAL01862157
   Kumar P, 2011, APPL OPTICS, V50, P1805, DOI 10.1364/AO.50.001805
   Murakami T, 2019, PATTERN RECOGN LETT, V126, P11, DOI 10.1016/j.patrec.2018.04.005
   Qiu J, 2018, IOP CONF SER-MAT SCI, V322, DOI 10.1088/1757-899X/322/5/052050
   Rathgeb C, 2014, COMPUT SECUR, V42, P1, DOI 10.1016/j.cose.2013.12.005
   Sreekumar S., 2016, PROC IEEE INT C COMP, P1
   Dang TK, 2016, IET BIOMETRICS, V5, P229, DOI 10.1049/iet-bmt.2015.0029
   Yang WC, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11020141
   Yang WC, 2018, PATTERN RECOGN, V78, P242, DOI 10.1016/j.patcog.2018.01.026
   Zhou K, 2018, IEEE T INF FOREN SEC, V13, P3050, DOI 10.1109/TIFS.2018.2838540
NR 23
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30813
EP 30838
DI 10.1007/s11042-020-09529-7
EA AUG 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560297300004
DA 2024-07-18
ER

PT J
AU Ali, SG
   Chen, Y
   Sheng, B
   Li, HT
   Wu, Q
   Yang, P
   Muhammad, K
   Yang, G
AF Ali, Saba Ghazanfar
   Chen, Yan
   Sheng, Bin
   Li, Huating
   Wu, Qiang
   Yang, Po
   Muhammad, Khan
   Yang, Geng
TI Cost-effective broad learning-based ultrasound biomicroscopy with 3D
   reconstruction for ocular anterior segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical data analytics; Machine learning; Broad learning system; 3D
   reconstruction; Ultrasound biomicroscopy; Iridocorneal angle of anterior
   chamber
ID FEATURE-DETECTORS; DESCRIPTORS
AB Anterior Chamber Angle (ACA) assessment plays an important role for the diagnosis of glaucoma. Most of the existing techniques relied on Anterior Segment Optical Coherence Tomography (AS-OCT) or Swept Source Optical Coherence Tomography (SS-OCT). We proposed a system for 360 degrees overview of iridocorneal angle of anterior chamber (ICAAC) via Ultrasound Biomicroscopy (UBM). UBM approach acquires the visualization of anterior segment components as well as diseased structures (glaucoma). Our system consists of a new pairing scheme of feature descriptors, i.e. (FREAK, BRISK), (SURF, BRISK) and Broad Learning System (BLS) for 3D reconstruction and segmentation of ICAAC. The 360 degrees overview of 2D ICAAC gives global conception for ACA assessment. 3D images provide a detailed assessment with the amount of opposition's and synechiae in angle-closure suspects, angle-closure and angle-closure glaucoma in bright light conditions. Extensive evaluations are performed on dataset consists of 650 ICAAC images in five directions of 65 subjects with 10 samples per subject (5 left eye and 5 right eye) from Shanghai Sixth People's Hospital. Experiments showed that our approach achieves an overall accuracy of 98.72% with training and testing time 29.26(s), 1.232(s) respectively.
C1 [Ali, Saba Ghazanfar; Sheng, Bin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
   [Chen, Yan; Li, Huating; Wu, Qiang] Shanghai Jiao Tong Univ Affiliated Peoples Hosp 6, Shanghai 200233, Peoples R China.
   [Yang, Po] Univ Sheffield, Dept Comp Sci, Sheffield, S Yorkshire, England.
   [Muhammad, Khan] Sejong Univ, Dept Software, Seoul 143747, South Korea.
   [Yang, Geng] Zhejiang Univ ZJU, Dept Mech Engn, Hangzhou, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University; University
   of Sheffield; Sejong University; Zhejiang University
RP Sheng, B (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.; Wu, Q (corresponding author), Shanghai Jiao Tong Univ Affiliated Peoples Hosp 6, Shanghai 200233, Peoples R China.; Muhammad, K (corresponding author), Sejong Univ, Dept Software, Seoul 143747, South Korea.
EM shengbin@sjtu.edu.cn; qiang.wu@shsmu.edu.cn; khan.muhammad.icp@gmail.com
RI Yang, Po/C-9936-2011; Ali, saba ghazanfar/ABD-4223-2020; Muhammad,
   Khan/L-9059-2016; Khan, Muhammad/IXN-8470-2023
OI Yang, Po/0000-0002-8553-7127; Muhammad, Khan/0000-0003-4055-7412;
   Muhammad, Khan/0000-0002-5302-1150
FU National Natural Science Foundation of China [61872241, 61572316];
   Science and Technology Commission of Shanghai Municipality [18410750700,
   17411952600, 16DZ0501100]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61872241 and Grant 61572316, in part by
   the Science and Technology Commission of Shanghai Municipality under
   Grant 18410750700, Grant 17411952600, and Grant 16DZ0501100.
CR Cao WM, 2018, IEEE ACCESS, V6, P21164, DOI 10.1109/ACCESS.2018.2818403
   Chanatittarat C, 2018, INT J TECHNOL ASSESS, V34, P584, DOI 10.1017/S0266462318003604
   Chen CLP, 2018, IEEE T NEUR NET LEAR, V29, P10, DOI 10.1109/TNNLS.2017.2716952
   Chen CLP, 2017, 2017 32ND YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P1271, DOI 10.1109/YAC.2017.7967609
   Chen XK, 2017, PROCEEDINGS OF 2017 IEEE 2ND INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC), P1091, DOI 10.1109/ITNEC.2017.8284908
   Cízek P, 2018, IEEE T IND INFORM, V14, P1155, DOI 10.1109/TII.2017.2764485
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P2493, DOI 10.1109/TMI.2018.2837012
   Fu HZ, 2019, AM J OPHTHALMOL, V203, P37, DOI 10.1016/j.ajo.2019.02.028
   Fu HZ, 2017, IEEE T MED IMAGING, V36, P1930, DOI 10.1109/TMI.2017.2703147
   Georgakis G, 2018, PROC CVPR IEEE, P1965, DOI 10.1109/CVPR.2018.00210
   Gomez CH, 2015, LECT NOTES COMPUT SC, V9163, P14, DOI 10.1007/978-3-319-20904-3_2
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Hoang VT, 2018, IEEE T IND INFORM, P1
   Huang K, 2020, LECT NOTES COMPUT SC, V11962, P161, DOI 10.1007/978-3-030-37734-2_14
   Huang QH, 2019, IEEE T IND INFORM, V15, P1173, DOI 10.1109/TII.2018.2871864
   Kondapalli H, 2018, IEEE T BIO-MED ENG, V65, P149, DOI 10.1109/TBME.2017.2697998
   Kumawat Anchal, 2018, Procedia Computer Science, V132, P277, DOI 10.1016/j.procs.2018.05.176
   Labati RD, 2019, IEEE T IND INFORM, V15, P1251, DOI 10.1109/TII.2018.2856466
   Li P, 2018, IEEE T IND INFORM, V14, P790, DOI 10.1109/TII.2017.2739340
   Liu H, 2019, MULTIMED TOOLS APPL, V78, P9033, DOI 10.1007/s11042-017-5277-6
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Ma YY, 2018, INTERVIROLOGY, V61, P237, DOI 10.1159/000495179
   Maheshwari S, 2017, IEEE J BIOMED HEALTH, V21, P803, DOI 10.1109/JBHI.2016.2544961
   Mak H, 2013, OPHTHALMOLOGY, V120, P2517, DOI 10.1016/j.ophtha.2013.05.009
   Malekabadi AJ, 2018, SCI HORTIC-AMSTERDAM, V228, P187, DOI 10.1016/j.scienta.2017.10.030
   McKee H, 2013, J GLAUCOMA, V22, P468, DOI 10.1097/IJG.0b013e31824485fa
   Mendes O. L. C., 2020, AIS, V1, P163
   Mo SY, 2020, LECT NOTES COMPUT SC, V11961, P278, DOI 10.1007/978-3-030-37731-1_23
   Mouats T, 2018, J INTELL ROBOT SYST, V92, P33, DOI 10.1007/s10846-017-0762-8
   Nguyen AT, 2016, J OPHTHALMOL, V2016, DOI 10.1155/2016/3062381
   Pan CY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P2499, DOI 10.1109/ICInfA.2015.7279706
   Porporato N, 2019, AM J OPHTHALMOL, V199, P133, DOI 10.1016/j.ajo.2018.11.015
   Qiao YC, 2016, IEEE T MED IMAGING, V35, P391, DOI 10.1109/TMI.2015.2476354
   Raluca Moisescu, 2015, Rom J Ophthalmol, V59, P208
   Rojas-Flores Jorge, 2018, Izquierdas (Santiago), P1
   Sait ARW, 2019, HDB MULTIMEDIA INFOR, P3
   Tanveer M., 2019, Machine Intelligence and Signal Analysis, V748
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Thirunavukkarasu V, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER APPLICATIONS (ICACA), P279, DOI 10.1109/ICACA.2016.7887966
   Wang XY, 2017, IEEE T MED IMAGING, V36, P1922, DOI 10.1109/TMI.2017.2699973
   Wang YX, 2019, IEEE T IND INFORM, V15, P105, DOI 10.1109/TII.2018.2810226
   Wu XL, 2015, IEEE T MED IMAGING, V34, P861, DOI 10.1109/TMI.2014.2360988
   Xiaobo Wang, 2017, 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P1, DOI 10.1109/CVPR.2017.8
   Xu BY, 2019, TRANSL VIS SCI TECHN, V8, DOI 10.1167/tvst.8.2.5
   Yang G, 2020, FUTURE GENER COMP SY, V107, P215, DOI 10.1016/j.future.2020.02.005
   Yang WC, 2019, IEEE T IND INFORM, V15, P4244, DOI 10.1109/TII.2019.2900665
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Zhou GH, 2017, 2017 9TH INTERNATIONAL CONFERENCE ON ADVANCED INFOCOMM TECHNOLOGY (ICAIT 2017), P387, DOI 10.1109/ICAIT.2017.8388951
NR 48
TC 15
Z9 15
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35105
EP 35122
DI 10.1007/s11042-020-09303-9
EA AUG 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000559640400008
DA 2024-07-18
ER

PT J
AU Li, Y
   Li, ZJ
   Ma, ML
   Wang, MJ
AF Li, Ying
   Li, Zhijun
   Ma, Minglin
   Wang, Mengjiao
TI Generation of grid multi-wing chaotic attractors and its application in
   video secure communication system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-wing chaotic system; Random number generator; Video secure
   communication; FPGA
ID ALGORITHM; MAP
AB In order to study the application of chaos in video image encryption, a real-time video secure communication system based on a new grid multi-wing chaotic system is proposed in this paper. First, by introducing sawtooth wave functions to the Lorenz system, a new grid multi-wing butterfly chaotic system with complicated dynamical behaviors is obtained. Compared with the existing multi-scroll and multi-wing chaotic systems, The system structure is simple and more easier to be implemented in a digital system. Then, a chaos-based pseudorandom random number generator is developed by implementing post-processing procedure. The present video secure communication system is designed with the closed-loop feedback scheme. The corresponding hardware implementation is developed by FPGA platforms, and the experimental results are given to verify its feasibility. Furthermore, a series of widely used secure analyses are applied to prove that the system has good security performance.
C1 [Li, Ying; Li, Zhijun; Ma, Minglin; Wang, Mengjiao] Xiangtan Univ, Coll Informat Engn, Xiangtan 411105, Hunan, Peoples R China.
C3 Xiangtan University
RP Li, ZJ (corresponding author), Xiangtan Univ, Coll Informat Engn, Xiangtan 411105, Hunan, Peoples R China.
EM lizhijun@xtu.edu.cn
RI ma, minglin/J-6627-2012; Li, Zhijun/O-1247-2016
OI ma, minglin/0000-0003-4599-8479; 
FU National Natural Science Foundation of China [61471310]; Natural Science
   Foundation of Hunan Province, China [2015JJ2142]
FX The author would like to thank the reviewers and the editor for their
   invaluable comments on the manuscript of this paper. This work was
   supported by the National Natural Science Foundation of China [grant
   number 61471310] and the Natural Science Foundation of Hunan Province,
   China [grant number 2015JJ2142].
CR Ahmad J, 2018, COMPUT SCI ELECTR, P208, DOI 10.1109/CEEC.2018.8674208
   Ahmad J, 2018, PROCEEDINGS OF 2018 IEEE 17TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC 2018), P524, DOI 10.1109/ICCI-CC.2018.8482047
   Ahmad J, 2018, NEURAL COMPUT APPL, V30, P3847, DOI 10.1007/s00521-017-2970-3
   Ahmed F, 2010, ASSETS 2010: PROCEEDINGS OF THE 12TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P235
   Bassham L. E., 2010, SPECIAL PUBLICATION
   Ben Slimane N, 2017, NONLINEAR DYNAM, V88, P1655, DOI 10.1007/s11071-017-3337-0
   Bouallegue K, 2011, CHAOS SOLITON FRACT, V44, P79, DOI 10.1016/j.chaos.2010.12.005
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02066-z
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Chowdhury K, 2019, MULTIMED TOOLS APPL, V78, P18617, DOI 10.1007/s11042-018-7100-4
   Pano-Azucena AD, 2017, NONLINEAR DYNAM, V87, P2203, DOI 10.1007/s11071-016-3184-4
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Gan QY, 2017, INT J CIRC THEOR APP, V45, P1849, DOI 10.1002/cta.2300
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Huang Y, 2015, IEEE T CIRCUITS-II, V62, P496, DOI 10.1109/TCSII.2014.2385274
   Hussain I, 2012, NONLINEAR DYNAM, V70, P181, DOI 10.1007/s11071-012-0440-0
   Karnatak R, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.035201
   Khan FA, 2017, J INTELL FUZZY SYST, V33, P3753, DOI 10.3233/JIFS-17656
   Lai Q, 2013, INT J BIFURCAT CHAOS, V23, DOI 10.1142/S0218127413501526
   Li CQ, 2019, IEEE T CIRCUITS-I, V66, P2322, DOI 10.1109/TCSI.2018.2888688
   Li CQ, 2018, IEEE MULTIMEDIA, V25, P46, DOI 10.1109/MMUL.2018.2873472
   Liao ZF, 2019, IEEE ACCESS, V7, P26411, DOI 10.1109/ACCESS.2019.2901742
   Lin ZS, 2018, NONLINEAR DYNAM, V94, P1003, DOI 10.1007/s11071-018-4406-8
   Lin ZS, 2015, IEEE T CIRC SYST VID, V25, P1203, DOI 10.1109/TCSVT.2014.2369711
   Lu X, 2019, CVPR19
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Neelima N, 2019, MULTIMED TOOLS APPL, V78, P31057, DOI 10.1007/s11042-019-07907-4
   Palazzi MJ, 2014, EUR PHYS J-SPEC TOP, V223, P2831, DOI 10.1140/epjst/e2014-02296-5
   Tlelo-Cuautle E, 2015, COMMUN NONLINEAR SCI, V27, P66, DOI 10.1016/j.cnsns.2015.03.003
   Wang Wenguan, 2019, CVPR19
   Wu HG, 2011, ACTA PHYS SIN-CH ED, V60, DOI 10.7498/aps.60.090502
   Yu SM, 2011, IEEE T CIRCUITS-II, V58, P314, DOI 10.1109/TCSII.2011.2149090
   Zhang JM, 2019, IEEE ACCESS, V7, P83873, DOI 10.1109/ACCESS.2019.2924944
   Zhang LL, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/6/064209
   Zhang S, 2018, J COMPUT NONLIN DYN, V13, DOI 10.1115/1.4039980
   Zhang S, 2018, CHINESE J PHYS, V56, P793, DOI 10.1016/j.cjph.2018.03.002
   Zhang S, 2018, PRAMANA-J PHYS, V90, DOI 10.1007/s12043-018-1556-7
   Zhang S, 2018, CHAOS, V28, DOI 10.1063/1.5006214
   Zhiben Z, 2020, J PHYS, V69, P50
NR 43
TC 33
Z9 33
U1 4
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29161
EP 29177
DI 10.1007/s11042-020-09448-7
EA AUG 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000557123500004
DA 2024-07-18
ER

PT J
AU Sharma, R
   Rani, S
   Memon, I
AF Sharma, Richa
   Rani, Shalli
   Memon, Imran
TI A smart approach for fire prediction under uncertain conditions using
   machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Forest fires; IoT; Boosted decision trees; Machine learning; Predictive
   systems; Smart environment
ID FOREST-FIRE; NEURAL-NETWORKS; DESIGN
AB One of the most ubiquitous cause of worldwide deforestation and devastation of wildlife is fire. To control fire and reach the forest area in time is not always possible. Consequently, the level of destruction is often high. Therefore, predicting fires well in time and taking immediate action is of utmost importance. However, traditional fire prediction approaches often fail to detect fire in time. Therefore, a more reliable approach like the Internet of Things (IoT) needs to be adopted. IoT sensors can not only observe the real-time conditions of an area, but it can also predict fire when combined with Machine learning. This paper provides an insight into the use of Machine Learning models towards the occurrence of forest fires. In this context, eight Machine Learning algorithms: Boosted Decision Trees, Decision Forest Classifier, Decision Jungle Classifier, Averaged Perceptron, 2-Class Bayes Point Machine, Local Deep Support Vector Machine (SVM), Logistic Regression and Binary Neural Network model have been implemented. Results suggest that the Boosted decision tree model with the Area Under Curve (AUC) value of 0.78 is the most suitable candidate for a fire prediction model. Based on the results, we propose a novel IoT-based smart Fire prediction system that would consider both meteorological data and images for early fire prediction.
C1 [Sharma, Richa; Rani, Shalli] Chitkara Univ, Chitkara Univ Inst Engn & Technol, Rajpura, Punjab, India.
   [Memon, Imran] Bahria Univ, Dept Comp Sci, Karachi Campus, Sindh, Pakistan.
C3 Chitkara University, Punjab
RP Rani, S (corresponding author), Chitkara Univ, Chitkara Univ Inst Engn & Technol, Rajpura, Punjab, India.
EM richa.sharma@chitkara.edu.in; shalli.rani@chitkara.edu.in;
   imranmemon.bukc@bahria.edu.pk
RI Rani, Shalli/AGY-9513-2022
OI Rani, Shalli/0000-0002-8474-9435; SHARMA, RICHA/0000-0002-5391-8195
CR Alkhatib AAA, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/597368
   Allison RS, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081310
   Amatulli G, 2007, ECOL MODEL, V200, P321, DOI 10.1016/j.ecolmodel.2006.08.001
   [Anonymous], 2007, DATA MINING APPROACH
   Bogue R, 2013, SENSOR REV, V33, P99, DOI 10.1108/02602281311299635
   Castelli M, 2015, FIRE ECOL, V11, P106, DOI 10.4996/fireecology.1101106
   Denham M, 2012, J COMPUT SCI-NETH, V3, P398, DOI 10.1016/j.jocs.2012.06.002
   Herutomo A, 2015, 2015 3rd International Conference on Information and Communication Technology (ICoICT), P87, DOI 10.1109/ICoICT.2015.7231402
   Imteaj A, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND COMMUNICATION ENGINEERING (ECCE), P899, DOI 10.1109/ECACE.2017.7913031
   Kansal A, 2015, 2015 THIRD INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P241, DOI 10.1109/ICIIP.2015.7414773
   Lazarescu MT, 2013, IEEE J EM SEL TOP C, V3, P45, DOI 10.1109/JETCAS.2013.2243032
   Lee BS, 1996, APPL NEURAL NETWORK
   Li Z, 2000, INT J REMOTE SENS, V21, P3057, DOI 10.1080/01431160050144956
   Martinez-de Dios J. R., 2005, IFAC P, V38, P660, DOI [https://doi.org/10.3182/20050703-6-CZ-1902.01380, DOI 10.3182/20050703-6-CZ-1902.01380]
   May A, 2014, FIRE SAFETY J, V63, P79, DOI 10.1016/j.firesaf.2013.11.007
   Molina-Pico A, 2016, J SENSORS, V2016, DOI 10.1155/2016/8325845
   Morse T, 2017, SAE TECHNICAL PAPER
   Muhammad K, 2018, IEEE ACCESS, V6, P18174, DOI 10.1109/ACCESS.2018.2812835
   Nie WZ, 2019, IEEE ACCESS, V7, P132161, DOI 10.1109/ACCESS.2019.2940281
   Oliveira S, 2012, FOREST ECOL MANAG, V275, P117, DOI 10.1016/j.foreco.2012.03.003
   Pourtaghi ZS, 2016, ECOL INDIC, V64, P72, DOI 10.1016/j.ecolind.2015.12.030
   Qu Z., 2009, 2009 INT WORKSHOP IN, P1, DOI [10.1109/IWISA.2009.5073121, DOI 10.1109/IWISA.2009.5073121]
   Roe BP, 2005, NUCL INSTRUM METH A, V543, P577, DOI 10.1016/j.nima.2004.12.018
   Sakr G. E., 2010, 2010 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM 2010), P1311, DOI 10.1109/AIM.2010.5695809
   Sun XL, 2017, IEEE SYS MAN CYBERN, P1001, DOI 10.1109/SMC.2017.8122741
   Taylor SW, 2013, STAT SCI, V28, P586, DOI 10.1214/13-STS451
   Woodruff K, 2017, INTRO BOOSTED DECISI
   Yuan C, 2015, CAN J FOREST RES, V45, P783, DOI 10.1139/cjfr-2014-0347
   Zhang J., 2008, FRONTIERS CHINA, V3, P369, DOI [10.1007/s11461-008-0054-3.24N.U., DOI 10.1007/S11461-008-0054-3.24N.U]
   Zhang YC, 2013, PROCEDIA ENGINEER, V52, P314, DOI 10.1016/j.proeng.2013.02.146
NR 30
TC 22
Z9 24
U1 1
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 28155
EP 28168
DI 10.1007/s11042-020-09347-x
EA AUG 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000554436800007
DA 2024-07-18
ER

PT J
AU Bhandari, B
   Alsadoon, A
   Prasad, PWC
   Abdullah, S
   Haddad, S
AF Bhandari, Bishal
   Alsadoon, Abeer
   Prasad, P. W. C.
   Abdullah, Salma
   Haddad, Sami
TI Deep learning neural network for texture feature extraction in oral
   cancer: enhanced loss function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Convolutional neural network (CNN); Oral tumor; Loss
   function; Region of interest (ROI)
ID CLASSIFICATION; PREDICTION; IDENTIFICATION; HEAD
AB The use of a binary classifier like the sigmoid function and loss functions reduces the accuracy of deep learning algorithms. This research aims to increase the accuracy of detecting and classifying oral tumours within a reduced processing time. The proposed system consists of a Convolutional neural network with a modified loss function to minimise the error in predicting and classifying oral tumours by reducing the overfitting of the data and supporting multi-class classification. The proposed solution was tested on data samples from multiple datasets with four kinds of oral tumours. The averages of the different accuracy values and processing times were calculated to derive the overall accuracy. Based on the obtained results, the proposed solution achieved an overall accuracy of 96.5%, which was almost 2.0% higher than the state-of-the-art solution with 94.5% accuracy. Similarly, the processing time has been reduced by 30-40 milliseconds against the state-of-the-art solution. The proposed system is focused on detecting oral tumours in the given magnetic resonance imaging (MRI) scan and classifying whether the tumours are benign or malignant. This study solves the issue of over fitting data during the training of neural networks and provides a method for multi-class classification.
C1 [Bhandari, Bishal; Alsadoon, Abeer; Prasad, P. W. C.] Charles Sturt Univ, Sch Comp & Math, Sydney Campus, Sydney, NSW, Australia.
   [Abdullah, Salma] Univ Technol Baghdad, Dept Comp Engn, Baghdad, Iraq.
   [Haddad, Sami] Greater Western Sydney Area Hlth Serv, Dept Oral & Maxillofacial Serv, Mt Druitt, Australia.
   [Haddad, Sami] Cent Coast Area Hlth, Dept Oral & Maxillofacial Serv, Gosford, Australia.
C3 Charles Sturt University; University of Technology- Iraq; Florey
   Institute of Neuroscience & Mental Health
RP Alsadoon, A (corresponding author), Charles Sturt Univ, Sch Comp & Math, Sydney Campus, Sydney, NSW, Australia.
EM aalsadoon@studygroup.com
RI Abdullah, Salma Hameedi/GRJ-1117-2022; Alsadoon, A/Prof.
   Abeer/AAU-1532-2021
OI Abdullah, Salma Hameedi/0000-0003-2087-0153; Alsadoon, A/Prof.
   Abeer/0000-0002-2309-3540; withana, chandana/0000-0002-3007-687X
CR Al-Ma'aitah M, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1052-0
   Alsmadi MK, 2018, AIN SHAMS ENG J, V9, P697, DOI 10.1016/j.asej.2016.03.016
   Anders S, 2010, GENOME BIOL, V11, DOI 10.1186/gb-2010-11-10-r106
   [Anonymous], 2018, HLTH BIOL DATA
   Anter AM, 2018, ARTIF INTELL MED, P1
   Aubreville M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12320-8
   Bur AM, 2019, ORAL ONCOL, V92, P20, DOI 10.1016/j.oraloncology.2019.03.011
   Das DK, 2018, TISSUE CELL, V53, P111, DOI 10.1016/j.tice.2018.06.004
   Das DK, 2015, TISSUE CELL, V47, P349, DOI 10.1016/j.tice.2015.04.009
   De Silva DA, 2018, IMPLEMENT SCI, V13, DOI 10.1186/s13012-017-0702-9
   Hahoek M, 2019, J BIOMED OPT, V24, DOI 10.1117/1.JBO.24.3.036007
   Halicek M, 2017, J BIOMED OPT, V22, DOI 10.1117/1.JBO.22.6.060503
   Jain DK, 2018, J COMPUT SCI-NETH, V25, P252, DOI 10.1016/j.jocs.2017.07.016
   Jeyaraj P, 2019, J CANCER RES CLIN, V145, P1
   Li HL, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25005-7
   Li HL, 2017, IEEE ACCESS, V5, P13665, DOI 10.1109/ACCESS.2017.2729943
   Liang SJ, 2019, EUR RADIOL, V29, P1961, DOI 10.1007/s00330-018-5748-9
   Lu GL, 2014, J BIOMED OPT, V19, DOI 10.1117/1.JBO.19.1.010901
   Mohammed MA, 2017, J COMPUT SCI-NETH, V21, P283, DOI 10.1016/j.jocs.2017.03.021
   Obermeyer Z, 2016, NEW ENGL J MED, V375, P1216, DOI 10.1056/NEJMp1606181
   Oetter N, 2016, J TRANSL MED, V14, DOI 10.1186/s12967-016-0919-4
   Poedjiastoeti W, 2018, HEALTHC INFORM RES, V24, P236, DOI 10.4258/hir.2018.24.3.236
   Sharma N., 2014, Intell Inf Manag, V6, P30, DOI 10.4236/iim.2014.62005
   Shi M, 2011, BIOINFORMATICS, V27, P3017, DOI 10.1093/bioinformatics/btr502
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Tolentino ED, 2011, J APPL ORAL SCI, V19, P448, DOI 10.1590/S1678-77572011000500003
   Tong LI, 2011, EXPERT SYST APPL, V38, P4222, DOI 10.1016/j.eswa.2010.09.087
   Xiao YW, 2018, COMPUT METH PROG BIO, V166, P99, DOI 10.1016/j.cmpb.2018.10.004
   Xiao YW, 2018, COMPUT METH PROG BIO, V153, P1, DOI 10.1016/j.cmpb.2017.09.005
   Yuan XH, 2018, PATTERN RECOGN, V77, P160, DOI 10.1016/j.patcog.2017.12.017
NR 30
TC 15
Z9 16
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27867
EP 27890
DI 10.1007/s11042-020-09384-6
EA JUL 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000559382300002
DA 2024-07-18
ER

PT J
AU Bekhouche, SE
   Dornaika, F
   Benlamoudi, A
   Ouafi, A
   Taleb-Ahmed, A
AF Bekhouche, S. E.
   Dornaika, F.
   Benlamoudi, A.
   Ouafi, A.
   Taleb-Ahmed, A.
TI A comparative study of human facial age estimation: handcrafted features
   vs. deep features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Age estimation; Handcrafted features; Deep features; Support vector
   regression
ID CLASSIFICATION; DATABASE; FACES
AB In recent times, the topic of human facial age estimation attracted much attention. This is due to its ability to improve biometrics systems. Recently, several applications that are based on the demographic attributes estimation have been developed. These include law enforcement, re-identification in videos, planed marketing, intelligent advertising, social media, and human-computer interaction. The main contributions of the paper are as follows. Firstly, it extends some handcrafted models that are based on the Pyramid Multi Level (PML) face representation. Secondly, it evaluates the performance of two different kinds of features that are handcrafted and deep features. It compares handcrafted and deep features in terms of accuracy and computational complexity. The proposed scheme of study includes the following three main steps: 1) face preprocessing; 2) feature extraction (two different kinds of features are studied: handcrafted and deep features); 3) feeding the obtained features to a linear regressor. In addition, we investigate the strengths and weaknesses of handcrafted and deep features when used in facial age estimation. Experiments are run on three public databases (FG-NET, PAL and FACES). These experiments show that both handcrafted and deep features are effective for facial age estimation.
C1 [Bekhouche, S. E.] Univ Djelfa, Dept Elect Engn, Djelfa, Algeria.
   [Bekhouche, S. E.; Dornaika, F.] Univ Basque Country, UPV EHU, San Sebastian, Spain.
   [Dornaika, F.] Basque Fdn Sci, Ikerbasque, Bilbao, Spain.
   [Benlamoudi, A.] Univ Kasdi Merbah Ouargla, Lab Genie Elect LAGE, Fac Nouvelles Technol Informat & Commun, Ouargla 30000, Algeria.
   [Ouafi, A.] Univ Biskra, Lab LESIA, Biskra, Algeria.
   [Taleb-Ahmed, A.] UPHF, IEMN DOAE UMR CNRS 8520, F-59313 Valenciennes, France.
C3 Universite de Djelfa; University of Basque Country; Basque Foundation
   for Science; Universite Kasdi Merbah Ouargla; Universite Mohamed Khider
   Biskra; Centre National de la Recherche Scientifique (CNRS); Universite
   Polytechnique Hauts-de-France; Universite de Lille
RP Dornaika, F (corresponding author), Univ Basque Country, UPV EHU, San Sebastian, Spain.; Dornaika, F (corresponding author), Basque Fdn Sci, Ikerbasque, Bilbao, Spain.
EM s.bekhouche@univ-djelfa.dz; fadi.dornaika@ehu.eus;
   benlamoudi.azeddine@univ-ouargla.dz; a.ouafi@univ-biskra.dz;
   taleb@uphf.fr
RI Benlamoudi, Azeddine/GVT-2924-2022; Bekhouche, Salah
   Eddine/AAK-6387-2021; Benlamoudi, Azeddine/ITV-3914-2023; benlamoudi,
   azeddine/IUM-4839-2023
OI Benlamoudi, Azeddine/0000-0002-2023-2154; Bekhouche, Salah
   Eddine/0000-0001-5538-7407; Dornaika, Fadi/0000-0001-6581-9680
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   ALLEY ST, 1988, APPL ASPECTS PERCEIV
   Angulu R, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0278-6
   [Anonymous], 2010, Proc. MPVA
   BEKHOUCHE S, 2014, P 1 INT C EL ENG ICE
   Bekhouche SE, 2017, EXPERT SYST APPL, V80, P297, DOI 10.1016/j.eswa.2017.03.030
   Bekhouche SE, 2017, IEEE COMPUT SOC CONF, P1660, DOI 10.1109/CVPRW.2017.211
   BEKHOUCHE SE, 2017, THESIS
   BERRY DS, 1986, PSYCHOL BULL, V100, P3, DOI 10.1037/0033-2909.100.1.3
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Dong YN, 2019, MULTIMEDIA SYST, V25, P49, DOI 10.1007/s00530-017-0534-0
   Dornaika F, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112942
   Dornaika F, 2019, MACH VISION APPL, V30, P177, DOI 10.1007/s00138-018-0976-1
   Ebner NC, 2010, BEHAV RES METHODS, V42, P351, DOI 10.3758/BRM.42.1.351
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   GRD P, 2013, RES PAPERS FACULTY M, V21, P24
   Grohmann S, 2015, 20TH INTERNATIONAL CONFERENCE ON COMPOSITE MATERIALS
   GUNAY A, 2017, INT J ADV TELECOMMUN, V6, P108, DOI DOI 10.11601/IJATES.V6I3.218
   Günay A, 2016, LECT NOTES ELECTR EN, V363, P295, DOI 10.1007/978-3-319-22635-4_27
   Günay A, 2008, 23RD INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, P378
   Guo GD, 2012, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2012.6247972
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Gurpinar F., 2016, P IEEE C COMP VIS PA, P80
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu ZZ, 2017, IEEE T IMAGE PROCESS, V26, P3087, DOI 10.1109/TIP.2016.2633868
   Jain A, 2011, INDIAN J CRIT CARE M, V15, DOI 10.4103/0972-5229.78234
   Kannala J, 2012, INT C PATT RECOG, P1363
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kotowski K, 2018, COMM COM INF SC, V928, P376, DOI 10.1007/978-3-319-99987-6_29
   Kwon YH, 1999, COMPUT VIS IMAGE UND, V74, P1, DOI 10.1006/cviu.1997.0549
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Levi G., 2015, CVPRW, P34
   Liao HB, 2019, MULTIMED TOOLS APPL, V78, P2181, DOI 10.1007/s11042-018-6342-5
   Liu H, 2019, IEEE T CIRC SYST VID, V29, P486, DOI 10.1109/TCSVT.2017.2782709
   Liu H, 2018, IEEE T INF FOREN SEC, V13, P292, DOI 10.1109/TIFS.2017.2746062
   Liu H, 2017, PATTERN RECOGN, V66, P82, DOI 10.1016/j.patcog.2016.10.026
   Liu XH, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010146
   Lou ZY, 2018, IEEE T PATTERN ANAL, V40, P365, DOI 10.1109/TPAMI.2017.2679739
   Lu JW, 2015, IEEE T IMAGE PROCESS, V24, P5356, DOI 10.1109/TIP.2015.2481327
   Minear M, 2004, BEHAV RES METH INS C, V36, P630, DOI 10.3758/BF03206543
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Panis G, 2016, IET BIOMETRICS, V5, P37, DOI 10.1049/iet-bmt.2014.0053
   Parkhi OM, 2015, Proceedings of the British Machine Vision Conference, DOI DOI 10.5244/C.29.41
   Sai PK, 2015, NEUROCOMPUTING, V149, P364, DOI 10.1016/j.neucom.2014.03.074
   Sawant M, 2019, MULTIMED TOOLS APPL, V78, P30419, DOI 10.1007/s11042-019-7589-1
   Sawant MM, 2019, IEEE ACCESS, V7, P9142, DOI 10.1109/ACCESS.2018.2889873
   SHEN W, 2018, P IEEE INT C COMP VI
   Shen Wei, 2019, IEEE T PATTERN ANAL
   Shu XB, 2018, IEEE T PATTERN ANAL, V40, P905, DOI 10.1109/TPAMI.2017.2705122
   Shu XB, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P789, DOI 10.1145/2733373.2807962
   Shu XB, 2016, PATTERN RECOGN, V59, P156, DOI 10.1016/j.patcog.2015.12.015
   Shu XB, 2016, NEUROCOMPUTING, V208, P249, DOI 10.1016/j.neucom.2016.01.101
   Shu XB, 2015, IEEE I CONF COMP VIS, P3970, DOI 10.1109/ICCV.2015.452
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Yang HF, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3152118
   Yang ZG, 2007, LECT NOTES COMPUT SC, V4642, P464
   Ylioinas J, 2012, INT C PATT RECOG, P1257
   Zighem MEN, 2019, J VIS COMMUN IMAGE R, V61, P236, DOI 10.1016/j.jvcir.2019.03.025
NR 60
TC 9
Z9 9
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26605
EP 26622
DI 10.1007/s11042-020-09278-7
EA JUL 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000549703700003
DA 2024-07-18
ER

PT J
AU Panico, F
   Cordasco, G
   Vogel, C
   Trojano, L
   Esposito, A
AF Panico, Francesco
   Cordasco, Gennaro
   Vogel, Carl
   Trojano, Luigi
   Esposito, Anna
TI Ethical issues in assistive ambient living technologies for ageing well
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Assistive ambient living; Elderly; Ethics; Ageing; Healthcare
ID OLDER-PEOPLE; GROWTH
AB Assistive Ambient Living (AAL) in ageing refers to any device used to support ageing related psychological and physical changes aimed at improving seniors' quality of life and reducing caregivers' burdens. The diffusion of these devices opens the ethical issues related to their use in the human personal space. This is particularly relevant when AAL technologies are devoted to the ageing population that exhibits special bio-psycho-social aspects and needs. In spite of this, relatively little research has focused on ethical issues that emerge from AAL technologies. The present article addresses ethical issues emerging when AAL technologies are implemented for assisting the elderly population and is aimed at raising awareness of these aspects among healthcare providers. The overall conclusion encourages a person-oriented approach when designing healthcare facilities. This process must be fulfilled in compliance with the general principles of ethics and individual nature of the person devoted to. This perspective will develop new research paradigms, paving the way for fulfilling essential ethical principles in the development of future generations of personalized AAL devices to support ageing people living independently at their home.
C1 [Panico, Francesco; Cordasco, Gennaro; Trojano, Luigi; Esposito, Anna] Univ Campania Luigi Vanvitelli, Dept Psychol, Caserta, Italy.
   [Cordasco, Gennaro; Esposito, Anna] Int Inst Adv Sci Studies, Vietri Sul Mare, Italy.
   [Vogel, Carl] Trinity Coll Dublin, Dublin, Ireland.
C3 Universita della Campania Vanvitelli; Trinity College Dublin
RP Panico, F (corresponding author), Univ Campania Luigi Vanvitelli, Dept Psychol, Caserta, Italy.
EM francesco.panico@unicampania.it
RI Trojano, Luigi/F-2396-2016; Esposito, Anna/GWC-6719-2022; Cordasco,
   Gennaro/AAQ-1914-2020; Cordasco, Gennaro/A-9686-2016; ESPOSITO,
   Anna/P-4018-2015; Panico, Francesco/HJI-1261-2023
OI Trojano, Luigi/0000-0002-0328-9642; Cordasco,
   Gennaro/0000-0001-9148-9769; Cordasco, Gennaro/0000-0001-9148-9769;
   ESPOSITO, Anna/0000-0002-7268-1795; Panico,
   Francesco/0000-0001-8346-5484; Vogel, Carl/0000-0001-8928-8546
FU Universita degli Studi della Campania Luigi Vanvitelli
FX Open access funding provided by Universita degli Studi della Campania
   Luigi Vanvitelli within the CRUI-CARE Agreement.
CR [Anonymous], 134852016 INT ORG ST
   [Anonymous], 2000, Dev. Biol
   [Anonymous], 2015, LECT NOTES COMPUTER, V9193, P1
   Arazy Ofer, 2015, THCI, V7, P43
   ARKING R, 1998, BIOL AGING
   Baltes P.B., 1990, SUCCESSFUL AGING PER, P1, DOI DOI 10.1017/CBO9780511665684.003
   BALTES PB, 1987, DEV PSYCHOL, V23, P611, DOI 10.1037/0012-1649.23.5.611
   Beauchamp T. L., 2001, PRINCIPLES BIOMEDICA
   Bedaf S, 2018, DISABIL REHABIL-ASSI, V13, P592, DOI 10.1080/17483107.2017.1358300
   Bedaf S, 2019, ASSIST TECHNOL, V31, P147, DOI 10.1080/10400435.2017.1402390
   Bennett B, 2017, B WORLD HEALTH ORGAN, V95, P749, DOI 10.2471/BLT.16.187484
   Bertelsen O, 2004, DAIMI REPORT SERIES, V33
   Blasco SA, 2019, RADIO ROBOTS ASSISTE, P19
   Bruder Ilvio, 2015, Health Information Science. 4th International Conference, HIS 2015. Proceedings: LNCS 9085, P154, DOI 10.1007/978-3-319-19156-0_16
   Carver J, 2016, DISABIL REHABIL-ASSI, V11, P468, DOI 10.3109/17483107.2015.1027295
   Cook A., 2009, DEV DISABILITIES B, V37, P127
   D'Errico F, 2010, LECT NOTES COMPUT SC, V6219, P125, DOI 10.1007/978-3-642-14715-9_13
   Daniel KM, 2009, GERIATR NURS, V30, P384, DOI 10.1016/j.gerinurse.2009.08.010
   De-Rosende-Celeiro I, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0215002
   Demiris G, 2008, Yearb Med Inform, P33
   Disabled Living Foundation, 2019, ETH ISS ASS TECHN
   Dziechciaz M, 2014, ANN AGR ENV MED, V21, P835, DOI 10.5604/12321966.1129943
   Esposito A, 2019, J AMB INTEL HUM COMP, V1, P8
   Esposito A, 2019, LECT NOTES INE ELECT
   Esposito A, 2014, COGN COMPUT, V6, P623, DOI 10.1007/s12559-014-9309-5
   Fiocco AJ, 2010, ARCH NEUROL-CHICAGO, V67, P876, DOI 10.1001/archneurol.2010.130
   Garçon L, 2016, GERONTOLOGIST, V56, pS293, DOI 10.1093/geront/gnw005
   Hammel J, 2003, NURS CLIN N AM, V38, P331, DOI 10.1016/S0029-6465(02)00053-1
   High-Level Expert Group on AI, 2019, Ethics Guidelines for Trustworthy AI., DOI DOI 10.2759/346720
   Huttunen A, 2010, LIBERATING INTELLIGE, P2
   Kitchener K.S., 2000, FDNS ETHICAL PRACTIC
   Kricos Patricia B, 2007, Trends Amplif, V11, P273, DOI 10.1177/1084713807304363
   Lattanzio F, 2010, J NUTR HEALTH AGING, V14, P238, DOI 10.1007/s12603-010-0056-3
   Leone G, 2012, COGN PROCESS, V13, P477, DOI 10.1007/s10339-011-0422-z
   Leroux C., 2012, Suggestion for A Green Paper on Legal Issues in Robotics' Report, euRobotics
   Martínez-Martí ML, 2018, PSYCHOL AESTHET CREA, V12, P272, DOI 10.1037/aca0000164
   Macklin R, 2003, BIOETHICS, V17, P472, DOI 10.1111/1467-8519.00362
   Martinez-Alcala Claudia I, 2016, JMIR Rehabil Assist Technol, V3, pe6, DOI 10.2196/rehab.5226
   MCCRAE RR, 1987, J PERS SOC PSYCHOL, V52, P81, DOI 10.1037/0022-3514.52.1.81
   Nadler A, 1998, STRATEGIC HELP SEEKING IMPLICATIONS FOR LEARNING AND TEACHING, P61
   Nadler A., 2015, The Oxford Handbook of Prosocial Behavior, P307
   Nadler A., 2012, OXFORD HDB PERSONALI, P394, DOI DOI 10.1093/OXFORDHB/9780195398991.013.0016
   National Institute of Child Health and Human Development Office of Communications, 2018, WHAT AR SOM TYP ASS
   Novitzky P, 2016, THESIS
   Olteanu A, 2019, FRONT BIG DATA, V2, DOI 10.3389/fdata.2019.00013
   Op den Akker H, 2018, PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES FOR AGEING WELL AND E-HEALTH (ICT4AWE), P219, DOI 10.5220/0006787702190226
   Pedersen H, 2019, DISABIL REHABIL-ASSI, V1, P9, DOI DOI 10.1080/17483107.2019.1642391
   Poggi I, 2009, 2009 3 INT C AFF COM, P1
   Rönnlund M, 2005, PSYCHOL AGING, V20, P3, DOI 10.1037/0882-7974.20.1.3
   Salatino C, 2017, STUD HEALTH TECHNOL, V242, P484, DOI 10.3233/978-1-61499-798-6-484
   Scherer MJ, 2015, NEUROREHABILITATION, V37, P315, DOI 10.3233/NRE-151264
   Schulke Astrid M, 2010, Philos Ethics Humanit Med, V5, P8, DOI 10.1186/1747-5341-5-8
   SEELBACH C, 1995, P NATL ACAD SCI USA, V92, P9989, DOI 10.1073/pnas.92.22.9989
   Small N, 2017, BMC PSYCHIATRY, V17, DOI 10.1186/s12888-017-1287-1
   Torres MI, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P629, DOI 10.1145/3316782.3322764
   Valstar M, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P419, DOI 10.1145/2993148.2998535
   Vandemeulebroucke T, 2019, J GERONTOL B
   Vandemeulebroucke T, 2018, AGING MENT HEALTH, V22, P149, DOI 10.1080/13607863.2017.1286455
   Vandemeulebroucke T, 2018, ARCH GERONTOL GERIAT, V74, P15, DOI 10.1016/j.archger.2017.08.014
   World Bank, 2019, LIF EXP BIRTH TOT YE
NR 60
TC 15
Z9 15
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 36077
EP 36089
DI 10.1007/s11042-020-09313-7
EA JUL 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000549703700006
OA hybrid
DA 2024-07-18
ER

PT J
AU Shen, XQ
   Liu, B
   Zhou, Y
   Zhao, JQ
AF Shen, Xiangqing
   Liu, Bing
   Zhou, Yong
   Zhao, Jiaqi
TI Remote sensing image caption generation via transformer and
   reinforcement learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transformer; Remote sensing image captioning; Attention mechanisms;
   Convolutional neural network; Reinforcement learning
ID NEURAL-NETWORKS; MODELS
AB Image captioning is a task generating the natural semantic description of the given image, which plays an essential role for machines to understand the content of the image. Remote sensing image captioning is a part of the field. Most of the current remote sensing image captioning models failed to fully utilize the semantic information in images and suffered the overfitting problem induced by the small size of the dataset. To this end, we propose a new model using the Transformer to decode the image features to target sentences. For making the Transformer more adaptive to the remote sensing image captioning task, we additionally employ dropout layers, residual connections, and adaptive feature fusion in the Transformer. Reinforcement Learning is then applied to enhance the quality of the generated sentences. We demonstrate the validity of our proposed model on three remote sensing image captioning datasets. Our model obtains all seven higher scores on the Sydney Dataset and Remote Sensing Image Caption Dataset (RSICD), four higher scores on UCM dataset, which indicates that the proposed methods perform better than the previous state of the art models in remote sensing image caption generation.
C1 [Shen, Xiangqing; Liu, Bing; Zhou, Yong] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
   [Liu, Bing; Zhou, Yong; Zhao, Jiaqi] Minist Educ Peoples Republ China, Mine Digitizat Engn Res Ctr, Xuzhou, Jiangsu, Peoples R China.
   [Liu, Bing] Chinese Acad Sci, Insititute Elect, Beijing 100190, Peoples R China.
C3 China University of Mining & Technology; Chinese Academy of Sciences
RP Liu, B (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.; Liu, B (corresponding author), Minist Educ Peoples Republ China, Mine Digitizat Engn Res Ctr, Xuzhou, Jiangsu, Peoples R China.; Liu, B (corresponding author), Chinese Acad Sci, Insititute Elect, Beijing 100190, Peoples R China.
EM liubing@cumt.edu.cn
FU Fundamental Research Funds for the Central Universities, China
   [2017XKQY082]
FX This work was supported by Fundamental Research Funds for the Central
   Universities, China (2017XKQY082).
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   [Anonymous], 2015, ICLR 2015
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   BENGIO S, 2015, ADV NEUR IN, V28, P28
   Biswas P, 2005, I CONF VLSI DESIGN, P651
   Chen K., 2013, IEEE MTT S INT MICR, P1, DOI DOI 10.1109/MWSYM.2013.6697759
   Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Choi Y, 2011, P 15 C COMPUTATIONAL, P220
   Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121
   Dong L, 2019, COMPUTATION OFFLOADI, P841, DOI [10.1109/ICDCS.2019.00088, DOI 10.1109/ICDCS.2019.00088]
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Feng K, 2020, ROUTL FRONT BUS MANA, P1
   Gerber R, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P805, DOI 10.1109/ICIP.1996.561027
   Gong YC, 2014, LECT NOTES COMPUT SC, V8692, P529, DOI 10.1007/978-3-319-10593-2_35
   Han XB, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9070666
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hinton G. E., 2012, ARXIV PREPRINT ARXIV
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   KARPATHY A, 2014, ADV NEUR IN, V27, P27
   Kingma D. P., 2014, arXiv
   Kulkarni G., 2011, CVPR 2011, DOI [10.1109/cvpr.2011, DOI 10.1109/CVPR.2011.5995466]
   Kundra H., 2015, RES J INF TECHNOL, V7, P58, DOI DOI 10.3923/RJIT.2015.58.69
   Li Y, 2012, TARGET DETECTION MET
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Liu Tingting, 2009, Geomatics and Information Science of Wuhan University, V34, P684
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Lu XX, 2018, IEEE T GEOSCI REMOTE, V56, P2183, DOI 10.1109/TGRS.2017.2776321
   Lu XQ, 2017, IEEE T GEOSCI REMOTE, V55, P5148, DOI 10.1109/TGRS.2017.2702596
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Nie GY, 2019, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2019.00340
   Pant T, 2019, APPL MATH MODEL, V72, P369, DOI 10.1016/j.apm.2019.03.016
   Papineni K, 2001, P 40 ANN M ASS COMP, DOI [10.3115/1073083.107313510.3115/1073083.1073135, DOI 10.3115/1073083.107313510.3115/1073083.1073135]
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Qu B, 2016, INT CONF COMP INFO, P124
   Rahaman KR, 2016, 2016 5TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS AND VISION (ICIEV), P256, DOI 10.1109/ICIEV.2016.7760006
   Raimond K, 2015, IEEE TECHNOLOGICAL I, DOI [10.1109/tiar.2015.735854810.1109/tiar.2015.7358548, DOI 10.1109/TIAR.2015.735854810.1109/TIAR.2015.7358548]
   Ranzato M, 2016, 4 INT C LEARN REPR I
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shi JZ, 2016, DISCRETE DYN NAT SOC, V2016, DOI 10.1155/2016/1801658
   Shi ZW, 2017, IEEE T GEOSCI REMOTE, V55, P3623, DOI 10.1109/TGRS.2017.2677464
   Spratling MW, 2004, J COGNITIVE NEUROSCI, V16, P219, DOI 10.1162/089892904322984526
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun C, 2015, IEEE I CONF COMP VIS, P2596, DOI 10.1109/ICCV.2015.298
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Toth C, 2016, ISPRS J PHOTOGRAMM, V115, P22, DOI 10.1016/j.isprsjprs.2015.10.004
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Wang BQ, 2019, IEEE GEOSCI REMOTE S, V16, P1274, DOI 10.1109/LGRS.2019.2893772
   Wang J., 2012, COMPUT DIGIT ENG, V40, P48
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Wu Y, 2020, IEEE T IMAGE PROCESS, V29, P3984, DOI 10.1109/TIP.2020.2967584
   Wu Y, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1029, DOI 10.1145/3240508.3240640
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   [杨俊俐 Yang Junli], 2015, [航空学报, Acta Aeronautica et Astronautica Sinica], V36, P3069
   Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI [10.1145/1869790.1869829, DOI 10.1145/1869790.1869829]
   Yao BZ, 2010, P IEEE, V98, P1485, DOI 10.1109/JPROC.2010.2050411
   Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Zhang F, 2015, IEEE T GEOSCI REMOTE, V53, P2175, DOI 10.1109/TGRS.2014.2357078
   Zhang LB, 2017, IEEE J-STARS, V10, P1511, DOI 10.1109/JSTARS.2016.2620900
   Zhang XR, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060612
   Zhu LG, 2019, IRONMAK STEELMAK, V46, P499, DOI 10.1080/03019233.2017.1405153
   Zhu QQ, 2014, INT GEOSCI REMOTE SE, DOI 10.1109/IGARSS.2014.6947071
NR 68
TC 25
Z9 25
U1 3
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26661
EP 26682
DI 10.1007/s11042-020-09294-7
EA JUL 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000549703700008
DA 2024-07-18
ER

PT J
AU Wang, J
   Xu, Z
   Pang, ZF
   Huo, ZQ
   Luo, JW
AF Wang, Jing
   Xu, Zhe
   Pang, Zhi-Feng
   Huo, Zhanqiang
   Luo, Junwei
TI Tumor detection for whole slide image of liver based on patch-based
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Liver cancer; Whole slide images (WSIs); Machine learning; Patch-based
   convolutional neural network; Classification
ID MARKERS
AB Liver cancer has a huge negative impact on the human survival. However, the traditional histopathological diagnostic methods have a large burden on the clinical diagnosis due to the large workload required. To this end, by combining the machine learning method and the whole slide images (WSIs), this paper proposes a novelty method to improve the efficiency of the clinical diagnosis. The core of our proposed method is to use a patch-based convolutional neural network to perform the category prediction (normal or tumor) on the patches extracted from the 60 liver tumor WSIs. Specifically, we design a total of four sets of the comparative experiment for the patch classification in order to screen the classifier with the best classification effect. The best classifier is then used to predict the category of patches in the testing set, and the results are combined to generate a probability heatmap to assist clinical diagnosis in an intuitive way. The experimental comparisons verify the validity of the proposed model which can achieve a classification accuracy rate of 99.94% in the patch classification task.
C1 [Wang, Jing; Xu, Zhe; Huo, Zhanqiang; Luo, Junwei] Henan Polytech Univ, Coll Comp Sci & Technol, Jiaozuo 454003, Henan, Peoples R China.
   [Pang, Zhi-Feng] Henan Univ, Sch Math & Stat, Kaifeng 475004, Peoples R China.
C3 Henan Polytechnic University; Henan University
RP Pang, ZF (corresponding author), Henan Univ, Sch Math & Stat, Kaifeng 475004, Peoples R China.
EM wjasmine@hpu.edu.cn; xzmystyle@hotmail.com; zhifengpang@163.com;
   hzq@hpu.edu.cn; luojunwei@hpu.edu.cn
RI , zhifengpang/AAE-6852-2020; Yuan, Ye/KBC-9835-2024
OI Yuan, Ye/0009-0008-1640-7047; Wang, Jing/0000-0002-3288-2111; Pang,
   Zhi-Feng/0000-0001-6824-3509
FU National Science Foundation of China [:61872311, 61972134, 61602156];
   Key Science and Technology Program of Henan Province [182102210053];
   Excellent Young Teachers Program of Henan Polytechnic University
   [2019XQG-02]; Korea Health Technology R&D Project through the Korea
   Health Industry Development Institute (KHIDI) - Ministry of Health &
   Welfare, Republic of Korea [HI18C0316]
FX This work is supported by the National Science Foundation of China
   (Nos.:61872311, 61972134, 61602156), Sorted by Key Science and
   Technology Program of Henan Province (No.:182102210053), Excellent Young
   Teachers Program of Henan Polytechnic University (No.:2019XQG-02).
   Deidentified pathology images and annotations used in this research were
   prepared and provided by the Seoul National University Hospital by a
   grant of the Korea Health Technology R&D Project through the Korea
   Health Industry Development Institute (KHIDI), funded by the Ministry of
   Health & Welfare, Republic of Korea (grant number: HI18C0316).
CR ANWANWAN D, 2020, BIOCH BIOPHYS ACTA R, V1
   Befeler AS, 2002, GASTROENTEROLOGY, V122, P1609, DOI 10.1053/gast.2002.33411
   Conze PH, 2017, INT J COMPUT ASS RAD, V12, P223, DOI 10.1007/s11548-016-1493-1
   Cruz-Roa A, 2014, PROC SPIE, V9041, DOI 10.1117/12.2043872
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou L, 2016, PROC CVPR IEEE, P2424, DOI 10.1109/CVPR.2016.266
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Jiang HY, 2019, IEEE ACCESS, V7, P24898, DOI 10.1109/ACCESS.2019.2899608
   Kuppili V, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0797-1
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu Y, 2017, COMMUN MATH BIOL NEU, DOI 10.1080/10408398.2017.1329704
   Nault JC, 2020, J HEPATOL, V72, P209, DOI 10.1016/j.jhep.2019.11.006
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tai SK, 2018, INT CONF AWARE SCI, P232, DOI 10.1109/ICAwST.2018.8517242
   Wang D., 2016, ARXIV PREPRINT ARXIV
   Wang WB, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON DIGITAL MEDICINE AND IMAGE PROCESSING (DMIP 2018), P56, DOI 10.1145/3299852.3299860
   Yu NC, 2011, CLIN GASTROENTEROL H, V9, P161, DOI 10.1016/j.cgh.2010.09.017
   Yuen MF, 2005, BEST PRACT RES CL GA, V19, P91, DOI 10.1016/j.bpg.2004.10.003
   [赵蒙蒙 Zhao Mengmeng], 2019, [中国胸心血管外科临床杂志, Chinese Journal of Clinical Thoracic and Cardiovascular Surgery], V26, P1063
   Zhao YJ, 2013, MOL CLIN ONCOL, V1, P593, DOI 10.3892/mco.2013.119
NR 22
TC 13
Z9 18
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17429
EP 17440
DI 10.1007/s11042-020-09282-x
EA JUL 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000548128400002
DA 2024-07-18
ER

PT J
AU Li, DJ
   Chen, HA
   Jin, GQ
   Jin, Y
   Zhu, CG
   Chen, EH
AF Li, Dongjie
   Chen, Huaian
   Jin, Guoqiang
   Jin, Yi
   Zhu, Changan
   Chen, Enhong
TI A multiscale dilated residual network for image denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Dilated convolution; Image denoising; Residual learning
ID TRANSFORM; CNN
AB In this paper, a more effective Gaussian denoiser is designed to enhance the resulting image quality. We propose a novel image denoising method using a multiscale dilated residual network, named MDRNet. The proposed method is based on two main strategies. First, we adopt dilated convolutions in our network to enlarge the receptive field while requiring fewer parameters. The hybrid dilation rate pattern (HDP) is implemented such that each pixel in the pattern contributes similarly to the receptive field, allowing our network to learn the image details equally. Second, we employ a contextualized structure to take advantage of the low-level features which are mainly concentrated in the first two layers. Our method achieves competitive denoising performance and requires fewer parameters compared to existing denoising methods that using convolutional network. Through comprehensive experiments, we show that the denoising performance of our method is competitive with the state-of-the-art methods in terms of both quantitative and qualitative evaluation.
C1 [Li, Dongjie; Chen, Huaian; Jin, Guoqiang; Jin, Yi; Zhu, Changan] Univ Sci & Technol China, Dept Precis Machinery & Precis Instrumentat, 96 Jinzhai Rd, Hefei 230026, Anhui, Peoples R China.
   [Chen, Enhong] Univ Sci & Technol China, Dept Comp Sci, 96 Jinzhai Rd, Hefei 230026, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; University of Science &
   Technology of China, CAS
RP Jin, Y (corresponding author), Univ Sci & Technol China, Dept Precis Machinery & Precis Instrumentat, 96 Jinzhai Rd, Hefei 230026, Anhui, Peoples R China.
EM jinyi08@ustc.edu.cn
RI Zhu, ChangAn/KIL-0881-2024; Jin, Yi/ABG-3022-2022; Li,
   Dong-Jie/AAQ-5991-2020
OI Chen, Enhong/0000-0002-4835-4102; Jin, Guoqiang/0000-0002-4964-6019;
   Chen, Huaian/0000-0003-3999-2206
FU Research on the Major Scientific Instrument of National Natural Science
   Foundation of China [61727809]
FX This research was sponsered by the Research on the Major Scientific
   Instrument of National Natural Science Foundation of China (61727809).
CR [Anonymous], 2017, ARXIV170705414
   [Anonymous], 2018, ARXIV180901826
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Burger H., 2012, CVPR
   Chen C, 2018, LECT NOTES COMPUT SC, V11215, P3, DOI 10.1007/978-3-030-01252-6_1
   Chen JW, 2018, PROC CVPR IEEE, P3155, DOI 10.1109/CVPR.2018.00333
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Cho SI, 2019, IEEE T MULTIMEDIA, V21, P484, DOI 10.1109/TMM.2018.2859791
   Cho SI, 2018, IEEE T MULTIMEDIA, V20, P1738, DOI 10.1109/TMM.2017.2781371
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Fan Q, 2018, MULTIMED TOOLS APPL, V77, P10807, DOI 10.1007/s11042-017-5077-z
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jain V., 2009, ADV NEURAL INFORM PR, P769, DOI DOI 10.5555/2981780.2981876
   Jianyong Cui, 2013, Advances in Neural Networks - ISNN 2013. 10th International Symposium on Neural Networks. Proceedings: LNCS 7951, P620, DOI 10.1007/978-3-642-39065-4_74
   Jiao JB, 2017, IEEE COMPUT SOC CONF, P1034, DOI 10.1109/CVPRW.2017.140
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2833, DOI 10.1109/CVPR.2011.5995309
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Munir B, 2019, MULTITOOLS APPL, P1
   Ning MY, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P164
   Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6
   Schmidt U, 2014, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR.2014.349
   SHENSA MJ, 1992, IEEE T SIGNAL PROCES, V40, P2464, DOI 10.1109/78.157290
   Shi ZH, 2017, MULTIMED TOOLS APPL, V76, P14921, DOI 10.1007/s11042-016-4284-3
   Su F, 2016, 2016 16TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), P280, DOI 10.1109/ISCIT.2016.7751636
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang TY, 2017, PROC INT C TOOLS ART, P1272, DOI 10.1109/ICTAI.2017.00192
   Xie J, 2015, IEEE T MULTIMEDIA, V17, P1525, DOI 10.1109/TMM.2015.2457678
   Xie Junyuan, 2012, ADV NEURAL INFORM PR, P341, DOI [DOI 10.5555/2999134.2999173, DOI 10.1109/AGRO-GEOINFORMATICS.2012.6311605]
   Yu F., 2017, PROC CVPR IEEE, P472, DOI [DOI 10.1109/CVPR.2017.75, 10.1109/CVPR.2017.75]
   Yu F., 2015, ARXIV
   Zha ZY, 2017, IEEE INT CON MULTI, P883, DOI 10.1109/ICME.2017.8019334
   Zhang K, 2018, IEEE TRANSIMAGE PROC
   Zhang K., 2017, PROC CVPR IEEE, P3929, DOI [DOI 10.1109/CVPR.2017.300, 10.1109/CVPR.2017.300]
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   ZHANG Y, 2018, ARXIV181210477
   Zheng X, 2016, MULTIMED TOOLS APPL, V75, P8719, DOI 10.1007/s11042-015-2788-x
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 40
TC 12
Z9 16
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34443
EP 34458
DI 10.1007/s11042-020-09113-z
EA JUL 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000545796700002
DA 2024-07-18
ER

PT J
AU Murtaza, G
   Shuib, L
   Wahab, AWA
   Mujtaba, G
   Raza, G
AF Murtaza, Ghulam
   Shuib, Liyana
   Wahab, Ainuddin Wahid Abdul
   Mujtaba, Ghulam
   Raza, Ghulam
TI Ensembled deep convolution neural network-based breast cancer
   classification with misclassification reduction algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Image classification; Convolutional neural network; Deep
   learning; Transfer learning; Histopathology biopsy image
ID FRAMEWORK
AB Breast cancer (BrC) is the leading cause of abnormal death in women. Mammograms and histopathology (Hp) biopsy images are generally recommended for early diagnosis of BrC because Hp image-based diagnosis enables doctors to make cancer diagnostic decisions more confidently than with mammograms. Several studies have used Hp images to classify BrC. However, the performance of classification models is compromised due to the higher misclassification rate. Therefore, this study aimed to develop a reliable, accurate, and computationally cost-effective ensembled BrC classification network (EBrC-Net) model with three misclassification algorithms to diagnose breast malignancy in early stages using Hp images. The proposed EBrC-Net model is based on the deep convolutional neural network approach. For experiments, the publicly available BreakHis dataset was used and split into training, validation, and testing sets. In addition, image augmentation was adopted for the training set only, and features were extracted through the well-trained EBrC-Net. Thereafter, the extracted features were further evaluated by six machine learning classifiers, of which two best performing classifiers (i.e., softmax and k-nearest neighbour [kNN]) were selected on the basis of five performance metric evaluation results. Furthermore, three misclassification reduction (McR) algorithms were developed and implemented in cascaded manner to reduce the false predictions of the softmax and kNN classifiers. After the implementation of the McR algorithms, experiments showed that the kNN results were much better and reliable than the softmax. The proposed BrC classification model achieved accuracy, specificity, and sensitivity rates of 97.74%, 100%, and 97.01%, respectively. Moreover, the performance of proposed BrC classification model was compared with that of state-of-the-art baseline models. Findings showed that the proposed EBrC-Net classification model, coupled with the proposed McR algorithms, achieved the best results in comparison with the baseline classification models. The proposed EBrC-Net model and the McR algorithms are a reliable source for doctors aiming for second opinion in making early diagnostic decisions for BrC using Hp images.
C1 [Murtaza, Ghulam; Shuib, Liyana; Wahab, Ainuddin Wahid Abdul; Mujtaba, Ghulam] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur 50603, Malaysia.
   [Murtaza, Ghulam; Mujtaba, Ghulam] Sukkur IBA Univ, Dept Comp Sci, Sukkur, Pakistan.
   [Raza, Ghulam] Our Lady Lourdes Hosp, Drogheda, Ireland.
C3 Universiti Malaya; Sukkur IBA University
RP Murtaza, G; Shuib, L (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur 50603, Malaysia.; Murtaza, G (corresponding author), Sukkur IBA Univ, Dept Comp Sci, Sukkur, Pakistan.
EM gmurtaza@iba-suk.edu.pk; liyanashuib@um.edu.my; ainuddin@um.edu.my;
   mujtaba@iba-suk.edu.pk; ghulam.raza@ymail.com
RI Mujtaba, Ghulam/AAW-4254-2021; Abdul Wahab, Ainuddin Wahid/A-9293-2013;
   Murtaza, Ghulam/ABD-7461-2020; Wahid, Abdul/JAO-5831-2023; Shuib,
   Liyana/M-8698-2013
OI Abdul Wahab, Ainuddin Wahid/0000-0003-1062-0329; Murtaza,
   Ghulam/0000-0003-0318-7168; Shuib, Liyana/0000-0002-7907-0671
CR Abdullah-Al Nahid, 2017, 2017 20TH INTERNATIONAL CONFERENCE OF COMPUTER AND INFORMATION TECHNOLOGY (ICCIT)
   Abdullah-Al Nahid, 2018, BIOMED RES INT, V2018, DOI 10.1155/2018/2362108
   Aghdam MH, 2015, J ARTIF INTELL SOFT, V5, P231, DOI 10.1515/jaiscr-2015-0031
   Allison KH, 2014, HISTOPATHOLOGY, V65, P240, DOI 10.1111/his.12387
   Amit G, 2017, PROGR BIOM OPT IM P
   [Anonymous], 2015, 2015 37 ANN INT C IE
   [Anonymous], 2018, IEEE ACCESS, DOI DOI 10.1109/ACCESS.2018.2831280
   [Anonymous], 2015, JAMA J AM MED ASSOC, DOI DOI 10.1001/JAMA.2015.1405
   Araújo T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177544
   Arefan D, 2015, J INSTRUM, V10, DOI 10.1088/1748-0221/10/12/T12002
   Bayramoglu N, 2017, P INT C PATT REC
   Bejnordi BE, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.4.044504
   Byun H, 2002, LECT NOTES COMPUT SC, V2388, P213
   Carneiro G, 2017, IEEE T MED IMAGING, V36, P2355, DOI 10.1109/TMI.2017.2751523
   Chang J, 2017, 2017 IEEE 19TH INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES (HEALTHCOM)
   Cirean DC, 2013, INT C MED IM COMP CO
   Evans AJ, 2011, J PATHOL INFORM, P2
   Feng YQ, 2018, INT J COMPUT ASS RAD, V13, P179, DOI 10.1007/s11548-017-1663-9
   Gandomkar Z, 2018, ARTIF INTELL MED, V88, P14, DOI 10.1016/j.artmed.2018.04.005
   Hadad O, 2017, P INT S BIOM IM
   Han S, 2017, PHYS MED BIOL, V62, P7714, DOI 10.1088/1361-6560/aa82ec
   Han ZY, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04075-z
   Jiang F, 2017, INT C ELECTR MACH SY
   Khan AM, 2014, IEEE T BIO-MED ENG, V61, P1729, DOI 10.1109/TBME.2014.2303294
   Kim DH, 2016, 2016 IEEE INT C AC S
   Kotsiantis SB, 2007, FRONT ARTIF INTEL AP, V160, P3
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar I, 2017, BIOCYBERN BIOMED ENG, V37, P217, DOI 10.1016/j.bbe.2017.01.001
   Kuramochi M, 2005, INT J ARTIF INTELL T, V14, P641, DOI 10.1142/S0218213005002302
   Macenko M, 2009, BIOM IM NAN MACR 200
   Murtaza G, 2018, DAT SCI RES S 2018
   Murtaza G, 2020, MULTIMED TOOLS APPL, V79, P15481, DOI 10.1007/s11042-019-7525-4
   Murtaza G, 2020, ARTIF INTELL REV, V53, P1655, DOI 10.1007/s10462-019-09716-5
   Nahid AA, 2017, 2017 INT C DIG IM CO
   Nahid AA, 2018, INFORMATION, V9, DOI 10.3390/info9010019
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nascimento Carmina Dessana Lima, 2016, Res. Biomed. Eng., V32, P283
   Nejad EM, 2017, ACM INT C P SER
   Rasti R, 2017, PATTERN RECOGN, V72, P381, DOI 10.1016/j.patcog.2017.08.004
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Rennie JD., 2003, P 20 INT C MACHINE L
   Rouhi R, 2015, EXPERT SYST APPL, V42, P990, DOI 10.1016/j.eswa.2014.09.020
   Samala RK, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aabb5b
   Samala RK, 2017, PHYS MED BIOL, V62, P8894, DOI 10.1088/1361-6560/aa93d4
   Spanhol F.A., 2016, P INT JOINT C NEUR N
   Spanhol FA, 2017, SYST MAN CYB SMC 201
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   U.S. Department of Health and Human Services, 2018, US CANC STAT WORK GR
   Wan T, 2017, NEUROCOMPUTING, V229, P34, DOI 10.1016/j.neucom.2016.05.084
   Wang HB, 2014, J MED IMAGING, V1, DOI 10.1117/1.JMI.1.3.034003
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Xu J, 2016, NEUROCOMPUTING, V191, P214, DOI 10.1016/j.neucom.2016.01.034
   Yosinski J, 2014, ADV NEUR IN, V27
   Zheng YS, 2017, PATTERN RECOGN, V71, P14, DOI 10.1016/j.patcog.2017.05.010
NR 54
TC 15
Z9 15
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18447
EP 18479
DI 10.1007/s11042-020-08692-1
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000587677800052
DA 2024-07-18
ER

PT J
AU Rodrigues, R
   Pocta, P
   Melvin, H
   Bernardo, MV
   Pereira, M
   Pinheiro, AMG
AF Rodrigues, Rafael
   Pocta, Peter
   Melvin, Hugh
   Bernardo, Marco V.
   Pereira, Manuela
   Pinheiro, Antonio M. G.
TI Audiovisual quality of live music streaming over mobile networks using
   MPEG-DASH
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MPEG-DASH; QoE; Multimedia broadcasting; Mobile TV
ID PERCEIVED AUDIO QUALITY; VIDEO QUALITY; EXPERIENCE; MODEL
AB The MPEG-DASH protocol has been rapidly adopted by most major network content providers and enables clients to make informed decisions in the context of HTTP streaming, based on network and device conditions using the available media representations. A review of the literature on adaptive streaming over mobile shows that most emphasis has been on adapting the video quality whereas this work examines the trade-off between video and audio quality. In particular, subjective tests were undertaken for live music streaming over emulated mobile networks with MPEG-DASH. A group of audio/video sequences was designed to emulate varying bandwidth arising from network congestion, with varying trade-off between audio and video bit rates. Absolute Category Rating was used to evaluate the relative impact of both audio and video quality in the overall Quality of Experience (QoE). One key finding from the statistical analysis of Mean Opinion Scores (MOS) results using Analysis of Variance indicates that providing reduced audio quality has a much lower impact on QoE than reducing video quality at similar total bandwidth situations. This paper also describes an objective model for audiovisual quality estimation that combines the outcomes from audio and video metrics into a joint parametric model. The correlation between predicted and subjective MOS was computed using several outcomes (Pearson and Spearman correlation coefficients, Root Mean Square Error (RMSE) and epsilon-insensitive RMSE). The obtained results indicate that the proposed approach is a viable solution for objective audiovisual quality assessment in the context of live music streaming over mobile network.
C1 [Rodrigues, Rafael; Bernardo, Marco V.; Pereira, Manuela; Pinheiro, Antonio M. G.] Inst Telecomunicacoes, Covilha, Portugal.
   [Rodrigues, Rafael; Bernardo, Marco V.; Pereira, Manuela; Pinheiro, Antonio M. G.] Univ Beira Interior, Covilha, Portugal.
   [Pocta, Peter] Univ Zilina, Dept Multimedia & Informat Commun Technol, Zilina, Slovakia.
   [Melvin, Hugh] Natl Univ Ireland, Sch Comp Sci, Galway, Ireland.
C3 Universidade da Beira Interior; University of Zilina; Ollscoil na
   Gaillimhe-University of Galway
RP Rodrigues, R (corresponding author), Inst Telecomunicacoes, Covilha, Portugal.; Rodrigues, R (corresponding author), Univ Beira Interior, Covilha, Portugal.
EM rafael.rodrigues@ubi.pt
RI Pereira, Manuela/Q-3456-2019; Pocta, Peter/A-6228-2010; Pinheiro,
   Antonio/B-2723-2012; Rodrigues, Rafael/L-3698-2018; Bernardo, Marco
   v./HNQ-4992-2023
OI Pereira, Manuela/0000-0002-8648-6464; Pocta, Peter/0000-0001-6791-1325;
   Pinheiro, Antonio/0000-0002-5968-9901; Rodrigues,
   Rafael/0000-0002-9481-9601; Bernardo, Marco v./0000-0003-0046-8685
FU QuiVVer - "Centro de competencia em Qualidade, Validacao e Verificacao
   de software" [CENTRO-07-CT62-FEDER-005009]; E.U. Action COST [IC 1003];
   Fundação para a Ciência e a Tecnologia [UID/EEA/50008/2013] Funding
   Source: FCT
FX The authors would like to acknowledge QuiVVer - "Centro de competencia
   em Qualidade, Validacao e Verificacao de software"
   (CENTRO-07-CT62-FEDER-005009) for providing the equipment used in the
   subjective tests. Furthermore, we acknowledge the E.U. Action COST IC
   1003 - Qualinet for enabling the cooperation between the three research
   institutions involved in this project.
CR [Anonymous], 2015, Methods for the subjective assesment of small impairments in audio systems
   [Anonymous], 2001, METHOD OBJECTIVE MEA
   [Anonymous], 2008, OBJECTIVE PERCEPTUAL
   [Anonymous], 2016, METHODS SUBJECTIVE A
   [Anonymous], 2008, SUBJECTIVE VIDEO QUA
   [Anonymous], 2017, PARAMETRIC BITSTREAM
   [Anonymous], 1998, SUBJECTIVE AUDIOVISU
   [Anonymous], 2012, Methods, metrics and procedures for statistical evaluation, qualification and comparison of objective quality prediction models
   [Anonymous], 2012, METHODOLOGY SUBJECTI
   [Anonymous], 2014, PERCEPTUAL OBJECTIVE
   [Anonymous], 2015, ITU-R BS. 1534-3 Recommendation
   Barman N, 2019, IEEE ACCESS, V7, P30831, DOI 10.1109/ACCESS.2019.2901778
   Martinez HAB, 2018, MULTIMED TOOLS APPL, V77, P23993, DOI 10.1007/s11042-018-5656-7
   Beerends JG, 1999, J AUDIO ENG SOC, V47, P355
   Bossen F, 2013, 11 M JOINT COLL TEAM
   Claeys M, 2014, IEEE COMMUN LETT, V18, P716, DOI 10.1109/LCOMM.2014.020414.132649
   Czepa C, 2016, IEEE INT ENTERP, P3
   De Vriendt J, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P1288
   Duanmu ZF, 2018, IEEE T IMAGE PROCESS, V27, P6135, DOI 10.1109/TIP.2018.2855403
   Garcia M.-N, 2014, 2014 Sixth International Workshop on Quality of Multimedia Experience (QoMEX), P141, DOI 10.1109/QoMEX.2014.6982310
   Hands DS, 2004, IEEE T MULTIMEDIA, V6, P806, DOI 10.1109/TMM.2004.837233
   Herre J, 2008, IEEE SIGNAL PROC MAG, V25, P137, DOI 10.1109/MSP.2008.918684
   Hines A, 2015, J ACOUST SOC AM, V137, pEL449, DOI 10.1121/1.4921674
   Hossfeld Tobias, 2013, Data Traffic Monitoring and Analysis. From Measurement, Classification, and Anomaly Detection to Quality of Experience, P264, DOI 10.1007/978-3-642-36784-7_11
   Irondi I, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3269494
   ITU-T, 2019, PARAMETRIC BITSTREAM
   Liu Y, 2015, IEEE T BROADCAST, V61, P651, DOI 10.1109/TBC.2015.2460611
   Manasa K, 2016, IEEE T IMAGE PROCESS, V25, P2480, DOI 10.1109/TIP.2016.2548247
   MASSEY FJ, 1951, J AM STAT ASSOC, V46, P68, DOI 10.2307/2280095
   Mok R. K. P., 2011, 2011 IFIP/IEEE International Symposium on Integrated Network Management (IM 2011), P485, DOI 10.1109/INM.2011.5990550
   Pinson MH, 2011, IEEE SIGNAL PROC MAG, V28, P60, DOI 10.1109/MSP.2011.942470
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Pocta P, 2015, IEEE T BROADCAST, V61, P407, DOI 10.1109/TBC.2015.2424373
   Rodrigues RR, 2016, TEMPO ARGUM, V8, P1
   Seshadrinathan K, 2009, P SPIE HUMAN VISION, V7240, P283
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Soundararajan R, 2013, IEEE T CIRC SYST VID, V23, P684, DOI 10.1109/TCSVT.2012.2214933
   Takahashi S., 2019, 2019 11 INT C QUALIT, P1, DOI [10.1109/QoMEX.2019.8743191, DOI 10.1109/QOMEX.2019.8743191]
   Tavakoli S, 2014, P SPIE IMAGE QUALITY, V9016, P197
   Tavakoli S, 2015, SIGNAL PROCESS-IMAGE, V39, P432, DOI 10.1016/j.image.2015.05.001
   Tran HTT, 2019, IEEE CONF COMPUT, P702, DOI [10.1109/infcomw.2019.8845041, 10.1109/INFCOMW.2019.8845041]
   Vu T, 2018, INT CONF WEARAB IMPL, P13, DOI 10.1109/BSN.2018.8329647
   Thang TC, 2012, IEEE T CONSUM ELECTR, V58, P78, DOI 10.1109/TCE.2012.6170058
   Vu P. V., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2505, DOI 10.1109/ICIP.2011.6116171
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wilk S, 2015, P ACM INT C INT EXP, P113
   Yamagishi K, 2017, IEEE T MULTIMEDIA, V19, P1545, DOI 10.1109/TMM.2017.2669859
   You JY, 2010, SIGNAL PROCESS-IMAGE, V25, P482, DOI 10.1016/j.image.2010.02.002
NR 50
TC 3
Z9 3
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24595
EP 24619
DI 10.1007/s11042-020-09047-6
EA JUN 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000542539200004
DA 2024-07-18
ER

PT J
AU Yang, CY
   Cheng, LT
   Wang, WF
AF Yang, Ching-Yu
   Cheng, Lian-Ta
   Wang, Wen-Fong
TI An efficient reversible ECG steganography by adaptive LSB approach based
   on 1D FDCT domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Reversible ECG steganography; 1D FDCT; Adaptive LSB
   technique
ID WATERMARKING; BLIND
AB Based on the processing of one-dimensional fast discrete cosine transform (1D FDCT) coefficients, we present an efficient reversible data hiding method for electrocardiogram (ECG) signal. The proposed method is implemented in two phases. The purpose of phase-I is to classify the FDCT (host) bundles, where each input bundle will be attributed to one of four different bundles. The aim of phase-II is to embed data bits in the selected coefficients of the classified bundles according to a predetermined bit-index table (which generated from phase-I) via adaptive least significant bit (LSB) technique. Simulations confirmed that hidden bits were extracted without distortion and the original ECG signal can be completely recovered. Furthermore, a good perceived quality and a hiding capacity superior to existing techniques were achieved. Moreover, our method is robust against attacks such as noise addition, inversion, truncation, translations, and so on. Notice that the robustness is rarely seen in conventional reversible ECG steganography methods. Since this method has a fast computation speed, it is feasible for real-time applications and can be installed in the health care devices such as the wearable ECG measure equipment.
C1 [Yang, Ching-Yu; Cheng, Lian-Ta] Natl Penghu Univ Sci & Technol, Dept Comp Sci & Informat Engn, 300 Liu Ho Rd, Magong 880, Penghu, Taiwan.
   [Wang, Wen-Fong] Natl Yunlin Univ Sci & Technol, Dept Comp Sci & Informat Engn, 123 Univ Rd,Sect 3, Touliu 64002, Yunlin, Taiwan.
C3 National Penghu University of Science & Technology; National Yunlin
   University Science & Technology
RP Yang, CY (corresponding author), Natl Penghu Univ Sci & Technol, Dept Comp Sci & Informat Engn, 300 Liu Ho Rd, Magong 880, Penghu, Taiwan.
EM chingyu@gms.npu.edu.tw
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Bhalerao S, 2019, PATTERN RECOGN LETT, V125, P463, DOI 10.1016/j.patrec.2019.06.004
   Cox IJ, 2008, DIGITAL WATERMARKING, P2
   FEIG E, 1992, IEEE T SIGNAL PROCES, V40, P2174, DOI 10.1109/78.157218
   Girdhar A, 2018, IET IMAGE PROCESS, V12, P1, DOI 10.1049/iet-ipr.2017.0162
   Guan B, 2020, J VIS COMMUN IMAGE R, V66, DOI 10.1016/j.jvcir.2019.102744
   Hsiao CY, 2018, MULTIMED TOOLS APPL, V77, P30419, DOI 10.1007/s11042-018-6121-3
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Lee YS, 2019, SIGNAL PROCESS-IMAGE, V70, P104, DOI 10.1016/j.image.2018.09.004
   Liang J, 2001, IEEE T SIGNAL PROCES, V49, P3032, DOI 10.1109/78.969511
   Liu S, 2017, IET IMAGE PROCESS, V11, P815, DOI 10.1049/iet-ipr.2016.0862
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Pandey A, 2019, BIOCYBERN BIOMED ENG, V39, P282, DOI 10.1016/j.bbe.2018.11.012
   Pandey A, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0830-4
   Sanivarapu PV, 2020, PHYS ENG SCI MED, V43, P213, DOI 10.1007/s13246-019-00838-2
   Shiu HJ, 2017, COMPUT METH PROG BIO, V151, P159, DOI 10.1016/j.cmpb.2017.08.015
   Swierkosz A, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103401
   Wang H, 2016, MULTIMED TOOLS APPL, V75, P13733, DOI 10.1007/s11042-015-2706-2
   Yang CY, 2016, J MED SYST, V40, DOI 10.1007/s10916-015-0426-9
   Yang CY, 2018, P FUT TECHN C FTC 20, V1, P640
NR 22
TC 4
Z9 4
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24449
EP 24462
DI 10.1007/s11042-020-09100-4
EA JUN 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000542143000005
DA 2024-07-18
ER

PT J
AU Chen, SN
AF Chen, Shih-Nung
TI Real-time interactive micro movie placement marketing system based on
   discrete-event simulation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video retrieval; Content-based image retrieval; Event-driven;
   Discrete-event simulation; Micro movie; Placement marketing
AB The vigorous development of the Internet has made it into an indispensable part of consumers' lives. Many companies and individuals are exploiting online video marketing by establishing brand channels or personal channels in order to voice their own brands, integrate marketing content, expand the scope of publicity, attract more customers, improve the market presence and increase market share to open up greater business opportunities. Placement marketing refers to the natural integration of products into content in an attempt to persuade consumers in a less aggressive way than traditional marketing, lead consumers to unconsciously accept product information, affect consumer decisions and achieve the effect of advertising. If able to more efficiently embed placement marketing content into the large amounts of micro movies can significantly reduce the cost of manpower and money. It will get better viewing or advertising effects. Therefore, this study proposes a real-time interactive micro movie placement marketing system based on discrete-event simulation. The proposed system can use the content in the storyboard, such as the character dialogue, narration, caption, background music, shot changes and scene descriptions, to accurately retrieve micro movie content for event-driven placement marketing of commercial micro movies.
C1 [Chen, Shih-Nung] Asia Univ, Dept Informat Commun, Taichung, Taiwan.
C3 Asia University Taiwan
RP Chen, SN (corresponding author), Asia Univ, Dept Informat Commun, Taichung, Taiwan.
EM nung@asia.edu.tw
CR Ansari Aasif., 2015, International Journal of Computer Applications, V112, P13
   Bargoti Suchet, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3626, DOI 10.1109/ICRA.2017.7989417
   Chen S.-N, 2007, International Journal of Computers & Applications, V29, P239, DOI 10.2316/Journal.202.2007.3.202-1770
   Chen SL, 2016, ENVIRON EARTH SCI, V75, DOI 10.1007/s12665-016-5458-z
   Calvillo AD, 2016, COMM COM INF SC, V597, P125, DOI 10.1007/978-3-319-30447-2_11
   Girshick R., 2015, IEEE I CONF COMP VIS, DOI [DOI 10.1109/ICCV.2015.169, 10.1109/ICCV.2015.169]
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   HALDAR P, 2012, INT J COMPUTER APPL, V48, P25
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang JJ, 2017, IEEE COMPUT SOC CONF, P1067, DOI 10.1109/CVPRW.2017.144
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu XJ, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/1376726
   MISRA J, 1986, COMPUT SURV, V18, P39, DOI 10.1145/6462.6485
   RAJ SN, 2017, INT J COMP SC IT, V8, P163
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   ROUTRAY SK, 2017, 2017 4 INT C ADV COM, P1, DOI DOI 10.1109/ICACCS.2017.8014576
   Shantaiya Sanjivani, 2013, INT J COMPUTER APPL, V65, P14
   SHARMA N, 2011, SIGNAL IMAGE PROCESS, V2, P94, DOI DOI 10.5121/SIPIJ.2011.2108
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tian D.P., 2013, International Journal of Multimedia and Ubiquitous Engineering, V8, P385
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
NR 27
TC 0
Z9 0
U1 4
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34137
EP 34152
DI 10.1007/s11042-020-09104-0
EA JUN 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000541402000006
DA 2024-07-18
ER

PT J
AU Xia, PF
   He, JS
   Yin, J
AF Xia, Pengfei
   He, Jingsong
   Yin, Jin
TI Boosting image caption generation with feature fusion module
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image caption; Feature fusion module; Encoder-decoder model
ID ATTENTION; MODELS
AB Image caption generation has been considered as a key issue on vision-to-language tasks. Using the classification model, such as AlexNet, VGG and ResNet as the encoder to extract image features is very common in previous work. However, there is an explicit gap in image feature requirements between caption task and classification task, and has not been widely concerned. In this paper, we propose a novel custom structure, named feature fusion module (FFM), to make the features extracted by the encoder more suitable for caption task. We evaluate the proposed module with two typical models, NIC (Neural Image Caption) and SA (Soft Attention), on two popular benchmarks, MS COCO and Flickr30k. It is consistently observed that FFM is able to boost the performance, and outperforms state-of-the-art methods over five metrics.
C1 [Xia, Pengfei; He, Jingsong; Yin, Jin] Univ Sci & Technol China, Hefei, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP He, JS (corresponding author), Univ Sci & Technol China, Hefei, Peoples R China.
EM xpengfei@mail.ustc.edu.cn; hjss@ustc.edu.cn; yinjin@mail.ustc.edu.cn
OI Xia, Pengfei/0000-0001-8268-2057; He, Jingsong/0000-0002-5404-0003
CR Anderson Peter, 2018, CVPR, DOI DOI 10.1109/CVPR.2018.00636
   Aneja J, 2018, PROC CVPR IEEE, P5561, DOI 10.1109/CVPR.2018.00583
   [Anonymous], 2014, Transactions of the Association for Computational Linguistics
   [Anonymous], ARXIV150400325
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bai S, NEUROCOMPUTING
   Bernardi R, 2016, J ARTIF INTELL RES, V55, P409, DOI 10.1613/jair.4900
   Biswas P, 2005, I CONF VLSI DESIGN, P651
   Chen C, 2019, AAAI CONF ARTIF INTE, P8142
   Chen Chen L. C. L. C., ARXIV170605587
   Chen L, ARXIV161105594
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Cornia M, ARXIV181110652
   Dai Bo, ARXIV170306029
   Deng J, FEI FEI L IMAGENET L
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He XW, 2019, NEUROCOMPUTING, V328, P48, DOI 10.1016/j.neucom.2018.02.106
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Hossain MZ, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3295748
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang L, 2019, ADV NEUR IN, V32
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Khademi M, 2018, IEEE COMPUT SOC CONF, P2024, DOI 10.1109/CVPRW.2018.00260
   Kinghorn P, 2018, NEUROCOMPUTING, V272, P416, DOI 10.1016/j.neucom.2017.07.014
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Li LH, 2017, AAAI CONF ARTIF INTE, P4133
   Li S, IEEE T EMERGING TOPI, P1
   Li Z, ARXIV180406215
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Mao J., ARXIV14101090
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, P747
   Mnih V, 2014, ADV NEUR IN, V27
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Qiu ZF, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P225, DOI 10.1145/3077136.3080842
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Socher R., 2014, Trans Assoc Comput Linguist, V2, P207, DOI [DOI 10.1162/TACLA00177, 10.1162/tacl_a_00177, DOI 10.1162/TACL_A_00177]
   Sutskever I., 2014, ADV NEURAL INFORM PR, V4, P3104, DOI DOI 10.5555/2969033.2969173
   Tan YH, 2019, NEUROCOMPUTING, V333, P86, DOI 10.1016/j.neucom.2018.12.026
   Tao Y, 2017, CHIN CONTR CONF, P4288, DOI 10.23919/ChiCC.2017.8028032
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang C, 2016, IMAGE CAPTIONING DEE, P988
   Wang Q, 2019, DESCRIBING HUMANS DI, P4195
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang Z, 2016, INT CONF ACOUST SPEE, P3236, DOI 10.1109/ICASSP.2016.7472275
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu HN, 2016, PROC CVPR IEEE, P4584, DOI 10.1109/CVPR.2016.496
   Zhao DX, 2019, NEUROCOMPUTING, V329, P476, DOI 10.1016/j.neucom.2018.11.004
   Zhou FS, 2019, IEEE INT CONF MULTI, P192, DOI 10.1109/ICMEW.2019.00-88
   Zhu XX, 2018, NEUROCOMPUTING, V319, P55, DOI 10.1016/j.neucom.2018.08.069
NR 64
TC 10
Z9 10
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24225
EP 24239
DI 10.1007/s11042-020-09110-2
EA JUN 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000541201200003
DA 2024-07-18
ER

PT J
AU Ibrahim, AU
   Al-Turjman, F
   Sa'id, Z
   Ozsoz, M
AF Ibrahim, Abdullahi Umar
   Al-Turjman, Fadi
   Sa'id, Zubaida
   Ozsoz, Mehmet
TI Futuristic CRISPR-based biosensing in the cloud and internet of things
   era: an overview
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CRISPR; Cas system; Biosensor; IIoT; Cloud; Big data
ID NUCLEIC-ACID DETECTION; VIRUS DETECTION; IMMUNE-SYSTEM; BACTERIA;
   INTELLIGENCE; COMPUTATION; DIAGNOSTICS; EFFICIENCY; SECURITY; DATABASE
AB Biosensors-based devices are transforming medical diagnosis of diseases and monitoring of patient signals. The development of smart and automated molecular diagnostic tools equipped with biomedical big data analysis, cloud computing and medical artificial intelligence can be an ideal approach for the detection and monitoring of diseases, precise therapy, and storage of data over the cloud for supportive decisions. This review focused on the use of machine learning approaches for the development of futuristic CRISPR-biosensors based on microchips and the use of Internet of Things for wireless transmission of signals over the cloud for support decision making. The present review also discussed the discovery of CRISPR, its usage as a gene editing tool, and the CRISPR-based biosensors with high sensitivity of Attomolar (10(-18)M), Femtomolar (10(-15)M) and Picomolar (10(-12)M) in comparison to conventional biosensors with sensitivity of nanomolar 10(-9)M and micromolar 10(-3)M. Additionally, the review also outlines limitations and open research issues in the current state of CRISPR-based biosensing applications.
C1 [Ibrahim, Abdullahi Umar; Sa'id, Zubaida; Ozsoz, Mehmet] Near East Univ, Dept Biomed Engn, 10 Mersin, Nicosia, Turkey.
   [Al-Turjman, Fadi] Near East Univ, Dept Artificial Intelligence, 10 Mersin, Nicosia, Turkey.
C3 Near East University; Near East University
RP Ibrahim, AU (corresponding author), Near East Univ, Dept Biomed Engn, 10 Mersin, Nicosia, Turkey.
EM Abdullahi.umaribrahim@neu.edu.tr; fadi.alturjman@neu.edu.tr;
   zubaidas11@gmail.com; mehmet.ozsoz@neu.edu.tr
RI Ozsoz, Mehmet Emin Sengun/AAZ-1285-2020; Al-Turjman, Fadi/L-2998-2019;
   Nasarian, Elham/ISB-6863-2023; Al-Turjman, Fadi/C-7891-2019; Ameen,
   Zubaida/ACT-3433-2022; Ibrahim, Abdullahi Umar/ACB-2170-2022
OI Al-Turjman, Fadi/0000-0001-5418-873X; Al-Turjman,
   Fadi/0000-0001-6375-4123; Ameen, Zubaida/0000-0003-3364-9263; ozsoz,
   mehmet/0000-0003-4037-3445
CR Abdelhamid HN, 2013, J MATER CHEM B, V1, P3950, DOI 10.1039/c3tb20413h
   Abudayyeh OO, 2019, CRISPR J, V2, P69, DOI 10.1089/crispr.2019.29053.oma
   Abudayyeh OO, 2016, SCIENCE, V353, DOI 10.1126/science.aaf5573
   Adli M, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04252-2
   AILENI RM, 2015, 2015 IEEE INT C PLAS, P1
   Al-Turjman Fadi M., 2016, 2016 23rd Iranian Conference on Biomedical Engineering and 2016 1st International Iranian Conference on Biomedical Engineering (ICBME), P102, DOI 10.1109/ICBME.2016.7890938
   Al-Turjman F, 2020, COMPUT COMMUN, V150, P644, DOI 10.1016/j.comcom.2019.12.030
   Al-Turjman F, 2020, FUTURE GENER COMP SY, V102, P357, DOI 10.1016/j.future.2019.08.009
   Al-Turjman F, 2019, IEEE ACCESS, V7, P115749, DOI 10.1109/ACCESS.2019.2931637
   Al-Turjman F, 2018, IEEE T IND INFORM, V14, P2736, DOI 10.1109/TII.2018.2808190
   ALTURJMAN F, T EMERGING TELECOMMU, pE3635
   [Anonymous], 2016, P IJCAI WORKSH KNOWL
   Baeumner AJ, 2002, ANAL CHEM, V74, P1442, DOI 10.1021/ac015675e
   Baltimore D, 2015, SCIENCE, V348, P36, DOI 10.1126/science.aab1028
   Barrangou R, 2007, SCIENCE, V315, P1709, DOI 10.1126/science.1138140
   Batista AC, 2018, J MICROBIOL METH, V152, P98, DOI 10.1016/j.mimet.2018.07.024
   Bellazzi R, 2014, Yearb Med Inform, V9, P8, DOI 10.15265/IY-2014-0024
   Bhaya D, 2011, ANNU REV GENET, V45, P273, DOI 10.1146/annurev-genet-110410-132430
   Brey P., 2007, Security, Privacy, and Trust in Modern Data Management, DOI DOI 10.1007/978-3-540-69861-6_3
   Brownlee Jason, 2016, Machine Learning, VMastery
   Bruch R, 2019, ADV MATER, V31, DOI 10.1002/adma.201905311
   Carroll D, 2016, ADV EXP MED BIOL, V895, P15, DOI 10.1007/978-1-4939-3509-3_2
   Chang E.Y., 2017, Proceedings of the 2nd International Workshop on Multimedia for Personal Health and Health Care pp, P11
   Ching T, 2018, J R SOC INTERFACE, V15, DOI 10.1098/rsif.2017.0387
   Daaboul GG, 2012, IEEE J SEL TOP QUANT, V18, P1422, DOI 10.1109/JSTQE.2011.2180516
   Dai YF, 2019, ANGEW CHEM INT EDIT, V58, P17399, DOI 10.1002/anie.201910772
   Daniel R, 2013, NATURE, V497, P619, DOI 10.1038/nature12148
   Das A, 2018, NEURAL NETWORKS, V99, P134, DOI 10.1016/j.neunet.2017.12.015
   Diouani MF, 2008, MAT SCI ENG C-BIO S, V28, P580, DOI 10.1016/j.msec.2007.10.043
   Doudna JA, 2014, SCIENCE, V346, P1077, DOI 10.1126/science.1258096
   Duan N, 2015, MICROCHIM ACTA, V182, P917, DOI 10.1007/s00604-014-1406-3
   East-Seletsky A, 2016, NATURE, V538, P270, DOI 10.1038/nature19802
   Eid A, 2016, EXP MOL MED, V48, DOI 10.1038/emm.2016.111
   Fan YJ, 2014, IEEE T IND INFORM, V10, P1568, DOI 10.1109/TII.2014.2302583
   Farzadfard F, 2018, SCIENCE, V361, P870, DOI 10.1126/science.aat9249
   Garneau JE, 2010, NATURE, V468, P67, DOI 10.1038/nature09523
   Gootenberg JS, 2018, SCIENCE, V360, P439, DOI 10.1126/science.aaq0179
   Guan C, 2017, INORG CHEM, V56, P438, DOI 10.1021/acs.inorgchem.6b02334
   Hajian R, 2019, NAT BIOMED ENG, V3, P427, DOI 10.1038/s41551-019-0371-x
   Heather JM, 2016, GENOMICS, V107, P1, DOI 10.1016/j.ygeno.2015.11.003
   Hendel A, 2014, CELL REP, V7, P293, DOI 10.1016/j.celrep.2014.02.040
   Hodgkins A, 2015, BIOINFORMATICS, V31, P3078, DOI 10.1093/bioinformatics/btv308
   Horvath P, 2010, SCIENCE, V327, P167, DOI 10.1126/science.1179555
   Hsu PD, 2014, CELL, V157, P1262, DOI 10.1016/j.cell.2014.05.010
   Huang MQ, 2018, ANAL CHEM, V90, P2193, DOI [10.1021/acs.analchem.7604542, 10.1021/acs.analchem.7b04542]
   Ishino Y, 2018, J BACTERIOL, V200, DOI 10.1128/JB.00580-17
   Jacob S, 2019, IEEE ACCESS, V7, P133463, DOI 10.1109/ACCESS.2019.2941491
   Jatmiko W, 2016, 2016 INTERNATIONAL WORKSHOP ON BIG DATA AND INFORMATION SECURITY (IWBIS), P31, DOI 10.1109/IWBIS.2016.7872886
   Jiang FG, 2017, ANNU REV BIOPHYS, V46, P505, DOI 10.1146/annurev-biophys-062215-010822
   Jinek M, 2012, SCIENCE, V337, P816, DOI 10.1126/science.1225829
   Jones VM, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P824
   Kanaparthi S, 2019, ADVANCED BIOSENSORS FOR HEALTH CARE APPLICATIONS, P209, DOI 10.1016/B978-0-12-815743-5.00007-X
   Kaushik A, 2017, TRENDS BIOTECHNOL, V35, P308, DOI 10.1016/j.tibtech.2016.10.001
   Kavakiotis I, 2017, COMPUT STRUCT BIOTEC, V15, P104, DOI 10.1016/j.csbj.2016.12.005
   Knott GJ, 2018, SCIENCE, V361, P866, DOI 10.1126/science.aat5011
   Koo B, 2018, SENSOR ACTUAT B-CHEM, V273, P316, DOI 10.1016/j.snb.2018.06.069
   Koonin EV, 2017, CURR OPIN MICROBIOL, V37, P67, DOI 10.1016/j.mib.2017.05.008
   Kosicki M, 2018, NAT BIOTECHNOL, V36, P765, DOI 10.1038/nbt.4192
   Lazcka O, 2007, BIOSENS BIOELECTRON, V22, P1205, DOI 10.1016/j.bios.2006.06.036
   Lenoir WF, 2018, NUCLEIC ACIDS RES, V46, pD776, DOI 10.1093/nar/gkx993
   Li SY, 2018, CELL DISCOV, V4, DOI 10.1038/s41421-018-0028-z
   Li Y, 2019, TRENDS BIOTECHNOL, V37, P792, DOI 10.1016/j.tibtech.2019.04.012
   Li Y, 2019, TRENDS BIOTECHNOL, V37, P730, DOI 10.1016/j.tibtech.2018.12.005
   Li Y, 2015, GENOME BIOL, V16, DOI 10.1186/s13059-015-0640-2
   Liu F, 2011, BIOCHIP J, V5, P123, DOI 10.1007/s13206-011-5204-2
   Liu XB, 2016, BIOSENS BIOELECTRON, V80, P9, DOI 10.1016/j.bios.2016.01.041
   Liu X, 2017, ACTA PHARM SIN B, V7, P292, DOI 10.1016/j.apsb.2017.01.002
   Ma XL, 2015, MOL PLANT, V8, P1274, DOI 10.1016/j.molp.2015.04.007
   Ma'sum MA, 2016, 2016 INTERNATIONAL WORKSHOP ON BIG DATA AND INFORMATION SECURITY (IWBIS), P121, DOI 10.1109/IWBIS.2016.7872900
   Makarova KS, 2017, CELL, V168, P946, DOI [10.1016/j.cell.2016.12.038, 10.1016/j.cell.2017.02.018]
   Mannoor MS, 2010, P NATL ACAD SCI USA, V107, P19207, DOI 10.1073/pnas.1008768107
   Mastoi QU, 2018, CARDIOL RES PRACT, V2018, DOI 10.1155/2018/2016282
   Miranda OR, 2011, J AM CHEM SOC, V133, P9650, DOI 10.1021/ja2021729
   Mohanty S., 2013, BIG DATA IMPERATIVES
   Myhrvold C, 2018, SCIENCE, V360, P444, DOI 10.1126/science.aas8836
   Nayak M, 2009, BIOSENS BIOELECTRON, V25, P661, DOI 10.1016/j.bios.2009.08.037
   Nehal Shaikh Afzal, 2020, International Journal of Information Technology, V12, P495, DOI 10.1007/s41870-019-00363-1
   Novak S, 2019, METHODS MOL BIOL, V1864, P295, DOI 10.1007/978-1-4939-8778-8_20
   Paiva JS, 2018, INT J MED INFORM, V109, P30, DOI 10.1016/j.ijmedinf.2017.10.011
   Pardee K, 2016, CELL, V165, P1255, DOI 10.1016/j.cell.2016.04.059
   Park J, 2016, BIOINFORMATICS, V32, P2017, DOI 10.1093/bioinformatics/btw103
   Radke SM, 2004, IEEE SENS J, V4, P434, DOI 10.1109/JSEN.2004.830300
   RAUSCHER B, 2016, NUCLEICAACIDS RES
   Tarouco LMR, 2012, IEEE ICC, P6121, DOI 10.1109/ICC.2012.6364830
   Rowley T, 2013, LAB ANIMAL, V42, P8, DOI 10.1038/laban.208
   Rubens JR, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms11658
   Savaliya R, 2015, CURR DRUG METAB, V16, P645, DOI 10.2174/1389200216666150625121546
   Sheth RU, 2018, NAT REV GENET, V19, P718, DOI 10.1038/s41576-018-0052-8
   Song GY, 2016, CROP J, V4, P75, DOI 10.1016/j.cj.2015.12.002
   Stefano GB, 2017, MED SCI MONITOR, V23, P3168, DOI 10.12659/MSM.905800
   Toga AW, 2015, J AM MED INFORM ASSN, V22, P1126, DOI 10.1093/jamia/ocv077
   Quan TM, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2019), P201, DOI [10.1109/aicas.2019.8771604, 10.1109/AICAS.2019.8771604]
   Ulusar UD, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P506, DOI 10.1109/UBMK.2017.8093446
   Uppada V, 2018, GENE, V656, P22, DOI 10.1016/j.gene.2018.02.066
   van der Woude MW, 2004, CLIN MICROBIOL REV, V17, P581, DOI 10.1128/CMR.17.3.581-611.2004
   Vashistha R, 2018, 3 BIOTECH, V8, DOI 10.1007/s13205-018-1368-y
   Villard A, 2015, J CLEAN PROD, V86, P98, DOI 10.1016/j.jclepro.2014.08.061
   Ye LP, 2018, CELL DISCOV, V4, DOI 10.1038/s41421-018-0049-7
   Yin YH, 2016, J IND INF INTEGR, V1, P3, DOI 10.1016/j.jii.2016.03.004
   Ymeti A, 2007, TRAC-TREND ANAL CHEM, V26, pIII, DOI 10.1021/nl062595n
   Zhang GJ, 2010, SENSOR ACTUAT B-CHEM, V146, P138, DOI 10.1016/j.snb.2010.02.021
   Zhang Y. H., 2016, NANOMATERIALS, V6, P2, DOI DOI 10.1021/acssynbio.6b00215
   Zhou JP, 2017, FRONT PLANT SCI, V8, DOI 10.3389/fpls.2017.01598
NR 103
TC 30
Z9 30
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 35143
EP 35171
DI 10.1007/s11042-020-09010-5
EA JUN 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000538977700007
PM 32837247
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Zhao, XM
   Wang, XX
   Cheng, D
AF Zhao, XiaoMing
   Wang, Xinxin
   Cheng, De
TI A model of co-saliency based audio attention
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spectrogram; Auditory saliency; Co-saliency; Sound detection
ID AUDITORY SALIENCE; INTEGRATION; DEEP
AB Inspired by biological perceptual characteristics in human auditory systems and the mechanisms of saliency detection, we study the relevance constraint between time-frequency characteristics of sound signals and the multiple spectrogram and propose a co-saliency detection method for multiple sound signals in this paper. Then, according to the auditory characteristics of the human ear, the distinctive saliency features from the acoustic channel and the image channel are fused. Finally, an auditory saliency map is obtained to complete the detection of significant sounds. The saliency features of the acoustic channel include the features calculated in the in the temporal and spectral domains of signal, which the temporal saliency features could be represented by the local maximum points in the Power Spectral Density (PSD) curve, and the spectral features could be represented by local maximum points in Mel Frequency Cepstrum Coefficient (MFCC) curve of sound signal. The saliency features of acoustic channel and cross-scale fusion with the contrast cue of spectrogram, whose result is more in line with the human auditory attention mechanism. Finally, combined with the corresponding cue which could reflect the distribution between multiple spectrograms, it could reflect the characteristics of global repeatability, and reflect high frequency of occurrence. Experimentally, the auditory Co-Saliency map verifies the accuracy and robustness of proposed method in this paper. It shows that the proposed method is superior to other traditional detection methods for auditory saliency, and can implement intelligent automatic detection to sound signals.
C1 [Zhao, XiaoMing; Wang, Xinxin] Luoyang Inst Sci & Technol, Luoyang, Peoples R China.
   [Cheng, De] Huawei Technol Co Ltd, Shenzhen, Peoples R China.
C3 Luoyang Institute of Science & Technology; Huawei Technologies
RP Wang, XX (corresponding author), Luoyang Inst Sci & Technol, Luoyang, Peoples R China.
EM 13643895183@163.com; 02xiaoxin02@163.com; chengde@huawei.com
RI zhao, xiaoming/IVU-6747-2023
OI zhao, xiaoming/0000-0001-7992-1045
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2007, INT C NEUR INF PROC
   Badshah A. M., 2017, INT C PLATF TECHN SE
   Badshah AM, 2019, MULTIMED TOOLS APPL, V78, P5571, DOI 10.1007/s11042-017-5292-7
   Cano P, 2002, REV ALGORITHMS AUDIO
   Cao XC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P997, DOI 10.1145/2647868.2655007
   Chang KY, 2011, PROC CVPR IEEE
   Chen M, 2017, MULTIMEDIA TOOLS AND
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cooke M., 1993, MODELLING AUDITORY P
   Darabi K, 2017, MULTIMED TOOLS APPL, V76, P2353, DOI 10.1007/s11042-015-3210-4
   Duangudom V, 2015, EUR SIGN PROC C
   Fu HZ, 2015, IEEE T IMAGE PROCESS, V24, P3415, DOI 10.1109/TIP.2015.2442915
   Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166
   Ge CJ, 2016, SIGNAL PROCESS-IMAGE, V44, P69, DOI 10.1016/j.image.2016.03.005
   Han JW, 2018, IEEE T CIRC SYST VID, V28, P2473, DOI 10.1109/TCSVT.2017.2706264
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Hou X, 2009, IEEE COMPUTER SOC C
   Hsu KJ, 2018, LECT NOTES COMPUT SC, V11209, P502, DOI 10.1007/978-3-030-01228-1_30
   Huang N, 2017, J ACOUST SOC AM, V141, P2163, DOI 10.1121/1.4979055
   Huang ZW, 2017, MULTIMED TOOLS APPL, V76, P6785, DOI 10.1007/s11042-016-3354-x
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Jacobs DE, 2010, ACM S US INT SOFTW T
   Kalinli O, 2007, INTERSPEECH
   Kaya EM, 2012, INFORM SCI SYSTEMS
   Kayser C, 2005, CURR BIOL, V15, P1943, DOI 10.1016/j.cub.2005.09.040
   Kim K, 2014, PATTERN RECOGN LETT, V38, P78, DOI 10.1016/j.patrec.2013.11.010
   Kleinschmidt M, 2002, ACTA ACUST UNITED AC, V88, P416
   Kumar K, 2011, IEEE INT C AC
   Lang C, 2012, ECCV, V2
   Lee DK, 1999, NAT NEUROSCI, V2, P375, DOI 10.1038/7286
   Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803
   Li YJ, 2015, IEEE SIGNAL PROC LET, V22, P588, DOI 10.1109/LSP.2014.2364896
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112
   Navalpakkam V, 2005, VISION RES, V45, P205, DOI 10.1016/j.visres.2004.07.042
   Petit C, 2016, AUDITION HEARING DEA
   Platt J, 2006, INT C NEUR INF PROC
   Sarkar R, 2020, MULTIMED TOOLS APPL, V79, P765, DOI 10.1007/s11042-019-08192-x
   Schreiner CE, 2000, ANNU REV NEUROSCI, V23, P501, DOI 10.1146/annurev.neuro.23.1.501
   Tao XU, 2017, ROBOT
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Venkitaraman A, 2014, SIGNAL PROCESS, V94, P608, DOI 10.1016/j.sigpro.2013.07.029
   Wang J, 2014, TECN IEEE REG 10 C
   Wang JY, 2015, NEUROCOMPUTING, V152, P444, DOI 10.1016/j.neucom.2014.09.046
   Xie Y, 2019, MULTIMEDIA TOOLS APP
   Yin H, 2011, SPEECH COMMUN, V53, P707, DOI 10.1016/j.specom.2010.04.008
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang D., 2016, REV COSALIENCY DETEC
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang DW, 2016, IEEE T NEUR NET LEAR, V27, P1163, DOI 10.1109/TNNLS.2015.2495161
   Zhang QY, 2019, MULTIMED TOOLS APPL, V78, P17825, DOI 10.1007/s11042-019-7180-9
   Zhang Y., 2013, ELECTROMAGN ANAL APP, V02, P31, DOI 10.12677/eaa.2013.23005
NR 55
TC 3
Z9 3
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23045
EP 23069
DI 10.1007/s11042-020-09020-3
EA JUN 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000538227500001
DA 2024-07-18
ER

PT J
AU Parvathy, DP
   Subramaniam, K
AF Parvathy, D. Priyanka
   Subramaniam, Kamalraj
TI Rapid speedup segment analysis based feature extraction for hand gesture
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human Computer Interaction; multi resolution coiflets wavelet transform;
   Radial basis neural network; Cambridge hand gesture
AB The dependency on computers and machines have progressively increased in the past few years and hence human interaction with computers is one of the most actively researched area in science. Many Hand Gesture Recognition (HGR) systems have been developed and they continue to evolve, where in which the gesture interaction becomes smoother and smarter. Gesture recognition is usually implemented in three phases- gesture segmentation, feature extraction and gesture classification, and it's important that the processes involved in these stages are chosen appropriately such that the misrecognition rate will be kept to a minimum. This paper has proposed a novel algorithm that combines 2D-Discrete Wavelet Transform along with Speed Up Robust Feature (SURF) extraction technique to achieve a robust HGR system that is rotation and scale invariant. The proposed method has achieved an overall classification accuracy of 96.9% with the Radial Basis Function Neural Network (RBFNN) classifier.
C1 [Parvathy, D. Priyanka] Karpagam Acad Higher Educ, Dept CSE, Coimbatore, Tamil Nadu, India.
   [Subramaniam, Kamalraj] Karpagam Acad Higher Educ, Dept ECE, Coimbatore, Tamil Nadu, India.
C3 Karpagam Academy of Higher Education (KAHE); Karpagam Academy of Higher
   Education (KAHE)
RP Parvathy, DP (corresponding author), Karpagam Acad Higher Educ, Dept CSE, Coimbatore, Tamil Nadu, India.
EM priyankaparvathy@yahoo.com
RI Subramaniam, Kamalraj/B-4069-2019
CR Agarwal R, SIGNAL PROCESSING IN
   [Anonymous], 2011, ICICS
   Aowal A, 2014, IEEE C TENCON
   Asad M, 2013, IEEE IMAGE PROC, P3735, DOI 10.1109/ICIP.2013.6738770
   Athavale S, 2014, INT J ENG RES GEN SC, V2, P2
   BEYLKIN G, 1991, COMMUN PUR APPL MATH, V44, P141, DOI 10.1002/cpa.3160440202
   Bibby C, 2006, INT WORKSH MOB VIS
   Collumeau L, 2012, INT C IM PROC THEOR
   Dardas NH, 2011, IEEE T INSTRUM MEAS, V60, P3592, DOI 10.1109/TIM.2011.2161140
   Dzyubachyk O, 2008, I S BIOMED IMAGING, P185, DOI 10.1109/ISBI.2008.4540963
   Gupta SM, 2002, IEEE T SYST MAN CYB, V31, P1
   Haar A, 1910, MATH ANN, V69, P331, DOI 10.1007/BF01456326
   Jena NR, 2011, PHYS BIOL, V8, DOI 10.1088/1478-3975/8/4/046007
   Jiang MW, ENG MED BIOL SOC IEE
   Keskin C, REAL TIME HAND TRACK
   Khaled H, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/741068
   Khan RZ, 2012, INT J ARTITICIAL INT, V3, P4
   Lionnie R, 2012, J ICT RES APPL, V6, P183, DOI 10.5614/itbj.ict.2012.6.3.1
   Michiel Hazewinkel:., 2001, Encyclopedia of Mathematics
   Moody J, 1989, NEURAL COMPUT, P284
   Padmavathi G, 2009, SENSORS, SIGNALS, VISUALIZATION, IMAGING, SIMULATION AND MATERIALS, P199
   Paulraj MP, 2012, 2012 IEEE EMBS INT C
   Porwik P, LECT NOTES COMPUTER, V3039, P1
   Rautaray SS, 2012, INT J UBICOMP IJU, V3, P1
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Song W., 2014, LECT NOTES ELECT ENG, V309, P485
   Xie R, 2015, IEEE SENS J, V15, P6
   Yang Z, 2012, INT C COMP SCI ED IC
   Yu C, 2010, INT C INT INT INF HI
   Zhu Ningbo., 2009, 2009 Chinese conference on pattern recognition, P1
NR 31
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16987
EP 17002
DI 10.1007/s11042-019-7528-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600065
DA 2024-07-18
ER

PT J
AU Saeed, F
   Paul, A
   Hong, WH
   Seo, H
AF Saeed, Faisal
   Paul, Anand
   Hong, Won Hwa
   Seo, Hyuncheol
TI Machine learning based approach for multimedia surveillance during fire
   emergencies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Multimedia surveillance; CNN; Fire detection
ID ADABOOST ALGORITHM; FLAME DETECTION; NEURAL-NETWORK; OPTIMIZATION;
   INTERNET
AB Video based surveillance of manmade disasters such as fire has become very hot topic in research and it is playing an important role in the development of smart environment. The disasters like fire cause many economic and social damages. We can prevent these damages by early detection of the fire. The current advancement in embedded processing have permitted the detection of fire using vision-based i.e. Convolutional Neural Networks (CNNs) for the surveillance. Therefore, we proposed a method using machine learning techniques for Multimedia Surveillance during fire emergencies. Our proposed model has two main deep neural networks models. Firstly, we used a hybrid model made of Adaboost and many Mulit-layer perceptron (MLP) neural networks. The purpose of hybrid Adaboost-MLP model is to predict fire efficiently. This model used different sensors data like smoke, heat, and gas for training. After predicting the fire, we proposed a CNN model to detect the fire immediately. These results show that our trained model has near 91% fire detection accuracy. We can the false positive results are quite low. These results can be improved more by further training.
C1 [Saeed, Faisal; Paul, Anand] Kyungpook Natl Univ, Dept Comp Sci & Engn, Daegu 702701, South Korea.
   [Hong, Won Hwa; Seo, Hyuncheol] Kyungpook Natl Univ, Sch Architectural Civil Environm & Energy Engn, Daegu 702701, South Korea.
C3 Kyungpook National University; Kyungpook National University
RP Paul, A (corresponding author), Kyungpook Natl Univ, Dept Comp Sci & Engn, Daegu 702701, South Korea.
EM bscsfaisal821@gmail.com; paul.editor@gmail.com; hongwh@knu.ac.kr;
   notsools@gmail.com
RI Saeed, Faisal/HNT-0710-2023; Paul, Anand/V-6724-2017; Seo,
   Hyuncheol/ABC-5117-2020
OI Saeed, Faisal/0000-0002-2822-1708; Paul, Anand/0000-0002-0737-2021;
   Paul, Anand/0000-0003-3115-2325; Seo, HyunCheol/0000-0002-3361-2316
CR Abdel-Basset M, 2018, PERS UBIQUIT COMPUT, V22, P1117, DOI 10.1007/s00779-018-1132-7
   Abdel-Basset M, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.4515
   Abdul R, 2018, ENERGIES, V11, DOI 10.3390/en11082089
   [Anonymous], 1989, P ADV NEURAL INFORM
   [Anonymous], 2018, GAS EXPL HARL BLOWS
   [Anonymous], 2018, PAR ATT
   [Anonymous], 2011, 22 INT JT C ART INT, DOI 10.5555/2283516.2283603
   [Anonymous], 2013, P ICML
   Anwar S, 2015, INT CONF ACOUST SPEE, P1131, DOI 10.1109/ICASSP.2015.7178146
   Celik T, 2007, 15 EUR SIGN PROC C E, P1794
   Çelik T, 2009, FIRE SAFETY J, V44, P147, DOI 10.1016/j.firesaf.2008.05.005
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chen TH, 2004, IEEE IMAGE PROC, P1707
   Chino DYT, 2015, SIBGRAPI, P95, DOI 10.1109/SIBGRAPI.2015.19
   Di Lascio R, 2014, LECT NOTES COMPUT SC, V8814, P477, DOI 10.1007/978-3-319-11758-4_52
   Foggia P, 2015, IEEE T CIRC SYST VID, V25, P1545, DOI 10.1109/TCSVT.2015.2392531
   Fraustino J. D., 2012, Social media use during disasters: A review of the knowledge base and gaps
   FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Guo L, 2012, EXPERT SYST APPL, V39, P4274, DOI 10.1016/j.eswa.2011.09.106
   Habiboglu YH, 2012, MACH VISION APPL, V23, P1103, DOI 10.1007/s00138-011-0369-1
   HUBEL DH, 1977, PROC R SOC SER B-BIO, V198, P1, DOI 10.1098/rspb.1977.0085
   Jiang B, 2017, J VIS COMMUN IMAGE R, V48, P356, DOI 10.1016/j.jvcir.2017.02.011
   Kantorov V, 2016, LECT NOTES COMPUT SC, V9909, P350, DOI 10.1007/978-3-319-46454-1_22
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liu H, 2015, ENERG CONVERS MANAGE, V92, P67, DOI 10.1016/j.enconman.2014.12.053
   Luo P, 2014, PROC CVPR IEEE, P899, DOI 10.1109/CVPR.2014.120
   Mueller M, 2013, IEEE T IMAGE PROCESS, V22, P2786, DOI 10.1109/TIP.2013.2258353
   Paul A, 2016, IEEE WIREL COMMUN, V23, P68, DOI 10.1109/MWC.2016.7721744
   Paul A, 2017, IEEE SYST J, V11, P1249, DOI 10.1109/JSYST.2015.2411856
   Paul A, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2423636.2423643
   Paul A, 2012, ACM T EMBED COMPUT S, V11, DOI 10.1145/2331147.2331149
   Rafei M, 2014, NEURAL NETW WORLD, V24, P31, DOI 10.14311/NNW.2014.24.002
   Rehman A, 2018, IET INTELL TRANSP SY, V12, P594, DOI 10.1049/iet-its.2017.0308
   Saeed F, 2018, J SENS ACTUAR NETW, V7, DOI 10.3390/jsan7010011
   Xu B, 2015, EMPIRICAL EVALUATION, DOI [10.1016/S0266-8920(98)00020-4, DOI 10.1016/S0266-8920(98)00020-4]
   Yang JC, 2017, IEEE T IND INFORM, V13, P2350, DOI 10.1109/TII.2017.2657545
   Zhang WL, 2015, NEUROIMAGE, V108, P214, DOI 10.1016/j.neuroimage.2014.12.061
NR 38
TC 16
Z9 17
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16201
EP 16217
DI 10.1007/s11042-019-7548-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600022
DA 2024-07-18
ER

PT J
AU Ural, B
   Ozisik, P
   Hardalac, F
AF Ural, Berkan
   Ozisik, Pinar
   Hardalac, Firat
TI An improved computer based diagnosis system for early detection of
   abnormal lesions in the brain tissues with using magnetic resonance and
   computerized tomography images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer-aided medical diagnosis systems; Abnormality detection and
   localization; Classification of brain masses; Deep learning; Artificial
   intelligence
ID INTRACEREBRAL HEMORRHAGE; SEGMENTATION; CHEMOTHERAPY; VALIDITY;
   CRITERIA; MRI
AB Detection of masses can be a challenging task for radiologists and physicians. Manual tumor diagnosis in the brain is sometimes a time consuming process and can be insufficient for fast and accurate detection and interpretation. This study introduces an improved interface-supported early diagnosis system to increase the speed and accuracy for supporting the traditional methods. The first stage in the system involves collecting information from the brain tissue, and assessing whether it is normal or abnormal through the processing of Magnetic Resonance Imaging (MRI) and Computerized Tomography (CT) images. The next stage involves gathering results from the image(s) after the single/multiple and volumetric and multiscale image analysis. The other stage involves Feature Extraction for some cases and making an interpretation about the abnormal Region of Interest (ROI) area via Deep Learning and conventional Artificial Intelligence methods is the last stage. The output of the system is mainly the name of the mass type which was introduced to the network. The results were obtained for totally 300 images for High-Grade Glioma (HGG), Low-Grade Glioma (LGG), Glioblastoma (GBM), Meningioma as well as Ischemic and Hemorrhagic stroke. For the cases, the DICE score was obtained as 0.927 and the normal/abnormal differentiation of the brain tissues was also achieved successfully. Finally, this system can give a chance to the doctors for supporting the results, speeding up the diagnosis process and also decreasing the rate of possible misdiagnosis.
C1 [Ural, Berkan; Hardalac, Firat] Gazi Univ, Dept Elect Elect Engn Biomed, Ankara, Turkey.
   [Ozisik, Pinar] TOBB ETU, Fac Med Neurosurg, Ankara, Turkey.
C3 Gazi University; TOBB Ekonomi ve Teknoloji University
RP Ural, B (corresponding author), Gazi Univ, Dept Elect Elect Engn Biomed, Ankara, Turkey.
EM uralberkan@gmail.com
RI URAL, ALi BERKAN/ABS-6458-2022
OI URAL, ALi BERKAN/0000-0001-5176-9280; OZISIK, PINAR/0000-0001-5183-8100
CR [Anonymous], 2015, IEEE T AUTOM SCI ENG
   [Anonymous], 2017, Nature Scientific Data
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], 2013, JMIR
   [Anonymous], 2011, 2011 INT S INTELLIGE
   [Anonymous], 2012, INT J LATEST RES SCI
   [Anonymous], 2016, J TELECOMMUN ELECT C
   [Anonymous], SIMPLE METHOD DETECT
   [Anonymous], MED IMAGE ANAL
   [Anonymous], 2017, J MED BIOL ENG
   Bagher-Ebadian H, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0022626
   Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117
   Banerjee S, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146388
   BOITEN J, 1991, STROKE, V22, P1374, DOI 10.1161/01.STR.22.11.1374
   Bray F, 2002, EUR J CANCER, V38, P99, DOI 10.1016/S0959-8049(01)00350-1
   CAIRNCROSS JG, 1988, ANN NEUROL, V23, P360, DOI 10.1002/ana.410230408
   De Vries LS, 2005, NEUROPEDIATRICS, V36, P12, DOI 10.1055/s-2005-837544
   DeAngelis LM, 2001, NEW ENGL J MED, V344, P114, DOI 10.1056/NEJM200101113440207
   Duta N, 1998, IEEE T MED IMAGING, V17, P1049, DOI 10.1109/42.746716
   Fiebach JB, 2004, STROKE, V35, P502, DOI 10.1161/01.STR.0000114203.75678.88
   Field P, 2001, J NEUROSURG, V94, P545, DOI 10.3171/jns.2001.94.4.0545
   Gargouri F, 2014, 2014 1ST INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP 2014), P209, DOI 10.1109/ATSIP.2014.6834608
   GonzalezVelez V, 1997, COMP MED SY, P167, DOI 10.1109/CBMS.1997.596428
   Gopal N. N., 2010, 2010 IEEE INT C COMP, P1
   Hardell L, 2006, INT J ONCOL, V28, P509
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   HOFFMAN HJ, 1980, NEUROSURGERY, V7, P243, DOI 10.1227/00006123-198009000-00007
   Ireland D, 2011, PROG ELECTROMA RES M, V21, P163, DOI 10.2528/PIERM11082907
   Jeena RS, 2013, PROCEEDINGSINTERNATI, P1
   Kidwell CS, 2004, JAMA-J AM MED ASSOC, V292, P1823, DOI 10.1001/jama.292.15.1823
   Kistler M, 2013, J MED INTERNET RES, V15, DOI 10.2196/jmir.2930
   Klöppel S, 2008, BRAIN, V131, P681, DOI 10.1093/brain/awm319
   KUNDU A, 1990, COMPUT MED IMAG GRAP, V14, P173, DOI 10.1016/0895-6111(90)90057-I
   Lefohn AE, 2003, LECT NOTES COMPUT SC, V2878, P564
   LEVIN VA, 1977, J NEUROSURG, V47, P329, DOI 10.3171/jns.1977.47.3.0329
   Liebeskind DS, 2003, STROKE, V34, P2279, DOI 10.1161/01.STR.0000086465.41263.06
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Menze B.H., IEEE Trans. Med. Imag.
   Meyers CA, 1998, J CLIN ONCOL, V16, P2522, DOI 10.1200/JCO.1998.16.7.2522
   Minniti G, 2018, PITUITARY, V21, P154, DOI 10.1007/s11102-018-0868-4
   Mitra S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187209
   Packard AS, 2003, ARCH NEUROL-CHICAGO, V60, P1156, DOI 10.1001/archneur.60.8.1156
   Patel MR, 1996, STROKE, V27, P2321, DOI 10.1161/01.STR.27.12.2321
   RAYA SP, 1990, IEEE T MED IMAGING, V9, P327, DOI 10.1109/42.57771
   Reddy GR, 2006, CLIN CANCER RES, V12, P6677, DOI 10.1158/1078-0432.CCR-06-0946
   Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747
   ZELTZER PM, 1985, CANCER, V56, P1824, DOI 10.1002/1097-0142(19851001)56:7+<1824::AID-CNCR2820561321>3.0.CO;2-H
   Zhang ST, 2018, EUR RADIOL, V28, P3692, DOI 10.1007/s00330-017-5180-6
   Zhang WL, 2015, NEUROIMAGE, V108, P214, DOI 10.1016/j.neuroimage.2014.12.061
   Zhang YD, 2011, EXPERT SYST APPL, V38, P10049, DOI 10.1016/j.eswa.2011.02.012
NR 50
TC 3
Z9 3
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15613
EP 15634
DI 10.1007/s11042-019-07823-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900068
DA 2024-07-18
ER

PT J
AU Vijayalakshmi, A
   Kanna, BR
AF Vijayalakshmi, A.
   Kanna, Rajesh B.
TI Deep learning approach to detect malaria from microscopic images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Malaria; Convolutional neural network; Transfer learning; VGG16; VGG19;
   Support vector machine; Deep learning
ID CLASSIFICATION; PARASITES
AB Malaria is an infectious disease which is caused by plasmodium parasite. Several image processing and machine learning based techniques have been employed to diagnose malaria, using its spatial features extracted from microscopic images. In this work, a novel deep neural network model is introduced for identifying infected falciparum malaria parasite using transfer learning approach. This proposed transfer learning approach can be achieved by unifying existing Visual Geometry Group (VGG) network and Support Vector Machine (SVM). Implementation of this unification is carried out by using "Train top layers and freeze out rest of the layers" strategy. Here, the pre-trained VGG facilitates the role of expert learning model and SVM as domain specific learning model. Initial 'k' layers of pre-trained VGG are retained and (n-k) layers are replaced with SVM. To evaluate the proposed VGG-SVM model, a malaria digital corpus has been generated by acquiring blood smear images of infected and non-infected malaria patients and compared with state-of-the-art Convolutional Neural Network (CNN) models. Malaria digital corpus images were used to analyse the performance of VGG19-SVM, resulting in classification accuracy of 93.1% in identification of infected falciparum malaria. Unification of VGG19-SVM shows superiority over the existing CNN models in all performance indicators such as accuracy, sensitivity, specificity, precision and F-Score. The obtained result shows the potential of transfer learning in the field of medical image analysis, especially malaria diagnosis.
C1 [Vijayalakshmi, A.; Kanna, Rajesh B.] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai
RP Vijayalakshmi, A (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM vijayalakshmi.av@vit.ac.in; rajeshkanna.b@vit.ac.in
RI Baskaran, Rajesh Kanna/Y-6659-2019; A, VIJAYALAKSHMI/AAC-1294-2021
OI Baskaran, Rajesh Kanna/0000-0001-5970-3702; 
CR A Simonyan Zisserman, 2015, COMPUTER VISION PATT
   Abbas Naveed, 2013, Journal of Theoretical and Applied Information Technology, V55, P117
   Ahn E, 2016, I S BIOMED IMAGING, P855, DOI 10.1109/ISBI.2016.7493400
   Anggraini D., 2011, Proceedings of the 2011 International Conference on Advanced Computer Science and Information Systems (ICACSIS), P347
   [Anonymous], 2009, AUTOMATIC MALARIA DI
   [Anonymous], 2015, PROCIEEE CONFCOMPUT
   Arco JE, 2015, EXPERT SYST APPL, V42, P3041, DOI 10.1016/j.eswa.2014.11.037
   Chavan S.N., 2014, International Journal Latest Trends Engineering Technology, V3, P218
   Chayadevi M., 2014, INT J VIDEO IMAGE PR, V14, P7
   Christodoulidis S, 2017, IEEE J BIOMED HEALTH, V21, P76, DOI 10.1109/JBHI.2016.2636929
   Damahe L.B., 2011, International Journal Computing Science and Applications, V4, P71
   Das DK, 2015, J MICROSC-OXFORD, V257, P238, DOI 10.1111/jmi.12206
   Díaz G, 2009, J BIOMED INFORM, V42, P296, DOI 10.1016/j.jbi.2008.11.005
   Dinesh Jackson Samuel R., 2018, MULTIMEDIA TOOLS APP, P1
   Dong YH, 2017, 2017 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), P101, DOI 10.1109/BHI.2017.7897215
   Hung Jane, 2017, Conf Comput Vis Pattern Recognit Workshops, V2017, P808, DOI [10.1109/cvprw.2017.112, 10.1109/CVPRW.2017.112]
   Jackson Samuel RD, 2018, NEURAL COMPUTING APP
   Kang JH, 2015, ADV MATH PHYS, V2015, DOI 10.1155/2015/521069
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Khan NA, 2014, INT JOINT CONF COMP, P263, DOI 10.1109/JCSSE.2014.6841878
   Khot ST, 2015, ADV INTELL SYST, V327, P69, DOI 10.1007/978-3-319-11933-5_9
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumarasamy SK, 2011, MACH VISION APPL, V22, P461, DOI 10.1007/s00138-010-0284-x
   Le MT, 2008, BMC CELL BIOL, V9, DOI 10.1186/1471-2121-9-15
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Ma Charles, 2010, Malar J, V9, P348, DOI 10.1186/1475-2875-9-348
   Makkapati VV, 2011, IEEE ENG MED BIO, P6138, DOI 10.1109/IEMBS.2011.6091516
   Malihi L, 2013, IRAN CONF MACH, P360, DOI 10.1109/IranianMVIP.2013.6780011
   Mandal Subhamoy, 2010, 2010 ANN IEEE IND C, P1, DOI DOI 10.1109/INDCON.2010.5712739
   May Z, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (IEEE ICSIPA 2013), P369, DOI 10.1109/ICSIPA.2013.6708035
   Memeu Daniel Maitethia., 2014, A rapid malaria diagnostic method based on automatic detection and classification of plasmodium parasites in stained thin blood smear images
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pallavi T, 2013, INT J ENG INN TECHNO, V2, P124
   Pan WD, 2017, MACHINE LEARNING ADV
   Poostchi M, 2018, TRANSL RES, V194, P36, DOI 10.1016/j.trsl.2017.12.004
   Prasad K, 2012, J DIGIT IMAGING, V25, P542, DOI 10.1007/s10278-011-9442-6
   Rajaraman S, 2018, PEERJ, V6, DOI 10.7717/peerj.4568
   Savkare S. S., 2015, 2015 International Conference on Communication, Information & Computing Technology (ICCICT), P1, DOI 10.1109/ICCICT.2015.7045660
   Schapire Robert E, 2013, EMPIRICAL INFERENCE, P37, DOI [DOI 10.1007/978-3-642-41136-65, DOI 10.1007/978-3-642-41136-6_5]
   Seman NA., 2008, International Journal of the Computer, the Internet and Management, V16, P46
   Soni J., 2011, Int J Adv Eng Technol, V1, P290
   Tek FB, 2010, COMPUT VIS IMAGE UND, V114, P21, DOI 10.1016/j.cviu.2009.08.003
   Wang SH, 2018, J MED SYST, V42, DOI [10.1007/s10916-017-0845-x, 10.1007/s10916-018-0932-7]
   WHO, WORLD MAL REP 2017
   Yunda L, 2012, SIST TELEMAT, V10, P9, DOI 10.18046/syt.v10i20.1151
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang Y. D., 2017, Multimedia Tools and Applications, P1
   Zhang YD, 2018, J COMPUT SCI-NETH, V27, P57, DOI 10.1016/j.jocs.2018.05.005
NR 49
TC 75
Z9 78
U1 2
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15297
EP 15317
DI 10.1007/s11042-019-7162-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900053
DA 2024-07-18
ER

PT J
AU Wang, XW
   Cheng, MW
   Wang, YF
   Liu, SH
   Tian, ZH
   Jiang, F
   Zhang, HJ
AF Wang, Xiaowei
   Cheng, Maowei
   Wang, Yefu
   Liu, Shaohui
   Tian, Zhihong
   Jiang, Feng
   Zhang, Hongjun
TI Obstructive sleep apnea detection using ecg-sensor with convolutional
   neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent surveillance; Sleep apnea; Feature extraction; ECG; Apnea
   detection; CNN
ID HEART-RATE; AUTOMATED DETECTION; KERNELS
AB In recent years, AI(Artificial Intelligence) has achieved great development in modern society. More and more modern technologies are applied in surveillance and monitoring. Healthcare monitoring is growing ubiquitous in modern wearable devices, such as a smart watch, electrocardiogram (ECG) necklace, smart band. Many sensors are attached to these smart devices to record and monitor physiological signals caused by activities, and then propagated those recorded electrical data to be further processed to give health diagnosis, disease prevention or making a distress call automatically. Obstructive sleep apnea (OSA) is a sleep disorder with a high occurrence in adult people and observed as an autonomous risk factor for circulatory problems such as ischemic heart attacks and stroke. Numerous traditional neural network based methods have been developed to detect OSA, where these methods however could not provide the intended result because they rely on shallow network. In this paper, we propose an effective OSA detection based on Convolutional neural network. Our method first extracts features from Apnea-Electrocardiogram (ECG) recordings using RR-intervals (time interval from one R-wave to the next R-wave in an ECG signal) and then CNN model having three convolution layers and three fully connected layers is trained with extracted features and applied for OSA detection. The first two convolution layers are followed by batch normalization and pooling layer, and softmax is connected to the last fully connected layer to give final decision. Experimental results on extracted feature of Apnea-ECG signal reveal that our model have better results in terms of performance measure sensitivity, specificity and accuracy. It is expected that the related technology can be applied into smart sensors, especially wearable devices.
C1 [Wang, Xiaowei] PLA Army Engn Univ, Command Automat Coll, Nanjing 210007, Peoples R China.
   [Cheng, Maowei] PLA Army Engn Univ, Coll Command Informat Syst, Nanjing 210007, Peoples R China.
   [Wang, Yefu] Nanjing Univ Sci & Technol, Sch Mech Engn, Nanjing 210094, Peoples R China.
   [Liu, Shaohui; Jiang, Feng] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
   [Tian, Zhihong] Guangzhou Univ, Cyberspace Inst Adv Technol, Guangzhou 510006, Peoples R China.
   [Zhang, Hongjun] PLA Army Engn Univ, Nanjing 210007, Peoples R China.
C3 Army Engineering University of PLA; Army Engineering University of PLA;
   Nanjing University of Science & Technology; Harbin Institute of
   Technology; Guangzhou University; Army Engineering University of PLA
RP Liu, SH (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
EM 523820457@qq.com; chengmaoweimm@126.com; wangyeful@163.com;
   shliu@hit.edu.cn; tianzhihong@gzhu.edu.cn; fjiang@hit.edu.cn;
   wangxiulai@126.com
RI Liu, shaohui/HKE-1383-2023; JIANG, Feng/HTP-2862-2023; WANG,
   YEFU/M-2360-2016
OI Liu, Shaohui/0000-0002-1810-5412
CR Acharya UR, 2017, INFORM SCIENCES, V405, P81, DOI 10.1016/j.ins.2017.04.012
   Al-Abed M, 2007, P ANN INT IEEE EMBS, P6102
   Almazaydeh L, 2012, IEEE ENG MED BIO, P4938, DOI 10.1109/EMBC.2012.6347100
   [Anonymous], 2013, 2013 P ANN C AFEKA A
   [Anonymous], IEEE T EMERGING TOPI
   [Anonymous], MATCONVNET CONVOLUTI
   Chen BW, 2018, FUTURE GENER COMP SY, V78, P859, DOI 10.1016/j.future.2016.11.008
   Chen BW, 2017, IEEE COMMUN MAG, V55, P92, DOI 10.1109/MCOM.2017.1600223CM
   Chen BW, 2016, J SUPERCOMPUT, V72, P3297, DOI 10.1007/s11227-015-1404-1
   Cheng MW, 2017, IEEE INT C COMPUT, P199, DOI 10.1109/CSE-EUC.2017.220
   de Chazal P, 2004, PHYSIOL MEAS, V25, P967, DOI 10.1088/0967-3334/25/4/015
   Deepu C., 2016, SENSORS-BASEL, V2
   Dempsey JA, 2010, PHYSIOL REV, V90, P47, DOI 10.1152/physrev.00043.2008
   Phan D, 2015, 2015 INTERNATIONAL SYMPOSIUM ON BIOELECTRONICS AND BIOINFORMATICS (ISBB), P144, DOI 10.1109/ISBB.2015.7344944
   Feng J, 2015, J MACH LEARN RES, V16, P2
   Feng J, 2014, MULTIMED TOOLS APPL, P1
   Feng JY, 2014, KSII T INTERNET INF, V8, P1, DOI 10.3837/tiis.2014.01.001
   GUILLEMINAULT C, 1984, LANCET, V1, P126
   Gyselinckx B, 2005, IEEE CUST INTEGR CIR, P13
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hossen A, 2013, INT CONF BIOMED, P182, DOI 10.1109/BMEI.2013.6746930
   Jiang F, 2015, IET COMPUT VIS, V9, P673, DOI 10.1049/iet-cvi.2014.0426
   Jiang F, 2015, J SUPERCOMPUT, V71, P2035, DOI 10.1007/s11227-014-1257-z
   Jifara W, 2019, J SUPERCOMPUT, V75, P704, DOI 10.1007/s11227-017-2080-0
   Kingma D. P, 2015, International Conference on Learning Representations
   Mukhopadhyay SC, 2015, IEEE SENS J, V15, P1321, DOI 10.1109/JSEN.2014.2370945
   Olson EJ, 2003, MAYO CLIN PROC, V78, P1545, DOI 10.4065/78.12.1545
   Otto C., 2006, J MOBILE MULTIMEDIA, V1, P307
   Penzel T, 2000, COMPUT CARDIOL, V27, P255, DOI 10.1109/CIC.2000.898505
   PENZEL T, 1990, SLEEP, V13, P175, DOI 10.1093/sleep/13.2.175
   Pham LV, 2015, PATHOGENESIS OBSTRUC, V7, P2072
   Saini I, 2013, J ADV RES, V4, P331, DOI 10.1016/j.jare.2012.05.007
   Shen B, 2017, J PARALLEL DISTRIBUT
   Shen B, 2017, INFORM FUSION, V36, P68, DOI 10.1016/j.inffus.2016.11.008
   Shen B, 2016, FUTURE GENER COMP SY, V61, P108, DOI 10.1016/j.future.2015.10.021
   Yadollahi A, 2009, IEEE ENG MED BIO, P7110, DOI 10.1109/IEMBS.2009.5332870
   Yang X, 2016, INT CONF WIRE COMMUN
NR 37
TC 20
Z9 21
U1 2
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 15813
EP 15827
DI 10.1007/s11042-018-6161-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600003
DA 2024-07-18
ER

PT J
AU Wei, J
   Gui, WJ
   Zhang, ZF
   Cui, YJ
   Cui, XT
   Wei, H
AF Wei Jia
   Gui Wenjun
   Zhang Zhifang
   Cui Yanjun
   Cui Xiaoting
   Wei Hu
TI Infrared imaging of modified chitosan hydrogel film morphology study of
   polyvinyl alcohol adsorption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chitosan; Acid red 73; Adsorption
ID RELEASE; MODEL
AB The hydrogel film of chitosan with pore structure can be produced by using glutaraldehyde as reaction crosslinking agent to crosslink polyvinyl alcohol and chitosan, which has higher adsorption efficiency. The structure of film is characterized by infrared image, and its morphology is characterized by SEM. The adsorption of acid red 73 under different conditions is primarily studied. The results show that the hydrogel film has a three-dimensional porous microstructure, and the material kinetics is found to effectively absorb acid red 73, with a maximum adsorption amount of 6.5639 mg/g. It is proven as an ideal adsorption material. After studying the thermodynamics of adsorption of the material, oH < 0 was obtained, divide oH divide = -81.59861kJ/mol, which belongs to exothermic reaction, primarily reflected as chemical adsorption.
C1 [Wei Jia; Gui Wenjun; Zhang Zhifang; Cui Yanjun; Cui Xiaoting; Wei Hu] Gansu Agr Univ, Inst Agr Resources Chem & Applicat, Coll Sci, Lanzhou 730000, Gansu, Peoples R China.
C3 Gansu Agricultural University
RP Wei, J (corresponding author), Gansu Agr Univ, Inst Agr Resources Chem & Applicat, Coll Sci, Lanzhou 730000, Gansu, Peoples R China.
EM Weijia1673@163.com
RI GUI, WEN/KIJ-6966-2024
CR Abdulhay E, 2020, NEURAL COMPUT APPL, V32, P10947, DOI 10.1007/s00521-018-3738-0
   Acharya UR, 2019, FUTURE GENER COMP SY, V91, P290, DOI 10.1016/j.future.2018.08.044
   Guojie WU, 2006, J GUANGDONG U TECHNO
   Jiao DD, 2019, FUTURE GENER COMP SY, V92, P324, DOI 10.1016/j.future.2018.10.019
   Khamparia A, 2020, NEURAL COMPUT APPL, V32, P11083, DOI 10.1007/s00521-018-3896-0
   Li HY, 2019, FUTURE GENER COMP SY, V98, P69, DOI 10.1016/j.future.2018.12.001
   Mahdavinia GR, 2016, IRAN POLYM J, V25, P933, DOI 10.1007/s13726-016-0480-2
   Mathews DT, 2008, J BIOMED MATER RES B, V84B, P531, DOI 10.1002/jbm.b.30901
   Mathews DT, 2006, THESIS
   Mohammed MA, 2020, J SUPERCOMPUT, V76, P1086, DOI 10.1007/s11227-018-2587-z
   Oh SL, 2020, NEURAL COMPUT APPL, V32, P10927, DOI 10.1007/s00521-018-3689-5
   Pereira RF, 2020, J SUPERCOMPUT, V76, P1212, DOI 10.1007/s11227-018-2579-z
   Santamaria-Granados L, 2019, IEEE ACCESS, V7, P57, DOI 10.1109/ACCESS.2018.2883213
   Sathishkumar BR, 2020, NEURAL COMPUT APPL, V32, P11097, DOI 10.1007/s00521-018-3919-x
   Srinivasa PC, 2003, CARBOHYD POLYM, V53, P431, DOI 10.1016/S0144-8617(03)00105-X
   Venkatraman V, 2018, INT J HEAVY VEH SYST, V25, P344, DOI 10.1504/IJHVS.2018.094829
   Wen YM, 2007, J GUANGDONG OCEAN U
   [吴国杰 Wu Guojie], 2006, [材料导报, Materials Review], V20, P139
   Wu ZC, 2019, FUTURE GENER COMP SY, V93, P170, DOI 10.1016/j.future.2018.10.018
   Xiao G, 2014, SEP SCI TECHNOL, V49, P1279, DOI 10.1080/01496395.2013.877031
   Zhou DM, 2018, J POWER SOURCES, V399, P314, DOI 10.1016/j.jpowsour.2018.06.098
   Zhou DM, 2018, ENERG CONVERS MANAGE, V162, P276, DOI 10.1016/j.enconman.2018.02.036
   Zu YG, 2012, INT J BIOL MACROMOL, V50, P82, DOI 10.1016/j.ijbiomac.2011.10.006
NR 23
TC 4
Z9 4
U1 3
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 17027
EP 17043
DI 10.1007/s11042-019-7555-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600068
DA 2024-07-18
ER

PT J
AU Zhang, FQ
   Gao, YH
   Xu, LQ
AF Zhang, Fengquan
   Gao, Yahui
   Xu, Liuqing
TI An adaptive image feature matching method using mixed Vocabulary-KD tree
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SIFT; Clustering; Vocabulary tree; KD tree; Voronoi graph; AR
ID ALGORITHM
AB This paper proposes an adaptive scale-invariant feature matching method based on data clustering, to solve the problem of low robustness of the KD tree matching method caused by SIFT feature noise sensitivity, and our method can be used to AR applications. The method has two stages: offline data re-clustering and online two-stage feature matching. This paper is the first to present a Vocabulary-KD data structure which achieves SIFT using KD tree by tuning the number of features of the Vocabulary nodes. Moreover, based on the Vocabulary-KD data structure, an adaptive feature matching method is proposed, which is consist of two clustering, one on the feature sets and the other on the feature sets contained by the leaf nodes of the Vocabulary-KD tree, along with adaptive adjustment of the relevant parameters of the Vocabulary-KD tree. At last, key images are selected in real-time for the second stage feature matching. The different results show that the proposed method can effectively resist noise, improve the adaptivity of the SIFT feature matching method, so as to achieve the trade-off between efficiency and robustness.
C1 [Zhang, Fengquan; Gao, Yahui] North China Univ Technol, Sch Comp Sci, Beijing 100144, Peoples R China.
   [Xu, Liuqing] Chinese Acad Sci, Airborne Remote Sensing Ctr, Inst Remote Sensing & Digital Earth, Beijing 100094, Peoples R China.
C3 North China University of Technology; Chinese Academy of Sciences; The
   Institute of Remote Sensing & Digital Earth, CAS
RP Zhang, FQ (corresponding author), North China Univ Technol, Sch Comp Sci, Beijing 100144, Peoples R China.
EM fqzhang@ncut.edu.cn
CR Abelson H., 1998, Higher Order Symbolic Computation, V11, P7, DOI 10.1023/A:1010051815785
   [Anonymous], 2019, SOFT COMPUT, DOI DOI 10.1007/s00500-017-2940-9
   Baumberg A, 2000, PROC CVPR IEEE, P774, DOI 10.1109/CVPR.2000.855899
   Cheng ZY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3291060
   Choudhary S, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P936, DOI 10.1109/ICCONS.2017.8250602
   Deng W, 2019, IEEE ACCESS, V7, P20281, DOI 10.1109/ACCESS.2019.2897580
   Deng W, 2018, IEEE ACCESS, V6, P35042, DOI 10.1109/ACCESS.2018.2834540
   Guo YY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3295822
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Jiang J, 2014, IEEE T CIRC SYST VID, V24, P1209, DOI 10.1109/TCSVT.2014.2302535
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   LEE DT, 1977, ACTA INFORM, V9, P23, DOI 10.1007/BF00263763
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Liu PC, 2019, EUR J MECH A-SOLID, V74, P16, DOI 10.1016/j.euromechsol.2018.10.016
   Liu PC, 2018, NONLINEAR DYNAM, V94, P1803, DOI 10.1007/s11071-018-4458-9
   Liu PC, 2018, INT J CONTROL AUTOM, V16, P2373, DOI 10.1007/s12555-017-0192-7
   Luo S, 2015, IEEE SENS J, V15, P5001, DOI 10.1109/JSEN.2015.2432127
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mustafa A, 2019, IEEE T IMAGE PROCESS, V28, P1118, DOI 10.1109/TIP.2018.2872906
   Nister David, 2006, CVPR
   Nowak E, 2007, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2007.382969
   Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414
   Toews M, 2010, NEUROIMAGE, V49, P2318, DOI 10.1016/j.neuroimage.2009.10.032
   Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8
   Dinh VQ, 2019, IEEE T IMAGE PROCESS, V28, P815, DOI 10.1109/TIP.2018.2870930
   Wang R, 2017, IEEE IND ELEC, P3545
NR 27
TC 7
Z9 7
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16421
EP 16439
DI 10.1007/s11042-019-7438-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600034
DA 2024-07-18
ER

PT J
AU Zhang, YL
   Hong, Y
   Choi, K
AF Zhang, Yunlong
   Hong, Yuan
   Choi, Ken
TI Optimal energy-dissipation control for SOC based balancing in series
   connected Lithium-ion battery packs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lithium-ion battery; Energy dissipation; SOC distribution; Balancing
   topology and system modeling
ID EQUALIZATION; TOPOLOGY
AB Since the state-of-charge (SOC) based balancing can prolong the battery pack's life and maximize its capacity, implementing the balancing process in the battery management system (BMS) can explicitly reduce the cost of the battery based energy-storage-system (ESS). With the same initial SOC distribution, different balancing topologies may lead to different amounts of energy transferred in the balancing process due to the energy transferring efficiency of equalizers. Furthermore, the more energy equalizers transfer, the more energy and time balancing process will consume. Thus, instead of solely minimizing the balancing time for balancing optimization, it is critical to take into account the energy dissipation of balancing process. This paper presents a novel balancing optimization method from the perspective of minimizing the energy dissipation of balancing process. First, we introduce a two-step balancing strategy in the fast charging system. This strategy can simplify the modular design of the balancing system, and ensure the safety performance of the fast charging system while maximizing the balancing current. Second, an effective system modeling method is proposed for different balancing topologies. With different initial SOC distributions, we simulate the energy dissipation for different balancing topologies. Simulation results are presented to show that the cascade and cascade-series connection topologies would achieve a balanced state in the optimal energy dissipation.
C1 [Zhang, Yunlong; Choi, Ken] IIT, Elect & Comp Engn, Chicago, IL 60616 USA.
   [Hong, Yuan] IIT, Comp Sci, Chicago, IL 60616 USA.
C3 Illinois Institute of Technology; Illinois Institute of Technology
RP Hong, Y (corresponding author), IIT, Comp Sci, Chicago, IL 60616 USA.
EM yzhan167@hawk.iit.edu; yuan.hong@iit.edu; kchoi@ece.iit.edu
OI Zhang, Yunlong/0000-0002-0227-2734
CR Baronti F, 2014, J POWER SOURCES, V267, P603, DOI 10.1016/j.jpowsour.2014.05.007
   Cassani PA, 2009, IEEE T VEH TECHNOL, V58, P3938, DOI 10.1109/TVT.2009.2031553
   Daowd M., 2011, 2011 IEEE Vehicle Power and Propulsion Conference, DOI 10.1109/VPPC.2011.6043010
   Einhorn M, 2011, IEEE T VEH TECHNOL, V60, P2448, DOI 10.1109/TVT.2011.2153886
   Gallardo-Lozano J, 2014, J POWER SOURCES, V246, P934, DOI 10.1016/j.jpowsour.2013.08.026
   Lee YS, 2005, IEEE T IND ELECTRON, V52, P1297, DOI 10.1109/TIE.2005.855673
   Lim CS, 2014, IEEE T POWER ELECTR, V29, P1791, DOI 10.1109/TPEL.2013.2270000
   McCurlie L, 2017, IEEE T IND ELECTRON, V64, P1350, DOI 10.1109/TIE.2016.2611488
   Nguyen N, 2014, IEEE T VEH TECHNOL, V63, P3651, DOI 10.1109/TVT.2014.2304453
   Ouyang Q, 2017, IEEE T IND APPL, V53, P2369, DOI [10.1109/TIA.2016.2645888, DOI 10.1109/TIA.2016.2645888]
   Ouyang Q, 2018, IEEE T IND ELECTRON, V65, P3427, DOI 10.1109/TIE.2017.2750629
   Ouyang Q, 2018, IEEE T SUSTAIN ENERG, V9, P350, DOI 10.1109/TSTE.2017.2733342
   Plett GL, 2004, J POWER SOURCES, V134, P262, DOI 10.1016/j.jpowsour.2004.02.032
   Nguyen TTN, 2015, IET POWER ELECTRON, V8, P458, DOI 10.1049/iet-pel.2013.0657
NR 14
TC 4
Z9 5
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 15923
EP 15944
DI 10.1007/s11042-018-6655-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600008
DA 2024-07-18
ER

PT J
AU Zhang, Z
   Bi, HB
   Kong, XX
   Li, N
   Lu, D
AF Zhang, Zheng
   Bi, Hongbo
   Kong, Xiaoxue
   Li, Ning
   Lu, Di
TI Adaptive compressed sensing of color images based on salient region
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive compressed sensing; Salient region detection; YUV channel;
   Color image
AB We propose a novel algorithm for color image compressed sensing (CS). Our method involves the adaptive measurement and reconstruction of color images based on visual saliency detection. First, we divide the image into blocks and transform the RGB channel into the YUV channel. Secondly, we use statistical texture distinctiveness to calculate the saliency of each block and normalize energy, thereby establishing an adaptive measurement rate and measurement matrix. Thirdly, we adaptively measure the Y channel according to block prominence and preserve the information of the UV channel. During reconstruction, we utilize adaptive block measurement rate to re-estimate block saliency and then reconstruct the objective function of the weighted reconstruction model according to the re-estimated block saliency. Finally, we combine the reconstructed Y channel with the reserved UV channel to obtain the final image. Experimental results show that compared with other state-of-the-art approaches, the proposed algorithm can not only provide good subjective visual quality but can also present higher peak signal to noise ratio (PSNR) under the same sampling rate.
C1 [Zhang, Zheng; Bi, Hongbo; Kong, Xiaoxue; Li, Ning; Lu, Di] Northeast Petr Univ, Sch Elect & Informat Engn, Daqing, Peoples R China.
C3 Northeast Petroleum University
RP Bi, HB (corresponding author), Northeast Petr Univ, Sch Elect & Informat Engn, Daqing, Peoples R China.
EM 33996478@qq.com; bhbdq@126.com; kxxwds@163.com; LNLNDY@126.com;
   18810463560@163.com
OI Bi, Hongbo/0000-0003-2442-330X
CR Afonso MV, 2010, IEEE T IMAGE PROCESS, V19, P2345, DOI 10.1109/TIP.2010.2047910
   Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319
   Blumensath T, 2009, APPL COMPUT HARMON A, V27, P265, DOI 10.1016/j.acha.2009.04.002
   Cai X, 2015, 2015 12TH INTERNATIONAL JOINT CONFERENCE ON E-BUSINESS AND TELECOMMUNICATIONS (ICETE), VOL 5, P14
   Chang K, 2017, VISUAL COMMUNICATION, P1
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Li R, 2013, CHINA COMMUN, V10, P58, DOI 10.1109/CC.2013.6674211
   [刘亚新 Liu Yaxin], 2010, [电子与信息学报, Journal of Electronics & Information Technology], V32, P2713, DOI 10.3724/SP.J.1146.2009.01623
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Majumdar A, 2010, IEEE IMAGE PROC, P1337, DOI 10.1109/ICIP.2010.5653685
   Majumdar A, 2010, SIGNAL PROCESS, V90, P3122, DOI 10.1016/j.sigpro.2010.05.016
   Nagesh P, 2009, INT CONF ACOUST SPEE, P1261, DOI 10.1109/ICASSP.2009.4959820
   Scharfenberger C, 2015, IEEE T IMAGE PROCESS, V24, P457, DOI 10.1109/TIP.2014.2380351
   Varadarajan B, 2011, IEEE SIGNAL PROC LET, V18, P27, DOI 10.1109/LSP.2010.2090143
   Vijayanagar KR, 2014, IEEE IMAGE PROC, P1307, DOI 10.1109/ICIP.2014.7025261
   Wakin MB, 2006, IEEE IMAGE PROC, P1273, DOI 10.1109/ICIP.2006.312577
NR 19
TC 9
Z9 11
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14777
EP 14791
DI 10.1007/s11042-018-7062-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900026
DA 2024-07-18
ER

PT J
AU Liang, Y
   Zhang, J
   Wang, MH
   Lin, C
   Xiao, J
AF Liang, Yun
   Zhang, Jian
   Wang, Mei-hua
   Lin, Chen
   Xiao, Jun
TI Multi-features guided robust visual tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Multi-features; Target template; Template matching
   method; Update template
ID OBJECT TRACKING; MODEL
AB This paper focuses on dealing with the tracking challenges such as target occlusion and deformation. It proposes a new tracking method via extracting and evaluating multi-features for both target region and its adjacent surroundings. The multi-features separately describe the key factors to detect target including the color feature, the shape and contour feature, and the distributions of structure and intensity described by the Pearson Correlation Coefficient. These multi-features are proposed as the basic representation of target template and candidates and used to define a matching algorithm between them. The best matched candidate is taken as the final tracking result. To improve the efficiency of target template and candidates, the region of importance (ROI) for target is proposed by evaluating the distribution of salient values on many extended regions. The ROIs produce more accurate regions to form target template and candidates. Finally, a new template update method is defined based on the precision of tracked result to adapt to target state and achieve the follow target tracking. Using 25 videos in visual tracking benchmark, we achieve the quantitative and qualitatively evaluations of 12 different trackers. Many experiments demonstrate that our tracker produces much better results than the present trackers in dealing with target occlusion, deformation, rotation, background clutters.
C1 [Liang, Yun; Wang, Mei-hua] South China Agr Univ, Coll Math & Informat, Guangzhou 510642, Peoples R China.
   [Zhang, Jian] Zhejiang Int Studies Univ, Sch Sci & Technol, Hangzhou 310023, Peoples R China.
   [Lin, Chen] Xiamen Univ, Dept Comp Sci, Xiamen 361005, Peoples R China.
   [Xiao, Jun] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.
C3 South China Agricultural University; Zhejiang International Studies
   University; Xiamen University; Zhejiang University
RP Zhang, J (corresponding author), Zhejiang Int Studies Univ, Sch Sci & Technol, Hangzhou 310023, Peoples R China.
EM jeyzhang@outlook.com
RI Lin, Chen/GRR-2799-2022
FU Natural Science Foundation of China [61472335, 61,972,328, 61772209,
   61972361]; Science and Technology Planning Project of Guangdong Province
   [2019A050510034, 2019B020219001]; National Natural Science Foundation of
   China [61572431]; Zhejiang Natural Science Foundation [LR19F020002,
   LZ17F020001, LY17F020009]
FX This paper is funded by some projects of the authors. Yun Liang is the
   Natural Science Foundation of China (No. 61772209), and the Science and
   Technology Planning Project of Guangdong Province (No. 2019A050510034,
   2019B020219001). Jian Zhang is supported by the Natural Science
   Foundation of China (No. 61972361). Chen Lin is supported by the Natural
   Science Foundation of China (No.61472335, 61,972,328). Jun Xiao is
   supported by the National Natural Science Foundation of China
   (No.61572431), and the Zhejiang Natural Science Foundation
   (No.LY17F020009, LR19F020002, LZ17F020001).
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2012, P AS C COMP VIS
   [Anonymous], 2014, REGISTRATION RECOGNI, DOI DOI 10.1007/978-3-642-44907-9_6
   Bibi A, 2016, LECT NOTES COMPUT SC, V9910, P419, DOI 10.1007/978-3-319-46466-4_25
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Choi J, 2018, PROC CVPR IEEE, P479, DOI 10.1109/CVPR.2018.00057
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Godec M, 2013, COMPUT VIS IMAGE UND, V117, P1245, DOI 10.1016/j.cviu.2012.11.005
   Grabner M, 2007, PROC CVPR IEEE, P200
   Guo YW, 2014, COMPUT VIS IMAGE UND, V118, P128, DOI 10.1016/j.cviu.2013.09.007
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hinterstoisser S, 2010, PROC CVPR IEEE, P2257, DOI 10.1109/CVPR.2010.5539908
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kwon J, 2013, IEEE T PATTERN ANAL, V35, P2427, DOI 10.1109/TPAMI.2013.32
   Kwon J, 2011, IEEE I CONF COMP VIS, P1195, DOI 10.1109/ICCV.2011.6126369
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Liu AA, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P821
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Liu LF, 2019, LECT NOTES ELECTR EN, V463, P1057, DOI 10.1007/978-981-10-6571-2_128
   Ma C, 2016, PATTERN RECOGN LETT, V69, P62, DOI 10.1016/j.patrec.2015.09.019
   Maresca ME, 2013, LECT NOTES COMPUT SC, V8157, P419, DOI 10.1007/978-3-642-41184-7_43
   Ning JF, 2016, PROC CVPR IEEE, P4266, DOI 10.1109/CVPR.2016.462
   Oron S, 2012, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2012.6247895
   Pearson K., 2014, PEARSON PRODUCT MOME
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   Song Y., 2017, IEEE INT C COMP VIS, P2555
   Tu WC, 2016, PROC CVPR IEEE, P2334, DOI 10.1109/CVPR.2016.256
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xu N, 2019, IEEE T CIRC SYST VID, V29, P2482, DOI 10.1109/TCSVT.2018.2867286
   Zhang J, 2018, INT J MOL SCI, V19, DOI [10.3390/ijms19102989, 10.1109/TIM.2018.2884583]
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang L, 2014, IEEE T PATTERN ANAL, V36, P756, DOI 10.1109/TPAMI.2013.221
   Zhaowei Cai, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P86, DOI 10.1007/978-3-642-37431-9_7
   Zhu G, 2016, PROC CVPR IEEE, P943, DOI 10.1109/CVPR.2016.108
   Zhu GB, 2016, AAAI CONF ARTIF INTE, P3690
NR 42
TC 0
Z9 0
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16367
EP 16395
DI 10.1007/s11042-020-08791-z
EA MAY 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000534982800004
DA 2024-07-18
ER

PT J
AU Song, XJ
   Yang, GP
   Wang, KK
   Huang, YW
   Yuan, F
   Yin, YL
AF Song, Xinjing
   Yang, Gongping
   Wang, Kuikui
   Huang, Yuwen
   Yuan, Feng
   Yin, Yilong
TI Short Term ECG Classification with Residual-Concatenate Network and
   Metric Learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Short term ECG classification; Feature representation;
   Residual-concatenate network; Information-Theoretic Metric Learning
ID NEURAL-NETWORK; FEATURES
AB ECG classification is important to the diagnosis of cardiovascular disease. This paper develops a robust and accurate algorithm for automatic detection of heart arrhythmias from ECG signals recorded with one lead. A novel model based on the convolutional neural network is proposed to extract low-level and high-level features of short term ECG. In addition, Information-Theoretic Metric Learning is utilized as a final classification model to boost the discrimination abilities of the network trained features. The experimental results over the MIT-BIH arrhythmia database show that the model achieves a comparable performance with most of the state-of-the-art methods and Information-Theoretic Metric Learning further improves the performance. Besides the good accuracy achieved, the proposed method balances different criteria.
C1 [Song, Xinjing; Yang, Gongping; Wang, Kuikui; Yin, Yilong] Shandong Univ, Sch Software, Jinan 250101, Peoples R China.
   [Yang, Gongping; Huang, Yuwen] Heze Univ, Sch Comp, Heze 274015, Peoples R China.
   [Yuan, Feng] Shandong Management Univ, Key Lab TCM Data Cloud Serv Univ Shandong, Jinan 250357, Peoples R China.
C3 Shandong University; Heze University; Shandong Management University
RP Yang, GP (corresponding author), Shandong Univ, Sch Software, Jinan 250101, Peoples R China.; Yang, GP (corresponding author), Heze Univ, Sch Comp, Heze 274015, Peoples R China.
EM gpyang@sdu.edu.cn
RI Yang, Gongping/B-9923-2012
OI Yang, Gongping/0000-0001-7637-2749
FU National Natural Science Foundation of China-Xinjiang Joint Fund
   [U1903127]; Key Research and Development Project of Shandong Province
   [2018GGX101032, 2019GGX101056, 2019JZZY010706]
FX This work was supported in part by the National Natural Science
   Foundation of China-Xinjiang Joint Fund under Grant U1903127 and in part
   by the Key Research and Development Project of Shandong Province under
   Grant 2018GGX101032, 2019GGX101056, 2019JZZY010706.
CR Acharya UR, 2017, INFORM SCIENCES, V405, P81, DOI 10.1016/j.ins.2017.04.012
   Andersen RS, 2019, EXPERT SYST APPL, V115, P465, DOI 10.1016/j.eswa.2018.08.011
   [Anonymous], REC PRACT TEST REP P
   Berkaya SK, 2018, BIOMED SIGNAL PROCES, V43, P216, DOI 10.1016/j.bspc.2018.03.003
   Davis J. V., 2007, ICML, P209
   de Chazal P, 2004, IEEE T BIO-MED ENG, V51, P1196, DOI 10.1109/TBME.2004.827359
   Dilmac S, 2015, APPL SOFT COMPUT, V36, P641, DOI 10.1016/j.asoc.2015.07.010
   Elhaj FA, 2016, COMPUT METH PROG BIO, V127, P52, DOI 10.1016/j.cmpb.2015.12.024
   Hannun AY, 2019, NAT MED, V25, P65, DOI 10.1038/s41591-018-0268-3
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   HUANG HF, 2014, BIOMED ENG ONLINE, V13
   Khalaf AF, 2015, EXPERT SYST APPL, V42, P8361, DOI 10.1016/j.eswa.2015.06.046
   Kiranyaz S., 2013, Multidimensional Particle Swarm Opti- mization for Machine Learning and Pattern Recognition, Adaptation, Learning, and Optimization
   Kiranyaz S, 2016, IEEE T BIO-MED ENG, V63, P664, DOI 10.1109/TBME.2015.2468589
   Li TY, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18080285
   Raj S, 2017, IEEE T INSTRUM MEAS, V66, P470, DOI 10.1109/TIM.2016.2642758
   Raj S, 2015, MICROPROCESS MICROSY, V39, P504, DOI 10.1016/j.micpro.2015.07.013
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sellami A, 2019, EXPERT SYST APPL, V122, P75, DOI 10.1016/j.eswa.2018.12.037
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh BN, 2006, DIGIT SIGNAL PROCESS, V16, P275, DOI 10.1016/j.dsp.2005.12.003
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wang JS, 2013, NEUROCOMPUTING, V116, P38, DOI 10.1016/j.neucom.2011.10.045
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Xiaolong Zhai, 2018, IEEE Access, V6, P27465, DOI 10.1109/ACCESS.2018.2833841
   Ye C, 2012, IEEE T BIO-MED ENG, V59, P2930, DOI 10.1109/TBME.2012.2213253
NR 31
TC 8
Z9 9
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22325
EP 22336
DI 10.1007/s11042-020-09035-w
EA MAY 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000534441900001
DA 2024-07-18
ER

PT J
AU Sridhar, S
   Sudha, GF
AF Sridhar, Srividhya
   Sudha, Gnanou Florence
TI Quality improved <i>(k, n)</i> priority based progressive visual secret
   sharing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Progressive visual secret sharing; Priority; Threshold; Codebook; Random
   grids
ID RANDOM GRIDS; CRYPTOGRAPHY; SCHEME; ENCRYPTION; SHADOW; IMAGES
AB Progressive Visual Secret Sharing (PVSS) is a Visual Secret Sharing scheme which shares a secret image among multiple users and during the decryption this secret image can be reconstructed in a progressive manner. Recently, PVSS has been extended for priority users by giving different importance to different shares. Thus, the higher priority user holding higher importance shares obtains better visual quality compared to the lower priority users. However, existing priority based visual secret sharing suffers from the problem of inconsistent contrast and degraded visual quality. Hence, this paper uses two different approaches namely Codebook approach and Random grid approach to construct (k, n) Priority based Progressive Visual Secret Sharing (PPVSS) without pixel expansion to provide consistent contrast and better visual quality of reconstructed image. Experimental results show the effectiveness of proposed scheme compared to the existing scheme.
C1 [Sridhar, Srividhya; Sudha, Gnanou Florence] Pondicheny Engn Coll, Dept Elect & Commun Engn, Puducheny, India.
C3 Pondicherry Engineering College
RP Sridhar, S (corresponding author), Pondicheny Engn Coll, Dept Elect & Commun Engn, Puducheny, India.
EM srividhya2207@gmail.com
RI Sudha, Gnanou Florence/GLU-3814-2022
OI Sudha, Gnanou Florence/0000-0002-5471-3255
CR Bhattacharjee T, 2017, J INF SECUR APPL, V33, P16, DOI 10.1016/j.jisa.2017.01.001
   Chao HC, 2018, MULTIMED TOOLS APPL, V77, P11867, DOI 10.1007/s11042-017-4836-1
   Chao HC, 2017, DISPLAYS, V49, P6, DOI 10.1016/j.displa.2017.05.004
   Chao HC, 2017, DIGIT SIGNAL PROCESS, V68, P69, DOI 10.1016/j.dsp.2017.05.009
   Chiu PL, 2019, SIGNAL PROCESS, V165, P233, DOI 10.1016/j.sigpro.2019.06.038
   Hou YC, 2015, J VIS COMMUN IMAGE R, V33, P358, DOI 10.1016/j.jvcir.2015.10.005
   Hou YC, 2011, IEEE T CIRC SYST VID, V21, P1760, DOI 10.1109/TCSVT.2011.2106291
   Huh JH, 2017, HUM-CENTRIC COMPUT I, V7, DOI 10.1186/s13673-017-0101-x
   Ibtihal M, 2017, INT J CLOUD APPL COM, V7, P27, DOI 10.4018/IJCAC.2017040103
   Jung SH, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11133499
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee JS, 2015, DIGIT SIGNAL PROCESS, V40, P131, DOI 10.1016/j.dsp.2015.02.012
   Li Z, 2019, INT J HIGH PERFORM C, V14, P60, DOI [10.1504/IJHPCN.2019.099744, DOI 10.1504/IJHPCN.2019.099744]
   Lin CH, 2015, J VIS COMMUN IMAGE R, V33, P31, DOI 10.1016/j.jvcir.2015.08.018
   Lin KS, 2014, INFORM SCIENCES, V288, P330, DOI 10.1016/j.ins.2014.07.016
   Liu X, 2018, MULTIMED TOOLS APPL, V77, P20673, DOI 10.1007/s11042-017-5482-3
   Liu YN, 2018, J INF SECUR APPL, V40, P166, DOI 10.1016/j.jisa.2018.03.009
   Mhala NC, 2019, SIGNAL PROCESS, V162, P253, DOI 10.1016/j.sigpro.2019.04.023
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Seo YS, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8020164
   Shivani S, 2017, MULTIMED TOOLS APPL, V76, P8711, DOI 10.1007/s11042-016-3484-1
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   Wu XT, 2013, SIGNAL PROCESS, V93, P977, DOI 10.1016/j.sigpro.2012.11.014
   Xuehu Yan, 2018, Journal of Real-Time Image Processing, V14, P61, DOI 10.1007/s11554-015-0540-4
   Yan XH, 2016, MULTIMED TOOLS APPL, V75, P8657, DOI 10.1007/s11042-015-2779-y
   Yan XH, 2015, MULTIMED TOOLS APPL, V74, P9279, DOI 10.1007/s11042-014-2080-5
   Yan XH, 2014, SIGNAL PROCESS, V105, P389, DOI 10.1016/j.sigpro.2014.06.011
   Yang CN, 2017, J VIS COMMUN IMAGE R, V42, P121, DOI 10.1016/j.jvcir.2016.10.014
   Yang CN, 2015, INFORM SCIENCES, V312, P131, DOI 10.1016/j.ins.2015.03.024
   Yang CN, 2015, SIGNAL PROCESS-IMAGE, V31, P1, DOI 10.1016/j.image.2014.11.003
   Yang CN, 2014, INFORM SCIENCES, V271, P246, DOI 10.1016/j.ins.2014.02.099
   Yang CN, 2011, J SYST SOFTWARE, V84, P1726, DOI 10.1016/j.jss.2011.05.008
   Zkik K, 2017, INT J CLOUD APPL COM, V7, P62, DOI 10.4018/IJCAC.2017040105
NR 34
TC 7
Z9 8
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11459
EP 11486
DI 10.1007/s11042-019-08319-0
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400009
DA 2024-07-18
ER

PT J
AU Xu, H
   Srivastava, G
AF Xu, Hao
   Srivastava, Gautam
TI Automatic recognition algorithm of traffic signs based on convolution
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution neural network; Traffic signs; Recognition algorithm;
   Feature extraction
AB Because of the hierarchical significance of traffic sign images, the traditional methods do not effectively control and extract the brightness and features of layered images. Therefore, an automatic recognition algorithm for traffic signs based on a convolution neural network is proposed in this paper. First, the histogram equalization method is used to pre-process the traffic sign images, with details of the images being enhanced and contrast of the images improved. Then, the traffic sign images are recognized by a convolution neural network and the large scale structure of information in the traffic sign images are obtained by using a hierarchical significance detection method based on graphical models. Next, the area of interest in the traffic sign images are extracted by using the hierarchical significance model. Finally, the Softmax classifier is selected to classify the input feature images to realize the automatic recognition of traffic signs. Experimental results show that the proposed algorithm can control the brightness of traffic sign images, which can accurately extract image regions of interest and complete the automatic recognition of traffic signs.
C1 [Xu, Hao] Xinyang Vocat & Tech Coll, Sch Math & Comp Sci, Xinyang 464000, Peoples R China.
   [Srivastava, Gautam] Brandon Univ, Dept Math & Comp Sci, Brandon, MB R7A 6A9, Canada.
   [Srivastava, Gautam] China Med Univ, Res Ctr Interneural Comp, Taichung 40402, Taiwan.
C3 Brandon University; China Medical University Taiwan
RP Srivastava, G (corresponding author), Brandon Univ, Dept Math & Comp Sci, Brandon, MB R7A 6A9, Canada.; Srivastava, G (corresponding author), China Med Univ, Res Ctr Interneural Comp, Taichung 40402, Taiwan.
EM SRIVASTAVAG@BrandonU.CA
RI Srivastava, Gautam/N-5668-2019
OI Srivastava, Gautam/0000-0001-9851-4103
CR Aziz S, 2018, PROCEDIA COMPUT SCI, V127, P146, DOI 10.1016/j.procs.2018.01.109
   Dwivedi AD, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020326
   Ge X, 2017, SENS MICRO SYS, V3, P124
   Girault M, 2016, JPN J APPL PHYS, V55, DOI 10.7567/JJAP.55.06GN05
   Huang PD, 2017, IEEE T INTELL TRANSP, V18, P2364, DOI 10.1109/TITS.2016.2639582
   Liu GC, 2018, IEEE ACCESS, V6, P29283, DOI 10.1109/ACCESS.2018.2834916
   Liu S, 2019, IEEE ACCESS, V7, P62412, DOI 10.1109/ACCESS.2019.2916934
   Liu S, 2018, COMPLEXITY, DOI 10.1155/2018/2016976
   Liu SA, 2017, MULTIMED TOOLS APPL, V76, P5787, DOI 10.1007/s11042-014-2408-1
   Mohan S, 2019, IEEE ACCESS, V7, P81542, DOI 10.1109/ACCESS.2019.2923707
   Pan M, 2017, COMP TECHNOL DEV, V2, P96
   Pan Z, 2018, J PARALLEL DISTR COM, V120, P182, DOI 10.1016/j.jpdc.2018.06.012
   Pan Z, 2017, MULTIMED TOOLS APPL, V76, P16989, DOI 10.1007/s11042-016-3647-0
   Pham D, 2017, PATTERN RECOGN, V72, P27, DOI 10.1016/j.patcog.2017.06.027
   Rehman Y, 2017, IET COMPUT VIS, V11, P368, DOI 10.1049/iet-cvi.2016.0303
   Rosario G, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P178, DOI 10.1109/IRI.2018.00034
   Sangaiah AK, 2015, APPL SOFT COMPUT, V30, P628, DOI 10.1016/j.asoc.2015.02.019
   Shi WJ, 2017, IEEE T VLSI SYST, V25, P1362, DOI 10.1109/TVLSI.2016.2631428
   Shumay M, 2018, INT J ELECTRON TELEC, V64, P151, DOI 10.24425/119363
   Srivastava G., J INTELLIGENT FUZZY, P1
   Villaión-Sepúlveda G, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061207
   Vishwasrao MD, 2017, IEEE T SUST COMPUT, V2, P49, DOI 10.1109/TSUSC.2017.2690378
   Wu L, 2018, J DALIAN U NATIONALI, V5, P78
   Zhang XB, 2019, IEEE ACCESS, V7, P64837, DOI 10.1109/ACCESS.2019.2914186
NR 24
TC 19
Z9 20
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11551
EP 11565
DI 10.1007/s11042-019-08239-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400013
DA 2024-07-18
ER

PT J
AU Jin, C
   Luan, NL
AF Jin, Cong
   Luan, Ningli
TI An image denoising iterative approach based on total variation and
   weighting function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Partial differential equation; Total variation;
   Weighting function; Staircase effect
ID MODEL; ENHANCEMENT
AB Image denoising is an important technology for image preprocessing. In recent years, the image denoising technology based on total variation (TV) has been rapidly developed. However, However, although it can preserve image details well, which generates obvious staircase effects. This is due to the traditional TV-based image denoising technology only applies the gradient information and ignored the local variance of the image. In order to suppress staircase effect, in this paper, a novel image denoising approach based on TV model and weighting function is proposed. First, the theory mechanism of staircase effect brought by the traditional TV model is analyzed. Second, the effects of weighting function on edge regions, flat regions, and gradation and detail regions are also analyzed. Third, based on the above analysis, an improved TV model is proposed. Finally, the image denoising approach is implemented by an iterative algorithm. The experimental results show that, compared with various state-of-the-art models denoising models, the proposed image denoising approach can effectively suppress the staircase effect of the traditional TV model in most cases, preserve the image details, and improve the image denoising performance.
C1 [Jin, Cong; Luan, Ningli] Cent China Normal Univ, Sch Comp, Wuhan 430079, Peoples R China.
C3 Central China Normal University
RP Jin, C (corresponding author), Cent China Normal Univ, Sch Comp, Wuhan 430079, Peoples R China.
EM jincong@mail.ccnu.edu.cn
CR Chen DL, 2015, APPL MATH COMPUT, V257, P537, DOI 10.1016/j.amc.2015.01.012
   Chen L., 2010, THESIS
   Du HQ, 2018, SIGNAL IMAGE VIDEO P, V12, P1027, DOI 10.1007/s11760-018-1248-2
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Gilboa G, 2002, IEEE T IMAGE PROCESS, V11, P689, DOI 10.1109/TIP.2002.800883
   Guo XL, 2016, LECT NOTES ELECTR EN, V375, P155, DOI 10.1007/978-981-10-0539-8_16
   Hasan M, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0264-z
   He N, 2015, SIGNAL PROCESS, V112, P180, DOI 10.1016/j.sigpro.2014.08.025
   Highnam R, 1997, IEEE T PATTERN ANAL, V19, P410, DOI 10.1109/34.588029
   Jain P, 2016, INFORM SYST FRONT, V18, P159, DOI 10.1007/s10796-014-9527-0
   Jiang L, 2015, NUMER ALGORITHMS, V69, P495, DOI 10.1007/s11075-014-9908-y
   Jin C, 2012, J OPT, V15, P025402
   Jin C, 2019, MULTIMED TOOLS APPL, V78, P28331, DOI 10.1007/s11042-019-07912-7
   Jin C, 2019, IET IMAGE PROCESS, V13, P623, DOI 10.1049/iet-ipr.2018.5371
   Jin C, 2016, J INTELL FUZZY SYST, V30, P245, DOI 10.3233/IFS-151750
   Lakestani M, 2016, IRAN J SCI TECHNOL S, V42, P31
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Lu XK, 2018, MULTIMED TOOLS APPL, V77, P15521, DOI 10.1007/s11042-017-5131-x
   Ma KD, 2018, IEEE T COMPUT IMAG, V4, P60, DOI 10.1109/TCI.2017.2786138
   Ma QT, 2017, MACH VISION APPL, V28, P635, DOI 10.1007/s00138-017-0857-z
   Ma TH, 2018, COMPUT APPL MATH, V37, P277, DOI 10.1007/s40314-016-0342-8
   Makovetskii A, 2015, COMM COM INF SC, V542, P114, DOI 10.1007/978-3-319-26123-2_11
   Poobathy D., 2014, International Journal of Image, Graphics and Signal Processing, V6, P55, DOI 10.5815/ijigsp.2014.10.07
   Rafsanjani HK, 2017, DIGIT SIGNAL PROCESS, V64, P71, DOI 10.1016/j.dsp.2017.02.004
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sara U., 2019, J COMPUT COMMUN, V7, P8, DOI [10.4236/jcc.2019.73002, DOI 10.4236/JCC.2019.73002]
   Shao L, 2014, IEEE T CYBERNETICS, V44, P1001, DOI 10.1109/TCYB.2013.2278548
   Shen Y, 2017, IEEE SIGNAL PROC LET, V24, P877, DOI 10.1109/LSP.2017.2688707
   Strong D, 2003, INVERSE PROBL, V19, pS165, DOI 10.1088/0266-5611/19/6/059
   Tang LM, 2016, EURASIP J ADV SIG PR, DOI 10.1186/s13634-016-0315-5
   Wang JH, 2017, INFORM SCIENCES, V402, P69, DOI 10.1016/j.ins.2017.03.023
   Wang XH, 2015, INT J APPL EARTH OBS, V34, P89, DOI 10.1016/j.jag.2014.06.001
   Wei J., 2020, ASS ADVANCEMENT ARTI, V34, P12321, DOI DOI 10.1609/AAAI.V34I07.6916
   Xu JL, 2017, MULTIMED TOOLS APPL, V76, P8131, DOI 10.1007/s11042-016-3451-x
   Xu JL, 2016, AEU-INT J ELECTRON C, V70, P1128, DOI 10.1016/j.aeue.2016.05.008
   Yan J, 2015, MULTIDIM SYST SIGN P, V26, P243, DOI 10.1007/s11045-013-0255-2
   Yue HJ, 2014, PROC CVPR IEEE, P2933, DOI 10.1109/CVPR.2014.375
   Zhang XJ, 2017, COMPUT MATH APPL, V74, P2529, DOI 10.1016/j.camwa.2017.07.036
   Zhao J, 2020, IEEE T FUZZY SYST, V28, P2287, DOI 10.1109/TFUZZ.2019.2930492
NR 41
TC 9
Z9 9
U1 2
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 20947
EP 20971
DI 10.1007/s11042-020-08871-0
EA APR 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000529468100004
DA 2024-07-18
ER

PT J
AU Kamrani, A
   Zenkouar, K
   Najah, S
AF Kamrani, Abdelhalim
   Zenkouar, Khalid
   Najah, Said
TI A new set of image encryption algorithms based on discrete orthogonal
   moments and Chaos theory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Discrete orthogonal moments; Chaos cryptography; DCT
ID PATTERN-RECOGNITION; COSINE-TRANSFORM; INVARIANTS; COMPUTATION;
   KRAWTCHOUK; EFFICIENT; WAVELET; SCHEME
AB In this paper, we introduce a new set of image encryption algorithms based on orthogonal discrete moments and chaos. Two logisitic maps are used to confuse and diffuse the moments' coefficients obtained using: Tchebichef, Krawtchouk, Hahn, dual Hahn and Racah. An external key of 128 bits is used as the encryption key, some mathematical operations are performed on the key to adapt it as the initial conditions of the logisitic maps. Several experiments are carried out to evaluate the security of the newly introduced algorithms: entropy, key space analysis, statistical and differential attacks. The results obtained show clearly that the proposed algorithms are secure enough to resist any type of known attacks. A comparative study with a similar algorithm operating in the Discrete Transform Domain (DCT) and the state-of-the-art methods validates the superiority of moments' domains particularly in highly textured images.
C1 [Kamrani, Abdelhalim; Zenkouar, Khalid; Najah, Said] Sidi Mohamed Ben Abdellah Univ, Lab Intelligent Syst & Applicat LSIA, Fac Sci & Technol, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP Kamrani, A (corresponding author), Sidi Mohamed Ben Abdellah Univ, Lab Intelligent Syst & Applicat LSIA, Fac Sci & Technol, Fes, Morocco.
EM abdelhalim.kamrani@usmba.ac.ma; khalid.zenkouar@usmba.ac.ma;
   said.najah@usmba.ac.ma
RI najah, said/ABB-8982-2021
FU Laboratory of Intelligent Systems and Applications (LSIA)
FX The authors thankfully acknowledge the Laboratory of Intelligent Systems
   and Applications (LSIA) for his support to achieve this work.
CR Ahmad J, 2015, WIRELESS PERS COMMUN, V84, P901, DOI 10.1007/s11277-015-2667-9
   Ahmed HAM, 2007, INZ MINER, P1
   Bailey RR, 1996, IEEE T PATTERN ANAL, V18, P389, DOI 10.1109/34.491620
   Baptista MS, 1998, PHYS LETT A, V240, P50, DOI 10.1016/S0375-9601(98)00086-3
   Batioua I, 2017, PATTERN RECOGN, V71, P264, DOI 10.1016/j.patcog.2017.06.013
   Batioua I, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0172-7
   Benouini R, 2018, MULTIMED TOOLS APPL, P1
   Benouini R, 2019, PATTERN RECOGN, V86, P332, DOI 10.1016/j.patcog.2018.10.001
   Bianco ME, 1991, US Patent, Patent No. [5,048,086, 5048086]
   CASASENT D, 1984, OPT COMMUN, V51, P227, DOI 10.1016/0030-4018(84)90047-6
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen CS, 2006, SEVENTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES, PROCEEDINGS, P61
   Deng C, 2009, SIGNAL PROCESS, V89, P1531, DOI 10.1016/j.sigpro.2009.02.005
   Dudani S. A., 1977, IEEE Transactions on Computers, VC-26, P39, DOI 10.1109/TC.1977.5009272
   El-Ashry I, 2010, THESIS
   El-Wahed M.A., 2008, P WORLD C ENG, V1, P2
   Elkamchouchi HM, 2005, RAD SCI C 2005 NRSC, P277, DOI DOI 10.1109/NRSC.2005.194011
   Enayatifar R, 2013, OPT LASER ENG, V51, P1066, DOI 10.1016/j.optlaseng.2013.03.010
   Fishawy NFE., 2007, INT J NETWORK SECUR, V5, P241
   FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Ge X., 2010, 2010 2 IEEE INT C IN
   GHOSAL S, 1993, PATTERN RECOGN, V26, P295, DOI 10.1016/0031-3203(93)90038-X
   Guan MM, 2019, IET IMAGE PROCESS, V13, P1535, DOI 10.1049/iet-ipr.2019.0051
   HSU HS, 1993, OPT ENG, V32, P1596, DOI 10.1117/12.139804
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hussain I, 2012, OPT COMMUN, V285, P4887, DOI 10.1016/j.optcom.2012.06.011
   Jiang NZX, 2006, ADV MACHINE VISION I
   Jolfaei A, 2016, IEEE T INF FOREN SEC, V11, P235, DOI 10.1109/TIFS.2015.2489178
   Khan JS, 2019, MULTIDIM SYST SIGN P, V30, P943, DOI 10.1007/s11045-018-0589-x
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Khotanzad A, 1996, IEEE T NEURAL NETWOR, V7, P897, DOI 10.1109/72.508933
   Kotulski Z, 1997, ANN PHYS-LEIPZIG, V6, P381, DOI 10.1002/andp.19975090504
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Li S, 2004, IACR's Crypto ePrint Arch Rep, V374, P2004
   Li SJ, 2007, IEEE T CIRC SYST VID, V17, P214, DOI 10.1109/TCSVT.2006.888840
   Lian S., 2008, Multimedia Content Encryption: Techniques And Applications
   Liang JY, 2004, INT J UNCERTAIN FUZZ, V12, P37, DOI 10.1142/S0218488504002631
   Liu S, 2014, OPT LASER TECHNOL, V57, P327, DOI 10.1016/j.optlastec.2013.05.023
   Luo YL, 2015, COMMUN NONLINEAR SCI, V20, P447, DOI 10.1016/j.cnsns.2014.05.022
   MARKANDEY V, 1992, IEEE T ROBOTIC AUTOM, V8, P186, DOI 10.1109/70.134273
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Naeem EA, 2016, COMPUT ELECTR ENG, V54, P450, DOI 10.1016/j.compeleceng.2015.08.018
   Nakagaki K, 2007, IEEE SIGNAL PROC LET, V14, P684, DOI 10.1109/LSP.2007.898331
   Papakostas GA, 2008, PATTERN RECOGN, V41, P1895, DOI 10.1016/j.patcog.2007.11.015
   Papakostas GA, 2010, APPL MATH COMPUT, V216, P1, DOI 10.1016/j.amc.2010.01.051
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Radwan AG, 2016, J ADV RES, V7, P193, DOI 10.1016/j.jare.2015.07.002
   Padilla-López JR, 2015, EXPERT SYST APPL, V42, P4177, DOI 10.1016/j.eswa.2015.01.041
   Sankpal PR, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P102, DOI 10.1109/ICSIP.2014.80
   See KW, 2007, APPL MATH COMPUT, V193, P346, DOI 10.1016/j.amc.2007.03.080
   Sen Teh J, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102421
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Suk T, 2003, PATTERN RECOGN, V36, P2895, DOI 10.1016/S0031-3203(03)00187-0
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Tedmori S, 2014, INFORM SCIENCES, V269, P21, DOI 10.1016/j.ins.2014.02.004
   Tsougenis ED, 2015, MULTIMED TOOLS APPL, V74, P3985, DOI 10.1007/s11042-013-1808-y
   WALLIN A, 1995, IEEE T PATTERN ANAL, V17, P1106, DOI 10.1109/34.473239
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang W, 2016, WIRELESS COMMUNICATION AND SENSOR NETWORK, P711
   Wang W, 2018, COMPUT ELECTR ENG, V65, P282, DOI 10.1016/j.compeleceng.2017.07.026
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wu JH, 2013, J MOD OPTIC, V60, P1760, DOI 10.1080/09500340.2013.858189
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xiong ZG, 2019, MULTIMED TOOLS APPL, V78, P31035, DOI 10.1007/s11042-018-7081-3
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Ye GD, 2018, NONLINEAR DYNAM, V94, P745, DOI 10.1007/s11071-018-4391-y
   Ye GD, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9191-x
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhou J, 2005, LECT NOTES COMPUT SC, V3656, P524, DOI 10.1007/11559573_65
   Zhu HQ, 2007, PATTERN RECOGN LETT, V28, P1688, DOI 10.1016/j.patrec.2007.04.013
   Zhu HQ, 2007, SIGNAL PROCESS, V87, P687, DOI 10.1016/j.sigpro.2006.07.007
NR 76
TC 18
Z9 18
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 20263
EP 20279
DI 10.1007/s11042-020-08879-6
EA APR 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000558430400002
DA 2024-07-18
ER

PT J
AU Xiao, ZL
   Liu, H
   Zhou, GQ
   Zhu, F
   Jin, HY
AF Xiao, Zhaolin
   Liu, Huan
   Zhou, Guoqing
   Zhu, Feng
   Jin, Haiyan
TI Behavioral features fusion for ethological CNN classification of open
   field test videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Open field test; Support vector machine;
   Video classification; Behavioral feature fusion
ID SVM
AB In both ethological and pharmacological experiments, open field test (OFT) is a classic experiment for measuring mouse general activity and exploratory behaviors. The OFT manual analysis is usually a time consuming and costly process. In this paper, we propose a convolutional neural network (CNN) based classification, which can automatically sort out two groups of mice with different behaviors. We first extract the multi-modality features from both spatial and time domain of the OFT video. Then, all extracted features are regularized and fused to a 2D behavior feature map. Finally, we train a CNN network to distinguish mice with different behaviors. On real OFT datasets experiments, the proposed classification significantly outperforms other methods.
C1 [Xiao, Zhaolin; Liu, Huan; Jin, Haiyan] Xian Univ Technol, Dept Comp Sci & Engn, Xian, Peoples R China.
   [Zhou, Guoqing] Northwestern Polytech Univ, Dept Comp Sci, Xian, Peoples R China.
   [Zhu, Feng] Xi An Jiao Tong Univ, Ctr Translat Med, Affiliated Hosp 1, Xian, Peoples R China.
C3 Xi'an University of Technology; Northwestern Polytechnical University;
   Xi'an Jiaotong University
RP Jin, HY (corresponding author), Xian Univ Technol, Dept Comp Sci & Engn, Xian, Peoples R China.
EM jinhaiyan@xaut.edu.cn
RI Zhou, Guoqing/JYP-4413-2024
FU NSFC funds [61871319]; ShaanXi Province [2019JM-221, 2016JQ8026]
FX This work was partially supported by NSFC funds (No.61871319), research
   grant of ShaanXi Province (No.2019JM-221,2016JQ8026).
CR An-An Liu, 2017, IEEE Transactions on Pattern Analysis and Machine Intelligence, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   [Anonymous], 2018, IEEE T INTELL TRANSP
   Burgos-Artizzu XP, 2012, PROC CVPR IEEE, P1322, DOI 10.1109/CVPR.2012.6247817
   CHENGGANG Y, 2019, CROSS MODALITY BRIDG, V21
   Choleris E, 2001, NEUROSCI BIOBEHAV R, V25, P235, DOI 10.1016/S0149-7634(01)00011-2
   DECKER C, 2014, 22 INT C PATT REC WO, P4
   Deng L., 2014, FOND T SIGN PROC, V7, P197, DOI [10.1561/2000000039, DOI 10.1561/2000000039, 10.1561/]
   Durand T, 2015, IEEE I CONF COMP VIS, P2713, DOI 10.1109/ICCV.2015.311
   Giancardo L, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0074557
   Hall CS, 1934, J COMP PSYCHOL, V18, P385, DOI 10.1037/h0071444
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong WZ, 2015, P NATL ACAD SCI USA, V112, pE5351, DOI 10.1073/pnas.1515982112
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jibanpriya Devi L., 2018, INT J ENG TECHNOL, V7, P81, DOI [10.14419/ijet.v7i1.2.8999, DOI 10.14419/IJET.V7I1.2.8999]
   Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Katsageorgiou VM, 2016, INT C PATT RECOG, P925, DOI 10.1109/ICPR.2016.7899754
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lin W.-H., 2002, Proceedings of the Tenth ACM International Conference on Multimedia, P323, DOI DOI 10.1145/641043.641075
   Liu J, 2019, IEEE T IMAGE PROCESS, V28, P4926, DOI 10.1109/TIP.2019.2912294
   Liu J, 2018, IEEE T IMAGE PROCESS, V27, P4860, DOI 10.1109/TIP.2018.2803306
   Min XK, 2018, IEEE T MULTIMEDIA, V20, P2049, DOI 10.1109/TMM.2017.2788206
   Min XK, 2018, IEEE T BROADCAST, V64, P508, DOI 10.1109/TBC.2018.2816783
   Monteiro JP, 2014, IEEE IMAGE PROC, P2261, DOI 10.1109/ICIP.2014.7025458
   Nair A., 2015, Massively parallel methods for deep reinforcement learning
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   NOVAKOVA J, 1997, SCRIPTA MED, V70, P267
   Ren J, 2016, AAAI CONF ARTIF INTE, P3581
   Sáenz JCB, 2006, BEHAV BRAIN RES, V169, P57, DOI 10.1016/j.bbr.2005.12.001
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Simon T, 2010, IEEE COMP VIS PATTER, DOI [10.1109/CVPR.2010.5539998, DOI 10.1109/CVPR.2010.5539998]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tarabalka Y, 2010, IEEE GEOSCI REMOTE S, V7, P736, DOI 10.1109/LGRS.2010.2047711
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Xu N, 2019, IEEE T CIRC SYST VID, V29, P2482, DOI 10.1109/TCSVT.2018.2867286
   Xu Zhenqi, 2016, 2016 IEEE INT C MULT, P1, DOI [10.1109/ICME.2016.7552971, DOI 10.1109/ICME.2016.7552971]
   Yu ZF, 2002, J ETHNOPHARMACOL, V83, P161, DOI 10.1016/S0378-8741(02)00211-8
NR 40
TC 1
Z9 1
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16283
EP 16297
DI 10.1007/s11042-020-08858-x
EA APR 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000526205900001
DA 2024-07-18
ER

PT J
AU Jaffar, MA
   Zia, MS
   Hussain, M
   Siddiqui, AB
   Akram, S
   Jamil, U
AF Jaffar, M. Arfan
   Zia, M. Sultan
   Hussain, Majid
   Siddiqui, Abdul Basit
   Akram, Sheeraz
   Jamil, Uzma
TI An ensemble shape gradient features descriptor based nodule detection
   paradigm: a novel model to augment complex diagnostic decisions
   assistance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shape-based features; CT-scan imaging; Segmentation; Nodules detection;
   Particle swarm optimization; Random forest
ID LUNG NODULES; AUTOMATIC DETECTION; PULMONARY NODULES; CANCER STATISTICS;
   DETECTION SYSTEM; CLASSIFICATION; SEGMENTATION; IMAGES
AB Primarily, there are three basic operational constituents of Nodule Detection Systems namely nodule candidate detection, classification of nodule and extraction of features. Thresholding is one of the most important factor for nodule detection. To segment the lungs and nodules, Gaussian approximation based Particle Swarm Optimization (PSO) is used to determine the optimal threshold value. After extracting lungs part, 2D and 3D region of interests (ROI's) are used to detect nodules with area and volume information of nodules and then distinguish between wall and vessels by using fuzzy C-mean. There are three key objects namely wall, nodule and vessel in the lugs volume with specific shape. Shape-based features with Histogram of Oriented Surface Normal Vectors (HOSNV) are used as a feature descriptor. A scaled and rotation invariant multi-coordinate histogram of thegradient is used to identify nodules with different sizes and directionless shapes. So, a Novel Ensemble Shape Gradient Features (NESGF) descriptor for pulmonary nodule classification is proposed using the Histogram of Oriented Surface Normal Vectors and Multi-Coordinate Histogram of Gradient descriptor. The random forest has been used to classify the nodules through intelligent usage of the ensemble concepts to learn weak classifiers. A standard benchmark database Lung Image Consortium Database (LICD) is used for testing and validation purposes. In order to show the performance of segmentation quality, the proposed model is compared through three quantitative measures inclusive of Variation of Information (VoI), Probabilistic Rand Index (PRI) and Jaccard Measure. The methods Area Under Curve, Sensitivity, Specificity and Sensitivity have are used for classification. For classification, accuracy, sensitivity, specificity and Area under curve (AUC) has been used.
C1 [Jaffar, M. Arfan] Al Imam Mohammad Ibn Saud Islamic Univ IMSIU, Riyadh, Saudi Arabia.
   [Zia, M. Sultan; Hussain, Majid] COMSATS Inst Sci & Technol, Sahiwal, Pakistan.
   [Siddiqui, Abdul Basit] Capital Univ Sci & Technol, Fac Comp, Islamabad, Pakistan.
   [Akram, Sheeraz] Fdn Univ, Dept Software Engn, Islamabad, Pakistan.
   [Jamil, Uzma] Bahria Univ, Comp Vis & Machine Learning Res Grp, Islamabad, Pakistan.
C3 Imam Mohammad Ibn Saud Islamic University (IMSIU); COMSATS University
   Islamabad (CUI); Capital University of Science & Technology
RP Jaffar, MA (corresponding author), Al Imam Mohammad Ibn Saud Islamic Univ IMSIU, Riyadh, Saudi Arabia.
EM majaffar@imamu.edu.sa; ziactn@ciitsahiwal.edu.pk;
   majidhussain@ciitsahiwal.edu.pk; abasit.siddiqui@cust.edu.pk;
   sheeraz@fui.edu.pk
RI Hussain, Majid/JXL-6148-2024; Jamil, Uzma/HLG-0716-2023; Akram,
   Sheeraz/AAA-6893-2020; Jaffar, Arfan/GQB-2768-2022; Basit, Muhammad
   Abdul/JJN-5751-2023
OI Hussain, Majid/0009-0002-5968-0509; Akram, Sheeraz/0000-0003-2321-3845;
   Basit, Abdul/0000-0002-2113-5524
CR Akram S., 2015, Appl. Math. Inf. Sci., V9, P183, DOI [10.12785/amis/090124, DOI 10.12785/AMIS/090124]
   Akram S, 2015, J EXP THEOR ARTIF IN, V27, P737, DOI 10.1080/0952813X.2015.1020526
   [Anonymous], 2017, CLUSTER COMPUTING
   Archer KJ, 2008, COMPUT STAT DATA AN, V52, P2249, DOI 10.1016/j.csda.2007.08.015
   Choi WJ, 2013, ENTROPY-SWITZ, V15, P507, DOI 10.3390/e15020507
   Choi WJ, 2012, INFORM SCIENCES, V212, P57, DOI 10.1016/j.ins.2012.05.008
   Dehmeshki J, 2007, COMPUT MED IMAG GRAP, V31, P408, DOI 10.1016/j.compmedimag.2007.03.002
   Sousa JRFD, 2010, COMPUT METH PROG BIO, V98, P1, DOI 10.1016/j.cmpb.2009.07.006
   Greenlee RT, 2000, CA-CANCER J CLIN, V50, P7, DOI 10.3322/canjclin.50.1.7
   Hussain M, 2016, J SENSORS, V2016, DOI 10.1155/2016/6319830
   Jabbar S, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-32
   Jaffar MA, 2012, INT J COMPUT INT SYS, V5, P494, DOI 10.1080/18756891.2012.696913
   Jaffar MA, 2011, INT J INNOV COMPUT I, V7, P5495
   Jaffar MA, 2010, KNOWL INF SYST, V24, P91, DOI 10.1007/s10115-009-0225-z
   Suárez-Cuenca JJ, 2009, COMPUT BIOL MED, V39, P921, DOI 10.1016/j.compbiomed.2009.07.005
   Jung KW, 2009, J KOREAN MED SCI, V24, P995, DOI 10.3346/jkms.2009.24.6.995
   Khalid S, 2017, J REAL-TIME IMAGE PR, V13, P449, DOI 10.1007/s11554-015-0545-z
   Khalid S, 2017, J PARALLEL DISTR COM, V110, P16, DOI 10.1016/j.jpdc.2017.04.004
   Khalid S, 2014, SCI WORLD J, DOI 10.1155/2014/492387
   Lee SLA, 2010, COMPUT MED IMAG GRAP, V34, P535, DOI 10.1016/j.compmedimag.2010.03.006
   Liao XL, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0160556
   Masoumi H, 2012, BIOMED SIGNAL PROCES, V7, P429, DOI 10.1016/j.bspc.2012.01.002
   Messay T, 2010, MED IMAGE ANAL, V14, P390, DOI 10.1016/j.media.2010.02.004
   Opfer R, 2007, PROC SPIE, V6515, DOI 10.1117/12.708210
   Reeves AP, 2007, ACAD RADIOL, V14, P1475, DOI 10.1016/j.acra.2007.09.005
   Rubin GD, 2005, RADIOLOGY, V234, P274, DOI 10.1148/radiol.2341040589
   Sahiner B, 2007, PROC SPIE, V6515, DOI 10.1117/12.709851
   Song Y, 2013, IEEE T MED IMAGING, V32, P797, DOI 10.1109/TMI.2013.2241448
   Suzuki K, 2003, MED PHYS, V30, P1602, DOI 10.1118/1.1580485
   Tan M, 2011, MED PHYS, V38, P5630, DOI 10.1118/1.3633941
   Ye XJ, 2009, IEEE T BIO-MED ENG, V56, P1810, DOI 10.1109/TBME.2009.2017027
   Zia M.S., 2018, Multimedia Tools and Applications, P1
   Zia MS, 2015, MULTIMED TOOLS APPL, V74, P3881, DOI 10.1007/s11042-013-1803-3
   Zia S, 2012, MICROSC RES TECHNIQ, V75, P1044, DOI 10.1002/jemt.22029
NR 34
TC 8
Z9 8
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8649
EP 8675
DI 10.1007/s11042-018-6092-4
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600016
DA 2024-07-18
ER

PT J
AU Jia, W
AF Jia, Wang
TI A novel image registration control system based on improved composite
   metric entropy function in color printing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image registration; Overprint; Color printing system; Measurement
   entropy; Sequential similarity detection; Similarity measure
AB The accuracy of overprint is one of the essential factors for the qualities of modern color printing technology. Using machine vision technology and image processing technology to detect overprint quality can steadily and accurately monitor overprint quality and avoid the disadvantages of human eyes detection. This paper firstly introduces the gradient entropy and direction constraint into sequential similarity detection algorithm (SSDA); then a novel joint function is proposed as similarity measure function; finally, Powell optimization algorithm is adopted to optimize the registration parameters. Simulation results, in both qualitative and quantitative, show that our proposed algorithm noticeably reduces the registration error compared with the traditional method. The obtained accurate registration parameter would make it possible for identifying the overprint qualities, sending signal when the misregister and deviation adjusting signal occur. In brief, our proposed algorithm can make the printing machine automatically adjust the plate location and correct the standard deviation in color printing system.
C1 [Jia, Wang] Yunnan Open Univ, Dept Print Media Technol, 318 Qi Xiu St, Kunming 650500, Yunnan, Peoples R China.
RP Jia, W (corresponding author), Yunnan Open Univ, Dept Print Media Technol, 318 Qi Xiu St, Kunming 650500, Yunnan, Peoples R China.
EM 209959209@qq.com
CR Akinlar MA, 2012, ADV DIFFER EQU-NY, DOI 10.1186/1687-1847-2012-193
   Ashburner J, 2007, NEUROIMAGE, V38, P95, DOI 10.1016/j.neuroimage.2007.07.007
   Bruckstein AM, 1998, IEEE T INFORM THEORY, V44, P3156, DOI 10.1109/18.737548
   Eddy WF, 1996, MAGNET RESON MED, V36, P923, DOI 10.1002/mrm.1910360615
   Furferi R, 2013, IMAGING SCI J, V61, P183, DOI 10.1179/1743131X11Y.0000000041
   Guizar-Sicairos M, 2008, OPT LETT, V33, P156, DOI 10.1364/OL.33.000156
   Haber E, 2007, INT J COMPUT VISION, V71, P361, DOI 10.1007/s11263-006-8984-4
   Huber-Moerk R, 2007, PATTERN RECOGN LETT, V28, P2037, DOI 10.1016/j.patrec.2007.06.008
   Jia HJ, 2011, NEUROIMAGE, V54, P928, DOI 10.1016/j.neuroimage.2010.09.019
   Kuo C, 2011, AVIAN DIS, V55, P674, DOI [10.1637/9687-021511-ResNote.1, DOI 10.1637/9687-021511-RESNOTE.1]
   Li Y, 2017, IEEE T CYBERNETICS, V47, P1285, DOI 10.1109/TCYB.2016.2548484
   Martin S, 2004, ELECTRON LETT, V40, P595, DOI 10.1049/el:20040375
   Peng XM, 2007, OPT ENG, V46, DOI 10.1117/1.2737438
   Qiu PH, 2013, TECHNOMETRICS, V55, P174, DOI 10.1080/00401706.2012.727768
   Ren JX, 2017, COMPUT IND, V92-93, P152, DOI 10.1016/j.compind.2017.08.003
   Rogelj P, 2006, MED IMAGE ANAL, V10, P484, DOI 10.1016/j.media.2005.03.003
   Tang ZY, 2016, NEUROINFORMATICS, V14, P131, DOI 10.1007/s12021-015-9285-2
   Yang LJ, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.025014
   Zhang HY, 2015, INT J FUZZY SYST, V17, P353, DOI 10.1007/s40815-015-0039-y
   Zhang YL, 2006, OPT ENG, V45, DOI 10.1117/1.2208587
   Zhong Zhang, 2001, Information Fusion, V2, P135, DOI 10.1016/S1566-2535(01)00020-3
NR 21
TC 0
Z9 0
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9225
EP 9236
DI 10.1007/s11042-019-7279-z
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600048
DA 2024-07-18
ER

PT J
AU Puhalanthi, N
   Lin, DT
AF Puhalanthi, Niraimathi
   Lin, Daw-Tung
TI Effective multiple person recognition in random video sequences using a
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person recognition; Deep learning; Convolutional neural network;
   Landmark identification; Face alignment; VGG; CASIA WebFace database;
   LFW database
AB Effective and efficient face recognition through pervasive networks of surveillance cameras is one of the most challenging objectives of advanced computer vision. This study developed a real-time person recognition system (PRS) for the effective identification of multiple people in video sequences. We focused on identifying approximately 9000 celebrities by intelligent preprocessing, training, and deployment of a deep-learning convolutional neural network (CNN). The proposed PRS method comprises the following three major steps. In the first step, multiple faces present in a given frame as well as their associated landmarks are detected. This must be precise because the accuracy of this step dictates the accuracy of the complete PRS. In the second step, the extracted facial regions of interest are then aligned using affine warping, based on their respective identified landmark positions. The alignment process is meant to ensure correct identification of a person, because a wide range of faces entails intrinsic interclass similarities. Finally, in the third step, a VGG-19 CNN is trained to classify the aligned facial images for person recognition. In the training phase of the PRS, we utilized images from the CASIA WebFace database, which contains nearly 9000 classes, and aligned them using their respective facial landmarks. Subsequently, we used the aligned images to train a VGG-19 CNN classifier. For the purpose of validation, the trained classifier was tested with the standard Labelled Faces in the Wild (LFW) database by extracting the features for the LFW images using the trained VGG. Specifically, the VGG-extracted LFW features were used to train support vector machine classifiers, and the obtained resultant classification accuracy of approximately 96% was very close to the currently existing benchmark for the LFW database. During the testing phase, alternate frames of the input video were extracted and the identified faces (post-alignment) were used as inputs into the trained VGG to recognize the people in a given frame. When tested on random samples of video images, the proposed PRS offered robust recognition performance for most of the facial regions that had reasonable facial orientations and sizes. Furthermore, the average recognition time per person was approximately 370 milliseconds. The proposed deep learning-based PRS is the first of its kind to exhibit real-time performance for person recognition with significant accuracy, without involving any prior knowledge of the people involved in a video.
C1 [Puhalanthi, Niraimathi; Lin, Daw-Tung] Natl Taipei Univ, Dept Comp Sci & Informat Engn, New Taipei, Taiwan.
C3 National Taipei University
RP Lin, DT (corresponding author), Natl Taipei Univ, Dept Comp Sci & Informat Engn, New Taipei, Taiwan.
EM niraingt@gmail.com; dalton@mail.ntpu.edu.tw
RI Lin, Daw-Tung/B-7043-2009
OI Lin, Daw-Tung/0000-0003-3261-806X
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], 2012, P BRIT MACH VIS C
   [Anonymous], P INT C AUT FAC GEST
   Baltrusaitis T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P354, DOI 10.1109/ICCVW.2013.54
   Bloice M.D., 2017, ARXIV170804680, V2, P1, DOI DOI 10.21105/JOSS.00432
   Cao XD, 2013, IEEE I CONF COMP VIS, P3208, DOI 10.1109/ICCV.2013.398
   Chen D, 2012, LECT NOTES COMPUT SC, V7574, P566, DOI 10.1007/978-3-642-33712-3_41
   Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Ding CX, 2018, IEEE T PATTERN ANAL, V40, P1002, DOI 10.1109/TPAMI.2017.2700390
   Fontaine X, 2017, INT CONF ACOUST SPEE, P1482, DOI 10.1109/ICASSP.2017.7952403
   Gonzalez C, 2010, DIGIT SIGNAL PROCESS, V20, P806, DOI [10.1016/j.dsp.2009.10.008, DOI 10.1016/J.DSP.2009.10.008]
   Gonzalez-Sosa E, 2018, IEEE T INF FOREN SEC, V13, P2001, DOI 10.1109/TIFS.2018.2807791
   Hauberg S, 2016, P 19 INT C ART INT S
   Hu LQ, 2017, IEEE INT CONF AUTOMA, P9, DOI 10.1109/FG.2017.12
   Huang G. B., 2012, NIPS
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Keren D, 2001, IEEE T PATTERN ANAL, V23, P747, DOI 10.1109/34.935848
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   LeCun Y., 1990, ADV NEURAL INFORM PR, P396
   Lee KC, 2003, P CVPR, V1
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Ludwiczuk B., 2016, Tech. Rep. CMU-CS-16-118
   Masi I., 2018, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Sund T, 2006, DENTOMAXILLOFAC RAD, V35, P133, DOI 10.1259/dmfr/21936923
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   YANG JL, 2017, PROC CVPR IEEE, P5216, DOI DOI 10.1109/CVPR.2017.554
   Yi Dong, 2014, ARXIV14117923
   Yin XX, 2017, HEALTH INFOR SCI, P1, DOI [10.1109/ICCV.2017.430, 10.1007/978-3-319-57027-3_1]
   Yonggang Lu, 2017, Multimedia Tools and Applications, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Zhao J, 2018, PROC CVPR IEEE, P2207, DOI 10.1109/CVPR.2018.00235
   Zhou E., 2015, arXiv preprint arXiv:1501.04690
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 44
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 11125
EP 11141
DI 10.1007/s11042-019-7323-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600075
DA 2024-07-18
ER

PT J
AU Rakesh, Y
   Krishna, KR
AF Rakesh, Y.
   Krishna, Rama K.
TI Short time fourier transform with coefficient optimization for detecting
   salient regions in stereoscopic 3D images: GSDU
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Human vision; Feature extraction; Depth saliency
   detection; STFT; GSDU
ID VISUAL-ATTENTION; TARGET DETECTION; ALGORITHM; MODEL
AB In multimedia scenario, number of saliency detection designs has been portrayed for different intelligent applications regarding the accurate saliency detection like human visual system. More challenges exist regarding complexity in natural images and lesser scale prototypes in salient objects. In lots of the prevailing methods, the competency of identifying objects' instances in the discovered salient regions is still not up to the mark. Hence it is planned to assist a new strategy by considering certain parameters of feature evaluation under optimization algorithms which diverts the new method of capturing the optimal parameters to acquire better outcomes. The given paper proposes a new saliency detection design that encompasses 2 phases like Feature extraction and depth saliency detection. In which Gaussian kernel model is processed for extracting the STFT features (Short-Time Fourier Transform), Texture features, and Depth features; and Gabor filter is used to get the depth saliency map. Here, the color space information is progressed under STFT model for extracting the STFT features. This is the major contribution, where all the STFT feature, Texture feature and Depth features are taken out to gain the depth saliency map. Additionally, this paper proffers a new optimization prototype that optimizes 2 coefficients namely feature difference amongst image patches from feature evaluation, and fine scale, by which more precise saliency detection outcomes can be attained through the proposed model. Subsequently, the proposed GSDU (Glowworm Swarm optimization with Dragonfly Update) contrasts its performance over other conventional methodologies concerning i) ROC (Receiver Operator Curve), ii) PCC (Pearson Correlation Coefficient), iii) KLD (Kullback Leibler Divergence) as well as iv) AUC (Area Under the Curve), and the efficiency of proposed model is proven grounded on higher accuracy rate.
C1 [Rakesh, Y.] UshaRama Coll Engn & Technol, Dept ECE, Gannavaram, India.
   [Krishna, Rama K.] Velagapudi Ramakrishna Siddhartha Engn Coll, Dept ECE, Vijayawada, India.
C3 Velagapudi Ramakrishna Siddhartha Engineering College
RP Rakesh, Y (corresponding author), UshaRama Coll Engn & Technol, Dept ECE, Gannavaram, India.
EM rakesh.yemineni@gmail.com; kalvasrk@gmail.com
RI K, SRI RAMA KRISHNA/GNH-2309-2022; YEMINENI, RAKESH/JCD-8293-2023
OI K, SRI RAMA KRISHNA/0000-0002-7479-649X; Yemineni,
   Rakesh/0000-0002-6131-4025; Y, Rakesh/0000-0002-2199-4601
CR Ahn E, 2017, IEEE J BIOMED HEALTH, V21, P1685, DOI 10.1109/JBHI.2017.2653179
   Cao XC, 2014, IEEE T IMAGE PROCESS, V23, P4175, DOI 10.1109/TIP.2014.2332399
   Chen HZ, 2014, IEEE GEOSCI REMOTE S, V11, P24, DOI 10.1109/LGRS.2013.2244845
   Chen ZZ, 2013, IEEE SIGNAL PROC LET, V20, P95, DOI 10.1109/LSP.2012.2230442
   Cong RM, 2016, IEEE SIGNAL PROC LET, V23, DOI 10.1109/LSP.2016.2557347
   Diao WH, 2016, IEEE GEOSCI REMOTE S, V13, P137, DOI 10.1109/LGRS.2015.2498644
   Dinh CV, 2011, IMAGE VISION COMPUT, V29, P546, DOI 10.1016/j.imavis.2011.06.002
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P2625, DOI 10.1109/TIP.2014.2305100
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Gao F, 2018, IEEE ACCESS, V6, P1000, DOI 10.1109/ACCESS.2017.2777444
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Ishikura K, 2018, IEEE T IMAGE PROCESS, V27, P703, DOI 10.1109/TIP.2017.2767288
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jafari M, 2017, EUR J MECH A-SOLID, V66, P1, DOI 10.1016/j.euromechsol.2017.06.003
   Li SQ, 2017, NEUROCOMPUTING, V230, P173, DOI 10.1016/j.neucom.2016.12.026
   Li ZC, 2011, IEEE T IMAGE PROCESS, V20, P2017, DOI 10.1109/TIP.2010.2099128
   Ma L, 2010, ELECTRON LETT, V46, P1066, DOI 10.1049/el.2010.0072
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Pedersen MEH, 2010, APPL SOFT COMPUT, V10, P618, DOI 10.1016/j.asoc.2009.08.029
   Quan HL, 2017, IEEE ACCESS, V5, P23519, DOI 10.1109/ACCESS.2017.2764503
   Ren ZX, 2013, IEEE T IMAGE PROCESS, V22, P3120, DOI 10.1109/TIP.2013.2259837
   Tang LZ, 2018, IEEE ACCESS, V6, P913, DOI 10.1109/ACCESS.2017.2776344
   Wang ZC, 2018, IEEE T GEOSCI REMOTE, V56, P1855, DOI 10.1109/TGRS.2017.2769045
   Yang JF, 2017, IET COMPUT VIS, V11, P710, DOI 10.1049/iet-cvi.2016.0469
   Zhang CQ, 2015, PATTERN RECOGN LETT, V63, P66, DOI 10.1016/j.patrec.2015.06.012
   Zhang LB, 2017, IEEE GEOSCI REMOTE S, V14, P2433, DOI 10.1109/LGRS.2017.2768070
   Zhang YB, 2016, NEUROCOMPUTING, V203, P34, DOI 10.1016/j.neucom.2016.04.005
   Zhou CB, 2014, IET COMPUT VIS, V8, P254, DOI 10.1049/iet-cvi.2012.0266
   Zhou YZ, 2013, APPL SOFT COMPUT, V13, P390, DOI 10.1016/j.asoc.2012.08.014
   Zhou YQ, 2013, APPL MATH INFORM SCI, V7, P537, DOI 10.12785/amis/072L24
NR 31
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8801
EP 8824
DI 10.1007/s11042-018-6686-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600023
DA 2024-07-18
ER

PT J
AU Xu, C
   Sun, JR
   Wang, CH
AF Xu, Cong
   Sun, Jingru
   Wang, Chunhua
TI A novel image encryption algorithm based on bit-plane matrix rotation
   and hyper chaotic systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaos; Bit-plane; Rotation; Chaotic; Cryptography
ID DNA ENCRYPTION; SCHEME; PERMUTATION; MAP
AB In this paper, we propose a new image encryption algorithm based on bit-plane matrix rotation and two hyper chaotic systems. The algorithm first decomposes the plain-image into eight bit planes and constructs a three-dimensional (3D) matrix. Then the sub-matrix of the 3D bit-plane matrix is rotated in different directions controlled by PRNS generated by a hyper-chaotic system. Finally, the pixel values of the intermediate image are modified by using another key stream. Furthermore, the initial values of diffusion and parameters related with generating chaotic sequences are produced by the MD5 hash function of the plain-image, which enhances the correlation between the encryption process and the plain-image. Simulation experiments are presented to analyze the image encryption scheme in terms of key space, histogram, information entropy, key sensitivity and adjacent pixels correlation index. Theoretical analysis and experimental results demonstrate that the proposed algorithm has excellent performance and suffcient security level.
C1 [Xu, Cong; Sun, Jingru; Wang, Chunhua] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
C3 Hunan University
RP Sun, JR (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
EM jt_sunjr@hnu.edu.cn
RI Wang, Chunhua/HCH-5464-2022; Sun, Jingru/KOC-4478-2024
OI Wang, Chunhua/0000-0001-6522-9795; Sun, Jingru/0000-0001-9474-7778
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   Chen JX, 2015, NONLINEAR DYNAM, V81, P1151, DOI 10.1007/s11071-015-2057-6
   Cheng GF, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419501153
   Fu C, 2011, OPT COMMUN, V284, P5415, DOI 10.1016/j.optcom.2011.08.013
   Grassi G, 2009, CHAOS SOLITON FRACT, V41, P284, DOI 10.1016/j.chaos.2007.12.003
   Hilborn R.C., 1994, AM J PHYS, V62, P861
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Jin J, 2019, COMPLEXITY, DOI 10.1155/2019/4106398
   Khan M, 2015, NONLINEAR DYNAM, V82, P527, DOI 10.1007/s11071-015-2173-3
   Khanzadi H, 2014, ARAB J SCI ENG, V39, P1039, DOI 10.1007/s13369-013-0713-z
   Li CQ, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102361
   Li CQ, 2018, IEEE MULTIMEDIA, V25, P46, DOI 10.1109/MMUL.2018.2873472
   Li CQ, 2018, IEEE ACCESS, V6, P75834, DOI 10.1109/ACCESS.2018.2883690
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Li SJ, 2007, IEEE T CIRC SYST VID, V17, P214, DOI 10.1109/TCSVT.2006.888840
   Liu DD, 2018, SIGNAL PROCESS, V151, P130, DOI 10.1016/j.sigpro.2018.05.008
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu JY, 2018, MULTIMED TOOLS APPL, V77, P10217, DOI 10.1007/s11042-017-5406-2
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Peng F, 2020, IEEE T CIRC SYST VID, V30, P2765, DOI 10.1109/TCSVT.2019.2924910
   Peng F, 2013, IEEE T INF FOREN SEC, V8, P1688, DOI 10.1109/TIFS.2013.2259819
   Ramasubramanian K, 2000, PHYSICA D, V139, P72, DOI 10.1016/S0167-2789(99)00234-1
   ROSSLER OE, 1979, PHYS LETT A, V71, P155, DOI 10.1016/0375-9601(79)90150-6
   Som S, 2019, MULTIMED TOOLS APPL, V78, P10373, DOI 10.1007/s11042-018-6539-7
   Sun S, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2017.2766087
   Tang ZJ, 2016, OPT LASER ENG, V80, P1, DOI 10.1016/j.optlaseng.2015.12.004
   Teng L, 2018, MULTIMED TOOLS APPL, V77, P6883, DOI 10.1007/s11042-017-4605-1
   Teng L, 2012, OPT COMMUN, V285, P4048, DOI 10.1016/j.optcom.2012.06.004
   Tong XJ, 2013, COMMUN NONLINEAR SCI, V18, P1725, DOI 10.1016/j.cnsns.2012.11.002
   Wang XY, 2008, PHYSICA A, V387, P3751, DOI 10.1016/j.physa.2008.02.020
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wang XY, 2015, NONLINEAR DYNAM, V79, P1141, DOI 10.1007/s11071-014-1729-y
   Wang XY, 2014, NONLINEAR DYNAM, V76, P1943, DOI 10.1007/s11071-014-1259-7
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2016, INFORM SCIENCES, V349, P137, DOI 10.1016/j.ins.2016.02.041
   Xiang LY, 2019, NEURAL PROCESS LETT, V49, P1055, DOI 10.1007/s11063-018-9892-7
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yin Q, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500475
   Zhang X, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419501177
   Zhang X, 2019, IEEE ACCESS, V7, P16336, DOI 10.1109/ACCESS.2019.2894853
   Zhang XP, 2014, NONLINEAR DYNAM, V75, P319, DOI 10.1007/s11071-013-1068-4
   Zhou L, 2018, INT J CIRC THEOR APP, V46, P84, DOI 10.1002/cta.2339
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
   Zhu CX, 2013, NONLINEAR DYNAM, V71, P25, DOI 10.1007/s11071-012-0639-0
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 54
TC 47
Z9 47
U1 1
U2 60
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5573
EP 5593
DI 10.1007/s11042-019-08273-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900007
DA 2024-07-18
ER

PT J
AU Feng, L
   Zhu, J
   Huang, LL
AF Feng, Lei
   Zhu, Jun
   Huang, Lili
TI Blind image recovery approach combing sparse and low-rank
   regularizations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind compressive sensing; Nonlocal low-rank regularization; Truncated
   Schatten-p norm; Alternative direction method of multipliers
ID ALGORITHM
AB The only useful prior knowledge in blind compressive sensing is that a signal is sparse in an unknown dictionary. Usually, general dictionaries cannot sparsify all images well. It simultaneously optimizes the dictionary and sparse coefficient in the reconstruction process and has been demonstrated to obtain same results as those compressive sensing techniques based on the known dictionary. In this paper, we propose a novel blind compressive sensing method combing sparse and low-rank regularizations to obtain competitive recovery results. We employ truncated Schatten-p norm and l(q) norm to approximate rank and norm. At last, we give an optimization strategy based on alternating direction method of multipliers to solve the recovery model. Experimental results prove that our approach could obtain the higher Peak Signal to Noise Ratio values than other competitive methods.
C1 [Feng, Lei; Zhu, Jun; Huang, Lili] Jinling Inst Technol, Sch Comp Engn, Nanjing 211169, Peoples R China.
C3 Jinling Institute of Technology
RP Feng, L (corresponding author), Jinling Inst Technol, Sch Comp Engn, Nanjing 211169, Peoples R China.
EM fenglei49232728@126.com; zhujun@jit.edu.cn; lili771012@jit.edu.cn
FU National Natural Science Foundation of China [61801199]; Natural Science
   Fund Project of Colleges in Jiangsu Province [18KJB520017]; High-level
   Talent Scientific Research Foundation of Jinling Institute of Technology
   [jit-b-201801, jit-b-201815]; Major Project of the Natural Science
   Foundation of the Jiangsu Higher Education Institutions of China
   [19KJA510004]
FX The authors would like to express their gratitude to the anonymous
   referees as well as the Editor and Associate Editor for their valuable
   comments, which led to substantial improvements of the paper. This work
   was supported by the National Natural Science Foundation of China (No.
   61801199), the Natural Science Fund Project of Colleges in Jiangsu
   Province (No. 18KJB520017), the High-level Talent Scientific Research
   Foundation of Jinling Institute of Technology (No. jit-b-201801 and
   jit-b-201815) and the Major Project of the Natural Science Foundation of
   the Jiangsu Higher Education Institutions of China (No. 19KJA510004).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2015, ARXIV150800278
   Ashwini K, 2018, MULTIMED TOOLS APPL, V77, P1
   Bhave S, 2016, MAGN RESON MED, V75, P1175, DOI 10.1002/mrm.25722
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Chartrand R, 2008, INT CONF ACOUST SPEE, P3869, DOI 10.1109/ICASSP.2008.4518498
   Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P3618, DOI 10.1109/TIP.2014.2329449
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730
   Egiazarian K, 2007, IEEE IMAGE PROC, P549
   Feng L, 2017, J VIS COMMUN IMAGE R, V42, P37, DOI 10.1016/j.jvcir.2016.11.007
   Feng L, 2016, NEUROCOMPUTING, V216, P45, DOI 10.1016/j.neucom.2016.07.012
   Feng L, 2016, SIGNAL PROCESS-IMAGE, V47, P28, DOI 10.1016/j.image.2016.05.012
   Gleichman S, 2011, IEEE T INFORM THEORY, V57, P6958, DOI 10.1109/TIT.2011.2165821
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Hawe S, 2013, IEEE T IMAGE PROCESS, V22, P2138, DOI 10.1109/TIP.2013.2246175
   He LH, 2009, IEEE T SIGNAL PROCES, V57, P3488, DOI 10.1109/TSP.2009.2022003
   Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271
   Lingala SG, 2013, IEEE T MED IMAGING, V32, P1132, DOI 10.1109/TMI.2013.2255133
   Majumdar A, 2015, MAGN RESON IMAGING, V33, P174, DOI 10.1016/j.mri.2014.08.031
   Silva J., 2011, ARXIV11032469
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Studer C, 2012, INT CONF ACOUST SPEE, P3341, DOI 10.1109/ICASSP.2012.6288631
   Zhang J, 2014, SIGNAL PROCESS, V103, P114, DOI 10.1016/j.sigpro.2013.09.025
   Zhang J, 2012, IEEE J EM SEL TOP C, V2, P380, DOI 10.1109/JETCAS.2012.2220391
NR 27
TC 0
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18059
EP 18070
DI 10.1007/s11042-019-08575-0
EA FEB 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516791200001
DA 2024-07-18
ER

PT J
AU Kanmani, M
   Narasimhan, V
AF Kanmani, Madheswari
   Narasimhan, Venkateswaran
TI Optimal fusion aided face recognition from visible and thermal face
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visible Image; Thermal Image; Image fusion; Multi-resolution; PSO STPSO;
   Curvelet transform; DT-DWT; Face recognition
ID DISCRETE COSINE TRANSFORM; PCA; REPRESENTATION; EIGENFACES
AB This paper proposes a novel Eigen face recognition that is aided by fusion of visible and thermal face images to improve the face recognition accuracy. We adopt three different fusion schemes where in the face information is fused by the optimal weights obtained by different optimization algorithms. The first two fusion approaches operate in the dual tree discrete wavelet transform (DT-DWT), while the third one operates in the Curvelet transform (CT) domain. We employ particle swarm optimization (PSO), self-tuning particle swarm optimization (STPSO) and brain storm optimization algorithm (BSO) to find optimal fusion coefficients. The proposed fusion aided face recognition approaches are evaluated through extensive experiments using OCTVBS benchmark face database and the Eigen face detection methodology. Simulation results show that proposed face recognition techniques have significant performance improvement in recognition accuracy suggesting fusion aided face recognition approach that deserves further study and consideration whenever high recognition accuracy is desired.
C1 [Kanmani, Madheswari] SSN Coll Engn, Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Narasimhan, Venkateswaran] SSN Coll Engn, Elect & Commun Engn, Chennai, Tamil Nadu, India.
C3 SSN College of Engineering; SSN College of Engineering
RP Kanmani, M (corresponding author), SSN Coll Engn, Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM madheswarik@ssn.edu.in; venkateswarann@ssn.edu.in
RI N, Venkateswaran/AGR-2157-2022
OI N, Venkateswaran/0000-0002-6789-4112
CR Ahmad A, 2016, IEEE SENS J, V16, P5123, DOI 10.1109/JSEN.2016.2556715
   [Anonymous], IEEE OTCBVS WS SER B
   [Anonymous], 2015, DEEP FAC REC BRIT MA
   Arivazhagan S, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL II, PROCEEDINGS, P301, DOI 10.1109/ICCIMA.2007.318
   Bebis G, 2006, IMAGE VISION COMPUT, V24, P727, DOI 10.1016/j.imavis.2006.01.017
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   BenAbdelkader C., 2005, Computer Vision and Pattern Recognition-Workshops, P52
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353
   Chen YL, 2016, IEEE SENS J, V16, P7731, DOI 10.1109/JSEN.2016.2602871
   Choudhary Alpa, 2018, Procedia Computer Science, V132, P1781, DOI 10.1016/j.procs.2018.05.153
   Dakin SC, 2009, J VISION, V9, DOI 10.1167/9.2.13
   Ekenel HK, 2005, IMAGE VISION COMPUT, V23, P469, DOI 10.1016/j.imavis.2004.09.002
   Eleyan Alaa, 2007, 2007 IEEE International Symposium on Signal Processing and Information Technology, P52, DOI 10.1109/ISSPIT.2007.4458158
   Er MJ, 2005, IEEE T NEURAL NETWOR, V16, P679, DOI 10.1109/TNN.2005.844909
   Gao Y, 2017, IEEE T IMAGE PROCESS, V26, P2545, DOI 10.1109/TIP.2017.2675341
   Ghasemzadeh A, 2018, IET BIOMETRICS, V7, P49, DOI 10.1049/iet-bmt.2017.0082
   Grotschel M, 1993, DIMACS TECHNICAL REP
   Guzman AM, 2013, IEEE J BIOMED HEALTH, V17, P214, DOI 10.1109/TITB.2012.2207729
   Hermosilla G, 2015, SENSORS-BASEL, V15, P17944, DOI 10.3390/s150817944
   Hizem W, 2009, IET SIGNAL PROCESS, V3, P282, DOI 10.1049/iet-spr.2008.0173
   Hollingsworth KP, 2012, IEEE T INF FOREN SEC, V7, P588, DOI 10.1109/TIFS.2011.2173932
   Imtiaz H, 2011, SIGNAL IMAGE PROCESS
   Kim TK, 2005, IEEE T PATTERN ANAL, V27, P318, DOI 10.1109/TPAMI.2005.58
   Klare BF, 2013, IEEE T PATTERN ANAL, V35, P1410, DOI 10.1109/TPAMI.2012.229
   Kong SG, 2007, INT J COMPUT VISION, V71, P215, DOI 10.1007/s11263-006-6655-0
   Kong WW, 2010, SCI CHINA INFORM SCI, V53, P2429, DOI 10.1007/s11432-010-4118-2
   Kumar A, 2006, IEEE T IMAGE PROCESS, V15, P2454, DOI 10.1109/TIP.2006.875214
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Li SZ, 2007, IEEE T PATTERN ANAL, V29, P627, DOI 10.1109/TPAMI.2007.1014
   Liu CJ, 2004, IEEE T PATTERN ANAL, V26, P572, DOI 10.1109/TPAMI.2004.1273927
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Ma JY, 2015, IEEE T SIGNAL PROCES, V63, P1115, DOI 10.1109/TSP.2014.2388434
   Ma JY, 2015, PATTERN RECOGN, V48, P772, DOI 10.1016/j.patcog.2014.09.005
   Madheswari K, 2016, QUANT INFRA THERMOGR, P1
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Meraoumia A., 2010, Proceedings International Conference on Machine and Web Intelligence (ICMWI 2010), P121, DOI 10.1109/ICMWI.2010.5648073
   Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227
   Nicolò F, 2012, IEEE T INF FOREN SEC, V7, P1717, DOI 10.1109/TIFS.2012.2213813
   Osuna E., 1997, TRAINING SUPPORT VEC
   Penev PS, 1996, NETWORK-COMP NEURAL, V7, P477, DOI 10.1088/0954-898X/7/3/002
   Petrovic V, 2007, INFORM FUSION, V8, P2018
   Raghavendra R, 2011, PATTERN RECOGN, V44, P401, DOI 10.1016/j.patcog.2010.08.006
   Rajoub BA, 2014, IEEE T INF FOREN SEC, V9, P1015, DOI 10.1109/TIFS.2014.2317309
   Schoelkopf B, 1997, ICANN97
   Seal A, 2016, AEU-INT J ELECTRON C, V70, P1041, DOI 10.1016/j.aeue.2016.04.016
   Shen LL, 2004, P IEEE INT C AUT FAC, P386
   Tan H, J COMPUT INF SYST, V9, P327
   TOET A, 1989, PATTERN RECOGN LETT, V9, P245, DOI 10.1016/0167-8655(89)90003-2
   Tripathi BK, 2017, APPL INTELL, V47, P382, DOI 10.1007/s10489-017-0902-7
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Turk M., 1991, COMP VIS PATT REC P
   Villegas-Quezada C, 2008, WORLD ACAD SCI ENG T, V44, P802
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang Y, 2016, IEEE SENS J, V16, P3735, DOI 10.1109/JSEN.2016.2533864
   Zhang X, 2009, PATTERN RECOGN, V42, P2876, DOI 10.1016/j.patcog.2009.04.017
   Zheng L, 2012, IEEE T PATTERN ANAL, V34
   Zhou M, 2006, INT C PATT RECOG, P404
NR 61
TC 25
Z9 25
U1 5
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17859
EP 17883
DI 10.1007/s11042-020-08628-9
EA FEB 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516511300001
DA 2024-07-18
ER

PT J
AU Zhao, JW
   Chen, NN
   Zhou, ZH
AF Zhao, Jianwei
   Chen, Ningning
   Zhou, Zhenghua
TI A temporal sparse collaborative appearance model for visual tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Sparse representation; Collaborative appearance model;
   Temporality; Sparse generative model
ID ROBUST OBJECT TRACKING
AB This paper proposes a temporal sparse collaborative appearance model in the particle filter frame for constructing a robust visual tracker, denoted by TSCAM tracker. The proposed collaborative appearance model includes two important branches: temporal Laplacian multi-task discriminative branch and similarity branch. The model in the first branch develops the classical Laplacian multi-task reverse sparse representation model by adding a temporality regularization term in the appearance model, which can get more global feature information and capture the relation of the adjacent frames. The application of sparse generative model (SGM) in the second branch can exploit the local appearance information of patches and occlusion to moderate the appearance variation and eliminate the partial occlusion. Therefore, with the alliance of above two branches, our proposed TSCAM tracker can track the object with occlusion and appearance variations effectively. Numerous experiments on various challenging videos of some databases illustrate that our proposed TSCAM tracker performs favorably against several state-of-the-art trackers.
C1 [Zhao, Jianwei; Chen, Ningning; Zhou, Zhenghua] China Jiliang Univ, Dept Informat Sci & Math, Hangzhou 310018, Zhejiang, Peoples R China.
   [Zhao, Jianwei] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Peoples R China.
C3 China Jiliang University; Nanjing University
RP Zhou, ZH (corresponding author), China Jiliang Univ, Dept Informat Sci & Math, Hangzhou 310018, Zhejiang, Peoples R China.
EM zzh@cjlu.edu.cn
FU Zhejiang Provincial Nature Science Foundation of China [LY18F020018,
   LSY19F020001]; National Natural Science Foundation of China [61571410]
FX This work was funded by the Zhejiang Provincial Nature Science
   Foundation of China (LY18F020018 and LSY19F020001) and the National
   Natural Science Foundation of China (61571410).
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2006, P 2006 IEEE COMP SOC
   [Anonymous], 2012, P 12 EUR C COMP VIS
   Avidan S, 2005, PROC CVPR IEEE, P494
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Black M. J., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P329, DOI 10.1007/BFb0015548
   Choi J, 2017, PROC CVPR IEEE, P4828, DOI 10.1109/CVPR.2017.513
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Grabner H., 2008, ECCV, p[234, 247]
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Ji H, 2012, IEEE COMP VIS PATT R, V2012, P1830
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li SY, 2017, AAAI CONF ARTIF INTE, P4140
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Oron S, 2012, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2012.6247895
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937
   Stalder Severin, 2009, INT C COMP VIS WORKS
   Sun C, 2018, PROC CVPR IEEE, P8962, DOI 10.1109/CVPR.2018.00934
   Tseng P, 2008, SIAM J OPTIMIZATION
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhang T, 2017, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2017.469
   Zhao JW, 2018, MULTIMED TOOLS APPL, V77, P30969, DOI 10.1007/s11042-018-6132-0
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
   Zhuang BH, 2014, IEEE T IMAGE PROCESS, V23, P1872, DOI 10.1109/TIP.2014.2308414
NR 38
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 14103
EP 14125
DI 10.1007/s11042-020-08630-1
EA FEB 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515999800001
DA 2024-07-18
ER

PT J
AU Borba, EZ
   Correa, AG
   Lopes, RD
   Zuffo, M
AF Borba, Eduardo
   Correa, Ana Grasielle
   Lopes, Roseli de Deus
   Zuffo, Marcelo
TI Usability in virtual reality: evaluating user experience with
   interactive archaeometry tools in digital simulations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Usability; Virtual reality; User experience; Human computer interaction
   and multimedia; Telepresence
ID ENVIRONMENTS
AB This is an experimental work presenting a study about usability experience of users in a cyber-archeology fully immersive 3D environment in Virtual Reality (VR). Particularly we research how users explore a realistic 3D environment with VR devices through archaeometry conventional techniques for archeology analysis and discoveries. Our main objective is to evaluate user's experience with interactive archaeometry tools of a population called archeologists, not a VR expert, but expert on the context of the real experience of practicing archeology in remote site; and compare the results with another population called VR experts, in this case, not experts in archeology, but in VR technology and multimedia applications. Several standard metrics will be used to collect data about their interactions with the cyber system (efficacy, efficiency, satisfaction, level of presence and cyber-sickness). Two hypotheses will be tested with this experiment: a) it is possible to represent the virtual world as realistically as the real one, in such way that a person unfamiliar with this kind of technology, in this case the archaeologist, can develop analytical process of discoveries in the VR model; and b) if this VR model is passive of exploration, virtually it is possible to create analytical tools that will help the archaeologist to manipulate archaeometry tools. Both sample population had participated in usability tests and the results are promising.
C1 [Borba, Eduardo; Correa, Ana Grasielle] Univ Sao Paulo CITI USP, Interdisciplinary Ctr Interact Technol, Ave Prof Lucio Martins Rodrigues 436-4, BR-05508020 Sao Paulo, Brazil.
   [Borba, Eduardo; Lopes, Roseli de Deus; Zuffo, Marcelo] Univ Sao Paulo, Polytech Sch, Dept Elect Engn & Digital Syst, Ave Prof Luciano Gualberto 158-3, BR-05508020 Sao Paulo, Brazil.
C3 Universidade de Sao Paulo
RP Borba, EZ (corresponding author), Univ Sao Paulo CITI USP, Interdisciplinary Ctr Interact Technol, Ave Prof Lucio Martins Rodrigues 436-4, BR-05508020 Sao Paulo, Brazil.; Borba, EZ (corresponding author), Univ Sao Paulo, Polytech Sch, Dept Elect Engn & Digital Syst, Ave Prof Luciano Gualberto 158-3, BR-05508020 Sao Paulo, Brazil.
EM ezb@lsi.usp.br; agrasi@lsi.usp.br; roseli@lsi.usp.br; mkzuffo@lsi.usp.br
RI Zuffo, Marcelo Knorich/T-4771-2019; de Deus Lopes, Roseli/CAF-2116-2022;
   Zuffo, Marcelo Knorich/A-7458-2011; de Deus Lopes, Roseli/F-3314-2010
OI Zuffo, Marcelo Knorich/0000-0002-2973-4476; de Deus Lopes,
   Roseli/0000-0001-8556-6473; Zuffo, Marcelo Knorich/0000-0002-2973-4476;
   de Deus Lopes, Roseli/0000-0001-8556-6473; Zilles Borba,
   Eduardo/0000-0001-5755-2509
CR [Anonymous], REMOVING GAMIFICATIO
   [Anonymous], REPLAY EXPERIENCES A
   [Anonymous], P 4 INT WORKSH PRES
   [Anonymous], COMPUTERS GRAPHICS
   [Anonymous], INT STANDARD
   [Anonymous], IEEE VIRTUAL REALITY
   [Anonymous], IEEE C
   [Anonymous], P INTERACT 93 CHI 93
   [Anonymous], HUMAN CTR COMPUTING
   [Anonymous], CIPA 2003 20 INT S
   [Anonymous], UNDESTANDING MEDIA E
   [Anonymous], HUMAN COMPUTER INTER
   [Anonymous], INT J DIGITAL CULTUR
   [Anonymous], INTERIN UTP
   [Anonymous], 9241210 INT ORG STAN
   [Anonymous], ACM SIGGRAPH 2016 AN
   Borba EZ, 2017, P IEEE VIRT REAL ANN, P463, DOI 10.1109/VR.2017.7892380
   Borba EZ, 2016, P IEEE VIRT REAL ANN, P326
   Brooke John., 1996, Usability evaluation in industry, V189, P4, DOI DOI 10.1201/9781498710411
   Burdea G. C., 2003, Virtual reality technology
   Cabral M, 2016, P IEEE VIRT REAL ANN, P327
   Forte M, 2011, VIRTUAL ARCHAEOL REV, V2, P7, DOI 10.4995/var.2011.4543
   Friedberg A., 2006, The Virtual Window
   Kennedy RS, 1997, PRESENCE-TELEOP VIRT, V6, P638, DOI 10.1162/pres.1997.6.6.638
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Khanna P., 2006, Proceedings of the ACM symposium on Virtual reality software and technology, VRST '06, P364, DOI DOI 10.1145/1180495.1180569
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Nielsen J., 1994, Heuristic evaluation. Usability inspection methods, V17, P25
   Nielsen J., 1993, USABILITY ENG, P358
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Song W, 2014, INT J DATA WAREHOUS, V10, P1, DOI 10.4018/ijdwm.2014010101
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   VIRZI RA, 1992, HUM FACTORS, V34, P457, DOI 10.1177/001872089203400407
   Youngblut C, 2003, P IEEE VIRT REAL ANN, P277, DOI 10.1109/VR.2003.1191158
NR 36
TC 4
Z9 4
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3425
EP 3447
DI 10.1007/s11042-019-07924-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700017
OA hybrid
DA 2024-07-18
ER

PT J
AU de Armas, C
   Tori, R
   Netto, AV
AF de Armas, Claudia
   Tori, Romero
   Netto, Antonio Valerio
TI Use of virtual reality simulators for training programs in the areas of
   security and defense: a systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Systematic review; Simulator; Security and defense; Virtual reality
AB Virtual Reality (VR) has been applied in training programs in the areas of security and defense, with simulators evolving from basic shooting systems into more immersive situations. In spite of all the efforts that have already been invested into research and development initiatives for such simulators, there are further challenges yet to be overcome. These include new devices of interaction and training modules that enable the recreation of security routines situations, as well as the creation of educational methods using simulation. The main contribution of this paper is mapping the state-of-the-art of VR simulators used on training of security agents and identifying which of them presents some kind of automated or semi-automated performance analysis, as well as research studies with simulators based on different techniques (immersive and non-immersive system). Upon completion of a systematic literature review, the authors detected certain gaps and challenges, such as the complete absence of information about educational methods used in simulation training and the lack of automatic users' assessments. The assessment systems detected were mainly for gunshot, while a posture assessment system has not been detected. So, it is possible to conclude that the creation of automated evaluation systems with the use of VR simulators remains as a challenge yet to be tackled.
C1 [de Armas, Claudia] Univ Sao Paulo, Escola Politecn, Sao Paulo, Brazil.
   [Tori, Romero] Univ Sao Paulo, Escola Politecn, Comp Engn Dept, Sao Paulo, Brazil.
   [Netto, Antonio Valerio] Natl Council Sci & Technol Dev, DT CNPq, Brasilia, DF, Brazil.
C3 Universidade de Sao Paulo; Universidade de Sao Paulo
RP de Armas, C (corresponding author), Univ Sao Paulo, Escola Politecn, Sao Paulo, Brazil.
EM claudiadearmas92@usp.br; tori@usp.br; antonio.valerio@pq.cnpq.br
RI Tori, Romero/F-7801-2012; de Armas, Claudia/AAS-6813-2020
OI Tori, Romero/0000-0001-9381-9565; Valerio Netto,
   Antonio/0000-0001-9215-8531; de Armas, Claudia/0000-0002-7830-1247
CR Afonso MB, REVISAO SISTEMATICA
   Anjos AM, 2012, J HLTH INFORM, V4, P28
   Barles J, OVERVIEW TRAINING SI
   Bogatinov D, 2017, MULTIMED TOOLS APPL, V76, P1403, DOI 10.1007/s11042-015-3118-z
   Cardenas-Delgado Sonia, 2018, Developments and Advances in Defense and Security. Proceedings of the Multidisciplinary International Conference of Research Applied to Defense and Security (MICRADS 2018). Smart Innovation, Systems and Technologies (SIST 94), P71, DOI 10.1007/978-3-319-78605-6_6
   Coie P, 2018, AUGMENTED VIRTUAL RE, P21
   Dinis B, 2016, SHO2016: INTERNATIONAL SYMPOSIUM ON OCCUPATIONAL SAFETY AND HYGIENE, P70
   Emond B, 2010, P 2010 SPRING MIL MO, P1
   Hall H, 1990, patent number, Patent No. 4948371
   Kingkangwan K, 2016, 2016 SECOND ASIAN CONFERENCE ON DEFENCE TECHNOLOGY (ACDT), P32, DOI 10.1109/ACDT.2016.7437639
   Kozlak M., 2014, Szybkobiezne Pojazdy Gsienicowe, V2, P5
   Kwon B., 2016, J NANOSCI, DOI [DOI 10.1155/2016/6571297, 10.1155/2016/6571297]
   Kwon B, 2017, IEEE ACCESS, V5, P12496, DOI 10.1109/ACCESS.2017.2723039
   Labr Miroslav, 2017, 2017 International Conference on Military Technologies (ICMT), P61, DOI 10.1109/MILTECHS.2017.7988731
   Lee S, 2015, SYMMETRY-BASEL, V7, P1043, DOI 10.3390/sym7021043
   Lele A, 2013, J AMB INTEL HUM COMP, V4, P17, DOI 10.1007/s12652-011-0052-4
   Manuel RUI, 1999, SIMULACAO COMO PARTE
   Martono KT, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, COMPUTER, AND ELECTRICAL ENGINEERING (ICITACEE), P377, DOI 10.1109/ICITACEE.2016.7892475
   Maxwell D., 2018, MODSIM World, P1
   Melo Leite Junior Antonio Jose, 2012, 2012 14th Symposium on Virtual and Augmented Reality (SVR), P254, DOI 10.1109/SVR.2012.12
   Netto AV, 2017, DESENVOLVIMENTO IMPL, P73
   Pinheiro ÉB, 2016, SYMP VIRTUAL AUGMENT, P234, DOI 10.1109/SVR.2016.47
   Pizzol LD, 2014, EMPREGO REALIDADE VI, P1
   Pollock B, 2012, PROC SPIE, V8289, DOI 10.1117/12.912193
   Rankis I, 2008, SHOOTING SIMULATOR S, V8, P1
   Shumaker R, 2015, LECT NOTES COMPUT SC, V9179
   Soares S, 2016, E&PDE, P27
   Soetedjo A, 2011, P 2011 INT C EL ENG, P1
   Soetedjo A, 2015, AM J APPL SCI, V12, P130, DOI [10.3844/ajassp.2015.130.141, DOI 10.3844/AJASSP.2015.130.141]
   Soetedjo A, 2013, INT CONF INSTRUM, P207, DOI 10.1109/ICA.2013.6734073
   Soetedjo A, 2014, INT J SMART SENS INT, V7, P423, DOI 10.21307/ijssis-2017-663
   Talhan A, 2017, IEEE ACCESS, V4, P1
   Taylor GS, 2013, HUM FACTORS, V55, P672, DOI 10.1177/0018720812466892
   Teng Y, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING SYSTEMS, P38, DOI 10.1109/ICSPS.2009.35
   VALERIO NETTO A., 2006, REV IEEE AM LATINA S, V4, P379
   Netto AV, 2015, SYMP VIRTUAL AUGMENT, P127, DOI 10.1109/SVR.2015.25
   Vieira JJ, 2014, REV LINE POLIT GEST, P4
   Villarejo CA, 2015, SIMULADOR TIRO CON C
   Wallace J, 2017, MODSIM WORLD, P42
   Yoshida EA, 2017, VIRTUAL REALITY FETA
   Zamboni AB, 2010, BRAZ C SOFTW THEOR P, P2005
NR 41
TC 17
Z9 18
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3495
EP 3515
DI 10.1007/s11042-019-08141-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700020
DA 2024-07-18
ER

PT J
AU Luo, RQ
   Zhong, X
   Chen, EX
AF Luo, Ruiqi
   Zhong, Xian
   Chen, Enxiao
TI Image classification with a MSF dropout
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neural network; Regularization; Genetic algorithm; Multi-scale; Dropout;
   Deep learning
ID NEURAL-NETWORKS
AB In recent years, as the main carrier of deep learning, Deep Neural Network has attracted the attention of experts in computer field. The application of deep neural network can effectively solve complex problems in life. However, in the process of training, the complex relationship caused by noisy data leads to an overfitting, which can impact the robustness of network model. Dropout, as one kind of random regularization techniques, carries a significant effect on restraining the overfitting of deep neural network. The traditional standard dropout can restrain the overfitting in a simple and quick way, but the accuracy is impacted because it cannot accurately locate the appropriate scale. This paper proposes a multi-scale fusion (MSF) dropout method on the basis of standard dropout. At first, several groups of network model with different combinations of dropout rates were trained; then the improved genetic algorithm was used to calculate the optimal scale of each network model; by reducing the corresponding network parameters through the optimal scale, the prediction sub-models were obtained; finally, these sub-models are fused into a final prediction model with certain weight. The present study applies MSF dropout to carry out the experiments in MNIST and CIFAR-10 standard datasets. The result of the study shows that the prediction accuracy is significantly improved compared with the other two kinds of dropout, which verifies the effectiveness of the multi-scale fusion method.
C1 [Luo, Ruiqi; Zhong, Xian; Chen, Enxiao] Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Zhong, Xian] Univ Florida, Gainesville, FL 32611 USA.
C3 Wuhan University of Technology; State University System of Florida;
   University of Florida
RP Zhong, X (corresponding author), Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.; Zhong, X (corresponding author), Univ Florida, Gainesville, FL 32611 USA.
EM luoruiqi@whut.edu.cn; zhongx@whut.edu.cn; chenenxiaoc3@163.com
OI Zhong, Xian/0000-0002-5242-0467
CR [Anonymous], INT C MACH LEARN
   [Anonymous], DEEP LEARN WORKSH
   [Anonymous], P 14 INT C ART INT S
   [Anonymous], ADV APPR BAYES INF W
   [Anonymous], SCI CHINA SC
   Baldi P, 2014, ARTIF INTELL, V210, P78, DOI 10.1016/j.artint.2014.02.004
   Baldi Pierre, 2013, Advances in Neural Information Processing Systems, P2814
   Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274
   Ghezaiel W, 2017, MULTIMED TOOLS APPL, V76, P20973, DOI 10.1007/s11042-016-4044-4
   Gresovnik I, 2012, CMC-COMPUT MATER CON, V30, P19
   Hasheminejad M, 2017, MULTIMED TOOLS APPL, V76, P21211, DOI 10.1007/s11042-016-4071-1
   Hinton G. E., 2012, ARXIV PREPRINT ARXIV
   Kingma DP, 2015, ADV NEUR IN, V28
   Liu CS, 2011, CMC-COMPUT MATER CON, V25, P239
   Nemirovski A, 2009, SIAM J OPTIMIZ, V19, P1574, DOI 10.1137/070704277
   NOWLAN SJ, 1992, NEURAL COMPUT, V4, P473, DOI 10.1162/neco.1992.4.4.473
   Ricks TM, 2014, CMC-COMPUT MATER CON, V40, P99
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Pham V, 2014, INT CONF FRONT HAND, P285, DOI 10.1109/ICFHR.2014.55
   Wager Stefan, 2013, Advances in Neural Information Processing Systems, P351, DOI DOI 10.48550/ARXIV.1307.1493
NR 20
TC 0
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4365
EP 4375
DI 10.1007/s11042-019-7172-9
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500008
DA 2024-07-18
ER

EF