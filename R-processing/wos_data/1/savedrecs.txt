FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Sun, MS
   Zhao, HW
   Liu, PP
   Zhou, JH
AF Sun, Mingsi
   Zhao, Hongwei
   Liu, Pingping
   Zhou, Jianhang
TI A multi-task mean teacher with two stage decoder for semi-supervised
   crack detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Crack detection; Multi-task mean teacher; Two stage decoder; Cross
   interaction
AB Crack detection is a simple but very practical computer vision task. Existing crack detection methods only supervise cracks on limited annotated data, which has limited their detection effectiveness. This paper aims to achieve crack detection by simultaneously learning cracks and crack-related information while using unlabeled data to train a multi-task mean teacher. Specifically, considering the characteristics of cracks, we construct the concept of multi-task from three perspectives of crack region, edge classification for both crack and noise, and crack count. All tasks will be explicitly supervised. Then we build a two stage decoder on top of using the powerful backbone as the encoder. Our first-stage decoder consists of a short connection and a first-stage prediction head. The latter enhances the representation of crack region in multiple ways and generates earlier and stronger feedback for network optimization. The second-stage decoder is mainly composed of a unified cross interaction module, which aims to facilitate the interaction between crack and edge category. Finally, we distribute our encoder and decoder to the student and teacher networks. On multiple crack benchmark datasets, our method outperforms other SOTA methods in all metrics. For example, AIU of 0.2243 and 0.2862 are achieved on the GAPS384 and CFD datasets, respectively. Furthermore, extensive ablation experiments confirm the rationality and effectiveness of our multi-task and decoder design.
C1 [Sun, Mingsi; Zhao, Hongwei; Liu, Pingping; Zhou, Jianhang] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.
   [Sun, Mingsi] Jilin Agr Sci & Technol Coll, Coll Elect & Informat Engn, Jilin 132101, Jilin, Peoples R China.
   [Sun, Mingsi; Zhao, Hongwei; Liu, Pingping; Zhou, Jianhang] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Jilin, Peoples R China.
   [Liu, Pingping] Jilin Univ, Coll Mech Sci & Engn, Changchun 130012, Jilin, Peoples R China.
C3 Jilin University; Jilin University
RP Liu, PP (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.; Liu, PP (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Jilin, Peoples R China.; Liu, PP (corresponding author), Jilin Univ, Coll Mech Sci & Engn, Changchun 130012, Jilin, Peoples R China.
EM sunms19@mails.jlu.edu.cn; zhaohw@jlu.edu.cn; liupp@jlu.edu.cn;
   jhzhou22@mails.jlu.edu.cn
FU Natural Science Foundation of Jilin Province
FX No Statement Available
CR Amhaz R, 2016, IEEE T INTELL TRANSP, V17, P2718, DOI 10.1109/TITS.2015.2477675
   Cha YJ, 2017, COMPUT-AIDED CIV INF, V32, P361, DOI 10.1111/mice.12263
   Chen ZH, 2020, PROC CVPR IEEE, P5610, DOI 10.1109/CVPR42600.2020.00565
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Eisenbach M, 2017, IEEE IJCNN, P2039, DOI 10.1109/IJCNN.2017.7966101
   Haciefendioglu K, 2022, Iran J Sci Technol Trans Civ Eng, P46
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huan LX, 2022, IEEE T PATTERN ANAL, V44, P6602, DOI 10.1109/TPAMI.2021.3084197
   Huang YX, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2177650
   Kaseko M. S., 1993, Transportation Research Part C (Emerging Technologies), V1C, P275, DOI 10.1016/0968-090X(93)90002-W
   Kaul V, 2012, IEEE T PATTERN ANAL, V34, P1952, DOI 10.1109/TPAMI.2011.267
   Lau SLH, 2020, IEEE ACCESS, V8, P114892, DOI 10.1109/ACCESS.2020.3003638
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu FF, 2008, KAM: 2008 INTERNATIONAL SYMPOSIUM ON KNOWLEDGE ACQUISITION AND MODELING, PROCEEDINGS, P610, DOI 10.1109/KAM.2008.29
   Liu Y, 2017, PROC CVPR IEEE, P5872, DOI 10.1109/CVPR.2017.622
   Pang J, 2022, SIGNAL IMAGE VIDEO P, V16, P911, DOI 10.1007/s11760-021-02034-w
   Pu MY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6859, DOI 10.1109/ICCV48922.2021.00680
   Shi Y, 2016, IEEE T INTELL TRANSP, V17, P3434, DOI 10.1109/TITS.2016.2552248
   Su Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5097, DOI 10.1109/ICCV48922.2021.00507
   Subirats P, 2006, IEEE IMAGE PROC, P3037, DOI 10.1109/ICIP.2006.313007
   Sun M, 2023, Mach Vis Appl
   Sun MS, 2022, IET IMAGE PROCESS, V16, P809, DOI 10.1049/ipr2.12388
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xu HY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9142867
   Yang F, 2020, IEEE T INTELL TRANSP, V21, P1525, DOI 10.1109/TITS.2019.2910595
   Zhang L, 2016, IEEE IMAGE PROC, P3708, DOI 10.1109/ICIP.2016.7533052
   Zhou D., 2020, P COMP VIS ECCV 2020, P680, DOI DOI 10.1007/978-3-030-58580-8_40
   Zhou Q, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3184351
   Zou Q, 2019, IEEE T IMAGE PROCESS, V28, P1498, DOI 10.1109/TIP.2018.2878966
NR 32
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 27
PY 2023
DI 10.1007/s11042-023-17846-w
EA DEC 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DE0M1
UT WOS:001130236200004
DA 2024-07-18
ER

PT J
AU Chaubey, M
   Singh, LK
   Gupta, M
AF Chaubey, Mrityunjay
   Singh, Lalit Kumar
   Gupta, Manjari
TI Estimation of missing video frames using Kalman filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Estimation; Kalman filter; Missing Frames; Prediction; Video Sequence
ID RATE UP-CONVERSION; MOTION; RECONSTRUCTION; ALGORITHM
AB In recent years, there has been a lot of interest in the estimation of missing frames in video sequences because of its usage in several critical applications such as medical imaging, manufacturing, security systems, etc. The present study employs the Kalman filtering approach to suggest a technique for estimating missing frames within a video sequence and forecasting forthcoming frames. The Kalman filter model proposed in this study employs a pixel-by-pixel approach to leverage information from both preceding and subsequent video frames for the purpose of predicting the missing frame. The experimental findings demonstrate the effectiveness of the proposed technique.
C1 [Chaubey, Mrityunjay; Gupta, Manjari] Banaras Hindu Univ, Inst Sci, Ctr Interdisciplinary Math Sci, Comp Sci, Varanasi 221005, India.
   [Singh, Lalit Kumar] IIT BHU, Dept Comp Sci & Engn, Varanasi, India.
C3 Banaras Hindu University (BHU); Indian Institute of Technology System
   (IIT System); Indian Institute of Technology BHU Varanasi (IIT BHU
   Varanasi)
RP Gupta, M (corresponding author), Banaras Hindu Univ, Inst Sci, Ctr Interdisciplinary Math Sci, Comp Sci, Varanasi 221005, India.
EM manjari@bhu.ac.in
RI Singh, Lalit/JHU-1601-2023
OI Singh, Lalit/0000-0002-3212-8485; Chaubey,
   Mrityunjay/0000-0001-5565-1933
CR Anwar MI, 2022, MULTIMED TOOLS APPL, V81, P35431, DOI 10.1007/s11042-022-12318-z
   Bao WB, 2021, IEEE T PATTERN ANAL, V43, P933, DOI 10.1109/TPAMI.2019.2941941
   Cui SH, 2014, SIGNAL IMAGE VIDEO P, V8, P1533, DOI 10.1007/s11760-012-0390-5
   Lin TL, 2018, IEEE SENS J, V18, P9792, DOI 10.1109/JSEN.2018.2865916
   Liu HB, 2012, IEEE T CIRC SYST VID, V22, P1188, DOI 10.1109/TCSVT.2012.2197081
   Liu XZ, 2020, INT J INTELL SYST, V35, P2087, DOI 10.1002/int.22285
   Liu X, 2011, INT J COMMUN SYST, V24, P1282, DOI 10.1002/dac.1193
   Matsushita Y, 2006, IEEE T PATTERN ANAL, V28, P1150, DOI 10.1109/TPAMI.2006.141
   Ogawa T, 2005, ITC CSCC INT TECHN C, P1543
   Paliwal A, 2020, IEEE T PATTERN ANAL, V42, P1557, DOI 10.1109/TPAMI.2020.2987316
   Rucci M, 2014, APPL OPTICS, V53, pC1, DOI 10.1364/AO.53.0000C1
   Scott JamesC., 2009, ART NOT BEING GOVERN, P1
   Shen W, 2021, IEEE T IMAGE PROCESS, V30, P277, DOI 10.1109/TIP.2020.3033617
   Szeto R, 2020, IEEE T PATTERN ANAL, V42, P1053, DOI 10.1109/TPAMI.2019.2951667
   Wang C, 2010, IEEE T CIRC SYST VID, V20, P886, DOI 10.1109/TCSVT.2010.2046057
   Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60
   Yan B, 2010, IEEE T IMAGE PROCESS, V19, P98, DOI 10.1109/TIP.2009.2032311
NR 17
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 20
PY 2023
DI 10.1007/s11042-023-17688-6
EA DEC 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4E4
UT WOS:001126688600009
DA 2024-07-18
ER

PT J
AU Dong, F
   Wang, YX
   Zhu, JC
   Li, YH
AF Dong, Feng
   Wang, Yuxuan
   Zhu, Jinchao
   Li, Yuehua
TI Adaptive interactive network for RGB-T salient object detection with
   double mapping transformer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Salient object detection; Multi-modal; Transformer; Attention mechanism;
   Feature fusion
AB The purpose of RGB-Thermal salient object detection (RGB-T SOD) is to segment the common salient objects or regions of the visible light image and the corresponding thermal-infrared image. Thermal-infrared information can provide more effective clues for finding prominent objects in complex environments. How to exploit the potential of multi-modal complementarity, make full use of the significant information provided by the dominant modality, and accurately locate the salient objects is still a problem worth exploring. In this paper, we first make a visual modal analysis of the complementarity between thermal-infrared images and visible images and then based on the analysis results, we propose a Transformer-based adaptive interactive network (AINet). In specific, we design a modal interaction module (MIM) with two parallel units to effectively use complementary modal information to fully complete modal information interaction. The spatial interaction unit (SIU) is responsible for directly completing modal interaction and integration in a weighted manner, and completing modal complementarity at the spatial level. The self-reinforcement unit (SRU) is responsible for enhancing the two single-modality features, strengthening the role of dominant modal features, and completing modal complementarity at the channel level. Besides, we propose a double mapping query-location module (QLM) for high-level features to complete global analysis and accurately confirm the location of salient objects. Finally, we adopt a re-calibration dual branch decoder (RCDB) to integrate the output features. We carry out sufficient experiments on RGB-T SOD datasets, and the results demonstrate that the proposed method performs outstanding against the other 13 state-of-the-art methods.
C1 [Dong, Feng] Tianjin Univ Finance & Econ, Sch Finance, Tianjin 300000, Peoples R China.
   [Wang, Yuxuan; Zhu, Jinchao] Nankai Univ, Coll Artificial Intelligence, Tianjin 300000, Peoples R China.
   [Zhu, Jinchao] Tsinghua Univ, Dept Automat, BNRist, Beijing 100089, Peoples R China.
   [Li, Yuehua] Zhejiang Lab, Hangzhou 310014, Peoples R China.
C3 Tianjin University of Finance & Economics; Nankai University; Tsinghua
   University; Zhejiang Laboratory
RP Zhu, JC (corresponding author), Nankai Univ, Coll Artificial Intelligence, Tianjin 300000, Peoples R China.; Zhu, JC (corresponding author), Tsinghua Univ, Dept Automat, BNRist, Beijing 100089, Peoples R China.
EM dongfengdeyx@163.com; jczhu@mail.nankai.edu.cn
OI wang, yu xuan/0000-0002-5743-2029
FU National Natural Science Foundation of China [2023M741952]; China
   Postdoctoral Science Foundation [U21B6001]; National Natural Science
   Foundation of China [2021YJSO2S02]; Tianjin Graduate Scientific Research
   Innovation Project
FX This work was supported by the China Postdoctoral Science Foundation
   under Grant 2023M741952, the National Natural Science Foundation of
   China under Grant U21B6001, and the Tianjin Graduate Scientific Research
   Innovation Project under Grant 2021YJSO2S02. A preliminary version of
   this work has appeared in CCDC 2022 [68].
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Chen G, 2022, IEEE T CIRC SYST VID, V32, P6308, DOI 10.1109/TCSVT.2022.3166914
   Chen SJ, 2020, IEEE SIGNAL PROC LET, V27, P1680, DOI 10.1109/LSP.2020.3025128
   Chen TC, 2009, PROC EUR SOLID-STATE, P1
   Chen ZY, 2021, IEEE T IMAGE PROCESS, V30, P7012, DOI 10.1109/TIP.2020.3028289
   Cheng MM, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778820
   Deng ZJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P684
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Gao W, 2022, IEEE T CIRC SYST VID, V32, P2091, DOI 10.1109/TCSVT.2021.3082939
   Gongyang Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P665, DOI 10.1007/978-3-030-58520-4_39
   Hongpeng Wang, 2019, 2019 IEEE International Conference on Real-time Computing and Robotics (RCAR). Proceedings, P901, DOI 10.1109/RCAR47638.2019.9043947
   Huang Q, 2020, PROCEEDING AAAI C AR
   Huo FS, 2022, IEEE T CIRC SYST VID, V32, P3111, DOI 10.1109/TCSVT.2021.3102268
   Jiang B, 2021, IEEE T MULTIMEDIA, V23, P1343, DOI 10.1109/TMM.2020.2997184
   Ju R, 2015, SIGNAL PROCESS-IMAGE, V38, P115, DOI 10.1016/j.image.2015.07.002
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu N, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4702, DOI 10.1109/ICCV48922.2021.00468
   Liu Y, 2022, IEEE T IMAGE PROCESS, V31, P6719, DOI 10.1109/TIP.2022.3215887
   Liu Y, 2022, IEEE T PATTERN ANAL, V44, P3688, DOI 10.1109/TPAMI.2021.3053577
   Liu Y, 2019, IEEE I CONF COMP VIS, P1232, DOI 10.1109/ICCV.2019.00132
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu ZY, 2022, IEEE T CIRC SYST VID, V32, P4486, DOI 10.1109/TCSVT.2021.3127149
   Mahadevan V, 2009, PROC CVPR IEEE, P1007, DOI 10.1109/CVPRW.2009.5206573
   Mallick R, 2022, IEEE IMAGE PROC, P3271, DOI 10.1109/ICIP46576.2022.9897347
   Nian Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13753, DOI 10.1109/CVPR42600.2020.01377
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Pang YW, 2023, IEEE T IMAGE PROCESS, V32, P892, DOI 10.1109/TIP.2023.3234702
   Park J., 2018, BRIT MACH VIS C, P147
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Piao YR, 2019, IEEE I CONF COMP VIS, P7253, DOI 10.1109/ICCV.2019.00735
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Quan Y, 2021, NEURAL COMPUT APPL, V33, P4299, DOI 10.1007/s00521-020-05255-1
   Rahman MA, 2016, P INT S VIS COMP ISV
   Shin U, 2023, Complementary random masking for RGB-thermal semantic segmentation
   Song SY, 2020, AAAI CONF ARTIF INTE, V34, P12023
   Tang J, 2020, IEEE T CIRC SYST VID, V30, P4421, DOI 10.1109/TCSVT.2019.2951621
   Tu ZZ, 2022, Arxiv, DOI arXiv:2007.03262
   Tu ZZ, 2021, IEEE T IMAGE PROCESS, V30, P5678, DOI 10.1109/TIP.2021.3087412
   Tu ZZ, 2020, IEEE T MULTIMEDIA, V22, P160, DOI 10.1109/TMM.2019.2924578
   Tu ZZ, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P141, DOI 10.1109/MIPR.2019.00032
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang G., 2018, CHINESE C IMAGE GRAP, P359
   Wang WH, 2023, Arxiv, DOI arXiv:2106.13797
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang YZ, 2022, MULTIMED TOOLS APPL, V81, P27551, DOI 10.1007/s11042-022-12839-7
   Wei Ji, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P52, DOI 10.1007/978-3-030-58523-5_4
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xiaoqi Zhao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P646, DOI 10.1007/978-3-030-58542-6_39
   Yang N, 2022, MULTIMED TOOLS APPL, V81, P35831, DOI 10.1007/s11042-021-11555-y
   Youwei Pang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P235, DOI 10.1007/978-3-030-58595-2_15
   Zhang J., 2023, IEEE Trans. Intell. Transp. Syst.
   Zhang Q, 2020, IEEE T IMAGE PROCESS, V29, P3321, DOI 10.1109/TIP.2019.2959253
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhou H, 2023, IEEE T IMAGE PROCESS, V32, P2593, DOI 10.1109/TIP.2023.3270801
   Zhou T, 2021, COMPUT VIS MEDIA, V7, P37, DOI 10.1007/s41095-020-0199-z
   Zhou ZH, 2022, MULTIMED TOOLS APPL, V81, P38921, DOI 10.1007/s11042-022-13083-9
   Zhu CB, 2019, IEEE INT CON MULTI, P199, DOI 10.1109/ICME.2019.00042
   Zhu CB, 2017, IEEE INT CONF COMP V, P3008, DOI 10.1109/ICCVW.2017.355
   Zhu Jinchao, 2022, 2022 34th Chinese Control and Decision Conference (CCDC), P1989, DOI 10.1109/CCDC55256.2022.10034159
   Zhu J, 2021, IEEE Signal Process Lett, V1-1
   Zhu JC, 2018, IEEE ANN INT CONF CY, P451, DOI 10.1109/CYBER.2018.8688130
NR 67
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 19
PY 2023
DI 10.1007/s11042-023-17747-y
EA DEC 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7T2
UT WOS:001126521200003
DA 2024-07-18
ER

PT J
AU Sharada, HN
   Anami, B
   Allagi, S
AF Sharada, H. N.
   Anami, Basavaraj
   Allagi, Shridhar
TI An optimized neural Network-based character recognition and relation
   finding for mathematical expression images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mathematical expression; Chimp optimization; Preprocessing;
   Segmentation; Recognition; Relation finding
AB Recognition of Mathematical Expressions (MEs) is a significant issue with numerous practical applications. Due to the range of writing styles and ME forms, ME recognition might be difficult. In many existing models, the exactness of the recognition system is degraded because of the additional noise present in the input, and the characters are wrongly predicted. Therefore, a novel Chimp-based Spiking Neural Recognition (CbSNR) framework was proposed to recognize the character from the handwritten/printed ME images. Initially, the input image datasets collected are noise-filtered in the preprocessing phase, and the features are extracted in the feature extraction process by the tracking function of the Chimp. Preprocessed images are then segmented into individual characters and are recognized in the recognition phase. Moreover, the Chimp position updating function is used to find the relation between the recognized characters. Furthermore, this test process is executed in the Python environment, and the robustness score has been valued in terms of F-score, recall, Accuracy, precision and error rate. The estimated outputs of the presented model were compared with existing approaches to validate the improvement score. The proposed model produced the highest character recognition rate compared to existing techniques.
C1 [Sharada, H. N.] SDM Coll Engn & Technol, Dept Comp Sci & Engn, Dharwad 580002, Karnataka, India.
   [Anami, Basavaraj; Allagi, Shridhar] KLE Inst Technol, Dept Comp Sci & Engn, Hubli 580030, Karnataka, India.
RP Sharada, HN (corresponding author), SDM Coll Engn & Technol, Dept Comp Sci & Engn, Dharwad 580002, Karnataka, India.
EM shnsdmcet@gmail.com; basu.anami@gmail.com; shridharallagi1@gmail.com
RI Allagi, Shridhar/IWU-7645-2023
CR Le AD, 2019, PATTERN RECOGN LETT, V128, P255, DOI 10.1016/j.patrec.2019.09.002
   Ayeb KK., 2020, Mediterr Conf Pattern Recog Artif Intell Springer Cham, DOI [10.1007/978-3-030-71804-6_15, DOI 10.1007/978-3-030-71804-6_15]
   Balaha HM, 2021, NEURAL COMPUT APPL, V33, P6325, DOI 10.1007/s00521-020-05397-2
   Phong BH, 2020, IEEE ACCESS, V8, P83663, DOI 10.1109/ACCESS.2020.2992067
   Nguyen CT, 2020, INT CONF FRONT HAND, P355, DOI [10.1109/icfhr2020.2020.00071, 10.1109/ICFHR2020.2020.00071]
   Ding HS, 2021, LECT NOTES COMPUT SC, V12822, P602, DOI 10.1007/978-3-030-86331-9_39
   Firdaus SA, 2020, ADV DECISION SCI IMA, P658, DOI [10.1007/978-3-030-24318-0_75, DOI 10.1007/978-3-030-24318-0_75]
   Gupta P, 2023, IEEE T AFFECT COMPUT, V14, P1431, DOI 10.1109/TAFFC.2021.3061967
   Haider MI, 2022, MULTIMED TOOLS APPL, V81, P23709, DOI 10.1007/s11042-022-12358-5
   Phan KM, 2018, INT J DOC ANAL RECOG, V21, P253, DOI 10.1007/s10032-018-0306-1
   Khishe M, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113338
   Li Z, 2020, INT CONF FRONT HAND, P175, DOI 10.1109/ICFHR2020.2020.00041
   Lincy RB, 2021, MULTIMED TOOLS APPL, V80, P5917, DOI 10.1007/s11042-020-09771-z
   Luo YL, 2020, IEEE ACCESS, V8, P46007, DOI 10.1109/ACCESS.2020.2978163
   Madisetty S, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12576
   Mahdavi Mahshad, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1533, DOI 10.1109/ICDAR.2019.00247
   Mahdavi Mahshad, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P647, DOI 10.1109/ICDAR.2019.00109
   Opitz M, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P186, DOI 10.1109/DAS.2014.29
   Pal A, 2022, MULTIMED TOOLS APPL, V81, P31405, DOI 10.1007/s11042-022-12889-x
   Roccetti M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00428-8
   Sakshi, 2021, ENG APPL ARTIF INTEL, V103, DOI 10.1016/j.engappai.2021.104292
   Sakshi V. K., 2021, 2021 9 INT C REL INF, P1, DOI [10.1109/ICRITO51393.2021.9596161, DOI 10.1109/ICRITO51393.2021.9596161]
   Sun JW, 2021, AEU-INT J ELECTRON C, V134, DOI 10.1016/j.aeue.2021.153698
   Truong TN, 2020, INT CONF FRONT HAND, P181, DOI 10.1109/ICFHR2020.2020.00042
   Torres-Muñoz D, 2020, MULTIMED TOOLS APPL, V79, P24873, DOI 10.1007/s11042-020-09168-y
   Khuong VTM, 2019, PROC INT CONF DOC, P26, DOI 10.1109/ICDARW.2019.10034
   Wang DH, 2020, INT CONF FRONT HAND, P211, DOI 10.1109/ICFHR2020.2020.00047
   Wang T, 2012, INT C PATT RECOG, P3304
   Wu FS, 2022, INT J SYST ASSUR ENG, V13, P72, DOI 10.1007/s13198-021-01262-0
   Yan ZY, 2021, INT C PATT RECOG, P4566, DOI 10.1109/ICPR48806.2021.9412913
   Yun XL, 2022, IEEE T MULTIMEDIA, V24, P2580, DOI 10.1109/TMM.2021.3087000
   Zhang JS, 2021, IEEE T MULTIMEDIA, V23, P2471, DOI 10.1109/TMM.2020.3011316
   Zhang J, 2019, IEEE T MULTIMEDIA, V21, P221, DOI 10.1109/TMM.2018.2844689
   Zhang JS, 2018, INT C PATT RECOG, P2245, DOI 10.1109/ICPR.2018.8546031
   Zhao WQ, 2021, LECT NOTES COMPUT SC, V12822, P570, DOI 10.1007/978-3-030-86331-9_37
NR 35
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 15
PY 2023
DI 10.1007/s11042-023-17725-4
EA DEC 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU3L6
UT WOS:001155145800002
DA 2024-07-18
ER

PT J
AU R, K
   Rs, VK
AF R., Kishor
   R.s., Vinod Kumar
TI CoC-ResNet - classification of colorectal cancer on histopathologic
   images using residual networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Colon cancer; Histopathology; Deep learning; Residual networks; Image
   classification
AB Colon Cancer (CoC) appears to be the third leading cause of cancer death in men and second among women. Therefore, the infection and mortality rates can be reduced with early identification of this cancer. For accurate colon cancer screening, this research proposes a novel deep-learning strategy using Residual Networks (ResNet). In this paper, the performance of four architectures, CoC-ResNet152, CoC-ResNet101, CoC-ResNet50, and CoC-ResNet50V2, is evaluated. Different deep learning architectures are compared in detail using the two-class public LC25000 histopathologic datasets, namely benign and Adenocarcinoma. From the experimental data, it is determined that the CoC-ResNet50V2 model is superior to the other three proposed models. After training on histopathological images, the CoC-ResNet50V2 model achieved 99.55% accuracy, 99.41% specificity, 99.38% precision, 99.69% recall, 0.58% False Positive Rate (FPvR), 0.30% False Negative Rate (FNvR), 99.54% F1 score, 0.990 Matthew's Correlation Coefficient (MCC), and 0.992 Cohen's Kappa Coefficient (KP).
C1 [R., Kishor; R.s., Vinod Kumar] Noorul Islam Ctr Higher Educ, Dept Elect & Commun Engn, Kanyakumari 629180, Tamil Nadu, India.
RP R, K (corresponding author), Noorul Islam Ctr Higher Educ, Dept Elect & Commun Engn, Kanyakumari 629180, Tamil Nadu, India.
EM ece.kishor@gmail.com; rsvinodkumar@niuniv.com
RI Kumar, R.S. Vinod/AAT-3266-2020
OI Kumar, R.S. Vinod/0000-0001-9727-8110; Ravikumar,
   Kishor/0000-0002-7049-1752
CR Albashish D, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.1031
   Ali M, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11081485
   Alqudah AM, 2022, MULTIMED TOOLS APPL, V81, P10839, DOI 10.1007/s11042-022-11946-9
   Anwar S, 2022, IEEE T PATTERN ANAL, V44, P1192, DOI 10.1109/TPAMI.2020.3021088
   Ari A, 2018, TURK J ELECTR ENG CO, V26, P2275, DOI 10.3906/elk-1801-8
   Ben Hamida A, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104730
   Bukhari SUK, 2020, MedRxiv, P2020
   Bushara AR, 2023, BIOMED SIGNAL PROCES, V85, DOI 10.1016/j.bspc.2023.104930
   Bushara AR, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-14893-1
   Bushara AR, 2023, J Artif Intell Technol, DOI [10.37965/jait.2023.0218, DOI 10.37965/JAIT.2023.0218]
   Bushara AR, 2022, Electron Lett Comput Vis Image Anal, V21, P130, DOI [10.5565/rev/elcvia.1490, DOI 10.5565/REV/ELCVIA.1490]
   Bychkov D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21758-3
   Engstrom PF., 2007, JNCCN J Natl Compr Cancer Netw, V5, P884, DOI [10.6004/jnccn.2007.0079, DOI 10.6004/JNCCN.2007.0079]
   Forghani R, 2019, COMPUT STRUCT BIOTEC, V17, P995, DOI 10.1016/j.csbj.2019.07.001
   Gupta P, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11081398
   Gupta S, 2022, BIOMED RES INT, V2022, DOI 10.1155/2022/1467070
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Health USP, 1999, Acad Radiol, V6, P1
   Huang KM, 2022, BIOINFORMATICS, V38, P5108, DOI 10.1093/bioinformatics/btac641
   Kavitha MS, 2022, CANCERS, V14, DOI 10.3390/cancers14153707
   Kim H, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-01905-z
   Kim SH, 2021, MULTIMED TOOLS APPL, V80, P35941, DOI 10.1007/s11042-021-10551-6
   Kumar A, 2021, IEEE INT C CONTROL A, P16
   Kwak MS, 2021, FRONT ONCOL, V10, DOI 10.3389/fonc.2020.619803
   Lin JT, 2022, IEEE T MED IMAGING, V41, P2252, DOI 10.1109/TMI.2022.3161787
   Liu FY, 2023, BIOMED SIGNAL PROCES, V80, DOI 10.1016/j.bspc.2022.104400
   Mangal S, 2020, Arxiv, DOI arXiv:2009.03878
   Mehmood S, 2022, IEEE ACCESS, V10, P25657, DOI 10.1109/ACCESS.2022.3150924
   Nanni L, 2017, PATTERN RECOGN, V71, P158, DOI 10.1016/j.patcog.2017.05.025
   Pogorelov K, 2017, MULTIMED TOOLS APPL, V76, P22493, DOI 10.1007/s11042-017-4989-y
   Puttagunta M, 2021, MULTIMED TOOLS APPL, V80, P24365, DOI 10.1007/s11042-021-10707-4
   Santosh KC, 2020, MULTIMED TOOLS APPL, V79, P34697, DOI 10.1007/s11042-020-10093-3
   Shaban M, 2020, IEEE T MED IMAGING, V39, P2395, DOI 10.1109/TMI.2020.2971006
   Sharma Parul, 2020, Information Processing in Agriculture, V7, P566, DOI 10.1016/j.inpa.2019.11.001
   Wang KS, 2021, BMC MED, V19, DOI 10.1186/s12916-021-01942-5
   Williamson AJ, 2022, NEOPLASIA, V27, DOI 10.1016/j.neo.2022.100787
   Wilm F, 2022, J MED IMAGING, V9, DOI 10.1117/1.JMI.9.2.027501
   Yari Y, 2020, IEEE ACCESS, V8, P162432, DOI 10.1109/ACCESS.2020.3021557
   Younas F, 2023, APPL INTELL, V53, P2410, DOI 10.1007/s10489-022-03689-9
   Zhang JFK, 2022, CELLS-BASEL, V11, DOI 10.3390/cells11040716
   Zhou PY, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-18879-1
NR 42
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 14
PY 2023
DI 10.1007/s11042-023-17740-5
EA DEC 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU3L5
UT WOS:001155145700002
DA 2024-07-18
ER

PT J
AU Kotkar, VA
   Golande, AL
   Deshpande, KV
   Shahade, M
   Bhutnal, VH
AF Kotkar, Vijay A.
   Golande, Avinash L.
   Deshpande, Kirti V.
   Shahade, Makarand
   Bhutnal, Vinodkumar H.
TI An IoT enabled healthcare framework for arrhythmia detection based on
   Qos aware trust aided osprey routing protocol and ensemble learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Arrhythmia classification; Cascaded Savitzky-Golay; Binarized
   convolutional neural network; Group decision-making; Ensemble learning;
   And trust routing
ID ALGORITHM
AB An electrocardiogram (ECG) is frequently used to assess heart state, which can guide more research into cardiac problems and identifying heart illnesses. The method is easy, quick, and non-intrusive. However, manually analyzing the ECG data takes time, making it difficult to identify and classify arrhythmia manually. The service of healthcare industries has become more effective and of higher quality due to integrating IoT elements into medical equipment. For arrhythmia detection, the proposed research undergoes two stage novel approach, which includes the novel routing model and the detection model. For an efficient data transfer, the routing strategy is crucial. Therefore, this research proposes a QoS based trust aware osprey geographic routing (QOS based TAOGR) by evaluating the trust score of the path (TSP). The multi-objective functions utilized here are total energy cost and delay for an optimal route selection from the source to the destination. The second stage is arrhythmia detection, which undergoes signal pre-processing for efficient detection. The triple phase cascaded Savitzky Golay smoothing (TPCSGSGS) filter is introduced by merging three Savitzky Golay smoothing (SGS) filters to eliminate the noise in the acquired ECG data from the IoT-based smart wearable devices. Afterwards, a binarized convolutional neural network and group decision-making-based ensemble learning (BCNN-GDM-EL) are proposed for detection. In the simulation scenario, the performance is evaluated under two sources: routing and detection performance, such as energy consumption, packet delivery ratio, delay, accuracy, specificity and sensitivity. Also, the tenfold cross validation analysis is performed in terms of accuracy, specificity and sensitivity and compared with existing models.
C1 [Kotkar, Vijay A.] PCETs Pimpri Chinchwad Coll Engn & Res, Dept Comp Engn, Pune, Maharashtra, India.
   [Golande, Avinash L.; Deshpande, Kirti V.; Bhutnal, Vinodkumar H.] JSPMs Rajarshi Shahu Coll Engn, Dept Comp Engn, Pune, Maharashtra, India.
   [Shahade, Makarand] SVKMs Inst Technol, Dept Comp Engn, Dhule, Maharashtra, India.
RP Golande, AL (corresponding author), JSPMs Rajarshi Shahu Coll Engn, Dept Comp Engn, Pune, Maharashtra, India.
EM avinash.golande@gmail.com
RI Shahade, Makarand/JTT-0083-2023; Deshpande, kirti/AAB-8140-2022
OI Deshpande, kirti/0000-0003-2418-2788
CR Acharya UR, 2017, COMPUT BIOL MED, V89, P389, DOI 10.1016/j.compbiomed.2017.08.022
   Ahmed G, 2017, WIRELESS PERS COMMUN, V96, P4737, DOI 10.1007/s11277-017-4415-9
   Altan G., 2016, Int J Intell Syst Appl Eng, V6, P222, DOI [DOI 10.18201/IJISAE.270367, 10.18201/ijisae.2016SpecialIssue-146978, DOI 10.18201/IJISAE.2016SPECIALISSUE-146978]
   Amini V, 2023, J SUPERCOMPUT, V79, P8178, DOI 10.1007/s11227-022-04987-2
   Azariadi D, 2016, 2016 5TH INTERNATIONAL CONFERENCE ON MODERN CIRCUITS AND SYSTEMS TECHNOLOGIES (MOCAST)
   Chen C, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101819
   Firouzi Farshad., 2020, Intelligent internet of things, P3, DOI DOI 10.1007/978-3-030-30367-9_1
   Hammad M, 2022, COMPUT ELECTR ENG, V100, DOI 10.1016/j.compeleceng.2022.108011
   Hammad M, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3033072
   He JY, 2020, WORLD WIDE WEB, V23, P2835, DOI 10.1007/s11280-019-00776-9
   Hernandez AA, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104041
   Isin A, 2017, PROCEDIA COMPUT SCI, V120, P268, DOI 10.1016/j.procs.2017.11.238
   Izci E, 2019, 2019 MEDICAL TECHNOLOGIES CONGRESS (TIPTEKNO), P121, DOI 10.1109/tiptekno.2019.8895011
   Kulach A, 2020, OPEN MED-WARSAW, V15, P697, DOI 10.1515/med-2020-0203
   Kumar A, 2022, BIOMED SIGNAL PROCES, V76, DOI 10.1016/j.bspc.2022.103638
   Li Z, 2020, J ELECTROCARDIOL, V58, P105, DOI 10.1016/j.jelectrocard.2019.11.046
   Liu F, 2021, INT J PAVEMENT ENG, V22, P331, DOI 10.1080/10298436.2019.1608992
   Meng Y., 2021, Sci Program, V2021, P1
   Mora H, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102302
   Parvaneh S, 2019, J ELECTROCARDIOL, V57, pS70, DOI 10.1016/j.jelectrocard.2019.08.004
   Raheja N, 2023, BIOMED SIGNAL PROCES, V80, DOI 10.1016/j.bspc.2022.104368
   Raj S, 2017, IEEE T INSTRUM MEAS, V66, P470, DOI 10.1109/TIM.2016.2642758
   Rajagopal R, 2018, ADV CLIN EXP MED, V27, P727, DOI 10.17219/acem/68982
   Rezaee AA, 2014, J NETW COMPUT APPL, V37, P216, DOI 10.1016/j.jnca.2013.02.014
   Sakib S, 2020, INT WIREL COMMUN, P595, DOI 10.1109/IWCMC48107.2020.9148134
   Shaker AM, 2020, IEEE ACCESS, V8, P35592, DOI 10.1109/ACCESS.2020.2974712
   Shi HT, 2020, KNOWL-BASED SYST, V188, DOI 10.1016/j.knosys.2019.105036
   Varghese A, 2022, J INTELL SYST, V31, P407, DOI 10.1515/jisys-2022-0015
   Yildirim O, 2019, COMPUT METH PROG BIO, V176, P121, DOI 10.1016/j.cmpb.2019.05.004
   Zhai XL, 2018, IEEE ACCESS, V6, P27465, DOI 10.1109/ACCESS.2018.2833841
   Zhang P, 2022, IEEE INTERNET THINGS, V9, P14563, DOI 10.1109/JIOT.2021.3067876
   Zhou SR, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105778
NR 32
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 7
PY 2023
DI 10.1007/s11042-023-17773-w
EA DEC 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AC0T4
UT WOS:001116150800004
DA 2024-07-18
ER

PT J
AU Liu, Y
   Li, DA
   Zhao, JM
   Liang, YC
AF Liu, Yi
   Li, Dengao
   Zhao, Jumin
   Liang, Yuchen
TI Enhancing heart failure diagnosis through multi-modal data integration
   and deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Heart failure; Deep learning; Classification; Multimodal fusion; Medical
ID FUSION; ECG
AB In the realm of medical data processing, the surge in electronic health records has opened avenues for addressing clinical challenges. Although machine and deep learning methods have gained traction, they often overlook the potential of multimodal data. Thus, multimodal fusion emerges as a prominent field in artificial intelligence research, capitalizing on the synergy between diverse data types to enhance classification models. This study introduces an innovative technique tailored for heart failure classification, harnessing the power of multimodal features. The proposed approach utilizes three distinct feature types: electrocardiogram, chest X-ray, and structured text data. These are integrated to form a comprehensive multimodal fusion model. This study demonstrates the superior performance of the proposed model compared to single-modality counterparts, even in the presence of noise, through a rigorous experiment involving 440 cases. It pioneers the integration of multimodal information using deep learning techniques for heart failure assessment, offering novel insights and a practical approach for accurate detection and treatment.
C1 [Liu, Yi; Zhao, Jumin] Taiyuan Univ Technol, Coll Informat & Comp, Taiyuan 030024, Peoples R China.
   [Liu, Yi; Li, Dengao; Zhao, Jumin] Key Lab Big Data Fus Anal & Applicat Shanxi Prov, Taiyuan 030024, Peoples R China.
   [Liu, Yi; Li, Dengao; Zhao, Jumin] Intelligent Percept Engn Technol Ctr Shanxi, Taiyuan 030024, Peoples R China.
   [Liu, Yi; Li, Dengao; Zhao, Jumin] Shanxi Prov Engn Technol Res Ctr Spatial Informat, Taiyuan 030024, Peoples R China.
   [Li, Dengao] Taiyuan Univ Technol, Coll Data Sci, Taiyuan 030024, Peoples R China.
   [Liang, Yuchen] Shanxi Cardiovasc Hosp, Taiyuan 030027, Peoples R China.
C3 Taiyuan University of Technology; Taiyuan University of Technology
RP Li, DA (corresponding author), Key Lab Big Data Fus Anal & Applicat Shanxi Prov, Taiyuan 030024, Peoples R China.; Li, DA (corresponding author), Intelligent Percept Engn Technol Ctr Shanxi, Taiyuan 030024, Peoples R China.; Li, DA (corresponding author), Shanxi Prov Engn Technol Res Ctr Spatial Informat, Taiyuan 030024, Peoples R China.; Li, DA (corresponding author), Taiyuan Univ Technol, Coll Data Sci, Taiyuan 030024, Peoples R China.
EM lidengao@tyut.edu.cn
FU National Natural Science Foundation of China
FX No Statement Available
CR Acharya UR, 2019, APPL INTELL, V49, P16, DOI 10.1007/s10489-018-1179-1
   Vásquez-Correa JC, 2019, IEEE J BIOMED HEALTH, V23, P1618, DOI 10.1109/JBHI.2018.2866873
   Chen JM, 2022, ESC HEART FAIL, V9, P3167, DOI 10.1002/ehf2.14042
   Eltrass AS, 2021, BIOMED SIGNAL PROCES, V65, DOI 10.1016/j.bspc.2020.102326
   Hammad M, 2019, COMPUT SECUR, V81, P107, DOI 10.1016/j.cose.2018.11.003
   Herman R, 2022, ESC HEART FAIL, V9, P3575, DOI 10.1002/ehf2.14011
   Jahmunah V, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104457
   Kingma D. P., 2014, arXiv
   Kline A, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00712-8
   Kusuma S, 2022, BIOCYBERN BIOMED ENG, V42, P247, DOI 10.1016/j.bbe.2022.02.003
   Kwon JM, 2021, EUR HEART J-DIGIT HL, V2, P106, DOI 10.1093/ehjdh/ztaa015
   Liu XW, 2021, KNOWL-BASED SYST, V227, DOI 10.1016/j.knosys.2021.107187
   Malek YN, 2021, BIG DATA MIN ANAL, V4, P56, DOI 10.26599/BDMA.2020.9020027
   Matsumoto T, 2020, INT HEART J, V61, P781, DOI 10.1536/ihj.19-714
   Mohsen F, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-22514-4
   Muhammad G, 2021, INFORM FUSION, V76, P355, DOI 10.1016/j.inffus.2021.06.007
   Pan D, 2021, CLIN RES CARDIOL, V110, P1743, DOI 10.1007/s00392-021-01836-9
   Savarese G, 2022, CARDIOVASC RES, V118, P3272, DOI 10.1093/cvr/cvac013
   Sharma V, 2022, J CARD FAIL, V28, P710, DOI 10.1016/j.cardfail.2021.12.004
   Soenksen LR, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00689-4
   Sokolski M, 2022, J CLIN MED, V11, DOI 10.3390/jcm11010241
   Soto JT, 2022, EUR HEART J-DIGIT HL, V3, P380, DOI 10.1093/ehjdh/ztac033
   Sterling MR, 2022, CIRC-HEART FAIL, V15, DOI 10.1161/CIRCHEARTFAILURE.121.008409
   Tiulpin A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-56527-3
   Tse G, 2020, ESC HEART FAIL, V7, P3716, DOI 10.1002/ehf2.12929
   Tu Y, 2022, COMPUT BIOL MED, V148, DOI 10.1016/j.compbiomed.2022.105901
   Wang CJ, 2021, BIG DATA MIN ANAL, V4, P223, DOI 10.26599/BDMA.2021.9020006
   Wu JTY, 2022, J DIGIT IMAGING, V35, P1514, DOI 10.1007/s10278-022-00674-z
   Xu YA, 2021, J NEUROVIROL, V27, P1, DOI 10.1007/s13365-020-00930-4
   Zhai GL, 2020, BIG DATA MIN ANAL, V3, P311, DOI 10.26599/BDMA.2020.9020024
   Zhang DD, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01297-6
NR 31
TC 0
Z9 0
U1 18
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 7
PY 2023
DI 10.1007/s11042-023-17716-5
EA DEC 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9MN6
UT WOS:001115250300005
DA 2024-07-18
ER

PT J
AU Ghasemi, S
   Akbarpour, S
   Farzan, A
   Jamali, MAJ
AF Ghasemi, Shabnam
   Akbarpour, Shahin
   Farzan, Ali
   Jamali, Mohammad Ali Jabraeil
TI Automatic pulmonary nodule detection on computed tomography images using
   novel deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Computer-aided Detection; Computed Tomography Imaging; Deep Learning;
   Convolutional Neural Network; Region Proposals Network; Pulmonary
   Nodules Detected
ID FALSE-POSITIVE REDUCTION; ARCHITECTURE; ALGORITHMS; CNNS
AB Lung cancer poses a significant threat, contributing significantly to cancer-related mortality. Computer-aided detection plays a pivotal role, particularly in the automated identification of pulmonary nodules, assisting radiologists in diagnosis. Despite the remarkable efficacy of deep convolutional neural networks in lesion identification, the detection of small nodules remains an enduring challenge. A conventional automated detection framework encompasses two critical stages: candidate detection and false positive reduction. This study introduces a novel approach named ReRointNet, focusing on meticulous lung nodule localization and detection through strategically placed sample points. To enhance nodule detection, we propose integrating PointNet anchors with RPN anchors. PointNet, operating on local key points, facilitates this integration. The synergy achieved by merging these anchors within our RePointNet framework enhances nodule detection rates and substantially improves localization accuracy. Post-detection, identified nodules undergo classification using the 3D Convolutional Neural Networks (CNN) method. Our contribution presents a novel paradigm for nodule detection in lung Computed Tomography (CT) images, with reduced computational costs and improved memory efficiency. The combined utilization of RePointNet and 3DCNN demonstrates proficiency in identifying nodules of various sizes, including small nodules. Our research underscores the superiority of lung nodule identification through the utilization of RePointNet based on point information, surpassing conventional networks. Rigorous evaluations of the LUNA16 dataset reveal our method's superior performance compared to state-of-the-art systems, achieving a notable sensitivity of 91.6 percent at a speed of 0.9 frames per second. These findings underscore the potential of our proposed approach in advancing precise lung nodule diagnosis, offering invaluable support to healthcare practitioners and radiologists engaged in diagnosing lung cancer patients.
C1 [Ghasemi, Shabnam; Akbarpour, Shahin; Farzan, Ali; Jamali, Mohammad Ali Jabraeil] Islamic Azad Univ, Dept Comp Engn, Shabestar Branch, Shabestar, Iran.
C3 Islamic Azad University
RP Akbarpour, S (corresponding author), Islamic Azad Univ, Dept Comp Engn, Shabestar Branch, Shabestar, Iran.
EM shabnam.ghasemi@iaushab.ac.ir; akbarpour@iaushab.ac.ir;
   Alifarzanam@gmail.com; m_jamali@itrc.ac.ir
RI Akbarpour, Shahin/ACO-6390-2022; Jabraeil Jamali, Mohammad
   Ali/I-8032-2019
OI Jabraeil Jamali, Mohammad Ali/0000-0001-7687-5469; ghasemi,
   shabnam/0000-0002-8189-8160
CR [Anonymous], 2017, 2017 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB), DOI [10.1109/CIBCB.2017. 8058549, DOI 10.1109/CIBCB.2017.8058549]
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Cao HC, 2019, IEEE ACCESS, V7, P67380, DOI 10.1109/ACCESS.2019.2906116
   da Nóbrega RVM, 2020, NEURAL COMPUT APPL, V32, P11065, DOI 10.1007/s00521-018-3895-1
   Ding XT, 2020, APPL INTELL, V50, P3007, DOI 10.1007/s10489-020-01665-9
   Dou Q, 2017, IEEE T BIO-MED ENG, V64, P1558, DOI 10.1109/TBME.2016.2613502
   Tran GS, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/5156416
   Gu Y, 2018, COMPUT BIOL MED, V103, P220, DOI 10.1016/j.compbiomed.2018.10.011
   Huang J, 2017, P IEEE C COMPUTER VI, DOI [10.48550/arXiv.1611.10012, DOI 10.48550/ARXIV.1611.10012]
   Jaszcz A, 2022, SCI PROGRAMMING-NETH, V2022, DOI 10.1155/2022/4494139
   Jetley S, 2018, Arxiv, DOI [arXiv:1804.02391, DOI 10.48550/ARXIV.1804.02391, 10.48550/arXiv.1804.02391]
   Jia Ding, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P559, DOI 10.1007/978-3-319-66179-7_64
   Jin HS, 2018, MED PHYS, V45, P2097, DOI 10.1002/mp.12846
   Jung H, 2018, BMC MED IMAGING, V18, DOI 10.1186/s12880-018-0286-0
   Khan MA, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11122208
   Khosravan N, 2018, INT C MEDICAL IMAGE, DOI [10.48550/arXiv.1805.02279, DOI 10.48550/ARXIV.1805.02279]
   Li W, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6215085
   Li YF, 2019, IEEE ACCESS, V7, P37822, DOI 10.1109/ACCESS.2019.2905574
   Li Y, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/6633242
   Liao FZ, 2019, IEEE T NEUR NET LEAR, V30, P3484, DOI 10.1109/TNNLS.2019.2892409
   Liu XL, 2018, PATTERN RECOGN, V77, P262, DOI 10.1016/j.patcog.2017.12.022
   Masood A, 2020, IEEE J TRANSL ENG HE, V8, DOI 10.1109/JTEHM.2019.2955458
   Monkam P, 2019, IEEE ACCESS, V7, P5564, DOI 10.1109/ACCESS.2018.2889350
   Naqi SM, 2020, NEURAL COMPUT APPL, V32, P4629, DOI 10.1007/s00521-018-3773-x
   Oktay O, 2018, Arxiv, DOI arXiv:1804.03999
   Polap D, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P2298, DOI 10.1109/SSCI.2018.8628869
   Ren SQ, 2016, Arxiv, DOI [arXiv:1506.01497, DOI 10.1109/TPAMI.2016.2577031]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sangamithraa PB, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2201, DOI 10.1109/WiSPNET.2016.7566533
   Setio AAA, 2017, MED IMAGE ANAL, V42, P1, DOI 10.1016/j.media.2017.06.015
   Shi J., 2018, Lung nodule detection using convolutional neural networks. Electrical Engineering and Computer Sciences
   Sun WQ, 2017, COMPUT BIOL MED, V89, P530, DOI 10.1016/j.compbiomed.2017.04.006
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wong A, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P95, DOI 10.1109/CRV.2018.00023
   Wu J., 2019, J Med Artif Intell, V2, P8, DOI [10.21037/jmai.2019.04.01, DOI 10.21037/JMAI.2019.04.01]
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Yang Z, 2019, IEEE I CONF COMP VIS, P9656, DOI 10.1109/ICCV.2019.00975
   Zhang N, 2020, Arxiv, DOI [arXiv:2001.11071, 10.48550/arXiv.2001.11071, DOI 10.48550/ARXIV.2001.11071]
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zhu WT, 2018, IEEE WINT CONF APPL, P673, DOI 10.1109/WACV.2018.00079
NR 40
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 1
PY 2023
DI 10.1007/s11042-023-17502-3
EA DEC 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z5LL9
UT WOS:001112488100007
DA 2024-07-18
ER

PT J
AU Zayed, SM
   Attiya, GM
   El-Sayed, A
   Hemdan, EED
AF Zayed, Samar M.
   Attiya, Gamal M.
   El-Sayed, Ayman
   Hemdan, Ezz El-Din
TI A review study on digital twins with artificial intelligence and
   internet of things: concepts, opportunities, challenges, tools and
   future scope
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Digital Twins; Tools; Artificial Intelligence; Data Analytics; And
   Internet of Things
ID AVERAGING FUSION STRATEGY; CYBER-PHYSICAL SYSTEMS; OPTIMIZATION;
   SERVICE; DESIGN; IMPLEMENTATION; MODEL
AB Recently, Digital Twin (DT) has a growth revolution by increasing Artificial Intelligence (AI) techniques and relative technologies as the Internet of Things (IoT). They may be considered as the panacea for DT technology for various applications in the real world such as manufacturing, healthcare, and smart cities. The integration of DT and AI is a new avenue for open research in the upcoming days. However, for exploring the issues of developing Digital Twins, there are interesting in identifying challenges with standardization ensures future developments in this innovative theme. This paper first presents the Digital Twins concept, challenges, and applications. Afterward, it discusses the incorporation of AI and DT for developing various IoT-based applications with exploring the challenges and opportunities in this innovative arena. Then, developing tools are presented for exploring the digital twins' system implementation. Further, a review of recent DT-based AI approaches is presented. Finally, a discussion of open research directions in this innovative theme is presented.
C1 [Zayed, Samar M.] Higher Inst Engn & Technol HIET, Kafr Al Sheikh, Egypt.
   [Attiya, Gamal M.; El-Sayed, Ayman; Hemdan, Ezz El-Din] Menoufia Univ, Comp Sci & Engn Dept, Fac Elect Engn, Menoufia, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP Zayed, SM (corresponding author), Higher Inst Engn & Technol HIET, Kafr Al Sheikh, Egypt.
EM eng_samar_zayed@yahoo.com; gamal.attiya@yahoo.com;
   ayman.elsayed@el-eng.menofia.edu.eg; ezzvip@yahoo.com
RI EL-SAYED, Ayman E./AFM-8547-2022
OI EL-SAYED, Ayman E./0000-0002-4437-259X
CR Aheleroff S, 2021, ADV ENG INFORM, V47, DOI 10.1016/j.aei.2020.101225
   Alexopoulos K, 2020, INT J COMPUT INTEG M, V33, P429, DOI 10.1080/0951192X.2020.1747642
   An J, 2021, INT J BIOPRINTING, V7, P1, DOI 10.18063/ijb.v7i1.342
   Anisi M. H., 2020, J. Wirel. Mob. NetworksUbiquitous Comput. Dependable Appl, V11, P77, DOI [DOI 10.22667/JOWUA.2020.12.31.077, 10.22667/JOWUA.2020.12.31.77, DOI 10.22667/JOWUA.2020.12.31.77]
   [Anonymous], Iot: number of connected devices worldwide 2012-2025
   Ansys, 2019, Creating a Digital Twin for a Pump
   arcweb, 2019, An update on SAP and trenitalia's IoT-enabled dynamic maintenance approach
   Ashton K., RFID journal, V22 22, P97, DOI DOI 10.1145/2967977
   Austin M, 2020, J MANAGE ENG, V36, DOI 10.1061/(ASCE)ME.1943-5479.0000774
   Barricelli BR, 2019, IEEE ACCESS, V7, P167653, DOI 10.1109/ACCESS.2019.2953499
   beckhoff, 2019, Twin CAT-PLC and motion control on the PC
   Bilberg A, 2019, CIRP ANN-MANUF TECHN, V68, P499, DOI 10.1016/j.cirp.2019.04.011
   Björnsson B, 2019, GENOME MED, V12, DOI 10.1186/s13073-019-0701-3
   Boschert S., 2016, Mechatronic Futures: Challenges and Solutions for Mechatronic Systems and Their Designers, P59, DOI [DOI 10.1007/978-3-319-32156-1_5, DOI 10.1007/978-3-319-32156-15]
   Boyes H, 2018, COMPUT IND, V101, P1, DOI 10.1016/j.compind.2018.04.015
   Castelli G, 2019, 2019 IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITIES: IMPROVING QUALITY OF LIFE USING ICT, IOT AND AI (IEEE HONET-ICT 2019), P33, DOI 10.1109/honet.2019.8907962
   Chen XM, 2018, 21ST ACM/IEEE INTERNATIONAL CONFERENCE ON MODEL DRIVEN ENGINEERING LANGUAGES AND SYSTEMS (MODELS 2018), P144, DOI 10.1145/3239372.3239401
   Dassault Systemes, Meet Virtual Singapore, the city's 3D digital twin
   Dembski F, 2019, 12 INT SP SYNTAX S S
   El Saddik A, 2018, IEEE MULTIMEDIA, V25, P87, DOI 10.1109/MMUL.2018.023121167
   Elayan H, 2021, IEEE INTERNET THINGS, V8, P16749, DOI 10.1109/JIOT.2021.3051158
   Farhat MH, 2021, MEAS SCI TECHNOL, V32, DOI 10.1088/1361-6501/abd280
   Ford DN, 2020, J MANAGE ENG, V36, DOI 10.1061/(ASCE)ME.1943-5479.0000779
   Fuller A, Digital Twin: Enabling Technologies, Challenges and Open Research, P1
   Gahlot S, 2019, IEEE INTERNET THINGS, V6, P2116, DOI 10.1109/JIOT.2018.2872389
   Gehrmann C, 2020, IEEE T IND INFORM, V16, P669, DOI 10.1109/TII.2019.2938885
   Ghita M, 2020, INT J ADV COMPUT SC, V11, P468
   Glaessgen E., 2012, The Digital Twin Paradigm for Future NASA and U.S. Air Force Vehicles
   Gockel B, 2012, PROC 53 STRUCT STRUC
   Granelli F, 2021, Evaluating a Digital Twin of an IoT Resource Slice: an Emulation Study using the ELIoT Platform, V3156, P1
   Grieves M., 2014, White paper
   Grieves M., 2017, TRANSDISCIPLINARY PE, P85, DOI [DOI 10.1007/978-3-319-38756-7_4, 10.1007/978-3-319-38756-7_4]
   Gupta A, 2012, SADHANA-ACAD P ENG S, V37, P241, DOI 10.1007/s12046-012-0062-8
   He B, 2021, ADV MANUF, V9, P1, DOI 10.1007/s40436-020-00302-5
   He Y, 2018, IEEE SIGNAL PROC MAG, V35, P120, DOI 10.1109/MSP.2018.2842228
   Hinchy EP, 2019, PROCEDIA MANUF, V38, P1213, DOI 10.1016/j.promfg.2020.01.212
   Hofmann W, 2019, IFAC PAPERSONLINE, V52, P2104, DOI 10.1016/j.ifacol.2019.11.516
   Howard D, 2019, 2019 PAN PACIFIC MICROELECTRONICS SYMPOSIUM (PAN PACIFIC), DOI 10.23919/panpacific.2019.8696712
   i-eio, 2019, How IoT is turning Rolls-Royce into a data-fuelled business
   Jazdi Nasser, 2021, Procedia CIRP, V97, P396, DOI 10.1016/j.procir.2020.05.257
   Jiang ZM, 2021, J IND INF INTEGR, V22, DOI 10.1016/j.jii.2020.100196
   Jo SK, 2018, I C INF COMM TECH CO, P1461, DOI 10.1109/ICTC.2018.8539516
   Jonathan F, 2021, Realizing the Digital Twin Transition for Smart Cities
   Jong JJ, 2017, Advanced Multimedia and Ubiquitous Engineering, V448
   Kanmani M, 2020, MULTIMED TOOLS APPL, V79, P17859, DOI 10.1007/s11042-020-08628-9
   Kanmani M, 2019, INT J BIOMED ENG TEC, V31, P278
   Kanmani M, 2019, MULTIDIM SYST SIGN P, V30, P1911, DOI 10.1007/s11045-019-00636-9
   Kanmani M, 2018, MULTIMED TOOLS APPL, V77, P12701, DOI 10.1007/s11042-017-4911-7
   Karadeniz AM, 2019, IEEE INT SYMP CIRC S
   Kiritsis D, 2011, COMPUT AIDED DESIGN, V43, P479, DOI 10.1016/j.cad.2010.03.002
   Kritzinger W, 2018, IFAC PAPERSONLINE, V51, P1016, DOI 10.1016/j.ifacol.2018.08.474
   Laaki H, 2019, IEEE ACCESS, V7, P20325, DOI 10.1109/ACCESS.2019.2897018
   Lechler T, 2020, IEEE INT C EMERG, P1773, DOI 10.1109/ETFA46521.2020.9212030
   Lee J, 2020, IET COLL INTEL MANUF, V2, P34, DOI 10.1049/iet-cim.2020.0009
   Liu Q, 2021, J MANUF SYST, V58, P52, DOI 10.1016/j.jmsy.2020.04.012
   Liu Y, 2019, IEEE ACCESS, V7, P49088, DOI 10.1109/ACCESS.2019.2909828
   Lu QC, 2020, J MANAGE ENG, V36, DOI 10.1061/(ASCE)ME.1943-5479.0000763
   Madheswari K, 2017, QUANT INFR THERM J, V14, P24, DOI 10.1080/17686733.2016.1229328
   Mandolla C, 2019, COMPUT IND, V109, P134, DOI 10.1016/j.compind.2019.04.011
   microsoft, 2019, The promise of a digital twin strategy
   Min QF, 2019, INT J INFORM MANAGE, V49, P502, DOI 10.1016/j.ijinfomgt.2019.05.020
   Mohammadi N, 2017, 2017 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI)
   Pargmann H, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA), P233, DOI 10.1109/ICCCBDA.2018.8386518
   Petrova-Antonova D., 2021, Human interaction, emerging technologies and future applications III: Proceedings of the 3rd international conference on human interaction and emerging technologies: Future applications (IHIET 2020), P384
   Petrova-Antonova D, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON SMART AND SUSTAINABLE TECHNOLOGIES (SPLITECH), P62, DOI 10.23919/splitech.2019.8783170
   Popa EO, 2021, LIFE SCI SOC POLICY, V17, DOI 10.1186/s40504-021-00113-x
   Qi QL, 2021, J MANUF SYST, V58, P3, DOI 10.1016/j.jmsy.2019.10.001
   Qi QL, 2018, PROC CIRP, V72, P237, DOI 10.1016/j.procir.2018.03.103
   Qi QL, 2018, IEEE ACCESS, V6, P3585, DOI 10.1109/ACCESS.2018.2793265
   Rasheed A, 2020, IEEE ACCESS, V8, P21980, DOI 10.1109/ACCESS.2020.2970143
   Ríos J, 2015, ADV TRANSDISCIPL ENG, V2, P657, DOI 10.3233/978-1-61499-544-9-657
   Ross Dickon, 2016, Engineering & Technology, V11, P44, DOI 10.1049/et.2016.1103
   Ruohomäki T, 2018, 2018 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P155, DOI 10.1109/IS.2018.8710517
   Saad A, 2020, IEEE T SMART GRID, V11, P5138, DOI 10.1109/TSG.2020.3000958
   Saad A, 2020, ENERGIES, V13, DOI 10.3390/en13184762
   Schleich B, 2017, CIRP ANN-MANUF TECHN, V66, P141, DOI 10.1016/j.cirp.2017.04.040
   Schrotter G, 2020, PFG-J PHOTOGRAMM REM, V88, P99, DOI 10.1007/s41064-020-00092-2
   Shalto M, 2010, Modeling, Simulation. Information Technology & Processing Roadmap
   Shangguan DS, 2019, PROCEEDINGS OF 2019 5TH INTERNATIONAL CONFERENCE ON MECHATRONICS AND ROBOTICS ENGINEERING (ICMRE 2019), P123, DOI 10.1145/3314493.3314504
   Sivalingam K, 2018, PROCEEDINGS OF 2018 2ND INTERNATIONAL CONFERENCE ON GREEN ENERGY AND APPLICATIONS (ICGEA), P197, DOI 10.1109/ICGEA.2018.8356292
   Sleuters J, 2019, 2019 14TH ANNUAL CONFERENCE SYSTEM OF SYSTEMS ENGINEERING (SOSE), P7, DOI [10.1109/sysose.2019.8753845, 10.1109/SYSOSE.2019.8753845]
   Sprunk C, 2017, AUTON ROBOT, V41, P473, DOI 10.1007/s10514-016-9557-1
   Talkhestani BA, 2019, AT-AUTOM, V67, P762, DOI 10.1515/auto-2019-0039
   Tao F, 2019, ENGINEERING-PRC, V5, P653, DOI 10.1016/j.eng.2019.01.014
   Tao F, 2019, IEEE T IND INFORM, V15, P2405, DOI 10.1109/TII.2018.2873186
   Tao F, 2018, INT J ADV MANUF TECH, V94, P3563, DOI 10.1007/s00170-017-0233-1
   Tuegel, 2012, PROC 53 STRUCT STRUC
   Tuegel E. J., 2011, International Journal of Aerospace Engineering, V2011, DOI [DOI 10.1155/2011/154798, 10.1155/2011/154798]
   U.S. Air Force, 2013, AF/ST TR 13-01
   Uzun M, 2019, IEEE AEROSP C PROC 2, P1
   Wan L., 2019, International Conference on Smart Infrastructure and Construction 2019 (ICSIC) Driving Data-Informed Decision-Making, P187
   Wang G, 2021, J MANUF SYST, V59, P165, DOI 10.1016/j.jmsy.2021.02.008
   Wu B, 2020, ENERGY AI, V1, DOI 10.1016/j.egyai.2020.100016
   Xu Y, 2019, IEEE ACCESS, V7, P19990, DOI 10.1109/ACCESS.2018.2890566
   Zhang ZA, 2019, J AMB INTEL HUM COMP, V10, P1217, DOI 10.1007/s12652-018-0687-5
   Zheng P, 2020, ROBOT CIM-INT MANUF, V64, DOI 10.1016/j.rcim.2020.101958
NR 96
TC 0
Z9 0
U1 11
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47081
EP 47107
DI 10.1007/s11042-023-15611-7
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH2U6
UT WOS:001151719300001
DA 2024-07-18
ER

PT J
AU Pabba, C
   Kumar, P
AF Pabba, Chakradhar
   Kumar, Praveen
TI A vision-based multi-cues approach for individual students' and overall
   class engagement monitoring in smart classroom environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Affective computing; Facial expression recognition; Smart classroom
   analytics; Transfer learning; Vision-based engagement estimation
ID FACIAL EXPRESSIONS; RECOGNITION; ACHIEVEMENT; EMOTIONS; FACES
AB Student disengagement in higher education offline classroom learning has become a critical concern because of digital distractions and insufficient student engagement monitoring. As the student count increases, it becomes harder for teachers to monitor individual students' engagement and maintain class engagement throughout the lecture. Computer vision, affective computing, and deep learning technologies can potentially build vision-based intelligent applications that can automatically estimate student engagement in real-time. Existing methods have limitations like scalability, high computation, non-real-time performance, and inability to track individual students' engagement. This paper attempts to address this research gap by proposing a real-time vision-based multi-cues approach. The approach obtained three kinds of scores: First, an affect score is based on the positive and negative academic affective states. Second, an attention score is based on frontal, and non-frontal head pose estimation using Perspective-n-Point technique. Third, a head movement score is based on head displacement distance. A Facial Expression Recognition model has been developed for academic affective state classification. This was achieved by fine-tuning MobileNetV2 through an incremental unfreezing approach on our newly developed dataset named Classroom Spontaneous Facial Expression Dataset. The model achieved training, validation, and testing accuracies of 95.7%, 94.9%, and 76%, respectively. The three obtained scores are combined using weighted fusion method to estimate individual students' engagement labels: engaged or non-engaged. Subsequently, every student's labels are aggregated to estimate the overall class engagement. Additionally, when validated with students' engagement self-reports the proposed approach yielded a 75% and 80% correlation for individual students and overall class engagement, respectively.
C1 [Pabba, Chakradhar; Kumar, Praveen] Visvesvaraya Natl Inst Technol, Dept Comp Sci & Engn, Nagpur 440010, Maharashtra, India.
C3 National Institute of Technology (NIT System); Visvesvaraya National
   Institute of Technology, Nagpur
RP Pabba, C (corresponding author), Visvesvaraya Natl Inst Technol, Dept Comp Sci & Engn, Nagpur 440010, Maharashtra, India.
EM pck2507@gmail.com
FU The authors would like to extend their gratitude to all of the
   individuals who took part in this work and the faculty and staff of the
   CSE department at VNIT for their assistance in carrying out this
   research. In addition, we would like to extend our thank
FX The authors would like to extend their gratitude to all of the
   individuals who took part in this work and the faculty and staff of the
   CSE department at VNIT for their assistance in carrying out this
   research. In addition, we would like to extend our thanks to Mahendra
   Prajapati and Vishal Bhardwaj, who are undergraduate and postgraduate
   students, for their assistance with this work.
CR Ahuja Karan, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3351229
   Altuwairqi K, 2021, SIGNAL IMAGE VIDEO P, V15, P1387, DOI 10.1007/s11760-021-01869-7
   Amatari V.O., 2015, INT J SECONDARY ED, V3, P43, DOI [10.11648/j.ijsedu.20150305.11, 10.11648/j.ijsedu.20150305]
   [Anonymous], 2013, 2013 IEEE international conference on acoustics, speech and signal processing
   [Anonymous], 2017, Recognizing facial expressions using deep learning
   [Anonymous], 2001, Rapid object detection using a boosted cascade of simple features
   [Anonymous], 2014, TRANSFERABLE ARE FEA
   Ashwin TS, 2020, FUTURE GENER COMP SY, V108, P334, DOI 10.1016/j.future.2020.02.075
   Azizi FN, 2022, Facial expression image based emotion detection using convolutional neural network, P157
   Banerjee A, 2023, MULTIMED TOOLS APPL, V82, P10887, DOI 10.1007/s11042-022-13721-2
   Behera A, 2020, INT J ARTIF INTELL E, V30, P236, DOI 10.1007/s40593-020-00195-2
   Bergdahl N, 2020, COMPUT EDUC, V149, DOI 10.1016/j.compedu.2019.103783
   Bhardwaj P, 2021, COMPUT ELECTR ENG, V93, DOI 10.1016/j.compeleceng.2021.107277
   Bosch N, 2015, INT C INTELLIGENT US, V2015, P379, DOI DOI 10.1145/2678025.2701397
   Bosch N, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2946837
   Bradbury NA, 2016, ADV PHYSIOL EDUC, V40, P509, DOI 10.1152/advan.00109.2016
   Anh BN, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9224729
   Calvo MG, 2008, BEHAV RES METHODS, V40, P109, DOI 10.3758/BRM.40.1.109
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   D'Mello S, 2013, J EDUC PSYCHOL, V105, P1082, DOI 10.1037/a0032674
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Di Lascio Elena, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3264913
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Eng S. K., 2019, IOP Conference Series: Materials Science and Engineering, V705, DOI 10.1088/1757-899X/705/1/012031
   Exeter DJ, 2010, STUD HIGH EDUC, V35, P761, DOI 10.1080/03075070903545058
   Gogu SR, 2023, INT J ARTIF INTELL T, V32, DOI 10.1142/S0218213023400055
   González-Hernández F, 2018, J INTELL FUZZY SYST, V34, P3325, DOI 10.3233/JIFS-169514
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Groccia J., 2018, NEW DIRECTIONS TEACH, V154, P11, DOI DOI 10.1002/TL.20287
   Gupta SK, 2019, MULTIMED TOOLS APPL, V78, P25321, DOI 10.1007/s11042-019-7651-z
   Gupta S, 2023, MULTIMED TOOLS APPL, V82, P11365, DOI 10.1007/s11042-022-13558-9
   Hu MJ, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22165932
   Huang LS, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9091837
   Joshi S., 2019, Issues in Training a Convolutional Neural Network Model for Image Classification, V1046, DOI 10.1007/978-981-13-9942-8_27
   Kamath S, 2021, Engagement analysis of students in online learning environments, P34
   Keras applications, 2023, The python deep learning library
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuh G.D., 2003, CHANGE, V35, P24, DOI [DOI 10.1080/00091380309604090, 10.1080/00091380309604090]
   Kwet M, 2020, TEACH HIGH EDUC, V25, P510, DOI 10.1080/13562517.2020.1734922
   Lebal A, 2023, MULTIMED TOOLS APPL, V82, P17391, DOI 10.1007/s11042-022-13947-0
   Lei H, 2018, SOC BEHAV PERSONAL, V46, P517, DOI 10.2224/sbp.7054
   Leo M, 2020, INFORMATION, V11, DOI 10.3390/info11030128
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Li YB, 2013, J YOUTH ADOLESCENCE, V42, P20, DOI 10.1007/s10964-012-9857-5
   Liao JC, 2021, APPL INTELL, V51, P6609, DOI 10.1007/s10489-020-02139-8
   Luo ZZ, 2022, INTERACT LEARN ENVIR, V30, P1117, DOI 10.1080/10494820.2019.1710852
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Monkaresi H, 2017, IEEE T AFFECT COMPUT, V8, P15, DOI 10.1109/TAFFC.2016.2515084
   Pabba C, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12839
   Pekrun R, 2006, EDUC PSYCHOL REV, V18, P315, DOI 10.1007/s10648-006-9029-9
   Raca M, 2015, Translating head motion into attention-towards processing of student's body-language
   Rashmi M, 2021, MULTIMED TOOLS APPL, V80, P2907, DOI 10.1007/s11042-020-09741-5
   Renawi A, 2022, EDUC INF TECHNOL, V27, P4753, DOI 10.1007/s10639-021-10808-5
   Rocca F, 2014, Head pose estimation by perspective-n-point solution based on 2d markerless face tracking, P67
   Rossi S, 2016, LECT NOTES COMPUT SC, V10037, P89, DOI 10.1007/978-3-319-49130-1_8
   Rouari A, 2021, SOFT COMPUT, V25, P12357, DOI 10.1007/s00500-021-05949-1
   Rumberger RW, 2012, HANDBOOK OF RESEARCH ON STUDENT ENGAGEMENT, P491, DOI 10.1007/978-1-4614-2018-7_24
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tandel GS, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104564
   Thati RP, 2023, MULTIMED TOOLS APPL, V82, P4787, DOI 10.1007/s11042-022-12315-2
   Uçar MU, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11091500
   Vanneste P, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9030287
   Whitehill J, 2014, IEEE T AFFECT COMPUT, V5, P86, DOI 10.1109/TAFFC.2014.2316163
   Wiranata IMN, 2020, AIP Conf Proc, V2217, DOI [10.1063/5.0000679, DOI 10.1063/5.0000679]
   Yadegaridehkordi E, 2019, COMPUT EDUC, V142, DOI 10.1016/j.compedu.2019.103649
   Yolcu G, 2020, J AMB INTEL HUM COMP, V11, P237, DOI 10.1007/s12652-019-01310-5
   Zaletelj J, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0228-8
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
NR 71
TC 0
Z9 0
U1 7
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 10
PY 2023
DI 10.1007/s11042-023-17533-w
EA NOV 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9QP0
UT WOS:001101716100007
DA 2024-07-18
ER

PT J
AU Chen, H
   Wu, HY
   Yang, N
   Huang, HP
   Liang, WB
AF Chen, Hui
   Wu, Hongyan
   Yang, Ning
   Huang, Heping
   Liang, Weibin
TI Irregular object measurement method based on improved adaptive slicing
   method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Profile feature measurement; Adaptive slicing; Multi contour boundary
   segmentation; Non contact type
AB Surface shape feature is a very important index for monitoring objects. However, in the existing slicing methods, the volume measurement accuracy of point cloud is easy to be low due to the problems of indistinguishable or fuzzy boundary and static slicing. In order to solve this problem, an improved method based on dynamic adaptation is proposed on the basis of slice method, which is suitable for calculating the volume of point cloud on irregular object surface when there are multiple contour boundaries. First, after the point cloud preprocessing, the rough and fine two-step clustering method is used to separate the multiple contour boundaries in the slice, and then the adaptive mechanism is introduced to achieve adaptive slicing and calculate the point cloud volume. In addition, the bounding box algorithm is used to calculate the two-dimensional parameters (length, width and height) of the point cloud data, and the surface area is calculated by generating the grid surface of the point cloud through the greedy projection triangulation measurement algorithm. Using multiple sets of data to calculate their volume by comparing algorithms, we find that the error in this paper is reduced. In addition, the validity of the two-dimensional parameters is verified by comparing the calculated value with its theoretical value. The results show that the method is effective and accurate in segmentation of multi contour boundary, and can effectively calculate the surface shape features of point cloud, and has certain application effects.
C1 [Chen, Hui; Wu, Hongyan; Yang, Ning] Shanghai Univ Elect Power, Coll Automat Engn, Shanghai 200090, Peoples R China.
   [Chen, Hui] Minist Educ, Key Lab Syst Control & Informat Proc, Shanghai 200240, Peoples R China.
   [Huang, Heping] Zhengtai Instrument Hangzhou Co Ltd, Zhejiang 310052, Peoples R China.
   [Liang, Weibin] Shanghai Enflame Technol Co Ltd, Shanghai 201203, Peoples R China.
C3 Shanghai University of Electric Power
RP Chen, H (corresponding author), Shanghai Univ Elect Power, Coll Automat Engn, Shanghai 200090, Peoples R China.; Chen, H (corresponding author), Minist Educ, Key Lab Syst Control & Informat Proc, Shanghai 200240, Peoples R China.
EM chenhui@shiep.edu.cn
FU Natural Science Foundation of Shanghai [20ZR1421300]; Shanghai Pujiang
   Program [21PJD025]; Project of the State Administration of foreign
   experts of the Ministry of science and technology [DL2022013007L];
   Shanghai Science and Technology Commission Program [21DZ1207300]
FX The Natural Science Foundation of Shanghai (No. 20ZR1421300), Shanghai
   Pujiang Program(No.21PJD025), Project of the State Administration of
   foreign experts of the Ministry of science and
   technology(No.DL2022013007L), Shanghai Science and Technology Commission
   Program (No.21DZ1207300).
CR Apolo AOE., 2020, Eur J Agron, V115, P1
   Bendels GH, 2006, JOURNAL WSCG, V14, P89
   Cai ZY, 2020, IEEE ACCESS, V8, P176565, DOI 10.1109/ACCESS.2020.3027154
   Cheng Xiaojun, 2014, Journal of Tongji University (Natural Science), V42, P1738, DOI 10.11908/j.issn.0253-374x.2014.11.018
   Fernández-Sarría A, 2013, COMPUT ELECTRON AGR, V90, P176, DOI 10.1016/j.compag.2012.09.017
   Guevara J, 2020, AUTOMAT CONSTR, V117, DOI 10.1016/j.autcon.2020.103207
   Jo HC, 2018, SENSOR ACTUAT A-PHYS, V283, P362, DOI 10.1016/j.sna.2018.09.012
   Jordi GM., 2021, Comput Electron Agric, V188, P1
   Kamari M, 2021, AUTOMAT CONSTR, V121, DOI 10.1016/j.autcon.2020.103430
   Li H, 2017, COMPUT ELECTRON AGR, V142, P416, DOI 10.1016/j.compag.2017.09.009
   Magistri F, 2022, IEEE ROBOT AUTOM LET, V7, P10120, DOI 10.1109/LRA.2022.3193239
   Nidhi K., 2021, Sensors, V21, P1
   Putman EB, 2018, IEEE T GEOSCI REMOTE, V56, P6484, DOI 10.1109/TGRS.2018.2839088
   Qin ZJ, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-07221-4
   Rusu RB, 2008, ROBOT AUTON SYST, V56, P927, DOI 10.1016/j.robot.2008.08.005
   Saquib M., 2019, 2019 IEEE/CVF Conf Comput Vision Pattern Recognit (CVPR), V2019, P1
   Sun GX, 2019, AGRONOMY-BASEL, V9, DOI 10.3390/agronomy9100596
   Sun SP, 2020, ISPRS J PHOTOGRAMM, V160, P195, DOI 10.1016/j.isprsjprs.2019.12.011
   Vijaypal S., 2021, Sensors, V21, P1
   Wang WL, 2014, J FOOD ENG, V142, P153, DOI 10.1016/j.jfoodeng.2014.06.019
   Zheng YT., 2022, Second International Conference on Sensors and InformationTechnology (ICSI 2022), V12248, P203
NR 21
TC 1
Z9 1
U1 8
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 7
PY 2023
DI 10.1007/s11042-023-17342-1
EA NOV 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3TF7
UT WOS:001097705200002
DA 2024-07-18
ER

PT J
AU Jadhav, S
   Singh, J
AF Jadhav, Sneha
   Singh, Jaibir
TI Design of EGTBoost Classifier for Automated External Skin Defect
   Detection in Mango Fruit
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mango Fruit Defects; Segmentation; Features; Cluster; Classifier;
   Adaptive Tunicate Swarm Optimizer
AB The presence of overlapping mangoes and leaves makes the segmentation process inaccurate. In addition, the variation in colour, texture, shape, temperature and shadow effects of the real conditioned image makes segmentation even more complex. The presence of outliers would further affect the classification accuracy. Many studies have reported the deep learning-based technique, but those methods failed to provide an effective solution due to the high processing stage and limited data usage. Hence, this work introduces a machine learning-based technique that reduces the problem of time-consuming predictions. This work aims to estimate the defected region of mangoes by enhanced segmentation and optimal feature selection to enhance classification accuracy. To detect mango fruit defects, initially, the collected mango images are pre-processed to smoothen and reduce image noise. This is achieved using the guided Gabor bilateral filter; the technique can reduce image noise without information loss. Then the obtained pre-processed image is segmented by considering the defect as a region of interest. The segmentation is achieved using the fuzzy level set method (FLSM), which creates clusters for an image's dynamic variation. Then, the features are extracted using the dual-tree complex transform (DT-CT) and the optimal features are selected using the metaheuristic algorithm adaptive tunicate swarm optimizer (ATSO). The obtained optimal features are used for the detection process, which uses an Extreme Gradient Tree boost classifier (EGTBoost) classifier and the output is generated using vote-based classification. This classifier accurately classifies the diseased and healthy mangoes. The experimentation is carried out on the Kaggle and the real-time datasets. The accuracy and precision values achieved by the proposed model are 0.969 and 0.986 on the Kaggle dataset, respectively.
C1 [Jadhav, Sneha; Singh, Jaibir] Om Parkash Jogender Singh Univ, Dept Comp Sci & Engn, Churu 331303, Rajasthan, India.
RP Jadhav, S (corresponding author), Om Parkash Jogender Singh Univ, Dept Comp Sci & Engn, Churu 331303, Rajasthan, India.
EM jadhav.sneha27@gmail.com
OI Singh, Dr. Jaibir/0009-0006-4231-0834
CR Andrushia AD, 2019, INTEL SYST REF LIBR, V150, P215, DOI 10.1007/978-3-319-96002-9_9
   Behera SK, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01865-8
   Bhargava A, 2021, J KING SAUD UNIV-COM, V33, P243, DOI 10.1016/j.jksuci.2018.06.002
   Chithra PL, 2021, SOFT COMPUT, V25, P431, DOI 10.1007/s00500-020-05158-2
   Dhiman B, 2022, MULTIMED TOOLS APPL, V81, P16255, DOI 10.1007/s11042-022-12652-2
   Dhiman B, 2021, SOFT COMPUT, V25, P9255, DOI 10.1007/s00500-021-05867-2
   Hemamalini V, 2022, J FOOD QUALITY, V2022, DOI 10.1155/2022/5262294
   Hitanshu, 2019, 2019 2nd International Conference on Intelligent Computing, Instrumentation and Control Technologies (ICICICT), P952, DOI 10.1109/ICICICT46008.2019.8993240
   Iqbal HMR, 2022, INT J FRUIT SCI, V22, P95, DOI 10.1080/15538362.2021.2023069
   Kaur S, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103541
   Kumari N, 2021, MULTIMED TOOLS APPL, V80, P4943, DOI 10.1007/s11042-020-09747-z
   Mia MR., 2020, IRAN J COMPUTER SCI, V3, P185, DOI DOI 10.1007/S42044-020-00057-Z
   Momin M. A., 2017, Information Processing in Agriculture, V4, P150, DOI 10.1016/j.inpa.2017.03.003
   Naik S., 2017, INT J COMPUTER APPL, V170, P22, DOI DOI 10.5120/IJCA2017914937
   Naik S, 2019, Mango dataset-studio setup
   Thong ND, 2019, INT CONF SYST SCI EN, P45, DOI [10.1109/icsse.2019.8823119, 10.1109/ICSSE.2019.8823119]
   Nguyen Truong Thinh, 2019, International Journal of Machine Learning and Computing, V9, P374, DOI 10.18178/ijmlc.2020.10.2.945
   Nithya R, 2022, FOODS, V11, DOI 10.3390/foods11213483
   Nturambirwe JFI, 2020, BIOSYST ENG, V189, P60, DOI 10.1016/j.biosystemseng.2019.11.011
   Pandey R, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1087, DOI 10.1109/ICACCI.2014.6968366
   Saleem R, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112411901
   Sanath Rao U., 2021, GLOBAL TRANSITIONS P, V2, P535, DOI [10.1016/j.gltp.2021.08.002, DOI 10.1016/J.GLTP.2021.08.002]
   Saranya CP, 2020, SOFT COMPUT, V24, P12659, DOI 10.1007/s00500-020-04707-z
   Pham TN, 2020, IEEE ACCESS, V8, P189960, DOI 10.1109/ACCESS.2020.3031914
   Wongsila Suwit, 2021, 2021 Joint International Conference on Digital Arts, Media and Technology with ECTI Northern Section Conference on Electrical, Electronics, Computer and Telecommunication Engineering, P249, DOI 10.1109/ECTIDAMTNCON51128.2021.9425737
   Wu A, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106454
   Yang SM, 2023, NEUROCOMPUTING, V542, DOI 10.1016/j.neucom.2023.126240
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P7126, DOI 10.1109/TNNLS.2021.3084250
NR 29
TC 0
Z9 0
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 25
PY 2023
DI 10.1007/s11042-023-17191-y
EA OCT 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U7WL5
UT WOS:001086870100003
DA 2024-07-18
ER

PT J
AU Shoaib, M
   Fitzpatrick, D
   Pitt, I
AF Shoaib, Muhammad
   Fitzpatrick, Donal
   Pitt, Ian
TI Assistive technology-based solutions in learning mathematics for
   visually-impaired people: exploring issues, challenges and opportunities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Assistive Technology; Visually Impaired; Learning; Mathematics;
   Education; Accessibility
ID IMPAIRMENTS SHARE; STUDENTS; SYSTEM; BLIND; EDUCATION; BRAILLE;
   ACCESSIBILITY; DISPLAYS; VISION; ACCESS
AB In the absence of vision, visually impaired and blind people rely upon the tactile sense and hearing to obtain information about their surrounding environment. These senses cannot fully compensate for the absence of vision, so visually impaired and blind people experience difficulty with many tasks, including learning. This is particularly true of mathematical learning. Nowadays, technology provides many effective and affordable solutions to help visually impaired and blind people acquire mathematical skills. This paper is based upon a systematic review of technology-based mathematical learning solutions for visually impaired people and discusses the findings and objectives for technological improvements. It analyses the issues, challenges and limitations of existing techniques. We note that audio feedback, tactile displays, a supportive academic environment, digital textbooks and other forms of accessible math applications improve the quality of learning mathematics in visually impaired and blind people. Based on these findings, it is suggested that smartphone-based solutions could be more convenient and affordable than desktop/laptop-based solutions as a means to enhance mathematical learning. Additionally, future research directions are discussed, which may assist researchers to propose further solutions that will improve the quality of life for visually impaired and blind people.
C1 [Shoaib, Muhammad; Pitt, Ian] Univ Coll Cork, Sch Comp Sci & Informat Technol, Cork, Ireland.
   [Fitzpatrick, Donal] Natl Disabil Author, Ctr Excellence Universal Design, Dublin, Ireland.
C3 University College Cork
RP Shoaib, M (corresponding author), Univ Coll Cork, Sch Comp Sci & Informat Technol, Cork, Ireland.
EM muhammad.shoaib@cs.ucc.ie
OI Shoaib, Muhammad/0000-0003-4393-2062
FU Science Foundation Ireland [18/CRT/6222]
FX This publication has emanated from research conducted with the financial
   support of Science Foundation Ireland under Grant number 18/CRT/6222.
   For the purpose of Open Access, the author has applied a CC BY public
   copyright licence to any Author Accepted Manuscript version arising from
   this submission.
CR Akar N, 2018, J EDUC FUTUR, P95
   [Anonymous], 2019, World report on vision, P180
   Armano T, 2015, C NAZ SIREM 2014, P119
   Asebriy Z, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10110547
   Ashraf MM., 2016, International Journal of Disability Management, V11, DOI DOI 10.1017/IDM.2016.6
   Ausbrooks Ron., 2003, Mathematical markup language (MathML) version 2.0, Vsecond
   Bateman A, 2018, INT J HUM-COMPUT ST, V109, P102, DOI 10.1016/j.ijhcs.2017.09.004
   Beal CR, 2018, J VISUAL IMPAIR BLIN, V112, P5
   Bouck EC, 2016, J VISUAL IMPAIR BLIN, V110, P41
   Bouck EC, 2011, J SPEC EDUC TECHNOL, V26, P1
   Cahill, 1994, INF TECHNOL DISABIL, V1, P1
   Clark-Wilson A, 2021, MATH ED DIGITAL AGE, DOI [10.4324/9781003137580, DOI 10.4324/9781003137580]
   Crollen V, 2011, J EXP CHILD PSYCHOL, V109, P525, DOI 10.1016/j.jecp.2011.03.011
   Emerson RW, 2018, J VISUAL IMPAIR BLIN, V112, P20
   Fallah N, 2010, ACM SIGACCESS AC JAN, P24, DOI 10.1145/1731849.1731853
   Ferreira F, 2014, PROC FRONT EDUC CONF
   Gaura P., 2002, Computers Helping People with Special Needs 8th International Conference, ICCHP 2002. Proceedings (Lecture Notes in Computer Science Vol.2398), P486
   Giesen JM, 2012, INT J SPEC EDUC, V27, P17
   Hansen EG, 2010, J VISUAL IMPAIR BLIN, V104, P275, DOI 10.1177/0145482X1010400503
   Harling PA., 1995, MATHGRASP DESIGN ALG
   Huang PH, 2015, INT J ENG EDUC, V31, P495
   Irvine D, 2014, NEURO-OPHTHALMOLOGY, V38, P53, DOI 10.3109/01658107.2013.874448
   Isaacson MD, 2010, DISABIL REHABIL-ASSI, V5, P83, DOI 10.3109/17483100903387226
   Karshmer A. I., 2004, ASSETS 2004. The Sixth International ACM SIGACCESS Conference on Computers and Accessibility, P55
   Karshmer A. J., 1998, ASSETS'98. Third International ACM Conference on Assistive Technologies, P136, DOI 10.1145/274497.274524
   Karshmer AI, 1999, P FRONTIERS ED C, V2, DOI [10.1109/FIE.1999.841638, DOI 10.1109/FIE.1999.841638]
   Kelly SM., 2023, USING TECHNOLOGY ENH, V37, P87, DOI [10.1108/S0270-401320230000037006, DOI 10.1108/S0270-401320230000037006]
   Ketamo H, 2003, EDUC TECHNOL SOC, V6, P83
   Kitchenham B., 2007, GUIDELINES PERFORMIN
   Kleanthous I, 2018, K 12 STEM ED BREAKTH, P359
   Klingenberg OG, 2020, BRIT J VISUAL IMPA, V38, P38, DOI 10.1177/0264619619876975
   Klingenberg OG, 2012, J VISUAL IMPAIR BLIN, V106, P453, DOI 10.1177/0145482X1210600802
   Kucirkova N, 2016, APPS TECHNOLOGY YOUN
   LaVenture S, 2007, PARENTS GUIDE SPECIA, P1
   Leo F, 2017, IEEE T NEUR SYS REH, V25, P861, DOI 10.1109/TNSRE.2016.2619742
   Li Q, 2010, EDUC PSYCHOL REV, V22, P215, DOI 10.1007/s10648-010-9125-8
   Liska M, 2015, COMBINING TEXT FORMU, P7, DOI [10.1145/2810355.2810359, DOI 10.1145/2810355.2810359]
   Loomis JM, 2005, J VISUAL IMPAIR BLIN, V99, P219, DOI 10.1177/0145482x0509900404
   Mackowski M, 2022, DISABIL REHABIL-ASSI, V17, P559, DOI 10.1080/17483107.2020.1800116
   Mackowski M, 2018, MULTIMED TOOLS APPL, V77, P6191, DOI 10.1007/s11042-017-4526-z
   Maguvhe M, 2015, AFR J DISABIL, V4, DOI 10.4102/ajod.v4i1.194
   Marshall L, 2008, EXPLORING USE MATH M
   Martiniello N, 2022, ASSIST TECHNOL, V34, P34, DOI 10.1080/10400435.2019.1682084
   mathedleadership, MATH ED DIG AG
   Mejía P, 2021, IEEE ACCESS, V9, P66929, DOI 10.1109/ACCESS.2021.3076306
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Morash V., 2014, Terra Haptica, V4, P13
   Mukherjee A, 2014, EDUC TECHNOL SOC, V17, P40
   Mulloy AM, 2014, AUT CHILD PSYCHO, P113, DOI 10.1007/978-1-4899-8029-8_5
   Nicotra G, 2010, LECT NOTES COMPUT SC, V6180, P423, DOI 10.1007/978-3-642-14100-3_63
   Oliveira FCMB, 2012, IEEE T HAPTICS, V5, P172, DOI [10.1109/ToH.2011.35, 10.1109/TOH.2011.35]
   Pires Ana Cristina, 2022, International Journal of Child-Computer Interaction, DOI 10.1016/j.ijcci.2021.100382
   Pires AC, 2019, ASSETS'19: THE 21ST INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P670, DOI 10.1145/3308561.3354596
   Pitchford NJ, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00262
   Raman T. V., 1992, Proceedings of the Johns Hopkins National Search for Computing Applications to Assist Persons with Disabilities (Cat. No.92TH0429-1), P170, DOI 10.1109/CAAPWD.1992.217377
   Ran L, 2004, SECOND IEEE ANNUAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS, PROCEEDINGS, P23, DOI 10.1109/PERCOM.2004.1276842
   Rose D, 2005, UNIVERSALLY DESIGNED, P216
   Rosenblum LP, 2018, J VISUAL IMPAIR BLIN, V112, P475
   Rosenblum LP, 2015, J VISUAL IMPAIR BLIN, V109, P173
   Rule AC, 2011, INT J SCI EDUC, V33, P865, DOI 10.1080/09500693.2010.506619
   Sanchez J., 2005, International Journal on Disability and Human Development, V4, P311, DOI DOI 10.1515/IJDHD.2005.4.4.311
   Schleppenbach D, 1997, BRAILLE MONITOR, V40
   Schweikhardt W, 2006, LECT NOTES COMPUT SC, V4061, P1223
   Soiffer N., 2005, Proceedings of the 7th international Association for Computing Machinery Special Interest Group on Accessible Computing Conference on Computers and Accessibility - ASSETS 2005, P204, DOI [DOI 10.1145/1090785.1090831, 10.1145/1090785.1090831]
   Stevens R., 1994, Computers for Handicapped Persons. 4th International Conference, ICCHP '94 Proceedings, P313
   Stevens RD, 1997, HUM-COMPUT INTERACT, V12, P47, DOI 10.1207/s15327051hci1201&2_3
   Stevens RD, 1996, CITESEER, P1
   Supalo CA, 2014, J CHEM EDUC, V91, P1257, DOI 10.1021/ed400585v
   Virvou M, 2005, EDUC TECHNOL SOC, V8, P54
   Wongkia W, 2012, COMPUT MATH APPL, V64, P2128, DOI 10.1016/j.camwa.2012.04.009
   Yesilada Y., 2019, WEB ACCESSIBILITY, P791, DOI [10.1007/978-1-4471-7440-0_40, DOI 10.1007/978-1-4471-7440-0_40]
NR 71
TC 1
Z9 1
U1 15
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 46153
EP 46184
DI 10.1007/s11042-023-17409-z
EA OCT 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:001086870100005
PM 38037570
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Upadhyay, N
AF Upadhyay, Navneet
TI Iterative-processed multiband speech enhancement for suppressing musical
   sounds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Iteration number; Musical sound; Over-subtraction of spectral data;
   Subband; Speech enhancement
AB A multiband spectral subtraction (MBSS) processing step transforms background noise into annoying musical sounds. The paper proposes an iterative-processed multiband speech enhancement (IP-MBSE) post-processing method for suppressing musical sounds in enhanced speech recordings. In the proposed technique, the outturn of the MBSS processing is employed as an input for the subsequent iteration. The noise spectrum is estimated in each iteration, and the spectral subtraction is executed in each subband individually. The proposed method reduces musical sound even further by applying the estimated speech to the input and repeating the process. This procedure is repeated only a few times. The performance of the proposed technique, IP-MBSE, is measured using: (i) objective clarity measurements such as signal to noise ratio (SNR), segmental SNR (SegSNR), and perceptual evaluation of speech quality (PESQ), as well as (ii) subjective clarity metrics such as mean opinion score (MOS) and spectrogram at various SNR levels. The results of the IP-MBSE are compared with the conventional MBSS, and it is found that the IP-MBSE estimated speech is more pleasant for auditors.
C1 [Upadhyay, Navneet] LNM Inst Informat Technol, Dept Elect & Commun Engn, Jaipur 302031, India.
C3 LNM Institute of Information Technology
RP Upadhyay, N (corresponding author), LNM Inst Informat Technol, Dept Elect & Commun Engn, Jaipur 302031, India.
EM nupadhyay@lnmiit.ac.in
OI Upadhyay, Navneet/0000-0001-6097-1624
CR [Anonymous], 2000, ITU, ITU-TRec.P.862
   Berouti M., 1979, ICASSP 79. 1979 IEEE International Conference on Acoustics, Speech and Signal Processing, P208
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209
   EPHRAIM Y, 1992, P IEEE, V80, P1526, DOI 10.1109/5.168664
   Ephraim Y, 2006, The Electrical Engineering Handbook, P12
   Ephraim Y., 2006, ELECT ENG HDB
   Kamath S, 2002, INT CONF ACOUST SPEE, P4164
   LIM JS, 1979, P IEEE, V67, P1586, DOI 10.1109/PROC.1979.11540
   Loizou Philipos C, 2013, SPEECH ENHANCEMENT T, DOI 10.1201/b14529
   O'Shaughnessy D., 2007, Speech Communications: Human and Machine, V2nd
   Ogata S, 2001, IEEE REGION 10 INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONIC TECHNOLOGY, VOLS 1 AND 2, P242, DOI 10.1109/TENCON.2001.949588
   Sheng Li, 2010, Journal of Biomedical Science & Engineering, V3, P187, DOI 10.4236/jbise.2010.32024
   Upadhyay N, 2012, 2012 2ND INTERNATIONAL CONFERENCE ON POWER, CONTROL AND EMBEDDED SYSTEMS (ICPCES 2012)
   utdallas, A noisy speech corpus for assessment of speech enhancement algorithms
NR 14
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 21
PY 2023
DI 10.1007/s11042-023-17336-z
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W1VN4
UT WOS:001089581100011
DA 2024-07-18
ER

PT J
AU Pal, PK
   Kumar, D
   Agarwal, V
AF Pal, Puneet Kumar
   Kumar, Dhirendra
   Agarwal, Varun
TI Efficient image encryption using the Tinkerbell map in conjunction with
   linear feedback shift registers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image encryption; Chaos based cryptography; Logistic map; Tinkerbell
   map; Linear feedback shift register
ID HENON-SINE MAP; HYPERCHAOTIC MAP; CHAOS; CRYPTANALYSIS; COMBINATION
AB Images are considered crucial for conveying information due to their visualisation properties and capacity to hold a large amount of data. To safeguard image data from potential risks of information leakage, numerous image encryption algorithms have been developed. These algorithms often make use of chaotic maps, known for their high unpredictability, ergodicity, and sensitivity to parameters and initial values. This paper introduces a new chaos-based digital image encryption algorithm to protect digital images from unauthorised access or attacks. The algorithm heavily relies on permutation and diffusion processes. Specifically, it employs two rounds of pixel permutation using a Tinkerbell chaotic map sequence on the source image and two rounds of pixel diffusion using the Linear Feedback Shift Register and Logistic Map sequences on the permuted image. The encryption algorithm's effectiveness is thoroughly examined through various cryptanalysis techniques, including key space analysis, information entropy, correlation coefficient, differential attack, key sensitivity, histogram analysis, occlusion attack, noise attack, and encryption execution time. The experimental results are then compared with the most recent literature to demonstrate the algorithm's reliability and its ability to withstand diverse attacks. Notably, the proposed algorithm stands out as a secure and viable encryption solution, requiring less computational time than previous studies, thus making it a more practical option for real-world applications.
C1 [Pal, Puneet Kumar; Kumar, Dhirendra; Agarwal, Varun] Delhi Technol Univ, Dept Appl Math, Delhi, India.
C3 Delhi Technological University
RP Kumar, D (corresponding author), Delhi Technol Univ, Dept Appl Math, Delhi, India.
EM puneetkumarpal_2k21phdam12@dtu.ac.in; dhirendrakumar@dtu.ac.in;
   agarwalvarun2000@gmail.com
RI Pal, Puneet/KBC-2285-2024
OI Pal, Puneet/0000-0002-2496-2568; Kumar, Dhirendra/0000-0002-8902-5022
FU CSIR, India [08/0133(13253)/2022-EMR-I]
FX The first author received financial support from CSIR, India, with
   sanction order no.(08/0133(13253)/2022-EMR-I) for conducting this
   research work
CR Alexan W, 2023, SYMMETRY-BASEL, V15, DOI 10.3390/sym15051081
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Amina Y, 2024, MULTIMED TOOLS APPL, V83, P7895, DOI 10.1007/s11042-023-15858-0
   [Anonymous], 2023, Fractal coding and analysis group
   [Anonymous], 1999, Medical image samples
   Askar SS, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/341729
   Balasamy K, 2023, IETE J RES, V69, P83, DOI 10.1080/03772063.2021.1893231
   Cao LC, 2015, CHINESE PHYS B, V24, DOI 10.1088/1674-1056/24/10/100501
   Cao WJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107457
   Chen YC, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107286
   El-Shafai W, 2021, J AMB INTEL HUM COMP, V12, P9007, DOI 10.1007/s12652-020-02597-5
   Erkan U, 2022, INFORM SCIENCES, V589, P770, DOI 10.1016/j.ins.2021.12.126
   Fan SJ, 2024, MULTIMED TOOLS APPL, V83, P11557, DOI 10.1007/s11042-023-15964-z
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gao Z., 2021, DISCRETE DYN NAT SOC, V2021, P1
   Ge SL, 2023, MULTIMED TOOLS APPL, V82, P38589, DOI 10.1007/s11042-023-15048-y
   Goldsztejn A, 2011, SIAM J APPL DYN SYST, V10, P1480, DOI 10.1137/100819011
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Han XT, 2021, EUR PHYS J-SPEC TOP, V230, P3913, DOI 10.1140/epjs/s11734-021-00331-6
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Huang SF, 2022, IET IMAGE PROCESS, V16, P1544, DOI 10.1049/ipr2.12429
   Huang Y, 2023, MULTIMED TOOLS APPL, V82, P41879, DOI 10.1007/s11042-023-15012-w
   Joshi AB, 2020, J MOD OPTIC, V67, P933, DOI 10.1080/09500340.2020.1789233
   Kanwal S, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/4152683
   Kumar CM, 2022, APPL INTELL, V52, P2556, DOI 10.1007/s10489-021-02508-x
   Lai Q, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.118845
   Lai Q, 2020, ELECTRON LETT, V56, P1044, DOI 10.1049/el.2020.1630
   Li LH, 2022, MULTIMED TOOLS APPL, V81, P40755, DOI 10.1007/s11042-022-12621-9
   Li M, 2019, IEEE ACCESS, V7, P63336, DOI 10.1109/ACCESS.2019.2916402
   Liu LF, 2017, MULTIMED TOOLS APPL, V76, P16511, DOI 10.1007/s11042-016-3925-x
   Man ZL, 2021, CHAOS SOLITON FRACT, V152, DOI 10.1016/j.chaos.2021.111318
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Melman A, 2023, ARTIF INTELL REV, V56, P15375, DOI 10.1007/s10462-023-10537-w
   Mishra P, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03410-7
   Moumen A, 2018, Medical and biological image analysis
   Nan SX, 2022, NONLINEAR DYNAM, V108, P2705, DOI 10.1007/s11071-022-07335-4
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Raghuvanshi KK, 2021, MULTIMED TOOLS APPL, V80, P21011, DOI 10.1007/s11042-021-10665-x
   Rijmen Vincent., 2001, P FEDERAL INFORM PRO, P19, DOI DOI 10.1007/978-3-662-04722-4_1
   Rohith S, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN ELECTRONICS, COMPUTERS AND COMMUNICATIONS (ICAECC)
   Salomon R, 1996, BIOSYSTEMS, V39, P263, DOI 10.1016/0303-2647(96)01621-8
   Sharma M, 2023, MULTIMED TOOLS APPL, V82, P11949, DOI 10.1007/s11042-022-13733-y
   Signing VRF, 2022, CHAOS SOLITON FRACT, V155, DOI 10.1016/j.chaos.2021.111777
   SMID ME, 1988, P IEEE, V76, P550, DOI 10.1109/5.4441
   Sun JL, 2021, IEEE ACCESS, V9, P59313, DOI 10.1109/ACCESS.2021.3070350
   Suri S, 2019, J AMB INTEL HUM COMP, V10, P2277, DOI 10.1007/s12652-018-0825-0
   Teng L, 2022, INFORM SCIENCES, V605, P71, DOI 10.1016/j.ins.2022.05.032
   Vaidya SP, 2023, VISUAL COMPUT, V39, P2245, DOI 10.1007/s00371-022-02406-4
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wang MX, 2021, INFORM SCIENCES, V544, P1, DOI 10.1016/j.ins.2020.07.051
   Wang XY, 2021, MULTIMED TOOLS APPL, V80, P10301, DOI 10.1007/s11042-020-10101-6
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang ZC, 2023, NEUROCOMPUTING, V537, P49, DOI 10.1016/j.neucom.2023.03.041
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Xiao D, 2009, CHAOS SOLITON FRACT, V40, P2191, DOI 10.1016/j.chaos.2007.10.009
   Yang YG, 2021, INFORM SCIENCES, V562, P304, DOI 10.1016/j.ins.2021.01.041
   Yavuz E, 2016, COMPUT ELECTR ENG, V54, P471, DOI 10.1016/j.compeleceng.2015.11.008
   Ye GD, 2016, SECUR COMMUN NETW, V9, P2015, DOI 10.1002/sec.1458
   Yuan HM, 2017, MULTIMED TOOLS APPL, V76, P8087, DOI 10.1007/s11042-016-3454-7
   Zhang W, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22010073
   Zheng JM, 2020, MULTIMED TOOLS APPL, V79, P29901, DOI 10.1007/s11042-020-09454-9
NR 62
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 19
PY 2023
DI 10.1007/s11042-023-17236-2
EA OCT 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6OE7
UT WOS:001085969000008
DA 2024-07-18
ER

PT J
AU Hong, M
   Wang, HY
AF Hong, Ming
   Wang, Heyong
TI Feature selection based on long short term memory for text
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Text classification; Feature selection; Deep learning; Long short term
   memory
ID BIDIRECTIONAL LSTM; OPTIMIZATION ALGORITHM; ATTENTION MECHANISM; NAIVE
   BAYES; INFORMATION; PERFORMANCE; NETWORK; PREDICTION; FREQUENCY;
   EFFICIENT
AB The selection of discriminative terms from large quantity of terms in text documents is helpful for achieving better accuracy of text classification. To focus on the task of selecting discriminative terms from text, a deep learning based feature selection method is proposed. The method is developed by using the long short term memory (LSTM) network. A deep network based on LSTM is trained in unsupervised manner to extracted deep features from bag-of-words term frequency vectors. The deep features are integrated with term frequencies to evaluate the effectiveness of terms. The proposed method extends the limitation of term frequency information by applying deep features for feature selection. Experiments in nine public datasets demonstrate better performance of our method in selecting discriminative terms than comparative methods.
C1 [Hong, Ming; Wang, Heyong] South China Univ Technol, Dept Elect Business, Guangzhou, Peoples R China.
C3 South China University of Technology
RP Wang, HY (corresponding author), South China Univ Technol, Dept Elect Business, Guangzhou, Peoples R China.
EM wanghey@scut.edu.cn
OI wang, heyong/0000-0001-8668-5378
FU This research was supported by the Fundamental Research Funds for
   Guangdong Natural Science Foundation, Grant No. 2022A1515011848;
   Guangzhou Philosophy and Social Science, Grant No. 2020GZYB04; Guangdong
   Philosophy and Social Science, Grant No. GD22YYJ15. [2022A1515011848];
   Fundamental Research Funds for Guangdong Natural Science Foundation
   [2020GZYB04]; Guangzhou Philosophy and Social Science [GD22YYJ15];
   Guangdong Philosophy and Social Science
FX This research was supported by the Fundamental Research Funds for
   Guangdong Natural Science Foundation, Grant No. 2022A1515011848;
   Guangzhou Philosophy and Social Science, Grant No. 2020GZYB04; Guangdong
   Philosophy and Social Science, Grant No. GD22YYJ15.
CR Abdi A, 2019, INFORM PROCESS MANAG, V56, P1245, DOI 10.1016/j.ipm.2019.02.018
   Abdullah M, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P835, DOI 10.1109/ICMLA.2018.00134
   Adel A, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122111296
   Agnihotri D, 2019, APPL INTELL, V49, P1597, DOI 10.1007/s10489-018-1349-1
   Agnihotri D, 2017, EXPERT SYST APPL, V81, P268, DOI 10.1016/j.eswa.2017.03.057
   Al-Dyani WZ, 2022, IEEE ACCESS, V10, P85655, DOI 10.1109/ACCESS.2022.3198654
   Ali F, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020234
   [Anonymous], 2004, P INT C INF KNOWL MA, DOI DOI 10.1145/1031171.1031241
   Asim M, 2021, INT J MACH LEARN CYB, V12, P2461, DOI 10.1007/s13042-021-01324-6
   Azam N, 2012, EXPERT SYST APPL, V39, P4760, DOI 10.1016/j.eswa.2011.09.160
   Balderas D, 2019, EXPERT SYST APPL, V122, P152, DOI 10.1016/j.eswa.2018.12.055
   Bharti KK, 2016, APPL SOFT COMPUT, V43, P20, DOI 10.1016/j.asoc.2016.01.019
   Bharti KK, 2015, EXPERT SYST APPL, V42, P3105, DOI 10.1016/j.eswa.2014.11.038
   Breuel TM, 2017, PROC INT CONF DOC, P11, DOI 10.1109/ICDAR.2017.12
   Brunello A, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12375
   Cekik R, 2020, EXPERT SYST APPL, V160, DOI 10.1016/j.eswa.2020.113691
   Chen ZP, 2019, IEEE T INF FOREN SEC, V14, P2454, DOI 10.1109/TIFS.2019.2901826
   Cheng CH, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217591
   Ciarelli P. M., 2010, Proceedings of the 2010 Eleventh Brazilian Symposium on Neural Networks (SBRN 2010), P182, DOI 10.1109/SBRN.2010.39
   Ciarelli PM, 2009, INT CONF INTELL SYST, P547, DOI 10.1109/ISDA.2009.9
   Cui QS, 2019, IEEE T POWER DELIVER, V34, P1203, DOI 10.1109/TPWRD.2019.2901634
   Deng XL, 2019, MULTIMED TOOLS APPL, V78, P3797, DOI 10.1007/s11042-018-6083-5
   El-Hajj W, 2022, COMPUT SPEECH LANG, V74, DOI 10.1016/j.csl.2022.101364
   Erenel Z, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155351
   Farghaly HM, 2023, SOFT COMPUT, V27, P11259, DOI 10.1007/s00500-023-08587-x
   Feng GZ, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174341
   Feng GZ, 2015, PATTERN RECOGN LETT, V65, P109, DOI 10.1016/j.patrec.2015.07.028
   Fernandes M, 2019, INT J INFORM MANAGE, V46, P252, DOI 10.1016/j.ijinfomgt.2018.10.006
   Fu GH, 2023, PATTERN RECOGN LETT, V168, P47, DOI 10.1016/j.patrec.2023.02.027
   Ganesan K, 2012, INFORM RETRIEVAL, V15, P116, DOI 10.1007/s10791-011-9174-8
   Gao Z, 2014, 2014 4TH INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, VEHICULAR TECHNOLOGY, INFORMATION THEORY AND AEROSPACE & ELECTRONIC SYSTEMS (VITAE)
   Garg M, 2022, EXPERT SYST APPL, V195, DOI 10.1016/j.eswa.2022.116563
   Ghareb AS, 2016, EXPERT SYST APPL, V49, P31, DOI 10.1016/j.eswa.2015.12.004
   Guo YB, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2940-0
   Heyong W, 2019, INFORM PROCESS MANAG, V56, P167, DOI 10.1016/j.ipm.2018.09.004
   Hosseinalipour A, 2021, APPL INTELL, V51, P4824, DOI 10.1007/s10489-020-02038-y
   Hu Q, 2019, INT J APPL EARTH OBS, V80, P218, DOI 10.1016/j.jag.2019.04.014
   Jang B, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10175841
   Javed K, 2015, NEUROCOMPUTING, V157, P91, DOI 10.1016/j.neucom.2015.01.031
   Jiang JW, 2021, IEEE ACCESS, V9, P123660, DOI 10.1109/ACCESS.2021.3110143
   Jin CX, 2015, IETE J RES, V61, P351, DOI 10.1080/03772063.2015.1021385
   Jin LB, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103251
   Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200
   Karthiga R, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1351-0
   Kilinç D, 2017, J INF SCI, V43, P174, DOI 10.1177/0165551515620551
   Kotzias D, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P597, DOI 10.1145/2783258.2783380
   Kozodoi N, 2019, DECIS SUPPORT SYST, V120, P106, DOI 10.1016/j.dss.2019.03.011
   Kumar MRP, 2023, J INTELL MANUF, V34, P2123, DOI 10.1007/s10845-021-01866-0
   Kushwaha N, 2018, FUTURE GENER COMP SY, V82, P190, DOI 10.1016/j.future.2017.12.005
   Labani M, 2018, ENG APPL ARTIF INTEL, V70, P25, DOI 10.1016/j.engappai.2017.12.014
   Lamirel JC, 2015, J INTELL INF SYST, V45, P379, DOI 10.1007/s10844-014-0317-4
   Leclercq M, 2019, FRONT GENET, V10, DOI 10.3389/fgene.2019.00452
   Li BY, 2017, 2017 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P609, DOI 10.1109/SPAC.2017.8304349
   Li CB, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), P890, DOI 10.1109/ITME.2018.00199
   Li LF, 2019, TEH VJESN, V26, P778, DOI 10.17559/TV-20190420161815
   Li Q, 2019, KNOWL-BASED SYST, V176, P122, DOI 10.1016/j.knosys.2019.03.025
   Lim CG, 2018, INT CONF BIG DATA, P666, DOI 10.1109/BigComp.2018.00121
   Lim H, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22040395
   Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078
   Liu YH, 2019, INFORM PROCESS MANAG, V56, P1457, DOI 10.1016/j.ipm.2018.11.003
   Liu Y, 2019, EXPERT SYST APPL, V132, P99, DOI 10.1016/j.eswa.2019.04.038
   Lu YH, 2015, APPL SOFT COMPUT, V35, P629, DOI 10.1016/j.asoc.2015.07.005
   Manochandar S, 2018, COMPUT IND ENG, V124, P139, DOI 10.1016/j.cie.2018.07.008
   Marafino BJ, 2015, J BIOMED INFORM, V54, P114, DOI 10.1016/j.jbi.2015.02.003
   Maruf S, 2016, ARAB J SCI ENG, V41, P951, DOI 10.1007/s13369-015-1945-x
   Mustafa AM, 2018, J INF SCI, V44, P15, DOI 10.1177/0165551516683617
   Ni C, 2019, J SYST SOFTWARE, V152, P215, DOI 10.1016/j.jss.2019.03.012
   Nowak J, 2017, LECT NOTES ARTIF INT, V10246, P553, DOI 10.1007/978-3-319-59060-8_50
   Ong P, 2019, J BRAZ SOC MECH SCI, V41, DOI 10.1007/s40430-019-1768-x
   Parwez MA, 2019, IEEE ACCESS, V7, P68678, DOI 10.1109/ACCESS.2019.2919494
   Pinheiro RHW, 2015, EXPERT SYST APPL, V42, P1941, DOI 10.1016/j.eswa.2014.10.011
   Rashid Tarik A., 2017, Information Technology Journal, V16, P27, DOI 10.3923/itj.2017.27.34
   Rashid TA, 2018, LECT NOTE DATA ENG, V6, P187, DOI 10.1007/978-3-319-59463-7_19
   Rehman A, 2017, INFORM PROCESS MANAG, V53, P473, DOI 10.1016/j.ipm.2016.12.004
   Saeed MM, 2022, NEURAL COMPUT APPL, V34, P22519, DOI 10.1007/s00521-022-07669-5
   Sahu SK, 2018, J BIOMED INFORM, V86, P15, DOI 10.1016/j.jbi.2018.08.005
   Sasankan N, 2019, MED PHYS, V46, pE336
   Shang WQ, 2007, EXPERT SYST APPL, V33, P1, DOI 10.1016/j.eswa.2006.04.001
   She XY, 2018, INT SYM COMPUT INTEL, P185, DOI 10.1109/ISCID.2018.10144
   Shi SM, 2017, INT CONF ASIAN LANG, P379, DOI 10.1109/IALP.2017.8300622
   Shih CH, 2017, ASIAPAC SIGN INFO PR, P641, DOI 10.1109/APSIPA.2017.8282104
   Shu B, 2018, I C INTELL COMPUT TE, P31, DOI 10.1109/ICICTA.2018.00015
   Singh G, 2023, CONNECT SCI, V35, DOI 10.1080/09540091.2023.2231171
   Song SL, 2019, MULTIMED TOOLS APPL, V78, P857, DOI 10.1007/s11042-018-5749-3
   Sprugnoli R, 2019, COMPUT LINGUIST, V45, P229, DOI [10.1162/coli_a_00347, 10.1162/COLIa00347]
   Su MH, 2018, 2018 FIRST ASIAN CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION (ACII ASIA)
   Sun CJ, 2017, LECT NOTES ARTIF INT, V10363, P448, DOI 10.1007/978-3-319-63315-2_39
   Tan A.-H., 1999, P PAKDD 1999 WORKSH, V8, P65
   Tang B, 2016, IEEE T KNOWL DATA EN, V28, P2508, DOI 10.1109/TKDE.2016.2563436
   Tang XC, 2019, EXPERT SYST APPL, V120, P207, DOI 10.1016/j.eswa.2018.11.018
   Thirumoorthy K, 2021, PATTERN RECOGN LETT, V147, P63, DOI 10.1016/j.patrec.2021.03.034
   Tomer M, 2020, ARAB J SCI ENG, V45, P10743, DOI 10.1007/s13369-020-04827-6
   Tommasel A, 2018, ARTIF INTELL REV, V49, P301, DOI 10.1007/s10462-016-9528-0
   Tutkan M, 2016, INFORM PROCESS MANAG, V52, P885, DOI 10.1016/j.ipm.2016.03.007
   Uguz H, 2011, KNOWL-BASED SYST, V24, P1024, DOI 10.1016/j.knosys.2011.04.014
   Uysal AK, 2018, IEEE ACCESS, V6, P43233, DOI 10.1109/ACCESS.2018.2863547
   Uysal AK, 2016, EXPERT SYST APPL, V43, P82, DOI 10.1016/j.eswa.2015.08.050
   VeeraSekharReddy B, 2023, WIRELESS PERS COMMUN, V130, P1435, DOI 10.1007/s11277-023-10339-x
   Wan C, 2019, IEEE ACCESS, V7, P35208, DOI 10.1109/ACCESS.2019.2904602
   Wang H., 2015, Mathematical Problems in Engineering, V2015
   Wang HT, 2022, CONNECT SCI, V34, P2466, DOI 10.1080/09540091.2022.2128047
   Wang J, 2017, 2017 17TH IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT 2017), P1891, DOI 10.1109/ICCT.2017.8359958
   Wang SX, 2019, INT J ELEC POWER, V109, P470, DOI 10.1016/j.ijepes.2019.02.022
   Wang W, 2019, APPL ENERG, V248, P217, DOI 10.1016/j.apenergy.2019.04.085
   Wang YW, 2018, FRONT INFORM TECH EL, V19, P221, DOI 10.1631/FITEE.1601761
   Witten IH, 2011, MOR KAUF D, P1
   Wu JL, 2020, IEEE ACCESS, V8, P66638, DOI 10.1109/ACCESS.2020.2985228
   Wu X, 2023, KNOWL-BASED SYST, V274, DOI 10.1016/j.knosys.2023.110635
   Xiao LZ, 2018, INT SYM COMPUT INTEL, P71, DOI 10.1109/ISCID.2018.00023
   Xu F, 2018, PROCEEDINGS OF 2018 TENTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P467, DOI 10.1109/ICACI.2018.8377504
   Xu H, 2022, COMPLEXITY, V2022, DOI 10.1155/2022/1845571
   Yao L, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0781-4
   Yao WX, 2017, P 12 KIPS INT C UB I, V474, P511
   Yin ZY., 2023, Appl Sci-Basel, V13, P1
   Zhai ZL, 2023, MULTIMED TOOLS APPL, V82, P20975, DOI 10.1007/s11042-023-14450-w
   Zhang BZ, 2019, NEUROCOMPUTING, V357, P86, DOI 10.1016/j.neucom.2019.05.013
   Zhang JR, 2018, PROCEEDINGS OF 2018 IEEE 3RD ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC 2018), P1675, DOI 10.1109/IAEAC.2018.8577620
   Zhang S, 2019, INT J COMPUT COMMUN, V14, P124, DOI 10.15837/ijccc.2019.1.3420
   Zhang ZD, 2019, APPL ENERG, V247, P270, DOI 10.1016/j.apenergy.2019.04.047
   Zheng Z., 2004, ACM Sigkdd Explorations Newsletter, V6, P80, DOI DOI 10.1145/1007730.1007741
   Zong W, 2015, INT J PROD ECON, V165, P215, DOI 10.1016/j.ijpe.2014.12.035
NR 121
TC 0
Z9 0
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 18
PY 2023
DI 10.1007/s11042-023-16990-7
EA OCT 2023
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6VJ6
UT WOS:001086159600001
DA 2024-07-18
ER

PT J
AU Soni, N
   Saini, I
   Singh, B
AF Soni, Neetika
   Saini, Indu
   Singh, Butta
TI Quality controlled 2D ECG compression using adaptive fourier
   decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Adaptive Fourier Decomposition (AFD); Takenaka-Malmaquist (TM)
   functions; Adaptive Bit Length Encoding (ABLE); Compression Ratio (CR);
   Weighted Wavelet PRD (WWPRD); Clinically significant distortion
ID SINGULAR-VALUE DECOMPOSITION; SIGNAL COMPRESSION; ALGORITHM; TRANSFORM
AB This work presents the recently developed Adaptive Fourier Decomposition (AFD) approach-based ECG compression technique that ensures considerable data reduction at guaranteed reconstructed signal quality. Unlike existing decomposition techniques with fixed Basis functions, AFD selects distinct Basis function in accordance with the input signal resulting in fast energy convergence with good signal fidelity. However, the complex nature of AFD coefficients and Basis functions restrain the compression efficiency. In the proposed technique AFD algorithm is modified to obtain integer valued Basis functions causing considerable improvements in the Compression Ratio (CR) and reconstructed signal quality. Additionally, the complex-valued AFD coefficients are encoded with the lossless Adaptive Bit Length Encoding (ABLE) approach which further modify the compression efficiency. The comprehensive experimentation of the proposed technique was done on various standard and self-recorded databases on varying values of decomposition levels (N) and window size (W). The proficiency of the technique was further analysed by computing optimum N in accordance with the pre-defined distortion to achieve maximum CR. Average Percentage Root Mean Square difference (PRD%), Weighted Wavelet PRD (WWPRD), Wavelet Energy based Diagnostic Distortion (WEDD), Peak Signal to noise Ratio (PSNR), CR and Quality Score (QS) obtained are 0.68, 18.24, 6.86, 47.19, 22.11 and 37.24 respectively when measured on 48 records of MIT-BIH arrhythmia database of 5 min duration at N = 50 and W = 2000. The experimental results demonstrated the competency of the proposed technique with excellent CR at negligible reconstruction error as compared to the other state of the art techniques.
C1 [Soni, Neetika; Saini, Indu] Dr B R Ambedkar Natl Inst Technol, Elect & Commun Engn Dept, Jalandhar 144011, India.
   [Soni, Neetika; Singh, Butta] Guru Nanak Dev Univ, Elect & Commun Engn Dept, Reg Campus, Jalandhar 144007, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar; Guru Nanak Dev University
RP Singh, B (corresponding author), Guru Nanak Dev Univ, Elect & Commun Engn Dept, Reg Campus, Jalandhar 144007, India.
EM bsl.khanna@gmail.com
RI Saini, Indu/GNP-7112-2022
OI Singh, Butta/0000-0002-0170-6270
CR Abo-Zahhad MM., 2014, Int J Commun Netw Syst Sci, V07, P53, DOI [10.4236/ijcns.2014.71007, DOI 10.4236/IJCNS.2014.71007]
   Akhter S, 2010, EUR SIGNAL PR CONF, P1645
   Al-Fahoum AS, 2006, IEEE T INF TECHNOL B, V10, P182, DOI 10.1109/TITB.2005.855554
   Benzid R, 2008, DIGIT SIGNAL PROCESS, V18, P56, DOI 10.1016/j.dsp.2007.08.003
   Chandra S, 2020, IRBM, V41, P2, DOI 10.1016/j.irbm.2019.06.002
   Fathi A, 2016, SIGNAL IMAGE VIDEO P, V10, P1433, DOI 10.1007/s11760-016-0944-z
   Feli M, 2019, BIOMED SIGNAL PROCES, V54, DOI 10.1016/j.bspc.2019.101596
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Hameed ME, 2020, FUTURE GENER COMP SY, V111, P829, DOI 10.1016/j.future.2019.10.010
   Hou H. S., 1992, Journal of Visual Communication and Image Representation, V3, P73, DOI 10.1016/1047-3203(92)90031-N
   Hsieh JH, 2018, INTEGRATION, V60, P248, DOI 10.1016/j.vlsi.2017.10.006
   Jha CK, 2018, BIOMED SIGNAL PROCES, V46, P174, DOI 10.1016/j.bspc.2018.06.009
   Kim H, 2010, IEEE T INF TECHNOL B, V14, P93, DOI 10.1109/TITB.2009.2031638
   Ku CT, 2010, IEEE T BIO-MED ENG, V57, P1399, DOI 10.1109/TBME.2009.2037605
   Kumar R, 2016, COMPUT METH PROG BIO, V129, P135, DOI 10.1016/j.cmpb.2016.01.006
   Kumar R, 2015, AEU-INT J ELECTRON C, V69, P80, DOI 10.1016/j.aeue.2015.09.011
   Kumar R, 2013, COMPUT ELECTR ENG, V39, P130, DOI 10.1016/j.compeleceng.2012.04.008
   Lee S, 2011, IEEE T BIO-MED ENG, V58, P2448, DOI 10.1109/TBME.2011.2156794
   Ma JL, 2015, IEEE J BIOMED HEALTH, V19, P986, DOI 10.1109/JBHI.2014.2357841
   Manikandan AS, 2007, BIOMED SIGNAL PROCES, V2, P80, DOI 10.1016/j.bspc.2007.05.001
   Manikandan MS, 2014, BIOMED SIGNAL PROCES, V14, P73, DOI 10.1016/j.bspc.2014.07.002
   Mukhopadhyay SK, 2018, BIOMED SIGNAL PROCES, V44, P288, DOI 10.1016/j.bspc.2018.05.005
   Mullen JA, 1966, IEEE Trans Inf Theory, P6
   Pandey A, 2020, MEASUREMENT, V152, DOI 10.1016/j.measurement.2019.107252
   Pandey A, 2019, MULTIMED TOOLS APPL, V78, P11223, DOI 10.1007/s11042-018-6681-2
   Pandey A, 2016, AUSTRALAS PHYS ENG S, V39, P833, DOI 10.1007/s13246-016-0476-4
   Pandey A, 2016, COMPUT ELECTR ENG, V56, P30, DOI 10.1016/j.compeleceng.2016.10.012
   Peric Z, 2013, J COMMUN TECHNOL EL+, V58, P1241, DOI 10.1134/S1064226913130068
   Qian T, 2013, NONLINEAR ANAL-REAL, V14, P1055, DOI 10.1016/j.nonrwa.2012.08.017
   Qian T, 2011, IEEE T SIGNAL PROCES, V59, P5899, DOI 10.1109/TSP.2011.2168520
   Raeiatibanadkooki M, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0433-5
   Sayood K, 2018, Introduction to data compression, P187
   Soni N, 2021, IET SIGNAL PROCESS, V15, P337, DOI 10.1049/sil2.12031
   Tai SC, 2005, IEEE T BIO-MED ENG, V52, P999, DOI 10.1109/TBME.2005.846727
   Tan CY, 2019, IEEE J BIOMED HEALTH, V23, P672, DOI 10.1109/JBHI.2018.2817192
NR 35
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 17
PY 2023
DI 10.1007/s11042-023-17318-1
EA OCT 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U5AL0
UT WOS:001084922000016
DA 2024-07-18
ER

PT J
AU Kumar, V
   Gupta, AK
   Garg, RR
   Kumar, N
   Kumar, R
AF Kumar, Vipin
   Gupta, Amit Kumar
   Garg, Ruchi Rani
   Kumar, Nikhil
   Kumar, Rajeev
TI The ultimate recommendation system: proposed Pranik System
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Recommendation engine; Machine learning; Deep learning; Natural language
   processing; Entertainment; Movies
AB In today's fast-paced world, recommendation systems have become indispensable tools, aiding users in making personalized decisions amidst an overwhelming array of choices. These systems leverage user data and preferences to generate tailor-made recommendations based on individual tastes and behaviors. This research paper introduces the development and implementation of Pranik Movies, an ultimate recommendation system for personalized movie suggestions. The system incorporates collaborative and content-based filtering techniques, utilizing machine learning algorithms to analyze user behaviors, ratings, and viewing histories. A comprehensive overview of the research framework is provided, encompassing system architecture, data pre-processing, feature engineering techniques, and model selection and design. Text processing methods such as stemming, bag-of-words (BoW), and TF-IDF (Term Frequency-Inverse Document Frequency) are employed for processing and analyzing textual movie data. The accuracy of recommendations is enhanced through the assessment of film similarities, utilizing algorithms like cosine similarity and Euclidean distance. The paper concludes by outlining future directions for advanced machine learning techniques, social media integration, expanded content support, and the refinement of the evaluation framework. Pranik Movies signifies a significant advancement in recommendation systems, enabling personalized and precise movie recommendations within a vast and diverse cinematic landscape.
C1 [Kumar, Vipin; Gupta, Amit Kumar; Kumar, Nikhil; Kumar, Rajeev] KIET Grp Inst, Ghaziabad, India.
   [Garg, Ruchi Rani] Meerut Inst Engn & Technol, Meerut, India.
C3 KIET Group of Institutions; Meerut Institute of Engineering & Technology
RP Kumar, R (corresponding author), KIET Grp Inst, Ghaziabad, India.
EM rajeev.rakshit@gmail.com
RI GUPTA, AMIT KUMAR/M-6482-2017; KUMAR, RAJEEV/AAO-5752-2020; KUMAR, Dr.
   VIPIN/M-6566-2017
OI KUMAR, RAJEEV/0000-0003-3705-2667; KUMAR, Dr. VIPIN/0000-0002-1056-8770
CR Adate A, 2019, DE GR FRONT COMPU IN, V1, P69, DOI 10.1515/9783110551433-003
   Aggarwal K., 2022, IRAQI J COMPUT SCI M, V3, P115, DOI [DOI 10.52866/IJCSM.2022.01.01.013, 10.52866/ijcsm.2022.01.01.013]
   Alfakih AY., 2018, EUCLIDEAN DISTANCE M, DOI [10.1007/978-3-319-97846-8_3, DOI 10.1007/978-3-319-97846-8_3]
   Alodadi M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI 2015), P521, DOI 10.1109/ICHI.2015.99
   Besancon R., 1999, Proceedings. Tenth International Workshop on Database and Expert Systems Applications. DEXA 99, P180, DOI 10.1109/DEXA.1999.795163
   Camizuli E., 2018, The Encyclopedia of Archaeological Sciences, P1, DOI [10.1002/9781119188230.saseas0271, DOI 10.1002/9781119188230.SASEAS0271]
   Chen B, 2022, SpringerBriefs in Computer Science, P5, DOI [10.1007/978-981-19-7369-7_2, DOI 10.1007/978-981-19-7369-7_2]
   Chiny M, 2021, BML 21 2 INT C BIG D, DOI DOI 10.5220/0010727500003101
   Christian H., 2016, COMTECH COMPUT MATH, V7, P285, DOI DOI 10.21512/COMTECH.V7I4.3746
   Dr PN., 2020, J Adv Res Dynamic Control Syst, V12, P141, DOI [10.5373/jardcs/v12sp4/20201475, DOI 10.5373/JARDCS/V12SP4/20201475]
   Gallavotti G, 2004, Aspects of Ergodic, Qualitative and Statistical Theory of Motion, P1, DOI [10.1007/978-3-662-05853-4_1, DOI 10.1007/978-3-662-05853-4_1]
   Hancock J M., 2004, Dictionary of Bioinformatics and Computational Biology, DOI [DOI 10.1002/9780471650126.DOB0956, 10.1002/9780471650126.dob0956]
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Iwahama K, 2004, 2004 INTERNATIONAL SYMPOSIUM ON APPLICATIONS AND THE INTERNET WORKSHOPS, PROCEEDINGS, P480, DOI 10.1109/SAINTW.2004.1268677
   Jiang LL, 2019, J AMB INTEL HUM COMP, V10, P3023, DOI 10.1007/s12652-018-0928-7
   Kapoor N., 2020, 2020 5 INT C COMM EL, P883, DOI [DOI 10.1109/ICCES48766.2020.9137993, 10.1109/icces48766.2020.9137993]
   Kryszkiewicz Marzena, 2014, Encyclopedia of Business Analytics and Optimization, P2498
   Lohmann S, 2015, IEEE INT CONF INF VI, P114, DOI 10.1109/iV.2015.30
   Pan XH, 2012, INT C MULTIMED INFO, P425, DOI 10.1109/MINES.2012.249
   Passalis N, 2018, PATTERN RECOGN, V81, P254, DOI 10.1016/j.patcog.2018.04.008
   Prajna KB., 2022, 2022 IEEE 2 MYS SUBS, DOI [10.1109/mysurucon55714.2022.9972580, DOI 10.1109/MYSURUCON55714.2022.9972580]
   Rendle Steffen, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P995, DOI 10.1109/ICDM.2010.127
   Sharma P, 2020, Int J Innov Res Comput Sci Technol, V8, DOI [10.21276/ijircst.2020.8.4.2, DOI 10.21276/IJIRCST.2020.8.4.2]
   Siswandi A. Arif, 2021, Journal of Physics: Conference Series, V1845, DOI 10.1088/1742-6596/1845/1/012019
   Tintarev N, 2007, I C DATA ENGIN WORKS, P801, DOI 10.1109/ICDEW.2007.4401070
   Wang H, 2017, 2017 IEEE 21 INT C C, DOI [10.1109/cscwd.2017.8066717, DOI 10.1109/CSCWD.2017.8066717]
   Wenzel T, 2022, P 6 INT C COMP HUM I, DOI [10.5220/0011528400003323, DOI 10.5220/0011528400003323]
   Zhang H, 2021, ISPRS INT J GEO-INF, V10, DOI 10.3390/ijgi10010036
NR 28
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17370-x
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU6A2
UT WOS:001155212900002
DA 2024-07-18
ER

PT J
AU Sheibani, S
   Shakeri, H
   Sheibani, R
AF Sheibani, Samaneh
   Shakeri, Hassan
   Sheibani, Reza
TI Applying multi-factor Beta distribution-based trust for improving
   accuracy of recommender systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Recommender systems; Trust; Beta distribution; Clustering; Context-aware
   recommendation
ID SOCIAL NETWORKS; LOCATION; PROPAGATION; DYNAMICS; POINT
AB Calculation and applying trust among users have become popular in designing recommender systems in recent years. Considering multiple factors for estimating the value of trust can improve the accuracy of trust-based recommender systems. In this paper, a multi-factor approach for estimating trust among users of recommender systems is introduced. In the proposed scheme, first, users of the system are clustered based on their similarities in demographic information and history of ratings. To predict the rating of the active user into a specific item, the value of trust between him and the other users in his cluster is calculated considering three factors i.e., time, location, and context of their ratings. To this end, we propose an algorithm based on the beta distribution. A novel tree-based measure for computing the semantic similarity between the contexts is utilized. Finally, the rating of the active user is predicted using weighted averaging where trust values are considered as weights. The proposed scheme was performed on three datasets, and the obtained results indicated that it outperforms existing methods in terms of accuracy and other efficiency metrics.
C1 [Sheibani, Samaneh; Shakeri, Hassan; Sheibani, Reza] Islamic Azad Univ, Dept Comp Engn, Mashhad Branch, Mashhad, Iran.
C3 Islamic Azad University
RP Shakeri, H (corresponding author), Islamic Azad Univ, Dept Comp Engn, Mashhad Branch, Mashhad, Iran.
EM s.sheibani@mshdiau.ac.ir; shakeri@mshdiau.ac.ir;
   sheibani1063@mshdiau.ac.ir
CR Adomavicius G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P217, DOI 10.1007/978-0-387-85820-3_7
   Agrawal S, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102690
   AlBanna B, 2016, ISPRS INT J GEO-INF, V5, DOI 10.3390/ijgi5120245
   Alhijawi B, 2023, MULTIMED TOOLS APPL, V82, P32421, DOI 10.1007/s11042-023-14728-z
   Antolic G, 2017, 2017 40 INT CONV INF
   Ardissono L, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112880
   Asani E, 2021, MACH LEARN APPL, V6, DOI 10.1016/j.mlwa.2021.100114
   Baczkiewicz A, 2021, J THEOR APPL EL COMM, V16, P2192, DOI 10.3390/jtaer16060122
   Cardoso IMG, 2022, IET SOFTW, V16, P111, DOI 10.1049/sfw2.12034
   Cho E., 2011, P 17 ACM SIGKDD INT, P1082, DOI DOI 10.1145/2020408.2020579
   El Yebdri Z, 2021, COMPUTING, V103, P1919, DOI 10.1007/s00607-020-00876-9
   Elahi M., 2018, COLLABORATIVE RECOMM, P253, DOI DOI 10.1142/9789813275355_0008
   Fang WD, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-016-9028-0
   Fard KB, 2013, Int J Electr Comput, VEng3, P751
   Friedkin N. E., 2011, Social Influence Network Theory: A Sociological Examination of Small Group Dynamics, V33
   Gao HJ, 2015, AAAI CONF ARTIF INTE, P1721
   Ghavipour M, 2018, COMPUT COMMUN, V123, P11, DOI 10.1016/j.comcom.2018.04.004
   Han P, 2022, IEEE T KNOWL DATA EN, V34, P5484, DOI 10.1109/TKDE.2021.3059744
   Celdrán AH, 2016, J COMPUT SCI-NETH, V12, P83, DOI 10.1016/j.jocs.2015.11.010
   Jianfei Li, 2020, 2020 Proceedings of Asia-Pacific Conference on Image Processing, Electronics and Computers (IPEC), P129, DOI 10.1109/IPEC49694.2020.9115132
   Kefalas P, 2017, EXPERT SYST APPL, V78, P396, DOI 10.1016/j.eswa.2017.01.060
   Khazaei E, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7020067
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Lathia N, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P210
   Li YM, 2013, DECIS SUPPORT SYST, V55, P740, DOI 10.1016/j.dss.2013.02.009
   Liu YD, 2017, PROC VLDB ENDOW, V10, P1010, DOI 10.14778/3115404.3115407
   Milias V, 2021, COMPUT ENVIRON URBAN, V86, DOI 10.1016/j.compenvurbsys.2021.101597
   Moe ME, 2009, IFIP INT C TRUST MAN
   Nilashi M, 2018, EXPERT SYST APPL, V92, P507, DOI 10.1016/j.eswa.2017.09.058
   Nobahari V, 2019, J INTELL INF SYST, V52, P239, DOI 10.1007/s10844-018-0513-8
   Rafailidis D, 2016, IEEE T SYST MAN CY-S, V46, P782, DOI 10.1109/TSMC.2015.2460691
   Remu SR, 2020, P INT C COMP ADV ASS, P1
   Richa, 2021, APPL ARTIF INTELL, V35, P326, DOI 10.1080/08839514.2021.1881297
   Richa, 2020, J INTELL FUZZY SYST, V38, P6235, DOI 10.3233/JIFS-179705
   Roy F, 2020, A comparative analysis of different trust metrics in user-user trust-based recommender system, DOI [10.20944/preprints202011.0466, DOI 10.20944/PREPRINTS202011.0466]
   Rrmoku K, 2022, COMPUTATION, V10, DOI 10.3390/computation10010006
   Rubens N, 2011, RECOMMENDER SYSTEMS HANDBOOK, P735, DOI 10.1007/978-0-387-85820-3_23
   Saiph Savage N., 2012, Advances in Location-Based Services, P37, DOI DOI 10.1007/978-3-642-24198-7_3
   Sani NS, 2017, INT J ADV COMPUT SC, V8, P152
   Seo YD, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.114018
   Tahmasbi H, 2018, 2018 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P194, DOI 10.1109/ICCKE.2018.8566316
   Ureña R, 2019, INFORM SCIENCES, V478, P461, DOI 10.1016/j.ins.2018.11.037
   Wangwatcharakul C, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115626
   Wu XL, 2019, IEEE ACCESS, V7, P43679, DOI 10.1109/ACCESS.2019.2905550
   WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P133
   Xiong L., 2010, P 2010 SIAM INT C DA, P211, DOI DOI 10.1137/1.9781611972801.19
   Xue H, 2019, ACM J DATA INF QUAL, V11, DOI 10.1145/3305258
   Yao L., 2019, DATA SCI DIGITAL BUS, P65, DOI DOI 10.1007/978-3-319-95651-0_5
   Yelp Inc, 2018, YELP CHALL DAT
   Yengikand AK, 2023, MULTIMED TOOLS APPL, V82, P34513, DOI 10.1007/s11042-023-15021-9
   Ying HC, 2019, WORLD WIDE WEB, V22, P2209, DOI 10.1007/s11280-018-0596-8
   Yuan W, 2006, HIGH PERFORMANCE COM, V2
   Zheng XL, 2015, IEEE T LEARN TECHNOL, V8, P345, DOI 10.1109/TLT.2015.2419262
NR 53
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 12
PY 2023
DI 10.1007/s11042-023-17265-x
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU6C6
UT WOS:001155215300003
DA 2024-07-18
ER

PT J
AU Kaur, S
   Chopra, S
   Nayyar, A
   Sharma, R
   Singh, G
AF Kaur, Simranjot
   Chopra, Sumit
   Nayyar, Anchal
   Sharma, Rajesh
   Singh, Gagandeep
TI A sequential convolutional neural network for image forgery detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Image forgery detection; Image manipulation detection;
   Copy-move forgery detection
AB In this digital era, images are the major information carriers of contemporary society. Several multimedia manipulation tools like CorelDRAW, GIMP, Freehand, Adobe Photoshop, etc. are being used to forge the visual media for malicious reasons. It is becoming increasingly difficult to distinguish forged images from pristine images as a result of new manipulation techniques that have emerged over the past time. The most intriguing area of multimedia forensics research is image forgery detection. In the field of forensic image analysis, the most important task is to verify the authenticity of digital media. A novel passive approach for detecting digital image forgery is proffered in this manuscript. It is a sequential framework that uses a deep convolutional neural network to differentiate between original and altered images. On the COVERAGE dataset, numerous experiments have been evaluated in order to construct an effective and robust model, achieveing AUC value of 0.85 and F-measure of 0.70. The comparative results have been represented in summarized form and the results perform better than the state-of-the-art techniques.
C1 [Kaur, Simranjot; Chopra, Sumit; Nayyar, Anchal; Sharma, Rajesh; Singh, Gagandeep] GNA Univ, Phagwara, Punjab, India.
RP Kaur, S (corresponding author), GNA Univ, Phagwara, Punjab, India.
EM simranjot.kaur@gnauniversity.edu.in; sumit.chopra@gnauniversity.edu.in;
   anchal.nayyar@gnauniversity.edu.in; rajesh.sharma@gnauniversity.edu.in;
   gagandeep.singh@gnauniversity.edu.in
CR Abd Warif NB, 2016, J NETW COMPUT APPL, V75, P259, DOI 10.1016/j.jnca.2016.09.008
   Abdalla Y, 2019, INFORMATION, V10, DOI 10.3390/info10090286
   Agarwal R, 2020, MULTIMED TOOLS APPL, V79, P7355, DOI 10.1007/s11042-019-08495-z
   Al Azrak FM, 2020, Multimedia Tools Appl, V79, p18 221
   Ali SS, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11030403
   Babu SBGT, 2023, MULTIMED TOOLS APPL, V82, P10061, DOI 10.1007/s11042-022-12311-6
   Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Bappy JH, 2017, IEEE I CONF COMP VIS, P4980, DOI 10.1109/ICCV.2017.532
   Bharti CN, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P877, DOI 10.1109/WiSPNET.2016.7566257
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Bourouis S, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12111811
   Elaskily MA, 2020, MULTIMED TOOLS APPL, V79, P19167, DOI 10.1007/s11042-020-08751-7
   Elaskily MA, 2017, 2017 INTL CONF ON ADVANCED CONTROL CIRCUITS SYSTEMS (ACCS) SYSTEMS & 2017 INTL CONF ON NEW PARADIGMS IN ELECTRONICS & INFORMATION TECHNOLOGY (PEIT), P193, DOI 10.1109/ACCS-PEIT.2017.8303041
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Fekri-Ershad S, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13040686
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Fridrich AJ, 2003, P DIG FOR RES WORKSH, V1, P403
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hu WC, 2016, MULTIMED TOOLS APPL, V75, P3495, DOI 10.1007/s11042-015-2449-0
   Kaur Simranjot, 2022, Advanced Machine Intelligence and Signal Processing. Lecture Notes in Electrical Engineering (858), P855, DOI 10.1007/978-981-19-0840-8_66
   Kaur S, 2022, INT J ELECTRON SECUR, V14, P456, DOI 10.1504/IJESDF.2022.125403
   Kumar S, 2023, MULTIMED TOOLS APPL, V82, P1431, DOI 10.1007/s11042-022-12391-4
   Mahdian B, 2009, IMAGE VISION COMPUT, V27, P1497, DOI 10.1016/j.imavis.2009.02.001
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Thakur R, 2020, FORENSIC SCI INT, V312, DOI 10.1016/j.forsciint.2020.110311
   Verdoliva L, 2020, IEEE J-STSP, V14, P910, DOI 10.1109/JSTSP.2020.3002101
   Wang X-Y, 2023, Multimedia Tools Appl, P1
   Wen BH, 2016, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2016.7532339
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhu Y, 2020, IEEE T IND INFORM, V16, P6714, DOI 10.1109/TII.2020.2982705
NR 30
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17028-8
EA OCT 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800024
DA 2024-07-18
ER

PT J
AU Kotwal, JG
   Kashyap, R
   Shafi, PM
AF Kotwal, Jameer Gulab
   Kashyap, Ramgopal
   Shafi, Pathan Mohd.
TI Artificial Driving based EfficientNet for Automatic Plant Leaf Disease
   Classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Plant leaf disease; Gaussian filtering; UNet-based segmentation; Gray
   level co-occurrence matrix; Artificial driving optimization; Disease
   classification
ID ALGORITHM
AB Plant disease (PD) detection is a substantial problem that needs to be tackled to develop the economy and improve agricultural production. Using conventional methods to classify plant leaf diseases consumes more time, undergoes vanishing gradients problems, overfitting issues, etc. However, automatic PD detection using deep learning (DL) has attained great significance in detecting PD during the early stages. Therefore, this paper proposes a hybrid strategy based on optimized automatic DL for plant leaf disease classification (PLDC). Initially, the proposed model performs pre-processing using image resizing and Gaussian filtering. Then, the disease infected region is then segmented using the UNet technique to acquire the relevant region and enhance disease classification accuracy. During segmentation, the weight of the UNet model has been tuned by employing the hunter-prey optimization (Hunt-PO) algorithm. Next, feature extraction is accomplished by means of a gray level co-occurrence matrix (GLCM), scale-invariant feature transform (SIFT) and a Gabor filter to extract the crucial features for classification. Further, based on the extracted features, PLDC is performed using artificial driving-EfficientNet (AD-ENet). The proposed PLDC model is implemented in the python platform through the PlantVillage dataset and assessed the performance in terms of different evaluation measures. Moreover, a proposed model's performance is compared with existing classifiers. The maximum classification accuracy obtained by the proposed PLDC model is 99.91%, superior to the existing classifiers for leaf disease classification.
C1 [Kotwal, Jameer Gulab] Amity Univ Chhattisgarh, Raipur 493225, India.
   [Kashyap, Ramgopal] Amity Univ Raipur, ASET, Raipur 493225, India.
   [Shafi, Pathan Mohd.] MIT ADT Univ, MITSOC, Pune 412201, India.
RP Kotwal, JG (corresponding author), Amity Univ Chhattisgarh, Raipur 493225, India.
EM jameerktwl@gmail.com
RI Kashyap, Ramgopal/O-5825-2014
OI Kashyap, Ramgopal/0000-0002-5352-1286; Pathan, Mohd
   Shafi/0000-0002-9148-7576
CR Agarwal M, 2023, 2023 IEEE INT STUD C, P1
   Ahmad A, 2022, CHEMOMETR INTELL LAB, V222, DOI 10.1016/j.chemolab.2022.104516
   Ahmed AA, 2021, AGRIENGINEERING, V3, P478, DOI 10.3390/agriengineering3030032
   Ahmed S, 2022, IEEE ACCESS, V10, P68868, DOI 10.1109/ACCESS.2022.3187203
   Akanksha E, 2021, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT 2021), P1322, DOI 10.1109/ICICT50816.2021.9358763
   Akbar S, 2023, IEEE Access
   Akbar S, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104778
   Albattah W, 2022, COMPLEX INTELL SYST, V8, P507, DOI 10.1007/s40747-021-00536-1
   Alsayed A, 2021, INT J COMPUT SCI NET, V21, P324, DOI 10.22937/IJCSNS.2021.21.7.37
   Anamisa DR, 2021, Commun Math Biol Neurosci
   Ansari AS, 2022, J FOOD QUALITY, V2022, DOI 10.1155/2022/9502475
   Ashok S, 2020, P 2020 5 INT C COMM, P979, DOI [DOI 10.1109/ICCES48766.2020.9137986, 10.1109/ICCES48766.2020.9137986]
   Ashwinkumar S, 2022, MATER TODAY-PROC, V51, P480, DOI 10.1016/j.matpr.2021.05.584
   Borhani Y, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-15163-0
   Chauhan MD., 2021, Turk. J. Comput. Math. Educ., V12, P715
   Dehghani M, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-14225-7
   Dhaka VS, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144749
   Dhakshayani J., 2023, SN Comput Sci, V4, P538, DOI [10.1007/s42979-023-01988-7, DOI 10.1007/S42979-023-01988-7]
   Geetha G., 2020, Journal of Physics: Conference Series, V1712, DOI 10.1088/1742-6596/1712/1/012012
   Islam MA, 2021, INT J ADV COMPUT SC, V12, P280
   Kaur Prabhjot, 2021, Proceedings of 3rd International Conference on Computing Informatics and Networks. ICCIN 2020. Lecture Notes in Networks and Systems (LNNS 167), P597, DOI 10.1007/978-981-15-9712-1_51
   Kaya Y, 2023, ECOL INFORM, V75, DOI 10.1016/j.ecoinf.2023.101998
   Khalifa N.E.M., 2021, Machine Learning and Big Data Analytics Paradigms: Analysis, Applications and Challenges, P63, DOI 10.1007/978-3-030-59338-4_4/COVER
   Khotimah BK., 2022, JURNAL INFOTEL, V14, P8, DOI [10.20895/infotel.v14i1.735, DOI 10.20895/INFOTEL.V14I1.735]
   Kumar VV, 2022, Journal of Mobile Multimedia, P325
   Kurmi Y, 2022, INFORM PROCESS AGR, V9, P456, DOI 10.1016/j.inpa.2021.03.001
   Li LL, 2021, IEEE ACCESS, V9, P56683, DOI 10.1109/ACCESS.2021.3069646
   Lu JZ, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11080707
   Luaibi A.R., 2021, International Journal of Electrical and Computer Engineering, V11, P1719, DOI [10.11591/ijece.v11i2.pp1719-1727, DOI 10.11591/IJECE.V11I2.PP1719-1727]
   Narayanan KL, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/9153699
   Naruei I, 2022, SOFT COMPUT, V26, P1279, DOI 10.1007/s00500-021-06401-0
   Panchal Adesh V., 2023, Materials Today: Proceedings, P3500, DOI 10.1016/j.matpr.2021.07.281
   Rajpoot V, 2023, MULTIMED TOOLS APPL, V82, P36091, DOI 10.1007/s11042-023-14969-y
   Reddy SRG, 2023, COMPUT ELECTR ENG, V105, DOI 10.1016/j.compeleceng.2022.108492
   Tanwar S, 2023, Multimed Tools Appl, P1
   Tiwari V, 2021, ECOL INFORM, V63, DOI 10.1016/j.ecoinf.2021.101289
   Upadhyay SK, 2021, Int J Inf Technol, P1
   Vishnoi VK, 2022, MULTIMED TOOLS APPL, V81, P367, DOI 10.1007/s11042-021-11375-0
   Wójtowicz A, 2021, J PHOTOCH PHOTOBIO B, V223, DOI 10.1016/j.jphotobiol.2021.112278
   Yin XX, 2022, J Healthc Eng
   Zhao WG, 2022, COMPUT METHOD APPL M, V388, DOI 10.1016/j.cma.2021.114194
NR 41
TC 1
Z9 1
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 4
PY 2023
DI 10.1007/s11042-023-16882-w
EA OCT 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T4GC2
UT WOS:001077578000001
DA 2024-07-18
ER

PT J
AU Johnson, SJ
   Murty, MR
   Navakanth, I
AF Johnson, S. Joshua
   Murty, M. Ramakrishna
   Navakanth, I.
TI A detailed review on word embedding techniques with emphasis on word2vec
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Word Embeddings; word2vec; Neural Networks; NLP
AB Text data has been growing drastically in the present day because of digitalization. The Internet, being flooded with millions of documents every day, makes the task of text processing by human beings relatively complex, which is neither adaptable nor successful. Many machine learning algorithms cannot interpret the raw text in its original format, as these algorithms purely need numbers as inputs to accomplish any task (say, classification, regression). A better way to represent text for computers, to understand and process text efficiently and effectively is needed. Word embedding is one such technique. Word embedding, or the encoding of words as vectors, has received much interest as a feature learning technique for natural language processing in recent times. This review presents a better way of understanding and working with word embeddings. Many researchers, who are non-experts in using different text processing techniques, would not know where to start their exploration due to a lack of comprehensive material. This review provides an overview of several word embedding strategies and the entire working procedure of word2vec,both in theory and mathematical perspectives which provides researchers with detailed information so that they may rapidly get to work on their research. Research results of standard word embedding techniques have also been included to better understand how word embedding have been improved from the past years to most recent findings.
C1 [Johnson, S. Joshua; Murty, M. Ramakrishna] Anil Neerukonda Inst Technol & Sci, CSE, Visakhapatnam, India.
   [Navakanth, I.] Maturi Venkata Subba Rao MVSR Engn Coll, CSE, Hyderabad, India.
C3 Maturi Venkata Subba Rao Engineering College
RP Johnson, SJ (corresponding author), Anil Neerukonda Inst Technol & Sci, CSE, Visakhapatnam, India.
CR [Anonymous], About us
   [Anonymous], Using Latent Semantic Indexing to Filter Spam Kevin R. Gee Dept. of Computer Science and Engineering
   [Anonymous], 2014, P 2014 C EMPIRICAL M, DOI DOI 10.3115/V1/D14-1110
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   DILLON M, 1983, INFORM PROCESS MANAG, V19, P402, DOI 10.1016/0306-4573(83)90062-6
   GOLUB GH, 1970, NUMER MATH, V14, P403, DOI 10.1007/BF02163027
   Hillebrand L, 2021, MACH LEARN KNOW EXTR, V3, P123, DOI 10.3390/make3010007
   Hofmann T, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P289
   Huang E. H, 2012, ANN M ASS COMP LING, P873
   Lebret R., 2014, EACL-2014, P482, DOI [DOI 10.3115/V1/E14-1051, 10.3115/v1/e14-1051]
   Levy O, 2014, ADV NEUR IN, V27
   Li J, 2015, C P EMNLP 2015 C EMP
   Maas Andrew, 2011, P 49 ANN M ASS COMP
   Mcdonald Scott, 2008, Testing the distributional hypothesis: The influence of context on judgements of semantic similarity
   medicalfuturist, About us
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Mikolov T., 2013, P 2013 C N AM CHAPT
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Neelakantan A, 2014, P 2014 C EMPIRICAL M, V2014, P1059, DOI [DOI 10.3115/V1/D14-1113, 10.3115/v1/D14-1113]
   Pennington J., 2014, P C EMP METH NAT LAN, P1532, DOI DOI 10.3115/V1/D14-1162
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846
   Rahimi Z, 2021, APPL INTELL, V51, P6056, DOI 10.1007/s10489-020-02163-8
   Reisinger J., 2010, HLT-NAACL, P109
   Rezaeinia SM, 2019, EXPERT SYST APPL, V117, P139, DOI 10.1016/j.eswa.2018.08.044
   Sen P, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1041
   Tian F., 2014, COLING
   Toshevska Martina, Comparative analysis of word embeddings for capturing word similarities
   Tshitoyan V, 2019, NATURE, V571, P95, DOI 10.1038/s41586-019-1335-8
   Weinberger K., 2009, P 26 ANN INT C MACH, P1113, DOI DOI 10.1145/1553374.1553516
   Wu ZH, 2015, AAAI CONF ARTIF INTE, P2188
   Yang ZL, 2019, ADV NEUR IN, V32
   Yu L. C., 2017, P 2017 C EMP METH NA, P534
   Zelong Liu, 2011, 2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2011), P2695, DOI 10.1109/FSKD.2011.6020066
   Zhang ZH, 2015, INT CONF ASIAN LANG, P94, DOI 10.1109/IALP.2015.7451540
NR 37
TC 4
Z9 4
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 3
PY 2023
DI 10.1007/s11042-023-17007-z
EA OCT 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM0
UT WOS:001076638500015
DA 2024-07-18
ER

PT J
AU Singh, G
   Verma, A
   Gupta, L
   Mehta, A
   Arora, V
AF Singh, Gurjot
   Verma, Abhinav
   Gupta, Lavanya
   Mehta, Anant
   Arora, Vinay
TI An automated diagnosis model for classifying cardiac abnormality
   utilizing deep neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Image classification; Data augmentation; Biomedical
   signal processing; Spectrogram; Convolutional neural networks
ID HEART-SOUND CLASSIFICATION; SCALOGRAM; FRAMEWORK; ENSEMBLE
AB Cardiovascular diseases remain the leading cause of global mortality, resulting in the loss of 17.9 million lives annually, as reported by the World Health Organization (WHO). This study focuses on the classification of human heart-related sounds into normal or pathological categories. The PhysioNet Computing in Cardiology (CinC) 2016 and 2022 reference datasets, also known as PhysioNet 2016 and PhysioNet 2022 respectively, have been employed to examine the technique suggested in this research work. These benchmark datasets are comprised of 3,200 and 3,168 Phonocardiogram (PCG) recordings, respectively. In the current research, Mel spectrograms hold special significance in reducing the dimensions of a raw audio signal without causing any loss of important data, thus making it more manageable for processing. The work proposes a classification system based on the UNet architecture, which processes transformed spectrograms of the PCG signals. The augmented spectrograms have yielded the best results. Specifically, on the PhysioNet 2016 dataset, the proposed model has achieved an accuracy of 96.05%, specificity of 98.82%, and F1 score as 0.91. As the focus of this study has been to develop a novel architecture for classification and not data cleaning, the model has attained an accuracy of 56.80%, specificity of 59.29%, with F1 score as 0.58 on the PhysioNet 2022 dataset which is perceived to be a noisy dataset.
C1 [Singh, Gurjot; Verma, Abhinav; Gupta, Lavanya; Mehta, Anant; Arora, Vinay] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, India.
C3 Thapar Institute of Engineering & Technology
RP Mehta, A (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, India.
EM gsingh_be20@thapar.edu; averma8_be20@thapar.edu; lgupta_be20@thapar.edu;
   amehta1_be20@thapar.edu; vinay.arora@thapar.edu
OI Singh, Gurjot/0009-0004-4759-1976
CR Ahamed KU, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.105014
   Alaskar Haya, 2019, Intelligent Computing Methodologies. 15th International Conference, ICIC 2019. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11645), P784, DOI 10.1007/978-3-030-26766-7_71
   Alqudah AM, 2020, NETW MODEL ANAL HLTH, V9, DOI 10.1007/s13721-020-00272-5
   Arora V, 2021, CMC-COMPUT MATER CON, V69, P4151, DOI 10.32604/cmc.2021.019178
   Aurna NF, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105539
   Ballas A, 2022, Arxiv, DOI arXiv:2208.14845
   Bozkurt B, 2018, COMPUT BIOL MED, V100, P132, DOI 10.1016/j.compbiomed.2018.06.026
   Chandra Mayank Arya, 2021, International Journal of Information Technology, V13, P1, DOI 10.1007/s41870-017-0080-1
   Chen JX, 2022, IEEE T IND INFORM, V18, P2000, DOI 10.1109/TII.2021.3088465
   Chen YC, 2020, MED BIOL ENG COMPUT, V58, P2039, DOI 10.1007/s11517-020-02218-5
   López-Cabrera JD, 2021, HEALTH TECHNOL-GER, V11, P411, DOI 10.1007/s12553-021-00520-2
   Dwivedi AK, 2019, IEEE ACCESS, V7, P8316, DOI 10.1109/ACCESS.2018.2889437
   Faruqui N, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.104961
   Gadosey PK, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10020110
   Gill HS, 2022, MATER TODAY-PROC, V51, P591, DOI 10.1016/j.matpr.2021.06.016
   Gjoreski M, 2020, IEEE ACCESS, V8, P20313, DOI 10.1109/ACCESS.2020.2968900
   He Y, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11020651
   Hettiarachchi R, 2021, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS51556.2021.9401093
   Huai XM, 2021, INFORM HEALTH SOC CA, V46, P320, DOI 10.1080/17538157.2021.1893736
   Humayun AI, 2018, INTERSPEECH, P127
   Iriawan N, 2020, TELKOMNIKA (Telecommun. Comput. Electron. Control.), V18, P1310, DOI [10.12928/telkomnika.v18i3.14753, DOI 10.12928/TELKOMNIKA.V18I3.14753, 10.12928/TELKOMNIKA.v18i3.14753]
   Ismail S, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104075
   Jabari Mohammad, 2023, Journal of Ambient Intelligence and Humanized Computing, P2873, DOI 10.1007/s12652-023-04528-6
   Karhade J, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3163156
   Jafarbigloo SK, 2021, CAAI T INTELL TECHNO, V6, P426, DOI 10.1049/cit2.12061
   Koike T, 2020, IEEE ENG MED BIO, P74, DOI 10.1109/EMBC44109.2020.9175450
   Koppanyi Z, 2019, MULTIMODAL SCENE UNDERSTANDING: ALGORITHMS, APPLICATIONS AND DEEP LEARNING, P41, DOI 10.1016/B978-0-12-817358-9.00009-3
   Li SY, 2020, BIOMED RES INT-UK, V2020, DOI 10.1155/2020/5846191
   Li Xin, 2022, 2022 Computing in Cardiology (CinC), P1, DOI 10.22489/CinC.2022.046
   Liu BY, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21134508
   Maknickas V, 2017, PHYSIOL MEAS, V38, P1671, DOI 10.1088/1361-6579/aa7841
   Meintjes A, 2018, IEEE ENG MED BIO, P409, DOI 10.1109/EMBC.2018.8512284
   Nguyen MT, 2023, CIRC SYST SIGNAL PR, V42, P344, DOI 10.1007/s00034-022-02124-1
   Mustafa B., 2021, arXiv, DOI DOI 10.48550/ARXIV.2101.05913
   Nilanon T, 2016, COMPUT CARDIOL CONF, V43, P585
   Noman F, 2019, INT CONF ACOUST SPEE, P1318, DOI 10.1109/ICASSP.2019.8682668
   Oliveira J, 2022, IEEE J BIOMED HEALTH, V26, P2524, DOI 10.1109/JBHI.2021.3137048
   Ozturk, 2020, International Journal of Environment and Geoinformatics (IJEGEO), V7, DOI [DOI 10.30897/IJEGEO.737993, 10.30897/ijegeo.737993]
   Panah DS., 2022, Comput Biol Med, DOI [10.48550/arXiv.2211.07445, DOI 10.48550/ARXIV.2211.07445]
   Puri C, 2016, COMPUT CARDIOL CONF, V43, P1125
   Quattoni A, 2008, PROC CVPR IEEE, P2300
   Rath A, 2022, MULTIMED TOOLS APPL, V81, P36069, DOI 10.1007/s11042-021-11259-3
   Ren Z, 2018, DH '18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON DIGITAL HEALTH, P143, DOI 10.1145/3194658.3194671
   Ren Z, 2018, IEEE-CAA J AUTOMATIC, V5, P662, DOI 10.1109/JAS.2018.7511066
   Reyna M.A., 2022, P 2022 COMP CARD CIN, VVolume 498, P1, DOI [10.22489/CinC.2022.109, DOI 10.22489/CINC.2022.109]
   Rubin J, 2017, P 25 INT JOINT C ART, P1, DOI [10.48550/arXiv.1707.04642, DOI 10.48550/ARXIV.1707.04642]
   Shuvo SB, 2021, IEEE ACCESS, V9, P36955, DOI 10.1109/ACCESS.2021.3063129
   Singh SA, 2019, IEEE IMTC P, P1558, DOI 10.1109/i2mtc.2019.8826991
   Sun YN, 2020, IEEE T CYBERNETICS, V50, P3840, DOI 10.1109/TCYB.2020.2983860
   Takezaki S, 2021, P INT MULTICONFERENC
   Taneja K, 2023, EXPERT SYST, V40, DOI 10.1111/exsy.13246
   Torrent-Guasp F, 2005, EUR J CARDIO-THORAC, V27, P191, DOI 10.1016/j.ejcts.2004.11.026
   Tran T, 2020, IEEE ACCESS, V8, P203655, DOI 10.1109/ACCESS.2020.3036769
   Wu ZR, 2021, IEEE ACCESS, V9, P159447, DOI 10.1109/ACCESS.2021.3130578
   Xiang MH, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104190
   Yadav A, 2020, NEURAL COMPUT APPL, V32, P17843, DOI 10.1007/s00521-019-04547-5
   [Yue Shihong 岳士弘], 2003, Applied Mathematics. Series B, A Journal of Chinese Universities, V18, P332, DOI 10.1007/s11766-003-0059-5
   Zhang Y, 2020, IEEE ACCESS, V8, P19033, DOI 10.1109/ACCESS.2020.2966827
   Zhang Y, 2019, MECH SYST SIGNAL PR, V122, P480, DOI 10.1016/j.ymssp.2018.12.039
   Zhou G, 2022, BMC MED INFORM DECIS, V22, DOI 10.1186/s12911-022-01942-2
   Zunino R., 2002, 2002 IEEE International Symposium on Circuits and Systems. Proceedings (Cat. No.02CH37353), pII, DOI 10.1109/ISCAS.2002.1010938
NR 61
TC 0
Z9 0
U1 5
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 3
PY 2023
DI 10.1007/s11042-023-16930-5
EA OCT 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM0
UT WOS:001076638500016
DA 2024-07-18
ER

PT J
AU Laghmati, S
   Hamida, S
   Hicham, K
   Cherradi, B
   Tmiri, A
AF Laghmati, Sara
   Hamida, Soufiane
   Hicham, Khadija
   Cherradi, Bouchaib
   Tmiri, Amal
TI An improved breast cancer disease prediction system using ML and PCA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CAD systems for breast cancer prediction; Machine Learning; Artificial
   Intelligence; Feature selection; PCA; Stacking with logistic regression;
   Majority voting; Flask
ID PHASED APPROACH; ALGORITHM
AB Computer-aided diagnosis (CAD) systems based on machine learning (ML) techniques have altered the field of medical research. The deployement of such models to classify breast cancer is one area of many where exactness has been the main preoccupation. CAD systems aim to reach the performance of trained clinicians in identifying breast cancer at its early stages, thus optimizing the outcome for breast cancer patients while reducing the cost of treatment. This paper presents a supervised machine learning CAD system for breast cancer classification based on feature selection, PCA, grid search for hyperparameter tuning, and cross-validation. The system draws on seven ML classifiers ANN, k-NN, SVM, DT, RF, XGboost, and Adaboost. Two ensemble models were developed by concatenating the prediction of each ML model using Majority voting and stacking with Logistic Regression S-LR for the final prediction. The system's performance is evaluated by computing various evaluation metrics, mainly accuracy, specificity, precision, recall, Matthews Correlation Coefficient, Jaccard, and F1-score. To this end, the data sets used are Wisconsin and Mass mammography. The results indicate that the XGboost model achieved the highest recall of over 96% for the Mammographic Mass dataset. While for the WBCD, both the AdaBoost and the S-LR models outperformed the others with a Recall of 95.35%. The stacking with logistic regression ensemble model obtained the highest accuracies of 93.37% for the Mammographic Mass dataset and 97.37% for the WBCD. Accordingly, the proposed model can be suggested to assist in decision-making in classifying breast cancer tumors. Therefore, a Flask application using the S-LR model is developed.
C1 [Laghmati, Sara; Cherradi, Bouchaib; Tmiri, Amal] Chouaib Doukkali Univ, Fac Sci, LaROSERI Lab, El Jadida 24000, Morocco.
   [Hamida, Soufiane; Cherradi, Bouchaib] Hassan II Univ Casablanca, EEIS Lab, ENSET Mohammedia, Mohammadia 28820, Morocco.
   [Hamida, Soufiane] SupMTI Rabat, GENIUS Lab, Rabat, Morocco.
   [Hicham, Khadija; Tmiri, Amal] Mohammed V Univ Rabat, Lab M2SM, ENSAM Rabat, Rabat 10100, Morocco.
   [Cherradi, Bouchaib] CRMEF Casablanca Settat, STIE Team, El Jadida 24000, Morocco.
C3 Chouaib Doukkali University of El Jadida; Hassan II University of
   Casablanca; Mohammed V University in Rabat
RP Cherradi, B (corresponding author), Chouaib Doukkali Univ, Fac Sci, LaROSERI Lab, El Jadida 24000, Morocco.; Cherradi, B (corresponding author), Hassan II Univ Casablanca, EEIS Lab, ENSET Mohammedia, Mohammadia 28820, Morocco.; Cherradi, B (corresponding author), CRMEF Casablanca Settat, STIE Team, El Jadida 24000, Morocco.
EM bouchaib.cherradi@gmail.com
RI bouchaib, cherradi/J-2572-2016; Laghmati, Sara/GSN-3414-2022; hicham,
   khadija/KRO-3957-2024
OI bouchaib, cherradi/0000-0002-2016-8682; hicham,
   Khadija/0009-0006-0003-1618
CR Agarap AFM, 2015, 2ND INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND SOFT COMPUTING (ICMLSC 2018), P5, DOI 10.1145/3184066.3184080
   Al-Azzam N, 2021, ANN MED SURG, V62, P53, DOI 10.1016/j.amsu.2020.12.043
   AlHinai N, 2020, BIOMED SIGNAL PROCES, P1, DOI DOI 10.1016/B978-0-12-818946-7.00001-9
   Alsmariy R, 2020, INT J ADV COMPUT SC, V11, P173
   Altaher A, 2017, Int J Adv Comput Sci Appl, V8, DOI [10.14569/IJACSA.2017.080611, DOI 10.14569/IJACSA.2017.080611]
   Andrade Alexandre Vicente de, 2023, Rev Bras Ginecol Obstet, V45, P215, DOI 10.1055/s-0043-1769468
   Aszemi NM, 2019, INT J ADV COMPUT SC, V10, P269
   Balli S, 2019, MEAS CONTROL-UK, V52, P37, DOI 10.1177/0020294018813692
   Bansal M., 2022, Decis. Anal. J., V3, DOI [10.1016/j.dajour.2022.100071, DOI 10.1016/J.DAJOUR.2022.100071]
   Ben Jabra M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11062884
   Boutahar K, 2023, 2023 3 INT C INN RES, P1, DOI [10.1109/IRASET57153.2023.10152913, DOI 10.1109/IRASET57153.2023.10152913]
   Bowers AJ, 2019, J EDUC STUDENTS PLAC, V24, P20, DOI 10.1080/10824669.2018.1523734
   Cerda P, 2018, MACH LEARN, V107, P1477, DOI 10.1007/s10994-018-5724-2
   Chatterjee R, 2019, MACHINE LEARNING IN BIO-SIGNAL ANALYSIS AND DIAGNOSTIC IMAGING, P183, DOI 10.1016/B978-0-12-816086-2.00008-4
   Chen W, 2021, J ENVIRON MANAGE, V284, DOI 10.1016/j.jenvman.2021.112015
   Dalianis H., 2018, Clinical text mining: Secondary use of electronic patient records, DOI DOI 10.1007/978-3-319-78503-5
   Dhahri H, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/4253641
   Du M, 2011, ADV MATER RES-SWITZ, V267, P732, DOI 10.4028/www.scientific.net/AMR.267.732
   El Gannour O., 2022, 2022 2nd international conference on innovative research in applied science, engineering and technology (IRASET), P1
   Elter M, 2007, MED PHYS, V34, P4164, DOI 10.1118/1.2786864
   Gannour OE, 2022, IJACSA, V13, DOI [10.14569/IJACSA.2022.0130668, DOI 10.14569/IJACSA.2022.0130668]
   Ghawi R, 2019, OPEN COMPUT SCI, V9, P160, DOI 10.1515/comp-2019-0011
   Ginsburg O, 2020, CANCER-AM CANCER SOC, V126, P2379, DOI 10.1002/cncr.32887
   Guo R, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186593
   Hamida S, 2019, 2019 1 INT C SMART S, P1, DOI [10.1109/ICSSD47982.2019.9003052, DOI 10.1109/ICSSD47982.2019.9003052]
   Hicham K, 2023, 2023 3 INT C INN RES, P01, DOI [10.1109/IRASET57153.2023.10152889, DOI 10.1109/IRASET57153.2023.10152889]
   Hijazi H, 2013, J HEALTHC ENG, V4, P255, DOI 10.1260/2040-2295.4.2.255
   Islam Md Milon, 2020, SN Comput Sci, V1, P274, DOI 10.1007/s42979-020-00300-1
   Jalalian A, 2017, EXCLI J, V16, P113, DOI [10.17179/excli201-701, 10.17179/excli2016-701]
   Laboratory L, Breast cancer classification using machine learning, P4, DOI [10.1109/EBBT.2018.8391453, DOI 10.1109/EBBT.2018.8391453]
   Lawson CE, 2021, METAB ENG, V63, P34, DOI 10.1016/j.ymben.2020.10.005
   Madaminov FSM, 2022, Breast cancer detection methods, symptoms, causes, treatment, DOI [10.5281/ZENODO.7401437, DOI 10.5281/ZENODO.7401437]
   Mambou SJ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092799
   Murugesan A, 2023, CURR PROBL DIAGN RAD, V52, P1, DOI 10.1067/j.cpradiol.2022.08.001
   Musa AB, 2021, Int J Advance Soft Compu Appl, V13, P136
   Mutebi M, 2020, CANCER-AM CANCER SOC, V126, P2365, DOI 10.1002/cncr.32910
   Naji MA., 2021, PROCEDIA COMPUT SCI, V191, P487, DOI [DOI 10.1016/J.PROCS.2021.07.062, https://doi.org/10.1016/j.procs.2021.07.062]
   Niell BL, 2017, RADIOL CLIN N AM, V55, P1145, DOI 10.1016/j.rcl.2017.06.004
   Novakovi J.D., 2017, Theory Appl. Math. Comput. Sci, V7, P39, DOI DOI 10.1007/978-3-319-58747-9_1
   Omondiagbe David A., 2019, IOP Conference Series: Materials Science and Engineering, V495, DOI 10.1088/1757-899X/495/1/012033
   Ouhmida A, 2021, 2021 INT C ADV TECHN, P1, DOI [10.1109/ICOTEN52080.2021.9493456, DOI 10.1109/ICOTEN52080.2021.9493456]
   Park YS, 2016, DEV ENVIRON MODEL, V28, P123, DOI 10.1016/B978-0-444-63623-2.00007-4
   Parmar A, 2019, LECT NOTE DATA ENG, V26, P758, DOI 10.1007/978-3-030-03146-6_86
   Ragab DA, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9040165
   Saba T, 2020, J INFECT PUBLIC HEAL, V13, P1274, DOI 10.1016/j.jiph.2020.06.033
   Shao Z, 2022, EXPERT SYST APPL, V209, DOI 10.1016/j.eswa.2022.118221
   Sidharth M., 2017, CHEMOM INTELL LAB SY, V7, P60, DOI [DOI 10.5455/IJLR.20170415115235, DOI 10.1016/0169-7439(87)80084-9, 10.5455/ijlr.20170415115235]
   Srivastava G, 2022, COMPUT BIOL MED, V149, DOI 10.1016/j.compbiomed.2022.105979
   Terrada O., 2020, Adv Sci Technol Eng Syst, V5, P269, DOI [10.25046/aj050533, DOI 10.25046/AJ050533]
   Tulyakov S, 2008, STUD COMPUT INTELL, V90, P361
   Vujovic ZD, 2021, INT J ADV COMPUT SC, V12, P599
   Wang H, 2013, Encyclopedia of Systems Biology, P1406, DOI DOI 10.1007/978-1-4419-9863-7_233
   Wang HF, 2018, EUR J OPER RES, V267, P687, DOI 10.1016/j.ejor.2017.12.001
   Yarabarla Mamatha Sai, 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P121, DOI 10.1109/ICOEI.2019.8862533
   Zhou QF, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16101752
NR 55
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33785
EP 33821
DI 10.1007/s11042-023-16874-w
EA SEP 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001075272400019
DA 2024-07-18
ER

PT J
AU Biswas, R
   Gini, JR
AF Biswas, Rashni
   Gini, J. Rolant
TI Multi-class classification of Alzheimer's disease detection from 3D MRI
   image using ML techniques and its performance analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alzheimer's; Feature fusion; Hippocampi; MRI image; Machine learning;
   Random forest
AB Alzheimer's disease is a prevalent kind of syndrome; critical to diagnose in its early stages causes the patient forgets everything in its later stages. In this work, we proposed a design for early diagnosis of Alzheimer's disease; where a multi-class classification system has been implemented which detects AD and classifies the level of disease as Normal, Mild and Severe. The proposed approach starts with mapping the brain's anatomical parts hippocampal, white matter and grey matter and respective volumes are calculated from 3D MRI images. The image segmentation and calculation of volume are done with two software; Analyze Direct and ITK Snap. Calculated volumes of the anatomical parts along with other features like age, gender and MMSE score are fed to different machine learning algorithms for Alzheimer's detection as well as its severity. The extracted features are also fused randomly in all possible ways for further analysis using ML classifiers. The ML algorithms used are random forest, gradient boost, decision tree and KNN. The proposed approach is tested with two sets of data; OASIS dataset and ADNI dataset. Classifier's performance is analyzed based on sensitivity, F1 Score, accuracy and precision for ML classifiers. Random forest is giving the highest accuracy of 99% for white matter volume using OASIS dataset and when all three volumes of hippocampal, white matter and grey matter are fused giving 98% accuracy. For ADNI data set using white matter volume, we are getting 92% accuracy for gradient boost classifier and after fusing all three volumes also getting 92% accuracy. Gradient boost gives an accuracy of around 91% for both databases.
C1 [Biswas, Rashni; Gini, J. Rolant] Amrita Vishwa Vidyapeetham, Dept Elect & Commun Engn, Amrita Sch Engn, Coimbatore, Tamil Nadu, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Coimbatore
RP Biswas, R (corresponding author), Amrita Vishwa Vidyapeetham, Dept Elect & Commun Engn, Amrita Sch Engn, Coimbatore, Tamil Nadu, India.
EM rashnibiswas1998@gmail.com; j_rolantgini@cb.amrita.edu
OI Gini J, Dr. Rolant/0000-0002-8013-1398
CR Abdulla AA, 2020, IET IMAGE PROCESS, V14, P4435, DOI 10.1049/iet-ipr.2020.0978
   Acharya UR, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1428-9
   Altinkaya E., 2020, Electr Comput Center J, V1, P39
   Apostolova LG., 2016, Lifelong Learn Neurol Dementia, V22, P404
   Aruna S., 2016, Int J Comput Inf Eng, V9, P881
   Asim Y, 2018, INT J IMAG SYST TECH, V28, P113, DOI 10.1002/ima.22263
   Ayed MB., 2020, Int J Comput Sci Netw Secur, V20, P166
   Carcagnì P, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23031694
   Cummings JL, 2002, JAMA-J AM MED ASSOC, V287, P2335, DOI 10.1001/jama.287.18.2335
   Demirhan Ayse., 2016, Int J Intell Syst Appl Eng, P195, DOI [DOI 10.18201/IJISAE.2016SPECIALISSUE-146973, 10.18201/ijisae.2016SpecialIssue-146973]
   Feng W, 2020, INT J NEURAL SYST, V30, DOI 10.1142/S012906572050032X
   Ganeshkumar M, 2022, Intelligent Vision in Healthcare, P23
   Ganeshkumar M., 2022, Cognitive and Soft Computing Techniques for the Analysis of Healthcare Data, P203
   Herzog NJ., 2022, Machine Learning-Supported MRI Analysis of Brain Asymmetry for Early Diagnosis of Dementia, P29
   Holtzman David M, 2012, Cold Spring Harb Perspect Med, V2, DOI 10.1101/cshperspect.a011585
   Holtzman DM, 2012, CSH PERSPECT MED, V2, DOI 10.1101/cshperspect.a011585
   John RG, 2019, COMPUT METH PROG BIO, V175, P193, DOI 10.1016/j.cmpb.2019.04.022
   Kamath D., 2021, Int J Artif Intell, V8, P25
   Krishnan KK, 2021, BIOMED ENG LETT, V11, P235, DOI 10.1007/s13534-021-00190-z
   Kharrat A., 2019, Applied Medical Informatics, V41, P9
   Kumar A, 2018, CURR NEUROPHARMACOL, V16, P726, DOI 10.2174/1570159X16666180315141643
   Leandrou Stephanos, 2018, IEEE Rev Biomed Eng, V11, P97, DOI 10.1109/RBME.2018.2796598
   Lodha P, 2018, 2018 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION (ICCUBEA)
   Rolant Gini J., 2017, Removal of BW and respiration noise in abdECG for fECG extraction, P3
   Sampath R., 2018, Med Prog J, V42, P1
   Sethi M, 2022, COMPUT MATH METHOD M, V2022, DOI 10.1155/2022/8680737
   Soman KP., 2022, Canonical Polyadic Decomposition of EEG Image Tensor for BCI Applications, P819
   Vikram K., 2018, Segmentation of brain parts from MRI image slices using genetic algorithm, P457
   Yao Zhiming, 2018, MATEC Web of Conferences, V232, DOI 10.1051/matecconf/201823202030
   Yushkevich P, 2005, INSIGHT J, V1, P1
NR 30
TC 1
Z9 1
U1 5
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33527
EP 33554
DI 10.1007/s11042-023-16519-y
EA SEP 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069514100006
DA 2024-07-18
ER

PT J
AU Ren, NA
   Cheng, GH
   Xie, D
   Chen, FL
   Li, BY
AF Ren, Nana
   Cheng, Guihua
   Xie, Dong
   Chen, Fulong
   Li, Boyu
TI A double-embedding hidden image encryption and authentication scheme
   based on compressed sensing and double random phase encoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sensing; Double random phase encoding; Singular value
   decomposition; Least significant bit
AB The image may be maliciously tampered when transmitted on the shared platform, and the receiver cannot determine whether the received image is a true image. In order to solve the above problems, an image encryption and authentication scheme with visual security based on compressed sensing and double random phase encoding are proposed. Firstly, the plain image is compressed and encoded by double random phase encoding to obtain authentication information to verify the authenticity of the image. Then, the compressed image and authentication information are fused and then scrambled to hide the authentication information and ensure the security of the encrypted image and authentication information. Finally, the secret image and authentication information are embedded into the carrier image by singular value decomposition and least significant bit method, respectively, to improve the security of the secret image and the anti-attack ability of the authentication information. The experimental results show that the PSNR and peak-to-correlation energy of the image are still greater than 17 dB and 0.001 under a certain attack intensity, indicating that the scheme has good reconstruction quality and strong robustness.
C1 [Ren, Nana; Cheng, Guihua; Xie, Dong; Chen, Fulong; Li, Boyu] Anhui Normal Univ, Sch Comp & Informat, Wuhu 241002, Peoples R China.
   [Ren, Nana; Cheng, Guihua; Xie, Dong; Chen, Fulong; Li, Boyu] Anhui Normal Univ, Anhui Prov Key Lab Network & Informat Secur, Wuhu 241002, Peoples R China.
C3 Anhui Normal University; Anhui Normal University
RP Xie, D (corresponding author), Anhui Normal Univ, Sch Comp & Informat, Wuhu 241002, Peoples R China.; Xie, D (corresponding author), Anhui Normal Univ, Anhui Prov Key Lab Network & Informat Secur, Wuhu 241002, Peoples R China.
EM xiedong@ahnu.edu.cn
RI LI, BOYU/IUO-0933-2023
FU National Natural Science Foundation of China [61801004, 61972438];
   Natural Science Foundation of Anhui Province [1808085QF211]; Key
   Research and Development Projects in Anhui Province [202004a05020002]
FX This paper is partially supported by the National Natural Science
   Foundation of China (Grant Nos. 61801004 and 61972438), the Natural
   Science Foundation of Anhui Province (Grant No. 1808085QF211), and the
   Key Research and Development Projects in Anhui Province (Grant Nos.
   202004a05020002)
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Bharath B, 2017, INT CONF COMPUT POW, P43, DOI 10.1109/ICCPEIC.2017.8290336
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chai XL, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107525
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chen JX, 2018, OPT LASER ENG, V107, P352, DOI 10.1016/j.optlaseng.2018.04.009
   Dittmann J., 2001, IEEE Multimedia, V8, P54, DOI 10.1109/93.959103
   Dong YH, 2022, INFORM SCIENCES, V593, P121, DOI 10.1016/j.ins.2022.01.031
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   DS Maini and Ashwani Kumar Aggarwal, 2018, INT J INNOV ENG TECH, V10, P199, DOI DOI 10.21172/IJIET.102.29
   Farah MAB., 2020, Opt Laser Technol, V121, P777
   Gan ZH, 2022, J KING SAUD UNIV-COM, V34, P9252, DOI 10.1016/j.jksuci.2022.09.006
   Hanis S, 2019, NONLINEAR DYNAM, V95, P421, DOI 10.1007/s11071-018-4573-7
   Hua Z., 2021, Signal Process, V183, P998
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Kanmani M, 2020, MULTIMED TOOLS APPL, V79, P17859, DOI 10.1007/s11042-020-08628-9
   Kanmani M, 2019, MULTIDIM SYST SIGN P, V30, P1911, DOI 10.1007/s11045-019-00636-9
   Kumar A., 2014, Seisan Kenkyu, V66, P101
   Kumar A., 2013, Seisan Kenkyu, V65, P91
   Li HJ, 2021, MULTIMED TOOLS APPL, V80, P8721, DOI 10.1007/s11042-020-10117-y
   Mansouri A, 2020, INFORM SCIENCES, V520, P46, DOI 10.1016/j.ins.2020.02.008
   Mohimani GH, 2007, LECT NOTES COMPUT SC, V4666, P389
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Ren H, 2022, MULTIMED TOOLS APPL, V81, P25993, DOI 10.1007/s11042-022-12013-z
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang H, 2019, SIGNAL PROCESS, V155, P218, DOI 10.1016/j.sigpro.2018.10.001
   Wang XY, 2021, INFORM SCIENCES, V574, P505, DOI 10.1016/j.ins.2021.06.032
   Wang XY, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116246
   Wang XY, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110102
   Wen WY, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107580
   Wu B, 2022, DIGIT SIGNAL PROCESS, V123, DOI 10.1016/j.dsp.2022.103391
   Xiao D, 2021, OPT LASER TECHNOL, V140, DOI 10.1016/j.optlastec.2021.107077
   Xie D, 2019, DIGIT SIGNAL PROCESS, V95, DOI 10.1016/j.dsp.2019.102587
   Xu QY, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106178
   Yao SY, 2019, OPT LASER TECHNOL, V120, DOI 10.1016/j.optlastec.2019.105703
   Ye GD, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107563
   Yi FL, 2018, IEEE ACCESS, V6, P70113, DOI 10.1109/ACCESS.2018.2880730
   Yuan L, 2017, OPT LASER TECHNOL, V88, P111, DOI 10.1016/j.optlastec.2016.09.004
   Zhang R, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10081242
   Zhang YS, 2020, IEEE T IND INFORM, V16, P7566, DOI 10.1109/TII.2019.2957404
   Zhou KL, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105769
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhu LY, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107629
NR 46
TC 0
Z9 0
U1 8
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31417
EP 31442
DI 10.1007/s11042-023-16743-6
EA SEP 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001066958500013
DA 2024-07-18
ER

PT J
AU Wang, BL
   Zhang, X
   Wang, JS
   Gao, C
   Duan, Q
   Li, LY
AF Wang, Baolei
   Zhang, Xuan
   Wang, Jishu
   Gao, Chen
   Duan, Qing
   Li, Linyu
TI Fine-grained cybersecurity entity typing based on multimodal
   representation learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cybersecurity; Information extraction; Fine-grained; Multimodal
ID VLSI IMPLEMENTATION; SIGNAL COMPRESSION; ECG; DESIGN
AB Fine-grained entity typing is crucial to improving the efficiency of research in the field of cybersecurity. However, modality limitations and type-labeling hierarchy complexity limit the construction of fine-grained entity typing datasets and the performance of related models. Therefore, in this paper, we constructed a fine-grained entity typing dataset based on multimodal information from the cybersecurity literatures and design a multimodal representation learning model based on it. Specifically, we design and introduce a new benchmark dataset called CySets to facilitate the study of new tasks and train a novel multimodal representation learning model called Cyst-MMET with multitask objectives. The model utilizes multimodal knowledge from literature and external to unify visual and textual representations by eliminating visual noise through a multi-level fusion encoder, thereby alleviating data bottlenecks and long-tail problems in the fine-grained entity typing task. Experimental results show that CySets have sharper hierarchies and more diverse labels than the existing datasets. Across all datasets, our model achieves state-of-the-art or dominant performance (3%), demonstrating that the model is effective in predicting entity types at different granularities.
C1 [Wang, Baolei; Zhang, Xuan; Duan, Qing; Li, Linyu] Yunnan Univ, Sch Software, Kunming 650091, Yunnan, Peoples R China.
   [Wang, Baolei] HRC, Yi Shu Si River Basin Adm Hydrol Bur, Xuzhou, Jiangsu, Peoples R China.
   [Zhang, Xuan; Duan, Qing] Key Lab Software Engn Yunnan Prov, Kunming 650091, Yunnan, Peoples R China.
   [Zhang, Xuan; Duan, Qing] Engn Res Ctr Cyberspace, Kunming 650091, Yunnan, Peoples R China.
   [Wang, Jishu; Gao, Chen] Yunnan Univ, Sch Informat Sci & Engn, Kunming 650091, Yunnan, Peoples R China.
C3 Yunnan University; Yunnan University
RP Zhang, X (corresponding author), Yunnan Univ, Sch Software, Kunming 650091, Yunnan, Peoples R China.; Zhang, X (corresponding author), Key Lab Software Engn Yunnan Prov, Kunming 650091, Yunnan, Peoples R China.; Zhang, X (corresponding author), Engn Res Ctr Cyberspace, Kunming 650091, Yunnan, Peoples R China.
EM zhxuan@ynu.edu.cn
RI Wang, Jishu/ITU-7659-2023; li, linyu/JCE-7598-2023
OI Wang, Jishu/0000-0001-5973-2415; li, linyu/0009-0005-8626-0608
FU National Natural Science Foundation of China
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61862063, 61502413, 61262025; the Science
   Foundation of Young and Middle-aged Academic and Technical Leaders of
   Yunnan under Grant No. 202205 AC160040; the Science Foundation of Yunnan
   Jinzhi Expert Workstation under Grant No. 202205AF150006; Major Project
   of Yunnan Natural Science Foundation under Grant No. 202202AE090066;
   Science and Technology Project of Yunnan Power Grid Co., Ltd. under
   Grant No.YNKJXM20222254; the Science Foundation of "Knowledge-driven
   intelligent software engineering innovation team".
CR Ali MA, 2020, AAAI CONF ARTIF INTE, V34, P7391
   Azadifar S, 2022, COMPUT BIOL MED, V147, DOI 10.1016/j.compbiomed.2022.105766
   Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3615
   Bridges R A, 2013, Comput Sci
   Chen Tongfei, 2020, P 58 ANN M ASS COMP, P8465
   Chenkai Sun, 2021, 2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), P1984, DOI 10.1109/BIBM52615.2021.9669360
   Choi E, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P87
   Dai HL, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6210
   Del Corro L, 2015, P 2015 C EMP METH NA, P868, DOI DOI 10.18653/V1/D15-1103
   Fang B., 2021, China Eng Sci, V23, P7
   Gillick Dan, 2014, ABS14121820 CORR
   Li LH, 2019, Arxiv, DOI [arXiv:1908.03557, DOI 10.48550/ARXIV.1908.03557]
   Huang S, 2022, Multimed Tools Appl, P1
   Joshi A, 2013, IEEE INT C SEMANT CO, P252, DOI 10.1109/ICSC.2013.50
   Kang YC, 2021, INT J ARTIF INTELL T, V30, DOI 10.1142/S0218213021400066
   Kingma Diederik P., 2015, P 3 INT C LEARN
   Lee Kenton, 2017, P C EMP METH NAT LAN
   Lin JCW, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106548
   Lin JCW, 2020, NEUROCOMPUTING, V403, P431, DOI 10.1016/j.neucom.2020.04.102
   Lin JCW, 2019, ENG APPL ARTIF INTEL, V85, P175, DOI 10.1016/j.engappai.2019.06.005
   Lin Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6197
   Lv J, 2023, PATTERN RECOGN, V137, DOI 10.1016/j.patcog.2023.109301
   Murty S, 2017, P 6 WORKSH AUT KNOWL, P1
   Nasiri E, 2023, MULTIMED TOOLS APPL, V82, P3745, DOI 10.1007/s11042-022-12943-8
   Obeidat R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P807
   Onoe Y, 2020, AAAI CONF ARTIF INTE, V34, P8576
   Pingle A, 2020, 2019 IEEE ACM INT C
   Rabinovich Maxim., 2017, P ASS COMPUTATIONAL
   Radford A, 2021, PR MACH LEARN RES, V139
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Raiman J, 2018, Deeptype: multilingual entity linking by neural type system evolution
   Raiman J, 2018, AAAI CONF ARTIF INTE, P5406
   Ren X, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1825, DOI 10.1145/2939672.2939822
   Ren YK, 2020, WWW'20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020, P846, DOI 10.1145/3366424.3382725
   Schutze H, 2016, P C EMP METH NAT LAN
   Selman, 2012, P 26 AAAI C ART INT
   Shao YN, 2021, PATTERN RECOGN LETT, V145, P157, DOI 10.1016/j.patrec.2021.02.008
   Sharma DK, 2022, COMPUT ELECTR ENG, V103, DOI 10.1016/j.compeleceng.2022.108356
   Shen GJ, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/3240675
   Shimaoka S, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1271
   Sun C, 2021, Fine-grained chemical entity typing with multimodal knowledge representation
   Weischedel Ralph, 2005, BBN pronoun coreference and entity type corpus[J], P112
   Wu JS, 2022, IEEE-ACM T AUDIO SPE, V30, P1305, DOI 10.1109/TASLP.2022.3155281
   Xu B, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P1215, DOI 10.1145/3488560.3498475
   Xu Peng, 2018, P 2018 C N AM CHAPTE, V1, P16
   Yao L, 2013, AUTOMATIC KNOWLEDGE
   Yavuz S., 2016, P 2016 C EMP METH NA, P149, DOI DOI 10.18653/V1/D16-1
   Zhang Sheng, 2018, P 7 JOINT C LEX COMP, P173, DOI 10.18653/v1/s18-2022
   Zhang S, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1833, DOI 10.1145/3340531.3412019
   Zhang Tao, 2020, P 28 INT C COMP LING, P77
NR 50
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30207
EP 30232
DI 10.1007/s11042-023-16839-z
EA SEP 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066762000007
DA 2024-07-18
ER

PT J
AU Li, WW
   Du, R
   Chen, SD
AF Li, Weiwei
   Du, Rong
   Chen, Shudong
TI Keypoint-based contextual representations for hand pose estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand pose estimation; Gesture recognition; Relational context; Keypoint
   heatmap; Object Detection
AB Most current methods for the hand pose estimation ignore the pixel-level relationship of hand keypoints, e.g. four specific keypoints in the same finger can form a semantically continuous area at pixel level. To make full use of pixel-level semantic information extracted from the origin RGB image, we propose a novel keypoint-based contextual representation(KCR) scheme for hand pose estimation, which can leverage pixel-level continuous contextual features based on the hand structure without using any additional labeling information. To extract hand structure information from the contextual features, we creatively design a novel keypoint representation and finger representation scheme by fusing the keypoints feature in a specific group. Then, the cross-attention mechanism is used to calculate the relation between the finger representations and contextual features to improve the feature integration. The augmented feature contains more hand structure information for the final hand pose estimation. Experimental results demonstrate that our method achieves competitive performance on various 2D and 3D hand pose estimation benchmarks.
C1 [Li, Weiwei; Du, Rong; Chen, Shudong] Chinese Acad Sci, Inst Microelect, Beijing 100029, Peoples R China.
   [Li, Weiwei; Du, Rong; Chen, Shudong] Univ Chinese Acad Sci, Sch Microelect, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Microelectronics, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Li, WW (corresponding author), Chinese Acad Sci, Inst Microelect, Beijing 100029, Peoples R China.; Li, WW (corresponding author), Univ Chinese Acad Sci, Sch Microelect, Beijing, Peoples R China.
EM liweiwei@ime.ac.cn; chenshudong@ime.ac.cn
FU Strategic Priority Research Program of the Chinese Academy of Sciences
   [XDC02070600]
FX This work was supported by the Strategic Priority Research Program of
   the Chinese Academy of Sciences under Grant XDC02070600.
CR Athitsos V, 2003, 2003 IEEE C COMP VIS, V2, pII
   Boukhayma A, 2019, PROC CVPR IEEE, P10835, DOI 10.1109/CVPR.2019.01110
   Brahmbhatt Samarth, 2020, EUR C COMP VIS ECCV, V16, P361, DOI DOI 10.1007/978-3-030-58601-0_22
   Cai YJ, 2018, LECT NOTES COMPUT SC, V11210, P678, DOI 10.1007/978-3-030-01231-1_41
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chen YF, 2020, IEEE WINT CONF APPL, P370, DOI [10.1109/WACV45572.2020.9093271, 10.1109/wacv45572.2020.9093271]
   Chen YJ, 2021, PROC CVPR IEEE, P10446, DOI 10.1109/CVPR46437.2021.01031
   Ci H, 2019, IEEE I CONF COMP VIS, P2262, DOI 10.1109/ICCV.2019.00235
   deLaGorceMartin FleetDavid J, 2011, IEEE T PATTERN ANAL
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Ge LH, 2019, PROC CVPR IEEE, P10825, DOI 10.1109/CVPR.2019.01109
   Hasson Y, 2019, PROC CVPR IEEE, P11799, DOI 10.1109/CVPR.2019.01208
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Iqbal U, 2018, LECT NOTES COMPUT SC, V11215, P125, DOI 10.1007/978-3-030-01252-6_8
   Joo H, 2018, PROC CVPR IEEE, P8320, DOI 10.1109/CVPR.2018.00868
   Kulon D., 2019, BMVC, P1
   Kulon D, 2020, PROC CVPR IEEE, P4989, DOI 10.1109/CVPR42600.2020.00504
   Moon G., 2020, COMPUTER VISION ECCV
   Moon G, 2018, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2018.00533
   Mueller F, 2018, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2018.00013
   Neverova N, 2017, COMPUT VIS IMAGE UND, V164, P56, DOI 10.1016/j.cviu.2017.10.006
   Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101
   Romero J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130883
   Spurr A, 2018, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2018.00017
   Taheri Omid, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P581, DOI 10.1007/978-3-030-58548-8_34
   Tkach A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980226
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang YG, 2020, IEEE T IMAGE PROCESS, V29, P2977, DOI 10.1109/TIP.2019.2955280
   Wang YG, 2019, IEEE T CIRC SYST VID, V29, P3258, DOI 10.1109/TCSVT.2018.2879980
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Xiang DL, 2019, PROC CVPR IEEE, P10957, DOI 10.1109/CVPR.2019.01122
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang LL, 2019, IEEE I CONF COMP VIS, P2335, DOI 10.1109/ICCV.2019.00242
   Yuan Y, 2018, OCNET OBJECT CONTEXT
   Zhang H, 2019, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2019.00064
   Zhang J., 2016, ARXIV
   Zhang X, 2019, IEEE I CONF COMP VIS, P2354, DOI 10.1109/ICCV.2019.00244
   Zhao L, 2019, PROC CVPR IEEE, P3420, DOI 10.1109/CVPR.2019.00354
   Zhou YX, 2020, PROC CVPR IEEE, P5345, DOI 10.1109/CVPR42600.2020.00539
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zimmermann C, 2019, IEEE I CONF COMP VIS, P813, DOI 10.1109/ICCV.2019.00090
   Zimmermann C, 2017, IEEE I CONF COMP VIS, P4913, DOI 10.1109/ICCV.2017.525
NR 45
TC 0
Z9 0
U1 10
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28357
EP 28372
DI 10.1007/s11042-023-15713-2
EA SEP 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066065600009
DA 2024-07-18
ER

PT J
AU Cheruku, R
   Hussain, K
   Kavati, I
   Reddy, AM
   Reddy, KS
AF Cheruku, Ramalingaswamy
   Hussain, Khaja
   Kavati, Ilaiah
   Reddy, A. Mallikarjuna
   Reddy, K. Sudheer
TI Sentiment classification with modified RoBERTa and recurrent neural
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; Context understanding; Natural language processing;
   RoBERTa; Recurrent neural networks
AB The unprecedented growth in the use of social media platforms, where opinions and decisions are made and updated within seconds. Hence, Twitter is becoming a huge commercial interest for brands and companies to assess the sentiment of customers. Sentiment analysis tries to extract subjective opinions and sentiments from opinionated data using Natural Language Processing (NLP). Ontology-based analysis was primarily used to disambiguate the terms and get a high precision score for the emotive terms. In this paper, to improve the accuracy of sentiment analysis we modified the RoBERTa model to extract the more relevant contextualized information. Moreover, this modified RoBERTa is combined with RNN for effective sentiment classification. The proposed work attempts to find which words or phrases actually contribute to the particular sentiment as output by a modified RoBERTa model and this output of the RoBERTa model is fed as input for RNNs. The proposed model is experimented on the Twitter comment dataset. The proposed model experimented on various models such as single RNN, single layer LSTM, and Bi-directional LSTM and evaluated performance measures in terms of accuracy, precision, recall, and F1-score. Our proposed model performance significantly improved with respect to all other models in terms of accuracy, precision, recall, and F1-score. The experiments show that the proposed model not only increases the Jaccard similarity score but also improves different RNN performance when compared to existing state-of-the-art models. The proposed approach obtained a maximum accuracy of 84.6% which is a huge improvement and also evaluated comparison analysis of Simple RNN, Single-LSTM, and Bi-LSTM on full text and selected test. Our proposed modified ROBERTa performance is superior with selected text and full text. Finally, the statistical paired T-test is performed between the proposed model, and other models such as simple RNN, One layer RNN is giving evidence that the proposed model performance is superior with 95% confidence and p<0.05.
C1 [Cheruku, Ramalingaswamy; Hussain, Khaja; Kavati, Ilaiah] Natl Inst Technol Warangal, Dept Comp Sci & Engn, Warangal 506004, Telangana, India.
   [Reddy, A. Mallikarjuna; Reddy, K. Sudheer] Anurag Univ, Hyderabad, Telangana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Warangal
RP Cheruku, R (corresponding author), Natl Inst Technol Warangal, Dept Comp Sci & Engn, Warangal 506004, Telangana, India.
EM rmlswamy@nitw.ac.in; khajahussain528@gmail.com; ilaiahkavati@nitw.ac.in;
   mallikarjunreddycse@cvsr.ac.in; sudheercse@gmail.com
RI Reddy, A Mallikarjuna/ABD-4913-2020; Reddy, Sudheer/AAF-6553-2019
OI Reddy, A Mallikarjuna/0000-0002-8665-9804; Reddy,
   Sudheer/0000-0001-5371-9869; Cheruku,
   Ramalingaswamy/0000-0003-1677-5321; Mallikarjun,
   Anna/0000-0002-9100-5004
CR Balakrishnan V, 2021, J SUPERCOMPUT, V77, P3795, DOI 10.1007/s11227-020-03412-w
   Bhuvan MS, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P28, DOI 10.1109/CCAA.2015.7148366
   Birjali M, 2021, KNOWL-BASED SYST, V226, DOI 10.1016/j.knosys.2021.107134
   Cambria E, 2017, SOCIO AFFECT COMPUT, V5, P1, DOI 10.1007/978-3-319-55394-8_1
   Carosia AED, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115470
   Devlin J., 2018, BERT PRE TRAINING DE
   Horne L, 2020, P 1 C AS PAC CHAPT A, P130
   Jing N, 2021, EXPERT SYST APPL, V178, DOI 10.1016/j.eswa.2021.115019
   Katz G, 2015, KNOWL-BASED SYST, V84, P162, DOI 10.1016/j.knosys.2015.04.009
   Lai S, 2020, 2020 2 INT C APPL MA, P232, DOI [10.1109/ICAML51583.2020.00056, DOI 10.1109/ICAML51583.2020.00056]
   Lerner I, 2020, J BIOMED INFORM, V102, DOI 10.1016/j.jbi.2019.103356
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Liu Yinhan, 2019, ARXIV190711692
   Ma J, 2018, ARXIV
   Monika R, 2019, INT CONF ADV COMPU, P92, DOI [10.1109/IACC48062.2019.8971592, 10.1109/iacc48062.2019.8971592]
   Nair Anu J., 2021, Proceedings of 5th International Conference on Computing Methodologies and Communication (ICCMC 2021), P1773, DOI 10.1109/ICCMC51019.2021.9418320
   Narayanasamy SK, 2021, FRONT PUBLIC HEALTH, V9, DOI 10.3389/fpubh.2021.798905
   Pak A, 2010, P 7 C INT LANG RES E, DOI DOI 10.17148/IJARCCE.2016.51274
   Petrucci G, 2016, ARXIV
   Qian Q., 2016, ARXIV
   Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3
   Sennrich Rico, 2015, arXiv
   SivaSai JG, 2020, STUDIES COMPUTATIONA, P163, DOI [DOI 10.1007/978-981-15-5495-7_9, 10.1007/978-981-15-5495-7_9/COVER/]
   Tan KL, 2022, IEEE ACCESS, V10, P21517, DOI 10.1109/ACCESS.2022.3152828
   Tang DY, 2016, IEEE T KNOWL DATA EN, V28, P496, DOI 10.1109/TKDE.2015.2489653
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Teng Zhiyang., 2016, EMNLP, P1629, DOI [10.18653/v1/d16-1169, DOI 10.18653/V1/D16-1169]
   Thukral S, 2023, HDB DESIGNING CONDUC, P139, DOI [10.1016/B978-0-12-823026-8.00104-8, DOI 10.1016/B978-0-12-823026-8.00104-8]
   Vaswani A, 2017, ADV NEUR IN, V30
   Vimali J. S., 2021, 2021 6th International Conference on Communication and Electronics Systems (ICCES), P1652, DOI 10.1109/ICCES51350.2021.9489129
   Zhang J, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107259
NR 31
TC 0
Z9 0
U1 11
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29399
EP 29417
DI 10.1007/s11042-023-16833-5
EA SEP 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066976400005
DA 2024-07-18
ER

PT J
AU Sekhar, PNRLC
   Shankar, TN
AF Sekhar, P. N. R. L. Chandra
   Shankar, T. N.
TI An object-based splicing forgery detection using multiple noise features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image splicing detection; Localization; Noise features; Cosine
   similarity; Logistic regression
AB In our modern age, everything is accessible from anywhere to share thoughts and monuments with loved ones via social networking. On the other hand, different photo editing tools manipulate images and videos and allow an incredible opportunity to challenge the intended audience. When altered images go viral on social media, people may lose confidence, faith and integrity on the shared images. Thus necessitating a digital, trustworthy forensic technique to authenticate such images. This paper presents a novel feature extraction approach for detecting a tampered region. Individual objects are retrieved from the spliced image, and noise standard deviation is evaluated for each object in three different domains. The noise deviation features are then obtained based on pair-wise deviation using cosine similarity between individual objects. These features are fused using logistic regression to obtain a fake regression score that reveals the tampering region of a spliced image. The experimental findings suggest that the features and approach are superior and robust to state-of-the-art methods in detecting the tampered region.
C1 [Sekhar, P. N. R. L. Chandra] Gandhi Inst Technol & Management, Dept Comp Sci & Engn, Visakhapatnam 530045, Andhra Pradesh, India.
   [Shankar, T. N.] Dr Vishwanath Karad World Peace Univ, Sch Comp Engn & Technol, Pune, Maharashtra, India.
C3 Gandhi Institute of Technology & Management (GITAM); Dr. Vishwanath
   Karad MIT World Peace University
RP Sekhar, PNRLC (corresponding author), Gandhi Inst Technol & Management, Dept Comp Sci & Engn, Visakhapatnam 530045, Andhra Pradesh, India.
EM cpnrl@gitam.edu; tnshankar2004@rediffmail.com
RI SHANKAR, TARUN NARAYAN/ABD-9474-2020; L, Chandra Sekhar P N
   R/AAT-3370-2021
OI SHANKAR, TARUN NARAYAN/0000-0001-6566-8595; 
CR Amerini I, 2014, IEEE INT WORKS INFOR, P143, DOI 10.1109/WIFS.2014.7084318
   Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bunk J, 2017, Computer Vision Pattern Recog, P1
   Chen BJ, 2018, IEEE ACCESS, V6, P69472, DOI 10.1109/ACCESS.2018.2880433
   Chen C, 2022, IEEE Trans Circu Syst Video Technol
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P1090, DOI 10.1109/TIP.2019.2934350
   Chen GY, 2015, IEEE I CONF COMP VIS, P477, DOI 10.1109/ICCV.2015.62
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Hsu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P549, DOI 10.1109/ICME.2006.262447
   Korus P, 2017, IEEE T INF FOREN SEC, V12, P809, DOI 10.1109/TIFS.2016.2636089
   Le N, 2019, IEEE ACCESS, V7, P125038, DOI 10.1109/ACCESS.2019.2938467
   Li WH, 2009, SIGNAL PROCESS, V89, P1821, DOI 10.1016/j.sigpro.2009.03.025
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Liu B, 2014, Scientific World J, P1
   Liu B, 2020, NEUROCOMPUTING, V387, P172, DOI 10.1016/j.neucom.2019.12.105
   Liu B, 2018, SIGNAL PROCESS-IMAGE, V66, P103, DOI 10.1016/j.image.2018.04.011
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Mahdian B, 2009, IMAGE VISION COMPUT, V27, P1497, DOI 10.1016/j.imavis.2009.02.001
   Matern F, 2020, IEEE T INF FOREN SEC, V15, P1303, DOI 10.1109/TIFS.2019.2935913
   Mire AV, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0257-y
   Pun CM, 2016, J VIS COMMUN IMAGE R, V38, P195, DOI 10.1016/j.jvcir.2016.03.005
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Saxena S., 2015, VIDEO INPAINTING DETECTION USING INCONSISTENCIES IN
   Sekhar PNRLC, 2021, J INTELL FUZZY SYST, V41, P5387, DOI 10.3233/JIFS-189861
   Sekhar PNRLC, 2021, INT J ELECTRON SECUR, V13, P346, DOI 10.1504/IJESDF.2021.114956
   Sekhar PC., 2019, IJRTE, V8, P764, DOI [10.35940/ijrte.C3999.098319, DOI 10.35940/IJRTE.C3999.098319]
   Waleed A, 2017, GITHUB REPOSITORY
   Xue F, 2019, MULTIMED TOOLS APPL, V78, P9895, DOI 10.1007/s11042-018-6611-3
   Zampoglou M, 2017, MULTIMED TOOLS APPL, V76, P4801, DOI 10.1007/s11042-016-3795-2
   Zeng H, 2017, MULTIMED TOOLS APPL, V76, P4783, DOI 10.1007/s11042-016-3712-8
   Zhang DP, 2019, MULTIMED TOOLS APPL, V78, P22223, DOI 10.1007/s11042-019-7408-8
NR 35
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28443
EP 28459
DI 10.1007/s11042-023-16534-z
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001059026300015
DA 2024-07-18
ER

PT J
AU Yechuri, S
   Vanambathina, S
AF Yechuri, Sivaramakrishna
   Vanambathina, Sunnydayal
TI Single channel speech enhancement using iterative constrained NMF based
   adaptive wiener gain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE NMF; Adaptive wiener gain; Inverse nakagami; Erlang; Inverse gamma;
   Students-t probability density functions; SDR; PESQ; STOI
ID NONNEGATIVE MATRIX FACTORIZATION; ALGORITHMS; EXTRACTION; MACHINE;
   FILTER
AB We propose a novel single channel speech enhancement algorithm using iterative constrained Non-negative matrix factorization (NMF) based adaptive Wiener gain for non-stationary noise. In the recent past, NMF-based Wiener filtering methods were used for speech enhancement. The Wiener filter performance depends on the adaptive gain factor value. The adaptive gain factor (alpha) value is constant regardless of noise type and signal to noise ratio (SNR), so it will affect speech enhancement performance. To overcome this, the adaptive factor value is calculated using a genetic algorithm (GA). Here, the GA adjusts the adaptive Wiener gain based on noise type and SNR level. The GA-based adaptive Wiener gain minimizes Wiener filter estimation errors and improves speech quality by adjusting the base vector weights of noise and speech. Additionally, we use the iterative constraints NMF (IC-NMF) method for calculating the priors from noisy speech magnitudes. We select the Erlang, Inverse Gamma, Students-t, and Inverse Nakagami distributions for speech priors and Gaussian distributions for noise priors. Noise and speech samples are well correlated with those distributions. This provides accurate estimation of the necessary statistics of these distributions to regularize the NMF criterion. So, we combine an iterative constrained NMF and a genetic algorithm-based adaptive Wiener filtering method for speech enhancement. The proposed method outperforms other benchmark algorithms in terms of source to distortion ratio (SDR), short-time objective intelligibility (STOI), and perceptual evaluation of speech quality (PESQ).
C1 [Yechuri, Sivaramakrishna; Vanambathina, Sunnydayal] VIT AP Univ, SENSE, Amaravati, India.
C3 VIT-AP University
RP Yechuri, S (corresponding author), VIT AP Univ, SENSE, Amaravati, India.
EM sivaramakrishna.20phd7163@vitap.ac.in; sunny.dayal@vitap.ac.in
CR Andrew AM, 1993, ROBOTICA, V11, P489, DOI DOI 10.1017/S0263574700017136
   Babaee M, 2016, NEUROCOMPUTING, V173, P245, DOI 10.1016/j.neucom.2015.03.121
   Barnett V, 1975, APPL LINEAR STAT MOD
   Berry MW, 2007, COMPUT STAT DATA AN, V52, P155, DOI 10.1016/j.csda.2006.11.006
   Bryan Nicholas., 2013, International Conference on Machine Learning, P208
   Chen WS, 2016, NEUROCOMPUTING, V205, P165, DOI 10.1016/j.neucom.2016.04.014
   Cichocki A, 2011, ENTROPY-SWITZ, V13, P134, DOI 10.3390/e13010134
   Cruces-Alvarez SA, 2004, IEEE T NEURAL NETWOR, V15, P859, DOI 10.1109/TNN.2004.828764
   Fakhry M, 2018, EUR SIGNAL PR CONF, P16, DOI 10.23919/EUSIPCO.2018.8553123
   Févotte C, 2009, NEURAL COMPUT, V21, P793, DOI 10.1162/neco.2008.04-08-771
   Han M, 2015, NEUROCOMPUTING, V149, P65, DOI 10.1016/j.neucom.2013.09.070
   Hoyer PO, 2002, NEURAL NETWORKS FOR SIGNAL PROCESSING XII, PROCEEDINGS, P557, DOI 10.1109/NNSP.2002.1030067
   Hu H, 2013, SENSORS-BASEL, V13, P878
   Kubo Y, 2020, IEEE-ACM T AUDIO SPE, V28, P1948, DOI 10.1109/TASLP.2020.3003165
   Lai YH, 2019, IEEE ACCESS, V7, P43286, DOI 10.1109/ACCESS.2019.2907175
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Li JF, 2011, SPEECH COMMUN, V53, P677, DOI 10.1016/j.specom.2010.04.009
   Lin CJ, 2007, IEEE T NEURAL NETWOR, V18, P1589, DOI 10.1109/TNN.2007.895831
   Liu HF, 2012, IEEE T PATTERN ANAL, V34, P1299, DOI 10.1109/TPAMI.2011.217
   Louzada F, 2018, IEEE T RELIAB, V67, P1030, DOI 10.1109/TR.2018.2829721
   Paliwal K, 2012, SPEECH COMMUN, V54, P282, DOI 10.1016/j.specom.2011.09.003
   Recommendation I.-T., 2001, Rec. ITU-T P. 862
   Rehr R, 2018, IEEE-ACM T AUDIO SPE, V26, P357, DOI 10.1109/TASLP.2017.2778151
   Salehi H, 2021, INT J IMAGE GRAPH, V21, DOI 10.1142/S0219467821500364
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881
   TUKEY JW, 1949, BIOMETRICS, V5, P99, DOI 10.2307/3001913
   Vincent E, 2006, IEEE T AUDIO SPEECH, V14, P1462, DOI 10.1109/TSA.2005.858005
   Yamaguchi Y, 2010, COMMUN STAT-THEOR M, V39, P2333, DOI 10.1080/03610926.2010.483306
   Yechuri Sivaramakrishna, 2023, Machine Learning, Image Processing, Network Security and Data Sciences: Select Proceedings of 3rd International Conference on MIND 2021. Lecture Notes in Electrical Engineering (946), P575, DOI 10.1007/978-981-19-5868-7_42
   Yoshii K, 2016, INT CONF ACOUST SPEE, P51, DOI 10.1109/ICASSP.2016.7471635
NR 30
TC 1
Z9 1
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26233
EP 26254
AR s11042-023-16480-w
DI 10.1007/s11042-023-16480-w
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060692700003
DA 2024-07-18
ER

PT J
AU Awasthi, D
   Srivastava, VK
AF Awasthi, Divyanshu
   Srivastava, Vinay Kumar
TI Multiple image watermarking with dual authentication for smart and safe
   city environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Authentication; Secured cities; Advanced encryption standard; Chaotic
   logistic map; BRISK; MinEigen
ID LIFTING SCHEME; DWT; SVD; TRANSFORM; CONSTRUCTION
AB The drastic advancement in medical data volume is a big concern for researchers to prevent it from forgery. The presented dual image watermarking technique is proposed to increase the robustness and imperceptibility along with enhanced security. Two-level authentication is utilized to prevent forgery: the first level uses an advanced encryption standard (AES) to verify the patient's identity, while the second level uses BRISK (Binary robust invariant scalable keypoints) and MinEigen features to verify watermarked images. The proposed technique uses the combination of lifting wavelet transform (LWT) and randomized singular value decomposition (RSVD) to enhance the efficiency. LWT is faster than discrete wavelet transforms (DWT) and RSVD is faster than SVD. To further enhance the security of MNNIT logo, chaotic logistic map encryption is used. Aadhar card of patient is used as the first watermark and MNNIT logo as the second. Ultrasound DICOM (digital imaging and communications in medicine) liver image is used as a test image. Peak signal-to-noise ratio (PSNR), Normalized correlation coefficient (NCC), Structural similarity index measurement (SSIM), Kullback-Leibler (KLD) and Jensen-Shannon (JSD) distances are used as the performance parameters. The results of the proposed technique concluded that it has much higher robustness and imperceptibility along with two-level authentication security verification.
C1 [Awasthi, Divyanshu; Srivastava, Vinay Kumar] Motilal Nehru Natl Inst Technol, Elect & Commun Engn Dept, Prayagraj 211004, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Awasthi, D (corresponding author), Motilal Nehru Natl Inst Technol, Elect & Commun Engn Dept, Prayagraj 211004, Uttar Pradesh, India.
EM divyanshuawasthi83@gmail.com; vinay@mnnit.ac.in
RI awasthi, divyanshu/ABX-1965-2022; Srivastava, Vinay Kumar/AAL-2501-2021
OI awasthi, divyanshu/0000-0002-1764-772X; Srivastava, Vinay
   Kumar/0000-0002-7993-0993
CR Abdullah A.M, 2017, Cryptogr. Netw. Secur., V16, P1
   Agarwal N, 2019, MULTIMED TOOLS APPL, V78, P8603, DOI 10.1007/s11042-018-7128-5
   Anand A, 2023, IEEE T IND INFORM, V19, P849, DOI 10.1109/TII.2022.3172622
   Anand A, 2023, IEEE T COMPUT SOC SY, V10, P2033, DOI 10.1109/TCSS.2022.3140862
   Anand A, 2020, 2020 IEEE SIXTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2020), P366, DOI 10.1109/BigMM50055.2020.00063
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   Awasthi D, 2023, MULTIMED TOOLS APPL, V82, P35685, DOI 10.1007/s11042-023-14723-4
   Awasthi D, 2023, MULTIMED TOOLS APPL, V82, P16555, DOI 10.1007/s11042-022-14002-8
   Awasthi D, 2022, MULTIMED TOOLS APPL, V81, P25075, DOI 10.1007/s11042-022-12456-4
   Bagan DKB, 2011, Arxiv, DOI arXiv:1103.3792
   Chen Y, 2020, IEEE ACCESS, V8, P30628, DOI 10.1109/ACCESS.2020.2973044
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Furqan A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P638, DOI 10.1109/CICT.2015.74
   Gong LH, 2021, MULTIMED TOOLS APPL, V80, P439, DOI 10.1007/s11042-020-09677-w
   Hurrah NN, 2019, FUTURE GENER COMP SY, V94, P654, DOI 10.1016/j.future.2018.12.036
   Jane O, 2014, J APPL RES TECHNOL, V12, P750, DOI 10.1016/S1665-6423(14)70091-4
   Khare P, 2021, J INTELL SYST, V30, P297, DOI 10.1515/jisys-2019-0046
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Liu JX, 2019, IEEE ACCESS, V7, P80849, DOI 10.1109/ACCESS.2019.2915596
   Misra MK, 2021, IN 2021 5 INT C INF, P1
   Nandi S, 2016, ADV INTELL SYST, V394, P69, DOI 10.1007/978-81-322-2656-7_7
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Sinhal R, 2021, PATTERN RECOGN LETT, V145, P171, DOI 10.1016/j.patrec.2021.02.011
   Soualmi A, 2021, MULTIMED TOOLS APPL, V80, P2279, DOI 10.1007/s11042-020-09614-x
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   Thakkar F, 2017, TURK J ELECTR ENG CO, V25, P3273, DOI 10.3906/elk-1603-17
   Thakur S, 2020, LECT NOTES ELECTR EN, V587, P897, DOI 10.1007/978-981-32-9775-3_80
   Verma VS, 2015, EXPERT SYST APPL, V42, P8184, DOI 10.1016/j.eswa.2015.06.041
   Ye HS, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107652
   Zear A, 2018, J INTELL SYST, V27, P5, DOI 10.1515/jisys-2016-0036
   Zhang LN, 2019, MULTIMED TOOLS APPL, V78, P28003, DOI 10.1007/s11042-019-07902-9
   Zhou NR, 2019, MULTIMED TOOLS APPL, V78, P2507, DOI 10.1007/s11042-018-6322-9
   Zhou NR, 2018, MULTIMED TOOLS APPL, V77, P30251, DOI 10.1007/s11042-018-6128-9
   Zhou NR, 2018, OPT LASER ENG, V110, P72, DOI 10.1016/j.optlaseng.2018.05.014
NR 35
TC 0
Z9 0
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 25
PY 2023
DI 10.1007/s11042-023-16523-2
EA AUG 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q8TX7
UT WOS:001060201500004
DA 2024-07-18
ER

PT J
AU Rajaram, K
   Amma, NGB
   Guptha, AS
   Selvakumar, S
AF Rajaram, Kanchana
   Amma, N. G. Bhuvaneswari
   Guptha, Ashwin S.
   Selvakumar, S.
TI CLNet: a contactless fingerprint spoof detection using deep neural
   networks with a transfer learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric security; Contactless fingerprints; Convolutional neural
   networks; Fingerprint spoof detection; Transfer learning
ID SECURITY; SYSTEMS; ATTACK; CONVOLUTION
AB Biometric fingerprint verification and identification have been extensively used in real life applications as an authentication and access control mechanism. Newer contactless fingerprint scanning technology offers high convenience and hygiene, especially in the view of COVID-19. Attackers still challenge the biometric security offered by contactless scanners by illegitimate acquisition of the user's fingerprint through various spoofing methods. Therefore, detection of contactless fingerprint spoof is on the urge to protect the biometric security systems. The existing solutions to contactless fingerint spoof detection face the lacuna of considering limited fingerprint features leading to low spoof detection accuracy. In this study, this issue has been addressed and CLNet (Contact Less Network) approach is proposed to detect the spoofness in contactless fingerprints. The proposed CLNet is a deep neural network approach utilizing contactless fingerprint images followed by a transfer learning approach called SpoofDetNet which is based on the MobileNetV2 model. The motivation for the development of the SpoofDetNet is to create a spoof detection method viable for contactless fingerprint images as well as contact-based fingerprint images which stand strong among state-of-the-art models. We created a Spoofed-Contactless Adult Fingerprint (S-CLAF) dataset with live and spoof contactless fingerprint images. The CLNet approach was trained and tested on S-CLAF dataset and it achieved an accuracy of 99.07% across all spoofed materials. Furthermore, the proposed approach was tested using LivDet 2015 benchmark dataset and IIT Bombay touchless fingerprint dataset achieving accuracy of 98.32% and 99.38% respectively. It is evident from the experimental results that the proposed CLNet outperforms the state-of-the-art fingerprint spoof detection methods.
C1 [Rajaram, Kanchana] Sri Sivasubramaniya Nadar Coll Engn, Dept Comp Sci & Engn, Chennai 603110, Tamil Nadu, India.
   [Amma, N. G. Bhuvaneswari; Guptha, Ashwin S.] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai Campus, Chennai 600127, Tamil Nadu, India.
   [Selvakumar, S.] Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli 620015, Tamil Nadu, India.
   [Selvakumar, S.] Indian Inst Informat Technol, Una 177209, Himachal Prades, India.
C3 SSN College of Engineering; Vellore Institute of Technology (VIT); VIT
   Chennai; National Institute of Technology (NIT System); National
   Institute of Technology Tiruchirappalli
RP Rajaram, K (corresponding author), Sri Sivasubramaniya Nadar Coll Engn, Dept Comp Sci & Engn, Chennai 603110, Tamil Nadu, India.
EM rkanch@ssn.edu.in; bhuvaneswariamma.ng@vit.ac.in;
   ashwins.guptha2018@vitstudent.ac.in; ssk@nitt.edu
OI rajaram, kanchana/0000-0002-2591-2482; Amma N. G., Dr.
   Bhuvaneswari/0000-0003-3660-380X
FU Grand Challenges India (GCI) for Immunization Data - Biotechnology
   Industry Research Assistance Council (BIRAC); Bill& Melinda Gates
   foundation
FX This work was supported by Grand Challenges India (GCI) for Immunization
   Data funded by Biotechnology Industry Research Assistance Council
   (BIRAC) and jointly funded by Bill& Melinda Gates foundation under the
   project titled Nagarik Rog Pratirakshak: Unified Smart Immunization
   Coverage Monitoring and Analysis (NRP-UniSICMA).
CR Agarwal R, 2020, MOD PHYS LETT B, V34, DOI 10.1142/S021798492030001X
   Agarwal S, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2019.113160
   Amma NGN, 2024, IETE J RES, V70, P467, DOI 10.1080/03772063.2022.2108917
   Anusha BVS, 2020, IEEE WINT CONF APPL, P2684, DOI 10.1109/WACV45572.2020.9093397
   Arora SS, 2016, IEEE T INF FOREN SEC, V11, P2284, DOI 10.1109/TIFS.2016.2581306
   Baldisserra D, 2006, LECT NOTES COMPUT SC, V3832, P265
   Biggio B, 2012, IET BIOMETRICS, V1, P11, DOI 10.1049/iet-bmt.2011.0012
   Birajadar P, 2019, SADHANA-ACAD P ENG S, V44, DOI 10.1007/s12046-019-1138-5
   Cheng X, 2023, FUTURE GENER COMP SY, V146, P114, DOI 10.1016/j.future.2023.04.012
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Chugh T, 2021, IEEE T INF FOREN SEC, V16, P42, DOI 10.1109/TIFS.2020.2990789
   Chugh T, 2018, IEEE T INF FOREN SEC, V13, P2190, DOI 10.1109/TIFS.2018.2812193
   Dwivedi Rudresh, 2021, ICMVA 2021: 2021 International Conference on Machine Vision and Applications., P8, DOI 10.1145/3459066.3459068
   Galbally J, 2020, IEEE ACCESS, V8, P145513, DOI 10.1109/ACCESS.2020.3014796
   Garg H, 2022, MULTIMED TOOLS APPL, V81, P26873, DOI 10.1007/s11042-021-11578-5
   Ghiani L, 2017, IMAGE VISION COMPUT, V58, P110, DOI 10.1016/j.imavis.2016.07.002
   Gragnaniello D, 2015, IEEE T INF FOREN SEC, V10, P849, DOI 10.1109/TIFS.2015.2404294
   Grosz StevenA., 2020, 2020 IEEE INT JOINT, P1
   Hadid A, 2015, IEEE SIGNAL PROC MAG, V32, P20, DOI 10.1109/MSP.2015.2437652
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang QG, 2015, PATTERN RECOGN LETT, V60-61, P1, DOI 10.1016/j.patrec.2015.03.015
   Ishfaq Rutbaa, 2021, 2021 Fourth International Conference on Computational Intelligence and Communication Technologies (CCICT), P22, DOI 10.1109/CCICT53244.2021.00016
   Jomaa RM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072085
   Kolberg J, 2020, ARXIV
   Kumar TKA, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), P243, DOI [10.1109/iccs45141.2019.9065713, 10.1109/ICCS45141.2019.9065713]
   Li H., 2023, arXiv
   Liu F, 2020, NEUROCOMPUTING, V402, P14, DOI 10.1016/j.neucom.2020.03.102
   Liu F, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107208
   Maheswari BU, 2022, NEURAL COMPUT APPL, V34, P8617, DOI 10.1007/s00521-021-06758-1
   Menotti D, 2015, IEEE T INF FOREN SEC, V10, P864, DOI 10.1109/TIFS.2015.2398817
   Moraru L., 2018, Soft Computing Based Medical Image Analysis, P149
   Nogueira RF, 2016, IEEE T INF FOREN SEC, V11, P1206, DOI 10.1109/TIFS.2016.2520880
   Peralta D, 2015, INFORM SCIENCES, V315, P67, DOI 10.1016/j.ins.2015.04.013
   Rayani PK, 2023, MULTIMED TOOLS APPL, V82, P1633, DOI 10.1007/s11042-022-13245-9
   Rehman YAU, 2018, EXPERT SYST APPL, V108, P159, DOI 10.1016/j.eswa.2018.05.004
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sasi N.M., 2013, Engineering, V5, P326, DOI DOI 10.4236/ENG.2013.510B066
   Sousedik C, 2014, IET BIOMETRICS, V3, P219, DOI 10.1049/iet-bmt.2013.0020
   Tan HZ, 2020, IEEE T INF FOREN SEC, V15, P3924, DOI 10.1109/TIFS.2020.3001732
   THENTU S, 2021, 2021 IEEE INT C CONS, P1
   Tuesta-Monteza VA, 2021, LECT NOTES COMPUT SC, V12725, P231, DOI 10.1007/978-3-030-77004-4_22
   Uliyan DM, 2020, ENG SCI TECHNOL, V23, P264, DOI 10.1016/j.jestch.2019.06.005
   Yuan CS, 2022, IEEE T COGN DEV SYST, V14, P648, DOI 10.1109/TCDS.2021.3062624
   Zhang YL, 2019, IEEE ACCESS, V7, P91476, DOI 10.1109/ACCESS.2019.2927357
   Zhang Z, 2021, PATTERN RECOGN, V120, DOI 10.1016/j.patcog.2021.108189
NR 45
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27703
EP 27722
DI 10.1007/s11042-023-16511-6
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001064537600004
DA 2024-07-18
ER

PT J
AU Saxena, D
   Patel, P
AF Saxena, Drishti
   Patel, Prabhat
TI Arnold transform and blockchain based signcryption scheme for novel
   reversible data hiding (RDH) technology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data embedding; RDH; PSNR; SSIM; Arnold transform; Block chain
ID IMAGE ENCRYPTION ALGORITHM; HIGH-CAPACITY; WATERMARKING SCHEME;
   INTERPOLATION; EFFICIENT; ROBUST
AB Information sharing mechanisms are becoming quicker and more efficient owing to improvements in computer and internet technologies. Data protection is an important consideration when exchanging and communicating data. Digital image encryption has rapidly evolved as an efficient scheme for ensuring data security. Data hiding technology can be used in multidisciplinary fields like healthcare, copyright protection, defence, etc. It is further important to note that the hidden data must be encrypted before transmission, and encrypted data must be secured over the transmission medium. In this paper, a detailed mechanism is proposed for data hiding, encryption, and security. First of all, a multilayer data hiding mechanism that considers interpolation of pixels and histogram shifting for data embedding is considered. Thereafter, for encryption of images, the Arnold transform is used, and finally, for security of encrypted data, the blockchain is used. The results of various state-of-the-art approaches are detailed, and it is shown that both data embedding and encryption algorithms perform better than recently published works.
C1 [Saxena, Drishti] Rajiv Gandhi Proudyogiki Vishwavidyalaya, Bhopal, India.
   [Patel, Prabhat] Rajiv Gandhi Proudyogiki Vishwavidyalaya, Dept ECE, Bhopal, India.
C3 Rajiv Gandhi Technological University; Rajiv Gandhi Technological
   University
RP Saxena, D (corresponding author), Rajiv Gandhi Proudyogiki Vishwavidyalaya, Bhopal, India.
EM dristeesaxenaphd@gmail.com; peekaypatel@gmail.com
CR Abadi M. A. M., 2010, 2010 5th International Symposium on Telecommunications (IST), P840, DOI 10.1109/ISTEL.2010.5734139
   Abd EL-Latif AA, 2020, OPT LASER TECHNOL, V124, DOI 10.1016/j.optlastec.2019.105942
   Abd El-Latif AA, 2013, OPT LASER TECHNOL, V54, P389, DOI 10.1016/j.optlastec.2013.04.018
   Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Alhadhrami Z., 2017, 2017 INT C EL COMP T, P1, DOI DOI 10.1109/ICECTA.2017.8251967
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Chetan KR, 2015, J INF SECUR APPL, V24-25, P13, DOI 10.1016/j.jisa.2015.07.002
   Chowdhuri Partha, 2021, International Journal of Computers and Applications, P38, DOI 10.1080/1206212X.2018.1505024
   Chowdhuri P., 2018, INF TECHNOL APPL MAT, V2017, P163
   Das Prasenjit Kumar., 2014, ADV ELECTR ELECTRON, V4, P179
   Dey S., 2012, INT J MODERN ED COMP, V4, P59, DOI [10.5815/ijmecs.2012.06.08, DOI 10.5815/IJMECS.2012.06.08]
   Dey S, 2013, INT CONF COMM SYST, P512, DOI 10.1109/CSNT.2013.112
   Ekodeck SGR, 2016, J INF SECUR APPL, V29, P1, DOI 10.1016/j.jisa.2015.11.008
   Farwa S, 2017, INT J ADV COMPUT SC, V8, P360
   Gaffar AF., 2020, INT J ADV INTELL INF, V6, P290, DOI [10.26555/ijain.v6i3.422, DOI 10.26555/IJAIN.V6I3.422]
   Ge HL, 2019, IEEE T CIRC SYST VID, V29, P2285, DOI 10.1109/TCSVT.2018.2863029
   Gupta AK, 2012, SADHANA-ACAD P ENG S, V37, P425, DOI 10.1007/s12046-012-0089-x
   Hassan FS, 2020, MULTIMED TOOLS APPL, V79, P30087, DOI 10.1007/s11042-020-09513-1
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hsu FH, 2013, MULTIMED TOOLS APPL, V67, P571, DOI 10.1007/s11042-012-1047-7
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Jie H., 2015, COMPUT ELECTR ENG, DOI [10.1016/j.compeleceng.2015.04.01, DOI 10.1016/J.COMPELECENG.2015.04.01]
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Jung TH, 2016, IEEE T INF FOREN SEC, V11, P868, DOI 10.1109/TIFS.2015.2509946
   Kaur G, 2021, ARCH COMPUT METHOD E, V28, P3517, DOI 10.1007/s11831-020-09512-3
   Keshavarzian R, 2016, AEU-INT J ELECTRON C, V70, P278, DOI 10.1016/j.aeue.2015.12.003
   Khan JS, 2019, MULTIDIM SYST SIGN P, V30, P943, DOI 10.1007/s11045-018-0589-x
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   Khan M, 2019, WIRELESS PERS COMMUN, V109, P849, DOI 10.1007/s11277-019-06594-6
   Khan M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206460
   Khashandarag AS, 2011, INT J COMPUT SCI, V8, P113
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Liang XK, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419540223
   Lingling Wu, 2009, 2009 1st International Conference on Information Science and Engineering (ICISE 2009), P1164, DOI 10.1109/ICISE.2009.347
   Liu ZJ, 2013, OPT LASER ENG, V51, P8, DOI 10.1016/j.optlaseng.2012.08.004
   Liu ZT, 2019, IEEE ACCESS, V7, P78367, DOI 10.1109/ACCESS.2019.2922376
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Malik A, 2020, MULTIMED TOOLS APPL, V79, P18005, DOI 10.1007/s11042-020-08691-2
   Mao YB, 2005, HANDBOOK OF GEOMETRIC COMPUTING: APPLICATIONS IN PATTERN RECOGNITION, COMPUTER VISION, NEURALCOMPUTING, AND ROBOTICS, P231, DOI 10.1007/3-540-28247-5_8
   Molina-Garcia J, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115725
   Munoz-Ramirez David-Octavio, 2019, 2019 IEEE International Scientific-Practical Conference Problems of Infocommunications, Science and Technology (PIC S&T). Proceedings, P63, DOI 10.1109/PICST47496.2019.9061223
   Naheed T., 2014, OPTIK, DOI [10.1016/j.ijleo.2013.10.2014.Elsevier, DOI 10.1016/J.IJLEO.2013.10.2014.ELSEVIER]
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Nyame G, 2020, INFORMATION, V11, DOI 10.3390/info11020111
   Ou B, 2012, NEUROCOMPUTING, V93, P67, DOI 10.1016/j.neucom.2012.04.021
   Pal P, 2019, SECUR PRIVACY, V2, DOI 10.1002/spy2.59
   Parah SA, 2017, STUD COMPUT INTELL, V660, P371, DOI 10.1007/978-3-319-44790-2_17
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P6473, DOI 10.1007/s11042-016-3301-x
   Reddy V. L., 2011, Proceedings of the 2011 International Conference on Ubiquitious Computing and Multimedia Applications (UCMA 2011), P42, DOI 10.1109/UCMA.2011.17
   Sen-Ren Jan, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P185, DOI 10.1109/IIHMSP.2011.88
   Shi X, 2013, INFORM SCIENCES, V240, P173, DOI 10.1016/j.ins.2013.03.031
   Soleimani M, 2012, SCI ACAD TRANSACT CO, V2, P122
   Tang MW, 2014, OPTIK, V125, P3972, DOI 10.1016/j.ijleo.2014.01.149
   Tariq S, 2020, MULTIMED TOOLS APPL, V79, P23507, DOI 10.1007/s11042-020-09134-8
   Tirkel Andrew Z., 1995, DICTA, V95, P5
   Tseng HW, 2009, INFORM SCIENCES, V179, P2460, DOI 10.1016/j.ins.2009.03.014
   Voloshynovskiy S, 2001, IEEE COMMUN MAG, V39, P118, DOI 10.1109/35.940053
   Wang HQ, 2020, FUTURE GENER COMP SY, V107, P854, DOI 10.1016/j.future.2017.06.028
   Wang XT, 2013, DIGIT SIGNAL PROCESS, V23, P569, DOI 10.1016/j.dsp.2012.06.015
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wu HQ, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511489
   Wu JJ, 2021, MULTIMED TOOLS APPL, V80, P2647, DOI 10.1007/s11042-020-09828-z
   Wu Q, 2016, J INF SECUR APPL, V26, P1, DOI 10.1016/j.jisa.2015.08.003
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2014, SIGNAL PROCESS, V102, P122, DOI 10.1016/j.sigpro.2014.03.015
   Yan XH, 2015, MULTIMED TOOLS APPL, V74, P3231, DOI 10.1007/s11042-013-1784-2
   Yang FF, 2019, IEEE ACCESS, V7, P58751, DOI 10.1109/ACCESS.2019.2914722
   Ye GD, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500104
   Ye GD, 2012, NONLINEAR DYNAM, V69, P2079, DOI 10.1007/s11071-012-0409-z
   Zhang XQ, 2017, MULTIMED TOOLS APPL, V76, P9195, DOI 10.1007/s11042-016-3521-0
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zheng ZB, 2017, IEEE INT CONGR BIG, P557, DOI 10.1109/BigDataCongress.2017.85
NR 74
TC 0
Z9 0
U1 6
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25135
EP 25162
DI 10.1007/s11042-023-16460-0
EA AUG 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001052828600005
DA 2024-07-18
ER

PT J
AU Sivakumar, D
   Devi, SS
   Nalini, T
AF Sivakumar, Deena
   Devi, S. Suganthi
   Nalini, T.
TI Energy aware clustering protocol using chaotic gorilla troops
   optimization algorithm for Wireless Sensor Networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Energy efficiency; Network lifetime; WSN; Clustering; Metaheuristics;
   Fitness function
AB Energy efficiency is treated as a challenging problem in Wireless Sensor Networks (WSNs) which involves limited non-replaceable and non-rechargeable inbuilt batteries. Optimal utilization of available energy in the sensor nodes is an effective way to improve the lifetime of the WSN with assured quality of service (QoS). Clustering can be employed as an efficient approach for enhancing network lifetime and scalability. Since clustering is considered an NP-hard problem, several metaheuristic algorithms are utilized for accomplishing energy efficiency. With this motivation, this study proposes an energy-aware clustering protocol utilizing a chaotic gorilla troops optimization algorithm (EACP-CGTOA) for WSN. The proposed EACP-CGTOA model derives a CGTOA by replacing the population initiation with circle chaotic mapping to explore the solutions with a high convergence rate and sensitivity. The CGTOA helps to increase the population diversity and overall performance of the optimization algorithm. Besides, the EACP-CGTOA model derives a fitness function involving three input parameters namely distance to neighbours (DTN), distance to base station (DBS), and energy ratio (ER). To ensure the enhanced performance of the EACP-CGTOA technique, a wide range of simulations were carried out and the outcomes are examined under several aspects. The experimental results ensured that the network lifetime and energy efficiency are considerably improved by the EACP-CGTOA model over the existing methods.
C1 [Sivakumar, Deena] Annamalai Univ, Dept CSE, Chidambaram, India.
   [Devi, S. Suganthi] Srinivasa Subbaraya Polytech Coll, Dept CSE, Puttur, Sirkali, India.
   [Nalini, T.] Saveetha Sch Engn SIMATS, Dept CSE, Chennai, India.
C3 Annamalai University; Saveetha Institute of Medical & Technical Science;
   Saveetha School of Engineering
RP Sivakumar, D (corresponding author), Annamalai Univ, Dept CSE, Chidambaram, India.
EM deena.dob21@gmail.com; suganthidevi@yahoo.com; nalinit.sse@saveetha.com
RI T, Nalini/AAX-8394-2020
OI T, Nalini/0000-0002-3425-6317
CR Abdollahzadeh B, 2021, INT J INTELL SYST, V36, P5887, DOI 10.1002/int.22535
   Arjunan S, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3811
   Arjunan S, 2019, J KING SAUD UNIV-COM, V31, P304, DOI 10.1016/j.jksuci.2017.03.006
   Arjunan S, 2018, APPL INTELL, V48, P2229, DOI 10.1007/s10489-017-1077-y
   Bai Y, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/4489436
   Bhushan B., 2021, WIRELESS PERS COMMUN, V2021, P1
   Bozorgi SM, 2021, SOFT COMPUT, V25, P5663, DOI 10.1007/s00500-020-05563-7
   Daniel J, 2021, WIREL NETW, V27, P5245, DOI 10.1007/s11276-021-02812-x
   Famila S, 2020, PEER PEER NETW APPL, V13, P1071, DOI 10.1007/s12083-019-00805-4
   Gorgich S, 2021, WIRELESS PERS COMMUN, V119, P1935, DOI 10.1007/s11277-021-08312-7
   Kalburgi SS, 2022, MULTIMED TOOLS APPL, V81, P15815, DOI 10.1007/s11042-022-12302-7
   Kotary DK, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107650
   Rambabu B, 2022, J KING SAUD UNIV-COM, V34, P1895, DOI 10.1016/j.jksuci.2019.12.006
   Rao PCS, 2021, MULTIMED TOOLS APPL, V80, P26093, DOI 10.1007/s11042-021-10901-4
   Raslan AF, 2021, IEEE ACCESS, V9, P156171, DOI 10.1109/ACCESS.2021.3126537
   Reddy DL, 2021, IET COMMUN, V15, P1561, DOI 10.1049/cmu2.12169
   Subramanian P, 2020, WIRELESS PERS COMMUN, V113, P905, DOI 10.1007/s11277-020-07259-5
   Suresh K, 2023, COMPUT J, V66, P1126, DOI 10.1093/comjnl/bxac002
   Uthayakumar J, 2020, IEEE T RELIAB, V69, P1398, DOI 10.1109/TR.2020.2972567
   Uthayakumar J, 2019, AD HOC NETW, V83, P149, DOI 10.1016/j.adhoc.2018.09.009
   Wang MH, 2020, AD HOC NETW, V102, DOI 10.1016/j.adhoc.2020.102138
   Xiao YN, 2022, CMES-COMP MODEL ENG, V131, P815, DOI 10.32604/cmes.2022.019198
   Yadav RK, 2021, COMPUT SCI REV, V41, DOI 10.1016/j.cosrev.2021.100417
NR 23
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 19
PY 2023
DI 10.1007/s11042-023-16487-3
EA AUG 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P4RW8
UT WOS:001050545200002
DA 2024-07-18
ER

PT J
AU Ye, MQ
   Luo, YM
AF Ye, Mengqi
   Luo, Yanmin
TI A deep convolution neural network fusing of color feature and
   spatio-temporal feature for smoke detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE smoke detection; color feature matrix; spatio-temporal features; full
   high resolution
ID IMAGE; RESOLUTION
AB The spatial characteristics, movement characteristics and color characteristics of smoke are important features that distinguish them to other objects. In order to make full use of these three features, we proposed a deep convolutional network called Full High Resolution Network(FHRNet).This network consists of two parts: Spatio-Temporal-aware Sub-network (STS) and Color-aware Sub-network (CS). We build high -resolution residual symmetrical units and embed the two sub-networks to ensure the integrity of two dimensional features.In the STS, the residual symmetrical unit extracts the spatial semantic characteristics of smoke from every frame, and combine them into a feature sequence, then the spatio-temporal perceptron is used to extract the spatio-temporal characteristics of smoke to further improve the characteristic expression. In the CS, the color feature of picture is converted into color feature matrix, which is easier to make the residual symmetrical unit to extract the color feature of smoke. We constructed a smoke vedio datasets which have a diverse background to avoid producing over-fitting situation.The experimental results show that mthod we proposed can effectively extract the color features and the spatio-temporal features of smoke and our method can effectively detect smoke.
C1 [Ye, Mengqi; Luo, Yanmin] Huaqiao Univ, Coll Comp Sci & Technol, Xiamen 361021, Peoples R China.
   [Ye, Mengqi; Luo, Yanmin] Huaqiao Univ, Key Lab Comp Vis & Pattern Recognit, Xiamen 361021, Peoples R China.
C3 Huaqiao University; Huaqiao University
RP Luo, YM (corresponding author), Huaqiao Univ, Coll Comp Sci & Technol, Xiamen 361021, Peoples R China.; Luo, YM (corresponding author), Huaqiao Univ, Key Lab Comp Vis & Pattern Recognit, Xiamen 361021, Peoples R China.
EM lym@hqu.edu.cn
RI Ye, Mengqi/AAU-7661-2021; Liu, Jinyu/JYQ-6274-2024; xiao,
   ming/KHT-1774-2024
OI Ye, Mengqi/0000-0003-4074-4744; 
CR Cai W., 2020, 2020 CROSS STRAIT RA
   Calderara S, 2011, MACH VISION APPL, V22, P705, DOI 10.1007/s00138-010-0272-1
   Cao YC, 2022, MULTIMED TOOLS APPL, V81, P10261, DOI 10.1007/s11042-021-11766-3
   Cao YC, 2019, IEEE ACCESS, V7, P154732, DOI 10.1109/ACCESS.2019.2946712
   Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.3115/V1/D14-1179, 10.48550/ARXIV.1406.1078, DOI 10.48550/ARXIV.1406.1078]
   Dimitropoulos K, 2017, IEEE T CIRC SYST VID, V27, P1143, DOI 10.1109/TCSVT.2016.2527340
   Ghosh R, 2022, MULTIMED TOOLS APPL, V81, P38643, DOI 10.1007/s11042-022-13068-8
   Gubbi J, 2009, FIRE SAFETY J, V44, P1110, DOI 10.1016/j.firesaf.2009.08.003
   Jeong M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195508
   Ji H, 2013, IEEE T IMAGE PROCESS, V22, P286, DOI 10.1109/TIP.2012.2214040
   Jia Y, 2016, FIRE TECHNOL, V52, P1271, DOI 10.1007/s10694-014-0453-y
   Khan S, 2019, IEEE INTERNET THINGS, V6, P9237, DOI 10.1109/JIOT.2019.2896120
   Ko BC, 2011, IEEE T CIRC SYST VID, V21, P1903, DOI 10.1109/TCSVT.2011.2157190
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lin GH, 2019, FIRE TECHNOL, V55, P1827, DOI 10.1007/s10694-019-00832-w
   Luo YM, 2018, MULTIMED TOOLS APPL, V77, P15075, DOI 10.1007/s11042-017-5090-2
   Malhotra P., 2015, ESANN, V89, P89
   Morerio P, 2012, IEEE IMAGE PROC, P1041, DOI 10.1109/ICIP.2012.6467041
   Park KM, 2020, IET IMAGE PROCESS, V14, P1141, DOI 10.1049/iet-ipr.2018.5305
   Sharma J, 2017, COMM COM INF SC, V744, P183, DOI 10.1007/978-3-319-65172-9_16
   Shi XJ, 2015, ADV NEUR IN, V28
   Shiping Ye, 2017, Pattern Recognition and Image Analysis, V27, P131
   STRICKER M, 1995, P SOC PHOTO-OPT INS, V2410, P381, DOI 10.1117/12.205308
   Sural S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P589
   Tao HJ, 2023, EXPERT SYST APPL, V215, DOI 10.1016/j.eswa.2022.119371
   Tian HD, 2018, IEEE T IMAGE PROCESS, V27, P1164, DOI 10.1109/TIP.2017.2771499
   Toreyin, 2006, P 14 EUR SIGN PROC C, P1
   Nguyen TKT, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.5.057001
   Tung TX, 2011, FIRE SAFETY J, V46, P276, DOI 10.1016/j.firesaf.2011.03.003
   Verlekar Tanmay T., 2020, Advances in Visual Computing. 15th International Symposium, ISVC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12510), P277, DOI 10.1007/978-3-030-64559-5_21
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Xu G, 2017, FIRE SAFETY J, V93, P53, DOI 10.1016/j.firesaf.2017.08.004
   Yamanaka Jin, 2017, Neural Information Processing. 24th International Conference, ICONIP 2017. Proceedings: LNCS 10635, P217, DOI 10.1007/978-3-319-70096-0_23
   Ye W, 2015, FIRE SAFETY J, V73, P91, DOI 10.1016/j.firesaf.2015.03.001
   Yin MX, 2019, MULTIMED TOOLS APPL, V78, P237, DOI 10.1007/s11042-017-5561-5
   Yin ZJ, 2017, IEEE ACCESS, V5, P18429, DOI 10.1109/ACCESS.2017.2747399
   Yuan F, 2008, PATTERN RECOGN LETT, V29, P925, DOI 10.1016/j.patrec.2008.01.013
   Yuan FN, 2015, IET IMAGE PROCESS, V9, P849, DOI 10.1049/iet-ipr.2014.1032
   Yuan FN, 2011, FIRE SAFETY J, V46, P132, DOI 10.1016/j.firesaf.2011.01.001
   Zaremba W, 2015, Arxiv, DOI arXiv:1409.2329
   Zhang L., 2023, Multimed. Tools Appl, P1
   Zhang QJ, 2016, ADV SOC SCI EDUC HUM, V47, P568
   Zhang S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235093
   Zhao YJ, 2021, MULTIMED TOOLS APPL, V80, P27407, DOI 10.1007/s11042-021-11037-1
NR 45
TC 1
Z9 1
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 17
PY 2023
DI 10.1007/s11042-023-16495-3
EA AUG 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P3YY0
UT WOS:001050048600001
DA 2024-07-18
ER

PT J
AU Bai, Y
   Sun, XY
   Ji, YF
   Fu, WT
   Zhang, JL
AF Bai, Yang
   Sun, Xiyan
   Ji, Yuanfa
   Fu, Wentao
   Zhang, Jinli
TI Two-stage multi-dimensional convolutional stacked autoencoder network
   model for hyperspectral images classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hyperspectral image classification; Deep learning; Stacked autoencoder;
   Multi-dimensional convolutional neural networks
ID SPECTRAL-SPATIAL CLASSIFICATION; LINEAR DISCRIMINANT-ANALYSIS; BAND
   SELECTION
AB Deep learning models have been widely used in hyperspectral images classification. However, the classification results are not satisfactory when the number of training samples is small. Focused on above-mentioned problem, a novel Two-stage Multi-dimensional Convolutional Stacked Autoencoder (TMC-SAE) model is proposed for hyperspectral images classification. The proposed model is composed of two sub-models SAE-1 and SAE-2. The SAE-1 is a 1D autoencoder with asymmetric structre based on full connection layers and 1D convolution layers to reduce spectral dimensionality. The SAE-2 is a hybrid autoencoder composed of 2D and 3D convolution operations to extract spectral-spatial features from the reduced dimensionality data by SAE-1. The SAE-1 is trained with raw data by unsupervised learning and the encoder of SAE-1 is employed to reduce spectral dimensionality of raw data. The data after dimension reduction is used to train the SAE-2 by unsupervised learning. The fine-tuning of SAE-2 encoder and the training of classifier are implemented simultaneously with small number of samples by supervised learning. Comparative experiments are performed on three widely used hyperspectral remote sensing data. The extensive comparative experiments demonstrate that the proposed architecture can effectively extract deep features and maintain high classification accuracy with small number of training samples.
C1 [Bai, Yang; Sun, Xiyan; Ji, Yuanfa; Fu, Wentao; Zhang, Jinli] Guilin Univ Elect Technol, Sch Informat & Commun, Guilin, Peoples R China.
   [Bai, Yang; Sun, Xiyan; Ji, Yuanfa] Guilin Univ Elect Technol, Guangxi Key Lab Precis Nav Technol & Applicat, Guilin, Peoples R China.
   [Sun, Xiyan; Fu, Wentao] Guilin Univ Elect Technol, Natl & Local Joint Engn Res Ctr, Satellite Nav & Locat Serv, Guilin, Peoples R China.
C3 Guilin University of Electronic Technology; Guilin University of
   Electronic Technology; Guilin University of Electronic Technology
RP Sun, XY (corresponding author), Guilin Univ Elect Technol, Sch Informat & Commun, Guilin, Peoples R China.; Sun, XY (corresponding author), Guilin Univ Elect Technol, Guangxi Key Lab Precis Nav Technol & Applicat, Guilin, Peoples R China.; Sun, XY (corresponding author), Guilin Univ Elect Technol, Natl & Local Joint Engn Res Ctr, Satellite Nav & Locat Serv, Guilin, Peoples R China.
EM sxy@guet.edu.cn
RI chen, yanhong/JVE-0289-2024; Zhang, Xiaoxi/KBP-8753-2024; Li,
   Kexin/KAO-2519-2024; Wang, Yuchen/JPW-9345-2023; wang,
   shuo/KCL-3379-2024; xiang, wei/JXL-3308-2024; xu, chen/JNE-5010-2023;
   chen, bin/KBQ-8114-2024; Li, Chun/KBC-9591-2024
OI chen, bin/0000-0002-3398-1314; 
FU Guangxi Key Laboratory of Precision Navigation Technology and
   Application; Guilin University of Electronic Technology [DH202208]
FX This research work is supported by the project supported by Guangxi Key
   Laboratory of Precision Navigation Technology and Application, Guilin
   University of Electronic Technology (No. DH202208).
CR Bai Y, 2022, INT J REMOTE SENS, V43, P5534, DOI 10.1080/01431161.2021.1949069
   Bao R, 2016, IEEE GEOSCI REMOTE S, V13, P359, DOI 10.1109/LGRS.2015.2513002
   Ben Hamida A, 2018, IEEE T GEOSCI REMOTE, V56, P4420, DOI 10.1109/TGRS.2018.2818945
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Chen YS, 2015, IEEE J-STARS, V8, P2381, DOI 10.1109/JSTARS.2015.2388577
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Du Q, 2008, LECT NOTES ARTIF INT, V5179, P392
   Falco N, 2015, IEEE T GEOSCI REMOTE, V53, P6223, DOI 10.1109/TGRS.2015.2436335
   Fauvel M, 2006, 2006 7TH NORDIC SIGNAL PROCESSING SYMPOSIUM, P238
   Fauvel M, 2008, IEEE T GEOSCI REMOTE, V46, P3804, DOI 10.1109/TGRS.2008.922034
   Feng J, 2016, IEEE T GEOSCI REMOTE, V54, P6516, DOI 10.1109/TGRS.2016.2585961
   Ghassemi M, 2018, PROCEEDINGSS OF THE 2018 IEEE INTERNATIONAL CONFERENCE ON AEROSPACE ELECTRONICS AND REMOTE SENSING TECHNOLOGY (ICARES 2018)
   Guilloteau C, 2020, PR IEEE SEN ARRAY, DOI 10.1109/sam48682.2020.9104393
   Haque MR, 2019, 2019 22 INT C COMP I, P1
   He MY, 2017, IEEE IMAGE PROC, P3904, DOI 10.1109/ICIP.2017.8297014
   Hu W, 2015, J SENSORS, V2015, DOI 10.1155/2015/258619
   Imani M, 2015, PHOTOGRAMM ENG REM S, V81, P777, DOI 10.14358/PERS.81.10.777
   Jijón-Palma ME, 2021, J APPL REMOTE SENS, V15, DOI 10.1117/1.JRS.15.026506
   Khan Z, 2015, IEEE T IMAGE PROCESS, V24, P4934, DOI 10.1109/TIP.2015.2472280
   Li W, 2011, IEEE GEOSCI REMOTE S, V8, P894, DOI 10.1109/LGRS.2011.2128854
   Li W, 2017, IEEE T GEOSCI REMOTE, V55, P844, DOI 10.1109/TGRS.2016.2616355
   Li Y, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010067
   Licciardi G, 2012, IEEE GEOSCI REMOTE S, V9, P447, DOI 10.1109/LGRS.2011.2172185
   Liu B, 2020, IEEE ACCESS, V8, P117096, DOI 10.1109/ACCESS.2020.3004968
   Lu B, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12162659
   Marotz J, 2019, MOLECULES, V24, DOI 10.3390/molecules24224164
   Mei SH, 2019, IEEE T GEOSCI REMOTE, V57, P6808, DOI 10.1109/TGRS.2019.2908756
   Nakayama K, 2021, J APPL REMOTE SENS, V15, DOI 10.1117/1.JRS.15.040501
   Peng JT, 2016, SIGNAL IMAGE VIDEO P, V10, P761, DOI 10.1007/s11760-015-0808-y
   Roy SK, 2020, IEEE GEOSCI REMOTE S, V17, P277, DOI 10.1109/LGRS.2019.2918719
   Sellami A, 2018, IEEE J-STARS, V11, P1337, DOI 10.1109/JSTARS.2018.2798661
   Shimoni M, 2019, IEEE GEOSC REM SEN M, V7, P101, DOI 10.1109/MGRS.2019.2902525
   Stuart MB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143071
   Sun QQ, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13081602
   Sun YL, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13132608
   Tao C, 2015, IEEE GEOSCI REMOTE S, V12, P2438, DOI 10.1109/LGRS.2015.2482520
   Tun NL, 2021, IEEE NW RUSS YOUNG, P2166, DOI 10.1109/ElConRus51938.2021.9396673
   Wang C, 2015, IEEE GEOSCI REMOTE S, V12, P1411, DOI 10.1109/LGRS.2015.2404772
   Weber C, 2018, INT GEOSCI REMOTE SE, P1628, DOI 10.1109/IGARSS.2018.8519085
   Ye Z, 2018, 10 INT C DIG IM PROC, P10806
   Yi BL, 2012, INFORMATION-TOKYO, V15, P3771
   Yu C, 2019, DEEP 2D CONVOLUTIONA, P149
   Yuan HL, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON CYBERNETICS (CYBCONF), DOI 10.1109/CYBConf.2013.6617430
   Yue J, 2015, REMOTE SENS LETT, V6, P468, DOI 10.1080/2150704X.2015.1047045
   Zhang J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185191
   Zhang L, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11101219
NR 46
TC 1
Z9 1
U1 19
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 16
PY 2023
DI 10.1007/s11042-023-16456-w
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P2QW4
UT WOS:001049147100005
OA hybrid
DA 2024-07-18
ER

PT J
AU Nancy, VAO
   Prabhavathy, P
   Arya, MS
   Ahamed, BS
AF Nancy, V. Auxilia Osvin
   Prabhavathy, P.
   Arya, Meenakshi S.
   Ahamed, B. Shamreen
TI Comparative study and analysis on skin cancer detection using machine
   learning and deep learning algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Melanoma; Benign; Machine learning; Deep learning; SVM; KNN; Random
   forest; CNN; VGG16
ID CLASSIFICATION; LESIONS; NODE
AB Exposure to UV rays due to global warming can lead to sunburn and skin damage, ultimately resulting in skin cancer. Early prediction of this type of cancer is crucial. A detailed review in this paper explores various algorithms, including machine learning (ML) techniques as well as deep learning (DL) techniques. While deep learning strategies, particularly CNNs, are commonly employed for skin cancer identification and classification, there is also some usage of machine learning and hybrid approaches. These techniques have proven to be effective classifiers of skin lesions, offering promising results for early detection. The paper analyzes various researchers' reviews on skin cancer diagnosis to identify a suitable methodology for improving diagnostic accuracy. A publicly available dataset of dermoscopic images retrieved from the ISIC archive has been trained and evaluated. Performance analysis is done, considering metrics such as test and validation accuracy. The results indicate that the RF(random forest) algorithm outperforms other machine learning algorithms in both scenarios, with accuracies of 58.57% without augmentation and 87.32% with augmentation. MobileNetv2, ensemble of Dense Net and Inceptionv3 exhibit superior performance. During training without augmentation, MobileNetv2 achieves an accuracy of 88.81%, while the ensemble model achieves an accuracy of 88.80%. With augmentation techniques applied, the accuracies improved to 97.58% and 97.50%, respectively. Furthermore, experiment with a customized convolutional neural network (CNN) model was also conducted, varying the number of layers and applying various hyperparameter tuning methodologies. Suitable architectures, including a CNN with 7 layers and batch normalization, a CNN with 5 layers, and a CNN with 3 layers were identified. These models achieved accuracies of 77.92%, 97.72%, and 98.02% on the raw data and augmentation datasets, respectively. The experimental results suggest that these techniques hold promise for integration into clinical settings, and further research and validation are necessary. The results highlight the effectiveness of transfer learning models, in achieving high accuracy rates. The findings support the future adoption of these techniques in clinical practice, pending further research and validation.
C1 [Nancy, V. Auxilia Osvin; Prabhavathy, P.; Ahamed, B. Shamreen] SRM Inst Sci & Technol, Coll Engn & Technol, Dept Comp Sci & Engn, Vadapalani campus, 1 Jawaharlal Nehru Rd, Chennai, Tamil Nadu, India.
   [Arya, Meenakshi S.] Iowa State Univ, Inst Transportat, Ames, IA USA.
C3 SRM Institute of Science & Technology Chennai; Iowa State University
RP Nancy, VAO (corresponding author), SRM Inst Sci & Technol, Coll Engn & Technol, Dept Comp Sci & Engn, Vadapalani campus, 1 Jawaharlal Nehru Rd, Chennai, Tamil Nadu, India.
EM auxilianancy@gmail.com
RI Arya, Meenakshi S/AAJ-2193-2020; Pachaiyappan,
   Prabhavathy/ABA-6002-2021; nancy, auxilia/KLD-2949-2024; Ahamed, Dr. B
   Shamreen/AGC-6114-2022
OI Arya, Meenakshi S/0000-0001-6631-8810; Pachaiyappan,
   Prabhavathy/0000-0002-6793-7557; nancy, auxilia/0000-0002-4254-0537; 
CR Adegun AA, 2020, IEEE ACCESS, V8, P150377, DOI 10.1109/ACCESS.2020.3016651
   Adjed F, 2016, AIP CONF PROC, V1787, DOI 10.1063/1.4968145
   Agarwal K., 2022, SSRN ELECT J, DOI [10.2139/ssrn.4055037, DOI 10.2139/SSRN.4055037]
   Al-Issa Y, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-18293-7
   Al-Qudah AA, 2022, J SUSTAIN FINANC INV, V12, P44, DOI 10.1080/20430795.2021.1880219
   Alqudah AM, 2020, NETW MODEL ANAL HLTH, V9, DOI 10.1007/s13721-020-00272-5
   Alqudah AM, 2019, BIOMED ENG-APP BAS C, V31, DOI 10.4015/S1016237219500078
   Alqudah A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11041573
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   [Anonymous], 2020, STRAD RES, V7, DOI [10.37896/sr7.9/003, DOI 10.37896/SR7.9/003]
   [Anonymous], 2021, CANC FACTS FIGS
   [Anonymous], WHAT IS HYPERPARAMET
   [Anonymous], 2020, SKIN LESION CLASSIFI
   [Anonymous], 2022, TYPES OPTIMIZERS DEE
   [Anonymous], Menzies Method
   [Anonymous], 2022, DEEPCHECKS
   [Anonymous], 2021, INT J E-HEALTH MED C, V12, DOI [10.4018/ijehmc.20211101oa09, DOI 10.4018/IJEHMC.20211101OA09]
   Camacho-Gutiérrez JA, 2022, EXPERT SYST APPL, V197, DOI 10.1016/j.eswa.2022.116671
   Auxilia Osvin Nancy V, 2022, MACHINE LEARNING ART, P93, DOI [10.1201/9781003265436-4, DOI 10.1201/9781003265436-4]
   Balabantaray BK., 2022, 2022 4 INT C ENERGY, DOI [10.1109/icepe55035.2022.9798123, DOI 10.1109/ICEPE55035.2022.9798123]
   Bansal P, 2022, SOFT COMPUT, V26, P8163, DOI 10.1007/s00500-022-07234-1
   Bansal P, 2022, COMPUT IND ENG, V168, DOI 10.1016/j.cie.2022.108060
   Carvajal DC, 2022, 2022 IEEE 29 INT C E, P1, DOI [10.1109/INTERCON55795.2022.9870129, DOI 10.1109/INTERCON55795.2022.9870129]
   Chaturvedi S.S., 2020, Advanced machine learning technologies and applications: proceedings of AMLTA 2020, P165, DOI [DOI 10.1007/978-981-15-3383-9_15, 10.1007/978-981-15-3383-9_15, DOI 10.1007/978-981-15-3383-915]
   Chen QP, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101233
   Codella NCF, 2017, IBM J RES DEV, V61, DOI 10.1147/JRD.2017.2708299
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Das NN, 2022, IRBM, V43, P114, DOI 10.1016/j.irbm.2020.07.001
   de Ville B, 2013, WIRES COMPUT STAT, V5, P448, DOI 10.1002/wics.1278
   DeVries T, 2017, PREPRINT
   Diwan T, 2023, MULTIMED TOOLS APPL, V82, P2369, DOI 10.1007/s11042-022-12633-5
   Dorj UO, 2018, MULTIMED TOOLS APPL, V77, P9909, DOI 10.1007/s11042-018-5714-1
   dshahid380, 2019, CONVOLUTIONAL NEURAL
   Duarte AF, 2021, EUR J DERMATOL, V31, P771, DOI 10.1684/ejd.2021.4171
   Elashiri MA, 2022, BIOMED SIGNAL PROCES, V76, DOI 10.1016/j.bspc.2022.103729
   Farooq MA, 2016, IEEE INT C BIOINF BI, P301, DOI 10.1109/BIBE.2016.53
   Fei D-Y., 2020, T MACH LEARN ARTIF I, V8, P01, DOI [10.14738/tmlai.84.8415, DOI 10.14738/TMLAI.84.8415]
   Gajera HK, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104186
   Gautam D, 2015, ANNU IEEE IND CONF
   Giotis I, 2015, EXPERT SYST APPL, V42, P6578, DOI 10.1016/j.eswa.2015.04.034
   Girdhar N, 2023, SOFT COMPUT, V27, P13285, DOI 10.1007/s00500-022-07406-z
   Grignaffini F, 2022, ALGORITHMS, V15, DOI 10.3390/a15110438
   Harley AW, 2015, LECT NOTES COMPUT SC, V9474, P867, DOI 10.1007/978-3-319-27857-5_77
   Hosny KM, 2022, J DIGIT IMAGING, V35, P258, DOI 10.1007/s10278-021-00552-0
   Hosny KM, 2020, J DIGIT IMAGING, V33, P1325, DOI 10.1007/s10278-020-00371-9
   Hosny KM, 2020, MULTIMED TOOLS APPL, V79, P24029, DOI 10.1007/s11042-020-09067-2
   Hussaindeen A., 2022, INT J ADV SIGNAL IMA, V8, P40, DOI [10.29284/ijasis.8.1.2022.40-53, DOI 10.29284/IJASIS.8.1.2022.40-53]
   Indraswari R., 2022, Procedia Comp. Sci, V197, P198, DOI DOI 10.1016/J.PROCS.2021.12.132
   Iqbal I, 2021, COMPUT MED IMAG GRAP, V88, DOI 10.1016/j.compmedimag.2020.101843
   Iqtidar Khushbakht, 2020, 2020 First International Conference of Smart Systems and Emerging Technologies (SMARTTECH), P208, DOI 10.1109/SMART-TECH49988.2020.00055
   Jafari MH, 2016, INT C PATT RECOG, P337, DOI 10.1109/ICPR.2016.7899656
   Jafari MH, 2017, INT J COMPUT ASS RAD, V12, P1021, DOI 10.1007/s11548-017-1567-8
   Jaisakthi SM, 2021, HDB DEEP LEARNING BI, P253, DOI [10.1201/9781003144694-10, DOI 10.1201/9781003144694-10]
   Jaworek-Korjakowska J, 2019, IEEE COMPUT SOC CONF, P2748, DOI 10.1109/CVPRW.2019.00333
   Acosta MFJ, 2021, BMC MED IMAGING, V21, DOI 10.1186/s12880-020-00534-8
   Kalouche S., 2016, Vision-Based Classification of Skin Cancer using Deep Learning
   Kanca E., 2022, 2022 INT C HUMAN COM, DOI [10.1109/hora55278.2022.9799834, DOI 10.1109/HORA55278.2022.9799834]
   Kassem MA, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11081390
   Kaur M, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/8829829
   KHAN MA, 2021, COMPUT ELECTR ENG, V90, DOI DOI 10.1016/J.COMPELECENG.2020.106956
   Kumar N, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03306-6
   Kumar N, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/7797548
   Kumar S., 2022, arXiv
   Lopes J, 2022, PHARMACEUTICS, V14, DOI 10.3390/pharmaceutics14091817
   Maglogiannis I, 2015, IEEE ENG MED BIO, P2960, DOI 10.1109/EMBC.2015.7319013
   Mahadik, 2022, 2022 3 INT C EMERGIN, DOI [10.1109/incet54531.2022.9825381, DOI 10.1109/INCET54531.2022.9825381]
   Mahbod A, 2019, INT CONF ACOUST SPEE, P1229, DOI [10.1109/ICASSP.2019.8683352, 10.1109/icassp.2019.8683352]
   Malibari AA, 2022, COMPUT ELECTR ENG, V103, DOI 10.1016/j.compeleceng.2022.108318
   Mane S., 2018, 2018 4 INT C COMPUTI, DOI [10.1109/iccubea.2018.8697804, DOI 10.1109/ICCUBEA.2018.8697804]
   MARKS R, 1995, CANCER-AM CANCER SOC, V75, P607, DOI 10.1002/1097-0142(19950115)75:2+<607::AID-CNCR2820751402>3.0.CO;2-8
   Masad IS., 2021, Int. J. Electr. Comput. Eng., V11, P5530
   Mendonca Teresa, 2013, 2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), P5437, DOI 10.1109/EMBC.2013.6610779
   Moazen H., 2020, 2020 INT C MACHINE V, DOI [10.1109/mvip49855.2020.9116918, DOI 10.1109/MVIP49855.2020.9116918]
   Montaha S, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0269826
   Munia TTK, 2017, IEEE ENG MED BIO, P4281, DOI 10.1109/EMBC.2017.8037802
   Nancy VA., 2022, 2022 5 INT C INFORM, DOI [10.1109/icict55905.2022.00020, DOI 10.1109/ICICT55905.2022.00020]
   Neela Krishna Babu G., 2021, ICTACT Journal on Soft Computing, V11, P2301
   Nugroho AA, 2019, AIP CONF PROC, V2202, DOI 10.1063/1.5141652
   Öztürk S, 2022, IEEE J BIOMED HEALTH, V26, P4679, DOI 10.1109/JBHI.2022.3187215
   Premier Surgical Staff, WHAT IS DIFF MEL NON
   Pujara A, 2022, MEDIUM
   R D Seeja, 2019, Asian Pac J Cancer Prev, V20, P1555
   Rahman Z., 2021, Informatics in Medicine Unlocked, V25, DOI [10.1016/j.imu.2021.100659, DOI 10.1016/J.IMU.2021.100659]
   Sarker I. H., 2021, SN COMPUT SCI, V2, DOI [DOI 10.1007/S42979-021-00592-X, 10.1007/s42979-021-00592-x, 10.1007 /s42979-021-00592-x]
   Sharafudeen M, 2023, MULTIMED TOOLS APPL, V82, P3155, DOI 10.1007/s11042-022-13046-0
   Shetty B, 2022, SCI REP-UK, V12, DOI [10.1038/s41598-022-22,644-9, DOI 10.1038/S41598-022-22,644-9]
   Sturm RA, 2002, MELANOMA RES, V12, P405, DOI 10.1097/00008390-200209000-00001
   Tabrizchi H, 2023, NEURAL PROCESS LETT, V55, P3715, DOI 10.1007/s11063-022-10927-1
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Venugopal V, 2022, COMPUT BIOL MED, V148, DOI 10.1016/j.compbiomed.2022.105852
   Venugopal V, 2022, COMPUT METH PROG BIO, V222, DOI 10.1016/j.cmpb.2022.106935
   Vipin V., 2021, 2021 INT C COMMUNICA, DOI [10.1109/iccisc52257.2021.9484861, DOI 10.1109/ICCISC52257.2021.9484861]
   Vocaturo E, 2018, IEEE INT C BIOINFORM, P2117, DOI 10.1109/BIBM.2018.8621507
   Woodie A, 2017, DATANAMI
   Wu Y., 2022, 2022 IEEE 4 INT C PO, DOI [10.1109/icpics55264.2022.9873756, DOI 10.1109/ICPICS55264.2022.9873756]
   Yuan XJ, 2006, 2006 28TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOLS 1-15, P3301
NR 97
TC 1
Z9 1
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45913
EP 45957
DI 10.1007/s11042-023-16422-6
EA AUG 2023
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:001049147100003
DA 2024-07-18
ER

PT J
AU Singh, J
   Pandey, D
   Singh, AK
AF Singh, Jagrati
   Pandey, Digvijay
   Singh, Anil Kumar
TI Event detection from real-time twitter streaming data using community
   detection algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Twitter stream; Clustering; Supervised; Unsupervised technique; Semantic
   correlation; Keyword co-occurrence; Topic modeling
ID SOCIAL NETWORKS; MODEL; ELECTIONS
AB The increasing popularity of social media services has led to more and more people using Twitter. There are millions of tweets with a high amount of noisy data that propagate daily on the Internet. Twitter acts as a source of information for events and breaking news. However, it is very challenging for any person to extract useful information related to important events manually, from the end- less stream of tweets. Hence, it is desired to automate the whole process of event detection, so that important events can be identified in real-time from a stream of tweets, as early as possible, after the actual happening. Most of the existing approaches are more focussed on "What happened". To define any event, answers of "When" and "Where" are also required. To handle emergency events, location and time parameters play a very important role. This article proposes a faster location based event detection approach without compromising accuracy, which automatically extracts separate clusters concerning local or global events from real-time streaming data. The proposed approach consists of four major steps. In the first step, a new dynamic weighting scheme named Conditional Term Frequency-Average Inverse Window Frequency (CTF-AIWF) based on TF-IDF is proposed to capture emerging keywords from the temporal dynamics of data. Next, a new clustering algorithm named Edge Significance based Louvain Algorithm (ESBLA) is proposed to group the same event keywords. This clustering helps in improving the run-time performance up to 50% while maintaining the quality performance (F1-score) comparable to the baseline models. In the third step, a new content-based location detection technique is proposed to detect the location of the event. This technique is able to handle various issues like use of informal text, short form of a text, and misspelled keywords of microblogging data. Finally, Google Map is used to visualize the events in happening locations. This step makes the decision faster regarding the detected events. For the experimentation, tweets are collected in real-time and stored in MongoDB NoSQL database for processing.
C1 [Singh, Jagrati; Singh, Anil Kumar] Motilal Nehru Natl Inst Technol, Comp Sci & Engn, Allahabad, Uttar Pradesh, India.
   [Pandey, Digvijay] Govt UP, Elect & Commun Engn, Dept Tech Educ, Lucknow, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Pandey, D (corresponding author), Govt UP, Elect & Commun Engn, Dept Tech Educ, Lucknow, Uttar Pradesh, India.
EM singh.jagriti5@gmail.com; digit11011989@gmail.com; ak@mnnit.ac.in
RI Singh, Anil/JUU-2219-2023
OI PANDEY, DIGVIJAY/0000-0003-0353-174X
CR Abdelhaq H, 2017, GEOINFORMATICA, V21, P365, DOI 10.1007/s10707-016-0258-x
   Ahmed S, 2016, TELEMAT INFORM, V33, P1071, DOI 10.1016/j.tele.2016.03.002
   Akhgari Zahra, 2022, 2022 8th International Conference on Web Research (ICWR), P16, DOI 10.1109/ICWR54782.2022.9786233
   Akhgari Zahra, 2022, 2022 8th International Conference on Web Research (ICWR), P61, DOI 10.1109/ICWR54782.2022.9786234
   Allan J, 2002, KLUW S INF, V12, P1
   Alomari E, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18010282
   [Anonymous], 2009, ICWSM
   [Anonymous], 2010, HLT 10
   [Anonymous], 2011, P 20 ACM INT C INF K
   [Anonymous], 2009, P 17 ACM SIGSPATIAL, DOI DOI 10.1145/1653771.1653781
   [Anonymous], 2016, Newspaper Research Journal, DOI DOI 10.1177/0739532916648961
   Bhuvaneswari A., 2021, J PHYS C SER
   Blei DavidM., 2006, P ICML
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Choi HJ, 2019, EXPERT SYST APPL, V115, P27, DOI 10.1016/j.eswa.2018.07.051
   Dhiman A, 2020, IEEE ACCESS, V8, P122168, DOI 10.1109/ACCESS.2020.3007004
   Fang Y, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10175922
   Fedoryszak M, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2774, DOI 10.1145/3292500.3330689
   Feng X, 2015, LECT NOTES COMPUT SC, V9243, P213, DOI 10.1007/978-3-319-23862-3_21
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Gaglio S, 2016, COMPUT COMMUN, V73, P236, DOI 10.1016/j.comcom.2015.09.021
   Ghaemi Z, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8020082
   Giridhar P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATION WORKSHOPS (PERCOM WORKSHOPS), P75, DOI 10.1109/PERCOMW.2015.7133997
   Girish KK, 2022, 2022 INTERNATIONAL CONFERENCE ON DECISION AID SCIENCES AND APPLICATIONS (DASA), P917, DOI 10.1109/DASA54658.2022.9765076
   Guille A, 2014, 2014 PROCEEDINGS OF THE IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2014), P375, DOI 10.1109/ASONAM.2014.6921613
   Hasan M., 2016, PEERJ PREPRINTS, V4, P2297
   Hoffman M., 2010, ADV NEURAL INFORM PR, V23, P856
   Hossny AH, 2018, INT CONF DAT MIN WOR, P1200, DOI 10.1109/ICDMW.2018.00172
   Hu Mengdie, 2012, P SIGCHI C HUM FACT, P2751, DOI [10.1145/2207676.2208672, DOI 10.1145/2207676.2208672]
   Ifrim G., 2014, CEUR Workshop Proceedings, V1150, P33
   Janjua NK, 2023, ENTERP INF SYST-UK, V17, DOI 10.1080/17517575.2021.1959652
   Kamoji S, 2023, ENG APPL ARTIF INTEL, V123, DOI 10.1016/j.engappai.2023.106365
   Karimi S, 2023, NAT LANG ENG, V29, P181, DOI 10.1017/S1351324921000462
   Khan Hikmat Ullah, 2021, Expert Systems with Applications, V164, P443, DOI 10.1016/j.eswa.2020.113990
   Li C., 2012, Cikm, P155, DOI DOI 10.1145/2396761.2396785
   Li R, 2012, PROC INT CONF DATA, P1273, DOI 10.1109/ICDE.2012.125
   McMinn AJ, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P409, DOI 10.1145/2505515.2505695
   Mehrotra R, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P889
   Mojiri MM, 2020, COMPUT INFORM, V39, P1336, DOI 10.31577/cai_2020_6_1336
   Newman MEJ, 2004, EUR PHYS J B, V38, P321, DOI 10.1140/epjb/e2004-00124-y
   Nguyen DT, 2017, FUTURE GENER COMP SY, V66, P137, DOI 10.1016/j.future.2016.04.012
   Noori Mohammed Ahsan Raza, 2020, 2020 IEEE 15th International Conference on Industrial and Information Systems (ICIIS), P403, DOI 10.1109/ICIIS51140.2020.9342671
   OSBORNE M., 2012, SIGIR 2012 WORKSH TI
   Ozdikis O, 2016, INFORM PROCESS MANAG, V52, P1227, DOI 10.1016/j.ipm.2016.06.001
   Pandya A., 2020, INFORM PROCESSING MA, P402
   Paul NR, 2023, MULTIMED TOOLS APPL, V82, P8921, DOI 10.1007/s11042-022-12183-w
   Raghavan UN, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.036106
   Rezaei Z, 2023, EVOL INTELL, V16, P833, DOI 10.1007/s12065-021-00696-6
   Said N, 2020, Arxiv, DOI arXiv:2011.14943
   Sakaki T, 2013, IEEE T KNOWL DATA EN, V25, P919, DOI 10.1109/TKDE.2012.29
   Salza D, 2022, ISCRAM 2022 C P 19 I
   Sayyadi H, 2013, ACM T INTERNET TECHN, V13, DOI 10.1145/2542214.2542215
   Song GZ, 2021, FUTURE INTERNET, V13, DOI 10.3390/fi13070163
   Sun X, 2021, DIGIT COMMUN NETW, V7, P559, DOI 10.1016/j.dcan.2021.03.006
   Unankard S, 2014, LECT NOTES COMPUT SC, V8787, P1, DOI 10.1007/978-3-319-11746-1_1
   Vieweg S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1079, DOI 10.1145/1753326.1753486
   Wei Y, 2017, KDD WORKSHOP MINING
   Weng J., 2021, Proc. Int. AAAI Conf. Web Soc. Media, V5, P401, DOI [10.1609/icwsm.v5i1.14102, DOI 10.1609/ICWSM.V5I1.14102]
   Xingfa Qiu, 2021, ICMLC 2021: 2021 13th International Conference on Machine Learning and Computing, P522, DOI 10.1145/3457682.3457762
   Yang H., 2011, Proceedings of the 1st International Workshop on Mobile Location-Based Service, P89
   Zeng K, 2021, INT C SOFTW ENG KNOW, DOI [10.18293/seke2021-092, DOI 10.18293/SEKE2021-092]
   Zhao S., 2017, IEEE Transactions on Cybernetics, P1
   Zhou SL, 2023, J INF SCI, V49, P465, DOI 10.1177/01655515211007724
NR 64
TC 0
Z9 0
U1 6
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 16
PY 2023
DI 10.1007/s11042-023-16263-3
EA AUG 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P5FE2
UT WOS:001050922800001
DA 2024-07-18
ER

PT J
AU Chatterjee, S
   Mukherjee, H
   Sen, S
   Obaidullah, SM
   Roy, K
AF Chatterjee, Somnath
   Mukherjee, Himadri
   Sen, Shibaprasad
   Obaidullah, Sk Md
   Roy, Kaushik
TI City name recognition for Indian postal automation: Exploring script
   dependent and independent approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Handwriting recognition; Indic-script; City name recognition; Postal
   automation system; Convolutional Neural Networks
ID NEURAL-NETWORKS
AB Postal documents are often used for official communication, online shopping, etc. At times, the delivery gets delayed due to multiple scripts leading to the need for postal sorting facilities. Understanding the destination city name plays a major part in solving automatic sorting problems as the same becomes more challenging due to the presence of handwritten documents. In order to develop an autonomous system to solve the problem, a Deep Learning-based system is proposed to recognize handwritten city names written in 6 major scripts namely Tamil, Roman, Devanagari, Bangla, Gurumukhi, and Arabic. Experiments were performed in both script-dependent (bi-stage) and independent approaches. In the bi-stage framework, we have obtained an average accuracy of 97.58% along with a back-end script recognition rate of 99.07% while in the script-independent approach, an accuracy of 97.03% was obtained on a dataset consisting of 807 classes.
C1 [Chatterjee, Somnath] Future Inst Engn & Management, Dept Comp Sci & Engn, Kolkata, West Bengal, India.
   [Mukherjee, Himadri; Roy, Kaushik] West Bengal State Univ, Dept Comp Sci, Kolkata, West Bengal, India.
   [Sen, Shibaprasad] Techno Main Salt Lake, Dept Comp Sci & Engn AIML, Kolkata, West Bengal, India.
   [Obaidullah, Sk Md] Aliah Univ, Dept Comp Sci & Engn, Kolkata, West Bengal, India.
C3 West Bengal State University; Aliah University
RP Roy, K (corresponding author), West Bengal State Univ, Dept Comp Sci, Kolkata, West Bengal, India.
EM kaushik.mrg@gmail.com
RI Roy, Kaushik/O-7021-2019
OI Roy, Kaushik/0000-0002-3360-7576
CR Aladem M, 2021, IEEE INTELL SYST, V36, P79, DOI 10.1109/MIS.2020.2993266
   Aloysius N, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P588, DOI 10.1109/ICCSP.2017.8286426
   [Anonymous], 2012, GUIDE OCR ARABIC SCR
   Arora S, 2008, IEEE REGION 10 COLLOQUIUM AND THIRD INTERNATIONAL CONFERENCE ON INDUSTRIAL AND INFORMATION SYSTEMS, VOLS 1 AND 2, P454
   Deepa RNA, 2020, PATTERN ANAL APPL, V23, P199, DOI 10.1007/s10044-018-00776-x
   Bianne-Bernard AL, 2011, IEEE T PATTERN ANAL, V33, P2066, DOI 10.1109/TPAMI.2011.22
   Bluche T, 2013, PROC INT CONF DOC, P285, DOI 10.1109/ICDAR.2013.64
   Dhande Pritam, 2017, 2017 International Conference on Trends in Electronics and Informatics (ICEI). Proceedings, P199, DOI 10.1109/ICOEI.2017.8300915
   Dholakia K., 2015, INT J COMPUT APPL, V115, P17, DOI [10.5120/20114-2159, DOI 10.5120/20114-2159]
   Dutta K., 2018, COMPUTER VISION PATT, P470, DOI [10.1007/978-981-13-0020-2_41, DOI 10.1007/978-981-13-0020-2_41]
   Hawkins DM, 2004, J CHEM INF COMP SCI, V44, P1, DOI 10.1021/ci0342472
   He KM, 2015, Arxiv, DOI [arXiv:1512.03385, 10.48550/arxiv.1512.03385]
   Ioffe S, 2015, Arxiv, DOI [arXiv:1502.03167, DOI 10.48550/ARXIV.1502.03167]
   Kaur H, 2021, DATA DRIVEN APPROACH, DOI 10.1007/978-981-15-9873-9_44
   Kaur H, 2019, DOCUMENT ANAL RECOGN, V1020, DOI [10.1007/978-981-13-9361-7_14, DOI 10.1007/978-981-13-9361-7_14]
   Kaur H, 2021, MULTIMED TOOLS APPL, V80, P11155, DOI 10.1007/s11042-020-10297-7
   Kaur H, 2021, SOFT COMPUT, V25, P4451, DOI 10.1007/s00500-020-05455-w
   Kessentini Y, 2010, PATTERN RECOGN LETT, V31, P60, DOI 10.1016/j.patrec.2009.08.009
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Kuang HL, 2016, IEEE INTELL SYST, V31, P57, DOI 10.1109/MIS.2016.17
   Kumar M, 2011, 2011 INT C IM INF PR, P1, DOI [10.1109/ICIIP.2011.6108863, DOI 10.1109/ICIIP.2011.6108863]
   Lasker A, 2023, MULTIMED TOOLS APPL, V82, P21801, DOI 10.1007/s11042-022-14247-3
   Liu FY, 2015, PATTERN RECOGN, V48, P2983, DOI 10.1016/j.patcog.2015.04.019
   LIU L, 2008, 2009 IEEE VEH POW PR, DOI DOI 10.1145/2641483.2641536
   Malakar S, 2020, NEURAL COMPUT APPL, V32, P2533, DOI 10.1007/s00521-018-3937-8
   Ng Andrew Y, 2004, INT C MACH LEARN, DOI [10.1145/1015330.1015435, DOI 10.1145/1015330.1015435]
   NOWLAN SJ, 1992, NEURAL COMPUT, V4, P473, DOI 10.1162/neco.1992.4.4.473
   Obaidullah SM, 2014, APPL COMPUT INTELL S, V2014, DOI 10.1155/2014/896128
   Pal U, 2007, PROC INT CONF DOC, P749
   Pal Umapada, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1985, DOI 10.1109/ICPR.2010.489
   Pal Umapada, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1111, DOI 10.1109/ICDAR.2009.244
   Pal U, 2012, INT CONF FRONT HAND, P169, DOI 10.1109/ICFHR.2012.238
   Pal U, 2009, IEICE T INF SYST, VE92D, P1146, DOI 10.1587/transinf.E92.D.1146
   Pramanik R, 2021, NEURAL COMPUT APPL, V33, P9329, DOI 10.1007/s00521-021-05693-5
   Rabby AKMSA, 2018, PROCEDIA COMPUT SCI, V143, P528, DOI 10.1016/j.procs.2018.10.426
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Roy K, 2004, PROCEEDINGS OF THE IEEE INDICON 2004, P266, DOI 10.1109/INDICO.2004.1497753
   Roy K, 2005, PROC INT CONF DOC, P1060, DOI 10.1109/ICDAR.2005.259
   Roy PP, 2016, PATTERN RECOGN, V60, P1057, DOI 10.1016/j.patcog.2016.04.012
   Roy RK, 2022, MULTIMED TOOLS APPL, V81, P11501, DOI 10.1007/s11042-022-12193-8
   Sen Maitra D, 2015, PROC INT CONF DOC, P1021, DOI 10.1109/ICDAR.2015.7333916
   Shakeri M, 2016, I S BIOMED IMAGING, P269, DOI 10.1109/ISBI.2016.7493261
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh TP, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082881
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2014, Arxiv, DOI [arXiv:1409.4842, DOI 10.48550/ARXIV.1409.4842]
   Thadchanamoorthy S, 2013, PROC INT CONF DOC, P793, DOI 10.1109/ICDAR.2013.162
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Yang WX, 2016, IEEE INTELL SYST, V31, P45, DOI 10.1109/MIS.2016.22
NR 49
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 5
PY 2023
DI 10.1007/s11042-023-16137-8
EA AUG 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O4EJ2
UT WOS:001043360000008
DA 2024-07-18
ER

PT J
AU Wang, H
   Wei, YT
   Ding, BX
   Song, JH
   Wang, ZY
AF Wang, Hui
   Wei, Yutao
   Ding, Boxu
   Song, Jiahao
   Wang, Zhengyou
TI Shape-based 3D human action retrieval using triplet network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human action retrieval; Point cloud sequences; Triplet network
AB Human action retrieval is a challenging task in computer vision and computer graphics. Existing action retrieval works are mainly for the human representation of skeleton sequences or videos. However, there are fewer researches for 3D human shapes. In this paper, we propose a novel action retrieval method for 3D human point cloud sequences. Specifically, a triplet network with the margin loss is adopted to learn embedding vectors, where their Euclidean distances are close for pairs of point cloud sequences with the same actions and are far away for pairs of sequences with different actions. Given a query point cloud sequences, the retrieval results are in ascending order via the Euclidean distances of the embedding vectors. Furthermore, we also construct a 3D human action dataset, which consists of 220 classes for evaluation of action retrieval. Extensive experiments show that the proposed method is better than the existing skeleton-based methods with a 0.05 higher precision.
C1 [Wang, Hui; Wei, Yutao; Ding, Boxu; Song, Jiahao; Wang, Zhengyou] Shijiazhuang Tiedao Univ, Sch Informat Sci & Technol, Shijiazhuang 050043, Hebei, Peoples R China.
C3 Shijiazhuang Tiedao University
RP Wang, ZY (corresponding author), Shijiazhuang Tiedao Univ, Sch Informat Sci & Technol, Shijiazhuang 050043, Hebei, Peoples R China.
EM zhengyouwang@stdu.edu.cn
FU National Natural Science Foundation of China [61972267]; Hebei Education
   Department Foundation for the Cultivation of Foundation of Hebei
   Province [F2019210306]; Key Project of Science and Technology Research
   of Hebei Province University [ZD2021333]
FX AcknowledgementsWe sincerely thank the anonymous reviewers for their
   constructive comments. This work was jointly supported by the National
   Natural Science Foundation of China under Grants No. 61972267, the Hebei
   Education Department Foundation for the Cultivation of Foundation of
   Hebei Province under Grants No. F2019210306 and the Key Project of
   Science and Technology Research of Hebei Province University under
   Grants No. ZD2021333.
CR Battan N, 2019, AS C PATT REC, P281
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Budikova P, 2021, INT J SEMANT COMPUT, V15, P189, DOI 10.1142/S1793351X21400031
   Cai ZG, 2022, LECT NOTES COMPUT SC, V13667, P557, DOI 10.1007/978-3-031-20071-7_33
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   De Smedt Q., 2017, 3DOR 10 EUR WORKSH 3, P1, DOI DOI 10.2312/3DOR.20171049
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Hu TY, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P1765, DOI 10.1109/ICASSP39728.2021.9413393
   Jiang HY, 2019, IEEE I CONF COMP VIS, P5430, DOI 10.1109/ICCV.2019.00553
   Lei YJ, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106981
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liu Q, 2021, SUSTAIN CITIES SOC, V73, DOI 10.1016/j.scs.2021.103067
   Liu XY, 2019, IEEE I CONF COMP VIS, P9245, DOI 10.1109/ICCV.2019.00934
   Loper M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661273
   Lv N, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2215, DOI 10.1109/ICASSP39728.2021.9413505
   Mahmood N, 2019, IEEE I CONF COMP VIS, P5441, DOI 10.1109/ICCV.2019.00554
   Min Y, 2019, BRIT MACH VIS C
   Min YC, 2020, PROC CVPR IEEE, P5760, DOI 10.1109/CVPR42600.2020.00580
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Ramezani M, 2018, MULTIMED TOOLS APPL, V77, P26009, DOI 10.1007/s11042-018-5835-6
   Shi XJ, 2015, ADV NEUR IN, V28
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Tan RB, 2021, IEEE WINT CONF APPL, P2082, DOI 10.1109/WACV48630.2021.00213
   Veinidis C, 2019, MULTIMED TOOLS APPL, V78, P2789, DOI 10.1007/s11042-018-5855-2
   Veinidis C, 2017, MULTIMED TOOLS APPL, V76, P2059, DOI 10.1007/s11042-015-3137-9
   Wang WG, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7283, DOI 10.1109/ICCV48922.2021.00721
   Wang Y, 2015, C MOT GAM, P37
   Wang YC, 2020, PROC CVPR IEEE, P508, DOI 10.1109/CVPR42600.2020.00059
   Wang Z, 2016, SIGNAL PROCESS, V120, P691, DOI 10.1016/j.sigpro.2014.11.015
   Wu CY, 2017, IEEE I CONF COMP VIS, P2859, DOI 10.1109/ICCV.2017.309
   Yichen Peng, 2021, 2021 Nicograph International (NicoInt), P42, DOI 10.1109/NICOINT52941.2021.00015
   Yurtsever MME, 2022, IEEE SENS J, V22, P13776, DOI 10.1109/JSEN.2022.3183502
   Zhou T, 2022, COMPUTER VISION PATT, P2582
   Zhou Tianfei, 2022, IEEECVF C COMPUT VIS, P4299
   Zou S., 2021, P IEEE INT C COMP VI, P10996
NR 37
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 5
PY 2023
DI 10.1007/s11042-023-16211-1
EA AUG 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O4EJ2
UT WOS:001043360000002
DA 2024-07-18
ER

PT J
AU Tong, HW
   Li, TY
   Xu, YY
   Su, XZ
   Qiao, GP
AF Tong, Huawei
   Li, Tianyou
   Xu, Youyun
   Su, Xinzhong
   Qiao, Guopeng
TI Chaotic coyote optimization algorithm for image encryption and
   steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Metaheuristic; Encryption; Steganography; Image processing; Information
   security
ID SPATIAL DOMAIN; INFORMATION; TRANSFORM; SYSTEM
AB It is significant to ensure the communication networks and information security, and balancing simplicity and complexity is still a real issue that is the key to improve the effectiveness of a scheme in many applications scenarios.Current researches focusing on the security of digital images and putting barriers to protect sensitive data still have room for improvement. Herein,the aim of this paper is twofold. Firstly, we propose a color image encryption method by utilizing Chaotic Coyote Optimization Algorithm to solve the key selection problem for minimizing the correlation between adjacent pixels of the cipher image, where three color channels are processed to enhance its security against various attacks. Secondly, we design a color image Steganography scheme that has ability to defend common types of the image attacks. In the design stage of embedding, the Chaotic Coyote Optimization Algorithm and a special designed strategy are implemented together to handle the problem of location selection to lower the distortion in all components of the embedded image. According to the simulation results, the proposed image encryption method is efficient and robust considering the performance indexes: correlation coefficient, information entropy, number of pixels change rate, unified average changing intensity, and histogram. Meanwhile, the image Steganography approach also provides satisfying effect compared with other methods in the literature, based on indicators of peak signal-to-noise ratio and structural similarity.
C1 [Tong, Huawei; Li, Tianyou; Xu, Youyun; Su, Xinzhong; Qiao, Guopeng] Nanjing Univ Posts & Telecommun, Coll Telecommun & Informat Engn, 66 New model Rd, Nanjing 210003, Jiangsu, Peoples R China.
   [Tong, Huawei; Li, Tianyou; Xu, Youyun; Su, Xinzhong; Qiao, Guopeng] Natl Engn Res Ctr Commun & Networking, 66 New model Rd, Nanjing 210003, Jiangsu, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Xu, YY (corresponding author), Nanjing Univ Posts & Telecommun, Coll Telecommun & Informat Engn, 66 New model Rd, Nanjing 210003, Jiangsu, Peoples R China.; Xu, YY (corresponding author), Natl Engn Res Ctr Commun & Networking, 66 New model Rd, Nanjing 210003, Jiangsu, Peoples R China.
EM 2021010111@njupt.edu.cn; 314634357@qq.com; yyxu@njupt.edu.cn;
   suxinz20@163.com; 1020010219@njupt.edu.cn
RI Tong, huawei/IZD-5142-2023
OI Tong, huawei/0000-0001-7641-3547
FU National Key Research and Development Program of China [2016YFE0200200];
   Postgraduate Research amp; Practice Innovation Program of Jiangsu
   Province; National Natural Science Funds of China [61701253, 61801240]
FX AcknowledgementsThis document is the results of the research project
   funded by the National Key Research and Development Program of China
   under Contract No. 2016YFE0200200, Postgraduate Research & Practice
   Innovation Program of Jiangsu Province No. KYCX22_0937, the National
   Natural Science Funds of China under Contract No. 61701253 and 61801240.
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   Ahmad Musheer, 2018, International Journal of Information Technology, V10, P247, DOI 10.1007/s41870-018-0099-y
   Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Krishnan RB, 2022, WIRELESS PERS COMMUN, V127, P979, DOI 10.1007/s11277-021-08477-1
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chuman T, 2019, IEEE T INF FOREN SEC, V14, P1515, DOI 10.1109/TIFS.2018.2881677
   Dalal M, 2021, MULTIMED TOOLS APPL, V80, P5723, DOI 10.1007/s11042-020-09929-9
   Divya CD., 2021, DISCOV ARTIF INTELL, V1, P10, DOI [10.1007/s44163-021-00010-4, DOI 10.1007/S44163-021-00010-4]
   El-Samie F.E. A., 2013, Image encryption: A communication perspective, DOI 10.1201/b1630
   Ghazvini M, 2020, MULTIMED TOOLS APPL, V79, P26927, DOI 10.1007/s11042-020-09058-3
   Gupta A, 2018, NEURAL COMPUT APPL, V30, P1611, DOI 10.1007/s00521-016-2759-9
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Itier V, 2020, IEEE T CIRC SYST VID, V30, P646, DOI 10.1109/TCSVT.2019.2894520
   Kadhim IJ, 2020, COGN SYST RES, V60, P20, DOI 10.1016/j.cogsys.2019.11.002
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Li ZT, 2018, J INF SECUR APPL, V43, P47, DOI 10.1016/j.jisa.2018.10.006
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Mohsin AH, 2019, IEEE ACCESS, V7, P168994, DOI 10.1109/ACCESS.2019.2949622
   Muhammad Khan, 2018, Future Generation Computer Systems, V86, P951, DOI 10.1016/j.future.2016.11.029
   Muhuri PK, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106257
   Nipanikar SI, 2018, ALEX ENG J, V57, P2343, DOI 10.1016/j.aej.2017.09.005
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Roy A, 2019, OPTIK, V176, P119, DOI 10.1016/j.ijleo.2018.09.062
   Snasel V, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5448
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Song W, 2022, SIGNAL PROCESS-IMAGE, V102, DOI 10.1016/j.image.2021.116628
   Swain G, 2019, ARAB J SCI ENG, V44, P2995, DOI 10.1007/s13369-018-3372-2
   Tong HW, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03234-5
   Wang XY, 2021, OPT LASER ENG, V137, DOI 10.1016/j.optlaseng.2020.106393
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, OPT LASER TECHNOL, V115, P42, DOI 10.1016/j.optlastec.2019.02.009
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang ZL, 2019, IEEE T INF FOREN SEC, V14, P1280, DOI 10.1109/TIFS.2018.2871746
   Zeng J, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6675565
   Zhang Y, 2021, INFORM SCIENCES, V550, P313, DOI 10.1016/j.ins.2020.10.026
NR 42
TC 3
Z9 3
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20861
EP 20887
DI 10.1007/s11042-023-16240-w
EA AUG 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001042010700003
DA 2024-07-18
ER

PT J
AU Lin, ZB
   Yao, ZL
   Wang, SS
   Song, WZ
AF Lin, Zhanbo
   Yao, Zhilin
   Wang, Shengsheng
   Song, Whenzhuo
TI Enhancing signed social recommendation via extracting consistent and
   inconsistent relations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social recommendation; Graph neural networks; Signed social networks
ID NETWORK
AB Signed Social recommendations leverage signed social information(e.g., trust and distrust) to alleviate the cold-start and data sparsity problem. Recently, Graph Neural Network (GNN) methods have demonstrated the powerful in graph representation learning, which motivates GNN-based social recommendation frameworks. However, building GNN-based signed social recommender systems faces challenges. For example, signed social recommendations face the social inconsistency problem, which indicates that the evidence of item preferences provided by the social information and user-item interactions information are not necessarily consistent. In order to alleviate social inconsistency problem, we present a novel GNN-based Enhancing Signed Social Recommendation framework(ESSRec). Specifically, ESSRec first learns item-space user embedding and final item embedding by embedding propagation on the user-item graph. Then, it reconstructs the signed social graph by extracting consistently positive relations, consistently negative relations, and inconsistent relations from original graph based on the item-space user embedding. Moreover, we design the embedding propagation rule on the reconstructed signed social graph to empowered GNNs Model. Extensive experiments on real-world dataset Epinions demonstrate the effectiveness of the proposed framework ESSRec, with more than 8% on MAE and 4% on RMSE performance improvements over the best baseline for rating prediction. Further experiments demonstrate that extracting consistent and inconsistent relations and reconstructing signed social networks can improve the performance of ESSRec.
C1 [Lin, Zhanbo; Yao, Zhilin; Wang, Shengsheng] Jilin Univ, Coll Software, Changchun, Peoples R China.
   [Yao, Zhilin; Wang, Shengsheng] Jilin Univ, Coll Comp Sci & Technol, Changchun, Peoples R China.
   [Yao, Zhilin; Wang, Shengsheng] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun, Peoples R China.
   [Song, Whenzhuo] Northeast Normal Univ, Coll Informat Sci & Technol, Changchun, Peoples R China.
C3 Jilin University; Jilin University; Jilin University; Northeast Normal
   University - China
RP Wang, SS (corresponding author), Jilin Univ, Coll Software, Changchun, Peoples R China.; Wang, SS (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun, Peoples R China.; Wang, SS (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun, Peoples R China.
EM linzb20@mails.jlu.edu.cn; yaozl@jlu.edu.cn; wss@jlu.edu.cn;
   wzsong17@gmail.com
FU Innovation Capacity Construction Project of Jilin Province Development
   and Reform Commission [2021FGWCXNLJSSZ10]; National Key Research and
   Development Program of China [2020YFA0714103]; Fundamental Research
   Funds for the Central Universities (JLU); Natural Science Foundation of
   Jilin Province [20200201290JC]
FX AcknowledgementsThis work is supported by the Innovation Capacity
   Construction Project of Jilin Province Development and Reform
   Commission(2021FGWCXNLJSSZ10), the National Key Research and Development
   Program of China (No. 2020YFA0714103), the Fundamental Research Funds
   for the Central Universities (JLU) and the Natural Science Foundation of
   Jilin Province(20200201290JC).
CR Bai TS, 2015, SECOND EUROPEAN NETWORK INTELLIGENCE CONFERENCE (ENIC 2015), P60, DOI 10.1109/ENIC.2015.17
   Berg R. V. D., 2017, ARXIV
   Billsus D., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P46
   Breese J., 1998, P 14 C UNC ART INT, P43
   Cacheda F, 2011, ACM T WEB, V5, DOI 10.1145/1921591.1921593
   Canny J., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P238, DOI 10.1145/564376.564419
   Cao YX, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P151, DOI 10.1145/3308558.3313705
   CARTWRIGHT D, 1956, PSYCHOL REV, V63, P277, DOI 10.1037/h0046049
   Derr T, 2018, IEEE DATA MINING, P929, DOI 10.1109/ICDM.2018.00113
   Fan WQ, 2019, RECSYS 2019: 13TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P305, DOI 10.1145/3298689.3347011
   Fan WQ, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P417, DOI 10.1145/3308558.3313488
   GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867
   Goldberg K, 2001, INFORM RETRIEVAL, V4, P133, DOI 10.1023/A:1011419012209
   Guo GB, 2015, AAAI CONF ARTIF INTE, P123
   He XN, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P639, DOI 10.1145/3397271.3401063
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   He XN, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P549, DOI 10.1145/2911451.2911489
   Hofmann T, 2004, ACM T INFORM SYST, V22, P89, DOI 10.1145/963770.963774
   Huang Z, 2004, ACM T INFORM SYST, V22, P116, DOI 10.1145/963770.963775
   Jamali M., 2010, P 4 ACM C REC SYST, P135, DOI DOI 10.1145/1864708.1864736
   Kingma D. P., 2014, arXiv
   Konstan J., 2001, P 10 INT C WORLD WID, P285
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Leskovec J., 2010, P 19 INT C WORLD WID, P641, DOI [10.1145/1772690.1772756, DOI 10.1145/1772690.1772756]
   Lewis K, 2012, P NATL ACAD SCI USA, V109, P68, DOI 10.1073/pnas.1109739109
   Lin TH, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1767, DOI 10.1145/3269206.3269234
   Ma H., 2011, Proceedings of the 4th ACM International Conference on Web Search and Data Mining, P287
   Ma H, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961201
   MARSDEN PV, 1993, SOCIOL METHOD RES, V22, P127, DOI 10.1177/0049124193022001006
   Massa P, 2007, RECSYS 07: PROCEEDINGS OF THE 2007 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P17
   McPherson M, 2001, ANNU REV SOCIOL, V27, P415, DOI 10.1146/annurev.soc.27.1.415
   Puertas E, 2021, COGN COMPUT, V13, P518, DOI 10.1007/s12559-021-09818-9
   Resnick P., 1994, P ACM C COMP SUPP CO, P175
   Schein A. I., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P253, DOI 10.1145/564376.564421
   Shardanand U, 1994, THESIS MIT
   Song WZ, 2018, NEUROCOMPUTING, V319, P42, DOI 10.1016/j.neucom.2018.08.072
   Tang JL, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P31, DOI 10.1145/2872427.2882971
   Tang JL, 2016, AAAI CONF ARTIF INTE, P251
   Tang JL, 2013, SOC NETW ANAL MIN, V3, P1113, DOI 10.1007/s13278-013-0141-9
   Ungar L.H., 1998, Proceeding of Recommender Systems, Papers from 1998 Workshop, Technical Report WS-98-08 1998
   Victor P, 2011, IEEE INTELL SYST, V26, P48, DOI 10.1109/MIS.2011.22
   Wang X, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P165, DOI 10.1145/3331184.3331267
   Wang X, 2020, AAAI CONF ARTIF INTE, V34, P6267
   Wu L, 2023, IEEE T KNOWL DATA EN, V35, P4425, DOI 10.1109/TKDE.2022.3145690
   Wu L, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P235, DOI 10.1145/3331184.3331214
   Wu QT, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2091, DOI 10.1145/3308558.3313442
   Wu S.-J., 2020, arXiv
   Yang B, 2017, IEEE T PATTERN ANAL, V39, P1633, DOI 10.1109/TPAMI.2016.2605085
   Yang L., 2021, ARXIV
   Ying R, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P974, DOI 10.1145/3219819.3219890
   Zhang J., 2019, arXiv
   Zhang M., 2019, ARXIV
   Zheng L, 2018, 12TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS), P311, DOI 10.1145/3240323.3240343
   Zheng XY, 2018, WORLD WIDE WEB, V21, P985, DOI 10.1007/s11280-017-0494-5
NR 54
TC 1
Z9 1
U1 6
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19199
EP 19217
DI 10.1007/s11042-023-16276-y
EA JUL 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001035535000002
DA 2024-07-18
ER

PT J
AU Balasubramanian, M
   Ramyadevi, K
   Geetha, R
AF Balasubramanian, M.
   Ramyadevi, K.
   Geetha, R.
TI Deep transfer learning based real time face mask detection system with
   computer vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Computer vision; Transfer learning; Face mask detection
AB The COVID -19 pandemic has great impact in almost all life in the world. Till a immunogen is identified, everyone must be very careful about the spread of corona virus. Wearing a mask will definitely prevent us from corona virus. This results from the requirement to keep everyone safe from the virus's propagation. However, because current systems can't more effectively match faces with masks, the steps made to stop the virus' propagation present a problem for security and surveillance systems. Three methods are proposed to identify or detect whether person is sporting a mask or improper wearing of mask or a person with no mask. The ResNet152V2,VGG16 will work with still pictures and jointly works with a live video stream. A mask detection dataset consists of pictures of both mask wearing and without mask wearing. OpenCV is used to do the real time face detection. It checks whether mask is properly worn over the nose area by completely covering chin and mouth. The proposed mask symbol is least complicated in structure and provides fast results so it is used in video surveillance. Mass screening is possible and thus utilized in thronged places like railway stations, bus stops, markets, streets, mall entrances, schools, colleges and so on. In proposed system, ResNet152V2 model is used for robust face detection. The head based model is selected for classifying faces as masked or non-masked. Finally computer vision concepts are added to improve performance on video streams. The results demonstrate that the proposed model improves accuracy by 99.1%, performance of precision by 99.2%, F1-score by 99.1%. It is identified that the proposed model ResNet152V2 accomplished highest results.
C1 [Balasubramanian, M.; Geetha, R.] SA Engn Coll, Dept Comp Sci & Engn, Chennai, India.
   [Ramyadevi, K.] RMK Engn Coll, Dept Comp Sci & Engn, Chennai, India.
C3 S.A. Engineering College; R.M.K. Engineering College
RP Geetha, R (corresponding author), SA Engn Coll, Dept Comp Sci & Engn, Chennai, India.
EM geetha@saec.ac.in
RI Asst.Professor, Ms. Ramya devi K/AAA-4706-2022
OI , Geetha/0000-0002-4541-3314
CR Abboah-Offei M, 2021, INT J NURS STUD ADV, V3, DOI 10.1016/j.ijnsa.2020.100013
   Abdulkareem KH, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5012962
   Chavali C, 2014, ARXIV
   Chollet F., 2017, arXiv
   Das A, 2020, 2020 IEEE PUNE SECTION INTERNATIONAL CONFERENCE (PUNECON), P1, DOI 10.1109/PuneCon50868.2020.9362416
   Dong J, 2014, LECT NOTES COMPUT SC, V8693, P299, DOI 10.1007/978-3-319-10602-1_20
   Eikenberry SE, 2020, INFECT DIS MODEL, V5, P293, DOI 10.1016/j.idm.2020.04.001
   Geetha R., 2022, Research on Biomedical Engineering, P955, DOI 10.1007/s42600-022-00230-2
   Geetha R, 2021, MULTIMED TOOLS APPL, V80, P19675, DOI 10.1007/s11042-021-10696-4
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Grassi M, 2007, APPL NEURAL NETWORKS, DOI [10.1007/978-3-540-73007-1_85, DOI 10.1007/978-3-540-73007-1_85]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hussain G. K. Jakir, 2021, Journal of Physics: Conference Series, V1916, DOI 10.1088/1742-6596/1916/1/012084
   Jignesh Chowdary G., 2020, Big Data Analytics. 8th International Conference, BDA 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12581), P81, DOI 10.1007/978-3-030-66665-1_6
   Karnati M, 2022, APPL SOFT COMPUT, V125, DOI 10.1016/j.asoc.2022.109109
   Karnati M, 2022, IEEE T COGN DEV SYST, V14, P971, DOI 10.1109/TCDS.2021.3086011
   Kisan S., 2020, INT J ADV SCI TECHNO, V29, P3878
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mangla Monika, 2021, 2021 2nd International Conference on Secure Cyber Computing and Communications (ICSCCC), P170, DOI 10.1109/ICSCCC51823.2021.9478175
   Matthias D, 2021, FACE MASK DETECTION, DOI [10.13140/RG.2.2.18493.59368, DOI 10.13140/RG.2.2.18493.59368]
   Mbunge E., 2021, Sustainable Operations and Computers, V2, P235, DOI [10.1016/j.susoc.2021.08.001, DOI 10.1016/J.SUSOC.2021.08.001]
   Mohammed HJ, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10193530
   Mohammed MA, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/1307944
   Mohan K, 2021, NEURAL COMPUT APPL, V33, P9125, DOI 10.1007/s00521-020-05676-y
   Mohan K, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3031835
   Mukhlif AA., 2023, Iraqi J Comput Sci Math, V4, P167, DOI DOI 10.52866/IJCSM.2023.01.01.0014
   Mukhlif AA, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23020570
   Rahman MM, 2020, AEROSP CONF PROC, DOI 10.1109/aero47225.2020.9172295
   Razavi Moein, 2022, SN Comput Sci, V3, P27, DOI 10.1007/s42979-021-00894-0
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sanjaya S.A., 2020, 2020 INT C DAT AN BU, P1, DOI DOI 10.1109/ICDABI51230.2020.9325631
   Sethi S, 2021, J BIOMED INFORM, V120, DOI 10.1016/j.jbi.2021.103848
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Teboulbi S, 2021, SCI PROGRAMMING-NETH, V2021, DOI 10.1155/2021/8340779
   Tomás J, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9081050
   Viola P, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P747
NR 38
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17511
EP 17530
DI 10.1007/s11042-023-16192-1
EA JUL 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001033666900003
DA 2024-07-18
ER

PT J
AU Subashini, MM
   Vignesh, RS
AF Subashini, M. Monica
   Vignesh, R. S.
TI Thermoplastic waste segregation classification system using deep
   learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Plastic wastage; Feature extraction; CNN; Segregation; Deep learning
   techniques
ID OBJECT
AB This research proposes a deep learning-based system, named deep CNN architecture, for the automated classification of the plastic resin in plastic waste. The system aims to detect and recognize objects such as drinking water bottles, detergent bottles, squeezable bottles, and plastic plates, and segregate them into PET, PE-HD, PE-LD, and other resin categories. The process involves capturing input images through a camera and using deep learning or traditional algorithms to detect and recognize the objects by comparing them with a trained database containing labeled objects. Unrecognized objects are dynamically trained, labeled, and updated in the database. The proposed system is implemented using Python, a versatile open-source programming language. Python's functional and aspect-oriented programming paradigms are leveraged to develop the models. The performance of the proposed architecture is evaluated against existing works, demonstrating a classification accuracy of 92.66% according to experimental results.
C1 [Subashini, M. Monica] Vellore Inst Technol, Dept Control & Automation, Vellore 632014, Tamil Nadu, India.
   [Vignesh, R. S.] Vellore Inst Technol, Sch Elect Engn, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of
   Technology (VIT); VIT Vellore
RP Subashini, MM (corresponding author), Vellore Inst Technol, Dept Control & Automation, Vellore 632014, Tamil Nadu, India.
EM monicasubashini.m@vit.ac.in; vignesh.rs@vit.ac.in
OI R S, Vignesh/0000-0002-9130-9008
CR Aref MM, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL AND INFORMATION PROCESSING (ICICIP), P236, DOI 10.1109/ICICIP.2018.8606719
   Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Bobulski J., 2018, Advances in Intelligent Systems and Computing, V681, P57, DOI DOI 10.1007/978-3-319-68720-9
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Chen JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105393
   Costa P, 2018, IEEE T MED IMAGING, V37, P781, DOI 10.1109/TMI.2017.2759102
   Ekundayo Oluwatobi, 2022, Intelligent Systems and Applications: Proceedings of the 2021 Intelligent Systems Conference (IntelliSys). Lecture Notes in Networks and Systems (296), P405, DOI 10.1007/978-3-030-82199-9_26
   Fallati L, 2019, SCI TOTAL ENVIRON, V693, DOI 10.1016/j.scitotenv.2019.133581
   Fulton M, 2019, IEEE INT CONF ROBOT, P5752, DOI [10.1109/ICRA.2019.8793975, 10.1109/icra.2019.8793975]
   Gopan L, 2018, L N COMPUT VIS BIOME, V28, P447, DOI 10.1007/978-3-319-71767-8_37
   Hahladakis JN, 2019, J HAZARD MATER, V380, DOI 10.1016/j.jhazmat.2019.120887
   Hussain MAI, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9061048
   Jeon HK, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020311
   Khaing MP, 2019, ADV INTELL SYST COMP, V744, P86, DOI 10.1007/978-981-13-0869-7_10
   Kiyokawa T, 2019, IEEE ROBOT AUTOM LET, V4, P1972, DOI 10.1109/LRA.2019.2899153
   Leng JX, 2021, NEUROCOMPUTING, V433, P287, DOI 10.1016/j.neucom.2020.12.093
   Liu Y, 2021, EXPERT SYST APPL, V172, DOI 10.1016/j.eswa.2021.114602
   Lorenzo-Navarro J, 2020, IEEE ACCESS, V8, P25249, DOI 10.1109/ACCESS.2020.2970498
   Madessa AH, 2019, 2019 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI 2019), P406, DOI 10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00113
   Mahmoudi MR, 2021, ALEX ENG J, V60, P1137, DOI 10.1016/j.aej.2020.10.037
   McDonnell MD, 2019, 2019 DIG IM COMP TEC, P1
   Music J., 2020, P 5 INT C SMART SUST, P1, DOI [DOI 10.23919/SPLITECH49282.2020.9243709, 10.23919/splitech49282.2020.9243709]
   Nasiri E, 2023, MULTIMED TOOLS APPL, V82, P3745, DOI 10.1007/s11042-022-12943-8
   Persak T, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10124269
   Pfaller JB, 2020, CURR BIOL, V30, pR213, DOI 10.1016/j.cub.2020.01.071
   Politikos DV, 2021, MAR POLLUT BULL, V164, DOI 10.1016/j.marpolbul.2021.111974
   Rowe SP, 2018, EUR UROL, V73, P485, DOI 10.1016/j.eururo.2017.10.027
   Shenderov E, 2018, UROL CASE REP, V17, P22, DOI 10.1016/j.eucr.2017.12.011
   Wang QR, 2019, IEEE T MULTIMEDIA, V21, P1839, DOI 10.1109/TMM.2018.2890360
   Werner RA, 2018, ANN NUCL MED, V32, P512, DOI 10.1007/s12149-018-1291-7
   Zhu Y, 2019, PROC CVPR IEEE, P8848, DOI 10.1109/CVPR.2019.00906
NR 32
TC 0
Z9 0
U1 7
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17451
EP 17467
DI 10.1007/s11042-023-16237-5
EA JUL 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001033666900002
DA 2024-07-18
ER

PT J
AU Sun, QF
   Xu, JY
   Duan, YX
   Zhang, PY
   Jiang, N
   Alsoud, AR
   Abualigah, L
AF Sun, Qifeng
   Xu, Jiayue
   Duan, Youxiang
   Zhang, Peiying
   Jiang, Nan
   Alsoud, Anas Ratib
   Abualigah, Laith
TI Improving word similarity computation accuracy by multiple parameter
   optimization based on ontology knowledge
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic similarity; Semantic distance; Ontology Knowledge Base; Network
   public opinion
ID SEMANTIC SIMILARITY; NETWORKS
AB Word similarity computation is one of the most fundamental areas of research in semantic information processing. Prior studies on Chinese word similarity computation have mostly adopted rule-based methods. Some studies have been conducted on English word similarity computation using the notable knowledge base WordNet. English word similarity computation methods cannot be used directly for word similarity computation. Therefore, we find a ontology knowledge base whose hierarchical structure is similar to WordNet. With the help of it, we develop an improved Chinese word similarity computation method, therein incorporating the common depth, depth parameter, depth adjustment parameter, concept relation parameter, density parameter and differential value into the Chinese word similarity computation process. First, we perform an in-depth analysis on the merits and disadvantages of existing word semantic similarity computation approaches; then, we investigate the effect of several factors on the word semantic similarity computation. Finally, we utilize the hierarchical tree structure of the ontology knowledge base to improve the word similarity computation accuracy. The experimental results show that our proposed method outperforms state-of-the-art methods. Network public opinion is the mapping of social public opinion on the Internet. By using the means of similarity calculation, a platform of online public opinion with prediction and early warning can be built to quickly find the hinge point of public opinion, which provides rich data support for the management.
C1 [Sun, Qifeng; Xu, Jiayue] China Univ Petr East China, Coll Comp Sci & Technol, Qingdao 266580, Peoples R China.
   [Duan, Youxiang; Zhang, Peiying] East China Jiaotong Univ, Dept Internet Things, Nanchang 330013, Peoples R China.
   [Jiang, Nan; Alsoud, Anas Ratib; Abualigah, Laith] Al Ahliyya Amman Univ, Hourani Ctr Appl Sci Res, Amman, Jordan.
   [Abualigah, Laith] Al Al Bayt Univ, Prince Hussein Bin Abdullah Fac Informat Technol, Comp Sci Dept, Mafraq 25113, Jordan.
   [Abualigah, Laith] Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos 135053, Lebanon.
   [Abualigah, Laith] Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
   [Abualigah, Laith] Appl Sci Private Univ, Appl Sci Res Ctr, Amman 11931, Jordan.
   [Abualigah, Laith] Univ Sains Malaysia, Sch Comp Sci, Pulau 11800, Pinang, Malaysia.
   [Abualigah, Laith] Sunway Univ Malaysia, Sch Engn & Technol, Petaling Jaya 27500, Malaysia.
C3 China University of Petroleum; East China Jiaotong University;
   Al-Ahliyya Amman University; Al al-Bayt University; Lebanese American
   University; Middle East University; Universiti Sains Malaysia; Sunway
   University
RP Abualigah, L (corresponding author), Al Ahliyya Amman Univ, Hourani Ctr Appl Sci Res, Amman, Jordan.; Abualigah, L (corresponding author), Al Al Bayt Univ, Prince Hussein Bin Abdullah Fac Informat Technol, Comp Sci Dept, Mafraq 25113, Jordan.; Abualigah, L (corresponding author), Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos 135053, Lebanon.; Abualigah, L (corresponding author), Middle East Univ, MEU Res Unit, Amman 11831, Jordan.; Abualigah, L (corresponding author), Appl Sci Private Univ, Appl Sci Res Ctr, Amman 11931, Jordan.; Abualigah, L (corresponding author), Univ Sains Malaysia, Sch Comp Sci, Pulau 11800, Pinang, Malaysia.; Abualigah, L (corresponding author), Sunway Univ Malaysia, Sch Engn & Technol, Petaling Jaya 27500, Malaysia.
EM sunqf_upc@163.com; 191491952@qq.com; yxduan@upc.edu.cn; 25640521@qq.com;
   jiangnan@ecjtu.edu.cn; a.alsoud@ammanu.edu.jo; aligah.2020@gmail.com
RI Abualigah, Laith/ABC-9695-2020; ALSOUD, ANAS RATIB/AAM-7546-2021; xu,
   jiayue/AAD-9811-2022
OI Abualigah, Laith/0000-0002-2203-4549; ALSOUD, ANAS
   RATIB/0000-0002-1410-8843; 
FU National Natural Science Foundation of China [41930429]; CNPC Major
   Science and Technology Project [ZD2019-183-006]; special fund for basic
   scientific research operations of central universities [20CX05017A]
FX AcknowledgmentsThis work is partially supported by the National Natural
   Science Foundation of China under Grant 41930429; CNPC Major Science and
   Technology Project (ZD2019-183-006); special fund for basic scientific
   research operations of central universities (20CX05017A); joint funding.
CR Agirre E, 1997, AMST STUD THEORY HIS, V136, P161
   Baker CF, 2002, M ASS COMPUTATIONAL, P86
   BROWN PF, 1991, 29TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS : PROCEEDINGS OF THE CONFERENCE, P264
   [蔡东风 Cai Dongfeng], 2010, [中文信息学报, Journal of Chinese Information Processing], V24, P24
   Chen YF, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P631
   Dagan I, 1999, MACH LEARN, V34, P43, DOI 10.1023/A:1007537716579
   Dong Z., 1998, LANG LIT APPL, V3, P76282
   Ehsani R, 2016, BMC BIOINFORMATICS, V17, DOI 10.1186/s12859-016-1160-0
   Fan MJ, 2015, 2015 12th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD), P1487, DOI 10.1109/FSKD.2015.7382164
   HIT-IRLab, HIT IR LAB TONG CIL
   Huang DG, 2018, ACM T ASIAN LOW-RESO, V17, DOI 10.1145/3182622
   Khaledian N, 2023, EXPERT SYST APPL, V228, DOI 10.1016/j.eswa.2023.120487
   LEE JH, 1993, J DOC, V49, P188, DOI 10.1108/eb026913
   Lee LJ, COMPUT THERM SCI
   Li S, 2008, NATURAL LANGUAGE PRO
   Li S., 2009, ACL/AFNLP'09, P692
   Li YH, 2003, IEEE T KNOWL DATA EN, V15, P871, DOI 10.1109/TKDE.2003.1209005
   Li YF, 2023, ENG STRUCT, V283, DOI 10.1016/j.engstruct.2023.115891
   Liu Q., 2002, Computational Linguistics and Chinese Language Processing, P59
   Lu W, 2016, INT J INTERDISCIP TE, V8, P45, DOI 10.4018/IJITN.2016040105
   [梅立军 Mei Lijun], 2005, [中文信息学报, Journal of Chinese Information Processing], V19, P63
   MILLER GA, 1991, LANG COGNITIVE PROC, V6, P1, DOI 10.1080/01690969108406936
   Nama S, 2023, SWARM EVOL COMPUT, V79, DOI 10.1016/j.swevo.2023.101304
   Nghia-Nguyen T, 2023, EXPERT SYST APPL, V223, DOI 10.1016/j.eswa.2023.119832
   Ning WX, 2016, J BIOMED INFORM, V64, P273, DOI 10.1016/j.jbi.2016.10.017
   Peiying Zhang, 2013, 2013 IEEE International Conference on Green Computing and Communications (GreenCom) and IEEE Internet of Things (iThings) and IEEE Cyber, Physical and Social Computing (CPSCom), P1638, DOI 10.1109/GreenCom-iThings-CPSCom.2013.297
   Resnik P, 1999, J ARTIF INTELL RES, V11, P95, DOI 10.1613/jair.514
   Richardson S., 1998, Proceedings of 17th International Conference on Computational Linguistics, P1098, DOI DOI 10.3115/980691
   RUBENSTEIN H, 1965, COMMUN ACM, V8, P627, DOI 10.1145/365628.365657
   Sánchez D, 2015, ENG APPL ARTIF INTEL, V39, P89, DOI 10.1016/j.engappai.2014.11.012
   Siming L, 2008, THESIS BEIJING U POS
   Tao Z, 2005, THESIS SHANXI U
   Tu M, ENHANCING GRAMMATICA
   Wei Wei, 2010, Journal of Computer Applications, V30, P1668, DOI 10.3724/SP.J.1087.2010.01668
   Wu YF, 2016, LECT NOTES COMPUT SC, V10102, P828, DOI 10.1007/978-3-319-50496-4_75
   Xia R, 2011, INFORM SCIENCES, V181, P1138, DOI 10.1016/j.ins.2010.11.023
   Xia Tian, 2007, Computer Engineering, V33, P191
   Xu J, J INF SCI ENG, V31
   Xun E, J CHINA SOC SCI TECH
   [于江生 Yu Jiangsheng], 2002, [中文信息学报, Journal of Chinese Information Processing], V16, P12
   Yushang Mao, 2020, 2020 International Conference on Culture-oriented Science & Technology (ICCST), P304, DOI 10.1109/ICCST50977.2020.00065
   Zare M., 2023, J. Bionic Eng., V5, P1
   Zare M, 2023, DECISION ANAL J, V7
   Zhang JJ, 2015, IEEE INTELL SYST, V30, P16, DOI 10.1109/MIS.2015.69
   Zhang QP, 2016, IEEE-CAA J AUTOMATIC, V3, P132, DOI 10.1109/JAS.2016.7451100
   [章志凌 ZHANG Zhiling], 2006, [计算机应用, Computer Applications], V26, P638
   [朱新华 Zhu Xinhua], 2016, [中文信息学报, Journal of Chinese Information Processing], V30, P29
NR 47
TC 0
Z9 0
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17469
EP 17489
DI 10.1007/s11042-023-16122-1
EA JUL 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035725700002
DA 2024-07-18
ER

PT J
AU Shim, JY
   Jung, SY
   Kim, J
   Kim, JK
AF Shim, Joo Yong
   Jung, Soyi
   Kim, Joongheon
   Kim, Jong-Kook
TI Stabilized Performance Maximization for GAN-based Real-Time
   Authentication Image Generation over Internet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE CAPTCHA; Authentication; Security; Lyapunov optimization; Generative
   adversarial network (GAN)
ID MARKOV DECISION POLICIES; WIRELESS
AB Providing the completely automated public test to tell computers and humans apart (CAPTCHA) services that are not vulnerable to learning is an important issue. Image-based CAPTCHA services have strengthened authentication by taking advantage of the fact that it is more difficult for computers to understand images, but the rapid growth of deep learning has made it possible to break and attack authentication. Image-based CAPTCHA uses pre-stored data, which enables learning and results in vulnerability. This paper presents an adaptive generative adversarial network (GAN) selection scheme using time-average image quality maximization subject to system/buffer stability. By using GAN, it can generate and provide new images for CAPTCHA authentication every time, preventing deep learning from learning images and enhancing security. In the image generation process, the trade-off exists between image quality and generation time, and in consideration of this trade-off, delay aware image-based authentication Lyapunov-based algorithm is proposed for stable and maximized performance. Moreover, through the performance evaluation, we investigate and show the existence of trade-off between generation time and generated image quality in the image generation process in both quantitative and qualitative manner.
C1 [Shim, Joo Yong; Kim, Joongheon; Kim, Jong-Kook] Korea Univ, Sch Elect Engn, Anam Ro 145, Seoul 02841, South Korea.
   [Jung, Soyi] Ajou Univ, Dept Elect & Comp Engn, Suwon 16499, South Korea.
C3 Korea University; Ajou University
RP Kim, JK (corresponding author), Korea Univ, Sch Elect Engn, Anam Ro 145, Seoul 02841, South Korea.
EM shimjoo@korea.ac.kr; sjung@ajou.ac.kr; joongheon@korea.ac.kr;
   jongkook@korea.ac.kr
RI Jung, Soyi/AAS-4333-2021
OI Jung, Soyi/0000-0001-8435-0646
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2016R1D1A1B04933156,
   NRF-2019M3E3A1084054]; Brain Korea 21 FOUR Project
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education under support programs (NRF-2016R1D1A1B04933156 and
   NRF-2019M3E3A1084054), and Brain Korea 21 FOUR Project in 2023.
CR Aziz MN, 2018, ELECTR POWER ELECTR, P332, DOI 10.1109/EECCIS.2018.8692982
   Bethanabhotla D, 2016, IEEE T WIREL COMMUN, V15, P4088, DOI 10.1109/TWC.2016.2533496
   Bethanabhotla D, 2016, IEEE T WIREL COMMUN, V15, P1835, DOI 10.1109/TWC.2015.2496942
   Bethanabhotla D, 2015, IEEE T COMMUN, V63, P268, DOI 10.1109/TCOMM.2014.2378774
   Choi M, 2019, IEEE T WIREL COMMUN, V18, P5705, DOI 10.1109/TWC.2019.2938755
   Choi M, 2018, IEEE J SEL AREA COMM, V36, P1245, DOI 10.1109/JSAC.2018.2844980
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hassaballah M, 2021, IEEE T IND INFORM, V17, P7743, DOI 10.1109/TII.2021.3053595
   Hou L, 2021, AAAI CONF ARTIF INTE, V35, P7746
   Jung S, 2021, IEEE SYST J, P1, DOI DOI 10.1109/JSYST.2020.3014231
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Kim J., 2013, P 19 ANN INT C MOBIL, P127, DOI DOI 10.1145/2500423.2505292
   Kim J, 2016, IEEE ACM T NETWORK, V24, P2319, DOI 10.1109/TNET.2015.2452272
   Koo J, 2019, IEEE T MOBILE COMPUT, V18, P1647, DOI 10.1109/TMC.2018.2863234
   Li MY, 2022, IEEE T PATTERN ANAL, V44, P9331, DOI 10.1109/TPAMI.2021.3126742
   Neely M., 2010, STOCHASTIC NETWORK O
   Neely MJ, 2013, IEEE T AUTOMAT CONTR, V58, P1948, DOI 10.1109/TAC.2013.2256682
   Salimans T, 2016, ADV NEUR IN, V29
   Shim JY, 2021, INT C PATT RECOG, P2226, DOI 10.1109/ICPR48806.2021.9412721
   Shim J, 2021, 35TH INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2021), P422, DOI 10.1109/ICOIN50884.2021.9333991
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tang MY, 2018, IEEE T INF FOREN SEC, V13, P2522, DOI 10.1109/TIFS.2018.2821096
   TASSIULAS L, 1992, IEEE T AUTOMAT CONTR, V37, P1936, DOI 10.1109/9.182479
NR 23
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUL 15
PY 2023
DI 10.1007/s11042-023-15885-x
EA JUL 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M3HP8
UT WOS:001029126000010
OA hybrid
DA 2024-07-18
ER

PT J
AU Ding, XT
   Li, BQ
   Zhou, W
   Zhao, C
AF Ding, Xintao
   Li, Boquan
   Zhou, Wen
   Zhao, Cheng
TI Core sample consensus method for two-view correspondence matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Two-view geometry; Correspondence matching; RANSAC; GPU calculation;
   Gradient difference
ID RANSAC; REGISTRATION; STATISTICS
AB Exploring reliable correspondences in a given putative set is a fundamental task in twoview geometry estimation. The random sample consensus (RANSAC) method is a widely used estimator. It typically searches inliers within the putative correspondences initialized by the local similarity of the descriptors. However, RANSAC may be inefficient when actual inliers are heavily contaminated by mismatches. In this study, we attempt to identify true inliers from heavily contaminated two-view correspondences and propose a parallel core sample consensus (CSAC) method based on gradient difference. CSAC employs the gradient difference between two images as a globalmetric to compensate for the locality of the typical initialization. First, a pool of errors is constructed in parallel based on the gradient differences of the pixels between a pair of correspondences. For four keypoints of two correspondences, the gradients of the pixels on the line between two keypoints in each image are calculated. The error of the two correspondences is the average difference between the two resulting gradient serials. Second, a core set is constructed using the correspondences with the topk smallest errors in the pool. Subsequently, CSAC searches the inliers in the input set via parallel testing of the minimal sets sampled in the core set. Finally, post-processing refines the resulting inliers based on neighborhood preservation. Experiments comparing seven state-ofthe-art methods are conducted on eight publicly available datasets. The experimental results indicate that CSAC outperforms the other competing methods in terms of inlier precision and model accuracy. The source code is available at https://github.com/xintaoding/ CSAC.
C1 [Ding, Xintao; Zhou, Wen; Zhao, Cheng] Anhui Normal Univ, Sch Comp & Informat, Wuhu 241002, Anhui, Peoples R China.
   [Ding, Xintao; Zhou, Wen; Zhao, Cheng] Anhui Prov Key Lab Network & Informat Secur, Wuhu 241002, Anhui, Peoples R China.
   [Ding, Xintao; Zhou, Wen] Anhui Engn Res Ctr Med Big Data Intelligent Syst, Wuhu 241002, Anhui, Peoples R China.
   [Li, Boquan] Anhui Normal Univ, Sch Math & Stat, Wuhu 241002, Anhui, Peoples R China.
C3 Anhui Normal University; Anhui Normal University
RP Ding, XT (corresponding author), Anhui Normal Univ, Sch Comp & Informat, Wuhu 241002, Anhui, Peoples R China.; Ding, XT (corresponding author), Anhui Prov Key Lab Network & Informat Secur, Wuhu 241002, Anhui, Peoples R China.; Ding, XT (corresponding author), Anhui Engn Res Ctr Med Big Data Intelligent Syst, Wuhu 241002, Anhui, Peoples R China.
EM dincent@ahnu.edu.cn; lbq7880@ahnu.edu.cn; w.zhou@ahnu.edu.cn;
   ntmaple@ahnu.edu.cn
RI Ding, Xintao/I-7890-2014
OI Ding, Xintao/0000-0003-3325-3306
FU Anhui Provincial Natural Science Foundation [1808085MF171]; National
   Natural Science Foundation of China [62272006, 61972439, 61976006]
FX AcknowledgementsThis work was supported by Anhui Provincial Natural
   Science Foundation (1808085MF171); the National Natural Science
   Foundation of China (62272006, 61972439, 61976006).
CR Barath D, 2022, IEEE T PATTERN ANAL, V44, P4961, DOI 10.1109/TPAMI.2021.3071812
   Bian JW, 2017, PROC CVPR IEEE, P2828, DOI 10.1109/CVPR.2017.302
   Chum O, 2008, IEEE T PATTERN ANAL, V30, P1472, DOI 10.1109/TPAMI.2007.70787
   Ding YQ, 2021, PROC CVPR IEEE, P394, DOI 10.1109/CVPR46437.2021.00046
   Fang BF, 2020, INT J ADV ROBOT SYST, V17, DOI 10.1177/1729881420904193
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fotouhi M, 2019, MULTIMED TOOLS APPL, V78, P9429, DOI 10.1007/s11042-018-6475-6
   Gao HH, 2023, IEEE T INTELL TRANSP, V24, P8831, DOI 10.1109/TITS.2022.3219474
   Gao HH, 2024, IEEE T NEUR NET LEAR, V35, P4826, DOI 10.1109/TNNLS.2022.3155486
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Imre E, 2015, INT J COMPUT VISION, V111, P276, DOI 10.1007/s11263-014-0745-1
   Ivashechkin Maksym, 2021, P IEEE CVF INT C COM, P15243
   Jiang JJ, 2023, IEEE T IND INFORM, V19, P328, DOI 10.1109/TII.2022.3165979
   Jin YH, 2021, INT J COMPUT VISION, V129, P517, DOI 10.1007/s11263-020-01385-0
   Jun C, 2022, MULTIMED TOOLS APPL, V81, P3939, DOI 10.1007/s11042-021-11731-0
   Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95
   Li JY, 2021, IEEE T GEOSCI REMOTE, V59, P9716, DOI 10.1109/TGRS.2020.3045456
   Li XR, 2010, INT J COMPUT VISION, V89, P1, DOI 10.1007/s11263-010-0318-x
   Li YM, 2017, COMPUT VIS IMAGE UND, V161, P99, DOI 10.1016/j.cviu.2017.05.013
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma JY, 2019, INT J COMPUT VISION, V127, P512, DOI [10.1109/TMAG.2017.2763198, 10.1007/s11263-018-1117-z]
   Ma JL, 2022, IET CONTROL THEORY A, V16, P1, DOI [10.1049/cth2.12191, 10.1109/TMM.2022.3162115]
   Ma SH, 2021, INFORM SCIENCES, V562, P452, DOI 10.1016/j.ins.2021.03.023
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Myatt D. R., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P458
   Nasiri SM, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108805
   Raguram R, 2013, IEEE T PATTERN ANAL, V35, P2022, DOI 10.1109/TPAMI.2012.257
   Ren K, 2022, OPTIK, V259, DOI 10.1016/j.ijleo.2022.169033
   Sarlin PE, 2020, PROC CVPR IEEE, P4937, DOI 10.1109/CVPR42600.2020.00499
   Sun ZL, 2022, MULTIMED TOOLS APPL, V81, P11107, DOI 10.1007/s11042-022-12134-5
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Truong G, 2023, IEEE T PATTERN ANAL, V45, P3890, DOI 10.1109/TPAMI.2022.3178442
   Wan ZH, 2022, IEEE T IND INFORM, V18, P3640, DOI 10.1109/TII.2021.3118022
   Wang WQ, 2022, J ELECTRON IMAGING, V31, DOI 10.1117/1.JEI.31.2.023039
   Wong HS, 2011, IEEE I CONF COMP VIS, P1044, DOI 10.1109/ICCV.2011.6126350
   Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458
   Yang LJ, 2022, APPL INTELL, V52, P10576, DOI 10.1007/s10489-021-02990-3
   Yi KM, 2018, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2018.00282
   Yin L, 2021, APPL INTELL, V51, P3664, DOI 10.1007/s10489-020-01967-y
   Zhang JH, 2019, IEEE I CONF COMP VIS, P5844, DOI 10.1109/ICCV.2019.00594
   Zhao J, 2022, IEEE T PATTERN ANAL, V44, P1777, DOI 10.1109/TPAMI.2020.3030161
NR 41
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUL 12
PY 2023
DI 10.1007/s11042-023-16080-8
EA JUL 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M2UA6
UT WOS:001028770200007
DA 2024-07-18
ER

PT J
AU Malik, M
   Joshi, A
   Sakya, G
AF Malik, Monika
   Joshi, Alok
   Sakya, Gayatri
TI Optimized leach protocol for energy management in wireless sensor
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cluster head; Low energy node; High energy node; Cluster node; Sensor
   node; Wireless sensor network
AB Wireless Sensor Network (WSN) is a robust communication network because it holds a lot of advancements like sensing and tracking events. However, high energy consumption is the main drawback of the WSN. The higher energy consumption node affects the communication of WSN by signal loss and packet transmission. Many techniques were developed to overcome the issues of high energy consumption nodes, but those techniques have reported problems in identifying cluster heads. In addition, it has recorded high packet loss and signal transmission during data transmission. So, a new Buffalo-based Energy Optimized LEACH Protocol (BEOLP) is designed to enhance communication performance in WSN. Thus the developed BEOLP technique identifies the less energy and high energy consumption nodes at an earlier stage of the energy-aware phase, and the high energy consumption node is neglected. Moreover, a temporary route is developed to avoid sudden signal failure and packet drop. Thus the developed technique is implemented in MATLAB with 125 nodes; also, Cluster Head (CH) is recognized based on the threshold value. Finally, a successive score of the developed method is related to other existing methods concerning throughput, energy consumption, delay, packet transmission rate, and packet loss.
C1 [Malik, Monika; Sakya, Gayatri] JSS Acad Tech Educ, Dept Elect & Commun Engn, Noida 201301, Uttar Pradesh, India.
   [Joshi, Alok] Jaypee Inst Informat & Technol, Dept Elect & Commun Engn, Noida 201309, Uttar Pradesh, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Malik, M (corresponding author), JSS Acad Tech Educ, Dept Elect & Commun Engn, Noida 201301, Uttar Pradesh, India.
EM monikamalik@jssaten.ac.in; alok.joshi@jiit.ac.in;
   gayatri.sakya@rediffmail.com
RI MALIK, MONIKA/W-1370-2018
OI SAKYA, Dr GAYATRI/0000-0002-4994-6505
CR Abdulsahib GM, 2021, J INFO TECH MANAGE, VManag13, P139, DOI DOI 10.22059/JITM.2021.80359
   Abraham R, 2023, WIRELESS PERS COMMUN, V130, P1503, DOI 10.1007/s11277-023-10342-2
   ALBAZ Ahmed, 2015, 2015 25 INT C COMP T, DOI [10.1109/ICCTA37466.2015.9513448, DOI 10.1109/ICCTA37466.2015.9513448]
   Angurala Mohit, 2021, International Journal of Information Technology, V13, P269, DOI 10.1007/s41870-020-00561-2
   Baradaran AA, 2023, IJST-T ELECTR ENG, V47, P1129, DOI 10.1007/s40998-022-00587-1
   Batool K, 2017, COMPLEX ADAPT SYST M, V5, DOI 10.1186/s40294-017-0043-1
   Bhola J, 2020, J AMB INTEL HUM COMP, V11, P1281, DOI 10.1007/s12652-019-01382-3
   Bhushan B, 2019, STUD COMPUT INTELL, V776, P215, DOI 10.1007/978-3-662-57277-1_10
   Chaurasia S, 2023, AD HOC NETW, V141, DOI 10.1016/j.adhoc.2022.103079
   Daanoune I, 2021, AD HOC NETW, V114, DOI 10.1016/j.adhoc.2020.102409
   Devika G., 2021, International Journal of Information Technology, V13, P721, DOI 10.1007/s41870-020-00597-4
   Diefenbach D, 2018, KNOWL INF SYST, V55, P529, DOI 10.1007/s10115-017-1100-y
   Din S, 2019, PEER PEER NETW APPL, V12, P348, DOI 10.1007/s12083-017-0607-z
   Fotohi R, 2020, J SUPERCOMPUT, V76, P6860, DOI 10.1007/s11227-019-03131-x
   Gulganwa Pooja, 2022, International Journal of Information Technology, V14, P135, DOI 10.1007/s41870-021-00744-5
   Gupta AR, 2021, ENVIRON SCI POLLUT R, V28, P19166, DOI 10.1007/s11356-020-11916-4
   Hasan K, 2019, J NETW COMPUT APPL, V143, P178, DOI 10.1016/j.jnca.2019.06.016
   Hnini A., 2020, PROCEDIA COMPUT SCI, V175, P548, DOI [10.1016/j.procs.2020.07.078, DOI 10.1016/J.PR0CS.2020.07.078]
   Karunanithy K, 2021, J IND INF INTEGR, V24, DOI 10.1016/j.jii.2021.100222
   Meenakshi B, 2023, T EMERG TELECOMMUN T, V34, DOI 10.1002/ett.4708
   Mistarihi MZ, 2023, PROCESSES, V11, DOI 10.3390/pr11020534
   Morgan J, 2021, J MANUF SYST, V59, P481, DOI 10.1016/j.jmsy.2021.03.001
   Nigam GK, 2021, J KING SAUD UNIV-COM, V33, P947, DOI 10.1016/j.jksuci.2018.08.002
   Nigam GK, 2015, LECT NOTES ENG COMP, P719
   Nigam GK., 2020, INT J SENS WIREL COM, V10, P967, DOI [10.2174/2210327909666191008101355, DOI 10.2174/2210327909666191008101355]
   Nigam GK., 2021, RECENT ADV COMPUT SC, V14, P1051, DOI [10.2174/2213275912666191031101421, DOI 10.2174/2213275912666191031101421]
   Prasad A.Y., 2019, TELKOMNIKA, V17, P1758, DOI DOI 10.12928/TELKOMNIKA.V17I4.12004
   Pratha SJ, 2023, WIRELESS PERS COMMUN, V128, P1567, DOI 10.1007/s11277-022-10010-x
   Radhika M, 2021, WIREL NETW, V27, P27, DOI 10.1007/s11276-020-02435-8
   Rastogi Ashutosh, 2021, International Journal of Information Technology, V13, P777, DOI 10.1007/s41870-020-00576-9
   Sachithanantham NC, 2021, INT J INNOV RES APPL, V4, DOI [10.29027/IJIRASE.v4.i7.2021.841-849, DOI 10.29027/IJIRASE.V4.I7.2021.841-849]
   Sasirekha S, 2017, J COMMUN NETW-S KOR, V19, P392, DOI 10.1109/JCN.2017.000063
   Sharma Richa, 2021, International Journal of Information Technology, P2381, DOI 10.1007/s41870-021-00789-6
   Sinde R, 2020, COGENT ENG, V7, DOI 10.1080/23311916.2020.1795049
   Spencer BF, 2017, PROCEDIA ENGINEER, V171, P5, DOI 10.1016/j.proeng.2017.01.304
   Tripathy Bata K., 2021, International Journal of Information Technology, V13, P921, DOI 10.1007/s41870-020-00520-x
   Vasan S, 2021, MATER TODAY-PROC, DOI [10.1016/j.matpr.2021.03.257, DOI 10.1016/J.MATPR.2021.03.257]
   Vijayalakshmi S, 2023, WIRELESS PERS COMMUN, V128, P25, DOI 10.1007/s11277-021-09398-9
   Vivekanand CV, 2020, WIRELESS PERS COMMUN, V113, P1823, DOI 10.1007/s11277-020-07294-2
   Worku B., 2021, TURK J COMPUT MATH E, V12, P5419
NR 40
TC 2
Z9 2
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16045
EP 16066
DI 10.1007/s11042-023-16248-2
EA JUL 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001028770200014
DA 2024-07-18
ER

PT J
AU Wang, B
   Huang, XL
   Cao, G
   Yang, LF
   Tao, ZL
   Wei, XL
AF Wang, Bing
   Huang, Xianglin
   Cao, Gang
   Yang, Lifang
   Tao, Zhulin
   Wei, Xiaolong
TI Attention-enhanced joint learning network for micro-video venue
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Micro-video venue classification; NNeXtVLAD; Enhanced non-local;
   Multi-modal
AB Currently, micro-video is a popular form on various multimedia platforms. The venue information of micro-videos is beneficial for venue-related applications, such as personalized location recommendation and venue recognition. However, the performance of micro-video venue classification task is limited in existing works due to the ignorant of the global dependency of features. To this end, an enhanced non-local (ENL) module is devised to improve the expressiveness of features. Furthermore, in this paper an attention-enhanced joint learning model is proposed to generate discriminative venue representations in an end-to-end manner. Such unified model is consisted of normalized NeXtVLAD, ENL module, CNN layer, and context gate. Specifically, the sequential features extracted from multiple modalities are aggregated into compact vectors via parallel NNeXtVLAD modules. In ENL, the interactions between any two positions of the aggregated features are captured to reinforce the valuable information in multiple modalities. Moreover, the enhanced channel information is adaptively added for further feature enhancement. Then, a CNN layer is applied to fuse enhanced features of multiple modalities. In addition, the effective activation function is explored in the CNN layer to achieve better performance. Finally, the context gate method is used to dynamically model the relationships between features and venue categories for prediction. Experimental results on a public dataset reveal that our proposed micro-video venue classification scheme achieves state-of-the-art performance.
C1 [Wang, Bing; Huang, Xianglin; Cao, Gang; Yang, Lifang; Tao, Zhulin; Wei, Xiaolong] Commun Univ China, State Key Lab Media Convergence & Commun, Beijing 100024, Peoples R China.
C3 Communication University of China
RP Cao, G (corresponding author), Commun Univ China, State Key Lab Media Convergence & Commun, Beijing 100024, Peoples R China.
EM hs8945@cuc.edu.cn; huangxl@cuc.edu.cn; gangcao@cuc.edu.cn;
   yanglifang@cuc.edu.cn; cnlutao@gmail.com; xiaol@cuc.edu.cn
FU national Key Research and Development Program of China [2019YFB1406201,
   2020YFB1406800]; National Natural Science Foundation of China
   [62071434]; Fundamental Research Funds for the Central Universities
   [CUC21GZ010, CUC210B017, CUC22GZ065]
FX The authors would like to thank the reviewers for their valuable
   comments. This research is supported by the national Key Research and
   Development Program of China (No.2019YFB1406201, No.2020YFB1406800), the
   National Natural Science Foundation of China under Grant (No.62071434),
   the Fundamental Research Funds for the Central Universities (Grant
   No.CUC21GZ010, CUC210B017, CUC22GZ065).
CR [Anonymous], 2009, P 17 ACM INT C MULT
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Bowles M, 2020, ARXIV
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1454, DOI 10.1145/2964284.2971477
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P898, DOI 10.1145/2964284.2964314
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Guo J, 2021, INFORM SCIENCES, V543, P504, DOI 10.1016/j.ins.2020.05.064
   Guo J, 2020, IEEE ACCESS, V8, P29518, DOI 10.1109/ACCESS.2020.2973240
   Guo J, 2018, LECT NOTES COMPUT SC, V11164, P721, DOI 10.1007/978-3-030-00776-8_66
   Guo M, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2105.02358
   Hammad M, 2022, MULTIMEDIA SYST, V28, P1373, DOI 10.1007/s00530-020-00728-8
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang L, 2017, MULTIMED TOOLS APPL, V76, P20341, DOI 10.1007/s11042-017-4781-z
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Kmiec S, 2019, LECT NOTES COMPUT SC, V11132, P229, DOI 10.1007/978-3-030-11018-5_21
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Lin RC, 2019, LECT NOTES COMPUT SC, V11132, P206, DOI 10.1007/978-3-030-11018-5_19
   Liu M, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P970, DOI 10.1145/3123266.3123341
   Liu M, 2019, IEEE T IMAGE PROCESS, V28, P1235, DOI 10.1109/TIP.2018.2875363
   Liu W, 2020, MULTIMED TOOLS APPL, V79, P6709, DOI 10.1007/s11042-019-08147-2
   Liu W, 2018, LECT NOTES COMPUT SC, V11165, P705, DOI 10.1007/978-3-030-00767-6_65
   Liu W, 2019, IEEE ACCESS, V7, P77091, DOI 10.1109/ACCESS.2019.2922430
   Miech A, 2017, ARXIV
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nguyen PX, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1603.09439
   Nie LQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1192, DOI 10.1145/3123266.3123313
   Ningning Ma, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P351, DOI 10.1007/978-3-030-58621-8_21
   Perronnin F, 2007, PROC CVPR IEEE, P2272
   Raisinghani Mahesh S., 2022, International Journal of Cloud Applications and Computing, V12, P1, DOI 10.4018/IJCAC.2022010109
   Ramachandran P., 2018, SEARCHING ACTIVATION
   Redi M, 2014, PROC CVPR IEEE, P4272, DOI 10.1109/CVPR.2014.544
   Salhi DE, 2021, INT J CLOUD APPL COM, V11, P32, DOI 10.4018/IJCAC.2021040103
   Sanden C, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P705
   Sharaff Aakanksha, 2020, International Journal of Web-Based Learning and Teaching Technologies, V15, P19, DOI 10.4018/IJWLTT.2020040102
   Sharaff A, 2019, ADV INTELL SYST, V924, P189, DOI 10.1007/978-981-13-6861-5_17
   Sharaff Aakanksha., 2016, Emerging Research in Computing, Information. Communication and Applications, P237, DOI DOI 10.1007/978-81-322-2553-9_23
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang WG, 2021, IEEE T PATTERN ANAL, V43, P2413, DOI 10.1109/TPAMI.2020.2966453
   Wei YW, 2020, IEEE T IMAGE PROCESS, V29, P1, DOI 10.1109/TIP.2019.2923608
   Wenguan Wang, 2018, IEEE Transactions on Image Processing, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu DM, 2022, IEEE T INF FOREN SEC, V17, P115, DOI 10.1109/TIFS.2021.3075894
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yin JB, 2023, IEEE T PATTERN ANAL, V45, P9822, DOI 10.1109/TPAMI.2021.3125981
   Zhang J., 2016, P ACM INT C MULT, P1415
NR 52
TC 0
Z9 0
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 12425
EP 12443
DI 10.1007/s11042-023-15699-x
EA JUL 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001020195700002
DA 2024-07-18
ER

PT J
AU Zhou, Y
   Ren, X
   Li, JX
   Yang, Y
   Zhou, HB
AF Zhou, Yan
   Ren, Xiao
   Li, Jianxun
   Yang, Yin
   Zhou, Haibin
TI DCMA-Net: dual cross-modal attention for fine-grained few-shot
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Few-shot learning; Fine-grained image recognition; Attention mechanism;
   Cross-modal fusion; Prototype
ID ALIGNMENT; ALGEBRA; NETWORK
AB Since obtaining comprehensive labeled samples is expensive, the Fine-grained Few-shot Recognition task aims to identify unseen meta classes by using one or several labeled known meta classes. Besides, Fine-grained Recognition suffers some challenges such as minimal inter-class variation, backgrounds clutter, and most of the previous methods are single visual modality. In this paper, we propose a novel Dual Cross-modal Attention Network (DCMA-Net) to address the mentioned problems. Concretely, we first propose the Local Mutuality Attention branch that encodes contextual information by merging cross-modal information to learn more discriminatory information and increase inter-class differences. Meanwhile, we add a regularization mechanism to filter the visual features that match the attribute information to ensure the effectiveness of learning. Focusing on local features is easy to ignore instance information, so we propose the Global Correlation Attention branch which gains details activation representation acquired by global pooling of visual features serially in spatial and channel dimensions. This branch avoids learning bias as the counterpart of the Local Mutuality Attention branch. After that, both outputs of the two branches are aggregated as an integral feature embedding, which can be used to enhance the prototypes. Extensive experiments on CUB and SUN datasets demonstrate that our framework is effective. Particularly, our method has improved the accuracy of Prototype Network from 51.31 to 77.67 on 5-way 1-shot scenarios on the CUB dataset with Conv-4 backbone.
C1 [Zhou, Yan; Ren, Xiao] Xiangtan Univ, Sch Automat & Elect Informat, Xiangtan 411105, Peoples R China.
   [Li, Jianxun] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai 200240, Peoples R China.
   [Yang, Yin] Xiangtan Univ, Sch Math & Comp Sci, Xiangtan 411105, Peoples R China.
C3 Xiangtan University; Shanghai Jiao Tong University; Xiangtan University
RP Zhou, Y (corresponding author), Xiangtan Univ, Sch Automat & Elect Informat, Xiangtan 411105, Peoples R China.
EM yanzhou@xtu.edu.cn
RI Zhou, Zhou/GYU-9809-2022
OI Zhou, Zhou/0000-0002-4787-9660
FU National Key Research and Development Project [2020YFA0713503]; National
   Natural Science Foundation of China [61773330]; Aeronautical Science
   Foundation of China [20200020114004]
FX AcknowledgementsThis work was supported in part by the National Key
   Research and Development Project under Grand 2020YFA0713503, in part by
   the National Natural Science Foundation of China under Grand 61773330,
   and in the part by the Aeronautical Science Foundation of China under
   Grand 20200020114004.
CR Abdelaziz M, 2021, MULTIMED TOOLS APPL, V80, P10491, DOI 10.1007/s11042-020-09875-6
   Aoxue Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12573, DOI 10.1109/CVPR42600.2020.01259
   Bhatti UA, 2022, ENVIRON SCI POLLUT R, V29, P14780, DOI 10.1007/s11356-021-16627-y
   Bhatti UA, 2021, J MED IMAG HEALTH IN, V11, P7, DOI 10.1166/jmihi.2021.3313
   Bhatti UA, 2020, IEEE ACCESS, V8, P155783, DOI 10.1109/ACCESS.2020.3018544
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Cao SY, 2022, INT J MACH LEARN CYB, V13, P2273, DOI 10.1007/s13042-022-01522-w
   Chen K, 2022, INT J MACH LEARN CYB, V13, P2507, DOI 10.1007/s13042-022-01540-8
   Chen W.Y., 2019, ICLR, DOI DOI 10.1109/MSR.2015.54
   Chen ZT, 2019, IEEE T IMAGE PROCESS, V28, P4594, DOI 10.1109/TIP.2019.2910052
   Finn C, 2017, PR MACH LEARN RES, V70
   HAN M, 2022, 2022 IEEE 24 INT WOR, P1
   Han-Jia Ye, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8805, DOI 10.1109/CVPR42600.2020.00883
   Hao FS, 2022, IEEE T CIRC SYST VID, V32, P4351, DOI 10.1109/TCSVT.2021.3132912
   Huang HX, 2021, IEEE T MULTIMEDIA, V23, P1666, DOI 10.1109/TMM.2020.3001510
   Huang HX, 2019, IEEE INT CON MULTI, P91, DOI 10.1109/ICME.2019.00024
   Huang ST, 2021, AAAI CONF ARTIF INTE, V35, P7840
   JI H, 2022, IEEE T IND ELECTRON, P1
   Ji Z, 2022, IEEE T IMAGE PROCESS, V31, P1520, DOI 10.1109/TIP.2022.3143005
   Kai Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13467, DOI 10.1109/CVPR42600.2020.01348
   Liu Y, 2022, MULTIMED TOOLS APPL, V81, P18305, DOI 10.1007/s11042-022-12096-8
   Mazumder P, 2022, NEUROCOMPUTING, V489, P179, DOI 10.1016/j.neucom.2022.02.044
   Mittal S, 2021, IEEE COMPUT SOC CONF, P3508, DOI 10.1109/CVPRW53098.2021.00390
   Pahde F, 2021, IEEE WINT CONF APPL, P2643, DOI 10.1109/WACV48630.2021.00269
   Pan C, 2022, MULTIMED TOOLS APPL, P1
   Pan LL, 2022, INT CONF SIGN PROCES, P190, DOI 10.1109/ICSP56322.2022.9965299
   Patterson G, 2014, INT J COMPUT VISION, V108, P59, DOI 10.1007/s11263-013-0695-z
   Ren K, 2022, ASIAPAC SIGN INFO PR, P520, DOI 10.23919/APSIPAASC55919.2022.9980160
   Schwartz E, 2022, PATTERN RECOGN LETT, V160, P142, DOI 10.1016/j.patrec.2022.06.012
   Shyam P., 2017, P INT C MACH LEARN, P3173
   Snell J, 2017, ADV NEUR IN, V30
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Tang L., 2020, P IEEECVF C COMPUTER, P14352
   Nguyen T, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P3460, DOI 10.1109/ICASSP39728.2021.9413446
   Tian DX, 2022, IEEE T INTELL TRANSP, V23, P4099, DOI 10.1109/TITS.2020.3041278
   Tliba M, 2022, IEEE ACCESS, V10, P20701, DOI 10.1109/ACCESS.2022.3152189
   Tokmakov P, 2019, IEEE I CONF COMP VIS, P6381, DOI 10.1109/ICCV.2019.00647
   Wah C, 2011, CALTECH UCSD BIRDS 2
   Wang Y, 2022, INT CONF ACOUST SPEE, P651, DOI 10.1109/ICASSP43922.2022.9746118
   Xing C., 2019, Advances in Neural Information Processing Systems, P4847
   Xu JY, 2022, PROC CVPR IEEE, P8993, DOI 10.1109/CVPR52688.2022.00880
   Xu WJ, 2022, INT J COMPUT VISION, V130, P1735, DOI 10.1007/s11263-022-01613-9
   Zhang Ce, 2022, 2022 International Conference on Electronics and Devices, Computational Science (ICEDCS), P485, DOI 10.1109/ICEDCS57360.2022.00110
   Zhang HG, 2021, PROC CVPR IEEE, P9427, DOI 10.1109/CVPR46437.2021.00931
NR 44
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14521
EP 14537
DI 10.1007/s11042-023-15776-1
EA JUN 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001020279100001
DA 2024-07-18
ER

PT J
AU Yu, Y
   Lee, BG
   Pike, M
   Zhang, Q
   Chung, WY
AF Yu, Yuan
   Lee, Boon Giin
   Pike, Matthew
   Zhang, Qian
   Chung, Wan-Young
TI Deep learning-based RGB-thermal image denoising: review and applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Deep learning; Computer vision; Object detection;
   Thermal imaging
ID SINGLE-IMAGE; NEURAL-NETWORK; GAN; ROBUST; RECONSTRUCTION; REDUCTION;
   ACCURATE; REMOVAL
AB Recently, vision-based detection (VD) technology has been well-developed, and its general-purpose object detection algorithms have been applied in various scenes. VD can be divided into two categories based on the type of modality: single-modal (single RGB or single thermal) and bimodal. Image denoising is typically the first stage of image processing in VD, where redundant information and noisy data are removed to produce clearer images for effective object detection. This study reviews deep learning-based image denoising for RGB and thermal images, investigating the denoising procedure, methodologies, and performances of algorithms tested with benchmark datasets. After introducing denoising models, the main results on public RGB and thermal datasets are presented and analyzed, and conclusions of objective comparison in practical effect are drawn. This review can serve as a reference for researchers in RGB-infrared denoising, image restoration, and related fields.
C1 [Yu, Yuan; Lee, Boon Giin; Pike, Matthew; Zhang, Qian] Univ Nottingham Ningbo China, Sch Comp Sci, Ningbo 315100, Zhejiang, Peoples R China.
   [Lee, Boon Giin] Nottingham Ningbo China Beacons Excellence Res & I, Ningbo 315000, Zhejiang, Peoples R China.
   [Chung, Wan-Young] Pukyong Natl Univ, Dept Elect Engn, Busan 48513, South Korea.
C3 University of Nottingham Ningbo China; Pukyong National University
RP Lee, BG (corresponding author), Univ Nottingham Ningbo China, Sch Comp Sci, Ningbo 315100, Zhejiang, Peoples R China.; Lee, BG (corresponding author), Nottingham Ningbo China Beacons Excellence Res & I, Ningbo 315000, Zhejiang, Peoples R China.
EM yuan.yu@nottingham.edu.cn; boon-giin.lee@nottingham.edu.cn;
   matthew.pike@nottingham.edu.cn; qian.zhang@nottingham.edu.cn;
   wychung@pknu.ac.kr
RI yu, xiao/KFT-1725-2024; Chen, Zheng/KCY-2338-2024; Lee, Boon
   Giin/E-3330-2016
OI Lee, Boon Giin/0000-0001-5743-1010
FU Zhejiang Provincial Natural Science Foundation of China [LQ21F020024];
   Ningbo Science and Technology Bureau under Major S amp;T Programme
   [2021Z037]; National Research Foundation of Korea (NRF) - Korea
   government (MSIT) [2020R1A4A1019463]
FX This research was supported by the Zhejiang Provincial Natural Science
   Foundation of China under Grant No. LQ21F020024; This work is supported
   by Ningbo Science and Technology Bureau under Major S &T Programme with
   project code 2021Z037; This work was supported by a research grant
   funded by National Research Foundation of Korea (NRF) grant funded by
   the Korea government (MSIT) (No. 2020R1A4A1019463).
CR Abascal JEPJ, 2021, EUR SIGNAL PR CONF, P1264, DOI 10.23919/Eusipco47968.2020.9287607
   Amal MFI, 2020, PROC INT C TELECOMMU, P1
   Anwar S, 2021, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2021.3131739
   Ashraf H, 2021, IEEE ACCESS, V9, P24513, DOI 10.1109/ACCESS.2021.3051263
   Aspandi D, 2019, 2019 16TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2019), P143, DOI 10.1109/CRV.2019.00027
   Bao L, 2020, IEEE COMPUT SOC CONF, P1823, DOI 10.1109/CVPRW50498.2020.00232
   Batchuluun G, 2021, IEEE ACCESS, V9, P5951, DOI 10.1109/ACCESS.2020.3048437
   Batson J, 2019, PR MACH LEARN RES, V97
   Borkar TS, 2019, IEEE T IMAGE PROCESS, V28, P6022, DOI 10.1109/TIP.2019.2924172
   Brown MS, SIDD DATASET
   Buades A, MCMASTER DATASET
   Cha S, 2019, IEEE I CONF COMP VIS, P4159, DOI 10.1109/ICCV.2019.00426
   Chan W, 2021, PREPRINT
   Chen H, 2017, IEEE T MED IMAGING, V36, P2524, DOI 10.1109/TMI.2017.2715284
   Chen JW, 2018, PROC CVPR IEEE, P3155, DOI 10.1109/CVPR.2018.00333
   Chen LH, 2020, IEEE SIGNAL PROC LET, V27, P2144, DOI 10.1109/LSP.2020.3040656
   Chen WM, 2020, IEEE T MED IMAGING, V39, P1582, DOI 10.1109/TMI.2019.2953626
   Chen Y, SET12 DATASET
   Chen YJ, 2021, I S BIOMED IMAGING, P400, DOI 10.1109/ISBI48211.2021.9433900
   Chen YS, 2018, PROC CVPR IEEE, P6306, DOI 10.1109/CVPR.2018.00660
   Chen YX, 2021, IEEE T GEOSCI REMOTE, V59, P5780, DOI 10.1109/TGRS.2020.3021765
   Chopra Ashish, 2021, 2021 Second International Conference on Electronics and Sustainable Communication Systems (ICESC), P103, DOI 10.1109/ICESC51422.2021.9532798
   Chrysostomou C, 2021, 2020 IEEE NUCL SCI S, P1, DOI [10.1109/NSS/MIC42677.2020.9507966, DOI 10.1109/NSS/MIC42677.2020.9507966]
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dang A, 2020, INT CONF ACOUST SPEE, P4432, DOI [10.1109/icassp40776.2020.9052993, 10.1109/ICASSP40776.2020.9052993]
   David JW, OSU DATASET
   Deepak S, 2021, 2021 ADV COMM TECHN, P1
   DND, DND DAT
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   FLIR, FLIR DAT
   Fu XY, 2021, INT J COMPUT VISION, V129, P1691, DOI 10.1007/s11263-020-01428-6
   Fu ZX, 2021, 2021 OPTOELECTRONICS GLOBAL CONFERENCE (OGC 2021), P212, DOI 10.1109/OGC52961.2021.9654293
   Fukushima S., 1982, inCompetition and Cooperation in Neural Nets, P267, DOI 10.1007/978-3-642-46466-9_18
   Gao MJ, 2021, IEEE T MED IMAGING, V40, P1805, DOI 10.1109/TMI.2021.3066896
   Gautam Aayushi, 2020, 2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT), P919, DOI 10.1109/ICSSIT48917.2020.9214230
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Goyal N, CC DATASET
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Guo Y, 2021, IEEE SIGNAL PROC LET, V28, P1515, DOI 10.1109/LSP.2021.3099963
   Gurrola-Ramos J, 2021, IEEE ACCESS, V9, P31742, DOI 10.1109/ACCESS.2021.3061062
   Duong HD, 2013, 2013 INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION (SOCPAR), P190, DOI 10.1109/SOCPAR.2013.7054125
   Han Z, 2022, IEEE J BIOMED HEALTH
   Hou RZ, 2022, IEEE T COMPUT IMAG, V8, P96, DOI 10.1109/TCI.2022.3145187
   Hou ZJ, 2021, INT C PATT RECOG, P2248, DOI 10.1109/ICPR48806.2021.9411955
   Huang Z, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2021.3128688
   Huang ZX, 2021, I S BIOMED IMAGING, P770, DOI 10.1109/ISBI48211.2021.9434136
   Issa TB, 2020, IEEE INT C BIOINF BI, P569, DOI 10.1109/BIBE50027.2020.00098
   Jadhav Sujay, 2021, Proceedings of the 2021 First International Conference on Advances in Electrical, Computing, Communication and Sustainable Technologies (ICAECT), DOI 10.1109/ICAECT49130.2021.9392554
   Jia XX, 2019, PROC CVPR IEEE, P6047, DOI 10.1109/CVPR.2019.00621
   Jiang X, 2021, IEEE ACCESS, V9, P106476, DOI 10.1109/ACCESS.2021.3100604
   Jimenez MFM, 2020, INT SYM INF THEOR AP, P549
   Jinbo Shen, 2021, 2021 2nd International Symposium on Computer Engineering and Intelligent Communications (ISCEIC), P112, DOI 10.1109/ISCEIC53685.2021.00030
   Jingyuan Zhou, 2021, 2021 6th International Conference on Intelligent Computing and Signal Processing (ICSP), P483, DOI 10.1109/ICSP51882.2021.9408801
   Karypis G, NCI1 DATASET
   Khamassi M, 2021, 2020 10 INT S SIGN I, P1
   Khan S, 2020, PREPRINT
   Khor HG, 2022, IEEE J BIOMED HEALTH, P1
   Kim DW, 2019, IEEE COMPUT SOC CONF, P2086, DOI 10.1109/CVPRW.2019.00261
   Kim Y, 2020, PROC CVPR IEEE, P3479, DOI 10.1109/CVPR42600.2020.00354
   Kodak, KODAK24 DAT
   Krull A, 2020, FRONT COMP SCI-SWITZ, V2, DOI 10.3389/fcomp.2020.00005
   Krull A, 2019, PROC CVPR IEEE, P2124, DOI 10.1109/CVPR.2019.00223
   Kuanar S, 2019, IEEE IMAGE PROC, P1351, DOI [10.1109/ICIP.2019.8803037, 10.1109/icip.2019.8803037]
   Kuang XD, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2017.2779149
   Lee J, 2021, EDGE PROFILE SUPER R, V9, P11
   Lehtinen J, 2018, PR MACH LEARN RES, V80
   Li MK, 2023, IEEE T EM TOP COMP I, V7, P604, DOI 10.1109/TETCI.2021.3100646
   Li SC, 2019, IEEE INT CON MULTI, P1192, DOI 10.1109/ICME.2019.00208
   Li TM, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3080834
   Li Y, 2021, P IEEE CVF INT C COM, P4651
   Li YS, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3080986
   Li Z, 2019, IEEE ACCESS, V7, P25016, DOI 10.1109/ACCESS.2019.2900323
   Liang JL, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P697, DOI 10.1109/CISP.2015.7407967
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Liang Z, POLYU DATASET
   Lin CH, 2021, IEEE SENS J, V21, P790, DOI 10.1109/JSEN.2020.3014254
   Lin SH, 2021, INT C PATT RECOG, P6742, DOI 10.1109/ICPR48806.2021.9412673
   Lin SY, 2021, CHIN CONT DECIS CONF, P1063, DOI 10.1109/CCDC52312.2021.9602115
   Liu X, 2019, INT GEOSCI REMOTE SE, P1951, DOI 10.1109/igarss.2019.8900642
   Liu Y, PD GAN PERCEPTUAL DE, P5
   Liu YJ, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P1840, DOI 10.1109/ICASSP39728.2021.9413433
   Loc Tan Ho, 2021, 2021 IEEE International Conference on Signal and Image Processing Applications (ICSIPA), P100, DOI 10.1109/ICSIPA52582.2021.9576764
   Luo YM, 2021, IEEE T BIO-MED ENG, V68, P2626, DOI 10.1109/TBME.2020.3041571
   Ma H., 2021, IEEE GEOSCI REMOTE S, V19, P1
   Matsui T, 2020, IEEE ACCESS, V8, P40892, DOI 10.1109/ACCESS.2020.2976761
   Matsushita Y, NAM DATASET
   Mehranian A, 2021, IEEE T RADIAT PLASMA, V5, P54, DOI 10.1109/TRPMS.2020.3004408
   Mehta A, 2021, IEEE WINT CONF APPL, P413, DOI 10.1109/WACV48630.2021.00046
   Mok GSP, 2020 IEEE NUCL SCI S, P1
   Moran Nick, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12061, DOI 10.1109/CVPR42600.2020.01208
   Motwani M. C., 2004, P GSPX, V27, P27
   Muneeb U, 2020, INT CONF ACOUST SPEE, P2992, DOI [10.1109/icassp40776.2020.9054442, 10.1109/ICASSP40776.2020.9054442]
   Naigong Yu, 2021, 2021 IEEE 6th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA), P612, DOI 10.1109/ICCCBDA51879.2021.9442497
   Nasonov A, 2018, P 7 EUR WORKSH VIS I, P1
   Nasrin S, 2019, PROC NAECON IEEE NAT, P345, DOI 10.1109/NAECON46414.2019.9057834
   NEWEY M, 2021, 2021 IEEE RADAR C RA, P1
   Othman A, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3054071
   Pistilli F, 2021, IEEE J-STSP, V15, P402, DOI 10.1109/JSTSP.2020.3047471
   Prajapati K, 2021, IEEE COMPUT SOC CONF, P4363, DOI 10.1109/CVPRW53098.2021.00493
   Prakash M, 2020, I S BIOMED IMAGING, P154, DOI [10.1109/ISBI45749.2020.9098612, 10.1109/isbi45749.2020.9098612]
   Quan YH, 2020, PROC CVPR IEEE, P1887, DOI 10.1109/CVPR42600.2020.00196
   Que Y, 2021, IEEE T MULTIMEDIA, V23, P3059, DOI 10.1109/TMM.2020.3019680
   Rani N. Shobha, 2021, 2021 Third International Conference on Inventive Research in Computing Applications (ICIRCA), P119, DOI 10.1109/ICIRCA51532.2021.9544864
   Ren DW, 2020, IEEE T IMAGE PROCESS, V29, P6852, DOI 10.1109/TIP.2020.2994443
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Saranya A, 2021, 2021 INT C SYST COMP, P1
   Sen Deng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14548, DOI 10.1109/CVPR42600.2020.01457
   Shahidi F, 2021, IEEE ACCESS, V9, P32795, DOI 10.1109/ACCESS.2021.3057497
   Shao D, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3145835
   Sharma M, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON MATHEMATICS AND COMPUTERS IN SCIENCES AND INDUSTRY (MCSI 2018), P81, DOI 10.1109/MCSI.2018.00027
   Siddiqui MA, 2021, INT MULTICONF SYST, DOI 10.1109/SSD52085.2021.9429345
   Song T.A., 2020 IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC), P1
   Suryanarayana G, 2021, IEEE ACCESS, V9, P71406, DOI 10.1109/ACCESS.2021.3077611
   Tal D, BSD300 DATASET
   Tal D, CBSD68 DATASET
   Tal D, BSD68 DATASET
   Tian CW, 2021, KNOWL-BASED SYST, V226, DOI 10.1016/j.knosys.2021.106949
   Tian CW, 2020, NEURAL NETWORKS, V131, P251, DOI 10.1016/j.neunet.2020.07.025
   Tian M, 2021, IEEE ACCESS, V9, P62266, DOI 10.1109/ACCESS.2021.3073944
   Tomosada H, 2021, IEEE ACCESS, V9, P135224, DOI 10.1109/ACCESS.2021.3116194
   Tomosada H, 2021, INT C PATT RECOG, P3675, DOI 10.1109/ICPR48806.2021.9412584
   Valsesia D, 2020, IEEE T IMAGE PROCESS, V29, P8226, DOI 10.1109/TIP.2020.3013166
   Wang BY, 2021, J HUM HYPERTENS, V35, P74, DOI 10.1038/s41371-020-0314-8
   Wang M, 2021, IEEE T MED IMAGING, V40, P1168, DOI 10.1109/TMI.2020.3048975
   Wang Q, 2021, CHIN CONTR CONF, P7027, DOI 10.23919/CCC52363.2021.9550033
   Wang X, 2018, PREPRINT
   Wang XW, 2020, IEEE ACCESS, V8, P127622, DOI 10.1109/ACCESS.2020.3008324
   Wang XY, 2020, IEEE I C VI COM I PR, P148, DOI [10.1109/ICBDIE50010.2020.00041, 10.1109/vcip49819.2020.9301892]
   Wang Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1833, DOI 10.1145/3343031.3350945
   Wei J, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2020), P266, DOI [10.1109/ICCCS49078.2020.9118520, 10.1109/icccs49078.2020.9118520]
   Wu ML, 2020, IEEE ACCESS, V8, P107912, DOI 10.1109/ACCESS.2020.3000174
   Wu Q, WATERLOO EXPLORATION
   Wu S, 2022, IEEE T MULTIMEDIA
   Xiao PF, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2018.2854303
   Xinxu Wei, 2021, 2021 6th International Conference on Robotics and Automation Engineering (ICRAE), P275, DOI 10.1109/ICRAE53653.2021.9657795
   Xu J, 2020, IEEE T IMAGE PROCESS, V29, P9316, DOI 10.1109/TIP.2020.3026622
   Xu W, DEEP RESIDUAL CONVOL, P6
   Xu Z., 2022, PREPRINT
   Yang X., 2023, MULTIDIMENSION SYST, V9, P1573
   Yang X, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3088144
   Yang Y, 2019, IEEE ACCESS, V7, P83888, DOI 10.1109/ACCESS.2019.2918409
   Yang ZY, 2021, IEEE ACCESS, V9, P105477, DOI 10.1109/ACCESS.2021.3100328
   Yixiong Zeng, 2019, 2019 International Conference on Information Technology and Computer Application (ITCA). Proceedings, P65, DOI 10.1109/ITCA49981.2019.00022
   Yu LW, 2019, IEEE SIGNAL PROC LET, V26, P557, DOI 10.1109/LSP.2019.2899253
   Yuan D, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105526
   Yuan Y, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3037104
   Yuzhou Zhong, 2022, 2022 3rd International Conference on Electronic Communication and Artificial Intelligence (IWECAI), P540, DOI 10.1109/IWECAI55315.2022.00110
   Zeng J, 2019, IEEE COMPUT SOC CONF, P1759, DOI 10.1109/CVPRW.2019.00226
   Zhang HX, 2019, IEEE INT CON MULTI, P242, DOI 10.1109/ICME.2019.00050
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang Yang, 2020, IEEE C COMP VIS PATT
   Zhang YL, 2021, IEEE T IMAGE PROCESS, V30, P6255, DOI 10.1109/TIP.2021.3093396
   Zhang ZF, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0056-7
   Zhao C, 2021, 2021 IEEE INT GEOSCI, P4408, DOI DOI 10.1109/IGARSS47720.2021.9553233
   Zhao Y., 2019, 2019 IEEE Visual Communications and Image Processing (VCIP), P1, DOI [DOI 10.1109/VCIP47243.2019.8965754, 10.1109/vcip47243.2019.8965754]
   Zhao YS, 2020, INT CONF ACOUST SPEE, P2668, DOI [10.1109/icassp40776.2020.9054658, 10.1109/ICASSP40776.2020.9054658]
   Zhong LQ, 2021, I S BIOMED IMAGING, P863, DOI 10.1109/ISBI48211.2021.9434150
   Zhong T, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3127637
   Zhu HY, 2021, IEEE WCNC, DOI [10.1109/ICME51207.2021.9428421, 10.1109/WCNC49053.2021.9417124]
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 161
TC 1
Z9 1
U1 13
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11613
EP 11641
DI 10.1007/s11042-023-15916-7
EA JUN 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001022136100007
DA 2024-07-18
ER

PT J
AU Kumar, D
   Kumar, D
AF Kumar, Deepak
   Kumar, Dharmender
TI A Binary Grey Wolf Optimization based Hybrid Convolutional Neural
   Network (BGWOHCNN) framework for hyperspectral image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Machine learning; Hyperspectral image classification;
   Hybrid design
ID SPECTRAL-SPATIAL CLASSIFICATION; FEATURE-SELECTION; BAND SELECTION;
   ALGORITHM; FUSION
AB In recent years deep learning (DL) models have obtained great success in hyperspectral image classification (HSIC) with commendable performance and especially convolutional neural networks (CNNs) have attracted huge attention due to the exceptional performance demonstrated in this area. However, most of the CNN-based models have to suffer with low classification performance due to non-availability of abundant training samples. Recently, hybrid-CNN models, utilizing both spectral and spatial features unitedly, have exhibited remarkable classification accuracy. Yet, the hybrid-CNN models have been adopted in very limited research works due to a very high computational complexity. Furthermore, huge dimensional HSIs contain highly correlated but irrelevant bands. The selection of most relevant spectral bands affects the performance and computational complexity of HSIC models very profoundly. To address these issues, the authors have proposed a binary grey wolf optimization-based hybrid CNN (BGWOHCNN) framework for HSIC, in this paper. In the hybrid framework, a 3-D CNN has been employed to exploit spatial and spectral features jointly along with a 2-D CNN utilizing the spatial features and reducing the computational complexity of the overall design. In addition, binary grey wolf optimization (BGWO) technique has been adapted to select the most relevant spectral bands for HSIC. As per the best of authors' knowledge and belief, the BGWO technique has been investigated for the first time with hybrid CNN for HSIC in the current work. Further, the experiments are conducted to investigate the performance and superiority of the proposed framework over three very popular datasets viz. Salinas, Indian Pines and Pavia University. The obtained results are compared with the six state-of-art DL models, in terms of average accuracy, overall accuracy and Cohen's kappa coefficient, to show that the proposed framework provides very promising results to HSIC tasks.
C1 [Kumar, Deepak; Kumar, Dharmender] Guru Jambheshwar Univ Sci & Technol, Dept Comp Sci & Engn, Hisar 125001, Haryana, India.
C3 Guru Jambheshwar University of Science & Technology
RP Kumar, D (corresponding author), Guru Jambheshwar Univ Sci & Technol, Dept Comp Sci & Engn, Hisar 125001, Haryana, India.
EM drdeepakjanghu@gmail.com; dharmindia24@gmail.com
RI Kumar, Dharmender/KHY-4909-2024
OI Kumar, Dharmender/0000-0003-4197-9705; Kumar, Deepak/0000-0003-2830-6733
CR [Anonymous], 2018, REMOTE SENS-BASEL, DOI [DOI 10.3390/RS10030396, DOI 10.3390/rs10030396]
   Chen CC, 2018, ENG APPL ARTIF INTEL, V68, P165, DOI 10.1016/j.engappai.2017.10.015
   Chen YS, 2019, IEEE T GEOSCI REMOTE, V57, P7048, DOI 10.1109/TGRS.2019.2910603
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Cheng J, 2018, ARXIV
   Dunne R. A., 1997, Proceedings of the Eighth Australian Conference on Neural Networks (ACNN'97), P181
   Emary E, 2016, NEUROCOMPUTING, V172, P371, DOI 10.1016/j.neucom.2015.06.083
   Fukushima S., 1982, inCompetition and Cooperation in Neural Nets, P267, DOI 10.1007/978-3-642-46466-9_18
   Ghaderizadeh S, 2021, IEEE J-STARS, V14, P7570, DOI 10.1109/JSTARS.2021.3099118
   Ghamisi P, 2017, IEEE GEOSC REM SEN M, V5, P37, DOI 10.1109/MGRS.2017.2762087
   Guo BF, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.083692
   HABBEMA JDF, 1977, TECHNOMETRICS, V19, P487, DOI 10.2307/1267890
   Hatta NM, 2019, ARTIF INTELL REV, V52, P2651, DOI 10.1007/s10462-018-9634-2
   He MY, 2017, IEEE IMAGE PROC, P3904, DOI 10.1109/ICIP.2017.8297014
   Hu W., 2019, arXiv
   Jensen J.R., 2009, Remote sensing of the environment: An earth resource perspective 2/e
   Jia S, 2016, IEEE T GEOSCI REMOTE, V54, P88, DOI 10.1109/TGRS.2015.2450759
   Jia S, 2014, IEEE J-STARS, V7, P1023, DOI 10.1109/JSTARS.2013.2282161
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar D., 2021, J PHYS C SERIES, V1950, P012087, DOI 10.1088/1742-6596/1950/1/012087
   Lee H, 2017, IEEE T IMAGE PROCESS, V26, P4843, DOI 10.1109/TIP.2017.2725580
   Li Y, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010067
   Liu QS, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121330
   Lu GL, 2014, J BIOMED OPT, V19, DOI 10.1117/1.JBO.19.1.010901
   Luo FL, 2020, NEUROCOMPUTING, V382, P162, DOI 10.1016/j.neucom.2019.11.084
   Luo H, 2018, ARXIV
   Ma XR, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0071-8
   Manley PV, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11151827
   Medjahed Seyyid Ahmed, 2015, IAENG International Journal of Computer Science, V42, P183
   Medjahed SA, 2016, APPL SOFT COMPUT, V40, P178, DOI 10.1016/j.asoc.2015.09.045
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Moughal TA, 2013, J PHYS CONF SER, V439, DOI 10.1088/1742-6596/439/1/012042
   Mughees A, 2019, TSINGHUA SCI TECHNOL, V24, P183, DOI 10.26599/TST.2018.9010043
   Pal KK, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P1778, DOI 10.1109/RTEICT.2016.7808140
   Pan B, 2018, ISPRS J PHOTOGRAMM, V145, P108, DOI 10.1016/j.isprsjprs.2017.11.003
   Pan ET, 2020, NEUROCOMPUTING, V387, P150, DOI 10.1016/j.neucom.2020.01.029
   Paoletti ME, 2018, ISPRS J PHOTOGRAMM, V145, P120, DOI 10.1016/j.isprsjprs.2017.11.021
   Pathak Y, 2019, MULTIMED TOOLS APPL, V78, P1473, DOI 10.1007/s11042-018-6155-6
   QI CM, 2017, NEUROCOMPUTING, V220, P181, DOI DOI 10.1016/J.NEUCOM.2016.05.103
   Roy SK, 2020, IEEE GEOSCI REMOTE S, V17, P277, DOI 10.1109/LGRS.2019.2918719
   Sawant SS, 2019, INT J REMOTE SENS, V40, P7852, DOI 10.1080/01431161.2019.1607609
   Sellami A, 2019, EXPERT SYST APPL, V129, P246, DOI 10.1016/j.eswa.2019.04.006
   SHAHSHAHANI BM, 1994, IEEE T GEOSCI REMOTE, V32, P1087, DOI 10.1109/36.312897
   Sharma A, 2018, NEURAL NETWORKS, V105, P346, DOI 10.1016/j.neunet.2018.05.019
   Shi C, 2018, PATTERN RECOGN, V74, P600, DOI 10.1016/j.patcog.2017.09.007
   Singh S, 2018, MULTIMED TOOLS APPL, V77, P27061, DOI 10.1007/s11042-018-5904-x
   Srinivasu PN, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.654
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Wang CX, 2019, ADV SPACE RES, V64, P886, DOI 10.1016/j.asr.2019.05.005
   Wen-Shuai Hu, 2020, IEEE Transactions on Geoscience and Remote Sensing, V58, P4237, DOI 10.1109/TGRS.2019.2961947
   Xie FD, 2019, APPL SOFT COMPUT, V75, P428, DOI 10.1016/j.asoc.2018.11.014
   Xu YH, 2018, IEEE T GEOSCI REMOTE, V56, P5893, DOI 10.1109/TGRS.2018.2827407
   Yang H, 2011, IEEE GEOSCI REMOTE S, V8, P138, DOI 10.1109/LGRS.2010.2053516
   Yang RL, 2017, J VIS COMMUN IMAGE R, V48, P396, DOI 10.1016/j.jvcir.2017.02.002
   Yin JH, 2012, IEEE T IND INFORM, V8, P935, DOI 10.1109/TII.2012.2205397
   Yu CY, 2020, IEEE J-STARS, V13, P2485, DOI 10.1109/JSTARS.2020.2983224
   Yu SQ, 2017, NEUROCOMPUTING, V219, P88, DOI 10.1016/j.neucom.2016.09.010
   Yuan Y, 2016, IEEE T GEOSCI REMOTE, V54, P1431, DOI 10.1109/TGRS.2015.2480866
   Zhai H, 2019, IEEE T GEOSCI REMOTE, V57, P1723, DOI 10.1109/TGRS.2018.2868796
   Zhao WZ, 2016, IEEE T GEOSCI REMOTE, V54, P4544, DOI 10.1109/TGRS.2016.2543748
   Zhao YQ, 2011, IEEE T GEOSCI REMOTE, V49, P747, DOI 10.1109/TGRS.2010.2059707
   Zhong ZL, 2018, IEEE T GEOSCI REMOTE, V56, P847, DOI 10.1109/TGRS.2017.2755542
   Zhou F, 2019, NEUROCOMPUTING, V328, P39, DOI 10.1016/j.neucom.2018.02.105
   Zhu JS, 2018, IEEE T GEOSCI REMOTE, V56, P1873, DOI 10.1109/TGRS.2017.2769113
NR 66
TC 0
Z9 0
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10091
EP 10114
DI 10.1007/s11042-023-15529-0
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001015589400008
DA 2024-07-18
ER

PT J
AU Wang, F
   Wang, B
AF Wang, Fan
   Wang, Bo
TI Boundary-guided feature integration network with hierarchical
   transformer for medical image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image segmentation; Feature integration network; Transformer;
   Cross fusion block; Boundary guidance
ID ARCHITECTURE
AB A variety of convolutional neural network (CNN) based methods for medical image segmentation have achieved outstanding performance, however, inherently suffered from a limited ability to capture long-range dependencies. In addition, some of the features integrated by complex strategy may be used repeatedly, resulting in more redundant information. To solve this problem, we propose a novel feature integration network by conducting hierarchical transformer under both explicit label and boundary guidance for accurate medical image segmentation. First, the encoder hierarchically extracts multiscale features by each hybrid attention module consisting of residual and Transformer blocks. Second, the parallel features from adjacent layers are integrated via cross fusion block to complement semantics to low-level features. Then, both deep boundary and label supervision are deployed for layer-wise decoders. Finally, the output features are fused by each layer instead of a top-to-down way to integrate multiscale semantic representation for prediction. The proposed method was evaluated on Synapse dataset with Dice of 81.63% and Promise12 dataset with Dice of 92.47%, 95HD of 2.06mm, and aRVD of 4.09%. Extensive experiments demonstrate that our proposed method achieves promising performance on multi-organ CT and prostate MR image segmentation.
C1 [Wang, Fan; Wang, Bo] Ningxia Univ, Sch Phys & Elect Elect Engn, Yinchuan 750021, Peoples R China.
C3 Ningxia University
RP Wang, B (corresponding author), Ningxia Univ, Sch Phys & Elect Elect Engn, Yinchuan 750021, Peoples R China.
EM tjuwb@nxu.edu.cn
FU National Natural Science Foundation of China [62041108]; Natural Science
   Foundation of Ningxia [2020AAC03029]; Innovation and Entrepreneurship
   Project for Returnees in Ningxia 2020
FX This work was supported by the National Natural Science Foundation of
   China (No. 62041108); the Natural Science Foundation of Ningxia (No.
   2020AAC03029); Innovation and Entrepreneurship Project for Returnees in
   Ningxia 2020.
CR Cao Hu, 2023, Computer Vision - ECCV 2022 Workshops: Proceedings. Lecture Notes in Computer Science (13803), P205, DOI 10.1007/978-3-031-25066-8_9
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Chen J., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2102.04306, 10.48550/arXiv.2102.04306]
   Chen J, 2021, PROC CVPR IEEE, P8060, DOI 10.1109/CVPR46437.2021.00797
   Chen L, 2018, IEEE T MED IMAGING, V37, P2453, DOI 10.1109/TMI.2018.2835303
   cicek Ozgtin, 2016, INT C MED IM COMP CO, P424, DOI DOI 10.1007/978-3-319-46723-8_49
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Fang X, 2020, IEEE T MED IMAGING, V39, P3619, DOI 10.1109/TMI.2020.3001036
   Gao YH, 2021, LECT NOTES COMPUT SC, V12903, P61, DOI 10.1007/978-3-030-87199-4_6
   Ghavami N, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101558
   Gridach M, 2021, I S BIOMED IMAGING, P1714, DOI 10.1109/ISBI48211.2021.9434072
   Gu R, 2021, IEEE T MED IMAGING, V40, P699, DOI 10.1109/TMI.2020.3035253
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   Guo XQ, 2022, IEEE T MED IMAGING, V41, P434, DOI 10.1109/TMI.2021.3114329
   Hatamizadeh A, 2022, IEEE WINT CONF APPL, P1748, DOI 10.1109/WACV51458.2022.00181
   Huang HM, 2020, INT CONF ACOUST SPEE, P1055, DOI [10.1109/ICASSP40776.2020.9053405, 10.1109/icassp40776.2020.9053405]
   Isensee F, 2021, NAT METHODS, V18, P203, DOI 10.1038/s41592-020-01008-z
   Jia HZ, 2017, I S BIOMED IMAGING, P762, DOI 10.1109/ISBI.2017.7950630
   Landman B., 2015, PROC MICCAI MULTIATL, V5, P12, DOI DOI 10.7303/SYN3193805
   Lin AL, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3178991
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Litjens G, 2014, MED IMAGE ANAL, V18, P359, DOI 10.1016/j.media.2013.12.002
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Meyer A, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105821
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Tong T, 2015, MED IMAGE ANAL, V23, P92, DOI 10.1016/j.media.2015.04.015
   Valanarasu Jeya Maria Jose, 2021, Medical Image Computing and Computer Assisted Intervention - MICCAI 2021: 24th International Conference, Proceedings. Lecture Notes in Computer Science, Image Processing, Computer Vision, Pattern Recognition, and Graphics (12901), P36, DOI 10.1007/978-3-030-87193-2_4
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang B, 2019, MED PHYS, V46, P1707, DOI 10.1002/mp.13416
   Wang HN, 2022, AAAI CONF ARTIF INTE, P2441
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang WX, 2021, LECT NOTES COMPUT SC, V12901, P109, DOI 10.1007/978-3-030-87193-2_11
   Wu WY, 2018, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2018.00227
   Xie YT, 2021, LECT NOTES COMPUT SC, V12903, P171, DOI 10.1007/978-3-030-87199-4_16
   Yu BT, 2019, IEEE T MED IMAGING, V38, P1750, DOI 10.1109/TMI.2019.2895894
   Zhang QL, 2021, ADV NEUR IN, V34
   Zhang SH, 2019, LECT NOTES COMPUT SC, V11764, P797, DOI 10.1007/978-3-030-32239-7_88
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao Y, 2019, IEEE J BIOMED HEALTH, V23, P1363, DOI 10.1109/JBHI.2019.2891526
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
   Zhu QK, 2020, IEEE T MED IMAGING, V39, P753, DOI 10.1109/TMI.2019.2935018
NR 44
TC 0
Z9 0
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8955
EP 8969
DI 10.1007/s11042-023-15948-z
EA JUN 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001012579700003
DA 2024-07-18
ER

PT J
AU Dujaili, MJA
AF Dujaili, Mohammed Jawad A., I
TI Survey on facial expressions recognition: databases, features and
   classification schemes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expressions recognition; Image processing; Expression
   recognition; Databases; Features; Classification schemes
ID FACE RECOGNITION; NETWORK; DEEP; MODEL
AB The recognition of facial expression in images is one of the motional states in the observing forms and is one of the most frequent non-verbal routes in which a person transfers his inner emotional expressions on faces. The recognition of facial expressions in a wide range of fields including psychological and legal studies, animation, robotics, lip-reading, image and video conferencing, communications, telecommunications, and security protection whilst counterterrorism is used to identify individuals as well as human-machine confrontation. The general solution to this problem includes three general steps: images preprocessing, features extraction, and expression classification algorithms. A series of pre-processing steps must be performed to process the area on the face and then detect the expression, that is, a square in the face must be localized while the rest of the image must be removed. Then, Features extraction is used to classify. Each facial expression to a specific category. We divide our data, including images from different expressions, into two parts: training and testing. Different categories have been learned to specify different features that tested thereafter. In recent years, a number of researches has been performed on a facial expression analysis. Even though much progress has been made in this field since the recognition of facial expression with a high accuracy rate is difficult to achieve due to the complexity and variability. In this research article, we noticed that most of researchers are used JAFFE and CK+ databases due the diversification and high accuracy. Nevertheless most of researchers are used PSO, PCA, and LBP features as well as HOG that presented high accuracy. We also noticed that SVM and CNN classification algorithms have been used mostly due to high accuracy and response latency with few errors.
C1 [Dujaili, Mohammed Jawad A., I] Univ Kufa, Fac Engn, Dept Elect & Commun, Najaf, Iraq.
C3 University of Kufa
RP Dujaili, MJA (corresponding author), Univ Kufa, Fac Engn, Dept Elect & Commun, Najaf, Iraq.
EM mohammed.challab@uokufa.edu
OI AL_Dujaili, Mohammed Jawad/0000-0002-3804-6667
CR Abdulrahman M, 2015, SIG PROCESS COMMUN, P276, DOI 10.1109/SIU.2015.7129813
   Agarwal S, 2012, P 8 INDIAN C COMP VI
   Agarwal S, 2018, VISUAL COMPUT, V34, P177, DOI 10.1007/s00371-016-1323-z
   Bilkhu Manjot Singh, 2019, Computational Intelligence: Theories, Applications and Future DirectionsVolume II. ICCI-2017. Advances in Intelligent Systems and Computing (AISC 799), P585, DOI 10.1007/978-981-13-1135-2_44
   Biswas S, 2015, PERCEPTION AND MACHINE INTELLIGENCE, 2015, P167, DOI 10.1145/2708463.2709036
   Breuer R., 2017, arXiv
   Butz MV, 2015, SPRINGER HANDBOOK OF COMPUTATIONAL INTELLIGENCE, P961
   Cha HS, 2022, VIRTUAL REAL-LONDON, V26, P385, DOI 10.1007/s10055-021-00575-6
   Chen CC, 2017, IEEE INT C ELECTR TA
   Chen JY, 2019, J PARALLEL DISTR COM, V131, P97, DOI 10.1016/j.jpdc.2019.04.017
   Cheng S, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420560030
   Christou N, 2019, ADV INTELL SYST COMP, V797, P539, DOI 10.1007/978-981-13-1165-9_49
   Cugu I, 2019, INT CONF IMAG PROC, DOI 10.1109/ipta.2019.8936114
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Damien D, 2008, 2 INT C PERS TECHN, V4
   Danelakis A, 2016, PATTERN RECOGN, V52, P174, DOI 10.1016/j.patcog.2015.10.012
   Deng LW, 2019, INT CONF COMP SCI ED, P32, DOI [10.1109/ICCSE.2019.8845493, 10.1109/iccse.2019.8845493]
   Dino H., 2020, TEST ENG MANAG, V83, P22319
   Dong JY, 2018, INT C PATT RECOG, P3433, DOI 10.1109/ICPR.2018.8545596
   Dourado CMJM Jr, 2019, COMPUT NETW, V152, P25, DOI 10.1016/j.comnet.2019.01.019
   Du S, 2012, 2012 25TH IEEE CANADIAN CONFERENCE ON ELECTRICAL & COMPUTER ENGINEERING (CCECE)
   Ekman P., 1969, Semiotica, V1, P49, DOI [10.1515/semi.1969.1.1.49, DOI 10.1515/SEMI.1969.1.1.49]
   Ekundayo O, 2019, 2019 CONFERENCE ON INFORMATION COMMUNICATIONS TECHNOLOGY AND SOCIETY (ICTAS), DOI 10.1109/ictas.2019.8703619
   Elaiwat S, 2016, PATTERN RECOGN, V49, P152, DOI 10.1016/j.patcog.2015.07.006
   Elmadhoun AMK, 2018, ARO, V6, P23, DOI 10.14500/aro.10378
   Eng S. K., 2019, IOP Conference Series: Materials Science and Engineering, V705, DOI 10.1088/1757-899X/705/1/012031
   Fei ZX, 2020, NEUROCOMPUTING, V388, P212, DOI 10.1016/j.neucom.2020.01.034
   Franco L, 2001, ISPA 2001: PROCEEDINGS OF THE 2ND INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P628, DOI 10.1109/ISPA.2001.938703
   Georgescu MI, 2019, IEEE ACCESS, V7, P64827, DOI 10.1109/ACCESS.2019.2917266
   Gogic I, 2020, VISUAL COMPUT, V36, P97, DOI 10.1007/s00371-018-1585-8
   Gonzalez-Lozoya SM, 2020, MULTIMED TOOLS APPL, V79, P13987, DOI 10.1007/s11042-020-08681-4
   Handa A., 2021, Int. J. Comput. Vis. Robot, V11, P1, DOI [10.1504/IJCVR.2021.111881, DOI 10.1504/IJCVR.2021.111881]
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Harit A, 2018, IOP CONF SER-MAT SCI, V331, DOI 10.1088/1757-899X/331/1/012013
   [何俊 He Jun], 2016, [计算机应用研究, Application Research of Computers], V33, P2509
   Hinton G. E., 2012, 12070580 ARXIV
   Hossain MS, 2017, IEEE ACCESS, V5, P2281, DOI 10.1109/ACCESS.2017.2672829
   Huang D-S, 2015, 11 INT C ICIC 2015 F
   Ilyas BR, 2019, INT C CONTROL DECISI, P344, DOI [10.1109/CoDIT.2019.8820410, 10.1109/codit.2019.8820410]
   Islam B, 2018, 2018 10TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE), P42, DOI 10.1109/ICECE.2018.8636780
   Jayalekshmi J, 2017, 2017 INTERNATIONAL CONFERENCE ON NETWORKS & ADVANCES IN COMPUTATIONAL TECHNOLOGIES (NETACT), P1, DOI 10.1109/NETACT.2017.8076732
   Jeni LA, 2014, LECT NOTES COMPUT SC, V8692, P135, DOI 10.1007/978-3-319-10593-2_10
   Jonitta Meryl C., 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P1155, DOI 10.1109/ICCSP48568.2020.9182094
   Joseph JL, 2021, 2021 IEEE 4 INT C CO
   Julina J. Kulandai Josephine, 2019, 2019 4th International Conference on Recent Trends on Electronics, Information, Communication & Technology (RTEICT), P56, DOI 10.1109/RTEICT46194.2019.9016766
   Kathirvel R, 2014, J THEOR APPL INF TEC, V61
   Kauser N, 2017, 2017 INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC), P445, DOI 10.1109/I-SMAC.2017.8058389
   Kauser N, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON ICT IN BUSINESS INDUSTRY & GOVERNMENT (ICTBIG)
   Khan SA, 2018, IEEE ACCESS, V6, P67459, DOI 10.1109/ACCESS.2018.2878601
   Khandait S, 2012, ARXIV
   Kim DH, 2019, IEEE T AFFECT COMPUT, V10, P223, DOI 10.1109/TAFFC.2017.2695999
   Kim JH, 2019, IEEE ACCESS, V7, P41273, DOI 10.1109/ACCESS.2019.2907327
   Kowalska M., 2017, HDB COGNITION EMOTIO, P1, DOI [https://doi.org/10.1007/978-3-319-28099-8495-1, DOI 10.1002/0470013494.CH3, 10.1002/0470013494.ch3]
   Kumar P, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, ANALYTICS AND SECURITY TRENDS (CAST), P289, DOI 10.1109/CAST.2016.7914982
   Kumbhar M., 2012, INT J COMPUT COMMUN, V1, P117, DOI [10.7763/IJCCE.2012.V1.33, DOI 10.7763/IJCCE.2012.V1.33]
   Lencioni GC, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0258672
   Li HB, 2015, COMPUT VIS IMAGE UND, V140, P83, DOI 10.1016/j.cviu.2015.07.005
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Li XL, 2015, SIGNAL PROCESS, V108, P297, DOI 10.1016/j.sigpro.2014.09.033
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Liliana DY, 2016, INT C ADV COMP SCI I, P439, DOI 10.1109/ICACSIS.2016.7872744
   Liu DZ, 2020, NEUROCOMPUTING, V413, P145, DOI 10.1016/j.neucom.2020.06.062
   Londhe R., 2012, International Journal of Computer Science Issues (IJCSI), V9, P388
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Maguire G, 2020, REAL TIME C 2020
   Mattela G, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P575, DOI 10.1109/SPIN.2018.8474206
   Md Abu M, 2007, TELKOMNIKA, V19, P1622
   Meng ZB, 2017, IEEE INT CONF AUTOMA, P558, DOI 10.1109/FG.2017.140
   Minaee S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093046
   Mistry K, 2017, IEEE T CYBERNETICS, V47, P1496, DOI 10.1109/TCYB.2016.2549639
   Mliki H, 2015, J SIGNAL PROCESS SYS, V81, P433, DOI 10.1007/s11265-014-0967-z
   Moeini A, 2016, J VIS COMMUN IMAGE R, V35, P1, DOI 10.1016/j.jvcir.2015.11.006
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Nezami M, 2018, MACHINE LEARNING KNO
   Nigam S, 2018, MULTIMED TOOLS APPL, V77, P28725, DOI 10.1007/s11042-018-6040-3
   Ozcan T, 2020, MULTIMED TOOLS APPL, V79, P26587, DOI 10.1007/s11042-020-09268-9
   Ozdemir Mehmet Akif, 2019, 2019 MED TECHN C TIP
   Panchal G., 2017, INT J ENG RES TECHNO, V6.5, P525
   Podilchuk C, 1996, INT CONF ACOUST SPEE, P2144, DOI 10.1109/ICASSP.1996.545740
   Pramerdorfer C, 2016, ARXIV
   Qayyum H, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/9854050
   Rahul Mayur, 2020, International Journal of Advanced Intelligence Paradigms, V17, P367
   Rahul M., 2018, INT J APPL ENG RES, V13, P6081
   Ravi R, 2020, 2020 4 INT C COMP ME
   Revina IM, 2021, J KING SAUD UNIV-COM, V33, P619, DOI 10.1016/j.jksuci.2018.09.002
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Saeed S, 2018, INT J ADV COMPUT SC, V9, P670
   Salmam FZ, 2016, I C COMP GRAPH IM VI, P125, DOI 10.1109/CGiV.2016.33
   Savran A, 2017, COMPUT VIS IMAGE UND, V162, P146, DOI 10.1016/j.cviu.2017.07.005
   Shah JH, 2020, PATTERN RECOGN LETT, V139, P166, DOI 10.1016/j.patrec.2017.06.021
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shen LL, 2006, PATTERN ANAL APPL, V9, P273, DOI 10.1007/s10044-006-0033-y
   Shih FY, 2008, INT J PATTERN RECOGN, V22, P445, DOI 10.1142/S0218001408006284
   Shiqing Zhang, 2012, WSEAS Transactions on Signal Processing, V8, P21
   Sikka Karan, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P18, DOI 10.1109/CVPRW.2015.7301350
   Sisodia P., 2013, INT J APPL INF SYST, V5, P9
   Sobottka K, 1998, SIGNAL PROCESS-IMAGE, V12, P263, DOI 10.1016/S0923-5965(97)00042-8
   Song YL, 2014, 2014 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATION (ISCC)
   Tai SC, 2007, TENCON IEEE REG 10 C, P1
   Tanuja SS, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON GREEN HIGH PERFORMANCE COMPUTING (ICGHPC)
   Theocharides T, 2006, IEEE COMPUTER SOCIETY ANNUAL SYMPOSIUM ON VLSI, PROCEEDINGS, P452
   Tsai HH, 2018, SOFT COMPUT, V22, P4389, DOI 10.1007/s00500-017-2634-3
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Uddin MZ, 2017, IEEE ACCESS, V5, P26146, DOI 10.1109/ACCESS.2017.2777003
   Varma S, 2020, TECHNO-SOCIETAL 2018: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SOCIETAL APPLICATIONS - VOL 1, P109, DOI 10.1007/978-3-030-16848-3_11
   Varshney T, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATIONS AND ELECTRONICS (COMPTELIX), P300, DOI 10.1109/COMPTELIX.2017.8003983
   Vasanth PC., 2015, INDONESIAN J ELECT E, V3, P16, DOI DOI 10.11591/IJEEI.V3I1.126
   Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wady SH., 2016, INT J MULTIDISCIPL C, V4, P200
   Wang G, 2019, CHIN CONT DECIS CONF, P5655, DOI [10.1109/ccdc.2019.8832535, 10.1109/CCDC.2019.8832535]
   Wang XH, 2015, OPTIK, V126, P3132, DOI 10.1016/j.ijleo.2015.07.073
   Wang Y, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8886872
   Wang YY, 2019, IEEE ACCESS, V7, P184599, DOI 10.1109/ACCESS.2019.2961161
   Wang YY, 2019, INFORMATION, V10, DOI 10.3390/info10120375
   Wu C, 2015, 2015 11 IEEE INT C W, V1
   Xu Q, 2020, 2020 IEEE 4 INF TECH, V1
   Yadan Lv, 2014, 2014 International Conference on Smart Computing (SMARTCOMP), P303, DOI 10.1109/SMARTCOMP.2014.7043872
   Yaddaden Yacine, 2021, 2020 2nd International Workshop on Human-Centric Smart Environments for Health and Well-being (IHSH), P221, DOI 10.1109/IHSH51661.2021.9378702
   Yadegaridehkordi E, 2019, COMPUT EDUC, V142, DOI 10.1016/j.compedu.2019.103649
   Yang HY, 2018, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2018.00231
   Yang HY, 2018, IEEE INT CONF AUTOMA, P294, DOI 10.1109/FG.2018.00050
   YAO F, 2021, Wireless Communications and Mobile Computing
   Yoshihiro S, 2018, P ACM 3 INT C ROB CO, P11
   Youssif AliaaA. A., 2011, Computer and Information Science, P115
   Yu WM, 2022, PATTERN RECOGN, V123, DOI 10.1016/j.patcog.2021.108401
   Zhang LG, 2009, LECT NOTES COMPUT SC, V5863, P724, DOI 10.1007/978-3-642-10677-4_83
   Zhang TW, 2020, INT J CONTROL, V93, P1442, DOI 10.1080/00207179.2018.1513165
   Zhang T, 2016, IEEE T MULTIMEDIA, V18, P2528, DOI 10.1109/TMM.2016.2598092
   Zhang Y, 2015, OPTIK, V126, P4501, DOI 10.1016/j.ijleo.2015.08.185
   Zhang ZP, 2018, INT J COMPUT VISION, V126, P550, DOI 10.1007/s11263-017-1055-1
   Zhang ZP, 2015, IEEE I CONF COMP VIS, P3631, DOI 10.1109/ICCV.2015.414
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
NR 136
TC 3
Z9 3
U1 7
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7457
EP 7478
DI 10.1007/s11042-023-15139-w
EA JUN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001003484200006
DA 2024-07-18
ER

PT J
AU Ramya, R
   Ramamoorthy, S
AF Ramya, R.
   Ramamoorthy, S.
TI QoS in multimedia application for IoT devices through edge intelligence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QoS (Quality of service); EC (Edge computing); IoT (Internet of Things);
   GGA (Greedy based genetic algorithm); Deep CNN (Convolutional neural
   network)
ID COMPUTING FRAMEWORK
AB Abnormal images predicted from video captured in surveillance system is considered as a primary concern in multimedia based IoT (Internet of Things).Conventional techniques comprises of poor quality of service (QoS) while making prediction of images from the videos, in order to overcome these issues proposed method incorporated greedy based genetic algorithm (GGA) for feature selection as traditional methods and Deep CNN for classification. The process involved in building an effective proposed model includes pre-processing, which helps in performing dimensionality reduction in order to minimize the over time of computation. Then the processed images are passed on to the perform object detection with v5 algorithm, which converts videos into images segments and array of images are stored in cloud, after that feature selection proceeded, in which feature selection method with GGA is employed for feature selection in order to select the best features. The key frames which are selected from the image segments of videos assist in the detection of the significant region. Finally, classification process is performed with deep CNN for classification of normal images and abnormal images which are captured from the video. Computational analysis such as time complexity are identified for the proposed framework in addition to it, stability analysis using k-fold cross validation and convergence analysis are detected for the proposed method. Finally performance metrics such as accuracy, precision, F1 score, and recall are implemented in order to evaluate the efficiency of the proposed framework. And various existing algorithms are compared with proposed method as well.
C1 [Ramya, R.] SRM Inst Sci & Technol, Dept Comp Sci & Engn, Kattankulathur, Tamil Nadu, India.
   [Ramamoorthy, S.] SRM Inst Sci & Technol, Dept Comp Technol, Kattankulathur, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai; SRM Institute of Science
   & Technology Chennai
RP Ramya, R (corresponding author), SRM Inst Sci & Technol, Dept Comp Sci & Engn, Kattankulathur, Tamil Nadu, India.
EM rr7135@srmist.edu.in; ramamoos@srmist.edu.in
RI R, Ramya/HMD-6095-2023
OI R, Ramya/0000-0002-8071-9343
CR Alam MS, 2019, MULTIMED TOOLS APPL, V78, P35119, DOI 10.1007/s11042-019-08067-1
   Bouaafia S, 2022, NEURAL COMPUT APPL, V34, P14135, DOI 10.1007/s00521-021-06491-9
   [陈珺娴 Chen Junxian], 2020, [高分子通报, Polymer Bulletin], P1
   Dey Ratnadeep, 2020, Advanced Computing and Systems for Security. Volume Twelve. Advances in Intelligent Systems and Computing (AISC 1136), P121, DOI 10.1007/978-981-15-2930-6_10
   Dou WC, 2021, IEEE T IND INFORM, V17, P2842, DOI 10.1109/TII.2020.3020386
   Dwivedi Shubhra, 2022, International Journal of Computers and Applications, V44, P219, DOI 10.1080/1206212X.2020.1720951
   Kashani MH, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4340
   Ho Samson, 2021, IEEE Open Journal of the Computer Society, V2, P14, DOI 10.1109/OJCS.2021.3050917
   Islam N, 2019, FUTURE GENER COMP SY, V100, P569, DOI 10.1016/j.future.2019.05.059
   Jha S, 2021, MULTIMED TOOLS APPL, V80, P3981, DOI 10.1007/s11042-020-09749-x
   Kuang L, 2020, FUTURE GENER COMP SY, V105, P717, DOI 10.1016/j.future.2019.12.039
   Kumar PP, 2022, IEEE T SUST COMPUT, V7, P774, DOI 10.1109/TSUSC.2021.3064245
   Lavanya Raja., 2019, Advancing Consumer-Centric Fog Computing Architectures, P63
   Liao HJ, 2021, IEEE T INTELL TRANSP, V22, P4051, DOI 10.1109/TITS.2020.3007770
   Lin SY, 2020, COMPUT COMMUN, V160, P636, DOI 10.1016/j.comcom.2020.05.044
   Long CC, 2018, IEEE T MULTIMEDIA, V20, P1126, DOI 10.1109/TMM.2017.2764330
   Nasir M, 2019, J PARALLEL DISTR COM, V126, P161, DOI 10.1016/j.jpdc.2018.11.004
   Pudasaini D, 2021, INT J ADV COMPUT SC, V12, P1
   Rajavel R, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03157-1
   Satheesh N, 2020, MICROPROCESS MICROSY, V79, DOI 10.1016/j.micpro.2020.103285
   Shukla S, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0224934
   Sultana T, 2019, IEEE ACCESS, V7, P134881, DOI 10.1109/ACCESS.2019.2941978
   Wan SH, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108146
   Wan SH, 2021, IEEE T INTELL TRANSP, V22, P4487, DOI 10.1109/TITS.2020.3017505
   Xiaoqing Zhu, 2015, Intel Technology Journal, V19, P202
   Xu XH, 2020, SOFTWARE PRACT EXPER, V50, P476, DOI 10.1002/spe.2701
   Xu XL, 2021, IEEE T INTELL TRANSP, V22, P1787, DOI 10.1109/TITS.2020.2995622
   Xu XL, 2020, IEEE INTERNET THINGS, V7, P2622, DOI 10.1109/JIOT.2019.2944007
   Zhang C, 2021, SEC COMM NETW, V2021
   Zhang T, 2020, DEEP LEARNING BASED
NR 30
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 9227
EP 9250
DI 10.1007/s11042-023-15941-6
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001004157400007
DA 2024-07-18
ER

PT J
AU Zhang, WM
   Rui, F
   Xiao, CJ
   Li, HB
   Li, YQ
AF Zhang, Wengming
   Rui, Feng
   Xiao, Cunjun
   Li, Haibin
   Li, Yaqian
TI JF-YOLO: the jellyfish bloom detector based on deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Jellyfish monitoring; Ocean environmental governance; Underwater object
   detection; Deep learning
ID SEA
AB The unmonitored jellyfish boom inevitably destroys coastal biodiversities as a type of planktons with extremely high fecundity. It even seriously endangers people's economic and social activities, such as clogging the water intake system of hydropower plants and hindering coastal tourism development. In the past, underwater video monitoring tended to be time-consuming and costly. This paper proposes JF-YOLO: an automatic jellyfish blooms detection model based on deep learning. We collecte many jellyfish videos in real environments to form a dataset for model training. JF-YOLO uses the improved YOLO-V4 detection model to ensure detection accuracy and speed. The experimental results show that the detection accuracy of the JF-YOLO network is better than that of the YOLO-V4 network, with the average detection accuracy increasing from 85.35% to 92.67% and the recall rate increasing from 72.32% to 85.74%. As a promising solution, JF-YOLO can effectively monitor the number or density of jellyfish and provide early warning when they appear abnormal, bringing convenience to ocean governance.
C1 [Zhang, Wengming; Rui, Feng; Xiao, Cunjun; Li, Haibin; Li, Yaqian] Yanshan Univ, Sch Elect Engn, Qinhuangdao 066004, Peoples R China.
   [Zhang, Wengming; Rui, Feng; Xiao, Cunjun; Li, Haibin; Li, Yaqian] Key Lab Ind Comp Control Engn Hebei Prov, Qinhuangdao 066004, Peoples R China.
C3 Yanshan University
RP Xiao, CJ (corresponding author), Yanshan Univ, Sch Elect Engn, Qinhuangdao 066004, Peoples R China.; Xiao, CJ (corresponding author), Key Lab Ind Comp Control Engn Hebei Prov, Qinhuangdao 066004, Peoples R China.
EM zwmwen@ysu.edu.cn; 809078075@qq.com; xcj@stumail.ysu.edu.cn;
   hbli@ysu.edu.cn; yaqianli@ysu.edu.cn
RI li, haibin/A-1012-2012
FU Natural Science Foundation of Hebei Province [F2019203195]; National
   Natural Science Foundation of China [62106214]
FX This work was supported in part by the Natural Science Foundation of
   Hebei Province, Research on 3D dense reconstruction of underwater vision
   based on deep learning and point cloud quadratic determination (Grant
   numbers F2019203195) and National Natural Science Foundation of China,
   Research on occlusion perception, repair and reliability evaluation
   method for occlusion face recognition (Grant numbers 62106214).
CR Ambati LS., 2019, J MIDWEST ASS INF SY, V2021, P49, DOI DOI 10.17705/3JMWA.000065
   An LN, 2021, J COAST CONSERV, V25, DOI 10.1007/s11852-021-00845-0
   Baliarsingh SK, 2020, ECOL PROCESS, V9, DOI 10.1186/s13717-020-00268-z
   Barrado C, 2014, IOP C SER EARTH ENV, V17, DOI 10.1088/1755-1315/17/1/012195
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Bosch-Belmar M, 2020, REV FISH SCI AQUAC, V29, P242, DOI 10.1080/23308249.2020.1806201
   Chen Q, 2021, PROC CVPR IEEE, P13034, DOI 10.1109/CVPR46437.2021.01284
   El-Gayar O F, 2020, WEARABLES ARTIFICIAL
   Ghermandi A, 2015, ECOSYST SERV, V11, P140, DOI 10.1016/j.ecoser.2014.12.004
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goutte C, 2005, LECT NOTES COMPUT SC, V3408, P345
   Graham WM, 2003, MAR ECOL PROG SER, V254, P129, DOI 10.3354/meps254129
   Han Y, 2022, MULTIMED TOOLS APPL, V81, P19429, DOI 10.1007/s11042-021-11307-y
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kamili A, 2020, J INTELL FUZZY SYST, V39, P8389, DOI 10.3233/JIFS-189157
   Kim D., 2013, Robot Intelligence Technology and Applications 2012, Proceedings of the An Edition of the Presented Papers from the 1st International Conference on Robot Intelligence Technology and Applications, Gwangju, Republic of Korea, 16-18 2012, P395
   Kim D, 2015, INT CONF UBIQ ROBOT, P144, DOI 10.1109/URAI.2015.7358846
   Kim H, 2015, INT CONF UBIQ ROBOT, P495, DOI 10.1109/URAI.2015.7358813
   Kim H, 2016, IEEE SENS J, V16, P2215, DOI 10.1109/JSEN.2016.2517823
   Labao AB, 2019, ECOL INFORM, V52, P103, DOI 10.1016/j.ecoinf.2019.05.004
   Li JY, 2018, IFAC PAPERSONLINE, V51, P76, DOI 10.1016/j.ifacol.2018.09.412
   Liang T., 2021, ARXIV
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu JT, 2020, IEEE ACCESS, V8, P24784, DOI 10.1109/ACCESS.2020.2971253
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YD, 2020, AAAI CONF ARTIF INTE, V34, P11653
   Martin-Abadal M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061708
   Mcilwaine B, 2021, INT J APPL EARTH OBS, V97, DOI 10.1016/j.jag.2020.102279
   Misra D., 2019, ARXIV190808681
   Miyao Y., 2014, J REMOTE SENS SOC JP, V34, P113
   Peng F, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115306
   Pierce J, 2009, ZOO BIOL, V28, P163, DOI 10.1002/zoo.20218
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rife J, 2003, IEEE J OCEANIC ENG, V28, P595, DOI 10.1109/JOE.2003.819315
   Roohi A, 2010, BIOL INVASIONS, V12, P2343, DOI 10.1007/s10530-009-9648-4
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sai Ambati L., 2020, Issues Inform Syst, V21, P103
   Samsuri SS., 2017, METHODS SAN DIEGO CA, V10, P0
   Tian YN, 2019, COMPUT ELECTRON AGR, V157, P417, DOI 10.1016/j.compag.2019.01.012
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang KX, 2019, IEEE I CONF COMP VIS, P9196, DOI 10.1109/ICCV.2019.00929
   Wang Zi, 2020, E3S Web of Conferences, V194, DOI 10.1051/e3sconf/202019401007
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiufen Wang, 2011, 2011 IEEE 13th International Conference on Communication Technology (ICCT), P762, DOI 10.1109/ICCT.2011.6157979
   Zhang JS, 2019, INT C INTEL HUM MACH, P233, DOI 10.1109/IHMSC.2019.00061
   Zhang Y, 2019, OPTIK, V183, P17, DOI 10.1016/j.ijleo.2019.02.038
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
NR 48
TC 3
Z9 3
U1 20
U2 68
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7097
EP 7117
DI 10.1007/s11042-023-15465-z
EA JUN 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001003562600009
DA 2024-07-18
ER

PT J
AU Woo, TH
   Jang, KB
   Baek, CH
AF Woo, Tae Ho
   Jang, Kyung Bae
   Baek, Chang Hyun
TI Human-machine interface (HMI) assessment in the nuclear control room
   operations using the modified machine learning (ML) algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Nuclear; Human; Machine; Assessment; Learning
AB The assessment of the operations in the nuclear power plants (NPPs) is performed by the artificial intelligence (AI) system where the neutral networking is one of characteristics because this algorithm mimics the neuron system in the human intelligence. The recurrent neural network (RNN) modeling is applied to this study where the feedback loop is attached to the hidden layer in neural networking system. The results show the dynamic analysis for the study where in the earlier year the value is higher except the Formula 3. In Formula 1, if the graph has the slightly decreasing slope, the positive predictive value decreases gradually. Especially, in Formula 3, the slope increases, which means that the true negative trend increases highly. Hence the risk in the control room could increase possibly. So, the high intelligence quotient (I.Q.) in the robot or AI system could analysis the next possible nuclear accident.
C1 [Woo, Tae Ho; Jang, Kyung Bae; Baek, Chang Hyun] Cyber Univ Korea, Dept Mech & Control Engn, 106 Bukchon Ro, Seoul 03051, South Korea.
RP Woo, TH (corresponding author), Cyber Univ Korea, Dept Mech & Control Engn, 106 Bukchon Ro, Seoul 03051, South Korea.
EM thwoo@cuk.edu
OI WOO, TAEHO/0000-0001-9415-1667
CR [Anonymous], 1995, IAEATECDOC812
   Asim KM, 2017, NAT HAZARDS, V85, P471, DOI 10.1007/s11069-016-2579-3
   Choi J, 2019, NUCL ENG TECHNOL, V51, P1554, DOI 10.1016/j.net.2019.04.010
   Hollnagel E., 2005, Joint cognitive systems: Foundations of cognitive systems engineering, DOI [10.1201/9781420038194, DOI 10.1201/9781420038194]
   Olson DL., 2008, Advanced data mining techniques, V1st, P138, DOI [10.1007/978-3-540-76917-0, DOI 10.1007/978-3-540-76917-0]
   Paltrinieri N, 2019, SAFETY SCI, V118, P475, DOI 10.1016/j.ssci.2019.06.001
   Porthin M, 2020, RELIAB ENG SYST SAFE, V194, DOI 10.1016/j.ress.2019.03.022
   SDS, 2020, SYST DYN STRAT WHAT
   Simonsen E, 2015, PROCEDIA MANUF, V3, P1248, DOI 10.1016/j.promfg.2015.07.260
   USNRC, 1993, SECY 93 092 PRA ATT
   Vantana, 2015, VENS COD SYST
   Yanhua Z., 2015, SAFE SCI, V80, P296, DOI [10.1016/j.ssci.2015.07.033, DOI 10.1016/J.SSCI.2015.07.033]
NR 12
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 4
PY 2023
DI 10.1007/s11042-023-15920-x
EA JUN 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I1QP3
UT WOS:001000602100001
DA 2024-07-18
ER

PT J
AU Choudhary, M
   Tiwari, V
   Jain, S
   Rajpoot, V
AF Choudhary, Meenakshi
   Tiwari, Vivek
   Jain, Swati
   Rajpoot, Vikram
TI Person Reidentification using 3D inception based Spatio-temporal
   features learning, attribute recognition, and Reranking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Person reidentification; 3D inception; Pedestrians identification;
   Intelligent surveillance; Video surveillance
ID NEURAL-NETWORK; REPRESENTATION; ENHANCEMENT
AB Identifying pedestrians in video sequences captured by non-overlapping multi-cameras is referred to as video-based Person Re-identification. The successive video frames in video clips embrace motion patterns of pedestrians and represent a person's appearance from varying angles with different body poses and, thus, provide critical features to counter occlusion, pose variation, viewpoint change, etc. This article proposes a novel person reidentification methodology, which incorporates a 3D Inception-based Person Re-identification model, which embraces four three-dimensional (3D) Inception modules with 3D convolution and pooling layers. The receptive fields of neurons are well expanded through 3D inception modules in both temporal and spatial dimensions. Due to this, the model learns discriminatory appearance along with pedestrians' long-term and short-term motion patterns without any motion approximation module. Further, the model is trained with a unified loss function integrating center loss with usual identification loss to reduce intra-class difference while increasing inter-class difference. Further, the proposed method incorporates an attribute recognition model to identify discriminatory attributes in the video frames. The Spatio-temporal and attribute features are then utilized by a reranking method, which generates the k-most similar video clips for the given input. The effectiveness of the proposed method is validated by performing extensive experiments over three realistic surveillance video datasets; MARS, DukeMTMC-VideoReID, and iLIDS.
C1 [Choudhary, Meenakshi] IIIT Pune, Dept Comp Sci & Engn, Pune, India.
   [Tiwari, Vivek] DSPM IIIT Naya Raipur, Dept Comp Sci & Engn, Raipur, Chhattisgarh, India.
   [Jain, Swati] Govt J Yoganandam Chhattisgarh Coll, Raipur, CG, India.
   [Rajpoot, Vikram] Madhav Inst Sci & Technol, Dept Informat Technol, Gwalior, India.
C3 Madhav Institute of Technology & Science
RP Tiwari, V (corresponding author), DSPM IIIT Naya Raipur, Dept Comp Sci & Engn, Raipur, Chhattisgarh, India.
EM viveknitbpl@gmail.com
CR Chen BH, 2019, IEEE I CONF COMP VIS, P371, DOI 10.1109/ICCV.2019.00046
   Chen DP, 2015, PROC CVPR IEEE, P1565, DOI 10.1109/CVPR.2015.7298764
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen ZQ, 2020, AAAI CONF ARTIF INTE, V34, P10591
   Choudhary M, 2022, MULTIMED TOOLS APPL, V81, P42099, DOI 10.1007/s11042-021-11292-2
   Fu H, 2022, IMAGE VISION COMPUT, V118, DOI 10.1016/j.imavis.2021.104356
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8287
   Ge Y., 2018, FD GAN POSE GUIDED F
   Gong WC, 2020, NEUROCOMPUTING, V383, P295, DOI 10.1016/j.neucom.2019.11.050
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Hou RB, 2019, PROC CVPR IEEE, P7176, DOI 10.1109/CVPR.2019.00735
   Jiang M, 2020, NEUROCOMPUTING, V381, P314, DOI 10.1016/j.neucom.2019.11.088
   Khamis S, 2014, EUR C COMP VIS
   Layne R, 2014, ADV COMPUT VIS PATT, P93, DOI 10.1007/978-1-4471-6296-4_5
   Li JN, 2019, IEEE I CONF COMP VIS, P3957, DOI 10.1109/ICCV.2019.00406
   Li JN, 2020, IEEE T IMAGE PROCESS, V29, P4461, DOI 10.1109/TIP.2020.2972108
   Li PK, 2021, IEEE T CIRC SYST VID, V31, P503, DOI 10.1109/TCSVT.2020.2988034
   Li SZ, 2020, AAAI CONF ARTIF INTE, V34, P11394
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Lin GJ, 2021, NEUROCOMPUTING, V453, P777, DOI 10.1016/j.neucom.2020.05.111
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu JW, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3231741
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mansouri N, 2021, NEURAL COMPUT APPL, V33, P12827, DOI 10.1007/s00521-021-05936-5
   Matsukawa T, 2016, INT C PATT RECOG, P2428, DOI 10.1109/ICPR.2016.7900000
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Ming ZQ, 2022, IMAGE VISION COMPUT, V119, DOI 10.1016/j.imavis.2022.104394
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Song WR, 2021, APPL INTELL, V51, P788, DOI 10.1007/s10489-020-01844-8
   Su C, 2016, Arxiv, DOI arXiv:1605.03259
   Subramaniam A, 2019, IEEE I CONF COMP VIS, P562, DOI 10.1109/ICCV.2019.00065
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wang TQ, 2016, IEEE T PATTERN ANAL, V38, P2501, DOI 10.1109/TPAMI.2016.2522418
   Wang ZK, 2022, IEEE T CIRC SYST VID, V32, P8179, DOI 10.1109/TCSVT.2021.3076097
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wu DM, 2022, IEEE T INF FOREN SEC, V17, P115, DOI 10.1109/TIFS.2021.3075894
   Wu YM, 2020, IEEE T IMAGE PROCESS, V29, P8821, DOI 10.1109/TIP.2020.3001693
   Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543
   Yan YC, 2020, PROC CVPR IEEE, P2896, DOI 10.1109/CVPR42600.2020.00297
   Yang F, 2022, NEUROCOMPUTING, V488, P424, DOI 10.1016/j.neucom.2022.03.032
   Yang JR, 2020, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR42600.2020.00335
   Yang X, 2021, IEEE T IMAGE PROCESS, V30, P6266, DOI 10.1109/TIP.2021.3093759
   Yao YM, 2022, PATTERN RECOGN, V129, DOI 10.1016/j.patcog.2022.108708
   Zhang L, 2021, IEEE T PATTERN ANAL, V43, P1460, DOI 10.1109/TPAMI.2020.2976969
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhou Z, 2017, PROC CVPR IEEE, P6776, DOI 10.1109/CVPR.2017.717
NR 54
TC 0
Z9 0
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 11
PY 2023
DI 10.1007/s11042-023-15473-z
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G1LI4
UT WOS:000986851800003
DA 2024-07-18
ER

PT J
AU Guo, TT
   Wang, H
   Zhang, ML
   Liu, YP
   Zhang, F
AF Guo, Tiantian
   Wang, Hua
   Zhang, Mingli
   Liu, Yepeng
   Zhang, Fan
TI Fast and highly coupled model for time series forecasting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Long sequence time-series forecasting; Transformer; Feature mapping;
   Conditional convolutional networks
AB Transformer-based methods have shown great potential for time series forecasting problems. However, they are difficult to use for long sequence time-series forecasting (LSTF) owing to high computational costs and memory requirements. In this paper, we propose a fast and highly coupled model that builds a feature mapping module (F-Map) to adjust the sequence feature distribution. It generates more feature information revealing the intrinsic association through low-cost linear operations on the time series, reduce the redundancy of the feature sequence to reduce the encoder computation. Then, a conditional convolutional network (ConNet) is built to learn a specific convolutional kernel for each input sequence. It can increase the capacity of the network while maintaining efficient inference and improve model performance while maintaining the coupling between sequences. The results of the experiments on five real datasets reveal that, compared to the state-of-the-art model, the proposed model exhibits 10.91% and 9.26% reduction in the mean squared error on multivariate and univariate time-series predictions, respectively. Furthermore, it outperforms other transformer-based models.
C1 [Guo, Tiantian; Liu, Yepeng; Zhang, Fan] Shandong Technol & Business Univ, Yantai 264005, Peoples R China.
   [Wang, Hua] Ludong Univ, Yantai 264005, Peoples R China.
   [Zhang, Mingli] McGill Univ, Montreal Neurol Inst, McGill Ctr Integrat Neurosci, Montreal, PQ H3A 2B4, Canada.
   [Liu, Yepeng; Zhang, Fan] Shandong Future Intelligent Financial Engn Lab, Yantai 264005, Peoples R China.
C3 Shandong Technology & Business University; Ludong University; McGill
   University
RP Zhang, F (corresponding author), Shandong Technol & Business Univ, Yantai 264005, Peoples R China.; Zhang, F (corresponding author), Shandong Future Intelligent Financial Engn Lab, Yantai 264005, Peoples R China.
EM 1729676801@qq.com; hwa229@163.com; zhangmellie@gmail.com;
   liuyepengdream@gmail.com; zhangfan51@sina.com
RI Liu, Yepeng/AAT-7017-2021; Zhang, Fan/GLT-6231-2022
OI Liu, Yepeng/0000-0001-6340-7818; Zhang, Fan/0000-0002-0343-3499
FU Youth Innovation Technology Project of Higher School in Shandong
   Province [2019KJN042]; National Natural Science Foundation of China
   [62272281, 62007017, 61902220, ZR2021QF134]; Shandong Provincial Natural
   Science Foundation
FX AcknowledgementsThis work was supported in part by the Youth Innovation
   Technology Project of Higher School in Shandong Province under Grant No.
   2019KJN042, the National Natural Science Foundation of China under Grant
   Nos. 62272281, 62007017, and 61902220, and the project ZR2021QF134
   supported by the Shandong Provincial Natural Science Foundation.
CR Adebiyi AA, 2014, UKSIM INT CONF COMP, P106, DOI 10.1109/UKSim.2014.67
   Almalaq A, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P511, DOI 10.1109/ICMLA.2017.0-110
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bai S., 2018, P 6 INT C LEARN REPR
   Bai SJ, 2018, Arxiv, DOI [arXiv:1803.01271, DOI 10.48550/ARXIV.1803.01271]
   Beltagy I, 2020, Arxiv, DOI arXiv:2004.05150
   Box G. E. P., 1970, Time series analysis, forecasting and control
   BOX GEP, 1968, ROY STAT SOC C-APP, V17, P91
   Chang SY, 2017, ADV NEUR IN, V30
   Child R, 2019, Arxiv, DOI arXiv:1904.10509
   Chong E, 2017, EXPERT SYST APPL, V83, P187, DOI 10.1016/j.eswa.2017.04.030
   Chung JY, 2014, Arxiv, DOI arXiv:1412.3555
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hyndman RJ, 2006, INT J FORECASTING, V22, P679, DOI 10.1016/j.ijforecast.2006.03.001
   Jiao XQ, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4163
   Kitaev N, 2020, arXiv
   Lai GK, 2018, ACM/SIGIR PROCEEDINGS 2018, P95, DOI 10.1145/3209978.3210006
   Li SY, 2020, Arxiv, DOI [arXiv:1907.00235, DOI 10.48550/ARXIV.1907.00235, 10.48550/ARXIV.1907.00235]
   Lin T, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2273
   Lin YY, 2022, INT J FINANC ENG, V09, DOI 10.1142/S2424786322500141
   Madhusudhanan K, 2021, Arxiv, DOI arXiv:2110.08255
   MAKRIDAKIS S, 1982, J FORECASTING, V1, P111, DOI 10.1002/for.3980010202
   Pascanu R., 2013, INT C MACH LEARN, P1310
   Price I, 2022, PR MACH LEARN RES, V151
   Rao YM, 2021, Advances in neural information processing systems, V34
   Salinas D, 2020, INT J FORECASTING, V36, P1181, DOI 10.1016/j.ijforecast.2019.07.001
   Sanh V, 2020, Arxiv, DOI arXiv:1910.01108
   Sen R, 2019, Arxiv, DOI [arXiv:1905.03806, 10.48550/arXiv.1905.03806]
   Tyagi S., 2022, RECENT ADV COMPUT SC, V6, P15
   Vaswani A, 2017, ADV NEUR IN, V30
   Venna SR, 2019, IEEE ACCESS, V7, P7691, DOI 10.1109/ACCESS.2018.2888585
   Wang SN, 2020, Arxiv, DOI arXiv:2006.04768
   Woo G., 2022, arXiv
   Xiong AY, 2022, J METEOROL RES-PRC, V36, P93, DOI 10.1007/s13351-022-1140-4
   Yu RS, 2019, Arxiv, DOI arXiv:1711.00073
   Yue Z, 2021, AAAI CONF ARTIF INTE, V36, P8980, DOI DOI 10.1609/AAAI.V36I8.20881
   Zhou HY, 2021, AAAI CONF ARTIF INTE, V35, P11106
   Zhu XL, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-3131-8
NR 42
TC 0
Z9 0
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 11
PY 2023
DI 10.1007/s11042-023-15787-y
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G1LI4
UT WOS:000986851800009
DA 2024-07-18
ER

PT J
AU Hu, YX
   Lu, WH
   Wei, JG
   Xu, JH
   Ma, MD
AF Hu, Yangxia
   Lu, Wenhuan
   Wei, Jianguo
   Xu, Junhai
   Ma, Maode
TI A watermark detection scheme based on non-parametric model applied to
   mute machine voice
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Man-machine voice dialogue; Non-parametric model; Digital speech
   watermarking; Watermark detection
ID AUDIO WATERMARKING; ROBUST; TRANSFORM
AB With the development of artificial intelligence and human-computer interaction, performance of man-machine voice dialogue system is becoming better and better. We proposed a new watermark detection method based on non-parametric model to mute machine voice when there are two or more robots around. We took a random sequence composed of 1 and - 1 as watermark in our experiment. In the embedding process, we modeled coefficients of speech frames after 3-level DWT (Discrete wavelet transform) though KDE (Kernel Density Estimation) of non-parametric test, and in watermark detection process, we designed a detector of ML (Maximum Likelihood), and calculated decision threshold by Neyman-Pearson criterion. We found proposed detector could respond when test speech signal was watermarked, and could further mute machine voice. We calculated the theoretical detection rates with false alarm rates from 0 to 1, and compared the theoretical values with experimental values. We found experimental values were very close to theoretical values, and they were almost close to 1 when false alarm rates were above 0.3. Compared with existing synthetic speech detection algorithms, our proposal was simpler and cost less, and was appropriate to detect watermark based on small samples. And our algorithm had a good imperceptibility and robustness, and average detection rates were all above 98% for some common noise attacks.
C1 [Hu, Yangxia; Lu, Wenhuan; Wei, Jianguo; Xu, Junhai; Ma, Maode] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.
   [Wei, Jianguo] Qinghai Nationalities Univ, Sch Comp Sci & Technol, Xining 810000, Qinghai, Peoples R China.
C3 Tianjin University; Qinghai Nationalities University
RP Wei, JG (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.; Wei, JG (corresponding author), Qinghai Nationalities Univ, Sch Comp Sci & Technol, Xining 810000, Qinghai, Peoples R China.
EM 15122299017@126.com
RI Ma, MMD/HLG-6791-2023; Wei, Jianguo/KBA-3200-2024
OI Wei, Jianguo/0000-0002-8964-9759
FU National Natural Science Foundation of China [NSFC61876131]; Key Basic
   Research and Development of Ministry of Science and Technology
   [2018YFC0806802]
FX AcknowledgementsThis research was supported by the National Natural
   Science Foundation of China (No. NSFC61876131), and the Key Basic
   Research and Development of Ministry of Science and Technology
   (No.2018YFC0806802).
CR Ahmaderaghi B, 2018, IEEE T COMPUT IMAG, V4, P46, DOI 10.1109/TCI.2018.2794065
   Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Amini M, 2017, SIGNAL PROCESS, V137, P213, DOI 10.1016/j.sigpro.2017.01.019
   Arnold M, 2014, IEEE T INF FOREN SEC, V9, P411, DOI 10.1109/TIFS.2013.2293952
   Chen C, 2020, INT CONF ACOUST SPEE, P6809, DOI [10.1109/ICASSP40776.2020.9052957, 10.1109/icassp40776.2020.9052957]
   Etemad S, 2018, PATTERN RECOGN, V77, P99, DOI 10.1016/j.patcog.2017.12.006
   Fkirin A, 2022, MULTIMED TOOLS APPL, V81, P15961, DOI 10.1007/s11042-022-12566-z
   Ge J, 2019, THESIS CENTRAL CHINA
   GitHub, 2020, ABOUT US
   Gunsel B, 2006, LECT NOTES COMPUT SC, V4105, P241
   Hu HT, 2015, SIGNAL PROCESS, V109, P226, DOI 10.1016/j.sigpro.2014.11.011
   Kang XG, 2011, IEEE T MULTIMEDIA, V13, P181, DOI 10.1109/TMM.2010.2098850
   Kim W, 2020, INT CONF ACOUST SPEE, P2842, DOI [10.1109/ICASSP40776.2020.9053869, 10.1109/icassp40776.2020.9053869]
   Lei BY, 2015, SIGNAL PROCESS, V113, P80, DOI 10.1016/j.sigpro.2014.11.007
   Lhéritier A, 2018, IEEE T INFORM THEORY, V64, P3361, DOI 10.1109/TIT.2018.2800658
   Liao J, 2014, IEEE SIGNAL PROC LET, V21, P677, DOI 10.1109/LSP.2014.2312371
   Lin XD., 2012, J AUTOM, V38, P1445
   Lv XL, 2010, THESIS HEBEI U TECHN
   Nematollahi MA, 2013, INT J SPEECH TECHNOL, V16, P471, DOI 10.1007/s10772-013-9192-6
   Niu PP, 2020, MULTIMED TOOLS APPL, V79, P13351, DOI 10.1007/s11042-019-08504-1
   Patil Abhijit, 2022, Intelligent Sustainable Systems: Selected Papers of WorldS4 2021 . Lecture Notes in Networks and Systems (334), P679, DOI 10.1007/978-981-16-6369-7_62
   Shuo L, 2017, SECUR COMMU NETW, V3847092
   Tang X, 2015, THESIS BEIJING U POS
   WANG KX, 2017, 6 INT C INFORMATICS, P1
   Wang TH, 2019, INT CONF ACOUST SPEE, P2622, DOI 10.1109/ICASSP.2019.8682202
   Wang XY., 2017, CHIN J COMPUT, V40, P1
   Wu QL, 2018, THESIS NANJING U POS
   Yang CS, 2020, MULTIMED TOOLS APPL, V79, P30709, DOI 10.1007/s11042-020-08916-4
   [杨明浩 Yang Minghao], 2014, [计算机科学, Computer Science], V41, P12
   Yu H, 2018, THESIS BEIJING U POS
   Yu H, 2018, IEEE T NEUR NET LEAR, V29, P4633, DOI 10.1109/TNNLS.2017.2771947
   Yuan XC, 2015, INFORM SCIENCES, V298, P159, DOI 10.1016/j.ins.2014.11.040
   Zhang C, 2014, THESIS TIANJIN U
   Zhang Wei, 2020, Journal of Computer Applications, V40, P1191
   Zhong J, 2007, IEEE T INF FOREN SEC, V2, P297, DOI 10.1109/TIFS.2007.902663
NR 35
TC 1
Z9 1
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 44763
EP 44782
DI 10.1007/s11042-023-15572-x
EA MAY 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000981387900004
DA 2024-07-18
ER

PT J
AU Bandhu, KC
   Litoriya, R
   Khatri, M
   Kaul, M
   Soni, P
AF Bandhu, Kailash Chandra
   Litoriya, Ratnesh
   Khatri, Mihir
   Kaul, Milind
   Soni, Prakhar
TI Integrating graphology and machine learning for accurate prediction of
   personality: a novel approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graphology; Support Vector Machine; Personality prediction; Personality
   traits; Handwriting analysis
AB The problems related to unique personality identification are faced by various fields like psychology, criminal justice, and forensics investigations when hiring employees and assigning responsibilities. Presently, this identification is made manually by appointing a graphologist, which involves a cost. A person's unique personality is predicted using graphological analyses, which helps identify the person's truth or uniqueness. This quality allows the various organisations to understand the person's mental status, analyse the person's handwriting, assign the work to newly appointed employees or existing employees, and save the employer's time. The personality prediction is made using the person's handwriting; the parameters taken from handwriting are the slant of the words, the margin left by the writer, the baseline, and the size of the letter. The proposed work gives optimal values of input parameters for better accuracy in personality prediction. The proposed solution is implemented using different steps, which include preprocessing and segmentation, extraction of image features, trait acquisition, training and testing of the model, and personality prediction. The proposed work solves the problems using a support vector machine with a classifier with an accuracy of 95.05% and the personality traits of the writer, which is better than existing work. Apart from this, in the image preprocessing steps, the optimal inversion value was 255 pixels. For dilation, the kernel value of 5100 was taken. For line segmentation of an image, the optimal anchor value lies between 5000 and 7000.
C1 [Bandhu, Kailash Chandra; Litoriya, Ratnesh; Khatri, Mihir; Kaul, Milind; Soni, Prakhar] Medi Caps Univ, Indore, India.
RP Litoriya, R (corresponding author), Medi Caps Univ, Indore, India.
EM kailashchandra.bandhu@gmail.com; litoriya.ratnesh@gmail.com;
   mkhatri684@gmail.com; milindkaul3@gmail.com; prakhar04soni@gmail.com
RI Bandhu, Kailash Chandra/ABF-4912-2020
OI Bandhu, Kailash Chandra/0000-0002-4337-4198; Litoriya,
   Ratnesh/0000-0002-7285-422X
CR Alafif Tarik, 2022, International Journal of Information Technology, V14, P165, DOI 10.1007/s41870-021-00814-8
   [Anonymous], 2010, International Journal of Computer Applications
   Asra S, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER, AND OPTIMIZATION TECHNIQUES (ICEECCOT), P260
   Aulia MR, 2020, P 5 INT C IND ENG OP, P1761
   Ayyadevara SA, 2018, 2018 3 IEEE INT C RE, P1239, DOI [10.1109/RTEICT42901.2018.9012248, DOI 10.1109/RTEICT42901.2018.9012248]
   Bandhu KC, 2023, MULTIMED TOOLS APPL, V82, P23541, DOI 10.1007/s11042-022-14238-4
   Bandhu KC, 2022, IEEE GLOBE WORK
   Basaran S, 2021, SAGE OPEN, V11, DOI 10.1177/21582440211032156
   Champa H. N., 2010, Proceedings of the 2010 First International Conference on Integrated Intelligent Computing (ICIIC 2010), P160, DOI 10.1109/ICIIC.2010.29
   Chandra Mayank Arya, 2021, International Journal of Information Technology, V13, P1, DOI 10.1007/s41870-017-0080-1
   Chitlangia A, 2019, PROCEDIA COMPUT SCI, V165, P384, DOI 10.1016/j.procs.2020.01.034
   Computer Vision and Artificial Intelligence, IAM HANDWR DAT
   Durga L., 2021, Glob. Transitions Proc, V2, P287, DOI [10.1016/j.gltp.2021.08.025, DOI 10.1016/J.GLTP.2021.08.025]
   Farooq Huma, 2020, International Journal of Information Technology, V12, P1281, DOI 10.1007/s41870-018-0230-0
   Garg Anupam, 2022, International Journal of Information Technology, V14, P145, DOI 10.1007/s41870-019-00399-3
   Gavrilescu M, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0297-3
   Ghosh Sohom, 2021, International Journal of Information Technology, V13, P1235, DOI 10.1007/s41870-020-00473-1
   Gupta R, 2022, BLOCKCHAIN 5G HEALTH, P35
   Jain Vanita, 2021, International Journal of Information Technology, V13, P1193, DOI 10.1007/s41870-021-00617-x
   Joseph Ferdin Joe John, 2020, International Journal of Information Technology, V12, P57, DOI 10.1007/s41870-019-00366-y
   Joshi P, 2015, Int J Comput Appl, V130, P40, DOI [10.5120/ijca2015907189, DOI 10.5120/IJCA2015907189]
   Khanday Akib Mohi Ud Din, 2021, Int J Inf Technol, V13, P115, DOI 10.1007/s41870-020-00550-5
   Litoriya R, 2022, ADOPTION BLOCKCHAIN, P211, DOI [10.1007/978-3-030-89546-4_11, DOI 10.1007/978-3-030-89546-4_11]
   Litoriya R, 2020, CELL MOL LIFE SCI, V29, P11060
   Malviya S, CLIN TOXICOL
   Niranjan Damini, 2021, International Journal of Information Technology, V13, P1667, DOI 10.1007/s41870-021-00690-2
   Oliveira LS, GRAPHOLOGY APPL SIGN
   Pandey M, 2020, WIRELESS PERS COMMUN, V110, P1659, DOI 10.1007/s11277-019-06805-0
   Pandey M, 2019, WIRELESS PERS COMMUN, V107, P1687, DOI 10.1007/s11277-019-06351-9
   Pandey P, 2020, WIRELESS PERS COMMUN, V112, P607, DOI 10.1007/s11277-020-07064-0
   Pandey P, 2020, INT J FUZZY SYST, V22, P1212, DOI 10.1007/s40815-020-00815-y
   Patil Anjali R., 2022, International Journal of Information Technology, P3781, DOI 10.1007/s41870-021-00831-7
   Patil V, 2020, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT-2020), DOI 10.1109/icict48043.2020.9112449
   Prasad S., 2010, INT J COMPUTER APPL, V8, P25, DOI [10.5120/1256-1758, DOI 10.5120/1256-1758]
   Revathi A, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/4190023
   Sharma N., 2019, INT J EMERG TECHNOL, V10, P374
   Sharma N, 2021, ADV MACHINE LEARNING, P267, DOI DOI 10.1007/978-981-15-3383-9_24
   Singh Kuldeep, 2019, International Journal of Information Technology, V11, P485, DOI 10.1007/s41870-018-0134-z
   Soner S, 2022, WIRELESS PERS COMMUN, V125, P3001, DOI 10.1007/s11277-022-09695-x
   Soner S, 2021, WIRELESS PERS COMMUN, V121, P2495, DOI 10.1007/s11277-021-08833-1
NR 40
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46457
EP 46481
DI 10.1007/s11042-023-15567-8
EA MAY 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000979963000002
DA 2024-07-18
ER

PT J
AU Takbiri, Y
   Bastanfard, A
   Amini, A
AF Takbiri, Yazdan
   Bastanfard, Azam
   Amini, Amineh
TI A gamified approach for improving the learning performance of K-6
   students using Easter eggs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distance education and online learning; Elementary education; Games;
   Human-computer interface; Improving classroom teaching
ID USER ENGAGEMENT; GAMIFICATION; CLASSROOM; FRAMEWORK
AB Gamification is mainly used to increase user engagement and motivation, hence increasing the user base and user activity. Defined by applying game elements to non-gaming contexts, gamification is mostly integrated with software applications in order to provide a gameful experience for users. Education has been one of the areas where gamification studies have focused a lot during the last decade. Young students with the age range of 712 years old (K-6) require different teaching methods to use their full potential. However, the methods and principles presented in studies on gamification and its application in education are not dedicated to K-6 students. Furthermore, the evolution of video games has brought new opportunities to develop new gamification elements and principles. In this research, the easter egg element has been implemented as a gamification element. Easter eggs can trigger children's curiosity by encouraging them to find all the Easter eggs, promising special rewards and perks. Additionally, a gamified approach is proposed for implementing a gamified software application for K-6 students. Based on the proposed approach, Science Island is implemented as an online gamified web application for K-6 students. In order to assess the proposed approach, a group of 47 sixth-grade students was selected to use the application for an observation period of 2 months. Feedbacks from students showed that more than 82% of the students agreed with the effectiveness of gamification in their educational performance. Additionally, the results from the data analysis revealed that students' learning performance was improved significantly after applying gamification elements; showing an increase of 0.63 in average quiz score from the second month compared to the first month. Furthermore, the user activity rate at the end of the observation period showed increased motivation among students for using the software application.
C1 [Takbiri, Yazdan; Bastanfard, Azam; Amini, Amineh] Islamic Azad Univ, Karaj Branch, Dept Comp Engn, Karaj, Iran.
C3 Islamic Azad University
RP Bastanfard, A (corresponding author), Islamic Azad Univ, Karaj Branch, Dept Comp Engn, Karaj, Iran.
EM bastanfard@kiau.ac.ir
OI Amini, Amineh/0000-0001-8427-5455
CR Amini A, 2014, J COMPUT SCI TECH-CH, V29, P116, DOI 10.1007/s11390-014-1416-y
   Azevedo JD, 2019, IEEE SYS INF ENGI DE, P1, DOI 10.1109/sieds.2019.8735645
   Baldeon J, 2015, 2 INT WORKSHOP GAMIF
   Barata G, 2017, COMPUT HUM BEHAV, V71, P550, DOI 10.1016/j.chb.2016.08.049
   Bastanfard A, 2010, LECT NOTES COMPUT SC, V6298, P705, DOI 10.1007/978-3-642-15696-0_65
   Bastanfard A, 2009, LECT NOTES COMPUT SC, V5879, P1080, DOI 10.1007/978-3-642-10467-1_104
   Cahyani AD, 2016, MATEC WEB CONF, V58, DOI 10.1051/matecconf/20165803006
   Cechetti NP, 2019, TELEMAT INFORM, V41, P126, DOI 10.1016/j.tele.2019.04.007
   Chuvaieva A, 2019, J INTELLET PROP LAW, V14, P864, DOI 10.1093/jiplp/jpz107
   Deterding S., 2011, P 15 INT AC MINDTREK, P9, DOI [10.1145/2181037.2181040, DOI 10.1145/2181037.2181040]
   Deterding Sebastian, 2011, P 2011 C HUMAN FACTO, P2425, DOI DOI 10.1145/1979742.1979575
   Eisingerich AB, 2019, INT J RES MARK, V36, P200, DOI 10.1016/j.ijresmar.2019.02.003
   Parra-González ME, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12020602
   García F, 2017, J SYST SOFTWARE, V132, P21, DOI 10.1016/j.jss.2017.06.021
   Hamari J, 2017, COMPUT HUM BEHAV, V71, P469, DOI 10.1016/j.chb.2015.03.036
   Hamari J, 2014, P ANN HICSS, P3025, DOI 10.1109/HICSS.2014.377
   Hammedi W, 2017, J SERV MANAGE, V28, P640, DOI 10.1108/JOSM-04-2016-0116
   Hanafiah SHM., 2019, INT J RECENT TECHNOL, V8, P364, DOI [10.35940/ijrte.B1062.0782S319, DOI 10.35940/IJRTE.B1062.0782S319]
   Hanus MD, 2015, COMPUT EDUC, V80, P152, DOI 10.1016/j.compedu.2014.08.019
   Harwood T, 2015, J SERV MARK, V29, P533, DOI 10.1108/JSM-01-2015-0045
   Hassan MA, 2021, INTERACT LEARN ENVIR, V29, P545, DOI 10.1080/10494820.2019.1588745
   Hollebeek LD, 2021, INT J INFORM MANAGE, V61, DOI 10.1016/j.ijinfomgt.2021.102308
   Huotari K., 2012, DEFINING GAMIFICATIO
   Khan Tayyeb Ahmed, 2021, Responsible AI and Analytics for an Ethical and Inclusive Digitized Society: 20th IFIP WG 6.11 Conference on e-Business, e-Services and e-Society, I3E 2021, Proceedings. Lecture Notes in Computer Science, Information Systems and Applications, incl. Internet/Web, and HCI (12896), P763, DOI 10.1007/978-3-030-85447-8_64
   Knutas A, 2019, MULTIMED TOOLS APPL, V78, P13593, DOI 10.1007/s11042-018-6913-5
   Koivisto J, 2021, GERONTOLOGIST, V61, pE360, DOI 10.1093/geront/gnaa047
   Koivisto J, 2019, INT J INFORM MANAGE, V45, P191, DOI 10.1016/j.ijinfomgt.2018.10.013
   Lakier Matthew, 2022, Proceedings of the ACM on Human-Computer Interaction, V6, DOI 10.1145/3512949
   Legaki NZ, 2020, INT J HUM-COMPUT ST, V144, DOI 10.1016/j.ijhcs.2020.102496
   Lieberoth A, 2015, GAMES CULT, V10, P229, DOI 10.1177/1555412014559978
   Lister M.C., 2015, Issues and Trends in Educational Technology, V3, P2, DOI DOI 10.2458/AZUITETV3I2LISTER
   Minoofam SAH, 2022, MULTIMED TOOLS APPL, V81, P6389, DOI 10.1007/s11042-021-11806-y
   Minoofam SAH, 2023, IEEE T NEUR NET LEAR, V34, P2480, DOI 10.1109/TNNLS.2021.3106705
   Monterrat B., 2013, 4 WORKSH MOT AFF ASP, DOI 10.1145/2513002.2513024
   Morschheuser B, 2018, INFORM SOFTWARE TECH, V95, P219, DOI 10.1016/j.infsof.2017.10.015
   Movahedi Z, 2021, MULTIMED TOOLS APPL, V80, P26773, DOI 10.1007/s11042-021-10968-z
   Oliveira W, 2021, IEEE INT CONF ADV LE, P97, DOI 10.1109/ICALT52272.2021.00037
   Pedreira O, 2015, INFORM SOFTWARE TECH, V57, P157, DOI 10.1016/j.infsof.2014.08.007
   Putz LM, 2020, COMPUT HUM BEHAV, V110, DOI 10.1016/j.chb.2020.106392
   Radovick S., 2018, THE J, V1, P71, DOI [10.3390/j1010008, DOI 10.3390/J1010008]
   Robson K, 2015, BUS HORIZONS, V58, P411, DOI 10.1016/j.bushor.2015.03.006
   Salvador Rodrigo B., 2017, J GEEK STUD, V4, P63
   Seixas LD, 2016, COMPUT HUM BEHAV, V58, P48, DOI 10.1016/j.chb.2015.11.021
   Seo-Hyun N., 2022, J KOREA GAME SOC, V22, P3, DOI [10.7583/JKGS.2022.22.1.3, DOI 10.7583/JKGS.2022.22.1.3]
   Simoes J, 2013, COMPUT HUM BEHAV, V29, P345, DOI 10.1016/j.chb.2012.06.007
   Stein KA, 2019, COMMUN TEACH, V33, P249, DOI 10.1080/17404622.2019.1575440
   Suh A, 2018, J COMPUT INFORM SYST, V58, P204, DOI 10.1080/08874417.2016.1229143
   Takbiri Y, 2019, 2019 5 IR C SIGN PRO, P1, DOI [10.1109/ICSPIS48872.2019.9066006, DOI 10.1109/ICSPIS48872.2019.9066006]
   Tang Jian, 2019, International Journal of Crowd Science, V3, DOI 10.1108/IJCS-09-2018-0025
   Toda AM, 2019, SMART LEARN ENVIRON, V6, DOI 10.1186/s40561-019-0106-1
   Weinel J, 2014, P 40 INT COMPUTER MU, P140
   Yang Y, 2017, COMPUT HUM BEHAV, V73, P459, DOI 10.1016/j.chb.2017.03.066
NR 52
TC 3
Z9 3
U1 6
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20683
EP 20701
DI 10.1007/s11042-023-14356-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:001062512700069
PM 36685015
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Jamali, M
   Karimi, N
   Khadivi, P
   Shirani, S
   Samavi, S
AF Jamali, Maedeh
   Karimi, Nader
   Khadivi, Pejman
   Shirani, Shahram
   Samavi, Shadrokh
TI Robust watermarking using diffusion of logo into auto-encoder feature
   maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind watermarking; Convolutional auto-encoder; Dilation layer;
   Robustness; Data expanding
ID FUZZY INFERENCE SYSTEM; BLIND WATERMARKING; NEURAL-NETWORKS; IMAGE;
   SCHEME; TRANSFORM; MACHINE; IDENTIFICATION
AB Digital content has grown dramatically in recent years, leading to increased attention to copyright. Image watermarking has been considered one of the most popular methods for copyright protection. With the recent advancements in the application of deep neural networks in image processing, these networks have also been used in image watermarking. Robustness and imperceptibility are two challenging features of watermarking methods that the trade-off between them should be satisfied. In this paper, we propose to use an end-to-end network for watermarking. We use a convolutional neural network (CNN) to control the embedding strength based on the images' content. Dynamic embedding helps the network to have the lowest effect on the visual quality of the watermarked image. Different image processing attacks are simulated as a network layer to improve the robustness of the model. Our method is a blind watermarking approach that replicates the watermark string to create a matrix of the same size as the input image. This helps the network to spread the watermark information in a wider space. Therefore, by removing some parts of the image by attacks, the watermark information can be retrieved from other parts. Using dilation layers is another innovation of the proposed method that helps the watermark spread in the wider neighborhood. This will improve the robustness of the method against image processing attacks during extraction. Instead of diffusing the watermark data into the input image, we inject the data into the feature space and force the network to do this in regions that increase the robustness against various attacks. Having embedding, extraction, and attack layer in an end-to-end network helps increase robustness and imperceptibility. Experimental results show the proposed method's superiority in imperceptibility and robustness compared to the state-of-the-art algorithms.
C1 [Jamali, Maedeh; Karimi, Nader; Shirani, Shahram; Samavi, Shadrokh] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
   [Khadivi, Pejman; Samavi, Shadrokh] Seattle Univ, Comp Sci Dept, Seattle, WA 98122 USA.
   [Samavi, Shadrokh] McMaster Univ, Elect & Comp Engn Dept, Hamilton, ON, Canada.
C3 Isfahan University of Technology; Seattle University; McMaster
   University
RP Khadivi, P (corresponding author), Seattle Univ, Comp Sci Dept, Seattle, WA 98122 USA.
EM khadivip@seattleu.edu
RI Karimi, Nader/HWP-4206-2023
OI Karimi, Nader/0000-0001-8904-1607
CR Abdelhakim AM, 2018, EXPERT SYST APPL, V100, P197, DOI 10.1016/j.eswa.2018.02.002
   Ahmadi M, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2019.113157
   Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Anbarjafari G, 2018, MULTIMED TOOLS APPL, V77, P24521, DOI 10.1007/s11042-018-5759-1
   [Anonymous], 2007, P 8 INT WORKSH IM AN
   [Anonymous], DATASET STANDARD 512
   Broughton, 1989, United States Patent, Patent No. [4,807,031, 4807031]
   Cheng, 2001, 2 INT S MUSIC INFORM
   Etemad E., 2017, MULTIMED TOOLS APPL, V77, P1, DOI DOI 10.1007/S11042-017-5543-7
   Etemad S, 2018, PATTERN RECOGN, V77, P99, DOI 10.1016/j.patcog.2017.12.006
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fan, 2021, MULTIMEDIA SYST, V28, P1
   Faundez-Zanuy M, 2007, PATTERN RECOGN, V40, P3027, DOI 10.1016/j.patcog.2007.02.016
   Fazlali HR, 2017, MULTIMED TOOLS APPL, V76, P3105, DOI 10.1007/s11042-015-3200-6
   Gong LH, 2021, MULTIMED TOOLS APPL, V80, P439, DOI 10.1007/s11042-020-09677-w
   Hamghalam M, 2014, IET IMAGE PROCESS, V8, P162, DOI 10.1049/iet-ipr.2013.0386
   Hatami E., 2022, MULTIMED TOOLS APPL, V70, P1
   Heidari M, 2017, MULTIMED TOOLS APPL, V76, P23459, DOI 10.1007/s11042-016-4150-3
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Hu FX, 2023, VISUAL COMPUT, V39, P4573, DOI 10.1007/s00371-022-02610-2
   Hua G, 2019, IEEE T CIRC SYST VID, V29, P625, DOI 10.1109/TCSVT.2018.2809585
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jagadeesh B, 2016, SOFT COMPUT, V20, P3679, DOI 10.1007/s00500-015-1729-y
   Jagadeesh B, 2015, PROCEDIA COMPUT SCI, V46, P1618, DOI 10.1016/j.procs.2015.02.095
   Jamali M, 2018, J INTELL FUZZY SYST, V35, P4589, DOI 10.3233/JIFS-171805
   Kandi H, 2017, COMPUT SECUR, V65, P247, DOI 10.1016/j.cose.2016.11.016
   Khan A, 2008, PATTERN RECOGN, V41, P2594, DOI 10.1016/j.patcog.2008.01.007
   Kingma D. P., 2014, arXiv
   Krizhevsky A., The cifar-10 dataset, in
   Kumar Dinesh, 2011, INFOCOMP Journal of Computer Science, V10, P25
   Kumar V, 2019, J INTELL SYST, V28, P749, DOI 10.1515/jisys-2017-0134
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu J., 2005, P 1 INT C INF COMM T, P337
   Makbol NM, 2017, INFORM SCIENCES, V417, P381, DOI 10.1016/j.ins.2017.07.026
   Mamta, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5291
   Moad MS, 2022, MICROPROCESS MICROSY, V90, DOI 10.1016/j.micpro.2022.104490
   Mun SM, 2017, ARXIV
   Nezhadarya E, 2011, IEEE T INF FOREN SEC, V6, P1200, DOI 10.1109/TIFS.2011.2163627
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Plata M, 2020, IEEE INT CONF TRUST, P62, DOI 10.1109/TrustCom50675.2020.00022
   Potdar VA, 2005, 2005 3RD IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS (INDIN), P709
   Rashid A., 2016, INT J COMPUTER APPL, V5, P147, DOI DOI 10.7753/IJCATR0503.1006
   Rasti P, 2017, SIG PROCESS COMMUN
   Rezaee K., 2022, Intelligent healthcare: Infrastructure, algorithms and management, P373, DOI [10.1007/978-981-16-8150-917, DOI 10.1007/978-981-16-8150-917]
   Sadreazami H, 2016, IEEE T MULTIMEDIA, V18, P196, DOI 10.1109/TMM.2015.2508147
   Savakar D. G., 2017, Pattern Recognition and Image Analysis, V27, P511, DOI 10.1134/S1054661817030257
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Singh RP, 2016, NEUROCOMPUTING, V174, P238, DOI 10.1016/j.neucom.2015.03.115
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Solachidis V, 2001, IEEE T IMAGE PROCESS, V10, P1741, DOI 10.1109/83.967401
   Szepanski W., 1979, Proceedings of the 1979 Carnahan Conference on Crime Countermeasures, P101
   Tagliasacchi M, 2009, IEEE T IMAGE PROCESS, V18, P2491, DOI 10.1109/TIP.2009.2028251
   Taherinia AH, 2009, INT J ELECTRON SECUR, V2, P280, DOI 10.1504/IJESDF.2009.027523
   Tian C, 2020, MULTIMED TOOLS APPL, V79, P7515, DOI 10.1007/s11042-019-08530-z
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Yu CY, 2021, WIREL NETW, V27, P3507, DOI 10.1007/s11276-019-02223-z
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Yu F., 2015, ARXIV
   Zhang H, 2011, IEEE T IMAGE PROCESS, V20, P2189, DOI 10.1109/TIP.2011.2118216
   Zhu JR, 2018, LECT NOTES COMPUT SC, V11219, P682, DOI 10.1007/978-3-030-01267-0_40
   Zong TR, 2015, IEEE T CIRC SYST VID, V25, P717, DOI 10.1109/TCSVT.2014.2363743
NR 61
TC 2
Z9 2
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45175
EP 45201
DI 10.1007/s11042-023-15371-4
EA APR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000977296200005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Patwari, B
   Nandi, U
   Ghosal, SK
AF Patwari, Biswajit
   Nandi, Utpal
   Ghosal, Sudipta Kr
TI Image steganography based on difference of Gaussians edge detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Edge detection; Difference of Gaussians; Embedding;
   Extraction; Payload
ID HIGH-PAYLOAD; WATERMARKING; LAPLACIAN; OPERATOR; NETWORK; SECURE
AB This paper introduces an edge-based image Steganography scheme in which the pixels of the cover images are categorized into two classes: edge and non-edge. In general, the edge pixels hide more secret bits compared to non-edge pixels due to the following two reasons: noisy nature and high tolerance level. The edge pixels are perceived as noisy due to the variation in intensities with respect to the neighboring pixels and hence it is difficult to model. Further the tolerance level of edge pixels is usually high compared to non-edge pixels on equivalent alteration. These two reasons motivate us to propose a new image Steganography method based on Difference of Gaussians (DoG) Edge detection. The proposed scheme has three major phases: pre-processing cum edge detection, embedding and extraction. In the leading two phases, we obtain the edge image from the cover image and then embed secret bits into the non-edge and edge pixels with X:Y ratio, where for all X, Y, 1 <= X <= 3 and 2 <= Y <= (X + 1). In the ultimate phase, we extract the secret bits from the Stego-image. The extracted secret bits helps us to regenerate the secret image which was embedded earlier. The experimental result confirms that the proposed technique offers variable payload and acceptable visual clarity. The comparison results also ensure that the proposed method is superior to the conventional edge detection based Steganography schemes as far as the payload is concerned.
C1 [Patwari, Biswajit] Panihati Mahavidyalaya, Dept Comp Sci, Barasat Rd,PO Sodepur, Kolkata 700110, West Bengal, India.
   [Nandi, Utpal] Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, West Bengal, India.
   [Ghosal, Sudipta Kr] Behala Govt Polytech, Dept Cyber Forens & Informat Secur, 756 Upendra Nath Banerjee Rd, Kolkata 700060, India.
C3 Vidyasagar University
RP Ghosal, SK (corresponding author), Behala Govt Polytech, Dept Cyber Forens & Informat Secur, 756 Upendra Nath Banerjee Rd, Kolkata 700060, India.
EM biswajit.pato@gmail.com; nandi.3utpal@gmail.com;
   sudipta.ghosal@gmail.com
RI Nandi, Utpal/AAW-9041-2021
OI Nandi, Utpal/0000-0002-9638-1906
CR Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Atta R, 2018, J VIS COMMUN IMAGE R, V53, P42, DOI 10.1016/j.jvcir.2018.03.009
   Bai JL, 2017, DISPLAYS, V46, P42, DOI 10.1016/j.displa.2016.12.004
   Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Boehm B., 2014, ARXIV
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164
   Chandwadkar R, 2013, 6 ANN C IRAJ
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Chin-Feng Lee, 2010, Proceedings of the 2010 Fourth International Conference on Genetic and Evolutionary Computing (ICGEC 2010), P654, DOI 10.1109/ICGEC.2010.167
   Dhargupta S, 2019, MULTIMED TOOLS APPL, V78, P17589, DOI 10.1007/s11042-018-7123-x
   Dumitrescu S, 2002, P INT C IM PROC, V3
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Gaurav K, 2018, J INF SECUR APPL, V41, P41, DOI 10.1016/j.jisa.2018.05.001
   Ghosal SK, 2018, MULTIMED TOOLS APPL, V77, P30403, DOI 10.1007/s11042-018-6126-y
   Ghosal SK, 2014, J INF SECUR APPL, V19, P272, DOI 10.1016/j.jisa.2014.07.004
   Ghosal SK, 2021, MULTIMEDIA SYST, V27, P73, DOI 10.1007/s00530-020-00703-3
   KIRSCH RA, 1971, COMPUT BIOMED RES, V4, P315, DOI 10.1016/0010-4809(71)90034-6
   Kumar S, 2019, DEF TECHNOL, V15, P162, DOI 10.1016/j.dt.2018.08.003
   Kuo WC, 2009, HIS 2009: 2009 NINTH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS, VOL 3, PROCEEDINGS, P69, DOI 10.1109/HIS.2009.226
   Lee CF, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P497
   Lei Yang, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P1197, DOI 10.1109/CISP.2011.6100495
   Ma X., 2012, Artificial Intelligence and Computational Intelligence, P50
   Mandal JK, 2013, ADV INTELL SYST, V177, P767
   Mathur N, 2016, PROCEDIA COMPUT SCI, V93, P431, DOI 10.1016/j.procs.2016.07.230
   Matthew JP-H, MOL EXPRESSIONS MICR
   Setiadi DIM, 2022, J KING SAUD UNIV-COM, V34, P104, DOI 10.1016/j.jksuci.2019.12.007
   Seyyedi SA, 2014, INT J SECUR APPL, V8, P183, DOI 10.14257/ijsia.2014.8.4.17
   Shrivakshan G., 2012, INT J COMPUT SCI ISS, V9, P269
   Tseng HW, 2014, IET IMAGE PROCESS, V8, P647, DOI 10.1049/iet-ipr.2013.0584
   Wang X, 2007, IEEE T PATTERN ANAL, V29, P886, DOI 10.1109/TPAMI.2007.1027
   Weber A., 1997, The usc-sipi image database
   Wong KS, 2007, SIGNAL PROCESS, V87, P1251, DOI 10.1016/j.sigpro.2006.10.014
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 37
TC 4
Z9 4
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43759
EP 43779
DI 10.1007/s11042-023-15360-7
EA APR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000977223400006
DA 2024-07-18
ER

PT J
AU Jayachandran, A
   Kumar, SR
   Perumal, TSR
AF Jayachandran, A.
   Kumar, S. Ratheesh
   Perumal, T. Sudarson Rama
TI Multi-dimensional cascades neural network models for the segmentation of
   retinal vessels in colour fundus images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Fundus images; Retinal blood vessel; Segmentation
ID HYBRID STRUCTURE DESCRIPTOR; SEVERITY ANALYSIS; BLOOD-VESSELS;
   CLASSIFICATION; HISTOGRAM
AB Deep learning has recently received attention as one of the most popular methods for boosting performance in different sectors, including medical image analysis, pattern recognition and classification. Diabetic retinopathy becomes an increasingly popular cause of vision loss in diabetic patients.. Retinal vascular status in fundus images is a reliable biomarker for diabetes, hypertension and many ophthalmic diseases. Therefore, accurate segmentation of retinal vessels is of great significance for the diagnosis of many diseases. However, due to the inherent complexity of the retina itself and the lack of data, it is difficult to obtain the ideal accuracy of the segmentation results of the vascular end. To solve this problem, we propose an innovative multi-dimensional deep convolutional Neural network (MDUNet) to segment the retinal vessels in fundus images. The fusion of cross-dimensional transformation makes full use of the relevance of information between different dimensions. Meanwhile, the self-attention calculation method of cross-window is applied to effectively reduce the computational complexity. MDUNet is proposed to provide a research basis for the application of Transformer structure in the field of medical image segmentation. The proposed method is evaluated on different evaluation metrics such as sensitivity, specificity, and accuracy. Experimental results on six public datasets show that the proposed work MDUNet achieves better vessel segmentation accuracy with a smaller number of parameters compared with classical models such as U-Net, SegNet, and DeepLabv3+.
C1 [Jayachandran, A.] Presidency Univ, Dept CSE, Bangalore, India.
   [Kumar, S. Ratheesh] PSN Coll Engn & Technol, Dept CSE, Tirunelveli, India.
   [Perumal, T. Sudarson Rama] Rohini Coll Engn & Technol, Dept CSE, Nagercoil, India.
C3 Presidency University, Bangalore
RP Jayachandran, A (corresponding author), Presidency Univ, Dept CSE, Bangalore, India.
EM ajaya1675@gmail.com; ratheeshnice@gmail.com; sudarsonphdcse@gmail.com
RI Kumar S, Ratheesh/ITT-1313-2023
OI KUMAR S, RATHEESH/0000-0001-7679-0609
CR Akram MU, 2013, PATTERN RECOGN, V46, P107, DOI 10.1016/j.patcog.2012.07.002
   Aslan MF, 2018, 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND DATA PROCESSING (IDAP), DOI 10.1109/IDAP.2018.8620890
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   cvit.iiit.ac.in, ABOUT US
   David DS, 2020, MULTIMED TOOLS APPL, V79, P5213, DOI 10.1007/s11042-018-6265-1
   David Jayachandran D.S., 2018, BIOMED PHARMACOL J, V11, P577, DOI DOI 10.13005/bpj/1410
   Fan Z, 2019, IEEE T IMAGE PROCESS, V28, P2367, DOI 10.1109/TIP.2018.2885495
   Feng ST, 2020, NEUROCOMPUTING, V392, P268, DOI 10.1016/j.neucom.2018.10.098
   Fraz MM, 2012, IEEE T BIO-MED ENG, V59, P2538, DOI 10.1109/TBME.2012.2205687
   Gegundez-Arias ME, 2021, COMPUT METH PROG BIO, V205, DOI 10.1016/j.cmpb.2021.106081
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   Jayachandran A, 2017, IRAN J FUZZY SYST, V14, P41
   Jayachandran A, 2015, INT J FUZZY SYST, V17, P434, DOI 10.1007/s40815-015-0064-x
   Jayachandran A, 2014, INT J IMAG SYST TECH, V24, P72, DOI 10.1002/ima.22081
   Jin QG, 2019, KNOWL-BASED SYST, V178, P149, DOI 10.1016/j.knosys.2019.04.025
   Lam BSY, 2010, IEEE T MED IMAGING, V29, P1369, DOI 10.1109/TMI.2010.2043259
   Leopold HA, 2019, J IMAGING, V5, DOI 10.3390/jimaging5020026
   Li X, 2021, IEEE T IND INFORM, V17, P1958, DOI 10.1109/TII.2020.2993842
   Mahiba C, 2019, MEASUREMENT, V135, P762, DOI 10.1016/j.measurement.2018.12.032
   Medical Image Analysis Group, ALG VAL
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Namboodiri TS, 2020, INT J COMPUT INT SYS, V13, P77, DOI 10.2991/ijcis.d.200117.002
   Odstrcilik J, 2013, IET IMAGE PROCESS, V7, P373, DOI 10.1049/iet-ipr.2012.0455
   Owen CG, 2009, INVEST OPHTH VIS SCI, V50, P2004, DOI 10.1167/iovs.08-3018
   Palanivel DA, 2020, APPL SOFT COMPUT, V94, DOI 10.1016/j.asoc.2020.106439
   Rezaee K, 2017, APPL SOFT COMPUT, V52, P937, DOI 10.1016/j.asoc.2016.09.033
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Samuel PM, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105769
   Saroj SK, 2020, COMPUT METH PROG BIO, V194, DOI 10.1016/j.cmpb.2020.105490
   Sathananthavathi V, 2021, COGN SYST RES, V67, P84, DOI 10.1016/j.cogsys.2021.01.003
   Soomro TA, 2019, EXPERT SYST APPL, V134, P36, DOI 10.1016/j.eswa.2019.05.029
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tang XL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106353
   Wang WH, 2019, IET IMAGE PROCESS, V13, P2538, DOI 10.1049/iet-ipr.2018.5636
   Wu YC, 2020, NEURAL NETWORKS, V126, P153, DOI 10.1016/j.neunet.2020.02.018
   Xiang Y, 2014, PROCEEDINGS OF 2014 IEEE INTERNATIONAL CONFERENCE ON PROGRESS IN INFORMATICS AND COMPUTING (PIC), P316, DOI 10.1109/PIC.2014.6972349
   Yan ZQ, 2019, IEEE J BIOMED HEALTH, V23, P1427, DOI 10.1109/JBHI.2018.2872813
   Yan ZQ, 2018, IEEE T BIO-MED ENG, V65, P1912, DOI 10.1109/TBME.2018.2828137
   Yang JZ, 2020, COMPUT METH PROG BIO, V197, DOI 10.1016/j.cmpb.2020.105752
   Yang JZ, 2020, COMPUT MED IMAG GRAP, V85, DOI [10.1016.j.compmedimag.2020.101783, 10.1016/j.compmedimag.2020.101783]
   Yang L, 2021, NEUROCOMPUTING, V448, P168, DOI 10.1016/j.neucom.2021.03.085
   Yuan Lan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12265), P755, DOI 10.1007/978-3-030-59722-1_73
   Zhang J, 2016, IEEE T MED IMAGING, V35, P2631, DOI 10.1109/TMI.2016.2587062
   Zhang Z, 2010, IEEE ENG MED BIO, P3065, DOI 10.1109/IEMBS.2010.5626137
NR 46
TC 4
Z9 4
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42927
EP 42943
DI 10.1007/s11042-023-15133-2
EA APR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000970495100002
DA 2024-07-18
ER

PT J
AU Ahmad, F
   Ahmed, Z
   Shaheen, M
   Muneeb, S
   Riasat, R
AF Ahmad, Faizan
   Ahmed, Zeeshan
   Shaheen, Momina
   Muneeb, Sara
   Riasat, Rubata
TI A pilot study on the evaluation of cognitive abilities' cluster through
   game-based intelligent technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cognitive evaluation; Gamification; Interactive system; Non-invasive
   data
ID SELECTIVE VISUAL-ATTENTION; VIDEO-GAME; PHYSICAL-ACTIVITY;
   WORKING-MEMORY; COMPUTER GAMES; PERFORMANCE; EXPERIENCE; CHILDREN;
   PLAYERS; SKILLS
AB Numerous scientific studies measured cognitive abilities through administered tests. Most of these traditional tests are inappropriate for several reasons, such as cost-ineffectiveness, tiresomeness, and invasiveness. The need is to build cost-effective, exciting, and plausibly engaging techniques that could noninvasively measure cognitive abilities. This paper presents LAS, an intelligent technique that utilizes non-invasively collected game analytics to automatically evaluate the cluster of three cognitive abilities (i.e., Visual Long-term Memory (VLTM), Analytical Capability (AC), and Visual Short-term Memory in Change Detection Paradigm (VSTMiCDP)). The experimental group-based cross-generational cognitive evaluation in the game-based scenario established the potential of the proposed technique is twofold: 1) It successfully categorizes cluster of three targeted cognitive abilities within the 5-point evaluation sphere (i.e., 0-1 = very bad, 1-2 = bad, 2-3 = fair, 3-4 = good, 4-5 = excellent), and 2) It highly correlates with the results of a control group that are measured with three traditional cognitive tests.
C1 [Ahmad, Faizan] Cardiff Metropolitan Univ, Cardiff Sch Technol, Llandaff Campus, Cardiff CF5 2YB, Wales.
   [Ahmed, Zeeshan] Chinese Acad Sci, Inst Software, Zhongguancun South, Beijing 100089, Peoples R China.
   [Shaheen, Momina] Univ Roehampton, Sch Arts, London SW15 5PJ, England.
   [Muneeb, Sara] COMSATS Univ Islamabad, Dept Comp Sci, Lahore Campus,Def Rd, Lahore 54000, Punjab, Pakistan.
   [Riasat, Rubata] Women Univ Swabi, Dept Comp Sci, Swabi 23430, Pakistan.
C3 Cardiff Metropolitan University; Chinese Academy of Sciences; Institute
   of Software, CAS; Roehampton University; COMSATS University Islamabad
   (CUI)
RP Ahmad, F (corresponding author), Cardiff Metropolitan Univ, Cardiff Sch Technol, Llandaff Campus, Cardiff CF5 2YB, Wales.
EM fahmad@cardiffmet.ac.uk; zeeshan_mscs@mails.ucas.ac.cn;
   momina.shaheen@roehampton.ac.uk; sara.muneeb@cuilahore.edu.pk;
   rubata.riasat@wus.edu.pk
RI Shaheen, Momina/HJB-3469-2022
OI Shaheen, Momina/0000-0001-9424-9787; Ahmad, Dr.
   Faizan/0000-0003-0595-5343
CR Achtman RL, 2008, RESTOR NEUROL NEUROS, V26, P435
   Ahmad F, 2023, INTERACT LEARN ENVIR, V31, P1265, DOI 10.1080/10494820.2020.1827440
   Ahmad F, 2021, INT J GAME-BASED LEA, V11, P67, DOI 10.4018/IJGBL.2021010105
   Ahmad F, 2017, J EXP THEOR ARTIF IN, V29, P1311, DOI 10.1080/0952813X.2017.1354079
   Aison C., 2002, APPEAL INTEREST VIDE
   [Anonymous], 1999, Psychology of intelligence analysis
   [Anonymous], 2016, ELEVATE YOUR PERS BR
   [Anonymous], 2016, FIT BRAINS ROS STON
   Basak C, 2008, PSYCHOL AGING, V23, P765, DOI 10.1037/a0013494
   Belchior P, 2013, COMPUT HUM BEHAV, V29, P1318, DOI 10.1016/j.chb.2013.01.034
   Bennett GK., 1947, DIFFERENTIAL APTITUD
   Brown DJ, 2009, J ASSIST TECHNOL, V3, P13, DOI 10.1108/17549450200900012
   Byun S, 2011, CCIS, P354, DOI DOI 10.1007/978-3-642-22098-2_71
   Castel AD, 2005, ACTA PSYCHOL, V119, P217, DOI 10.1016/j.actpsy.2005.02.004
   Cecilia SL., 2014, COMMUN COMPUT PHYS, V435, P371, DOI DOI 10.1007/978-3-319-07854-0
   Chang C., 2011, HEALTHCARE SYSTEMS E, V173, P358
   Chen JY, 2019, COMPUT HUM BEHAV, V90, P204, DOI 10.1016/j.chb.2018.08.057
   Chuang TY, 2007, DIGITEL 2007: The First IEEE International Workshop on Digital Game and Intelligent Toy Enhanced Learning, Proceedings, P114
   Clark K, 2011, ACTA PSYCHOL, V136, P67, DOI 10.1016/j.actpsy.2010.10.003
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   Cohen J., 1988, STAT POWER ANAL BEHA
   Colzato LS, 2013, PSYCHOL RES-PSYCH FO, V77, P234, DOI 10.1007/s00426-012-0415-2
   Colzato LS, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00008
   Connors EC, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00223
   Dang J, 2014, ARCH PSYCHIAT NURS, V28, P197, DOI 10.1016/j.apnu.2014.01.003
   de la Guía E, 2015, BRIT J EDUC TECHNOL, V46, P664, DOI 10.1111/bjet.12165
   Dobrowolski P, 2015, COMPUT HUM BEHAV, V44, P59, DOI 10.1016/j.chb.2014.11.051
   Donohue SE, 2010, ATTEN PERCEPT PSYCHO, V72, P1120, DOI 10.3758/APP.72.4.1120
   DORVAL M, 1986, PERCEPT MOTOR SKILL, V62, P159, DOI 10.2466/pms.1986.62.1.159
   Drew B., 1986, COGN REHABIL, V4, P26
   Durlach PJ, 2009, MIL PSYCHOL, V21, P24, DOI 10.1080/08995600802565694
   DUSTMAN RE, 1992, J GERONTOL, V47, pP168, DOI 10.1093/geronj/47.3.P168
   Dye MWG, 2009, NEUROPSYCHOLOGIA, V47, P1780, DOI 10.1016/j.neuropsychologia.2009.02.002
   Dye MWG, 2009, CURR DIR PSYCHOL SCI, V18, P321, DOI 10.1111/j.1467-8721.2009.01660.x
   Eggermont S., 2006, Poiesis Praxis, V4, P199, DOI DOI 10.1007/S10202-005-0017-9
   Esteban-Cornejo I, 2015, J SCI MED SPORT, V18, P534, DOI 10.1016/j.jsams.2014.07.007
   Faizan A., 2016, LECT NOTES COMPUT SC
   Gaggi O, 2017, COMPUT ENTERTAIN, V15, DOI 10.1145/2629558
   Glass BD, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0070350
   Green CS, 2007, PSYCHOL SCI, V18, P88, DOI 10.1111/j.1467-9280.2007.01853.x
   Green CS, 2006, COGNITION, V101, P217, DOI 10.1016/j.cognition.2005.10.004
   Green CS, 2006, J EXP PSYCHOL HUMAN, V32, P1465, DOI 10.1037/0096-1523.32.6.1465
   Green CS, 2010, CURR BIOL, V20, P1573, DOI 10.1016/j.cub.2010.07.040
   Greenfield P.M., 1996, Interacting with video, P187
   Hubert-Wallander B, 2011, WIRES COGN SCI, V2, P222, DOI 10.1002/wcs.116
   IJsselsteijn W., 2007, P 2007 C FUTURE PLAY, P17, DOI [DOI 10.1145/1328202.1328206, 10.1145/1328202.1328206]
   JiHoon Jeon, 2017, 2017 IEEE Conference on Computational Intelligence and Games (CIG), P150, DOI 10.1109/CIG.2017.8080428
   Joshi V, 2016, 2016 3RD IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL AND HEALTH INFORMATICS, P521, DOI 10.1109/BHI.2016.7455949
   Khowaja K, 2019, INT J HUM-COMPUT INT, V35, P1, DOI 10.1080/10447318.2017.1420006
   Koops MC, 2008, DIGITAL ADVENTURE GA
   Kueider AM, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040588
   Li RJ, 2010, J VISION, V10, DOI 10.1167/10.14.33
   Li RJ, 2009, NAT NEUROSCI, V12, P549, DOI 10.1038/nn.2296
   Linehan C., 2014, CHI 14 HUM FACT COMP, VISBN: 978-1-4503-2474-8, P1207
   Lowery B. R., 1982, Journal of Educational Technology Systems, V11, P155, DOI 10.2190/3PAN-CHJM-RT0L-W6AC
   Luck S.J., 2007, SCHOLARPEDIA, V2, P3328, DOI DOI 10.4249/SCHOLARPEDIA.3328
   Lumosity, 2016, US
   Luna-Oliva L, 2013, NEUROREHABILITATION, V33, P513, DOI 10.3233/NRE-131001
   Maillot P, 2012, PSYCHOL AGING, V27, P589, DOI 10.1037/a0026268
   Matsushima, 2014, COMMUN COMPUT PHYS, V435, P361, DOI [DOI 10.1007/978-3-319-07854-0, DOI 10.1007/978-3-319-07854-0_63]
   MCCLURG PA, 1987, J EDUC COMPUT RES, V3, P95, DOI 10.2190/9N5U-P3E9-R1X8-0RQM
   McDermott AF, 2014, COMPUT HUM BEHAV, V34, P69, DOI 10.1016/j.chb.2014.01.018
   Melenhorst AS, 2002, THESIS TU EINDHOVEN
   Miller KJ, 2005, PEDIATR ANN, V34, P310, DOI 10.1146/annurev-psych-113011-143750
   Montani V, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00409
   Navarro J, 2013, AMB INTELL SMART ENV, V17, P116, DOI 10.3233/978-1-61499-286-8-116
   Nishiguchi S, 2015, J CLIN GERONTOL GERI, V6, P9, DOI 10.1016/j.jcgg.2014.08.003
   Oei AC, 2014, COMPUT HUM BEHAV, V37, P216, DOI 10.1016/j.chb.2014.04.046
   Oei AC, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0058546
   Okagaki L., 1994, Journal of Applied Developmental Psychology, V15, P33, DOI DOI 10.1016/0193-3973(94)90005-1
   Pearce C., 2008, Games and Culture: A Journal of Interactive Media, V3, P142, DOI [DOI 10.1177/1555412008314132, 10.1177/1555412008314132]
   Plowman L, 2004, COMPUTER, V37, P98, DOI 10.1109/MC.2004.1266302
   Prensky M., 2001, HORIZON, V9, P1, DOI [10.1108/10748120110424816, DOI 10.1108/10748120110424816, 10.1108/10748120110424843]
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   Roschelle JM, 2000, FUTURE CHILD, V10, P76, DOI 10.2307/1602690
   Ruiz JR, 2010, J PEDIATR-US, V157, P917, DOI 10.1016/j.jpeds.2010.06.026
   Ruiz-Ariza A, 2017, INT REV SPORT EXER P, V10, P108, DOI 10.1080/1750984X.2016.1184699
   Serences JT, 2006, TRENDS COGN SCI, V10, P38, DOI 10.1016/j.tics.2005.11.008
   Strobach T, 2012, ACTA PSYCHOL, V140, P13, DOI 10.1016/j.actpsy.2012.02.001
   Subrahmanyam K., 1994, J APPL DEV PSYCHOL, V15, P13, DOI [DOI 10.1016/0193-3973(94)90004-3, 10.1016/0193-3973(94)90004-3]
   Tanabe A, 2009, BEHAV RES METHODS, V41, P309, DOI 10.3758/BRM.41.2.309
   Tarling A, 2005, THESIS U SESSEX
   Tong T, 2014, PROCEEDINGS OF CHINESE CHI 2014: SECOND INTERNATIONAL SYMPOSIUM OF CHINESE CHI (CHINESE CHI 2014), P70, DOI 10.1145/2592235.2592246
   Wang R, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P3, DOI 10.1145/2632048.2632054
   Williams JM, 1991, INT J ENG EDUC, V199
   Wilms IL, 2013, ACTA PSYCHOL, V142, P108, DOI 10.1016/j.actpsy.2012.11.003
   Yuji H, 1996, PERCEPT MOTOR SKILL, V83, P643, DOI 10.2466/pms.1996.83.2.643
NR 87
TC 3
Z9 3
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 41323
EP 41341
DI 10.1007/s11042-023-15100-x
EA APR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000967652700001
OA hybrid
DA 2024-07-18
ER

PT J
AU Shoka, AAE
   Dessouky, MM
   El-Sayed, A
   Hemdan, EE
AF Ein Shoka, Athar A. A.
   Dessouky, Mohamed M. M.
   El-Sayed, Ayman
   Hemdan, Ezz El-Din
TI EEG seizure detection: concepts, techniques, challenges, and future
   trends
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Epilepsy; Electroencephalography (EEG); Features extraction;
   Classification; Artificial intelligence; IoT
ID AUTOMATIC EPILEPSY DETECTION; NEURAL-NETWORKS; SIGNALS; CLASSIFICATION;
   DIAGNOSIS; PREDICTION; TRANSFORMS; ENTROPY; MODEL
AB A central nervous system disorder is usually referred to as epilepsy. In epilepsy brain activity becomes abnormal, leading to times of abnormal behavior or seizures, and at times loss of awareness. Consequently, epilepsy patients face problems in daily life due to precautions they must take to adapt to this condition, particularly when they use heavy equipment, e.g., vehicle derivation. Epilepsy studies rely primarily on electroencephalography (EEG) signals to evaluate brain activity during seizures. It is troublesome and time-consuming to manually decide the location of seizures in EEG signals. The automatic detection framework is one of the principal tools to help doctors and patients take appropriate precautions. This paper reviews the epilepsy mentality disorder and the types of seizure, preprocessing operations that are performed on EEG data, a generally extracted feature from the signal, and a detailed view on classification procedures used in this problem and provide insights on the difficulties and future research directions in this innovative theme. Therefore, this paper presents a review of work on recent methods for the epileptic seizure process along with providing perspectives and concepts to researchers to present an automated EEG-based epileptic seizure detection system using IoT and machine learning classifiers for remote patient monitoring in the context of smart healthcare systems. Finally, challenges and open research points in EEG seizure detection are investigated.
C1 [Ein Shoka, Athar A. A.; Dessouky, Mohamed M. M.; El-Sayed, Ayman; Hemdan, Ezz El-Din] Menoufia Univ, Fac Elect Engn, Comp Sci & Engn Dept, Menoufia, Egypt.
   [Dessouky, Mohamed M. M.] Univ Jeddah, Coll Comp Sci & Engn, Dept Comp Sci & Artificial Intelligence, Jeddah, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Menofia University; University of Jeddah
RP Shoka, AAE (corresponding author), Menoufia Univ, Fac Elect Engn, Comp Sci & Engn Dept, Menoufia, Egypt.
EM atharali@el-eng.menofia.edu.eg; mohamed.moawad@el-eng.menofia.edu.eg;
   ayman.elsayed@el-eng.menofia.edu.eg; ezzvip@yahoo.com
RI EL-SAYED, Ayman E./AFM-8547-2022
OI EL-SAYED, Ayman E./0000-0002-4437-259X
CR Aayesha, 2021, MULTIMED TOOLS APPL, V80, P17849, DOI 10.1007/s11042-021-10597-6
   Abdelhameed A, 2021, FRONT COMPUT NEUROSC, V15, DOI 10.3389/fncom.2021.650050
   Abu Sayeed M, 2018, 2018 IEEE 4TH INTERNATIONAL SYMPOSIUM ON SMART ELECTRONIC SYSTEMS (ISES 2018), P156, DOI 10.1109/iSES.2018.00042
   Abualsaud K, 2018, INT WIREL COMMUN, P364, DOI 10.1109/IWCMC.2018.8450279
   Acharya UR, 2019, FUTURE GENER COMP SY, V91, P290, DOI 10.1016/j.future.2018.08.044
   Acharya UR, 2015, KNOWL-BASED SYST, V88, P85, DOI 10.1016/j.knosys.2015.08.004
   Achilles F, 2018, COMP M BIO BIO E-IV, V6, P264, DOI 10.1080/21681163.2016.1141062
   Ahammad N, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/450573
   Ahmad I, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/6486570
   Aileni RM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123346
   Akut R, 2019, HEALTH INF SCI SYST, V7, DOI 10.1007/s13755-019-0069-1
   Alam SMS, 2013, IEEE J BIOMED HEALTH, V17, P312, DOI 10.1109/JBHI.2012.2237409
   Alhussein M, 2019, IEEE ACCESS, V7, P27781, DOI 10.1109/ACCESS.2019.2901672
   Almustafa KM., 2020, Inf. Med. Unlocked, V2, P1, DOI DOI 10.1016/J.IMU.2020.100444
   Alotaibi SM, 2021, CMC-COMPUT MATER CON, V68, P149, DOI 10.32604/cmc.2021.015976
   Alotaiby TN, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-183
   [Anonymous], 2015, INT J COMPUT SCI INF
   [Anonymous], 2016, 2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)
   [Anonymous], 2018, 2018 6th International Conference on Brain-Computer Interface, DOI [DOI 10.1109/IWW-BCI.2018.8311530, 10.1109/IWW-BCI.2018.8311530, DOI 10.1109/GLOCOM.2018.8647521]
   Bashashati A, 2007, J NEURAL ENG, V4, pR32, DOI 10.1088/1741-2560/4/2/R03
   Ben Slimen I, 2020, J BIOMED RES, V34, P162, DOI 10.7555/JBR.34.20190097
   Bhattacharyya A, 2018, NEURAL COMPUT APPL, V29, P47, DOI 10.1007/s00521-016-2646-4
   Bose R, 2019, IET SIGNAL PROCESS, V13, P157, DOI 10.1049/iet-spr.2018.5258
   Chen GY, 2017, J MED BIOL ENG, V37, P123, DOI 10.1007/s40846-016-0214-0
   Cho KO, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-56958-y
   Choudhury NR, 2018, 2018 FOURTH IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P70, DOI 10.1109/ICRCICN.2018.8718687
   Cura OK, 2020, BIOMED ENG ONLINE, V19, DOI 10.1186/s12938-020-0754-y
   Daoud H, 2020, 2020 IEEE 6TH WORLD FORUM ON INTERNET OF THINGS (WF-IOT)
   De Cooman T, 2018, SEIZURE-EUR J EPILEP, V59, P48, DOI 10.1016/j.seizure.2018.04.020
   Dhif I, 2017, EPILEPTIC SEIZURE DE, P2814
   Diykh M, 2017, EXPERT SYST APPL, V90, P87, DOI 10.1016/j.eswa.2017.08.012
   Durai S., 2017, ASIAN J RES SOC SCI, V7, P1230, DOI [10.5958/2249-7315.2017.00239.8, DOI 10.5958/2249-7315.2017.00239.8]
   Ein Shoka Athar A, 2021, Brain Inform, V8, P1, DOI 10.1186/s40708-021-00123-7
   Elgohary S., 2016, 2016 IEEE C COMP INT, P1
   Fasil OK, 2019, NEUROSCI LETT, V694, P1, DOI 10.1016/j.neulet.2018.10.062
   Feng B, 2018, INT CONF SOFTW ENG, P382, DOI 10.1109/ICSESS.2018.8663773
   Gajic D, 2014, BIOMED ENG-APP BAS C, V26, DOI 10.4015/S1016237214500215
   Gao YY, 2020, FRONT NEUROL, V11, DOI 10.3389/fneur.2020.00375
   Correa AG, 2019, J MED BIOL ENG, V39, P912, DOI 10.1007/s40846-019-00467-w
   Ghayab Hadi Ratham Al, 2016, Brain Inform, V3, P85, DOI 10.1007/s40708-016-0039-1
   Gill Ammama Furrukh, 2014, 2014 IEEE Symposium on Industrial Electronics & Applications (ISIEA), P32, DOI 10.1109/ISIEA.2014.8049867
   Giourou E, 2015, INTRO EPILEPSY RELAT, P11
   Gogna A, 2017, IEEE T BIO-MED ENG, V64, P2196, DOI 10.1109/TBME.2016.2631620
   Gómez C, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-78784-3
   Gupta V, 2018, IEEE INT C BIOINFORM, P2597, DOI 10.1109/BIBM.2018.8621311
   Hussain W, 2021, APPL ACOUST, V177, DOI 10.1016/j.apacoust.2021.107941
   Hussein R, 2019, CLIN NEUROPHYSIOL, V130, P25, DOI 10.1016/j.clinph.2018.10.010
   Ibrahim F, 2019, INT J SPEECH TECHNOL, V22, P191, DOI 10.1007/s10772-018-09565-7
   Iftikhar M, 2018, 2018 IEEE 9TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P395, DOI 10.1109/IEMCON.2018.8614893
   Ilakiyaselvan N, 2020, J BIOMED RES, V34, P240, DOI 10.7555/JBR.34.20190043
   Islam MS, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030728
   Jaiswal AK, 2018, AUSTRALAS PHYS ENG S, V41, P81, DOI 10.1007/s13246-017-0610-y
   Jang HJ, 2019, KOREAN J PHYSIOL PHA, V23, P131, DOI 10.4196/kjpp.2019.23.2.131
   Jiang X, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19050987
   Jindal K, 2018, INT C ULTRA MOD TELE
   Khalid MI, 2016, IEEE ACCESS, V4, P4629, DOI 10.1109/ACCESS.2016.2602354
   Kocadagli O, 2017, EXPERT SYST APPL, V88, P419, DOI 10.1016/j.eswa.2017.07.020
   Kumar Y, 2014, NEUROCOMPUTING, V133, P271, DOI 10.1016/j.neucom.2013.11.009
   Lahmiri S, 2019, IEEE T INSTRUM MEAS, V68, P791, DOI 10.1109/TIM.2018.2855518
   Lakshmi M.R., 2014, Int. J. Adv. Res. Comput. Sci. Softw. Eng, V4
   Li FL, 2019, COGN NEURODYNAMICS, V13, P175, DOI 10.1007/s11571-018-09517-6
   Li MY, 2018, BIOMED SIGNAL PROCES, V41, P233, DOI 10.1016/j.bspc.2017.12.005
   Li MY, 2017, BIOCYBERN BIOMED ENG, V37, P679, DOI 10.1016/j.bbe.2017.08.003
   Li MY, 2016, BIOCYBERN BIOMED ENG, V36, P708, DOI 10.1016/j.bbe.2016.07.004
   Li P, 2016, FRONT PHYSIOL, V7, DOI 10.3389/fphys.2016.00136
   Li Y, 2018, INT J NEURAL SYST, V28, DOI 10.1142/S012906571850003X
   Liu H., 2019, Mach. Learn. Res., V4, P39, DOI DOI 10.11648/J.MLR.20190403.11
   M NR., 2019, BRIT J SURG, V6, P123
   Mahjoub C, 2020, BIOMED ENG-BIOMED TE, V65, P33, DOI 10.1515/bmt-2019-0001
   McHale SA, 2017, 2017 14TH INTERNATIONAL SYMPOSIUM ON PERVASIVE SYSTEMS, ALGORITHMS AND NETWORKS & 2017 11TH INTERNATIONAL CONFERENCE ON FRONTIER OF COMPUTER SCIENCE AND TECHNOLOGY & 2017 THIRD INTERNATIONAL SYMPOSIUM OF CREATIVE COMPUTING (ISPAN-FCST-ISCC), P414, DOI 10.1109/ISPAN-FCST-ISCC.2017.34
   Mohammadpoory Z, 2019, COGN NEURODYNAMICS, V13, P325, DOI 10.1007/s11571-019-09527-y
   Mohammadpoory Z, 2017, SEIZURE-EUR J EPILEP, V50, P202, DOI 10.1016/j.seizure.2017.07.001
   Muhammad G, 2018, IEEE ACCESS, V6, P45372, DOI 10.1109/ACCESS.2018.2859267
   Mursalin M, 2017, NEUROCOMPUTING, V241, P204, DOI 10.1016/j.neucom.2017.02.053
   Nielsen JM, 2022, CLIN NEUROPHYSIOL, V136, P40, DOI 10.1016/j.clinph.2022.01.005
   Nkengfack LCD., 2021, INFORM MED UNLOCKED, V23, DOI [10.1016/j.imu.2021.100536, DOI 10.1016/J.IMU.2021.100536]
   Nogay HS, 2021, EUR NEUROL, V83, P602, DOI 10.1159/000512985
   Osman AH, 2019, IEEE ACCESS, V7, P4741, DOI 10.1109/ACCESS.2018.2886608
   Park C., 2018, P INT C EL INF COMM, P1, DOI DOI 10.23919/ELINFOCOM.2018.8330671
   Parvez MZ, 2017, IEEE T BIO-MED ENG, V64, P208, DOI 10.1109/TBME.2016.2553131
   Patidar S, 2017, BIOMED SIGNAL PROCES, V34, P74, DOI 10.1016/j.bspc.2017.01.001
   Peachap A B., 2019, Informatics in Medicine Unlocked, V16, P100209, DOI DOI 10.1016/J.IMU.2019.100209
   Peker M, 2016, IEEE J BIOMED HEALTH, V20, P108, DOI 10.1109/JBHI.2014.2387795
   Pippa E, 2016, NEUROCOMPUTING, V171, P576, DOI 10.1016/j.neucom.2015.06.071
   Pisano F, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/4825767
   Prabhakar SK, 2017, INT WINT WORKSH BR, P81, DOI 10.1109/IWW-BCI.2017.7858166
   Qi Y, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/703816
   Raghu S, 2019, COMPUT BIOL MED, V110, P127, DOI 10.1016/j.compbiomed.2019.05.016
   Rajaei H, 2016, IEEE ENG MED BIO, P1018, DOI 10.1109/EMBC.2016.7590875
   Rajaguru H, 2017, 2017 INTERNATIONAL CONFERENCE OF ELECTRONICS, COMMUNICATION AND AEROSPACE TECHNOLOGY (ICECA), VOL 1, P581, DOI 10.1109/ICECA.2017.8203604
   Rajaguru H, 2017, 2017 INTERNATIONAL CONFERENCE OF ELECTRONICS, COMMUNICATION AND AEROSPACE TECHNOLOGY (ICECA), VOL 1, P577, DOI 10.1109/ICECA.2017.8203602
   Rajaguru H, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/813197
   Rizzo C., 2019, EEG SIGNAL ACQUISITI, P53, DOI [10.1007/978-3-030-04573-9_5, DOI 10.1007/978-3-030-04573-9_5]
   Rukasha T, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060968
   Sai CY, 2018, IEEE J BIOMED HEALTH, V22, P664, DOI 10.1109/JBHI.2017.2723420
   Samie F, 2018, DES AUT TEST EUROPE, P955, DOI 10.23919/DATE.2018.8342147
   Saminu S, 2019, INT CONF ELECT COMP, DOI 10.1109/icecco48375.2019.9043241
   San-Segundo R, 2019, COMPUT BIOL MED, V109, P148, DOI 10.1016/j.compbiomed.2019.04.031
   Sareen S, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0579-1
   Sharanreddy, 2013, INT J PUBLIC HLTH SC, V2, P23, DOI [DOI 10.11591/ijphs.v2i1.1836, DOI 10.11591/IJPHS.V2I1.1836]
   Sharma M, 2018, KNOWL-BASED SYST, V160, P265, DOI 10.1016/j.knosys.2018.07.019
   Sharma M, 2017, J MECH MED BIOL, V17, DOI 10.1142/S0219519417400036
   Sharmila A., 2018, Journal of Medical Engineering & Technology, V42, P368, DOI 10.1080/03091902.2018.1513576
   Sharmila A, 2016, IEEE ACCESS, V4, P7716, DOI 10.1109/ACCESS.2016.2585661
   Sheela P, 2020, J NEUROSCI METH, V336, DOI 10.1016/j.jneumeth.2020.108638
   Shoeibi A, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18115780
   Shoka A., 2019, Menoufia J. Electron. Eng. Res., V28, P292, DOI 10.21608/mjeer.2019.64927
   Siddiqui MK, 2019, NEURAL COMPUT APPL, V31, P5595, DOI 10.1007/s00521-018-3381-9
   Singh G., 2015, 2 INT C REC ADV ENG, P1, DOI [10.1109/RAECS.2015.7453376, DOI 10.1109/RAECS.2015.7453376]
   Singh K, 2020, J RELIG HEALTH, V59, P2753, DOI 10.1007/s10943-019-00877-9
   Sriraam N, 2018, AUSTRALAS PHYS ENG S, V41, P1047, DOI 10.1007/s13246-018-0694-z
   Stevens GC, 2018, 2018 IEEE 2ND INTERNATIONAL CONFERENCE ON DIELECTRICS (ICD)
   Stevenson NJ, 2019, SCI DATA, V6, DOI 10.1038/sdata.2019.39
   Subasi A, 2005, EXPERT SYST APPL, V29, P343, DOI 10.1016/j.eswa.2005.04.007
   Sudalaimani C, 2019, BIOCYBERN BIOMED ENG, V39, P160, DOI 10.1016/j.bbe.2018.11.007
   Supriya S, 2016, ELECTRON LETT, V52, P1430, DOI 10.1049/el.2016.1992
   Tanveer M, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P1946, DOI 10.1109/SSCI.2018.8628733
   Tanveer M, 2018, ADV INTELL SYST, V748
   Thara DK, 2021, EVOL INTELL, V14, P823, DOI 10.1007/s12065-020-00459-9
   Thara DK, 2019, PATTERN RECOGN LETT, V128, P544, DOI 10.1016/j.patrec.2019.10.029
   Thodoroff P, 2016, ARXIV
   Tiwari AK, 2017, IEEE J BIOMED HEALTH, V21, P888, DOI 10.1109/JBHI.2016.2589971
   Tjepkema-Cloostermans MC, 2018, CLIN NEUROPHYSIOL, V129, P2191, DOI 10.1016/j.clinph.2018.06.024
   Torse Dattaprasad A., 2019, Proceedings of the 2nd International Conference on Data Engineering and Communication Technology (ICDECT 2017). Advances in Intelligent Systems and Computing (AISC 828), P87, DOI 10.1007/978-981-13-1610-4_9
   Torse D, 2017, BRAIN-BROAD RES ARTI, V8, P109
   Tsiouris KM, 2019, 2019 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), DOI 10.1109/bhi.2019.8834644
   Tsipouras M, 2019, EURASIP J ADV SIG PR, DOI 10.1186/s13634-019-0606-8
   Tzimourta KD, 2019, HEALTH TECHNOL-GER, V9, P135, DOI 10.1007/s12553-018-0265-z
   Ullah I, 2018, EXPERT SYST APPL, V107, P61, DOI 10.1016/j.eswa.2018.04.021
   Upadhyay R, 2016, COMPUT ELECTR ENG, V53, P163, DOI 10.1016/j.compeleceng.2016.05.016
   Vandecasteele K, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102338
   Vergara PM, 2017, J SENSORS, V2017, DOI 10.1155/2017/6043069
   Wang G, 2018, IEEE ACCESS, V6, P47189, DOI 10.1109/ACCESS.2018.2867008
   Wang S, 2015, INT J SIGNAL PROCESS
   Wang XS, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020219
   Wei XY, 2018, BMC MED INFORM DECIS, V18, DOI 10.1186/s12911-018-0693-8
   Yayik A., 2015, INT J INTELL SYST, V3, P14, DOI [DOI 10.18201/IJISAE.14531, 10.18201/ijisae.14531]
   Yildiz M, 2017, BIOMED RES-INDIA, V28, P858
   Yol S, 2018, 2018 MEDICAL TECHNOLOGIES NATIONAL CONGRESS (TIPTEKNO)
   Yuan Y, 2019, IEEE J BIOMED HEALTH, V23, P83, DOI 10.1109/JBHI.2018.2871678
   Yuan Y, 2017, ACM-BCB' 2017: PROCEEDINGS OF THE 8TH ACM INTERNATIONAL CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY,AND HEALTH INFORMATICS, P213, DOI 10.1145/3107411.3107419
   Yuvaraj R, 2018, CONF REC ASILOMAR C, P368, DOI 10.1109/ACSSC.2018.8645301
   Zabihi M., 2013, IET Intell. Signal Process. Conf, V2013, P1, DOI 10.1049/cp.2013.2060
   Asmat Z, 2017, COMPUT BIOL MED, V88, P132, DOI 10.1016/j.compbiomed.2017.07.010
   Zazzaro GETO, 2022, BIOMEDICINES, V10, DOI 10.3390/biomedicines10071491
   Zhang GK, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00870
   Zhao W, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/9689821
   Zhou DM, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00606
   Zhou MN, 2018, FRONT NEUROINFORM, V12, DOI 10.3389/fninf.2018.00095
NR 149
TC 10
Z9 10
U1 10
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42021
EP 42051
DI 10.1007/s11042-023-15052-2
EA APR 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000983404900004
PM 37362745
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Jawad, MA
   Khursheed, F
AF Jawad, M. Abdul
   Khursheed, Farida
TI Histo-fusion: a novel domain specific learning to identify invasive
   ductal carcinoma (IDC) from histopathological images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast Cancer; Invasive ductal carcinoma; Transfer learning;
   Histopathological images; Domain specific learning
ID TEXTURE CLASSIFICATION; SCREENING MAMMOGRAPHY; BREAST
AB On the global level, Invasive Ductal Carcinoma (IDC) is one of the leading malignancies among women undergoing breast cancer screening. A slight delay in detecting and diagnosing this disease may result in irreversible complications. Histopathological images obtained from a biopsy examination present enormous structural information, which helps significantly in improving the prognosis of the disease. Pathological analysis involving microscopic examination of the histopathological slides is a highly challenging task due to the limited abilities of conventional computer-aided detection (CAD) methods to reach a precise diagnosis. The problem has become more accentuated due to the less availability of medical data in the public domain. Lately, deep learning methods using artificial neural networks are being used consistently to improve the performance of these CAD methods. Despite less medical data availability, transfer learning has recently been commonly practised to facilitate a deep neural network to train on a specific dataset in resolving the problem. However, the performance of this method is not remarkably appreciable on small and low-resolution medical image datasets compared to those comprising whole slide images of higher resolutions. In this direction, this study proposes a domain-specific learning strategy, Histo-Fusion, with the objective of detecting the IDC more precisely. In the proposed method, the deep CNN model is initially trained on higher-resolution histopathological images of breast tissue which presents ample information for a model to learn the significant features for better discrimination between normal and malignant tissues. Subsequently, through a positive transfer of domain features, the model is further trained on the small and low-resolution images, enabling it to classify these histology images into IDC - and IDC + categories. Moreover, shallow and deep neural network architectures are utilized in the study to compare their performance across the two learning approaches: transfer learning and Histo-Fusion on the IDC dataset. As revealed by the present study results, the proposed Histo-Fusion learning approach has improved each deep CNN's discriminating abilities by yielding better accuracy scores of around 5% over and above those obtained by the commonly used transfer learning strategy. Therefore, the procedure is expected to reduce false-positive rates and help expert pathologists reach accurate diagnoses.
C1 [Jawad, M. Abdul; Khursheed, Farida] NIT Srinagar, Dept Elect & Commun Engn, Srinagar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Srinagar
RP Jawad, MA (corresponding author), NIT Srinagar, Dept Elect & Commun Engn, Srinagar, India.
EM jawad_03phd19@nitsri.ac.in; fklone@nitsri.ac.in
OI JAWAD, M ABDUL/0000-0002-5963-269X
CR Alanazi SA, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/5528622
   Alghodhaifi H, 2019, PROC NAECON IEEE NAT, P374, DOI [10.1109/naecon46414.2019.9057822, 10.1109/NAECON46414.2019.9057822]
   Alzubaidi L, 2021, CANCERS, V13, DOI 10.3390/cancers13071590
   Attallah O, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.493
   Attallah O, 2019, IEEE INT C COMPUT, P110, DOI 10.1109/CSE/EUC.2019.00030
   Barsha NA, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.104931
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chan A, 2016, ROY SOC OPEN SCI, V3, DOI 10.1098/rsos.160558
   Chapala H., 2020, P 2020 INT C ELECT S, P60, DOI DOI 10.1109/ICESC48915.2020.9155805
   Chen JT, 2021, IEEE ACM T COMPUT BI, V18, P103, DOI 10.1109/TCBB.2020.2991173
   Chen Z, 2016, CORRABS161207640
   Coelho LP, 2010, LECT N BIOINFORMAT, V6004, P23, DOI 10.1007/978-3-642-13131-8_4
   Cruz-Roa A, 2014, PROC SPIE, V9041, DOI 10.1117/12.2043872
   Elmore JG, 2009, RADIOLOGY, V253, P641, DOI 10.1148/radiol.2533082308
   Feig SA, 2014, RADIOL CLIN N AM, V52, P455, DOI 10.1016/j.rcl.2014.02.009
   Gao H, 2022, IEEE T NEURAL NET LE
   Gao HH, 2022, IEEE T COMPUT SOC SY, V9, P336, DOI 10.1109/TCSS.2021.3102591
   Hamidinekoo A, 2018, MED IMAGE ANAL, V47, P45, DOI 10.1016/j.media.2018.03.006
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hedjazi MA, 2017, SIG PROCESS COMMUN
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Janowczyk Andrew, 2016, J Pathol Inform, V7, P29, DOI 10.4103/2153-3539.186902
   Jawad MA, 2022, BIOMED SIGNAL PROCES, V78, DOI 10.1016/j.bspc.2022.103935
   Kowal M, 2013, COMPUT BIOL MED, V43, P1563, DOI 10.1016/j.compbiomed.2013.08.003
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lehman CD, 2015, JAMA INTERN MED, V175, P1828, DOI 10.1001/jamainternmed.2015.5231
   Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188
   Li Y, 2016, J. Health Med. Inform., V4, P1, DOI 10.4172/2157-7420.1000238
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Macenko M, 2009, I S BIOMED IMAGING, P1107, DOI 10.1109/ISBI.2009.5193250
   Mathur P, 2020, JCO GLOB ONCOL, V6, P1063, DOI 10.1200/GO.20.00122
   Nanni L, 2017, PATTERN RECOGN, V71, P158, DOI 10.1016/j.patcog.2017.05.025
   Narayanan BN, 2019, PROC NAECON IEEE NAT, P291, DOI [10.1109/naecon46414.2019.9058279, 10.1109/NAECON46414.2019.9058279]
   Neal L, 2010, MAYO CLIN PROC, V85, P274, DOI 10.4065/mcp.2009.0656
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Prokhorenkova L, 2018, ADV NEUR IN, V31
   Raghu M, 2019, ADV NEUR IN, V32
   Rahman MJU, 2018, TENCON IEEE REGION, P0673, DOI 10.1109/TENCON.2018.8650376
   Robboy SJ, 2013, ARCH PATHOL LAB MED, V137, P1723, DOI 10.5858/arpa.2013-0200-OA
   Romano AM, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA (ICAIBD 2019), P142, DOI [10.1109/icaibd.2019.8837044, 10.1109/ICAIBD.2019.8837044]
   Romero FP, 2019, I S BIOMED IMAGING, P1092, DOI 10.1109/isbi.2019.8759410
   Roy SD, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113628
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sharma S, 2020, J DIGIT IMAGING, V33, P632, DOI 10.1007/s10278-019-00307-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Tangudu N, 2021, INT J IMAG SYST TECH
   Tharwat A, 2016, INT J APPL PATTERN R, V3, P145, DOI 10.1504/IJAPR.2016.079050
   Veta M, 2014, IEEE T BIO-MED ENG, V61, P1400, DOI 10.1109/TBME.2014.2303852
   Wang J.L., 2018, 2018 INT C COMPUTATI, P703, DOI 10.1109/CSCI46756.2018.00141
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Welch HG, 2014, JAMA INTERN MED, V174, P448, DOI 10.1001/jamainternmed.2013.13635
   Xie JY, 2019, FRONT GENET, V10, DOI 10.3389/fgene.2019.00080
   Zhang W, 2022, IEEE CAA J AUTOM SIN
   Zhang XL, 2019, LECT N BIOINFORMAT, V11465, P204, DOI 10.1007/978-3-030-17938-0_19
NR 60
TC 2
Z9 2
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39371
EP 39392
DI 10.1007/s11042-023-15134-1
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000960423600007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Heydari, Z
   Mahabadi, A
AF Heydari, Zahra
   Mahabadi, Aminollah
TI Real-time TDOA-based stationary sound source direction finding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Acoustic; Sound source direction finding; Time difference of arrival;
   Krill Herd algorithm; Successive unconstrained minimization; Real-time
   cyber-physical system; Three-dimensional space
ID SOURCE LOCALIZATION; TRACKING
AB Performance improvement of sound source direction finding is a critical acoustic task in target localization, tracking, and navigation as an NP problem that suffers from sound reflection and noise in passive or active methods. The accuracy of prediction increases by integrating more information about the signal specification, source position, sensor attributes, microphone array topology, characteristics of hardware architecture, dimension of distance, the status of environmental sounds, climatic conditions, effects of signal propagation, properties of barriers, and setting of initial estimation which is time-consuming. This paper presents a scalable method of sound source direction finding based on the time-difference-of-arrival approach to improve the accuracy of predictions of three-dimensional space in an outdoor environment. The real-time passive process is robust to sound reflection and ambient noise that decreases the running-time and increases the accuracy significantly through complexity reduction by proposing a novel Krill Herd algorithm based on successive unconstrained minimization technique. Experimental results of different actual and simulated datasets show the angle error amounts of Azimuth and Elevation are 0.7164(circle) and 1.5054(circle) in the near-field, and are 1.0260(circle) and 0.2071(circle) in the far-field, respectively. Performance evaluation of the passive proposed process shows that higher accuracy can be reached by using more parallel distributed sensor arrays.
C1 [Heydari, Zahra; Mahabadi, Aminollah] Shahed Univ, Comp Engn Dept, Tehran, Iran.
   [Heydari, Zahra; Mahabadi, Aminollah] Shahed Univ, Acoust Res Ctr, Tehran, Iran.
   [Mahabadi, Aminollah] Inst Res Fundamental Sci IPM, Sch Comp Sci, Tehran, Iran.
C3 Shahed University; Shahed University
RP Mahabadi, A (corresponding author), Shahed Univ, Comp Engn Dept, Tehran, Iran.; Mahabadi, A (corresponding author), Shahed Univ, Acoust Res Ctr, Tehran, Iran.; Mahabadi, A (corresponding author), Inst Res Fundamental Sci IPM, Sch Comp Sci, Tehran, Iran.
EM mahabadi@shahed.ac.ir
CR Abiri A, 2020, IEEE SENS J, V20, P7253, DOI 10.1109/JSEN.2020.2978814
   Bai Y, 2020, COMPUT NETW, V181, DOI 10.1016/j.comnet.2020.107447
   Berdugo B, 1999, J ACOUST SOC AM, V105, P3355, DOI 10.1121/1.424664
   CHAN YT, 1994, IEEE T SIGNAL PROCES, V42, P1905, DOI 10.1109/78.301830
   Chen J, 2020, PARTICUL SCI TECHNOL, V38, P247, DOI 10.1080/02726351.2018.1504152
   Chen X, 2019, EURASIP J ADV SIG PR, DOI 10.1186/s13634-019-0602-z
   Cui XX, 2020, IEEE T INSTRUM MEAS, V69, P985, DOI 10.1109/TIM.2019.2908694
   Cui XX, 2018, IEEE SENS J, V18, P3360, DOI 10.1109/JSEN.2018.2803150
   Dang XD, 2022, IEEE-ACM T AUDIO SPE, V30, P1108, DOI 10.1109/TASLP.2022.3153251
   Fabregat G, 2020, IEEE T CIRCUITS-II, V67, P3547, DOI 10.1109/TCSII.2020.2986296
   Foy W. H., 1976, IEEE Transactions on Aerospace and Electronic Systems, VAES-12, P187, DOI 10.1109/TAES.1976.308294
   Gillette MD, 2008, IEEE SIGNAL PROC LET, V15, P1, DOI 10.1109/LSP.2007.910324
   Gombots S, 2021, ELEKTROTECH INFORMAT, V138, P229, DOI 10.1007/s00502-021-00881-6
   Grondin F, 2019, ROBOT AUTON SYST, V113, P63, DOI 10.1016/j.robot.2019.01.002
   Heydari Z., 2021, J ACOUSTICAL ENG SOC, V8, P13
   Heydari Z., 2021, CSI J COMPUT SCI INF, V19, P23
   Invernizzi D, 2021, IEEE T CONTR SYST T, V29, P1147, DOI 10.1109/TCST.2020.2992389
   Jahanshahi H, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8020201
   Jin BN, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030778
   Liu MN, 2020, HUM-CENTRIC COMPUT I, V10, DOI 10.1186/s13673-019-0207-4
   Manamperi W, 2022, IEEE-ACM T AUDIO SPE, V30, P508, DOI 10.1109/TASLP.2022.3140550
   Mirbeygi M., 2022, MULTIMED TOOLS APPL, V1, P1
   Mirbeygi M, 2021, SPEECH COMMUN, V126, P22, DOI 10.1016/j.specom.2020.12.003
   Seidel A, 2021, TELEMAT INFORM, V64, DOI 10.1016/j.tele.2021.101686
   Shi ZG, 2020, IEEE T VEH TECHNOL, V69, P2731, DOI 10.1109/TVT.2020.2964110
   SMITH JO, 1987, IEEE T ACOUST SPEECH, V35, P1661, DOI 10.1109/TASSP.1987.1165089
   Sudo Y, 2021, IEEE/SICE I S SYS IN, P382, DOI 10.1109/IEEECONF49454.2021.9382730
   Sun YM, 2019, IEEE T SIGNAL PROCES, V67, P320, DOI 10.1109/TSP.2018.2879622
   Wu P, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112554
   Yan Peng, 2021, Journal of Physics: Conference Series, V1952, DOI 10.1088/1742-6596/1952/4/042052
   Yan T, 2018, ZTDOA TIME DELAY EST
   Zhou ZL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123553
   Zou YB, 2020, INT CONF ACOUST SPEE, P4881, DOI [10.1109/icassp40776.2020.9053746, 10.1109/ICASSP40776.2020.9053746]
NR 33
TC 1
Z9 1
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 39929
EP 39960
DI 10.1007/s11042-023-14741-2
EA MAR 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000955293100008
DA 2024-07-18
ER

PT J
AU Torse, DA
   Khanai, R
   Pai, K
   Iyer, S
   Mavinkattimath, S
   Kallimani, R
   Shahpur, S
AF Torse, Dattaprasad A.
   Khanai, Rajashri
   Pai, Krishna
   Iyer, Sridhar
   Mavinkattimath, Swati
   Kallimani, Rakhee
   Shahpur, Salma
TI Optimal feature selection for COVID-19 detection with CT images enabled
   by metaheuristic optimization and artificial intelligence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Metaheuristic; Optimal feature selection; Convolutional neural
   networks; Artificial intelligence
ID IMPROVE
AB There is a broad range of novel Coronaviruses (CoV) such as the common cold, cough, and severe lung infections. The mutation of this virus, which originally started as COVID-19 in Wuhan, China, has continued the rapid spread globally. As the mutated form of this virus spreads across the world, testing and screening procedures of patients have become tedious for healthcare departments in largely populated countries such as India. To diagnose COVID-19 pneumonia by radiological methods, high-resolution computed tomography (CT) of the chest has been considered the most precise method of examination. The use of modern artificial intelligence (AI) techniques on chest high-resolution computed tomography (HRCT) images can help to detect the disease, especially in remote areas with a lack of specialized physicians. This article presents a novel metaheuristic algorithm for automatic COVID-19 detection using a least square support vector machine (LSSVM) classifier for three classes namely normal, COVID, and pneumonia. The proposed model results in a classification accuracy of 87.2% and an F1-score of 86.3% for multiclass classifications from simulations. The analysis of information transfer rate (ITR) revealed that the modified quantum-based marine predators algorithm (Mq-MPA) feature selection algorithm reduces the classification time of LSSVM by 23% when compared to the deep learning models.
C1 [Torse, Dattaprasad A.; Pai, Krishna; Iyer, Sridhar; Mavinkattimath, Swati] KLE Dr MS Sheshgiri Coll Engn & Technol, Dept ECE, Belagavi 590008, KA, India.
   [Khanai, Rajashri] KLE Dr MS Sheshgiri Coll Engn & Technol, Dept CSE, Belagavi 590008, KA, India.
   [Kallimani, Rakhee] KLE Dr MS Sheshgiri Coll Engn & Technol, Dept EEE, Belagavi 590008, KA, India.
   [Shahpur, Salma] Jain Coll Engn, Dept ECE, Belagavi 590008, KA, India.
RP Torse, DA (corresponding author), KLE Dr MS Sheshgiri Coll Engn & Technol, Dept ECE, Belagavi 590008, KA, India.
EM datorse@klescet.ac.in; rajashrikhanai@klescet.ac.in;
   krishnapai271999@gmail.com; sridhariyer1983@klescet.ac.in;
   swatisgm@gmail.com; rakhee.kallimani@klescet.ac.in; salma.jce@gmail.com
RI PAI, KRISHNA/AFL-7466-2022; Iyer, Sridhar/AAE-6849-2020; mavinkattimath,
   swati/AAR-6279-2020; Torse, Dattaprasad/A-7500-2019
OI PAI, KRISHNA/0000-0003-0972-3275; Iyer, Sridhar/0000-0002-8466-3316;
   mavinkattimath, swati/0000-0002-3997-2937; Kallimani, Dr.
   Rakhee/0000-0003-0790-024X; Torse, Dattaprasad/0000-0002-2101-487X
CR Abd Elaziz M, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107598
   Ahuja S, 2021, APPL INTELL, V51, P571, DOI 10.1007/s10489-020-01826-w
   Allwein E. L., 2001, Journal of Machine Learning Research, V1, P113, DOI 10.1162/15324430152733133
   Arpaci I, 2021, MULTIMED TOOLS APPL, V80, P11943, DOI 10.1007/s11042-020-10340-7
   Bahel V, 2020, BIG DATA ANALYTICS A, P117, DOI [10.1007/978-3-030-55258-9_7, DOI 10.1007/978-3-030-55258-9_7]
   Bannigidad P, 2019, EXUDATES DETECTION D, P245, DOI [10.1007/978-981-13-9184-2_22, DOI 10.1007/978-981-13-9184-2_22]
   Bhargava A, 2021, MULTIMED TOOLS APPL, V80, P19931, DOI 10.1007/s11042-021-10714-5
   Caponetto R, 2003, IEEE T EVOLUT COMPUT, V7, P289, DOI 10.1109/TEVC.2003.810069
   Chaki J., 2020, Texture Feature Extraction Techniques for Image Recognition, DOI [10.1007/978-981-15-0853-0, DOI 10.1007/978-981-15-0853-0]
   Charte D, 2021, SLICER FEATURE LEARN, P305, DOI [10.1007/978-3-030-86271-8_26, DOI 10.1007/978-3-030-86271-8_26]
   Cohen JB, 2020, CURR HYPERTENS REP, V22, DOI 10.1007/s11906-020-01048-y
   Dey N, 2020, COGN COMPUT, V12, P1011, DOI 10.1007/s12559-020-09751-3
   Diniz JOB, 2021, MULTIMED TOOLS APPL, V80, P29367, DOI 10.1007/s11042-021-11153-y
   Diwan Sourabh S, 2020, Trans Indian Natl Acad Eng, V5, P255, DOI 10.1007/s41403-020-00106-w
   Du RH, 2020, EUR RESPIR J, V55, DOI 10.1183/13993003.00524-2020
   Elaziz MA, 2021, ENERG CONVERS MANAGE, V236, DOI 10.1016/j.enconman.2021.113971
   Elpeltagy M, 2021, MULTIMED TOOLS APPL, V80, P26451, DOI 10.1007/s11042-021-10783-6
   Faramarzi A, 2020, EXPERT SYST APPL, V152, DOI 10.1016/j.eswa.2020.113377
   Gianchandani N, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02669-6
   Gifani P, 2021, INT J COMPUT ASS RAD, V16, P115, DOI 10.1007/s11548-020-02286-w
   Hadjinicolaou AV, 2011, ARCH VIROL, V156, P671, DOI 10.1007/s00705-010-0906-7
   Hassanien AE, 2020, AUTOMATIC XRAY COVID, P1
   Hossam A., 2022, MULTIMED TOOLS APPL, P338, DOI [10.1007/978-3-030-89701-7_30, DOI 10.1007/978-3-030-89701-7_30]
   Houssein EH, 2021, NEURAL COMPUT APPL, V33, P16899, DOI 10.1007/s00521-021-06273-3
   Jindal Himanshu, 2021, SN Compr Clin Med, V3, P2383, DOI 10.1007/s42399-021-01059-z
   Kang Z, 2020, EUR RADIOL, V30, P4356, DOI 10.1007/s00330-020-06809-6
   Kevadiya BD, 2021, NAT MATER, V20, P593, DOI 10.1038/s41563-020-00906-z
   Kumar H, 2021, WORLD J RADIOL, V13, P75, DOI 10.4329/wjr.v13.i4.75
   Le DN, 2021, INT J MACH LEARN CYB, V12, P3235, DOI 10.1007/s13042-020-01248-7
   Loey M, 2020, NEURAL COMPUT APPL, DOI 10.1007/s00521-020-05437-x
   Mohanty SK, 2020, DIAGN PATHOL, V15, DOI 10.1186/s13000-020-01017-8
   Nazish, 2021, Artificial Intelligence Systems and the Internet of Things in the Digital Era. Proceedings of EAMMIS 2021. Lecture Notes in Networks and Systems (LNNS 239), P13, DOI 10.1007/978-3-030-77246-8_2
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Pisano ED, 1998, J DIGIT IMAGING, V11, P193, DOI 10.1007/BF03178082
   Shahbahrami A, 2012, J SUPERCOMPUT, V59, P1455, DOI 10.1007/s11227-011-0556-x
   Shaheen MAM, NOVEL APPL IMPROVED
   Sharma AK, 2020, RESONANCE, V25, P647, DOI 10.1007/s12045-020-0981-3
   Singh MR, 2016, COMPUT IND ENG, V93, P36, DOI 10.1016/j.cie.2015.12.004
   Soares E, 2020, CT SCANS SARS COV 2, P1
   Sornette D, 2020, NONLINEAR DYNAM, V101, P1751, DOI 10.1007/s11071-020-05966-z
   Sparavigna AC, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21050502
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   The MathWorks I., 2021, MATLAB STAT TOOLB RE
   Weigl JAI, 2000, EUR J CLIN MICROBIOL, V19, P336, DOI 10.1007/s100960050490
   Yasar H, 2021, MULTIMED TOOLS APPL, V80, P5423, DOI 10.1007/s11042-020-09894-3
   Zhang GC, 2004, LECT NOTES COMPUT SC, V3338, P179
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 48
TC 2
Z9 2
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 41073
EP 41103
DI 10.1007/s11042-023-15031-7
EA MAR 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000984224700001
PM 37362744
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Bhosale, YH
   Patnaik, KS
AF Bhosale, Yogesh H.
   Patnaik, K. Sridhar
TI Bio-medical imaging (X-ray, CT, ultrasound, ECG), genome sequences
   applications of deep neural network and machine learning in diagnosis,
   detection, classification, and segmentation of COVID-19: a Meta-analysis
   & systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Pattern; feature extraction; Bio-medical imaging; Deep machine learning;
   Diagnosis; Classification; Radiography imaging(X-ray; CT; Ultrasound;
   ECG); Deep neural network; Chronic obstructive pulmonary diseases (COPD)
ID CHEST; CORONAVIRUS; FRAMEWORK; LOCALIZATION; FUSION; IMAGES
AB This review investigates how Deep Machine Learning (DML) has dealt with the Covid-19 epidemic and provides recommendations for future Covid-19 research. Despite the fact that vaccines for this epidemic have been developed, DL methods have proven to be a valuable asset in radiologists' arsenals for the automated assessment of Covid-19. This detailed review debates the techniques and applications developed for Covid-19 findings using DL systems. It also provides insights into notable datasets used to train neural networks, data partitioning, and various performance measurement metrics. The PRISMA taxonomy has been formed based on pretrained(45 systems) and hybrid/custom(17 systems) models with radiography modalities. A total of 62 systems with respect to X-ray(32), CT(19), ultrasound(7), ECG(2), and genome sequence(2) based modalities as taxonomy are selected from the studied articles. We originate by valuing the present phase of DL and conclude with significant limitations. The restrictions contain incomprehensibility, simplification measures, learning from incomplete labeled data, and data secrecy. Moreover, DML can be utilized to detect and classify Covid-19 from other COPD illnesses. The proposed literature review has found many DL-based systems to fight against Covid19. We expect this article will assist in speeding up the procedure of DL for Covid-19 researchers, including medical, radiology technicians, and data engineers.
C1 [Bhosale, Yogesh H.; Patnaik, K. Sridhar] Birla Inst Technol, Comp Sci & Engn Dept, Ranchi, India.
C3 Birla Institute of Technology Mesra
RP Bhosale, YH (corresponding author), Birla Inst Technol, Comp Sci & Engn Dept, Ranchi, India.
EM yogeshbhosale988@gmail.com
RI Bhosale, Yogesh H./AFE-7600-2022
OI Bhosale, Yogesh H./0000-0001-6901-1419; Patnaik, K
   Sridhar/0000-0002-4994-4489
CR Abdani S.R., 2020, 2020 IEEE S IND EL A, P1, DOI 10.1109/ISIEA49364.2020.9188133
   Abdelminaam DS, 2021, IEEE ACCESS, V9, P27840, DOI 10.1109/ACCESS.2021.3058066
   Acharya UR, 2018, COMPUT BIOL MED, V100, P270, DOI 10.1016/j.compbiomed.2017.09.017
   Ahmed, 2019, PNEUM SAMPL XRAYS
   Ahmed I, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102571
   Alakus TB, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110120
   Alizadehsani R, 2020, MEDRXIV
   [Anonymous], 2021, COVID 19 DATABASE
   [Anonymous], 2023, PACIFIC RNA GENOME S, DOI [10.1038/s41598-021-82,043-4, DOI 10.1038/S41598-021-82,043-4]
   [Anonymous], 2021, COVID 19 XRAYS CT SN
   [Anonymous], 2021, COMMON AUGMENTATION
   [Anonymous], 2021, COVID CT DATASET CT
   [Anonymous], 2023, SIIM FISABIO RSNA CO
   [Anonymous], 2023, 2019NCOVR RNA GENOME
   [Anonymous], 2021, COVID 19 RADIOGRAPHY
   [Anonymous], 2021, COVID 19 DATABASE SI
   [Anonymous], 2021, GITHUB SARS COV 2 CT
   [Anonymous], 2021, COVID 19 CT SEGMENTA
   [Anonymous], 2021, NIH CHEST XRAYS KAGG
   [Anonymous], 2021, COVID 19 CT LUNG INF
   [Anonymous], 2022, MINISTRY HFW COVID R
   [Anonymous], 2021, Covid-19 Chest Xray Ontasel [Thutuset]
   [Anonymous], 2023, DATASET TUBERCULOSIS
   [Anonymous], 2021, PING GOOD DOCTOR SHO
   [Anonymous], 2021, KAGGLE COVID 19 CHES
   [Anonymous], 2021, KAGGLE CHEST XRAY RE
   [Anonymous], 2021, medRxiv
   [Anonymous], 2021, UNDERSTANDING ML CON
   [Anonymous], 2021, COVID 19 RT PCR TEST
   [Anonymous], 2021, GITHUB MUHAMMEDTALO
   [Anonymous], 2021, AAROGYASETU KNOWS CO
   [Anonymous], 2021, FIGURE 1 COVID 19 CL
   [Anonymous], 2021, ITALIAN COVID 19 LUN
   [Anonymous], 2023, W C D C DASHBOARD
   Apostolopoulos ID, 2020, J MED BIOL ENG, V40, P462, DOI 10.1007/s40846-020-00529-4
   Ardakani AA, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103795
   Arntfield R., 2020, MEDRXIV, DOI [DOI 10.1101/2020.10.13.20212258, 10.13.20212258]
   Aslan MF, 2021, APPL SOFT COMPUT, V98, DOI 10.1016/j.asoc.2020.106912
   Bassi Pedro R. A. S., 2022, Research on Biomedical Engineering, V38, P139, DOI 10.1007/s42600-021-00132-9
   Bhattacharyya A, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103182
   Bhoi SK, 2023, SOFT COMPUT, V27, P2717, DOI 10.1007/s00500-021-06168-4
   Bhosale, 2022 IEEE SILCHAR SU
   Bhosale Yogesh H., 2022, 2022 8th International Conference on Signal Processing and Communication (ICSC), P381, DOI 10.1109/ICSC56524.2022.10009568
   Bhosale Yogesh H., 2022, 2022 8th International Conference on Advanced Computing and Communication Systems (ICACCS), P1398, DOI 10.1109/ICACCS54159.2022.9785113
   Bhosale Y.H., 2022, 2022 INT C IOT BLOCK, P1
   Bhosale Y. H., 2022, 2022 13 INT C COMP C, P1, DOI [10.1109/ICCCNT54827.2022.9984237, DOI 10.1109/ICCCNT54827.2022.9984237]
   Bhosale Y.H., 2023, LECT NOTES NETWORKS, V492, P283, DOI [10.1007/978-981-19-3679-1_22, DOI 10.1007/978-981-19-3679-1_22]
   Bhosale YH, 2020, DIGITIZATION HOUSEHO, V5, P22
   Bhosale YH, 2023, BIOMED SIGNAL PROCES, V81, DOI 10.1016/j.bspc.2022.104445
   Bhosale YH, 2023, NEURAL PROCESS LETT, V55, P3551, DOI 10.1007/s11063-022-11023-0
   Born, 2021, POCOVID NET DATA SET
   Born J, 2021, ARXIV
   Born J, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11020672
   Chen J, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76282-0
   D'Agostino MA, 2010, BEST PRACT RES CL RH, V24, P693, DOI 10.1016/j.berh.2010.05.003
   Dalui M., 2020, BioRxiv, DOI DOI 10.1101/2020.07.15.205567
   Das NN, 2022, IRBM, V43, P114, DOI 10.1016/j.irbm.2020.07.001
   Desai Sudhen B, 2020, Intell Based Med, V3, P100013, DOI 10.1016/j.ibmed.2020.100013
   Distelmaier F, 2007, PEDIATR BLOOD CANCER, V49, P1029, DOI 10.1002/pbc.20783
   Dong D, 2021, IEEE REV BIOMED ENG, V14, P16, DOI 10.1109/RBME.2020.2990959
   El Asnaoui K, 2021, J BIOMOL STRUCT DYN, V39, P3615, DOI 10.1080/07391102.2020.1767212
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fontanellaz M, 2021, INVEST RADIOL, V56, P348, DOI 10.1097/RLI.0000000000000748
   Ghassemi N, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101678
   Ghassemi N, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE 2019), P403, DOI [10.1109/iccke48569.2019.8964826, 10.1109/ICCKE48569.2019.8964826]
   github, GITHUB BORGWARDTLAB
   github, GITHUB ARTHURSDAYS H
   GitHub, 2021, COVID CHESTXRAY DATA
   Gozes O., 2020, RAPID AI DEV CYCLE C
   Gudla Surya Pavan Kumar, 2022, Advances in Distributed Computing and Machine Learning: Proceedings of ICADCML 2022. Lecture Notes in Networks and Systems (427), P25, DOI 10.1007/978-981-19-1018-0_3
   Han ZY, 2020, IEEE T MED IMAGING, V39, P2584, DOI 10.1109/TMI.2020.2996256
   Harapan H, 2020, J INFECT PUBLIC HEAL, V13, P667, DOI 10.1016/j.jiph.2020.03.019
   Harikrishnan NB, 2022, MED BIOL ENG COMPUT, V60, P2245, DOI 10.1007/s11517-022-02591-3
   He X., 2020, BENCHMARKING DEEP LE, DOI [10.1101/2020.06.08.20125963, DOI 10.1101/2020.06.08.20125963]
   Hernandez Santa Cruz Jose Francisco, 2021, Intell Based Med, V5, P100027, DOI 10.1016/j.ibmed.2021.100027
   Horry MJ, 2020, IEEE ACCESS, V8, P149808, DOI 10.1109/ACCESS.2020.3016780
   Hussain E, 2021, CHAOS SOLITON FRACT, V142, DOI 10.1016/j.chaos.2020.110495
   IEEEDataport, 2021, IEEEDATAPORT CCAP CT
   Ilyas M, 2020, ARXIV
   Irmak E, 2020, 2020 MEDICAL TECHNOLOGIES CONGRESS (TIPTEKNO)
   Irmak E, 2022, PHYS ENG SCI MED, V45, P167, DOI 10.1007/s13246-022-01102-w
   Islam MM, 2021, IEEE ACCESS, V9, P30551, DOI 10.1109/ACCESS.2021.3058537
   Islam MR, 2022, EXPERT SYST APPL, V195, DOI 10.1016/j.eswa.2022.116554
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Jain G, 2020, BIOCYBERN BIOMED ENG, V40, P1391, DOI 10.1016/j.bbe.2020.08.008
   Jain R, 2021, APPL INTELL, V51, P1690, DOI 10.1007/s10489-020-01902-1
   Jaiswal A, 2021, J BIOMOL STRUCT DYN, V39, P5682, DOI 10.1080/07391102.2020.1788642
   Jena, 2021, MACHINE LEARNING BAS, DOI [10.1002/9781119786122.ch1, DOI 10.1002/9781119786122.CH1]
   Jena KK, 2021, INT J COMPUT APPL T, V66, P350, DOI 10.1504/IJCAT.2021.120462
   Jena KK, 2022, NEURAL COMPUT APPL, V34, P11361, DOI 10.1007/s00521-021-05719-y
   Jiang YF, 2021, IEEE J BIOMED HEALTH, V25, P441, DOI 10.1109/JBHI.2020.3042523
   Joshi RC, 2021, BIOCYBERN BIOMED ENG, V41, P239, DOI 10.1016/j.bbe.2021.01.002
   Kalane P, 2021, BIOMED SIGNAL PROCES, V67, DOI 10.1016/j.bspc.2021.102518
   Karhan Z., 2020, MED TECHNOLOGIES C T, P1, DOI [10.1109/TIPTEKNO50054.2020.9299315, DOI 10.1109/TIPTEKNO50054.2020.9299315]
   Karki R., 2021, BIORXIV, DOI DOI 10.11.02.05.429385,2021
   Karthik R, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106744
   Kastelein JJP, 2008, EUR HEART J, V29, P849, DOI 10.1093/eurheartj/ehn070
   Kermany, 2021, LARGE DATASET LABELE
   Khan AH, 2021, DATA BRIEF, V34, DOI 10.1016/j.dib.2021.106762
   Khan AI, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105581
   Khan E, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22031211
   Konar D, 2021, IEEE ACCESS, V9, P28716, DOI 10.1109/ACCESS.2021.3058854
   Kroft LJM, 2019, J THORAC IMAG, V34, P179, DOI 10.1097/RTI.0000000000000404
   Lencioni R, 2008, J HEPATOL, V48, P848, DOI 10.1016/j.jhep.2008.02.005
   Li L, 2020, RADIOLOGY, V296, pE65, DOI 10.1148/radiol.2020200905
   Li YF, 2023, SCI CHINA MATER, V66, P1719, DOI 10.1007/s40843-022-2332-9
   Liu XB, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3465220
   Loey M, 2020, NEURAL COMPUT APPL, DOI 10.1007/s00521-020-05437-x
   Loey M, 2021, MEASUREMENT, V167, DOI 10.1016/j.measurement.2020.108288
   Lussier F, 2020, TRAC-TREND ANAL CHEM, V124, DOI 10.1016/j.trac.2019.115796
   Luz Eduardo, 2022, Research on Biomedical Engineering, V38, P149, DOI 10.1007/s42600-021-00151-6
   Mazurowski MA, 2019, J MAGN RESON IMAGING, V49, P939, DOI 10.1002/jmri.26534
   Medhi K., 2020, AUTOMATIC DETECTION, DOI [10.1101/2020.05.10.20097063, DOI 10.1101/2020.05.10.20097063]
   Mohammadpoor M., 2016, IRAN J MED PHYS, V13, P261, DOI DOI 10.22038/IJMP.2016.8453
   Mostafiz R, 2022, J KING SAUD UNIV-COM, V34, P3226, DOI 10.1016/j.jksuci.2020.12.010
   Muhammad G, 2021, INFORM FUSION, V72, P80, DOI 10.1016/j.inffus.2021.02.013
   Mukherjee H, 2021, COGN COMPUT, DOI 10.1007/s12559-020-09775-9
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   Nayak SR, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102365
   Nazari K, 2022, J SCI FOOD AGR, V102, P6907, DOI 10.1002/jsfa.12052
   Negin medical center, 2021, COVID CTSET
   Ni QQ, 2020, EUR RADIOL, V30, P6517, DOI 10.1007/s00330-020-07044-9
   nih, CHEST XRAY IMAGES IN
   Nithya A, 2020, MEASUREMENT, V149, DOI 10.1016/j.measurement.2019.106952
   Nour M, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106580
   Orioli L, 2020, ANN ENDOCRINOL-PARIS
   Ouchicha C, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110245
   Ozcan T, 2020, IN PRESS, DOI [10.21203/rs.3.rs-26500/v1, DOI 10.21203/RS.3.RS-26500/V1]
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Paluru N, 2021, IEEE T NEUR NET LEAR, V32, P932, DOI 10.1109/TNNLS.2021.3054746
   Pandit MK, 2021, RADIOGRAPHY, V27, P483, DOI 10.1016/j.radi.2020.10.018
   Panwar H, 2020, CHAOS SOLITON FRACT, V138, DOI 10.1016/j.chaos.2020.109944
   Radiological Society of North America, 2021, RSNA PNEUM DET CHALL
   Rafi TH, 2020, 2020 IEEE CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY (CIBCB), P210, DOI 10.1109/cibcb48159.2020.9277695
   Rahimzadeh M, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102588
   Rahimzadeh Mohammad, 2020, Inform Med Unlocked, V19, P100360, DOI 10.1016/j.imu.2020.100360
   Rajaraman S, 2020, IEEE ACCESS, V8, P115041, DOI [10.1109/ACCESS.2020.3003810, 10.1109/access.2020.3003810]
   Rojas-Azabache C, 2021, ARXIV
   Rostami M, 2022, ARTIF INTELL MED, V123, DOI 10.1016/j.artmed.2021.102228
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Roy S, 2020, IEEE T MED IMAGING, V39, P2676, DOI 10.1109/TMI.2020.2994459
   Rubin GD, 2020, RADIOLOGY
   Saberi-Movahed Farshad, 2021, medRxiv, DOI 10.1101/2021.07.07.21259699
   Saeedi MS, NOVEL RELIABLE DEEP, P9
   Saiz FA, 2020, INT J INTERACT MULTI, V6, P11, DOI 10.9781/ijimai.2020.04.003
   Salman FM, 2020, COVID 19 DETECTION U, V4, P8
   Sedik A, 2022, NEURAL COMPUT APPL, V34, P11423, DOI 10.1007/s00521-020-05410-8
   Self WH, 2013, AM J EMERG MED, V31, P401, DOI 10.1016/j.ajem.2012.08.041
   Sethy PK, 2020, INT J MATH ENG MANAG, V5, P643, DOI 10.33889/IJMEMS.2020.5.4.052
   Sevi M., 2020, 2020 INT C DATA ANAL, P1, DOI [10.1109/ICDABI51230.2020.9325626, DOI 10.1109/ICDABI51230.2020.9325626]
   Silva Pedro, 2020, Inform Med Unlocked, V20, P100427, DOI 10.1016/j.imu.2020.100427
   Singh OP, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104650
   Sohrabi C, 2020, INT J SURG, V76, P71, DOI 10.1016/j.ijsu.2020.02.034
   Song LP, 2022, APPL SOFT COMPUT, V122, DOI 10.1016/j.asoc.2022.108883
   Steinl DC, 2015, INT J MOL SCI, V16, P9749, DOI 10.3390/ijms16059749
   Subramanian N, 2022, COMPUT BIOL MED, V143, DOI 10.1016/j.compbiomed.2022.105233
   Talo M, 2019, COMPUT MED IMAG GRAP, V78, DOI 10.1016/j.compmedimag.2019.101673
   The cancer imaging archive (TCIA, 2021, US
   Togaçar M, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103805
   Verma P, 2021, MATER TODAY-PROC, V46, P11098, DOI 10.1016/j.matpr.2021.02.244
   Villanueva FS, 2008, NAT CLIN PRACT CARD, V5, pS26, DOI 10.1038/ncpcardio1246
   Wang S, 2021, EUR RADIOL, V31, P6096, DOI [10.1080/1064119X.2021.1966557, 10.1079/9781789246070.0001, 10.1007/s00330-021-07715-1]
   Wang XG, 2020, IEEE T MED IMAGING, V39, P2615, DOI 10.1109/TMI.2020.2995965
   Wang Y, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/2485934
   Wang ZC, 2020, NAT MED, V26, P458, DOI 10.1038/s41591-020-0823-6
   worldometers, WORLDMETERS COVID 19
   Xu XW, 2020, ENGINEERING-PRC, V6, P1122, DOI 10.1016/j.eng.2020.04.010
   Yan QS, 2021, IEEE T BIG DATA, V7, P13, DOI 10.1109/TBDATA.2021.3056564
   Yang MM, 2021, J SUPERCOMPUT, V77, P7598, DOI 10.1007/s11227-020-03535-0
   Zebin T, 2021, APPL INTELL, V51, P1010, DOI 10.1007/s10489-020-01867-1
   Zhang HT, 2020, EUR J NUCL MED MOL I, V47, P2525, DOI 10.1007/s00259-020-04953-1
NR 171
TC 3
Z9 3
U1 11
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39157
EP 39210
DI 10.1007/s11042-023-15029-1
EA MAR 2023
PG 54
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000950119600008
PM 37362676
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Jin, YF
   Lu, HJ
   Li, Z
   Wang, YB
AF Jin, Yufei
   Lu, Huijuan
   Li, Zhao
   Wang, Yanbin
TI A cross-modal deep metric learning model for disease diagnosis based on
   chest x-ray images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chest X-ray; Generalized zero-shot learning; Deep metric learning;
   Cross-modal; Multi-label classification
ID CLASSIFICATION
AB The emergence of unknown diseases is often with few or no samples available. Zero-shot learning and few-shot learning have promising applications in medical image analysis. In this paper, we propose a Cross-Modal Deep Metric Learning Generalized Zero-Shot Learning (CM-DML-GZSL) model. The proposed network consists of a visual feature extractor, a fixed semantic feature extractor, and a deep regression module. The network belongs to a two-stream network for multiple modalities. In a multi-label setting, each sample contains a small number of positive labels and a large number of negative labels on average. This positive-negative imbalance dominates the optimization procedure and may prevent the establishment of an effective correspondence between visual features and semantic vectors during training, resulting in a low degree of accuracy. A novel weighted focused Euclidean distance metric loss is introduced in this regard. This loss not only can dynamically increase the weight of hard samples and decrease the weight of simple samples, but it can also promote the connection between samples and semantic vectors corresponding to their positive labels, which helps mitigate bias in predicting unseen classes in the generalized zero-shot learning setting. The weighted focused Euclidean distance metric loss function can dynamically adjust sample weights, enabling zero-shot multi-label learning for chest X-ray diagnosis, as experimental results on large publicly available datasets demonstrate.
C1 [Jin, Yufei; Lu, Huijuan] China JiLiang Univ, Hangzhou 310018, Zhejiang, Peoples R China.
   [Jin, Yufei; Lu, Huijuan] Key Lab Electromagnet Wave Informat Technol & Metr, Hangzhou 310018, Zhejiang, Peoples R China.
   [Li, Zhao] Zhejiang Univ, Hangzhou 310018, Zhejiang, Peoples R China.
   [Wang, Yanbin] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310018, Zhejiang, Peoples R China.
C3 China Jiliang University; Zhejiang University; Zhejiang University
RP Lu, HJ (corresponding author), China JiLiang Univ, Hangzhou 310018, Zhejiang, Peoples R China.; Lu, HJ (corresponding author), Key Lab Electromagnet Wave Informat Technol & Metr, Hangzhou 310018, Zhejiang, Peoples R China.
EM s20030812005@cjlu.edu.cn; hjlu@cjlu.edu.cn; zhao_li@zju.edu.cn;
   wangyanbin15@mails.ucas.ac.cn
FU National Natural Science Foundation of China [61272315]; Natural Science
   Foundation of Zhejiang Province [LY21F020028]; Funded Project of
   Zhejiang Province University Student Scientific Research and Innovation
   Activities Plan [2021R409054]
FX AcknowledgementsIn this paper, the research was sponsored by the
   National Natural Science Foundation of China (61272315), the Natural
   Science Foundation of Zhejiang Province (LY21F020028), and the Funded
   Project of Zhejiang Province University Student Scientific Research and
   Innovation Activities Plan (No.2021R409054).
CR Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111
   Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009
   Cao XH, 2019, NEUROCOMPUTING, V356, P217, DOI 10.1016/j.neucom.2019.05.019
   Chen TS, 2019, IEEE I CONF COMP VIS, P522, DOI 10.1109/ICCV.2019.00061
   Chen ZM, 2019, PROC CVPR IEEE, P5172, DOI 10.1109/CVPR.2019.00532
   Cheng G, 2021, SCI CHINA INFORM SCI, V64, DOI 10.1007/s11432-020-3156-7
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Dat Huynh, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8773, DOI 10.1109/CVPR42600.2020.00880
   Feng S, 2018, BIOTECHNOL BIOTEC EQ, V32, P1613, DOI 10.1080/13102818.2018.1521302
   Fu YW, 2015, Arxiv, DOI arXiv:1503.07790
   Fürnkranz J, 2008, MACH LEARN, V73, P133, DOI 10.1007/s10994-008-5064-8
   Gabruseva T, 2020, IEEE COMPUT SOC CONF, P1436, DOI 10.1109/CVPRW50498.2020.00183
   Gaure A., 2017, The Conference on Uncertainty in Artificial Intelligence (UAI), V1, P3
   Gouk H., 2016, 8 AS C MACH LEARN, V63, P318
   Gu K, 2021, IEEE T NEUR NET LEAR, V32, P4278, DOI 10.1109/TNNLS.2021.3105394
   Gu K, 2021, IEEE T IND INFORM, V17, P2261, DOI 10.1109/TII.2020.2991208
   Gu K, 2020, IEEE T MULTIMEDIA, V22, P311, DOI 10.1109/TMM.2019.2929009
   Gupta A, 2021, Arxiv, DOI arXiv:2101.11606
   Hayat N., 2021, P 6 MACH LEARN HEALT, P461
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang H, 2020, Arxiv, DOI arXiv:2007.15610
   Huang S, 2020, IEEE SIGNAL PROC LET, V27, P301, DOI 10.1109/LSP.2020.2968213
   Ji Z, 2020, IEEE T IMAGE PROCESS, V29, P6549, DOI 10.1109/TIP.2020.2991527
   Ji Z, 2020, NEUROCOMPUTING, V373, P90, DOI 10.1016/j.neucom.2019.09.062
   Jiang HJ, 2019, IEEE SIGNAL PROC LET, V26, P1270, DOI 10.1109/LSP.2019.2917148
   Jiang W, 2021, IEEE T CIRC SYST VID, V31, P1091, DOI 10.1109/TCSVT.2020.2995754
   Karagoz GN, 2021, INT J MACH LEARN CYB, V12, P53, DOI 10.1007/s13042-020-01156-w
   Kodirov E, 2017, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2017.473
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Lang CB, 2022, PROC CVPR IEEE, P8047, DOI 10.1109/CVPR52688.2022.00789
   Lee CW, 2018, PROC CVPR IEEE, P1576, DOI 10.1109/CVPR.2018.00170
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Li CS, 2020, IEEE T NEUR NET LEAR, V31, P2294, DOI 10.1109/TNNLS.2019.2924023
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Mahapatra D., 2021, P IEEECVF INT C COMP, P3344
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   National Institutes of Health, 2017, NIH clinical center provides one of the largest publicly available chest x-ray datasets to scientific community
   Peng J., 2020, P IEEECVF C COMPUTER, P9709
   Romera-Paredes B, 2015, PR MACH LEARN RES, V37, P2152
   Salim I, 2021, MULTIMED TOOLS APPL, V80, P30461, DOI 10.1007/s11042-021-10935-8
   Sariyildiz MB, 2019, PROC CVPR IEEE, P2163, DOI 10.1109/CVPR.2019.00227
   Sharma H, 2020, PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING, P227, DOI [10.1109/Confluence47617.2020.9057809, 10.1109/confluence47617.2020.9057809]
   Shigeto Y, 2015, LECT NOTES ARTIF INT, V9284, P135, DOI 10.1007/978-3-319-23528-8_9
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369
   Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581
   Xian YQ, 2016, PROC CVPR IEEE, P69, DOI 10.1109/CVPR.2016.15
   Xie GS, 2019, PROC CVPR IEEE, P9376, DOI 10.1109/CVPR.2019.00961
   Xu W., 2020, NEURIPS, V33, P21969
   Yan Z, 2019, IEEE ACCESS, V7, P98005, DOI 10.1109/ACCESS.2019.2929512
   Yu BS, 2019, IEEE I CONF COMP VIS, P6499, DOI 10.1109/ICCV.2019.00659
   Yu YL, 2019, IEEE T CYBERNETICS, V49, P3755, DOI 10.1109/TCYB.2018.2850750
   Yuming Shen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P614, DOI 10.1007/978-3-030-58517-4_36
   Zhang F., 2019, INT C MACHINE LEARNI, P7434
   Zhang L, 2017, PROC CVPR IEEE, P3010, DOI 10.1109/CVPR.2017.321
   Zhang MY, 2019, IEEE IMAGE PROC, P2134, DOI [10.1109/ICIP.2019.8803160, 10.1109/icip.2019.8803160]
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
   Zunair H, 2021, SOC NETW ANAL MIN, V11, DOI 10.1007/s13278-021-00731-5
   Zunair H, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/ab86d3
NR 68
TC 4
Z9 4
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 33421
EP 33442
DI 10.1007/s11042-023-14790-7
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000950119600005
PM 37362731
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Kumar, S
   Kumar, D
   Singh, N
AF Kumar, Sunil
   Kumar, Dilip
   Singh, Naini
TI Performance and security analysis using B-128 modified blowfish
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption; Decryption; Security; Blowfish; Block size; Throughput;
   Avalanche effect
ID IMAGE ENCRYPTION
AB Information security is a domain having extensive applications in the twenty-first century and beyond. Encryption is a technique used to prevent data from being accessed without authorization. Symmetric key encryption algorithms are extremely fast compared to asymmetric key algorithms and hence, are used widely. Blowfish is a symmetric key encryption algorithm that is unpatented, free-to-use, fast, compact, and efficient. It is also a very secure algorithm. But, its 64-bit block size prevents it from being widespread. The paper aims to propose a modified version of the Blowfish algorithm that performs high-speed encryption with high throughput and supports 128-bit block size, enhancing its applicability in various areas. The algorithm can be an alternative to the AES algorithm with limited power consumption. The proposed algorithm is compared with the original Blowfish algorithm based on execution speed, throughput, and the avalanche effect. The algorithm's performance is also evaluated on images based on diffusion properties, image histogram, entropy, and correlation coefficient.
C1 [Kumar, Sunil; Kumar, Dilip; Singh, Naini] Natl Inst Technol, Dept Comp Sci & Engn, Jamshedpur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur
RP Kumar, S (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Jamshedpur, India.
EM 2018rscs016@nitjsr.ac.in; dilip.cse@nitjsr.ac.in;
   2020pgcscs01@nitjsr.ac.in
RI Kumar, Sunil/GYV-0347-2022
OI Kumar, Sunil/0000-0002-1953-6273
CR Alabaichi Ashwak, 2013, 2013 Second International Conference on Informatics & Applications (ICIA), P12, DOI 10.1109/ICoIA.2013.6650222
   Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   At N., 2012, Proceedings of the Fifth IFIP International Conference on New Technologies, Mobility and Security-NTMS 2012, P1
   Bahnasawi MA, 2016, INT C MICROELECTRON, P285, DOI 10.1109/ICM.2016.7847871
   Christina L., 2014, INT J INNOV RES COMP, V2, P5009
   Dasgupta D, 2016, COMPUT SECUR, V63, P85, DOI 10.1016/j.cose.2016.09.004
   Dhiman K, 2018, COMPUT ELECTR ENG, V70, P647, DOI 10.1016/j.compeleceng.2017.09.017
   Dixit P, 2018, LECT NOTE DATA ENG, V4, P239, DOI 10.1007/978-981-10-4600-1_22
   Harmouch Y., 2017, ADV INTELL SYST
   Jang S.W., 2017, Anal Appl Math, V10, P5
   Kumar S., 2021, J. Cyber Secur. Mobil, V10, P537
   Luo HB, 2019, MULTIMED TOOLS APPL, V78, P34323, DOI 10.1007/s11042-019-08072-4
   Mandal P. C., 2012, J. Global Res. Comput. Sci., V3, P67
   Oishi NJ, 2016, 2016 INTERNATIONAL CONFERENCE ON NETWORKING SYSTEMS AND SECURITY (NSYSS), P123
   Patil P, 2016, PROCEDIA COMPUT SCI, V78, P617, DOI 10.1016/j.procs.2016.02.108
   Pujari SK, 2018, PROCEDIA COMPUT SCI, V125, P165, DOI 10.1016/j.procs.2017.12.023
   Quilala TFG., 2021, B ELECT ENG, V10, P2192
   Quilala TFG., 2018, J ELECT ENG COMPUT S, V11, P1027
   Ramesh A, 2013, PROCEEDINGS OF 2013 INTERNATIONAL CONFERENCE ON CIRCUITS, POWER AND COMPUTING TECHNOLOGIES (ICCPCT 2013), P840, DOI 10.1109/ICCPCT.2013.6528957
   Reyes AR., 2018, 8 INT WORKSH COMP SC, P578
   Schneier B., 1994, Fast Software Encryption. Cambridge Security Workshop Proceedings, P191
   Schneier B, 1998, DR DOBBS J, V23, P30
   Shamina Ross B., 2017, INT J APPL ENG RES, V12, P9236
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Suresh M, 2016, PROC TECH, V25, P248, DOI 10.1016/j.protcy.2016.08.104
   Thakur J., 2011, International Journal of Emerging Technology and Advanced Engineering, V1, P6
   Usha A., 2016, INT J ENG COMPUT SCI, V5, P19596
   Wang XY, 2019, IETE TECH REV, V36, P39, DOI 10.1080/02564602.2017.1393352
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
NR 30
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26661
EP 26678
DI 10.1007/s11042-023-15038-0
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000948950300006
DA 2024-07-18
ER

PT J
AU Liu, HJ
AF Liu, Hongjun
TI Audio block encryption using 3D chaotic system with adaptive parameter
   perturbation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio block encryption; Time domain; Lorenz system; Impulsive
   perturbation
ID FPGA IMPLEMENTATION; ALGORITHM; SCHEME
AB To ensure the sensitive audio data transmit securely over the insecure internet, we proposed a chaos based dual-channel audio block encryption algorithm. A 3D chaotic system is served as pseudo random number generator to encrypt the audio data in time domain through confusion and diffusion. The encryption process includes, (1) generating initial values of chaotic system based on random external values and hash value of plain audio; (2) before encrypting each block, iterate the chaotic system with adaptive parameter perturbation to generate confusion and diffusion sequences; (3) divide the plain audio data into blocks with the same size, confuse and diffuse the time domain vector of each block. Experimental and analysis results demonstrated that, for a 60 second dual-channel wave file with 44.1 kHz and 16-bit quantization, its encryption or decryption speed is only about 1 second, hence the proposed scheme is so suitable for real-time secure communication.
C1 [Liu, Hongjun] Univ Jinan, Sch Math Sci, Jinan 250022, Peoples R China.
C3 University of Jinan
RP Liu, HJ (corresponding author), Univ Jinan, Sch Math Sci, Jinan 250022, Peoples R China.
EM sms_liuhj@ujn.edu.cn
FU Natural Science Foundation of Shandong Province [ZR2022MF232]; General
   Research Project of Liaoning Provincial Education Department of China
   [LJKZ1185]
FX AcknowledgmentsThis research is supported by the Natural Science
   Foundation of Shandong Province (No. ZR2022MF232), the General Research
   Project of Liaoning Provincial Education Department of China (No.
   LJKZ1185).
CR Abd El-Maksoud AJ, 2019, MICROELECTRON J, V90, P323, DOI 10.1016/j.mejo.2019.05.005
   Chang D, 2018, AEU-INT J ELECTRON C, V88, P20, DOI 10.1016/j.aeue.2018.03.007
   Dai WY, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14010017
   Elsafty AH, 2020, AEU-INT J ELECTRON C, V125, DOI 10.1016/j.aeue.2020.153347
   Gan QY, 2017, INT J CIRC THEOR APP, V45, P1849, DOI 10.1002/cta.2300
   Gebereselassie SA, 2022, IFAC PAPERSONLINE, V55, P914, DOI 10.1016/j.ifacol.2022.04.150
   Ghasemzadeh H, 2017, ISECURE-ISC INT J IN, V9, P33
   He ZL, 2021, NONLINEAR ANAL-HYBRI, V39, DOI 10.1016/j.nahs.2020.100970
   Imran OA, 2020, PROCEDIA COMPUT SCI, V167, P1028, DOI 10.1016/j.procs.2020.03.402
   Kordov K, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8050530
   Li GD, 2019, CLUSTER COMPUT, V22, pS7423, DOI 10.1007/s10586-018-1700-7
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2019, OPT LASER ENG, V122, P123, DOI 10.1016/j.optlaseng.2019.05.027
   Liu HJ, 2019, APPL MATH COMPUT, V360, P83, DOI 10.1016/j.amc.2019.04.078
   Liu HJ, 2016, OPTIK, V127, P7431, DOI 10.1016/j.ijleo.2016.05.073
   Liu HJ, 2015, SIGNAL PROCESS, V113, P104, DOI 10.1016/j.sigpro.2015.01.016
   Mahdi A, 2016, Int J Inform Communication Sci, V1, P16
   Naskar PK, 2019, MULTIMED TOOLS APPL, V78, P25019, DOI 10.1007/s11042-019-7696-z
   Öztürk I, 2015, NONLINEAR DYNAM, V80, P1147, DOI 10.1007/s11071-015-1932-5
   Parvees MYM., 2018, INT J APPL SYST STUD, V8, P51, DOI [10.1504/IJASS.2018.091847, DOI 10.1504/IJASS.2018.091847]
   Piotr K, 2022, NOVEL DISTORTION TOL, DOI [10.1016/j.specom.2022.06.007, DOI 10.1016/J.SPECOM.2022.06.007]
   Ren HW, 2020, J FRANKLIN I, V357, P12308, DOI 10.1016/j.jfranklin.2020.09.016
   Ren W, 2019, SYST CONTROL LETT, V133, DOI 10.1016/j.sysconle.2019.104516
   Renza D, 2019, J INF SECUR APPL, V46, P62, DOI 10.1016/j.jisa.2019.02.010
   Sathiyamurthi P, 2020, MULTIMED TOOLS APPL, V79, P17817, DOI 10.1007/s11042-020-08729-5
   Tolba MF, 2020, INTEGRATION, V72, P163, DOI 10.1016/j.vlsi.2020.02.003
   Wang XY, 2008, PHYSICA A, V387, P3751, DOI 10.1016/j.physa.2008.02.020
   Yong-Xiao Chen, 2015, 2015 IEEE 33rd VLSI Test Symposium (VTS). Proceedings, P1, DOI 10.1109/VTS.2015.7116247
NR 28
TC 6
Z9 6
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27973
EP 27987
DI 10.1007/s11042-023-14572-1
EA MAR 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000948950300002
DA 2024-07-18
ER

PT J
AU Das, D
   Naskar, R
   Chakraborty, RS
AF Das, Debjit
   Naskar, Ruchira
   Chakraborty, Rajat Subhra
TI Image splicing detection with principal component analysis generated
   low-dimensional homogeneous feature set based on local binary pattern
   and support vector machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Digital forensics; Feature dimension; Image splicing;
   Local binary pattern; Principal component analysis
ID MARKOV FEATURES; WAVELET
AB Due to the wide availability of various ready-to-use image tampering software tools, image manipulation has become widespread nowadays. Tampered images are often used intentionally for unlawful and malicious purposes. One of the most common forms of image manipulation today includes the Image Splicing attack. Image splicing can be defined as generating a composite image by combining parts of different images from different sources, forming one artificially generated composite image. Given its prevalence, image splicing detection has a fundamental importance in digital forensics, and therefore, several research works have been carried out in the recent past to address this problem. In this paper, we propose an image forensic technique using a homogeneous image feature set of optimal dimensions for the successful detection of image splicing attacks. The Columbia Image Splicing Detection Evaluation Dataset has been used in our experiments, and different feature sets extracted from the available data have been adopted and experimented with. We have succeeded in finding a feature set of dimension as low as 31 comprising of Local Binary Pattern features for image splicing detection, obtaining state-of-the-art spliced image classification result using the Support Vector Machine classifier.
C1 [Das, Debjit; Naskar, Ruchira] Indian Inst Engn Sci & Technol, Dept Informat Technol, Sibpur 711103, India.
   [Chakraborty, Rajat Subhra] Indian Inst Technol, Dept Comp Sci & Engn, Kharagpur 721302, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST);
   Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Das, D (corresponding author), Indian Inst Engn Sci & Technol, Dept Informat Technol, Sibpur 711103, India.
EM 2020itp002.debjit@students.iiests.ac.in; ruchira@it.iiests.ac.in;
   rschakraborty@cse.iitkgp.ac.in
RI Das, Debjit/GLV-5429-2022
OI Das, Debjit/0000-0003-2606-8786
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Ahmed B, 2020, SIGNAL IMAGE VIDEO P, V14, P1035, DOI 10.1007/s11760-020-01636-0
   Binjie Xiao, 2010, 2010 International Conference on Computer and Communication Technologies in Agriculture Engineering (CCTAE 2010), P250, DOI 10.1109/CCTAE.2010.5544358
   Chen JX, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116287
   Chen W, 2007, PROC SPIE, V6505, DOI 10.1117/12.704321
   Das A, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1237, DOI 10.1109/ICCSP.2016.7754350
   Fu DD, 2006, LECT NOTES COMPUT SC, V4283, P177
   Gill NK, 2017, INT CONF COMPUT
   Hadi SJ, 2018, WATER RESOUR MANAG, V32, P4661, DOI 10.1007/s11269-018-2077-3
   Han JG, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.2.023031
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Hsu YF, 2010, IEEE T INF FOREN SEC, V5, P816, DOI 10.1109/TIFS.2010.2077628
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Islam MM, 2018, 2018 DIGITAL IMAGE C, P1, DOI 10.1109/DICTA.2018.8615874
   Jaiswal AK, 2020, MULTIMED TOOLS APPL, V79, P11837, DOI 10.1007/s11042-019-08480-6
   Kakar P, 2011, IEEE T MULTIMEDIA, V13, P443, DOI 10.1109/TMM.2011.2121056
   Kuo F. Y., 2005, NOTICES AMS, V52, P1320
   Li C, 2017, NEUROCOMPUTING, V228, P29, DOI 10.1016/j.neucom.2016.04.068
   Liao X, 2021, INFORM SCIENCES, V575, P231, DOI 10.1016/j.ins.2021.06.045
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Q, 2009, P 1 ACM WORKSH MULT, P43, DOI [10.1145/1631081.1631092, DOI 10.1145/1631081.1631092]
   Mahmood T, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/8713202
   Marcano-Cedeno A., 2010, IECON 2010 - 36th Annual Conference of IEEE Industrial Electronics, P2845, DOI 10.1109/IECON.2010.5675075
   Meena K.B., 2019, DATA ENG APPL, P163, DOI [DOI 10.1007/978-981-13-6351-1_14, 10.1007/978-981-13-6351-1_14]
   Pham NT, 2019, MULTIMED TOOLS APPL, V78, P12405, DOI 10.1007/s11042-018-6792-9
   Ng Tian-Tsong, 2009, Columbia Image Splicing Detection Evaluation DatasetEB/ OL
   Noor, 2017, P 2 INT C INT THINGS, V140, P1, DOI [10.1145/3018896.3036383, DOI 10.1145/3018896.3036383]
   Pietikainen, 2010, SCHOLARPEDIA, V5, P9775, DOI DOI 10.4249/SCHOLARPEDIA.9775.REVISION#188481
   Pomari T, 2018, IEEE IMAGE PROC, P3788, DOI 10.1109/ICIP.2018.8451227
   Porwik P., 2004, Machine Graphics & Vision, V13, P79
   Rao Y, 2020, IEEE ACCESS, V8, P25611, DOI 10.1109/ACCESS.2020.2970735
   Rinky BP, 2012, PROC TECH, V1, P344, DOI 10.1016/j.protcy.2012.10.041
   Shahroudnejad A, 2016, 2016 2ND INTERNATIONAL CONFERENCE OF SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS), P149, DOI 10.1109/ICSPIS.2016.7869896
   Sharif I, 2014, INT ARCH PHOTOGRAMM, V40-8, P937, DOI 10.5194/isprsarchives-XL-8-937-2014
   Shi YQ, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P51
   Stanton J., 2019, CVPR WORKSH, P138
   Wang R., 2020, DIGITAL FORENSICS FO, P61
   Wu Y, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1480, DOI 10.1145/3123266.3123411
   Xiao B, 2019, IEEE T CIRC SYST VID, V29, P2796, DOI 10.1109/TCSVT.2018.2869841
   Xuemin Wu, 2011, 2011 3rd International Conference on Multimedia Information Networking and Security, P600, DOI 10.1109/MINES.2011.135
   Zhang QB, 2018, MULTIMED TOOLS APPL, V77, P31239, DOI 10.1007/s11042-018-6230-z
   Zhao XD, 2015, IEEE T CIRC SYST VID, V25, P185, DOI 10.1109/TCSVT.2014.2347513
NR 43
TC 2
Z9 2
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 25847
EP 25864
DI 10.1007/s11042-023-14658-w
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000946494700013
DA 2024-07-18
ER

PT J
AU Hashemi, M
   Moghim, N
AF Hashemi, Mahshid
   Moghim, Neda
TI An efficient multicast multi-rate reinforcement learning based
   opportunistic routing algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multicasting; Multi-rate; Opportunistic routing; Reinforcement learning;
   5G network
ID WIRELESS; THROUGHPUT
AB Multicasting through device-to-device communication (MD2D) is a promising solution for handling the heavy load caused by the extraordinary high traffic in 5G cellular networks. One of the most important challenges of effective multicast in wireless networks is routing. Traditional multicast routing is not a good option in wireless environments due to the limited battery and energy of the users and users' mobility, leading to entering and leaving multicast groups. Opportunistic Routing (OR) was introduced to meet these challenges in wireless networks. In OR, the forwarding nodes are selected along the way and in each hop from the packet receivers. Although multicast opportunistic routing solves these problems to some extent, it poses challenges such as suitable forwarder set selection, forwarder nodes' coordination, and the crying baby problem. Multi-rate Multicast Reinforcement Learning based Opportunistic Routing (2MRLOR) is proposed in this paper to deal with these problems. In this algorithm, the transmission ranges of the nodes are altered by changing their transmission rate. Therefore, the neighboring nodes will also vary, and more candidates may be available for the packet forwarding. In 2MRLOR, we introduce a routing metric called EMD (Expected Multicast Delay) to determine the best forwarders along the packets' way in a multi-rate condition. In this algorithm, the suitable transmission rate of each node is calculated based on the network conditions. Reinforcement learning is also used to reduce the amount of information exchanged between the nodes in the network. Furthermore, network coding is used to facilitate the forwarders' transmission and eliminate the need for forwarders' coordination. Based on the simulation results, the proposed algorithm leads to an increase in network throughput and a reduction in end-to-end delay in the network compared to the benchmark algorithms.
C1 [Hashemi, Mahshid; Moghim, Neda] Univ Isfahan, Dept Comp Engn, Esfahan, Iran.
C3 University of Isfahan
RP Moghim, N (corresponding author), Univ Isfahan, Dept Comp Engn, Esfahan, Iran.
EM n.moghim@eng.ui.ac.ir
OI Moghim, Neda/0000-0002-6338-5505
CR Ben Hassouna A, 2018, INT J AD HOC UBIQ CO, V27, P210, DOI 10.1504/IJAHUC.2016.10001801
   Bhardwaj A, 2015, 2015 IEEE 26TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), P1498, DOI 10.1109/PIMRC.2015.7343535
   Biswas S, 2005, ACM SIGCOMM COMP COM, V35, P133, DOI 10.1145/1090191.1080108
   Chachulski S, 2007, ACM SIGCOMM COMP COM, V37, P169, DOI 10.1145/1282427.1282400
   Chakchouk N, 2015, IEEE COMMUN SURV TUT, V17, P2214, DOI 10.1109/COMST.2015.2411335
   Cheng L, 2014, IEEE T PARALL DISTR, V25, P1864, DOI 10.1109/TPDS.2013.240
   Choumas K, 2017, IEEE T VEH TECHNOL, V66, P8372, DOI 10.1109/TVT.2017.2683266
   Feng L, 2018, IEEE COMMUN MAG, V56, P112, DOI 10.1109/MCOM.2018.1700667
   Ganesan D., 2001, MOBILE COMPUTER COMM, V5, P11, DOI DOI 10.1145/509506.509514
   Guokai Zeng, 2011, 2011 IEEE 8th International Conference on Mobile Ad-Hoc and Sensor Systems, P600, DOI 10.1109/MASS.2011.63
   Jain S, 2008, AD HOC NETW, V6, P805, DOI 10.1016/j.adhoc.2007.07.002
   Koutsonikolas D, 2012, IEEE ACM T NETWORK, V20, P1375, DOI 10.1109/TNET.2011.2177274
   Laneman J.Nicholas., 2000, PROC ALLERTON C COMM
   Laufer R, 2012, IEEE ACM T NETWORK, V20, P742, DOI 10.1109/TNET.2011.2165852
   Le T, 2010, GLOB TELECOMM CONF
   Li CL, 2018, IEEE T MULTIMEDIA, V20, P361, DOI 10.1109/TMM.2017.2745709
   Li LQ, 2022, COMPUT COMMUN, V181, P357, DOI 10.1016/j.comcom.2021.10.030
   Li P, 2012, IEEE INFOCOM SER, P100, DOI 10.1109/INFCOM.2012.6195456
   Mammeri Z, 2019, IEEE ACCESS, V7, P55916, DOI 10.1109/ACCESS.2019.2913776
   Qabajeh LK., 2021, INT J ELECT ELECT EN, V10, P341
   Qin X, 2022, INFECT CONT HOSP EP, V43, P401, DOI 10.1017/ice.2020.1433
   Rozner E, 2009, IEEE T MOBILE COMPUT, V8, P1622, DOI 10.1109/TMC.2009.82
   Singh D, 2020, INT J ELECTRON, V107, P1963, DOI 10.1080/00207217.2020.1756444
   Sudhakar BS, 2019, J HIGH ENERGY PHYS, P0731
   Tang K., 2017, IEEE 19th International Workshop on Multimedia Signal Processing (MMSP), P1, DOI [DOI 10.1109/MMSP.2017.8122255, DOI 10.1109/ICSSSM.2017.7996286, 10.1109/ ICSSSM.2017.7996286]
   Yang WZ, 2010, 2010 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, NETWORKING AND INFORMATION SECURITY (WCNIS), VOL 2, P540, DOI 10.1109/WCINS.2010.5544144
   Zeng K, 2007, MOBILE NETW APPL, V12, P347, DOI 10.1007/s11036-008-0051-7
   Zhao J, 2006, IEEE T MULTIMEDIA, V8, P1021, DOI 10.1109/TMM.2006.879847
   US
NR 29
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26613
EP 26630
DI 10.1007/s11042-023-14645-1
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000946494700016
DA 2024-07-18
ER

PT J
AU da Silveira, AC
   Rodrigues, EC
   Saleme, EB
   Covaci, A
   Ghinea, G
   Santos, CAS
AF da Silveira, Aleph Campos
   Rodrigues, Eduardo C.
   Saleme, Estevao B.
   Covaci, Alexandra
   Ghinea, Gheorghita
   Santos, Celso A. S.
TI Thermal and wind devices for multisensory human-computer interaction: an
   overview
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Thermal devices; Wind; Virtual reality; Multisensory technology;
   Human-computer interaction
ID MULSEMEDIA; FUTURE; SENSE; SMELL
AB In order to create immersive experiences in virtual worlds, we need to explore different human senses (sight, hearing, smell, taste, and touch). Many different devices have been developed by both industry and academia towards this aim. In this paper, we focus our attention on the researched area of thermal and wind devices to deliver the sensations of heat and cold against people's skin and their application to human-computer interaction (HCI). First, we present a review of devices and their features that were identified as relevant. Then, we highlight the users' experience with thermal and wind devices, highlighting limitations either found or inferred by the authors and studies selected for this survey. Accordingly, from the current literature, we can infer that, in wind and temperature-based haptic systems (i) users experience wind effects produced by fans that move air molecules at room temperature, and (ii) there is no integration of thermal components to devices intended for the production of both cold or hot airflows. Subsequently, an analysis of why thermal wind devices have not been devised yet is undertaken, highlighting the challenges of creating such devices.
C1 [da Silveira, Aleph Campos; Rodrigues, Eduardo C.; Saleme, Estevao B.; Santos, Celso A. S.] Univ Fed Espirito Santo, Vitoria, ES, Brazil.
   [Covaci, Alexandra] Univ Kent, Canterbury, England.
   [Ghinea, Gheorghita] Brunel Univ London, London, England.
C3 Universidade Federal do Espirito Santo; University of Kent; Brunel
   University
RP da Silveira, AC (corresponding author), Univ Fed Espirito Santo, Vitoria, ES, Brazil.
EM aleph.campos@gmail.com; eduardo.rodrigues17@gmail.com;
   estevaobissoli@gmail.com; a.covaci@kent.ac.uk;
   george.ghinea@brunel.ac.uk; saibel@inf.ufes.br
RI SANTOS, CELSO Alberto Saibel/M-9733-2014; Saleme, Estevao
   B./AAZ-7161-2020
OI SANTOS, CELSO Alberto Saibel/0000-0002-3287-5843; Saleme, Estevao
   B./0000-0003-1856-3824; Covaci, Alexandra/0000-0002-3205-2273; Ghinea,
   Gheorghita/0000-0003-2578-5580; Campos da Silveira,
   Aleph/0000-0001-9465-4280
FU Espirito Santo Research and Innovation Foundation (FAPES, Brazil)
   [2021-GL60J]; Coordination for the Improvement of Higher Education
   Personnel (CAPES, Brazil) [88881.187844/2018-01, 88887.570688/2020-00];
   National Council for Scientific and Technological (CNPq, Brazil)
   [307718/2020-4]; European Union's Horizon 2020 Research and Innovation
   programme [688503]
FX This study was financed in part by the Espirito Santo Research and
   Innovation Foundation (FAPES, Brazil) - Finance Code 2021-GL60J), the
   Coordination for the Improvement of Higher Education Personnel (CAPES,
   Brazil) - Finance Code 88881.187844/2018-01 and 88887.570688/2020-00 and
   by the National Council for Scientific and Technological (CNPq, Brazil)
   - Finance Code 307718/2020-4. The work was also funded by the European
   Union's Horizon 2020 Research and Innovation programme under Grant
   Agreement no. 688503. E. B. Saleme additionally acknowledges aid from
   the Federal Institute of Espirito Santo.
CR Ademoye OA, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2487268.2487270
   Billinghurst M, 1999, COMPUTER, V32, P57, DOI 10.1109/2.738305
   Brooks J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376806
   Cai SY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P248, DOI [10.1109/VR46266.2020.1580801081068, 10.1109/VR46266.2020.00-60]
   Cardenas S, 2007, PA STUD HUM RIGHTS, P101
   Celestrini J, 2021, P 1 WORKSHOP MULTISE, DOI [10.5753/sensoryx.2021.15685, DOI 10.5753/SENSORYX.2021.15685]
   Vi CT, 2018, 3RD WORKSHOP ON MULTISENSORY APPROACHES TO HUMAN-FOOD INTERACTION (MHFI), DOI 10.1145/3279954.3279955
   Chu JH, 2016, DIS 2016: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P1294, DOI 10.1145/2901790.2901829
   Claisse C, 2018, P 2018 DIGITAL HERIT
   Covaci A, 2018, MULTIMED TOOLS APPL, P1
   Covaci A, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2378, DOI 10.1145/3343031.3350954
   De Barros P.G., 2013, Proceedings of the 1st symposium on Spatial user interaction, P41, DOI DOI 10.1145/2491367.2491371
   Dinh HQ, 1999, P IEEE VIRT REAL ANN, P222, DOI 10.1109/VR.1999.756955
   El Ali A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376682
   Ghinea G, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2617994
   Grant MJ, 2009, HEALTH INFO LIBR J, V26, P91, DOI 10.1111/j.1471-1842.2009.00848.x
   Han PH, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P247, DOI [10.1109/WHC.2019.8816140, 10.1109/whc.2019.8816140]
   Han PH, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281507
   Hojatmadani M, 2017, HEAT TRANSFER THERMA, V11, DOI [10.1115/IMECE2017-71995, DOI 10.1115/IMECE2017-71995]
   Hulsmann F, 2014, J VIRTUAL REALITY BR, V11
   Ke PC, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365718
   Kim S, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188656
   Klasnja-Milicevic A, 2019, ADV INTELL SYST, V804, P213, DOI 10.1007/978-3-319-98872-6_25
   Lipanov D, 2015, KICKSTARTER PROJECT
   Martins J, 2017, J DESTIN MARK MANAGE, V6, P103, DOI 10.1016/j.jdmm.2017.02.002
   Matsukura H, 2011, P IEEE VIRT REAL ANN, P119, DOI 10.1109/VR.2011.5759448
   Melo M, 2022, IEEE T VIS COMPUT GR, V28, P1428, DOI 10.1109/TVCG.2020.3010088
   Mi Feng, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P149, DOI 10.1109/3DUI.2015.7131744
   Moon T., 2004, 11 ACM S VIRTUAL REA, P122, DOI [10.1145/1077534.1077558, DOI 10.1145/1077534.1077558]
   Nakajima M, 2020, IEEE/SICE I S SYS IN, P1238, DOI [10.1109/sii46433.2020.9025959, 10.1109/SII46433.2020.9025959]
   Nakatani M, 2018, LECT NOTES ELECTR EN, V432, P437, DOI 10.1007/978-981-10-4157-0_73
   Narciso D, 2020, ACM T APPL PERCEPT, V17, DOI 10.1145/3380903
   Narumi T, 2009, LECT NOTES COMPUT SC, V5622, P355, DOI 10.1007/978-3-642-02771-0_40
   Niijima A, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382849
   Peiris RL, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5452, DOI 10.1145/3025453.3025824
   Peiris RL, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300400
   Petit O., 2018, Springer eBooks, P349, DOI [https://doi.org/10.1007/978-3-319-94977-2_13, DOI 10.1007/978-3-319-94977-2_13]
   Petit O, 2019, J INTERACT MARK, V45, P42, DOI 10.1016/j.intmar.2018.07.004
   Philips, 2015, PHIL AMBX GAM PC PER
   Pusch Andreas, 2011, P 13 INT C MULT INT, P57, DOI [10.1145/2070481.2070494, DOI 10.1145/2070481.2070494]
   Rainer B, 2012, INT WORK QUAL MULTIM, P278, DOI 10.1109/QoMEX.2012.6263842
   Ramalho J., 2013, P 11 EUROPEAN C INTE, P107, DOI DOI 10.1145/2465958.2465969
   Ranasinghe N, EXTENDED ABSTRACTS 2, DOI [10.1145/3170427.3186513, DOI 10.1145/3170427.3186513]
   Ranasinghe N, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186513
   Ranasinghe N, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1731, DOI 10.1145/3025453.3025723
   Rheiner M., 2014, ACM SIGGRAPH 2014 Emerging Technologies, P3, DOI DOI 10.1145/2614066.2614101
   Rodrigues EC, 2021, PROCEEDINGS OF THE 27TH BRAZILIAN SYMPOSIUM ON MULTIMEDIA AND THE WEB (WEBMEDIA '21), P73, DOI 10.1145/3470482.3479638
   SA S, 2019, BIRDLY VR FULLY IMME
   Saleme EB, 2019, THESIS FEDERAL U ESP, V12
   Saleme EB, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3319853
   Saleme EB, 2018, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON MANAGEMENT OF DIGITAL ECOSYSTEMS (MEDES'18), P23, DOI 10.1145/3281375.3281378
   Saleme EB, 2019, MULTIMEDIA SYST, V25, P421, DOI 10.1007/s00530-019-00618-8
   Saleme EB, 2019, IEEE MULTIMEDIA, V26, P66, DOI 10.1109/MMUL.2018.2873565
   Seneviratne S, 2017, IEEE COMMUN SURV TUT, V19, P2573, DOI 10.1109/COMST.2017.2731979
   Serrano B, 2016, COMPUT HUM BEHAV, V55, P1, DOI 10.1016/j.chb.2015.08.007
   Shaw E, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300856
   Soucy N, 2020, P FUTURE TECHNOLOGIE, P809, DOI [10.1007/978-3-030-63089-8_53, DOI 10.1007/978-3-030-63089-8_53]
   Spence C, 2019, FOOD QUAL PREFER, V71, P106, DOI 10.1016/j.foodqual.2018.06.010
   Spencer BS, 2006, IEEE T INF TECHNOL B, V10, P168, DOI 10.1109/TITB.2005.856851
   Stone RJ, 2017, J ROY ARMY MED CORPS, V163, P280, DOI 10.1136/jramc-2016-000726
   Suhaimi NS, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8875426
   Sulema Y, 2016, INT CONF SYST SIGNAL, P19
   Tal I, 2019, IEEE COMMUN MAG, V57, P60, DOI 10.1109/MCOM.001.1900241
   Tolley D, 2019, P 13 INT C TANG EMB, DOI [10.1145/3294109.3295624, DOI 10.1145/3294109.3295624]
   van der Meulen E, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P102, DOI [10.1109/ISMAR-Adjunct.2016.0050, 10.1109/ISMAR-Adjunct.2016.43]
   Waltl M, 2013, SIGNAL PROCESS-IMAGE, V28, P136, DOI 10.1016/j.image.2012.10.009
   Waltl M, 2012, INT WORK QUAL MULTIM, P115, DOI 10.1109/QoMEX.2012.6263841
   Wettach R., 2007, P 9 INT C HUM COMP I, P182, DOI [10.1145/1377999.1378004, DOI 10.1145/1377999.1378004]
   Wilberz A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376481
   Wilson G, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2555
   Wnuk E, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01373
   Xu JY, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P133, DOI [10.1109/whc.2019.8816089, 10.1109/WHC.2019.8816089]
   Yecies B, 2016, MEDIA INT AUST, V159, P22, DOI 10.1177/1329878X16640104
   Zou LH, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P315, DOI 10.1145/3083187.3084014
NR 74
TC 1
Z9 1
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34485
EP 34512
DI 10.1007/s11042-023-14672-y
EA MAR 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000945313000003
OA Green Accepted, hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Demiroglu, U
   Senol, B
   Yildirim, M
   Eroglu, Y
AF Demiroglu, Ugur
   Senol, Bilal
   Yildirim, Muhammed
   Eroglu, Yesim
TI Classification of computerized tomography images to diagnose non-small
   cell lung cancer using a hybrid model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Deep learning; Classifiers; Neighborhood
   component analysis; Lung cancer
AB Lung cancer arises from the abnormal and uncontrolled reproduction of parenchymal cells. Among all cancer cases, lung cancer is one of the prevailing types. Prevalence and death rates of the cancer increases day by day. From this point of view, early diagnosis and treatment of this cancer increases survival times and rates. The main idea in the development of the method presented in this publication is to increase the rate of early diagnosis. Computerized Tomography (CT) is the major screening method when encountered with suspicious symptoms. The cancer can be determined with CT and besides subtyping can be done. Diagnosing the disease with the human eye can sometimes lead to the emergence of deficiencies. This is one of the problems faced today. In this direction, the study in this paper presents a hybrid method to predict and diagnose the lung cancer from CT images to minimize potential human errors. Using the method, feature maps of the CT images of the dataset are obtained using the previously trained DarkNet-53 and DenseNet-201 deep model architectures. DarkNet-53 and DenseNet-201 architectures were chosen because they gave the best feature extraction results among 7 different architectures. The purpose of using the two architectures is to combine two high-performance models to create a hybrid classification method with high accuracy. Feature concatenation is applied to increase the diagnosis accuracy. To optimize the performance and computation cost of the proposed method, the Neighborhood Component Analysis (NCA) optimization method is used in determining and analysis of the features with more information. Therefore, features with less contribution in the accuracy are eliminated. Next, new feature maps are achieved by grading all features upon their weights and applying an elimination using a threshold value. The new feature maps are classified using Classical Machine Learning (CML) classifiers. Classification accuracies on DarkNet-53 architecture were calculated as 69.11% with SoftMax and 96.25% with Ensemble Classifiers and Nearest Neighbor Classifiers respectively. Similarly, accuracies on DenseNet-201 architecture were calculated as 68.29% with SoftMax and 97.39% with Ensemble Classifiers and Nearest Neighbor Classifiers respectively. With the proposed hybrid model, the Ensemble Classifiers reached the accuracy of 98.69% and the highest accuracy is achieved by using k-Nearest Neighbor Classifier (kNN) with the value of 98.86%. The results are supported with detailed illustrations.
C1 [Demiroglu, Ugur] Firat Univ, Tech Vocat Sch, Comp Sci Dept, Elazig, Turkiye.
   [Senol, Bilal] Aksaray Univ, Fac Engn, Software Engn Dept, Aksaray, Turkiye.
   [Yildirim, Muhammed] Malatya Turgut Ozal Univ, Fac Engn & Nat Sci, Comp Engn Dept, Malatya, Turkiye.
   [Eroglu, Yesim] Firat Univ, Sch Med, Radiol Dept, Elazig, Turkiye.
C3 Firat University; Aksaray University; Malatya Turgut Ozal University;
   Firat University
RP Demiroglu, U (corresponding author), Firat Univ, Tech Vocat Sch, Comp Sci Dept, Elazig, Turkiye.
EM ugurdemiroglu@firat.edu.tr
RI SENOL, Bilal/Y-5328-2018; YILDIRIM, Muhammed/AAK-6342-2021; Demiroglu,
   Ugur/W-2298-2018
OI YILDIRIM, Muhammed/0000-0003-1866-4721; Demiroglu,
   Ugur/0000-0002-0000-8411
CR Bentoumi M, 2022, MULTIMED TOOLS APPL, V81, P29887, DOI 10.1007/s11042-022-12058-0
   Blanc-Durand P, 2020, EUR RADIOL, V30, P3528, DOI 10.1007/s00330-019-06630-w
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chaunzwa TL, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84630-x
   Cheong KH, 2021, BIOCYBERN BIOMED ENG, V41, P997, DOI 10.1016/j.bbe.2021.05.010
   Cinar A, 2021, TRAIT SIGNAL, V38, P165, DOI 10.18280/ts.380117
   Çinar A, 2020, MED HYPOTHESES, V139, DOI 10.1016/j.mehy.2020.109684
   Clark SB., 2022, STATPEARLS
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   D'Arnese E, 2022, IEEE J BIOMED HEALTH, V26, P2670, DOI 10.1109/JBHI.2022.3156984
   Dewi C, 2020, MULTIMED TOOLS APPL, V79, P32897, DOI 10.1007/s11042-020-09509-x
   DUMA N, 2019, MAYO CLIN PROC, V94, P1623, DOI [DOI 10.1016/J.MAYOCP.2019.01.013, DOI 10.1016/J.MAY0CP.2019.01.013]
   Eroglu Y, 2021, COMPUT BIOL MED, V133, DOI 10.1016/j.compbiomed.2021.104407
   Globerson A., 2005, Advances in neural information processing systems, P451, DOI DOI 10.5555/2976248.2976305
   Goel N, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103624
   Goel N, 2022, SOFT COMPUT, V26, P1231, DOI 10.1007/s00500-021-06546-y
   Goldberger J., 2004, P 17 INT C NEUR INF, P513
   Gudigar A, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102733
   Guo HF, 2017, MULTIMED TOOLS APPL, V76, P14581, DOI 10.1007/s11042-016-3802-7
   Han Y, 2021, EUR J NUCL MED MOL I, V48, P350, DOI 10.1007/s00259-020-04771-5
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hintze C, 2011, RADIOLOGE, V51, P135, DOI 10.1007/s00117-010-2112-8
   Hofman P, 2017, CANCERS, V9, DOI 10.3390/cancers9080107
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang WC, 2022, FRONT PHARMACOL, V13, DOI 10.3389/fphar.2022.898529
   Imyanitov EN, 2021, CRIT REV ONCOL HEMAT, V157, DOI 10.1016/j.critrevonc.2020.103194
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Kar MK., 2021, SN Computer Sci, V2, P397, DOI DOI 10.1007/S42979-021-00784-5
   Klecka W.R., 1980, DISCRIMINANT ANAL, P07, DOI [10.4135/9781412983938, DOI 10.4135/9781412983938]
   Koh JEW, 2021, COMPUT METH PROG BIO, V203, DOI 10.1016/j.cmpb.2021.106010
   Kohavi R., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P202
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai YH, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-61588-w
   Lanjewar MG, 2022, MULTIMED TOOLS APPL, V81, P10313, DOI 10.1007/s11042-022-12200-y
   Le T, 2017, SEMIN CANCER BIOL, V42, P81, DOI 10.1016/j.semcancer.2016.08.007
   Ma Serie, 2022, [Journal of the Korea Computer Graphics Society, 한국컴퓨터그래픽스학회논문지], V28, P1, DOI 10.15701/kcgs.2022.28.1.1
   Malan NS, 2019, COMPUT BIOL MED, V107, P118, DOI 10.1016/j.compbiomed.2019.02.009
   Marentakis P, 2021, MED BIOL ENG COMPUT, V59, P215, DOI 10.1007/s11517-020-02302-w
   Oudkerk M, 2021, NAT REV CLIN ONCOL, V18, P135, DOI 10.1038/s41571-020-00432-6
   QUINLAN JR, 1990, IEEE T SYST MAN CYB, V20, P339, DOI 10.1109/21.52545
   Rankin NM, 2020, RESPIROLOGY, V25, P5, DOI 10.1111/resp.13963
   Ravenel JG, 2012, J THORAC IMAG, V27, P315, DOI 10.1097/RTI.0b013e318254a198
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Shankar DD, 2021, MULTIMED TOOLS APPL, V80, P4073, DOI 10.1007/s11042-020-09820-7
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Song MJ, 2020, TRANSL LUNG CANCER R, V9, P659, DOI 10.21037/tlcr-19-589
   Song ZB, 2021, EUR J NUCL MED MOL I, V48, P361, DOI 10.1007/s00259-020-04986-6
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tian PW, 2021, THERANOSTICS, V11, P2098, DOI 10.7150/thno.48027
   Wang HK, 2017, EJNMMI RES, V7, DOI 10.1186/s13550-017-0260-9
   Wang R., 2021, EAI ENDORSED T LEARN, V7, DOI [10.4108/eai.11-8-2021.170669, DOI 10.4108/EAI.11-8-2021.170669]
   Wang SH, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3341095
   Wu JH, 2015, MULTIMED TOOLS APPL, V74, P10697, DOI 10.1007/s11042-014-2199-4
   Yang XY, 2022, EUR RADIOL, V32, P2693, DOI 10.1007/s00330-021-08366-y
   Yildirim Muhammed, 2019, Revue d'Intelligence Artificielle, V33, P335, DOI 10.18280/ria.330502
   Yildirim M, 2022, CURR PSYCHOL, V41, P7812, DOI 10.1007/s12144-020-01244-8
   Zachara-Szczakowski S, 2015, HUM PATHOL, V46, P776, DOI 10.1016/j.humpath.2015.02.001
   Zhang JG, 2020, CANCER CELL INT, V20, DOI 10.1186/s12935-020-01429-y
   Zhang X, 2022, 2022 4 INT C INTELLI, DOI [10.1145/3524086.3524103, DOI 10.1145/3524086.3524103]
   US
NR 64
TC 3
Z9 3
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 33379
EP 33400
DI 10.1007/s11042-023-14943-8
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943970200009
DA 2024-07-18
ER

PT J
AU Nanda, SK
   Panda, SK
   Dash, M
AF Nanda, Saroj Kumar
   Panda, Sandeep Kumar
   Dash, Madhabananda
TI Medical supply chain integrated with blockchain and IoT to track the
   logistics of medical products
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Supply chain management; IoT; Medical logistics; Trust;
   Security; Traceability; Healthcare system
ID THINGS IOT; INTERNET; FRAMEWORK
AB Nowadays blockchain technology plays a vital role in creative developments and important discoveries in the world. Blockchain develops secure and trustworthy platforms for data sharing in various application areas such as secure sharing of medical data, Anti-money laundering, tracking systems, Supply chain, and logistics monitoring, Crypto-currency exchange, etc. Today's Supply chain in the healthcare sector faces many problems like security, transparency, tampering with medical products, counterfeit drugs, more paperwork, high cost, and more time-consuming process while transporting medical equipment from manufacture to end-users. To overcome these problems, we introduce Novel Approach for Integrated IoT (Internet of Things) With Blockchain in Health Supply Chain (NAIBHSC) approach. By using this approach, we can eliminate all supply chain-related issues between suppliers and end-users. The goal of this research is by combining Blockchain technology with IoT to develop a smart health supply chain management system. This approach provides security, privacy, trust, visibility, decentralized tracking and tracing of the medical product, avoids counterfeit drugs, avoids the damage to medical components, authentication, reduces the cost, and provides the status of the products during the shipment process between manufacturers to end-user. In this approach, we conduct a series of experiments on a different group of users. The experimental results show that compare to existing approaches our proposed NAIBHSC approach gives better response time that is the average Transaction Per Second (TPS) for a group of 500 users is 100 milliseconds, reduces the latency time that is average latency time for 500 users group has 403 milliseconds, and improves the overall performance of the smart health supply chain management system.
C1 [Nanda, Saroj Kumar; Dash, Madhabananda] KIIT Deemed Univ, Sch Comp Engn, Bhubaneswar, Orissa, India.
   [Panda, Sandeep Kumar] ICFAI Fdn Higher Educ, Fac Sci & Technol IcfaiTech, Dept Data Sci & Artificial Intelligence, Hyderabad, Telangana, India.
C3 Kalinga Institute of Industrial Technology (KIIT); The ICFAI Foundation
   for Higher Education (IFHE)
RP Nanda, SK (corresponding author), KIIT Deemed Univ, Sch Comp Engn, Bhubaneswar, Orissa, India.
EM sarojkumarnanda1979@gmail.com; skpanda00007@gmail.com;
   mndas_prof@kiit.ac.in
RI Panda, Sandeep Kumar/AAU-1903-2021
OI Panda, Sandeep Kumar/0000-0002-0752-4267; Nanda, Saroj
   Kumar/0000-0002-0227-5492
CR Abdel-Basset M, 2018, FUTURE GENER COMP SY, V86, P614, DOI 10.1016/j.future.2018.04.051
   Abu-elezz I, 2020, INT J MED INFORM, V142, DOI 10.1016/j.ijmedinf.2020.104246
   Agbo CC, 2019, HEALTHCARE-BASEL, V7, DOI 10.3390/healthcare7020056
   Alizadeh M, 2020, COMPUT IND ENG, V140, DOI 10.1016/j.cie.2019.106229
   Ben Fekih Rim, 2020, Impact of Digital Technologies on Public Health in Developed and Developing Countries. 18th International Conference, ICOST 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12157), P268, DOI 10.1007/978-3-030-51517-1_23
   Bocek Thomas, 2017, 2017 IFIP/IEEE Symposium on Integrated Network and Service Management (IM), P772, DOI 10.23919/INM.2017.7987376
   Bryatov S., 2019, INT C INFORM TECHNOL
   Chang SE, 2019, TECHNOL FORECAST SOC, V144, P1, DOI 10.1016/j.techfore.2019.03.015
   Costa C, 2013, FOOD BIOPROCESS TECH, V6, P353, DOI 10.1007/s11947-012-0958-7
   Datta S, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03591-1
   Datta S, 2021, PEER PEER NETW APPL, V14, P3688, DOI 10.1007/s12083-021-01187-2
   Ding BY, 2018, PROCESS SAF ENVIRON, V119, P115, DOI 10.1016/j.psep.2018.06.031
   Dwivedi SK, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102554
   Faulkner C, 2020, WHAT IS NFC EVERYTHI
   Fernando E., 2019, 2019 6th International Conference on Information Technology, Computer and Electrical Engineering (ICITACEE), P1, DOI DOI 10.1109/ICITACEE.2019.8904335
   Gan C., 2020, MULTIMED TOOLS APPL, P1, DOI DOI 10.1007/S11042-020-09322-6
   Geneva: World Health Organization, 2017, STUD PUBL HLTH SOC I
   Goodarzian F, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104188
   Huang Y, 2018, 2018 IEEE CONFS INTE, DOI [10.1016/j.psep.2018.06.031, DOI 10.1016/J.PSEP.2018.06.031]
   Humayun Mamoona, 2020, IEEE Internet of Things Magazine, V3, P58, DOI 10.1109/IOTM.0001.1900097
   Jamil F, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8050505
   Jayaraman R, 2019, INT J HEALTHC INF SY, V14, P49, DOI 10.4018/IJHISI.2019040104
   Jenkins R, 2020, SMART TRACK
   Khatoon A, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010094
   Khezr S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9091736
   Koh L, 2020, INT J PROD RES, V58, P2054, DOI 10.1080/00207543.2020.1736428
   Kuandeet W, 2019, INT J ONLINE BIOMED, V15, P4, DOI 10.3991/ijoe.v15i03.8533
   Kumar SG, 2021, INT CO SIG PROC COMM, P757, DOI 10.1109/ICSPC51351.2021.9451700
   Kuo TT, 2017, J AM MED INFORM ASSN, V24, P1211, DOI 10.1093/jamia/ocx068
   Manavalan E, 2019, COMPUT IND ENG, V127, P925, DOI 10.1016/j.cie.2018.11.030
   McGhin T, 2019, J NETW COMPUT APPL, V135, P62, DOI 10.1016/j.jnca.2019.02.027
   Musamih A, 2021, IEEE ACCESS
   Panda Sandeep Kumar, 2024, Personal and Ubiquitous Computing, V28, P75, DOI 10.1007/s00779-021-01588-3
   Panda S.K., 2021, DATA ENG INTELLIGENT, P549, DOI [10.1007/978-981-16-0171-2_52, DOI 10.1007/978-981-16-0171-2_52]
   Raj R, 2019, TENCON IEEE REGION, P1572, DOI [10.1109/TENCON.2019.8929271, 10.1109/tencon.2019.8929271]
   Singh AP, 2021, IEEE T IND INFORM, V17, P5779, DOI 10.1109/TII.2020.3037889
   Singh B, 2020, PROC INT C INNOV COM, DOI [10.2139/ssrn.3565930, DOI 10.2139/SSRN.3565930]
   Singh RK, 2020, J GLOB OPER STRATEG, V13
   Sinha D, 2019, ADV INTELL SYST COMP, P133, DOI DOI 10.1007/978-3-030-39875-0_14
   Tijan E, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11041185
   Tseng JH, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15061055
   Xu QQ, 2018, MULTIMED TOOLS APPL, V77, P18223, DOI 10.1007/s11042-017-5224-6
   Yli-Huumo J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163477
NR 43
TC 22
Z9 22
U1 11
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32917
EP 32939
DI 10.1007/s11042-023-14846-8
EA MAR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943638900003
PM 37362711
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Liu, X
   Lin, S
   Tao, ZY
AF Liu, Xu
   Lin, Sen
   Tao, Zhiyong
TI Learning multiscale pipeline gated fusion for underwater image
   enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater image enhancement; Multiscale feature extraction; Gated
   fusion; MS-SSIM loss; Conditional GAN
ID QUALITY; NETWORK
AB Evidence suggests that vision is among the most critical factors in marine information exploration. Instead, underwater images are generally poor quality due to color casts, lack of texture details, and blurred edges. Therefore, we propose the Multiscale Gated Fusion conditional GAN (MGF-cGAN) for underwater image enhancement. The generator of MGF-cGAN consists of Multiscale Feature Extract Module (Ms-FEM) and Gated Fusion Module (GFM). In Ms-FEM, we use three different parallel subnets to extract feature information, which can extract richer features than a single branch. The GFM can adaptively fuse the three outputs from Ms-FEM. GFM generates better chromaticity and contrast than other fusion ways. Additionally, we add the Multiscale Structural Similarity Index Measure (MS-SSIM) loss to train the network, which is highly similar to human perception. Extensive experiments across three benchmark underwater image datasets corroborate that MGF-cGAN can generate images with better visual perception than classical and State-Of-The-Art (SOTA) methods. It achieves 27.1078dB PSNR and 11.9437 RMSE on EUVP dataset. More significantly, enhanced results of MGF-cGAN also provide excellent performance in underwear saliency detection, SURF key matching test, and so on. Based on this study, MGF-cGAN is found to be suitable for data preprocessing in an underwater multimedia system.
C1 [Liu, Xu] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230601, Peoples R China.
   [Lin, Sen] Shenyang Ligong Univ, Sch Automation & Elect Engn, Shenyang 110159, Peoples R China.
   [Tao, Zhiyong] Liaoning Tech Univ, Sch Elect & Informat Engn, Huludao 125105, Peoples R China.
C3 Hefei University of Technology; Shenyang Ligong University; Liaoning
   Technical University
RP Lin, S (corresponding author), Shenyang Ligong Univ, Sch Automation & Elect Engn, Shenyang 110159, Peoples R China.
EM dalong.xu.liu@ieee.org; lin_sen6@126.com; xyzmail@126.com
OI Lin, Sen/0000-0003-2051-3500; Liu, Xu/0000-0001-9916-0968
FU National Key Research and Development Program of China [2018YFB1403303];
   Key Research and Development Program of Liaoning Province
   [2019JH2/10100014]
FX AcknowledgementsThis work is supported by the National Key Research and
   Development Program of China under Grant (No. 2018YFB1403303), the Key
   Research and Development Program of Liaoning Province under Grant (No.
   2019JH2/10100014).
CR Ahn J, 2020, IEEE J OCEANIC ENG, V45, P350, DOI 10.1109/JOE.2018.2872500
   Anwar S, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115978
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chen XY, 2019, IEEE T IND ELECTRON, V66, P9350, DOI 10.1109/TIE.2019.2893840
   Fan GF, 2021, UTIL POLICY, V73, DOI 10.1016/j.jup.2021.101294
   Fazlali H, 2020, MULTIMED TOOLS APPL, V79, P29493, DOI 10.1007/s11042-020-09383-7
   Feng XM, 2020, MULTIMED TOOLS APPL, V79, P32973, DOI 10.1007/s11042-020-09562-6
   Fu XY, 2020, SIGNAL PROCESS-IMAGE, V86, DOI 10.1016/j.image.2020.115892
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   [郭继昌 Guo Jichang], 2017, [中国图象图形学报, Journal of Image and Graphics], V22, P273
   Guo YC, 2020, IEEE J OCEANIC ENG, V45, P862, DOI 10.1109/JOE.2019.2911447
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Huang DM, 2018, LECT NOTES COMPUT SC, V10704, P453, DOI 10.1007/978-3-319-73603-7_37
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang KQ, 2006, COMPUT VIS IMAGE UND, V103, P52, DOI 10.1016/j.cviu.2006.02.007
   Huang YF, 2021, SIGNAL PROCESS-IMAGE, V93, DOI 10.1016/j.image.2021.116174
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Gulrajani I, 2017, ADV NEUR IN, V30
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   JAFFE JS, 1990, IEEE J OCEANIC ENG, V15, P101, DOI 10.1109/48.50695
   Li C, 2016, IEEE INT SEMICONDUCT
   Li CY, 2021, IEEE T IMAGE PROCESS, V30, P4985, DOI 10.1109/TIP.2021.3076367
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li HY, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116248
   Li RD, 2018, PROC CVPR IEEE, P8202, DOI 10.1109/CVPR.2018.00856
   Li SW, 2022, MULTIMED TOOLS APPL, V81, P4935, DOI 10.1007/s11042-021-11269-1
   Liu P, 2019, IEEE ACCESS, V7, P94614, DOI 10.1109/ACCESS.2019.2928976
   McGlamery B. L., 1979, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V208, P221
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Naga Srinivasu P., 2021, BIOINSPIRED NEUROCOM, P1
   Pan PW, 2018, J MAR SCI TECH-TAIW, V26, P531, DOI 10.6119/JMST.201808_26(4).0006
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Rahman ZU, 2004, J ELECTRON IMAGING, V13, P100, DOI 10.1117/1.1636183
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Sharma T, 2020, MULTIMED TOOLS APPL, V79, P30769, DOI 10.1007/s11042-020-09496-z
   Shen PY, 2021, MULTIMED TOOLS APPL, V80, P28087, DOI 10.1007/s11042-021-10888-y
   Sun X, 2019, IET IMAGE PROCESS, V13, P469, DOI 10.1049/iet-ipr.2018.5237
   Tsai DY, 2008, J DIGIT IMAGING, V21, P338, DOI 10.1007/s10278-007-9044-5
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang Y, 2017, IEEE IMAGE PROC, P1382, DOI 10.1109/ICIP.2017.8296508
   Wang YB, 2021, MULTIMED TOOLS APPL, V80, P32539, DOI 10.1007/s11042-021-11209-z
   Wang YD, 2021, SIGNAL PROCESS-IMAGE, V96, DOI 10.1016/j.image.2021.116250
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu Q, 2021, MULTIMED TOOLS APPL, V80, P29985, DOI 10.1007/s11042-021-11200-8
   Yang M, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115723
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Yu XL, 2019, LECT NOTES COMPUT SC, V11188, P66, DOI 10.1007/978-3-030-05792-3_7
   Yuan Q, 2020, VISUAL COMPUT, V36, P1591, DOI 10.1007/s00371-019-01762-y
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407
   Zhou JC, 2022, MULTIMED TOOLS APPL, V81, P1811, DOI 10.1007/s11042-021-11327-8
   Zong XH, 2021, APPL INTELL, V51, P1947, DOI 10.1007/s10489-020-01931-w
NR 55
TC 2
Z9 2
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32281
EP 32304
DI 10.1007/s11042-023-14687-5
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000942756000001
DA 2024-07-18
ER

PT J
AU Lamba, M
   Munjal, G
   Gigras, Y
   Kumar, M
AF Lamba, Monika
   Munjal, Geetika
   Gigras, Yogita
   Kumar, Manoj
TI Breast cancer prediction and categorization in the molecular era of
   histologic grade
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature selection; Histologic grade; Breast cancer; Consistency;
   Correlation; Best-first search; Gene; CFS; Kaplan Meier; Overall
   survival
ID SELECTION; SURVIVAL; FEATURES
AB Breast cancer is the second utmost common cancer among women. In this research study, two feature selection methods, namely Consistency first Search-Best First search (CFS-BFS) and Consistency-Best First Search (Consistency-BFS) are used to find out the significant biomarkers for breast cancer. The feature selection methods pick a small count of important and relevant genes providing a higher degree of accuracy. The count of biomarkers selected in Consistency-BFS is less in comparison to CFS-BFS method. Three common identified biomarkers' genes are recognised to help in diagnosis and prognosis of breast cancer, namely SLC39A6, ESR1, and CDC20 are selected on the basis of histologic-grade and molecular subtype of breast cancer. These three genes identified are even found in PAM50 and judged for survival variances using Kaplan-Meier Survival Model. The result suggested that overexpression of SLC39A6, ESR1, and CDC20 proves to be an influencing factor for the poor prognosis of patients suffering from breast cancer. The proposed method is successful in creating a prognostic gene signature in forecasting the survival likelihood of patients.
C1 [Lamba, Monika; Gigras, Yogita] NorthCap Univ, Gurugram, India.
   [Munjal, Geetika] Amity Univ, Noida, UP, India.
   [Kumar, Manoj] Univ Wollongong Dubai, Fac Engn & Informat Sci, Dubai Knowledge Pk, Dubai, U Arab Emirates.
   [Kumar, Manoj] Middle East Univ, Fac Informat Technol, Amman 11831, Jordan.
C3 The Northcap University; Amity University Noida; University of
   Wollongong; Middle East University
RP Munjal, G (corresponding author), Amity Univ, Noida, UP, India.
EM missmonikalamba@gmail.com; munjal.geetika@gmail.com;
   yogitagigras@ncuindia.edu; Wss.manojkumar@gmail.co
RI Munjal, Geetika/ABE-8000-2020; Lamba, Monika/GON-6740-2022; Kumar,
   Manoj/AAL-6474-2021
OI Munjal, Geetika/0000-0001-5213-9993; Lamba, Monika/0000-0003-1695-9614;
   Kumar, Manoj/0000-0003-3733-295X
CR Alfarsi LH, 2019, BREAST CANCER RES TR, V178, P535, DOI 10.1007/s10549-019-05420-8
   Allaire J., 2012, R Boston MA, V770, P165
   ALMUALLIM H, 1994, ARTIF INTELL, V69, P279, DOI 10.1016/0004-3702(94)90084-1
   [Anonymous], 2006, GESTS International Transactions on Computer Science and Engineering
   [Anonymous], 1974, Pattern Recognition Principles, DOI DOI 10.1002/ZAMM.19770570626
   Armstrong N, 2018, BMJ QUAL SAF, V27, P571, DOI 10.1136/bmjqs-2017-007571
   Billmann M, 2018, CELL SYST, V6, P52, DOI 10.1016/j.cels.2017.10.015
   Blows FM, 2010, PLOS MED, V7, DOI 10.1371/journal.pmed.1000279
   Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5
   Byler S, 2014, ANTICANCER RES, V34, P1071
   Chaddad A, 2017, ONCOTARGET, V8, P104393, DOI 10.18632/oncotarget.22251
   Chen WX, 2019, BIOSCIENCE REP, V39, DOI 10.1042/BSR20182062
   Chowdhury Nilotpal, 2011, Patholog Res Int, V2011, P890938, DOI 10.4061/2011/890938
   Cui XB, 2015, J TRANSL MED, V13, DOI 10.1186/s12967-015-0681-z
   Dash M, 2003, ARTIF INTELL, V151, P155, DOI 10.1016/S0004-3702(03)00079-1
   De Santo I, 2019, CANCERS, V11, DOI 10.3390/cancers11121894
   Deshmukh PR, 2021, MED BIOL ENG COMPUT, V59, P1751, DOI 10.1007/s11517-021-02399-7
   Engstrom MJ, 2013, BREAST CANCER RES TR, V140, P463, DOI 10.1007/s10549-013-2647-2
   Foley John, 2010, Semin Cell Dev Biol, V21, P951, DOI 10.1016/j.semcdb.2010.08.009
   Garg L, 2019, LECT NOTE NETW SYST, V75, DOI 10.1007/978-981-13-7150-9_18
   Ghiasi MM, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104089
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Houtsma D, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-82002-z
   Hu J, 2021, TRANSL ONCOL, V14, DOI 10.1016/j.tranon.2021.101054
   Huan Liu, 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P319
   Jayanthi VSPKSA, 2020, GENOMICS, V112, P388, DOI 10.1016/j.ygeno.2019.03.001
   Karra H, 2014, BRIT J CANCER, V110, P2905, DOI 10.1038/bjc.2014.252
   Kheybari S, 2019, OPSEARCH, V56, P539, DOI 10.1007/s12597-019-00365-4
   Kuchenbaecker KB, 2017, JAMA-J AM MED ASSOC, V317, P2402, DOI 10.1001/jama.2017.7112
   Lamba Monika, 2018, Procedia Computer Science, V132, P1619, DOI 10.1016/j.procs.2018.05.127
   Lamba M., 2021, ECABC EV CLASS ALG B
   Lamba M, 2023, J STAT MANAG SYST, P434
   Lamba M., 2022, Internet of Healthcare Things: Machine Learning for Security and Privacy, P241
   Lamba M, 2023, INT J INF TECH DECIS, V22, P803, DOI 10.1142/S0219622022500523
   Lamba M, 2021, INT J INTELL ENG INF, V9, P425, DOI 10.1504/IJIEI.2021.120694
   Lamba M, 2021, INT J APPL PATTERN R, V6, P195
   Lamba M, 2020, J STAT MANAG SYST, V23, P999, DOI 10.1080/09720510.2020.1799500
   Leong ASY, 2011, PATHOBIOLOGY, V78, P99, DOI 10.1159/000292644
   Li JD, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3136625
   Liu H, 2002, DATA MIN KNOWL DISC, V6, P393, DOI 10.1023/A:1016304305535
   Liu H., 2012, Feature Selection for Knowledge Discovery and Data Mining, V454
   Mittal Kavita, 2019, International Journal of Information Technology, V11, P535, DOI 10.1007/s41870-018-0233-x
   Nagpal Arpita, 2018, Procedia Computer Science, V132, P244, DOI 10.1016/j.procs.2018.05.195
   Nagpal A, 2018, J ENG SCI TECHNOL, V13, P2446
   Olsson N, 2013, MOL CELL PROTEOMICS, V12, P3612, DOI 10.1074/mcp.M113.030379
   Pickard MR, 2009, BREAST CANCER RES, V11, DOI 10.1186/bcr2350
   Rakha EA, 2010, BREAST CANCER RES, V12, DOI 10.1186/bcr2607
   Raschka S., 2015, Python Machine Learning: Unlock Deeper Insights Into Machine Learning with this Vital Guide to Cutting-edge Predictive Analytics
   Rauber TW, 1994, THESIS U NOVA LISBOA
   Repo H, 2017, BMC CANCER, V17, DOI 10.1186/s12885-017-3694-6
   Schäfer SA, 2019, FUTURE ONCOL, V15, P1921, DOI 10.2217/fon-2018-0564
   Schettini F, 2021, NPJ BREAST CANCER, V7, DOI 10.1038/s41523-020-00208-2
   Schlimmer J.C., 1993, ICML, P284
   Shavlik J.W., 1990, Readings in Machine Learning
   Sotiriou C, 2006, JNCI-J NATL CANCER I, V98, P262, DOI 10.1093/jnci/djj052
   Srinivasan SM, 2017, PARKINSONS DIS-US, V168
   van Dooijeweert C, 2022, VIRCHOWS ARCH, V480, P33, DOI 10.1007/s00428-021-03141-2
   Zhu XW, 2007, GENE DEV, V21, P1010, DOI 10.1101/gad.1528707
NR 58
TC 5
Z9 5
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29629
EP 29648
DI 10.1007/s11042-023-14918-9
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000943009100015
DA 2024-07-18
ER

PT J
AU Song, WJ
   Dai, P
   Zhang, QW
AF Song, Wenjun
   Dai, Pu
   Zhang, Qiuwen
TI Content-adaptive mode decision for low complexity 3D-HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D video; 3D-HEVC; Content-adaptive; Fast mode prediction scheme;
   Complexity reduction
ID MULTIVIEW VIDEO; CU SIZE; DEPTH; EXTENSIONS; ALGORITHM; SYSTEM
AB 3D-high efficiency video coding (3D-HEVC) provides great improvements in coding efficiency of multiview texture image and associated depth map. It inherits the prediction mode of HEVC, and several new coding tools for a better representation of the dependent texture and depth video are also employed by the 3D-HEVC encoder. These give a high coding efficiency, but require significantly high runtime due to huge complexity of mode decision. In this paper, we introduce a content-adaptive mode decision to reduce 3D-HEVC coding complexity. The basic idea of this method is to use the temporal-spatial, inter-view and texture-depth correlations to analyze content properties of treeblock, and adaptive skip some unnecessary prediction modes. Experimental results demonstrate that the proposed scheme can drastically save encoding time with no noticeable loss of rate distortion (RD) performance.
C1 [Song, Wenjun; Dai, Pu; Zhang, Qiuwen] Zhengzhou Univ Light Ind, Coll Comp & Commun Engn, Zhengzhou 450002, Peoples R China.
C3 Zhengzhou University of Light Industry
RP Zhang, QW (corresponding author), Zhengzhou Univ Light Ind, Coll Comp & Commun Engn, Zhengzhou 450002, Peoples R China.
EM zhangqwen@126.com
FU National Natural Science Foundation of China [61771432, 61302118,
   61702464]; Basic Research Projects of Education Department of Henan
   [21zx003, 20A880004]; Key projects Natural Science Foundation of Henan
   [2023045]; Postgraduate Education Reform and Quality Improvement Project
   of Henan Province [YJS2021KC12, YJS2022AL034]
FX This work was supported in part by the National Natural Science
   Foundation of China No.61771432, 61302118, and 61702464, the Basic
   Research Projects of Education Department of Henan No. 21zx003,
   andNo.20A880004, and the Key projects Natural Science Foundation of
   Henan (2023045), and the Postgraduate Education Reform and Quality
   Improvement Project of Henan Province YJS2021KC12 and YJS2022AL034
CR Arora M, 2021, MULTIMED TOOLS APPL, V80, P3039, DOI 10.1007/s11042-020-09726-4
   Arora M, 2018, NATL ACAD SCI LETT, V41, P365, DOI 10.1007/s40009-018-0694-2
   Bakkouri S, 2020, MULTIMED TOOLS APPL, V79, P6987, DOI 10.1007/s11042-019-08461-9
   Bjontegaard G, 2001, DOCUMENT ITU T SG16
   Chen J, 2017, J VIS COMMUN IMAGE R, V48, P329, DOI 10.1016/j.jvcir.2017.05.006
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Lei JJ, 2018, IEEE T CIRC SYST VID, V28, P706, DOI 10.1109/TCSVT.2016.2617332
   Lei JJ, 2015, IEEE T IND INFORM, V11, P978, DOI 10.1109/TII.2015.2446769
   Merkle P, 2016, IEEE T CIRC SYST VID, V26, P570, DOI 10.1109/TCSVT.2015.2407791
   Mora EG, 2014, IEEE T CIRC SYST VID, V24, P1554, DOI 10.1109/TCSVT.2013.2283110
   Moura C., 2020, P 2020 27 IEEE INT C, P1
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Muller K, 2014, ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11, JCT3v, VG1100, P1
   Ning X, 2020, IEEE SIGNAL PROC LET, V27, P1944, DOI 10.1109/LSP.2020.3032277
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Saldanha M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1738, DOI 10.1109/ICASSP.2018.8462283
   Shen LQ, 2018, IEEE T IMAGE PROCESS, V27, P4195, DOI 10.1109/TIP.2018.2837379
   Shen LQ, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700298
   Shen LQ, 2014, IEEE T CIRC SYST VID, V24, P1709, DOI 10.1109/TCSVT.2014.2313892
   Shen LQ, 2014, IEEE T IMAGE PROCESS, V23, P4232, DOI 10.1109/TIP.2014.2341927
   Shen LQ, 2011, IEEE T CIRC SYST VID, V21, P837, DOI 10.1109/TCSVT.2011.2130310
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Stankiewicz O, 2018, IEEE T MULTIMEDIA, V20, P2182, DOI 10.1109/TMM.2018.2790162
   Suhairi M., 2019, 2019 International Conference of Artificial Intelligence and Information Technology (ICAIIT). Proceedings, P163, DOI 10.1109/ICAIIT.2019.8834478
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Tanimoto M., 2008, JTC1SC29WG11 ISOIEC
   Tech G, 2016, IEEE T CIRC SYST VID, V26, P35, DOI 10.1109/TCSVT.2015.2477935
   Tohidypour Hamid Reza, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P895, DOI 10.1109/ICASSP.2014.6853726
   Tohidypour HR, 2016, IEEE T CIRC SYST VID, V26, P1870, DOI 10.1109/TCSVT.2015.2477955
   Walia S, 2021, IEEE ACCESS, V9, P99742, DOI 10.1109/ACCESS.2021.3096240
   Xu YW, 2021, IEEE T CIRC SYST VID, V31, P4096, DOI 10.1109/TCSVT.2020.3043005
   Yeh CH, 2014, IEEE T IND INFORM, V10, P594, DOI 10.1109/TII.2013.2273308
   Zhang HB, 2018, IEEE T CIRC SYST VID, V28, P513, DOI 10.1109/TCSVT.2016.2612693
   Zhang N, 2014, SIGNAL PROCESS-IMAGE, V29, P951, DOI 10.1016/j.image.2014.06.003
   Zhang Q, 2014, IEEE INT SYMP CIRC S
   Zhang QW, 2017, J VIS COMMUN IMAGE R, V45, P170, DOI 10.1016/j.jvcir.2017.03.004
   Zhang QW, 2015, DIGIT SIGNAL PROCESS, V44, P37, DOI 10.1016/j.dsp.2015.06.005
   Zhang QW, 2011, IEEE T CONSUM ELECTR, V57, P1857, DOI 10.1109/TCE.2011.6131164
NR 38
TC 2
Z9 2
U1 4
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26435
EP 26450
DI 10.1007/s11042-023-14874-4
EA MAR 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000943009100016
DA 2024-07-18
ER

PT J
AU Shang, XW
   Li, GP
   Zhao, XL
   Han, H
   Zuo, YF
AF Shang, Xiwu
   Li, Guoping
   Zhao, Xiaoli
   Han, Hua
   Zuo, Yifan
TI Fast CU size decision algorithm for VVC intra coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Versatile Video Coding (VVC); Intra coding; CU size decision
ID HEVC; INFORMATION; PARTITION
AB Recently, an emerging video coding standard called Versatile Video Coding (VVC) is established using quadtree with nested multi-type tree structure to improve the coding efficiency. However, the coding complexity increases dramatically due to the flexible block partition structure. To tackle this issue, a fast CU size decision algorithm is proposed to speed up the intra coding process utilizing the coding information and the texture information, which consists of a fast quadtree decision method (FQD) and a fast multi-type tree decision method (FMD). Firstly, the correlation of the depths of the neighboring CUs is analyzed, which can predict the quadtree depth of the current CU early to skip unnecessary depths. Then, the distribution of the Rate-Distortion (RD) cost of the multi-type tree combined with the texture information is utilized to make an early decision on the splits of the binary-tree (BT) and ternary-tree (TT). Experimental results demonstrate that the proposed algorithm can reduce the coding complexity by 51.89% on average, with negligible loss of coding performance. Compared with state-of-the-art methods, the proposed algorithm can obtain an additional time saving from 6% to 17%, while keeps a better coding performance.
C1 [Shang, Xiwu; Li, Guoping; Zhao, Xiaoli; Han, Hua] Shanghai Univ Engn Sci, Shanghai, Peoples R China.
   [Zuo, Yifan] Jiangxi Univ Finance & Econ, Nanchang, Jiangxi, Peoples R China.
C3 Shanghai University of Engineering Science; Jiangxi University of
   Finance & Economics
RP Shang, XW (corresponding author), Shanghai Univ Engn Sci, Shanghai, Peoples R China.
EM dxsxw@126.com; liguoping@sues.edu.cn; zhaoxiaoli@sues.edu.cn;
   2070967@mail.dhu.edu.cn; kenny0410@sina.com
RI Zuo, Yifan/JVZ-3041-2024; Liu, yuqing/KEI-3260-2024
OI Zuo, Yifan/0000-0003-4980-7211; 
FU National Natural Science Foundation of China [62001283, 61901197];
   National Key R&D Project of China [2019YFB1802702]
FX This work was supported by the National Natural Science Foundation of
   China under 62001283, National Key R&D Project of China under
   2019YFB1802702, National Natural Science Foundation of China under
   61901197.
CR Ahn S, 2015, IEEE T CIRC SYST VID, V25, P422, DOI 10.1109/TCSVT.2014.2360031
   Bjontegaard G., 2001, Document VCEG-M33
   Bross B., 2018, JVET J1001
   Bross B, 2021, IEEE T CIRC SYST VID, V31, P3736, DOI 10.1109/TCSVT.2021.3101953
   Bross B, 2021, P IEEE, V109, P1463, DOI 10.1109/JPROC.2020.3043399
   Chen F, 2020, MULTIMED TOOLS APPL, V79, P27923, DOI 10.1007/s11042-020-09401-8
   Chen J., 2018, JVETJ1002
   Chen JK, 2018, IEEE T AFFECT COMPUT, V9, P38, DOI 10.1109/TAFFC.2016.2593719
   Chen MJ, 2018, IEEE T IND INFORM, V14, P4735, DOI 10.1109/TII.2018.2801852
   Gweon RH, 2012, IEICE T FUND ELECTR, VE95A, P1215, DOI 10.1587/transfun.E95.A.1215
   Jia S, 2018, MULTIMED TOOLS APPL, V77, P14859, DOI 10.1007/s11042-017-5070-6
   Jin ZP, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Jin ZP, 2018, IEEE ACCESS, V6, P54660, DOI 10.1109/ACCESS.2018.2872492
   Lee HS, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.6.067402
   Lei JJ, 2017, IEEE T BROADCAST, V63, P48, DOI 10.1109/TBC.2016.2623241
   Lei M, 2019, IEEE IMAGE PROC, P4120, DOI [10.1109/ICIP.2019.8803421, 10.1109/icip.2019.8803421]
   Li TY, 2021, IEEE T IMAGE PROCESS, V30, P5377, DOI 10.1109/TIP.2021.3083447
   Li X, 2020, IEEE COMPUT SOC CONF, P615, DOI 10.1109/CVPRW50498.2020.00087
   Liu H, 2021, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS51556.2021.9401737
   Liu YC, 2015, IEEE DATA COMPR CONF, P458, DOI 10.1109/DCC.2015.32
   Liu ZY, 2016, IEEE T IMAGE PROCESS, V25, P5088, DOI 10.1109/TIP.2016.2601264
   Liu ZY, 2016, IEEE INT SYMP CIRC S, P2270, DOI 10.1109/ISCAS.2016.7539036
   Min B, 2015, IEEE T CIRC SYST VID, V25, P892, DOI 10.1109/TCSVT.2014.2363739
   Nagulapati R, 2018, IEEE INT CONF HEALT, P9, DOI 10.1109/ICHI-W.2018.00009
   Park SH, 2019, IEEE ACCESS, V7, P172597, DOI 10.1109/ACCESS.2019.2956196
   Saldanha M, 2020, IEEE T CIRC SYST VID, V30, P850, DOI 10.1109/TCSVT.2019.2898122
   Shang XW, 2019, IEEE T CIRC SYST VID, V29, P1239, DOI 10.1109/TCSVT.2018.2836974
   Shang XW, 2016, CIRC SYST SIGNAL PR, V35, P4331, DOI 10.1007/s00034-016-0264-0
   Shen LQ, 2014, IEEE T IMAGE PROCESS, V23, P4232, DOI 10.1109/TIP.2014.2341927
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Shen XL, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-4
   Suehring K, 2019, JVETM1010
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun XB, 2017, IET IMAGE PROCESS, V11, P717, DOI 10.1049/iet-ipr.2016.1082
   Tai KH, 2017, IEEE T BROADCAST, V63, P680, DOI 10.1109/TBC.2017.2722239
   Tang G., 2019, P IEEE VIS COMM IM P, P1
   Wang M, 2021, IEEE T IMAGE PROCESS, V30, P2378, DOI 10.1109/TIP.2021.3051460
   Wang Z, 2018, IEEE IMAGE PROC, P2550, DOI 10.1109/ICIP.2018.8451258
   Wang Z, 2018, IEEE T IMAGE PROCESS, V27, P1475, DOI 10.1109/TIP.2017.2778564
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
   Yang SH, 2021, ELECTRON LETT, V57, P11, DOI 10.1049/ell2.12011
   Yeo Woon-Ha, 2021, Journal of Multimedia Information System, V8, P147
   Zhang MM, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0446-3
   Zhang QW, 2017, J VIS COMMUN IMAGE R, V45, P170, DOI 10.1016/j.jvcir.2017.03.004
   Zhang Y, 2016, IEEE T CIRC SYST VID, V26, P950, DOI 10.1109/TCSVT.2015.2426552
   Zhang Y, 2015, IEEE T IMAGE PROCESS, V24, P2225, DOI 10.1109/TIP.2015.2417498
   Zhao JC, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10243112
   Zhu LW, 2018, IEEE T BROADCAST, V64, P681, DOI 10.1109/TBC.2017.2762470
NR 49
TC 4
Z9 4
U1 6
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28301
EP 28322
DI 10.1007/s11042-023-14691-9
EA FEB 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000936302600002
DA 2024-07-18
ER

PT J
AU Bhimavarapu, U
AF Bhimavarapu, Usharani
TI Prediction and classification of rice leaves using the improved PSO
   clustering and improved CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Activation function; Crop yield; Deep learning; Neural networks;
   Optimizer
ID FUZZY-LOGIC; INFERENCE
AB The world's main source of food supply in agriculture, and due to the increase in population growth, the requirement for food supply is increasing day by day. Rice is the main food crop in many countries, and rice leaf infections are a common hazard to rice yield. So the early detection of rice leaf infection is crucial for rice crop growth and ensuring sufficient supply for a fast-growing population. Conventional manual identification of rice diseases is time-consuming, ineffective, and costly. To overcome this challenge, we can take images of the affected area of the plants and test them with a pre-trained model to identify and classify the rice diseases. Convolutional Neural Networks (CNN) in deep learning extracts the features from the images and diagnoses the diseases efficiently, which addresses the above issues. The main objective of this study is to minimize the loss and the processing time to predict rice diseases. Optimizers play a crucial role in reducing the loss in the neural network. We proposed an Improved Activation and Optimizer Function (IAOF) in the CNN model to minimize the loss and improve the prediction performance and classification accuracy. The output performance of the proposed IAOF-CNN surpasses the other existing methods and has been verified as the best implementation.
C1 [Bhimavarapu, Usharani] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Bhimavarapu, U (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, Andhra Pradesh, India.
EM ushareddy@kluniversity.in
CR Amara J., 2017, Lecture Notes in Informatics (LNI), Gesellschaft fur Informatik, P79
   Anthonys G, 2009, 2009 INTERNATIONAL CONFERENCE ON INDUSTRIAL AND INFORMATION SYSTEMS, P403, DOI 10.1109/ICIINFS.2009.5429828
   Bandara D, 2021, INT C ADV RES COMPUT, P1
   Bhimavarapu U, 2022, NEURAL COMPUT APPL, V34, P20165, DOI 10.1007/s00521-022-07577-8
   Brahimi M, 2017, APPL ARTIF INTELL, V31, P299, DOI 10.1080/08839514.2017.1315516
   Chen H, 2016, THEOR APPL CLIMATOL, V126, P105, DOI 10.1007/s00704-015-1559-y
   Chen JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105393
   Chen K, 2021, ARXIV
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Fuentes A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092022
   Gandhi N, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER APPLICATIONS (ICACA), P357, DOI 10.1109/ICACA.2016.7887981
   Geetharamani G, 2019, COMPUT ELECTR ENG, V76, P323, DOI 10.1016/j.compeleceng.2019.04.011
   Hosseinpourtehrani M., 2011, Asian Journal of Applied Sciences, V4, P493, DOI 10.3923/ajaps.2011.493.513
   Jenifer S, 2016, APPL SOFT COMPUT, V42, P167, DOI 10.1016/j.asoc.2016.01.039
   Kumar P, 2011, Math TheoryMod, V1, P1
   Li Y, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105803
   Liang QK, 2019, COMPUT ELECTRON AGR, V157, P518, DOI 10.1016/j.compag.2019.01.034
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Mazloumzadeh SM, 2010, PRECIS AGRIC, V11, P258, DOI 10.1007/s11119-009-9132-2
   Mohan KJ., 2016, INT J COMPUT APPL, V144, P34, DOI DOI 10.5120/IJCA2016910505
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Naderloo L, 2012, MEASUREMENT, V45, P1406, DOI 10.1016/j.measurement.2012.03.025
   Nagaraju M, 2020, INT J SYST ASSUR ENG, V11, P547, DOI 10.1007/s13198-020-00972-1
   Prajapati HB, 2017, INTELL DECIS TECHNOL, V11, P357, DOI 10.3233/IDT-170301
   Qin F, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168274
   Rahman MM, 2014, 2014 ANNUAL GLOBAL ONLINE CONFERENCE ON INFORMATION AND COMPUTER TECHNOLOGY, P1, DOI 10.1109/GOCICT.2014.9
   Ratuja RP., 2021, IEEE ACCESS, V10, P5207
   Su YX, 2017, SAUDI J BIOL SCI, V24, P537, DOI 10.1016/j.sjbs.2017.01.024
   Tagarakis A, 2014, PRECIS AGRIC, V15, P555, DOI 10.1007/s11119-014-9354-9
   Tremblay N, 2010, PRECIS AGRIC, V11, P621, DOI 10.1007/s11119-010-9188-z
   Usharani B, 2022, SOFT COMPUT, VComput1, P1
   Yousefi M, 2015, STOCH ENV RES RISK A, V29, P2115, DOI 10.1007/s00477-015-1055-z
   Zarbafi SS, 2019, AGRONOMY-BASEL, V9, DOI 10.3390/agronomy9040177
   Zeng WH, 2020, COMPUT ELECTRON AGR, V172, DOI 10.1016/j.compag.2020.105341
   Zhang SW, 2019, COMPUT ELECTRON AGR, V162, P422, DOI 10.1016/j.compag.2019.03.012
NR 35
TC 2
Z9 2
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21701
EP 21714
DI 10.1007/s11042-023-14631-7
EA FEB 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000934222700008
DA 2024-07-18
ER

PT J
AU Kiania, K
   Jameii, SM
   Rahmani, AM
AF Kiania, Kianoush
   Jameii, Seyed Mahdi
   Rahmani, Amir Masoud
TI Blockchain-based privacy and security preserving in electronic health: a
   systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Electronic Health Records (HER)left-to-right mark; Blockchain; Security;
   Privacy; Smart contract; SLR
AB In today's world, health and medicine play an undeniable role in human life. Traditional and current Electronic Health Records (EHR) systems that are used to exchange information between medical stakeholders (patients, physicians, insurance companies, pharmaceuticals, medical researchers, etc.) suffer weaknesses in terms of security and privacy due to having centralized architecture. Blockchain technology ensures the privacy and security of EHR systems thanks to the use of encryption. Moreover, due to its decentralized nature, this technology prevents central failure and central attack points. In this paper, a systematic literature review (SLR) is proposed to analyze the existing Blockchain-based approaches for improving privacy and security in electronic health systems. The research methodology, paper selection process, and the search query are explained. 51 papers returned from our search criteria published between 2018 and Dec 2022 are reviewed. The main ideas, type of Blockchain, evaluation metrics, and used tools of each selected paper are discussed in detail. Finally, future research directions, open challenges, and some issues are discussed.
C1 [Kiania, Kianoush] Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Tehran, Iran.
   [Jameii, Seyed Mahdi] Islamic Azad Univ, Dept Comp Engn, Shahr Eqods Branch, Tehran, Iran.
   [Rahmani, Amir Masoud] Natl Yunlin Univ Sci & Technol, Future Technol Res Ctr, 123 Univ Rd,Sect 3, Touliu 64002, Taiwan.
C3 Islamic Azad University; Islamic Azad University; National Yunlin
   University Science & Technology
RP Jameii, SM (corresponding author), Islamic Azad Univ, Dept Comp Engn, Shahr Eqods Branch, Tehran, Iran.
EM sm.jameii@iau.ac.ir
RI Rahmani, Amir Masoud/K-2702-2013; Jameii, Seyed Mahdi/AAJ-4820-2020
OI Rahmani, Amir Masoud/0000-0001-8641-6119; Jameii, Seyed
   Mahdi/0000-0002-9407-665X
CR Abbas AF, 2022, INT J ONLINE BIOMED, V18, P2
   Abid A., 2022, SOFTWARE PRACT EXPER, V52, P1
   Abou-Nassar EM, 2020, IEEE ACCESS, V8, P111223, DOI 10.1109/ACCESS.2020.2999468
   Abu-elezz I, 2020, INT J MED INFORM, V142, DOI 10.1016/j.ijmedinf.2020.104246
   Akbar MA, 2022, J SOFTW-EVOL PROC, V34, DOI 10.1002/smr.2500
   Al Omar A, 2019, FUTURE GENER COMP SY, V95, P511, DOI 10.1016/j.future.2018.12.044
   Ali A, 2022, SENSORS-BASEL, V22, P2
   Alsayegh M, 2022, NETWORK, V2, P2
   Butt GQ, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12052307
   Chakraborty Sabyasachi, 2020, International Journal of Information Technology, V12, P473, DOI 10.1007/s41870-019-00318-6
   Chen L., 2019, FUTURE GENER COMP SY, V95, P2
   Dagher GG, 2018, SUSTAIN CITIES SOC, V39, P283, DOI 10.1016/j.scs.2018.02.014
   Fathi M, 2022, ARCH COMPUT METHOD E, V29, P1247, DOI 10.1007/s11831-021-09616-4
   Alonso SG, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1279-4
   Griggs KN, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0982-x
   Gross M., 2021, HEALTH TECHNOL-GER, V11, P1
   Guo R., 2019, ADV MATER TECHNOL-US, V7, P1
   Guo R., 2018, IEEE ACCESS, V6, P3
   Hasselgren A, 2020, INT J MED INFORM, V134, DOI 10.1016/j.ijmedinf.2019.104040
   Hussien HM, 2021, J IND INF INTEGR, V22, DOI 10.1016/j.jii.2021.100217
   Ismail L., 2019, IEEE ACCESS, V7, P2
   Jeet R, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/3940849
   Ji YX, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0998-2
   Johari R, 2022, ICT EXPRESS, V8, P56, DOI 10.1016/j.icte.2021.06.002
   Kassab MH, 2019, IEEE T EMERG TOP COM, V9, P8
   Khatri S, 2021, IEEE ACCESS, V9, P84666, DOI 10.1109/ACCESS.2021.3087608
   Kim T-H, 2020, IEEE ACCESS, V8, P1
   Kshetri N., 2018, COMPUTER, V51, P1
   Lee TF, 2021, INT J INF SECUR, V20, P589, DOI 10.1007/s10207-020-00521-8
   Li HH, 2018, J FOOD PROCESS PRES, V42, DOI [10.1007/s10916-018-0993-7, 10.1111/jfpp.13348]
   Li P., 2019, IEEE SYST J, V14, P1
   Lopes J, 2018, ADV INTELL SYST, P435
   McGhin T, 2019, J NETW COMPUT APPL, V135, P62, DOI 10.1016/j.jnca.2019.02.027
   Miyachi K, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102535
   Muofhe M, 2019, 2019 OPEN INNOVATIONS CONFERENCE (OI), P97, DOI 10.1109/oi.2019.8908221
   Musamih A, 2021, IEEE ACCESS, V9, P9728, DOI 10.1109/ACCESS.2021.3049920
   Nagasubramanian G, 2020, NEURAL COMPUT APPL, V32, P639, DOI 10.1007/s00521-018-3915-1
   Nguyen DC., 2019, IEEE ACCESS, V7, P1
   Nie XL, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/8293716
   Nishi FK, 2022, J SENSORS, V2022, DOI 10.1155/2022/7299185
   Pandey P, 2021, WIRELESS PERS COMMUN, V117, P7, DOI 10.1007/s11277-020-07041-7
   Pandey P, 2020, HEALTH POLICY TECHN, V9, P69, DOI 10.1016/j.hlpt.2020.01.004
   Rahmani MKI, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/9766844
   Rajasekaran AS, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/2793116
   Ranjith J., 2021, SN COMPUT SCI, V2, P1, DOI DOI 10.1007/S42979-021-00568-X
   Ray PP, 2021, IEEE SYST J, V15, P85, DOI 10.1109/JSYST.2020.2963840
   Rejeb A., 2021, Journal of Data, Information and Management, V3, P109, DOI DOI 10.1007/S42488-021-00046-2
   Roehrs A, 2019, J BIOMED INFORM, V92, DOI 10.1016/j.jbi.2019.103140
   Saeed H, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0266462
   Shahnaz A, 2019, IEEE ACCESS, V7, P147782, DOI 10.1109/ACCESS.2019.2946373
   Sharma V, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/9697545
   Sharma Y., 2020, PROCEDIA COMPUT SCI, V173, P2
   Soltanisehat L, 2023, IEEE T ENG MANAGE, V70, P353, DOI 10.1109/TEM.2020.3013507
   Su Q., 2020, IEEE ACCESS, V8, P2
   Syed TA, 2019, IEEE ACCESS, V7, P176838, DOI 10.1109/ACCESS.2019.2957660
   Tandon A, 2020, COMPUT IND, V122, DOI 10.1016/j.compind.2020.103290
   Tripathi G, 2020, HEALTHCARE-J DEL SCI, V8, DOI 10.1016/j.hjdsi.2019.100391
   Uddin MA, 2018, IEEE ACCESS, V6, P32700, DOI 10.1109/ACCESS.2018.2846779
   Usman Muhammad, 2020, Procedia Computer Science, V174, P321, DOI 10.1016/j.procs.2020.06.093
   Wang S, 2018, IEEE T COMPUT SOC SY, V5, P942, DOI 10.1109/TCSS.2018.2865526
   Wu HJ, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3408321
   Wu SH, 2019, PROCEEDINGS OF 2019 THE 3RD INTERNATIONAL CONFERENCE ON CRYPTOGRAPHY, SECURITY AND PRIVACY (ICCSP 2019) WITH WORKSHOP 2019 THE 4TH INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP 2019), P13, DOI 10.1145/3309074.3309079
   Yaqoob I, 2022, NEURAL COMPUT APPL, V34, P11475, DOI 10.1007/s00521-020-05519-w
   Yin TX, 2021, BMC INFECT DIS, V21, DOI 10.1186/s12879-021-05915-0
   Zarour M, 2020, IEEE ACCESS, V8, P157959, DOI 10.1109/ACCESS.2020.3019829
   Zhang C, 2021, COMPUT STAND INTER, V77, DOI 10.1016/j.csi.2021.103520
   Zhang D, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/2759787
   Zhang P, 2018, ADV COMPUT, V111, P1, DOI 10.1016/bs.adcom.2018.03.006
   Zhang R, 2022, IEEE T SERV COMPUT, V15, P3668, DOI 10.1109/TSC.2021.3085913
NR 69
TC 10
Z9 10
U1 7
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28493
EP 28519
DI 10.1007/s11042-023-14488-w
EA FEB 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000934222700009
PM 36811000
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Kiliçarslan, S
AF Kilicarslan, Serhat
TI A novel nonlinear hybrid HardSReLUE activation function in transfer
   learning architectures for hemorrhage classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hemorrhage; Gabor transform; CNN; YOLOv5; Activation functions
ID DIABETIC-RETINOPATHY; LESION DETECTION; DISEASE
AB Convolutional neural networks (CNN) are widely used in the fields of object detection and image segmentation thanks to their high performance. The choice of architecture and activation functions in convolutional neural networks are of great importance in the learning process when performing object detection on an image. Among several activation functions, the Rectified Linear Unit (ReLU) activation function is widely used in the CNN and hemorrhage classification tasks. However, ReLU has the disadvantage of the negative region problem during neural activation. Numerous studies have been carried out on activation functions to improve the learning of convolutional neural networks. In this context, there are many challenges such as learning saturation, vanishing/exploding gradient problem, and formation of dead neurons. We proposed a new activation function called HardSReLUE. In this study, retinal blood vessels were detected and removed from the image using the Gabor transform to detect and classify hemorrhages in diabetic retinopathy lesions. The detection and classification of hemorrhagic areas were performed using the VGG-19, ResNet-50, and YOLOv5 CNN architectures. Moreover, experimental studies were carried out using ReLU, ELU, SeLU, PReLU, Mish, Swish, and the proposed HardSReLUE activation functions to increase the classification performance of CNN architectures. In the experimental studies, the EyePACS database was used due to the diverse and large number of retinal images. Additionally, an experimental study was performed using the MNIST dataset to support the success of the proposed activation function. The results of the experimental studies show that the proposed HardSReLUE activation function and the YOLOv5 architecture have better performance than others. Final training accuracy after 100 epochs for VGG-19, ResNet-50, and YOLOv5 are 91.72%, 93.38%, and 94.75% respectively.
C1 [Kilicarslan, Serhat] Bandirma Onyedi Eylul Univ, Dept Software Engn, Bandinna, Turkey.
RP Kiliçarslan, S (corresponding author), Bandirma Onyedi Eylul Univ, Dept Software Engn, Bandinna, Turkey.
EM skilicarslan@bandirma.edu.tr
RI KILIÇARSLAN, Serhat/AHB-3775-2022
OI KILIÇARSLAN, Serhat/0000-0001-9483-4425
CR Abràmoff MD, 2016, INVEST OPHTH VIS SCI, V57, P5200, DOI 10.1167/iovs.16-19964
   Adem K, 2019, TURK J ELECTR ENG CO, V27, P4220, DOI 10.3906/elk-1903-112
   Adem K, 2019, EXPERT SYST APPL, V115, P557, DOI 10.1016/j.eswa.2018.08.050
   Adem K, 2018, EXPERT SYST APPL, V114, P289, DOI 10.1016/j.eswa.2018.07.053
   Aggarwal K., 2022, IRAQI J COMPUT SCI M, V3, P115, DOI [DOI 10.52866/IJCSM.2022.01.01.013, 10.52866/ijcsm.2022.01.01.013]
   Alom MZ, 2018, arXiv
   Alyoubi W. L., 2020, Informatics in Medicine Unlocked, V20, DOI [DOI 10.1016/J.IMU.2020.100377, 10.1016/j.imu.2020.100377]
   Arbabshirani MR, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-017-0015-z
   Bawa VS, 2019, EXPERT SYST APPL, V120, P346, DOI 10.1016/j.eswa.2018.11.042
   Chilamkurthy S, 2018, ARXIV
   Clevert D. A., 2015, FAST ACCURATE DEEP N
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Gonul S, 2013, TIP ARASTIRMALARI DE, V11, P87
   Govindaiah A, 2022, INVEST OPHTH VIS SCI, V63
   Grigorescu S, 2020, J FIELD ROBOT, V37, P362, DOI 10.1002/rob.21918
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   HILLER R, 1988, AM J EPIDEMIOL, V128, P402, DOI 10.1093/oxfordjournals.aje.a114980
   Ji QG, 2019, ALGORITHMS, V12, DOI 10.3390/a12030051
   Jin X, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108159
   Kiliçarslan S, 2021, EXPERT SYST APPL, V174, DOI 10.1016/j.eswa.2021.114805
   Kilicarslan S, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102231
   Kilicarslan S, 2020, MED HYPOTHESES, V137, DOI 10.1016/j.mehy.2020.109577
   Klambauer Gunter, 2017, arXiv
   Klein R, 1999, ARCH OPHTHALMOL-CHIC, V117, P1487
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li J, 2022, IEEE T KNOWL DATA EN, V34, P50, DOI 10.1109/TKDE.2020.2981314
   Li T, 2021, MED IMAGE ANAL, V69, DOI 10.1016/j.media.2021.101971
   Li Yandong, 2016, Journal of Computer Applications, V36, P2508, DOI 10.11772/j.issn.1001-9081.2016.09.2508
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Megahed M, 2020, EXPERT SYST APPL, V157, DOI 10.1016/j.eswa.2020.113460
   Mehrotra A, 2014, IEEE INT ADV COMPUT, P1142, DOI 10.1109/IAdCC.2014.6779487
   Misra D., 2020, ARXIV
   Mondal SS, 2020, PROCEDIA COMPUT SCI, V167, P2060, DOI 10.1016/j.procs.2020.03.246
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Orlando JI, 2018, COMPUT METH PROG BIO, V153, P115, DOI 10.1016/j.cmpb.2017.10.017
   Pacal I, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104519
   Ramachandran P., 2017, ARXIV
   Ravanelli M, 2018, IEEE T EM TOP COMP I, V2, P92, DOI 10.1109/TETCI.2017.2762739
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Skouta A, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-022-00632-0
   Tripathi S., 2013, INT J ENG TECHNOLOGY, V5, P2024
   Vijayan T., 2020, Microprocess. Microsyst, P103353, DOI [10.3390/s22145103, DOI 10.1016/J.MICPRO.2020.103353, 10.1016/j.micpro.2020.103353]
   Wan SH, 2018, COMPUT ELECTR ENG, V72, P274, DOI 10.1016/j.compeleceng.2018.07.042
   Wang JL, 2020, IET COMPUT VIS, V14, P1, DOI 10.1049/iet-cvi.2018.5508
   Wang X, 2019, NEUROCOMPUTING, V363, P88, DOI 10.1016/j.neucom.2019.07.017
   Yan B, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13091619
   Yau JWY, 2012, DIABETES CARE, V35, P556, DOI 10.2337/dc11-1909
   Yoo H.-J., 2015, IEIE Transactions on Smart Processing and Computing, V4, P35, DOI DOI 10.5573/IEIESPC.2015.4.1.035
   Zago GT, 2020, COMPUT BIOL MED, V116, DOI 10.1016/j.compbiomed.2019.103537
   Zhang GY, 2021, COMPUT MED IMAG GRAP, V90, DOI 10.1016/j.compmedimag.2021.101929
   Zhao HZ, 2018, APPL INTELL, V48, P1707, DOI 10.1007/s10489-017-1028-7
   Zhou Y, 2021, EXPERT SYST APPL, V171, DOI 10.1016/j.eswa.2020.114534
NR 52
TC 2
Z9 2
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 6345
EP 6365
DI 10.1007/s11042-022-14313-w
EA DEC 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000904017400002
DA 2024-07-18
ER

PT J
AU Jiang, K
   Zhao, CY
   Zhu, L
   Sun, QD
AF Jiang, Kun
   Zhao, Congyao
   Zhu, Lei
   Sun, Qindong
TI Class-oriented and label embedding analysis dictionary learning for
   pattern classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Analysis dictionary learning; Sparse representation; Incoherence
   promotion; Block-diagonal representation
ID K-SVD; DISCRIMINATIVE DICTIONARY; ALGORITHM; REPRESENTATION;
   RECOGNITION; IMBALANCE; LOCALITY
AB Analysis dictionary learning (ADL) has obtained lots of research interest in sparse representation-based classification recent years, due to its flexibility and low complexity for out-of-sample representation. However, the discrimination of the dominant analysis dictionary is not fully explored and the manifold information is not inherited into analysis atoms for classification. To remedy the deficiencies, we present joint class-oriented and label embedding (COLE) constraints on the analysis dictionary for pattern classification. Specifically, the comprehensive class-oriented constraints on the analysis subdictionaries efficiently yield discriminative class-wise atoms and between-class separable representation for classification. The redundant atoms can be eliminated by orthogonal subdictionary constraints, leading to a robust and within-class compact analysis dictionary. Furthermore, the label embedding term of analysis atoms inherits the supervised manifold information of the training samples and guarantees an ideal block-diagonal representation. Finally, an computationally efficient alternating direction minimization algorithm is presented with iterative reweighted and closed-form solutions, which avoids the time-consuming multiplication of class-specific data samples and the subdictionaries. Extensive experiments on five benchmark databases demonstrate at least comparable or better classification accuracy and efficiency of the proposed model compared with state-of-the-art ADL models.
C1 [Jiang, Kun; Zhao, Congyao; Zhu, Lei; Sun, Qindong] Xian Univ Technol, Sch Comp Sci & Engn, Xian, Peoples R China.
C3 Xi'an University of Technology
RP Jiang, K (corresponding author), Xian Univ Technol, Sch Comp Sci & Engn, Xian, Peoples R China.
EM jk_365@xaut.edu.cn
RI Jiang, Kun/J-9212-2016
OI Jiang, Kun/0000-0003-1316-5237
FU Natural Science Basic Research Program of Shaanxi, China;  [2021JM-339]
FX AcknowledgementsThis work was carried out when the first author was
   working as the postdoctoral researcher at Xi'an Jiaotong University.
   This work is partially supported by the Natural Science Basic Research
   Program of Shaanxi, China (Program No. 2021JM-339).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ambati LS, 2021, 27 AMERICAS C INFORM
   Ambati LS., 2019, J MIDWEST ASS INF SY, V2021, P49, DOI DOI 10.17705/3JMWA.000065
   Chen Z, 2022, IEEE T NEUR NET LEAR, V33, P3645, DOI 10.1109/TNNLS.2021.3053941
   Chen Z, 2023, IEEE T MULTIMEDIA, V25, P5374, DOI 10.1109/TMM.2022.3190678
   Ding SY, 2018, NEUROCOMPUTING, V277, P139, DOI 10.1016/j.neucom.2017.02.102
   Du HS, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2021.106794
   El-Gayar OmarF., 2020, BIG DATAS POTENTIAL, P104, DOI DOI 10.4018/978-1-5225-9687-5.CH005
   Gu SH, 2014, ADV NEUR IN, V27
   Guo J, 2016, AAAI CONF ARTIF INTE, P1617
   Gurkan F, 2021, IEEE T IMAGE PROCESS, V30, P7938, DOI 10.1109/TIP.2021.3112010
   Hawe S, 2013, IEEE T IMAGE PROCESS, V22, P2138, DOI 10.1109/TIP.2013.2246175
   Jiang K, 2022, J ELECTRON IMAGING, V31, DOI 10.1117/1.JEI.31.3.033028
   Jiang WM, 2017, INT CONF DAT MIN WOR, P510, DOI 10.1109/ICDMW.2017.72
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Kong S, 2012, DICT LEARNING APPROA
   Li ZM, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03262-1
   Li ZM, 2020, IEEE T NEUR NET LEAR, V31, P786, DOI 10.1109/TNNLS.2019.2910146
   Li ZM, 2017, IEEE T NEUR NET LEAR, V28, P278, DOI 10.1109/TNNLS.2015.2508025
   Li ZN, 2017, NEUROCOMPUTING, V239, P165, DOI 10.1016/j.neucom.2017.02.014
   Ma F, 2019, NEUROCOMPUTING, V348, P16, DOI 10.1016/j.neucom.2018.07.081
   Mairal J., 2009, ADV NEURAL INFORM PR, P1033
   Ramirez I, 2010, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR.2010.5539964
   Ravishankar S, 2013, IEEE T SIGNAL PROCES, V61, P1072, DOI 10.1109/TSP.2012.2226449
   Rubinstein R, 2013, IEEE T SIGNAL PROCES, V61, DOI 10.1109/TSP.2012.2226445
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Sai Ambati L., 2020, Issues Inform Syst, V21, P103
   Shao S, 2020, NEUROCOMPUTING, V385, P122, DOI 10.1016/j.neucom.2019.12.071
   Shekhar S, 2014, IEEE IMAGE PROC, P5207, DOI 10.1109/ICIP.2014.7026054
   Shu XB, 2018, IEEE T CIRC SYST VID, V28, P454, DOI 10.1109/TCSVT.2016.2607345
   Sun SJ, 2021, IEEE T PATTERN ANAL, V43, P104, DOI 10.1109/TPAMI.2019.2929520
   Tang W, 2022, NEUROCOMPUTING, V509, P244, DOI 10.1016/j.neucom.2022.08.069
   Tang W, 2019, IEEE T IMAGE PROCESS, V28, P6035, DOI 10.1109/TIP.2019.2919409
   Vu TH, 2017, IEEE T IMAGE PROCESS, V26, P5160, DOI 10.1109/TIP.2017.2729885
   Wang JJ, 2017, IEEE SIGNAL PROC LET, V24, P1822, DOI 10.1109/LSP.2017.2734860
   Wang JJ, 2017, NEUROCOMPUTING, V238, P103, DOI 10.1016/j.neucom.2017.01.041
   Wang QY, 2018, MULTIMED TOOLS APPL, V77, P17023, DOI 10.1007/s11042-017-5269-6
   Wang QY, 2018, IEEE ACCESS, V6, P20174, DOI 10.1109/ACCESS.2018.2791578
   Wang XD, 2017, IEEE T IMAGE PROCESS, V26, P3859, DOI 10.1109/TIP.2017.2703101
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang L, 2021, IEEE T INF FOREN SEC, V16, P4869, DOI 10.1109/TIFS.2021.3118894
   Yang M, 2017, NEUROCOMPUTING, V269, P13, DOI 10.1016/j.neucom.2016.08.146
   Yang M, 2017, NEUROCOMPUTING, V219, P404, DOI 10.1016/j.neucom.2016.09.037
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Ye J., 2007, P 21 ANN C NEUR INF, V20, P1649
   Yu H, 2022, IEEE T KNOWL DATA EN, V34, P4572, DOI 10.1109/TKDE.2020.3046114
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang Q.Z.Q., 2010, PROC CVPR IEEE, DOI [10.1109/CVPR.2010.5539989, DOI 10.1109/CVPR.2010.5539989]
   Zhang X, 2022, IEEE T CIRC SYST VID, V32, P1681, DOI 10.1109/TCSVT.2021.3056098
   Zhang Z, 2021, IEEE T NEUR NET LEAR, V32, P947, DOI 10.1109/TNNLS.2020.2979748
   Zhang Z, 2018, IEEE T NEUR NET LEAR, V29, P3798, DOI 10.1109/TNNLS.2017.2740224
   Zhang Z, 2018, IEEE T NEUR NET LEAR, V29, P3111, DOI 10.1109/TNNLS.2017.2712801
   Zhang ZY, 2022, IEEE T PATTERN ANAL, V44, P345, DOI 10.1109/TPAMI.2020.2998790
   Zhou N, 2014, IEEE T PATTERN ANAL, V36, P715, DOI 10.1109/TPAMI.2013.189
NR 57
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24919
EP 24942
DI 10.1007/s11042-022-14295-9
EA DEC 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000903319100003
DA 2024-07-18
ER

PT J
AU Devi, A
   Kumar, A
   Rathee, G
   Saini, H
AF Devi, Anju
   Kumar, Amit
   Rathee, Geetanjali
   Saini, Hemraj
TI User authentication of industrial internet of things (IIoT) through
   Blockchain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User authentication scheme; Ethereum blockchain; IPFS; Blockchain
   security; Authentication mechanism
ID ENHANCING SECURITY; PRIVACY
AB The Industrial IoT is starting an enormous advancement occasion in the industrial epoch. Data security as well as privacy becomes a challenge in almost every field in the real life for the duration of monitoring and collection of data in Industrial Internet of Things (IIoT) applications. The security and privacy of data in IIoT depends on the user's reliability that can be obtained by using the user authentication scheme otherwise unable to secure the IIoT applications data. Many authors have proposed the user authentication schemes in industrial internet of things who suffer from some hindrances such as data security, throughput, single point of failure, storage problem and latency (due to which increases the eavesdropping attacks chances). Therefore, to eliminate the above security issues, this paper proposes a new hybrid authentication approach instead of that also increases the throughput of IIoT applications, reduces the latency as well as enhances the accuracy of IIoT users. To create smart contracts of user authentication approaches by using the PKI and ECC algorithms, whereas it helps to achieve the privacy preservation. Instead of that, ECC that constructs the trustworthy user authentication blockchain scheme which enhance the privacy further as well as helps to maintain the number of keys along, every time keys are updated continuously. Moreover, we implement the proposed approach on the Ethereum blockchain and put all the data through smart contract on the decentralized IPFS cloud server which is transparent, secure, traceable, and storage utilization. Only authenticated users can interface with IIoT applications, even if someone tries to corrupt them, and then revoke the digital certificate from the user. It will be known from the performance of this paper that the proposed approach not only provides the privacy of the users but also obtains the high authentication accuracy, throughput and reduces the latency in comparison of existing approach.
C1 [Devi, Anju; Kumar, Amit] Jaypee Univ Informat Technol, Dept Comp Sci & Engn, Waknaghat, Solan 173234, Himachal Prades, India.
   [Rathee, Geetanjali] Netaji Subhas Univ Technol, Dept Comp Sci & Engn, Dwarka Sect, 3, New Delhi, India.
   [Saini, Hemraj] DIT Univ, Sch Comp, Dehra Dun 248009, India.
C3 Jaypee University of Information Technology; Netaji Subhas University of
   Technology; DIT University
RP Rathee, G (corresponding author), Netaji Subhas Univ Technol, Dept Comp Sci & Engn, Dwarka Sect, 3, New Delhi, India.
EM geetanjali.rathee123@gmail.com
RI Saini, Hemraj/K-9849-2015
OI Rathee, Geetanjali/0000-0002-4761-1912
CR Ahsan T, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/8570064
   Bai L, 2019, IEEE ACCESS, V7, P58381, DOI 10.1109/ACCESS.2019.2914223
   Bhuyan H. K., INTELLIGENT DATA ANA, V2021, P57
   Bhuyan HK, 2022, ENG OPTIMIZ, V54, P1305, DOI 10.1080/0305215X.2021.1922897
   Bhuyan HK, 2014, CLUSTER COMPUT, V17, P1383, DOI 10.1007/s10586-014-0393-9
   Cai XJ, 2021, IEEE T IND INFORM, V17, P7650, DOI 10.1109/TII.2021.3051607
   Fan Q, 2021, J SYST ARCHITECT, V117, DOI 10.1016/j.sysarc.2021.102112
   Figueroa-Lorenzo S, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102558
   Huang JQ, 2019, IEEE T IND INFORM, V15, P3680, DOI 10.1109/TII.2019.2903342
   Iqbal S, 2021, IEEE INTERNET THINGS, V8, P14746, DOI 10.1109/JIOT.2021.3071562
   Javaid U, 2021, IEEE T IND INFORM, V17, P7679, DOI 10.1109/TII.2020.3032607
   Jia B, 2022, IEEE T IND INFORM, V18, P4049, DOI 10.1109/TII.2021.3085960
   Latif S, 2021, J IND INF INTEGR, V21, DOI 10.1016/j.jii.2020.100190
   Maria A, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11030488
   Qiu C, 2019, IEEE INTERNET THINGS, V6, P4627, DOI 10.1109/JIOT.2018.2871394
   Tao D, 2019, INT J COMMUN SYST, V32, DOI 10.1002/dac.4099
   Vishwakarma L, 2021, J PARALLEL DISTR COM, V154, P94, DOI 10.1016/j.jpdc.2021.04.003
   Wan JF, 2019, IEEE T IND INFORM, V15, P3652, DOI 10.1109/TII.2019.2894573
   Wang CY, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-020-2975-6
   Wang J, 2021, AD HOC NETW, V119, DOI 10.1016/j.adhoc.2021.102526
   Wang J, 2020, IEEE T IND INFORM, V16, P1984, DOI 10.1109/TII.2019.2936278
   Wang XD, 2021, IEEE T IND INFORM, V17, P7725, DOI 10.1109/TII.2021.3049405
   Yu KP, 2021, IEEE T IND INFORM, V17, P7669, DOI 10.1109/TII.2021.3049141
   Zareen H, 2021, LECT NOTE NETW SYST, V278, P259, DOI 10.1007/978-3-030-79725-6_25
   Zhai X, 2023, COMPLEX INTELL SYST, V9, P2865, DOI 10.1007/s40747-021-00617-1
   Zhao SS, 2019, IEEE T COMPUT SOC SY, V6, P1442, DOI 10.1109/TCSS.2019.2924054
NR 26
TC 4
Z9 4
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 19021
EP 19039
DI 10.1007/s11042-022-14154-7
EA DEC 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000921144700002
DA 2024-07-18
ER

PT J
AU Ullah, A
   Khan, SN
   Nawi, NM
AF Ullah, Arif
   Khan, Sundas Naqeeb
   Nawi, Nazri Mohd
TI Review on sentiment analysis for text classification techniques from
   2010 to 2021
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Sentiment analysis; Text classification; Opinion mining; Natural
   language
ID PRODUCT FEATURE-EXTRACTION; SUPPORT VECTOR MACHINE; STRENGTH DETECTION;
   MINING OPINIONS; CHINESE REVIEWS; SUBJECTIVE DATA; NAIVE BAYES; DOMAIN;
   MODEL; ALGORITHMS
AB Progression in the popularity of social media activities had provided huge amount of data in the form of text that can immeasurably augment its specialty. This textual data offers a platform for the reviewers to share their comments about any product, service or event on social media. These types of discussions among the reviewers boost the demand and supply in business and industry field. Furthermore, for every passing day the textual data is also increasing in amount which makes data mining especially sentiment analysis or opinion mining, a research hungry area. This is mainly because of data is represented in the form of calculations about reviewers' comments, assessment, attitudes, behavior and emotions to individual issues, events, topics, services and attributes. Previously, researchers focus on systems to recognize and categorize sentiments from the written material where opinions are extremely unstructured, assorted and classified. In this paper, authors try to presents a meticulous survey on sentiment analysis with classification, in which one hundred and forty three articles were reviewed regarding important activities, approaches, applications with multilingual and cross domain jobs. This systematic survey considers published literature during 2010-2021, organized based on machine learning, lexicon and hybrid approaches with multilingual and cross domain knowledge.
C1 [Ullah, Arif] Riphah Int Univ, Dept Comp, Faisalabad 44000, Punjab, Pakistan.
   [Khan, Sundas Naqeeb; Nawi, Nazri Mohd] Univ Tun Hussein Onn Malaysia UTHM, Fac Comp Sci & Informat Technol, Soft Comp & Data Min Ctr SMC, Parit Raja, Malaysia.
RP Ullah, A (corresponding author), Riphah Int Univ, Dept Comp, Faisalabad 44000, Punjab, Pakistan.
EM arifullahms88@gamil.com; sndskhan87@gmail.com; nazri@uthm.edu.my
RI MOHD NAWI, NAZRI/F-6360-2011; ULLAH, ARIF/C-3845-2019
OI ULLAH, ARIF/0000-0002-7740-2206
CR Abbasi A, 2008, ACM T INF SYST TOIS, V26, P12
   Abbasi A, 2011, IEEE T KNOWL DATA EN, V23, P447, DOI 10.1109/TKDE.2010.110
   Abdul-Mageed M, 2014, COMPUT SPEECH LANG, V28, P20, DOI 10.1016/j.csl.2013.03.001
   Adeleke A.O., 2017, INT J ADV SCI ENG IN, V7, P1419, DOI DOI 10.18517/IJASEIT.7.4.2198
   Ali F, 2016, APPL SOFT COMPUT, V47, P235, DOI 10.1016/j.asoc.2016.06.003
   [Anonymous], 2011, P 4 ACM INT C WEB SE, DOI DOI 10.1145/1935826.1935884
   [Anonymous], 2005, P HLTEMNLP 2005 INTE
   [Anonymous], 2015, P 24 ACM INT C INFOR
   [Anonymous], 2008, P C EMP METH NAT LAN
   [Anonymous], 2004, P 20 INT C COMP LING
   [Anonymous], 2013, P C EMP METH NAT LAN
   [Anonymous], 2010, P 23 INT C COMP LING
   [Anonymous], 2009, Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing
   [Anonymous], 2013, P ACL
   [Anonymous], 2006, P 5 INT C LANG RES E
   [Anonymous], 2009, Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing
   [Anonymous], 2007, P 45 ANN M ASS COMPU
   [Anonymous], 1963, AFIPS Conference Proceedings
   [Anonymous], 1992, P 14 C COMPUTATIONAL
   Archak N, 2007, DERIVING PRICING POW
   Arif MH, 2018, SOFT COMPUT, V22, P7281, DOI 10.1007/s00500-017-2729-x
   Atkinson, 2006, Gnu aspell, Patent No. [0.60.4, 0604]
   Baccianella S, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Bai X, 2011, DECIS SUPPORT SYST, V50, P732, DOI 10.1016/j.dss.2010.08.024
   Balahur A, 2012, DECIS SUPPORT SYST, V53, P742, DOI 10.1016/j.dss.2012.05.024
   Bao HY, 2013, DECIS SUPPORT SYST, V55, P698, DOI 10.1016/j.dss.2013.02.007
   Basari AH, 2013, PROCEDIA ENGINEER, V53, P453, DOI 10.1016/j.proeng.2013.02.059
   Bell D, 2014, KNOWL-BASED SYST, V69, P64, DOI 10.1016/j.knosys.2014.05.009
   Benamara F., 2007, ICWSM, V7, P203
   Bhatia Parminder, 2015, ARXIV
   Bilianos D, 2022, J QUANT LINGUIST, V29, P374, DOI 10.1080/09296174.2021.1885872
   Bird S., 2009, NATURAL LANGUAGE PRO
   Blackburn, 2015, DEV PSYCHOMETRIC PRO
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blitzer J., 2007, Proceedings of the 45th annual meeting of the association of computational linguistics, V45, P440
   Boiy Erik, 2007, 11th International Conference on Electronic Publishing. Openness in Digital Publishing: Awareness, Discovery and Access, P349
   Boiy E, 2009, INFORM RETRIEVAL, V12, P526, DOI 10.1007/s10791-008-9070-z
   Boldrini E, 2012, DATA MIN KNOWL DISC, V25, P603, DOI 10.1007/s10618-012-0259-9
   Bollegala D., 2011, P 49 ANN M ASS COMPU, P132
   Bollegala D, 2013, IEEE T KNOWL DATA EN, V25, P1719, DOI 10.1109/TKDE.2012.103
   Bollen J, 2011, J COMPUT SCI-NETH, V2, P1, DOI 10.1016/j.jocs.2010.12.007
   Bonzanini M, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P991, DOI 10.1145/2348283.2348415
   Bouazizi M, 2017, IEEE ACCESS, V5, P20617, DOI 10.1109/ACCESS.2017.2740982
   Brody S., 2010, HUMAN LANGUAGE TECHN, P804
   Bross J, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P1077
   Cambria E, 2015, NEUROCOMPUTING, V149, P443, DOI 10.1016/j.neucom.2014.01.064
   Cambria E, 2014, IEEE COMPUT INTELL M, V9, P48, DOI 10.1109/MCI.2014.2307227
   Cambria E, 2013, IEEE INTELL SYST, V28, P15, DOI 10.1109/MIS.2013.30
   Cao Q, 2011, DECIS SUPPORT SYST, V50, P511, DOI 10.1016/j.dss.2010.11.009
   Chambers N., 2015, P 2015 C EMPIRICAL M, P65, DOI DOI 10.18653/V1/D15-1007
   Che W., 2010, Proceedings of the 23rd international conference on computational linguistics: Demonstrations, P13
   Chen CC, 2011, DECIS SUPPORT SYST, V50, P755, DOI 10.1016/j.dss.2010.08.023
   Chen LS, 2011, J INFORMETR, V5, P313, DOI 10.1016/j.joi.2011.01.003
   Chen Q, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P419
   Chen X, 2014, IEEE T LEARN TECHNOL, V7, P246, DOI 10.1109/TLT.2013.2296520
   Chen XC, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1744
   Chenlo Jose M., 2013, Natural Language Processing and Information Systems. 18th International Conference on Applications of Natural Language to Information Systems, NLDB 2013. Proceedings: LNCS 7934, P13, DOI 10.1007/978-3-642-38824-8_2
   Chklovski T., 2004, P 2004 C EMPIRICAL M
   Coussement K, 2009, EXPERT SYST APPL, V36, P6127, DOI 10.1016/j.eswa.2008.07.021
   Crammer K, 2003, J MACH LEARN RES, V3, P951, DOI 10.1162/jmlr.2003.3.4-5.951
   Cruz FL, 2013, EXPERT SYST APPL, V40, P3174, DOI 10.1016/j.eswa.2012.12.031
   Cui H., 2006, Proceedings of the AAAI conference on artificial intelligence, V6, P1265
   Da Silva NFF, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2932708
   Dang Y, 2010, IEEE INTELL SYST, V25, P46, DOI 10.1109/MIS.2009.105
   Das S, 2001, P AS PAC FIN ASS ANN, V35, P43
   Dasgupta Sajib, 2009, Proceedings of the Joint Conference ACL-IJCNLP, P701
   Demirtas E., 2013, Cross-Lingual Sentiment Analysis with Machine Translation
   Deng ZH, 2014, EXPERT SYST APPL, V41, P3506, DOI 10.1016/j.eswa.2013.10.056
   Derczynski L., 2013, P INT C REC ADV NAT, P198
   Deshmukh JS, 2017, APPL COMPUT INF
   Di Caro L, 2013, COMPUT STAND INTER, V35, P442, DOI 10.1016/j.csi.2012.10.005
   Ding XW, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1125
   Du JF, 2014, EXPERT SYST APPL, V41, P1680, DOI 10.1016/j.eswa.2013.08.065
   Duric A, 2012, DECIS SUPPORT SYST, V53, P704, DOI 10.1016/j.dss.2012.05.023
   Eirinaki M, 2012, J COMPUT SYST SCI, V78, P1175, DOI 10.1016/j.jcss.2011.10.007
   El Rahman SA, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P336, DOI 10.1109/iccisci.2019.8716464
   Fan TK, 2011, EXPERT SYST APPL, V38, P1777, DOI 10.1016/j.eswa.2010.07.105
   Fang Q, 2015, IEEE T MULTIMEDIA, V17, P2281, DOI 10.1109/TMM.2015.2491019
   Fauzi MA, 2018, IMPROVING SENTIMENT
   Feldman R, 2013, COMMUN ACM, V56, P82, DOI 10.1145/2436256.2436274
   Fu XH, 2013, KNOWL-BASED SYST, V37, P186, DOI 10.1016/j.knosys.2012.08.003
   Gao DH, 2015, COMPUT LINGUIST, V41, P21, DOI 10.1162/COLI_a_00207
   Ghiassi M, 2013, EXPERT SYST APPL, V40, P6266, DOI 10.1016/j.eswa.2013.05.057
   Gimpel K, 2011, P 49 ANN M ASS COMPU, V49, P42
   Gindl S, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P557
   Go A., 2009, Twitter sentiment classification using distant supervision, V150, DOI DOI 10.1016/J.SEDGEO.2006.07.004
   Gupta SK, 2013, DATA MIN KNOWL DISC, V26, P57, DOI 10.1007/s10618-011-0244-8
   Hagenau M, 2013, DECIS SUPPORT SYST, V55, P685, DOI 10.1016/j.dss.2013.02.006
   He Y., 2011, ACL, VVolume 1, P123, DOI DOI 10.1007/978-3-319-18458-6_3
   He YL, 2011, INFORM PROCESS MANAG, V47, P606, DOI 10.1016/j.ipm.2010.11.003
   Heerschop B., 2011, Proceedings of the 20th ACM International Conference on Information and Knowledge Management CIKM, P1061, DOI [10.1145/2063576.2063730, DOI 10.1145/2063576.2063730]
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P755
   Hu N, 2012, DECIS SUPPORT SYST, V52, P674, DOI 10.1016/j.dss.2011.11.002
   Hu YH, 2017, INFORM PROCESS MANAG, V53, P436, DOI 10.1016/j.ipm.2016.12.002
   Hu Y, 2011, COMPUT SPEECH LANG, V25, P386, DOI 10.1016/j.csl.2010.07.004
   Hung C, 2013, IEEE INTELL SYST, V1
   Xuan HNT, 2012, INT CONF ASIAN LANG, P17, DOI 10.1109/IALP.2012.47
   Ismail S, 2016, INTERNATIONAL CONFERENCE ON INFORMATICS AND SYSTEMS (INFOS 2016), P173, DOI 10.1145/2908446.2908467
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jenq-Haur Wang, 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P820, DOI 10.1109/PASSAT/SocialCom.2011.134
   Jiang DD, 2017, IEEE ACCESS, V5, P2373, DOI 10.1109/ACCESS.2016.2607218
   Jiang Long, 2011, P 49 ANN M ASS COMP, P151
   Jiao J, 2011, PHYSCS PROC, V22, P590, DOI 10.1016/j.phpro.2011.11.091
   Jindal N., 2008, WSDM 08, P219, DOI [DOI 10.1145/1341531.1341560, 10.1145/1341531.1341560]
   Jo Yohan, 2011, P 4 ACM INT C WEB SE, P815, DOI DOI 10.1145/1935826.1935932
   Kamps J, 2001, WORDS ATTITUDE, P332
   Kanayama H., 2006, Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2006), P355
   Kang H, 2012, EXPERT SYST APPL, V39, P6000, DOI 10.1016/j.eswa.2011.11.107
   Kang M, 2018, EXPERT SYST APPL, V94, P218, DOI 10.1016/j.eswa.2017.07.019
   Kaufmann M., 2012, P COLING 2012 DEMONS, P277
   Kaur H, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3343440
   Kennedy A, 2006, COMPUT INTELL-US, V22, P110, DOI 10.1111/j.1467-8640.2006.00277.x
   Keshtkar F, 2013, COMPUT INTELL-US, V29, P417, DOI 10.1111/j.1467-8640.2012.00458.x
   Khamparia A, 2020, EDUC INF TECHNOL, V25, P1303, DOI 10.1007/s10639-019-10028-y
   Khan FH, 2014, DECIS SUPPORT SYST, V57, P245, DOI 10.1016/j.dss.2013.09.004
   KHAN SN, 2018, INT J ADV SCI ENG IN, V8, P1836, DOI DOI 10.18517/IJASEIT.8.5.5002
   Kim S., 2004, P 20 INT C COMP LING, DOI DOI 10.3115/1220355.1220555
   Kontopoulos E, 2013, EXPERT SYST APPL, V40, P4065, DOI 10.1016/j.eswa.2013.01.001
   Kouloumpis E., 2011, Icwsm, P538
   Ku LW, 2007, J AM SOC INF SCI TEC, V58, P1838, DOI 10.1002/asi.20630
   Kumar Akshi, 2020, International Journal of Information Technology, V12, P1159, DOI 10.1007/s41870-017-0072-1
   Lafferty John, 2001, INT C MACH LEARN ICM
   Lambert P, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P781
   Lambov D, 2011, PROCD SOC BEHV, V27, P248, DOI 10.1016/j.sbspro.2011.10.605
   Lane PCR, 2012, DECIS SUPPORT SYST, V53, P712, DOI 10.1016/j.dss.2012.05.028
   Lazaridou Angeliki., 2013, ACL, P1630
   Li FT, 2010, AAAI CONF ARTIF INTE, P1371
   Li S., 2011, 22 INT JOINT C ART I
   Li ST, 2013, KNOWL-BASED SYST, V39, P23, DOI 10.1016/j.knosys.2012.10.005
   Li SS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P27
   Li Shoushan., 2013, AAAI, P2127
   Li YM, 2013, DECIS SUPPORT SYST, V55, P206, DOI 10.1016/j.dss.2013.01.023
   Li YM, 2012, DECIS SUPPORT SYST, V54, P9, DOI 10.1016/j.dss.2012.02.012
   Lin C., 2009, P 18 ACM C INF KNOWL, P375, DOI DOI 10.1145/1645953.1646003
   Lin CH, 2012, IEEE T KNOWL DATA EN, V24, P1134, DOI 10.1109/TKDE.2011.48
   Liu B., 2002, ICML, P387
   Liu B., 2005, Proceedings of 14th International Conference of World Wide Web, P342
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Liu K., 2009, PROC 18 ACM C INFORM, P1717
   Liu K, 2015, IEEE T KNOWL DATA EN, V27, P636, DOI 10.1109/TKDE.2014.2339850
   Liu Y, 2007, P ACM SIGIR C RES DE, P607, DOI [10.1145/1277741.1277845, DOI 10.1145/1277741.1277845]
   Lu CY, 2010, EXPERT SYST APPL, V37, P1643, DOI 10.1016/j.eswa.2009.06.099
   Lu Y, 2010, LECT NOTES COMPUT SC, V6184, P471, DOI 10.1007/978-3-642-14246-8_46
   Lu Yue., 2011, WWW, DOI [DOI 10.1145/1963405.1963456, 10.1145/1963405.1963456]
   Ma JQ, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1733
   Maas Andrew, 2011, P 49 ANN M ASS COMP
   Maks I, 2012, DECIS SUPPORT SYST, V53, P680, DOI 10.1016/j.dss.2012.05.025
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Marrese-Taylor E, 2014, EXPERT SYST APPL, V41, P7764, DOI 10.1016/j.eswa.2014.05.045
   MARSTAWI A., 2017, P 8 INT C COMP MOD S, P100
   Martín-Valdivia MT, 2013, EXPERT SYST APPL, V40, P3934, DOI 10.1016/j.eswa.2012.12.084
   McDonald Ryan., 2007, Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, P432
   McDonald Ryan, 2005, P 43 ANN M ASS COMPU, P91
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Meng X., 2012, Proceedings of ACL, P572
   Miao QL, 2009, EXPERT SYST APPL, V36, P7192, DOI 10.1016/j.eswa.2008.09.035
   Min HJ, 2012, EXPERT SYST APPL, V39, P11830, DOI 10.1016/j.eswa.2012.01.116
   Mohammad SM, 2012, DECIS SUPPORT SYST, V53, P730, DOI 10.1016/j.dss.2012.05.030
   Montoyo A, 2012, DECIS SUPPORT SYST, V53, P675, DOI 10.1016/j.dss.2012.05.022
   Moraes R, 2013, EXPERT SYST APPL, V40, P621, DOI 10.1016/j.eswa.2012.07.059
   Moreo A, 2012, EXPERT SYST APPL, V39, P9166, DOI 10.1016/j.eswa.2012.02.057
   Mostafa MM, 2013, EXPERT SYST APPL, V40, P4241, DOI 10.1016/j.eswa.2013.01.019
   Mukherjee S, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3092
   Mullen T., 2004, P 2004 C EMPIRICAL M
   Narayanan R., 2009, Proceedings of EMNLP '09, V1, P180, DOI 10.3115/1699510.1699534
   Nasukawa T., 2003, P 2 INT C KNOWLEDGE, P70, DOI DOI 10.1145/945645.945658
   Neviarouskaya A., 2010, Proceedings of the 23rd International Conference on Computational Linguistics, Beijing, China, P806
   Nopp C., 2015, P 2015 C EMPIRICAL M, P591, DOI [DOI 10.18653/V1/D15-1071, 10.18653/v1/D15-1071]
   OConnor B., 2010, P INT AAAI C WEBLOGS, P1
   Ortigosa A, 2014, COMPUT HUM BEHAV, V31, P527, DOI 10.1016/j.chb.2013.05.024
   Ortigosa-Hernández J, 2012, NEUROCOMPUTING, V92, P98, DOI 10.1016/j.neucom.2012.01.030
   Ouhame S, 2021, NEURAL COMPUT APPL, V33, P10043, DOI 10.1007/s00521-021-05770-9
   Owoputi O, 2013, ASS COMPUT LINGUIST
   Pai MY, 2013, EXPERT SYST APPL, V40, P1993, DOI 10.1016/j.eswa.2012.10.024
   Pak A., 2010, COMPUTER, P19, DOI DOI 10.17148/IJARCCE.2016.51274
   Pan S. J., 2010, Cross-domain sentiment classi fication via spectral feature alignment, P751, DOI DOI 10.1145/1772690.1772767
   Pang B., 2004, ANN M ASS COMP LING, P271, DOI [10.3115/1218955.1218990, DOI 10.3115/1218955.1218990]
   Pang B, 2005, P 43 ANN M ASS COMP, P115, DOI [10.3115/1219840.1219855, DOI 10.3115/1219840.1219855]
   Pang B., 2008, INFORM RETRIEVAL, V2, P1, DOI [10.1561/1500000011, DOI 10.1561/1500000011, https://doi.org/10.1561/1500000011]
   Peñalver-Martinez I, 2014, EXPERT SYST APPL, V41, P5995, DOI 10.1016/j.eswa.2014.03.022
   Peng F., 2004, InternationalConferenceonComputational Linguistics, DOI DOI 10.3115/1220355.1220436
   Pisal S., 2011, 2011 IEEE International Conference on Data Mining Workshops, P1243, DOI 10.1109/ICDMW.2011.24
   Popescu Ana-Maria., 2005, Proceedings of HLT/EMNLP on interactive demonstrations, P32
   Popescu O, 2014, KNOWL-BASED SYST, V69, P3, DOI 10.1016/j.knosys.2014.04.029
   Poria S, 2016, KNOWL-BASED SYST, V108, P42, DOI 10.1016/j.knosys.2016.06.009
   Prabowo R, 2009, J INFORMETR, V3, P143, DOI 10.1016/j.joi.2009.01.003
   Przepiorkowski A, 2009, P PRACTICAL APPL LAN
   Ptaszynski M, 2013, EXPERT SYST APPL, V40, P168, DOI 10.1016/j.eswa.2012.07.025
   Qazi A, 2017, INT RES ELSIVER
   Qiao FL, 2021, IEEE T INTELL TRANSP, V22, P4443, DOI 10.1109/TITS.2020.3003211
   Qiu GA, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1199
   Qiu GA, 2010, EXPERT SYST APPL, V37, P6182, DOI 10.1016/j.eswa.2010.02.109
   Qiu LF, 2013, DECIS SUPPORT SYST, V55, P978, DOI 10.1016/j.dss.2013.01.007
   Quan CQ, 2014, INFORM SCIENCES, V272, P16, DOI 10.1016/j.ins.2014.02.063
   Rabelo JCB, 2012, IEEE SYS MAN CYBERN, P681, DOI 10.1109/ICSMC.2012.6377805
   Racherla P, 2012, ELECTRON COMMER R A, V11, P548, DOI 10.1016/j.elerap.2012.06.003
   Rahman MMFZ, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P155, DOI 10.1145/2872427.2883073
   Raut Mukta Y., 2016, 2016 IEEE International Conference on Advances in Electronics, Communication and Computer Technology (ICAECCT), P333, DOI 10.1109/ICAECCT.2016.7942608
   Rehurek R., 2010, P LREC 2010 WORKSH N, P45, DOI DOI 10.13140/2.1.2393.1847
   Reyes A, 2012, DECIS SUPPORT SYST, V53, P754, DOI 10.1016/j.dss.2012.05.027
   Rezaeinia SM, 2019, EXPERT SYST APPL, V117, P139, DOI 10.1016/j.eswa.2018.08.044
   Rill S, 2014, KNOWL-BASED SYST, V69, P24, DOI 10.1016/j.knosys.2014.05.008
   Riloff E, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P105
   Riloff E., 2003, Proceedings of the 7th Conference on Natural Language Learning (CoNLL-2003), V4, P25
   Roiger R.J., 2017, Data mining: a tutorial-based primer
   Roussev V, 2013, DIGIT INVEST, V10, pS69, DOI 10.1016/j.diin.2013.06.008
   Rui HX, 2013, DECIS SUPPORT SYST, V55, P863, DOI 10.1016/j.dss.2012.12.022
   Saleh MR, 2011, EXPERT SYST APPL, V38, P14799, DOI 10.1016/j.eswa.2011.05.070
   Santosh DT, 2016, IJEME, V6, P1
   Seki Y, 2009, INFORM PROCESS MANAG, V45, P189, DOI 10.1016/j.ipm.2008.11.004
   Severyn A, 2016, INFORM PROCESS MANAG, V52, P46, DOI 10.1016/j.ipm.2015.03.002
   Shah K., 2020, AUGMENT HUMAN RES, V5, P1, DOI DOI 10.1007/S41133-020-00032-0
   Sharma R, 2014, ARXIV
   Shawe-Taylor J, 2011, NEUROCOMPUTING, V74, P3609, DOI 10.1016/j.neucom.2011.06.026
   Sindhwani V, 2008, IEEE DATA MINING, P1025, DOI 10.1109/ICDM.2008.113
   Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Sperberg-McQueen C. M., 1991, Literary & Linguistic Computing, V6, P34, DOI 10.1093/llc/6.1.34
   Spina D, 2013, EXPERT SYST APPL, V40, P4986, DOI 10.1016/j.eswa.2013.03.001
   Steinberger J, 2012, DECIS SUPPORT SYST, V53, P689, DOI 10.1016/j.dss.2012.05.029
   Stone P. J., 1966, GEN INQUIRER COMPUTE
   Sun YG, 2021, IEEE T INTELL TRANSP, V22, P4431, DOI 10.1109/TITS.2020.3045319
   Taboada M, 2004, AAAI TECHNICAL RE PO
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Tackstrom Oscar., 2011, ACL, P569
   Taddy M, 2013, TECHNOMETRICS, V55, P415, DOI 10.1080/00401706.2013.778791
   Tan LKW, 2012, J COMPUT SCI TECH-CH, V27, P650, DOI 10.1007/s11390-012-1251-y
   Tan SL, 2014, IEEE T KNOWL DATA EN, V26, P1158, DOI 10.1109/TKDE.2013.116
   Tan SB, 2011, EXPERT SYST APPL, V38, P12094, DOI 10.1016/j.eswa.2011.02.105
   Tan SB, 2011, EXPERT SYST APPL, V38, P10524, DOI 10.1016/j.eswa.2011.02.106
   Tan SB, 2009, LECT NOTES COMPUT SC, V5478, P337
   Tang DY, 2015, IEEE-ACM T AUDIO SPE, V23, P1750, DOI 10.1109/TASLP.2015.2449071
   Thelen M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P214
   Thelwall M, 2013, J AM SOC INF SCI TEC, V64, P1608, DOI 10.1002/asi.22872
   Thelwall M, 2012, J AM SOC INF SCI TEC, V63, P163, DOI 10.1002/asi.21662
   Thelwall M, 2011, J AM SOC INF SCI TEC, V62, P406, DOI 10.1002/asi.21462
   Thelwall M, 2010, J AM SOC INF SCI TEC, V61, P2544, DOI 10.1002/asi.21416
   Thet TT, 2010, J INF SCI, V36, P823, DOI 10.1177/0165551510388123
   Tong RichardM., 2001, WORKING NOTES ACM SI, P1
   Trivedi Rakshit., 2013, Proceedings of NAACL-HLT, P808
   Tsai ACR, 2013, IEEE INTELL SYST, V28, P22, DOI 10.1109/MIS.2013.25
   Tseng H., 2005, P 4 SIGHAN WORKSHOP, V171
   Tsytsarau M, 2012, DATA MIN KNOWL DISC, V24, P478, DOI 10.1007/s10618-011-0238-6
   Tumasjan A, 2010, 4 INT AAAI C WEBL SO, V10, P178, DOI 10.1074/jbc.M501708200
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   Ullah Arif, 2020, International Journal of High Performance Computing and Networking, V16, P43, DOI 10.1504/IJHPCN.2020.110258
   Ullah A, 2020, INT J MODEL SIMUL SC, V11, DOI 10.1142/S1793962320500415
   Usai A, 2018, J KNOWL MANAG, V22, P1471, DOI 10.1108/JKM-11-2017-0517
   van de Camp M, 2012, DECIS SUPPORT SYST, V53, P761, DOI 10.1016/j.dss.2012.05.031
   Vinodhini G., 2014, CSI Transactions on ICT, V2, P169
   Walker MA, 2012, DECIS SUPPORT SYST, V53, P719, DOI 10.1016/j.dss.2012.05.032
   Wan X., 2009, P JOINT C 47 ANN M A, P235
   Wan Xiaojun., 2008, EMNLP, P553, DOI DOI 10.3115/1613715.1613783
   Wang G, 2014, DECIS SUPPORT SYST, V57, P77, DOI 10.1016/j.dss.2013.08.002
   Wang H, 2010, Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P783, DOI [DOI 10.1145/1835804.1835903, 10.1145/1835804.1835903]
   Wang JZ, 2015, INFORM FUSION, V23, P3, DOI 10.1016/j.inffus.2014.04.002
   Wang LL, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P616
   Wang S., 2012, Baselines and bigrams: Simple, good sentiment and topic classification, P90
   Wang SG, 2011, EXPERT SYST APPL, V38, P8696, DOI 10.1016/j.eswa.2011.01.077
   Wang T, 2014, KNOWL-BASED SYST, V71, P86, DOI 10.1016/j.knosys.2014.05.018
   Wei B., 2010, P ACL 2010 C SHORT P, P258
   Weichselbraun A, 2014, KNOWL-BASED SYST, V69, P78, DOI 10.1016/j.knosys.2014.04.039
   Weichselbraun A, 2013, IEEE INTELL SYST, V28, P39, DOI 10.1109/MIS.2013.41
   Whitelaw C, 2005, P 14 ACM INT C INF K, P625, DOI 10.1145/1099554.1099714
   Wiebe J, 2005, LANG RESOUR EVAL, V39, P165, DOI 10.1007/s10579-005-7880-9
   Wilson TS, 2005, PHIL EDUC, P347, DOI 10.3115/1220575.1220619
   Wu CE, 2014, KNOWL-BASED SYST, V69, P100, DOI 10.1016/j.knosys.2014.04.043
   Wu Q, 2011, EXPERT SYST APPL, V38, P14269, DOI 10.1016/j.eswa.2011.04.240
   Xia R, 2011, INFORM SCIENCES, V181, P1138, DOI 10.1016/j.ins.2010.11.023
   Xu H, 2015, KNOWL-BASED SYST, V76, P166, DOI 10.1016/j.knosys.2014.12.012
   Xu KQ, 2011, DECIS SUPPORT SYST, V50, P743, DOI 10.1016/j.dss.2010.08.021
   Xu T, 2012, KNOWL-BASED SYST, V35, P279, DOI 10.1016/j.knosys.2012.04.011
   Xu XK, 2013, CHINA COMMUN, V10, P25, DOI 10.1109/CC.2013.6488828
   Xu YC, 2013, WITHDRAWN MEASURING
   Yadav SK, 2012, ARXIV
   Yan ZJ, 2015, INFORM MANAGE-AMSTER, V52, P850, DOI 10.1016/j.im.2015.02.002
   Yang BS, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P325
   Yang HH, 2019, IEEE T IND INFORM, V15, P4178, DOI 10.1109/TII.2019.2897128
   Yang P, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3339474
   Ye Q., 2006, Proceedings of the 39th Annual Hawaii International Conference on System Sciences, V3, P53, DOI [DOI 10.1109/HICSS.2006.432, 10.1109/HICSS.2006.432]
   Yi JH, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P427, DOI 10.1109/ICDM.2003.1250949
   Yu H, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P129
   Yu LC, 2013, KNOWL-BASED SYST, V41, P89, DOI 10.1016/j.knosys.2013.01.001
   Yu Y, 2013, DECIS SUPPORT SYST, V55, P919, DOI 10.1016/j.dss.2012.12.028
   Zhan JM, 2009, EXPERT SYST APPL, V36, P2107, DOI 10.1016/j.eswa.2007.12.039
   Zhang CL, 2009, J AM SOC INF SCI TEC, V60, P2474, DOI 10.1002/asi.21206
   Zhang Lei., 2010, Proceedings of the 23rd International Conference on Computational Linguistics: Posters, P1462
   Zhang W., 2010, P INT AAAI C WEB SOC, P375
   Zhang WH, 2012, EXPERT SYST APPL, V39, P10283, DOI 10.1016/j.eswa.2012.02.166
   Zhang Yue., 2008, P ACL 08, P888
   Zhang Z, 2008, IEEE INTELL SYST, V23, P42, DOI 10.1109/MIS.2008.95
   Zhang ZQ, 2011, EXPERT SYST APPL, V38, P7674, DOI 10.1016/j.eswa.2010.12.147
   Zhao L, 2015, PROC INT C INF KNOWL, P343
   Zhao Yan-Yan, 2010, Acta Automatica Sinica, V36, P1417, DOI 10.3724/SP.J.1004.2010.01417
   Zhou Lanjun., 2011, EMNLP, P162
   Zhou L, 2008, J AM SOC INF SCI TEC, V59, P98, DOI 10.1002/asi.20735
   Zhou XJ, 2016, IEEE T KNOWL DATA EN, V28, P1650, DOI 10.1109/TKDE.2016.2541148
   Zhu JB, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2015): SYSTEM DEMONSTRATIONS, P145
   Zirn Cacilia., 2011, IJCNLP, P336
NR 299
TC 1
Z9 1
U1 21
U2 62
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8137
EP 8193
DI 10.1007/s11042-022-14112-3
EA DEC 2022
PG 57
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000893056800004
DA 2024-07-18
ER

PT J
AU Al-Qaysi, ZT
   Ahmed, MA
   Hammash, NM
   Hussein, AF
   Albahri, AS
   Suzani, MS
   Al-Bander, B
AF Al-Qaysi, Z. T.
   Ahmed, M. A.
   Hammash, Nayif Mohammed
   Hussein, Ahmed Faeq
   Albahri, A. S.
   Suzani, M. S.
   Al-Bander, Baidaa
TI A systematic rank of smart training environment applications with motor
   imagery brain-computer interface
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Evaluation and benchmarking; STE application; BCI; Motor imagery; MCDM
ID DECISION; BCI; VR
AB Brain-Computer Interface (BCI) research is considered one of the significant interdisciplinary fields. It assists people with severe motor disabilities to recover and improve their motor actions through rehabilitation sessions using Motor Imagery (MI) based BCI systems. Several smart criteria, such as virtual reality, plays a significant role in training people for motor recovery in a virtual environment. Accordingly, Smart Training Environments (STEs) based on virtual reality for MI-BCI users provide a safe environment. They are cost-effective for real-life conditions and scenarios with severe motor disabilities. Fundamentally, the literature presents a lack of comparison of the STE applications considering the smart and effective criteria of the developed applications. Accordingly, three key issues faced the comparison process: importance, multi-evaluation criteria, and data variation, which falls under complex Multi-Criteria Decision Making (MCDM). Performance issues increased comparison complexity caused by the rapidly changing market demands of the MI-BCI. Therefore, this study developed two methodology phases for evaluating and benchmarking the STE applications for the MI-BCI community; making effective decisions is vital. In the first phase, formulate the STE Decision Matrix (DM) based on two main dimensions: the evaluation of ten smart criteria of STE and the alternatives (27 STE applications) developed in the literature for MI-BCI. In the second phase, integration methods of MCDM have been formulated: Analytic Hierarchy Process (AHP) for weighting the ten smart criteria and Fuzzy Decision by Opinion Score Method (FDOSM) for benchmarking STE applications based on constructed AHP weights. The evaluation results show importunity in the obtained weights among the ten STE criteria to distinguish the greatest and lowest important weights. Through the benchmarking performance, FDOSM processes prioritized all STE applications. The ranking results were objectively validated based on five groups of alternatives, and the results were systematically ranked. Finally, this study argued three important summary points concerning the STE dataset, formulated a DM of STE applications, and smart criteria for STE applications to support the MI-BCI community and market. Developing the appropriate STE application for MI-BCI is a better choice to support a large BCI community by identifying the ten smart criteria and considering the presented methodology to establish a robust, practical, cost-efficient, and reliable BCI system.
C1 [Al-Qaysi, Z. T.; Ahmed, M. A.] Tikrit Univ, Comp Sci & Math Coll, Dept Comp Sci, Tikrit, Iraq.
   [Hammash, Nayif Mohammed; Hussein, Ahmed Faeq] Al Nahrain Univ, Fac Engn, Biomed Engn Dept, Baghdad 10072, Iraq.
   [Albahri, A. S.] Iraqi Commiss Comp & Informat ICCI, Baghdad, Iraq.
   [Suzani, M. S.] Univ Pendidikan Sultan Idris, Dept Comp, Tanjong Malim, Perak, Malaysia.
   [Al-Bander, Baidaa] Univ Diyala, Dept Comp Engn, Baqubah, Iraq.
C3 University of Tikrit; Al-Nahrain University; Universiti Pendidikan
   Sultan Idris; University of Diyala
RP Albahri, AS (corresponding author), Iraqi Commiss Comp & Informat ICCI, Baghdad, Iraq.
EM ahmed.bahri1978@gmail.com
RI Albahri, A.S./E-7428-2018; Albahrey, Osamah Shihab/D-5150-2018;
   Al-Bander, Baidaa/F-3116-2019; Hussein, Ahmed Faeq/P-3662-2019
OI Albahri, A.S./0000-0003-3335-457X; Albahrey, Osamah
   Shihab/0000-0002-7844-3990; Al-Bander, Baidaa/0000-0002-2518-7364;
   Hussein, Ahmed Faeq/0000-0003-2483-0028
CR Aamer A, 2019, INT C MICROELECTRON, P166, DOI [10.1109/icm48031.2019.9021752, 10.1109/ICM48031.2019.9021752]
   Abdulkareem KH, 2020, INT J INF TECH DECIS, V19, P909, DOI 10.1142/S0219622020500169
   Abdulkareem KH, 2021, NEURAL COMPUT APPL, V33, P1029, DOI 10.1007/s00521-020-05020-4
   Achanccaray D, 2018, IEEE SYS MAN CYBERN, P1006, DOI 10.1109/SMC.2018.00179
   Afdideh F., 2012, 2012 20th Iranian Conference on Electrical Engineering (ICEE 2012), P1579, DOI 10.1109/IranianCEE.2012.6292612
   Aggarwal S, 2019, ARRAY-NY, V1-2, DOI 10.1016/j.array.2019.100003
   Al-Qaysi ZT, 2021, HEALTH TECHNOL-GER, V11, P783, DOI 10.1007/s12553-021-00560-8
   Alamoodi AH, 2022, INT J FUZZY SYST, V24, P1909, DOI 10.1007/s40815-021-01246-z
   Albahri OS, INT J INTELL SYST
   Albahri OS, 2021, INT J INTELL SYST, V36, P796, DOI 10.1002/int.22322
   Alchalabi B, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/2503431
   Alsalem MA, 2021, J INFECT PUBLIC HEAL, V14, P1513, DOI 10.1016/j.jiph.2021.08.026
   Badia SBI, 2013, IEEE T NEUR SYS REH, V21, P174, DOI 10.1109/TNSRE.2012.2229295
   Cantillo-Negrete J, 2019, BIOCYBERN BIOMED ENG, V39, P263, DOI 10.1016/j.bbe.2018.12.002
   Chin ZY, 2010, IEEE ENG MED BIO, P3341, DOI 10.1109/IEMBS.2010.5627911
   Chin ZY, 2013, 2013 IEEE S COMPUTAT
   Choi J, 2020, 2020 8 INT WINTER C
   Dhital A, 2013, P IEEE VIRT REAL ANN, P71, DOI 10.1109/VR.2013.6549368
   Hamedi M, 2016, NEURAL COMPUT, V28, P999, DOI 10.1162/NECO_a_00838
   Huang DD, 2012, IEEE T NEUR SYS REH, V20, P379, DOI 10.1109/TNSRE.2012.2190299
   Kalid N, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0916-7
   Kalid N, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0883-4
   Khan MA, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103843
   Khatari M, 2021, INT J INF TECH DECIS, V20, P1409, DOI 10.1142/S0219622021500127
   Krishnan E, 2021, INT J INTELL SYST, V36, P4723, DOI 10.1002/int.22489
   Kwon BH, 2020, I WINT C BRAIN-COMP, P232, DOI 10.1109/bci48061.2020.9061621
   Liang S, 2016, COMPUT METH PROG BIO, V132, P63, DOI 10.1016/j.cmpb.2016.04.023
   Liang S, 2014, 2014 7TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI 2014), P297, DOI 10.1109/BMEI.2014.7002788
   Liu XL, 2017, IEEE INT SYM MULTIM, P25, DOI 10.1109/ISM.2017.15
   Longo BB, 2014, ISSNIP BIOSIG BIOROB, P28
   Lotte F., 1999, Wiley Encyclopedia of Electrical and Electronics Engineering., P1, DOI DOI 10.1002/047134608X.W8278
   Mahmoud U. S., 2023, Journal of Ambient Intelligence and Humanized Computing, P12747, DOI 10.1007/s12652-022-04201-4
   Martín-Clemente R, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20010007
   Mohammed KI, 2020, IEEE ACCESS, V8, P91521, DOI 10.1109/ACCESS.2020.2994746
   Mohammed KI, 2020, COMPUT METH PROG BIO, V185, DOI 10.1016/j.cmpb.2019.105151
   Qader MA, 2017, MEASUREMENT, V111, P38, DOI 10.1016/j.measurement.2017.07.024
   Ren SX, 2020, IEEE T NEUR SYS REH, V28, P1846, DOI 10.1109/TNSRE.2020.3001990
   Roc A, 2021, J NEURAL ENG, V18, DOI 10.1088/1741-2552/abca17
   SAATY TL, 1990, EUR J OPER RES, V48, P9, DOI 10.1016/0377-2217(90)90057-I
   Saaty TL., 1988, What is the Analytic Hierarchy Process?, P109, DOI DOI 10.1007/978-3-642-83555-1_5
   Salih MM, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106595
   Salih MM, J INTELL FUZZY SYST, P1
   Singh A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062173
   Skola F, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00329
   Skola F, 2018, COMPUT GRAPH-UK, V75, P59, DOI 10.1016/j.cag.2018.05.024
   Song M, 2019, IEEE T NEUR SYS REH, V27, P477, DOI 10.1109/TNSRE.2019.2895029
   Velasco-Alvarez F, 2013, NEUROCOMPUTING, V121, P89, DOI 10.1016/j.neucom.2012.11.038
   Vourvopoulos A, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00244
   Vourvopoulos A, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0173-2
   Wang W, 2019, 2019 IEEE MTT-S INTERNATIONAL MICROWAVE BIOMEDICAL CONFERENCE (IMBIOC 2019), DOI 10.1109/imbioc.2019.8777805
   Wierzgala P, 2018, FRONT NEUROINFORM, V12, DOI 10.3389/fninf.2018.00078
   Xia B, 2010, 2010 6 INT C NAT COM
   Yang F, 2010, 2 INT C INF SCI ENG, P64
   Yeh SC, 2018, J SYST ARCHITECT, V89, P30, DOI 10.1016/j.sysarc.2018.06.004
   Zughoul O, 2021, INT J INF TECH DECIS, V20, P67, DOI 10.1142/S021962202050042X
NR 55
TC 8
Z9 8
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 17905
EP 17927
DI 10.1007/s11042-022-14118-x
EA NOV 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000883287200006
DA 2024-07-18
ER

PT J
AU Yan, SH
   Gu, BX
   Ren, Y
   Sun, X
   Wang, ET
AF Yan, Shaohui
   Gu, Binxian
   Ren, Yu
   Sun, Xi
   Wang, Ertong
TI Dynamical analysis of four-dimensional chaotic system and its
   application in image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic system; Offset boosting; Hash algorithm; DNA; Bit cyclic shift
ID ALGORITHM; COMPRESSION; MATRIX; MAP
AB In this paper, a phase diagram of a four-dimensional chaotic system is established by introducing cosine function into Lorenz system. Then 0-1 test, complexity, and offset boosting, National Institute of Standards and Technology (NIST) test is conducted on the pseudo-random sequence generated by the system. Result shows that the system is suitable for image encryption. Combining with the proposed system, an image encryption algorithm based on hash and deoxyribonucleic acid (DNA) is designed. In this algorithm, through the plaintext hash value generated by the system initial values and the number of iterations to generate chaos sequence. By reordering the sequence of indexes to scrambling plaintext. In the diffusion module, we use XOR and cyclic left shift to get the final ciphertext. After simulation and security analysis, the algorithm has good encryption efficiency and security. It can resist most common attacks.
C1 [Yan, Shaohui; Gu, Binxian; Ren, Yu; Sun, Xi; Wang, Ertong] Northwest Normal Univ, Coll Phys & Elect Engn, 967 Anning East Rd, Lanzhou 730070, Gansu, Peoples R China.
   [Yan, Shaohui] Gansu Intelligent Informat Technol & Applicat Eng, Lanzhou 730070, Gansu, Peoples R China.
C3 Northwest Normal University - China
RP Yan, SH (corresponding author), Northwest Normal Univ, Coll Phys & Elect Engn, 967 Anning East Rd, Lanzhou 730070, Gansu, Peoples R China.; Yan, SH (corresponding author), Gansu Intelligent Informat Technol & Applicat Eng, Lanzhou 730070, Gansu, Peoples R China.
EM mortalsysh@163.com; 1791412041@qq.com; 1339948998@qq.com;
   2020222244@nwnu.edu.cn; 18802969970@163.com
FU Natural Science Foundation of Gansu Province [20JR5RA531]
FX This research is supported by the Natural Science Foundation of Gansu
   Province(No.20JR5RA531).
CR Alawida M, 2019, SIGNAL PROCESS, V164, P249, DOI 10.1016/j.sigpro.2019.06.013
   Babu NR, 2021, MULTIMED TOOLS APPL, V80, P18043, DOI 10.1007/s11042-020-10288-8
   Bao H, 2021, IEEE T IND INFORM, V17, P1132, DOI 10.1109/TII.2020.2992438
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   Chen M, 2019, FRONT INFORM TECH EL, V20, P1706, DOI 10.1631/FITEE.1900360
   Dong WL, 2021, OPT COMMUN, V499, DOI 10.1016/j.optcom.2021.127211
   Feudjio, T INDIAN NATL ACAD E, DOI [10.1007/s41403-022-00326-2, DOI 10.1007/S41403-022-00326-2]
   Gong LH, 2019, OPT LASER ENG, V121, P169, DOI 10.1016/j.optlaseng.2019.03.006
   Gong LH, 2019, OPT LASER TECHNOL, V115, P257, DOI 10.1016/j.optlastec.2019.01.039
   Himeur Y, 2018, MULTIMED TOOLS APPL, V77, P8603, DOI 10.1007/s11042-017-4754-2
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Huang HQ, 2020, IET IMAGE PROCESS, V14, P1157, DOI 10.1049/iet-ipr.2019.0551
   Li HJ, 2019, OPT LASER ENG, V115, P197, DOI 10.1016/j.optlaseng.2018.12.002
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Mansouri A, 2021, INFORM SCIENCES, V563, P91, DOI 10.1016/j.ins.2021.02.022
   Moon S, 2021, COMMUN NONLINEAR SCI, V96, DOI 10.1016/j.cnsns.2021.105708
   Muthukumar P, 2021, P NATL A SCI INDIA A, V91, P661, DOI 10.1007/s40010-021-00763-8
   Nezhad SYD, 2020, OPTIK, V224, DOI 10.1016/j.ijleo.2020.165661
   Roohi M, 2020, NONLINEAR DYNAM, V100, P3979, DOI 10.1007/s11071-020-05719-y
   Sahasrabuddhe A, 2021, INFORM SCIENCES, V550, P252, DOI 10.1016/j.ins.2020.10.031
   Shakiba A, 2019, MULTIMED TOOLS APPL, V78, P34773, DOI 10.1007/s11042-019-08071-5
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Talhaoui MZ, 2021, INFORM SCIENCES, V550, P13, DOI 10.1016/j.ins.2020.10.048
   Wang MJ, 2019, INT J NONLIN MECH, V111, P149, DOI 10.1016/j.ijnonlinmec.2019.02.009
   Wang XY, 2021, OPT LASER TECHNOL, V138, DOI 10.1016/j.optlastec.2020.106837
   Wang XY, 2020, OPT LASER ENG, V125, DOI 10.1016/j.optlaseng.2019.105851
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, NONLINEAR DYNAM, V95, P2797, DOI 10.1007/s11071-018-4723-y
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Xin BG, 2020, PHYSICA A, V558, DOI 10.1016/j.physa.2020.124993
   Yan SH, 2021, PHYS SCRIPTA, V96, DOI 10.1088/1402-4896/ac379b
   Yang Y, 2021, OPT LASER TECHNOL, V133, DOI 10.1016/j.optlastec.2020.106553
   Ye XL, 2020, OPT LASER ENG, V127, DOI 10.1016/j.optlaseng.2019.105905
   Ye XL, 2020, NONLINEAR DYNAM, V99, P1489, DOI 10.1007/s11071-019-05370-2
   Yildirim M, 2022, CHAOS SOLITON FRACT, V155, DOI 10.1016/j.chaos.2021.111631
   Zhang S, 2021, CHAOS SOLITON FRACT, V145, DOI 10.1016/j.chaos.2021.110761
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhou LL, 2019, NONLINEAR DYNAM, V96, P869, DOI 10.1007/s11071-019-04828-7
NR 42
TC 2
Z9 2
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21509
EP 21534
DI 10.1007/s11042-022-14026-0
EA NOV 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000880546100002
DA 2024-07-18
ER

PT J
AU Pattanaik, A
   Balabantaray, RC
AF Pattanaik, Anmol
   Balabantaray, Rakesh Chandra
TI Enhancement of license plate recognition performance using Xception with
   Mish activation function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generative Adversarial Networks; Xception; Connected Component Analysis;
   Improved Bernsen Algorithm; Transfer Learning
ID ALGORITHM; SEGMENTATION; LOCALIZATION; VEHICLES; SYSTEM
AB The current breakthroughs in the highway research sector have resulted in a greater awareness and focus on the construction of an effective Intelligent Transportation System (ITS). One of the most actively researched areas is Vehicle Licence Plate Recognition (VLPR), concerned with determining the characters contained in a vehicle's Licence Plate (LP). Many existing methods have been used to deal with different environmental complexity factors but are limited to motion deblurring. The aim of our research is to provide an effective and robust solution for recognizing characters present in license plates in complex environmental conditions. Our proposed approach is capable of handling not only the motion-blurred LPs but also recognizing the characters present in different types of low resolution and blurred license plates, illegible vehicle plates, license plates present in different weather and light conditions, and various traffic circumstances, as well as high-speed vehicles. Our research provides a series of different approaches to execute different steps in the character recognition process. The proposed approach presents the concept of Generative Adversarial Networks (GAN) with Discrete Cosine Transform (DCT) Discriminator (DCTGAN), a joint image super resolution and deblurring approach that uses a discrete cosine transform with low computational complexity to remove various types of blur and complexities from licence plates. License Plates (LPs) are detected using the Improved Bernsen Algorithm (IBA) with Connected Component Analysis(CCA). Finally, with the aid of the proposed Xception model with transfer learning, the characters in LPs are recognised. Here we have not used any segmentation technique to split the characters. Four benchmark datasets such as Stanford Cars, FZU Cars, HumAIn 2019 Challenge datasets, and Application-Oriented License Plate (AOLP) dataset, as well as our own collected dataset, were used for the validation of our proposed algorithm. This dataset includes the images of vehicles captured in different lighting and weather conditions such as sunny, rainy, cloudy, blurred, low illumination, foggy, and night. The suggested strategy does better than the current best practices in both numbers and quality.
C1 [Pattanaik, Anmol; Balabantaray, Rakesh Chandra] Int Inst Informat Technol Bhubaneswar, Bhubaneswar, Odisha, India.
C3 International Institute of Information Technology, Bhubaneswar
RP Pattanaik, A (corresponding author), Int Inst Informat Technol Bhubaneswar, Bhubaneswar, Odisha, India.
EM c119001@iiit-bh.ac.in; rakesh@iiit-bh.ac.in
OI , Anmol Pattanaik/0009-0003-1632-8828
CR Adorni G, 1998, P IEEE INT C INT VEH, V2
   Akter L., 2021, SN Comput Sci, V2, P1, DOI DOI 10.1007/S42979-021-00551-6
   Al-Rakhami MS, 2021, medRxiv
   Aly H, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P665
   Aly HA, 2005, IEEE T IMAGE PROCESS, V14, P1647, DOI 10.1109/TIP.2005.851684
   Anagnostopoulos CNE, 2006, IEEE T INTELL TRANSP, V7, P377, DOI 10.1109/TITS.2006.880641
   [Anonymous], 2013, ADV COMPUT SCI INT J
   Asraf Amanullah, 2020, SN Comput Sci, V1, P363, DOI 10.1007/s42979-020-00383-w
   Ayon S. I., 2019, International Journal of Information Engineering & Electronic Business, V11
   Ayon SI, 2022, IETE J RES, V68, P2488, DOI 10.1080/03772063.2020.1713916
   Baran R, 2016, MULTIMED TOOLS APPL, V75, P10471, DOI 10.1007/s11042-015-3151-y
   Bernsen J., 1986, ICPR 86, P1251
   Chang SL, 2004, IEEE T INTELL TRANSP, V5, P42, DOI 10.1109/TITS.2004.825086
   Chen ZX, 2009, IEEE T VEH TECHNOL, V58, P3781, DOI 10.1109/TVT.2009.2013139
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   COMELLI P, 1995, IEEE T VEH TECHNOL, V44, P790, DOI 10.1109/25.467963
   Conci A, 2009, IEEE LAT AM T, V7, P497, DOI 10.1109/TLA.2009.5361185
   Das S, 2019, INT CONF ELECTR ENG, DOI 10.1109/eict48899.2019.9068754
   Davies P, 1990, IEE C IMAGE ANAL TRA, P7
   Deb K, 2009, LECT NOTES COMPUT SC, V5754, P555, DOI 10.1007/978-3-642-04070-2_61
   Dehshibi Mohammad Mahdi, 2012, INT J ELECT COMPUT E, V4, P355, DOI 10.7763/IJCEE.2012.V4.511
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301
   Ferdib-Al-Islam, 2021, 2021 2nd International Conference on Robotics, Electrical and Signal Processing Techniques (ICREST), P445, DOI 10.1109/ICREST51555.2021.9331108
   Ghofrani S., 2011, MAJLESI J ELECT ENG, V5, P44
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graf, 2017, ARXIV160808710, P1, DOI DOI 10.48550/ARXIV.1608.08710
   Guo JM, 2008, IEEE T VEH TECHNOL, V57, P1417, DOI 10.1109/TVT.2007.909284
   Haque M E., 2018, Proceedings of 2018 21st International Conference of Computer and Information Technology (ICCIT'18), P21, DOI [DOI 10.1109/ICCITECHN.2018.8631957, 10.1109/IC4ME2.2018.8465658, DOI 10.1109/IC4ME2.2018.8465658]
   Hasan M, 2019, INTERNET THINGS-NETH, V7, DOI 10.1016/j.iot.2019.100059
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hladek D, 2017, MULTIMED TOOLS APPL, V76, P24549, DOI 10.1007/s11042-016-4185-5
   Islam M. M., 2020, Social Netw. Comput. Sci., V1, P1, DOI [10.1007/s42979-020-00223-x, DOI 10.1007/S42979-020-00223-X]
   Islam MM, 2021, IEEE ACCESS, V9, P30551, DOI 10.1109/ACCESS.2021.3058537
   Islam MM, 2020, IEEE ACCESS, V8, P166117, DOI 10.1109/ACCESS.2020.3021943
   Islam MM, 2017, IEEE REG 10 HUMANIT, P226, DOI 10.1109/R10-HTC.2017.8288944
   Islam MR, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104757
   Islam MR, 2021, IEEE ACCESS, V9, P94601, DOI 10.1109/ACCESS.2021.3091487
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Jiao JB, 2009, PATTERN RECOGN, V42, P358, DOI 10.1016/j.patcog.2008.08.016
   Jiji CV, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/73767
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee J, 2021, MAGN RESON MED, V86, P1077, DOI 10.1002/mrm.28719
   Lee OY, 2019, IEEE ACCESS, V7, P136496, DOI 10.1109/ACCESS.2019.2942779
   Li XG, 2009, J VIS COMMUN IMAGE R, V20, P312, DOI 10.1016/j.jvcir.2009.03.008
   Liu J, 2021, MULTIMEDIA SYST, V27, P821, DOI 10.1007/s00530-020-00712-2
   Menotti D, 2014, 2014 27TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES (SIBGRAPI), P298, DOI 10.1109/SIBGRAPI.2014.52
   Muhammad L J, 2020, SN Comput Sci, V1, P206, DOI 10.1007/s42979-020-00216-w
   Naito T, 2000, IEEE T VEH TECHNOL, V49, P2309, DOI 10.1109/25.901900
   Nasr M, 2021, IEEE ACCESS, V9, P145248, DOI 10.1109/ACCESS.2021.3118960
   Niblack W., 1986, INTRO DIGITAL IMAGE, P115
   Rahman Mohammad Marufur, 2021, SN Comput Sci, V2, P384, DOI 10.1007/s42979-021-00774-7
   Rahman MM, 2020, 2020 IEEE INTERNATIONAL IOT, ELECTRONICS AND MECHATRONICS CONFERENCE (IEMTRONICS 2020), P271
   ROSENFEL.A, 1966, J ACM, V13, P471
   Saha Prottoy, 2021, Inform Med Unlocked, V22, P100505, DOI 10.1016/j.imu.2020.100505
   Salgado L., 1999, Proceedings IEEE 33rd Annual 1999 International Carnahan Conference on Security Technology (Cat. No.99CH36303), P71, DOI 10.1109/CCST.1999.797895
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su CY, 2005, PATTERN RECOGN, V38, P813, DOI 10.1016/j.patcog.2004.11.007
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Wang F, 2008, PATTERN RECOGN LETT, V29, P1007, DOI 10.1016/j.patrec.2008.01.026
   Wang R, 2016, SIGNAL PROCESS, V127, P24, DOI 10.1016/j.sigpro.2016.02.003
   Wen Y, 2011, IEEE T INTELL TRANSP, V12, P830, DOI 10.1109/TITS.2011.2114346
   Yoo H, 2021, MULTIMEDIA SYST, V27, P779, DOI 10.1007/s00530-020-00655-8
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zheng D, 2005, PATTERN RECOGN LETT, V26, P2431, DOI 10.1016/j.patrec.2005.04.014
NR 69
TC 3
Z9 3
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16793
EP 16815
DI 10.1007/s11042-022-13922-9
EA OCT 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000874060400004
PM 36258895
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Li, YS
   Liu, Y
   Yu, R
   Zong, HL
   Xie, WX
AF Li, Yanshan
   Liu, Yan
   Yu, Rui
   Zong, Hailin
   Xie, Weixin
TI Dual attention based spatial-temporal inference network for volleyball
   group activity recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Group activity recognition; Dual attention; Mixture channel attention;
   Spatial-temporal inference
ID REPRESENTATION
AB With the growing demand for video content analysis, sports video activity recognition has wide application prospects and commercial value, such as computer-assisted highlight extraction, tactic statistics and strategic analysis. Volleyball group activity recognition focuses on understanding the action performed by a group of players in volleyball matches. However, due to the cluttered backgrounds and the complex relationships between individuals in volleyball video, group activity recognition for sports video has become a significant and challenging issue. Therefore, we propose a dual attention based on a spatial-temporal inference network for volleyball group activity recognition. First, a dual attention model composed of spatial attention and mixture channel attention is proposed to assign attention weight dynamically to each feature and concern on the interdependencies of group members. It can improve the capacity of the model to distinguish features representation with intra-class variation by obtaining rich contextual relationships. Next, to focus on individual spatial-temporal information, an individual spatial-temporal inference network (ISTIN) is designed to capture person-group interactions for emphasizing the variability of these information. Finally, these features are fed into a recurrent neural network to capture temporal dependencies and make the classification. Experimental results show that this approach can be effective in group activity recognition, with our model improving recognition rates over baseline method on the benchmark datasets: Volleyball dataset and Collective Activity dataset.
C1 [Li, Yanshan; Liu, Yan; Yu, Rui; Zong, Hailin; Xie, Weixin] Shenzhen Univ, ATR Natl Key Lab Def Technol, Shenzhen 518061, Peoples R China.
   [Li, Yanshan; Liu, Yan; Yu, Rui; Zong, Hailin; Xie, Weixin] Shenzhen Univ, Dept Elect & Informat Engn, Shenzhen 518061, Peoples R China.
   [Li, Yanshan; Liu, Yan; Yu, Rui; Zong, Hailin] Shenzhen Univ, China Guangdong Key Lab Intelligent Informat Proc, Shenzhen 518061, Peoples R China.
C3 Shenzhen University; Shenzhen University; Shenzhen University
RP Li, YS (corresponding author), Shenzhen Univ, ATR Natl Key Lab Def Technol, Shenzhen 518061, Peoples R China.; Li, YS (corresponding author), Shenzhen Univ, Dept Elect & Informat Engn, Shenzhen 518061, Peoples R China.; Li, YS (corresponding author), Shenzhen Univ, China Guangdong Key Lab Intelligent Informat Proc, Shenzhen 518061, Peoples R China.
EM lys@szu.edu.cn; 571246917@qq.com; yurui2020@email.szu.edu.cn;
   1910433003@email.szu.edu.cn; wxxie@szu.edu.cn
RI Li, Yanshan/GVS-5245-2022; Yu, Rui/KRO-9318-2024
OI Yu, Rui/0000-0003-1782-6258
FU National Natural Science Foundation of China [62076165, 61871154];
   Natural Science Foundation of Guangdong Province [2019A1515011307];
   Shenzhen Science and Technology Project [JCYJ20180507182259896,
   2020KCXTD004, WDZC20195500201]
FX This work was partially supported by National Natural Science Foundation
   of China (62076165, 61871154), Natural Science Foundation of Guangdong
   Province (No. 2019A1515011307), Shenzhen Science and Technology Project
   (No. JCYJ20180507182259896) and the other project(Nos. 2020KCXTD004,
   WDZC20195500201).
CR Amer MR, 2016, IEEE T PATTERN ANAL, V38, P800, DOI 10.1109/TPAMI.2015.2465955
   Amer MR, 2013, IEEE I CONF COMP VIS, P1353, DOI 10.1109/ICCV.2013.171
   Amer MR, 2014, LECT NOTES COMPUT SC, V8694, P572, DOI 10.1007/978-3-319-10599-4_37
   Bagautdinov T, 2017, PROC CVPR IEEE, P3425, DOI 10.1109/CVPR.2017.365
   Bastian A, 2019, 2019 2ND INTERNATIONAL CONFERENCE OF COMPUTER AND INFORMATICS ENGINEERING (IC2IE 2019), P1, DOI 10.1109/ic2ie47452.2019.8940861
   Berlin SJ, 2022, VISUAL COMPUT, V38, P223, DOI 10.1007/s00371-020-02012-2
   Berlin SJ, 2020, APPL ARTIF INTELL, V34, P656, DOI 10.1080/08839514.2020.1765110
   Biswas Sovan, 2018, 2018 IEEE Winter Conference on Applications of Computer Vision (WACV). Proceedings, P1625, DOI 10.1109/WACV.2018.00180
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Dasgupta A, 2021, INT C PATT RECOG, P10098, DOI 10.1109/ICPR48806.2021.9412306
   Deng Z, 2015, ARXIV
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Hajimirsadeghi H, 2015, PROC CVPR IEEE, P2596, DOI 10.1109/CVPR.2015.7298875
   Han M., 2022, P IEEE CVF C COMP VI, P2990
   Hsing-Yu Chen, 2020, Pattern Recognition. 5th Asian Conference, ACPR 2019. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12047), P705, DOI 10.1007/978-3-030-41299-9_55
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Hussain R, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13234941
   Ibrahim MS, 2018, LECT NOTES COMPUT SC, V11207, P742, DOI 10.1007/978-3-030-01219-9_44
   Ibrahim MS, 2016, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2016.217
   Ibrahim MS, 2016, ARXIV
   Islam MM, 2020, IEEE INT C INT ROBOT, P10285, DOI 10.1109/IROS45743.2020.9340987
   Lamghari S, 2021, INT C PATT RECOG, P10500, DOI 10.1109/ICPR48806.2021.9413136
   Lan T, 2012, PROC CVPR IEEE, P1354, DOI 10.1109/CVPR.2012.6247821
   Li X, 2017, IEEE I CONF COMP VIS, P2895, DOI 10.1109/ICCV.2017.313
   Liu HH, 2018, IEEE T NEUR NET LEAR, V29, P1427, DOI 10.1109/TNNLS.2017.2669522
   Liu J, 2018, IEEE T IMAGE PROCESS, V27, P1586, DOI 10.1109/TIP.2017.2785279
   Peng XJ, 2016, LECT NOTES COMPUT SC, V9908, P744, DOI 10.1007/978-3-319-46493-0_45
   Perez M, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108360
   Qi MS, 2020, IEEE T CIRC SYST VID, V30, P549, DOI 10.1109/TCSVT.2019.2894161
   Qi MS, 2018, LECT NOTES COMPUT SC, V11214, P104, DOI 10.1007/978-3-030-01249-6_7
   Ramchandran A, 2020, MULTIMED TOOLS APPL, V79, P35275, DOI 10.1007/s11042-019-7702-5
   Rao YM, 2017, IEEE I CONF COMP VIS, P3951, DOI 10.1109/ICCV.2017.424
   Roy AG, 2018, LECT NOTES COMPUT SC, V11070, P421, DOI 10.1007/978-3-030-00928-1_48
   Ryoo MS, 2011, INT J COMPUT VISION, V93, P183, DOI 10.1007/s11263-010-0355-5
   Salehifar H, 2011, P INT C IM PROC COMP, P1
   Salehifar H, 2011, IEEE ICSAP, P398
   Savarese S, 2009, 2009 IEEE 12 INT C C, P1282
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shu TM, 2017, PROC CVPR IEEE, P4255, DOI 10.1109/CVPR.2017.453
   Shu TM, 2015, PROC CVPR IEEE, P4576, DOI 10.1109/CVPR.2015.7299088
   Singh G, 2017, IEEE I CONF COMP VIS, P3657, DOI 10.1109/ICCV.2017.393
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Talukder A, 2014, MULTIMED TOOLS APPL, V70, P237, DOI 10.1007/s11042-012-1088-y
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Tang YS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1283, DOI 10.1145/3240508.3240576
   Vaswani A, 2017, ADV NEUR IN, V30
   [王传旭 Wang Chuanxu], 2020, [电子学报, Acta Electronica Sinica], V48, P1465
   Wang MS, 2017, PROC CVPR IEEE, P7408, DOI 10.1109/CVPR.2017.783
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang ZH, 2013, PROC CVPR IEEE, P1690, DOI 10.1109/CVPR.2013.221
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu JC, 2019, PROC CVPR IEEE, P9956, DOI 10.1109/CVPR.2019.01020
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Xu DZ, 2020, IEEE ACCESS, V8, P65689, DOI 10.1109/ACCESS.2020.2979742
   Yan R, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1292, DOI 10.1145/3240508.3240572
   YANG JL, 2017, PROC CVPR IEEE, P5216, DOI DOI 10.1109/CVPR.2017.554
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P7126, DOI 10.1109/TNNLS.2021.3084250
   Yang SM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.601109
   Yang SM, 2020, IEEE T NEUR NET LEAR, V31, P148, DOI 10.1109/TNNLS.2019.2899936
   Yuan HJ, 2021, AAAI CONF ARTIF INTE, V35, P3261
   Zalluhoglu C, 2019, J VIS COMMUN IMAGE R, V60, P170, DOI 10.1016/j.jvcir.2019.02.016
   Zhang ZJ, 2022, IEEE T NEUR NET LEAR, V33, P6856, DOI 10.1109/TNNLS.2021.3083710
NR 66
TC 5
Z9 5
U1 4
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15515
EP 15533
DI 10.1007/s11042-022-13867-z
EA OCT 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000864966800006
DA 2024-07-18
ER

PT J
AU Ye, CH
   Tan, SL
   Wang, Z
   Shi, L
   Wang, J
AF Ye, Conghuan
   Tan, Shenglong
   Wang, Zheng
   Shi, Li
   Wang, Jun
TI A secure social multimedia sharing scheme in the TSHWT_SVD domain based
   on neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic neural network; Social multimedia sharing; Multimedia
   encryption; Joint fingerprinting and encryption; TSHWT_SVD domain
ID ENCRYPTION; CLASSIFICATION; WATERMARKING; CODE
AB The rapid development of mobile social networks and wireless communication technology has made image/video sharing easier and more efficient. However, the convenience of social multimedia sharing can also cause serious problems such as privacy disclosure because of illegal use of shared contents, and the existing content sharing scheme cannot meet the privacy protection requirements of users in social networks. Therefore, secure multimedia sharing and privacy protection have become critical and urgent in multimedia social networks. For protecting multimedia sharing in multimedia social networks, a novel joint fingerprinting and encryption (JFE) scheme is proposed. Both fingerprint embedding and encryption are performed in the tree structure haar wavelet transform and singular value decomposition (TSHWT_SVD) domain based on chaotic neural network. First, the social image is decomposed based on the fingerprint code structure by the TSHWT. Then, perform SVD computing for selective subbands for parallel piecewise fingerprint segments embedding. In the end, the fingerprinted coefficient stream is encrypted via block permutation and SVD diffusion. It is worth mentioning that most of the existing image security algorithms encrypt and embed a watermark in the spatial domain, which cannot meet the requirements of the era of multimedia social networks due to lack of scalability. The proposed method, to the best of our knowledge, is the first scalable JFE method for fingerprinting and encryption in the TSHWT_SVD domain. The use of fingerprinting along with encryption in the TSHWT_SVD domain can provide scalable double-layer protection for secure social multimedia sharing. When compared with existing image security algorithms, the scalable selective encryption method greatly improves encryption efficiency. Moreover, experimental results and contrastive analyses show that the proposed JFE scheme has high security, fast speed and can resist various attacks.
C1 [Ye, Conghuan; Tan, Shenglong; Wang, Zheng; Shi, Li; Wang, Jun] Hubei Univ Econ, Sch Informat & Commun Engn, Wuhan 430205, Hubei, Peoples R China.
   [Ye, Conghuan] Hubei Engn Univ, Sch Comp & Informat Sci, Xiaogan 432000, Hubei, Peoples R China.
C3 Hubei University of Economics; Hubei Engineering University
RP Ye, CH (corresponding author), Hubei Univ Econ, Sch Informat & Commun Engn, Wuhan 430205, Hubei, Peoples R China.; Ye, CH (corresponding author), Hubei Engn Univ, Sch Comp & Informat Sci, Xiaogan 432000, Hubei, Peoples R China.
EM ychzzw@163.com; tslnet@163.com; wangzheng@hbue.edu.cn;
   shily0118@163.com; wjwj@whu.edu.cn
FU Natural Science Foundation of China [61502154, 61972136, 61370092]; NSF
   of Chinese Hubei Provinc [2015CFB236]; Natural Science Fundation of
   Hubei Provincial Department of Education; Philosophy and Social Science
   Research Project of Hubei Provincial Department of Education [21Q213]
FX This paper is supported by Natural Science Foundation of China
   (No.61502154, No.61972136, No.61370092), NSF of Chinese Hubei Provinc
   (No.2015CFB236), Natural Science Fundation of Hubei Provincial
   Department of Education (No.D20142703), Philosophy and Social Science
   Research Project of Hubei Provincial Department of Education
   (No.21Q213).
CR Al-Haj A, 2021, MULTIMED TOOLS APPL, V80, P26021, DOI 10.1007/s11042-021-10801-7
   Anand A, 2023, IEEE T DEPEND SECURE, V20, P859, DOI 10.1109/TDSC.2022.3144657
   Cancellaro M, 2011, SIGNAL PROCESS-IMAGE, V26, P1, DOI 10.1016/j.image.2010.11.001
   Czaplewski B, 2016, J VIS COMMUN IMAGE R, V40, P1, DOI 10.1016/j.jvcir.2016.06.006
   Diaconu AV, 2016, INFORM SCIENCES, V355, P314, DOI 10.1016/j.ins.2015.10.027
   Ding Y, 2021, IEEE INTERNET THINGS, V8, P1504, DOI 10.1109/JIOT.2020.3012452
   Divya CD., 2021, DISCOV ARTIF INTELL, V1, P10, DOI [10.1007/s44163-021-00010-4, DOI 10.1007/S44163-021-00010-4]
   Egiazarian K, 2002, J MATH IMAGING VIS, V16, P269, DOI 10.1023/A:1020385811959
   Egorova E, 2019, DESIGN CODE CRYPTOGR, V87, P455, DOI 10.1007/s10623-018-0551-9
   Elhoseny M, 2020, NEURAL COMPUT APPL, V32, P10979, DOI 10.1007/s00521-018-3801-x
   Haddad S, 2020, IEEE T INF FOREN SEC, V15, P2556, DOI 10.1109/TIFS.2020.2972159
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Jiang J, 2020, DESIGN CODE CRYPTOGR, V88, P851, DOI 10.1007/s10623-020-00717-y
   Kundur D, 2004, P IEEE, V92, P918, DOI 10.1109/JPROC.2004.827356
   Li M, 2020, IEEE SIGNAL PROC LET, V27, P1794, DOI 10.1109/LSP.2020.3028037
   Li M, 2019, MULTIMED TOOLS APPL, V78, P22727, DOI 10.1007/s11042-019-7560-1
   Lian SG, 2008, IEEE T CIRC SYST VID, V18, P1462, DOI 10.1109/TCSVT.2008.2002829
   Lin CY, 2016, J VIS COMMUN IMAGE R, V38, P858, DOI 10.1016/j.jvcir.2016.02.003
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Megías D, 2017, EXPERT SYST APPL, V71, P147, DOI 10.1016/j.eswa.2016.11.015
   Mohamed Kadry Sayed, 2019, International Journal of Computer Networks and Applications, V6, P13, DOI 10.22247/ijcna/2019/49578
   Peng HP, 2020, IEEE INTERNET THINGS, V7, P2432, DOI 10.1109/JIOT.2019.2957747
   REN H, MULTIMED TOOLS APPL
   Rostami MJ, 2017, COMPUT ELECTR ENG, V62, P384, DOI 10.1016/j.compeleceng.2017.04.004
   Sahoo SR, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106983
   Sahoo SR, 2020, ENTERP INF SYST-UK, V14, P710, DOI 10.1080/17517575.2020.1712742
   Sahoo SR, 2019, ENTERP INF SYST-UK, V13, P832, DOI 10.1080/17517575.2019.1605542
   Sahoo SR, 2019, COMPUT ELECTR ENG, V76, P65, DOI 10.1016/j.compeleceng.2019.03.003
   Shanmugam L, 2020, IEEE T CYBERNETICS, V50, P911, DOI 10.1109/TCYB.2018.2877410
   Singh SK, 2021, INT J SEMANT WEB INF, V17, P59, DOI [10.4018/IJSWIS.2021040104, 10.15740/HAS/IJAS/17.1/59-64]
   Skoric B, 2011, IEEE T INF FOREN SEC, V6, P906, DOI 10.1109/TIFS.2011.2116783
   Subhash S., 2016, INDIAN J COMPUT SCI, V148, P1, DOI 10.5120/ijca2016911002
   Tanuja U., 2020, Proceedings of First International Conference on Computing, Communications, and Cyber-Security (IC4S 2019). Lecture Notes in Networks and Systems (LNNS 121), P485, DOI 10.1007/978-981-15-3369-3_37
   Tembhurne JV, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.295553
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Thanki R, 2021, MULTIMED TOOLS APPL, V80, P4307, DOI 10.1007/s11042-020-09941-z
   Wang XY, 2019, OPT LASER ENG, V115, P107, DOI 10.1016/j.optlaseng.2018.11.010
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Xiong LZ, 2019, MULTIMED TOOLS APPL, V78, P30297, DOI 10.1007/s11042-018-6981-6
   Xiong ZG, 2019, MULTIMED TOOLS APPL, V78, P31035, DOI 10.1007/s11042-018-7081-3
   Yan LY, 2022, MULTIMED TOOLS APPL, V81, P319, DOI 10.1007/s11042-021-11530-7
   Yan LY, 2021, MULTIMED TOOLS APPL, V80, P14363, DOI 10.1007/s11042-020-10310-z
   Yan LY, 2019, MULTIMED TOOLS APPL, V78, P15101, DOI 10.1007/s11042-018-6855-y
   Yang Y, 2020, IEEE T DEPEND SECURE, V17, P78, DOI 10.1109/TDSC.2017.2729556
   Yasui T, 2020, IEEE T INF FOREN SEC, V15, P2069, DOI 10.1109/TIFS.2019.2956587
   Ye CH, 2013, TELECOMMUN SYST, V54, P315, DOI 10.1007/s11235-013-9736-8
   Zhang LY, 2020, IEEE T DEPEND SECURE, V17, P1218, DOI 10.1109/TDSC.2018.2864748
   Zhao FX, 2021, OPT LASER TECHNOL, V135, DOI 10.1016/j.optlastec.2020.106610
NR 48
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15395
EP 15414
DI 10.1007/s11042-022-13953-2
EA OCT 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000863811400001
DA 2024-07-18
ER

PT J
AU Han, CG
   Cheng, DQ
   Kou, QQ
   Wang, XY
   Chen, LL
   Zhao, JM
AF Han, Chenggong
   Cheng, Deqiang
   Kou, Qiqi
   Wang, Xiaoyi
   Chen, Liangliang
   Zhao, Jiamin
TI Self-supervised monocular Depth estimation with multi-scale structure
   similarity loss
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Self-supervised learning; Monocular depth estimation; Structural
   similarity; Attentional mechanism
AB The raw depth image captured by the depth sensor usually has an extensive range of missing depth values, and the incomplete depth map burdens many downstream vision tasks. In order to overcome the incorrect estimation issue of depth information with the original luminosity loss function for processing complex texture areas and distant moving objects, this paper proposes a self-supervised monocular depth estimation algorithm based on multi-scale structure similarity loss. So as to enhance the perception ability of the depth prediction network for pixel edges, this paper proposes a multi-scale structural similarity when calculating the loss. In addition, an attention mechanism is also added to the encoder stage of the deep prediction network. As a result, the network not only ignores the features with small contributions, but also strengthens the features assist judgment based on the adjustment of the feature map. Finally, the experiments on the KITTI dataset and Cityscapes are conducted, and then the results are compared and analyzed with the state-of-the-art algorithms. The experimental results demonstrate that the proposed algorithm achieves significant improvements in accuracy, especially on the KITTI dataset, whose precision is raised to 88.4%. Moreover, under the premise of outstanding accuracy, the visualization effect of depth estimation has also been significantly improved, especially in the scenes with multi-person overlap on Cityscapes.
C1 [Han, Chenggong; Cheng, Deqiang; Wang, Xiaoyi; Chen, Liangliang; Zhao, Jiamin] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
   [Kou, Qiqi] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
C3 China University of Mining & Technology; China University of Mining &
   Technology
RP Cheng, DQ (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
EM chengdq@cumt.edu.cn
RI WANG, XIAOYI/GWZ-5583-2022; Cheng, Deqiang/HDO-0132-2022
OI WANG, XIAOYI/0000-0001-5665-0991; 
FU National Natural Science Foundation of China [51774281]
FX This paper is supported by the National Natural Science Foundation of
   China under Grant No. 51774281.
CR Ahmed Sohail, 2016, 2016 13th International Conference on Service Systems and Service Management (ICSSSM), P1, DOI 10.1109/ICSSSM.2016.7538459
   Ali U, 2021, IMAGE VISION COMPUT, V113, DOI 10.1016/j.imavis.2021.104261
   Behley J, 2019, IEEE I CONF COMP VIS, P9296, DOI 10.1109/ICCV.2019.00939
   Bian JW, 2019, ADV NEUR IN, V32
   Casser V, 2019, AAAI CONF ARTIF INTE, P8001
   Chen LL, 2020, OPTIK, V202, DOI 10.1016/j.ijleo.2019.163678
   Dc A., 2021, IMAGE VIS COMPUT, V114, DOI [10.1016/j.imavis.2021.104267, DOI 10.1016/J.IMAVIS.2021.104267]
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Gordon A, 2019, IEEE I CONF COMP VIS, P8976, DOI 10.1109/ICCV.2019.00907
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jung H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12622, DOI 10.1109/ICCV48922.2021.01241
   Khan F, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082272
   Kline J, 2020, PROCEEDINGS OF THE 2020 32ND INTERNATIONAL TELETRAFFIC CONGRESS (ITC 32), P1, DOI [10.1109/ITC3249928.2020.00009, 10.1007/978-3-030-58565-5_35]
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Li JH, 2021, IEEE SIGNAL PROC LET, V28, P379, DOI 10.1109/LSP.2021.3055116
   Li RH, 2018, IEEE INT CONF ROBOT, P7286, DOI 10.1109/ICRA.2018.8461251
   Luo CX, 2020, IEEE T PATTERN ANAL, V42, P2624, DOI 10.1109/TPAMI.2019.2930258
   Mathew A, 2020, IMAGE VISION COMPUT, V100, DOI 10.1016/j.imavis.2020.103934
   Mehta I, 2018, INT CONF 3D VISION, P314, DOI 10.1109/3DV.2018.00044
   Meng Y, 2019, PROC CVPR IEEE, P9802, DOI 10.1109/CVPR.2019.01004
   Pillai S, 2019, IEEE INT CONF ROBOT, P9250, DOI [10.1109/icra.2019.8793621, 10.1109/ICRA.2019.8793621]
   Poggi M, 2018, INT CONF 3D VISION, P324, DOI 10.1109/3DV.2018.00045
   Praveena HD, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/3297316
   Ranftl R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12159, DOI 10.1109/ICCV48922.2021.01196
   Ranjan A, 2019, PROC CVPR IEEE, P12232, DOI 10.1109/CVPR.2019.01252
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rosa ND, 2019, 2019 19TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P793, DOI [10.1109/icar46387.2019.8981652, 10.1109/ICAR46387.2019.8981652]
   Schon M., 2021, P IEEECVF INT C COMP, P15804
   Tosi F, 2019, PROC CVPR IEEE, P9791, DOI 10.1109/CVPR.2019.01003
   Wang CY, 2018, PROC CVPR IEEE, P2022, DOI 10.1109/CVPR.2018.00216
   Wang H., 2022, P IEEECVF C COMPUTER, P6209
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wong A, 2019, PROC CVPR IEEE, P5627, DOI 10.1109/CVPR.2019.00579
   Zhan HY, 2018, PROC CVPR IEEE, P340, DOI 10.1109/CVPR.2018.00043
   Zhe Cao, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P5587, DOI 10.1109/CVPR.2019.00574
   Zhou JS, 2019, IEEE I CONF COMP VIS, P6871, DOI 10.1109/ICCV.2019.00697
NR 39
TC 0
Z9 0
U1 6
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 OCT 3
PY 2022
DI 10.1007/s11042-022-14012-6
EA OCT 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5B4PT
UT WOS:000863553600004
DA 2024-07-18
ER

PT J
AU Li, HJ
   Sun, XH
   Li, CB
   Shen, XL
   Chen, JY
   Chen, JJ
   Xie, ZG
AF Li, Hongjun
   Sun, Xiaohu
   Li, Chaobo
   Shen, Xulin
   Chen, Jinyi
   Chen, Junjie
   Xie, Zhengguang
TI MPAT: multi-path attention temporal method for video anomaly detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video abnormal detection; Recursive residual convolutional unit; Skip
   attention gate; Time steps; Spatio-temporal features
ID EVENT DETECTION; CROWDED SCENES
AB Video anomaly detection is a recent focus of computer vision research thanks to the rarity and uncertainty of anomalous events. However, most existing research works are limited to learning the apparent and motion information of specific objects, ignoring the effect of temporal information. In this paper, multi-path attentional temporal method is proposed to detect whether videos contain anomalies. Specifically, the activity of adjacent units is regulated by a novel intra-layer Recurrent Residual Convolution Unit (RRCU) with temporal function, and different time steps are set to enhance the model's ability to integrate contextual information. Furthermore, considering the information loss caused by image compression in the encoding stage, Skip Attention Gates (SAG) are used to focus on specific objects of different shapes and sizes and aggregate information from multiple feature scales. As an end-to-end learning framework, the proposed model can extract more discriminative spatio-temporal features, and the experimental results on three datasets demonstrate the effectiveness and generalization of the proposed approach.
C1 [Li, Hongjun; Sun, Xiaohu; Li, Chaobo; Shen, Xulin; Chen, Jinyi; Chen, Junjie; Xie, Zhengguang] Nantong Univ, Sch Informat Sci & Technol, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.
   [Li, Hongjun] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
   [Li, Hongjun; Chen, Junjie] Nantong Res Inst Adv Commun Technol, Nantong 226019, Jiangsu, Peoples R China.
C3 Nantong University; Nanjing University
RP Li, HJ (corresponding author), Nantong Univ, Sch Informat Sci & Technol, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.; Li, HJ (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.; Li, HJ (corresponding author), Nantong Res Inst Adv Commun Technol, Nantong 226019, Jiangsu, Peoples R China.
EM lihongjun@ntu.edu.cn; 2010310052@stmail.ntu.edu.cn;
   1811310007@yjs.ntu.edu.cn; 2010320003@stmail.ntu.edu.cn;
   2010320025@stmail.ntu.edu.cn; cjjcy@ntu.edu.cn; xie_zg@126.com
OI Li, Chaobo/0000-0003-3772-3344; Chen, Junjie/0000-0003-4219-6171; sun,
   xiao hu/0000-0002-5501-5424; li, hongjun/0000-0001-7500-4979
FU National Natural Science Foundation of China [61871241, 61971245,
   61976120]; Nanjing University State Key Lab [KFKT2019B15]; Nantong
   Science and Technology Program [JC2021131]; Postgraduate Research and
   Practice Innovation Program of Jiangsu Province [KYCX21_3084,
   KYCX22_3340]
FX This work is supported in part by National Natural Science Foundation of
   China under Grant 61871241, Grant 61971245 and Grant 61976120, in part
   by Nanjing University State Key Lab. for Novel Software Technology under
   Grant KFKT2019B15, in part by Nantong Science and Technology Program
   JC2021131 and in part by Postgraduate Research and Practice Innovation
   Program of Jiangsu Province KYCX21_3084 and KYCX22_3340.
CR Aggarwal A. K., 2020, J COMPUT SCI-NETH, V16, P651, DOI DOI 10.3844/JCSSP.2020.651.659
   Aggarwal A.K., 2015, Int. J. Soft. Comput. Eng., V5, P21
   Alafif T, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03323-5
   Ashwani K., 2013, SEISAN KENKYU, V65, P91
   Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524
   Chauhan S, 2021, DATA SCI DATA ANALYT
   Chen HM, 2017, IEEE INT CONGR BIG, P368, DOI 10.1109/BigDataCongress.2017.54
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Cosar S, 2017, IEEE T CIRC SYST VID, V27, P683, DOI 10.1109/TCSVT.2016.2589859
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Del Giorno A, 2016, LECT NOTES COMPUT SC, V9909, P334, DOI 10.1007/978-3-319-46454-1_21
   Fanta H, 2020, INFORM SCIENCES, V524, P15, DOI 10.1016/j.ins.2020.03.034
   Han QL, 2020, J REAL-TIME IMAGE PR, V17, P2153, DOI 10.1007/s11554-020-01029-z
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hyunjong Park, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14360, DOI 10.1109/CVPR42600.2020.01438
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Kingma D. P., 2014, arXiv
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Kumar A., 2014, Seisan Kenkyu, V66, P101
   Li NJ, 2021, IEEE T MULTIMEDIA, V23, P203, DOI 10.1109/TMM.2020.2984093
   Li RR, 2018, IEEE J-STARS, V11, P3954, DOI 10.1109/JSTARS.2018.2833382
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2021, IEEE T PATTERN ANAL, V43, P1070, DOI 10.1109/TPAMI.2019.2944377
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   Ma Z, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21227508
   MAHADEVAN V, 2010, PROC CVPR IEEE, P1975, DOI DOI 10.1109/CVPR.2010.5539872
   Mathieu M., 2015, PROC INT C LEARN REP
   Medel JR., 2016, P COMP VIS PATT REC, P1
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Tay N, 2016, P 1 INT C ELECT CONT, P1
   Wang DL, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.2.023009
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Yan SY, 2020, IEEE T COGN DEV SYST, V12, P30, DOI 10.1109/TCDS.2018.2883368
   Ye MC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1805, DOI 10.1145/3343031.3350899
   Zhang Y, 2016, PATTERN RECOGN, V51, P443, DOI 10.1016/j.patcog.2015.09.005
   Zhang Y, 2021, IEEE T CIRC SYST VID, V31, P3694, DOI 10.1109/TCSVT.2020.3039798
   Zhao YR, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1933, DOI 10.1145/3123266.3123451
   Zhou SF, 2015, INT CONF ACOUST SPEE, P1300, DOI 10.1109/ICASSP.2015.7178180
   Zhou XG, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATIONS (CSA), P222, DOI 10.1109/CSA.2015.64
NR 47
TC 2
Z9 2
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12557
EP 12575
DI 10.1007/s11042-022-13834-8
EA SEP 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000857685800003
DA 2024-07-18
ER

PT J
AU Pankiraj, JB
   Govindaraj, V
   Zhang, YD
   Murugan, PR
   Milton, A
AF Pankiraj, Jeya Bright
   Govindaraj, Vishnuvarthanan
   Zhang, Yudong
   Murugan, Pallikonda Rajasekaran
   Milton, Anisha
TI Development of scalable coding for the encryption and decryption of
   images using modified diagonal min-max block truncation code
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image compression; Scalable coding on encrypted image; Image encryption;
   Secured signal processing; Image reconstruction
ID COMPRESSION
AB Many of the researchers have so far commendably worked and contributed towards the scalability coding of unencrypted images, and there is adequate space for research and evolvement in the area of scalable coding on encrypted images. This paper proposes a novel method of scalable coding on encrypted images using Modified Diagonal Min-Max Block Truncation Code (MDMMBTC). The given raw image is compressed at the encoder using Modified Min-Max Block Truncation Coding, and then encryption is done using the pseudo-random number (PRN) technique. The PRN Key is shared between the encoder and decoder. At the decoder, first, the encoded image is subtracted with the PRN key, and the resultant output is used to rebuild the principal content by using MDMMBTC, scaled by scaling factor 2, and Bilinear Interpolation Technique. The MDMMBTC gives a 36.6 dB PSNR ratio and 1.08 Compression ratio than existing Hadamard, BTC, and DMMBTC techniques, making the proposed technique readily be used for the better purpose of encrypting and decrypting the image without any impediments.
C1 [Pankiraj, Jeya Bright; Murugan, Pallikonda Rajasekaran] Kalasalingam Acad Res & Educ, Dept ECE, Srivilliputhur, India.
   [Govindaraj, Vishnuvarthanan; Milton, Anisha] Kalasalingam Acad Res & Educ, Dept BME, Srivilliputhur, India.
   [Zhang, Yudong] Univ Leicester, Sch Informat, F26,Informat Bldg,Univ Rd, Leicester, Leics, England.
C3 Kalasalingam Academy of Research & Education; Kalasalingam Academy of
   Research & Education; University of Leicester
RP Pankiraj, JB (corresponding author), Kalasalingam Acad Res & Educ, Dept ECE, Srivilliputhur, India.
EM jeyabright@gmail.com; g.vishnuvarthanan@klu.ac.in
RI ; Zhang, Yudong/I-7633-2013
OI , Dr Jeya Bright Pankiraj/0000-0002-9246-5301; Zhang,
   Yudong/0000-0002-4870-1493
CR Alagarsamy S, 2019, BIOCYBERN BIOMED ENG, V39, P1005, DOI 10.1016/j.bbe.2019.05.007
   [Anonymous], 2009, PROC TENCON 2009 IEE
   Bianchi T, 2010, IEEE T INF FOREN SEC, V5, P180, DOI 10.1109/TIFS.2009.2036230
   Bianchi T, 2009, IEEE T INF FOREN SEC, V4, P86, DOI 10.1109/TIFS.2008.2011087
   Bilgin A, 2000, IEEE T IMAGE PROCESS, V9, P1972, DOI 10.1109/83.877218
   Bright P. Jeya, 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P934, DOI 10.1109/ICOEI.2019.8862525
   Chen CC, 2019, IEEE ACCESS, V7, P149515, DOI 10.1109/ACCESS.2019.2944833
   Chuang J.-C., 2006, International Journal of Computers & Applications, V28, P329, DOI 10.2316/Journal.202.2006.4.202-1735
   Edward J., 1979, IEEE T COMMUN, V27, P1335, DOI [10.1109/TCOM.1979.1094560, DOI 10.1109/TCOM.1979.1094560]
   Erkin Z., 2007, EURASIP Journal on Information Security, V7, P1
   Hamzaoui R., 2006, FRACTAL IMAGE COMPRE, P168
   Johnson M, 2004, IEEE T SIGNAL PROCES, V52, P2992, DOI 10.1109/TSP.2004.833860
   Kuribayashi M, 2005, IEEE T IMAGE PROCESS, V14, P2129, DOI 10.1109/TIP.2005.859383
   Lazzeretti R., 2008, P 16 EUR SIGN PROC C, P1
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Malik A, 2017, MULTIMED TOOLS APPL, V76, P14151, DOI 10.1007/s11042-016-3815-2
   Mathews, 2013, CONTROL COMPRESSED S, P377
   Memon N, 2001, IEEE T IMAGE PROCESS, V10, P643, DOI 10.1109/83.913598
   Ou DH, 2015, MULTIMED TOOLS APPL, V74, P9117, DOI 10.1007/s11042-014-2059-2
   Pankiraj JB., 2019, INT J ENG ADV TECHNO, V9, P718, DOI [10.35940/ijeat.A1130.1291S419, DOI 10.35940/IJEAT.A1130.1291S419]
   Troncoso-Pastoriza JR, 2011, IEEE T INF FOREN SEC, V6, P469, DOI 10.1109/TIFS.2011.2109385
   Schonberg D., 2005, 43 ANN ALL C ALL IL
   Su GD, 2020, IEEE ACCESS, V8, P26984, DOI 10.1109/ACCESS.2020.2966234
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Welstead StephenT., 1999, Fractal and wavelet image compression techniques, P155, DOI DOI 10.1117/3.353798
   Yang CN, 2017, J VIS COMMUN IMAGE R, V48, P182, DOI 10.1016/j.jvcir.2017.06.012
   Yu Z, 2019, IEEE ACCESS, V7, P148439, DOI 10.1109/ACCESS.2019.2943505
   Zhang XP, 2012, IEEE T IMAGE PROCESS, V21, P3108, DOI 10.1109/TIP.2012.2187671
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P53, DOI 10.1109/TIFS.2010.2099114
NR 29
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12263
EP 12277
DI 10.1007/s11042-022-13832-w
EA SEP 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000859342300002
DA 2024-07-18
ER

PT J
AU Mishra, KC
   Dutta, S
AF Mishra, Kailash Chandra
   Dutta, Subrata
TI Colluder detection in SaaS cloud applications with subscription based
   license
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Colluders; User authentication; SaaS
AB The use of web applications has been increased by the rapid growth of the Internet. The software application providers moved to cloud computing and offered software as a service (SaaS) as the basis for software delivery to minimize the unauthorized copying of applications by stealing the product key or transforming the license file of the applications. Different forms of SaaS application licensing schemes exist. Subscription-based license has many benefits for the service provider as the business can forecast its revenue through this and can provide its products with better service as well as from the point of view of the customer; customers can relax for the whole subscription duration, can use the application without worry and can get service at any time. Most SaaS application providers support this because of the advantages of the subscription-based licensing scheme. This leads to another problem of unauthorized use of an application's user authentication data. Upon subscription, application providers provide user authentication. But the user authentication information has been exchanged with other entities knowingly or unknowingly. Therefore, many individuals use the same authentication information to access the application, which leads to a huge loss for service providers. The loss is in the form of finance, an excessive spike in cloud server traffic and an increased burden on customer service provision. We proposed a new method for user authentication that will make it easier to memorize and identify colluders. The proposed method automatically keeps tracks of user system with its unique key and detects colluders.
C1 [Mishra, Kailash Chandra; Dutta, Subrata] Natl Inst Technol Jamshedpur, Dept CSE, Jamshedpur, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur
RP Mishra, KC (corresponding author), Natl Inst Technol Jamshedpur, Dept CSE, Jamshedpur, Bihar, India.
EM kailash8590@gmail.com; subrataduttaa.ese@gmail.com
RI Mishra, Kailash Chandra/AAI-3629-2021; Dutta, Subrata/ADS-2550-2022
OI Mishra, Kailash Chandra/0000-0003-4967-3938; 
CR Ahmed I, 2020, INT J PARALLEL PROG, V48, P344, DOI 10.1007/s10766-018-0601-y
   [Anonymous], COMMS CPN CPN TOOLS
   [Anonymous], CPN TOOLS TOOL EDITI
   [Anonymous], GITHUB Z3PROVER Z3 Z
   [Anonymous], UPPAAL
   Lou XS, 2009, IEEE T COMPUT, V58, P970, DOI 10.1109/TC.2009.26
   McKeay M, 2019, 2019 YEAR REV
   Nick I, 2020, PUBL CLOUD REV GROW
   Sun AY, 2019, ENVIRON MODELL SOFTW, V116, P1, DOI 10.1016/j.envsoft.2019.02.015
   Zhang HL, 2013, IEEE J SEL AREA COMM, V31, P105, DOI 10.1109/JSAC.2013.SUP.0513010
   Zhou R, 2008, IEEE T KNOWL DATA EN, V20, P1282, DOI 10.1109/TKDE.2008.48
NR 11
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12135
EP 12149
DI 10.1007/s11042-022-13825-9
EA SEP 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000858369900003
DA 2024-07-18
ER

PT J
AU Mustafa, H
   Umer, M
   Hafeez, U
   Hameed, A
   Sohaib, A
   Ullah, S
   Madni, HA
AF Mustafa, Hassan
   Umer, Muhammad
   Hafeez, Umair
   Hameed, Ahmad
   Sohaib, Ahmed
   Ullah, Saleem
   Madni, Hamza Ahmad
TI Pepper bell leaf disease detection and classification using optimized
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Leaf disease; Image classification; Deep learning; Optimized
   convolutional neural network
AB Agriculture production plays a significant role in the country's economy. Diseases are quite natural and common among plants. Identification of diseases in plants is necessary for averting losses in the yield of agricultural products. Manual monitoring of plants requires expertise, immense effort, and excessive time. Automatic detection will not only help in reducing time and effort but will also help in detecting disease at an early stage, as soon as it will start appearing on plant leaves. Recently, image processing in agriculture has attained a surge of interest by researchers. This study presents a five-layered CNN model for automatic detection of plant disease utilizing leaf images. In order to better train a CNN model, 20,000 augmented images are generated. Experimental results demonstrate that proposed optimized-CNN model can predict pepper bell plant leaf as healthy or bacterial with 99.99% accuracy. Robust results make the proposed optimized-CNN model a preliminary warning tool that can be applied as a disease identification system in a real cultivation environment.
C1 [Mustafa, Hassan; Hafeez, Umair; Hameed, Ahmad; Sohaib, Ahmed; Madni, Hamza Ahmad] Khwaja Fareed Univ Engn & Informat Technol, Dept Comp Engn, Rahim Yar Khan, Pakistan.
   [Umer, Muhammad] Islamia Univ Bahawalpur, Dept Comp Sci, Bahawalpur, Pakistan.
   [Ullah, Saleem] Khwaja Fareed Univ Engn & Informat Technol, Dept Comp Sci, Rahim Yar Khan, Pakistan.
C3 Khwaja Fareed University of Engineering & Information Technology,
   Pakistan; Islamia University of Bahawalpur; Khwaja Fareed University of
   Engineering & Information Technology, Pakistan
RP Umer, M (corresponding author), Islamia Univ Bahawalpur, Dept Comp Sci, Bahawalpur, Pakistan.
EM umersabir1996@gmail.com; ahmed.sohaib@kfueit.edu.pk;
   saleem.ullah@kfueit.edu.pk; 101101770@seu.edu.cn
RI Umer, Muhammad/AAX-4594-2020; Ullah, Saleem/D-2644-2014; Umer,
   Muhammad/KHU-2339-2024; Madni, Hamza Ahmad/S-3459-2018
OI Umer, Muhammad/0000-0002-6015-9326; Ullah, Saleem/0000-0003-3747-1263;
   Umer, Muhammad/0009-0001-8751-6100; Madni, Hamza
   Ahmad/0000-0003-1303-2493
FU Department of Computer Engineering under Khwaja Fareed University of
   Engineering and Information Technology (KFUEIT), Punjab, Rahim Yar Khan,
   Pakistan
FX This research was supported by Department of Computer Engineering under
   Khwaja Fareed University of Engineering and Information Technology
   (KFUEIT), Punjab, Rahim Yar Khan, Pakistan.
CR Alom MZ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030292
   Amara J., 2017, LECT NOTES INFORM LN
   Baranwal S, 2019, P INT C SUST COMP SC
   Bock CH, 2010, CRIT REV PLANT SCI, V29, P59, DOI 10.1080/07352681003617285
   Boulent J, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.00941
   Castiglione A, 2021, IEEE T IND INFORM, V17, P6480, DOI 10.1109/TII.2021.3057524
   Chouhan Siddharth Singh, 2019, 2019 4th International Conference on Information Systems and Computer Networks (ISCON), P700, DOI 10.1109/ISCON47742.2019.9036158
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Fujita E., 2018, Int. J. Eng. Technol., V7, P49
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Hahnloser RHR, 2000, NATURE, V405, P947, DOI 10.1038/35016072
   Huang X., 2018, IEEE COMPUT SOC CONF
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Kim P., 2017, MATLAB DEEP LEARNING, P121, DOI DOI 10.1007/978-1-4842-2845-6
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kundu Nidhi, 2020, 2020 Sixth International Conference on Parallel, Distributed and Grid Computing (PDGC), P243, DOI 10.1109/PDGC50313.2020.9315821
   Lamichhane JR, 2015, FRONT PLANT SCI, V6, DOI 10.3389/fpls.2015.00385
   Lee SH, 2015, IEEE IMAGE PROC, P452, DOI 10.1109/ICIP.2015.7350839
   Liakos KG, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082674
   Mohanty S. P., 2016, Frontiers in Plant Science, V7, P1419
   Pagare R., 2013, INT J COMPUT APPL, V67
   Pandey P, 2017, FRONT PLANT SCI, V8, DOI 10.3389/fpls.2017.00537
   Pawara P, 2017, ICPRAM: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, P479, DOI 10.5220/0006196204790486
   Purwins H, 2019, IEEE J-STSP, V13, P206, DOI 10.1109/JSTSP.2019.2908700
   Rajaraman S, 2018, PEERJ, V6, DOI 10.7717/peerj.4568
   Savary S, 2012, FOOD SECUR, V4, P519, DOI 10.1007/s12571-012-0200-5
   Sharma Parul, 2020, Information Processing in Agriculture, V7, P566, DOI 10.1016/j.inpa.2019.11.001
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Tan QY, 2019, FRONT BIG DATA, V2, DOI 10.3389/fdata.2019.00002
   Tian K, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104962
   Umer M, 2020, IEEE ACCESS, V8, P93782, DOI 10.1109/ACCESS.2020.2994810
   Yu J, 2018, MACH VISION APPL, V29, P929, DOI 10.1007/s00138-018-0948-5
NR 32
TC 13
Z9 13
U1 3
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12065
EP 12080
DI 10.1007/s11042-022-13737-8
EA SEP 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000858393000004
DA 2024-07-18
ER

PT J
AU He, Y
   Yang, P
   Cheng, PS
AF He, Ying
   Yang, Pin
   Cheng, Pengsen
TI Semi-supervised internet water army detection based on graph embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet water army detection; Graph embedding; Semi-supervised
   learning; Online social network
ID SPAMMER DETECTION; ACCOUNTS
AB Sina Weibo is one of the most popular online social networks, which provides users with a convenient and fast way to communicate. However, its openness and large user base are often exploited by water armies to spread disinformation. These water armies seriously affect the security and reliability of social networks. Existing approaches on the water army detection mainly classify users by their account information, behavior and other features. However, the increasing anti-detection capability of water armies has led to insufficient differentiation of detection features. In addition, there is a lack of labeled data for model training. In this paper, we propose a semi-supervised approach combining network structure features and user attribute features for identifying the Internet water army. This approach uses the graph embedding algorithm to obtain network structure features of users, which together with the defined user attribute features constitute the detection feature set. Users are classified by Tri-Training, a semi-supervised learning algorithm, which leverages the synergistic advantages of multiple classifiers and reduces the need for a large number of labeled data. Experiments on real-world data illustrate that our approach can identify the Internet water army effectively, and it is more suitable for real scenarios with less labeled data. The accuracy can reach 95.15%.
C1 [He, Ying; Yang, Pin; Cheng, Pengsen] Sichuan Univ, Sch Cyber Sci & Engn, Chengdu, Peoples R China.
C3 Sichuan University
RP Yang, P (corresponding author), Sichuan Univ, Sch Cyber Sci & Engn, Chengdu, Peoples R China.
EM hying@stu.scu.edu.cn; yangpin@scu.edu.cn; cps11@163.com
FU Sichuan Science and Technology Program [2020YFG0076]
FX This research was funded by Sichuan Science and Technology Program,
   grant number No.2020YFG0076.
CR Adewole KS, 2020, J SUPERCOMPUT, V76, P4802, DOI 10.1007/s11227-018-2641-x
   Aggarwal A., 2012, ECRIME RES SUMMIT EC, P1
   Ahmed F, 2013, COMPUT COMMUN, V36, P1120, DOI 10.1016/j.comcom.2013.04.004
   Al-Thelaya Khaled A., 2020, 2020 IEEE International Conference on Informatics, IoT, and Enabling Technologies (ICIoT), P206, DOI 10.1109/ICIoT48696.2020.9089509
   Alhosseini SA, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P148, DOI 10.1145/3308560.3316504
   Almaatouq A, 2016, INT J INF SECUR, V15, P475, DOI 10.1007/s10207-016-0321-5
   [Anonymous], 2012, P 9 USENIX S NETW SY
   Benevenuto F, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P620, DOI 10.1145/1571941.1572047
   Bhat SY, 2013, 2013 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P106
   Bindu PV, 2018, J INTELL INF SYST, V51, P503, DOI 10.1007/s10844-017-0494-z
   Cai HY, 2018, IEEE T KNOWL DATA EN, V30, P1616, DOI 10.1109/TKDE.2018.2807452
   Chen C, 2013, 2013 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P122
   Chen H, 2018, INFORM FUSION, V44, P22, DOI 10.1016/j.inffus.2017.11.002
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chu Z, 2012, IEEE T DEPEND SECURE, V9, P811, DOI 10.1109/TDSC.2012.75
   Cresci S, 2016, IEEE INTELL SYST, V31, P58, DOI 10.1109/MIS.2016.29
   Fazil M, 2018, IEEE T INF FOREN SEC, V13, P2707, DOI 10.1109/TIFS.2018.2825958
   Fire M, 2014, SOC NETW ANAL MIN, V4, DOI 10.1007/s13278-014-0194-4
   Fu H, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/3086637
   Goldberg Y., 2014, ARXIV
   Goyal P, 2018, KNOWL-BASED SYST, V151, P78, DOI 10.1016/j.knosys.2018.03.022
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Guo ZY, 2018, WEBSCI'18: PROCEEDINGS OF THE 10TH ACM CONFERENCE ON WEB SCIENCE, P210, DOI 10.1145/3201064.3201104
   Harsule S R., 2016, N-Gram Classifier System to Filter Spam Messages from OSN User Wall Innovations in Computer Science and Engineering, P21
   Jeong S, 2016, INFORM SCIENCES, V369, P481, DOI 10.1016/j.ins.2016.07.033
   Kipf TN, 2016, ARXIV
   Lee K, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P435, DOI 10.1145/1835449.1835522
   Lee S, 2014, COMPUT COMMUN, V54, P48, DOI 10.1016/j.comcom.2014.08.006
   Lian Y, 2019, IEEE ACCESS, V7, P55108, DOI 10.1109/ACCESS.2019.2913005
   Lim E.P., 2010, P ACM INT C INFORM K, P939, DOI DOI 10.1145/1871437.1871557
   LIN C., 2013, proceedings of the 7th workshop on social network mining and analysis, P1
   Liu DH, 2015, LECT NOTES COMPUT SC, V9098, P554, DOI 10.1007/978-3-319-21042-1_61
   Martinez-Romo J, 2013, EXPERT SYST APPL, V40, P2992, DOI 10.1016/j.eswa.2012.12.015
   Miller Z, 2014, INFORM SCIENCES, V260, P64, DOI 10.1016/j.ins.2013.11.016
   Pal M, 2005, INT J REMOTE SENS, V26, P217, DOI 10.1080/01431160412331269698
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Rodríguez-Ruiz J, 2020, COMPUT SECUR, V91, DOI 10.1016/j.cose.2020.101715
   Rout RR, 2020, IEEE T COMPUT SOC SY, V7, P1004, DOI 10.1109/TCSS.2020.2992223
   Sahami M., 1998, P LEARN TEXT CAT 199, VVolume 62, P98
   Singh M., 2014, ACM International Conference Proceeding Series, P247
   Stein T., 2011, P 4 WORKSH SOC NETW, P1
   Stringhini G, 2010, 26TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2010), P1
   Wang G, 2012, ARXIV
   Wang J, 2019, SYST SCI CONTROL ENG, V7, P32, DOI 10.1080/21642583.2019.1620658
   Wang K, 2014, 2014 INT C COMPUTER
   Wang W, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-63698-x
   Yang Z, 2016, IEEE T DEPEND SECURE, V13, P488, DOI 10.1109/TDSC.2015.2410792
   Zeng Ke., 2014, World Congr, V19, P9858, DOI 10.3182/20140824-6-za-1003.01402
   Zhou ZH, 2005, IEEE T KNOWL DATA EN, V17, P1529, DOI 10.1109/TKDE.2005.186
NR 49
TC 2
Z9 2
U1 9
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 9891
EP 9912
DI 10.1007/s11042-022-13633-1
EA SEP 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000854694900002
DA 2024-07-18
ER

PT J
AU Jayaswal, R
   Dixit, M
AF Jayaswal, Ruchi
   Dixit, Manish
TI AI-based face mask detection system: a straightforward proposition to
   fight with Covid-19 situation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Covid-19; CNN models; Face mask detection; Deep neural
   network; Face mask dataset
AB The whole world is suffering from a novel coronavirus, which has become an epidemic. According to a World Health Organization report, this is a communicable disease, i.e., it transfers from an infected person to a healthy person. Therefore, wearing a mask is the most important precaution to protect from COVID-19. This paper presented a deep learning-based approach to design a Face Mask Detection framework to predict whether a person is wearing a mask or not. The proposed method uses a Single Shot Multibox detector as a face detector model and a deep Inception V3 architecture (SSDIV3) to extract the pertinent features of images and discriminate them in mask and without masks labels. Optimizing the SSDIV3 approach using different modeling parameters is a genuine contribution of this work. In addition to this, the system is tested and analyzed on VGG16, VGG19, Xception, Mobilenet V2 models at different modeling parameters. Furthermore, two synthesized novel Face Mask Datasets are introduced containing diversified masks (2d_printed, 3d_printed, handkerchief, transparent, natural-looking mask appearance masks) and unmask images of humans collected in outdoor and indoor environments such as parks, homes, laboratories. The experiment outcomes demonstrate that the proposed system has achieved an accuracy of 98% on the synthesized benchmark datasets, which comparatively outperforms other state-of-art methods and datasets in a real-time environment.
C1 [Jayaswal, Ruchi; Dixit, Manish] MITS, Dept CSE, Gwalior, Madhya Pradesh, India.
C3 Madhav Institute of Technology & Science
RP Jayaswal, R (corresponding author), MITS, Dept CSE, Gwalior, Madhya Pradesh, India.
EM ruchi.jayaswal23@mitsgwalior.in; dixitmits@mitsgwalior.in
RI JAYASWAL, RUCHI/HZM-0177-2023
CR [Anonymous], 2020, Situation Report-47
   Ansari MA, 2021, MULTIMED TOOLS APPL, V80, P8759, DOI 10.1007/s11042-020-10103-4
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Bazi Y, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11242908
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Dalgleish T, 2007, J EXP PSYCHOL GEN, V136, P23, DOI 10.1037/0096-3445.136.1.23
   Das A, 2020, 2020 IEEE PUNE SECTION INTERNATIONAL CONFERENCE (PUNECON), P1, DOI 10.1109/PuneCon50868.2020.9362416
   Deng J., 2019, P COMP VIS PATT REC, P5203, DOI 10.1109/CVPR42600.2020.00525
   Duan Y., 2016, 2 INT C COMPUTER ENG, P4077
   Duchi JC, 2012, IEEE DECIS CONTR P, P5442, DOI 10.1109/CDC.2012.6426698
   Ge S., 2017, IEEE C COMPUT VIS PA, P2682, DOI DOI 10.1109/CVPR.2017.53
   Guo YH, 2019, PROC CVPR IEEE, P4800, DOI 10.1109/CVPR.2019.00494
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Hariri W, 2022, SIGNAL IMAGE VIDEO P, V16, P605, DOI 10.1007/s11760-021-02050-w
   Hussain G. K. Jakir, 2021, Journal of Physics: Conference Series, V1916, DOI 10.1088/1742-6596/1916/1/012084
   Jayaswal R, 2021, TRAIT SIGNAL, V38, P1875, DOI 10.18280/ts.380632
   Jayaswal R, 2020, INT CONF COMM SYST, P66, DOI [10.1109/CSNT.2020.13, 10.1109/CSNT48778.2020.9115779]
   Jayaswal R, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1125, DOI 10.1109/CCAA.2017.8229965
   Jiang M., 2020, ARXIV
   Jignesh Chowdary G., 2020, Big Data Analytics. 8th International Conference, BDA 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12581), P81, DOI 10.1007/978-3-030-66665-1_6
   Kingma D. P., 2014, arXiv
   Kumar A, 2019, ARTIF INTELL REV, V52, P927, DOI 10.1007/s10462-018-9650-2
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   McMahan HB, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P1222
   Nagrath P, 2021, SUSTAIN CITIES SOC, V66, DOI 10.1016/j.scs.2020.102692
   Paul S, 2019, ADV NEUR IN, V32
   Probst P, 2019, J MACH LEARN RES, V20
   Ruder S., 2016, ARXIV
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sethi S, 2021, J BIOMED INFORM, V120, DOI 10.1016/j.jbi.2021.103848
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Susanto, 2020, 2020 3RD INTERNATIONAL CONFERENCE ON APPLIED ENGINEERING (ICAE), DOI 10.1109/ICAE50557.2020.9350556
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Wang ZY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1072
   WHO, 2020, Coronavirus disease (COVID-19) pandemic
   Worldometer, 2020, COVID 19 COR PAND
   Yadav Shashi., 2020, INT J RES APPL SCI E, V8, P1368, DOI [DOI 10.22214/IJRASET.2020.30560, 10.22214/IJRASET.2020.30560]
   Zeiler Matthew D, 2012, ARXIV12125701
   Zhang F, 2019, ARXIV
NR 43
TC 8
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13241
EP 13273
DI 10.1007/s11042-022-13697-z
EA SEP 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000852263700001
PM 36101885
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Rezaei, GA
   Karimi, S
   Jafari, H
AF Rezaei, Gholam Ali
   Karimi, Saeed
   Jafari, Hamidreza
TI Risk assessment of bomb blasts in a military zone
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Explosion; Emergency response; Risk assessment; Overpressure; Military
   zone
ID HYDROGEN ADDITION; ETHANE; MIXTURES; METHANE
AB Explosion in the military zone emergency response plan includes the process of preparedness, risk reduction, and normalization of the emergency. A bomb blast causes human and financial losses to people. Therefore, to prepare and reduce the risk, it is necessary to simulate a bomb blast in a military zone. For this purpose, in this study, the risk of a bomb blast containing ethane, methane, and propane fuel was simulated by the Baker-Strehlow-Tang explosion method in the form of 3 scenarios. According to this method, at a distance of 6, 4.5, and 5 km from the place of ethane, methane, and propane bombs explosion, respectively, the amount of impulse caused by the explosion is reduced by 50%. According to these results, it is clear that the overpressure explosion of ethane, methane, and propane bombs in the military zone is not directly related to the distance from the site of the explosion. The pulse from the explosion of ethane, methane, and propane bombs occurs in one second and will be the same at all distances.
C1 [Rezaei, Gholam Ali; Karimi, Saeed; Jafari, Hamidreza] Univ Tehran, Fac Environm, 15 Qods St,Enghelab Ave, Tehran, Iran.
C3 University of Tehran
RP Karimi, S (corresponding author), Univ Tehran, Fac Environm, 15 Qods St,Enghelab Ave, Tehran, Iran.
EM rezaei.gholamali97@gmail.com; karimis@ut.ac.ir; hjafari@ut.ac.ir
CR Abdel-Jawad M, 2021, PROCESS SAF PROG, V40, P281, DOI 10.1002/prs.12247
   Addai EK, 2020, PROCESS SAF PROG, V39, DOI 10.1002/prs.12139
   [Anonymous], 1994, GUIDELINES EVALUATIN
   Bosschaart KJ, 2004, COMBUST FLAME, V136, P261, DOI 10.1016/j.combustflame.2003.10.005
   Brecher Michael., 2008, International Political Earthquakes, DOI [DOI 10.3998/MPUB.293883, 10.3998/mpub.293883]
   CCPS, 1999, GUID CHEM PROC QUANT
   Cigler B.A., 1987, CRISIS MANAGEMENT CA
   Clough SR., 2005, ENCY TOXICOLOGY, P529, DOI [10.1016/B0-12-369400-0/00797-3, DOI 10.1016/B0-12-369400-0/00797-3]
   Commission on Human Security, 2003, HUM SEC NOW
   Crowl D.A., 2002, CHEM PROCESS SAFETY, VSecond
   Fouchier C, 2017, J LOSS PREVENT PROC, V49, P248, DOI 10.1016/j.jlp.2017.06.021
   Goswami M, 2016, FUEL, V166, P410, DOI 10.1016/j.fuel.2015.11.013
   Halter F, 2007, INT J HYDROGEN ENERG, V32, P2585, DOI 10.1016/j.ijhydene.2006.11.033
   Helsel E, 2021, HBK COMMUN MEDIA, P194
   Hu ER, 2015, ENERG FUEL, V29, P4557, DOI 10.1021/acs.energyfuels.5b00462
   Huang ZH, 2006, COMBUST FLAME, V146, P302, DOI 10.1016/j.combustflame.2006.03.003
   Iannotti F.A., 2018, Endocannabinoidome, DOI DOI 10.1002/9781119379256.CH4
   Jokela M, 2017, EUR J PERSONAL, V31, P234, DOI [10.1002/per.2106, DOI 10.1002/PER.2106]
   Kent, 2003, RIEGELS HDB IND CHEM, DOI [10.1007/0-387-23816-6, DOI 10.1007/0-387-23816-6]
   Kouzmin A., 2008, Adm. Theory Prax, V30, P155, DOI [DOI 10.1080/10841806.2008.11029631, 10.1080/10841806.2008.11029631]
   Li ZQ, 2017, INT J HYDROGEN ENERG, V42, P24055, DOI 10.1016/j.ijhydene.2017.07.190
   Liao SY, 2005, J HAZARD MATER, V119, P81, DOI 10.1016/j.jhazmat.2004.09.031
   Lowry W, 2011, J ENG GAS TURB POWER, V133, DOI 10.1115/1.4002809
   Naik CV, 2006, COMBUST FLAME, V145, P16, DOI 10.1016/j.combustflame.2005.12.006
   Oyewole S., 2018, Defence Studies, V18, P514, DOI [10.1080/14702436.2018.1524709, DOI 10.1080/14702436.2018.1524709]
   Pan L, 2014, INT J HYDROGEN ENERG, V39, P6024, DOI 10.1016/j.ijhydene.2014.01.157
   Park DJ, 2009, KOREAN J CHEM ENG, V26, P313, DOI 10.1007/s11814-009-0054-5
   Rangra A, 2022, MULTIMED TOOLS APPL, V81, P34447, DOI 10.1007/s11042-021-11486-8
   Ravi S, 2015, P COMBUST INST, V35, P679, DOI 10.1016/j.proci.2014.05.130
   Ravikumar K, 2020, MULTIMED TOOLS APPL, V79, P3929, DOI 10.1007/s11042-019-7583-7
   Remennikov A.M., 2003, Journal of Battlefield Technology
   Said N, 2019, MULTIMED TOOLS APPL, V78, P31267, DOI 10.1007/s11042-019-07942-1
   Shariatmadar Mortazavi Zavareh SM., 2018, IRANIAN J MECH ENG, V20, P170
   Tang MJ, 1999, PROCESS SAF PROG, V18, P235, DOI 10.1002/prs.680180412
   The World Bank and the United Nations, 2010, Natural Hazards, Unnatural Disasters: The Economics of Effective Prevention
   Veloo PS, 2010, COMBUST FLAME, V157, P1989, DOI 10.1016/j.combustflame.2010.04.001
   Verma C., 2018, INT J PURE APPL MATH, V119, P49
   Williams G, 2000, CITIES, V17, P293, DOI 10.1016/S0264-2751(00)00025-1
   Yong Y, 2020, MULTIMED TOOLS APPL, V79, P35463, DOI 10.1007/s11042-019-07790-z
NR 39
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 SEP 6
PY 2022
DI 10.1007/s11042-022-13371-4
EA SEP 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4H6YG
UT WOS:000850022900001
DA 2024-07-18
ER

PT J
AU Mahajan, S
   Mittal, N
   Pandit, AK
AF Mahajan, Shubham
   Mittal, Nitin
   Pandit, Amit Kant
TI Image segmentation approach based on adaptive flower pollination
   algorithm and type II fuzzy entropy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image pre-processing; Segmentation; Flower pollination algorithm; Fuzzy
   entropy; Multilevel thresholding
ID DIFFERENTIAL EVOLUTION; MULTILEVEL
AB Image segmentation depend on fuzzy entropy (FE) and intelligent optimization is among the most widely used and popular approaches. Segmentation is an important and pre-processing step in the analysis of an image. Multilevel thresholding is efficient for color images in different multimedia applications in day-to-day life. The method of assessing optimal threshold values using conventional schemes consumes more time. To alleviate the above-mentioned problem, meta-heuristic method has been used for optimization in this area over the last few years. This paper proposes a novel image thresholding technique depend on Adaptive Flower Pollination Algorithm (AFPA) and type II fuzzy entropy (TII-FE). The thresholding methodology is assessed against competitive algorithms concerning the quality, convergence and accuracy of segmented images. The quality is computed in relation of SSIM, PSNR and MSE parameters. The results indicate that AFPA for TII-FE is effective technique for image thresholding.
C1 [Mahajan, Shubham; Pandit, Amit Kant] Shri Mata Vaishno Devi Univ, Katra, India.
   [Mahajan, Shubham] Ajeenkya DY Patil Univ, Sch Engn, DY Patil Knowledge City Rd, Pune 412105, Maharashtra, India.
   [Mittal, Nitin] Shri Vishwakarma Skill Univ, Skill Fac Engn & Technol, Palwal 121102, Haryana, India.
C3 Shri Mata Vaishno Devi University
RP Mahajan, S (corresponding author), Shri Mata Vaishno Devi Univ, Katra, India.; Mahajan, S (corresponding author), Ajeenkya DY Patil Univ, Sch Engn, DY Patil Knowledge City Rd, Pune 412105, Maharashtra, India.
EM mahajanshubham2232579@gmail.com; mittal.nitin84@gmail.com;
   amitkantpandit@gmail.com
RI MAHAJAN, SHUBHAM/AAY-6389-2020
OI MAHAJAN, SHUBHAM/0000-0003-0385-3933; mittal, nitin/0000-0003-0758-2755
CR Abd Elaziz M, 2020, SOFT COMPUT, V24, P14885, DOI 10.1007/s00500-020-04842-7
   Agarwal P, 2016, SMART INNOV SYST TEC, V51, P249, DOI 10.1007/978-3-319-30927-9_25
   Agrawal S, 2013, SWARM EVOL COMPUT, V11, P16, DOI 10.1016/j.swevo.2013.02.001
   [Anonymous], 2017, TYPE 2 FUZZY ENTROPY, DOI DOI 10.31224/OSF.IO/5KQZD
   Benzid R., 2008, 5 INT MULT SYST SIGN, P1, DOI DOI 10.1109/SSD.2008.4632831
   Bhandari AK, 2014, EXPERT SYST APPL, V41, P3538, DOI 10.1016/j.eswa.2013.10.059
   Chuang LY, 2011, APPL MATH COMPUT, V217, P6900, DOI 10.1016/j.amc.2011.01.081
   Das S, 2009, IEEE T EVOLUT COMPUT, V13, P526, DOI 10.1109/TEVC.2008.2009457
   He LF, 2017, NEUROCOMPUTING, V240, P152, DOI 10.1016/j.neucom.2017.02.040
   Horng MH, 2011, EXPERT SYST APPL, V38, P14805, DOI 10.1016/j.eswa.2011.05.069
   Jiang YC, 2013, INFORM SCIENCES, V240, P95, DOI 10.1016/j.ins.2013.03.052
   Kansal I, 2020, MULTIMED TOOLS APPL, V79, P12069, DOI 10.1007/s11042-019-08240-6
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kukreja S, 2021, VISUAL COMPUT, V37, P1481, DOI 10.1007/s00371-020-01883-9
   Kukreja S, 2020, MULTIMED TOOLS APPL, V79, P26155, DOI 10.1007/s11042-020-09130-y
   Kukreja S, 2019, MULTIMED TOOLS APPL, V78, P6139, DOI 10.1007/s11042-018-6169-0
   LI CH, 1993, PATTERN RECOGN, V26, P617, DOI 10.1016/0031-3203(93)90115-D
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mlakar U, 2016, EXPERT SYST APPL, V65, P221, DOI 10.1016/j.eswa.2016.08.046
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pare S, 2017, EXPERT SYST APPL, V87, P335, DOI 10.1016/j.eswa.2017.06.021
   Singh P, 2021, WIREL NETW, V27, P1999, DOI 10.1007/s11276-021-02557-7
   Singh U.K., 2017, ISH J. Hydraul. Eng, V3, P308, DOI [10.1080/09715010.2017.1313144, DOI 10.1080/09715010.2017.1313144]
   Sumathi R, 2018, BIOCYBERN BIOMED ENG, V38, P918, DOI 10.1016/j.bbe.2018.07.005
   Wu JR, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113340
   Wu XL, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/3498363
   Xin-She Yang, 2012, Unconventional Computation and Natural Computation. Proceedings of the 11th International Conference, UCNC 2012, P240, DOI 10.1007/978-3-642-32894-7_27
NR 27
TC 7
Z9 7
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8537
EP 8559
DI 10.1007/s11042-022-13551-2
EA AUG 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000844934900005
DA 2024-07-18
ER

PT J
AU Dehdar, A
   Keshavarz, A
   Parhizgar, N
AF Dehdar, Abouzar
   Keshavarz, Ahmad
   Parhizgar, Naser
TI Image steganalysis using modified graph clustering based ant colony
   optimization and Random Forest
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganalysis; Graph clustering; Random forest; Ant colony
ID STEGANOGRAPHY; ALGORITHM
AB In this paper, a steganalysis algorithm is proposed based on Modified Graph Clustering Based Ant Colony Optimization (MGCACO) feature selection and Random Forest classifier. First, different features related to the steganalysis problem are extracted from each image, and then an optimal set of the extracted features is selected by using the MGCACO feature selection algorithm, and finally a trained classifier used to separate the clean images from the steganography images. Our proposed algorithm is compared with four steganography algorithms including least significant bit matching (LSB), highly undetectable steganography (HUGO), wavelet obtained weights (WOW) and spatial-universal relative wavelet distortion (S_UNIWARD) with different embedding rates such as 0.1, 0.2, 0.3 and 0.4. Moreover, as a new study, the types of steganography algorithms are identified by using the proposed algorithm. The results of the proposed algorithm show that our approach can distinguish between clean and steganography images acceptably and, in addition, this algorithm can detect the type of steganography algorithm with an average accuracy of 90%.
C1 [Dehdar, Abouzar; Parhizgar, Naser] Islamic Azad Univ, Dept Elect Engn, Shiraz Branch, Shiraz, Iran.
   [Keshavarz, Ahmad] Persian Gulf Univ, Fac Intelligent Syst Engn & Data Sci, ICT Res Inst, IoT & Signal Proc Res Grp, Bushehr 7516913817, Iran.
C3 Islamic Azad University; Persian Gulf University
RP Keshavarz, A (corresponding author), Persian Gulf Univ, Fac Intelligent Syst Engn & Data Sci, ICT Res Inst, IoT & Signal Proc Res Grp, Bushehr 7516913817, Iran.
EM Abouzar.dehdar@yahoo.com; A.keshavarz@pgu.ac.ir; N.parhizgar47@gmail.com
RI Parhizgar, Naser/AAO-3245-2021; Keshavarz, Ahmad/G-7030-2018
OI Parhizgar, Naser/0000-0002-0508-232X; Keshavarz,
   Ahmad/0000-0002-5103-8311
CR Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Alyousuf Din, 2020, Bulletin of Electrical Engineering and Informatics, V9, P573
   [Anonymous], 2014, RES J APPL SCI ENG T, DOI DOI 10.19026/RJASET.7.773
   [Anonymous], 2017, 2017 5 INT WORKSHOP, DOI DOI 10.1109/IWBF.2017.7935103
   [Anonymous], 2000, COLT
   [Anonymous], 2014, Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2014 Asia-Pacific, DOI [10.1109/APSIPA.2014, 10.1109/APSIPA.2014.7041565]
   Arabi PunalM., 2016, Perspectives in Science, V8, P203
   Avcibas I, 2001, PROC SPIE, V4314, P523, DOI 10.1117/12.435436
   Banerjee, 2014, INT J COMPUT ELECT A, V8, P1504
   Berrendero JR, 2016, J STAT COMPUT SIM, V86, P891, DOI 10.1080/00949655.2015.1042378
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Cilluffo A.R., 2019, World's population is projected to nearly stop growing by the end of the century
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Dua D., 2018, UCI MACHINE LEARNING
   Feng BW, 2017, J VIS COMMUN IMAGE R, V46, P119, DOI 10.1016/j.jvcir.2017.01.008
   Geetha S, 2009, COMPUT SECUR, V28, P683, DOI 10.1016/j.cose.2009.03.006
   Ghamsarian N, 2021, MULTIMED TOOLS APPL, V80, P9137, DOI 10.1007/s11042-020-10001-9
   Ghimatgar H, 2018, KNOWL-BASED SYST, V159, P270, DOI 10.1016/j.knosys.2018.06.025
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Kabir MM, 2011, NEUROCOMPUTING, V74, P2914, DOI 10.1016/j.neucom.2011.03.034
   Karampidis K, 2018, J INF SECUR APPL, V40, P217, DOI 10.1016/j.jisa.2018.04.005
   Kodovsky J, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P187
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Liao X, 2016, SECUR COMMUN NETW, V9, P5756, DOI 10.1002/sec.1734
   Liu Y, 2006, PATTERN RECOGN, V39, P1333, DOI 10.1016/j.patcog.2005.10.006
   Malekmohamadi H, 2009, IEEE INT CON MULTI, P1740
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Miranda JD, 2022, MULTIMED TOOLS APPL, V81, P785, DOI 10.1007/s11042-021-11527-2
   Mohamed Nour, 2020, 2020 14th International Conference on Innovations in Information Technology (IIT), P45, DOI 10.1109/IIT50501.2020.9299075
   Moradi P, 2015, KNOWL-BASED SYST, V84, P144, DOI 10.1016/j.knosys.2015.04.007
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Pibre L., 2016, Electronic Imaging, V2016, P1, DOI DOI 10.2352/ISSN.2470-1173.2016.8.MWSF-078
   Qian YL, 2018, MULTIMED TOOLS APPL, V77, P19633, DOI 10.1007/s11042-017-5326-1
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Reinel TS, 2019, IEEE ACCESS, V7, P68970, DOI 10.1109/ACCESS.2019.2918086
   Saha S, 2015, ARXIV
   Seiffert C, 2008, INT C PATT RECOG, P3650
   Shankar DD, 2020, LECT NOTES NETWORKS, P405
   Singhal A, 2021, MULTIMED TOOLS APPL, V80, P13931, DOI 10.1007/s11042-020-10353-2
   Wang L., 2005, SUPPORT VECTOR MACHI, VVolume 177, DOI DOI 10.1007/B95439
   Wang P, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107422
   Wu ST, 2020, IEEE T MULTIMEDIA, V22, P256, DOI 10.1109/TMM.2019.2920605
   Wu ST, 2018, MULTIMED TOOLS APPL, V77, P10437, DOI 10.1007/s11042-017-4440-4
   Wu ST, 2017, IEEE INT CON MULTI, P241, DOI 10.1109/ICME.2017.8019304
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Yang Yu, 2022, The International Conference on Image, Vision and Intelligent Systems (ICIVIS 2021). Lecture Notes in Electrical Engineering (813), P933, DOI 10.1007/978-981-16-6963-7_82
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Zhang H, 2014, SCI CHINA INFORM SCI, V57, DOI 10.1007/s11432-013-4793-x
   Zheng EG, 2011, KSII T INTERNET INF, V5, P840, DOI 10.3837/tiis.2011.04.012
NR 52
TC 3
Z9 3
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7401
EP 7418
DI 10.1007/s11042-022-13599-0
EA AUG 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000842923700002
DA 2024-07-18
ER

PT J
AU Parsuramka, S
   Panja, AK
   Roy, P
   Neogy, S
   Chowdhury, C
AF Parsuramka, Satyam
   Panja, Ayan Kumar
   Roy, Priya
   Neogy, Sarmistha
   Chowdhury, Chandreyee
TI FABEL: feature association based ensemble learning for positioning in
   indoor environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural selection; RSS; Ensemble learning; Majority voting; AP
   selection; Indoor localization; Training pipeline
ID ACCESS-POINT SELECTION; LOCALIZATION
AB Optimal selection of features leads to the increase in perceptibility of the predictor procedure and thereby in turn increases the accuracy. In the domain of WiFi-based indoor positioning, access points are a ubiquitous source of features with which the positioning process is carried out. The selection of a proper subset of access points is crucial for sustainable localization performance. Most of the existing works in the literature focus on important AP selection whereas, the stability of the feature sets w.r.t varying context remains mostly ignored. Thus, to impart sustainable localization performance, in this work, the problem of identification of a stable set(s) of APs is investigated. Thus, the contribution of this work is two-fold. A genetic algorithm based feature selection technique for indoor localization is proposed first. The motive behind the approach is to capture different subsets of APs that best contribute to the localization process. Accordingly, our second contribution is the design of a Feature Association Based Ensemble Learning (FABEL) model that utilizes the selected feature sets in order to retain generality for sustainable localization performance. Experimentation has been carried out on real-world data and analysis has been presented. The proposed training pipeline has been tested for device heterogeneity. It has been found that even for an unknown test device, the localization accuracy is significantly good and 80% of the errors lies within 4m.
C1 [Parsuramka, Satyam] Jadavpur Univ, Kolkata, W Bengal, India.
   [Panja, Ayan Kumar] Jadavpur Univ, Inst Engn & Management, Comp Sci & Engn, Kolkata, W Bengal, India.
   [Roy, Priya] Sister Nivedita Univ, New Town 700156, W Bengal, India.
   [Neogy, Sarmistha; Chowdhury, Chandreyee] Jadavpur Univ, Comp Sci & Engn, Kolkata, W Bengal, India.
C3 Jadavpur University; Jadavpur University; Institute of Engineering &
   Management (IEM), Kolkata; Jadavpur University
RP Chowdhury, C (corresponding author), Jadavpur Univ, Comp Sci & Engn, Kolkata, W Bengal, India.
EM samparsuramka@gmail.com; ayanpanja1992@gmail.com;
   priyaroy.rs@jadavpuruniversity.in; sarmisthaneogy@gmail.com;
   chandreyee.chowdhury@gmail.com
RI Panja, Ayan Kumar/ABD-7606-2021; Roy Karmakar, Priya/GLS-5145-2022
OI Panja, Ayan Kumar/0000-0002-6569-9794; Roy Karmakar,
   Priya/0000-0001-8790-0017
FU Ministry of Science and Technology, Department of Science and
   Technology, NGP Division, Government of India
   [NRDMS/UG/NetworkingProject/e-13/2019(G)]
FX This research work is partially supported by the project entitled-
   "Developing Framework for Indoor Location Based Services with Seamless
   Indoor Outdoor Navigation by expanding Spatial Data Infrastructure",
   funded by the Ministry of Science and Technology, Department of Science
   and Technology, NGP Division, Government of India, ref no.
   NRDMS/UG/NetworkingProject/e-13/2019(G).
CR Alsmady A, 2017, INT CONF INFORM COMM, P287, DOI 10.1109/IACS.2017.7921986
   Amer B, 2016, PROCEEDINGS OF 2016 11TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES), P329, DOI 10.1109/ICCES.2016.7822023
   [Anonymous], 2015, WI FI BASED INDOOR L
   [Anonymous], 2016, 2016 INT C INDOOR PO, DOI [10.1109/NOC.2016.7507005, DOI 10.1109/IPIN.2016.7743586, DOI 10.1109/ICCCN.2016.7568532]
   Bouaguel W, 2016, PROC ADAPT LEARN OPT, V5, P75, DOI 10.1007/978-3-319-27000-5_6
   Bozkurt S, 2015, 2015 INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA) PROCEEDINGS, P47
   Chen YQ, 2006, IEEE T KNOWL DATA EN, V18, P877, DOI 10.1109/TKDE.2006.112
   Cheng YK, 2016, IEEE VTS VEH TECHNOL, DOI 10.1109/VTCSpring.2016.7504333
   Friedl MA, 1997, REMOTE SENS ENVIRON, V61, P399, DOI 10.1016/S0034-4257(97)00049-7
   Gan XL, 2017, INT C INDOOR POSIT
   Giuliano R, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9061055
   Guo H, 2019, MEASUREMENT, V134, P908, DOI 10.1016/j.measurement.2018.12.038
   Houck C. R., 1995, NCSU IE T, V95, P1
   Huang PY, 2021, MOBILE NETW APPL, V26, P649, DOI 10.1007/s11036-019-01411-7
   Iwendi C, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092559
   Jiang P, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/429104
   Jiang WC, 2017, MULTIMED TOOLS APPL, V76, P20317, DOI 10.1007/s11042-017-4779-6
   Kaemarungsi K, 2004, IEEE INFOCOM SER, P1012
   Karci A, 2004, LECT NOTES COMPUT SC, V3214, P268
   Laitinen E, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16050737
   Lee K, 2018, MULTIMED TOOLS APPL, V77, P12635, DOI 10.1007/s11042-017-4908-2
   Li A, 2021, IEEE INTERNET THINGS, V8, P187, DOI 10.1109/JIOT.2020.3001383
   Li D, 2016, IEEE INTERNET THINGS, V3, P590, DOI 10.1109/JIOT.2015.2495229
   Li GQ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092820
   Lin TN, 2014, IEEE T VEH TECHNOL, V63, P3967, DOI 10.1109/TVT.2014.2303141
   Lipowski A, 2012, PHYSICA A, V391, P2193, DOI 10.1016/j.physa.2011.12.004
   Luo Junhai, 2017, Sensors (Basel), V17, DOI 10.3390/s17061339
   Meng W, 2011, SECURE ROBUST WI FI, P1
   Roy P, 2019, 2019 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET 2019): ADVANCING WIRELESS AND MOBILE COMMUNICATIONS TECHNOLOGIES FOR 2020 INFORMATION SOCIETY, P491, DOI [10.1109/WiSPNET45539.2019.9032859, 10.1109/wispnet45539.2019.9032859]
   Roy P, 2019, WIRELESS PERS COMMUN, V106, P739, DOI 10.1007/s11277-019-06188-2
   Sheikhan M, 2013, NEURAL COMPUT APPL, V23, P215, DOI 10.1007/s00521-012-0814-8
   Shi HY, 2012, PROCEEDING OF THE IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P137, DOI 10.1109/ICInfA.2012.6246797
   Sinha RS, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8050554
   Song ZQ, 2015, LECT NOTES COMPUT SC, V9486, P319, DOI 10.1007/978-3-319-26626-8_24
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Tian Y, 2018, LECT NOTES COMPUT SC, V11336, P489, DOI 10.1007/978-3-030-05057-3_37
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Xiao J, 2012, IEEE IC COMP COM NET, DOI 10.1109/ICCCN.2012.6289200
   Youssef MA, 2003, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS (PERCOM 2003), P143, DOI 10.1109/PERCOM.2003.1192736
   Zhang LW, 2017, CHINA COMMUN, V14, P141, DOI 10.1109/CC.2017.8233657
   Zhang S, 2018, LECT NOTES ELECTR EN, V499, P725, DOI 10.1007/978-981-13-0029-5_61
   Zhou BD, 2020, IEEE WIREL COMMUN LE, V9, P1799, DOI 10.1109/LWC.2020.2981793
NR 42
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7247
EP 7266
DI 10.1007/s11042-022-13651-z
EA AUG 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000847198200002
DA 2024-07-18
ER

PT J
AU Li, QW
   Wang, X
   Pei, QQ
AF Li, Qianwen
   Wang, Xiang
   Pei, Qingqi
TI A robust reversible watermarking scheme overcomes the misalignment
   problem of generalized histogram shifting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robust reversible watermarking; Histogram shifting; Non-synchronous
   problem
ID LOSSLESS WATERMARKING; DIFFERENCE EXPANSION; TRANSFORM
AB There are a lot of reversible watermarking (RW) methods have been proposed to losslessly embed watermarks. However, the embedding process of reversible watermarks is fragile, i.e., the hiding data can not resist any attacks. To the end, the robust reversible watermarking (RRW) algorithms are proposed, which enable the embedded information can resist incidental alteration. Generalized histogram shifting (GHS) is a mainstream algorithm of RRW, which extends the traditional histogram shifting (HS) by shifting extra space. However, a non-synchronous problem may be generated under some attacks due to the shifting bins are misjudged as embedding bins, which results watermarks are meaningless. In this work, we propose a RRW global embedding scheme to deal with this problem. Specifically, the shifted bins in GHS are further extended to embed data, which ensures that all blocks in the image are embedded information. As a result, the non-synchronous problem can be solved by our method. Experiment results show that the proposed method outperforms some other state of the art works.
C1 [Li, Qianwen] Xidian Univ, Sch Telecommun Engn, Xian 710071, Shaanxi, Peoples R China.
   [Wang, Xiang] Xidian Univ, Sch Cyber Engn, Xian 710071, Shaanxi, Peoples R China.
   [Pei, Qingqi] Xidian Univ, Sch Telecommun Engn, State Key Lab Integrated Serv Networks, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University; Xidian University; Xidian University
RP Wang, X (corresponding author), Xidian Univ, Sch Cyber Engn, Xian 710071, Shaanxi, Peoples R China.
EM wangxiang@xidian.edu.cn
OI Wang, Xiang/0000-0001-5900-8486
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], 2016, J INFORM HIDING MULT
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Celik MU, 2006, IEEE T IMAGE PROCESS, V15, P1042, DOI 10.1109/TIP.2005.863053
   Coltuc D, 2007, PROC SPIE, V6505
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Coltuc D, 2007, J PHYS CONF SER, V77, DOI 10.1088/1742-6596/77/1/012005
   De Vleeschouwer C, 2003, IEEE T MULTIMEDIA, V5, P97, DOI 10.1109/TMM.2003.809729
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   Goljan M., 2001, 4th Information Hiding Workshop, LNCS, V2137, P27, DOI DOI 10.1007/3-540-45496-9
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Hwang J, 2006, LECT NOTES COMPUT SC, V4283, P348
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Koch E., 1995, PROC WORKSHOP NONLIN, P452
   Lee SK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1321, DOI 10.1109/icme.2006.262782
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ni ZC, 2008, IEEE T CIRC SYST VID, V18, P497, DOI 10.1109/TCSVT.2008.918761
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Suryavanshi HE, 2014, IEEE INT C POW EL DR, P1
   Thodi DM, 2004, IEEE IMAGE PROC, P1549
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Weng S., 2012, JJIH MSP, V3, P320
   Xuan GR, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P312
   Zeng XT, 2010, PATTERN RECOGN, V43, P1656, DOI 10.1016/j.patcog.2009.09.016
   Zou DK, 2004, 2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P195
NR 33
TC 1
Z9 1
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7207
EP 7227
DI 10.1007/s11042-022-13611-7
EA AUG 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000842591000004
DA 2024-07-18
ER

PT J
AU Djebli, H
   Ait-Aoudia, S
   Michelucci, D
AF Djebli, Hamza
   Ait-Aoudia, Samy
   Michelucci, Dominique
TI Quantized random projections of SIFT features for cancelable
   fingerprints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cancelable biometrics; Fingerprint; Template protection; SIFT features;
   Random projections
ID TEMPLATE PROTECTION; BIOMETRICS; SECURITY; SYSTEM; GENERATION; PRIVACY;
   DESIGN
AB Biometric recognition, particularly fingerprint, has been widely adopted in many civil and military applications. However, security concerns have arisen regarding the protection of the saved biometric templates. If the fingerprints database is compromised, the person can no longer use his/her registered fingerprint for authentication. Cancelable biometrics have been used to overcome this issue, by transforming fingerprint templates to a secure representation before saving them on the database. The identity verification is performed in the transformed domain, and a new transform is assigned to a user if his/her biometric data is compromised. In this context, we propose a unique cancelable fingerprint scheme based on the extraction of Scale Invariant Feature Transform (SIFT) features from fingerprint minutiae positions. To provide cancelability, SIFT features are transformed by applying user-specific random projections, followed by quantization to ensure irreversibility. We successfully achieved a zero Equal Error Rate (EER) for the Fingerprint Verification Competition (FVC) 2002 DB1 benchmark in the different-key scenario, and 1.78 EER in the stolen-key scenario. We compare our results with state-of-the-art methods based on the EER metric in the stolen-key scenario. Genuine and impostor distributions have also been used for performance and security assessment of the proposed method. Moreover, we demonstrate the robustness of the proposed approach against brute force attacks.
C1 [Djebli, Hamza; Ait-Aoudia, Samy] Ecole Natl Super Informat, Lab LMCS, Algiers, Algeria.
   [Michelucci, Dominique] Univ Bourgogne, Lab LiB, Dijon, France.
C3 Ecole Nationale Superieure d'Informatique; Universite de Bourgogne
RP Djebli, H (corresponding author), Ecole Natl Super Informat, Lab LMCS, Algiers, Algeria.
EM h_djebli@esi.dz
OI Djebli, Hamza/0000-0002-9328-9186
CR Ahmad T, 2011, PATTERN RECOGN, V44, P2555, DOI 10.1016/j.patcog.2011.03.015
   Ajish S, 2020, COMPUT SECUR, V90, DOI 10.1016/j.cose.2020.101714
   Ali SS, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104004
   Ali SS, 2020, PATTERN RECOGN LETT, V129, P263, DOI 10.1016/j.patrec.2019.11.037
   Ali SS, 2018, IET BIOMETRICS, V7, P536, DOI 10.1049/iet-bmt.2018.5070
   [Anonymous], 2011, 24745 ISOIEC
   [Anonymous], 2014, P 31 INT C MACH LEAR
   Atighehchi K, 2019, FUTURE GENER COMP SY, V101, P819, DOI 10.1016/j.future.2019.07.022
   Belguechi R., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1168, DOI 10.1109/ICPR.2010.292
   Cavoukian A., 2007, Biometr Technol Today, V15, P11, DOI DOI 10.1016/S0969-4765(07)70084-X
   Chikkerur S., 2008, 2nd IEEE International Conference on Biometrics: Theory, Applications and Systems, P1
   Dasgupta S, 2003, RANDOM STRUCT ALGOR, V22, P60, DOI 10.1002/rsa.10073
   DEMMEL JW, 1993, SIAM J MATRIX ANAL A, V14, P1, DOI 10.1137/0614001
   Diephuis M, 2011, INT SYMP IMAGE SIG, P460
   Djebli H, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE (ICPRAI 2018), P350
   Feng Q, 2008, ISCSCT 2008: INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND COMPUTATIONAL TECHNOLOGY, VOL 2, PROCEEDINGS, P572, DOI 10.1109/ISCSCT.2008.226
   Feng YC, 2008, PROC SPIE, V6944, DOI 10.1117/12.778652
   Gedalia Razafindrobelina Nabe, 2020, 2020 International Seminar on Application for Technology of Information and Communication (iSemantic), P286, DOI 10.1109/iSemantic50169.2020.9234192
   Hämmerle-Uhl J, 2009, LECT NOTES COMPUT SC, V5735, P135, DOI 10.1007/978-3-642-04474-8_11
   Jacob IJ, 2021, MULTIMED TOOLS APPL, V80, P7547, DOI 10.1007/s11042-020-10127-w
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jin ATB, 2004, PATTERN RECOGN, V37, P2245, DOI 10.1016/j.patcog.2004.04.011
   Jin Z, 2014, PATTERN RECOGN LETT, V42, P137, DOI 10.1016/j.patrec.2014.02.011
   Jin Z, 2012, EXPERT SYST APPL, V39, P6157, DOI 10.1016/j.eswa.2011.11.091
   KARIMOVICH GS, 2016, INF SCI COMM TECHN I, P1
   Kaur H, 2019, PATTERN RECOGN LETT, V126, P31, DOI 10.1016/j.patrec.2018.02.016
   Kaur H, 2016, MULTIMED TOOLS APPL, V75, P16333, DOI 10.1007/s11042-015-2933-6
   Khan SH, 2015, PATTERN RECOGN, V48, P458, DOI 10.1016/j.patcog.2014.08.024
   Kho JB, 2019, PATTERN RECOGN, V91, P245, DOI 10.1016/j.patcog.2019.01.039
   Khodadoust J, 2021, EXPERT SYST APPL, V176, DOI 10.1016/j.eswa.2021.114687
   Koval O, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P177, DOI 10.1145/1411328.1411359
   Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144
   Manisha, 2020, ARTIF INTELL REV, V53, P3403, DOI 10.1007/s10462-019-09767-8
   Mehmood R, 2020, INT ARAB J INF TECHN, V17, P926, DOI 10.34028/iajit/17/6/11
   neurotechnology, NEUROTECHNOLOGY VERI
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P54, DOI 10.1109/MSP.2015.2434151
   Pillai JK, 2010, INT CONF ACOUST SPEE, P1838, DOI 10.1109/ICASSP.2010.5495383
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Sandhya M, 2017, IET BIOMETRICS, V6, P173, DOI 10.1049/iet-bmt.2016.0008
   Sandhya M, 2016, IET BIOMETRICS, V5, P131, DOI 10.1049/iet-bmt.2015.0034
   Sandhya M, 2015, INT CONF BIOMETR, P386, DOI 10.1109/ICB.2015.7139100
   Sarkar A, 2020, MULTIMED TOOLS APPL, V79, P27721, DOI 10.1007/s11042-020-09197-7
   Sehar Eain Ul, 2021, 2021 Fourth International Conference on Computational Intelligence and Communication Technologies (CCICT), P260, DOI 10.1109/CCICT53244.2021.00056
   Sharma Pratima, 2020, Proceedings of the 2020 9th International Conference System Modeling and Advancement in Research Trends (SMART), P137, DOI 10.1109/SMART50582.2020.9337107
   Teoh ABJ, 2007, IEEE T SYST MAN CY B, V37, P1096, DOI 10.1109/TSMCB.2007.903538
   Trivedi AK, 2020, COMPUT SECUR, V90, DOI 10.1016/j.cose.2019.101690
   Wang S, 2017, PATTERN RECOGN, V66, P295, DOI 10.1016/j.patcog.2017.01.019
   Wang S, 2016, PATTERN RECOGN, V54, P14, DOI 10.1016/j.patcog.2016.01.001
   Wang S, 2014, PATTERN RECOGN, V47, P1321, DOI 10.1016/j.patcog.2013.10.003
   Weinzaepfel P, 2011, PROC CVPR IEEE, P337, DOI 10.1109/CVPR.2011.5995616
   Wong WJ, 2013, PATTERN RECOGN LETT, V34, P1221, DOI 10.1016/j.patrec.2013.03.039
   Yang GH, 2010, INT CONF SMART GRID, P1, DOI 10.1109/SMARTGRID.2010.5622001
NR 53
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7917
EP 7937
DI 10.1007/s11042-022-13646-w
EA AUG 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000840595400002
DA 2024-07-18
ER

PT J
AU Asbai, N
   Zitouni, S
   Bounazou, H
   Yahi, A
AF Asbai, Nassim
   Zitouni, Sihem
   Bounazou, Hadjer
   Yahi, Amina
TI Noisy speech enhancement based on correlation canceling/log-MMSE hybrid
   method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech enhancement; Log-MMSE estimator; Noise estimation; Correlation
   canceling approach; Orthogonal projection
ID ALGORITHM
AB In this paper, a speech enhancement method based on correlation canceling approach associated with the Log- minimum mean-square-error estimator is presented. Unlike the conventional statistical-model methods based on the nonlinear estimation of the enhanced speech signal, such as Maximum-Likelihood estimator (ML), Maximum A Posteriori (MAP) estimator, Minimum Mean Square Error (MMSE) estimator and log MMSE estimator, in the proposed hybrid method (CC/Log-MMSE), the nonlinear estimation is transformed into a linear estimation by exploiting the orthogonal projection of clean signal into the noisy signal. Thus, the enhanced signal represents the best "copy," or estimate, of clean signal that can be made on the basis of the noisy signal vector. This is also seen as a canceling of the component of the noisy vector residing in the noise subspace, which therefore leads to improve the intelligibility of the enhanced signal. Extensive simulations are carried out using speech files corrupted by different noises available in the NOIZEUS corpus, show that the proposed hybrid method CC/Log-MMSE consistently outperforms the baseline methods of speech enhancement at different levels of SNR in terms of objective and subjective measures, spectrogram analysis and the overall SNR improvement.
C1 [Asbai, Nassim] USTHB, Fac Elect & Comp Sci, Speech Com & Signal Proc Lab, Bab Ezzouar 16111, Algeria.
   [Asbai, Nassim; Bounazou, Hadjer; Yahi, Amina] Mohamed El Bachir El Ibrahimi Univ, Fac Sci & Technol, Dept Elect, Bordj Bou Arreridj 34030, Algeria.
   [Zitouni, Sihem] Mohamed El Bachir El Ibrahimi Univ, Dept Comp Sci, Fac Math & Comp Sci, Bordj Bou Arreridj 34030, Algeria.
C3 University Science & Technology Houari Boumediene
RP Asbai, N (corresponding author), USTHB, Fac Elect & Comp Sci, Speech Com & Signal Proc Lab, Bab Ezzouar 16111, Algeria.; Asbai, N (corresponding author), Mohamed El Bachir El Ibrahimi Univ, Fac Sci & Technol, Dept Elect, Bordj Bou Arreridj 34030, Algeria.
EM asbainassim@gmail.com
CR Akbacak M, 2007, IEEE T AUDIO SPEECH, V15, P465, DOI 10.1109/TASL.2006.881694
   de Reyna JA, 2019, RAMANUJAN J, V50, P551, DOI 10.1007/s11139-018-0084-x
   Asbai N, 2017, COMPUT ELECTR ENG, V62, P648, DOI 10.1016/j.compeleceng.2017.03.022
   Bahrami M, 2018, IRAN CONF ELECTR ENG, P749, DOI 10.1109/ICEE.2018.8472626
   Bbeach JT, 2014, US PATENT, P660
   Cohen I, 2003, IEEE T SPEECH AUDI P, V11, P466, DOI 10.1109/TSA.2003.811544
   Cohen I, 2002, IEEE SIGNAL PROC LET, V9, P12, DOI 10.1109/97.988717
   Cohen I, 2001, SIGNAL PROCESS, V81, P2403, DOI 10.1016/S0165-1684(01)00128-1
   EPHRAIM Y, 1985, IEEE T ACOUST SPEECH, V33, P443, DOI 10.1109/TASSP.1985.1164550
   Hirsch Hans-Gunter, 2000, ASR2000 AUT SPEECH R
   Hu Y, NOIZEUS NOISY SPEECH
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054
   Hu Y, 2006, INT CONF ACOUST SPEE, P153
   ITU-T, 2001, PERC EV SPEECH QUAL, P862
   ITU-T Rec. P.835, 2003, ITU-T Recommendation G.114
   Ju GH, 2002, 7 INT C SPOKEN LANGU
   Junqua Jean-Claude., 1996, Robustness in Automatic Speech Recognition
   Kates J.M., 2008, Digital Hearing Aids
   Kenai O, 2019, INT J SPEECH TECHNOL, V22, P827, DOI 10.1007/s10772-019-09625-6
   Lee GW, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093230
   Loizou Philipos C, 2013, SPEECH ENHANCEMENT T, DOI 10.1201/b14529
   Malah D, 1999, INT CONF ACOUST SPEE, P789, DOI 10.1109/ICASSP.1999.759789
   Martin R, 2001, IEEE T SPEECH AUDI P, V9, P504, DOI 10.1109/89.928915
   Poularikas A. D., 2018, HDB FORMULAS TABLES
   Rangachari S, 2006, SPEECH COMMUN, V48, P220, DOI 10.1016/j.specom.2005.08.005
   Sharma RR, 2018, CIRC SYST SIGNAL PR, V37, P3313, DOI 10.1007/s00034-018-0834-4
   Sophocles JO, 2018, OPTIMUM SIGNAL PROCE, P392
   Vondrásek M, 2005, RADIOENGINEERING, V14, P6
   Wang HK, 2018, INT WORKSH ACOUSTIC, P456, DOI 10.1109/IWAENC.2018.8521410
NR 29
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5803
EP 5821
DI 10.1007/s11042-022-13591-8
EA AUG 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000834736500011
DA 2024-07-18
ER

PT J
AU Liu, DW
   Yu, JY
AF Liu, Dawei
   Yu, Jinyang
TI Explicating reader behavior toward adoption of multi-screen devices:
   combination of TAM and HLM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-screen; Ubiquitous systems; Context-aware; Hierarchical linear
   model; Technology acceptance model; Social influence
ID WORD-OF-MOUTH; SOCIAL COMMERCE; CONTEXT-AWARE; PURCHASE INTENTION;
   NETWORK STRUCTURE; MOBILE COMMERCE; CONSUMER TRUST; S-COMMERCE; ONLINE;
   SATISFACTION
AB This paper present and discussed a multilevel analysis of digital reading acceptance intention and behavior. It aims to develop and extend the existing Technology Acceptance Model into digital reading products purchase behaviors by proposing, operationalizing, and testing emerging variables. The study utilized a survey approach to gathering data regarding consumers' acceptance intention of digital reading products. Surveys were administered to 359 respondents from mobile readers. A hierarchical linear model was adopted to test the hypotheses generated from the model. Results show that perceived social benefit and trust affect acceptance of digital reading products and that ubiquitous connection and familiarity as antecedents of social benefit with a significant influence. The finding is a theoretical supplement of the acceptance behavior of multi-screen reading devices. The finding on consumer behavior analysis indicated that trust was outperformed by social influence in the mediating process at all levels and these differences were statistically significant. This study strongly endorses the view that the acceptance of mobile readers is linked to the extent of the context-aware and ubiquitous connection.
C1 [Liu, Dawei] Ningbo Univ Finance & Econ, Sch Business, 899 Xueyuan Rood, Ningbo 315174, Peoples R China.
   [Yu, Jinyang] Hangzhou Dianzi Univ, Sch Management, Hangzhou, Peoples R China.
C3 Ningbo University of Finance & Economics; Hangzhou Dianzi University
RP Liu, DW (corresponding author), Ningbo Univ Finance & Econ, Sch Business, 899 Xueyuan Rood, Ningbo 315174, Peoples R China.
EM hduldw@163.com
RI Liu, Dawei/AAD-3130-2019
FU Natural Science Foundation of Zhejiang Province [LY19G020014]
FX The paper was financially supported by the Natural Science Foundation of
   Zhejiang Province (LY19G020014).
CR Al-Maroof RAS, 2018, INT J EMERG TECHNOL, V13, P112, DOI 10.3991/ijet.v13i06.8275
   Alikilic O, 2012, PUBLIC RELAT REV, V38, P56, DOI 10.1016/j.pubrev.2011.11.002
   Ameer IS, 2013, PROCD SOC BEHV, V90, P187, DOI 10.1016/j.sbspro.2013.07.081
   Arts JWC, 2011, INT J RES MARK, V28, P134, DOI 10.1016/j.ijresmar.2010.11.002
   Bahmanziari Tammy, 2009, International Journal of Accounting Information Systems, V10, P152, DOI 10.1016/j.accinf.2008.11.001
   Baltrunas L, 2012, PERS UBIQUIT COMPUT, V16, P507, DOI 10.1007/s00779-011-0417-x
   Baptista G, 2015, COMPUT HUM BEHAV, V50, P418, DOI 10.1016/j.chb.2015.04.024
   Bauer HH, 2006, J BUS RES, V59, P866, DOI 10.1016/j.jbusres.2006.01.021
   Baumgartner H., 1996, INT J RES MARK, V13, P139, DOI [10.1016/0167-8116(95)00038-0, DOI 10.1016/0167-8116(95)00038-0]
   Bianchi C, 2012, INT MARKET REV, V29, P253, DOI 10.1108/02651331211229750
   Casaló LV, 2013, J BUS RES, V66, P706, DOI 10.1016/j.jbusres.2011.09.007
   Chakravarty A, 2010, J INTERACT MARK, V24, P185, DOI 10.1016/j.intmar.2010.04.001
   Chen CW, 2020, INT J HUM-COMPUT INT, V36, P1178, DOI 10.1080/10447318.2020.1726106
   Chong AYL, 2013, EXPERT SYST APPL, V40, P523, DOI 10.1016/j.eswa.2012.07.068
   Davis L, 2012, J RETAIL CONSUM SERV, V19, P229, DOI 10.1016/j.jretconser.2012.01.004
   Dong W.Y, 2014, J JIAXING U, V26, P136
   Ecker UKH, 2007, INT J PSYCHOPHYSIOL, V64, P146, DOI 10.1016/j.ijpsycho.2007.01.005
   Fang YH, 2014, INT J ELECTRON COMM, V18, P67, DOI 10.2753/JEC1086-4415180303
   Gallego D, 2012, 2012 THIRD FTRA INTERNATIONAL CONFERENCE ON MOBILE, UBIQUITOUS, AND INTELLIGENT COMPUTING (MUSIC), P13, DOI 10.1109/MUSIC.2012.11
   Gao HX, 2014, ELECTRON MARK, V24, P67, DOI 10.1007/s12525-013-0142-6
   Gao LL, 2015, COMPUT HUM BEHAV, V53, P249, DOI 10.1016/j.chb.2015.07.014
   Gefen D, 2003, MIS QUART, V27, P51, DOI 10.2307/30036519
   Gronli TM, 2014, PERS UBIQUIT COMPUT, V18, P883, DOI 10.1007/s00779-013-0698-3
   Ha HY, 2012, INT J CONSUM STUD, V36, P327, DOI 10.1111/j.1470-6431.2011.01035.x
   Hansen H, 2008, IND MARKET MANAG, V37, P206, DOI 10.1016/j.indmarman.2006.09.001
   Herbig P., 1997, PRICING STRATEGY PRA, V5, P25
   Hill WW, 2013, J SERV MARK, V27, P347, DOI 10.1108/JSM-10-2011-0157
   Hsu HH, 2014, PERS UBIQUIT COMPUT, V18, P259, DOI 10.1007/s00779-013-0642-6
   Hung KH, 2007, J ADVERTISING RES, V47, P485, DOI 10.2501/S002184990707050X
   Hyman JA, 2014, ETR&D-EDUC TECH RES, V62, P35, DOI 10.1007/s11423-013-9330-5
   Khalifa M, 2012, J COMPUT INFORM SYST, V53, P14
   Khan A, 2016, ELECTRON LIBR, V34, P958, DOI 10.1108/EL-08-2015-0163
   Kim DJ, 2012, INF SYST E-BUS MANAG, V10, P219, DOI 10.1007/s10257-010-0136-2
   Kim DJ, 2009, INFORM SYST RES, V20, P237, DOI 10.1287/isre.1080.0188
   Kim D, 2013, ELECTRON COMMER R A, V12, P69, DOI 10.1016/j.elerap.2012.12.002
   Kim JB, 2012, ELECTRON COMMER RES, V12, P125, DOI 10.1007/s10660-012-9089-5
   Kim J, 2009, J RETAIL CONSUM SERV, V16, P239, DOI 10.1016/j.jretconser.2008.11.019
   Kim MJ, 2011, TOURISM MANAGE, V32, P256, DOI 10.1016/j.tourman.2010.01.011
   Kim S, 2013, INT J INFORM MANAGE, V33, P318, DOI 10.1016/j.ijinfomgt.2012.11.006
   Kurkovsky S, 2006, PERS UBIQUIT COMPUT, V10, P227, DOI 10.1007/s00779-005-0044-5
   Landeta J, 2006, TECHNOL FORECAST SOC, V73, P467, DOI 10.1016/j.techfore.2005.09.002
   Lee HC, 2013, SERV BUS, V7, P713, DOI 10.1007/s11628-013-0203-0
   Lee T., 2005, J ELECTRON COMMER RE, V6, P165, DOI [DOI 10.1145/1964921.1964953, 10.1145/1964921.1964953]
   Lee Y, 2011, ELECTRON COMMER R A, V10, P342, DOI 10.1016/j.elerap.2010.11.005
   Leek S, 2011, IND MARKET MANAG, V40, P1060, DOI 10.1016/j.indmarman.2011.09.019
   Li YM, 2013, DECIS SUPPORT SYST, V55, P740, DOI 10.1016/j.dss.2013.02.009
   Lin YC, 2013, INT J CONTEMP HOSP M, V25, P346, DOI 10.1108/09596111311311017
   Liu CL, 2011, J RETAIL CONSUM SERV, V18, P101, DOI 10.1016/j.jretconser.2010.10.004
   Liu HJ, 2012, NEURAL NETW WORLD, V22, P549, DOI 10.14311/NNW.2012.22.034
   Liu X, 2013, ELECTRON COMMER R A, V12, P24, DOI 10.1016/j.elerap.2012.07.001
   Lu XB, 2008, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON PRODUCT INNOVATION MANAGEMENT, VOLS I AND II, P685
   Lu YB, 2010, ELECTRON COMMER R A, V9, P346, DOI 10.1016/j.elerap.2009.07.003
   Malhotra NK, 2006, MANAGE SCI, V52, P1865, DOI 10.1287/mnsc.1060.0597
   Mayrhofer R, 2014, PERS UBIQUIT COMPUT, V18, P115, DOI 10.1007/s00779-012-0630-2
   McCorkindale T, 2013, PUBLIC RELAT REV, V39, P193, DOI 10.1016/j.pubrev.2013.03.008
   McDonnell MH, 2013, ADMIN SCI QUART, V58, P387, DOI 10.1177/0001839213500032
   Ng CSP, 2013, INFORM MANAGE-AMSTER, V50, P609, DOI 10.1016/j.im.2013.08.002
   Ngai EWT, 2007, DECIS SUPPORT SYST, V43, P3, DOI 10.1016/j.dss.2005.05.003
   Noh M, 2013, J ELECTRON COMMER RE, V14, P244
   Okazaki S, 2008, J COMPUT-MEDIAT COMM, V13, P827, DOI 10.1111/j.1083-6101.2008.00421.x
   Pagani M, 2011, INT J ELECTRON COMM, V16, P41, DOI 10.2753/JEC1086-4415160203
   Pallapa G, 2014, PERVASIVE MOB COMPUT, V12, P232, DOI 10.1016/j.pmcj.2013.12.004
   Panniello U, 2016, INFORM SYST RES, V27, P182, DOI 10.1287/isre.2015.0610
   Panniello U, 2014, USER MODEL USER-ADAP, V24, P35, DOI 10.1007/s11257-012-9135-y
   Park J, 2014, J BUS RES, V67, P295, DOI 10.1016/j.jbusres.2013.05.016
   Pavelka J, 2014, PROCD SOC BEHV, V139, P87, DOI 10.1016/j.sbspro.2014.08.031
   Pavlou PA, 2006, MIS QUART, V30, P115
   Premazzi K, 2010, J RETAIL CONSUM SERV, V17, P229, DOI 10.1016/j.jretconser.2010.03.006
   Ratcliffe M., 2002, Phenomenology and the Cognitive Sciences, V1, P287, DOI 10.1023/A:1021312100964
   Raus M, 2010, GOV INFORM Q, V27, P122, DOI 10.1016/j.giq.2009.04.007
   Martín HS, 2012, TOURISM MANAGE, V33, P341, DOI 10.1016/j.tourman.2011.04.003
   Shafiq R, 2011, AFR J BUS MANAGE, V5, P10577, DOI 10.5897/AJBM10.1088
   Shankar V, 2003, INT J RES MARK, V20, P153, DOI 10.1016/S0167-8116(03)00016-8
   Shi YN, 2013, INT J INFORM MANAGE, V33, P419, DOI 10.1016/j.ijinfomgt.2013.02.001
   Shin DH, 2017, INTERNET RES, V27, P338, DOI 10.1108/IntR-12-2015-0334
   Sohn D, 2014, COMPUT HUM BEHAV, V32, P145, DOI 10.1016/j.chb.2013.12.006
   Sotiriadis MD, 2013, ELECTRON COMMER RES, V13, P103, DOI 10.1007/s10660-013-9108-1
   Steenhaut S, 2006, J BUS ETHICS, V64, P137, DOI 10.1007/s10551-005-5905-3
   Tanyeli N, 2009, PROCD SOC BEHV, V1, P564, DOI 10.1016/j.sbspro.2009.01.102
   Teo T, 2011, COMPUT EDUC, V57, P1645, DOI 10.1016/j.compedu.2011.03.002
   Tsai YC, 2010, AFR J BUS MANAGE, V4, P4057
   Valvi AC, 2013, J ELECTRON COMMER RE, V14, P99
   Vázquez-Carrasco R, 2006, J RETAIL CONSUM SERV, V13, P205, DOI 10.1016/j.jretconser.2005.08.006
   Veloutsou C, 2009, J BUS RES, V62, P314, DOI 10.1016/j.jbusres.2008.05.010
   Venkatesh V, 2000, INT J HUM-COMPUT ST, V52, P991, DOI 10.1006/ijhc.1999.0367
   Vossen G, 2009, WINSYS 2009: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON WIRELESS INFORMATION NETWORKS AND SYSTEMS, pIS33
   Wang F, 2017, ADV SOC SCI EDUC HUM, V117, P294
   Wang YD, 2005, COMPUT HUM BEHAV, V21, P105, DOI 10.1016/j.chb.2003.11.008
   Weilenmann A, 2014, PERS UBIQUIT COMPUT, V18, P737, DOI 10.1007/s00779-013-0703-x
   Williams CC, 2014, J BUS RES, V67, P802, DOI 10.1016/j.jbusres.2013.11.048
   Ya-Wen Y, 2010, 2010 PORTL INT C MAN
   Yadav MS, 2013, J INTERACT MARK, V27, P311, DOI 10.1016/j.intmar.2013.09.001
   Yan Z, 2013, PERS UBIQUIT COMPUT, V17, P1295, DOI 10.1007/s00779-013-0636-4
   Yang FX, 2017, J HOSP TOUR RES, V41, P93, DOI 10.1177/1096348013515918
   Yen NY, 2013, PERS UBIQUIT COMPUT, V17, P1731, DOI 10.1007/s00779-012-0607-1
   Yoganarasimhan H, 2012, QME-QUANT MARK ECON, V10, P111, DOI 10.1007/s11129-011-9105-4
   Yurdugül H, 2013, EGIT BILIM, V38, P391
   Zhang H, 2014, INFORM MANAGE-AMSTER, V51, P1017, DOI 10.1016/j.im.2014.07.005
   Zhang LY, 2011, LIBR HI TECH, V29, P424, DOI 10.1108/07378831111174396
   Zhang YN, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/6043769
   Zheng XL, 2013, DECIS SUPPORT SYST, V56, P211, DOI 10.1016/j.dss.2013.06.002
   Zhou LN, 2013, ELECTRON COMMER R A, V12, P61, DOI 10.1016/j.elerap.2013.02.003
   남수태, 2018, [Journal of the Korea Institute Of Information and Communication Engineering, 한국정보통신학회논문지], V22, P978
NR 103
TC 0
Z9 1
U1 5
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4479
EP 4496
DI 10.1007/s11042-022-13576-7
EA JUL 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000832844000010
DA 2024-07-18
ER

PT J
AU Yadav, K
   Tiwari, S
   Jain, A
   Alshudukhi, J
AF Yadav, Kusum
   Tiwari, Shamik
   Jain, Anurag
   Alshudukhi, Jalawi
TI Convolution neural network based model to classify colon cancerous
   tissue
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cancerous tissue; Deep learning; Convolution neural network; Activation
   function
ID STATISTICS
AB Computer vision-based methods play a significant role in the recognition of cancerous tissue from histopathological images. Therefore, computer-assisted diagnosis systems provide an effective system for medical diagnosis. At the same time, conventional medical image processing methods rely on feature extraction algorithms suited for a particular problem. However, deep learning-based methods are becoming vital alternatives with new developments in the machine learning area to reduce the complications of the feature-based methods. Therefore, a Convolutional Neural Network-based model has been proposed to categorize colon cancer histopathological images having multiple classes of cancerous tissues. Eight different classes of cancer have been examined, namely tumor epithelium, simple stroma, immune cells, complex stroma, normal mucosal glands, debris, adipose tissue, and background. The Convolution Neural Network (ConvNet) classification model is evaluated with four distinct activation layers, namely Rectified Linear Unit (ReLU), Leaky Rectified Linear Unit (LReLU), Parametrized Rectified Linear Unit (PReLU), and Exponential Linear Unit (ELU). Based on the produced results, the ELU activation function has shown the highest classification accuracy with on average 98% and in some cases 99%.
C1 [Yadav, Kusum; Alshudukhi, Jalawi] Univ Hail, Coll Comp Sci & Engn, Comp Sci & Informat Syst, Hail, Saudi Arabia.
   [Tiwari, Shamik; Jain, Anurag] Univ Petr & Energy Studies, Sch Comp Sci, Dehra Dun 248007, Uttarakhand, India.
C3 University Ha'il; University of Petroleum & Energy Studies (UPES)
RP Tiwari, S (corresponding author), Univ Petr & Energy Studies, Sch Comp Sci, Dehra Dun 248007, Uttarakhand, India.
EM shamik.tiwari@ddn.upes.ac.in
RI tiwari, shamik/AAO-2551-2021; Yadav, Kusum/AAR-2008-2021; Alshudukhi,
   Jalawi/S-9016-2018
OI Yadav, Kusum/0000-0002-6658-6839; Alshudukhi, Jalawi/0000-0003-0619-0020
CR [Anonymous], 2014, ARXIV
   Berner J, 2019, ARXIV
   Brouwer NPM, 2020, ANN SURG ONCOL, V27, P1580, DOI 10.1245/s10434-019-08100-5
   Damodharan S, 2015, INT ARAB J INF TECHN, V12, P42
   Debelee TG, 2020, EVOL SYST-GER, V11, P143, DOI 10.1007/s12530-019-09297-2
   Eckle K, 2019, NEURAL NETWORKS, V110, P232, DOI 10.1016/j.neunet.2018.11.005
   Jain A., 2019, International Journal of Control and Automation, V12, P558
   Kather JN, 2016, SCI REP-UK, V6, DOI 10.1038/srep27988
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Mukhopadhyay S, 2018, PROC SPIE, V10501, DOI 10.1117/12.2291485
   Niu MK, 2020, ANN TRANSL MED, V8, DOI 10.21037/atm-20-4428
   Pavel MI, 2017, THESIS BRAC U
   Powers D.M., 2020, arXiv
   Rodriguez JH, 2016, P 4 INT C TECHN EC E, P517
   Setzer FC, 2020, J ENDODONT, V46, P987, DOI 10.1016/j.joen.2020.03.025
   Shang WL, 2016, PR MACH LEARN RES, V48
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Siegel RL, 2017, CA-CANCER J CLIN, V67, P177, DOI [DOI 10.3322/CAAC.21395, 10.3322/caac.21395]
   Su HH, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164409
   Thurmaier J, 2021, INT J CANCER, V148, P1919, DOI 10.1002/ijc.33364
   Tiwari S., 2017, INDONESIAN J ELECT E, V5, P162
   Tiwari S, 2021, IEEE ACCESS, V9, P110710, DOI 10.1109/ACCESS.2021.3103316
   Tiwari S, 2021, INT J IMAG SYST TECH, V31, P525, DOI 10.1002/ima.22566
   Tiwari S, 2018, INT J INF SYST MODEL, V9, DOI 10.4018/IJISMD.2018100101
   Xu B., 2015, ARXIV
   Xu Y, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1685-x
   Ye JP, 2004, IEEE ACM T COMPUT BI, V1, P181, DOI 10.1109/TCBB.2004.45
NR 27
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37461
EP 37476
DI 10.1007/s11042-022-13504-9
EA JUL 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000832844000007
DA 2024-07-18
ER

PT J
AU Si, WJ
   Wan, CX
   Deng, ZA
AF Si, Weijian
   Wan, Chenxia
   Deng, Zhian
TI An efficient deep convolutional neural network with features fusion for
   radar signal recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Radar signal recognition; Convolutional neural network; Features fusion;
   Signal to noise ratio; Recognition accuracy
ID AUTOMATIC MODULATION CLASSIFICATION
AB This paper proposes an efficient deep convolutional neural network with features fusion for recognizing radar signal, which mainly includes data pre-processing, features extraction, multi-features fusion, and classification. Radar signals are first transformed into time-frequency images by using choi-williams distribution and smooth pseudo-wigner-ville distribution, and the image pre-processing methods are used to resize and normalize the time-frequency images. Then, two constructed deep convolutional neural network models are aimed to extract more effective features. Furthermore, a multi-features fusion model is proposed to integrate features extracted from two deep convolutional neural network models, which makes full use of the relationship among different features and further improves the recognition performance. Experimental results shown that the average recognition accuracy of the proposed method is up to 84.38% when the signal to noise ratio is at -12 dB, and even reach to 94.31% at -10 dB, which achieved the superior recognition performance than others, especially at the lower signal to noise ratio. Moreover, the recognition performance of various radar signals can be largely improved, especially for 2FSK, 4FSK and SFM. This work provides a sound experimental foundation for further improving radar signal recognition in modern electronic warfare systems.
C1 [Si, Weijian; Wan, Chenxia; Deng, Zhian] Harbin Engn Univ, Coll Informat & Commun Engn, Harbin 150001, Peoples R China.
   [Si, Weijian; Wan, Chenxia; Deng, Zhian] Harbin Engn Univ, Key Lab Adv Marine Commun & Informat Technol, Minist Ind & Informat Technol, Harbin 150001, Peoples R China.
C3 Harbin Engineering University; Harbin Engineering University
RP Deng, ZA (corresponding author), Harbin Engn Univ, Coll Informat & Commun Engn, Harbin 150001, Peoples R China.; Deng, ZA (corresponding author), Harbin Engn Univ, Key Lab Adv Marine Commun & Informat Technol, Minist Ind & Informat Technol, Harbin 150001, Peoples R China.
EM dengzhian@hrbeu.edu.cn
FU National Natural Science Foundation of China [61671168, 61801143];
   National Natural Science Foundation of Heilongjiang Province
   [JJ2019LH1760, LH2020F019]; Aeronautical Science Foundation of China
   [2019010P6001, 2019010P6002]; Fundamental Research Funds for the Central
   Universities [HEUCFJ180801]
FX This work was financially supported in part by the National Natural
   Science Foundation of China (Grant No. 61671168 and 61801143), in part
   by the National Natural Science Foundation of Heilongjiang Province
   (Grant No. JJ2019LH1760 and LH2020F019), in part by the Aeronautical
   Science Foundation of China (Grant No. 2019010P6001 and 2019010P6002),
   and in part by the Fundamental Research Funds for the Central
   Universities (Grant No. HEUCFJ180801).
CR Ayazgok S, 2018, IET RADAR SONAR NAV, V12, P466, DOI 10.1049/iet-rsn.2017.0354
   Bu K, 2020, IEEE SIGNAL PROC LET, V27, P880, DOI 10.1109/LSP.2020.2991875
   Cao R, 2019, MULTIMED TOOLS APPL, V78, P28953, DOI 10.1007/s11042-018-6134-y
   Fan XL, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.035018
   Feng ZP, 2013, MECH SYST SIGNAL PR, V38, P165, DOI 10.1016/j.ymssp.2013.01.017
   Han LB, 2017, IEEE T WIREL COMMUN, V16, P400, DOI 10.1109/TWC.2016.2623716
   Hazar MA, 2018, NEURAL COMPUT APPL, V29, P351, DOI 10.1007/s00521-017-3040-6
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Huang S, 2017, IEEE T VEH TECHNOL, V66, P6089, DOI 10.1109/TVT.2016.2636324
   Kingma D. P., 2015, PROC INT C LEARN REP, P1
   Kishore TR, 2017, IEEE T AERO ELEC SYS, V53, P901, DOI 10.1109/TAES.2017.2667142
   Li DJ, 2020, IET RADAR SONAR NAV, V14, P782, DOI 10.1049/iet-rsn.2019.0550
   Hoang LM, 2019, IEEE T SIGNAL PROCES, V67, P3516, DOI 10.1109/TSP.2019.2918983
   Liu SK, 2018, IEEE T CIRCUITS-II, V65, P2062, DOI 10.1109/TCSII.2018.2819666
   Liu YJ, 2015, J SYST ENG ELECTRON, V26, P973, DOI 10.1109/JSEE.2015.00106
   Ma N, 2013, J SYST ENG ELECTRON, V24, P919, DOI 10.1109/JSEE.2013.00107
   Meng F, 2018, IEEE T VEH TECHNOL, V67, P10760, DOI 10.1109/TVT.2018.2868698
   Qin ZJ, 2020, IEEE T COGN COMMUN, V6, P6, DOI 10.1109/TCCN.2019.2949279
   Qu QZ, 2020, IEEE COMMUN LETT, V24, P1729, DOI 10.1109/LCOMM.2020.2992266
   Qu ZY, 2020, IEEE ACCESS, V8, P49125, DOI 10.1109/ACCESS.2020.2980363
   Qu ZY, 2019, IEEE ACCESS, V7, P112339, DOI 10.1109/ACCESS.2019.2935247
   Qu ZY, 2018, IEEE ACCESS, V6, P43874, DOI 10.1109/ACCESS.2018.2864347
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shao GQ, 2020, IEEE ACCESS, V8, P117236, DOI 10.1109/ACCESS.2020.3004188
   Si WJ, 2021, MULTIMED TOOLS APPL, V80, P1779, DOI 10.1007/s11042-020-09490-5
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wei W, 2000, IEEE T COMMUN, V48, P189, DOI 10.1109/26.823550
   Wu ZL, 2017, IEEE ACCESS, V5, P19733, DOI 10.1109/ACCESS.2017.2746140
   Zhang HJ, 2016, IEEE SIGNAL PROC LET, V23, P139, DOI 10.1109/LSP.2015.2504565
   Zhang ZF, 2019, IEEE T SIGNAL INF PR, V5, P469, DOI 10.1109/TSIPN.2019.2900201
NR 30
TC 3
Z9 3
U1 2
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2871
EP 2885
DI 10.1007/s11042-022-13407-9
EA JUL 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000825738000001
DA 2024-07-18
ER

PT J
AU Paul, S
   Mishra, D
AF Paul, Subhajit
   Mishra, Deepak
TI Hiding images within audio using deep generative model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio steganography; Image hiding; Deep generative model;
   Mel-spectrogram; Residual connection
AB Image steganography is a procedure of hiding any messages within an image. In this paper, our major goal is to conceal images within audio, and we converted this audio steganography problem to image steganography by utilizing the mel-spectrogram of the audio files as the cover medium. Previously, this audio steganography problem was implemented using statistical methods like least significant bit (LSB) encoding. Here we explore the use of deep neural networks (DNNs), and we propose a new technique to hide images within the audio using deep generative models which allow us to optimize the perceptual quality of the reconstructed audio and image by our model. We showed that our model efficiently hides images within audio and evades detection by steganalysis tools, is robust to different color spectrum images, and can hide multiple image data in single audio.
C1 [Paul, Subhajit; Mishra, Deepak] Indian Inst Space Sci & Technol IIST, Dept Avion, Elect & Commun Engn, Trivandrum 695547, Kerala, India.
C3 Department of Space (DoS), Government of India; Indian Institute of
   Space Science & Technology
RP Paul, S (corresponding author), Indian Inst Space Sci & Technol IIST, Dept Avion, Elect & Commun Engn, Trivandrum 695547, Kerala, India.
EM subhajitpaul27998@gmail.com; deepak.mishra@iist.ac.in
CR ALLEN JB, 1977, P IEEE, V65, P1558, DOI 10.1109/PROC.1977.10770
   Almohammad A., 2010, 2 INT C IMAGE PROCES, P215
   [Anonymous], 2016, CoRR
   Asad M., 2011, Proceedings of the 1st International Conference on Computer Networks and Information Technology (ICCNIT 2011), P143, DOI 10.1109/ICCNIT.2011.6020921
   Balgurgi P P, 2012, P 2012 INT C COMM IN, P1, DOI DOI 10.1109/ICCICT.2012.6398182
   Baluja S, 2017, ADV NEUR IN, V30
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Boehm B., 2014, CORR
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Djebbar F., 2011, 2011 International Conference on Innovations in Information Technology (IIT), P409, DOI 10.1109/INNOVATIONS.2011.5893859
   Dumitrescu S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P641, DOI 10.1109/ICIP.2002.1039052
   Dumitrescu S, 2003, LECT NOTES COMPUT SC, V2578, P355
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Gandikota R, 2019, LECT NOTES COMPUT SC, V11942, P389, DOI 10.1007/978-3-030-34872-4_43
   Gang L, 2001, INT CONF ACOUST SPEE, P1365, DOI 10.1109/ICASSP.2001.941182
   Gauch S, 2007, LECT NOTES COMPUT SC, P54, DOI 10.1007/978-3-540-72079-9_2
   GRIFFIN DW, 1984, IEEE T ACOUST SPEECH, V32, P236, DOI 10.1109/TASSP.1984.1164317
   Gruhl D., 1996, Information Hiding. First International Workshop Proceedings, P295
   Hayes J, 1996, ADV NEURAL INFORM PR
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ito K., 2017, The LJ Speech Dataset
   Khare N, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040692
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu PJ, 2018, IEEE COMPUT SOC CONF, P886, DOI 10.1109/CVPRW.2018.00121
   Morkel T., 2005, ISSA, V1, P1
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saroha K., 2010, INT J COMPUTER APPL, VI I, P12
   Wang YT, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P55, DOI 10.1145/3206004.3206011
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Yari IA, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS (ITHINGS) AND IEEE GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) AND IEEE CYBER, PHYSICAL AND SOCIAL COMPUTING (CPSCOM) AND IEEE SMART DATA (SMARTDATA), P360, DOI 10.1109/iThings-GreenCom-CPSCom-SmartData.2017.60
   Zhang KA., 2019, ARXIV 190103892
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
   Zuras D., 2008, 7542008 IEEE, V754-2008, P1, DOI [DOI 10.1109/IEEESTD.2008.4610935, DOI 10.1109/IEEESTD.2008.5976968]
NR 37
TC 1
Z9 1
U1 4
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5049
EP 5072
DI 10.1007/s11042-022-13034-4
EA JUL 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000823376500005
DA 2024-07-18
ER

PT J
AU Touil, DE
   Terki, N
   Zitouni, A
AF Touil, Djamel Eddine
   Terki, Nadjiba
   Zitouni, Athmane
TI Improved ECG signal compression quality using bat algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electrocardiogram; Wavelet; Encoder; Compression; Bat
ID REDUCTION
AB Recently, electrocardiogram (ECG) data has gained significant importance not only for the medical context but also for purposes related to the biometric context, particularly data security and privacy. In this article, we propose an efficient ECG compression method to ensure high reliability and efficiency in data retention and transmission with high quality and confidentiality to convince patient information safety. The proposed method presents two main contributions. First, the discrete wavelet transform (DWT) coefficients are optimally thresholded using bat algorithm (BA), which provides high efficiency in improving the data compression rate without degrading the quality of the reconstructed data. Second, we perfectly encode the quantized vector of the wavelet coefficients by a two-role encoder (TRE). The effectiveness of the proposed search is evaluated in terms of compression ratio (CR) and root mean square difference (PRD) on the MIT-BIH arrhythmia data set. The results of the simulation validate the effectiveness of the proposed method compared to state-of-the-art methods.
C1 [Touil, Djamel Eddine] Univ Biskra, Energy Syst Modeling Lab, Biskra, Algeria.
   [Terki, Nadjiba; Zitouni, Athmane] Univ Biskra, Dept Elect Engn, LESIA Lab Res, Biskra, Algeria.
C3 Universite Mohamed Khider Biskra; Universite Mohamed Khider Biskra
RP Touil, DE (corresponding author), Univ Biskra, Energy Syst Modeling Lab, Biskra, Algeria.
EM tde.touil@gmail.com
CR Abo-Zahhad M, 2012, MOD SIMUL ENG, V2012, DOI 10.1155/2012/742786
   Ahmeda SM, 2001, MED ENG PHYS, V23, P117, DOI 10.1016/S1350-4533(01)00026-1
   Ali Alaa Maieed, 2020, 2020 2nd Annual International Conference on Information and Sciences (AiCIS), P91, DOI 10.1109/AiCIS51645.2020.00024
   [Anonymous], 2005, MIT-BIH arrhythmia database
   [Anonymous], 2008, SIGNAL PROCESSING IN
   Benzid R, 2008, DIGIT SIGNAL PROCESS, V18, P56, DOI 10.1016/j.dsp.2007.08.003
   Benzid R, 2007, IEEE SIGNAL PROC LET, V14, P373, DOI 10.1109/LSP.2006.887841
   Birnbaum T, 2019, APPL OPTICS, V58, P6193, DOI 10.1364/AO.58.006193
   Blanco-Velasco M, 2004, ELECTRON LETT, V40, P1466, DOI 10.1049/el:20046382
   Blanco-Velasco M, 2004, MED ENG PHYS, V26, P553, DOI 10.1016/j.medengphy.2004.04.004
   Boucheham B, 2006, COMPUT METH PROG BIO, V81, P162, DOI 10.1016/j.cmpb.2005.11.008
   Boucheham B, 2007, SIGNAL PROCESS, V87, P2336, DOI 10.1016/j.sigpro.2007.03.007
   Boukaache A, 2019, J MECH MED BIOL, V19, DOI 10.1142/S0219519419500052
   Bousselmi S., 2016, International Journal of Electrical and Computer Engineering, V6, P2150
   Butta S, 2015, INT J COMPUTER APPL, V116
   Chatterjee A, 2005, IEEE T BIO-MED ENG, V52, P945, DOI 10.1109/TBME.2005.845226
   Das A., 2017, SIG PROCESS, V2, P2015
   Devvrat T, 2021, ANAL LINEAR QUANTIZA, V12, P118, DOI [10.34218/IJEET.12.1.2021.013, DOI 10.34218/IJEET.12.1.2021.013]
   Djohan A., 1995, Proc. IEEE 17th Annual Conference on Engineering in Medicine and Biology Society, V1, P167, DOI [DOI 10.1109/IEMBS.1995.575053, 10.1109/IEMBS.1995.575053]
   Gao Y, 2017, J COMPUT APPL MATH, V324, P204, DOI 10.1016/j.cam.2017.04.029
   Ibaida A, 2021, COMPUT COMMUN, V166, P1, DOI 10.1016/j.comcom.2020.11.010
   Kumar A., 2021, Res. Biomed. Eng, V37, P79, DOI [10.1007/s42600-020-00108-1, DOI 10.1007/S42600-020-00108-1]
   Kumar R, 2013, COMPUT ELECTR ENG, V39, P130, DOI 10.1016/j.compeleceng.2012.04.008
   Leinonen M, 2013, 2013 SEG ANN M ONEPE
   Lu ZT, 2000, IEEE T BIO-MED ENG, V47, P849, DOI 10.1109/10.846678
   Manikandan AS, 2006, BIOMED SIGNAL PROCES, V1, P261, DOI 10.1016/j.bspc.2006.11.003
   NAVE G, 1993, IEEE T BIO-MED ENG, V40, P877, DOI 10.1109/10.245608
   Ramakrishnan AG, 1997, IEEE T BIO-MED ENG, V44, P1253, DOI 10.1109/10.649997
   Tun H.M., 2017, International Journal of Psychological and Brain Sciences, V02, P127, DOI DOI 10.11648/J.IJPBS.20170206.12
   Wang XY, 2008, DIGIT SIGNAL PROCESS, V18, P179, DOI 10.1016/j.dsp.2007.03.003
   Yang, 2012, XS
   Yang XS, 2016, BIO-INSPIRED COMPUTATION AND APPLICATIONS IN IMAGE PROCESSING, P1, DOI 10.1016/B978-0-12-804536-7.00001-6
   Yang XS, 2013, INT J BIO-INSPIR COM, V5, P141, DOI 10.1504/IJBIC.2013.055093
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Zhai P, 2019, IPCC Special Report on Climate Change, Desertification, Land Degradation, Sustainable Land Management, Food Security, and Greenhouse Gas Fluxes in Terrestrial Ecosystems, DOI DOI 10.1017/CBO9781107415324
   Zhao CJ, 2016, ELECTRON LETT, V52, P688, DOI 10.1049/el.2015.3391
NR 36
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2749
EP 2764
DI 10.1007/s11042-022-12881-5
EA JUL 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000820563900001
DA 2024-07-18
ER

PT J
AU Li, C
   Song, ZY
   Wang, Y
   Zhang, YC
AF Li, Chao
   Song, Ziyu
   Wang, Yi
   Zhang, Yancheng
TI Research on bud counting of cut lily flowers based on machine vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SVM; Ellipse fitting; Arcs combination; Direct least square method
ID RECOGNITION
AB The number of buds is an important index for the classification of cut lily flowers. Since manual counting is time-consuming and laborious, the cut flowers can be easily damaged, and the cut flowers' quality can be greatly affected. To build an efficient and non-destructive automatic counting of the lily cut flower grading system, we proposed a method for counting lily buds based on machine vision. However, in the images, the color of immature buds, stems, and leaves is similar. The buds are obscured by each other and by leaves, which may affect bud counting accuracy. In this paper, the threshold segmentation of color space transformation is applied to rough segmentation. Then the SVM is used for the second segmentation to extract the complete flower buds. Aiming at the flower buds shaded by each other and by the leaves, the ellipse fitting, and bud counting were was performed by arcs combination and direct least square method in the end. A total of 80 cut lily images (292 flower buds) were counted by the method, and the counting accuracy rate is 81.2% and 91.4% of flower buds were successfully fitted. The fitting accuracy of 91 flower buds was analyzed, and the mean relative errors of the long-axis and the short-axis of the fitting ellipses were less than 5%. When counting an image, the algorithm took a time of 2.371 s. The experimental results show that the proposed algorithm can count and fit flower buds better than other algorithms, which lays a foundation for the automatic classification of cut lily flowers to save labor costs and provides ideas and methods for ellipse fitting of ellipsoid-like objects shaded by each other.
C1 [Li, Chao; Zhang, Yancheng] Yunnan Agr Univ, Fac Mech & Elect Engn, Kunming 650000, Yunnan, Peoples R China.
   [Song, Ziyu] Bohai Univ, Fac Math Sci, Jinzhou 121013, Peoples R China.
   [Wang, Yi] Zaozhuang Univ, Fac Foreign Languages, Zaozhuang 277100, Peoples R China.
C3 Yunnan Agricultural University; Bohai University; Zaozhuang University
RP Zhang, YC (corresponding author), Yunnan Agr Univ, Fac Mech & Elect Engn, Kunming 650000, Yunnan, Peoples R China.
EM yanCZ18@tom.com
FU Yunnan Province Scientific Research Fund major Research special project
   [:202002AE09001002]
FX The work was supported by Yunnan Province Scientific Research Fund major
   Research special project (grant number:202002AE09001002).
CR Abu Arqub Omar, 2018, Neural Computing and Applications, V30, P2595, DOI 10.1007/s00521-017-2845-7
   Abu Arqub O, 2014, INFORM SCIENCES, V279, P396, DOI 10.1016/j.ins.2014.03.128
   Akiva P, 2020, IEEE COMPUT SOC CONF, P219, DOI 10.1109/CVPRW50498.2020.00033
   [Anonymous], 2015, International Journal of Computer and Information Engineering
   BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749
   Brosnan T, 2002, BIOSYST ENG, V83, P191, DOI 10.1006/bioe.2002.0111
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Lima MCF, 2020, AGRICULTURE-BASEL, V10, DOI 10.3390/agriculture10050161
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   Fornaciari M, 2014, PATTERN RECOGN, V47, P3693, DOI 10.1016/j.patcog.2014.05.012
   Huang L, 2020, IET IMAGE PROCESS, V14, P3689, DOI 10.1049/iet-ipr.2020.0088
   Huang ZY, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.5.053009
   Kadir M.F.A., 2015, APPL MATH SCI, V9, P6427
   Koirala A, 2019, COMPUT ELECTRON AGR, V162, P219, DOI 10.1016/j.compag.2019.04.017
   Krishnaveni S, 2017, ICT EXPRESS, V3, P148, DOI 10.1016/j.icte.2017.04.006
   Kwon BK, 2016, INT J CONTROL AUTOM, V14, P804, DOI 10.1007/s12555-014-0561-y
   Liao SC, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6063
   Liao SC, 2020, J INTELL FUZZY SYST, V38, P2725, DOI 10.3233/JIFS-179558
   Lin Z, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.534853
   Liu HongFei Liu HongFei, 2018, Transactions of the Chinese Society of Agricultural Engineering, V34, P170
   Meng C, 2020, IEEE T IMAGE PROCESS, V29, P4406, DOI 10.1109/TIP.2020.2967601
   Nanaa K, 2014, IEEE INT CONF INF VI, P388, DOI 10.1109/IV.2014.54
   Naranjo-Torres J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103443
   Pour AS, 2018, POSTHARVEST BIOL TEC, V139, P67, DOI 10.1016/j.postharvbio.2018.01.013
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tax DMJ, 1999, PATTERN RECOGN LETT, V20, P1191, DOI 10.1016/S0167-8655(99)00087-2
   Wang, 1999, WORLD AGR, V1999, P37
   Wang Y., 2015, BRIT MACHINE VISION, V2015, P1, DOI DOI 10.5244/C.29.156
   Wang YB, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEM AND ARTIFICIAL INTELLIGENCE (ISAI 2016), P390, DOI [10.1109/ISAI.2016.48, 10.1109/ISAI.2016.0089]
   Xiong D, 2019, J FOR SCI-PRAGUE, V65, P150, DOI 10.17221/82/2018-JFS
   XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z
   Yang QH, 2019, INT J AGR BIOL ENG, V12, P127, DOI 10.25165/j.ijabe.20191204.4584
   Zhang Ning, 2011, Application Research of Computers, V28, P4001, DOI 10.3969/j.issn.1001-3695.2011.11.001
   Zhang Q, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20051520
NR 35
TC 1
Z9 1
U1 6
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2709
EP 2730
DI 10.1007/s11042-022-13332-x
EA JUL 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000820564000003
DA 2024-07-18
ER

PT J
AU Al-Azawi, MAN
AF Al-Azawi, Mohammad A. N.
TI Symmetry-based brain abnormality identification in Magnetic Resonance
   Images (MRI)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image identification; Brain MRI; Features; CAD; Brain tumour; Symmetry
ID SEGMENTATION
AB Medical image processing, which includes many applications such as magnetic resonance image (MRI) processing, is one of the most significant fields of computer-aided diagnostic (CAD) systems. It has witnessed great growth over the last few decades as a result of the tremendous advancements in computer technology. One of the applications that uses MRI and digital image processing techniques is to assess whether the brain has any anomalies. The large variation in the brain shape among people poses a significant challenge in the computer-based diagnosis process. As a result, comparing a person's brain image to other people's brain images may not be a reliable way to diagnose a brain tumour. In this study, we present a method that takes advantage of the fact that the two lobes of the brain are symmetric to decide if there are any abnormalities as tumours cause a deformation in the shape of one of the lobes, which affects this symmetry. The proposed method determines the status of the brain by comparing the two lobes of the brain with each other and decides the presence of abnormalities in it based on the results of the comparison. Various features extracted from the images, such as colour and texture, have been studied, discussed, and used in the comparison process. The proposed algorithm was applied to 300 images from standard datasets and the results obtained were very satisfactory where the precision, recall, and accuracy reached 95.3%, 94.7%, and 95% respectively. The obtained results and the limitations are thoroughly discussed and benchmarked with state-of-the-art approaches and the results of the evaluation are discussed as well.
C1 [Al-Azawi, Mohammad A. N.] Oman Coll Management & Technol, Dept Comp Sci, Muscat, Oman.
   [Al-Azawi, Mohammad A. N.] Oman Coll Management & Technol, MIS, Muscat, Oman.
RP Al-Azawi, MAN (corresponding author), Oman Coll Management & Technol, Dept Comp Sci, Muscat, Oman.; Al-Azawi, MAN (corresponding author), Oman Coll Management & Technol, MIS, Muscat, Oman.
EM mohd.alazawi@omancollege.edu.om
RI Al-Azawi, Mohammad A. N./A-1777-2018
OI Al-Azawi, Mohammad A. N./0000-0003-3073-610X
CR al-Azawi A.n., 2013, International Journal of Computers and Applications, V83, P36, DOI [10.5120/14480-2781, DOI 10.5120/14480-2781]
   Al-Azawi M, 2017, SALIENCY BASED IMAGE
   Al-Azawi M, 2018, INT J COMPUT APPL, V180, P27, DOI [10.5120/ijca2018916165, DOI 10.5120/IJCA2018916165]
   Al-Azawi M, 2014, IEEE INT ADV COMPUT, P946, DOI 10.1109/IAdCC.2014.6779450
   Al-Tamimi Mohammed Sabbih Hamoud, 2014, Journal of Theoretical and Applied Information Technology, V62, P387
   Anand A., 2016, INT J ADV RES COMPUT, V5, P79, DOI [10.17148/IJARCCE.2016.5118, DOI 10.17148/IJARCCE.2016.5118]
   Anitha V, 2016, IET COMPUT VIS, V10, P9, DOI 10.1049/iet-cvi.2014.0193
   Anwar SM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1088-1
   Bahadure NB, 2018, J DIGIT IMAGING, V31, P477, DOI 10.1007/s10278-018-0050-6
   Bahadure NB, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9749108
   Benson CC, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P187, DOI 10.1109/ICACCI.2016.7732045
   Chakrabarty, 2018, BRAIN MRI IMAGES BRA
   Chen JL, 2018, J PHYS CONF SER, V1004, DOI 10.1088/1742-6596/1004/1/012035
   Cui WC, 2013, INT J BIOMED IMAGING, V2013, DOI 10.1155/2013/930301
   Damodharan S, 2015, INT ARAB J INF TECHN, V12, P42
   El-Dahshan ESA, 2010, DIGIT SIGNAL PROCESS, V20, P433, DOI 10.1016/j.dsp.2009.07.002
   Gilanie G, 2018, SIGNAL IMAGE VIDEO P, V12, P479, DOI 10.1007/s11760-017-1182-8
   Ibrahim ESH, 2017, HEART MECH MAGNETIC, P81
   Isin A, 2016, PROCEDIA COMPUT SCI, V102, P317, DOI 10.1016/j.procs.2016.09.407
   Kale PN, 2016, INT J CURRENT ENG IN, V6, P1271
   Kostelec PJ., 2003, Modern Signal Processing, V46, P161
   Kulkarni Sunita M., 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P552, DOI 10.1109/ICECA.2018.8474893
   Kumar DM, 2021, MULTIMED TOOLS APPL, V80, P6939, DOI 10.1007/s11042-020-09635-6
   Li QY, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20154203
   Louis DN, 2007, ACTA NEUROPATHOL, V114, P547, DOI 10.1007/s00401-007-0278-6
   Ozyurt F, 2019, MEASUREMENT, V147, DOI 10.1016/j.measurement.2019.07.058
   Pei LM, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-74419-9
   Rajput S., 2020, ARXIV
   Roslan R., 2010, 2010 IEEE EMBS Conference on Biomedical Engineering and Sciences (IECBES 2010), P26, DOI 10.1109/IECBES.2010.5742193
   Sachdeva J, 2013, J DIGIT IMAGING, V26, P1141, DOI 10.1007/s10278-013-9600-0
   Saladi S, 2016, INT J IMAG SYST TECH, V26, P295, DOI 10.1002/ima.22201
   Sartaj, 2020, BRAIN TUM CLASS MRI
   Tjahyaningtijas HPA, 2018, IOP CONF SER-MAT SCI, V336, DOI 10.1088/1757-899X/336/1/012012
   Tomasila G, 2020, AIP CONF PROC, V2296, DOI 10.1063/5.0030978
   Tripathi S., 2018, INT J RES ANALYTICAL, V5, P1295
   Wadhwa A, 2019, MAGN RESON IMAGING, V61, P247, DOI 10.1016/j.mri.2019.05.043
   Wang GT, 2019, LECT NOTES COMPUT SC, V11384, P61, DOI 10.1007/978-3-030-11726-9_6
   Wu WT, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/6789306
   Zabir I, 2015, 2015 IEEE International WIE Conference on Electrical and Computer Engineering (WIECON-ECE), P503, DOI 10.1109/WIECON-ECE.2015.7443979
NR 39
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2563
EP 2586
DI 10.1007/s11042-022-12197-4
EA JUN 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000819342400004
DA 2024-07-18
ER

PT J
AU Darshni, P
   Dhaliwal, BS
   Kumar, R
   Balogun, VA
   Singh, S
   Pruncu, CI
AF Darshni, Priya
   Dhaliwal, Balwinder Singh
   Kumar, Raman
   Balogun, Vincent Aizebeoje
   Singh, Sunpreet
   Pruncu, Catalin Iulian
TI Artificial neural network based character recognition using SciLab
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Character recognition; Artificial neural network; SciLab; Topology;
   Backpropagation
ID SYSTEM
AB Character recognition (CR) from an image of text is challenging research in pattern recognition and image processing. New CR systems use artificial neural network (ANN) methods embedded in commercially available software. However, with the rising cost of software, a research revolution in CR is becoming limited. In this work, a CR system is developed using open-source and free software, SciLab. It is the most desirable choice than other compensated software. CR experiments have been done using ANN. The topologies of the neural network varied to recognize ten numerals. The neural network is applied to classify the character with the online backpropagation algorithm by changing the weights for each input online. The results reveal a lower error and the system's accuracy of 99.92%. With standard backpropagation (batch version) while varying weights after a particular batch. An error is comparatively more, and the system's output accuracy of 99.62% for the same topology. The application of pre-processing techniques to the given images with topology optimization. The image recognition accuracy is increased by 100%. The system provided optimum results with a topology of 135-100-10. So, the online backpropagation algorithm is more accurate than the standard batch version and should be adopted. Other CR research models can be developed with the SciLab Toolboxes at no cost and with maximum system accuracy.
C1 [Darshni, Priya] Ludhiana Coll Engn & Technol, Dept Elect & Commun, Ludhiana 141113, Punjab, India.
   [Dhaliwal, Balwinder Singh] NITTTR Chandigarh, Dept Elect & Commun Engn, Chandigarh, India.
   [Kumar, Raman] Guru Nanak Dev Engn Coll, Dept Mech & Prod Engn, Ludhiana, Punjab, India.
   [Balogun, Vincent Aizebeoje] Edo Univ Iyamho, Dept Mech Engn, Okpella, Edo State, Nigeria.
   [Singh, Sunpreet] Natl Univ Singapore, Mech Engn, Singapore, Singapore.
   [Pruncu, Catalin Iulian] Imperial Coll, Mech Engn, Exhibit Rd, London SW7 2AZ, England.
   [Pruncu, Catalin Iulian] Univ Strathclyde, Design Mfg & Engn Management, Glasgow G1 1XJ, Lanark, Scotland.
C3 National Institute of Technical Teachers Training & Research,
   Chandigarh; Guru Nanak Dev Engineering College Ludhiana; National
   University of Singapore; Imperial College London; University of
   Strathclyde
RP Kumar, R (corresponding author), Guru Nanak Dev Engn Coll, Dept Mech & Prod Engn, Ludhiana, Punjab, India.; Pruncu, CI (corresponding author), Imperial Coll, Mech Engn, Exhibit Rd, London SW7 2AZ, England.; Pruncu, CI (corresponding author), Univ Strathclyde, Design Mfg & Engn Management, Glasgow G1 1XJ, Lanark, Scotland.
EM priyachabra10@gmail.com; bsdhaliwal@ymail.com; sehgal91@yahoo.co.in;
   vincent.balogun@edouniversity.edu.ng; snprt.singh@gmail.com;
   c.pruncu@imperial.ac.uk
RI Kumar, Raman/I-6869-2019; Dhaliwal, Balwinder S/AAP-8604-2020; Balogun,
   Vincent Aizebeoje/J-6982-2012; Pruncu, Catalin/A-6880-2018
OI Kumar, Raman/0000-0003-2934-7609; Dhaliwal, Balwinder
   S/0000-0001-5092-017X; Balogun, Vincent Aizebeoje/0000-0002-4628-1245;
   Pruncu, Catalin/0000-0002-4926-2189
CR Adhvaryu RV., 2013, INT J COMPUTER SCI E, V3, P227
   Afroge S, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER & TELECOMMUNICATION ENGINEERING (ICECTE)
   Ali MS, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION ENGINEERING (ICCIE), P91, DOI 10.1109/CCIE.2015.7399325
   Alotaibi F, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2771621
   Amaranageswarao G, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2020.102819
   Amato F, 2013, J APPL BIOMED, V11, P47, DOI 10.2478/v10136-012-0031-x
   [Anonymous], 2012, INT J COMPUT SCI ENG, DOI DOI 10.5121/IJCSES.2012.3112
   Arica N, 2001, IEEE T SYST MAN CY C, V31, P216, DOI 10.1109/5326.941845
   Arnold R., 2010, Proceedings 2010 11th International Symposium on Computational Intelligence and Informatics (CINTI 2010), P311, DOI 10.1109/CINTI.2010.5672225
   Ashwin TV, 2002, SADHANA-ACAD P ENG S, V27, P35, DOI 10.1007/BF02703311
   Boyd A, 2020, PATTERN RECOGN LETT, V138, P483, DOI 10.1016/j.patrec.2020.08.018
   CAO J, 1995, PATTERN RECOGN, V28, P153, DOI 10.1016/0031-3203(94)00094-3
   Cao XH, 2019, MEAS CONTROL-UK, V52, P252, DOI 10.1177/0020294019833073
   Chandio AA, 2020, IEEE ACCESS, V8, P109054, DOI 10.1109/ACCESS.2020.3001605
   Chen ZL, 2018, IEEE INT CONF AUTOMA, P381, DOI 10.1109/FG.2018.00061
   Dave NJIjosp image processing recognition p, 2015, INT J SIGNAL PROCESS, V8, P155
   Dholakia K., 2015, INT J COMPUT APPL, V115, P17, DOI [10.5120/20114-2159, DOI 10.5120/20114-2159]
   Dubey SC, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P268, DOI [10.1109/ICICCS48265.2020.9120957, 10.1109/iciccs48265.2020.9120957]
   En S, 2016, INT C PATT RECOG, P2054, DOI 10.1109/ICPR.2016.7899938
   Fouda Y., 2015, TRENDS APPL SCI RES, V10, P195, DOI [DOI 10.3923/tasr.2015.195.206, 10.3923/tasr.2015.195.206]
   Gürsoy Ö, 2019, MEAS CONTROL-UK, V52, P599, DOI 10.1177/0020294019827972
   Hanmandlu M., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P241, DOI 10.1109/ICDAR.1999.791769
   Jain A, 2019, NEURAL PROCESS LETT, V50, P3019, DOI 10.1007/s11063-019-09991-x
   Jena OP, 2020, 2020 INT C COMPUTER, P1, DOI [10.1109/ICCSEA49143.2020.9132915, DOI 10.1109/ICCSEA49143.2020.9132915]
   Karthika M, 2014, 2014 INT C ADV ENG T, P1, DOI [10.1109/ICAETR.2014.7012826, DOI 10.1109/ICAETR.2014.7012826]
   Khan S, 2019, MEAS CONTROL-UK, V52, P1532, DOI 10.1177/0020294019877508
   Lina Liu, 2012, 2012 4th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC), P25, DOI 10.1109/IHMSC.2012.12
   Liu CL, 2008, STUD COMPUT INTELL, V90, P139
   Liu PP, 2015, CHIN CONT DECIS CONF, P4132, DOI 10.1109/CCDC.2015.7162656
   Mehmood F, 2019, MEAS CONTROL-UK, V52, P1517, DOI 10.1177/0020294019877506
   Muda N, 2007, NATL C SOFTWARE ENG, V12, P1
   Nijhuis JAG, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P2232, DOI 10.1109/ICNN.1995.487708
   Pachpande Snehal, 2017, 2017 International Conference on Trends in Electronics and Informatics (ICEI). Proceedings, P717, DOI 10.1109/ICOEI.2017.8300796
   Peng HC, 2003, IEEE T PATTERN ANAL, V25, P1188, DOI 10.1109/TPAMI.2003.1227996
   Priyadarshni, 2016, OPTIK, V127, P10510, DOI 10.1016/j.ijleo.2016.05.106
   Ramesh G, 2019, 2019 5TH IEEE INTERNATIONAL WIE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (WIECON-ECE 2019), DOI 10.1109/wiecon-ece48653.2019.9019914
   Raus M, 1996, 38TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, PROCEEDINGS, VOLS 1 AND 2, P538, DOI 10.1109/MWSCAS.1995.504495
   Sahare P, 2018, IEEE ACCESS, V6, P10603, DOI 10.1109/ACCESS.2018.2795104
   Sekhar V, 2019, MEAS CONTROL-UK, V52, P1048, DOI 10.1177/0020294019858102
   Shah Parul, 2009, 2009 IEEE International Conference on Vehicular Electronics and Safety (ICVES 2009), P31, DOI 10.1109/ICVES.2009.5400240
   Sun S, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2019.102704
   Wang TW, 2019, PATTERN RECOGN LETT, V125, P821, DOI 10.1016/j.patrec.2019.08.005
   Wang WC, 2014, MEAS CONTROL-UK, V47, P283, DOI 10.1177/0020294014553322
   Wenying M., 2013, INT J SMART HOME, V7, P53
   Yanping G, 2010, 2010 2 INT C COMPUTE
   Yetis Y., 2014, 2014 WORLD AUT C WAC, DOI DOI 10.1109/WAC.2014.6936118
   Yo-Ping Huang, 2004, 2004 IEEE International Conference on Networking, Sensing and Control (IEEE Cat. No.04EX761), P737
   Zhang XY, 2018, IEEE T PATTERN ANAL, V40, P849, DOI 10.1109/TPAMI.2017.2695539
NR 48
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2517
EP 2538
DI 10.1007/s11042-022-13082-w
EA JUN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000817856900001
DA 2024-07-18
ER

PT J
AU Li, HY
   Xuan, ZX
   Zhou, JP
   Hu, XY
   Yang, B
AF Li, Hangyu
   Xuan, Zuxing
   Zhou, Jianpin
   Hu, Xiyuan
   Yang, Bo
TI Fast and accurate super-resolution of MR images based on lightweight
   generative adversarial network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MR images; Generative adversarial networks; Super-resolution;
   Multi-scale up sampling
ID RECONSTRUCTION
AB Single image super-resolution reconstruction (SISR) can effectively and economically improve the spatial resolution of magnetic resonance (MR) images, and it helps more accurate early clinical diagnosis and subsequent analysis. To increase the imaging speed and reduce the patient's pain and motion artifacts, many studies have moved from only considering the quality of the reconstructed image to proposing some lightweight models. However, the model's lightweight will limit its performance, and high-resolution MR images are often reconstructed with a single target (LOSS). In this work, we propose a lightweight generative adversarial network to alleviate this problem. The network mainly contains generators and discriminators. The generator uses a global cascade module to extract image features, and multi-scale up sampling of high-frequency and low-frequency features of different depths. As the cascaded modules lead to similar features, a consistent spatial attention module is used to weigh them and share the up-sampling module to reduce network parameters. The discriminator judges the authenticity of the input MR image, and it constructs two losses with the pre-trained VGG network to assist the generator training and provide diversified standards for the generation of MR images. In addition, we use knowledge transfer to train the network to explore the toplimit of network performance. Qualitative and quantitative experiments on the FASTMRI dataset show that the MR images generated by the designed multiple targets (loss) have better visual effects in detail. The proposed network has advantages in running time and parameter memory and achieved the highest precision results compared with state-of-the-art methods.
C1 [Li, Hangyu] Beijing Union Univ, Beijing Key Lab Informat Serv Engn, Beijing, Peoples R China.
   [Xuan, Zuxing] Beijing Union Univ, Inst Fundamental & Interdisciplinary Sci, Beijing 100101, Peoples R China.
   [Zhou, Jianpin] Anhui Univ Technol, Anhui Prov Key Lab Special Heavy Load Robot, Maanshan 243032, Peoples R China.
   [Hu, Xiyuan] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
   [Yang, Bo] Beijing Forestry Univ, Sch Informat Engn, Beijing, Peoples R China.
C3 Beijing Union University; Beijing Union University; Anhui University of
   Technology; Nanjing University of Science & Technology; Beijing Forestry
   University
RP Xuan, ZX (corresponding author), Beijing Union Univ, Inst Fundamental & Interdisciplinary Sci, Beijing 100101, Peoples R China.
EM 461933977@qq.com; zuxingxuan@163.com; jpzhou@ahut.edu.cn;
   xiyuan.hu@foxmail.com; yangbo090313@163.com
RI Hu, Xiyuan/AAF-7773-2021
OI Hu, Xiyuan/0000-0002-7095-6986
FU Beijing Outstanding Talents Training Fund Youth Top Individual Project,
   Premium Funding Project for Academic Human Resources Development in
   Beijing Union University [BPHR2020EZ01]
FX The work is supported by Beijing Outstanding Talents Training Fund Youth
   Top Individual Project, Premium Funding Project for Academic Human
   Resources Development in Beijing Union University under. grant
   BPHR2020EZ01.
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Carmi E, 2006, MAGN RESON IMAGING, V24, P133, DOI 10.1016/j.mri.2005.09.011
   Chen YH, 2018, LECT NOTES COMPUT SC, V11070, P91, DOI 10.1007/978-3-030-00928-1_11
   Chu XX, 2021, INT C PATT RECOG, P59, DOI 10.1109/ICPR48806.2021.9413080
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Fitzgibbon AW, 2006, EUR C COMP VIS ECCV
   Giannakidis A., 2017, P 25 SCI M INT SOC M
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Greenspan H, 2002, MAGN RESON IMAGING, V20, P437, DOI 10.1016/S0730-725X(02)00511-8
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang T.S., 1984, ADV COMPUTER VISION, V1, P317
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jolicoeur-Martineau A, 2019, ARXIV ABS180700734 N
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim S, 2019, ARXIV ABS180511360 N
   Lai W-S, 2017, PROC CVPR IEEE, P624, DOI DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Li YH, 2021, IEEE T IMAGE PROCESS, V30, P4840, DOI 10.1109/TIP.2021.3076285
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu J, 2020, PROC CVPR IEEE, P2356, DOI 10.1109/CVPR42600.2020.00243
   Lyu Q, 2020, IEEE T COMPUT IMAG, V6, P615, DOI 10.1109/TCI.2020.2964201
   Ma Y, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P1, DOI 10.1007/978-1-4419-9326-7
   Manjón JV, 2010, INT J BIOMED IMAGING, V2010, DOI 10.1155/2010/425891
   McDonagh S, 2017, LECT NOTES COMPUT SC, V10555, P116, DOI 10.1007/978-3-319-67564-0_12
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Ramzi Z, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051816
   Shi J, 2019, IEEE J BIOMED HEALTH, V23, P1129, DOI 10.1109/JBHI.2018.2843819
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Shilling RZ, 2009, IEEE T MED IMAGING, V28, P633, DOI 10.1109/TMI.2008.2007348
   Song DH, 2021, PROC CVPR IEEE, P15643, DOI 10.1109/CVPR46437.2021.01539
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tanno Ryutaro, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10433, P611, DOI 10.1007/978-3-319-66182-7_70
   Tian CW, 2020, KNOWL-BASED SYST, V205, DOI 10.1016/j.knosys.2020.106235
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Wang X, 2018, ARXIV ABS180900219 N
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xia Y, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102037
   Xue XT, 2020, IEEE J BIOMED HEALTH, V24, P377, DOI 10.1109/JBHI.2019.2945373
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yuan Y, 2018, IEEE COMPUT SOC CONF, P814, DOI 10.1109/CVPRW.2018.00113
   Yue LW, 2016, SIGNAL PROCESS, V128, P389, DOI 10.1016/j.sigpro.2016.05.002
   Yuhua Chen, 2018, 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018), P739, DOI 10.1109/ISBI.2018.8363679
   Zbontar J, 2018, ARXIV ABS
   Zeng K, 2018, COMPUT BIOL MED, V99, P133, DOI 10.1016/j.compbiomed.2018.06.010
   Zhang W, 2018, IEEE CONF COMPUT
   Zhang WL, 2019, IEEE I CONF COMP VIS, P3096, DOI 10.1109/ICCV.2019.00319
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhao C, 2018, I S BIOMED IMAGING, P365, DOI 10.1109/ISBI.2018.8363594
   Zhao XL, 2020, COMPUT VIS IMAGE UND, V201, DOI 10.1016/j.cviu.2020.103075
   Zhao XL, 2020, MULTIMED TOOLS APPL, V79, P33711, DOI 10.1007/s11042-019-08143-6
   Zhao XL, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2921882
   Zhu XZ, 2019, IEEE I CONF COMP VIS, P6687, DOI 10.1109/ICCV.2019.00679
NR 64
TC 2
Z9 2
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2465
EP 2487
DI 10.1007/s11042-022-13326-9
EA JUN 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000817041800003
DA 2024-07-18
ER

PT J
AU Yao, RZ
   Du, SY
   Wan, T
   Cui, WT
AF Yao, Runzhao
   Du, Shaoyi
   Wan, Teng
   Cui, Wenting
TI A robust registration algorithm based on salient object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Point set registration; Salient object detection; RGB-D images; GICP
ID MODEL
AB Point cloud registration plays an important role in 3D computer vision. A challenge in this field is the presence of small salient objects with huge flat backgrounds in point clouds, which may result in poor registration. Despite substantial approaches for point cloud registration have been proposed, few attempts have been made to address this problem. In this paper, we present an approach which fully leverages not only geometric information but also texture information presented by RGB images to tackle with this problem. To mitigate the influence of background, we introduce a superior 2D salient object detection method to highlight the role of the salient objects. The color supported generalized iterative closest points algorithm is the state-of-the-art approach in iterative closest points (ICP) variations, which can efficiently exploit the color information. However, it cannot deal with the mentioned problem. On this basis, we further propose a joint objective to align both salient color points and background points. The registration and reconstruction experiments demonstrate the robustness and accuracy of our method.
C1 [Yao, Runzhao; Du, Shaoyi; Wan, Teng; Cui, Wenting] Xi An Jiao Tong Univ, Coll Artificial Intelligence, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.
   [Yao, Runzhao; Du, Shaoyi; Wan, Teng; Cui, Wenting] Xi An Jiao Tong Univ, Coll Stomatol, Clin Res Ctr Shaanxi Prov Dent & Maxillofacial Di, Xian 710049, Shaanxi, Peoples R China.
   [Du, Shaoyi] Shunan Acad Artificial Intelligence, Ningbo 315000, Zhejiang, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University
RP Du, SY (corresponding author), Xi An Jiao Tong Univ, Coll Artificial Intelligence, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.; Du, SY (corresponding author), Xi An Jiao Tong Univ, Coll Stomatol, Clin Res Ctr Shaanxi Prov Dent & Maxillofacial Di, Xian 710049, Shaanxi, Peoples R China.; Du, SY (corresponding author), Shunan Acad Artificial Intelligence, Ningbo 315000, Zhejiang, Peoples R China.
EM dushaoyi@gmail.com
RI Yao, Runzhao/KBR-3537-2024
OI Du, Shaoyi/0000-0002-7092-0596
FU National Natural Science Foundation of China [61790562, 61971343,
   62088102]; Fundamental Research Funds for the Central Universities
   [xzy022020052]; Clinical Research Center of Shaanxi Province for Dental
   and Maxillofacial Diseases, College of Stomatology, Xi'an Jiaotong
   University [2021YHJB04]
FX This work was supported by the National Natural Science Foundation of
   China under Grant Nos. 61790562, 61971343 and 62088102, the Fundamental
   Research Funds for the Central Universities under Grant No.xzy022020052
   and the Clinical Research Center of Shaanxi Province for Dental and
   Maxillofacial Diseases, College of Stomatology, Xi'an Jiaotong
   University under Grant No. 2021YHJB04.
CR BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Breitenreicher D, 2011, INT J COMPUT VISION, V92, P32, DOI 10.1007/s11263-010-0401-3
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Choy C, 2020, PROC CVPR IEEE, P2511, DOI 10.1109/CVPR42600.2020.00259
   Dai A., 2017, ACM Transactions on Graphics (ToG), V36, DOI DOI 10.1145/3054739
   Druon S, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON INFORMATION ACQUISITION, VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P249, DOI 10.1109/ICIA.2006.306004
   Du SY, 2020, PATTERN RECOGN LETT, V132, P91, DOI 10.1016/j.patrec.2018.06.028
   Du SY, 2015, NEUROCOMPUTING, V157, P187, DOI 10.1016/j.neucom.2015.01.019
   El-Gamal FEA, 2016, EGYPT INFORM J, V17, P99, DOI 10.1016/j.eij.2015.09.002
   Ferrante E, 2017, MED IMAGE ANAL, V39, P101, DOI 10.1016/j.media.2017.04.010
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jian B, 2005, IEEE I CONF COMP VIS, P1246
   Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223
   Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499
   Korn M, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 3, P592
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Ma GX, 2020, IEEE T MULTIMEDIA, V22, P324, DOI 10.1109/TMM.2019.2929943
   Men H, 2011, IEEE INT CONF ROBOT, P1511
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Nüchter A, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P419
   Park J, 2017, IEEE I CONF COMP VIS, P143, DOI 10.1109/ICCV.2017.25
   Paschos G, 2001, IEEE T IMAGE PROCESS, V10, P932, DOI 10.1109/83.923289
   Phillips JM, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P427
   Ren MJ, 2017, IEEE T INSTRUM MEAS, V66, P414, DOI 10.1109/TIM.2016.2636538
   Segal AV, 2009, GEN ICP, DOI DOI 10.15607/RSS.2009.V.021
   Wan T, 2022, IEEE T NEUR NET LEAR, V33, P3547, DOI 10.1109/TNNLS.2021.3053274
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang Y, 2019, IEEE I CONF COMP VIS, P3522, DOI 10.1109/ICCV.2019.00362
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yang JL, 2013, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2013.184
   Ye M, 2011, IEEE I CONF COMP VIS, P731, DOI 10.1109/ICCV.2011.6126310
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhu L., 2020, IEEE MULTIMEDIA, V7, P2094
   Zhu XF, 2018, IEEE T KNOWL DATA EN, V30, P517, DOI 10.1109/TKDE.2017.2763618
   Zi Jian Yew, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11821, DOI 10.1109/CVPR42600.2020.01184
NR 37
TC 2
Z9 2
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34387
EP 34400
DI 10.1007/s11042-022-13194-3
EA JUN 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000813560900001
DA 2024-07-18
ER

PT J
AU Mademlis, I
   Torres-González, A
   Capitán, J
   Montagnuolo, M
   Messina, A
   Negro, F
   Le Barz, C
   Gonçalves, T
   Cunha, R
   Guerreiro, B
   Zhang, F
   Boyle, S
   Guerout, G
   Tefas, A
   Nikolaidis, N
   Bull, D
   Pitas, I
AF Mademlis, Ioannis
   Torres-Gonzalez, Arturo
   Capitan, Jesus
   Montagnuolo, Maurizio
   Messina, Alberto
   Negro, Fulvio
   Le Barz, Cedric
   Goncalves, Tiago
   Cunha, Rita
   Guerreiro, Bruno
   Zhang, Fan
   Boyle, Stephen
   Guerout, Gregoire
   Tefas, Anastasios
   Nikolaidis, Nikos
   Bull, David
   Pitas, Ioannis
TI A multiple-UAV architecture for autonomous media production
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple-UAV cooperation; Media production; UAV cinematography;
   Autonomous drones
AB Cinematography with Unmanned Aerial Vehicles (UAVs) is an emerging technology promising to revolutionize media production. On the one hand, manually controlled drones already provide advantages, such as flexible shot setup, opportunities for novel shot types and access to difficult-to-reach spaces and/or viewpoints. Moreover, little additional ground infrastructure is required. On the other hand, enhanced UAV cognitive autonomy would allow both easier cinematography planning (from the Director's perspective) and safer execution of that plan during actual filming; while integrating multiple UAVs can additionally augment the cinematic potential. In this paper, a novel multiple-UAV software/hardware architecture for media production in outdoor settings is proposed. The architecture encompasses mission planning and control under safety constraints, enhanced cognitive autonomy through visual analysis, human-computer interfaces and communication infrastructure for platform scalability with Quality-of-Service provisions. Finally, the architecture is demonstrated via a relevant subjective study on the adequacy of UAV and camera parameters for different cinematography shot types, as well as with field experiments where multiple UAVs film outdoor sports events.
C1 [Mademlis, Ioannis; Tefas, Anastasios; Nikolaidis, Nikos; Pitas, Ioannis] Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki, Greece.
   [Torres-Gonzalez, Arturo; Capitan, Jesus] Univ Seville, GRVC Robot Lab, Seville, Spain.
   [Montagnuolo, Maurizio; Messina, Alberto; Negro, Fulvio] RAI Ctr Res & Technol Innovat, Turin, Italy.
   [Le Barz, Cedric; Goncalves, Tiago] Thales Adv Studies Dept THERESIS, Palaiseau, France.
   [Cunha, Rita; Guerreiro, Bruno] Inst Super Tecn, Inst Syst & Robot ISR LARSyS, Lisbon, Portugal.
   [Zhang, Fan; Boyle, Stephen; Bull, David] Univ Bristol, Dept Elect & Elect Engn, Bristol, Avon, England.
   [Guerout, Gregoire] Alerion, Nancy, France.
C3 Aristotle University of Thessaloniki; University of Sevilla;
   Universidade de Lisboa; University of Bristol
RP Mademlis, I (corresponding author), Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki, Greece.
EM imademlis@csd.auth.gr; arturotorres@us.es; jcapitan@us.es;
   maurizio.montagnuolo@rai.it; alberto.messina@rai.it;
   fulvio.negro@rai.it; cedric.lebarz@thalesgroup.com;
   tiago-f.goncalves@thalesgroup.com; rita@isr.tecnico.ulisboa.pt;
   bguerreiro@isr.ist.utl.pt; fan.zhang@bristol.ac.uk;
   stephen.boyle@bristol.ac.uk; gregoire.guerout@alerion.fr;
   tefas@csd.auth.gr; nnik@csd.auth.gr; dave.bull@bristol.ac.uk;
   pitas@csd.auth.gr
RI Mademlis, Ioannis/K-3673-2019; Capitan, Jesus/F-8797-2010; Nikolaidis,
   Nikos/F-1819-2010; Guerreiro, Bruno/C-1257-2008; Cunha,
   Rita/E-5758-2011; Tefas, Anastasios/F-1899-2010
OI Mademlis, Ioannis/0000-0001-5479-0632; Nikolaidis,
   Nikos/0000-0003-1515-7986; Guerreiro, Bruno/0000-0002-4511-5114;
   Messina, Alberto/0000-0002-8262-2449; Cunha, Rita/0000-0002-8925-1273;
   Tefas, Anastasios/0000-0003-1288-3667
FU European Union's European Union [731667]; EPSRC [EP/M000885/1] Funding
   Source: UKRI
FX The research leading to these results has received funding from the
   European Union's European Union Horizon 2020 research and innovation
   programme under grant agreement No 731667 (MULTIDRONE). This publication
   reflects only the author's views. The European Union is not liable for
   any use that may be made of the information contained therein.
CR Alcántara A, 2021, ROBOT AUTON SYST, V140, DOI 10.1016/j.robot.2021.103778
   Alcántara A, 2020, IEEE ACCESS, V8, P201300, DOI 10.1109/ACCESS.2020.3036239
   [Anonymous], 2002, Recommendation ITU-R BT.500-11 Methodology for the subjective assessment of the quality of television pictures
   [Anonymous], YUNEEC YUNEEC PRODUC
   Arev I, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601198
   Bonatti R, 2019, IEEE INT C INT ROBOT, P229, DOI [10.1109/IROS40897.2019.8968163, 10.1109/iros40897.2019.8968163]
   Bonatti R, 2020, J FIELD ROBOT, V37, P606, DOI 10.1002/rob.21931
   Bucker A, 2020, ARXIV
   Caraballo LE, 2020, IEEE INT C INT ROBOT, P1509, DOI 10.1109/IROS45743.2020.9341622
   Cunha R, 2019, EUSIPCO
   Daniyal F., 2011, 2011 Conference for Visual Media Production, P11, DOI 10.1109/CVMP.2011.8
   FreeSkies, 2020, FREESKIES COPILOT
   Galvane Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3181975
   Gandhi V, 2015, P EUR WORKSH INT CIN
   Garage, 2020, SKYWAND
   Gebhardt C, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2508, DOI 10.1145/2858036.2858353
   Gschwindt M, 2019, IEEE INT C INT ROBOT, P1107, DOI [10.1109/IROS40897.2019.8967592, 10.1109/iros40897.2019.8967592]
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hornung A, 2013, AUTON ROBOT, V34, P189, DOI 10.1007/s10514-012-9321-0
   Huang C, 2019, IEEE INT CONF ROBOT, P1871, DOI [10.1109/icra.2019.8793915, 10.1109/ICRA.2019.8793915]
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Joubert N, 2016, ARXIV 161001691
   Kakaletsis E., 2019, P INT C MULT MOD MMM
   Karakostas I, 2019, INT CONF ACOUST SPEE, P1937, DOI 10.1109/ICASSP.2019.8683014
   Karakostas I, 2018, IEEE IMAGE PROC, P76, DOI 10.1109/ICIP.2018.8451385
   Karakostas L, 2020, INFORM SCIENCES, V506, P273, DOI 10.1016/j.ins.2019.08.011
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mademlis I, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3347713
   Mademlis I, 2019, IEEE T BROADCAST, V65, P627, DOI 10.1109/TBC.2019.2892585
   Mademlis I, 2018, IEEE INT CON MULTI
   Mademlis I, 2019, IEEE SIGNAL PROC MAG, V36, P147, DOI 10.1109/MSP.2018.2875190
   Matrice DJI., 2020, Dji
   Messina A., 2018, P INT BROADC CONV IB
   Montes-Romero A, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041494
   Moss FM, 2016, SIGNAL PROCESS-IMAGE, V48, P38, DOI 10.1016/j.image.2016.08.005
   Moss FM, 2016, IEEE T CIRC SYST VID, V26, P1977, DOI 10.1109/TCSVT.2015.2461971
   MULTIDRONE-Consortium, 2017, D2 1 MULT MED PROD R
   Nägeli T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073712
   Nägeli T, 2017, IEEE ROBOT AUTOM LET, V2, P1696, DOI 10.1109/LRA.2017.2665693
   Nousi Paraskevi, 2019, 2019 IEEE International Conference on Real-time Computing and Robotics (RCAR). Proceedings, P708, DOI 10.1109/RCAR47638.2019.9043931
   Nousi P, 2020, SIGNAL PROCESS-IMAGE, V88, DOI 10.1016/j.image.2020.115969
   Nousi P, 2018, IEEE IMAGE PROC, P321, DOI 10.1109/ICIP.2018.8451600
   Papaioannidis Christos, 2021, 2021 IEEE International Conference on Robotics and Automation (ICRA), P11074, DOI 10.1109/ICRA48506.2021.9560830
   Passalis N, 2019, NEUROCOMPUTING, V335, P37, DOI 10.1016/j.neucom.2019.01.046
   Real F, 2020, INT J ADV ROBOT SYST, V17, DOI 10.1177/1729881420925011
   Saeed A, 2017, ARXIV 170203456
   Skydio, 2020, SKYD PROD
   Symeonidis C, 2019, IEEE INT WORKS MACH
   Tzelepi M, 2017, EUR SIGNAL PR CONF, P743, DOI 10.23919/EUSIPCO.2017.8081306
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 51
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 1905
EP 1934
DI 10.1007/s11042-022-13319-8
EA JUN 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000810821800010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Sheng, QH
   Huang, J
   Li, Z
   Zhou, CY
   Yin, HB
AF Sheng, Qing-hua
   Huang, Jian
   Li, Zhu
   Zhou, Chao-yu
   Yin, Hai-bing
TI SiamDAG: Siamese dynamic receptive field and global context modeling
   network for visual tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual object tracking; Global context; Selective convolution kernel;
   Receptive field
AB Trackers based on anchor-free strategy have achieved a great success in recent years. However, they have limitations. To be specific, receptive fields of their models in each layer are fixed, so that the flexibility is lost. Then, they have no effective modeling of global context. Therefore, our model SiamDAG is put forward in this paper. The core part is Global Context - Selective Kernel block. This part can dynamically adjust its receptive field size based on multiple scales of input information, and model the global context effectively so that the tracker has the global understanding of a visual scene. Meanwhile, the Intersection over Union (IoU) prediction branch linking classification task and regression task is added. Our tracker was evaluated in VOT2019, OTB100 and GOT-10 k benchmark datasets, which achieved good results. It can also run up to 65FPS, far above the real-time requirement.
C1 [Sheng, Qing-hua; Huang, Jian; Li, Zhu; Zhou, Chao-yu; Yin, Hai-bing] Hangzhou Dianzi Univ, Sch Elect & Informat, Hangzhou 310000, Peoples R China.
C3 Hangzhou Dianzi University
RP Yin, HB (corresponding author), Hangzhou Dianzi Univ, Sch Elect & Informat, Hangzhou 310000, Peoples R China.
EM yhb@hdu.edu.cn
FU National Natural Science Foundation of China (NSFC) [61972123]; Zhejiang
   Provincial Key Lab of Equipment Electronics [2019E10009]
FX This research was funded by National Natural Science Foundation of
   China(NSFC, 61972123) and Zhejiang Provincial Key Lab of Equipment
   Electronics(2019E10009).
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Fu LH, 2020, MULTIMED TOOLS APPL, V79, P32623, DOI 10.1007/s11042-020-09546-6
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Huang T. S., 2016, P 24 ACM INT C MULT, P516, DOI 10.1145/2964284.2967274
   Jaderberg M, 2015, ADV NEUR IN, V28
   Kristan M., 2019, ICCVW
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li MW, 2021, NONLINEAR DYNAM, V103, P1167, DOI 10.1007/s11071-020-06111-6
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Real E, 2017, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR.2017.789
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tian Z, 2022, IEEE T PATTERN ANAL, V44, P1922, DOI 10.1109/TPAMI.2020.3032166
   Tripathi AS, 2019, BMVC, P6
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang GT, 2019, PROC CVPR IEEE, P3638, DOI 10.1109/CVPR.2019.00376
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wang Q, 2018, PROC CVPR IEEE, P4854, DOI 10.1109/CVPR.2018.00510
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu YD, 2020, AAAI CONF ARTIF INTE, V34, P12549
   Yang TY, 2018, LECT NOTES COMPUT SC, V11213, P153, DOI 10.1007/978-3-030-01240-3_10
   Zhang YF, 2019, MULTIMED TOOLS APPL, V78, P30355, DOI 10.1007/s11042-019-07860-2
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhao L, 2016, ARXIV PREPRINT ARXIV
   Zhipeng Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P771, DOI 10.1007/978-3-030-58589-1_46
   Zhu JM, 2021, MULTIMED TOOLS APPL, V80, P15469, DOI 10.1007/s11042-021-10574-z
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 50
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 681
EP 701
DI 10.1007/s11042-022-12008-w
EA JUN 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9KA1
UT WOS:000808527600007
DA 2024-07-18
ER

PT J
AU Sharafudeen, M
   Chandra, SSV
AF Sharafudeen, Misaj
   Chandra, Vinod S. S.
TI Detecting skin lesions fusing handcrafted features in image network
   ensembles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Melanoma detection; Deep neural networks; Feature extraction;
   Multi-input single-output model; Ensemble strategy
ID CLASSIFICATION
AB Skin cancer is the most prevalent genre of all cancers. Melanoma, being the deadliest of all skin cancers, calls for the requirement of an automated Artificial Intelligence-based skin diagnosis system to assist physicians with early diagnosis. We propose a fusion of conventional therapeutic approaches and deep learning frameworks to identify skin lesions. The work explores the scope of employing image data, handcrafted lesion features, and patient-centric metadata together to diagnose skin cancers effectively. We combined the image features transfer-learned from EfficientNets, colour and texture information extracted from the images, and patients' preprocessed metadata to produce the final hybrid model. They were fed to a multi-input single-output (MISO) model to fine-tune an artificial neural network classifier. Multiple MISO models were trained with their backbones substituted with EfficientNets B4 through B7. The predicted labels from these, along with a separate set of models trained with only image data and metadata were ensembled using majority soft voting. We experimented with weighing the models based on their contribution to ensemble accuracy and ensemble sensitivity. Each model was trained and evaluated using the well-known ISIC2018 and ISIC2019 datasets. The extreme imbalance in the datasets necessitates the use of appropriate evaluation metrics. ISIC2018 tested 90.49% sensitive and 97.76% specific, whereas the larger and more divergent dataset ISIC2019 rated 85.58% sensitive and 98.29% specific. The network is by far the finest compared to most other research in the field.
C1 [Sharafudeen, Misaj; Chandra, Vinod S. S.] Univ Kerala, Dept Comp Sci, Trivandrum 695581, Kerala, India.
C3 University of Kerala
RP Sharafudeen, M (corresponding author), Univ Kerala, Dept Comp Sci, Trivandrum 695581, Kerala, India.
EM misaj@keralauniversity.ac.in; vinod@keralauniversity.ac.in
RI Chandra, Vinod/ABC-1379-2020; Sharafudeen, Misaj/JED-3933-2023
OI Chandra, Vinod/0000-0003-2298-1906; Sharafudeen,
   Misaj/0000-0003-3866-4542
CR Almaraz-Damian JA, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22040484
   Anand H, 2018, INT J MACH LEARN CYB, V9, P589, DOI 10.1007/s13042-016-0546-7
   [Anonymous], ISIC CHALLENGE DATAS
   [Anonymous], ISIC Challenge
   Aswathy AL, 2021, J INFECT PUBLIC HEAL, V14, P1435, DOI 10.1016/j.jiph.2021.07.015
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Combalia Marc, 2019, ARXIV190802288
   Dugonik B, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082876
   Gessert N., 2018, ARXIV 180801694
   Gessert N, 2020, METHODSX, V7, DOI 10.1016/j.mex.2020.100864
   Ghalejoogh GS, 2020, EXPERT SYST APPL, V145, DOI 10.1016/j.eswa.2019.113127
   Gong A, 2020, IEEE ACCESS, V8, P155337, DOI 10.1109/ACCESS.2020.3019210
   Guissous A. E., 2019, ARXIV 191107817
   Ha Q., 2020, ARXIV 201005351
   Hameed N, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112961
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Harangi B, 2018, J BIOMED INFORM, V86, P25, DOI 10.1016/j.jbi.2018.08.006
   Kassem MA, 2020, IEEE ACCESS, V8, P114822, DOI 10.1109/ACCESS.2020.3003890
   Milton M. A. A., 2019, ARXIV 190110802
   Monika MK, 2020, MATER TODAY-PROC, V33, P4266, DOI 10.1016/j.matpr.2020.07.366
   Nahata Hardik., 2020, Machine Learning with Health Care Perspective: Machine Learning and Healthcare, P159, DOI [DOI 10.1007/978-3-030-40850-3_8, 10.1007/978-3-030-40850-3_8]
   Shahin AH, 2018, CAIRO INT BIOM ENG, P150, DOI 10.1109/CIBEC.2018.8641815
   Sondermann W, 2016, MEDICINE, V95, DOI 10.1097/MD.0000000000004332
   Steppan J., 2021, ARXIV 210103814
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Valiuddin M., 2019, USING EFFICIENTNET C
   Zghal NS, 2020, CURR MED IMAGING, V16, P50, DOI 10.2174/1573405614666180911120546
NR 28
TC 12
Z9 12
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 3155
EP 3175
DI 10.1007/s11042-022-13046-0
EA JUN 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000805749700003
DA 2024-07-18
ER

PT J
AU Hussain, N
   Ghinea, G
AF Hussain, Nadia
   Ghinea, Gheorghita
TI Guidelines for evaluating wearables' quality of experience in a
   mulsemedia context
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QoE; Mulsemedia; Heart rate; Crossmodal; Olfaction
ID SMART-WEARABLES; CROSSMODAL CORRESPONDENCES; VIDEO QUALITY; DESIGN;
   IMPACT; FUTURE; ODORS; MODEL; COLOR
AB Quality of Experience (QoE) is inextricably linked to the user experience of multimedia computing and, although QoE has been explored in relation to other types of multimedia devices, thus far its applicability to wearables has remained largely ignored. Given the proliferation of wearable devices and their growing use to augment and complement the multimedia user experience, the need for a set of QoE guidelines becomes imperative. This study meets that need and puts forward a set of guidelines tailored exclusively towards wearables' QoE. Accordingly, an extensive experimental investigation has been undertaken to see how wearables impact users' QoE in multiple sensorial media (mulsemedia) context. Based on the exploratory study, the findings have shown that the haptic vest (KOR-FX) enhanced user QoE to a certain extent. In terms of adoption, participants reported they would generally incorporate the heart rate (HR) monitor wristband (Mio Go) into their daily lives as opposed to the haptic vest. Other findings revealed that human factors play a part in user's attitudes towards wearables and predominantly age was the major influencing factor. Moreover, the participants' HR varied throughout the experiments, suggesting an enhanced level of engagement whilst viewing the multimedia video clips. Furthermore, the results suggest that there is a potential future for wearables, if the QoE is a positive one and if the design of such devices are appealing as well as unobtrusive.
C1 [Hussain, Nadia; Ghinea, Gheorghita] Brunel Univ, Dept Comp Sci, London, England.
C3 Brunel University
RP Ghinea, G (corresponding author), Brunel Univ, Dept Comp Sci, London, England.
EM nadia.hussain@brunel.ac.uk; george.ghinea@brunel.ac.uk
RI Ghinea, Gheorghita/AAG-6770-2020; Hussain, Nadia/GXH-7350-2022
OI Ghinea, Gheorghita/0000-0003-2578-5580; 
CR Aalto Pami., 2008, The New Northern Dimension of the European Neighborhood
   Alam KM, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2501643.2501649
   Alfian G, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072183
   Allie P., 2005, CHOOSING CHAIR BASED, V2, P1
   Amft O, 2009, IEEE PERVAS COMPUT, V8, P8, DOI 10.1109/MPRV.2009.44
   Anderson G, 2008, IEEE PERVAS COMPUT, V7, P10, DOI 10.1109/MPRV.2008.64
   [Anonymous], 2009, ScienceDaily
   [Anonymous], 2007, Cross-Modal Influences on Gustatory Perception
   [Anonymous], 2007, ITU T REPORT 2007
   [Anonymous], 2007, ISO 8589:2007 Sensory Analysis-General Guidance for the Design of Test Rooms
   Ariyatum B., 2005, Journal of the Textile Institute, V96, P199, DOI 10.1533/joti.2004.0071
   AYOUB MM, 1973, HUM FACTORS, V15, P265, DOI 10.1177/001872087301500309
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Bland JM, 1997, BRIT MED J, V314, P572, DOI 10.1136/bmj.314.7080.572
   Bodine K, 2003, SEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P57, DOI 10.1109/ISWC.2003.1241394
   Borgstrom L., 2011, Mousaion, V29, P193
   Brunnstrom K., 2013, P OUTP 5 QUAL M NOV
   Brunnström K, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.053013
   Bryson D, 2007, AI SOC, V22, P25, DOI 10.1007/s00146-006-0072-3
   Buenaflor C., 2013, International Journal of Multimedia and Ubiquitous Engineering, V8, P103, DOI DOI 10.1145/1056808.1056826
   Burgess T., 2001, GUIDE DESIGN QUESTIO
   Buruk OT, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174087
   Celestrini JR., 2021, SENSORYX 21 WORKSHOP, P1
   Chandra A., 2009, Proceedings of international conference on energy and environment, P913
   Ching KW, 2016, INT J NETWORK SECURI, V8, P1930
   Covaci A, 2018, MULTIMED TOOLS APPL, V77, P21245, DOI 10.1007/s11042-017-5459-2
   Crisinel AS, 2009, NEUROSCI LETT, V464, P39, DOI 10.1016/j.neulet.2009.08.016
   CRONBACH LJ, 1951, PSYCHOMETRIKA, V16, P297, DOI [10.1007/BF02310555, DOI 10.1007/BF02310555]
   Demattè ML, 2006, CHEM SENSES, V31, P531, DOI 10.1093/chemse/bjj057
   Dias D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082414
   Etikan I., 2016, AM J THEORETICAL APP, V5, P1, DOI [DOI 10.11648/J.AJTAS.20160501.11, 10.11648/j.atas.20160501.1]
   Fizza K., 2021, Discover Internet of Things, V1, P4, DOI [10.1007/s43926-021-00006-7, DOI 10.1007/S43926-021-00006-7, 10.1007/S43926-021-00006-7]
   Gemperle F, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P116, DOI 10.1109/ISWC.1998.729537
   Ghinea G, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2071396.2071398
   Ghinea G, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2379790.2379794
   Ghinea G, 2011, MULTIMED TOOLS APPL, V55, P601, DOI 10.1007/s11042-010-0581-4
   Gilbert AN, 1996, AM J PSYCHOL, V109, P335, DOI 10.2307/1423010
   Go M, 2017, MIO GO
   Graham JM, 2006, EDUC PSYCHOL MEAS, V66, P930, DOI 10.1177/0013164406288165
   Guedes GP, 2018, LAT AM C LEARN OBJ T
   Hancock PA, 2013, ERGONOMICS, V56, P729, DOI 10.1080/00140139.2013.771219
   Hanson-Vaux G, 2013, CHEM SENSES, V38, P161, DOI 10.1093/chemse/bjs087
   Hassenzahl M, 2001, INT J HUM-COMPUT INT, V13, P481, DOI 10.1207/S15327590IJHC1304_07
   Hawkins M, 2014, MIO INK HEART RATE B
   Hoshino S., 2011, IEEE INT WORKSHOP TE
   Hupont Isabelle., 2015, 2015 Seventh International Workshop on Quality of Multimedia Experience (QoMEX), P1, DOI [DOI 10.1109/QOMEX.2015.7148110, 10.1109/QoMEX.2015.7148110]
   Ijaz MF, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10103756
   Ijaz MF, 2016, SUSTAINABILITY-BASEL, V8, DOI 10.3390/su8060511
   Interaction Design Foundation, 2017, 7 FACT INFL US EXP
   Iwata H., 2003, ICAT 03 P 13 TH INT
   Jalal L, 2017, INT WORK QUAL MULTIM
   Jhajharia S., 2014, Int. J. Comput. Sci. Inform. Technol., V5, P5700
   Karahanolu Armaan, 2011, P 2011 C DESIGNING P
   Kemp SE, 1997, AM J PSYCHOL, V110, P35, DOI 10.2307/1423699
   Kim HL, 2010, INT CONF ADV COMMUN, P1377
   Kohn KT., 1999, To Err Is Human: Building a Safer Health System
   KOR-FX, 2014, KOR FX GAM VEST WIR
   Laghari KUR, 2012, IEEE COMMUN MAG, V50, P58, DOI 10.1109/MCOM.2012.6178834
   Lin JM, 2016, ADV INTELL SYST, V388, P243, DOI 10.1007/978-3-319-23207-2_24
   Liu LY, 2006, 2006 1ST INTERNATIONAL SYMPOSIUM ON PERVASIVE COMPUTING AND APPLICATIONS, PROCEEDINGS, P178
   Marcus A., 2014, PROC PART 1 3 INT C, P173
   MARKS LE, 1975, PSYCHOL BULL, V82, P303, DOI 10.1037/0033-2909.82.3.303
   Martens H, 2001, Multivariate analysis of quality: An introduction
   Mashable, 2019, 8 BEST FITN TRACK MO
   Mercun T, 2017, INFORM RES, V22
   Moen J., 2007, Proceedings of the 1st international conference on Tangible and embedded interaction, P251, DOI [https://doi.org/10.1145/1226969.1227021, DOI 10.1145/1226969.1227021]
   Motti VG, 2015, LECT NOTES COMPUT SC, V8976, P231, DOI 10.1007/978-3-662-48051-9_17
   Murray N, 2013, IEEE INT CON MULTI
   Murray N, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3108243
   Murray N, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2540994
   Murray Niall., 2013, Proceedings of the 4th ACM Multimedia Systems Conference, MMSys'13, P162, DOI [https://doi.org/10.1145/2483977.2483999, DOI 10.1145/2483977.2483999]
   Nakamoto T, 2008, IEEE COMPUT GRAPH, V28, P75, DOI 10.1109/MCG.2008.3
   Narumi T, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P93
   Nokia, 2006, CISC VIS NETW IND GL
   Nunnally J. C., 1994, Psychometric Theory
   Pal D, 2020, IEEE CONSUM ELECTR M, V9, P49, DOI 10.1109/MCE.2019.2941462
   Pal D, 2019, I C DATA ENGIN WORKS, P74, DOI 10.1109/ICDEW.2019.00-32
   Pal D, 2019, IEEE ACCESS, V7, P64266, DOI 10.1109/ACCESS.2019.2917061
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9070751
   Paradiso JA, 2010, PERS UBIQUIT COMPUT, V14, P137, DOI 10.1007/s00779-009-0239-2
   PARASURAMAN A, 1985, J MARKETING, V49, P41, DOI 10.2307/1251430
   Parise CV, OXFORD HDB SYNAESTHE
   Poslad S., 2009, Ubiquitous Computing
   Preusse KC, 2017, J APPL GERONTOL, V36, P127, DOI 10.1177/0733464815624151
   Rehman S., 2014, P 51 ANN DES AUT C D, P1, DOI DOI 10.7873/DATE.2014.119
   Rekimoto J, 2001, FIFTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P21, DOI 10.1109/ISWC.2001.962092
   Rodriguez Demostenes Z., 2016, International Journal of Digital Information and Wireless Communications, V6, P241
   Rutter B, 2019, ERGONOMICS WEARABL 1
   Sakai N, 2005, CHEM SENSES, V30, pI244, DOI 10.1093/chemse/bjh205
   Sandvine, 2006, CISC VIS NETW IND GL
   Schrepp M, 2017, INT J INTERACT MULTI, V4, P103, DOI 10.9781/ijimai.2017.09.001
   Scott MJ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P481, DOI 10.1145/2733373.2806254
   Scott MJ, 2016, IEEE T MULTIMEDIA, V18, P1796, DOI 10.1109/TMM.2016.2574623
   Simner J., 2009, 3 INT C SYNAESTHESIA
   Spagnolli A, 2014, LECT NOTES COMPUT SC, V8820, P87, DOI 10.1007/978-3-319-13500-7_7
   Spence C, 2011, ATTEN PERCEPT PSYCHO, V73, P971, DOI 10.3758/s13414-010-0073-7
   Spence C, 2012, I-PERCEPTION, V3, P410, DOI 10.1068/i0540ic
   Spence C, 2012, J CONSUM PSYCHOL, V22, P37, DOI 10.1016/j.jcps.2011.09.004
   Staelens N, 2010, IEEE T BROADCAST, V56, P458, DOI 10.1109/TBC.2010.2067710
   Stickel C, 2009, LECT NOTES COMPUT SC, V5614, P615, DOI 10.1007/978-3-642-02707-9_70
   Streeter NL, 2011, CHEMOSENS PERCEPT, V4, P1, DOI 10.1007/s12078-010-9082-0
   S┬u├nchez-Azqueta C., 2016, 2 INT C HIGH ED ADV, P84
   Tavakol M, 2011, INT J MED EDUC, V2, P1, DOI [10.5116/ijme.4d27.32ff, 10.5116/ijme.4dfb.8dfd]
   Tortell R., 2007, Virtual Reality, V11, P61, DOI 10.1007/s10055-006-0056-0
   Vermeulen J, 2016, DIS 2016: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P712, DOI 10.1145/2901790.2901887
   Vlahovic S., 2020, 2020 12 INT C QUALIT, P1
   Wentzel J, 2016, 13TH WEB FOR ALL CONFERENCE MONTREAL, CANADA 2016, DOI 10.1145/2899475.2899496
   Wentzel Jobke, 2016, P 2016 ACM WORKSH MU, P45
   Woo EHC, 2016, ERGONOMICS, V59, P464, DOI 10.1080/00140139.2015.1076528
   Yang H, 2016, TELEMAT INFORM, V33, P256, DOI 10.1016/j.tele.2015.08.007
   Yau JM, 2009, CURR BIOL, V19, P561, DOI 10.1016/j.cub.2009.02.013
   Yuan ZH, 2015, IEEE T MULTIMEDIA, V17, P957, DOI 10.1109/TMM.2015.2431915
   Yuan ZH, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2661329
   Zapater M.N., 2007, ICDS '07: Proceedings of the First International Conference on the Digital Society, P25, DOI [10.1109/ICDS.2007.4, DOI 10.1109/ICDS.2007.4]
   Zhu Y, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3183512
   Zhu Y, 2015, COMPUT HUM BEHAV, V49, P412, DOI 10.1016/j.chb.2015.02.054
   Zou LH, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P315, DOI 10.1145/3083187.3084014
NR 117
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43283
EP 43314
DI 10.1007/s11042-022-12766-7
EA MAY 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000800827500002
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Zhou, DM
   Zhang, CL
   Tang, YP
   Li, ZX
AF Zhou, Dongming
   Zhang, Canlong
   Tang, Yanping
   Li, Zhixin
TI Fine-grained alignment network and local attention network for person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human semantic parsing; Attention mechanism; Person re-identification;
   Partial alignment
AB Due to the influence of person posture changes, light angle of view, background and other factors, person re-identification is a challenging task. To improve the identification accuracy, recent studies have divided the pedestrians in the dataset into several blocks to extract the local features of the image for re-identification. However, these methods have such problems as the mismatch of local features of the human body and the loss of contextual clues of non-human body parts. To solve the above problems, this paper proposes a partially aligned network that can be used for person re-identification, which uses accurate local features to increase the ability of human body semantic parsing to model arbitrary contours. On this basis, the local attention network captures contextual cues that are not part of the human body. In addition, by aligning the local features of human body semantic parsing, the robustness and mobility of the model can be effectively increased. The experimental results obtained with the three datasets, Market-1501, DukeMTMC and CUHK03, show the effectiveness of the proposed model.
C1 [Zhou, Dongming; Zhang, Canlong; Li, Zhixin] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Tang, Yanping] Guilin Univ Elect Technol, Guilin 541004, Peoples R China.
C3 Guangxi Normal University; Guilin University of Electronic Technology
RP Zhang, CL (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
EM dmzhou95@stu.gxnu.edu.cn; clzhang@mailbox.gxnu.edu.cn;
   typhanzi@sina.com; lizx@gxnu.edu.cn
RI Huang, Liping/KIB-4430-2024; Zhao, YuHan/KIE-0813-2024; Li,
   Zhixin/ABI-9264-2022
OI Li, Zhixin/0000-0002-5313-6134; Zhang, Canlong/0000-0003-4375-1405
FU National Natural Science Foundation of China [61866004, 61966004,
   61962007]; Guangxi Natural Science Foundation [2018GXNSFDA281009,
   2019GXNSFDA245018, 2018GXNSFDA294001]; Research Fund of Guangxi Key Lab
   of Multi-source Information Mining and Security [20-A-03-01]; Guangxi
   "Bagui Scholar" Teams for Innovation Research Project
FX Y This work is supported by the National Natural Science Foundation of
   China (Nos.61866004, 61966004, 61962007), the Guangxi Natural Science
   Foundation (Nos.2018GXNSFDA281009, 2019GXNSFDA245018,2018GXNSFDA294001),
   Research Fund of Guangxi Key Lab of Multi-source Information Mining and
   Security (No.20-A-03-01), and Guangxi "Bagui Scholar" Teams for
   Innovation Research Project.
CR Bai S, 2017, AAAI CONF ARTIF INTE, P1281
   Cakir F, 2019, PROC CVPR IEEE, P1861, DOI 10.1109/CVPR.2019.00196
   Chen BH, 2019, IEEE I CONF COMP VIS, P371, DOI 10.1109/ICCV.2019.00046
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen WY, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.05.001
   Chen XS, 2020, PROC CVPR IEEE, P3297, DOI 10.1109/CVPR42600.2020.00336
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Elnagar A, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102121
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Han K, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P2040, DOI 10.1145/3240508.3240550
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Laenen K, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102316
   Li C, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102185
   Li SZ, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.107016
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Liu P, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102099
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Ristani E, 2018, PROC CVPR IEEE, P6036, DOI 10.1109/CVPR.2018.00632
   Ruan T, 2019, AAAI CONF ARTIF INTE, P4814
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Shen YT, 2018, PROC CVPR IEEE, P2265, DOI 10.1109/CVPR.2018.00241
   Su YH, 2019, PROC CVPR IEEE, P10474, DOI 10.1109/CVPR.2019.01073
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tao ZL, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102277
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang QZ, 2019, PROC CVPR IEEE, P4190, DOI 10.1109/CVPR.2019.00432
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Yao HT, 2019, IEEE T IMAGE PROCESS, V28, P2860, DOI 10.1109/TIP.2019.2891888
   Yuan Y, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102175
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhang ZZ, 2019, PROC CVPR IEEE, P667, DOI 10.1109/CVPR.2019.00076
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng M, 2019, PROC CVPR IEEE, P5728, DOI 10.1109/CVPR.2019.00588
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
NR 39
TC 0
Z9 0
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43267
EP 43281
DI 10.1007/s11042-022-12638-0
EA MAY 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000800825900004
DA 2024-07-18
ER

PT J
AU Jung, G
   Yoon, SM
AF Jung, Geunho
   Yoon, Sang Min
TI Monocular depth estimation with multi-view attention autoencoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth estimation; Autoencoder; Attention module
AB Depth map estimation from a single RGB image is a fundamental computer vision and image processing task for various applications. Deep learning based depth map estimation has improved prediction accuracy compared with traditional approaches by learning huge numbers of RGB-D images, but challenging issues remain for distorted and blurry reconstruction in object boundaries because the features are not enforced during training. This paper presents a multi-view attention autoencoder embedded in a deep neural network to emphasize self-representative features, which provide robust depth maps by simultaneously accentuating useful features and reducing redundant features to improve depth map estimation performance. Qualitative and quantitative experiments were conducted to verify the proposed network effectiveness, which can be utilized for three-dimensional scene reconstruction and understanding.
C1 [Jung, Geunho; Yoon, Sang Min] Kookmin Univ, Coll Comp Sci, HCI Lab, 77 Jeongneung Ro, Seoul 02707, South Korea.
C3 Kookmin University
RP Yoon, SM (corresponding author), Kookmin Univ, Coll Comp Sci, HCI Lab, 77 Jeongneung Ro, Seoul 02707, South Korea.
EM smyoon@kookmin.ac.kr
FU Institute of Information communications Technology Planning and
   Evaluation (IITP) [2020-0-00457]; National Research Foundation of Korea
   [NRF-2021R1A2C1008555]
FX This work is supported by Institute of Information communications
   Technology Planning and Evaluation (IITP) (No.2020-0-01826, and
   2020-0-00457) and by the National Research Foundation of Korea (No.
   NRF-2021R1A2C1008555).
CR Aleotti F, 2019, LECT NOTES COMPUT SC, V11129, P337, DOI 10.1007/978-3-030-11009-3_20
   Alhashim I., 2018, High quality monocular depth estimation via transfer learning
   [Anonymous], 2016, DEEPCONTEXT CONTEXT
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Cao YZH, 2018, IEEE T CIRC SYST VID, V28, P3174, DOI 10.1109/TCSVT.2017.2740321
   Chakravarty P, 2019, IEEE INT CONF ROBOT, P147, DOI [10.1109/ICRA.2019.8793530, 10.1109/icra.2019.8793530]
   Chen JZ, 2016, PROCEEDINGS OF 2016 12TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P551, DOI [10.1109/CIS.2016.133, 10.1109/CIS.2016.0134]
   Chen WF, 2016, ADV NEUR IN, V29
   Chen Y., 2019, ARXIV190110137
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Eigen D, 2014, ADV NEUR IN, V27
   El Jamiy F, 2019, IET IMAGE PROCESS, V13, P707, DOI 10.1049/iet-ipr.2018.5920
   Fu C, 2019, IEEE INT C INTELL TR, P273, DOI [10.1109/ITSC.2019.8917201, 10.1109/itsc.2019.8917201]
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Furukawa R, 2017, IEEE I CONF COMP VIS, P4650, DOI 10.1109/ICCV.2017.497
   Garg R, ARXIV160304992
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Holynski A, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275083
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Lee JH, 2018, PROC CVPR IEEE, P330, DOI 10.1109/CVPR.2018.00042
   Li J, 2017, IEEE I CONF COMP VIS, P3392, DOI 10.1109/ICCV.2017.365
   Lin Zhouhan, 2017, A structured self-attentive sentence embedding
   Ling Zou, 2010, 2010 International Conference on Audio, Language and Image Processing (ICALIP), P185, DOI 10.1109/ICALIP.2010.5684978
   Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Moon J, 2018, INTEL SERV ROBOT, V11, P347, DOI 10.1007/s11370-018-0257-x
   Parikh AP., 2016, EMNLP
   Paulus Romain, 2018, ICLR
   Ping JM, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1124, DOI [10.1109/VR.2019.8798174, 10.1109/vr.2019.8798174]
   Ranftl R, 2016, PROC CVPR IEEE, P4058, DOI 10.1109/CVPR.2016.440
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Shao ZZ, 2016, IFIP ADV INF COMM TE, V486, P222, DOI 10.1007/978-3-319-48390-0_23
   ULLMAN S, 1979, PROC R SOC SER B-BIO, V203, P405, DOI 10.1098/rspb.1979.0006
   Wang R, 2019, PROC CVPR IEEE, P5647, DOI 10.1109/CVPR.2019.00570
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu D, 2017, PROC CVPR IEEE, P161, DOI 10.1109/CVPR.2017.25
   Yuanfa Ji, 2020, 2020 7th International Forum on Electrical Engineering and Automation (IFEEA), P843, DOI 10.1109/IFEEA51475.2020.00177
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 41
TC 5
Z9 5
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33759
EP 33770
DI 10.1007/s11042-022-12301-8
EA APR 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784679300027
DA 2024-07-18
ER

PT J
AU Madhu, G
   Govardhan, A
   Ravi, V
   Kautish, S
   Srinivas, BS
   Chaudhary, T
   Kumar, M
AF Madhu, G.
   Govardhan, A.
   Ravi, Vinayakumar
   Kautish, Sandeep
   Srinivas, B. Sunil
   Chaudhary, Tanupriya
   Kumar, Manoj
TI DSCN-net: a deep Siamese capsule neural network model for automatic
   diagnosis of malaria parasites detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep Siamese capsule network; Neural network; Machine learning; Malaria
   parasites detection; Deep learning
ID IMAGE-ANALYSIS; CLASSIFICATION; QUANTIFICATION
AB The epidemic of malaria has caused many deaths for decades around the world. To shorten the morbidity of malaria, accurate and fast diagnostic tools are to be implied with Artificial Intelligence. In this research, an automated, fast, and accurate diagnostic model for one-shot detection and classification of malaria thin blood smears were developed using the Deep Siamese Capsule Network (D-SCN) and contributions for our research are threefold. Firstly, we proposed the D-SCN model which consists of two crucial phases which are feature extraction and feature discrimination. Secondly, we implied an end-to-end trained capsule network with an imperative routing (IR) mechanism for the feature extraction phase to capture feature invariances. Finally, at the feature discrimination phase, Lorentz, L-1 and L-2 similarity metrics were proposed for the dissimilation of features. During experimentation, it is observed that the Lorentz similarity metric provided more discriminative capability by acquiring the least MSE at most of the instances. Further, an algorithm is proposed to obtain faster convergence by cautiously tuning the hyperparameters, and this aided in decreasing the noise scale in training the D-SCN. The experimental outcomes proved that D-SCN outperformed with the highest detection accuracy of 97.24% for Lorentz as a similarity measure, and the Capsule network with IR mechanism outperformed with the highest classification accuracy of 98.89%. To our knowledge, the proposed research implications are the first applications of D-SCN for one-shot detection and classification of thin blood smears with state-of-the-art performance.
C1 [Madhu, G.] VNRVJIET, Dept Informat Technol, Hyderabad 500090, India.
   [Govardhan, A.] JNTUH Coll Engn, Dept Comp Sci & Engn, Hyderabad 85, TS, India.
   [Ravi, Vinayakumar] Prince Mohammad Bin Fahd Univ, Ctr Artificial Intelligence, Khobar, Saudi Arabia.
   [Kautish, Sandeep] LBEF Campus, Kathmandu 44600, Nepal.
   [Srinivas, B. Sunil] TKR Coll Engn & Technol, Dept Comp Sci & Engn, Hyderabad 97, TS, India.
   [Chaudhary, Tanupriya; Kumar, Manoj] Univ Petr & Energy Studies, Sch Comp Sci, Dehra Dun, Uttarakhand, India.
C3 Vallurupalli Nageswara Rao Vignana Jyothi Institute of Engineering
   &Technology (VNR VJIET); Jawaharlal Nehru Technological University -
   Hyderabad; Prince Mohammad Bin Fahd University; University of Petroleum
   & Energy Studies (UPES)
RP Kumar, M (corresponding author), Univ Petr & Energy Studies, Sch Comp Sci, Dehra Dun, Uttarakhand, India.
EM madhu_g@vnrvjiet.in; govardhan_cse@jntuh.ac.in; vravi@pmu.edu.sa;
   dr.skautish@gmail.com; sunilsrinivasb@tkrcet.com;
   tanupriya1986@gmail.com; wss.manojkumar@gmail.com
RI Ravi, Vinayakumar/L-4202-2018; Srinivas, Dr.B.Sunil/HRD-2111-2023;
   Kautish, Sandeep/Y-5555-2019; Golla, Madhu/F-3654-2012; Madhu,
   Golla/AAN-7843-2021; Aliseri, Govardhan/N-4554-2019; GOVARDHAN, Prof.
   ALISERI/U-2721-2017; Kumar, Manoj/AFS-0700-2022
OI Kautish, Sandeep/0000-0001-5120-5741; Golla, Madhu/0000-0002-4170-3146;
   Aliseri, Govardhan/0000-0001-9239-0138; GOVARDHAN, Prof.
   ALISERI/0000-0001-9239-0138; Kumar, Manoj/0000-0001-9598-0280;
   Choudhury, Tanupriya/0000-0002-9826-2759
CR Anggraini D, 2011, P 2011 INT C EL ENG
   Arco JE, 2015, EXPERT SYST APPL, V42, P3041, DOI 10.1016/j.eswa.2014.11.037
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bibin D, 2017, IEEE ACCESS, V5, P9099, DOI 10.1109/ACCESS.2017.2705642
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Das DK, 2015, J MICROSC-OXFORD, V257, P238, DOI 10.1111/jmi.12206
   Das DK, 2013, MICRON, V45, P97, DOI 10.1016/j.micron.2012.11.002
   Deza MM, 2009, Encyclopedia of distances, P1, DOI [10.1007/978-3-642-00234-2, DOI 10.1007/978-3-642-00234-2]
   Díaz G, 2009, J BIOMED INFORM, V42, P296, DOI 10.1016/j.jbi.2008.11.005
   Dong YH, 2017, 2017 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), P101, DOI 10.1109/BHI.2017.7897215
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gopakumar GP, 2018, J BIOPHOTONICS, V11, DOI 10.1002/jbio.201700003
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Janocha, 2017, 12016 SCHED INF
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumarasamy SK, 2010, MACH VIS APPL
   Liang ZH, 2016, IEEE INT C BIOINFORM, P493, DOI 10.1109/BIBM.2016.7822567
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Madhu, 2020, 2020 IEEE INT C INN
   Madhu G, 2021, CMC-COMPUT MATER CON, V68, P903, DOI 10.32604/cmc.2021.016114
   Madhu G, 2021, COMPUT MAT CONTINUA, V68, P1
   Madhu G, 2021, DEMYSTIFYING BIG DAT, P277, DOI [10.1016/B978-0-12-821633-0.00007-6, DOI 10.1016/B978-0-12-821633-0.00007-6]
   Maity M, 2020, PATTERN RECOGN LETT, V138, P88, DOI 10.1016/j.patrec.2020.07.002
   Malihi L, 2013, IRAN CONF MACH, P360, DOI 10.1109/IranianMVIP.2013.6780011
   Moon S, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0061812
   Rajaraman S, 2018, PEERJ, V6, DOI 10.7717/peerj.4568
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ross NE, 2006, MED BIOL ENG COMPUT, V44, P427, DOI 10.1007/s11517-006-0044-2
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sabour S, 2017, ADV NEUR IN, V30
   Sayyed AQMS, 2019, 2019 IEEE INT C SIGN
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sio SWS, 2007, J MICROBIOL METH, V68, P11, DOI 10.1016/j.mimet.2006.05.017
   Sivaramakrishnan R, 2017, MED INFORM
   Smith KP, 2020, CLIN MICROBIOL INFEC, V26, P1318, DOI 10.1016/j.cmi.2020.03.012
   Smith S. L., 2017, ARXIV171100489
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Swati, 2017, IEEE INT CONF COMP V, P72, DOI 10.1109/ICCVW.2017.17
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Tek FB, 2010, COMPUT VIS IMAGE UND, V114, P21, DOI 10.1016/j.cviu.2009.08.003
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang J, 2017, COMPUT BIOL MED, V84, P137, DOI 10.1016/j.compbiomed.2017.03.024
   WHO, 2012, GLOBAL TUBERCULOSIS REPORT 2012, P1
   Zeng XL, 2019, IEEE ACCESS, V7, P30744, DOI 10.1109/ACCESS.2019.2903171
NR 54
TC 11
Z9 11
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 34105
EP 34127
DI 10.1007/s11042-022-13008-6
EA APR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784679300004
DA 2024-07-18
ER

PT J
AU Sadeghi, F
   Bidgoly, AJ
   Amirkhani, H
AF Sadeghi, Fariba
   Bidgoly, Amir Jalaly
   Amirkhani, Hossein
TI Fake news detection on social media using a natural language inference
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fake news detection; Natural language inference; Social media; Content
   features
AB Fake news detection is a challenging problem in online social media, with considerable social and political impacts. Several methods have already been proposed for the automatic detection of fake news, which are often based on the statistical features of the content or context of news. In this paper, we propose a novel fake news detection method based on Natural Language Inference (NLI) approach. Instead of using only statistical features of the content or context of the news, the proposed method exploits a human-like approach, which is based on inferring veracity using a set of reliable news. In this method, the related and similar news published in reputable news sources are used as auxiliary knowledge to infer the veracity of a given news item. We also collect and publish the first inference-based fake news detection dataset, called FNID, in two formats: the two-class version (FNID-FakeNewsNet) and the six-class version (FNID-LIAR). We use the NLI approach to boost several classical and deep machine learning models, including Decision Tree, Naive Bayes, Random Forest, Logistic Regression, k-Nearest Neighbors, Support Vector Machine, BiGRU, and BiLSTM along with different word embedding methods including Word2vec, GloVe, fastText, and BERT. The experiments show that the proposed method achieves 85.58% and 41.31% accuracies in the FNID-FakeNewsNet and FNID-LIAR datasets, respectively, which are 10.44% and 13.19% respective absolute improvements.
C1 [Sadeghi, Fariba; Bidgoly, Amir Jalaly; Amirkhani, Hossein] Univ Qom, Qom 3716146611, Iran.
C3 University of Qom
RP Bidgoly, AJ (corresponding author), Univ Qom, Qom 3716146611, Iran.
EM f.sadeghi@stu.qom.ac.ir; jalaly@qom.ac.ir; amirkhani@qom.ac.ir
RI Bidgoly, Amir Jalaly/ABE-1769-2020
OI Bidgoly, Amir Jalaly/0000-0002-8574-3537
CR Ajao O, 2019, INT CONF ACOUST SPEE, P2507, DOI 10.1109/ICASSP.2019.8683170
   Amirkhani H, 2021, ARXIV200908820
   [Anonymous], 2019, ARXIV190409482
   [Anonymous], 2018, ARXIV180808762
   Bakhteev O, 2020, NOTEBOOK PAPERS
   Behzad B, 2021, ARXIV210609586
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Bowman S. R., 2015, Proceedings of the 2015 conference on empirical methods in natural language processing, DOI [DOI 10.18653/V1/D15-1075, 10.18653/v1/d15-1075, 10.18653/v1/D15-1075]
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chen Q, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1657, DOI 10.18653/v1/P17-1152
   Cho K., 2014, ARXIV14061078
   Conneau A., 2017, P 2017 C EMPIRCAL ME, P670, DOI [DOI 10.18653/V1/D17-1070, 10.18653/v1/d17-1070]
   Della Vedova ML, 2018, PROC CONF OPEN INNOV, P272, DOI 10.23919/FRUCT.2018.8468301
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dey R, 2017, MIDWEST SYMP CIRCUIT, P1597, DOI 10.1109/MWSCAS.2017.8053243
   Dong XS, 2020, IEEE T COMPUT SOC SY, V7, P1386, DOI 10.1109/TCSS.2020.3027639
   Dreiseitl S, 2002, J BIOMED INFORM, V35, P352, DOI 10.1016/S1532-0464(03)00034-0
   Farajtabar M, 2017, PR MACH LEARN RES, V70
   Golbeck J, 2018, WEBSCI'18: PROCEEDINGS OF THE 10TH ACM CONFERENCE ON WEB SCIENCE, P17, DOI 10.1145/3201064.3201100
   Grave E, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3483
   Hakak Saqib, 2020, Computational Data and Social Networks. 9th International Conference, CSoNet 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12575), P345, DOI 10.1007/978-3-030-66046-8_28
   Hakak S, 2021, FUTURE GENER COMP SY, V117, P47, DOI 10.1016/j.future.2020.11.022
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Holtzman A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1638
   Horne BD, 2017, 11 INT AAAI C WEB SO
   Hu Hai, 2020, Findings of EMNLP
   Jiang LX, 2007, LECT NOTES ARTIF INT, V4632, P134
   Jiang SY, 2019, LECT NOTES ARTIF INT, V11838, P634, DOI 10.1007/978-3-030-32233-5_49
   Kaliyar RK, 2021, MULTIMED TOOLS APPL, V80, P11765, DOI 10.1007/s11042-020-10183-2
   Karimi Hamid, 2018, P 27 INT C COMP LING, P1546
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   Khot T, 2018, AAAI CONF ARTIF INTE, P5189
   Kumar P J S, 2021 5 INT C TRENDS, P829
   Li P, 2020, SA NLI SUPERVISED AT
   Li X, 2022, MULTIMED TOOLS APPL, V81, P19341, DOI 10.1007/s11042-021-11065-x
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5070
   MacCartney B., 2009, Natural Language Inference
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Moreno-Sandoval LG, 2020, NOTEBOOK PAPERS
   Noureen J, 2017, INT J ADV COMPUT SC, V8, P363
   Pamungkas EW, 2019, ARXIV190101911
   Parikh AP., 2016, EMNLP
   Pasunuru R, 2017, ARXIV170802300 CORR
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Pradhan A, 2012, SUPPORT VECTOR MACHI, V2
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Reddy H, 2020, INT J AUTOM COMPUT, V17, P210, DOI 10.1007/s11633-019-1216-5
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shabani S, 2018, 2018 4TH IEEE INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC 2018), P299, DOI 10.1109/CIC.2018.00048
   Shu K, 2018, FakeNewsNet: A Data Repository with News Content, Social Context and Dynamic Information for Studying Fake News on Social Media
   Shu K, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P436, DOI 10.1145/3341161.3342927
   Shu K, 2019, COMPUT MATH ORGAN TH, V25, P60, DOI 10.1007/s10588-018-09280-3
   Silverman Craig., 2016, Buzzfeed News, V20
   Thornton JF, 2018, FACIAL RECONSTRUCTION AFTER MOHS SURGERY, P1
   Trivedi H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2948
   Vlachos A., 2014, P ACL 2014 WORKSH LA, P18, DOI [DOI 10.3115/V1/W14-2508, 10.3115/v1/W14-2508]
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Williams A., 2017, ARXIV170405426
   Xinyi Zhou, 2019, ACM SIGKDD Explorations Newsletter, V21, P48, DOI 10.1145/3373464.3373473
   Yang ZL, 2019, ADV NEUR IN, V32
   Zhao ZL, 2020, EPJ DATA SCI, V9, DOI 10.1140/epjds/s13688-020-00224-z
   Zhou X., 2018, ARXIV181200315
   Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603
NR 64
TC 15
Z9 15
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33801
EP 33821
DI 10.1007/s11042-022-12428-8
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784679300028
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Tao, XX
   Shi, TQ
   Ma, X
   Zhang, HW
   Pei, ZP
AF Tao, Xiaoxiao
   Shi, Tianqi
   Ma, Xin
   Zhang, Haowei
   Pei, Zhipeng
TI An improved indoor pedestrian dead reckoning algorithm using ambient
   light and sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian dead reckoning; Smartphone; Ambient light; Indoor navigation
ID UWB; SYSTEM; LOCALIZATION; FUSION
AB Aiming at the problem of high cost and heavy preparation workload of indoor positioning technology, this paper proposes an ambient light-assisted smartphone-based pedestrian dead reckoning (PDR) indoor positioning technology. We propose a group weighted average algorithm to calculate the heading angle of pedestrians, which reduces the positioning error. During the PDR process, the smartphone continuously collects light intensity values, which are used to detect the light source location by using a light detection algorithm. Therefore, PDR has a self-correcting ability. The experimental results show that our method can effectively eliminate the cumulate error of traditional PDR and increase the operation distance. This paper has a certain contribution to the positioning of tunnels, underground shopping malls and other indoor places without sunlight interference.
C1 [Tao, Xiaoxiao] Henan Polytech Univ, Sch Surveying & Land Informat Engn, Jiaozuo 454000, Henan, Peoples R China.
   [Shi, Tianqi; Ma, Xin; Zhang, Haowei] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Luoyu Rd 129, Wuhan 430079, Peoples R China.
   [Pei, Zhipeng] Wuhan Univ, Sch Remote Sensing & Informat Engn, Luoyu Rd 129, Wuhan 430079, Peoples R China.
C3 Henan Polytechnic University; Wuhan University; Wuhan University
RP Shi, TQ (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Luoyu Rd 129, Wuhan 430079, Peoples R China.
EM txx_0607@163.com; shitian@whu.edu.cn; maxinwhu@whu.edu.cn;
   haoweizhang@whu.edu.cn; peisipand@whu.edu.cn
RI SHI, TIANQI/AGH-7938-2022
FU National Natural Science Foundation of China [41971283, 41801261,
   41827801, 41901274, 41801282]; National Key Research and Development
   Program of China [2017YFC0212600]; Open Research Fund of CAS Key
   Laboratory of Spectral Imaging Technology
FX This work was supported by the National Natural Science Foundation of
   China (Grant No.41971283, 41801261, 41827801, 41901274, 41801282), the
   National Key Research and Development Program of China (2017YFC0212600),
   and the Open Research Fund of CAS Key Laboratory of Spectral Imaging
   Technology (No.LSIT201917W).
CR Aguilar-Garcia A, 2015, EURASIP J WIREL COMM, DOI 10.1186/s13638-015-0444-9
   Alavi B, 2006, IEEE COMMUN LETT, V10, P275, DOI 10.1109/LCOMM.2006.04026
   Alletto S, 2016, IEEE INTERNET THINGS, V3, P244, DOI 10.1109/JIOT.2015.2506258
   Bisio I, 2016, PERVASIVE MOB COMPUT, V31, P107, DOI 10.1016/j.pmcj.2016.02.001
   Paterna VC, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122927
   Chen L, 2013, WIRELESS PERS COMMUN, V70, P1735, DOI 10.1007/s11277-012-0777-1
   Dardari D, 2008, IEEE T COMMUN, V56, P1366, DOI 10.1109/TCOMM.2008.050551
   Deng ZA, 2015, SENSORS-BASEL, V15, P21518, DOI 10.3390/s150921518
   Du JZ, 2015, AD HOC SENS WIREL NE, V26, P73
   Faragher R, 2015, IEEE J SEL AREA COMM, V33, P2418, DOI 10.1109/JSAC.2015.2430281
   Faulkner N, 2019, IEEE IMTC P, P1740, DOI 10.1109/i2mtc.2019.8826875
   Feng C, 2012, IEEE T MOBILE COMPUT, V11, P1983, DOI 10.1109/TMC.2011.216
   Hernández N, 2016, J MULT-VALUED LOG S, V26, P221
   Huang CH, 2015, IEEE T INSTRUM MEAS, V64, P728, DOI 10.1109/TIM.2014.2347691
   Lee MS, 2017, INT J CONTROL AUTOM, V15, P627, DOI 10.1007/s12555-015-0342-2
   Lin P, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/371456
   Meissner P, 2014, IEEE WIREL COMMUN LE, V3, P501, DOI 10.1109/LWC.2014.2341636
   Oh J, 2018, ICT EXPRESS, V4, P91, DOI 10.1016/j.icte.2018.04.004
   Shi TQ, 2021, GEOPHYS RES LETT, V48, DOI 10.1029/2020GL091160
   Tesoriero R, 2010, EXPERT SYST APPL, V37, P894, DOI 10.1016/j.eswa.2009.05.062
   Tesoriero R, 2009, IEEE T CONSUM ELECTR, V55, P650, DOI 10.1109/TCE.2009.5174435
   Wang Y, 2019, IEEE SENS J, V19, P2902, DOI 10.1109/JSEN.2018.2888493
   Yao YB, 2018, KSII T INTERNET INF, V12, P3657, DOI 10.3837/tiis.2018.08.007
   Yu JG, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-019-1365-9
   Zhou Y, 2011, IEEE T INSTRUM MEAS, V60, P248, DOI 10.1109/TIM.2010.2049185
NR 25
TC 4
Z9 5
U1 4
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32581
EP 32592
DI 10.1007/s11042-022-13072-y
EA APR 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000782551600003
DA 2024-07-18
ER

PT J
AU Simonetta, F
   Avanzini, F
   Ntalampiras, S
AF Simonetta, Federico
   Avanzini, Federico
   Ntalampiras, Stavros
TI A perceptual measure for evaluating the resynthesis of automatic music
   transcriptions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic music transcription; Audio resynthesis; Music perception;
   Music information retrieval
ID ROOM ACOUSTICS; DURATION; TEMPO; PERFORMANCE; RESPONSES; RATINGS; LEVEL;
   TIME
AB This study focuses on the perception of music performances when contextual factors, such as room acoustics and instrument, change. We propose to distinguish the concept of "performance" from the one of "interpretation", which expresses the "artistic intention". Towards assessing this distinction, we carried out an experimental evaluation where 91 subjects were invited to listen to various audio recordings created by resynthesizing MIDI data obtained through Automatic Music Transcription (AMT) systems and a sensorized acoustic piano. During the resynthesis, we simulated different contexts and asked listeners to evaluate how much the interpretation changes when the context changes. Results show that: (1) MIDI format alone is not able to completely grasp the artistic intention of a music performance; (2) usual objective evaluation measures based on MIDI data present low correlations with the average subjective evaluation. To bridge this gap, we propose a novel measure which is meaningfully correlated with the outcome of the tests. In addition, we investigate multimodal machine learning by providing a new score-informed AMT method and propose an approximation algorithm for the p-dispersion problem.
C1 [Simonetta, Federico; Avanzini, Federico; Ntalampiras, Stavros] Univ Milan, Dept Comp Sci, LIM Mus Informat Lab, Milan, Italy.
C3 University of Milan
RP Simonetta, F (corresponding author), Univ Milan, Dept Comp Sci, LIM Mus Informat Lab, Milan, Italy.
EM Federico.Simonetta@unimi.it; Federico.Avanzini@unimi.it;
   Stavros.Ntalampiras@unimi.it
RI Avanzini, Federico/HCI-9135-2022; Simonetta, Federico/GSN-1308-2022;
   Ntalampiras, Stavros/W-5636-2019
OI Avanzini, Federico/0000-0002-1257-5878; Simonetta,
   Federico/0000-0002-5928-9836; Ntalampiras, Stavros/0000-0003-3482-9215
CR Akbari M, 2015, IEEE T MULTIMEDIA, V17, P2113, DOI 10.1109/TMM.2015.2473702
   Alías F, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6050143
   Benetos E, 2019, IEEE SIGNAL PROC MAG, V36, P20, DOI 10.1109/MSP.2018.2869928
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Bogdanov D, 2013, ACM INT C MULT
   BOLZINGER S, 1994, J PHYS IV, V4, P617, DOI 10.1051/jp4:19945132
   Breebaart J, 2017, J ACOUST SOC AM, V141, pEL526, DOI 10.1121/1.4984044
   Chernick MR., 2011, INT ENCY STAT SCI, DOI DOI 10.1007/978-3-642-04898-2_150
   Contardo C, 2020, INFORMS J OPTIMIZATI
   Dannenberg R.B., 2006, ICMC
   Davies S, 2001, INTERPRETATION, DOI 10.1093/gmo/9781561592630.article.13863
   Devaney J, 2017, ICASSP
   Dreyfus L, 2020, J MUSICOL RES, V39, P161, DOI 10.1080/01411896.2020.1775087
   ERKUT E, 1990, EUR J OPER RES, V46, P48, DOI 10.1016/0377-2217(90)90297-O
   Everitt B. S, 2011, HIERARCHICAL CLUSTER
   Feiten B, 2005, IEEE T MULTIMEDIA, V7, P446, DOI 10.1109/TMM.2005.846793
   Fu ZY, 2011, IEEE T MULTIMEDIA, V13, P303, DOI 10.1109/TMM.2010.2098858
   Gabrielsson A., 1999, The psychology of music, P501602
   Gari SVA, 2019, ANAL TRUMPET PERFORM
   Geringer JM, 2007, J RES MUSIC EDUC, V55, P289, DOI 10.1177/0022429408317366
   Godsill S. J., 1998, Digital Audio Restora- tion
   Goebl Werner, 1999, The Vienna 4x22 Piano Corpus, DOI DOI 10.21939/4X22
   Guido RC, 2019, IEEE SIGNAL PROC MAG, V36, P154, DOI 10.1109/MSP.2018.2874549
   Gutierrez-Parera P, 2018, J ACOUST SOC AM, V143, P2085, DOI 10.1121/1.5031030
   Hawthorne C., 2018, P 19 INT SOC MUS INF, P50
   Inc. P. T., 2015, COLL DAT SCI
   Jeong D, 2020, J AUDIO ENG SOC, V68, P34, DOI 10.17743/jaes.2019.0049
   Jeong D, 2017, 2017 AES INTERNATIONAL CONFERENCE ON SEMANTIC AUDIO
   Jillings N, 2015, SMC
   Kalkandjiev Z S, 2015, THESIS TU BERLIN
   Kalkandjiev Zora Scharer., 2015, Psychomusicology: Music, Mind, and Brain, V25, P195, DOI DOI 10.1037/PMU0000065
   Kato K, 2015, ACTA ACUST UNITED AC, V101, P743, DOI 10.3813/AAA.918870
   Klapuri AP, 2004, J NEW MUSIC RES, V33, P269, DOI 10.1080/0929821042000317840
   Kob M, 2020, ROOM EFFECT MUSICIAN, P223, DOI DOI 10.1007/978-3-030-00386-9_9
   Kwon T., 2017, AUDIO TO SCORE ALIGN
   Luizard P, 2018, SINGERS ADAPT ROOM A
   Marinelli L, 2020, SMC
   Mizumachi M, 2017, J AUDIO ENG SOC
   Mortberg J-E, 2007, IS DITHERED TRUNCATI
   Napoles J, 2009, B COUN RES MUSIC ED, P21
   NAYLOR GM, 1992, ACUSTICA, V75, P256
   Orcalli A, 2001, J NEW MUSIC RES, V30, P307, DOI 10.1076/jnmr.30.4.307.7496
   Potocan Z, 2020, THESIS U LJUBLJANA
   Raffel C., 2014, P ISMIR, P367
   RAVI SS, 1994, OPER RES, V42, P299, DOI 10.1287/opre.42.2.299
   Repp R, 2006, ICMC
   Rizzi A, 2017, IEEE T MULTIMEDIA, V19, P1405, DOI 10.1109/TMM.2017.2674603
   Salvadora S, 2007, INTELL DATA ANAL, V11, P561, DOI 10.3233/IDA-2007-11508
   Schwarz D, 2016, ICMC
   Simonetta F, 2020, SMC
   Simonetta F, 2021, IEEE INT WORKSH MULT, DOI 10.1109/MMSP53017.2021.9733531
   Simonetta F, 2019, 2019 INTERNATIONAL WORKSHOP ON MULTILAYER MUSIC REPRESENTATION AND PROCESSING (MMRP 2019), P10, DOI [10.1109/MMRP.2019.00012, 10.1109/MMRP.2019.8665366]
   Storm W, 1980, PHONOGRAPHIC B
   Tanur JM., 2011, MARGIN ERROR, P765
   Ternstr┬u├em, 1989, VOICE UK, V2, P55
   Ueno K, 2010, ACTA ACUST UNITED AC, V96, P505, DOI 10.3813/AAA.918303
   Ueno K, 2005, ACOUST SCI TECHNOL, V26, P345, DOI 10.1250/ast.26.345
   Ueno K, 2005, ACOUST SCI TECHNOL, V26, P156, DOI 10.1250/ast.26.156
   Von Bekesy G, 1968, FEEDBACK PHENOMENA S
   Wang SY, 2017, IEEE-ACM T AUDIO SPE, V25, P1877, DOI 10.1109/TASLP.2017.2724203
   Wapnick J, 2005, J RES MUSIC EDUC, V53, P162, DOI 10.2307/3345516
   Weinzierl S, 2018, J ACOUST SOC AM, V144, P1347, DOI 10.1121/1.5053113
   Williams M, 2016, RES PERSPECTIVES MUS
   Wu YT, 2019, INT CONF ACOUST SPEE, P166, DOI 10.1109/ICASSP.2019.8682605
   Xu MR, 2019, INT CONF ACOUST SPEE, P221, DOI 10.1109/ICASSP.2019.8683165
   Ycart A, 2020, TISMIR
   Zapata JR, 2014, IEEE-ACM T AUDIO SPE, V22, P816, DOI 10.1109/TASLP.2014.2305252
NR 67
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32371
EP 32391
DI 10.1007/s11042-022-12476-0
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000783454600008
PM 35437421
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Bhadoria, RS
   Samanta, S
   Pathak, Y
   Shukla, PK
   Zubi, AA
   Kaur, M
AF Bhadoria, Robin Singh
   Samanta, Sovan
   Pathak, Yadhunath
   Shukla, Piyush Kumar
   Zubi, Ahmad Ali
   Kaur, Manjit
TI Bunch graph based dimensionality reduction using auto-encoder for
   character recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bunch graph; Auto-encoders; Dimensionality reduction; Noise reduction;
   Convolution neural network; Character recognition
ID AUTOENCODER; CYCLES
AB Sometimes a group of similar types of dimensions is also treated as nodes. However, these groups can be considered as bunch nodes which may contain several nodes. This paper also justifies the study on bunch graphs which introduced a concept of graphs. where bunch nodes are also allowed. The auto-encoder, a specific type of feedforward neural network generally applied for encoding data in an unsupervised learning methodology to achieve good performance and better-classified data. This kind of network is composed of an encoder and decoder. The encoder compresses the data to an extent or layer, and then from that central layer decoder starts reconstructing the original data. This paper also investigates the dimensionality reduction ability of auto-encoders for character recognition and manipulates the results to accomplish better handling side of auto-encoders. This paper also focuses on the abilities of auto-encoders to reduce noise in data along with dimensionality reduction, trying to interpret the difference between results generated using bunch graph cut techniques. The dataset associated with computing for implementation purposes has been taken from MNIST dataset. Mainly, the two-dimensional plots are used in this paper for comparing results gen crated associated with different parameters that help in recognizing the character as partial and non-partial separabilities.
C1 [Bhadoria, Robin Singh] GLA Univ, Dept Comp Engn & Applict, Mathura 281406, Uttar Pradesh, India.
   [Samanta, Sovan] Tamralipta Mahavidyalaya, Dept Math, Tamlu 721636, W Bengal, India.
   [Pathak, Yadhunath] Indian Inst Informat Technol IIIT Bhopal, Dept Informat Technol, Bhimtal, India.
   [Shukla, Piyush Kumar] Univ Inst Technol RGPV, Dept Comp Sci & Engn, Bhopal, India.
   [Zubi, Ahmad Ali] King Saud Univ, Community Coll, Comp Sci Dept, Riyadh, Saudi Arabia.
   [Kaur, Manjit] Gwangju Inst Sci & Technol, Sch Elect Engn & Comp Sci, Gwangju, South Korea.
C3 GLA University; Rajiv Gandhi Technological University; King Saud
   University; Gwangju Institute of Science & Technology (GIST)
RP Kaur, M (corresponding author), Gwangju Inst Sci & Technol, Sch Elect Engn & Comp Sci, Gwangju, South Korea.
EM manjit@ieee.org
RI Shukla, Dr. Piyush Kumar/GVT-3949-2022; PATHAK, YADUNATH/AFR-0689-2022;
   user, user/GLQ-6797-2022; Samanta, Sovan/C-6054-2017; Bhadoria, Robin
   Singh/H-4324-2013
OI Shukla, Dr. Piyush Kumar/0000-0002-3715-3882; PATHAK,
   YADUNATH/0000-0002-4062-7858; Samanta, Sovan/0000-0003-3200-8990;
   Bhadoria, Robin Singh/0000-0002-6314-4736
FU King Saud University, Riyadh, Saudi Arabia [RSP-2021/395]
FX This work was supported by the Researchers Supporting Project (No.
   RSP-2021/395), King Saud University, Riyadh, Saudi Arabia.
CR Almotiri J, 2017, 2017 IEEE LONG ISLAND SYSTEMS, APPLICATIONS AND TECHNOLOGY CONFERENCE (LISAT)
   Bae SW, 2018, THEOR COMPUT SCI, V745, P36, DOI 10.1016/j.tcs.2018.05.029
   Ben Ali R, 2020, MULTIMED TOOLS APPL, V79, P25237, DOI 10.1007/s11042-020-09056-5
   Chen XW, 2019, CLUSTER COMPUT, V22, P13293, DOI 10.1007/s10586-018-1848-1
   Chenna, 2016, THESIS
   CHHAJRO MA, 2020, INDIAN J SCI TECHNOL, V13, P1746, DOI DOI 10.17485/IJST/v13i17.113
   Dai X, 2021, MULTIMED TOOLS APPL, P1
   Dougherty AL, 2020, DISCRETE APPL MATH, V284, P20, DOI 10.1016/j.dam.2020.03.010
   Dvorak T, 1997, DISCRETE MATH, V171, P89
   Feng J, 2018, AAAI CONF ARTIF INTE, P2967
   Gnouma M, 2019, MULTIMED TOOLS APPL, V78, P2157, DOI 10.1007/s11042-018-6273-1
   Gogna A, 2019, NEURAL PROCESS LETT, V49, P1723, DOI 10.1007/s11063-018-9894-5
   Hell P, 2020, DISCRETE APPL MATH, V282, P271, DOI 10.1016/j.dam.2020.03.013
   Hoffmann H, 2007, PATTERN RECOGN, V40, P863, DOI 10.1016/j.patcog.2006.07.009
   Kajla NI, 2021, IEEE ACCESS, V9, P99103, DOI 10.1109/ACCESS.2021.3096845
   Koutsoukas A, 2017, J CHEMINFORMATICS, V9, DOI 10.1186/s13321-017-0226-y
   Kumari S, 2021, INT J INTELL SYST, V36, P2412, DOI 10.1002/int.22384
   Li ZY, 2020, AAAI CONF ARTIF INTE, V34, P4804
   Liu ZJ, 2020, APPL NETW SCI, V5, DOI 10.1007/s41109-019-0248-7
   Maity A, 2021, SOC NETW ANAL MIN, V11, DOI 10.1007/s13278-021-00721-7
   Namasudra S, 2023, NEURAL PROCESS LETT, V55, P171, DOI 10.1007/s11063-021-10495-w
   Öztürk S, 2020, EXPERT SYST APPL, V161, DOI 10.1016/j.eswa.2020.113693
   Prakash S, 2014, OPSEARCH, V51, P183, DOI 10.1007/s12597-013-0143-4
   Qi JK, 2021, J CHEM ENG JPN, V54, P144, DOI 10.1252/jcej.19we235
   Ramamurthy M, 2020, MICROPROCESS MICROSY, V79, DOI 10.1016/j.micpro.2020.103280
   Rifai S., 2011, CONTRACTIVE AUTOENCO, DOI DOI 10.5555/3104482.3104587
   Samanta S, 2022, INFORM SCIENCES, V589, P1, DOI 10.1016/j.ins.2021.12.025
   Samanta S, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/2517415
   Samanta S, 2018, J INTELL FUZZY SYST, V35, P3413, DOI 10.3233/JIFS-17322
   Vineeth Menta Sai, 2020, Ambient Communications and Computer Systems. RACCCS 2019. Advances in Intelligent Systems and Computing (AISC 1097), P15, DOI 10.1007/978-981-15-1518-7_2
   Wang YS, 2016, NEUROCOMPUTING, V184, P232, DOI 10.1016/j.neucom.2015.08.104
   Xu JY, 2020, COMPUT METHOD APPL M, V372, DOI 10.1016/j.cma.2020.113379
   Yang F, 2020, IEEE SIGNAL PROC LET, V27, P331, DOI 10.1109/LSP.2020.2970539
   Yang MR, 2021, MULTIMED TOOLS APPL, V80, P17365, DOI 10.1007/s11042-020-09019-w
   Zhang GJ, 2020, FRONT COMPUT SCI-CHI, V14, P430, DOI 10.1007/s11704-018-8052-6
NR 35
TC 4
Z9 4
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32093
EP 32115
DI 10.1007/s11042-022-12907-y
EA APR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781941600004
DA 2024-07-18
ER

PT J
AU Jarrahi, A
   Safari, L
AF Jarrahi, Ali
   Safari, Leila
TI Evaluating the effectiveness of publishers' features in fake news
   detection on social media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fake news detection; CreditRank algorithm; Social media; Deep neural
   network; Machine learning; Text classification
ID INFORMATION
AB With the expansion of the Internet and attractive social media infrastructures, people prefer to follow the news through these media. Despite the many advantages of these media in the news field, the lack of control and verification mechanism has led to the spread of fake news as one of the most critical threats to democracy, economy, journalism, health, and freedom of expression. So, designing and using efficient automated methods to detect fake news on social media has become a significant challenge. One of the most relevant entities in determining the authenticity of a news statement on social media is its publishers. This paper examines the publishers' features in detecting fake news on social media, including Credibility, Influence, Sociality, Validity, and Lifetime. In this regard, we propose an algorithm, namely CreditRank, for evaluating publishers' credibility on social networks. We also suggest a high accurate multi-modal framework, namely FR-Detect, for fake news detection using user-related and content-related features. Furthermore, a sentence-level convolutional neural network is provided to properly combine publishers' features with latent textual content features. Experimental results show that the publishers' features can improve the performance of content-based models by up to 16% and 31% in accuracy and F1, respectively. Also, the behavior of publishers in different news domains has been statistically studied and analyzed.
C1 [Jarrahi, Ali; Safari, Leila] Univ Zanjan, Elect & Comp Engn, Zanjan, Iran.
C3 University Zanjan
RP Jarrahi, A (corresponding author), Univ Zanjan, Elect & Comp Engn, Zanjan, Iran.
EM jarrahi@znu.ac.ir; lsafari@znu.ac.ir
OI Jarrahi, Ali/0000-0002-4969-3624; Safari, Leila/0000-0002-2872-0937
CR Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Apuke OD, 2021, TELEMAT INFORM, V56, DOI 10.1016/j.tele.2020.101475
   Baly R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3528
   Berahmand K, 2022, J KING SAUD UNIV-COM, V34, P5375, DOI 10.1016/j.jksuci.2021.05.006
   Bhutani B, 2019, 2019 12 INT C CONT C, P1, DOI DOI 10.1109/IC3.2019.8844880
   BOEHM LE, 1994, PERS SOC PSYCHOL B, V20, P285, DOI 10.1177/0146167294203006
   Bondielli A, 2019, INFORM SCIENCES, V497, P38, DOI 10.1016/j.ins.2019.05.035
   Choudhary A, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114171
   Choudhary M, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107614
   Cui LM, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2961, DOI 10.1145/3357384.3357862
   Cui LM, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P41, DOI 10.1145/3341161.3342894
   D'Ulizia A, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.518
   de Oliveira NR, 2021, INFORMATION, V12, DOI 10.3390/info12010038
   Goldani MH, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102418
   Hakak S, 2021, FUTURE GENER COMP SY, V117, P47, DOI 10.1016/j.future.2020.11.022
   Hinton G. E., 2012, 12070580 ARXIV
   Hosseinzadeh S, 2019, POLYM BULL, V76, P4827, DOI 10.1007/s00289-018-2618-1
   Jiang T, 2021, IEEE ACCESS, V9, P22626, DOI 10.1109/ACCESS.2021.3056079
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Kaliyar RK, 2021, MULTIMED TOOLS APPL, V80, P11765, DOI 10.1007/s11042-020-10183-2
   Kaliyar RK, 2021, J SUPERCOMPUT, V77, P1015, DOI 10.1007/s11227-020-03294-y
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Karimi, 2019, ARXIV PREPRINT ARXIV
   Kim Y., 2014, P 2014 C EMP METH NA, P1746, DOI [DOI 10.3115/V1/D14-1181, 10.3115/v1/D14-1181]
   King DB, 2015, ACS SYM SER, V1214, P1
   Leibenstein H, 1950, Q J ECON, V64, P183, DOI 10.2307/1882692
   Mihalcea, 2017, AUTOMATIC DETECTION
   Mihalcea Rada, 2009, P ACL IJCNLP 2009 C, P309, DOI [10.3115/1667583.1667679, DOI 10.3115/1667583.1667679]
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Mitra Tanushree, 2015, P 9 INT C WEB SOC ME, V9, P258, DOI DOI 10.1609/ICWSM.V9I1.14625
   Mouratidis D, 2021, COMPUTATION, V9, DOI 10.3390/computation9020020
   Nasir J.A., 2021, International Journal of Information Management Data Insights, V1, P100007, DOI [10.1016/j.jjimei.2020.100007, DOI 10.1016/J.JJIMEI.2020.100007]
   Nickerson R. S., 1998, REV GEN PSYCHOL, V2, P175, DOI DOI 10.1037/1089-2680.2.2.175
   Ozbay FA, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123174
   Page L., 1999, PAGERANK CITATION RA, DOI DOI 10.1109/IISWC.2012.6402911
   Parikh SB, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P436, DOI 10.1109/MIPR.2018.00093
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Qian F, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3834
   Rapoza K., 2017, FORBES
   Reis JCS, 2019, IEEE INTELL SYST, V34, P76, DOI 10.1109/MIS.2019.2899143
   Rubin V.L., 2015, P HAW INT C SYST SCI, P5
   Rubin Victoria L., 2015, Proceedings of the Association for Information Science and Technology, V52, P1, DOI [10.1002/pra2.2015.145052010083, DOI 10.1002/PRA2.2015.145052010083]
   Rubin VL, 2010, P 73 ASIS T ANN M NA, V47
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Saleh H, 2021, IEEE ACCESS, V9, P129471, DOI 10.1109/ACCESS.2021.3112806
   Sharma D, 2021, CEREAL RES COMMUN, V49, P663, DOI 10.1007/s42976-021-00139-z
   Shu K., 2017, ACM SIGKDD EXPLOR NE, V19, P22, DOI [DOI 10.1145/3137597.3137600, 10.1145/3137597.3137600]
   Shu K, 2021, IEEE INTELL SYST, V36, P96, DOI 10.1109/MIS.2020.2997781
   Shu K, 2020, BIG DATA, V8, P171, DOI 10.1089/big.2020.0062
   Shu K, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P436, DOI 10.1145/3341161.3342927
   Singhal S, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P39, DOI [10.1109/BigMM.2019.00-44, 10.1109/BigMM.2019.00018]
   Singhania S, 2017, LECT NOTES COMPUT SC, V10635, P572, DOI 10.1007/978-3-319-70096-0_59
   Sitaula N., 2020, Disinformation, Misinformation, and Fake News in Social Media: Emerging Research Challenges and Opportunities, P163
   Huynh TLD, 2020, ECON BULL, V40, P758
   Varma R, 2021, INT J INTELL COMPUT, V14, P617, DOI 10.1108/IJICC-04-2021-0069
   Verma A., 2019, 2019 12 INT C CONT C, P1
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wang ZH, 2020, NEUROCOMPUTING, V397, P224, DOI 10.1016/j.neucom.2020.01.095
   Xu Y, 2021, MEASUREMENT, V169, DOI 10.1016/j.measurement.2020.108502
   Yang CF, 2016, IEEE IC COMP COM NET
   Yang S, 2019, AAAI CONF ARTIF INTE, P5644
   Yang Y., 2018, ARXIV PREPRINT ARXIV, DOI DOI 10.1115/FEDSM2018-83038
   Zhang JW, 2020, PROC INT CONF DATA, P1826, DOI 10.1109/ICDE48307.2020.00180
   Zhang XC, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.03.004
   Zhou X., 2020, DIGITAL THREATS RES, V1, P1
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
   Zhou XY, 2020, LECT NOTES ARTIF INT, V12085, P354, DOI 10.1007/978-3-030-47436-2_27
   Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603
NR 71
TC 16
Z9 16
U1 3
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2913
EP 2939
DI 10.1007/s11042-022-12668-8
EA APR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000779973300002
PM 35431607
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Mehta, P
   Tripathi, RK
AF Mehta, Preeti
   Tripathi, Rajiv Kumar
TI Near-duplicate detection for LCD screen acquired images using edge
   histogram descriptor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image forensics; Blurriness; Aliasing; Edge histogram
   descriptor; Near-duplicate image; Recapture detection; SVM classifier
ID FORENSICS
AB The expressive ability of digital visual media with the simplicity of their acquisition, processing, distribution, manipulation, and storage is such that they are utilized more to convey information over other sources of the information carriers. Formerly and conventionally, there has been credence in the authenticity of digital visual media. Still, with the availability of inexpensive and easy to use digital devices with high-resolution cameras coming in handy in mobile phones and the availability of low-cost and user-convenient editing tools, visual media forgery is ubiquitous. In general, forgery introduces certain artifacts in digital images. The recapturing process eliminates those artifacts and misleads the forensic system. The research work proposed in this paper presents a novel technique for the detection of near-duplicate images by examining the edge profile obtained by the edge histogram descriptor. The difference between the numbers of grouped directional edges present in singly captured and the near-duplicate image is used to build the feature vectors. Based on the training of those feature vectors, a model is generated using the SVM classifier. The proposed method is tested on three datasets of high-resolution and high-quality near-duplicate images, namely, NTU-ROSE, ICL, and Mturk. The evaluated results exemplify that the technique proposed is comparatively better than the state-of-the-art methods for near-duplicate detection. Features extracted from the image of vector length 91 allows an SVM classifier to achieve the precision of 100% and selectivity value above 97%. Furthermore, our results show that the proposed method achieves a performance rate that exceeds the overall accuracy of 99% for all three datasets.
C1 [Mehta, Preeti; Tripathi, Rajiv Kumar] Natl Inst Technol, Delhi, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Delhi
RP Mehta, P (corresponding author), Natl Inst Technol, Delhi, India.
EM preetimehta@nitdelhi.ac.in; rajivtripathi@nitdelhi.ac.in
OI Mehta, Preeti/0000-0002-8539-3741
CR Agarwal S, 2018, DIVERSE LARGE SCALE
   Anjum A, 2020, MULTIMED TOOLS APPL, V79, P6965, DOI 10.1007/s11042-019-08418-y
   [Anonymous], 2003, 2003 C COMPUTER VISI, DOI [DOI 10.1109/CVPRW.2003.10093, DOI 10.1109/CVPRW.2003.10093.27.T.-T]
   [Anonymous], 2018, MATLAB and Statistics Toolbox Release
   [Anonymous], 2017, Electron. Imaging
   Bai JM, 2010, IEEE INT SYMP CIRC S, P3425, DOI 10.1109/ISCAS.2010.5537866
   Cao H., 2010, ROSE RECAPTURED IMAG
   Cao H, 2010, INT CONF ACOUST SPEE, P1790, DOI 10.1109/ICASSP.2010.5495419
   Chen RC, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00327-4
   Edmunds T, 2018, IET BIOMETRICS, V7, P27, DOI 10.1049/iet-bmt.2017.0077
   Gao XT, 2010, IEEE INT CON MULTI, P1469, DOI 10.1109/ICME.2010.5583280
   Gloe T., 2007, Proceedings of the 15th international conference on Multimedia, P78, DOI [10.1145/1291233.1291252, DOI 10.1145/1291233.1291252]
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hajj-Ahmad A, 2017, IEEE T INF FOREN SEC, V12, P89, DOI 10.1109/TIFS.2016.2603603
   Hong C, 2010, THESIS NANYANG TECHN
   Moreira-Pérez JJ, 2013, IEEE INT WORKS INFOR, P132, DOI 10.1109/WIFS.2013.6707807
   Jung DJ, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0096-z
   Ke Y., 2013, INT J MULTIMEDIA UBI, V8, P71, DOI DOI 10.14257/IJMUE.2013.8.5.08
   Kim I, 2016, IEEE SYS MAN CYBERN, P4299, DOI 10.1109/SMC.2016.7844907
   Kose N, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P1027, DOI 10.1109/ICIEV.2012.6317336
   Li HR, 2021, MEMET COMPUT, V13, P1, DOI 10.1007/s12293-021-00328-7
   Li HR, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106593
   Luan X, 2017, 2017 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P429, DOI 10.1109/SPAC.2017.8304317
   Mahdian B, 2015, DETECTING CYCLOSTATI, V6, P1
   Muammar H, 2013, INT CONF ACOUST SPEE, P2242, DOI 10.1109/ICASSP.2013.6638053
   Patel K, 2015, INT CONF BIOMETR, P98, DOI 10.1109/ICB.2015.7139082
   Pinheiro AMG, 2009, PROCEEDINGS 2009 FOURTH INTERNATIONAL WORKSHOP ON SEMANTIC MEDIA ADAPTATION AND PERSONALIZATION, P73, DOI 10.1109/SMAP.2009.27
   Quan Q, 2021, VISUAL COMPUT, V37, P245, DOI 10.1007/s00371-020-01796-7
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Ruihan Li, 2016, Digital Forensics and Watermarking. 14th International Workshop, IWDW 2015. Revised Selected Papers: LNCS 9569, P107, DOI 10.1007/978-3-319-31960-5_10
   Shang YY, 2021, COMPUT GRAPH-UK, V95, P47, DOI 10.1016/j.cag.2021.01.008
   Sharma Neha, 2018, Procedia Computer Science, V132, P377, DOI 10.1016/j.procs.2018.05.198
   Thongkamwitoon T, 2014, RECAPTURE IMAGE DATA
   Thongkamwitoon T, 2015, IEEE T INF FOREN SEC, V10, P953, DOI 10.1109/TIFS.2015.2392566
   Visentini-Scarzanella M, 2013, IEEE INT WORKSH MULT, P412, DOI 10.1109/MMSP.2013.6659324
   Wang K, 2017, DIGIT INVEST, V23, P75, DOI 10.1016/j.diin.2017.10.001
   Won CS, 2004, LECT NOTES COMPUT SC, V3333, P583
   Yang PP, 2017, LECT NOTES COMPUT SC, V10431, P31, DOI 10.1007/978-3-319-64185-0_3
   Yang PP, 2017, LECT NOTES COMPUT SC, V10082, P119, DOI 10.1007/978-3-319-53465-7_9
   Yasmin M, 2013, J APPL RES TECHNOL, V11, P727, DOI 10.1016/S1665-6423(13)71581-5
   Yin J., 2012, P 20 ACM INT C MULT, P1113
   Yin J, 2012, PROC SPIE, V8303, DOI 10.1117/12.907597
   Yu H, 2008, IEEE IMAGE PROC, P3140, DOI 10.1109/ICIP.2008.4712461
   YUE H, 2020, IEEE T CIRC SYST VID
   Zhai XB, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2013), P234, DOI 10.1109/IIH-MSP.2013.67
   Zhang LB, 2018, J VIS COMMUN IMAGE R, V51, P56, DOI 10.1016/j.jvcir.2018.01.001
NR 46
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30977
EP 30995
DI 10.1007/s11042-022-12637-1
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000781336500015
DA 2024-07-18
ER

PT J
AU Sahu, AK
   Gutub, A
AF Sahu, Aditya Kumar
   Gutub, Adnan
TI Improving grayscale steganography to protect personal information
   disclosure within hotel services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cybercrime; Confidentiality; Attack; Hospitality; Steganography
ID IMAGE STEGANOGRAPHY; SECURITY
AB An unauthorized leak of information that is not tolerable always implies inadequate or poor security measures of information. Globally, the hospitality industry has in the recent past been targeted by cybercrimes. Management of cybercrimes are divided into facets like policies of security frameworks, cyber-threats, and management appreciating the value of Information Technology investment. These aspects possess a notable influence on the information security of an organization. This study's purpose is to examine cybersecurity activities of network threats, electronic information, and the techniques of preventing cybercrime in hotels. Helping Chief Information Officers (CIO) and the directors of information technology is the main aim of the research to improve policy for electronic information security in the hospitality industry and recommending several tools and techniques to stabilize the network of computers. Further, to protect personal information disclosure for the visitors, an information hiding technique has been proposed by utilizing the least significant bits (LSBs) of each pixel of grayscale image adopting XOR features of the host image (HI) pixels. Also, the proposed technique successfully withstands various steganalysis attacks like regular and singular (RS) attack, pixel difference histogram (PDH) attack, and subtractive pixel adjacency matrix (SPAM) steganalysis.
C1 [Sahu, Aditya Kumar] Vignans Fdn Sci Technol & Res, Dept CSE, Guntur 522213, Andhra Pradesh, India.
   [Gutub, Adnan] Umm Al Qura Univ, Dept Comp Engn, Mecca, Saudi Arabia.
C3 Vignan's Foundation for Science, Technology & Research (VFSTR); Umm Al
   Qura University
RP Gutub, A (corresponding author), Umm Al Qura Univ, Dept Comp Engn, Mecca, Saudi Arabia.
EM adityasahu.cse@gmail.com; aagutub@uqu.edu.sa
RI Gutub, Adnan Abdul-Aziz/O-1240-2016; Sahu, Dr. Aditya Kumar/P-8681-2015
OI Gutub, Adnan Abdul-Aziz/0000-0003-0923-202X; Sahu, Dr. Aditya
   Kumar/0000-0003-4257-0688
CR Abu-Hashem M, 2022, CAAI T INTELL TECHNO, V7, P278, DOI 10.1049/cit2.12070
   Al-Roithy BO, 2021, MULTIMED TOOLS APPL, V80, P28521, DOI 10.1007/s11042-021-11051-3
   Al-Shaarani F., 2020, RAS Engineering and Technology, V1, P1
   Al-Shaarani F, 2022, ARAB J SCI ENG, V47, P2455, DOI 10.1007/s13369-021-06165-7
   Almehmadi E, 2022, ARAB J SCI ENG, V47, P2585, DOI 10.1007/s13369-021-06200-7
   Almutairi S., 2019, Review of Business and Technology Research (RBTR), V16, P43
   ALSHAARANI F, 2021, J KING SAUD U COMPUT
   [Anonymous], 2021, Database
   Bin Hureib ES, 2020, INT J COMPUT SCI NET, V20, P1
   Enescu, 2016, UNWANTED GUESTS HACK
   Facchini, 2016, CYBERSECURITY HOSPIT
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   GUTUB A, 2022, PAMUKKALE U J ENG SC
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub A, 2022, INT J INF SECUR PRIV, V16, DOI 10.4018/IJISP.2022010118
   Gutub A, 2020, ARAB J SCI ENG, V45, P2631, DOI 10.1007/s13369-020-04413-w
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Gutub AAA, 2007, PROC WRLD ACAD SCI E, V21, P28
   Gutub AAA, 2022, MULTIMED TOOLS APPL, DOI 10.1007/s11042-022-12062-4
   Gwebu K, 2020, J HOSP TOUR TECHNOL, V11, P511, DOI 10.1108/JHTT-11-2019-0138
   Hassan FS, 2020, MULTIMED TOOLS APPL, V79, P30087, DOI 10.1007/s11042-020-09513-1
   Hemavathy, 2005, CYBERCRIMINAL ACTIVI
   Hilliard TW, 2008, J CONV EVENT TOUR, V9, P15, DOI 10.1080/15470140802104557
   Ip C, 2011, INT J CONTEMP HOSP M, V23, P533, DOI 10.1108/09596111111130029
   Kheshaifaty N., 2021, J ENG RES-KUWAIT
   Khodaei M, 2012, IET IMAGE PROCESS, V6, P677, DOI 10.1049/iet-ipr.2011.0059
   King, 2017, TRAVEL WEEKLY
   Koegler S., 2017, How hotel cybersecurity keeps guests and data secure
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Muraya, THESIS MOI U
   Papanikolaou A., 2014, TELFOR J, V6, P86, DOI DOI 10.5937/TELFOR1402086P
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Sahu AK, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2021.102808
   Sahu AK, 2019, 3D RES, V10, DOI 10.1007/s13319-018-0211-x
   Samkari H., 2019, Recent Trends in Information Technology and Its Application, V2, P1, DOI DOI 10.5281/ZENODO.3543455
   Seamans E., 2018, The unique challenges of data security in the hospitality industry
   Shabani, 2017, ARXIV PREPRINT ARXIV
   Shambour M.K., 2022, HAJJ RES FOR MAD SAU, P254
   Shambour M.K.Y., 2021, J ENG RES-KUWAIT
   Shambour MK, 2022, ARAB J SCI ENG, V47, P1253, DOI 10.1007/s13369-021-05838-7
   Singh A, 2022, ARAB J SCI ENG, V47, P9801, DOI 10.1007/s13369-021-06348-2
   Swain G, 2016, PROCEDIA COMPUT SCI, V85, P31, DOI 10.1016/j.procs.2016.05.173
   The Network Support Company, 2017, CYB HOSP IND
   Trust Wave, 2016, HOSP CROSSH CYB
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu NI, 2017, IMAGING SCI J, V65, P371, DOI 10.1080/13682199.2017.1355089
   Yallop A, 2020, J TOUR FUTURES, V6, P257, DOI 10.1108/JTF-10-2019-0108
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Zakaria AA, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8112199
NR 54
TC 19
Z9 19
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30663
EP 30683
DI 10.1007/s11042-022-13015-7
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779229700006
DA 2024-07-18
ER

PT J
AU Raponi, S
   Oligeri, G
   Ali, IM
AF Raponi, Simone
   Oligeri, Gabriele
   Ali, Isra Mohamed
TI Sound of guns: digital forensics of gun audio samples meets artificial
   intelligence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia Forensics; AI-driven Forensics; Gun Audio Sample
   Classification; Convolutional Neural Network
ID WEAPON CLASSIFICATION; NEURAL-NETWORKS
AB Classifying a weapon based on its muzzle blast is a challenging task that has significant applications in various security and military fields. Most of the existing works rely on ad-hoc deployment of spatially diverse microphone sensors to capture multiple replicas of the same gunshot, which enables accurate detection and identification of the acoustic source. However, carefully controlled setups are difficult to obtain in scenarios such as crime scene forensics, making the aforementioned techniques inapplicable and impractical. We introduce a novel technique that requires zero knowledge about the recording setup and is completely agnostic to the relative positions of both the microphone and shooter. Our solution can identify the category, caliber, and model of the gun, reaching over 90% accuracy on a dataset composed of 3655 samples that are extracted from YouTube videos. Our results demonstrate the effectiveness and efficiency of applying Convolutional Neural Network (CNN) in gunshot classification eliminating the need for an ad-hoc setup while significantly improving the classification performance.
C1 [Raponi, Simone; Oligeri, Gabriele; Ali, Isra Mohamed] Hamad Bin Khalifa Univ, Div Informat & Comp Technol, Coll Sci & Engn, Doha, Qatar.
C3 Qatar Foundation (QF); Hamad Bin Khalifa University-Qatar
RP Raponi, S (corresponding author), Hamad Bin Khalifa Univ, Div Informat & Comp Technol, Coll Sci & Engn, Doha, Qatar.
EM sraponi@hbku.edu.qa; goligeri@hbku.edu.qa; isali@hbku.edu.qa
OI Raponi, Simone/0000-0002-1813-546X; Ali, Isra/0000-0002-2689-348X
FU QNRF-Qatar National Research Fund, a member of The Qatar Foundation
   [NPRP12S-0125-190013]; Innovation Research Project "Anti-Spoofers - GPS
   Spoofing Detection Exploiting Crowd-Sourced Information" - HBKU
   Innovation Center
FX This publication was partially supported by the following awards:
   NPRP12S-0125-190013 from QNRF-Qatar National Research Fund, a member of
   The Qatar Foundation, and the Innovation Research Project "Anti-Spoofers
   - GPS Spoofing Detection Exploiting Crowd-Sourced Information" awarded
   by the HBKU Innovation Center. The information and views set out in this
   publication are those of the authors and do not necessarily reflect the
   official opinion of the QNRF.
CR [Anonymous], 2014, Improved Musical Onset Detection with Convolutional Neural Networks, DOI DOI 10.1109/ICASSP.2014.6854953
   Costa YMG, 2017, APPL SOFT COMPUT, V52, P28, DOI 10.1016/j.asoc.2016.12.024
   Dennis J, 2011, IEEE SIGNAL PROC LET, V18, P130, DOI 10.1109/LSP.2010.2100380
   Djeddou M, 2013, ARAB J SCI ENG, V38, P3399, DOI 10.1007/s13369-013-0655-5
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Khan S, 2010, PROC SPIE, V7666, DOI 10.1117/12.850185
   Khan S, 2009, PROC SPIE, V7305, DOI 10.1117/12.818375
   Kiktova E, 2015, I W BIOMETRIC FORENS, DOI 10.1109/IWBF.2015.7110240
   Kim Y, 2016, IEEE GEOSCI REMOTE S, V13, P8, DOI 10.1109/LGRS.2015.2491329
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Libal U, 2014, EXPERT SYST APPL, V41, P5097, DOI 10.1016/j.eswa.2014.02.037
   Morton Jr K D, 2011, SENSORS COMMAND CONT, V8019
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Navratil Milan, 2011, 13th WSEAS International Conference on Automatic Control, Modelling & Simulations (ACMOS 2011). Recent Researches in Automatic Control, P262
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Ravì D, 2016, INT CONF WEARAB IMPL, P71, DOI 10.1109/BSN.2016.7516235
   Saleem S, 2020, FORENS SCI INT-DIGIT, V34, DOI 10.1016/j.fsidi.2020.300982
   Sallai J, 2011, P 9 ACM C EMB NETW S, P96
   Sallai J, 2011, J SYST ARCHITECT, V57, P869, DOI 10.1016/j.sysarc.2011.04.003
   Sánchez-Hevia HA, 2017, IEEE-ACM T AUDIO SPE, V25, P1172, DOI 10.1109/TASLP.2017.2690579
   Satt A, 2017, INTERSPEECH, P1089, DOI 10.21437/Interspeech.2017-200
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Volgyesi P, 2007, MOBISYS '07: PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P113
   Wyse L., 2017, P 1 INT C DEEP LEARN, P37
NR 28
TC 10
Z9 10
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30387
EP 30412
DI 10.1007/s11042-022-12612-w
EA APR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000778917900002
OA Green Published, hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Meenakshi, A
   Ruth, JA
   Kanagavalli, VR
   Uma, R
AF Meenakshi, A.
   Ruth, J. Anitha
   Kanagavalli, V. R.
   Uma, R.
TI Automatic classification of white blood cells using deep features based
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE White blood cells; Mayfly; Velocity; RNN; Classification; Statistical
   measurements; Feature extraction and feature selection
ID SEGMENTATION; IMAGES
AB White blood cells (WBCs) are widely presented in human body which plays an important role in the human body immune system. Recently, the incidence of blood diseases related to WBC increases in the human body. The optimal WBC count given useful information for the diagnosis of the blood disease and it has become a popular field of research applications. Hence, in this paper, Deep Features based Convolutional Neural Network (DFCNN) is developed to identify the count of WBC from the image database. The proposed method is working with three phases such as feature extraction, feature selection and classification phases. In the feature extraction phase, the Combined CNN structure is designed which combination of AlexNet, GoogLeNet and ResNet-50 respectively. The combined CNN architecture is utilized to extract 3000 essential features from the images database. In the feature selection phase, hybrid Mayfly Algorithm with Particle Swarm Optimization (HMA-PSO) is designed for selecting the essential feature from the feature sets. In the HMA-PSO algorithm, the velocity updating of mayfly is achieved with the help of PSO algorithm. The selected features are sent to the proposed classifier which named as Recurrent Neural Network- Long Short-Term Memory (RNN-LSTM). This classifier is utilized to classify the WBC types such as Neutrophils, Eosinophils, Monocytes and Lymphocytes respectively. The proposed method is implemented in MATLAB and performances are evaluated by statistical measurements such as accuracy, precision, recall, specificity and F_Measure. The proposed method is compared with the existing methods such as MA-RNN and PSO-RNN respectively. The proposed methodology has been achieved best performance metrics such as recall: 0.98, precision: 0.9 and accuracy; 0.97.
C1 [Meenakshi, A.] SRMIST, Dept Comp Sci & Applicat, Chennai, Tamil Nadu, India.
   [Ruth, J. Anitha] SRM Inst Sci & Technol, Dept Comp Sci, Chennai, Tamil Nadu, India.
   [Kanagavalli, V. R.] Sri Sai Ram Engn Coll, Dept Humanities & Sci, Chennai, Tamil Nadu, India.
   [Uma, R.] Sri Sairam Engn Coll, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai; SRM Institute of Science
   & Technology Chennai; Sri Sai Ram Engineering College; Sri Sai Ram
   Engineering College
RP Meenakshi, A (corresponding author), SRMIST, Dept Comp Sci & Applicat, Chennai, Tamil Nadu, India.
EM meenaksa@srmist.edu.in
RI R, UMA/AAX-2131-2021; Uma, R./AAY-6998-2021; V R,
   Kanagavalli/AAB-4660-2022
OI V R, Kanagavalli/0000-0003-0757-5547; AYYATHURAI,
   MEENAKSHI/0000-0002-5404-6552
CR Abdurrazzaq A, 2021, MULTIMED TOOLS APPL, V80, P4627, DOI 10.1007/s11042-020-09946-8
   Alagu S., 2021, Innovations in Computational Intelligence and Computer Vision. Proceedings of ICICV 2020. Advances in Intelligent Systems and Computing (AISC 1189), P403, DOI 10.1007/978-981-15-6067-5_45
   Almiani M, 2020, SIMUL MODEL PRACT TH, V101, DOI 10.1016/j.simpat.2019.102031
   Bani-Hani D., 2018, in Proc. 7th Annu. World Conf. Soc. Ind. Syst. Eng, P1
   Banik PP, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113211
   Bhattacharyya T, 2020, IEEE ACCESS, V8, P195929, DOI 10.1109/ACCESS.2020.3031718
   Buxhofer-Ausch V, 2021, EUR J HAEMATOL, V106, P58, DOI 10.1111/ejh.13516
   Di Ruberto C, 2020, COMPUT BIOL MED, V116, DOI 10.1016/j.compbiomed.2019.103530
   Fischer T, 2018, EUR J OPER RES, V270, P654, DOI 10.1016/j.ejor.2017.11.054
   Habibzadeh M, 2013, LECT NOTES ARTIF INT, V7895, P263, DOI 10.1007/978-3-642-38610-7_25
   He J, 2020, IEEE J BIOMED HEALTH, V24, P2473, DOI 10.1109/JBHI.2020.2970091
   Hegde RB, 2019, MULTIMED TOOLS APPL, V78, P17879, DOI 10.1007/s11042-018-7107-x
   Hegde RB, 2019, AUSTRALAS PHYS ENG S, V42, P627, DOI 10.1007/s13246-019-00742-9
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Ijaz MF, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8081325
   Ilié M, 2018, ANN ONCOL, V29, P193, DOI 10.1093/annonc/mdx636
   Khan MA, 2021, MICROSC RES TECHNIQ, V84, P202, DOI 10.1002/jemt.23578
   Kumar D, 2020, IEEE ACCESS, V8, P142521, DOI 10.1109/ACCESS.2020.3012292
   Kutlu H, 2020, MED HYPOTHESES, V135, DOI 10.1016/j.mehy.2019.109472
   Li X, 2017, ENVIRON POLLUT, V231, P997, DOI 10.1016/j.envpol.2017.08.114
   Liang GB, 2018, IEEE ACCESS, V6, P36188, DOI 10.1109/ACCESS.2018.2846685
   Lin JCW, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106548
   Makem M., 2020, Inform Med Unlocked, V20, DOI [10.1016/j.imu.2020.100416, DOI 10.1016/J.IMU.2020.100416]
   Mandal M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165571
   Qian R., 2021, ARXIV PREPRINT ARXIV
   Rodrigues AM, 2017, LECT NOTES COMPUT SC, V10525, P301, DOI 10.1007/978-3-319-67738-5_18
   Sedighizadeh D, 2021, MATH COMPUT SIMULAT, V179, P194, DOI 10.1016/j.matcom.2020.08.013
   Shahin AI, 2019, COMPUT METH PROG BIO, V168, P69, DOI 10.1016/j.cmpb.2017.11.015
   Sharma Mayank, 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 900), P135, DOI 10.1007/978-981-13-3600-3_13
   Srinivasu PN, 2021, CMC-COMPUT MATER CON, V69, P3303, DOI 10.32604/cmc.2021.018472
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Togaçar M, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106810
   Wang F, 2021, SWARM EVOL COMPUT, V60, DOI 10.1016/j.swevo.2020.100808
   Wang JL, 2018, IEEE INT SYMP SIGNAL, P325, DOI 10.1109/ISSPIT.2018.8642630
   Yao XF, 2021, ARTIF CELL NANOMED B, V49, P147, DOI 10.1080/21691401.2021.1879823
   Zervoudakis K, 2020, COMPUT IND ENG, V145, DOI 10.1016/j.cie.2020.106559
   Zhao J., 2020, J PHYS C SER, V1693, DOI DOI 10.1088/1742-6596/1693/1/012098
   Zhao J, 2020, J PHYS C SER, V1684
   Zhao JW, 2017, MED BIOL ENG COMPUT, V55, P1287, DOI 10.1007/s11517-016-1590-x
   Zheng X, 2018, MICRON, V107, P55, DOI 10.1016/j.micron.2018.01.010
NR 40
TC 3
Z9 3
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30121
EP 30142
DI 10.1007/s11042-022-12539-2
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500023
DA 2024-07-18
ER

PT J
AU Tango, K
   Katsurai, M
   Maki, H
   Goto, R
AF Tango, Koya
   Katsurai, Marie
   Maki, Hayato
   Goto, Ryosuke
TI Anime-to-real clothing: Cosplay costume generation via image-to-image
   translation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clothing images; Image-to-image translation; Generative adversarial
   networks; Dataset construction; Image synthesis
AB Cosplay has grown from its origins at fan conventions into a billion-dollar global dress phenomenon. To facilitate the imagination and reinterpretation of animated images as real garments, this paper presents an automatic costume-image generation method based on image-to-image translation. Cosplay items can be significantly diverse in their styles and shapes, and conventional methods cannot be directly applied to the wide variety of clothing images that are the focus of this study. To solve this problem, our method starts by collecting and preprocessing web images to prepare a cleaned, paired dataset of the anime and real domains. Then, we present a novel architecture for generative adversarial networks (GANs) to facilitate high-quality cosplay image generation. Our GAN consists of several effective techniques to bridge the two domains and improve both the global and local consistency of generated images. Experiments demonstrated that, with quantitative evaluation metrics, the proposed GAN performs better and produces more realistic images than conventional methods. Our codes and pretrained model are available on the web.
C1 [Tango, Koya; Katsurai, Marie] Doshisha Univ, 1-3 Tatara Miyakodani, Kyotanabe, Kyoto 6100394, Japan.
   [Maki, Hayato; Goto, Ryosuke] ZOZO Technol, Shibuya Ku, Aoyama Oval Bldg 3F,5-52-2 Jingumae, Tokyo 1500001, Japan.
C3 Doshisha University
RP Katsurai, M (corresponding author), Doshisha Univ, 1-3 Tatara Miyakodani, Kyotanabe, Kyoto 6100394, Japan.
EM tango@mm.doshisha.ac.jp; katsurai@mm.doshisha.ac.jp;
   hayato.maki@zozo.com; ryosuke.goto@zozo.com
OI Katsurai, Marie/0000-0003-4899-2427
CR Azathoth, 2018, MYANIMELIST DATASET
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Cheng W.H., 2020, Fashion meets computer vision: A survey
   Ci YZ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1536, DOI 10.1145/3240508.3240661
   CooperUnion, 2016, AN REC DAT REC DAT
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hamada K., 2018, P EUR C COMP VIS ECC, P67
   Han XT, 2018, PROC CVPR IEEE, P7543, DOI 10.1109/CVPR.2018.00787
   Hensel M, 2017, ADV NEUR IN, V30
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jin Yanghua, 2017, ARXIV170805509
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kwon Y, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4, P83, DOI 10.5220/0007306900830090
   Li V, 2018, FASHIONAI KEYPOINT D
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   lltcggie, 2018, WAIFU2X CAFF
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Miyato T, 2018, INT C LEARN REPR
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   ripobi-tan, 2016, DUPFILEELIMINATOR
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Royer A., 2020, Domain Adaptation for Visual Understanding, P33
   Salimans T, 2016, ADV NEUR IN, V29
   Shocher Assaf, 2018, ARXIV181200231
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tang H, 2019, ARXIV190312296
   Ulyanov D, 2017, PROC CVPR IEEE, P4105, DOI 10.1109/CVPR.2017.437
   Vijayanarasimhan S, 2011, INT J COMPUT VISION, V91, P24, DOI 10.1007/s11263-010-0372-4
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   WCS Inc, 2020, WHATS WCS
   Wu WY, 2019, PROC CVPR IEEE, P8004, DOI 10.1109/CVPR.2019.00820
   Wu ZH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P293, DOI 10.1145/3343031.3351083
   Yoo D, 2016, LECT NOTES COMPUT SC, V9912, P517, DOI 10.1007/978-3-319-46484-8_31
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu SZ, 2017, IEEE I CONF COMP VIS, P1689, DOI 10.1109/ICCV.2017.186
   Zou XX, 2019, IEEE COMPUT SOC CONF, P296, DOI 10.1109/CVPRW.2019.00039
NR 45
TC 0
Z9 1
U1 3
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29505
EP 29523
DI 10.1007/s11042-022-12576-x
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000778057700006
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Wang, XY
   Yang, HY
   Gao, SY
   Niu, PP
AF Wang, Xiangyang
   Yang, Hongying
   Gao, Siyang
   Niu, Panpan
TI Texture image retrieval using DNST domain local neighborhood intensity
   pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture image retrieval; Discrete non-separable shearlet transform;
   Local neighborhood intensity pattern; Binary bit-string encoding;
   Feature vector; Kullback-Leibler divergences
ID BINARY PATTERNS; FEATURE DESCRIPTOR; FACE RECOGNITION; CLASSIFICATION;
   ROTATION; SEGMENTATION; SCALE
AB In this paper, we proposed a new texture image retrieval method based on discrete non-separable shearlet transform (DNST) domain local neighborhood intensity pattern (LNIP), which can fully characterize the discriminative information among particular coefficient and its adjacent neighbors within a local window. Firstly, the original image is decomposed into different subbands of frequency and orientation responses by using discrete non-separable shearlet transform (DNST). Secondly, based on center symmetric-local binary pattern theory, the sign and magnitude patterns of DNST domain LNIP descriptor are constructed using novel computation rule. Meanwhile, a new binary bit-string encoding scheme is developed, which can overcome the information redundant and inaccurate problem of conventional encoding strategy in LNIP. Thirdly, the mean, standard deviation and entropy values of the DNST domain LNIP at different scales are calculated and fused into a vector as the image texture feature values, which effectively reduce the feature dimensions. And finally, image similarity measurement is accomplished by using closed-form solutions for the Kullback-Leibler divergences between the DNST domain LNIP based image texture features. Experimental results on some test images and comparison with well-known existing methods demonstrate the efficacy and superiority of the proposed method.
C1 [Wang, Xiangyang; Yang, Hongying; Gao, Siyang; Niu, Panpan] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Wang, XY; Yang, HY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com; yhy_65@126.com
RI Yang, Jing/JFK-4046-2023; Niu, Panpan/Q-9953-2017
OI Yang, Jing/0009-0004-8274-9863; 
FU National Natural Science Foundation of China [61472171, 61701212];
   Scientific Research Project of Liaoning Provincial Education Department
   [LJKZ0985]; Natural Science Foundation of Liaoning Province
   [2019-ZD-0468]
FX This work was supported partially by the National Natural Science
   Foundation of China (Nos. 61472171 & 61701212), Scientific Research
   Project of Liaoning Provincial Education Department (No. LJKZ0985), and
   Natural Science Foundation of Liaoning Province (No. 2019-ZD-0468).
CR Abdelmounaime, 2013, NEW BRODATZ BASED IM
   Ahmadian A, 2005, P ANN INT IEEE EMBS, P1567, DOI 10.1109/IEMBS.2005.1616734
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Ambika A, 2014, 2014 INT C COMP COMM, P1
   [Anonymous], URBAN NATURAL SCENE
   [Anonymous], 2013, INT J ENG TRENDS TEC
   Banerjee P, 2018, EXPERT SYST APPL, V113, P100, DOI 10.1016/j.eswa.2018.06.044
   Celik T, 2009, PATTERN RECOGN LETT, V30, P331, DOI 10.1016/j.patrec.2008.10.006
   Chakraborti T, 2018, IEEE SIGNAL PROC LET, V25, P635, DOI 10.1109/LSP.2018.2817176
   Chakraborty S, 2018, PATTERN RECOGN LETT, V115, P50, DOI 10.1016/j.patrec.2017.10.015
   Chakraborty S, 2018, IEEE T CIRC SYST VID, V28, P171, DOI 10.1109/TCSVT.2016.2603535
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P1201, DOI 10.1007/s11042-015-3111-6
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   Dubey SR, 2015, IEEE SIGNAL PROC LET, V22, P1215, DOI 10.1109/LSP.2015.2392623
   Fadaei S, 2017, SIGNAL PROCESS, V137, P274, DOI 10.1016/j.sigpro.2017.02.013
   Fan H, 2018, IEEE SIGNAL PROC LET, V25, P788, DOI 10.1109/LSP.2018.2825947
   Fan KC, 2014, IEEE T IMAGE PROCESS, V23, P2877, DOI 10.1109/TIP.2014.2321495
   Fröba B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P91, DOI 10.1109/AFGR.2004.1301514
   Ghose S, 2020, MULTIMED TOOLS APPL, V79, P18527, DOI 10.1007/s11042-020-08752-6
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Hafiane A, 2007, LECT NOTES COMPUT SC, V4633, P387
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Kou QQ, 2019, IEEE SIGNAL PROC LET, V26, P129, DOI 10.1109/LSP.2018.2881544
   Lan RS, 2016, IEEE T IMAGE PROCESS, V25, P566, DOI 10.1109/TIP.2015.2507404
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Li CR, 2017, PATTERN RECOGN, V64, P118, DOI 10.1016/j.patcog.2016.10.030
   Li CR, 2013, IEEE SIGNAL PROC LET, V20, P799, DOI 10.1109/LSP.2013.2247596
   Li XQ, 2021, NEUROCOMPUTING, V452, P675, DOI 10.1016/j.neucom.2020.07.139
   Lim WQ, 2013, IEEE T IMAGE PROCESS, V22, P2056, DOI 10.1109/TIP.2013.2244223
   Liu G-H, IMAGE RANK MACHINE B
   Lu CS, 1997, PATTERN RECOGN, V30, P729, DOI 10.1016/S0031-3203(96)00116-1
   Miao C., 2014, TECHN APPL V INT SOC, V9263, p92631W
   Mosleh A, 2009, 2009 INT S SIGN CIRC, P1
   Murala S, 2014, IEEE J BIOMED HEALTH, V18, P929, DOI 10.1109/JBHI.2013.2288522
   Murala S, 2012, INT J MULTIMED INF R, V1, P191, DOI 10.1007/s13735-012-0008-2
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan ZB, 2018, MULTIMED TOOLS APPL, V77, P26469, DOI 10.1007/s11042-018-5871-2
   Pan ZB, 2017, EXPERT SYST APPL, V88, P238, DOI 10.1016/j.eswa.2017.07.007
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Qian XM, 2011, PATTERN RECOGN, V44, P2502, DOI 10.1016/j.patcog.2011.03.029
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Ryu B, 2017, IEEE T IMAGE PROCESS, V26, P6006, DOI 10.1109/TIP.2017.2726010
   Singh C, 2018, PATTERN RECOGN, V76, P50, DOI 10.1016/j.patcog.2017.10.021
   Song TC, 2018, IEEE SIGNAL PROC LET, V25, P625, DOI 10.1109/LSP.2018.2809607
   Su SZ, 2010, ELECTRON LETT, V46, P996, DOI 10.1049/el.2010.1104
   Subrahmanyam M, 2012, SIGNAL PROCESS, V92, P1467, DOI 10.1016/j.sigpro.2011.12.005
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Verma M, 2016, DIGIT SIGNAL PROCESS, V51, P62, DOI 10.1016/j.dsp.2016.02.002
   Wang Q, 2017, IEEE SIGNAL PROC LET, V24, P1358, DOI 10.1109/LSP.2017.2728122
   Xia Y, 2014, PROC SPIE, V9069, DOI 10.1117/12.2049916
   Xia ZH, 2020, IEEE T SYST MAN CY-S, V50, P1526, DOI 10.1109/TSMC.2018.2874281
   Xiao B, 2019, IEEE T CIRC SYST VID, V29, P2796, DOI 10.1109/TCSVT.2018.2869841
   Yang P, 2018, IEEE ACCESS, V6, P13336, DOI 10.1109/ACCESS.2018.2797072
   Zhao Y, 2012, IEEE T IMAGE PROCESS, V21, P4492, DOI 10.1109/TIP.2012.2204271
NR 61
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29525
EP 29554
DI 10.1007/s11042-022-12819-x
EA APR 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000778057700009
DA 2024-07-18
ER

PT J
AU Xu, DW
   Liu, Y
AF Xu, Dawen
   Liu, Yong
TI Reversible data hiding in H.264/AVC videos based on hybrid-dimensional
   histogram modification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Histogram shifting; Hybrid-dimensional histogram
   modification; H.264/AVC
ID FRAME ERROR CONCEALMENT; PREDICTION; EXPANSION
AB In this paper, a new reversible data hiding (RDH) scheme for H.264/AVC video based on hybrid histogram modification is proposed. Two nonzero quantized transform coefficients (QTCs) are combined to generate coefficient pairs. Unlike previous works, only small QTCs s are put into pairs to construct two-dimensional (2D) histogram, and the remaining coefficients are formed into one-dimensional (1D) histogram. Then a hybrid dimensional histogram modification is designed to embed data. An appropriate 2D modification is determined to modify the small QTCs in the pairwise manner. For the large QTCs, only the 1D shifting operation is performed on them for the sake of reversibility. Experimental results demonstrate that compared with the existing two methods, the average value of the maximum embedding capacity can be increased by 43.59% and 17.48% respectively. Furthermore, with the same embedding capacity, the proposed method can achieve better performance in terms of bit rate variation and visual quality.
C1 [Xu, Dawen; Liu, Yong] Ningbo Univ Technol, Sch Elect & Informat Engn, Ningbo 315016, Peoples R China.
C3 Ningbo University of Technology
RP Xu, DW (corresponding author), Ningbo Univ Technol, Sch Elect & Informat Engn, Ningbo 315016, Peoples R China.
EM dawenxu@126.com
OI xu, dawen/0000-0002-9619-8407
FU National Natural Science Foundation of China [61771270, 62071267];
   Zhejiang Provincial Natural Science Foundation of China [LR20F020001]
FX This work is supported by the National Natural Science Foundation of
   China (61771270, 62071267), Zhejiang Provincial Natural Science
   Foundation of China (LR20F020001).
CR Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chung KL, 2010, IEEE T CIRC SYST VID, V20, P1643, DOI 10.1109/TCSVT.2010.2077577
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   He WG, 2020, IEEE T INF FOREN SEC, V15, P3859, DOI 10.1109/TIFS.2020.3002377
   Hu XC, 2015, IEEE T INF FOREN SEC, V10, P653, DOI 10.1109/TIFS.2015.2392556
   Hu YJ, 2008, IEEE T MULTIMEDIA, V10, P1500, DOI 10.1109/TMM.2008.2007341
   Jia YJ, 2019, SIGNAL PROCESS, V163, P238, DOI 10.1016/j.sigpro.2019.05.020
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Kim H, 2018, MULTIMED TOOLS APPL, V77, P8043, DOI 10.1007/s11042-017-4698-6
   Li N, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107476
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Liu YX, 2015, NEUROCOMPUTING, V151, P1053, DOI 10.1016/j.neucom.2014.03.088
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Niu K, 2017, TSINGHUA SCI TECHNOL, V22, P489
   Ou B, 2019, IEEE T CIRC SYST VID, V29, P2176, DOI 10.1109/TCSVT.2018.2859792
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Qi WF, 2020, IEEE T CIRC SYST VID, V30, P2300, DOI 10.1109/TCSVT.2019.2942489
   Roy A, 2020, IEEE T CIRC SYST VID, V30, P2377, DOI 10.1109/TCSVT.2019.2911042
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Song GH, 2015, MULTIMED TOOLS APPL, V74, P3759, DOI 10.1007/s11042-013-1798-9
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2020, IEEE T CIRC SYST VID, V30, P2313, DOI 10.1109/TCSVT.2019.2915584
   Xu DW, 2016, SIGNAL PROCESS-IMAGE, V47, P369, DOI 10.1016/j.image.2016.08.003
   Xu DW, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.5.053022
   Xu DW, 2014, IEEE T INF FOREN SEC, V9, P596, DOI 10.1109/TIFS.2014.2302899
   Xu DW, 2014, J VIS COMMUN IMAGE R, V25, P410, DOI 10.1016/j.jvcir.2013.12.008
   Xu DW, 2016, INT WORKSH DIG FOR W
   Yao YZ, 2016, SIGNAL PROCESS, V128, P531, DOI 10.1016/j.sigpro.2016.05.004
   Zhao J, 2016, MULTIMED TOOLS APPL, V75, P5959, DOI 10.1007/s11042-015-2558-9
NR 31
TC 4
Z9 4
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29305
EP 29319
DI 10.1007/s11042-022-12740-3
EA APR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777384900004
DA 2024-07-18
ER

PT J
AU Pazouki, E
AF Pazouki, Ehsan
TI AgriBot: a mobile application for imaging farm fields Imaging of the
   farm fields
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Farm field imaging; Large-area image stitching; Field measurement;
   Mobile image processing; Smart farming
AB The issue of food security is one of the serious challenges. Precision agriculture, including imaging and analyzing the captured images is used to increase productivity. In this paper a software for smartphones is proposed for imaging the agricultural fields. In app, the imaging process is facilitated using all the available capabilities of the smartphone. By app, the farmer first determines the boundary of the field just by walking around it. The app provides pattern of imaging points. The farmer captures images of the land. Then, panoramic image of whole field is rendered using planar stitching algorithm. Based on the experiments performed in accordance with the technical specifications of the used smartphone, it was determined that the app has the ability to capture images with 0.09 centimeter spatial resolution. By comparing the features of the imaging method provided by the app with other imaging methods, it is clear that the proposed app provides images with much better spatial resolution and time-controlled resolution or revisiting rate by the farmer at a much lower cost. By analyzing the images obtained from this app, using a variety of classification, detection, recognition, etc. algorithms based on tools such as deep learning, knowledge such as the pattern of distribution of various weeds, pests and diseases on the field is obtained. By this knowledge, the farmer can make timely and effective decisions. This app provides a valuable source of information for a wide range of smallholders to benefit from new technologies to ensure food security.
C1 [Pazouki, Ehsan] Shahid Rajaei Teacher Training Univ, Comp Engn Fac, Tehran, Iran.
C3 Shahid Rajaee Teacher Training University (SRTTU)
RP Pazouki, E (corresponding author), Shahid Rajaei Teacher Training Univ, Comp Engn Fac, Tehran, Iran.
EM ehsan.pazouki@sru.ac.ir
RI Pazouki, Ehsan/AAP-1512-2020
OI Pazouki, Ehsan/0000-0002-4567-6800
CR Abioye EA, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105441
   Alvarez-Vanhard E, 2021, SCI REMOTE SENSING, V3, DOI 10.1016/j.srs.2021.100019
   Bajpai P, 2018, PROCEEDINGS OF THE 2018 APWG SYMPOSIUM ON ELECTRONIC CRIME RESEARCH (ECRIME), P35
   Boutellier JJ, 2007, PROC SPIE, V6498, DOI 10.1117/12.703527
   Brugger F., 2011, Mobile applications in agriculture
   Cheng X, 2017, COMPUT ELECTRON AGR, V141, P351, DOI 10.1016/j.compag.2017.08.005
   DigitalGlobe, 2015, REMOTE SENSING TECHN
   Feng L, 2021, COMPUT ELECTRON AGR, V182, DOI 10.1016/j.compag.2021.106033
   Fritz S, 2019, AGR SYST, V168, P258, DOI 10.1016/j.agsy.2018.05.010
   Hasan ASMM, 2021, COMPUT ELECTRON AGR, V184, DOI 10.1016/j.compag.2021.106067
   Humair LL, 2015, THESIS ETH ZURICH, DOI [10.3929/ethz-a-010510186, DOI 10.3929/ETHZ-A-010510186]
   Jain A, 2019, COMPASS '19 - PROCEEDINGS OF THE CONFERENCE ON COMPUTING & SUSTAINABLE SOCIETIES, P41, DOI 10.1145/3314344.3332485
   Jiang HH, 2020, COMPUT ELECTRON AGR, V174, DOI 10.1016/j.compag.2020.105450
   Khanal S, 2017, COMPUT ELECTRON AGR, V139, P22, DOI 10.1016/j.compag.2017.05.001
   Lee WS, 2015, COMPUT ELECTRON AGR, V112, P2, DOI 10.1016/j.compag.2014.11.005
   Li DL, 2020, COMPUT ELECTRON AGR, V174, DOI 10.1016/j.compag.2020.105459
   Li WY, 2021, COMPUT ELECTRON AGR, V183, DOI 10.1016/j.compag.2021.106048
   Lyu W, 2019, VIRTUAL REALITY INTE, V1, P55, DOI [10.3724/SP.J.2096-5796.2018.0008, DOI 10.3724/SP.J.2096-5796.2018.0008]
   Maghsoudi H, 2015, COMPUT ELECTRON AGR, V112, P149, DOI 10.1016/j.compag.2014.12.015
   Mastelic T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061658
   Mendes J, 2020, AGRONOMY-BASEL, V10, DOI 10.3390/agronomy10060855
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Nigon TJ, 2015, COMPUT ELECTRON AGR, V112, P36, DOI 10.1016/j.compag.2014.12.018
   Pongnumkul S, 2015, J SENSORS, V2015, DOI 10.1155/2015/195308
   Shi Y, 2015, COMPUT ELECTRON AGR, V112, P92, DOI 10.1016/j.compag.2014.11.026
   Szeliski R, 2006, MSRTR200492, P98052
   Tao C, 2017, BUILD PANORAMAS ANDR
   Tetila EC, 2020, COMPUT ELECTRON AGR, V179, DOI [10.1016/j.compeg.2020.105836, 10.1016/j.compag.2020.105836]
   Tian Hong-kun, 2020, Information Processing in Agriculture, V7, P1, DOI 10.1016/j.inpa.2019.09.006
   Twetman T, 2015, THESIS KTH ROYAL I T
   Wang AC, 2019, COMPUT ELECTRON AGR, V158, P226, DOI 10.1016/j.compag.2019.02.005
   Wang J, 2015, COMPUT ELECTRON AGR, V112, P75, DOI 10.1016/j.compag.2014.12.016
   Wang QS, 2016, ELECTRON NOTES THEOR, V327, P125, DOI 10.1016/j.entcs.2016.09.027
   Wang ZB, 2020, MULTIMEDIA SYST, V26, P413, DOI 10.1007/s00530-020-00651-y
   Wu MQ, 2017, COMPUT ELECTRON AGR, V139, P1, DOI 10.1016/j.compag.2017.05.003
   Xiong YG, 2010, IEEE T CONSUM ELECTR, V56, P298, DOI 10.1109/TCE.2010.5505931
   Yao W, 2015, IEEE SIGNAL PROC LET, V22, P6, DOI 10.1109/LSP.2014.2345773
   Yingen Xiong, 2010, 2010 IEEE International Conference on Consumer Electronics (ICCE 2010), P319, DOI 10.1109/ICCE.2010.5419027
   Zhang JY, 2021, COMPUT ELECTRON AGR, V185, DOI 10.1016/j.compag.2021.106138
   Zhang JC, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104943
   Zhang KK, 2021, COMPUT ELECTRON AGR, V183, DOI 10.1016/j.compag.2021.106064
NR 41
TC 0
Z9 0
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28917
EP 28954
DI 10.1007/s11042-022-12777-4
EA MAR 2022
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777375900008
DA 2024-07-18
ER

PT J
AU He, ZC
   Ma, YD
   Wang, ZX
   Li, E
AF He, Zhicheng
   Ma, Yadong
   Wang, Zhenxing
   Li, Eric
TI A novel efficient method for welding spots detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Welding spots detection; Light-weight deep learning model; Circle
   detection; Right-triangle sampling strategy
ID CIRCLE DETECTION; ALGORITHM; IMPLEMENTATION
AB The traditional welding spots detection methods are very sensitive to light pollution, rust and oil stain. In this work, a novel method that combines light-weight deep learning model and circle detection algorithm for welding spots detection is proposed. First, a light-weight model called Modified You Only Look Once version 2 (M-YOLOv2) which substitutes MobileNetv2 for Darknet-19 convolution structure in YOLOv2 and incorporates fine-grained features (FGF) is developed. The proposed M-YOLOv2 is very effective and efficient to capture the position of welding spot compared with YOLOv2, YOLOv3 and Tiny-YOLOv2. Secondly, a novel right-triangle circle detection (RTCD) is developed to refine the shapes of the welding spots. The novel algorithm called M-YOLOv2-RTCD that combines M-YOLOv2 and RTCD is able to accurately and fast detect welding spots. The theoretical analysis and experimental results demonstrate that the proposed M-YOLOv2-RTCD outperforms the methods only using M-YOLOv2 or RTCD, in terms of accuracy and real-time performance.
C1 [He, Zhicheng; Ma, Yadong; Wang, Zhenxing] Hunan Univ, State Key Lab Adv Design & Mfg Vehicle Body, Changsha 410082, Peoples R China.
   [Li, Eric] Teesside Univ, Sch Comp Engn & Digital Technol, Middlesbrough, England.
C3 Hunan University; University of Teesside
RP Li, E (corresponding author), Teesside Univ, Sch Comp Engn & Digital Technol, Middlesbrough, England.
EM ericsg2012@gmail.com
FU Foundation for Innovative Research Groups of the National Natural
   Science Foundation of China [51621004]; Natural Science Foundation of
   China [U1864207]; Opening Project of the Guangxi Key Laboratory of
   Automobile Components and Vehicle Technology of Guangxi University of
   Science and Technology [2017GKLACVTKF01]
FX The project is supported by the Foundation for Innovative Research
   Groups of the National Natural Science Foundation of China (Grant No.
   51621004) and the Natural Science Foundation of China (Grant No.
   U1864207), the Opening Project of the Guangxi Key Laboratory of
   Automobile Components and Vehicle Technology of Guangxi University of
   Science and Technology (No. 2017GKLACVTKF01).
CR Abhishek, 2021, MULTIMED TOOLS APPL, V80, P3571, DOI 10.1007/s11042-020-09816-3
   Akinlar C, 2013, PATTERN RECOGN, V46, P725, DOI 10.1016/j.patcog.2012.09.020
   [Anonymous], 2015, CVPR, DOI DOI 10.1109/CVPR.2015.7298642
   Caesar H, 2015, BRIT MACH VIS C BMVC
   Chen TC, 2001, COMPUT VIS IMAGE UND, V83, P172, DOI 10.1006/cviu.2001.0923
   Chiu SH, 2005, PATTERN RECOGN LETT, V26, P121, DOI 10.1016/j.patrec.2004.09.037
   Chung KL, 2012, PATTERN RECOGN, V45, P252, DOI 10.1016/j.patcog.2011.07.004
   Cuevas E, 2017, STUD COMPUT INTELL, V686, P35, DOI 10.1007/978-3-319-51109-2_3
   De Marco T, 2015, PATTERN RECOGN, V48, P411, DOI 10.1016/j.patcog.2014.08.007
   Dong N, 2012, COMPUT MATH APPL, V64, P1886, DOI 10.1016/j.camwa.2012.03.040
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fornaciari M, 2014, PATTERN RECOGN, V47, P3693, DOI 10.1016/j.patcog.2014.05.012
   Fourie J, 2017, J OPTIM, V2017, DOI 10.1155/2017/9710719
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gonzalez R, 2015, INT CONF ACOUST SPEE, P1354, DOI 10.1109/ICASSP.2015.7178191
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang YH, 2012, PATTERN RECOGN LETT, V33, P2071, DOI 10.1016/j.patrec.2012.06.016
   Krizhevsky, 2012, ADV NEURAL INFORM PR, V25, P1075
   Kultanen P., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P631, DOI 10.1109/ICPR.1990.118177
   Kumar V, 2018, IET IMAGE PROCESS, V12, P1753, DOI 10.1049/iet-ipr.2017.1167
   Li Y, 2014, 6 INT C GRAPH IM PRO, V9443
   Li-qin Jia, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P820, DOI 10.1109/CISP.2011.6100372
   Lin D, 2015, PROC CVPR IEEE, P1666, DOI 10.1109/CVPR.2015.7298775
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin YK, 2021, MULTIMED TOOLS APPL, V80, P4037, DOI 10.1007/s11042-020-09276-9
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lopez-Martinez A, 2019, APPL INTELL, V49, P2001, DOI 10.1007/s10489-018-1372-2
   Manzanera A, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0149-y
   Pan LL, 2011, IEEE SIGNAL PROC LET, V18, P639, DOI 10.1109/LSP.2011.2166956
   Redmon J., 2018, COMPUTER VISION PATT
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Topal Cihan, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2424, DOI 10.1109/ICPR.2010.593
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yadav VK, 2016, ADV INTELL SYST, V408, P25, DOI 10.1007/978-981-10-0129-1_3
   Yao ZJ, 2016, EXPERT SYST APPL, V51, P26, DOI 10.1016/j.eswa.2015.12.019
   Yu HC, 2017, J OPT SOC AM A, V34, P415, DOI 10.1364/JOSAA.34.000415
   Yuan BD, 2015, PATTERN RECOGN, V48, P3268, DOI 10.1016/j.patcog.2015.01.003
   Zhang HQ, 2016, PATTERN RECOGN, V54, P218, DOI 10.1016/j.patcog.2015.12.004
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   2017, INTEL SYST REF LIBR, V117, P113
NR 54
TC 2
Z9 2
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26381
EP 26401
DI 10.1007/s11042-022-12921-0
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000780464900012
DA 2024-07-18
ER

PT J
AU Nassar, SS
   El-Bendary, MAM
AF Nassar, Sabry S.
   El-Bendary, Mohsen A. M.
TI Confidentiality considerations: multimedia signals transmission over
   different wireless channels utilized efficient secured model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Confidentiality; Security techniques; Wireless channels; OFDM; Discrete
   transforms; Randomized error control technique
AB The confidentiality of highly-sensitive multimedia signals is considered in this paper, it can be enhanced by efficient secured model utilizing several-layer security algorithms. The hybrid data hiding and cryptographic techniques are merged for constructing secured model. The Least Significant Bit (LSB) data hiding steganography is utilized with a 2-D Logistic-based map (Model-I) and second Model-II involves data hiding merging within chaotic-Baker-based image encryption security techniques. Performance analyzing and comparison have been presented utilizing various images for examining the applicability of the different proposed image security scenarios for securing wireless image transmission over noise-free, and noisy channels. Moreover, the proposed algorithms are applied for transmission over Orthogonal Frequency-Division Multiplexing (OFDM) channels, and their performance is evaluated under different conditions of fading environments with utilizing the powerful error control schemes in the case of SUI-3 model channel and randomizing the packet based on the encryption tools. An equalizer is used to mitigate the impact of composite fading. A multi-layer security model using Discrete Wavelet Transform (DWT) steganography with chaotic Baker encryption is proposed to protect highly-sensitive text based data records. The results reveal that it can be used efficiently for protecting highly-sensitive text message and records (text-based data). The timing analysis and comparative study are considered with respect to the previous related works.
C1 [Nassar, Sabry S.] Atom Energy Author Egypt, Nucl Res Ctr, Cairo, Egypt.
   [El-Bendary, Mohsen A. M.] Helwan Univ, Fac Technol & Educ, Dept Elect Technol, Helwan, Egypt.
C3 Egyptian Knowledge Bank (EKB); Egyptian Atomic Energy Authority (EAEA);
   Egyptian Knowledge Bank (EKB); Helwan University
RP El-Bendary, MAM (corresponding author), Helwan Univ, Fac Technol & Educ, Dept Elect Technol, Helwan, Egypt.
EM sabry2000@yahoo.com; engmohsen2004@yahoo.com
RI El-Bendary, Mohsen A. M./P-8567-2019
OI El-Bendary, Mohsen A. M./0000-0002-2425-4967
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Al-Nuaimy W, 2011, DIGIT SIGNAL PROCESS, V21, P764, DOI 10.1016/j.dsp.2011.01.013
   Al-Roithy BO, 2021, MULTIMED TOOLS APPL, V80, P28521, DOI 10.1007/s11042-021-11051-3
   Algarni AD, 2021, MULTIMED TOOLS APPL, V80, P10679, DOI 10.1007/s11042-020-09369-5
   [Anonymous], 2013, IOSR J COMPUTER ENG, DOI DOI 10.9790/0661-1254954
   Chang, 2010, SEMIFRAGILE WATERMAR, DOI [10.1109/ISCIT.2010.5665087, DOI 10.1109/ISCIT.2010.5665087]
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen HP, 2022, MULTIMEDIA SYST, V28, P363, DOI 10.1007/s00530-021-00801-w
   Choudhary K, 2012, GLOBAL SECURITY STUD, V3
   El-Bendary MAM, 2019, MULTIMED TOOLS APPL, V78, P16633, DOI 10.1007/s11042-018-6843-2
   El-Bendary MAM, 2017, MULTIMED TOOLS APPL, V76, P26463, DOI 10.1007/s11042-016-4177-5
   El-Bendary MAMM, 2012, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2012-4
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Goel S, 2013, INT J COMPUTERS DIST, V3
   HSE Nuclear Directorate Division 5 Office for Civil Nuclear Security, 2008, MAN SENS NUCL INF GE
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   International Atomic Energy Agency, 2011, TECHN GUID SER IAEA, V17
   Izquierdo E, 2021, MULTIMED TOOLS APPL, V80, P23313, DOI 10.1007/s11042-021-11108-3
   Jin X, 2022, MULTIMED TOOLS APPL, V81, P35733, DOI 10.1007/s11042-021-11126-1
   Juneja M, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN RECENT TECHNOLOGIES IN COMMUNICATION AND COMPUTING (ARTCOM 2009), P302, DOI 10.1109/ARTCom.2009.228
   Kamal AHM, 2013, INT J COMPUT TECHNOL, V4
   Kaur G, 2021, MULTIMED TOOLS APPL, V80, P10927, DOI 10.1007/s11042-020-10223-x
   Krenn J.R., 2004, Steganography and steganalysis
   Kumar A, 2010, INT J COMPUTER APPL, V9
   Kwok HS, 2007, CHAOS SOLITON FRACT, V32, P1518, DOI 10.1016/j.chaos.2005.11.090
   Mao YB, 2005, HANDBOOK OF GEOMETRIC COMPUTING: APPLICATIONS IN PATTERN RECOGNITION, COMPUTER VISION, NEURALCOMPUTING, AND ROBOTICS, P231, DOI 10.1007/3-540-28247-5_8
   Mehboob B, 2008, IEEE42442427
   Miller ML., 1997, IEEE INT C IMAGE PRO
   Ming C, 2006, INT C INT INF HID MU
   Moerland T., Steganography and steganalysis, Leiden Institute of advanced computing science
   Musheer Ahmad M, 2009, INT J COMPUT SCI ENG, V2
   Nassar SS, 2021, WIRELESS PERS COMMUN, V119, P37, DOI 10.1007/s11277-021-08176-x
   Nassar SS, 2016, WIRELESS PERS COMMUN, V91, P1023, DOI 10.1007/s11277-016-3387-5
   Nassar SS, 2016, WIRELESS PERS COMMUN, V88, P479, DOI 10.1007/s11277-015-3142-3
   Neeta D, 2004, IMPLEMENTATION LSB S
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Patel R, 2021, MULTIMEDIA SYST, V27, P985, DOI 10.1007/s00530-021-00763-z
   Petrovic R, 2005, DIGITAL WATERMARKS A
   Radharani S., 2010, INT J COMPUTER APPL, V2, P24, DOI DOI 10.5120/658-925
   Rudko CS, 2002, INDEPENDENT STUDYEER
   Selvi CT, 2021, MULTIMEDIA SYST, V27, P1059, DOI 10.1007/s00530-021-00764-y
   Sharma H, 2021, MULTIMED TOOLS APPL, V80, P29067, DOI 10.1007/s11042-021-11068-8
   Sharma N, 2021, COMPUTING, V103, P1883, DOI 10.1007/s00607-020-00881-y
   Srividya G., 2011, 2011 International Conference on Communications and Signal Processing (ICCSP), P266, DOI 10.1109/ICCSP.2011.5739316
   Tewfik AH, 2000, SAN MERCURY NEW 0814
   Wu CW, 1993, IEEE T CIRCUITS SYST, V40
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Zhou S, 2022, MULTIMEDIA SYST, V28, P95, DOI 10.1007/s00530-021-00803-8
NR 47
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25707
EP 25744
DI 10.1007/s11042-022-12297-1
EA MAR 2022
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000772731900003
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhuo, L
   Tan, SQ
   Li, B
   Huang, JW
AF Zhuo, Long
   Tan, Shunquan
   Li, Bin
   Huang, Jiwu
TI ISP-GAN: inception sub-pixel deconvolution-based lightweight GANs for
   colorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ISP-GAN; Colorization; Inception sub-pixel deconvolution; Richer
   features
ID STEGANALYSIS; COLOR
AB Though there are many encouraging reports, existing image colorization algorithms are still prone to unnatural visual distortions. We observe that unnatural visual distortions are mainly introduced in the deconvolutional modules of existing generative models. Furthermore, the existing algorithms are with heavily structures, which hinders the deployment of algorithms on edge devices. In this paper, we propose ISP-GAN, a novel lightweight generative adversarial network with inception sub-pixel deconvolution aimed at improving the performance of image colorization. In the generator of our proposed ISP-GAN, we propose a novel inception sub-pixel deconvolutional block (ISP), along with a modified residual convolutional block (MRC), to avoid representational bottlenecks and consequently expand perceptual fields. For the ISP-GAN discriminator, we apply deep-learning-based steganalytic networks to improve the training efficiency of the whole framework and consequently enhance the performance of the corresponding generator. Our ISP-GAN is with lightweight structures and experimental results on the benchmark datasets show that ISP-GAN can achieve state-of-the-art performance in the image colorization task.
C1 [Zhuo, Long; Tan, Shunquan; Li, Bin; Huang, Jiwu] Guangdong Key Lab Intelligent Informat Proc, Shenzhen Key Lab Media Secur, Guangdong Lab Artificial Intelligence & Digital E, Shenzhen 518060, Peoples R China.
   [Zhuo, Long; Tan, Shunquan; Li, Bin; Huang, Jiwu] Shenzhen Univ, Shenzhen Inst Artificial Intelligence & Robot Soc, Shenzhen 518172, Peoples R China.
   [Tan, Shunquan] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
C3 Guangming Laboratory; Shenzhen Institute of Artificial Intelligence &
   Robotics for Society; Shenzhen University; Shenzhen University
RP Tan, SQ (corresponding author), Guangdong Key Lab Intelligent Informat Proc, Shenzhen Key Lab Media Secur, Guangdong Lab Artificial Intelligence & Digital E, Shenzhen 518060, Peoples R China.; Tan, SQ (corresponding author), Shenzhen Univ, Shenzhen Inst Artificial Intelligence & Robot Soc, Shenzhen 518172, Peoples R China.; Tan, SQ (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
EM tansq@szu.edu.cn
RI huang, jw/KVY-9917-2024
FU NSFC [U19B2022, 61772349, 61872244, 62072313, 61806131, 61802262];
   Guangdong Basic and Applied Basic Research Foundation [2019B151502001];
   Shenzhen RD Program [JCYJ20200109105008228, 20200813110043002]; Alibaba
   Group through Alibaba Innovative Research (AIR) Program
FX This work was supported in part by NSFC (U19B2022, 61772349, 61872244,
   62072313, 61806131, 61802262), Guangdong Basic and Applied Basic
   Research Foundation (2019B151502001), and Shenzhen R&D Program
   (JCYJ20200109105008228, 20200813110043002). This work was also supported
   in part by Alibaba Group through Alibaba Innovative Research (AIR)
   Program.
CR Arjovsky M, 2017, PR MACH LEARN RES, V70
   Baldassarre F., 2017, ARXIV PREPRINT ARXIV, p1712.03400, DOI [10.1016/j.patrec.2021.06.021, DOI 10.1016/J.PATREC.2021.06.021]
   Chan KCK, 2021, PROC CVPR IEEE, P14240, DOI 10.1109/CVPR46437.2021.01402
   Charpiat G, 2008, LECT NOTES COMPUT SC, V5304, P126, DOI 10.1007/978-3-540-88690-7_10
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Cherepkov A, 2021, PROC CVPR IEEE, P3670, DOI 10.1109/CVPR46437.2021.00367
   Chia AYS, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024190
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo YF, 2018, IEEE T INF FOREN SEC, V13, P1932, DOI 10.1109/TIFS.2018.2806926
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   IIZUKA S, 2016, ACM T GRAPHIC, V35, P1, DOI DOI 10.1145/2897824.2925974
   Ironi R., 2005, RENDERING TECHNIQUES, P201
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Karras T., 2018, INT CONFLEARN REPRES
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272
   Liang W, 2021, INFRARED PHYS TECHN, V116, DOI 10.1016/j.infrared.2021.103764
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Morimoto Y, 2009, SIGGRAPH 2009 TALKS
   Odena A., 2016, DISTILL, V1, pe3, DOI 10.23915/distill.00003.-URL
   Radford A., 2015, ARXIV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruder S., 2016, ARXIV
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tritrong N, 2021, PROC CVPR IEEE, P4473, DOI 10.1109/CVPR46437.2021.00445
   Wan SH, 2020, IEEE T MULTIMEDIA, V22, P1756, DOI 10.1109/TMM.2020.2976573
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Yi-Chin Huang, 2005, 13th Annual ACM International Conference on Multimedia, P351, DOI 10.1145/1101149.1101223
   Zeng JS, 2019, IEEE T INF FOREN SEC, V14, P2735, DOI 10.1109/TIFS.2019.2904413
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhao J, 2016, 2016 IEEE MTT-S INTERNATIONAL WIRELESS SYMPOSIUM (IWS), DOI 10.1109/ICSSSM.2016.7538614
NR 39
TC 2
Z9 2
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24977
EP 24994
DI 10.1007/s11042-022-12587-8
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000771882300015
DA 2024-07-18
ER

PT J
AU Haider, MI
   Shah, T
   Ali, A
   Shah, D
   Khalid, I
AF Haider, Muhammad Imran
   Shah, Tariq
   Ali, Asif
   Shah, Dawood
   Khalid, Ijaz
TI Pseudo random sequences based on elliptic curve subgroups and
   mathematical model for its application to digital image security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Elliptic curve; Subgroup; Pseudo random number; S-box; Image encryption
ID GENERATOR; SYSTEM
AB The security strength of the elliptic curve cryptosystems (ECC) is due to its core operations-based group law. This aspect of the elliptic curve provides key service to ensure security against modern cryptanalysis. However, the excess use of group law in EC based algorithms make it computationally hard for real time applications. In this context, this paper presented a smart-like algorithm based on subgroup co-set operations. The suggested scheme uses all co-sets that generates multiple sequences that can smoothly be adopted in most promising communication architectures of the future such as internet of things (IoT). Besides, the subgroup structure on a small prime with possible embedding is managed to construct efficient substitution box (S-box). Whereas, the performance of the proposed S-box is examined via standardized tests thus found significant for multimedia data security applications. Moreover, a small prime based EC subgroup coset model is designed, that generates a set of experimentally verified independent pseudo random streams. The atypical mathematical model for its application to image data encryption is established, by combining the S-box module (SM) and subgroup coset module (ES-PM). Several statistical tests revealed that the proposed technique is suitable for various cryptographic applications.
C1 [Haider, Muhammad Imran; Shah, Tariq; Ali, Asif; Shah, Dawood; Khalid, Ijaz] Quaid I Azam Univ, Dept Math, Islamabad, Pakistan.
C3 Quaid I Azam University
RP Haider, MI (corresponding author), Quaid I Azam Univ, Dept Math, Islamabad, Pakistan.
EM mimran@math.qau.edu.pk
CR Abd El-Latif AA, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58636-w
   Abd El-Latif AA, 2013, AEU-INT J ELECTRON C, V67, P136, DOI 10.1016/j.aeue.2012.07.004
   Adams C., 1990, Journal of Cryptology, V3, P27, DOI 10.1007/BF00203967
   Akhshani A, 2014, COMMUN NONLINEAR SCI, V19, P101, DOI 10.1016/j.cnsns.2013.06.017
   [Anonymous], 2008, ELLIPTIC CURVES NUMB, DOI DOI 10.1201/9781420071474
   Azimi Z, 2020, MULTIMED TOOLS APPL, V79, P1727, DOI 10.1007/s11042-019-08375-6
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Bansal M, 2021, ARCH COMPUT METHOD E, V28, P1147, DOI 10.1007/s11831-020-09409-1
   Brown J, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59080-6
   Çavusoglu Ü, 2017, NONLINEAR DYNAM, V87, P1081, DOI 10.1007/s11071-016-3099-0
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Chiang YT, 2013, APPL MECH MATER, V311, P99, DOI 10.4028/www.scientific.net/AMM.311.99
   Farwa S, 2020, MULTIMED TOOLS APPL, V79, P28225, DOI 10.1007/s11042-020-09324-4
   Gallian J., 2010, CONT ABSTRACT ALGEBR, V43, P84
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Haider MI, 2021, MULTIMED TOOLS APPL, V80, P4693, DOI 10.1007/s11042-020-09892-5
   Hussain I, 2013, NEURAL COMPUT APPL, V22, P1085, DOI 10.1007/s00521-012-0870-0
   Ibrahim S, 2020, IEEE ACCESS, V8, P194289, DOI 10.1109/ACCESS.2020.3032403
   Jia S., 2016, J. Inform. Hiding Multimedia SignalProcess., V7, P637
   Jiang WG, 2017, NAT COMMUN, V8, P1, DOI 10.1038/ncomms15066
   Kang XJ, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115670
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   Kumar M. M., 2020, COMPUT METHODS DATA, V1227, P207
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   LAI XJ, 1991, LECT NOTES COMPUT SC, V473, P389
   Li W, 2021, OPT LASER ENG, V136, DOI 10.1016/j.optlaseng.2020.106319
   Liu GJ, 2015, NONLINEAR DYNAM, V82, P1867, DOI 10.1007/s11071-015-2283-y
   Liu Q, 2020, IEEE ACCESS, V8, P83596, DOI 10.1109/ACCESS.2020.2991420
   Matsui M., 1993, ADV CRYPTOLOGY, P23
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   Nian-Sheng L, 2011, COMMUN NONLINEAR SCI, V16, P761, DOI 10.1016/j.cnsns.2010.04.021
   Özkaynak F, 2019, NEURAL COMPUT APPL, V31, P3317, DOI 10.1007/s00521-017-3287-y
   Özkaynak F, 2017, SIGNAL IMAGE VIDEO P, V11, P659, DOI 10.1007/s11760-016-1007-1
   Ramesh A., 2015, 2015 INT C TRENDS AU, P1, DOI [10.1109/ITACT.2015.7492652, DOI 10.1109/ITACT.2015.7492652]
   Ran QW, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-1958-y
   Reyad O, 2015, COMM COM INF SC, V566, P34, DOI 10.1007/978-3-319-26404-2_3
   Reyad Z., 2016, Appl.Math. Inf. Sci., V10, P1283
   Shah D, 2020, MICROPROCESS MICROSY, V77, DOI 10.1016/j.micpro.2020.103181
   Shah D, 2020, MULTIDIM SYST SIGN P, V31, P885, DOI 10.1007/s11045-019-00689-w
   Shah T, 2020, WIRELESS PERS COMMUN, V113, P1201, DOI 10.1007/s11277-020-07274-6
   Shahgholian-Ghahfarokhi D, 2021, MECH BASED DES STRUC, V49, P1059, DOI 10.1080/15397734.2019.1704777
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   The University of Southern California (USC) Signal and Image Processing Institute (SIPI), IM DAT
   Tian Y, 2018, NONLINEAR DYNAM, V94, P2115, DOI 10.1007/s11071-018-4478-5
   Toughi S, 2017, SIGNAL PROCESS, V141, P217, DOI 10.1016/j.sigpro.2017.06.010
   ul Haq T, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102592
   ul Haq T, 2020, OPTIK, V217, DOI 10.1016/j.ijleo.2020.164922
   Wang XY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-66486-9
   Wang X, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040781
   Wang Y, 2016, NONLINEAR DYNAM, V83, P2373, DOI 10.1007/s11071-015-2488-0
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Ye GD, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-78127-2
   Yu SS, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105816
   Zahid AH, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030437
   Zhang YQ, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106040
NR 55
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 23709
EP 23734
DI 10.1007/s11042-022-12358-5
EA MAR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770549800005
DA 2024-07-18
ER

PT J
AU Zhai, LJ
   Sheng, DH
AF Zhai, Lijie
   Sheng, Duanhai
TI Image information loss estimation of video stream based on improved
   SPIHT algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wavelet transform; Information loss; Threshold optimization; SPIHT
ID COMPRESSION
AB With the continuous development of multimedia technology, digital image and video data show a massive growth. Many files containing image and video data often need to be exchanged between different users and systems, which requires effective methods to store and transfer these files. The application of video image compression and coding technology is more and more extensive. Its outstanding problem is the large amount of data, requiring a lot of transmission bandwidth and high real-time. The traditional Set Partitioning in Hierarchical Trees (SPIHT) algorithm has the disadvantages of repeated operation and large storage. In order to ensure the real-time image transmission, obtain high compression ratio and reduce the loss of image information, a new improved algorithm for image compression technology is proposed. The improved algorithm MSPIHT (modified SPIHT) introduces fast lifting wavelet transform to improve the transformation process and threshold optimization to improve the quality of real-time image restoration. Simulation results show that the improved method can reduce the loss of video stream image information, and has good real-time performance.
C1 [Zhai, Lijie] Weinan Normal Univ, Dept Phys & Elect Engn, Weinan 714099, Shaanxi, Peoples R China.
   [Sheng, Duanhai] Sichuan AI Link Technol Co Ltd, Xian R&D Ctr, Xian 710100, Shaanxi, Peoples R China.
C3 Weinan Normal University
RP Zhai, LJ (corresponding author), Weinan Normal Univ, Dept Phys & Elect Engn, Weinan 714099, Shaanxi, Peoples R China.
EM authorzhailijie@wnu.edu.cn
FU Special scientific research project of Shaanxi Provincial Department of
   Education [19JK0288]
FX Special scientific research project of Shaanxi Provincial Department of
   Education (2019) Application of content-based image retrieval algorithm
   in x-ray point feeder (19JK0288).
CR Anjaneya P, 2020, INT J SPEECH TECHNOL, V23, P737, DOI 10.1007/s10772-020-09725-8
   Cai YQ, 2019, FRONT INFORM TECH EL, V20, P716, DOI 10.1631/FITEE.1700737
   Dua Y, 2020, OPT ENG, V59, DOI 10.1117/1.OE.59.9.090902
   Esmaiel H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235271
   Feng WZ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19040946
   Galan-Hernandez JC, 2018, ENG APPL ARTIF INTEL, V69, P127, DOI 10.1016/j.engappai.2017.12.008
   Gu YY, 2019, MULTIMED TOOLS APPL, V78, P21041, DOI 10.1007/s11042-019-7380-3
   He FZ, 2019, INT J ONLINE BIOMED, V15, P143, DOI 10.3991/ijoe.v15i01.9782
   Hellel O, 2019, IET IMAGE PROCESS, V13, P698, DOI 10.1049/iet-ipr.2018.5345
   Hsieh JH, 2018, IEEE T BIOMED CIRC S, V12, P1450, DOI 10.1109/TBCAS.2018.2871184
   Kabir MA, 2018, J IMAGING, V4, DOI 10.3390/jimaging4050064
   Kim Ho-Young, 2019, IEIE Transactions on Smart Processing & Computing, V8, P347, DOI 10.5573/IEIESPC.2019.8.5.347
   Kong FQ, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13010009
   Landir M, 2019, OPT LASER TECHNOL, V109, P534, DOI 10.1016/j.optlastec.2018.08.040
   Lee RC, 2019, J MED BIOL ENG, V39, P18, DOI 10.1007/s40846-018-0384-z
   Li J, 2019, SIGNAL PROCESS, V159, P72, DOI 10.1016/j.sigpro.2019.01.024
   Nasrullah, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101963
   Pandit S, 2020, INT J MOD PHYS B, V34, DOI 10.1142/S0217979220500617
   Pillai KGR, 2021, MULTIMED TOOLS APPL, V80, P7077, DOI 10.1007/s11042-020-10062-w
   Salih Y. A., 2019, KURD J APPL RES, V4, P90, DOI DOI 10.24017/SCIENCE.2019.2.9
   Sran PK, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102089
   Yuan F, 2021, SIGNAL PROCESS-IMAGE, V91, DOI 10.1016/j.image.2020.116082
   Zhang H, 2020, SIGNAL PROCESS-IMAGE, V84, DOI 10.1016/j.image.2020.115829
NR 23
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36275
EP 36291
DI 10.1007/s11042-021-11572-x
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000770549800027
DA 2024-07-18
ER

PT J
AU Rangarajan, AK
   Balu, EJ
   Boligala, MS
   Jagannath, A
   Ranganathan, BN
AF Rangarajan, Aravind Krishnaswamy
   Balu, Edwin Jayaraj
   Boligala, Muni Sekhar
   Jagannath, Arjun
   Ranganathan, Badri Narayanan
TI A low-cost UAV for detection of <i>Cercospora</i> leaf spot in okra
   using deep convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Agricultural Robotics; UAV; Convolutional neural network; Okra;
   Cercospora leaf spot
ID PLANT-DISEASE; FARM SIZE; MARKET
AB Artificial Intelligence (AI)-enabled agricultural robotics is expected to significantly disrupt the domain of agriculture with promise of profitable farming. However, significant challenges exist while deploying such technologies in economically backward countries in a cost-effective manner that can ensure profitability. This study focusses on identification of Cercospora Leaf Spot (CLS) disease in the okra plant, which is also referred to as lady's finger or Abelmoschus esculentus L. The disease is identified by using deep learning models on images acquired using a modified cost-effective quadcopter fitted with a camera. Two deep learning models, namely SqueezeNet and ResNet-18, were used for this study with a validation accuracy of 99.1% and 99% respectively. Testing of the models with the images collected using the modified quadcopter produced an accuracy of 92.3% and 94.6% respectively. The misclassifications have been analysed using confusion matrices and possible reasons affecting the classification process are discussed. In addition, the learning process has been visualized using feature parameters from different layers with t-SNE algorithm that reduces the dimension of the input parameters. The internal representation of the last feature extraction layer has been assessed using Class Activated Mapping (CAM). Further, the effect of motion blur on disease identification has been analysed using confusion matrix and CAM. For effective disease detection, it is required that the proposed quadcopter system is restricted to operate within certain limits. Finally, an insight on the future directions for improvement has been provided.
C1 [Rangarajan, Aravind Krishnaswamy; Balu, Edwin Jayaraj; Boligala, Muni Sekhar; Jagannath, Arjun; Ranganathan, Badri Narayanan] SASTRA Deemed Univ, Sch Mech Engn, Thanjavur 613401, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Ranganathan, BN (corresponding author), SASTRA Deemed Univ, Sch Mech Engn, Thanjavur 613401, Tamil Nadu, India.
EM badrinamyanan@mech.sastra.edu
OI Ranganathan, Badri/0000-0001-6024-9789
CR Abdulridha J, 2020, PRECIS AGRIC, V21, P955, DOI 10.1007/s11119-019-09703-4
   Alsharif MH, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010088
   [Anonymous], 1997, FAOSTAT STAT DAT
   Barbedo JGA, 2018, BIOSYST ENG, V172, P84, DOI 10.1016/j.biosystemseng.2018.05.013
   Bharati Puja, 2020, Computational Intelligence in Pattern Recognition. Proceedings of CIPR 2019. Advances in Intelligent Systems and Computing (AISC 999), P657, DOI 10.1007/978-981-13-9042-5_56
   Bohnenkamp D, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11212495
   Bouabdallah S, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P153, DOI 10.1109/IROS.2007.4399042
   CORNIA GA, 1985, WORLD DEV, V13, P513, DOI 10.1016/0305-750X(85)90054-3
   DadrasJavan F, 2019, J PLANT DIS PROTECT, V126, P307, DOI 10.1007/s41348-019-00234-8
   Das VK, 2018, DECISION, V45, P185, DOI 10.1007/s40622-018-0177-9
   Duarte-Carvajalino JM, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101513
   Eastwood R, 2004, HDB AGR EC, V4, P3323
   Ha JG, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042621
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Heltberg R, 1998, WORLD DEV, V26, P1807, DOI 10.1016/S0305-750X(98)00084-9
   Hu GS, 2019, COMPUT ELECTRON AGR, V163, DOI 10.1016/j.compag.2019.104852
   Iandola Forrest N, 2016, SQUEEZENET ALEXNET L
   Jha K, 2019, ARTIF INTELL AGR, V2, P1, DOI 10.1016/j.aiia.2019.05.004
   Jiang Z., 2018, ACM SysML
   Kalita Dhruba Jyoti, 2020, Social Networking and Computational Intelligence. Proceedings of SCI-2018. Lecture Notes in Networks and Systems (LNNS 100), P243, DOI 10.1007/978-981-15-2071-6_20
   Kerkech M, 2020, COMPUT ELECTRON AGR, V174, DOI 10.1016/j.compag.2020.105446
   Kerkech M, 2018, COMPUT ELECTRON AGR, V155, P237, DOI 10.1016/j.compag.2018.10.006
   Liu B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010011
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Lowder SK, 2016, WORLD DEV, V87, P16, DOI 10.1016/j.worlddev.2015.10.041
   Lowenberg-DeBoer J, 2020, PRECIS AGRIC, V21, P278, DOI 10.1007/s11119-019-09667-5
   Lu JZ, 2017, COMPUT ELECTRON AGR, V135, P289, DOI 10.1016/j.compag.2017.01.017
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Mogili UMR, 2018, PROCEDIA COMPUT SCI, V133, P502, DOI 10.1016/j.procs.2018.07.063
   Mondino EB, 2017, EUR J REMOTE SENS, V50, P310, DOI 10.1080/22797254.2017.1328269
   Pilleron Sophie, 2014, Int Psychogeriatr, P1
   Polder G, 2019, IFAC PAPERSONLINE, V52, P12, DOI 10.1016/j.ifacol.2019.12.482
   Press Trust of India, 2016, BUSINESS STANDARD
   Radoglou-Grammatikis P, 2020, COMPUT NETW, V172, DOI 10.1016/j.comnet.2020.107148
   Strange RN, 2005, ANNU REV PHYTOPATHOL, V43, P83, DOI 10.1146/annurev.phyto.43.113004.133839
   Sugiura R, 2018, 2018 ASABE ANN INT M, DOI [10.13031/aim.201800594, DOI 10.13031/AIM.201800594]
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Tetila EC, 2017, IEEE GEOSCI REMOTE S, V14, P2190, DOI 10.1109/LGRS.2017.2743715
   Tharwat A, 2021, APPL COMPUT INFORM, V17, P168, DOI 10.1016/j.aci.2018.08.003
   Tsouros DC, 2019, INFORMATION, V10, DOI 10.3390/info10110349
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang AL, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19224927
   Yang YT, 2020, COMPUT IND, V123, DOI 10.1016/j.compind.2020.103306
   Ye HC, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12060938
   Zecha CW, 2013, J SENS SENS SYST, V2, P51, DOI 10.5194/jsss-2-51-2013
   Zhang NQ, 2002, COMPUT ELECTRON AGR, V36, P113, DOI 10.1016/S0168-1699(02)00096-0
   Zhang X, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11131554
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
   Zhou J, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105576
NR 49
TC 4
Z9 4
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21565
EP 21589
DI 10.1007/s11042-022-12464-4
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000769836800008
DA 2024-07-18
ER

PT J
AU Jia, X
   Wang, YB
   Peng, YX
   Chen, SY
AF Jia, Xin
   Wang, Yunbo
   Peng, Yuxin
   Chen, Shengyong
TI Semantic association enhancement transformer with relative position for
   image captioning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transformer; Image captioning; Semantic connection; Relative position
AB Transformer-based architectures have shown encouraging results in image captioning. They usually utilize self-attention based methods to establish the semantic association between objects in an image for predicting caption. However, when appearance features between the candidate object and query object show weak dependence, the self-attention based methods are hard to capture the semantic association between them. In this paper, a Semantic Association Enhancement Transformer model is proposed to address the above challenge. First, an Appearance-Geometry Multi-Head Attention is introduced to model a visual relationship by integrating the geometry features and appearance features of the objects. The visual relationship characterizes the semantic association and relative position among the objects. Secondly, a Visual Relationship Improving module is presented to weigh the importance of appearance feature and geometry feature of query object to the modeled visual relationship. Then, the visual relationship among different objects is adaptively improved according to the constructed importance, especially the objects with weak dependence on appearance features, thereby enhancing their semantic association. Extensive experiments on MS COCO dataset demonstrate that the proposed method outperforms the state-of-the-art methods.
C1 [Jia, Xin; Chen, Shengyong] Tianjin Univ Technol, Engn Res Ctr Learning Based Intelligent Syst, Minist Educ, Tianjin 300384, Peoples R China.
   [Jia, Xin; Chen, Shengyong] Tianjin Univ Technol, Key Lab Comp Vis & Syst, Minist Educ, Tianjin 300384, Peoples R China.
   [Wang, Yunbo; Peng, Yuxin] Peking Univ, Wangxuan Inst Comp Technol, Beijing 100871, Peoples R China.
C3 Tianjin University of Technology; Tianjin University of Technology;
   Peking University
RP Chen, SY (corresponding author), Tianjin Univ Technol, Engn Res Ctr Learning Based Intelligent Syst, Minist Educ, Tianjin 300384, Peoples R China.; Chen, SY (corresponding author), Tianjin Univ Technol, Key Lab Comp Vis & Syst, Minist Educ, Tianjin 300384, Peoples R China.
EM sy@ieee.org
RI Chen, S./H-3083-2011
OI Chen, S.Y./0000-0002-6705-3831
FU National Natural Science Foundation of China [61925201, 62132001,
   U21B2025, 62020106004, 92048301]; National Key R&D Program of China
   [2018YFB1305200]
FX This work was supported by the National Natural Science Foundation of
   China under Grants (61925201, 62132001, U21B2025, 62020106004, and
   92048301) and the National Key R&D Program of China (2018YFB1305200).
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Banerjee S., 2005, P WORKSHOP INTRINSIC, P65
   Bansal M, 2021, ARCH COMPUT METHOD E, V28, P1147, DOI 10.1007/s11831-020-09409-1
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J., 2018, BERT PRE TRAINING DE
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Guo LT, 2020, IEEE T MULTIMEDIA, V22, P2149, DOI 10.1109/TMM.2019.2951226
   Herdade S, 2019, ADV NEUR IN, V32
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Huang L, 2019, ADV NEUR IN, V32
   Huang YQ, 2020, IEEE T IMAGE PROCESS, V29, P4013, DOI 10.1109/TIP.2020.2969330
   Ji JZ, 2020, IEEE T IMAGE PROCESS, V29, P7615, DOI 10.1109/TIP.2020.3004729
   Jiang WH, 2018, LECT NOTES COMPUT SC, V11206, P510, DOI 10.1007/978-3-030-01216-8_31
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Li G, 2019, IEEE I CONF COMP VIS, P8927, DOI 10.1109/ICCV.2019.00902
   Li JY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163260
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Longteng Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10324, DOI 10.1109/CVPR42600.2020.01034
   Monika, 2021, Computational Methods and Data Engineering. Proceedings of ICMDE 2020. Advances in Intelligent Systems and Computing (AISC 1227), P207, DOI 10.1007/978-981-15-6876-3_16
   Naqvi N, 2020, MULTIMED TOOLS APPL, V79, P24429, DOI 10.1007/s11042-020-09128-6
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Qin Y, 2019, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2019.00856
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Ryan K, 2014, ARXIV1411253
   Shen XQ, 2020, MULTIMED TOOLS APPL, V79, P26661, DOI 10.1007/s11042-020-09294-7
   Shi Z., 2020, Association for Computational Linguistics, P7454
   Tran Alasdair, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13032, DOI 10.1109/CVPR42600.2020.01305
   Vaswani A, 2017, ADV NEUR IN, V30
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang L, 2020, AAAI CONF ARTIF INTE, V34, P12176
   Wang P, 2022, MULTIMEDIA SYST, V28, P2015, DOI 10.1007/s00530-020-00671-8
   Wang SW, 2020, MULTIMED TOOLS APPL, V79, P11531, DOI 10.1007/s11042-019-08567-0
   Wen Z, 2021, IEEE T CIRC SYST VID, V31, P1042, DOI 10.1109/TCSVT.2020.2991866
   WU L, 2019, IEEE T CIRCUITS SYST
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yan CG, 2022, IEEE T CIRC SYST VID, V32, P43, DOI 10.1109/TCSVT.2021.3067449
   Yang LY, 2021, IEEE T MULTIMEDIA, V23, P835, DOI 10.1109/TMM.2020.2990074
   Yang X, 2019, PROC CVPR IEEE, P10677, DOI 10.1109/CVPR.2019.01094
   Yao T, 2019, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2019.00271
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yu J, 2020, IEEE T CIRC SYST VID, V30, P4467, DOI 10.1109/TCSVT.2019.2947482
   Zhang Y, 2021, PATTERN RECOGN LETT, V143, P43, DOI 10.1016/j.patrec.2020.12.020
   Zhu XX, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8050739
NR 50
TC 6
Z9 6
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21349
EP 21367
DI 10.1007/s11042-022-12776-5
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000769256200001
DA 2024-07-18
ER

PT J
AU Rao, A
   Rao, CS
   Cheruku, DR
AF Rao, Alluvenkateswara
   Rao, Chanamallu Srinivasa
   Cheruku, Dharma Raj
TI Differentiating digital image forensics and tampering localization by a
   novel hybrid approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer generated images; Natural images; Splicing images; Tampered
   region; Grey wolf optimization; Ant lion optimization
ID NATURAL IMAGES; NEURAL-NETWORK
AB Digital images are very necessary for various fields because of the availability of software and applications, which can create the images as looking reality. Moreover, the categorization of Computer-generated Images (CGI) from Natural Images (NI) is difficult because it can't be differentiated by the human eyes. So, this research developed a novel Knowledge-based Fuzzy Approximation (KBFA) model for differentiating CGI, NI, and Spliced Images (SI). Subsequently, Hybrid Grey Wolf Ant Lion (H-GWAL) optimization approach is developed to the localization of tampered region in a spliced image. Moreover, the proposed H-GWAL algorithm has been utilized for enhancing the classification accuracy of the proposed method. Hence, this method distinguishes the CGI from NI and SI from original images and the classified images are detected by the proposed KBFA with H-GWAL model. Additionally, this method is simulated using Python and the obtained results prove the performance of an innovative method. Moreover, the obtained results in terms of detection accuracy, precision, recall, and F1-measure are compared with recent existing approaches.
C1 [Rao, Alluvenkateswara; Cheruku, Dharma Raj] GITAM Deemed Univ, ECE Dept, Visakhapatnam 530045, Andhra Pradesh, India.
   [Rao, Chanamallu Srinivasa] JNTUK, ECE Dept, UCEV, Vizianagaram 535003, Andhra Pradesh, India.
C3 Gandhi Institute of Technology & Management (GITAM); Jawaharlal Nehru
   Technological University - Kakinada; JNTUK University College of
   Engineering, Vizianagaram
RP Rao, A (corresponding author), GITAM Deemed Univ, ECE Dept, Visakhapatnam 530045, Andhra Pradesh, India.
EM allu.jeevani@gmail.com; chsrao.ece@jntukucev.ac.in;
   dharmaraj.cheruku@gitam.edu
CR Abdel-Basset M, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112824
   Abrahim AR, 2019, CLUSTER COMPUT, V22, P647, DOI 10.1007/s10586-017-1668-8
   Alipour N, 2020, MULTIMED TOOLS APPL, V79, P8249, DOI 10.1007/s11042-019-08597-8
   Vega EAA, 2020, FUTURE GENER COMP SY, V107, P229, DOI 10.1016/j.future.2020.01.016
   Barani MJ, 2019, OPTIK, V187, P205, DOI 10.1016/j.ijleo.2019.04.074
   Jaiswal AK, 2020, MULTIMED TOOLS APPL, V79, P11837, DOI 10.1007/s11042-019-08480-6
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Kabbai L, 2019, VISUAL COMPUT, V35, P679, DOI 10.1007/s00371-018-1503-0
   Kanwal N, 2020, MULTIMED TOOLS APPL, V79, P12829, DOI 10.1007/s11042-020-08621-2
   Kilic H, 2020, NEURAL COMPUT APPL, V32, P3803, DOI 10.1007/s00521-018-3871-9
   Liu YQ, 2019, IEEE T INF FOREN SEC, V14, P2551, DOI 10.1109/TIFS.2019.2902826
   Long M, 2019, MULTIMED TOOLS APPL, V78, P489, DOI 10.1007/s11042-017-5101-3
   Pham NT, 2019, MULTIMED TOOLS APPL, V78, P12405, DOI 10.1007/s11042-018-6792-9
   Ozgen A.C., 2018, P SIGN PROC COMM APP, P1, DOI [10.1109/SIU.2018.8404600, DOI 10.1109/SIU.2018.8404600]
   Quan WZ, 2018, IEEE T INF FOREN SEC, V13, P2772, DOI 10.1109/TIFS.2018.2834147
   Rao Y, 2020, IEEE ACCESS, V8, P25611, DOI 10.1109/ACCESS.2020.2970735
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Sharma S, 2019, INT J IMAGE GRAPHICS, V11
   Sharma S, 2018, OPTIK, V172, P470, DOI 10.1016/j.ijleo.2018.07.021
   Soni R, 2019, MULTIMED TOOLS APPL, V78, P31757, DOI 10.1007/s11042-019-07998-z
   Tan D. Q., 2016, Pattern Recognition and Image Analysis, V26, P720, DOI 10.1134/S1054661816040167
   Tim SCW, 2020, COMPUT VIS IMAGE UND, V191, DOI 10.1016/j.cviu.2018.08.002
   Wang JW, 2019, IEEE T CIRC SYST VID, V29, P2775, DOI 10.1109/TCSVT.2018.2867786
   Xiao B, 2020, INFORM SCIENCES, V511, P172, DOI 10.1016/j.ins.2019.09.038
   Xue F, 2019, MULTIMED TOOLS APPL, V78, P9895, DOI 10.1007/s11042-018-6611-3
   Zeng H, 2017, MULTIMED TOOLS APPL, V76, P4783, DOI 10.1007/s11042-016-3712-8
   Zhang RS, 2020, J COMPUT SCI TECH-CH, V35, P592, DOI 10.1007/s11390-020-0216-9
   Zhang WW, 2019, MULTIMED TOOLS APPL, V78, P20113, DOI 10.1007/s11042-019-7288-y
   Zheng LL, 2019, J VIS COMMUN IMAGE R, V58, P380, DOI 10.1016/j.jvcir.2018.12.022
NR 29
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18693
EP 18713
DI 10.1007/s11042-022-12257-9
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766438300017
DA 2024-07-18
ER

PT J
AU Zhang, CW
   Jia, DY
   Wu, NK
   Guo, ZG
   Ge, HR
AF Zhang, Chuanwang
   Jia, Dongyao
   Wu, Nengkai
   Guo, Zhigang
   Ge, Hairui
TI Autofocus method based on multi regions of interest window for cervical
   smear images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autofocus; Dynamic ROI focus window; Cervical smear image; Image
   denoising
ID ALGORITHM; MICROSCOPE; ROBUST
AB Autofocus methods play crucial roles in optical systems, which closely relate to the collected image quality. Due to the different focal lengths of cervical areas in smears, existing focusing approaches often result in blurry images of lymphocytes and epithelial cells, which are the keys for the cervical cancer detection. Aiming at this problem, a novel focus method based on multi regions of interest window is presented. The proposed approach applies multiple-median filter and histogram equalization for the image denoising. Multi-ROI (Region of interest) focus window consisting of image processing, selective search and BP (Back Propagation) neural network is used for the autofocus. Comprehensive analysis denotes that the proposed autofocus algorithm achieves the accuracy of 93.7% and an average focusing time (sec/mm(2)) of 11.89. Validation on another dataset CC proves its robustness, comparison with the recent studies shows its practical performance. The results which we obtained suggest that the proposed autofocus model based on multi-ROI window can be used effectively in scanning of cervical cell images.
C1 [Zhang, Chuanwang; Jia, Dongyao; Wu, Nengkai; Guo, Zhigang; Ge, Hairui] Beijing Jiaotong Univ, Sch Elect & Informat Engn, 3 Shangyuancun Haidian Dist, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University
RP Jia, DY (corresponding author), Beijing Jiaotong Univ, Sch Elect & Informat Engn, 3 Shangyuancun Haidian Dist, Beijing 100044, Peoples R China.
EM dongyaojia1974@163.com
FU Beijing Jiaotong University Technology development project [W19L00130]
FX Beijing Jiaotong University Technology development project(W19L00130).
CR Anwar S, 2019, IEEE I CONF COMP VIS, P3155, DOI 10.1109/ICCV.2019.00325
   Chang Y, 2018, IEEE ACCESS, V6, P11782, DOI 10.1109/ACCESS.2018.2797872
   Chen G, 2018, PROC SPIE, V10827, DOI 10.1117/12.2500193
   Cruza JF, 2019, ULTRASONICS, V99, DOI 10.1016/j.ultras.2019.105965
   Cui JN, 2019, EUR J NUCL MED MOL I, V46, P2780, DOI 10.1007/s00259-019-04468-4
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dastidar TR, 2019, IEEE COMPUT SOC CONF, P1049, DOI 10.1109/CVPRW.2019.00137
   Dastidar TR, 2020, BIOMED OPT EXPRESS, V11, P480, DOI 10.1364/BOE.379780
   Deivalakshmi S, 2016, AEU-INT J ELECTRON C, V70, P757, DOI 10.1016/j.aeue.2016.03.002
   El Helou M, 2020, IEEE T IMAGE PROCESS, V29, P4885, DOI 10.1109/TIP.2020.2976814
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Gai S, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.07.032
   GE Y H, 2019, P 9 INT C BIOM ENG T, P180
   Gu CC, 2015, MICROSC RES TECHNIQ, V78, P382, DOI 10.1002/jemt.22484
   Hao Q, 2018, OPT COMMUN, V410, P269, DOI 10.1016/j.optcom.2017.10.017
   Hecht-Nielsen R., 1989, IJCNN: International Joint Conference on Neural Networks (Cat. No.89CH2765-6), P593, DOI 10.1109/IJCNN.1989.118638
   Ingram M, 2020, INSIGHT, V62, P408, DOI 10.1784/insi.2020.62.7.408
   Ivanov T, 2020, PROC SPIE, V11511, DOI 10.1117/12.2568990
   Jiang SW, 2018, BIOMED OPT EXPRESS, V9, P1601, DOI 10.1364/BOE.9.001601
   Juocas L, 2019, INT J ADV MANUF TECH, V102, P3217, DOI 10.1007/s00170-019-03407-9
   Kim H., 2019, Microsc. Microanalysis, V25, P182, DOI [DOI 10.1017/S1431927619001648, 10.1017/s1431927619001648]
   Kudryavtsev AV, 2017, ULTRAMICROSCOPY, V182, P216, DOI 10.1016/j.ultramic.2017.07.008
   Kumar MA, 2017, INT J ELECTRON, V104, P692, DOI 10.1080/00207217.2016.1242165
   Li LD, 2017, IEEE T MULTIMEDIA, V19, P1030, DOI 10.1109/TMM.2016.2640762
   Li L, 2019, CHIN OPT LETT, V17, DOI 10.3788/COL201917.061001
   Li QY, 2019, KSII T INTERNET INF, V13, P2529, DOI 10.3837/tiis.2019.05.016
   Li X, 2016, GOOGLE PATENTS
   Li Yu-feng, 2010, Application Research of Computers, V27, P1534, DOI 10.3969/j.issn.1001-3695.2010.04.093
   Liang YX, 2019, OPTIK, V198, DOI 10.1016/j.ijleo.2019.163002
   Liu Ding, 2017, ARXIV PREPRINT ARXIV
   Luo YL, 2021, ACS PHOTONICS, V8, P625, DOI 10.1021/acsphotonics.0c01774
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pirsiavash H, 2011, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2011.5995604
   Qinghua Zhao, 2013, 2013 5th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC 2013), P255, DOI 10.1109/IHMSC.2013.208
   Saito H, 2019, JPN J APPL PHYS, V58, DOI 10.7567/1347-4065/ab28ff
   Santos A, 1997, J MICROSC-OXFORD, V188, P264, DOI 10.1046/j.1365-2818.1997.2630819.x
   Sara U., 2019, J COMPUT COMMUN, V7, P8, DOI [10.4236/jcc.2019.73002, DOI 10.4236/JCC.2019.73002]
   Shah MI, 2017, CYTOM PART A, V91A, P800, DOI 10.1002/cyto.a.23142
   Shilston RT, 2012, BLUR PERCEPTION EVAL
   Tang JR, 2017, APPL SOFT COMPUT, V55, P31, DOI 10.1016/j.asoc.2017.01.053
   Torre LA, 2015, GLOBAL CANC STAT 201, V65, P87
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang ZJ, 2015, BIOMED OPT EXPRESS, V6, P4353, DOI 10.1364/BOE.6.004353
   Weng JF, 2021, OPT EXPRESS, V29, P1, DOI 10.1364/OE.421926
   Wu H, 2019, 2019 INT C BIG DAT E, P88, DOI DOI 10.2991/ACSR.K.191223.020
   Yan ZD, 2018, APPL OPTICS, V57, P9714, DOI 10.1364/AO.57.009714
   YEO TTE, 1993, IMAGE VISION COMPUT, V11, P629, DOI 10.1016/0262-8856(93)90059-P
   Yu JM, 2017, IEEE ACCESS, V5, P12275, DOI 10.1109/ACCESS.2017.2718558
   Zhai Y., 2011, ACTA OPT SIN, V31, DOI 10.3788/AOS201131.0418002
   Zhang FS, 2017, CLUSTER COMPUT, V20, P485, DOI 10.1007/s10586-017-0752-4
   Zhang H, 2013, AEU-INT J ELECTRON C, V67, P799, DOI 10.1016/j.aeue.2013.04.001
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang XB, 2019, IEEE ACCESS, V7, P64837, DOI 10.1109/ACCESS.2019.2914186
   Zhang YP, 2018, SENSOR MATER, V30, P1165, DOI 10.18494/SAM.2018.1785
   Zhou R, 2018, REAL TIME PHOTONIC M
NR 55
TC 3
Z9 3
U1 5
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18783
EP 18805
DI 10.1007/s11042-022-12247-x
EA MAR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766438300010
DA 2024-07-18
ER

PT J
AU Bisen, D
   Shukla, R
   Rajpoot, N
   Maurya, P
   Uttam, AK
   Arjaria, SK
AF Bisen, Dhananjay
   Shukla, Rishabh
   Rajpoot, Narendra
   Maurya, Praphull
   Uttam, Atul Kr.
   Arjaria, Siddhartha Kr.
TI Responsive human-computer interaction model based on recognition of
   facial landmarks using machine learning algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human computer interaction; Gesture recognition; Facial recognition;
   DLib; Eye blink detection; HOG; EAR
ID FACE
AB This paper is addressed on the idea of building up a model to control computer systems by utilizing facial landmarks like eyes, nose and head gestures. The face recognition systems mainly detect and recognize eyes, nose and head gestures to control the movement of the mouse cursor in order to operate computer system in real time. This paper proposes the facial landmarks based human-computer interaction model in which histogram of oriented gradients (HOG) has been taken for global facial feature identification and extraction that is considered as HOG descriptors. Furthermore, pre-trained linear SVM classifier gets extracted features to detect whether it is a human face or not, including use of pyramid based images and sliding window algorithm. Moreover pre-trained ensemble of Regression Trees algorithm is applied to recognize facial landmarks such as eyes, eyebrows, nose, mouth, and jawline. The main purpose is to effectively utilize facial landmarks and allow the user to perform activities mapped to explicit eye blinks, nose and head motions using PC webcam. In this model, eye blinks has been detected through estimated value of eye aspect ratio (EAR) and newly proposed beta parameter. Accordingly classification report has generated for both estimation and analysed best results for beta parameter in terms of accuracy with 98.33%, precision with 100%, recall with 98.33% and F1 score with 99.16% under good lighting conditions.
C1 [Bisen, Dhananjay] Madhav Inst Sci & Technol, Gwalior, India.
   [Shukla, Rishabh; Rajpoot, Narendra; Maurya, Praphull; Uttam, Atul Kr.; Arjaria, Siddhartha Kr.] Rajkiya Engn Coll Banda, Banda, India.
C3 Madhav Institute of Technology & Science
RP Bisen, D (corresponding author), Madhav Inst Sci & Technol, Gwalior, India.
EM bisen.it2007@gmail.com; rishabhshukla475@gmail.com;
   nrajpoot1146@gmail.com; praphullmaurya123@gmail.com;
   atuluttam150998@gmail.com; arjarias@gmail.com
RI bisen, dhananjay/ABG-6485-2021
OI bisen, dhananjay/0000-0003-4165-3959
CR Akakin HÇ, 2011, IMAGE VISION COMPUT, V29, P470, DOI 10.1016/j.imavis.2011.03.001
   Ananthakumar A, 2018, IEEE SW SYMP IMAG, P117, DOI 10.1109/SSIAI.2018.8470351
   Bisen D, 2021, MULTIMED TOOLS APPL, V80, P6443, DOI 10.1007/s11042-020-10038-w
   Bulling A, 2010, IEEE PERVAS COMPUT, V9, P8, DOI 10.1109/MPRV.2010.86
   Caschera M. C., 2007, International Journal of Web and Grid Services, V3, P82, DOI 10.1504/IJWGS.2007.012638
   Chaubey G, 2021, NATL ACAD SCI LETT, V44, P233, DOI 10.1007/s40009-020-00979-z
   Colaco S, 2020, I C INF COMM TECH CO, P584, DOI [10.1109/ICTC49870.2020.9289429, 10.1109/ictc49870.2020.9289429]
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Elleuch H., 2016, ADV CONCEPTS INTELLI, V10016
   Elleuch H, 2014, 2014 INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD (FICLOUD), P393, DOI 10.1109/FiCloud.2014.70
   Fernandez A, 2013, IMAGE ANAL RECOGNITI, V7950
   Geetha A, 2009, EXPERT SYST APPL, V36, P303, DOI 10.1016/j.eswa.2007.09.002
   Johnston B, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0324-4
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Konstantin K, 2020, FAST FACIAL LANDMARK, DOI [10.13140/RG.2.2.32735.07847/1, DOI 10.13140/RG.2.2.32735.07847/1]
   Liu JQ, 2019, IEEE IMAGE PROC, P375, DOI [10.1109/ICIP.2019.8802970, 10.1109/icip.2019.8802970]
   Maior CS, 2018, P PROB SAF ASS MAN P
   Mardanbegi D., 2012, P S EYE TRACK RES AP, P139, DOI DOI 10.1145/2168556.2168578
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Rosebrock A, 2021, FACIAL LANDMARKS DLI
   Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002
   Sidenmark L, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1161, DOI 10.1145/3332165.3347921
   Skodras E, 2015, IMAGE VISION COMPUT, V36, P51, DOI 10.1016/j.imavis.2015.01.006
   Soukupova T., 2016, 21 COMPUTER VISION W
   Stoimenov S, 2016, 2016 13TH SYMPOSIUM ON NEURAL NETWORKS AND APPLICATIONS (NEUREL), P125
   Vaitukaitis V, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P711
   Zaytseva E, 2012, LECT NOTES COMPUTER, V7441, DOI [10.1007/978-3-642-33275-3_46, DOI 10.1007/978-3-642-33275-3_46]
   Zhang T, 2020, INT J FUZZY SYST, V22, P1330, DOI 10.1007/s40815-020-00825-w
   Zhao JB, 2017, IEEE SYS MAN CYBERN, P2361, DOI 10.1109/SMC.2017.8122975
   Zielasko D, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P113, DOI 10.1109/3DUI.2016.7460040
NR 30
TC 7
Z9 7
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18011
EP 18031
DI 10.1007/s11042-022-12775-6
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766064000004
DA 2024-07-18
ER

PT J
AU Cizmeciler, K
   Erdem, E
   Erdem, A
AF Cizmeciler, Kemal
   Erdem, Erkut
   Erdem, Aykut
TI Leveraging semantic saliency maps for query-specific video summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Query-specific; Video summarization
ID EGOCENTRIC VIDEO; SCENE
AB The immense amount of videos being uploaded to video sharing platforms makes it impossible for a person to watch all the videos understand what happens in them. Hence, machine learning techniques are now deployed to index videos by recognizing key objects, actions and scenes or places. Summarization is another alternative as it offers to extract only important parts while covering the gist of the video content. Ideally, the user may prefer to analyze a certain action or scene by searching a query term within the video. Current summarization methods generally do not take queries into account or require exhaustive data labeling. In this work, we present a weakly supervised query-focused video summarization method. Our proposed approach makes use of semantic attributes as an indicator of query relevance and semantic attention maps to locate related regions in the frames and utilizes both within a submodular maximization framework. We conducted experiments on the recently introduced RAD dataset and obtained highly competitive results. Moreover, to better evaluate the performance of our approach on longer videos, we collected a new dataset, which consists of 10 videos from YouTube and annotated with shot-level multiple attributes. Our dataset enables much diverse set of queries that can be used to summarize a video from different perspectives with more degrees of freedom.
C1 [Cizmeciler, Kemal; Erdem, Erkut] Hacettepe Univ, Dept Comp Engn, Ankara, Turkey.
   [Erdem, Aykut] Koc Univ, Dept Comp Engn, Istanbul, Turkey.
C3 Hacettepe University; Koc University
RP Erdem, E (corresponding author), Hacettepe Univ, Dept Comp Engn, Ankara, Turkey.
EM kemalcizmeci@gmail.com; erkut@cs.hacettepe.edu.tr; aerdem@ku.edu.tr
RI Erdem, Aykut/A-2290-2012
OI Erdem, Aykut/0000-0002-6280-8422
FU GEBIP 2018 Award of the Turkish Academy of Sciences; BAGEP 2021 Award of
   the Science Academy
FX This work was supported in part by GEBIP 2018 Award of the Turkish
   Academy of Sciences to E. Erdem, BAGEP 2021 Award of the Science Academy
   to A. Erdem.
CR Basavarajaiah M, 2021, MULTIMED TOOLS APPL, V80, P14459, DOI 10.1007/s11042-020-10460-0
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Goldman DB, 2006, ACM T GRAPHIC, V25, P862, DOI 10.1145/1141911.1141967
   Gong BQ, 2014, ADV NEUR IN, V27
   GYGLI M, 2015, PROC CVPR IEEE, P3090, DOI DOI 10.1109/CVPR.2015.7298928
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Jiang P, 2019, P INT C MULT RETR IC
   Kaushal V, 2021, ARXIV210110514
   Khosla A, 2013, PROC CVPR IEEE, P2698, DOI 10.1109/CVPR.2013.348
   Kim G, 2014, PROC CVPR IEEE, P4225, DOI 10.1109/CVPR.2014.538
   Kothawade S, 2018, ARXIV180908846
   Laganiere R, 2008, P ACM TRECVID VID SU, P144
   Lee YJ, 2015, INT J COMPUT VISION, V114, P38, DOI 10.1007/s11263-014-0794-5
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Li Y., 2010, ACM International Conference on Multimedia, P851
   Lin H., 2011, P 49 ANN M ASS COMP, P510
   Liu W, 2015, PROC CVPR IEEE, P3707, DOI 10.1109/CVPR.2015.7298994
   Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350
   Mendi E, 2013, COMPUT ELECTR ENG, V39, P790, DOI 10.1016/j.compeleceng.2012.11.020
   Monfort M, 2020, IEEE T PATTERN ANAL, V42, P502, DOI 10.1109/TPAMI.2019.2901464
   Mundnich K, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P4155, DOI 10.1109/ICASSP39728.2021.9413394
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Otani M, 2016, AS C COMP VIS
   Otani M, 2019, PROC CVPR IEEE, P7579, DOI 10.1109/CVPR.2019.00778
   Panda R, 2017, IEEE I CONF COMP VIS, P3677, DOI 10.1109/ICCV.2017.395
   Pantazis G, 2020, ARXIV201110432
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Rapantzikos K, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P320, DOI 10.1109/MMSP.2007.4412882
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shao J, 2015, PROC CVPR IEEE, P4657, DOI 10.1109/CVPR.2015.7299097
   Sharghi A, 2018, LECT NOTES COMPUT SC, V11207, P533, DOI 10.1007/978-3-030-01219-9_32
   Sharghi A, 2017, PROC CVPR IEEE, P2127, DOI 10.1109/CVPR.2017.229
   Sharghi A, 2016, LECT NOTES COMPUT SC, V9912, P3, DOI 10.1007/978-3-319-46484-8_1
   Shrikumar A, 2017, PR MACH LEARN RES, V70
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Springenberg J. T., 2015, ARXIV PREPRINT ARXIV
   Sun K, 2017, IEEE INT CON MULTI, P643, DOI 10.1109/ICME.2017.8019411
   Tiwari V., 2021, MULTIMED TOOLS APPL
   Vasudevan AB, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P582, DOI 10.1145/3123266.3123297
   Wolf W, 1996, INT CONF ACOUST SPEE, P1228, DOI 10.1109/ICASSP.1996.543588
   Xiong B, 2014, LECT NOTES COMPUT SC, V8693, P282, DOI 10.1007/978-3-319-10602-1_19
   Xu J, 2015, PROC CVPR IEEE, P2235, DOI 10.1109/CVPR.2015.7298836
   Yeung S., 2014, ARXIV14065824
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang J, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901336
   Zhang Y, 2018, P BRIT MACH VIS C BM
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 49
TC 7
Z9 7
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 17457
EP 17482
DI 10.1007/s11042-022-12442-w
EA MAR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000765701900019
DA 2024-07-18
ER

PT J
AU Daoui, A
   Karmouni, H
   Sayyouri, M
   Qjidaa, H
AF Daoui, Achraf
   Karmouni, Hicham
   Sayyouri, Mhamed
   Qjidaa, Hassan
TI New method for bio-signals zero-watermarking using quaternion shmaliy
   moments and short-time fourier transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Signal zero-watermarking; High-order Shmaliy polynomials; Quaternion
   Shmaliy moments; Signal copyright protection; Short-time Fourier
   transform
ID IMAGE-ANALYSIS; CHARLIER MOMENTS; TCHEBICHEF MOMENTS; FAST COMPUTATION;
   ALGORITHM; CLASSIFICATION; SPECTROGRAM; KRAWTCHOUK; PROTECTION; PRIVACY
AB In this paper, we first present a stable computation of high-order discrete orthonormalized Shmaliy polynomials (SPs). Then, based on SPs we introduce a new type of color image descriptor called Quaternion Shmaliy Moments (QSMs). This descriptor is applied to the copyright protection of bio-signals after converting the latter into color spectrograms images using the Short-Time Fourier Transform (STFT). The proposed method for bio-signal copyright protection is implemented via a novel zero-watermarking scheme. The simulation and comparison results prove on one hand the numerical stability of the proposed computation of high-order SPs, and on the other hand, they demonstrate the robustness of the proposed zero-watermarking scheme against various signal-processing attacks (compression, filtering, noise, etc.).
C1 [Daoui, Achraf; Sayyouri, Mhamed] Sidi Mohamed Ben Abdellah Fez Univ, Natl Sch Appl Sci, Lab Engn Syst & Applicat, Fes, Morocco.
   [Karmouni, Hicham; Qjidaa, Hassan] Sidi Mohamed Ben Abdellah Fez Univ, Fac Sci, Lab Elect Signals & Syst Informat, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Daoui, A (corresponding author), Sidi Mohamed Ben Abdellah Fez Univ, Natl Sch Appl Sci, Lab Engn Syst & Applicat, Fes, Morocco.
EM achraf.daoui@usmba.ac.ma; hicham.karmouni@usmba.ac.ma;
   mhamed.sayyouri@usmba.ac.ma; qjidah@yahoo.fr
RI Sayyouri, Mhamed/AAB-5496-2020; Karmouni, Hicham/ACB-0232-2022
OI Sayyouri, Mhamed/0000-0002-1615-419X; Karmouni,
   Hicham/0000-0001-9225-8380; DAOUI, Achraf/0000-0002-2326-9550
CR Ali Z, 2018, FUTURE GENER COMP SY, V88, P400, DOI 10.1016/j.future.2018.05.058
   Ali Z, 2018, FUTURE GENER COMP SY, V82, P290, DOI 10.1016/j.future.2017.12.007
   Ali Z, 2018, IEEE ACCESS, V6, P7930, DOI 10.1109/ACCESS.2018.2799604
   Arora M, 2021, MULTIMED TOOLS APPL, V80, P3039, DOI 10.1007/s11042-020-09726-4
   Asli BHS, 2017, SIGNAL PROCESS, V141, P57, DOI 10.1016/j.sigpro.2017.05.023
   Bansal M, 2021, MULTIMED TOOLS APPL, P1
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Bansal M, 2021, ARCH COMPUT METHOD E, V28, P1147, DOI 10.1007/s11831-020-09409-1
   Benouini R, 2019, PATTERN RECOGN, V91, P100, DOI 10.1016/j.patcog.2019.02.014
   Camacho-Bello C, 2018, PATTERN RECOGN LETT, V112, P332, DOI 10.1016/j.patrec.2018.08.020
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Daoui A., 2020, Embedded Systems and Artificial Intelligence. Proceedings of ESAI 2019. Advances in Intelligent Systems and Computing (AISC 1076), P369, DOI 10.1007/978-981-15-0947-6_35
   Daoui A., 2020, 2020 INT C INT SYST, P1, DOI DOI 10.1109/ISCV49265.2020.9204132
   Daoui A, 2021, EXPERT SYST APPL, V177, DOI 10.1016/j.eswa.2021.114978
   Daoui A, 2021, SIGNAL PROCESS, V180, DOI 10.1016/j.sigpro.2020.107854
   Daoui A, 2021, MULTIMED TOOLS APPL, V80, P1641, DOI 10.1007/s11042-020-09739-z
   Daoui A, 2020, CIRC SYST SIGNAL PR, V39, P4552, DOI 10.1007/s00034-020-01384-z
   Daoui A, 2020, INFORM SCIENCES, V521, P251, DOI 10.1016/j.ins.2020.02.019
   El Ogri O, 2019, PROCEDIA COMPUT SCI, V148, P428, DOI 10.1016/j.procs.2019.01.055
   González G, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/1673283
   Gupta S, 2019, MULTIMED TOOLS APPL, V78, P34157, DOI 10.1007/s11042-019-08232-6
   Hamilton W., 1866, ELEMENTS QUATERNIONS
   Hosny KM, 2018, BIOCYBERN BIOMED ENG, V38, P385, DOI 10.1016/j.bbe.2018.02.006
   Huang JS, 2019, IEEE ACCESS, V7, P92871, DOI 10.1109/ACCESS.2019.2928017
   Jahid T., 2017, 2017 INT C ELECT INF, P1
   Jahid T, 2019, MULTIMED TOOLS APPL, V78, P12183, DOI 10.1007/s11042-018-6757-z
   Karakasis EG, 2013, PATTERN RECOGN, V46, P1998, DOI 10.1016/j.patcog.2013.01.008
   Karmouni H., 2019, J REAL-TIME IMAGE PR, V17, P1
   Karmouni H, 2019, MULTIMED TOOLS APPL, V78, P31245, DOI 10.1007/s11042-019-07961-y
   Karmouni H, 2017, 2017 INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV)
   Karmouni H, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P99
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Monika, 2021, Computational Methods and Data Engineering. Proceedings of ICMDE 2020. Advances in Intelligent Systems and Computing (AISC 1227), P207, DOI 10.1007/978-981-15-6876-3_16
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Morales-Mendoza LJ, 2013, SIGNAL PROCESS, V93, P1785, DOI 10.1016/j.sigpro.2013.01.023
   Mukherjee T, 2019, VISUAL OBJECT TRACKI, DOI [10.5772/intechopen.85382, DOI 10.5772/INTECHOPEN.85382]
   Sangwine SJ, 2001, IEEE IMAGE PROC, P137, DOI 10.1109/ICIP.2001.958972
   Sayyouri M, 2013, J OPT SOC AM A, V30, P2381, DOI 10.1364/JOSAA.30.002381
   Sayyouri M, 2012, PROCEEDINGS OF 2012 INTERNATIONAL CONFERENCE ON COMPLEX SYSTEMS (ICCS12), P289
   Shao ZH, 2016, SIGNAL PROCESS, V120, P522, DOI 10.1016/j.sigpro.2015.10.005
   Thanh TM, 2017, MULTIMED TOOLS APPL, V76, P13455, DOI 10.1007/s11042-016-3750-2
   Takamichi S, 2018, INT WORKSH ACOUSTIC, P286, DOI 10.1109/IWAENC.2018.8521313
   Umapathy K, 2005, IEEE T BIO-MED ENG, V52, P421, DOI 10.1109/TBME.2004.842962
   Wang CP, 2017, MULTIMED TOOLS APPL, V76, P26355, DOI 10.1007/s11042-016-4130-7
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang WJ, 2019, FUTURE GENER COMP SY, V98, P227, DOI 10.1016/j.future.2018.12.060
   Wen Q., 2001, P 3 CHIN INF HID MUL, P102
   Weruaga L, 2007, SIGNAL PROCESS, V87, P1504, DOI 10.1016/j.sigpro.2007.01.006
   Xia ZQ, 2019, SIGNAL PROCESS, V157, P108, DOI 10.1016/j.sigpro.2018.11.011
   Yamni M, 2021, DIGIT SIGNAL PROCESS, V108, DOI 10.1016/j.dsp.2020.102878
   Yamni M, 2019, PROCEDIA COMPUT SCI, V148, P418, DOI 10.1016/j.procs.2019.01.054
   Yap PT, 2007, IEEE T PATTERN ANAL, V29, P2057, DOI 10.1109/TPAMI.2007.70709
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zhang GJ, 2010, PATTERN RECOGN LETT, V31, P548, DOI 10.1016/j.patrec.2009.12.007
   Zhang WJ, 2017, EXPERT SYST APPL, V84, P220, DOI 10.1016/j.eswa.2017.05.014
   Zhang WJ, 2017, BIOMED SIGNAL PROCES, V32, P20, DOI 10.1016/j.bspc.2016.10.004
   Zhu HQ, 2007, PATTERN RECOGN LETT, V28, P1688, DOI 10.1016/j.patrec.2007.04.013
   Zhu HQ, 2007, SIGNAL PROCESS, V87, P687, DOI 10.1016/j.sigpro.2006.07.007
NR 60
TC 2
Z9 2
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 17369
EP 17399
DI 10.1007/s11042-022-12660-2
EA MAR 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000765701900004
DA 2024-07-18
ER

PT J
AU Lin, JY
   Horng, JH
   Chang, CC
AF Lin, Jiang-Yi
   Horng, Ji-Hwei
   Chang, Chin-Chen
TI A reversible and authenticable secret sharing scheme using dual images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding (RDH); Turtle shell (TS) matrix; Dual images;
   Pixel-value differencing histogram (PDH); Rule singular (RS)
AB Reversible data hiding (RDH) is a steganographic method that can restore the cover medium after extracting the embedded secret data. This work proposes a novel RDH scheme based on turtle shell (TS) reference matrix with dual image shadows. By modifying a cover pixel pair, two stego pixel pairs are generated and separately recorded to two image shadows. The first stego pixel pair is embedded with three bits of secret data, while the second stego pixel pair is embedded with one secret bit and require no information for recovery of the cover pixels. Since secret data is embedded through slight modification of cover pixel values, experimental results show that the image shadows have good visual quality and are robust under steganalysis attack. In addition, an authentication mechanism is proposed to detect tampered shadows.
C1 [Lin, Jiang-Yi] Xiamen Univ Technol, Sch Comp & Informat Engn, Xiamen 361024, Peoples R China.
   [Lin, Jiang-Yi; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Horng, Ji-Hwei] Natl Quemoy Univ, Dept Elect Engn, Kinmen 89250, Taiwan.
C3 Xiamen University of Technology; Feng Chia University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
EM alan3c@gmail.com
RI Horng, Jihwei/GPX-5709-2022; Chang, Ching-Chun/JAN-6210-2023
OI Horng, Ji-Hwei/0000-0002-2134-5257
FU Education and Research Project for Young and Middle-aged Teachers in
   Fujian Province [JAT200458]
FX This work is partially supported by the Education and Research Project
   for Young and Middle-aged Teachers in Fujian Province (Grant number:
   JAT200458).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Chang C.-C., 2008, 2008 3 INT C INN COM, P17, DOI 10.1109/ICICIC.2008.149
   Chang CC, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P145, DOI 10.1109/MUE.2009.35
   Chang CC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P89, DOI 10.1109/IIH-MSP.2014.29
   Chang T. Duc, 2007, P IEEE REG 10 C NOV, P1, DOI [10.1109/TENCON.2007.4483783, DOI 10.1109/TENCON.2007.4483783]
   Fridrich J, 2002, PROC SPIE, V4675, P1, DOI 10.1117/12.465263
   Hassan FS, 2020, MULTIMED TOOLS APPL, V79, P30087, DOI 10.1007/s11042-020-09513-1
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Hwang MS, 2003, IEEE T KNOWL DATA EN, V15, P1552, DOI 10.1109/TKDE.2003.1245292
   Jia YJ, 2019, SIGNAL PROCESS, V163, P238, DOI 10.1016/j.sigpro.2019.05.020
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Lin JY, 2019, J REAL-TIME IMAGE PR, V16, P673, DOI 10.1007/s11554-019-00863-0
   Liu YJ, 2018, MULTIMED TOOLS APPL, V77, P25295, DOI 10.1007/s11042-018-5785-z
   Huynh NT, 2015, J VIS COMMUN IMAGE R, V28, P105, DOI 10.1016/j.jvcir.2015.01.011
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Schneier B., 1996, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Weng SW, 2019, INFORM SCIENCES, V489, P136, DOI 10.1016/j.ins.2019.03.032
   Yin ZX, 2020, IEEE T MULTIMEDIA, V22, P874, DOI 10.1109/TMM.2019.2936314
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhang XP, 2004, PATTERN RECOGN LETT, V25, P331, DOI 10.1016/j.patrec.2003.10.014
NR 23
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 17527
EP 17545
DI 10.1007/s11042-022-12430-0
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000765701900008
DA 2024-07-18
ER

PT J
AU Kuo, LW
   Chang, T
   He, CB
AF Kuo, Lungwen
   Chang, Tsuiyueh
   He, Ciou-Bai
TI Research on multimedia application development and color mode of App
   users
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Design; Smartphone; Media; App; Color
ID MOBILE; NEWS; PLATFORM
AB In this rapidly changing technological era, the increasing popularity of mobile devices has driven the prevalence of apps and changed the way people communicate and deliver messages. The maturity and development of technology have enabled faster access to network resources, and the number of services for downloading App applications has increased significantly. Because of the popularity of mobile devices and the convenience of the Internet, News App can immediately read the latest and most immediate domestic and foreign news no matter where you are. Not only has it changed everyone's habit of reading news in the past, but its convenience also allows the public to immediately Grasp the first-hand news. This research uses the theory of use and satisfaction as the main framework to explore the user's personal characteristics, use motivation, and satisfaction after use. The main research object is News App users of smart mobile devices, based on the use and satisfaction theory-related literature. Organize and analyze to establish a research framework, and conduct in-depth relevant research, verification, of the constructed concepts and research hypotheses through quantitative research methods. The results of the study found that the motivations of News App users are the information economy, entertainment relief, knowledge technology, and personal needs. The higher the use level, the higher their motivation needs and satisfaction levels. The color interface is the most blue. Popular, the results of this study can provide a way and reference direction when developing App applications.
C1 [Kuo, Lungwen] Sanming Univ, Dept Prod Design, Sanming, Fujian, Peoples R China.
   [Chang, Tsuiyueh] Tzu Chi Acad, Dept Educ, Cupertino, CA 95014 USA.
   [He, Ciou-Bai] Natl Taiwan Univ Arts, Dept Graph Commun Arts, New Taipei, Taiwan.
C3 Sanming University; National Taiwan University of Arts
RP Chang, T (corresponding author), Tzu Chi Acad, Dept Educ, Cupertino, CA 95014 USA.
EM yueh5031162@yahoo.com.tw
RI Kuo, Lungwen/AAV-1958-2021
OI Kuo, Lungwen/0000-0001-9894-2706
FU Fujian Province Science [FJ2021B190]; Sanming University, Research
   Foundation for Advanced Talent [21YG02S]
FX Supported by Fujian Province Science, Grant Number: FJ2021B190. Sanming
   University, Research Foundation for Advanced Talent, Grant Number:
   21YG02S.
CR Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Areán PA, 2016, DIALOGUES CLIN NEURO, V18, P163
   Badshah S, 2021, MULTIMED TOOLS APPL, V80, P9177, DOI 10.1007/s11042-020-10099-x
   Byun J, 2017, MULTIMED TOOLS APPL, V76, P19665, DOI 10.1007/s11042-016-3369-3
   De Pessemier T, 2016, MULTIMED TOOLS APPL, V75, P3323, DOI 10.1007/s11042-014-2437-9
   Dorgham O, 2018, INT J CLOUD APPL COM, V8, P154, DOI 10.4018/IJCAC.2018010108
   Duffy A, 2020, DIGIT JOURNAL, V8, P1, DOI 10.1080/21670811.2020.1712220
   Dunaway J, 2018, J COMPUT-MEDIAT COMM, V23, P107, DOI 10.1093/jcmc/zmy004
   Duxbury L, 2011, CREATING BALANCE? INTERNATIONAL PERSPECTIVES ON THE WORK-LIFE INTEGRATION OF PROFESSIONALS, P269, DOI 10.1007/978-3-642-16199-5_15
   Goggin G, 2015, JOURNALISM STUD, V16, P41, DOI 10.1080/1461670X.2014.890329
   Ingraham N., 2015, APPLES APP STORE HAS
   Jenny, 2012, FURR RES REP REL APP
   Katz Elihu., 1974, USES MASS COMMUNICAT, P19, DOI DOI 10.1561/106.00000008
   Kawamoto Kevin., 2003, DIGIT JOURNAL, P1
   Krebs P, 2015, JMIR MHEALTH UHEALTH, V3, P107, DOI 10.2196/mhealth.4924
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Lim SL, 2015, IEEE T SOFTWARE ENG, V41, P40, DOI 10.1109/TSE.2014.2360674
   Ling R.S., 2004, MOBILE CONNECTION CE
   Liu CH, 2019, MULTIMED TOOLS APPL, V78, P4885, DOI 10.1007/s11042-018-6268-y
   Mallet KH, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0167950
   Martin L., 2009, NEW MEDIA CRITICAL I
   Newman Nic., 2018, REUTERS I STUDY JOUR
   Olakanmi OO, 2019, INT J CLOUD APPL COM, V9, P79, DOI 10.4018/IJCAC.2019040105
   Robinson S, 2009, NEW MEDIA SOC, V11, P795, DOI 10.1177/1461444809105353
   Ruggeri K, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00021
   Stroud NJ, 2020, DIGIT JOURNAL, V8, P32, DOI 10.1080/21670811.2019.1655462
   Van Damme K, 2020, DIGIT JOURNAL, V8, P49, DOI 10.1080/21670811.2019.1655461
   Wiki, 2015, APP STOR
   Wu HT, 2020, MULTIMED TOOLS APPL, V79, P1, DOI 10.1007/s11042-019-7523-6
   Xiang Y., 2007, CHASING APP STORES F
   Yang HC, 2017, MULTIMED TOOLS APPL, V76, P11651, DOI 10.1007/s11042-016-3325-2
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
NR 32
TC 0
Z9 0
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 17015
EP 17032
DI 10.1007/s11042-022-12488-w
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000764599600002
DA 2024-07-18
ER

PT J
AU Huang, L
   Zhao, YG
   Yang, TJ
AF Huang, Lin
   Zhao, Yi-Gong
   Yang, Tie-Jun
TI Piezoresistor defect classification using convolutional neural networks
   based on incremental branch growth
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neural architecture search; Incremental branch growth; Convolutional
   neural networks; Surface defect classification
ID SURFACE; SYSTEM
AB Surface defects significantly deteriorate piezoresistor quality. We propose an accurate end-to-end classification method for piezoresistor surface defects based on an incremental branch growth convolutional neural network (IBG-CNN) for automatic CNN construction. First, an incremental branch (IB) is proposed to grow a CNN dynamically. Then, IBG-CNN establishes and trains a starting network based on IB, which is then grown continuously using the IBG algorithm. The next generation of the growing network is trained using the pretrained previous generation, which significantly accelerates the search process of the network model. A CNN based on IBG-CNN for classifying six piezoresistor defect types was automatically built on one GPU in only approximately 16 h. A test dataset of 6248 images was evaluated using the mean average precision (mAP). The experimental results demonstrate that the classification accuracy of our algorithm (mAP = 0.935) is higher than or very close to those of state-of-the-art methods, i.e., conventional CNN-based methods and the efficient neural architecture search (ENAS).
C1 [Huang, Lin; Zhao, Yi-Gong] Xidian Univ, Sch Elect Engn, Xian, Shanxi, Peoples R China.
   [Huang, Lin; Yang, Tie-Jun] Guilin Univ Technol, Guangxi Key Lab Embedded Technol & Intelligent Sy, Guilin, Guangxi, Peoples R China.
C3 Xidian University; Guilin University of Technology
RP Zhao, YG (corresponding author), Xidian Univ, Sch Elect Engn, Xian, Shanxi, Peoples R China.
EM ygzhaoxd@vip.qq.com
RI Yang, Tiejun/AAJ-8197-2020
OI Yang, Tiejun/0000-0002-8644-4651; Huang, Lin/0000-0002-2678-2085
FU National Natural Science Foundation of China [62166012, 61941202];
   Guangxi Natural Science Foundation [2018GXNSFBA281081]
FX This study was partially supported by the National Natural Science
   Foundation of China (62166012, 61941202) and the Guangxi Natural Science
   Foundation (2018GXNSFBA281081).
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   [Anonymous], 2016, ARXIV160207360
   Arshaghi A, 2020, MULTIMED TOOLS APPL, V79, P26623, DOI 10.1007/s11042-020-09236-3
   Carrera D, 2017, IEEE T IND INFORM, V13, P551, DOI 10.1109/TII.2016.2641472
   Chondronasios A, 2016, INT J ADV MANUF TECH, V83, P33, DOI 10.1007/s00170-015-7514-3
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Glorot Xavier., 2010, J MACH LEARN RES, V15, P315
   Gong B., 2019, 8 APPL OPTICS PHOTON, P7
   He ZY, 2015, APPL OPTICS, V54, P9823, DOI 10.1364/AO.54.009823
   Hutter F, 2019, SPRING SER CHALLENGE, P1, DOI 10.1007/978-3-030-05318-5
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kang GQ, 2019, IEEE T INSTRUM MEAS, V68, P2679, DOI 10.1109/TIM.2018.2868490
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kwon BK, 2015, INT J PRECIS ENG MAN, V16, P965, DOI 10.1007/s12541-015-0125-y
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li XP, 2017, APPL OPTICS, V56, P6520, DOI 10.1364/AO.56.006520
   Lin M., 2013, P 2 INT C LEARNING R
   Park JK, 2016, INT J PR ENG MAN-GT, V3, P303, DOI 10.1007/s40684-016-0039-x
   Park Y, 2016, IEEE T IND INFORM, V12, P597, DOI 10.1109/TII.2016.2522191
   Pham Hieu., 2018, ICML, V80, P4095, DOI [https://doi.org/10.48550/arXiv.1802.03268, DOI 10.48550/ARXIV.1802.03268]
   Roy D, 2020, NEURAL NETWORKS, V121, P148, DOI 10.1016/j.neunet.2019.09.010
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Takahashi R, 2020, IEEE T CIRC SYST VID, V30, P2917, DOI 10.1109/TCSVT.2019.2935128
   Tan AJ, 2021, MULTIMED TOOLS APPL, V80, P9109, DOI 10.1007/s11042-020-10036-y
   Tsai DM, 2013, IEEE T IND INFORM, V9, P122, DOI 10.1109/TII.2012.2209663
   Wang HF, 2017, INT J PRECIS ENG MAN, V18, P931, DOI 10.1007/s12541-017-0110-8
   Wu SL, 2019, MULTIMED TOOLS APPL, V78, P34627, DOI 10.1007/s11042-019-08042-w
   Xi JQ, 2017, APPL OPTICS, V56, P184, DOI 10.1364/AO.56.000184
   Xiao TJ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P177, DOI 10.1145/2647868.2654926
   Yi L, 2017, STEEL RES INT, V88, P176, DOI 10.1002/srin.201600068
   Zhong Z, 2018, PROC CVPR IEEE, P2423, DOI 10.1109/CVPR.2018.00257
   Zoph B., 2017, ICLR, P1, DOI DOI 10.1109/ICAIIC48513.2020.9065031
NR 33
TC 1
Z9 1
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16743
EP 16760
DI 10.1007/s11042-022-12651-3
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763872100011
DA 2024-07-18
ER

PT J
AU Hurst, W
   Withington, A
   Kolivand, H
AF Hurst, William
   Withington, Adam
   Kolivand, Hoshang
TI Virtual conference design: features and obstacles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual conferencing; User experience; Covid-19; User journey mapping
ID EDUCATION; REALITY
AB The Covid-19 pandemic has forced a change in the way people work, and the location that they work from. The impact has caused significant disruption to education, the work environment and how social interactions take place. Online user habits have also changed due to lockdown restrictions and virtual conferencing software has become a vital cog in team communication. In result, a spate in software solutions have emerged in order to support the challenges of remote learning and working. The conferencing software landscape is now a core communication solution for company-wide interaction, team discussions, screen sharing and face-to-face contact. Yet the number of existing platforms is diverse. In this article, a systematic literature review investigation on virtual conferencing is presented. As output from the analysis, 67 key features and 74 obstacles users experience when interacting with virtual conferencing technologies are identified from 60 related open-source journal articles from 5 digital library repositories.
C1 [Hurst, William] Wageningen Univ & Res, Informat Technol Grp, Hollandseweg 1, NL-6706 KN Wageningen, Netherlands.
   [Withington, Adam] Liverpool John Moores Univ, Engn & Technol, Byrom St, Liverpool L3 3AF, Merseyside, England.
   [Kolivand, Hoshang] Liverpool John Moores Univ, Dept Comp Sci, Byrom St, Liverpool L3 3AF, Merseyside, England.
C3 Wageningen University & Research; Liverpool John Moores University;
   University of Liverpool; Liverpool John Moores University
RP Hurst, W (corresponding author), Wageningen Univ & Res, Informat Technol Grp, Hollandseweg 1, NL-6706 KN Wageningen, Netherlands.
EM will.hurst@wur.nl; a.j.withington@ljmu.ac.uk; h.kolivand@ljmu.ac.uk
RI Kolivand, Hoshang/F-4736-2011; Kolivand, Hoshang/B-2501-2016
OI Kolivand, Hoshang/0000-0001-5460-5679
CR Ahrar S, 2020, BIOMEDICAL ENG ED
   Alomari HW, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e03917
   Anwar MS, 2020, IEEE ACCESS, V8, P148084, DOI 10.1109/ACCESS.2020.3015556
   Arena, 2020, BIOMEDICAL ENG ED
   August SE, 2016, IEEE T LEARN TECHNOL, V9, P18, DOI 10.1109/TLT.2015.2419253
   Boje C, 2020, AUTOMAT CONSTR, V114, DOI 10.1016/j.autcon.2020.103179
   Bump, 2020, 40 REMOTE WORK STATS
   Cai MH, 2019, HUM-CENT COMPUT INFO, V9, DOI 10.1186/s13673-019-0180-y
   Cameron A., 2020, Coronavirus and Homeworking in the UK: April 2020
   Case John, 2020, Zoom, Microsoft Teams, and Slack Have Exploded Due to the COVID-19 Pandemic. Can They Hold onto This Growth?
   Centre of Education and Learning, 2020, MINECRAFT CAMPUS UPD
   Champion E, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11082425
   Cheng Adam, 2020, Adv Simul (Lond), V5, P18, DOI 10.1186/s41077-020-00141-1
   Clark B, 2020, TRANSPORTATION, V47, P2777, DOI 10.1007/s11116-019-09983-9
   Clark-Wilson A, 2020, ZDM-MATH EDUC, V52, P1223, DOI 10.1007/s11858-020-01196-0
   Delft, 2020, TU DELFT CAMPUS MINE
   Ding Y, 2020, IEEE ACCESS, V8, P96065, DOI 10.1109/ACCESS.2020.2992283
   Dong H, 2019, IEEE ACCESS, V7, P121024, DOI 10.1109/ACCESS.2019.2937877
   Doumanoglou A, 2018, IEEE T BROADCAST, V64, P379, DOI 10.1109/TBC.2018.2823909
   Everett AS, 2021, ADV RADIAT ONCOL, V6, DOI 10.1016/j.adro.2020.08.011
   Faraji S, 2020, NURS OPEN, V7, P1691, DOI 10.1002/nop2.552
   Fraser H, 2017, CONSERV BIOL, V31, P540, DOI 10.1111/cobi.12837
   Frederick JK, 2020, BEHAV ANAL PRACT, V13, P748, DOI 10.1007/s40617-020-00476-1
   García-Valle G, 2018, IEEE ACCESS, V6, P7224, DOI 10.1109/ACCESS.2017.2782254
   Horne M, 2020, INTERNET INTERV, V19, DOI 10.1016/j.invent.2019.100295
   Insights F., 2019, VISUAL ADVANTAGE HAR
   Janssen A, 2020, BUS INFORM SYST ENG+, V62, P211, DOI 10.1007/s12599-020-00644-1
   Johnson Daniel, 2016, Internet Interv, V6, P89, DOI 10.1016/j.invent.2016.10.002
   Kim S, 2020, J MULTIMODAL USER IN, V14, P313, DOI 10.1007/s12193-020-00346-8
   Lamming Dudley W, 2020, Transl Med Aging, V4, P55, DOI 10.1016/j.tma.2020.05.002
   Latoschik ME, 2019, IEEE T VIS COMPUT GR, V25, P2134, DOI 10.1109/TVCG.2019.2899250
   Leonidis A, 2020, TECHNOLOGIES, V8, DOI 10.3390/technologies8040066
   Liddle J, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17155544
   Liu DY, 2018, IEEE ACCESS, V6, P56323, DOI 10.1109/ACCESS.2018.2873367
   Liu W.-H., 2018, INFORM VISUALIZATION
   Lombardo Evelyne, 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P330, DOI 10.1007/978-3-319-39907-2_31
   Lortie CJ, 2020, ECOL EVOL, V10, P12442, DOI 10.1002/ece3.6923
   Lowe J, 2020, JACEP OPEN, V1, P974, DOI 10.1002/emp2.12214
   Machidon OM, 2018, J CULT HERIT, V33, P249, DOI 10.1016/j.culher.2018.01.007
   Mallik B, 2019, MULTIMED TOOLS APPL, V78, P6701, DOI 10.1007/s11042-018-6272-2
   Milovanovic A, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12177024
   Mohatta S., 2017, ROBUST HAND GESTURAL
   Niner Holly J, 2020, Socioecol Pract Res, V2, P253, DOI 10.1007/s42532-020-00059-y
   Nooren P, 2018, POLICY INTERNET, V10, P264, DOI 10.1002/poi3.177
   Oliver, 2019, VISUALIZATION ENG, V7
   Osimani F, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19010070
   Philippe S., 2020, VIRTUAL REALITY INTE, V2, P421, DOI [DOI 10.1016/J.VRIH.2020.07.008, 10.1016/j.vrih.2020.07.008]
   Pickersgill M, 2019, SOCIOL HEALTH ILL, V41, P16, DOI 10.1111/1467-9566.12811
   Rawle M, 2017, J MED RADIAT SCI, V64, P244, DOI 10.1002/jmrs.229
   Rothe S, 2021, VIRTUAL REAL-LONDON, V25, P613, DOI 10.1007/s10055-020-00472-4
   Rubinger L, 2020, INT ORTHOP, V44, P1461, DOI 10.1007/s00264-020-04615-9
   Sardi L, 2017, J BIOMED INFORM, V71, P31, DOI 10.1016/j.jbi.2017.05.011
   Schouten DGM, 2017, UNIVERSAL ACCESS INF, V16, P681, DOI 10.1007/s10209-016-0502-z
   Silva JNA, 2018, JACC-BASIC TRANSL SC, V3, P420, DOI 10.1016/j.jacbts.2017.11.009
   Simiscuka AA, 2019, IEEE ACCESS, V7, P106588, DOI 10.1109/ACCESS.2019.2933014
   Smigelski M, 2020, CURR UROL REP, V21, DOI 10.1007/s11934-020-01004-y
   Soltanian A, 2018, IEEE ACCESS, V6, P9792, DOI 10.1109/ACCESS.2018.2794258
   Stone K., 2020, STATE VIDEO CONFEREN
   Sweetman, 2020, BIOADVANCES, P1
   Syamimi A., 2020, Virtual Reality Intelligent Hardware, V2, P409, DOI 10.1016/j.vrih.2020.06.001
   Taylor MJ, 2020, BMC HEALTH SERV RES, V20, DOI 10.1186/s12913-020-05290-7
   Tibaná-Herrera G, 2018, INT J EDUC TECHNOL H, V15, P1, DOI 10.1186/s41239-018-0103-4
   Tregillus S, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1250, DOI 10.1145/2858036.2858084
   Trust T, 2016, COMPUT EDUC, V102, P15, DOI 10.1016/j.compedu.2016.06.007
   Tummers J, 2019, COMPUT ELECTRON AGR, V157, P189, DOI 10.1016/j.compag.2018.12.044
   Turner S, 2022, J CANCER EDUC, V37, P905, DOI 10.1007/s13187-020-01898-9
   UCAS, 2020, VIRTUAL TOURS
   van Ewijk S, 2021, J IND ECOL, V25, P778, DOI 10.1111/jiec.13079
   Vielma K, 2020, BIOMEDICAL ENG ED
   Wilde, 2015, FLYING LESS REDUCING
   Wilkerson B, 2020, SYST DYNAM REV, V36, P358, DOI 10.1002/sdr.1662
   Zhang S, 2019, IEEE ACCESS, V7, P165961, DOI 10.1109/ACCESS.2019.2953798
   Zhang W, 2018, IEEE ACCESS, V6, P35879, DOI 10.1109/ACCESS.2018.2851956
   Zhang Y., 2019, Virtual Real. Intell. Hardw, V1, P341, DOI [10.1016/j.vrih.2019.01.001, DOI 10.1016/J.VRIH.2019.01.001]
   Zöller N, 2020, TECHNOL FORECAST SOC, V161, DOI 10.1016/j.techfore.2020.120291
   Zou WJ, 2019, IEEE ACCESS, V7, P183405, DOI 10.1109/ACCESS.2019.2920443
NR 76
TC 4
Z9 4
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16901
EP 16919
DI 10.1007/s11042-022-12402-4
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763872100007
PM 35261553
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Meng, LZ
   Liu, LS
   Wang, XL
   Tian, G
AF Meng, Lingzhuang
   Liu, Lianshan
   Wang, Xiaoli
   Tian, Gang
TI Reversible data hiding in encrypted images based on IWT and chaotic
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic system; Image encryption; Integer wavelet transform (IWT);
   Reversible data hiding (RDH)
ID HISTOGRAM-MODIFICATION; SCHEME
AB In this paper, a reversible data hiding in encrypted image (RDH-EI) algorithm based on integer wavelet transform (IWT) and chaotic system was proposed. The image decrypted and the extracted data by the algorithm were both lossless. In this scheme, IWT transform was used to decompose the carrier image into wavelet components, and the chaotic system was used to generate position sequence, encryption sequence and scrambling sequence, which were used for data hiding and image encryption. The secret data was hidden in the diagonal component according to the position sequence, and the approximate component was encrypted according to the encryption sequence and the scrambling sequence, and then the final encrypted image was obtained. A solution was proposed to solve the problem of pixel loss in the reconstruction process after the wavelet component is encrypted. The key used to decrypt the image and extract the secret information was divided into two parts for different levels of security considerations. The method of encrypting image after data hiding made the solution more secure and with higher maximum payload. Simulation results showed that, compared with some existing schemes, this scheme could obtain better performance, which including higher embedding rate, visual quality of decrypted and extracted images, and anti-attack performance.
C1 [Meng, Lingzhuang; Liu, Lianshan; Tian, Gang] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
   [Wang, Xiaoli] Shandong Univ Sci & Technol, Off Network Secur & Informatizat, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Liu, LS (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
EM lzhmeng1688@163.com; lshliu6042@163.com; wangxiaoli6093@163.com;
   gtian@sdust.edu.cn
RI wang, xiao/HGB-7081-2022; meng, lingzhuang/IQR-7631-2023; wang,
   xu/IAN-4886-2023; wang, xiao/HZI-9156-2023
OI wang, xiao/0000-0002-4088-3341; meng, lingzhuang/0000-0002-6549-6989;
   liu, lianshan/0000-0003-4400-6490
FU National Natural Science Foundation of China [61702305]
FX This research is supported in part by National Natural Science
   Foundation of China under Grant 61702305.
CR Abdulla AA, 2014, PROC SPIE, V9120, DOI 10.1117/12.2050518
   Abdulla AA, 2013, IEEE INT SYM MULTIM, P287, DOI 10.1109/ISM.2013.55
   Abdulla AA, 2013, PROC SPIE, V8755, DOI 10.1117/12.2018994
   Akgul A, 2019, MOD PHYS LETT B, V33, DOI 10.1142/S0217984919503573
   Alshoura WH, 2020, IEEE ACCESS, V8, P43391, DOI 10.1109/ACCESS.2020.2978186
   Bhatnagar G, 2012, IEEE T INSTRUM MEAS, V61, P876, DOI 10.1109/TIM.2011.2179330
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Dhall S, 2020, MULTIMED TOOLS APPL, V79, P1987, DOI 10.1007/s11042-019-08223-7
   Guo Y, 2020, IEEE ACCESS, V8, P9896, DOI 10.1109/ACCESS.2019.2963717
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Jung SW, 2011, IEEE SIGNAL PROC LET, V18, P95, DOI 10.1109/LSP.2010.2095498
   Li F, 2018, MULTIMED TOOLS APPL, V77, P5149, DOI 10.1007/s11042-017-4388-4
   Ma B, 2019, J REAL-TIME IMAGE PR, V16, P821, DOI 10.1007/s11554-019-00891-w
   Ma GY, 2019, SIGNAL PROCESS-IMAGE, V75, P55, DOI 10.1016/j.image.2019.03.013
   Mamatha G, 2018, 2018 INT C COMP SCI
   Meng LZ, 2021, MULTIMED TOOLS APPL, V80, P711, DOI 10.1007/s11042-020-09686-9
   Ponuma R, 2019, MULTIMED TOOLS APPL, V78, P25707, DOI 10.1007/s11042-019-07808-6
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qin C, 2018, INFORM SCIENCES, V465, P285, DOI 10.1016/j.ins.2018.07.021
   Qiu YQ, 2020, IEEE ACCESS, V8, P23209, DOI 10.1109/ACCESS.2020.2969252
   Qiu YQ, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107288
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Subburam S, 2018, MULTIMED TOOLS APPL, V77, P7071, DOI 10.1007/s11042-017-4622-0
   Wang SY, 2013, IET IMAGE PROCESS, V7, P805, DOI 10.1049/iet-ipr.2012.0521
   Wen WY, 2020, NONLINEAR DYNAM, V99, P1587, DOI 10.1007/s11071-019-05378-8
   Xiang SJ, 2018, IEEE T CIRC SYST VID, V28, P3099, DOI 10.1109/TCSVT.2017.2742023
   Xiao F, 2020, IEEE T EMERG TOP COM, V8, P752, DOI [10.1109/JPHOT.2018.2827165, 10.1109/TETC.2018.2790080]
   Yang CH, 2017, MULTIMED TOOLS APPL, V76, P23699, DOI 10.1007/s11042-016-4133-4
   Yi S, 2017, SIGNAL PROCESS, V133, P40, DOI 10.1016/j.sigpro.2016.10.017
   Zhang LN, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107421
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 32
TC 7
Z9 7
U1 5
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16833
EP 16861
DI 10.1007/s11042-022-12415-z
EA MAR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763256300004
DA 2024-07-18
ER

PT J
AU Raj, JA
   Idicula, SM
   Paul, B
AF Raj, Anil J.
   Idicula, Sumam Mary
   Paul, Binu
TI A novel sarnede method for real-time ship detection from synthetic
   aperture radar image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ship detection; SAR; Deep learning; Convolution neural network; Marine
   target detection
AB Deep learning-based ship detection from SAR data is one of the challenging problems in the remote sensing area. Also, SAR ship detection is precise object detection and pattern recognition task under the computer vision area. The main problems are false detection, primarily due to speckle presence and multi-scale SAR image availability. We propose a novel real-time system with a preprocessing technique exclusively for SAR ship detection to address this problem. The proposed SarNeDe preprocessing stage is specially designed using image processing techniques and lee filter to reduce the false prediction and improve the SAR image quality, which increases the detection accuracy because the lee filter alone could increase missed detections. The SarNeDe image is generated from raw SAR image and is given to a novel multi-scale lightweight deep learning model to predict all ships' positions. The proposed model has a feature merging & boosting network and three detection parts for detecting big, medium, & small ships. We experimented on the public SAR ship detection dataset (SSDD) and Dataset of Ship Detection for Deep Learning under Complex Backgrounds (SDCD) to validate the proposed method's feasibility. The experimental results indicated that our proposed method's ship detection accuracy is superior to other state-of-the-art ship detectors with reduced false detections.
C1 [Raj, Anil J.; Idicula, Sumam Mary] Cochin Univ Sci & Technol, Dept Comp Sci, Kochi, Kerala, India.
   [Paul, Binu] Cochin Univ Sci & Technol, Sch Engn, Div Elect Engn, Kochi, Kerala, India.
C3 Cochin University Science & Technology; Cochin University Science &
   Technology
RP Raj, JA (corresponding author), Cochin Univ Sci & Technol, Dept Comp Sci, Kochi, Kerala, India.
EM anilzaraj@cusat.ac.in
RI Idicula, Sumam/KIH-5568-2024
OI Idicula, Sumam/0000-0001-7088-6909
CR Alswayed A.S., 2020, 2020 3 INT C COMP AP, P1, DOI [10.1109/ICCAIS48893.2020.9096876, DOI 10.1109/ICCAIS48893.2020.9096876]
   Anil Raj J., 2019, 2019 9th International Conference on Advances in Computing and Communication (ICACC). Proceedings, P92, DOI 10.1109/ICACC48162.2019.8986210
   Bao, 2021, ARXIV210308251
   Chang YL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11070786
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Collobert R, 2008, P 25 ICML, P160, DOI 10.1145/1390156.1390177
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Hassaballah, 2019, STUDIES COMPUTATIONA, V804
   Hassaballah M, 2016, STUD COMPUT INTELL, V630, P1, DOI 10.1007/978-3-319-28854-3_1
   Hassaballah M., 2020, Deep Learning in Computer Vision: Principles and Applications, DOI DOI 10.1201/9781351003827
   Helal M., 2017, BORDER SECURITY SAFE, V184
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   LEE JS, 1981, COMPUT VISION GRAPH, V17, P24, DOI 10.1016/S0146-664X(81)80005-6
   Li D, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3062038
   Li Q, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P3754, DOI 10.1109/ICASSP.2018.8462297
   Lin Z, 2019, IEEE GEOSCI REMOTE S, V16, P751, DOI 10.1109/LGRS.2018.2882551
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mao YX, 2020, IEEE ACCESS, V8, P69742, DOI 10.1109/ACCESS.2020.2985637
   Parker S, 2017, EDUC POL SOC INEQUAL, V1, P1, DOI 10.1007/978-981-10-4039-9_1
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tsantekidis A, 2017, CONF BUS INFORM, V1, P7, DOI 10.1109/CBI.2017.23
   Van den Oord A., 2013, ADV NEURAL INFORM PR, P2643, DOI [DOI 10.1109/MMUL.2011.34.VAN, 10.5555/2999792.2999907]
   Wang YY, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11070765
   Wang YY, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11050531
   Zhang TW, 2021, IEEE GEOSCI REMOTE S, V18, P1234, DOI 10.1109/LGRS.2020.2993899
   Zhang TW, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11212483
   Zhang TW, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11101206
   Zhao JP, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-017-9405-6
   Zhao Y, 2020, IEEE J-STARS, V13, P2738, DOI 10.1109/JSTARS.2020.2997081
NR 31
TC 5
Z9 5
U1 4
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16921
EP 16944
DI 10.1007/s11042-022-12243-1
EA MAR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763256300008
DA 2024-07-18
ER

PT J
AU Viola, R
   Zorrilla, M
   Angueira, P
   Montalbán, J
AF Viola, Roberto
   Zorrilla, Mikel
   Angueira, Pablo
   Montalban, Jon
TI Multi-access Edge Computing video analytics of ITU-T P.1203 Quality of
   Experience for streaming monitoring in dense client cells
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 5G; MEC; MOS; MPEG-DASH; QoE
AB 5G promises unseen network rates and capacity. Furthermore, 5G ambitions agile networking for specific service traffic catalysing the application and network symbiosis. Nowadays, the video streaming services consume lots of networking assets and produce high dynamics caused by players mobility meaning a challenging traffic for network management. The Quality of Experience (QoE) metric defined by ITU-T P.1203 formulates the playback issues related to widely employed Dynamic Adaptive Streaming over HTTP (DASH) technologies based on a set of parameters measured at the video player. Monitoring the individual QoE is essential to dynamically provide the best experience to each user in a cell, while video players compete to enhance their individual QoE and cause high network performance dynamics. The edge systems have a perfect position to bring live coordination to dense and dynamic environments, but they are not aware of QoE experienced by each video player. This work proposes a mechanism to assess QoE scores from network dynamics at the cell and manifests of DASH streams without an explicit out of band messaging from video players to edge systems. Hence, this paper implements an edge proxy, independent from video servers and players, to monitor and estimate QoE providing the required information to later decide streaming qualities in a coordinated manner in a dense client cell. Its lightweight computation design provides real-time and distributed processing of local sessions. To check its validity, a WiFi setup has been exercised where the accuracy of the system at the edge is checked by assessing the ITU-T P.1203 QoE of individual players.
C1 [Viola, Roberto; Zorrilla, Mikel] Basque Res & Technol Alliance BRTA, Vicomtech Fdn, Mikeletegi 57, San Sebastian 20009, Spain.
   [Viola, Roberto; Angueira, Pablo] Univ Basque Country UPV EHU, Dept Commun Engn, Bilbao 48013, Spain.
   [Montalban, Jon] Univ Basque Country UPV EHU, Dept Elect Technol, San Sebastian 20018, Spain.
C3 University of Basque Country; University of Basque Country
RP Viola, R (corresponding author), Basque Res & Technol Alliance BRTA, Vicomtech Fdn, Mikeletegi 57, San Sebastian 20009, Spain.; Viola, R (corresponding author), Univ Basque Country UPV EHU, Dept Commun Engn, Bilbao 48013, Spain.
EM rviola@vicomtech.org; mzorrilla@vicomtech.org; pablo.angueira@ehu.eus;
   jon.montalban@ehu.eus
RI Montalban, Jon/M-1528-2015; Viola, Roberto/ABA-9922-2020; Montalban,
   Jon/GRX-0617-2022; Angueira, Pablo/M-2284-2014
OI Montalban, Jon/0000-0003-0309-3401; Viola, Roberto/0000-0002-8201-2632;
   Montalban, Jon/0000-0003-0309-3401; Angueira, Pablo/0000-0002-5188-8412;
   Zorrilla, Mikel/0000-0003-2589-2490
FU 5G-TEST project (Gipuzkoa's research and innovation programme);
   Open-VERSO project (Red Cervera program, Spanish government's Centre for
   the Development of Industrial Technology)
FX This work was fully supported by the 5G-TEST project (Gipuzkoa's
   research and innovation programme) and Open-VERSO project (Red Cervera
   program, Spanish government's Centre for the Development of Industrial
   Technology).
CR Akhshabi Saamer, 2013, Proceeding of the 23rd ACM Workshop on Network and Operating Systems Support for Digital Audio and Video-NOSSDAV'13
   [Anonymous], 2017, INTRODUCTIONINTERNAT
   [Anonymous], 2012, Proceedings of the 22nd international workshop on Network and Operating System Support for Digital Audio and Video
   [Anonymous], 2016, P8001 ITUT
   [Anonymous], 2017, P1203 ITUT
   De Cock J, 2016, IEEE IMAGE PROC, P1484, DOI 10.1109/ICIP.2016.7532605
   Dutta S, 2016, IEEE GLOB COMM CONF
   ETSI, 2018, ETSI TS 122 261 VERS
   ETSI, 2020, ETSI GS MEC 028 VERS
   ETSI, 2018, ETSI GS MEC 002 VERS
   Ge C, 2018, IEEE CONF COMPUT, P766
   Ge XH, 2016, IEEE WIREL COMMUN, V23, P72, DOI 10.1109/MWC.2016.7422408
   Hongliang Yu, 2006, Operating Systems Review, V40, P333, DOI 10.1145/1218063.1217968
   Huang WW, 2018, IEEE T BROADCAST, V64, P590, DOI 10.1109/TBC.2018.2789580
   Juluri P, 2016, IEEE COMMUN SURV TUT, V18, P401, DOI 10.1109/COMST.2015.2401424
   Khan Koffka, 2018, International Journal of Advanced Networking and Applications, V10, P3704
   Lederer S., 2013, Proceedings of the 4th ACM Multimedia Systems Conference (MMSys '13), P131
   Liotou E, 2016, 2016 23RD INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (ICT), DOI 10.1109/ICT.2016.7500363
   Mangla T, 2018, 2018 NETWORK TRAFFIC MEASUREMENT AND ANALYSIS CONFERENCE (TMA)
   Mangla T, 2017, TMA CONFERENCE 2017 - PROCEEDINGS OF THE 1ST NETWORK TRAFFIC MEASUREMENT AND ANALYSIS CONFERENCE
   Mazhar MH, 2018, IEEE INFOCOM SER, P1331, DOI 10.1109/INFOCOM.2018.8486321
   Node.js, AS EV DRIV JAVASCRIP
   Fajardo JO, 2015, IEEE NETWORK, V29, P40, DOI 10.1109/MNET.2015.7340423
   Quadri C, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP 2018), P25, DOI 10.1109/SMARTCOMP.2018.00095
   Vo QD, 2015, IEEE INT CONF MO, P9, DOI [10.1109/MS.2015.12, 10.1109/MobServ.2015.12]
   Raake A., 2017, 2017 9 INT C QUALITY, P1, DOI DOI 10.1109/QOMEX.2017.7965631
   Richardson M., 2012, Getting Started With Raspberry PI
   Robitza W, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P466, DOI 10.1145/3204949.3208124
   Younis A, 2019, I S WORLD WIREL MOBI, DOI 10.1109/wowmom.2019.8793052
   Zhang X, 2018, ANN C INF SCI SYST, P1, DOI DOI 10.1109/CISS.2018.8362265
NR 30
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12387
EP 12403
DI 10.1007/s11042-022-12537-4
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000763872100019
DA 2024-07-18
ER

PT J
AU Lafraxo, S
   El Ansari, M
   Charfi, S
AF Lafraxo, Samira
   El Ansari, Mohamed
   Charfi, Said
TI MelaNet: an effective deep learning framework for melanoma detection
   using dermoscopic images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin cancer; Melanoma; Deep learning; Convolutional neural network;
   Regularization
ID SKIN-LESIONS; CLASSIFICATION; SEGMENTATION; DIAGNOSIS; RECOGNITION;
   FEATURES; TEXTURE; NETWORK
AB Skin cancer is considered one of the most dangerous and popular sorts of cancer. The deadliest form of this type of cancer is called melanoma, it happens while pigmented cells named melanocytes begin to subdivide tensely. If early detected melanoma could be easily and accurately healed. Hence, immediate diagnosis of this kind of skin cancer is crucial. Currently, dermoscopy has become one of the most efficient tools utilized in pigmented skin lesions diagnosis. Due to the expense of processing each patient by dermatologists, a computerized recognition system is highly required to evaluate every patient's state. This paper aims to automatize the process of classifying dermoscopic images containing skin lesions into benign or malignant. Therefore an improved deep learning-based solution with a convolutional neural network is proposed. Regularization, dropout, and data augmentation are used to avoid the CNN model over-fitting. The proposed method has been tested on three different publicly available datasets and the obtained results demonstrate its effectiveness when compared to the state-of-the-art methods. Thus, the proposed framework can be adopted for assisting dermatologists with melanoma diagnosis.
C1 [Lafraxo, Samira; El Ansari, Mohamed; Charfi, Said] Ibn Zohr Univ, Fac Sci, Dept Comp Sci, LabSIV, BP 8106, Agadir 80000, Morocco.
   [El Ansari, Mohamed] My Ismail Univ Meknes, Dept Comp Sci, Informat & Applicat Lab, Fac Sci, Meknes, Morocco.
C3 Ibn Zohr University of Agadir; Moulay Ismail University of Meknes
RP Lafraxo, S (corresponding author), Ibn Zohr Univ, Fac Sci, Dept Comp Sci, LabSIV, BP 8106, Agadir 80000, Morocco.
EM samira.lafraxo@gmail.com; melansari@gmail.com; charfisaid@gmail.com
RI El Ansari, Mohamed/L-9738-2016; LAFRAXO, Samira/GXH-8925-2022
OI El Ansari, Mohamed/0000-0001-5394-9066; LAFRAXO,
   Samira/0000-0002-8876-3357
CR ADDI-Project, 2003, PH2 DAT
   Albahar MA, 2019, IEEE ACCESS, V7, P38306, DOI 10.1109/ACCESS.2019.2906241
   [Anonymous], 2017, ARXIV170503360
   Arasi Munya A., 2017, 2017 8th International Conference on Information Technology (ICIT). Proceedings, P55, DOI 10.1109/ICITECH.2017.8079915
   Argenziano G, 2003, J AM ACAD DERMATOL, V48, P679, DOI 10.1067/mjd.2003.281
   Arvis V., 2004, Image Analysis & Stereology, V23, P63, DOI 10.5566/ias.v23.p63-72
   Barata C, 2014, IEEE SYST J, V8, P965, DOI 10.1109/JSYST.2013.2271540
   Bengani S, 2021, MULTIMED TOOLS APPL, V80, P3443, DOI 10.1007/s11042-020-09778-6
   Beuren A. T., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P284
   Bi L, 2016, I S BIOMED IMAGING, P1055, DOI 10.1109/ISBI.2016.7493447
   Celebi ME, 2007, COMPUT MED IMAG GRAP, V31, P362, DOI 10.1016/j.compmedimag.2007.01.003
   Codella Noel, 2015, Machine Learning in Medical Imaging. 6th International Workshop, MLMI 2015, held in conjunction with MICCAI 2015. Proceedings: LNCS 9352, P118, DOI 10.1007/978-3-319-24888-2_15
   Codella NCF, 2017, IBM J RES DEV, V61, DOI 10.1147/JRD.2017.2708299
   Cummins DL, 2006, MAYO CLIN PROC, V81, P500, DOI 10.4065/81.4.500
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Gilmore S, 2010, EXP DERMATOL, V19, P830, DOI 10.1111/j.1600-0625.2010.01112.x
   Giotis I, 2015, EXPERT SYST APPL, V42, P6578, DOI 10.1016/j.eswa.2015.04.034
   Glowacz A, 2016, BIOCYBERN BIOMED ENG, V36, P95, DOI 10.1016/j.bbe.2015.12.005
   Hagerty JR, 2019, IEEE J BIOMED HEALTH, V23, P1385, DOI 10.1109/JBHI.2019.2891049
   ISIC-Archive, 2017, MEL PROJ
   Jadhav Ashwin R., 2019, Computational Intelligence: Theories, Applications and Future Directions - Volume I. ICCI-2017. Advances in Intelligent Systems and Computing (AISC 798), P97, DOI 10.1007/978-981-13-1132-1_8
   Jafari MH, 2017, INT J COMPUT ASS RAD, V12, P1021, DOI 10.1007/s11548-017-1567-8
   Jaisakthi SM, 2018, IET COMPUT VIS, V12, P1088, DOI 10.1049/iet-cvi.2018.5289
   Juneja M, 2020, MULTIMED TOOLS APPL, V79, P15531, DOI 10.1007/s11042-019-7460-4
   Kasmi R, 2016, IET IMAGE PROCESS, V10, P448, DOI 10.1049/iet-ipr.2015.0385
   Kawahara J, 2016, I S BIOMED IMAGING, P1397, DOI 10.1109/ISBI.2016.7493528
   Kaymak S, 2018, 2018 14TH SYMPOSIUM ON NEURAL NETWORKS AND APPLICATIONS (NEUREL)
   Khan MQ, 2019, IEEE ACCESS, V7, P90132, DOI 10.1109/ACCESS.2019.2926837
   Kingma D. P., 2014, arXiv
   Kwasigroch A, 2017, ADV INTELL SYST COMP, V577, P848, DOI 10.1007/978-3-319-60699-6_81
   Li YX, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020556
   Mahbod A, 2019, COMPUT MED IMAG GRAP, V71, P19, DOI 10.1016/j.compmedimag.2018.10.007
   Majtner T, 2016, INT CONF IMAG PROC, DOI 10.1109/IPTA.2016.7821017
   Majtner T, 2019, MULTIMED TOOLS APPL, V78, P11883, DOI 10.1007/s11042-018-6734-6
   Majtner T, 2016, LECT NOTES COMPUT SC, V9730, P30, DOI 10.1007/978-3-319-41501-7_4
   Matthews NH., 2017, CUTANEOUS MELANOMA E, DOI DOI 10.15586/CODON.CUTANEOUSMELANOMA.2017.CH1
   MED-NODE, 2015, MED NOD DAT
   Nida N, 2019, INT J MED INFORM, V124, P37, DOI 10.1016/j.ijmedinf.2019.01.005
   Pennisi A, 2016, COMPUT MED IMAG GRAP, V52, P89, DOI 10.1016/j.compmedimag.2016.05.002
   Ratul MAR, 2019, ATROUS CONVOLUTION T
   Sarkar R, 2019, IET IMAGE PROCESS, V13, P2130, DOI 10.1049/iet-ipr.2018.6669
   Schaefer G, 2014, MEMET COMPUT, V6, P233, DOI 10.1007/s12293-014-0144-8
   Scharcanski J, 2014, SER BIOENG, P1, DOI 10.1007/978-3-642-39608-3
   Sivaranjini S, 2020, MULTIMED TOOLS APPL, V79, P15467, DOI 10.1007/s11042-019-7469-8
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sultana NN, 2018, IET COMPUT VIS, V12, P1096, DOI 10.1049/iet-cvi.2018.5238
   Tommasi T, 2006, LECT NOTES COMPUT SC, V4241, P1
   Vasconcelos C.N., 2017, CORR, P1
   Waheed Z, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION, COMPUTING AND DIGITAL SYSTEMS (C-CODE), P316, DOI 10.1109/C-CODE.2017.7918949
   Xie FY, 2017, IEEE T MED IMAGING, V36, P849, DOI 10.1109/TMI.2016.2633551
   Yang JW, 2018, IEEE ACCESS, V6, P65130, DOI 10.1109/ACCESS.2018.2877587
   Yélamos O, 2019, J AM ACAD DERMATOL, V80, P341, DOI 10.1016/j.jaad.2018.07.073
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Yuan YD, 2019, IEEE J BIOMED HEALTH, V23, P519, DOI 10.1109/JBHI.2017.2787487
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhang JB, 2020, IEEE T KNOWL DATA EN, V32, P468, DOI [10.1109/TMI.2019.2893944, 10.1109/TKDE.2019.2891537]
NR 56
TC 12
Z9 12
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 16021
EP 16045
DI 10.1007/s11042-022-12521-y
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762902100001
DA 2024-07-18
ER

PT J
AU Singh, NK
   Khare, M
   Jethva, HB
AF Singh, Nikhil Kumar
   Khare, Manish
   Jethva, Harikrishna B.
TI A comprehensive survey on person re-identification approaches: various
   aspects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Machine learning; Feature extraction; Metric
   learning
ID PEOPLE REIDENTIFICATION; PEDESTRIAN RECOGNITION; MULTIPLE CAMERAS;
   APPEARANCE; TRACKING; NETWORK; GAIT; SURVEILLANCE; DEPTH
AB Person re-identification (Re-ID) is an application of video surveillance and has become popular among Computer Vision and Image processing research communities since last decade due to having its strong safety and security potential. It is the process of identifying a person of interest in distributed non-overlapping camera views. Person re-identification has broad application in maintaining the security by re-identifying the malicious persons in networking cameras. Now a days terrorist and criminal activities are increasing day by day and it is utmost important to re-identify a person of interest at public places like - shopping malls, railway stations, airports, huge public events etc. A lot of challenges are involved in the re-identification process like variation in lighting condition, different poses and viewpoints, blurring effect, image resolution, background changes etc. Basically 2 types of datasets (image based, video based) are designed for re-identification purpose based on application and approaches. This paper includes the study of many popular datasets like ViPER, iLIDS, Market1501, DukeMTMC4ReID, CUHK01, CHUK02, CHUK03, PRID2011 etc. including the various parameters (no of persons, no of images, no of cameras, size of frames etc.) and challenges involved in that. In this paper various aspects of person re-identification approaches are discussed including temporal, spatial, feature, distance metric, machine learning, automation etc. to get the comprehensive and exhaustive idea of person re-identification methods.
C1 [Singh, Nikhil Kumar] Gujarat Technol Univ, Ahmadabad, Gujarat, India.
   [Khare, Manish] Dhirubhai Ambani Inst Informat & Commun Technol, Gandhinagar, Gujarat, India.
   [Jethva, Harikrishna B.] Govt Engn Coll, Patan, Gujarat, India.
C3 Gujarat Technological University; Dhirubhai Ambani Institute of
   Information & Communication Technology
RP Khare, M (corresponding author), Dhirubhai Ambani Inst Informat & Commun Technol, Gandhinagar, Gujarat, India.
EM nikhil.singh31@gmail.com; mkharejk@gmail.com; hbjethva@gmail.com
RI Khare, Manish/AAF-4582-2019; Jethva, Harikrishna Babubhai/AAI-3290-2020
OI Khare, Manish/0000-0002-2296-2732; Jethva, Harikrishna
   Babubhai/0000-0003-2954-117X
CR ACCL, 2019, MAN CCTV CAM AR THER
   Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   Albiol A, 2012, IET COMPUT VIS, V6, P378, DOI 10.1049/iet-cvi.2011.0140
   Annesley J., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P105
   [Anonymous], 2019, INDIA DELHI AAP GOVT
   [Anonymous], 2011, ACM WORKSH HUM GEST
   [Anonymous], P 16 INT C VIS INT
   Avraham T, 2012, LECT NOTES COMPUT SC, V7583, P381
   Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P1, DOI 10.1109/AVSS.2010.68
   Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P435, DOI 10.1109/AVSS.2010.34
   Bak S., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P179, DOI 10.1109/AVSS.2011.6027316
   Bak S, 2018, LECT NOTES COMPUT SC, V11217, P193, DOI 10.1007/978-3-030-01261-8_12
   Bak S, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P175, DOI 10.1109/AVSS.2014.6918664
   Balazia M, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P208, DOI 10.1109/BTAS.2017.8272700
   Bazzani Loris, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1413, DOI 10.1109/ICPR.2010.349
   Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008
   Bedagkar-Gala A., 2014, Asian Conference on Computer Vision, P633
   Bedagkar-Gala A, 2014, IMAGE VISION COMPUT, V32, P270, DOI 10.1016/j.imavis.2014.02.001
   Bhuiyan A, 2015, LECT NOTES COMPUT SC, V9280, P449, DOI 10.1007/978-3-319-23234-8_42
   Bolle RM, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P15, DOI 10.1109/AUTOID.2005.48
   Bouchrika I, 2016, MULTIMED TOOLS APPL, V75, P1201, DOI 10.1007/s11042-014-2364-9
   Calderara S, 2008, IEEE T PATTERN ANAL, V30, P354, DOI 10.1109/TPAMI.2007.70814
   Chattopadhyay P, 2015, IET IMAGE PROCESS, V9, P969, DOI 10.1049/iet-ipr.2014.0773
   Chen DP, 2015, PROC CVPR IEEE, P1565, DOI 10.1109/CVPR.2015.7298764
   Chen JX, 2015, IEEE T IMAGE PROCESS, V24, P4741, DOI 10.1109/TIP.2015.2466117
   Chen JX, 2014, INT C PATT RECOG, P1657, DOI 10.1109/ICPR.2014.292
   Chen YB, 2017, IEEE INT CONF COMP V, P2590, DOI 10.1109/ICCVW.2017.304
   Chen YC, 2018, PR MACH LEARN RES, V80
   Chen YC, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3402
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Cho YJ, 2016, PROC CVPR IEEE, P1354, DOI 10.1109/CVPR.2016.151
   Cong DNT, 2010, SIGNAL PROCESS, V90, P2362, DOI 10.1016/j.sigpro.2009.09.005
   D'Angelo A, 2011, PROC SPIE, V7882, DOI 10.1117/12.876453
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dandan Xu, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P477, DOI 10.1109/ICIG.2013.100
   Das A, 2014, LECT NOTES COMPUT SC, V8690, P330, DOI 10.1007/978-3-319-10605-2_22
   de Oliveira IO, 2009, EIGHTH IEEE INTERNATIONAL CONFERENCE ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, PROCEEDINGS, P461, DOI 10.1109/DASC.2009.33
   DeCann B, 2015, IET BIOMETRICS, V4, P209, DOI 10.1049/iet-bmt.2015.0061
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Dikmen M, 2011, LECT NOTES COMPUT SC, V6495, P501, DOI 10.1007/978-3-642-19282-1_40
   Ding GD, 2020, PATTERN RECOGN LETT, V137, P91, DOI 10.1016/j.patrec.2019.02.015
   Doretto G, 2011, J AMB INTEL HUM COMP, V2, P127, DOI 10.1007/s12652-010-0034-y
   Du YN, 2012, INT C PATT RECOG, P1371
   Ess A, 2007, IEEE I CONF COMP VIS, P2065
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Gong SG, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6296-4_1
   Gosselin PH, 2008, IEEE T IMAGE PROCESS, V17, P1200, DOI 10.1109/TIP.2008.924286
   Gou MR, 2017, IEEE COMPUT SOC CONF, P1425, DOI 10.1109/CVPRW.2017.185
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Hamdoun O, 2008, 2008 SECOND ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P140
   Hirzer M, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P203, DOI 10.1109/AVSS.2012.55
   Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hou RB, 2019, PROC CVPR IEEE, P7176, DOI 10.1109/CVPR.2019.00735
   Hu WM, 2006, IEEE T PATTERN ANAL, V28, P663, DOI 10.1109/TPAMI.2006.80
   Huang HJ, 2018, PROC CVPR IEEE, P5098, DOI 10.1109/CVPR.2018.00535
   Huang T, 1997, INT JOINT CONF ARTIF, P1276
   Huang YK, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P365, DOI 10.1145/3343031.3350994
   Iwashita Yumi, 2010, Proceedings of the 2010 International Conference on Emerging Security Technologies (EST 2010), P30, DOI 10.1109/EST.2010.19
   Javed O, 2005, PROC CVPR IEEE, P26
   Jeong K, 2008, MACH VISION APPL, V19, P443, DOI 10.1007/s00138-007-0079-x
   Jiang M, 2020, NEUROCOMPUTING, V381, P314, DOI 10.1016/j.neucom.2019.11.088
   Jin-Peng Xiang, 2012, 2012 International Conference on Machine Learning and Cybernetics (ICMLC 2012). Proceedings, P336, DOI 10.1109/ICMLC.2012.6358936
   Karanam S, 2019, IEEE T PATTERN ANAL, V41, P523, DOI 10.1109/TPAMI.2018.2807450
   Karanam S, 2015, IEEE I CONF COMP VIS, P4516, DOI 10.1109/ICCV.2015.513
   Kawai R, 2012, INT C PATT RECOG, P2694
   Khan A., 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P357, DOI 10.1109/DICTA.2010.67
   Kodirov E., 2015, BMVC, DOI DOI 10.5244/C.29.44
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li MX, 2018, LECT NOTES COMPUT SC, V11208, P772, DOI 10.1007/978-3-030-01225-0_45
   Li R, 2021, APPL INTELL, V51, P1479, DOI 10.1007/s10489-020-01880-4
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2017, IEEE INT CONF AUTOMA, P103, DOI 10.1109/FG.2017.136
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Li X., 2018, PROCEEDING EUROPEAN, V280, P296
   Li X, 2015, IEEE I CONF COMP VIS, P3765, DOI 10.1109/ICCV.2015.429
   Liao S, 2014, ARXIV PREPRINT ARXIV
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin Shan, 2018, 2018 IEEE 36 VLSI TE
   Lin YT, 2019, AAAI CONF ARTIF INTE, P8738
   Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055
   Liu CX, 2012, LECT NOTES COMPUT SC, V7583, P391, DOI 10.1007/978-3-642-33863-2_39
   Liu GQ, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104068
   Liu HM, 2021, NEUROCOMPUTING, V423, P57, DOI 10.1016/j.neucom.2020.10.019
   Liu Z, 2015, NEUROCOMPUTING, V168, P1144, DOI 10.1016/j.neucom.2015.05.008
   Loy CC, 2013, IEEE IMAGE PROC, P3567, DOI 10.1109/ICIP.2013.6738736
   Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41
   Ma LY, 2014, IEEE T IMAGE PROCESS, V23, P3656, DOI 10.1109/TIP.2014.2331755
   Martinel N, 2016, LECT NOTES COMPUT SC, V9908, P858, DOI 10.1007/978-3-319-46493-0_52
   Mazzon R, 2012, PATTERN RECOGN LETT, V33, P1828, DOI 10.1016/j.patrec.2012.02.014
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Nambiar A, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 5, P108, DOI 10.5220/0006165301080119
   Oreifej O, 2010, PROC CVPR IEEE, P709, DOI 10.1109/CVPR.2010.5540147
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Park U, 2006, INT C PATT RECOG, P1204
   Porikli F, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P133
   Prosser B., 2010, P BRIT MACH VIS C BM, DOI DOI 10.5244/C.24.21
   Prosser Bryan James, 2008, P BMVC, V8, P74
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Roy A, 2012, PATTERN RECOGN LETT, V33, P1891, DOI 10.1016/j.patrec.2012.02.003
   Salve SG, 2010, INT CONF COMP SCI, P471, DOI 10.1109/ICCSIT.2010.5565098
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Satta R, 2011, LECT NOTES COMPUT SC, V6979, P140, DOI 10.1007/978-3-642-24088-1_15
   Shao H, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P753
   Sheshkal Sajad Amouei, 2020, Proceedings of the 10th International Conference on Computer and Knowledge Engineering (ICCKE 2020), P463, DOI 10.1109/ICCKE50421.2020.9303722
   Stanciulescu B, 2008, INTEREST POINTS HARV
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Vezzani R, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543596
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wang TQ, 2016, IEEE T PATTERN ANAL, V38, P2501, DOI 10.1109/TPAMI.2016.2522418
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Wang XG, 2014, ADV COMPUT VIS PATT, P351, DOI 10.1007/978-1-4471-6296-4_17
   Wang XG, 2013, PATTERN RECOGN LETT, V34, P3, DOI 10.1016/j.patrec.2012.07.005
   Wang Y, 2018, PROC CVPR IEEE, P8042, DOI [10.1109/CVPR.2018.00839, 10.1109/CVPR.2018.00736]
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wong KM, 2007, IEEE IMAGE PROC, P3161
   Wu L, 2020, IEEE T IMAGE PROCESS, V29, P1233, DOI 10.1109/TIP.2019.2940684
   Wu SH, 2019, INT J PAVEMENT ENG, V20, P33, DOI 10.1080/10298436.2016.1248204
   Wu YM, 2020, IEEE T IMAGE PROCESS, V29, P8821, DOI 10.1109/TIP.2020.3001693
   XIA KG., 2018, DESTECH T COMPUTER S
   Xiang ZJ, 2014, MULTIMED TOOLS APPL, V73, P91, DOI 10.1007/s11042-012-1286-7
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xu YL, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P937, DOI 10.1145/2647868.2654965
   Yang X, 2019, IEEE T NEUR NET LEAR, V30, P2987, DOI [10.1109/TNNLS.2018.2861991, 10.1109/TNNLS.2018.2790479]
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Ying Zhang, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P368, DOI 10.1109/ICIG.2011.40
   Yinghao Cai, 2010, Computer Vision. International Workshops (ACCV 2010). Revised Selected Papers, P205, DOI 10.1007/978-3-642-22822-3_21
   Yoon K, 2006, J VIS COMMUN IMAGE R, V17, P605, DOI 10.1016/j.jvcir.2005.09.003
   Yu HX, 2020, IEEE T PATTERN ANAL, V42, P956, DOI 10.1109/TPAMI.2018.2886878
   Yu Y, 2007, MACH VISION APPL, V18, P139, DOI 10.1007/s00138-006-0061-z
   Zajdel W, 2005, IEEE INT CONF ROBOT, P2081
   Zhang RM, 2019, IEEE T IMAGE PROCESS, V28, P4870, DOI 10.1109/TIP.2019.2911488
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2016, arXiv preprint arXiv
   Zheng M, 2018, IEEE COMPUT SOC CONF, P1974, DOI 10.1109/CVPRW.2018.00251
   Zheng WS, 2016, IEEE T PATTERN ANAL, V38, P591, DOI 10.1109/TPAMI.2015.2453984
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
   Zheng Wei-Shi, 2009, P BRIT MACH VIS C, P23, DOI DOI 10.5244/C.23.23
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11
   Zhu XP, 2021, INT J COMPUT VISION, V129, P1580, DOI 10.1007/s11263-021-01440-4
   Zhu XK, 2018, IEEE T IMAGE PROCESS, V27, P5683, DOI 10.1109/TIP.2018.2861366
NR 156
TC 7
Z9 7
U1 1
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15747
EP 15791
DI 10.1007/s11042-022-12585-w
EA MAR 2022
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762902200004
DA 2024-07-18
ER

PT J
AU Dignan, C
   Perez, E
   Ahmad, I
   Huber, M
   Clark, A
AF Dignan, Cameron
   Perez, Eliud
   Ahmad, Ishfaq
   Huber, Manfred
   Clark, Addison
TI An AI-based Approach for Improved Sign Language Recognition using
   Multiple Videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Assistive technology; Hearing impaired; Sign language; EMG; Video
   processing
ID GESTURE RECOGNITION; ACCELEROMETER; MODEL
AB People with hearing and speaking disabilities face significant hurdles in communication. The knowledge of sign language can help mitigate these hurdles, but most people without disabilities, including relatives, friends, and care providers, cannot understand sign language. The availability of automated tools can allow people with disabilities and those around them to communicate ubiquitously and in a variety of situations with non-signers. There are currently two main approaches for recognizing sign language gestures. The first is a hardware-based approach, involving gloves or other hardware to track hand position and determine gestures. The second is a software-based approach, where a video is taken of the hands and gestures are classified using computer vision techniques. However, some hardware, such as a phone's internal sensor or a device worn on the arm to track muscle data, is less accurate, and wearing them can be cumbersome or uncomfortable. The software-based approach, on the other hand, is dependent on the lighting conditions and on the contrast between the hands and the background. We propose a hybrid approach that takes advantage of low-cost sensory hardware and combines it with a smart sign-recognition algorithm with the goal of developing a more efficient gesture recognition system. The Myo band-based approach using the Support Vector Machine method achieves an accuracy of only 49%. The software-based approach uses the Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) methods to train the Myo-based module and achieves an accuracy of over 80% in our experiments. Our method combines the two approaches and shows the potential for improvement. Our experiments are done with a dataset of nine gestures generated from multiple videos, each repeated five times for a total of 45 trials for both the software-based and hardware-based modules. Apart from showing the performance of each approach, our results show that with a more improved hardware module, the accuracy of the combined approach can be significantly improved.
C1 [Dignan, Cameron; Perez, Eliud; Ahmad, Ishfaq; Huber, Manfred; Clark, Addison] Univ Texas Arlington, Comp Sci & Engn, Arlington, TX 76019 USA.
C3 University of Texas System; University of Texas Arlington
RP Ahmad, I (corresponding author), Univ Texas Arlington, Comp Sci & Engn, Arlington, TX 76019 USA.
EM iahmad@cse.uta.edu
OI Clark, Addison/0000-0003-1313-3921; Huber, Manfred/0009-0007-0294-9147
FU National Science Foundation [:1757641]; Div Of Information & Intelligent
   Systems; Direct For Computer & Info Scie & Enginr [1757641] Funding
   Source: National Science Foundation
FX This project was funded by the National Science Foundation under Award
   Number:1757641.
CR Abreu JG, 2016, SYMP VIRTUAL AUGMENT, P64, DOI 10.1109/SVR.2016.21
   Amin M.S., 2020, 2020 IEEE 23 INT MUL, P1, DOI [10.1109/INMIC50486.2020.9318185, DOI 10.1109/INMIC50486.2020.9318185]
   Assan M., 1998, Gesture and Sign Language in Human-Computer Interaction. International Gesture Workshop Proceedings, P97
   Bauer B, 2002, INT C PATT RECOG, P434, DOI 10.1109/ICPR.2002.1048332
   Choe B, 2010, LECT NOTES COMPUT SC, V6444, P650, DOI 10.1007/978-3-642-17534-3_80
   Chu XZ, 2021, 2021 IEEE 3RD GLOBAL CONFERENCE ON LIFE SCIENCES AND TECHNOLOGIES (IEEE LIFETECH 2021), P311, DOI [10.1109/LifeTech52111.2021.9391981, 10.1109/LIFETECH52111.2021.9391981]
   Cui Y, 2000, COMPUT VIS IMAGE UND, V78, P157, DOI 10.1006/cviu.2000.0837
   Dignan Cameron, 2020, 2020 3rd International Conference on Data Intelligence and Security (ICDIS), P87, DOI 10.1109/ICDIS50059.2020.00018
   Elleuch H, 2015, INT CONF INTELL SYST, P195, DOI 10.1109/ISDA.2015.7489224
   Fayyaz S, 2019, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND SOFT COMPUTING (ICMLSC 2019), P192, DOI 10.1145/3310986.3311011
   Gandhi P., 2015, Int. J. Eng. Tech, V1, P55
   Gaolin Fang, 2002, Gesture and Sign Language in Human-Computer Interaction. International Gesture Workshop, GW 2001. Revised Papers (Lecture Notes in Artificial Intelligence Vol.2298), P76
   Ghanem S, 2017, 10TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2017), P171, DOI 10.1145/3056540.3056549
   Gupta HP, 2016, IEEE SENS J, V16, P6425, DOI 10.1109/JSEN.2016.2581023
   Hays P, 2013, WEST NY IMAGE PROCES, P39, DOI 10.1109/WNYIPW.2013.6890987
   Huang CL, 1998, MACH VISION APPL, V10, P292, DOI 10.1007/s001380050080
   Jin CM, 2016, IEEE REGION 10 SYMP, P104, DOI 10.1109/TENCONSpring.2016.7519386
   Joselli Mark, 2009, Proceedings of the VIII Brazilian Symposium on Games and Digital Entertainment (SBGAMES 2009), P141, DOI 10.1109/SBGAMES.2009.24
   Joshi TJ, 2015, IJCA, V120, P48
   Kadous M W., 1996, P WORKSHOP INTEGRATI, P165
   Kamat R., 2016, Journal of Communications Technology, Electronics and Computer Science, V8, P24
   Kau Lih-Jen., 2015, CIRCUITS SYSTEMS MWS, P1
   Kobayashi T, 1997, INT CONF ACOUST SPEE, P3081, DOI 10.1109/ICASSP.1997.595443
   Krishnan Arjun, 2020, Proceedings of the 3rd International Conference on Intelligent Sustainable Systems (ICISS 2020), P391, DOI 10.1109/ICISS49785.2020.9315897
   Kwok YK, 1996, IEEE J SEL AREA COMM, V14, P1332, DOI 10.1109/49.536483
   Lahiani H, 2015, INT CONF INTELL SYST, P591, DOI 10.1109/ISDA.2015.7489184
   Makarov I, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P204, DOI 10.1145/3316782.3316786
   Masood S, 2017, REAL TIME SIGN LANGU
   Matsuo H., 1998, Gesture and Sign Language in Human-Computer Interaction. International Gesture Workshop Proceedings, P273
   Murakami K., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P237, DOI 10.1145/108844.108900
   Niezen G., 2008, International Workshop on Devices that Alter Perception (DAP 2008), in conjunction with Ubicomp, P17
   Ong SCW, 2005, IEEE T PATTERN ANAL, V27, P873, DOI 10.1109/TPAMI.2005.112
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Prasuhn L, 2014, IEEE IMAGE PROC, P3973, DOI 10.1109/ICIP.2014.7025807
   Preetham C, 2013, 2013 TEXAS INSTRUMENTS INDIA EDUCATORS' CONFERENCE (TIIEC 2013), P328, DOI 10.1109/TIIEC.2013.65
   Raheja J, 2015, ANDROID BASED PORTAB, P1
   Rao G.A., 2016, International Journal of Electrical and Computer Engineering, V6, P2176, DOI [DOI 10.11591/IJECE.V6I5.11384, 10.11591/ijece.v6i5.11384]
   Ronchetti, HANDSHAPE RECOGNITIO
   Rosero-Montalvo P.D., 2018, 2018 IEEE 3 ECUADOR, P1, DOI DOI 10.1109/ETCM.2018.8580268
   Saxena A, 2014, INT CONF COMM SYST, P810, DOI 10.1109/CSNT.2014.168
   Saxena A, 2014, INT CONF COMM SYST, P819, DOI 10.1109/CSNT.2014.170
   Sequeira, SIGN LANGUAGE RECOGN
   Setiawardhana, 2015, 2015 International Electronics Symposium (IES), P114, DOI 10.1109/ELECSYM.2015.7380825
   Seymour M, 2015, AFRICON
   Shrestha S. L., 2020, 2020 INT C COMP SCI, P1, DOI DOI 10.1109/ICCSEA49143.2020.9132899
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   Sun Y, 2004, IEEE T CIRC SYST VID, V14, P1167, DOI 10.1109/TCSVT.2004.833164
   Tanibata N., 2002, PROC INT C VISION IN, P391
   Wang CL, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P411, DOI 10.1109/AFGR.2002.1004188
   Wang X, 2012, ADV INTEL SOFT COMPU, V151, P173
   Warrier KS, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1777, DOI 10.1109/ICCSP.2016.7754472
   Wikipedia, AM MAN ALPH
   Wu J., 2000, FAST SIGN WORD RECOG, V2, P599
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P1061, DOI 10.1109/TPAMI.2002.1023803
NR 54
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34525
EP 34546
DI 10.1007/s11042-021-11830-y
EA FEB 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000762173600001
DA 2024-07-18
ER

PT J
AU Liu, ZH
   Chen, WJ
   Chen, AB
   Zhou, GX
   Yi, JZ
AF Liu, Zhihua
   Chen, Wenjie
   Chen, Aibin
   Zhou, Guoxiong
   Yi, Jizheng
TI Birdsong classification based on multi feature channel fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Birdsong classification; Feature fusion;
   Time domain characteristics; Time-frequency domain features
AB Aiming at the essential feature of the time-continuity of birdsong in nature, this paper proposed a birdsong classification model composed of two feature channels, which combines the features of time domain and time frequency domain. In order to make better use of the features, we used the improved average threshold method to denoise the original time-domain waveform features to reduce the influence of noise features. The most suitable feature extractor and the best fusion method of these two features are discussed. In this paper, the 3D convolutional neural network (3DCNN) and 2D convolutional neural network (2DCNN) were respectively applied as feature extractors of log_mel spectrum and waveform images. Then the advanced feature, which was extracted from these two feature channels, was fused in the middle stage, and the output enhanced feature was used as the input of double gated recurrent unit (d-GRU) network. In the work, birdsongs of four species from Xeno-Canto were selected for testing. The results showed that these three methods had improved the classification effect: feature fusion method in time domain and time-frequency domain, weighted average threshold noise reduction method and the method of extracting birdsong features via different types of feature extractors. The method of this paper had achieved mean average precision (MAP) of 95.9% in the classification comparison experiments, which was an inspiring outcome.
C1 [Liu, Zhihua; Chen, Wenjie; Chen, Aibin; Zhou, Guoxiong; Yi, Jizheng] Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Inst Artificial Intelligence Applicat, Changsha, Peoples R China.
C3 Central South University of Forestry & Technology
RP Chen, AB (corresponding author), Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Inst Artificial Intelligence Applicat, Changsha, Peoples R China.
EM hotaibin@163.com
RI 刘, 志华/HOF-8314-2023
OI 刘, 志华/0000-0003-3980-2927; Zhou, Guoxiong/0000-0002-5142-4845
FU National Natural Science Foundation of China [61703441]
FX This work supported in part by the National Natural Science Foundation
   of China (Grant No. 61703441).
CR Abdoli S, 2019, EXPERT SYST APPL, V136, P252, DOI 10.1016/j.eswa.2019.06.040
   Adavanne S, 2017, EUR SIGNAL PR CONF, P1729, DOI 10.23919/EUSIPCO.2017.8081505
   [Anonymous], 2016, DCASE
   [Anonymous], 2016, CLEF WORKING NOTES
   [Anonymous], 2014, PhD thesis
   Bai S., 2018, CoRR
   Bhatt G., 2018, ARXIV PREPRINT ARXIV
   Bold N, 2019, IEICE T INF SYST, VE102D, P2033, DOI 10.1587/transinf.2018EDP7383
   Briggs F, 2012, J ACOUST SOC AM, V131, P4640, DOI 10.1121/1.4707424
   Chen X, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105730
   Chou C., 2007, Innovative Computing, Information and Control, P143
   Fagerlund S, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/38637
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Grill T, 2017, EUR SIGNAL PR CONF, P1764, DOI 10.23919/EUSIPCO.2017.8081512
   Hessel M, 2017, ARXIV PREPRINT ARXIV
   Himawan I, 2018, 3D CONVOLUTION RECUR
   Kahl S., 2017, CLEF WORKING NOTES
   Kim J, 2020, J ACOUST SOC KOREA, V39, P406, DOI 10.7776/ASK.2020.39.5.406
   Koh C.-Y., 2019, CLEF
   Lasseck M., 2013, P NEUR INF PROC SCAL, P176
   Lee CH, 2006, PATTERN RECOGN LETT, V27, P93, DOI 10.1016/j.patrec.2005.07.004
   Leng YR, 2014, ASIAPAC SIGN INFO PR
   McFee B., 2015, P 14 PYTH SCI C, P18, DOI [DOI 10.25080/MAJORA-7B98E3ED-003, 10.25080/Majora-7b98e3ed-003]
   McLoughlin I, 2020, CIRC SYST SIGNAL PR, V39, P1672, DOI 10.1007/s00034-019-01203-0
   Mualler, 2018, CLEF WORKING NOTES
   Nanni L., 2020, ARXIV PREPRINT ARXIV
   Qiao Y., 2020, INT C NEUR INF PROC, P130, DOI 10.1007/978-3-030-63823-8_16
   Sainath TN, 2015, INT CONF ACOUST SPEE, P4580, DOI 10.1109/ICASSP.2015.7178838
   Selin A, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/51806
   SHORE JE, 1980, IEEE T INFORM THEORY, V26, P26, DOI 10.1109/TIT.1980.1056144
   Stevens SS, 1937, J ACOUST SOC AM, V8, P185, DOI 10.1121/1.1915893
   Takahashi N, 2018, IEEE T MULTIMEDIA, V20, P513, DOI 10.1109/TMM.2017.2751969
   Tuncer T, 2021, APPL ACOUST, V176, DOI 10.1016/j.apacoust.2020.107866
   Xie JT, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P369
   Xie J, 2019, ECOL INFORM, V52, P74, DOI 10.1016/j.ecoinf.2019.05.007
   Zhang HM, 2015, INT CONF ACOUST SPEE, P559, DOI 10.1109/ICASSP.2015.7178031
   Zhang X, 2019, ECOL INFORM, V54, DOI 10.1016/j.ecoinf.2019.101009
NR 37
TC 5
Z9 6
U1 6
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15469
EP 15490
DI 10.1007/s11042-022-12570-3
EA FEB 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173600013
DA 2024-07-18
ER

PT J
AU Chakraborty, S
   Roy, M
   Chatterjee, S
   Mali, K
   Banerjee, S
AF Chakraborty, Shouvik
   Roy, Mousomi
   Chatterjee, Sankhadeep
   Mali, Kalyani
   Banerjee, Soumen
TI Detection of HIV-1 progression phases from transcriptional profiles in
   ex vivo CD4+and CD8+T cells using meta-heuristic supported artificial
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HIV-1 progression; Gene expression analysis; Meta-heuristic supported
   ANN; HIV state analysis
ID PARTICLE SWARM OPTIMIZATION; GENE-EXPRESSION DATA; VECTOR MACHINES;
   T-CELLS; CLASSIFICATION; CANCER; ALGORITHM; PREDICTION; DISCOVERY;
   SELECTION
AB Gene expression studies can explore various information about different diseases more specifically the working mechanism of diseases. Fortunately, HIV (Human Immunodeficiency Virus)-1 has a well-known pattern of progression. There are three stages through which HIV-1 progresses namely acute, chronic, and non-progressor. The detection of different stages is very important because late detection can lead to AIDS. Automated frameworks can be helpful in the precise detection of different progression stages. In this work, an automated framework has been proposed to detect several stages of HIV-1 progression. This work is based on the analysis of transcriptional profiles of CD4+ and CD8+ T cells. The microarray array data has been processed and reduced before classification. The detection process is based on the Artificial Neural Network which is trained with the help of meta-heuristic algorithms for better convergence. Three different metaheuristic algorithms namely GA, CPSO, and NSGA-II have been compared. The experimental results show that the artificial neural network trained with the Genetic Algorithm achieves 72.22% accuracy, 69.05% precision, 70.73% recall, and 69.88% F-Measure whereas the artificial neural network trained with the Constrained Particle Swarm Optimization achieves 86.67% accuracy, 78.79% precision, 83.87% recall, and 81.25% F-Measure. In contrast, the proposed approach i.e., the artificial neural network trained with the NSGA-II approach achieves 88.24% accuracy, 82.56% precision, 88.87% recall, and 85.6% F-Measure values and outperforms other approaches including decision tree, SVM, and KNN. The results have been verified using the cross-validation procedure that ensures and reflects the usefulness of the method.
C1 [Chakraborty, Shouvik; Roy, Mousomi; Mali, Kalyani] Univ Kalyani, Dept Comp Sci & Engn, Nadia, W Bengal, India.
   [Chatterjee, Sankhadeep] Univ Engn & Management, Dept Comp Sci & Technol, Kolkata, India.
   [Banerjee, Soumen] Univ Engn & Management, Dept Elect & Commun Engn, Kolkata, India.
C3 Kalyani University
RP Chatterjee, S (corresponding author), Univ Engn & Management, Dept Comp Sci & Technol, Kolkata, India.
EM shouvikchakraborty51@gmail.com; iammouroy@gmail.com;
   chatterjeesankhadeep.cu@gmail.com; kalyanimali1992@gmail.com;
   prof.sbanerjee@gmail.com
RI Chatterjee, Sankhadeep/F-4672-2017
OI Chatterjee, Sankhadeep/0000-0002-3930-4699
CR Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Annavarapu CSR, 2016, EXCLI J, V15, P460, DOI 10.17179/excli2016-481
   [Anonymous], **DATA OBJECT**
   [Anonymous], **DATA OBJECT**
   Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765
   Ayyad SM, 2019, BIOSYSTEMS, V176, P41, DOI 10.1016/j.biosystems.2018.12.009
   Becker A, 2019, HEALTH POLICY TECHN, V8, P198, DOI 10.1016/j.hlpt.2019.03.004
   Brown MPS, 2000, P NATL ACAD SCI USA, V97, P262, DOI 10.1073/pnas.97.1.262
   Carvajal-Carreño W, 2014, ENG APPL ARTIF INTEL, V36, P164, DOI 10.1016/j.engappai.2014.07.019
   Chakraborty S., 2015, 2 NATL C NCETAS 2015, V4, P61
   Chakraborty S., 2021, BIOMEDICAL IMAGE SEG, P299, DOI 10.1007/978-981-15-9433-5_29
   Chakraborty S., 2021, BIOMEDICAL IMAGE SEG, P299, DOI DOI 10.1007/978-981-15-9433-5_29
   Chakraborty S., 2017, Advancements in Applied Metaheuristic Computing, P143, DOI [10.4018/978-1-5225-4151-6.ch006, DOI 10.4018/978-1-5225-4151-6.CH006]
   Chakraborty S., 2013, First International Conference on Computation and Communication Advancement, P69
   Chakraborty S., 2015, Int. J. Hybrid Inform. Technol, V8, P273
   Chakraborty S, 2020, APPL INTELL, V50, P1775, DOI 10.1007/s10489-019-01604-3
   Chakraborty S, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102800
   Chakraborty S, 2021, EXPERT SYST APPL, V178, DOI 10.1016/j.eswa.2021.115069
   Chakraborty S, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114142
   Chakraborty S, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106800
   Chakraborty S, 2017, 2017 8TH ANNUAL INDUSTRIAL AUTOMATION AND ELECTROMECHANICAL ENGINEERING CONFERENCE (IEMECON), P224, DOI 10.1109/IEMECON.2017.8079594
   Chakraborty S, 2017, MICROSC RES TECHNIQ, V80, P1051, DOI 10.1002/jemt.22900
   Chatterjee S, 2017, STRUCT ENG MECH, V63, P429, DOI 10.12989/sem.2017.63.4.429
   Chatterjee S, 2017, LECT NOTES COMPUT SC, V10244, P481, DOI 10.1007/978-3-319-59105-6_41
   Chatterjee S, 2017, NEURAL COMPUT APPL, V28, P2005, DOI 10.1007/s00521-016-2190-2
   Chatterjee S, 2016, ADV INTELL SYST COMP, V435, P227, DOI 10.1007/978-81-322-2757-1_23
   Chu C, 2010, AM FAM PHYSICIAN, V81, P1239
   Cohn LB, 2018, NAT MED, V24, P604, DOI 10.1038/s41591-018-0017-7
   CUZICK J, 1985, STAT MED, V4, P87, DOI 10.1002/sim.4780040112
   Daneshyari M, 2012, IEEE T SYST MAN CY A, V42, P475, DOI 10.1109/TSMCA.2011.2162498
   Deb K., 2000, Parallel Problem Solving from Nature PPSN VI. 6th International Conference. Proceedings (Lecture Notes in Computer Science Vol.1917), P849
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Gadekallu TR, 2021, J REAL-TIME IMAGE PR, V18, P1383, DOI 10.1007/s11554-020-00987-8
   Gallo RC, 2003, NEW ENGL J MED, V349, P2283, DOI 10.1056/NEJMp038194
   Ganesh S., 2019, INDIAN J PUBLIC HEAL, V10, P350, DOI [10.5958/0976-5506.2019.01025.8, DOI 10.5958/0976-5506.2019.01025.8]
   Getz G, 2003, BIOINFORMATICS, V19, P1079, DOI 10.1093/bioinformatics/btf876
   Ghaderian M, 2021, J BUILD ENG, V41, DOI 10.1016/j.jobe.2021.102440
   Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531
   Hartung J., 2008, Statistical Meta-Analysis with Applications, DOI DOI 10.1002/9780470386347
   HOLLAND JH, 1992, SCI AM, V267, P66, DOI 10.1038/scientificamerican0792-66
   Hore S., 2015, J ADV MICROSCOPY RES, V10, P93, DOI [10.1166/jamr.2015.1245, DOI 10.1166/JAMR.2015.1245]
   Hore S, 2017, ADV MULTIMED INTER, P66, DOI 10.4018/978-1-5225-1025-3.ch004
   Hore Sirshendu., 2016, International Journal of Electrical and Computer Engineering, V6, P2773, DOI [DOI 10.11591/IJECE.V6I6.11801, 10.11591/ijece.v6i6.11801]
   Hu HL, 2019, BIOINFORMATICS, V35, P1660, DOI 10.1093/bioinformatics/bty842
   Hyrcza MD, 2007, J VIROL, V81, P3477, DOI 10.1128/JVI.01552-06
   Jarboui B, 2007, APPL MATH COMPUT, V192, P337, DOI 10.1016/j.amc.2007.03.010
   Jemai Jaber, 2012, Evolutionary Computation in Combinatorial Optimization. Proceedings of the 12th European Conference, EvoCOP 2012, P37, DOI 10.1007/978-3-642-29124-1_4
   Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044
   Kim G, 2010, ARTIF INTELL MED, V48, P83, DOI 10.1016/j.artmed.2009.07.010
   Kohlmann A, 2004, LEUKEMIA, V18, P63, DOI 10.1038/sj.leu.2403167
   Kumar P, 2013, INDIAN J MED RES, V138, P291
   Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102
   Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131
   Ludwig SA, 2018, INT SER OPER RES MAN, V262, P327, DOI 10.1007/978-3-319-65455-3_13
   Lumini A, 2006, PATTERN RECOGN LETT, V27, P1537, DOI 10.1016/j.patrec.2006.01.014
   Mali K, 2015, INT J SECUR APPL, V9, P279, DOI 10.14257/ijsia.2015.9.12.26
   Mallik S, 2019, MODULATING GENE EXPR
   Nanni L, 2006, NEUROCOMPUTING, V69, P838, DOI 10.1016/j.neucom.2005.09.004
   O'Neill MC, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-13
   PANTALEO G, 1993, NEW ENGL J MED, V328, P327, DOI 10.1056/NEJM199302043280508
   PANTALEO G, 1995, NEW ENGL J MED, V332, P209, DOI 10.1056/NEJM199501263320402
   Ramon E, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2991-2
   Reddy GT, 2020, EVOL INTELL, V13, P185, DOI 10.1007/s12065-019-00327-1
   Remita MA, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1602-3
   Roy M, 2017, 2017 8TH ANNUAL INDUSTRIAL AUTOMATION AND ELECTROMECHANICAL ENGINEERING CONFERENCE (IEMECON), P230, DOI 10.1109/IEMECON.2017.8079595
   Seal A, 2017, ADV INTELL SYST, V458, P603, DOI 10.1007/978-981-10-2035-3_61
   Shukla AK, 2019, INFORM SCIENCES, V503, P238, DOI 10.1016/j.ins.2019.06.063
   Singh Y, 2010, SCI RES ESSAYS, V5, P2384
   WHO, 2015, HIV AIDS WHO FACT SH
   Wiens J, 2018, CLIN INFECT DIS, V66, P149, DOI 10.1093/cid/cix731
   Xu CY, 2014, AIDS RES HUM RETROV, V30, P134, DOI [10.1089/aid.2013.0073, 10.1089/AID.2013.0073]
   Young SD, 2017, JAIDS-J ACQ IMM DEF, V74, pS128, DOI [10.1097/QAI.0000000000001240, 10.1097/qai.0000000000001240]
   Zeng M, 2012, BLOOD, V120, P1856, DOI 10.1182/blood-2012-03-418624
   Zhang XY, 2018, CLIN EPIGENETICS, V10, DOI 10.1186/s13148-018-0591-z
NR 75
TC 4
Z9 4
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15103
EP 15126
DI 10.1007/s11042-022-12534-7
EA FEB 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000769532200002
DA 2024-07-18
ER

PT J
AU Ullah, Z
   Qi, L
   Binu, D
   Rajakumar, BR
   Ismail, BM
AF Ullah, Zia
   Qi, Lin
   Binu, D.
   Rajakumar, B. R.
   Ismail, B. Mohammed
TI 2-D canonical correlation analysis based image super-resolution scheme
   for facial emotion recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face image; Image super-resolution; Facial expression; 2D CCA; GM-WLBP;
   CNN; LSTM; ITSA
ID ROBUST FACE SUPERRESOLUTION; RESOLUTION; HALLUCINATION; ALGORITHM;
   NETWORK; MODELS
AB In this research work, a new Image super-resolution-based Face Emotion Recognition Model has been introduced. The proposed work includes two major phases: (a) Facial image super-resolution and (b) Facial emotion recognition. Initially, the collected facial image is subjected to the facial image super-resolution phase, where the Higher Resolution (HR) facial images are subjected to two-dimensional canonical correlation analysis (2D CCA). The acquired HR facial images are considered as the input for facial emotion recognition. From the acquired HR facial images, the face region alone (lips, eyes, and cheeks) is detected by Viola-Jones facial detection model. Subsequently, from the acquired facial regions, the most relevant features like proposed "Geometric Mean based Weighted Local Binary Pattern (GM-WLBP), Gray Level Co-occurrence Matrix (GLCM)" and generalized low-rank model (GLRM) features are extracted. Then, Principal Component Analysis (PCA) technique is applied to solve the curse of dimensionality. Finally, the reduced dimensional features are given to the emotion classification phase to classify the emotions as sad, happy, fear, rage, disgust, and surprise. The proposed hybrid classifier framework includes the renowned Long-Short Term Memory Network (LSTM) and Convolutional Neural Network (CNN) models. These deep learning models is separately trained using the dimensionally reduced features, and the outcomes are combined. Then, the mean value is computed on the final combined outcome (output of LSTM+ output of CNN), which results in the type of emotions. To enhance the classification accuracy, the weight of CNN is fine-tuned by a new Improved Tunicate swarm Optimization Model (ITSA), which is the conceptual improvement of standard Tunicate swarm Optimization (TSA). The performance of the proposed work is evaluated over the existing model to show the supremacy of the proposed work.
C1 [Ullah, Zia; Qi, Lin] Zhengzhou Univ, Zhengzhou, Peoples R China.
   [Binu, D.; Rajakumar, B. R.] Resbee Info Technol Private Ltd, Thuckalay, Tamil Nadu, India.
   [Ismail, B. Mohammed] Dept Informat Technol, Kannur Univ Campus, Mangattuparamba, Kerala, India.
C3 Zhengzhou University
RP Ullah, Z (corresponding author), Zhengzhou Univ, Zhengzhou, Peoples R China.
EM ziaullahkhanhaji@gmail.com
RI B, Mohammed Ismail/U-6139-2018; b, m/HPE-0989-2023
OI B, Mohammed Ismail/0000-0003-4480-3801; 
CR Amiri M, 2019, SIGNAL PROCESS-IMAGE, V70, P259, DOI 10.1016/j.image.2018.10.008
   An L, 2014, SIGNAL PROCESS, V103, P184, DOI 10.1016/j.sigpro.2013.10.004
   Anita J. S., 2019, MULTIMEDIA RES, V2, P9
   Boothalingam R, 2018, EVOL INTELL, V11, P31, DOI 10.1007/s12065-018-0168-y
   Cao L, 2020, IEEE ACCESS, V8, P173387, DOI 10.1109/ACCESS.2020.3025972
   Chen CF, 2021, IEEE T IMAGE PROCESS, V30, P1219, DOI 10.1109/TIP.2020.3043093
   Chen J, 2020, IEEE SIGNAL PROC LET, V27, P645, DOI 10.1109/LSP.2020.2986942
   Chen K, 2021, ARXIV PREPRINT ARXIV, P1, DOI DOI 10.1061/(ASCE)EY.1943-7897.0000804
   Chen L, 2020, IEEE T CIRC SYST VID, V30, P4513, DOI 10.1109/TCSVT.2019.2917511
   Chen L, 2020, IEEE T IMAGE PROCESS, V29, P9002, DOI 10.1109/TIP.2020.3023580
   Chen L, 2019, IEEE T IMAGE PROCESS, V28, P5897, DOI 10.1109/TIP.2019.2920510
   Darekar A. P., 2019, Multimed Res., V2, P12
   Farrugia RA, 2017, IEEE T IMAGE PROCESS, V26, P4562, DOI 10.1109/TIP.2017.2717181
   Grm K, 2020, IEEE T IMAGE PROCESS, V29, P2150, DOI 10.1109/TIP.2019.2945835
   Hu X, 2021, KNOWL-BASED SYST
   Ismail Mohammad, 2019, INT J INNOVATIVE TEC, V8, P1529
   Ismail BM, 2020, INT CONF ELECTRO INF, P228, DOI [10.1109/eit48999.2020.9208240, 10.1109/EIT48999.2020.9208240]
   Ismail BM, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER AND OPTIMIZATION TECHNIQUES (ICEECCOT), P21, DOI 10.1109/ICEECCOT.2016.7955179
   Ismail BM, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS, VISION AND INFORMATION SECURITY (CGVIS), P284, DOI 10.1109/CGVIS.2015.7449938
   Jiancheng Cai, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P109, DOI 10.1109/TBIOM.2019.2951063
   Jiang JJ, 2017, IEEE T CYBERNETICS, V47, P3991, DOI 10.1109/TCYB.2016.2594184
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P27, DOI 10.1109/TMM.2016.2601020
   Kaur S, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103541
   Koulierakis I., 2020, P LREC2020 9 WORKSHO, P123
   Gola KK, 2021, INT J COMMUN SYST, V34, DOI 10.1002/dac.4723
   Li JN, 2020, IEEE ACCESS, V8, P138373, DOI 10.1109/ACCESS.2020.3011699
   Li MY, 2021, IEEE T MULTIMEDIA, V23, P468, DOI 10.1109/TMM.2020.2984092
   Liu BL, 2020, NEUROCOMPUTING, V374, P109, DOI 10.1016/j.neucom.2019.09.035
   Liu L, 2019, IEEE ACCESS, V7, P77027, DOI 10.1109/ACCESS.2019.2921859
   Liu QM, 2020, IEEE ACCESS, V8, P4110, DOI 10.1109/ACCESS.2019.2962790
   Liu ZS, 2019, IEEE ACCESS, V7, P129112, DOI 10.1109/ACCESS.2019.2934078
   Lu T, 2020, NEUROCOMPUTING, V387, P309, DOI 10.1016/j.neucom.2020.01.015
   Lu T, 2018, IEEE ACCESS, V6, P56269, DOI 10.1109/ACCESS.2018.2872761
   Lu T, 2017, IEEE ACCESS, V5, P13103, DOI 10.1109/ACCESS.2017.2717963
   Mohammed Ismail B., 2012, Journal of Theoretical and Applied Information Technology, V42, P191
   Mohammed Ismail B., 2020, INT J EMERG TRENDS E, V8, P5693, DOI [10.30534/ijeter/2020/127892020, DOI 10.30534/IJETER/2020/127892020]
   Nagar S, 2021, INFORM SCIENCES, V546, P121, DOI 10.1016/j.ins.2020.08.002
   Pei XB, 2019, IEEE ACCESS, V7, P55180, DOI 10.1109/ACCESS.2019.2913008
   Potamias RA, 2019, COMM COM INF SC, V1000, P164, DOI 10.1007/978-3-030-20257-6_14
   Sarkar A., 2020, MULTIMED RES, DOI 10.46253/j.mr.v3i2.a5
   Shahane R., 2019, J COMPUT THEOR NANOS, V16, P5078, DOI [10.1166/jctn.2019.8567, DOI 10.1166/JCTN.2019.8567]
   Shaik GA, 2020, INT CONF ADVAN COMPU, P510, DOI [10.1109/ICACCS48705.2020.9074352, 10.1109/icaccs48705.2020.9074352]
   Sharma S, IOSR J COMPUTER ENG, V22, P51
   Shi JG, 2018, IEEE T IMAGE PROCESS, V27, P2980, DOI 10.1109/TIP.2018.2813163
   Wang H, 2021, KNOWL-BASED SYST, V222, DOI 10.1016/j.knosys.2021.106987
   Yan Y, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107370
   Yang S, 2018, IEEE T CYBERNETICS, V48, P399, DOI 10.1109/TCYB.2016.2638856
   Yu X, 2020, IEEE T PATTERN ANAL, V42, P2926, DOI 10.1109/TPAMI.2019.2916881
   Yu X, 2018, IEEE T IMAGE PROCESS, V27, P2747, DOI 10.1109/TIP.2018.2808840
   Yuan YH, 2021, INFORM SCIENCES, V561, P52, DOI 10.1016/j.ins.2021.01.082
   Yun JU, 2020, IEEE ACCESS, V8, P159661, DOI 10.1109/ACCESS.2020.3020729
   Zhang Y, 2021, IEEE T IMAGE PROCESS, V30, P1728, DOI 10.1109/TIP.2020.3046918
NR 52
TC 4
Z9 4
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13911
EP 13934
DI 10.1007/s11042-022-11922-3
EA FEB 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761979300016
DA 2024-07-18
ER

PT J
AU Gao, H
   Ding, XH
AF Gao, Hui
   Ding, Xiuhao
TI The research landscape on the artificial intelligence: a bibliometric
   analysis of recent 20 years
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial intelligence (AI); Bibliometric methods; Patent analysis;
   Visualization
ID STRATEGIC-MANAGEMENT; PATTERNS; PERSPECTIVE; SCIENCE; TRENDS; DOMAIN;
   MODEL
AB Artificial intelligence (AI), a general term that implies the imitation of information process of intelligent behavior and sense with minimal intervention, is one of the most promising research areas and has received a considerable attention with coexisting pros and cons. In order to understand the research status quo and future trends on AI technology, this work uses bibliometric analysis method to obtain this objective. By analyzing the datasets including journal article data collected from Web of Science (WOS), conference paper data retrieved from Scopus and the patent data extracted from Derwent Innovations Index (DII) in the period of 2000-2019, we primarily provide a comprehensive overview to better understand the research status of AI. Bibliometric analysis results can also shed light on the evolution and trends in AI.
C1 [Gao, Hui] Hubei Univ, Sch Business, Youyi Ave 368, Wuhan, Peoples R China.
   [Ding, Xiuhao] Huazhong Univ Sci & Technol, Sch Management, Luoyu Rd 1037, Wuhan, Peoples R China.
C3 Hubei University; Huazhong University of Science & Technology
RP Gao, H (corresponding author), Hubei Univ, Sch Business, Youyi Ave 368, Wuhan, Peoples R China.
EM gaohui-hust@qq.com
OI Gao, Hui/0000-0001-8629-6532
CR [Anonymous], 1950, MIND, DOI 10.1093/mind/LIX.236.433
   Browne M, 2007, COAST ENG, V54, P445, DOI 10.1016/j.coastaleng.2006.11.007
   Carvalho MM, 2013, TECHNOL FORECAST SOC, V80, P1418, DOI 10.1016/j.techfore.2012.11.008
   Castelfranchi C, 2013, TOPOI-INT REV PHILOS, V32, P293, DOI 10.1007/s11245-013-9182-y
   Chen CM, 2017, J DATA INFO SCI, V2, P1, DOI 10.1515/jdis-2017-0006
   Chen CM, 2014, J ASSOC INF SCI TECH, V65, P334, DOI 10.1002/asi.22968
   Chen CM, 2010, J AM SOC INF SCI TEC, V61, P1386, DOI 10.1002/asi.21309
   Chen CM, 2009, J INFORMETR, V3, P191, DOI 10.1016/j.joi.2009.03.004
   Chen CM, 2006, J AM SOC INF SCI TEC, V57, P359, DOI 10.1002/asi.20317
   Chen CM, 2004, P NATL ACAD SCI USA, V101, P5303, DOI 10.1073/pnas.0307513100
   Cobo MJ, 2015, KNOWL-BASED SYST, V80, P3, DOI 10.1016/j.knosys.2014.12.035
   Érdi P, 2013, SCIENTOMETRICS, V95, P225, DOI 10.1007/s11192-012-0796-4
   Fernandes C, 2017, SCIENTOMETRICS, V112, P529, DOI 10.1007/s11192-017-2397-8
   Fujii H, 2018, ECON ANAL POLICY, V58, P60, DOI 10.1016/j.eap.2017.12.006
   Hamet P, 2017, METABOLISM, V69, pS36, DOI 10.1016/j.metabol.2017.01.011
   He JX, 2019, NAT MED, V25, P30, DOI 10.1038/s41591-018-0307-0
   Hinojo-Lucena FJ, 2019, EDUC SCI, V9, DOI 10.3390/educsci9010051
   Koyuncugil AS, 2012, EXPERT SYST APPL, V39, P6238, DOI 10.1016/j.eswa.2011.12.021
   Liu JY, 2018, IEEE ACCESS, V6, P34403, DOI 10.1109/ACCESS.2018.2819688
   MARR D, 1977, ARTIF INTELL, V9, P37, DOI 10.1016/0004-3702(77)90013-3
   Mikhaylov SJ, 2018, PHILOS T R SOC A, V376, DOI 10.1098/rsta.2017.0357
   Najmi A, 2017, SCIENTOMETRICS, V110, P843, DOI 10.1007/s11192-016-2171-3
   Niu JQ, 2016, ISPRS INT J GEO-INF, V5, DOI 10.3390/ijgi5050066
   Palaniappan R, 2014, BIOMED ENG-BIOMED TE, V59, P7, DOI 10.1515/bmt-2013-0074
   Parkes DC, 2015, SCIENCE, V349, P267, DOI 10.1126/science.aaa8403
   Patrício DI, 2018, COMPUT ELECTRON AGR, V153, P69, DOI 10.1016/j.compag.2018.08.001
   Prasad S, 2005, INFORM MANAGE-AMSTER, V42, P1137, DOI 10.1016/j.im.2005.01.003
   Ramos-Rodríguez AR, 2004, STRATEGIC MANAGE J, V25, P981, DOI 10.1002/smj.397
   Rodriguez A, 2016, IEEE T ENG MANAGE, V63, P426, DOI 10.1109/TEM.2016.2580619
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Salah K, 2019, IEEE ACCESS, V7, P10127, DOI 10.1109/ACCESS.2018.2890507
   Sikdar S, 2018, CLEAN TECHNOL ENVIR, V20, P1, DOI 10.1007/s10098-017-1478-y
   Soranzo B, 2016, J ENG TECHNOL MANAGE, V42, P15, DOI 10.1016/j.jengtecman.2016.08.002
   Tseng CY, 2013, INNOV-ORGAN MANAG, V15, P463, DOI 10.5172/impp.2013.15.4.463
   Wang FY, 2017, IEEE INTEL TRANSP SY, V9, P6, DOI 10.1109/MITS.2017.2746407
   Wang MG, 2018, APPL ENERG, V220, P480, DOI 10.1016/j.apenergy.2018.03.148
   Youssef A, 2017, RENEW SUST ENERG REV, V78, P72, DOI 10.1016/j.rser.2017.04.046
   Zeng Y, 2017, NATL SCI REV, V4, P490, DOI 10.1093/nsr/nwx060
NR 38
TC 5
Z9 5
U1 15
U2 76
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12973
EP 13001
DI 10.1007/s11042-022-12208-4
EA FEB 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000760059700008
DA 2024-07-18
ER

PT J
AU Niazi, M
   Rahbar, K
   Sheikhan, M
   Khademi, M
AF Niazi, Mehrnaz
   Rahbar, Kambiz
   Sheikhan, Mansour
   Khademi, Maryam
TI Entropy-based kernel graph cut for textural image region segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Kernel graph cut; Entropy; Texture
ID ACTIVE CONTOURS DRIVEN; MODEL; FRAMEWORK; ENERGY
AB Recently, image segmentation based on graph cut methods has shown impressive performance on a set of image data. Although kernel graph cut provides more comprehensive performance, its performance is largely dependent on intensity values of the input image. Meanwhile kernel graph cut is not well-performed for textural images. This paper investigated entropy-based kernel graph cut image segmentation. The method consists of incorporating 2-layer feature space (1-layer gray level and 1-layer entropy feature) and minimizing an objective function to have localized and intensity-based comparison. By taking the advantage of a new feature space, the objective function comprises a data term to assess the transformed data deviation within each region of segmented image and a boundary regularization term. The proposed method supersedes modeling of the non-textural and complex textural images efficiently while taking advantage of the graph cuts computational profits. Experimentations were carried out over a collection of (real and synthetic) datasets to demonstrate the superior performance of the entropy-based kernel as compared to the state-of-the-art methods in energy-based image segmentation. The texture of the artificial images was created manually using the Color Brodatz, Fabric and DTD datasets. The simulation results report the maximum accuracy of the proposed solution on artificial and real images as 96.90% and 92.45%, respectively.
C1 [Niazi, Mehrnaz; Rahbar, Kambiz] Islamic Azad Univ, South Tehran Branch, Dept Comp Engn, Tehran, Iran.
   [Sheikhan, Mansour] Islamic Azad Univ, South Tehran Branch, Dept Elect Engn, Tehran, Iran.
   [Khademi, Maryam] Islamic Azad Univ, South Tehran Branch, Dept Appl Math, Tehran, Iran.
C3 Islamic Azad University; Islamic Azad University; Islamic Azad
   University
RP Rahbar, K (corresponding author), Islamic Azad Univ, South Tehran Branch, Dept Comp Engn, Tehran, Iran.
EM k_rahbar@azad.ac.ir
RI Rahbar, Kambiz/F-6037-2012
OI Rahbar, Kambiz/0000-0003-2212-0479
CR Abid Rahman Chowdhury Mohammad, 2019, 2019 IEEE International Conference on Signal Processing, Information, Communication & Systems (SPICSCON), P86, DOI 10.1109/SPICSCON48833.2019.9065146
   Achanta SDM, 2019, SOFT COMPUT, V23, P8359, DOI 10.1007/s00500-019-04108-x
   Amirkhani D, 2021, MULTIMED TOOLS APPL, V80, P26199, DOI 10.1007/s11042-021-10883-3
   Atkinson D, 1997, IEEE T MED IMAGING, V16, P903, DOI 10.1109/42.650886
   Ben Salah M, 2011, IEEE T IMAGE PROCESS, V20, P545, DOI 10.1109/TIP.2010.2066982
   Chen X, 2016, IEEE SYS MAN CYBERN, P2547, DOI 10.1109/SMC.2016.7844622
   Deng G, 2009, IEEE T IMAGE PROCESS, V18, P1135, DOI 10.1109/TIP.2009.2016796
   Ding KY, 2018, PATTERN RECOGN LETT, V104, P29, DOI 10.1016/j.patrec.2018.01.019
   Ding KY, 2017, SIGNAL PROCESS, V134, P224, DOI 10.1016/j.sigpro.2016.12.021
   Dubolia R., 2011, 2011 International Conference on Communication Systems and Network Technologies (CSNT), P593, DOI 10.1109/CSNT.2011.127
   Faliu Yi, 2012, 2012 International Conference on Systems and Informatics (ICSAI 2012), P1936, DOI 10.1109/ICSAI.2012.6223428
   Gao PC, 2020, IEEE ACCESS, V8, P92552, DOI 10.1109/ACCESS.2020.2994345
   González-Díaz I, 2014, IEEE T MULTIMEDIA, V16, P169, DOI 10.1109/TMM.2013.2286083
   Harini R., 2012, Proceedings of the 2012 International Conference on Pattern Recognition, Informatics and Medical Engineering (PRIME), P261, DOI 10.1109/ICPRIME.2012.6208355
   Huang QW, 2021, TSINGHUA SCI TECHNOL, V26, P833, DOI 10.26599/TST.2020.9010042
   Kang Z, 2019, KNOWL-BASED SYST, V163, P510, DOI 10.1016/j.knosys.2018.09.009
   Kaur Dilpreet, 2014, International Journal of Computer Science and Mobile Computing, V3, P809, DOI DOI 10.13140/RG.2.2.28324.07046
   Kéchichian R, 2018, IEEE T MED IMAGING, V37, P2739, DOI 10.1109/TMI.2018.2851780
   Koh RGL, 2020, IEEE ENG MED BIO, P2015, DOI 10.1109/EMBC44109.2020.9176526
   Liao XY, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103334
   Luo Qing, 2013, Biomed Eng Online, V12, P124, DOI 10.1186/1475-925X-12-124
   Luo Q, 2013, APPL MECH MATER, V333-335, P938, DOI 10.4028/www.scientific.net/AMM.333-335.938
   Malcolm J, 2007, IEEE IMAGE PROC, P2061
   Modhej N, 2020, IEEE ACCESS, V8, P212803, DOI 10.1109/ACCESS.2020.3040298
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Mohan AS, 2014, 2014 First International Conference on Computational Systems and Communications (ICCSC), P288, DOI 10.1109/COMPSC.2014.7032664
   Mukherjee S, 2015, IEEE SIGNAL PROC LET, V22, P298, DOI 10.1109/LSP.2014.2346538
   Müller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517
   Ns R, 2016, J TELECOMMUN SYST MA, V5, P3, DOI 10.4172/2167-0919.1000143
   Panigrahi L, 2019, EXPERT SYST APPL, V115, P486, DOI 10.1016/j.eswa.2018.08.013
   Prakash J, 2019, IEEE T BIO-MED ENG, V66, P2604, DOI 10.1109/TBME.2019.2892842
   Rahbar K, 2019, SIGNAL PROCESS, V164, P1, DOI 10.1016/j.sigpro.2019.05.033
   Setiawan Agung W., 2020, 2020 International Conference on Computer Engineering, Network, and Intelligent Multimedia (CENIM), P97, DOI 10.1109/CENIM51130.2020.9297970
   Tu LY, 2018, IEEE T MED IMAGING, V37, P1, DOI 10.1109/TMI.2017.2755550
   Xiangzhi Bai, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1083, DOI 10.1109/CISP.2010.5646893
   Yang DD, 2016, APPL SOFT COMPUT, V44, P30, DOI 10.1016/j.asoc.2016.01.055
   Yuan J, 2014, NUMER MATH, V126, P559, DOI 10.1007/s00211-013-0569-x
   Zeng S, 2019, NEUROCOMPUTING, V335, P59, DOI 10.1016/j.neucom.2019.01.042
   Zhang LL, 2013, IEEE IMAGE PROC, P4358, DOI 10.1109/ICIP.2013.6738898
   Zhang QH, 2020, IEEE ACM T COMPUT BI, V17, P679, DOI 10.1109/TCBB.2018.2864203
   Zheng Z, 2019, IEEE ACCESS, V7, P92943, DOI 10.1109/ACCESS.2019.2927655
NR 41
TC 5
Z9 6
U1 9
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 13003
EP 13023
DI 10.1007/s11042-022-12005-z
EA FEB 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000760059700001
DA 2024-07-18
ER

PT J
AU Mannepalli, DP
   Namdeo, V
AF Mannepalli, Durga Prasad
   Namdeo, Varsha
TI A cad system design based on HybridMultiscale convolutional Mantaray
   network for pneumonia diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CNN; SVR; Self-attention module (SAM); Mantaray foraging optimization;
   Pneumonia; Fuzzy color; Stacking
ID CHEST X-RAYS
AB Pneumonia is one of the diseases that people may encounter in any period of their lives. Recently, researches and developers all around the world are focussing on deep learning and image processing strategies to quicken the pneumonia diagnosis as those strategies are capable of processing numerous X-ray and computed tomography (CT) images. Clinicians need more time and appropriate experiences for making a diagnosis. Hence, a precise, reckless, and less expensive tool to detect pneumonia is necessary. Thus, this research focuses on classifying the pneumonia chest X-ray images by proposing a very efficient stacked approach to improve the image quality and hybridmultiscale convolutional mantaray feature extraction network model with high accuracy. The input dataset is restructured with the sake of a hybrid fuzzy colored and stacking approach. Then the deep feature extraction stage is processed with the aid of stacking dataset by hybrid multiscale feature extraction unit to extract multiple features. Also, the features and network size are diminished by the self-attention module (SAM) based convolutional neural network (CNN). In addition to this, the error in the proposed network model will get reduced with the aid of adaptivemantaray foraging optimization (AMRFO) approach. Finally, the support vector regression (SVR) is suggested to classify the presence of pneumonia. The proposed module has been compared with existing technique to prove the overall efficiency of the system. The huge collection of chest X-ray images from the kaggle dataset was emphasized to validate the proposed work. The experimental results reveal an outstanding performance of accuracy (97%), precision (95%) and f-score (96%) progressively.
C1 [Mannepalli, Durga Prasad] Sarvepalli Radhakrishnan Univ, Dept Comp Sci Engn, Bhopal, Madhya Pradesh, India.
   [Namdeo, Varsha] Sarvepalli Radhakrishnan Univ, Dept Comp Sci & Engn, Bhopal, Madhya Pradesh, India.
RP Mannepalli, DP (corresponding author), Sarvepalli Radhakrishnan Univ, Dept Comp Sci Engn, Bhopal, Madhya Pradesh, India.
EM dp.mannepalli@gmail.com
CR Achanta SDM, 2019, INT J INTELL UNMANNE, V8, P43, DOI 10.1108/IJIUS-01-2019-0005
   Achanta SDM, 2019, SOFT COMPUT, V23, P8359, DOI 10.1007/s00500-019-04108-x
   Ait Skourt B, 2018, PROCEDIA COMPUT SCI, V127, P109, DOI 10.1016/j.procs.2018.01.104
   Asuntha A, 2020, MULTIMED TOOLS APPL, V79, P7731, DOI 10.1007/s11042-019-08394-3
   Chen HJ, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8040545
   Chouhan V, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020559
   Demir F, 2019, HEALTH INF SCI SYST, V8, DOI 10.1007/s13755-019-0091-3
   Elpeltagy M, 2021, MULTIMED TOOLS APPL, V80, P26451, DOI 10.1007/s11042-021-10783-6
   Fujita H, 2020, RADIOL PHYS TECHNOL, V13, P6, DOI 10.1007/s12194-019-00552-4
   Hashmi MF, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10060417
   Hu QH, 2020, ARTIF INTELL MED, V103, DOI 10.1016/j.artmed.2020.101792
   Ibrahim AU, 2021, COGN COMPUT, DOI 10.1007/s12559-020-09787-5
   Jain R, 2020, MEASUREMENT, V165, DOI 10.1016/j.measurement.2020.108046
   Jaiswal AK, 2019, MEASUREMENT, V145, P511, DOI 10.1016/j.measurement.2019.05.076
   Khan AI, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105581
   Li YY, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103898
   Liang GB, 2020, COMPUT METH PROG BIO, V187, DOI 10.1016/j.cmpb.2019.06.023
   Mahmud T, 2020, COMPUT BIOL MED, V122, DOI 10.1016/j.compbiomed.2020.103869
   Moon WK, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105361
   Moujahid H., 2020, Adv. Sci. Technol. Eng. Syst. J., V5, P167
   Ni QQ, 2020, EUR RADIOL, V30, P6517, DOI 10.1007/s00330-020-07044-9
   Qin JH, 2020, ECOL INFORM, V58, DOI 10.1016/j.ecoinf.2020.101093
   Rahman T, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093233
   Singh VK, 2022, MULTIMED TOOLS APPL, V81, P3, DOI 10.1007/s11042-021-11158-7
   Sirazitdinov I, 2019, COMPUT ELECTR ENG, V78, P388, DOI 10.1016/j.compeleceng.2019.08.004
   Song Y, 2021, IEEE ACM T COMPUT BI, V18, P2775, DOI 10.1109/TCBB.2021.3065361
   Varela-Santos S., 2020, STUDIES COMPUTATIONA, P237
   Yee Sara Lee Kit, 2020, ICBET 2020: Proceedings of the 2020 10th International Conference on Biomedical Engineering and Technology, P101, DOI 10.1145/3397391.3397412
   Yue ZJ, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8876798
   Zhang JP, 2021, IEEE T MED IMAGING, V40, P879, DOI 10.1109/TMI.2020.3040950
NR 30
TC 1
Z9 1
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12857
EP 12881
DI 10.1007/s11042-022-12547-2
EA FEB 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000759366800001
PM 35221779
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Zheng, SF
   Liu, CY
   Feng, ZJ
   Chen, RQ
   Liu, XL
AF Zheng, Sifei
   Liu, Chengyu
   Feng, Zijing
   Chen, Riqing
   Liu, Xiaolong
TI Visual image encryption scheme based on vector quantization and content
   transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Discrete wavelet transforms; Vector quantization;
   Visual image encryption
ID INFORMATION SECURITY; ALGORITHM; CLOUD; IMPROVEMENT; WAVELET; CHAOS
AB The security issues of outsourced storage make it challenging to protect the privacy of image contents. The noise-like encrypted image generated by traditional image encryption schemes are easy to attract the interest of attackers, courting malicious attacks and analysis on it. In this paper, a novel visual image encryption scheme is proposed to encrypt original image into a visually meaningful camouflaged image, thereby not only protects original images in an encryption way, but also provides an additional visual protection to avoid the risk of being attacked. The original image is first subjected to vector quantization (VQ) encoding, and then visually encrypted by content transform based on discrete wavelet transform (DWTCT) to generate the camouflaged image. The experimental results show that the size of camouflaged image is the same as original image, thereby maintaining the storage efficiency in the outsourced cloud environment. Compared with existing visual image encryption schemes, the proposed scheme shows outstanding performance on both storage and camouflage characteristics of the encrypted images.
C1 [Zheng, Sifei; Liu, Chengyu; Feng, Zijing; Chen, Riqing; Liu, Xiaolong] Fujian Agr & Forestry Univ, Coll Comp & Informat Sci, Fuzhou 350002, Peoples R China.
C3 Fujian Agriculture & Forestry University
RP Liu, XL (corresponding author), Fujian Agr & Forestry Univ, Coll Comp & Informat Sci, Fuzhou 350002, Peoples R China.
EM zhengsifei@sina.com; liu714yu@sina.com; fzj971012@sina.com;
   riqing.chen@fafu.edu.cn; xlliu@fafu.edu.cn
FU Natural Science Foundation of Fujian Province, China [2021J01123];
   Social Science Planning Project of Fujian Province, China [FJ2021BF048];
   fund of scientific and technological innovation of Fujian agriculture
   and Forestry University [KCX21F31A]
FX This paragraph of the first footnote will contain the date on which you
   submitted your paper for review. This work was supported in part by the
   fund of Natural Science Foundation of Fujian Province, China (Grant No.
   2021J01123), Social Science Planning Project of Fujian Province, China
   (Grant No. FJ2021BF048) and fund of scientific and technological
   innovation of Fujian agriculture and Forestry University (Grant No.
   KCX21F31A).
CR Ab Rahman NH, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3868
   Agrawal V, 2017, J COMPUT, V12, P57, DOI 10.17706/jcp.12.1.57-67
   Ahmad M, 2011, COMM COM INF SC, V169, P257
   Al-Dhuraibi Y, 2018, IEEE T SERV COMPUT, V11, P430, DOI 10.1109/TSC.2017.2711009
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Chang V, 2016, FUTURE GENER COMP SY, V57, P56, DOI 10.1016/j.future.2015.10.003
   Chen TS, 1998, IEEE T IMAGE PROCESS, V7, P1485, DOI 10.1109/83.718488
   Cheng L, 2020, IEEE T SERV COMPUT, V13, P368, DOI 10.1109/TSC.2019.2906203
   Dang PP, 2000, IEEE T CONSUM ELECTR, V46, P395, DOI 10.1109/30.883383
   Fan HJ, 2018, MULTIMED TOOLS APPL, V77, P20103, DOI 10.1007/s11042-017-5437-8
   Gu GS, 2014, OPTIK, V125, P4700, DOI 10.1016/j.ijleo.2014.05.023
   He JH, 2018, IEEE T MULTIMEDIA, V20, P2645, DOI 10.1109/TMM.2018.2817065
   Hoang T, 2019, IEEE T SERV COMPUT, P1
   Jia K, 2013, IEEE T PATTERN ANAL, V35, P367, DOI 10.1109/TPAMI.2012.95
   Kanso A, 2017, OPT LASER ENG, V90, P196, DOI 10.1016/j.optlaseng.2016.10.009
   Kwon HS, 2017, MULTIMED TOOLS APPL, V76, P5889, DOI 10.1007/s11042-015-2595-4
   Li CQ, 2009, IMAGE VISION COMPUT, V27, P1371, DOI 10.1016/j.imavis.2008.12.008
   Lin CC, 2015, INFORM SCIENCES, V293, P314, DOI 10.1016/j.ins.2014.08.057
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Liu ZJ, 2011, OPT COMMUN, V284, P123, DOI 10.1016/j.optcom.2010.09.013
   Luo YL, 2015, COMMUN NONLINEAR SCI, V20, P447, DOI 10.1016/j.cnsns.2014.05.022
   McCormac A, 2017, COMPUT HUM BEHAV, V69, P151, DOI 10.1016/j.chb.2016.11.065
   Rao L, 2020, IEEE T SERV COMPUT, V13, P451, DOI 10.1109/TSC.2017.2708116
   Tsu-Yang Wu, 2019, Proceedings of the Fifth Euro-China Conference on Intelligent Data Analysis and Applications. Advances in Intelligent Systems and Computing (AISC 891), P241, DOI 10.1007/978-3-030-03766-6_27
   Varghese B, 2018, FUTURE GENER COMP SY, V79, P849, DOI 10.1016/j.future.2017.09.020
   Wang CY, 2018, IEEE T IMAGE PROCESS, V27, P4066, DOI 10.1109/TIP.2018.2836316
   Wang YQ, 2015, INT CONF ACOUST SPEE, P4984, DOI 10.1109/ICASSP.2015.7178919
   Wu SY, 2019, J INTERNET TECHNOL, V20, P13, DOI 10.3966/160792642019012001002
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xu L, 2014, IEEE ACCESS, V2, P1149, DOI 10.1109/ACCESS.2014.2362522
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
   Zhang YS, 2018, IEEE INTERNET THINGS, V5, P3442, DOI 10.1109/JIOT.2017.2781737
   Zheng S., 2019 IEEE INT C PAR, V2019, P891
NR 34
TC 3
Z9 4
U1 3
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12815
EP 12832
DI 10.1007/s11042-022-12583-y
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000758977800001
DA 2024-07-18
ER

PT J
AU Liu, HJ
   Liu, J
   Ma, C
AF Liu, Hongjun
   Liu, Jian
   Ma, Chao
TI Constructing dynamic strong S-Box using 3D chaotic map and application
   to image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D improved quadratic map; Non-degeneration; S-Box; Random
   substitution-depth
ID ALGORITHM; SCHEME; SYSTEM; DESIGN; KEYS
AB The main contribution is to design a cryptographically keyed strong S-Box construction method, based on a non-degenerate 3D improved quadratic map (3D-IQM). First, a 3D-IQM is constructed, dynamics analysis demonstrated its ergodicity and better randomness in phase space. Based on 3D-IQM, a keyed dynamic strong S-Box construction method is designed, which can satisfy six criteria and without fixed-point, reverse fixed-point, or short cycles. To verify its effectiveness in cryptography, the red, green and blue components of color image are encrypted using three S-Boxes, to further enhance the encryption intensity, three random substitution-depth sequences are generated to substitute each pixel with S-Box for random times. Security analysis and experimental statistics verified the algorithm's security and effectiveness.
C1 [Liu, Hongjun; Liu, Jian; Ma, Chao] Jinan Univ, Sch Math Sci, Jinan 250022, Shandong, Peoples R China.
C3 University of Jinan
RP Liu, HJ (corresponding author), Jinan Univ, Sch Math Sci, Jinan 250022, Shandong, Peoples R China.
EM sms_liuhj@ujn.edu.cn
RI Liu, Jian/ABD-2888-2021
OI Liu, Hongjun/0000-0003-4991-6696
FU National Natural Science Foundation of China [61662073, 61773010];
   Science and Technology Program of University of Jinan [XKY2070]
FX This research is supported by the National Natural Science Foundation of
   China (Nos: 61662073, 61773010), the Science and Technology Program of
   University of Jinan (No: XKY2070).
CR Belazi A, 2017, OPTIK, V130, P1438, DOI 10.1016/j.ijleo.2016.11.152
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Ding Y, 2021, IEEE INTERNET THINGS, V8, P1504, DOI 10.1109/JIOT.2020.3012452
   Farah T, 2017, NONLINEAR DYNAM, V88, P1059, DOI 10.1007/s11071-016-3295-y
   GRASSBERGER P, 1983, PHYS REV A, V28, P2591, DOI 10.1103/PhysRevA.28.2591
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Hua ZY, 2016, IEEE T CYBERNETICS, V46, P3330, DOI 10.1109/TCYB.2015.2504180
   Hussain I, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030351
   Khan M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0225031
   Khan M, 2018, NEURAL COMPUT APPL, V29, P993, DOI 10.1007/s00521-016-2511-5
   Khan MA, 2018, IJST-T ELECTR ENG, V42, P219, DOI 10.1007/s40998-018-0061-9
   Lambic D, 2017, NONLINEAR DYNAM, V87, P2407, DOI 10.1007/s11071-016-3199-x
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Liu HJ, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501734
   Liu HJ, 2020, APPL MATH COMPUT, V376, DOI 10.1016/j.amc.2020.125153
   Liu HJ, 2019, OPT LASER ENG, V122, P123, DOI 10.1016/j.optlaseng.2019.05.027
   Liu HJ, 2019, MULTIMED TOOLS APPL, V78, P15997, DOI 10.1007/s11042-018-6996-z
   Liu HJ, 2019, APPL MATH COMPUT, V360, P83, DOI 10.1016/j.amc.2019.04.078
   Liu HJ, 2017, IET IMAGE PROCESS, V11, P324, DOI 10.1049/iet-ipr.2016.0040
   Liu HJ, 2015, OPT COMMUN, V338, P340, DOI 10.1016/j.optcom.2014.10.021
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Manjula G, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL COMPUTING AND COMMUNICATION TECHNOLOGY (ICATCCT), P613, DOI 10.1109/ICATCCT.2016.7912073
   Moreira FJS., 1993, CHAOTIC DYNAMICS QUA
   Ullah A, 2017, NONLINEAR DYNAM, V88, P2757, DOI 10.1007/s11071-017-3409-1
   Wang MX, 2019, OPT LASER ENG, V121, P479, DOI 10.1016/j.optlaseng.2019.05.013
   Wang XY, 2018, MULTIMED TOOLS APPL, V77, P6243, DOI 10.1007/s11042-017-4534-z
   Wang XY, 2019, NONLINEAR DYNAM, V95, P2797, DOI 10.1007/s11071-018-4723-y
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P6191, DOI 10.1007/s11042-018-6326-5
   Wang XY, 2019, OPT LASER TECHNOL, V115, P42, DOI 10.1016/j.optlastec.2019.02.009
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2018, IEEE ACCESS, V6, P23733, DOI 10.1109/ACCESS.2018.2805847
   Wang XY, 2018, OPT LASER ENG, V103, P1, DOI 10.1016/j.optlaseng.2017.11.009
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
NR 33
TC 66
Z9 66
U1 14
U2 59
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 23899
EP 23914
DI 10.1007/s11042-022-12069-x
EA FEB 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000757777400015
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Xiao, MH
   Zhang, W
   Zhao, YF
   Xu, XM
   Zhou, SF
AF Xiao, Maohua
   Zhang, Wei
   Zhao, Yuanfang
   Xu, Xiaomei
   Zhou, Shufang
TI Fault diagnosis of gearbox based on wavelet packet transform and
   CLSPSO-BP
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wavelet packet transform; BP neural network; Chaotic particle swarm
   algorithm; Fault diagnosis
ID PARTICLE SWARM OPTIMIZATION
AB Fault diagnosis of gearbox is difficult due to the complexity and instability of its vibration signal. A fault diagnosis method of gearbox based on WPT-CLSPSO-BP (Wavelet Packet Transform- Chaos Particle Swarm Optimization-Back Propagation Neural Network) is proposed in this study to solve this problem. Wavelet packet transform (WPT) is used to decompose and reconstruct the signal, and the energy value of each component is calculated according to the formula, and the energy value is used as a feature input to form a feature sample. Aiming at the problem of slow convergence speed and easy local optimization of traditional BP neural network, a chaotic particle swarm algorithm is proposed to optimize the weight and threshold of the network, and the optimized network performance is verified with the data collected by experiments. Experimental results show that the average diagnosis rate of CLSPSO-BP is above 92%,the trained model not only has a high diagnostic rate, which can be improved by nearly 10%, but also can keep the error value between the actual output and the predicted output below 0.1%, indicating that the optimized network has a higher fault recognition rate.
C1 [Xiao, Maohua; Zhang, Wei; Zhao, Yuanfang] Nanjing Agr Univ, Coll Engn, Nanjing 210031, Peoples R China.
   [Xiao, Maohua; Zhou, Shufang] Nanjing Forestry Univ, Coll Automobile & Traff Engn, Nanjing 210037, Peoples R China.
   [Xu, Xiaomei] Qingdao Huanghai Univ, Intelligent Mfg Coll, Qingdao 266427, Peoples R China.
C3 Nanjing Agricultural University; Nanjing Forestry University
RP Xiao, MH (corresponding author), Nanjing Agr Univ, Coll Engn, Nanjing 210031, Peoples R China.; Xiao, MH (corresponding author), Nanjing Forestry Univ, Coll Automobile & Traff Engn, Nanjing 210037, Peoples R China.
EM xiaomaohua@njau.edu.cn
FU Modern Agricultural Machinery Equipment and Technology Demonstration and
   Promotion Project in Jiangsu Province [NJ2020-01]; Key Research and
   Development Program of Jiangsu Province [BE2020317]
FX The research is funded partially by Modern Agricultural Machinery
   Equipment and Technology Demonstration and Promotion Project in Jiangsu
   Province (NJ2020-01), and the Key Research and Development Program of
   Jiangsu Province (BE2020317).
CR Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   [Anonymous], 2012, INT J INTELL SYST AP, DOI [DOI 10.5815/IJISA.2012.07.03, 10.5815/ijisa10.5815/ijisa:2012.0710.5815/ijisa:2012.07.03]
   Azamfar M, 2020, MECH SYST SIGNAL PR, V144, DOI 10.1016/j.ymssp.2020.106861
   Dongardive J, 2017, NEURAL COMPUT APPL, V28, P1947, DOI 10.1007/s00521-015-2150-2
   Plaza EG, 2018, MECH SYST SIGNAL PR, V98, P902, DOI 10.1016/j.ymssp.2017.05.028
   Huang WT, 2018, J INTELL MANUF, V29, P1257, DOI 10.1007/s10845-015-1174-x
   Javidi MM, 2016, TURK J ELECTR ENG CO, V24, P3852, DOI 10.3906/elk-1404-220
   Karami V, 2020, APPL OCEAN RES, V101, DOI 10.1016/j.apor.2020.102224
   Kim Y, 2020, MECH SYST SIGNAL PR, V138, DOI 10.1016/j.ymssp.2019.106544
   Paul R, 2017, MEASUREMENT, V97, P226, DOI 10.1016/j.measurement.2016.11.005
   Santana Gisele A., 2018, J. Microw. Optoelectron. Electromagn. Appl., V17, P268, DOI 10.1590/2179-10742018v17i21258
   Singh J, 2018, MECH SYST SIGNAL PR, V100, P662, DOI 10.1016/j.ymssp.2017.06.040
   Sun RB, 2019, MECH SYST SIGNAL PR, V122, P737, DOI 10.1016/j.ymssp.2018.12.054
   Tayab UB, 2020, ENERGY, V203, DOI 10.1016/j.energy.2020.117857
   Wang LM, 2017, ENG FAIL ANAL, V71, P166, DOI 10.1016/j.engfailanal.2016.11.003
   Wang YX, 2010, MECH SYST SIGNAL PR, V24, P119, DOI 10.1016/j.ymssp.2009.06.015
   Xu XM, 2019, ARAB J SCI ENG, V44, P1365, DOI 10.1007/s13369-018-3527-1
   Yesilli MC, 2020, CIRP J MANUF SCI TEC, V28, P118, DOI 10.1016/j.cirpj.2019.11.003
   Zhang Y, 2020, IEEE ACCESS, V8, P19033, DOI 10.1109/ACCESS.2020.2966827
   Zhang Y, 2019, MECH SYST SIGNAL PR, V122, P480, DOI 10.1016/j.ymssp.2018.12.039
   Zhang Y, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1, DOI 10.1145/3025453.3025842
   Zhang Z, 2019, P I MECH ENG D-J AUT, V233, P3449, DOI 10.1177/0954407019825987
   [周兴康 Zhou Xingkang], 2020, [机械工程学报, Journal of Mechanical Engineering], V56, P96
   Zhou ZC, 2019, INSIGHT, V61, P35, DOI 10.1784/insi.2019.61.1.35
   Zuber N, 2013, APPL MECH MATER, V430, P70, DOI 10.4028/www.scientific.net/AMM.430.70
NR 27
TC 6
Z9 8
U1 4
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11519
EP 11535
DI 10.1007/s11042-022-12465-3
EA FEB 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757777400016
DA 2024-07-18
ER

PT J
AU Sánchez-Hevia, HA
   Gil-Pita, R
   Utrilla-Manso, M
   Rosa-Zurera, M
AF Sanchez-Hevia, Hector A.
   Gil-Pita, Roberto
   Utrilla-Manso, Manuel
   Rosa-Zurera, Manuel
TI Age group classification and gender recognition from speech with
   temporal convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive voice response; Age estimation; Gender recognition;
   Human-robot interaction; Machine learning
AB This paper analyses the performance of different types of Deep Neural Networks to jointly estimate age and identify gender from speech, to be applied in Interactive Voice Response systems available in call centres. Deep Neural Networks are used, because they have recently demonstrated discriminative and representation capabilities in a wide range of applications, including speech processing problems based on feature extraction and selection. Networks with different sizes are analysed to obtain information on how performance depends on the network architecture and the number of free parameters. The speech corpus used for the experiments is Mozilla's Common Voice dataset, an open and crowdsourced speech corpus. The results are really good for gender classification, independently of the type of neural network, but improve with the network size. Regarding the classification by age groups, the combination of convolutional neural networks and temporal neural networks seems to be the best option among the analysed, and again, the larger the size of the network, the better the results. The results are promising for use in IVR systems, with the best systems achieving a gender identification error of less than 2% and a classification error by age group of less than 20%.
C1 [Sanchez-Hevia, Hector A.; Gil-Pita, Roberto; Utrilla-Manso, Manuel; Rosa-Zurera, Manuel] Univ Alcala, Signal Theory & Commun Dept, Madrid, Spain.
C3 Universidad de Alcala
RP Rosa-Zurera, M (corresponding author), Univ Alcala, Signal Theory & Commun Dept, Madrid, Spain.
EM hectoradrian.sanchez@uah.es; roberto.gil@uah.es; manuel.utrilla@uah.es;
   manuel.rosa@uah.es
RI Gil-Pita, Roberto/N-3748-2014; Utrilla-Manso, Manuel/H-5645-2015;
   Sánchez-Hevia, Héctor Adrián A/H-6420-2015; Rosa-Zurera,
   Manuel/L-3644-2014
OI Rosa-Zurera, Manuel/0000-0002-3073-3278
FU CRUE-CSIC; Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature.
CR Abadi, 2015, TENSORFLOW LARGE SCA
   Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   [Anonymous], 2007, 2007 IEEE INT C AC S
   Badshah AM, 2017, 2017 INTERNATIONAL CONFERENCE ON PLATFORM TECHNOLOGY AND SERVICE (PLATCON), P125
   Bahari MH, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P506
   Bhat C, 2013, 2013 INTERNATIONAL CONFERENCE ON HUMAN COMPUTER INTERACTIONS (ICHCI)
   Cakir E, 2017, EUR SIGNAL PR CONF, P1744, DOI 10.23919/EUSIPCO.2017.8081508
   Chen JL, 2019, RELIAB ENG SYST SAFE, V185, P372, DOI 10.1016/j.ress.2019.01.006
   Cho K., 2014, ARXIV14061078
   Chollet F, 2015, KERAS
   Couper M.P., 2004, J OFF STAT, V20, P551
   Devillers L, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P801
   Gao YJ, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1342, DOI 10.1145/3368089.3417050
   Ghahremani P, 2018, INTERSPEECH, P277, DOI 10.21437/Interspeech.2018-2015
   Gorin AL, 1997, SPEECH COMMUN, V23, P113, DOI 10.1016/S0167-6393(97)00040-X
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang J, 2017, MULTIMED TOOLS APPL, V76, P20231, DOI 10.1007/s11042-017-4646-5
   Ilyas M, 2020, MULTIMED TOOLS APPL, V79, P21603, DOI 10.1007/s11042-020-08843-4
   Kalluri SB, 2019, INT CONF ACOUST SPEE, P6580, DOI 10.1109/ICASSP.2019.8683397
   Lea C, 2016, LECT NOTES COMPUT SC, V9915, P47, DOI 10.1007/978-3-319-49409-8_7
   Markitantov M, 2019, LECT NOTES ARTIF INT, V11658, P327, DOI 10.1007/978-3-030-26061-3_34
   Mehrbod N, 2018, INT ICE CONF ENG
   Minematsu N, 2002, INT CONF ACOUST SPEE, P137
   Mohino-Herranz I, 2018, 145 CONV AUD ENG SOC, P10090
   Mubarak E, 2020, P 2020 INT C INF COM, P739
   Neumann M, 2017, INTERSPEECH, P1263, DOI 10.21437/Interspeech.2017-917
   Pandey A, 2019, INT CONF ACOUST SPEE, P6875, DOI [10.1109/ICASSP.2019.8683634, 10.1109/icassp.2019.8683634]
   Pappas D, 2015, INT CONF COGN INFO, P139, DOI 10.1109/CogInfoCom.2015.7390579
   Park SR, 2017, INTERSPEECH, P1993, DOI 10.21437/Interspeech.2017-1465
   Pitts Walter, 1947, BULL MATH BIOPHYS, V9, P127, DOI 10.1007/BF02478291
   Ranjan S, 2017, INTERSPEECH, P1009, DOI 10.21437/Interspeech.2017-1182
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sanchez-Hevia H, 2019, 2019 SIGN PROC S KRA, P246
   Sanchez-Hevia H. A., 2020, WORKSHOP PHYS AGENTS, P332
   Sengupta S, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105596
   Singh R., 2016, Braced Resilience Intel, V6, P1
   Tsang K, 2020, TORONTO WORKING PAPE, V42, P1
   Vidrascu L, 2005, LECT NOTES COMPUT SC, V3784, P739
   Wang M, 2010, ADV EC BUSINESS MANA, V159, P577
   Xu Y, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P121, DOI 10.1109/ICASSP.2018.8461975
   Zazo R, 2018, IEEE ACCESS, V6, P22524, DOI 10.1109/ACCESS.2018.2816163
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
NR 43
TC 8
Z9 8
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3535
EP 3552
DI 10.1007/s11042-021-11614-4
EA JAN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000742319000004
OA hybrid
DA 2024-07-18
ER

PT J
AU Gao, XH
AF Gao, Xiaohong
TI A nonlinear prediction model for Chinese speech signal based on RBF
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chinese speech signal; Nonlinear theory; Prediction model; Radical basis
   function neural network
ID CHAOTIC TIME-SERIES; EMBEDDING DIMENSION; PARAMETERS; DYNAMICS
AB A novel method for Chinese speech time series prediction model is proposed. In order to reconstruct the phase space of Chinese speech signal, the delay time and embedding dimension are calculated by C-C method and false nearest neighbor algorithm. The maximum lyapunov exponent and correlation dimension of Chinese speech phoneme are calculated by wolf algorithm and genetic programming algorithm. The numerical results show that there exists nonlinear characteristics in Chinese speech signal. Based on the analysis method of RBF neural network and the nonlinear characteristic parameters such as the delay time and embedding dimension, a nonlinear prediction model is designed. In order to further verify the prediction performance of the designed prediction model, waveform comparison and four evaluation indexes are used. It is shown that compared with the linear prediction model and back propagation neural network nonlinear prediction model, prediction error of the RBF neural network nonlinear prediction model is significantly reduced, and the model has higher prediction accuracy and prediction performance.
C1 [Gao, Xiaohong] Longdong Univ, Sch Elect Engn, Qingyang, Gansu, Peoples R China.
C3 Longdong University
RP Gao, XH (corresponding author), Longdong Univ, Sch Elect Engn, Qingyang, Gansu, Peoples R China.
EM gaoxh0219@126.com
FU National Natural Science Foundation of China (NSFC) [11847163]; Gansu
   education department project [2021B-27]; Qingyang science and technology
   planning project [QY2021A-G004]
FX This work reported in this paper was supported by the National Natural
   Science Foundation of China (NSFC) under Grant 11847163, in part by the
   Gansu education department project under Grant 2021B-27 and the Qingyang
   science and technology planning project under Grant QY2021A-G004. The
   author thanks the referees for their valuable suggestions and comments.
CR Al-Jumeily D., 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9226, P654, DOI 10.1007/978-3-319-22186-1_65
   BARNA G, 1993, PHYS LETT A, V175, P421, DOI 10.1016/0375-9601(93)90994-B
   BUZUG T, 1992, PHYSICA D, V58, P127, DOI 10.1016/0167-2789(92)90104-U
   Cao LY, 1997, PHYSICA D, V110, P43, DOI 10.1016/S0167-2789(97)00118-8
   Dahmani M, 2019, J INFORM OPTIM SCI, V40, P1307, DOI 10.1080/02522667.2018.1499600
   Datta AK., 2018, TIME DOMAIN REPRESEN, P131, DOI [10.1007/978-981-13-2303-4_7, DOI 10.1007/978-981-13-2303-4_7]
   Dutt, 2013, P INT C VLSI COMM AD, V258, P343
   GRASSBERGER P, 1983, PHYSICA D, V9, P189, DOI 10.1016/0167-2789(83)90298-1
   Handa A, 2020, MULTIMED TOOLS APPL, V79, P20461, DOI 10.1007/s11042-020-08837-2
   Hanilçi C, 2018, MULTIMED TOOLS APPL, V77, P16099, DOI 10.1007/s11042-017-5181-0
   Hermassi H, 2017, MULTIMED TOOLS APPL, V76, P1177, DOI 10.1007/s11042-015-3030-6
   Hou L., 2005, THESIS SHANGHAI U SH
   Hu Shuiqing, 2000, Acta Acustica, V25, P329
   Jiang JJ, 2003, J ACOUST SOC AM, V114, P2198, DOI 10.1121/1.1610462
   KENNEL MB, 1992, PHYS REV A, V45, P3403, DOI 10.1103/PhysRevA.45.3403
   Kim HS, 1999, PHYSICA D, V127, P48, DOI 10.1016/S0167-2789(98)00240-1
   Kokkinos I, 2005, IEEE T SPEECH AUDI P, V13, P1098, DOI 10.1109/TSA.2005.852982
   Kugiumtzis D, 1996, PHYSICA D, V95, P13, DOI 10.1016/0167-2789(96)00054-1
   Kumar A, 1996, J ACOUST SOC AM, V100, P615, DOI 10.1121/1.415886
   Lin TN, 1996, IEEE T NEURAL NETWOR, V7, P1329, DOI 10.1109/72.548162
   Lin WJ, 1999, SIGNAL PROCESS, V78, P201, DOI 10.1016/S0165-1684(99)00060-2
   Liu Y, 2001, SIGNAL PROCESS, V17, P322
   NARAYANAN SS, 1995, J ACOUST SOC AM, V97, P2511, DOI 10.1121/1.411971
   Qin Ai-na, 2008, Computer Engineering and Applications, V44, P141
   Sun Ying, 2015, Journal of Tianjin University, V48, P681, DOI 10.11784/tdxbz201507039
   Takens F, 1981, Lecture Notes in Mathematics, V898, P366, DOI [10.1007/BFb0091924, DOI 10.1007/BFB0091924]
   THYSSEN J, 1994, INT CONF ACOUST SPEE, P185
   Tuller B, 2010, STUD COMPUT INTELL, V328, P135
   Wang FN, 2015, MULTIMED TOOLS APPL, V74, P9983, DOI 10.1007/s11042-014-2319-1
   Wang Y.F., 2000, CHIN J PREV VET MED, V1, P61
   WOLF A, 1985, PHYSICA D, V16, P285, DOI 10.1016/0167-2789(85)90011-9
   Xie XF, 2002, IEEE C EVOL COMPUTAT, P1456
   Yang L, 2016, APPL SOFT COMPUT, V38, P754, DOI 10.1016/j.asoc.2015.10.003
NR 33
TC 3
Z9 3
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5033
EP 5049
DI 10.1007/s11042-021-11612-6
EA JAN 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000740429700007
DA 2024-07-18
ER

PT J
AU Liu, XJ
   Li, KL
   Luan, HY
   Wang, WH
   Chen, ZY
AF Liu, Xue-Jun
   Li, Kai-li
   Luan, Hai-ying
   Wang, Wen-hui
   Chen, Zhao-yu
TI Few-shot learning for skin lesion image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Small sample learning; Relational network; Metric
   learning; Convolutional neural network
AB The mortality of skin pigmented malignant lesions is very high, especially melanoma. Due to the limitation of marking means, the large-scale annotation data of skin lesions are generally more difficult to obtain. When the deep learning model is trained on a small dataset, its generalization performance is limited. Using prior knowledge to expand small sample data is a general model method of learning classification, which is difficult to deal with complex skin problems. On the basis of a small amount of labeled skin lesion image data, this paper uses the improved Relational Network for measurement learning to realize the classification of skin disease. This method uses relative position network (RPN) and relative mapping network (RMN), in which RPN captures and extracts feature information by attention mechanism, and RMN obtains the similarity of image classification by weighted sum of attention mapping distance. The average accuracy of classification is 85% on the public ISIC melanoma dataset, and the results show the effectiveness and applicability of the method.
C1 [Liu, Xue-Jun; Li, Kai-li; Wang, Wen-hui; Chen, Zhao-yu] Beijing Inst Petrochem Technol, Sch Informat Engn, Beijing 102617, Peoples R China.
   [Luan, Hai-ying] Beijing Res Inst Automat Machinery Ind Co Ltd, Fluid Power & Automot Equipment Ctr, Beijing 100120, Peoples R China.
C3 Beijing Institute of Petrochemical Technology
RP Liu, XJ (corresponding author), Beijing Inst Petrochem Technol, Sch Informat Engn, Beijing 102617, Peoples R China.
EM lxj@bipt.edu.cn
CR [Anonymous], 2018, SIGNAL PROCESS, P145
   Bertinetto Luca, 2018, P INT C LEARN REPR
   Bossuyt PM, 2015, BMJ-BRIT MED J, V351, DOI [10.1373/clinchem.2015.246280, 10.1136/bmj.h5527, 10.1148/radiol.2015151516]
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Dulmage B, 2020, J INVEST DERMATOL, V141, P1230, DOI 10.1016/j.jid.2020.08.027
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fan YL, 2020, SIGNAL IMAGE VIDEO P, V14, P455, DOI 10.1007/s11760-019-01574-6
   Jeddi Fatemeh Rangraz, 2016, Acta Inform Med, V24, P30, DOI 10.5455/aim.2016.24.30-33
   Kawahara J, 2016, I S BIOMED IMAGING, P1397, DOI 10.1109/ISBI.2016.7493528
   Liu XQ, 2020, NEUROCOMPUTING, V383, P224, DOI 10.1016/j.neucom.2019.12.034
   Malla S, 2021, APPL SOFT COMPUT, V107, DOI 10.1016/j.asoc.2021.107495
   Menegola A, 2017, I S BIOMED IMAGING, P297, DOI 10.1109/ISBI.2017.7950523
   Snell J, 2017, ADV NEUR IN, V30
   Sousa AFM, 2016, NEUROCOMPUTING, V194, P45, DOI 10.1016/j.neucom.2016.02.007
   Sun XX, 2016, LECT NOTES COMPUT SC, V9910, P206, DOI 10.1007/978-3-319-46466-4_13
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Valle E, 2020, NEUROCOMPUTING, V383, P303, DOI 10.1016/j.neucom.2019.12.003
   Xu CY, 2020, IEEE T INF FOREN SEC, V15, P3540, DOI 10.1109/TIFS.2020.2991876
   Xu Z., 2020, J PHYS, V1631
   Xue ZY, 2020, IEEE COMPUT SOC CONF, P4032, DOI 10.1109/CVPRW50498.2020.00474
   Yosinski J, 2014, ADV NEUR IN, V27
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhong ZS, 2019, NEURAL NETWORKS, V110, P104, DOI 10.1016/j.neunet.2018.10.016
   Zhou Y, 2016, EXPERT SYST APPL, V55, P361, DOI 10.1016/j.eswa.2016.02.011
NR 25
TC 11
Z9 11
U1 5
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 4979
EP 4990
DI 10.1007/s11042-021-11472-0
EA JAN 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000740429700038
DA 2024-07-18
ER

PT J
AU Senalp, FM
   Ceylan, M
AF Senalp, Fatih Mehmet
   Ceylan, Murat
TI Effects of the deep learning-based super-resolution method on thermal
   image classification applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Thermal imaging; Super-resolution; Deep learning; Data sets;
   Classification
AB Thermal imaging can be used in many sectors such as public security, health, and defense in image processing. However, thermal imaging systems are very costly, limiting their use, especially in the medical field. Also, thermal camera systems obtain blurry images with low levels of detail. Therefore, the need to improve their resolution has arisen. Here, super-resolution techniques can be a solution. Developments in deep learning in recent years have increased the success of super-resolution (SR) applications. This study proposes a new deep learning-based approach TSRGAN model for SR applications performed on a new dataset consisting of thermal images of premature babies. This dataset was created by downscaling the thermal images (ground truth) of premature babies as traditional SR studies. Thus, a dataset consisting of high-resolution (HR) and low-resolution (LR) thermal images were obtained. SR images created due to the applications were compared with LR, bicubic interpolation images, and obtained SR images using state-of-the-art models. The success of the results was evaluated using image quality metrics of peak signal to noise ratio (PSNR) and structural similarity index measure (SSIM). The results show that the proposed model achieved the second-best PSNR value and the best SSIM value. Additionally, a CNN-based classifier model was developed to perform task-based evaluation, and classification applications were carried out separately on LR, HR, and reconstructed SR image sets. Here, the success of classifying unhealthy and healthy babies was compared. This study showed that the classification accuracy of SR images increased by approximately 5% compared to the classification accuracy of LR images. In addition, the classification accuracy of SR thermal images approached the classification accuracy of HR thermal images by about 2%. Therefore, with the approach proposed in this study, it has been proven that LR thermal images can be used in classification applications by increasing their resolution. Thus, widespread use of thermal imaging systems with lower costs in the medical field will be achieved.
C1 [Senalp, Fatih Mehmet; Ceylan, Murat] Konya Tech Univ, Dept Elect Elect Engn, Konya, Turkey.
C3 Konya Technical University
RP Senalp, FM (corresponding author), Konya Tech Univ, Dept Elect Elect Engn, Konya, Turkey.
EM fatih.senalp@gmail.com; mceylan@ktun.edu.tr
OI Senalp, Fatih Mehmet/0000-0001-7831-6724
FU Scientific Research Projects Coordinatorship of Konya Technical
   University [201102001]; Scientific and Technological Research Council of
   Turkey (TUBITAK) [215E019]
FX This project is financially supported by the Scientific Research
   Projects Coordinatorship of Konya Technical University (Project Number:
   201102001).; The thermal images used in this study were obtained in
   project studies supported by the Scientific and Technological Research
   Council of Turkey (TUBITAK, Project Number: 215E019).
CR Achanta SDM, 2019, INT J INTELL UNMANNE, V8, P43, DOI 10.1108/IJIUS-01-2019-0005
   Achanta SDM, 2019, SOFT COMPUT, V23, P8359, DOI 10.1007/s00500-019-04108-x
   Anwar S, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3390462
   Choi Y, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P223, DOI 10.1109/IROS.2016.7759059
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Chudasama V, 2020, IEEE COMPUT SOC CONF, P388, DOI 10.1109/CVPRW50498.2020.00051
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong WS, 2016, IEEE T IMAGE PROCESS, V25, P2337, DOI 10.1109/TIP.2016.2542360
   Dosovitskiy A., 2016, Advances in Neural Information Processing Systems, P658
   Du WX, 2020, IEEE T INSTRUM MEAS, V69, P3566, DOI 10.1109/TIM.2019.2932175
   Fan ZL, 2018, NEUROCOMPUTING, V272, P396, DOI 10.1016/j.neucom.2017.07.017
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu YC, 2020, MULTIMED TOOLS APPL, V79, P21815, DOI 10.1007/s11042-020-08980-w
   Guei AC, 2018, APPL OPTICS, V57, pD98, DOI 10.1364/AO.57.000D98
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZW, 2019, IEEE T CIRC SYST VID, V29, P2310, DOI 10.1109/TCSVT.2018.2864777
   Hwang S, 2015, PROC CVPR IEEE, P1037, DOI 10.1109/CVPR.2015.7298706
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Javaid H., 2013, THESIS BLEKINGE I TE
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Nguyen K, 2013, COMPUT VIS IMAGE UND, V117, P1526, DOI 10.1016/j.cviu.2013.06.010
   Lai ZF, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/2061516
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee K, 2017, IEEE ACCESS, V5, P26867, DOI 10.1109/ACCESS.2017.2769687
   Li JC, 2018, LECT NOTES COMPUT SC, V11212, P527, DOI 10.1007/978-3-030-01237-3_32
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu SW, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2019), P1004, DOI [10.1109/SIPROCESS.2019.8868566, 10.1109/siprocess.2019.8868566]
   Loussaief Sehla, 2016, 2016 7th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT), P58, DOI 10.1109/SETIT.2016.7939841
   Mandanici E, 2019, APPL GEOMAT, V11, P215, DOI 10.1007/s12518-019-00253-y
   Miranda E, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND TECHNOLOGY (ICIMTECH), P56, DOI 10.1109/ICIMTech.2016.7930302
   Ornek AH, 2019, INFRARED PHYS TECHN, V103, DOI 10.1016/j.infrared.2019.103044
   Park SJ, 2018, LECT NOTES COMPUT SC, V11220, P455, DOI 10.1007/978-3-030-01270-0_27
   Radford A., 2015, ARXIV
   Rivadeneira RE, 2020, VISAPP: PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4: VISAPP, P111, DOI 10.5220/0009173601110119
   Rivadeneira RE, 2019, LECT NOTES COMPUT SC, V11663, P417, DOI 10.1007/978-3-030-27272-2_37
   Savasci D., 2020, INT J INTELL SYST AP, V8, P28, DOI [10.18201/ijisae.2020158886, DOI 10.18201/IJISAE.2020158886]
   Senalp FM., 2020, EUR J SCI TECHNOL, P131, DOI [10.31590/ejosat.802174, DOI 10.31590/EJOSAT.802174]
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh K, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.4.043015
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Toyran M., 2008, THESIS I SCI ISTANBU
   Wang MX, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01073-6
   Xin MY, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0417-8
   Yue LW, 2016, SIGNAL PROCESS, V128, P389, DOI 10.1016/j.sigpro.2016.05.002
   Zhang XD, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082587
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 49
TC 4
Z9 4
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9313
EP 9330
DI 10.1007/s11042-021-11436-4
EA JAN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000740429700008
DA 2024-07-18
ER

PT J
AU Zhou, Y
   Liu, K
   Dou, QY
   Liu, ZT
   Jeon, G
   Yang, XM
AF Zhou, Yang
   Liu, Kai
   Dou, Qingyu
   Liu, Zitao
   Jeon, Gwanggil
   Yang, Xiaomin
TI LNMF: lightweight network for multi-focus image fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial Intelligence; Image fusion; Multi-focus fusion; Lightweight
   network
AB Due to limitations of the optical lenses, using the digital single-lens camera to obtain an all-in-focus image is difficult. In order to overcome this difficulty, a lot of multi-focus image fusion methods have been proposed to produce all-in-focus images. With the development of Deep Learning (DL), the Convolutional Neural Networks (CNNs) have been successfully applied to image fusion. Currently proposed DL-based multi-focus fusion methods use deeper and wider networks to obtain better fusion results. However, due to the large computational complexity and memory consumption of standard convolution operations and deeper networks, these methods are unable to be applied to small devices. To address this issue, we propose a novel multi-focus image fusion method using a lightweight network. In this paper, we convert the fusion problem into a classification problem firstly. Then, using a lightweight network to classify focus and defocus areas of source images. Finally, focus areas are fused to obtain an all-in-focus image. The proposed lightweight network reduces operation complexity and memory consumption while achieving good fusion effects. The experimental results demonstrate that the proposed method with fewer parameters and computational costs has a better performance on quality and quantitative evaluations than other state-of-the-art methods.
C1 [Zhou, Yang; Yang, Xiaomin] Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Sichuan, Peoples R China.
   [Liu, Kai] Sichuan Univ, Coll Elect Engn, Chengdu 610065, Sichuan, Peoples R China.
   [Dou, Qingyu] Sichuan Univ, West China Hosp, Ctr Gerontol & Geriatr, Chengdu, Peoples R China.
   [Liu, Zitao] TAL Educ Grp NYSE TAL, Beijing, Peoples R China.
   [Jeon, Gwanggil] Incheon Natl Univ, Dept Embedded Syst Engn, Incheon 22012, South Korea.
   [Jeon, Gwanggil] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
C3 Sichuan University; Sichuan University; Sichuan University; Incheon
   National University; Xidian University
RP Liu, K (corresponding author), Sichuan Univ, Coll Elect Engn, Chengdu 610065, Sichuan, Peoples R China.
EM kailiu@scu.edu.cn
RI wang, yu/IUQ-6654-2023; Huang, Yu/KDM-9182-2024; chen,
   yanhong/JVE-0289-2024; Liu, Kai/IST-6808-2023; yang, xiao/HJI-7815-2023
FU Science Foundation of Sichuan Science and Technology Department
   [2021YFH0119]; Sichuan University [2020SCUNG205]
FX This work is sponsored by the Science Foundation of Sichuan Science and
   Technology Department (Grant No.2021YFH0119) and the funding from
   Sichuan University (Grant No.2020SCUNG205).
CR Amin-Naji M, 2019, INFORM FUSION, V51, P201, DOI 10.1016/j.inffus.2019.02.003
   Ben Hamza A, 2005, INTEGR COMPUT-AID E, V12, P135
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Wei H, 2007, PATTERN RECOGN LETT, V28, P493, DOI 10.1016/j.patrec.2006.09.005
   Iandola Forrest, 2017, 2017 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS), DOI 10.1145/3125502.3125606
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   MA B, 2019, ARXIV190801703
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Mitianoudis N, 2007, INFORM FUSION, V8, P131, DOI 10.1016/j.inffus.2005.09.001
   Nencini F, 2007, INFORM FUSION, V8, P143, DOI 10.1016/j.inffus.2006.02.001
   Prabhakar KR, 2017, IEEE I CONF COMP VIS, P4724, DOI 10.1109/ICCV.2017.505
   QiangW, 2004, IEEE INSTRUMENTATION
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Stathaki T, 2008, IMAGE FUSION: ALGORITHMS AND APPLICATIONS, P1
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Tang H, 2018, INFORM SCIENCES, V433, P125, DOI 10.1016/j.ins.2017.12.043
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
   Yang C, 2008, INFORM FUSION, V9, P156, DOI 10.1016/j.inffus.2006.09.001
   ZHANG HY, 2018, PROC CVPR IEEE
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zhao HJ, 2013, PATTERN RECOGN, V46, P1002, DOI 10.1016/j.patcog.2012.09.012
   Zheng YF, 2007, INFORM FUSION, V8, P177, DOI 10.1016/j.inffus.2005.04.003
NR 33
TC 0
Z9 1
U1 3
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22335
EP 22353
DI 10.1007/s11042-021-11659-5
EA JAN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000740429700001
DA 2024-07-18
ER

PT J
AU Singh, RS
   Gelmecha, DJ
   Sinha, DK
AF Singh, Ram Sewak
   Gelmecha, Demissie Jobir
   Sinha, D. K.
TI Expert system based detection and classification of coronary artery
   disease using ranking methods and nonlinear attributes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 1-norm extreme learning machine; Generalized discriminant analysis;
   Ranking methods; 1-norm root mean square error; Receiver operating
   characteristic
ID EXTREME LEARNING-MACHINE; LEMPEL-ZIV COMPLEXITY; APPROXIMATE ENTROPY;
   AUTOMATED DIAGNOSIS; HEART; FEATURES; WAVELET; OPTIMIZATION; SELECTION;
   PCA
AB This article presents an automated algorithm which combines ranking method with generalized discriminant analysis (GDA) and 1-norm extreme learning machine (1 - NELM) to detect coronary artery disease (CAD) subject. For detection of CAD, the eleven nonlinear attributes like correlation dimension (CD), poincare plot, multivariate largest Lyapunov exponent (MLLE), hurst exponent (HE), Lempel-Ziv (LZ), sample entropy (SampEn), dispersion entropy (DispEn), improved permutation entropy (IPE), adaptive multiscale PE (AMPE), multifractal detrended fluctuation analysis (MFDFA) and cumulative bi-correlation (CBC) have been retrieved from heart rate variability (HRV) signal. For this analysis, the HRV data have been taken from publicly available database of healthy elderly (ELY), young (YNG) and CAD subjects. The rank of attributes have been calculated using ranking methods such as Fisher, Wilcoxon, Entropy, Bhattacharya, and receiver operating characteristic (ROC). The experiments were carried out numerically through the combination of database sets YNG-ELY, YNG - CAD and ELY - CAD subjects. The numerical results have shown that ROC with GDA and 1 - NELM approach achieved an accuracy of 99.76 +/- 0.14, 99.87 +/- 0.12 and 100 +/- 0 respectivly for YNG - CAD, YNG - ELY and ELY - CAD groups. The Fisher with GDA and 1-NELM; and Bhattacharya with GDA and 1 - NELM approach achieved an accuracy of 100 +/- 0 for all considered datasets. The proposed method also achieved very good generalization performance with the smallest 1-norm root mean square error (RMSE) and less execution validation time as compared to support vector machine (SVM) and probabilistic neural network (PNN).
C1 [Singh, Ram Sewak; Gelmecha, Demissie Jobir] ASTU, Elect & Commun Engn Dept SIG, Sch Elect Engn & Comp, Adama, Ethiopia.
   [Sinha, D. K.] ASTU, Sch Mech Chem & Mat Engn, Mech Design & Mfg Engn Dept, Adama, Ethiopia.
RP Singh, RS (corresponding author), ASTU, Elect & Commun Engn Dept SIG, Sch Elect Engn & Comp, Adama, Ethiopia.
EM reamsewak_coer2004@yahoo.com; demissie.jobir@astu.edu.et
RI Gelmecha, Demissie/ABB-8141-2020
OI Gelmecha, Demissie/0000-0002-7948-8285
CR Aboy M, 2006, IEEE T BIO-MED ENG, V53, P2282, DOI 10.1109/TBME.2006.883696
   Acharya R, 2004, PHYSIOL MEAS, V25, P1139, DOI 10.1088/0967-3334/25/5/005
   Alizadehsani R, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103346
   Asl BM, 2008, ARTIF INTELL MED, V44, P51, DOI 10.1016/j.artmed.2008.04.007
   Azami H, 2017, IEEE T BIO-MED ENG, V64, P2872, DOI 10.1109/TBME.2017.2679136
   Azami H, 2016, BIOMED SIGNAL PROCES, V23, P28, DOI 10.1016/j.bspc.2015.08.004
   Babaoglu I, 2010, EXPERT SYST APPL, V37, P3177, DOI 10.1016/j.eswa.2009.09.064
   Babaoglu I, 2010, EXPERT SYST APPL, V37, P2182, DOI 10.1016/j.eswa.2009.07.055
   Balasundaram S, 2014, NEUROCOMPUTING, V128, P4, DOI 10.1016/j.neucom.2013.03.051
   Bartlett PL, 1998, IEEE T INFORM THEORY, V44, P525, DOI 10.1109/18.661502
   Bravi A, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-90
   Butchart A, 2015, INJURY PREV, V21, P213, DOI 10.1136/injuryprev-2015-041640
   Camm AJ, 1996, EUR HEART J, V17, P354
   Castiglioni P, 2018, COMPLEXITY, DOI 10.1155/2018/4801924
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen XP, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10217656
   Costa M, 2002, PHYS REV LETT, V89, DOI 10.1103/PhysRevLett.89.068102
   Costa T, 2009, AUTON NEUROSCI-BASIC, V151, P183, DOI 10.1016/j.autneu.2009.08.011
   Derryberry DR, 2010, J STAT EDUC, V18
   Ding SF, 2015, ARTIF INTELL REV, V44, P103, DOI 10.1007/s10462-013-9405-z
   Djoussé L, 2011, CLIN NUTR, V30, P182, DOI 10.1016/j.clnu.2010.08.005
   Dua S, 2012, J MECH MED BIOL, V12, DOI 10.1142/S0219519412400179
   Fazan FS, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20010047
   Gao ZK, 2015, EPL-EUROPHYS LETT, V109, DOI 10.1209/0295-5075/109/30005
   Giri D, 2013, KNOWL-BASED SYST, V37, P274, DOI 10.1016/j.knosys.2012.08.011
   GRASSBERGER P, 1983, PHYSICA D, V9, P189, DOI 10.1016/0167-2789(83)90298-1
   Gu Q., 2012, ABS12023725 CORR
   Guyon I., 2003, Journal of Machine Learning Research, V3, P1157, DOI 10.1162/153244303322753616
   Huang GB, 2011, INT J MACH LEARN CYB, V2, P107, DOI 10.1007/s13042-011-0019-y
   Huang GB, 2010, NEUROCOMPUTING, V74, P155, DOI 10.1016/j.neucom.2010.02.019
   Janney B, 2020, MULTIMED TOOLS APPL, V79, P3713, DOI 10.1007/s11042-018-6927-z
   Jercic P, 2020, MULTIMED TOOLS APPL, V79, P3145, DOI 10.1007/s11042-018-6518-z
   Kalpana R, 2015, ASIAN J MED SCI, V7, P41
   Kamen PW, 1996, CLIN SCI, V91, P201, DOI 10.1042/cs0910201
   Kampouraki A, 2009, IEEE T INF TECHNOL B, V13, P512, DOI 10.1109/TITB.2008.2003323
   Kantelhardt JW, 2002, PHYSICA A, V316, P87, DOI 10.1016/S0378-4371(02)01383-3
   Karimi M., 2005, 3rd IEE International Seminar on Medical Applications of Signal Processing, P117, DOI 10.1049/ic:20050342
   Krithiga RR, 2020, MULTIMED TOOLS APPL, V79, P3761, DOI 10.1007/s11042-018-7045-7
   Kugiumtzis D, 2010, J STAT SOFTW, V33, P1
   Kumar M, 2016, EXPERT SYST APPL, V63, P165, DOI 10.1016/j.eswa.2016.06.038
   LEMPEL A, 1976, IEEE T INFORM THEORY, V22, P75, DOI 10.1109/TIT.1976.1055501
   Liu K, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/309756
   Mangasarian OL, 2006, J MACH LEARN RES, V7, P1517
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Nagarajan R, 2002, IEEE T BIO-MED ENG, V49, P1371, DOI 10.1109/TBME.2002.804582
   PINCUS SM, 1991, P NATL ACAD SCI USA, V88, P2297, DOI 10.1073/pnas.88.6.2297
   Poddar Monappa Gundappa, 2015, Journal of Medical Engineering & Technology, V39, P331, DOI 10.3109/03091902.2015.1063721
   Praveena D, 2020, MULTIMED TOOLS APPL, V79, P5161, DOI 10.1007/s11042-018-6339-0
   Raghu PP, 1998, IEEE T NEURAL NETWOR, V9, P516, DOI 10.1109/72.668893
   Rao CR., 1972, P 6 BERK S MATH STAT, P601, DOI DOI 10.2307/1266840
   Richman JS, 2000, AM J PHYSIOL-HEART C, V278, pH2039
   Saeidi R, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481420
   Saxena S., 2019, INT J INNOV TECHNOL, V8, P851
   Singh RS, 2018, INT J MULTISCALE COM, V16, P465, DOI 10.1615/IntJMultCompEng.2018026587
   Wei HL, 2007, IEEE T PATTERN ANAL, V29, P162, DOI 10.1109/TPAMI.2007.250607
   Yan RQ, 2012, MECH SYST SIGNAL PR, V29, P474, DOI 10.1016/j.ymssp.2011.11.022
   Yue W., 2018, DESIGNS, V2, P13, DOI [10.3390/designs2020013, DOI 10.3390/DESIGNS2020013]
NR 57
TC 3
Z9 3
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19723
EP 19750
DI 10.1007/s11042-021-11528-1
EA JAN 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000739790800005
DA 2024-07-18
ER

PT J
AU Tripathi, PM
   Kumar, A
   Komaragiri, R
   Kumar, M
AF Tripathi, Prashant Mani
   Kumar, Ashish
   Komaragiri, Rama
   Kumar, Manjeet
TI Watermarking of ECG signals compressed using Fourier decomposition
   method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electrocardiogram; Watermarking; Compression; Fourier decomposition
   method
ID DISCRETE COSINE TRANSFORM; QRS COMPLEX DETECTOR; QUANTIZATION; DATABASE
AB Secure and efficient transmission of biomedical signals containing delicate and vital health information of a subject over the network is challenging. Digital watermarking is an attractive choice for the secure and reliable transmission of biomedical signals using smart healthcare devices. This paper proposes a method that integrates watermarking and compression of an electrocardiogram (ECG) of a subject. ECG watermarking secures the cardiac information of a subject, while signal compression reduces the amount of data. In this study, a sequence of binary ones and zeros are used as a watermark to secure the ECG signal. The watermarked ECG signal is analyzed and compressed by the Fourier decomposition method by removing the redundant component present in the ECG signal. The proposed method is validated using the MIT-BIH arrhythmia database. Percentage root-mean-square difference (PRD), the output signal to noise ratio (SNR), compression ratio, and computation time are used to evaluate the performance of the proposed method. Results show that the proposed method reduces the PRD by a factor of three, and the compression ratio increases by a factor of two. The proposed algorithm is evaluated at different input SNR values. The improved output SNR demonstrates the denoising capabilities of the watermarked signal.
C1 [Tripathi, Prashant Mani; Komaragiri, Rama] Bennett Univ, Dept Elect & Commun Engn, Greater Noida, India.
   [Kumar, Ashish] Vellore Inst Technol, Sch Elect Engn, Chennai, Tamil Nadu, India.
   [Kumar, Manjeet] Delhi Technol Univ, Dept Elect & Commun Engn, Delhi, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai; Delhi Technological
   University
RP Kumar, M (corresponding author), Delhi Technol Univ, Dept Elect & Commun Engn, Delhi, India.
EM pmanitripathi@gmail.com; akumar.1june@gmail.com;
   rama.komaragiri@gmail.com; manjeetchhillar@gmail.com
RI Kumar, Manjeet/K-1325-2015; Tripathi, Prashant Mani/IAP-7773-2023
OI Kumar, Manjeet/0000-0001-6578-9741; Tripathi, Prashant
   Mani/0000-0002-8960-8260
CR Act A, 1996, PUBLIC LAW, V104, P191, DOI 10.4135/9781452234243.n359
   Ajdaraga E, 2017, 2017 25TH TELECOMMUNICATION FORUM (TELFOR), P685
   ALNASHASH HAM, 1995, MED ENG PHYS, V17, P197, DOI 10.1016/1350-4533(95)95710-R
   *AM HEART ASS, AHA DAT
   Averkiou, 2015, DIGITAL WATERMARKING
   Batista LV, 2001, MED ENG PHYS, V23, P127, DOI 10.1016/S1350-4533(01)00030-3
   Bousseljot R., 1995, INTERNET, V40, P317, DOI [DOI 10.1515/BMTE.1995.40.S1.317, 10.1515/bmte.1995.40.s1.317]
   Camm AJ, 1996, CIRCULATION, V93, P1043
   Chin WL, 2019, IEEE INTERNET THINGS, V6, P5540, DOI 10.1109/JIOT.2019.2903530
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   El B'charri O, 2016, INT J ADV COMPUT SC, V7, P181
   Fathi A, 2016, SIGNAL IMAGE VIDEO P, V10, P1433, DOI 10.1007/s11760-016-0944-z
   Fatimah B, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.102005
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Gutiérrez-Rivas R, 2015, IEEE SENS J, V15, P6036, DOI 10.1109/JSEN.2015.2450773
   Hammad M, 2018, MEASUREMENT, V125, P634, DOI 10.1016/j.measurement.2018.05.033
   Hao H, 2017, IEICE T FUND ELECTR, VE100A, P769, DOI 10.1587/transfun.E100.A.769
   Iyengar N, 1996, AM J PHYSIOL-REG I, V271, pR1078, DOI 10.1152/ajpregu.1996.271.4.R1078
   JALALEDDINE SMS, 1990, IEEE T BIO-MED ENG, V37, P329, DOI 10.1109/10.52340
   Jero SE, 2015, BIOMED SIGNAL PROCES, V22, P161, DOI 10.1016/j.bspc.2015.07.004
   Jero SE, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0132-z
   Kaur Suneet, 2010, Proceedings of the 2010 International Conference on Recent Trends in Information, Telecommunication and Computing (ITC 2010), P140, DOI 10.1109/ITC.2010.96
   Kirovski D, 2003, IEEE T SIGNAL PROCES, V51, P1020, DOI 10.1109/TSP.2003.809384
   Kumar A., 2021, Res. Biomed. Eng, V37, P79, DOI [10.1007/s42600-020-00108-1, DOI 10.1007/S42600-020-00108-1]
   Kumar A, 2021, ISA T, V114, P251, DOI 10.1016/j.isatra.2020.12.029
   Kumar A, 2019, BIOMED ENG LETT, V9, P407, DOI 10.1007/s13534-019-00117-9
   Kumar A, 2019, INT J CIRC THEOR APP, V47, P1459, DOI 10.1002/cta.2667
   Kumar A, 2018, J MED SYST, V42, DOI [10.1007/s10916-017-0886-1, 10.1515/joc-2018-0071]
   Laguna P, 1997, COMPUT CARDIOL, V24, P673, DOI 10.1109/CIC.1997.648140
   Lee W, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041005
   Manikandan MS, 2014, BIOMED SIGNAL PROCES, V14, P73, DOI 10.1016/j.bspc.2014.07.002
   Marcel S, 2007, IEEE T PATTERN ANAL, V29, P743, DOI 10.1109/TPAMI.2007.1012
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Olmos S, 1996, COMPUT CARDIOL, P253, DOI 10.1109/CIC.1996.542521
   Pandey A, 2016, AUSTRALAS PHYS ENG S, V39, P833, DOI 10.1007/s13246-016-0476-4
   Rhee M.Y., 2003, Internet Security: Cryptographic Principles, Algorithms and Protocols
   Sanivarapu PV, 2020, PHYS ENG SCI MED, V43, P213, DOI 10.1007/s13246-019-00838-2
   Sellami A, 2017, 2017 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING - BOUMERDES (ICEE-B)
   Singh P, 2017, P ROY SOC A-MATH PHY, V473, DOI 10.1098/rspa.2016.0871
   Singhal A, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101741
   TADDEI A, 1992, EUR HEART J, V13, P1164, DOI 10.1093/oxfordjournals.eurheartj.a060332
   Tseng KK, 2014, SENSORS-BASEL, V14, P3721, DOI 10.3390/s140203721
   Zhang B, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182500
   Zou DK, 2006, IEEE T CIRC SYST VID, V16, P1294, DOI 10.1109/TCSVT.2006.881857
NR 44
TC 7
Z9 7
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19543
EP 19557
DI 10.1007/s11042-021-11492-w
EA JAN 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000737099300002
DA 2024-07-18
ER

PT J
AU Tseng, SS
   Chen, SN
   Yang, TY
AF Tseng, Shian-Shyong
   Chen, Shih-Nung
   Yang, Tsung-Yu
TI Building an AR-based smart campus platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive context-aware ubiquitous learning; Internet of things (IoT);
   Augmented reality (AR); Case-based reasoning (CBR); Smart campus;
   Ontology
ID INTERNET
AB With the fast development of artificial intelligence (AI) and Internet of Things (IoT) technologies, we have developed a ubiquitous learning environment. Therefore, the rich learning content can be retrieved and demonstrated according to the learners' requirements and the context information. To provide an adaptive context-aware ubiquitous learning service of a smart campus, our idea is to combine GPS, sensors and augmented reality (AR) technologies with ubiquitous learning applications to provide multi-disciplinary learning. Therefore, the students can immerse themselves in learning anytime, anywhere. In this study, we firstly show the architecture of the AR-based smart campus platform, and then propose a campus course ontology building algorithm to construct a campus course ontology. Based upon the ontology and the deployed sensors, teachers can design AR-based learning content for points of interest. This study also enhances the case-based reasoning (CBR) approach to enhance the students' problem solving abilities and facilitate the development of a campus by utilizing domain knowledge and previous user experience. This study proposes four similarity functions for similarity-based case reasoning and knowledge discovery. The proposed methodology can be easily evolved according to either new cases or the feedback to increase the case database, improve reasoning quality, and evolve the similarity measures. Using our platform in the smart campus, students can obtain adaptive learning content according to the requirements and their own characteristics.
C1 [Tseng, Shian-Shyong] Asia Univ, Dept M Commerce & Multimedia Applicat, Taichung, Taiwan.
   [Chen, Shih-Nung] Asia Univ, Dept Informat Commun, Taichung, Taiwan.
   [Yang, Tsung-Yu] Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
C3 Asia University Taiwan; Asia University Taiwan; Asia University Taiwan
RP Chen, SN (corresponding author), Asia Univ, Dept Informat Commun, Taichung, Taiwan.
EM sstseng@asia.edu.tw; nung@asia.edu.tw; zongyu212@gmail.com
FU Ministry of Science and Technology of the Republic of China, Taiwan
   [MOST 109-2511-H-468-001-MY2, MOST 110-2511-H-468006-MY2]; Asia
   University
FX This research was partially supported by the Ministry of Science and
   Technology of the Republic of China, Taiwan, under grants MOST
   109-2511-H-468-001-MY2 and MOST 110-2511-H-468006-MY2. The authors would
   also like to thank Asia University for supporting the teaching/learning
   materials.
CR AAMODT A, 1994, AI COMMUN, V7, P39
   Cárdenas-Robledo LA, 2018, TELEMAT INFORM, V35, P1097, DOI 10.1016/j.tele.2018.01.009
   Alce G, 2019, LECT NOTES COMPUT SC, V11749, P267, DOI 10.1007/978-3-030-29390-1_15
   Arroyo I., 2011, 2011 11th IEEE International Conference on Advanced Learning Technologies (ICALT 2011), P295, DOI 10.1109/ICALT.2011.91
   Badouch A, 2018, ACM INT CONF PR SER, DOI 10.1145/3234698.3234751
   Banks A, 2014, MQTT
   Billinghurst M, 2001, IEEE COMPUT GRAPH, V21, P6, DOI 10.1109/38.920621
   CBR Collaborative, 2020, DES SYST AI
   Chang Y-H., 2013, TURKISH ONLINE J ED, V12, P21
   Chen D-R, 2014, INT J DISTRIB SENSOR
   Chen GD, 2008, COMPUT EDUC, V50, P77, DOI 10.1016/j.compedu.2006.03.004
   Chen S.-N, 2007, International Journal of Computers & Applications, V29, P239, DOI 10.2316/Journal.202.2007.3.202-1770
   Chun SH, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12177124
   Clarke S., 2018, P INT C SERV OR COMP, P149
   Deng SG, 2016, IEEE CLOUD COMPUT, V3, P32, DOI 10.1109/MCC.2016.92
   Finochietto M, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19214801
   Gimenez R, 2010, P W3CWORKSH AUGM REA
   Jo D, 2015, P 21 ACM S VIRTUAL R, P196
   Jo D, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19194330
   Jo D, 2019, HUM-CENT COMPUT INFO, V9, DOI 10.1186/s13673-018-0162-5
   Lee I, 2015, BUS HORIZONS, V58, P431, DOI 10.1016/j.bushor.2015.03.008
   Lee J-H, 2017, ICONFERENCE 2017
   Lee S, 2019, I SYMP CONSUM ELECTR
   Li-Ling Hu, 2018, WSEAS Transactions on Information Science and Applications, V15, P7
   Matsuo K, 2018, 2018 32ND INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA), P203, DOI 10.1109/WAINA.2018.00088
   MISRA J, 1986, COMPUT SURV, V18, P39, DOI 10.1145/6462.6485
   Perera C, 2014, T EMERG TELECOMMUN T, V25, P81, DOI 10.1002/ett.2704
   Phupattanasilp P, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11092658
   Ru Xue, 2011, 2011 Second International Conference on Mechanic Automation and Control Engineering, P7878
   Sethi P, 2017, J ELECTR COMPUT ENG, V2017, DOI 10.1155/2017/9324035
   Shapsough S., 2019, UBIQUITOUS COMPUTING, P53, DOI [10.1007/978-3-030-01566-4_3, DOI 10.1007/978-3-030-01566-4_3]
   Shelby Z., 2014, The Constrained Application Protocol (CoAP), DOI [DOI 10.17487/RFC7252, 10.17487/RFC7252, 10.17487/rfc7252]
   Shian-Shyong Tseng, 2020, Innovative Mobile and Internet Services in Ubiquitous Computing. Proceedings of the 14th International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing (IMIS-2020). Advances in Intelligent Systems and Computing (AISC 1195), P404, DOI 10.1007/978-3-030-50399-4_39
   Shih WC, 2012, EDUC TECHNOL SOC, V15, P90
   Srimathi B., 2017, INT J INTELL ADV RES, V5, P809
   Tseng S-S, 2019, PART ADV INTELLIGENT, V994, P572
   Van Krevelen D. W. F., 2010, Int. J. Virtual Real., V9, P1, DOI [10.20870/IJVR.2010.9.2.2767, DOI 10.20870/IJVR.2010.9.2.2767]
   Zhang H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19091987
   Zualkernan Imran A., 2010, 2010 IEEE 10th International Conference on Advanced Learning Technologies (ICALT 2010), P740, DOI 10.1109/ICALT.2010.216
NR 39
TC 2
Z9 2
U1 4
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5695
EP 5716
DI 10.1007/s11042-021-11702-5
EA DEC 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000735722700003
DA 2024-07-18
ER

PT J
AU Shen, FL
   Lu, ZM
   Lu, ZQ
   Wang, ZH
AF Shen, Fengli
   Lu, Zhe-Ming
   Lu, Ziqian
   Wang, Zonghui
TI Dual semantic-guided model for weakly-supervised zero-shot semantic
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Weakly-supervised zero-shot semantic segmentation; Zero-shot leaning;
   Weakly-supervised semantic segmentation
AB The major obstacle in semantic segmentation is that it requires a large number of pixel-level labeled data to train an effective model. In order to reduce the cost of annotation, weakly-supervised methods use weaker labels to overcome the need for per-pixel labels, while zero-shot methods transfer the knowledge learned from seen classes to unseen classes to reduce the number of classes that need to be labeled. To further alleviate the burden of annotation, we introduce a more challenging task of Weakly-supervised Zero-shot Semantic Segmentation (WZSS): learning models which only utilize image-level annotation of seen classes to segment images containing unseen objects. To this end, we propose a Dual Semantic-Guided (DSG) model which is double guided by semantic embeddings of classes to obtain classification scores and localization maps. By ignoring the localization maps with low classification scores, our proposed framework can generate prediction segmentation masks. To improve our model's performance, we propose a simple stochastic selection on semantic embeddings during inference, which explores the difference between image-level class embeddings and pixel-level class embeddings. This simple approach increases our model's performance in terms of hIoU from 25.9 to 31.8. In addition, compared with some zero-shot semantic segmentation methods, our method delivers better results in terms of hIoU (31.8) and mIoU(u) (22.0) on the PASCAL VOC 2012 dataset with less supervision information.
C1 [Shen, Fengli; Lu, Zhe-Ming; Lu, Ziqian] Zhejiang Univ, Sch Aeronaut & Astronaut, Hangzhou 310027, Peoples R China.
   [Wang, Zonghui] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Lu, ZM (corresponding author), Zhejiang Univ, Sch Aeronaut & Astronaut, Hangzhou 310027, Peoples R China.; Wang, ZH (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.
EM zheminglu@zju.edu.cn; zhwang@zju.edu.cn
FU National Key Research and Development Program of China [2020AAA0140004]
FX This research is supported in part by the National Key Research and
   Development Program of China under Grant No.2020AAA0140004.
CR Ahn J, 2018, PROC CVPR IEEE, P4981, DOI 10.1109/CVPR.2018.00523
   Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   Armand J, 2016, ARXIV PREPRINT ARXIV
   Bearman Amy, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9911, P549, DOI 10.1007/978-3-319-46478-7_34
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Bucher M, 2019, ADV NEUR IN, V32
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen XL, 2015, IEEE I CONF COMP VIS, P1431, DOI 10.1109/ICCV.2015.168
   Ding L, 2020, IEEE T MED IMAGING, P1
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fan JS, 2020, PROC CVPR IEEE, P4282, DOI 10.1109/CVPR42600.2020.00434
   Gu ZX, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1921, DOI 10.1145/3394171.3413593
   Guolei Sun, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P347, DOI 10.1007/978-3-030-58536-5_21
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Khoreva A, 2017, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2017.181
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lapin M, 2018, IEEE T PATTERN ANAL, V40, P1533, DOI 10.1109/TPAMI.2017.2751607
   Lee J, 2019, PROC CVPR IEEE, P5262, DOI 10.1109/CVPR.2019.00541
   Lin D, 2016, PROC CVPR IEEE, P3159, DOI 10.1109/CVPR.2016.344
   Mancini M., 2020, P EUR C COMP VIS, P466, DOI DOI 10.1007/978-3-030-58592
   Mirikharaji Z, 2019, LECT NOTES COMPUT SC, V11795, P207, DOI 10.1007/978-3-030-33391-1_24
   Navarro F, 2018, LECT NOTES COMPUT SC, V11071, P398, DOI 10.1007/978-3-030-00934-2_45
   Rasmus A, 2015, ADV NEUR IN, V28
   Raza H, 2019, IEEE INT CONF COMP V, P1401, DOI 10.1109/ICCVW.2019.00176
   Siam M., 2020, IJCAI, V2020, P860
   Wang Y, 2020, CVPR, V2020
   Xian YQ, 2019, PROC CVPR IEEE, P8248, DOI 10.1109/CVPR.2019.00845
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   YANG K, 2020, INT J ANTENN PROPAG, V2020, P1
   Yu ZD, 2018, LECT NOTES COMPUT SC, V11207, P400, DOI 10.1007/978-3-030-01219-9_24
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106
NR 34
TC 2
Z9 2
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5443
EP 5458
DI 10.1007/s11042-021-11792-1
EA DEC 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000733870800003
DA 2024-07-18
ER

PT J
AU Si, NW
   Zhang, WL
   Qu, D
   Chang, HY
   Zhao, DN
AF Si, Nianwen
   Zhang, Wenlin
   Qu, Dan
   Chang, Heyu
   Zhao, Dongning
TI Fine-grained visual explanations for the convolutional neural network
   via class discriminative deconvolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Visual explanation; Saliency map;
   Grad-CAM; Deconvolution
AB Deep convolution neural networks have been widely studied and applied in many computer vision tasks. However, they are commonly treated as black-boxes and plagued by the inexplicability. In this paper, we propose a novel method to visually interpret the convolutional neural network in the field of image classification. Our method is capable of generating fine-grained and class discriminative heatmap that highlights the important input features contributing to specific predictions. Specifically, through the combination of the modified deconvolution and the pixel-wise Grad-CAM, the fine-grained heatmap and discriminative mask can be fused to achieve fine-grained deconvolution characteristics, and retain the class discriminativeness of the Grad-CAM, enhancing the interpretation effect of the heatmap. Both qualitative and quantitative experiments on ILSVRC 2012 dataset and PASCAL VOC 2012 dataset are conducted. The results indicate that the proposed method achieves a better visual effect with less noise in comparison to the previous methods, especially for visualising small objects in simple contexts. Furthermore, this method can realize a moderately effective performance on weakly supervised instance segmentation tasks, whereas the existing methods only work for weakly supervised object localisation.
C1 [Si, Nianwen; Zhang, Wenlin; Qu, Dan; Chang, Heyu] Informat Engn Univ, Zhengzhou 450001, Peoples R China.
   [Zhao, Dongning] Shenzhen Vetose Technol Co Ltd, Shenzhen 518102, Peoples R China.
C3 PLA Information Engineering University
RP Zhang, WL (corresponding author), Informat Engn Univ, Zhengzhou 450001, Peoples R China.; Zhao, DN (corresponding author), Shenzhen Vetose Technol Co Ltd, Shenzhen 518102, Peoples R China.
EM zwlin_2004@163.com; 582101@qq.com
RI Zhao, Dongning/A-5836-2018
FU National Natural Science Foundation of China [61673395]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61673395). We would like to thank anonymous editors and
   reviewers for their valuable comments on this article.
CR Adebayo J, 2018, ADV NEUR IN, V31
   Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140
   Bojarski Mariusz, 2016, arXiv
   Chattopadhay Aditya, 2018, 2018 IEEE Winter Conference on Applications of Computer Vision (WACV). Proceedings, P839, DOI 10.1109/WACV.2018.00097
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fong RC, 2017, IEEE I CONF COMP VIS, P3449, DOI 10.1109/ICCV.2017.371
   Gu J., 2018, UNDERSTANDING INDIVI, P119
   Gupta Rajiv, 2015, P 19 INT C EV ASS SO, P1
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Iwana BK, 2019, IEEE INT CONF COMP V, P4176, DOI 10.1109/ICCVW.2019.00513
   Kim B, 2019, IEEE INT CONF COMP V, P4149, DOI 10.1109/ICCVW.2019.00510
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   LU XQ, 2021, IEEE T IND INFORM, V17, P1483, DOI DOI 10.1109/TII.2020.2985905
   Marcel S., 2010, P 18 ACM INT C MULTI, P1485, DOI DOI 10.1145/1873951.1874254
   Montavon G, 2017, PATTERN RECOGN, V65, P211, DOI 10.1016/j.patcog.2016.11.008
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Ozbulak U., 2019, PyTorch CNN visualizations
   Paszke Adam, 2017, NIPS W
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Simonyan K., 2014, 14091556 ARXIV
   Simonyan Karen, 2014, WORKSH P INT C LEARN
   Smilkov D., 2017, ARXIV170603825
   Springenberg Jost Tobias, 2015, Striving for simplicity: The all convolutional net, DOI DOI 10.48550/ARXIV.1412.6806
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Sundararajan M, 2017, PR MACH LEARN RES, V70
   Wagner J, 2019, PROC CVPR IEEE, P9089, DOI 10.1109/CVPR.2019.00931
   Wang H, 2020, PROC CVPR IEEE, P3100, DOI 10.1109/CVPR42600.2020.00317
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 31
TC 1
Z9 1
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2733
EP 2756
DI 10.1007/s11042-021-11464-0
EA NOV 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000714321500002
DA 2024-07-18
ER

PT J
AU Barina, D
   Solony, M
   Chlubna, T
   Dlabaja, D
   Klima, O
   Zemcik, P
AF Barina, David
   Solony, Marek
   Chlubna, Tomas
   Dlabaja, Drahomir
   Klima, Ondrej
   Zemcik, Pavel
TI Comparison of light field compression methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 4D light fields; Plenoptic imaging; Compression; Image refocusing; 3D
   Reconstruction
AB In this article, we compare the impact of state-of-the-art light field compression methods. It addresses quality of (a) refocused images and (b) point clouds reconstructed from 4D light field data. The methods include recent video compression formats, specifically H.265, AV1, XVC, and H.266/VVC (finalized in 2020). In addition, we have extended a standard image compression method into four dimensions and compared it with the video compression formats. It turned out that the new VVC format demonstrated superior performance, closely followed by the underrated XVC. Apart from the comparison, we show that the four-dimensional light field data can be compressed with a higher ratio than independent still images while maintaining the same visual quality of a perceived picture.
C1 [Barina, David; Solony, Marek; Chlubna, Tomas; Dlabaja, Drahomir; Klima, Ondrej; Zemcik, Pavel] Brno Univ Technol, Fac Informat Technol, Ctr Excellence IT4 Innovat, Bozetechova 1-2, Brno, Czech Republic.
C3 Brno University of Technology
RP Barina, D (corresponding author), Brno Univ Technol, Fac Informat Technol, Ctr Excellence IT4 Innovat, Bozetechova 1-2, Brno, Czech Republic.
EM ibarina@fit.vutbr.cz; isolony@fit.vutbr.cz; ichlubna@fit.vutbr.cz;
   iklima@fit.vutbr.cz; zemcik@fit.vutbr.cz
RI Klíma, Ondřej/I-4030-2018; Zemcik, Pavel/G-6439-2010; Barina,
   David/A-9035-2015; Chlubna, Tomáš/AAX-5104-2021; Chlubna,
   Tomáš/Y-7496-2018
OI Klíma, Ondřej/0000-0001-9295-065X; Zemcik, Pavel/0000-0001-7969-5877;
   Barina, David/0000-0003-0917-5512; Chlubna, Tomáš/0000-0003-3126-0545
FU Ministry of Education, Youth and Sports of the Czech Republic from the
   National Programme of Sustainability (NPU II) project IT4Innovations
   excellence in science [LQ1602]; Electronic Component Systems for
   European Leadership Joint Undertaking [737475]; European Union's Horizon
   2020 Research and Innovation Programme [780470]; H2020 - Industrial
   Leadership [780470] Funding Source: H2020 - Industrial Leadership
FX This work has been supported by the Ministry of Education, Youth and
   Sports of the Czech Republic from the National Programme of
   Sustainability (NPU II) project IT4Innovations excellence in science
   (LQ1602), the Electronic Component Systems for European Leadership Joint
   Undertaking under grant agreement No 737475, and the European Union's
   Horizon 2020 Research and Innovation Programme under grant agreement No
   780470.
CR Adelson E.H., 1991, Computational Models of Visual Processing, P3
   Akyazi P, 2018, INT WORK QUAL MULTIM, P150
   Alves Gustavo, 2016, 2016 IEEE International Conference on Multimedia & Expo: Workshops (ICMEW), DOI 10.1109/ICMEW.2016.7574774
   Astola P., 2020, ITU J ICT DISCOVERIE, V3, P1, DOI DOI 10.1002/pub/8153d79a-en
   Barina D., 2019, COMPUTER SCI RES N 1, V2901, P55, DOI [10.24132/CSRN.2019.2901.1.7, DOI 10.24132/CSRN.2019.2901.1.7]
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Camahort E., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P117
   Camahort E, 1999, GEOMETRIC STUDY LIGH
   Chen JL, 2020, IEEE T CIRC SYST VID, V30, P1208, DOI 10.1109/TCSVT.2019.2945830
   de Carvalho MB, 2018, IEEE IMAGE PROC, P435, DOI 10.1109/ICIP.2018.8451684
   Domanski M, 2017, INT CONF SYST SIGNAL, DOI 10.1109/IWSSIP.2017.7965623
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Grois D, 2016, PICT COD SYMP
   Grois D, 2013, PICT COD SYMP, P394, DOI 10.1109/PCS.2013.6737766
   Han HX, 2018, LECT NOTES COMPUT SC, V11165, P274, DOI 10.1007/978-3-030-00767-6_26
   Ila V, 2017, INT J ROBOT RES, V36, P210, DOI 10.1177/0278364917691110
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Li L, 2017, IEEE J-STSP, V11, P1107, DOI 10.1109/JSTSP.2017.2725198
   Li L, 2017, IEEE DATA COMPR CONF, P131, DOI 10.1109/DCC.2017.10
   Li Y, 2016, IEEE T CIRC SYST VID, V26, P1308, DOI 10.1109/TCSVT.2015.2450333
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   McGuire M., 2017, P 21 ACM SIGGRAPH S, P2, DOI [DOI 10.1145/30233683023378, 10.1145/30233683023378]
   Ng R, 2005, RES REPORT, DOI DOI 10.1145/3097571
   Panayides AS, 2020, IEEE ACCESS, V8, P11469, DOI 10.1109/ACCESS.2020.2965325
   Samuelsson, 2019, SMPTE MOTION IMAG J, V128, P1, DOI DOI 10.5594/JMI.2019.2937737
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Trottnow J, 2019, SA'19: SIGGRAPH ASIA 2019 TECHNICAL BRIEFS, P71, DOI 10.1145/3355088.3365158
   Nguyen T, 2018, PICT COD SYMP, P31, DOI 10.1109/PCS.2018.8456289
   Viola I, 2017, IEEE J-STSP, V11, P1092, DOI 10.1109/JSTSP.2017.2740167
   Wu GC, 2017, IEEE J-STSP, V11, P926, DOI 10.1109/JSTSP.2017.2747126
   Yun Li, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P539, DOI 10.1109/ICASSP.2014.6853654
   Zhang F, 2020, ARXIV200310282EESSIV
NR 33
TC 4
Z9 4
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2517
EP 2528
DI 10.1007/s11042-021-11645-x
EA OCT 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000712943000001
DA 2024-07-18
ER

PT J
AU Hafsa, A
   Fradi, M
   Sghaier, A
   Malek, J
   Machhout, M
AF Hafsa, Amal
   Fradi, Marwa
   Sghaier, Anissa
   Malek, Jihene
   Machhout, Mohsen
TI Real-time video security system using chaos- improved advanced
   encryption standard (IAES)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video encryption; Security; Real time; IAES; Chaos theory
ID SCHEME; QUALITY
AB Real-time multimedia applications are increasingly achieving success in the everyday world. Thereby, multimedia information relies on security to protect private life. The Advanced Encryption Standard (AES) has been designed to secure different applications. Yet, some limitations are given, making it inappropriate for secure video storation and transmission. The limitations are the time complexity, the multiple iterations, and the predefined substitution box. Thus, any user can use it to break the encryption. Moreover, the multiple iterations augment the need for CPU usage, and so the overall run time. Hence, it is necessary to modify the AES algorithm to make it more appropriate for securing video frames transmission over insecure channel. In this paper, an Improved AES (IAES) is put forward, which improves both diffusion and confusion in ciphered video. Our work consists in the following two main points: First, we propose to eliminate both shift-row and sub-byte transformations and replace them with a mix-row operation. This task reduces the run time, which presents a significant factor for real-time video transmission. Equally important, we propose to use the henon chaotic map in the key generation procedure, which provides more randomness. The Hash Algorithm SHA-3 is used to generate the initial conditions of the chaotic attractor. The video encryption procedure is verified with success, and the experimental results confirm that the novel algorithm combining chaos and IAES augments the entropy of the ciphered video by 15% and reduces the complexity time for both encryption and decryption compared to the standard one. Security analysis is successfully performed, and the results prove that our suggested technique provides the basics of cryptography with more correctness. The PRNG is tested by NIST 800-22 test suit, which indicates that it is suitable for secure image encryption. It provides a large key space of 2(128) which resists the brute-force attack. All in all, the findings confirm that the novel security approach eliminates the limitation of the existing AES and provides a trade-off between speed and safety levels to secure video transmission.
C1 [Hafsa, Amal; Fradi, Marwa; Sghaier, Anissa; Malek, Jihene; Machhout, Mohsen] Univ Monastir, Elect & Microelect Lab, Monastir, Tunisia.
   [Malek, Jihene] Sousse Univ, Higher Inst Appl Sci & Technol, Dept Elect, LR99ES30 E E Lab, Sousse, Tunisia.
C3 Universite de Monastir; Universite de Sousse
RP Hafsa, A (corresponding author), Univ Monastir, Elect & Microelect Lab, Monastir, Tunisia.
EM amalhafsa12@gmail.com; marwa.fradi@gmail.com; sghaier.anissa@gmail.com;
   Jihenemalek.14@gmail.com; machhoutt@yahoo.fr
OI Mohsen, Machhout/0000-0002-5629-0508; Anissa,
   Sghaier/0000-0002-4578-7308
CR AGAIAN S, 2010, IEEE INT C SYSTEMS M, DOI DOI 10.1109/ICSMC.2010.5642260
   Arab A, 2019, J SUPERCOMPUT, V75, P6663, DOI 10.1007/s11227-019-02878-7
   Barakat ML, 2013, ETRI J, V35, P448, DOI 10.4218/etrij.13.0112.0677
   Ben Atitallah A, 2008, DES AUTOM EMBED SYST, V12, P293, DOI 10.1007/s10617-008-9030-2
   Bentoutou Y., 2019, ADV SPACE RES
   Chen YT, 2021, VISUAL COMPUT, V37, P1691, DOI 10.1007/s00371-020-01932-3
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02066-z
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112316
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Cheng SL, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12030332
   Ding L, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8891778
   ELHASSAN K, 2019, IET IMAGE PROCESS, DOI DOI 10.1049/IET-IPR.2018.5250
   Ganesan K, 2008, I C COMP GRAPH IM VI, P211, DOI 10.1109/CGIV.2008.66
   Hafsa Amal, 2020, International Journal of Information and Computer Security, V13, P118
   Han QQ, 2020, INT J INTERNET PROTO, V13, P1, DOI 10.1504/IJIPT.2020.105046
   Hayajneh T, 2017, IEEE SYST J, V11, P2536, DOI 10.1109/JSYST.2015.2424702
   Jiang N, 2019, INT J THEOR PHYS, V58, P979, DOI 10.1007/s10773-018-3989-7
   Jing M, 2020, MULTIMEDIA SYST, V26, P363, DOI [10.1007/s00530-020-00648-7, DOI 10.1007/S00530-020-00648-7]
   Kollias S., 2004, ACM MULTIMEDIA, DOI [10.1145/1027527.1027609, DOI 10.1145/1027527.1027609]
   Li JJ, 2018, MULTIMED TOOLS APPL, V77, P12837, DOI 10.1007/s11042-017-4916-2
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Mat Kiah M L, 2014, J Med Syst, V38, P133, DOI 10.1007/s10916-014-0133-y
   Moafimadani SS, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21060577
   National Institute of Standards and Technology, 2001, NIST FIPS PUB, P197
   Neupane A, 2020, MULTIMED TOOLS APPL, V79, P29043, DOI 10.1007/s11042-020-09478-1
   Quan HT, 2012, TELECOMMUN SYST, V49, P35, DOI 10.1007/s11235-010-9351-x
   Rached T., 2015, RECENT ADV TELECOMMU
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Wang XY, 2016, OPT LASER ENG, V82, P79, DOI 10.1016/j.optlaseng.2015.12.006
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wickramage C, 2016, 2016 IEEE 18TH INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES (HEALTHCOM), P43
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xi J., 2019, WILEY CONCURRENCY CO, DOI [10.1002/cpe.5533, DOI 10.1002/CPE.5533]
   Yu F, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/4047957
   Yu F, 2019, NEUROCOMPUTING, V350, P108, DOI 10.1016/j.neucom.2019.03.053
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhang JM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041188
   Zhang X, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P889, DOI 10.1109/ICALIP.2008.4590187
   Zheng YF, 2015, MULTIMED TOOLS APPL, V74, P7803, DOI 10.1007/s11042-014-2024-0
   Zhou LY, 2020, IEEE ACCESS, V8, P30436, DOI 10.1109/ACCESS.2020.2972269
NR 44
TC 18
Z9 18
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2275
EP 2298
DI 10.1007/s11042-021-11668-4
EA OCT 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000710608700003
DA 2024-07-18
ER

PT J
AU Brahimi, N
   Bouden, T
   Brahimi, T
   Boubchir, L
AF Brahimi, Nabila
   Bouden, Toufik
   Brahimi, Tahar
   Boubchir, Larbi
TI Efficient multiplier-less parametric integer approximate transform based
   on 16-points DCT for image compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image compression; DCT-II; Integer DCT; Integer approximation; JPEG
ID DISCRETE COSINE; ALGORITHM
AB The Discrete Cosine Transform (DCT) is one of the major components in most image and video compression systems. In this paper, a novel approach for developing integer approximation of the two-dimension 8 points conventional DCT-II is introduced. The proposed method is based on 16 points DCT-II and rounding off operations. As result, we obtained multiplication-free 8-points approximation of conventional DCT-II, noted T-pa, with the parameter a = {1,2}, and its basic elements are {0, +/- 1, +/- 2}; no multiplication operations are required. These two transforms are the more efficient DCT approximations with a reduction in the term of complexity computation, requiring 24 additions and 2-bit shifts for a = 1 or 24 additions and 6-bit shifts for a = 2; no multiplication required. The comparative study carried-out to assess the performance of the proposed transform matrices against some popular existing ones using different quality measures, has shown that the proposed transforms outperform the state-of-the-art of DCT approximations at low and high bit rates, as well as providing a lower computational complexity. Therefore, the capability of proposed transforms matrices is improved in image compression application.
C1 [Brahimi, Nabila] Univ Mohammed Seddik Benyahia, Dept Elect, NDT Lab, BP 98, Jijel 18000, Algeria.
   [Bouden, Toufik] Univ Mohammed Seddik Benyahia, Automat Dept, NDT Lab, BP 98, Jijel 18000, Algeria.
   [Brahimi, Tahar] Univ Mohammed Seddik Benyahia, Dept Elect, L2EI Lab, BP 98, Jijel 18000, Algeria.
   [Boubchir, Larbi] Univ Paris, Dept Comp Sci, LIASD Res Lab, 8 2 Rue Liberte, F-93526 St Denis, France.
C3 Universite Paris Cite
RP Brahimi, N (corresponding author), Univ Mohammed Seddik Benyahia, Dept Elect, NDT Lab, BP 98, Jijel 18000, Algeria.
EM nabila.brahimi@univ-jijel.dz; bouden_toufik@yahoo.com;
   t.brahimi@gmail.com; boubchir@ai.univ-paris8.fr
RI Boubchir, Larbi/I-9623-2019; BRAHIMI, Nabila/JDW-4272-2023
OI Boubchir, Larbi/0000-0002-5668-6801; 
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Arai Y., 1988, Transactions of the Institute of Electronics, Information and Communication Engineers E, VE71, P1095
   Bayer FM, 2012, ELECTRON LETT, V48, P919, DOI 10.1049/el.2012.1148
   Blahut Richard E., 2010, FAST ALGORITHMS SIGN
   Bouguezel S, 2008, ELECTRON LETT, V44, P1249, DOI 10.1049/el:20082239
   Bouguezel Saad, 2009, 2009 21st International Conference on Microelectronics (ICM 2009), P74, DOI 10.1109/ICM.2009.5418584
   Bouguezel S, 2011, 7 INT WORKSH SYST SI
   Bouguezel S, 2013, IEEE T CIRCUITS-I, V60, P989, DOI 10.1109/TCSI.2012.2224751
   Bouguezel S, 2011, IEEE INT SYMP CIRC S, P2145
   Bouguezel S, 2010, MIDWEST SYMP CIRCUIT, P509, DOI 10.1109/MWSCAS.2010.5548745
   Bouguezel S, 2008, SCS: 2008 2ND INTERNATIONAL CONFERENCE ON SIGNALS, CIRCUITS AND SYSTEMS, P184
   Brahimi N, 2020, MULTIMED TOOLS APPL, V79, P7615, DOI 10.1007/s11042-019-08325-2
   Britanak V., 2010, DISCRETE COSINE SINE
   CHEN WH, 1977, IEEE T COMMUN, V25, P1004, DOI 10.1109/TCOM.1977.1093941
   Cintra RJ, 2014, SIGNAL PROCESS, V99, P201, DOI 10.1016/j.sigpro.2013.12.027
   Cintra RJ, 2016, CIRC SYST SIGNAL PR, V35, P4009, DOI 10.1007/s00034-015-0233-z
   Cintra RJ, 2011, IEEE SIGNAL PROC LET, V18, P579, DOI 10.1109/LSP.2011.2163394
   CLARKE RJ, 1981, IEE PROC-F, V128, P359, DOI 10.1049/ip-f-1.1981.0061
   Coutinho VA, 2016, J REAL-TIME IMAGE PR, V12, P247, DOI 10.1007/s11554-015-0492-8
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Ezhilarasi R, 2020, MULTIMED TOOLS APPL, V79, P8539, DOI 10.1007/s11042-018-5960-2
   Grgic S., 2001, Proceedings VIPromCom-2001. 3rd International Symposium on Video Processing and Multimedia Communications, P79
   Haweel RT, 2016, J VIS COMMUN IMAGE R, V40, P357, DOI 10.1016/j.jvcir.2016.07.003
   Haweel TI, 2001, SIGNAL PROCESS, V81, P2309, DOI 10.1016/S0165-1684(01)00106-2
   Le Gall D. J., 1992, Signal Processing: Image Communication, V4, P129, DOI 10.1016/0923-5965(92)90019-C
   LEE BG, 1984, IEEE T ACOUST SPEECH, V32, P1243
   Loeffer C., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P988, DOI 10.1109/ICASSP.1989.266596
   Oliveira PAM, 2017, IEEE T CIRC SYST VID, V27, P1066, DOI 10.1109/TCSVT.2016.2515378
   Oliveira RS, 2019, MULTIDIM SYST SIGN P, V30, P1363, DOI 10.1007/s11045-018-0601-5
   Pourazad MT, 2012, IEEE CONSUM ELECTR M, V1, P36, DOI 10.1109/MCE.2012.2192754
   Puri A, 2004, SIGNAL PROCESS-IMAGE, V19, P793, DOI 10.1016/j.image.2004.06.003
   Senapati R, 2010, P ANN IEEE IND C IND, P1, DOI [10.1109/INDCON.2010.5712707, DOI 10.1109/INDCON.2010.5712707]
   Tablada CJ, 2017, SIGNAL PROCESS-IMAGE, V58, P14, DOI 10.1016/j.image.2017.06.014
   TAMBOLI P, 2015, INT J ADV RES ELECT, V4, P6185
   Wahid KA, 2007, IEEE T CIRCUITS-II, V54, P700, DOI 10.1109/TCSII.2007.898891
   Wallace G. K., 1991, Communications of the ACM, V34, P30, DOI 10.1145/103085.103089
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watkins D. S., 2004, FUNDAMENTALS MATRIX
   Yuan WJ, 2006, INT CONF ACOUST SPEE, P3399
NR 39
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37723
EP 37746
DI 10.1007/s11042-021-11348-3
EA SEP 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000701393200001
DA 2024-07-18
ER

PT J
AU Rajesh, M
   Sitharthan, R
AF Rajesh, M.
   Sitharthan, R.
TI Image fusion and enhancement based on energy of the pixel using Deep
   Convolutional Neural Network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Energy; Multi-exposure; Multifocal; Multi modal;
   Multispectral images; Deep Convolutional Neural Network (DCNN);
   Multimodal medical image
ID SELECTION
AB This paper presents a novel and generic framework for the recognition of emotions using human body expression like head, hand and leg movements. Whole body movements are among the main visual stimulus categories that are naturally associated with faces and the neuro scientific investigation of how body expressions are processed has entered the research agenda this last decade. The database was composed of 254 whole body expressions from 46 actors expressing four emotions (anger, fear, happiness, and sadness). In all pictures the face of the actor was blurred and participants were asked to categorize the emotions expressed in the stimuli in a four alternative-forced-choice task. Using Deep Convolutional Neural Network (DCNN), the input images are trained and modeled. Then the model can be tested by test images for recognizing human emotion from non-verbal communication.
C1 [Rajesh, M.] Sanjivani Coll Engn, Dept Comp Sci Engn, Kopargaon, India.
   [Sitharthan, R.] Vellore Inst Technol, Sch Elect Engn, Dept Elect Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Rajesh, M (corresponding author), Sanjivani Coll Engn, Dept Comp Sci Engn, Kopargaon, India.
EM rajesmano@gmail.com
RI M, Rajesh/N-2253-2017; R, Sitharthan/K-1786-2017; Manoharan,
   Rajesh/N-2253-2017
OI M, Rajesh/0000-0001-8843-699X; Manoharan, Rajesh/0000-0003-0003-473X
CR [Anonymous], IEEE C COMP VIS PATT
   Babu RG, 2021, IET NETW, V10, P253, DOI 10.1049/ntw2.12027
   Battimelli G., 2020, Computer Meets Theoretical Physics
   Dael Nele, 2012, BODY ACTION POSTURE
   Dalal N, 2005, INT C COMP VIS PATT, V1, P225
   Dinh PH, 2021, EXPERT SYST APPL, V171, DOI 10.1016/j.eswa.2021.114576
   Fourat, 2015, MULTILEVEL CLASSIFIC, V5
   Gopal VN, 2021, MEASUREMENT, V178, DOI 10.1016/j.measurement.2021.109442
   Goyal S, 2020, SIGNAL IMAGE VIDEO P, V14, P719, DOI 10.1007/s11760-019-01597-z
   Indhumathi R, 2021, ADV MACHINE LEARNING, P853
   Jose J, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102480
   Joshi J, 2013, IEEE INT CONF AUTOMA
   Kaâniche MB, 2010, PROC CVPR IEEE, P2745, DOI 10.1109/CVPR.2010.5539999
   Kahlessenane F, 2021, CLUSTER COMPUT, V24, P2069, DOI 10.1007/s10586-020-03215-x
   Karg M, 2013, IEEE T AFFECT COMPUT, V4, P341, DOI 10.1109/T-AFFC.2013.29
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Matikainen Pyry, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P514, DOI 10.1109/ICCVW.2009.5457659
   Melissa Gross M, 2010, METHODOLOGY ASSESSIN
   Moshika A, 2021, IEEE ACCESS, V9, P74659, DOI 10.1109/ACCESS.2021.3081567
   NATARAJ S, 2020, IEEE SENS J
   Natarajan Balaji, 2021, IEEE Systems Journal, V15, P4980, DOI 10.1109/JSYST.2020.3025407
   Parvathy VS, 2020, PHYS COMMUN-AMST, V41, DOI 10.1016/j.phycom.2020.101119
   Purushothaman R, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106651
   Rajesh M, 2020, WIRELESS PERS COMMUN, V113, P2463, DOI 10.1007/s11277-020-07336-9
   Sitharthan R, 2021, IET RENEW POWER GEN, V15, P1968, DOI 10.1049/rpg2.12119
   Sitharthan R, 2022, INT J PERVASIVE COMP, V18, P476, DOI 10.1108/IJPCC-08-2020-0115
   Sitharthan R, 2021, INT T ELECTR ENERGY, V31, DOI 10.1002/2050-7038.12685
   Xu LN, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101885
   Yadav SP, 2020, MED BIOL ENG COMPUT, V58, P669, DOI 10.1007/s11517-020-02136-6
   Zacharatos Haris, 2014, AUTOMATIC EMOTION RE
NR 30
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 873
EP 885
DI 10.1007/s11042-021-11501-y
EA SEP 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000696768700001
DA 2024-07-18
ER

PT J
AU Adhikari, S
   Karforma, S
AF Adhikari, Subhajit
   Karforma, Sunil
TI A novel image encryption method for e-governance application using
   elliptic curve pseudo random number and chaotic random number sequence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Elliptic curve pseudo random number; Chaotic map;
   Egovernance; Security; Entropy; Bits per pixels; PSNR; Correlation
ID SEMI-TENSOR PRODUCT; LEVEL PERMUTATION; ALGORITHM; MATRIX; SYSTEM; CODE
AB Image encryption is gaining popularity due to the rapid use of internet technology. Security attacks on the image can occur when images are shared through the internet. E-governance generates important documents with images like identity cards, admit cards, and medical reports. An attacker can steal the image data. An attacker can modify or alter the documents using their own images to create duplicate documents. So, image encryption is a must to prevent the security and privacy of images. In this paper, a novel image encryption method using elliptic curve pseudo-random number is proposed for image data transfer in E-governance. The encryption method creates the cipher image with secp256r1 elliptic curve points and a map table. The map table consists of bit positions as index numbers. In the decryption phase, the receiver decodes the cipher image complementing index numbers in the map table. The map table is also encrypted and decrypted with a chaotic sequence. Our method gives better results than other image encryption methods, according to bits per pixels, entropy, correlation of adjacent pixels, histogram analysis, peak signal to noise ratio, unified average changing intensity, encryption, and decryption time. The experimental results prove the proposed method's effectiveness and security.
C1 [Adhikari, Subhajit] Dinabandhu Andrews Inst Technol & Management, Dept Comp Applicat, Kolkata 700094, W Bengal, India.
   [Karforma, Sunil] Univ Burdwan, Dept Comp Sci, Burdwan 713104, W Bengal, India.
C3 University of Burdwan
RP Adhikari, S (corresponding author), Dinabandhu Andrews Inst Technol & Management, Dept Comp Applicat, Kolkata 700094, W Bengal, India.
EM subhajit15dec@gmail.com; sunilkarforma@yahoo.com
RI Karforma, Sunil/AAQ-7556-2021
OI Karforma, Sunil/0000-0003-4968-4055; ADHIKARI,
   SUBHAJIT/0000-0002-9435-7400
CR Abdelfatah RI, 2020, IEEE ACCESS, V8, P3875, DOI 10.1109/ACCESS.2019.2958336
   Abdulla A. A., 2015, Ph.D. dissertation
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Akhavan A, 2017, OPT LASER TECHNOL, V95, P94, DOI 10.1016/j.optlastec.2017.04.022
   Amin R, 2016, COMPUT NETW, V101, P42, DOI 10.1016/j.comnet.2016.01.006
   Arab A, 2019, J SUPERCOMPUT, V75, P6663, DOI 10.1007/s11227-019-02878-7
   Bendaoud S, 2019, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON NETWORKING, INFORMATION SYSTEMS & SECURITY (NISS19), DOI 10.1145/3320326.3320361
   Çavusoglu Ü, 2017, CHAOS SOLITON FRACT, V95, P92, DOI 10.1016/j.chaos.2016.12.018
   Certicom SEC, 2000, P STANDARDS EFFICIEN
   Dawahdeh ZE., 2015, INDIAN J SCI TECHNOL, V8, P1, DOI 10.17485/ijst/2015/v8i15/64749
   Dawahdeh ZE, 2018, J KING SAUD UNIV-COM, V30, P349, DOI 10.1016/j.jksuci.2017.06.004
   Fang XJ, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT (ICIM 2017), P412, DOI 10.1109/INFOMAN.2017.7950418
   Gong LH, 2019, OPT LASER TECHNOL, V115, P257, DOI 10.1016/j.optlastec.2019.01.039
   Gupta K, 2009, 2009 1ST INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, COMMUNICATION SYSTEMS AND NETWORKS(CICSYN 2009), P342, DOI 10.1109/CICSYN.2009.33
   Hafsa A, 2019, I C SCI TECH AUTO CO, P95, DOI [10.1109/STA.2019.8717302, 10.1109/sta.2019.8717302]
   Hayat U, 2019, SIGNAL PROCESS, V155, P391, DOI 10.1016/j.sigpro.2018.10.011
   HS SK., 2012, INT J COMPUT APPL, V59
   Kolhekar M., 2011, INT J ENTERP COMPUT, V1
   Leng L, 2015, MULTIMED TOOLS APPL, V74, P11683, DOI 10.1007/s11042-014-2255-0
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Martinez Victor Gayoso, 2010, A survey of the elliptic curve integrated encryption scheme
   McAteer I, 2019, TECHNOLOGIES, V7, DOI 10.3390/technologies7020034
   Panduranga HT., 2012, INT J COMPUT APPL, V60
   Parvaz R, 2018, OPT LASER TECHNOL, V101, P30, DOI 10.1016/j.optlastec.2017.10.024
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Rewagad P, 2013, INT CONF COMM SYST, P437, DOI 10.1109/CSNT.2013.97
   Reyad O, 2015, COMM COM INF SC, V566, P34, DOI 10.1007/978-3-319-26404-2_3
   Salleh M., 2003, P 2003 IEEE INT S CI, V39, P1, DOI DOI 10.11113/JT.V39.458
   Shaikh JR, 2017, IEEE INT CONF MICROW, P532
   Shankar K, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616501383
   Singh LD, 2015, PROCEDIA COMPUT SCI, V54, P472, DOI 10.1016/j.procs.2015.06.054
   Suárez-Albela M, 2018, 2018 GLOBAL INTERNET OF THINGS SUMMIT (GIOTS), P246
   Tawalbeh L, 2013, IET INFORM SECUR, V7, P67, DOI 10.1049/iet-ifs.2012.0147
   Toughi S, 2017, SIGNAL PROCESS, V141, P217, DOI 10.1016/j.sigpro.2017.06.010
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Xiang Li, 2010, 2010 International Conference on Audio, Language and Image Processing (ICALIP), P396, DOI 10.1109/ICALIP.2010.5684554
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang X, 2018, IEEE PHOTONICS J, V10, DOI [10.1109/JPHOT.2018.2859257, 10.1109/JPHOT.2018.2818715]
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhao ZJ, 2013, ADV INTELL SYST, V181, P859
   Zhu CX, 2018, IEEE ACCESS, V6, P18759, DOI 10.1109/ACCESS.2018.2817600
NR 53
TC 6
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 759
EP 784
DI 10.1007/s11042-021-11323-y
EA SEP 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000696143400001
DA 2024-07-18
ER

PT J
AU Winston, JJ
   Hemanth, DJ
   Angelopoulou, A
   Kapetanios, E
AF Winston, J. Jenkin
   Hemanth, D. Jude
   Angelopoulou, Anastassia
   Kapetanios, Epaminondas
TI Hybrid deep convolutional neural models for iris image recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Iris recognition; Convolutional neural networks; Deep
   learning
ID NETWORK; SYSTEM
AB This paper briefly explains about the application of deep learning-based methods for biometric applications. This work attempts to solve the problem of limited availability of datasets which affects accuracy of the classifiers. This paper explores the iris recognition problem using a basic convolutional neural network model and hybrid deep learning models. The augmentations used to populate the dataset and their outputs are also shown in this study. An illustration of learned weights and the outputs of intermediary stages the network like convolution layer, normalization layer and activation layer are given to help better understanding of the process. The performance of the network is studied using accuracy and receiver operating characteristic curve. The empirical results of our experiments show that Adam based optimization is good at learning iris features using deep learning. Moreover, the hybrid deep learning network with SVM performs better in iris recognition with a maximum accuracy of 97.8%. These experiments have also revealed that not all hybrid networks will give better performance as the hybrid deep learning network with KNN has given lesser accuracy.
C1 [Winston, J. Jenkin; Hemanth, D. Jude] Karunya Inst Technol & Sci, Dept ECE, Coimbatore, Tamil Nadu, India.
   [Angelopoulou, Anastassia; Kapetanios, Epaminondas] Univ Westminster, Sch Comp Sci & Engn, London, England.
C3 Karunya Institute of Technology & Sciences; University of Westminster
RP Hemanth, DJ (corresponding author), Karunya Inst Technol & Sci, Dept ECE, Coimbatore, Tamil Nadu, India.
EM judehemanth@karunya.edu
RI Karunya, Librarian/HHS-3630-2022; Angelopoulou, Anastassia/AAE-8857-2020
OI Karunya, Librarian/0009-0006-0726-2507; Angelopoulou,
   Anastassia/0000-0003-1453-492X
CR Al-Waisy AS, 2018, PATTERN ANAL APPL, V21, P783, DOI 10.1007/s10044-017-0656-1
   [Anonymous], IIT Delhi Iris Database
   Baqar M, 2016, 2016 INTERNATIONAL CONFERENCE ON OPEN SOURCE SYSTEMS AND TECHNOLOGIES (ICOSST), P72, DOI 10.1109/ICOSST.2016.7838580
   Benalcazar DP, 2020, IEEE ACCESS, V8, P98584, DOI 10.1109/ACCESS.2020.2996563
   Chen YF, 2020, IEEE ACCESS, V8, P32365, DOI 10.1109/ACCESS.2020.2973433
   Ciocoiu IB, 2020, IEEE ACCESS, V8, P218966, DOI 10.1109/ACCESS.2020.3042547
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Hu Y, 2017, IEEE T INF FOREN SEC, V12, P157, DOI 10.1109/TIFS.2016.2606083
   Kavukcuoglu K., 2010, Advances in neural information processing systems, P1
   King DB, 2015, ACS SYM SER, V1214, P1
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee MB, 2019, IEEE ACCESS, V7, P122134, DOI 10.1109/ACCESS.2019.2937809
   Liu M, 2020, IEEE T FUZZY SYST, V28, P92, DOI 10.1109/TFUZZ.2019.2912576
   Liu NAF, 2016, PATTERN RECOGN LETT, V82, P154, DOI 10.1016/j.patrec.2015.09.016
   Liu XN, 2019, PATTERN RECOGN LETT, V117, P66, DOI 10.1016/j.patrec.2018.12.003
   Maiorana E, 2020, NEUROCOMPUTING, V410, P374, DOI 10.1016/j.neucom.2020.06.009
   Malik J, 2020, IEEE ACCESS, V8, P195832, DOI 10.1109/ACCESS.2020.3033848
   Marra F, 2018, PATTERN RECOGN LETT, V113, P46, DOI 10.1016/j.patrec.2017.04.010
   Menotti D, 2015, IEEE T INF FOREN SEC, V10, P864, DOI 10.1109/TIFS.2015.2398817
   Minaee S, 2019, ARXIV190709380
   Minaee S., 2016, IEEE Region, P1
   *NARS REDDY AJ RAT, 2020, IMAGE VIS COMPUT, V103
   Nguyen K, 2018, IEEE ACCESS, V6, P18848, DOI 10.1109/ACCESS.2017.2784352
   Nguyen K, 2020, IEEE T IMAGE PROCESS, V29, P7166, DOI 10.1109/TIP.2020.2999211
   Oktiana M, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e03407
   Oktiana M, 2019, IEEE ACCESS, V7, P130484, DOI 10.1109/ACCESS.2019.2939326
   Oyedotun O, 2017, TURK J ELECTR ENG CO, V25, P1106, DOI 10.3906/elk-1507-190
   Pillai JK, 2014, IEEE T PATTERN ANAL, V36, P73, DOI 10.1109/TPAMI.2013.98
   Qian N, 1999, NEURAL NETWORKS, V12, P145, DOI 10.1016/S0893-6080(98)00116-6
   Qingqiao Hu, 2020, Procedia Computer Science, V174, P505, DOI 10.1016/j.procs.2020.06.118
   Raja KB, 2017, PATTERN RECOGN LETT, V91, P27, DOI 10.1016/j.patrec.2016.12.025
   Rakvic R, 2016, IEEE ACCESS, V4, P2831, DOI 10.1109/ACCESS.2016.2571747
   Ribeiro E, 2019, IET BIOMETRICS, V8, P69, DOI 10.1049/iet-bmt.2018.5146
   Srivastva R, 2021, INFORM SCIENCES, V558, P208, DOI 10.1016/j.ins.2021.01.001
   Sudhakar T, 2020, IEEE ACCESS, V8, P112932, DOI 10.1109/ACCESS.2020.3003869
   Umer S, 2020, NEURAL NETWORKS, V122, P407, DOI 10.1016/j.neunet.2019.11.009
   Wang CY, 2020, IEEE T INF FOREN SEC, V15, P2944, DOI 10.1109/TIFS.2020.2980791
   Wang K, 2019, PATTERN RECOGN, V86, P85, DOI 10.1016/j.patcog.2018.08.010
   Zhao TM, 2019, IEEE ACCESS, V7, P49691, DOI 10.1109/ACCESS.2019.2911056
   Zhao ZJ, 2019, PATTERN RECOGN, V93, P546, DOI 10.1016/j.patcog.2019.04.010
NR 40
TC 9
Z9 9
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9481
EP 9503
DI 10.1007/s11042-021-11482-y
EA SEP 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000695102100005
DA 2024-07-18
ER

PT J
AU Rao, SN
AF Rao, Sana
TI A framework for robust motion estimation and segmentation in adverse
   outdoor conditions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion estimation; Motion segmentation; Total variation; Optical flow;
   Robust fitting
ID OPTICAL-FLOW ESTIMATION
AB Robust motion estimation and segmentation are two important interrelated tasks with a variety of applications. Traditional motion estimation and segmentation methods focus on normal scenarios. However, they may fail to robustly estimate and segment the moving objects because of the ill-defined edges and boundaries in these scenarios. In this paper, a robust framework for motion estimation and segmentation in adverse outdoor conditions is presented. In the proposed framework, a non-local total variation motion estimation method (NLTV- L1) with a support weight function is proposed. It is efficient to preserve the edges and handle the smoothness near the edges using a coarse-to-fine strategy for adverse outdoor scenarios. To deal with the segmentation problem, we take advantage of the motion pattern based background-foreground layer extraction to segment the moving objects. Such a way effectively groups the pixels that move in a similar direction and thus these pixels can be extracted from the noisy background. In addition, our framework does not require any post-processing step to remove noise. We demonstrate that the proposed framework outperforms other state-of-the-art methods on two commonly used datasets (i.e., Middlebury and MPI Sintel) for motion estimation and segmentation. Moreover, the experiments on real outdoor benchmarks (i.e., Foggy Zurich, Traffic and CDnet2014) show the robustness and efficiency of our framework in adverse outdoor conditions.
C1 [Rao, Sana] Xiamen Univ, Sch Informat, Fujian Key Lab Sensing & Comp Smart City, Xiamen 361005, Peoples R China.
C3 Xiamen University
RP Rao, SN (corresponding author), Xiamen Univ, Sch Informat, Fujian Key Lab Sensing & Comp Smart City, Xiamen 361005, Peoples R China.
EM rao.sana10@yahoo.com
RI Rao, Sana/AAT-4222-2021; rao, sana/AAY-9797-2021
OI , Sana/0000-0001-9642-9466
FU CSC; Fujian key Laboratory of Sensing and Computing for Smart City of
   Xiamen University, China
FX I would like to express my deep gratitude to Professor Hanzi Wang, my
   Ph.D. research supervisor, and Professor YanYan, for his patient
   guidance. We acknowledge the support of the CSC and Fujian key
   Laboratory of Sensing and Computing for Smart City of Xiamen University,
   China.
CR Anthwal S, 2019, IMAGING SCI J, V67, P284, DOI 10.1080/13682199.2019.1641316
   Belhachmi Z, 2016, J MATH IMAGING VIS, V54, P358, DOI 10.1007/s10851-015-0608-6
   Ben Said A, 2019, J MATH IMAGING VIS, V61, P106, DOI 10.1007/s10851-018-0829-6
   Bengtsson T, 2017, IMAGE VISION COMPUT, V57, P78, DOI 10.1016/j.imavis.2016.11.003
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Chan KL, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0308-4
   Emilien A, 2013, IEEE IMAGE PROC, P2514, DOI 10.1109/ICIP.2013.6738518
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Gupta B, 2018, MULTIMED TOOLS APPL, V77, P19527, DOI 10.1007/s11042-017-5401-7
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Jarraya S. K., 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P52, DOI 10.1109/DICTA.2010.18
   Jiang B, 2018, MULTIMED TOOLS APPL, V77, P13513, DOI 10.1007/s11042-017-4973-6
   Li R., 2017, P EUR C COMP VIS, V17, P288, DOI [10.48550/arXiv.1704.05239, DOI 10.48550/ARXIV.1704.05239]
   Li W., 2018, 29 BRIT MACH VIS C
   Li YY, 2009, COMMUN MATH SCI, V7, P741
   Liu QG, 2016, MULTIMED TOOLS APPL, V75, P7909, DOI 10.1007/s11042-015-2709-z
   Mei L, 2020, IEEE T CIRC SYST VID, V30, P495, DOI 10.1109/TCSVT.2019.2890861
   Sakaridis C, 2018, INT J COMPUT VISION, V126, P973, DOI 10.1007/s11263-018-1072-8
   Sánchez J, 2013, IMAGE PROCESS ON LIN, V3, P137, DOI 10.5201/ipol.2013.26
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Sevilla-Lara L, 2016, PROC CVPR IEEE, P3889, DOI 10.1109/CVPR.2016.422
   Singaraju D, 2011, IEEE T PATTERN ANAL, V33, P1295, DOI 10.1109/TPAMI.2010.206
   Soumya T, 2008, LECT NOTES ENG COMP, P1161
   Sun DQ, 2014, INT J COMPUT VISION, V106, P115, DOI 10.1007/s11263-013-0644-x
   Sun DQ, 2012, PROC CVPR IEEE, P1768, DOI 10.1109/CVPR.2012.6247873
   Unger M, 2012, PROC CVPR IEEE, P1878, DOI 10.1109/CVPR.2012.6247887
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Wedel Andreas, 2009, Statistical and Geometrical Approaches to Visual Motion Analysis. International Dagstuhl Seminar. Revised Papers, P23, DOI 10.1007/978-3-642-03061-1_2
   Werlberger M, 2010, PROC CVPR IEEE, P2464, DOI 10.1109/CVPR.2010.5539945
   Xiao JJ, 2005, PROC CVPR IEEE, P698
   Yang JL, 2015, PROC CVPR IEEE, P1019, DOI 10.1109/CVPR.2015.7298704
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhang CX, 2017, IEEE T IMAGE PROCESS, V26, P4055, DOI 10.1109/TIP.2017.2712279
NR 36
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 15267
EP 15287
DI 10.1007/s11042-021-11502-x
EA SEP 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000692967700001
DA 2024-07-18
ER

PT J
AU Li, JX
   Chen, HJ
   Li, YF
   Peng, YH
   Cai, NX
   Cao, XY
AF Li, Jiaxin
   Chen, Houjin
   Li, Yanfeng
   Peng, Yahui
   Cai, Naxin
   Cao, Xuyang
TI AMRSegNet: adaptive modality recalibration network for lung tumor
   segmentation on multi-modal MR images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lung tumor segmentation; Multi-modal MRI; Adaptive modality
   recalibration; Feature-level fusion strategy; Modality-descriptor
AB Segmentation of lung tumor on magnetic resonance (MR) images is challenging. In this study, we propose an adaptive modality recalibration segmentation network (AMRSegNet) for lung tumor segmentation on T2-weighted (T2W) and diffusion-weighted imaging (DWI) MR images. AMRSegNet is composed of two parts: a multi-stream segmentation framework and an adaptive modality-recalibration module. Considering the insufficient capability on the feature representation of the single-stream segmentation network with multi-modality input, a feature-level fusion strategy is used on the multi-stream residual U-Net (Res-UNet) concatenating the feature maps of all layers from two streams of T2W and DWI. Besides, we adopt residual squeeze-and-excitation (Res-SE) blocks with a modality-wise descriptor to adaptively recalibrate the concatenated multi-modality feature stacks. We applied dice similarity coefficient (DSC) and Hausdorff distance (HD) as evaluation metrics on ablation studies and comparison experiments. The ablative studies demonstrate the effectiveness and generalization capability of the multi-stream segmentation framework and adaptive modality recalibration module. Also, the experimental results show that our proposed AMRSegNet achieved 20% improvement on DSC and 30% improvement on HD over the state-of-the-art methods, especially on the cases of tumors adjacent to the chest wall, mediastinum, and the concomitant inflammation region. The code is released in https://github.com/Nicholasxin/AMRSegNet.
C1 [Li, Jiaxin; Chen, Houjin; Li, Yanfeng; Peng, Yahui; Cai, Naxin; Cao, Xuyang] Beijing Jiaotong Univ, Sch Elect & Informat Engn, Beijing, Peoples R China.
C3 Beijing Jiaotong University
RP Chen, HJ (corresponding author), Beijing Jiaotong Univ, Sch Elect & Informat Engn, Beijing, Peoples R China.
EM hjchen@bjtu.edu.cn
RI 李, 佳欣/GSO-0978-2022; 李, 嘉馨/IWM-4023-2023
OI Li, Jiaxin/0000-0001-6808-1140
FU National Natural Science Foundation of China [61872030, 61771039];
   Shandong Province Major Science and Technology Innovation Project
   [2019TSLH0206]
FX This work was funded by National Natural Science Foundation of China
   (Grant No. 61872030, 61771039) and Shandong Province Major Science and
   Technology Innovation Project (Grant No. 2019TSLH0206).
CR Amorim, 2019, IEEE T MED IMAGING, V38, P1, DOI [10.1109/TMI.2017.2725639, DOI 10.1109/TMI.2017.2725639]
   Chartsias A, 2021, IEEE T MED IMAGING, V40, P781, DOI 10.1109/TMI.2020.3036584
   Chartsias A, 2018, IEEE T MED IMAGING, V37, P803, DOI 10.1109/TMI.2017.2764326
   Chilla GS, 2015, QUANT IMAG MED SURG, V5, P407, DOI 10.3978/j.issn.2223-4292.2015.03.01
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Dolz J., 2019, IVD NET INTERVERTEBR
   Dolz J, 2019, IEEE T MED IMAGING, V38, P1116, DOI 10.1109/TMI.2018.2878669
   Guo Z, 2019, IEEE T RADIAT PLASMA, V3, P162, DOI [10.1109/TRPMS.2018.2890359, 10.1109/trpms.2018.2890359]
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hsu, 2015, P IEEE COMP SOC C CO, V37, P448
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang, 2018, ANATOMYNET DEEP 3D S, DOI [10.1101/392969, DOI 10.1101/392969]
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jiang J, 2018, LECT NOTES COMPUT SC, V11071, P777, DOI 10.1007/978-3-030-00934-2_86
   Kingma D. P., 2014, arXiv
   Li J, 2019, ADV CIV ENG, V2019, DOI 10.1155/2019/5369532
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Liu P, 2020, IEEE ACCESS, V8, P34029, DOI 10.1109/ACCESS.2020.2973707
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Pollard JM, 2017, BRIT J RADIOL, V90, DOI 10.1259/bjr.20160667
   Roy AG, 2019, IEEE T MED IMAGING, V38, P540, DOI 10.1109/TMI.2018.2867261
   Rundo L, 2019, NEUROCOMPUTING, V365, P31, DOI 10.1016/j.neucom.2019.07.006
   Torre LA, 2016, ADV EXP MED BIOL, V893, P1, DOI 10.1007/978-3-319-24223-1_1
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yang H, 2020, IEEE IC COMP COM NET, DOI 10.1109/icccn49398.2020.9209630
   Zhang S, 2019, LECT NOTES COMPUT SC, V11861, P54, DOI 10.1007/978-3-030-32692-0_7
   Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029
   Zhou TX, 2020, I S BIOMED IMAGING, P377, DOI [10.1109/ISBI45749.2020.9098392, 10.1109/isbi45749.2020.9098392]
   Zhou TX, 2019, ARRAY-NY, V3-4, DOI 10.1016/j.array.2019.100004
NR 34
TC 4
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 25
BP 33779
EP 33797
DI 10.1007/s11042-021-11225-z
EA AUG 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WK6LS
UT WOS:000690516400004
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Chen, LF
   Tan, F
   Wang, SF
   Yin, BC
AF Zhang, Yong
   Chen, Lufei
   Tan, Fei
   Wang, Shaofan
   Yin, Baocai
TI An improved <i>l</i><sub>1</sub> median model for extracting 3D human
   body curve-skeleton
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE l(1) median model; Shape segmentation; Curve-skeleton extraction;
   Continuous frames optimization
ID POINT CLOUDS; OPTIMIZATION; SHAPE
AB Three-dimensional human body curve-skeleton is widely used in pose estimation, skeleton animation and other fields. This paper proposes an improved l(1) median model that can extract three-dimensional human body curve-skeleton. The model includes three-dimensional human body reconstruction from multi-view images, interpolation curve-skeleton extraction, l(1) median skeleton completion, and continuous frame curve-skeleton optimization. Through the completion and optimization processes, the curve-skeleton we extract is smoother and more complete compared with previous methods. We conduct experiments on multi-view human body image dataset collected from light field acquisition system. Both quantitative and qualitative results demonstrate the effectiveness of our model.
C1 [Zhang, Yong; Chen, Lufei; Tan, Fei; Wang, Shaofan; Yin, Baocai] Beijing Univ Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing Inst Artificial Intelligence, Fac Informat Technol, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Wang, SF (corresponding author), Beijing Univ Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing Inst Artificial Intelligence, Fac Informat Technol, Beijing 100124, Peoples R China.
EM wangshaofan@bjut.edu.cn
RI tan, fei/KOD-4737-2024; Zhang, Yong/AAW-8880-2021
OI Zhang, Yong/0000-0001-6650-6790; WANG, SHAOFAN/0000-0002-3045-624X
FU National Natural Science Foundation of China [62072015, U19B2039,
   U1811463, 61876012]; Natural Science Foundation of Beijing [4202003]
FX This work was ed in part by the National Natural Science Foundation of
   China under Grant 62072015, U19B2039, U1811463, 61876012, and in part by
   the Natural Science Foundation of Beijing under Grant 4202003.
CR Au OKC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360643
   Avron H, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1857907.1857911
   Baran I, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239523, 10.1145/1276377.1276467]
   Benzine A, 2020, PROC CVPR IEEE, P6855, DOI 10.1109/CVPR42600.2020.00689
   BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6
   Cao J., 2010, SHAP MOD INT C SMI 2, P187, DOI [DOI 10.1109/SMI.2010.25, 10.1109/SMI.2010.25]
   Chuang JH, 2004, COMPUT GRAPH-UK, V28, P907, DOI 10.1016/j.cag.2004.08.004
   de Aguiar E, 2008, COMPUT GRAPH FORUM, V27, P389, DOI 10.1111/j.1467-8659.2008.01136.x
   Dey T.K., 2006, S GEOM PROC, P143, DOI DOI 10.2312/SGP/SGP06/143-152
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461913
   James DL, 2005, ACM T GRAPHIC, V24, P399, DOI 10.1145/1073204.1073206
   Katz S, 2003, ACM T GRAPHIC, V22, P954, DOI 10.1145/882262.882369
   Kleiman Y, 2019, COMPUT GRAPH FORUM, V38, P7, DOI 10.1111/cgf.13389
   Le BH, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601161
   Liang J, 2012, PROC CVPR IEEE, P214, DOI 10.1109/CVPR.2012.6247678
   Mei J, 2017, INT J GEOGR INF SCI, V31, P999, DOI 10.1080/13658816.2016.1264075
   Moon G, 2019, IEEE I CONF COMP VIS, P10132, DOI 10.1109/ICCV.2019.01023
   Pang ZQ, 2015, COMPUT ANIMAT VIRT W, V26, P301, DOI 10.1002/cav.1658
   Pantuwong N, 2012, COMPUT ANIMAT VIRT W, V23, P125, DOI 10.1002/cav.1429
   Qi SY, 2018, LECT NOTES COMPUT SC, V11213, P407, DOI 10.1007/978-3-030-01240-3_25
   Sharf A, 2007, COMPUT GRAPH FORUM, V26, P323, DOI 10.1111/j.1467-8659.2007.01054.x
   Shen W, 2013, SCI CHINA INFORM SCI, V56, DOI 10.1007/s11432-012-4715-3
   Singh G., 2007, EUR S POINT BAS GRAP, P91, DOI [DOI 10.2312/SPBG/SPBG07/091-100, 10.2312/SPBG/SPBG07/091-100]
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Tagliasacchi A, 2012, COMPUT GRAPH FORUM, V31, P1735, DOI 10.1111/j.1467-8659.2012.03178.x
   Tagliasacchi A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531377
   Wandt B, 2019, PROC CVPR IEEE, P7774, DOI 10.1109/CVPR.2019.00797
   Wang K., 2015, MULTIMED TOOLS APPL, V75, P1
   Wang WG, 2019, IEEE I CONF COMP VIS, P5702, DOI 10.1109/ICCV.2019.00580
   Wang WG, 2018, PROC CVPR IEEE, P4271, DOI 10.1109/CVPR.2018.00449
   Wenguan Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8926, DOI 10.1109/CVPR42600.2020.00895
   Zhang Dejia, 2015, Journal of Computer Aided Design & Computer Graphics, V27, P1247
   Zhang Y, 2018, ISPRS J PHOTOGRAMM, V143, P124, DOI 10.1016/j.isprsjprs.2018.04.016
   Zheng Q, 2010, COMPUT GRAPH FORUM, V29, P635, DOI 10.1111/j.1467-8659.2009.01633.x
   Zhou TF, 2020, PROC CVPR IEEE, P4262, DOI 10.1109/CVPR42600.2020.00432
   Zimovnov Andrey, 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P666
NR 39
TC 3
Z9 4
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 24
BP 33547
EP 33571
DI 10.1007/s11042-021-11373-2
EA AUG 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WJ3HO
UT WOS:000686512700003
DA 2024-07-18
ER

PT J
AU Ning, XJ
   Tian, G
   Wang, YH
AF Ning, Xiaojuan
   Tian, Ge
   Wang, Yinghui
TI Shape classification guided method for automated extraction of urban
   trees from terrestrial laser scanning point clouds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Terrestrial laser scanning; Feature extraction; Shape classification;
   Tree extraction; Candidate tree trunk
ID INDIVIDUAL TREES; STREET TREES; SEGMENTATION; MODELS; FEATURES
AB Accurate detection and extraction of individual trees is one of hottest topics, which can be widely used in vehicles navigation, tree modeling, tree growth monitoring and urban green quantity estimation. The difficulty associated with individual trees extraction is the occlusion with other objects in cluttered point clouds of urban scenes, which inhibits the automatic extraction of individual trees. In this paper, we present a comprehensive framework that can be used to extract individual trees from terrestrial scanned outdoor scene. In our framework, a bottom-up method by shape-guided classification is achieved to select the candidate tree crowns and tree trunks, and a novel three-stage shape merging rule containing localization, filtering, and matching (LFM) are proposed to generate a complete individual tree. The primary advantage of the proposed method is that it is independent of the quality of data and different shapes. We made comparison experiments of classification methods of support vector machine and random forest on the accuracy assessment. The effectiveness of the proposed framework was tested in five street scenarios in point clouds from Oakland outdoor MLS dataset. The results for the five test sites achieved tree detection rates higher than 97%; the overall accuracy was approximately 98%, and the completion quality of both procedures was 96%. Non-detected trees are always sparse which come from occlusions in the point cloud data; most misclassifications occurred in man-made pillars adjacent to trees and have the same height with tree trunk. Comparison experiments to the existing methods are made to illustrate the effectiveness of our method.
C1 [Ning, Xiaojuan; Tian, Ge; Wang, Yinghui] Xian Univ Technol, Inst Comp Sci & Engn, Xian, Peoples R China.
C3 Xi'an University of Technology
RP Ning, XJ (corresponding author), Xian Univ Technol, Inst Comp Sci & Engn, Xian, Peoples R China.
EM fly-snow2001@163.com
RI wang, yinghui/GWV-7334-2022
OI Ning, xiaojuan/0000-0001-9764-5400
FU National Natural Science Foundation of China [61871320, 61872291];
   National Key Research and Development Project of China [2018YFB1004905];
   China Postdoctoral Science Foundation [2014M552469]; Key laboratory
   project of Shaanxi Provincial Education Department [17JS099]; Shaanxi
   Postdoctoral Science Foundation [434015014]
FX This work was supported in part by National Natural Science Foundation
   of China (Nos.61871320, 61872291); in part by National Key Research and
   Development Project of China (2018YFB1004905); in part by China
   Postdoctoral Science Foundation (2014M552469); in part by Key laboratory
   project of Shaanxi Provincial Education Department (17JS099); in part by
   Shaanxi Postdoctoral Science Foundation (434015014).
CR Vo AV, 2015, ISPRS J PHOTOGRAMM, V104, P88, DOI 10.1016/j.isprsjprs.2015.01.011
   [Anonymous], 2013, INT S MOB MAPP TECHN
   Barnea S, 2013, ISPRS J PHOTOGRAMM, V76, P33, DOI 10.1016/j.isprsjprs.2012.05.001
   Bienert A, 2012, TREE DETECTION DIAME, P50
   Bonneau DA, 2020, REMOTE SENS ENVIRON, V251, DOI 10.1016/j.rse.2020.112098
   Börcs A, 2017, IEEE GEOSCI REMOTE S, V14, P992, DOI 10.1109/LGRS.2017.2674799
   Demantké J, 2011, INT ARCH PHOTOGRAMM, V38-5, P97
   Dimitrov A, 2015, AUTOMAT CONSTR, V51, P32, DOI 10.1016/j.autcon.2014.12.015
   Dold C, 2004, AUTOMATIC MATCHING T
   Guan HY, 2014, ISPRS J PHOTOGRAMM, V87, P93, DOI 10.1016/j.isprsjprs.2013.11.005
   Husain A, 2020, REMOTE SENS APPL, V20, DOI 10.1016/j.rsase.2020.100371
   Hyyppä J, 2001, IEEE T GEOSCI REMOTE, V39, P969, DOI 10.1109/36.921414
   Jaakkola A, 2010, ISPRS J PHOTOGRAMM, V65, P514, DOI 10.1016/j.isprsjprs.2010.08.002
   Jutras P, 2009, COMPUT ELECTRON AGR, V67, P9, DOI 10.1016/j.compag.2009.02.008
   Lalonde JF, 2006, J FIELD ROBOT, V23, P839, DOI 10.1002/rob.20134
   Li JL, 2013, AGR FOREST METEOROL, V171, P104, DOI 10.1016/j.agrformet.2012.11.012
   Li L, 2016, ISPRS J PHOTOGRAMM, V120, P37, DOI 10.1016/j.isprsjprs.2016.07.009
   Liang ZY, 2020, IEEE T IMAGE PROCESS, V29, P3351, DOI 10.1109/TIP.2019.2959256
   Lindenbergh RC, 2015, INT ARCH PHOTOGRAMM, V40-3, P589, DOI 10.5194/isprsarchives-XL-3-W3-589-2015
   Liu L, 2019, COMPUT ELECTRON AGR, V163, DOI 10.1016/j.compag.2019.104871
   Liu XY, 2017, LECT NOTES COMPUT SC, V10345, P115, DOI 10.1007/978-3-319-65849-0_14
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Lu XC, 2014, ISPRS J PHOTOGRAMM, V94, P1, DOI 10.1016/j.isprsjprs.2014.03.014
   Ma LF, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101531
   Maalek R, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030819
   Mayr A, 2017, PHOTOGRAMM REC, V32, P377, DOI 10.1111/phor.12215
   Monnier F., 2012, TREES DETECTION LASE
   Munoz D, 2009, PROC CVPR IEEE, P975, DOI 10.1109/CVPRW.2009.5206590
   Ning XJ, 2019, ADV ELECTR COMPUT EN, V19, P11, DOI 10.4316/AECE.2019.03002
   Pu S, 2011, ISPRS J PHOTOGRAMM, V66, pS28, DOI 10.1016/j.isprsjprs.2011.08.006
   Puttonen E, 2011, SENSORS-BASEL, V11, P5158, DOI 10.3390/s110505158
   Qinghao Meng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P515, DOI 10.1007/978-3-030-58601-0_31
   Rabbani T, 2007, ISPRS J PHOTOGRAMM, V61, P355, DOI 10.1016/j.isprsjprs.2006.09.006
   Ramiya AM, 2019, REMOTE SENS APPL, V15, DOI 10.1016/j.rsase.2019.100242
   Raumonen P, 2013, REMOTE SENS-BASEL, V5, P491, DOI 10.3390/rs5020491
   Rutzinger M, 2011, PHOTOGRAMM REC, V26, P361, DOI 10.1111/j.1477-9730.2011.00635.x
   ShenJ TangX, 2019, IEEE T CYBERNETICS, P1
   Shi ZW, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10121891
   Sirmacek B, 2015, ISPRS ANN PHOTO REM, VII-3, P137, DOI 10.5194/isprsannals-II-3-W5-137-2015
   Trochta J, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0176871
   Vanegas CA, 2012, IEEE T VIS COMPUT GR, V18, P1627, DOI 10.1109/TVCG.2012.30
   Vosselman G, 2013, INT ARCH PHOTOGRAMM, V40-7-W2, P257, DOI 10.5194/isprsarchives-XL-7-W2-257-2013
   Wang JH, 2018, PHOTOGRAMM REC, V33, P315, DOI 10.1111/phor.12247
   Wang YS, 2008, SENSORS-BASEL, V8, P3938, DOI 10.3390/s8063938
   Weinmann M., 2016, Reconstruction and Analysis of 3D Scenes, VVolume 1
   Weinmann M, 2015, ISPRS J PHOTOGRAMM, V105, P286, DOI 10.1016/j.isprsjprs.2015.01.016
   Williams J, 2020, IEEE T GEOSCI REMOTE, V58, P754, DOI 10.1109/TGRS.2019.2940146
   Wu B, 2013, REMOTE SENS-BASEL, V5, P584, DOI 10.3390/rs5020584
   Xiang BB, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), P172, DOI 10.1109/ICInfA.2016.7831817
   Xu S, 2018, INT J APPL EARTH OBS, V69, P64, DOI 10.1016/j.jag.2018.02.016
   Xu S, 2018, REMOTE SENS LETT, V9, P515, DOI [10.1080/2150704X.2018.1444286, 10.1080/2150704x.2018.1444286]
   Yang BS, 2013, ISPRS J PHOTOGRAMM, V81, P19, DOI 10.1016/j.isprsjprs.2013.04.002
   YANG J, 2020, IEEE J-STARS, P1
   Yin J, 2020, COMPUT VIS PATTERN R
   Zhong LS, 2017, IEEE J-STARS, V10, P774, DOI 10.1109/JSTARS.2016.2565519
   Zhong RF, 2013, MATH COMPUT MODEL, V58, P727, DOI 10.1016/j.mcm.2012.12.038
NR 56
TC 4
Z9 4
U1 4
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 24
BP 33357
EP 33375
DI 10.1007/s11042-021-11328-7
EA AUG 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WJ3HO
UT WOS:000686512900001
DA 2024-07-18
ER

PT J
AU Ali, S
   Hafeez, Y
   Abbas, MA
   Aqib, M
   Nawaz, A
AF Ali, Sadia
   Hafeez, Yaser
   Abbas, Muhammad Azeem
   Aqib, Muhammad
   Nawaz, Asif
TI Enabling remote learning system for virtual personalized preferences
   during COVID-19 pandemic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distance education; COVID-19; Augmented and virtual reality;
   Recommendation system; Teaching; learning strategies; Architectures for
   educational technology system; Text mining
ID FRAMEWORK; NOVELTY
AB The education system worldwide has been affected by the Corona Virus Diseases 2019 (COVID-19) pandemic, resulting in the interruption of all educational institutions. Moreover, as a precautionary measure, the lockdown has been imposed that has severely affected the learning processes, especially assessment activities, including exams and viva. In such challenging situations, E-learning platforms could play a vital role in conducting seamless academic activities. In spite of all the advantages of remote learning systems, many hurdles and obstacles, like a selection of suitable learning resources/material encounter by individual users based on their interests or requirements. Especially those who are not well familiar with the internet technology in developing countries and are in need of a platform that could help them in resolving the issues related to the online virtual environment. Therefore, in this work, we have proposed a mechanism that intelligently and correctly predicts the appropriate preferences for the selection of resources relevant to a specific user by considering the capabilities of diverse perspectives users to provide quality online education and to make work from home policy more effective and progressive during the pandemic. The proposed system helps teachers in providing quality online education, familiarizing them with advanced technology in the online environment. It also semantically predicts the preferences for virtual assistance of those users who are in need of learning the new tools and technologies in short time as per their institutional requirements in order to meet the quality standards of online education. The experimental and statistical results have demonstrated that the proposed virtual personalized preferences system has improved overall academic activities as compared to the current method. The proposed system enhanced user's learning abilities and facilitated them in selecting short courses while using different online education tools adopted/suggested by the institutions to conduct online classes/seminars/webinars etc., as compared to the conventional classes/activities.
C1 [Ali, Sadia; Hafeez, Yaser; Abbas, Muhammad Azeem; Aqib, Muhammad; Nawaz, Asif] PMAS Arid Agr Univ, Univ Inst Informat Technol, Rawalpindi, Pakistan.
C3 Arid Agriculture University
RP Ali, S (corresponding author), PMAS Arid Agr Univ, Univ Inst Informat Technol, Rawalpindi, Pakistan.
EM sadiaalief@gmail.com
RI Aqib, Muhammad/HSH-2004-2023; Abbas, Muhammad Azeem/L-8148-2015
OI Abbas, Muhammad Azeem/0000-0001-9536-0065
CR Aher SB, 2013, KNOWL-BASED SYST, V51, P1, DOI 10.1016/j.knosys.2013.04.015
   Arias M, 2018, ELECTRON NOTES THEOR, V339, P5, DOI 10.1016/j.entcs.2018.06.002
   Baloian N, 2016, INFORM SYST FRONT, V18, P125, DOI 10.1007/s10796-015-9580-3
   Bank W, 2020, REM LEARN DIST ED ON
   Bawazir A, 2018, J INFECT PUBLIC HEAL, V11, P89, DOI 10.1016/j.jiph.2017.05.003
   Beer UM, 2017, EUR J PSYCHOTRAUMATO, V8, DOI 10.1080/20008198.2017.1378053
   Brigui-Chtioui I, 2017, P 9 INT C MACH LEARN, P71, DOI DOI 10.1145/3055635.3056592
   Campos R, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P193, DOI 10.1109/IRI.2018.00036
   Cao WJ, 2020, PSYCHIAT RES, V287, DOI 10.1016/j.psychres.2020.112934
   CEREZO R, 2019, J COMPUT HIGH EDUC
   Chabrun F, 2020, FRONT GENET, V10, DOI 10.3389/fgene.2019.01292
   Chavarriaga O, 2014, LECT NOTES COMPUT SC, V8719, P56, DOI 10.1007/978-3-319-11200-8_5
   Choi CR, 2019, MULTIMED TOOLS APPL, V78, P28853, DOI 10.1007/s11042-019-7351-8
   Dandouh K, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0169-4
   Elazony M, 2018, DESIGN IMPLEMENTATIO, V3, P17
   Fraihat Salam, 2015, Journal of Software, V10, P317, DOI 10.17706/jsw.10.3.317-330
   Fridin M, 2014, INT J HUM-COMPUT INT, V30, P459, DOI 10.1080/10447318.2014.888500
   Graics B, 2020, SOFTW SYST MODEL, V19, P1483, DOI 10.1007/s10270-020-00806-5
   Hwang GJ, 2019, INTERACT LEARN ENVIR, V27, P567, DOI 10.1080/10494820.2018.1486861
   Hwang GJ, 2011, COMPUT EDUC, V56, P1023, DOI 10.1016/j.compedu.2010.12.002
   Jeno LM, 2019, COMPUT EDUC, V128, P398, DOI 10.1016/j.compedu.2018.10.008
   Khribi MK, 2008, 8TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P241, DOI 10.1109/ICALT.2008.198
   Klasnja-Milicevic A, 2018, APPL INTELL, V48, P1519, DOI 10.1007/s10489-017-1051-8
   Li YT, 2020, NEURAL PROCESS LETT, V52, P1613, DOI 10.1007/s11063-020-10329-1
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P18, DOI 10.1109/MIC.2020.2969610
   Li YT, 2018, IET COMMUN, V12, P751, DOI 10.1049/iet-com.2017.0502
   LINDER S, 1973, J EXP EDUC, V42, P44
   Oza KS, 2016, PROCEDIA COMPUT SCI, V92, P468, DOI 10.1016/j.procs.2016.07.369
   Palombi O, 2019, ARTIF INTELL MED, V96, P59, DOI 10.1016/j.artmed.2019.03.006
   Pecori R, 2018, FUTURE INTERNET, V10, DOI 10.3390/fi10010004
   Perron BE, 2019, CHILD ABUSE NEGLECT, V98, DOI 10.1016/j.chiabu.2019.104180
   Poppenk J, 2010, J EXP PSYCHOL LEARN, V36, P1321, DOI 10.1037/a0019900
   Qi JX, 2020, NEURAL COMPUT APPL, V32, P6343, DOI 10.1007/s00521-019-04142-8
   QIU L, 2019, J COMPUT HIGH EDUC
   Sarwar S, 2019, MULTIMED TOOLS APPL, V78, P34745, DOI 10.1007/s11042-019-08125-8
   Setiawan A.R., 2020, Scientific Literacy Worksheets for Distance Learning in the Topic of Coronavirus 2019 (COVID-19)
   Shahzad Arfan, 2021, Qual Quant, V55, P805, DOI 10.1007/s11135-020-01028-z
   Sharif N., 2015, P 7 INT C MAN COMP C, P137
   Sheoran K, 2020, COGN NEURODYNAMICS, V14, P509, DOI 10.1007/s11571-020-09585-7
   Swadia J., 2016, STUDY TEXT MINING FR
   Tsay CHH, 2020, J COMPUT ASSIST LEAR, V36, P128, DOI 10.1111/jcal.12385
   Viner RM, 2020, LANCET CHILD ADOLESC, V4, P397, DOI 10.1016/S2352-4642(20)30095-X
   Zaw SK, 2019, J COMPUT NETW COMMUN, V2019, DOI 10.1155/2019/7198435
NR 43
TC 9
Z9 9
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 24
BP 33329
EP 33355
DI 10.1007/s11042-021-11414-w
EA AUG 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA WJ3HO
UT WOS:000685385700001
PM 34421330
OA Green Published, hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Chahal, ES
   Patel, A
   Gupta, A
   Purwar, A
   Dhanalekshmi, G
AF Chahal, Ekam Singh
   Patel, Aarya
   Gupta, Ayush
   Purwar, Archana
   Dhanalekshmi, G.
TI Unet based Xception Model for Prostate Cancer Segmentation from MRI
   Images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Prostate Segmentation; Convolution Neural Network (CNN); Magnetic
   Resonance Imaging (MRI); Deep Learning
ID NETWORK
AB One of the most prevalent forms of tumor found in males all over the world is prostate cancer. The main risk factors are age and family history. Magnetic Resonance Imaging (MRI) is highly recommended for detecting and localizing prostate cancer. It is very important for precise segmentation of the prostate region in MRI scans to improve the treatment possibilities and the chance of patient survival with prostate cancer. Manually segmenting the prostate region is a daunting task and often time-consuming because of the variation in shapes of prostates among patients, poor delineation of the boundary, and the use of different MRI modes. In this paper, we propose an automatic segmentation model for the prostate regions in MRI scans based on Unet and Xception net. To boost the performance of model, local residual connections are added in the decoder stage of the Unet. The empirical results are compared to different Unet based models with different preprocessing methods to assess the effectiveness of the proposed model. The experimentations are performed to support the fact that the proposed model performs better than other methods taken under study.
C1 [Chahal, Ekam Singh; Patel, Aarya; Gupta, Ayush; Purwar, Archana; Dhanalekshmi, G.] Jaypee Inst Informat Technol, Dept Comp Sci & Engn Informat Technol, Noida, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Purwar, A (corresponding author), Jaypee Inst Informat Technol, Dept Comp Sci & Engn Informat Technol, Noida, India.
EM ecsingh1997@gmail.com; aaryapatel98@gmail.com; ayushgupta2959@gmail.com;
   archana.purwar@gmail.com; dhanalekshmig@gmail.com
RI Patel, Aarya/GRY-3209-2022
OI Patel, Aarya/0000-0003-3244-5445
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Canziani A., 2016, An Analysis of Deep Neural Network Models for Practical Applications
   Cho C, 2017, IEEE IMAGE PROC, P3071, DOI 10.1109/ICIP.2017.8296847
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dorothy R., 2015, Int J Nano Corros Sci Eng, V2, P21
   Ghasab MAJ, 2017, IEEE IMAGE PROC, P4452, DOI 10.1109/ICIP.2017.8297124
   Gillespie D, 2020, ARXIV PREPRINT ARXIV
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hossain MS, 2018, LECT NOTES COMPUT SC, V11307, P510, DOI 10.1007/978-3-030-04239-4_46
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Jia HZ, 2018, NEUROCOMPUTING, V275, P1358, DOI 10.1016/j.neucom.2017.09.084
   Jia HZ, 2017, I S BIOMED IMAGING, P762, DOI 10.1109/ISBI.2017.7950630
   Liao S, 2013, LECT NOTES COMPUT SC, V8150, P254, DOI 10.1007/978-3-642-40763-5_32
   Litjens G, 2020, PROMISE12 GRAND CHAL
   Litjens G, 2014, MED IMAGE ANAL, V18, P359, DOI 10.1016/j.media.2013.12.002
   Liu QD, 2020, IEEE T MED IMAGING, V39, P2713, DOI 10.1109/TMI.2020.2974574
   Liu XL, 2019, ARTIF INTELL REV, V52, P1089, DOI 10.1007/s10462-018-9641-3
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   To NN, 2018, INT J COMPUT ASS RAD, V13, P1687, DOI 10.1007/s11548-018-1841-4
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Song S., 2017, BIOMED ENG REV, V1, P2375, DOI 10.18103/bme.v3i1.1550
   Tustison NJ, 2010, IEEE T MED IMAGING, V29, P1310, DOI 10.1109/TMI.2010.2046908
   Vincent G, 2012, FULLY AUTOMATIC SEGM
   Yan PK, 2010, IEEE T BIO-MED ENG, V57, P1158, DOI 10.1109/TBME.2009.2037491
   Yoo S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-55972-4
   Yu LQ, 2017, AAAI CONF ARTIF INTE, P66
   Zhang L, 2021, ALEX ENG J, V60, P897, DOI 10.1016/j.aej.2020.10.018
   Zhou WH, 2020, DIGIT SIGNAL PROCESS, V98, DOI 10.1016/j.dsp.2019.102649
   Zhu QK, 2017, IEEE IJCNN, P178, DOI 10.1109/IJCNN.2017.7965852
NR 32
TC 13
Z9 14
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37333
EP 37349
DI 10.1007/s11042-021-11334-9
EA AUG 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000684785000005
DA 2024-07-18
ER

PT J
AU Lee, JM
   Kang, DS
AF Lee, Jun-Mock
   Kang, Dae-seong
TI Improved method for learning data imbalance in gender classification
   model using DA-FSL
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Few-shot learning; Image classification; Generative adversarial network;
   Data augmentation; Artificial intelligence
AB As the deep learning technology grows, the accuracy of the training data to improve the model becomes important. If there are not enough learning data between classes, there is a problem that the accuracy of the deep learning model is greatly reduced. In this paper, we propose a method to solve data imbalance caused by the difficulty of collecting learning data through DA-FSL(Data Augmentation based Few-Shot Learning). The proposed method is to separate the class with the data imbalance and the normal class, and to re-learn by creating the data of the data imbalance class through DA-FSL. It adopts GAN(Generative Adversarial Network) architecture, then initialize through mapping network to improve the generation accuracy and speed of new latent vector. The purpose of this paper is to verify whether the data imbalance of gender classification model can be solved through the experiments applied by the proposed method and to prove its effectiveness.
C1 [Lee, Jun-Mock; Kang, Dae-seong] Dong A Univ, Dept Elect Engn, Busan, South Korea.
C3 Dong A University
RP Kang, DS (corresponding author), Dong A Univ, Dept Elect Engn, Busan, South Korea.
EM mogilee@dau.ac.kr; dskang@dau.ac.kr
OI Lee, Jun Mock/0000-0002-2454-0672
FU National Research Foundation of Korea (NRF) - Korean Government
   [2017R1D1A1B04030870]
FX This work was supported by the National Research Foundation of Korea
   (NRF) Grant funded by the Korean Government (NO. 2017R1D1A1B04030870).
CR [Anonymous], 2012, PASCAL VOC
   [Anonymous], ANIMAL SPECIES IMAGE
   [Anonymous], CS231N CONVOLUTIONAL
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Estabrooks A, 2004, COMPUT INTELL-US, V20, P18, DOI 10.1111/j.0824-7935.2004.t01-1-00228.x
   Fan W., 2010, INT J SOC HUMAN COMP, V1, P282, DOI [10.1504/IJSHC.2010.032689, DOI 10.1504/IJSHC.2010.032689]
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Holland O, 2016, 2016 23RD INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (ICT), DOI 10.1109/ICT.2016.7500442
   Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Japkowicz N., 2002, Intelligent Data Analysis, V6, P429
   Jiang L., 2018, INT C MACH LEARN
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Li D, 2019, IEEE I CONF COMP VIS, P1446, DOI 10.1109/ICCV.2019.00153
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Purkait P., 2017, ARXIV171203452
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rodrigues Andreia, 2010, International Journal of Social and Humanistic Computing, V1, P246, DOI 10.1504/IJSHC.2010.032686
   Snell J, 2017, ADV NEUR IN, V30
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wang C, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3670
NR 27
TC 0
Z9 0
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34403
EP 34421
DI 10.1007/s11042-021-11309-w
EA AUG 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000684785000001
DA 2024-07-18
ER

PT J
AU Velpula, P
   Pamula, R
AF Velpula, Prasad
   Pamula, Rajendra
TI EBGO: an optimal load balancing algorithm, a solution for existing
   tribulation to balance the load efficiently on cloud servers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big Data; Cloud computing; Cloud Technology; Energy efficiency; Internet
   of Things (IoT); Health Care Systems; Load balancing; Performance
   Optimization; Quality of Service (QoS); Resource utilization; Time To
   Live (TTL)
ID FRAMEWORK
AB A burning challenge is balancing the demand for servers in computer data centers. In the modern era, the bulk of computer systems are used for big data and cloud computing. The Internet of Things (IoT) is becoming a hyper-world of physical, cyber and social worlds with big data as a connection. In the latest systems architectures, managing the load in cloud applications is a major challenge. While several techniques and algorithms have been framed to achieve optimality in the load balancing definition, they are limited to the current problems of that time. However, due to a massive increase in data to be handled for the computing activities that are running on servers, exponential petabytes of data that are stored, the complexity of the problem increases day by day. By efficiently balancing the load and high utilization of the available resources from the computing pool, the solution to such problems can be achieved. When these are performed professionally, optimum values can be accomplished with the prominent use of available resources. Genetic Algorithms, Bacteria Foraging, optimizes the algorithm, Artificial Bee Colony, Optimized ABC are current trending algorithms used in load balancing concepts. All these trending algorithms, while strong, lack certain factors. To overcome them, we proposed an EBGO algorithm that has overcome the disadvantages of the trending load balancing algorithms in terms of certain significant parameters such as response time, energy consumption, weighted total cost, procession time, and many. This model aims to achieve overall optimal parameter values, thus efficiently balancing the demand on servers in data centers, resulting in optimal resource use. This model is often appropriate for health care systems, where large number of different types of systems and data are shared between them.
C1 [Velpula, Prasad; Pamula, Rajendra] Indian Inst Technol ISM, Dept CSE, Dhanbad, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Velpula, P (corresponding author), Indian Inst Technol ISM, Dept CSE, Dhanbad, Bihar, India.
EM officialmail2vprasad@gmail.com; rajendra@iitism.ac.in
RI Pamula, Rajendra/V-9454-2019
OI Pamula, Rajendra/0000-0002-4806-3495
CR Ahmed A, 2018, MULTIMED TOOLS APPL, V77, P21947, DOI 10.1007/s11042-017-5540-x
   Aldribi A., 2018, Cloud computing for optimization: foundations, applications
   Amiri M, 2017, J NETW COMPUT APPL, V82, P93, DOI 10.1016/j.jnca.2017.01.016
   Aslam S, 2015, 2015 NATIONAL SOFTWARE ENGINEERING CONFERENCE (NSEC), P30, DOI 10.1109/NSEC.2015.7396341
   BABOU CSM, IEEE ACCESS
   Barik H, 2020, INT C COMP SCI ENG A, V2020, P1, DOI [10.1109/ICCSEA49143.2020.9132838, DOI 10.1109/ICCSEA49143.2020.9132838]
   Barik RK, 2018, STUD BIG DATA, V39, P367, DOI 10.1007/978-3-319-73676-1_14
   Chaudhury KS., 2020, ADV INTELLIGENT SYST, DOI 10.1007/978-981-15-2475-2_24
   Chen HK, 2013, 2013 NATIONAL CONFERENCE ON PARALLEL COMPUTING TECHNOLOGIES (PARCOMPTECH), DOI [10.1007/s11063-013-9318-5, 10.1109/ParCompTech.2013.6621389]
   Dam S., 2014, ADV COMPUTING NETWOR, V2, DOI 10.1007/978-3-319-07350-7_45
   Das S, 2009, IEEE T SYST MAN CY A, V39, P670, DOI 10.1109/TSMCA.2008.2011474
   Du K.L., 2019, Neural Networks and Statistical Learning
   Ebadifard F, 2020, 2020 6TH INTERNATIONAL CONFERENCE ON WEB RESEARCH (ICWR), P177, DOI [10.1109/ICWR49608.2020.9122287, 10.1109/icwr49608.2020.9122287]
   Elrotub M, 2018, PROCEDIA COMPUT SCI, V130, P683, DOI 10.1016/j.procs.2018.04.120
   Essa YM, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1250-4
   [顾熹 Gu Xi], 2017, [电力系统保护与控制, Power System Protection and Control], V45, P73
   Hu JJ, 2020, 2020 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA (ICAIBD 2020), P83, DOI [10.1109/ICAIBD49809.2020.9137481, 10.1109/icaibd49809.2020.9137481]
   Jing Yao, 2012, Proceedings of the 2012 8th International Conference on Computing Technology and Information Management (NCM and ICNIT), P185
   Kapoor S, 2015, INT CONF CONTEMP, P76, DOI 10.1109/IC3.2015.7346656
   Kong WC, 2019, IEEE T SMART GRID, V10, P841, DOI 10.1109/TSG.2017.2753802
   Lim J, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040686
   Maheswari SU, 2020, MULTIMED TOOLS APPL, V79, P4075, DOI 10.1007/s11042-019-7724-z
   Mohiddin S., 2019, UNIQUE METHODOLOGY M, V8, P1569, DOI [10.35940/ijitee.A1037.0881019, DOI 10.35940/IJITEE.A1037.0881019]
   Mohiddin SK, 2020, ADV INTELL SYST, V1057, P91, DOI 10.1007/978-981-15-0184-5_9
   Mohiddin SK, 2019, ADV INTELL SYST, V817, P509, DOI 10.1007/978-981-13-1595-4_41
   Mohiddin SK, 2019, IJITEE, P2278
   Mulla BP, 2020, INT J COMPUTER NETWO, V12
   Muthulakshmi B, 2019, CLUSTER COMPUT, V22, P10769, DOI 10.1007/s10586-017-1174-z
   Nace D, 2008, IEEE COMMUN SURV TUT, V10, P5, DOI 10.1109/SURV.2008.080403
   Nasr AA, 2019, J INTERNET TECHNOL, V20, P1371, DOI 10.3966/160792642019092005005
   Nayak L., 2020, LECT NOTES DATA ENG, DOI 10.1007/978-3-030-43192-1_4
   Nayyar A, 2020, MULTIMED TOOLS APPL, V79, P35221, DOI 10.1007/s11042-019-7627-z
   Peng K, 2020, IET CYBER PHYS SYST, V5, P196, DOI 10.1049/iet-cps.2019.0085
   Remesh Babu KR., 2016, ADV INTELLIGENT SYST, DOI 10.1007/978-3-319-28031-8_6
   SAIF T, 2019, ADV P2P PARALLEL GRI
   Seema B, 2020, MULTIMED TOOLS APPL, V79, P34241, DOI 10.1007/s11042-020-08775-z
   Semmoud A, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5652
   Stanojevic R, 2009, IEEE ICC, P1091
   Stavrinides GL, 2021, MULTIMED TOOLS APPL, V80, P16781, DOI 10.1007/s11042-020-08974-8
   Wang JZ, 2018, ENERGY, V148, P59, DOI 10.1016/j.energy.2018.01.112
   Xu MX, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.4123
   Zomaya AY, 2001, IEEE T PARALL DISTR, V12, P899, DOI 10.1109/71.954620
NR 42
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34653
EP 34675
DI 10.1007/s11042-021-11012-w
EA AUG 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000681607900001
DA 2024-07-18
ER

PT J
AU Faisal, A
   Khalil, A
   Chai, HY
   Lai, KW
AF Faisal, Amir
   Khalil, Azira
   Chai, Hum Yan
   Lai, Khin Wee
TI X-ray carpal bone segmentation and area measurement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Area measurement; Carpal bone; Image segmentation; Level set method;
   X-ray imaging
ID AGE ASSESSMENT; IMAGE SEGMENTATION; CHILDREN
AB A computerized bone age assessment requires segmentation of the X-ray carpal bones from other undesired tissue regions. This paper presents segmentation and area measurement of carpal bones in X-ray images. The locally weighted K-means variational level set was applied in segmenting 67 X-ray carpal bone datasets. Dice coefficient and Hausdorff distance measures show mean values above 0.7 and around 3 pixels, respectively. These satisfying segmentation outcomes enable the carpal bone areas to be measured on the segmented images. The carpal bone area measurement ranged from 4.24 mm to 48.96 mm with a mean value of 20.70 +/- 10.51 mm and various values of the Pearson's correlation coefficient implies that the segmentation method is insensitive to different carpal bone areas and locations. These results suggest that the methods can be applied in the bone age assessment by quantifying changes in the carpal bone area over certain time intervals.
C1 [Faisal, Amir] Inst Teknol Sumatera, Dept Prod & Ind Engn, Biomed Engn Study Program, Lampung Selatan 35365, Indonesia.
   [Khalil, Azira] Univ Sains Islam Malaysia, Fac Sci & Technol, Nilai 71800, Negeri Sembilan, Malaysia.
   [Chai, Hum Yan] Univ Tunku Abdul Rahman, Fac Sci & Engn, Dept Mechatron & Biomed Engn, Kajang 43000, Selangor, Malaysia.
   [Lai, Khin Wee] Univ Malaya, Dept Biomed Engn, Kuala Lumpur 50603, Malaysia.
C3 Universiti Sains Islam Malaysia; Universiti Tunku Abdul Rahman (UTAR);
   Universiti Malaya
RP Faisal, A (corresponding author), Inst Teknol Sumatera, Dept Prod & Ind Engn, Biomed Engn Study Program, Lampung Selatan 35365, Indonesia.
EM amir.faisal@bm.itera.ac.id
RI Khalil, Azira/JVY-6923-2024; Lai, Khin Wee/A-2997-2011; Faisal,
   Amir/C-2794-2016; Hum, Yan Chai/H-9021-2018; KHALIL, AZIRA/G-9340-2017
OI Lai, Khin Wee/0000-0002-8602-0533; Faisal, Amir/0000-0002-4693-2490;
   Hum, Yan Chai/0000-0002-9657-8311; KHALIL, AZIRA/0000-0003-0661-0064
CR Adeshina S. A., 2014, ELECT COMPUTER COMPU, P1
   [Anonymous], 2009, Insight J
   Benedick A, 2021, J BONE JOINT SURG AM, V103, P795, DOI 10.2106/JBJS.20.00404
   Cao F, 2000, COMPUT MED IMAG GRAP, V24, P297, DOI 10.1016/S0895-6111(00)00026-4
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Fancourt HSM, 2021, J FORENSIC SCI, V66, P821, DOI 10.1111/1556-4029.14681
   Gertych A, 2007, COMPUT MED IMAG GRAP, V31, P322, DOI 10.1016/j.compmedimag.2007.02.012
   Gertych A, 2007, PATTERN ANAL APPL, V10, P115, DOI 10.1007/s10044-006-0056-4
   Giavarina D, 2015, BIOCHEM MEDICA, V25, P141, DOI 10.11613/BM.2015.015
   Giordano D, 2010, IEEE T INSTRUM MEAS, V59, P2539, DOI 10.1109/TIM.2010.2058210
   Han CC, 2007, PATTERN RECOGN, V40, P2994, DOI 10.1016/j.patcog.2007.01.010
   Jonsson K., 2002, ACTA RADIOL, V43, P236, DOI [10.1034/j.1600-0455.2002.430228_5.x, DOI 10.1034/J.1600-0455.2002.430228_5.X]
   Kim JR, 2017, AM J ROENTGENOL, V209, P1374, DOI 10.2214/AJR.17.18224
   Koc U, 2021, JPN J RADIOL, V39, P267, DOI 10.1007/s11604-020-01055-8
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li SW, 2022, COMPLEX INTELL SYST, V8, P1929, DOI 10.1007/s40747-021-00376-z
   Liu J, 2008, COMPUT MED IMAG GRAP, V32, P678, DOI 10.1016/j.compmedimag.2008.08.005
   Mahmoodi S, 2000, IEEE T INF TECHNOL B, V4, P292, DOI 10.1109/4233.897061
   McGill, 2021, ENDOCRINE CONDITIONS, P215
   Meng LK, 2019, CURR MED IMAGING, V15, P983, DOI 10.2174/1573405615666190724101600
   Peloschek P, 2009, EUR J RADIOL, V72, P252, DOI 10.1016/j.ejrad.2009.05.053
   PIETKA E, 1993, IEEE T MED IMAGING, V12, P44, DOI 10.1109/42.222665
   Sebastian TB, 2003, MED IMAGE ANAL, V7, P21, DOI 10.1016/S1361-8415(02)00065-8
   Shen LQ, 2012, IEEE T IMAGE PROCESS, V21, P2582, DOI 10.1109/TIP.2011.2177849
   Somkantha K, 2011, J DIGIT IMAGING, V24, P1044, DOI 10.1007/s10278-011-9372-3
   Sotoca JM, 2003, COMPUT MED IMAG GRAP, V27, P459, DOI 10.1016/S0895-6111(03)00053-3
   Su LL, 2018, IEEE ACCESS, V6, P19993, DOI 10.1109/ACCESS.2018.2815031
   Tanner, 1975, AM J HUM BIOL
   TANNER JM, 1994, J PEDIATR ENDOCRINOL, V7, P141
   Zhang AF, 2007, COMPUT MED IMAG GRAP, V31, P299, DOI 10.1016/j.compmedimag.2007.02.008
   Zhang KH, 2016, IEEE T CYBERNETICS, V46, P546, DOI 10.1109/TCYB.2015.2409119
NR 32
TC 6
Z9 6
U1 5
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37321
EP 37332
DI 10.1007/s11042-021-11281-5
EA JUL 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000679633100002
DA 2024-07-18
ER

PT J
AU Karthika, KP
   Sekar, RCG
   Jebarani, WSL
AF Karthika, Pon K.
   Sekar, Chandra Guru R.
   Jebarani, Sylvia Lilly W.
TI Construction of XVCS for (<i>k</i>,<i>n</i>,<i>t</i>)* access structure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptography; Access structure; Essential participants; Pixel
   expansion; Relative contrast
ID VISUAL CRYPTOGRAPHY SCHEME
AB XOR-based Visual Cryptography System (XVCS) is developed to achieve high contrast and good resolution of the recovered secret image. In general (k,n) VCS, the secret image can be visualized only if k or more than k shares are stacked together. In (k,n,t)* access structure, t number of participants are considered as the essential participants(t <= k <= n) whose shares are absolutely necessary to reconstruct the secret image. Several methods have been already proposed for the construction of (k,n)* VCS for black and white images. The major focus of this work is to design an XVCS for (k,n,t)* access structure for both black and white images and color images with maximum contrast. The experimental outcome shows that the proposed method has better results than other techniques proposed so far. Also, numerical examples are provided for (k,n,t)* XVCS for t = 1 and 2. The XVCS designed for (k,n,t)* access structure can be used for any real time application and is demonstrated with an example of user authentication in banking system.
C1 [Karthika, Pon K.] Mepco Schlenk Engn Coll, Dept Comp Sci & Engn, Sivakasi, India.
   [Sekar, Chandra Guru R.] Mepco Schlenk Engn Coll, Dept Math, Sivakasi, India.
   [Jebarani, Sylvia Lilly W.] Mepco Schlenk Engn Coll, Dept Elect & Commun Engn, Sivakasi, India.
C3 Mepco Schlenk Engineering College; Mepco Schlenk Engineering College;
   Mepco Schlenk Engineering College
RP Sekar, RCG (corresponding author), Mepco Schlenk Engn Coll, Dept Math, Sivakasi, India.
EM ponkarthika.k@gmail.com; chandragurusekaronly@gmail.com;
   vivimishi@yahoo.co.in
RI R, CHANDRA GURU SEKAR/AAO-1860-2020; Kasirajan, Pon
   Karthika/HOF-5319-2023; Jebarani, Sylvia Lilly/T-3297-2019; padmavathy
   engg college, prince shri venkateshwara/GOH-3256-2022
OI R, CHANDRA GURU SEKAR/0000-0002-1436-1785; Kasirajan, Pon
   Karthika/0000-0001-8135-9661; Jebarani, Sylvia
   Lilly/0000-0002-2308-7693; 
CR Arumugam S, 2014, DESIGN CODE CRYPTOGR, V71, P153, DOI 10.1007/s10623-012-9722-2
   Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Cimato S, 2007, THEOR COMPUT SCI, V374, P261, DOI 10.1016/j.tcs.2007.01.006
   Cu DH, 2015, SIGNAL PROCESS, V108, P604, DOI 10.1016/j.sigpro.2014.10.011
   Droste S., 1996, Advances in Cryptology - CRYPTO'96. 16th Annual International Cryptology Conference. Proceedings, P401
   Dutta S, 2019, DESIGN CODE CRYPTOGR, V87, P1699, DOI 10.1007/s10623-018-0570-6
   Fu Z., 2018, MULTIMED TOOLS APPL, V78, P1
   Guo T, 2014, LECT NOTES COMPUT SC, V8317, P56, DOI 10.1007/978-3-319-04268-8_4
   Guo T, 2014, SIGNAL PROCESS, V94, P90, DOI 10.1016/j.sigpro.2013.06.003
   Hu H, 2016, MULTIMED TOOLS APPL, V75, P13883, DOI 10.1007/s11042-016-3250-4
   Liu F, 2010, IEEE T INF FOREN SEC, V5, P27, DOI 10.1109/TIFS.2009.2037660
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Verheul E. R., 1997, Designs, Codes and Cryptography, V11, P179, DOI 10.1023/A:1008280705142
   Wu XT, 2014, IEEE T INF FOREN SEC, V9, P1592, DOI 10.1109/TIFS.2014.2346014
   Yan XH, 2014, LECT NOTES COMPUT SC, V8836, P636, DOI 10.1007/978-3-319-12643-2_77
NR 15
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29519
EP 29537
DI 10.1007/s11042-021-11132-3
EA JUN 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000668401600003
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Huang, YB
   Zhao, DN
   Wu, CH
   Ip, WH
   Yung, KL
AF Zhang, Yong
   Huang, Yubei
   Zhao, Donning
   Wu, Chun Ho
   Ip, Wai Hung
   Yung, Kai Leung
TI A scene text detector based on deep feature merging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene text detector; Deep feature merging; DenseNet121; Convolutional
   neural network
AB Scene text detection has become an important research topic. It can be broadly applied to much industrial equipment, such as smart phones, intelligent scanners, and IoT devices. Many existing scene text detection methods have achieved advanced performance. However, text in scene images is presented with differing orientations and varying shapes, rendering scene text detection a challenging task. This paper proposes a method for detecting texts in scene images. First, four stages of low-level features is extracted using DenseNet121. Low-level features are then merged by transposed convolution and skip connection. Second, the merged feature map is used to generate a score map, box map, and angle map. Finally, the Locality-Aware Non-Maximum Suppression (LANMS) is applied as post-processing to generate the final bounding box. The proposed method achieves an F-measure of 0.826 on ICDAR 2015 and 0.761 on MSRA-TD500, respectively.
C1 [Zhang, Yong; Huang, Yubei] Shenzhen Univ, ATR Key Lab Natl Def Technol, Shenzhen 518060, Peoples R China.
   [Zhang, Yong] Shenzhen Univ, Guangdong Key Lab Intelligent Informat Proc, Shenzhen 518060, Peoples R China.
   [Zhang, Yong] Shenzhen Univ, Guangdong Lab Artificial Intelligence & Digital E, Shenzhen 518060, Peoples R China.
   [Zhao, Donning] Shenzhen Vetose Technol Co Ltd, Shenzhen 518102, Peoples R China.
   [Wu, Chun Ho] Hang Seng Univ Hong Kong, Dept Supply Chain & Informat Management, Hong Kong 999077, Peoples R China.
   [Ip, Wai Hung; Yung, Kai Leung] Hong Kong Polytech Univ, Dept Ind & Syst Engn, Hong Kong 999077, Peoples R China.
C3 Shenzhen University; Shenzhen University; Guangming Laboratory; Shenzhen
   University; Hang Seng University of Hong Kong; Hong Kong Polytechnic
   University
RP Zhao, DN (corresponding author), Shenzhen Vetose Technol Co Ltd, Shenzhen 518102, Peoples R China.
EM 582101@qq.com
RI Huang, Yubei/AAE-8296-2020; IP, W.H./J-2941-2013; WU, Chun
   Ho/H-8815-2012
OI IP, W.H./0000-0001-6609-0713; WU, Chun Ho/0000-0003-1259-4048
FU Science and Technology Plan Projects of Shenzhen [JSGG20200807171601010,
   JSGG20191127151401743]; Graduate Education Reform Project of Shenzhen
   University [SZUGS2020JG11]; Department of Industrial and Systems
   Engineering, The Hong Kong Polytechnic University, China [H-ZG3K]
FX This work was supported by the Science and Technology Plan Projects of
   Shenzhen (No. JSGG20200807171601010, JSGG20191127151401743), the
   Graduate Education Reform Project of Shenzhen University (SZUGS2020JG11)
   and the grants from the Department of Industrial and Systems
   Engineering, The Hong Kong Polytechnic University, China (H-ZG3K).
CR Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   [Anonymous], 2017, R2CNN: Rotational Region CNN for Orientation Robust Scene Text Detection
   Bai Nong, 2016, ARXIV160609002
   Ch'ng CK, 2017, PROC INT CONF DOC, P935, DOI 10.1109/ICDAR.2017.157
   Deng LJ, 2019, IEEE ACCESS, V7, P153400, DOI 10.1109/ACCESS.2019.2948405
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   He P, 2017, IEEE I CONF COMP VIS, P3066, DOI 10.1109/ICCV.2017.331
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang WL, 2014, LECT NOTES COMPUT SC, V8692, P497, DOI 10.1007/978-3-319-10593-2_33
   Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Kim K.-H., 2016, Pvanet: deep but lightweight neural networks for real-time object detection
   King DB, 2015, ACS SYM SER, V1214, P1
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Nahari R. V., 2020, Journal of Physics: Conference Series, V1569, DOI 10.1088/1742-6596/1569/3/032070
   Neumann L, 2011, LECT NOTES COMPUT SC, V6494, P770, DOI 10.1007/978-3-642-19318-7_60
   Ranjitha P, 2020, REV TEXT DETECTION M, P240, DOI [10.1109/ICESC48915.2020.9156002, DOI 10.1109/ICESC48915.2020.9156002]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Shi BG, 2017, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2017.371
   Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4
   Xing D, 2017, ARXIV PREPRINT ARXIV
   Xu YC, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2900589
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Yu J., 2016, P 24 ACM INT C MULT, P516, DOI DOI 10.1145/2964284.2967274
   Zhang Z, 2015, PROC CVPR IEEE, P2558, DOI 10.1109/CVPR.2015.7298871
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
   Zhu SY, 2016, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2016.74
   Zhu YY, 2016, FRONT COMPUT SCI-CHI, V10, P19, DOI 10.1007/s11704-015-4488-0
NR 32
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29005
EP 29016
DI 10.1007/s11042-021-11101-w
EA JUN 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000661795700002
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Shashidhar, R
   Patilkulkarni, S
AF Shashidhar, R.
   Patilkulkarni, Sudarshan
TI Visual speech recognition for small scale dataset using VGG16
   convolution neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual speech recognition; Lip-reading; Convolutional neural network;
   VGG16
AB Visual speech recognition is a method that comprehends speech from speakers lip movements and the speech is validated only by the shape and lip movement. Implementation of this practice not only helps people with hearing impaired but also can be used for professional lip reading whose application can be seen in crime and forensics. It plays a crucial role in aforementioned domains, as normal person's speech will be converted to text. Here, it is proposed to enhance the visual speech recognition technique from the video. The dataset was created and the same was used for implementation and verification. The aim of the approach was to recognize words only from the lip movement using video in the absence of audio and this mostly helps to extract words from a video without audio that helps in forensic and crime analysis. The proposed method employs VGG16 pre trained Convolutional Neural Network architecture for classification and recognition of data. It was observed that the visual modality improves the performance of speech recognition system. Finally, the obtained results were compared with the Hahn Convolutional Neural Network architecture (HCNN). The accuracy of the recommended model is 76% in visual speech recognition.
C1 [Shashidhar, R.; Patilkulkarni, Sudarshan] JSS Sci & Technol Univ, Dept Elect & Commun Engn, Mysuru 570006, India.
C3 JSS Science & Technology University
RP Shashidhar, R (corresponding author), JSS Sci & Technol Univ, Dept Elect & Commun Engn, Mysuru 570006, India.
EM shashidhar.r@sjce.ac.in
RI R, shashidhar/B-5334-2018; Patilkulkarni, Sudarshan/GPX-1011-2022; R,
   shashidhar/GSI-7748-2022
OI R, shashidhar/0000-0002-3737-7819; Patilkulkarni,
   Sudarshan/0000-0001-9368-4859; R, shashidhar/0000-0002-3737-7819
CR Amit A., 2016, Lip reading using cnn and lstm
   Anina Iryna, 2015, 2015 11 IEEE INT C W
   Aran LR, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON AUTOMATIC CONTROL AND INTELLIGENT SYSTEMS (I2CACIS), P196, DOI 10.1109/I2CACIS.2017.8239057
   Bastanfard A, 2009, LECT NOTES COMPUT SC, V5879, P1080, DOI 10.1007/978-3-642-10467-1_104
   Bastanfard A, 2009, IEEE SYS MAN CYBERN, P169, DOI 10.1109/ICSMC.2009.5346591
   Chang XK, 2019, INT CONF ACOUST SPEE, P6256, DOI 10.1109/ICASSP.2019.8682822
   Chen XJ, 2020, SIGNAL IMAGE VIDEO P, V14, P981, DOI 10.1007/s11760-019-01630-1
   Chung JS, 2017, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2017.367
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   COOTES TF, 1998, IEEE T PATTERN ANAL, V1407
   Hilder S, 2009, INT C AUD SPEECH PRO, P11
   Hu D, 2016, PROC CVPR IEEE, P3574, DOI 10.1109/CVPR.2016.389
   Krishnan M.R., 2012, 2012 INT C COMPUTING, P1, DOI DOI 10.1109/ICCCA.2012.6179154
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Lu YY, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0243-9
   Matthews I, 2002, IEEE T PATTERN ANAL, V24, P198, DOI 10.1109/34.982900
   Mesbah A, 2019, IMAGE VISION COMPUT, V88, P76, DOI 10.1016/j.imavis.2019.04.010
   Ozcan T., 2019, BALK J ELECT COMPUT, V7, P195
   Petridis S, 2020, PATTERN RECOGN LETT, V131, P421, DOI 10.1016/j.patrec.2020.01.022
   Petridis S, 2016, INT CONF ACOUST SPEE, P2304, DOI 10.1109/ICASSP.2016.7472088
   Qiu G, 2010, LNCS, V6298, P1, DOI [10.1007/978-3-642-15696-0, DOI 10.1007/978-3-642-15696-0]
   Sooraj V, 2020, LIP READING TECHNIQU, V9
   Wand M, 2016, INT CONF ACOUST SPEE, P6115, DOI 10.1109/ICASSP.2016.7472852
   Yao WenJuan, 2010, 2010 3rd International Conference on Advanced Computer Theory and Engineering (ICACTE 2010), P363, DOI 10.1109/ICACTE.2010.5579830
   Zhao GY, 2009, IEEE T MULTIMEDIA, V11, P1254, DOI 10.1109/TMM.2009.2030637
NR 25
TC 16
Z9 17
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 28941
EP 28952
DI 10.1007/s11042-021-11119-0
EA JUN 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000661795800003
DA 2024-07-18
ER

PT J
AU Sharma, VK
   Mittal, N
   Vidyarthi, A
AF Sharma, Vijay Kumar
   Mittal, Namita
   Vidyarthi, Ankit
TI Semantic morphological variant selection and translation disambiguation
   for cross-lingual information retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-lingual information retrieval; Translation; Disambiguation;
   Parallel corpus; Recurrent neural network; Continuous bag of word
AB Cross-Lingual Information Retrieval (CLIR) enables a user to query in a language which is different from the target documents language. CLIR incorporates a translation technique based on either a manual dictionary or a probabilistic dictionary which is generated from a parallel corpus. The translation techniques for Hindi language suffer from a translation mis-mapped issue which is due to the morphological richness of Hindi language. In addition, a word may have multiple translations in a dictionary leading to word translation disambiguation issue. This paper addresses two key findings, i.e., Semantic Morphological Variant Selection (SMVS), and Hybrid Word Translation Disambiguation (HWTD), the former resolves translation mis-mapped issue and the later disambiguates the queries more effectively. The proposed techniques are investigated for FIRE ad-hoc datasets, where SMVS and HWTD at word level achieve better evaluation measures in comparison to the baseline Statistical Machine Translation.
C1 [Sharma, Vijay Kumar; Mittal, Namita] Malaviya Natl Inst Technol, Jaipur, India.
   [Vidyarthi, Ankit] Jaypee Inst Informat Technol, Dept CSE & IT, Noida, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur; Jaypee Institute of Information
   Technology (JIIT)
RP Vidyarthi, A (corresponding author), Jaypee Inst Informat Technol, Dept CSE & IT, Noida, India.
EM 2014rcp9541@mnit.ac.in; nmittal.cse@mnit.ac.in;
   dr.ankit.vidyarthi@gmail.com
RI Vidyarthi, Ankit/AAD-4939-2020; Mittal, Namita/AAL-3336-2020; Sharma,
   Vijay/AAX-2052-2020
OI Vidyarthi, Ankit/0000-0002-8026-4246; Mittal,
   Namita/0000-0001-6886-9974; 
CR Adriani M., 2000, Information Retrieval, V2, P69, DOI 10.1023/A:1009989801965
   [Anonymous], 2010, P 5 INT WORKSH SEM E
   [Anonymous], 2017, P 3 WORKSHOP DISCOUR
   [Anonymous], 2013, LONG PAPERS
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Das A, 2017, ACM T ASIAN LOW-RESO, V16, DOI 10.1145/3015467
   Duque A, 2015, KNOWL-BASED SYST, V81, P65, DOI 10.1016/j.knosys.2015.02.007
   Finch A, 2017, ACM T ASIAN LOW-RESO, V16, DOI 10.1145/3003726
   Ganguly D., 2012, COLING, P927
   Ganguly D, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P795, DOI 10.1145/2766462.2767780
   Gupta Suneet Kumar, 2011, Advanced Computing, V2, P33
   Jagarlamudi J, 2008, LECT NOTES COMPUT SC, V5152, P80, DOI 10.1007/978-3-540-85760-0_10
   Janarthanam SC, 2008, P 2 ACM WORKSH IMPR, P33
   Karimi S, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922654
   Klementiev Alexandre., 2012, Inducing crosslingual distributed representations of words
   Koehn P., 2010, Statistical machine translation, DOI DOI 10.1017/CBO9780511815829
   Kunchukuttan Anoop, 2017, ARXIV PREPRINT ARXIV
   Larkey Leah S., 2003, ACM Transactions on Asian Language Information Processing, V2, P130
   Makin R, 2007, LECT NOTES ARTIF INT, V4578, P430
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Monz C., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P520, DOI 10.1145/1076034.1076123
   Mustafa A, 2005, T ENG COMP TECHNOL
   Nagarathinam A., 2011, INT J COMPUTER APPL, V35, P15
   Nasharuddin NA., 2010, ELECT J COMPUTER SCI, V2, P1
   Nothman Joel, 2008, Proceedings of the Australasian Language Technology Association Workshop 2008, P124
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Pingali P, 2008, P 2 WORKSH CROSS LIN
   Pingali P, 2007, CLEF WORKING NOTES
   Prasad G., 2015, INT C CIRC POW COMP, P1, DOI 10.1109/ICCPCT.2015.7159443
   Saravanan K, 2010, FOR INF RETR EV FIRE
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715
   Shakery A, 2013, INFORM RETRIEVAL, V16, P1, DOI 10.1007/s10791-012-9194-z
   Sharma V., 2016, 2016 Symposium on Colossal Data Analysis and Networking (CDAN), P1, DOI DOI 10.1109/CDAN.2016.7570965
   Sharma VK, 2022, IETE TECH REV, V39, P276, DOI 10.1080/02564602.2020.1843553
   Sharma VK, 2017, LECT NOTES COMPUT SC, V10597, P365, DOI 10.1007/978-3-319-69900-4_46
   Sharma VK, 2016, PROCEDIA COMPUT SCI, V89, P428, DOI 10.1016/j.procs.2016.06.092
   Sharma Vijay Kumar, 2018, Advances in Computer and Computational Sciences, P611
   Sorg P, 2012, DATA KNOWL ENG, V74, P26, DOI 10.1016/j.datak.2012.02.003
   Ture F, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2644807
   Turney PD, 2004, ARXIV0407065
   Vahid AH, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P859, DOI 10.1145/2740908.2743008
   Vulic I, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P363, DOI 10.1145/2766462.2767752
   Wu Y., 2016, GOOGLES NEURAL MACHI
   Xiao HM, 2008, SER INF MANAGE SCI, V7, P16
   Zhang Sheng., 2017, Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers), V1, P832
   Zhou D, 2012, ACM COMPUT SURV, V45, DOI 10.1145/2379776.2379777
   Zou W.Y., 2013, EMNLP, P1393
NR 47
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8197
EP 8212
DI 10.1007/s11042-021-11074-w
EA JUN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000660358100002
DA 2024-07-18
ER

PT J
AU Fang, LL
   Zhang, LR
   Yao, YB
   Chen, L
AF Fang, Lingling
   Zhang, Lirong
   Yao, Yibo
   Chen, Le
TI Ultrasound image segmentation using an active contour model and
   learning-structured inference
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Active contour model (ACM); Machine learning; Generalized linear model
   (GLM); Learning-structured inference; Ultrasound (US) image segmentation
ID LEFT-VENTRICLE; DRIVEN; ARCHITECTURES; FRAMEWORK
AB Automated segmentation of medical ultrasound (US) images is a challenging problem due to the complicated features of lesions, inconsistent lesions across individuals, and the high segmentation accuracy requirement. From recently published papers in this area, the active contour model (ACM) and machine learning method produce more accurate lesion segmentation results than previous methods. This paper proposes a novel image segmentation approach that integrates an ACM with a generalized linear model (GLM) and forms learning-structured inference. Compared with the GLM, the proposed method can solve the problems of initialization and the local minimum of the ACM. Furthermore, rather than using the ACM as a postprocessing tool, we integrate it into the training phase to fine-tune the GLM. This step allows the use of unlabeled data during training in a semisupervised setting. The integrated model requires only one image as the training set and is not as sensitive to labeled data as other methods. The proposed method is verified using US images, and the results show that the proposed method can produce accurate segmentation results.
C1 [Fang, Lingling; Zhang, Lirong; Yao, Yibo] Liaoning Normal Univ, Dept Comp & Informat Technol, Dalian, Liaoning, Peoples R China.
   [Fang, Lingling] Nanchang Inst Technol, Nanchang, Jiangxi, Peoples R China.
   [Chen, Le] Northeast Univ, Coll Comp Sci & Engn, Shenyang, Liaoning, Peoples R China.
C3 Liaoning Normal University; Nanchang Institute Technology; Northeastern
   University - China
RP Fang, LL (corresponding author), Liaoning Normal Univ, Dept Comp & Informat Technol, Dalian, Liaoning, Peoples R China.; Fang, LL (corresponding author), Nanchang Inst Technol, Nanchang, Jiangxi, Peoples R China.
EM fanglingling@lnnu.edu.cn
RI Zhang, Li/GWM-7501-2022; Zhang, Liqun/JDN-3523-2023; zhang,
   lin/IZQ-4870-2023; Fang, Lingling/N-1534-2018
OI Fang, Lingling/0000-0002-4397-7212
FU National Natural Science Foundation of China [61801202]; Provincial
   College Students Innovation and Entrepreneurship Training Program;
   Undergraduate Scientific Research Training Projects Guided by Teachers
   [CX201902022]
FX This work was supported by the National Natural Science Foundation of
   China [grant numbers 61801202], Provincial College Students Innovation
   and Entrepreneurship Training Program, and the Undergraduate Scientific
   Research Training Projects Guided by Teachers [grant number
   CX201902022].
CR Abdelsamea MM, 2017, SOFT COMPUT, V21, P2047, DOI 10.1007/s00500-015-1906-z
   Balla-Arabé S, 2013, IEEE T CYBERNETICS, V43, P910, DOI 10.1109/TSMCB.2012.2218233
   Carneiro G, 2013, IEEE T PATTERN ANAL, V35, P2592, DOI 10.1109/TPAMI.2013.96
   Carneiro G, 2012, IEEE T IMAGE PROCESS, V21, P968, DOI 10.1109/TIP.2011.2169273
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cunningham RJ, 2017, IEEE T MED IMAGING, V36, P653, DOI 10.1109/TMI.2016.2623819
   Fang LL, 2018, COMPUT MATH APPL, V75, P4286, DOI 10.1016/j.camwa.2018.03.029
   Foster B, 2014, COMPUT BIOL MED, V50, P76, DOI 10.1016/j.compbiomed.2014.04.014
   Friedman J, 2010, J STAT SOFTW, V33, P1, DOI 10.18637/jss.v033.i01
   Gupta D, 2017, BIOMED SIGNAL PROCES, V31, P116, DOI 10.1016/j.bspc.2016.06.012
   Hafiane A, 2014, COMPUT BIOL MED, V52, P88, DOI 10.1016/j.compbiomed.2014.06.001
   Ilunga-Mbuyamba E, 2016, EXPERT SYST APPL, V56, P59, DOI 10.1016/j.eswa.2016.02.048
   Jeong D, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8071173
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Ke Yong Li, 2007, 2007 IEEE Aerospace Conference, P1
   Lai CC, 2009, EXPERT SYST APPL, V36, P248, DOI 10.1016/j.eswa.2007.09.003
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Ma C, 2018, IEEE T MED IMAGING, V37, P1943, DOI 10.1109/TMI.2018.2805821
   Meiburger KM, 2018, COMPUT BIOL MED, V92, P210, DOI 10.1016/j.compbiomed.2017.11.018
   Meng XM, 2018, IEEE SIGNAL PROC LET, V25, P398, DOI 10.1109/LSP.2017.2789163
   Milletari F, 2017, COMPUT VIS IMAGE UND, V164, P92, DOI 10.1016/j.cviu.2017.04.002
   Noble JA, 2006, IEEE T MED IMAGING, V25, P987, DOI 10.1109/TMI.2006.877092
   Paul G, 2013, INT J COMPUT VISION, V104, P69, DOI 10.1007/s11263-013-0615-2
   Raj ANJ, 2018, MED BIOL ENG COMPUT, V2, P1
   Saha PK, 2001, IEEE T PATTERN ANAL, V23, P689, DOI 10.1109/34.935844
   Shi J, 2016, NEUROCOMPUTING, V194, P87, DOI 10.1016/j.neucom.2016.01.074
   Torres HR, 2018, COMPUT METH PROG BIO, V157, P49, DOI 10.1016/j.cmpb.2018.01.014
   Udupa JK, 2006, COMPUT MED IMAG GRAP, V30, P75, DOI 10.1016/j.compmedimag.2005.12.001
   Wang L, 2009, COMPUT MED IMAG GRAP, V33, P520, DOI 10.1016/j.compmedimag.2009.04.010
   Wang LF, 2014, PATTERN RECOGN, V47, P1917, DOI 10.1016/j.patcog.2013.11.014
   Weijers G, 2010, ULTRASONIC IMAGING, V32, P143, DOI 10.1177/016173461003200303
   Xu Y, 2019, ULTRASONICS, V91, P1, DOI 10.1016/j.ultras.2018.07.006
   Yuan J, 2012, IET IMAGE PROCESS, V6, P1075, DOI 10.1049/iet-ipr.2012.0120
   Zhou ZH, 2014, ULTRASONIC IMAGING, V36, P256, DOI 10.1177/0161734614524735
   Zong JJ, 2019, COMPUT MATH APPL, V78, P929, DOI 10.1016/j.camwa.2019.03.022
NR 36
TC 4
Z9 4
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13389
EP 13407
DI 10.1007/s11042-021-11088-4
EA JUN 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000659016500004
DA 2024-07-18
ER

PT J
AU Ghahremani, M
   Ghadiri, H
   Hamghalam, M
AF Ghahremani, Mona
   Ghadiri, Hamid
   Hamghalam, Mohammad
TI Local features integration for content-based image retrieval based on
   color, texture, and shape
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval (CBIR); Medical image processing;
   Morphology; LBP algorithm; HOG descriptor
ID FUSION; EXTRACTION; HISTOGRAM; MACHINE
AB Imaging techniques like computed tomography (CT) and ultrasound are employed to provide valuable information for physicians, including size, contour, and internal organs' anatomical information. Information retrieval systems can be used to deliver on-time information to the radiologists when some sections of scans are lost. In this study, a new content-based image retrieval (CBIR) model based on an effective combination of color, texture, and shape features is proposed to reconstruct these images' corrupted portions. For this purpose, image scans are normalized, and their noise is reduced by employing a median filter. Then, the color channel shift is modified utilizing the Simple Linear Iterative Clustering (SLIC) superpixel. Afterward, a Histogram of Oriented Gradients (HOG) descriptor is introduced to enhance image contrast and feature extraction. Finally, local thresholding based on Local Binary Patterns (LBP) is performed to separate the image details into three components to examine the light and edge intensity. The proposed method is experimented on several images by evaluating the texture, color, and shape morphology of the reconstructed images compared to the ground truth. The highest content retrieval rate of 90.54% on a liver CT scan image demonstrates the proposed method's efficiency compared with former state-of-the-art approaches.
C1 [Ghahremani, Mona] Darolfonoon Univ, Dept Control Elect Engn, Qazvin, Iran.
   [Ghadiri, Hamid; Hamghalam, Mohammad] Islamic Azad Univ, Fac Elect Biomed & Mechatron Engn, Qazvin Branch, Qazvin, Iran.
C3 Islamic Azad University
RP Ghadiri, H; Hamghalam, M (corresponding author), Islamic Azad Univ, Fac Elect Biomed & Mechatron Engn, Qazvin Branch, Qazvin, Iran.
EM monaghahremani1991@gmail.com; h.ghadiri@qiau.ac.ir;
   m.hamghalam@gmail.com
RI Hamghalam, Mohammad/X-7134-2019
OI Hamghalam, Mohammad/0000-0003-2543-0712; ghadiri,
   hamid/0000-0003-3602-4090
CR Alsmadi MK, 2018, J KING SAUD UNIV-COM, V30, P373, DOI 10.1016/j.jksuci.2017.05.002
   [Anonymous], 2011, 2011 24 INT S COMPUT, DOI DOI 10.1109/CBMS.2011.5999142
   [Anonymous], 1992, Active perception and robot vision, DOI [10.1007/978-3-642-77225-2_13, DOI 10.1007/978-3-642-77225-2_13]
   Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008
   Berens J, 2000, IEE P-VIS IMAGE SIGN, V147, P349, DOI 10.1049/ip-vis:20000630
   Bianconi F, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.1.011002
   Brahnam S., 2014, Local Binary Patterns - New Variants and Applications
   CHANG SK, 1992, IEEE T KNOWL DATA EN, V4, P431, DOI 10.1109/69.166986
   Chu JH, 2015, MED PHYS, V42, P3859, DOI 10.1118/1.4921612
   Ciocca G, 2015, MULTIMED TOOLS APPL, V74, P3013, DOI 10.1007/s11042-013-1766-4
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dy JG, 2003, IEEE T PATTERN ANAL, V25, P373, DOI 10.1109/TPAMI.2003.1182100
   Elango P., 2009, INT J OPEN PROBLEMS, V2, P439
   Favorskaya M, 2014, PROCEDIA COMPUT SCI, V35, P861, DOI 10.1016/j.procs.2014.08.253
   Feng L, 2020, CIRC SYST SIGNAL PR, V39, P586, DOI 10.1007/s00034-019-01126-w
   Oliveira LLG, 2008, INT J MED INFORM, V77, P555, DOI 10.1016/j.ijmedinf.2007.10.010
   Gevers T, 2000, IEEE T IMAGE PROCESS, V9, P102, DOI 10.1109/83.817602
   HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417
   Han J, 2002, IEEE T IMAGE PROCESS, V11, P944, DOI 10.1109/TIP.2002.801585
   Hiremath PS, 2007, ADCOM 2007: PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATIONS, P780, DOI 10.1109/ADCOM.2007.21
   Humeau-Heurtier A, 2019, IEEE ACCESS, V7, P8975, DOI 10.1109/ACCESS.2018.2890743
   Jahne B., 2004, PRACTICAL HDB IMAGE, V2nd
   JINDAL H, 2016, P INT C REC COGN WIR, P1
   Kaur Sandeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P23, DOI 10.5815/ijigsp.2017.07.03
   Kavitha S, 2017, SOFT COMPUT, V21, P3307, DOI 10.1007/s00500-015-2009-6
   Kavitha S, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P1482, DOI 10.1109/ICCSP.2015.7322761
   Korn PF, 1998, IEEE T KNOWL DATA EN, V10, P889, DOI 10.1109/69.738356
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li K, 2018, PATTERN RECOGN, V73, P1, DOI 10.1016/j.patcog.2017.06.036
   Li XX, 2002, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON INSTRUMENTATION SCIENCE AND TECHNOLOGY, VOL 1, P152
   Li YB, 2015, DIGIT SIGNAL PROCESS, V37, P65, DOI 10.1016/j.dsp.2014.11.006
   Liu YJ, 2018, IEEE T PATTERN ANAL, V40, P653, DOI 10.1109/TPAMI.2017.2686857
   Liu Z, 2019, C ART INT SEC, P606
   Long FH, 2003, SIG COM TEC, P1
   Mander Kuldeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P17, DOI 10.5815/ijigsp.2017.08.03
   Mehmood Z, 2018, ARAB J SCI ENG, V43, P7265, DOI 10.1007/s13369-018-3062-0
   Minu RI, 2014, INT J AUTOM COMPUT, V11, P489, DOI 10.1007/s11633-014-0832-3
   Minu RI, 2013, ADV INTELL SYST, V182, P333
   Mittal Archie, 2017, International Journal of Image, Graphics and Signal Processing, V9, P28, DOI 10.5815/ijigsp.2017.05.04
   Mutasem K.A., 2017, Egyptian Journal of Basic and Applied Sciences, V4, P112, DOI 10.1016/j.ejbas.2017.02.004
   Nagarajan G, 2012, PROCEDIA ENGINEER, V38, P2164, DOI 10.1016/j.proeng.2012.06.260
   Nagarajan G., 2014, INT REV COMPUT SOFTW, V9, P266
   Nomir O, 2008, PATTERN RECOGN, V41, P130, DOI 10.1016/j.patcog.2007.05.015
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Owais M, 2019, J CLIN MED, V8, DOI 10.3390/jcm8040462
   Pattanaik S., 2012, INT J COMPUT APPL, V53, P19
   Qin C, 2018, SIGNAL PROCESS, V142, P194, DOI 10.1016/j.sigpro.2017.07.019
   Rui, 2006, 5 INT C CIVR 2006 TE
   Sajjad M, 2018, MULTIMED TOOLS APPL, V77, P4769, DOI 10.1007/s11042-017-5010-5
   Sakr NA, 2016, COMPUT ELECTR ENG, V54, P522, DOI 10.1016/j.compeleceng.2016.04.015
   Sharif U, 2019, ARTIF INTELL REV, V52, P901, DOI 10.1007/s10462-018-9636-0
   Thyagharajan KK, 2019, ARCH COMPUT METHOD E, V26, P933, DOI 10.1007/s11831-018-9266-3
   Torrione PA, 2014, IEEE T GEOSCI REMOTE, V52, P1539, DOI 10.1109/TGRS.2013.2252016
   Tyagi V., 2017, Content-Based Image Retrieval: Ideas, Influences, and Current Trends, DOI DOI 10.1007/978-981-10-6759-4
   Unar S, 2018, INFORM FUSION, V44, P176, DOI 10.1016/j.inffus.2018.03.006
   Veltkamp R.C., 2000, Content-based image retrieval systems
   Wang C, 2017, ARXIV PREPRINT ARXIV
   Xie Junyuan, 2012, ADV NEURAL INFORM PR, P341, DOI [DOI 10.5555/2999134.2999173, DOI 10.1109/AGRO-GEOINFORMATICS.2012.6311605]
   Xu XQ, 2008, IEEE T INF TECHNOL B, V12, P100, DOI 10.1109/TITB.2007.904149
   Yu SN, 2005, COMPUT MED IMAG GRAP, V29, P617, DOI 10.1016/j.compmedimag.2005.06.001
   Zagoris K, 2009, SISAP 2009: 2009 SECOND INTERNATIONAL WORKSHOP ON SIMILARITY SEARCH AND APPLICATIONS, PROCEEDINGS, P154, DOI 10.1109/SISAP.2009.15
NR 61
TC 11
Z9 11
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28245
EP 28263
DI 10.1007/s11042-021-10895-z
EA JUN 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000657212500004
DA 2024-07-18
ER

PT J
AU Nguyen, VT
   Nguyen, TN
   Le, TL
   Pham, DT
   Vu, H
AF Van-Toi Nguyen
   Tien-Nam Nguyen
   Thi-Lan Le
   Dinh-Tan Pham
   Hai Vu
TI Adaptive most joint selection and covariance descriptions for a robust
   skeleton-based human action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skeleton-based human action recognition; Covariance descriptor; Most
   informative joints; Cross-dataset evaluation
ID FUNCTIONAL-DEPENDENCIES; REPRESENTATION
AB In this paper, we propose two effective manners of utilizing skeleton data for human action recognition (HAR). The proposed method on one hand takes advantage of the skeleton data thanks to their robustness to human appearance change as well as the real-time performance. On the other hand, it avoids inherent drawbacks of the skeleton data such as noises, incorrect human skeleton estimation due to self-occlusion of human pose. To this end, in terms of feature designing, we propose to extract covariance descriptors from joint velocity and combine them with those of joint position. In terms of 3-D skeleton-based activity representation, we propose two schemes to select the most informative joints. The proposed method is evaluated on two benchmark datasets. On the MSRAction-3D dataset, the proposed method outperformed different hand-designed features-based methods. On the challenging dataset CMDFall, the proposed method significantly improves accuracy when compared with techniques based on recent neuronal networks. Finally, we investigate the robustness of the proposed method via a cross-dataset evaluation.
C1 [Van-Toi Nguyen] AA Green Phoenix Grp JSC, PHENIKAA Res & Technol Inst PRATI, 167 Hoang Ngan, Hanoi 11313, Vietnam.
   [Van-Toi Nguyen] PHENIKAA Univ, Fac Elect & Elect Engn, Hanoi 12116, Vietnam.
   [Tien-Nam Nguyen; Thi-Lan Le; Dinh-Tan Pham; Hai Vu] Hanoi Univ Sci & Technol, MICA Int Res Inst, Comp Vis Dept, Hanoi, Vietnam.
   [Tien-Nam Nguyen] La Rochelle Univ, Lab Informat Image Interact L3i, F-17042 La Rochelle, France.
   [Thi-Lan Le; Hai Vu] Hanoi Univ Sci & Technol, Sch Elect & Telecommun, Hanoi, Vietnam.
   [Dinh-Tan Pham] Hanoi Univ Min & Geol, Fac Informat Technol, Hanoi, Vietnam.
C3 Hanoi University of Science & Technology (HUST); Hanoi University of
   Science & Technology (HUST); Hanoi University of Mining & Geology
RP Le, TL (corresponding author), Hanoi Univ Sci & Technol, MICA Int Res Inst, Comp Vis Dept, Hanoi, Vietnam.; Le, TL (corresponding author), Hanoi Univ Sci & Technol, Sch Elect & Telecommun, Hanoi, Vietnam.
EM Thi-Lan.Le@mica.edu.vn
RI Pham, Dinh-Tan/JJF-1335-2023; Vu, Hai/AAI-9419-2020
OI Pham, Dinh-Tan/0000-0003-1366-0617; Vu, Hai/0000-0003-2880-4417; Le,
   Thi-Lan/0000-0001-9541-3905
FU Vietnam National Foundation for Science and Technology Development
   (NAFOSTED) [102.01-2017.12]
FX This research is funded by Vietnam National Foundation for Science and
   Technology Development (NAFOSTED) under grant number 102.01-2017.12.
CR Afsar P, 2015, EXPERT SYST APPL, V42, P6935, DOI 10.1016/j.eswa.2015.05.023
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   [Anonymous], 2011, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2011.5995316, 10.1109/CVPR.2011.5995316]
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Caruccio L, 2020, DATA MIN KNOWL DISC, V34, P443, DOI 10.1007/s10618-019-00667-7
   Caruccio L, 2019, EXPERT SYST APPL, V131, P190, DOI 10.1016/j.eswa.2019.04.031
   Caruccio L, 2016, IEEE T KNOWL DATA EN, V28, P147, DOI 10.1109/TKDE.2015.2472010
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   Chen YC, 2020, COMPUT VIS IMAGE UND, V192, DOI 10.1016/j.cviu.2019.102897
   Ding WW, 2017, CHINESE J ELECTRON, V26, P790, DOI 10.1049/cje.2017.06.012
   Pham DT, 2019, PROCEEDINGS OF 2019 6TH NATIONAL FOUNDATION FOR SCIENCE AND TECHNOLOGY DEVELOPMENT (NAFOSTED) CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS), P61, DOI [10.1109/NICS48868.2019.9023859, 10.1109/nics48868.2019.9023859]
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   El-Ghaish HA, 2018, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2018), VOL 5: VISAPP, P343, DOI 10.5220/0006625703430350
   Franco A, 2020, PATTERN RECOGN LETT, V131, P293, DOI 10.1016/j.patrec.2020.01.010
   Guilly Marie, 2020, Transactions on Large-Scale Data- and Knowledge-Centered Systems XLIV. Special Issue on Data Management - Principles, Technologies, and Applications. Lecture Notes in Computer Science (LNCS 12380), P132, DOI 10.1007/978-3-662-62271-1_5
   Han F, 2017, COMPUT VIS IMAGE UND, V158, P85, DOI 10.1016/j.cviu.2017.01.011
   HOANG VN, 2019, 2019 INT C MULT AN P, P1
   Hussein, 2013, INT JOINT C ART INT
   Jiang M, 2015, SIGNAL PROCESS-IMAGE, V33, P29, DOI 10.1016/j.image.2015.02.004
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Joshi K. A., 2012, INT J SOFT COMPUT EN, V2, P44
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Lavee G, 2009, IEEE T SYST MAN CY C, V39, P489, DOI 10.1109/TSMCC.2009.2023380
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liu Y, 2019, IEEE T CIRC SYST VID, V29, P2416, DOI 10.1109/TCSVT.2018.2868123
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Luvizon DC, 2017, PATTERN RECOGN LETT, V99, P13, DOI 10.1016/j.patrec.2017.02.001
   Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007
   Park E, 2016, IEEE WINT CONF APPL
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Si CY, 2018, LECT NOTES COMPUT SC, V11205, P106, DOI 10.1007/978-3-030-01246-5_7
   Song YF, 2019, PROCEEDING INT C IMA
   Tran TH, 2018, INT C PATT RECOG, P1947, DOI 10.1109/ICPR.2018.8546308
   Nguyen TN, 2018, INT CONF KNOWL SYS, P50, DOI 10.1109/KSE.2018.8573421
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vemulapalli R, 2016, PROC CVPR IEEE, P4471, DOI 10.1109/CVPR.2016.484
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang L, 2015, IEEE I CONF COMP VIS, P4570, DOI 10.1109/ICCV.2015.519
   Wang T, 2018, OPTIK, V152, P50, DOI 10.1016/j.ijleo.2017.07.064
   Wu QX, 2013, J VIS COMMUN IMAGE R, V24, P1064, DOI 10.1016/j.jvcir.2013.07.001
   Xie CY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1639
   Xu M, 2017, IEEE INT CON MULTI, P517, DOI 10.1109/ICME.2017.8019351
   Xu ZY, 2020, IEEE ACCESS, V8, P213038, DOI 10.1109/ACCESS.2020.3038235
   Xue HY, 2016, NEUROCOMPUTING, V204, P70, DOI 10.1016/j.neucom.2015.06.112
   Yan S., 2018, AAAI, P1
   Yao GL, 2019, PATTERN RECOGN LETT, V118, P14, DOI 10.1016/j.patrec.2018.05.018
   Yao H, 2008, DATA MIN KNOWL DISC, V16, P197, DOI 10.1007/s10618-007-0083-9
   Zhang HB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051005
   Zhang JT, 2018, IEEE T IMAGE PROCESS, V27, P4709, DOI 10.1109/TIP.2018.2836323
   Zhang SG, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/3090343
   Zhang TY, 2016, INT CONF ACOUST SPEE, P2707, DOI 10.1109/ICASSP.2016.7472169
NR 53
TC 4
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27757
EP 27783
DI 10.1007/s11042-021-10866-4
EA MAY 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000653635900002
DA 2024-07-18
ER

PT J
AU Pramanik, R
   Bag, S
AF Pramanik, Rahul
   Bag, Soumen
TI A novel skew correction methodology for handwritten words in
   multilingual multi-oriented documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Curve fitting; Indian regional language; Multilingual; Skew detection;
   Skew estimation
ID CHARACTER-RECOGNITION; ALGORITHM; OPTIMIZATION; BANGLA
AB Multi-oriented handwritten documents require additional preprocessing for segmentation and subsequent phases to work accurately in handwritten recognition systems. Skew correction is one such additional phase. Appearance of skew in multi-oriented Indian language based handwritten document is higher due to the presence of cursive nature. In the current work, we utilise a salient feature present in Indian scripts called matra (also known as headline), extract a group of eligible pixels, and employ linear curve fitting for detecting and correcting skew in handwritten words. The proposed method is capable of correcting skew in four distinct Indian languages, viz. Bangla, Hindi, Marathi, and Punjabi. It is capable of efficiently handling skewed word images to an extent of +/- 55 degrees and delivers precise result even when the matra is mostly absent or discontinuous.
C1 [Pramanik, Rahul] BITS Pilani, Dept Comp Sci, Dubai Campus,POB 345055, Dubai, U Arab Emirates.
   [Bag, Soumen] Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad 826004, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Pramanik, R (corresponding author), BITS Pilani, Dept Comp Sci, Dubai Campus,POB 345055, Dubai, U Arab Emirates.
EM rahul@dubai.bits-pilani.ac.in; soumen@iitism.ac.in
OI Pramanik, Rahul/0000-0002-1410-9950
CR [Anonymous], 2011, LECT NOTES COMPUT SC
   [Anonymous], 2018, P INT S EL SMART DEV
   Bag S, 2018, P INT C REC ADV, P1
   Bag S, 2013, SADHANA-ACAD P ENG S, V38, P133, DOI 10.1007/s12046-013-0121-9
   Bagdanov A, 1997, PROC INT CONF DOC, P401, DOI 10.1109/ICDAR.1997.619878
   Basu S, 2007, PATTERN RECOGN, V40, P1825, DOI 10.1016/j.patcog.2006.10.002
   Bhowmik TK, 2005, P IAPR TC3 NNLDAR
   Boukharouba A, 2017, J KING SAUD UNIV-COM, V29, P29, DOI 10.1016/j.jksuci.2016.02.002
   Brodic D, 2012, RADIOENGINEERING, V21, P162
   Gupta D, 2019, MULTIMED TOOLS APPL, V78, P19361, DOI 10.1007/s11042-019-7286-0
   Guru D. S., 2015, Mining Intelligence and Knowledge Exploration. Third International Conference, MIKE 2015. Proceedings: LNCS 9468, P216, DOI 10.1007/978-3-319-26832-3_21
   Jayadevan R, 2011, PROC INT CONF DOC, P304, DOI 10.1109/ICDAR.2011.69
   Jundale TA, 2015, 2015 INTERNATIONAL CONFERENCE ON ENERGY SYSTEMS AND APPLICATIONS, P480, DOI 10.1109/ICESA.2015.7503396
   Jundale TA, 2015, PROCEDIA COMPUT SCI, V45, P305, DOI 10.1016/j.procs.2015.03.147
   Kar R, 2019, IMAGING SCI J, V67, P159, DOI 10.1080/13682199.2019.1574368
   Kavallieratou E, 2002, IMAGE VISION COMPUT, V20, P813, DOI 10.1016/S0262-8856(02)00091-4
   Kumar R, 2010, 2010 IEEE 2ND INTERNATIONAL ADVANCE COMPUTING CONFERENCE, P353, DOI 10.1109/IADCC.2010.5422927
   Liang YQ, 2020, INTEGR COMPUT-AID E, V27, P417, DOI 10.3233/ICA-200641
   Liu SQ, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4892
   Liu SQ, 2019, PHYSICA A, V521, P667, DOI 10.1016/j.physa.2019.01.036
   Malakar S, 2012, PROC INT CONF EMERG, P303, DOI 10.1109/EAIT.2012.6407929
   Mandal, 2012, INT J COMP SCI ISSUE, V9, P202
   Manjunath, 2013, INT J COMP SCI ISSUE, V10, P65
   Mei MQ, 2020, GEOINFORMATICA, V24, P221, DOI 10.1007/s10707-019-00383-w
   Obaidullah SM, 2018, MULTIMED TOOLS APPL, V77, P1643, DOI 10.1007/s11042-017-4373-y
   Pramanik Rahul, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 704), P129, DOI 10.1007/978-981-10-7898-9_11
   Pramanik R, 2017, LECT NOTES COMPUT SC, V10597, P116, DOI 10.1007/978-3-319-69900-4_15
   Pramanik R, 2018, J VIS COMMUN IMAGE R, V50, P123, DOI 10.1016/j.jvcir.2017.11.016
   Roy A., 2005, P DIG IM COMP TECHN, P30
   Roy K., 2006, Procedings of National Conference on Recent Trends in Information Systems, P196
   Sharma MK, 2016, NEURAL COMPUT APPL, V27, P1369, DOI 10.1007/s00521-015-1940-x
   Shaw Bikash, 2010, Machine Interpretation of Patterns. Image Analysis and Data Mining, P145, DOI 10.1142/9789814299190_0008
   Shi ZX, 2003, PROC INT CONF DOC, P715
   Stamatopoulos N, 2013, PROC INT CONF DOC, P1402, DOI 10.1109/ICDAR.2013.283
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Xu QZ, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123205
   Xu QZ, 2019, PHYSICA A, V531, DOI 10.1016/j.physa.2019.121808
   Xu QZ, 2019, IMAGE VISION COMPUT, V87, P1, DOI 10.1016/j.imavis.2019.04.002
   Xu QZ, 2018, MULTIMED TOOLS APPL, V77, P6311, DOI 10.1007/s11042-017-4537-9
   Xu QZ, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0904-y
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zhang DJ, 2016, INTEGR COMPUT-AID E, V23, P31, DOI 10.3233/ICA-150499
NR 42
TC 2
Z9 2
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27323
EP 27342
DI 10.1007/s11042-021-10822-2
EA MAY 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000651689300004
DA 2024-07-18
ER

PT J
AU Kumar, P
   Thakur, RS
AF Kumar, Pushpendra
   Thakur, Ramjeevan Singh
TI Liver disorder detection using variable- neighbor weighted fuzzy K
   nearest neighbor approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Liver disease; Imbalance data; Tomek link (T-Link); Redundant pair;
   Undersampling; Fuzzy K-NN; Classification
ID IMBALANCED DATA; CLASSIFICATION
AB The human liver disorder is a genetic problem due to the habituality of alcohol or effect by the virus. It can lead to liver failure or liver cancer, if not been detected in initial stage. The aim of the proposed method is to detect the liver disorder in initial stage using liver function test dataset. The problem with many real-world datasets including liver disease diagnosis data is class imbalanced. The word imbalance refers to the conditions that the number of observations belongs to one class having more or less than the other class(es). Traditional K- Nearest Neighbor (KNN) or Fuzzy KNN classifier does not work well on the imbalanced dataset because they treat the neighbor equally. The weighted variant of Fuzzy KNN assign a large weight for the neighbor belongs to the minority class data and relatively small weight for the neighbor belongs to the majority class to resolve the issues with data imbalance. In this paper, Variable- Neighbor Weighted Fuzzy K Nearest Neighbor Approach (Variable-NWFKNN) is proposed, which is an improved variant of Fuzzy-NWKNN. The proposed Variable-NWFKNN method is implemented on three real-world imbalance liver function test datasets BUPA, ILPD from UCI and MPRLPD. The Variable-NWFKNN is compared with existing NWKNN and Fuzzy-NWKKNN methods and found accuracy 73.91% (BUPA Dataset), 77.59% (ILPD Dataset) and 87.01% (MPRLPD Dataset). Further, TL_RUS method is used for preprocessing and it improved the accuracy as 78.46% (BUPA Dataset), 78.46% (ILPD Dataset) and 95.79% (MPRLPD Dataset).
C1 [Kumar, Pushpendra; Thakur, Ramjeevan Singh] Maulana Azad Natl Inst Technol, Dept Comp Applicat, Bhopal 462003, Madhya Pradesh, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal
RP Kumar, P (corresponding author), Maulana Azad Natl Inst Technol, Dept Comp Applicat, Bhopal 462003, Madhya Pradesh, India.
EM pushpendra7589@gmail.com
RI Kumar, Pushpendra/HNP-5223-2023
OI Kumar, Pushpendra/0000-0001-7555-2625
CR Abdar M, 2018, J MED BIOL ENG, V38, P953, DOI 10.1007/s40846-017-0360-z
   Abdar M, 2017, EXPERT SYST APPL, V67, P239, DOI 10.1016/j.eswa.2016.08.065
   Al Shalabi L, 2006, DEPCOS-RELCOMEX 2006, P207
   Alfisahrin SNN, 2014, INT CONF ADV COMPUT, P379, DOI 10.1109/ACSAT.2013.81
   Bach M, 2017, INFORM SCIENCES, V384, P174, DOI 10.1016/j.ins.2016.09.038
   Basha SM, 2019, MULTIMED TOOLS APPL, P1
   Basha SM, 2018, INT J GRID DISTRIB, V11, P41, DOI 10.14257/ijgdc.2018.11.2.05
   Batista G. E., 2004, ACM SIGKDD EXPL NEWS, V6, P20, DOI DOI 10.1145/1007730.1007735
   Benni KE, 2018, IEEE T SOFTWARE ENG, V44, P534, DOI 10.1109/TSE.2017.2731766
   Bond EJ, 2003, IEEE T ANTENN PROPAG, V51, P1690, DOI 10.1109/TAP.2003.815446
   Brownlee J., 2016, How to Normalize and Standardize Time Series Data in Python
   Chikh MA, 2012, J MED SYST, V36, P2721, DOI 10.1007/s10916-011-9748-4
   Chuang CL, 2011, ARTIF INTELL MED, V53, P15, DOI 10.1016/j.artmed.2011.06.002
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Devi D, 2017, PATTERN RECOGN LETT, V93, P3, DOI 10.1016/j.patrec.2016.10.006
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Dorj UO, 2018, MULTIMED TOOLS APPL, V77, P9909, DOI 10.1007/s11042-018-5714-1
   Esposito M, 2011, INT J MED INFORM, V80, pE245, DOI 10.1016/j.ijmedinf.2011.09.003
   Galar M, 2012, IEEE T SYST MAN CY C, V42, P463, DOI 10.1109/TSMCC.2011.2161285
   Gong J, 2017, COMPUT STAT DATA AN, V111, P1, DOI 10.1016/j.csda.2017.01.005
   Han J, 2012, MOR KAUF D, P1
   Harshita P, 2018, IETE J RES, V2018, P1
   Hashem S, 2018, IEEE ACM T COMPUT BI, V15, P861, DOI 10.1109/TCBB.2017.2690848
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   Ishtiaq U, 2020, MULTIMED TOOLS APPL, V79, P15209, DOI 10.1007/s11042-018-7044-8
   Kang Q, 2017, IEEE T CYBERNETICS, V47, P4263, DOI 10.1109/TCYB.2016.2606104
   Kantardzic M., 2011, Data Mining: Concepts, Models, Methods, and Algorithms
   Kaur P, 2019, MULTIMED TOOLS APPL, V78, P19905, DOI 10.1007/s11042-019-7327-8
   Kavakiotis I, 2017, COMPUT STRUCT BIOTEC, V15, P104, DOI 10.1016/j.csbj.2016.12.005
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   Khakhar A, 2017, LIVER DIS INDIA
   Kumar S, 2018, SOFT COMPUT, P1
   Lin RH, 2010, COMPUT BIOL MED, V40, P665, DOI 10.1016/j.compbiomed.2010.06.002
   Lin RH, 2009, ARTIF INTELL MED, V47, P53, DOI 10.1016/j.artmed.2009.05.005
   Liu DY, 2012, J MED SYST, V36, P3243, DOI 10.1007/s10916-011-9815-x
   Media L., 2017, WORLD HLTH RANKING
   Meng D, 2017, IEEE ACCESS, V5, P5804, DOI 10.1109/ACCESS.2017.2689058
   Patel H., 2017, Int. J. Intell. Eng. Syst., V10, P56, DOI [10.2991/ijcis.2017.10.1.5, 10.22266/ijies2017.0228.07]
   Peng LZ, 2014, INFORM SCIENCES, V288, P347, DOI 10.1016/j.ins.2014.04.046
   Priya RV, 2019, MICROSYST TECHNOL, P1
   Seiffert C, 2010, IEEE T SYST MAN CY A, V40, P185, DOI 10.1109/TSMCA.2009.2029559
   Tan SB, 2005, EXPERT SYST APPL, V28, P667, DOI 10.1016/j.eswa.2004.12.023
   Tiwari V, 2016, PATTERN DATA ANAL HE
   UCI, 2012, **NON-TRADITIONAL**
   Witten IH, 2011, MOR KAUF D, P1
   Yan YT, 2019, IEEE ACCESS, V7, P23537, DOI 10.1109/ACCESS.2019.2899467
   Yu C, 2019, MULTIMED TOOLS APPL, P1
   Yu HF, 2019, MULTIMED TOOLS APPL, P1
   Zhou XF, 2014, BIOMED SIGNAL PROCES, V11, P27, DOI 10.1016/j.bspc.2014.02.006
   Zomaya AY, 2017, Handbook of big data technologies
NR 50
TC 21
Z9 21
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16515
EP 16535
DI 10.1007/s11042-019-07978-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000652283400024
DA 2024-07-18
ER

PT J
AU Gupta, A
   Bhatia, R
AF Gupta, Amit
   Bhatia, Rajesh
TI Ensemble approach for web page classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web page classification; Transfer learning; Residual inception
   modelling; Pre-trained model
AB Over the decades World Wide Web has become abundance source of distributed web content repository hyper-linked with diverse information domains. Performance of search engines in locating the information is exemplary but still there is inadequacy in search engines for focused crawling of web content. Web Page Classification being pivotal for information retrieval and management task plays imperative role for natural language processing in creating classified web document repositories and building indexed web directories. The conventional machine learning approaches extract the desired features from web pages in order to classify them whereas deep leaning algorithms learns the covet features as the network goes deeper and deeper. Transfer learning based Pre-trained models such as BERT attains impressive performance for text classification. In this study, we evaluate the effectiveness of adopting pre-trained model BERT for the task of classifying web pages into different categories. In this paper, we proposed an ensemble approach for web page classification by learning contextual representation using pre-trained bidirectional BERT and then applying deep Inception modelling with Residual connections for fine-tunes the target task by utilizing parallel multi-scale semantics. Experimental evaluation exhibit that proposed ensemble model outperforms benchmark baselines and achieve better performance in contrast to other transfer learning approaches evaluated on the web page classification task for different classification datasets.
C1 [Gupta, Amit; Bhatia, Rajesh] Deemed Univ, Punjab Engn Coll, Dept Comp Sci & Engn, Chandigarh, India.
C3 Punjab Engineering College (Deemed University)
RP Gupta, A (corresponding author), Deemed Univ, Punjab Engn Coll, Dept Comp Sci & Engn, Chandigarh, India.
EM amitgupta.phdcse15@pec.edu.in; rbhatia@pec.edu.in
RI Bhatia, Dr Rajesh/JUU-9542-2023
CR Altingövde IS, 2001, LECT NOTES COMPUT SC, V2113, P699
   [Anonymous], NIPS 15 P 28 INT C N, V1, P649
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   [Anonymous], 2015, 2015 IEEE C COMP VIS, P1
   [Anonymous], P 2016 C N AM CHAPT, P1480
   Brin S, 2012, COMPUT NETW, V56, P3825, DOI 10.1016/j.comnet.2012.10.007
   Chen RC, 2006, EXPERT SYST APPL, V31, P427, DOI 10.1016/j.eswa.2005.09.079
   Chung J., 2014, NIPS 2014 WORKSH DEE
   Conneau A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1107
   DEBRA PME, 1994, COMPUT NETWORKS ISDN, V27, P183, DOI 10.1016/0169-7552(94)90132-5
   Devlin J., 2018, BERT PRE TRAINING DE
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holden N, 2004, LECT NOTES COMPUT SC, V3242, P1092
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Hu HL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND STORAGE (NAS)
   Huang ML, 2017, ACM T INFORM SYST, V35, DOI 10.1145/3052770
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kwon O.-W., 2000, Proceedings of the 5th International Workshop on Information Retrieval with Asian Languages, P9
   Li YT, 2020, ACM T SENSOR NETWORK, V16, DOI 10.1145/3397179
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P49, DOI 10.1109/MIC.2020.2971447
   Li YT, 2019, IEEE INTERNET THINGS, V6, P628, DOI 10.1109/JIOT.2018.2851185
   Menczer F., 2004, ACM T INTERNET TECHN, V4, P378, DOI DOI 10.1145/1031114.1031117
   Meshkizadeh S., 2010, INT J ADV COMPUTING, V2, P36, DOI [10.4156/ijact.vol2.issue4.4, DOI 10.4156/IJACT.VOL2.ISSUE4.4]
   Ozel Selma Ayse, 2011, 2011 International Symposium on Innovations in Intelligent Systems and Applications (INISTA 2011), P282, DOI 10.1109/INISTA.2011.5946076
   Özel SA, 2011, EXPERT SYST APPL, V38, P3407, DOI 10.1016/j.eswa.2010.08.126
   Qi XG, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1459352.1459357
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Ribeiro A, 2003, LECT NOTES ARTIF INT, V2663, P103
   Selamat A, 2004, INFORM SCIENCES, V158, P69, DOI 10.1016/j.ins.2003.03.003
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Wang BX, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2311
   Zhou Chunting, 2015, ARXIV
NR 33
TC 9
Z9 9
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 25219
EP 25240
DI 10.1007/s11042-021-10891-3
EA APR 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000640469800001
DA 2024-07-18
ER

PT J
AU Kohli, M
   Kumar, S
AF Kohli, Monika
   Kumar, Satish
TI Segmentation of handwritten words into characters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Segmentation; Touching components; Junction path; Junction pixel; OCR
   (optical character recognition)
AB In this paper, SFF (Segmentation Facilitate Feature) technique is proposed to find the junction path to segment touched components based on the seed pixel selected among candidate pixels. Handwritten Recognition system has number of applications like reading postal address, filling forms, reading bank cheques, offering several challenges. In practice, constitute of the word images get touched in handwritten data due to variability in stroke, shortage of space which make the individual character extraction from the word image more complicated. Segmentation of individual in a word image requires a technique that takes care of the variability of writing. This paper proposed the SFF (Segmentation Facilitate Feature) technique to find seed pixel among candidate pixels based on 3-neighbouring pixels. It is used to find junction pixels which form a junction path to segregate the touched component. The junction path is selected to avoid the issues arising due to artifacts or deletion of components features. For experimentation, 1840 legal amount words containing touching components are used. The above number includes 250 words from benchmark database (ICDAR) and 1590 words are gathered from 15 different writers. On implementing, SFF (Segmentation Facilitate Feature) technique on the above mentioned database, 89.9% accuracy is achieved and a higher accuracy level 96.2% is achieved when performed on 1000 words containing two touching consonants.
C1 [Kohli, Monika] Panjab Univ, Dept Comp Sci & Applicat, Chandigarh, India.
   [Kumar, Satish] Panjab Univ, Dept Comp Sci & Applicat, SSG Reg Ctr, Hoshiarpur, Punjab, India.
C3 Panjab University; Panjab University
RP Kohli, M (corresponding author), Panjab Univ, Dept Comp Sci & Applicat, Chandigarh, India.
EM monikakrajotia@gmail.com
CR Aneja Nagender, 2019, 2019 1st International Conference on Advances in Information Technology (ICAIT). Proceedings, P293, DOI 10.1109/ICAIT47043.2019.8987286
   Avola Danilo, 2010, International Journal of Virtual Technology and Multimedia, V1, P104, DOI 10.1504/IJVTM.2010.032056
   Bansal V, 2002, PATTERN RECOGN, V35, P875, DOI 10.1016/S0031-3203(01)00081-4
   CHEN MY, 1994, IEEE T PATTERN ANAL, V16, P481
   Choudhary A, 2013, PROCEDIA COMPUT SCI, V17, P88, DOI 10.1016/j.procs.2013.05.013
   Co?asnon B., 2011, DOC RECOGNIT RETR 18, V7874
   Dhaka VP, 2015, NEURAL COMPUT APPL, V26, P1881, DOI 10.1007/s00521-015-1844-9
   Gaurav DD, 2012, FEATURE EXTRACTION T, P1
   Gupta D, 2019, MULTIMED TOOLS APPL, V78, P19361, DOI 10.1007/s11042-019-7286-0
   Kamble, 2011, MORPHOLOGICAL APPROA, V3, P99
   Kaur, 2015, T NETWORKS COMMUN, V3, P37, DOI [10.14738/tnc.32.1094, DOI 10.14738/TNC.32.1094]
   Kumar Munish, 2014, International Journal of Information Technology and Computer Science, V6, P58, DOI 10.5815/ijitcs.2014.02.08
   Kumar M, 2015, P 2014 3 INT C REL I
   Kurniawan F, 2011, J ICT RES APPL, V5, P1
   Ladwani V. M., 2010, Proceedings of the Third International Conference on Emerging Trends in Engineering and Technology (ICETET 2010), P219, DOI 10.1109/ICETET.2010.143
   Louloudis G, 2009, PATTERN RECOGN, V42, P3169, DOI 10.1016/j.patcog.2008.12.016
   Lu Y, 1996, PATTERN RECOGN, V29, P77, DOI 10.1016/0031-3203(95)00072-0
   Mamatha H.R., 2012, Int. J. Appl. Inf. Syst, V4, P13, DOI [10.5120/ijais12-450704, DOI 10.5120/IJAIS12-450704]
   Modi N., 2013, IJ ADV RES COMPUT SC, V3, P1075
   Naveena C, 2012, PROCEEDINGS OF THE 2012 WORLD CONGRESS ON INFORMATION AND COMMUNICATION TECHNOLOGIES, P144, DOI 10.1109/WICT.2012.6409065
   Pal U, 2003, PROC INT CONF DOC, P1128
   Pal U, 2003, PATTERN RECOGN LETT, V24, P261, DOI 10.1016/S0167-8655(02)00240-4
   Sarkar, 2010, SCRIPT INDEPENDENT T, V1, P83
   Verma V., 2014, INT J INFORM TECHNOL, V2, P11
NR 24
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 22121
EP 22133
DI 10.1007/s11042-021-10638-0
EA MAR 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000631790800002
DA 2024-07-18
ER

PT J
AU Saman, S
   Narayanan, SJ
AF Saman, Sangeetha
   Narayanan, Swathi Jamjala
TI Active contour model driven by optimized energy functionals for MR brain
   tumor segmentation with intensity inhomogeneity correction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Segmentation; Brain tumor; Active contours; MRI; Region-scalable
   fitting; Level set
AB Segmentation of brain tumors is important for medical diagnosis, treatment planning, and disease development. However, the presence of image artifacts such as noise, intensity inhomogeneity, and partial volume effect in real-world images can aggressively affect the segmentation task. The manual segmentation of the tumor is highly error-prone and is a time-consuming task. Hence, in this work, we propose a methodology that can identify and segment the brain tumor slices in magnetic resonance (MRI) images. The work is composed of three main stages namely pre-processing, segmentation, and post-processing. In the pre-processing stage, N4ITK is applied to correct the intensity inhomogeneity and an Anisotropic diffusion filter is used to remove the noise present in MR images. In the segmentation stage, an active contour model that combines the region scalable fitting energy (RSF) and optimized laplacian of gaussian energy (OLoG) is proposed to segment the tumor region from MRI. The proposed segmentation method first presents an LoG energy term optimized by an energy functional that can smooth the homogeneous regions and enhance edge information simultaneously. Next, the optimized LoG energy term is combined with the RSF energy term which utilizes the local region information to drive the curve towards the boundaries. With the addition of the LoG term, the proposed model is insensitive to the positions of the initial contour and produces an accurate segmentation result. Finally, morphological operations and thresholding are used to extract the tumor region from the segmented image which is computed previously. The performance of the proposed segmentation method is evaluated using the BRATS, and J.Cheng dataset. The obtained experimental results demonstrate that our proposed method significantly outperforms the manual process and state of the art methods in brain tumor segmentation.
C1 [Saman, Sangeetha; Narayanan, Swathi Jamjala] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Narayanan, SJ (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
EM sangeethacse1990@gmail.com; swathi.jns@gmail.com
RI Narayanan S J, Jishnu/GQH-1507-2022
OI Narayanan S J, Jishnu/0000-0002-5950-5877; , Swathi
   S/0000-0002-5926-6423
CR Al-Saffar ZA, 2020, IEEE ACCESS, V8, P52575, DOI 10.1109/ACCESS.2020.2980728
   [Anonymous], 2007, 2007 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2007.383014
   [Anonymous], 1996, Level Set Methods: Evolving Interfaces in Computational Geometry, Fluid Mechanics, Computer Vision, and Materials Science
   [Anonymous], 2017, BRAIN TUM STAT
   Aswathy SU, 2019, CLUSTER COMPUT, V22, P13369, DOI 10.1007/s10586-018-1914-8
   Balafar MA, 2014, ARTIF INTELL REV, V41, P441, DOI 10.1007/s10462-012-9318-2
   Ben Naceur M, 2018, COMPUT METH PROG BIO, V166, P39, DOI 10.1016/j.cmpb.2018.09.007
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chaplot S, 2006, BIOMED SIGNAL PROCES, V1, P86, DOI 10.1016/j.bspc.2006.05.002
   Cheng J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157112
   Csillik O, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9030243
   Deepa B, 2019, MULTIDIM SYST SIGN P, V30, P2081, DOI 10.1007/s11045-019-00642-x
   Ding KY, 2017, SIGNAL PROCESS, V134, P224, DOI 10.1016/j.sigpro.2016.12.021
   Dogra J, 2020, VISUAL COMPUT, V36, P875, DOI 10.1007/s00371-019-01698-3
   Farhi L, 2017, J VIS COMMUN IMAGE R, V46, P303, DOI 10.1016/j.jvcir.2017.04.013
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Gupta N, 2018, J COMPUT SCI-NETH, V25, P213, DOI 10.1016/j.jocs.2017.02.009
   Hasan AM, 2016, SYMMETRY-BASEL, V8, DOI 10.3390/sym8110132
   Hasan S M Kamrul, 2018, Brain Inform, V5, P8, DOI 10.1186/s40708-018-0086-x
   Held K, 1997, IEEE T MED IMAGING, V16, P878, DOI 10.1109/42.650883
   Ho S, 2002, INT C PATT RECOG, P532, DOI 10.1109/ICPR.2002.1044788
   Hu K, 2019, IEEE ACCESS, V7, P92615, DOI 10.1109/ACCESS.2019.2927433
   Ibrahim RW, 2018, COMPUT METH PROG BIO, V163, P21, DOI 10.1016/j.cmpb.2018.05.031
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kaya IE, 2017, COMPUT METH PROG BIO, V140, P19, DOI 10.1016/j.cmpb.2016.11.011
   Kermi A, 2018, IET IMAGE PROCESS, V12, P1964, DOI 10.1049/iet-ipr.2017.1124
   Khosravanian A, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105809
   Kimmel R, 2003, INT J COMPUT VISION, V53, P225, DOI 10.1023/A:1023030907417
   Krishnarajan S, 2020, J CONFLICT RESOLUT, V64, P1279, DOI 10.1177/0022002719900001
   Kumar GA, 2018, AUTOM CONTROL COMPUT, V52, P439, DOI 10.3103/S0146411618050048
   LAUTERBUR PC, 1973, NATURE, V242, P190, DOI 10.1038/242190a0
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Lin F, 2020, MULTIMED TOOLS APPL, P1
   Louis DN, 2016, ACTA NEUROPATHOL, V131, P803, DOI 10.1007/s00401-016-1545-1
   Ma C, 2018, IEEE T MED IMAGING, V37, P1943, DOI 10.1109/TMI.2018.2805821
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Nayak DR, 2016, NEUROCOMPUTING, V177, P188, DOI 10.1016/j.neucom.2015.11.034
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pratondo A, 2017, J VIS COMMUN IMAGE R, V43, P1, DOI 10.1016/j.jvcir.2016.11.019
   Sachdeva J, 2013, J DIGIT IMAGING, V26, P1141, DOI 10.1007/s10278-013-9600-0
   Sharma A, 2019, MULTIDIM SYST SIGN P, V30, P1263, DOI 10.1007/s11045-018-0603-3
   Tarkhaneh O, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.07.037
   Tian GJ, 2011, IEEE T INF TECHNOL B, V15, P373, DOI 10.1109/TITB.2011.2106135
   Tustison NJ, 2010, IEEE T MED IMAGING, V29, P1310, DOI 10.1109/TMI.2010.2046908
   Verma VS, 2019, MAGN RESON IMAGING
   Zeineldin RA, 2020, INT J COMPUT ASS RAD, V15, P909, DOI 10.1007/s11548-020-02186-z
NR 50
TC 16
Z9 16
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21925
EP 21954
DI 10.1007/s11042-021-10738-x
EA MAR 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000630993600001
DA 2024-07-18
ER

PT J
AU Roy, M
   Chakraborty, S
   Mali, K
AF Roy, Mousomi
   Chakraborty, Shouvik
   Mali, Kalyani
TI The MSK: a simple and robust image encryption method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hybrid image encryption; Cryptography; Bitplane decomposition; Chaotic
   maps; Bit-level scrambling; Security analysis
ID CHAOS-BASED IMAGE; SELECTIVE ENCRYPTION; TRANSFORM; SCHEME; MAP
AB This article proposes a new image encryption approach based on bitplane decomposition methods and chaotic maps. This approach does not depend on any additional images to initiate the encryption process. The encryption method involves a chaotic logistic map to create the initial security bitplanes. The proposed approach is flexible enough to choose any one of the available bitplane decomposition methods. Moreover, some different scrambling algorithms can be used that can efficiently scramble the bitplanes, instead of using the proposed scrambling algorithm. The proposed method can be implemented very easily and does not involve highly complex operations that makes the algorithm suitable for real time applications. The proposed method is simulated, tested, compared with some standard image encryption approaches and analyzed with the help of some standard cipher image evaluation parameters. Both visual and quantitative analysis of the obtained results are presented in detail. The results of the experiments are very promising and shows effective encryption performance on various types of images, that makes the proposed algorithm suitable for the real-life applications. The experimental results also demonstrate the strength of the proposed algorithm against different types of the cryptographic attacks.
C1 [Roy, Mousomi; Chakraborty, Shouvik; Mali, Kalyani] Univ Kalyani, Dept Comp Sci & Engn, Kalyani, W Bengal, India.
C3 Kalyani University
RP Chakraborty, S (corresponding author), Univ Kalyani, Dept Comp Sci & Engn, Kalyani, W Bengal, India.
EM iammouroy@gmail.com; shouvikchakraborty51@gmail.com;
   kalyanimali1992@gmail.com
CR AGAIAN S, 1995, SIGNAL PROCESS, V41, P101, DOI 10.1016/0165-1684(94)00093-F
   Ahmed HEH, 2006, OPT ENG, V45, DOI 10.1117/1.2358991
   Aulí-Llinàs F, 2012, IEEE T IMAGE PROCESS, V21, P1920, DOI 10.1109/TIP.2011.2176953
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Chakraborty S, 2016, INT J SECUR APPL, V10, P205, DOI 10.14257/ijsia.2016.10.2.19
   Cheng H, 2000, IEEE T SIGNAL PROCES, V48, P2439, DOI 10.1109/78.852023
   COOPERSMITH D, 1994, IBM J RES DEV, V38, P243, DOI 10.1147/rd.383.0243
   Cui GZ, 2008, 2008 THIRD INTERNATIONAL CONFERENCE ON BIO-INSPIRED COMPUTING: THEORIES AND APPLICATIONS, P37, DOI 10.1109/BICTA.2008.4656701
   Daemen J., 1999, 1 CAND C AES1
   Daemen J., 2020, The Design of Rijndael-The Advanced Encryption Standard (AES), V2nd, DOI [10.1007/978-3-662-60769-5, DOI 10.1007/978-3-662-60769-5]
   De Silva DVSX, 2010, ELECTRON LETT, V46, P1546, DOI 10.1049/el.2010.2320
   Gehani A., 2000, DNA Based Computers V. DIMACS Workshop (Series in Discrete Mathematics and Theoretical Computer Science Vol.54), P233
   Gehani A, 2004, LECT NOTES COMPUT SC, V2950, P167
   GEVORKIAN DZ, 1995, IEEE T SIGNAL PROCES, V43, P286, DOI 10.1109/78.365308
   Gonzalez R., 2008, DIGITAL IMAGE PROCES, V1, P376
   Grangetto M, 2006, IEEE T MULTIMEDIA, V8, P905, DOI 10.1109/TMM.2006.879919
   Han JW, 1999, OPT ENG, V38, P47, DOI 10.1117/1.602060
   Hu JK, 2009, J NETW COMPUT APPL, V32, P788, DOI 10.1016/j.jnca.2009.02.009
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Jolfaei Alireza, 2010, International Journal of Computer and Network Security, V2, P38
   Kamali SH, 2010, ICEIE 2010 2010 INT
   Ko SJ, 1999, IEEE T CONSUM ELECTR, V45, P598, DOI 10.1109/30.793546
   Leong MP, 2000, ANN IEEE SYM FIELD P, P122, DOI 10.1109/FPGA.2000.903399
   Li S, 2006, MULTIMEDIA ENCRYPTIO, V129
   Luo RC, 2002, IEEE T IND ELECTRON, V49, P933, DOI 10.1109/TIE.2002.801252
   Moon D, 2006, ETRI J, V28, P444, DOI 10.4218/etrij.06.0106.0013
   Mozaffari S, 2018, MULTIMED TOOLS APPL, V77, P25799, DOI 10.1007/s11042-018-5817-8
   Pareek NK, 2003, PHYS LETT A, V309, P75, DOI 10.1016/S0375-9601(03)00122-1
   Patidar V, 2009, INFORM-J COMPUT INFO, V33, P441
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Qi M, 2010, J NETW COMPUT APPL, V33, P247, DOI 10.1016/j.jnca.2009.12.004
   Qiudong Sun, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P2630, DOI 10.1109/CECNet.2012.6201673
   Roy M., 2020, APPL ADV MACHINE INT, P1, DOI [10.1007/s11042-021-10761-y, DOI 10.1007/S11042-021-10761-Y]
   Seal A, 2017, NEW RESILIENT IMAGE
   Shujun L., 2001, LECT NOTES COMPUTER, V2247, P316, DOI DOI 10.1007/3-540-45311-3_30
   Standard DE, 1999, FEDERAL INFORM PROCE, V112
   Sun FY, 2010, OPT COMMUN, V283, P2066, DOI 10.1016/j.optcom.2010.01.028
   Wadi SM, 2014, WIRELESS PERS COMMUN, V79, P811, DOI 10.1007/s11277-014-1888-7
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang X, 2009, INT J CONTROL, V82, P1870, DOI 10.1080/00207170902802984
   Wu XJ, 2016, INFORM SCIENCES, V349, P137, DOI 10.1016/j.ins.2016.02.041
   Wu Y, 2014, INFORM SCIENCES, V264, P317, DOI 10.1016/j.ins.2013.11.027
   Xu M, 2019, INFORM SCIENCES, V478, P1, DOI 10.1016/j.ins.2018.11.010
   Ye RS, 2011, OPT COMMUN, V284, P5290, DOI 10.1016/j.optcom.2011.07.070
   Yu XY, 2006, J PHYS CONF SER, V48, P408, DOI 10.1088/1742-6596/48/1/077
   Yue TW, 2007, J NETW COMPUT APPL, V30, P24, DOI 10.1016/j.jnca.2005.08.003
   Zahmoul R, 2017, OPT LASER ENG, V96, P39, DOI 10.1016/j.optlaseng.2017.04.009
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
   Zhou YC, 2013, IEEE T CYBERNETICS, V43, P515, DOI 10.1109/TSMCB.2012.2210706
   Zhou YC, 2012, OPT COMMUN, V285, P594, DOI 10.1016/j.optcom.2011.11.044
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 54
TC 8
Z9 9
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21261
EP 21291
DI 10.1007/s11042-021-10761-y
EA MAR 2021
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000629113400004
DA 2024-07-18
ER

PT J
AU Kahlessenane, F
   Khaldi, A
   Kafi, MR
   Euschi, S
AF Kahlessenane, Fares
   Khaldi, Amine
   Kafi, Med Redouane
   Euschi, Salah
TI A color value differentiation scheme for blind digital image
   watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Blind watermark; Digital image; Fragile
   watermarking; Spatial domain; Least significant bit; Pixels value
   difference
ID DECOMPOSITION
AB In order to contribute to the security of medical image, we present in this paper a blind and robust watermarking technique that allows the integration of the electronic patient's record into retinal images. In our work, we present an approach developed to find a compromise between capacity and imperceptibility. The proposed blind watermarking approach is based on the color values difference calculation between pixels to determine the substitution to be made. We proposed in this work ten possible variants of this approach to determine which offers the best compromise between the capacity and the imperceptibility. Following the evaluation of the approach by metrics designed for reliability tests, some variants confirm remarkably good results either by objective or subjective evaluation. The capacity and imperceptibility evaluations reveal very encouraging results. We obtained good results concerning the imperceptibility with a PSNR greater than 69 dB for some variants due to the insignificance of the least significant bits modification. An evaluation of the watermark's robustness demonstrates the proposed schemas generate reasonably robust watermarked samples against various attacks. A high-quality watermark with a normalized cross-correlation greater than 0.9 for some variants is obtained. However, some variants remain weak in terms of robustness because any simple treatment can modify the LSBs, which makes the extraction impossible.
C1 [Kahlessenane, Fares; Khaldi, Amine; Kafi, Med Redouane; Euschi, Salah] Univ Kasdi Merbah, Fac Sci & Technol, Dept Comp Sci, Artificial Intelligence & Informat Technol Lab LI, Ouargla 30000, Algeria.
C3 Universite Kasdi Merbah Ouargla
RP Khaldi, A (corresponding author), Univ Kasdi Merbah, Fac Sci & Technol, Dept Comp Sci, Artificial Intelligence & Informat Technol Lab LI, Ouargla 30000, Algeria.
EM Khaldi.Amine@univ-ouargla.dz
RI Khaldi, Amine/AAV-1266-2020; Kafi, Mohamed Redouane/AAT-2301-2021
OI Khaldi, Amine/0000-0002-1637-9129; Kafi, Mohamed
   Redouane/0000-0002-5500-0943; Salah, EUSCHI/0000-0002-8724-1530;
   KAHLESSENANE, Fares/0000-0003-1193-6325
CR Abraham J, 2019, J KING SAUD UNIV-COM, V31, P125, DOI 10.1016/j.jksuci.2016.12.004
   Ahmaderaghi B, 2018, IEEE T COMPUT IMAG, V4, P46, DOI 10.1109/TCI.2018.2794065
   Amini M, 2019, IEEE T MULTIMEDIA, V21, P65, DOI 10.1109/TMM.2018.2851447
   Aparna P, 2019, IET IMAGE PROCESS, V13, P421, DOI 10.1049/iet-ipr.2018.5288
   Bhat SA, 2018, 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT CIRCUITS AND SYSTEMS (ICICS 2018), P334, DOI 10.1109/ICICS.2018.00075
   Dubolia R., 2011, 2011 International Conference on Communication Systems and Network Technologies (CSNT), P593, DOI 10.1109/CSNT.2011.127
   Ernawan F, 2018, IEEE ACCESS, V6, P20464, DOI 10.1109/ACCESS.2018.2819424
   Euschi S., 2020, OPTIK, V208
   Hu Q, 2013, LECT NOTES COMPUT SC, V8150, P436, DOI 10.1007/978-3-642-40763-5_54
   Jung K, 2019, SECUR COMMUN NETW
   Kahlessenane F, 2021, J AMB INTEL HUM COMP, V12, P2931, DOI 10.1007/s12652-020-02450-9
   Khaldi A., 2019, INT ANN SCI, V8, P143, DOI [10.21467/ias.8.1.143-149, DOI 10.21467/IAS.8.1.143-149]
   Khaldi A., 2020, IJCVR, V10, P373, DOI [10.1504/IJCVR.2020.109389, DOI 10.1504/IJCVR.2020.109389]
   Khaldi A., 2018, REV DIREITO ESTA MAY, V10, P147
   Kim C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040644
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Koju R, 2016, PROCEEDINGS OF THE 2016 IEEE 2ND INTERNATIONAL CONFERENCE ON ADVANCES IN ELECTRICAL & ELECTRONICS, INFORMATION, COMMUNICATION & BIO INFORMATICS (IEEE AEEICB-2016), P509, DOI 10.1109/AEEICB.2016.7538342
   Kwon OJ, 2018, IEEE ACCESS, V6, P46194, DOI 10.1109/ACCESS.2018.2866153
   Leng L, 2020, APPL SCI, V10, P1
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Murugan B, 2016, IET COMPUT VIS, V10, P593, DOI 10.1049/iet-cvi.2015.0344
   Peng F, 2014, COMPUT AIDED DESIGN, V49, P42, DOI 10.1016/j.cad.2013.12.006
   Peng F, 2011, COMPUT AIDED DESIGN, V43, P1018, DOI 10.1016/j.cad.2011.03.011
   Sampat MP, 2009, IEEE T IMAGE PROCESS, V18, P2385, DOI 10.1109/TIP.2009.2025923
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Shukla D, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P1647, DOI 10.1109/WiSPNET.2016.7566419
   Singh H, 2018, IET IMAGE PROCESS, V12, P1994, DOI 10.1049/iet-ipr.2018.5399
   Su QT, 2019, IEEE ACCESS, V7, P4358, DOI 10.1109/ACCESS.2018.2888857
   Usha Nandini D., 2017, P 2017 INT C INVENTI, P1, DOI [10.1109/ICISC.2017.8068717, DOI 10.1109/ICISC.2017.8068717]
   Xiang LY, 2018, MULTIMED TOOLS APPL, V77, P28969, DOI 10.1007/s11042-018-6072-8
   Xiang LY, 2018, CMC-COMPUT MATER CON, V55, P541, DOI 10.3970/cmc.2018.03510
   Xiong XG, 2019, IEEE ACCESS, V7, P136592, DOI 10.1109/ACCESS.2019.2942449
NR 34
TC 17
Z9 17
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19827
EP 19844
DI 10.1007/s11042-021-10713-6
EA MAR 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000624399500001
DA 2024-07-18
ER

PT J
AU Al-Otum, HM
   Ibrahim, M
AF Al-Otum, Hazem Munawer
   Ibrahim, Mouaz
TI Color image watermarking for content authentication and self-restoration
   applications based on a dual-domain approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Tamper detection and localization; Self-restoration;
   The discrete cosine transform (DCT); Singular value decomposition and
   least significant bit approaches
ID FRAGILE WATERMARKING; TAMPERING DETECTION; SCHEME
AB Digital image watermarking has been witnessed as a powerful tool that can be used in image ownership identification, copyright protection and content authentication applications. In this paper, a dual-domain watermarking scheme for digital image authentication with self-recovery capabilities is proposed. The proposed scheme has a high ability to recover tampered image regions while pertaining high watermarking imperceptibility and high robustness under various types of attacks. The proposed scheme employs two watermarks: 1) content-dependent, and, 2) content-independent, where the content-dependent watermark contains two-bit sequences for authentication and recovery operations. The authentication bits are generated based on the singular value decomposition (SVD) of each block, while the recovery bits are generated from the average value within selected sub-blocks. The independent watermark is embedded using the Discrete Cosine Transform (DCT), whereas, the dependent watermark is embedded directly into the first and second least significant bits (LSB) of the image pixels. The developed dual-domain watermarking scheme has exhibited high robustness performance against various attacks with high imperceptibility and watermarking capacity as well. For authentication purposes, the proposed scheme incorporated three developed measures to detect the authenticity of the probe image, and, to accurately localize tampered regions. The experimental results have shown that the proposed scheme has a high imperceptibility, compared to other existing schemes, and can effectively distinguish malicious from incidental attacks with accurate tampering localization. Moreover, the proposed scheme exhibits high performance against moderate-to-strong incidental attacks such as noise and low-quality JPEG attacks.
C1 [Al-Otum, Hazem Munawer; Ibrahim, Mouaz] Jordan Univ Sci & Technol, EE Dept, POB 3030, Irbid 22110, Jordan.
C3 Jordan University of Science & Technology
RP Al-Otum, HM (corresponding author), Jordan Univ Sci & Technol, EE Dept, POB 3030, Irbid 22110, Jordan.
EM hazem-ot@just.edu.jo; myibrahim15@eng.just.edu.jo
OI Al-Otum, Hazem/0000-0002-3628-3191
CR Barani MJ, 2019, OPTIK, V187, P205, DOI 10.1016/j.ijleo.2019.04.074
   Begum M, 2020, INFORMATION, V11, DOI 10.3390/info11020110
   Dadkhah S, 2014, SIGNAL PROCESS-IMAGE, V29, P1197, DOI 10.1016/j.image.2014.09.001
   Ernawan F, 2020, VISUAL COMPUT, V36, P19, DOI 10.1007/s00371-018-1567-x
   Fan MQ, 2018, SIGNAL PROCESS-IMAGE, V66, P19, DOI 10.1016/j.image.2018.04.003
   Ghosal SK, 2014, J INF SECUR APPL, V19, P272, DOI 10.1016/j.jisa.2014.07.004
   Hemida O, 2020, MULTIMED TOOLS APPL, V79, P18695, DOI 10.1007/s11042-020-08727-7
   Kalra GS, 2015, MULTIMED TOOLS APPL, V74, P6849, DOI 10.1007/s11042-014-1932-3
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Liu XL, 2018, IEEE T CIRC SYST VID, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Lu CS, 2001, IEEE T IMAGE PROCESS, V10, P1579, DOI 10.1109/83.951542
   Lusson F, 2013, SIGNAL PROCESS, V93, P1268, DOI 10.1016/j.sigpro.2012.10.018
   Molina-Garcia J, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115725
   Nematollahi Mohammad Ali, 2017, Digital watermarking
   Patra B, 2012, I S INTELL SIG PROC
   Qi XJ, 2015, J VIS COMMUN IMAGE R, V30, P312, DOI 10.1016/j.jvcir.2015.05.006
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Savakar D. G., 2017, Pattern Recognition and Image Analysis, V27, P511, DOI 10.1134/S1054661817030257
   Sikder I, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND COMMUNICATION ENGINEERING (ECCE), P881, DOI 10.1109/ECACE.2017.7913027
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Tai WL, 2018, SIGNAL PROCESS-IMAGE, V65, P11, DOI 10.1016/j.image.2018.03.011
   Tong XJ, 2013, SIGNAL PROCESS-IMAGE, V28, P301, DOI 10.1016/j.image.2012.12.003
   Zhang F, 2007, PATTERN RECOGN LETT, V28, P1, DOI 10.1016/j.patrec.2006.04.020
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
NR 25
TC 9
Z9 9
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11739
EP 11764
DI 10.1007/s11042-020-10368-9
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RQ2GA
UT WOS:000642237200001
DA 2024-07-18
ER

PT J
AU Frasca, M
   Tortora, G
AF Frasca, Maria
   Tortora, Genoveffa
TI Visualizing correlations among Parkinson biomedical data through
   information retrieval and machine learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biomedical data analysis; Health information visualization; Information
   retrieval; Machine learning
AB In the last few years, the integration of researches in Computer Science and medical fields has made available to the scientific community an enormous amount of data, stored in databases. In this paper, we analyze the data available in the Parkinson's Progression Markers Initiative (PPMI), a comprehensive observational, multi-center study designed to identify progression biomarkers important for better treatments for Parkinson's disease. The data of PPMI participants are collected through a comprehensive battery of tests and assessments including Magnetic Resonance Imaging and DATscan imaging, collection of blood, cerebral spinal fluid, and urine samples, as well as cognitive and motor evaluations. To this aim, we propose a technique to identify a correlation between the biomedical data in the PPMI dataset for verifying the consistency of medical reports formulated during the visits and allow to correctly categorize the various patients. To correlate the information of each patient's medical report, Information Retrieval and Machine Learning techniques have been adopted, including the Latent Semantic Analysis, Text2Vec and Doc2Vec techniques. Then, patients are grouped and classified into affected or not by using clustering algorithms according to the similarity of medical reports. Finally, we have adopted a visualization system based on the D3 framework to visualize correlations among medical reports with an interactive chart, and to support the doctor in analyzing the chronological sequence of visits in order to diagnose Parkinson's disease early.
C1 [Frasca, Maria; Tortora, Genoveffa] Univ Salerno, Salerno, Italy.
C3 University of Salerno
RP Frasca, M (corresponding author), Univ Salerno, Salerno, Italy.
EM mfrasca@unisa.it
RI Frasca, Maria/JGE-0224-2023; Tortora, Genoveffa/M-8155-2019
OI Frasca, Maria/0000-0003-3164-1858; 
FU Universita degli Studi di Salerno within the CRUI-CARE Agreement
FX Open Access funding provided by Universita degli Studi di Salerno within
   the CRUI-CARE Agreement.
CR Aigner Wolfgang, 2011, Foundations and Trends in Human-Computer Interaction, V5, P207, DOI 10.1561/1100000039
   Anagaw A, 2019, J AMB INTEL HUM COMP, V10, P3889, DOI 10.1007/s12652-018-1160-1
   [Anonymous], 2014, MAY THYROID GLAND TH
   [Anonymous], 2010, 12 IEEE INT S WEB SY
   Beam AL., 2018, ARXIV PREPRINT ARXIV
   Blaas J., 2007, EuroVis, P123
   Bleik S, 2013, IEEE ACM T COMPUT BI, V10, P1211, DOI 10.1109/TCBB.2013.16
   Bouadjenek MR, 2017, DATABASE-OXFORD, DOI 10.1093/database/bax062
   Chen HC, 2005, INT SER I S, V8, P3
   Chen Q, 2018, ARXIV180500352
   Chou SC, 2008, IEEE ENG MED BIO, P1474, DOI 10.1109/IEMBS.2008.4649446
   Citarella AA, 2019, IEEE INT CON INF VIS, P269, DOI 10.1109/IV.2019.00052
   Davie CA, 2008, BRIT MED BULL, V86, P109, DOI 10.1093/bmb/ldn013
   Dynomant E, 2019, ARXIV191111698
   Euzenat J, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P348
   GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473
   Gefen D, 2018, COMMUN ACM, V61, P72, DOI 10.1145/3209086
   Gelb DJ, 1999, ARCH NEUROL-CHICAGO, V56, P33, DOI 10.1001/archneur.56.1.33
   Hu G, 2010, PARKINSONS DIS-US, V2010, DOI 10.4061/2010/836962
   Khan Aurangzeb, 2010, Journal of Advances in Information Technology, V1, P4, DOI 10.4304/jait.1.1.4-20
   Lesselroth B.J., 2011, Data visualization strategies for the electronic health record
   Li QZ, 2006, J BIOMED INFORM, V39, P668, DOI 10.1016/j.jbi.2006.02.001
   Mao WL, 2007, DATA KNOWL ENG, V61, P76, DOI 10.1016/j.datak.2006.02.008
   Marek K, 2011, PROG NEUROBIOL, V95, P629, DOI 10.1016/j.pneurobio.2011.09.005
   Munhoz RP, 2004, PARKINSONISM RELAT D, V10, P381, DOI 10.1016/j.parkreldis.2004.03.008
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Rajaraman A., 2011, Data mining, P1, DOI DOI 10.1017/CBO9781139058452.002
   Romano S., 2011, 2011 IEEE 27th International Conference on Software Maintenance, P500, DOI 10.1109/ICSM.2011.6080818
   Ropinski T, 2011, COMPUT GRAPH-UK, V35, P392, DOI 10.1016/j.cag.2011.01.011
   Selivanov D., 2016, text2vec: Modern Text Mining Framework for R
   Singh, 2000, 1 WORKSH HIGH PERF D
   Uysal AK, 2014, INFORM PROCESS MANAG, V50, P104, DOI 10.1016/j.ipm.2013.08.006
   West VL, 2015, J AM MED INFORM ASSN, V22, P330, DOI 10.1136/amiajnl-2014-002955
   Xu Q, 2011, DIABETES CARE, V34, P910, DOI 10.2337/dc10-1922
   Zhou GD, 2004, BIOINFORMATICS, V20, P1178, DOI 10.1093/bioinformatics/bth060
NR 35
TC 3
Z9 3
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 14685
EP 14703
DI 10.1007/s11042-021-10506-x
EA FEB 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000622668700002
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, XX
   Wang, ZY
   Zhang, YS
   Jiang, XW
   Cal, ZH
AF Wang, Xinxin
   Wang, Zhenyu
   Zhang, Yongshan
   Jiang, Xinwei
   Cal, Zhihua
TI Latent representation learning based autoencoder for unsupervised
   feature selection in hyperspectral imagery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autoencoder; Unsupervised feature selection; Latent representation
   learning; Hyperspectral image classification
ID FEATURE-EXTRACTION; CLASSIFICATION
AB In hyperspectral image (HSI) analysis, high-dimensional data may contain noisy, irrelevant and redundant information. To mitigate the negative effect from these information, feature selection is one of the useful solutions. Unsupervised feature selection is a data preprocessing technique for dimensionality reduction, which selects a subset of informative features without using any label information. Different from the linear models, the autoencoder is formulated to nonlinearly select informative features. The adjacency matrix of HSI can be constructed to extract the underlying relationship between each data point, where the latent representation of original data can be obtained via matrix factorization. Besides, a new feature representation can be also learnt from the autoencoder. For a same data matrix, different feature representations should consistently share the potential information. Motivated by these, in this paper, we propose a latent representation learning based autoencoder feature selection (LRLAFS) model, where the latent representation learning is used to steer feature selection for the autoencoder. To solve the proposed model, we advance an alternative optimization algorithm. Experimental results on three HSI datasets confirm the effectiveness of the proposed model.
C1 [Wang, Xinxin; Wang, Zhenyu; Zhang, Yongshan; Jiang, Xinwei; Cal, Zhihua] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China.
C3 China University of Geosciences
RP Zhang, YS (corresponding author), China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China.
EM wangxinxin@cug.edu.cn; zhenyuwang94@gmail.com; yszhang.cug@gmail.com;
   ysjxw@hotmail.com; zhcai@cug.edu.cn
FU National Nature Science Foundation of China [61703355]; Natural Science
   Foundation of Hubei Province of China [2020CFB328]; Fundamental Research
   Funds for the Central Universities, China University of Geosciences
   (Wuhan)
FX This work is supported in part by the National Nature Science Foundation
   of China under Grant 61703355, the Natural Science Foundation of Hubei
   Province of China under Grant 2020CFB328, the Fundamental Research Funds
   for the Central Universities, China University of Geosciences (Wuhan).
CR Abid A, 2019, PR MACH LEARN RES, V97
   Andrychowicz M, 2016, ADV NEUR IN, V29
   [Anonymous], 2005, ADV NEURAL INF PROCE
   Cai D., 2010, KDD, P333
   Chandra B, 2015, 2015 INT JOINT C NEU, P1, DOI DOI 10.1109/IJCNN.2015.7280391
   Fauvel M, 2015, IEEE J-STARS, V8, P2824, DOI 10.1109/JSTARS.2015.2441771
   Feng J, 2016, PATTERN RECOGN, V51, P295, DOI 10.1016/j.patcog.2015.08.018
   FENG S, 2018, AS C SIGN SYST COMP, P55
   Gnouma M, 2019, MULTIMED TOOLS APPL, V78, P2157, DOI 10.1007/s11042-018-6273-1
   Gui J, 2017, IEEE T NEUR NET LEAR, V28, P1490, DOI 10.1109/TNNLS.2016.2551724
   Han K, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2941, DOI 10.1109/ICASSP.2018.8462261
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Jia WJ, 2019, MULTIMED TOOLS APPL, V78, P4045, DOI 10.1007/s11042-017-5174-z
   Jiang JJ, 2018, IEEE T GEOSCI REMOTE, V56, P4581, DOI 10.1109/TGRS.2018.2828029
   Li J, 2009, SIAM INT C DATA MINI, P387
   Li ZC, 2015, IEEE T IMAGE PROCESS, V24, P5343, DOI 10.1109/TIP.2015.2479560
   Li ZC, 2014, IEEE T KNOWL DATA EN, V26, P2138, DOI 10.1109/TKDE.2013.65
   Lunga D, 2014, IEEE SIGNAL PROC MAG, V31, P55, DOI 10.1109/MSP.2013.2279894
   Maillo J, 2020, IEEE T FUZZY SYST, V28, P874, DOI 10.1109/TFUZZ.2019.2936356
   Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133
   Pal M, 2010, IEEE T GEOSCI REMOTE, V48, P2297, DOI 10.1109/TGRS.2009.2039484
   Prasad S, 2008, IEEE GEOSCI REMOTE S, V5, P625, DOI 10.1109/LGRS.2008.2001282
   Saha, 2014, ADV NEURAL INFORM PR, P1853
   Serpico SB, 2001, IEEE T GEOSCI REMOTE, V39, P1360, DOI 10.1109/36.934069
   Shen LL, 2013, IEEE GEOSCI REMOTE S, V10, P29, DOI 10.1109/LGRS.2012.2191761
   Shuangjiang Li, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2693, DOI 10.1109/ICIP.2011.6116223
   Tang C, 2019, NEURAL NETWORKS, V117, P163, DOI 10.1016/j.neunet.2019.04.015
   Taskin G, 2017, IEEE T IMAGE PROCESS, V26, P2918, DOI 10.1109/TIP.2017.2687128
   Wan YT, 2020, IEEE T GEOSCI REMOTE, V58, P3601, DOI 10.1109/TGRS.2019.2958812
   Wang SY, 2017, AAAI CONF ARTIF INTE, P2725
   Wang SH, 2015, AAAI CONF ARTIF INTE, P470
   Yang X, 2019, PROC CVPR IEEE, P4061, DOI 10.1109/CVPR.2019.00419
   Yang Yi., 2011, Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence, AAAI'11, P555
   Zeng K, 2017, IEEE T CYBERNETICS, V47, P27, DOI 10.1109/TCYB.2015.2501373
   Zhang YS, 2020, IEEE T MULTIMEDIA, V22, P2844, DOI 10.1109/TMM.2020.2966887
   Zhang YS, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11171983
   Zhang YS, 2019, NEURAL NETWORKS, V112, P85, DOI 10.1016/j.neunet.2019.01.007
   Zhou YC, 2015, IEEE T GEOSCI REMOTE, V53, P1082, DOI 10.1109/TGRS.2014.2333539
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
NR 39
TC 20
Z9 38
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12061
EP 12075
DI 10.1007/s11042-020-10474-8
EA FEB 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000622668700001
DA 2024-07-18
ER

PT J
AU Zhang, YQ
   Huang, HF
   Wang, XY
   Huang, XH
AF Zhang, Ying-Qian
   Huang, Hui-Fang
   Wang, Xing-Yuan
   Huang, Xin-Hao
TI A secure image encryption scheme based on genetic mutation and MLNCML
   chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaotic map; Genetic mutation; Crossover
ID HYPER-CHAOS; ALGORITHM; PERMUTATION; IMPROVEMENT; OPERATION
AB This paper presents a novel encryption scheme based on genetic operations and Mixed Linear-Nonlinear Coupled Logistic Map Lattice (MLNCML) spatiotemporal chaotic system. The initial values of the MLNCML system are related to the plain-image. Therefore, this scheme is sensitive to the plaintext and keys. For the simplicity and efficiency of the encryption process, expanded XOR (eXOR) operation and genetic operations are applied in the scheme. Spatiotemporal chaotic system can resist dynamical degradation and periodic phenomena, which offers good randomness for encryption. Moreover, the eXOR operation in this paper can effectively avoid the chosen-plaintext attack of traditional XOR operation. The DNA mutation and crossover operations are controlled by chaotic sequences, which overcome man-in-the-middle attack in the traditional DNA addition and subtraction operation. The experimental results indicate that the proposed scheme has good security to resist common attacks.
C1 [Zhang, Ying-Qian; Huang, Hui-Fang; Huang, Xin-Hao] Xiamen Univ, Tan Kah Kee Coll, Sch Informat Sci & Technol, Zhangzhou 363105, Peoples R China.
   [Wang, Xing-Yuan] Dalian Maritime Univ, Informat Sci & Technol Coll, Dalian 116023, Peoples R China.
C3 Xiamen University; Dalian Maritime University
RP Zhang, YQ; Huang, HF (corresponding author), Xiamen Univ, Tan Kah Kee Coll, Sch Informat Sci & Technol, Zhangzhou 363105, Peoples R China.
EM zhangyqxmu@xmu.edu.cn; 13661363592@163.com
RI Wang, Xing-yuan/I-6353-2015; Zhang, Yingqian/CAI-2129-2022; Zhang,
   Ying-Qian/AGS-3457-2022
OI Zhang, Yingqian/0000-0001-9568-0392; 
FU Program for the Natural Science Foundation of Fujian Province of China
   [2018 J01100]; National Natural Science Foundation of China [61672124];
   Password Theory Project of the 13th Five-Year Plan National Cryptography
   Development Fund [MMJJ20170203]; Liaoning Province Science and
   Technology Innovation Leading Talents Program Project [XLYC1802013]; Key
   R&D Projects of Liaoning Province [2019020105-JH2/103]; Educational
   Scientific Research of Middle-aged and Young Teacher of Fujian Province
   of China [JAT191078]
FX This research is supported by the Program for the Natural Science
   Foundation of Fujian Province of China (No.2018 J01100), the National
   Natural Science Foundation of China (No: 61672124), the Password Theory
   Project of the 13th Five-Year Plan National Cryptography Development
   Fund (No: MMJJ20170203), Liaoning Province Science and Technology
   Innovation Leading Talents Program Project (No: XLYC1802013), Key R&D
   Projects of Liaoning Province (No: 2019020105-JH2/103), Educational
   Scientific Research of Middle-aged and Young Teacher of Fujian Province
   of China (No: JAT191078).
CR Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chapaneri S, 2014, 2014 INTERNATIONAL CONFERENCE ON CIRCUITS, SYSTEMS, COMMUNICATION AND INFORMATION TECHNOLOGY APPLICATIONS (CSCITA), P59, DOI 10.1109/CSCITA.2014.6839235
   Dhall S, 2018, SIGNAL PROCESS, V146, P22, DOI 10.1016/j.sigpro.2017.12.021
   Guo SF, 2018, MULTIMED TOOLS APPL, V77, P21109, DOI 10.1007/s11042-017-5570-4
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Kocarev L., 1998, ISCAS '98. Proceedings of the 1998 IEEE International Symposium on Circuits and Systems (Cat. No.98CH36187), P514, DOI 10.1109/ISCAS.1998.698968
   Kong LY, 2016, CHIN CONTR CONF, P4932, DOI 10.1109/ChiCC.2016.7554120
   Li M, 2018, SIGNAL PROCESS-IMAGE, V62, P164, DOI 10.1016/j.image.2018.01.002
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Özkaynak F, 2014, NONLINEAR DYNAM, V78, P1311, DOI 10.1007/s11071-014-1517-8
   Parvaz R, 2018, OPT LASER TECHNOL, V101, P30, DOI 10.1016/j.optlastec.2017.10.024
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wilson AM, 2003, NATURE, V421, P35, DOI 10.1038/421035a
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Ye GD, 2018, NONLINEAR DYNAM, V94, P745, DOI 10.1007/s11071-018-4391-y
   Ye GD, 2016, NONLINEAR DYNAM, V83, P2067, DOI 10.1007/s11071-015-2465-7
   Zhan K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013021
   Zhang Q, 2014, AEU-INT J ELECTRON C, V68, P186, DOI 10.1016/j.aeue.2013.08.007
   Zhang Q, 2013, OPTIK, V124, P6276, DOI 10.1016/j.ijleo.2013.05.009
   Zhang XP, 2014, COMPUT ELECTR ENG, V40, P931, DOI 10.1016/j.compeleceng.2013.08.008
   Zhang YQ, 2016, OPT LASER ENG, V82, P95, DOI 10.1016/j.optlaseng.2016.02.002
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 26
TC 16
Z9 16
U1 2
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19291
EP 19305
DI 10.1007/s11042-021-10724-3
EA FEB 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000621742800001
DA 2024-07-18
ER

PT J
AU Liu, JD
   Ming, Z
   Bo, L
   Liu, YJ
   Bo, L
AF Jiandong Liu
   Ming Zhong
   Bo Liu
   Yujie Liu
   Bo Li
TI Design of three-dimensional dynamic integer tent map and its image
   encryption algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic image encryption; Dynamic integer tent map; Arnold map; Color
   image encryption
ID CHAOS
AB A three-dimensional dynamic integer tent map is proposed which is based on one-dimensional and two-dimensional integer tent maps, and the effects of dimension, accuracy and disturbance on the chaotic map system are studied. Experiments show that this system can quickly generate multiple integer pseudo-random sequences that are independent of each other and distributed uniformly, so that the problem of accuracy loss due to the integer real number model and the problem of insufficient independence and uniformity of a multi-dimensional model are solved. According to the characteristics of three-dimensional map systems, a color image encryption algorithm is designed and its performance is analyzed from different aspects.
C1 [Jiandong Liu; Ming Zhong; Bo Liu; Yujie Liu; Bo Li] Beijing Inst Petrochem Technol, Sch Informat Engn, Beijing 102617, Peoples R China.
C3 Beijing Institute of Petrochemical Technology
RP Liu, JD (corresponding author), Beijing Inst Petrochem Technol, Sch Informat Engn, Beijing 102617, Peoples R China.
EM liujiandong@bipt.edu.cn
RI Liu, Yujie/IWU-6535-2023; Yang, Tian/JFB-1008-2023; Wu,
   Lijuan/JJG-0701-2023; chen, yuying/JNS-9778-2023; zhou,
   xian/JYQ-9844-2024
OI Liu, Yujie/0000-0002-1153-6156; 
CR Chen Fei, 2019, Computer Engineering and Applications, V55, P103, DOI 10.3778/j.issn.1002-8331.1709-0253
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen JX, 2015, OPT LASER ENG, V67, P191, DOI 10.1016/j.optlaseng.2014.11.017
   Han, 2013, INT C COMP INF SCI
   Hermassi H, 2014, MULTIMED TOOLS APPL, V72, P2211, DOI 10.1007/s11042-013-1533-6
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Hussain I, 2012, NONLINEAR DYNAM, V70, P181, DOI 10.1007/s11071-012-0440-0
   Liu JD., 2007, INT S COMP SCI TECHN
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Na SH, 2002, CLIN NEUROPHYSIOL, V113, P1954, DOI 10.1016/S1388-2457(02)00197-9
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Rukhin A, 2010, APPL PHYS LETT, V22, P1645
   Wang W, 2016, WIRELESS COMMUNICATION AND SENSOR NETWORK, P711
   Wang W, 2018, COMPUT ELECTR ENG, V65, P282, DOI 10.1016/j.compeleceng.2017.07.026
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wang XY, 2016, OPT LASER ENG, V82, P79, DOI 10.1016/j.optlaseng.2015.12.006
   Xu HH, 2018, IEEE ACCESS, V6, P11634, DOI 10.1109/ACCESS.2017.2783320
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P584, DOI 10.1016/j.cnsns.2012.08.010
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
NR 20
TC 5
Z9 5
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19219
EP 19236
DI 10.1007/s11042-021-10668-8
EA FEB 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000621282300003
DA 2024-07-18
ER

PT J
AU Telem, ANK
   Fotsin, HB
   Kengne, J
AF Telem, Adelaide Nicole Kengnou
   Fotsin, Hilaire Bertrand
   Kengne, Jacques
TI Image encryption algorithm based on dynamic DNA coding operations and 3D
   chaotic systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DNA coding; 3D chaotic system; Zigzag process; Chaotic DNA permutation;
   FWT DNA algorithm
ID SEQUENCE OPERATION; CIRCUIT; CIPHER
AB This paper presents a new image encryption algorithm based on 3D chaotic system and deoxyribonucleic acid (DNA) coding. It uses two keys, an external one of 128 bits long and an internal one of 64 gray values coming from the plain image. The initial conditions come from the two keys and vary from one line of the image to the other and from one image to the other and consequently the sequences of substitutions too. In general, in image encryption based on 3D chaotic systems, each chaotic variable is used independently of the others in one phase of the encryption. Here we use the zigzag process to combine the sequences from all the variables before using them simultaneously in the encryption process. DNA coding generally uses one of the 24 DNA rules and one of the 16 join operations to perform the encryption. Here we use all the 24 rules dynamically as well as the 16 join operations in the encryption. Also we apply the chaotic permutation on DNA chain. The logical DNA operations are used according to an algorithm similar to that of the Fast Walsh Transform (FWT) in those 24 DNA rules. The algorithm has been evaluated. It has good statistical properties of cipher images. The proposed system presents high sensitivity on the encryption-decryption keys and on the plain images. These latter features make the proposed algorithm very efficient, robust and resistant against brute force attacks and good for the future secure image communication.
C1 [Telem, Adelaide Nicole Kengnou] Univ Buea, Dept Elect & Elect Engn, Coll Technol COT, POB 63, Buea, Cameroon.
   [Kengne, Jacques] Univ Dschang, Dept Genie Elect, IUT Fotso Victor Bandjoun, Lab Automat & Informat Appl LAIA, BP 134, Bandjoun, Cameroon.
   [Fotsin, Hilaire Bertrand; Kengne, Jacques] Univ Dschang, Fac Sci, Lab Rech Mat Condensee Elect & Traitement Signal, Dept Phys, Dschang, Cameroon.
C3 Universite de Dschang; Universite de Dschang
RP Telem, ANK (corresponding author), Univ Buea, Dept Elect & Elect Engn, Coll Technol COT, POB 63, Buea, Cameroon.
EM adelkengnou@Gmail.com; hbfotsin@yahoo.fr; kengnemozart@yahoo.fr
CR Abdelfattah Roayat Ismail, 2020, Journal of Physics: Conference Series, V1447, DOI 10.1088/1742-6596/1447/1/012053
   Al-Maadeed TA, 2020, ARXIV200611847
   Babaei M, 2013, NAT COMPUT, V12, P101, DOI 10.1007/s11047-012-9334-9
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Bin Faheem Z, 2020, ETRI J, V42, P619, DOI 10.4218/etrij.2019-0138
   Chai XL, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/2/020504
   Chai XL, 2016, CHINESE PHYS B, V25, DOI 10.1088/1674-1056/25/10/100503
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P9907, DOI 10.1007/s11042-016-3585-x
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Dieu J., 2014, COMPUT SCI APPL, V1, P232
   Fouda JSAE, 2014, COMMUN NONLINEAR SCI, V19, P578, DOI 10.1016/j.cnsns.2013.07.016
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Guesmi R, 2015, 2015 IEEE 12TH INTERNATIONAL MULTI-CONFERENCE ON SYSTEMS, SIGNALS & DEVICES (SSD)
   Hamza R, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/1625678
   Hamza R, 2020, INFORM SCIENCES, V527, P493, DOI 10.1016/j.ins.2019.01.070
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Hussain I, 2013, MATH COMPUT MODEL, V57, P2576, DOI 10.1016/j.mcm.2013.01.009
   Khade PN, 2012, IJCSI, V9, P1
   Lian S., 2008, Multimedia Content Encryption: Techniques And Applications
   Lima JB, 2015, SIGNAL PROCESS-IMAGE, V35, P1, DOI 10.1016/j.image.2015.03.005
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu L, 2017, OPT COMMUN, V398, P62, DOI 10.1016/j.optcom.2017.04.015
   Liu LF, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-1959-1
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P7739, DOI 10.1007/s11042-015-2691-5
   Niu Y, 2020, MULTIMED TOOLS APPL, V79, P25613, DOI 10.1007/s11042-020-09237-2
   Pan HL, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0386-3
   Pareek NK, 2013, DIGIT SIGNAL PROCESS, V23, P894, DOI 10.1016/j.dsp.2013.01.005
   Patidar V, 2010, COMMUN NONLINEAR SCI, V15, P2755, DOI 10.1016/j.cnsns.2009.11.010
   Pisarchik AN, 2008, PHYSICA D, V237, P2638, DOI 10.1016/j.physd.2008.03.049
   Shafique A, 2018, EUR PHYS J PLUS, V133, DOI 10.1140/epjp/i2018-12138-3
   Shi Y, 2010, CELL STEM CELL, V6, P1, DOI 10.1016/j.stem.2009.12.012
   Telem ANK, 2014, ADV MULTIMED, V2014, DOI 10.1155/2014/602921
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Vaidyanathan S, 2018, EUR PHYS J PLUS, V133, DOI 10.1140/epjp/i2018-11872-8
   Volos C, 2017, NONLINEAR DYNAM, V89, P1047, DOI 10.1007/s11071-017-3499-9
   Wan YJ, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22020171
   Wang Kefeng, 2015, Applied Mechanics and Materials, V734, P554, DOI 10.4028/www.scientific.net/AMM.734.554
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang Y, 2009, CHAOS SOLITON FRACT, V41, P1773, DOI 10.1016/j.chaos.2008.07.031
   Yu-Zhen LI, 2016, COMPUTER ENG DESIGN, V37, P2001
   Zhang J, 2016, Mathematical problems in engineering, V2016
   Zhang J., 2014, MATH PROBL ENG, V2014, P10, DOI DOI 10.1016/J.IJEPES.2014.09.041
   Zhang Q, 2013, OPTIK, V124, P6276, DOI 10.1016/j.ijleo.2013.05.009
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang Q, 2013, J COMPUT THEOR NANOS, V10, P341, DOI 10.1166/jctn.2013.2702
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   ZHANG XC, 2017, COMPUT INTEL NEUROSC, V2017
   Zhang YQ, 2016, OPT LASER ENG, V82, P95, DOI 10.1016/j.optlaseng.2016.02.002
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P21589, DOI 10.1007/s11042-017-5585-x
   Zhang YS, 2014, INFORM SCIENCES, V289, P254, DOI 10.1016/j.ins.2014.08.005
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
NR 58
TC 33
Z9 33
U1 2
U2 65
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 19011
EP 19041
DI 10.1007/s11042-021-10549-0
EA FEB 2021
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000621015900002
DA 2024-07-18
ER

PT J
AU Xue, H
AF Xue, Han
TI Low light image enhancement based on modified Retinex optimized by
   fractional order gradient descent with momentum RBF neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low-light enhancement; Neural network; Image reconstruction
ID EQUALIZATION
AB To dynamically adjust the edge preservation and smoothness of low-light images, this paper proposed a fractional order gradient descent with momentum radial basis function neural network (FOGDMRBF) to optimizing Retinex.Its convergence is proved. In order to speed up the convergence process, an adaptive learning rate is used to adjust the training process reasonably. The results verify the theoretical results of the proposed algorithm such as its monotonicity and convergence. The descending curve of error values by FOGDM is more smoother than gradient descent and gradient descent with momentum method. The influence of regularization parameter is analyzed and compared. Compared with Dark Channel Prior, Histogram Equalization, Homomorphic Filtering and Multiple Exposure Fusion, the halo and noise generated are significantly reduced with higher Peak Signal-to-Noise Ratio and Structural Similarity Index.
C1 [Xue, Han] Jimei Univ, Sch Nav, Xiamen 361021, Fujian, Peoples R China.
   [Xue, Han] Jimei Univ, Natl Local Joint Engn Res Ctr Marine Nav Aids Ser, Xiamen 361021, Fujian, Peoples R China.
   [Xue, Han] Fujian Shipping Res Inst, Xiamen 361021, Fujian, Peoples R China.
   [Xue, Han] Xiamen Southeast Int Shipping Res Ctr, Xiamen 361021, Fujian, Peoples R China.
C3 Jimei University; Jimei University
RP Xue, H (corresponding author), Jimei Univ, Sch Nav, Xiamen 361021, Fujian, Peoples R China.; Xue, H (corresponding author), Jimei Univ, Natl Local Joint Engn Res Ctr Marine Nav Aids Ser, Xiamen 361021, Fujian, Peoples R China.; Xue, H (corresponding author), Fujian Shipping Res Inst, Xiamen 361021, Fujian, Peoples R China.; Xue, H (corresponding author), Xiamen Southeast Int Shipping Res Ctr, Xiamen 361021, Fujian, Peoples R China.
EM imlmd@163.com
OI XUE, Han/0000-0002-6418-9581
FU National Natural Science Foundation of China [51879119]; Natural Science
   Foundation of Fujian Province [2018 J05085]; high level research and
   cultivation fund of transportation engineering discipline in Jimei
   University [HHXY2020003]; National Natural Science Foundation
   Cultivation Project of Jimei University [ZP2020005]
FX The work is supported by the National Natural Science Foundation of
   China (51879119), Natural Science Foundation of Fujian Province (2018
   J05085), the high level research and cultivation fund of transportation
   engineering discipline in Jimei University (HHXY2020003), National
   Natural Science Foundation Cultivation Project of Jimei
   University(ZP2020005).
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   Cai BL, 2017, IEEE I CONF COMP VIS, P4020, DOI 10.1109/ICCV.2017.431
   Feng XM, 2020, MULTIMED TOOLS APPL, V79, P32973, DOI 10.1007/s11042-020-09562-6
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Galdran A, 2018, SIGNAL PROCESS, V149, P135, DOI 10.1016/j.sigpro.2018.03.008
   Guo X, 2016, IEEE BIPOL BICMOS, P86, DOI 10.1109/BCTM.2016.7738941
   Iqbal M, 2020, OPTIK, V209, DOI 10.1016/j.ijleo.2020.164260
   Kinh CT, 2018, NEURAL PROCESS LETT, V47, P139, DOI 10.1007/s11063-017-9637-z
   Kobayashi M, 2017, NEUROCOMPUTING, V260, P174, DOI 10.1016/j.neucom.2017.04.025
   Singh H, 2019, MULTIMED TOOLS APPL, V78, P20431, DOI 10.1007/s11042-019-7383-0
   SUTHERLAND F, 1975, INTRO METRIC TOPOLOG, P23
   Utomo, 2017, J INTERNET BANK COMM, V22, P1
   Wang LN, 2017, NEURAL NETWORKS, V93, P219, DOI 10.1016/j.neunet.2017.06.003
   Wu W, 2008, J COMPUT MATH, V26, P613
   Xie JY, 2020, PATTERN RECOGN LETT, V138, P308, DOI 10.1016/j.patrec.2020.07.041
   Xu YD, 2021, INFORM SCIENCES, V548, P378, DOI 10.1016/j.ins.2020.09.066
   Yin PH, 2019, ARXIV180805240
NR 17
TC 10
Z9 10
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 19057
EP 19077
DI 10.1007/s11042-021-10611-x
EA FEB 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000621015900003
DA 2024-07-18
ER

PT J
AU Babu, NR
   Kalpana, M
   Balasubramaniam, P
AF Babu, N. Ramesh
   Kalpana, M.
   Balasubramaniam, P.
TI A novel audio encryption approach via finite-time synchronization of
   fractional order hyperchaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fractional order; Hyperchaotic system; Sender system; Receiver system;
   Finite-time control; Synchronization; Audio encryption
ID CHAOTIC SYSTEMS; UNKNOWN-PARAMETERS; NEURAL-NETWORKS; STABILIZATION;
   CIRCUITS; NUMBER
AB Synchronization of 4-D nonlinear fractional order hyperchaotic system with external disturbance is important models for encryption and decryption technique. In this paper, the fractional order 0 < alpha <= 1 is consider to establish finite-time control for synchronization of sender and receiver system. An audio encryption and decryption algorithms are investigated based on converting an audio data samples into image data. A random mask generated from chaotic mask is used to encrypt and decrypt the audio signals. The path of error system of fractional order hyperchaotic system is shown to be highly better than the classical one. Further, high level security of the proposed work is entrusted or assured by analyzing various metrics including MSE, PSNR, SSIM, NPCR and SNR along with numerical simulations.
C1 [Babu, N. Ramesh; Balasubramaniam, P.] Gandhigram Rural Inst Deemed Be Univ, Dept Math, Dindigul 624302, Tamil Nadu, India.
   [Kalpana, M.] Univ Malaya, Inst Math Sci, Fac Sci, Kuala Lumpur 50603, Malaysia.
C3 Gandhigram Rural Institute; Universiti Malaya
RP Balasubramaniam, P (corresponding author), Gandhigram Rural Inst Deemed Be Univ, Dept Math, Dindigul 624302, Tamil Nadu, India.
EM balugru@gmail.com
RI P, Balasubramaniam/O-3041-2013; Babu, Dr. N. Ramesh/ABG-1382-2021;
   padmavathy engg college, prince shri venkateshwara/GOH-3256-2022;
   Kalpana, M./G-6639-2016
OI Babu, Dr. N. Ramesh/0000-0002-1887-9514; Kalpana, M./0000-0003-0605-6657
FU University Grants Commission-Special Assistance Programme (Department of
   Special Assistance-I), New Delhi, India [F. 510/7/DSA-1/2015 (SAP-I)];
   NFSC, UGC, New Delhi [82-1/2018 (SA-III)]; UGC [4071]
FX This work is partially supported by University Grants Commission-Special
   Assistance Programme (Department of Special Assistance-I), New Delhi,
   India, File No. F. 510/7/DSA-1/2015 (SAP-I) and partially supported by
   NFSC, UGC, New Delhi, File No. 82-1/2018 (SA-III), UGC-Ref. No.:
   4071/(CSIR-UGC NET JUNE 2018).
CR Abdurahman A, 2016, FUZZY SET SYST, V297, P96, DOI 10.1016/j.fss.2015.07.009
   Aghababa MP, 2011, APPL MATH MODEL, V35, P3080, DOI 10.1016/j.apm.2010.12.020
   Al-kateeb ZN, 2020, MULTIMED TOOLS APPL, V79, P19615, DOI 10.1007/s11042-020-08869-8
   Cafagna D, 2003, INT J BIFURCAT CHAOS, V13, P2889, DOI 10.1142/S0218127403008284
   Chen AM, 2006, PHYSICA A, V364, P103, DOI 10.1016/j.physa.2005.09.039
   Chen GR, 1999, INT J BIFURCAT CHAOS, V9, P1465, DOI 10.1142/S0218127499001024
   Chen HH, 2009, CHAOS SOLITON FRACT, V40, P466, DOI 10.1016/j.chaos.2007.07.098
   Cheng J, 2018, IEEE T CYBERNETICS, V48, P2232, DOI 10.1109/TCYB.2017.2729581
   CUOMO KM, 1993, IEEE T CIRCUITS-II, V40, P626, DOI 10.1109/82.246163
   Dadras S, 2012, NONLINEAR DYNAM, V67, P1161, DOI 10.1007/s11071-011-0060-0
   Feng MK, 2015, J VIB CONTROL, V21, P2259, DOI 10.1177/1077546313508970
   Gao TG, 2006, INT J MOD PHYS C, V17, P471, DOI 10.1142/S0129183106008625
   Jawahir A., 2015, INT J ADV INTELL INF, V1, P98, DOI [10.26555/ijain.v1i2.24, DOI 10.26555/IJAIN.V1I2.24]
   Jia QA, 2007, PHYS LETT A, V366, P217, DOI 10.1016/j.physleta.2007.02.024
   Kalpana M, 2019, MULTIMED TOOLS APPL, V78, P5969, DOI 10.1007/s11042-018-6373-y
   Kalpana M, 2018, NONLINEAR DYNAM, V93, P543, DOI 10.1007/s11071-018-4208-z
   Kwon OM, 2011, NONLINEAR DYNAM, V63, P239, DOI 10.1007/s11071-010-9800-9
   Lassoued A, 2016, NONLINEAR ANAL-MODEL, V21, P770, DOI 10.15388/NA.2016.6.3
   Li XY, 2011, NONLINEAR DYNAM, V65, P255, DOI 10.1007/s11071-010-9887-z
   Li XD, 2020, MULTIMED TOOLS APPL, V79, P23995, DOI 10.1007/s11042-020-09200-1
   Lima JB, 2016, MULTIMED TOOLS APPL, V75, P8403, DOI 10.1007/s11042-015-2755-6
   Lin TC, 2015, INT J FUZZY SYST, V17, P206, DOI 10.1007/s40815-015-0024-5
   Liu HJ, 2016, OPTIK, V127, P7431, DOI 10.1016/j.ijleo.2016.05.073
   MATSUMOTO T, 1984, IEEE T CIRCUITS SYST, V31, P1055, DOI 10.1109/TCS.1984.1085459
   Muthukumar P, 2018, ISA T, V82, P51, DOI 10.1016/j.isatra.2017.07.007
   Nadir Jihad, 2016, International Journal of Computer and Information Technology, V5, P465
   Naskar PK, 2019, MULTIMED TOOLS APPL, V78, P25019, DOI 10.1007/s11042-019-7696-z
   Niu YJ, 2010, COMMUN NONLINEAR SCI, V15, P3518, DOI 10.1016/j.cnsns.2009.12.005
   Pang SQ, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/7693547
   Pang SQ, 2011, J COMPUT APPL MATH, V235, P2775, DOI 10.1016/j.cam.2010.11.029
   Podlubny I, 1998, FRACTIONAL DIFFERENT
   Prabu AV., 2012, INT J COMPUTER APPL, V40, P40
   Shen H, 2017, IEEE T NEUR NET LEAR, V28, P346, DOI 10.1109/TNNLS.2015.2511196
   Srivastava M, 2014, NONLINEAR DYNAM, V76, P905, DOI 10.1007/s11071-013-1177-0
   Sun JW, 2016, NONLINEAR DYNAM, V85, P1105, DOI 10.1007/s11071-016-2747-8
   Wan Z, 2014, OPTIK, V125, P1371, DOI 10.1016/j.ijleo.2013.08.025
   Wang FQ, 2006, CHINESE PHYS, V15, P963, DOI 10.1088/1009-1963/15/5/016
   Wang LM, 2019, APPL MATH COMPUT, V347, P293, DOI 10.1016/j.amc.2018.11.017
   Wang LM, 2018, INFORM SCIENCES, V466, P270, DOI 10.1016/j.ins.2018.07.039
   Wang LM, 2017, IEEE T NEUR NET LEAR, V28, P2648, DOI 10.1109/TNNLS.2016.2598598
   Wang LM, 2015, IEEE T NEUR NET LEAR, V26, P2033, DOI 10.1109/TNNLS.2014.2361776
   Wang XY, 2009, MOD PHYS LETT B, V23, P963, DOI 10.1142/S021798490901920X
   Wang ZP, 2013, CHINESE PHYS B, V22, DOI 10.1088/1674-1056/22/8/088801
   Wen SP, 2013, PHYS LETT A, V377, P2016, DOI 10.1016/j.physleta.2013.05.046
   Wen SP, 2012, PHYS LETT A, V376, P2775, DOI 10.1016/j.physleta.2012.08.021
   Yang NN, 2013, NONLINEAR DYNAM, V74, P721, DOI 10.1007/s11071-013-1000-y
   Yin C, 2012, COMMUN NONLINEAR SCI, V17, P356, DOI 10.1016/j.cnsns.2011.04.024
   Zhang G, 2007, CHAOS SOLITON FRACT, V32, P773, DOI 10.1016/j.chaos.2005.11.099
   Zou LM, 2017, COMPLEXITY, DOI 10.1155/2017/5186714
NR 49
TC 24
Z9 25
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18043
EP 18067
DI 10.1007/s11042-020-10288-8
EA FEB 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000617861200001
DA 2024-07-18
ER

PT J
AU Saâdi, IB
   Souabni, R
   Ben Ghezala, H
AF Saadi, Ines Bayoudh
   Souabni, Raoudha
   Ben Ghezala, Henda
TI Ubiquitous learning situations : quality-aware description and modelling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ubiquitous learning; Situation description; Quality of situation;
   Ontological model
ID MOBILE TECHNOLOGY; HIGHER-EDUCATION; CONTEXT; SYSTEMS
AB In ubiquitous environments, the heterogeneous and dynamic nature of context sensors besides their characteristics have a great importance on undermining the quality of the detected context and the whole situation described by that context. A recent interest had been made to manage the quality of low-level context in the ubiquitous learning (u-learning) field; however, the quality of the u-learning situation has never been a main concern. Hence, a quality-aware description and a quality-aware ontological model of the u-learning situation are proposed. Experimentation results are given to show the implication of the quality of situation in the enhancement of situation identification. Quality-based situation identification provided 52% of high-quality identified situations compared to only 38% for the standard identification showing an enhancement of 14% in high-quality situation identification.
C1 [Saadi, Ines Bayoudh; Souabni, Raoudha; Ben Ghezala, Henda] Manouba Univ, RIADI Res Lab, ENSI, Manouba, Tunisia.
C3 Universite de la Manouba
RP Saâdi, IB (corresponding author), Manouba Univ, RIADI Res Lab, ENSI, Manouba, Tunisia.
EM Ines.Bayoudh@ensi.rnu.tn; raoudha.souabni@riadi.rnu.tn;
   henda.benghezala@ensi.rnu.tn
RI Ben Ghezala, Henda Hajjami/AAK-7052-2021; Saadi, Ines
   Bayoudh/M-2391-2015
OI Ben Ghezala, Henda Hajjami/0000-0002-6874-1388; Saadi, Ines
   Bayoudh/0000-0001-7419-3800
CR [Anonymous], 2016, IEEE INT C ADV INF N
   Aousji, 2016, THESIS U TUNIS TUNIS
   Beetham H., 2013, Rethinking pedagogy for a digital age: Designing for 21st century learning
   Ben Salah N, 2016, 2016 INT IEEE CONFERENCES ON UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING AND COMMUNICATIONS, CLOUD AND BIG DATA COMPUTING, INTERNET OF PEOPLE, AND SMART WORLD CONGRESS (UIC/ATC/SCALCOM/CBDCOM/IOP/SMARTWORLD), P171, DOI [10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.67, 10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0046]
   Bettini C, 2010, PERVASIVE MOB COMPUT, V6, P161, DOI 10.1016/j.pmcj.2009.06.002
   Bouzeghoub A., 2010, 2010 Fifth International Conference on Digital Information Management (ICDIM 2010), P222, DOI 10.1109/ICDIM.2010.5664620
   Bringel J, 2010, INT CON ADV INFO NET, P690, DOI 10.1109/AINA.2010.164
   Camilleri MA, 2017, TECHNOL KNOWL LEARN, V22, P65, DOI 10.1007/s10758-016-9287-7
   Chaouche AC, 2016, J AMB INTEL HUM COMP, V7, P555, DOI 10.1007/s12652-016-0342-y
   Christensen R., 2002, Journal of Research on Technology in Education, V34, P411
   Cowan D, 2012, HDB RES MOBILE SOFTW, P693
   Crompton H, 2017, COMPUT EDUC, V110, P51, DOI 10.1016/j.compedu.2017.03.013
   Czaja SJ, 2006, PSYCHOL AGING, V21, P333, DOI 10.1037/0882-7974.21.2.333
   D'Aniello G, 2014, IEEE INT CONF ADV LE, P136, DOI 10.1109/ICALT.2014.47
   D'Aniello G, 2015, 2015 INTERNATIONAL CONFERENCE ON INTELLIGENT NETWORKING AND COLLABORATIVE SYSTEMS IEEE INCOS 2015, P440, DOI 10.1109/INCoS.2015.59
   D'Aniello G, 2015, 2015 IEEE INTERNATIONAL MULTI-DISCIPLINARY CONFERENCE ON COGNITIVE METHODS IN SITUATION AWARENESS AND DECISION SUPPORT (COGSIMA), P101, DOI 10.1109/COGSIMA.2015.7108182
   DEMPSTER AP, 1967, ANN MATH STAT, V38, P325, DOI 10.1214/aoms/1177698950
   Dolin RH, 2006, J AM MED INFORM ASSN, V13, P30, DOI 10.1197/jamia.M1888
   ENDSLEY MR, 1995, HUM FACTORS, V37, P32, DOI 10.1518/001872095779049543
   Gangemi A, 2006, LECT NOTES COMPUT SC, V4011, P140
   Domingo MG, 2016, COMPUT HUM BEHAV, V56, P21, DOI 10.1016/j.chb.2015.11.023
   Halverson A., 2009, Rethinking education in the age of technology
   Harchay A, 2015, J UNIVERS COMPUT SCI, V21, P1061
   Harkema SJM, 2008, EUR J EDUC, V43, DOI 10.1111/j.1465-3435.2008.00372.x
   Heflin H, 2017, COMPUT EDUC, V107, P91, DOI 10.1016/j.compedu.2017.01.006
   Hooft M., 2007, Ubiquitous computing in education
   Hwang GJ, 2008, EDUC TECHNOL SOC, V11, P81
   Jahnke JH, 2004, P KI 04 WORKSH MOD R
   Kim Y, 2006, 2006 INTERNATIONAL CONFERENCE ON HYBRID INFORMATION TECHNOLOGY, VOL 2, PROCEEDINGS, P576
   Ko EJ, 2007, IEICE T INF SYST, VE90D, P1262, DOI 10.1093/ietisy/e90-d.8.1262
   Krause M, 2005, LECT NOTES COMPUT SC, V3744, P324
   Liu TC, 2009, EDUC TECHNOL SOC, V12, P344
   Lozano-Tello A, 2004, J DATABASE MANAGE, V15, P1, DOI 10.4018/jdm.2004040101
   Manzoor A, 2008, LECT NOTES COMPUT SC, V5279, P140
   Manzoor A, 2014, KNOWL ENG REV, V29, P154, DOI 10.1017/S0269888914000034
   Manzoor A, 2009, LECT NOTES COMPUT SC, V5786, P144, DOI 10.1007/978-3-642-04559-2_13
   Matheus CJ, 2003, FUSION 2003: PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE OF INFORMATION FUSION, VOLS 1 AND 2, P545
   Mavengere N, 2018, EDUC INF TECHNOL, V23, P1607, DOI 10.1007/s10639-017-9681-3
   Nunes FB, 2016, ADV GAME BASE LEARN, P410, DOI 10.4018/978-1-5225-0125-1.ch017
   Nunez F., 2013, Patologia de la voz, P55
   Ogata H, 2005, INT FED INFO PROC, V171, P121
   Ogata H, 2004, 2ND IEEE INTERNATIONAL WORKSHOP ON WIRELESS AND MOBILE TECHNOLOGIES IN EDUCATION, P19, DOI 10.1109/WMTE.2004.1281328
   Perera C, 2014, IEEE COMMUN SURV TUT, V16, P414, DOI 10.1109/SURV.2013.042313.00197
   Pernas AM, 2014, INT CON ADV INFO NET, P1119, DOI 10.1109/AINA.2014.136
   Pimmer C, 2016, COMPUT HUM BEHAV, V63, P490, DOI 10.1016/j.chb.2016.05.057
   Shafer G., 1976, A Mathematical Theory of Evidence, V1, DOI 10.1515/9780691214696
   Souabni R, 2019, TELEMAT INFORM, V43, DOI 10.1016/j.tele.2019.101246
   Souabni R, 2018, INT J INF TECH DECIS, V17, P247, DOI 10.1142/S0219622017500407
   Souabni R, 2016, IEEE INT FUZZY SYST, P1805, DOI 10.1109/FUZZ-IEEE.2016.7737909
   Souabni R, 2013, CREATING GLOBAL COMPETITIVE ECONOMIES: 2020 VISION PLANNING & IMPLEMENTATION, VOLS 1-3, P1557
   Tartir S., 2005, IEEE WORKSH KNOWL AC, V9
   Verbert K, 2012, IEEE T LEARN TECHNOL, V5, P318, DOI 10.1109/TLT.2012.11
   Virtanen MA, 2018, EDUC INF TECHNOL, V23, P985, DOI 10.1007/s10639-017-9646-6
   Wang TD, 2007, LECT NOTES COMPUT SC, V4825, P595
   Wei<ss> S, 2010, LOOKING FUTURE TECHN
   Weiser M., 1995, READINGS HUMAN COMPU, DOI DOI 10.1016/B978-0-08-051574-8.50097-2
   Wishart J., 2018, MOBILE UBIQUITOUS LE, P81, DOI [10.1007/978-981-10-6144-8_5, DOI 10.1007/978-981-10-6144-8_5]
   Ye J, 2012, PERVASIVE MOB COMPUT, V8, P36, DOI 10.1016/j.pmcj.2011.01.004
NR 58
TC 0
Z9 0
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 17583
EP 17609
DI 10.1007/s11042-021-10546-3
EA FEB 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000616467500003
DA 2024-07-18
ER

PT J
AU Psaltoglou, A
   Vakali, A
AF Psaltoglou, Artemis
   Vakali, Athena
TI An exploratory approach for urban data visualization and spatial
   analysis with a game engine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data visualization; Urban planning; Spatial data; Spatial analysis; Game
   engine; Urban governance
ID PUBLIC-PARTICIPATION; SMART CITIES; SPACE; CHALLENGES; USABILITY;
   TWITTER; DESIGN
AB The extensive use of Information and Communication Technologies and the consequent unprecedented generation of data have radically transformed the way we understand cities today. The vision of smart cities considers technology as an enabling force for the emergence of new forms of intelligence and collaboration, enhancing, thus, the problem-solving capacity of the city. Despite the wide range of applications aiming to improve urban systems and city governance, urban planning processes are rarely informed by online platforms and data generated by them lack comprehensive data visualization approaches. This research introduces an exploratory approach to exploit urban data through interactive visualization and game design, as a way to facilitate the access and understanding of such data. A novel methodology is proposed, leveraging on spatial data as an input source which drives the generation of three-dimensional environments and interactive applications supported by game engines. More specifically, this research builds upon existing tools and methods for geoprocessing and spatial analysis and embeds them in a 3D environment that employs game design elements. Three indicative visualization scenarios are designed, developed, and implemented to showcase the dynamics and flexibility of the proposed methodology, based on the registry of an urban reporting application in Thessaloniki.
C1 [Psaltoglou, Artemis; Vakali, Athena] Aristotle Univ Thessaloniki, Thessaloniki, Greece.
C3 Aristotle University of Thessaloniki
RP Psaltoglou, A (corresponding author), Aristotle Univ Thessaloniki, Thessaloniki, Greece.
EM artemisps@urenio.org
OI Psaltoglou, Artemis/0000-0002-6397-6663
FU General Secretariat for Research and Technology (GSRT); Hellenic
   Foundation for Research and Innovation (HFRI) [2564]
FX This research has been financially supported by General Secretariat for
   Research and Technology (GSRT) and the Hellenic Foundation for Research
   and Innovation (HFRI) (Scholarship Code: 2564).
CR Almirall E, 2016, CALIF MANAGE REV, V59, P141, DOI 10.1177/0008125616683949
   Angelidou Margarita, 2019, International Journal of Electronic Governance, V11, P5
   Angelidou M, 2018, J SCI TECHNOL POLICY, V9, P146, DOI 10.1108/JSTPM-05-2017-0016
   Angelini C., 2020, ARXIV200106578
   [Anonymous], 2014, VISUALIZING DATA CIT
   [Anonymous], 2019, J URBAN TECHNOL, DOI DOI 10.1080/10630732.2018.1485368
   Bartosh Amber, 2019, Technology Architecture + Design, V3, P89, DOI 10.1080/24751448.2019.1571832
   Batty Michael, 2013, Dialogues Hum Geogr, V3, P274, DOI 10.1177/2043820613513390
   Brabham DC, 2009, PLAN THEOR, V8, P242, DOI 10.1177/1473095209104824
   Bugs G, 2010, CITIES, V27, P172, DOI 10.1016/j.cities.2009.11.008
   Carbonell-Carrera C, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9030159
   Chaves-Diéguez D, 2015, SENSORS-BASEL, V15, P16083, DOI 10.3390/s150716083
   Clemenson GD, 2015, J NEUROSCI, V35, P16116, DOI 10.1523/JNEUROSCI.2580-15.2015
   Cranshaw J, 2012, P ICWSM DUBL IR
   Cristie V, 2015, SIGGRAPH ASIA VIS HI, P3
   Cristie V, 2017, GAMING MEDIA SOC EFF, P87, DOI 10.1007/978-981-10-1962-3_5
   Davis Jr C A, 2018, SIGSPATIAL 18
   Dey A, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00037
   Ertiö TP, 2015, PLAN PRACT RES, V30, P303, DOI 10.1080/02697459.2015.1052942
   Evans-Cowley J, 2010, PLAN PRACT RES, V25, P397, DOI 10.1080/02697459.2010.503432
   Falco E, 2018, INT J E-PLAN RES, V7, P52, DOI 10.4018/IJEPR.2018070105
   Gottwald S, 2016, INT J GEOGR INF SCI, V30, P2321, DOI 10.1080/13658816.2016.1170837
   Hasler S. C. J., 2017, Civil Engineering and Architecture, V5, P230
   Hemmersam P, 2015, J URBAN TECHNOL, V22, P45, DOI 10.1080/10630732.2015.1073898
   Hollands R., 2009, City, V12, P303, DOI 10.1080/13604810802479126
   Jirotka M, 2017, COMMUN ACM, V60, P62, DOI 10.1145/3064940
   Kitchin R, 2014, GEOJOURNAL, V79, P1, DOI 10.1007/s10708-013-9516-8
   Kloeckl K, 2012, J URBAN TECHNOL, V19, P89, DOI 10.1080/10630732.2012.698068
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Lupi G, 2012, HUM CIT S 2012 RECL, P91
   McGarrigle C, 2018, SPR SER CULT COMPUT, P115, DOI 10.1007/978-3-319-69932-5_5
   Moustaka V, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P1167, DOI 10.1145/3041021.3054714
   Moustaka V, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3239566
   Mueller J, 2018, CITIES, V72, P181, DOI 10.1016/j.cities.2017.08.018
   Münster S, 2017, PROCEDIA COMPUT SCI, V112, P2391, DOI 10.1016/j.procs.2017.08.102
   Pak B, 2017, J URBAN TECHNOL, V24, P65, DOI 10.1080/10630732.2016.1270047
   Perhac J, 2017, IEEE INT CON INF VIS, P312, DOI 10.1109/iV.2017.33
   Psyllidis A, 2015, COMM COM INF SC, V527, P21, DOI 10.1007/978-3-662-47386-3_2
   Resch B, 2016, URBAN PLAN, V1, P114, DOI 10.17645/up.v1i2.617
   Resch B, 2015, LECT NOTES GEOINF CA, P199, DOI 10.1007/978-3-319-11879-6_14
   Roberts H, 2018, URBAN PLAN, V3, P21, DOI 10.17645/up.v3i1.1231
   Rowe G, 2004, SCI TECHNOL HUM VAL, V29, P512, DOI 10.1177/0162243903259197
   Schaffers Hans, 2012, J. theor. appl. electron. commer. res., V7, pii
   Schmidt CM., 2011, PARSONS J INF MAPP, V3, P1
   Sharp H., 2019, INTERACTION DESIGN H, VFifth
   Snyder H, 2019, J BUS RES, V104, P333, DOI 10.1016/j.jbusres.2019.07.039
   Stratigea A, 2015, J URBAN TECHNOL, V22, P43, DOI 10.1080/10630732.2015.1018725
   Talukdar P.P., 2010, GRAPH BASED WEAKLY S
   Thakuriah P., 2017, Big Data and Urban Informatics: Innovations and Challenges to Urban Planning and Knowledge Discovery, P11, DOI [DOI 10.1007/978-3-319-40902-3_2, 10.1007/978-3-319-40902-3, DOI 10.1007/978-3-319-40902-3]
   Trencher G, 2019, TECHNOL FORECAST SOC, V142, P117, DOI 10.1016/j.techfore.2018.07.033
   Vande Moere A, 2012, J URBAN TECHNOL, V19, P25, DOI 10.1080/10630732.2012.698065
   Westvang E, 2012, BENGLER SEEPLAN
NR 52
TC 4
Z9 5
U1 6
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15849
EP 15873
DI 10.1007/s11042-021-10585-w
EA FEB 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000615564900010
DA 2024-07-18
ER

PT J
AU Gurbuz, E
   Ulutas, G
   Ulutas, M
AF Gurbuz, Emre
   Ulutas, Guzin
   Ulutas, Mustafa
TI Source-destination discrimination on copy-move forgeries
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Source-destination discrimination; Copy-move forgery; Support vector
   machine; Digital image forensics
AB Since digital images are one of the most important carriers of information, their authenticity is quite important. There are miscellaneous forgery techniques for manipulating digital images, and one of those is copy-move forgery. Many forgery detection techniques have been developed for detection of copy-move forgery so far. However, the main lack of these techniques is that although they can successfully detect the copied and pasted regions on a copy-move forgery image, they are not able to determine which of the detected regions is the source region and which of them is the destination region. In this study, a novel and standalone technique has been proposed for source-destination discrimination on copy-move forgery images. The proposed technique is based on machine learning and uses Support Vector Machine. Our technique can be regarded as an appendage for the classical copy-move forgery detection algorithms, which cannot make source-destination discrimination. To the best of our knowledge, the proposed technique is the first standalone technique which makes source-destination discrimination on copy-move forgeries, in the literature, and it is the only successful source-destination discrimination technique in the literature.
C1 [Gurbuz, Emre] Tokat Gaziosmanpasa Univ, Tokat Vocat Sch, Tokat, Turkey.
   [Ulutas, Guzin; Ulutas, Mustafa] Karadeniz Tech Univ, Dept Comp Engn, Trabzon, Turkey.
C3 Gaziosmanpasa University; Karadeniz Technical University
RP Gurbuz, E (corresponding author), Tokat Gaziosmanpasa Univ, Tokat Vocat Sch, Tokat, Turkey.
EM emregurbuz@msn.com; guzin@ieee.org; ulutas@ieee.org
RI Ulutas, Guzin/ABI-4484-2020
CR [Anonymous], 2017, 2017 INT C COMP COMM, DOI DOI 10.1109/ICCUBEA.2017.8463695
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Bishop C, 2007, RECOGNITION PATTERN
   Dixit R, 2019, MULTIMED TOOLS APPL, V78, P13819, DOI 10.1007/s11042-018-6666-1
   Emam M, 2016, IEICE T INF SYST, VE99D, P2413, DOI 10.1587/transinf.2016EDL8024
   Huang HY, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0469-9
   Ikhlayel M, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING, NETWORK AND INTELLIGENT MULTIMEDIA (CENIM), P260, DOI 10.1109/CENIM.2018.8711029
   Islam MN, 2018, INT SYMPOS VLSI DES
   Khuspe Kalyani, 2015, 2015 International Conference on Communication, Information & Computing Technology (ICCICT), P1, DOI 10.1109/ICCICT.2015.7045718
   LI Y, 2018, IEEE T INF FOREN SEC, V14, P1307, DOI DOI 10.1109/TIFS.2018.2876837
   Ouyang JL, 2019, MULTIMED TOOLS APPL, V78, P10207, DOI 10.1007/s11042-018-6605-1
   Parashar A, 2019, MULTIMED TOOLS APPL, V78, P29413, DOI 10.1007/s11042-018-6707-9
   Pavlovic A, 2019, MULTIMED TOOLS APPL, V78, P20655, DOI 10.1007/s11042-019-7277-1
   Prakash CS, 2019, MULTIMED TOOLS APPL, V78, P23535, DOI 10.1007/s11042-019-7629-x
   Prakash CS, 2018, MULTIMED TOOLS APPL, V77, P26939, DOI 10.1007/s11042-018-5899-3
   Ramirez-Gutierrez K, 2019, I W BIOMETRIC FORENS, DOI 10.1109/iwbf.2019.8739168
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P2311, DOI 10.1007/s11042-018-6354-1
   Wu Y, 2018, LECT NOTES COMPUT SC, V11210, P170, DOI 10.1007/978-3-030-01231-1_11
NR 18
TC 0
Z9 0
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12831
EP 12842
DI 10.1007/s11042-020-10436-0
EA JAN 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000607369100001
DA 2024-07-18
ER

PT J
AU Wang, YX
   Zhu, L
   Qian, XM
AF Wang, Yaxiong
   Zhu, Li
   Qian, Xueming
TI Social image retrieval based on topic diversity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tag-based image retrieval; Social media; Feature fusion; Re-ranking;
   Topic analysis
ID SEARCH RERANKING; RELEVANCE
AB Image search re-ranking is one of the most important approaches to enhance the text-based image search results. Extensive efforts have been dedicated to improve the accuracy and diversity of tag-based image retrieval. However, how to make the top-ranked results relevant and diverse is still a challenging problem. In this paper, we propose a novel method to diversify the retrieval results by latent topic analysis. We first employ NMF (Non-negative Matrix Factorization) Lee and Seung (Nature 401(6755):788-791, 1999) to estimate the initial relevance score to the query q. Then, the initial relevance score is fed into an adaptive multi-feature fusion model to learn the final relevance score. Next, the diversification process is conducted. We group all the images by semantic clustering and estimate the topic distribution of each cluster by topic analysis. The clusters are ranked based on the topic distribution vector and the final retrieval image list is obtained by a greedy selection mechanism based on the estimated relevances. Experimental results on the NUS-Wide dataset show the effectiveness of the proposed approach.
C1 [Wang, Yaxiong; Zhu, Li] Xi An Jiao Tong Univ, Sch Software Engn, Xian, Peoples R China.
   [Qian, Xueming] Xi An Jiao Tong Univ, Minist Educ, SMILES LAB, Key Lab Intelligent Networks & Network Secur, Xian, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University
RP Zhu, L (corresponding author), Xi An Jiao Tong Univ, Sch Software Engn, Xian, Peoples R China.; Qian, XM (corresponding author), Xi An Jiao Tong Univ, Minist Educ, SMILES LAB, Key Lab Intelligent Networks & Network Secur, Xian, Peoples R China.
EM wangyx15@stu.xjtu.edu.cn; zhuli@mail.xjtu.edu.cn;
   qianxm@mail.xjtu.edu.cn
FU NSFC [161772407, 61701391, 61732008, 61902309]; National Key Research
   and Development Project [2019YFB2102500, 2018AAA0101100]
FX This work was supported in part by the NSFC under Grant 161772407,
   61701391, 61732008, and 61902309 and National Key Research and
   Development Project with No: 2019YFB2102500; and Emergence Mechanism and
   Calculation Method of Group Intelligence based on Internet with No:
   2018AAA0101100.
CR [Anonymous], 2010, IMPROVING SOCIAL TAG
   [Anonymous], 2013, INT C LEARN REPRESEN, DOI 10.1109/TCBB.2021.3077905
   [Anonymous], 2014, MEDIAEVAL
   [Anonymous], 2010, P ACM MULTIMEDIA
   Blei D, 2011, NIPS, P601
   Cai D, 2004, P ACM MULT
   Calumby RT, 2014, IEEE IMAGE PROC, P2197, DOI 10.1109/ICIP.2014.7025445
   Cui H, 2020, IEEE T IMAGE PROCESS, V29, P1271, DOI 10.1109/TIP.2019.2940693
   Cui Y, 2019, IEEE T FUZZY SYST, V27, P2443, DOI 10.1109/TFUZZ.2019.2900610
   Dai SC, 2016, CHIN CONT DECIS CONF, P20, DOI 10.1109/CCDC.2016.7530948
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Ghahramani Z, 2014, NIPS
   Gu Y, 2015, IEEE T IMAGE PROCESS, V24, P3450, DOI 10.1109/TIP.2015.2443501
   Haubold A, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1761, DOI 10.1109/ICME.2006.262892
   Hofmann T., 1999, NIPS, P914
   Hoque E, 2013, INFORM PROCESS MANAG, V49, P1122, DOI 10.1016/j.ipm.2012.12.001
   Ksibi Amel, 2013, Computer Analysis of Images and Patterns. 15th International Conference, CAIP 2013. Proceedings: LNCS 8048, P571, DOI 10.1007/978-3-642-40246-3_71
   Ksibi A, 2014, INT J MULTIMED INF R, V3, P29, DOI 10.1007/s13735-013-0045-5
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee S, 2010, SIGNAL PROCESS-IMAGE, V25, P761, DOI 10.1016/j.image.2010.10.002
   Li Xirong., 2008, Proceedings of the 1st ACM International Conference on Multimedia Information Retrieval, MIR '08, P180
   Lin W, 2016, PROC IEEE INT CONF S, P189, DOI 10.1109/ICSME.2016.25
   Lin X, 2017, P INT C INT MULT COM, P105
   LIU LD, 2019, IEEE INT SYM BROADB, pNIL46
   Liu Q, 2019, IEEE ACCESS, P123
   Lu D, 2016, IEEE T MULTIMEDIA, V18, P1628, DOI 10.1109/TMM.2016.2568099
   Natsev Apostol., 2007, MULTIMEDIA 07, P991
   Qian XM, 2017, IEEE T IMAGE PROCESS, V26, P3734, DOI 10.1109/TIP.2017.2699623
   Qian XM, 2015, IEEE T CIRC SYST VID, V25, P1857, DOI 10.1109/TCSVT.2014.2369731
   Qian XM, 2014, IEEE T CYBERNETICS, V44, P2493, DOI 10.1109/TCYB.2014.2309593
   Qian XM, 2013, NEUROCOMPUTING, V111, P144, DOI 10.1016/j.neucom.2012.12.021
   Shen JG, 2013, IEEE INT SYMP CIRC S, P1, DOI 10.1109/ISCAS.2013.6571767
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Song K., 2006, ACM Multimedia, P707
   Song ML, 2020, SUSTAINABLE MARINE RESOURCE UTILIZATION IN CHINA: A COMPREHENSIVE EVALUATION, P1, DOI 10.1016/B978-0-12-819911-4.00001-1
   Spyromitros-Xioufis E, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P323, DOI 10.1145/2671188.2749334
   Sun FM, 2012, NEUROCOMPUTING, V95, P40, DOI 10.1016/j.neucom.2011.05.040
   Tang JH, 2018, IEEE T CIRC SYST VID, V28, P2730, DOI 10.1109/TCSVT.2017.2715227
   Tian XM, 2015, IEEE T CYBERNETICS, V45, P2177, DOI 10.1109/TCYB.2014.2366740
   Van Leuken Reinier H, 2009, P 18 INT C WORLD WID, P341, DOI 10.1145/1526709.1526756
   Wang GX, 2012, J PHYS D APPL PHYS, V45, DOI 10.1088/0022-3727/45/37/375302
   Wang L, 2020, IEEE T CIRC SYST VID, V30, P4929, DOI 10.1109/TCSVT.2019.2959875
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397
   Wang M, 2010, IEEE T MULTIMEDIA, V12, P829, DOI 10.1109/TMM.2010.2055045
   Wang Y., 2019, IJCAI, P3792
   Wang YX, 2021, IEEE T MULTIMEDIA, V23, P3362, DOI 10.1109/TMM.2020.3024822
   Wu D, 2014, INT SYMP PARAL ARCH, P191, DOI 10.1109/PAAP.2014.26
   Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938
   Yan Y, 2017, MULTIMEDIA SYST, V23, P41, DOI 10.1007/s00530-014-0419-4
   Yanai K, 2013, MEDIAEVAL
   Yang XP, 2016, IEEE T IMAGE PROCESS, V25, P4617, DOI 10.1109/TIP.2016.2593653
   Yang XP, 2015, MULTIMEDIA SYST, V21, P217, DOI 10.1007/s00530-014-0379-8
   Yang Y, 2011, WORLD WIDE WEB, V14, P133, DOI 10.1007/s11280-010-0099-8
   Yang Y, 2015, INT J COMPUT VISION, V113, P113, DOI 10.1007/s11263-014-0781-x
   Yao T, 2015, IEEE I CONF COMP VIS, P28, DOI 10.1109/ICCV.2015.12
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Zhai HJ, 2021, IEEE T CIRC SYST VID, V31, P742, DOI 10.1109/TCSVT.2020.2991171
   Zhang YD, 2014, IEEE T IMAGE PROCESS, V23, P4448, DOI 10.1109/TIP.2014.2346991
NR 62
TC 1
Z9 1
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12367
EP 12387
DI 10.1007/s11042-020-10221-z
EA JAN 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000607038100004
OA hybrid
DA 2024-07-18
ER

PT J
AU Banerjee, S
   Kaur, S
   Kumar, P
AF Banerjee, Sneha
   Kaur, Sawinder
   Kumar, Parteek
TI Quote examiner: verifying quoted images using web-based text similarity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optical character recognition; Post-processing; Google Cloud Vision;
   Non-local means Denoising; Custom Google search engine
AB Over the last few years, there has been a rapid growth in digital data. Images with quotes are spreading virally through online social media platforms. Misquotes found online often spread like a forest fire through social media, which highlights the lack of responsibility of the web users when circulating poorly cited quotes. Thus, it is important to authenticate the content contained in the images being circulated online. So, there is a need to retrieve the information within such textual images to verify quotes before its usage in order to differentiate a fake or misquote from an authentic one. Optical Character Recognition (OCR) is used in this paper, for converting textual images into readable text format, but none of the OCR tools are perfect in extracting information from the images accurately. In this paper, a method of post-processing on the retrieved text to improve the accuracy of the detected text from images has been proposed. Google Cloud Vision has been used for recognizing text from images. It has also been observed that using post-processing on the extracted text improved the accuracy of text recognition by 3.5% approximately. A web-based text similarity approach (URLs and domain name) has been used to examine the authenticity of the content of the quoted images. Approximately, 96.26% accuracy has been achieved in classifying quoted images as verified or misquoted. Also, a ground truth dataset of authentic site names has been created. In this research, images with quotes by famous celebrities and global leaders have been used. A comparative analysis has been performed to show the effectiveness of our proposed algorithm.
C1 [Banerjee, Sneha; Kaur, Sawinder; Kumar, Parteek] TIET, Dept Comp Sci & Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Banerjee, S (corresponding author), TIET, Dept Comp Sci & Engn, Patiala, Punjab, India.
EM sneha.banerjee06@gmail.com; sawinderkaurvohra@gmail.com;
   parteek.bhatia@thapar.edu
FU NVIDIA Corporation
FX We gratefully acknowledge the support of NVIDIA Corporation with the
   donation of the Titan Xp GPU used for this research.
CR [Anonymous], 2012, ARXIV12040191
   Du S, 2013, IEEE T CIRC SYST VID, V23, P322, DOI 10.1109/TCSVT.2012.2203741
   Dutta S., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P130, DOI 10.1109/DAS.2012.76
   Geetha M., 2020, International Journal of Control and Automation, V13, P646
   Gur E, 2012, INT CONF FRONT HAND, P354, DOI 10.1109/ICFHR.2012.262
   Joshi N, 2017, INT CONF RELI INFO, P640, DOI 10.1109/ICRITO.2017.8342506
   Kushol Rafsanjany, 2018, International Journal of Computer Theory and Engineering, V10, P77, DOI 10.7763/IJCTE.2018.V10.1203
   Manwatkar PM, 2015, INT C INN INF EMB CO, P1
   Mihailidis P, 2017, AM BEHAV SCI, V61, P441, DOI 10.1177/0002764217701217
   Mukherjee A, 2013, UICCS032013
   Ntirogiannis K, 2013, IEEE T IMAGE PROCESS, V22, P595, DOI 10.1109/TIP.2012.2219550
   Papapicco C, 2019, ONLINE J COMMUN MEDI, V9, DOI 10.29333/ojcmt/5764
   Rajan V, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC), P1136, DOI 10.1109/ICCMC.2017.8282651
   Samarinas C, 2018, 10TH HELLENIC CONFERENCE ON ARTIFICIAL INTELLIGENCE (SETN 2018), DOI 10.1145/3200947.3201023
   Tripathy A, 2015, PROCEDIA COMPUT SCI, V57, P821, DOI 10.1016/j.procs.2015.07.523
   Vaithiyanathan D, 2019, INT CONF ADV COMPU, P90, DOI 10.1109/ICoAC48765.2019.246822
   Yang JF, 2012, IEEE IMAGE PROC, P1889, DOI 10.1109/ICIP.2012.6467253
NR 17
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12135
EP 12154
DI 10.1007/s11042-020-10270-4
EA JAN 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000606296900003
DA 2024-07-18
ER

PT J
AU Yu, YB
   Qi, MH
   Tang, YF
   Deng, QX
   Mai, F
   Zhaxi, NM
AF Yu, Yong-bin
   Qi, Min-hui
   Tang, Yi-fan
   Deng, Quan-xin
   Mai, Feng
   Zhaxi, Nima
TI A sample-level DCNN for music auto-tagging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sample-level; Strided convolutional layer; Residual block; WaveNet;
   Music auto-tagging
ID NEURAL-NETWORKS; CLASSIFICATION
AB Deep convolutional neural networks (DCNNs) has been widely used in music auto-tagging which is a multi-label classification task that predicts tags of audio signals. This paper presents a sample-level DCNN for music auto-tagging. The proposed DCNN highlights two components: strided convolutional layer for extracting local feature and reducing temporal dimension, and residual block from WaveNet for preserving input resolution and extracting more complex features. In order to further improve performance, squeeze-and-excitation (SE) block is introduced to the residual block. Under the evaluation metric of Area Under Receiver Operating Characteristic Curve (AUC-ROC) score, experiment results on MagnaTagATune (MTAT) dataset show that the two proposed models achieve 91.47% and 92.76% respectively. Furthermore, our proposed models have slightly surpass the state-of-the-art model SampleCNN with SE block.
C1 [Yu, Yong-bin; Qi, Min-hui; Tang, Yi-fan; Deng, Quan-xin; Mai, Feng] Univ Elect Sci & Technol China, Sch Informat & Software Engn, Chengdu 610054, Peoples R China.
   [Zhaxi, Nima] Tibet Univ, Sch Informat Sci & Technol, Lasa 850000, Peoples R China.
C3 University of Electronic Science & Technology of China; Tibet University
RP Qi, MH (corresponding author), Univ Elect Sci & Technol China, Sch Informat & Software Engn, Chengdu 610054, Peoples R China.
EM 2640415930@qq.com
FU Research Fund for International Young Scientists of National Nat-ural
   Science Foundation of China (NSFC) [61550110248]; Sichuan Science and
   Technology Program [2019YFG0190]; Research on Sino-Tibetan multi-source
   information acquisition, fusion, data mining and its application
   [H04W170186]
FX This work is supported by Research Fund for International Young
   Scientists of National Nat-ural Science Foundation of China (NSFC Grant
   No.61550110248), Sichuan Science and Technology Program (Grant
   No.2019YFG0190) and Research on Sino-Tibetan multi-source information
   acquisition, fusion, data mining and its application (Grant
   No.H04W170186).
CR [Anonymous], 2016, LECT NOTES COMPUTER
   Bertin-Mahieux T., 2011, ISMIR, P591
   Choi K, 2017, INT CONF ACOUST SPEE, P2392, DOI 10.1109/ICASSP.2017.7952585
   Dieleman Sander, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6964, DOI 10.1109/ICASSP.2014.6854950
   Fu ZY, 2011, IEEE T MULTIMEDIA, V13, P303, DOI 10.1109/TMM.2010.2098858
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holschneider M, 1990, Wavelets, P286, DOI DOI 10.1007/978-3-642-75988-828
   Hoshen Y, 2015, INT CONF ACOUST SPEE, P4624, DOI 10.1109/ICASSP.2015.7178847
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Kim T, 2019, IEEE J-STSP, V13, P285, DOI 10.1109/JSTSP.2019.2909479
   Kumar A, 2018, INT CONF KNOWL SYS, P175, DOI 10.1109/KSE.2018.8573325
   Lee J, 2017, ABS170301789 ARXIV
   Lee J, 2017, IEEE SIGNAL PROC LET, V24, P1208, DOI 10.1109/LSP.2017.2713830
   Lin YH, 2018, EUR SIGNAL PR CONF, P2270, DOI 10.23919/EUSIPCO.2018.8553318
   Nam J, 2019, IEEE SIGNAL PROC MAG, V36, P41, DOI 10.1109/MSP.2018.2874383
   Pons J, 2016, INT WORK CONTENT MUL
   Rajanna AR, 2015, 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P655, DOI 10.1109/ICMLA.2015.160
   Song GX, 2018, NEUROCOMPUTING, V292, P104, DOI 10.1016/j.neucom.2018.02.076
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Ulaganathan AS, 2019, J INTELL INF SYST, V52, P85, DOI 10.1007/s10844-018-0505-8
   van den Oord A, 2016, ADV NEUR IN, V29
   Zen HG, 2016, INTERSPEECH, P2273, DOI 10.21437/Interspeech.2016-522
NR 22
TC 0
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11459
EP 11469
DI 10.1007/s11042-020-10330-9
EA JAN 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000605119700002
DA 2024-07-18
ER

PT J
AU Zhou, SR
   Qiu, J
AF Zhou, Shuren
   Qiu, Jia
TI Enhanced SSD with interactive multi-scale attention features for object
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; SSD; Multi-scale feature; Attention mechanism
AB Single Shot MultiBox Detector (SSD) method using multi-scale feature maps for object detection, showing outstanding performance in object detection task. However, as a one-stage detection method, it's difficult for SSD methods to quickly notice significant areas of objects in the image. In the SSD network structure, feature maps of different scales are used to independently predict object, and there is a lack of interaction between low-level feature maps and high-level feature maps. In this paper we propose an enhanced SSD method using interactive multi-scale attention features (MA-SSD). Our method uses the attention mechanism to generate attention features of multiple scales and adds it to the original detection branch of the SSD method, which effectively enhances the feature representation ability and improves the detection accuracy. At the same time, the feature of different detection scales interacts with each other, and all the detection branches in our method have a parallel structure, which ensures the detection efficiency. Our proposed method achieves competitive performance on the public dataset PascalVOC.
C1 [Zhou, Shuren; Qiu, Jia] Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410114, Peoples R China.
C3 Changsha University of Science & Technology
RP Zhou, SR (corresponding author), Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410114, Peoples R China.
EM zsr@csust.edu.cn
RI zhou, shuren/JNS-2873-2023
OI zhou, shuren/0000-0002-0465-3258
FU Scientific Research Fund of Hunan Provincial Education Department of
   China [17A007]; Teaching Reform and Research Project of Hunan Province
   of China
FX This work was supported by the Scientific Research Fund of Hunan
   Provincial Education Department of China (Project No. 17A007); and the
   Teaching Reform and Research Project of Hunan Province of China (Project
   No. JG1615).
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   [Anonymous], 2014, Advances in Neural Information Processing Systems
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Buzcu I, 2016, IEEE IMAGE PROC, P3633, DOI 10.1109/ICIP.2016.7533037
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Everingham M., 2007, The PASCAL Visual Object Classes Chal- lenge (VOC) Results, DOI 10.1007/s11263-009-0275-4
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Gui Y, 2020, VISUAL COMPUT, V36, P469, DOI 10.1007/s00371-019-01633-6
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Li WJ, 2020, IEEE INTERNET THINGS, V7, P5882, DOI 10.1109/JIOT.2019.2949352
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mnih V, 2014, ADV NEUR IN, V27
   Qin JH, 2019, IEEE ACCESS, V7, P24626, DOI 10.1109/ACCESS.2019.2894673
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sempau J, 2000, PHYS MED BIOL, V45, P2263, DOI 10.1088/0031-9155/45/8/315
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang Q, 2019, MOBILE NETW APPL, V24, P1722, DOI 10.1007/s11036-018-1049-4
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang J, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/9472075
   Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685
   Zeng DJ, 2018, CMC-COMPUT MATER CON, V55, P121, DOI 10.3970/cmc.2018.055.121
   Zhang DY, 2017, J VIS COMMUN IMAGE R, V48, P281, DOI 10.1016/j.jvcir.2017.07.006
   Zhang JM, 2020, MULTIMED TOOLS APPL, V79, P15095, DOI 10.1007/s11042-018-6562-8
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang ZS, 2018, PROC CVPR IEEE, P5813, DOI 10.1109/CVPR.2018.00609
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
NR 37
TC 40
Z9 41
U1 6
U2 69
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11539
EP 11556
DI 10.1007/s11042-020-10191-2
EA JAN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000605548700027
DA 2024-07-18
ER

PT J
AU Muthalagu, R
   Bolimera, A
   Kalaichelvi, V
AF Muthalagu, Raja
   Bolimera, Anudeepsekhar
   Kalaichelvi, V.
TI Vehicle lane markings segmentation and keypoint determination using deep
   convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
AB Lane detection is used to detect the lane markings in a road scene between which the vehicle is driving and provide the accurate location and shape of each lane marking. It serves as one of the key techniques to enable modern, assisted, and autonomous driving systems. However, lane detection poses several challenges. The lane markings vary in their shapes, colors, and patterns. The lack of distinct features and the presence of several occlusions on the roads makes the use of conventional methods using handcrafted features less robust and computationally expensive. In this study, we propose a compact and efficient multi-stage Convolutional Neural Network (CNN) architecture which can learn both the lane markings segmentation and also the localization and shape of each lane in the form of key-points. The proposed model combines a lane mask proposal network with a lane key-point determination network to accurately predict the key-points that describe the left and right lane-markings of the vehicle lanes. The high running speed and low computational cost of the proposed method make it suitable for being deployed in the real world vehicle systems. Through simulation results, we also show that the proposed method is robust to a variety of weather conditions and highway driving scenarios.
C1 [Muthalagu, Raja] Birla Inst Technol & Sci Pilani, Dept Comp Sci, Dubai Campus, Dubai, U Arab Emirates.
   [Bolimera, Anudeepsekhar; Kalaichelvi, V.] Birla Inst Technol & Sci Pilani, Dept Elect & Elect Engn, Dubai Campus, Dubai, U Arab Emirates.
RP Muthalagu, R (corresponding author), Birla Inst Technol & Sci Pilani, Dept Comp Sci, Dubai Campus, Dubai, U Arab Emirates.
EM raja.sanjeeve@gmail.com
RI Venkatesan, Kalaichelvi/AAE-7605-2022
OI M, Raja/0000-0003-0971-6235
CR Amaradi P, 2016, INT CONF ELECTRO INF, P674, DOI 10.1109/EIT.2016.7535320
   Ayachi Riadh, 2020, Proceedings of the 8th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT18). Smart Innovation, Systems and Technologies (SIST 146), P234, DOI 10.1007/978-3-030-21005-2_23
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bellis EA, 2008, NATL MOTOR VEHICLE C
   Chougule S, 2018, IEEE INT VEH SYM, P1444, DOI 10.1109/IVS.2018.8500598
   Gayko JE, 2012, HANDBOOK OF INTELLIGENT VEHICLES, VOLS 1 AND 2, P689, DOI 10.1007/978-0-85729-085-4_26
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hou YN, 2019, IEEE I CONF COMP VIS, P1013, DOI 10.1109/ICCV.2019.00110
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kervadec H, 2019, PR MACH LEARN RES, V102, P285
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mingfa, 2018, ADV MULTIMED, V24, P1687
   Muthalagu R, 2020, COMPUT ELECTR ENG, V85, DOI 10.1016/j.compeleceng.2020.106653
   Oliveira M, 2015, INFORM FUSION, V24, P108, DOI 10.1016/j.inffus.2014.09.003
   Pan XG, 2018, AAAI CONF ARTIF INTE, P7276
   Paszke A., 2016, ARXIV160602147
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Singh S., 2015, CRITICAL REASONS CRA
   Tabelini L, 2021, INT C PATT RECOG, P6150, DOI 10.1109/ICPR48806.2021.9412265
   Talib ML, 2013, LECT NOTES COMPUT SC, V8237, P176, DOI 10.1007/978-3-319-02958-0_17
   Visvikis C, 2008, 374 PPR TRASP RES LA
   Wu Huikai, 2019, ARXIV190311816
   Xing Y, 2018, IEEE-CAA J AUTOMATIC, V5, P645, DOI 10.1109/JAS.2018.7511063
   Yan XQ, 2017, CHIN AUTOM CONGR, P2120, DOI 10.1109/CAC.2017.8243122
   Yosinski J., 2015, ARXIV150606579, V2015, P12
NR 27
TC 12
Z9 13
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 11201
EP 11215
DI 10.1007/s11042-020-10248-2
EA JAN 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000605119800001
DA 2024-07-18
ER

PT J
AU Kim, H
   Yeo, C
   Cha, M
   Mun, D
AF Kim, Hyungki
   Yeo, Changmo
   Cha, Moohyun
   Mun, Duhwan
TI A method of generating depth images for view-based shape retrieval of 3D
   CAD models from partial point clouds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth image; Image resolution selection; Point cloud; View-based 3D
   shape retrieval; Viewpoint selection
ID SEGMENTATION
AB Laser scanners can easily acquire the geometric data of physical environments in the form of point clouds. Industrial 3D reconstruction processes generally recognize objects from point clouds, which should include both geometric and semantic data. However, the recognition process is often a bottleneck in 3D reconstruction because it is labor intensive and requires expertise in domain knowledge. To address this problem, various methods have been developed to recognize objects by retrieving their corresponding models from a database via input geometric queries. In recent years, geometric data conversion to images and view-based 3D shape retrieval applications have demonstrated high accuracies. Depth images that encode the depth values as pixel intensities are frequently used for view-based 3D shape retrieval. However, geometric data collected from objects are often incomplete owing to occlusions and line-of-sight limitations. Images generated by occluded point clouds lower the view-based 3D object retrieval performance owing to loss of information. In this paper, we propose a viewpoint and image-resolution estimation method for view-based 3D shape retrieval from point cloud queries. Further, automatic selection of viewpoint and image resolution are proposed using the data acquisition rate and density calculations from sampled viewpoints and image resolutions. The retrieval performances for images generated by the proposed method are investigated via experiments and compared for various datasets. Additionally, view-based 3D shape retrieval performance with a deep convolutional neural network was investigated using the proposed method.
C1 [Kim, Hyungki] Jeonbuk Natl Univ, Div Comp Sci & Engn, 567 Baekje Daero, Jeonju Si 54896, Jeollabuk Do, South Korea.
   [Yeo, Changmo] Kyungpook Natl Univ, Dept Precis Mech Engn, 2559 Gyeongsang Daero, Sangju 37224, Gyeongsangbuk D, South Korea.
   [Cha, Moohyun] Korea Inst Machinery & Mat, Mech Syst Safety Res Div, 156 Gajeongbuk Ro, Daejeon 34103, South Korea.
   [Mun, Duhwan] Korea Univ, Sch Mech Engn, 145 Anam Ro, Seoul 02841, South Korea.
C3 Jeonbuk National University; Jeonbuk National University Hospital;
   Kyungpook National University; Korea Institute of Machinery & Materials
   (KIMM); Korea University
RP Mun, D (corresponding author), Korea Univ, Sch Mech Engn, 145 Anam Ro, Seoul 02841, South Korea.
EM hk.kim@jbnu.ac.kr; ycm2420@gmail.com; mhcha@kimm.re.kr;
   dhmun@korea.ac.kr
RI Mun, Duhwan/AAC-5360-2020; Mun, Duhwan/AAV-6700-2021
OI Mun, Duhwan/0000-0002-5477-0671
FU Industrial Core Technology Development Program - Korean government
   (MOTIE) [20000725]; Basic Science Research Program through the National
   Research Foundation of Korea (NRF) - Korean government (MSIT)
   [NRF-2019R1F1A1053542]; "Research Base Construction Fund Support
   Program" - Jeonbuk National University in 2020
FX This research was supported by the Industrial Core Technology
   Development Program (Project ID: 20000725) funded by the Korean
   government (MOTIE) and the Basic Science Research Program (Project ID:
   NRF-2019R1F1A1053542) through the National Research Foundation of Korea
   (NRF) funded by the Korean government (MSIT) and by "Research Base
   Construction Fund Support Program" funded by Jeonbuk National University
   in 2020.
CR Anil E.B., 2011, 28 INT S AUTOMATION, DOI DOI 10.22260/ISARC2011/0063
   [Anonymous], 2006, 2006 IEEE COMPUTER S
   [Anonymous], 2016, ARXIV160306208
   Biasotti S, 2003, LECT NOTES COMPUT SC, V2886, P194
   Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186
   COHEN I, 1992, LECT NOTES COMPUT SC, V588, P458
   Dey TK, 2003, LECT NOTES COMPUT SC, V2748, P25
   Feixas M, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1462055.1462056
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Kazhdan M., 2003, Symposium on Geometry Processing, P156
   Liu YJ, 2013, IEEE T AUTOM SCI ENG, V10, P783, DOI 10.1109/TASE.2012.2228481
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Marton ZC, 2009, IEEE INT CONF ROBOT, P2829
   Maruyama T, 2016, J COMPUT DES ENG, V3, P250, DOI 10.1016/j.jcde.2016.03.001
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   McWherter D., 2001, Sixth ACM Symposium on Solid Modeling and Applications, P78
   Novotni M., 2003, P 8 ACM S SOL MOD AP, P216, DOI DOI 10.1145/781606.781639
   Ohbuchi Ryutarou, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P63, DOI 10.1109/ICCVW.2009.5457716
   Ohbuchi R, 2005, INT J COMPUT APPL T, V23, P70, DOI 10.1504/IJCAT.2005.006466
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Paquet E, 2000, SIGNAL PROCESS-IMAGE, V16, P103, DOI 10.1016/S0923-5965(00)00020-5
   Qi C.R., 2016, P IEEE CVF C COMPUTE
   Rusu RB, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3384, DOI 10.1109/IROS.2008.4650967
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Sánchez-Cruz H, 2003, IMAGE VISION COMPUT, V21, P1027, DOI 10.1016/S0262-8856(03)00119-7
   Savelonas MA, 2015, MULTIMED TOOLS APPL, V74, P11783, DOI 10.1007/s11042-014-2267-9
   Son H., 2013, Computing in Civil Engineering. 2013 ASCE International Workshop on Computing in Civil Engineering. Proceedings, P765
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609
   Tang PB, 2010, AUTOMAT CONSTR, V19, P829, DOI 10.1016/j.autcon.2010.06.007
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Tasse FP, 2015, IEEE I CONF COMP VIS, P163, DOI 10.1109/ICCV.2015.27
   Vazquez P.-P., 2001, Vision, Modeling, and Visualization 2001. Proceedings, P273
   Woo H, 2002, INT J MACH TOOL MANU, V42, P167, DOI 10.1016/S0890-6955(01)00120-1
   Yeo C., 2020, JMST ADV, V2, P15, DOI [10.1007/s42791-019-00027-y, DOI 10.1007/S42791-019-00027-Y]
   Zehtaban L, 2016, J COMPUT DES ENG, V3, P274, DOI 10.1016/j.jcde.2016.04.002
   Zhang C, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P935, DOI 10.1109/ICIP.2001.958278
NR 37
TC 12
Z9 13
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10859
EP 10880
DI 10.1007/s11042-020-10283-z
EA JAN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000604479100012
DA 2024-07-18
ER

PT J
AU Su, XP
   Zhu, DY
   Ren, J
   Rätsch, M
AF Su, Xueping
   Zhu, Danyao
   Ren, Jie
   Raetsch, Matthias
TI Automatic identification of focus personage in multi-lingual news images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recurrent convolutional neural network (RCNN); Long short-term memory
   network (LSTM); Iterative quantization (ITQ); Multi-lingual news
ID FACE REPRESENTATION; BINARY PATTERN
AB Annotations of character IDs in news images are critical as ground truth for news retrieval and recommendation system. Universality and accuracy optimization of deep neural network models constitutes the key technology to improve the precision and computing efficiency of automatic news character identification, which is attracting increased attention globally. This paper explores the optimized deep neural network model for automatic focus personage identification in multi-lingual news. First, the face model of the focus personage is trained by using the corresponding face images from German news as positive samples. Next, the scheme of Recurrent Convolutional Neural Network (RCNN) + Bi-directional Long-Short Term Memory (Bi-LSTM) + Conditional Random Field (CRF) is utilized to label the focus name, and the RCNN-RCNN encoder-decoder is applied to translate names of people into multiple languages. Third, face features are described by combining the advantages of Local Gabor Binary Pattern Histogram Sequence (LGBPHS) and RCNN, and iterative quantization (ITQ) is used to binarize codes. Finally, a name semantic network is built for different domains. Experiments are performed on a dataset which comprises approximately 100,000 news images. The experimental results demonstrate that the proposed method achieves a significant improvement over other algorithms.
C1 [Su, Xueping; Zhu, Danyao; Ren, Jie] Xian Polytech Univ, Sch Elect & Informat, Xian, Peoples R China.
   [Raetsch, Matthias] Reutlingen Univ, Dept Engn, Interact & Mobile Robot & Artificial Intelligence, Reutlingen, Germany.
C3 Xi'an Polytechnic University
RP Su, XP (corresponding author), Xian Polytech Univ, Sch Elect & Informat, Xian, Peoples R China.
EM yifeichongtian1201@163.com
FU National Natural Science Foundation of China [61902301]; Shaanxi natural
   science basic research project [2019JQ-255]; Scientific Research Program
   - Shaanxi Provincial Education Department [19JK0364]; Graduate
   Scientific Innovation Fund for Xi'an Polytechnic University [chx2020018]
FX This work is supported by National Natural Science Foundation of China
   under Grant 61902301, Shaanxi natural science basic research project
   under Grant 2019JQ-255, the Scientific Research Program funded by
   Shaanxi Provincial Education Department, under Grant 19JK0364, and
   Graduate Scientific Innovation Fund for Xi'an Polytechnic University
   No.chx2020018.
CR Chen JZ, 2016, PROCEEDINGS OF 2016 12TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P551, DOI [10.1109/CIS.2016.133, 10.1109/CIS.2016.0134]
   Chen X, 2017, IEEE COMPUT SOC CONF, P2088, DOI 10.1109/CVPRW.2017.260
   Cho K., 2014, ARXIV14061078
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   Guillaumin M, 2010, LECT NOTES COMPUT SC, V6311, P634, DOI 10.1007/978-3-642-15549-9_46
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/685404
   Le DD, 2012, PROC CVPR IEEE, P2965, DOI 10.1109/CVPR.2012.6248025
   Li L, 2017, AER ADV ENG RES, V102, P1
   Liang M, 2015, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR.2015.7298958
   Liu LDY, 2018, DEEP LEARNING NATURA
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Lu JW, 2015, IEEE T INF FOREN SEC, V10, P1371, DOI 10.1109/TIFS.2015.2408431
   Luo G., 2015, P 2015 C EMP METH NA, P879, DOI [10.18653/v1/D15-1104, DOI 10.18653/V1/D15-1104]
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Ozkan D, 2010, PATTERN RECOGN, V43, P1717, DOI 10.1016/j.patcog.2009.10.015
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123
   Su XP, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.3.033036
   Su XP, 2016, MULTIMED TOOLS APPL, V75, P6445, DOI 10.1007/s11042-015-2581-x
   Su XP, 2014, MULTIMED TOOLS APPL, V73, P1643, DOI 10.1007/s11042-013-1578-6
   Sun Y, 2016, PROC CVPR IEEE, P4856, DOI 10.1109/CVPR.2016.525
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Sundermeyer M, 2015, IEEE-ACM T AUDIO SPE, V23, P517, DOI 10.1109/TASLP.2015.2400218
   Tran K, 2016, P 2016 C N AM CHAPTE, P321, DOI 10.18653/v1/N16-1036
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wohlhart Paul, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P132, DOI 10.1007/978-3-642-23123-0_14
   Xueping Su, 2017, 2017 International Conference on the Frontiers and Advances in Data Science (FADS). Proceedings, P64, DOI 10.1109/FADS.2017.8253195
   Yang J, 2005, Proceedings of the 2005 International Conference on Active Media Technology (AMT 2005), P28
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhou J, 2016, IEEE COMPUT SOC CONF, P1535, DOI 10.1109/CVPRW.2016.191
NR 31
TC 0
Z9 0
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 11015
EP 11030
DI 10.1007/s11042-020-10254-4
EA JAN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000604479100005
DA 2024-07-18
ER

PT J
AU Muhammed, A
   Mhala, NC
   Pais, AR
AF Muhammed, Ajnas
   Mhala, Nikhil C.
   Pais, Alwyn R.
TI A novel fingerprint template protection and fingerprint authentication
   scheme using visual secret sharing and super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fingerprint template; Fingerprint authentication; Visual Secret Sharing
   (VSS); Share; Block-Based Progressive Visual Secret Sharing (BPVSS);
   Super-Resolution (SR)
ID CANCELABLE BIOMETRICS; FUZZY VAULT; CRYPTOGRAPHY; SECURITY; DESIGN;
   IMAGE; ENHANCEMENT; PRIVACY
AB Fingerprint is the most recommended and extensively practicing biometric trait for personal authentication. Most of the fingerprint authentication systems trust minutiae as the characteristic for authentication. These characteristics are preserved as fingerprint templates in the database. However, it is observed that the databases are not secure and can be negotiated. Recent studies reveal that, if a person's minutiae points are dripped, fingerprint can be restored from these points. Similarly, if the fingerprint records are lost, it is a permanent damage. There is no mechanism to replace the fingerprint as it is part of the human body. Hence there is a necessity to secure the fingerprint template in the database. In this paper, we introduce a novel fingerprint template protection and fingerprint authentication scheme using visual secret sharing and super-resolution. During enrollment, a secret fingerprint image is encrypted into n shares. Each share is stored in a distinct database. During authentication, the shares are collected from various databases. The original secret fingerprint image is restored using a multiple image super-resolution procedure. The experimental results show that the reconstructed fingerprints are similar to the original fingerprints. The proposed method is robust, secure, and efficient in terms of fingerprint template protection and authentication.
C1 [Muhammed, Ajnas; Mhala, Nikhil C.; Pais, Alwyn R.] NITK Surathkal, Informat Secur Res Lab, Mangalore, Karnataka, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Muhammed, A (corresponding author), NITK Surathkal, Informat Secur Res Lab, Mangalore, Karnataka, India.
EM ajnas.177co001@nitk.edu.in
RI Mhala, Nikhil/P-8806-2019
OI MHALA, NIKHIL/0000-0003-0223-6335; Pais, Alwyn/0000-0003-4571-4608;
   Muhammed, Ajnas/0000-0003-0068-6885
CR Ahmad T, 2011, PATTERN RECOGN, V44, P2555, DOI 10.1016/j.patcog.2011.03.015
   Ahn D, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P29, DOI 10.1109/CISP.2008.742
   Alam B, 2018, J NETW COMPUT APPL, V115, P20, DOI 10.1016/j.jnca.2018.04.013
   Alsuhibany SA, 2019, IEEE ACCESS, V7, P76573, DOI 10.1109/ACCESS.2019.2920858
   Ang R, 2005, LECT NOTES COMPUT SC, V3574, P242
   [Anonymous], 2012, INFORM KNOWLEDGE MAN
   [Anonymous], 2010, ARXIV10041748
   [Anonymous], 2012, INT J EMERG TECHNOL
   Belguechi R., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P196, DOI 10.1109/ICB.2012.6199808
   Bhosale AG, 2020, INF SECUR J, V29, P199, DOI 10.1080/19393555.2020.1740840
   Breebaart J., 2009, Datenschutz und Datensicherheit-DuD, V33, P299
   Camlikaya E, 2008, PROC SPIE, V6944, DOI 10.1117/12.777738
   Chin CS, 2006, COMPUT VIS IMAGE UND, V102, P169, DOI 10.1016/j.cviu.2006.01.002
   Chiu PL, 2020, IEEE ACCESS, V8, P111330, DOI 10.1109/ACCESS.2020.3000308
   Chiu PL, 2019, SIGNAL PROCESS, V165, P233, DOI 10.1016/j.sigpro.2019.06.038
   Derman E, 2016, INT CONF SYST SIGNAL, P153
   Dutta S, 2019, DESIGN CODE CRYPTOGR, V87, P1699, DOI 10.1007/s10623-018-0570-6
   Elad M, 1997, IEEE T IMAGE PROCESS, V6, P1646, DOI 10.1109/83.650118
   Feng Q, 2008, ISCSCT 2008: INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND COMPUTATIONAL TECHNOLOGY, VOL 2, PROCEEDINGS, P572, DOI 10.1109/ISCSCT.2008.226
   Gomez-Barrero M, 2018, INFORM FUSION, V42, P37, DOI 10.1016/j.inffus.2017.10.003
   Gunjan VK, 2019, ICCCE 2019, P405
   Gurunathan K, 2020, MULTIMED TOOLS APPL, V79, P3893, DOI 10.1007/s11042-019-7471-1
   Hu H, 2019, MULTIMED TOOLS APPL, V78, P12055, DOI 10.1007/s11042-018-6738-2
   Hwang JW, 2004, IEEE SIGNAL PROC LET, V11, P359, DOI 10.1109/LSP.2003.821718
   Jin Z, 2016, IEEE T SYST MAN CY-S, V46, P1415, DOI 10.1109/TSMC.2015.2499725
   Jin Z, 2014, PATTERN RECOGN LETT, V42, P137, DOI 10.1016/j.patrec.2014.02.011
   Jin Z, 2012, EXPERT SYST APPL, V39, P6157, DOI 10.1016/j.eswa.2011.11.091
   Juels A, 2006, DESIGN CODE CRYPTOGR, V38, P237, DOI 10.1007/s10623-005-6343-z
   Juels A, 1999, 6TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P28, DOI 10.1145/319709.319714
   Kaur H, 2020, ADV INTELL SYST, V1024, P13, DOI 10.1007/978-981-32-9291-8_2
   Kaur H, 2016, MULTIMED TOOLS APPL, V75, P16333, DOI 10.1007/s11042-015-2933-6
   Kho JB, 2019, PATTERN RECOGN, V91, P245, DOI 10.1016/j.patcog.2019.01.039
   Kumar Gaurav, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P890, DOI 10.1109/ICPR.2010.224
   Lacharme P., 2013, International Conference on Security and Cryptography (SECRYPT), P8
   Lee MJ, 2018, 2018 IEEE INT WORKSH, P1
   Lee Y, 2009, CIB: 2009 IEEE WORKSHOP ON COMPUTATIONAL INTELLIGENCE IN BIOMETRICS: THEORY, ALGORITHMS, AND APPLICATIONS, P92
   Li C, 2014, CONCURR COMP-PRACT E, V26, P1593, DOI 10.1002/cpe.3042
   Liu WJ, 2019, IEEE ACCESS, V7, P114374, DOI 10.1109/ACCESS.2019.2931073
   Lumini A, 2007, PATTERN RECOGN, V40, P1057, DOI 10.1016/j.patcog.2006.05.030
   Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144
   Maltoni D., 2009, HDB FINGERPRINT RECO, DOI 10.1007/978-1-84882-254-2
   Manisha, 2020, Intelligent Computing. Proceedings of the 2020 Computing Conference. Advances in Intelligent Systems and Computing (AISC 1230), P532, DOI 10.1007/978-3-030-52243-8_38
   Mehmood R, 2020, LECT NOTES ELECTR EN, V597, P455, DOI 10.1007/978-3-030-29407-6_33
   Mhala NC, 2019, SIGNAL PROCESS, V162, P253, DOI 10.1016/j.sigpro.2019.04.023
   Mhala NC, 2018, IET IMAGE PROCESS, V12, P422, DOI 10.1049/iet-ipr.2017.0759
   Monoth T, 2010, PROCEDIA COMPUT SCI, V2, P143, DOI 10.1016/j.procs.2010.11.018
   Monoth T, 2010, 2010 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2010), P171, DOI 10.1109/CW.2010.39
   Mukesh R., 2012, 2012 International Conference on Advances in Engineering, Science and Management (ICAESM), P16
   Murad SH, 2019, ARXIV190211167
   Nagar A, 2008, INT C PATT RECOG, P822
   Nandakumar K., 2017, 2017 IEEE WORKSH INF, P1
   Nandakumar K, 2010, IEEE INT WORKS INFOR
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Patil S, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P190, DOI 10.1109/ICCUBEA.2015.42
   Rao YV Subba., 2008, TENCON 2008-2008 IEEE Region 10 Conference, P1
   Ratha N, 2006, INT C PATT RECOG, P370
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Ross A, 2005, PROC SPIE, V5779, P68, DOI 10.1117/12.604477
   Ross A, 2011, IEEE T INF FOREN SEC, V6, P70, DOI 10.1109/TIFS.2010.2097252
   Ross A, 2010, PROC SPIE, V7667, DOI 10.1117/12.852280
   Sadhya D, 2018, MULTIMED TOOLS APPL, V77, P15113, DOI 10.1007/s11042-017-5095-x
   Sandhya M, 2018, PATTERN ANAL APPL, V21, P397, DOI 10.1007/s10044-016-0584-5
   Sandhya M, 2017, IET BIOMETRICS, V6, P173, DOI 10.1049/iet-bmt.2016.0008
   Sandhya M, 2016, IET BIOMETRICS, V5, P131, DOI 10.1049/iet-bmt.2015.0034
   Sandhya M, 2015, INT CONF BIOMETR, P386, DOI 10.1109/ICB.2015.7139100
   Savvides M, 2004, INT C PATT RECOG, P922, DOI 10.1109/ICPR.2004.1334679
   SHERLOCK BG, 1994, IEE P-VIS IMAGE SIGN, V141, P87, DOI 10.1049/ip-vis:19949924
   Shin SW, 2009, ETRI J, V31, P628, DOI 10.4218/etrij.09.0209.0137
   Sinduja R., 2012, 2012 International Conference on Advances in Engineering, Science and Management (ICAESM), P650
   Tan LD, 2020, MULTIMED TOOLS APPL, V79, P5719, DOI 10.1007/s11042-019-08351-0
   Trivedi AK, 2020, COMPUT SECUR, V90, DOI 10.1016/j.cose.2019.101690
   Tulyakov S, 2007, PATTERN RECOGN LETT, V28, P2427, DOI 10.1016/j.patrec.2007.08.008
   VeriFinger SDK, 2010, NEURO TECHNOLOGY
   Wang S, 2013, J INEQUAL APPL, DOI 10.1186/1029-242X-2013-81
   Wang S, 2017, PATTERN RECOGN, V61, P447, DOI 10.1016/j.patcog.2016.08.017
   Wang S, 2016, PATTERN RECOGN, V54, P14, DOI 10.1016/j.patcog.2016.01.001
   Wang S, 2012, PATTERN RECOGN, V45, P4129, DOI 10.1016/j.patcog.2012.05.004
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Wong WJ, 2013, PATTERN RECOGN LETT, V34, P1221, DOI 10.1016/j.patrec.2013.03.039
   Yan B, 2019, IEEE T IMAGE PROCESS, V28, P896, DOI 10.1109/TIP.2018.2874378
   Yan XH, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS (ITHINGS) AND IEEE GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) AND IEEE CYBER, PHYSICAL AND SOCIAL COMPUTING (CPSCOM) AND IEEE SMART DATA (SMARTDATA), P578, DOI 10.1109/iThings-GreenCom-CPSCom-SmartData.2016.129
   Yang WC, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11020141
   Yang WC, 2014, PATTERN RECOGN, V47, P1309, DOI 10.1016/j.patcog.2013.10.001
   Yanikoglu B., 2004, P ICPR BCTP WORKSH A, P43
   Zhou Z, 2019, IEEE ACCESS, V7, P108818, DOI 10.1109/ACCESS.2019.2933228
NR 86
TC 4
Z9 4
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10255
EP 10284
DI 10.1007/s11042-020-10095-1
EA NOV 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000590503300003
DA 2024-07-18
ER

PT J
AU Díaz, E
   Panach, JI
   Rueda, S
   Vanderdonckt, J
AF Diaz, Eduardo
   Panach, Jose Ignacio
   Rueda, Silvia
   Vanderdonckt, Jean
TI An empirical study of rules for mapping BPMN models to graphical user
   interfaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BPMN patterns; Business process model and notation; Experimental study;
   Graphical User Interfaces; Mapping rules; Usability engineering
ID DESIGN; FRAMEWORK
AB Generation of Graphical User Interfaces (GUIs) from Business Process Model Notation (BPMN) models is a step manually performed by an analyst in any information system development. By analyzing twelve BPMN projects and comparing them with their associated GUIs, a set of rules for mapping BPMN models expressed in terms of BPMN patterns to GUIs has been identified. This paper provides three main contributions: an empirical validation of these mapping rules; a classification of their alternatives to identify which ones support usability; and the validation of this classification. We conducted an experiment to study whether 43 participants apply the same rules as previously identified with response variables as: correctness of the rules, their completeness, perceived usefulness and intention to use. To select the mapping rules alternatives that effectively impact usability, we classified them according to empirically validated usability guidelines found in the literature. We also validated them with participants and response variables as: correctness of the guidelines, their perceived usefulness and intention to use. Correctness of the mapping rules was assessed positively (74%), as well as their completeness (76%), perceived usefulness (95%) and intention to use (68%). Correctness of the usability recommendations for using these mapping rules was also assesses positively (57%), as well as their perceived usefulness (86%) and intention to use (72%). This paper provides analysts with effective and efficient guidance on how to apply them consistently and to feed a software for semi-automatic transformation of BPMN models into their corresponding GUIs.
C1 [Diaz, Eduardo; Panach, Jose Ignacio; Rueda, Silvia] Univ Valencia, Escola Tecn Super Engn, Dept Informat, Ave Univ S-N, Valencia 46100, Spain.
   [Vanderdonckt, Jean] Catholic Univ Louvain, LouRIM Inst, Pl Doyens 1, B-1348 Louvain La Neuve, Belgium.
C3 University of Valencia; Universite Catholique Louvain
RP Díaz, E (corresponding author), Univ Valencia, Escola Tecn Super Engn, Dept Informat, Ave Univ S-N, Valencia 46100, Spain.
EM diazsua@alumni.uv.es
RI Panach, Jose Ignacio/ABF-2099-2020; Rueda Pascual, Silvia/A-2132-2019
OI Panach, Jose Ignacio/0000-0002-7043-6227; Rueda Pascual,
   Silvia/0000-0002-1020-706X; Diaz Suarez, Jorge
   Eduardo/0000-0003-2794-8152
FU Ministry of Education of Peru; National Scholarship and Educational Loan
   Program PRONABEC -President of the Republic Scholarship; Spanish
   Ministry of Science and Innovation through project DataME
   [TIN2016-80811-P]
FX The first author acknowledges support from the Ministry of Education of
   Peru with the National Scholarship and Educational Loan Program PRONABEC
   -President of the Republic Scholarship. This project also has the
   support of Spanish Ministry of Science and Innovation through project
   DataME (ref: TIN2016-80811-P). We would like to thank the participants
   for conducting the experiment.
CR Acerbis R, 2007, LECT NOTES COMPUT SC, V4607, P501
   [Anonymous], 2007, APPL SYSTEMS PRODUCT
   [Anonymous], BUS MOD PATT
   [Anonymous], BON SOFTW
   [Anonymous], 2019, SOFT
   [Anonymous], US WEB DES SYST
   [Anonymous], 2007, MICROSOFT COMMON UI
   [Anonymous], 2002, ESSENTIAL GUIDE USER
   [Anonymous], 2006, Business Process Execution Language for Web Services BPEL and BPEL4WS
   [Anonymous], 247652017 ISOIECIEEE
   Barforooshi Sahar Yousefi, 2010, Proceedings of the 2010 2nd International Conference on Electronic Computer Technology (ICECT 2010), P59, DOI 10.1109/ICECTECH.2010.5479990
   Borst C, 2019, IEEE T HUM-MACH SYST, V49, P623, DOI 10.1109/THMS.2019.2919742
   Bouchelligua W., 2010, User interfaces modelling of workflow information systems
   Bouillon L, 2005, THIRD LATIN AMERICAN WEB CONGRESS, PROCEEDINGS, P3
   Bouzidi A, 2018, 2018 IEEE ACS 15 INT, P1
   Brambilla M, 2012, LECT NOTES BUS INF P, V99, P219
   Brambilla M, 2010, LECT NOTES COMPUT SC, V6189, P415, DOI 10.1007/978-3-642-13911-6_28
   Bush A, 2011, INFORM MODELING NEW, P199
   Calvary G, 2003, INTERACT COMPUT, V15, P289, DOI 10.1016/S0953-5438(03)00010-9
   Cruz E. F., 2018, ICSOFT, P605
   DAVIS FD, 1989, MANAGE SCI, V35, P982, DOI 10.1287/mnsc.35.8.982
   de Carvalho EA, 2021, COGN TECHNOL WORK, V23, P65, DOI 10.1007/s10111-019-00620-0
   Diaz E, 2018, INT CONF RES CHAL
   Driss M, 2020, IEEE ACCESS, V8, P59326, DOI 10.1109/ACCESS.2020.2982592
   García JG, 2008, J UNIVERS COMPUT SCI, V14, P3160
   Giner P, 2007, CEUR WORKSHOP P, V261
   Google Inc, MAT DESIGN
   Han L, 2016, COMM COM INF SC, V602, P19, DOI 10.1007/978-981-10-1019-4_2
   Hautojrvi P., 1979, Experimentation in software engineering, V1ST, DOI [10.1007/978-3-642-81316-0, 10.1007/978-3-642-29044-2., DOI 10.1007/978-3-642-29044-2]
   J Gonzalez-Huerta, 2017, BUSINESS PROCESS REE
   Johnson J., 2007, GUI BLOOPERS 2 0 COM
   Kieffer S, 2017, AIS T HUMANCOMPUTER, V9, P149, DOI [10.17705/1thci.00093, DOI 10.17705/1THCI.00093]
   Kolb J, 2012, UIB201204
   Kolb J., 2012, On the Move to Meaningful Internet Systems: OTM 2012, P444
   Kotronis C, 2019, 2019 IEEE INTERNATIONAL CONGRESS ON INTERNET OF THINGS (IEEE ICIOT 2019), P100, DOI 10.1109/ICIOT.2019.00028
   Kristiansen R, 2007, MODEL BASED USER INT
   Langer P., 2014, MODELLIERUNG 2014, P289
   Li X, 2010, AUTOPA AUTOMATIC PRO
   Likert R., 1932, Arch. Psychol., V22, P44, DOI DOI 10.4135/9781412961288.N454
   Limbourg Q, 2004, ENGINEERING ADVANCED WEB APPLICATIONS, P325
   LINDLAND OI, 1994, IEEE SOFTWARE, V11, P42, DOI 10.1109/52.268955
   Ling Yin, 2011, Proceedings of the 2011 IEEE 5th International Symposium on Theoretical Aspects of Software Engineering (TASE 2011), P169, DOI 10.1109/TASE.2011.8
   Lopez-Arredondo LP, 2019, BUSINESS PROCESS MAN
   Maqbool B, 2019, LECT NOTES ELECTR EN, V514, P543, DOI 10.1007/978-981-13-1056-0_54
   Miers D, 2008, BPMN MODELING REFERE, V4
   Moody D.L., 2003, ECIS 2003 P, P79
   Object Management Group, MOF 2 0 QUER VIEWS T
   Object Management Group, BUS PROC MOD NOT
   Ouyang C, 2009, ACM T SOFTW ENG METH, V19, DOI 10.1145/1555392.1555395
   Pintus A, 2010, WEBIST 2010: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS AND TECHNOLOGY, VOL 2, P175
   Polancic G, 2019, COMPUT STAND INTER, V65, P45, DOI 10.1016/j.csi.2019.02.001
   Radeke F, 2007, LECT NOTES COMPUT SC, V4849, P184
   Ramadan Q, 2020, SOFTW SYST MODEL, V19, P1191, DOI 10.1007/s10270-020-00781-x
   Rieger C, 2018, PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), P5725
   Rieger D, 2018, PERMANENTLY ONLINE, PERMANENTLY CONNECTED: LIVING AND COMMUNICATING IN A POPC WORLD, P149
   Ruiz J, 2019, SOFTW SYST MODEL, V18, P2753, DOI 10.1007/s10270-018-0698-x
   Rusu C, 2018, LECT NOTES COMPUT SC, V10913, P121, DOI 10.1007/978-3-319-91521-0_10
   Shamim A, 2016, BEHAV INFORM TECHNOL, V35, P680, DOI 10.1080/0144929X.2016.1141235
   Sousa K, 2011, BUS PROCESS MANAG J, V17, P748, DOI 10.1108/14637151111166178
   Sousa K, 2010, LECT NOTES COMPUT SC, V5963, P1, DOI 10.1007/978-3-642-11797-8_1
   Sousa K, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P553
   Torres V, 2006, LECT NOTES COMPUT SC, V4102, P322
   Trætteberg H, 2008, LECT NOTES COMPUT SC, V5247, P110, DOI 10.1007/978-3-540-85992-5_9
   Welie M., 2000, 2000 PATT LANG PROGR, P13
   WHITEFIELD A, 1991, BEHAV INFORM TECHNOL, V10, P65, DOI 10.1080/01449299108924272
   YADAV SB, 1988, COMMUN ACM, V31, P1090, DOI 10.1145/48529.48533
   Yongchareon S, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5646
   Yongchareon S, 2018, COMPUT IND, V96, P66, DOI 10.1016/j.compind.2017.11.001
   Yongchareon S, 2010, LECT NOTES COMPUT SC, V6488, P419, DOI 10.1007/978-3-642-17616-6_38
   Zafar I, 2019, IEEE ACCESS, V7, P93653, DOI 10.1109/ACCESS.2019.2927785
   Zhang Q, 2006, PROC IEEE INT CONF S, P428
   Zhao X, 2007, BUSINESS PROCESS DRI
NR 72
TC 3
Z9 3
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 9813
EP 9848
DI 10.1007/s11042-020-09651-6
EA NOV 2020
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000589499300002
DA 2024-07-18
ER

PT J
AU Dhar, D
   Garain, A
   Singh, PK
   Sarkar, R
AF Dhar, Dibyajyoti
   Garain, Avishek
   Singh, Pawan Kumar
   Sarkar, Ram
TI HP_DocPres: a method for classifying printed and handwritten texts in
   doctor's prescription
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HP_DocPres; Printed text; Handwritten text; OCR; Doctor&#8217; s
   prescriptions; Shape-based features; GUI
ID IDENTIFICATION
AB Optical Character Recognition (OCR) system is used to convert the document images, either printed or handwritten, into its electronic counterpart. But dealing with handwritten texts is much more challenging than printed ones due to the erratic writing style of the individuals. The problem becomes more severe when the input image is a doctor's prescription. Before feeding such an image to the OCR engine, the classification of printed and handwritten texts is a necessity as a doctor's prescription contains both handwritten and printed texts which are to be processed separately. Much work has been done in the domain of handwritten and printed text separation albeit work related to doctor's handwriting. In this paper, a method is proposed which first localizes the position of texts in a doctor's prescription, and then separates out the printed texts from the handwritten ones. Due to the unavailability of a large database, we have used some standard data (image) augmentation techniques to evaluate as well as to prove the robustness of our method. Besides, we have also designed a Graphical User Interface (GUI) so that anybody can visualize the output by providing a prescription image as input.
C1 [Dhar, Dibyajyoti; Garain, Avishek; Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
   [Singh, Pawan Kumar] Jadavpur Univ, Dept Informat Technol, Kolkata 700106, India.
C3 Jadavpur University; Jadavpur University
RP Singh, PK (corresponding author), Jadavpur Univ, Dept Informat Technol, Kolkata 700106, India.
EM dibyajyotidhar@gmail.com; avishekgarain@gmail.com;
   pawansingh.ju@gmail.com; ramjucse@gmail.com
RI Sarkar, Ram/AAX-3822-2020; Garain, Avishek/AAV-3835-2020; SINGH, PAWAN
   KUMAR/E-3408-2013
OI Sarkar, Ram/0000-0001-8813-4086; Garain, Avishek/0000-0001-6225-3343;
   SINGH, PAWAN KUMAR/0000-0002-9598-7981
CR Alard C, 2000, ASTRON ASTROPHYS SUP, V144, P363, DOI 10.1051/aas:2000214
   Aman K.S., 2011, Inter. Jour. of Comp. Sci. and Eng, P1890
   [Anonymous], 2020, LOOKUP TABLE
   [Anonymous], 2013, ARXIV13033087
   Banerjee S, 2013, ADV INTELL SYST, V177, P823
   Becker BG, 1998, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION - PROCEEDINGS, P102, DOI 10.1109/INFVIS.1998.729565
   Berwick DM, 1996, BRIT MED J, V313, P1657, DOI 10.1136/bmj.313.7072.1657
   Bhattacharya R, 2021, MULTIMED TOOLS APPL, V80, P3529, DOI 10.1007/s11042-020-09751-3
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chang SI, 2010, PME CONFERENCE PROCE, P18, DOI 10.1145/1774088.1774093
   Core RS, RANDOM TREE RAPIDMIN
   Dhar Dibyajyoti, 2020, International Journal of Computer Vision and Image Processing, V10, P1, DOI 10.4018/IJCVIP.2020070103
   Dutly N, 2019, PROC INT CONF DOC, P20, DOI 10.1109/ICDARW.2019.10033
   Garain A, 2020, DATASET CLASSIFICATI, DOI [10.21227/5zbc-8g23, DOI 10.21227/5ZBC-8G23]
   Garlapati BM, 2017, UKSIM INT CONF COMP, P50, DOI 10.1109/UKSim.2017.37
   Ghosh S, 2018, WORKSH DOC AN REC, P27
   Hamerly GEC, 2003, ADV NEURAL INF PROCE
   HARALICK RM, 1995, GRAPH MODEL IM PROC, V57, P1, DOI 10.1006/gmip.1995.1001
   Herf M, 2005, US Patent, Patent No. [6,925,210, 6925210]
   Jawas N, 2013, IMAGE INPAINTING USI
   Jindal A, 2014, IEEE INT ADV COMPUT, P1028, DOI 10.1109/IAdCC.2014.6779466
   Lim K. H. J., 1999, SMJ, V40, P416
   Malakar S, 2013, PROC TECH, V10, P831, DOI 10.1016/j.protcy.2013.12.428
   MANDELBROT BB, 1971, WATER RESOUR RES, V7, P543, DOI 10.1029/WR007i003p00543
   Moghaddam RF, 2012, PATTERN RECOGN, V45, P2419, DOI 10.1016/j.patcog.2011.12.013
   Peng X., 2010, Proceedings of the International Workshop on Document Analysis Systems, P129
   Peng XJ, 2013, INT J DOC ANAL RECOG, V16, P1, DOI 10.1007/s10032-011-0179-z
   Singh PK, 2016, INT J COMPUT SCI MAT, V7, P410, DOI 10.1504/IJCSM.2016.080073
   Singh PK, 2015, INT J APPL PATTERN R, V2, P1, DOI 10.1504/IJAPR.2015.068929
   Sudhakar S., 2017, Histogram equalization
   Van Rossum G., 2009, Python 3 Reference Manual
   Zheng YF, 2004, IEEE T PATTERN ANAL, V26, P337, DOI 10.1109/TPAMI.2004.1262324
NR 32
TC 3
Z9 3
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 9779
EP 9812
DI 10.1007/s11042-020-10151-w
EA NOV 2020
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000588867700001
DA 2024-07-18
ER

PT J
AU Bhowmik, S
   Kundu, S
   Sarkar, R
AF Bhowmik, Showmik
   Kundu, Soumyadeep
   Sarkar, Ram
TI BINYAS: a complex document layout analysis system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Document layout analysis; BINYAS; Text non-text separation; Non-text
   classification; Inverted text; RDCL
ID PAGE SEGMENTATION; ALGORITHM; TEXT
AB Document layout analysis (DLA) is an irreplaceable pre-requisite for the development of a comprehensive document image processing and analysis system. The main purpose of DLA is to segment an input document image into its constituent and coherent regions and identify their classes. In this paper, we propose a competent DLA system, named as BINYAS, based on the connected component (CC) and pixel analysis based approach. Here, we initially identify the regions and then classify these regions as paragraph, separator, graphic, image, table, chart, and inverted text etc. The proposed system is evaluated on four publicly available standard datasets, namely ICDAR 2009, 2015, 2017 and 2019 page segmentation competition datasets, and the performance is compared with many contemporary methods, which also include some well-known software products and deep learning based methods. Experimental results show that our method performs significantly better than state-of-the-art methods in terms of the evaluation metrics considered by the research community of this domain.
C1 [Bhowmik, Showmik] Ghani Khan Choudhury Inst Engn & Technol, Dept Comp Sci & Engn, Malda, India.
   [Kundu, Soumyadeep; Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
C3 Jadavpur University
RP Bhowmik, S (corresponding author), Ghani Khan Choudhury Inst Engn & Technol, Dept Comp Sci & Engn, Malda, India.
EM showmik.cse@gmail.com; soumyadeep1497@gmail.com; ramjucse@gmail.com
RI Sarkar, Ram/AAX-3822-2020; Bhowmik, Showmik/M-4248-2017
OI Sarkar, Ram/0000-0001-8813-4086; Bhowmik, Showmik/0000-0003-3971-5807
CR Acharyya M., 2001, Computer Analysis of Images and Patterns. 9th International Conference, CAIP 2001. Proceedings (Lecture Notes in Computer Science Vol.2124), P510
   [Anonymous], 2015, FINEREADER ENG 11
   [Anonymous], FINEREADER ENG 12
   [Anonymous], FINEREADER ENG 10
   Antonacopoulos A, 2015, PROC INT CONF DOC, P1151, DOI 10.1109/ICDAR.2015.7333941
   Antonacopoulos A, 2013, PROC INT CONF DOC, P1454, DOI 10.1109/ICDAR.2013.293
   Antonacopoulos A., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1370, DOI 10.1109/ICDAR.2009.275
   ANTONACOPOULOS A, 1994, INT C PATT RECOG, P339, DOI 10.1109/ICPR.1994.576932
   Bhowmik S, 2019, IEEE T IMAGE PROCESS, V28, P1443, DOI 10.1109/TIP.2018.2878959
   Bhowmik S, 2018, INT J DOC ANAL RECOG, V21, P1, DOI 10.1007/s10032-018-0296-z
   Binmakhashen G.M., 2019, ACM COMPUT SURV, V52, P1
   Bloomberg D. S., 1991, P INT C DOC AN REC S
   Bukhari S.S., 2010, P 9 IAPR INT WORKSH, P183, DOI [DOI 10.1145/1815330.1815354, 10.1145/1815330.1815354]
   Bukhari S. S., 2011, IS T SPIE ELECT IMAG
   Chen K, 2013, PROC INT CONF DOC, P958, DOI 10.1109/ICDAR.2013.194
   Clausner Christian, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1521, DOI 10.1109/ICDAR.2019.00245
   Clausner C, 2017, PROC INT CONF DOC, P1404, DOI 10.1109/ICDAR.2017.229
   Clausner C, 2011, PROC INT CONF DOC, P1404, DOI 10.1109/ICDAR.2011.282
   Eskenazi S, 2017, PATTERN RECOGN, V64, P1, DOI 10.1016/j.patcog.2016.10.023
   Dai-Ton H, 2016, PATTERN RECOGN LETT, V80, P137, DOI 10.1016/j.patrec.2016.06.011
   Kaur RP, 2020, VISUAL COMPUT, P1
   Kise K, 1998, COMPUT VIS IMAGE UND, V70, P370, DOI 10.1006/cviu.1998.0684
   Kise K., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P788, DOI 10.1109/ICPR.1996.547276
   Kise K., 2014, HDB DOCUMENT IMAGE P, P135, DOI DOI 10.1007/978-0-85729-859-1_5
   Lin M., 2006, Journal of South African Computer, V36, P49
   NAGY G, 1992, COMPUTER, V25, P10, DOI 10.1109/2.144436
   Nestor T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010083
   Normand N., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P138, DOI 10.1109/ICDAR.1995.598961
   Olszewska JI, 2015, NEUROCOMPUTING, V161, P65, DOI 10.1016/j.neucom.2014.12.089
   Oyedotun OK, 2016, APPL INTELL, V45, P198, DOI 10.1007/s10489-015-0753-z
   PAVLIDIS T, 1992, CVGIP-GRAPH MODEL IM, V54, P484, DOI 10.1016/1049-9652(92)90068-9
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Shih FY, 1996, IEEE T SYST MAN CY B, V26, P797, DOI 10.1109/3477.537322
   Smith Raymond W., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P241, DOI 10.1109/ICDAR.2009.257
   Smith R, 2013, PROC SPIE, V8658, DOI 10.1117/12.2010051
   Sun HM, 2005, PROC INT CONF DOC, P116
   Tran TA, 2017, EXPERT SYSTEMS APPL
   Tran TA, 2016, INT J DOC ANAL RECOG, V19, P191, DOI 10.1007/s10032-016-0265-3
   Tran TA, 2015, KSII T INTERNET INF, V9, P4072, DOI 10.3837/tiis.2015.10.017
   Vasilopoulos N, 2017, ENG APPL ARTIF INTEL, V65, P220, DOI 10.1016/j.engappai.2017.08.002
   Vasilopoulos N, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013009
   Le VP, 2015, PROC INT CONF DOC, P1096, DOI 10.1109/ICDAR.2015.7333930
   Zagoris K, 2011, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2011-47
   ZLATOPOLSKY AA, 1994, PATTERN RECOGN LETT, V15, P699, DOI 10.1016/0167-8655(94)90074-4
NR 44
TC 12
Z9 12
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8471
EP 8504
DI 10.1007/s11042-020-09832-3
EA NOV 2020
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587038500001
DA 2024-07-18
ER

PT J
AU Bousnina, N
   Zheng, LL
   Mikram, M
   Ghouzali, S
   Minaoui, K
AF Bousnina, Naima
   Zheng, Lilei
   Mikram, Mounia
   Ghouzali, Sanaa
   Minaoui, Khalid
TI Unraveling robustness of deep face anti-spoofing models against pixel
   attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face liveness detection; Spoofing attacks; Convolutional neural
   networks; Differential evolution; Deep learning
AB In the last few decades, deep-learning-based face verification and recognition systems have had enormous success in solving complex security problems. However, it has been recently shown that such efficient frameworks are vulnerable to face-spoofing attacks, which has led researchers to build proficient anti-facial-spoofing (or liveness detection) models as an additional security layer. In response, increasingly challenging and tricky attacks have been launched to fool these anti-spoofing mechanisms. In this context, this paper presents the results of an analytical study on transfer-learning-based convolutional neural networks (CNNs) for face liveness detection and differential evolution-based adversarial attacks to evaluate the efficiency of face anti-spoofing classifiers against adversarial attacks. Specifically, experiments were conducted under different use-case scenarios on four face anti-spoofing databases to highlight practical criteria that can be used in the development of countermeasures to address face-spoofing issues.
C1 [Bousnina, Naima; Minaoui, Khalid] Mohammed V Univ Morocco, Fac Sci Rabat, IT Ctr, LRIT CNRST URAC 29, Rabat, Morocco.
   [Zheng, Lilei] Shopee Singapore, Data Sci, Image Proc Team, Singapore, Singapore.
   [Mikram, Mounia] Sch Informat Sci, LYRICA Lab, Meridian Team, Rabat, Morocco.
   [Ghouzali, Sanaa] King Saud Univ Riyadh, Coll Comp & Informat Sci, Informat Technol Dept, Riyadh, Saudi Arabia.
C3 Mohammed V University in Rabat; Centre National de la Recherche
   Scientifique & Technologique (CNRST); King Saud University
RP Bousnina, N (corresponding author), Mohammed V Univ Morocco, Fac Sci Rabat, IT Ctr, LRIT CNRST URAC 29, Rabat, Morocco.
EM naimabousnina2@gmail.com; lilei.zheng@shopee.com;
   mikrammounia@gmail.com; sghouzali@ksu.edu.sa; kminaoui@gmail.com
RI Ghouzali, Sanaa/J-3682-2013
OI Ghouzali, Sanaa/0000-0001-9381-4246; khalid, Minaoui/0000-0002-3918-8552
CR [Anonymous], 2016, ISO/IEC 30107-1
   Atoum Y, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P319, DOI 10.1109/BTAS.2017.8272713
   Bose AJ, 2018, IEEE INT WORKSH MULT
   Boulkenafet Z, 2017, IEEE INT CONF AUTOMA, P612, DOI 10.1109/FG.2017.77
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Chen Xinyun, 2017, ARXIV171205526
   Chingovska I, 2013, INT CONF BIOMETR
   Chingovska I., 2012, 2012 BIOSIG P INT C, P1
   de Souza GB, 2018, SIBGRAPI, P258, DOI 10.1109/SIBGRAPI.2018.00040
   Dong YP, 2018, PROC CVPR IEEE, P9185, DOI 10.1109/CVPR.2018.00957
   Erdogmus N, 2013, 2013 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS)
   Feng LT, 2016, J VIS COMMUN IMAGE R, V38, P451, DOI 10.1016/j.jvcir.2016.03.019
   Fourati E, 2020, MULTIMED TOOLS APPL, V79, P865, DOI 10.1007/s11042-019-08115-w
   Gan JY, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP), P1, DOI 10.1109/ICMIP.2017.9
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Goswami G, 2019, INT J COMPUT VISION, V127, P719, DOI 10.1007/s11263-019-01160-w
   Hadid A., 2016, IPTA, P1
   Hadid A, 2014, IEEE COMPUT SOC CONF, P113, DOI 10.1109/CVPRW.2014.22
   Hu W, 2018, ARXIV181111594
   IJCB, 2017, COMP GEN PRES ATT DE
   Jiawei Su, 2019, IPSJ Transactions on Computer Vision and Applications, V11, DOI 10.1186/s41074-019-0053-3
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Jourabloo A, 2018, LECT NOTES COMPUT SC, V11217, P297, DOI 10.1007/978-3-030-01261-8_18
   Komulainen J, 2015, THESIS
   Kose N, 2013, INT CONF ACOUST SPEE, P2357, DOI 10.1109/ICASSP.2013.6638076
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kurakin Alexey, 2017, INT C LEARN REPR
   Li HL, 2018, IEEE T INF FOREN SEC, V13, P1794, DOI 10.1109/TIFS.2018.2801312
   Li L, 2018, IET BIOMETRICS, V7, P3, DOI 10.1049/iet-bmt.2017.0089
   Liu Y., ARXIV, V2019
   Liu YJ, 2019, PROC CVPR IEEE, P4675, DOI 10.1109/CVPR.2019.00481
   Liu YJ, 2018, PROC CVPR IEEE, P389, DOI 10.1109/CVPR.2018.00048
   Lucena O, 2017, LECT NOTES COMPUT SC, V10317, P27, DOI 10.1007/978-3-319-59876-5_4
   Moosavi-Dezfooli SM, 2017, PROC CVPR IEEE, P86, DOI 10.1109/CVPR.2017.17
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Nagpal C., 2019, 2019 International Joint Conference on Neural Networks (IJCNN), P1
   Nguyen MD, 2009, BLACK HAT DC
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Patel K, 2016, LECT NOTES COMPUT SC, V9967, P611, DOI 10.1007/978-3-319-46654-5_67
   Patel K, 2016, IEEE T INF FOREN SEC, V11, P2268, DOI 10.1109/TIFS.2016.2578288
   Peng F, 2018, MULTIMED TOOLS APPL, V77, P8883, DOI 10.1007/s11042-017-4780-0
   Rehman YAU, 2019, J VIS COMMUN IMAGE R, V59, P574, DOI 10.1016/j.jvcir.2019.02.014
   Saon G, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3140
   Sharif M, 2019, ACM T PRIV SECUR, V22, DOI 10.1145/3317611
   Sharif M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1528, DOI 10.1145/2976749.2978392
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song Q., 2018, ABS181112026 CORR
   Souza L, 2018, ENG APPL ARTIF INTEL, V72, P368, DOI 10.1016/j.engappai.2018.04.013
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Su JW, 2019, IEEE T EVOLUT COMPUT, V23, P828, DOI 10.1109/TEVC.2019.2890858
   Szegedy C, 2014, ARXIV13126199 ICLR
   Tu XG, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.4.043001
   Tu Xiaoguang, 2019, ARXIV190105635
   Wang Z, 2019, ARXIV181105118V3
   Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395
   Yang J, 2014, ADV MATER RES-SWITZ, V850-851, P373, DOI 10.4028/www.scientific.net/AMR.850-851.373
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
   Zhou Zhe, 2018, ARXIV180304683
   Zhu F., 2019, IEEE ICC, P1, DOI DOI 10.1109/icc.2019.8761825
NR 60
TC 8
Z9 8
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7229
EP 7246
DI 10.1007/s11042-020-10041-1
EA OCT 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000584568200004
DA 2024-07-18
ER

PT J
AU Takács, P
   Kovács, L
   Manno-Kovacs, A
AF Takacs, Petra
   Kovacs, Levente
   Manno-Kovacs, Andrea
TI A fusion of salient and convolutional features applying healthy
   templates for MRI brain tumor segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual saliency; Medical image segmentation; Brain tumor detection;
   Convolutional neural networks
ID FRAMEWORK; REGISTRATION; CRF
AB This paper proposes an improved brain tumor segmentation method based on visual saliency features on MRI image volumes. The proposed method introduces a novel combination of multiple MRI modalities used as pseudo-color channels for highlighting the potential tumors. The novel pseudo-color model incorporates healthy templates generated from the MRI slices without tumors. The constructed healthy templates are also used during the training of neural network models. Based on a saliency map built using the pseudo-color templates, combination models are proposed, fusing the saliency map with convolutional neural networks' prediction maps to improve predictions and to reduce the networks' eventual overfitting which may result in weaker predictions for previously unseen cases. By introducing the combination technique for deep learning techniques and saliency-based, handcrafted feature models, the fusion approach shows good abstraction capabilities and it is able to handle diverse cases that the networks were less trained for. The proposed methods were tested on the BRATS2015 and BRATS2018 databases, and the quantitative results show that hybrid models (including both trained and handcrafted features) can be promising alternatives for reaching higher segmentation performance. Moreover, healthy templates can provide additional information for the training process, enhancing the prediction performance of neural network models.
C1 [Takacs, Petra; Kovacs, Levente; Manno-Kovacs, Andrea] Inst Comp Sci & Control SZTAKI, Budapest, Hungary.
   [Takacs, Petra; Manno-Kovacs, Andrea] Pazmany Peter Catholic Univ, Fac Informat Technol & Bion, Budapest, Hungary.
C3 Hungarian Academy of Sciences; Hungarian Research Network; HUN-REN
   Institute for Computer Science & Control; Pazmany Peter Catholic
   University
RP Manno-Kovacs, A (corresponding author), Inst Comp Sci & Control SZTAKI, Budapest, Hungary.; Manno-Kovacs, A (corresponding author), Pazmany Peter Catholic Univ, Fac Informat Technol & Bion, Budapest, Hungary.
EM takacs.petra@sztaki.hu; levente.kovacs@sztaki.hu;
   andrea.manno-kovacs@sztaki.hu
OI Manno-Kovacs, Andrea/0000-0002-9392-379X
FU Hungarian National Research, Development and Innovation Fund (NKFIA)
   [KH-126688]; Hungarian Government, Ministry for National Economy (NGM)
   [GINOP-2.2.1-15-2017-00083]; Janos Bolyai Research Scholarship of the
   Hungarian Academy of Sciences; Hungarian Government, Ministry of Human
   Capacities in the New National Excellence Program [uNKP-18-4-PPKE-132]
FX This work was partially funded by the Hungarian National Research,
   Development and Innovation Fund (NKFIA) grant nr. KH-126688 and the
   Hungarian Government, Ministry for National Economy (NGM), grant nr.
   GINOP-2.2.1-15-2017-00083. This paper was supported by the Janos Bolyai
   Research Scholarship of the Hungarian Academy of Sciences and by the
   Hungarian Government, Ministry of Human Capacities in the New National
   Excellence Program under grant nr. uNKP-18-4-PPKE-132.
CR [Anonymous], 2015, P MICCAI BRATS
   Bakas S, 2015, P MULT BRAIN TUM IM, P5
   Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117
   Banerjee S, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146388
   Bauer S, 2011, LECT NOTES COMPUT SC, V6893, P354, DOI 10.1007/978-3-642-23626-6_44
   Gibson E, 2018, COMPUT METH PROG BIO, V158, P113, DOI 10.1016/j.cmpb.2018.01.025
   Holland EC, 2001, CURR OPIN NEUROL, V14, P683, DOI 10.1097/00019052-200112000-00002
   Isensee Fabian, 2018, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. Third International Workshop, BrainLes 2017. Held in Conjunction with MICCAI 2017. Revised Selected Papers: LNCS 10670, P287, DOI 10.1007/978-3-319-75238-9_25
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Kayalibay B., 2017, Cnn-based segmentation of medical imaging data
   Kirby J., 2017, CANC IMAGING ARCH, V286, DOI [DOI 10.7937/K9/TCIA.2017.GJQ7R0EF, 10.1038/sdata.2017.117, DOI 10.1038/SDATA.2017.117]
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Mattes D, 2003, IEEE T MED IMAGING, V22, P120, DOI 10.1109/TMI.2003.809072
   Mehmood I, 2019, MULTIMED TOOLS APPL, V78, P12723, DOI 10.1007/s11042-018-6027-0
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Mohammadreza S., 2017, INT MICCAI BRAINL WO, P279
   Pereira Sergio, 2016, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. First International Workshop, Brainles 2015, held in conjunction with MICCAI 2015. Revised Selected Papers: LNCS 9556, P131, DOI 10.1007/978-3-319-30858-6_12
   Prastawa M, 2004, MED IMAGE ANAL, V8, P275, DOI 10.1016/j.media.2004.06.007
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shaikh M, 2018, LECT NOTES COMPUT SC, V10670, P309, DOI 10.1007/978-3-319-75238-9_27
   Takacs P, 2018, P INT WORKSH CONT BA, P1, DOI DOI 10.1109/CBMI.2018.8516544
   Villanueva-Meyer JE, 2017, NEUROSURGERY, V81, P397, DOI 10.1093/neuros/nyx103
   Virupakshappa, 2020, MULTIMED TOOLS APPL, V79, P3571, DOI 10.1007/s11042-018-6176-1
   Wang GT, 2018, LECT NOTES COMPUT SC, V10670, P178, DOI 10.1007/978-3-319-75238-9_16
   Wu W, 2014, INT J COMPUT ASS RAD, V9, P241, DOI 10.1007/s11548-013-0922-7
   Zacharaki EI, 2008, IEEE T MED IMAGING, V27, P1003, DOI 10.1109/TMI.2008.916954
NR 27
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22533
EP 22550
DI 10.1007/s11042-020-09871-w
EA OCT 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000582095600001
OA hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Ojeda-Castelo, JJ
   Piedra-Fernandez, JA
   Iribarne, L
AF Ojeda-Castelo, Juan Jesus
   Piedra-Fernandez, Jose A.
   Iribarne, Luis
TI A device-interaction model for users with special needs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural interaction; Adaptation; User model
ID E-LEARNING ENVIRONMENT; SERIOUS GAMES; INTELLIGENT; INTEGRATION;
   STUDENTS; DESIGN; REHABILITATION; IMPLEMENTATION; CONSTRUCTION;
   DISABILITIES
AB Interaction is a fundamental part of using any computer system but it is still an issue for people with special needs. In order to improve this situation, this paper describes a new device-interaction model based on adaptation rules for user models. The aim is the adaptation at the interaction level, taking into account the interaction device features in order to improve the usability through the user experience in the education sector. In the evaluation process, several students from a special education center have participated. These students have either a physical or sensory disability or autism. The results are promising enough to consider that this model will be able to help students with disabilities to interact with a computer system which will inevitably provide tremendous benefits to their academic and personal development.
C1 [Ojeda-Castelo, Juan Jesus; Piedra-Fernandez, Jose A.; Iribarne, Luis] Univ Almeria, Dept Informat, Appl Comp Grp, Almeria, Spain.
C3 Universidad de Almeria
RP Ojeda-Castelo, JJ (corresponding author), Univ Almeria, Dept Informat, Appl Comp Grp, Almeria, Spain.
EM juanje.ojeda@ual.es
RI Iribarne, Luis/A-2811-2008; Piedra-Fernandez, Jose/C-3284-2019
OI Iribarne, Luis/0000-0003-1815-4721; Ojeda-Castelo, Juan
   Jesus/0000-0001-6842-8159; Piedra-Fernandez, Jose/0000-0002-8845-8547
FU EU ERDF; Spanish Ministry of Economy and Competitiveness (MINECO)
   [TIN2017-83964-R]
FX This work was supported by the EU ERDF and the Spanish Ministry of
   Economy and Competitiveness (MINECO) under Project TIN2017-83964-R. We
   would also like to thank Dr. Ana Garcia Serrano because of her
   collaboration in this study. We also want to thank to ARASAAC
   (http://arasaac.org) for allowing us to use Sergio Palao's pictograms
   which belongs to the Aragon government.
CR Afyouni I, 2017, USER MODEL USER-ADAP, V27, P215, DOI 10.1007/s11257-017-9191-4
   Alquraini T, 2012, INT J SPEC EDUC, V27, P42
   Altanis G, 2013, INTERACT DES ARCHIT, P91
   [Anonymous], 2013, COMPUTER
   Avila-Pesantez D, 2018, INT CONF EDEMOC EGOV, P286, DOI 10.1109/ICEDEG.2018.8372351
   Backlund P., 2013, P 2013 5 INT C GAM V, P1, DOI [DOI 10.1109/VSGAMES.2013.6624226, DOI 10.1109/VS-GAMES.2013.6624226]
   Bartoli L., 2013, ACM INT C PROCEEDING, P102, DOI [DOI 10.1145/2485760.2485774, 10.1145/2485760.2485774]
   Blumberg F. C., 2013, The Oxford Handbook of Media Psychology, P334, DOI [10.1093/oxfordhb/9780195398809.013.0019, DOI 10.1093/OXFORDHB/9780195398809.013.0019]
   Brown DJ, 2011, COMPUT EDUC, V56, P11, DOI 10.1016/j.compedu.2010.04.014
   Brusilovsky P., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P3, DOI 10.1007/978-3-540-72079-9_1
   Cai S, 2018, INTERACT LEARN ENVIR, V26, P1039, DOI 10.1080/10494820.2018.1437048
   Cieza A, 2008, EUR J PHYS REHAB MED, V44, P303
   Cinquin PA, 2020, BEHAV INF TECHNOL, P1
   Connolly TM, 2012, COMPUT EDUC, V59, P661, DOI 10.1016/j.compedu.2012.03.004
   De Bra P, 1999, ACM COMPUT SURV, V31, pU58
   De Gloria A, 2014, INT J SERIOUS GAMES, V1, DOI 10.17083/ijsg.v1i1.11
   Desmarais MC, 2012, USER MODEL USER-ADAP, V22, P9, DOI 10.1007/s11257-011-9106-8
   Dhouib A, 2016, C HUM SYST INTERACT, P246, DOI 10.1109/HSI.2016.7529639
   Dias P, 2019, IEEE COMPUT GRAPH, V39, P64, DOI 10.1109/MCG.2018.2875630
   DIN E, 1996, 924110 DIN E
   Dolenc K, 2015, COMPUT EDUC, V82, P354, DOI 10.1016/j.compedu.2014.12.010
   Labib AE, 2017, COMPUT HUM BEHAV, V73, P433, DOI 10.1016/j.chb.2017.03.054
   Faisal N, 2016, ASIAN J ENG SCI TECH
   Fernández-López A, 2013, COMPUT EDUC, V61, P77, DOI 10.1016/j.compedu.2012.09.014
   Ferrero M, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0183618
   Girard C, 2013, J COMPUT ASSIST LEAR, V29, P207, DOI 10.1111/j.1365-2729.2012.00489.x
   Granollers T, 2006, HCI RELATED PAPERS OF INTERACCION 2004, P243, DOI 10.1007/1-4020-4205-1_20
   Guillén-Nieto V, 2012, COMPUT EDUC, V58, P435, DOI 10.1016/j.compedu.2011.07.015
   HALASZ F, 1994, COMMUN ACM, V37, P30, DOI 10.1145/175235.175237
   Hocine N, 2015, USER MODEL USER-ADAP, V25, P65, DOI 10.1007/s11257-015-9154-6
   Hsiao HS, 2016, COMPUT EDUC, V95, P151, DOI 10.1016/j.compedu.2016.01.005
   Katona J, 2014, 2014 IEEE 12TH INTERNATIONAL SYMPOSIUM ON APPLIED MACHINE INTELLIGENCE AND INFORMATICS (SAMI), P91, DOI 10.1109/SAMI.2014.6822382
   Khenissi MA., 2015, SMART LEARNING ENV, V2, P1, DOI DOI 10.1186/S40561-015-0014-Y
   Kourakli Maria, 2017, International Journal of Child-Computer Interaction, V11, P28, DOI 10.1016/j.ijcci.2016.10.009
   Kushniruk AW, 2015, STUD HEALTH TECHNOL, V208, P221, DOI 10.3233/978-1-61499-488-6-221
   Laamarti F, 2014, INT J COMPUT GAMES T, V2014, DOI 10.1155/2014/358152
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   Lei Shi, 2013, Artificial Intelligence in Education. Proceedings of 16th International Conference (AIED 2013): LNCS 7926, P708, DOI 10.1007/978-3-642-39112-5_94
   Lei Shi, 2013, User Modeling, Adaptation, and Personalization. 21th International Conference, UMAP 2013. Proceedings., P338, DOI 10.1007/978-3-642-38844-6_32
   Lewis C., 1997, HDB HUMAN COMPUTER I, P717, DOI DOI 10.1016/B978-044481862-1.50096-0
   Lozano MD, 2018, P 32 INT BCS HUM COM, V32, P1
   Özyurt H, 2012, EXPERT SYST APPL, V39, P9837, DOI 10.1016/j.eswa.2012.02.168
   Özyurt Ö, 2014, COMPUT EDUC, V75, P1, DOI 10.1016/j.compedu.2014.02.005
   Özyurt Ö, 2013, COMPUT HUM BEHAV, V29, P726, DOI 10.1016/j.chb.2012.11.013
   Özyurt Ö, 2013, EXPERT SYST APPL, V40, P2914, DOI 10.1016/j.eswa.2012.12.008
   Patern`o F., 2015, P 7 ACM SIGCHI S ENG, V15, P158
   Pellerin M., 2013, CAN J EDUC, V36
   Pourabdollahian B, 2012, PROCEDIA COMPUT SCI, V15, P256, DOI 10.1016/j.procs.2012.10.077
   Premlatha KR, 2015, ARTIF INTELL REV, V44, P443, DOI 10.1007/s10462-015-9432-z
   Puspitasari W, 2013, IN C IND ENG ENG MAN, P1097, DOI 10.1109/IEEM.2013.6962580
   Schrepp M., 2014, Design, User Experience, and Usability. Theories, Methods, and Tools for Designing the User Experience, P383, DOI [DOI 10.1007/978-3-319-07668-3_37, 10.9781/ijimai.2017.445, DOI 10.9781/IJIMAI.2017.445, DOI 10.1007/978-3-319-07668-337]
   Schrepp M, 2017, INT J INTERACT MULTI, V4, P103, DOI 10.9781/ijimai.2017.09.001
   Schrepp M, 2017, INT J INTERACT MULTI, V4, P40, DOI 10.9781/ijimai.2017.445
   Shi L, 2013, IEEE INT CONF ADV LE, P294, DOI 10.1109/ICALT.2013.92
   Young MF, 2012, REV EDUC RES, V82, P61, DOI 10.3102/0034654312436980
   Ypsilanti A, 2014, EDUC INF TECHNOL, V19, P515, DOI 10.1007/s10639-014-9325-9
   Zaini N. A., 2019, EVALUATION, V10
   Zarraonandia T, 2018, INT C GAM LEARN ALL, P297
NR 58
TC 3
Z9 3
U1 4
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 6675
EP 6710
DI 10.1007/s11042-020-10026-0
EA OCT 2020
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000582172600001
DA 2024-07-18
ER

PT J
AU Yuan, MN
   Li, XF
   Xu, JL
   Jia, CC
   Li, XR
AF Yuan, Munan
   Li, Xiaofeng
   Xu, Jinlin
   Jia, Chaochuan
   Li, Xiru
TI 3D foot scanning using multiple RealSense cameras
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D scanning; Calibration; Reconstruction; RealSense
ID RECONSTRUCTION; KINEMATICS; SYSTEM; TIME; MAP
AB 3D scanning of the foot is of great significance for footwear customization, intelligent shoe size recommendation and foot disease diagnosis. In this paper, we propose a 3D foot scanning system that consists of four Intel RealSense cameras and one host PC and scans both feet simultaneously. A novel calibration method that is based on a Tower-type block was proposed for calculating the extrinsic parameters of multiple RGB-Depth cameras. The Tower-type block was designed to realize the automatic execution of the multi-camera calibration process and reduce the operational complexity. This paper introduced the complete procedure of the system, including partial view scanning, point cloud filtering, registration, and non-visible area filling, reconstruction and foot measurement. The presented experimental results demonstrated that the proposed methods were efficient and versatile approaches for 3D foot scanning.
C1 [Yuan, Munan; Li, Xiaofeng; Xu, Jinlin; Li, Xiru] Chinese Acad Sci, Anhui Inst Opt & Fine Mech, Hefei 230031, Peoples R China.
   [Yuan, Munan; Li, Xiaofeng; Xu, Jinlin; Li, Xiru] Univ Sci & Technol China, Hefei 230026, Peoples R China.
   [Jia, Chaochuan] Shandong Univ Sci & Technol, Qingdao 266590, Peoples R China.
C3 Chinese Academy of Sciences; Hefei Institutes of Physical Science, CAS;
   Anhui Institute of Optics & Fine Mechanics (AIOFM), CAS; Chinese Academy
   of Sciences; University of Science & Technology of China, CAS; Shandong
   University of Science & Technology
RP Yuan, MN (corresponding author), Chinese Acad Sci, Anhui Inst Opt & Fine Mech, Hefei 230031, Peoples R China.; Yuan, MN (corresponding author), Univ Sci & Technol China, Hefei 230026, Peoples R China.
EM mnyuan@hfcas.ac.cn
RI li, xiao/HJP-5134-2023; li, xiaofeng/GXF-9442-2022; Zhang,
   Can/JUU-9511-2023; Li, Tao/IWU-9607-2023; wang, xueting/JPY-2782-2023;
   li, jian/IAQ-2794-2023; XU, nan/KDP-0628-2024; Zhang,
   Wenxiao/KCK-3295-2024; fang, yu/KCK-2014-2024
CR Alexandrov D, 2015, VOPR OBRAZOVANIYA-ED, P173, DOI 10.17323/1814-9545-2015-2-173-195
   Alexiadis DS, 2013, IEEE T MULTIMEDIA, V15, P339, DOI 10.1109/TMM.2012.2229264
   Atherton TJ, 1999, IMAGE VISION COMPUT, V17, P795, DOI 10.1016/S0262-8856(98)00160-7
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Carfagni M, 2017, IEEE SENS J, V17, P4508, DOI 10.1109/JSEN.2017.2703829
   Cui Y., 2011, 2nd International Conference on 3D Body Scanning Technologies, P121, DOI DOI 10.1109/TIP.2016.2563981
   Dou MS, 2015, PROC CVPR IEEE, P493, DOI 10.1109/CVPR.2015.7298647
   Gao F, 2011, SCI CHINA INFORM SCI, V54, P2256, DOI 10.1007/s11432-011-4361-1
   Krischkowsky A, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS (CTS), P99
   Lee YC, 2014, J FOOT ANKLE RES, V7, DOI 10.1186/s13047-014-0044-7
   [刘春阳 Liu Chunyang], 2017, [测绘科学, Science of Surveying and Mapping], V42, P118
   Liu ZB, 2015, SIGNAL PROCESS, V112, P162, DOI 10.1016/j.sigpro.2014.10.021
   Ma X, 2014, INT J IND ERGONOM, V44, P866, DOI 10.1016/j.ergon.2014.08.006
   Maimone A., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P137, DOI 10.1109/ISMAR.2011.6092379
   Maruyama M, 2018, IEEE WINT CONF APPL, P921, DOI 10.1109/WACV.2018.00106
   Molfino R, 2005, IEEE ROBOT AUTOM MAG, V12, P66, DOI 10.1109/MRA.2005.1458327
   Novak B, 2014, STROJ VESTN-J MECH E, V60, P685, DOI 10.5545/sv-jme.2014.1950
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pesce M, 2015, PROC CIRP, V28, P88, DOI 10.1016/j.procir.2015.04.015
   Pioaru I, 2017, 2017 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P241, DOI 10.1109/CW.2017.50
   Psota P, 2017, IEEE INT C EMERG
   Rout N, 2010, INT C ACCTA 2010 3 5, V1, DOI DOI 10.1080/17415977.2017.1391243
   Seo SG, 2014, J FOOT ANKLE RES, V7, pA75, DOI [10.1186/1757-1146-7-S1-A75, DOI 10.1186/1757-1146-7-S1-A75]
   SHI ZF, 2012, RES J APPL SCI ENG T, V4, P2887
   Shi ZF, 2012, IEICE T INF SYST, VE95D, P2585, DOI 10.1587/transinf.E95.D.2585
   Shuping Xiong, 2010, 2010 IEEE International Conference on Industrial Engineering & Engineering Management (IE&EM 2010), P497, DOI 10.1109/IEEM.2010.5674498
   Tong J, 2012, IEEE T VIS COMPUT GR, V18, P643, DOI 10.1109/TVCG.2012.56
   Van den Herrewegen I., 2012, J BIOMECH, V45, pS197
   Van den Herrewegen I, 2014, J BIOMECH, V47, P2531, DOI 10.1016/j.jbiomech.2014.06.010
   Wan FKW, 2017, MEASUREMENT, V99, P134, DOI 10.1016/j.measurement.2016.12.005
   Witana CP, 2006, INT J IND ERGONOM, V36, P789, DOI 10.1016/j.ergon.2006.06.004
   Wu G, 2016, TEXT RES J, V88, P1, DOI DOI 10.1049/IET-GTD.2017.0502
   Wu G, 2017, INT J CLOTH SCI TECH, V29, P314, DOI 10.1108/IJCST-05-2016-0051
   Xiong SP, 2010, INT J ADV MANUF TECH, V46, P11, DOI 10.1007/s00170-009-2087-7
   Závoti J, 2016, ACTA GEOD GEOPHYS, V51, P245, DOI 10.1007/s40328-015-0124-6
   Zhang XG, 2011, PROCEEDINGS OF THE 2011 INTERNATIONAL CONFERENCE ON ENGINEERING AND RISK MANAGEMENT, P1
NR 36
TC 12
Z9 13
U1 2
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22773
EP 22793
DI 10.1007/s11042-020-09839-w
EA OCT 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000576709400001
DA 2024-07-18
ER

PT J
AU Reddy, GT
   Bhattacharya, S
   Maddikunta, PKR
   Hakak, S
   Khan, WZ
   Bashir, AK
   Jolfaei, A
   Tariq, U
AF Reddy, Thippa G.
   Bhattacharya, Sweta
   Maddikunta, Praveen Kumar Reddy
   Hakak, Saqib
   Khan, Wazir Zada
   Bashir, Ali Kashif
   Jolfaei, Alireza
   Tariq, Usman
TI Antlion re-sampling based deep neural network model for classification
   of imbalanced multimodal stroke dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep neural networks; Antlion optimization; Stroke prediction;
   Re-sampling; Imbalanced dataset
ID PREDICTION; ALGORITHM; SYSTEM; CANCER
AB Stroke is enlisted as one of the leading causes of death and serious disability affecting millions of human lives across the world with high possibilities of becoming an epidemic in the next few decades. Timely detection and prompt decision making pertinent to this disease, plays a major role which can reduce chances of brain death, paralysis and other resultant outcomes. Machine learning algorithms have been a popular choice for the diagnosis, analysis and predication of this disease but there exists issues related to data quality as they are collected cross-institutional resources. The present study focuses on improving the quality of stroke data implementing a rigorous pre-processing technique. The present study uses a multimodal stroke dataset available in the publicly available Kaggle repository. The missing values in this dataset are replaced with attribute means and LabelEncoder technique is applied to achieve homogeneity. However the dataset considered was observed to be imbalanced which reflect that the results may not represent the actual accuracy and would be biased. In order to overcome this imbalance, resampling technique was used. In case of oversampling, some data points in the minority class are replicated to increase the cardinality value and rebalance the dataset. transformed and oversampled data is further normalized using Standardscalar technique. Antlion optimization (ALO) algorithm is implemented on the deep neural network (DNN) model to select optimal hyperparameters in minimal time consumption. The proposed model consumed only 38.13% of the training time which was also a positive aspect. The experimental results proved the superiority of proposed model.
C1 [Reddy, Thippa G.; Bhattacharya, Sweta; Maddikunta, Praveen Kumar Reddy] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore 632014, Tamil Nadu, India.
   [Hakak, Saqib] Univ New Brunswick, Canadian Inst Cybersecur, Fac Comp Sci, Fredericton, NB, Canada.
   [Khan, Wazir Zada] Jazan Univ, Fac CS, IT, Jazan, Saudi Arabia.
   [Bashir, Ali Kashif] Manchester Metropolitan Univ Manchester, Dept Comp & Math, Manchester, Lancs, England.
   [Jolfaei, Alireza] Macquarie Univ, Dept Comp, Sydney, NSW, Australia.
   [Tariq, Usman] Prince Sattam bin Abdulaziz Univ, Coll Comp Engn & Sci, Al Kharj 11942, Saudi Arabia.
C3 Vellore Institute of Technology (VIT); VIT Vellore; University of New
   Brunswick; Jazan University; Manchester Metropolitan University;
   Macquarie University; Prince Sattam Bin Abdulaziz University
RP Hakak, S (corresponding author), Univ New Brunswick, Canadian Inst Cybersecur, Fac Comp Sci, Fredericton, NB, Canada.; Khan, WZ (corresponding author), Jazan Univ, Fac CS, IT, Jazan, Saudi Arabia.
EM thippareddy.g@vit.ac.in; sweta.b@vit.ac.in; praveenkumarreddy@vit.ac.in;
   saqib.hakak@unbc.ca; wazirzadakhan@jazanu.edu.sa;
   dr.alikashif.b@ieee.org; alireza.jolfaei@mq.edu.au; u.tariq@psau.edu.sa
RI Jolfaei, Alireza/GQH-6907-2022; Tariq, Usman/AAF-8954-2020; Gadekallu,
   Thippa Reddy/T-4254-2019; Hakak, Saqib/AAC-5134-2021; Bhattacharya,
   Sweta/HPH-3283-2023; Maddikunta, Praveen Kumar Reddy/HSG-8292-2023;
   Khan, Wazir Zada/G-8580-2015; Tariq, Usman/AAE-8037-2022; Reddy, Praveen
   Kumar/AAB-4338-2019; Bashir, Ali Kashif/R-4015-2019
OI Gadekallu, Thippa Reddy/0000-0003-0097-801X; Bhattacharya,
   Sweta/0000-0002-6082-164X; Maddikunta, Praveen Kumar
   Reddy/0000-0003-4209-2495; Khan, Wazir Zada/0000-0003-0819-4236; Tariq,
   Usman/0000-0001-7672-1187; Reddy, Praveen Kumar/0000-0003-4209-2495;
   Bashir, Ali Kashif/0000-0003-2601-9327
FU University of Northern British Columbia under FUND [15021 ORG 4460]
FX The work of Saqib Hakak is supported by the University of Northern
   British Columbia under FUND 15021 ORG 4460.
CR Al-khafajiy M, 2019, MULTIMED TOOLS APPL, V78, P24681, DOI 10.1007/s11042-018-7134-7
   [Anonymous], 2020, STROKE PREDICTION
   Benjamin EJ, 2017, CIRCULATION, V135, pE146, DOI [10.1161/CIR.0000000000000485, 10.1161/CIR.0000000000000558, 10.1161/CIR.0000000000000530]
   Bentley P, 2014, NEUROIMAGE-CLIN, V4, P635, DOI 10.1016/j.nicl.2014.02.003
   Cao Y., 2010, P KDD 10 16 ACM SIGK, P183, DOI [10.1145/1835804.1835830, DOI 10.1145/1835804.1835830]
   Chantamit-O-Pas P., 2018, Machine Learning and Data Mining in Pattern Recognition, V10934, P312, DOI 10.1007/978-3-319-96136-1_25
   Chantamit-o-pas P, 2017, LECT NOTES COMPUT SC, V10638, P774, DOI 10.1007/978-3-319-70139-4_78
   Chen L, 2017, NEUROIMAGE-CLIN, V15, P633, DOI 10.1016/j.nicl.2017.06.016
   Chiroma H, 2020, ADV INTELL SYST COMP, V943, P59, DOI 10.1007/978-3-030-17795-9_5
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Feng L, 2019, IEEE T IND INFORM, V15, P3016, DOI 10.1109/TII.2019.2902604
   Gadekallu TR, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01963-7
   Garg S, 2019, IEEE T MULTIMEDIA, V21, P566, DOI 10.1109/TMM.2019.2893549
   Heidari A., 2020, NATURE INSPIRED OPTI, DOI [10.1007/978-3-030-12127-3_3, DOI 10.1007/978-3-030-12127-3_3]
   Huang CX, 2019, NEUROCOMPUTING, V325, P283, DOI 10.1016/j.neucom.2018.09.065
   Jindal A, 2018, IEEE GLOB COMM CONF, DOI 10.1109/ICOPS35962.2018.9575456
   Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5
   Kamal H, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.00945
   Kaur H, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3343440
   Kutia S, 2019, IEEE ACCESS, V7, P90777, DOI 10.1109/ACCESS.2019.2924584
   Li JY, 2018, INFORM FUSION, V39, P1, DOI 10.1016/j.inffus.2017.03.007
   Liu TY, 2019, ARTIF INTELL MED, V101, DOI 10.1016/j.artmed.2019.101723
   Maddikunta PKR, 2020, COMPUT COMMUN, V159, P97, DOI 10.1016/j.comcom.2020.05.020
   Manogaran G, 2018, MULTIMED TOOLS APPL, V77, P4379, DOI 10.1007/s11042-017-5515-y
   Mirjalili S, 2015, ADV ENG SOFTW, V83, P80, DOI 10.1016/j.advengsoft.2015.01.010
   Patel H, 2020, INT J DISTRIB SENS N, V16, DOI 10.1177/1550147720916404
   Pham QV, 2020, IEEE T VEH TECHNOL, V69, P4285, DOI 10.1109/TVT.2020.2973294
   Priya RMS, 2020, J PARALLEL DISTR COM, V142, P16, DOI 10.1016/j.jpdc.2020.02.010
   Qin ZB, 2014, MATH STRUCT COMP SCI, V24, DOI 10.1017/S0960129513000777
   Reddy GT, 2020, IEEE ACCESS, V8, P54776, DOI 10.1109/ACCESS.2020.2980942
   Reddy GT, 2018, INT J BIOMED ENG TEC, V27, P183, DOI 10.1504/IJBET.2018.094122
   Reddy GT, 2020, COMPUT COMMUN, V157, P64, DOI 10.1016/j.comcom.2020.04.004
   Salunkhe UR, 2016, PROCEDIA COMPUT SCI, V85, P725, DOI 10.1016/j.procs.2016.05.259
   Sattar HA, 2019, INT J SWARM INTELL R, V10, P1, DOI 10.4018/IJSIR.2019070101
   Scalzo F, 2013, MAGN RESON IMAGING, V31, P961, DOI 10.1016/j.mri.2013.03.013
   Sultan S, 2019, J AMB INTEL HUM COMP, V10, P4197, DOI 10.1007/s12652-019-01444-6
   Takahashi N, 2014, RADIOL PHYS TECHNOL, V7, P79, DOI 10.1007/s12194-013-0234-1
   Thabtah F, 2020, INFORM SCIENCES, V513, P429, DOI 10.1016/j.ins.2019.11.004
   Thomalla G, 2018, NEW ENGL J MED, V379, P611, DOI 10.1056/NEJMoa1804355
   Tripathy BK, 2017, ADV INTELL SYST, V509, P3, DOI 10.1007/978-981-10-2525-9_1
   Tripathy BK, 2008, LECT NOTES ARTIF INT, V5306, P92, DOI 10.1007/978-3-540-88425-5_10
   Wang DS, 2018, IEEE T NEUR NET LEAR, V29, P3815, DOI 10.1109/TNNLS.2017.2741349
   Yu YN, 2018, IEEE T BIO-MED ENG, V65, P2058, DOI 10.1109/TBME.2017.2783241
   Yuan XH, 2018, PATTERN RECOGN, V77, P160, DOI 10.1016/j.patcog.2017.12.017
   Zerdoumi S, 2018, MULTIMED TOOLS APPL, V77, P10091, DOI 10.1007/s11042-017-5045-7
   Zhang C, 2019, IEEE T NEUR NET LEAR, V30, P109, DOI 10.1109/TNNLS.2018.2832648
   Zhu M, 2018, IEEE ACCESS, V6, P4641, DOI 10.1109/ACCESS.2018.2789428
NR 47
TC 50
Z9 51
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41429
EP 41453
DI 10.1007/s11042-020-09988-y
EA OCT 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000576709300002
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Thabet, E
   Khalid, F
   Sulaiman, PS
   Yaakob, R
AF Thabet, Eman
   Khalid, Fatimah
   Sulaiman, Puteri Suhaiza
   Yaakob, Razali
TI Algorithm of local features fusion and modified covariance-matrix
   technique for hand motion position estimation and hand gesture
   trajectory tracking approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand gesture tracking; Gabor filter; Brisk feature; Fast marching method
   (FMM); Entropy filter; Region covariance matrix (RCM); Minimum
   eigenvalue; Hog feature; Canny feature
ID REGION COVARIANCE; RECOGNITION; SEGMENTATION; MODEL
AB Nowadays, visual recognition based dynamic hand gesture tracking has gained very considerable attention. Hand gestures can play an important role as a non-touchable communication tool between machines and humans based on using the affordable built-in webcam. The need for replacing touch-based computing devices interaction has been increasing in many fields like healthcare, security, and generally as interface-based devices controlling. Especially with COVID19 outbreak spreading around the world, where people take a risk and avoid dealing with electronic consumer machines that required hand touching. However, in any dynamic hand gesture recognition system, dynamic hand gesture tracking is a very hard task, where position estimation over video frames for freely moving hand in the air is quite challenging. This shortcoming is due to hand great scale changes, posture variations, and translation problems. Hence, to tackle these difficulties and extract gesture features for gesture recognition phase accurately, this paper proposed an algorithm of dynamic hand trajectory tracking for gesture recognition. The presented algorithm proposes local features fusion based on Gabor-Canny- Hog features embedded an updated compact covariance matrix technique as sophisticated feature-based tracking, utilizing video sequences of IBGHT dataset. As a result, the proposed approach has shown adorable optimization achieving an accuracy rate of 96.97%, overcoming the problems of hand appearance variation in the complicated environment.
C1 [Thabet, Eman] Univ Basra, Coll Educ Pure Sci, Dept Comp Sci, Basra, Iraq.
   [Thabet, Eman; Khalid, Fatimah; Sulaiman, Puteri Suhaiza; Yaakob, Razali] Univ Putra Malaysia UPM, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
C3 University of Basrah
RP Thabet, E (corresponding author), Univ Basra, Coll Educ Pure Sci, Dept Comp Sci, Basra, Iraq.; Thabet, E (corresponding author), Univ Putra Malaysia UPM, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
EM eman.alasadi@uobasrah.edu.iq; fatimahk@upm.edu.my; psuhaiza@upm.edu.my;
   razaliy@upm.edu.my
RI Sulaiman, Puteri/HJI-3470-2023; Sulaiman, Puteri Suhaiza/ABA-9377-2021;
   Thabet Khalid, Eman/F-3320-2019
OI Sulaiman, Puteri Suhaiza/0000-0002-8350-556X; Thabet Khalid,
   Eman/0000-0002-6720-2032
CR Abdelgawad H. M., 2015, INT J COMPUT ELECT A, V9, P148
   Ahlawat S, 2019, LECT NOTE NETW SYST, V56, P179, DOI 10.1007/978-981-13-2354-6_20
   [Anonymous], 2010, WORLD ENG C
   Asaari Mohd Shahrimie Mohd, 2010, Proceedings 10th International Conference on Intelligent Systems Design and Applications (ISDA 2010), P166, DOI 10.1109/ISDA.2010.5687273
   Asaari MSM, 2015, MULTIMED TOOLS APPL, V74, P9231, DOI 10.1007/s11042-014-2078-z
   Asaari MSM, 2014, MULTIMED TOOLS APPL, V70, P1869, DOI 10.1007/s11042-012-1212-z
   Bao PJ, 2017, IEEE T CONSUM ELECTR, V63, P251, DOI 10.1109/TCE.2017.014971
   Madeo RCB, 2016, EXPERT SYST APPL, V56, P100, DOI 10.1016/j.eswa.2016.02.021
   Bhuyan MK, 2014, J MULTIMODAL USER IN, V8, P333, DOI 10.1007/s12193-014-0165-0
   Black M. J., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P329, DOI 10.1007/BFb0015548
   Bouchrika T, 2014, MULTIMED TOOLS APPL, V72, P2949, DOI 10.1007/s11042-013-1557-y
   Bourennane S, 2012, SIGNAL IMAGE VIDEO P, V6, P147, DOI 10.1007/s11760-010-0176-6
   Bray M, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P675, DOI 10.1109/AFGR.2004.1301612
   Chai D, 1999, IEEE T CIRC SYST VID, V9, P551, DOI 10.1109/76.767122
   Chi JN, 2014, NEUROCOMPUTING, V128, P42, DOI 10.1016/j.neucom.2013.03.052
   Chong LY., 2014, LECT NOTES COMPUTER, V8836
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dixit V, 2015, P 4 INT C SOFT COMP, P153
   ELMEZAIN M, 2010, WASET, V3, P131
   Faudzi AAM, 2012, PROCEDIA ENGINEER, V41, P798, DOI 10.1016/j.proeng.2012.07.246
   Feichtenhofer C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P246, DOI 10.1109/ICCVW.2013.40
   Feng KP, 2013, 2013 2ND INTERNATIONAL SYMPOSIUM ON INSTRUMENTATION AND MEASUREMENT, SENSOR NETWORK AND AUTOMATION (IMSNA), P936, DOI 10.1109/IMSNA.2013.6743432
   Forstner W, 2003, Geodesy-the Challenge of the 3rd Millennium, P299, DOI [10.1007/978-3-662-05296-9_31, DOI 10.1007/978-3-662-05296-9_31]
   Frikha R, 2015, LECT NOTES COMPUT SC, V9375, P457, DOI 10.1007/978-3-319-24834-9_53
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   Ghosh DK, 2015, INT CONF COMM SYST, P1094, DOI 10.1109/CSNT.2015.18
   Golash R, 2014, INT J COMPUT APPL, V105, P1011
   Gupta P, 2014, TRACKING HAND MOVEME
   Gupta S, 2012, PROCEDIA ENGINEER, V41, P827, DOI 10.1016/j.proeng.2012.07.250
   Hamahashi S, 2008, U.S. Patent, Patent No. [7,460,702, 7460702]
   Hsieh CC, 2015, J REAL-TIME IMAGE PR, V10, P357, DOI 10.1007/s11554-012-0295-0
   Huang DY, 2011, EXPERT SYST APPL, V38, P6031, DOI 10.1016/j.eswa.2010.11.016
   Huang Z., 2010, ADV MECH ENG, V2010, P1
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jeyakumar R, 2015, PROCEEDINGS OF 2015 ONLINE INTERNATIONAL CONFERENCE ON GREEN ENGINEERING AND TECHNOLOGIES (IC-GET)
   Kiliboz NÇ, 2015, J VIS COMMUN IMAGE R, V28, P97, DOI 10.1016/j.jvcir.2015.01.015
   Kim JG, 2013, INT J CONTROL AUTOM, V11, P84, DOI 10.1007/s12555-012-9217-y
   Kolsch M., 2004, Computer Vision and Pattern Recognition Workshop, P158
   Koppula VK, 2020, ADV CYBERNETICS COGN, P377
   Lee YW, 2013, NEUROCOMPUTING, V116, P272, DOI 10.1016/j.neucom.2011.10.046
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Lim KM, 2016, EXPERT SYST APPL, V54, P208, DOI 10.1016/j.eswa.2016.01.047
   Liu XY, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL, AUTOMATIC DETECTION AND HIGH-END EQUIPMENT (ICADE), P201, DOI 10.1109/ICADE.2012.6330127
   Maleki B, 2015, MULTIMEDIA SYST, V21, P581, DOI 10.1007/s00530-014-0420-y
   Manasa N, 2016, BRAIN
   Palacios JM, 2013, SENSORS-BASEL, V13, P11842, DOI 10.3390/s130911842
   Maqueda AI, 2015, COMPUT VIS IMAGE UND, V141, P126, DOI 10.1016/j.cviu.2015.07.009
   Mazumdar D, 2015, SIGNALS COMMUN TECHN, P115, DOI 10.1007/978-81-322-2407-5_9
   Murata T, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/278460
   Neethu PS, 2020, SOFT COMPUT, V24, P15239, DOI 10.1007/s00500-020-04860-5
   Norouzi M., 2012, ADV NEURAL INFORM PR
   Nyirarugira C, 2015, SIGNAL PROCESS-IMAGE, V30, P178, DOI 10.1016/j.image.2014.10.008
   Oz C, 2011, ENG APPL ARTIF INTEL, V24, P1204, DOI 10.1016/j.engappai.2011.06.015
   Ozturk O, 2015, APPL INTELL, V43, P786, DOI 10.1007/s10489-015-0680-z
   Pang YW, 2008, IEEE T CIRC SYST VID, V18, P989, DOI 10.1109/TCSVT.2008.924108
   Park J, 2009, INT J CONTROL AUTOM, V7, P817, DOI 10.1007/s12555-009-0514-z
   Pisipati M, 2019, INT C COMM INT SYST, P21
   Premaratne Prashan, 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9225, P623, DOI 10.1007/978-3-319-22180-9_62
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Rautaray SiddharthS., 2012, Int J UbiComp, V3, P21
   Rehg JM, 2003, CMUCS93220
   Ren M, 2005, COMPUT ENG, V20, P12
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Rosten E, 2005, IEEE I CONF COMP VIS, P1508
   Sarma D, 2018, ANNU IEEE IND CONF
   Sgouropoulos K, 2014, J INTELL ROBOT SYST, V76, P283, DOI 10.1007/s10846-013-9983-7
   Shan C, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P669
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Shitole S. M., 2013, INT J COMPUT APPL, V74, P24
   Silanon K, 2011, LECT NOTES ARTIF INT, V6746, P178
   Simoes WCSS, 2015, L N COMPUT VIS BIOME, V19, P335, DOI 10.1007/978-3-319-13407-9_20
   Singha J, 2017, MULTIMEDIA SYST, V23, P499, DOI 10.1007/s00530-016-0510-0
   Stergiopoulou E, 2014, ENG APPL ARTIF INTEL, V35, P54, DOI 10.1016/j.engappai.2014.06.006
   Thabet E, 2017, J AMBIENT INTELL HUM, P1
   Thabet E, 2017, J ADV SCI ENG RES, V7, P43
   Thabet E, 2017, ADV MULTIMED, V2017, DOI 10.1155/2017/7645189
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Tuzel O, 2007, PROC CVPR IEEE, P1736
   Wang C, 2015, IEEE T MULTIMEDIA, V17, P29, DOI 10.1109/TMM.2014.2374357
   Wang Liang, 2015, Journal of China Universities of Posts and Telecommunications, V22, P81, DOI 10.1016/S1005-8885(15)60643-4
   Wenjun Jin, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P8, DOI 10.1109/CECNet.2012.6201605
   Xu QZ, 2019, PHYSICA A, V531, DOI 10.1016/j.physa.2019.121808
   Xu WY, 2010, I C CONT AUTOMAT ROB, P878, DOI 10.1109/ICARCV.2010.5707276
   Xu WY, 2009, COMM COM INF SC, V61, P90
   Yeo HS, 2015, MULTIMED TOOLS APPL, V74, P2687, DOI 10.1007/s11042-013-1501-1
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yin J, 2009, PROCEEDINGS OF THE ASME INTERNATIONAL MANUFACTURING SCIENCE AND ENGINEERING CONFERENCE, VOL 1, P9, DOI 10.1115/MSEC2009-84374
   Zhang XQ, 2015, NEUROCOMPUTING, V157, P296, DOI 10.1016/j.neucom.2015.01.002
   Zhao ZY, 2012, PROCEDIA ENGINEER, V29, P3065, DOI 10.1016/j.proeng.2012.01.441
   Zhou HY, 2014, PATTERN RECOGN, V47, P3552, DOI 10.1016/j.patcog.2014.05.006
   Zhou YM, 2016, PATTERN RECOGN, V49, P102, DOI 10.1016/j.patcog.2015.07.014
   Zou X, 2013, COMM COM INF SC, V391, P651
NR 93
TC 5
Z9 6
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5287
EP 5318
DI 10.1007/s11042-020-09903-5
EA OCT 2020
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000575795600005
DA 2024-07-18
ER

PT J
AU Li, DF
   Zhang, M
   Zhang, LF
   Chen, WF
   Feng, GC
AF Li, Defang
   Zhang, Min
   Zhang, Lifang
   Chen, Weifu
   Feng, Guocan
TI A novel attribute-based generation architecture for facial image editing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adversarial Variational Autoencoders; Generative Adversarial Networks;
   Facial editing; Disentangled features
AB Facial image editing is one of the hot topics in recent years due to the great development in deep generative models. Current models are either based on variational autoencoder(VAE) or generative adversarial network(GAN). However, VAE-based models usually generate oversmooth images, while GAN-based-only models cannot randomly generate images with specific attributes and suffer from unstable training. To overcome these limitations, a novel attribute-disentangled generative model based on the combination of VAE and GAN is proposed for facial image editing by manipulating specific attributes and synthesizing facial images conditioned on the specified attributes. In the encoder-decoder architecture of the proposed model, the latent space mapped by the encoder is split into two subspaces: the attribute-irrelevant space and the attribute-relevant space. The attribute-irrelevant space characterizes the factors such as identity, position, background etc, which are expected to be kept unchanged during the editing. The attribute-relevant space is used to represent the attributes such as hair color, gender, age etc that we want to manipulate. We use the adversarial training scheme to train the model, where images generated by the proposed model are re-feeded to the encoder to ensure their distribution is close to the real data distribution in the attribute-irrelevant subspace while they can be correctly classified in the attribute-relevant subspace, without explicitly giving the discriminators such as in GANs. To evaluate the performance of the proposed model, quantitative and qualitative comparisons between the proposed model and other state-of-the-art algorithms were tesed on the CelebA dataset. The evaluation results show that the proposed model can effectively generate high-quality facial images with diverse specified attributes.
C1 [Li, Defang; Zhang, Min; Chen, Weifu; Feng, Guocan] Sun Yat Sen Univ, Sch Math, Guangzhou, Peoples R China.
   [Li, Defang; Zhang, Min; Chen, Weifu; Feng, Guocan] Sun Yat Sen Univ, Guangdong Prov Key Lab, Guangzhou, Peoples R China.
   [Zhang, Lifang] Dongguan Univ Technol, Sch Comp Sci & Technol, Dongguan, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University; Dongguan University of
   Technology
RP Chen, WF (corresponding author), Sun Yat Sen Univ, Sch Math, Guangzhou, Peoples R China.; Chen, WF (corresponding author), Sun Yat Sen Univ, Guangdong Prov Key Lab, Guangzhou, Peoples R China.
EM chenwf26@mail.sysu.edu.cn
RI Li, Defang/JAN-4454-2023
OI Feng, Guocan/0000-0002-0097-5591
FU Natural Science Foundation of China [61673018, 61272338, 61703443];
   Guangzhou Science and Technology Founding Committee [201707010222];
   Guangdong Province Key Laboratory of Computer Science
FX This research was funded by Natural Science Foundation of China under
   grants numbers 61673018, 61272338, 61703443 and Guangzhou Science and
   Technology Founding Committee under grant No. 201707010222 and Guangdong
   Province Key Laboratory of Computer Science.
CR Akhtar Z, 2019, NUT COLL ENG RES INT
   [Anonymous], 2017, COMPUTER VISION PATT
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bao JM, 2017, IEEE I CONF COMP VIS, P2764, DOI 10.1109/ICCV.2017.299
   Bengio Y, 2014, PR MACH LEARN RES, V32, P226
   Brock Andrew, 2018, ARXIV180911096
   Charlier P, 2014, FORENSIC SCI MED PAT, V10, P654, DOI 10.1007/s12024-014-9618-8
   Che Tong, 2016, CoRR
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Dai B., 2019, INT C LEARN REPR
   Donahue J., 2016, ARXIV160509782
   Dumoulin V., 2016, A guide to convolution arithmetic for deep learning[J
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gregor K, 2015, PR MACH LEARN RES, V37, P1462
   Guo Q, 2017, ARXIV170202805
   He ZL, 2019, IEEE T IMAGE PROCESS, V28, P5464, DOI 10.1109/TIP.2019.2916751
   Hensel M, 2017, ADV NEUR IN, V30
   Huang HB, 2018, ADV NEUR IN, V31
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Karras T, 2018, P INT C LEARN REPR I
   Karras T., 2019, ARXIV191204958
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Kim T., 2017, P 34 INT C MACH LEAR, P1857, DOI DOI 10.1109/WPT.2017.7953894
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lample G, 2017, ADV NEUR IN, V30
   Larsen ABL, 2016, PR MACH LEARN RES, V48
   Li M., 2016, ARXIV161005586
   Lim Theodore, 2016, P INT C LEARN REPR
   Liu MY, 2016, ADV NEUR IN, V29
   Liu MY, 2017, ADV NEUR IN, V30
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lu YY, 2018, LECT NOTES COMPUT SC, V11216, P293, DOI 10.1007/978-3-030-01258-8_18
   Makhzani A., 2015, ARXIV
   Marcolin F, 2017, MULTIMED TOOLS APPL, V76, P13805, DOI 10.1007/s11042-016-3741-3
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Perarnau G., 2016, NIPS WORKSH ADV TRAI
   Radford A., 2016, INT C LEARN REPR
   Rezende DJ, 2014, PR MACH LEARN RES, V32, P1278
   Salimans T, 2016, ADV NEUR IN, V29
   Shen W, 2017, PROC CVPR IEEE, P1225, DOI 10.1109/CVPR.2017.135
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sohn K, 2015, ADV NEUR IN, V28
   Taigman Y., 2017, INT C LEARN REPR ICL, P1
   Tolosana Ruben, 2020, Information Fusion, V64, P131, DOI 10.1016/j.inffus.2020.06.014
   Tolstikhin I., 2018, 6 INT C LEARNING REP
   Ulyanov D, 2018, AAAI CONF ARTIF INTE, P1250
   Upchurch P, 2017, PROC CVPR IEEE, P6090, DOI 10.1109/CVPR.2017.645
   Vezzetti E, 2018, MULTIMED TOOLS APPL, V77, P14177, DOI 10.1007/s11042-017-5025-y
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   XIAO T, 2018, INT C LEARN REPR WOR
   Xiao TH, 2018, LECT NOTES COMPUT SC, V11214, P172, DOI 10.1007/978-3-030-01249-6_11
   Yan, 2016, ATTRIBUTE2IMAGE COND
   Zeng XW, 2013, PROCEEDINGS OF THE 2013 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL AND INFORMATION PROCESSING (ICICIP), P535
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhou Shuchang, 2017, BMVC
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 59
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 4881
EP 4902
DI 10.1007/s11042-020-09858-7
EA OCT 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000574727600006
DA 2024-07-18
ER

PT J
AU Lee, JY
AF Lee, Jin Young
TI Novel skip motion estimation for efficient inter coding in HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Motion estimation; Skip mode; Inter coding
ID VIDEO
AB Video coding is necessary to transmit large amounts of video information. HEVC, which is the latest video coding standard, includes many advanced tools to achieve higher coding efficiency than previous standards, such as MPEG-1/2/4 and H.264/AVC. In particular, new techniques in inter prediction, such as skip, merge, and advanced motion vector prediction (AMVP) modes, drastically improve coding performance by reducing temporal redundancies between consecutive frames within a video. However, the skip mode, which does not perform a motion estimation, can deteriorate the coding performance, because of inaccurate motion vector prediction in videos with fast and complex motions. In order to solve this problem, a novel skip motion estimation method is proposed for efficient inter coding in HEVC. Unlike the conventional skip mode, the proposed skip mode performs the motion estimation, and then transmits the associated motion information. Experimental results demonstrate that the proposed method achieves the high coding performance with the low decoding complexity.
C1 [Lee, Jin Young] Sejong Univ, Sch Intelligent Mechatron Engn, Seoul, South Korea.
C3 Sejong University
RP Lee, JY (corresponding author), Sejong Univ, Sch Intelligent Mechatron Engn, Seoul, South Korea.
EM jinyounglee@sejong.ac.kr
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [2018R1C1B5086072]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (No.
   2018R1C1B5086072).
CR [Anonymous], 2012, JCTVCI0408
   [Anonymous], 2007, PICT COD S
   [Anonymous], 2003, ADV VID COD GEN AUD
   [Anonymous], 2013, 230082 ISOIEC
   Bjotegaard G., 2001, VCEGM33
   Bossen F., 2013, JCTVCL110
   Cha R, 2011, IEEE INT CON MULTI
   Chen H, 2015, IEEE 17 INT WORKSH M
   Chen YA, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6853979
   Cheung HK, 2010, IEEE INT SYMP CIRC S, P1555, DOI 10.1109/ISCAS.2010.5537406
   Fan K, 2019, IEEE T CIRC SYST VID, V29, P3716, DOI 10.1109/TCSVT.2018.2885002
   Fan R, 2017, IEEE T MULTIMEDIA, V19, P893, DOI 10.1109/TMM.2016.2642786
   Grellert M, 2019, IEEE T CIRC SYST VID, V29, P1741, DOI 10.1109/TCSVT.2018.2849941
   Huang H, 2012, ASIA COMMUN PHOTON, DOI 10.1117/12.904390
   Kordasiewicz RC, 2007, IEEE T CIRC SYST VID, V17, P1388, DOI 10.1109/TCSVT.2007.903777
   Li L, 2018, IEEE T CIRC SYST VID, V28, P1934, DOI 10.1109/TCSVT.2017.2699919
   Nalluri P, 2015, SIGNAL PROCESS-IMAGE, V39, P280, DOI 10.1016/j.image.2015.09.015
   Narroschke M, 2013, PICT COD SYMP, P321, DOI 10.1109/PCS.2013.6737748
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   Seiler J, 2010, PICT COD S
   Seiler J, 2008, IEEE IMAGE PROC, P2788, DOI 10.1109/ICIP.2008.4712373
   Seiler J, 2009, IEEE INT WORKSH MULT, P80
   Soro S, 2009, ADV MULTIMED, V2009, DOI 10.1155/2009/640386
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun YC, 2016, IEEE J EM SEL TOP C, V6, P433, DOI 10.1109/JETCAS.2016.2598193
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xu XZ, 2016, IEEE J EM SEL TOP C, V6, P409, DOI 10.1109/JETCAS.2016.2597645
   Yang SH, 2014, ELECTRON LETT, V50, P673, DOI 10.1049/el.2014.0536
   Yang Z, 2017, MULTIMEDIA TOOLS APP, V76
   Zhang JL, 2016, IEEE T CIRC SYST VID, V26, P1502, DOI 10.1109/TCSVT.2015.2461991
   Zhao L, 2013, P IEEE INT C IM PROC
   Zhong GY, 2015, MULTIMED TOOLS APPL, V74, P11023, DOI 10.1007/s11042-014-2216-7
NR 33
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4493
EP 4505
DI 10.1007/s11042-020-09945-9
EA SEP 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000574101100005
DA 2024-07-18
ER

PT J
AU Chakraborty, S
   Thounaojam, DM
   Sinha, N
AF Chakraborty, Saptarshi
   Thounaojam, Dalton Meitei
   Sinha, Nidul
TI A Shot boundary Detection Technique based on Visual Colour Information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shot boundary; cut; dissolve; Luminance; Video Segmentation
AB The paper proposes a novel video segmentation system with maiden application of CIEDE2000 colour-difference and mean luminace pattern. CIEDE2000 colour-difference uses Lab colour space which is a stable and efficient colour space. The main advantage of Lab colour space model is that it can approximate all the available colours perceived by our human eye. CIEDE2000 colour difference is used for detecting abrupt transitions in the video. The novel contribution of the paper is the maiden use of the mean luminance pattern, increasing and decreasing patterns of the mean value of frame luminance, for detecting the gradual transition. The approach is validated on standard databases TRECVid 2001 and 2007 test video database. The performance of the proposed technique is compared with recently reported techniques and found to be superior as compared to other techniques. The accuracy achieved with the proposed method on the standard databases is95.9%for cut transition,78.6%for gradual transition and92.1%overall.
C1 [Chakraborty, Saptarshi; Thounaojam, Dalton Meitei; Sinha, Nidul] Natl Inst Technol Silchar, Dept Comp Sci, Comp Vis Lab, Engn, Silchar, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Chakraborty, S (corresponding author), Natl Inst Technol Silchar, Dept Comp Sci, Comp Vis Lab, Engn, Silchar, Assam, India.
EM chakraborty0007@gmail.com
RI thounaojam, Dalton/AAN-8432-2020; Thounaojam, Dalton/AAO-8511-2021
OI Thounaojam, Dalton/0000-0002-2655-3821; Chakraborty,
   Saptarshi/0000-0002-8213-1615
CR Abdulhussain Sadiq H, 2018, ENTROPY, V20, P1
   [Anonymous], 2011, VIDEO SHOT BOUNDARY
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   Boccignone G, 2005, IEEE T CIRC SYST VID, V15, P365, DOI 10.1109/TCSVT.2004.842603
   Cai C., 2005, P INT C
   Farshid A, 1993, IMAGE PROCESSING COM, P267
   Gong Y., 2000, VIDEO SHOT SEGMENTAT
   Kar T, 2017, SIGNAL IMAGE VIDEO P, V11, P1237, DOI 10.1007/s11760-017-1080-0
   Koprinska I, 2001, SIGNAL PROCESS-IMAGE, V16, P477, DOI 10.1016/S0923-5965(00)00011-4
   Küçüktunç O, 2010, COMPUT VIS IMAGE UND, V114, P125, DOI 10.1016/j.cviu.2009.09.008
   Li YN, 2009, IET IMAGE PROCESS, V3, P121, DOI 10.1049/iet-ipr.2007.0193
   Lienhart R, 1998, PROC SPIE, V3656, P290, DOI 10.1117/12.333848
   Liu F, 2015, 2015 SEVENTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P351, DOI 10.1109/ICACI.2015.7184728
   Liu X, 2020, IEEE T IND INFORM, V16, P5379, DOI 10.1109/TII.2019.2947435
   Liu X, 2019, IEEE INTERNET THINGS, V6, P5962, DOI 10.1109/JIOT.2018.2847731
   Lu ZM, 2013, IEEE T IMAGE PROCESS, V22, P5136, DOI 10.1109/TIP.2013.2282081
   NAGASAKA A, 1992, IFIP TRANS A, V7, P113
   Pei SC, 1999, IEEE T MULTIMEDIA, V1, P321, DOI 10.1109/6046.807952
   Prabavathy A.K., 2017, HISTOGRAM DIFFERENCE
   Prasertsakul P, 2020, MULTIMED TOOLS APPL, V79, P17403, DOI 10.1007/s11042-019-08378-3
   Priya GGL, 2014, IEEE T IMAGE PROCESS, V23, P5187, DOI 10.1109/TIP.2014.2362652
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Shen JL, 2008, IEEE T CIRC SYST VID, V18, P1587, DOI 10.1109/TCSVT.2008.2005607
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   Thounaojam D.M., 2013, P INT C ADV COMP NET, P903
   Thounaojam D.M., 2016, COMPUTATIONAL INTELL, V2016, P11
   Thounaojam DM, 2017, INT J MULTIMED INF R, V6, P167, DOI 10.1007/s13735-017-0123-1
   Tippaya S, 2017, IEEE ACCESS, V5, P12563, DOI 10.1109/ACCESS.2017.2717998
   Tong W., 2015, CNN BASED SHOT BOUND
   Wu GS, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3076
   Xu W., 2010, 2010 2 INT CONF ED T, P1570
   Yasuyuki N, 1999, IEICE T INF SYST, V77, P1355
   Zhang H., 1995, Multimedia Tools and Applications, V1, P89, DOI 10.1007/BF01261227
NR 33
TC 16
Z9 16
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4007
EP 4022
DI 10.1007/s11042-020-09857-8
EA SEP 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572719800007
DA 2024-07-18
ER

PT J
AU Ganaa, ED
   Shen, XJ
   Abeo, TA
AF Ganaa, Ernest Domanaanmwi
   Shen, Xiang-Jun
   Abeo, Timothy Apasiba
TI Deflated manifold embedding PCA framework via multiple instance
   factorings
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Principal component analysis; Manifold embedding; Dimension reduction;
   Deflation; Instance factorings
ID PRINCIPAL COMPONENT ANALYSIS; PRESERVING PROJECTIONS; LP-NORM; KERNEL;
   REDUCTION; SPARSE; MATRIX; NOISE; FACE
AB Principal component analysis is a widely used technique. However, it is sensitive to noise and considers data samples to be linearly distributed globally. To tackle these challenges, a novel technique robust to noise termed deflated manifold embedding PCA is proposed. In this framework, we unify PCA with manifold embedding to preserve both global and local geometric structures of linear and non-linear data in sub-manifolds. Additionally, a scaling-factor is imposed in the instance space to mitigate the impact of noise in pursuing projections. By using cosine similarity and total distance approaches, we iteratively learn the relationships between instances and projections in order to discriminate between authentic and corrupt instances. Further, a deflation technique is applied to establish multi-relationships between instances and every pursued projection for thorough discrimination. Experimental evaluation of the proposed methods on five datasets show great improvements in their performances over six state-of-the-art techniques.
C1 [Ganaa, Ernest Domanaanmwi; Shen, Xiang-Jun] Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Ganaa, Ernest Domanaanmwi] Wa Tech Univ, Sch Appl Sci & Technol, Box 553, Wa, Ghana.
   [Shen, Xiang-Jun] JiangSu Univ, Jingkou New Generat Informat Technol Ind Inst, Zhenjiang, Jiangsu, Peoples R China.
   [Abeo, Timothy Apasiba] Tamale Tech Univ, Sch Appl Sci, Box 3ER, Tamale, Ghana.
C3 Jiangsu University; Jiangsu University
RP Shen, XJ (corresponding author), Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.; Shen, XJ (corresponding author), JiangSu Univ, Jingkou New Generat Informat Technol Ind Inst, Zhenjiang, Jiangsu, Peoples R China.
EM xjshen@ujs.edu.cn
RI Ganaa, Ernest Domanaanmwi/O-5746-2019
OI Ganaa, Ernest Domanaanmwi/0000-0002-2161-7435
FU National Natural Science Foundation of China [61572240]
FX This work was funded by the National Natural Science Foundation of
   China, No. 61572240.
CR Abeo TA, 2019, PATTERN RECOGN, V90, P1, DOI 10.1016/j.patcog.2019.01.012
   Aïssa-El-Bey A, 2017, EURASIP J ADV SIG PR, DOI 10.1186/s13634-017-0459-y
   Aminu Muhammad, 2019, Journal of Physics: Conference Series, V1372, DOI 10.1088/1742-6596/1372/1/012002
   The AP, 2013, APPL INTELL, V39, P367, DOI 10.1007/s10489-012-0418-0
   [Anonymous], 2007, CVPR
   [Anonymous], 2017, P 2017 SIAM INT C DA
   [Anonymous], 2017, P MACH LEARN RES
   [Anonymous], 2009, P 26 ANN INT C MACHI, DOI DOI 10.1145/1553374.1553494
   Becker H, 2015, IEEE J BIOMED HEALTH, V21, P94
   Cai D, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P714
   Chaib S, 2016, IEEE GEOSCI REMOTE S, V13, P147, DOI 10.1109/LGRS.2015.2501383
   Chen J., 2007, INT C PARALLEL DISTR, P1
   Chen SB, 2019, NEURAL COMPUT APPL, V31, P6383, DOI 10.1007/s00521-018-3467-4
   Chung A, 2016, CRIT CARE MED, V44
   Datta A., 2017, ADV PRINCIPAL COMPON, P19, DOI DOI 10.1007/978-981-10-6704-4_2
   Ding C., 2006, P 23 INT C MACH LEAR, P281, DOI DOI 10.1145/1143844.1143880
   Eckart C, 1936, PSYCHOMETRIKA, V1, P211, DOI 10.1007/BF02288367
   Feng C-M, 2017, JOINT NORM CONSTRAIN
   Feng GY, 2008, NEURAL PROCESS LETT, V27, P247, DOI 10.1007/s11063-008-9073-1
   Goodenough D. G., 2009, 2009 1 WORKSH HYP IM, P1
   Hansen TJ, 2014, PATTERN RECOGN LETT, V49, P114, DOI 10.1016/j.patrec.2014.06.015
   He JR, 2019, J AMB INTEL HUM COMP, V10, P3249, DOI 10.1007/s12652-018-1096-5
   He ZN, 2020, INT J MACH LEARN CYB, V11, P603, DOI 10.1007/s13042-019-00999-2
   Huang KK, 2017, PATTERN RECOGN, V62, P87, DOI 10.1016/j.patcog.2016.08.024
   Huang P, 2015, AEU-INT J ELECTRON C, V69, P1724, DOI 10.1016/j.aeue.2015.08.009
   Huang S, 2015, PATTERN ANAL APPL, V18, P639, DOI 10.1007/s10044-014-0434-2
   López-Rubio FJ, 2018, ARTIF INTELL REV, V49, P407, DOI 10.1007/s10462-016-9525-3
   Jiang B, 2018, NEUROCOMPUTING, V275, P523, DOI 10.1016/j.neucom.2017.08.053
   Jiang B, 2013, PROC CVPR IEEE, P3492, DOI 10.1109/CVPR.2013.448
   Karami A, 2017, IET IMAGE PROCESS, V11, P767, DOI 10.1049/iet-ipr.2016.0554
   Karami A, 2011, IEEE J-STSP, V5, P487, DOI 10.1109/JSTSP.2011.2132692
   Koringa PA, 2019, PATTERN ANAL APPL, V22, P1481, DOI 10.1007/s10044-018-0745-9
   Lai ZH, 2017, IEEE T CYBERNETICS, V47, P3733, DOI 10.1109/TCYB.2016.2578642
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Li Y, 2017, 2017 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P94, DOI 10.1109/SPAC.2017.8304257
   Liang ZZ, 2013, PATTERN RECOGN LETT, V34, P1037, DOI 10.1016/j.patrec.2013.01.030
   Liu X, 2013, NEUROIMAGE, V83, P148, DOI 10.1016/j.neuroimage.2013.06.033
   Liu Y, 2019, NEURAL NETWORKS, V119, P85, DOI 10.1016/j.neunet.2019.07.015
   Lu Leng, 2012, Proceedings of the 2012 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR), P164, DOI 10.1109/ICWAPR.2012.6294772
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Luo F., 2016, P 25 INT JOINT C ART, P1802, DOI [10.5555/3060832.3060873, DOI 10.5555/3060832.3060873]
   Menon S, 2018, CHILDHOODS IN INDIA: TRADITIONS, TRENDS AND TRANSFORMATIONS, P1
   Mi JX, 2019, APPL INTELL, V49, P2169, DOI 10.1007/s10489-018-1382-0
   Monteiro JM, 2016, J NEUROSCI METH, V271, P182, DOI 10.1016/j.jneumeth.2016.06.011
   Narayanan Ram M., 2003, Geocarto Int., V18, P15
   Nie FP, 2014, PR MACH LEARN RES, V32, P1062
   Oh J, 2016, PATTERN RECOGN, V54, P116, DOI 10.1016/j.patcog.2016.01.002
   Pan YC, 2019, 2019 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI 2019), P1494, DOI 10.1109/SSCI44817.2019.9002887
   Park CH, 2005, SIAM J MATRIX ANAL A, V27, P87, DOI 10.1137/S0895479804442334
   Qian LQ, 2017, IET IMAGE PROCESS, V11, P190, DOI 10.1049/iet-ipr.2016.0254
   Ravi S, 2013, 5 INT C ADV REC TECH, P6
   Shen XJ, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107023
   Shi Q., 2017, IEEE Trans. Neural. Netw. Learn. Syst., V29, P4744
   Tang MF, 2017, NEUROCOMPUTING, V225, P58, DOI 10.1016/j.neucom.2016.11.012
   Tsai FS, 2011, EXPERT SYST APPL, V38, P2766, DOI 10.1016/j.eswa.2010.08.067
   Tu ShangTan., 2012, Geoscience and Remote Sensing, IEEE Transactions on, V50, P170, DOI DOI 10.1109/TGRS.2011.2168532
   Vaswani N, 2018, IEEE SIGNAL PROC MAG, V35, P32, DOI 10.1109/MSP.2018.2826566
   Wang D, 2020, IEEE ACCESS, V8, P81864, DOI 10.1109/ACCESS.2020.2990493
   Wang J., 2012, Geometric Structure of HighDimensional Data and Dimensionality Reduction, P51
   Wang J, 2016, IEEE T CYBERNETICS, V46, P792, DOI 10.1109/TCYB.2015.2416274
   Wang Q, 2016, NEUROCOMPUTING, V174, P18, DOI 10.1016/j.neucom.2015.03.116
   Wang SJ, 2018, IET COMPUT VIS, V12, P659, DOI 10.1049/iet-cvi.2017.0302
   Wen J, 2019, IEEE T CIRC SYST VID, V29, P390, DOI 10.1109/TCSVT.2018.2799214
   Wornyo DK, 2019, WORLD WIDE WEB, V22, P717, DOI 10.1007/s11280-018-0576-z
   Xing W, 2015, P ROY SOC A-MATH PHY, V471, DOI 10.1098/rspa.2014.0697
   Xu JP, 2009, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON MANAGEMENT SCIENCE AND ENGINEERING MANAGEMENT, P1
   Yang LB, 2020, IEEE ACCESS, V8, P44100, DOI 10.1109/ACCESS.2020.2978287
   Ye QL, 2018, NEURAL NETWORKS, V105, P393, DOI 10.1016/j.neunet.2018.05.020
   Yi S, 2019, IEEE T NEUR NET LEAR, V31, P2153
   Yi SY, 2017, 2017 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P13, DOI 10.1109/SPAC.2017.8304243
   Yi SY, 2017, PATTERN RECOGN, V61, P524, DOI 10.1016/j.patcog.2016.08.025
   Zhang CS, 2010, NEUROCOMPUTING, V73, P959, DOI 10.1016/j.neucom.2009.08.014
   Zhou YP, 2016, INT SYM COMPUT INTEL, P378, DOI [10.1109/ISCID.2016.2096, 10.1109/ISCID.2016.201]
NR 74
TC 2
Z9 2
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3809
EP 3833
DI 10.1007/s11042-020-09789-3
EA SEP 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572601100006
DA 2024-07-18
ER

PT J
AU da Fonseca, GB
   Sargent, G
   Sicre, R
   Patrocínio, ZKG
   Gravier, G
   Guimaraes, SJF
AF da Fonseca, Gabriel Barbosa
   Sargent, Gabriel
   Sicre, Ronan
   Patrocinio, Zenilton K. G., Jr.
   Gravier, Guillaume
   Guimaraes, Silvio Jamil F.
TI Hierarchical multi-label propagation using speaking face graphs for
   multimodal person discovery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia indexing; Multimodal fusion; Label propagation; Face
   recognition; Speaker recognition
ID FUSION; IDENTIFICATION; RECOGNITION
AB TV archives are growing in size so fast that manually indexing becomes unfeasible. Automatic indexing techniques can be applied to overcome this issue, and this work proposes an unsupervised technique for multimodal person discovery. To achieve this goal, we propose a hierarchical label propagation technique based on quasi-flat zones theory, that learns from labeled and unlabeled data and propagates names through a multimodal graph representation. In this representation, we combine audio, video, and text processing techniques to model the data as a graph ofspeaking faces. In the proposed modeling, we extract names via optical character recognition and propagate them through the graph using audiovisual relationships between speaking faces. We also use a random walk label propagation and two graph clustering strategies to serve as baselines. The proposed label propagation techniques always outperform the clustering baselines on the quantitative assessments. Our approach also outperforms all literature methods tested on the same dataset except for one, which uses a different preprocessing step. The proposed hierarchical label propagation and the random walk baseline produce highly equivalent results according to the Kappa coefficient, but the hierarchical propagation is parameter-free and over 9 times faster than the random walk under the same configurations.
C1 [da Fonseca, Gabriel Barbosa; Patrocinio, Zenilton K. G., Jr.; Guimaraes, Silvio Jamil F.] Pontificia Univ Catolica Minas Gerais, ImSci, BR-31980110 Belo Horizonte, MG, Brazil.
   [Sargent, Gabriel; Sicre, Ronan; Gravier, Guillaume] CNRS, IRISA, Campus Beaulieu, F-35042 Rennes, France.
C3 Pontificia Universidade Catolica de Minas Gerais; Centre National de la
   Recherche Scientifique (CNRS); Universite de Rennes
RP Guimaraes, SJF (corresponding author), Pontificia Univ Catolica Minas Gerais, ImSci, BR-31980110 Belo Horizonte, MG, Brazil.
EM gbrl12@gmail.com; gabriel.sargent@yahoo.fr;
   ronan.sicre@centrale-marseille.fr; zenilton@pucminas.br;
   guillaume.gravier@irisa.fr; sjamil@pucminas.br
RI Patrocínio, Zenilton K G/E-8913-2013; sicre, ronan/HNP-6960-2023;
   GUIMARAES, Silvio/C-7881-2014
OI Patrocínio, Zenilton K G/0000-0003-0804-1790; GUIMARAES,
   Silvio/0000-0001-8522-2056
FU Conselho Nacional de Desenvolvimento Cientifico e Tecnologico - CNPq
   [421521/2016-3, PQ 310075/2019-0]; Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior - CAPES [STIC-AmSUD MOTIf 001/2013];
   Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior - CAPES
   (STIC-AmSUD TRANSFORM) [88881.143258/2017-01]; Fundacao de Amparo a
   Pesquisa do Estado de Minas Gerais - FAPEMIG [PPM-00006-18,
   APQ-01806-13, CEX-APQ-03195-13]; STIC AmSud program, under the project
   "Unsupervised Mining of Multimedia Content"; INRIA Associate Team
   program; PUC Minas
FX The authors thank Conselho Nacional de Desenvolvimento Cientifico e
   Tecnologico - CNPq - (Universal 421521/2016-3 and PQ 310075/2019-0),
   Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior - CAPES -
   (Grant STIC-AmSUD MOTIf 001/2013 and STIC-AmSUD TRANSFORM
   88881.143258/2017-01) and Fundacao de Amparo a Pesquisa do Estado de
   Minas Gerais - FAPEMIG - (Grants PPM-00006-18, APQ-01806-13 and
   CEX-APQ-03195-13). This work was also partially supported by the STIC
   AmSud program, under the project "Unsupervised Mining of Multimedia
   Content", by the INRIA Associate Team program, and by PUC Minas..
CR [Anonymous], 2004, INT C SPOK LANG PROC
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Azab Mahmoud., 2018, Proceedings_of_the_Conference_of_the North_American_Chapter_of_the_Association_for_Computational_Linguistics:_Human Language_Technologies, P2206
   Bechat F, 2014, INTERSPEECH, P607
   Bernal EA, 2018, IEEE T MULTIMEDIA, V20, P107, DOI 10.1109/TMM.2017.2726187
   Betser M, 2004, P 8 INT C SPOK LANG, P333
   Bredin H, 2016, MED 2016 WORKSH
   Bredin H, 2014, INT J MULTIMED INF R, V3, P161, DOI 10.1007/s13735-014-0055-y
   Canseco L, 2005, 2005 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P415
   Cayllahua-Cahuina E, 2020, PATTERN RECOGN LETT, V131, P105, DOI 10.1016/j.patrec.2019.12.014
   Chen DT, 2005, PATTERN RECOGN LETT, V26, P1386, DOI 10.1016/j.patrec.2004.11.019
   Cousty J, 2018, J MATH IMAGING VIS, V60, P479, DOI 10.1007/s10851-017-0768-7
   Da Fonseca GB, 2017, P 15 INT WORKSH CONT, P15
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Dasarathy B., 1994, DECISION FUSION, V1994
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Dos Santos Jr CE, 2015, P MEDIAEVAL 2015 WOR
   Esteve Y., 2007, 8 ANN C INT SPEECH C, P2601
   Galibert O., 2013, 1 WORKSH SPEECH LANG
   Garcia-Romero D., 2011, INTERSPEECH
   Gay P, 2014, 12 INT WORKSH CONT B, P1
   Geng J, 2015, IEEE T MULTIMEDIA, V17, P498, DOI 10.1109/TMM.2015.2398195
   Houghton R, 1999, IEEE INTELL SYST APP, V14, P45, DOI 10.1109/5254.796089
   Hu YT, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1107, DOI 10.1145/2733373.2806293
   de Almeida CSJ, 2019, LECT NOTES COMPUT SC, V11752, P3, DOI 10.1007/978-3-030-30645-8_1
   Kahne J., 2012, Political Psychology, V34, P1
   Kakaletsis E, 2018, SIGNAL PROCESS-IMAGE, V67, P199, DOI 10.1016/j.image.2018.06.008
   Lahat D, 2015, P IEEE, V103, P1449, DOI 10.1109/JPROC.2015.2460697
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Le N, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095732
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1662, DOI 10.1109/TMM.2012.2199293
   Marti G, 2016, P MEDIAEVAL 2016 WOR
   Masuda N, 2017, PHYS REP, V716, P1, DOI 10.1016/j.physrep.2017.07.007
   Mauclair J., 2006, IEEE SPEAK LANG REC, P1
   Meignier S, 2016, P MEDIAEVAL 2016 WOR
   Najman L, 2006, IEEE T IMAGE PROCESS, V15, P3531, DOI 10.1109/TIP.2006.877518
   Nishi F, 2016, P MEDIAEVAL 2016 SOR
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Otero PL, 2016, P MEDIAEVAL 2016 WOR
   Pang L, 2015, IEEE T MULTIMEDIA, V17, P854, DOI 10.1109/TMM.2015.2419452
   Perret B, 2018, IEEE T IMAGE PROCESS, V27, P1676, DOI 10.1109/TIP.2017.2779604
   Perret B, 2015, LECT NOTES COMPUT SC, V9082, P39, DOI 10.1007/978-3-319-18720-4_4
   Pham PT, 2010, IEEE T MULTIMEDIA, V12, P13, DOI 10.1109/TMM.2009.2036232
   Pham PT, 2011, IEEE MULTIMEDIA, V18, P44, DOI 10.1109/MMUL.2011.22
   Pini S, 2019, MULTIMED TOOLS APPL, V78, P14007, DOI 10.1007/s11042-018-7040-z
   Poignant J, 2015, P MEDIAEVAL 2015 WOR
   Poignant J, 2017, MULTIMED TOOLS APPL, V76, P22547, DOI 10.1007/s11042-017-4730-x
   Poignant J, 2016, MULTIMED TOOLS APPL, V75, P8999, DOI 10.1007/s11042-015-2723-1
   Poignant J, 2015, IEEE-ACM T AUDIO SPE, V23, P57, DOI 10.1109/TASLP.2014.2367822
   Raymond C, 2013, INT CONF ACOUST SPEE, P8475, DOI 10.1109/ICASSP.2013.6639319
   Razavian A. S., 2016, ITE Trans. Media Technol. Appl., V4, P251, DOI [DOI 10.3169/MTA.4.251, 10.3169/mta.4.251]
   Rohrbach A, 2017, PROC CVPR IEEE, P4196, DOI 10.1109/CVPR.2017.447
   Rouvier M, 2013, INTERSPEECH, P1476
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P586, DOI 10.1109/TMM.2012.2188784
   Satoh S, 1999, IEEE MULTIMEDIA, V6, P22, DOI 10.1109/93.752960
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sicre R, 2017, IEEE INT CONF COMP V, P1059, DOI 10.1109/ICCVW.2017.129
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Somandepalli K, 2018, IEEE T MULTIMEDIA, V20, P539, DOI 10.1109/TMM.2017.2745712
   Tolias G., 2016, Conference Track Proceedings,
   Tranter SE, 2006, 2006 IEEE ICASSP, V1, pI
   Vallet F, 2013, IEEE T MULTIMEDIA, V15, P509, DOI 10.1109/TMM.2012.2233724
   Nguyen VT, 2016, PROC INT CONF ADV, P169, DOI 10.1109/ATC.2016.7764767
   Wu J, 2017, IEEE T MULTIMEDIA, V19, P1156, DOI 10.1109/TMM.2017.2652065
   Xiong C, 2014, IEEE T MULTIMEDIA, V16, P1473, DOI 10.1109/TMM.2014.2316475
   Yang J, 2005, Proceedings of the 2005 International Conference on Active Media Technology (AMT 2005), P28
   Yang J, 2004, IEEE IMAGE PROC, P805
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Zhang X, 2012, IEEE T MULTIMEDIA, V14, P995, DOI 10.1109/TMM.2012.2186121
   Zhang YF, 2016, IEEE T IMAGE PROCESS, V25, P5780, DOI 10.1109/TIP.2016.2601491
   Zhou DY, 2004, ADV NEUR IN, V16, P321
   Zhu Xiaojin Jerry, 2008, Semi-supervised learning literature survey
   Zoidi O, 2014, IEEE T MULTIMEDIA, V16, P1358, DOI 10.1109/TMM.2014.2315595
NR 76
TC 3
Z9 3
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2797
EP 2820
DI 10.1007/s11042-020-09692-x
EA SEP 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000570470300003
DA 2024-07-18
ER

PT J
AU Li, HJ
   Li, CB
   Ding, YP
AF Li, Hongjun
   Li, Chaobo
   Ding, Yupeng
TI Fall detection based on fused saliency maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fall detection; Saliency maps; Fusion; Deep network
ID OBJECT DETECTION; SYSTEM
AB Fall detection is drawing more attention from both academia and industry. The human body occupies smaller space relative to the background in images, so the complex background affects the extraction of human fall or non-fall features. In order to reduce the interference of the complex background, a fall detection method based on fused saliency maps is proposed, which consists of saliency maps generation model and fall detection model. For saliency maps generation model, M-level segmentation is to obtain segmented images in different level. The saliency detection mainly uses two-stream convolutional neural network extract global and local features to generate the saliency maps. The saliency maps fusion automatically learns the weights according to mean structural similarity for fusing saliency maps. For fall detection model, a simple deep network is constructed to extract the discriminant features of fall or non-fall, where the fused saliency maps is used. Experimental result show that the proposed method achieves 99.67% and 98.92% accuracy on UR Fall Detection and our self-built NT Fall Detection database, respectively. And the convergence speed is fastest compared with those of using RGB images and depth images. The proposed fall detection method that can reduce the interference of complex background outperforms the other methods in terms of higher accuracy and faster convergence.
C1 [Li, Hongjun; Li, Chaobo] Nantong Univ, Sch Informat Sci & Technol, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.
   [Li, Hongjun] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
   [Li, Hongjun] Nantong Res Inst Adv Commun Technol, Nantong 226019, Jiangsu, Peoples R China.
   [Li, Hongjun] TONGKE Sch Microelect, Nantong 226019, Jiangsu, Peoples R China.
   [Ding, Yupeng] China Mobile Commun Grp Co Ltd, Taizhou 225300, Jiangsu, Peoples R China.
C3 Nantong University; Nanjing University; China Mobile
RP Li, HJ (corresponding author), Nantong Univ, Sch Informat Sci & Technol, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.; Li, HJ (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.; Li, HJ (corresponding author), Nantong Res Inst Adv Commun Technol, Nantong 226019, Jiangsu, Peoples R China.; Li, HJ (corresponding author), TONGKE Sch Microelect, Nantong 226019, Jiangsu, Peoples R China.
EM lihongjun@ntu.edu.cn; 1811310007@yjs.ntu.edu.cn; 16110027@yjs.ntu.edu.cn
RI Li, Hongjun/J-7912-2019
OI Li, Hongjun/0000-0001-7500-4979; Li, Chaobo/0000-0003-3772-3344
FU National Natural Science Foundation of China [61871241, 61976120];
   Science and Technology Program of Nantong [JC2018025, JC2018129];
   Nantong University-Nantong Joint Research Center for Intelligent
   Information Technology [KFKT2017B04]; Nanjing University State Key Lab
   [KFKT2019B15]; Postgraduate Research and Practice Innovation Program of
   Jiangsu Province [KYCX19_2056]
FX This work is supported by National Natural Science Foundation of China
   (NO.61871241, NO.61976120);the Science and Technology Program of Nantong
   (JC2018025, JC2018129); Nantong University-Nantong Joint Research Center
   for Intelligent Information Technology (KFKT2017B04); Nanjing University
   State Key Lab. for Novel Software Technology (KFKT2019B15); Postgraduate
   Research and Practice Innovation Program of Jiangsu Province
   (KYCX19_2056).
CR Abualigah L. M. Q., 2019, Feature selection and enhanced krill herd algorithm for text document clustering, DOI [DOI 10.1007/978-3-030-10674-4, 10.1007/978-3-030-10674-4]
   Abualigah LM, 2018, APPL INTELL, V48, P4047, DOI 10.1007/s10489-018-1190-6
   Alzahrani MS, 2019, SIGNAL IMAGE VIDEO P, V13, P1431, DOI 10.1007/s11760-019-01490-9
   Bet P, 2019, INT J MED INFORM, V130, DOI 10.1016/j.ijmedinf.2019.08.006
   Cai X, 2020, IEEE ACCESS, V8, P44493, DOI 10.1109/ACCESS.2020.2978249
   Casilari-Pérez E, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.07.028
   Chen YB, 2020, J CONTEMP CHINA, V29, P1, DOI [10.1080/10670564.2019.1621526, 10.1080/01932691.2020.1791172, 10.1007/s12652-020-02066-z]
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Chung KL, 2019, SENSOR MATER, V31, P2657, DOI 10.18494/SAM.2019.2438
   Dhiman C, 2020, IEEE T IMAGE PROCESS, V29, P3835, DOI 10.1109/TIP.2020.2965299
   Ezatzadeh S, 2019, MULTIMED TOOLS APPL, V78, P25515, DOI 10.1007/s11042-019-7720-3
   Ge CJ, 2017, IEEE INT WORKS MACH
   Ge CJ, 2018, IEEE ENG MED BIO, P1572, DOI 10.1109/EMBC.2018.8512586
   Harrou F, 2017, IEEE INSTRU MEAS MAG, V20, P49, DOI 10.1109/MIM.2017.8121952
   Hasan Md Mahedi, 2019, 2019 IEEE International Conference on Robotics, Automation, Artificial-intelligence and Internet-of-Things (RAAICON), P48, DOI 10.1109/RAAICON48939.2019.23
   Huo SW, 2019, IEEE T NEUR NET LEAR, V30, P225, DOI 10.1109/TNNLS.2018.2809702
   Jansi R, 2020, MULTIDIM SYST SIGN P, V31, P1207, DOI 10.1007/s11045-020-00705-4
   Khraief C, 2020, MULTIMED TOOLS APPL, V79, P19537, DOI 10.1007/s11042-020-08812-x
   Kong YQ, 2019, J VIS COMMUN IMAGE R, V59, P215, DOI 10.1016/j.jvcir.2019.01.024
   Kwolek B, 2015, NEUROCOMPUTING, V168, P637, DOI 10.1016/j.neucom.2015.05.061
   Kwolek B, 2014, COMPUT METH PROG BIO, V117, P489, DOI 10.1016/j.cmpb.2014.09.005
   Li C. B., 2017, CISP BMEI
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li JX, 2018, IET IMAGE PROCESS, V12, P400, DOI 10.1049/iet-ipr.2017.0251
   Li X, 2018, IEEE INT VAC ELECT C, P335, DOI 10.1109/IVEC.2018.8391513
   Lie WN, 2019, PROC SPIE, V11049, DOI 10.1117/12.2521623
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu W, 2017, AIP CONF PROC, V1794, DOI 10.1063/1.4971938
   Lu N, 2019, IEEE J BIOMED HEALTH, V23, P314, DOI 10.1109/JBHI.2018.2808281
   Luvizon DC, 2021, IEEE T PATTERN ANAL, V43, P2752, DOI 10.1109/TPAMI.2020.2976014
   Min WD, 2018, IET COMPUT VIS, V12, P1133, DOI 10.1049/iet-cvi.2018.5324
   Núñez-Marcos A, 2017, WIREL COMMUN MOB COM, DOI 10.1155/2017/9474806
   Peterson AB, 2020, MMWR-MORBID MORTAL W, V69, P225, DOI 10.15585/mmwr.mm6909a2
   Qiu Y, 2020, NEUROCOMPUTING, V388, P124, DOI 10.1016/j.neucom.2019.12.123
   Silva R, 2019, IEEE INT CONF AUTON, P194
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Wang JD, 2017, INT J COMPUT VISION, V123, P251, DOI 10.1007/s11263-016-0977-3
   Wang WG, 2019, PROC CVPR IEEE, P5961, DOI 10.1109/CVPR.2019.00612
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Yang R, 2019, ARXIV190409146
   Yun YX, 2015, IEEE IMAGE PROC, P3280, DOI 10.1109/ICIP.2015.7351410
   Zerrouki N, 2018, MULTIMED TOOLS APPL, V77, P6405, DOI 10.1007/s11042-017-4549-5
   Zhang DW, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3158674
   Zhang LG, 2020, NEURAL COMPUT APPL, V32, P1949, DOI 10.1007/s00521-019-04491-4
   Zhang LH, 2019, NEUROCOMPUTING, V340, P42, DOI 10.1016/j.neucom.2019.02.041
   Zhao Ting, 2019, IEEE C COMP VIS PATT, P3085, DOI DOI 10.48550/ARXIV.1903.00179
NR 48
TC 19
Z9 20
U1 7
U2 72
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 1883
EP 1900
DI 10.1007/s11042-020-09708-6
EA SEP 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568184100005
DA 2024-07-18
ER

PT J
AU Wang, HM
   Liu, PZ
AF Wang, Hongmei
   Liu, Pengzhong
TI Image recognition based on improved convolutional deep belief network
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image recognition; Convolutional deep belief network; Convolutional
   restricted boltzmann machine; Homogeneity; Gradient diffusion
AB Aiming at the homogeneity of convolution kernels in Convolutional Deep Belief Network (CDBN), a cross-entropy-based sparse penalty mechanism suitable for Convolutional Restricted Boltzmann Machine (CRBM) model is introduced which makes the hidden layer units of the whole network in a lower activation state. On this basis, a parameter learning algorithm is applied to compensate the gradient by introducing the prior information of the samples, which alternates the supervised learning and unsupervised learning. The experimental results show that the proposed model can weaken the homogeneity of convolution kernels and improve the supervising and predicting ability of the network. The recognition rate on simulated dataset achieves 97.45%, which is increased 5.12% and 1.29% than Convolutional Neural Network (CNN) and the traditional CDBN model, respectively. At the same time, test error rate on common dataset MNIST also shows that the proposed model is more effective than some other state-of-the-art deep learning models.
C1 [Wang, Hongmei; Liu, Pengzhong] Northwestern Polytech Univ, Sch Astronaut, Xian, Peoples R China.
   [Wang, Hongmei; Liu, Pengzhong] Northwestern Polytech Univ, Natl Key Lab Aerosp Flight Dynam, Xian, Peoples R China.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University
RP Wang, HM (corresponding author), Northwestern Polytech Univ, Sch Astronaut, Xian, Peoples R China.; Wang, HM (corresponding author), Northwestern Polytech Univ, Natl Key Lab Aerosp Flight Dynam, Xian, Peoples R China.
EM haipw@nwpu.edu.cn
FU National Natural Science Foundation of China [61771400]; Key Research
   and Development Program of Shaanxi Province [2020GY-014]; Seed
   Foundation of Innovation and Creation for Graduate Students in
   Northwestern Polytechnical University [ZZ2018061]
FX This work is jointly supported by the National Natural Science
   Foundation of China (No. 61771400), the Key Research and Development
   Program of Shaanxi Province (No. 2020GY-014) and the Seed Foundation of
   Innovation and Creation for Graduate Students in Northwestern
   Polytechnical University (No. ZZ2018061). The authors would like to
   thank the editors and the anonymous reviewers for their valuable
   comments and helpful suggestions.
CR [Anonymous], 2015, COMPUT THERM SCI
   [Anonymous], 2008, ADV NEURAL INFORM PR
   Bai S, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417550138
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Chen SZ, 2016, IEEE T GEOSCI REMOTE, V54, P4806, DOI 10.1109/TGRS.2016.2551720
   Diao WH, 2016, IEEE GEOSCI REMOTE S, V13, P137, DOI 10.1109/LGRS.2015.2498644
   Hinton G. E., 2012, Neural networks: tricks of the trade, P599
   Jaderberg M, 2015, ADV NEUR IN, V28
   [焦李成 Jiao Licheng], 2016, [计算机学报, Chinese Journal of Computers], V39, P1697
   Kingma DP, 2014, ADV NEUR IN, V27
   Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295
   Li JF, 2016, SPECTROSC SPECT ANAL, V36, P3261, DOI 10.3964/j.issn.1000-0593(2016)10-3261-04
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Liu Kai, 2015, Journal of Zhejiang University. Engineering Science, V49, P1070, DOI 10.3785/j.issn.1008-973X.2015.06.010
   Springenberg Jost Tobias, 2015, Striving for simplicity: The all convolutional net, DOI DOI 10.48550/ARXIV.1412.6806
   Teng W, 2014, NANOTECHNOLOGY, V25, DOI 10.1088/0957-4484/25/6/065702
   Tieleman T., 2008, P 25 INT C MACHINE L, V307, P1064, DOI 10.1145/1390156
   Tieleman T, 2009, P 26 ANN INT C MACH, P1064
   Tong GF, 2017, C IND ELECT APPL, P1757, DOI 10.1109/ICIEA.2017.8283123
   Yang S, 2015, AAAI CONF ARTIF INTE, P3848
   Yang ZC, 2015, IEEE I CONF COMP VIS, P1476, DOI 10.1109/ICCV.2015.173
   Yin Bao-cai, 2015, Journal of Beijing University of Technology, V41, P48, DOI 10.11936/bjutxb2014100026
   Yu K, 2015, J COMPUT RES DEV, V50, P1799
NR 23
TC 4
Z9 5
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2031
EP 2045
DI 10.1007/s11042-019-08300-x
EA SEP 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568765500001
DA 2024-07-18
ER

PT J
AU Qi, H
   Xue, MZ
   Peng, XL
   Wang, C
   Jiang, Y
AF Qi, Hong
   Xue, Mingzhu
   Peng, Xianglong
   Wang, Chong
   Jiang, Yu
TI Dolphin movement direction recognition using contour-skeleton
   information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Dolphin movement; Direction recognition
ID TRACKING
AB Detecting and tracking social marine mammals, including dolphins, can help to explain their social dynamics, predict their behavior, and measure the impact of human interference. The underwater environment is very special and different from the land environment: acoustic recorders are the main equipment for researchers to track dolphins at a long distance. Close-range detection of visual data is often seriously affected by the underwater environment, because the underwater environment is highly dynamic and the light source has attenuation in the deep water. Nonetheless, compared with acoustic information, visual data can provide more detailed information at low cost. The videos and images of dolphins provide researchers with great convenience in studying the body structure and social behavior of dolphins. At the same time, dolphin movement direction recognition helps researchers to learn more about dolphins through a series of accurate movement data. In this paper, we proposed an approach to detect the movement direction of dolphins effectively. First, the contours and skeletons are detected, which could reduce the impact of wrong detections significantly. And then another CNN-based model obtains the movement directions with feature images extracted from the previous steps. The experiment result shows the correctness and efficiency of the proposed method.
C1 [Qi, Hong; Xue, Mingzhu; Peng, Xianglong; Wang, Chong; Jiang, Yu] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Qi, Hong] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
C3 Jilin University; Jilin University
RP Jiang, Y (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
EM jiangyu2011@jlu.edu.cn
RI Chen, YiJun/KFS-9282-2024
FU National Natural Science Foundation of China [51679105, 51809112,
   51939003]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 51679105, Grant 51809112, and Grant 51939003.
CR Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Arnab A, 2017, PROC CVPR IEEE, P879, DOI 10.1109/CVPR.2017.100
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343
   Eichner M, 2010, LECT NOTES COMPUT SC, V6311, P228, DOI 10.1007/978-3-642-15549-9_17
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Gkioxari G, 2014, PROC CVPR IEEE, pCP32, DOI 10.1109/CVPR.2014.458
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hosang J, 2016, IEEE T PATTERN ANAL, V38, P814, DOI 10.1109/TPAMI.2015.2465908
   Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3
   Jiang Y, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102225
   Karnowski J, 2015, 2015 IEEE WINTER APPLICATIONS AND COMPUTER VISION WORKSHOPS (WACVW), P51, DOI 10.1109/WACVW.2015.10
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li H, 2019, TRAIT SIGNAL, V36, P439, DOI 10.18280/ts.360509
   PAPANIKOLOPOULOS NP, 1993, IEEE T AUTOMAT CONTR, V38, P429, DOI 10.1109/9.210141
   Pinheiro PO, 2015, ADV NEUR IN, V28
   Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533
   Prasad B, 2015, 2015 IEEE UNDERWATER, P1, DOI DOI 10.1109/UT.2015.7108300
   Qin HD, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1271-6
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronchi MR, 2017, IEEE I CONF COMP VIS, P369, DOI 10.1109/ICCV.2017.48
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Sattar J, 2009, IEEE INT CONF ROBOT, P133
   Wajeed MA, 2019, TRAIT SIGNAL, V36, P445, DOI 10.18280/ts.360510
   Wiggins SM, 2013, J ACOUST SOC AM, V133, P3813, DOI 10.1121/1.4802645
   Wiggins SM, 2012, J ACOUST SOC AM, V131, P156, DOI 10.1121/1.3662076
   Yu SC, 2001, OCEANS 2001 MTS/IEEE: AN OCEAN ODYSSEY, VOLS 1-4, CONFERENCE PROCEEDINGS, P409, DOI 10.1109/OCEANS.2001.968760
   Zhao MH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020350
NR 28
TC 1
Z9 1
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21907
EP 21923
DI 10.1007/s11042-020-09659-y
EA SEP 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000566871700001
DA 2024-07-18
ER

PT J
AU Qiu, YG
   Duan, HT
AF Qiu, Yinguo
   Duan, Hongtao
TI A novel multi-stage watermarking scheme of vector maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vector map; Multi-stage watermarking; Data distribution; Multi-copyright
   protection
ID MULTIPLE WATERMARKING; ROBUST
AB Vector maps are distributed frequently among various departments and subscribers, and traditional single-stage watermarking technology cannot provide powerful multi-copyright protection of them. In this paper, a novel multi-stage watermarking algorithm is proposed for vector maps, aiming at robustness enhancement and maximum-supported watermark capacity improvement. A watermark generation method is designed based on QR code to shorten watermark length, and watermarks are embedded into polar coordinates of map vertices so as to improve the robustness of the proposed scheme. Another method of copyright information combination is raised to keep watermark length invariant along with the increasing of the total stages of watermark data, and the maximum-supported stages of watermarks can be thus improved without affecting the robustness of watermarking algorithm. Moreover, each stage of copyright information occupies a specified space within the final watermark data, and non-interference among various watermarks can be guaranteed and different copyright data can be efficiently distinguished after watermark extraction. Compared with the existing researches, the proposed scheme can increase effectively the size of maximum-supported watermark capacity, and it has strong robustness under common geometric and non-geometric attacks, which have been validated by both theoretical analysis and comprehensive experiments.
C1 [Qiu, Yinguo; Duan, Hongtao] Chinese Acad Sci, Key Lab Watershed Geog Sci, Nanjing Inst Geog & Limnol, Nanjing 210008, Peoples R China.
C3 Chinese Academy of Sciences; Nanjing Institute of Geography & Limnology,
   CAS
RP Qiu, YG (corresponding author), Chinese Acad Sci, Key Lab Watershed Geog Sci, Nanjing Inst Geog & Limnol, Nanjing 210008, Peoples R China.
EM ygqiu@niglas.ac.cn
RI Qiu, Yinguo/IZD-6490-2023; Duan, Hongtao/B-7210-2011
OI Duan, Hongtao/0000-0002-1985-2292
FU Talent Start-up Project of NIGLAS [NIGLAS2018QD07]; Major Science and
   Technology Program for Water Pollution Control and Treatment
   [2017ZX07603001]
FX This work was supported in part by the Talent Start-up Project of NIGLAS
   under Grant NIGLAS2018QD07, and in part by the Major Science and
   Technology Program for Water Pollution Control and Treatment under Grant
   2017ZX07603001.
CR Abuturab MR, 2017, OPT LASER ENG, V89, P47, DOI 10.1016/j.optlaseng.2016.02.014
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   [Anonymous], 2014, THESIS
   Bhatnagar G, 2015, MULTIMED TOOLS APPL, V74, P8421, DOI 10.1007/s11042-013-1681-8
   Cao Y., 2016, J. South China Norm. Univ. (Nat. Sci. Ed.), V48, P69
   Cui H, 2013, THESIS
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Golea Nour El-Houda, 2019, International Journal of High Performance Computing and Networking, V13, P199
   Jian-Guo Sun, 2014, International Journal of Network Security, V16, P40
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   [李强 Li Qiang], 2011, [测绘科学, Science of Surveying and Mapping], V36, P119
   Li S, 2019, IEEE T IMAGE PROCESS, V28, P1482, DOI 10.1109/TIP.2018.2878290
   Liang W., 2018, Acta Sci. Naturaum Univ. Sunyatseni, V57, P7
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Peng YW, 2018, MULTIMED TOOLS APPL, V77, P7239, DOI 10.1007/s11042-017-4631-z
   Qiu YG, 2019, MULTIMED TOOLS APPL, V78, P24955, DOI 10.1007/s11042-019-7681-6
   Qiu YG, 2018, MULTIMED TOOLS APPL, V77, P6385, DOI 10.1007/s11042-017-4546-8
   Qu Z., 2019, INT J HIGH PERFORM C, V14, P121, DOI [10.1504/IJHPCN.2019.10022723, DOI 10.1504/IJHPCN.2019.10022723]
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Singh RK, 2018, J INFORM OPTIM SCI, V39, DOI 10.1080/02522667.2017.1372153
   Sleit A, 2012, IMAGING SCI J, V60, P29, DOI 10.1179/1743131X11Y.0000000010
   [孙建国 Sun Jianguo], 2010, [哈尔滨工程大学学报, Journal of Harbin Engineering University], V31, P488
   Tao JY, 2019, IEEE T CIRC SYST VID, V29, P594, DOI 10.1109/TCSVT.2018.2881118
   Vybornova YD, 2017, COMPUT OPT, V41, P913, DOI 10.18287/2412-6179-2017-41-6-913-919
   Wang YY, 2018, INFORMATION, V9, DOI 10.3390/info9120296
   Wang YY, 2018, MULTIMED TOOLS APPL, V77, P19261, DOI 10.1007/s11042-017-5358-6
   Xiong LZ, 2016, MULTIMED TOOLS APPL, V75, P5377, DOI 10.1007/s11042-015-2504-x
   [杨成松 YANG Chengsong], 2010, [中国图象图形学报, Journal of Image and Graphics], V15, P684
   Zhang LM, 2016, J GEOM, V41, P32, DOI [10.14188/J.2095-6045.2016.05.008, DOI 10.14188/J.2095-6045.2016.05.008]
   [朱长青 Zhu Changqing], 2017, [测绘学报, Acta Geodetica et Cartographica Sinica], V46, P1609
NR 31
TC 6
Z9 7
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 877
EP 897
DI 10.1007/s11042-020-09776-8
EA SEP 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566318900007
DA 2024-07-18
ER

PT J
AU Mittal, M
   Kumar, M
   Verma, A
   Kaur, I
   Kaur, B
   Sharma, M
   Goyal, LM
AF Mittal, Mamta
   Kumar, Munish
   Verma, Amit
   Kaur, Iqbaldeep
   Kaur, Bhavneet
   Sharma, Meenakshi
   Goyal, Lalit Mohan
TI FEMT: a computational approach for fog elimination using multiple
   thresholds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fog Removal; Multiple Thresholds; Image Enhancement; Visibility
   Restoration
ID ALGORITHM; ENHANCEMENT; VISIBILITY; HAZE
AB Refining visibility through haze removal from image becomes an inevitable chore and essential to recognize and track vehicles, traffic signal, and signs clearly under road safety. That can face a recurrent degradation under destitute climatic circumstances for instance fog, rain, cloud, and smog. To diminish this constraint, various methods were designed and implemented, but most were not capable of obtaining the improved quantitative outcomes. Therefore, a new algorithm Fog Elimination using Multiple Thresholds (FEMT) for single image haze eviction that meritoriously obtains the significant results on both gray and colored over real and synthetic images using multiple thresholds is proposed in this paper. The proposed method targets on the light regions by reducing the brightness and increasing the contrast of image at different levels. Finally, by grouping all the obtained resultant images leads to the generation of the resultant defogged image. The qualitative and quantitative analysis is carried out for an assessment of digitalized de-hazed images acquired from the proposed algorithm and compared to the prior techniques. Simulated fallouts entitle high resemblance to the corresponding ground truth, reduction in computation time consumption to 88% and error of 98%. The proposed approach can be applied in the field of robotics, human activity monitoring, smart systems, and digital investigation on the hazy images.
C1 [Mittal, Mamta] GB Pant Govt Engn Coll, Dept Comp Sci & Engn, New Delhi, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
   [Verma, Amit; Kaur, Iqbaldeep] Chandigarh Grp Coll, Dept Comp Sci & Engn, Mohali, India.
   [Kaur, Bhavneet; Sharma, Meenakshi] Chandigarh Univ, Univ Inst Comp, Mohali, Punjab, India.
   [Goyal, Lalit Mohan] JC Bose Univ Sci & Technol, Dept Comp Engn, YMCA, Faridabad, India.
C3 Chandigarh University; J.C. Bose University of Science & Technology,
   YMCA
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM munishcse@gmail.com
RI Mittal, Mamta/AAC-2229-2020; Kaur, Bhavneet/IZE-0785-2023; Kumar,
   Munish/P-7756-2018; Sharma, Meenakshi/AAW-5493-2021; GOYAL, LALIT
   MOHAN/AAH-4030-2020
OI Mittal, Mamta/0000-0003-0490-4413; Kumar, Munish/0000-0003-0115-1620;
   GOYAL, LALIT MOHAN/0000-0003-4618-0281
CR Ali M, 2018, EXPERT SYST APPL, V91, P434, DOI 10.1016/j.eswa.2017.09.027
   Ancuti CO, 2016, IEEE C IM PROC, P1
   Ancuti CO, 2011, LECT NOTES COMPUT SC, V6493, P501
   [Anonymous], 2008, ACM T GRAPH
   Anwar I, 2017, ENG SCI TECHNOL INT
   Economopoulos TL, 2010, IMAGE VISION COMPUT, V28, P45, DOI 10.1016/j.imavis.2009.04.011
   Eksioglu EM, 2014, EXPERT SYST APPL, V41, P3682, DOI 10.1016/j.eswa.2013.11.036
   Ganeshan VRP, 2014, INT C ADV EL ENG
   Hassan MK, 2018, NEURAL COMPUT APPL
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Huang SC, 2014, IEEE T INTELL TRANSP, V15, P2321, DOI 10.1109/TITS.2014.2314696
   Issac A, 2018, NEURAL COMPUT APPL, V6789
   Kala R, 2017, NEURAL COMPUT
   Kim JH, 2017, EXPERT SYST APPL, V87, P252, DOI 10.1016/j.eswa.2017.06.015
   Kratz L, 2009, IEEE I CONF COMP VIS, P1701, DOI 10.1109/ICCV.2009.5459382
   Li C, 2014, INT SYM COMPUT INTEL, P417, DOI 10.1109/ISCID.2014.198
   Li Li., 2016, Neural Computing and Applications, P1
   Liu CX, 2014, PROCEEDINGS OF 2014 IEEE INTERNATIONAL CONFERENCE ON PROGRESS IN INFORMATICS AND COMPUTING (PIC), P373, DOI 10.1109/PIC.2014.6972360
   Mahajan T, 2017, ADV COMPUT SCI TECHN, V10, P1327
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Sun C., 2016, IEEE T SYST MAN CYB, VPP, P1, DOI 10.1109/TSMC.2016.2557223
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tarel JP, 2012, IEEE INTEL TRANSP SY, V4, P6, DOI 10.1109/MITS.2012.2189969
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Tarel JP, 2010, IEEE INT VEH SYM, P478, DOI 10.1109/IVS.2010.5548128
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
   Zhang SD, 2020, VISUAL COMPUT, V36, P305, DOI 10.1007/s00371-018-1612-9
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 31
TC 4
Z9 4
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 227
EP 241
DI 10.1007/s11042-020-09657-0
EA SEP 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000565163400007
DA 2024-07-18
ER

PT J
AU Permatasari, J
   Connie, T
   Ong, TS
AF Permatasari, Jessica
   Connie, Tee
   Ong, Thian Song
TI Inertial sensor fusion for gait recognition with symmetric positive
   definite Gaussian kernels analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Covariance matrices; Extreme learning machines (ELMs); Gaussian kernel;
   Riemannian manifold; Sensor fusion
ID CLASSIFICATION; PATTERN
AB Wearable sensor-based gait recognition has received much interest because it is unobtrusive and is user friendly. Many research has been carried out in this area but conventional gait recognition methods are not free from drawbacks. In this paper, accelerometer and gyroscope signals representing gait movements are encoded using covariance matrices. The covariance matrices provide a compact and descriptive representation for the accelerometer and gyroscope signals. Non-singular covariance matrices are inherently Symmetric Positive Define (SPD) matrices. Interpreting such SPD matrices as points on the Riemannian manifold leads to increased performance. However, direct geodesic distance calculation for the matrix manifold may yield a suboptimal result. The proposed method solves this issue by embedding the manifold valued points to a higher dimensional Reproducing Kernel Hilbert Space (RKHS) via Positive Definite Gaussian Kernel functions. Extensive experiments have been conducted on three challenging benchmark datasets and a self-collected dataset. Experiment results testify the performance of the proposed RKHS embedding approach.
C1 [Permatasari, Jessica; Connie, Tee; Ong, Thian Song] Multimedia Univ, Fac Informat Sci & Technol, Jalan Ayer Keroh Lama, Melaka 75450, Malaysia.
C3 Multimedia University
RP Connie, T (corresponding author), Multimedia Univ, Fac Informat Sci & Technol, Jalan Ayer Keroh Lama, Melaka 75450, Malaysia.
EM 1171402368@student.mmu.edu.my; tee.connie@mmu.edu.my; tsong@mmu.edu.my
RI ; Ong, Thian Song/Q-6932-2018
OI Tee, Connie/0000-0002-0901-3831; Ong, Thian Song/0000-0002-5867-9517
CR Ailisto H, 2005, PROC SPIE, V5779, P7, DOI 10.1117/12.603331
   Asuncion LVR, 2018, I C HUMANOID NANOTEC, DOI 10.1109/HNICEM.2018.8666422
   Ayrulu-Erdem B, 2011, SENSORS-BASEL, V11, P1721, DOI 10.3390/s110201721
   Cherian A, 2014, LECT NOTES COMPUTER
   Connie T, 2017, IEEE T CYBERN
   Dawar N, 2018, IEEE INT CONF CON AU, P482, DOI 10.1109/ICCA.2018.8444326
   Dehzangi O, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122735
   Derawi Mohammad O., 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P312, DOI 10.1109/IIHMSP.2010.84
   Dey Sanorita., 2014, Accelprint: Imperfections of accelerometers make smartphones trackable
   Ehatisham-Ul-Haq M, 2019, IEEE ACCESS
   Fukuchi CA, 2019, SYST REV-LONDON, V8, DOI 10.1186/s13643-019-1063-z
   Gadaleta M, 2018, PATTERN RECOGN, V74, P25, DOI 10.1016/j.patcog.2017.09.005
   Gravina R, 2017, INF FUSION
   Guo K, 2010, P IEEE INT C ADV VID
   Harandi M. T., 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P433, DOI 10.1109/WACV.2012.6163005
   Harandi M, 2018, IEEE T PATTERN ANAL, V40, P48, DOI 10.1109/TPAMI.2017.2655048
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Jain A, 2018, EXPERT SYST APPL
   Jansi R, 2019, MULTIMED TOOLS APPL, V78, P11027, DOI 10.1007/s11042-018-6662-5
   Jayasumana S., 2015, IEEE T PATTERN ANAL
   Kasun LLC, 2016, IEEE T IMAGE PROCESS
   Malawski F, 2018, MULTIMED TOOLS APPL, V77, P23825, DOI 10.1007/s11042-018-5696-z
   Mannini A, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010134
   Merat P, 2018, P IEEE NAT AER EL C
   Mufandaidza MP, 2018, P IECON 2018 44 ANN
   Murray M P, 1967, Am J Phys Med, V46, P290
   Nandy A, 2019, MULTIMED TOOLS APPL, V78, P19697, DOI 10.1007/s11042-019-7310-4
   Nweke HF, 2019, INFORM FUSION, V46, P147, DOI 10.1016/j.inffus.2018.06.002
   Pannurat N., 2017, SENSORS
   Permatasari J, 2020, MMUISD GAIT DATABASE
   Poh N, 2010, MULTIMODAL SIGNAL PROCESSING: THEORY AND APPLICATIONS FOR HUMAN-COMPUTER INTERACTION, P153, DOI 10.1016/B978-0-12-374825-6.00017-4
   Qi MB, 2019, MULTIMED TOOLS APPL, V78, P27029, DOI 10.1007/s11042-017-4649-2
   Qiu S, 2018, INF FUSION
   Rahman MW, 2019, J ARTIF INTELL SOFT
   Reyes-Ortiz JL, 2016, NEUROCOMPUTING, V171, P754, DOI 10.1016/j.neucom.2015.07.085
   Shoaib M, 2014, SENSORS-BASEL, V14, P10146, DOI 10.3390/s140610146
   Stisen A, 2015, SENSYS'15: PROCEEDINGS OF THE 13TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P127, DOI 10.1145/2809695.2809718
   Subramanian R., 2018, IEEE T INF FORENSICS, V14
   Tao WJ, 2012, SENSORS-BASEL, V12, P2255, DOI 10.3390/s120202255
   Hoang T, 2014, SCI WORLD J, DOI 10.1155/2014/438254
   Ngo TT, 2014, PATTERN RECOGN, V47, P228, DOI 10.1016/j.patcog.2013.06.028
   Tunçel O, 2009, SENSORS-BASEL, V9, P8508, DOI 10.3390/s91108508
   Sang VNT, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113612
   Wang G, 2018, SENSORS
   Yao SC, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P351, DOI 10.1145/3038912.3052577
   Youn I.-H., 2016, J INF COMMUN CONVERG
   Yuan C, 2010, LECT NOTES COMPUTER
NR 47
TC 5
Z9 5
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32665
EP 32692
DI 10.1007/s11042-020-09438-9
EA AUG 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000563739900002
DA 2024-07-18
ER

PT J
AU Luo, YF
   Peng, DZ
AF Luo, Yifan
   Peng, Dezhong
TI A robust watermarking method for MPEG-4 SLS audio
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio watermarking; MPEG-4 SLS; Scale factor-band; Bit-plane;
   Significant state
ID VIDEO WATERMARKING; SCHEME; ALGORITHM; SYNCHRONIZATION; DWT; SEQUENCE
AB Audio lossless compression technology has been widely used to provide customers with higher quality music works. The protection of these works becomes very important. However, there are few digital watermarking methods specifically for lossless compressed audio, and the features of the lossless codec have not been used to improve the performance of watermarking. In this research, we propose a robust audio watermarking method to protect the music encoded by MPEG-4 SLS (Scalable Lossless Coding) format and improve the watermark security and robustness in two aspects. We design an adaptive selection method for watermark embedding position to enhance the security. The significant states combinations of consecutive scale factor-bands (SFB) are constructed as the feature data to determine the embedding target SFB. In this way, the embedding SFB adaptively changes with the audio signal variation, so the security improves. Based on the feature of the MPEG-4 SLS codec, we design new watermark embedding and extraction methods to improve the robustness. The watermark data are embedded into the target SFB. Meanwhile, the embedding is achieved through changing the probability distributions of Bit-plane coding results, which is stable when the audio faces attacks. The watermark data are extracted by comparing the probability distributions before and after embedding. The probability distributions are stable under attacks, so the robustness improves. The experimental data show that the proposed method can resist conventional signal processing attacks while guaranteeing the imperceptibility.
C1 [Luo, Yifan; Peng, Dezhong] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.
   [Peng, Dezhong] Shenzhen Peng Cheng Lab, Shenzhen 518052, Peoples R China.
   [Peng, Dezhong] Southwest Univ, Coll Comp & Informat Sci, Chongqing 400715, Peoples R China.
C3 Sichuan University; Peng Cheng Laboratory; Southwest University - China
RP Luo, YF (corresponding author), Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.
EM tgyifan1@qq.com; pengdz@scu.edu.cn
FU National Natural Science Foundation of China [61971296, U19A2078,
   61625204]; Sichuan Science and Technology Planning Projects
   [2020YFH0186, 2020YFG0319, 2017GFW0097]
FX This work is supported by the National Natural Science Foundation of
   China (Grants No. 61971296, U19A2078, 61625204), and Sichuan Science and
   Technology Planning Projects (Grants No. 2020YFH0186, 2020YFG0319,
   2017GFW0097).
CR Abdelwahab KM, 2020, MULTIMED TOOLS APPL, V79, P5617, DOI 10.1007/s11042-019-08023-z
   Arnold M, 2014, IEEE T INF FOREN SEC, V9, P411, DOI 10.1109/TIFS.2013.2293952
   Asikuzzaman M, 2018, IEEE T CIRC SYST VID, V28, P2131, DOI 10.1109/TCSVT.2017.2712162
   Attari AA, 2018, MULTIMED TOOLS APPL, V77, P25607, DOI 10.1007/s11042-018-5809-8
   Bassia P, 2001, IEEE T MULTIMEDIA, V3, P232, DOI 10.1109/6046.923822
   Chen ST, 2013, DIGIT SIGNAL PROCESS, V23, P971, DOI 10.1016/j.dsp.2012.12.013
   Esfahani R, 2019, MULTIMED TOOLS APPL, V78, P16159, DOI 10.1007/s11042-018-6892-6
   Geiger R., 2006, P INT C ACOUSTICS AU, P205, DOI [10.1109/ICASSP.2006.1661248, DOI 10.1109/ICASSP.2006.1661248]
   Giurcaneanu CD, 2000, SIGNAL PROCESS, V80, P2283, DOI 10.1016/S0165-1684(00)00117-1
   Hemis M, 2018, MULTIMED TOOLS APPL, V77, P11693, DOI 10.1007/s11042-017-4813-8
   Hu HT, 2018, SIGNAL PROCESS, V147, P190, DOI 10.1016/j.sigpro.2018.02.001
   Hu HT, 2017, WIRELESS PERS COMMUN, V94, P221, DOI 10.1007/s11277-016-3178-z
   Hua G, 2016, SIGNAL PROCESS, V128, P222, DOI 10.1016/j.sigpro.2016.04.005
   Hwang MJ, 2018, IEEE T MULTIMEDIA, V20, P45, DOI 10.1109/TMM.2017.2721642
   Jiang WZ, 2019, SIGNAL PROCESS, V162, P153, DOI 10.1016/j.sigpro.2019.04.017
   Kanhe A, 2019, CIRC SYST SIGNAL PR, V38, P3697, DOI 10.1007/s00034-018-0994-2
   Kirovski D, 2003, IEEE T SIGNAL PROCES, V51, P1020, DOI 10.1109/TSP.2003.809384
   Ko BS, 2005, IEEE T MULTIMEDIA, V7, P212, DOI 10.1109/TMM.2005.843366
   Lei BY, 2015, AEU-INT J ELECTRON C, V69, P188, DOI 10.1016/j.aeue.2014.08.012
   Li T, 2009, IEEE T MULTIMEDIA, V11, P422, DOI 10.1109/TMM.2009.2012917
   Li W, 2006, IEEE T MULTIMEDIA, V8, P60, DOI 10.1109/TMM.2005.861291
   Li Y, 2019, MULTIMED TOOLS APPL, V78, P8535, DOI 10.1007/s11042-018-6942-0
   Li Z, 2006, IEEE T SIGNAL PROCES, V54, P3064, DOI 10.1109/TSP.2006.875393
   Liang XY, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107584
   Liu ZH, 2019, IEEE T INF FOREN SEC, V14, P1171, DOI 10.1109/TIFS.2018.2871748
   Lu WH, 2020, IEEE ACCESS, V8, P63643, DOI 10.1109/ACCESS.2020.2984283
   Luo AW, 2020, MULTIMED TOOLS APPL, V79, P243, DOI 10.1007/s11042-019-08074-2
   Luo YF, 2019, IEEE ACCESS, V7, P10533, DOI 10.1109/ACCESS.2019.2890972
   Painter T, 2000, P IEEE, V88, P451, DOI 10.1109/5.842996
   Pourhashemi SM, 2019, MULTIMED TOOLS APPL, V78, P22883, DOI 10.1007/s11042-019-7595-3
   Quackenbush S, 2013, IEEE MULTIMEDIA, V20, P72, DOI 10.1109/MMUL.2013.24
   Quan XM, 2006, INT C PATT RECOG, P727
   Saadi S, 2019, SIGNAL PROCESS, V154, P74, DOI 10.1016/j.sigpro.2018.08.011
   Shu Ruo, 2009, Signal Processing, V25, P1376
   Terchi Y, 2018, MULTIMED TOOLS APPL, V77, P25681, DOI 10.1007/s11042-018-5813-z
   Wang XY, 2006, IEEE T SIGNAL PROCES, V54, P4835, DOI 10.1109/TSP.2006.881258
   Wu SQ, 2005, IEEE T BROADCAST, V51, P69, DOI 10.1109/TBC.2004.838265
   Xiang SJ, 2007, IEEE T MULTIMEDIA, V9, P1357, DOI 10.1109/TMM.2007.906580
   Xiang Y, 2018, IEEE-ACM T AUDIO SPE, V26, P529, DOI 10.1109/TASLP.2017.2782487
   Xiang Y, 2011, IEEE T MULTIMEDIA, V13, P2, DOI 10.1109/TMM.2010.2080668
   Yu R, 2003, INT CONF ACOUST SPEE, P277
   Yu R, 2005, 2005 IEEE 7 WORKSH M, P1
   Zhou NR, 2019, MULTIMED TOOLS APPL, V78, P2507, DOI 10.1007/s11042-018-6322-9
   Zhou NR, 2018, MULTIMED TOOLS APPL, V77, P30251, DOI 10.1007/s11042-018-6128-9
NR 44
TC 3
Z9 3
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32259
EP 32283
DI 10.1007/s11042-020-09507-z
EA AUG 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562943300005
DA 2024-07-18
ER

PT J
AU Rahnema, N
   Gharehchopogh, FS
AF Rahnema, Nouria
   Gharehchopogh, Farhad Soleimanian
TI An improved artificial bee colony algorithm based on whale optimization
   algorithm for data clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial bee colony algorithm; Whale optimization algorithm; Data
   clustering; Optimization
ID CUCKOO SEARCH ALGORITHM; KRILL HERD ALGORITHM; HYBRIDIZATION; STRATEGY
AB Data clustering is one of the branches of unsupervised learning and it is a process whereby the samples are divided into categories whose members are similar to each other. The K-means algorithm is a simple and fast clustering technique, but it has many initial problems, for example, it depends heavily on the initial value for better clustering. Moreover, it is susceptible to outliers and unbalanced clusters. The artificial bee colony (ABC) algorithm is one of the meta-heuristic algorithms that is used nowadays to solve many optimization problems including clustering and the fundamental problem of this algorithm is exploration and late convergence. In this paper, to solve the problem of exploration and late convergence in ABC are used Random Memory (RM) and Elite Memory (EM) called ABCWOA algorithm. RM in the ABCWOA algorithm has used the search stage for the bait in the whale optimization algorithm (WOA) and EM is also used to increase convergence. In addition, we control the use of EM dynamically. Finally, the proposed method was implemented on ten standard datasets from the UCI Machine Learning Database for evaluation. Moreover, it was compared in terms of statistical criteria and analysis of variance (ANOVA) test with basic ABC and WOA, vortex search (VS) algorithm, butterfly optimization algorithm (BOA), crow search (CS) algorithm, and cuckoo search algorithm (CSA). The simulation results showed that the degree of convergence maintained its performance by increasing the number of repetitions of the proposed method, but the ABC algorithm has shown poor performance by increasing the repetition of performance. ANOVA results also confirmed that the ABCWOA algorithm has a positive effect on the population and it contains less noise than other comparative algorithms. The ABCWOA algorithm show that the ABCWOA algorithm performs better than other meta-heuristic algorithms.
C1 [Rahnema, Nouria; Gharehchopogh, Farhad Soleimanian] Islamic Azad Univ, Dept Comp Engn, Urmia Branch, Orumiyeh, Iran.
C3 Islamic Azad University
RP Gharehchopogh, FS (corresponding author), Islamic Azad Univ, Dept Comp Engn, Urmia Branch, Orumiyeh, Iran.
EM bonab.farhad@gmail.com
RI Gharehchopogh, Farhad Soleimanian/AAX-9598-2020
OI Gharehchopogh, Farhad Soleimanian/0000-0003-1588-1659
CR Abdel-Basset M, 2018, FUTURE GENER COMP SY, V85, P129, DOI 10.1016/j.future.2018.03.020
   Abedi M, 2020, INTELL DATA ANAL, V24, P309, DOI 10.3233/IDA-194485
   Abualigah L., 2015, INT J COMPUTER SCI E, V5, P19, DOI [10.5121/ijcsea.2015.5102, DOI 10.5121/ijcsea.2015.5102]
   Abualigah L. M. Q., 2019, Feature selection and enhanced krill herd algorithm for text document clustering, DOI [DOI 10.1007/978-3-030-10674-4, 10.1007/978-3-030-10674-4]
   Abualigah L, 2020, NEURAL COMPUT APPL, V32, P12381, DOI 10.1007/s00521-020-04839-1
   Abualigah LM, 2018, APPL INTELL, V48, P4047, DOI 10.1007/s10489-018-1190-6
   Abualigah LM, 2018, ENG APPL ARTIF INTEL, V73, P111, DOI 10.1016/j.engappai.2018.05.003
   Abualigah LM, 2018, J COMPUT SCI-NETH, V25, P456, DOI 10.1016/j.jocs.2017.07.018
   Abualigah LM, 2017, APPL SOFT COMPUT, V60, P423, DOI 10.1016/j.asoc.2017.06.059
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   Askarzadeh A, 2016, COMPUT STRUCT, V169, P1, DOI 10.1016/j.compstruc.2016.03.001
   Banharnsakun A, 2017, PATTERN RECOGN LETT, V93, P78, DOI 10.1016/j.patrec.2016.07.027
   Boushaki SI, 2018, EXPERT SYST APPL, V96, P358, DOI 10.1016/j.eswa.2017.12.001
   Cui LZ, 2018, SOFT COMPUT, V22, P2217, DOI 10.1007/s00500-017-2485-y
   Das P, 2018, APPL SOFT COMPUT, V70, P590, DOI 10.1016/j.asoc.2018.05.045
   Dogan B, 2015, INFORM SCIENCES, V293, P125, DOI 10.1016/j.ins.2014.08.053
   Du Z, 2019, J SUPERCOMPUT, P1
   Farshidpour S, 2012, ORIENT J COMP SCI TE, V5
   Gandomi AH, 2013, ENG COMPUT-GERMANY, V29, P17, DOI 10.1007/s00366-011-0241-y
   Ghany KKA, 2020, J KING SAUD U COMP I
   Gharehchopogh FS, 2020, ARTIF INTELL REV, V53, P2265, DOI 10.1007/s10462-019-09733-4
   Gharehchopogh FS, 2019, SWARM EVOL COMPUT, V48, P1, DOI 10.1016/j.swevo.2019.03.004
   Guo C, 2019, DATA CLUSTERING USIN
   Inkaya T, 2015, APPL SOFT COMPUT, V28, P301, DOI 10.1016/j.asoc.2014.11.060
   Jadhav AN, 2017, ALEXANDRIA ENG J
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Karaboga D., 2005, Technical Report-TR06
   Long W, 2018, SOFT COMPUT, V22, P4789, DOI 10.1007/s00500-017-2665-9
   Luqman M, 2017, PAKISTAN J SCI, V69
   Mafarja MM, 2017, NEUROCOMPUTING, V260, P302, DOI 10.1016/j.neucom.2017.04.053
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Shayanfar H, 2018, APPL SOFT COMPUT, V71, P728, DOI 10.1016/j.asoc.2018.07.033
   Van der Merwe D, 2003, EV COMP 2003 CEC 03
   Wang GG, 2019, NEURAL COMPUT APPL, V31, P1995, DOI 10.1007/s00521-015-1923-y
   Wang JZ, 2017, APPL ENERG, V208, P344, DOI 10.1016/j.apenergy.2017.10.031
   Wu XH, 2015, APPL MATH MODEL, V39, P3398, DOI 10.1016/j.apm.2014.11.041
   Wu Z-X, 2018, 2018 C TECHN APPL AR
   Xiang WL, 2017, APPL SOFT COMPUT, V60, P1, DOI 10.1016/j.asoc.2017.06.015
   Xue Y, 2018, SOFT COMPUT, V22, P2935, DOI 10.1007/s00500-017-2547-1
   Yan XH, 2012, NEUROCOMPUTING, V97, P241, DOI 10.1016/j.neucom.2012.04.025
   Zabihi F, 2018, APPL SOFT COMPUT, V71, P226, DOI 10.1016/j.asoc.2018.06.013
   Zhong FL, 2017, ENG APPL ARTIF INTEL, V58, P134, DOI 10.1016/j.engappai.2016.11.005
NR 42
TC 52
Z9 52
U1 3
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32169
EP 32194
DI 10.1007/s11042-020-09639-2
EA AUG 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562943300004
DA 2024-07-18
ER

PT J
AU Afif, M
   Ayachi, R
   Pissaloux, E
   Said, Y
   Atri, M
AF Afif, Mouna
   Ayachi, Riadh
   Pissaloux, Edwige
   Said, Yahia
   Atri, Mohamed
TI Indoor objects detection and recognition for an ICT mobility assistance
   of visually impaired people
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Indoor object detection and recognition; Deep convolutional neural
   networks (DCNN); Visually impaired people (VIP) mobility; Indoor
   navigation
AB Indoor object detection in real scene presents a challenging computer vision task; it is also a key component of an ICT autonomous displacement assistance of Visually Impaired People (VIP). To handle this challenge, a DCNN (Deep Convolutional Neural Networks) for indoor object detection and a new indoor dataset are proposed. The novel DCNN design is based on a pre-trained DCNN called YOLO v3. In order to train and test the proposed DCNN, a new dataset for indoor objects was created. The images of the new dataset present large variety of objects, of indoor illuminations and of indoor architectural structures potentially unsafe for a VIP independent mobility. The dataset contains about 8000 images and presents 16 indoor object categories. Experimental results prove the high performance of the proposed indoor object detection as its recognition rate (a mean average precision) is 73,19%.
C1 [Afif, Mouna; Ayachi, Riadh; Said, Yahia] Univ Monastir, Fac Sci Monastir, Lab Elect & Microelect EuE, Monastir, Tunisia.
   [Pissaloux, Edwige] Univ Rouen Normandy Rouen, LITIS Lab, Rouen, France.
   [Pissaloux, Edwige] Univ Rouen Normandy Rouen, CNRS FR 3638, Rouen, France.
   [Said, Yahia] Northern Border Univ, Coll Engn, Elect Engn Dept, Ar Ar, Saudi Arabia.
   [Atri, Mohamed] King Khalid Univ, Coll Comp Sci, Abha, Saudi Arabia.
C3 Universite de Monastir; Universite de Rouen Normandie; Centre National
   de la Recherche Scientifique (CNRS); CNRS - Institute for Information
   Sciences & Technologies (INS2I); Northern Border University; King Khalid
   University
RP Afif, M (corresponding author), Univ Monastir, Fac Sci Monastir, Lab Elect & Microelect EuE, Monastir, Tunisia.
EM mouna.afif@outlook.fr
RI ATRI, Mohamed/C-4069-2014; Said, Yahia/A-7333-2018; Ayachi,
   Riadh/AAU-2160-2020
OI ATRI, Mohamed/0000-0001-8528-5647; Said, Yahia/0000-0003-0613-4037;
   Ayachi, Riadh/0000-0003-4683-9592
CR Afif M, 2019, ARTIF INTELL ADV, V1, P52, DOI 10.30564/aia.v1i1.925
   [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322
   [Anonymous], 2017, J PHYS AGENTS, DOI DOI 10.3389/FIMMU.2017.00125
   [Anonymous], 2018, P ICRC 2018 2018 3, DOI DOI 10.1145/3265639.3265671
   [Anonymous], 2014, INT C ED SOC SCIENC
   Ayachi Riadh, 2020, Proceedings of the 8th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT18). Smart Innovation, Systems and Technologies (SIST 146), P234, DOI 10.1007/978-3-030-21005-2_23
   Bashiri FS, 2018, LECT NOTES COMPUT SC, V11241, P500, DOI 10.1007/978-3-030-03801-4_44
   Bashiri FS, 2018, DATA BRIEF, V17, P71, DOI 10.1016/j.dib.2017.12.047
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Chae HW, 2016, INT CONF UBIQ ROBOT, P405, DOI 10.1109/URAI.2016.7734070
   Chen YJ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082692
   Couprie C, 2013, INT C LEARN REPR ICL
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Eitel A, 2015, IEEE INT C INT ROBOT, P681, DOI 10.1109/IROS.2015.7353446
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Girchick R, 2014, IEEE C COMP VIS PATT, P580
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Guerrero LA, 2012, SENSORS-BASEL, V12, P8236, DOI 10.3390/s120608236
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148
   Hu HL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND STORAGE (NAS)
   Husain F, 2017, IEEE ROBOT AUTOM LET, V2, P49, DOI 10.1109/LRA.2016.2532927
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Kim DK, 2015, 25 ICDERS
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky A, 2012, INT C NEUR INF PROC, V6, P1097
   LeCun Y, 2004, PROC CVPR IEEE, P97
   Li GF, 2019, MULTIMED TOOLS APPL, V78, P29765, DOI 10.1007/s11042-018-6293-x
   Li YT, 2020, ACM T SENSOR NETWORK, V16, DOI 10.1145/3397179
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Ma R, 2020, ALEXANDRIA ENG J
   Nan LL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366156
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Redmon J., 2018, COMPUTER VISION PATT
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Reza M. A., 2014, C 5 WORKSH RGB D ADV
   Shao WH, 2018, IEEE ACCESS, V6, P74699, DOI 10.1109/ACCESS.2018.2884193
   Verschae R, 2015, FRONT ROBOT AI, DOI 10.3389/frobt.2015.00029
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
NR 43
TC 33
Z9 33
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31645
EP 31662
DI 10.1007/s11042-020-09662-3
EA AUG 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000561718500002
DA 2024-07-18
ER

PT J
AU Mathur, M
   Vasudev, D
   Sahoo, S
   Jain, D
   Goel, N
AF Mathur, Monika
   Vasudev, Diksha
   Sahoo, Sonalika
   Jain, Divanshi
   Goel, Nidhi
TI Crosspooled FishNet: transfer learning based fish species classification
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater images; Convolution neural network; Fish species; ResNet;
   Cross convolutional layer pooling
AB Fish species classifiction is an important task for biologists and marine ecologists to frequently estimate the relative abundance of fish species in their natural habitats and monitor changes in their populations. Traditional methods used for fish species classifiction were laboriuos, time consuming and expensive. So, there is need for an automated system that can not only detect and track but also categorize fish as well as other aquatic species in underwater imagery, minimizing the manual interference. Absorption and scattering of light in deep sea environment leads to low resolution images making fish species recognition and classification a challenging task. Further, performance of traditional computer vision techniques tends to degrade in underwater conditions due to the presence of high background clutter and highly indistinct features of marine species. For such classification problems, Artificial Neural Networks (ANN) or deep neural network are being increasingly employed for improved performance. But the limited dataset of fish images makes it difficult to train such networks as they require huge datasets for training. Thus to reduce the requirement for a huge amount of training data, an algorithm using cross convolutional layer pooling on a pre-trained Convolutional Neural Networks (CNN) is proposed. The present paper focuses on the development of automatic system for classification, which can detect and classify fish from underwater images captured through videos. Thorough analysis on image dataset of 27,370 fish images gives a validation accuracy of 98.03%. The proposed method will be an efficient replacement to strenuous and time consuming method of manual recognition by marine experts and thus be advantageous for monitoring fish biodiversity in their natural habitats.
C1 [Mathur, Monika; Vasudev, Diksha; Sahoo, Sonalika; Jain, Divanshi; Goel, Nidhi] IGDTUW, Dept ECE, Delhi 06, India.
RP Goel, N (corresponding author), IGDTUW, Dept ECE, Delhi 06, India.
EM monika009phd0215@igdtuw.ac.in; diksha024btece15@igdtuw.ac.in;
   sonalika004btece15@igdtuw.ac.in; divanshi026btece15@igdtuw.ac.in;
   nidhigoel@igdtuw.ac.in
RI Goel, Nidhi/AAW-1536-2020
OI Goel, Nidhi/0000-0001-7089-7077; goel, nidhi/0000-0001-6337-9052
CR Allken V, 2019, ICES J MAR SCI, V76, P342, DOI 10.1093/icesjms/fsy147
   [Anonymous], 2007, MVA
   Bamba B, 2015, IEEE IC COMP COM NET
   Boom BJ, 2012, INT C PATT RECOG, P1542
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   dos Santos AA, 2019, ECOL INFORM, V53, DOI 10.1016/j.ecoinf.2019.100977
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   FLEISS JL, 1973, EDUC PSYCHOL MEAS, V33, P613, DOI 10.1177/001316447303300309
   Gandarias JM, 2019, IEEE SENS J, V19, P6872, DOI 10.1109/JSEN.2019.2912968
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Jalal A, 2020, ECOL INFORM, V57, DOI 10.1016/j.ecoinf.2020.101088
   Jin LL, 2017, OCEANS-IEEE
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Larsen R, 2009, LECT NOTES COMPUT SC, V5575, P745
   Liu LQ, 2017, IEEE T PATTERN ANAL, V39, P2305, DOI 10.1109/TPAMI.2016.2637921
   Mathur NGM, 2019, INT C SIGN PROC VLSI
   Nagaoka Y, 2019, IEEE ACCESS, V7, P63767, DOI 10.1109/ACCESS.2019.2917554
   Qin HW, 2016, NEUROCOMPUTING, V187, P49, DOI 10.1016/j.neucom.2015.10.122
   Qiu CC, 2018, IEEE ACCESS, V6, P78503, DOI 10.1109/ACCESS.2018.2885055
   Rathi D, 2017, 2017 NINTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION (ICAPR), P344
   Rauf HT, 2019, COMPUT ELECTRON AGR, V167, DOI 10.1016/j.compag.2019.105075
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rodrigues MTA, 2015, PATTERN ANAL APPL, V18, P783, DOI 10.1007/s10044-013-0362-6
   Salman A, 2016, LIMNOL OCEANOGR-METH, V14, P570, DOI 10.1002/lom3.10113
   Schettini R, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/746052
   Siddiqui SA, 2018, ICES J MAR SCI, V75, P374, DOI 10.1093/icesjms/fsx109
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Spampinato C., 2010, P 1 ACM INT WORKSH A, P45, DOI [DOI 10.1145/1877868, DOI 10.1145/1877868.1877881]
   Storbeck F, 2001, FISH RES, V51, P11, DOI 10.1016/S0165-7836(00)00254-X
   STRACHAN NJC, 1995, ICES J MAR SCI, V52, P145, DOI 10.1016/1054-3139(95)80023-9
   Tamou B, 2018, IMAGE SIGNAL PROCESS, P275
   Tharwat A, 2018, FISH RES, V204, P324, DOI 10.1016/j.fishres.2018.03.008
   Villon S, 2018, ECOL INFORM, V48, P238, DOI 10.1016/j.ecoinf.2018.09.007
   White DJ, 2006, FISH RES, V80, P203, DOI 10.1016/j.fishres.2006.04.009
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao J, 2020, IEEE T FUZZY SYST, V28, P2287, DOI 10.1109/TFUZZ.2019.2930492
NR 37
TC 26
Z9 29
U1 2
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31625
EP 31643
DI 10.1007/s11042-020-09371-x
EA AUG 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000561517900001
DA 2024-07-18
ER

PT J
AU Sanasam, I
   Choudhary, P
   Singh, KM
AF Sanasam, Inunganbi
   Choudhary, Prakash
   Singh, Khumanthem Manglem
TI Line and word segmentation of handwritten text document by mid-point
   detection and gap trailing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Line segmentation; Word segmentation; Handwritten documents; Meitei
   Mayek documents; English text
ID RECOGNITION; SYSTEM
AB This paper presents the text line and word segmentation from unconstrained handwritten documents based on horizontal projection histogram (HPH) to detect mid-points and gap trailing between lines. The midpoints are estimated from the HPH for the first 100 to 200 columns of the whole document. Then, considering the mid-points, the gap is tracked between two consecutive lines from locally computed HPH for a block havingkrows andjcolumns. The HPH block is examined for various cases to locate optimal rows that separate adjacent lines. The proposed method segments curve, touching and skew-lines and is robust to writing variation and language independent. Word segmentation is not treated as a separate problem and goes efficiently alongside the line segmentation. As the trailing of space between neighboring lines goes on, the vertical projection Histogram (VPH) oftcolumns is monitored between the above and below separator of a line and find the optimal word separator. The algorithm is evaluated on two isolated datasets of different languages (Meitei Mayek and English). Text-line and word segmentation on Meitei Mayek handwritten documents achieve 91.84% and 88.96% accuracy respectively. Similarly, the handwritten English document meets 94.18% and 87.73% accuracy for line and word segmentation.
C1 [Sanasam, Inunganbi; Singh, Khumanthem Manglem] NIT Manipur, Imphal, Manipur, India.
   [Choudhary, Prakash] NIT Hamirpur, Imphal, HP, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Manipur; National Institute of Technology (NIT System);
   National Institute of Technology Hamirpur
RP Sanasam, I (corresponding author), NIT Manipur, Imphal, Manipur, India.
EM inung.sam@gmail.com; choudharyprakash87@gmail.com; manglem@gmail.com
RI Choudhary, Dr. Prakash/ABE-2494-2021; Singh, Khumanthem/AFZ-2177-2022
OI Choudhary, Dr. Prakash/0000-0003-4337-7273; Singh,
   Khumanthem/0000-0002-6698-1185; Inunganbi, Sanasam/0000-0002-7879-1039
CR Abuhaiba ISI, 1995, P 3 INT C DOC AN REC, V1
   [Anonymous], 2014, ENVIRON SCI ENG, DOI DOI 10.1007/978-3-319-03002-9_37
   [Anonymous], 2018, INT J NAT LANG COMPU
   [Anonymous], 2003, IEEE C EVOL COMPUTAT
   [Anonymous], 2007, PROC SPIE
   Basu S, 2007, PATTERN RECOGN, V40, P1825, DOI 10.1016/j.patcog.2006.10.002
   dos Santos RP, 2009, 2009 INT 10 C DOC AN
   Ghosh S, 2013, 2013 4 NAT C COMP VI
   Jindal P, 2015, 2015 2 INT C REC ADV
   KAHAN S, 1987, IEEE T PATTERN ANAL, V9, P274, DOI 10.1109/TPAMI.1987.4767901
   Kise K, 1998, COMPUT VIS IMAGE UND, V70, P370, DOI 10.1006/cviu.1998.0684
   Li Y, 2006, 18 INT C PATT REC IC, V2
   Li Y, 2006, 10 INT WORKSH FRONT
   Li Y, 2008, IEEE T PATTERN ANAL, V30, P1313, DOI 10.1109/TPAMI.2007.70792
   Likforman-Sulem L, 1995, P 3 INT C DOC AN REC, V2
   Louloudis G, 2009, PATTERN RECOGN, V42, P3169, DOI 10.1016/j.patcog.2008.12.016
   Louloudis G, 2006, 10 INT WORKSH FRONT
   Malik SA, 2019, FUT INF COMM C
   Marti U, 1999, P 5 INT C DOC AN REC, P705
   Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071
   Marti UV, 2001, PROC INT CONF DOC, P159, DOI 10.1109/ICDAR.2001.953775
   NAGY G, 1992, COMPUTER, V25, P10, DOI 10.1109/2.144436
   Nguyen K.C., 2016, IEICE TECHN REP, V115, P53
   Nicolas S, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P245, DOI 10.1109/IWFHR.2004.100
   OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677
   Pal U, 2003, PROC INT CONF DOC, P1128
   Pu Y., 1998, Proc. of the 6 Int'l Workshop on Frontiers in Handwriting Recognition, P637
   Saha S, 2010, ARXIV10024048
   Simon A, 1997, IEEE T PATTERN ANAL, V19, P273, DOI 10.1109/34.584106
   Su T-H, 2007, 9 INT C DOC AN REC I, V2
   Weliwitage C, 2005, DIGITAL IMAGE COMPUT
   Yin F, 2009, PATTERN RECOGN, V42, P3146, DOI 10.1016/j.patcog.2008.12.013
   Zahour A, 2001, PROC INT CONF DOC, P281
   Zahour A, 2007, 9 INT C DOC AN REC I, V1
NR 34
TC 7
Z9 7
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30135
EP 30150
DI 10.1007/s11042-020-09416-1
EA AUG 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000559430400005
DA 2024-07-18
ER

PT J
AU Shukla, P
   Verma, A
   Abhishek
   Verma, S
   Kumar, M
AF Shukla, Prashant
   Verma, Abhishek
   Abhishek
   Verma, Shekhar
   Kumar, Manish
TI Interpreting SVM for medical images using Quadtree
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non linear classification; Interpretability; Localization; Quadtree
ID SUPPORT VECTOR MACHINES; RULE EXTRACTION; CLASSIFICATION; DIAGNOSIS;
   LESIONS
AB In this paper, we propose a quadtree based approach to capture the spatial information of medical images for explaining nonlinear SVM prediction. In medical image classification, interpretability becomes important to understand why the adopted model works. Explaining an SVM prediction is difficult due to implicit mapping done in kernel classification is uninformative about the position of data points in the feature space and the nature of the separating hyperplane in the original space. The proposed method finds ROIs which contain the discriminative regions behind the prediction. Localization of the discriminative region in small boxes can help in interpreting the prediction by SVM. Quadtree decomposition is applied recursively before applying SVMs on sub images and model identified ROIs are highlighted. Pictorial results of experiments on various medical image datasets prove the effectiveness of this approach. We validate the correctness of our method by applying occlusion methods.
C1 [Shukla, Prashant; Verma, Abhishek; Abhishek; Verma, Shekhar; Kumar, Manish] Indian Inst Informat Technol Allahabad, Dept IT, Allahabad, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Shukla, P (corresponding author), Indian Inst Informat Technol Allahabad, Dept IT, Allahabad, Uttar Pradesh, India.
EM rsi2016502@iiita.ac.in; ism2013002@iiita.ac.in; rsi2016006@iiita.ac.in;
   sverma@iiita.ac.in; manish@iiita.ac.in
OI Kumar, Manish/0000-0002-1311-0976; Verma, Shekhar/0000-0003-3460-2707; ,
   ABHISHEK/0000-0002-6491-8967
CR Abdullah M, 2011, IEEE DATA MINING, P248, DOI 10.1109/DMO.2011.5976536
   Achmad A, 2019, 1 INT C MAT ENG MAN
   Agurto C, 2010, IEEE T MED IMAGING, V29, P502, DOI 10.1109/TMI.2009.2037146
   Akram MU, 2014, COMPUT BIOL MED, V45, P161, DOI 10.1016/j.compbiomed.2013.11.014
   Barakat N., 2004, 3 C NEUR EV INT NCEI
   Barakat N, 2010, NEUROCOMPUTING, V74, P178, DOI 10.1016/j.neucom.2010.02.016
   Barakat NH, 2007, IEEE T KNOWL DATA EN, V19, P729, DOI [10.1109/TKDE.2007.1023, 10.1109/TKDE.2007.1023.]
   Bauer S, 2011, LECT NOTES COMPUT SC, V6893, P354, DOI 10.1007/978-3-642-23626-6_44
   Boyle, 2014, CENGAGE LEARNING
   Caragea D., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P251, DOI 10.1145/502512.502547
   Chatchinarat A, 2017, INT CONF KNOWL SMART, P106, DOI 10.1109/KST.2017.7886104
   Chung KL, 2001, PATTERN RECOGN LETT, V22, P1545, DOI 10.1016/S0167-8655(01)00106-4
   Dhahbi S, 2015, COMPUT BIOL MED, V64, P79, DOI 10.1016/j.compbiomed.2015.06.012
   GALIL Z, 1980, SIAM J COMPUT, V9, P197, DOI 10.1137/0209016
   Ghassemi, 2020, ARXIV200611988
   Hassanien Aboul Ella, 2020, AUTOMATIC XRAY COVID
   He JY, 2006, IEEE T NANOBIOSCI, V5, P46, DOI 10.1109/TNB.2005.864021
   Hundekar S, 2019, J IMAGE VIDEO PROCES, V9
   Jakulin A., 2005, Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining, P108, DOI DOI 10.1145/1081870.1081886
   Langote V. B., 2012, INT J ADV ENG RES ST, V2, P252
   Liu WF, 2019, IEEE T CYBERNETICS, V49, P2927, DOI 10.1109/TCYB.2018.2833843
   Ma XQ, 2019, IEEE T GEOSCI REMOTE, V57, P1585, DOI 10.1109/TGRS.2018.2867570
   Nandpuru HB, 2014, 2014 IEEE STUDENTS' CONFERENCE ON ELECTRICAL, ELECTRONICS AND COMPUTER SCIENCE (SCEECS)
   Nguyen D.-H., 2014, ARXIV14085246
   Nunez H., 2002, 10th European Symposium on Artificial Neural Networks. ESANN'2002. Proceedings, P107
   Othman MFB, 2011, 2011 4 INT C MOD SIM, P1, DOI DOI 10.1109/ICMSAO.2011.5775605
   Posso M, 2017, EUR J RADIOL, V96, P40, DOI 10.1016/j.ejrad.2017.09.013
   Poulet F, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P499, DOI 10.1109/ICDM.2004.10068
   Rastgarpour M, 2011, P INT MULT ENG COMP, VI
   Salas-Gonzalez D, 2010, PHYS MED BIOL, V55, P2807, DOI 10.1088/0031-9155/55/10/002
   Sampaio WB, 2011, COMPUT BIOL MED, V41, P653, DOI 10.1016/j.compbiomed.2011.05.017
   de Oliveira FSS, 2015, COMPUT BIOL MED, V57, P42, DOI 10.1016/j.compbiomed.2014.11.016
   Shou-Yi Tseng, 2009, 2009 WRI World Congress on Computer Science and Information Engineering, CSIE, P401, DOI 10.1109/CSIE.2009.662
   Sidibé D, 2015, COMPUT BIOL MED, V62, P175, DOI 10.1016/j.compbiomed.2015.04.026
   Solanke A, 2019, LUNG, V20, P176
   Sun Z, 2018, NEUROIMAGE, V178, P445, DOI 10.1016/j.neuroimage.2018.05.051
   Tao DP, 2013, IEEE T MULTIMEDIA, V15, P833, DOI 10.1109/TMM.2013.2238909
   Wang XH, 2006, LECT NOTES COMPUT SC, V3971, P968
   Wang Z, 2018, WORKSH 32 AAAI C ART
   Yahyaoui A, 2018, DECISION SUPPORT SYS
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 41
TC 18
Z9 18
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29353
EP 29373
DI 10.1007/s11042-020-09431-2
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559626500003
PM 32837249
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Liu, H
   Zhang, N
   Jin, SG
   Xu, DY
   Gao, WZ
AF Liu, Hao
   Zhang, Ning
   Jin, Shangang
   Xu, Dayou
   Gao, Weizhe
TI Small sample color fundus image quality assessment based on gcforest
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color fundus image; Quality assessment; Small sample; Gcforest;
   Re-sampling
AB Color fundus image quality greatly influence the doctors' diagnostic accuracy. However, the problems of imbalance data and small sample are the key issues of the color fundus images quality assessment. Hence, this paper purposes a small sample color fundus image quality assessment based on gcforest to solve these problems. Firstly, this paper extracts color and texture features to represent the quality of color fundus image. Next, re-sampling process is used to re-balance training data. Thirdly, the training data after re-balanced is sent to train gcforest which is a forest integration model. Finally, the trained gcforest which is good for small sample problem is used to evaluate color fundus images quality. Experiments demonstrate that the proposed method not only in color fundus image quality assessment but also in glaucoma classification task get good results.
C1 [Liu, Hao; Zhang, Ning; Jin, Shangang; Xu, Dayou; Gao, Weizhe] Lanzhou Univ Technol, Coll Elect & Informat Engn, Lanzhou 730050, Peoples R China.
C3 Lanzhou University of Technology
RP Liu, H (corresponding author), Lanzhou Univ Technol, Coll Elect & Informat Engn, Lanzhou 730050, Peoples R China.
EM helenliuhao@gmail.com; zhangning@lut.edu.cn; jin_shangang@163.com;
   cvxudayou@163.com; gaoweizhe9@126.com
FU National Natural Science Foundation [61866022]; Gansu Provincial Basic
   Research Innovation Group [1506RJIA031]
FX This paper is partly funded by the National Natural Science Foundation
   Project No.(61866022) and the Gansu Provincial Basic Research Innovation
   Group No. (1506RJIA031).
CR Abdel-Hamid L, 2017, COMPUT BIOL MED, V90, P68, DOI 10.1016/j.compbiomed.2017.09.012
   [Anonymous], 2015, P SPIE
   [Anonymous], 2006, INTERACTION OF COLOR
   Chalakkal RJ, 2019, COMPUT BIOL MED, V108, P317, DOI 10.1016/j.compbiomed.2019.03.019
   Cheung N, 2010, LANCET, V376, P124, DOI 10.1016/S0140-6736(09)62124-3
   Cong J, 2019, CHIN OPT, V12, P97, DOI 10.3788/CO.20191201.0097
   Diaz-Pinto A, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0649-y
   Fan Ci-en, 2018, Optics and Precision Engineering, V26, P916, DOI 10.3788/OPE.20182604.0916
   Fasiha M, 2014, P SPIE INT SOC OPTIC, V9035
   Fleming AD, 2012, MED ENG PHYS, V34, P849, DOI 10.1016/j.medengphy.2011.09.027
   Fu HZ, 2019, LECT NOTES COMPUT SC, V11764, P48, DOI 10.1007/978-3-030-32239-7_6
   Gao Wei-wei, 2018, Journal of Chongqing University (English Edition), V17, P77, DOI 10.11835/j.issn.1671-8224.2018.03.01
   Giancardo L., 2010, NEW DEV BIOMEDICAL E, P201
   Jager RD, 2008, NEW ENGL J MED, V358, P2606, DOI 10.1056/NEJMra0801537
   Köhler T, 2013, COMP MED SY, P95, DOI 10.1109/CBMS.2013.6627771
   Lee SC, 1999, P SOC PHOTO-OPT INS, V3661, P1581, DOI 10.1117/12.348562
   Luzio S, 2004, DIABETIC MED, V21, P1121, DOI 10.1111/j.1464-5491.2004.01305.x
   Mitani A, 2020, NAT BIOMED ENG, V4, P18, DOI 10.1038/s41551-019-0487-z
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Palmer DW, 2018, BIOMED OPT EXPRESS, V9, P3178, DOI 10.1364/BOE.9.003178
   Patton N, 2006, PROG RETIN EYE RES, V25, P99, DOI 10.1016/j.preteyeres.2005.07.001
   Dias JMP, 2014, INFORM FUSION, V19, P73, DOI 10.1016/j.inffus.2012.08.001
   Raj A, 2020, IEEE ACCESS, V8, P57810, DOI 10.1109/ACCESS.2020.2982588
   Raj A, 2019, IET IMAGE PROCESS, V13, P1211, DOI 10.1049/iet-ipr.2018.6212
   Ruderman DL, 1998, J OPT SOC AM A, V15, P2036, DOI 10.1364/JOSAA.15.002036
   Saha SK, 2018, J DIGIT IMAGING, V31, P869, DOI 10.1007/s10278-018-0084-9
   Saha SK, 2016, SYSTEMS LEVEL QUALIT, V40
   Serte S., 2019, 2019 3 INT S MULT ST, P1, DOI [DOI 10.1109/ISMSIT.2019.8932753, 10.1109/ISMSIT.2019.8932753]
   Sevik U, 2014, J BIOMED OPT, V19, DOI 10.1117/1.JBO.19.4.046006
   Shao F, 2018, IEEE ACCESS, V6, P2169
   Wang JH, 2015, IEEE T IMAGE PROCESS, V24, P3400, DOI 10.1109/TIP.2015.2446942
   Wang SZ, 2016, IEEE T MED IMAGING, V35, P1046, DOI 10.1109/TMI.2015.2506902
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Welikala RA, 2016, COMPUT BIOL MED, V71, P67, DOI 10.1016/j.compbiomed.2016.01.027
   Zago GT, 2018, COMPUT BIOL MED, V103, P64, DOI 10.1016/j.compbiomed.2018.10.004
   Zhou Z., 2017, IJCAI, P3553
NR 36
TC 5
Z9 6
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17441
EP 17459
DI 10.1007/s11042-020-09362-y
EA AUG 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000557319900001
DA 2024-07-18
ER

PT J
AU Gong, JL
   Zhang, YF
   Sun, K
   Sun, XF
AF Gong, Jinliang
   Zhang, Yanfei
   Sun, Ke
   Sun, Xiaofeng
TI Adaptive lane line detection and warning algorithm based on dynamic
   constraint
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lane line detection; adaptive threshold; canny operator; dynamic
   constraints; departure pre-warning
ID LOCALIZATION
AB The lane line detection algorithm is highly sensitive to the environment. And the selection of parameters is greatly affected by human subjective factors. Therefore, the concept of adaptive and dynamic constraint is introduced into the lane line detection algorithm. The evaluation function is set based on the detected information. A high precision lane line detection algorithm with supervision and warning mechanism is proposed. Firstly, the Canny operator gradient calculation method is improved by using eight neighborhood models. And by setting multi-level threshold instead of double threshold detection method, the algorithm's adaptability is improved. Secondly, the concept of dynamic region of interest is proposed. The detection region of Canny operator is constrained, the environment interference to the algorithm is reduced. Finally, lane line information is included in the supervision and correction warning mechanism. And the early warning is given to drivers. The experimental results show that the algorithm is of high accuracy, real-time and adaptability.
C1 [Gong, Jinliang; Sun, Ke] Shandong Univ Technol, Sch Mech Engn, Zhangdian Dist 255049, Zibo, Peoples R China.
   [Zhang, Yanfei] Shandong Univ Technol, Sch Agr Engn & Food Sci, Zhangdian Dist 255049, Zibo, Peoples R China.
   [Sun, Xiaofeng] Goertek Technol Ltd Co, Qingdao 266000, Shandong, Peoples R China.
C3 Shandong University of Technology; Shandong University of Technology
RP Zhang, YF (corresponding author), Shandong Univ Technol, Sch Agr Engn & Food Sci, Zhangdian Dist 255049, Zibo, Peoples R China.
EM gjlwing@qq.com
RI LI, Wenhui/JCD-9947-2023; Gong, Jinliang/AAJ-9605-2020; Li,
   Juan/JEO-6872-2023
FU National Natural Science Foundation of China [61303006]; Top Talents
   Program for One Case One Discussion of Shandong Province; National Key
   Research and Development Program in Shandong Province [2019GNC106127]
FX This work was funded by the National Natural Science Foundation of China
   (61303006), Top Talents Program for One Case One Discussion of Shandong
   Province, National Key Research and Development Program in Shandong
   Province (2019GNC106127).
CR Aldibaja M, 2017, IEEE T IND INFORM, V13, P2369, DOI 10.1109/TII.2017.2713836
   Bastan M, 2017, IET IMAGE PROCESS, V11, P1325, DOI 10.1049/iet-ipr.2017.0336
   Cai Yingfeng, 2018, China Mechanical Engineering, V29, P1863, DOI 10.3969/j.issn.1004-132X.2018.15.014
   Chen L, 2020, P IEEE, V108, P262, DOI 10.1109/JPROC.2019.2952735
   Diwakar M, 2018, IET IMAGE PROCESS, V12, P708, DOI 10.1049/iet-ipr.2017.0639
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Duan ZG, 2016, ACTA OPT SINICA, V36, P206
   Goh TY, 2018, MEASUREMENT, V114, P298, DOI 10.1016/j.measurement.2017.09.052
   Han YM, 2018, COLLOID INTERFAC SCI, V24, P40, DOI 10.1016/j.colcom.2018.03.007
   Lan Xia, 2017, Geomatics and Information Science of Wuhan University, V42, P1731, DOI 10.13203/j.whugis20150520
   Lei Jun, 2017, Systems Engineering and Electronics, V39, P1653, DOI 10.3969/j.issn.1001-506X.2017.07.32
   Li Chenxi, 2017, Systems Engineering and Electronics, V39, P2603, DOI 10.3969/j.issn.1001-506X.2017.11.30
   Li L, 2016, IET INTELL TRANSP SY, V10, P545, DOI 10.1049/iet-its.2015.0173
   Navarro J, 2017, APPL ERGON, V59, P123, DOI 10.1016/j.apergo.2016.08.010
   Navarro J, 2016, ERGONOMICS, V59, P1553, DOI 10.1080/00140139.2016.1158323
   Ososinski M, 2015, J FIELD ROBOT, V32, P504, DOI 10.1002/rob.21494
   Sebdani F. M., 2012, Proceedings of the 2012 IEEE International Conference on Computer Science and Automation Engineering (CSAE 2012), P256, DOI 10.1109/CSAE.2012.6272950
   Song W, 2018, IEEE SENS J, V18, P5151, DOI 10.1109/JSEN.2018.2832291
   Tan DK, 2017, IEEE INTEL TRANSP SY, V9, P76, DOI 10.1109/MITS.2017.2743204
   Tao Z, 2017, J FIELD ROBOT, V34, P1010, DOI 10.1002/rob.21708
   Wang Wanliang, 2019, Computer Integrated Manufacturing Systems, V25, P529, DOI 10.13196/j.cims.2019.03.001
   Xue JR, 2017, FRONT INFORM TECH EL, V18, P122, DOI 10.1631/FITEE.1601873
   Yang P, 2020, INT J COMPUT SCI ENG, V22, P146, DOI 10.1504/IJCSE.2020.107266
   [张新钰 Zhang Xinyu], 2018, [清华大学学报. 自然科学版, Journal of Tsinghua University. Science and Technology], V58, P438
NR 24
TC 1
Z9 1
U1 2
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28711
EP 28727
DI 10.1007/s11042-020-09472-7
EA AUG 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000556646300008
DA 2024-07-18
ER

PT J
AU Zhang, YZ
   Liu, SW
   Qi, L
   Coleman, S
   Kerr, D
   Shi, WD
AF Zhang, Yunzhou
   Liu, Shuangwei
   Qi, Lin
   Coleman, Sonya
   Kerr, Dermot
   Shi, Weidong
TI Multi-level and multi-scale horizontal pooling network for person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-level and multi-scale; Horizontal pooling network; Part sensitive
   loss; Person re-identification
AB Person re-identification (Re-ID) is the task of matching a target person across different cameras, which has drawn extensive attention in computer vision and has become an essential component in the video surveillance system. Despite recent remarkable progress, person re-identification methods are either subject to the power of feature representation, or give equal importance to all examples. To mitigate these issues, we introduce a simple, yet effective, Multi-level and Multi-scale Horizontal Pooling Network (MMHPN) for person re-identification. Concretely, our contributions are three-fold:1) we take partial feature representation into account at different pooling scales and different semantic levels so that various partial information is obtained to form a robust descriptor; 2) we introduce a Part Sensitive Loss (PSL) to reduce the effect of easily classified partition to facilitate training of the person re-identification network, 3) we conduct extensive experimental results using the Market-1501, DukeMTMC-reID and CUHK03 datasets and achieve mAP scores of 83.4%, 75.1% and 65.4% respectively on these challenging datasets.
C1 [Zhang, Yunzhou; Liu, Shuangwei; Qi, Lin; Shi, Weidong] Northeastern Univ China, Coll Informat Sci & Engn, Shenyang 110819, Peoples R China.
   [Coleman, Sonya; Kerr, Dermot] Ulster Univ, Intelligent Syst Res Ctr, Derry BT52 1SA, Londonderry, North Ireland.
C3 Northeastern University - China; Ulster University
RP Zhang, YZ (corresponding author), Northeastern Univ China, Coll Informat Sci & Engn, Shenyang 110819, Peoples R China.
EM zhangyunzhou@ise.neu.edu.cn
FU National Natural Science Foundation of China [61973066, 61471110];
   Foundation Project of National Key Laboratory [6142002301, 61420030302];
   Distinguished Creative Talent Program of Shenyang [RC170490];
   Fundamental Research Funds for the Central Universities [N172608005,
   N182608004]
FX This work is supported by National Natural Science Foundation of China
   (No. 61973066, 61471110), Foundation Project of National Key Laboratory
   (6142002301, 61420030302), the Distinguished Creative Talent Program of
   Shenyang(RC170490) and the Fundamental Research Funds for the Central
   Universities (N172608005, N182608004).
CR [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2018, ARXIV180105339
   Bai X, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107036
   Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008
   Chen YB, 2017, IEEE INT CONF COMP V, P2590, DOI 10.1109/ICCVW.2017.304
   Cheng D, 2018, MULTIMED TOOLS APPL, V77, P3533, DOI 10.1007/s11042-017-5182-z
   Dai Z., 2019, P IEEE INT C COMP VI
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   Guo YL, 2018, PROC CVPR IEEE, P2335, DOI 10.1109/CVPR.2018.00248
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hermans Alexander, 2017, ARXIV170307737
   Hou RB, 2019, PROC CVPR IEEE, P9309, DOI 10.1109/CVPR.2019.00954
   Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3
   Jaderberg M, 2015, ADV NEUR IN, V28
   Li D, IEEE C COMP VIS PATT, P384
   Li S, 2018, IEEE T PATTERN ANAL, V40, P2963, DOI 10.1109/TPAMI.2017.2764893
   Li W, 2018, 2018 IEEE C COMP VIS
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Yang Y, 2017, AAAI C ART INT
   Yao H., 2017, ARXIV170700798
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Yu Qian, 2017, ARXIV171108106
   Zhang Xiangyu, 2017, CoRRabs/1711.08184
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zhedong Zheng, 2017, ACM Transactions on Multimedia Computing, Communications and Applications, V14, DOI 10.1145/3159171
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng M, 2019, PROC CVPR IEEE, P5728, DOI 10.1109/CVPR.2019.00588
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhou SP, 2019, IEEE I CONF COMP VIS, P8039, DOI 10.1109/ICCV.2019.00813
NR 46
TC 5
Z9 6
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28603
EP 28619
DI 10.1007/s11042-020-09427-y
EA AUG 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000556182200003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, ZY
   Yi, XW
   Zhao, XF
AF Zhang, Zhenyu
   Yi, Xiaowei
   Zhao, Xianfeng
TI An AAC steganography scheme for adaptive embedding with distortion
   minimization model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AAC; Adaptive steganography; QMDCT coefficients; Psychoacoustic model;
   Uniform embedding
AB Nowadays, most prevailing approaches to advanced audio coding (AAC) steganography are content non-adaptive which have low embedding capacity and poor security. In this paper, we construct a new distortion by integrating the uniform embedding distortion with the masking threshold, and propose an adaptive steganographic scheme for AAC audio by modifying quantized modified discrete cosine transform (QMDCT) coefficients. To hold the statistical distribution of QMDCT coefficients we introduce uniform embedding idea. Then the psychoacoustic model is used to avoid the declining of hearing quality. Finally, we minimize the overall embedding distortion by utilizing syndrome-trellis codes (STCs) technique and the defined distortion function. Comprehensive experimental results show that the proposed scheme achieves better performance than related works. The detection error of 128-kbps-AAC dataset is higher than 24.78% when the embedding payload reaches 3.70 kbps, which is significantly lower than the state-of-the-art AAC steganographic methods.
C1 [Zhang, Zhenyu; Yi, Xiaowei; Zhao, Xianfeng] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
   [Zhang, Zhenyu; Yi, Xiaowei; Zhao, Xianfeng] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100093, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Information Engineering, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Zhao, XF (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.; Zhao, XF (corresponding author), Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100093, Peoples R China.
EM zhangzhenyu@iie.ac.cn; yixiaowei@iie.ac.cn; zhaoxianfeng@iie.ac.cn
RI zhang, zhenyu/HOA-8440-2023; Zhao, Xianfeng/AAE-7278-2021; yi,
   xiao/JHT-3220-2023
OI Zhao, Xianfeng/0000-0002-5617-8399; 
FU NSFC [61902391, 61972390, U1736214, 61802393, 61872356]; National Key
   Technology RD Program [2019QY0701, 2019QY2202, 2019QY(Y)0207]; IIE CAS
   Climbing Program
FX This work was supported by NSFC under 61902391, 61972390, U1736214,
   61802393 and 61872356, National Key Technology R&D Program under
   2019QY0701, 2019QY2202 and 2019QY(Y)0207, and IIE CAS Climbing Program.
CR [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], 2009, FAAC128
   Brandenburg K, 1996, AUDIO ENG SOC, V45, P789
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J., 2009, INFORM HIDING
   Fridrich J, 2007, PROC SPIE, V6505, DOI 10.1117/12.697471
   Guo LJ, 2014, IEEE T INF FOREN SEC, V9, P814, DOI 10.1109/TIFS.2014.2312817
   Jie Zhu, 2011, Information Technology Journal, V10, P1983, DOI 10.3923/itj.2011.1983.1988
   Johnston J. D., 1988, ICASSP 88: 1988 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.88CH2561-9), P2524, DOI 10.1109/ICASSP.1988.197157
   Jordan G, 2011, SIKHS IN EUROPE: MIGRATION, IDENTITIES AND REPRESENTATIONS, P305
   Kim C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040644
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Luo WQ, 2017, LECT NOTES COMPUT SC, V10431, P177, DOI 10.1007/978-3-319-64185-0_14
   Nissar A, 2010, DIGIT SIGNAL PROCESS, V20, P1758, DOI 10.1016/j.dsp.2010.02.003
   Painter T, 2000, P IEEE, V88, P451, DOI 10.1109/5.842996
   Ren YZ, 2017, LECT NOTES COMPUT SC, V10431, P217, DOI 10.1007/978-3-319-64185-0_17
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Standard I, 1997, INF TECHN GEN COD 7, P13818
   [唐步天 TANG Butian], 2008, [声学技术, Technical Acoustics], V27, P533
   Thiede T, 2000, J AUDIO ENG SOC, V48, P3
   Wang Pengjun, 2007, Journal of Southeast University (Natural Science Edition), V37, P149
   Wang R, 2013, CHIN J NAT MEDICINES, V11, P30, DOI 10.3724/SP.J.1009.2013.00030
   Wang Y, 2019, AUDIO STEGANALYSIS D
   Wang Yu-jie, 2011, Journal of Chinese Computer Systems, V32, P1465
   Yang K, 2017, LECT NOTES COMPUT SC, V10431, P202, DOI 10.1007/978-3-319-64185-0_16
   Zhu JZ, 2010, 2010 INTERNATIONAL COLLOQUIUM ON COMPUTING, COMMUNICATION, CONTROL, AND MANAGEMENT (CCCM2010), VOL I, P1
   Zhu YK, 2010, PROCEEDINGS OF THE 7TH CONFERENCE ON BIOLOGICAL DYNAMIC SYSTEM AND STABILITY OF DIFFERENTIAL EQUATION, VOLS I AND II, P841
NR 31
TC 4
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27777
EP 27790
DI 10.1007/s11042-020-09344-0
EA JUL 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000553718200001
DA 2024-07-18
ER

PT J
AU Garg, P
   Kishore, RR
AF Garg, Preeti
   Kishore, R. Rama
TI Performance comparison of various watermarking techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Robustness; Imperceptibility; DCT; DWT; SVD; CNN;
   NN
ID ROBUST IMAGE WATERMARKING; DIGITAL WATERMARKING; DOMAIN; SCHEME; DCT;
   SVD; OPTIMIZATION; ALGORITHM; RESISTANT; FRAMEWORK
AB Digital watermarking is a method to provide authenticity and copyright ownership to digital content by embedding any presume content like audio, text, data or video into the original content. This embedding of data should not damage the quality of the original content and should fulfill its objective also. From a decade a number of researchers are working on watermarking for providing security, robustness and imperceptibility to the digital images. This paper describes the information about watermarking in terms of its characteristics, application areas, types and various attacks performed on it. A comparative study of various techniques used in the field of watermarking is provided here by measuring their performance in terms of various characteristics. A number of performance measures used by various researchers are also discussed here along with possible attacks. This paper can help researchers to find various techniques used in watermarking field and their performances against various attacks for further proceedings.
C1 [Garg, Preeti; Kishore, R. Rama] Guru Gobind Singh Indraprastha Univ, Univ Sch Informat & Commun Technol, New Delhi, India.
   [Garg, Preeti] SGT Univ, Dept CSE, Gurugram, India.
C3 GGS Indraprastha University
RP Garg, P (corresponding author), Guru Gobind Singh Indraprastha Univ, Univ Sch Informat & Commun Technol, New Delhi, India.; Garg, P (corresponding author), SGT Univ, Dept CSE, Gurugram, India.
EM preeti.itgarg@gmail.com; ram_kish@yahoo.com
OI Garg, Preeti/0000-0001-6635-3296
CR Abdelhakim AM, 2016, IET IMAGE PROCESS, V10, P247, DOI 10.1049/iet-ipr.2015.0379
   Abdelhakim AM, 2018, EXPERT SYST APPL, V100, P197, DOI 10.1016/j.eswa.2018.02.002
   Abraham J, 2019, J KING SAUD UNIV-COM, V31, P125, DOI 10.1016/j.jksuci.2016.12.004
   Advith J, 2016, NOVEL DIGITAL IMAGE, P1
   Agarwal C, 2013, J VIS COMMUN IMAGE R, V24, P1135, DOI 10.1016/j.jvcir.2013.07.007
   Ali MM, 2014, LIBYAN J MED, V9, P1
   Ambadekar P, 2019, DIGITAL IMAGE WATERM, DOI [10.1007/978-981-10-8863-6_19, DOI 10.1007/978-981-10-8863-6_19]
   [Anonymous], 2014, MULTIMEDIA TOOLS APP
   Arnold M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1013, DOI 10.1109/ICME.2000.871531
   Asikuzzaman M, 2018, IEEE T CIRC SYST VID, V28, P2131, DOI 10.1109/TCSVT.2017.2712162
   Aziz N, 2019, RECENT APPLICATIONS IN QUANTITATIVE METHODS AND INFORMATION TECHNOLOGY, P1
   Bagheri M., 2020, ARXIV, P1, DOI [10.48550/arXiv.2001.03251, DOI 10.48550/ARXIV.2001.03251]
   Bamatraf A, 2011, INT C COMP APPL IND, P155
   Chang T, 2018, MULTIMED TOOLS APPL, V78, P1
   Chen BJ, 2014, DIGIT SIGNAL PROCESS, V28, P106, DOI 10.1016/j.dsp.2014.02.010
   Chitra K, 2016, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INFORMATICS AND ANALYTICS (ICIA' 16), DOI 10.1145/2980258.2980363
   COCO, DAT
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Dang H. V., 2012, Proceedings of the 2012 11th IEEE International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC), P115, DOI 10.1109/ICCI-CC.2012.6311135
   Deeba Farah, 2020, International Journal of Machine Learning and Computing, P277, DOI 10.18178/ijmlc.2020.10.2.932
   Deguillaume F, 2003, SIGNAL PROCESS, V83, P2133, DOI 10.1016/S0165-1684(03)00172-5
   Dehghan H, 2010, ICEE C ARXIV, P1
   Dhar J, 2019, SN APPL SCI, P1
   Doërr G, 2003, SIGNAL PROCESS-IMAGE, V18, P263, DOI 10.1016/S0923-5965(02)00144-3
   Dubolia R., 2011, 2011 International Conference on Communication Systems and Network Technologies (CSNT), P593, DOI 10.1109/CSNT.2011.127
   Fang H, 2018, MULTIMED TOOLS APPL, P1
   Fazli S, 2015, OPERATIONAL RES, P1
   Garg P, 2020, J DISCRET MATH SCI C, V23, P73, DOI 10.1080/09720529.2020.1721875
   Ghazvini M, 2017, J APPL SEC RES, V12, P260, DOI 10.1080/19361610.2017.1277878
   Gonge S, 2013, INT J ELECT ELECT DA, V1, P27
   Gupta R., 2017, MULTIMEDIA TOOLS APP, V7, P1
   Gupta S, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P332, DOI 10.1109/SPIN.2018.8474121
   Hamidi R, 2018, 1ST COLLOQUIUM PAPER: ADVANCED MATERIALS AND MECHANICAL ENGINEERING RESEARCH (CAMMER'18), P1
   Han SC, 2018, OPTOELECTRON LETT, V14, P61, DOI 10.1007/s11801-018-7212-0
   Hannoun K, 2018, IFAC PAPERSONLINE, V51, P50, DOI 10.1016/j.ifacol.2018.12.089
   Haribabu M, 2016, PROCEDIA COMPUT SCI, V93, P462, DOI 10.1016/j.procs.2016.07.234
   Hong W., 2006, IEEE T SIGNAL PROCES, V12, P1
   Hsu LY, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113225
   Hua G, 2016, SIGNAL PROCESS, V128, P222, DOI 10.1016/j.sigpro.2016.04.005
   Huang S, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P5985, DOI 10.1109/WCICA.2008.4594557
   Ingemar M. L. M., 2008, DIGITAL WATERMARKING
   Irshad A, 2017, ARAB J SCI ENG, P1
   Islam M, 2019, KARBALA INT J MODERN, V5, P1
   Issa M, 2018, STUD COMPUT INTELL, V730, P683, DOI 10.1007/978-3-319-63754-9_30
   Jagadeesh B, 2015, PROCEDIA COMPUT SCI, V46, P1618, DOI 10.1016/j.procs.2015.02.095
   Jane O, 2014, TURK J ELECTR ENG CO, V22, P1354, DOI 10.3906/elk-1212-75
   Jero SE, 2016, EXPERT SYST APPL, V49, P123, DOI 10.1016/j.eswa.2015.12.010
   Kandi H, 2017, COMPUT SECUR, V65, P247, DOI 10.1016/j.cose.2016.11.016
   Kang X, 2017, MULTIMED TOOLS APPL, P1
   Kang XB, 2020, SOFT COMPUT, V24, P10561, DOI 10.1007/s00500-019-04563-6
   Kansal M., 2012, 2012 International Conference on Computing Sciences (ICCS), P77, DOI 10.1109/ICCS.2012.28
   Kashyap N., 2012, INT J MODERN ED COMP, V4, P50, DOI [10.5815/ijmecs. 2012.03.07, DOI 10.5815/IJMECS.2012.03.07.[]
   Kimpan S, 2004, IEEE INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES 2004 (ISCIT 2004), PROCEEDINGS, VOLS 1 AND 2, P374
   Ko H. J., 2019, INFORM SCIENCES, P1
   Kumar GD, 2017, PROCEDIA COMPUT SCI, V115, P423, DOI 10.1016/j.procs.2017.09.101
   Kumar NA., 2014, INT J COMPUT APPL, V106, P13, DOI [10.5120/15675-4423, DOI 10.5120/15675-4423]
   Kumar P., 2019, International Journal of Computer Science and Information Security (IJCSIS), V18, P36
   Kundur D, 1998, INT CONF ACOUST SPEE, P2969, DOI 10.1109/ICASSP.1998.678149
   Li D, 2018, INFORM SCI, P1
   Li G, 2014, STRUCT SAF, V48, P1, DOI 10.1016/j.strusafe.2014.01.002
   Li H, 2019, PROC INT CONF DATA, P2127, DOI 10.1109/ICDE.2019.00258
   Li JZ, 2010, INT CONF COMP SCI, P367, DOI 10.1109/ICCSIT.2010.5564713
   Li N, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P942, DOI 10.1109/ISECS.2008.140
   Liu Y, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1509, DOI 10.1145/3343031.3351025
   Malik S., 2018, Int J Adv Stud Sci Res, V4, P1
   Mansoori EG, 2016, IMAGING SCI J, V64, P204, DOI 10.1080/13682199.2016.1159816
   Mathur S, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2696, DOI 10.1109/ICACCI.2016.7732468
   Meenpal Ankita, 2020, 2020 First International Conference on Power, Control and Computing Technologies (ICPC2T), P62, DOI 10.1109/ICPC2T48082.2020.9071464
   Mehta R, 2016, MULTIMED TOOLS APPL, V75, P4129, DOI 10.1007/s11042-015-3084-5
   Mingfang Jiang, 2012, Information Technology Journal, V11, P1322, DOI 10.3923/itj.2012.1322.1326
   Mishra A., 2012, 2012 INT JOINT C NEU, P1, DOI DOI 10.1109/IJCNN.2012.6252363
   Moeinaddini E, 2018, SOFT COMPUT, V23, P1
   Mohammad LA, 2013, P 2013 IEEE 9 INT C, P235, DOI [10.1109/CSPA.2013.6530048, DOI 10.1109/CSPA.2013.6530048]
   Moosazadeh M, 2017, OPTIK, V140, P975, DOI 10.1016/j.ijleo.2017.05.011
   Mukherjee DP, 2004, IEEE T MULTIMEDIA, V6, P1, DOI 10.1109/TMM.2003.819759
   Mun S. M., 2017, ARXIV, P1
   Mun SM, 2019, NEUROCOMPUTING, V337, P191, DOI 10.1016/j.neucom.2019.01.067
   Nasr A, 2016, J COMPUT SCI, P62
   Nematollahi MA., 2017, DIGITAL WATERMARKING, DOI [10.1007/978-981-10-2095-7, DOI 10.1007/978-981-10-2095-7]
   Nikolaidis A, 2001, IEEE T IMAGE PROCESS, V10, P1726, DOI 10.1109/83.967400
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   Nurul K., 2018, Methods Appl IEEE Access, V6, P1
   Parah S, 2016, DIGIT SIGNAL PROCESS, P1
   Patel S. B., 2011, Technol Research, V3, P81, DOI [10.1504/ijitst.2011.039680,2, DOI 10.1504/IJITST.2011.039680, DOI 10.1504/IJITST.2011.039680,2]
   Pereira S, 2000, IEEE T IMAGE PROCESS, V9, P1123, DOI 10.1109/83.846253
   Perwej Y., 2012, Int J Multimed Its Appl, V4, P21, DOI [10.5121/ijma.2012.4202, DOI 10.5121/IJMA.2012.4202]
   Phade R, 2013, GLOBAL J COMPUTER SC, V13, P1
   Poljicak A, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3609010
   Pradhan C, 2012, PROCEEDINGS OF THE 2012 INTERNATIONAL CONFERENCE ON COMMUNICATIONS, DEVICES AND INTELLIGENT SYSTEMS (CODLS), P274, DOI 10.1109/CODIS.2012.6422191
   Priyadarshy S., 2017, OPTIK INT J LIGHT EL, P1
   Purwar R, 2017, INT J TOMOGRAPHY SIM, V30, P53
   Rafigh Majid, 2010, Proceedings of the 2010 Seventh International Conference on Computer Graphics, Imaging and Visualization (CGIV 2010), P105, DOI 10.1109/CGIV.2010.24
   Rajani D, 2020, SIGNAL PROCESS, P1
   Saikrishna N, 2016, PROCEDIA COMPUT SCI, V93, P808, DOI 10.1016/j.procs.2016.07.299
   Savakar D, 2019, ARAB J SCI ENG, V44, P1
   Savakar D. G., 2017, Pattern Recognition and Image Analysis, V27, P511, DOI 10.1134/S1054661817030257
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Selvi C, 2016, DWT BASED WATERMARKI, P1, DOI [10.1109/ISCO.2016.7726895, DOI 10.1109/ISC0.2016.7726895]
   Sharma S, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105696
   Sharma VD, 2020, J NEUROSURG, V133, P1582, DOI 10.3171/2019.6.JNS19548
   Shih Frank Y, 2017, Digital watermarking and steganography: fundamentals and techniques
   Shivani JLD, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9030033
   Singab A.N., 2015, MED AROMATIC PLANTS, P001
   Singh A, 2014, MANAGING EMOTION IN DESIGN INNOVATION, P1
   Singh A, 2019, ADV INTELL SYST, V731, P1, DOI 10.1007/978-981-10-8848-3_1
   Singh AK, 2012, 2012 2ND IEEE INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P497, DOI 10.1109/PDGC.2012.6449871
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Singh RK, 2017, J BRAZ SOC MECH SCI, V39, P4677, DOI 10.1007/s40430-017-0839-0
   SPECHT DF, 1991, IEEE T NEURAL NETWOR, V2, P568, DOI 10.1109/72.97934
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Su Qingtang, 2017, COLOR IMAGE WATERMAR
   Sun L, 2017, NEURAL COMPUT APPL, P1
   Tech M, 2017, INT J INNOVATION ENG, V4, P1
   Thajeel S, 2018, J THEOR APPL INF TEC, P2324
   Thakkar F, 2016, MULTIMED TOOLS APPL, V76, P1
   Thien H-T, 2016, ELSEVIER EXPERT SYST, P1
   Tiwari A, 2017, AEU-INT J ELECTRON C, V78, P114, DOI 10.1016/j.aeue.2017.05.027
   Tsui TK, 2008, IEEE T INF FOREN SEC, V3, P16, DOI 10.1109/TIFS.2007.916275
   Vali M, 2018, EXPERT SYSTEMS APPL, P1
   Verma V, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P3198, DOI 10.1109/ICEEOT.2016.7755292
   Vishwakarma Virendra P., 2018, Procedia Computer Science, V132, P1012, DOI 10.1016/j.procs.2018.05.017
   Wang JY, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102627
   Wang XY, 2013, J SYST SOFTWARE, V86, P255, DOI 10.1016/j.jss.2012.08.015
   Winter F, 2019, ENERGY ENV SUSTAIN, P1, DOI 10.1007/978-981-13-3296-8_1
   Xu HC, 2018, INT J ELECTRON SECUR, V10, P79, DOI 10.1504/IJESDF.2018.089215
   Zear Aditi, 2017, International Journal of Information and Computer Security, V9, P20
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zheng WB, 2018, C IND ELECT APPL, P1233, DOI 10.1109/ICIEA.2018.8397898
   Zhou N. R., 2018, MULTIMED TOOLS APPL, P1
NR 129
TC 21
Z9 21
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25921
EP 25967
DI 10.1007/s11042-020-09262-1
EA JUL 2020
PG 47
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000546532400005
DA 2024-07-18
ER

PT J
AU Ghamsarian, N
   Khademi, M
AF Ghamsarian, Negin
   Khademi, Morteza
TI Undetectable video steganography by considering spatio-temporal
   steganalytic features in the embedding cost function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video steganography; Information hiding; Motion vector; Motion
   estimation; H; 264; AVC; Security; Syndrom-trellis code; Video
   compression; Blind steganalysis
ID DIGITAL VIDEO; ALGORITHM
AB The basic requirement of a steganography approach is security against steganalysis attacks. In other words, a steganography method is reliable as long as it withstands all of the known steganalysis approaches. In order to preserve the security of a steganography method, the statistical features of the embedded and the original media must be as close as possible. To achieve this goal, in this paper steganography is applied by introducing the following contributions. Firstly, a new method is suggested to find the most impalpable embedded motion vector (MV). Also, a novel modification cost function with respect to the MVs' intra-frame and inter-frame statistical differences before and after embedding is proposed for the syndrome-trellis coder. Furthermore, a pseudo-random generator is introduced for altering the arrangement of motion vectors which are used by the syndrome-trellis coder to improve its efficiency. Experimental results show that the proposed method is the most secure MV-based steganography scheme against the state-of-the-art video steganalysis methods as well as preserving other steganography measurements including imperceptibility and compression ratio. Moreover, the computational cost of the proposed scheme is far less than its main rival.
C1 [Ghamsarian, Negin; Khademi, Morteza] Ferdowsi Univ Mashhad, Dept Elect Engn, Mashhad, Razavi Khorasan, Iran.
C3 Ferdowsi University Mashhad
RP Khademi, M (corresponding author), Ferdowsi Univ Mashhad, Dept Elect Engn, Mashhad, Razavi Khorasan, Iran.
EM negin@itec.aau.at; khademi@um.ac.ir
RI Ghamsarian, Negin/AFS-1341-2022
OI Ghamsarian, Negin/0000-0002-0908-8972
CR Altaay AAJ, 2012, INT CONF ADV COMPUT, P122, DOI 10.1109/ACSAT.2012.25
   Aly HA, 2011, IEEE T INF FOREN SEC, V6, P14, DOI 10.1109/TIFS.2010.2090520
   [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   Bilal M, 2013, MULTIMED TOOLS APPL, V72, P306
   Böhme R, 2010, ADVANCED STATISTICAL STEGANALYSIS, P11
   Bohme R., 2010, INFORM SECURITY CRYP, Vfirst
   Budhia U, 2006, IEEE T INF FOREN SEC, V1, P502, DOI 10.1109/TIFS.2006.885020
   Cao Y., 2015, P 3 ACM WORKSH INF H, P25, DOI DOI 10.1145/2756601.2756609
   Cao Y, 2012, VIDEO STEGANALYSIS E, V19, P35, DOI DOI 10.1109/LSP.2011.2176116
   Cao Y, 2015, IEEE COMMUN LETT, V19, P203, DOI 10.1109/LCOMM.2014.2387160
   CHANG SK, 1971, INFORM SCIENCES, V3, P121, DOI 10.1016/S0020-0255(71)80002-6
   Costagliola G, 2007, J VISUAL LANG COMPUT, V18, P165, DOI 10.1016/j.jvlc.2006.06.002
   Cox Ingemar, 2008, DIGITAL WATERMARKING, V2
   Dalal Mukesh, 2018, Proceedings of the International Conference on Computing and Communication Systems. I3CS 2016. Lecture Notes in Networks and Systems (LNNS 24), P705, DOI 10.1007/978-981-10-6890-4_67
   Fang DY, 2006, IEEE INT SYMP CIRC S, P1422
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Feng Pan, 2010, 2010 IEEE International Conference on Software Engineering and Service Sciences (ICSESS 2010), P592, DOI 10.1109/ICSESS.2010.5552283
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J, 2005, IEEE T SIGNAL PROCES, V53, P3923, DOI 10.1109/TSP.2005.855393
   Fridrich J., 2004, MMSEC 04, P4
   Fridrich J, 2001, STEGANALYSIS BASED J, V4518, P11
   Fridrich J, 2013, INT CONF ACOUST SPEE, P2949, DOI 10.1109/ICASSP.2013.6638198
   Ghasemzadeh H, 2017, CORR
   Hu Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1231
   Idbeaa TF, 2015, PROC INT CONF ADV, P50, DOI 10.1109/ATC.2015.7388379
   Kapotas SK, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P277, DOI 10.1109/ICME.2008.4607425
   Ker A.D., 2013, P 1 ACM WORKSH INF H, P4558, DOI DOI 10.1145/2482513.2482965
   Kok Sheik Wong, 2009, IEEE Transactions on Circuits and Systems for Video Technology, V19, P1499, DOI 10.1109/TCSVT.2009.2022781
   Kuznetsov AV, 1974, PROBL INFORM TRANSM, V7, P132
   Li Y, 2010, INT CONF SIGN PROCES, P1833, DOI 10.1109/ICOSP.2010.5656918
   Liao K, 2012, TELECOMMUN SYST, V49, P261, DOI 10.1007/s11235-010-9372-5
   Liu B, 2008, ARES 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON AVAILABILITY, SECURITY AND RELIABILITY, P1382, DOI 10.1109/ARES.2008.140
   Moulin P, 2003, IEEE T INFORM THEORY, V49, P563, DOI 10.1109/TIT.2002.808134
   Mstafa R.J., 2015, IEEE Long Island Systems, Applications and Technology Conference (LISAT), P1, DOI 10.1109/LISAT.2015.7160192
   Rana S, 2018, ADV INTELL SYST, V624, P719, DOI 10.1007/978-981-10-5903-2_74
   Sadat ES, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040244
   Schöffmann K, 2007, LECT NOTES COMPUT SC, V4641, P782
   Shanableh T, 2012, IEEE T INF FOREN SEC, V7, P455, DOI 10.1109/TIFS.2011.2177087
   Sharp A, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (IEEE ICSIPA 2013), P182, DOI 10.1109/ICSIPA.2013.6708000
   ShengDun Hu, 2011, Proceedings of the 2011 IEEE 14th International Conference on Computational Science and Engineering (CSE 2011). 11th International Symposium on Pervasive Systems, Algorithms, Networks (I-SPAN 2011). 10th IEEE International Conference on Ubiquitous Computing and Communications (IUCC 2011), P57, DOI 10.1109/CSE.2011.24
   Su YT, 2011, SIGNAL PROCESS, V91, P1901, DOI 10.1016/j.sigpro.2011.02.012
   Tasdemir K, 2016, IEEE T IMAGE PROCESS, V25, P3316, DOI 10.1109/TIP.2016.2567073
   Wang KR, 2014, IEEE T INF FOREN SEC, V9, P741, DOI 10.1109/TIFS.2014.2308633
   Wu HT, 2014, IEEE IMAGE PROC, P5512, DOI 10.1109/ICIP.2014.7026115
   XU CY, 2006, P 1 INT C INN COMP I
   Yang GB, 2011, AEU-INT J ELECTRON C, V65, P331, DOI 10.1016/j.aeue.2010.03.011
   Yao YZ, 2015, MULTIMED TOOLS APPL, V74, P11163, DOI 10.1007/s11042-014-2223-8
   Yun Cao, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P193, DOI 10.1007/978-3-642-24178-9_14
   Zhang H., 2014, P 2 ACM WORKSH INF H, P115
   Zhang H, 2017, IEEE T INF FOREN SEC, V12, P465, DOI 10.1109/TIFS.2016.2623587
   Zhang H, 2016, MULTIMED TOOLS APPL, V75, P13503, DOI 10.1007/s11042-015-2743-x
   Zhang MS, 2014, C IND ELECT APPL, P940, DOI 10.1109/ICIEA.2014.6931298
   Zhang YN, 2017, TSINGHUA SCI TECHNOL, V22, P198
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
NR 55
TC 8
Z9 8
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 18909
EP 18939
DI 10.1007/s11042-020-08617-y
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000558544500003
DA 2024-07-18
ER

PT J
AU Li, XD
   Yu, HY
   Zhang, HY
   Jin, X
   Sun, HB
   Liu, J
AF Li, Xiaodong
   Yu, Haoyang
   Zhang, Hongyu
   Jin, Xin
   Sun, Hongbo
   Liu, Jing
TI Video encryption based on hyperchaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video encryption; Audio encryption; Hyperchaotic
AB With the increasing popularity of multimedia data on the internet and our daily life, the way people get information is becoming more diverse, video is becoming an important part of our dailylife and work. At the same time, the popularity of video also brings new security risks and challenges, more and more people are paying attention to video security issues. Based on hyperchaotic system, this paper proposes and implements a video encryption scheme. The encryption algorithm divide a video stream into a color image stream and an audio stream. Color image is composed of three-dimensional channels of Y, Cb, and Cr, the amount of practical information carried by three channels is different. Therefore, an Anorld transforms and a DNA encoding algorithm is used for the Y channel with more information. The Cb and Cr channels with less information are encrypted by Lorenz hyperchaotic map. Audio information is encrypted by Logistic chaotic map. The paper thoroughly tested the feasibility of the process of encryption and decryption, analyzed the resistance of statistical attacks and completed tests on the histogram, information entropy, and correlation of neighboring pixels. The paper also tested the scheme's ability to resist violent attacks and completed the analysis of key space, key sensitivity, signal-to-noise ratio, spectrogram, variance, and mean. At the end of the article we test the comparison of capability and efficiency of our scheme and other two methods. Results of experiment show that our scheme has better security and encryption efficiency.
C1 [Li, Xiaodong; Yu, Haoyang; Zhang, Hongyu; Jin, Xin; Sun, Hongbo; Liu, Jing] Beijing Elect Sci & Technol Inst, Dept Cyber Secur, Beijing 100070, Peoples R China.
   [Li, Xiaodong; Jin, Xin] State Key Lab Cryptol, POB 5159, Beijing 100878, Peoples R China.
C3 Beijing Electronic Science & Technology Institute
RP Jin, X (corresponding author), Beijing Elect Sci & Technol Inst, Dept Cyber Secur, Beijing 100070, Peoples R China.; Jin, X (corresponding author), State Key Lab Cryptol, POB 5159, Beijing 100878, Peoples R China.
EM jinxin@besti.edu.cn
RI li, xiao/HJP-5134-2023; Yu, Haoyang/P-4934-2017; li,
   xiaofeng/GXF-9442-2022; liang, liang/IAO-8518-2023; li,
   xiao/GSN-6181-2022; jin, xin/GQZ-5811-2022
FU National Natural Science Foundation of China [61772047,61701008]; Open
   Project Program of State Key Laboratory of Cryptology [MMKFKT201804];
   Open Project Program of State Key Laboratory of Virtual Reality
   Technology and Systems, Beihang University [VRLAB2019C03]; Fundamental
   Research Funds for the Central Universities [328201907]
FX This work is partially supported by the National Natural Science
   Foundation of China (grant numbers 61772047,61701008), the Open Project
   Program of State Key Laboratory of Cryptology (grant number.
   MMKFKT201804), the Open Project Program of State Key Laboratory of
   Virtual Reality Technology and Systems, Beihang University (grant
   number. VRLAB2019C03) and the Fundamental Research Funds for the Central
   Universities (grant number. 328201907).
CR [Anonymous], 2012, LORENZ EQUATIONS BIF
   Atlas R, 2007, OPER RES COMPUT SCI, V37, P1
   Chen ZQ, 2010, NONLINEAR DYNAM, V62, P647, DOI 10.1007/s11071-010-9751-1
   Li H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19245366
   Li JJ, 2018, MULTIMED TOOLS APPL, V77, P12837, DOI 10.1007/s11042-017-4916-2
   Li SJ, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2360697
   Lian Shi-guo, 2004, Information and Control, V33, P560
   [廉士国 Lian Shiguo], 2004, [中国图象图形学报. A, Journal of image and graphics], V9, P483
   LIPTON RJ, 1995, SCIENCE, V268, P542, DOI 10.1126/science.7725098
   Liu L, 2015, RGB IMAGE ENCRYPTION, V15, P043012
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Lui OY, 2013, J SYST SOFTWARE, V86, P3183, DOI 10.1016/j.jss.2013.07.054
   Percival D., 1993, SPECTRAL ANAL PHYS A, DOI DOI 10.1017/CBO9780511622762
   Peterson G., 1997, ARNOLDS CAT MAP, V45, P1
   Standard NIST-FIPS, 2001, FEDERAL INFORM PROCE, V197, P3
   Tsang PWM, 2011, APPL OPTICS, V50, pB46, DOI 10.1364/AO.50.000B46
   Wang L, 2011, THESIS
   Wang XY, 2007, ACTA PHYS SIN-CH ED, V56, P5136, DOI 10.7498/aps.56.5136
   Wu Min, 2003, Journal of China Institute of Communications, V24, P31
   Xin J, 2016, INT C WIR COMM SIGN
   Yang N, 2017, TECHNOLOGY INNOVATIO, V2017, P9
   Zhang X, 2017, RES COLOR IMAGE ENCR
NR 22
TC 17
Z9 17
U1 3
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 23995
EP 24011
DI 10.1007/s11042-020-09200-1
EA JUN 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000540942100001
DA 2024-07-18
ER

PT J
AU Jung, J
   Oh, R
   Lee, G
   Ahn, J
AF Jung, Juho
   Oh, Ryumduk
   Lee, Gwang
   Ahn, Junho
TI Real-time unusual user event detection algorithm fusing vision, audio,
   activity, and dust patterns
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligence; Vision; Deep learning; Unusual event; Pattern recognition
AB According to the statistics examined by the National Safety Council, Injury Facts in 2017, a significant number of preventable injury-related deaths occurred in home and indoor public areas, and the rate of preventable deaths occurring indoors has increased by 156% since 1999. Indoor smart Internet of Things devices such as security cameras, intelligent speakers, smartphones, and air cleaners are being utilized to seek help during dangerous or emergency situations in indoor settings. Theses Internet of Things devices can also assist single-person household rescues during emergency situations where no one is present for assistance. We propose a real-time algorithm to detect unusual user events which may help in reducing the rate of people dying alone and remaining undiscovered for a long period of time. We designed and developed unusual user behavior patterns related to vision, audio, dust, and activity via Internet of Things sensors and fused these patterns to improve the performance accuracy. We evaluated the proposed individual pattern algorithms and the fusion method through the data collected in indoor smart environments.
C1 [Jung, Juho; Oh, Ryumduk; Lee, Gwang; Ahn, Junho] Korea Natl Univ Transportat, Dept Software, Chungju Si, Chung Cheongbuk, South Korea.
C3 Korea National University of Transportation
RP Ahn, J (corresponding author), Korea Natl Univ Transportat, Dept Software, Chungju Si, Chung Cheongbuk, South Korea.
EM jhahn@ut.ac.kr
OI Jung, Juho/0000-0002-0321-9433
FU National Research Foundation of Korea (NRF) - Korea government (MSIP;
   Ministry of Science, ICT & Future Planning) [2017R1C1B5017847]; Korea
   National University of Transportation
FX This work was supported by the National Research Foundation of Korea
   (NRF), grant funded by the Korea government (MSIP; Ministry of Science,
   ICT & Future Planning) (No. 2017R1C1B5017847). This was also supported
   by Korea National University of Transportation in 2020.
CR Santoyo-Ramón JA, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041155
   Debard G, 2017, J SENSORS, V2017, DOI 10.1155/2017/8241910
   DHARM SJ, 2019, INTELLIGENT SPEECH S, P101
   *EUR STAT, 2019, HOUS COMP STAT
   Gemmeke JortF., 2013, 2013 IEEE workshop on applications of signal processing to audio and acoustics, P1, DOI DOI 10.1109/WASPAA.2013.6701847
   Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351
   ISLAM ZZ, 2017, P 5 INT C INT SYST I, P5, DOI DOI 10.12792/ICISIP2017.077
   Jalal A, 2019, INT BHURBAN C APPL S, P353, DOI 10.1109/IBCAST.2019.8667183
   JINGYEONG K, 2018, P KOR SOC COMP INF C, V26, P234
   정주호, 2019, [Journal of Internet Computing and Services, 인터넷정보학회논문지], V20, P77, DOI 10.7472/jksii.2019.20.1.77
   Lim M, 2018, KSII T INTERNET INF, V12, P2748, DOI 10.3837/tiis.2018.06.017
   LOUIS AAC, 2019, INT J ENG MANAG EC, V9, P1, DOI DOI 10.5815/IJEM.2019.03.01
   Mohammed HA, 2018, J PHYS CONF SER, V1032, DOI 10.1088/1742-6596/1032/1/012055
   *NAT SAF COUNC, 2017, NAT SAF COUNC INJ FA
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sahoo S, 2018, IEEE T AFFECT COMPUT, V9, P217, DOI 10.1109/TAFFC.2016.2615607
   Santos GL, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071644
   Song Jung-Eun, 2019, [Journal of The Korea Society of Computer and Information, 한국컴퓨터정보학회논문지], V24, P95, DOI 10.9708/jksci.2019.24.08.095
   Srivastava Chavi, 2020, Intelligent Systems, Technologies and Applications. Proceedings of ISTA 2018. Advances in Intelligent Systems and Computing (AISC 910), P173, DOI 10.1007/978-981-13-6095-4_13
   SUPARNA B, 2018, INT C WIR COMM SIGN, P1
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   *TENS, 2019, OBJ DET MOD ZOO
NR 23
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35773
EP 35788
DI 10.1007/s11042-020-09149-1
EA JUN 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000538977700009
DA 2024-07-18
ER

PT J
AU Hu, HD
   Wang, DY
   Gao, H
   Wei, CL
   He, YZ
AF Hu, Haidong
   Wang, Dayi
   Gao, Hao
   Wei, Chunling
   He, Yingzi
TI Vision-based position and pose determination of non-cooperative target
   for on-orbit servicing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-cooperative target; Satellite-rocket docking ring; Extra-close
   range; Feature recognition and measurement
AB For finding an effective measurement for space non-cooperative targets in close distance, a vision-based position and pose determination algorithm of non-cooperative target for on-orbit servicing is investigated. First, the satellite-rocket docking ring's region is separated from the background environment by a selected grayscale thresholding method and the Canny operator algorithm is used to extract the edge of the satellite-rocket docking ring. Furthermore, the mathematical alignment of the image plane and binocular stereo matching are used to obtain the correspondence of 3D points. Finally, the model of 3D reconstruction is established to determine the relative position and pose of the satellite-rocket docking ring. The ground simulation test shows that our method can measure the relative position and pose of the satellite-rocket docking ring effectively. The precision of the relative position is 0.001 m and that of the relative attitude is 0.1 deg., which satisfies the requirements of the relative measurement for non-cooperative target in extra-close range.
C1 [Hu, Haidong; Wei, Chunling; He, Yingzi] Beijing Inst Control Engn, Beijing, Peoples R China.
   [Wang, Dayi] Beijing Inst Spacecraft Syst Engn, Beijing, Peoples R China.
   [Gao, Hao] Nanjing Univ Posts & Telecommun, Nanjing, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Hu, HD (corresponding author), Beijing Inst Control Engn, Beijing, Peoples R China.
EM haidong_2005@163.com
CR Cai H, 2005, J ASTRONAUT SCI, V36, P715
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chong S, 2018, IEEE C COMP VIS PATT
   Debus T.J., 2009, Proceedings of the 2009 AIAA In-fotech@Aerospace Conference, P1, DOI [DOI 10.2514/6.2009-1870, 10.2514/6.2009-1870]
   Du XD, 2011, ACTA ASTRONAUT, V68, P2047, DOI 10.1016/j.actaastro.2010.10.021
   Ke Z, 2016, IEEE T CIRC SYST VID, V28, P1301
   Leinz MR, 2008, P SOC PHOTO-OPT INS, V6958, p69580A
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Miravet C, 2008, AUT C, P1
   Miravet C, 2008, 7 INT ESA C GUID NAV, P1
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Sullivan Brook, 2013, AIAA SPACE 2013 Conference and Exposition
   Wang D, 2015, IEEE T IMAGE PROCESS, V24, P2646, DOI 10.1109/TIP.2015.2427518
   Wingo DR, 2004, AIAA 2 RESP SPAC C, P1
   Xu WF, 2009, OPTICS PRECISION ENG, V17, P1571
NR 18
TC 11
Z9 13
U1 5
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14405
EP 14418
DI 10.1007/s11042-018-6696-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900006
DA 2024-07-18
ER

PT J
AU Singh, L
   Singh, AK
   Singh, PK
AF Singh, Laxmanika
   Singh, A. K.
   Singh, P. K.
TI Secure data hiding techniques: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Steganography; Cryptography; Robustness; Imperceptibility
ID DIGITAL IMAGE WATERMARKING; ROBUST; SCHEME; AUTHENTICATION;
   STEGANOGRAPHY; COMPRESSION; ENCRYPTION; RDWT
AB This article presents a detailed discussion of different prospects of digital image watermarking. This discussion of watermarking included: brief comparison of similar information security techniques, concept of watermark embedding and extraction process, watermark characteristics and applications, common types of watermarking techniques, major classification of watermarking attacks, brief summary of various secure watermarking techniques. Further, potential issues and some existing solutions are provided. Furthermore, the performance comparisons of the discussed techniques are presented in tabular format. Authors believe that this article contribution will provide as catalyst for potential researchers to implement efficient watermarking systems.
C1 [Singh, Laxmanika; Singh, P. K.] Jaypee Univ IT, Dept CSE & IT, Solan, Himachal Prades, India.
   [Singh, A. K.] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
C3 Jaypee University of Information Technology; National Institute of
   Technology (NIT System); National Institute of Technology Patna
RP Singh, AK (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
EM laxmanika.singh81@gmail.com; amit_245singh@yahoo.com;
   pradeep_84cs@yahoo.com
RI Singh, Ashwani/GQP-2566-2022; SINGH, ASHUTOSH KUMAR/KHY-2988-2024
CR Ahmad S, 2004, E-TECH 2004, P10, DOI 10.1109/ETECH.2004.1353837
   Ahmad S, 2007, CIS WORKSHOPS 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY WORKSHOPS, P676
   Aleksandrova M, 2017, INT SPR SEM ELECT TE
   [Anonymous], INT J SIGNAL IMAGE P
   [Anonymous], 2007, INT C BIOM BERL HEID
   [Anonymous], 2015, THESIS
   [Anonymous], 1999, DIGITAL WATERMARKING
   Baiying Lei, 2019, Multimedia Tools and Applications, V78, P27085, DOI 10.1007/s11042-017-4743-5
   Bartlow N, 2007, 2007 IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P192, DOI 10.1109/AUTOID.2007.380618
   Bhowmik D, 2016, IEEE ACCESS, V4, P8002, DOI 10.1109/ACCESS.2016.2627241
   Bianchi T, 2013, IEEE SIGNAL PROC MAG, V30, P87, DOI 10.1109/MSP.2012.2228342
   Bianchi T, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/716357
   Caldelli R, 2006, SIGNAL PROCESS-IMAGE, V21, P890, DOI 10.1016/j.image.2006.08.006
   Cao XY, 2016, J ELECTR COMPUT ENG, V2016, DOI 10.1155/2016/3219042
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Chang CC, 2011, J SYST SOFTWARE, V84, P1462, DOI 10.1016/j.jss.2011.02.029
   Chang IC, 2015, SIGNAL PROCESS, V108, P376, DOI 10.1016/j.sigpro.2014.09.036
   Chen J, 2010, IMAGING SCI J, V58, P177, DOI 10.1179/136821910X12651933390629
   Chen YY, 2019, MULTIMEDIA SYST, V25, P551, DOI 10.1007/s00530-017-0560-y
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Dharwadkar N. V., 2010, Int. J. Signal Process., V6, P93
   Fridrich J, 2004, PROC SPIE, V5306, P354, DOI 10.1117/12.525418
   Golea N., 2010, IEEE INT C COMPUTER, P1
   Gordy JD, 2000, PROCEEDINGS OF THE 43RD IEEE MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS I-III, P456, DOI 10.1109/MWSCAS.2000.951682
   Gunjal BL, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-0904-z
   Guo JT, 2015, J VIS COMMUN IMAGE R, V30, P125, DOI 10.1016/j.jvcir.2015.03.009
   Gupta R., 2017, MULTIMEDIA TOOLS APP, V7, P1
   Gupta R, 2015, 2015 1ST INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P46, DOI 10.1109/NGCT.2015.7375080
   Haddad S, 2017, IRBM, V38, P198, DOI 10.1016/j.irbm.2017.06.007
   Hien TD, 2006, SIGNAL PROCESS, V86, P2981, DOI 10.1016/j.sigpro.2005.12.003
   Hong W, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P13, DOI 10.1109/CISP.2008.638
   Hossain MS, 2016, COMPUT NETW, V101, P192, DOI 10.1016/j.comnet.2016.01.009
   Hsu CS, 2010, OPT COMMUN, V283, P1737, DOI 10.1016/j.optcom.2009.12.073
   Hsu CS, 2005, OPT ENG, V44, DOI 10.1117/1.1951647
   Huang CH, 2009, IEEE T INF FOREN SEC, V4, P193, DOI 10.1109/TIFS.2009.2020778
   Jiang L, 2018, MULTIMED TOOLS APPL, V77, P30575, DOI 10.1007/s11042-018-6142-y
   Kalra GS, 2015, MULTIMED TOOLS APPL, V74, P6849, DOI 10.1007/s11042-014-1932-3
   Kaur G., 2013, International Journal of Innovative Technology and Exploring Engineering, V2, P181
   Kim J, 2010, SIGNAL PROCESS-IMAGE, V25, P559, DOI 10.1016/j.image.2010.07.004
   Kim WG, 2009, SIGNAL PROCESS, V89, P2385, DOI 10.1016/j.sigpro.2009.04.014
   Kittawi Nour, 2017, 2017 8th International Conference on Information Technology (ICIT). Proceedings, P808, DOI 10.1109/ICITECH.2017.8079951
   Kumar GD, 2017, PROCEDIA COMPUT SCI, V115, P423, DOI 10.1016/j.procs.2017.09.101
   Lei BY, 2013, J SYST SOFTWARE, V86, P1638, DOI 10.1016/j.jss.2013.02.022
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Majumder S, 2013, IET BIOMETRICS, V2, P21, DOI 10.1049/iet-bmt.2012.0052
   Marvel LM, 1999, IEEE T IMAGE PROCESS, V8, P1075, DOI 10.1109/83.777088
   Mohanty S. P., 1999, P 7 ACM INT C MUL OC, P49
   Mohanty SP, 2017, IEEE CONSUM ELECTR M, V6, P83, DOI 10.1109/MCE.2017.2684980
   Moon D, 2005, LECT NOTES ARTIF INT, V3802, P635
   Naderahmadian Yashar, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P127, DOI 10.1109/IIHMSP.2010.39
   Ou DH, 2015, MULTIMED TOOLS APPL, V74, P9117, DOI 10.1007/s11042-014-2059-2
   Park KR, 2007, LECT NOTES COMPUT SC, V4432, P415
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P1597, DOI 10.1016/j.dsp.2010.03.010
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P442, DOI 10.1016/j.dsp.2009.07.004
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   Rawat S, 2011, AEU-INT J ELECTRON C, V65, P840, DOI 10.1016/j.aeue.2011.01.016
   Seenivasagam V, 2013, COMPUT MATH METHODS, V2013, P1
   Shang-Lin Hsieh, 2008, Journal of Multimedia, V3, P42
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   SINGH AK, 2016, HDB RES MODERN CRYPT, P246, DOI DOI 10.4018/978-1-5225-0105-3.CH011
   Singh AK, 2018, FUTURE GENER COMP SY, V86, P926, DOI 10.1016/j.future.2016.11.023
   Song W, 2011, J CENT SOUTH UNIV T, V18, P116, DOI 10.1007/s11771-011-0668-8
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Su QT, 2017, AEU-INT J ELECTRON C, V78, P64, DOI 10.1016/j.aeue.2017.05.025
   Su QT, 2014, MULTIMED TOOLS APPL, V72, P987, DOI 10.1007/s11042-013-1653-z
   Tanha Maryam., 2012, 2012 INT C CYBER SEC, P265, DOI DOI 10.1109/CYBERSEC.2012.6246095
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Vatsa M, 2006, IEICE ELECTRON EXPR, V3, P23, DOI 10.1587/elex.3.23
   Vatsa M, 2009, IMAGE VISION COMPUT, V27, P293, DOI 10.1016/j.imavis.2007.05.003
   Wang MS, 2009, COMPUT STAND INTER, V31, P757, DOI 10.1016/j.csi.2008.09.003
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Yeung MM, 1998, J ELECTRON IMAGING, V7, P578, DOI 10.1117/1.482612
   Yin ZX, 2014, SCI WORLD J, DOI 10.1155/2014/604876
   Zhang J, 2011, COMPUT J, V54, P1661, DOI 10.1093/comjnl/bxr078
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   [No title captured]
   [No title captured]
NR 80
TC 56
Z9 57
U1 3
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 15901
EP 15921
DI 10.1007/s11042-018-6407-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600007
DA 2024-07-18
ER

PT J
AU Xie, WD
   Cheng, XC
AF Xie, Wen-da
   Cheng, Xiaochun
TI Imbalanced big data classification based on virtual reality in cloud
   computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; Cloud computing; Big data; Imbalance; Classification
AB Currently, there are many problems in imbalanced big data classification based on rough set with virtual reality technology in cloud computing. For example, redundant big data cleaning is not clear, the effect is poor for big data denoising and feature extraction, and the precision of classification is low. In this paper, an imbalanced big data classification is proposed based on Hubness and K nearest neighbor to address such problems. First, the SNM algorithm is used in order to efficient cleaning of redundant big data. Then, wavelet threshold denoising algorithm is used to denoise the big data to improve the denoising effect. Meantime, feature of big data is extracted based on Lyapunov theorem. Moreover, the Hubness and K-nearest neighbor algorithms are used to achieve high precision of imbalanced big data classification. Experiments verify that the proposed method effectively strengthens current cleaning and denoising methods of redundant imbalanced big data, as well as improves accuracy of extraction and classification of big data.
C1 [Xie, Wen-da] Jiangmen Polytech, Dept Elect & Informat Technol, Jinengmen 529000, Peoples R China.
   [Cheng, Xiaochun] Middlesex Univ, Sch Comp Sci, London, England.
C3 Middlesex University
RP Cheng, XC (corresponding author), Middlesex Univ, Sch Comp Sci, London, England.
EM X.cheng@mdx.ac.uk
RI Cheng, Xiaochun/AAA-8538-2019
OI Cheng, Xiaochun/0000-0003-0371-9646
CR Ammari H, 2015, J COMPUT PHYS, V301, P201, DOI 10.1016/j.jcp.2015.08.027
   Cestarelli V, 2015, BIOINFORMATICS, V32, P5
   Ding QC, 2015, IEEE T IND ELECTRON, V62, P4994, DOI 10.1109/TIE.2015.2403797
   Duan MX, 2018, IEEE T NEUR NET LEAR, V29, P2337, DOI 10.1109/TNNLS.2017.2654357
   Ellison DW, 2015, NEW ENGL J MED, V372, P2555, DOI 10.1056/NEJMe1506813
   Guan HY, 2015, REMOTE SENS LETT, V6, P864, DOI 10.1080/2150704X.2015.1088668
   Lee YC, 2015, ERGONOMICS, V58, P513, DOI 10.1080/00140139.2014.974683
   Lienert D, 1998, PHYTOCHEM ANALYSIS, V9, P88, DOI 10.1002/(SICI)1099-1565(199803/04)9:2<88::AID-PCA384>3.0.CO;2-4
   Lin KC, 2016, J SUPERCOMPUT, V72, P3210, DOI 10.1007/s11227-016-1631-0
   Liu GC, 2018, IEEE ACCESS, V6, P29283, DOI 10.1109/ACCESS.2018.2834916
   Liu S, 2018, COMPLEXITY, DOI 10.1155/2018/2016976
   Liu S, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19060269
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8
   Liu SA, 2017, MULTIMED TOOLS APPL, V76, P5787, DOI 10.1007/s11042-014-2408-1
   Liu Zhi-qing, 2016, Optics and Precision Engineering, V24, P210, DOI 10.3788/OPE.20162401.0210
   Mirza B, 2016, NEURAL NETWORKS, V80, P79, DOI 10.1016/j.neunet.2016.04.008
   Pan Z, 2018, J PARALLEL DISTR COM, V120, P182, DOI 10.1016/j.jpdc.2018.06.012
   Reese H, 2015, INT J REMOTE SENS, V36, P403, DOI 10.1080/2150704X.2014.999382
   Simmonds P, 2015, J GEN VIROL, V96, P1193, DOI 10.1099/jgv.0.000016
   Tu EM, 2016, INFORM SCIENCES, V367, P673, DOI 10.1016/j.ins.2016.07.016
   Wang L, 2017, J CEREBR BLOOD F MET, V37, P48
   Wei-Ping LI, 2017, J MINES MET FUELS, V65, P169
   Zhang Shaoping, 2015, Journal of Computer Applications, V35, P1306, DOI 10.11772/j.issn.1001-9081.2015.05.1306
NR 23
TC 7
Z9 7
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16403
EP 16420
DI 10.1007/s11042-019-7317-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600033
DA 2024-07-18
ER

PT J
AU Montagud, M
   Boronat, F
   Pastor, J
   Marfil, D
AF Montagud, Mario
   Boronat, Fernando
   Pastor, Javier
   Marfil, Dani
TI Web-based platform for a customizable and synchronized presentation of
   subtitles in single- and multi-screen scenarios
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Accessibility; Multi-screen; QoE; Personalization; Subtitles;
   Synchronization
AB This paper presents a web-based platform for a customized and synchronized presentation of subtitles in both single- and multi-screen scenarios. The platform enables a dynamic user-level customization of subtitles in terms of format (font family, size, color, transparency...) and position, according to the users' preferences and/or needs. It also allows adjusting the number of subtitle lines to be presented, being able to skip to the corresponding playout position of the beginning of a specific line by clicking on it. Likewise, multiple languages can be simultaneously presented, and a delay offset to the presentation of subtitles can be applied. All these functionalities can also be available on companion devices, by associating them to the session on the main screen. This enables the presentation of subtitles in a synchronized manner with the content on the main screen and their independent customization. The platform provides support for different subtitle formats, as well as for HTML5 and Youtube videos. It includes a module to upload videos and their subtitle files, and to manage playlists. Overall, the platform enables personalized and more engaging consumption experiences, contributing to improve the Quality of Experience (QoE). It can additionally provide benefits in a variety of scenarios, such as language learning, crowded multi-culture and noisy environments. The results from a subjective evaluation study, with the participation of 40 users without accessibility needs, reveal that the platform can provide relevant benefits for the whole spectrum of consumers. In particular, users have been very satisfied with the usability, attractiveness, effectiveness and usefulness of all features of the platform.
   Graphical abstract Demo video:
C1 [Montagud, Mario; Boronat, Fernando; Pastor, Javier; Marfil, Dani] Univ Politecn Valencia UPV, Campus Gandia, Valencia, Spain.
   [Montagud, Mario] Univ Valencia UV, Valencia, Spain.
C3 Universitat Politecnica de Valencia; University of Valencia
RP Montagud, M (corresponding author), Univ Politecn Valencia UPV, Campus Gandia, Valencia, Spain.; Montagud, M (corresponding author), Univ Valencia UV, Valencia, Spain.
EM mamontor@gmail.com; fboronat@dcom.upv.es; fjpastor@dib.upv.es;
   damarre@dcom.upv.es
RI Boronat, Fernando/A-3234-2011; Marfil Reguero, Daniel/B-8731-2019
OI Boronat, Fernando/0000-0001-5525-3441; Marfil Reguero,
   Daniel/0000-0002-7918-3342
FU Spanish Ministry of Economy and Competitiveness, under its R&D&I Support
   Program [TEC2013-45492-R]; Fundacion Espanola para la Ciencia y
   Tecnologia (FECYT) [FCT-15-9579]; Spanish Ministry of Science,
   Innovation and Universities; Juan de la Cierva - Incorporacion grant
   [IJCI-2017-34611]
FX This work has been funded, partially, by the Spanish Ministry of Economy
   and Competitiveness, under its R&D&I Support Program, in project with
   Ref. TEC2013-45492-R, and by "Fundacion Espanola para la Ciencia y
   Tecnologia (FECYT)", in project with Ref. FCT-15-9579. Work by Mario
   Montagud has been additionally funded by the Spanish Ministry of
   Science, Innovation and Universities with a Juan de la Cierva -
   Incorporacion grant, with reference IJCI-2017-34611. Finally, the
   authors would also like to thank our student Juan Gonzalez for his
   contribution in the development of the platform.
CR [Anonymous], 2010, LISTENING SUBTITLES
   [Anonymous], 2010, LISTENING SUBTITLES
   Armstrong M, 2015, IBC 2015
   ARMSTRONG M, 2013, 259 WHP BBC RES DEV
   ARNTZEN IM, 2018, MEDIASYNC HDB MULTIM
   BASTANFARD A, 2010, ADV MULTIMEDIA INFOR
   *BBC, 2019, SUBT GUID
   BORONAT F, 2018, IEEE T BROADCASTING, V64
   BROWN A, 2015, ACM TVX 15
   Foerster A., 2010, New Insights into Audiovisual Translation and Media Accessibility, P81
   GOMEZ D, 2018, ACM MMSYS 18
   *HBBTV ASS RES LIB, 2016, HYBR BROADC BROADB T
   Hong R., 2011, ACM Trans. Multimedia Comput. Commun. Appl, V7S
   Hu YT, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2632111
   Jensema CJ, 2000, AM ANN DEAF, V145, P275, DOI 10.1353/aad.2012.0093
   Lavaur JM, 2011, INT J PSYCHOL, V46, P455, DOI 10.1080/00207594.2011.565343
   Lee Daniel G, 2007, Comput. Entertain., V5, P11, DOI [DOI 10.1145/1279540.1279551, 10.1145/1279540.1279551]
   LEMIEUX P, 2018, TTML PROFILES INTERN
   Montagud M., 2017, ACM TVX 2017
   Montagud M, 2018, TVX 2018: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P245, DOI 10.1145/3210825.3213570
   Montagud M, 2017, COMPUT COMMUN, V103, P61, DOI 10.1016/j.comcom.2017.01.017
   Montagud M, 2016, COMM COM INF SC, V605, P26, DOI 10.1007/978-3-319-38907-3_4
   Montagud M, 2012, MULTIMEDIA SYST, V18, P459, DOI 10.1007/s00530-012-0278-9
   Neate T, 2017, PERS UBIQUIT COMPUT, V21, P391, DOI 10.1007/s00779-017-1016-2
   Neate T, 2015, BRITISH HCI 2015, P285, DOI 10.1145/2783446.2783613
   Pereira A., 2010, LISTENING SUBTITLES, P87
   Petrie Helen., 2009, The universal access handbook, V1, P1, DOI 10.1201/9781420064995-c20
   PIETERS S, 2017, WEBVTT WEB VIDEO TEX
   PORTEIRO M, 2012, PERSPECT STUD TRANSL, V21, P1
   POWER CD, 2018, WEB ACCESSIBILITY FD
   Rodriguez-Alsina A, 2012, SENSORS-BASEL, V12, P8710, DOI 10.3390/s120708710
   VANATTENHOVEN J, 2018, MEDIASYNC HDB MULTIM
   VANDEVENTER MO, 2018, MEDIASYNC HDB MULTIM
   VINAYAGAMOORTHY V, 2016, ACM TVX 16
   Vy QV, 2010, LECT NOTES COMPUT SC, V6179, P247, DOI 10.1007/978-3-642-14097-6_40
   ZIEGLER C, 2017, ACM TVX 17
   2015, DIAL DISCOVERY LAUNC
NR 37
TC 7
Z9 7
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21889
EP 21923
DI 10.1007/s11042-020-08955-x
EA MAY 2020
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000532672800004
DA 2024-07-18
ER

PT J
AU Agarwal, A
   Gupta, A
AF Agarwal, Aanchal
   Gupta, Abhinav
TI A maximum relevancy and minimum redundancy feature selection approach
   for median filtering forensics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital forensics; Median filtering; Combined features set
AB The forensics of the median filtering is a challenging task due to its content preserving nature. Several methods have been proposed for median filtering forensics in digital images. However the performance of these methods deteriorates for compressed images, small resolutions of images and for anti-forensic operations. Moreover large feature set dimensions of these methods also pose a computational challenge. This paper proposes, a 8-dimensional feature set, derived from two state-of-the-art techniques by employing maximum relevancy and minimum redundancy (mRMR) feature selection approach. Features are selected by mRMR on the basis of distance correlation as an association measure. Extensive experiments are performed to evaluate the efficacy of proposed method through six different databases. The proposed method outperforms state-of-the-art techniques for uncompressed images, compressed images at low quality factors, low resolutions images and for an anti-forensic operation. The performance of the proposed method is also compared with convolutional neural network (CNN) based features for the detection of median filtering at low resolutions and for compressed images. Also, experimental results support the performance of proposed method over other manipulations (average and Gaussian filtering).
C1 [Agarwal, Aanchal; Gupta, Abhinav] Jaypee Inst Informat Technol, Elect & Commun Engn Dept, Noida, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Gupta, A (corresponding author), Jaypee Inst Informat Technol, Elect & Commun Engn Dept, Noida, India.
EM abhinav.gupta@jiit.ac.in
OI GUPTA, ABHINAV/0000-0002-1939-5407; Agarwal, Aanchal/0000-0001-5058-8031
CR Aljawarneh S, 2018, MULTIMED TOOLS APPL, V77, P10997, DOI 10.1007/s11042-017-4873-9
   Aljawarneh S, 2017, MULTIMED TOOLS APPL, V76, P22703, DOI 10.1007/s11042-016-4333-y
   Aljawarneh SA, 2016, FUTURE GENER COMP SY, V60, P67, DOI 10.1016/j.future.2016.01.020
   [Anonymous], 1981, Median filtering: statistical properties, DOI DOI 10.1007/BFB0057597
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bas P., 2007, Break our Watermarking System, V2nd
   BOVIK AC, 1987, IEEE T ACOUST SPEECH, V35, P493, DOI 10.1109/TASSP.1987.1165153
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen CC, 2013, INT J DISTRIB SENS N, DOI [10.1007/978-3-642-36373-3_1, 10.1155/2013/620248]
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Cuevas A, 2015, ARXIV150703496
   Dang-Nguyen D.T., 2015, P ACM MULT SYST C, P219
   Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523, DOI 10.1109/CSB.2003.1227396
   Fan W, 2015, IEEE T INF FOREN SEC, V10, P1076, DOI 10.1109/TIFS.2015.2398362
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   Gupta A, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3176650
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Kirchner M, 2010, PROC SPIE, V7541, DOI 10.1117/12.839100
   Kirchner M, 2008, IEEE T INF FOREN SEC, V3, P582, DOI 10.1109/TIFS.2008.2008214
   NRCS, 2019, NAT RES CONS SERV PH
   Peng AJ, 2019, IEEE ACCESS, V7, P28525, DOI 10.1109/ACCESS.2019.2897761
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Rhee KH, 2015, 2015 IEEE 5TH INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS - BERLIN (ICCE-BERLIN), P103, DOI 10.1109/ICCE-Berlin.2015.7391206
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Stamm MC, 2011, IEEE T INF FOREN SEC, V6, P1050, DOI 10.1109/TIFS.2011.2119314
   Stamm MC, 2010, IEEE T INF FOREN SEC, V5, P492, DOI 10.1109/TIFS.2010.2053202
   Székely GJ, 2007, ANN STAT, V35, P2769, DOI 10.1214/009053607000000505
   Vergara JR, 2014, NEURAL COMPUT APPL, V24, P175, DOI 10.1007/s00521-013-1368-0
   Yang JQ, 2018, MULTIMED TOOLS APPL, V77, P7931, DOI 10.1007/s11042-017-4691-0
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
NR 30
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21743
EP 21770
DI 10.1007/s11042-020-08994-4
EA MAY 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000531793100002
DA 2024-07-18
ER

PT J
AU Hua, KL
   Ho, TT
   Jangtjik, KA
   Chen, YJ
   Yeh, MC
AF Hua, Kai-Lung
   Ho, Trang-Thi
   Jangtjik, Kevin-Alfianto
   Chen, Yu-Jen
   Yeh, Mei-Chen
TI Artist-based painting classification using Markov random fields with
   convolution neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Multi-scale pyramid; Markov random fields;
   Convolutional neural network
ID DEPTH MAP SUPERRESOLUTION; DEEP
AB Determining the authorship of a painting image is a challenging task because paintings of an artist may not have a unique style and various artists may have similar painting styles. In this paper, we present a new approach to categorize digital painting images based on artist. We construct a multi-scale pyramid from a painting image to consider both globally and locally the information contained in one image. For each layer, we train a Convolutional Neural Network (CNN) model to determine the class label. To build the relationship within local image patches, we employ Markov random fields (MRFs) by optimizing the Gibbs energy function defined by (1) the data term measuring the compatibility of labeling with given data, and (2) the smoothness term penalizing assignments that label neighboring patches differently. A new fusion scheme is proposed to aggregate patch-level classification results. The proposed CNN-MRF method is validated using two challenging painting image datasets. Experimental results show that the proposed method is effective and achieves state-of-the-art performance.
C1 [Hua, Kai-Lung; Ho, Trang-Thi; Jangtjik, Kevin-Alfianto] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Chen, Yu-Jen] MacKay Mem Hosp, Taipei, Taiwan.
   [Yeh, Mei-Chen] Natl Taiwan Normal Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology; Mackay Memorial
   Hospital; National Taiwan Normal University
RP Yeh, MC (corresponding author), Natl Taiwan Normal Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
EM myeh@csie.ntnu.edu.tw
OI Thi Ho, Trang/0000-0001-7541-3932; Hua, Kai-Lung/0000-0002-7735-243X;
   Yeh, Mei-Chen/0000-0001-8665-7860
CR [Anonymous], PAINTINGDB FAST GROW
   [Anonymous], 2011, Proceedings of the 19th ACM international conference on Multimedia, DOI [DOI 10.1145/2072298.2072344, 10.1145/2072298.2072344.URL, DOI 10.1145/2072298.2072344.URL]
   [Anonymous], MARKOV RANDOM FIELDS
   [Anonymous], 2019, P 2019 4 INT C MULTI
   Chang YT, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P91, DOI 10.1145/3123266.3123268
   Che YL, 2019, INT CONF ACOUST SPEE, P2222, DOI [10.1109/ICASSP.2019.8682382, 10.1109/icassp.2019.8682382]
   CLIFFORD, 1971, MARKOV FIELDS FINITE, P46
   Cordero-Maldonado ML, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0202377
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Guo J, 2019, INFORM FUSION, V51, P224, DOI 10.1016/j.inffus.2019.02.007
   Guo YM, 2018, MULTIMED TOOLS APPL, V77, P10251, DOI 10.1007/s11042-017-5443-x
   Hua KL, 2015, ONCOTARGETS THER, V8, P2015, DOI 10.2147/OTT.S80733
   Jangtjik KA, 2016, P 24 ACM INT C MULT, P635, DOI DOI 10.1145/2964284.2967299
   Jangtjik KA, 2017, IEEE IMAGE PROC, P2866, DOI 10.1109/ICIP.2017.8296806
   Kalliatakis G, 2019, IEEE ACCESS, V7, P10045, DOI 10.1109/ACCESS.2019.2891745
   Katib I., 2011, Proceedings of the 2011 23rd International Teletraffic Congress (ITC 2011), P31
   Ke JC, 2019, MULTIMED TOOLS APPL, V78, P7667, DOI 10.1007/s11042-018-6277-x
   Kelek MO, 2019, PROCEDIA COMPUT SCI, V154, P369, DOI 10.1016/j.procs.2019.06.053
   Khan S, 2019, PATTERN RECOGN LETT, V125, P1, DOI 10.1016/j.patrec.2019.03.022
   Kim D, 2012, IEEE IMAGE PROC, P553, DOI 10.1109/ICIP.2012.6466919
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar S, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P800, DOI 10.1109/SPIN.2018.8474290
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lee J, 2020, MULTIVAR BEHAV RES, V55, P149, DOI 10.1080/00273171.2019.1697862
   Liu ZW, 2018, IEEE T PATTERN ANAL, V40, P1814, DOI 10.1109/TPAMI.2017.2737535
   Lo KH, 2013, INT CONF ACOUST SPEE, P1414, DOI 10.1109/ICASSP.2013.6637884
   Lu JB, 2011, INT CONF ACOUST SPEE, P985
   Lubomirsky B, 2014, SOC WORK MENT HEALTH, V12, P69, DOI 10.1080/15332985.2013.841611
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Peng KC, 2015, IEEE IMAGE PROC, P3057, DOI 10.1109/ICIP.2015.7351365
   Qi HC, 2011, INT CONF ACOUST SPEE, P2036
   Qiu ZS, 2019, IEEE SENS J, V19, P4290, DOI 10.1109/JSEN.2019.2893892
   Sanchez-Riera J, 2018, IEEE T CIRC SYST VID, V28, P2289, DOI 10.1109/TCSVT.2017.2718622
   Sandoval C, 2019, IEEE ACCESS, V7, P41770, DOI 10.1109/ACCESS.2019.2907986
   Sudharshan PJ, 2019, EXPERT SYST APPL, V117, P103, DOI 10.1016/j.eswa.2018.09.049
   Sun MJ, 2015, IEEE IMAGE PROC, P626, DOI 10.1109/ICIP.2015.7350874
   Tan WR, 2016, IEEE IMAGE PROC, P3703, DOI 10.1109/ICIP.2016.7533051
   Wang W, 2014, PROC VLDB ENDOW, V7, P649, DOI 10.14778/2732296.2732301
   WikiArt, 2016, WIKIART ONL HOM VIS
   Yang XF, 2018, IEEE T GEOSCI REMOTE, V56, P5408, DOI 10.1109/TGRS.2018.2815613
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
   Zhao SC, 2015, IEEE IMAGE PROC, P2459, DOI 10.1109/ICIP.2015.7351244
   Zhong S-h, 2019, INT J MACH LEARN CYB, P1
   Zhong SH, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2957754
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 46
TC 12
Z9 12
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12635
EP 12658
DI 10.1007/s11042-019-08547-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400061
DA 2024-07-18
ER

PT J
AU Chen, MS
   Chen, JX
   Yang, P
   Liu, SC
   Tang, K
AF Chen, Minshi
   Chen, Jianxun
   Yang, Peng
   Liu, Shengcai
   Tang, Ke
TI A heuristic repair method for dial-a-ride problem in intracity logistic
   based on neighborhood shrinking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dial-A-Ride problem; Intra-city logistic; Heuristic search; Heuristic
   repairment method
ID LOCAL SEARCH HEURISTICS
AB The Dial-a-ride problem (DARP) is a challenging combinatorial optimization problem with lots of applications in the real world. It has so many applications in the smart city like bus intelligent scheduling and taxi intelligent scheduling. However, most of these works rarely address how to handle the infeasible initial solution. The infeasible solution is an unstable factor in the search framework which gives a negative influence on the quality of the final local optimal solution. In this paper, we present a heuristic repair method (HRM) for DARP. Based on a greedy strategy and proper evaluation function, the HRM will reduce the infeasibility of the most infeasible route by deleting several waypoints in the route and reinsert them into one feasible route. The result of experiments shows that HRM can raise about 50% of the fixing ability of a local search operator.
C1 [Chen, Minshi; Chen, Jianxun] Wuhan Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430065, Peoples R China.
   [Chen, Minshi; Yang, Peng; Tang, Ke] Southern Univ Sci & Technol, Univ Key Lab Evolving Intelligent Syst Guangdong, Dept Comp Sci & Engn, Shenzhen 518055, Peoples R China.
   [Chen, Minshi; Chen, Jianxun] Wuhan Univ Sci & Technol, Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan 430065, Peoples R China.
   [Liu, Shengcai] Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei 230027, Peoples R China.
C3 Wuhan University of Science & Technology; Southern University of Science
   & Technology; Wuhan University of Science & Technology; Chinese Academy
   of Sciences; University of Science & Technology of China, CAS
RP Chen, JX (corresponding author), Wuhan Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430065, Peoples R China.; Chen, JX (corresponding author), Wuhan Univ Sci & Technol, Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan 430065, Peoples R China.
EM kanberra354562007@gmail.com; cjxwh@wust.edu.cn; yangp@sustech.edu.cn;
   liuscyyf@mail.ustc.edu.cn; tangk3@sustech.edu.cn
RI Liu, Shengcai/ABA-9832-2020; chen, jianxun/JVO-9091-2024
FU Natural Science Foundation of China [61806090, 61672478, 61602349];
   Shenzhen Peacock Plan [KQTD2016112514355531]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant 61806090 , Grant 61672478 and Grant 61602349, in part
   by the Shenzhen Peacock Plan under Grant KQTD2016112514355531.
CR Acampora Gi, 2020, COMPUTATIONAL INTELL, P53, DOI DOI 10.1007/978-3-030-23760-8
   Arya V, 2004, SIAM J COMPUT, V33, P544, DOI 10.1137/S0097539702416402
   Bagger NCF, 2019, EUR J OPER RES, V272, P430, DOI 10.1016/j.ejor.2018.06.042
   BARTELS RH, 1969, COMMUN ACM, V12, P266, DOI 10.1145/362946.362974
   Belhaiza S, 2019, ALGORITHMS, V12, DOI 10.3390/a12020039
   Cordeau JF, 2007, ANN OPER RES, V153, P29, DOI 10.1007/s10479-007-0170-8
   Cordeau JF, 2006, OPER RES, V54, P573, DOI 10.1287/opre.1060.0283
   Cordeau JF, 2003, TRANSPORT RES B-METH, V37, P579, DOI 10.1016/S0191-2615(02)00045-0
   Garaix T, 2011, COMPUT OPER RES, V38, P1435, DOI 10.1016/j.cor.2010.12.014
   HEALY P, 1995, EUR J OPER RES, V83, P83, DOI 10.1016/0377-2217(93)E0292-6
   Ho SC, 2018, TRANSPORT RES B-METH, V111, P395, DOI 10.1016/j.trb.2018.02.001
   Ho SC, 2011, OR SPECTRUM, V33, P961, DOI 10.1007/s00291-009-0175-6
   LAWLER EL, 1966, OPER RES, V14, P699, DOI 10.1287/opre.14.4.699
   Parragh SN, 2010, COMPUT OPER RES, V37, P1129, DOI 10.1016/j.cor.2009.10.003
   PSARAFTIS HN, 1980, TRANSPORT SCI, V14, P130, DOI 10.1287/trsc.14.2.130
   Tang K, 2017, IEEE T CYBERNETICS, V47, P3928, DOI 10.1109/TCYB.2016.2590558
   Van Breedam A, 2001, COMPUT OPER RES, V28, P289, DOI 10.1016/S0305-0548(99)00101-X
   Watel D, 2018, THEOR COMPUT SCI, V745, P202, DOI 10.1016/j.tcs.2018.06.006
   Xiang ZH, 2006, EUR J OPER RES, V174, P1117, DOI 10.1016/j.ejor.2004.09.060
NR 19
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30775
EP 30787
DI 10.1007/s11042-020-08894-7
EA APR 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000529074000005
DA 2024-07-18
ER

PT J
AU Sun, M
   Wei, H
AF Sun, Min
   Wei, Hui
TI An improved cuckoo search algorithm for multi-level gray-scale image
   thresholding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cuckoo search algorithm; Multi-level thresholding; Adaptive; Gray-scale
   image
ID TSALLIS ENTROPY; SEGMENTATION; KAPURS
AB In decades, Yang's cuckoo search algorithm has been widely developed to select the optimal threshold of bi-level image threshoding, but the amount of computation of which increases exponentially with multi-level thresholding. To reduce the computation quantity, the iterative step size is adaptively decided by its fitness values of the current iteration without using the Levy distribution in this study. The modification may cause the solution drops into the local optima during the later period. Therefore, the constant discovery probability p(a) is automatically changed relating to the current and total iterations. And then, to verify segmentation accuracy and efficiency of the proposed method, an adaptive cuckoo search algorithm proposed by Naik and Yang's cuckoo search algorithm are included to test on several gray-scale images. The results show that the proposed algorithm is expert in selecting optimal thresholds for segmenting gray-scale image.
C1 [Sun, Min; Wei, Hui] Anhui Univ Sci & Technol, Sch Math & Big Data, Huainan 232001, Anhui, Peoples R China.
C3 Anhui University of Science & Technology
RP Wei, H (corresponding author), Anhui Univ Sci & Technol, Sch Math & Big Data, Huainan 232001, Anhui, Peoples R China.
EM 2196892863@qq.com
FU National Natural Science Foundation of China [11601007, 11701007]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No.11601007 and No.11701007.
CR Abhinaya B., 2015, Information Systems Design and Intelligent Applications, P177, DOI [10.1007/978-81-322-2250-7_18, DOI 10.1007/978-81-322-2250-7_18]
   Agrawal S, 2013, SWARM EVOL COMPUT, V11, P16, DOI 10.1016/j.swevo.2013.02.001
   Alihodzic A, 2014, SCI WORLD J, DOI 10.1155/2014/176718
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P1573, DOI 10.1016/j.eswa.2014.09.049
   Bhandari AK, 2014, EXPERT SYST APPL, V41, P3538, DOI 10.1016/j.eswa.2013.10.059
   Cherukuri A, 2018, AM J TRANSPLANT, V18, P437
   de Albuquerque MP, 2004, PATTERN RECOGN LETT, V25, P1059, DOI 10.1016/j.patrec.2004.03.003
   Feng YC, 2017, MULTIMED TOOLS APPL, V76, P23139, DOI 10.1007/s11042-016-4098-3
   Ghamisi P, 2012, EXPERT SYST APPL, V39, P12407, DOI 10.1016/j.eswa.2012.04.078
   Hammouche K, 2008, COMPUT VIS IMAGE UND, V109, P163, DOI 10.1016/j.cviu.2007.09.001
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Li XT, 2015, INFORM SCIENCES, V298, P80, DOI 10.1016/j.ins.2014.11.042
   MANTEGNA RN, 1994, PHYS REV E, V49, P4677, DOI 10.1103/PhysRevE.49.4677
   Naik M, 2015, 2015 IEEE 2ND INTERNATIONAL CONFERENCE ON RECENT TRENDS IN INFORMATION SYSTEMS (RETIS), P1, DOI 10.1109/ReTIS.2015.7232842
   Naik MK, 2016, APPL SOFT COMPUT, V38, P661, DOI 10.1016/j.asoc.2015.10.039
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Panda R, 2013, EXPERT SYST APPL, V40, P7617, DOI 10.1016/j.eswa.2013.07.060
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Suresh S, 2016, EXPERT SYST APPL, V58, P184, DOI 10.1016/j.eswa.2016.03.032
   Tiwari V., 2012, Indian Journal of Computer Science and Engineering, V3, P401
   TSALLIS C, 1988, J STAT PHYS, V52, P479, DOI 10.1007/BF01016429
   Valian E., 2011, Int J Artif Intell Appl, V2, P36, DOI DOI 10.5121/IJAIA.2011.2304
   Wang LJ, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/715635
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei HT, 2017, 2017 IEEE 2ND ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P2292, DOI 10.1109/IAEAC.2017.8054429
   Wen Wang, 2018, Journal of Physics: Conference Series, V1087, DOI 10.1088/1742-6596/1087/2/022003
   Xin-She Yang, 2010, International Journal of Mathematical Modelling and Numerical Optimisation, V1, P330, DOI 10.1504/IJMMNO.2010.035430
   Yang X., 2009, Cuckoo Search Via L'evy Flights
   Yang XS, 2013, COMPUT OPER RES, V40, P1616, DOI 10.1016/j.cor.2011.09.026
   Zhang YD, 2011, ENTROPY-SWITZ, V13, P841, DOI 10.3390/e13040841
   Zhou YQ, 2018, MULTIMED TOOLS APPL, V77, P23699, DOI 10.1007/s11042-018-5637-x
NR 33
TC 5
Z9 6
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 34993
EP 35016
DI 10.1007/s11042-020-08931-5
EA APR 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000528990000005
DA 2024-07-18
ER

PT J
AU Luo, S
   Feng, JQ
AF Luo, Shan
   Feng, Jieqing
TI Symmetry-aware kinematic skeleton generation of a 3D human body model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kinematic skeleton; Symmetric ambiguity; Skeleton embedding
ID SHAPE; ANIMATION
AB In this paper, an automatic method is proposed to generate a symmetry-aware kinematic skeleton for a human body model with an arbitrary pose and orientation. First, a template kinematic skeleton with semantics is embedded into the input human body model. Then, the joints of the embedded kinematic skeleton are refined according to the geometry of the human body model and some prior knowledge. Finally, a specific local coordinate system is defined on the kinematic skeleton and is used to distinguish the symmetry of the kinematic skeleton. In this way, the symmetric joints of the kinematic skeleton, e.g., the left knee joint and the right knee joint, can be distinguished. Quantitative and qualitative analysis and comparison show that the proposed method can generate a symmetry-aware kinematic skeleton with accurate joints and has no restrictions on the pose and orientation of the input human body model. Moreover, this paper presents validation of the proposed method in many applications, such as shape alignment, shape deformation, shape co-segmentation and shape correspondence.
C1 [Luo, Shan; Feng, Jieqing] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Peoples R China.
C3 Zhejiang University
RP Feng, JQ (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Peoples R China.
EM jqfeng@cad.zju.edu.cn
OI Luo, Shan/0009-0004-9378-7291
FU National Natural Science Foundation of China [61732015, 61472349]; Key
   Research and Development Program of Zhejiang Province [2018C01090]
FX This work was supported by the National Natural Science Foundation of
   China under Grants No. 61732015 and No. 61472349, and Key Research and
   Development Program of Zhejiang Province under Grants No. 2018C01090.
CR Aigerman N, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766921
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   Au OKC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360643
   Aujay G, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P151
   Avril Q, 2016, COMPUT GRAPH FORUM, V35, P115, DOI 10.1111/cgf.12816
   Baran I., 2007, TOG, V26, P72
   Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491
   Chen XB, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531379
   Cornea ND, 2007, IEEE T VIS COMPUT GR, V13, P530, DOI 10.1109/TVCG.2007.1002
   de Aguiar E, 2008, COMPUT GRAPH FORUM, V27, P389, DOI 10.1111/j.1467-8659.2008.01136.x
   Fechteler P., 2016, EG 16 P 37 ANN C EUR, P5
   Feng Andrew, 2015, P 8 ACM SIGGRAPH C M, P57
   Hajari N, 2016, IEEE INT SYM MULTIM, P271, DOI [10.1109/ISM.2016.119, 10.1109/ISM.2016.0060]
   Kleiman Y, 2019, COMPUT GRAPH FORUM, V38, P7, DOI 10.1111/cgf.13389
   Le BH, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601161
   Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482
   Lien J, 2006, P 2006 ACM S SOL PHY, P219
   Liu PC, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P409
   Liu TQ, 2012, COMPUT GRAPH FORUM, V31, P1607, DOI 10.1111/j.1467-8659.2012.03166.x
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Ma J, 2014, COMPUT AIDED DESIGN, V46, P221, DOI 10.1016/j.cad.2013.08.036
   Marin R, 2020, COMPUT GRAPH FORUM, V39, P160, DOI 10.1111/cgf.13751
   Ovsjanikov M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185526
   Ovsjanikov M, 2013, COMPUT GRAPH FORUM, V32, P1, DOI 10.1111/cgf.12167
   Pantuwong N, 2012, COMPUT ANIMAT VIRT W, V23, P125, DOI 10.1002/cav.1429
   Poirier M, 2009, Graphics interface, P103
   Ren J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275040
   Saha PK, 2016, PATTERN RECOGN LETT, V76, P1, DOI 10.1016/j.patrec.2016.01.005
   Sahillioglu Y, 2013, COMPUT GRAPH FORUM, V32, P177, DOI 10.1111/cgf.12007
   Sellamani S., 2010, COMPUT AIDED DESIGN, V7, P601
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Wang K, 2016, MULTIMED TOOLS APPL, V75, P11741, DOI 10.1007/s11042-015-2629-y
   Wang M, 2016, ACM INT C MULT, P526
   Xu Z, 2019, INT CONF 3D VISION, P298, DOI 10.1109/3DV.2019.00041
   Yang Y, 2019, IEEE T VIS COMPUT GR, V25, P2999, DOI 10.1109/TVCG.2018.2861396
   Yoshiyasu Y, 2016, COMPUT GRAPH-UK, V60, P9, DOI 10.1016/j.cag.2016.07.002
   Yoshiyasu Y, 2014, PROC CVPR IEEE, P4193, DOI 10.1109/CVPR.2014.534
   Zhang ZY, 2013, COMPUT GRAPH FORUM, V32, P355, DOI 10.1111/cgf.12243
NR 38
TC 1
Z9 2
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 20579
EP 20602
DI 10.1007/s11042-020-08933-3
EA APR 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000528819200002
DA 2024-07-18
ER

PT J
AU Kalboussi, R
   Azaza, A
   van de Weijer, J
   Abdellaoui, M
   Douik, A
AF Kalboussi, Rahma
   Azaza, Aymen
   van de Weijer, Joost
   Abdellaoui, Mehrez
   Douik, Ali
TI Object proposals for salient object segmentation in videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video saliency; Object proposals; Motion estimation; Object detection
AB Salient object segmentation in videos is generally broken up in a video segmentation part and a saliency assignment part. Recently, object proposals, which are used to segment the image, have had significant impact on many computer vision applications, including image segmentation, object detection, and recently saliency detection in still images. However, their usage has not yet been evaluated for salient object segmentation in videos. Therefore, in this paper, we investigate the application of object proposals to salient object segmentation in videos. In addition, we propose a new motion feature derived from the optical flow structure tensor for video saliency detection. Experiments on two standard benchmark datasets for video saliency show that the proposed motion feature improves saliency estimation results, and that object proposals are an efficient method for salient object segmentation. Results on the challenging SegTrack v2 and Fukuchi benchmark data sets show that we significantly outperform the state-of-the-art.
C1 [Kalboussi, Rahma] Univ Sousse, Natl Engn Sch Sousse, ISITCOM Hammam Sousse, Sahloul 4054, Tunisia.
   [Azaza, Aymen] Univ Monastir, Natl Engn Sch Monastir, Ibn Eljazzar St, Monastir 5000, Tunisia.
   [van de Weijer, Joost] Comp Vis Ctr, Edificio O Campus UAB, Barcelona 08193, Spain.
   [Abdellaoui, Mehrez; Douik, Ali] Univ Sousse, Natl Engn Sch Sousse, Pole Technol Sousse, Route Ceinture Sahloul, Sousse 4054, Tunisia.
C3 Universite de Sousse; Universite de Monastir; Centre de Visio per
   Computador (CVC); Universite de Sousse
RP Kalboussi, R (corresponding author), Univ Sousse, Natl Engn Sch Sousse, ISITCOM Hammam Sousse, Sahloul 4054, Tunisia.
EM rahma.kalboussi@gmail.com; aazaza@cvc.uab.es; joost@cvc.uab.es;
   mehrez.abdellaoui@enim.rnu.tn; ali.douik@enim.rnu.tn
RI Abdellaoui, Mehrez/AAR-5016-2020; van de Weijer, Joost/A-1643-2009
OI van de Weijer, Joost/0000-0002-9656-9706; DOUIK,
   Ali/0000-0002-0178-501X; Kalboussi, Rahma/0000-0003-3256-2334
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], ARXIV PREPRINT ARXIV
   [Anonymous], INT J COMPUTER VISIO
   [Anonymous], ADV NEURAL INFORM PR
   Azaza A, 2018, COMPUT VIS IMAGE UND, V174, P1, DOI 10.1016/j.cviu.2018.06.002
   BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668
   Bing Han, 2012, 2012 International Conference on Computing, Networking and Communications (ICNC), P371, DOI 10.1109/ICCNC.2012.6167446
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21
   Carreira J, 2010, PROC CVPR IEEE, P3241, DOI 10.1109/CVPR.2010.5540063
   Fragkiadaki K, 2012, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2012.6247883
   Frintrop S, 2015, PROC CVPR IEEE, P82, DOI 10.1109/CVPR.2015.7298603
   Fukuchi K, 2009, IEEE INT CON MULTI, P638, DOI 10.1109/ICME.2009.5202577
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Itti L, 2005, PROC CVPR IEEE, P631
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang H, 2011, DES AUT CON, P836
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kim H, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2425544
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Krähenbühl P, 2014, LECT NOTES COMPUT SC, V8693, P725, DOI 10.1007/978-3-319-10602-1_47
   Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471
   Lezama J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3369, DOI 10.1109/CVPR.2011.6044588
   Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Lin X, 2017, EUR SIGNAL PR CONF, P66, DOI 10.23919/EUSIPCO.2017.8081170
   Liu Z, 2014, IEEE T CIRC SYST VID, V24, P1522, DOI 10.1109/TCSVT.2014.2308642
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Ma TY, 2012, PROC CVPR IEEE, P670, DOI 10.1109/CVPR.2012.6247735
   Mancas M, 2011, IEEE IMAGE PROC, P229, DOI 10.1109/ICIP.2011.6116099
   Mauthner T, 2015, PROC CVPR IEEE, P2494, DOI 10.1109/CVPR.2015.7298864
   Nah S, 2015, ASIAPAC SIGN INFO PR, P604, DOI 10.1109/APSIPA.2015.7415340
   Oneata D, 2014, LECT NOTES COMPUT SC, V8691, P737, DOI 10.1007/978-3-319-10578-9_48
   Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223
   Rahman A, 2011, J REAL-TIME IMAGE PR, V6, P3, DOI 10.1007/s11554-010-0164-7
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Simoncelli E. P., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P310, DOI 10.1109/CVPR.1991.139707
   Singh Anurag, 2015, 4th International Conference on Pattern Recognition Applications and Methods (ICPRAM 2015). Proceedings, P201
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Van de Weijer J, 2006, IEEE T IMAGE PROCESS, V15, P118, DOI 10.1109/TIP.2005.860343
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang P, 2012, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2012.6248054
   Wang X, 2016, PATTERN RECOGN LETT, V75, P1, DOI 10.1016/j.patrec.2016.02.008
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhang D, 2013, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2013.87
   Zhong S.-h., 2013, AAAI Conference on Artificial Intelligence, P1063
NR 51
TC 3
Z9 3
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8677
EP 8693
DI 10.1007/s11042-019-07781-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600017
DA 2024-07-18
ER

PT J
AU Khan, I
   Islam, N
   Rehman, HU
   Khan, M
AF Khan, Irshad
   Islam, Naveed
   Rehman, Hafeez Ur
   Khan, Murad
TI A comparative study of graphic symbol recognition methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Symbol recognition; Object recognition and classification
ID IMAGE-ANALYSIS; MATHEMATICAL EXPRESSIONS; SUBGRAPH ISOMORPHISM; FOURIER
   DESCRIPTORS; PATTERN-RECOGNITION; LOGO RECOGNITION; HOUGH TRANSFORM;
   RETRIEVAL; SYSTEM; INVARIANTS
AB From the very beginning of written scripts, contents of documents generally comprise of text, images, figures, graphs and graphic symbols. A graphic recognition system involves representation of graphic symbols, description of features extracted from the symbol and classification of the unknown symbols. Due to the wide range of symbols, no generalize technique is available that can recognize the symbol for all the application domains. this paper, we present an overview of the many models and methodologies available to symbol recognition for representation, description and classification. We provide a general survey of symbol recognition process, beginning with the basic definition of symbol, which is further classified into their types based on application areas. distinctive part of the survey is categorization of different symbol recognition methods into four categories i.e. statistical, structural, syntactical and hybrid methods, which is aimed to help potential researchers in exploring areas of research in the field of graphic symbol recognition.
C1 [Khan, Irshad; Khan, Murad] Sarhad Univ Sci & Informat Technol, Peshawar, Pakistan.
   [Islam, Naveed] Islamia Coll Univ, Peshawar, Pakistan.
   [Rehman, Hafeez Ur] FAST Natl Univ Comp & Emerging Sci, Peshawar, Pakistan.
C3 University of Peshawar
RP Khan, I (corresponding author), Sarhad Univ Sci & Informat Technol, Peshawar, Pakistan.
EM irshad.csit@suit.edu.pk; naveed.islam@icp.edu.pk;
   hafeez.urrehman@nu.edu.pk; murad.csit@suit.edu.pk
RI Khan, Irshad/AAN-8522-2020; Khan, Murad/AAB-6060-2019; Rehman, Hafeez
   Ur/AAW-4327-2021
OI Khan, Irshad/0000-0001-6960-2083; Khan, Murad/0000-0001-9905-8904;
   Rehman, Hafeez Ur/0000-0002-3274-6347; Islam, Naveed/0000-0003-0648-8804
CR Ablameyko S., 1998, Advances in Pattern Recognition. Joint IAPR International Workshops SSPR'98 and SPR'98. Proceedings, P460, DOI 10.1007/BFb0033267
   Ablameyko Sergey., 1997, An introduction to interpretation of graphic images, V27
   Adam S., 2000, Graphics Recognition. Recent Advances. Third International Workshop, GREC'99. Selected Papers (Lecture Notes in Computer Science Vol.1941), P238
   Ah-Soon C, 2001, PATTERN RECOGN LETT, V22, P231, DOI 10.1016/S0167-8655(00)00091-X
   Almazán J, 2012, PATTERN RECOGN, V45, P3105, DOI 10.1016/j.patcog.2012.01.010
   [Anonymous], SYNTACTIC PATTERN RE
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], COMBINING GRAPH MATC
   [Anonymous], 2016, INT J COMPUT APPL
   [Anonymous], STRUCTURAL PATTERN R
   [Anonymous], INT J DOCUMENT ANAL
   [Anonymous], ICPR
   [Anonymous], STABLE ROBUST OFF TH
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], R ANDOMIZED H OUGH T
   [Anonymous], GRAPHICS RECOGNITION
   [Anonymous], SYNTACTIC STRUCTURAL
   [Anonymous], 1973, PATTERN CLASSIFICATI
   [Anonymous], 2018, ARXIV180103530
   [Anonymous], OXFORD ADV LEARNER D
   [Anonymous], STRUCTURED DOCUMENT
   [Anonymous], INT SYMB REC CONT GR
   [Anonymous], MAPPING SPATIAL MODE
   [Anonymous], ARXIV10045427
   [Anonymous], 70012007 ISO
   [Anonymous], STRUCTURAL RECOGNITI
   Anquetil E., 2000, Graphics Recognition. Recent Advances. Third International Workshop, GREC'99. Selected Papers (Lecture Notes in Computer Science Vol.1941), P209
   Antoine D., 1992, Structured Document Image Analysis, P385
   Aoki Y., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P747, DOI 10.1109/ICPR.1996.547268
   ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206
   Arias J. F., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P365, DOI 10.1109/ICDAR.1993.395714
   Armand J.-P., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P906, DOI 10.1109/ICDAR.1993.395590
   Attalla E, 2005, PATTERN RECOGN, V38, P2229, DOI 10.1016/j.patcog.2005.02.009
   Bailey RR, 1996, IEEE T PATTERN ANAL, V18, P389, DOI 10.1109/34.491620
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   BELKASIM SO, 1991, PATTERN RECOGN, V24, P1117, DOI 10.1016/0031-3203(91)90140-Z
   Blostein D., 1992, STRUCTURED DOCUMENT, P405
   Blostein D., 1995, P INT WORKSH GRAPH R, P106
   BOATTO L, 1992, COMPUTER, V25, P25, DOI 10.1109/2.144437
   Boumaiza A., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P165, DOI 10.1109/DAS.2012.83
   Boumaiza A, 2012, INT C PATT RECOG, P278
   Bunke H., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P710
   Bunke H., 1995, Image Analysis and Processing. 8th International Conference, ICIAP '95. Proceedings, P45
   Bunke H, 1997, INT J PATTERN RECOGN, V11, P169, DOI 10.1142/S0218001497000081
   BUNKE H, 1982, IEEE T PATTERN ANAL, V4, P574, DOI 10.1109/TPAMI.1982.4767310
   Bunke H., 1990, SYNTACTIC STRUCTURAL, V7
   Bunke H, 2011, PATTERN RECOGN, V44, P1057, DOI 10.1016/j.patcog.2010.11.015
   Cardot H., 2007, 2007 INT C SIGN PROC, P477
   Celik M, 2011, PROC INT CONF DOC, P161, DOI 10.1109/ICDAR.2011.41
   Cesarini F, 1997, PROC INT CONF DOC, P175, DOI 10.1109/ICDAR.1997.619836
   Chang MT, 2001, PATTERN RECOGN, V34, P953, DOI 10.1016/S0031-3203(00)00053-4
   Chaudhuri BB, 2000, PATTERN ANAL APPL, V3, P120, DOI 10.1007/s100440070017
   Chhabra AK, 1998, LECT NOTES COMPUT SC, V1389, P68
   Chiang YY, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2557423
   Chong CW, 2003, PATTERN RECOGN, V36, P731, DOI 10.1016/S0031-3203(02)00091-2
   Collin S., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P1131, DOI 10.1142/S0218001494000565
   Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228
   Cordella L. P., 2000, International Journal on Document Analysis and Recognition, V3, P73, DOI 10.1007/s100320000036
   Coustaty M, 2011, IEEE T SYST MAN CY B, V41, P1136, DOI 10.1109/TSMCB.2011.2108646
   de las Heras LP, 2014, INT J DOC ANAL RECOG, V17, P221, DOI 10.1007/s10032-013-0215-2
   Deans SR, 2007, The Radon transform and some of its applications
   den Hartog J., 1996, Graphics Recognition, Methods and Applications. First International Workshop. Selected Papers, P159
   Doermann D, 1996, MACH VISION APPL, V9, P73
   Dori D, 1997, ADV ENG SOFTW, V28, P11, DOI 10.1016/S0965-9978(96)00035-X
   Dosch P, 2004, LECT NOTES COMPUT SC, V3088, P154
   Dosch P., 2000, International Journal on Document Analysis and Recognition, V3, P102, DOI 10.1007/PL00010901
   El-Ghazal A, 2007, IEEE IMAGE PROC, P161
   Escalera S, 2011, IEEE T SYST MAN CY B, V41, P497, DOI 10.1109/TSMCB.2010.2060481
   Escalera S, 2009, PATTERN RECOGN LETT, V30, P1424, DOI 10.1016/j.patrec.2009.08.001
   Fahmy H., 1993, Machine Vision and Applications, V6, P83, DOI 10.1007/BF01211933
   FAHMY H, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P294, DOI 10.1109/ICPR.1992.201776
   Feng GH, 2009, PATTERN RECOGN, V42, P3215, DOI 10.1016/j.patcog.2009.01.031
   Foggia P, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414500013
   Foulds L. R., 2012, Graph Theory Applications
   Francesconi E, 1998, LECT NOTES COMPUT SC, V1389, P104
   Gelernter J, 2009, J AM SOC INF SCI TEC, V60, P1965, DOI 10.1002/asi.21107
   GROEN FCA, 1985, PATTERN RECOGN LETT, V3, P343, DOI 10.1016/0167-8655(85)90066-2
   Guangyu Zhu, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P606, DOI 10.1109/ICDAR.2009.60
   Hilaire X, 2006, IEEE T PATTERN ANAL, V28, P890, DOI 10.1109/TPAMI.2006.127
   Hoshino T., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P449
   Hui-Lung Lee, 2016, 2016 International Conference on Machine Learning and Cybernetics (ICMLC). Proceedings, P552, DOI 10.1109/ICMLC.2016.7872947
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Janssen RDT, 1997, COMPUT VIS IMAGE UND, V65, P38, DOI 10.1006/cviu.1996.0484
   Jouili S, 2011, LECT NOTES COMPUT SC, V6658, P72, DOI 10.1007/978-3-642-20844-7_8
   Kadyrov A, 2001, IEEE T PATTERN ANAL, V23, P811, DOI 10.1109/34.946986
   Kamila NK, 2005, PATTERN RECOGN LETT, V26, P747, DOI 10.1016/j.patrec.2004.09.026
   Kanungo T., 1995, Proceedings of the 4th Annual Symposium on Document Analysis and Information Retrieval, P217
   Kassim AA, 1999, IMAGE VISION COMPUT, V17, P737, DOI 10.1016/S0262-8856(98)00156-5
   KASTURI R, 1990, IEEE T PATTERN ANAL, V12, P978, DOI 10.1109/34.58870
   KAUPPINEN H, 1995, IEEE T PATTERN ANAL, V17, P201, DOI 10.1109/34.368168
   Kherfi ML, 2004, ACM COMPUT SURV, V36, P35, DOI 10.1145/1013208.1013210
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kim S. H., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P349, DOI 10.1109/ICDAR.1993.395717
   Kiyko V. M., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P970, DOI 10.1109/ICDAR.1995.602063
   Kuner P., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P527, DOI 10.1142/S0218001488000303
   LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346
   Lavirotte S, 1997, PROC INT CONF DOC, P357, DOI 10.1109/ICDAR.1997.619871
   LEE HJ, 1994, PATTERN RECOGN, V27, P447, DOI 10.1016/0031-3203(94)90121-X
   Lee Seong-Whan., 1992, STRUCTURED DOCUMENT, P340
   Lee W, 2007, COMPUT GRAPH-UK, V31, P554, DOI 10.1016/j.cag.2007.04.007
   Liao SX, 1998, IEEE T PATTERN ANAL, V20, P1358, DOI 10.1109/34.735809
   LIN CS, 1987, PATTERN RECOGN, V20, P535, DOI 10.1016/0031-3203(87)90080-X
   Lin XY, 2014, INT J DOC ANAL RECOG, V17, P239, DOI 10.1007/s10032-013-0216-1
   Liu WY, 2007, INT J DOC ANAL RECOG, V9, P13, DOI 10.1007/s10032-006-0025-x
   Liu WY, 2001, PROC INT CONF DOC, P1050, DOI 10.1109/ICDAR.2001.953946
   Liu XX, 2012, LECT NOTES ARTIF INT, V7197, P263, DOI 10.1007/978-3-642-28490-8_28
   Liu Y, 2004, INT C PATT RECOG, P371, DOI 10.1109/ICPR.2004.1334129
   Lladós J, 2004, INT J PATTERN RECOGN, V18, P455, DOI 10.1142/S0218001404003204
   Llados J., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P479, DOI 10.1109/ICDAR.1999.791829
   Lladós J, 2002, LECT NOTES COMPUT SC, V2390, P104
   Lladós J, 1998, LECT NOTES COMPUT SC, V1389, P91
   Llados J, 1997, MACH VISION APPL, V10, P150, DOI 10.1007/s001380050068
   Luqman Muhammad Muzzamil, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1325, DOI 10.1109/ICDAR.2009.92
   Luqman M.M., 2011, 9 IAPR INT WORKSHOP, V9, P117
   Luqman MM, 2013, PATTERN RECOGN, V46, P551, DOI 10.1016/j.patcog.2012.07.029
   Luqman MM, 2010, LECT NOTES COMPUT SC, V6388, P93, DOI 10.1007/978-3-642-17711-8_10
   Luqman MM, 2010, LECT NOTES COMPUT SC, V6020, P12
   Lutz S, 2014, ERKENNTNIS, V79, P1475, DOI 10.1007/s10670-013-9578-5
   MADEJ D, 1991, P 1 INT C DOC AN REC, P602
   MAES M, 1991, PATTERN RECOGN, V24, P433, DOI 10.1016/0031-3203(91)90056-B
   MEHLHORN K, 1984, DATA STRUCTURES ALGO, V2
   Messmer BT, 2000, IEEE T KNOWL DATA EN, V12, P307, DOI 10.1109/69.842269
   Miao QG, 2017, IEEE T IMAGE PROCESS, V26, P2751, DOI 10.1109/TIP.2016.2613409
   MIN WD, 1993, PATTERN RECOGN, V26, P1407, DOI 10.1016/0031-3203(93)90146-N
   Miyao H, 1996, IEICE T INF SYST, VE79D, P548
   Mouchère H, 2016, INT J DOC ANAL RECOG, V19, P173, DOI 10.1007/s10032-016-0263-5
   Myers G. K., 1996, Graphics Recognition, Methods and Applications. First International Workshop. Selected Papers, P190
   NAGY G, 1968, PR INST ELECTR ELECT, V56, P836, DOI 10.1109/PROC.1968.6414
   OKAZAKI A, 1988, IEEE T PATTERN ANAL, V10, P331, DOI 10.1109/34.3898
   Paek S, 1998, P SOC PHOTO-OPT INS, V3305, P151, DOI 10.1117/12.304628
   PAL SK, 1991, PATTERN RECOGN LETT, V12, P585, DOI 10.1016/0167-8655(91)90011-A
   Park BG, 2003, COMPUT VIS IMAGE UND, V90, P217, DOI 10.1016/S1077-3142(03)00049-3
   PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681
   Pinjarkar L, 2018, SMART INNOV SYST TEC, V77, P53, DOI 10.1007/978-981-10-5544-7_6
   PROKOP RJ, 1992, CVGIP-GRAPH MODEL IM, V54, P438, DOI 10.1016/1049-9652(92)90027-U
   Rabbani M, 2016, PROCEDIA COMPUT SCI, V84, P41, DOI 10.1016/j.procs.2016.04.064
   Ramel J. Y., 2000, International Journal on Document Analysis and Recognition, V3, P58, DOI 10.1007/s100320000037
   Ramel J.-Y., 2000, Graphics Recognition. Recent Advances. Third International Workshop, GREC'99. Selected Papers (Lecture Notes in Computer Science Vol.1941), P228
   Randriamahefa R., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P898, DOI 10.1109/ICDAR.1993.395592
   Rebelo A, 2010, INT J DOC ANAL RECOG, V13, P19, DOI 10.1007/s10032-009-0100-1
   Reiher E., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P783, DOI 10.1109/ICPR.1996.547275
   Robles-Kelly A, 2004, INT J PATTERN RECOGN, V18, P315, DOI 10.1142/S0218001404003277
   ROSENFELD A, 1986, COMPUT VISION GRAPH, V33, P156, DOI 10.1016/0734-189X(86)90113-1
   ROSENFELD A, 1984, PATTERN RECOGN, V17, P3, DOI 10.1016/0031-3203(84)90031-1
   Rosenfeld A., 2014, Digital picture processing, V1
   Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P659, DOI 10.1109/34.601253
   Rui Y, 1998, SER SOFTW ENGN KNOWL, V8, P165
   Rusinol Marcal, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P111, DOI 10.1109/ICDAR.2009.103
   Rusiñol M, 2006, LECT NOTES COMPUT SC, V3926, P35
   Rusiñol M, 2008, PROCEEDINGS OF THE 8TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, P489, DOI 10.1109/DAS.2008.24
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Samet H, 1996, IEEE T PATTERN ANAL, V18, P783, DOI 10.1109/34.531799
   Sánchez G, 2001, PROC INT CONF DOC, P465, DOI 10.1109/ICDAR.2001.953833
   Santosh KC, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414500177
   Santosh KC, 2014, INT J DOC ANAL RECOG, V17, P61, DOI 10.1007/s10032-013-0205-4
   Santosh K. C., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1330, DOI 10.1109/ICDAR.2009.166
   Seo W, 2015, INT J DOC ANAL RECOG, V18, P47, DOI 10.1007/s10032-014-0226-7
   Seong-Whan Lee, 1990, International Journal of Pattern Recognition and Artificial Intelligence, V4, P1, DOI 10.1142/S0218001490000022
   Soffer A, 1998, INT C PATT RECOG, P571, DOI 10.1109/ICPR.1998.711207
   Stuckelberg M. V., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P115, DOI 10.1109/ICDAR.1999.791738
   Tabbone S, 2006, COMPUT VIS IMAGE UND, V102, P42, DOI 10.1016/j.cviu.2005.06.005
   Tabbone S., 2003, International Journal on Document Analysis and Recognition, V6, P115, DOI 10.1007/s10032-003-0105-0
   Tabbone S, 2003, LECT NOTES COMPUT SC, V2886, P184
   Tan QZ, 2009, LECT NOTES COMPUT SC, V5478, P162
   Tang YY, 1996, PATTERN RECOGN, V29, P1931, DOI 10.1016/S0031-3203(96)00044-1
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Tian Fei, 2010, Proceedings of the 2010 International Conference on Electrical and Control Engineering (ICECE 2010), P5357, DOI 10.1109/iCECE.2010.1300
   Tombre K, 1998, LECT NOTES COMPUT SC, V1389, P257
   Valveny E, 2000, INT C PATT RECOG, P239, DOI 10.1109/ICPR.2000.906057
   WALL K, 1984, COMPUT VISION GRAPH, V28, P220, DOI 10.1016/S0734-189X(84)80023-7
   Xiaoyi Jiang, 2000, Graphics Recognition. Recent Advances. Third International Workshop, GREC'99. Selected Papers (Lecture Notes in Computer Science Vol.1941), P183
   Xu Xiaogang, 2004, International Journal on Document Analysis and Recognition, V7, P44, DOI 10.1007/s10032-004-0126-3
   YadidPecht O, 1996, MACH VISION APPL, V9, P65
   YANG DS, 1993, FIFTH INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE, TAI '93, PROCEEDINGS, P272, DOI 10.1109/TAI.1993.633967
   Yang S, 2005, IEEE T PATTERN ANAL, V27, P278, DOI 10.1109/TPAMI.2005.38
   Yu YJ, 2007, PROC INT CONF DOC, P516
   ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949
   Zhang DS, 2005, IMAGE VISION COMPUT, V23, P33, DOI 10.1016/j.imavis.2004.09.001
   Zhang DS, 2002, SIGNAL PROCESS-IMAGE, V17, P825, DOI 10.1016/S0923-5965(02)00084-X
   Zhang W, 2006, IEEE T PATTERN ANAL, V28, P2020, DOI 10.1109/TPAMI.2006.254
NR 181
TC 6
Z9 6
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8695
EP 8725
DI 10.1007/s11042-018-6289-6
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600018
DA 2024-07-18
ER

PT J
AU Kim, PW
AF Kim, Pyoung Won
TI Thermal infrared image processing profiles for speech anxiety monitoring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Thermal infrared image; Real-time; Image processing; Speech anxiety;
   Education
AB This study relates to a method for analyzing speech anxiety by processing biosignals in real time. In the previous study, the effect of galvanic skin response feedback on performance in speech anxiety was determined. The present study is a method to process the speech anxiety state in real time, and this is done by processing the facial thermal image of the presenter in real time. The root mean square waveform that tracks facial temperature changes in real time can be used as a useful indicator for diagnosing speech anxiety. The visualization of the speech anxiety profile feedback with a facial thermal image can be a better cognitive therapeutic strategy in speech anxiety education.
C1 [Kim, Pyoung Won] Incheon Natl Univ, Coll Educ, Dept Korean Language Educ, 12 Gaetbeol Ro, Incheon, South Korea.
C3 Incheon National University
RP Kim, PW (corresponding author), Incheon Natl Univ, Coll Educ, Dept Korean Language Educ, 12 Gaetbeol Ro, Incheon, South Korea.
EM pwkim@inu.ac.kr
OI Kim, Pyoung Won/0000-0002-3621-9480
CR [Anonymous], 2001, ANXIETY ITS DISORDER
   Berntson GG, 1997, PSYCHOPHYSIOLOGY, V34, P623, DOI 10.1111/j.1469-8986.1997.tb02140.x
   Figner B., 2011, A Handbook of Process Tracing Methods for Decision Research, P163, DOI [10.4324/9780203875292, DOI 10.4324/9780203875292-18/USING-SKIN-CONDUCTANCE-JUDGMENT-DECISION-MAKING-RESEARCH-MICHAEL-SCHULTE-MECKLENBECK-ANTON-KUEHBERGER-JOSEPH-JOHNSON-JOSEPH-JOHNSON]
   Fox S. I., 2008, HUMAN PHYSL
   Hui TKL, 2018, BIOSENSORS-BASEL, V8, DOI 10.3390/bios8020030
   Kim PW, 2012, APPL PSYCHOPHYS BIOF, V37, P261, DOI 10.1007/s10484-012-9199-9
   Lang A, 2005, J BROADCAST ELECTRON, V49, P3, DOI 10.1207/s15506878jobem4901_2
   LANG A, 1995, J BROADCAST ELECTRON, V39, P313, DOI 10.1080/08838159509364309
   Merla A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00802
   Nota G, 2019, J AMB INTEL HUM COMP, V10, P239, DOI 10.1007/s12652-017-0643-9
NR 10
TC 1
Z9 1
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9075
EP 9081
DI 10.1007/s11042-019-7215-2
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600037
DA 2024-07-18
ER

PT J
AU Li, Z
   Li, QL
   Wu, W
   Wu, ZJ
   Lu, L
   Yang, XM
AF Li, Zhen
   Li, Qilei
   Wu, Wei
   Wu, Zongjun
   Lu, Lu
   Yang, Xiaomin
TI Clustering based multiple branches deep networks for single image
   super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image super-resolution; Deep learning; K-means clustering; Multiple CNN
   branches
ID INTERPOLATION
AB Since the limitation of optical sensors, it's often hard to obtain an image with the ideal resolution. Image super-resolution (SR) technology can generate a high-resolution image from the corresponding low-resolution image. Recently, deep learning (DL) based SR methods draw much attention due to their satisfying reconstruction results. However, these methods often neglect the diversity of image patches. Therefore, the reconstruction effect is limited. To fully exploit the texture variability across different image patches, we propose a universal, flexible, and effective framework. The proposed framework can be adopted to any DL based methods. It can significantly improve the SR accuracy while maintaining the running time. In the proposed framework, K-means is employed to cluster image patches into different categories. Multiple CNN branches are designed for these different categories to reconstruct the SR image. Each branch is weighted in accordance with the Euclidean distance to the cluster centers. Experimental results demonstrate that by applying the proposed framework, performance of the DL based SR method can be significantly improved.
C1 [Li, Zhen; Li, Qilei; Wu, Wei; Wu, Zongjun; Lu, Lu; Yang, Xiaomin] Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Sichuan, Peoples R China.
C3 Sichuan University
RP Wu, W (corresponding author), Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Sichuan, Peoples R China.
EM 2016222055165@stu.scu.edu.cn; qilei.li@outlook.com; wuwei@scu.edu.cn;
   zongjunwu@foxmail.com; lulu19900303@126.com; arielyang@scu.edu.cn
RI , 李启磊/K-7546-2019; Li, Zhen/KDN-2236-2024; Lu, Lu/GPX-6708-2022; lu,
   lu/HGA-0894-2022; lu, lu/HII-7530-2022; yang, xiao/HJI-7815-2023; LU,
   LU/JEZ-4760-2023
OI , 李启磊/0000-0002-9675-9016; 
CR Ali M, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (ICSPCC), P184, DOI 10.1109/ICSPCC.2014.6986179
   [Anonymous], 2012, LOW COMPLEXITY SINGL
   [Anonymous], 2014, INF SOFTW TECHNOL
   [Anonymous], 2013, APPL MATH SCI
   [Anonymous], ACM T GRAPH P SIGGRA
   Breiman L., 2001, Mach. Learn., V45, P5
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   DUCHON CE, 1979, J APPL METEOROL, V18, P1016, DOI 10.1175/1520-0450(1979)018<1016:LFIOAT>2.0.CO;2
   Freedman G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944852
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Haris Muhammad, 2018, C COMP VIS PATT REC
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Jeon G, 2016, INFORM SCIENCES, V354, P112, DOI 10.1016/j.ins.2016.03.016
   Jeon G, 2009, IEEE T FUZZY SYST, V17, P1245, DOI 10.1109/TFUZZ.2009.2026638
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li M, 2008, IEEE T IMAGE PROCESS, V17, P1121, DOI 10.1109/TIP.2008.924289
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Lim B., 2017, IEEE C COMP VIS PATT, V1, P4
   Liu D, 2016, IEEE T IMAGE PROCESS, V25, P3194, DOI 10.1109/TIP.2016.2564643
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Paszke A., 2017, NIPS W
   Piccialli F, 2013, PROCEDIA COMPUT SCI, V18, P2643, DOI 10.1016/j.procs.2013.06.001
   Salvador J, 2015, IEEE I CONF COMP VIS, P325, DOI 10.1109/ICCV.2015.45
   Schulter S, 2015, PROC CVPR IEEE, P3791, DOI 10.1109/CVPR.2015.7299003
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Sun J, 2011, IEEE T IMAGE PROCESS, V20, P1529, DOI 10.1109/TIP.2010.2095871
   Terada Katsuyuki, 2013, Collection and Research (Taichung), P1
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang J, 2018, OPT ENG, V57, DOI 10.1117/1.OE.57.5.053102
   Wang Xintao, 2018, ARXIV180402815
   Wang YQ, 2014, IEEE IMAGE PROC, P1852, DOI 10.1109/ICIP.2014.7025371
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JJ, 2016, IEEE T IMAGE PROCESS, V25, P5369, DOI 10.1109/TIP.2016.2604489
   Wu W, 2016, J SYST ARCHITECT, V64, P63, DOI 10.1016/j.sysarc.2015.11.005
   Yang CY, 2011, LECT NOTES COMPUT SC, V6494, P497, DOI 10.1007/978-3-642-19318-7_39
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yang XM, 2017, MULTIMED TOOLS APPL, V76, P24871, DOI 10.1007/s11042-017-4639-4
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
NR 47
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9019
EP 9035
DI 10.1007/s11042-018-7017-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600034
DA 2024-07-18
ER

PT J
AU Wu, HQ
   Kuang, SJ
   Hou, HB
   Khandelwal, P
AF Wu, Hequan
   Kuang, Shijie
   Hou, Haibin
   Khandelwal, Prashant
TI Verification and injury risk study of FE model of upper limbs in elderly
   under dynamic loading
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Elderly driver; Upper limb biomechanics; Bio-fidelity; Injury tolerance
   limit; Injury risk
ID FINITE-ELEMENT MODEL; UPPER EXTREMITY; RESPONSES
AB The ageing population becomes an increasingly serious issue in the world. The number of elderly drivers has also been rising year by year. In order to study the biomechanical response and injury risk of elderly drivers in vehicle collisions. Firstly, the finite element (FE) method is used to establish the upper limb FE model of elderly people with biological fidelity. Based on the experimental data onto cadaver upper limbs in literature, the simulation reliability of the upper limb FE model was verified under dynamic loading. The results showed that the model can accurately reproduce the response and injury to the upper limb of the human body, and obtains the tolerance limits of each part of the FE model of the aged upper limbs were consistent with the cadaver experiment. Moreover, the study used the verified FE model of upper limbs to precede the airbag initiation experiments in order to study the risk of forearm injury at different positions of the airbag. The risk of forearm injury was found related to the crash velocity from distance. Lastly, when an included angle was added between the forearm and the airbag module and the forearm was away from the airbag center. It can reduce the distal velocity of the forearm and thus reduce the risk of upper limb injury.
C1 [Wu, Hequan; Kuang, Shijie; Hou, Haibin] Changsha Univ Sci & Technol, Educ Dept Hunan Prov, Key Lab Lightweight & Reliabil Technol Engn Vehic, Changsha 410004, Peoples R China.
   [Wu, Hequan; Hou, Haibin] Wayne State Univ, Bioengn Ctr, Detroit, MI 48201 USA.
   [Khandelwal, Prashant] Med Coll Wisconsin, Dept Neurosurg, Milwaukee, WI 53227 USA.
C3 Changsha University of Science & Technology; Wayne State University;
   Medical College of Wisconsin
RP Wu, HQ (corresponding author), Changsha Univ Sci & Technol, Educ Dept Hunan Prov, Key Lab Lightweight & Reliabil Technol Engn Vehic, Changsha 410004, Peoples R China.; Wu, HQ (corresponding author), Wayne State Univ, Bioengn Ctr, Detroit, MI 48201 USA.
EM wuhequan@163.com
OI Wu, Hequan/0000-0003-1939-6474
CR [Anonymous], 2015, INT J VEHICLE SAFETY, DOI DOI 10.1504/IJVS.2015.070788
   Bass CR, 1997, SOC AUTO ENG SAE, V41, P111
   Beillas P, 2017, TRAFFIC INJ PREV, V18, pS142, DOI 10.1080/15389588.2017.1307971
   Chen J-Q, 2017, J S CHINA U TECHNOL, V08, P27
   Conroy C, 2007, INJURY, V38, P350, DOI 10.1016/j.injury.2006.03.017
   Davis Matthew L, 2016, Stapp Car Crash J, V60, P509
   Duma SM, 1999, J ANAT, V194, P463, DOI 10.1046/j.1469-7580.1999.19430463.x
   Hardy W., 1998, SAE TRANSACTIONS, V7, P1366
   Hardy W N, 2001, Stapp Car Crash J, V45, P511
   Hardy WN, 1997, SAE T, P3663
   Hault-Dubrulle A, 2012, Comput Methods Biomech Biomed Engin, V15 Suppl 1, P295
   Iwamoto M, 2001, JSME INT J C-MECH SY, V44, P1072, DOI 10.1299/jsmec.44.1072
   Jernigan MV, 2003, AM J EMERG MED, V21, P100, DOI 10.1053/ajem.2003.50037
   Kirkish SL, 1996, STAPP CAR C, VP-30, P75
   McGovern MK, 2000, ANN PLAS SURG, V44, P481, DOI 10.1097/00000637-200044050-00002
   Meng YZ, 2017, ACCIDENT ANAL PREV, V98, P206, DOI 10.1016/j.aap.2016.10.002
   Milanowicz M, 2016, INT J OCCUP SAF ERGO, V22, P320, DOI 10.1080/10803548.2015.1131070
   Nie B, 2018, INT J CRASHWORTHINES, V2018, P1
   Richter M, 2000, J TRAUMA, V48, P907, DOI 10.1097/00005373-200005000-00015
   Van Rooij L, 2003, DEVELOPMENT, V2003, P22
NR 20
TC 1
Z9 1
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10267
EP 10283
DI 10.1007/s11042-019-7373-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600029
DA 2024-07-18
ER

PT J
AU Li, G
   Hu, RM
   Zhang, R
   Wang, XH
AF Li, Gang
   Hu, Ruimin
   Zhang, Rui
   Wang, Xiaochen
TI A mapping model of spectral tilt in normal-to-Lombard speech conversion
   for intelligibility enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligibility Enhancement (IENH); Lombard reflex; Spectral tilt;
   Linear prediction; Deep Neural Networks (DNNs)
ID NOISE; IMPROVEMENT; PREDICTION; SPEAKING
AB Environmental noise degrades the speech intelligibility when listening to the phone. Although the phone has a clean signal source, it is still difficult for the listener to get information. Intelligibility enhancement (IENH) is a type of perceptual enhancement technique for clean speech rendered in noisy environments. This study focuses on IENH by normal-to-Lombard speech conversion, which is inspired by Lombard reflex. In this conversion process, the key point is to map the spectral tilt from the normal speech (normal style) to the Lombard speech (Lombard style). For mapping the spectral tilt, we propose a mapping model combining linear-prediction-based mapping networks and tilt modification. Compared with previous studies, we use deep neural networks (DNNs) instead of Gaussian-based models for higher dimensional mapping, and inventively add a tilt modification module to reduce the mapping errors of formant magnitudes further. In this paper, we use AVS-M codec and two datasets as the benchmark platform. The valuation shows that our method gets better results than reference methods in both objective and subjective experiments.
C1 [Li, Gang; Hu, Ruimin; Zhang, Rui; Wang, Xiaochen] Wuhan Univ, Sch Comp Sci, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.
   [Hu, Ruimin] Wuhan Univ, Hubei Key Lab Multimedia & Network Commun Engn, Wuhan 430072, Peoples R China.
   [Wang, Xiaochen] Collaborat Innovat Ctr Geospatial Technol, Wuhan 430079, Peoples R China.
C3 Wuhan University; Wuhan University
RP Hu, RM (corresponding author), Wuhan Univ, Sch Comp Sci, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.; Hu, RM (corresponding author), Wuhan Univ, Hubei Key Lab Multimedia & Network Commun Engn, Wuhan 430072, Peoples R China.
EM ligang10@whu.edu.cn; hrm@whu.edu.cn; ruizhang1216@whu.edu.cn;
   clowang@whu.edu.cn
FU National Nature Science Foundation of China [61801334, U1736206];
   National Key Research and Development Program of China [2017YFB1002803]
FX This work was supported by National Nature Science Foundation of China
   (Grant Nos. 61801334 and U1736206) and National Key Research and
   Development Program of China (Grant Nos. 2017YFB1002803).
CR Alghamdi N, 2018, J ACOUST SOC AM, V143, pEL523, DOI 10.1121/1.5042758
   [Anonymous], 2014, P INTERSPEECH
   [Anonymous], 1997, ANSI S3.5-1997
   [Anonymous], 2014, DEEP LEARNING METHOD
   AVS, 2010, GBT20090102013 AVS N
   Chen JD, 2006, IEEE T AUDIO SPEECH, V14, P1218, DOI 10.1109/TSA.2005.860851
   Cooke M., 2013, Proceedings of interspeech, P3552, DOI DOI 10.21437/INTERSPEECH.2013-764
   Cooke M, 2014, COMPUT SPEECH LANG, V28, P543, DOI 10.1016/j.csl.2013.08.003
   Ellis D.P. W., 2003, Dynamic Time Warp (DTW) in Matlab
   Garnier M, 2014, COMPUT SPEECH LANG, V28, P580, DOI 10.1016/j.csl.2013.07.005
   Huber R, 2018, J AUDIO ENG SOC, V66, P759, DOI 10.17743/jaes.2018.0041
   ITU-T R, 1996, P 800 METH SUBJ DET
   Jensen TL, 2016, SPEECH COMMUN, V76, P143, DOI 10.1016/j.specom.2015.09.013
   Jokinen E, 2017, IEEE-ACM T AUDIO SPE, V25, P1985, DOI 10.1109/TASLP.2017.2740004
   Jokinen E, 2017, J ACOUST SOC AM, V141, pEL327, DOI 10.1121/1.4979162
   Jokinen E, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P85
   Junqua JC, 1999, INT CONF ACOUST SPEE, P2083, DOI 10.1109/ICASSP.1999.758343
   JUNQUA JC, 1991, INT CONF ACOUST SPEE, P361, DOI 10.1109/ICASSP.1991.150351
   Kakouros S, 2018, SPEECH COMMUN, V103, P11, DOI 10.1016/j.specom.2018.08.002
   Kleijn WB, 2015, IEEE SIGNAL PROC MAG, V32, P43, DOI 10.1109/MSP.2014.2365594
   Kodrasi I, 2017, J AUDIO ENG SOC, V65, P117, DOI 10.17743/jaes.2016.0047
   Koutsogiannaki M, 2017, INTERSPEECH, P1973, DOI 10.21437/Interspeech.2017-1157
   Koutsogiannaki M, 2014, INT CONF ACOUST SPEE
   Li Gao, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3670, DOI 10.1109/ICASSP.2014.6854286
   Lombard E., 1911, Ann. Maladies Oreille, Larynx, Nez, Pharynx, V37, P101, DOI DOI 10.1145/1168987.1169028
   López AR, 2017, INTERSPEECH, P1363, DOI 10.21437/Interspeech.2017-400
   Lu YY, 2009, SPEECH COMMUN, V51, P1253, DOI 10.1016/j.specom.2009.07.002
   Petkov PN, 2015, IEEE-ACM T AUDIO SPE, V23, P327, DOI 10.1109/TASLP.2014.2384271
   Rabiner LR, 2011, Theory and applications of digital speech processing
   Schepker H, 2013, INTERSPEECH, P3544
   Sooducha M, 2016, P GERM ANN C AC DAGA
   Taal CH, 2013, INTERSPEECH, P3549
   Taal CH, 2014, COMPUT SPEECH LANG, V28, P858, DOI 10.1016/j.csl.2013.11.003
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   Wang X, 2013, P INT C INT MULT COM, P101
   Zhang R, 2019, LECT NOTES COMPUT SC, V11296, P144, DOI 10.1007/978-3-030-05716-9_12
   Zhang Wen, 2010, 2010 International Conference on Audio, Language and Image Processing (ICALIP), P31, DOI 10.1109/ICALIP.2010.5685024
   Zorila TC, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P634
NR 38
TC 7
Z9 7
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19471
EP 19491
DI 10.1007/s11042-020-08838-1
EA MAR 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000521701400002
DA 2024-07-18
ER

PT J
AU Alkasasbeh, AA
   Ghinea, G
AF Alkasasbeh, Anas Ali
   Ghinea, Gheorghita
TI Using olfactory media cues in e-learning - perspectives from an
   empirical investigation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Olfactory media; Olfactory cues; Traditional digital media; Learner
   performance; Quality of experience
ID MULTIMEDIA; QUALITY
AB People interact with computers using their senses. Currently, in a digital context, traditional digital media like videos and images used to convey information to users, and these media can be used as a source of information. However, relatively few studies have been conducted on olfactory media as a source of information in a digital context. In this paper, we report on a study that examined the possibility of using olfactory media as a source of information and whether its usage as informational cues enhances learning performance and user Quality of Experience (QoE). To this end, an olfactory-enhanced quiz (web-based) was developed about four countries. The quiz contained different types of questions employing four types of digital media in their contents: text, image, audio and olfactory media. Four scents were used that were considered to be related to the respective countries. Sixty-four participants were invited to our experiment to evaluate this application. Our results revealed that usage of olfactory media synchronised with traditional digital media had a significant impact on learner performance compared to the case when no olfactory media was employed. In respect of user QoE, it was found that olfactory media influenced users positively; moreover, they were passionate about engaging with enhanced olfactory applications in the future.
C1 [Alkasasbeh, Anas Ali; Ghinea, Gheorghita] Brunel Univ London, Coll Engn Design & Phys Sci, Dept Comp Sci, London, England.
   [Alkasasbeh, Anas Ali] Mutah Univ, Coll Informat Technol, Comp Sci Dept, Mutah, Jordan.
C3 Brunel University; Mutah University
RP Ghinea, G (corresponding author), Brunel Univ London, Coll Engn Design & Phys Sci, Dept Comp Sci, London, England.
EM george.ghinea@brunel.ac.uk
RI Ghinea, Gheorghita/AAG-6770-2020
OI Ghinea, Gheorghita/0000-0003-2578-5580; Alkasasbeh, Anas
   Ali/0009-0004-8586-4461
CR Ademoye OA, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2487268.2487270
   Astleitner H., 2004, J ED MULTIMEDIA HYPE, V13, P3
   Berney S, 2016, COMPUT EDUC, V101, P150, DOI 10.1016/j.compedu.2016.06.005
   Bogusevschi D, 2018, IR INT C ED IPETEL W
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Davidson F, 1999, CONTEMP PSYCHOL, V44, P100
   Dobbelstein D, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (ISWC 17), P130, DOI 10.1145/3123021.3123035
   Garcia-Ruiz M, 2008, Interactive Computer Aided Learning
   Garcia-Ruiz M., 2008, Proceedings of E-Learn: World Conference on E-Learning in Corporate, Government, Healthcare, and Higher Education 2008, P2647
   Ghergulescu I., 2012, ASSESSMENT GAME BASE, P355, DOI [DOI 10.1007/978-1-4614-3546-4_18, 10.1007/978-1-4614-3546-4_18]
   Ghinea G, 2006, MULTIMEDIA SYST, V11, P271, DOI 10.1007/s00530-005-0007-8
   Ghinea G, 2011, MULTIPLE SENSORIAL M, P344
   Ghinea G, 2008, COMPUT HUM BEHAV, V24, P1317, DOI 10.1016/j.chb.2007.07.013
   Ghinea G, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2617994
   Ghinea G, 2015, PROCEEDINGS OF 2015 INTERNATIONAL CONFERENCE ON INTERACTIVE MOBILE COMMUNICATION TECHNOLOGIES AND LEARNING (IMCL), P296, DOI 10.1109/IMCTL.2015.7359606
   Ghinea G, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2379790.2379794
   Goldstein E. B., 2010, Sensation and Perception
   Gonçcalves F, 2017, LECT NOTES COMPUT SC, V10514, P165, DOI 10.1007/978-3-319-67684-5_11
   Kaye J. N., 2001, THESIS
   Kim JD, 2015, ETRI J, V37, P88, DOI 10.4218/etrij.15.0113.0078
   Kwok R.C.-W., 2009, P 2009 WORKSH AMB ME, P65
   Leenders MAAM, 2019, J RETAIL CONSUM SERV, V48, P270, DOI 10.1016/j.jretconser.2016.05.007
   Mayer R.E., 2002, New Directions for Teaching Learning, P55, DOI DOI 10.1002/TL.47
   Mehta MA, 2010, ENCY PSYCHOPHARMACOL, P1262
   Miyaura M, 2011, P IEEE VIRT REAL ANN, P139, DOI 10.1109/VR.2011.5759452
   Murray N, 2017, IEEE T SYST MAN CY-S, V47, P2503, DOI 10.1109/TSMC.2016.2531654
   Murray N, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3108243
   Murray Niall., 2013, Proceedings of the 4th ACM Multimedia Systems Conference, MMSys'13, P162, DOI [https://doi.org/10.1145/2483977.2483999, DOI 10.1145/2483977.2483999]
   Noguchi D, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P83
   Pellas N, 2019, VIRTUAL REAL-LONDON, V23, P329, DOI 10.1007/s10055-018-0347-2
   Ranasinghe N, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1139, DOI 10.1145/3123266.3123440
   Richard E., 2006, Virtual Reality, V10, P207, DOI DOI 10.1007/S10055-006-0040-8
   Saleme EB, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3319853
   Sauro J., 2011, Measuring Usability Quantitative Usability, Statistics ; Six Sigma by Jeff Sauro
   Sauro Jef, 2011, A Practical Guide to the System Usability Scale: Background, Benchmarks, and Best Practices
   Sprinkle R., 1999, Jaounal ofTeaching English in the Two-Year Collage, V27, P188
   Stafford LD, 2009, CHEMOSENS PERCEPT, V2, P59, DOI 10.1007/s12078-009-9045-5
   Sugimoto Sayumi., 2010, Proceedings of the 18th ACM International Conference on Multimedia, MM'10, P301, DOI DOI 10.1145/1873951.1873994
   Suzuki Risa, 2014, P 16 INT C MULT INT, DOI 10.1145/2663204.2663269
   Tijou A, 2006, LECT NOTES COMPUT SC, V3942, P1223, DOI 10.1007/11736639_152
   Yuan ZH, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2661329
   Zou LH, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P315, DOI 10.1145/3083187.3084014
NR 42
TC 8
Z9 8
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19265
EP 19287
DI 10.1007/s11042-020-08763-3
EA MAR 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000521018900005
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Dong, E
   Han, B
   Jian, H
   Tong, J
   Wang, Z
AF Dong, Enzeng
   Han, Bo
   Jian, Hao
   Tong, Jigang
   Wang, Zenghui
TI Moving target detection based on improved Gaussian mixture model
   considering camera motion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Moving target detection; Gaussian mixture model; Motion compensation
ID BACKGROUND SUBTRACTION; OBJECT DETECTION; OPTICAL-FLOW; ALGORITHM;
   TRACKING
AB This paper proposes a moving target detection scheme suitable for camera motion. Firstly, the background model is initialized by a Gaussian mixture model algorithm. Then Kanade-Lucas-Tomasi Feature Tracker (KLT) method is used to detect optical flow feature points of two adjacent frames, RANdom SAmple Consensus (RANSAC) algorithm is used to filter out the correct matching points and obtain a homography matrix, which can recover the background model matching the current frame, the new background model is used to detect moving target of the current frame. In the foreground detection stage, the current pixel is first compared with its own background model, and then compared with the background model of its 8 neighborhood pixels, the algorithm is speeded up without reducing the detection accuracy in this way; In the update stage of the background model, in order to adapt to the background changes caused by camera motion, an age value variable is set for each pixel. The experimental results show that the improved algorithm has a significant improvement in detection accuracy and running time compared to Gaussian mixture background modeling.
C1 [Dong, Enzeng; Han, Bo; Jian, Hao; Tong, Jigang; Wang, Zenghui] Tianjin Univ Technol, Complex Syst Control Theory & Applicat Key Lab, 391 Binshui Xidao, Tianjin 300384, Peoples R China.
   Univ South Africa, Dept Elect & Min Engn, ZA-1710 Florida, South Africa.
C3 Tianjin University of Technology; University of South Africa
RP Dong, E; Tong, J (corresponding author), Tianjin Univ Technol, Complex Syst Control Theory & Applicat Key Lab, 391 Binshui Xidao, Tianjin 300384, Peoples R China.
EM dongenzeng@163.com; tongjg163@163.com
RI Wang, Zenghui/B-8280-2015
CR Azzam R, 2016, J VIS COMMUN IMAGE R, V36, P90, DOI 10.1016/j.jvcir.2015.11.009
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bouwmans T, 2018, COMPUT SCI REV, V28, P26, DOI 10.1016/j.cosrev.2018.01.004
   Brutzer S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1937, DOI 10.1109/CVPR.2011.5995508
   Chen XR, 2015, OPTIK, V126, P2256, DOI 10.1016/j.ijleo.2015.05.122
   Gao DP, 2013, OPT LASER TECHNOL, V49, P95, DOI 10.1016/j.optlastec.2012.12.004
   Guo XM, 2016, J VIS COMMUN IMAGE R, V39, P164, DOI 10.1016/j.jvcir.2016.05.016
   Hu M, 2008, INT C PATT RECOG, P9
   Hu X., 2016, OPEN J APPL SCI, V6, P449
   Hu YT, 2016, INVEST OPHTH VIS SCI, V57
   Huang W, 2015, INFRARED PHYS TECHN, V71, P518, DOI 10.1016/j.infrared.2015.06.011
   Li YF, 2018, INFRARED PHYS TECHN, V92, P44, DOI 10.1016/j.infrared.2018.05.009
   Liu BZ, 2017, SIGNAL PROCESS-IMAGE, V54, P1, DOI 10.1016/j.image.2017.02.008
   Liu G, 2012, COMM COM INF SC, V346, P261
   [栾庆磊 Luan Qinglei], 2011, [光电工程, Opto-Electronic Engineering], V38, P77
   Motai Y, 2012, SIGNAL PROCESS-IMAGE, V27, P83, DOI 10.1016/j.image.2011.06.005
   Mstafa RJ, 2016, MULTIMED TOOLS APPL, V75, P10311, DOI 10.1007/s11042-015-3060-0
   Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x
   [石雪 Shi Xue], 2017, [中国图象图形学报, Journal of Image and Graphics], V22, P1758
   Wang HZ, 2007, PATTERN RECOGN, V40, P1091, DOI 10.1016/j.patcog.2006.05.024
   Xin YH, 2014, OPTIK, V125, P5690, DOI 10.1016/j.ijleo.2014.06.092
   [徐凯 Xu Kai], 2012, [激光与红外, Laser and Infrared], V42, P821
   Xue WL, 2018, MEASUREMENT, V124, P233, DOI 10.1016/j.measurement.2018.04.019
   Yin C., 2014, CHINESE J LASERS, V41, P239
   Yuan Guo-wu, 2013, Journal of Chinese Computer Systems, V34, P668
   Zeng Z. Y., 2012, ADV ENG FORUM, P717
   Zhang SP, 2017, IEEE T NEUR NET LEAR, V28, P2357, DOI 10.1109/TNNLS.2016.2586194
   Zhang SP, 2009, IEEE INT CON MULTI, P518, DOI 10.1109/ICME.2009.5202547
   Zhang SP, 2009, INT J PATTERN RECOGN, V23, P1397, DOI 10.1142/S0218001409007569
   Zhong Q. U., 2013, COMPUTER SCI, V659, P75
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 31
TC 8
Z9 9
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7005
EP 7020
DI 10.1007/s11042-019-08534-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100005
DA 2024-07-18
ER

PT J
AU Liu, W
   Huang, XL
   Cao, G
   Zhang, JL
   Song, GG
   Yang, LF
AF Liu, Wei
   Huang, Xianglin
   Cao, Gang
   Zhang, Jianglong
   Song, Gege
   Yang, Lifang
TI Multi-modal sequence model with gated fully convolutional blocks for
   micro-video venue classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Micro-video venue classification; Gated fully convolutional block;
   Multi-modal sequence model; Prototype learning
AB With the large amount of micro-videos available in social network applications, micro-video venue category provides extremely valuable venue information that assists location-oriented applications, personalized services, etc. In this paper, we formulate micro-video venue classification as a multi-modal sequential modeling problem. Unlike existing approaches that use long short-term memory (LSTM) models to capture temporal patterns for micro-video, we propose multi-modality sequence model with gated fully convolutional blocks. Specifically, we firstly adopt three parallel gated fully convolutional blocks to extract spatiotemporal features from visual, acoustic and textual modalities of micro-videos. Then, an additional gated fully convolutional block is used to fuse such three modalities of spatiotemporal features. Finally, corresponding prototype is simultaneously learned to improve the robustness against softmax classification function. Extensive experimental results on a real-world benchmark dataset demonstrate the effectiveness of our model in terms of both Micro-F and Macro-F scores.
C1 [Liu, Wei; Huang, Xianglin; Cao, Gang; Song, Gege; Yang, Lifang] Commun Univ China, Sch Comp Sci & Cybersecur, Beijing, Peoples R China.
   [Liu, Wei] Nanyang Inst Technol, Nanyang, Peoples R China.
   [Zhang, Jianglong] State Grid Fujian Informat & Telecommun Co, Fuzhou, Peoples R China.
C3 Communication University of China; Nanyang Institute of Technology
RP Huang, XL (corresponding author), Commun Univ China, Sch Comp Sci & Cybersecur, Beijing, Peoples R China.
EM cuclw12@163.com; huangxl@cuc.edu.cn; gangcao@cuc.edu.cn;
   zhangjianglong135@126.com; sggever@163.com; yanglifang@cuc.edu.cn
CR [Anonymous], IEEE T MULTIMEDIA
   [Anonymous], P 56 ANN M ASS COMP
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2016, ARXIV160309439
   [Anonymous], 2009, P 17 ACM INT C MULT
   [Anonymous], 2018, MULTIMEDIA TOOLS APP
   Bai S., 2018, EMPIRICAL EVALUATION
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1454, DOI 10.1145/2964284.2971477
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P898, DOI 10.1145/2964284.2964314
   Cheng B, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P4584, DOI 10.1109/WCICA.2010.5554118
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Gehring J., 2017, P MACHINE LEARNING R, P1243
   Guo J, 2018, LECT NOTES COMPUT SC, V11164, P721, DOI 10.1007/978-3-030-00776-8_66
   Hays J, 2008, PROC CVPR IEEE, P3436
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang L, 2017, MULTIMED TOOLS APPL, V76, P20341, DOI 10.1007/s11042-017-4781-z
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li Yehao., 2016, P 24 ACM INT C MULT, P928
   Liu M, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P970, DOI 10.1145/3123266.3123341
   Liu W, 2018, LECT NOTES COMPUT SC, V11165, P705, DOI 10.1007/978-3-030-00767-6_65
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   Miech A., 2017, ARXIV PREPRINT ARXIV
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Nie LQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1192, DOI 10.1145/3123266.3123313
   Redi M, 2014, PROC CVPR IEEE, P4272, DOI 10.1109/CVPR.2014.544
   Rochan M, 2018, LECT NOTES COMPUT SC, V11216, P358, DOI 10.1007/978-3-030-01258-8_22
   Sanden C, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P705
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shi XJ, 2015, ADV NEUR IN, V28
   Xu K, 2019, IEEE ICC
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yang H, 2018, IEEE CONF COMM NETW
   Zhao B, 2018, PROC CVPR IEEE, P7405, DOI 10.1109/CVPR.2018.00773
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu W, 2016, IEEE INT C BIOINFORM, P1415, DOI 10.1109/BIBM.2016.7822730
NR 41
TC 12
Z9 13
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6709
EP 6726
DI 10.1007/s11042-019-08147-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900057
DA 2024-07-18
ER

PT J
AU Wang, WQ
AF Wang, Weiqing
TI A reversible data hiding algorithm based on bidirectional difference
   expansion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Histogram shifting; Difference expansion; Image
   encryption; Information security
ID SCHEME; WATERMARKING
AB After the extraction of hidden data, reversible data hiding (RDH) algorithms are able to completely recover the original image without any error. For the past few years, a number of RDH algorithms based on difference expansion (DE) have been developed rapidly. However, their embedding capacity (EC) and the quality of the stego images are relatively low. In this paper, a reversible data hiding algorithm based on bidirectional difference expansion was proposed. Firstly, it scans the cover image in a Z-shaped way to transform the cover image into a 1D array. Secondly, the difference between two adjacent pixels was expanded towards two directions to embed one bit into the left pixel. Thirdly, the array was transformed into a 2D matrix to obtain the stego image. After receiving the stego image, the extraction process is performed in the following three steps. Firstly, the stego image was first transformed into a 1D array in the Z-shaped way. Secondly, the difference between two adjacent pixels was compressed towards two directions to extract the embedded bits and to restore the cover 1D array. Thirdly, the cover 1D array was transformed into a 2D matrix. Besides, to improve the quality of the stego image, the range of the mean of the two embedding pixels was used to solve the issue of overflow/underflow. Experimental results show, the EC of the cover image, the quality of the stego image and the security of the secret data are improved obviously.
C1 [Wang, Weiqing] Southwest Univ, Coll Business, Chongqing 402460, Peoples R China.
C3 Southwest University - China
RP Wang, WQ (corresponding author), Southwest Univ, Coll Business, Chongqing 402460, Peoples R China.
EM wwqlhy@163.com
RI liao, xingyu/KHE-4272-2024; zhu, zhu/JDN-0159-2023; yin,
   yue/JQV-9753-2023; Zhang, Yuting/JRW-3937-2023
CR Amini M, 2017, SIGNAL PROCESS, V137, P213, DOI 10.1016/j.sigpro.2017.01.019
   Arham A, 2017, SIGNAL PROCESS, V137, P52, DOI 10.1016/j.sigpro.2017.02.001
   Chang JC, 2017, SIGNAL PROCESS, V133, P135, DOI 10.1016/j.sigpro.2016.11.003
   Chen HS, 2016, SIGNAL PROCESS-IMAGE, V46, P1, DOI 10.1016/j.image.2016.04.006
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Darabkh KA, 2015, INF TECHNOL CONTROL, V44, P315, DOI 10.5755/j01.itc.44.3.8949
   De V. C, 2003, IEEE T MULTIMEDIA, V5, P97, DOI DOI 10.1109/TMM.2003.809729
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Gao GY, 2017, INFORM SCIENCES, V385, P250, DOI 10.1016/j.ins.2017.01.009
   Garg P, 2017, J CIRCUIT SYST COMP, V26, DOI 10.1142/S0218126617501031
   He WG, 2018, INFORM SCIENCES, V467, P784, DOI 10.1016/j.ins.2018.04.088
   Highland HJ, 1997, COMPUT SECUR, V16, P369, DOI 10.1016/S0167-4048(97)82243-2
   Hong W, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/104835
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Jararweh Y, 2019, MULTIMED TOOLS APPL, V78, P3961, DOI 10.1007/s11042-017-5092-0
   Jung KH, 2018, MULTIMED TOOLS APPL, V77, P7795, DOI 10.1007/s11042-017-5066-2
   Jung KH, 2018, J REAL-TIME IMAGE PR, V14, P159, DOI 10.1007/s11554-016-0618-7
   Jung KH, 2016, IETE TECH REV, V33, P441, DOI 10.1080/02564602.2015.1102099
   Lee CF, 2017, MULTIMED TOOLS APPL, V76, P9993, DOI 10.1007/s11042-016-3591-z
   Lee SH, 2018, MULTIMED TOOLS APPL, V77, P19499, DOI 10.1007/s11042-017-5379-1
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin S. L., 2013, J INF HIDING MULTIME, V1, P19
   Liu H, 2017, MULTIMED TOOLS APPL
   Liu SH, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3990
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Nikolaidis A, 2003, IEEE T IMAGE PROCESS, V12, P563, DOI 10.1109/TIP.2003.810586
   Ou B, 2017, NEUROCOMPUTING, V226, P23, DOI 10.1016/j.neucom.2016.11.017
   Rahmani P, 2015, MULTIMED TOOLS APPL, V74, P10713, DOI 10.1007/s11042-014-2200-2
   Ri Y, 2018, SMART INNOV SYST TEC, V82, P42, DOI 10.1007/978-3-319-63859-1_6
   Run RS, 2011, EXPERT SYST APPL, V38, P14357, DOI 10.1016/j.eswa.2011.03.024
   Shah M, 2018, ARAB J SCI ENG, V43, P8145, DOI 10.1007/s13369-018-3354-4
   Shen SY, 2015, MULTIMED TOOLS APPL, V74, P707, DOI 10.1007/s11042-014-2016-0
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Nguyen TS, 2015, J VIS COMMUN IMAGE R, V33, P389, DOI 10.1016/j.jvcir.2015.10.008
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Weng SW, 2017, MULTIMED TOOLS APPL, V76, P13173, DOI 10.1007/s11042-016-3693-7
   Wu HT, 2018, SIGNAL PROCESS-IMAGE, V62, P64, DOI 10.1016/j.image.2017.12.006
   Yi S, 2018, SIGNAL PROCESS-IMAGE, V64, P78, DOI 10.1016/j.image.2018.03.001
   Zhang WM, 2016, IEEE T MULTIMEDIA, V18, P1469, DOI 10.1109/TMM.2016.2569497
   Zhang XQ, 2017, MULTIMED TOOLS APPL, V76, P9195, DOI 10.1007/s11042-016-3521-0
NR 46
TC 16
Z9 17
U1 2
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5965
EP 5988
DI 10.1007/s11042-019-08255-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900024
DA 2024-07-18
ER

PT J
AU Yao, HC
   Ni, RR
   Zhao, Y
AF Yao, Haichao
   Ni, Rongrong
   Zhao, Yao
TI Double compression detection for H.264 videos with adaptive GOP
   structure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video forensics; Double compression detection; Adaptive GOP; Frame byte
   count sequence
AB As a blind forensic method, double compression detection is valid to multiple manipulations. However, the existing methods only consider to detect the videos with fixed Group of Pictures (GOP). In this paper, we put forward a novel double compression detection method for videos with both fixed and adaptive GOP structure in H.264 videos. Considering that video may contain adaptive GOPs caused by fast moving contents or scene changes, in our double compression detection scheme, temporal segmentation is first used to divide video into static and rapid periods which contain normal fixed and adaptive GOPs respectively. Then, new artifacts based on the sequence of frame's byte count (FBC) are analyzed. A feature sequence composed of recognizable distances is generated by combining the artifacts in the static and rapid periods of video. Finally, to reveal the intrinsic property of the feature sequence, a scoring strategy is designed to determine whether or not double compression. The experiments demonstrate that the proposed scheme is effective to detect double compression of H.264 videos, and it outperforms other existing state-of-the-art methods.
C1 [Yao, Haichao; Ni, Rongrong; Zhao, Yao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Yao, Haichao; Ni, Rongrong; Zhao, Yao] Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Ni, RR (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.; Ni, RR (corresponding author), Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
EM rrni@bjtu.edu.cn
CR Aghamaleki JA, 2017, MULTIMED TOOLS APPL, V76, P20691, DOI 10.1007/s11042-016-4004-z
   [Anonymous], 2010, 2010 Asia-Pacific Power and Energy Engineering Conference, DOI DOI 10.1109/APPEEC.2010.5448448
   [Anonymous], P 4 INT WORKSH VED P
   [Anonymous], 2006, P 8 WORKSHOP MULTIME, DOI DOI 10.1145/1161366.1161375
   [Anonymous], P SPIE
   Chen W, 2009, LECT NOTES COMPUT SC, V5450, P16, DOI 10.1007/978-3-642-04438-0_2
   Feng CH, 2017, IEEE T CIRC SYST VID, V27, P2543, DOI 10.1109/TCSVT.2016.2593612
   He PS, 2017, NEUROCOMPUTING, V228, P84, DOI 10.1016/j.neucom.2016.09.084
   Jiang XH, 2018, IEEE T INF FOREN SEC, V13, P170, DOI 10.1109/TIFS.2017.2745687
   Jiang XH, 2013, IEEE SIGNAL PROC LET, V20, P447, DOI 10.1109/LSP.2013.2251632
   Milani S, 2012, APSIPA TRANS SIGNAL, V1, DOI 10.1017/ATSIP.2012.2
   Singh RD, 2018, MULTIMEDIA SYST, V24, P211, DOI 10.1007/s00530-017-0538-9
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Sun TF, 2012, INT CONF ACOUST SPEE, P1389, DOI 10.1109/ICASSP.2012.6288150
   Vázquez-Padín D, 2012, IEEE INT WORKS INFOR, P151, DOI 10.1109/WIFS.2012.6412641
   Wang WH, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P39
   Yang J, 2016, GEODERMA, V264, P61, DOI 10.1016/j.geoderma.2015.10.003
   Yao H, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9120313
NR 18
TC 5
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5789
EP 5806
DI 10.1007/s11042-019-08306-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900016
DA 2024-07-18
ER

PT J
AU Kiashari, SEH
   Nahvi, A
   Bakhoda, H
   Homayounfard, A
   Tashakori, M
AF Kiashari, Serajeddin Ebrahimian Hadi
   Nahvi, Ali
   Bakhoda, Hamidreza
   Homayounfard, Amirhossein
   Tashakori, Masoumeh
TI Evaluation of driver drowsiness using respiration analysis by thermal
   imaging on a driving simulator
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Drowsiness detection; Thermal imaging; Non-contact monitoring;
   Respiration rate; Driver monitoring system; Driving simulator
ID DETECTION SYSTEM; SLEEPINESS; TRACKING; VISION; FUSION; EEG
AB In this paper, a new non-intrusive driver drowsiness detection method is introduced based on respiration analysis using facial thermal imaging. Drowsiness is the cause of many driving accidents all over the world. Drivers' respiration system undergoes significant changes from wakefulness to drowsiness and can be used to detect drowsiness. Current respiration measurement methods are intrusive and uncomfortable making respiration the least measured vital sign during driving. In this paper, a new method is presented based on facial thermal imaging to analyze drivers' respiration signal non-intrusively. Thirty subjects are tested in a car simulator. They are fully awake at the beginning and experience drowsiness during the tests. The mean and the standard deviation of the respiration rate and the inspiration-to-expiration time ratio are extracted from the subjects' respiration signal. To detect drowsiness, the Support Vector Machine (SVM) and the K-Nearest Neighbor (KNN) classifiers are used. The Observer Rating of Drowsiness method is used for scoring the drowsiness level and validating the proposed method. The performance and the results of both methods are presented and compared. The results indicate that drowsiness can be detected with the accuracy of 90%, sensitivity of 92%, specificity of 85%, and precision of 91%.
C1 [Kiashari, Serajeddin Ebrahimian Hadi; Nahvi, Ali; Bakhoda, Hamidreza; Homayounfard, Amirhossein; Tashakori, Masoumeh] KN Toosi Univ Technol, Fac Mech Engn, Tehran, Iran.
C3 K. N. Toosi University of Technology
RP Kiashari, SEH (corresponding author), KN Toosi Univ Technol, Fac Mech Engn, Tehran, Iran.
EM sebrahimian@mail.kntu.ac.ir
OI tashakori, masoumeh/0000-0001-5117-3065; Ebrahimian Hadi Kiashari,
   Serajeddin/0000-0002-2255-8000
FU Cognitive Science and Technology Council (CSTC) [1307]
FX This paper is based upon a work supported by the Cognitive Science and
   Technology Council (CSTC) under Grant No. 1307.
CR AKERSTEDT T, 1990, INT J NEUROSCI, V52, P29, DOI 10.3109/00207459008994241
   Alkali AH, 2013, UKSIM EURO SYMP COMP, P265, DOI 10.1109/EMS.2013.46
   [Anonymous], 2018, Critical Reasons for Crashes Investigated in the National Motor Vehicle Crash Causation Survey
   Arefnezhad S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19040943
   Balandong RP, 2018, IEEE ACCESS, V6, P22908, DOI 10.1109/ACCESS.2018.2811723
   Bartula M, 2013, IEEE ENG MED BIO, P2672, DOI 10.1109/EMBC.2013.6610090
   Bernacchia N, 2014, IEEE INT SYM MED MEA, P243, DOI 10.1109/MeMeA.2014.6860065
   Chai M, 2019, TRANSPORT RES D-TR E, V66, P95, DOI 10.1016/j.trd.2018.07.007
   Chauvin R, 2016, IEEE SYST J, V10, P1046, DOI 10.1109/JSYST.2014.2336372
   Chekmenev SY, 2009, ADV PATTERN RECOGNIT, P87, DOI 10.1007/978-1-84800-277-7_4
   Chowdhury A, 2018, IEEE SENS J, V18, P3055, DOI 10.1109/JSEN.2018.2807245
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Danisman T., 2010, Proceedings International Conference on Machine and Web Intelligence (ICMWI 2010), P230, DOI 10.1109/ICMWI.2010.5648121
   Dasgupta A, 2013, INT J ADV ENG SCI AP, V5, P94, DOI 10.1007/s12572-013-0086-2
   Daubechies I, 2011, APPL COMPUT HARMON A, V30, P243, DOI 10.1016/j.acha.2010.08.002
   de Naurois CJ, 2018, ACCIDENT ANAL PREV, V121, P118, DOI 10.1016/j.aap.2018.08.017
   Dhupati L. S., 2010, 2010 IEEE International Conference on Automation Science and Engineering (CASE 2010), P917, DOI 10.1109/COASE.2010.5584246
   DOUGLAS NJ, 1982, THORAX, V37, P840, DOI 10.1136/thx.37.11.840
   Fei J, 2010, IEEE T BIO-MED ENG, V57, P988, DOI 10.1109/TBME.2009.2032415
   Fei J, 2009, LECT NOTES COMPUT SC, V5762, P1084
   Flores MJ, 2011, IET INTELL TRANSP SY, V5, P241, DOI 10.1049/iet-its.2009.0090
   Fors C, 2018, J TRANSP SAF SECUR, V10, P72, DOI 10.1080/19439962.2016.1228092
   Friedrichs F, 2010, IEEE INT VEH SYM, P101, DOI 10.1109/IVS.2010.5548039
   Gade R, 2014, MACH VISION APPL, V25, P245, DOI 10.1007/s00138-013-0570-5
   Garbey M, 2007, IEEE T BIO-MED ENG, V54, P1418, DOI 10.1109/TBME.2007.891930
   GAULT T.R., 2010, COMPUTER VISION PATT, P1, DOI DOI 10.1109/CVPRW.2010.5544602
   González-Ortega D, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020399
   Guede-Fernández F, 2019, IEEE ACCESS, V7, P81826, DOI 10.1109/ACCESS.2019.2924481
   Harris C., 1988, ALVEY VISION C, P147151
   HODDES E, 1973, PSYCHOPHYSIOLOGY, V10, P431, DOI 10.1111/j.1469-8986.1973.tb00801.x
   Hu SY, 2009, EXPERT SYST APPL, V36, P7651, DOI 10.1016/j.eswa.2008.09.030
   Igasaki T, 2016, BIOM ENG INT C BEMIC, P1
   Igasaki T, 2015, 2015 8TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI), P189, DOI 10.1109/BMEI.2015.7401498
   Kartsch VJ, 2018, INFORM FUSION, V43, P66, DOI 10.1016/j.inffus.2017.11.005
   Kiashari SEH., 2018, Journal of Sleep Sciences, V3, P1
   Kotsiantis SB, 2007, INFORM-J COMPUT INFO, V31, P249
   Langroodi AK, 2018, SAE INT J COMMER VEH, V11, P57, DOI 10.4271/02-11-01-0005
   Lee BG, 2014, SENSORS-BASEL, V14, P17915, DOI 10.3390/s141017915
   Mahmoodi M, 2019, P I MECH ENG H, V233, P395, DOI 10.1177/0954411919831313
   McDonald AD, 2018, ACCIDENT ANAL PREV, V113, P25, DOI 10.1016/j.aap.2018.01.005
   Murthy JN, 2009, SLEEP, V32, P1521, DOI 10.1093/sleep/32.11.1521
   Murthy R, 2004, P ANN INT IEEE EMBS, V26, P1196
   Patel M, 2011, EXPERT SYST APPL, V38, P7235, DOI 10.1016/j.eswa.2010.12.028
   Pereira CB, 2015, BIOMED OPT EXPRESS, V6, P4378, DOI 10.1364/BOE.6.004378
   Philip RC, 2014, IEEE SW SYMP IMAG, P109, DOI 10.1109/SSIAI.2014.6806041
   Rahman A, 2015, 2015 NATIONAL SOFTWARE ENGINEERING CONFERENCE (NSEC), P1, DOI 10.1109/NSEC.2015.7396336
   Rezaei M, 2014, PROC CVPR IEEE, P129, DOI 10.1109/CVPR.2014.24
   Rodríguez-Ibáñez N, 2011, IEEE ENG MED BIO, P6055, DOI 10.1109/IEMBS.2011.6091496
   Rodriguez-Ibanez N, 2013, 13 MED C MED BIOL EN, P965
   Rohit F, 2017, IET INTELL TRANSP SY, V11, P255, DOI 10.1049/iet-its.2016.0183
   Sahayadhas A, 2012, SENSORS-BASEL, V12, P16937, DOI 10.3390/s121216937
   Samiee S, 2014, SENSORS-BASEL, V14, P17832, DOI 10.3390/s140917832
   Schleicher R, 2008, ERGONOMICS, V51, P982, DOI 10.1080/00140130701817062
   Tarassenko L, 2014, PHYSIOL MEAS, V35, P807, DOI 10.1088/0967-3334/35/5/807
   Tashakori Masoumeh., 2018, Journal of Sleep Sciences, V3, P45
   Tateno S, 2018, 2018 57TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P1664, DOI 10.23919/SICE.2018.8492599
   TRINDER J, 1992, J APPL PHYSIOL, V73, P2462, DOI 10.1152/jappl.1992.73.6.2462
   Wang MS, 2016, INT J AUTO TECH-KOR, V17, P165, DOI 10.1007/s12239-016-0016-y
   Wang XS, 2016, ACCIDENT ANAL PREV, V95, P350, DOI 10.1016/j.aap.2015.09.002
   Warwick B, 2015, IEEE INT CONF MOB, P585, DOI 10.1109/MASS.2015.22
   Wiegand D., 2009, Development and Evaluation of a Naturalistic Observer Rating of Drowsiness Protocol: Final Report
   Wilburta LQ, 2010, DELMARS COMPREHENSIV, P564
   Wu HY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185561
   Xie AL, 2012, J THORAC DIS, V4, P194, DOI 10.3978/j.issn.2072-1439.2011.04.04
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhen Z, 2008, IEEE 5 INT C ADV VID, V2008, P237
NR 66
TC 29
Z9 29
U1 2
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17793
EP 17815
DI 10.1007/s11042-020-08696-x
EA FEB 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516363300006
DA 2024-07-18
ER

PT J
AU Anitha, K
   Naresh, K
   Devi, DR
AF Anitha, K.
   Naresh, K.
   Devi, D. Rukmani
TI A framework to reduce category proliferation in fuzzy ARTMAP classifiers
   adopted for image retrieval using differential evolution algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy ARTMAP; Category proliferation; Differential evolution; CBIR;
   Classifier
ID NEURAL-NETWORK; RELEVANCE FEEDBACK; OPTIMIZATION
AB Image classifiers are largely adopted to categorize a pool of images or patterns in a databank, match category of a query image and to retrieve similar images to query from the category. Fuzzy ARTMAP (FAM) architecture have been widely included for pattern classification in various applications. The major constraint that limits the application of FAM network is category proliferation problem. That is the architecture has the tendency to increase the network size. The issue is because of noisy data, order of presenting training data and/or overlapping categories. In this paper, we propose a new methodology, DE-FAM to handle category proliferation problem by reducing the quantity of categories in the trained FAM architectures. The enhanced generalized performance, reduction in network size and influence of the proposed algorithm in computational cost is demonstrated by adopting the algorithm for image classification and retrieval. Furthermore the comparison of DE-FAM with other algorithms that address the category proliferation problem illustrate the advantages of DE-FAM.
C1 [Anitha, K.] Saveetha Sch Engn, Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Naresh, K.] VIT Univ, Vellore, Tamil Nadu, India.
   [Devi, D. Rukmani] Anna Univ, RMD Engn Coll, Chennai, Tamil Nadu, India.
C3 Saveetha Institute of Medical & Technical Science; Saveetha School of
   Engineering; Vellore Institute of Technology (VIT); VIT Vellore; Anna
   University; Anna University Chennai
RP Anitha, K (corresponding author), Saveetha Sch Engn, Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM anitha9k3@gmail.com; naresh.k@vit.ac.in; rdrukmani319@gmail.com
RI K, Anitha/AAV-6618-2020; Dams, ruks/V-9152-2019
OI K, Anitha/0000-0002-9569-4206; Dams, ruks/0000-0002-0153-6283; Kannan,
   Naresh/0000-0002-3106-6091
CR Al-Daraiseh A, 2007, NEURAL NETWORKS, V20, P874, DOI 10.1016/j.neunet.2007.05.006
   Anagnostopoulos GC, 2002, IEEE IJCNN, P2650, DOI 10.1109/IJCNN.2002.1007562
   Anagnostopoulos GC, 2001, THESIS
   [Anonymous], 1995, Technical Report tr-95-012
   CARPENTER GA, 1992, IEEE T NEURAL NETWOR, V3, P698, DOI 10.1109/72.159059
   Chi GX, 2018, J PHYS CONF SER, V1026, DOI 10.1088/1742-6596/1026/1/012024
   Coelho LD, 2009, CHAOS SOLITON FRACT, V42, P522, DOI 10.1016/j.chaos.2009.01.012
   Das S, 2011, IEEE T EVOLUT COMPUT, V15, P4, DOI 10.1109/TEVC.2010.2059031
   Das S, 2008, STUD COMPUT INTELL, V116, P1, DOI 10.1007/978-3-540-78297-1_1
   Dhariwal S, 2012, ADV COMPUTER SCI ENG, V167
   Gómez-Sánchez E, 2002, IEEE T NEURAL NETWOR, V13, P58, DOI 10.1109/72.977271
   Grigorova A, 2007, IEEE T MULTIMEDIA, V9, P1183, DOI 10.1109/TMM.2007.902828
   Hoi SCH, 2006, IEEE T KNOWL DATA EN, V18, P509, DOI 10.1109/TKDE.2006.1599389
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Kaburlasos VG, 2013, IEEE T NEUR NET LEAR, V24, P1526, DOI 10.1109/TNNLS.2012.2237038
   Kaylani A, 2009, NEUROCOMPUTING, V72, P2079, DOI 10.1016/j.neucom.2008.09.016
   Li J, 2006, IEEE T IMAGE PROCESS, V15, P3597, DOI 10.1109/TIP.2006.881938
   Makrushin A, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P89
   Marcek D, 2017, ACTA POLYTECH HUNG, V14, P49, DOI 10.12700/APH.14.5.2017.5.4
   Matias ALS, 2018, NEURAL NETWORKS, V98, P236, DOI 10.1016/j.neunet.2017.11.012
   Panda S, 2009, SIMUL MODEL PRACT TH, V17, P1618, DOI 10.1016/j.simpat.2009.07.002
   Pourpanah F, 2019, INT J MACH LEARN CYB, V10, P1643, DOI 10.1007/s13042-018-0843-4
   Rao T. K. R. K., 2012, 2012 IEEE 8th International Colloquium on Signal Processing & its Applications, P228, DOI 10.1109/CSPA.2012.6194723
   Saadatmand-Tarzjan M, 2007, IEEE T SYST MAN CY B, V37, P139, DOI 10.1109/TSMCB.2006.880137
   Seetharaman K, 2014, EGYPT INFORM J, V15, P59, DOI 10.1016/j.eij.2014.02.001
   Sit WY, 2009, IEEE T NEURAL NETWOR, V20, P1244, DOI 10.1109/TNN.2009.2022477
   Song Y, 2007, IEEE T NEURAL NETWOR, V18, P595, DOI 10.1109/TNN.2006.890809
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Su JH, 2011, IEEE T KNOWL DATA EN, V23, P360, DOI 10.1109/TKDE.2010.124
   Subudhi Bidyadhar, 2009, Archives of Control Sciences, V19, P59
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TAMURA H, 1984, PATTERN RECOGN, V17, P29, DOI 10.1016/0031-3203(84)90033-5
   Tong S, 2001, P ACM MULT OTT ON CA
   Verzi SJ, 2001, IEEE IJCNN, P1191, DOI 10.1109/IJCNN.2001.939530
   Williamson JR, 1996, NEURAL NETWORKS, V9, P881, DOI 10.1016/0893-6080(95)00115-8
   Yonekawa M, 2012, WCCI2012 IEEE WORLD
   Yu J, 2008, IEEE T PATTERN ANAL, V30, P451, DOI 10.1109/TPAMI.2007.70714
   Zorarpaci E, 2016, EXPERT SYST APPL, V62, P91, DOI 10.1016/j.eswa.2016.06.004
NR 38
TC 21
Z9 21
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 4217
EP 4238
DI 10.1007/s11042-019-07887-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700063
DA 2024-07-18
ER

PT J
AU Shanthakumari, R
   Malliga, S
AF Shanthakumari, R.
   Malliga, S.
TI Dual layer security of data using LSB inversion image steganography with
   elliptic curve cryptography encryption algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Embedding data; Information security; Least significant bit
   inversion; Elliptic curve cryptography
AB The steganography is a graceful tactic to convey the confidential information to an authorized recipient with the most reliable safety measure which leads to avoiding the breaches of data security. Nowadays the significance of taking strong protection measures in data communication medium has a challenging task because of the security related issues which are developed by unauthorized intervention. This presentation intends to provide a new approach based on a combination of Steganography and Cryptography procedure for inserting the hidden data into a cover object and obtain high data embedding capacity with an improved security level. In this approach, the Elliptic Curve Cryptography algorithm is used to encrypt the hidden information and the encrypted data inserted into a cover object by the process of the LSB Inversion algorithm. This blend of technology has successfully reached the benchmark level of some essential properties known as data confidentiality, integrity verification, capacity and robustness which are the evidence to prove the excellent performance and effective implementation of this steganography process. This new approach intensely tested through several steganalysis attacks such as analysis of visual, histogram, and chi-square. The outcome of the experimental result shown that the stego image has delivered the strong opposition force against all attacks. The data embedding capacity has attained at an improved level compared with typical methods.
C1 [Shanthakumari, R.] Kongu Engn Coll, Dept Informat Technol, Perundurai, India.
   [Malliga, S.] Kongu Engn Coll, Dept Comp Sci & Engn, Perundurai, India.
C3 Kongu Engineering College; Kongu Engineering College
RP Shanthakumari, R (corresponding author), Kongu Engn Coll, Dept Informat Technol, Perundurai, India.
EM shanabiraki@gmail.com
RI Malliga, S/AAL-4560-2020; R, Shanthakumari/AAL-5664-2020
OI Malliga, S/0000-0003-3263-0376; R, Shanthakumari/0000-0001-8711-0197
CR [Anonymous], INFORM MED UNLOCKED
   [Anonymous], 2018, J AMBIENT INTELL HUM
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2018, DES AUTOM EMBED SYST
   Chang CC, 2002, INT J PATTERN RECOGN, V16, P399, DOI 10.1142/S0218001402001770
   Desoky Abdelrahman, 2008, Journal of Digital Forensic Practice, V2, P132, DOI 10.1080/15567280802558818
   Kekre HB, 2009, P ACM INT C ADV COMP, P342
   Kumar PM, 2018, FUTURE GENER COMP SY, V86, P527, DOI 10.1016/j.future.2018.04.036
   Liao X, 2010, J VIS COMMUN IMAGE R, V10, P1
   Lokesh S., 2018, NEURAL COMPUT APPL, V2018, P1
   Luo XY, 2008, SIGNAL PROCESS, V88, P2138, DOI 10.1016/j.sigpro.2008.03.016
   Mandal JK, 2012, COMPUTER SCI INFORM, P93
   Parthasarathy P, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0043-3
   Shanthakumari R., 2017, ASIAN J RES SOC SCI, V7, P198, DOI DOI 10.5958/2249-7315.2017.00015.6
   Shanthakumari R., 2014, INT J COMPUT SCI ENG, V4, P400
   Shanthakumari R, 2015, INT J INNOVATIVE RES, V3
   Sharmila B, 2012, ICTACT J IMAGE VIDEO, V02
   Stluka P, 2018, ADV IND CONTROL, P11, DOI 10.1007/978-3-319-68462-8_2
   Sundarasekar R, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1093-4
   Tyagi V., 2012, J GLOBAL RES COMP SC, V3, P53
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Wu MY, 2004, PATTERN RECOGN LETT, V25, P301, DOI 10.1016/j.patrec.2003.10.013
   Yang CH, 2011, J SYST SOFTWARE, V84, P669, DOI 10.1016/j.jss.2010.11.889
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 24
TC 14
Z9 15
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3975
EP 3991
DI 10.1007/s11042-019-7584-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700049
DA 2024-07-18
ER

PT J
AU Patro, KAK
   Acharya, B
AF Patro, K. Abhimanyu Kumar
   Acharya, Bibhudendra
TI A novel multi-dimensional multiple image encryption technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; Multiple image encryption; Multi-dimensional images; PWLCM
   system; SHA-256 hash algorithm
ID ALGORITHM; CHAOS; COMPRESSION; OPERATION; SEQUENCE
AB This paper proposes a novel secure and fast multiple image encryption technique to encrypt multiple images of arbitrary sizes. In the proposed technique, a group of images is divided into non-overlapping blocks of size 2 x 2 pixels. For odd numbered image size, separate 2 x 2 sized blocks are formed from the last row and/or column pixels. The generated blocks and the remaining pixels (if any) are then arranged in separate arrays. Finally, the array of blocks and remaining pixels are separately permuted and diffused using different piece-wise linear chaotic map (PWLCM) systems. The significance of this algorithm is the use of arbitrary sized multiple images to perform multiple image encryptions. Another significance of this algorithm is the use of only PWLCM systems in permutation and diffusion operations to make the algorithm secure and efficient in both software and hardware platforms. The computer simulation reveals the good encryption results of the proposed cryptosystem. The security analysis shows that the proposed method performs better against widely known security attacks.
C1 [Patro, K. Abhimanyu Kumar; Acharya, Bibhudendra] Natl Inst Technol Raipur, Dept Elect & Commun Engn, GE Rd, Raipur, Madhya Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Acharya, B (corresponding author), Natl Inst Technol Raipur, Dept Elect & Commun Engn, GE Rd, Raipur, Madhya Pradesh, India.
EM bacharya.etc@nitrr.ac.in
RI Patro, K Abhimanyu/U-9497-2019; Patro, K./ABE-1560-2021; Patro,
   K./AAS-8530-2021
OI Patro, K Abhimanyu/0000-0001-7807-7874; Acharya,
   Bibhudendra/0000-0001-7233-7591
CR [Anonymous], 2001, ADV ENCR STAND AES
   [Anonymous], 1977, USC SIPI IMAGE DATAB
   Bouslimi D, 2012, IEEE T INF TECHNOL B, V16, P891, DOI 10.1109/TITB.2012.2207730
   Brindha M, 2016, APPL SOFT COMPUT, V40, P379, DOI 10.1016/j.asoc.2015.09.055
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Cheng H, 2000, IEEE T SIGNAL PROCES, V48, P2439, DOI 10.1109/78.852023
   COOPERSMITH D, 1994, IBM J RES DEV, V38, P243, DOI 10.1147/rd.383.0243
   Dang PP, 2000, IEEE T CONSUM ELECTR, V46, P395, DOI 10.1109/30.883383
   Gao HJ, 2006, CHAOS SOLITON FRACT, V29, P393, DOI 10.1016/j.chaos.2005.08.110
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Guesmi R, 2016, MULTIMED TOOLS APPL, V75, P4753, DOI 10.1007/s11042-015-2501-0
   Gupta AK, 2016, INFECT DRUG RESIST, V9, P1, DOI 10.2147/IDR.S61998
   He J, 2018, JPEG IMAGE ENCRYPTIO
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   IEEE Standard for Binary Floating-Point Arithmetic, 19857541985 ANSI IEE
   Joshi M, 2008, OPT COMMUN, V281, P5713, DOI 10.1016/j.optcom.2008.08.024
   Kong DZ, 2013, APPL OPTICS, V52, P2619, DOI 10.1364/AO.52.002619
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Li HJ, 2011, OPT LASER ENG, V49, P753, DOI 10.1016/j.optlaseng.2011.03.017
   Li HJ, 2008, OPT COMMUN, V281, P5745, DOI 10.1016/j.optcom.2008.09.001
   Li JH, 2013, IET INFORM SECUR, V7, P265, DOI 10.1049/iet-ifs.2012.0304
   Li YB, 2015, OPT LASER ENG, V72, P18, DOI 10.1016/j.optlaseng.2015.03.027
   Liu HJ, 2013, J SYST SOFTWARE, V86, P826, DOI 10.1016/j.jss.2012.11.026
   Liu ZJ, 2007, OPT COMMUN, V275, P324, DOI 10.1016/j.optcom.2007.03.039
   Liu ZJ, 2010, J OPT-UK, V12, DOI 10.1088/2040-8978/12/3/035407
   Liu ZJ, 2009, OPT COMMUN, V282, P518, DOI 10.1016/j.optcom.2008.10.068
   Lou YH, 2019, IEEE INT CON MULTI, P19, DOI 10.1109/ICME.2019.00012
   Mao YN, 2006, IEEE T IMAGE PROCESS, V15, P2061, DOI 10.1109/TIP.2006.873426
   Mohanty S., 2017, Indian J. Sci. Res., V14, P190
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Pan XM, 2015, APPL OPTICS, V54, P8485, DOI 10.1364/AO.54.008485
   Patro KAK, 2019, MICROSYST TECHNOL, V25, P2331, DOI 10.1007/s00542-018-4121-x
   Patro KAK, 2018, J INF SECUR APPL, V40, P111, DOI 10.1016/j.jisa.2018.03.006
   PatroKAK BA, 2017, PROCINTCONFNEXT GEN, P396
   Praveenkumar P, 2015, SECUR COMMUN NETW, V8, P3335, DOI 10.1002/sec.1257
   Rehman AU, 2019, MULTIMED TOOLS APPL, V78, P9355, DOI 10.1007/s11042-018-6516-1
   SAMHITA P, 2016, INT J CONT T APPL, V9, P17
   Shadangi V, 2017, International Journal Control Theory and Applications, V10, P93
   Singh N, 2010, OPT LASER TECHNOL, V42, P724, DOI 10.1016/j.optlastec.2009.11.016
   Sui LS, 2014, OPT LASER ENG, V56, P1, DOI 10.1016/j.optlaseng.2013.12.001
   Tang ZJ, 2016, OPT LASER ENG, V80, P1, DOI 10.1016/j.optlaseng.2015.12.004
   Tao R, 2010, IEEE T INF FOREN SEC, V5, P734, DOI 10.1109/TIFS.2010.2068289
   Wang XY, 2014, IET INFORM SECUR, V8, P213, DOI 10.1049/iet-ifs.2012.0279
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2016, NONLINEAR DYNAM, V83, P333, DOI 10.1007/s11071-015-2330-8
   Wu CP, 2005, IEEE T MULTIMEDIA, V7, P828, DOI 10.1109/TMM.2005.854469
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Xiang T, 2007, APPL MATH COMPUT, V190, P1637, DOI 10.1016/j.amc.2007.02.103
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Ye GD, 2018, NONLINEAR DYNAM, V94, P745, DOI 10.1007/s11071-018-4391-y
   Zhang J, 2014, MATH PROB ENG
   Zhang XQ, 2017, COMPUT ELECTR ENG, V62, P401, DOI 10.1016/j.compeleceng.2016.12.025
   Zhang XQ, 2017, OPT LASER ENG, V92, P6, DOI 10.1016/j.optlaseng.2016.12.005
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-2104-6
   Zhou NR, 2018, OPT LASER ENG, V110, P72, DOI 10.1016/j.optlaseng.2018.05.014
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-1902-1
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
   Zhu Wei, 2014, Journal of Nanjing University of Posts and Telecommunications, V34, P87
NR 59
TC 53
Z9 53
U1 3
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 12959
EP 12994
DI 10.1007/s11042-019-08470-8
EA JAN 2020
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000509165900009
DA 2024-07-18
ER

PT J
AU Shabanam, ST
   Udupi, VR
   Subudhi, BN
AF Shabanam, S. Tamboli
   Udupi, V. R.
   Subudhi, Badri Narayan
TI An efficient framework for increasing image quality using DRN Bi-layer
   enfolded compressor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DRN Bi-layer enfolded compressor; Lloyd's quantization; Deep residual
   network; Lossless compression; Lossy compression
ID MODE DECISION ALGORITHM
AB Lossy /lossless image compression technique results will either improve the quality of image with reduced compression ratio or degrades the image with better compression ratio. But on dealing with the combined lossy/lossless techniques, they provide the output with better image quality and high compression rate, however, the techniques failed to obtain better efficiency due to less predictive nature. Hence, to acquire an image having better compression rate with improved predictive nature, a novel framework is introduced in our proposed work. It uses a Deep Residual Network Bi-Layer Enfolded Compressor (DRN-BLEC) to enhance the image quality. In order to obtain better compression rate, the Mexican Meyer Hat Wavelet Transform (MMHWT) is used. Similarly, the well knowledge quantization is achieved by utilizing DRN for learning; it is then followed by the Lloyds quantization technique that groups the feature values by quantizing it, which in turn boost-up the resolution of the image. Consequently with DRN, the process of encoding and decoding doesn't requires to be done separately since two residual layer of the DRN are trained to encode and decode the images, which thereby reduces the time required for compression process. Thus a compressed image with high resolution is obtained without redundancy, moreover with high compression ratio. The architecture of the DRN-BLEC is implemented in MATLAB and the respective result structure is validated.
C1 [Shabanam, S. Tamboli] Ashta ADCET, Annasaheb Dange Coll Engn & Technol, Ashtasangli 416301, Maharashtra, India.
   [Udupi, V. R.] MMEC, Belgaum, Karnataka, India.
   [Subudhi, Badri Narayan] IIT, Jammu, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) Jammu
RP Shabanam, ST (corresponding author), Ashta ADCET, Annasaheb Dange Coll Engn & Technol, Ashtasangli 416301, Maharashtra, India.
EM tambolishabanams@gmail.com; udupivr213@gmail.com;
   badrinarayansubudhi213@gmail.com
RI SUBUDHI, BADRI N/B-6830-2013; Tamboli, Shabanam/E-6978-2019
OI SUBUDHI, BADRI N/0000-0002-4378-0065; 
CR Agustsson E, 2017, ADV NEUR IN, V30
   Agustsson Eirikur, 2017, IEEE CVF C COMP VIS, P126, DOI DOI 10.1109/CVPRW.2017.150
   Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   [Anonymous], 2017, CORR ABS17031
   Balle J., 2016, 5 INT C LEARNING REP
   Chen Q, 2005, LECT NOTES COMPUT SC, V3612, P490
   Cheng J, 2017, IEEE T NEUR NET LEAR, V99, P14
   Courbariaux Y., 2015, ADV NEURAL INFORM PR, P3123, DOI DOI 10.5555/2969442.2969588
   DEVORE RA, 1992, IEEE T INFORM THEORY, V38, P719, DOI 10.1109/18.119733
   Gaidhane H. Vila, 2011, J INTELLIGENT LEARNI, V3, P220, DOI DOI 10.4236/JILSA.2011.34025
   Ginesu G, 2012, SIGNAL PROCESS-IMAGE, V27, P867, DOI 10.1016/j.image.2012.01.011
   He KJ, 2018, IEEE ACCESS, V6, P32850, DOI 10.1109/ACCESS.2018.2845855
   Hou WL, 2015, IEEE T NEUR NET LEAR, V26, P1275, DOI 10.1109/TNNLS.2014.2336852
   Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082
   Jianxiong Wang, 2010, 2010 International Conference on Intelligent Computing and Cognitive Informatics (ICICCI 2010), P130, DOI 10.1109/ICICCI.2010.70
   Kundu D, 2015, IEEE IMAGE PROC, P2374, DOI 10.1109/ICIP.2015.7351227
   Li HF, 2018, PATTERN RECOGN, V79, P130, DOI 10.1016/j.patcog.2018.02.005
   Mi XC, 2005, PLANT ECOL, V179, P1, DOI 10.1007/s11258-004-5089-4
   PENG F, 2017, INT C SEC PRIV COMM, P774, DOI DOI 10.1007/978-3-319-59608
   Prakash A, 2017, IEEE DATA COMPR CONF, P250, DOI 10.1109/DCC.2017.56
   Rein SA, 2015, SIGNAL PROCESS-IMAGE, V37, P58, DOI 10.1016/j.image.2015.07.010
   Ruiz D, 2016, SIGNAL PROCESS-IMAGE, V44, P12, DOI 10.1016/j.image.2016.03.002
   Sulavko Alexey E., 2018, 2018 XIV International Scientific-Technical Conference on Actual Problems of Electronics Instrument Engineering (APEIE). Proceedings, P218, DOI 10.1109/APEIE.2018.8545676
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   Tao DP, 2018, IEEE T CIRC SYST VID, V28, P2657, DOI 10.1109/TCSVT.2017.2726580
   Theis L., 2017, ICLR
   Toderici G., 2015, ARXIV PREPRINT ARXIV
   Todeschini G, 2017, INVENTIONS-BASEL, V2, DOI 10.3390/inventions2030014
   Torfason R., 2018, P INT C LEARN REPR, P1
   Nguyen T, 2015, IEEE T CIRC SYST VID, V25, P790, DOI 10.1109/TCSVT.2014.2358000
   Wang YY, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/7943498
   Wei YC, 2017, IEEE GEOSCI REMOTE S, V14, P1795, DOI 10.1109/LGRS.2017.2736020
   Wu ST, 2018, MULTIMED TOOLS APPL, V77, P10437, DOI 10.1007/s11042-017-4440-4
   Xu FC, 2018, LECT NOTES ARTIF INT, V10956, P472, DOI 10.1007/978-3-319-95957-3_50
   Yao YB, 2016, MULTIMED TOOLS APPL, V75, P1963, DOI 10.1007/s11042-014-2382-7
   Yu J., 2018, P IEEE C COMPUTER VI
   Zhong ZL, 2018, IEEE T GEOSCI REMOTE, V56, P847, DOI 10.1109/TGRS.2017.2755542
NR 38
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12401
EP 12426
DI 10.1007/s11042-019-08227-3
EA JAN 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000507365000001
DA 2024-07-18
ER

PT J
AU Ortis, A
   Farinella, GM
   Torrisi, G
   Battiato, S
AF Ortis, Alessandro
   Farinella, Giovanni Maria
   Torrisi, Giovanni
   Battiato, Sebastiano
TI Exploiting objective text description of images for visual sentiment
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual sentiment analysis; Objective text features; Embedding spaces;
   Social media
AB This paper addresses the problem of Visual Sentiment Analysis focusing on the estimation of the polarity of the sentiment evoked by an image. Starting from an embedding approach which exploits both visual and textual features, we attempt to boost the contribution of each input view. We propose to extract and employ anObjective Textdescription of images rather than the classicSubjective Textprovided by the users (i.e., title, tags and image description) which is extensively exploited in the state of the art to infer the sentiment associated to social images.Objective Textis obtained from the visual content of the images through recent deep learning architectures which are used to classify object, scene and to perform image captioning.Objective Textfeatures are then combined with visual features in an embedding space obtained with Canonical Correlation Analysis. The sentiment polarity is then inferred by a supervised Support Vector Machine. During the evaluation, we compared an extensive number of text and visual features combinations and baselines obtained by considering the state of the art methods. Experiments performed on a representative dataset of 47235 labelled samples demonstrate that the exploitation ofObjective Texthelps to outperform state-of-the-art for sentiment polarity estimation.
C1 [Ortis, Alessandro; Farinella, Giovanni Maria; Battiato, Sebastiano] Univ Catania, Viale A Doria 6, I-95125 Catania, Italy.
   [Torrisi, Giovanni] JOL Catania Telecom Italia, Viale A Doria 6, I-95125 Catania, Italy.
C3 University of Catania
RP Ortis, A (corresponding author), Univ Catania, Viale A Doria 6, I-95125 Catania, Italy.
EM ortis@dmi.unict.it; gfarinella@dmi.unict.it;
   giovanni.torrisi@telecomitalia.it; battiato@dmi.unict.it
RI Farinella, Giovanni Maria/L-8555-2015; Battiato,
   Sebastiano/ABI-1584-2020; Battiato, Sebastiano/F-5842-2012; Ortis,
   Alessandro/P-9214-2017; Battiato, Sebastiano/O-7799-2019
OI Battiato, Sebastiano/0000-0001-6127-2470; Ortis,
   Alessandro/0000-0003-3461-4679; 
FU Telecom Italia TIM - Joint Open Lab
FX This work has been partially supported by Telecom Italia TIM - Joint
   Open Lab.
CR Ahmad K, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3199668
   [Anonymous], 2015, P 1 INT WORKSH AFF S, DOI 10.1145/2813524.2813530
   Baecchi C, 2016, MULTIMED TOOLS APPL, V75, P2507, DOI 10.1007/s11042-015-2646-x
   Battiato S, 2013, IS T SPIE ELECT IMAG, P866008
   Battiato S, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P397, DOI 10.1145/2911996.2912024
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Campos V, 2017, IMAGE VISION COMPUT, V65, P15, DOI 10.1016/j.imavis.2017.01.011
   Chen T, 2014, ARXIV14108586
   Cui P, 2018, IEEE T MULTIMEDIA, V20, P198, DOI 10.1109/TMM.2017.2724843
   DATTA R., 2006, European Conference on Computer Vision, P288, DOI DOI 10.1007/11744078_23
   Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P584, DOI 10.1007/978-3-319-10605-2_38
   Gong YC, 2014, LECT NOTES COMPUT SC, V8692, P529, DOI 10.1007/978-3-319-10593-2_35
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   GUILLAUMIN M, 2010, PROC CVPR IEEE, P902, DOI DOI 10.1109/CVPR.2010.5540120
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Huang FR, 2019, KNOWL-BASED SYST, V167, P26, DOI 10.1016/j.knosys.2019.01.019
   Hung CL, 2013, IEEE INTELL SYST, V28, P47, DOI 10.1109/MIS.2013.1
   Hwang SJ, 2012, INT J COMPUT VISION, V100, P134, DOI 10.1007/s11263-011-0494-3
   Itten J., 1962, The Art of Color; the Subjective Experience and Objective Rationale of Colour
   Johnson J, 2015, IEEE I CONF COMP VIS, P4624, DOI 10.1109/ICCV.2015.525
   Jou B, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P159, DOI 10.1145/2733373.2806246
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Katsurai M, 2016, INT CONF ACOUST SPEE, P2837, DOI 10.1109/ICASSP.2016.7472195
   Lei XJ, 2016, IEEE T MULTIMEDIA, V18, P1910, DOI 10.1109/TMM.2016.2575738
   Lemieux G, 2010, RILEM BOOKSER, V1, P25, DOI 10.1007/978-90-481-9664-7_3
   Li XR, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2906152
   Machaj J, 2010, PROCEEDINGS OF THE 20TH INTERNATIONAL CONFERENCE, RADIOELETRONIKA 2010, P83, DOI 10.1109/RADIOELEK.2010.5478585
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Ortis A, 2018, INT WORK CONTENT MUL
   Pang L, 2015, IEEE T MULTIMEDIA, V17, P2008, DOI 10.1109/TMM.2015.2482228
   Perronnin F, 2010, PROC CVPR IEEE, P2297, DOI 10.1109/CVPR.2010.5539914
   Qian SS, 2016, IEEE T MULTIMEDIA, V18, P233, DOI 10.1109/TMM.2015.2510329
   Rahimi A., 2007, NIPS, P1177
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Rudinac S, 2013, IEEE T MULTIMEDIA, V15, P1231, DOI 10.1109/TMM.2013.2261481
   Sebastiani F., 2006, P 5 INT C LANG RES E, P417, DOI DOI 10.1155/2015/715730
   Siersdorfer S., 2010, ACM MM, P715
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Thelwall M, 2010, J AM SOC INF SCI TEC, V61, P2544, DOI 10.1002/asi.21416
   VALDEZ P, 1994, J EXP PSYCHOL GEN, V123, P394, DOI 10.1037/0096-3445.123.4.394
   Wang G, 2009, PROC CVPR IEEE, P1367, DOI 10.1109/CVPRW.2009.5206816
   Wang YL, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2378
   Xu C., 2014, Visual sentiment prediction with deep convolutional neural networks
   Yang XS, 2015, IEEE T MULTIMEDIA, V17, P64, DOI 10.1109/TMM.2014.2375793
   You QZ, 2015, IEEE T MULTIMEDIA, V17, P2271, DOI 10.1109/TMM.2015.2487863
   You QZ, 2015, AAAI CONF ARTIF INTE, P381
   Yu FLX, 2013, PROC CVPR IEEE, P771, DOI 10.1109/CVPR.2013.105
   Yuan J., 2013, P 2 INT WORKSH ISS S, P1
   Yuan Z., 2013, Plane-based 3D mapping for structured indoor environment, P1
   Yuan ZQ, 2014, IEEE T MULTIMEDIA, V16, P1624, DOI 10.1109/TMM.2014.2322338
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhu XL, 2019, LECT NOTES COMPUT SC, V11295, P264, DOI 10.1007/978-3-030-05710-7_22
NR 52
TC 15
Z9 15
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22323
EP 22346
DI 10.1007/s11042-019-08312-7
EA JAN 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000574071300001
DA 2024-07-18
ER

PT J
AU Zhang, JH
   Min, XK
   Jia, J
   Zhu, ZH
   Wang, J
   Zhai, GT
AF Zhang, Jiahe
   Min, Xiongkuo
   Jia, Jun
   Zhu, Zehao
   Wang, Jia
   Zhai, Guangtao
TI Fine localization and distortion resistant detection of multi-class
   barcode in complex environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Barcode detection; Deep learning; Quadrilateral bounding box;
   Multi-scale; Spatial pyramid pooling
AB Barcode, including one-dimensional (1D) barcode and two-dimensional (2D) barcode, can be seen almost anywhere in our lives. In many barcode-based mobile systems, different barcodes will appear simultaneously with different angles, shapes, and image quality. Barcode localization is a significant prerequisite for barcode decoding in these applications. In this paper, we propose a region-based end-to-end network to finely localize and classify 1D barcode and Quick Response (QR) code in complex environments. Two special layers are designed in our network. One is a quadrilateral regression layer to localize arbitrary quadrilateral bounding boxes, and another is a Multi-scale Spatial Pyramid Pooling (MSPP) layer to improve the detection accuracy of small-scale barcodes. Extensive experiments on existing public datasets and our own dataset have verified the effectiveness of proposed layers. We also demonstrate that our method can resist some distortions by simulating barcode images of different image qualities. What's more, a human decoding experiment is also performed to prove the effectiveness of our method as a preprocessor for QR code decoding.
C1 [Zhang, Jiahe; Min, Xiongkuo; Jia, Jun; Zhu, Zehao; Wang, Jia; Zhai, Guangtao] Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Zhai, GT (corresponding author), Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai, Peoples R China.
EM zhangjiahe@sjtu.edu.cn; minxiongkuo@sjtu.edu.cn; jiajun0302@sjtu.edu.cn;
   zhuzehao@sjtu.edu.cn; jiawang@sjtu.edu.cn; zhaiguangtao@sjtu.edu.cn
RI Zhai, Guangtao/X-5949-2019; jia, jia/JKJ-5720-2023; Min,
   Xiongkuo/A-7097-2019
OI Zhai, Guangtao/0000-0001-8165-9322; Min, Xiongkuo/0000-0001-5693-0416
CR Al-Khalifa HS, 2008, LECT NOTES COMPUT SC, V5105, P1065, DOI 10.1007/978-3-540-70540-6_159
   Anezaki T., 2011, 2011 17th Korea-Japan Joint Workshop on Frontiers of Computer Vision (FCV), P1
   [Anonymous], 2012, PACIS
   [Anonymous], 2013, P 12 INT C MOBILE UB, DOI DOI 10.1145/2541831.2541844
   Ardón P, 2018, LECT NOTES COMPUT SC, V10894, P353, DOI 10.1007/978-3-319-93399-3_31
   Belussi L.F., 2011, Graphics, Patterns and Images (Sibgrapi), 2011 24th SIBGRAPI Conference on, P281
   Busta M, 2017, IEEE I CONF COMP VIS, P2223, DOI 10.1109/ICCV.2017.242
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Chang YJ, 2007, ASSETS'07: PROCEEDINGS OF THE NINTH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P231
   Dai JF, 2016, ADV NEUR IN, V29
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dubská M, 2016, J REAL-TIME IMAGE PR, V11, P193, DOI 10.1007/s11554-013-0325-6
   Ebrahim Y, 2005, CONSUM COMM NETWORK, P172
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Grósz T, 2014, IEEE INT WORKS MACH
   Hansen D.K., 2017, P INT JOINT C COMP I, P321
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hu GX, 2018, INT J DIGIT MULTIMED, V2018, DOI 10.1155/2018/4546896
   Katona M, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P307, DOI 10.1109/SITIS.2012.53
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020
   Pandya K.H., 2014, International Journal of Emerging Technology and Advanced Engineering, V4, P258
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szentandrasi I., 2012, P 28 SPRING C COMP G, P129
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wachenfeld S, 2008, INT C PATT RECOG, P583
   Walsh A., 2010, Journal of Information Literacy, V4, P55, DOI DOI 10.11645/4.1.1458
   Xu S., 2011, IEEE WORKSHOP APPL C, P159
   Zamberletti A, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P160, DOI 10.1109/ACPR.2013.17
NR 32
TC 25
Z9 26
U1 2
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16153
EP 16172
DI 10.1007/s11042-019-08578-x
EA JAN 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000574100900003
DA 2024-07-18
ER

PT J
AU Asuntha, A
   Srinivasan, A
AF Asuntha, A.
   Srinivasan, Andy
TI Deep learning for lung Cancer detection and classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lung cancer; Deep learning; Classifiers; Real-time; CNN
ID LOW-DOSE CT; NODULES; DISEASES; BENIGN
AB Lung cancer is one of the main reasons for death in the world among both men and women, with an impressive rate of about five million deadly cases per year. Computed Tomography (CT) scan can provide valuable information in the diagnosis of lung diseases. The main objective of this work is to detect the cancerous lung nodules from the given input lung image and to classify the lung cancer and its severity. To detect the location of the cancerous lung nodules, this work uses novel Deep learning methods. This work uses best feature extraction techniques such as Histogram of oriented Gradients (HoG), wavelet transform-based features, Local Binary Pattern (LBP), Scale Invariant Feature Transform (SIFT) and Zernike Moment. After extracting texture, geometric, volumetric and intensity features, Fuzzy Particle Swarm Optimization (FPSO) algorithm is applied for selecting the best feature. Finally, these features are classified using Deep learning. A novel FPSOCNN reduces computational complexity of CNN. An additional valuation is performed on another dataset coming from Arthi Scan Hospital which is a real-time data set. From the experimental results, it is shown that novel FPSOCNN performs better than other techniques.
C1 [Asuntha, A.] SRM Inst Sci & Technol, Dept Elect & Instrumentat Engn, Kattankulathur, Tamil Nadu, India.
   [Srinivasan, Andy] Valliammai Engn Coll, Dept Elect & Instrumentat Engn, Kattankulathur, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai; SRM Valliammai
   Engineering College
RP Asuntha, A (corresponding author), SRM Inst Sci & Technol, Dept Elect & Instrumentat Engn, Kattankulathur, Tamil Nadu, India.
EM asuntha.srm@gmail.com
RI Asuntha, Asuntha/AAS-7112-2021
CR Aggarwal T, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1189, DOI 10.1109/ICACCI.2015.7275773
   Akram S, 2015, J EXP THEOR ARTIF IN, V27, P737, DOI 10.1080/0952813X.2015.1020526
   Alakwaa W, 2017, INT J ADV COMPUT SC, V8, P409
   Bhuvaneswari P, 2015, PROC MAT SCI, V10, P433, DOI 10.1016/j.mspro.2015.06.077
   Brown A, 2018, WIRELESS PERS COMMUN, V98, P2427, DOI [10.1007/s11277-017-4981-x, DOI 10.1007/S11277-017-4981-X]
   Chabat F, 2003, RADIOLOGY, V228, P871, DOI 10.1148/radiol.2283020505
   da Silva GLF, 2017, MULTIMED TOOLS APPL, V76, P19039, DOI 10.1007/s11042-017-4480-9
   de Carvalho AO, 2017, J SIGNAL PROCESS SYS, V87, P179, DOI 10.1007/s11265-016-1134-5
   Costa RWD, 2018, MED BIOL ENG COMPUT, V56, P2125, DOI 10.1007/s11517-018-1841-0
   Dhaware BU, 2016, 2016 INTERNATIONAL CONFERENCE ON AUTOMATIC CONTROL AND DYNAMIC OPTIMIZATION TECHNIQUES (ICACDOT), P170, DOI 10.1109/ICACDOT.2016.7877572
   Dong DY, 2008, J IRON STEEL RES INT, V15, P5, DOI 10.1016/S1006-706X(08)60116-8
   Hui Chen, 2010, Academic Radiology, V17, P595, DOI 10.1016/j.acra.2009.12.009
   Ignatious Sruthi, 2015, Proceedings of 2015 Global Conference on Communication Technologies (GCCT), P555, DOI 10.1109/GCCT.2015.7342723
   Jin XY, 2016, INT SYM COMPUT INTEL, P202, DOI [10.1109/ISCID.2016.52, 10.1109/ISCID.2016.1053]
   Kumar D, 2015, 2015 12TH CONFERENCE ON COMPUTER AND ROBOT VISION CRV 2015, P133, DOI 10.1109/CRV.2015.25
   Li XX, 2018, IET IMAGE PROCESS, V12, P1253, DOI 10.1049/iet-ipr.2016.1014
   Makaju S, 2018, PROCEDIA COMPUT SCI, V125, P107, DOI 10.1016/j.procs.2017.12.016
   Mary NAB, 2019, MULTIMED TOOLS APPL, V78, P11387, DOI 10.1007/s11042-018-6673-2
   Mary NAB, 2018, WIRELESS PERS COMMUN, V98, P2427, DOI 10.1007/s11277-017-4981-x
   Mary NAB, 2017, J VIS COMMUN IMAGE R, V49, P225, DOI 10.1016/j.jvcir.2017.09.008
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Orozco HM, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0003-y
   Orozco HM, 2012, INT C INF SCI SIGN P
   Park SC, 2011, PHYS MED BIOL, V56, P1139, DOI 10.1088/0031-9155/56/4/016
   Roy TS, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P1204, DOI 10.1109/CCAA.2015.7148560
   Sangamithraa Govindaraju, 2016, LUNG TUMOUR DETECTIO
   Shao H, 2012, IEEE 2 INT C COMP SC
   Silva Giovanni Lucca França da, 2016, Res. Biomed. Eng., V32, P263, DOI 10.1590/2446-4740.04615
   Song QZ, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/8314740
   Sun WQ, 2015, PROC SPIE, V9785, DOI 10.1117/12.2216307
   Suzuki K, 2005, IEEE T MED IMAGING, V24, P1138, DOI 10.1109/TMI.2005.852048
   Tian DP, 2009, FIRST IITA INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P263, DOI 10.1109/JCAI.2009.50
   van Ginneken B, 2015, I S BIOMED IMAGING, P286, DOI 10.1109/ISBI.2015.7163869
   Zhang L, 2017, IEEE T CYBERNETICS, V47, P3243, DOI 10.1109/TCYB.2016.2588526
   Zhang LF, 2015, PATTERN RECOGN, V48, P3102, DOI 10.1016/j.patcog.2014.12.016
   Zhou ZH, 2002, ARTIF INTELL MED, V24, P25, DOI 10.1016/S0933-3657(01)00094-X
   Zhu YJ, 2010, J DIGIT IMAGING, V23, P51, DOI 10.1007/s10278-009-9185-9
NR 38
TC 105
Z9 105
U1 0
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7731
EP 7762
DI 10.1007/s11042-019-08394-3
EA JAN 2020
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000505356600016
DA 2024-07-18
ER

PT J
AU Chandra, SK
   Bajpai, MK
AF Chandra, Saroj Kumar
   Bajpai, Manish Kumar
TI Brain tumor detection and segmentation using mesh-free super-diffusive
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alternating direction implicit; Fractional diffusion; Fractional
   calculus; Brain tumor detection; Mesh-free
ID EDGE-DETECTION; EFFICIENT; ALGORITHM
AB Brain tumor detection and segmentation is a complex and challenging task in image processing. Most of the techniques used for brain tumor detection and segmentation in the early stage are failed to locate a tumor region accurately. In order to get higher performance, a partial differential equation has been designed and has been used in tumor detection and segmentation. However, these methods take more time due to processing of mesh. In this manuscript, a mesh-free fractional partial differential equation based super-diffusive model is being proposed. The model enables to choose an arbitrary order of spatial derivative which enables to locate tumor region more accurately in the early stage. A mesh-free approach has been used to solve the proposed model to remove the dependency on the mesh. Qualitative and quantitative analysis have been done to verify the claim in early stage detection and segmentation of brain tumor. It has been found that the proposed model is efficient in solving super-diffusive process and is able to extract tumor region more accurately than state-of-the-art methods.
C1 [Chandra, Saroj Kumar; Bajpai, Manish Kumar] Indian Inst Informat Technol Design & Mfg, Comp Sci & Engn, Jabalpur, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur
RP Chandra, SK (corresponding author), Indian Inst Informat Technol Design & Mfg, Comp Sci & Engn, Jabalpur, India.
EM sarojkumarchandra@iiitdmj.ac.in
RI Chandra, Saroj Kumar/AAH-1933-2022; Bajpai, Manish Kumar/K-7915-2015;
   Chandra, Saroj Kumar/AFL-9755-2022
OI Bajpai, Manish Kumar/0000-0003-2258-2390; chandra, saroj
   kumar/0000-0002-2317-4498
CR Abdel-Maksoud E, 2015, EGYPT INFORM J, V16, P71, DOI 10.1016/j.eij.2015.01.003
   Al-Naami B, 2011, J MED SYST, V35, P463, DOI 10.1007/s10916-009-9382-6
   [Anonymous], 2004, APPL PARTIAL DIFFERE
   [Anonymous], 2014, BRAIN TUMOR DETECTIO
   [Anonymous], 2013, FRACTIONAL DERIVATIV
   [Anonymous], 2008, J EC
   Aslam A, 2015, PROCEDIA COMPUT SCI, V58, P430, DOI 10.1016/j.procs.2015.08.057
   Bai J, 2007, IEEE T IMAGE PROCESS, V16, P2492, DOI 10.1109/TIP.2007.904971
   Bonacina L, 2016, J MED ULTRASOUND, V24, P142, DOI 10.1016/j.jmu.2016.08.003
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Chandra SK, 2018, IEEE INT ADV COMPUT, P344, DOI 10.1109/IADCC.2018.8692094
   Chandra SK, 2018, TENCON IEEE REGION, P2408, DOI 10.1109/TENCON.2018.8650163
   Gao CB, 2011, IET IMAGE PROCESS, V5, P261, DOI 10.1049/iet-ipr.2009.0409
   Gonzalez Rafael C., 2014, DIGITAL IMAGE PROCES
   Gordillo N, 2013, MAGN RESON IMAGING, V31, P1426, DOI 10.1016/j.mri.2013.05.002
   Hasan AM, 2016, SYMMETRY-BASEL, V8, DOI 10.3390/sym8110132
   Kashyap KL, 2018, MULTIMED TOOLS APPL, V77, P9249, DOI 10.1007/s11042-017-4751-5
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   Kreyszig E., 2009, Advanced engineering mathematics
   Menze B, 2014, IEEE Transactions on Medical Imaging, V33
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Polak M, 2009, IMAGE VISION COMPUT, V27, P1223, DOI 10.1016/j.imavis.2008.09.008
   Qin JG, 2010, APPL MATH MODEL, V34, P890, DOI 10.1016/j.apm.2009.07.006
   SHEPP LA, 1974, IEEE T NUCL SCI, VNS21, P21, DOI 10.1109/TNS.1974.6499235
   Vezzetti E, 2015, IMAGE ANAL STEREOL, V35
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   Weickert J, 2002, COMPUT SUPPEMENT, V11, P221
   Wright N, 2006, SUBST ABUSE TREAT PR, V1, DOI 10.1186/1747-597X-1-28
   Zhao CJ, 2005, PATTERN RECOGN LETT, V26, P581, DOI 10.1016/j.patrec.2004.09.022
NR 31
TC 6
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2653
EP 2670
DI 10.1007/s11042-019-08374-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NR2LJ
UT WOS:000571393900001
DA 2024-07-18
ER

PT J
AU Dong, YY
   Yang, WK
   Wang, JW
   Zhao, ZJ
   Wang, SH
   Cui, Q
   Qiang, Y
AF Dong, Yunyun
   Yang, Wenkai
   Wang, Jiawen
   Zhao, Zijuan
   Wang, Sanhu
   Cui, Qiang
   Qiang, Yan
TI An improved supervoxel 3D region growing method based on PET/CT
   multimodal data for segmentation and reconstruction of GGNs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal data; Supervoxel; Fuzzy connectivity map; Region growing
ID PULMONARY-NODULES; LUNG NODULES; CT IMAGES; FUZZY-CONNECTEDNESS; TUMOR
   SEGMENTATION; DEFORMABLE MODEL; ALGORITHM; VOLUME; CLASSIFICATION;
   DEFINITION
AB Among the various types of lung nodules, ground glass nodules (GGNs) are difficult to segment accurately due to complex morphological characteristics. Moreover, GGNs are associated with a higher malignancy probability. Three-dimensional (3D) segmentation and reconstruction techniques can help physicians intuitively elucidate the relationship between lung nodules and their surrounding tissues. We propose an improved supervoxel 3D region growing approach based on positron emission tomography/computed tomography (PET/CT) multimodal data for the segmentation and reconstruction of GGNs. First, the seed point is automatically located with PET information and a 3D mask is generated. Then, a fuzzy connectivity (FC) map is generated based on the 3D mask, and an improved supervoxel 3D region growing is utilized on a fuzzy connectivity map under the constraints of the 3D mask. Finally, 3D GGNs segmentation and reconstruction results are obtained. Qualitative and quantitative comparisons between our proposed method and other region growing methods shows great superiority of our proposed method, with the Jaccard similarity coefficient between our proposed method and physician manual segmentation reaching 95.61%; the average processing time is 16.38 s. Experimental results show that our proposed supervoxel-based 3D region growing method is very promising for assisting physicians in diagnosis.
C1 [Dong, Yunyun; Yang, Wenkai; Wang, Jiawen; Zhao, Zijuan; Cui, Qiang; Qiang, Yan] Taiyuan Univ Technol, Coll Informat & Comp, Taiyuan 030024, Peoples R China.
   [Wang, Sanhu] Lvliang Univ, Dept Comp Sci & Technol, Lvliang 033000, Peoples R China.
C3 Taiyuan University of Technology; Lvliang University
RP Qiang, Y (corresponding author), Taiyuan Univ Technol, Coll Informat & Comp, Taiyuan 030024, Peoples R China.
EM qiangyan@tyut.edu.cn
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Al-Ayyoub M, 2018, MULTIMED TOOLS APPL, V77, P4939, DOI 10.1007/s11042-016-4218-0
   AlZu'bi S., 2018, MULTIMED TOOLS APPL, P1, DOI DOI 10.1007/S11042-020-08676-1
   [Anonymous], INT J PERFORMABILITY
   [Anonymous], DIGITAL IMAGE PROCES
   [Anonymous], MED IMAGING 2013 COM
   [Anonymous], SOLITARY LUNG NODULE
   [Anonymous], 2008, MIDAS J, DOI DOI 10.54294/ROFIBW
   [Anonymous], RES SUPERVOXEL BASED
   Aokage K, 2017, JPN J CLIN ONCOL, V47, P7, DOI 10.1093/jjco/hyw148
   Badura P, 2014, COMPUT BIOL MED, V53, P230, DOI 10.1016/j.compbiomed.2014.08.005
   Bellotti R, 2007, MED PHYS, V34, P4901, DOI 10.1118/1.2804720
   Cascio D, 2012, COMPUT BIOL MED, V42, P1098, DOI 10.1016/j.compbiomed.2012.09.002
   Chang HH, 2009, NEUROIMAGE, V47, P122, DOI 10.1016/j.neuroimage.2009.03.068
   Charbonnier JP, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-017-19101-3
   Conze PH, 2017, INT J COMPUT ASS RAD, V12, P223, DOI 10.1007/s11548-016-1493-1
   del Fresno M, 2009, COMPUT MED IMAG GRAP, V33, P369, DOI 10.1016/j.compmedimag.2009.03.002
   Diciotti S, 2008, IEEE T INF TECHNOL B, V12, P7, DOI 10.1109/TITB.2007.899504
   Fabbri R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1322432.1322434
   Feng Y., 2019, Journal of Ambient Intelligence and Humanized Computing, P1
   Fu GH, 2018, 2018 INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY ROBOTICS (ICT-ROBOT)
   Hansell DM, 2008, RADIOLOGY, V246, P697, DOI 10.1148/radiol.2462070712
   Harati V, 2011, COMPUT BIOL MED, V41, P483, DOI 10.1016/j.compbiomed.2011.04.010
   Huang S, 2018, PROC SPIE, V10575, DOI 10.1117/12.2293217
   Hullebrand M., 2011, Bildverarbeitung fur die Medizin 2011, ed, P3
   Hussein S, 2017, IEEE T MED IMAGING, V36, P734, DOI 10.1109/TMI.2016.2636188
   Irving B, 2014, LECT NOTES COMPUT SC, V8673, P609
   Jacobs C, 2015, INVEST RADIOL, V50, P168, DOI 10.1097/RLI.0000000000000121
   Jung J, 2018, COMPUT BIOL MED, V92, P128, DOI 10.1016/j.compbiomed.2017.11.013
   Kadkhodaei M, 2016, IEEE ENG MED BIO, P5945, DOI 10.1109/EMBC.2016.7592082
   Kim YJ, 2016, HEALTHC INFORM RES, V22, P305, DOI 10.4258/hir.2016.22.4.305
   Li GB, 2007, I C WIREL COMM NETW, P3067
   Li Q, 2008, ACAD RADIOL, V15, P165, DOI 10.1016/j.acra.2007.09.018
   Lian CF, 2019, IEEE T IMAGE PROCESS, V28, P755, DOI 10.1109/TIP.2018.2872908
   Liu H, 2018, SOFT COMPUT, V22, P3983, DOI 10.1007/s00500-017-2608-5
   Lloréns R, 2012, COMPUT METH PROG BIO, V108, P832, DOI 10.1016/j.cmpb.2012.05.014
   Lu HM, 2018, MOBILE NETW APPL, V23, P1669, DOI 10.1007/s11036-018-1111-2
   Mercieca S, 2018, RADIOTHER ONCOL, V129, P227, DOI 10.1016/j.radonc.2018.06.028
   Mukhopadhyay S, 2016, J DIGIT IMAGING, V29, P86, DOI 10.1007/s10278-015-9801-9
   Piert M, 2018, EJNMMI RES, V8, DOI 10.1186/s13550-018-0377-5
   Revol-Muller C, 2002, PATTERN RECOGN LETT, V23, P137, DOI 10.1016/S0167-8655(01)00116-7
   Rose JL, 2008, I S BIOMED IMAGING, P967, DOI 10.1109/ISBI.2008.4541159
   Saha PK, 2001, COMPUT VIS IMAGE UND, V83, P275, DOI 10.1006/cviu.2001.0927
   Siegel R, 2013, CA-CANCER J CLIN, V63, P11, DOI 10.3322/caac.21166
   Sun MJ, 2015, INT CONF WIRE COMMUN
   Sun XJ, 2006, ACAD RADIOL, V13, P670, DOI 10.1016/j.acra.2006.02.039
   Tian ZQ, 2015, PROC SPIE, V9413, DOI 10.1117/12.2082255
   Tong YB, 2017, PROC SPIE, V10137, DOI 10.1117/12.2254968
   Tu XG, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-08040-8
   Udupa JK, 1996, GRAPH MODEL IM PROC, V58, P246, DOI 10.1006/gmip.1996.0021
   Wang HZ, 2013, LECT NOTES COMPUT SC, V8151, P535, DOI 10.1007/978-3-642-40760-4_67
   Werner MK, 2009, AM J ROENTGENOL, V193, P1640, DOI 10.2214/AJR.09.2516
   Wu WW, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/9093721
   Xi T, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0111126
   Xie YT, 2018, INFORM FUSION, V42, P102, DOI 10.1016/j.inffus.2017.10.005
   Xu WN, 2017, NUCL MED COMMUN, V38, P259, DOI 10.1097/MNM.0000000000000641
   Yau H T., 2008, Computer-Aided Design and Applications, V5, P743
   Zhang W, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184290
   Zhao JJ, 2018, INT J BIO-INSPIR COM, V11, P54, DOI 10.1504/IJBIC.2018.090097
NR 59
TC 3
Z9 5
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2309
EP 2338
DI 10.1007/s11042-019-08250-4
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000515433000026
DA 2024-07-18
ER

PT J
AU Barani, MJ
   Ayubi, P
   Valandar, MY
   Irani, BY
AF Jafari Barani, Milad
   Ayubi, Peyman
   Yousefi Valandar, Milad
   Yosefnezhad Irani, Behzad
TI A blind video watermarking algorithm robust to lossy video compression
   attacks based on generalized Newton complex map and contourlet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video watermarking; Newton complex map; Contourlet transform; Singular
   value decomposition
ID MULTIPURPOSE IMAGE WATERMARKING; DIGITAL WATERMARKING; SCHEME; SVD;
   DOMAIN; DECOMPOSITION; PROTECTION; FEATURES; DCT
AB The rapid growth of fast communication networks for digital video transmission has created a need to copyright protection for these media. Digital video can be manipulated easily by users with various motivations. Compression is the most common attack that users can apply on videos in order to eliminate digital video copyright. Proposed technique in this article is specially designed for resisting against compression attacks. This method is presented a blind and robust watermarking method to copyright protection in digital video. In the proposed method, the coefficients of the contourlet transform are extracted and then encrypted watermark embedded into video with using the singular value decomposition (SVD). Embedding watermark in SVD domain increases the robustness of proposed method against attacks. In the embedding process and watermark encryption, pseudo-random numbers generated by the proposed new chaotic map, which is a generalized two-dimensional complex map based on the Newton model. The PSNR, SSIM, BER, and NCC measures examine the performance of the proposed method in terms of robustness and visual quality.
C1 [Jafari Barani, Milad; Yousefi Valandar, Milad] Islamic Azad Univ, Urmia Branch, Young Researchers & Elite Club, Orumiyeh, Iran.
   [Ayubi, Peyman; Yosefnezhad Irani, Behzad] Islamic Azad Univ, Urmia Branch, Dept Comp Engn, Orumiyeh, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Barani, MJ (corresponding author), Islamic Azad Univ, Urmia Branch, Young Researchers & Elite Club, Orumiyeh, Iran.
EM milad.jafare@gmail.com; p.ayubi@iaurmia.ac.ir;
   milad_yousefi@hotmail.com; b.yousefnezhad@iaurmia.ac.ir
RI Ayubi, Peyman/Q-3006-2019; Barani, Milad Jafari/AAE-4503-2019; Valandar,
   Milad/AAD-4670-2019
OI Ayubi, Peyman/0000-0002-2765-6224; Barani, Milad
   Jafari/0000-0002-9631-9889; Valandar, Milad/0000-0003-3637-9262
CR Agilandeeswari L, 2016, MULTIMED TOOLS APPL, V75, P8745, DOI 10.1007/s11042-015-2789-9
   Al-Maweri NAAS, 2017, MULTIMED TOOLS APPL, V76, P16239, DOI 10.1007/s11042-016-3906-0
   Alenizi F, 2015, IEEE I C ELECT CIRC, P41, DOI 10.1109/ICECS.2015.7440244
   [Anonymous], 2011, P INT C COMP VIS ICC
   [Anonymous], 2009, IEEE C COMP VIS PATT
   Ansari IA, 2017, PATTERN RECOGN LETT, V94, P228, DOI 10.1016/j.patrec.2016.12.010
   Asikuzzaman M, 2012, INT C DIG IM COMP TE, P1
   Bahrami Z, 2018, MULTIMED TOOLS APPL, V77, P327, DOI 10.1007/s11042-016-4226-0
   Barani MJ, 2015, SECUR COMMUN NETW, V8, P4343, DOI 10.1002/sec.1365
   Barati M, 2015, INT C ULTRA MOD TELE, P1, DOI 10.1109/ICUMT.2015.7382395
   Bayoudh I., 2017, MULTIMED TOOLS APPL, P1
   Bhardwaj SK, 2017, 2017 IEEE INTERNATIONAL WIE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (IEEE WIECON-ECE 2017), P1, DOI 10.1109/WIECON-ECE.2017.8468927
   Chen L, 2018, MULTIMED TOOLS APPL, V77, P7187, DOI 10.1007/s11042-017-4628-7
   Chen L, 2017, SIGNAL PROCESS-IMAGE, V54, P56, DOI 10.1016/j.image.2017.02.011
   Chen L, 2015, MED IMAGE ANAL, V23, P1, DOI 10.1016/j.media.2015.03.004
   Cox IJ., 2007, DIGITAL WATERMARKING
   El'Arbi M, 2011, MULTIMED TOOLS APPL, V55, P579, DOI 10.1007/s11042-010-0580-5
   Fan MQ, 2018, SIGNAL PROCESS-IMAGE, V66, P19, DOI 10.1016/j.image.2018.04.003
   Farri E, 2018, NONLINEAR DYNAM, P1
   Foundation X, 2018, XIPH ORG VIDEO TEST
   Furht B, 1998, HDB INTERNET MULTIME, V6
   Gaj S, 2017, MULTIMED TOOLS APPL, V76, P20755, DOI 10.1007/s11042-016-3961-6
   Goldberger AL, 1996, LANCET, V347, P1312, DOI 10.1016/S0140-6736(96)90948-4
   Hasnaoui M, 2014, SIGNAL PROCESS-IMAGE, V29, P107, DOI 10.1016/j.image.2013.07.007
   Himeur Y, 2018, MULTIMED TOOLS APPL, V77, P17309, DOI 10.1007/s11042-017-5307-4
   Huang HY, 2010, IEEE T INF FOREN SEC, V5, P625, DOI 10.1109/TIFS.2010.2080675
   Hubbard J, 2001, INVENT MATH, V146, P1, DOI 10.1007/s002220100149
   Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028
   Jiang XM, 2013, MULTIMED TOOLS APPL, V62, P545, DOI 10.1007/s11042-011-0857-3
   Jiang YG, 2018, IEEE T PATTERN ANAL, V40, P352, DOI 10.1109/TPAMI.2017.2670560
   Karmakar A, 2016, J KING SAUD UNIV-COM, V28, P199, DOI 10.1016/j.jksuci.2014.06.019
   KLEMA VC, 1980, IEEE T AUTOMAT CONTR, V25, P164, DOI 10.1109/TAC.1980.1102314
   Lian S., 2008, Multimedia Content Encryption: Techniques And Applications
   Lin SD, 2000, IEEE T CONSUM ELECTR, V46, P415, DOI 10.1109/30.883387
   Liu H, 2016, SIGNAL PROCESS-IMAGE, V45, P41, DOI 10.1016/j.image.2016.04.002
   Liu XY, 2017, SIGNAL PROCESS-IMAGE, V54, P140, DOI 10.1016/j.image.2017.03.002
   Liu Y, 2010, SIGNAL PROCESS, V90, P626, DOI 10.1016/j.sigpro.2009.08.001
   Lu ZM, 2005, IEEE T IMAGE PROCESS, V14, P822, DOI 10.1109/TIP.2005.847324
   Madine F, 2018, SIGNAL PROCESS-IMAGE, V68, P229, DOI 10.1016/j.image.2018.06.015
   Mandelbrot B B, 1982, FRACTAL GEOMETRY NAT, V1
   Mansouri A, 2010, IEEE T INF FOREN SEC, V5, P649, DOI 10.1109/TIFS.2010.2076280
   Masoumi M, 2013, AEU-INT J ELECTRON C, V67, P528, DOI 10.1016/j.aeue.2012.11.009
   Najafi E, 2019, J INF SECUR APPL, V44, P144, DOI 10.1016/j.jisa.2018.12.002
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   O'Keeffe GS, 2011, PEDIATRICS, V127, P800, DOI 10.1542/peds.2011-0054
   Pantiukhin D., 2017, 2017 3 INT C COMP IN, P1
   Podilchuk CI, 2001, IEEE SIGNAL PROC MAG, V18, P33, DOI 10.1109/79.939835
   Poonam, 2018, Procedia Computer Science, V132, P1441, DOI 10.1016/j.procs.2018.05.076
   Preda RO, 2010, MEASUREMENT, V43, P1720, DOI 10.1016/j.measurement.2010.07.009
   Seitz J., 2005, DIGITAL WATERMARKING
   Shao ZH, 2016, SIGNAL PROCESS-IMAGE, V48, P12, DOI 10.1016/j.image.2016.09.001
   Singh KS, 2019, METEOROL ATMOS PHYS, V131, P11, DOI [10.1080/10426914.2017.1291955, 10.1007/s00703-017-0552-7]
   Song HH, 2008, SIGNAL PROCESS-IMAGE, V23, P162, DOI 10.1016/j.image.2008.01.005
   Su PC, 2017, J VIS COMMUN IMAGE R, V42, P161, DOI 10.1016/j.jvcir.2016.11.018
   Tekalp A. M., 2015, Digital Video Processing, V2nd
   Thind DK, 2015, PROCEDIA COMPUT SCI, V46, P1661, DOI 10.1016/j.procs.2015.02.104
   Valandar MY, 2017, J INF SECUR APPL, V34, P142, DOI 10.1016/j.jisa.2017.04.004
   Valandar MY, 2018, MULTIMED TOOLS APPL, P1
   Wang YW, 2002, IEEE T IMAGE PROCESS, V11, P77, DOI 10.1109/83.982816
   Wu CH, 2011, AEU-INT J ELECTRON C, V65, P27, DOI 10.1016/j.aeue.2010.02.003
   Wu D, 2009, SOFT COMPUT, V13, P375, DOI 10.1007/s00500-008-0328-6
   Xu D, 2007, P ANN INT IEEE EMBS, P994
   Xu DW, 2011, SIGNAL PROCESS-IMAGE, V26, P267, DOI 10.1016/j.image.2011.04.008
   Yadav Jyotsna, 2018, Procedia Computer Science, V132, P863, DOI 10.1016/j.procs.2018.05.098
   Yassin NI, 2014, ALEX ENG J, V53, P833, DOI 10.1016/j.aej.2014.07.008
NR 65
TC 35
Z9 36
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2127
EP 2159
DI 10.1007/s11042-019-08225-5
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000515433000020
DA 2024-07-18
ER

PT J
AU Zhang, J
   He, FZ
   Chen, YL
AF Zhang, Jian
   He, Fazhi
   Chen, Yilin
TI A new haze removal approach for sky/river alike scenes based on external
   and internal clues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image haze removal; Dark channel; Sky and river alike areas
ID IMAGE QUALITY ASSESSMENT; COLOR TRANSFER; ALGORITHM; SIMPLIFICATION;
   FRAMEWORK; WEATHER; MODEL
AB Sky/river alike areas are important parts of natural scenes. The haze of these areas will impact the vividness of natural scenes. More serious, once the haze occurs in navigation of flight and ship, it will threaten the safety. However, previous researches did not dehaze well for these areas. In this paper, a new haze removal approach is presented to improve the dehazing effect for the sky/river alike areas based on our new discovers. Inspired by the two discovers, we define two theoretical clues: the external boundary clue and the internal clue. And then a correction model is constructed to correct the dark channel values in the sky/river alike areas. Finally, an optimization solution is presented to solve this model. Both the visual experiment and the quantitative experiment show that proposed method outperforms the classical dark channel method and the deep learning method in sky/river alike areas.
C1 [Zhang, Jian; He, Fazhi; Chen, Yilin] Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China.
   [Zhang, Jian] Wuhan Sports Univ, Coll Sport Engn & Informat Technol, Wuhan, Peoples R China.
C3 Wuhan University; Wuhan Sports University
RP He, FZ (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China.
EM fzhe@whu.edu.cn
RI He, Fazhi/Q-3691-2018
CR Alajarmeh A, 2018, MULTIMED TOOLS APPL, V77, P26315, DOI 10.1007/s11042-018-5861-4
   Ancuti Codruta O., 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P501, DOI 10.1007/978-3-642-19309-5_39
   [Anonymous], 2014, P 31 INT C INT C MAC
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chambers A, 2011, IEEE INT C INT ROBOT, P227, DOI 10.1109/IROS.2011.6048799
   Chaudhury KN, 2013, IEEE T IMAGE PROCESS, V22, P1291, DOI 10.1109/TIP.2012.2222903
   Chen X, 2019, MULTIMED TOOLS APPL, V78, P11173, DOI 10.1007/s11042-018-6690-1
   Cheng Z, 2017, IJCAI, P3748
   Ding M, 2013, SCI CHINA INFORM SCI, V56, DOI 10.1007/s11432-012-4566-y
   Djenouri Y, 2019, INFORM SCIENCES, V496, P326, DOI 10.1016/j.ins.2018.06.060
   Fan X, 2017, IEEE T CIRC SYST VID, V27, P2505, DOI 10.1109/TCSVT.2016.2592328
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Feng C, 2013, IEEE IMAGE PROC, P2363, DOI 10.1109/ICIP.2013.6738487
   Fu YP, 2018, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2018.00488
   Gao Z, 2018, J VIS COMMUN IMAGE R, V56, P305, DOI 10.1016/j.jvcir.2018.10.007
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He LL, 2018, MULTIMED TOOLS APPL, V77, P30035, DOI 10.1007/s11042-018-5947-z
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hou N, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-8184-3
   Kim H, 2017, MULTIMED TOOLS APPL, V76, P15867, DOI 10.1007/s11042-016-3881-5
   Kwon S, 2017, INT J ADV MANUF TECH, V88, P1831, DOI 10.1007/s00170-016-8937-1
   Kwon S, 2015, COMPUT AIDED DESIGN, V59, P140, DOI 10.1016/j.cad.2014.03.003
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li HR, 2019, APPL MATH SER B, V34, P1, DOI 10.1007/s11766-019-3706-1
   Li HR, 2020, SOFT COMPUT, V24, P6851, DOI 10.1007/s00500-019-04324-5
   Li K, 2019, FRONT COMPUT SCI-CHI, V13, P1116, DOI 10.1007/s11704-018-6442-4
   Luo JK, 2020, INTELL DATA ANAL, V24, P581, DOI 10.3233/IDA-194641
   Makarau A, 2014, IEEE T GEOSCI REMOTE, V52, P5895, DOI 10.1109/TGRS.2013.2293662
   McCartney E.J., 1976, Optics of the atmosphere: Scattering by molecules and particles, P421
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Narasimhan SG, 2001, PROC CVPR IEEE, P186
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Pan YT, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-8123-3
   Pan YT, 2019, NEUROCOMPUTING, V332, P137, DOI 10.1016/j.neucom.2018.12.025
   Pei SC, 2012, IEEE IMAGE PROC, P957, DOI 10.1109/ICIP.2012.6467020
   Provenzi E, 2005, J OPT SOC AM A, V22, P2613, DOI 10.1364/JOSAA.22.002613
   Raikwar SC, 2018, MULTIMED TOOLS APPL, V77, P19719, DOI 10.1007/s11042-017-5398-y
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Singh D, 2018, MULTIMED TOOLS APPL, V77, P27363, DOI 10.1007/s11042-018-5924-6
   Sun J, 2016, APPL MATH SER B, V31, P177, DOI 10.1007/s11766-016-3378-z
   Tan HL, 2017, MULTIMED TOOLS APPL, V76, P23413, DOI 10.1007/s11042-016-4036-4
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Wang MH, 2018, MULTIMED TOOLS APPL, V77, P11259, DOI 10.1007/s11042-017-5518-8
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Xiao CX, 2012, VISUAL COMPUT, V28, P713, DOI 10.1007/s00371-012-0679-y
   Xu K, 2012, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION APPLICATIONS (ICCIA 2012), P663
   Yan QA, 2017, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2017.24
   Yan QA, 2016, COMPUT GRAPH FORUM, V35, P1, DOI 10.1111/cgf.12998
   Yan XH, 2018, INT J COOP INF SYST, V27, DOI 10.1142/S0218843017410015
   Yang L, 2018, IEEE T VIS COMPUT GR, V24, P1190, DOI 10.1109/TVCG.2017.2657766
   Yong JS, 2019, APPL MATH SER B, V34, P480, DOI 10.1007/s11766-019-3714-1
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Zhang SD, 2020, VISUAL COMPUT, V36, P305, DOI 10.1007/s00371-018-1612-9
   Zhou Y, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-015-0594-2
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu QS, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P2414, DOI 10.1109/ROBIO.2013.6739832
NR 64
TC 48
Z9 49
U1 1
U2 59
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2085
EP 2107
DI 10.1007/s11042-019-08399-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000515433000018
DA 2024-07-18
ER

PT J
AU Zhu, Q
   Xu, NY
   Zhang, Z
   Guan, DH
   Wang, R
   Zhang, DQ
AF Zhu, Qi
   Xu, Nuoya
   Zhang, Zheng
   Guan, Donghai
   Wang, Ran
   Zhang, Daoqiang
TI Cross-spectral palmprint recognition with low-rank canonical correlation
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Palmprint recognition; Cross-spectral recognition; Low-rank;
   Multispectral palmprint; Biometrics
ID ALGORITHM; KERNEL
AB As an important biometric trait, palmprint has been widely studied in individual identification. With the popularity of palmprint recognition, many palmprint acquisition devices with different spectra have been designed and applied into practical application, so it is difficult to ensure that the spectra of collectors are consistent during training and testing, which leads to the challenge of cross-spectral palmprint images classification. To address this problem, this paper presents a domain adaptive method based on subspace learning, i.e., low-rank canonical correlation analysis (LRCCA). The proposed method seeks to find the common subspace of cross-spectral palmprint images and capture the low-rank structural relationships in data simultaneously. We perform the experiment on the multi-spectral palmprint dataset with 12 cross-spectral palmprint recognition tasks. The experimental results show that our method achieves the promising results in both identification and verification and outperforms the classical transfer learning methods and deep canonical component analysis (DCCA).
C1 [Zhu, Qi; Xu, Nuoya; Guan, Donghai; Wang, Ran; Zhang, Daoqiang] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 210016, Jiangsu, Peoples R China.
   [Zhu, Qi; Zhang, Daoqiang] Corroborat Innovat Ctr Novel Software Technol & I, Nanjing 210093, Jiangsu, Peoples R China.
   [Zhang, Zheng] Harbin Inst Technol, Biocomp Res Ctr, Shenzhen 518055, Guangdong, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Harbin Institute of
   Technology
RP Zhang, Z (corresponding author), Harbin Inst Technol, Biocomp Res Ctr, Shenzhen 518055, Guangdong, Peoples R China.
EM darrenzz219@gmail.com
RI Zhu, Qidan/ABG-2126-2021; Zhang, Zheng/M-6325-2014; Zhang,
   Zhang/JAX-2097-2023
OI Zhang, Zheng/0000-0003-1470-6998; 
FU National Natural Science Foundation of China [61501230, 61732006,
   61876082, 61861130366]; National Science and Technology Major Project of
   China [2018ZX10201002]
FX This work was supported in part by National Natural Science Foundation
   of China (Nos. 61501230, 61732006, 61876082 and 61861130366), and
   National Science and Technology Major Project of China (No.
   2018ZX10201002).
CR Aberni Y, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P793, DOI 10.1109/TSP.2017.8076097
   Akaho S, 2006, INT M PSYCHOM SOC, V383, P1343
   Andrew G., 2013, ICML, P1247
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Connie T, 2005, IMAGE VISION COMPUT, V23, P501, DOI 10.1016/j.imavis.2005.01.002
   De Bie T., 2003, P INT S IND COMP AN, P785
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Fei LK, 2016, NEUROCOMPUTING, V218, P264, DOI 10.1016/j.neucom.2016.08.048
   Fei LK, 2016, PATTERN RECOGN LETT, V69, P35, DOI 10.1016/j.patrec.2015.10.003
   Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368
   Ghifary M, 2014, LECT NOTES ARTIF INT, V8862, P898, DOI 10.1007/978-3-319-13560-1_76
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344
   Grey D., 1981, The Mathematical Gazette, V65, P75, DOI [10.2307/3617970, DOI 10.2307/3617970]
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hoffman J, 2014, INT J COMPUT VISION, V109, P28, DOI 10.1007/s11263-014-0719-3
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Jhuo IH, 2012, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2012.6247924
   Jiang Jing, 2007, ANN M ASS COMP LING, P264, DOI DOI 10.1145/1273496.1273558
   Kong AWK, 2004, INT C PATT RECOG, P520, DOI 10.1109/ICPR.2004.1334184
   Laadjel M, 2013, J REAL-TIME IMAGE PR, V8, P253, DOI 10.1007/s11554-011-0230-9
   Lee C, 2010, ETRI J, V32, P120, DOI 10.4218/etrij.10.0109.0425
   Li C, 2018, J SYST ARCHITECT, V88, P43, DOI 10.1016/j.sysarc.2018.05.008
   Li J, 2016, IJCAI INT JOINT C AR
   Li JJ, 2017, IEEE T CYBERNETICS, V47, P3516, DOI 10.1109/TCYB.2016.2565898
   Li JJ, 2017, IEEE T CIRC SYST VID, V27, P1700, DOI 10.1109/TCSVT.2016.2539541
   Long MS, 2016, IEEE T KNOWL DATA EN, V28, P2027, DOI 10.1109/TKDE.2016.2554549
   Lu GM, 2003, PATTERN RECOGN LETT, V24, P1463, DOI 10.1016/S0167-8655(02)00386-0
   Lu YW, 2019, IEEE T CIRC SYST VID, V29, P941, DOI 10.1109/TCSVT.2018.2822761
   Luo YT, 2016, PATTERN RECOGN, V50, P26, DOI 10.1016/j.patcog.2015.08.025
   Pan SJ, 2009, INT JOINT C ART INT
   Pinheiro PO, 2018, PROC CVPR IEEE, P8004, DOI 10.1109/CVPR.2018.00835
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Saito K, 2017, 2017 IEEE COMP SOC C, P2630
   Shi Y, 2009, KNOWL BASED SYST, V22
   Tamrakar D, 2016, J VIS COMMUN IMAGE R, V40, P432, DOI 10.1016/j.jvcir.2016.07.008
   von Bünau P, 2009, PHYS REV LETT, V103, DOI 10.1103/PhysRevLett.103.214101
   Yan K, 2016, DOMAIN ADAPTATION VI, P1
   Yang WK, 2017, MULTIMED TOOLS APPL, V76, P4491, DOI 10.1007/s11042-016-3446-7
   Yang WK, 2016, NEUROCOMPUTING, V213, P183, DOI 10.1016/j.neucom.2015.11.134
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang D, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071391
   Zhang D, 2010, IEEE T INSTRUM MEAS, V59, P480, DOI 10.1109/TIM.2009.2028772
   Zhang DZL, 2018, IEEE T NEURAL NETWOR
   Zhang L, 2017, IEEE T INSTRUM MEAS, V66, P1679, DOI 10.1109/TIM.2017.2669818
   Zhang L, 2016, IEEE T IMAGE PROCESS, V25, P1177, DOI 10.1109/TIP.2016.2516952
   Zhang L, 2015, IEEE T INSTRUM MEAS, V64, P1790, DOI 10.1109/TIM.2014.2367775
   Zhang Z, 2019, IEEE T PATTERN ANAL, V41, P1774, DOI 10.1109/TPAMI.2018.2847335
   Zhang Z, 2018, IEEE T NEUR NET LEAR, V29, P4645, DOI 10.1109/TNNLS.2017.2772264
   Zhang Z, 2018, IEEE T NEUR NET LEAR, V29, P3111, DOI 10.1109/TNNLS.2017.2712801
   Zhou YB, 2011, IEEE T INF FOREN SEC, V6, P1259, DOI 10.1109/TIFS.2011.2158423
   Zhouchen Lin YM, 2009, UILUENG092214 UIUC D, V1
NR 54
TC 14
Z9 15
U1 0
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33771
EP 33792
DI 10.1007/s11042-019-08362-x
EA DEC 2019
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000504891300001
DA 2024-07-18
ER

PT J
AU García-Pereira, I
   Portalés, C
   Gimeno, J
   Casas, S
AF Garcia-Pereira, Inma
   Portales, Cristina
   Gimeno, Jesus
   Casas, Sergio
TI A collaborative augmented reality annotation tool for the inspection of
   prefabricated buildings
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Annotations; Collaborative interaction; Prefabricated
   buildings; Inspection
ID SYSTEM; OPPORTUNITIES; VISUALIZATION; SUS
AB The inspection of prefabricated buildings involves different stages and tasks such as the collection of measurements, the visual inspection of components and the written annotation of defects. Traditionally, inspectors have documented the process, the kind of defects and the proposed correction measures in paper format, hindering the collaboration with other experts (either simultaneously or asynchronously) and the collection of other types of annotations (e.g. images, 3D elements). In this paper, we present an AR tool designed to aid inspectors during this process. The tool has many benefits, as it allows simultaneously performing a collaborative inspection, taking multitype and geolocated annotations, their monitoring and edition, and performing in situ augmented visualizations. The quantitative and qualitative user evaluation carried out with our tool in a real environment (including usability and satisfaction evaluations) shows the relevance that such a technology might bring to the field and prove that our tool is usable and fulfils most of the inspectors' expectations.
C1 [Garcia-Pereira, Inma; Portales, Cristina; Gimeno, Jesus; Casas, Sergio] Univ Valencia, Inst Robot & Informat & Commun Technol IRTIC, C Catedrat Jose Beltran 2, Valencia 46980, Spain.
C3 University of Valencia
RP García-Pereira, I (corresponding author), Univ Valencia, Inst Robot & Informat & Commun Technol IRTIC, C Catedrat Jose Beltran 2, Valencia 46980, Spain.
EM inmaculada.garcia-pereira@uv.es
RI Portalés, Cristina/K-2296-2015; Casas Yrurzum, Sergio/S-3693-2017;
   Gimeno Sancho, Jesus/M-2021-2017
OI Portalés, Cristina/0000-0002-4520-2250; Casas Yrurzum,
   Sergio/0000-0002-0396-4628; Gimeno Sancho, Jesus/0000-0002-5123-7580;
   Garcia-Pereira, Inma/0000-0001-6114-2211
FU Spanish Plan Estatal de Investigacion Cientifica y Tecnica de Innovacion
   2013-2016 [RTC-2015-4203-7]; European Commission
FX The SIRAE project (RTC-2015-4203-7) is supported by the Spanish Plan
   Estatal de Investigacion Cientifica y Tecnica de Innovacion 2013-2016
   and by the European Commission by means of FEDER funds.
CR Alam MF, 2017, J NETW COMPUT APPL, V89, P109, DOI 10.1016/j.jnca.2017.03.022
   [Anonymous], 2016, P 16 INT C KNOWL TEC
   ARTEC, 2015, SIRAE SIST REAL AUM
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Billinghurst M, 2002, COMMUN ACM, V45, P64, DOI 10.1145/514236.514265
   Birkfellner W, 2002, IEEE T MED IMAGING, V21, P991, DOI 10.1109/TMI.2002.803099
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Calderita LV, 2015, REV IBEROAM AUTOM IN, V12, P99, DOI 10.1016/j.riai.2014.09.007
   Chi HL, 2013, AUTOMAT CONSTR, V33, P116, DOI 10.1016/j.autcon.2012.12.017
   Cuenca J., 2018, WORLD ACAD SCI ENG T, V5
   Fiorentino M, 2014, COMPUT IND, V65, P270, DOI 10.1016/j.compind.2013.11.004
   Garcia-Pereira I, 2018, DESIGN MIXED REALITY
   Garcia-Pereira I., 2018, ADJ P IEEE INT S MIX
   Gauglitz S., 2014, P 27 ANN ACM S USER, P449
   Gay-Bellile G., 2012, ISMAR WORKSH
   Gimeno J, 2017, AUGMENTED REALITY SO
   Gimeno J., 2011, AUGMENTED REALITY SO
   Golparvar-Fard M, 2014, J COMPUT CIVIL ENG, V28, P17, DOI 10.1061/(ASCE)CP.1943-5487.0000311
   Graf H, 2011, SYMPOSIUM ON SIMULATION FOR ARCHITECTURE AND URBAN DESIGN 2011 (SIMAUD 2011) - 2011 SPRING SIMULATION MULTICONFERENCE - BK 8 OF 8, P5
   Hansen F.A., 2006, P 17 C HYPERTEXT HYP, P121
   Henderson S, 2011, IEEE T VIS COMPUT GR, V17, P1355, DOI 10.1109/TVCG.2010.245
   HITLabNZ, 2003, ARTOOLKIT
   Kaufmann H, 2003, COMPUT GRAPH-UK, V27, P339, DOI 10.1016/S0097-8493(03)00028-1
   Kilgus T, 2015, INT J COMPUT ASS RAD, V10, P573, DOI 10.1007/s11548-014-1106-9
   Kopsida M., 2016, 16 INT C COMP CIV BU
   Kounavis CD, 2012, INT J ENG BUS MANAG, V4, DOI 10.5772/51644
   Kwon OS, 2014, AUTOMAT CONSTR, V46, P74, DOI 10.1016/j.autcon.2014.05.005
   Linaza M. T., 2013, INFORM COMMUNICATION, P497
   Meza S, 2014, AUTOMAT CONSTR, V42, P1, DOI 10.1016/j.autcon.2014.02.011
   Mizell D.W., 1992, P 25 HAW INT C SYST, VVolume 2, P659, DOI [DOI 10.1109/HICSS.1992.183317, 10.1109/HICSS.1992.183317]
   Occipital, 2017, STRUCTURE SENSOR
   Palmarini R, 2018, ROBOT CIM-INT MANUF, V49, P215, DOI 10.1016/j.rcim.2017.06.002
   Portales C., 2016, Handbook of Research on Human-Computer Interfaces, Developments, and Applications, P216, DOI DOI 10.4018/978-1-5225-0435-1.CH009
   Portalés C, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041262
   Portalés C, 2010, IEEE MULTIMEDIA, V17, P8, DOI 10.1109/MMUL.2010.72
   Schoenfelder R, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P83
   Straub Ad, 2009, Structural Survey, V27, P23, DOI 10.1108/02630800910941665
   Thomas B, 2000, FOURTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, DIGEST OF PAPERS, P139, DOI 10.1109/ISWC.2000.888480
   Vera L, 2018, LECT NOTES COMPUT SC, V10714, P293, DOI 10.1007/978-3-319-76270-8_21
   Webel S, 2013, ROBOT AUTON SYST, V61, P398, DOI 10.1016/j.robot.2012.09.013
   Wither J, 2009, COMPUT GRAPH-UK, V33, P679, DOI 10.1016/j.cag.2009.06.001
   Woodward Charles., 2010, 10th International Conference on Construction Applications of Virtual Reality, P4
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Zhu J, 2014, INT J INTERACT DES M, V8, P293, DOI 10.1007/s12008-013-0199-7
   Zillner J, 2018, AUGMENTED REALITY RE
NR 47
TC 22
Z9 22
U1 3
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6483
EP 6501
DI 10.1007/s11042-019-08419-x
EA DEC 2019
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000502584400002
DA 2024-07-18
ER

PT J
AU Wan, S
   Qi, LL
   Yang, GZ
   Lu, YL
   Yan, XH
   Li, LL
AF Wan, Song
   Qi, Lanlan
   Yang, Guozheng
   Lu, Yuliang
   Yan, Xuehu
   Li, Longlong
TI Visual secret sharing scheme with (<i>n</i>, <i>n</i>) threshold for
   selective secret content based on QR codes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual secret sharing; QR code; Visual cryptography application; Error
   correction; Express delivery; Security
AB In this paper, a visual secret sharing (VSS) scheme with (n, n)(n >= 2) threshold for selective secret content using QR codes is investigated. Firstly, the secret message which can include different types of information(selective secret content) could be encoded into a secret QR code. Secondly, the secret QR code can be embedded into n cover QR codes. Finally, the proposed QR code visual secret sharing scheme(QRVSS) can visually reveal secret QR code with the abilities of stacking and XOR decryptions. Our QRVSS exploits the error correction mechanism inherent in the QR code structure, to embed the bits corresponding to shares that generated by VSS from a secret QR code bit into the same locations of the cover QR codes in the processing of encoding QRs. Each output share is a valid QR code that can be decoded and it may reduce the likelihood of attracting the attention of potential attackers. The reconstructed secret QR code can be decoded as same as the secret contents. In addition, QR codes can assist alignment for VSS recovery and the proposed scheme can be applied to many applications, such as express delivery. The experiment results show the effectiveness of our scheme.
C1 [Wan, Song; Qi, Lanlan; Yang, Guozheng; Lu, Yuliang; Yan, Xuehu; Li, Longlong] Natl Univ Def Technol, Hefei 230037, Anhui, Peoples R China.
C3 National University of Defense Technology - China
RP Yan, XH (corresponding author), Natl Univ Def Technol, Hefei 230037, Anhui, Peoples R China.
EM wsong1031@163.com; 693475860@qq.com; publicYangGZ@126.com;
   publicLuYL@126.com; publictiger@126.com; lilongs8636@163.com
RI Yan, Xuehu/AFK-3139-2022; Yan, Xuehu/AAG-1718-2022
OI Yan, Xuehu/0000-0001-6388-1720; Yan, Xuehu/0000-0001-6388-1720; Li,
   Longlong/0000-0001-7390-3647
FU National Natural Science Foundation of China [61602491]
FX This research was funded by [the National Natural Science Foundation of
   China] grant number [61602491].
CR Beimel Amos, 2011, Coding and Cryptology. Proceedings of the Third International Workshop, IWCC 2011, P11, DOI 10.1007/978-3-642-20901-7_2
   Buckley O, 2014, WORKSH SOCIOTECH ASP, P8, DOI 10.1109/STAST.2014.10
   Chen Y., 2018, IEEE T CONTR SYST T, V99, P1
   Chow YW, 2016, EXPLOITING ERROR COR
   Jtc1/Sc I, 2006, INF TECHN AUT ID DAT
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Li L, 2016, J SYST SOFTWARE, V116, P85, DOI 10.1016/j.jss.2015.07.009
   Lin P, 2016, ACTA GEOTECH, V12, P1, DOI DOI 10.1109/TII.2016.2517358
   Liu Y, 2018, Multimed Tools Appl, V77, P1
   Liu ZH, 2011, COMM COM INF SC, V143, P346
   Naor M., 1999, LNCS, V950, P1
   Snyder A. J, 2012, PATTERN RECOGNIT LET, V34, P283
   Wan S, 2016, 9 EAI INT WIR INT C
   Wan S., 2017, J REAL TIME IMAGE PR
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang DS, 2009, PATTERN RECOGN, V42, P3071, DOI 10.1016/j.patcog.2009.02.015
   Wang GG, 2018, MEMET COMPUT, V10, P151, DOI 10.1007/s12293-016-0212-3
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Weir Jonathan, 2012, Digital-Forensics and Watermarking 10th International Workshop, IWDW 2011. Revised Selected Papers, P196, DOI 10.1007/978-3-642-32205-1_17
   Weir J, 2010, COMPREHENSIVE STUDY
   Yan X, 2016, CLARITY CORRES CONTR
   Yan X, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/540687
   Yan XH, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P1158, DOI 10.1109/IIH-MSP.2008.213
   Yan XH, 2015, MULTIMED TOOLS APPL, V74, P3231, DOI 10.1007/s11042-013-1784-2
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 25
TC 7
Z9 7
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2789
EP 2811
DI 10.1007/s11042-019-08246-0
EA DEC 2019
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000500178200002
DA 2024-07-18
ER

PT J
AU Khairuzzaman, AKM
   Chaudhury, S
AF Khairuzzaman, Abdul Kayom Md
   Chaudhury, Saurabh
TI Masi entropy based multilevel thresholding for image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multilevel thresholding; Image segmentation; Masi entropy; Particle
   swarm optimization; Minimumcross entropy; Kapur's entropy
ID PARTICLE SWARM OPTIMIZATION; MOTH-FLAME OPTIMIZATION; ALGORITHM;
   EVOLUTIONARY; TSALLIS; KAPURS; SCHEME
AB A new multilevel thresholding based image segmentation technique is developed which utilizes Masi entropy as an objective function. Thresholding is an important image segmentation technique. It may be divided into two types such as bi-level and multilevel thresholding. Bi-level thresholding uses a single threshold to classify an image into two classes: object and the background. For an image containing a single object in a distinct background, bi-level thresholding can be successfully used for segmentation. But in case of complex images containing multiple objects, bi-level thresholding often fails to give satisfactory segmentation. In such cases, multilevel thresholding is generally preferred over bi-level thresholding. However, computational complexity of multilevel thresholding increases very rapidly with increasing number of thresholds. Metaheuristic algorithms are generally used to optimize the threshold searching process to reduce the computational complexity involved in multilevel thresholding. In this paper, Particle Swarm Optimization (PSO) along with Masi entropy is proposed for multilevel thresholding based image segmentation. The proposed technique is evaluated using a set of standard test images. The proposed technique is compared with the recently proposed Dragonfly Algorithm (DA) based technique that uses Kapur's entropy as objective function. The proposed technique is also compared with PSO based technique that uses minimum cross entropy (MCE) as objective function. The quality of the segmented images is measured using Mean Structural SIMilarity (MSSIM) index and Peak Signal-to-Noise Ratio (PSNR). The experimental results suggest that the proposed technique outperforms Kapur's entropy and gives very competitive result when compared with the MCE based technique. Further, computational complexity of multilevel thresholding is also greatly reduced.
C1 [Khairuzzaman, Abdul Kayom Md; Chaudhury, Saurabh] Natl Inst Technol NIT Silchar, Dept Elect Engn, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Khairuzzaman, AKM (corresponding author), Natl Inst Technol NIT Silchar, Dept Elect Engn, Silchar 788010, Assam, India.
EM kayomabdul@gmail.com; saurabh1971@gmail.com
RI Md Khairuzzaman, Abdul Kayom/AAE-8608-2020
OI Md Khairuzzaman, Abdul Kayom/0000-0001-5191-5743; Chaudhury,
   Saurabh/0000-0001-8116-1903
CR Abd El Aziz M, 2017, EXPERT SYST APPL, V83, P242, DOI 10.1016/j.eswa.2017.04.023
   Agrawal S, 2013, SWARM EVOL COMPUT, V11, P16, DOI 10.1016/j.swevo.2013.02.001
   Akay B, 2013, APPL SOFT COMPUT, V13, P3066, DOI 10.1016/j.asoc.2012.03.072
   Ali M, 2014, APPL SOFT COMPUT, V17, P1, DOI 10.1016/j.asoc.2013.11.018
   [Anonymous], 2018, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Arora S, 2008, PATTERN RECOGN LETT, V29, P119, DOI 10.1016/j.patrec.2007.09.005
   Ben Ishak A, 2017, APPL SOFT COMPUT, V52, P306, DOI 10.1016/j.asoc.2016.10.034
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P1573, DOI 10.1016/j.eswa.2014.09.049
   Bhandari AK, 2014, EXPERT SYST APPL, V41, P3538, DOI 10.1016/j.eswa.2013.10.059
   Chakraborty R, 2019, ARAB J SCI ENG, V44, P3005, DOI 10.1007/s13369-018-3400-2
   Chen W, 2008, PROCEEDINGS OF THE 27TH CHINESE CONTROL CONFERENCE, VOL 7, P348, DOI 10.1109/CHICC.2008.4605745
   Gao H, 2010, IEEE T INSTRUM MEAS, V59, P934, DOI 10.1109/TIM.2009.2030931
   Hammouche K, 2010, ENG APPL ARTIF INTEL, V23, P676, DOI 10.1016/j.engappai.2009.09.011
   Hanbay K, 2014, APPL SOFT COMPUT, V21, P433, DOI 10.1016/j.asoc.2014.04.008
   Horng MH, 2011, EXPERT SYST APPL, V38, P13785, DOI 10.1016/j.eswa.2011.04.180
   Jothi AA, 2016, APPL SOFT COMPUT, V46, P652, DOI 10.1016/j.asoc.2016.02.030
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khairuzzaman AKM, 2017, INT J APPL METAHEUR, V8, P58, DOI 10.4018/IJAMC.2017100104
   Khairuzzaman AKM, 2017, EXPERT SYST APPL, V86, P64, DOI 10.1016/j.eswa.2017.04.029
   Kurban T, 2014, APPL SOFT COMPUT, V23, P128, DOI 10.1016/j.asoc.2014.05.037
   LI CH, 1993, PATTERN RECOGN, V26, P617, DOI 10.1016/0031-3203(93)90115-D
   Li CH, 1998, PATTERN RECOGN LETT, V19, P771, DOI 10.1016/S0167-8655(98)00057-9
   Li YY, 2017, APPL SOFT COMPUT, V56, P345, DOI 10.1016/j.asoc.2017.03.018
   Liang LM, 2018, OPT LASER ENG, V100, P141, DOI 10.1016/j.optlaseng.2017.08.005
   Liao PS, 2001, J INF SCI ENG, V17, P713
   Ma M, 2011, APPL SOFT COMPUT, V11, P5205, DOI 10.1016/j.asoc.2011.05.039
   Maitra M, 2008, MEASUREMENT, V41, P1124, DOI 10.1016/j.measurement.2008.03.002
   Masi M, 2005, PHYS LETT A, V338, P217, DOI 10.1016/j.physleta.2005.01.094
   Nie FY, 2017, SIGNAL PROCESS, V134, P23, DOI 10.1016/j.sigpro.2016.11.004
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Panda R, 2017, APPL SOFT COMPUT, V50, P94, DOI 10.1016/j.asoc.2016.11.011
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Sambandam RK, 2018, J KING SAUD UNIV-COM, V30, P449, DOI 10.1016/j.jksuci.2016.11.002
   Sarkar S, 2017, APPL SOFT COMPUT, V50, P142, DOI 10.1016/j.asoc.2016.10.032
   Sathya PD, 2011, MEASUREMENT, V44, P1828, DOI 10.1016/j.measurement.2011.09.005
   Sathya PD, 2011, NEUROCOMPUTING, V74, P2299, DOI 10.1016/j.neucom.2011.03.010
   Sathya PD, 2011, ENG APPL ARTIF INTEL, V24, P595, DOI 10.1016/j.engappai.2010.12.001
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Shi YH, 1998, IEEE C EVOL COMPUTAT, P69, DOI 10.1109/ICEC.1998.699146
   Suresh S, 2017, APPL SOFT COMPUT, V55, P503, DOI 10.1016/j.asoc.2017.02.005
   Wei MQ, 2018, OPT LASER ENG, V103, P110, DOI 10.1016/j.optlaseng.2017.11.014
   WESZKA JS, 1978, COMPUT VISION GRAPH, V7, P259, DOI 10.1016/0146-664X(78)90116-8
   Xiao QK, 2018, MULTIMED TOOLS APPL, V77, P6955, DOI 10.1007/s11042-017-4614-0
   Xiao QK, 2015, SOFT COMPUT, V19, P133, DOI 10.1007/s00500-014-1237-5
   Xiao QK, 2014, MULTIMED TOOLS APPL, V72, P951, DOI 10.1007/s11042-013-1416-x
   Xiao QK, 2011, NEUROCOMPUTING, V74, P3486, DOI 10.1016/j.neucom.2011.06.002
   Yin PY, 2007, APPL MATH COMPUT, V184, P503, DOI 10.1016/j.amc.2006.06.057
   Yin PY, 1999, SIGNAL PROCESS, V72, P85, DOI 10.1016/S0165-1684(98)00167-4
   Yin PY, 1997, SIGNAL PROCESS, V60, P305, DOI 10.1016/S0165-1684(97)00080-7
NR 51
TC 26
Z9 27
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33573
EP 33591
DI 10.1007/s11042-019-08117-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600046
DA 2024-07-18
ER

PT J
AU Liu, J
   Sun, SN
   Chen, Y
AF Liu, Jin
   Sun, Shengnan
   Chen, Yue
TI A novel region-based active contour model based on kernel function for
   image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Level set; Active contour model; Local CV model;
   Intensity inhomogeneity
ID LEVEL SET EVOLUTION; FITTING ENERGY; DRIVEN
AB It is a difficult task to accurately segment images with intensity inhomogeneity, because most of existing algorithms are based upon the assumption of the homogeneity of image intensity. In this paper, we propose a novel region-based active contour model, referred to as the K-GLIF, which utilizes both global and local image intensity fittings with kernel functions. The model consists of an intensity fitting term and a new regularization term. The intensity fitting term of the level set function is the gradient descent flow that minimizes the global binary fitting energy functional. The local intensity fitting value based on the generalized Gaussian kernel function is then incorporated into the global intensity fitting value to form the weighted intensity fitting value on the two sides of the contour. Owing to the kernel function, the intensity information in local regions is extracted to guide the motion of the contour, which enables the model to effectively segment images with intensity inhomogeneity and smooth noise. A new regularization term is used to control the smoothness of the level set function and avoid complicated re-initialization. Experimental results and comparisons with other models of inhomogeneous images, synthetic images, medical images, multi-object images, natural and infrared images show that the proposed K-GLIF model improves the quality of image segmentation in terms of accuracy and robustness of initial contours.
C1 [Liu, Jin; Sun, Shengnan; Chen, Yue] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
C3 Xidian University
RP Liu, J (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
EM Jinliu@xidian.edu.cn; snsun@stu.xidian.edu.cn; chenyue@stu.xidian.edu.cn
FU National Natural Science Foundation of China [61101246]; Fundamental
   Research Funds for the Central Universities [JB150209]
FX This research was supported in part by the National Natural Science
   Foundation of China (Grant No. 61101246) and the Fundamental Research
   Funds for the Central Universities (Grant No. JB150209).
CR [Anonymous], 2007, 2007 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2007.383014
   [Anonymous], 2016, OTCBVS BENCHMARK DAT
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Aubert G., 2006, MATH PROBLEMS IMAGE
   Balla-Arabé S, 2013, IEEE T CYBERNETICS, V43, P910, DOI 10.1109/TSMCB.2012.2218233
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chabrier S, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/96306
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   He CJ, 2012, SIGNAL PROCESS, V92, P587, DOI 10.1016/j.sigpro.2011.09.004
   Ji ZX, 2015, INFORM SCIENCES, V301, P285, DOI 10.1016/j.ins.2015.01.006
   Jiang XL, 2015, OPTIK, V126, P5672, DOI 10.1016/j.ijleo.2015.09.021
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Li CM, 2005, PROC CVPR IEEE, P430
   Liu L, 2017, MULTIMED TOOLS APPL, V76, P10149, DOI 10.1007/s11042-016-3603-z
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Shahvaran Zahra, 2012, J Med Signals Sens, V2, P17
   STACY EW, 1962, ANN MATH STAT, V33, P1187, DOI 10.1214/aoms/1177704481
   Wang L, 2017, INFORM SCIENCES, V418, P61, DOI 10.1016/j.ins.2017.06.042
   Wang L, 2009, COMPUT MED IMAG GRAP, V33, P520, DOI 10.1016/j.compmedimag.2009.04.010
   Wang XF, 2015, PATTERN RECOGN, V48, P189, DOI 10.1016/j.patcog.2014.07.008
   Wang XF, 2010, PATTERN RECOGN, V43, P603, DOI 10.1016/j.patcog.2009.08.002
   Yu CY, 2013, COMPUT MATH APPL, V65, P1746, DOI 10.1016/j.camwa.2013.03.021
   Zhang KH, 2016, IEEE T CYBERNETICS, V46, P546, DOI 10.1109/TCYB.2015.2409119
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
NR 25
TC 1
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33659
EP 33677
DI 10.1007/s11042-019-08174-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600050
DA 2024-07-18
ER

PT J
AU Qian, YC
   Yin, XY
   Gao, W
AF Qian, Youcheng
   Yin, Xueyan
   Gao, Wei
TI Robust inner product regularized unsupervised feature selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised feature selection; Self-representation; Spectral
   clustering; Inner product regularization
ID GENE-EXPRESSION; SPARSE REGRESSION; FEATURE SUBSET; ALGORITHM;
   REDUNDANCY; FRAMEWORK
AB Feature selection aims to select the optimal feature subset which can reduce time complexity, save storage space and improve the performances of various tasks. In this paper, a novel algorithm termed Robust Inner Product Regularized Unsupervised Feature Selection (RIRUFS) is proposed. In RIRUFS algorithm, we firstly combine the self-representation of samples, spectral clustering and feature selection into a unified framework. In this way, RIRUFS can well uncover the underlying multi-subspace structure of the data and iteratively learn the most optimal similarity matrix and clustering labels. Secondly, through introducing the inner product regularization into our objective function, the features selected by our RIRUFS possess the independence and contain low redundancy. Moreover, an effective iterative updating optimization algorithm is developed to solve the RIRUFS model. Extensive experimental results on six datasets show our algorithm is more effective than existing state-of-the-art unsupervised feature selection methods.
C1 [Qian, Youcheng; Gao, Wei] Northeast Normal Univ, Sch Math & Stat, Key Lab Appl Stat, MOE, Changchun 130024, Jilin, Peoples R China.
   [Qian, Youcheng] Jilin Inst Chem Technol, Sch Sci, Appl Math, Jilin 132022, Jilin, Peoples R China.
   [Yin, Xueyan] Dalian Univ Technol, Sch Comp Sci & Technol, Dalian 116024, Liaoning, Peoples R China.
C3 Northeast Normal University - China; Jilin Institute of Chemical
   Technology; Dalian University of Technology
RP Gao, W (corresponding author), Northeast Normal Univ, Sch Math & Stat, Key Lab Appl Stat, MOE, Changchun 130024, Jilin, Peoples R China.
EM qianyc430@nenu.edu.cn; gaow@nenu.edu.cn
FU National Natural Science Foundation of China [11871141]; Funds for the
   Central Universities [2412019FZ049]
FX We would like to thank Dr. Jianzhong Wang from School of Information
   Science and Technology, Northeast Normal University for his help with
   experiment design, technical editing and acquisition of funding during
   the revision of this paper. This work is supported by the National
   Natural Science Foundation of China under Grants 11871141 and the Funds
   for the Central Universities under Grant 2412019FZ049.
CR Ahmadian A, 2003, P ANN INT IEEE EMBS, V25, P930, DOI 10.1109/IEMBS.2003.1279918
   [Anonymous], 1997, BMVC
   [Anonymous], 2005, ADV NEURAL INF PROCE
   [Anonymous], 2007, PROC IEEE INT C COMP
   [Anonymous], 2019, ARTIFICIAL INTELLIGE
   [Anonymous], AAAI
   [Anonymous], 2019, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2018.2794348
   Boyd S., 2004, CONVEX OPTIMIZATION
   Chen YY, 2019, KNOWL-BASED SYST, V163, P51, DOI 10.1016/j.knosys.2018.08.014
   Dong WH, 2019, PATTERN ANAL APPL, V22, P165, DOI 10.1007/s10044-018-00774-z
   Doquire G, 2013, NEUROCOMPUTING, V121, P5, DOI 10.1016/j.neucom.2012.10.028
   Du SQ, 2017, NEUROCOMPUTING, V241, P115, DOI 10.1016/j.neucom.2017.02.034
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Feng ZX, 2012, 2011 3RD INTERNATIONAL CONFERENCE ON COMPUTER TECHNOLOGY AND DEVELOPMENT (ICCTD 2011), VOL 3, P343
   Freije WA, 2004, CANCER RES, V64, P6503, DOI 10.1158/0008-5472.CAN-04-0452
   Gao HC, 2015, IEEE I CONF COMP VIS, P4238, DOI 10.1109/ICCV.2015.482
   Guo J, 2017, IEEE INT CON MULTI, P1213, DOI 10.1109/ICME.2017.8019357
   Han D, 2015, PROC CVPR IEEE, P5016, DOI 10.1109/CVPR.2015.7299136
   Han JQ, 2015, KNOWL-BASED SYST, V86, P210, DOI 10.1016/j.knosys.2015.06.008
   Hou CP, 2014, IEEE T CYBERNETICS, V44, P793, DOI 10.1109/TCYB.2013.2272642
   Ishikawa M, 2005, CANCER SCI, V96, P387, DOI 10.1111/j.1349-7006.2005.00064.x
   Jiang H, 2019, CRIT REV FOOD SCI, V59, P2335, DOI 10.1080/10408398.2018.1514363
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu LL, 2012, ASIA-PAC INT SYM ELE, P269, DOI 10.1109/APEMC.2012.6237809
   Ma BT, 2017, APPL SOFT COMPUT, V58, P328, DOI 10.1016/j.asoc.2017.04.042
   Qi M, 2018, NEUROCOMPUTING, V273, P593, DOI 10.1016/j.neucom.2017.08.047
   Ranzato M., 2008, P 25 INT C MACH LEAR, P792, DOI DOI 10.1145/1390156.1390256
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Shang RH, 2018, IEEE T CYBERNETICS, V48, P793, DOI 10.1109/TCYB.2017.2657007
   Shang RH, 2016, NEUROCOMPUTING, V171, P1242, DOI 10.1016/j.neucom.2015.07.068
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Spira A, 2007, NAT MED, V13, P361, DOI 10.1038/nm1556
   Tang C, 2018, KNOWL-BASED SYST, V145, P109, DOI 10.1016/j.knosys.2018.01.009
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang JZ, 2013, PATTERN RECOGN, V46, P1616, DOI 10.1016/j.patcog.2012.11.025
   Wang SP, 2017, KNOWL-BASED SYST, V124, P70, DOI 10.1016/j.knosys.2017.03.002
   Wang SH, 2015, AAAI CONF ARTIF INTE, P470
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Zhang H., 2007, P 15 INT C MULTIMEDI, P273
   Zhang J, 2019, IEEE Transactions on Medical Imaging
   Zhang Q., 2018, 2018 INT JOINT C NEU, P1, DOI DOI 10.1109/IJCNN.2018.8489477
   Zhao Z, 2016, IEEE T KNOWL DATA EN, V28, P689, DOI 10.1109/TKDE.2015.2493537
   Zhou W, 2017, IEEE ACCESS, V5, P8792, DOI 10.1109/ACCESS.2017.2699741
   Zhu PF, 2017, PATTERN RECOGN, V66, P364, DOI 10.1016/j.patcog.2017.01.016
   Zhu PF, 2015, PATTERN RECOGN, V48, P438, DOI 10.1016/j.patcog.2014.08.006
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
NR 48
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33593
EP 33615
DI 10.1007/s11042-019-08159-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600047
DA 2024-07-18
ER

PT J
AU Zhao, XL
   Zhang, HL
   Zhou, YL
   Bian, W
   Zhang, T
   Zou, XM
AF Zhao, Xiaole
   Zhang, Huali
   Zhou, Yuliang
   Bian, Wei
   Zhang, Tao
   Zou, Xueming
TI Gibbs-ringing artifact suppression with knowledge transfer from natural
   images to MR images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Gibbs-ringing artifacts; Knowledge
   transfer; Magnetic resonance imaging
AB Gibbs-ringing is a common artifact in magnetic resonance imaging (MRI), which is mainly caused by the finite k-space sampling and the truncation of high frequency (HF) information at the sampling border. It is especially visible for imaging acquisitions at low resolution and can be typically suppressed by filtering at the expense of further loss of HF components. As a classic image restoration problem in MRI, Gibbs-ringing artifact suppression can be viewed as a typical ill-posed inverse problem of image generation in computer vision community, such as image super-resolution and inpainting. Inspired by this, the present work presents a novel method to suppress the Gibbs-ringing artifacts with knowledge transfer from natural images to MR images. The highly nonlinear relation between the artifact-degraded image and the corresponding artifact-free counterpart is modeled with a typical convolutional neural network (CNN), which is first trained with natural images and then fine-tuned with MR images. Unlike many other works, we use transfer learning between different types of images to deal with regression problems, rather than classification problems. The experimental results exhibit that there exists information sharing between natural images and MR images with regard to the same problem, and the knowledge learned from natural images can indeed improve the performance of regression models on MR images.
C1 [Zhao, Xiaole; Zhang, Huali; Zhou, Yuliang; Bian, Wei; Zhang, Tao; Zou, Xueming] Univ Elect Sci & Technol China, Sch Life Sci & Technol, Chengdu 611731, Sichuan, Peoples R China.
   [Zhang, Tao; Zou, Xueming] High Field Magnet Resonance Brain Imaging Lab Sic, Chengdu 611731, Sichuan, Peoples R China.
   [Zhang, Tao; Zou, Xueming] Minist Educ, China Key Lab Neuro Informat, Chengdu 611731, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Zhao, XL (corresponding author), Univ Elect Sci & Technol China, Sch Life Sci & Technol, Chengdu 611731, Sichuan, Peoples R China.
EM zxlation@foxmail.com; uestczhanghuali@163.com; zhouyuliang1225@163.com;
   wei.bian@alltechmed.com; taozhangjin@gmail.com; mark.zou@alltechmed.com
RI Zhang, Tao/AAY-3651-2021; Zhao, Xiaole/AAK-4616-2020
OI Zhao, Xiaole/0000-0003-0100-2414
FU National Key Research and Development Program of China [2016YFC0100 800,
   2016YFC0100802]
FX The work is supported in part by the National Key Research and
   Development Program of China (No. 2016YFC0100 800 and 2016YFC0100802).
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   [Anonymous], 2008, NEURAL INFORM PROCES
   Archibald R, 2002, IEEE T MED IMAGING, V21, P305, DOI 10.1109/TMI.2002.1000255
   Bae W, 2017, ARXIV161106345CSCV
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Block KT, 2008, INT J BIOMED IMAGING, V2008, DOI 10.1155/2008/184123
   Boyd JP, 2005, J COMPUT PHYS, V204, P253, DOI 10.1016/j.jcp.2004.10.008
   Carroll J, 2017, ARXIV171009875CSNE
   CONSTABLE RT, 1991, MAGNET RESON MED, V17, P108, DOI 10.1002/mrm.1910170115
   Ding ZM, 2018, IEEE T NEUR NET LEAR, V29, P310, DOI 10.1109/TNNLS.2016.2618765
   Ding ZM, 2017, IEEE T IMAGE PROCESS, V26, P660, DOI 10.1109/TIP.2016.2631887
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Gottlieb D., 1997, SIAM Review, V39, P644, DOI 10.1137/S0036144596301390
   GOTTLIEB D, 1992, J COMPUT APPL MATH, V43, P81, DOI 10.1016/0377-0427(92)90260-5
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hu Y, 2018, ARXIV180208808CSCV
   Kellner E, 2016, MAGN RESON MED, V76, P1574, DOI 10.1002/mrm.26054
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Latt JL, 2016, ARXIV161003764V1CSNA
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li JJ, 2019, IEEE T NEUR NET LEAR, V30, P1381, DOI 10.1109/TNNLS.2018.2868854
   Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174
   Liang ZP., 1992, REV MAGN RESON MED, V14, P67
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Manjón JV, 2010, MED IMAGE ANAL, V14, P784, DOI 10.1016/j.media.2010.05.010
   Ouyang, 2014, ARXIV14093505, DOI [10.1016/j.patcog.2018.02.004, DOI 10.1016/J.PATCOG.2018.02.004]
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Perrone D, 2015, NEUROIMAGE, V120, P441, DOI 10.1016/j.neuroimage.2015.06.068
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sarra SA, 2006, NUMER ALGORITHMS, V41, P17, DOI 10.1007/s11075-005-9003-5
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Sun Y, 2015, ARXIV
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Veraart J, 2016, MAGN RESON MED, V76, P301, DOI 10.1002/mrm.25866
   Wang SY, 2019, IEEE T PATTERN ANAL, V41, P2783, DOI [10.1109/INTMAG.2018.8508542, 10.1109/TNNLS.2017.2771290, 10.1109/TPAMI.2018.2861871]
   Wang T, 2018, ARXIV170805473CSCV
   Wang YY, 2018, IEEE T FUZZY SYST, V26, P1164, DOI 10.1109/TFUZZ.2017.2710952
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   YAN H, 1993, IEEE T MED IMAGING, V12, P73, DOI 10.1109/42.222669
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
   Zou X., 2018, ARXIV181006453
NR 62
TC 12
Z9 13
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33711
EP 33733
DI 10.1007/s11042-019-08143-6
EA NOV 2019
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000497812200001
DA 2024-07-18
ER

PT J
AU Adeyemi-Ejeye, AO
   Alreshoodi, M
   Al-Jobouri, L
   Fleury, M
AF Adeyemi-Ejeye, Anthony O.
   Alreshoodi, Mohammed
   Al-Jobouri, Laith
   Fleury, Martin
TI Impact of packet loss on 4K UHD video for portable devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 4K UHD; H; 264; AVC; HEVC; IEEE 802; ad; Packet loss visibility
ID QUALITY ASSESSMENT; EFFICIENCY; HEVC; VISIBILITY; EVOLUTION
AB Ultra High Definition (UHD) video streaming to portable devices has become topical. Two standardized codecs are current, H.264/Advanced Video Coding (AVC) and the more recent High Efficiency Video Coding (HEVC). This paper compares the two codecs' robustness to packet loss, after making allowances for relative coding gain. A significant finding from the comparison is that the H.264/AVC codec is less impacted by packet loss than HEVC, despite their differing coding efficiencies and including at low levels of packet loss. The results will be especially relevant to those designing portable devices with 4K UHD video display capability, allowing them to estimate the level of error concealment necessary. The paper also includes the results of HEVC compressed UHD video streaming over an IEEE 802.11ad wireless link operating at 60 GHz as a pointer to future performance in an error-prone channel.
C1 [Adeyemi-Ejeye, Anthony O.] Univ Surrey, Dept Mus & Media, Innovat Media Lab, Guildford GU2 7XH, Surrey, England.
   [Alreshoodi, Mohammed] Qassim Univ, Univ Coll, Buraydah, Saudi Arabia.
   [Al-Jobouri, Laith; Fleury, Martin] Univ Suffolk, Sch Sci Technol & Engn, Ipswich IP4 1QJ, Suffolk, England.
C3 University of Surrey; Qassim University; University of Suffolk
RP Fleury, M (corresponding author), Univ Suffolk, Sch Sci Technol & Engn, Ipswich IP4 1QJ, Suffolk, England.
EM fleury.martin55@gmail.com
RI Adeyemi-Ejeye, Anthony/AAO-8477-2020; Alreshoodi, Mohammed/AAK-4165-2020
OI Adeyemi-Ejeye, Anthony/0000-0002-8371-7829; Alreshoodi,
   Mohammed/0000-0002-3066-6909; Al-Jobouri, Laith/0000-0003-4600-9513
CR Abe A, 2016, 2016 39TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P94, DOI 10.1109/TSP.2016.7760836
   Adeyemi-Ejeye AO, 2019, J REAL-TIME IMAGE PR, V16, P127, DOI 10.1007/s11554-018-0807-7
   Akyazi P, 2018, P IEEE 10 INT C QUAL
   Alreshoodi Mohammed, 2017, 2017 IEEE International Conference on Consumer Electronics (ICCE), P237, DOI 10.1109/ICCE.2017.7889298
   [Anonymous], 2015, QUALITY MULTIMEDIA E
   [Anonymous], 2013, P IEEE REG 10 C XIAN, DOI DOI 10.1109/TENCON.2013.6718911
   [Anonymous], 2007, PACKET VIDEO 2007
   [Anonymous], 2003, Digital Video and HDTV Algorithms and Interfaces
   Argyropoulos S, 2011, INT CONF ACOUST SPEE, P1169
   Bae SH, 2013, IEEE T BROADCAST, V59, P209, DOI 10.1109/TBC.2013.2247171
   Blender-Foundation, 2011, SINT 4K
   Boulos F, 2009, P 4 INT WORKSH VID P, P1
   Cermak GW, 2009, INT WORK QUAL MULTIM, P41, DOI 10.1109/QOMEX.2009.5246980
   Chan A., 2010, 2010 Proceedings IEEE INFOCOM, P1, DOI DOI 10.1109/INFCOM.2010.5461979
   Chang YC, 2013, PRIVATE PROPERTY AND TAKINGS COMPENSATION: THEORETICAL FRAMEWORK AND EMPIRICAL ANALYSIS, P1
   Cheon M, 2018, IEEE T CIRC SYST VID, V28, P1467, DOI 10.1109/TCSVT.2017.2683504
   Cordeiro C, 2009, P IEEE INT C COMM WO, P1
   Emoto M, 2012, J DISP TECHNOL, V8, P424, DOI 10.1109/JDT.2012.2191390
   Fraunhofer HHI, 2018, HEVC 4K LIVE DECODER
   Gökce H, 2018, CHEMISTRYSELECT, V3, DOI 10.1002/slct.201802484
   Halák J, 2011, FUTURE GENER COMP SY, V27, P886, DOI 10.1016/j.future.2010.11.014
   Hamidouche W, 2014, P IEEE INT C MULT EX
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P511, DOI 10.1109/TCSVT.2002.800313
   International Telecommunications Union, 2014, PRES STAT ULTR DEF T
   Jingjing Wang, 2012, Journal of Networks, V7, P203, DOI 10.4304/jnw.7.1.203-209
   Kanumuri S, 2006, IEEE T MULTIMEDIA, V8, P341, DOI 10.1109/TMM.2005.864343
   Kanumuri S, 2006, IEEE IMAGE PROC, P2245, DOI 10.1109/ICIP.2006.312809
   Khan A, 2012, IEEE T MULTIMEDIA, V14, P431, DOI 10.1109/TMM.2011.2176324
   Kim DH, 2018, ETRI J, V40, P266, DOI 10.4218/etrij.2017-0078
   Kim Y, 2018, IEEE T CIRC SYST VID
   Korhonen J, 2005, IEEE WCNC, P1608
   Kulupana Gosala, 2016, 2016 IEEE International Conference on Consumer Electronics (ICCE), P85, DOI 10.1109/ICCE.2016.7430531
   Kumar A, 2018, ADV STRUCT CHEM IMAG, V4, DOI 10.1186/s40679-018-0057-6
   Kunic Srecko, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P83
   Leppkes H, 2014, LAV FILT 0 62
   Li H, 2012, PROCEEDINGS OF THE TWELFTH INTERNATIONAL WORKSHOP ON WEB INFORMATION AND DATA MANAGEMENT, P33
   Liang B, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P684, DOI 10.1109/ICCVW.2013.94
   Mehendale M., 2012, 2012 IEEE International Solid-State Circuits Conference (ISSCC), P226, DOI 10.1109/ISSCC.2012.6176986
   Microsoft, 2012, DIRECTSHOW
   Mohamed S, 2002, IEEE T CIRC SYST VID, V12, P1071, DOI 10.1109/TCSVT.2002.806808
   Moorthy AK, 2010, IEEE T CIRC SYST VID, V20, P587, DOI 10.1109/TCSVT.2010.2041829
   Nallappan K, 2018, P 11 GLOB S MILL WAV
   Nightingale J, 2014, IEEE T CONSUM ELECTR, V60, P242, DOI 10.1109/TCE.2014.6852000
   Nightingale J, 2012, IEEE T CONSUM ELECTR, V58, P404, DOI 10.1109/TCE.2012.6227440
   Nitsche T, 2014, IEEE COMMUN MAG, V52, P132, DOI 10.1109/MCOM.2014.6979964
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Oztas B, 2012, IEEE I C ELECT CIRC, P785, DOI 10.1109/ICECS.2012.6463542
   Pal U, 2018, SMPTE MOTION IMAG J, V127, P1, DOI [10.5594/JMI.2018.2844569, DOI 10.5594/JMI.2018.2844569]
   Pinson MH, 2010, IEEE T BROADCAST, V56, P86, DOI 10.1109/TBC.2009.2034511
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Pourazad MT, 2012, IEEE CONSUM ELECTR M, V1, P36, DOI 10.1109/MCE.2012.2192754
   Rappaport T. S., 2014, MILLIMETER WAVE WIRE
   Rerbek M, 2014, APPL DIGITAL IMAGE P, V9217
   Ryu ES, 2015, AEU-INT J ELECTRON C, V69, P1070, DOI 10.1016/j.aeue.2015.03.008
   Salva-Garcia P, 2018, COMPUT COMMUN, V118, P171, DOI 10.1016/j.comcom.2017.11.007
   Schierl T, 2012, IEEE T CIRC SYST VID, V22, P1871, DOI 10.1109/TCSVT.2012.2223054
   Seufert M, 2015, IEEE COMMUN SURV TUT, V17, P469, DOI 10.1109/COMST.2014.2360940
   Shin J, 2010, INT CONF ACOUST SPEE, P910, DOI 10.1109/ICASSP.2010.5495279
   Shirai D, 2009, FUTURE GENER COMP SY, V25, P192, DOI 10.1016/j.future.2008.07.003
   Shirai D, 2006, 2006 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P1855
   Stockhammer T., 2007, MULTIMEDIA IP WIRELE, P13, DOI DOI 10.1016/B978-012088480-3/50003-5
   Sugawara M, 2014, IEEE SIGNAL PROC MAG, V31, P170, DOI 10.1109/MSP.2014.2302331
   Sukho Lee, 2016, 2016 IEEE 6th International Conference on Consumer Electronics - Berlin (ICCE-Berlin), P94, DOI 10.1109/ICCE-Berlin.2016.7684727
   Tan TK, 2016, IEEE T CIRC SYST VID, V26, P76, DOI 10.1109/TCSVT.2015.2477916
   Valdes-Garcia A, 2011, IEEE COMMUN MAG, V49, P120, DOI 10.1109/MCOM.2011.5741156
   VQEG, 2014, FIN REP VID QUAL EXP
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   Wood D, 2011, HDTV ITU R EBU TECH
   Wu N, 2012, INT C PAR DISTRIB SY, P276, DOI 10.1109/ICPADS.2012.46
NR 71
TC 5
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31733
EP 31755
DI 10.1007/s11042-019-07996-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000034
DA 2024-07-18
ER

PT J
AU Bhandari, AK
   Singh, N
   Shubham, S
AF Bhandari, Ashish Kumar
   Singh, Neha
   Shubham, Swapnil
TI An efficient optimal multilevel image thresholding with
   electromagnetism-like mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Electromagnetism-like mechanism; Renyi's entropy;
   Tsallis entropy; Kapur's entropy
ID PARTICLE SWARM OPTIMIZATION; CUCKOO SEARCH ALGORITHM; SEGMENTATION;
   ENTROPY; KAPURS; RENYI
AB Segmentation process is considered a major part of various image-processing applications due to its extreme inspiration on the subsequent image analysis. Thresholding is one of the simplest techniques for segmentation. In this paper, Renyi's entropy is combined with electromagnetism-like mechanism optimization (EMO) to perform multilevel thresholding based color image segmentation. For statistical independent subsystems, Renyi's entropy shows an extensive property and is applied to find best threshold value for image segmentation. The entropic parameter alpha can handle the additive information that is existent in the image. The feasibility of the EMO-Renyi's based approach has been tested on various satellite and standard color images with bat algorithm (BAT), backtracking search algorithm (BSA), firefly algorithm (FA), particle swarm optimization (PSO), and wind driven optimization (WDO) for solving the multilevel color image thresholding problem. The analysis based on statistics of different optimization algorithms indicates the proposed EMO-Renyi's algorithm to be more robust and precise for multilevel color image segmentation problem. These claims have been confirmed by comparing fidelity parameters such as mean error (ME), mean squared error (MSE), peak signal-to-noise ratio (PSNR), feature similarity index (FSIM), structure similarity index (SSIM) and entropy. Experiments on standard daily-life color images are conducted to prove the effectiveness of the proposed scheme. The results show that the proposed method can produce more promising segmentation results from the aspect of objective and subjective observations.
C1 [Bhandari, Ashish Kumar; Singh, Neha; Shubham, Swapnil] Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna 800005, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Bhandari, AK (corresponding author), Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna 800005, Bihar, India.
EM bhandari.iiitj@gmail.com; nehasingh0910@gmail.com;
   swapnil612chi@gmail.com
RI Bhandari, Ashish Kumar/AAA-9991-2019; Singh, Neha/JED-4558-2023
OI Bhandari, Ashish Kumar/0000-0001-9842-8125; Singh,
   Neha/0000-0001-7214-7392
CR Agrawal S, 2013, SWARM EVOL COMPUT, V11, P16, DOI 10.1016/j.swevo.2013.02.001
   Aja-Fernández S, 2015, KNOWL-BASED SYST, V83, P1, DOI 10.1016/j.knosys.2015.02.029
   [Anonymous], ARAB J SCI ENG
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2018, IEEE J-STARS
   [Anonymous], APPL SOFT COMPUT
   [Anonymous], 2017, SIGNAL IMAGE VIDEO P
   [Anonymous], IEEE T INSTRUM MEAS
   Ben Ishak A, 2017, PHYSICA A, V466, P521, DOI 10.1016/j.physa.2016.09.053
   Bhandari AK, 2017, MULTIDIM SYST SIGN P, V28, P495, DOI 10.1007/s11045-015-0353-4
   Bhandari AK, 2016, EXPERT SYST APPL, V63, P112, DOI 10.1016/j.eswa.2016.06.044
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P8707, DOI 10.1016/j.eswa.2015.07.025
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P1573, DOI 10.1016/j.eswa.2014.09.049
   Bhandari AK, 2018, NEURAL COMPUT APPL, P1
   Bhandari AK, 2019, APPL SOFT COMPUT, V81, DOI 10.1016/j.asoc.2019.105515
   Bhandari AK, 2019, INFRARED PHYS TECHN, V98, P132, DOI 10.1016/j.infrared.2019.03.010
   Bhandari AK, 2016, J EXP THEOR ARTIF IN, V28, P71, DOI 10.1080/0952813X.2015.1020518
   Bhandari AK, 2014, INT J REMOTE SENS, V35, P1601, DOI 10.1080/01431161.2013.876518
   Bhandari AK, 2014, EXPERT SYST APPL, V41, P3538, DOI 10.1016/j.eswa.2013.10.059
   Birbil SI, 2004, J GLOBAL OPTIM, V30, P301, DOI 10.1007/s10898-004-8270-3
   Birbil SI, 2003, J GLOBAL OPTIM, V25, P263, DOI 10.1023/A:1022452626305
   Bouaziz A, 2015, SWARM EVOL COMPUT, V21, P32, DOI 10.1016/j.swevo.2014.12.002
   Chao Y, 2016, OPTIK, V127, P5770, DOI 10.1016/j.ijleo.2016.03.059
   Choy SK, 2017, PATTERN RECOGN, V68, P141, DOI 10.1016/j.patcog.2017.03.009
   Civicioglu P, 2013, APPL MATH COMPUT, V219, P8121, DOI 10.1016/j.amc.2013.02.017
   de Albuquerque MP, 2004, PATTERN RECOGN LETT, V25, P1059, DOI 10.1016/j.patrec.2004.03.003
   de Castro LN, 2002, IEEE T EVOLUT COMPUT, V6, P239, DOI 10.1109/TEVC.2002.1011539
   Dey S, 2017, APPL SOFT COMPUT, V56, P472, DOI 10.1016/j.asoc.2016.04.024
   Dey S, 2016, APPL SOFT COMPUT, V46, P677, DOI 10.1016/j.asoc.2015.09.042
   Fan F, 2017, INFORM SCIENCES, V397, P48, DOI 10.1016/j.ins.2017.02.044
   Gandomi AH, 2011, COMPUT STRUCT, V89, P2325, DOI 10.1016/j.compstruc.2011.08.002
   He LF, 2017, NEUROCOMPUTING, V240, P152, DOI 10.1016/j.neucom.2017.02.040
   Huo FC, 2017, SIGNAL IMAGE VIDEO P, V11, P1585, DOI 10.1007/s11760-017-1123-6
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Lahmiri S, 2017, BIOMED SIGNAL PROCES, V31, P148, DOI 10.1016/j.bspc.2016.07.008
   Li YY, 2017, APPL SOFT COMPUT, V56, P345, DOI 10.1016/j.asoc.2017.03.018
   Nie FY, 2017, SIGNAL PROCESS, V134, P23, DOI 10.1016/j.sigpro.2016.11.004
   Oliva D, 2015, EXPERT SYST APPL, V42, P5874, DOI 10.1016/j.eswa.2015.03.028
   Oliva D, 2014, NEUROCOMPUTING, V139, P357, DOI 10.1016/j.neucom.2014.02.020
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ouadfel S, 2016, EXPERT SYST APPL, V55, P566, DOI 10.1016/j.eswa.2016.02.024
   Pare S, 2018, COMPUT ELECTR ENG, V70, P476, DOI 10.1016/j.compeleceng.2017.08.008
   Pare S, 2017, EXPERT SYST APPL, V87, P335, DOI 10.1016/j.eswa.2017.06.021
   Pare S, 2016, APPL SOFT COMPUT, V47, P76, DOI 10.1016/j.asoc.2016.05.040
   Pare S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P730, DOI 10.1109/ICDSP.2015.7251972
   Rajathilagam B, 2017, PATTERN RECOGN, V67, P1, DOI 10.1016/j.patcog.2017.01.028
   Rajinikanth V, 2018, ARAB J SCI ENG, V43, P4365, DOI 10.1007/s13369-017-3053-6
   Rajinikanth V, 2016, ADV INTELL SYST COMP, V433, P379, DOI 10.1007/978-81-322-2755-7_40
   Sahoo P, 1997, PATTERN RECOGN, V30, P71, DOI 10.1016/S0031-3203(96)00065-9
   Sahoo PK, 2004, PATTERN RECOGN, V37, P1149, DOI 10.1016/j.patcog.2003.10.008
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Sarkar S, 2016, EXPERT SYST APPL, V50, P120, DOI 10.1016/j.eswa.2015.11.016
   Suresh S, 2017, APPL SOFT COMPUT, V55, P503, DOI 10.1016/j.asoc.2017.02.005
   Suresh S, 2016, EXPERT SYST APPL, V58, P184, DOI 10.1016/j.eswa.2016.03.032
   TSAI WH, 1985, COMPUT VISION GRAPH, V29, P377, DOI 10.1016/0734-189X(85)90133-1
   Yuan B, 2015, COMPUT OPER RES, V53, P32, DOI 10.1016/j.cor.2014.07.011
   Zhang JX, 2017, PATTERN RECOGN, V64, P39, DOI 10.1016/j.patcog.2016.10.025
NR 57
TC 13
Z9 14
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35733
EP 35788
DI 10.1007/s11042-019-08195-8
EA OCT 2019
PG 56
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000495416400001
DA 2024-07-18
ER

PT J
AU Basha, SM
   Rajput, DS
AF Basha, Syed Muzamil
   Rajput, Dharmendra Singh
TI A roadmap towards implementing parallel aspect level sentiment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; Aspects; Sarcasm; F-score; Latent Dirichlet
   allocation; Gibbs sampling; Rand index; Classification accuracy; Latent
   aspect rating regression; Root mean absolute error
ID REVIEWS; ALGORITHM
AB In the digital era, the importance of extracting the hidden sentiments from user reviews plays a prominent role, to increase the profitability of an organization. The interest among, the research community in Sentiment Analysis (SA) has grown exponentially. But there are enormous challenges still being faced in the field of SA namely: Identification of sarcasm/Irony/Conditional/Modifier statements present in the review, Identification of Aspects and sentiment word as a pair (Data Transformation), Rating the recognized Aspects towards predicting the overall aggregated sentiment, Analyzing and designing issues towards implementing the parallel Aspect Level sentiment. In the present research work, We have addressed each of this challenges using a serial hybridization model, Where, the output of each step, is input to the following stage. First, towards identification sarcasm. In which, the dictionary is updated with the set of sentiment words by manually crafted rules. Next, to mitigate the discovery of sentiment and aspect word pair. In which, Latent Dirichlet Allocation (LDA), Gibbs sampling techniques are used. Next, to present the result of sentiment analysis as the overall rating of data considered, Latent Aspect Rating Regression (LARR) model is proposed (Data Presentation). Finally, addressed the designing issues (deciding numbers of mappers and reducers needed) towards implementing the parallel Aspect Level sentiment Analysis with the objective of improving the resource utilization in Big Data clusters. This work can help the researchers doing research in the field of speech recognition, development of recommended systems. The evaluation Metric used in estimating the performance of each step in our research are F-score, Rand Index, Classification accuracy and Root Mean Absolute Error (RMAE), Throughput. The findings of our research work help the customer to directly use the result obtained from the proposed model in the form of Aspect level rating.
C1 [Basha, Syed Muzamil] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
   [Rajput, Dharmendra Singh] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of
   Technology (VIT); VIT Vellore
RP Rajput, DS (corresponding author), Vellore Inst Technol, Sch Informat Technol & Engn, Vellore 632014, Tamil Nadu, India.
EM muza.basha@gmail.com; dharmendrasingh@vit.ac.in
RI rajput, dharmendra/AAZ-3053-2021; Basha, Syed Muzamil/AAC-9313-2020
OI Basha, Syed Muzamil/0000-0002-1169-3151
CR [Anonymous], J MACHINE LEARNING R
   [Anonymous], 2014, P 8 INT WORKSH SEM E
   [Anonymous], IEEE T KNOWLEDGE DAT
   Bafna K, 2013, PROCEDIA COMPUT SCI, V22, P142, DOI 10.1016/j.procs.2013.09.090
   Balazs JA, 2016, INFORM FUSION, V27, P95, DOI 10.1016/j.inffus.2015.06.002
   Bamman David, 2015, ICWSM, V2, P15
   BASHA S.M., 2018, International Journal of Engineering & Technology, V7, P248
   Basha SM, 2018, HDB RES PATTERN ENG, P130
   Basha SM, 2019, SENTIMENT ANAL KNOWL, P148
   Basha SM, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY (ICIT 2017), P96, DOI 10.1145/3176653.3176665
   Basha SM, 2018, INT J GRID DISTRIB, V11, P41, DOI 10.14257/ijgdc.2018.11.2.05
   Bouk SH, 2017, IEEE COMMUN MAG, V55, P105, DOI 10.1109/MCOM.2017.1600230CM
   Bulkowski BJ, 2018, United States patent application, Patent No. [US 15/488,511, 15488511]
   Buschmeier K., 2014, P 5 WORKSH COMP APPR, P42
   Chan HW, 2004, LECT NOTES COMPUT SC, V2920, P154, DOI 10.1007/978-3-540-24606-0_11
   Charalampakis B, 2016, ENG APPL ARTIF INTEL, V51, P50, DOI 10.1016/j.engappai.2016.01.007
   Ganesan K, 2012, INFORM RETRIEVAL, V15, P116, DOI 10.1007/s10791-011-9174-8
   Guo Y, 2017, TOURISM MANAGE, V59, P467, DOI 10.1016/j.tourman.2016.09.009
   Hai Z, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P617, DOI 10.1145/2600428.2609570
   Hai Z, 2017, IEEE T KNOWL DATA EN, V29, P1172, DOI 10.1109/TKDE.2017.2669027
   Hai Z, 2014, IEEE T KNOWL DATA EN, V26, P623, DOI 10.1109/TKDE.2013.26
   Hirschberg J, 2015, SCIENCE, V349, P261, DOI 10.1126/science.aaa8685
   Hox JJ, 2017, MULTILEVEL ANAL TECH
   Huang S, 2014, KNOWL-BASED SYST, V56, P191, DOI 10.1016/j.knosys.2013.11.009
   Hutchins B, 2011, INFORM COMMUN SOC, V14, P237, DOI 10.1080/1369118X.2010.508534
   Ibrahim IA, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SMART CLOUD (SMARTCLOUD), P120, DOI 10.1109/SmartCloud.2017.25
   Joshi A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3124420
   Kaplan AM, 2010, BUS HORIZONS, V53, P59, DOI 10.1016/j.bushor.2009.09.003
   Karmiloff-Smith A., 2018, THINKING DEV, P64
   Kim Y, 2017, J COGN SCI, V18, P85
   Lau RYK, 2018, PROD OPER MANAG, V27, P1775, DOI 10.1111/poms.12737
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liu ZC, 2017, IEEE T VIS COMPUT GR, V23, P321, DOI 10.1109/TVCG.2016.2598797
   Mathwick C, 2017, J SERV RES-US, V20, P204, DOI 10.1177/1094670516682088
   McGranahan N, 2017, CELL, V168, P613, DOI 10.1016/j.cell.2017.01.018
   Morad T. Y., 2006, IEEE Computer Architecture Letters, V5, P14, DOI 10.1109/L-CA.2006.6
   Papadimitriou D, 2017, IEEE T KNOWL DATA EN, V29, P1860, DOI 10.1109/TKDE.2017.2699965
   Rajadesingan A, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P97, DOI 10.1145/2684822.2685316
   Reyes A, 2013, LANG RESOUR EVAL, V47, P239, DOI 10.1007/s10579-012-9196-x
   Saif H, 2016, INFORM PROCESS MANAG, V52, P5, DOI 10.1016/j.ipm.2015.01.005
   Smith AN, 2012, J INTERACT MARK, V26, P102, DOI 10.1016/j.intmar.2012.01.002
   Soleymani M, 2017, IMAGE VISION COMPUT, V65, P3, DOI 10.1016/j.imavis.2017.08.003
   Tang J., 2016, J COMPUT THEORET NAN, V13, P7705
   Tzoreff E, 2017, SIGNAL PROCESS, V133, P32, DOI 10.1016/j.sigpro.2016.10.015
   Venkatesh S, 1997, IEEE T SEMICONDUCT M, V10, P418, DOI 10.1109/66.641483
   Wang P, 2016, NEUROCOMPUTING, V174, P806, DOI 10.1016/j.neucom.2015.09.096
   You L, 2018, IEEE T KNOWL DATA EN
   You LL, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P3563, DOI 10.1109/BigData.2016.7841020
   You LL, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P693, DOI 10.1109/ASONAM.2016.7752312
NR 50
TC 18
Z9 18
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29463
EP 29492
DI 10.1007/s11042-018-7093-z
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700058
DA 2024-07-18
ER

PT J
AU Choi, S
   Youm, S
AF Choi, Seunghyun
   Youm, Sekyoung
TI A study on a fall detection monitoring system for falling elderly using
   open source hardware
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fall detection; Elder; Open source hardware; Monitoring
AB Due to the rapid increase in the elderly population and single-person households, it is absolutely necessary to observe the indoor activities of marginalized people, such as the elderly or the disabled, to detect abnormal conditions. At this time, contact sensors are have limited applicability due to their continuous wear, so there is a need to develop technology to collect daily life activities of the elderly. In this study, we tried to track the elderly living alone using images obtained from an open source camera. The system captures images by linking a low-cost camera module to open source hardware, and an algorithm is implemented to detect falls. This system can be used to reduce the cost of social care by improving the cost of care in the aging population, and this will contribute to promoting and developing management prescription guidelines through risk detection.
C1 [Choi, Seunghyun; Youm, Sekyoung] Dongguk Univ, Dept Ind & Syst Engn, 82-1 Pil Dong, Seoul, South Korea.
C3 Dongguk University
RP Youm, S (corresponding author), Dongguk Univ, Dept Ind & Syst Engn, 82-1 Pil Dong, Seoul, South Korea.
EM sekyoungyoum@gmail.com
FU Ministry of Land, Infrastructure and Transport in Korea
   [17CTAP-C114867-02]
FX This work was supported by the Ministry of Land, Infrastructure and
   Transport in Korea. (17CTAP-C114867-02)
CR [Anonymous], 2014, HLTH DAT 2013
   Choi K-S, 2015, J KOREA I INFORM ELE, V9, P9, DOI [10.17661/jkiiect.2016.9.1.009, DOI 10.17661/JKIIECT.2016.9.1.009]
   Kim CI, 2016, KOREAN J RES GERONTO, V25, P63
   Kim H-D, 2015, J KOREA ACAD IND COO, V15, P2743
   Kim J, 2003, 20033 NAT HLTH INS S
   Lee HT, 1994, J KOREAN ACAD FAMILY, V15, P273
   Park E. J., 2016, HLTH WELFARE POLICY, V10, P61
   Roach, 2001, INTRO GERONTOLOGICAL, P401
   Roelands M, 2011, ARCHITECTING THE INTERNET OF THINGS, P37
   Seung Hee You, 2017, [Journal of Digital Convergence, 디지털융복합연구], V15, P11, DOI 10.14400/JDC.2017.15.1.11
   TINETTI ME, 1988, NEW ENGL J MED, V319, P1701, DOI 10.1056/NEJM198812293192604
   진경찬, 2015, [Journal of Sensor Science and Technology, 센서학회지], V24, P299
   전병찬, 2008, [The Journal of The Institute of Internet, Broadcasting and Communication, 한국인터넷방송통신학회 논문지], V8, P41
   김종민, 2007, [KOREAN JOURNAL OF HEALTH EDUCATION AND PROMOTION, 보건교육건강증진학회지], V24, P23
NR 14
TC 3
Z9 4
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28423
EP 28434
DI 10.1007/s11042-017-5452-9
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700005
DA 2024-07-18
ER

PT J
AU Singh, A
   Chatterjee, K
AF Singh, Ashish
   Chatterjee, Kakali
TI ITrust: identity and trust based access control model for healthcare
   system security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EHS; Beta reputation approach; AHP method; ACM; User trust; ITrust
   model; Trust evidence parameter
ID CLOUD; MANAGEMENT
AB The patient and healthcare professionals use the Electronic Healthcare System (EHS) for accessing medical records from the remote locations via the Internet. The emerging healthcare system has several advantages such as better management of the healthcare data, streamlined collaboration, improvement of medical care, insurance purpose, medical data backup, etc. Regardless of its advantages, the sensitivity and openness nature of the healthcare system arises different type of attacks and threats such as insider attack, service hijacking, abuse use of healthcare data, and impersonation attack. In the EHS, without knowing the prior information of the requester, data sharing is another considerable issue. Hence, a dynamic Access Control Model (ACM) is needed to overcome the above-discussed issues. In the EHS, the addition of trust into the access control solutions can provide dynamic access to the resources. To achieve such a model, in this paper, we have added user trust into the Identity Based Access Control (IBAC) model. For the computation of user trust, we have used beta reputation approach. An access control rule set has been proposed based on the trust degree and identity of the user to provide access in a controlled manner. This hybrid ACM and rule set not only protect the data from unauthorized access but also dynamically control the access view of the healthcare data. The experimental result of the proposed model shows that it is more accurate and reliable as compared to other trust models.
C1 [Singh, Ashish; Chatterjee, Kakali] Natl Inst Technol, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Singh, A (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
EM ashish.cse15@nitp.ac.in; kakali@nitp.ac.in
RI SINGH, ASHISH/JBR-7750-2023; SINGH, ASHISH/AAA-5140-2019; Chatterjee,
   Kakali/AAC-3782-2019
OI Chatterjee, Kakali/0000-0003-3522-2044
CR [Anonymous], 2000, P INT SCH FDN SEC AN
   [Anonymous], USER BEHAV TRUST BAS
   Ardagna CA, 2010, COMPUT SECUR, V29, P848, DOI 10.1016/j.cose.2010.07.001
   Ashtiani M, 2016, SOFT COMPUT, V20, P399, DOI 10.1007/s00500-014-1516-1
   Bai Y, 2014, SECUR COMMUN NETW, V7, P574, DOI 10.1002/sec.759
   Balamurugan B, 2015, ADV INTELL SYST, V324, P837, DOI 10.1007/978-81-322-2126-5_89
   Banayal R. K., 2014, P 2014 INT C INF COM, P1
   Behera PK, 2017, LECT NOTES ELECTR EN, V395, P285, DOI 10.1007/978-81-322-3592-7_29
   Benantar M., 2006, ACCESS CONTROL SYSTE
   Bhattasali T, 2018, INT J SOFTW ENG KNOW, V28, P781, DOI 10.1142/S0218194018500225
   Chakraborty S., 2006, SACMAT 2006. Proceedings of Eleventh ACM Symposium on Access Control Models and Technologies, P49
   Deshpande S., 2018, INT J NETW SECUR, V20, P291
   Duan JQ, 2013, AD HOC NETW, V11, P2675, DOI 10.1016/j.adhoc.2013.05.005
   Fang WD, 2016, J NETW COMPUT APPL, V59, P88, DOI 10.1016/j.jnca.2015.06.013
   Hosseinpour Farhoud, 2018, Research and Practical Issues of Enterprise Information Systems. 11th IFIP WG 8.9 Working Conference, CONFENIS 2017. Revised Selected Papers. Lecture Notes in Business Information Processing (LNBIP 310), P168, DOI 10.1007/978-3-319-94845-4_15
   Josang A., 2002, P 15 BLED EL COMM C, V5, P2502
   Li XY, 2011, J PARALLEL DISTR COM, V71, P837, DOI 10.1016/j.jpdc.2011.01.007
   Lin GY, 2014, INT J COMPUT INT SYS, V7, P785, DOI 10.1080/18756891.2013.864479
   Lin GY, 2014, CHINA COMMUN, V11, P154, DOI 10.1109/CC.2014.6827577
   Liu Y, 2018, FUTURE GENER COMP SY, V78, P1020, DOI 10.1016/j.future.2016.12.027
   Manuel P, 2015, ANN OPER RES, V233, P281, DOI 10.1007/s10479-013-1380-x
   Narayanan H. A. J., 2011, 2011 IEEE Consumer Communications and Networking Conference (CCNC 2011), P247, DOI 10.1109/CCNC.2011.5766466
   Rostad L., 2009, ACCESS CONTROL HEALT
   Satsiou A, 2010, IEEE T PARALL DISTR, V21, P466, DOI 10.1109/TPDS.2009.80
   Senese S.V., 2015, A study of access control for electronic health records
   Servos D, 2017, ACM COMPUT SURV, V49, DOI 10.1145/3007204
   Teacy WTL, 2006, AUTON AGENT MULTI-AG, V12, P183, DOI 10.1007/s10458-006-5952-x
   Wang W, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0022993
   Willmott CJ, 2005, CLIMATE RES, V30, P79, DOI 10.3354/cr030079
   Xia H, 2011, IET WIREL SENS SYST, V1, P248, DOI 10.1049/iet-wss.2011.0042
   Yachana, 2018, TELEMAT INFORM, V35, P790, DOI 10.1016/j.tele.2017.09.008
   Younis YA, 2014, J INF SECUR APPL, V19, P45, DOI 10.1016/j.jisa.2014.04.003
   Yüksel B, 2017, FUTURE GENER COMP SY, V68, P1, DOI 10.1016/j.future.2016.08.011
   Zhang R, 2014, SECUR COMMUN NETW, V7, P994, DOI 10.1002/sec.817
NR 34
TC 11
Z9 11
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 28309
EP 28330
DI 10.1007/s11042-019-07923-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000068
DA 2024-07-18
ER

PT J
AU Wu, JJ
   Jiang, JG
   Qi, MB
   Liu, H
AF Wu, Jingjing
   Jiang, Jianguo
   Qi, Meibin
   Liu, Hao
TI Independent metric learning with aligned multi-part features for
   video-based person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video-based person re-identification; Aligned multi-part image model;
   Independent metric learning; Pedestrian alignment
AB Video-based person re-identification attracts wide attention because it plays a crucial role for many applications in the video surveillance. The task of video-based person re-identification is to match image sequences of the pedestrian recorded by non-overlapping cameras. Like many visual recognition problems, variations in pose, viewpoints, illumination, and occlusion make this task non-trivial. Aiming at increasing the robustness of features to variations and occlusion, this paper designs an aligned multi-part image model inspired by human visual attention mechanism. This model performs a pose estimation method to align the pedestrians. Then, it divides the images to extract multi-part appearance features. Besides, we present independent metric learning to combine the multi-part appearance and spatial-temporal features, which obtains several metric kernels by feeding these features into distance metric learning respectively. These kernels are fused with the weights learned by the attention measure. The novel way of features fusion can achieve better functional complementarity of these features. In experiments, we analyze the effectiveness of the major components. Extensive experiments on two public benchmark datasets, i.e., the iLIDS-VID and PRID-2011 datasets, demonstrate the effectiveness of the proposed method.
C1 [Wu, Jingjing; Jiang, Jianguo; Qi, Meibin; Liu, Hao] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230009, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Wu, JJ (corresponding author), Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230009, Anhui, Peoples R China.
EM hfutwujingjing@mail.hfut.edu.cn; jgjiang@hfut.edu.cn; qimeibin@163.com;
   hfut.haoliu@gmail.com
OI Wu, Jingjing/0000-0002-3818-4277
FU National Natural Science Foundation of China [61876056, 61771180]
FX This work is supported by the National Natural Science Foundation of
   China Grant 61876056 and Grant 61771180.
CR [Anonymous], 2017, ARXIV170206294
   [Anonymous], 2017, ARXIV170700798
   [Anonymous], 2016, ARXIV
   [Anonymous], 2016, ARXIV161106026
   [Anonymous], 2008, P BMVC 2008 19 BRIT
   Chen JX, 2016, IEEE SIGNAL PROC LET, V23, P998, DOI 10.1109/LSP.2016.2574323
   Cho YJ, 2016, PROC CVPR IEEE, P1354, DOI 10.1109/CVPR.2016.151
   CHU H, 2017, MULTIMED TOOLS APPL, P1
   Ferrari V, 2009, PROC CVPR IEEE, P1, DOI 10.1109/CVPRW.2009.5206495
   Gao CX, 2016, IEEE IMAGE PROC, P4284, DOI 10.1109/ICIP.2016.7533168
   Gordon C. C., 1989, TECH REP
   He L, 2017, IEEE INT CON MULTI, P1153, DOI 10.1109/ICME.2017.8019549
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Li YJ, 2017, IEEE COMPUT SOC CONF, P1454, DOI 10.1109/CVPRW.2017.188
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu H., 2017, IEEE T CIRCUITS SYST, V1, DOI [DOI 10.1109/TCSVT.2016.2637798, 10.1109/TCSVT.2016.2637798]
   Liu K, 2015, IEEE I CONF COMP VIS, P3810, DOI 10.1109/ICCV.2015.434
   Liu Z, 2016, IEEE IMAGE PROC, P4294, DOI 10.1109/ICIP.2016.7533170
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Ramanan D., 2007, Advances in Neural Information Processing Systems, V19, P1129
   Song ZT, 2017, 2017 IEEE 2ND ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P2020, DOI 10.1109/IAEAC.2017.8054370
   Sutong Zheng, 2017, 2017 IEEE International Conference on Multimedia and Expo: Workshops (ICMEW), P674, DOI 10.1109/ICMEW.2017.8026267
   Varior Rahul Rama, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Wang TQ, 2016, IEEE T PATTERN ANAL, V38, P2501, DOI 10.1109/TPAMI.2016.2522418
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507
   Xu X, 2019, WORLD WIDE WEB, V22, P657, DOI 10.1007/s11280-018-0541-x
   Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261
   You JJ, 2016, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2016.150
   Zhang W., 2017, IEEE T INSTRUM MEAS, V99, P1, DOI [DOI 10.1109/TCSVT.2017.2718188, DOI 10.1109/TCSVT.2017.2718225]
   Zhang W, 2018, NEUROCOMPUTING, V275, P781, DOI 10.1016/j.neucom.2017.09.012
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zheng L., 2017, IEEE T IMAGE PROCESS
   Zhou Z, 2017, PROC CVPR IEEE, P6776, DOI 10.1109/CVPR.2017.717
   Zhu JB, 2018, IEEE T ENERGY CONVER, V33, P773, DOI 10.1109/TEC.2017.2764089
   Zhu Xiangyu, 2017, IEEE Transactions on Pattern Analysis and Machine Intelligence, DOI [DOI 10.1109/TPAMI.2017.2778152, DOI 10.1109/TBDATA.2017.2736547]
   Zhu Xiaoke., 2016, Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, P3552
NR 40
TC 5
Z9 8
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29323
EP 29341
DI 10.1007/s11042-018-7119-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700050
DA 2024-07-18
ER

PT J
AU Li, XL
   Li, DQ
   Peng, L
   Zhou, HB
   Chen, D
   Zhang, YD
   Xie, L
AF Li, Xiaolin
   Li, Daoqing
   Peng, Li
   Zhou, Huabing
   Chen, Deng
   Zhang, Yanduo
   Xie, Liang
TI Color and depth image registration algorithm based on
   multi-vector-fields constraints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EM algorithm; Image registration; Depth image; Multi-vector-fields
   constraints
ID FUSION; MODEL
AB Image registration, which aim to establish a reliable feature relationship between images, is a critical problem in the field of image processing. In order to enhance the accuracy of color and depth image registration, this paper proposes an novel image registration algorithm based on multi-vector-fields constraints. We first initialize the edge information features of color and depth images, and establish putative correspondences based on edge information. Consider the correlation between the images, establish the functional relationships of the multi-vector-fields constraints based on the relationships. In the reproducing nuclear Hilbert space (RKHS), this constraint is added to the probability model, and the model parameters are optimized using the EM algorithm. Finally, the probability of corresponding edge points of the image is obtained. In order to further improve registration accuracy, this paper will change the input from one pair to two pairs and let the feature transformation relationship between images be iteratively evaluated using the parameter model. Taking publicly available RGB-D images as experimental subjects, results show that for single object image registration, the algorithm image registration accuracy in this paper is improved by about 5% compared with SC, ICP, and CPD algorithms. In addition, artificial noise was used to test the proposed algorithm's anti-noise ability, results show that the proposed algorithm has superior anti-noise ability relative to SC, ICP and CPD algorithms.
C1 [Li, Xiaolin; Li, Daoqing; Peng, Li; Zhou, Huabing; Chen, Deng; Zhang, Yanduo] Wuhan Inst Technol, Hubei Key Lab Intelligent Robot, Wuhan, Hubei, Peoples R China.
   [Xie, Liang] Wuhan Univ Techonol, Dept Math, Wuhan, Hubei, Peoples R China.
C3 Wuhan Institute of Technology; Wuhan University of Technology
RP Zhou, HB (corresponding author), Wuhan Inst Technol, Hubei Key Lab Intelligent Robot, Wuhan, Hubei, Peoples R China.
EM zhouhuabing@gmail.com
RI liu, mengjie/KDN-1890-2024; zhen, li/KGK-6604-2024
OI Chen, Deng/0000-0001-6359-801X; Zhou, Huabing/0000-0001-5007-7303
FU National Natural Science Foundation of China [41501505, 61771353];
   Natural Science Foundation of China Open University [G16F2505Q,
   G16F3702Z]; 13th Five Year National Key R&D Project in China "The Hybrid
   Cloud-based Ubiquitous Location Awareness and Information Overlay
   Protoco" [2017YFB0503701]; Open Fund of the Key Laboratory of
   Intelligent Robotics of Hubei Province [HBIR201601]; Research Center of
   Artificial Intelligence, Yunnan Open University [2018JS373]; Scientific
   Research Project of Education Department of Hubei Province [20181508]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 41501505 and 61771353, Natural Science
   Foundation of China Open University (G16F2505Q, G16F3702Z), 13th Five
   Year National Key R&D Project in China "The Hybrid Cloud-based
   Ubiquitous Location Awareness and Information Overlay Protoco"
   2017YFB0503701, the Open Fund of the Key Laboratory of Intelligent
   Robotics of Hubei Province (HBIR201601) and Research Center of
   Artificial Intelligence, Yunnan Open University(No. 2018JS373)
   Scientific Research Project of Education Department of Hubei
   Province(No. 20181508).
CR Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221
   Essmaeel K, 2015, MULTIMED TOOLS APPL, V74, P7331, DOI 10.1007/s11042-014-1982-6
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Foulley JL, 2000, GENET SEL EVOL, V32, P143, DOI 10.1051/gse:2000111
   Hill DLG, 2001, PHYS MED BIOL, V46, pR1, DOI 10.1088/0031-9155/46/3/201
   Jackson BP, 2010, IEEE T IMAGE PROCESS, V19, P795, DOI 10.1109/TIP.2009.2036668
   Jing PG, 2019, IEEE T CIRC SYST VID, V29, P1296, DOI 10.1109/TCSVT.2018.2832095
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Jorge-Peñas A, 2017, BIOMATERIALS, V136, P86, DOI 10.1016/j.biomaterials.2017.05.015
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Ma JY, 2017, INFORM SCIENCES, V417, P128, DOI 10.1016/j.ins.2017.07.010
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Ma JY, 2016, IEEE T IMAGE PROCESS, V25, P53, DOI 10.1109/TIP.2015.2467217
   Ma JY, 2015, IEEE T GEOSCI REMOTE, V53, P6469, DOI 10.1109/TGRS.2015.2441954
   Ma JY, 2015, IEEE T SIGNAL PROCES, V63, P1115, DOI 10.1109/TSP.2014.2388434
   Ma JY, 2015, PATTERN RECOGN, V48, P772, DOI 10.1016/j.patcog.2014.09.005
   Ma JY, 2014, IEEE T IMAGE PROCESS, V23, P1706, DOI 10.1109/TIP.2014.2307478
   Ma JY, 2013, PATTERN RECOGN, V46, P3519, DOI 10.1016/j.patcog.2013.05.017
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Zhou H, 2018, IEEE ACCESS, V7
   Zhou HB, 2016, IEEE GEOSCI REMOTE S, V13, P374, DOI 10.1109/LGRS.2016.2514521
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 27
TC 7
Z9 7
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24301
EP 24319
DI 10.1007/s11042-018-7048-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900028
DA 2024-07-18
ER

PT J
AU Ponuma, R
   Amutha, R
   Aparna, S
   Gopal, G
AF Ponuma, R.
   Amutha, R.
   Aparna, S.
   Gopal, Gayatri
TI Visually meaningful image encryption using data hiding and chaotic
   compressive sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic maps; Compressive sensing; Cover image; Data hiding; Secret
   image; Image encryption; Image compression; Visually secure
ID ALGORITHM
AB A visually secure multiple image encryption using chaotic map and compressive sensing is proposed. The existing image encryption algorithms transform a secret image into a random noise like cipher image which can lead to cryptanalysis by an intruder. In the proposed method, compressive sampling is done using a chaos based, key controlled measurement matrix. An image dependent key generation scheme is used to generate the parameters of the chaotic map. The secret images are transformed into wavelet coefficients, and scrambled along a zigzag path, so that the high correlation among them can be reduced and thereby provide increased security level. The sparse coefficients are measured using the chaotic map-based measurement matrix, whose initial parameters are obtained from the keys generated. Then the reduced measurements are embedded into the sub-bands of the wavelet transformed cover image. Therefore, the proposed algorithm is highly sensitive to the secret images and can effectively withstand known-plaintext and chosen-plaintext attacks. Additionally, the cipher image and the secret images are of same size and do not require additional transmission bandwidth and storage space.
C1 [Ponuma, R.; Amutha, R.; Aparna, S.; Gopal, Gayatri] SSN Coll Engn, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
C3 SSN College of Engineering
RP Ponuma, R (corresponding author), SSN Coll Engn, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
EM ponumar@ssn.edu.in
RI Amutha, R./AAB-9399-2020
CR Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Cao XW, 2017, J VIS COMMUN IMAGE R, V44, P236, DOI 10.1016/j.jvcir.2016.08.003
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Hu GQ, 2017, J VIS COMMUN IMAGE R, V44, P116, DOI 10.1016/j.jvcir.2017.01.022
   Kanso A, 2017, OPT LASER ENG, V90, P196, DOI 10.1016/j.optlaseng.2016.10.009
   Li MF, 2018, INT J DIGIT MULTIMED, V2018, DOI 10.1155/2018/2619438
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Ponuma R, 2018, STUD COMPUT INTELL, V730, P373, DOI 10.1007/978-3-319-63754-9_17
   Ponuma R, 2018, MULTIMED TOOLS APPL, V77, P19209, DOI 10.1007/s11042-017-5378-2
   Ponuma R, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P172, DOI 10.1109/WiSPNET.2016.7566114
   Singh LD, 2018, ARAB J SCI ENG, V43, P7397, DOI 10.1007/s13369-018-3104-7
   Sreedhanya AV, 2013, Bonfring Int J Adv Image Process, V3, P1
   Thanki R, 2017, IMAGING SCI J, V65, P457, DOI 10.1080/13682199.2017.1367129
   Wang H, 2019, SIGNAL PROCESS, V155, P218, DOI 10.1016/j.sigpro.2018.10.001
   Wen WY, 2018, NEURAL COMPUT APPL, V29, P653, DOI 10.1007/s00521-016-2490-6
   Xiao D, 2016, MULTIMED TOOLS APPL, V75, P13779, DOI 10.1007/s11042-015-2922-9
   Xiao MY, 2015, PROC SPIE, V9811, DOI 10.1117/12.2205279
   Yu L, 2010, IEEE SIGNAL PROC LET, V17, P731, DOI 10.1109/LSP.2010.2052243
   Zhang D, 2018, MULTIMED TOOLS APPL, V77, P2191, DOI 10.1007/s11042-017-4370-1
   Zhang YS, 2016, NEUROCOMPUTING, V205, P472, DOI 10.1016/j.neucom.2016.04.053
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
NR 21
TC 26
Z9 26
U1 2
U2 85
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25707
EP 25729
DI 10.1007/s11042-019-07808-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700022
DA 2024-07-18
ER

PT J
AU Yang, ZJ
   Huang, P
   Wan, MH
   Zhan, TM
   Zhang, FL
   Luo, LM
AF Yang, Zhangjing
   Huang, Pu
   Wan, Minghua
   Zhan, Tianming
   Zhang, Fanlong
   Luo, Limin
TI Discriminant maximum margin projections for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dimensionality reduction; Face recognition; Locality preserving
   projections; Discriminant maximum margin projections
ID DIMENSIONALITY REDUCTION; REGULARIZATION; EIGENFACES; EXTRACTION
AB In this paper, we propose a novel dimensionality reduction algorithm called discriminant maximum margin projections (DMMP) for face recognition. By discovering both geometrical and discriminant structures of the data points, DMMP aims at finding a subspace that optimally preserves the local neighborhood information of the data set, as well as maximizes the margin between data points from different classes at each local area. Moreover, DMMP utilizes a equilibrium parameter to adjust the significance of the locality preserving property and margin distances of the data points. Finally, with the experiments used face recognition data sets, such as the ORL, Yale, and FERET face databases, the results prove that DMMP can attain a better effectiveness than most other advanced approaches.
C1 [Yang, Zhangjing; Luo, Limin] Southeast Univ, Sch Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China.
   [Yang, Zhangjing; Wan, Minghua; Zhan, Tianming; Zhang, Fanlong] Nanjing Audit Univ, Sch Technol, Nanjing, Jiangsu, Peoples R China.
   [Yang, Zhangjing; Huang, Pu] Nanjing Univ Sci & Technol, Jiangsu Key Lab Image & Video Understanding Socia, Nanjing, Jiangsu, Peoples R China.
   [Yang, Zhangjing] Minjiang Univ, 2011 Collaborat Innovat Ctr Internet Things Techn, Fuzhou, Fujian, Peoples R China.
   [Huang, Pu] Nanjing Univ Posts & Telecommun, Sch Comp Sci & Technol, Nanjing, Jiangsu, Peoples R China.
C3 Southeast University - China; Nanjing Audit University; Nanjing
   University of Science & Technology; Minjiang University; Nanjing
   University of Posts & Telecommunications
RP Yang, ZJ (corresponding author), Southeast Univ, Sch Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China.; Yang, ZJ (corresponding author), Nanjing Audit Univ, Sch Technol, Nanjing, Jiangsu, Peoples R China.; Yang, ZJ (corresponding author), Nanjing Univ Sci & Technol, Jiangsu Key Lab Image & Video Understanding Socia, Nanjing, Jiangsu, Peoples R China.; Yang, ZJ (corresponding author), Minjiang Univ, 2011 Collaborat Innovat Ctr Internet Things Techn, Fuzhou, Fujian, Peoples R China.
EM yzzjjj@126.com; hangpu3355@163.com; wmh36@sina.com; ztm@nau.edu.cn;
   csfzhang@nau.edu.cn; luo.list@seu.edu.cn
FU China Postdoctoral Science Foundation [2017 M611656]; National Natural
   Science Fund of China [61502206, 61503195, 61462064, 61203243, 61603192,
   61402231]; Natural Science Fund of Jiangsu Province [BK20150523,
   BK20161580]; University Natural Science Fund of Jiangsu Province of
   China [16KJB520020]; Jiangsu Key Laboratory of Image and Video
   Understanding for Social Safety (Nanjing University of Science and
   Technology) [30916014107]; 2011 Collaborative Innovation Center of
   Internet of Things Technology and Intelligent Systems(Minjiang
   University)
FX This research was supported by China Postdoctoral Science Foundation
   funded project (Grant Nos. 2017 M611656), the National Natural Science
   Fund of China (Grant Nos. 61502206, 61503195, 61462064, 61203243,
   61603192, 61402231), the Natural Science Fund of Jiangsu Province (Grant
   No. BK20150523 and BK20161580), the University Natural Science Fund of
   Jiangsu Province of China (Grant No. 16KJB520020), the Project supported
   by the Jiangsu Key Laboratory of Image and Video Understanding for
   Social Safety (Nanjing University of Science and Technology) (Grant No.
   30916014107), and 2011 Collaborative Innovation Center of Internet of
   Things Technology and Intelligent Systems(Minjiang University).
CR Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Cai LJ, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P708
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Dai DQ, 2003, PATTERN RECOGN, V36, P845, DOI 10.1016/S0031-3203(02)00092-4
   He XF, 2004, ADV NEUR IN, V16, P153
   Howland P, 2006, PATTERN RECOGN, V39, P277, DOI 10.1016/j.patcog.2005.06.013
   Howland P, 2004, IEEE T PATTERN ANAL, V26, P995, DOI 10.1109/TPAMI.2004.46
   Huang P, 2016, DIGIT SIGNAL PROCESS, V55, P78, DOI 10.1016/j.dsp.2016.05.001
   Huang P, 2016, NEUROCOMPUTING, V190, P50, DOI 10.1016/j.neucom.2016.01.001
   Huang P, 2015, COMPUT ELECTR ENG, V46, P231, DOI 10.1016/j.compeleceng.2015.03.013
   Huang P, 2015, AEU-INT J ELECTRON C, V69, P1724, DOI 10.1016/j.aeue.2015.08.009
   Jiang XD, 2008, IEEE T PATTERN ANAL, V30, P383, DOI 10.1109/TPAMI.2007.70708
   Lai ZH, 2014, IEEE T NEUR NET LEAR, V25, P1942, DOI 10.1109/TNNLS.2013.2297381
   Lai ZH, 2014, IEEE T NEUR NET LEAR, V25, P1779, DOI 10.1109/TNNLS.2013.2295717
   Li JB, 2008, INFORM SCIENCES, V178, P1825, DOI 10.1016/j.ins.2007.12.001
   Li ZC, 2014, IEEE T KNOWL DATA EN, V26, P2138, DOI 10.1109/TKDE.2013.65
   Li ZC, 2013, COMPUT VIS IMAGE UND, V117, P1175, DOI 10.1016/j.cviu.2013.04.003
   Mandal B, 2010, PATTERN RECOGN LETT, V31, P717, DOI 10.1016/j.patrec.2009.10.006
   Qian JJ, 2013, IEEE T IMAGE PROCESS, V22, P3591, DOI 10.1109/TIP.2013.2264676
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sugiyama M, 2007, J MACH LEARN RES, V8, P1027
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang ZJ, 2013, INT SYM COMPUT INTEL, P116, DOI 10.1109/ISCID.2013.36
   Ye JP, 2005, IEEE T KNOWL DATA EN, V17, P1208, DOI 10.1109/TKDE.2005.148
   Ye JP, 2004, IEEE T PATTERN ANAL, V26, P982, DOI 10.1109/TPAMI.2004.37
   Yu WW, 2006, IMAGE VISION COMPUT, V24, P239, DOI 10.1016/j.imavis.2005.11.006
   Zhang HG, 2010, MACH VISION APPL, V21, P577, DOI 10.1007/s00138-009-0213-z
   Zhao HT, 2006, PATTERN RECOGN, V39, P1546, DOI 10.1016/j.patcog.2006.02.023
NR 31
TC 4
Z9 5
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 23847
EP 23865
DI 10.1007/s11042-018-6242-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900004
DA 2024-07-18
ER

PT J
AU Zeng, FC
   Xu, JL
AF Zeng, Fancong
   Xu, Jinli
TI Multimedia document image retrieval based on regional correlation fusion
   texture feature FDPC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Denoising; Texture characteristic; Resource retrieval; Image retrieval;
   Density peak
AB In order to realize the retrieval efficiency and detection precision of digital library collection resources, a new clustering algorithm (Fast density peak clustering,FDPC) based on fast texture density peak is proposed. Firstly, a framework of document image retrieval based on content description is given, based on median filter and direct-square equalization strategy, denoising and background processing of input document image are introduced, then density peak clustering (DPC) is used to classify image, and the convergence performance of DPC algorithm is improved by using dynamic truncation distance mode. Finally, based on the library standard test library (Corel), the performance of the proposed algorithm is validated experimentally, and the experimental results show that the proposed method has higher retrieval efficiency and retrieval accuracy.
C1 [Zeng, Fancong; Xu, Jinli] Wuhan Univ Technol, Luoshi Rd 122, Wuhan 430070, Hubei, Peoples R China.
C3 Wuhan University of Technology
RP Zeng, FC (corresponding author), Wuhan Univ Technol, Luoshi Rd 122, Wuhan 430070, Hubei, Peoples R China.
EM zfcong2018@163.com
CR Acharya UR, 2019, FUTURE GENER COMP SY, V91, P290, DOI 10.1016/j.future.2018.08.044
   Alaei F, 2016, INT CONF IMAG VIS, P128
   [Anonymous], 2018, CAAI T INTELL TECHNO
   Armelao L, 2006, COORDIN CHEM REV, V250, P1294, DOI 10.1016/j.ccr.2005.12.003
   Benjamin R, 2001, IEE P-RADAR SON NAV, V148, P233, DOI 10.1049/ip-rsn:20010421
   Brand C, 2007, MOL VIS, V13, P920
   Fu Y, 2012, INT C INT HUM MACH S, P352
   Kim JS, 2000, NEURAL NETWORKS FOR SIGNAL PROCESSING X, VOLS 1 AND 2, PROCEEDINGS, P497, DOI 10.1109/NNSP.2000.890126
   Mahdi FA, 2012, PRICAI 2012 TRENDS A, P765
   Manzotti R, 2001, COMPUT VIS IMAGE UND, V83, P97, DOI 10.1006/cviu.2001.0924
   OGURA Y, 1971, MON WEATHER REV, V99, P895, DOI 10.1175/1520-0493(1971)099<0895:NSOTLC>2.3.CO;2
   Oh SL, 2020, NEURAL COMPUT APPL, V32, P10927, DOI 10.1007/s00521-018-3689-5
   Qian C., 2018, INTELL TECHNOL, V3, P18, DOI DOI 10.1049/trit.2018.0007
   Shawi RE, 2008, IM VIS COMP NZ 2008, P1
   Yang XF, 2016, INT CONF SIGN PROCES, P1353, DOI 10.1109/ICSP.2016.7878047
NR 15
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24023
EP 24034
DI 10.1007/s11042-019-7161-z
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900012
DA 2024-07-18
ER

PT J
AU Brahimi, S
   Ben Aoun, N
   Benoit, A
   Lambert, P
   Ben Amar, C
AF Brahimi, Sourour
   Ben Aoun, Najib
   Benoit, Alexandre
   Lambert, Patrick
   Ben Amar, Chokri
TI Semantic segmentation using reinforced fully convolutional densenet with
   multiscale kernel
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic Segmentation; Fully Convolutional DenseNet; Wider Dense Block;
   MultiScale kernel prediction
ID VIDEO; RECOGNITION
AB In recent years, semantic segmentation has become one of the most active tasks of the computer vision field. Its goal is to group image pixels into semantically meaningful regions. Deep learning methods, in particular those who use convolutional neural network (CNN), have shown a big success for the semantic segmentation task. In this paper, we will introduce a semantic segmentation system using a reinforced fully convolutional densenet with multiscale kernel prediction method. Our main contribution is to build an encoder-decoder based architecture where we increase the width of dense block in the encoder part by conducting recurrent connections inside the dense block. The resulting network structure is called wider dense block where each dense block takes not only the output of the previous layer but also the initial input of the dense block. These recurrent structure emulates the human brain system and helps to strengthen the extraction of the target features. As a result, our network becomes deeper and wider with no additional parameters used because of weights sharing. Moreover, a multiscale convolutional layer has been conducted after the last dense block of the decoder part to perform model averaging over different spatial scales and to provide a more flexible method. This proposed method has been evaluated on two semantic segmentation benchmarks: CamVid and Cityscapes. Our method outperforms many recent works from the state of the art.
C1 [Brahimi, Sourour; Ben Aoun, Najib; Ben Amar, Chokri] Univ Sfax, Natl Engn Sch Sfax ENIS, REGIM Lab REsearch Grp Intelligent Machines, BP 1173, Sfax 3038, Tunisia.
   [Ben Aoun, Najib] Al Baha Univ, Coll Comp Sci & Informat Technol, Dept Comp Sci, Al Baha, Saudi Arabia.
   [Benoit, Alexandre; Lambert, Patrick] Univ Savoie Mt Blanc, LISTIC, Polytech Annecy Chambery, LISTIC Lab, 5 Ch Bellevue, F-74940 Annecy, France.
   [Ben Amar, Chokri] Taif Univ, Dept Comp Engn, Coll Comp & Informat Technol, At Taif, Saudi Arabia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS); Al Baha
   University; Universite Savoie Mont Blanc; Taif University
RP Ben Aoun, N (corresponding author), Univ Sfax, Natl Engn Sch Sfax ENIS, REGIM Lab REsearch Grp Intelligent Machines, BP 1173, Sfax 3038, Tunisia.; Ben Aoun, N (corresponding author), Al Baha Univ, Coll Comp Sci & Informat Technol, Dept Comp Sci, Al Baha, Saudi Arabia.
EM sourour.brahimi.TN@ieee.org; najib.benaoun@ieee.org;
   alexandre.benoit@univ-smb.fr; patrick.lambert@univ-smb.fr;
   chokri.benamar@ieee.org
RI BEN AOUN, Najib/Q-6414-2019; Chokri, BEN AMAR/K-5237-2012
OI BEN AOUN, Najib/0000-0001-9444-8209; benoit,
   alexandre/0000-0002-0627-4948
FU Ministry of Higher Education and Scientific Research of Tunisia
   [LR11ES48]
FX The research leading to these results has received funding from the
   Ministry of Higher Education and Scientific Research of Tunisia under
   the grant agreement number LR11ES48. LISTIC experiments have been made
   possible thanks to the MUST computing center of the University of Savoie
   Mont Blanc.
CR Abadi M., 2016, TENSORFLOW LARGE SCA, P3243
   [Anonymous], 2015, ARXIV151100561
   [Anonymous], ICMV
   [Anonymous], 2016, ENET DEEP NEURAL NET
   [Anonymous], ARXIV170103056V2
   [Anonymous], ARXIV 1608 06993V3
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.492
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], SMC
   [Anonymous], 2016, INT C LEARNING REPRE
   [Anonymous], BRIT MACH VIS C
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   [Anonymous], ICASSP
   [Anonymous], ARXIV150500393V3
   [Anonymous], 2015, PROCIEEE CONFCOMPUT
   [Anonymous], 2016, P 24 ACM INT C MULT
   [Anonymous], 2014, ARXIV160600915
   [Anonymous], 2018, J WSCG, DOI DOI 10.24132/JWSCG.2018.26.2.5
   Audebert N, 2017, LECT NOTES COMPUT SC, V10111, P180, DOI 10.1007/978-3-319-54181-5_12
   Batenburg KJ, 2009, IEEE T MED IMAGING, V28, P676, DOI 10.1109/TMI.2008.2010437
   Batenburg KJ, 2009, PATTERN RECOGN, V42, P2297, DOI 10.1016/j.patcog.2008.11.027
   Ben Ahmed O, 2015, MULTIMED TOOLS APPL, V74, P1249, DOI 10.1007/s11042-014-2123-y
   Ben Aoun Najib, 2011, 2011 International Conference on Innovations in Information Technology (IIT), P114, DOI 10.1109/INNOVATIONS.2011.5893799
   Ben Aoun N, 2012, ADVANCES IN WAVELET THEORY AND THEIR APPLICATIONS IN ENGINEERING, PHYSICS AND TECHNOLOGY, P23
   Ben Aoun N, 2014, J VIS COMMUN IMAGE R, V25, P329, DOI 10.1016/j.jvcir.2013.11.003
   Ben Aoun N, 2011, LECT NOTES COMPUT SC, V6855, P324, DOI 10.1007/978-3-642-23678-5_38
   Ben Aoun N, 2010, INT CONF SIGN PROCES, P1121, DOI 10.1109/ICOSP.2010.5655869
   Boughrara H, 2012, INT CONF MULTIMED, P233, DOI 10.1109/ICMCS.2012.6320263
   Brahimi S, 2019, NEUROCOMPUTING, V330, P337, DOI 10.1016/j.neucom.2018.11.031
   Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005
   Cordts M, 2015, CVPR WORKSHOP FUTURE, V2, P1
   Dong J, 2017, IEEE SYS MAN CYBERN, P450, DOI 10.1109/SMC.2017.8122646
   El'Arbi M, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1577, DOI 10.1109/ICME.2006.262846
   Fabijanska A, 2014, IET IMAGE PROCESS, V8, P239, DOI 10.1049/iet-ipr.2013.0104
   Garcia-Garcia A., 2017, ARXIV170406857
   Guedri Boulbaba, 2011, 2011 International Conference on High Performance Computing & Simulation, P369
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jégou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Kendall A, 2015, ARXIV 1511 02680
   Lai SW, 2015, AAAI CONF ARTIF INTE, P2267
   Lin J, 2017, METHODS MOL BIOL, V1592, P1, DOI 10.1007/978-1-4939-6925-8_1
   Mejdoub M, 2008, INT WORK CONTENT MUL, P349
   Mejdoub M, 2015, INTELL DATA ANAL, V19, P75, DOI 10.3233/IDA-140697
   Othmani M, 2010, INT J WAVELETS MULTI, V8, P149, DOI 10.1142/S0219691310003353
   Pourian N, 2015, IEEE I CONF COMP VIS, P1359, DOI 10.1109/ICCV.2015.160
   Qin AK, 2010, IEEE T IMAGE PROCESS, V19, P2157, DOI 10.1109/TIP.2010.2045708
   Raza SH, 2013, PROC CVPR IEEE, P3081, DOI 10.1109/CVPR.2013.396
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K., 2014, 14091556 ARXIV
   Tieleman T., 2012, COURSERA NEURAL NETW
   Visin F, 2016, IEEE COMPUT SOC CONF, P426, DOI 10.1109/CVPRW.2016.60
   Wali A, 2010, LECT NOTES COMPUT SC, V6475, P110, DOI 10.1007/978-3-642-17691-3_11
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang C, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3115432
   Wang C, 2016, IEEE IJCNN, P1924, DOI 10.1109/IJCNN.2016.7727435
   Wang C, 2015, PROC INT C TOOLS ART, P234, DOI 10.1109/ICTAI.2015.45
   Wu Zifeng, 2016, CoRR
   Zhang K, 2014, AAAI CONF ARTIF INTE, P2867
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zou WB, 2012, IEEE IMAGE PROC, P2577, DOI 10.1109/ICIP.2012.6467425
NR 62
TC 9
Z9 10
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 22077
EP 22098
DI 10.1007/s11042-019-7430-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400067
DA 2024-07-18
ER

PT J
AU Gu, YY
   Yang, HM
   Yan, B
   Wang, XD
   Zhao, ZY
AF Gu, Yuying
   Yang, Hongmei
   Yan, Bin
   Wang, Xiaodong
   Zhao, Zhongying
TI Digital image self-recovery algorithm based on improved joint
   source-channel coding optimizer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image authentication recovery; SPIHT coding; RS coding; Quadtree
   decomposition
ID WATERMARKING; PROTECTION
AB The purpose of the digital image self-recovery is to restore high quality images as much as possible when the image is tampered. Existing algorithms can only achieve high recovered image quality with tiny tampering rate. To obtain high recovered image quality with large tampering rate, this paper proposes a digital image self-recovery algorithm based on improved JSCC (Joint Source-Channel Coding) optimizer. The algorithm performs quadtree decomposition of original grayscale image corresponding to different decomposition factors gamma and performs bit-plane layering according to the block class obtained by quadtree decomposition. Size of each bit-plane is the number of pixels of each block class. Then, the original image is compressed by SPIHT, and the compressed bit-stream of SPIHT is segmented into bit-plane according to the size in order. The bit-planes are protected by different RS (Reed-Solomon) coders to get optimal decomposition result of corresponding gamma. Finally, JSCC optimization is designed to get an optimal quality of recovered image. Experimental results show that, using our algorithm, for 2-LSB embedding, when the tampering rate is less the minimum TTR (Tolerable Tempering Rate), the PSNR is improved by 4.93dB. When the tampering rate is larger the minimum TTR, the PSNR is improved by 2dB. When 3-LSB watermark are embedded, the PSNR of recovered image is improved by 2.58dB on average. It shows that our improved optimizer effectively improves the quality of the recovered image at high tampering rates, compared with the similar algorithms.
C1 [Gu, Yuying; Yang, Hongmei; Zhao, Zhongying] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Shandong, Peoples R China.
   [Yan, Bin] Shandong Univ Sci & Technol, Coll Elect Commun & Phys, Qingdao 266590, Shandong, Peoples R China.
   [Wang, Xiaodong] Shandong Univ Sci & Technol, Coll Mat Sci & Engn, Qingdao 266590, Shandong, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology; Shandong University of Science & Technology
RP Yang, HM (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Shandong, Peoples R China.
EM yhm1998@163.com
RI wang, xiao/HZI-9156-2023; Yan, Bin/Y-7642-2019; zhao,
   zhongying/V-6991-2019
OI Zhao, Zhongying/0000-0002-5880-0225; Yan, Bin/0000-0003-2929-464X
FU National Statistical Research of China [2015LZ59]; Key Projects of
   National Natural Science Foundation of China [61433012]; Qingdao
   Scientific Development Plan of China [KJZD-13-28-JCH]; Natural Science
   Foundation of Shandong Province of China [ZR2014JL044]
FX This work was funded by National Statistical Research of China (No.
   2015LZ59), Key Projects of National Natural Science Foundation of China
   (No. 61433012), Qingdao Scientific Development Plan of China (No.
   KJZD-13-28-JCH), Natural Science Foundation of Shandong Province of
   China (No. ZR2014JL044). The authors is deeply grateful to everyone who
   contributed to this work, including the respectable reviewers for
   constructive comments, editors' hard working, Mrs Yang for theoretical
   supporting, structural construction, experimental analysis and logical
   expression, Mr Yan for language editing and writing assistance, Mr Wang
   for technical editing, Mr Yan, Mrs Zhao and Mrs Yang for helping with
   acquisition of funding.
CR Baig N, 2016, IEEE SIGNAL PROC LET, V23, P853, DOI 10.1109/LSP.2016.2559805
   Chen C, 2018, IEEE COMMUN LETT, V22, P672, DOI 10.1109/LCOMM.2018.2804382
   Chung HW, 2017, JOURNAL, P1
   Dadkhah S, 2014, SIGNAL PROCESS-IMAGE, V29, P1197, DOI 10.1016/j.image.2014.09.001
   Du L., 2016, SCI CHINA, V59, P1, DOI 10.1007/s11432-016-5542-8
   Fridrich J., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P792, DOI 10.1109/ICIP.1999.817228
   He HJ, 2009, SIGNAL PROCESS, V89, P1557, DOI 10.1016/j.sigpro.2009.02.009
   Jin L., 2018, IEEE Transactions on Industrial Informatics PP, V99, P1
   Korus P, 2011, IEEE INT C IM PROC, P2765
   Korus P, 2013, IEEE T IMAGE PROCESS, V22, P1134, DOI 10.1109/TIP.2012.2227769
   Liu M, 2019, IEEE T IMAGE PROCESS, V28, P1235, DOI 10.1109/TIP.2018.2875363
   Liu ZH, 2016, SIGNAL PROCESS, V123, P157, DOI 10.1016/j.sigpro.2015.10.023
   Nie L., 2016, Synthesis Lectures on Information Concepts Retrieval & Services, V8, P1, DOI 10.2200/S00714ED1V01Y201603ICR048
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Qian ZX, 2016, IEEE SIGNAL PROC LET, V23, P1672, DOI 10.1109/LSP.2016.2585580
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Qin C, 2017, MULTIMED TOOLS APPL, V76, P2267, DOI 10.1007/s11042-015-3218-9
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Sarreshtedari S, 2017, SIGNAL IMAGE VIDEO P, V11, P1371, DOI 10.1007/s11760-017-1095-6
   Sarreshtedari S, 2015, IEEE T IMAGE PROCESS, V24, P2266, DOI 10.1109/TIP.2015.2414878
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Singh P, 2016, MULTIMED TOOLS APPL, V75, P8165, DOI 10.1007/s11042-015-2736-9
   Wicker SB, 1999, REED SOLOMON CODES T, V583-584
   Yin Z, 2016, CONGNITIVE COMPUTATI, V8, P1
   Yin ZX, 2017, MULTIMED TOOLS APPL, V76, P3899, DOI 10.1007/s11042-016-4049-z
   Zhang XP, 2011, MULTIMED TOOLS APPL, V54, P385, DOI 10.1007/s11042-010-0541-z
NR 28
TC 3
Z9 3
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21041
EP 21064
DI 10.1007/s11042-019-7380-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400022
DA 2024-07-18
ER

PT J
AU Kahani, R
   Talebpour, A
   Mahmoudi-Aznaveh, A
AF Kahani, Reza
   Talebpour, Alireza
   Mahmoudi-Aznaveh, Ahmad
TI A correlation based feature representation for first-person activity
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human activity recognition; First-person activity recognition; Feature
   encoding; Feature representation; Convolutional neural network
ID HISTOGRAMS; DENSE
AB In this paper, a simple yet efficient activity recognition method for first-person video is introduced. The proposed method is appropriate for the representation of high-dimensional features such as those extracted from convolutional neural networks (CNNs). The per-frame (per-segment) extracted features are considered as a set of time series, and inter and intra-time series relations are employed to represent the video descriptors. To find the inter-time relations, the series are grouped and the linear correlation between each pair of groups is calculated. The relations between them can represent the scene dynamics and local motions. The introduced grouping strategy helps to considerably reduce the computational cost. Furthermore, we split the series in thetemporal direction in order to preserve long term motions and better focus on each local time window. In order to extract the cyclic motion patterns, which can be considered as primary components of various activities, intra-time series correlations are exploited. The representation method results in highly discriminative features which can be linearly classified. The experiments confirm that our method outperforms the state-of-the-art methods in recognizing first-person activities on the three challenging first-person datasets.
C1 [Kahani, Reza; Talebpour, Alireza] Shahid Beheshti Univ, Dept Comp Sci & Engn, Tehran, Iran.
   [Kahani, Reza; Talebpour, Alireza; Mahmoudi-Aznaveh, Ahmad] Shahid Beheshti Univ, Cyberspace Res Inst, Tehran, Iran.
C3 Shahid Beheshti University; Shahid Beheshti University
RP Mahmoudi-Aznaveh, A (corresponding author), Shahid Beheshti Univ, Cyberspace Res Inst, Tehran, Iran.
EM r.kahani@mail.sbu.ac.ir; talebpour@sbu.ac.ir; a_mahmoudi@sbu.ac.ir
RI Kahani, Reza/AAD-6648-2021; Mahmoudi-Aznaveh, Ahmad/AAC-1996-2022
OI Talebpour, Alireza/0000-0003-2538-3928
CR Abebe G, 2016, COMPUT VIS IMAGE UND, V149, P229, DOI 10.1016/j.cviu.2015.10.015
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Agrawal P, 2014, LECT NOTES COMPUT SC, V8695, P329, DOI 10.1007/978-3-319-10584-0_22
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], P 31 AAAI C ART INT
   [Anonymous], 2014, CVPR
   [Anonymous], ARXIV150504868
   [Anonymous], NEUROCOMPUTING
   [Anonymous], 2008, PROC BRIT MACH VIS C
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], ARXIV170206799
   [Anonymous], SPIE DEFENSE SECURIT
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], 2015, INT C HUMAN ROBOT IN
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2015, ARXIV150204623
   [Anonymous], EVOLUTION 1 PERSON V
   [Anonymous], ARXIV171101201
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Choi J., 2008, ACM ICMR, P291
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Feichtenhofer C., 2016, P INT C NEUR INF PRO, P3468
   Fu Y., 2016, Human activity recognition and prediction
   Gong SG, 2011, VISUAL ANALYSIS OF BEHAVIOUR: FROM PIXELS TO SEMANTICS, P133, DOI 10.1007/978-0-85729-670-2_6
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Iwashita Y, 2014, INT C PATT RECOG, P4310, DOI 10.1109/ICPR.2014.739
   Jaakkola TS, 1999, ADV NEUR IN, V11, P487
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kahani R, 2016, IRAN CONF ELECTR ENG, P805, DOI 10.1109/IranianCEE.2016.7585630
   Kitani K. M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3241, DOI 10.1109/CVPR.2011.5995406
   Kong Y, 2016, IEEE T IMAGE PROCESS, V25, P2856, DOI 10.1109/TIP.2016.2556940
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Moreira TP, 2017, INT CONF ACOUST SPEE, P2627, DOI 10.1109/ICASSP.2017.7952632
   Narayan S, 2014, IEEE COMPUT SOC CONF, P526, DOI 10.1109/CVPRW.2014.82
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Perronnin F., 2007, P IEEE CVPR, P1
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Philbin J., 2008, P CVPR, P1
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Ryoo MS, 2015, PROC CVPR IEEE, P896, DOI 10.1109/CVPR.2015.7298691
   Ryoo MS, 2013, PROC CVPR IEEE, P2730, DOI 10.1109/CVPR.2013.352
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Simonyan K., 2014, 14091556 ARXIV
   Simonyan K., 2015, P ICLR
   Sudhakaran S, 2017, IEEE INT CONF COMP V, P2339, DOI 10.1109/ICCVW.2017.276
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   van Gemert Jan C., 2008, Computer Vision. Proceedings 10th European Conference on Computer Vision, ECCV 2008, P696, DOI 10.1007/978-3-540-88690-7_52
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wang L., 2016, P ECCV
   Wang X., 2011, Visual Analysis of Humans, P311
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Zhen XT, 2013, IEEE T CIRC SYST VID, V23, P1182, DOI 10.1109/TCSVT.2013.2240916
NR 61
TC 4
Z9 5
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21673
EP 21694
DI 10.1007/s11042-019-7429-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400051
DA 2024-07-18
ER

PT J
AU Li, TP
   Song, HH
   Zhang, KH
   Liu, QS
   Lian, W
AF Li, Tengpeng
   Song, Huihui
   Zhang, Kaihua
   Liu, Qingshan
   Lian, Wei
TI Low-rank weighted co-saliency detection via efficient manifold ranking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Manifold ranking; Color histogram; Low-rank constraints; Graph cut;
   Co-saliency detection
ID ENERGY MINIMIZATION; OBJECT DETECTION
AB Co-saliency detection, which aims to detect common salient objects in a group of images, has attracted much attention in the field of computer vision. In this paper, we present an effective co-saliency detection approach that first exploits an efficient manifold ranking scheme to extract a set of co-saliency regions, and then renders rank constraint to the feature matrix of the extracted regions to achieve a high-quality co-saliency map. Specifically, for each input image, we first develop a two-stage manifold ranking algorithm to generate multiple coarse co-saliency maps, and then we extract a group of co-salient regions from each image by fusing the co-saliency maps and the superpixels extracted from it. Then, we design an adaptive weight for each co-saliency map based on the sparse error matrix that is obtained by rendering rank constraint on the feature matrix of the salient regions. Finally, we multiply the coarse co-saliency maps with their corresponding weights to get the fine fusion results, which are further optimized by Graph cuts. Extensive evaluations on the iCoseg dataset demonstrate favorable performance of the proposed approach over some state-of-art methods in terms of both qualitative and quantitative results.
C1 [Li, Tengpeng; Song, Huihui; Zhang, Kaihua; Liu, Qingshan] Nanjing Univ Informat Sci & Technol, Jiangsu Key Lab Big Data Anal Technol B DAT, Nanjing, Jiangsu, Peoples R China.
   [Lian, Wei] Changzhi Univ, Dept Comp Sci, Changzhi 046011, Shanxi, Peoples R China.
C3 Nanjing University of Information Science & Technology; Changzhi
   University
RP Zhang, KH (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Key Lab Big Data Anal Technol B DAT, Nanjing, Jiangsu, Peoples R China.
EM zhkhua@gmail.com
RI ZHANG, Kaihua/ABE-9067-2020; Liu, Qingshan/A-2837-2011
OI ZHANG, Kaihua/0000-0002-1613-3401; 
FU National Natural Science Foundation of China [61876088, 61532009,
   61773002]; Natural Science Foundation of Jiangsu Province [BK20170040]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61876088, Grant 61532009, and Grant
   61773002, in part by the Natural Science Foundation of Jiangsu Province
   under Grant BK20170040.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080
   Boykov Y, 2001, LECT NOTES COMPUT SC, V2134, P359
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Cao X., 2013, P IEEE INT C MULT EX, P1, DOI DOI 10.1109/WCSP.2013.6677045
   Cao XC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P997, DOI 10.1145/2647868.2655007
   Cao XC, 2014, IEEE T IMAGE PROCESS, V23, P4175, DOI 10.1109/TIP.2014.2332399
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166
   Ge CJ, 2016, SIGNAL PROCESS-IMAGE, V44, P69, DOI 10.1016/j.image.2016.03.005
   Huang R, 2015, IEEE INT CON MULTI
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jia YQ, 2013, IEEE I CONF COMP VIS, P1761, DOI 10.1109/ICCV.2013.221
   Jian M, 2017, MULTIMED TOOLS APPL, P1
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Li HL, 2013, IEEE T MULTIMEDIA, V15, P1896, DOI 10.1109/TMM.2013.2271476
   Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803
   Li L, 2014, CHANDOS INF PROF SER, P1
   Li YJ, 2015, IEEE SIGNAL PROC LET, V22, P588, DOI 10.1109/LSP.2014.2364896
   Liu Z, 2014, IEEE SIGNAL PROC LET, V21, P88, DOI 10.1109/LSP.2013.2292873
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Wang L, 2018, MULTIMED TOOLS APPL, V77, P3387, DOI 10.1007/s11042-017-5152-5
   Wei LN, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3041
   Xiang D, 2017, MULTIMED TOOLS APPL, V76, P6209, DOI 10.1007/s11042-016-3310-9
   Xu B, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P525
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhang DW, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3158674
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 33
TC 9
Z9 9
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21309
EP 21324
DI 10.1007/s11042-019-7403-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400035
DA 2024-07-18
ER

PT J
AU Zhao, H
   Wang, J
   Wang, Q
   Liu, F
AF Zhao, Hui
   Wang, Jing
   Wang, Quan
   Liu, Feng
TI Queue-based and learning-based dynamic resources allocation for virtual
   streaming media server cluster of multi-version VoD system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Resources allocation; Multi-version VoD; Queueing theory; Learning
   automaton
ID CLOUD; OPTIMIZATION; ENERGY; SMART
AB Nowadays, video-on-demand (VoD) providers offer multiple-quality video streaming services to users, called as multi-version VoD. Unlike traditional VoD, multi-version VoD providers should consider to allocate bandwidth resource and transcoding computation resource simultaneously. However, most of existing resource allocation works only focused on cost reduction or bandwidth optimization, and they did not consider to allocate transcoding computation resources for multi-version VoD systems. Therefore, how to allocate bandwidth resource and transcoding computation resource simultaneously for multi-version VoD systems is still one major challenge. In this paper, we propose a queue-based and learning-based dynamic resources allocation strategy (QLRA) for virtual streaming media server cluster of multi-version VoD system. First, we analyze the user behavior habits and build the virtual streaming media server cluster as an M/G/n queue system. Based on queueing theory, we can allocate initial resources for virtual streaming media server cluster of multi-version VoD system. Second, taking the changes of the user arrival rate and the workload of multi-version VoD system as feedbacks, we introduce learning automaton to allocate resources dynamically for virtual streaming media server cluster. Third, we evaluate QLRA with other methods, and results show the correctness and effectiveness of our strategy.
C1 [Zhao, Hui; Wang, Jing; Wang, Quan; Liu, Feng] Xidian Univ, Sch Comp Sci & Technol, Xian, Shaanxi, Peoples R China.
C3 Xidian University
RP Wang, J (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Xian, Shaanxi, Peoples R China.
EM hzhao@mail.xidian.edu.cn; wangjing@mail.xidian.edu.cn;
   qwang@xidian.edu.cn; liufeng@stu.xidian.edu.cn
FU National Natural Science Foundation of China [61702394, 61702395,
   61702409, 61702400]; Fundamental Research Funds for the Central
   Universities [JB180306, JB190308]; Projects of International Cooperation
   and Exchanges NSFC [61711530248]; Shaanxi National Science Foundation;
   Ningbo Natural Science Foundation [2018A610051]
FX This research was mainly supported by the National Natural Science
   Foundation of China (61702400) and the Fundamental Research Funds for
   the Central Universities (JB180306, JB190308). It was also partially
   supported by the Projects of International Cooperation and Exchanges
   NSFC (61711530248), Shaanxi National Science Foundation, Ningbo Natural
   Science Foundation (2018A610051) and the National Natural Science
   Foundation of China (61702394, 61702395, 61702409).
CR Abhari A, 2010, MULTIMED TOOLS APPL, V46, P91, DOI 10.1007/s11042-009-0309-5
   Alasaad A, 2015, IEEE T PARALL DISTR, V26, P1021, DOI 10.1109/TPDS.2014.2316827
   Alasaad A, 2012, IEEE GLOBE WORK, P753, DOI 10.1109/GLOCOMW.2012.6477669
   [Anonymous], 2017, INT C GLOB RES ED
   [Anonymous], 2018, INT C INN MOB INT SE, DOI DOI 10.1007/978-3-319-93554-6_26
   Chang ZY, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2983638
   Chen Y., 2018, 2018 IEEE GLOB COMM, P1
   Chowdhury SA, 2012, 2012 SEVENTH INTERNATIONAL CONFERENCE ON BROADBAND, WIRELESS COMPUTING, COMMUNICATION AND APPLICATIONS (BWCCA 2012), P244, DOI 10.1109/BWCCA.2012.47
   Ciullo D, 2015, IEEE ACM T NETWORK, V23, P1846, DOI 10.1109/TNET.2014.2346077
   Deng R, 2018, MULTIMED TOOLS APPL, V77, P6445, DOI 10.1007/s11042-017-4551-y
   Du J, 2016, IEEE T MULTIMEDIA, V18, P820, DOI 10.1109/TMM.2016.2537781
   Gao Y, 2010, J CHONGQING NORMAL U, V27
   Ge C, 2017, IEEE T MULTIMEDIA, V19, P2222, DOI 10.1109/TMM.2017.2735301
   Karunaratne M., 2018, P 55 ANN DES AUT C, P1
   Kumar A, 2018, COMPUT INFORM, V37, P781, DOI 10.4149/cai_2018_4_781
   Leontiou N, 2018, COMPUT ELECTR ENG, V67, P235, DOI 10.1016/j.compeleceng.2018.03.035
   Li JN, 2018, FUTURE GENER COMP SY, V85, P210, DOI 10.1016/j.future.2018.03.044
   Li MX, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING AND COMMUNICATIONS (BIGCOM 2018), P181, DOI 10.1109/BIGCOM.2018.00036
   Liu W, 2017, J VIS COMMUN IMAGE R, V48, P502, DOI 10.1016/j.jvcir.2017.01.010
   Liu Z, 2018, WIREL NETW, V24, P1491, DOI 10.1007/s11276-016-1416-7
   Misra S, 2013, IEEE COMMUN MAG, V51, P98, DOI 10.1109/MCOM.2013.6400445
   Nan XM, 2014, J VIS COMMUN IMAGE R, V25, P928, DOI 10.1016/j.jvcir.2014.02.008
   Niño-Mora J, 2019, COMPUT OPER RES, V103, P221, DOI 10.1016/j.cor.2018.11.012
   Niu D, 2012, IEEE INFOCOM SER, P460, DOI 10.1109/INFCOM.2012.6195785
   Oommen B. J., 2010, 2010 2nd International Conference on Computer Engineering and Technology (ICCET), P724, DOI 10.1109/ICCET.2010.5485366
   Pandey M, 2017, 8 INT C COMP COMM NE
   Patel N, 2018, INT J DISTRIB SYST T, V9, P39, DOI 10.4018/IJDST.2018010103
   Ranjbari M, 2017, J PARALLEL DISTRIB C, V113
   Sankar SG, 2014, INT CONF ADV COMPU, P312, DOI 10.1109/ICoAC.2014.7229732
   Santos IL, 2019, FUTURE GENER COMP SY, V92, P564, DOI 10.1016/j.future.2018.03.026
   Shen B, 2004, IEEE T MULTIMEDIA, V6, P375, DOI 10.1109/TMM.2003.822791
   Szabo M, 2018, INFOCOMMUNICATIONS J, V10, P15
   Tang SJ, 2018, IEEE T SERV COMPUT, V11, P20, DOI 10.1109/TSC.2016.2531698
   Tian XH, 2017, IEEE T MOBILE COMPUT, V16, P2970, DOI 10.1109/TMC.2016.2639500
   Tseng FH, 2018, IEEE SYST J, V12, P1688, DOI 10.1109/JSYST.2017.2722476
   Valliyammai C, 2019, ADV INTELL SYST, V755, P309, DOI 10.1007/978-981-13-1951-8_28
   Xhagjika V, 2017, INT CONF NETW FUT, P14, DOI 10.1109/NOF.2017.8251214
   Xhagjika V, 2017, IEEE ACM INT SYMP, P739, DOI 10.1109/CCGRID.2017.118
   Zhang C, 2016, 2016 DIGITAL MEDIA INDUSTRY AND ACADEMIC FORUM (DMIAF), P89, DOI 10.1109/DMIAF.2016.7574908
   Zhang JH, 2012, PROCEEDINGS OF 2012 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT 2012), P1, DOI 10.1109/ICCSNT.2012.6525878
   Zhang JX, 2018, CMC-COMPUT MATER CON, V56, P123, DOI 10.3970/cmc.2018.03728
   Zhang WZ, 2016, COMPUT COMMUN, V85, P89, DOI 10.1016/j.comcom.2016.04.001
   Zhang Yi, 2015, Journal of China Universities of Posts and Telecommunications, V22, P84, DOI 10.1016/S1005-8885(15)60656-2
   Zhang ZH, 2014, CHIN CONTR CONF, P5527, DOI 10.1109/ChiCC.2014.6895884
   Zhao H, 2017, IEEE T MULTIMEDIA, V19, P149, DOI 10.1109/TMM.2016.2612123
   Zhao H, 2016, MULTIMED TOOLS APPL, V75, P1923, DOI 10.1007/s11042-014-2380-9
   Zhao H, 2015, 2015 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATION (ISCC), P943, DOI 10.1109/ISCC.2015.7405635
   Zheng Qingji., 2012, CODASPY '12: ACM conference on Data and Application Security and Privacy, P1
NR 48
TC 7
Z9 7
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21827
EP 21852
DI 10.1007/s11042-019-7457-z
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400057
DA 2024-07-18
ER

PT J
AU Chowdhury, K
   Chaudhuri, D
   Pal, AK
   Samal, A
AF Chowdhury, Kuntal
   Chaudhuri, Debasis
   Pal, Arup Kumar
   Samal, Ashok
TI Seed selection algorithm through K-means on optimal number of clusters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clustering; Cluster building time; Cluster validity indices; Joint
   probability; K-means; Seed point; Seed generation time; Segmentation
   entropy
ID VALIDITY INDEX; INITIALIZATION; CRITERION; SUBSET; SET
AB Clustering is one of the important unsupervised learning in data mining to group the similar features. The growing point of the cluster is known as a seed. To select the appropriate seed of a cluster is an important criterion of any seed based clustering technique. The performance of seed based algorithms are dependent on initial cluster center selection and the optimal number of clusters in an unknown data set. Cluster quality and an optimal number of clusters are the important issues in cluster analysis. In this paper, the proposed seed point selection algorithm has been applied to 3 band image data and 2D discrete data. This algorithm selects the seed point using the concept of maximization of the joint probability of pixel intensities with the distance restriction criteria. The optimal number of clusters has been decided on the basis of the combination of seven different cluster validity indices. We have also compared the results of our proposed seed selection algorithm on an optimal number of clusters using K-Means clustering with other classical seed selection algorithms applied through K-Means Clustering in terms of seed generation time (SGT), cluster building Time (CBT), segmentation entropy and the number of iterations (NOTK-means). We have also made the analysis of CPU time and no. of iterations of our proposed seed selection method with other clustering algorithms.
C1 [Chowdhury, Kuntal; Pal, Arup Kumar] ISM, IIT, Dept Comp Sci & Engn, Dhanbad, Jharkhand, India.
   [Chaudhuri, Debasis] DRDO Integrat Ctr, Panagarh, W Bengal, India.
   [Samal, Ashok] Univ Nebraska, Dept Comp Sci & Engn, Linclon, England.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad; Defence Research &
   Development Organisation (DRDO); DRDO Integration Centre (DIC)
RP Chowdhury, K (corresponding author), ISM, IIT, Dept Comp Sci & Engn, Dhanbad, Jharkhand, India.
EM ikuntal09@gmail.com; deba_chaudhuri@yahoo.co.in; arupkrpal@gmail.com;
   samal@cse.unl.edu
RI Pal, Arup Kumar/I-2496-2016; CHOWDHURY, KUNTAL/AAA-5002-2021
OI Chaudhuri, Debasis/0000-0002-6895-456X
CR AlMalki A, 2016, OPEN J OPTIM, V5, P71, DOI [10.4236/OJOP.2016.52009, DOI 10.4236/OJOP.2016.52009]
   Alswaitti M, 2018, EXPERT SYST APPL, V91, P170, DOI 10.1016/j.eswa.2017.08.050
   [Anonymous], TECH REP
   [Anonymous], 2012, P 2012 C INF COMP NE
   Arifin AZ, 2006, PATTERN RECOGN LETT, V27, P1515, DOI 10.1016/j.patrec.2006.02.022
   Astrahan M., 1970, TECH REP
   Bai L, 2012, EXPERT SYST APPL, V39, P8022, DOI 10.1016/j.eswa.2012.01.131
   Bandyopadhyay O, 2016, INT J IMAGE GRAPH, V16, DOI 10.1142/S0219467816500017
   BEZDEK JC, 1974, J MATH BIOL, V1, P57, DOI 10.1007/BF02339490
   Bhattacharya A, 2008, BIOINFORMATICS, V24, P1359, DOI 10.1093/bioinformatics/btn133
   Bhusare BB, 2014, INT J ADV RES COMPUT, V3, P1317
   Calinski T., 1974, Communications in Statistics-Simulation and Computation, V3, P1, DOI [10.1080/03610927408827101, DOI 10.1080/03610927408827101]
   Cao FY, 2009, COMPUT MATH APPL, V58, P474, DOI 10.1016/j.camwa.2009.04.017
   Celebi ME, 2013, EXPERT SYST APPL, V40, P200, DOI 10.1016/j.eswa.2012.07.021
   Celeux G, 1996, J CLASSIF, V13, P195, DOI 10.1007/BF01246098
   CHAUDHURI BB, 1994, PATTERN RECOGN LETT, V15, P893, DOI 10.1016/0167-8655(94)90151-1
   Chaudhuri D, 1997, IEEE T SYST MAN CY B, V27, P871, DOI 10.1109/3477.623240
   CHAUDHURI D, 1994, IEEE T SYST MAN CYB, V24, P1416, DOI 10.1109/21.310520
   Chaudhuri D, 1994, THESIS
   Chen K., 2005, BEST K ENTROPY BASED
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Fahim AM., 2006, J ZHEJIANG UNIV-SC A, V7, P1626, DOI DOI 10.1631/JZUS.2006.A1626
   FORGY EW, 1965, BIOMETRICS, V21, P768
   GONZALEZ TF, 1985, THEOR COMPUT SCI, V38, P293, DOI 10.1016/0304-3975(85)90224-5
   Jain A K, 1988, ALGORITHMS CLUSTERIN
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Jinlan T., 2005, TSINGHUA SCI TECHNOL, V10, P277
   Kalyani S, 2011, EXPERT SYST APPL, V38, P10839, DOI 10.1016/j.eswa.2011.02.086
   Kim DJ, 2001, IEICE T INF SYST, VE84D, P281
   Kim DW, 2004, PATTERN RECOGN, V37, P2009, DOI 10.1016/j.patcog.2004.04.007
   Kodabagi M, 2014, COMPUTER SCI INFORM, V15
   Kumar Y.K. Yugal., 2014, International Journal of Advanced Science and Technology, V62, P43
   Liu ZX, 2012, FUTURE GENER COMP SY, V28, P780, DOI 10.1016/j.future.2011.04.019
   Lu JF, 2008, PATTERN RECOGN LETT, V29, P787, DOI 10.1016/j.patrec.2007.12.009
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Madhu YedlaS.R. Pathakota., 2010, International Journal of Computer Science and Information Technologies, V1, P121
   MILLIGAN GW, 1981, PSYCHOMETRIKA, V46, P187, DOI 10.1007/BF02293899
   Nazeer KAA, 2009, LECT NOTES ENG COMP, P308
   Nie LQ, 2017, IEEE T CYBERNETICS, V47, P3680, DOI 10.1109/TCYB.2016.2577590
   Oyelade O.J., 2010, International Journal of Computer Science and Information Security (IJCSIS), P292, DOI DOI 10.48550/ARXIV.1002
   Pal S.K., 1986, FUZZY MEASURES DETER
   Pol DUR, 2014, INT J ADV RES COMPUT, V4
   Purohit Pallavi, 2013, INT J COMPUTER SCI C, V4, P125
   Reddy C.K., 2013, DATA CLUSTERING ALGO, V87
   Reddy D, 2012, PROC TECH, V4, P395, DOI 10.1016/j.protcy.2012.05.061
   Sardar TH, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING, INSTRUMENTATION AND CONTROL TECHNOLOGIES (ICICICT), P110, DOI 10.1109/ICICICT1.2017.8342543
   Singh Dilpreet, 2015, J Big Data, V2, P8
   Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293
   Tou JT, 1974, APPL MATH COMPUT, V7, P75
   Tzortzis G, 2014, PATTERN RECOGN, V47, P2505, DOI 10.1016/j.patcog.2014.01.015
   Villmann T, 2001, LECT NOTES COMPUT SC, V2206, P619
   Wang Q, 2005, PROC SPIE, V5812, P31, DOI 10.1117/12.603567
   Wang X, 2016, COMPUT INTELL NEUROS
   XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677
   Xiuchang H, 2014, J NETWORKS, V9, P1
   Zahra S, 2015, INFORM SCIENCES, V320, P156, DOI 10.1016/j.ins.2015.03.062
NR 56
TC 13
Z9 21
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18617
EP 18651
DI 10.1007/s11042-018-7100-4
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200057
DA 2024-07-18
ER

PT J
AU Fan, XL
   Wang, L
AF Fan, Xunli
   Wang, Lin
TI Image defogging approach based on incident light frequency
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image defogging; Dark primary color prior; Color distortion;
   Transmittance; Incident light frequency
ID RING PARTITION; VISION
AB Aiming at solving the problem of color distortion existing in the dark original pruning algorithm, an improved transmittance computation approach separated for each color channel is proposed. Firstly, the influence of the incident light frequency on the transmittance of each color channel is analyzed based on Beer-Lambert law. Meanwhile, the proportional relationship among the transmittance of each channel is deduced. Secondly, the image is resumed to improve the operation efficiency. After that, the image is pretreated to get the refined transmittance. Finally, the transmittance of all the color channels is obtained through the proportional relationship. And the corresponding transmittance is used to recover the image on each channel. Thus, the image defogging is realized. We evaluate the proposed algorithm qualitatively and quantitatively. From the subjective results, the proposed algorithm has better visual effect than that of the other algorithms, and our method has more details compared to the other two methods. While from the objective results, the proposed approach can achieve natural image color without high saturation, and reduce the running time by 4 to 10 times compared with several state-of-art algorithms. The proposed algorithm can obtain a higher color fidelity and a better image color in terms of e, r<mml:mo stretchy="true"><overbar></mml:mover> and H. The proposed method is obviously superior to those of the others in terms of no-reference quality evaluator in spatial domain and has the highest average PSNR value.
C1 [Fan, Xunli; Wang, Lin] Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Shaanxi, Peoples R China.
C3 Northwest University Xi'an
RP Wang, L (corresponding author), Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Shaanxi, Peoples R China.
EM xunlfan@nwu.edu.cn; wanglin@nwu.edu.cn
OI Wang, Lin/0000-0003-1026-0060
FU National Natural Science Foundation of China [61503300, 61801384];
   National Key R&D Program of China [2017YFB1002804, 2017YFB1402105];
   Natural Science Foundation of Shaanxi Province of China [2018JM6122]
FX This work was supported in part by National Natural Science Foundation
   of China under grants 61503300 and 61801384. National Key R&D Program of
   China under grants 2017YFB1002804 and 2017YFB1402105, Natural Science
   Foundation of Shaanxi Province of China under grant 2018JM6122.
CR Caraffa L, 2013, IEEE INT VEH SYM, P994, DOI 10.1109/IVS.2013.6629596
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   [郭璠 Guo Fan], 2012, [自动化学报, Acta Automatica Sinica], V38, P1410
   [郝增周 Hao Zengzhou], 2008, [光学学报, Acta Optica Sinica], V28, P2420
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hongyu Zhao, 2015, IEEE/CAA Journal of Automatica Sinica, V2, P158, DOI 10.1109/JAS.2015.7081655
   Jiang B, 2018, MULTIMED TOOLS APPL, V77, P13513, DOI 10.1007/s11042-017-4973-6
   Jobson DJ, 2002, P SOC PHOTO-OPT INS, V4736, P25, DOI 10.1117/12.477589
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   [李月臣 LI Yuechen], 2006, [成都理工大学学报. 自然科学版, Journal of Chengdu University of Technology. Science & Technonogy Edition], V33, P58
   Li YN, 2018, NEUROCOMPUTING, V283, P73, DOI 10.1016/j.neucom.2017.12.046
   [刘海波 Liu Haibo], 2015, [自动化学报, Acta Automatica Sinica], V41, P1264
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Nishino K, 2012, INT J COMPUT VISION, V98, P263, DOI 10.1007/s11263-011-0508-1
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Rui Yi-bin, 2006, Journal of Nanjing University of Science and Technology, V30, P622
   Sajana MI, 2015, INT J DIGIT APPL CON, V4, P1
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Shi ZH, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0251-4
   Taimei Zhang, 2015, Advances in Swarm and Computational Intelligence. 6th International Conference, ICSI 2015 held in conjunction with the Second BRICS Congress, CCI 2015. Proceedings: LNCS 9142, P205, DOI 10.1007/978-3-319-20469-7_23
   Tang ZJ, 2016, IEEE T INF FOREN SEC, V11, P200, DOI 10.1109/TIFS.2015.2485163
   Tang ZJ, 2014, IEEE T KNOWL DATA EN, V26, P711, DOI 10.1109/TKDE.2013.45
   Tarel JP, 2012, IEEE INTEL TRANSP SY, V4, P6, DOI 10.1109/MITS.2012.2189969
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Wang W, 2018, PATTERN RECOGN, V80, P196, DOI 10.1016/j.patcog.2018.03.009
   Wang YK, 2014, IEEE T IMAGE PROCESS, V23, P4826, DOI 10.1109/TIP.2014.2358076
   Wen XF, 2014, INT J REMOTE SENS, V35, P4865, DOI 10.1080/01431161.2014.930564
   Xiong C, 2018, MULTIMEDIA TOOLS APP
   Yang QL, 2017, PARTICUOLOGY, V31, P1, DOI 10.1016/j.partic.2016.10.001
   Yin FS, 2015, IEEE ENG MED BIO, P1596, DOI 10.1109/EMBC.2015.7318679
   Yitzhaky Y, 1997, OPT ENG, V36, P3064, DOI 10.1117/1.601526
   Zhang L, 2015, 2015 FIRST INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE THEORY, SYSTEMS AND APPLICATIONS (CCITSA 2015), P177, DOI 10.1109/CCITSA.2015.55
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   [祝培 Zhu Pei], 2004, [中国图象图形学报. A, Journal of image and graphics], V9, P124
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 39
TC 5
Z9 5
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17653
EP 17672
DI 10.1007/s11042-018-7103-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200016
DA 2024-07-18
ER

PT J
AU Li, LL
   Si, YJ
AF Li, Liangliang
   Si, Yujuan
TI Enhancement of hyperspectral remote sensing images based on improved
   fuzzy contrast in nonsubsampled shearlet transform domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral remote sensing image; NSST; Guided filter; Fuzzy contrast
ID HISTOGRAM EQUALIZATION; CONTOURLET TRANSFORM; UNSHARP MASKING; NSCT;
   FILTER; SHRINKAGE; ALGORITHM
AB In order to deal with the pseudo-Gibbs phenomenon in the process of hyperspectral remote sensing image enhancement, a novel image enhancement method based on nonsubsampled shearlet transform (NSST) is proposed in this paper. The main motivation of this study is to adjust the coefficient of remote sensing image enhancement as a pattern recognition task. Firstly, the input image is decomposed into a low-frequency component and some high-frequency components by NSST decomposition; Secondly, the guided filter is applied to process the low-frequency component to improve the contrast, and the improved fuzzy contrast is used to suppress the noise of the high-frequency components; Thirdly, the processed coefficients of low-frequency and high-frequency are reconstructed by inverse nonsubsampled shearlet transform (INSST), and the final enhanced image is obtained. The experimental results demonstrate that the proposed approach has obvious advantages in terms of objective data and subjective vision.
C1 [Li, Liangliang; Si, Yujuan] Jilin Univ, Coll Commun Engn, Changchun 130012, Jilin, Peoples R China.
   [Si, Yujuan] Jilin Univ, Zhuhai Coll, Dept Elect Informat, Zhuhai 519041, Peoples R China.
C3 Jilin University; Jilin University
RP Si, YJ (corresponding author), Jilin Univ, Coll Commun Engn, Changchun 130012, Jilin, Peoples R China.; Si, YJ (corresponding author), Jilin Univ, Zhuhai Coll, Dept Elect Informat, Zhuhai 519041, Peoples R China.
EM siyj@jlu.edu.cn
RI Li, Chun/KBC-9591-2024; Yu, Chongxiu/KDM-7354-2024
OI Yu, Chongxiu/0000-0002-8221-6221; Li, Liangliang/0000-0001-7354-7494
FU Key Scientific and Technological Research Project of Jilin Province
   [20150204039GX, 20170414017GH]; Natural Science Foundation of Guangdong
   Province [2016A030313658]; Innovation and Strengthening School Project
   (provincial key platform and major scientific research project) -
   Guangdong Government [2015KTSCX175]; Premier-Discipline Enhancement
   Scheme - Zhuhai Government [2015YXXK02-2]; Premier Key-Discipline
   Enhancement Scheme - Guangdong Government Funds [2016GDYSZDXK036]
FX We thank all the volunteers and colleagues provided helpful comments on
   previous versions of the manuscript. The experimental measurements and
   data collection were carried out by Liangliang Li and Yujuan Si. The
   manuscript was written by Liangliang Li with assistance of Yujuan Si. We
   would like to thank Prof. Yujuan Si for her contributions in
   proofreading of the paper. This work was supported by the Key Scientific
   and Technological Research Project of Jilin Province under Grant Nos.
   20150204039GX and 20170414017GH; the Natural Science Foundation of
   Guangdong Province under Grant No. 2016A030313658; the Innovation and
   Strengthening School Project (provincial key platform and major
   scientific research project) supported by Guangdong Government under
   Grant No. 2015KTSCX175; the Premier-Discipline Enhancement Scheme
   Supported by Zhuhai Government under Grant No. 2015YXXK02-2; the Premier
   Key-Discipline Enhancement Scheme Supported by Guangdong Government
   Funds under Grant No. 2016GDYSZDXK036.
CR Abazari R, 2018, MULTIMED TOOLS APPL, V77, P17829, DOI 10.1007/s11042-018-5648-7
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Chavan SS, 2017, COMPUT BIOL MED, V81, P64, DOI 10.1016/j.compbiomed.2016.12.006
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang ZW, 2017, J MED IMAG HEALTH IN, V7, P229, DOI 10.1166/jmihi.2017.2011
   Jafari S, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.015002
   Ji XU, 2017, MULTIMED TOOLS APPL, V76, P5873, DOI 10.1007/s11042-015-2560-2
   Joseph J, 2018, BIOMED SIGNAL PROCES, V39, P271, DOI 10.1016/j.bspc.2017.08.003
   Kallel F, 2018, SIGNAL IMAGE VIDEO P, V12, P905, DOI 10.1007/s11760-017-1232-2
   LI L, 2018, AIP ADV, V8
   Li LL, 2018, J MED IMAG HEALTH IN, V8, P1207, DOI 10.1166/jmihi.2018.2469
   Li LL, 2018, INT J IMAG SYST TECH, V28, P124, DOI 10.1002/ima.22264
   Li LL, 2018, J MED IMAG HEALTH IN, V8, P431, DOI 10.1166/jmihi.2018.2328
   Li LL, 2017, ALGORITHMS, V10, DOI 10.3390/a10040116
   Li LL, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P319, DOI 10.1109/ICIVC.2017.7984569
   Li LL, 2016, J INDIAN SOC REMOTE, V44, P995, DOI 10.1007/s12524-016-0561-x
   Liu JH, 2017, IEEE GEOSCI REMOTE S, V14, P1715, DOI 10.1109/LGRS.2017.2730247
   Liu L, 2017, T I MEAS CONTROL, V39, P183, DOI 10.1177/0142331215604210
   Liu L, 2015, INT J IMAG SYST TECH, V25, P199, DOI 10.1002/ima.22137
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu ZW, 2017, OPT LASER ENG, V97, P71, DOI 10.1016/j.optlaseng.2017.05.007
   Luo XQ, 2017, IEEE SENS J, V17, P1760, DOI 10.1109/JSEN.2016.2646741
   Lv DL, 2016, OPT ENG, V55, DOI 10.1117/1.OE.55.10.103104
   Math SSP, 2017, SADHANA-ACAD P ENG S, V42, P1505, DOI 10.1007/s12046-017-0708-7
   Pu XT, 2014, CONCURR COMP-PRACT E, V26, P742, DOI 10.1002/cpe.3041
   Qian Li, 2014, Information Technology Journal, V13, P153, DOI 10.3923/itj.2014.153.158
   Quevedo E, 2017, OPT COMMUN, V404, P94, DOI 10.1016/j.optcom.2017.06.054
   Ren RZ, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.026014
   Sharif M, 2015, MULTIMED TOOLS APPL, V74, P5533, DOI 10.1007/s11042-014-1867-8
   Singh P, 2018, MULTIMED TOOLS APPL, V77, P12581, DOI 10.1007/s11042-017-4906-4
   [陶飞翔 Tao Feixiang], 2015, [测绘学报, Acta Geodetica et Cartographica Sinica], V44, P884
   Wang C, 2005, IEEE T CONSUM ELECTR, V51, P1326, DOI 10.1109/TCE.2005.1561863
   Wang JJ, 2015, INT J IMAG SYST TECH, V25, P7, DOI 10.1002/ima.22115
   Wang XY, 2015, MULTIMED TOOLS APPL, V74, P11703, DOI 10.1007/s11042-014-2258-x
   Wang Y, 2017, INFRARED PHYS TECHN, V86, P59, DOI 10.1016/j.infrared.2017.08.005
   Wu CD, 2017, REV SCI INSTRUM, V88, DOI 10.1063/1.4983375
   Wu Y Q, 2015, ACTA OPT SINICA, V35, P79
   [吴一全 Wu Yiquan], 2015, [光电子·激光, Journal of Optoelectronics·Laser], V26, P978
   [杨波 Yang Bo], 2013, [光电子·激光, Journal of Optoelectronics·Laser], V24, P2249
   Zhan K, 2017, NEUROCOMPUTING, V238, P1, DOI 10.1016/j.neucom.2017.01.031
   Zhang J, 2017, APPL OPTICS, V56, P4785, DOI 10.1364/AO.56.004785
   Zhang QL, 2017, AUTOM CONTROL COMPUT, V51, P263, DOI 10.3103/S0146411617040113
   Zhang Q, 2017, SMART MATER STRUCT, V26, DOI 10.1088/1361-665X/aa8b23
   Zhou SB, 2015, MULTIMED TOOLS APPL, V74, P6827, DOI 10.1007/s11042-014-1931-4
NR 47
TC 11
Z9 11
U1 2
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18077
EP 18094
DI 10.1007/s11042-019-7203-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200034
DA 2024-07-18
ER

PT J
AU Liu, YX
   Yang, CN
   Wu, CM
   Sun, QD
   Bi, W
AF Liu, Yan-Xiao
   Yang, Ching-Nung
   Wu, Chi-Ming
   Sun, Qin-Dong
   Bi, Wei
TI Threshold changeable secret image sharing scheme based on interpolation
   polynomial
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret image sharing; Threshold changeable; Interpolation polynomial
ID BOOLEAN-OPERATIONS
AB In previous (k,n) secret image sharing scheme, the threshold k is decided by dealer according to the security requirement, and this threshold value is fixed without considering the dynamic secure environment in future. In this work, we propose a novel threshold changeable secret image sharing scheme where the threshold value can be changed according to the changeable security requirement. In our scheme, each participant only needs to keep one initial shadow. When reconstructing image, the dealer decides the threshold according to security level. If the threshold is unchanged, any k or more initial shadows can recover the image; else if the threshold is increased or decreased, dealer publishes additional information, each participant update their shadows accordingly such that the threshold of updated shadows is changed correspondingly. The contribution of our work is that the threshold of shadows can be changed flexibly to satisfy the dynamic secure environment, and each participant only need to keep one initial shadows. The feature of threshold changeable makes our scheme more practical than previous secret image sharing in some complicated applications.
C1 [Liu, Yan-Xiao; Sun, Qin-Dong] Xian Univ Technol, Dept Comp Sci & Engn, Xian, Shaanxi, Peoples R China.
   [Yang, Ching-Nung; Wu, Chi-Ming] Natl Dong Hwa Univ, Dept CSIE, Shoufeng Township, Hualien County, Taiwan.
   [Bi, Wei] SeeleTech Corp, San Francisco, CA USA.
C3 Xi'an University of Technology; National Dong Hwa University
RP Liu, YX (corresponding author), Xian Univ Technol, Dept Comp Sci & Engn, Xian, Shaanxi, Peoples R China.
EM liuyanxiao@xaut.edu.cn
RI Yang, Ching-Nung/HKV-1639-2023
FU China National Natural Science Foundation [61502384, 61571360,
   61872289]; Shaanxi Science and Technology Co-ordination and Innovation
   Project [2016KTZDGY05-09]; Innovation Project of Shaanxi Provincial
   Department of Education [17JF023]; Ministry of Science and Technology
   (MOST) [107-2221-E-259-007]
FX The research presented in this paper is supported in part by the China
   National Natural Science Foundation (No.: 61502384, 61571360, 61872289),
   Shaanxi Science and Technology Co-ordination and Innovation Project
   (No.: 2016KTZDGY05-09), and the Innovation Project of Shaanxi Provincial
   Department of Education (No.: 17JF023). This research was supported in
   part by Ministry of Science and Technology (MOST), under Grant
   107-2221-E-259-007.
CR Blundo C., 1994, Advances in Cryptology - CRYPTO '93. 13th Annual International Cryptology Conference Proceedings, P110
   Chao HC, 2017, DIGIT SIGNAL PROCESS, V68, P69, DOI 10.1016/j.dsp.2017.05.009
   Chao KY, 2009, INT J PATTERN RECOGN, V23, P263, DOI 10.1142/S0218001409007090
   Gong XQ, 2018, IEEE T INF FOREN SEC, V13, P1906, DOI 10.1109/TIFS.2018.2806922
   Harn L, 2015, INFORM PROCESS LETT, V115, P851, DOI 10.1016/j.ipl.2015.06.014
   Li P, 2013, J VIS COMMUN IMAGE R, V24, P1106, DOI 10.1016/j.jvcir.2013.07.005
   Liu YX, 2018, SIGNAL PROCESS-IMAGE, V66, P77, DOI 10.1016/j.image.2018.05.004
   Liu YX, 2014, SECUR COMMUN NETW, V7, P2237, DOI 10.1002/sec.930
   Liu YX, 2017, SIGNAL PROCESS-IMAGE, V58, P49, DOI 10.1016/j.image.2017.06.011
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Shamir A., 1979, Communications of the ACM, V22, P612, DOI 10.1145/359168.359176
   Steinfeld R, 2007, IEEE T INFORM THEORY, V53, P2542, DOI 10.1109/TIT.2007.899541
   Steinfeld R, 2006, FINITE FIELDS TH APP, V12, P653, DOI 10.1016/j.ffa.2005.04.007
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Wang HX, 2008, IEEE T INFORM THEORY, V54, P473, DOI 10.1109/TIT.2007.911179
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Wang RZ, 2009, IEEE SIGNAL PROC LET, V16, P659, DOI 10.1109/LSP.2009.2021334
   Wang ZH, 2016, SECUR COMMUN NETW, V9, P4075, DOI 10.1002/sec.1589
   Xiao HL, 2016, INT J THEOR PHYS, V55, P3807, DOI 10.1007/s10773-016-3010-2
   Yan XH, 2016, MULTIMED TOOLS APPL, V75, P8657, DOI 10.1007/s11042-015-2779-y
   Yang CN, 2012, IEEE T CIRC SYST VID, V22, P799, DOI 10.1109/TCSVT.2011.2180952
   Yang CN, 2012, OPT COMMUN, V285, P1725, DOI 10.1016/j.optcom.2011.12.003
   Yang CN, 2011, J SYST SOFTWARE, V84, P1726, DOI 10.1016/j.jss.2011.05.008
   Yang CN, 2010, OPT COMMUN, V283, P1750, DOI 10.1016/j.optcom.2009.12.077
   Yuan LF, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0165512
   Zhang ZF, 2012, THEOR COMPUT SCI, V418, P106, DOI 10.1016/j.tcs.2011.09.027
NR 28
TC 71
Z9 71
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18653
EP 18667
DI 10.1007/s11042-019-7205-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200058
DA 2024-07-18
ER

PT J
AU Raju, P
   Rao, VM
   Rao, BP
AF Raju, Paladugu
   Rao, Veera Malleswara
   Rao, Bhima Prabhakara
TI Optimal GLCM combined FCM segmentation algorithm for detection of kidney
   cysts and tumor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature based Fuzzy C-means (FbFCM); Whale Optimization algorithm (WOA);
   Gray Level Co-occurrence Matrix (GLCM); Ultrasound (US) kidney tumor and
   cyst segmentation
AB In this document, we employed an efficient Optimal GLCM attribute related FCM segmentation algorithm which is used to categorize the kidney cysts and tumor from the ultrasound kidney images. The FCM is exploiting some appropriate attributes of GLCM texture feature extractor and optimally attach the cluster centroids of FCM by the help of Whale optimization algorithm. The proposed approach is executed in the working platform of Matlab. The findings demonstrate that the proposed model have better performance in recognizing the detection of kidney cysts and tumor in patients by examining US kidney images. Also, we have shown the comparison of our proposed method FB-FCM-WOA with the existing methodologies like FB-FCM, FB-K-means, IB-FCM and IB-K-means. Hence, we would suggest that our proposed method is much better for detecting kidney cysts and tumor.
C1 [Raju, Paladugu] JNTUK Kakinada, Dept ECE, Kakinada 533003, Andhra Pradesh, India.
   [Rao, Veera Malleswara] GITAM Deemed Be Univ, GIT, Dept ECE, Visakhapatnam 530045, Andhra Pradesh, India.
   [Rao, Bhima Prabhakara] JNTUK Kakinada, Nanotechnol, Kakinada 533003, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Kakinada; Gandhi Institute
   of Technology & Management (GITAM); Jawaharlal Nehru Technological
   University - Kakinada
RP Raju, P (corresponding author), JNTUK Kakinada, Dept ECE, Kakinada 533003, Andhra Pradesh, India.
EM praju0817@gmail.com
RI Malleswara Rao, Dr Veera/IYI-9906-2023
OI Rao, Veera/0009-0006-3559-7996
CR Aljarah I, 2018, SOFT COMPUT, V22, P1, DOI 10.1007/s00500-016-2442-1
   [Anonymous], ARXIV170807077
   [Anonymous], P NAT C ADV EL POW E
   Attia MW, 2015, IJACSA INT J ADV COM, V6, P4
   Ding M, 2016, IEEE T IMAGE PROCESS, V25, P776, DOI 10.1109/TIP.2015.2507445
   Gayathri K, 2017, BRAIN TUMOR SEGMENTA
   Goceri N, 2015, MACH LEARN APPL ICML
   Guo L, 2017, INT J FUZZY SYST, V19, P1660, DOI 10.1007/s40815-017-0322-1
   Hong S, 2015, BMC SYST BIOL, V9, P5
   Jin C, 2017, MED PHYS, V44, P6353, DOI 10.1002/mp.12594
   Jin C, 2016, IEEE T MED IMAGING, V35, P1395, DOI 10.1109/TMI.2015.2512606
   Kairuddin WNHW, 2017, IOP CONF SER-MAT SCI, V226, DOI 10.1088/1757-899X/226/1/012136
   Kaveh A, 2017, MECH BASED DES STRUC, V45, P345, DOI 10.1080/15397734.2016.1213639
   Khalifa A, 2016, IEEE INTL CONF CONTR
   Kirubha V., 2016, INT J COMPUT TRENDS, V38, P124, DOI [10.14445/22312803/ijctt-v38p122, DOI 10.14445/22312803/IJCTT-V38P122]
   Krishna KD, 2016, IRBM, V37, P189, DOI 10.1016/j.irbm.2016.05.001
   Lee LK, 2015, 2015 4TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING AND COMPUTER SYSTEMS (ICSECS), P171, DOI 10.1109/ICSECS.2015.7333105
   Lin DT, 2006, IEEE T INF TECHNOL B, V10, P59, DOI 10.1109/TITB.2005.855561
   Mahdi M, 2017, IEEE J BIOMED HEALTH, V21, P1079
   Mahmud W, 2013, THESIS
   Mary JM., 2017, IMAGE SEGMENTATION T
   Pawar MP, 2017, DESIGN ANAL PERFORMA
   Pugazhenthi D, 2016, BREAST
   Sharawi M, 2017, ADV COMP INT ICACI 2
   Torres HR, 2018, COMPUTER METHODS PRO
   TRIVEDI C, 2016, INDIAN J SCI TECHNOL, V9, DOI DOI 10.3390/EN9020074
   Velmurugan V, 2017, BIOS IM INSTR ICBSII
NR 27
TC 8
Z9 11
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18419
EP 18441
DI 10.1007/s11042-018-7145-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200049
DA 2024-07-18
ER

PT J
AU Cheng, YB
   Yang, CK
   Chang, GC
   Chang, TW
AF Cheng, Yuan-Bang
   Yang, Chuan-Kai
   Chang, Guan-Chung
   Chang, Teng-Wen
TI Automatic generation of video navigation from Google Street View data
   with car detection and inpainting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Google Earth; Google Street View; HOG and Exemplar-SVMs; HAAR and
   Adaboost; Region Growing; Image Inpainting; Caffe; Faster R-CNN
AB In spite of the existence of numerous navigation tools/systems, Google Street View, offering only a single static image at a time, is still sometimes preferred for the provision of a realistic scene. However, for the sake of navigation, given the starting and ending locations, a navigation video consisting of images obtained from Google Street View service is desired. Several papers have tried to address this issue in some sense; however, there is still much room for further improvement. First, the generation of navigation video is not very smooth, i.e., the transition from one frame to another frame is not properly controlled, thus resulting a potential abrupt change from one scene toward another. Second, the generated video oftentimes contains many undesired vehicles and people, and the removal of these distracting objects would greatly enhance the quality of the navigational video. In this paper, we first make use of HOG and/or Haar features for detecting vehicles and people, and then we have also made some preliminary trials of using Faster R-CNN and Caffe to speed up detecting vehicles and people. Results are demonstrated to prove the effectiveness of our approaches and compared with similar approaches when applicable to show our improvement. In addition, a post-processing tool is also developed to interactively refine the results in case the automatic object detection is not perfect.
C1 [Cheng, Yuan-Bang; Yang, Chuan-Kai; Chang, Guan-Chung] Natl Taiwan Univ Sci & Technol, Dept Informat Management, 43,Sect 4,Keelung Rd, Taipei 106, Taiwan.
   [Chang, Teng-Wen] Natl Yunlin Univ Sci & Technol, Dept Digital Media Design, 123,Sect 3,Daxue Rd, Douliou City 640, Taiwan.
C3 National Taiwan University of Science & Technology; National Yunlin
   University Science & Technology
RP Yang, CK (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Informat Management, 43,Sect 4,Keelung Rd, Taipei 106, Taiwan.
EM davinban@gmail.com; ckyang@cs.ntust.edu.tw; M10009113@mail.ntust.edu.tw;
   tengwen@yuntech.edu.tw
RI Cheng, Yuan-Bang/H-1158-2014; Chang, Teng-Wen/AAH-3678-2020
OI Cheng, Yuan-Bang/0000-0001-7573-1631; Chang,
   Teng-Wen/0000-0001-9503-2766
FU Ministry of Science and Technology of Taiwan [MOST
   104-2221-E-011-083-MY2, MOST 105-2218-E-011-005, MOST
   105-2218-E-001-001, MOST 106-3114-E-011-003, MOST
   106-2221-E-011-148-MY3, MOST 107-2218-E-011-012]
FX We deeply appreciate the precious comments given by many anonymous
   reviewers. This work was supported in part by the Ministry of Science
   and Technology of Taiwan under the grants MOST 104-2221-E-011-083-MY2,
   MOST 105-2218-E-011-005, MOST 105-2218-E-001-001, MOST
   106-3114-E-011-003, MOST 106-2221-E-011-148-MY3 and MOST
   107-2218-E-011-012.
CR [Anonymous], COMP GRAPH
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chen JB, 2011, 2011 INTERNATIONAL CONFERENCE ON FUTURE COMPUTER SCIENCE AND APPLICATION (FCSA 2011), VOL 3, P230
   Chen Y, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/504896
   Chu WT, 2015, MULTIMED TOOLS APPL, V74, P10965, DOI 10.1007/s11042-014-2213-x
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Flynn J, 2016, PROC CVPR IEEE, P5515, DOI 10.1109/CVPR.2016.595
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Guy Richard, 2012, P SIGCHI C HUM FACT, P405, DOI [10.1145/2207676.2207733, DOI 10.1145/2207676.2207733]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Huang JB, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601205
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Kansal S., 2015, INT J ADV ENG TECHNO, V8, P362
   Kim G, 2012, 2012 12TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS), P625
   Kopf J, 2010, ACM SIGGRAPH 2010 PA
   Le Meur O., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3401, DOI 10.1109/ICIP.2011.6116441
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Malisiewicz T, 2012, EXEMPLAR SVMS VISUAL, V1, plxix
   Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229
   Mortensen E. N., 1995, P 22 ANN C COMP GRAP, P191, DOI DOI 10.1145/218380.218442
   Oliveira MR, 2008, IEEE C TRANSM DISTR, P1
   Prananta E, 2016, TELKOMNIKA, V14, P1009, DOI DOI 10.12928/telkomnika.v14i3.3412
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rybski PE, 2010, IEEE INT VEH SYM, P921, DOI 10.1109/IVS.2010.5547996
   Shih FY, 2005, IMAGE VISION COMPUT, V23, P877, DOI 10.1016/j.imavis.2005.05.015
   Vincent L, 2007, COMPUTER, V40, P118, DOI 10.1109/MC.2007.442
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang J, 2007, ACM SIGGRAPH 2007 SI
   Yang C., 2016, High-Resolution Image Inpainting using Multi-Scale Neural Patch Synthesis
   Ye XH, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION PROBLEM-SOLVING (ICCP), P300, DOI 10.1109/ICCPS.2015.7454156
   Yoshimoto Y., 2011, P ACM INT C INTERACT, P254, DOI [10.1145/2076354.2076402, DOI 10.1145/2076354.2076402]
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
NR 36
TC 1
Z9 2
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16129
EP 16158
DI 10.1007/s11042-018-6880-x
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500018
DA 2024-07-18
ER

PT J
AU El-Bendary, MAM
   Abou El-Azm, AE
AF El-Bendary, Mohsen A. M.
   Abou El-Azm, A. E.
TI Complexity considerations: efficient image transmission over mobile
   communications channels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secured interleaved channel coding technique; Data computational
   complexity; Chaotic-Baker interleaver; Wireless communications;
   Mobility; Image transmission
AB In this paper the computational complexity of the image transmission over mobile communications channel is investigated. The computational complexity due to the amount of transmitted data and the utilized data protection schemes is analyzed over wireless channel with the different image transmission scenarios. The proposed secured and efficient protection technique is presented in this research work with lower computational complexity. The presented technique is based on chaotic-Baker encryption which is utilized as an interleaver to randomize the data packet in the proposed secured interleaved channel coding technique. The proposed technique is evaluated utilizing convolutional codes with different constraint lengths and single error correction block code. Different images with the size variation are utilized for evaluating the proposed image transmission scenarios. Numerical analysis of the different scenarios is presented. The secret key generation of chaotic-Baker encryption is discussed; it can be generated automatically or manually. Several computer simulation experiments are carried out to evaluate the proposed techniques performance. Different objective measures error based metrics are used such as the Bit Error Rate (BER), Peak Signal to Noise Ratio (PSNR) and Number of Lost packet percentage (NLP%) to measure the error performance of the proposed technique and quality of the received images. Simulation results reveal a good performance and the superiority of the proposed technique with lower computational complexity of the proposed image transmission scenarios.
C1 [El-Bendary, Mohsen A. M.] Helwan Univ, Fac Ind Educ, Dept Elect Technol, Cairo, Egypt.
   [Abou El-Azm, A. E.] Menoufia Univ, Fac Elect Egineering, Dept Elect & Elect Commun, Menof, Egypt.
C3 Egyptian Knowledge Bank (EKB); Helwan University; Modern Sciences & Arts
   University (MSA); Egyptian Knowledge Bank (EKB); Menofia University
RP El-Bendary, MAM (corresponding author), Helwan Univ, Fac Ind Educ, Dept Elect Technol, Cairo, Egypt.
EM engmohsen2004@yahoo.com
RI Elazm, Atef Elsayed Abou/AAA-1449-2020; El-Bendary, Mohsen A.
   M./P-8567-2019
OI Elazm, Atef Elsayed Abou/0000-0003-2456-695X; El-Bendary, Mohsen A.
   M./0000-0002-2425-4967
CR ABOUELFADL AA, 2014, LIFE SCI J, V11, P342
   Al-kamali FS., 2018, Am. J. Comput. Commun. Control, V5, P30
   Al-Najjar Y.A.Y., 2012, INT J SCI ENG RES, V3, P8
   [Anonymous], MIXED SIGNAL VLSI WI
   Aziz S. M., 2013, IEEE COMMUNICATIONS, V17
   BHARGAVA V.K., 1981, Digital Communications by Satellite: Modulation, Multiple Access and Coding
   Bouchemel A, 2018, IEEE COMMUN LETT, V22, P934, DOI 10.1109/LCOMM.2018.2812821
   Chan F., 1997, IEEE T COMMUNICATION, V45
   Chen Z, 2018, IEEE T MULTIMEDIA, V20, P1610, DOI 10.1109/TMM.2017.2774004
   Dent P, 1993, ELECT LETT 24, V29
   El-Bendary MA, 2012, WIREL NETW, V19, P517
   El-Bendary MAM, 2017, MULTIMED TOOLS APPL, V76, P26463, DOI 10.1007/s11042-016-4177-5
   Fridrich J, 1997, IEEE SYS MAN CYBERN, P1105, DOI 10.1109/ICSMC.1997.638097
   Gao Wei, 2017, SPRINGER SIGNALS COM, DOI [10.1007/978-3-319-44222-8, DOI 10.1007/978-3-319-44222-8]
   Gazi O, 2006, ETRI J, V28, P453, DOI 10.4218/etrij.06.0105.0187
   Hagenauer J, 1996, IEEE T INFORM THEORY, V42, P429, DOI 10.1109/18.485714
   Han FL, 2006, ISSCAA 2006: 1ST INTERNATIONAL SYMPOSIUM ON SYSTEMS AND CONTROL IN AEROSPACE AND ASTRONAUTICS, VOLS 1AND 2, P1273
   Hemalatha R, 2015, COMPUT ELECTR ENG, V44, P67, DOI 10.1016/j.compeleceng.2015.01.011
   Himeur Y, 2017, MULTIMED TOOLS APPL, V76, P2813, DOI 10.1007/s11042-015-3216-y
   Horé A, 2013, IET IMAGE PROCESS, V7, P12, DOI 10.1049/iet-ipr.2012.0489
   Huang F, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P1340, DOI 10.1109/IIH-MSP.2008.227
   Jiang N, 2017, COMPUT METH PROG BIO, V145, P103, DOI 10.1016/j.cmpb.2017.04.002
   Kaiser M., 2009, PROC 10 INT S COMMUN, P2
   Kasban H, 2017, WIRELESS PERS COMMUN, V94, P1087, DOI 10.1007/s11277-016-3671-4
   Khan MA, 2017, J MODERN OPTICS, V64
   Koduru SC, 2008, 8TH IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY WORKSHOPS: CIT WORKSHOPS 2008, PROCEEDINGS, P260, DOI 10.1109/CIT.2008.Workshops.33
   Kong JJ, 2003, EURASIP J APPL SIG P, V2003, P1328, DOI 10.1155/S1110865703309126
   Lee J. S., 2007, 33 ANN C IEEE IND EL
   Lee SH, 2006, ETRI J, V28, P672, DOI 10.4218/etrij.06.0206.0060
   Lentmaier M, 1999, IEEE COMMUNICATIONS, V3
   Lin S., 1983, Error Control Coding: Fundamentals and Applications
   Loukil H, 2012, INT J COMPUT APPL, V60
   Mohamed MAM, 2008, P 2 INT C EL ENG DES
   Mohsen A.M.El-Bendary, 2018, SPRINGER SIGNALS COM
   Nassar SS, 2016, WIRELESS PERS COMMUN, V91, P1023, DOI 10.1007/s11277-016-3387-5
   Olanigan S, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.1.013024
   Pekhteryev G., 1998, IEEE T COMMUNICATION, V46
   Sidhu B., 2007, WORLD ACAD SCI ENG T, V25
   Tao D, 2016, CHINESE J ELECTRON, V25, P284, DOI 10.1049/cje.2016.03.014
   Usman K, 2007, HEALTHCOM 2007: UBIQUITOUS HEALTHCARE IN AGING SOCIETIES, P244, DOI 10.1109/HEALTH.2007.381640
   Vafi S, 2005, 6th Australian Communications Theory Workshop 2005, Proceedings, P8
   Xu C, 2007, VEH TECHN C
   Xu HS, 2015, DIGIT COMMUN NETW, V1, P213, DOI 10.1016/j.dcan.2015.05.002
   Xuelan Z, 2010, CHIN J ELECT, V19
   Yahong Zheng R, 2002, IEEE COMMUNICATIONS, V6
   Yin JJ, 2018, DIGIT SIGNAL PROCESS, V81, P173, DOI 10.1016/j.dsp.2018.06.014
   Yuan D, 1991, IEEE TENCON 91 INDIA
   Yuan DF, 2000, P IEEE WIR COMM NETW, V2, P634
   Zhang H, 2004, ICCCAS INT C COMM CI
   Zhang Y, 2012, PROCEDIA ENGINEER, V29, P3322, DOI 10.1016/j.proeng.2012.01.488
   Zheng Y, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P62, DOI 10.1109/AVSS.2014.6918645
   Zhuang Y, 2016, MULTIMED TOOLS APPL, V75, P2931, DOI 10.1007/s11042-014-2413-4
NR 52
TC 14
Z9 14
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16633
EP 16664
DI 10.1007/s11042-018-6843-2
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500041
DA 2024-07-18
ER

PT J
AU Guo, FH
   Zhang, CM
AF Guo, Fenghua
   Zhang, Caiming
TI Edge preserving mixed noise removal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mixed Noise Removal; Edge Preserving; High-frequency Components
ID IMPULSE NOISE; MEDIAN FILTERS; IMAGE; SPARSE; RESTORATION; ALGORITHMS
AB To faithfully recover the clean images corrupted by additive white Gaussian noise (AWGN) and impulse noise (IN), a novel edge preserving image denoising algorithm is proposed. The low- and high-frequency components of the image are restored separately. The high-frequency components of the images are restored based on nonlocal self-similarity (NSS) learning from natural images. An energy minimization function is developed to combine the low- and high-frequency components into one model. Experiments demonstrate that the proposed method outperforms existing mixture noise removal methods in peak signal-to-noise ratio (PSNR), edges preservation and visual performance.
C1 [Guo, Fenghua; Zhang, Caiming] Shandong Univ, Sch Software, Jinan 250101, Shandong, Peoples R China.
C3 Shandong University
RP Zhang, CM (corresponding author), Shandong Univ, Sch Software, Jinan 250101, Shandong, Peoples R China.
EM czhang@sdu.edu.cn
RI Cheng, Lin/KFQ-3111-2024
OI Guo, Fenghua/0000-0003-3623-221X
FU National Natural Science Foundation of China [61772312, 61602277]; NSFC
   Joint Fund with Zhejiang Integration of Informatization and
   Industrialization under Key Project [U1609218]; Natural Science
   Foundation of Shandong Province, China [ZR2017MF033]
FX The authors would like to thank the reviewers for their invaluable
   comments. This work was supported partly by National Natural Science
   Foundation of China (No. 61772312, 61602277), NSFC Joint Fund with
   Zhejiang Integration of Informatization and Industrialization under Key
   Project(U1609218) and Natural Science Foundation of Shandong Province,
   China (No. ZR2017MF033).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Anderson M, 2012, INT CONF ACOUST SPEE, P1885, DOI 10.1109/ICASSP.2012.6288271
   Bovik Alan C, 2010, Handbook of image and video processing
   BROWNRIGG DRK, 1984, COMMUN ACM, V27, P807, DOI 10.1145/358198.358222
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Cai JF, 2008, INVERSE PROBL IMAG, V2, P187
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Chang H, 2014, IEEE C COMP VIS PATT, P275
   Chen CLP, 2015, IEEE T IMAGE PROCESS, V24, P4014, DOI 10.1109/TIP.2015.2456432
   Chen T, 1999, IEEE T IMAGE PROCESS, V8, P1834, DOI 10.1109/83.806630
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong YQ, 2007, IEEE SIGNAL PROC LET, V14, P193, DOI 10.1109/LSP.2006.884014
   Gilboa G, 2008, MULTISCALE MODEL SIM, V7, P1005, DOI 10.1137/070698592
   Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5
   Guo FH, 2018, IET IMAGE PROCESS, V12, P1394, DOI 10.1049/iet-ipr.2017.0880
   Huang T, 2017, IEEE T IMAGE PROCESS, V26, P3171, DOI 10.1109/TIP.2017.2676466
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Ji H, 2011, SIAM J IMAGING SCI, V4, P1122, DOI 10.1137/100817206
   Ji H, 2010, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2010.5539849
   Jiang JL, 2014, IEEE T IMAGE PROCESS, V23, P2651, DOI 10.1109/TIP.2014.2317985
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   Li YR, 2011, IEEE T IMAGE PROCESS, V20, P1822, DOI 10.1109/TIP.2010.2103950
   Li YH, 2015, INT CONF ACOUST SPEE, P1201, DOI 10.1109/ICASSP.2015.7178160
   Liu J, 2013, IEEE T IMAGE PROCESS, V22, P1108, DOI 10.1109/TIP.2012.2227766
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   NIEMINEN A, 1987, IEEE T PATTERN ANAL, V9, P74, DOI 10.1109/TPAMI.1987.4767873
   Nikolova M, 2004, J MATH IMAGING VIS, V20, P99, DOI 10.1023/B:JMIV.0000011920.58935.9c
   Pok G, 2003, IEEE T IMAGE PROCESS, V12, P85, DOI 10.1109/TIP.2002.804278
   SUN T, 1994, PATTERN RECOGN LETT, V15, P341, DOI 10.1016/0167-8655(94)90082-5
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Xiao Y, 2011, PATTERN RECOGN, V44, P1708, DOI 10.1016/j.patcog.2011.02.002
   Xu J, 2015, IEEE I CONF COMP VIS, P244, DOI 10.1109/ICCV.2015.36
   Yan M, 2013, SIAM J IMAGING SCI, V6, P1227, DOI 10.1137/12087178X
   Zhang F, 2015, J COMPUT SCI TECH-CH, V30, P489, DOI 10.1007/s11390-015-1539-9
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang ML, 2017, IET IMAGE PROCESS, V11, P54, DOI 10.1049/iet-ipr.2016.0098
   Zhu Y, 2014, PROC CVPR IEEE, P2917, DOI 10.1109/CVPR.2014.373
NR 44
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16601
EP 16613
DI 10.1007/s11042-018-7004-3
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500039
DA 2024-07-18
ER

PT J
AU Qasim, AF
   Aspin, R
   Meziane, F
   Hogg, P
AF Qasim, Asaad F.
   Aspin, Rob
   Meziane, Farid
   Hogg, Peter
TI ROI-based reversible watermarking scheme for ensuring the integrity and
   authenticity of DICOM MR images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical imaging; Reversible watermarking; Difference expansion; DICOM;
   Integrity; Authenticity
ID DATA HIDING SCHEME; MEDICAL IMAGES; HIGH-CAPACITY; DIFFERENCE EXPANSION;
   CONTRAST ENHANCEMENT; TAMPER LOCALIZATION; INFORMATION
AB Reversible and imperceptible watermarking is recognized as a robust approach to confirm the integrity and authenticity of medical images and to verify that alterations can be detected and tracked back. In this paper, a novel blind reversible watermarking approach is presented to detect intentional and unintentional changes within brain Magnetic Resonance (MR) images. The scheme segments images into two parts; the Region of Interest (ROI) and the Region of Non Interest (RONI). Watermark data is encoded into the ROI using reversible watermarking based on the Difference Expansion (DE) technique. Experimental results show that the proposed method, whilst fully reversible, can also realize a watermarked image with low degradation for reasonable and controllable embedding capacity. This is fulfilled by concealing the data into smooth' regions inside the ROI and through the elimination of the large location map required for extracting the watermark and retrieving the original image. Our scheme delivers highly imperceptible watermarked images, at 92.18-99.94dB Peak Signal to Noise Ratio (PSNR) evaluated through implementing a clinical trial based on relative Visual Grading Analysis (relative VGA). This trial defines the level of modification that can be applied to medical images without perceptual distortion. This compares favorably to outcomes reported under current state-of-art techniques. Integrity and authenticity of medical images are also ensured through detecting subsequent changes enacted on the watermarked images. This enhanced security measure, therefore, enables the detection of image manipulations, by an imperceptible approach, that may establish increased trust in the digital medical workflow.
C1 [Qasim, Asaad F.; Aspin, Rob] Univ Salford, Sch Comp Sci & Engn, Salford, Lancs, England.
   [Meziane, Farid] Univ Salford, Sch Comp Sci & Engn, Data & Knowledge Engn, Salford, Lancs, England.
   [Meziane, Farid] Univ Salford, Sch Comp Sci & Engn, Informat Res Ctr, Salford, Lancs, England.
   [Qasim, Asaad F.] Minist Higher Educ & Sci Res, Baghdad, Iraq.
   [Hogg, Peter] Univ Salford, Sch Hlth Sci, Salford, Lancs, England.
C3 University of Salford; University of Salford; University of Salford;
   University of Salford
RP Qasim, AF (corresponding author), Univ Salford, Sch Comp Sci & Engn, Salford, Lancs, England.; Qasim, AF (corresponding author), Minist Higher Educ & Sci Res, Baghdad, Iraq.
EM A.Qasim@edu.salford.ac.uk; R.Aspin@salford.ac.uk;
   F.Meziane@salford.ac.uk; P.Hogg@salford.ac.uk
RI Meziane, Farid/ABE-9919-2020
OI Meziane, Farid/0000-0001-9811-6914; Aspin, Rob/0000-0002-2202-1326
FU ministry of higher education and scientific research (Iraq)
FX We would like to thank the ministry of higher education and scientific
   research (Iraq), for providing scholarship support to the first author
   of this research paper.
CR Abd-Eldayem MM, 2013, EGYPT INFORM J, V14, P1, DOI 10.1016/j.eij.2012.11.002
   Al-Qershi OM, 2011, J SYST SOFTWARE, V84, P105, DOI 10.1016/j.jss.2010.08.055
   Alattar AM, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P377
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Alattar AM, 2003, IEEE IMAGE PROC, P501
   Ali AH, 2018, MULTIMED TOOLS APPL, V77, P31487, DOI 10.1007/s11042-018-6213-0
   [Anonymous], 2014, INT J TELEMED APPL
   Arsalan M, 2012, J SYST SOFTWARE, V85, P883, DOI 10.1016/j.jss.2011.11.005
   Atta-ur Rahman, 2018, COMPUT MATH METHODS, P1
   Balasamy K., 2018, CLUSTER COMPUT, V22, P1, DOI [10.1007/s10586-018-1991-8, DOI 10.1007/S10586-018-1991-8]
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chiang KH, 2008, J DIGIT IMAGING, V21, P77, DOI 10.1007/s10278-007-9012-0
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Coatrieux G, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P4691
   Das S, 2013, COMPUT METH PROG BIO, V111, P662, DOI 10.1016/j.cmpb.2013.05.027
   Gao GY, 2017, INFORM SCIENCES, V385, P250, DOI 10.1016/j.ins.2017.01.009
   Hasan Ali M., 2016, BIOSTEC 2016. 9th International Joint Conference on Biomedical Engineering Systems and Technologies. Proceedings: Bioimaging, P55
   Hasan AM, 2016, SYMMETRY-BASEL, V8, DOI 10.3390/sym8110132
   Hasan AM, 2016, COMPUT ELECTR ENG, V53, P276, DOI 10.1016/j.compeleceng.2016.03.008
   He WG, 2017, J VIS COMMUN IMAGE R, V49, P351, DOI 10.1016/j.jvcir.2017.10.001
   Kamran, 2014, INFORM SCIENCES, V256, P162, DOI 10.1016/j.ins.2013.07.035
   Ko L.T., 2012, COMPUT MATH METHOD M, V2012, P1
   Kumar CV, 2016, COMPUT ELECTR ENG, V53, P333, DOI 10.1016/j.compeleceng.2015.11.033
   Larobina M, 2014, J DIGIT IMAGING, V27, P200, DOI 10.1007/s10278-013-9657-9
   Lee S-H, 2017, MULTIMED TOOLS APPL, V77, P1, DOI [10.1007/s11042-015-3011-9, DOI 10.1007/S11042-015-3011-9]
   Lei BY, 2014, EXPERT SYST APPL, V41, P3178, DOI 10.1016/j.eswa.2013.11.019
   Li F, 2018, MULTIMED TOOLS APPL, V77, P5149, DOI 10.1007/s11042-017-4388-4
   Liew SC, 2013, J DIGIT IMAGING, V26, P316, DOI 10.1007/s10278-012-9484-4
   Maity H.K., 2012, The International Journal of Multimedia Its Applications (IJMA), V4, P83, DOI DOI 10.5121/ijma.2012.4408
   Kobayashi LOM, 2009, IEEE T INF TECHNOL B, V13, P582, DOI 10.1109/TITB.2009.2014751
   Mousavi SM, 2014, J DIGIT IMAGING, V27, P714, DOI 10.1007/s10278-014-9700-5
   Pan W, 2018, COMPUT METH PROG BIO, V160, P119, DOI 10.1016/j.cmpb.2018.03.011
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Pianykh O, 2009, Digital imaging and communications in medicine (DICOM): a practical introduction and survival guide
   Qasim AF, 2018, P 24 INT C AUT COMP
   Qasim AF, 2019, SIGNAL PROCESS-IMAGE, V70, P246, DOI 10.1016/j.image.2018.10.007
   Qasim AF, 2018, COMPUT SCI REV, V27, P45, DOI 10.1016/j.cosrev.2017.11.003
   Rocek A, 2016, BIOMED SIGNAL PROCES, V29, P44, DOI 10.1016/j.bspc.2016.05.005
   Selvam P, 2017, OPTIK, V145, P655, DOI 10.1016/j.ijleo.2017.07.060
   Soille P., 2013, MORPHOLOGICAL IMAGE
   Tan CK, 2011, J DIGIT IMAGING, V24, P528, DOI 10.1007/s10278-010-9295-4
   Nguyen TS, 2015, J VIS COMMUN IMAGE R, V33, P389, DOI 10.1016/j.jvcir.2015.10.008
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Yang Y, 2018, MULTIMED TOOLS APPL, V77, P18043, DOI 10.1007/s11042-017-4444-0
NR 45
TC 21
Z9 22
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16433
EP 16463
DI 10.1007/s11042-018-7029-7
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500032
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Saric, Z
   Subotic, M
   Bilibajkic, R
   Barjaktarovic, M
AF Saric, Zoran
   Subotic, Misko
   Bilibajkic, Ruzica
   Barjaktarovic, Marko
TI Bidirectional microphone array with adaptation controlled by voice
   activity detector based on multiple beamformers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Microphone array; Speech enhancement; Adaptive beamforming;
   Super-directive microphone array; Voice activity detection; Speech
   therapy
ID SEPARATION
AB Ambient noise suppression in a reverberant room is usually performed by the microphone array. The adaptive beamforming, whose typical representative is minimum variance distortionless (MVDR) beamformer, is an effective method for noise suppression. However, MVDR beamformer gives poor results in the real room because of its sensitivity to the steering error and the multipath wave propagation. In this paper we propose a noise suppression method based on assumption that the positions of the speakers in the reverberant room are roughly known. Noise reduction is realized by two MVDR beamformers directed toward each of the speakers. Adaptation of the MVDR beamformers are controlled by a speaker activity detector which decision is based on power transfer model of the multiple superdirective beamformers in combined diffuse and coherent noise field. The proposed voice activity detector also provides residual noise reduction. The proposed method and its robustness to steering error were tested on the model of simulated room as well as in real room environment. The improvement of the restored speech signal was evaluated by Signal to Noise Ratio Enhancement (SNRE) and by Perceptual evaluation of speech quality (PESQ) measure.
C1 [Saric, Zoran; Subotic, Misko; Bilibajkic, Ruzica] Life Act Advancement Ctr, Lab Acoust, Gospodar Jovanova 35, Belgrade 11000, Serbia.
   [Barjaktarovic, Marko] Univ Belgrade, Fac Elect Engn, Belgrade, Serbia.
C3 University of Belgrade
RP Saric, Z (corresponding author), Life Act Advancement Ctr, Lab Acoust, Gospodar Jovanova 35, Belgrade 11000, Serbia.
EM sariczoran@yahoo.com; m.subotic@add-for-life.com;
   r.bilibajkic@add-for-life.com; mbarjaktarovic@etf.bg.ac.rs
RI Bilibajkic, Ruzica/AAC-2521-2020; Barjaktarovic, Marko/F-7533-2011;
   Subotic, Misko/AAC-4803-2020
OI Barjaktarovic, Marko/0000-0002-6113-629X; Bilibajkic,
   Ruzica/0000-0003-0869-0395; Subotic, Misko/0000-0001-7945-2824; Saric,
   Zoran/0000-0001-9964-9974
FU Ministry of Education, Science and Technological Development of the
   Republic of Serbia [178027, TR32032, TR32035]
FX This research was supported by grants 178027, TR32032 and TR32035 from
   the Ministry of Education, Science and Technological Development of the
   Republic of Serbia.
CR Agnew J, 2000, J Am Acad Audiol, V11, P330
   ALLEN JB, 1979, J ACOUST SOC AM, V65, P943, DOI 10.1121/1.382599
   [Anonymous], 2009, Distant Speech Recognition
   Bitzer J, 2001, DIGITAL SIGNAL PROC, P19
   Cabañas-Molero P, 2018, MULTIMED TOOLS APPL, V77, P27685, DOI 10.1007/s11042-018-5944-2
   DeFatta D, 1988, DIGITAL SIGNAL PROCE
   FarhangBoroujeny B., 1998, Adaptive Filters: Theory and Applications, V3rd ed.
   FROST OL, 1972, PR INST ELECTR ELECT, V60, P926, DOI 10.1109/PROC.1972.8817
   GRIFFITHS LJ, 1982, IEEE T ANTENN PROPAG, V30, P27, DOI 10.1109/TAP.1982.1142739
   Hoshuyama O, 1999, IEEE T SIGNAL PROCES, V47, P2677, DOI 10.1109/78.790650
   ITU-T, 2001, PERCEPTUAL EVALUATIO
   Jovicic ST, 2005, ACOUST RES LETT ONL, V6, P232, DOI 10.1121/1.1989785
   Marro C, 1998, IEEE T SPEECH AUDI P, V6, P240, DOI 10.1109/89.668818
   McCowan AI, 2003, IEEE T SPEECH AUDIO, V11
   Papp II, 2007, J ACOUST SOC AM, V122, pEL44, DOI 10.1121/1.2749077
   Parra L, 2000, IEEE T SPEECH AUDI P, V8, P320, DOI 10.1109/89.841214
   Parra LC, 2002, IEEE T SPEECH AUDI P, V10, P352, DOI 10.1109/TSA.2002.803443
   Saric ZM, 2004, ACOUST RES LETT ONL, V5, P68, DOI 10.1121/1.1650411
   Saric ZM, 2011, CIRC SYST SIGNAL PR, V30, P483, DOI 10.1007/s00034-010-9233-1
   Simmer KU, 2001, DIGITAL SIGNAL PROC, P39
   Spriet A, 2002, EUR T TELECOMMUN, V13, P149, DOI 10.1002/ett.4460130210
   Van Trees Harry L., 2004, OPTIMUM ARRAY PROCES, DOI DOI 10.1002/0471221104
   Wang L, 2010, EURASIP J AUDIO SPEE, DOI 10.1155/2010/797962
   White G., 2005, AUDIO DICT REVISED E
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Zelinski R., 1988, ICASSP 88: 1988 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.88CH2561-9), P2578, DOI 10.1109/ICASSP.1988.197172
NR 26
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15235
EP 15254
DI 10.1007/s11042-018-6895-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700048
DA 2024-07-18
ER

PT J
AU El Bouny, L
   Khalil, M
   Adib, A
AF El Bouny, Lahcen
   Khalil, Mohammed
   Adib, Abdellah
TI ECG signal filtering based on CEEMDAN with hybrid interval thresholding
   and higher order statistics to select relevant modes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ECG; Denoising; EMD; EEMD; CEEMDAN; Interval thresholding; Higher order
   statistics
ID SIMILARITY MEASURE; EMD; DECOMPOSITION
AB In this paper, we propose a novel ECG signal enhancement method based on Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN) and Higher Order Statistics (HOS). In our scheme, the noisy ECG signal is first decomposed adaptively into oscillatory components called intrinsic mode functions (IMFs) by using Empirical Mode Decomposition (EMD) or its variants. Therefore, the obtained modes are separated into two groups of noisy signal modes and one group of useful signal modes, by using a novel criterion derived from the HOS namely the fourth order cumulant or kurtosis. After that, a modified shrinkage scheme based on Interval Thresholding technique is adaptively applied to each selected IMF from the noise-dominant groups in order to reduce the noise and to preserve the QRS complex. The overall filtered ECG signal is then reconstructed by combining the thresholded IMFs and the retained unprocessed lower frequency relevant IMFs. Various tests and simulations are investigated to evaluate the performance of our proposed approach in combination with the EMD, Ensemble EMD (EEMD) and CEEMDAN algorithms. The simulation results carried on MIT-BIH Arrhythmia database, show that CEEMDAN method gives better performance than the two other methods, and outperforms some state-of-the-art methods in terms of Signal to Noise Ratio (SNR) and Root Mean Square Error (RMSE).
C1 [El Bouny, Lahcen; Khalil, Mohammed; Adib, Abdellah] LIM II FSTM, BP 146, Mohammadia 20650, Morocco.
RP El Bouny, L (corresponding author), LIM II FSTM, BP 146, Mohammadia 20650, Morocco.
EM lahcenbouny@gmail.com; medkhalil87@gmail.com; adib@fstm.ac.ma
RI ADIB, Abdellah/HTQ-2801-2023
OI ADIB, Abdellah/0000-0002-0670-7221; Khalil, Mohammed/0000-0002-4211-1011
FU National Center for Scientific and Technical Research of Morocco (CNRST)
   [148UH22017]
FX This research was supported by the National Center for Scientific and
   Technical Research of Morocco (CNRST) (grant number : 148UH22017).
CR [Anonymous], 2008, Am. J. Appl. Sci., DOI [10.3844/ajassp.2008.276.281, DOI 10.3844/AJASSP.2008.276.281]
   Ari S, 2013, COMPUT BIOL MED, V43, P649, DOI 10.1016/j.compbiomed.2013.02.015
   Blanco-Velasco M, 2008, COMPUT BIOL MED, V38, P1, DOI 10.1016/j.compbiomed.2007.06.003
   Boudraa AO, 2007, IEEE T INSTRUM MEAS, V56, P2196, DOI 10.1109/TIM.2007.907967
   Bouny L.E., 2017, 2017 International Conference on Advanced Technologies for Signal and Image Processing (ATSIP), P1, DOI DOI 10.1109/ATSIP.2017.8075546
   Chang KM, 2011, J SIGNAL PROCESS SYS, V64, P249, DOI 10.1007/s11265-009-0447-z
   Chawla MPS, 2009, NEURAL COMPUT APPL, V18, P539, DOI 10.1007/s00521-008-0195-1
   Clifford GD., 2006, ARTECH HOUSE BOSTON, V45, P1
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   EL bouny L, 2017, IEEE ICEIT INT C RAB
   El Hamdouni N, 2013, MULTIMED TOOLS APPL, V64, P809, DOI 10.1007/s11042-012-0988-1
   Erçelebi E, 2004, COMPUT BIOL MED, V34, P479, DOI 10.1016/S0010-4825(03)00090-8
   Flandrin Patrick, 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P1581
   He TG, 2006, NEURAL COMPUT APPL, V15, P105, DOI 10.1007/s00521-005-0013-y
   Hong HB, 2007, J VIB ACOUST, V129, P458, DOI 10.1115/1.2748467
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Kabir MA, 2012, BIOMED SIGNAL PROCES, V7, P481, DOI 10.1016/j.bspc.2011.11.003
   Khaldi K, 2008, 2008 3RD INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING, VOLS 1-3, P1155, DOI 10.1109/ISCCSP.2008.4537399
   Khaldi K, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/873204
   Khalil M., 2012, INT S COMM CONTR SIG
   Komarov AS, 2014, IEEE T GEOSCI REMOTE, V52, P121, DOI 10.1109/TGRS.2012.2236845
   Komaty A, 2014, IEEE T INSTRUM MEAS, V63, P27, DOI 10.1109/TIM.2013.2275243
   Kopsinis Y., 2008, PROC 1 INT WORKSHOP, P1
   Kopsinis Y, 2009, IEEE T SIGNAL PROCES, V57, P1351, DOI 10.1109/TSP.2009.2013885
   Maniruzzaman M, 2012, INT C INF EL VIS
   Nason G. P., 1995, LECT NOTES STAT, V103, P281
   Nimunkar AJ, 2007, P ANN INT IEEE EMBS, P1904, DOI 10.1109/IEMBS.2007.4352688
   Nguyen P, 2016, INFORM SCIENCES, V373, P499, DOI 10.1016/j.ins.2016.09.033
   Poornachandra S, 2008, DIGIT SIGNAL PROCESS, V18, P49, DOI 10.1016/j.dsp.2007.09.006
   Rilling G, 2009, IEEE SIGNAL PROCESSI, V11, P112
   Sameni R, 2007, IEEE T BIO-MED ENG, V54, P2172, DOI 10.1109/TBME.2007.897817
   Sayadi O, 2006, 28 IEEE EMBS ANN INT
   Seema rani., 2011, International Journal of Computer Science and Information Technologies(IJCSIT), V2, P1105
   Sharma LN, 2010, BIOMED SIGNAL PROCES, V5, P214, DOI 10.1016/j.bspc.2010.03.003
   Suchetha M, 2013, BIOMED SIGNAL PROCES, V8, P575, DOI 10.1016/j.bspc.2013.05.001
   Torres ME, 2011, INT CONF ACOUST SPEE, P4144
   Tsolis G., 2011, International Journal of Signal Processing, Image Processing and 136 Pattern Recognition, V4, P91
   Wu ZH, 2004, P ROY SOC A-MATH PHY, V460, P1597, DOI 10.1098/rspa.2003.1221
   Wu ZH, 2009, ADV DATA SCI ADAPT, V1, P1, DOI 10.1142/S1793536909000047
   Yang GL, 2015, SIGNAL PROCESS, V109, P95, DOI 10.1016/j.sigpro.2014.10.038
NR 40
TC 18
Z9 18
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13067
EP 13089
DI 10.1007/s11042-018-6143-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900018
DA 2024-07-18
ER

PT J
AU Kowalczyk, P
   Sawicki, D
AF Kowalczyk, Piotr
   Sawicki, Dariusz
TI Blink and wink detection as a control tool in multimodal interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal interaction; Blinking; Winking; Eye state recognition
ID MOVEMENTS
AB The problem of multimodal interaction is discussed. The use of blinking and winking, interpreted as eye gestures, is considered. The main aim of this study is to propose a simple method that allows the recognition of the state of the eye: open or closed; and to distinguish between blinking and winking. Wearable technology has been used in the introduced solution. Placing the camera close to the eye allows us to simplify the complicated image analysis. The proposed method works irrespective of the user's location and his/her gaze direction. Further, the use of infrared radiation limits the influence of external disturbing factors such as lighting conditions and pollution. The new solution is tested in two types of experiments: with 2x5000 pictures of open and closed eyes and with a group of 30 participants. The total correctness of the eye state recognition is 99.68% (99.94% for open eyes and 99.42% for closed ones). This result implies that the proposed solution can be effectively applied to real-world scenarios. Two applications are considered. In the first one, blinking recognition allows us to check whether safety glasses are used appropriately. In the second application, the control of mouse keys is replaced with eye gestures interpreted from a winking analysis. The introduced solution allows for effective and correct eye state recognition. The new method of control by eye gestures was accepted by the participants of this study.
C1 [Kowalczyk, Piotr; Sawicki, Dariusz] Warsaw Univ Technol, Warsaw, Poland.
   [Sawicki, Dariusz] Warsaw Univ Technol, Inst Theory Elect Engn Measurement & Informat Sys, Warsaw, Poland.
C3 Warsaw University of Technology; Warsaw University of Technology
RP Sawicki, D (corresponding author), Warsaw Univ Technol, Warsaw, Poland.; Sawicki, D (corresponding author), Warsaw Univ Technol, Inst Theory Elect Engn Measurement & Informat Sys, Warsaw, Poland.
EM Dariusz.Sawicki@ee.pw.edu.pl
RI Sawicki, Dariusz/AFT-3396-2022
OI Sawicki, Dariusz/0000-0003-3990-0121
CR Al-Rahayfeh A, 2013, IEEE J TRANSL ENG HE, V1, DOI 10.1109/JTEHM.2013.2289879
   [Anonymous], 2012, ISO 9241-411:2012
   Bacivarov I, 2008, IEEE T CONSUM ELECTR, V54, P1312, DOI 10.1109/TCE.2008.4637622
   Baranoski G., 2010, Light & Skin Interactions: Simulations for Computer Graphics Applications
   Bartkowiak G, 2012, HDB HUMAN FACTORS ER, DOI [10. 1002/9781118131350. ch30, DOI 10.1002/9781118131350.CH30]
   Bastos T, 2013, ISSNIP BIOSIG BIOROB, P12
   Calvo AA, 2014, AHCI, V2014, P10
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dorsey J., 2007, DIGITAL MODELING MAT
   EVINGER C, 1991, INVEST OPHTH VIS SCI, V32, P387
   Grauman K, 2001, PROC CVPR IEEE, P1010
   Grauman Kristen, 2003, Universal Access in the Information Society, V2, P359, DOI [10.1007/s10209-003-0062-x, DOI 10.1007/s10209-003-0062-x]
   Le H, 2013, IEEE INT SYM MULTIM, P305, DOI 10.1109/ISM.2013.59
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   Kapoor Ashish., 2001, Proceedings of the 2001 workshop on Perceptive user interfaces, P1
   Karson C N, 1988, Adv Neurol, V49, P25
   Kim D, 2011, PROC SPIE, V7863, DOI 10.1117/12.873354
   Kim S, 2010, INT CONF BIOMED, P1503, DOI 10.1109/BMEI.2010.5639399
   Kojima N., 2001, IVEC2001. Proceedings of the IEEE International Vehicle Electronics Conference 2001. IVEC 2001 (Cat. No.01EX522), P31, DOI 10.1109/IVEC.2001.961722
   Krishna G. V. S., 2013, INT J ADVANCEMENTS R, V2, P289
   Krishnasree V., 2014, WSEAS Transactions on Signal Processing, V10, P146
   Liu Jian-zheng, 2011, Proceedings of the 2011 Seventh International Conference on Networked Computing and Advanced Information Management (NCM), P232
   Liu K., 2008, Proc. Vehicle Power and Propulsion Conference (VPPC'08), P1, DOI [10.1109/VPPC.2008.4677536, DOI 10.1109/VPPC.2008.4677536]
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Mandal B, 2012, IEEE ENG MED BIO, P6060, DOI 10.1109/EMBC.2012.6347376
   Manogna S., 2010, Proc.4th International Conference on Bioinformatics and Biomedical Engineering (iCBBE), P1, DOI DOI 10.1109/ICBBE.2010.5517790
   Nakano T, 2013, P NATL ACAD SCI USA, V110, P702, DOI 10.1073/pnas.1214804110
   Patel RA, 2015, IJEDR, V3, P168
   Ponder E., 1927, Q J EXP PHYSL, V18, P99
   Sawicki DJ, 2015, IET IMAGE PROCESS, V9, P751, DOI 10.1049/iet-ipr.2014.0859
   Schiffman HarveyRichard., 2001, SENSATION PERCEPTION
   Singh H., 2012, Int. J. Sci. Res. Publ, V2, P1, DOI DOI 10.1371/J0URNAL.P0NE.0029319
   Smith S, 2010, WORKERS ARE RISKING
   Strumillo P, 2012, 2012 JOINT CONFERENCE NEW TRENDS IN AUDIO & VIDEO AND SIGNAL PROCESSING: ALGORITHMS, ARCHITECTURES, ARRANGEMENTS, & APPLICATIONS (NTAV-SPA 2012), P143
   Tada H, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0066018
   Wolska A, 2013, ARTIFICIAL OPTICAL R
NR 37
TC 14
Z9 15
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13749
EP 13765
DI 10.1007/s11042-018-6554-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900051
OA hybrid
DA 2024-07-18
ER

PT J
AU Mohtasham-zadeh, V
   Mosleh, M
AF Mohtasham-zadeh, Vahid
   Mosleh, Mohammad
TI Audio Steganalysis based on collaboration of fractal dimensions and
   convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio steganography; Audio steganalysis; Fractal dimensions;
   Convolutional neural networks (CNN)
AB Steganography is the art of concealing a message within a cover media with the least understandable changes. On the other hand, steganalysis algorithms try to distinguish information-carrying signals from clean signals. This paper proposes a new approach to audio steganalysis that uses fractal dimensions as features and convolutional neural network (CNN) as a classifier. Fractal dimensions are extracted using Higuchi's, Katz's, and Petrosian's algorithms. Hide4PGP and StegHide are the two steganography tools employed at different embedding rates. In order to evaluate the proposed audio steganalysis system, we use 10 audio samples, consisting of 4000 clean and steganographic frames. The proposed system has been compared with several audio steganalysis systems based on MFCC, Wavelet, 2D-MFCC, R-MFCC and LPC as well as classifiers LDA, SVM and KNN. According to the experiment results, the proposed audio steganalysis system shows a so better performance than other systems and brings above 99.5%.
C1 [Mohtasham-zadeh, Vahid; Mosleh, Mohammad] Islamic Azad Univ, Dezful Branch, Dept Comp Engn, Dezful, Iran.
C3 Islamic Azad University
RP Mosleh, M (corresponding author), Islamic Azad Univ, Dezful Branch, Dept Comp Engn, Dezful, Iran.
EM Mosleh@iaud.ac.ir
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Al-Juaid N, 2018, J COMPUT HARDWARE EN, V1
   [Anonymous], 2018, J Inf Secur Cybercrimes Res (JISCR), DOI DOI 10.26735/16587790.2018.006
   [Anonymous], 2014, INT C ADV ENG TECHN
   BURROUGH PA, 1981, NATURE, V294, P240, DOI 10.1038/294240a0
   Esteller R, 2001, IEEE T CIRCUITS-I, V48, P177, DOI 10.1109/81.904882
   Geetha S, 2010, EXPERT SYST APPL, V37, P7469, DOI 10.1016/j.eswa.2010.04.012
   Ghasemzadeh H, 2016, DIGIT SIGNAL PROCESS, V51, P133, DOI 10.1016/j.dsp.2015.12.015
   Goh C., 2005, CIMED2005. Proceedings of the 2nd International Conference on Computational Intelligence in Medicine and Healthcare, P464
   Gutub A., 2008, WoSPA 2008 - 5th IEEE International Workshop on Signal Processing and its Applications, P18
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Han CL, 2018, MULTIMED TOOLS APPL, V77, P15431, DOI 10.1007/s11042-017-5123-x
   Hetzl S., 2003, StegHide Steganography
   Johnson MK, 2005, INT SOC OPTICS PHOTO, P664
   Khan F, 2007, 4 IEEE GCC C EXH GUL, P11
   Koçal OH, 2008, IEEE T INF FOREN SEC, V3, P651, DOI 10.1109/TIFS.2008.2004289
   Kraetzer C, 2007, PROC SPIE, V6505, DOI 10.1117/12.704040
   Latifpour H, 2015, INT J SPEECH TECHNOL, V18, P697, DOI 10.1007/s10772-015-9318-0
   Li CR, 2009, NSWCTC 2009: INTERNATIONAL CONFERENCE ON NETWORKS SECURITY, WIRELESS COMMUNICATIONS AND TRUSTED COMPUTING, VOL 1, PROCEEDINGS, P240, DOI 10.1109/NSWCTC.2009.78
   Liu QZ, 2009, IEEE T INF FOREN SEC, V4, P359, DOI 10.1109/TIFS.2009.2024718
   Mohsenfar SM, 2015, MULTIMED TOOLS APPL, V74, P759, DOI 10.1007/s11042-013-1694-3
   Mosleh M, 2016, FRONT INFORM TECH EL, V17, P1320, DOI 10.1631/FITEE.1500297
   Özer H, 2003, PROC SPIE, V5020, P55, DOI 10.1117/12.477313
   Paulin C, 2016, IEEE C EV COMP CEC I
   Paulin C, 2016, INT J SPEECH TECHNOL, V19, P585, DOI 10.1007/s10772-016-9352-6
   Petry A, 2002, CHAOS SOLITON FRACT, V13, P221, DOI 10.1016/S0960-0779(00)00260-5
   Repp H., 1996, Hide4PGP Steganography
NR 28
TC 2
Z9 3
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11369
EP 11386
DI 10.1007/s11042-018-6702-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900013
DA 2024-07-18
ER

PT J
AU Zhu, QD
   Wang, YK
   He, YQ
   Hong, X
AF Zhu, Qidan
   Wang, Yanke
   He, Yunqian
   Hong, Xiao
TI Object tracking with particles weighted by region proposal network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Particle filter; Region proposal network; Anchor score
ID FILTER
AB Most of existing particle filters suffer from computation of weights and almost all object detection networks have the risk of missing objects. Therefore, we propose a novel way to calculate the weight for each particle using the anchor scores output from region proposal network (RPN) in Faster RCNN. We first change the original anchor style in RPN slightly while training and then cast particles in feature space of VGG16 to do filtering both for center and scale. Without fully connected layers, it can lower the computational cost to a large extent and it can effectively maintain an accurate prediction of the posterior density using less than 30 particles. When increasing the number of particles, it is still capable to stay in a stable operating speed as there is no need to compute weights for particles a second time. Extensive experimental results on parts of OTB datasets and comparison with other methods demonstrate that the proposed tracker performs favorably both in location of object and the decision of scale.
C1 [Zhu, Qidan; Wang, Yanke; He, Yunqian; Hong, Xiao] Harbin Engn Univ, Coll Automat, Inst Intelligent Control, Harbin, Heilongjiang, Peoples R China.
C3 Harbin Engineering University
RP Wang, YK (corresponding author), Harbin Engn Univ, Coll Automat, Inst Intelligent Control, Harbin, Heilongjiang, Peoples R China.
EM wangyanke@hrbeu.edu.cn
RI Zhu, Qidan/ABG-2126-2021
CR [Anonymous], 2012, P NEUR INF PROC SYST
   [Anonymous], 2017, arXiv
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Cuevas E., 2005, KALMAN FILTER VISION
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Derpanis K.G., 2004, HARRIS CORNER DETECT
   Ding JW, 2015, NEUROCOMPUTING, V161, P277, DOI 10.1016/j.neucom.2015.02.027
   Fang JW, 2014, IEEE T CIRC SYST VID, V24, P854, DOI 10.1109/TCSVT.2013.2283646
   Geng Y, 2016, ESANN 2017 P
   Geng YY, 2017, LECT NOTES COMPUT SC, V10614, P539, DOI 10.1007/978-3-319-68612-7_61
   Ghazi MM, 2016, IEEE COMPUT SOC CONF, P102, DOI 10.1109/CVPRW.2016.20
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Jenkins MD, 2018, IEEE T CYBERNETICS, V48, P264, DOI 10.1109/TCYB.2016.2631660
   Levi DM, 2008, VISION RES, V48, P635, DOI 10.1016/j.visres.2007.12.009
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Lienhart R, 2002, INT C IM PROC ICIP
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Pancham A, 2015, 14 IAPR INT C MACH V
   Porikli F., 2006, IEEE COMP SOC C COMP
   Ray S., 1999, PROC 4 INT C ADV PAT, P137, DOI DOI 10.1109/TKDE.2008.158
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Rout RK, 2015, SURVEY OBJECT DETECT, P1
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Tang F, 2007, IEEE 11 INT C COMP V
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Vedaldi A., 2007, OPEN IMPLEMENTATION
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yuan Y, 2017, IEEE T INTELL TRANSP, V18, P3339, DOI 10.1109/TITS.2017.2686871
   Zhang G, 2018, LECT NOTES ARTIFICIA
   Zhang GH, 2017, LECT NOTES COMPUT SC, V10585, P1, DOI 10.1007/978-3-319-68935-7_1
   Zhou ZP, 2017, MULTIMED TOOLS APPL, V76, P2979, DOI 10.1007/s11042-015-3211-3
   Zhu GK, 2013, NEUROCOMPUTING, V113, P227, DOI 10.1016/j.neucom.2013.01.020
   [No title captured]
NR 44
TC 2
Z9 2
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12083
EP 12101
DI 10.1007/s11042-018-6743-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900045
DA 2024-07-18
ER

PT J
AU Li, B
   Zhang, HX
   Luo, H
   Tan, SQ
AF Li, Bin
   Zhang, Haoxin
   Luo, Hu
   Tan, Shunquan
TI Detecting double JPEG compression and its related anti-forensic
   operations with CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Convolutional neural network; Double JPEG compression
ID TRACES; IMAGES
AB Detecting double JPEG compression is important to forensic experts in identifying the originality and authenticity of images. However, there are some anti-forensic techniques which can evade existing double compression detectors. It is desirable to design a unified approach to address the issues of JPEG forensics and counter-anti-forensics simultaneously, but existing hand-crafted feature based methods and deep learning based methods may fail to satisfy the requirement. In this paper, we present a data-driven approach by using a convolutional neural network (CNN) which takes input from both raw JPEG DCT coefficients and decompressed image pixels. Expert knowledge about JPEG characteristics is incorporated in the CNN design by exploring the intricate relations both within and among DCT subbands and by looking for spatial artifacts both within and among JPEG grids. The CNN is capable of learning deep representations from training data and thus can effectively detect double JPEG compression and its related anti-forensic operations together. The end-to-end CNN that takes into account the information from both DCT domain and spatial domain, shows outstanding performance when compared to prior arts in the experiments. It shows a promising way to address counter-anti-forensic issues without designing specific features for each anti-forensic operation.
C1 [Li, Bin; Zhang, Haoxin; Luo, Hu; Tan, Shunquan] Shenzhen Univ, Guangdong Key Lab Intelligent Informat Proc, Shenzhen, Peoples R China.
   [Li, Bin; Zhang, Haoxin; Luo, Hu; Tan, Shunquan] Shenzhen Univ, Shenzhen Key Lab Media Secur, Shenzhen, Peoples R China.
C3 Shenzhen University; Shenzhen University
RP Li, B (corresponding author), Shenzhen Univ, Guangdong Key Lab Intelligent Informat Proc, Shenzhen, Peoples R China.; Li, B (corresponding author), Shenzhen Univ, Shenzhen Key Lab Media Secur, Shenzhen, Peoples R China.
EM libin@szu.edu.cn; 2015130123@email.szu.edu.cn; luohu@email.szu.edu.cn;
   tansq@szu.edu.cn
FU NSFC [61872244, 61572329, 61772349, U1636202]; Shenzhen RD Program
   [JCYJ20160328144421330]
FX This work was supported in part by NSFC (Grant 61872244, 61572329,
   61772349, and U1636202) and in part by the Shenzhen R&D Program (Grant
   JCYJ20160328144421330).
CR Abadi Martin, 2016, TENSORFLOW LARGE SCA, V16, P265
   Amerini I, 2017, IEEE COMPUT SOC CONF, P1865, DOI 10.1109/CVPRW.2017.233
   Amerini I, 2014, IEEE INT WORKS INFOR, P143, DOI 10.1109/WIFS.2014.7084318
   [Anonymous], 2003, P DIG FOR RES WORKSH
   [Anonymous], 2011, P 4 INT C ART INT ST
   Anthony HT, 2015, HDB DIGITAL FORENSIC
   Barni M, 2017, J VIS COMMUN IMAGE R, V49, P153, DOI 10.1016/j.jvcir.2017.09.003
   Barni M, 2017, EUR SIGNAL PR CONF, P281, DOI 10.23919/EUSIPCO.2017.8081213
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   BOUREAU YL, 2010, PROC CVPR IEEE, P2559, DOI DOI 10.1109/CVPR.2010.5539963
   Chu XY, 2015, IEEE T IMAGE PROCESS, V24, P1087, DOI 10.1109/TIP.2015.2390137
   Clevert D., 2016, ARXIV151107289
   Fan W., 2013, P IH MMSEC 2013 2013, P117, DOI [10.1145/2482513.2482536, DOI 10.1145/2482513.2482536]
   Fan W, 2014, IEEE T INF FOREN SEC, V9, P1211, DOI 10.1109/TIFS.2014.2317949
   Fan W, 2013, INT CONF ACOUST SPEE, P3058, DOI 10.1109/ICASSP.2013.6638220
   FU D, 2005, PROC SPIE ELECTRONIC, V1, pL1
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kalman B. L., 1992, IJCNN International Joint Conference on Neural Networks (Cat. No.92CH3114-6), P578, DOI 10.1109/IJCNN.1992.227257
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li B., 2017, ARXIV
   Li B, 2018, IEEE T INF FOREN SEC, V13, P1242, DOI 10.1109/TIFS.2017.2780805
   Li HD, 2012, IEEE IMAGE PROC, P241, DOI 10.1109/ICIP.2012.6466840
   Pasquini C, 2017, IEEE T INF FOREN SEC, V12, P2890, DOI 10.1109/TIFS.2017.2725201
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P247, DOI 10.1109/TIFS.2008.922456
   Piva A., 2013, ISRN SIGNAL PROCESS, V2013, DOI [10.1155/2013/496701, DOI 10.1155/2013/496701]
   Popescu A.C., 2004, Statistical Tools for Digital Forensics
   ShiYue Lai, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P285, DOI 10.1007/978-3-642-24178-9_20
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh G, 2017, IMPROVED JPEG ANTIFO
   Stamm MC, 2011, IEEE T INF FOREN SEC, V6, P1050, DOI 10.1109/TIFS.2011.2119314
   Stamm MC, 2010, IEEE IMAGE PROC, P2109, DOI 10.1109/ICIP.2010.5652553
   Stamm MC, 2010, INT CONF ACOUST SPEE, P1694, DOI 10.1109/ICASSP.2010.5495491
   Taimori A, 2016, J MATH IMAGING VIS, V54, P269, DOI 10.1007/s10851-015-0602-z
   Valenzise G, 2014, IEEE IMAGE PROC, P5337, DOI 10.1109/ICIP.2014.7026080
   Valenzise G., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P1949, DOI 10.1109/ICIP.2011.6115854
   Valenzise G, 2011, INT CONF ACOUST SPEE, P1884
   Valenzise G, 2013, IEEE T INF FOREN SEC, V8, P335, DOI 10.1109/TIFS.2012.2234117
   Verma V, 2017, ARXIV171202313
   Wallace G. K., 1991, Communications of the ACM, V34, P30, DOI 10.1145/103085.103089
   Wang JY, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P433
   Wang Q, 2016, EURASIP J INF SECUR, DOI 10.1186/s13635-016-0047-y
   Yu JJ, 2017, LECT NOTES COMPUT SC, V10082, P3, DOI 10.1007/978-3-319-53465-7_1
NR 46
TC 16
Z9 17
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8577
EP 8601
DI 10.1007/s11042-018-7073-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800038
DA 2024-07-18
ER

PT J
AU Li, XL
   Li, W
AF Li, Xiaolong
   Li, Wei
TI A case study of a two-stage image segmentation algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mumford-Shah (MS) model; Image segmentation; Two-stage image
   segmentation
ID MUMFORD; IMPLEMENTATION; APPROXIMATION; MODEL
AB Mumford-Shah (MS) model has attracted considerable research interests in the past decades. It is a classical and important approach for image segmentation. In a recent work, as an extension to MS model, Cai et al. proposed a two-stage image segmentation method. In the first stage of this method, a convex variant of MS model is developed. Then, after finding the unique minimizer of this new model, in the second stage, image segmentation is conducted by automatically thresholding. Compared with MS model, the new model is convex and computationally efficient. In this paper, as a further study, the theoretical aspect of Cai et al.'s method is emphasized and some primary results are obtained.
C1 [Li, Xiaolong] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Li, Wei] Capital Normal Univ, Sch Math Sci, Beijing 100048, Peoples R China.
C3 Beijing Jiaotong University; Capital Normal University
RP Li, XL (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
EM lixl@bjtu.edu.cn; weili973@aliyun.com
RI li, xiao/GSN-6181-2022; Li, xiaolong/GRS-9148-2022; zhou,
   bolin/KHX-0072-2024; Wang, Peiyun/JVE-1196-2024
FU National Natural Science Foundation of China [61572052, U1736213];
   Fundamental Research Funds for the Central Universities [2017RC008]
FX This work was supported by the National Natural Science Foundation of
   China (Nos. 61572052 and U1736213) and the Fundamental Research Funds
   for the Central Universities (No. 2017RC008).
CR ADAMS R., 2003, SOBOLEV SPACES
   Bourdin B, 2000, NUMER MATH, V85, P609, DOI 10.1007/s002110000099
   Brown E.S., 2010, CONVEX RELAXATION ME
   Cai XH, 2013, SIAM J IMAGING SCI, V6, P368, DOI 10.1137/120867068
   CHAMBOLLE A, 1995, SIAM J APPL MATH, V55, P827, DOI 10.1137/S0036139993257132
   Chambolle A, 1999, RAIRO-MATH MODEL NUM, V33, P651
   Chan R, 2014, SIAM J IMAGING SCI, V7, P98, DOI 10.1137/130920241
   Chan T.F., 2000, IMAGE SEGMENTATION U
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P161, DOI 10.1109/VLSM.2001.938895
   Chan TF, 2000, CONF REC ASILOMAR C, P490, DOI 10.1109/ACSSC.2000.911004
   Dacorogna B., 2008, APPL MATH SCI, V78
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Huang YM, 2013, SIAM J SCI COMPUT, V35, pA2856, DOI 10.1137/120898693
   Jung MY, 2011, IEEE T IMAGE PROCESS, V20, P1583, DOI 10.1109/TIP.2010.2092433
   Lie J, 2006, IEEE T IMAGE PROCESS, V15, P1171, DOI 10.1109/TIP.2005.863956
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Pock T, 2009, IEEE I CONF COMP VIS, P1133, DOI 10.1109/ICCV.2009.5459348
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
NR 20
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8197
EP 8206
DI 10.1007/s11042-018-6778-7
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800018
DA 2024-07-18
ER

PT J
AU Liu, MY
   Po, LM
   Rehman, YAU
   Xu, XY
   Li, YM
   Feng, LT
AF Liu, Mengyang
   Po, Lai-Man
   Rehman, Yasar Abbas Ur
   Xu, Xuyuan
   Li, Yuming
   Feng, Litong
TI Video copy detection by conducting fast searching of inverted files
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video copy detection; Inverted file; Video indexing and searching; Video
   fingerprint
ID EFFICIENT; ROBUST; RETRIEVAL; ALGORITHM
AB Fast content-based video copy detection is challenging because video databases have become extremely large. Conventional video-fingerprint-based copy detection systems that use the inverted-file approach involve many similarity computations based on the Hamming distance. To overcome this problem, a novel fast searching strategy for inverted files is proposed in this paper. The strategy involves simple table look-up and word counting operations for the fingerprint matching process. The similarity of video fragments is based on the number of matched fingerprints among all video candidates. In this method, the offset time is used, and fingerprints are ordered to further select the matched fingerprints from the video candidates. Moreover, a novel regional average fingerprint that is compatible with the proposed fast searching strategy is proposed. An experimental video copy detection system was used with the proposed algorithms, and the proposed algorithms were compared with other state-of-the-art fingerprinting algorithms on TRECVID 2011 dataset for different types of video distortions. In addition, VCDB dataset was also used to demonstrate the accuracy and efficiency of the proposed fast searching strategy while using inverted files to demonstrate the practicality of the method for a large database. The proposed system achieved higher accuracy on VCDB dataset with considerably higher operation speed compared with conventional inverted-file-based searching methods.
C1 [Liu, Mengyang; Po, Lai-Man; Rehman, Yasar Abbas Ur] City Univ Hong Kong, Dept Elect Engn, Kowloon Tong, Hong Kong, Peoples R China.
   [Xu, Xuyuan] Tencent Holdings Ltd, Tencent Video, Shenzhen, Peoples R China.
   [Li, Yuming] MINIEYE, Shenzhen, Peoples R China.
   [Feng, Litong] SenseTime Grp Ltd, Beijing, Peoples R China.
C3 City University of Hong Kong; Tencent
RP Liu, MY (corresponding author), City Univ Hong Kong, Dept Elect Engn, Kowloon Tong, Hong Kong, Peoples R China.
EM mengyaliu7-c@my.cityu.edu.hk
RI wang, yi/HOF-6668-2023
OI rehman, yasar/0000-0002-2945-7181; Liu, Mengyang/0000-0003-3527-6907
FU City University of Hong Kong, Kowloon, Hong Kong [7004609]
FX The work described in this paper was substantially supported financially
   by the City University of Hong Kong, Kowloon, Hong Kong, under the Grant
   number: 7004609.
CR Abdel-Mottaleb M, 1999, PROC SPIE, V3845, P22, DOI 10.1117/12.371217
   [Anonymous], 2009, P ACM INT C MULT, DOI DOI 10.1145/1631272.1631295
   [Anonymous], 2016, J. Signal Inf. Process, DOI [10.4236/jsip.2016.72010, DOI 10.4236/JSIP.2016.72010]
   Ayari M, 2011, TRECVID
   Chen L, 2008, PATTERN RECOGN LETT, V29, P1824, DOI 10.1016/j.patrec.2008.05.015
   Cherubini Mauro., 2009, Proceedings of the 17th ACM International Conference on Multimedia, number April in MM '09, P35, DOI DOI 10.1145/1631272.1631280
   Coskun B, 2006, IEEE T MULTIMEDIA, V8, P1190, DOI 10.1109/TMM.2006.884614
   Devi S, 2012, INT J COMPUT APPL, V51, P29
   Douze M, 2010, IEEE T MULTIMEDIA, V12, P257, DOI 10.1109/TMM.2010.2046265
   Esmaeili Mani Malek, 2010, 2010 IEEE International Conference on Consumer Electronics (ICCE 2010), P179, DOI 10.1109/ICCE.2010.5418777
   Esmaeili MM, 2012, IEEE T PATTERN ANAL, V34, P2481, DOI 10.1109/TPAMI.2012.170
   Esmaeili MM, 2011, IEEE T INF FOREN SEC, V6, P213, DOI 10.1109/TIFS.2010.2097593
   Haitsma JA, 2009, US Patent, Patent No. [7,549,052, 7549052]
   Hao YB, 2017, IEEE T IMAGE PROCESS, V26, P5531, DOI 10.1109/TIP.2017.2737329
   Harvey RC, 2012, P 3 MULT SYST C, P35
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Guzman-Zavaleta ZJ, 2017, MULTIMED TOOLS APPL, V76, P24143, DOI 10.1007/s11042-016-4168-6
   Jiang YG, 2014, LECT NOTES COMPUT SC, V8692, P357, DOI 10.1007/978-3-319-10593-2_24
   Joly A, 2007, IEEE T MULTIMEDIA, V9, P293, DOI 10.1109/TMM.2006.886278
   Jun W, 2016, MULTIMED TOOLS APPL, V75, P15665, DOI 10.1007/s11042-015-2724-0
   Kim C, 2005, IEEE T CIRC SYST VID, V15, P127
   Kordopatis-Zilos G, 2017, LECT NOTES COMPUT SC, V10132, P251, DOI 10.1007/978-3-319-51811-4_21
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liao KY, 2015, J INTELL INF SYST, V44, P133, DOI 10.1007/s10844-014-0332-5
   Liu JJ, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2501654.2501658
   Liu XC, 2013, IEEE INT WORKS INFOR, P109, DOI 10.1109/WIFS.2013.6707803
   Liu XY, 2017, SIGNAL PROCESS-IMAGE, V54, P140, DOI 10.1016/j.image.2017.03.002
   Lu J, 2009, MEDIA FORENSICS SECU, V7254
   Barrios JM, 2013, MULTIMED TOOLS APPL, V62, P75, DOI 10.1007/s11042-011-0915-x
   Mao JF, 2016, NEUROCOMPUTING, V173, P2022, DOI 10.1016/j.neucom.2015.09.001
   Oostveen J., 2002, Recent Advances in Visual Information Systems. 5th International Conference VISUAL 2002. Proceedings (Lecture Notes in Computer Science Vol.2314), P117
   Özkan S, 2014, INT C PATT RECOG, P3945, DOI 10.1109/ICPR.2014.676
   Poullot S., 2008, Proceedings of the ACM International Conference on Multimedia, P61
   Radhakrishnan R, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P341, DOI 10.1109/MMSP.2007.4412886
   Richang Hong, 2015, IEEE Transactions on Big Data, V1, P152, DOI 10.1109/TBDATA.2016.2515640
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sarkar A, 2010, IEEE T CIRC SYST VID, V20, P870, DOI 10.1109/TCSVT.2010.2046056
   Shen H.T., 2007, VLDB, P1374
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Wang L, 2017, LECT NOTES COMPUT SC, V10132, P576, DOI 10.1007/978-3-319-51811-4_47
   Wu A. G., 2007, P ACM MM, P218
   Yang B, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P167
   Yu-Gang Jiang, 2016, IEEE Transactions on Big Data, V2, P32, DOI 10.1109/TBDATA.2016.2530714
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 46
TC 4
Z9 4
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10601
EP 10624
DI 10.1007/s11042-018-6639-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400048
DA 2024-07-18
ER

PT J
AU Sen, D
   Datta, S
   Balasubramanian, R
AF Sen, Debashis
   Datta, Samyak
   Balasubramanian, R.
TI Facial emotion classification using concatenated geometric and textural
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial emotion classification; Geometric features; Textural features;
   Local binary patterns; DAGSVM
ID EXPRESSION RECOGNITION; SEQUENCES
AB Geometric and textural features have been separately used in the literature for facial emotion classification. In this paper, we theoretically and empirically study the capture of facial expressions through geometric and texture-based features, and demonstrate that a simple concatenation of these features can lead to significant improvement in facial emotion classification. We also propose the use of the Directed Acyclic Graph SVM (DAGSVM) for facial emotion classification using the concatenated feature, by analyzing DAGSVM structures. We perform experiments using the well-known extended Cohn-Kanade (CK+), the MUG facial expression (MUG) and the Japanese Female Facial Expression (JAFFE) databases to evaluate the integration of geometric and textural features, and the use of DAGSVM for facial emotion classification. The said integration is found to be effective and DAGSVM is found to be computationally efficient in facial emotion classification.
C1 [Sen, Debashis] Indian Inst Technol, Dept Elect & Elect Commun Engn, Kharagpur, W Bengal, India.
   [Datta, Samyak; Balasubramanian, R.] Indian Inst Technol, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Roorkee
RP Sen, D (corresponding author), Indian Inst Technol, Dept Elect & Elect Commun Engn, Kharagpur, W Bengal, India.
EM dsen@ece.iitkgp.ernet.in
RI Sen, Debashis/R-3236-2016
OI Sen, Debashis/0000-0002-9756-1191
CR Agarwal S, 2017, MULTIMED TOOLS APPL, V76, P1073, DOI 10.1007/s11042-015-3103-6
   Aifanti N., 2010, P 11 INT WORKSH IM A, DOI DOI 10.1371/JOURNAL.PONE.0009715
   [Anonymous], 2003, P 2003 C COMP VIS PA, DOI DOI 10.1109/CVPRW.2003.10057
   [Anonymous], 2013, INTRO BYZANTINE AEST
   Bashyal S, 2008, ENG APPL ARTIF INTEL, V21, P1056, DOI 10.1016/j.engappai.2007.11.010
   Bazrafkan Shabab, 2017, 2017 IEEE International Conference on Consumer Electronics (ICCE), P217, DOI 10.1109/ICCE.2017.7889290
   Bickel S, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P19, DOI 10.1109/ICDM.2004.10095
   Bihan Jiang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P314, DOI 10.1109/FG.2011.5771416
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Buciu I, 2004, INT C PATT RECOG, P288, DOI 10.1109/ICPR.2004.1334109
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Chaudhuri K., 2009, P 26 ANN INT C MACH, P129
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cruz A, 2011, LECT NOTES COMPUT SC, V6975, P341, DOI 10.1007/978-3-642-24571-8_45
   Dahmane M, 2011, LECT NOTES COMPUT SC, V6975, P351, DOI 10.1007/978-3-642-24571-8_46
   Datta S., 2016, PROC CVIP, P619
   Dhall A, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P509, DOI 10.1145/2522848.2531739
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   Douglas-Cowie E., P LREC WORKSH CORP R, P1
   Farquhar JDR, 2005, ADV NEURAL INFORM PR, V18, P355, DOI DOI 10.5555/2976248.2976293
   Glodek M, 2011, LECT NOTES COMPUT SC, V6975, P359, DOI 10.1007/978-3-642-24571-8_47
   Grites T., 2008, Academic advising: a comprehensive handbook, P1, DOI [10.1109/AFGR.2008.4813379, DOI 10.1109/AFGR.2008.4813379]
   Gu WF, 2012, PATTERN RECOGN, V45, P80, DOI 10.1016/j.patcog.2011.05.006
   Hongying Meng, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P854, DOI 10.1109/FG.2011.5771362
   Jeni L.A., 2013, Proc. 10th IEEE Int. Conf. Workshops Autom. Face Gesture Recognit, P1
   Jiang BH, 2014, IEEE T CYBERNETICS, V44, P161, DOI 10.1109/TCYB.2013.2249063
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Knill O., 2009, Probability and Stochastic Processes with Aplications
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   KREBEL U, 1999, ADVANCES IN KERNEL M, V255, P268
   Kumar P., 2011, Adv. Neural Inf. Process. Syst., P1413, DOI DOI 10.5555/2986459.2986617
   Liu WF, 2018, INFORM FUSION, V41, P119, DOI 10.1016/j.inffus.2017.09.001
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Long F, 2012, NEUROCOMPUTING, V93, P126, DOI 10.1016/j.neucom.2012.04.017
   Lucey P., 2010, ieee computer society conference on computer vision and pattern recognition-workshops, P94
   LUCEY S, 2007, FACE RECOGNITION BOO, P395
   Luo Y, 2015, IEEE T IMAGE PROCESS, V24, P2355, DOI 10.1109/TIP.2015.2421309
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Mariooryad S, 2016, IEEE T AFFECT COMPUT, V7, P346, DOI 10.1109/TAFFC.2015.2490070
   McKeown G, 2010, IEEE INT CON MULTI, P1079, DOI 10.1109/ICME.2010.5583006
   Mehrotra S, 2010, IEEE INT CON MULTI, P1, DOI 10.1109/ICME.2010.5582531
   Milborrow S, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P380
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Nicolle J, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P501
   Niese R, 2012, IET COMPUT VIS, V6, P79, DOI 10.1049/iet-cvi.2011.0064
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Pantic M, 2005, IEEE SYS MAN CYBERN, P3358
   Pantic M, 2004, IEEE T SYST MAN CY B, V34, P1449, DOI 10.1109/TSMCB.2004.825931
   Peng Liu, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163094
   Platt JC, 2000, ADV NEUR IN, V12, P547
   Quadrianto Novi., 2011, ICML, P425
   Rudovic O, 2012, PROC CVPR IEEE, P2634, DOI 10.1109/CVPR.2012.6247983
   Saeed A., 2014, ADV HUM-COMPUT INTER, V2014, P2014
   Saeed A, 2012, INT CONF SIGN PROCES, P623, DOI 10.1109/ICoSP.2012.6491565
   Sariyanidi E, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.108
   Savran A, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P485
   Senechal T, 2011, LECT NOTES COMPUT SC, V6915, P495, DOI 10.1007/978-3-642-23687-7_45
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shiqing Zhang, 2012, WSEAS Transactions on Signal Processing, V8, P21
   Shojaeilangari S, 2015, IEEE T IMAGE PROCESS, V24, P2140, DOI 10.1109/TIP.2015.2416634
   Sikka K, 2012, LECT NOTES COMPUT SC, V7584, P250, DOI 10.1007/978-3-642-33868-7_25
   Sindhwani V., 2005, P WORKSHOP LEARNING
   Songfan Yang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P866, DOI 10.1109/FG.2011.5771364
   Tao H, 1998, PROC CVPR IEEE, P735, DOI 10.1109/CVPR.1998.698685
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P28, DOI 10.1109/TSMCB.2011.2163710
   van der Schalk J, 2011, EMOTION, V11, P907, DOI 10.1037/a0023853
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wu Tingfan., 2010, IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P42
   Yang P, 2008, LECT NOTES COMPUT SC, V5302, P685, DOI 10.1007/978-3-540-88682-2_52
   Yang P, 2011, COMPUT VIS IMAGE UND, V115, P456, DOI 10.1016/j.cviu.2010.11.015
   Yang SF, 2015, IEEE I CONF COMP VIS, P1215, DOI 10.1109/ICCV.2015.144
   Yang XH, 2017, INFORM SCIENCES, V385, P338, DOI 10.1016/j.ins.2017.01.011
   Zen G, 2016, IEEE T MULTIMEDIA, V18, P775, DOI 10.1109/TMM.2016.2523421
   Zhang JL, 2016, NEUROCOMPUTING, V208, P333, DOI 10.1016/j.neucom.2016.01.099
   Zhang T, 2016, IEEE T MULTIMEDIA, V18, P2528, DOI 10.1109/TMM.2016.2598092
   Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2009, PATTERN RECOGN LETT, V30, P1117, DOI 10.1016/j.patrec.2009.03.018
   Zhu YF, 2011, IEEE T AFFECT COMPUT, V2, P79, DOI 10.1109/T-AFFC.2011.10
NR 87
TC 18
Z9 18
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10287
EP 10323
DI 10.1007/s11042-018-6537-9
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400036
DA 2024-07-18
ER

PT J
AU Wang, DY
   Xiao, Y
   Gao, Y
AF Wang Deyan
   Xiao Yin
   Gao Ya
TI Image Denoising method based on NSCT bivariate model and Variational
   Bayes threshold estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Nonsubsampled Contourlet transform; Bivariate model;
   Variation Bayes; Threshold estimation
ID CONTOURLET TRANSFORM
AB In order to reduce the Gaussian noise introduced during image generation, this paper presents an image denoising algorithm based on variational Bayes (V-Bayes) estimation and nonsubsampled contourlet transform (NSCT) bivariate model. First, the proposed algorithm uses the NSCT's advantages of translation-invariant and multidirection-selectivity, exploits the intra-scale and inter-scale correlations of NSCT coefficients. Then, the corresponding nonlinear bivariate threshold function of the model is deduced by using V-Bayes estimation theory. Finally, the noise-reduced coefficients are inverse-transformed by NSCT to obtain denoised image. The simulation results show that the denoised image has obvious improvement in subjective visual effects and performance indicators, and effectively preserves the details and texture information in the original image.
C1 [Wang Deyan] Management Sci Univ, Shah Alam, Malaysia.
   [Wang Deyan; Xiao Yin; Gao Ya] Wuxi Insititute Technol, Sch Internet Things Technol, Wuxi, Jiangsu, Peoples R China.
C3 Management Science University
RP Wang, DY (corresponding author), Management Sci Univ, Shah Alam, Malaysia.; Wang, DY (corresponding author), Wuxi Insititute Technol, Sch Internet Things Technol, Wuxi, Jiangsu, Peoples R China.
EM wangdy@wxit.edu.cn
RI wang, Xiaoming/KBB-8854-2024
FU National Natural Science Foundation of China [61502204]
FX My paper is supported by the Project supported by the National Natural
   Science Foundation of China (61502204).
CR Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Devanna H., 2011, RES J APPL SCI ENG T, V3, P589
   Dong M, 2015, SIGNAL PROCESS, V109, P25, DOI 10.1016/j.sigpro.2014.10.017
   Eslami R, 2003, CONF REC ASILOMAR C, P1982
   Fraysse A, 2014, SIAM J IMAGING SCI, V7, P2591, DOI 10.1137/140966575
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Hashemi SM, 2011, 2011 IEEE STATISTICAL SIGNAL PROCESSING WORKSHOP (SSP), P713, DOI 10.1109/SSP.2011.5967802
   Jia J, 2009, J ELECT INFORM TECHN, V31, P349
   LI DM, 2016, ELECTRON OPTICS, V127, P5029, DOI DOI 10.1016/j.ijleo.2016.02.042
   Li X, 2008, IEEE IMAGE PROC, P1748, DOI 10.1109/ICIP.2008.4712113
   Lin XH, 2008, J IMAGE GRAPH, V13, P1841
   Luisier F, 2011, IEEE T IMAGE PROCESS, V20, P696, DOI 10.1109/TIP.2010.2073477
   Mohideen SK, 2010, DIGIT IMAGE PROCESS, V21, P121
   Naimi H, 2015, J KING SAUD UNIV-COM, V27, P40, DOI 10.1016/j.jksuci.2014.03.015
   Ou Y, 2013, 3 INT C INT SYST DES, V2013, P832
   Rasti B, 2014, IEEE J-STARS, V7, P2458, DOI 10.1109/JSTARS.2013.2272879
   Sadreazami H, 2014, ELECT COMPUT ENG IEE, P1
   Sendur L, 2002, IEEE T SIGNAL PROCES, V50, P2744, DOI 10.1109/TSP.2002.804091
   Shandoosti HR, 2017, DIGIT SIGNAL PROCESS, V67, P17, DOI 10.1016/j.dsp.2017.04.011
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Wang XY, 2013, INFORM SCIENCES, V246, P155, DOI 10.1016/j.ins.2013.05.028
   Zhang S, 2008, ELECT COMPUT ENG IEE, P1323
NR 23
TC 6
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8927
EP 8941
DI 10.1007/s11042-018-6685-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800057
DA 2024-07-18
ER

PT J
AU Lin, CY
   Huang, YW
   Shih, TK
AF Lin, Chih-Yang
   Huang, Yun-Wen
   Shih, Timothy K.
TI Creating waterfall animation on a single image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video synthesis; Image rendering; Waterfall animation
ID VIDEO SYNTHESIS
AB A static image always becomes more eye-catching with an animation. In this paper, we present a system for adding a waterfall animation to a single image by extracting a flow animation from a video sequence. To the best of our knowledge, this is the first attempt by researchers to create a waterfall animation on a still waterfall image. Such work poses challenges in many areas, including color consistency, texture consistency, flow velocity, block matching, and block effects. The proposed method integrates optical flow, line integral convolution, color transfer, graph-cut, and multi-resolution splining techniques to mimic a real waterfall on a single image. It uses a segmentation process to separate the necessary foreground and the unnecessary background. Then, flow analysis is performed on the target image and source video. Finally, flow similarity and a synthesis process are applied to form the animation. Experiments generated 8 animation results that prove the feasibility of the proposed method. The limitations and potential impact of this research are also discussed in our experimental results.
C1 [Lin, Chih-Yang] Yuan Ze Univ, Dept Elect Engn, Taoyuan, Taiwan.
   [Huang, Yun-Wen; Shih, Timothy K.] Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan, Taiwan.
C3 Yuan Ze University; National Central University
RP Shih, TK (corresponding author), Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan, Taiwan.
EM timothykshih@gmail.com
RI Huang, Yun-Wen/N-6867-2019; Lin, Chih-Yang/HOF-2583-2023
OI Huang, Yun-Wen/0000-0002-5216-2226; Lin, Chih-Yang/0000-0002-0401-8473
CR Bai JM, 2013, COMPUT GRAPH FORUM, V32, P17, DOI 10.1111/cgf.12147
   Barrett WA, 2002, ACM T GRAPHIC, V21, P777, DOI 10.1145/566570.566651
   Bhat KS, 2004, ACM T GRAPHIC, V23, P360, DOI 10.1145/1015706.1015729
   BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247
   Cabral B., 1993, P 20 ANN C COMP GRAP, P263, DOI DOI 10.1145/166117.166151
   Chuang YY, 2005, ACM T GRAPHIC, V24, P853, DOI 10.1145/1073204.1073273
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Gonzalex RC, 2006, DIGITAL IMAGE PROCES
   Hornung A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1186644.1186645
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   Kaiming He, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2049, DOI 10.1109/CVPR.2011.5995495
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   Litwinowicz P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P409, DOI 10.1145/192161.192270
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   McNamara A, 2004, ACM T GRAPHIC, V23, P449, DOI 10.1145/1015706.1015744
   Porter T., 1984, Computers & Graphics, V18, P253
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Tompkin J., 2011, 2011 Conference for Visual Media Production, P87, DOI 10.1109/CVMP.2011.16
   Treuille A, 2003, ACM T GRAPHIC, V22, P716, DOI 10.1145/882262.882337
   Wang YZ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P213, DOI 10.1109/ICCV.2003.1238343
   Xie L, 2016, MULTIMED TOOLS APPL, V75, P9185, DOI 10.1007/s11042-016-3432-0
   Zhu L, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P843, DOI 10.1145/2733373.2806345
   Zhu L, 2014, J SUPERCOMPUT, V68, P820, DOI 10.1007/s11227-013-1068-7
NR 28
TC 3
Z9 5
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6637
EP 6653
DI 10.1007/s11042-018-6332-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700010
DA 2024-07-18
ER

PT J
AU Liu, H
   Wang, BL
   Yan, FS
   Song, J
AF Liu, Hui
   Wang, Beilei
   Yan, Fusheng
   Song, Jie
TI An optimized phase-shifting algorithm for depth image acquisition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth acquiring; Phase shifting algorithm; Structured light;
   Optimization
AB As developing science and technology, traditional two-dimensional computer vision cannot meet the people's needs for the three-dimensional recognition, and the depth information of objects are required by more and more applications. Recently, structured light has become one of the core techniques of depth acquisition. The main idea of the approach is first projecting pre-designed pattern onto objects, then capturing an image and processing further. In a structured light system, the phase-shifting algorithm, which is a depth acquiring algorithm for sinusoidal pattern, is discussed in this paper, and is argued that its performance weakness for applying in the real time environments. Then we propose the performance optimization on its phase wrapping step and phase unwrapping step, respectively. Finally, we compare acquiring results and advantages as well as disadvantages of them by experiments results. Experiments show that the optimized phase-shifting algorithm is 4.6x faster than the original one with the ignorable errors.
C1 [Liu, Hui; Yan, Fusheng] Northeastern Univ, Sch Met, Shenyang 110819, Liaoning, Peoples R China.
   [Wang, Beilei; Song, Jie] Northeastern Univ, Software Coll, Shenyang 110819, Liaoning, Peoples R China.
C3 Northeastern University - China; Northeastern University - China
RP Song, J (corresponding author), Northeastern Univ, Software Coll, Shenyang 110819, Liaoning, Peoples R China.
EM china.songjie@yahoo.com
RI Song, Jie/JXK-0735-2024; Song, Jie/GLR-2301-2022
FU National Natural Science Foundation of China [61662057, 61672143,
   U1435216]; Fundamental Research Funds for the Central Universities
   [N162504007, N161602003, N151704004]; Doctor Research Starting
   Foundation of Liaoning [20141011]
FX This research is supported by the National Natural Science Foundation of
   China (61662057, 61672143, U1435216), the Fundamental Research Funds for
   the Central Universities (N162504007, N161602003, N151704004), the
   Doctor Research Starting Foundation of Liaoning (20141011).
CR [Anonymous], CVPR 2011 WORKSHOPS, DOI DOI 10.1109/CVPRW.2011.5981811
   Bhandari A, 2016, IEEE SIGNAL PROC MAG, V33, P45, DOI 10.1109/MSP.2016.2582218
   Charles J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1202, DOI 10.1109/ICCVW.2011.6130387
   Cong PY, 2015, IEEE J-STSP, V9, P396, DOI 10.1109/JSTSP.2014.2378217
   Huang PS, 2006, APPL OPTICS, V45, P5086, DOI 10.1364/AO.45.005086
   Huang PS, 2004, P SOC PHOTO-OPT INS, V5606, P143
   Koninckx TP, 2005, PROC CVPR IEEE, P611
   Susanto W, 2012, LECT NOTES COMPUT SC, V7584, P93, DOI 10.1007/978-3-642-33868-7_10
   Yang LL, 2017, J VIS COMMUN IMAGE R, V46, P139, DOI 10.1016/j.jvcir.2017.03.018
   Yang Z, 2013, PROC CVPR IEEE, P25, DOI 10.1109/CVPR.2013.11
   Zhang Song, 2010, ADV MEASUREMENT SYST
   Zhang YD, 2014, PROG ELECTROMAGN RES, V145, P273, DOI 10.2528/PIER14021005
   Zhang YY, 2014, IEEE T IMAGE PROCESS, V23, P97, DOI 10.1109/TIP.2013.2286901
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 14
TC 0
Z9 0
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5367
EP 5380
DI 10.1007/s11042-018-6007-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100017
DA 2024-07-18
ER

PT J
AU Liu, YX
   Liu, SY
   Zhao, HG
   Liu, S
AF Liu, Yunxia
   Liu, Shuyang
   Zhao, Hongguo
   Liu, Si
TI A new data hiding method for H.265/HEVC video streams without
   intra-frame distortion drift
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; H.265/HEVC; Intra-frame distortion drift; Multi-coefficient
ID H.264/AVC; SCHEME
AB This paper presents a readable H.265/HEVC data hiding method. First, three conditions of the directions of intra-frame prediction and the multi-coefficients are given to avert intra-frame distortion drift. Then, the message is embedded into the multi-coefficients of the 4x4 luminance DST blocks of the selected frames which meet the specific conditions. The experimental results show that this data hiding algorithm can effectively avert intra-frame distortion drift and get good visual quality.
C1 [Liu, Yunxia; Zhao, Hongguo; Liu, Si] Zhengzhou Normal Univ, Coll Informat Sci & Technol, Zhengzhou, Henan, Peoples R China.
   [Liu, Shuyang] Lanzhou Univ, Sch Math & Stat, Lanzhou, Gansu, Peoples R China.
C3 Zhengzhou Normal University; Lanzhou University
RP Liu, YX (corresponding author), Zhengzhou Normal Univ, Coll Informat Sci & Technol, Zhengzhou, Henan, Peoples R China.
EM liuyunxia0110@hust.edu.cn
FU National Natural Science Foundation of China (NSFC) [61572447]
FX This paper is sponsored by the National Natural Science Foundation of
   China (NSFC, Grant 61572447).
CR [Anonymous], 2012, J SOFTW
   KIM D, 2010, VISION, V28, P1220, DOI DOI 10.1016/j.imavis.2009.12.006
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Lin T-J, IMPROVED DCT BASED P
   Liu YX, 2015, NEUROCOMPUTING, V151, P1076, DOI 10.1016/j.neucom.2014.03.089
   Liu YX, 2015, NEUROCOMPUTING, V151, P1053, DOI 10.1016/j.neucom.2014.03.088
   Liu YX, 2014, LECT NOTES COMPUT SC, V8588, P553, DOI 10.1007/978-3-319-09333-8_61
   Liu YX, 2013, J SYST SOFTWARE, V86, P2174, DOI 10.1016/j.jss.2013.03.101
   Liu YX, 2014, NEUROCOMPREDICTION U
   Liu YX, 2013, ROBUST INTRAFRAME DI
   Ma XJ, 2010, IEEE T CIRC SYST VID, V20, P1320, DOI 10.1109/TCSVT.2010.2070950
   Ma XJ, 2009, DATA HIDING H 264 AV
   Noorkami M, 2007, IEEE T INF FOREN SEC, V2, P14, DOI 10.1109/TIFS.2006.890306
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Shanableh T, 2012, IEEE T INF FOREN SEC, V7, P455, DOI 10.1109/TIFS.2011.2177087
   Sullivan G.J., 2012, IEEE Trans. Circuits and Systems for Video Technology
   Swati S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0105613
   Tew Y, 2014, IEEE IMAGE PROC, P5502, DOI 10.1109/ICIP.2014.7026113
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yao Guo, 2010, 2010 IEEE International Conference on Information Theory and Information Security, P419, DOI 10.1109/ICITIS.2010.5689580
NR 20
TC 43
Z9 44
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6459
EP 6486
DI 10.1007/s11042-018-6320-y
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700003
DA 2024-07-18
ER

PT J
AU Alsmirat, MA
   Al-Alem, F
   Al-Ayyoub, M
   Jararweh, Y
   Gupta, B
AF Alsmirat, Mohammad A.
   Al-Alem, Fatimah
   Al-Ayyoub, Mahmoud
   Jararweh, Yaser
   Gupta, Brij
TI Impact of digital fingerprint image quality on the fingerprint
   recognition accuracy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fingerprint recognition; Digital cameras; Raw images; JPEG compression
ID IRIS RECOGNITION
AB Despite the large body of work on fingerprint identification systems, most of it focused on using specialized devices. Due to the high price of such devices, some researchers directed their attention to digital cameras as an alternative source for fingerprints images. However, such sources introduce new challenges related to image quality. Specifically, most digital cameras compress captured images before storing them leading to potential losses of information. This study comes to address the need to determine the optimum ratio of the fingerprint image compression to ensure the fingerprint identification system's high accuracy. This study is conducted using a large in-house dataset of raw images. Therefore, all fingerprint information is stored in order to determine the compression ratio accurately. The results proved that the used software functioned perfectly until a compression ratio of (30-40%) of the raw images; any higher ratio would negatively affect the accuracy of the used system.
C1 [Alsmirat, Mohammad A.; Al-Alem, Fatimah; Al-Ayyoub, Mahmoud; Jararweh, Yaser] Jordan Univ Sci & Technol, Comp Sci Dept, Irbid 22110, Jordan.
   [Gupta, Brij] Natl Inst Technol Kurukshetra, Kurukshetra, Haryana, India.
C3 Jordan University of Science & Technology; National Institute of
   Technology (NIT System); National Institute of Technology Kurukshetra
RP Alsmirat, MA (corresponding author), Jordan Univ Sci & Technol, Comp Sci Dept, Irbid 22110, Jordan.
EM masmirat@just.edu.jo; maalshbool@just.edu.jo; yijararweh@just.edu.jo
RI Jararweh, Yaser/JCO-2836-2023; Gupta, Brij B/E-9813-2011; Jararweh,
   Yaser/ABE-6543-2021
OI Gupta, Brij B/0000-0003-4929-4698; Alsmirat,
   Mohammad/0000-0002-1071-7713
FU Jordan University of Science and Technology Deanship of Research project
   [20150348]
FX This work is supported by the Jordan University of Science and
   Technology Deanship of Research project number 20150348.
CR [Anonymous], 2006, PROC 6 ICRASC
   [Anonymous], 2006, FVC2006 4 INT FINGER
   [Anonymous], 2015, NIST BIOMETRIC IMAGE
   [Anonymous], P 2 INT WORKSH SEC C
   [Anonymous], 2010, CASIA FINGERPRINTV5
   Behera B, 2014, LECT NOTES COMPUT SC, V8563, P51, DOI 10.1007/978-3-319-08849-5_6
   Bhargava N., 2013, INT J COMPUTER TREND, V4, P515
   Cappelli R., 2007, Biom. Technol. Today, V15, P7, DOI DOI 10.1016/S0969-4765(07)70140-6
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Daugman J, 2008, IEEE T INF FOREN SEC, V3, P52, DOI 10.1109/TIFS.2007.916009
   Funk W, 2005, Proceedings from the Sixth Annual IEEE Systems, Man and Cybernetics Information Assurance Workshop, P72, DOI 10.1109/IAW.2005.1495936
   Hassanat ABA, 2015, 2015 6TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION SYSTEMS (ICICS), P188, DOI 10.1109/IACS.2015.7103225
   Hiew BY, 2006, I C CONT AUTOMAT ROB, P600
   Hiew BY, 2010, J VIS COMMUN IMAGE R, V21, P219, DOI 10.1016/j.jvcir.2009.12.003
   Hu CF, 2010, IEEE IMAGE PROC, P3097, DOI 10.1109/ICIP.2010.5654276
   Irtaza A, 2015, SIGNAL IMAGE VIDEO P, V9, P1503, DOI 10.1007/s11760-013-0601-8
   Islam Md Rajibul, 2010, Journal of Applied Sciences, V10, P1397, DOI 10.3923/jas.2010.1397.1404
   Ives RW, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2891313
   Johnson P, 2013, IEEE COMPUT SOC CONF, P154, DOI 10.1109/CVPRW.2013.30
   Khalil MS, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0029-1
   Kurniawan F, 2013, 2013 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES (ISBAST), P241, DOI 10.1109/ISBAST.2013.42
   Lee H.C., 2001, Advances in Fingerprint Technology
   Li GQ, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2013), P342, DOI 10.1109/IIH-MSP.2013.92
   Liu EY, 2011, FRONT COMPUT SCI CHI, V5, P148, DOI 10.1007/s11704-011-9134-x
   Ma L, 2004, IEEE T IMAGE PROCESS, V13, P739, DOI 10.1109/TIP.2004.827237
   Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144
   Maio D., 2004, FVC2004 3 FINGERPRIN, P1
   Maio D., 2000, FVC2000 FINGERPRINT
   Mascher-Kampfer A, 2007, PROC SPIE, V6508, DOI 10.1117/12.699199
   Modi SK, 2007, 2007 IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P19, DOI 10.1109/AUTOID.2007.380586
   Mohammedsayeemuddin S, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON ISSUES AND CHALLENGES IN INTELLIGENT COMPUTING TECHNIQUES (ICICT), P756, DOI 10.1109/ICICICT.2014.6781375
   Mueller Robert, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P1096, DOI 10.1109/IIH-MSP.2009.50
   Piuri V., 2008, Biometrics: Theory, Applications and Systems, P1
   Sankaran A., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P377, DOI 10.1109/BTAS.2012.6374604
   Sankaran A., 2011, Biometrics (IJCB), 2011 International Joint Conference On, P1, DOI [10.1109/IJCB.2011.6117525, DOI 10.1109/IJCB.2011.6117525]
   Sankaran A, 2015, IEEE ACCESS, V3, P653, DOI 10.1109/ACCESS.2015.2428631
   Silvestre-Blanes J, 2015, 2015 23RD TELECOMMUNICATIONS FORUM TELFOR (TELFOR), P744, DOI 10.1109/TELFOR.2015.7377573
   STONEY DA, 1988, AM J PHYS ANTHROPOL, V77, P367, DOI 10.1002/ajpa.1330770309
   Uysal M, 2014, ELEKTRON ELEKTROTECH, V20, P65, DOI 10.5755/j01.eee.20.7.8026
   Webb L, 2014, 2014 SECOND INTERNATIONAL SYMPOSIUM ON COMPUTING AND NETWORKING (CANDAR), P549, DOI 10.1109/CANDAR.2014.80
   Wu JS, 2014, IEEE COMMUN MAG, V52, P14, DOI 10.1109/MCOM.2014.6829939
   Xi-Feng Tong, 2011, Proceedings of the 2011 International Conference on Machine Learning and Cybernetics (ICMLC 2011), P1780, DOI 10.1109/ICMLC.2011.6016981
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 58
TC 137
Z9 137
U1 0
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3649
EP 3688
DI 10.1007/s11042-017-5537-5
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600055
DA 2024-07-18
ER

PT J
AU Kim, Y
   Jung, S
   Ji, S
   Hwang, E
   Rho, S
AF Kim, Yongsung
   Jung, Seungwon
   Ji, Seonmi
   Hwang, Eenjun
   Rho, Seungmin
TI IoT-based personalized NIE content recommendation system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; News in education; Multimedia in education; Semantic
   web; Deep learning; Data integration
ID INTERNET; THINGS; WEB
AB Recently, the Internet of Things (IoT) has become a popular topic and a dominant trend in various fields, such as healthcare, agriculture, manufacturing, and transportation. In particular, in the field of education, it has become a popular tool to improve learners' interests and achievements by making them interact with various devices in and out of the classroom. Lessons in newspaper in education (NIE), which uses newspapers as an educational resource, have started to utilize it. For instance, by analyzing the data generated from a learner's device, such as Raspberry Pi, appropriate news and related multimedia data can be provided to the learners as learning materials to support the lesson. However, as news and multimedia data are scattered in a wide variety of forms, it is very difficult to select appropriate ones for the learner. In this paper, we propose a news and related multimedia recommendation scheme based on IoT for supporting NIE lessons. Specifically, news and related multimedia data are collected from the Web, and they are integrated and stored into the server. After that, the learner can easily browse such contents using a mobile device through personalized visualization, which increase the efficiency of NIE lessons. To show the effectiveness of our scheme, we implemented a prototype system and performed various experiments. We present some of the results.
C1 [Kim, Yongsung; Jung, Seungwon; Ji, Seonmi; Hwang, Eenjun] Korea Univ, Sch Elect Engn, Seoul, South Korea.
   [Rho, Seungmin] Sungkyul Univ, Dept Media Software, Anyang, South Korea.
C3 Korea University; Sungkyul University
RP Hwang, E (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM kys1001@korea.ac.kr; jsw161@korea.ac.kr; lovelyminari@korea.ac.kr;
   ehwang04@korea.ac.kr; smrho@sungkyul.edu
RI Rho, Seungmin/HTP-6683-2023
FU Institute for Information & communications Technology Promotion (IITP) -
   Korea government (MSIT) [R0190-16-2012]; Basic Science Research Program
   through the National Research Foundation of Korea(NRF) - Ministry of
   Education [NRF-2016R1D1A1A09919590]
FX This work was partly supported by Institute for Information &
   communications Technology Promotion (IITP) grant funded by the Korea
   government (MSIT) (No. R0190-16-2012, High Performance Big Data
   Analytics Platform Performance Acceleration Technologies Development)
   and Basic Science Research Program through the National Research
   Foundation of Korea(NRF) funded by the Ministry of
   Education(NRF-2016R1D1A1A09919590).
CR [Anonymous], ARXIV140858823
   [Anonymous], 2013, FOUND TRENDS SIGNAL, DOI DOI 10.1561/2000000039
   [Anonymous], 2012, P 27 ACM S APPL COMP, DOI DOI 10.1145/2245276.2245347
   [Anonymous], 2015, P 2015 C EMP METH NA, DOI DOI 10.18653/V1/D15-1166
   [Anonymous], 2011, 22 INT JOINT C ART I, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-385
   [Anonymous], 2009, LDOW
   Ashton K., 2011, RFiD Journal, V22
   Atzori L, 2010, COMPUT NETW, V54, P2787, DOI 10.1016/j.comnet.2010.05.010
   Bengio Y., 2014, TECHNICAL REPORT
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Chorowski J, 2015, ADV NEUR IN, V28
   Daga E, 2016, SEMANT WEB, V7, P183, DOI 10.3233/SW-150182
   Daniel A, 2016, WIRELESS PERS COMMUN, V87, P461, DOI 10.1007/s11277-015-3078-7
   Deng L, 2013, INT CONF ACOUST SPEE, P8604, DOI 10.1109/ICASSP.2013.6639345
   Dietze S, 2013, PROGRAM-ELECTRON LIB, V47, P60, DOI 10.1108/00330331211296312
   Elmisery AM, 2016, IEEE ACCESS, V4, P8418, DOI 10.1109/ACCESS.2016.2631546
   Elmisery AM, 2017, Cluster Comput., P1
   Freda Margaret Comerford, 2005, J Pediatr Health Care, V19, P151
   Gómez J, 2013, PROCEDIA COMPUT SCI, V21, P132, DOI 10.1016/j.procs.2013.09.019
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   He J, 2016, INT J PSYCHOL, V51, P445, DOI 10.1002/ijop.12263
   Kim YC, 2016, J DRUG TARGET, V24, P943, DOI 10.3109/1061186X.2016.1159213
   Kim YC, 2016, INT CONF IT CONVERGE, P1, DOI 10.1109/PlatCon.2016.7456835
   Kortuem G, 2013, COMPUTER, V46, P53, DOI 10.1109/MC.2012.390
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li SC, 2015, INFORM SYST FRONT, V17, P243, DOI 10.1007/s10796-014-9492-7
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Mihalcea R., 2004, P 2004 C EMPIRICAL M, P404, DOI DOI 10.3115/1219044.1219064
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Mikolov T, 2013, ICLR WORKSHOP POSTER
   Nentwig M, 2017, SEMANT WEB, V8, P419, DOI 10.3233/SW-150210
   Oliveras B, 2013, INT J SCI EDUC, V35, P885, DOI 10.1080/09500693.2011.586736
   Rajabi E, 2013, FIRST INTERNATIONAL CONFERENCE ON TECHNOLOGICAL ECOSYSTEM FOR ENHANCING MULTICULTURALITY (TEEM'13), P339, DOI 10.1145/2536536.2536588
   Rajabi E, 2014, J INF SCI, V40, P637, DOI 10.1177/0165551514538151
   Rathore MM, 2016, COMPUT NETW, V101, P63, DOI 10.1016/j.comnet.2015.12.023
   Raths D., 2014, The Education Digest, V79, P15
   Roach T, 2014, INT REV ECON EDUC, V17, P74, DOI 10.1016/j.iree.2014.08.003
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Severyn A, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P959, DOI 10.1145/2766462.2767830
   Sherrer P., 2011, COLL TEACH, V59, P56, DOI 10.1080/87567555.2010.511313
   Singh D, 2014, 2014 IEEE WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P287, DOI 10.1109/WF-IoT.2014.6803174
   Sun X, 2016, NEUROCOMPUTING, V210, P227, DOI 10.1016/j.neucom.2016.02.077
   WANG Y, 2010, COMP APPL SYST MOD I, V13, pV13
   Whitmore A, 2015, INFORM SYST FRONT, V17, P261, DOI 10.1007/s10796-014-9489-2
   Xu L, 2016, IEEE T KNOWL DATA EN, V28, P1779, DOI 10.1109/TKDE.2016.2540639
   Yu HQ, 2012, IEEE T LEARN TECHNOL, V5, P130, DOI 10.1109/TLT.2012.1
NR 46
TC 7
Z9 7
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3009
EP 3043
DI 10.1007/s11042-018-5610-8
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600019
DA 2024-07-18
ER

PT J
AU Liu, N
   Huo, H
   Fang, T
AF Liu, Na
   Huo, Hong
   Fang, Tao
TI Robust object tracking via constrained online dictionary learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Human motion analysis; Dictionary learning; Appearance
   changes
ID TIME VISUAL TRACKING
AB Robust object tracking has widespread applications in human motion analysis systems, but it is challenging due to various factors, such as occlusion, illumination variation, and complex backgrounds. In this paper, we present a novel tracking method on the basis of a constrained online dictionary learning algorithm. Some existing tracking methods cannot consider background effects and thus have weak discriminative ability. Moreover, some dictionary learning-based tracking methods directly collect target templates and background templates as positive and negative dictionaries, respectively. The main issue is that the dictionaries cannot effectively represent the target and background and handle appearance changes. Thus, a constrained online dictionary learning algorithm is proposed to obtain a discriminative dictionary, which can ensure that the proposed tracker has good discriminative ability in distinguishing targets from complex backgrounds. Experimental results show that the proposed algorithm performs favorably against other state-of-the-art methods in terms of accuracy and robustness.
C1 [Liu, Na; Huo, Hong; Fang, Tao] Shanghai Jiao Tong Univ, Dept Automat, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Liu, N (corresponding author), Shanghai Jiao Tong Univ, Dept Automat, Shanghai, Peoples R China.
EM liuna_sjtu@163.com; tfang@sjtu.edu.cn
RI fang, tao/IQU-3074-2023
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 12 IEEE INT C ADV VI
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Cheng X, 2017, IEEE T SYST MAN CY-S, V47, P628, DOI 10.1109/TSMC.2016.2618749
   Dou JF, 2017, MULTIMED TOOLS APPL, V76, P15839, DOI 10.1007/s11042-016-3872-6
   Hoseinnezhad R, 2013, IEEE T SIGNAL PROCES, V61, P392, DOI 10.1109/TSP.2012.2222389
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li HX, 2011, PROC CVPR IEEE, P1305, DOI 10.1109/CVPR.2011.5995483
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Oron S, 2015, INT J COMPUT VISION, V111, P213, DOI 10.1007/s11263-014-0740-6
   Ou W., 2017, MULTIMED TOOLS APPL, P1
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Shuyang Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P17, DOI 10.1109/CVPRW.2015.7301315
   Tang S, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEM AND ARTIFICIAL INTELLIGENCE (ISAI 2016), P630, DOI [10.1109/ISAI.2016.0139, 10.1109/ISAI.2016.138]
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang DJ, 2016, MULTIMED TOOLS APPL, V75, P10271, DOI 10.1007/s11042-015-3078-3
   Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307
   Wang NY, 2013, IEEE I CONF COMP VIS, P657, DOI 10.1109/ICCV.2013.87
   Xie XH, 2017, INT J COMPUT VISION, V122, P409, DOI 10.1007/s11263-017-1008-8
   Xie Y, 2014, IEEE T CYBERNETICS, V44, P539, DOI 10.1109/TCYB.2013.2259230
   Xing JL, 2013, IEEE I CONF COMP VIS, P665, DOI 10.1109/ICCV.2013.88
   Yang M, 2010, IEEE IMAGE PROC, P1601, DOI 10.1109/ICIP.2010.5652363
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
   Zhang SP, 2013, PATTERN RECOGN, V46, P1772, DOI 10.1016/j.patcog.2012.10.006
   Zhang TZ, 2013, INT J COMPUT VISION, V101, P367, DOI 10.1007/s11263-012-0582-z
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
NR 31
TC 4
Z9 4
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3689
EP 3703
DI 10.1007/s11042-017-5538-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600056
DA 2024-07-18
ER

PT J
AU Zhao, LJ
   Bai, HH
   Wang, AH
   Zhao, Y
AF Zhao, Lijun
   Bai, Huihui
   Wang, Anhong
   Zhao, Yao
TI Iterative range-domain weighted filter for structural preserving image
   smoothing and de-noising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artifact removal; Compression distortion; Depth image; Piece-wise
   smoothness image; De-noising; Image smoothing
AB The filtering weights from both spatial domain and range domain in the bilateral filtering always restrict filtering output value highly related to very close neighboring pixels, which results in very small changes before and after filtering. In order to better resolve the problem of piece-wise smoothness image's de-noising, such as artifact removal of compressed depth image, we firstly propose an iterative range-domain weighted filter method. The filtering weights of the proposed method are calculated within a fixed window in an iterative way according to both pixel similarity in the range domain and image's pixel occurring frequency, but there is no filtering weight from the spatial domain. Secondly, the proposed method is combined with Gaussian filtering as an engine in order to finish the task of image smoothing, because image smoothing for extracting structures is often sensitive to image's fine details with strong gradients during suppressing image's textures. To demonstrate the efficiency, we have applied the proposed method into many applications. For example, the proposed method has better performances on compressed depth artifact removal than BF, CVBF, and ADTF. Meanwhile, the proposed method is used for capture-noise removal of depth image. Additionally, the proposed method performs better performance on structural information preservation for image smoothing, as compared to several existing methods.
C1 [Zhao, Lijun; Bai, Huihui; Zhao, Yao] Beijing Jiaotong Univ, Inst Informat Sci, 3 Shangyuancun, Beijing, Peoples R China.
   [Wang, Anhong] Taiyuan Univ Sci & Technol, Inst Digital Media & Commun, 66 Waliu Rd, Taiyuan, Shanxi, Peoples R China.
C3 Beijing Jiaotong University; Taiyuan University of Science & Technology
RP Bai, HH (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, 3 Shangyuancun, Beijing, Peoples R China.
EM 15112084@bjtu.edu.cn; hhbai@bjtu.edu.cn; wah_ty@163.com;
   yzhao@bjtu.edu.cn
RI Zhao, Lijun/S-7237-2019
OI Zhao, Lijun/0000-0002-2305-1914
FU National Natural Science Foundation of China [61672087, 61402033,
   61672373]; Fundamental Research Funds for the Central Universities
FX This work was supported in part by This work was supported in part by
   National Natural Science Foundation of China (No. 61672087, 61402033,
   61672373) and the Fundamental Research Funds for the Central
   Universities.
CR [Anonymous], 2011, CALL PROP 3D VIED CO
   [Anonymous], 3DV SEQ ETRI GIST
   Barash D, 2004, IMAGE VISION COMPUT, V22, P73, DOI 10.1016/j.imavis.2003.08.005
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dabov K, 2006, PROC SPIE, V6064, DOI 10.1117/12.643267
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Fraunhofer Heinrich Hertz Inst Berlin Germany, 2013, 3DV SEQ HHI
   Ham B, 2018, IEEE T PATTERN ANAL, V40, P192, DOI 10.1109/TPAMI.2017.2669034
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Karacan L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508403
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276497, 10.1145/1239451.1239547]
   Li T, 2013, IEEE INT CONF MULTI
   Liu SJ, 2011, IEEE T BROADCAST, V57, P551, DOI 10.1109/TBC.2011.2120750
   Lu S, 2014, PROC CVPR IEEE, P3390, DOI 10.1109/CVPR.2014.433
   Min DB, 2014, IEEE T IMAGE PROCESS, V23, P5638, DOI 10.1109/TIP.2014.2366600
   Min DB, 2012, IEEE T IMAGE PROCESS, V21, P1176, DOI 10.1109/TIP.2011.2163164
   Nowak RD, 1999, IEEE T IMAGE PROCESS, V8, P1408, DOI 10.1109/83.791966
   Paris S., 2008, INCOMPUTERGRAPHICSAN, V4, P1
   Richardt C, 2012, COMPUT GRAPH FORUM, V31, P247, DOI 10.1111/j.1467-8659.2012.03003.x
   Shen G, 2011, EDG AD TRANSF EFF DE, P566, DOI [10.1109/PCS.2010.5702565, DOI 10.1109/PCS.2010.5702565]
   Sutton C, 2012, FOUND TRENDS MACH LE, V4, P267, DOI 10.1561/2200000013
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   van de Weijer J, 2001, PROC CVPR IEEE, P428
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Xu XY, 2014, SIGNAL PROCESS-IMAGE, V29, P316, DOI 10.1016/j.image.2013.12.005
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
   Zhao L, 2017, SUBJECT COMPUTER VIS
   Zhao LJ, 2017, SIGNAL PROCESS-IMAGE, V54, P11, DOI 10.1016/j.image.2017.02.009
   Zhao LJ, 2015, ELECTRON LETT, V51, P224, DOI 10.1049/el.2014.3912
   Zhao L, 2016, J NANOMATER, V2016, DOI 10.1155/2016/6709764
   Zhu LF, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366146
NR 32
TC 6
Z9 6
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 47
EP 74
DI 10.1007/s11042-017-5253-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500004
DA 2024-07-18
ER

PT J
AU Anami, BS
   Bhandage, VA
AF Anami, Basavaraj S.
   Bhandage, Venkatesh A.
TI A vertical-horizontal-intersections feature based method for
   identification of bharatanatyam double hand mudra images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Samyukta mudras; Contour of mudras; Cell features; Intersections; Rule
   based classifier
AB Bharatanatyam is an Indian classical dance, which has to be studied under an expert. In villages, semi-urban areas and foreign countries the experts are scarce. In order to promote, popularize and make it self-pursuable, this Indian art requires technological leveraging. With this motivation, the goal of this work is to automate identification of mudras through Image processing. This paper presents a three stage methodology for identification of 24 double hand mudra images of Bharatanatyam dance. In the first stage, acquired images of Bharatanatyam mudras are preprocessed to obtain contours of mudras using canny edge detector. In the second stage, cell features are extracted that include number of vertical and horizontal intersections of grid lines with the contours of the mudras. In the third stage, a rule based classifier is developed to classify the given image into 24 classes of mudras. The proposed method is implemented using OpenCV with Microsoft visual C++ IDE. The proposed method finds many applications such as e-learning of mudras and proper postures leading to self-learning of Bharatanatyam dance, online commentary during concerts, and adoption to many other forms of dances prevailing in India and outside.
C1 [Anami, Basavaraj S.] KLE Inst Technol, Hubballi, Karnataka, India.
   [Bhandage, Venkatesh A.] Tontadarya Coll Engn, Dept CSE, Gadag, Karnataka, India.
RP Bhandage, VA (corresponding author), Tontadarya Coll Engn, Dept CSE, Gadag, Karnataka, India.
EM venkateshabhandage@gmail.com
CR Adithya V, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P1080
   [Anonymous], 2012 INT C COMP COMM
   Bretzner L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P423, DOI 10.1109/AFGR.2002.1004190
   Dardas NH, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MEASUREMENT SYSTEMS AND APPLICATIONS (CIMSA), P11
   Fagiani M, 2015, PATTERN ANAL APPL, V18, P385, DOI 10.1007/s10044-014-0400-z
   Hariharan D, 2011, LECT NOTES COMPUT SC, V6744, P186, DOI 10.1007/978-3-642-21786-9_32
   Kumar K., 2017, International Journal of Electrical Computer Engineering, V7, P2537, DOI DOI 10.11591/IJECE.V7I5.PP2537-2546
   Li YT, 2013, IMAGE VISION COMPUT, V31, P649, DOI 10.1016/j.imavis.2013.06.008
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Yun, 2009, Proceedings of the 2009 Second International Workshop on Computer Science and Engineering (WCSE 2009), P72, DOI 10.1109/WCSE.2009.769
   Mozarkar S., 2013, INT J COMPUT SCI NET, V2, P46
   Nadgeri S. M., 2010, Proceedings of the Third International Conference on Emerging Trends in Engineering and Technology (ICETET 2010), P37, DOI 10.1109/ICETET.2010.63
   Saha Sriparna, 2013, 2013 5th International Conference on Computational Intelligence and Communication Networks (CICN), P331, DOI 10.1109/CICN.2013.75
   Shrivastava R, 2013, IEEE INT ADV COMPUT, P947
   Srimani P., 2013, Int. J. Curr. Res., V5, P1457
   Stergiopoulou E, 2009, ENG APPL ARTIF INTEL, V22, P1141, DOI 10.1016/j.engappai.2009.03.008
   Wang M, 2016, MEASUREMENT, V94, P734, DOI 10.1016/j.measurement.2016.09.018
   Zaki MM, 2011, PATTERN RECOGN LETT, V32, P572, DOI 10.1016/j.patrec.2010.11.013
NR 18
TC 8
Z9 8
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 31021
EP 31040
DI 10.1007/s11042-018-6223-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600039
DA 2024-07-18
ER

PT J
AU Evsutin, O
   Kokurina, A
   Meshcheryakov, R
   Shumskaya, O
AF Evsutin, Oleg
   Kokurina, Anna
   Meshcheryakov, Roman
   Shumskaya, Olga
TI The adaptive algorithm of information unmistakable embedding into
   digital images based on the discrete Fourier transformation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information security; Image steganography; Embedding into the image
   frequency domain; DFT; Unmistakable embedding
ID STEGANOGRAPHY SCHEME; JPEG STEGANOGRAPHY; GENETIC ALGORITHM; COLOR
   IMAGE; INTERPOLATION; CAPACITY; DOMAIN; DFT
AB Many effective methods of the data embedding into digital images are based on the frequency transformations. However use of similar transformations is connected to the following problem: the built-in message is distorted because of information losses in case of restoration of pixels' integer values from the frequency domain. It represents a vital issue if the integrity of the transmitted data is critical. For example, an insignificant distortion of the ciphered message results in impossibility of deciphering and to loss of all ciphered information. In this paper is described the new algorithm of the information embedding into digital images on the basis of the discrete Fourier transformation allowing to provide unmistakable extraction of the built-in messages from the frequency domain. The faultlessness is reached through an iterative procedure of embedding and non-uniform distribution of the message parts for the image-container's blocks. Our algorithm not only solves a problem of the built-in messages distortions, but also provides high visual quality of stego-image. Moreover, our approach to the unmistakable embedding of information into the digital images frequency domain is applicable not only for the discrete Fourier transformation, but also for other frequency transformations.
C1 [Evsutin, Oleg; Kokurina, Anna; Meshcheryakov, Roman; Shumskaya, Olga] Tomsk State Univ Control Syst & Radioelect, 40 Lenina Prospect, Tomsk 634050, Russia.
C3 Tomsk State University of Control Systems & Radioelectronics
RP Evsutin, O (corresponding author), Tomsk State Univ Control Syst & Radioelect, 40 Lenina Prospect, Tomsk 634050, Russia.
EM eoo@keva.tusur.su
RI Evsutin, Oleg/E-6719-2017; Melman, Anna/V-4267-2019; Meshcheryakov,
   Roman V./P-4918-2014
OI Evsutin, Oleg/0000-0002-8257-2082; Melman, Anna/0000-0001-6444-7774;
   Meshcheryakov, Roman V./0000-0002-1129-8434; Shumskaya,
   Olga/0000-0002-8287-5032
FU Russian Federation Ministry of Education and Science [2.3583.2017/4.6]
FX The work was funded by the Russian Federation Ministry of Education and
   Science (grant 2.3583.2017/4.6). We are very grateful to the anonymous
   referees for their constructive comments and helpful suggestions to
   improve the quality of this paper.
CR Al-Dmour H, 2016, EXPERT SYST APPL, V46, P293, DOI 10.1016/j.eswa.2015.10.024
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   [Anonymous], 2007, J CHEM INF MODEL, DOI DOI 10.1017/CBO9781107415324.004
   [Anonymous], DIGITAL IMAGE PROCES
   Bakshi S, 2018, MULTIMED TOOLS APPL, V77, P17595, DOI 10.1007/s11042-017-4965-6
   Cedillo-Hernandez M, 2015, SIGNAL IMAGE VIDEO P, V9, P1163, DOI 10.1007/s11760-013-0555-x
   Chen Q, 2018, MULTIMED TOOLS APPL, V77, P18601, DOI 10.1007/s11042-017-5299-0
   Chen ST, 2016, MULTIMED TOOLS APPL, V75, P5493, DOI 10.1007/s11042-015-2522-8
   Chen WY, 2008, APPL MATH COMPUT, V196, P40, DOI 10.1016/j.amc.2007.05.063
   Choi YH, 2014, MULTIMED TOOLS APPL, V71, P263, DOI 10.1007/s11042-012-1315-6
   Dogan S, 2016, ARTIF INTELL REV, V46, P129, DOI 10.1007/s10462-016-9459-9
   Ejaz N, 2014, MULTIMED TOOLS APPL, V73, P825, DOI 10.1007/s11042-013-1377-0
   Fallahpour M, 2011, MULTIMED TOOLS APPL, V52, P513, DOI 10.1007/s11042-010-0486-2
   Fridrich J., 2010, STEGANOGRAPHY DIGITA
   Holliman M, 1997, P SOC PHOTO-OPT INS, V3312, P284, DOI 10.1117/12.298461
   Huang FJ, 2012, IEEE T INF FOREN SEC, V7, P1181, DOI 10.1109/TIFS.2012.2198213
   Islam S, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-8
   Jiang CL, 2014, CIRC SYST SIGNAL PR, V33, P1611, DOI 10.1007/s00034-013-9703-3
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Li FY, 2014, ANN TELECOMMUN, V69, P431, DOI 10.1007/s12243-013-0415-2
   Liu SA, 2017, MULTIMED TOOLS APPL, V76, P5787, DOI 10.1007/s11042-014-2408-1
   Maity SP, 2009, SOFT COMPUT, V13, P361, DOI 10.1007/s00500-008-0329-5
   Pakdaman Z, 2017, MULTIMED TOOLS APPL, V76, P8517, DOI 10.1007/s11042-016-3490-3
   Poljicak A, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3609010
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P16657, DOI 10.1007/s11042-016-3942-9
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P8627, DOI 10.1007/s11042-016-3501-4
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P6473, DOI 10.1007/s11042-016-3301-x
   Ridzon R, 2013, TELECOMMUN SYST, V52, P1617, DOI 10.1007/s11235-011-9655-5
   Solachidis V, 2001, IEEE T IMAGE PROCESS, V10, P1741, DOI 10.1109/83.967401
   Song J, 2018, MULTIMED TOOLS APPL, V77, P23529, DOI 10.1007/s11042-018-5682-5
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Weng CY, 2012, OPTO-ELECTRON REV, V20, P126, DOI 10.2478/s11772-012-0020-3
   Xie X, 2017, P INT C MICRO EL SYS, DOI [10.1109/MEMSYS.2017.7863532, DOI 10.1109/MEMSYS.2017.7863532]
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   [No title captured]
   [No title captured]
   [No title captured]
NR 40
TC 9
Z9 9
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28567
EP 28599
DI 10.1007/s11042-018-6055-9
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500033
DA 2024-07-18
ER

PT J
AU Paliyawan, P
   Choensawat, W
   Thawonmas, R
AF Paliyawan, Pujana
   Choensawat, Worawat
   Thawonmas, Ruck
TI Mossar: motion segmentation by using splitting and remerging strategies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion segmentation; Motion representation; Graph Kernel matching
ID RETRIEVAL
AB This paper presents a novel approach for motion segmentation by using strategies of splitting and remerging. The presented approach, Mossar, hybridizes two existing ones to obtain their potential advantages while covering weaknesses: (1) velocity-based, one of the most widely used approaches that has fairly low accuracy but provides computational simplicity and (2) graph-based, a state-of-the-art approach that provides outstanding accuracy, yet bears high computational complexity and a burden in setting of thresholds. An initial set of key frames is generated by a velocity-based splitting process and then fed into a graph-based remerging process for refinement. We present mechanisms that improve key-frames capturing in the velocity-based approach as well as details on how the graph-based approach is modified and later applied to remerging. The proposed approach also allows users to interactively add or reduce the number of key frames to control segmentation hierarchy without the need to change threshold values and re-run segmentation, as usually done in existing approaches. Our experimental results show that the presented hybrid approach, compared to both velocity-based and graph-based, demonstrates superior performance in terms of accuracy and in comparison to graph-based, our approach has not only less complexity but also a lesser number of thresholds, the values of which can be much more simply determined.
C1 [Paliyawan, Pujana; Thawonmas, Ruck] Ritsumeikan Univ, Grad Sch Informat Sci & Engn, Intelligent Comp Entertainment Lab, Kusatsu, Shiga, Japan.
   [Choensawat, Worawat] Bangkok Univ, Sch Informat Technol & Innovat, Multimedia Intelligent Technol Lab, Bangkok, Thailand.
C3 Ritsumeikan University; Bangkok University
RP Paliyawan, P (corresponding author), Ritsumeikan Univ, Grad Sch Informat Sci & Engn, Intelligent Comp Entertainment Lab, Kusatsu, Shiga, Japan.
EM Pujana.P@gmail.com
CR [Anonymous], CMU GRAPH LAB MOT CA
   [Anonymous], 2007, COMPUTER ANIMATION S
   [Anonymous], 2014, P 2014 ACM SIGGRAPHE
   [Anonymous], 2003, KDD
   Choensawat W, 2015, MULTIMED TOOLS APPL, V74, P10823, DOI 10.1007/s11042-014-2209-6
   Devanne M, 2015, FGW, V7, P1
   Escalera S, 2016, J MACH LEARN RES, V17
   Gong D, 2012, LECT NOTES COMPUT SC, V7574, P229, DOI 10.1007/978-3-642-33712-3_17
   Hachimura K, 2001, ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P122, DOI 10.1109/ROMAN.2001.981889
   Keogh E., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases, P406
   Khan S, 2014, INT J COMPUT APPL T, V50, P75, DOI 10.1504/IJCAT.2014.063910
   Krüger B, 2017, IEEE T MULTIMEDIA, V19, P797, DOI 10.1109/TMM.2016.2635030
   Li M, 2016, MULTIMED TOOLS APPL, V75, P9205, DOI 10.1007/s11042-016-3480-5
   Li M, 2016, COMPUT GRAPH-UK, V54, P104, DOI 10.1016/j.cag.2015.07.005
   Lim IS, 2001, P ANN INT IEEE EMBS, V23, P1167
   Liu F, 2003, COMPUT VIS IMAGE UND, V92, P265, DOI 10.1016/j.cviu.2003.06.001
   Miura Takeshi, 2011, Information and Media Technologies, V6, P172
   Paliyawan P, 2015, 2015 IEEE 4TH GLOBAL CONFERENCE ON CONSUMER ELECTRONICS (GCCE), P332, DOI 10.1109/GCCE.2015.7398599
   Panagiotakis C, 2013, LECT NOTES COMPUT SC, V8034, P118, DOI 10.1007/978-3-642-41939-3_12
   Ruffieux S, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P483, DOI 10.1145/2522848.2532590
   Shiratori T, 2018, P INT C VIRT SYST MU, V3
   Tunca C, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040825
   Van Mieghem P., 2010, GRAPH SPECTRA COMPLE
   Wang QF, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P562, DOI 10.1109/3DV.2015.69
   Wessa P., KERNEL DENSITY ESTIM
   Yin Y, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P489, DOI 10.1145/2522848.2532588
   Zhou F, 2013, IEEE T PATTERN ANAL, V35, P582, DOI 10.1109/TPAMI.2012.137
NR 27
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 27761
EP 27788
DI 10.1007/s11042-018-5965-x
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500002
DA 2024-07-18
ER

PT J
AU Becerra, A
   de la Rosa, JI
   González, E
   Pedroza, AD
   Escalante, NI
AF Becerra, Aldonso
   Ismael de la Rosa, J.
   Gonzalez, Efren
   David Pedroza, A.
   Iracemi Escalante, N.
TI Training deep neural networks with non-uniform frame-level cost function
   for automatic speech recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech recognition; Neural networks; Deep learning; Cross-entropy;
   Extropy; Frame-level loss function
ID HIDDEN MARKOV-MODELS; MIXTURE OBSERVATIONS; ADAPTATION; ALGORITHM;
   ENTROPY
AB The aim of this paper is to exhibit two new variations of the frame-level cost function for training a deep neural network in order to achieve better word error rates in speech recognition. Optimization methods and their minimization functions are underlying aspects to consider when someone is working on neural nets, and hence their improvement is one of the salient objectives of researchers, and this paper deals in part with such a situation. The first proposed framework is based on the concept of extropy, the complementary dual function of an uncertainty measure. The conventional cross-entropy function can be mapped to a non-uniform loss function based on its corresponding extropy, enhancing the frames that have ambiguity in their belonging to specific senones. The second proposal makes a fusion of the presented mapped cross-entropy function and the idea of boosted cross-entropy, which emphasizes those frames with low target posterior probability. The proposed approaches have been performed by using a personalized mid-vocabulary speaker-independent voice corpus. This dataset is employed for recognition of digit strings and personal name lists in Spanish from the northern central part of Mexico on a connected-words phone dialing task. A relative word error rate improvement of and is obtained with the two proposed approaches, respectively, with regard to the conventional well-established cross-entropy objective function.
C1 [Becerra, Aldonso; Ismael de la Rosa, J.; Gonzalez, Efren; David Pedroza, A.] Univ Autonoma Zacatecas, Unidad Acad Ingn Elect, Av Lopez Velarde 801, Zacatecas 98068, Mexico.
   [Iracemi Escalante, N.] Inst Tecnol Pabellon Arteaga, Dept Basic Sci, Carretera Estn Rincon KM 1, Pabellon De Arteaga 20670, Ags, Mexico.
C3 Universidad Autonoma de Zacatecas
RP Becerra, A (corresponding author), Univ Autonoma Zacatecas, Unidad Acad Ingn Elect, Av Lopez Velarde 801, Zacatecas 98068, Mexico.
EM a7donso@uaz.edu.mx; ismaelrv@ieee.org; gonzalez_efren@hotmail.com;
   P.A.D_16@hotmail.com; aivinsg_2682@hotmail.com
RI De la Rosa, José Ismael/N-7394-2019
OI De la Rosa, José Ismael/0000-0002-7337-8974; Pedroza,
   Angel/0000-0003-3568-2745; Escalante, Nivia/0000-0003-2688-6519;
   Becerra, Aldonso/0000-0002-4274-4396; GONZALEZ-RAMIREZ,
   EFREN/0000-0002-8060-6170
FU Universidad Autonoma de Zacatecas (UAZ); CONACyT
FX The first author acknowledge all support given by the Universidad
   Autonoma de Zacatecas (UAZ) during the years 2014-2017 to realize his
   PhD academic formation. Additional acknowledgements for the support
   given by CONACyT during his stay of postgraduate studies.
CR Ali A, 2014, IEEE W SP LANG TECH, P525, DOI 10.1109/SLT.2014.7078629
   Allauzen C, 2007, LECT NOTES COMPUT SC, V4783, P11
   [Anonymous], 2006, The HTK book (for HTK version 3.4) [Computer software manual]
   [Anonymous], P AUT SPEECH REC UND
   [Anonymous], 2011, P INT C FLOR IT 27 3, DOI DOI 10.5555/3042573.3042574
   [Anonymous], 2014, P IEEE INT C AC SPEE
   Bacchiani M, 2014, P INTERSPEECH, P1900
   Becerra A, 2016, PROCEEDINGS OF THE 2016 IEEE ANDESCON
   Becerra A, 2018, MULTIMED TOOLS APPL, V77, P15875, DOI 10.1007/s11042-017-5160-5
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bilmes JA, 2006, IEICE T INF SYST, VE89D, P869, DOI 10.1093/ietisy/e89-d.3.869
   Bishop Christopher M, 2006, PATTERN RECOGNITION, DOI DOI 10.1117/1.2819119
   Bourlard Herve A., 1993, Connectionist speech recognition: a hybrid approach, DOI 10.1007/978-1-4615-3210-1
   BURBEA J, 1982, IEEE T INFORM THEORY, V28, P489, DOI 10.1109/TIT.1982.1056497
   Chen X, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P26
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   DENG L, 1991, IEEE T SIGNAL PROCES, V39, P1677, DOI 10.1109/78.134406
   Deng L, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/atsip.2013.9
   Deng L, 2013, IEEE T AUDIO SPEECH, V21, P1060, DOI 10.1109/TASL.2013.2244083
   Duda R. O., 2001, PATTERN CLASSIFICATI, P517
   Gales M, 2007, FOUND TRENDS SIGNAL, V1, P195, DOI 10.1561/2000000004
   Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278
   Ge ZH, 2017, PROCEEDINGS OF THE 2017 INTELLIGENT SYSTEMS CONFERENCE (INTELLISYS), P1089, DOI 10.1109/IntelliSys.2017.8324265
   Hagan M. T., 2014, NEURAL NETWORK DESIG
   Heigold G, 2013, IEEE T AUDIO SPEECH, V21, P2616, DOI 10.1109/TASL.2013.2280234
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang Z, 2014, INTERSPEECH, P1214
   JUANG BH, 1986, IEEE T INFORM THEORY, V32, P307, DOI 10.1109/TIT.1986.1057145
   Jurafsky D., 2021, SPEECH LANGUAGE PROC
   Kingsbury B, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P10
   Lad F, 2015, STAT SCI, V30, P40, DOI 10.1214/14-STS430
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li X, 2013, P SIGN INF PROC ASS
   Li XG, 2014, 2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP), P10, DOI 10.1109/ISCSLP.2014.6936622
   Li XG, 2015, NEUROCOMPUTING, V170, P251, DOI 10.1016/j.neucom.2014.07.087
   Liao Y, 2015, P IEEE C AUT SPEECH, DOI [10.1109/ASRU.2015.7404786, DOI 10.1109/ASRU.2015.7404786]
   McLachlan G., 1988, MIXTURE MODELS
   Mehrotra K., 1997, ELEMENTS ARTIFICIAL
   Miao YJ, 2013, INTERSPEECH, P2236
   Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382
   Morgan N., 1995, IEEE Signal Processing Magazine, V12, P24, DOI 10.1109/79.382443
   Pan J, 2012, 2012 8TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING, P301, DOI 10.1109/ISCSLP.2012.6423452
   Povey S, 2011, P AUT SPEECH REC UND
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   RAO R, 1984, MULTIVARIATE STAT ME, P49
   Rath SP, 2013, INTERSPEECH, P109
   Ray J, 2014, 2014 FIRST WORKSHOP FOR HIGH PERFORMANCE TECHNICAL COMPUTING IN DYNAMIC LANGUAGES HPTCDL 2014, P41, DOI 10.1109/HPTCDL.2014.12
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Sainath TN, 2013, IEEE T AUDIO SPEECH, V21, P2267, DOI 10.1109/TASL.2013.2284378
   Scowen R. S., 1993, Proceedings 1993 Software Engineering Standards Symposium (Cat. No.93TH0568-6), P25, DOI 10.1109/SESS.1993.263968
   Seide F., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P24, DOI 10.1109/ASRU.2011.6163899
   Seki H, 2014, 2014 INTERNATIONAL CONFERENCE OF ADVANCED INFORMATICS: CONCEPT, THEORY AND APPLICATION (ICAICTA), P249, DOI 10.1109/ICAICTA.2014.7005949
   Seltzer ML, 2013, INT CONF ACOUST SPEE, P7398, DOI 10.1109/ICASSP.2013.6639100
   Siniscalchi SM, 2014, NEUROCOMPUTING, V140, P326, DOI 10.1016/j.neucom.2014.03.005
   Su H, 2013, INT CONF ACOUST SPEE, P6664, DOI 10.1109/ICASSP.2013.6638951
   Tao DP, 2016, IEEE T NEUR NET LEAR, V27, P1122, DOI 10.1109/TNNLS.2015.2461554
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Tao DP, 2016, IEEE T CYBERNETICS, V46, P756, DOI 10.1109/TCYB.2015.2414920
   Trentin E, 2001, NEUROCOMPUTING, V37, P91, DOI 10.1016/S0925-2312(00)00308-8
   Vesely K, 2013, INTERSPEECH, P2344
   Vesely K, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P267, DOI 10.1109/ASRU.2013.6707741
   Vincent Pascal, 2008, P 25 INT C MACHINE L, DOI DOI 10.1145/1390156.1390294
   WEI W, 1998, P IEEE INT C AC SPEE, P1520, DOI DOI 10.1109/ICASSP.1998.674476
   Wiesler S, 2015, INT CONF ACOUST SPEE, P4565, DOI 10.1109/ICASSP.2015.7178835
   Xue SF, 2014, IEEE-ACM T AUDIO SPE, V22, P1713, DOI 10.1109/TASLP.2014.2346313
   Yang Z, 2014, LECT NOTES COMPUT SC, V8679, P68, DOI 10.1007/978-3-319-10581-9_9
   Yao KS, 2012, IEEE W SP LANG TECH, P366, DOI 10.1109/SLT.2012.6424251
   Yu D, 2015, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-4471-5779-3
   Yu D., 2010, P NIPS WORKSH DEEP L
   Yu D, 2012, INT CONF ACOUST SPEE, P4409, DOI 10.1109/ICASSP.2012.6288897
   Zhang C., 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5597, DOI 10.1109/ICASSP.2014.6854674
   Zhang Tong, 2004, P 21 INT C MACH LEAR, P116, DOI DOI 10.1145/1015330.1015332
   ZHAO R, 2014, P INTERSPEECH
   Zhou P, 2015, IEEE-ACM T AUDIO SPE, V23, P631, DOI 10.1109/TASLP.2015.2392944
NR 76
TC 15
Z9 15
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27231
EP 27267
DI 10.1007/s11042-018-5917-5
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500046
DA 2024-07-18
ER

PT J
AU Channoufi, I
   Bourouis, S
   Bouguila, N
   Hamrouni, K
AF Channoufi, Ines
   Bourouis, Sami
   Bouguila, Nizar
   Hamrouni, Kamel
TI Image and video denoising by combining unsupervised bounded generalized
   gaussian mixture modeling and spatial information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image and video denoising; Image modeling; Mixture of bounded
   generalized gaussian distribution; Spatial information
ID SCALE MIXTURES; RESTORATION; ENHANCEMENT
AB In recent years, a great deal of effort has been expended on developing robust solutions for images quality degradation caused mainly by noise. In this paper, we explore this area of research and we propose a new unsupervised algorithm for both image and video denoising. Our solution is based on a flexible statistical mixture model driven by a finite mixtures of bounded generalized Gaussian distributions (BGGMD) which offers more flexibility in data modeling than the well known classical gaussian distributions which fail to fit the shape of heavy-tailed data produced by the presence of noise or outliers. The proposed framework takes into account also spatial information between neighboring pixels to be more robust and flexible, and able to provide smooth and accurate denoising results. For model's parameters estimation, we investigate the unsupervised expectation-maximization (EM) algorithm. In order to evaluate the performance of the proposed model, we conducted a series of extensive experiments. Obtained results are more encouraging than those obtained using similar approaches. These results show the robustness and flexibility of the proposed method to adapt different shapes of observed data and bounded support data in the case of noisy images and videos.
C1 [Channoufi, Ines; Hamrouni, Kamel] Univ Tunis El Manar, Ecole Natl Ingenieurs Tunis, LR SITI Lab Signal Image & Technol Informat, Tunis 1002, Tunisia.
   [Bourouis, Sami] Taif Univ, At Taif, Saudi Arabia.
   [Bourouis, Sami] LR SITI Lab Signal Image & Technol Informat, Tunis 1002, Tunisia.
   [Bouguila, Nizar] Concordia Univ, CIISE, Montreal, PQ H3G 1T7, Canada.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT); Taif University; Concordia University - Canada
RP Channoufi, I (corresponding author), Univ Tunis El Manar, Ecole Natl Ingenieurs Tunis, LR SITI Lab Signal Image & Technol Informat, Tunis 1002, Tunisia.
EM ines.channoufi@esprit.tn; s.bourouis@tu.edu.sa;
   nizar.bouguila@concordia.ca; kamel.hamrouni@enit.rnu.tn
RI Bouguila, Nizar/AGN-5929-2022; Bourouis, Sami/N-4995-2019; Bouguila,
   Nizar/AAJ-2518-2020
OI Bourouis, Sami/0000-0002-6638-7039; 
CR Aguerrebere C, 2017, IEEE T COMPUT IMAG, V3, P633, DOI 10.1109/TCI.2017.2704439
   Alisha P.B., 2016, IMAGE DENOISING TECH, V11, P78
   [Anonymous], 2017, 14 IEEE INT C COMP S
   Boulanger J, 2007, IEEE T PATTERN ANAL, V29, P1096, DOI 10.1109/TPAMI.2007.1064
   Buades A, 2016, IEEE T IMAGE PROCESS, V25, P2573, DOI 10.1109/TIP.2016.2551639
   Cao Y, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P339, DOI 10.1109/CISP.2008.312
   Chen Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1930
   Elguebaly T, 2011, SIGNAL PROCESS, V91, P801, DOI 10.1016/j.sigpro.2010.08.014
   Elguebaly T, 2010, LECT NOTES ARTIF INT, V5998, P207, DOI 10.1007/978-3-642-12159-3_19
   Fan SKS, 2009, COMPUT VIS IMAGE UND, V113, P839, DOI 10.1016/j.cviu.2009.03.003
   Goossens B, 2009, IEEE T IMAGE PROCESS, V18, P1689, DOI 10.1109/TIP.2009.2022006
   Hotz T, 2012, COMPUT STAT DATA AN, V56, P543, DOI 10.1016/j.csda.2011.08.018
   Lindblom J, 2003, IEEE T SPEECH AUDI P, V11, P88, DOI 10.1109/TSA.2002.805639
   López-Rubio E, 2011, MED IMAGE ANAL, V15, P498, DOI 10.1016/j.media.2011.02.006
   Luo EM, 2016, IEEE T IMAGE PROCESS, V25, P4489, DOI 10.1109/TIP.2016.2590318
   Maggioni M, 2012, IEEE T IMAGE PROCESS, V21, P3952, DOI 10.1109/TIP.2012.2199324
   McLachlan G., 2004, FINITE MIXTURE MODEL
   Meignen S, 2006, IEEE T IMAGE PROCESS, V15, P1647, DOI 10.1109/TIP.2006.873455
   Ndajah P., 2011, INT J CIRCUITS SYSTE, V5, P423
   Niknejad M, 2015, IEEE T IMAGE PROCESS, V24, P3624, DOI 10.1109/TIP.2015.2447836
   Pi MH, 2006, PATTERN RECOGN LETT, V27, P1710, DOI 10.1016/j.patrec.2006.04.019
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Rajpoot N, 2012, PATTERN RECOGN, V45, P2938, DOI 10.1016/j.patcog.2012.01.023
   Sattar F, 1997, IEEE T IMAGE PROCESS, V6, P888, DOI 10.1109/83.585239
   Scheunders P, 2007, IEEE T IMAGE PROCESS, V16, P1865, DOI 10.1109/TIP.2007.899598
   Schwenker F, 2010, P 4 IAPR TC3 WORKSH, V5998
   Sefidpour A, 2012, EXPERT SYST APPL, V39, P8993, DOI 10.1016/j.eswa.2012.02.024
   Teodoro Afonso M. A. M., 2015, 4th International Conference on Pattern Recognition Applications and Methods (ICPRAM 2015). Proceedings, P283
   Nguyen TM, 2014, PATTERN RECOGN, V47, P3132, DOI 10.1016/j.patcog.2014.03.030
   Varghese G, 2010, IEEE T CIRC SYST VID, V20, P1032, DOI 10.1109/TCSVT.2010.2051366
   Wang YQ, 2013, SIAM J IMAGING SCI, V6, P999, DOI 10.1137/120901131
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie CH, 2014, IET IMAGE PROCESS, V8, P464, DOI 10.1049/iet-ipr.2013.0202
   Yang HY, 2011, COMPUT ELECTR ENG, V37, P656, DOI 10.1016/j.compeleceng.2010.09.004
   Zhang RQ, 2013, IEEE GLOB CONF SIG, P1089, DOI 10.1109/GlobalSIP.2013.6737083
   [No title captured]
NR 36
TC 20
Z9 20
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25591
EP 25606
DI 10.1007/s11042-018-5808-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400043
DA 2024-07-18
ER

PT J
AU Kumar, K
   Shrimankar, DD
AF Kumar, Krishan
   Shrimankar, Deepti D.
TI Deep Event Learning boosT-up Approach: DELTA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AdaBoosting; Deep learning; Event summarization; Key-frame; Multi-view
   video
ID VIDEO; MODEL
AB Nowadays, the video surveillance systems may be omnipresent, but essential for supervision everywhere, e.g., ATM, airport, railway station and other crowded situations. In the multi-view video systems, various cameras are producing a huge amount of video content around the clock which makes it difficult for fast browsing, retrieval, and analysis. Accessing and managing such huge data in real time becomes a real challenging task because of inter-view dependencies, illumination changes and the bearing of many inactive frames. The work highlights an accurate and efficient technique to detect and summarize the event in multi-view surveillance videos using boosting, a machine learning algorithm, as a solution to the above issues. Interview dependencies across multiple views of the video are captured via weak learning classifiers in boosting algorithm. The light changes and still frames are tackled with moving an object in the frame by Deep learning framework. It helps to reach the correct decision for the active frame and inactive frame, without any prior information about the number of issues in a video. Target, as well as subjective ratings, clearly indicate the potency of our proposed DELTA model, where it successfully reduces the video data, while keeping the important information as events.
C1 [Kumar, Krishan; Shrimankar, Deepti D.] Visvesvaraya Natl Inst Technol Nagpur, Dept Comp Sci & Engn, Nagpur, Maharashtra, India.
   [Kumar, Krishan] Natl Inst Technol Uttarakhand, Srinagar, Uttarakhand, India.
C3 National Institute of Technology (NIT System); Visvesvaraya National
   Institute of Technology, Nagpur; National Institute of Technology (NIT
   System); National Institute of Technology Uttarakhand
RP Kumar, K (corresponding author), Visvesvaraya Natl Inst Technol Nagpur, Dept Comp Sci & Engn, Nagpur, Maharashtra, India.; Kumar, K (corresponding author), Natl Inst Technol Uttarakhand, Srinagar, Uttarakhand, India.
EM kkberwal@nituk.ac.in; dshrimankar@cse.vnit.ac.in
RI Kumar, Dr. Krishan/N-9846-2018; Berwal, Krishan/AAC-3473-2020; Kumar,
   Krishan/AAE-1656-2021
OI Kumar, Dr. Krishan/0000-0002-7068-6541; Berwal,
   Krishan/0000-0002-7068-6541; 
CR Alfaro A, 2016, PROC CVPR IEEE, P2688, DOI 10.1109/CVPR.2016.294
   Almeida J, 2013, J VIS COMMUN IMAGE R, V24, P729, DOI 10.1016/j.jvcir.2012.01.009
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   Anurag K, 2017, IEEE CICT 17
   Brunelli R, 1999, J VIS COMMUN IMAGE R, V10, P78, DOI 10.1006/jvci.1997.0404
   Chang P, 2002, IEEE IMAGE PROC, P609
   Chang XJ, 2016, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2016.208
   Fu Y, 2014, CORR
   Fu YW, 2010, IEEE T MULTIMEDIA, V12, P717, DOI 10.1109/TMM.2010.2052025
   Gagandeep S, 2017, PICS NOVEL TECHNIQUE
   Gan C, 2015, PROC CVPR IEEE, P2568, DOI 10.1109/CVPR.2015.7298872
   Gygli M, 2015, PROC CVPR IEEE, P3090, DOI 10.1109/CVPR.2015.7298928
   Hao Wei., 2006, CVPRW 06, P113, DOI [10.1109/CVPRW.2006.87, DOI 10.1109/CVPRW.2006.87]
   Jasim H, 2016, WASET INT J COMP ELE, V10, P1652
   Jiang YG, 2015, IEEE T MULTIMEDIA, V17, P1174, DOI 10.1109/TMM.2015.2436813
   Jones, 2006, U.S. Patent, Patent No. [7,099,510.29, 709951029]
   Krishan K, 2017, IEEE TMM
   Krishan K, 2017, ACM ICCCT 17
   Krishan K, 2017, CVIP 17
   Krishan K, 2017, ICACNI 17
   Krogh A., 1995, Advances in Neural Information Processing Systems 7, P231
   Kuanar SK, 2015, IEEE T MULTIMEDIA, V17, P1166, DOI 10.1109/TMM.2015.2443558
   Kumar K, 2017, EVENT BAGGING NOVEL
   Kumar K, 2017, KEY LECTURES KEYFRAM
   Kumar KM, 2018, MATER MANUF PROCESS, V33, P414, DOI 10.1080/10426914.2017.1291951
   Kumar K, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P119, DOI 10.1109/SITIS.2016.27
   Lu SY, 2014, IEEE T MULTIMEDIA, V16, P1497, DOI 10.1109/TMM.2014.2319778
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Mazloom M, 2016, IEEE T MULTIMEDIA, V18, P1378, DOI 10.1109/TMM.2016.2559947
   Mazloom M, 2014, IEEE T MULTIMEDIA, V16, P2214, DOI 10.1109/TMM.2014.2359771
   Merler M, 2012, IEEE T MULTIMEDIA, V14, P88, DOI 10.1109/TMM.2011.2168948
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Musfequs S, 2016, IEEE DICTA 16
   Nagasaka A, 1991, 2 WORK C VIS DAT SYS, P119
   Ou SH, 2015, IEEE J-STSP, V9, DOI 10.1109/JSTSP.2014.2331916
   Panagiotakis C, 2009, IEEE T CIRC SYST VID, V19, P447, DOI 10.1109/TCSVT.2009.2013517
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Qian SS, 2016, IEEE T MULTIMEDIA, V18, P233, DOI 10.1109/TMM.2015.2510329
   Singh N, 2017, MULTIMED TOOLS APPL, V76, P10521, DOI 10.1007/s11042-016-3676-8
   Singh N, 2016, DIGIT SIGNAL PROCESS, V55, P22, DOI 10.1016/j.dsp.2016.05.003
   Sun XD, 2000, REAL-TIME IMAGING, V6, P449, DOI 10.1006/rtim.1999.0197
   Valdes V., 2008, Proceedings of the TRECVID BBC Rushes Summarization Workshop (TVS 2008) at ACM Multimedia, P134, DOI [10.1145/1463563.1463588, DOI 10.1145/1463563.1463588]
   Vezhnevets A, 2007, LECT NOTES ARTIF INT, V4701, P430
   Wang F, 2014, IEEE T MULTIMEDIA, V16, P1303, DOI 10.1109/TMM.2014.2315780
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Wang S, 2014, IEEE T MULTIMEDIA, V16, P289, DOI 10.1109/TMM.2013.2293060
   Wang XY, 2015, PROC CVPR IEEE, P4418, DOI 10.1109/CVPR.2015.7299071
   Weber B., 2008, Generic Object Detection using AdaBoost
   WU B., 2004, Sixth IEEE International Conference on Automatic Face and Gesture Recognition (FG'04), P79
   Xu B, 2016, IEEE TMM 23, V23, P23
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Yang XS, 2015, IEEE T MULTIMEDIA, V17, P346, DOI 10.1109/TMM.2015.2393635
   Zhang TZ, 2012, IEEE T MULTIMEDIA, V14, P1206, DOI 10.1109/TMM.2012.2191944
   Ziyou Xiong, 2004, 2004 IEEE International Conference on Multimedia and Expo (ICME) (IEEE Cat. No.04TH8763), P1947, DOI 10.1109/ICME.2004.1394642
NR 54
TC 50
Z9 50
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26635
EP 26655
DI 10.1007/s11042-018-5882-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500019
DA 2024-07-18
ER

PT J
AU Shao, ZH
   Shang, YY
   Tong, QB
   Ding, H
   Zhao, XX
   Fu, XY
AF Shao, Zhuhong
   Shang, Yuanyuan
   Tong, Qingbin
   Ding, Hui
   Zhao, Xiaoxu
   Fu, Xiaoyan
TI Multiple color image encryption and authentication based on phase
   retrieval and partial decryption in quaternion gyrator domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image authentication; Phase retrieval; Quaternion gyrator transform;
   Multiple-image encryption; Partial decryption
ID FRACTIONAL FOURIER-TRANSFORM; INFORMATION AUTHENTICATION; SPARSE
   REPRESENTATION; ALGORITHM; SECURITY
AB In this paper, a multiple color image encryption and authentication scheme by using phase retrieval in quaternion gyrator domain and partial decryption is introduced. The quaternion representation is firstly employed to combine three color channels into a single-channel architecture. Then each color image is respectively encoded into a phase-only function according to quaternion gyrator transform based double phase encoding through phase retrieval technique. Subsequently, all phase-only functions are modulated to obtain the final ciphertext. To remain the content of secret images under cover, only a small part of the encrypted data that is selected by multiplying the random binary amplitude mask is preserved for decryption, where nonlinear quaternion correlation is developed to further perform authentication. Since the proposed encryption algorithm is asymmetric, such interest can significantly enhance security of the cryptosystem. The numerical simulations have demonstrated the feasibility and validity of the proposed scheme as well as its better performance compared with other schemes.
C1 [Shao, Zhuhong; Shang, Yuanyuan; Ding, Hui; Zhao, Xiaoxu; Fu, Xiaoyan] Capital Normal Univ, Coll Informat Engn, Beijing 100048, Peoples R China.
   [Shao, Zhuhong; Shang, Yuanyuan] Capital Normal Univ, Beijing Adv Innovat Ctr Imaging Technol, Beijing 100048, Peoples R China.
   [Shang, Yuanyuan] Capital Normal Univ, Beijing Engn Res Ctr High Reliable Embedded Syst, Beijing 100048, Peoples R China.
   [Tong, Qingbin] Beijing Jiaotong Univ, Sch Elect Engn, Beijing 100044, Peoples R China.
C3 Capital Normal University; Capital Normal University; Capital Normal
   University; Beijing Jiaotong University
RP Shang, YY (corresponding author), Capital Normal Univ, Coll Informat Engn, Beijing 100048, Peoples R China.; Shang, YY (corresponding author), Capital Normal Univ, Beijing Adv Innovat Ctr Imaging Technol, Beijing 100048, Peoples R China.; Shang, YY (corresponding author), Capital Normal Univ, Beijing Engn Res Ctr High Reliable Embedded Syst, Beijing 100048, Peoples R China.
EM cieshang@163.com
RI Shao, Zhuhong/AAD-4129-2022; Shang, Yuanyuan/ACH-0016-2022; Fu,
   Xiaoyan/C-2573-2012
OI Shang, Yuanyuan/0000-0003-4219-2541; 
FU National Natural Science Foundation of China [61601311, 51575140];
   Project of Beijing Excellent Talents [2016000020124G088]; Beijing
   Municipal Education Research Plan Project [SQKM201810028018]; Support
   Project of High-level Teachers in Beijing Municipal Universities in the
   Period of 13th Five-year Plan [CITTCD20170322]; Natural Science
   Foundation of Beijing [4162017]
FX This work was supported by the National Natural Science Foundation of
   China (61601311, 51575140), Project of Beijing Excellent Talents
   (2016000020124G088), Beijing Municipal Education Research Plan Project
   (SQKM201810028018), Support Project of High-level Teachers in Beijing
   Municipal Universities in the Period of 13th Five-year Plan
   (CIT&TCD20170322) and Natural Science Foundation of Beijing (4162017).
   The authors would like to appreciate the anonymous reviewers for their
   constructive comments and suggestions, which have greatly helped us in
   improving the quality of the paper.
CR Abuturab MR, 2012, APPL OPTICS, V51, P3006, DOI 10.1364/AO.51.003006
   Amaya D, 2008, J OPT A-PURE APPL OP, V10, DOI 10.1088/1464-4258/10/10/104031
   Amaya D, 2009, APPL OPTICS, V48, P2099, DOI 10.1364/AO.48.002099
   Bhatnagar G, 2013, INFORM SCIENCES, V223, P297, DOI 10.1016/j.ins.2012.09.053
   Chen H, 2013, OPT LASER ENG, V51, P768, DOI 10.1016/j.optlaseng.2013.01.016
   Chen JX, 2015, OPT LASER TECHNOL, V70, P50, DOI 10.1016/j.optlastec.2015.01.016
   Chen LF, 2006, OPT EXPRESS, V14, P8552, DOI 10.1364/OE.14.008552
   Chen W, 2013, IEEE PHOTONICS J, V5, DOI 10.1109/JPHOT.2013.2258144
   Gong Q, 2013, APPL OPTICS, V52, P7486, DOI 10.1364/AO.52.007486
   Guo CL, 2015, APPL OPTICS, V54, P4698, DOI 10.1364/AO.54.004698
   Guo C, 2017, OPT LASER ENG, V89, P2, DOI 10.1016/j.optlaseng.2016.03.021
   Hamilton W., 1866, ELEMENTS QUATERNIONS
   Joshi M, 2007, OPT COMMUN, V279, P35, DOI 10.1016/j.optcom.2007.07.012
   Joshi M, 2008, OPT COMMUN, V281, P5713, DOI 10.1016/j.optcom.2008.08.024
   Kang XJ, 2016, IEEE T SIGNAL PROCES, V64, P3402, DOI 10.1109/TSP.2016.2544740
   Liu S, 2014, OPT LASER TECHNOL, V57, P327, DOI 10.1016/j.optlastec.2013.05.023
   Liu ZJ, 2013, OPT LASER TECHNOL, V47, P152, DOI 10.1016/j.optlastec.2012.09.007
   Moon I, 2016, APPL OPTICS, V55, P4328, DOI 10.1364/AO.55.004328
   Mosso F, 2011, OPT EXPRESS, V19, P13779, DOI 10.1364/OE.19.013779
   Pei SC, 2001, IEEE T SIGNAL PROCES, V49, P2783, DOI 10.1109/78.960426
   Pérez-Cabré E, 2011, OPT LETT, V36, P22, DOI 10.1364/OL.36.000022
   Rajput SK, 2017, OPT COMMUN, V388, P38, DOI 10.1016/j.optcom.2016.11.002
   Rawat N, 2015, J OPTICS-UK, V17, DOI 10.1088/2040-8978/17/6/065704
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Sang J, 2016, PROC SPIE, V9845, DOI 10.1117/12.2223798
   Sang J, 2015, SENSORS-BASEL, V15, P19199, DOI 10.3390/s150819199
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shao ZH, 2015, OPT COMMUN, V343, P56, DOI 10.1016/j.optcom.2015.01.002
   Shao ZH, 2013, IEEE IMAGE PROC, P4579, DOI 10.1109/ICIP.2013.6738943
   Shao ZH, 2014, OPT EXPRESS, V22, P4932, DOI 10.1364/OE.22.004932
   Situ GH, 2005, OPT LETT, V30, P1306, DOI 10.1364/OL.30.001306
   Sui LS, 2014, OPT LASER ENG, V62, P139, DOI 10.1016/j.optlaseng.2014.06.003
   Sui LS, 2013, OPT LETT, V38, P1996, DOI 10.1364/OL.38.001996
   Tao R, 2007, OPT EXPRESS, V15, P16067, DOI 10.1364/OE.15.016067
   Unnikrishnan G, 2000, OPT LETT, V25, P887, DOI 10.1364/OL.25.000887
   Wang Q, 2014, OPT COMMUN, V320, P12, DOI 10.1016/j.optcom.2014.01.041
   Wang XG, 2015, IEEE PHOTONICS J, V7, DOI 10.1109/JPHOT.2015.2412936
   Wang XL, 2011, OPTIK, V122, P1856, DOI 10.1016/j.ijleo.2010.11.016
   Wang Y, 2016, J OPT SOC AM A, V33, P2158, DOI 10.1364/JOSAA.33.002158
   Yao LL, 2017, OPT LASER ENG, V89, P72, DOI 10.1016/j.optlaseng.2016.06.006
   Yuan L, 2017, OPT LASER TECHNOL, V88, P111, DOI 10.1016/j.optlastec.2016.09.004
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhong SL, 2017, OPT LASER ENG, V88, P214, DOI 10.1016/j.optlaseng.2016.08.015
   Zhou L, 2014, IEEE COMMUN MAG, V52, P66, DOI 10.1109/MCOM.2014.6766087
   Zhou L, 2011, IEEE J SEL AREA COMM, V29, P1358, DOI 10.1109/JSAC.2011.110803
   Zhou NR, 2011, OPT COMMUN, V284, P2789, DOI 10.1016/j.optcom.2011.02.066
NR 46
TC 13
Z9 14
U1 1
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25821
EP 25840
DI 10.1007/s11042-018-5818-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400051
DA 2024-07-18
ER

PT J
AU Almeida, P
   de Abreu, JF
   Oliveira, R
   Gomes, D
AF Almeida, Pedro
   de Abreu, Jorge Ferraz
   Oliveira, Rita
   Gomes, Diogo
TI A video engine supported by social buzz to automatically create TV
   summaries
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE TV summary; Highlights; Twitter activity; Evaluation
AB Viewers post a lot of TV program-related information on social networks while they are watching TV, especially during its key moments. Therefore, this social buzz has the potential to be used as an automatic editorial criterion. Having this premise in consideration, this paper reports on the nowUP solution, a service developed with the main goal of automatically creating TV summaries of popular television programs (like football matches, talent or reality shows) based on the Twitter activity and integrating a part of that activity in the TV show summary. A data-mining engine continuously processes the activity of this social network looking for tweets associated with the TV shows. Based on the program metadata it indexes the twitter activity; correlates tweets; and creates clusters of peaks, being the relevant clusters associated with the highlights of the TV show. With this, the video engine automatically creates a full video summary (an edited sequence of TV highlights) and publishes it in an online platform and on a Catch-up TV service. The paper reports on the nowUP development and on the results of its evaluation, namely comparing its outputs with official editorial/ professional video summaries. The results show that the solution was very successful in achieving the project main goal and users want to have access to this type of social buzz based video summaries. The nowUP solution also promises potential gains in the value chain of TV producers and broadcasters.
C1 [Almeida, Pedro; de Abreu, Jorge Ferraz; Oliveira, Rita] Univ Aveiro, Dept Commun & Art, Digimedia, Aveiro, Portugal.
   [Gomes, Diogo] Univ Aveiro, Dept Elect Telecommun & Informat, Inst Telecommun, Aveiro, Portugal.
C3 Universidade de Aveiro; Universidade de Aveiro; Instituto de
   Telecomunicacoes
RP Almeida, P (corresponding author), Univ Aveiro, Dept Commun & Art, Digimedia, Aveiro, Portugal.
EM almeida@ua.pt; jfa@ua.pt; ritaoliveira@ua.pt; dgomes@ua.pt
RI Gomes, Diogo/AAB-8850-2020; Abreu, Jorge/G-9141-2014; Almeida,
   Pedro/AAA-5104-2020; Oliveira, Rita/IWD-5185-2023; Almeida,
   Pedro/K-9055-2018; Almeida, Pedro/GVU-5277-2022; Oliveira,
   Rita/I-8394-2014; de Oliveira, Rita de Cássia Silva/IZQ-6191-2023;
   Gomes, Diogo/E-9376-2010
OI Gomes, Diogo/0000-0002-5848-2802; Abreu, Jorge/0000-0002-0492-2307;
   Almeida, Pedro/0000-0001-5878-3317; Almeida, Pedro/0000-0001-5878-3317;
   Almeida, Pedro/0000-0001-5878-3317; Oliveira, Rita/0000-0001-6041-9469;
   de Oliveira, Rita de Cássia Silva/0000-0003-3835-1183; Gomes,
   Diogo/0000-0002-5848-2802
CR Abel F, 2011, LECT NOTES COMPUT SC, V6644, P375, DOI 10.1007/978-3-642-21064-8_26
   Abreu J, 2017, TELECOMMUN SYST, V64, P57, DOI 10.1007/s11235-016-0157-3
   Abreu Jorge., 2013, PROCS 11 EUROPEAN C, P5, DOI DOI 10.1145/2465958.2465970
   Alonso O, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P1037
   Beuker I, 2012, VIRAL BLOG
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Capon G, 2014, GUARDIAN
   Cremonesi P., 2013, P 11 EUR C INT TV VI, P45, DOI DOI 10.1145/2465958.2465960
   Crisci A, 2018, MULTIMED TOOLS APPL, V77, P12203, DOI 10.1007/s11042-017-4880-x
   Doman K, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P949, DOI 10.1145/2647868.2654973
   Dumont É, 2012, INT J DIGIT MULTIMED, V2012, DOI 10.1155/2012/732514
   Flick U., 2009, An Introduction to Qualitative Research, V4th
   Forlines C, 2006, PROC SPIE, V6073, DOI 10.1117/12.648554
   Genc Y, 2011, LECT NOTES ARTIF INT, V6780, P484, DOI 10.1007/978-3-642-21852-1_55
   Jianguo Wang, 2011, Proceedings of the 2011 2nd International Conference on Control, Instrumentation, and Automation (ICCIA), P1, DOI 10.1109/ICCIAutom.2011.6183890
   Kantar Media, 2015, WHOS TWEET TV UK
   Kim HG, 2008, IEEE T CONSUM ELECTR, V54, P831, DOI 10.1109/TCE.2008.4560167
   Marlow S., 2002, P IR SIGN SYST C ISS, P25
   Nielsen Social, 2017, TV SEAS REV TOP SOC
   Nielsen Social, 2017, WHAT WE DO
   Otani M, 2017, MULTIMED TOOLS APPL, V76, P12097, DOI 10.1007/s11042-016-4061-3
   Outhwaite William., 2007, SAGE HDB SOCIAL SCI
   Ozdikis O, 2012, P INT C ADV SOC NETW, P20, DOI [10.1109/ASONAM.2012.14, DOI 10.1109/ASONAM.2012.14]
   Sgarbi E, 2005, LECT NOTES COMPUT SC, V3773, P691
   Tellyo, 2017, MED SHAR
   Ulanoff L., 2015, TWITTER EXPT TV TIME
   Viacom, 2013, NETW NETW TV GETS SO
   Vilaca A., 2015, P 14 C RED COMP EV P
   Vilaca A, 2015, P CONFTELE 2015 10 C
   WildMoka, 2014, MOM SHAR
   WildMoka, 2014, MOM CAPT
   WildMoka, 2014, MOM REPL
   Yang JC, 2009, EDUC TECHNOL SOC, V12, P49
   Yang J, 2018, MYCOL PROG, V17, P591, DOI 10.1007/s11557-017-1339-4
   Zhang J, 2017, MULTIMED TOOLS APPL, V76, P12005, DOI 10.1007/s11042-016-3936-7
NR 35
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24313
EP 24331
DI 10.1007/s11042-018-5723-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900054
DA 2024-07-18
ER

PT J
AU Chen, YH
   Yin, CY
   Lin, YJ
   Zuo, WL
AF Chen, Y. H.
   Yin, C. Y.
   Lin, Y. J.
   Zuo, W. L.
TI Multi-modal multi-layered topic classification model for social event
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-modal topic model; Event analysis; Image annotation; Nonparametric
   Bayesian statistics; Variational inference algorithm
ID ANNOTATION
AB In this paper, we pay attention to reveal the event topics and track the evolutionary trend of social event and a novel probabilistic topic model is proposed. The Multi-modal Multi-layered Topic Classification Model (tm_MMC) for Social Event Analysis has the capacity for revealing visual and non-visual topics, by jointly modeling the textual and visual information while simultaneously learning and predicting the multi-layered category labels. In order to track the evolutionary trends of the topics online, tm_MMC uses topic intensity and heritability to incrementally build an up-to-date model. To evaluate the effectiveness of our model, we experiment using a collected data, and compare the results with those of other traditional models. The results demonstrate the effectiveness and advantages of our model against several state-of-the-art methods.
C1 [Chen, Y. H.; Lin, Y. J.] Minnan Normal Univ, Coll Comp Sci, Zhangzhou 363000, Fujian, Peoples R China.
   [Chen, Y. H.; Lin, Y. J.] Fujian Prov Univ, Key Lab Data Sci & Intelligence Applicat, Zhangzhou, Peoples R China.
   [Yin, C. Y.] Minnan Normal Univ, Sch Journalism & Commun, Zhangzhou 363000, Fujian, Peoples R China.
   [Zuo, W. L.] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.
C3 MinNan Normal University; Fuzhou University; MinNan Normal University;
   Jilin University
RP Chen, YH (corresponding author), Minnan Normal Univ, Coll Comp Sci, Zhangzhou 363000, Fujian, Peoples R China.; Chen, YH (corresponding author), Fujian Prov Univ, Key Lab Data Sci & Intelligence Applicat, Zhangzhou, Peoples R China.
EM YH_chen@mnnu.edu.cn; chuny_yin@163.com; yjlin@mnnu.edu.cn;
   wanli@jlu.edu.cn
FU National Natural Science Foundation of China [61303131, 61672272,
   60973040]; Educational Reform Project of Fujian [FBJG20170055]
FX This work is supported by the National Natural Science Foundation of
   China No.61303131, No. 61672272, No. 60973040; Educational Reform
   Project of Fujian No.FBJG20170055.
CR Adams RP, 2010, THE ENERGY READER, P19
   Allan J., 2002, INTRO TOPIC DETECTIO
   [Anonymous], 2010, ARXIV PREPRINT ARXIV
   [Anonymous], 2010, TECH REP
   [Anonymous], 2013, P 6 ACM INT C WEB SE
   [Anonymous], 2008, P ADV NEURAL INFORM
   [Anonymous], UAI 2002
   [Anonymous], 2012, P 20 ACM INT C MULTI
   [Anonymous], 2008, P 1 ACM INT C MULTIM
   ANTONIAK CE, 1974, ANN STAT, V2, P1152, DOI 10.1214/aos/1176342871
   Bao Y, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P239, DOI 10.1145/2505515.2505556
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Becker H, 2009, EVENT IDENTIFICATION, P291
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPR.2009.5206800, 10.1109/CVPRW.2009.5206800]
   Diakopoulos N., 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P115, DOI 10.1109/VAST.2010.5652922
   Hatzivassiloglou V, 2000, INVESTIGATION LINGUI, P224
   Hoffman M., 2010, P ADV NEUR INF PROC, V23:856-864
   Kim Joon Hee, 2012, P 21 ACM INT C INF K, P783
   Kliegr T, 2008, INT WORKSH MULT DAT, V29, P10
   Li C., 2012, Cikm, P155, DOI DOI 10.1145/2396761.2396785
   Li LJ, 2009, PROC CVPR IEEE, P2036, DOI 10.1109/CVPRW.2009.5206718
   Lin YR, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2071396.2071400
   Liu XC, 2013, PROCEEDINGS OF THE 1ST INTERNATIONAL JOINT SYMPOSIUM ON JOINING AND WELDING, P151
   Makkonen J, 2004, INFORM RETRIEVAL, V7, P347, DOI 10.1023/B:INRT.0000011210.12953.86
   McMinn AJ, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P409, DOI 10.1145/2505515.2505695
   Nguyen C, 2013, P 23 INT JOINT C ART, P1558
   Niu ZX, 2011, PROC CVPR IEEE, P1769, DOI 10.1109/CVPR.2011.5995426
   Patel D., 2008, P 2008 ACM SIGMOD IN, P393, DOI DOI 10.1145/1376616.1376658
   Pham T., 2007, Proc. ACM International Conference on Information and Knowledge Management, P439
   Putthividhya D, 2010, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2010.5540000
   Qian S., 2014, MULTIMODAL SUPERVISE, P152
   Ramage Daniel., 2009, EMNLP, DOI DOI 10.3115/1699510.1699543
   Reuter T., 2012, PROC ANN ACM INT C M, P22
   Suhara Y, 2008, PROCEEDINGS OF THE I, P225
   Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302
   Wang G, 2009, PROC CVPR IEEE, P1367, DOI 10.1109/CVPRW.2009.5206816
   Wang Xuerui., P 12 ACM SIGKDD INT, P424
   Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1762, DOI 10.1109/TPAMI.2009.43
   Yang XS, 2015, IEEE T MULTIMEDIA, V17, P346, DOI 10.1109/TMM.2015.2393635
   Zhang Kuo, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P215, DOI 10.1145/1277741.1277780
   Zhang T, 2014, ACM T MULTIMEDIA COM, V10, P1
   Zhang TZ, 2013, IEEE I CONF COMP VIS, P281, DOI 10.1109/ICCV.2013.42
   Zhang TZ, 2012, IEEE T MULTIMEDIA, V14, P1206, DOI 10.1109/TMM.2012.2191944
   Zhuang Y., 2012, P 20 ACM INT C MULT, P957
NR 46
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23291
EP 23315
DI 10.1007/s11042-017-5588-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900010
DA 2024-07-18
ER

PT J
AU Ming, Y
   Shi, JK
AF Ming, Yue
   Shi, Jiakun
TI Mesh motion scale invariant feature and collaborative learning for
   visual recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual recognition; Mesh motion scale invariant feature description;
   Hierarchical collaborative feature learning
ID FACE-RECOGNITION; DESCRIPTOR
AB Visual recognition has been gradually played important roles in many fields. An effective feature descriptor, with higher discrimination and higher descriptiveness for the different visual recognition tasks, is a challenging issue. In this paper, we propose a novel feature, called mesh motion scale invariant feature description, to facilitate the different visual task description and balance discrimination and efficiency. Then, a hierarchical collaborative feature learning model for multi-visual tasks in complex scenes is presented for obtaining the recognition results. Four large databases, FRGC, CASIA, BU-3DFE and 3D Online Action, are introduced to the performance comparison and the experimental results show a better performance for face recognition, expression recognition and activity recognition based on our proposed method.
C1 [Ming, Yue] Beijing Univ Posts & Telecommun, Sch Elect Engn, Beijing Key Lab Work Safety Intelligent Monitorin, Beijing 100876, Peoples R China.
   [Shi, Jiakun] Beijing Univ Posts & Telecommun, Sch Elect Engn, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Beijing University of
   Posts & Telecommunications
RP Ming, Y (corresponding author), Beijing Univ Posts & Telecommun, Sch Elect Engn, Beijing Key Lab Work Safety Intelligent Monitorin, Beijing 100876, Peoples R China.
EM myname35875235@126.com
FU National Natural Science Foundation of China [NSFC-61402046]; Fund for
   the Doctoral Program of Higher Education of China [20120005110002];
   National Great Science Specific Project [2011ZX0300200301,
   2012ZX03005008]; Beijing Municipal Commission of Education Build
   Together Project
FX The work presented in this paper was supported by the National Natural
   Science Foundation of China (Grants No. NSFC-61402046), Fund for the
   Doctoral Program of Higher Education of China (Grants No.
   20120005110002), National Great Science Specific Project (Grants No.
   2011ZX0300200301, 2012ZX03005008) and Beijing Municipal Commission of
   Education Build Together Project.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Andrew G., 2013, ICML, P1247
   [Anonymous], 2005, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2005.268
   [Anonymous], P 4 INT S 3D DAT PRO
   [Anonymous], 2012, Representation learning: A review and new perspectives
   [Anonymous], ARXIV12114246
   [Anonymous], 2009, Technical report
   [Anonymous], 2010, ARXIV10103467
   [Anonymous], 2014, Asian Conference on Computer Vision
   [Anonymous], BRIT MACH VIS C
   Batrinca L, 2016, IEEE T MULTIMEDIA, V18, P659, DOI 10.1109/TMM.2016.2522763
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bellotto N, 2012, COMPUT VIS IMAGE UND, V116, P457, DOI 10.1016/j.cviu.2011.09.011
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Cheung W, 2009, IEEE T IMAGE PROCESS, V18, P2012, DOI 10.1109/TIP.2009.2024578
   Chiu LC, 2013, IEEE T IMAGE PROCESS, V22, P3158, DOI 10.1109/TIP.2013.2259841
   Dardas NH, 2011, IEEE T INSTRUM MEAS, V60, P3592, DOI 10.1109/TIM.2011.2161140
   Darom T, 2012, IEEE T IMAGE PROCESS, V21, P2758, DOI 10.1109/TIP.2012.2183142
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Evangelopoulos G, 2013, IEEE T MULTIMEDIA, V15, P1553, DOI 10.1109/TMM.2013.2267205
   Gao Z, 2017, J VIS COMMUN IMAGE R, V48, P442, DOI 10.1016/j.jvcir.2017.03.014
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gao Z, 2014, MULTIMED TOOLS APPL, V68, P641, DOI 10.1007/s11042-012-1071-7
   Goodfellow I.J., 2012, ICML
   Huang D, 2012, IEEE T INF FOREN SEC, V7, P1551, DOI 10.1109/TIFS.2012.2206807
   Huang LH, 2017, IEEE T IMAGE PROCESS, V26, P5800, DOI 10.1109/TIP.2017.2745204
   Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017
   Kim D, 2009, IEEE T VLSI SYST, V17, P370, DOI 10.1109/TVLSI.2008.2011226
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Li XL, 2012, NEUROCOMPUTING, V82, P99, DOI 10.1016/j.neucom.2011.10.029
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Lo TWR, 2009, COMPUT VIS IMAGE UND, V113, P1235, DOI 10.1016/j.cviu.2009.06.005
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Maugey T, 2013, IEEE T MULTIMEDIA, V15, P1070, DOI 10.1109/TMM.2013.2246147
   Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105
   Ming Y, 2015, IMAGE VISION COMPUT, V35, P14, DOI 10.1016/j.imavis.2014.12.003
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Osada K, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P245, DOI 10.1109/SMI.2008.4547989
   Panagakis Y, 2016, IEEE T PATTERN ANAL, V38, P1665, DOI 10.1109/TPAMI.2015.2497700
   Peng Yuxin, 2016, IJCAI, P3846
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Song XH, 2017, IEEE T IMAGE PROCESS, V26, P2721, DOI 10.1109/TIP.2017.2686017
   Srivastava N., 2012, ADV NEURAL INFORM PR, P2222, DOI DOI 10.1109/CVPR.2013.49
   Tariq U, 2012 IEEE COMP SOC C, P146
   Wan J, 2013, J MACH LEARN RES, V14, P2549
   Wu K, THESIS
   Yang Y, 2015, INT J COMPUT VISION, V113, P113, DOI 10.1007/s11263-014-0781-x
   Yue Ming, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P344, DOI 10.1109/ICME.2012.8
   Zhang BC, 2017, IEEE T IMAGE PROCESS, V26, P4648, DOI 10.1109/TIP.2017.2718189
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
   Zhang HW, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P187, DOI 10.1145/2647868.2654915
   Zhang Q., 2008, Microwave conference, P1, DOI [10.1109/IPDPS.2008.4536131, DOI 10.1109/IPDPS.2008.4536131]
NR 55
TC 1
Z9 1
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22367
EP 22384
DI 10.1007/s11042-018-5969-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500034
DA 2024-07-18
ER

PT J
AU Vikhe, PS
   Thool, VR
AF Vikhe, P. S.
   Thool, V. R.
TI Morphological operation and scaled Reyni entropy based approach for
   masses detection in mammograms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scaled reyni entropy; Mass detection; Morphological operations;
   Enhancement and segmentation
ID PECTORAL MUSCLE; SEGMENTATION; IDENTIFICATION; CLASSIFICATION;
   ENHANCEMENT; TEXTURE
AB Detection of suspicious masses in mammograms play a vital role in early diagnosis of breast cancer, to reduce the death rate among women. The presence of masses and calcification's in mammograms is distinguishing signs for breast cancer diagnosis. But in some cases, due to contrast variation, fuzzy boundaries and presence of noise in mammograms, segmentation and detection of masses is challenging assignment. This paper presents a new segmentation approach to detect masses in mammographic images. The proposed approach consist of artifacts elimination and pectoral region extraction, suspicious mass enhancement using dual morphological operation technique and finally, extraction of Regions of Interest (ROIs) from background using scaled Reyni entropy. The proposed system has been tested on two data-sets i.e. mini- Mammographic Image Analysis Society (mini-MIAS) and Digital Database for Screening Mammography (DDSM), over 50 and 90 mammograms respectively. Performance achieved with proposed system in terms of True Positive Fraction (TPF) yields 93.2% and 93.9% respectively, at the rate of 1.48 and 0.74 average False Positive per Image (FP/I), tested on both Cranio-Caudal (CC) and Medio-Lateral Oblique (MLO) views. The obtained experimental results demonstrates that proposed method gives improved results for mass detection and can be useful for radiologists in diagnosis of breast cancer at early stage.
C1 [Vikhe, P. S.] Pravara Rural Engn Coll, Loni, Maharashtra, India.
   [Thool, V. R.] SGGSIE&T, Nanded, India.
C3 Shri Guru Gobind Singhji Institute of Engineering & Technology
RP Vikhe, PS (corresponding author), Pravara Rural Engn Coll, Loni, Maharashtra, India.
EM pratapvikhe@gmail.com; vrthool@yahoo.com
RI Vikhe, Pratap/ABZ-0664-2022; THOOL, VIJAYA/ABH-2175-2020; Vikhe,
   Pratap/AAQ-4833-2021
OI Vikhe, Pratap/0000-0002-3771-0386; 
CR Abo-Eleneen Z. A., 2013, J EGYPTIAN MATH SOC, V21, P162
   Alfred R, 1961, 4 BERK S REN, P547
   Anitha J, 2017, COMPUT METH PROG BIO, V138, P93, DOI 10.1016/j.cmpb.2016.10.026
   [Anonymous], 1982, IMAGE ANAL MATH MORP
   [Anonymous], 1989, DIGITAL IMAGE PROCES
   [Anonymous], 1994, Measures of information and their applications
   Berber T, 2013, COMPUT METH PROG BIO, V110, P150, DOI 10.1016/j.cmpb.2012.11.003
   Cao AZ, 2008, COMPUT VIS IMAGE UND, V109, P86, DOI 10.1016/j.cviu.2007.07.004
   Cheng HD, 2003, PATTERN RECOGN, V36, P2967, DOI 10.1016/S0031-3203(03)00192-4
   Choi JY, 2015, BIOMED ENG LETT, V5, P251, DOI 10.1007/s13534-015-0191-1
   Eltonsy NH, 2007, IEEE T MED IMAGING, V26, P880, DOI 10.1109/TMI.2007.895460
   Ganesan Karthikeyan, 2013, IEEE Rev Biomed Eng, V6, P77, DOI 10.1109/RBME.2012.2232289
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Gupta B, 2017, MULTIDIM SYST SIGN P, V28, P1549, DOI 10.1007/s11045-016-0432-1
   Hsu WY, 2012, EXPERT SYST APPL, V39, P3950, DOI 10.1016/j.eswa.2011.08.148
   Hu K, 2011, IEEE T INSTRUM MEAS, V60, P462, DOI 10.1109/TIM.2010.2051060
   Kashyap KL, 2018, MULTIMED TOOLS APPL, V77, P9249, DOI 10.1007/s11042-017-4751-5
   Khehra BS, 2011, P WORLD C ENG, V2, P2011
   Khuwaja GA, 2004, PATTERN ANAL APPL, V7, P235, DOI 10.1007/s10044-004-0220-7
   Kobatake H, 1999, IEEE T MED IMAGING, V18, P369, DOI 10.1109/42.774164
   Kom G, 2007, COMPUT BIOL MED, V37, P37, DOI 10.1016/j.compbiomed.2005.12.004
   Kurt B, 2014, COMPUT METH PROG BIO, V114, P349, DOI 10.1016/j.cmpb.2014.02.014
   Li XZ, 2014, PATTERN RECOGN LETT, V36, P117, DOI 10.1016/j.patrec.2013.10.001
   Li YF, 2015, COMPUT BIOL MED, V57, P84, DOI 10.1016/j.compbiomed.2014.12.007
   Ma F, 2007, PATTERN RECOGN, V40, P2592, DOI 10.1016/j.patcog.2006.12.011
   Mehdi MZ, 2016, MULTIMED TOOLS APPL, P1
   Mencattini A, 2008, IEEE T INSTRUM MEAS, V57, P1422, DOI 10.1109/TIM.2007.915470
   Mohanalin, 2010, SIGNAL PROCESS, V90, P952, DOI 10.1016/j.sigpro.2009.09.012
   Neto OPS, 2017, MULTIMED TOOLS APPL, V76, P19263, DOI 10.1007/s11042-017-4710-1
   Oliver A, 2010, MED IMAGE ANAL, V14, P87, DOI 10.1016/j.media.2009.12.005
   Pereira DC, 2014, COMPUT METH PROG BIO, V114, DOI 10.1016/j.cmpb.2014.01.014
   Pharwaha A. P. S., 2009, P WORLD C ENG COMP S, V2, P20
   Smolikova R, 2002, ENG MED BIOL 2002 24, V2
   Soille P., 2013, MORPHOLOGICAL IMAGE
   Tai SC, 2014, IEEE J BIOMED HEALTH, V18, P618, DOI 10.1109/JBHI.2013.2279097
   Tang JS, 2009, IEEE T INF TECHNOL B, V13, P236, DOI 10.1109/TITB.2008.2009441
   Vikhe PS, 2016, 2016 INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (ICONSIP)
   Vikhe PS, 2016, PROCEDIA COMPUT SCI, V79, P262, DOI 10.1016/j.procs.2016.03.034
   Vikhe PS, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0435-3
   Wang ST, 2005, PATTERN RECOGN LETT, V26, P2309, DOI 10.1016/j.patrec.2005.03.027
   Xu SZ, 2011, J DIGIT IMAGING, V24, P754, DOI 10.1007/s10278-011-9365-2
NR 41
TC 8
Z9 8
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23777
EP 23802
DI 10.1007/s11042-018-5681-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900031
DA 2024-07-18
ER

PT J
AU Wang, S
   Shen, XK
   Zhang, Y
AF Wang, Shan
   Shen, Xukun
   Zhang, Yan
TI 3D facial feature and expression computing from Internet image or video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D understanding of multimedia data; Image/video based 3D face
   acquisition; 2D & 3D facial feature computing
ID GEOMETRY; CAPTURE
AB Large-scale multimedia datasets such as the Internet image and video collections provide new opportunities to understand and analyze human actions, among which one of the most interesting type is facial performance. In this paper, we present an automatic reconstruction system of detailed face performances. Many existing facial performance reconstruction systems rely on data captured under controlled environments with densely spaced cameras and lights. On the contrary, our system reconstructs detailed facial geometry from just one image or a monocular video sequence with unknown lighting. To achieve this, we first simultaneously track 2D and 3D sparse features, then reconstruct the low frequency facial geometry by performing a 2D-3D feature trajectory fusion optimization, which we formulate as a linear problem that can be solved efficiently. Finally, we use a per-pixel shape-from-shading algorithm to estimate the fine-scale geometry details such as wrinkles to further improve the reconstruction fidelity. We demonstrate the accuracy of our system with reconstruction results using both single images and monocular video sequences.
C1 [Wang, Shan; Shen, Xukun; Zhang, Yan] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
   [Wang, Shan; Shen, Xukun] Beihang Univ, Sch New Media Art & Design, Beijing, Peoples R China.
C3 Beihang University; Beihang University
RP Wang, S (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.; Wang, S (corresponding author), Beihang Univ, Sch New Media Art & Design, Beijing, Peoples R China.
EM wangshan@buaa.edu.cn
FU National Key R&D Program of China [2017YFB1002702]
FX This work is supported by National Key R&D Program of China
   (2017YFB1002702).
CR Aldrian O, 2013, IEEE T PATTERN ANAL, V35, P1080, DOI 10.1109/TPAMI.2012.206
   [Anonymous], 2016, P 11 INT JOINT C COM
   [Anonymous], 2011, ACM transactions on graphics (TOG), DOI DOI 10.1145/1964921.1964972
   [Anonymous], MULTIPLE VIEW GEOMET
   Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153
   Beeler T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778777
   Bickel B, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239484
   Bouaziz S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461976
   Bradley D, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778778
   Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941
   Cao C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766943
   Cao C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601204
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Dai YC, 2012, PROC CVPR IEEE, P2018, DOI 10.1109/CVPR.2012.6247905
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gao Z, 2014, MULTIMED TOOLS APPL, V68, P641, DOI 10.1007/s11042-012-1071-7
   Garrido P, 2015, COMPUT GRAPH FORUM, V34, P193, DOI 10.1111/cgf.12552
   Garrido P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2890493
   Garrido P, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508380
   Guenin BM, 1998, P IEEE SEMICOND THER, P55, DOI 10.1109/STHERM.1998.660387
   He XN, 2017, IEEE T KNOWL DATA EN, V29, P57, DOI 10.1109/TKDE.2016.2611584
   Huang H, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024189
   Li H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618521
   Li H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462019
   Ma WC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409074
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Shi FH, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661290
   Suwajanakorn S, 2014, LECT NOTES COMPUT SC, V8692, P796, DOI 10.1007/978-3-319-10593-2_52
   Tian F, 2019, MULTIMED TOOLS APPL, V78, P437, DOI 10.1007/s11042-017-5068-0
   Tian F, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING AND COMMUNICATIONS (BIGCOM), P1, DOI 10.1109/BIGCOM.2017.9
   Valgaerts L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366206
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P572, DOI 10.1109/TMM.2012.2234731
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Zhang HW, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P781, DOI 10.1145/2964284.2964308
   Zhang HW, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P187, DOI 10.1145/2647868.2654915
   Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759
NR 36
TC 0
Z9 0
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22231
EP 22246
DI 10.1007/s11042-018-5895-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500027
DA 2024-07-18
ER

PT J
AU Zhao, G
   Qin, SY
   Wang, DY
AF Zhao, Guo
   Qin, Shiyin
   Wang, Danyang
TI Interactive segmentation of texture image based on active contour model
   with local inverse difference moment feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gray level co-occurrence matrix; Active contour model; Texture image
   segmentation; Local inverse difference moment
ID GRAY-SCALE; CLASSIFICATION; REGION; MINIMIZATION; ALGORITHMS
AB Texture image segmentation is a challenging problem in image processing field due to wide variability of characterizing textures and a lack of proper contour information. In this paper, an effective presentation is found with which different textures can be represented with some corresponding distributions generated by feature values of local inverse difference moment (LIDM). By the analysis of local statistical information in gray level co-occurrence matrix (GLCM), we found that similar textures can be characterized with similar distributions. In this way, an interactive segmentation method is presented to achieve the segmentation of texture image based on GLCM with an optimizing model. Our scheme can be narrated separately as follows, firstly, a proper Gaussian kernel is selected to discriminate two classes of textures by analyzing LIDM feature distributions, which are obtained from two different local regions marked manually in the initial texture image. Secondly, the LIDM feature map can be constructed by computing LIDM feature values of image patches with the proper Gaussian kernel, and the center of these image patches may traverse the whole image domain. Finally, the texture image segmentation is implemented based on an improved optimizing model with local binary fitting and local extremum regularizing. In order to validate the performance of our proposed method, two kinds of experiments about discriminative feature map construction and texture image segmentation are carried out to demonstrate its well performance, and more experiments on real texture images are also conducted.
C1 [Zhao, Guo; Qin, Shiyin; Wang, Danyang] Beihang Univ, Sch Automat Sci & Elect Engn, 37 Xueyuan Rd, Beijing 100191, Peoples R China.
C3 Beihang University
RP Zhao, G (corresponding author), Beihang Univ, Sch Automat Sci & Elect Engn, 37 Xueyuan Rd, Beijing 100191, Peoples R China.
EM zhaoguo.cn@gmail.com; qsy@buaa.edu.cn; danyaw2@uci.edu
RI zhao, guo/JCO-6971-2023; qin, shi/JNY-1785-2023
OI zhao, guo/0000-0002-3205-376X; 
FU National Nature Science Foundation of China [61731001, U1435220];
   Beijing Science and Technology Project of China
   [D16110400130000-D161100001316001]
FX This work was supported in part by National Nature Science Foundation of
   China (Grant Nos. 61731001 and U1435220), the Beijing Science and
   Technology Project of China (Grant No.
   D16110400130000-D161100001316001).
CR Ahonen T, 2009, PATTERN RECOGN LETT, V30, P368, DOI 10.1016/j.patrec.2008.10.012
   Ali S, 2012, IEEE T MED IMAGING, V31, P1448, DOI 10.1109/TMI.2012.2190089
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], 2017, MULTIMEDIA TOOLS APP
   Chan TE, 2000, J VIS COMMUN IMAGE R, V11, P130, DOI 10.1006/jvci.1999.0442
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286
   Clausi DA, 2005, IEEE T IMAGE PROCESS, V14, P925, DOI 10.1109/TIP.2005.849319
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   de Siqueira FR, 2013, NEUROCOMPUTING, V120, P336, DOI 10.1016/j.neucom.2012.09.042
   HARALICK RM, 1973, IEEE T GEOSCI REMOTE, VGE11, P171, DOI 10.1109/TGE.1973.294312
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Li C., 2007, IEEE C COMPUTER VISI, P1
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2005, PROC CVPR IEEE, P430
   Lianantonakis M, 2007, IEEE J OCEANIC ENG, V32, P744, DOI 10.1109/JOE.2007.893683
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Liu L, 2017, MULTIMED TOOLS APPL, V76, P10149, DOI 10.1007/s11042-016-3603-z
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu JG, 2017, MULTIMED TOOLS APPL, V76, P10991, DOI 10.1007/s11042-016-3462-7
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T, 2000, LECT NOTES COMPUT SC, V1842, P404
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068
   RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153
   Samson C, 2000, IEEE T PATTERN ANAL, V22, P460, DOI 10.1109/34.857003
   Wang T, 2017, WOODHEAD PUBL SER EN, P1, DOI 10.1016/B978-0-08-100167-7.00001-9
   Wu QG, 2015, NEUROCOMPUTING, V151, P1133, DOI 10.1016/j.neucom.2014.04.085
   Wu QG, 2012, IEEE J-STARS, V5, P1509, DOI 10.1109/JSTARS.2012.2197672
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
   Zhao ZQ, 2004, PATTERN RECOGN LETT, V25, P1351, DOI 10.1016/j.patrec.2004.05.008
   Zhu LF, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366146
NR 35
TC 6
Z9 6
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24537
EP 24564
DI 10.1007/s11042-018-5777-z
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900065
DA 2024-07-18
ER

PT J
AU Seema, A
   Shah, T
   Schwoebel, L
   Liu, Y
   Reisslein, M
AF Seema, Adolph
   Shah, Tejas
   Schwoebel, Lukas
   Liu, Yu
   Reisslein, Martin
TI Power profiling of multimedia sensor node with name-based segment
   streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic adaptive HTTP streaming (DASH); HTTP live streaming (HLS); Power
   measurement; Video streaming; Wireless video sensor
ID WIRELESS SENSOR; ENERGY-EFFICIENCY; NETWORKS; SURVEILLANCE;
   TRANSMISSION; CONSUMPTION; ADAPTATION; PROTOCOL; COST
AB Multimedia streaming from miniaturized sensors is attractive for a wide range of web-based applications, including surveillance and Internet of Things (IoT) applications. This paper profiles the power consumption in a wireless video sensor node. We compare the power consumption of video streaming frameworks based on a manifest file, such as the Hypertext Transfer Protocol (HTTP) Live Streaming (HLS), with a Wireless Video Sensor Network Platform compatible Dynamic Adaptive Streaming over HTTP (WVSNP-DASH) framework. The WVSNP-DASH framework is based on independently playable video segments that convey the metadata required for playback in their names (and do not require a manifest file). The power consumption components of the video capture and storage pipeline are evaluated. The presented extensive power profiling measurements provide real-world empirical data on architectural design decisions for multimedia sensor nodes suitable for IoT applications. Our measurement results indicate that the name-based WVSNP-DASH framework is well suited for flexible low-power web-based video streaming from miniaturized sensors.
C1 [Seema, Adolph; Shah, Tejas; Reisslein, Martin] Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85287 USA.
   [Schwoebel, Lukas] Favendo GmbH, Gena, Germany.
   [Liu, Yu] Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing, Peoples R China.
C3 Arizona State University; Arizona State University-Tempe; Beijing
   University of Posts & Telecommunications
RP Reisslein, M (corresponding author), Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85287 USA.
EM adolphseema@asu.edu; tpshah1@asu.edu; lukeschwoebel@gmail.com;
   yliu581@asu.edu; reisslein@asu.edu
RI Reisslein, Martin/B-3278-2014; Chen, Qi/GVU-3024-2022
OI Reisslein, Martin/0000-0003-1606-233X; Chen, Qi/0000-0002-6568-7267
FU China Scholarship Council
FX Parts of this work were conducted while Y. Liu visited Arizona State
   University, Tempe, sponsored by the China Scholarship Council.
CR Abas K, 2014, COMPUTER, V47, P37, DOI 10.1109/MC.2014.140
   Accardi K, 2017, POWERTOP USERS GUIDE
   Adzic V, 2012, IEEE T CONSUM ELECTR, V58, P397, DOI 10.1109/TCE.2012.6227439
   Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   Anisi MH, 2015, PRECIS AGRIC, V16, P216, DOI 10.1007/s11119-014-9371-8
   [Anonymous], 2020, PROD
   [Anonymous], 2017, GStreamer: Open source multimedia framework
   [Anonymous], 2014, IEEE 11 INT MULTICON, DOI DOI 10.1109/SSD.2014.6808887
   [Anonymous], 2016, PROBABILITY STAT ENG
   [Anonymous], 2016, 2016 21 S SIGNAL PRO
   Apple Inc, 2012, TECHNICAL REPORT
   Bicakci K, 2009, IEEE COMMUN LETT, V13, P905, DOI 10.1109/LCOMM.2009.12.091331
   Bourdon A., 2012, PowerAPI: A software library to monitor the energy consumed at the process-level
   Braeckman G, 2015, P ACM INT C DISTR SM, P170
   SanMiguel JC, 2017, IEEE T CIRC SYST VID, V27, P2661, DOI 10.1109/TCSVT.2016.2593598
   Carrano RC, 2014, IEEE COMMUN SURV TUT, V16, P181, DOI 10.1109/SURV.2013.052213.00116
   Castellanos WE, 2017, MULTIMED TOOLS APPL, V76, P437, DOI 10.1007/s11042-015-3046-y
   Chan KM, 2016, MULTIMED TOOLS APPL, V75, P5917, DOI 10.1007/s11042-015-2556-y
   Chang HK, 2018, CONF TECHNOL APPL, P1, DOI 10.1109/TAAI.2018.00010
   Chen SY, 2016, IEEE T BROADCAST, V62, P55, DOI 10.1109/TBC.2015.2472986
   Chien SY, 2013, IEEE J EM SEL TOP C, V3, P55, DOI 10.1109/JETCAS.2013.2242771
   Cotuk H, 2014, IEEE WCNC, P2787, DOI 10.1109/WCNC.2014.6952870
   Cotuk H, 2014, IEEE T COMPUT, V63, P2866, DOI 10.1109/TC.2013.151
   Engineering Services, 2017, WANDC AES WCAM ADPT
   Feldt R, 2010, 22ND INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING & KNOWLEDGE ENGINEERING (SEKE 2010), P374
   Gayan, 2012, POWERSTAT POWER CONS
   Ghadi M, 2016, MULTIMED TOOLS APPL, V75, P3425, DOI 10.1007/s11042-014-2443-y
   Ghasemzadeh H, 2014, IEEE T HUM-MACH SYST, V44, P537, DOI 10.1109/THMS.2014.2320277
   Go Y, 2015, IEEE T MULTIMEDIA, V17, P1646, DOI 10.1109/TMM.2015.2451951
   Guerrero-Zapata M, 2010, TELECOMMUN SYST, V45, P77, DOI 10.1007/s11235-009-9235-0
   Haas Christian, 2012, Wireless Sensor Networks. Proceedings 9th European Conference, EWSN 2012, P82, DOI 10.1007/978-3-642-28169-3_6
   Haas C, 2013, INT CONF PERVAS COMP, P560
   Hamid Z, 2016, MULTIMED TOOLS APPL, V75, P8195, DOI 10.1007/s11042-015-2737-8
   HEITMANN N, 2016, IEEE INT S VLSI DES, P1
   Hergenroeder A., 2010, ARCHITECTURE COMPUTI, P1
   Hergenröder A, 2012, IEEE ICC, P6268, DOI 10.1109/ICC.2012.6364942
   Heydari N, 2017, INT J COMPUT SCI NET, V17, P98
   Horneber J, 2014, IEEE COMMUN SURV TUT, V16, P1820, DOI 10.1109/COMST.2014.2320051
   Huang SC, 2017, MULTIMED TOOLS APPL, V76, P19463, DOI 10.1007/s11042-015-3175-3
   JAVAID S, 2018, MULTIMED TOOLS APPL, P1
   Jiang XF, 2007, PROCEEDINGS OF THE SIXTH INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING IN SENSOR NETWORKS, P186, DOI 10.1109/IPSN.2007.4379678
   Karakus C, 2013, IEEE SENS J, V13, P1999, DOI 10.1109/JSEN.2013.2244036
   Kidwai NR, 2016, IEEE SENS J, V16, P2575, DOI 10.1109/JSEN.2016.2519600
   Kim Y, 2017, MULTIMED TOOLS APPL, V76, P17193, DOI 10.1007/s11042-016-3794-3
   Ko JH, 2015, IEEE T MULTI-SCALE C, V1, P7, DOI 10.1109/TMSCS.2015.2478469
   Kua J, 2017, IEEE COMMUN SURV TUT, V19, P1842, DOI 10.1109/COMST.2017.2685630
   Lee JY, 2017, MULTIMED TOOLS APPL, V76, P19843, DOI 10.1007/s11042-016-3732-4
   Lenk J., 1997, Simplified Design of Voltage/Frequency Converters, EDN Series for Design Engineers
   Li YT, 2017, MULTIMED TOOLS APPL, V76, P20781, DOI 10.1007/s11042-016-4002-1
   Liu B, 2008, MULTIMED TOOLS APPL, V38, P209, DOI 10.1007/s11042-007-0177-9
   Liu Chun., 2018, Modeling Human Diseases with Induced Pluripotent Stem Cells: From 2D to 3D and Beyond, P1, DOI [DOI 10.1242/DEV.156166, DOI 10.1080/10910344.2017.1402933]
   Magno M, 2014, IEEE T IND INFORM, V10, P946, DOI 10.1109/TII.2013.2295198
   Margi C.B., 2006, Proc. Int. Conf. on Testbeds Research Infrastr. for the DEvelopm. of NeTworks COMmunities (TRIDENTCOM), P1
   Mekonnen T, 2016, 15TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2016), P373, DOI 10.1145/3012709.3017604
   Milenkovic A, 2005, SE SYM SYS THRY, P406, DOI 10.1109/SSST.2005.1460946
   Misra S, 2010, MULTIMED TOOLS APPL, V47, P121, DOI 10.1007/s11042-009-0410-9
   Mooshimeter M., 2016, DMM-BLE-2x01A Mooshimeter Technical Specifications
   Naderiparizi S, 2016, IEEE INT CONF RFID, P123
   Noureddine A., 2012, 2012 First International Workshop on Green and Sustainable Software (GREENS), P21, DOI 10.1109/GREENS.2012.6224251
   Noureddine A, 2012, IEEE INT CONF AUTOM, P160, DOI 10.1145/2351676.2351699
   Pantazis NA, 2007, IEEE COMMUN SURV TUT, V9, P86, DOI 10.1109/COMST.2007.4444752
   Pantazis NA, 2013, IEEE COMMUN SURV TUT, V15, P551, DOI 10.1109/SURV.2012.062612.00084
   Popovici E, 2013, 2013 5TH IEEE INTERNATIONAL WORKSHOP ON ADVANCES IN SENSORS AND INTERFACES (IWASI), P194, DOI 10.1109/IWASI.2013.6576090
   Porambage P., 2016, Proceedings of the 22nd European Wireless Conference, Oulu, 18-20 May 2016, P1
   Rainer B, 2017, IEEE T MULTIMEDIA, V19, P849, DOI 10.1109/TMM.2016.2629761
   Ramakrishna M, 2017, MULTIMED TOOLS APPL, V76, P21171, DOI 10.1007/s11042-016-4017-7
   Rashid B, 2016, J NETW COMPUT APPL, V60, P192, DOI 10.1016/j.jnca.2015.09.008
   Rault T, 2014, COMPUT NETW, V67, P104, DOI 10.1016/j.comnet.2014.03.027
   Redondi A, 2014, IEEE T CIRC SYST VID, V24, P2117, DOI 10.1109/TCSVT.2014.2329378
   Rein S, 2011, IEEE COMMUN SURV TUT, V13, P291, DOI 10.1109/SURV.2011.100110.00059
   Runeson P, 2009, EMPIR SOFTW ENG, V14, P131, DOI 10.1007/s10664-008-9102-8
   Saginbekov S., 2016, ARXIV160201567
   Sarif BA, 2014, P INT C DIG SOC ICDS, P1
   Sarif BA, 2015, P WORLD C INF TECHN, P1
   Sarif BAB, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/304787
   Schroeder D, 2018, IEEE T CIRCUITS SYST
   Seema A, 2015, IEEE T BROADCAST, V61, P346, DOI 10.1109/TBC.2015.2400816
   Seema A, 2011, IEEE COMMUN SURV TUT, V13, P462, DOI 10.1109/SURV.2011.102910.00098
   Shin H, 2017, MULTIMED TOOLS APPL, V76, P19379, DOI 10.1007/s11042-015-3089-0
   Slotfeldt T, 2016, MX 6 SERIES PROCESSO
   Smith J, 2016, MPEG 2 TS BYTE STREA
   Smith J, 2016, WEBM BYTE STREAM FOR
   Snajder B, 2016, AD HOC NETW, V49, P29, DOI 10.1016/j.adhoc.2016.06.004
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Stamatescu G, 2014, C IND ELECT APPL, P1615, DOI 10.1109/ICIEA.2014.6931426
   Tavli B, 2012, MULTIMED TOOLS APPL, V60, P689, DOI 10.1007/s11042-011-0840-z
   Thomas E., 2016, Proceedings of the 10th International Conference, P1
   Titzer BL, 2005, 2005 Fourth International Symposium on Information Processing in Sensor Networks, P477
   Thang TC, 2012, IEEE T CONSUM ELECTR, V58, P78, DOI 10.1109/TCE.2012.6170058
   van Rest J, 2014, MULTIMED TOOLS APPL, V70, P573, DOI 10.1007/s11042-013-1575-9
   Vergados DJ, 2016, IEEE SYST J, V10, P859, DOI 10.1109/JSYST.2015.2478879
   Watson M, 2016, ISO BMFF BYTE STREAM
   Watson M, 2016, MEDIA SOURCE EXTENSI
   Wohlin C, 2003, LECT NOTES COMPUT SC, V2765, P7
   Wohlin C., 2012, Experimentation in Software Engineering
   Wunderlich S, 2017, IEEE INTERNET THINGS, V4, P917, DOI 10.1109/JIOT.2017.2703813
   Yan RQ, 2013, IEEE T INSTRUM MEAS, V62, P1183, DOI 10.1109/TIM.2013.2245181
   Yap FGH, 2014, SENSORS-BASEL, V14, P3506, DOI 10.3390/s140203506
   Yuan DW, 2017, PERVASIVE MOB COMPUT, V37, P45, DOI 10.1016/j.pmcj.2016.10.001
   Zhang C, 2017, DEPENDENCY SIMILARIT, P1
   Zhang J., 2016, P 8 INT WORKSH MOB V, P1, DOI [10.1145/2910018.2910656, DOI 10.1145/2910018.2910656]
NR 101
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21417
EP 21443
DI 10.1007/s11042-017-5565-1
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300048
DA 2024-07-18
ER

PT J
AU Xia, BB
   Wang, AH
   Chang, CC
   Liu, L
AF Xia, Binbin
   Wang, Anhong
   Chang, Chin-Chen
   Liu, Li
TI Reversible data hiding for VQ indices using hierarchical state codebook
   mapping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Vector-quantization (VQ); Hierarchical state
   codebook mapping (HSCM); Side-match distortion method(SMD)
ID IMAGES
AB In this paper, we present an approach to efficiently hide sensitive data in vector quantization (VQ) indices and reversibly extract sensitive data from encrypted code stream. The approach uses two patterns to compress VQ indices. When an index is equal to its upper neighbor's index or left neighbor's index, it is encoded by the corresponding equivalent index; otherwise, it is encoded by a modified VQ codebook mapping named as hierarchical state codebook mapping (HSCM). In the proposed scheme, the hierarchical state codebook mapping (HSCM) is main coding pattern and it is generated according to the side-match distortion method(SMD). By the above two patterns, the size of original code stream is reduced, and more storage space can be used to embed sensitive data. The experimental results indicated that the proposed scheme can achieve a higher embedding capacity than the previous state-of-the-art VQ-index-based data hiding methods.
C1 [Xia, Binbin; Wang, Anhong; Liu, Li] Taiyuan Univ Sci & Technol, Coll Elect Informat & Engn, Taiyuan 030024, Shanxi, Peoples R China.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
C3 Taiyuan University of Science & Technology; Feng Chia University
RP Wang, AH (corresponding author), Taiyuan Univ Sci & Technol, Coll Elect Informat & Engn, Taiyuan 030024, Shanxi, Peoples R China.; Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
EM 237531301@qq.com; wah_ty@163.com; alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023
FU National Natural Science Foundation of China [61272262, 61210006];
   International Cooperative Program of Shanxi Province [20150310032];
   Shanxi Scholarship Council of China [2014-056]; Program for New Century
   Excellent Talent in Universities [NCET-12-1037]; Scientific and
   Technological Innovation Team of Shanxi Province [201705D131025];
   Collaborative Innovation Center of Internet+3D Printing in Shanxi
   Province
FX This work has been supported in part by National Natural Science
   Foundation of China (No. 61272262 and No. 61210006), International
   Cooperative Program of Shanxi Province (No. 20150310032), Research
   Project Supported by Shanxi Scholarship Council of China (2014-056) and
   Program for New Century Excellent Talent in Universities (NCET-12-1037),
   Scientific and Technological Innovation Team of Shanxi Province (No.
   201705D131025), Collaborative Innovation Center of Internet+3D Printing
   in Shanxi Province.
CR Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2004, PATTERN RECOGN LETT, V25, P1253, DOI 10.1016/j.patrec.2004.04.003
   Chang CC, 2015, INFORM SCIENCES, V300, P85, DOI 10.1016/j.ins.2014.12.028
   Chang CC, 2009, PATTERN RECOGN, V42, P1597, DOI 10.1016/j.patcog.2008.11.040
   Chang CC, 2009, J VIS COMMUN IMAGE R, V20, P57, DOI 10.1016/j.jvcir.2008.08.005
   DIFFIE W, 1977, COMPUTER, V10, P74, DOI 10.1109/C-M.1977.217750
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Kim TJ, 1992, IEEE T IMAGE PROCESS, V1, P170, DOI 10.1109/83.136594
   Lee JD, 2013, INFORM SCIENCES, V221, P419, DOI 10.1016/j.ins.2012.09.020
   Lin CC, 2015, INFORM SCIENCES, V293, P314, DOI 10.1016/j.ins.2014.08.057
   Lin YC, 1999, NATL COMPUTER S, P76
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Pan ZB, 2013, J SYST SOFTWARE, V86, P2863, DOI 10.1016/j.jss.2013.06.066
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2009, INFORM SCIENCES, V179, P3332, DOI 10.1016/j.ins.2009.05.021
   Wang WJ, 2013, INFORM SCIENCES, V246, P69, DOI 10.1016/j.ins.2013.05.007
   Wu HC, 2009, J SYST SOFTWARE, V82, P1966, DOI 10.1016/j.jss.2009.06.056
   Yang CH, 2011, J SYST SOFTWARE, V84, P388, DOI 10.1016/j.jss.2010.11.924
   Yang CH, 2010, J VIS COMMUN IMAGE R, V21, P334, DOI 10.1016/j.jvcir.2010.02.008
   Yang CH, 2009, J VIS COMMUN IMAGE R, V20, P399, DOI 10.1016/j.jvcir.2009.04.001
NR 23
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20519
EP 20533
DI 10.1007/s11042-017-5490-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300010
DA 2024-07-18
ER

PT J
AU Zebbiche, K
   Khelifi, F
   Loukhaoukha, K
AF Zebbiche, Khalil
   Khelifi, Fouad
   Loukhaoukha, Khaled
TI Robust additive watermarking in the DTCWT domain based on perceptual
   masking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DTCWT; Perceptual masking; Additive watermarking; Watermark detection
ID TREE COMPLEX WAVELET; ASYMPTOTICALLY OPTIMAL DETECTION; COPYRIGHT
   PROTECTION; CONTRAST SENSITIVITY; IMAGE WATERMARKING; SCHEME; DWT;
   COMPRESSION; DCT
AB In this paper, a robust additive image watermarking system operating in the Dual Tree Complex Wavelet Transform (DTCWT) domain is proposed. The system takes advantage of a new perceptual masking model that exploits the Human Visual System (HVS) characteristics at the embedding stage. It also uses an efficient watermark detection structure, called the Rao-test, to verify the presence of the candidate watermark. This structure relies on the statistical modeling of high frequency DTCWT coefficients by the Generalized Gaussian distribution. Experimental results show that the proposed system outperforms related state-of-the-art watermarking systems in terms of imperceptibility and robustness.
C1 [Zebbiche, Khalil; Loukhaoukha, Khaled] Natl Ctr Res & Dev, Algiers, Algeria.
   [Khelifi, Fouad] Northumbria Univ, Dept Comp & Informat Sci, Newcastle Upon Tyne NE2 1XE, Tyne & Wear, England.
C3 Northumbria University
RP Khelifi, F (corresponding author), Northumbria Univ, Dept Comp & Informat Sci, Newcastle Upon Tyne NE2 1XE, Tyne & Wear, England.
EM kzebbiche01@qub.ac.uk; fouad.khelifi@northumbria.ac.uk;
   khaled.loukhaoukha.1@ulaval.ca
RI Loukhaoukha, Khaled/ABI-3136-2020
OI Loukhaoukha, Khaled/0000-0002-9000-4210; zebbiche,
   khalil/0000-0002-6926-8203
CR Agarwal H, 2015, MULTIMED TOOLS APPL, V74, P10883, DOI 10.1007/s11042-014-2212-y
   Albalawi U, 2016, MULTIMED TOOLS APPL, P1
   Alkhathami M, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1717, DOI 10.1109/CISP.2013.6743953
   Asikuzzaman Md, 2014, IEEE Transactions on Information Forensics and Security, V9, P1502, DOI 10.1109/TIFS.2014.2338274
   Asikuzzaman M, 2012, INT C DIG IM COMP TE, P1
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Benyoussef Meryem, 2014, Journal of Theoretical and Applied Information Technology, V60, P372
   Cheng Q, 2001, IEEE T MULTIMEDIA, V3, P273, DOI 10.1109/6046.944472
   Coria LE, 2008, IEEE T INF FOREN SEC, V3, P466, DOI 10.1109/TIFS.2008.927421
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   Guo BL, 2008, ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, PROCEEDINGS, P19, DOI 10.1109/ISDA.2008.112
   Hernández JR, 2000, IEEE T IMAGE PROCESS, V9, P55, DOI 10.1109/83.817598
   Hill P, 2016, IEEE T IMAGE PROCESS, V25, P2739, DOI 10.1109/TIP.2016.2552725
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Jinhua Liu, 2010, 2010 International Conference on Image Analysis and Signal Processing (IASP 2010), P675, DOI 10.1109/IASP.2010.5476180
   Kay S. M., 1998, FUNDAMENTALS STAT SI, V2
   KAY SM, 1989, IEEE T ACOUST SPEECH, V37, P627, DOI 10.1109/29.17554
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   Kingsbury N.G., 1998, IEEE Digital Signal Processing Workshop, DSP 98
   Kwitt R, 2009, 16 INT C DIG SIGN PR, P1
   Kwitt R, 2011, IEEE T IMAGE PROCESS, V20, P474, DOI 10.1109/TIP.2010.2064327
   Lewis AS, 1992, IEEE T IMAGE PROCESS, V1, P244, DOI 10.1109/83.136601
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Loo P, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P29, DOI 10.1109/ICIP.2000.899275
   Loo P, 2002, THESIS
   Lu W, 2009, COMPUT ELECTR ENG, V35, P183, DOI 10.1016/j.compeleceng.2008.09.004
   Mabtoul S, 2008, IEEE S COMM ISCC 200, P1000
   Nadenau MJ, 2003, IEEE T IMAGE PROCESS, V12, P58, DOI 10.1109/TIP.2002.807358
   Nikolaidis A, 2003, IEEE T IMAGE PROCESS, V12, P563, DOI 10.1109/TIP.2003.810586
   Pickering M, 2007, IEEE ICCE, P289
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Tang LL, 2015, MULTIMED TOOLS APPL, V74, P4397, DOI 10.1007/s11042-013-1531-8
   Voloshynovskiy S, 2000, LECT NOTES COMPUT SC, V1768, P211
   Wang CP, 2017, SIGNAL PROCESS, V134, P197, DOI 10.1016/j.sigpro.2016.12.010
   Wang XY, 2014, COMPUT ELECTR ENG, V40, P942, DOI 10.1016/j.compeleceng.2013.12.017
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie G, 2005, IEEE IMAGE PROC, P89
   Yang HJ, 2011, LECT NOTES COMPUT SC, V6730, P18, DOI 10.1007/978-3-642-24556-5_2
   Zebbiche K, 2014, IET IMAGE PROCESS, V8, P23, DOI 10.1049/iet-ipr.2013.0055
NR 44
TC 37
Z9 39
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21281
EP 21304
DI 10.1007/s11042-017-5451-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300043
OA Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Hu, X
   Tang, CM
   Wong, DS
   Zheng, XH
AF Hu, Xing
   Tang, Chunming
   Wong, Duncan S.
   Zheng, Xianghan
TI Efficient pairing-free PRE schemes for multimedia data sharing in IoT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia data security; Proxy re-encryption; CCA security; Without
   pairing; Public verifiability
ID ENCRYPTION; SECURITY; IMAGES
AB Nowadays, Internet of things (IoT) become more and more popular. At the same time, the requirements of security mechanism for multimedia in IoT received a huge concern. Multimedia data is easily shared by devises, applications and social networks set by IoT. Therefore, it is indispensable to guarantee the privacy and security of shared multimedia data. In this paper, we address the secure multimedia data sharing problem in cloud computing by designing proxy re-encryption (PRE) scheme. Our schemes cope with the issues of data validity, data confidentiality and authentication during encrypted multimedia data sharing. Unlike as usually done in the literature, we present a CCA-secure PRE scheme which removes pairings firstly. Then we design a refined CCA-secure PRE scheme called publicly verifiable PRE without parings. It is demonstrated that our schemes meet not only the security and high efficiency requirements of multimedia data sharing, but also the public verifiability. The validity of ciphertext, both the original and re-encrypted ciphertext, can be publicly verified which brings additional efficiency due to offloading the validity check of ciphertexts from the power-limited clients to any semi-honest public cloud.
C1 [Hu, Xing] Hunan Univ Sci & Technol, Sch Math & Computat Sci, Xiangtan, Hunan, Peoples R China.
   [Hu, Xing] Guangzhou Univ, Sch Math & Informat Sci, Key Lab Informat Secir, Guangzhou, Guangdong, Peoples R China.
   [Tang, Chunming] Guangzhou Univ, Sch Math & Informat Sci, Guangzhou, Guangdong, Peoples R China.
   [Wong, Duncan S.] CryptoBLK Co, Hong Kong, Hong Kong, Peoples R China.
   [Zheng, Xianghan] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou, Fujian, Peoples R China.
C3 Hunan University of Science & Technology; Guangzhou University;
   Guangzhou University; Fuzhou University
RP Tang, CM (corresponding author), Guangzhou Univ, Sch Math & Informat Sci, Guangzhou, Guangdong, Peoples R China.
EM ctang@gzhu.edu.cn
FU Scientific Research Fund of Hunan Provincial Education Department
   [15C0536]; Foundation of National Natural Science of China [11271003];
   Guangdong Province Natural Science Foundation of major basic research
   and Cultivation project [2015A030308016]; Project of Ordinary University
   Innovation Team Construction of Guangdong Province [2015KCXTD014]; Basic
   Research Major Projects of Department of education of Guangdong Province
   [2014KZDXM044]; Collaborative Innovation Major Projects of Bureau of
   Education of Guangzhou City [1201610005]
FX I would like to thank Prof. Duncan S. WONG for his instructive
   suggestions, which have significantly improved the design and revised
   the manuscript. Hu's research was supported in part by the Scientific
   Research Fund of Hunan Provincial Education Department (No. 15C0536),
   Tang's research was supported in part by the Foundation of National
   Natural Science of China (No. 11271003), Guangdong Province Natural
   Science Foundation of major basic research and Cultivation project (No.
   2015A030308016), Project of Ordinary University Innovation Team
   Construction of Guangdong Province (No. 2015KCXTD014), Basic Research
   Major Projects of Department of education of Guangdong Province (No.
   2014KZDXM044) and Collaborative Innovation Major Projects of Bureau of
   Education of Guangzhou City (No. 1201610005). The authors declare that
   they have no conflict of interest.
CR [Anonymous], 2016, FUTURE GENERATION CO
   [Anonymous], IACR CRYPTOLOGY EPRI
   Ateniese G., 2006, ACM Transactions on Information and Systems Security, V9, P1, DOI 10.1145/1127345.1127346
   Ateniese G, 2000, LECT NOTES COMPUT SC, V1880, P255
   Ateniese G, 2005, IN NDSS
   Ateniese G, 2009, LECT NOTES COMPUT SC, V5473, P279, DOI 10.1007/978-3-642-00862-7_19
   Bianchi T, 2013, IEEE SIGNAL PROC MAG, V30, P87, DOI 10.1109/MSP.2012.2228342
   Bianchi T, 2009, IEEE T INF FOREN SEC, V4, P86, DOI 10.1109/TIFS.2008.2011087
   Blaze M, 1998, LECT NOTES COMPUT SC, V1403, P127, DOI 10.1007/BFb0054122
   Boneh D, 2005, LECT NOTES COMPUT SC, V3378, P325
   Bouslimi D, 2012, COMPUT METH PROG BIO, V106, P47, DOI 10.1016/j.cmpb.2011.09.015
   Cancellaro M, 2011, SIGNAL PROCESS-IMAGE, V26, P1, DOI 10.1016/j.image.2010.11.001
   Canetti R, 2003, LECT NOTES COMPUT SC, V2729, P565
   Canetti R, 2007, CCS'07: PROCEEDINGS OF THE 14TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P185
   Chang V, 2016, FUTURE GENER COMP SY, V57, P24, DOI 10.1016/j.future.2015.09.031
   Cheng H, 2000, IEEE T SIGNAL PROCES, V48, P2439, DOI 10.1109/78.852023
   Chow SSM, 2010, LECT NOTES COMPUT SC, V6055, P316
   Chu CK, 2007, LECT NOTES COMPUT SC, V4779, P189
   Cohen J. D., 1985, 26th Annual Symposium on Foundations of Computer Science (Cat. No.85CH2224-4), P372, DOI 10.1109/SFCS.1985.2
   Coron JS, 2000, LECT NOTES COMPUT SC, V1880, P229
   Damgård I, 2003, LECT NOTES COMPUT SC, V2727, P350
   Deng RH, 2008, LECT NOTES COMPUT SC, V5339, P1, DOI 10.1007/978-3-540-89641-8_1
   Dodis Y., 2003, Network and Distributed System Security Symposium
   ELGAMAL T, 1985, IEEE T INFORM THEORY, V31, P469, DOI 10.1109/TIT.1985.1057074
   Fouda JSAE, 2014, COMMUN NONLINEAR SCI, V19, P578, DOI 10.1016/j.cnsns.2013.07.016
   Gentry C, 2009, ACM S THEORY COMPUT, P169, DOI 10.1145/1536414.1536440
   Goldwasser S, 2005, LECT NOTES COMPUT SC, V3378, P529
   GOLDWASSER S, 1984, J COMPUT SYST SCI, V28, P270, DOI 10.1016/0022-0000(84)90070-9
   Goldwasser Shafi., P 14 ANN ACM S THEOR, P365, DOI DOI 10.1145/800070.802212
   Goto K, 2013, MOB INF SYST, V9, P295, DOI 10.1155/2013/604068
   Green M, 2007, LECT NOTES COMPUT SC, V4521, P288
   Hohenberger S, 2007, LECT NOTES COMPUT SC, V4392, P233
   Hu X, 2016, INT SYMP PARA DISTR, P261, DOI 10.1109/ISPDC.2016.45
   Jindan Zhang, 2012, 2012 4th International Conference on Intelligent Networking and Collaborative Systems (INCoS 2012), P571, DOI 10.1109/iNCoS.2012.53
   Kawachi A, 2007, LECT NOTES COMPUT SC, V4450, P315
   Khurana H., 2006, ASIACCS 2006, P46
   Khurana H., 2005, ACM SAC 2005, P306
   Libert B, 2008, LECT NOTES COMPUT SC, V5209, P332, DOI 10.1007/978-3-540-85538-5_22
   Libert B, 2008, LECT NOTES COMPUT SC, V4939, P360, DOI 10.1007/978-3-540-78440-1_21
   Melchor CA, 2008, IEEE INT SYMP INFO, P1858, DOI 10.1109/ISIT.2008.4595310
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Peikert C, 2011, SIAM J COMPUT, V40, P1803, DOI 10.1137/080733954
   Shao J, 2008, ANAL CCA SECURE UNID
   Shao J, 2009, LECT NOTES COMPUT SC, V5443, P357
   Smith T., 2005, DVD JON BUY DRM LESS
   Talmy A, 2006, 20TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 2, PROCEEDINGS, P77
   Vijayakumar P., 2017, CLUSTER COMPUT, P1
   Wang ZW, 2017, J COMPUT SYST SCI, V89, P41, DOI 10.1016/j.jcss.2016.12.006
   Ye C, 2013, INT WORKSH DIG FOR W, P507
   Ye CH, 2014, J VISUAL LANG COMPUT, V25, P658, DOI 10.1016/j.jvlc.2014.10.020
   Zhang LM, 2017, MULTIMEDIA SYST, V23, P1, DOI 10.1007/s00530-016-0527-4
   Zhang MQ, 2013, J COMPUT, V8, P1987, DOI 10.4304/jcp.8.8.1987-1994
NR 52
TC 0
Z9 0
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18327
EP 18354
DI 10.1007/s11042-017-5387-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900040
OA hybrid
DA 2024-07-18
ER

PT J
AU Lu, GF
   Zou, J
   Wang, Y
   Wang, ZQ
AF Lu, Gui-Fu
   Zou, Jian
   Wang, Yong
   Wang, Zhongqun
TI Sparse L1-norm-based linear discriminant analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature extraction; Dimensionality reduction; L1-norm; L2-norm; elastic
   net regularization
ID PRINCIPAL COMPONENT ANALYSIS; ROBUST FEATURE-EXTRACTION; MAXIMUM MARGIN
   CRITERION; LOCAL BINARY PATTERNS; PALMPRINT RECOGNITION; FACE;
   REGRESSION; CLASSIFICATION; MAXIMIZATION; PROJECTION
AB Linear discriminant analysis (LDA) is a well-known feature extraction method, which has been widely used for many pattern recognition problems. However, the objective function of conventional LDA is based on L2-norm, which makes LDA sensitive to outliers. Besides, the basis vectors learned by conventional LDA are dense and it is often hard to explain the extracted features. In this paper, we propose a novel sparse L1-norm-based linear discriminant analysis (SLDA-L1) which not only replaces L2-norm in conventional LDA with L1-norm, but also use the elastic net to regularize the basis vectors. Then L1-norm used in SLDA-L1 is for both robust and sparse modelling simultaneously. We also propose an efficient iterative algorithm to solve SLDA-L1 which is theoretically shown to arrive at a locally maximal point. Experiment results on some image databases demonstrate the effectiveness of the proposed method.
C1 [Lu, Gui-Fu; Zou, Jian; Wang, Yong; Wang, Zhongqun] AnHui Polytech Univ, Sch Comp & Informat, Wuhu 241000, Anhui, Peoples R China.
   [Lu, Gui-Fu] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Anhui Polytechnic University; Nanjing University of Information Science
   & Technology
RP Lu, GF (corresponding author), AnHui Polytech Univ, Sch Comp & Informat, Wuhu 241000, Anhui, Peoples R China.; Lu, GF (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
EM luguifu_tougao@163.com
RI Wang, Yong/HLW-0025-2023
OI Wang, Yong/0000-0002-2719-1017
FU NSFC of China [61572033, 71371012]; Natural Science Foundation of
   Education Department of Anhui Province of China [KJ2015ZD08]; Social
   Science and Humanity Foundation of the Ministry of Education of China
   [13YJA630098]
FX This research is supported by supported by NSFC of China (No. 61572033,
   71371012), the Natural Science Foundation of Education Department of
   Anhui Province of China (No. KJ2015ZD08), the Social Science and
   Humanity Foundation of the Ministry of Education of China (No.
   13YJA630098).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], P 21 AAAI C ART INT
   Bair E, 2006, J AM STAT ASSOC, V101, P119, DOI 10.1198/016214505000000628
   Barshan E, 2011, PATTERN RECOGN, V44, P1357, DOI 10.1016/j.patcog.2010.12.015
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Cai D, 2007, IEEE DATA MINING, P73, DOI 10.1109/ICDM.2007.89
   Ding C., 2006, P 23 INT C MACH LEAR, P281, DOI DOI 10.1145/1143844.1143880
   Duda R., 1973, Pattern Classification and Scene Analysis
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Gu B., 2016, IEEE Transactions on Neural Networks and Learning Systems, DOI DOI 10.1109/TNNLS.2016.2527796
   Gu B, 2017, IEEE T NEUR NET LEAR, V28, P1646, DOI 10.1109/TNNLS.2016.2544779
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   Gu B, 2015, NEURAL NETWORKS, V67, P140, DOI 10.1016/j.neunet.2015.03.013
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jenatton R., 2010, JMLR WORKSH C P 2010, P366
   Kawulok M, 2011, PATTERN RECOGN, V44, P929, DOI 10.1016/j.patcog.2010.10.010
   Ke Q, 2005, P IEEE C COMP VIS PA, P1
   Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852
   Li HF, 2004, ADV NEUR IN, V16, P97
   Li X, 2010, NEUROCOMPUTING, V73, P2571, DOI 10.1016/j.neucom.2010.05.016
   Li XL, 2010, IEEE T SYST MAN CY B, V40, P1170, DOI 10.1109/TSMCB.2009.2035629
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Meng DY, 2012, PATTERN RECOGN, V45, P487, DOI 10.1016/j.patcog.2011.07.009
   Nie F., 2011, P 22 INT JOINT C ART, P1
   Pang YW, 2010, IEEE T CIRC SYST VID, V20, P172, DOI 10.1109/TCSVT.2009.2020337
   Wang HX, 2014, IEEE T CYBERNETICS, V44, P828, DOI 10.1109/TCYB.2013.2273355
   Wang HX, 2013, NEURAL NETWORKS, V46, P190, DOI 10.1016/j.neunet.2013.06.002
   Wang HX, 2012, IEEE T BIO-MED ENG, V59, P653, DOI 10.1109/TBME.2011.2177523
   Wang HX, 2012, NEURAL NETWORKS, V27, P38, DOI 10.1016/j.neunet.2011.11.003
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Xia JS, 2014, IEEE J-STARS, V7, P2224, DOI 10.1109/JSTARS.2013.2279693
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zheng WM, 2014, IEEE T NEUR NET LEAR, V25, P793, DOI 10.1109/TNNLS.2013.2281428
   Zhong FJ, 2013, IEEE T IMAGE PROCESS, V22, P3018, DOI 10.1109/TIP.2013.2253476
   Zhou TY, 2011, DATA MIN KNOWL DISC, V22, P340, DOI 10.1007/s10618-010-0182-x
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
   Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430
NR 42
TC 4
Z9 4
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16155
EP 16175
DI 10.1007/s11042-017-5193-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300008
DA 2024-07-18
ER

PT J
AU Alvarez-Ramos, V
   Ponomaryov, V
   Reyes-Reyes, R
AF Alvarez-Ramos, Valentin
   Ponomaryov, Volodymyr
   Reyes-Reyes, Rogelio
TI Image super-resolution via two coupled dictionaries and sparse
   representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Sparse representation; Feature; extraction; Filters;
   Quality criteria
ID RESOLUTION ENHANCEMENT; INTERPOLATION
AB In image processing, the super-resolution (SR) technique has played an important role to perform high-resolution (HR) images from the acquired low-resolution (LR) images. In this paper, a novel technique is proposed that can generate a SR image from a single LR input image. Designed framework can be used in images of different kinds. To reconstruct a HR image, it is necessary to perform an intermediate step, which consists of an initial interpolation; next, the features are extracted from this initial image via convolution operation. Then, the principal component analysis (PCA) is used to reduce information redundancy after features extraction step. Non-overlapping blocks are extracted, and for each block, the sparse representation is performed, which it is later used to recover the HR image. Using the quality objective criteria and subjective visual perception, the proposed technique has been evaluated demonstrating their competitive performance in comparison with state-of-the-art methods.
C1 [Alvarez-Ramos, Valentin; Ponomaryov, Volodymyr; Reyes-Reyes, Rogelio] Inst Politecn Nacl, ESIME Culhuacan, SEPI, Av Santa Ana 1000, Mexico City, DF, Mexico.
C3 Instituto Politecnico Nacional - Mexico
RP Alvarez-Ramos, V (corresponding author), Inst Politecn Nacl, ESIME Culhuacan, SEPI, Av Santa Ana 1000, Mexico City, DF, Mexico.
EM vaalra@yahoo.com; vponomar@ipn.mx; rreyesre@ipn.mx
RI Ponomaryov, Volodymyr/AAK-1537-2021; PONOMARYOV,
   VOLODYMYR/AAF-2858-2021; Reyes-Reyes, Rogelio/AAC-7553-2019
OI Ponomaryov, Volodymyr/0000-0003-4477-4676; Reyes-Reyes,
   Rogelio/0000-0001-5506-6611
FU Instituto Politecnico Nacional (Mexico); Consejo Nacional de Ciencia y
   Tecnologia (Mexico) [220347]
FX Authors would like to thank Instituto Politecnico Nacional (Mexico) and
   Consejo Nacional de Ciencia y Tecnologia (Mexico) (grant 220347) for
   their supports in this work.
CR Abedi A, 2017, MULTIMED TOOLS APPL, V76, P16415, DOI 10.1007/s11042-016-3919-8
   Acharya A, 2012, I CONF SENS TECHNOL, P57, DOI 10.1109/ICSensT.2012.6461746
   Alvarez-Ramos V, 2016, INT CONF ELECTR COMM, P156, DOI 10.1109/CONIELECOMP.2016.7438568
   Ameer S, 2008, INT CONF SIGN PROCES, P728, DOI 10.1109/ICOSP.2008.4697233
   Anbarjafari G, 2015, SIGNAL IMAGE VIDEO P, V9, P87, DOI 10.1007/s11760-012-0422-1
   Anbarjafari G, 2010, ETRI J, V32, P390, DOI 10.4218/etrij.10.0109.0303
   [Anonymous], IM SUP RES VIA SPARS
   [Anonymous], 2016, Psicologia O Portal dos Psicologos, DOI DOI 10.1109/MSMW.2016.7538183
   [Anonymous], EUROPEAN SIGNAL PROC
   [Anonymous], ADV MULT 2009 MMEDIA
   Azimi-Sadjadi MR, 2014, IEEE IMAGE PROC, P1599, DOI 10.1109/ICIP.2014.7025320
   Bovik A, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, pV, DOI 10.1016/B978-012119792-6/50062-0
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2016, ACM T KNOWL DISCOV D, V11, DOI 10.1145/2910585
   Chavez-Roman H, 2014, IEEE GEOSCI REMOTE S, V11, P1777, DOI 10.1109/LGRS.2014.2308905
   Chen Lei., 2016, P 3 INT S MOVEMENT C, P1
   Chen Y, 2017, PHYS MED BIOL, V62, P2103, DOI 10.1088/1361-6560/aa5c24
   Chen Y, 2014, IEEE T MED IMAGING, V33, P2271, DOI 10.1109/TMI.2014.2336860
   Dai S., 2007, Computer Vision and Pattern Recognition, P1
   Damkat C, 2011, SIGNAL IMAGE VIDEO P, V5, P343, DOI 10.1007/s11760-010-0205-5
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Elad M, 2010, P IEEE, V98, P972, DOI 10.1109/JPROC.2009.2037655
   Geng L, 2017, IEEE WINT CONF APPL, P1, DOI 10.1109/WACVW.2017.8
   Han W, 2017, MULTIMED TOOLS APPL, V76, P11143, DOI 10.1007/s11042-016-3656-z
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hu YT, 2016, IEEE T IMAGE PROCESS, V25, P4091, DOI 10.1109/TIP.2016.2580942
   Jiang JJ, 2014, MULTIMED TOOLS APPL, V72, P2573, DOI 10.1007/s11042-013-1567-9
   Kang XD, 2012, INT C PATT RECOG, P1043
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim J, 2016, IEEE CONF COMPUT
   Li JM, 2016, MULTIMED TOOLS APPL, V75, P4115, DOI 10.1007/s11042-015-3016-4
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Mallat S, 2010, IEEE T IMAGE PROCESS, V19, P2889, DOI 10.1109/TIP.2010.2049927
   Meng W, 2015, NANOSCALE RES LETT, V10, P1, DOI 10.1186/s11671-015-0746-1
   Pan LL, 2016, MULTIMED TOOLS APPL, V75, P11037, DOI 10.1007/s11042-015-2834-8
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P27, DOI 10.1109/TIP.2008.2008065
   Ramakanth SA, 2015, MULTIMED TOOLS APPL, V74, P6691, DOI 10.1007/s11042-014-1925-2
   Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551
   Sahoo SK, 2013, IEEE SIGNAL PROC LET, V20, P587, DOI 10.1109/LSP.2013.2258912
   Sajjad M, 2015, MULTIMED TOOLS APPL, V74, P8961, DOI 10.1007/s11042-013-1570-1
   Shen B, 2009, INT CONF ACOUST SPEE, P697, DOI 10.1109/ICASSP.2009.4959679
   Temizel A, 2005, ELECTRON LETT, V41, P119, DOI 10.1049/el:20057150
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhou ZN, 2012, IEEE IMAGE PROC, P489, DOI 10.1109/ICIP.2012.6466903
NR 47
TC 7
Z9 7
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13487
EP 13511
DI 10.1007/s11042-017-4968-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900019
DA 2024-07-18
ER

PT J
AU Christaline, JA
   Ramesh, R
   Gomathy, C
   Vaishali, D
AF Christaline, Anita J.
   Ramesh, R.
   Gomathy, C.
   Vaishali, D.
TI Nature inspired metaheuristics for improved JPEG steganalysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE JPEG steganalysis; Fusion classifiers; Ant Lion Optimization; Bayes
   fusion classifier
ID RAY OPTIMIZATION; DESIGN; ALGORITHM
AB The performance accuracy of JPEG steganalysis depends on the best features extracted from the images. This demands extraction of all possible features that undergo changes during embedding. The computational complexity due to such large number of features necessitates feature set optimization. Existing research in JPEG image steganalysis tend to extract rich feature sets and reduce them by statistical feature reduction techniques. Compared to these techniques, genetic algorithm based optimization techniques are more promising as they converge to global minima. The objective of this paper is to implement genetic based optimization to reduce the high dimensional image features and hence obtain improved classification accuracy. The method implemented includes the extraction of image features in terms of co-occurrence matrices of the differences of all possible Discrete Cosine Transform (DCT) coefficients to give 200 x 23,230 features. These features are optimized by a nature inspired meta-heuristic, Ant Lion Optimization (ALO) which considers the features as ants that move in random space. The fitness function for the antlion to hunt the ants is proportional to the traps built by the antlion. The proposed steganalyser has been tested for classification accuracies with different payloads. The classifiers implemented include Support Vector Machines (SVM), Multi Layer Perceptron (MLP) and fusion classifiers based on Bayes, Decision template and Dempster Schafer data fusion schemes. The results show that highest average classification accuracy has been obtained for Bayes fusion classifier followed by Dempster Schafer fusion classifier. It has been noted that the performance of fusion classifiers is better compared to individual classifiers. Thus the proposed method gives better classification accuracy for JPEG steganalysis than existing methods.
C1 [Christaline, Anita J.; Gomathy, C.; Vaishali, D.] SRM Univ, Dept ECE, Chennai, Tamil Nadu, India.
   [Ramesh, R.] Saveetha Engn Coll, ECE Dept, Chennai, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai
RP Christaline, JA (corresponding author), SRM Univ, Dept ECE, Chennai, Tamil Nadu, India.
EM anita.j@vdp.srmuniv.ac.in; ramesh@saveetha.ac.in;
   hod.ece@vdp.srmuniv.ac.in; vaishali.b@vdp.srmuniv.ac.in
RI , Gomathy/J-6134-2019; JOHNVICTOR, ANITA CHRISTALINE/C-7790-2018
OI , Gomathy/0000-0001-6713-2700; JOHNVICTOR, ANITA
   CHRISTALINE/0000-0001-5884-5733; C, Gomathy/0000-0002-9848-8096; R,
   RAMESH/0000-0001-7992-9127
CR [Anonymous], 2011, P 13 INF HID C PRAG
   Bianchi Leonora, 2009, Natural Computing, V8, P239, DOI 10.1007/s11047-008-9098-4
   Chenggang Y, 2014, ELECTRON LETT, V50, P805
   Chhikara RR, 2018, INT J MACH LEARN CYB, V9, P821, DOI 10.1007/s13042-016-0610-3
   Chikkara RR, 2017, P 6 INT C INT SYST M
   Christaline J. Anita, 2015, International Journal of Advanced Intelligence Paradigms, V7, P368
   Christaline J. Anita, 2016, INDIAN J SCI TECHNOL, V9
   Christaline J. Anita, 2016, INT J MULTIMEDIA UBI, V11, P385, DOI DOI 10.14257/IJMUE.2016.11.1.37
   Christaline JA, 2014, ARPN J ENG APPL SCI, V9
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Fridrich Jessica., 2007, STATISTICALLY UNDETE, P3
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Huang FJ, 2008, IEEE IMAGE PROC, P2068, DOI 10.1109/ICIP.2008.4712193
   Kaveh A, 2012, COMPUT STRUCT, V112, P283, DOI 10.1016/j.compstruc.2012.09.003
   Kaveh A, 2013, PERIOD POLYTECH-CIV, V57, P97, DOI 10.3311/PPci.7166
   Kodovsky J, 2011, P SOC PHOTO-OPT INS, VXIII, P23
   Kuncheva LI, 2002, IEEE T PATTERN ANAL, V24, P281, DOI 10.1109/34.982906
   Liu Q, 2011, P 13 ACM WORKSH MULT
   Liu Qingzhong., 2011, Proceedings of the 3rd International ACM Workshop on Multimedia in Forensics and Intelligence, MiFor'11, page, P25
   Mirjalili S, 2015, ADV ENG SOFTW, V83, P80, DOI 10.1016/j.advengsoft.2015.01.010
   Rajabioun R, 2011, APPL SOFT COMPUT, V11, P5508, DOI 10.1016/j.asoc.2011.05.008
   Roshini D, 2009, INT J COMPUT, V3, P161
   Sajedi H, 2017, J EXP THEOR ARTIF IN, V29, P949, DOI 10.1080/0952813X.2016.1266037
   Shi YQ, 2006, MARKOV PROCESS BASED
   Talbi E.-G., 2009, METAHEURISTICS DESIG, V74
   Wang Y H, 2016, SUSTAINABILITY, V9, P1, DOI DOI 10.14257/IJSIP.2016.9.1.32
   Windeatt T, 2006, IEEE T NEURAL NETWOR, V17, P1194, DOI 10.1109/TNN.2006.875979
   Xin-She Yang, 2010, International Journal of Mathematical Modelling and Numerical Optimisation, V1, P330, DOI 10.1504/IJMMNO.2010.035430
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang XS, 2010, INT J BIO-INSPIR COM, V2, P78, DOI 10.1504/IJBIC.2010.032124
NR 31
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13701
EP 13720
DI 10.1007/s11042-017-4983-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900029
DA 2024-07-18
ER

PT J
AU Lian, XH
   Pang, YW
   Yang, AP
AF Lian, Xuhang
   Pang, Yanwei
   Yang, Aiping
TI Learning intensity and detail mapping parameters for dehazing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Haze removal; Image enhancement; Intensity mapping; Detail mapping;
   Detail enhancement; Color fidelity
ID HAZE REMOVAL; CONTRAST ENHANCEMENT; IMAGE; FRAMEWORK; VISION
AB State-of-the-art methods for removing haze from a single image rely on a haze image formation model and the inversion problem is solved by estimating medium transmission and global atmospheric light. In this paper, we propose a hazy image enhancement framework, called Intensity Mapping and Detail Mapping(IMDM), for dehazing, which can strike a good balance in enhancing details and preserving color fidelity. We propose two mapping fucntions to respectively process the detail and intensity components of the hazy image instead of jointly tackling the two parts. Compared with joint tackling of these two kinds of information, respective processings are more advantagous in stretching the contrast and highlight the details. For obtaining the optimal parameters of mapping functions, we specially set up an image dataset, which consists of numbers of pairs of hazy and the corresponding ground truth images, for the training process. In order to simulate hazy images in the real world as much as possible, hazy images in this dataset are captured in an artificial hazy environment. With the learned parameters, details in the hazy image can be clearly restored without causing color infidelity. Experimental results demonstrate that the proposed method (called IMDM) is superior to both the enhancement and model-based methods in terms of improving the visibility and preserving color fidelity.
C1 [Lian, Xuhang; Pang, Yanwei; Yang, Aiping] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Pang, YW (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM xuhang_lian@163.com; pyw@tju.edu.cn; aipingyang20160106@gmail.com
FU National Natural Science Foundation of China [61632081, 61372145]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 61632081 and 61372145).
CR Agaian SS, 2001, IEEE T IMAGE PROCESS, V10, P367, DOI 10.1109/83.908502
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Bennett EP, 2005, ACM T GRAPHIC, V24, P845, DOI 10.1145/1073204.1073272
   Bhattacharya S, 2016, IEEE IMAGE PROC, P2251, DOI 10.1109/ICIP.2016.7532759
   Bin Xie, 2010, Proceedings 2010 International Conference on Intelligent System Design and Engineering Application (ISDEA 2010), P848, DOI 10.1109/ISDEA.2010.141
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Drago F, 2003, COMPUT GRAPH FORUM, V22, P419, DOI 10.1111/1467-8659.00689
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Eisemann E, 2004, ACM T GRAPHIC, V23, P673, DOI 10.1145/1015706.1015778
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Gao YY, 2014, SIGNAL PROCESS, V103, P380, DOI 10.1016/j.sigpro.2014.02.016
   Gibson KB, 2012, IEEE T IMAGE PROCESS, V21, P662, DOI 10.1109/TIP.2011.2166968
   Hautière N, 2006, MACH VISION APPL, V17, P8, DOI [10.1007/s00138-005-0011-1, 10.1007/s00138-006-0011-9]
   He JX, 2016, IEEE IMAGE PROC, P2246, DOI 10.1109/ICIP.2016.7532758
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Jain P, 2017, MULTIMED TOOLS APPL, V76, P1659, DOI 10.1007/s11042-015-3154-8
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Lai YH, 2015, IEEE T CIRC SYST VID, V25, P1, DOI 10.1109/TCSVT.2014.2329381
   Li Y, 2014, LECT NOTES COMPUT SC, V8690, P174, DOI 10.1007/978-3-319-10605-2_12
   Li ZW, 2015, PROC CVPR IEEE, P4988, DOI 10.1109/CVPR.2015.7299133
   Liu Q, 2017, SIGNAL PROCESS, V137, P33, DOI 10.1016/j.sigpro.2017.01.036
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Narasimhan S. G., 2003, Interactive (de) weathering of an image using physical models, V6, P1
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Ni WP, 2016, NEUROCOMPUTING, V175, P25, DOI 10.1016/j.neucom.2015.10.010
   Park H, 2014, IEEE IMAGE PROC, P4502, DOI 10.1109/ICIP.2014.7025913
   Pei SC, 2012, IEEE IMAGE PROC, P957, DOI 10.1109/ICIP.2012.6467020
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Scharstein Daniel., 2007, IEEE Conference on Computer Vision and Pattern Recognition, P1
   Shwartz S., 2006, 2006 IEEE COMP SOC C, V2, P1984, DOI DOI 10.1109/CVPR.2006.71
   Tan R, 2008, IEEE C COMPUTER VISI, P1
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Wang C, 2017, MULTIMED TOOLS APPL, V76, P2019, DOI 10.1007/s11042-015-3195-z
   Xiao CX, 2012, VISUAL COMPUT, V28, P713, DOI 10.1007/s00371-012-0679-y
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu QS, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1796, DOI 10.1109/ROBIO.2013.6739728
NR 46
TC 6
Z9 6
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15695
EP 15720
DI 10.1007/s11042-017-5142-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200055
DA 2024-07-18
ER

PT J
AU Ruiz, IL
   García, GC
   Gómez-Nieto, MA
AF Luque Ruiz, Irene
   Cerruela Garcia, Gonzalo
   Angel Gomez-Nieto, Miguel
TI Interactive mosaic building and its application to marketing strategies
   using NFC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photo mosaic; Matching algorithm; Marketing; NFC
ID IMAGE; ASSIGNMENT; ALGORITHMS
AB Although the building of photo mosaics has been widely studied, the existing solutions are not appropriate for solving problems where the photos are not already known. In this paper, we describe an efficient solution to interactive photo mosaics building in real time through the incorporation of new images provided by users. Efficient matching algorithms and data structures make possible the incorporation, in real time, of new images whose visualisation can be created from mobile devices, producing high quality and realistic mosaics. The application and validation of our solution using Near Field Communication (NFC) as a trigger for user interaction has demonstrated its usefulness for its application in marketing strategies.
C1 [Luque Ruiz, Irene; Cerruela Garcia, Gonzalo; Angel Gomez-Nieto, Miguel] Univ Cordoba, Dept Comp & Numer Anal, Campus Rabanales,Albert Einstein Bldg, E-14071 Cordoba, Spain.
C3 Universidad de Cordoba
RP Ruiz, IL (corresponding author), Univ Cordoba, Dept Comp & Numer Anal, Campus Rabanales,Albert Einstein Bldg, E-14071 Cordoba, Spain.
EM iluque@uco.es; gcerruela@uco.es; mangel@uco.es
RI Ruiz, Indalecio/K-9946-2014; Cerruela-García, Gonzalo/AAH-3728-2020;
   Gomez-Nieto, Miguel Angel/U-2651-2017
OI Cerruela-García, Gonzalo/0000-0001-9140-3347; Luque Ruiz,
   Irene/0000-0003-2996-7429; Gomez-Nieto, Miguel Angel/0000-0002-1946-5495
CR Alamareen A, 2016, INT J INF TECHNOL WE, V11, P1, DOI 10.4018/IJITWE.2016070101
   [Anonymous], 2002, P EUR A PHICS SAARBR
   [Anonymous], BIPARTITE MATCHING H
   [Anonymous], PHOTOMONTAGE AS
   [Anonymous], DATA MINING KNOWLEDG
   [Anonymous], J COMPUT THEOR NANOS
   [Anonymous], NETWORK FLOWS MATCHI
   [Anonymous], 2014, INT J ENG RES GEN SC
   [Anonymous], 1976, COMBINATORIAL OPTIMI
   [Anonymous], COMPUTATIONAL AESTHE
   [Anonymous], 2005, PUZZLE IMAGE MOSAIC
   [Anonymous], 2015, SIMPLEX METHOD LINEA
   [Anonymous], 2014, P INT C DISTRIBUTED
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2006, P EUR IT CHAPT C 200
   [Anonymous], INT J COMPUT APPL TE
   Azzari P, 2008, LECT NOTES COMPUT SC, V5259, P89, DOI 10.1007/978-3-540-88458-3_9
   Battiato S, 2007, COMPUT GRAPH FORUM, V26, P794, DOI 10.1111/j.1467-8659.2007.01021.x
   Battiato S, 2006, WSCG 2006: FULL PAPERS PROCEEDINGS, P133
   Battiato S, 2012, LECT NOTES COMPUT SC, V7583, P581, DOI 10.1007/978-3-642-33863-2_60
   Cantone D, 2005, IEEE T KNOWL DATA EN, V17, P535, DOI 10.1109/TKDE.2005.53
   Chi DX, 2012, INT SYM COMPUT INTEL, P370, DOI 10.1109/ISCID.2012.244
   Cui H, 2016, AER ADV ENG RES, V73, P822
   Elber G, 2003, VISUAL COMPUT, V19, P67, DOI 10.1007/s00371-002-0175-x
   Hoff KE, 1999, COMP GRAPH, P277, DOI 10.1145/311535.311567
   Kang D, 2013, MULTIMED TOOLS APPL, V63, P145, DOI 10.1007/s11042-012-1065-5
   Kim J, 2002, ACM T GRAPHIC, V21, P657
   Kourouthanassis P, 2015, PERVASIVE MOB COMPUT, V18, P71, DOI 10.1016/j.pmcj.2014.08.009
   Kovács P, 2015, OPTIM METHOD SOFTW, V30, P94, DOI 10.1080/10556788.2014.895828
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Laraqui A, 2017, MULTIMED TOOLS APPL, V76, P8803, DOI 10.1007/s11042-016-3478-z
   Lee Sang-Un, 2013, [The Journal of The Institute of Internet, Broadcasting and Communication, 한국인터넷방송통신학회 논문지], V13, P163, DOI 10.7236/JIIBC.2013.13.5.163
   Lee YL, 2014, IEEE T CIRC SYST VID, V24, P695, DOI 10.1109/TCSVT.2013.2283431
   Li ZQ, 2016, IEEE ROBOT AUTOM LET, V1, P295, DOI 10.1109/LRA.2016.2519946
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Nock R, 2004, IEEE T PATTERN ANAL, V26, P1452, DOI 10.1109/TPAMI.2004.110
   Phithakkitnukoon S, 2015, PERVASIVE MOB COMPUT, V18, P18, DOI 10.1016/j.pmcj.2014.07.003
   Singh R, 2007, IEEE T SYST MAN CY B, V37, P1212, DOI 10.1109/TSMCB.2007.903537
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Uyttendaele M, 2001, PROC CVPR IEEE, P509
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
NR 41
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15291
EP 15320
DI 10.1007/s11042-017-5115-x
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200039
DA 2024-07-18
ER

PT J
AU Mukherjee, S
   Singh, KK
AF Mukherjee, Snehasis
   Singh, Krit Karan
TI Human action and event recognition using a novel descriptor based on
   improved dense trajectories
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event recognition; Action recognition; Dense trajectories; Fisher vector
ID HISTOGRAMS
AB We propose a unified method for recognizing human action and human related events in a realistic video. We use an efficient pipeline of (a) a 3D representation of the Improved Dense Trajectory Feature (DTF) and (b) Fisher Vector (FV). Further, a novel descriptor is proposed, capable of representing human actions and human related events based on the FV representation of the input video. The proposed unified descriptor is a 168-dimensional vector obtained from each video sequence by statistically analyzing the motion patterns of the 3D joint locations of the human body. The proposed descriptor is trained using binary Support Vector Machine (SVM) for recognizing human actions or human related events. We evaluate the proposed approach on two challenging action recognition datasets: UCF sports and CMU Mocap datasets. In addition to the two action recognition dataset, the proposed approach is tested on the Hollywood2 event recognition dataset. On all the benchmark datasets for both action and event recognition, the proposed approach has shown its efficacy compared to the state-of-the-art techniques.
C1 [Mukherjee, Snehasis; Singh, Krit Karan] IIIT Chittoor, Sricity 517646, Andhra Pradesh, India.
RP Mukherjee, S (corresponding author), IIIT Chittoor, Sricity 517646, Andhra Pradesh, India.
EM snehasis.mukherjee@iiits.in; kritkaran.b13@iiits.in
RI Mukherjee, Snehasis/Q-1000-2019
OI Mukherjee, Snehasis/0000-0002-2196-8980
CR [Anonymous], 2009, ICCV WORKSH VID OR O
   Asteriadis S, 2017, MULTIMED TOOLS APPL, V76, P4505, DOI 10.1007/s11042-016-3945-6
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bregonzio M, 2009, PROC CVPR IEEE, P1948, DOI 10.1109/CVPRW.2009.5206779
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4651, DOI 10.1007/s11042-016-3284-7
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   David G., 1999, P 7 IEEE INT C COMP, V2, P1150
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gaidon A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3201, DOI 10.1109/CVPR.2011.5995646
   Gupta A, 2014, PROC CVPR IEEE, P2601, DOI 10.1109/CVPR.2014.333
   Harris C., 1988, ALVEY VISION C, P147151
   Jiang YG, 2013, INT J MULTIMED INF R, V2, P73, DOI 10.1007/s13735-012-0024-2
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Mukherjee S, 2015, LECT NOTES COMPUT SC, V9163, P477, DOI 10.1007/978-3-319-20904-3_43
   Mukherjee S, 2014, MACH VISION APPL, V25, P1033, DOI 10.1007/s00138-013-0589-7
   Mukherjee S, 2011, IEEE T CIRC SYST VID, V21, P1228, DOI 10.1109/TCSVT.2011.2135290
   Mukherjee S, 2015, IEEE ANTENNAS PROP, P488, DOI 10.1109/APS.2015.7304630
   Oneata D, 2013, IEEE I CONF COMP VIS, P1817, DOI 10.1109/ICCV.2013.228
   Raptis M, 2010, LECT NOTES COMPUT SC, V6311, P577, DOI 10.1007/978-3-642-15549-9_42
   Soomro K., 2012, ARXIV12120402CS
   Sun J, 2010, IEEE INT CON MULTI, P322, DOI 10.1109/ICME.2010.5583046
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Vinodh B, 2016, ICVGIP
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang H., 2009, BMVC
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Wong K. O., 2007, ICCV, P1, DOI DOI 10.1109/VTSA.2007.378923
   Yao A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.67
   Ziaeefard M, 2015, PATTERN RECOGN, V48, P2329, DOI 10.1016/j.patcog.2015.03.006
NR 35
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13661
EP 13678
DI 10.1007/s11042-017-4980-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900027
DA 2024-07-18
ER

PT J
AU Rajalakshmi, K
   Mahesh, K
AF Rajalakshmi, K.
   Mahesh, K.
TI ZLBM: zero level binary mapping technique for video security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy adaptive median filter (FAMF); Video steganography; Impulse noise;
   Zero level binary mapping; Block wise pixel grouping; Video embedding;
   Patch wise code formation and pixel regrouping
ID STEGANOGRAPHY; ALGORITHM
AB In recent days, providing security to data is a crucial and critical task in many image processing applications. Specifically, video security is an important and demanding concept. For this purpose, some of the embedding, encoding and decoding techniques are mentioned in existing works, but it has some drawbacks such as increased time complexity, computational complexity and memory consumption. Moreover, it does not provide high security during video transmission. To overcome all these issues, a new technique, namely, Zero Level Binary Mapping (ZLBM) is proposed in this paper for video embedding scheme. The motivation of this paper is to provide high security during video transformation by using the video steganography technique. At first, the cover and stego videos are given as the inputs and it will be converted into the video frames for further processing. Here, the Fuzzy Adaptive Median Filtering (FAMF) technique is employed to remove the impulse noise in the video frames. Then, the pixels in the filtered frames are grouped by using the block wise pixel grouping technique. After that, the frames are embedded with the help of ZLBM technique and encoded based on the patch wise code formation technique. On the receiver side, the inverse ZLBM and block wise pixel regrouping techniques are applied to get the original cover and stego videos. The novel concept of this paper is the use of ZLBM and patch wise code formation techniques for video embedding and compression. The main advantages of the proposed system are high security, good quality and reduced complexity. The experimental results evaluate the performance of the proposed video embedding technique in terms of Peak Signal-to-Noise Ratio (PSNR), Mean Squared Error (MSE), Compression Ratio (CR), Bits Per Pixel (BPP) and Signal-to-Noise Ratio (SNR).
C1 [Rajalakshmi, K.; Mahesh, K.] Alagappa Univ, Dept Comp Applicat, Karaikkudi 600006, Tamil Nadu, India.
C3 Alagappa University
RP Rajalakshmi, K (corresponding author), Alagappa Univ, Dept Comp Applicat, Karaikkudi 600006, Tamil Nadu, India.
EM rajalakshmiphd2016@gmail.com
RI K, Rajalakshmi/AAA-9607-2021
OI K, Rajalakshmi/0000-0003-0076-3107
CR Abd-El-Hafiz SK, 2014, IET IMAGE PROCESS, V8, P742, DOI 10.1049/iet-ipr.2013.0570
   [Anonymous], 2016, ARXIV161009462
   [Anonymous], IMPERIAL J INTERDISC
   [Anonymous], 2014, INT J ADV RES COMPUT
   [Anonymous], INT J ELECT COMMUN S
   [Anonymous], ARXIV14102175
   [Anonymous], INT J INNOV ADV COMP
   [Anonymous], 2016, YUV Video Sequences
   [Anonymous], INT J MAT MECH MANUF
   [Anonymous], INT J ENG SCI
   [Anonymous], EURASIP J WIRELESS C
   Boho A, 2013, IEEE SIGNAL PROC MAG, V30, P97, DOI 10.1109/MSP.2012.2230220
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Dasgupta K, 2013, PROC TECH, V10, P131, DOI 10.1016/j.protcy.2013.12.345
   Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P3194, DOI 10.1109/TIP.2012.2190080
   Gupta H, 2014, INT J COMPUT SCI NET, V14, P99
   Hsieh MH, 2013, ENG APPL ARTIF INTEL, V26, P1333, DOI 10.1016/j.engappai.2012.10.012
   Karim MSA, 2014, SIGNAL PROCESS, V94, P174, DOI 10.1016/j.sigpro.2013.06.014
   Kashyap N., 2012, INT J MODERN ED COMP, V4, P50, DOI [10.5815/ijmecs. 2012.03.07, DOI 10.5815/IJMECS.2012.03.07.[]
   Khare R., 2014, International Journal of Research in Advent Technology, V2
   Kokkonis G, 2016, J SUPERCOMPUT, P1
   Kokkonis G, 2016, J REAL-TIME IMAGE PR, V12, P343, DOI 10.1007/s11554-015-0505-7
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y.-S., 2015, Sci. World J, V2015, P2, DOI DOI 10.1016/J.LINDIF.2015.02.002
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Liu YX, 2016, NEUROCOMPUTING, V188, P113, DOI 10.1016/j.neucom.2015.02.102
   Liu YX, 2016, NEUROCOMPUTING, V188, P63, DOI 10.1016/j.neucom.2014.10.109
   Lu YF, 2017, MATH MECH SOLIDS, V22, P1997, DOI 10.1177/1081286516653272
   Maggiani L, 2015, IEEE SIGNAL PROC LET, V22, P2132, DOI 10.1109/LSP.2015.2463092
   Memos VA, 2016, J REAL-TIME IMAGE PR, V12, P473, DOI 10.1007/s11554-015-0509-3
   Ohm JR, 2013, IEEE SIGNAL PROC MAG, V30, P152, DOI 10.1109/MSP.2012.2219672
   Papadopoulos NA, 2018, J REAL-TIME IMAGE PR, V14, P75, DOI 10.1007/s11554-016-0630-y
   Pourazad MT, 2012, IEEE CONSUM ELECTR M, V1, P36, DOI 10.1109/MCE.2012.2192754
   Preotiuc-Pietro Daniel, 2017, ACL
   Psannis KE, 2006, IEEE T CIRC SYST VID, V16, P280, DOI 10.1109/TCSVT.2005.859933
   Psannis K, 2008, IEICE T COMMUN, VE91B, P2692, DOI 10.1093/ietcom/e91-b.8.2692
   Psannis K, 2009, IEICE ELECTRON EXPR, V6, P1497, DOI [10.1587/elex.6.1497, 10.1587/elex.6.1437]
   Psannis K, 2008, IEICE ELECTRON EXPR, V5, P827, DOI 10.1587/elex.5.827
   Psannis KE, 2016, J REAL-TIME IMAGE PR, V12, P509, DOI 10.1007/s11554-015-0514-6
   Psannis KE, 2009, TELECOMMUN SYST, V41, P65, DOI 10.1007/s11235-009-9151-3
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   RAMALINGAM M, 2015, INDIAN J SCI TECHNOL, V8, P79
   Ramanjaneyulu K, 2012, IET IMAGE PROCESS, V6, P364, DOI 10.1049/iet-ipr.2010.0347
   Sadek MM, 2015, MULTIMED TOOLS APPL, V74, P7063, DOI 10.1007/s11042-014-1952-z
   Singh P., 2013, INT J ENG INNOV TECH, V2, P165
   Venugopala PS, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P259, DOI 10.1109/ICSIP.2014.47
   Wajgade VM., 2013, INT J EMERGING TECHN, V3, P549
   Wang WJ, 2013, INFORM SCIENCES, V246, P69, DOI 10.1016/j.ins.2013.05.007
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
   Zong TR, 2015, IEEE T CIRC SYST VID, V25, P717, DOI 10.1109/TCSVT.2014.2363743
NR 54
TC 7
Z9 7
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13225
EP 13247
DI 10.1007/s11042-017-4942-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900008
DA 2024-07-18
ER

PT J
AU Bo, CJ
   Lu, HC
   Wang, D
AF Bo, Chunjuan
   Lu, Huchuan
   Wang, Dong
TI Spectral-spatial K-Nearest Neighbor approach for hyperspectral image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral image classification; KNN; Spectral-spatial; Joint model
ID JOINT COLLABORATIVE REPRESENTATION; REMOTE-SENSING IMAGES;
   SPARSE-REPRESENTATION; LOGISTIC-REGRESSION; ATTRIBUTE PROFILES; ANOMALY
   DETECTION; SUPPORT; GENERATION; FUSION; COVER
AB Hyperspectral image (HSI) classification is a very active research topic in remote sensing and has numerous potential applications. This paper presents a simple but effective classification method based on spectral-spatial information and K-nearest neighbor (KNN). To be specific, we propose a spectral-spatial KNN (SSKNN) method to deal with the HSI classification problem, which effectively exploits the distances all neighboring pixels of a given test pixel and training samples. In the proposed SSKNN framework, a set-to-point distance is exploited based on least squares and a weighted KNN method is used to achieve stable performance. By using two standard HSI benchmark, we evaluate the proposed method by comparing it with eight competing methods. Both qualitative and quantitative results demonstrate our SSKNN method achieves better performance than other ones.
C1 [Bo, Chunjuan; Lu, Huchuan; Wang, Dong] Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116024, Peoples R China.
   [Bo, Chunjuan] Dalian Minzu Univ, Coll Electromech Engn, Dalian 116600, Peoples R China.
C3 Dalian University of Technology; Dalian Minzu University
RP Wang, D (corresponding author), Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116024, Peoples R China.
EM bcj@dlnu.edu.cn; lhchuan@dlut.edu.cn; wdice@dlut.edu.cn
RI LU, Jia-Hong/X-1395-2019
OI LU, Jia-Hong/0000-0002-1147-125X
FU Natural Science Foundation of China [61502070]; Fundamental Research
   Funds for Central Universities [DUT16RC(4)16]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant No. 61502070, and in part by Fundamental Research
   Funds for Central Universities under Grant No. DUT16RC(4)16.
CR Banerjee A, 2006, IEEE T GEOSCI REMOTE, V44, P2282, DOI 10.1109/TGRS.2006.873019
   Bannari A, 2006, REMOTE SENS ENVIRON, V104, P447, DOI 10.1016/j.rse.2006.05.018
   Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   Benediktsson JA, 2003, IEEE T GEOSCI REMOTE, V41, P1940, DOI 10.1109/TGRS.2003.814625
   Bo CJ, 2016, IEEE GEOSCI REMOTE S, V13, P177, DOI 10.1109/LGRS.2015.2504449
   Bruzzone L, 2006, IEEE T GEOSCI REMOTE, V44, P3363, DOI 10.1109/TGRS.2006.877950
   Camps-Valls G, 2006, IEEE GEOSCI REMOTE S, V3, P93, DOI 10.1109/LGRS.2005.857031
   Cevikalp H, 2010, PROC CVPR IEEE, P2567, DOI 10.1109/CVPR.2010.5539965
   Chen Y, 2013, IEEE T GEOSCI REMOTE, V51, P217, DOI 10.1109/TGRS.2012.2201730
   Chen Y, 2011, IEEE T GEOSCI REMOTE, V49, P3973, DOI 10.1109/TGRS.2011.2129595
   Chen Y, 2011, IEEE J-STSP, V5, P629, DOI 10.1109/JSTSP.2011.2113170
   Dalla Mura M, 2011, IEEE GEOSCI REMOTE S, V8, P542, DOI 10.1109/LGRS.2010.2091253
   Dalla Mura M, 2010, INT J REMOTE SENS, V31, P5975, DOI 10.1080/01431161.2010.512425
   Dalla Mura M, 2010, IEEE T GEOSCI REMOTE, V48, P3747, DOI 10.1109/TGRS.2010.2048116
   Datt B, 2003, IEEE T GEOSCI REMOTE, V41, P1246, DOI 10.1109/TGRS.2003.813206
   Du Q, 2015, P SOC PHOTO-OPT INS, V9501
   DUDANI SA, 1976, IEEE T SYST MAN CYB, V6, P327
   Gao LR, 2015, IEEE GEOSCI REMOTE S, V12, P349, DOI 10.1109/LGRS.2014.2341044
   Gualtieri JA, 1999, AIRB EARTH SCI WORKS
   Krishnapuram B, 2005, IEEE T PATTERN ANAL, V27, P957, DOI 10.1109/TPAMI.2005.127
   Larsolle A, 2007, PRECIS AGRIC, V8, P37, DOI 10.1007/s11119-006-9027-4
   Lawrence RL, 2006, REMOTE SENS ENVIRON, V100, P356, DOI 10.1016/j.rse.2005.10.014
   Li JY, 2014, ISPRS J PHOTOGRAMM, V94, P25, DOI 10.1016/j.isprsjprs.2014.04.014
   Li JY, 2014, IEEE T GEOSCI REMOTE, V52, P3707, DOI 10.1109/TGRS.2013.2274875
   Li J, 2013, IEEE T GEOSCI REMOTE, V51, P4816, DOI 10.1109/TGRS.2012.2230268
   Li W, 2015, IEEE GEOSCI REMOTE S, V12, P48, DOI 10.1109/LGRS.2014.2325978
   Li W, 2015, IEEE GEOSCI REMOTE S, V12, P389, DOI 10.1109/LGRS.2014.2343956
   Li W, 2014, IEEE J-STARS, V7, P2200, DOI 10.1109/JSTARS.2014.2306956
   Li Y, 2016, CONCURRENCY COMPUTAT
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Liu JJ, 2014, IEEE GEOSCI REMOTE S, V11, P1320, DOI 10.1109/LGRS.2013.2292831
   Manolakis D, 2002, IEEE SIGNAL PROC MAG, V19, P29, DOI 10.1109/79.974724
   Marpu PR, 2013, IEEE GEOSCI REMOTE S, V10, P293, DOI 10.1109/LGRS.2012.2203784
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Melgani F, 2002, PATTERN RECOGN LETT, V23, P1053, DOI 10.1016/S0167-8655(02)00052-1
   Moser G, 2013, IEEE T GEOSCI REMOTE, V51, P2734, DOI 10.1109/TGRS.2012.2211882
   Palmason JA, 2005, INT GEOSCI REMOTE SE, P176
   Patel NK, 2001, INT J REMOTE SENS, V22, P2401, DOI 10.1080/014311601300229881
   Pesaresi M, 2001, IEEE T GEOSCI REMOTE, V39, P309, DOI 10.1109/36.905239
   Plaza A, 2009, REMOTE SENS ENVIRON, V113, pS110, DOI 10.1016/j.rse.2007.07.028
   Qian YT, 2013, IEEE T GEOSCI REMOTE, V51, P2276, DOI 10.1109/TGRS.2012.2209657
   Shuangjiang Li, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2693, DOI 10.1109/ICIP.2011.6116223
   Soltani-Farani A, 2015, IEEE T GEOSCI REMOTE, V53, P527, DOI 10.1109/TGRS.2014.2325067
   Srinivas U, 2013, IEEE GEOSCI REMOTE S, V10, P505, DOI 10.1109/LGRS.2012.2211858
   Stein DWJ, 2002, IEEE SIGNAL PROC MAG, V19, P58, DOI 10.1109/79.974730
   Sun XX, 2014, IEEE GEOSCI REMOTE S, V11, P1235, DOI 10.1109/LGRS.2013.2290531
   Tarabalka Y, 2010, IEEE GEOSCI REMOTE S, V7, P736, DOI 10.1109/LGRS.2010.2047711
   Vincent P, 2002, ADV NEUR IN, V14, P985
   Wang ZW, 2013, INT CONF ACOUST SPEE, P3427, DOI 10.1109/ICASSP.2013.6638294
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xiong MM, 2015, IEEE GEOSCI REMOTE S, V12, P1209, DOI 10.1109/LGRS.2015.2388703
   Yang SY, 2013, INT CONF MACH LEARN, P952, DOI 10.1109/ICMLC.2013.6890419
   Yang SY, 2014, IEEE GEOSCI REMOTE S, V11, P479, DOI 10.1109/LGRS.2013.2268847
   Zhang EL, 2015, IEEE GEOSCI REMOTE S, V12, P1397, DOI 10.1109/LGRS.2015.2402971
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zomer RJ, 2009, J ENVIRON MANAGE, V90, P2170, DOI 10.1016/j.jenvman.2007.06.028
   Zou JY, 2015, IEEE GEOSCI REMOTE S, V12, P2418, DOI 10.1109/LGRS.2015.2481181
NR 57
TC 30
Z9 32
U1 2
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10419
EP 10436
DI 10.1007/s11042-017-4403-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900003
DA 2024-07-18
ER

PT J
AU Paramanandham, N
   Rajendiran, K
AF Paramanandham, Nirmala
   Rajendiran, Kishore
TI Multi sensor image fusion for surveillance applications using hybrid
   image fusion algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dwt; Edge; Roberts operator; SWPT; Spatial domain; Transform domain
ID MANY-CORE PROCESSORS; PARALLEL FRAMEWORK; WAVELET TRANSFORM; HEVC;
   NETWORKS
AB Image fusion is the process of integrating several source images into a single image that provides more reliable information along with reduced redundancy. In this paper, a hybrid image fusion algorithm for multi focus and multi modality images is presented by exploiting the advantages of both the transform as well as spatial domain techniques. In the initial image fusion framework, the source images are decomposed only once using cascaded wavelet transform and the transformed coefficients are combined according to the fusion rules. Inverse cascaded wavelet transform is applied for obtaining the initial fused image. Further, Roberts operator is used for extracting the edge information and decision rule is introduced for choosing the edges from the focused part. The extracted edge information from the focused part replaces the existing edge information in the initial fused image for enhancing the reliability of the fused image. Experiments on various types of images such as multifocus as well as multimodality images are conducted to examine the performance of the proposed algorithm. Experimental results have shown that the proposed algorithm outperforms the well known techniques in terms of both visual perception and quantitative evaluation. Furthermore, the proposed algorithm achieves a good balance between enhancing fusion quality meanwhile reducing the computational cost.
C1 [Paramanandham, Nirmala; Rajendiran, Kishore] SSN Coll Engn, Dept Elect & Commun Engn, Madras, Tamil Nadu, India.
C3 SSN College of Engineering
RP Paramanandham, N (corresponding author), SSN Coll Engn, Dept Elect & Commun Engn, Madras, Tamil Nadu, India.
EM nirmalap@ssn.edu.in
RI Paramanandham, Nirmala/ABI-7089-2020; Rajendiran, Kishore/AGJ-8384-2022
OI Rajendiran, Kishore/0000-0002-0779-6035
CR Abdipour M, 2016, COMPUT ELECTR ENG, V51, P74, DOI 10.1016/j.compeleceng.2016.03.011
   Bai XZ, 2011, IMAGE VISION COMPUT, V29, P829, DOI 10.1016/j.imavis.2011.09.003
   De I, 2013, INFORM FUSION, V14, P136, DOI 10.1016/j.inffus.2012.01.007
   Ding M, 2013, INFRARED PHYS TECHN, V57, P56, DOI 10.1016/j.infrared.2012.12.014
   Drajic D, 2007, IEEE T CONSUM ELECTR, V53, P1456, DOI 10.1109/TCE.2007.4429237
   Duran J, 2014, SIAM J IMAGING SCI, V7, P761, DOI 10.1137/130928625
   Haro G, 2012, SIAM J IMAGING SCI, V5, P1055, DOI 10.1137/120873923
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Ji XX, 2017, MULTIMED TOOLS APPL, V76, P17633, DOI 10.1007/s11042-015-2879-8
   Kausar N, 2016, COMPUT ELECTR ENG, V54, P393, DOI 10.1016/j.compeleceng.2016.01.013
   Konishi S, 2003, IEEE T PATTERN ANAL, V25, P57, DOI 10.1109/TPAMI.2003.1159946
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li HF, 2013, OPTIK, V124, P40, DOI 10.1016/j.ijleo.2011.11.088
   Li ST, 2008, PATTERN RECOGN LETT, V29, P1295, DOI 10.1016/j.patrec.2008.02.002
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Maini R, IJIP, V3, P1
   Mitianoudis N, 2008, IEEE SENS J, V8, P2016, DOI 10.1109/JSEN.2008.2007678
   Naidu VPS, 2008, DEFENCE SCI J, V58, P338
   Nejati M, 2017, INFORM FUSION, V36, P284, DOI 10.1016/j.inffus.2016.12.009
   Paramanandham Nirmala, 2015, IEEE ICCSP 2015
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Raol JitendraR., 2010, MULTISENSOR DATA FUS
   Shi WZ, 2005, INT J APPL EARTH OBS, V6, P241, DOI 10.1016/j.jag.2004.10.010
   Vijayarajan R, 2015, AEU-INT J ELECTRON C, V69, P896, DOI 10.1016/j.aeue.2015.02.007
   Wang ZJ, 2005, IEEE T GEOSCI REMOTE, V43, P1391, DOI 10.1109/TGRS.2005.846874
   Wei Zhenggang, 1999, Acta Electronica Sinica, V27, P79
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang Y, 2015, IEEE SENS J, V15, P2824, DOI 10.1109/JSEN.2014.2380153
   Yu BT, 2016, NEUROCOMPUTING, V182, P1, DOI 10.1016/j.neucom.2015.10.084
   Zhang X, 2008, PROG ELECTROMAGN RES, V86, P291, DOI 10.2528/PIER08100104
   Zhang X, 2016, MULTIMED TOOLS APPL
   Zhang XL, 2014, SIGNAL PROCESS, V102, P64, DOI 10.1016/j.sigpro.2014.02.024
   Zheng S, 2007, IEEE T IMAGE PROCESS, V16, P1831, DOI 10.1109/TIP.2007.896687
   Zheng YF, 2007, INFORM FUSION, V8, P177, DOI 10.1016/j.inffus.2005.04.003
NR 38
TC 26
Z9 33
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12405
EP 12436
DI 10.1007/s11042-017-4895-3
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100034
DA 2024-07-18
ER

PT J
AU Ahmed, R
   Riaz, MM
   Ghafoor, A
AF Ahmed, Ramsha
   Riaz, M. Mohsin
   Ghafoor, Abdul
TI Attack resistant watermarking technique based on fast curvelet transform
   and Robust Principal Component Analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Curvelet transform; Principal Component Analysis
ID SCHEME
AB Watermarking is a technique which embeds the copyright information/identifier to provide authenticity in robust and imperceptible manner. In this paper, a hybrid watermarking technique is proposed based on combination of Fast Curvelet Tansform (FCT), Robust Principal Component Analysis (RPCA) and Singular Value Decomposition (SVD). The gray-scale watermark logo is scrambled using Generalized Arnold Transform (GAT) to enhance the robustness and security. The original image is decomposed to low rank and sparse components using RPCA; the curvelet coefficients are obtained using FCT via Unequally-Spaced Fast Fourier Transforms (USFFT) to embed the processed watermark using SVD into the color image. In curvelet transform, fewer coefficients contain the most energy, also giving optimally sparse representation of the significant image features and edges that helps in efficient recovery of the embedded watermark even after severe image degradation. The robustness and imperceptibility of the proposed technique is verified against a variety of processing operations (noise, filtering) and geometric attacks (crop, resize, projection etc.). The quantitative and visual results reveal that the watermarking technique proposed is more efficient and provides high tolerance against different geometric and image processing attacks.
C1 [Ahmed, Ramsha] NUST, Informat Secur, Islamabad, Pakistan.
   [Ghafoor, Abdul] NUST, Elect Engn, Islamabad, Pakistan.
   [Riaz, M. Mohsin] COMSATS, CAST, Islamabad, Pakistan.
C3 National University of Sciences & Technology - Pakistan; National
   University of Sciences & Technology - Pakistan; COMSATS University
   Islamabad (CUI)
RP Ghafoor, A (corresponding author), NUST, Elect Engn, Islamabad, Pakistan.
EM ramsha.ahmed46@hotmail.com; mohsin.riaz@comsats.edu.pk;
   abdulghafoor-mcs@nust.edu.pk
RI Ahmed, Ramsha/ABB-9824-2021
OI Ahmed, Ramsha/0000-0002-9337-1921
CR Afandy KAA, 2016, INT C EL COMM COMP
   Ali M, 2014, SIGNAL PROCESS, V94, P545, DOI 10.1016/j.sigpro.2013.07.024
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Cedillo-Hernández M, 2014, SIGNAL IMAGE VIDEO P, V8, P49, DOI 10.1007/s11760-013-0459-9
   FAZLI S, 2015, OPTIK INT J LIGHT EL, V127, P964
   Gao GY, 2015, MULTIMED TOOLS APPL, V74, P841, DOI 10.1007/s11042-013-1701-8
   Ghafoor A., 2012, RADIOENGINEERING, V21, P1246
   Ghebleh M, 2014, SECUR COMMUN NETW, V7, P800, DOI 10.1002/sec.783
   Gunjal B.L., 2011, INT J COMPUT THEORY, V3, P714, DOI [10.7763/IJCTE.2011.V3.397, DOI 10.7763/IJCTE.2011.V3.397]
   Keshavarzian R, 2015, INT J ELECT COMMUN, V70, P278
   Khalifa mal, 2012, INT J COMPUTER APPL, V37, P33, DOI DOI 10.5120/4631-6666
   Kong F, 2010, INT C IND INF SYST
   Li J., 2016, SOFT COMPUT, P1
   Ma JW, 2010, IEEE SIGNAL PROC MAG, V27, P118, DOI 10.1109/MSP.2009.935453
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Niu PP, 2011, EXPERT SYST APPL, V38, P2081, DOI 10.1016/j.eswa.2010.07.147
   Ranjbar S, 2013, SIGNAL PROCESS-IMAGE, V28, P1526, DOI 10.1016/j.image.2013.07.002
   Shao ZH, 2016, SIGNAL PROCESS-IMAGE, V48, P12, DOI 10.1016/j.image.2016.09.001
   Tao P, 2007, INT C INT INF HID MU
   Thien HT, 2016, EXPERT SYST APPL, V62, P177, DOI 10.1016/j.eswa.2016.06.015
   Wang XY, 2015, NEUROCOMPUTING, V151, P620, DOI 10.1016/j.neucom.2014.03.091
   Xing Y, 2010, RADIOENGINEERING, V19, P62
   Zareian M, 2014, IEEE T INF FOREN SEC, V9, DOI 10.1109/TIFS.2014.2355912
   Zhu XS, 2012, INT CONF ACOUST SPEE, P1765, DOI 10.1109/ICASSP.2012.6288241
NR 24
TC 6
Z9 6
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9443
EP 9453
DI 10.1007/s11042-017-5128-5
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200016
DA 2024-07-18
ER

PT J
AU Doulamis, N
AF Doulamis, Nikolaos
TI Adaptable deep learning structures for object labeling/tracking under
   dynamic visual environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Neural adaptation; Stacked autoencoders; Object tracking
   and labeling; Industrial workflows
ID NEURAL-NETWORKS; TRACKING; RECOGNITION
AB In this paper, we propose a self-adaptive deep neural network architecture suitable for object tracking and labelling. In particular, an adaptation mechanism is introduced that automatically evaluates the performance of the network and then updates its weights to fit the current environmental conditions. The retraining algorithm trusts as much as possible the current conditions (discriminative constraints), while simultaneously providing a minimal degradation of the already obtained knowledge of the network (generative constraints). The underline assumption is that a small weight perturbation is adequate to modify the performance of the network to the new situations, without this constraint implying a small modification of the network output due to the highly non-linear surface that the network models. Under this assumption, we propose a computationally efficient re-training algorithm to tackle the variations of the visual environment, requiring a small number of labelled samples for the adaptation. Weight updating is combined with an unsupervised learning paradigm, implemented through stacked autoencoders, in order to improve convergence, stability and performance of the object tracking and labeling process by propagating the sensory inputs into deep level of hierarchies and therefore structuring the inputs from low representations to more abstract forms. Approximates of current visual environment are provided through a dynamic tracker that combines motion and learning features to automatically create few confident labeled data. The proposed retraining scheme is computationally efficient and able to model non-stationary environments, like the ones appeared in real-life computer vision application scenarios. Experimental results and comparisons are provided on video datasets of very complicated visual content, monitoring industrial workflows of car assembly within a manufactory. The results indicates that our self-adaptive deep neural network architecture is able to correctly label and separate foreground objects from background even under severe visual changes, such as occlusion, illumination variations and change of camera views, and within real time computational constraints.
C1 [Doulamis, Nikolaos] Natl Tech Univ Athens, 9 Heroon Polytech Str, GR-15773 Athens, Zografou, Greece.
C3 National Technical University of Athens
RP Doulamis, N (corresponding author), Natl Tech Univ Athens, 9 Heroon Polytech Str, GR-15773 Athens, Zografou, Greece.
EM adoulam@cs.ntua.gr
RI Doulamis, Anastasios/AAL-5972-2021
FU European Union [740610]; H2020 Societal Challenges Programme [740610]
   Funding Source: H2020 Societal Challenges Programme
FX This research work was support by the European Union funded H2020
   STOP-IT project, "Strategic, Tactical, Operational Protection of water
   Infrastructure against cyber-physical Threats," grand agreement, 740610.
CR [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], 2009, 2009 TREC VIDEO RETR
   [Anonymous], 2009, INT INT PERF PRIM IN
   [Anonymous], 2009, ADVNEURAL INF PROCES
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Chen B, 2013, IEEE T PATTERN ANAL, V35, P1887, DOI 10.1109/TPAMI.2013.19
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Denil M., 2013, P 26 INT C NEUR INF, P2148
   Doulamis A, 2003, IEEE T NEURAL NETWOR, V14, P616, DOI 10.1109/TNN.2003.810605
   Doulamis A, 2008, ACM WORKSH AN RETR E, P97
   Doulamis AD, 2003, IEEE T NEURAL NETWOR, V14, P150, DOI 10.1109/TNN.2002.806645
   Doulamis AD, 2000, IEEE T NEURAL NETWOR, V11, P137, DOI 10.1109/72.822517
   Doulamis A, 2014, MULTIMED TOOLS APPL, V69, P339, DOI 10.1007/s11042-012-0992-5
   Doulamis A, 2010, MULTIMED TOOLS APPL, V50, P49, DOI 10.1007/s11042-009-0368-7
   Doulamis A, 2009, LECT NOTES COMPUT SC, V5769, P715, DOI 10.1007/978-3-642-04277-5_72
   Doulamis N, 2016, P 9 ACM INT C PERVAS, DOI 10.1145/2910674.2935836
   Doulamis Nikolaos., 2010, Proceedings of the 3rd International Conference on PErvasive Technologies Related to Assistive Environments, P62
   Dubuisson Severine, 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P446
   Fan JL, 2010, IEEE T NEURAL NETWOR, V21, P1610, DOI 10.1109/TNN.2010.2066286
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kandylakis Z, 2015, WORK HYPERSP IMAG
   Kang YM, 2015, J SIGNAL PROCESS SYS, V81, P197, DOI 10.1007/s11265-014-0935-7
   Kokkinos M, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/54049
   Kosmopoulos DI, 2009, SIGNAL PROCESS-IMAGE, V24, P158, DOI 10.1016/j.image.2008.12.010
   Kosmopoulos DI, 2012, COMPUT VIS IMAGE UND, V116, P422, DOI 10.1016/j.cviu.2011.09.006
   Lalos C, 2014, MULTIMED TOOLS APPL, V69, P277, DOI 10.1007/s11042-012-0994-3
   Larochelle H, 2009, J MACH LEARN RES, V10, P1
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee H., 2009, P 26 ANN INT C MACH, P609
   Lucas B., 1981, Proc. DARPA Image Understanding Workshop, P121
   Luenberger DG, 1984, LINEAR NONLINEAR PRO
   Luo P, 2012, PROC CVPR IEEE, P2480, DOI 10.1109/CVPR.2012.6247963
   Makantasis K, 2015, LECT NOTES COMPUT SC, V9474, P717, DOI 10.1007/978-3-319-27857-5_64
   Makantasis K, 2015, INT GEOSCI REMOTE SE, P4959, DOI 10.1109/IGARSS.2015.7326945
   Makantasis K, 2015, INT C INTELL COMP CO, P335, DOI 10.1109/ICCP.2015.7312681
   Nater F., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1912, DOI 10.1109/ICCVW.2011.6130482
   Norouzi M, 2009, PROC CVPR IEEE, P2727
   Protopapadakis E, 2015, LECT NOTES COMPUT SC, V9474, P706, DOI 10.1007/978-3-319-27857-5_63
   Ranzato MA., 2007, CVPR, DOI [10.1109/cvpr.2007.383157, 10.1109/CVPR.2007.383157]
   Salakhutdinov R., 2007, P 24 INT C MACHINE L, P791
   Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465
   Shi J, 2004, INT IEEE INT C COMP, P593
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Voulodimos A, 2012, IEEE MULTIMEDIA, V19, P42, DOI 10.1109/MMUL.2012.31
   Weston J, 2010, MACH LEARN, V81, P21, DOI 10.1007/s10994-010-5198-3
   Zeiler MD, 2013, INT CONF ACOUST SPEE, P3517, DOI 10.1109/ICASSP.2013.6638312
   Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957
NR 54
TC 12
Z9 18
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9651
EP 9689
DI 10.1007/s11042-017-5349-7
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200023
DA 2024-07-18
ER

PT J
AU Fan, TK
AF Fan, Tongke
TI Research and implementation of user clustering based on MapReduce in
   multimedia big data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia big data; Cloud computing; Hadoop; MapReduce; Clustering
   algorithm
AB Poor understanding and low clustering efficiency of massive data is a problem under the context of big data. To solve this problem, Canopy + K-means clustering algorithm is proposed, and the MapReduce programming model is used to make full use of the computing and storage capacity of Hadoop cluster. Large quantities of buyers on taobao are taken as application context to do case study through Hadoop platform's data mining set Mahout. General procedure for miming with Mahout is also given. Clustering algorithm based on MapReduce shows preferable clustering quality and operation speed. Comparison is made between Canopy + K-means algorithm and K-means algorithm in respect of runtime, speed-up ratio and extendibility. Test is conducted for these two clustering algorithms on clusters with different numbers of nodes in context of dataset of various scales. The experimental results show that Canopy + K-means algorithm has faster operation speed than K-means algorithm, but both of them show good speed-up ratio under Hadoop environment and Canopy + K-means algorithm is even much better K-means algorithm.
C1 [Fan, Tongke] Xian Int Univ, Sch Informat & Network, Xian 710077, Shaanxi, Peoples R China.
RP Fan, TK (corresponding author), Xian Int Univ, Sch Informat & Network, Xian 710077, Shaanxi, Peoples R China.
EM fantongke@126.com
FU Scientific research project of Shaanxi Provincial Education Department
   [15JK2113]; Xi'an social science research project (special for Xi'an
   International University) [161 N08]
FX This work was supported by the Scientific research project 2015 of
   Shaanxi Provincial Education Department (NO. 15JK2113) and the Xi'an
   social science research project (special for Xi'an International
   University) (NO. 161 N08). The authors would like to thank the anonymous
   reviewers and the editor for the very instructive suggestions that led
   to the much improved quality of this paper.
CR [Anonymous], 2006, Advances in neural information processing systems
   Cai B, 2013, HADOOP TECHNIQUE IN
   Capriolo E, 2013, HIVE PROGRAMMING GUI
   Chen Q, 2009, J COMPUT APPL, V26, P2
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Dong XC, 2013, HADOOP TECHNIQUE IN
   Ericson K, 2013, FUTURE GENER COMP SY, V29, P1024, DOI 10.1016/j.future.2012.05.026
   Fan DL, 2015, HADOOP MASSIVE DATA, P290
   Fan Z, 2014, MAHOUT ALGORITHM INT
   Giacomelli P, 2014, APACHE MAHOUT COOKBO
   Han J, 2012, MOR KAUF D, P1
   Highland F, 2012, PROCEDIA COMPUT SCI, V12, P212, DOI 10.1016/j.procs.2012.09.058
   Jiang X., 2011, J HUAZHONG U SCI TEC, V39, P120
   Li Wen-hai, 2014, Computer Engineering and Design, V35, P130
   Li YA, 2010, MAPREDUCE BASED CLUS
   Niu YH, 2015, COMPUTER SCI, P465
   Owen Sean., 2010, MAHOUT ACTION
   Pan WB, 2013, RES APPL PARALLEL K
   Polo J, 2010, IEEE IFIP NETW OPER, P373, DOI 10.1109/NOMS.2010.5488494
   Tan PN, 2007, INTRO DATA MINING, P490
   Wegener D, 2009, INT CONF DAT MIN WOR, P296, DOI 10.1109/ICDMW.2009.34
   White T., 2011, Hadoop: The Definitive Guide, Vsecond
   Wu X., 2013, The Top Ten Algorithms in Data Mining
   Yu C., 2014, Computer Science, V41, P316
   Zhu Q, 2013, B SCI TECHNOL, V29, P35
NR 25
TC 15
Z9 15
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 10017
EP 10031
DI 10.1007/s11042-017-4825-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200043
DA 2024-07-18
ER

PT J
AU Raghavendra, S
   Girish, S
   Geeta, CM
   Buyya, R
   Venugopal, KR
   Iyengar, SS
   Patnaik, LM
AF Raghavendra, S.
   Girish, S.
   Geeta, C. M.
   Buyya, Rajkumar
   Venugopal, K. R.
   Iyengar, S. S.
   Patnaik, L. M.
TI Split keyword fuzzy and synonym search over encrypted cloud data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Data privacy; Keyword search; Searchable encryption;
   Synonym search
ID PUBLIC-KEY ENCRYPTION; SIMILARITY SEARCH; SEMANTIC SEARCH; RANKED
   SEARCH; SCHEME; SECURE
AB A substitute solution for various organizations of data owners to store their data in the cloud using storage as a service(SaaS). The outsourced sensitive data is encrypted before uploading into the cloud to achieve data privacy. The encrypted data is search based on keywords and retrieve interested files by data user using a lot of traditional Search scheme. Existing search schemes supports exact keyword match or fuzzy keyword search, but synonym based multi-keyword search are not supported. In the real world scenario, cloud users may not know the exact keyword for searching and they might give synonym of the keyword as the input for search instead of exact or fuzzy keyword due to lack of appropriate knowledge of data. In this paper, we describe an efficient search approach for encrypted data called as Split Keyword Fuzzy and Synonym Search (S K F S). Multi-keyword ranked search with accurate keyword and Fuzzy search supports synonym queries are a major contribution of SKFS. The wildcard Technique is used to store the keywords securely within the index tree. Index tree helps to search faster, accurate and low storage cost. Extensive experimental results on real-time data sets shows, the proposed solution is effective and efficient for multi-keyword ranked search and synonym queries Fuzzy based search over encrypted cloud data.
C1 [Raghavendra, S.; Girish, S.; Geeta, C. M.; Venugopal, K. R.] Univ Visvesvaraya, Coll Engn, Bengaluru, India.
   [Buyya, Rajkumar] Univ Melbourne, Dept Comp & Informat Syst, Cloud Comp & Distributed Syst CLOUDS Lab, Melbourne, Vic, Australia.
   [Iyengar, S. S.] Florida Int Univ, Miami, FL 33199 USA.
   [Patnaik, L. M.] Natl Inst Adv Studies, Bengaluru, India.
C3 University of Melbourne; State University System of Florida; Florida
   International University
RP Raghavendra, S (corresponding author), Univ Visvesvaraya, Coll Engn, Bengaluru, India.
EM raghush86@gmail.com
RI Mara, Geeta/GXG-3384-2022; Patnaik, Mohan/AAH-8735-2020; Buyya,
   Rajkumar/C-3424-2009
OI Mara, Geeta/0000-0003-3547-9317; S, Raghavendra/0000-0003-2733-3916;
   Buyya, Rajkumar/0000-0001-9754-6496
CR [Anonymous], 2013, NATL SCI FDN RES AWA
   Balamuralikrishna T, 2013, ASIAN J COMPUT SCI I, V1
   Bijral S, 2014, ARXIV14116773
   Cao N, 2014, IEEE T PARALL DISTR, V25, P222, DOI 10.1109/TPDS.2013.45
   ChinnaSamy R., 2012, 2012 International Conference on Recent Trends in Information Technology (ICRTIT), P488, DOI 10.1109/ICRTIT.2012.6206776
   Chuah M., 2011, Proceedings of the 2011 31st International Conference on Distributed Computing Systems Workshops (ICDCS Workshops), P273, DOI 10.1109/ICDCSW.2011.11
   Cong Wang, 2011, Proceedings of the 2011 31st International Conference on Distributed Computing Systems Workshops (ICDCS Workshops), P282, DOI 10.1109/ICDCSW.2011.16
   Fu ZM, 2014, INT J ADV MANUF TECH, V71, P357, DOI 10.1007/s00170-013-5289-y
   Fu ZJ, 2014, SCC'14: PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON SECURITY IN CLOUD COMPUTING, P59, DOI 10.1145/2600075.2600081
   Fu ZJ, 2014, IEEE T CONSUM ELECTR, V60, P762, DOI 10.1109/TCE.2014.7027353
   Fu ZJ, 2014, IEEE T CONSUM ELECTR, V60, P164, DOI 10.1109/TCE.2014.6780939
   He Tuo, 2013, 2013 5th International Conference on Intelligent Networking and Collaborative Systems, P786, DOI 10.1109/INCoS.2013.150
   Jie W, 2014, 2014 IEEE 12TH INTERNATIONAL CONFERENCE ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING (DASC)/2014 IEEE 12TH INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTING (EMBEDDEDCOM)/2014 IEEE 12TH INTERNATIONAL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING (PICOM), P91, DOI 10.1109/DASC.2014.25
   Khan NM, 2014, IEEE INT CONF COMP, P24, DOI 10.1109/CIVEMSA.2014.6841433
   Ko J, 2014, IEEE INT CONF MOB DA, P245, DOI 10.1109/MDM.2014.36
   Mehrotra S, 2010, IEEE INT CON MULTI, P1, DOI 10.1109/ICME.2010.5582531
   Moh TS, 2014, 2014 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS), P382, DOI 10.1109/HPCSim.2014.6903711
   Raghavendra S, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING AND NETWORK COMMUNICATIONS (COCONET), P374, DOI 10.1109/CoCoNet.2015.7411213
   Raghavendra S., 2015, P 6 ANN INT C ICT BI
   Raghavendra S, 2016, INT J COMPUT SCI INF, V14
   Raghavendra S., 2015, 12 IEEE IND INT C E3
   Shekokar N, 2015, PROCEDIA COMPUT SCI, V45, P499, DOI 10.1016/j.procs.2015.03.089
   Sun W., 2013, Proceedings of the 8th ACM SIGSAC Symposium on Information, Computer and Communications Security, P71
   Sun WH, 2014, IEEE T PARALL DISTR, V25, P3025, DOI 10.1109/TPDS.2013.282
   Wang B, 2014, IEEE INFOCOM SER, P2112, DOI 10.1109/INFOCOM.2014.6848153
   Wang C, 2012, IEEE INFOCOM SER, P451, DOI 10.1109/INFCOM.2012.6195784
   Wang C, 2012, IEEE T PARALL DISTR, V23, P1467, DOI 10.1109/TPDS.2011.282
   Wang DS, 2013, INT CONF CLOUD COMP, P663, DOI 10.1109/CloudCom.2013.94
   Wang JF, 2013, COMPUT SCI INF SYST, V10, P667, DOI 10.2298/CSIS121104028W
   Xia Q, 2015, J UNIVERS COMPUT SCI, V21, P440
   Xia ZH, 2013, INT J FUTUR GENER CO, V6, P71, DOI 10.14257/ijfgcn.2013.6.6.08
   Xu P, 2013, IEEE T COMPUT, V62, P2266, DOI 10.1109/TC.2012.215
   Xu QQ, 2013, 2013 INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES (PDCAT), P239, DOI 10.1109/PDCAT.2013.44
   Yuan D, 2013, IEEE T PARALL DISTR, V24, P1234, DOI 10.1109/TPDS.2013.20
   Zhou W., 2013, Journal of Software Engineering and Applications, V6, P29, DOI [10.4236/jsea.2013.61004, DOI 10.4236/JSEA.2013.61004]
NR 35
TC 3
Z9 4
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 10135
EP 10156
DI 10.1007/s11042-017-5055-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200050
DA 2024-07-18
ER

PT J
AU Chang, YC
   Hsieh, CM
AF Chang, Yu-Ching
   Hsieh, Chi-Min
TI Filmic framing in video games: a comparative analysis of screen space
   design
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Screen space; Eye space; Filmic framing; Game design; Gameplay
AB The screen space, also known as the eye space of players, is the main component of game design in that it has not only direct interactions with players but also profound impacts on gameplay. Screen space design in games appears to adopt multiple conventions from film theory; however, discussions of the influences or rules related to these patterns are rare. Therefore, the main question of this article concerns the possible relevance of framing the screen space in films and video games, primarily by the means of content analysis comparison. Games have a cross-disciplinary nature. In order to discover their unique mechanics, possibilities, and trends; this research, based on cinematic framing techniques, uses a qualitative descriptive approach to analyze the design and strategy of the visual perspective that is determined by monitors in popular and classic games. This work also attempts to identify the commonalities and differences between games and movies. It is hoped that this research will serve as a reference for future studies and provide some insights into both game design and other visual multimedia applications.
C1 [Chang, Yu-Ching; Hsieh, Chi-Min] Natl Chiao Tung Univ, Inst Appl Arts, 1001 Univ Rd, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Chang, YC (corresponding author), Natl Chiao Tung Univ, Inst Appl Arts, 1001 Univ Rd, Hsinchu 300, Taiwan.
EM rainnysunny@gmail.com; chimin.hsieh@gmail.com
CR Aarseth E., 2001, Game Studies, V1
   Aarseth Espen, 1997, Cybertext: Perspectives on ergodic literature
   Adams E., 2012, Game Mechanics: Advanced Game Design
   [Anonymous], 1991, Film directing shot by shot: visualizing from concept to screen
   Arjoranta J, 2017, GAMES CULT, V12, P696, DOI 10.1177/1555412015596271
   Arsenault D, 2015, LOADING J CANADIAN G, V9, P88
   Bordwell D., 2008, FILM ART INTRO, VEighth
   Boyd Davis S., 2002, Digital Creativity, V13, P71, DOI 10.1076/digc.13.2.71.3202
   Brown Blain., 2011, Cinematography: Theory and Practice
   Chang Yu-Ching., 2017, Art and Design Review, V05, P84, DOI [10.4236/adr.2017.51007, DOI 10.4236/ADR.2017.51007]
   Chen XL, 2008, INT J HERIT STUD, V14, P229, DOI 10.1080/13527250801953710
   Friedman A, 2015, GAMES CULT, V10, P291, DOI 10.1177/1555412014559977
   Galloway AlexanderR., 2006, GAMING ESSAYS ALGORI, V18, DOI DOI 10.5749/J.CTTTSS5P
   Gaynor S, 2013, AAA LEV DES DAY BOOT
   Giannetti L., 2001, Understanding Movies
   Girina Ivan., 2013, Interactive Storytelling, Lecture Notes in Computer Science, P45, DOI [10.1007/978-3-319-02756-2_5, DOI 10.1007/978-3-319-02756-2_5]
   Jones M, 2005, IM WORLDS S SYDN AUS
   Joseph MASCELLI., 1998, The Five C's of Cinematography - Motion Picture Filming Techniques
   Juul J., 2001, GAME STUDIES, V1, P1
   Lakin C. S., 2014, SHOOT YOUR NOVEL CIN
   Logas H, 2005, P 2005 DIGRA INT C C
   Manovich Lev, 2001, The Language of new media
   MATEAS M, 2005, DIGRA CHANGING VIEWS
   Mateas M., 2006, The game design reader, P642
   Mercado Gustavo., 2013, FILMMAKERS EYE LEARN
   Morris Sue., 2002, SCREENPLAY, P81
   Natkin S, 2010, IFIP ADV INF COMM TE, V333, P160
   Nitsche M, 2005, DIGRA CHANG VIEWS WO
   Nitsche M., 2008, Video Game Spaces: Image, Play, and Structure in 3D Worlds
   Nitsche M, 2006, P FUTUREPLAY 2006 ON
   Papale Luca., 2014, Journal of Game Criticism, V1, P1
   Persson P, 1998, FRAMEWORK DESIGN EVA
   Seif El-Nasr M., 2006, P 2006 ACM SIGCHI IN, DOI DOI 10.1145/1178823.1178849
   Sicart M, 2008, GAME STUDIES, V8, P1604
   Stadler J., 2009, SCREEN MEDIA ANAL FI
   Thomas D, 2005, DIGEA CHANGING VIEWS
   Thompson R., 2009, GRAMMAR OF THE SHOT
   Town C, 2003, LECT NOTES COMPUT SC, V2626, P54
   Tumminello W, 2004, EXPLORING STORYBOARD
   Villarejo A, 2007, FILM STUDIES: THE BASICS, P1
   Wolf Mark., 2001, MEDIUM VIDEO GAME, P51
   Wolf MJP, 2011, DIGAREC SERIES, V06
   Wood A, 2012, GAMES CULT, V7, P87, DOI 10.1177/1555412012440310
   Zagal JP, 2010, SIMULAT GAMING, V41, P844, DOI 10.1177/1046878110375594
NR 44
TC 2
Z9 3
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6531
EP 6554
DI 10.1007/s11042-017-4564-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700005
DA 2024-07-18
ER

PT J
AU Chen, HC
   Wo, Y
   Han, GQ
AF Chen, Haichao
   Wo, Yan
   Han, Guoqiang
TI Multi-granularity geometrically robust video hashing for tampering
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video hashing; Multi-granularity; Tampering detection; Geometric
   invariant; Temporal de-synchronization
ID AUTHENTICATION; PROJECTIONS
AB The wide-spread video editing tools make it much easier to tamper a video, which raises a huge need for authentication techniques that can prove the originality of video content and locate the tampered regions on the video sequences. In this paper, a multi-granularity geometrically robust video hashing method is proposed for tampering detection and localization. In order to balance the robustness and sensitiveness, we describe a video from three levels of granularity: frame sequence level, block level and pixel level, and then hashes are generated at these three levels. Polar Complex Exponential Transform (PCET) moments are calculated on the low-pass sub-band of 3D Discrete Wavelet Transform (3D-DWT) on frame sequence to extract geometric invariant spatio-temporal hash, which is used for video authentication. Local PCET moments are calculated on annular and angular blocks, which are used for geometric correction and coarse tampering localization. Position information of salient objects is obtained from saliency map for fine tampering localization. Experimental results show that the proposed method is robust against temporal de-synchronization and geometrical transformation, and has high tampering localization accuracy even when the video is rotated. Compared with state-of-the-art methods, it is more robust against content-preserving operations and more sensitive to malicious manipulations.
C1 [Chen, Haichao; Wo, Yan; Han, Guoqiang] South China Univ Technol, Coll Comp Sci & Engn, Guangzhou 510641, Guangdong, Peoples R China.
C3 South China University of Technology
RP Wo, Y (corresponding author), South China Univ Technol, Coll Comp Sci & Engn, Guangzhou 510641, Guangdong, Peoples R China.
EM woyan@scut.edu.cn
RI CHEN, HAICHAO/JTV-7262-2023
FU Guangdong Province Special funds for University-Industry Cooperation
   [2013B090500015]; Science and Technology Planning Project of Guangdong
   Province, China [2016B090918042]; National Natural Science Foundation of
   China [61472145]; National Natural Science Foundation of Guangdong
   [2016A030313472]
FX This paper is supported by National Natural Science Foundation of
   Guangdong (No. 2016A030313472); National Natural Science Foundation of
   China (Grant No. 61472145); Guangdong Province Special funds for
   University-Industry Cooperation (No. 2013B090500015); Science and
   Technology Planning Project of Guangdong Province, China (No.
   2016B090918042).
CR [Anonymous], 2010, J COMPUT INFORM SYST
   [Anonymous], AUTOMATIC DETECTION
   [Anonymous], IM PROC 2007 ICIP 20
   Ceri S., 2013, Web information retrieval, P3, DOI [10.1007/978-3-642-39314-3_1, DOI 10.1007/978-3-642-39314-3_1]
   Coskun B, 2006, IEEE T MULTIMEDIA, V8, P1190, DOI 10.1109/TMM.2006.884614
   De Roover C, 2005, IEEE T SIGNAL PROCES, V53, P4020, DOI 10.1109/TSP.2005.855414
   Karthikeyan A, 2013, INT J ENG SCI INNOVA, V2
   Kumar CA, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2123, DOI 10.1109/WiSPNET.2016.7566517
   Lee S.S., 2006, Interactions: UCLA Journal of Education and Information Studies, V2, P2
   Lee S, 2008, IEEE T CIRC SYST VID, V18, P983, DOI 10.1109/TCSVT.2008.920739
   Lee S, 2008, INT CONF ACOUST SPEE, P1237
   Li M., 2011, P IEEE RAD FREQ INT, P1, DOI DOI 10.1109/RFIC.2011.5940608
   Li M, 2012, IEEE T IMAGE PROCESS, V21, P4397, DOI 10.1109/TIP.2012.2206036
   Lu WJ, 2014, IEEE ACCESS, V2, P125, DOI 10.1109/ACCESS.2014.2307057
   Malekesmaeili M, 2009, EIGHTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P69, DOI 10.1109/ICMLA.2009.32
   Nie X., 2011, J. Comput. Inf. Syst., V7, P2112
   Ouyang, 2016, MULTIMED TOOLS APPL, P1
   Saikia N., 2011, P NAT C COMM NCC BAN, P1
   Saikia N, 2015, 2015 INTERNATIONAL CONFERENCE ON GREEN COMPUTING AND INTERNET OF THINGS (ICGCIOT), P694, DOI 10.1109/ICGCIoT.2015.7380552
   Wang XF, 2015, IEEE T INF FOREN SEC, V10, P1336, DOI 10.1109/TIFS.2015.2407698
   Willems Geert., 2008, PROCEEDING 1 ACM INT, P283
   Wo Y, 2015, SIGNAL PROCESS-IMAGE, V30, P121, DOI 10.1016/j.image.2014.10.004
   Wo Yan, 2012, Journal of South China University of Technology, V40, P23, DOI 10.3969/j.issn.1000-565X.2012.04.004
   Yan CP, 2016, SIGNAL PROCESS, V121, P1, DOI 10.1016/j.sigpro.2015.10.027
   Yap PT, 2010, IEEE T PATTERN ANAL, V32, P1259, DOI 10.1109/TPAMI.2009.119
   Zhao Y, 2013, IEEE T INF FOREN SEC, V8, P55, DOI 10.1109/TIFS.2012.2223680
NR 26
TC 12
Z9 12
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5303
EP 5321
DI 10.1007/s11042-017-4434-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800010
DA 2024-07-18
ER

PT J
AU Chutani, S
   Goyal, A
AF Chutani, Shaveta
   Goyal, Anjali
TI Improved universal quantitative steganalysis in spatial domain using ELM
   ensemble
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Universal quantitative steganalysis; Extreme learning machines (ELM);
   Ensemble learning; Random subspaces
ID RANDOM SUBSPACE METHOD; EXTREME LEARNING-MACHINE; STEGANOGRAPHY;
   REGRESSION
AB Quantitative steganalysis seeks to extract the additional information about the hidden message in the covert communications. Most of the quantitative steganalyzers available in the literature target a specific embedding algorithm and generally extract the payload information using structural paradigm. Modern steganalyzers use supervised machine learning to estimate the stego payload using sophisticated feature sets. In this paper, an Ensemble Framework based universal quantitative steganalyzer for digital images is proposed which employs optimised Extreme Learning Machines as the base regressors. The framework exploits inherent diversity of the base regressor and the use of random subspaces of the image features further reduces the prediction error. The proposed ensemble regressor exhibits improved payload predictions when evaluated vis-A -vis the individual base regressor and other state-of-the-art algorithms. The experimental results across different embedding algorithms, image datasets and variedly sized feature sets demonstrate the robustness and wide applicability of the proposed framework.
C1 [Chutani, Shaveta] IK Gujral Punjab Tech Univ, Kapurthala, Punjab, India.
   [Goyal, Anjali] GNIMT, Dept Comp Applicat, Ludhiana, Punjab, India.
C3 I. K. Gujral Punjab Technical University
RP Chutani, S (corresponding author), IK Gujral Punjab Tech Univ, Kapurthala, Punjab, India.
EM shaveta.chutani@gmail.com
RI CHUTANI, SHAVETA/AAV-4717-2021
OI CHUTANI, SHAVETA/0000-0001-5352-4148
CR [Anonymous], 2002, Matrices: Theory and Applications
   [Anonymous], 2012, LECT NOTES COMPUTER
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bertoni A, 2005, NEUROCOMPUTING, V63, P535, DOI 10.1016/j.neucom.2004.07.007
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P7973, DOI 10.1007/s11042-016-3449-4
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   DASARATHY BV, 1979, P IEEE, V67, P708, DOI 10.1109/PROC.1979.11321
   Drucker H, 1997, ADV NEUR IN, V9, P155
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Freund Y., 1996, INT C MACHINE LEARNI, P148
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Fridrich J, 2006, P SOC PHOTO-OPT INS, V5306, P23
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Guan QX, 2011, LECT NOTES COMPUT SC, V6526, P266, DOI 10.1007/978-3-642-18405-5_22
   HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Hou XD, 2016, SIGNAL PROCESS-IMAGE, V47, P72, DOI 10.1016/j.image.2016.05.011
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Jacobs RA, 1991, NEURAL COMPUT, V3, P79, DOI 10.1162/neco.1991.3.1.79
   Ker AK, 2006, P SOC PHOTO-OPT INS, V6072, P1
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kodovsky J, 2013, QUANTITATIVE STEGANA
   Kodovsky J, 2012, IEEE T INF FORENSICS, V7
   Kodovsky J, 2013, SPIE ELECT IMAGING M, P8665
   Lai C, 2006, PATTERN RECOGN LETT, V27, P1067, DOI 10.1016/j.patrec.2005.12.018
   Lerch-Hostalot D, 2016, ENG APPL ARTIF INTEL, V50, P45, DOI 10.1016/j.engappai.2015.12.013
   Miche Y, 2010, SERIES TKK DISSERTAT, V20
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Petitcolas F, 1999, P IEEE, P87
   Pevny T, 2012, IEEE T INF FOREN SEC, V7, P445, DOI 10.1109/TIFS.2011.2175918
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Piva A, 2007, P SPIE ELECT IMAGING, V6505
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Sajedi H, 2016, J INF SECUR APPL, V30, P3, DOI 10.1016/j.jisa.2016.04.001
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Sharif A, 2017, MULTIMED TOOLS APPL, V76, P7849, DOI 10.1007/s11042-016-3398-y
   Skiljan I, 2005, IRFANVIEW VERSION 4
   Skurichina M, 2002, PATTERN ANAL APPL, V5, P121, DOI 10.1007/s100440200011
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   *US DEP AGR, 2002, NAT RES CONS SERV PH
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xu B, 2007, ICNC 2007: THIRD INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 3, PROCEEDINGS, P215
   Zhang T, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P545
NR 48
TC 11
Z9 11
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7447
EP 7468
DI 10.1007/s11042-017-4656-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700047
DA 2024-07-18
ER

PT J
AU Ghouti, L
AF Ghouti, Lahouari
TI A new perceptual video fingerprinting system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video content summarization; Video fingerprinting; Robustness and
   security of fingerprinting codes; Video content identification; Video
   content authentication; Video content forgery detection
ID HASHING ALGORITHM; SHIFT PROPERTY; ROBUST; TRANSFORM; DCTS
AB Search, retrieval and storage of video content over the Internet and online repositories can be efficiently improved using compact summarizations of this content. Robust and perceptual fingerprinting codes, extracted from local video features, are astutely used for identification and authentication purposes. Unlike existing fingerprinting schemes, this paper proposes a robust and perceptual fingerprinting solution that serves both video content identification and authentication. While content identification is served by the robustness of the proposed fingerprinting codes to content alterations and geometric attacks, their sensitivity to malicious attacks makes them fit for forgery detection and authentication. This dual usage is facilitated by a new concept of sequence normalization based on the circular shift properties of the discrete cosine and sine transforms (DCT and DST). Sequences of local features are normalized by estimating the circular shift required to align each of these sequences to a reference sequence. The fingerprinting codes, consisting of normalizing shifts, are properly modeled using information-theoretic concepts. Security, robustness and sensitivity analysis of the proposed scheme is provided in terms of the security of the secret keys used during the proposed normalization stage. The computational efficiency of the proposed scheme makes it appropriate for large scale and online deployment. Finally, the robustness (identification-based) and sensitivity (authentication-based) of the proposed fingerprinting codes to content alterations and geometric attacks is evaluated over a large set of video sequences where they outperform existing DCT-based codes in terms of robustness, discriminability and sensitivity to moderate and large size intentional alterations.
C1 [Ghouti, Lahouari] King Fahd Univ Petr & Minerals, Dept Informat & Comp Sci, Dhahran 31261, Saudi Arabia.
C3 King Fahd University of Petroleum & Minerals
RP Ghouti, L (corresponding author), King Fahd Univ Petr & Minerals, Dept Informat & Comp Sci, Dhahran 31261, Saudi Arabia.
EM lahouari@kfupm.edu.sa
OI Ghouti, Lahouari/0000-0002-6381-4250
FU King Fahd University of Petroleum and Minerals
FX The author would like to thank King Fahd University of Petroleum and
   Minerals for supporting this work.
CR [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], RIAA IFPI REQUEST IN
   [Anonymous], YUV VIDEO SEQUENCES
   [Anonymous], 2012, MATRIX COMPUTATIONS
   [Anonymous], [No title captured]
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2004 INT C IM PROC
   [Anonymous], ELECT IMAGING 2008
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], 2016, J. Signal Inf. Process, DOI [10.4236/jsip.2016.72010, DOI 10.4236/JSIP.2016.72010]
   [Anonymous], SIGNAL PROCESS UNPUB
   [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], FDN CRYPTOGRAPHY BAS
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], 2014, DISCRETE COSINE TRAN
   [Anonymous], PHOTONICS W 98 ELECT
   [Anonymous], [No title captured]
   [Anonymous], 2009, FDN CRYPTOGRAPHY
   Cannons J, 2004, IEEE T IMAGE PROCESS, V13, P1393, DOI 10.1109/TIP.2004.834660
   Chiu CY, 2008, IEEE T CIRC SYST VID, V18, P412, DOI 10.1109/TCSVT.2008.918447
   Coskun B, 2006, IEEE T MULTIMEDIA, V8, P1190, DOI 10.1109/TMM.2006.884614
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   De Roover C, 2005, IEEE T SIGNAL PROCES, V53, P4020, DOI 10.1109/TSP.2005.855414
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Douze M, 2010, IEEE T MULTIMEDIA, V12, P257, DOI 10.1109/TMM.2010.2046265
   Esmaeili MM, 2011, IEEE T INF FOREN SEC, V6, P213, DOI 10.1109/TIFS.2010.2097593
   Fridrich J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P178, DOI 10.1109/ITCC.2000.844203
   Gueziec AP, 1997, IEEE COMPUT SCI ENG, V4, P29, DOI 10.1109/99.641607
   Haitsma J, 2003, J NEW MUSIC RES, V32, P211, DOI 10.1076/jnmr.32.2.211.16746
   Katzenbeisser S, 2008, IEEE T INF FOREN SEC, V3, P783, DOI 10.1109/TIFS.2008.2002939
   Lee S, 2009, IEEE INT CON MULTI, P1386, DOI 10.1109/ICME.2009.5202762
   Lee S, 2008, IEEE T CIRC SYST VID, V18, P983, DOI 10.1109/TCSVT.2008.920739
   Lee S, 2009, IEEE T CIRC SYST VID, V19, P1379, DOI 10.1109/TCSVT.2009.2022801
   Li M, 2015, IEEE T INF FOREN SEC, V10, P1727, DOI 10.1109/TIFS.2015.2425362
   Li M, 2014, IEEE IMAGE PROC, P5362, DOI 10.1109/ICIP.2014.7026085
   Li M, 2013, IEEE T INF FOREN SEC, V8, P1709, DOI 10.1109/TIFS.2013.2278100
   Li M, 2012, IEEE T IMAGE PROCESS, V21, P4397, DOI 10.1109/TIP.2012.2206036
   Liu YF, 2016, J VIS COMMUN IMAGE R, V36, P80, DOI 10.1016/j.jvcir.2016.01.010
   Loong TW, 2003, BMJ-BRIT MED J, V327, P716, DOI 10.1136/bmj.327.7417.716
   Meyer S, 2015, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2015.7298747
   Monga V, 2007, IEEE T INF FOREN SEC, V2, P376, DOI 10.1109/TIFS.2007.902670
   Monga V, 2006, IEEE T IMAGE PROCESS, V15, P3452, DOI 10.1109/TIP.2006.881948
   Oostveen J, 2001, PROC SPIE, V4472, P121, DOI 10.1117/12.449746
   Oostveen J., 2002, Recent Advances in Visual Information Systems. 5th International Conference VISUAL 2002. Proceedings (Lecture Notes in Computer Science Vol.2314), P117
   Oppenheim A. V., 1989, Discrete -Time Signal Processing
   Ou Y, 2010, IEICE T INF SYST, VE93D, P1020, DOI 10.1587/transinf.E93.D.1020
   Ouyang JL, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2978572
   Rhee S, 1999, OPT ENG, V38, P1348, DOI 10.1117/1.602177
   Schneider M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P227, DOI 10.1109/ICIP.1996.560425
   Su PC, 2009, IEEE T CIRC SYST VID, V19, P668, DOI 10.1109/TCSVT.2009.2017404
   Sun JD, 2012, IEEE SIGNAL PROC LET, V19, P328, DOI 10.1109/LSP.2012.2192271
   Sun R, 2017, OPTIK, V128, P139, DOI 10.1016/j.ijleo.2016.09.105
   Sutcu Y., 2005, P 7 WORKSHOP MULTIME, P111
   Wolfson HJ, 1997, IEEE COMPUT SCI ENG, V4, P10, DOI 10.1109/99.641604
   WU LN, 1990, IEEE T ACOUST SPEECH, V38, P186, DOI 10.1109/29.45571
   Xu ZH, 2009, IEEE INT CON MULTI, P434, DOI 10.1109/ICME.2009.5202527
   Yang GB, 2012, COMPUT SECUR, V31, P33, DOI 10.1016/j.cose.2011.11.004
   Ye CH, 2016, INT J SECUR APPL, V10, P125, DOI 10.14257/ijsia.2016.10.1.13
   YIP P, 1987, IEEE T ACOUST SPEECH, V35, P404, DOI 10.1109/TASSP.1987.1165127
   Zauner C., 2010, IMPLEMENTATION BENCH
   Zhijie Zhang, 2010, 2010 IEEE International Conference on Automation and Logistics (ICAL), P13, DOI 10.1109/ICAL.2010.5585375
NR 65
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6713
EP 6751
DI 10.1007/s11042-017-4595-z
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700014
DA 2024-07-18
ER

PT J
AU Hu, R
   Li, XL
   Guo, ZM
AF Hu, Ran
   Li, Xiaolong
   Guo, Zongming
TI Decorrelated local binary patterns for efficient texture classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local binary patterns (LBP); Decorrelation; Discrete cosine transform
   (DCT); Texture classification
ID SCALE
AB Local binary patterns (LBP) has been successfully applied to several tasks in computer vision due to its efficacy and computational simplicity. LBP can be computed in different neighborhoods to derive multi-scale LBP (MS-LBP) for performance enhancement. In MS-LBP, different scales LBP histograms are either combined in a concatenate way assuming that different scales LBP are independent, or jointly combined to generate a multi-dimensional histogram. However, the independence assumption does not hold so that the cross-scale information is lost in concatenate MS-LBP, while joint MS-LBP suffers high feature dimension. Then, to deal with the independence assumption and better exploit multi-scale information, a new texture descriptor called decorrelated local binary patterns (dLBP) is proposed in this paper. Unlike traditional MS-LBP schemes, discrete cosine transform (DCT) is firstly applied as a decorrelation transform to different scales differences to derive independent patterns. Then, the histograms corresponding to each pattern are concatenated as a new texture descriptor. Besides, the decorrelated magnitude components are also utilized to further enhance the performance. Experimental results show that the proposed dLBP features outperform both the concatenate MS-LBP and some recent state-of-the-art schemes for texture classification.
C1 [Hu, Ran; Guo, Zongming] Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.
   [Li, Xiaolong] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
C3 Peking University; Beijing Jiaotong University
RP Guo, ZM (corresponding author), Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.
EM huran0719@pku.edu.cn; lixl@bjtu.edu.cn; guozongming@pku.edu.cn
RI Li, xiaolong/GRS-9148-2022; li, xiao/GSN-6181-2022
FU National Natural Science Foundation of China [61572052, U1636206]
FX This work is supported by National Natural Science Foundation of China
   under contract No. 61572052 and No. U1636206.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2008, 2008 3 INT C INF COM, DOI DOI 10.1109/ICTTA.2008.4530124
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], P BRIT MACH VIS C
   Cai ZB, 2016, MULTIMED TOOLS APPL, V75, P2393, DOI 10.1007/s11042-014-2411-6
   Chen PZ, 2010, ADV INTEL SOFT COMPU, V82, P811
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Davarzani R, 2015, SIGNAL PROCESS, V111, P274, DOI 10.1016/j.sigpro.2014.11.005
   Guo M, 2016, MULTIMED TOOLS APPL, P1
   Guo ZH, 2012, NEURAL COMPUT APPL, V21, P1893, DOI 10.1007/s00521-011-0586-6
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Hu R, 2015, 2015 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP), P397, DOI 10.1109/IIH-MSP.2015.79
   Hu YT, 2016, IEEE IMAGE PROC, P3548, DOI 10.1109/ICIP.2016.7533020
   Khellah FM, 2011, IEEE T IMAGE PROCESS, V20, P3270, DOI 10.1109/TIP.2011.2143422
   Li Z, 2012, IEEE T IMAGE PROCESS, V21, P2130, DOI 10.1109/TIP.2011.2173697
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Lin QY, 2016, IEEE IMAGE PROC, P2737, DOI 10.1109/ICIP.2016.7532857
   Lin QY, 2015, IEEE IMAGE PROC, P26, DOI 10.1109/ICIP.2015.7350752
   Liu L, 2014, IEEE T IMAGE PROCESS, V23, P3071, DOI 10.1109/TIP.2014.2325777
   Lu FX, 2016, INT CONF ACOUST SPEE, P1308, DOI 10.1109/ICASSP.2016.7471888
   Mehta R, 2016, PATTERN RECOGN LETT, V71, P16, DOI 10.1016/j.patrec.2015.11.019
   Mu Y., 2008, Proceedings of IEEE Conference on Computer Vision and Pattern Recognition
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Qi XB, 2015, IMAGE VISION COMPUT, V43, P16, DOI 10.1016/j.imavis.2015.07.005
   Ren HY, 2016, PATTERN RECOGN, V60, P793, DOI 10.1016/j.patcog.2016.07.010
   Saipullah KM, 2012, MULTIMED TOOLS APPL, V59, P717, DOI 10.1007/s11042-011-0766-5
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123
   Schaefer G, 2012, INT C PATT RECOG, P2500
   Shakoor MH, 2016, MULTIMED TOOLS APPL, P1
   Shi Yun Q., 2013, Information Hiding. 14th International Conference, IH 2012 Revised Selected Papers, P63, DOI 10.1007/978-3-642-36373-3_5
   Shi ZP, 2012, MULTIMED TOOLS APPL, V61, P263, DOI 10.1007/s11042-011-0836-8
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Nguyen VD, 2014, IEEE T CIRC SYST VID, V24, P263, DOI 10.1109/TCSVT.2013.2254898
   Wang K, 2013, IEEE SIGNAL PROC LET, V20, P853, DOI 10.1109/LSP.2013.2270405
   Zhang M, 2015, IEEE SIGNAL PROC LET, V22, P207, DOI 10.1109/LSP.2014.2326399
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
   Zhao Y, 2016, NEUROCOMPUTING, V207, P354, DOI 10.1016/j.neucom.2016.05.016
   Zhao Y, 2012, IEEE T IMAGE PROCESS, V21, P4492, DOI 10.1109/TIP.2012.2204271
NR 45
TC 3
Z9 4
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6863
EP 6882
DI 10.1007/s11042-017-4604-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700019
DA 2024-07-18
ER

PT J
AU Huang, XD
AF Huang, Xiaodong
TI Automatic video superimposed text detection based on Nonsubsampled
   Contourlet Transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video text; Nonsubsampled Contourlet Transform; Text detection; Text
   frame classification
ID LOCALIZATION; FEATURES; EXTRACTION; SCENE
AB Compared with other video semantic clues, such as gestures, motions etc., video text generally provides highly useful and fairly precise semantic information, the analysis of which can to a great extent facilitate video and scene understanding. It can be observed that the video texts show stronger edges. The Nonsubsampled Contourlet Transform (NSCT) is a fully shift-invariant, multi-scale, and multi-direction expansion, which can preserve the edge/silhouette of the text characters well. Therefore, in this paper, a new approach has been proposed to detect video text based on NSCT. First of all, the 8 directional coefficients of NSCT are combined to build the directional edge map (DEM), which can keep the horizontal, vertical and diagonal edge features and suppress other directional edge features. Then various directional pixels of DEM are integrated into a whole binary image (BE). Based on the BE, text frame classification is carried out to determine whether the video frames contain the text lines. Finally, text detection based on the BE is performed on consecutive frames to discriminate the video text from non-text regions. Experimental evaluations based on our collected TV videos data set demonstrate that our method significantly outperforms the other 3 video text detection algorithms in both detection speed and accuracy, especially when there are challenges such as video text with various sizes, languages, colors, fonts, short or long text lines.
C1 [Huang, Xiaodong] Capital Normal Univ, Beijing 100048, Peoples R China.
C3 Capital Normal University
RP Huang, XD (corresponding author), Capital Normal Univ, Beijing 100048, Peoples R China.
EM hxd@cnu.edu.cn
FU Beijing Natural Science Foundation [4173073]; Surface Project of Beijing
   Committee of Education [KM201710028021]
FX This work reported in this paper is supported by Beijing Natural Science
   Foundation(4173073); the Surface Project of Beijing Committee of
   Education under Grant No. KM201710028021.
CR Barinova O, 2012, IEEE T PATTERN ANAL, V34, P1773, DOI 10.1109/TPAMI.2012.79
   Chen ZJ, 2017, IEEE T CYBERNETICS, V47, P3706, DOI 10.1109/TCYB.2016.2577718
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Pham DS, 2015, IEEE T IMAGE PROCESS, V24, P332, DOI 10.1109/TIP.2014.2378034
   Huang XD, 2014, MULTIMED TOOLS APPL, V70, P1703, DOI 10.1007/s11042-012-1201-2
   Jing Zhang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3979, DOI 10.1109/ICPR.2010.968
   Jung C, 2009, IMAGE VISION COMPUT, V27, P1295, DOI 10.1016/j.imavis.2008.11.012
   Jung C, 2009, PATTERN RECOGN LETT, V30, P114, DOI 10.1016/j.patrec.2008.05.014
   Kim W, 2009, IEEE T IMAGE PROCESS, V18, P401, DOI 10.1109/TIP.2008.2008225
   Lu S, 2008, INT CONF ACOUST SPEE, P1341
   Lyu MR, 2005, IEEE T CIRC SYST VID, V15, P243, DOI 10.1109/TCSVT.2004.841653
   Moradi M, 2013, IET IMAGE PROCESS, V7, P154, DOI 10.1049/iet-ipr.2012.0441
   Mosleh A, 2013, IEEE T IMAGE PROCESS, V22, P4460, DOI 10.1109/TIP.2013.2273672
   Raza A, 2013, PROC INT CONF DOC, P309, DOI 10.1109/ICDAR.2013.69
   Shivakumara Palaiahnakote, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P156, DOI 10.1109/ICDAR.2009.85
   Shivakumara Palaiahnakote, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1285, DOI 10.1109/ICDAR.2009.83
   Shivakumara P, 2010, IEEE T CIRC SYST VID, V20, P1520, DOI 10.1109/TCSVT.2010.2077772
   Shivakumara P, 2009, IEEE INT CON MULTI, P514, DOI 10.1109/ICME.2009.5202546
   Shivakumara P, 2010, PATTERN RECOGN, V43, P2165, DOI 10.1016/j.patcog.2010.01.009
   Sun L, 2009, IEEE INT CON MULTI, P390, DOI 10.1109/ICME.2009.5202516
   Trung Quy Phan, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P66, DOI 10.1109/ICDAR.2009.153
NR 21
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7033
EP 7049
DI 10.1007/s11042-017-4619-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700028
DA 2024-07-18
ER

PT J
AU Jung, KH
AF Jung, Ki-Hyun
TI Authenticable reversible data hiding scheme with less distortion in dual
   stego-images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Information hiding; Dual images; Reversible data hiding;
   Exploiting modification directions
AB In reversible data hiding, dual image-based data hiding methods are recently proposed, in which two stego-images are generated after embedding the secret data. In this paper, a new reversible data hiding method is proposed to provide less distortion and integrity of forgery modification in dual stego-images. The modulus function is used to generate four pixel pairs in a sub-block of the cover image. The gap function is used to obtain two pixel pairs from four pixel pairs to maintain less distortion, and the parity bit function is applied to prevent forgery modification attack from the unauthorized party. On the receiver side, the secret data can be extracted and the cover image can be also recovered from the dual stego-images. The experimental results show that the proposed method has strength on embedding capacity and visual image quality.
C1 [Jung, Ki-Hyun] Kyungil Univ, Dept Cyber Secur, 50 Gamasil Gil, Gyongsan 38428, Gyeongbuk, South Korea.
C3 Kyungil University
RP Jung, KH (corresponding author), Kyungil Univ, Dept Cyber Secur, 50 Gamasil Gil, Gyongsan 38428, Gyeongbuk, South Korea.
EM khanny.jung@gmail.com
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2015R1D1A1A01058019]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (No. 2015R1D1A1A01058019).
CR [Anonymous], 2016, J INFORM HIDING MULT
   Chang CJ, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/526806
   Chang CC, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P145, DOI 10.1109/MUE.2009.35
   Chang T. Duc, 2007, P IEEE REG 10 C NOV, P1, DOI [10.1109/TENCON.2007.4483783, DOI 10.1109/TENCON.2007.4483783]
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Huang HC, 2013, EXPERT SYST APPL, V40, P34, DOI 10.1016/j.eswa.2012.07.010
   Huang HC, 2011, IEEE T CONSUM ELECTR, V57, P779, DOI 10.1109/TCE.2011.5955222
   Jana B, 2016, OPTIK, V127, P3347, DOI 10.1016/j.ijleo.2015.12.055
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2143, DOI 10.1007/s11042-013-1832-y
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Lu TC, 2015, SIGNAL PROCESS, V108, P77, DOI 10.1016/j.sigpro.2014.08.022
   Nissar A, 2010, DIGIT SIGNAL PROCESS, V20, P1758, DOI 10.1016/j.dsp.2010.02.003
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 19
TC 15
Z9 15
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 6225
EP 6241
DI 10.1007/s11042-017-4533-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800051
DA 2024-07-18
ER

PT J
AU Lv, GH
   Teng, SW
   Lu, GJ
AF Lv, Guohua
   Teng, Shyh Wei
   Lu, Guojun
TI A detector of structural similarity for multi-modal microscopic image
   registration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-modal microscopic images; Structural similarity; Image
   registration
ID SEGMENTATION; PERFORMANCE; DESCRIPTOR
AB This paper presents a Detector of Structural Similarity (DSS) to minimize the visual differences between brightfield and confocal microscopic images. The context of this work is that it is very challenging to effectively register such images due to a low structural similarity in image contents. To address this issue, DSS aims to maximize the structural similarity by utilizing the intensity relationships among red-green-blue (RGB) channels in images. Technically, DSS can be combined with any multi-modal image registration technique in registering brightfield and confocal microscopic images. Our experimental results show that DSS significantly increases the visual similarity in such images, thereby improving the registration performance of an existing state-of-the-art multi-modal image registration technique by up to approximately 27%.
C1 [Lv, Guohua] Qilu Univ Technol, Sch Informat, Jinan, Shandong, Peoples R China.
   [Teng, Shyh Wei; Lu, Guojun] Federat Univ Australia, Fac Sci & Technol, Ballarat, Vic, Australia.
C3 Qilu University of Technology; Federation University Australia
RP Lv, GH (corresponding author), Qilu Univ Technol, Sch Informat, Jinan, Shandong, Peoples R China.
EM drguohualv@163.com
OI Lu, Guojun/0000-0003-2523-7576; Lv, Guohua/0000-0003-3550-8026; Teng,
   Shyh Wei/0000-0003-0347-3797
CR Awad A.I., 2016, Image Feature Detectors and Descriptors: Foundations and Applications, V1st
   Chaira T, 2004, PATTERN RECOGN LETT, V25, P865, DOI 10.1016/j.patrec.2004.01.018
   Chen JA, 2010, IEEE T BIO-MED ENG, V57, P1707, DOI 10.1109/TBME.2010.2042169
   Chen J, 2009, PROG NAT SCI-MATER, V19, P643, DOI 10.1016/j.pnsc.2008.06.029
   Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7
   Cinque L, 2004, PATTERN RECOGN, V37, P1797, DOI 10.1016/j.patcog.2003.04.001
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dettmeyer R.B., 2011, FORENSIC HISTOPATHOL, DOI [10.1007/978-3-642-20659-7, DOI 10.1007/978-3-642-20659-7, 10.1007/978-3-642-20659-7_2, DOI 10.1007/978-3-642-20659-7_2]
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Fu X, 2015, IEEE I CONF COMP VIS, P1618, DOI 10.1109/ICCV.2015.189
   Ghassabi Z., 2013, Eurasip Journal on Image and Video Processing, V2013, P1
   Gong M, 2013, IEEE T IMAGE PROCESS
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Heinrich MP, 2012, MED IMAGE ANAL, V16, P1423, DOI 10.1016/j.media.2012.05.008
   Hossain M. T., 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P197, DOI 10.1109/DICTA.2011.40
   Ilea DE, 2011, PATTERN RECOGN, V44, P2479, DOI 10.1016/j.patcog.2011.03.005
   Katikireddy KR, 2011, METHODS MOL BIOL, V784, P155, DOI 10.1007/978-1-61779-289-2_11
   Kelman A., 2007, INT C COMP VIS PATT, P1
   Kim TH, 2013, IEEE T PATTERN ANAL, V35, P1690, DOI 10.1109/TPAMI.2012.237
   Klein S, 2010, IEEE T MED IMAGING, V29, P196, DOI 10.1109/TMI.2009.2035616
   Lee JA, 2015, PROC CVPR IEEE, P1046, DOI 10.1109/CVPR.2015.7298707
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li ZG, 2012, PROC CVPR IEEE, P789, DOI [10.1109/CVPR.2012.6247750, 10.1109/ISRA.2012.6219309]
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lv G, 2013, INT C DIG IM COMP TE, P1
   Lv GH, 2016, PATTERN RECOGN LETT, V84, P156, DOI 10.1016/j.patrec.2016.09.011
   Ma L, 2007, PATTERN RECOGN, V40, P3005, DOI 10.1016/j.patcog.2007.02.005
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Petitjean C, 2011, MED IMAGE ANAL, V15, P169, DOI 10.1016/j.media.2010.12.004
   Rai V, 2007, BASICS CONFOCAL MICR
   Ramos-Vara JA, 2005, VET PATHOL, V42, P405, DOI 10.1354/vp.42-4-405
   Saleem S, 2014, IEEE SIGNAL PROC LET, V21, P400, DOI 10.1109/LSP.2014.2304073
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Smistad E, 2015, MED IMAGE ANAL, V20, P1, DOI 10.1016/j.media.2014.10.012
   Teng SW, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.013013
   Wachinger C, 2012, MED IMAGE ANAL, V16, P1, DOI 10.1016/j.media.2011.03.001
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Woo J, 2015, IEEE T IMAGE PROCESS, V24, P757, DOI 10.1109/TIP.2014.2387019
   Yang GH, 2007, IEEE T PATTERN ANAL, V29, P1973, DOI [10.1109/TPAMI.2007.1116, 10.1109/TPAMl.2007.1116.]
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 42
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7675
EP 7701
DI 10.1007/s11042-017-4669-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700056
DA 2024-07-18
ER

PT J
AU Muddamsetty, SM
   Sidibé, D
   Trémeau, A
   Mériaudeau, F
AF Muddamsetty, Satya M.
   Sidibe, Desire
   Tremeau, Alain
   Meriaudeau, Fabrice
TI Salient objects detection in dynamic scenes using color and texture
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual saliency; Dynamic textures; Salient objects detection; Local
   binary patterns
ID SPATIOTEMPORAL SALIENCY; MODEL
AB Visual saliency is an important research topic in the field of computer vision due to its numerous possible applications. It helps to focus on regions of interest instead of processing the whole image or video data. Detecting visual saliency in still images has been widely addressed in literature with several formulations. However, visual saliency detection in videos has attracted little attention, and is a more challenging task due to additional temporal information. A common approach for obtaining a spatio-temporal saliency map is to combine a static saliency map and a dynamic saliency map. In our work, we model the dynamic textures in a dynamic scene with local binary patterns to compute the dynamic saliency map, and we use color features to compute the static saliency map. Both saliency maps are computed using a bio-inspired mechanism of human visual system with a discriminant formulation known as center surround saliency, and are fused in a proper way. The proposed model has been extensively evaluated with diverse publicly available datasets which contain several videos of dynamic scenes, and comparison with state-of-the art methods shows that it achieves competitive results.
C1 [Muddamsetty, Satya M.; Sidibe, Desire; Meriaudeau, Fabrice] Univ Bourgogne France Comte, CNRS, Le2i, UMR 6306, Bourgogne, France.
   [Tremeau, Alain] Univ Jean Monnet, Lab Hubert Curien, CNRS, UMR 5116, St Etienne, France.
   [Meriaudeau, Fabrice] Univ Teknol Petronas, Elect & Elect Engn Dept, CISIR, Seri Iskander, Perek, Malaysia.
C3 Universite de Bourgogne; Centre National de la Recherche Scientifique
   (CNRS); Centre National de la Recherche Scientifique (CNRS); CNRS -
   Institute for Humanities & Social Sciences (INSHS); Universiti Teknologi
   Petronas
RP Sidibé, D (corresponding author), Univ Bourgogne France Comte, CNRS, Le2i, UMR 6306, Bourgogne, France.
EM dro-desire.sidibe@u-bourgogne.fr
RI SIDIBE, DESIRE/AFQ-8070-2022; Trémeau, Alain/ABB-4819-2022
OI SIDIBE, DESIRE/0000-0002-5843-7139; Trémeau, Alain/0000-0003-2826-7519
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Chetverikov D, 2005, ADV SOFT COMP, P17
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Frintrop S., 2011, COMPUTATIONAL VISUAL
   Fu KR, 2014, INT C PATT RECOG, P2371, DOI 10.1109/ICPR.2014.411
   Goferman S., 2010, IEEE CVPR
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Hou X., 2008, Advances in Neural Information Processing Systems, V5, P7
   Kim W, 2011, IEEE T CIRC SYST VID, V21, P446, DOI 10.1109/TCSVT.2011.2125450
   Le Meur O, 2013, BEHAV RES METHODS, V45, P251, DOI 10.3758/s13428-012-0226-9
   Liu C, 2009, PATTERN RECOGN, V42, P2897, DOI 10.1016/j.patcog.2009.02.002
   Lu T., 2010, ICIP
   Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112
   Mancas M, 2011, IEEE IMAGE PROC, P229, DOI 10.1109/ICIP.2011.6116099
   Marat S, 2009, INT J COMPUT VISION, V82, P231, DOI 10.1007/s11263-009-0215-3
   Muddamsetty S., 2013, ICIP
   Pinto Y, 2013, J VISION, V13, DOI 10.1167/13.3.16
   Riche Nicolas, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P586, DOI 10.1007/978-3-642-37431-9_45
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Shilang S, 2013, NEURAL COMPUT APPL, V7-8, P2013
   Siagian C, 2009, IEEE T ROBOT, V25, P861, DOI 10.1109/TRO.2009.2022424
   Sidibe D., 2010, EUSIPCO
   Tong YB, 2011, COGN COMPUT, V3, P241, DOI 10.1007/s12559-010-9094-8
   Xu C., 2013, SURVEY MULTIVIEW LEA
   Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578
   Zhang L., 2009, PROC 31 ANN COGNIT S, P2944
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhou BL, 2011, LECT NOTES COMPUT SC, V6494, P225, DOI 10.1007/978-3-642-19318-7_18
NR 31
TC 4
Z9 4
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5461
EP 5474
DI 10.1007/s11042-017-4462-y
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800016
DA 2024-07-18
ER

PT J
AU Huynh, NT
   Bharanitharan, K
   Chang, CC
   Liu, YJ
AF Ngoc-Tu Huynh
   Bharanitharan, K.
   Chang, Chin-Chen
   Liu, Yanjun
TI Minima-maxima preserving data hiding algorithm for absolute moment block
   truncation coding compressed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Absolute moment block truncation coding (AMBTC); Compressed
   image; Embedding rate; Visual quality
ID HALF-TONE IMAGES; COLOR IMAGES; WATERMARKING; SCHEME; MODULATION
AB Preventing secret from being suspicious during transferring over Internet has become an emergent issue in the past decades. Several protecting data methods such as cryptographic techniques, watermarking or steganography techniques, etc. have been proposed to conceal secrets from being discovered. In this paper, we introduce the Minima-Maxima Preserving (MMP) data hiding algorithm for absolute moment block truncation coding (AMBTC) compressed images, which preserves the high and low values in each block to reversibly extract secret and recover host images during the extracting procedure. As a result, image quality is maintained that makes the secret messages hidden and avoids suspicion from attackers. Experimental results show that the scheme has better performance compared to state-of-the-art schemes in terms of visual quality and embedding rate. Besides, with the high embedding rate, the scheme can be widely used in practice.
C1 [Ngoc-Tu Huynh] Ton Duc Thang Univ, Fac Informat Technol, Ho Chi Minh City, Vietnam.
   [Bharanitharan, K.] Australian Natl Univ, Res Sch Management, Canberra, ACT, Australia.
   [Chang, Chin-Chen; Liu, Yanjun] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 407, Taiwan.
C3 Ton Duc Thang University; Australian National University; Feng Chia
   University
RP Liu, YJ (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 407, Taiwan.
EM huynhngoctu@tdt.edu.vn; Dharan@ieee.org; alan3c@gmail.com;
   yjliu104@gmail.com
RI liu, yan/HCI-5542-2022; 刘, 严君/GZL-5764-2022; Chang,
   Ching-Chun/JAN-6210-2023; liu, yan/HGV-1365-2022
OI Brown, Darren K/0000-0003-1246-1974
CR [Anonymous], 2012, TEST IMAGE DATABASE
   [Anonymous], 1997, USC SIPI IMAGE DATAB
   Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Fallahpour M, 2011, IET IMAGE PROCESS, V5, P190, DOI 10.1049/iet-ipr.2009.0226
   Guo JM, 2012, IEEE T IMAGE PROCESS, V21, P4808, DOI 10.1109/TIP.2012.2210236
   Guo JM, 2012, IEEE T IMAGE PROCESS, V21, P4117, DOI 10.1109/TIP.2012.2198221
   Guo JM, 2011, IEEE MULTIMEDIA, V18, P48, DOI 10.1109/MMUL.2010.23
   Guo JM, 2010, IEEE T IMAGE PROCESS, V19, P2056, DOI 10.1109/TIP.2010.2045709
   Hamghalam M, 2013, IET IMAGE PROCESS, V7, P451, DOI 10.1049/iet-ipr.2012.0693
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Hou CL, 2011, IEEE T IMAGE PROCESS, V20, P880, DOI 10.1109/TIP.2010.2072513
   Jung SW, 2011, IEEE SIGNAL PROC LET, V18, P95, DOI 10.1109/LSP.2010.2095498
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Liu YF, 2011, IEEE T IMAGE PROCESS, V20, P1077, DOI 10.1109/TIP.2010.2087765
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Subramanyam AV, 2012, IEEE T MULTIMEDIA, V14, P703, DOI 10.1109/TMM.2011.2181342
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Wang SY, 2013, IET IMAGE PROCESS, V7, P805, DOI 10.1049/iet-ipr.2012.0521
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zareian M, 2013, IET IMAGE PROCESS, V7, P432, DOI 10.1049/iet-ipr.2013.0048
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
   Zhang WM, 2012, IEEE T IMAGE PROCESS, V21, P2991, DOI 10.1109/TIP.2012.2187667
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 34
TC 14
Z9 14
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5767
EP 5783
DI 10.1007/s11042-017-4487-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800028
OA Green Published
DA 2024-07-18
ER

PT J
AU Yang, LJ
   Zhu, L
   Li, ZG
   Lu, BC
AF Yang, Lijun
   Zhu, Li
   Li, Zongan
   Lu, Baochun
TI Fabrication of PDMS microfluidic chips used in rapid diagnosis by micro
   jetting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE PDMS microfluidic chips; Directly printing; Liquid molds; Hydrophilic
   surface; Smooth microchannel
ID COMPUTER-AIDED DIAGNOSIS; DEVICES; POLYMER; CANCER; MICROFABRICATION;
   SILICON
AB In this paper, a simple method was demonstrated to fabricate polydimethylsiloxane (PDMS) microfluidic chips used in rapid diagnosis based on printing the liquid molds directly. The liquid droplets were jetted by a glass micronozzle onto the hydrophilic glass substrate based on microfluidic pulse interior force to form various liquid molds, and then a replication process and a bonding process were followed for the fabrication of PDMS microfluidic chips. The effects of the wettability of the substrate and the overlap between the droplets on the formation of the liquid molds were investigated. Liquid molds with width ranging from 40 mu m to 365 mu m were prepared with an aspect ratio of 0.080 through controlling the overlap and the droplet size. The surface of the fabricated microchannels was smooth as the arithmetical mean deviation of the profile Ra was 179.1 nm with the 80 x 320 mu m(2) area at the bottom. The microreactions at the well-defined interfaces of several different solutions were realized with the fabricated PDMS microfluidic chips.
C1 [Yang, Lijun; Zhu, Li; Lu, Baochun] Nanjing Univ Sci & Technol, Nanjing, Jiangsu, Peoples R China.
   [Li, Zongan] Southeast Univ, Nanjing, Jiangsu, Peoples R China.
   [Li, Zongan] Nanjing Normal Univ, Jiangsu Key Lab Printing Equipment & Mfg 3D, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology; Southeast University -
   China; Nanjing Normal University
RP Zhu, L (corresponding author), Nanjing Univ Sci & Technol, Nanjing, Jiangsu, Peoples R China.
EM fulisayang@163.com; nlgzl@163.com; ethan301@126.com; lbcnust@sina.com
RI Li, Zongan/ABF-1785-2020
OI Li, Zongan/0000-0002-3580-5891
FU National Natural Science Foundation of China [51175268]; Open Program of
   Jiangsu Key Laboratory of 3D Printing Equipment and Manufacturing
   [BM2013006]; Zhejiang Provincial Top Key Discipline of Mechanical
   Engineering
FX This work is supported by the National Natural Science Foundation of
   China (No. 51175268) and the Open Program of Jiangsu Key Laboratory of
   3D Printing Equipment and Manufacturing (No. BM2013006) and the Zhejiang
   Provincial Top Key Discipline of Mechanical Engineering.
CR Belligundu S, 2006, J MICROLITH MICROFAB, V5, DOI 10.1117/1.2198794
   Browne AW, 2009, LAB CHIP, V9, P2941, DOI 10.1039/b903755a
   Chang WH, 2014, LAB CHIP, V14, P3376, DOI 10.1039/c4lc00471j
   Chung CH, 2015, INT J PRECIS ENG MAN, V16, P2033, DOI 10.1007/s12541-015-0264-1
   Easley CJ, 2009, LAB CHIP, V9, P1119, DOI 10.1039/b816575k
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   Eves DJ, 2009, ANAL BIOANAL CHEM, V393, P431, DOI 10.1007/s00216-008-2408-y
   Fan YQ, 2012, J MICROMECH MICROENG, V22, DOI 10.1088/0960-1317/22/2/027001
   Jalalian A, 2013, CLIN IMAG, V37, P420, DOI 10.1016/j.clinimag.2012.09.024
   Jena RK, 2012, SENSOR ACTUAT B-CHEM, V163, P233, DOI 10.1016/j.snb.2012.01.043
   Kaigala GV, 2007, LAB CHIP, V7, P384, DOI 10.1039/b617764f
   Kenis PJA, 1999, SCIENCE, V285, P83, DOI 10.1126/science.285.5424.83
   Koesdjojo MT, 2008, SENSOR ACTUAT B-CHEM, V131, P692, DOI 10.1016/j.snb.2008.01.008
   Lasave LC, 2015, RSC ADV, V5, P70808, DOI 10.1039/c5ra15591f
   Liu X, 2009, LAB CHIP, V9, P1200, DOI 10.1039/b818721e
   Looper J, 2016, SPIE MED IMAGING
   Lu Y, 2011, ANAL CHEM, V83, P1830, DOI 10.1021/ac102577n
   McDonald JC, 2002, ANAL CHEM, V74, P1537, DOI 10.1021/ac010938q
   Mogensen KB, 2009, ELECTROPHORESIS, V30, pS92, DOI 10.1002/elps.200900101
   Peng YH, 2013, RADIOLOGY, V267, P787, DOI 10.1148/radiol.13121454
   Selvaraj H, 2011, J MICROMECH MICROENG, V21, DOI 10.1088/0960-1317/21/7/075018
   Stoller MA, 2015, RSC ADV, V5, P97934, DOI 10.1039/c5ra22742a
   Thomas MS, 2010, LANGMUIR, V26, P2951, DOI 10.1021/la902886d
   Verma MKS, 2006, LANGMUIR, V22, P10291, DOI 10.1021/la062516n
   Ying L, 2013, BMC BIOTECHNOL, V13, DOI 10.1186/1472-6750-13-76
   Yu IF, 2014, LAB CHIP, V14, P3621, DOI 10.1039/c4lc00502c
   Yuan H, 2014, ANAL METHODS-UK, V6, P2015, DOI 10.1039/c3ay41925h
   Yue WQ, 2013, BIOSENS BIOELECTRON, V41, P675, DOI 10.1016/j.bios.2012.09.046
   Zhang YD, 2016, ADV MECH ENG, V8, DOI 10.1177/1687814016634243
   Zhang YD, 2013, SCI WORLD J, DOI 10.1155/2013/130134
   Zhang YD, 2015, BIO-MED MATER ENG, V26, pS1283, DOI 10.3233/BME-151426
   Zhang YD, 2014, PROG ELECTROMAGN RES, V145, P273, DOI 10.2528/PIER14021005
   Zhang YD, 2011, EXPERT SYST APPL, V38, P10049, DOI 10.1016/j.eswa.2011.02.012
   Zhu XY, 2015, OPT LASER TECHNOL, V66, P156, DOI 10.1016/j.optlastec.2014.09.002
NR 34
TC 8
Z9 8
U1 2
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3761
EP 3774
DI 10.1007/s11042-016-3958-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600048
DA 2024-07-18
ER

PT J
AU Antony, A
   Sreelekha, G
AF Antony, Abhilash
   Sreelekha, G.
TI Selective intra prediction in HEVC planar and angular modes for
   efficient near-lossless video compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lossless mode; Angular prediction; Planar prediction; SIP-A; SIP-C
ID PARALLEL FRAMEWORK
AB In the lossless mode of HEVC (high efficiency video coding), the coding gains of sample-based prediction algorithms are always better than the conventional block-based predictions within the HEVC anchor. Both block based and sample-based prediction strategies select the best prediction mode for the current prediction unit (PU), on the basis of a cost function evaluated at the PU level. Hence, the selected prediction mode for a PU may not be generating the best prediction at the pixel level. If the selection of the best prediction mode can be performed at the pixel level, the accuracy of prediction can be increased significantly. In this work, we propose two selective intra prediction strategies (SIP) which select the best prediction mode from the block-based and sample-based predictions at the pixel level. In the proposed SIP-A algorithm the SIP strategy is applied to only angular prediction modes while the combined SIP algorithm (SIP-C) employs the SIP strategy in both the angular and planar prediction modes. The proposed SIP-C algorithm enhances the performance of the current state of the art SIP algorithm in the literature by introducing better prediction strategies for both angular and planar predictions of HEVC intra prediction. To avoid the enormous overhead required to convey the choice of prediction from the encoder to the decoder, SIP algorithms utilise the least significant bit (LSB) piggybacking strategy. The experimental results provide significant improvements in coding gain and run time for the proposed near-lossless SIP algorithms.
C1 [Antony, Abhilash] Muthoot Inst Technol & Sci, Dept Elect & Commun Engn, Varikoli 682308, Kerala, India.
   [Sreelekha, G.] Natl Inst Technol, Dept Elect & Commun Engn, Calicut 673601, Kerala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Calicut
RP Antony, A (corresponding author), Muthoot Inst Technol & Sci, Dept Elect & Commun Engn, Varikoli 682308, Kerala, India.
EM abhilashantony@mgits.ac.in; lekha@nitc.ac.in
RI Antony, Abhilash/I-9692-2019
OI Antony, Abhilash/0000-0001-7974-2733
CR [Anonymous], JCTVCG093
   [Anonymous], 12 M GEN
   [Anonymous], ASIA PACIFIC SIGNAL
   [Anonymous], 2013, Technical Report JCTVC-L1100
   [Anonymous], JCTVCH0083
   [Anonymous], 17 M VAL
   Antony A, 2017, MULTIMED TOOLS APPL, V76, P1639, DOI 10.1007/s11042-015-3138-8
   Antony A, 2015, AEU-INT J ELECTRON C, V69, P1650, DOI 10.1016/j.aeue.2015.07.019
   Bross Benjamin, 2012, 2012 IEEE Second International Conference on Consumer Electronics - Berlin (ICCE-Berlin), P26, DOI 10.1109/ICCE-Berlin.2012.6336460
   Budagavi M, 2013, IEEE J-STSP, V7, P1029, DOI 10.1109/JSTSP.2013.2270429
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Li F, 2011, IEEE IMAGE PROC, P373
   MARTUCCI SA, 1990, 1990 IEEE INTERNATIONAL SYMP ON CIRCUITS AND SYSTEMS, VOLS 1-4, P1310, DOI 10.1109/ISCAS.1990.112371
   Pourazad MT, 2012, IEEE CONSUM ELECTR M, V1, P36, DOI 10.1109/MCE.2012.2192754
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Weinberger MJ, 1996, DCC '96 - DATA COMPRESSION CONFERENCE, PROCEEDINGS, P140, DOI 10.1109/DCC.1996.488319
   Wige E, 2013, PICT COD SYMP, P305, DOI 10.1109/PCS.2013.6737744
   Wige E, 2013, IEEE IMAGE PROC, P1806, DOI 10.1109/ICIP.2013.6738372
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yao YB, 2016, MULTIMED TOOLS APPL, V75, P1963, DOI 10.1007/s11042-014-2382-7
   Zhou MH, 2012, IEEE T CIRC SYST VID, V22, P1839, DOI 10.1109/TCSVT.2012.2221524
NR 23
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 1093
EP 1113
DI 10.1007/s11042-016-4309-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400046
DA 2024-07-18
ER

PT J
AU Khan, SA
   Hussain, A
   Usman, M
AF Khan, Sajid Ali
   Hussain, Ayyaz
   Usman, Muhammad
TI Reliable facial expression recognition for multi-scale images using
   weber local binary image based cosine transform features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Discrete cosine transform; Local binary
   image; Weber local descriptor; Multi-scale images; Dimension reduction
ID FACE RECOGNITION; PATTERNS; CLASSIFICATION
AB Accurate recognition of facial expression is a challenging problem especially from multi-scale and multi orientation face images. In this article, we propose a novel technique called Weber Local Binary Image Cosine Transform (WLBI-CT). WLBI-CT extracts and integrates the frequency components of images obtained through Weber local descriptor and local binary descriptor. These frequency components help in accurate classification of various facial expressions in the challenging domain of multi-scale and multi-orientation facial images. Identification of significant feature set plays a vital role in the success of any facial expression recognition system. Effect of multiple feature sets with varying block sizes has been investigated using different multi-scale images taken from well-known JAFEE, MMI and CK+ datasets. Extensive experimentation has been performed to demonstrate that the proposed technique outperforms the contemporary techniques in terms of recognition rate and computational time.
C1 [Khan, Sajid Ali; Usman, Muhammad] Shaheed Zulfikar Ali Bhutto Inst Sci & Technol, Dept Comp Sci, House 13,St 52,CAT B,G 10-3, Islamabad 44000, Pakistan.
   [Hussain, Ayyaz] Int Islamic Univ, Dept Comp Sci & Software Engn, Islamabad, Pakistan.
C3 Shaheed Zulfikar Ali Bhutto Institute of Science & Technology;
   International Islamic University, Pakistan
RP Khan, SA (corresponding author), Shaheed Zulfikar Ali Bhutto Inst Sci & Technol, Dept Comp Sci, House 13,St 52,CAT B,G 10-3, Islamabad 44000, Pakistan.
EM sajidalibn@gmail.com; ayyaz.hussain@iiu.edu.pk;
   dr.usman@szabist-isb.edu.pk
RI khan, sajid/HGE-2406-2022; Usman, Muhammad/JEP-1477-2023
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], C4 5 PROGRAMS MACHIN
   [Anonymous], 2003, P 2003 C COMP VIS PA, DOI DOI 10.1109/CVPRW.2003.10057
   Chao WL, 2015, SIGNAL PROCESS, V117, P1, DOI 10.1016/j.sigpro.2015.04.007
   Chen J.H., 2016, GASTROENT RES PRACT, V2016, P1, DOI DOI 10.1080/0951192X.2016.1145805
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Chen WJ, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION (ICNC), P34, DOI 10.1109/ICNC.2013.6817939
   Dabbaghchian S, 2010, PATTERN RECOGN, V43, P1431, DOI 10.1016/j.patcog.2009.11.001
   Dornaika F, 2011, PATTERN RECOGN LETT, V32, P740, DOI 10.1016/j.patrec.2010.12.010
   Du SC, 2011, J VISION, V11, DOI 10.1167/11.13.24
   Eleftheriadis S, 2015, IEEE T IMAGE PROCESS, V24, P189, DOI 10.1109/TIP.2014.2375634
   Fan XJ, 2015, PATTERN RECOGN, V48, P3407, DOI 10.1016/j.patcog.2015.04.025
   Gao T, 2013, OPTIK, V124, P6286, DOI 10.1016/j.ijleo.2013.05.007
   Han J, 2012, MOR KAUF D, P1
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Inchul Song, 2014, 2014 IEEE International Conference on Consumer Electronics (ICCE), P564, DOI 10.1109/ICCE.2014.6776135
   Jing XY, 2005, PATTERN RECOGN, V38, P453, DOI 10.1016/j.patcog.2003.09.020
   Kamarol SKA, 2016, IET IMAGE PROCESS, V10, P534, DOI 10.1049/iet-ipr.2015.0519
   Khan RA, 2013, PATTERN RECOGN LETT, V34, P1159, DOI 10.1016/j.patrec.2013.03.022
   Khan RA, 2012, IEEE IMAGE PROC, P2593, DOI 10.1109/ICIP.2012.6467429
   Krisshna NLA, 2014, APPL SOFT COMPUT, V22, P141, DOI 10.1016/j.asoc.2014.05.007
   Kumar J, 2015, PROCEDIA COMPUT SCI, V58, P486, DOI 10.1016/j.procs.2015.08.011
   Kumbhar M., 2012, INT J COMPUT COMMUN, V1, P117, DOI [10.7763/IJCCE.2012.V1.33, DOI 10.7763/IJCCE.2012.V1.33]
   Li YS, 2016, IEEE GEOSCI REMOTE S, V13, P157, DOI 10.1109/LGRS.2015.2503142
   Liu HW, 2009, PATTERN RECOGN, V42, P1330, DOI 10.1016/j.patcog.2008.10.028
   Long F, 2016, NEUROCOMPUTING, V173, P2049, DOI 10.1016/j.neucom.2015.09.049
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons MJ, 1997, JAPANESE FEMALE FACI, P200
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Owusu E, 2014, EXPERT SYST APPL, V41, P3383, DOI 10.1016/j.eswa.2013.11.041
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Tian Y, 2004, CHIN ACAD MED MAG OR, P1
   Tian Y, 2005, HDB FACE RECOGNITION, P1
   Tong Y, 2014, OPTIK, V125, P4186, DOI 10.1016/j.ijleo.2014.04.062
   Uçar A, 2016, NEURAL COMPUT APPL, V27, P131, DOI 10.1007/s00521-014-1569-1
   Valstar M., 2006, COMP VIS PATT REC WO, P149
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang Z, 2016, NEUROCOMPUTING, V174, P756, DOI 10.1016/j.neucom.2015.09.083
   XiaoHui Guo, 2013, Journal of Multimedia, V8, P402, DOI 10.4304/jmm.8.4.402-409
   Yan OY, 2015, NEUROCOMPUTING, V149, P71, DOI 10.1016/j.neucom.2014.03.073
   Yu KM, 2013, PATTERN RECOGN, V46, P2144, DOI 10.1016/j.patcog.2013.01.032
   Zhang W, 2015, PATTERN RECOGN, V48, P3191, DOI 10.1016/j.patcog.2015.04.012
   Zhang Yankun, 2004, Journal of Systems Engineering and Electronics, V15, P211
NR 48
TC 41
Z9 42
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 1133
EP 1165
DI 10.1007/s11042-016-4324-z
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400048
DA 2024-07-18
ER

PT J
AU Wu, HL
   Chang, CC
AF Wu, Hsiao-Ling
   Chang, Chin-Chen
TI Attacks on "a provably secure and efficient authentication scheme for
   access control in mobile pay-TV systems"
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile pay-TVsystems; One-to-many authentication; Conditional access
   control; Privacy
ID NON-REPUDIATION; KEY DISTRIBUTION; PRIVACY
AB Mobile pay-TV systems represent an application of important electronic commerce, providing mobile users with the multimedia services. In 2016, Farash and Attari employed the elliptic curves and bilinear pairing technologies to design a one-to-many authentication scheme for mobile pay-TV systems. They claimed that their scheme provides a high level of efficiency and can resist most attacks on mobile pay-TV systems. In this paper, we point out their scheme cannot achieve the fundamental requirement of authentication that is, the mutual authentication. In addition, their scheme still suffers from three security weaknesses.
C1 [Wu, Hsiao-Ling; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 407, Taiwan.
C3 Feng Chia University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 407, Taiwan.
EM wuhsiaoling590@gmail.com; alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023
CR Chen TH, 2011, J NETW COMPUT APPL, V34, P1131, DOI 10.1016/j.jnca.2010.11.005
   COUTROT F, 1989, IEEE T CONSUM ELECTR, V35, P464, DOI 10.1109/30.44305
   Dolev D., 1981, 22nd Annual Symposium on Foundations of Computer Science, P350, DOI 10.1109/SFCS.1981.32
   DVB Standard, 2005, IP DAT CAST DVB H SE
   Farash MS, 2016, MULTIMED TOOLS APPL, V75, P405, DOI 10.1007/s11042-014-2296-4
   Huang XY, 2012, SECUR COMMUN NETW, V5, P1248, DOI 10.1002/sec.620
   Huang YL, 2004, IEEE T MULTIMEDIA, V6, P760, DOI 10.1109/TMM.2004.834861
   Khedr W, 2013, J INF SECUR, V4, P225
   Kim H, 2012, COMM COM INF SC, V339, P471
   Kim JY, 2010, IEEE T MULTIMEDIA, V12, P337, DOI 10.1109/TMM.2010.2046362
   Lee NY, 2000, IEEE T CONSUM ELECTR, V46, P20, DOI 10.1109/30.826376
   Song R, 2003, IEEE T CONSUM ELECTR, V49, P408, DOI 10.1109/TCE.2003.1209533
   Song RG, 2001, IEEE T CONSUM ELECTR, V47, P729, DOI 10.1109/30.982783
   Sun HM, 2008, IEEE T MULTIMEDIA, V10, P1109, DOI 10.1109/TMM.2008.2001381
   Sun HM, 2009, IEEE T MULTIMEDIA, V11, P947, DOI 10.1109/TMM.2009.2021790
   Wang H, 2012, IET INFORM SECUR, V6, P281, DOI 10.1049/iet-ifs.2011.0281
   Wang SY, 2008, IEEE T MULTIMEDIA, V10, P480, DOI 10.1109/TMM.2008.917417
   Wu HL, 2016, SECUR COMMUN NETW, V9, P1577, DOI 10.1002/sec.1449
   Yeh LY, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2487268.2487271
   Yeh LY, 2012, IEEE T MULTIMEDIA, V14, P1690, DOI 10.1109/TMM.2012.2199290
NR 20
TC 3
Z9 3
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1525
EP 1535
DI 10.1007/s11042-017-4377-7
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400002
DA 2024-07-18
ER

PT J
AU Yao, YB
   Jia, TJ
   Li, XJ
   Lu, Y
AF Yao, Yingbiao
   Jia, Tianjie
   Li, Xiaojuan
   Lu, Yu
TI A fast DEA-based intra-coding algorithm for HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Intra-coding; Dominant edge assent; Block partitioning;
   Intra-prediction mode selection; EOclass decision
ID MODE DECISION ALGORITHM; SAMPLE ADAPTIVE OFFSET; PREDICTION
AB As the newest video coding standard, High Efficiency Video Coding (HEVC) greatly enhances the encoding performance of H. 264/AVC. However, HEVC also has high computational complexity, which limits application of this new standard. In this paper, we propose a fast DEA-based intra-coding algorithm, including block partitioning; prediction mode selection and edge offset (EO) class decision algorithms. The idea behind the proposed algorithm is to utilize the texture characteristics of the encoding image, which are quantified by dominant edge assent (DEA) and its distribution, to reduce the decision space. Specifically, for block partitioning, we propose the most possible depth range (MPDR) and employ DEA to determine whether the current coding block can use the MPDR to predict the partitioning depth or not; for intra-prediction mode selection, we use DEA and its distribution to reduce the range of prediction direction; for the EO class decision, we use DEA to determine the EO class of the sample adaptive offset. We integrate the proposed algorithm into the test model HM 13.0 and present a detailed comparative analysis. Experimental results show that the proposed fast DEA-based intra-coding algorithm reduces the computational complexity of HM 13.0 to about 46% in encoding time with 2.08% increases in the Biontegaard-Delta bitrate (BD-rate). Moreover, the proposed algorithm also demonstrates better performance over other state-of-the-art work.
C1 [Yao, Yingbiao; Jia, Tianjie; Li, Xiaojuan; Lu, Yu] Hangzhou Dianzi Univ, Coll Commun Engn, Hangzhou Xiasha 2 Rd, Hangzhou 310018, Zhejiang, Peoples R China.
C3 Hangzhou Dianzi University
RP Yao, YB (corresponding author), Hangzhou Dianzi Univ, Coll Commun Engn, Hangzhou Xiasha 2 Rd, Hangzhou 310018, Zhejiang, Peoples R China.
EM yaoyb@hdu.edu.cn
RI yao, yao/HHZ-7438-2022
CR [Anonymous], 2013, P 11 JCT VC M
   Bossen F., 2012, JCTVCK1100 ITUTISOIE
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chaple G.N., 2015, 2015 INT C TECHNOLOG, DOI [DOI 10.1109/ICTSD.2015, 10.1109/ictsd.2015]
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   da Silva TL, 2012, EUR SIGNAL PR CONF, P1214
   Gao LF, 2015, IEEE INT SYMP CIRC S, P517, DOI 10.1109/ISCAS.2015.7168684
   Gender W, 2015, IEEE IMAGE PROC, P242, DOI 10.1109/ICIP.2015.7350796
   Jaehwan Joo, 2013, 2013 IEEE Third International Conference on Consumer Electronics - Berlin (ICCE-Berlin). Proceedings, P50, DOI 10.1109/ICCE-Berlin.2013.6698011
   Joo J, 2014, IEEE IMAGE PROC, P3749, DOI 10.1109/ICIP.2014.7025761
   Khan MUK, 2013, IEEE IMAGE PROC, P1578, DOI 10.1109/ICIP.2013.6738325
   Kim WS, 2013, INT CONF ACOUST SPEE, P1700, DOI 10.1109/ICASSP.2013.6637942
   Lee JH, 2015, I SYMP CONSUM ELECTR, P270, DOI 10.1109/ICCE.2015.7066409
   Pan F, 2005, IEEE T CIRC SYST VID, V15, P813, DOI 10.1109/TCSVT.2005.848356
   Piao Y, 2010, JCTVCC207 ITUTISOIEC
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Suwanmanee S, 2013, BIOM ENG INT C BMEIC, P1, DOI DOI 10.1109/BMEICON.2013.6687686
   Tian GF, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P405, DOI 10.1109/PCS.2012.6213317
   Ting YC, 2014, IEEE INT SYMP CIRC S, P1929, DOI 10.1109/ISCAS.2014.6865538
   Tsai AC, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1587
   Yao YB, 2016, MULTIMED TOOLS APPL, V75, P1963, DOI 10.1007/s11042-014-2382-7
   Yoo HM, 2014, ELECTRON LETT, V50, P750, DOI 10.1049/el.2014.0451
   Zhao Liang, 2011, VISUAL COMMUN-US, P1, DOI DOI 10.1109/VCIP.2011.6115979
NR 24
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1861
EP 1881
DI 10.1007/s11042-017-4372-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400017
DA 2024-07-18
ER

PT J
AU Lee, JG
   Choi, KC
   Yeon, SH
   Kim, JW
   Ko, YW
AF Lee, Jae-Gu
   Choi, Kyung-Chan
   Yeon, Seung-Ho
   Kim, Jeong Won
   Ko, Young-Woong
TI Enhanced image similarity analysis system in digital pathology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE OpenSlide; Leveling; Tiling; Image similarity; Image sync
AB In digital pathology, image similarity algorithms are used to find cancer in tissue cells from medical images. However, it is very difficult to apply image similarity algorithms used in general purpose system. Because in the medical field, accuracy and reliability must be perfect when looking for cancer cells by using image similarity techniques to pathology images. To cope with this problem, this paper proposes an efficient similar image search algorithm for digital pathology by applying leveling and tiling scheme on OpenSlide format. Furthermore, we apply image sync method to extract feature key points during image similarity processing. In the experiment, to prove the efficiency of the proposed system, we conduct several experiments including algorithm performance, algorithm accuracy and computation time. The experiments result shows that the proposed system efficiently retrieves similar cell images from pathology images.
C1 [Lee, Jae-Gu; Yeon, Seung-Ho; Ko, Young-Woong] Hallym Univ, Dept Comp Engn, Chunchon 200702, Gangwon, South Korea.
   [Choi, Kyung-Chan] Hallym Univ, Chuncheon Sacred Heart Hosp, Dept Pathol, Chunchon 200702, Gangwon, South Korea.
   [Kim, Jeong Won] Hallym Univ, Kangnam Sacred Heart Hosp, Dept Pathol, Coll Med, Seoul 07441, South Korea.
C3 Hallym University; Hallym University; Hallym University
RP Ko, YW (corresponding author), Hallym Univ, Dept Comp Engn, Chunchon 200702, Gangwon, South Korea.
EM yuko@hallym.ac.kr
OI ko, young woong/0000-0002-6292-0799
FU Hallym University [H20150684]; Leading Human Resource Training Program
   of Regional Neo industry through the National Research Foundation of
   Korea (NRF) - Ministry of Science, ICT and future Planning
   [2016H1D5A1910630]
FX This research was supported by Hallym University Research Fund
   2015(H20150684) and this research was also supported by The Leading
   Human Resource Training Program of Regional Neo industry through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Science, ICT and future Planning (2016H1D5A1910630).
CR [Anonymous], 2010, IEEE T INF FOREN SEC, DOI DOI 10.1109/TIFS.2010.2078506
   Chiu LC, 2013, IEEE T IMAGE PROCESS, V22, P3158, DOI 10.1109/TIP.2013.2259841
   Corvee E, 2010, 2010 7 IEEE INT C IE
   Déniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   Goode Adam, 2013, J Pathol Inform, V4, P27, DOI 10.4103/2153-3539.119005
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Kang LW, 2011, IEEE T MULTIMEDIA, V13, P1019, DOI 10.1109/TMM.2011.2159197
   Karatzanis I, 2014, 2014 6TH INTERNATIONAL ADVANCED RESEARCH WORKSHOP ON IN SILICO ONCOLOGY AND CANCER INVESTIGATION (IARWISOCI)
   Miksik O, 2012, 2012 21 INT C IEEE
   Pan HW, 2014, IEEE J BIOMED HEALTH, V18, P574, DOI 10.1109/JBHI.2013.2274798
   Psyllos AP, 2010, IEEE T INTELL TRANSP, V11, P322, DOI 10.1109/TITS.2010.2042714
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rublee E, 2011, 2011 I E INT C IEEE
   Shi J, 2013, 2013 7 INT C IEEE
   Xu G, 2011, 2011 I E INT C IEEE
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Zhang Y, 2011, 2011 I E C IEEE
   Zhao X, 2011, IEEE T IMAGE PROCESS, V20, P790, DOI 10.1109/TIP.2010.2068553
   Zheng Y, 2014, 2014 I E INT C IEEE
NR 19
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25477
EP 25494
DI 10.1007/s11042-017-4773-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300049
DA 2024-07-18
ER

PT J
AU Mostafa, A
   Hassanien, AE
   Houseni, M
   Hefny, H
AF Mostafa, Abdalla
   Hassanien, Aboul Ella
   Houseni, Mohamed
   Hefny, Hesham
TI Liver segmentation in MRI images based on whale optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Whale optimizer; Clustering; Segmentation
AB This paper proposes an approach for liver segmentation in MRI images based on Whale optimization algorithm (WOA). It is used to extract the different clusters in the abdominal image to support the segmentation process. A statistical image is prepared to define the potential liver position in the abdominal image. Then, WOA divides the image into a predefined number of clusters. The prepared statistical image is converted into a binary image and multiplied by the image clustered by WOA. This multiplication process removes a great part of other organs from the image. It is followed by some points, picked up by user interaction, representing the required clusters which reside in the area of liver. The morphological operations enhance the initial segmented liver and produces the final image. The proposed approach is tested using a set of 70 MRI images, annotated and approved by radiology specialists. The resulting image is validated using structural similarity index measure (SSIM), similarity index (SI) and other five measures. The overall accuracy of the experimental result showed accuracy of 96.75% using SSIM and 97.5 using SI%.
C1 [Mostafa, Abdalla] Cairo Univ, Inst Stat Studies & Res, Dept Comp Sci, Giza, Egypt.
   [Hefny, Hesham] Cairo Univ, Inst Stat Studies & Res, Comp Sci, Giza, Egypt.
   [Hassanien, Aboul Ella] Cairo Univ, Fac Comp & Informat, Giza, Egypt.
   [Houseni, Mohamed] Menoufia Univ, Natl Liver Inst, Radiol Dept, Shibin Al Kawm, Egypt.
   [Mostafa, Abdalla; Hassanien, Aboul Ella] SRGE, Cairo, Egypt.
   [Mostafa, Abdalla] ISSR, Comp Dept, 5 Zewail St, Giza, Egypt.
C3 Egyptian Knowledge Bank (EKB); Cairo University; Egyptian Knowledge Bank
   (EKB); Cairo University; Egyptian Knowledge Bank (EKB); Cairo
   University; Egyptian Knowledge Bank (EKB); Menofia University
RP Mostafa, A (corresponding author), Cairo Univ, Inst Stat Studies & Res, Dept Comp Sci, Giza, Egypt.; Mostafa, A (corresponding author), SRGE, Cairo, Egypt.; Mostafa, A (corresponding author), ISSR, Comp Dept, 5 Zewail St, Giza, Egypt.
EM abdalla_mosta75@yahoo.com
RI Hassanien, Aboul ella/O-5672-2014; Hefny, Hesham/A-5619-2013; Hefny,
   Hesham/AAA-3071-2020
OI Hassanien, Aboul ella/0000-0002-9989-6681; Hefny,
   Hesham/0000-0001-5862-675X; Houseni, Mohamed/0000-0001-8386-4581
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Ali AR, 2014, COMM COM INF SC, V488, P331
   [Anonymous], 2014, SCI WORLD J
   [Anonymous], 2014, INT J COMPUT COMMUN, DOI DOI 10.7763/IJCCE.2014.V3.281
   [Anonymous], 20 INT C PATT REC IS
   [Anonymous], NATURE INSPIRED META
   [Anonymous], 2014, J COMPUT INF SYST
   [Anonymous], 2015, Swarm Intelligence: Principles, Advances and Applications
   Ben George E, 2012, INT J ENG TECHNOLOGY, V4
   Chen EL, 1998, IEEE T BIO-MED ENG, V45, P783, DOI 10.1109/10.678613
   Dorigo M, 2005, THEOR COMPUT SCI, V344, P243, DOI 10.1016/j.tcs.2005.05.020
   Fouad Ali A, 2016, NATURE INSPIRED OPTI
   Horng MH, 2011, EXPERT SYST APPL, V38, P13785, DOI 10.1016/j.eswa.2011.04.180
   Junrui L, 2015, INT J SIGNAL PROCESS, V8, P239
   Karaboga D, LECT NOTES COMPUTER, V4529, P789
   Karaboga D, 2009, APPL MATH COMPUT, V214, P108, DOI 10.1016/j.amc.2009.03.090
   Kaur D, 2014, INT J COMPUTER SCI I, V5
   Li X., 2013, J. Signal Inf. Process, V4, P36, DOI DOI 10.4236/JSIP.2013.43B007
   Liang Y., 2013, INT J INNOV COMPUT I, V9, P1
   Liu X., 2014, INT J SIGNAL PROCESS, V7, P433
   Mandal D, 2014, ENG APPL ARTIF INTEL, V35, P199, DOI 10.1016/j.engappai.2014.07.001
   Miguel Carreira-Perpinan A, 2015, HDB CLUSTER ANAL CRC
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mostafa A, 2012, INT C BIOM HLTH INF
   Mostafa A., 2015, 1 INT C ADV INT SYST
   Mostafa A, 2015, INT AFR C IND ADV AE
   Mostafa A., 2015, INT C ADV INF TECHN
   Mostafa A, 2015, PROCEDIA COMPUT SCI, V60, P1622, DOI 10.1016/j.procs.2015.08.272
   Nelson AL, 2009, ROBOT AUTON SYST, V57, P345, DOI 10.1016/j.robot.2008.09.009
   Neumüller C, 2012, LECT NOTES COMPUT SC, V6927, P367
   Oliveira DAB, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-30
   Raja NSM, 2014, MOD SIMUL ENG, V2014, DOI 10.1155/2014/794574
   Robinson PJA, 2006, MRI LIVER A PRACTICA
   Sankari L, 2014, INT J SCI REIJSR, V3
   Sivaramakrishnan A, INT C INF IM PROC IC, P316
   Sunny S, 2014, INT J EMERGING TECHN, V1
   Szeliski R, 2014, COMPUTER VISION ALGO
   Talbi E.-G, 2009, METAHEURISTICS DESIG, V74, DOI DOI 10.1002/9780470496916
   Thiagarajan B, 2014, INT J MED HLTH BIOME, V8
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu  G., 2015, BIOMEDICAL ENG ONLIN, P14
   Xian-hua J, 2013, INT J DIGITAL CONTEN, V7
   Zidan A, 2012, 12 INT C HYBR INT SY
   Zidan A, 2013, INT J IMAGING ROBOTI, V9
NR 44
TC 73
Z9 74
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 24931
EP 24954
DI 10.1007/s11042-017-4638-5
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300020
DA 2024-07-18
ER

PT J
AU Niu, YZ
   Lin, LN
   Chen, YZ
   Ke, LL
AF Niu, Yuzhen
   Lin, Lening
   Chen, Yuzhong
   Ke, Lingling
TI Machine learning-based framework for saliency detection in distorted
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distortion type; Saliency detection; Distortion level; Distortion
   removal
ID JPEG DECOMPRESSION
AB Visual saliency detection is useful in carrying out image compression, image segmentation, image retrieval, and other image processing applications. Majority of existing saliency detection algorithms are presented for distortion-free images. However, this situation is not always the case. In this paper, we first evaluate the performances of state-of-the-art saliency detection algorithms against different distortion types and levels. A machine learning-based framework for saliency detection is proposed for two common types of distortions, noise and JPEG compression. First, a machine learning method is proposed to predict the distortion level, and then the distortion is removed using the parameter setting that is tuned for that distortion level. Finally, the saliency map is calculated by using saliency detection algorithms. We evaluate the saliency detection algorithms on Tampere Image Database (TID2013), which is proposed for image quality assessment application. We manually label the salient objects in each image and obtain its ground truth saliency map in order to adapt TID2013 for visual saliency detection application. Experimental results demonstrate that the distortions usually decrease the performances of the saliency detection algorithms, particularly in high levels of distortions. The performance rankings of the saliency detection algorithms for the distortion-free images and distorted images are different. Moreover, our proposed machine learning-based framework for saliency detection improves the performances of saliency detection algorithms in distorted images in most of the distortion levels, particularly in high levels of distortions.
C1 [Niu, Yuzhen; Lin, Lening; Chen, Yuzhong; Ke, Lingling] Fuzhou Univ, Coll Math & Comp Sci, Qi Shan Campus,2 Xue Yuan Rd, Fuzhou 350116, Fujian, Peoples R China.
   [Niu, Yuzhen; Lin, Lening; Chen, Yuzhong; Ke, Lingling] Fuzhou Univ, Fujian Key Lab Network Comp & Intelligent Informa, Fuzhou, Fujian, Peoples R China.
C3 Fuzhou University; Fuzhou University
RP Chen, YZ (corresponding author), Fuzhou Univ, Coll Math & Comp Sci, Qi Shan Campus,2 Xue Yuan Rd, Fuzhou 350116, Fujian, Peoples R China.; Chen, YZ (corresponding author), Fuzhou Univ, Fujian Key Lab Network Comp & Intelligent Informa, Fuzhou, Fujian, Peoples R China.
EM yzchen@fzu.edu.cn
FU National Natural Science Foundation of China [61300102, 61672158];
   Fujian Natural Science Funds for Distinguished Young Scholar
   [2015J06014]; Natural Science Foundation of Fujian Province
   [2014J01233]; Key Project of Industry-Academic Cooperation of Fujian
   Province [2014H6014]
FX This work is partly supported by the National Natural Science Foundation
   of China under Grant No. 61300102 and No. 61672158, the Fujian Natural
   Science Funds for Distinguished Young Scholar under Grant No.
   2015J06014, the Natural Science Foundation of Fujian Province under
   Grant No. 2014J01233, and the Key Project of Industry-Academic
   Cooperation of Fujian Province under Grant No. 2014H6014.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alers H., TUD IMAGE QUALITY DA
   [Anonymous], 2008, P INT C NEUR INF PRO
   Bao L, 2015, MULTIMED TOOLS APPL, V74, P4045, DOI 10.1007/s11042-014-2043-x
   Bredies K, 2012, SIAM J IMAGING SCI, V5, P366, DOI 10.1137/110833531
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Burger H., 2012, CVPR
   Chang HB, 2014, IEEE T SIGNAL PROCES, V62, P718, DOI 10.1109/TSP.2013.2290508
   Dabov K, 2007, IEEE IMAGE PROC, P313, DOI 10.1109/icip.2007.4378954
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Gide MS, 2012, COMP EVALUATION VISU
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Kim C, 2013, J VISION, V13, DOI 10.1167/13.4.5
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Kong XF, 2013, IEEE I CONF COMP VIS, P2888, DOI 10.1109/ICCV.2013.359
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Liang ZJ, 2014, MULTIMED TOOLS APPL, V68, P517, DOI 10.1007/s11042-012-1040-1
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Neethu KJ, 2015, INT J ADV RES COMPUT, V3, P350
   Niu YZ, 2012, IEEE T CIRC SYST VID, V22, P1037, DOI 10.1109/TCSVT.2012.2189689
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Tang C, 2016, MULTIMED TOOLS APPL, V75, P6963, DOI 10.1007/s11042-015-2622-5
   Wang Z, 2002, IEEE IMAGE PROC, P477
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 35
TC 17
Z9 17
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26329
EP 26353
DI 10.1007/s11042-016-4128-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500037
DA 2024-07-18
ER

PT J
AU Tsipas, N
   Vrysis, L
   Dimoulas, C
   Papanikolaou, G
AF Tsipas, Nikolaos
   Vrysis, Lazaros
   Dimoulas, Charalampos
   Papanikolaou, George
TI Efficient audio-driven multimedia indexing through similarity-based
   speech/music discrimination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech/music discrimination; Self-similarity matrix analysis; Transition
   point detection; Supervised learning
ID MUSIC
AB In this paper, an audio-driven algorithm for the detection of speech and music events in multimedia content is introduced. The proposed approach is based on the hypothesis that short-time frame-level discrimination performance can be enhanced by identifying transition points between longer, semantically homogeneous segments of audio. In this context, a two-step segmentation approach is employed in order to initially identify transition points between the homogeneous regions and subsequently classify the derived segments using a supervised binary classifier. The transition point detection mechanism is based on the analysis and composition of multiple self-similarity matrices, generated using different audio feature sets. The implemented technique aims at discriminating events focusing on transition point detection with high temporal resolution, a target that is also reflected in the adopted assessment methodology. Thereafter, multimedia indexing can be efficiently deployed (for both audio and video sequences), incorporating the processes of high resolution temporal segmentation and semantic annotation extraction. The system is evaluated against three publicly available datasets and experimental results are presented in comparison with existing implementations. The proposed algorithm is provided as an open source software package in order to support reproducible research and encourage collaboration in the field.
C1 [Tsipas, Nikolaos; Vrysis, Lazaros; Dimoulas, Charalampos; Papanikolaou, George] Aristotle Univ Thessaloniki, Thessaloniki 54124, Greece.
C3 Aristotle University of Thessaloniki
RP Tsipas, N (corresponding author), Aristotle Univ Thessaloniki, Thessaloniki 54124, Greece.
EM nitsipas@auth.gr; lvrysis@auth.gr; babis@eng.auth.gr; pap@eng.auth.gr
RI Dimoulas, Charalampos/ABU-1098-2022; Vrysis, Lazaros/V-2260-2019
OI Dimoulas, Charalampos/0000-0001-7923-9361; Vrysis,
   Lazaros/0000-0003-2900-4657; Tsipas, Nikolaos/0000-0001-7232-8839
CR Ajmera J, 2001, TECH REP
   Miro XA, 2012, IEEE T AUDIO SPEECH, V20, P356, DOI 10.1109/TASL.2011.2125954
   Carey MJ, 1999, INT CONF ACOUST SPEE, P149, DOI 10.1109/ICASSP.1999.758084
   Dimoulas CA, 2015, IEEE MULTIMEDIA, V22, P26, DOI 10.1109/MMUL.2015.33
   El-Maleh K, 2000, INT CONF ACOUST SPEE, P2445, DOI 10.1109/ICASSP.2000.859336
   Elizalde B, 2013, IEEE INT CON MULTI
   Foote J, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P452, DOI 10.1109/ICME.2000.869637
   Foote J, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P77, DOI 10.1145/319463.319472
   Jiang H, 2000, P IEEE ICME
   Jun S, 2015, MULTIMED TOOLS APPL, V74, P287, DOI 10.1007/s11042-013-1761-9
   Khonglah BK, 2016, DIGIT SIGNAL PROCESS, V48, P71, DOI 10.1016/j.dsp.2015.09.005
   Kim SK, 2009, IEICE T FUND ELECTR, VE92A, P630, DOI 10.1587/transfun.E92.A.630
   Kinnunen T., 2007, INT C SPEECH COMPUTE, V2, P556
   Kotsakis R, 2012, SPEECH COMMUN, V54, P743, DOI 10.1016/j.specom.2012.01.004
   Lavner Y, 2009, EURASIP J AUDIO SPEE, DOI 10.1155/2009/239892
   Lim C, 2015, MULTIMED TOOLS APPL, V74, P5375, DOI 10.1007/s11042-014-1859-8
   Mathieu B., 2010, P 11 INT C MUS INF R, P441
   Minami K, 1998, IEEE MULTIMEDIA, V5, P17, DOI 10.1109/93.713301
   Moattar M. H., 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P2549
   Panagiotakis C, 2005, IEEE T MULTIMEDIA, V7, P155, DOI 10.1109/TMM.2004.840604
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pikrakis A, 2006, SIGN PROC C 2006 14, P1
   Pikrakis A, 2008, IEEE T MULTIMEDIA, V10, P846, DOI 10.1109/TMM.2008.922870
   Pikrakis A, 2014, EUR SIGNAL PR CONF, P616
   Ramalingam Thiruvengatanadhan, 2014, Journal of Computer Science, V10, P34, DOI 10.3844/jcssp.2014.34.44
   Saunders J, 1996, INT CONF ACOUST SPEE, P993, DOI 10.1109/ICASSP.1996.543290
   Scheirer E, 1997, INT CONF ACOUST SPEE, P1331, DOI 10.1109/ICASSP.1997.596192
   Sell Gregory, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2489, DOI 10.1109/ICASSP.2014.6854048
   Seyerlehner K., 2007, P 10 INT C DIG AUD E
   Shirazi J, 2010, MULTIMED TOOLS APPL, V50, P415, DOI 10.1007/s11042-009-0416-3
   Teodorescu H.N., 2015, IEEE P JOINT C 4 INT, V107C, P325, DOI 10.1016/j.proeng.2015.06.088
   Tsipas N., 2015, P MUS INF RETR EV EX
   Tsipas N, 2015, AUDIO ENG SOC CONVEN, P138
   Tsipas N, 2015, PROCEEDINGS OF THE 10TH AUDIO MOSTLY: A CONFERENCE ON INTERACTION WITH SOUND, AM'15, DOI 10.1145/2814895.2814907
   Wieser Ewald, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2134, DOI 10.1109/ICASSP.2014.6853976
   Zhang T, 2001, IEEE T SPEECH AUDI P, V9, P441, DOI 10.1109/89.917689
NR 36
TC 18
Z9 18
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 25603
EP 25621
DI 10.1007/s11042-016-4315-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500005
DA 2024-07-18
ER

PT J
AU Yang, XM
   Wu, W
   Liu, K
   Chen, WL
   Zhang, P
   Zhou, ZL
AF Yang, Xiaomin
   Wu, Wei
   Liu, Kai
   Chen, Weilong
   Zhang, Ping
   Zhou, Zhili
TI Multi-sensor image super-resolution with fuzzy cluster by using
   multi-scale and multi-view sparse coding for infrared image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-sensor; Super-resolution; Sparse coding; Infrared image;
   Dictionary learning; Multiview representation; Fuzzy clustering theory
ID INTERPOLATION; SEGMENTATION; DICTIONARY; ALGORITHM; MOTION
AB Super-resolution (SR) methods are effective for generating a high-resolution image from a single low-resolution image. However, four problems are observed in existing SR methods. (1) They cannot reconstruct many details from a low-resolution infrared image because infrared images always lack detailed information. (2) They cannot extract the desired information from images because they do not consider that images naturally come at different scales in many cases. (3) They fail to reveal different physical structures of low-resolution patch because they extract features from a single view. (4) They fail to extract all the different patterns because they use only one dictionary to represent all patterns. To overcome these problems, we propose a novel SR method for infrared images. First, we combine the information of high-resolution visible light images and low-resolution infrared images to improve the resolution of infrared images. Second, we use multiscale patches instead of fixed-size patches to represent infrared images more accurately. Third, we use different feature vectors rather than a single feature to represent infrared images. Finally, we divide training patches into several clusters, and multiple dictionaries are learned for each cluster to provide each patch with a more accurate dictionary. In the proposed method, clustering information for low-resolution patches is learnt by using fuzzy clustering theory. Experiments validate that the proposed method yields better results in terms of quantization and visual perception than the state-of-the-art algorithms.
C1 [Yang, Xiaomin; Wu, Wei] Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Sichuan, Peoples R China.
   [Liu, Kai] Sichuan Univ, Sch Elect Engn & Informat, Chengdu 610064, Sichuan, Peoples R China.
   [Chen, Weilong] Sichuan Normal Univ, Coll Movie & Media, Chengdu 610018, Sichuan, Peoples R China.
   [Zhang, Ping] Univ Elect Sci & Technol China, Graph Image & Signal Proc Applicat Lab, Chengdu 611731, Sichuan, Peoples R China.
   [Zhou, Zhili] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
   [Zhou, Zhili] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Sichuan University; Sichuan University; Sichuan Normal University;
   University of Electronic Science & Technology of China; Nanjing
   University of Information Science & Technology; Nanjing University of
   Information Science & Technology
RP Wu, W (corresponding author), Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Sichuan, Peoples R China.
EM arielyang@scu.edu.cn; wuwei@scu.edu.cn; kailiu@scu.edu.cn;
   312790467@qq.com; pingzh@uestc.edu.cn; zhou_zhili@163.com
RI yang, xiao/HJI-7815-2023; xu, chen/JNE-5010-2023; zhen,
   wang/KBA-3844-2024; Liu, Kai/IST-6808-2023
OI Wu, Wei/0000-0001-5769-9340
FU National Natural Science Foundation of China [61271330, 61473198];
   Priority Academic Program Development of Jiangsu Higer Education
   Institutions(PAPD) Fund; Jiangsu Collaborative Innovation Center on
   Atmospheric Environment and Equipment Technology(CICAEET) Fund
FX The research is sponsored by the National Natural Science Foundation of
   China(No. 61271330, No. 61473198), also is supported by the Priority
   Academic Program Development of Jiangsu Higer Education
   Institutions(PAPD) Fund, Jiangsu Collaborative Innovation Center on
   Atmospheric Environment and Equipment Technology(CICAEET) Fund.
CR Aguena MLS, 2006, COMPUT VIS IMAGE UND, V102, P178, DOI 10.1016/j.cviu.2006.01.001
   [Anonymous], 1984, ADV COMPUTER VISION
   Ben XY, 2013, NEUROCOMPUTING, V120, P577, DOI 10.1016/j.neucom.2013.04.012
   Ben XY, 2012, NEUROCOMPUTING, V97, P44, DOI 10.1016/j.neucom.2012.06.022
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Dodgson NA, 1997, IEEE T IMAGE PROCESS, V6, P1322, DOI 10.1109/83.623195
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Fu ZJ, 2016, IEEE T INF FOREN SEC, V11, P2706, DOI 10.1109/TIFS.2016.2596138
   Huang DA, 2013, IEEE I CONF COMP VIS, P2496, DOI 10.1109/ICCV.2013.310
   Jeon G, 2013, SENSORS-BASEL, V13, P3056, DOI 10.3390/s130303056
   Jeon G, 2010, J DISP TECHNOL, V6, P235, DOI 10.1109/JDT.2009.2037524
   Jeon G, 2009, IMAGE VISION COMPUT, V27, P425, DOI 10.1016/j.imavis.2008.06.001
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Li XL, 2010, SIGNAL PROCESS, V90, P405, DOI 10.1016/j.sigpro.2009.05.028
   Mairal J, 2008, MULTISCALE MODEL SIM, V7, P214, DOI 10.1137/070697653
   Morris N.J.W., 2007, P CVPR, V1, P17
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Qu XB, 2015, ANGEW CHEM INT EDIT, V54, P852, DOI 10.1002/anie.201409291
   Qu XB, 2014, MED IMAGE ANAL, V18, P843, DOI 10.1016/j.media.2013.09.007
   Tang Y, 2011, 2011 FIRST ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P52, DOI 10.1109/ACPR.2011.6166563
   Vrigkas M, 2013, SIGNAL PROCESS-IMAGE, V28, P494, DOI 10.1016/j.image.2012.12.008
   Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Wu W, 2016, J SYST ARCHITECT, V64, P63, DOI 10.1016/j.sysarc.2015.11.005
   Wu W, 2013, OPT COMMUN, V287, P63, DOI 10.1016/j.optcom.2012.08.101
   Wu W, 2011, IMAGE VISION COMPUT, V29, P394, DOI 10.1016/j.imavis.2011.02.001
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang XM, 2016, J SYST ARCHITECT, V64, P11, DOI 10.1016/j.sysarc.2015.11.007
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang KB, 2012, PROC CVPR IEEE, P1114, DOI 10.1109/CVPR.2012.6247791
   Zhang KB, 2011, IEEE J-STSP, V5, P230, DOI 10.1109/JSTSP.2010.2048606
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 37
TC 10
Z9 10
U1 1
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 24871
EP 24902
DI 10.1007/s11042-017-4639-4
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300017
DA 2024-07-18
ER

PT J
AU Kuang, SF
   Chao, HY
   Yang, J
AF Kuang, Shenfen
   Chao, HongYang
   Yang, Jun
TI Efficient <i>l</i> <sub><i>q</i></sub> norm based sparse subspace
   clustering via smooth IRLS and ADMM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse subspace clustering; Smooth IRLS; ADMM; l(q) minimization; Sparse
   representation
ID REWEIGHTED LEAST-SQUARES; ENHANCING SPARSITY; MINIMIZATION; RECOVERY
AB Recently, sparse subspace clustering, as a subspace learning technique, has been successfully applied to several computer vision applications, e.g. face clustering and motion segmentation. The main idea of sparse subspace clustering is to learn an effective sparse representation that are used to construct an affinity matrix for spectral clustering. While most of existing sparse subspace clustering algorithms and its extensions seek the forms of convex relaxation, the use of non-convex and non-smooth l (q) (0 < q < 1) norm has demonstrated better recovery performance. In this paper we propose an l (q) norm based Sparse Subspace Clustering method (lqSSC), which is motivated by the recent work that l (q) norm can enhance the sparsity and make better approximation to l (0) than l (1). However, the optimization of l (q) norm with multiple constraints is much difficult. To solve this non-convex problem, we make use of the Alternating Direction Method of Multipliers (ADMM) for solving the l (q) norm optimization, updating the variables in an alternating minimization way. ADMM splits the unconstrained optimization into multiple terms, such that the l (q) norm term can be solved via Smooth Iterative Reweighted Least Square (SIRLS), which converges with guarantee. Different from traditional IRLS algorithms, the proposed algorithm is based on gradient descent with adaptive weight, making it well suit for general sparse subspace clustering problem. Experiments on computer vision tasks (synthetic data, face clustering and motion segmentation) demonstrate that the proposed approach achieves considerable improvement of clustering accuracy than the convex based subspace clustering methods.
C1 [Kuang, Shenfen; Chao, HongYang; Yang, Jun] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Guangdong, Peoples R China.
   [Kuang, Shenfen] Shaoguan Univ, Sch Math & Stat, Shaoguan, Peoples R China.
C3 Sun Yat Sen University; Shaoguan University
RP Chao, HY (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Guangdong, Peoples R China.
EM shfkuang@gmail.com; isschhy@mail.sysu.edu.cn; yangj95@mail2.sysu.edu.cn
FU NSF of China [61672548, 61173081]; Guangzhou Science and Tech-nology
   Program, China [201510010165]
FX This work is partially supported by NSF of China under Grant 61672548,
   61173081, and the Guangzhou Science and Tech-nology Program, China,
   under Grant 201510010165.
CR [Anonymous], 2015, ARXIV150500824
   [Anonymous], 2012, EUR C COMP VIS
   [Anonymous], 2009, NEURAL COMPUT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2016, BRAIN INFORM
   [Anonymous], ARXIV150707105
   [Anonymous], 2015, ARXIV150904063
   [Anonymous], AAAI C ART INT AAAI
   [Anonymous], INT C COMP VIS
   [Anonymous], COMPUT VIS IMAGE UND
   [Anonymous], ARXIV150701307
   [Anonymous], 2013, ARXIV13074891
   Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Cheng WL, 2016, NEUROCOMPUTING, V205, P22, DOI 10.1016/j.neucom.2016.04.010
   Daubechies I, 2010, COMMUN PUR APPL MATH, V63, P1, DOI 10.1002/cpa.20303
   Deng Y, 2013, IEEE T NEUR NET LEAR, V24, P383, DOI 10.1109/TNNLS.2012.2235082
   Dyer EL, 2013, J MACH LEARN RES, V14, P2487
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Feng JS, 2014, PROC CVPR IEEE, P3818, DOI 10.1109/CVPR.2014.482
   Fornasier M, 2011, SIAM J OPTIMIZ, V21, P1614, DOI 10.1137/100811404
   Guo S, 2013, NEUROCOMPUTING, V99, P592, DOI 10.1016/j.neucom.2012.05.028
   He R, 2015, IEEE T IMAGE PROCESS, V24, P4001, DOI 10.1109/TIP.2015.2456504
   Lai MJ, 2013, SIAM J NUMER ANAL, V51, P927, DOI 10.1137/110840364
   Lai MJ, 2011, SIAM J OPTIMIZ, V21, P82, DOI 10.1137/090775397
   Liu G., 2010, P 27 INT C MACH LEAR
   Liu JM, 2014, IEEE T IMAGE PROCESS, V23, P4022, DOI 10.1109/TIP.2014.2343458
   Lu CY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2014.2380155
   Soltanolkotabi M, 2014, ANN STAT, V42, P669, DOI 10.1214/13-AOS1199
   Sui Y, 2015, IEEE T IMAGE PROCESS, V24, P4686, DOI 10.1109/TIP.2015.2462076
   Vidal R, 2014, PATTERN RECOGN LETT, V43, P47, DOI 10.1016/j.patrec.2013.08.006
   Wang S., 2011, AAAI, V1, P519
   Wen JM, 2015, APPL COMPUT HARMON A, V38, P161, DOI 10.1016/j.acha.2014.06.003
   Yang AY, 2013, IEEE T IMAGE PROCESS, V22, P3234, DOI 10.1109/TIP.2013.2262292
   Zhang CH, 2012, STAT SCI, V27, P576, DOI 10.1214/12-STS399
   Zhang YY, 2013, IEEE I CONF COMP VIS, P3096, DOI 10.1109/ICCV.2013.384
NR 37
TC 4
Z9 4
U1 4
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23163
EP 23185
DI 10.1007/s11042-016-4091-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700002
DA 2024-07-18
ER

PT J
AU Wang, SH
   Zhao, JW
   Chen, YQ
AF Wang, Shuo Hong
   Zhao, Jing Wen
   Chen, Yan Qiu
TI Robust tracking of fish schools using CNN for head identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-object tracking; Tracking by identification; Fish school;
   Convolutional neural network
ID VIDEO TRACKING; ETHOVISION; NETWORKS; BEHAVIOR; SYSTEM
AB Tracking individuals in a fish school with video cameras is one of the most effective ways to quantitatively investigate their behavior which is of great value for biological research. However, tracking large numbers of fish with complex non-rigid deformation, similar appearance and frequent mutual occlusions is a challenge task. In this paper we propose an effective tracking method that can reliably track a large number of fish throughout the entire duration. The first step of the proposed method is to detect fish heads using a scale-space method. Data association across frames is achieved via identifying the head image pattern of each individual fish in each frame, which is accomplished by a convolutional neural network (CNN) specially tailored to suit this task. Then the prediction of the motion state and the recognition result by CNN are combined to associate detections across frames. The proposed method was tested on 5 video clips having different number of fish respectively. Experiment results show that the correctness of their identities is not affected by frequent occlusions. The proposed method outperforms two state-of-the-art fish tracking methods in terms of 7 performance metrics.
C1 [Wang, Shuo Hong; Zhao, Jing Wen; Chen, Yan Qiu] Fudan Univ, Shanghai Key Lab Intelligent Informat Proc, Sch Comp Sci, Shanghai, Peoples R China.
C3 Fudan University
RP Chen, YQ (corresponding author), Fudan Univ, Shanghai Key Lab Intelligent Informat Proc, Sch Comp Sci, Shanghai, Peoples R China.
EM sh_wang@fudan.edu.cn; jingwenzhao13@fudan.edu.cn; chenyq@fudan.edu.cn
OI Zhao, Jingwen/0000-0001-9704-4066
FU National Natural Science Foundation of China [61175036]
FX Thanks to National Natural Science Foundation of China, Grant No.
   61175036 for funding.
CR Andriluka M., 2008, IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)
   [Anonymous], APPL SOFT COMPUT
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2014, ARXIV14124564
   [Anonymous], 2013, INT C LEARN REPR ICL
   [Anonymous], THESIS
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Berclaz J., 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, V1, P744, DOI DOI 10.1109/CVPR.2006.258
   Bruyndoncx L, 2002, J FISH BIOL, V60, P260, DOI 10.1006/jfbi.2001.1828
   Butail S, 2012, J R SOC INTERFACE, V9, P77, DOI 10.1098/rsif.2011.0113
   Ciresan D., 2012, ADV NEURAL INFORM PR, V25, P2843
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Delcourt J, 2006, BEHAV RES METHODS, V38, P704, DOI 10.3758/BF03193904
   Delcourt J, 2013, FISH FISH, V14, P186, DOI 10.1111/j.1467-2979.2012.00462.x
   Delcourt J, 2011, BEHAV RES METHODS, V43, P590, DOI 10.3758/s13428-011-0060-5
   Fan JL, 2010, IEEE T NEURAL NETWOR, V21, P1610, DOI 10.1109/TNN.2010.2066286
   Fontaine E, 2008, J EXP BIOL, V211, P1305, DOI 10.1242/jeb.010272
   Guo YW, 2014, COMPUT VIS IMAGE UND, V118, P128, DOI 10.1016/j.cviu.2013.09.007
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li HX, 2015, LECT NOTES COMPUT SC, V9007, P194, DOI 10.1007/978-3-319-16814-2_13
   Liu JD, 2010, J BIONIC ENG, V7, P35, DOI 10.1016/S1672-6529(09)60184-0
   Miller N., 2012, Zebrafish Protocols for Neurobehavioral Research, P217, DOI DOI 10.1007/978-1-61779-597-8_16
   Miller N, 2007, BEHAV BRAIN RES, V184, P157, DOI 10.1016/j.bbr.2007.07.007
   Noldus LPJJ, 2001, BEHAV RES METH INS C, V33, P398, DOI 10.3758/BF03195394
   Pérez-Escudero A, 2014, NAT METHODS, V11, P743, DOI [10.1038/NMETH.2994, 10.1038/nmeth.2994]
   Pirsiavash H, 2011, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2011.5995604
   Qian ZM, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0106506
   REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177
   Rosemberg DB, 2012, NEUROPHARMACOLOGY, V63, P613, DOI 10.1016/j.neuropharm.2012.05.009
   Rosenthal SB, 2015, P NATL ACAD SCI USA, V112, P4690, DOI 10.1073/pnas.1420068112
   Szegedy C., 2013, Advances in Neural Information Processing Systems, V26, P2553
   Wang T, 2012, INT C PATT RECOG, P3304
   Yu Q, 2007, IEEE C COMPUTER VISI, P1
   Yuan Li, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2953, DOI 10.1109/CVPRW.2009.5206735
   Zhou X, 2015, INT J ANTENN PROPAG, V2015, DOI 10.1155/2015/601835
NR 39
TC 39
Z9 42
U1 12
U2 66
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23679
EP 23697
DI 10.1007/s11042-016-4045-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700026
DA 2024-07-18
ER

PT J
AU Chang, HY
   Chen, KB
   Lu, HC
AF Chang, Hong-Yi
   Chen, Kwei-Bor
   Lu, Hsin-Che
TI A novel resource allocation mechanism for live cloud-based video
   streaming service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video streaming service; Cloud computing; Resource allocation; Nim game;
   Game theory; High utilization
AB With the recent emergence of cloud computing, growing numbers of clients are using online cloud services through the Internet such as video streaming service. The rent costs of cloud service providers increase when the resource utilizations of the cloud-servers are not well. Therefore, resource allocation is a crucial problem for cloud data centers. The resource allocation problem is an NP-hard problem. This paper proposes a novel cloud resource allocation mechanism based on a winning strategy for a Nim game. This mechanism offers all clients an effective number of running cloud servers, and allocates cloud resources rapidly and effectively by using a pre-pairing approach. The proposed mechanism does not require searching for remaining resources of the running cloud server; hence, it can reduce the time taken to arrange resources. The experimental results show that the proposed mechanism can improve utilization of cloud servers and reduce the rent costs of the cloud service providers. The proposed mechanism can reach the utilization of cloud servers by as much as 99.96 %. The proposed mechanism is approximately 9 % more efficient than the market-based grid resource allocation algorithm, and 19 % more efficient than the modified best fit decreasing algorithm.
C1 [Chang, Hong-Yi; Lu, Hsin-Che] Natl Chiayi Univ, Dept Management Informat Syst, Chiayi, Taiwan.
   [Chen, Kwei-Bor] Minghsin Univ Sci & Technol, Dept Comp Sci & Informat Engn, 1 Xinxing Rd, Hsinchu 30401, Taiwan.
C3 National Chiayi University
RP Chen, KB (corresponding author), Minghsin Univ Sci & Technol, Dept Comp Sci & Informat Engn, 1 Xinxing Rd, Hsinchu 30401, Taiwan.
EM hychang@mail.ncyu.edu.tw; kbchen.tw@gmail.com; s1001418@mail.ncyu.edu.tw
OI Chen, Kwei-Bor/0000-0002-9146-1069
FU Ministry of Science and Technology (MOST) project of Taiwan [MOST
   103-2221-E-415-021-, 104-2221-E-415-003-]
FX This work was supported by Ministry of Science and Technology (MOST)
   project of Taiwan [MOST 103-2221-E-415-021-] and [104-2221-E-415-003-].
   Furthermore, we wish to thank Yu-Huei Huang for his assistance in
   collecting the experiment data.
CR Abba H.A., 2012, RES J INFORM TECHNOL, V4, P38
   [Anonymous], 2009, UCBEECS200928
   Beloglazov A, 2012, FUTURE GENER COMP SY, V28, P755, DOI 10.1016/j.future.2011.04.017
   Bouton CL, 1901, ANN MATH, V3, P35, DOI 10.2307/1967631
   Chang HY, 2014, COMPUT J, V57, P255, DOI 10.1093/comjnl/bxt008
   Cheng Shi-wei, 2011, Computer Engineering, V37, P45, DOI 10.3969/j.issn.1000-3428.2011.11.016
   Elmisery AM, 2011, J CONVERGENCE, V2, P33
   Ferguson T.S., 2000, GAME THEORY
   Golmohammadi R., 2010, 2010 5th International Symposium on Telecommunications (IST), P187, DOI 10.1109/ISTEL.2010.5734022
   Isard M, 2009, SOSP'09: PROCEEDINGS OF THE TWENTY-SECOND ACM SIGOPS SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P261
   Li Li, 2009, Acta Electronica Sinica, V37, P165
   Li Ming-Chu, 2012, Journal of Software, V23, P428, DOI 10.3724/SP.J.1001.2012.03972
   Lin X, 2010, INF ELECT ENG, V8, P495
   Lu JX, 2004, COMPUT MODEENIZATION, V9
   Luo J, 2009, 2009 7TH INTERNATIONAL SYMPOSIUM ON MODELING AND OPTIMIZATION IN MOBILE, AD HOC, AND WIRELESS, P313
   Parsa S, 2009, NDT: 2009 FIRST INTERNATIONAL CONFERENCE ON NETWORKED DIGITAL TECHNOLOGIES, P146, DOI 10.1109/NDT.2009.5272120
   Peres Y., 2009, GAME THEORY ALIVE
   Sasnauskaite E, 2001, NIM GAME COMPUTER SC
   Singh Manpreet, 2010, Journal of Advances in Information Technology, V1, P133, DOI 10.4304/jait.1.3.133-135
   Sun DW, 2010, 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 2, P22, DOI 10.1109/ICACC.2010.5487177
   Tseng FH, 2011, HUM-CENTRIC COMPUT I, V1, DOI 10.1186/2192-1962-1-4
   Wang Xiaolin., 2011, JoC, V2, P19
   Xie X, 2012, HUM-CENTRIC COMPUT I, V2, DOI 10.1186/2192-1962-2-8
   Yaling Z, 2008, NEW TECHNOL LIB INF, V24, P32
   Yang Y- Q, 2009, J SCI TEACH COLL U, V5, P85
   Yousif A., 2011, INT J COMPUTER APPL, V16, P39
   Yu Chia-yu, 2006, INT MICR PACK ASS C, P1
NR 27
TC 7
Z9 7
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19689
EP 19706
DI 10.1007/s11042-016-3347-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500022
DA 2024-07-18
ER

PT J
AU Gaj, S
   Rathore, AK
   Sur, A
   Bora, PK
AF Gaj, Sibaji
   Rathore, Anoop Kumar
   Sur, Arijit
   Bora, Prabin Kumar
TI A robust watermarking scheme against frame blending and projection
   attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video watermarking; Cam-cording attack; Frame blending; Frame projection
AB Camcorder based video copy attack has become a serious threat to the electronic movie distribution services. Although watermarking is used to authenticate against such camcorder based copy attack, in the camcorder recorded videos, the embedded watermark suffers from several geometric distortions and temporal de-synchronizations. This paper proposes a watermarking scheme which is robust against the distortion due to cam-cordering process. Firstly, a comprehensive literature survey has been done on the watermarking schemes resilient to the cam-cording attack. Based on the existing limitations of the state-of-art literature, a watermarking scheme is devised to embed a watermark which is robust against to frame blending and projection attacks which are the major distortions caused during cam-cording. A comprehensive set of experiments has been carried out to show the applicability of the proposed scheme over the existing literature.
C1 [Gaj, Sibaji; Rathore, Anoop Kumar; Sur, Arijit] IIT Guwahati, Multimedia Lab, Dept Comp Sci & Engn, Gauhati 781039, India.
   [Bora, Prabin Kumar] IIT Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Guwahati
RP Gaj, S (corresponding author), IIT Guwahati, Multimedia Lab, Dept Comp Sci & Engn, Gauhati 781039, India.
EM sibaji@iitg.ernet.in; anoopkumar.jkinstitute@gmail.com;
   arijit@iitg.ernet.in; prabin@iitg.ernet.in
RI Sur, Arijit/AAB-4216-2020; Gaj, Sibaji/AAE-8920-2022
OI Gaj, Sibaji/0000-0002-6997-5717
CR Delannay D, 2001, COMPENSATION GEOMETR, DOI [10.1117/12.435395, DOI 10.1117/12.435395]
   Do H, 2008, IEEE INT SYMP SIGNAL, P330, DOI 10.1109/ISSPIT.2008.4775680
   Gaj S, 2016, MULTIMED TOOLS APPL, V75, P3053, DOI 10.1007/s11042-014-2422-3
   Lee MJ, 2009, IEEE IMAGE PROC, P101, DOI 10.1109/ICIP.2009.5414109
   Lee MJ, 2008, IEEE IMAGE PROC, P425, DOI 10.1109/ICIP.2008.4711782
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li L, 2015, J VIS COMMUN IMAGE R, V26, P1, DOI 10.1016/j.jvcir.2014.08.009
   Li X, 2015, INT J COMMUN SYST, V28, P374, DOI 10.1002/dac.2676
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Schaber Philipp, 2014, P 5 ACM MULT SYST C, P91, DOI DOI 10.1145/2557642.2557644
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Siast J, 2013, PICT COD SYMP, P53, DOI 10.1109/PCS.2013.6737681
   Stankowski J, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P265, DOI 10.1109/PCS.2012.6213343
   Thanh TM, 2014, AEU-INT J ELECTRON C, V68, P1007, DOI 10.1016/j.aeue.2014.05.004
   van Leest A, 2003, DIGITAL CINEMA WATER, DOI [10.1117/12.476856, DOI 10.1117/12.476856]
   Vinukonda P, 2011, THESIS
   Wang YL, 2009, PROCEEDINGS 2009 IEEE INTERNATIONAL WORKSHOP ON OPEN-SOURCE SOFTWARE FOR SCIENTIFIC COMPUTATION, P169, DOI 10.1109/OSSC.2009.5416913
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weng CC, 2005, IEEE INT SYMP CIRC S, P3801
   Yang HY, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700299
   Yuan XC, 2014, MULTIMED TOOLS APPL, V72, P777, DOI 10.1007/s11042-013-1405-0
   Yuan XC, 2013, IEEE INT CONF TRUST, P763, DOI 10.1109/TrustCom.2013.92
NR 23
TC 7
Z9 7
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20755
EP 20779
DI 10.1007/s11042-016-3961-6
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400017
DA 2024-07-18
ER

PT J
AU Huang, BT
   Liu, ZG
   Chen, JH
   Liu, AA
   Liu, Q
   He, QM
AF Huang, Butian
   Liu, Zhenguang
   Chen, Jianhai
   Liu, Anan
   Liu, Qi
   He, Qinming
TI Behavior pattern clustering in blockchain networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain technology; Behavior pattern clustering; Clustering;
   Sequences
AB Blockchain holds promise for being the revolutionary technology, which has the potential to find applications in numerous fields such as digital money, clearing, gambling and product tracing. However, blockchain faces its own problems and challenges. One key problem is to automatically cluster the behavior patterns of all the blockchain nodes into categories. In this paper, we introduce the problem of behavior pattern clustering in blockchain networks and propose a novel algorithm termed BPC for this problem. We evaluate a long list of potential sequence similarity measures, and select a distance that is suitable for the behavior pattern clustering problem. Extensive experiments show that our proposed algorithm is much more effective than the existing methods in terms of clustering accuracy.
C1 [Huang, Butian; Chen, Jianhai; He, Qinming] Zhejiang Univ, Dept Comp Sci, Hangzhou, Zhejiang, Peoples R China.
   [Liu, Zhenguang; Liu, Qi] Natl Univ Singapore, Sch Comp, Singapore, Singapore.
   [Liu, Anan] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
C3 Zhejiang University; National University of Singapore; Tianjin
   University
RP Liu, ZG (corresponding author), Natl Univ Singapore, Sch Comp, Singapore, Singapore.
EM butine@zju.edu.cn; zhenguangliu@zju.edu.cn; chenjh919@zju.edu.cn;
   anan0422@gmai.com; qiliumize@gmail.com; hqm@zju.edu.cn
RI Wang, Yiru/JMB-2281-2023; Liu, Qi/AAE-3162-2019
OI Liu, Qi/0000-0001-5378-6404
CR Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49
   [Anonymous], P 23 INT C VER LARG
   [Anonymous], 2016, IACR CRYPTOLOGY EPRI
   [Anonymous], 2015, P INT WORKSH OP PROB
   [Anonymous], DISCOVERING ELITE US
   [Anonymous], 2015, UNDERSTANDING MODERN
   [Anonymous], OPODIS
   [Anonymous], 2015, 1 MONDAY
   Chen L., 2005, P 2005 ACM SIGMOD IN, P491
   Christidis K, 2016, IEEE ACCESS, V4, P2292, DOI 10.1109/ACCESS.2016.2566339
   Croman K, 2016, LECT NOTES COMPUT SC, V9604, P106, DOI 10.1007/978-3-662-53357-4_8
   Dorri A., 2016, Blockchain in Internet of Things: Challenges and Solutions
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Forte P., 2015, IACR Cryptology ePrint Archive, V2015, P1164
   Gervais A., 2016, P 2016 ACMSIGSAC C C, P3
   Guha S, 2001, INFORM SYST, V26, P35, DOI 10.1016/S0306-4379(01)00008-4
   Hirano S, 2003, PROC SPIE, V5098, P219, DOI 10.1117/12.487508
   Karame GO, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1861, DOI 10.1145/2976749.2976756
   Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637
   Liao TW, 2005, PATTERN RECOGN, V38, P1857, DOI 10.1016/j.patcog.2005.01.025
   Liu LZ, 2012, ADV MATER RES-SWITZ, V418-420, P179, DOI 10.4028/www.scientific.net/AMR.418-420.179
   Morse M.D., 2007, P 2007 ACM SIGMOD IN, P569, DOI [DOI 10.1145/1247480.1247544, 10.1145/1247480.1247544]
   Underwood S, 2016, COMMUN ACM, V59, P15, DOI 10.1145/2994581
   Vlachos M, 2002, PROC INT CONF DATA, P673, DOI 10.1109/ICDE.2002.994784
   Wang F, 2014, IEEE CONF VIS ANAL, P103, DOI 10.1109/VAST.2014.7042486
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Zhang T., 1996, BIRCH EFFICIENT DATA, V25, P103, DOI [DOI 10.1145/233269.233324, 10.1145/235968.233324]
   Zhou XK, 2015, MULTIMED TOOLS APPL, V74, P5015, DOI 10.1007/s11042-014-2230-9
   Zyskind G, 2015, 2015 IEEE SECURITY AND PRIVACY WORKSHOPS (SPW), P180, DOI 10.1109/SPW.2015.27
NR 29
TC 48
Z9 61
U1 3
U2 122
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 20099
EP 20110
DI 10.1007/s11042-017-4396-4
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500045
DA 2024-07-18
ER

PT J
AU Wei, ZQ
   Yan, Y
   Huang, L
   Nie, J
AF Wei, Zhiqiang
   Yan, Yan
   Huang, Lei
   Nie, Jie
TI Inferring intrinsic correlation between clothing style and wearers'
   personality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personality; Clothing features; Portraits; Clothing features extraction
AB Clothing, as a language of signs, transmit more information of wearers' inner-self. Specially, portraits and Selfies take a high percent on social networking. Is there any relationship between wearers' personality and a range of relevant clothing features? In this work, we intend to explore the inherent relationship between wearers' personality type and expressive wearing. First, a sufficiently large dataset was built based on the theory of personality type. More than 300 celebrities who were classified according to the personality theory have been collected and the images of their wearing were downloaded from Google Image. To understand the intrinsic characteristics of different style of clothing, a suite of image analysis algorithms, including face detection, approximately body detection, clothing area detection using GrabCut algorithm and skin detection, clothing features extraction were developed in this research. Statistical analysis with Binary Logistic verified the significance level of extracted features correlated with personality types. Experimental results demonstrated that the proposed scheme can achieve higher precision accuracy through an SVM (Support Vector Machine) scheme than simple binary classification.
C1 [Wei, Zhiqiang; Yan, Yan; Huang, Lei; Nie, Jie] Ocean Univ China, Coll Informat Sci & Engn, Qingdao, Peoples R China.
C3 Ocean University of China
RP Yan, Y (corresponding author), Ocean Univ China, Coll Informat Sci & Engn, Qingdao, Peoples R China.
EM weizhiqiang@ouc.edu.cn; yanyan.azj@gmail.com; ithuanglei@gmail.com;
   niejie@tsinghua.edu.cn
FU National Natural Science Foundation of China [61672475, 61402428,
   61602430]; Qingdao Science and Technology Development Plan
   [16-5-1-13-jch]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61672475, No. 61402428, and No. 61602430); Qingdao Science
   and Technology Development Plan (No. 16-5-1-13-jch).
CR [Anonymous], 2012, P 20 ACM INT C MULT
   [Anonymous], 2013, ICMR
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Carl Gustav J, 2014, PSYCHOL TYPES
   Chen HZ, 2012, LECT NOTES COMPUT SC, V7574, P609, DOI 10.1007/978-3-642-33712-3_44
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Damhorst M.L., 1990, Clothing and Textiles Research, V8, P1, DOI [DOI 10.1177/0887302X9000800201, 10.1177/0887302X9000800201]
   FIORE AM, 1984, PERCEPT MOTOR SKILL, V59, P267, DOI 10.2466/pms.1984.59.1.267
   Flugel John Carl, 1933, The Sociological Review, V25, P1, DOI DOI 10.1111/J.1467-954X.1933.TB01889.X
   Forczmanski P, 2014, LECT NOTES COMPUT SC, V8671, P203, DOI 10.1007/978-3-319-11331-9_25
   Howlett N, 2013, J FASH MARK MANAG, V17, P38, DOI 10.1108/13612021311305128
   Huang L, 2015, J VIS COMMUN IMAGE R, V29, P147, DOI 10.1016/j.jvcir.2015.02.004
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Johnson K.K. P., 2002, Clothing and Textiles Research Journal, V20, P125, DOI DOI 10.1177/0887302X0202000301
   Kaplan Robert., 2012, Psychological testing: Principles, applications
   Lin K, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P499, DOI 10.1145/2671188.2749318
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   MacIntyre PD, 1996, J LANG SOC PSYCHOL, V15, P3, DOI 10.1177/0261927X960151001
   Malcolm B, 2002, FASHION COMMUNICATIO
   Myers I.B., 1962, The Myers-Briggs Type Indicator: Manual
   Roger P, 2010, IM NOT CRAZY IM JUST
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Wei Di, 2013, 2013 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P8, DOI 10.1109/CVPRW.2013.6
   Yamaguchi K, 2015, IEEE T PATTERN ANAL, V37, P1028, DOI 10.1109/TPAMI.2014.2353624
   Yan K, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P407, DOI 10.1145/2964284.2967252
   Yao W., 2017, RES FACIAL EXPRESSIO
NR 27
TC 5
Z9 6
U1 4
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 20273
EP 20285
DI 10.1007/s11042-017-4778-7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500054
DA 2024-07-18
ER

PT J
AU Zhang, YJ
   Qi, R
   Zeng, YN
AF Zhang, Yujie
   Qi, Rui
   Zeng, Yanni
TI Forward-backward pursuit method for distributed compressed sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed compressed sensing; Forward-backward pursuit; Sparsity;
   Sparse signal reconstruction
ID SIGNAL RECOVERY; ALGORITHM; ROBUST
AB In this paper, a forward-backward pursuit method for distributed compressed sensing (DCSFBP) is proposed. In contrast to existing distributed compressed sensing (DCS), it is an adaptive iterative approach where each iteration consists of consecutive forward selection and backward removal stages. And it not needs sparsity as prior knowledge and multiple indices are identified at each iteration for recovery. These make it a potential candidate for many practical applications, when the sparsity of signals is not available. Numerical experiments, including recovery of random sparse signals with different nonzero coefficient distributions in many scenarios, in addition to the recovery of sparse image and the real-life electrocardiography (ECG) data, are conducted to demonstrate the validity and high performance of the proposed algorithm, as compared to other existing DCS algorithms.
C1 [Zhang, Yujie; Qi, Rui; Zeng, Yanni] China Univ Geosci, Sch Math & Phys, Wuhan 430074, Peoples R China.
   [Zhang, Yujie] Univ Windsor, Sch Comp Sci, Windsor, ON N9B 3P4, Canada.
   [Qi, Rui] Naval Univ Engn, Sch Sci, Wuhan 430033, Hubei, Peoples R China.
   [Zeng, Yanni] Hubei Univ Econ, Fac Stat, Wuhan 430070, Hubei, Peoples R China.
C3 China University of Geosciences; University of Windsor; Wuhan Naval
   University of Engineering; Hubei University of Economics
RP Zhang, YJ (corresponding author), China Univ Geosci, Sch Math & Phys, Wuhan 430074, Peoples R China.; Zhang, YJ (corresponding author), Univ Windsor, Sch Comp Sci, Windsor, ON N9B 3P4, Canada.
EM zhangyujie@cug.edu.cn
RI zhang, yujie/JAA-9367-2023; yujie, zhang/AGX-7804-2022
FU Natural Science Foundation of China [61302138, 61601417]; Youth
   Foundation of Naval University of Engineering [HGDQNJJ13005]
FX This work is supported by Natural Science Foundation of China (No.
   61302138 and No. 61601417) and Youth Foundation of Naval University of
   Engineering (No. HGDQNJJ13005). The authors would like to thank the
   anonymous reviewers for their thorough reading of the paper, and patient
   feedback.
CR Adcock B, 2016, FOUND COMPUT MATH, V16, P1263, DOI 10.1007/s10208-015-9276-6
   [Anonymous], 2005, SIGNALS SYSTEMS COMP, DOI DOI 10.1109/ACSSC.2005.1600024
   [Anonymous], IEEE T INFORM THEORY
   [Anonymous], WORKSH NEUR INF PROC
   Bajwa WU, 2010, P IEEE, V98, P1058, DOI 10.1109/JPROC.2010.2042415
   Berger CR, 2010, IEEE T SIGNAL PROCES, V58, P1708, DOI 10.1109/TSP.2009.2038424
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Chen J, 2015, MULTIMED TOOLS APPL, V74, P2085, DOI 10.1007/s11042-013-1743-y
   Dai W, 2009, IEEE T INFORM THEORY, V55, P2230, DOI 10.1109/TIT.2009.2016006
   Do TT, 2008, CONF REC ASILOMAR C, P581, DOI 10.1109/ACSSC.2008.5074472
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1382, DOI 10.1109/TIP.2012.2231086
   Donoho D., 2006, SPARSE SOLUTION UNDE
   Duarte MF, 2013, APPL COMPUT HARMON A, V35, P111, DOI 10.1016/j.acha.2012.08.003
   Duarte MF, 2012, IEEE T IMAGE PROCESS, V21, P494, DOI 10.1109/TIP.2011.2165289
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Hou SJ, 2014, MULTIMED TOOLS APPL, V72, P3031, DOI 10.1007/s11042-013-1573-y
   Jacques L, 2013, IEEE T INFORM THEORY, V59, P2082, DOI 10.1109/TIT.2012.2234823
   Karahanoglu NB, 2013, DIGIT SIGNAL PROCESS, V23, P1539, DOI 10.1016/j.dsp.2013.05.007
   Kirmani A, 2012, INT CONF ACOUST SPEE, P5425, DOI 10.1109/ICASSP.2012.6289148
   Li KZ, 2013, IEEE T SIGNAL PROCES, V61, DOI 10.1109/TSP.2012.2229994
   Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002
   Needell D, 2010, IEEE J-STSP, V4, P310, DOI 10.1109/JSTSP.2010.2042412
   Sundman D., 2010, Proceedings 2010 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT 2010), P354, DOI 10.1109/ISSPIT.2010.5711810
   Sundman D, 2014, J SENS ACTUAT NETW, V3, P1, DOI 10.3390/jsan3010001
   Sundman D, 2011, EUR SIGNAL PR CONF, P368
   Tropp JA, 2005, INT CONF ACOUST SPEE, P721
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang Q, 2011, COMPUT ELECTR ENG, V37, P916, DOI 10.1016/j.compeleceng.2011.09.008
   Wu PKT, 2012, INT CONF ACOUST SPEE, P4053, DOI 10.1109/ICASSP.2012.6288808
   Yu Y, 2011, IEEE T SIGNAL PROCES, V59, P5338, DOI 10.1109/TSP.2011.2162328
   Zhang T, 2011, IEEE T INFORM THEORY, V57, P4689, DOI 10.1109/TIT.2011.2146690
   Zhao GH, 2012, SIGNAL PROCESS, V92, P120, DOI 10.1016/j.sigpro.2011.06.011
NR 33
TC 5
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20587
EP 20608
DI 10.1007/s11042-016-3968-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400010
DA 2024-07-18
ER

PT J
AU de Sousa, JA
   de Paiva, AC
   de Almeida, JDS
   Silva, AC
   Braz, G
   Gattass, M
AF de Sousa, Jefferson Alves
   de Paiva, Anselmo Cardoso
   Sousa de Almeida, Joao Dallyson
   Silva, Aristofanes Correa
   Braz Junior, Geraldo
   Gattass, Marcelo
TI Texture based on geostatistic for glaucoma diagnosis from fundus eye
   image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Glaucoma; Diagnosis; Retinal fundus image; Image processing
ID SYSTEM; DISC; CUP
AB Glaucoma is an ocular disorder that can permanently damage patient vision. Initially, it reduces the visual field, and may cause blindness. Effective methods for early detection is crucial for avoiding significant damages of the patient vision. The use of CAD (Computer-Aided Detection) and CADx (Computer-Aided Diagnosis) systems has contributed to increase the chances of detection and precise diagnoses, assisting experts' decision making on treatment regarding glaucoma. This paper proposes a method that analyzes the texture of the optical disk image region to diagnose glaucoma. Such analysis is done using the Local Binary Pattern (LBP) to represent the optic disk region, and geostatistical functions to describe texture patterns. The obtained texture features are used for classification based on Support Vector Machine. The proposed method presented as best results a sensitivity of 95%, accuracy of 91% and specificity of 88% in the diagnosis of glaucoma. The method has proved to be promising in assisting glaucoma diagnosis.
C1 [de Sousa, Jefferson Alves; de Paiva, Anselmo Cardoso; Sousa de Almeida, Joao Dallyson; Silva, Aristofanes Correa; Braz Junior, Geraldo] Univ Fed Maranhao, Ave Portugueses 1966, BR-65080805 Sao Luis, Maranhao, Brazil.
   [Gattass, Marcelo] Pontif Catholic Univ Rio de Janeiro, Rio De Janeiro, RJ, Brazil.
C3 Universidade Federal do Maranhao
RP de Sousa, JA (corresponding author), Univ Fed Maranhao, Ave Portugueses 1966, BR-65080805 Sao Luis, Maranhao, Brazil.
EM alves.jefferson27@gmail.com
RI Braz, Geraldo/AAW-1827-2021; Paiva, Anselmo/L-2358-2013
OI Braz, Geraldo/0000-0003-3731-6431; Paiva, Anselmo/0000-0003-4921-0626;
   Almeida, Joao Dallyson Sousa de Almeida/0000-0001-7013-9700
CR Acharya UR, 2016, COMPUT BIOL MED, V75, P54, DOI 10.1016/j.compbiomed.2016.04.015
   Acharya UR, 2015, BIOMED SIGNAL PROCES, V15, P18, DOI 10.1016/j.bspc.2014.09.004
   [Anonymous], 2015, TELEOPHTHALMOLOGY PR, DOI DOI 10.1007/978-3-662-44975-2_9
   Bland M., 2015, An introduction to medical statistics
   Chakrabarty L, 2015, J GLAUCOMA
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Claro M, 2015, COMP C CLEI, V2015, P1
   de Carvalho AO, 2014, ARTIF INTELL MED, V60, P165, DOI 10.1016/j.artmed.2013.11.002
   Devi TMG, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P423, DOI 10.1109/ECS.2015.7124939
   Dubey M, 2008, P IEEE JOINT INT C P, P1
   Maheshwari S, 2016, AUTOMATED DIAGNOSIS
   Mookiah MRK, 2012, KNOWL-BASED SYST, V33, P73, DOI 10.1016/j.knosys.2012.02.010
   Nayak J, 2009, J MED SYST, V33, P337, DOI 10.1007/s10916-008-9195-z
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Salam AA, 2015, IEEE INT SYMP SIGNAL, P370, DOI 10.1109/ISSPIT.2015.7394362
   Silva AC, 2004, PATTERN ANAL APPL, V7, P227, DOI 10.1007/s10044-004-0219-0
   de Almeida JDS, 2012, COMPUT BIOL MED, V42, P135, DOI 10.1016/j.compbiomed.2011.11.001
   Tham Yih-Chung, 2014, Ophthalmology, V121, P2081, DOI 10.1016/j.ophtha.2014.05.013
   Trucco E, 2013, INVEST OPHTH VIS SCI, V54, P3546, DOI 10.1167/iovs.12-10347
   Vapnik V., 1998, STAT LEARNING THEORY, V3
   Xu YL, 2015, J MED IMAG HEALTH IN, V5, P1833, DOI 10.1166/jmihi.2015.1654
NR 21
TC 28
Z9 28
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 19173
EP 19190
DI 10.1007/s11042-017-4608-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800047
DA 2024-07-18
ER

PT J
AU Li, X
   Lv, ZH
   Zheng, ZG
   Zhong, C
   Hijazi, IH
   Cheng, SD
AF Li, Xin
   Lv, Zhihan
   Zheng, Zhigao
   Zhong, Chen
   Hijazi, Ihab Hamzi
   Cheng, Shidan
TI Assessment of lively street network based on geographic information
   system and space syntax
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Street network; GIS; Space syntax; Spatial hierarchy; Hankou
ID URBAN LAND; MOVEMENT
AB Axial and visibility graph analysis models are combined with GIS and Space Syntax to study the corresponding relationship between street network and specific city life in Hankou, China, based on three scales - city, district, and community, so as to interpret the hidden structure out of complex urban form through the spatial logic of street network. In this paper, a quantitative analysis is made on selected parameters in Space Syntax, including Integration, Choice, density of road, and Ht index. The result indicates that there is certain correlation among these parameters. Moreover, these parameters also present certain changing patterns along with the increase of analysis radius. The results reveal that the street network of Hankou presents a multi-hierarchical structure and spatial wholeness from all these three scales. This characteristic creates vitality and diversity while maintaining the feature of wholeness for the urban space. Research has turned out that community-scale street network performs a positive role to keep neighborhoods alive. Therefore, it is an important strategy for maintaining the vitality of urban space and realizing coordination and unification between parts and the whole. It is proposed in this paper that a good street network is a key factor for carrying forward urban context of Hankou. Undoubtedly, it is worthy of reflecting on large-scale demolition of existing urban space, especially in historical areas. Afterwards, the paper proposes a hierarchically synergetic planning strategy based on the analysis. More attention should be paid to street network to preserve diversity, continuity, and integrity, and finally archive holistically sustainable development within a city.
C1 [Li, Xin; Cheng, Shidan] Wuhan Univ, Sch Urban Design, Wuhan, Hubei, Peoples R China.
   [Lv, Zhihan] Chinese Acad Sci, SIAT, Shenzhen, Peoples R China.
   [Zhong, Chen] UCL, Ctr Adv Spatial Anal, London, England.
   [Hijazi, Ihab Hamzi] An Najah Natl Univ, Urban Planning Engn Dept, Nablus, Palestine.
   [Zheng, Zhigao] Huazhong Univ Sci & Technol, Cluster & Grid Comp Lab, Wuhan, Hubei, Peoples R China.
C3 Wuhan University; Chinese Academy of Sciences; Shenzhen Institute of
   Advanced Technology, CAS; University of London; University College
   London; An Najah National University; Huazhong University of Science &
   Technology
RP Lv, ZH (corresponding author), Chinese Acad Sci, SIAT, Shenzhen, Peoples R China.
EM lvzhihan@gmail.com
RI Lv, Zhihan/GLR-6000-2022; zhong, chen/AAB-5097-2019; Lyu,
   Zhihan/I-3187-2014; hijazi, ihab/AAH-5439-2019
OI Lv, Zhihan/0000-0003-2525-3074; zhong, chen/0000-0003-3582-1266; Lyu,
   Zhihan/0000-0003-2525-3074; Hijazi, Ihab/0000-0001-7152-8935
FU National Natural Science Foundation of China [51408442]
FX The authors gratefully acknowledge financial support from the National
   Natural Science Foundation of China (No. 51408442). They sincerely
   appreciate anonymous reviewers for their constructive comments and
   suggestions.
CR Alexander C., 2002, The nature of order: The process of creating life
   Alexander C., 1977, PATTERN LANGUAGE TOW
   [Anonymous], ECAADE2009 C IST
   Bafna S, 2003, ENVIRON BEHAV, V35, P17, DOI 10.1177/0013916502238863
   Bartier PM, 1996, COMPUT GEOSCI, V22, P795, DOI 10.1016/0098-3004(96)00021-0
   Batty M, 2001, ENVIRON PLANN B, V28, P123, DOI 10.1068/b2725
   Batty M, 2005, ENV PLAN A, V37
   Bian CY, 2015, IEEE INT WORKS LOCAL
   Chang D, 2002, ENVIRON BEHAV, V34, P582, DOI 10.1177/0013916502034005002
   Conzen Michael Robert Gunter., 1960, Transactions and Papers, piii, DOI DOI 10.2307/621094
   Dennis P, 2004, URBAN PLAN OVERSEAS, V1
   Grant Jill., 2001, PlanningPerspectives, V16, P219, DOI [10.1080/02665430152469575, DOI 10.1080/02665430152469575]
   Gurer TK, 2012, GREEN AND ECOLOGICAL TECHNOLOGIES FOR URBAN PLANNING: CREATING SMART CITIES, P293, DOI 10.4018/978-1-61350-453-6.ch016
   Hillier B, 2005, LECT NOTES COMPUT SC, V3693, P475
   Hillier B., 1984, SOCIAL LOGIC SPACE, DOI DOI 10.1017/CBO9780511597237
   Hillier B., 1996, Space is the Machine
   Hölscher C, 2009, J ENVIRON PSYCHOL, V29, P208, DOI 10.1016/j.jenvp.2008.05.010
   Jacobs AB, 1993, ACCESS MAGAZINE, V1
   Jiang B, 2014, PROF GEOGR, V66, P676, DOI 10.1080/00330124.2013.852037
   Jiang B, 2013, PROF GEOGR, V65, P482, DOI 10.1080/00330124.2012.700499
   Jiang B, 2009, INT J GEOGR INF SCI, V23, P823, DOI 10.1080/13658810802022822
   Jiang DD, 2016, WIRELESS PERS COMMUN, V86, P901, DOI 10.1007/s11277-015-2961-6
   Jiang DD, 2015, J SYST SOFTWARE, V104, P152, DOI 10.1016/j.jss.2015.03.006
   Jiang DD, 2014, J NETW COMPUT APPL, V40, P292, DOI 10.1016/j.jnca.2013.09.014
   Jiang DD, 2011, COMPUT ELECTR ENG, V37, P1106, DOI 10.1016/j.compeleceng.2011.06.009
   Jiang DD, 2011, COMPUT NETW, V55, P3533, DOI 10.1016/j.comnet.2011.06.027
   Jiang DD, 2009, IEEE COMMUN LETT, V13, P52, DOI 10.1109/LCOMM.2008.081271
   Kim HK, 2002, CITIES, V19, P409, DOI 10.1016/S0264-2751(02)00071-9
   Lang J.T., 1994, URBAN DESIGN AM EXPE
   Li X, 2015, IEEE COMPUTATIONAL I
   Liang BF, 2014, CHIN J URBAN ENV STU, V2, DOI 10.1142/S2345748114500110
   Lin Y, 2015, SENSORS
   Liu MJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0084769
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8
   Lui S., 2017, Multimedia Tools and Applications, V76, P5787, DOI DOI 10.1007/S11042-014-2408-1
   Lv ZH, 2015, PERS UBIQUIT COMPUT, V19, P551, DOI 10.1007/s00779-015-0844-1
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Lv ZH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057990
   Penn A, 2003, ENVIRON BEHAV, V35, P30, DOI 10.1177/0013916502238864
   Polsky C, 2014, P NATL ACAD SCI USA, V111, P4432, DOI 10.1073/pnas.1323995111
   Proshansky HM., 1983, Journal of environmental psychology, DOI [10.1016/S0272-4944(83)80021-8, DOI 10.1016/S0272-4944(83)80021-8]
   Rowe William T., 1992, HANKOW CONFLICT COMM, V2
   Ruan Y, 2004, J TONGJI U SOC SCI S, V5
   Seto KC, 2012, P NATL ACAD SCI USA, V109, P7687, DOI 10.1073/pnas.1117622109
   Tengfei Yin, 2011, Journal of Networks, V6, P990, DOI 10.4304/jnw.6.7.990-998
   Trancik R., 1986, Finding Lost Space: Theories of Urban Design
   Turner A, 2004, DEPTHMAP 4 RESEARCHE
   Walker JA, 1997, CONCEPT VISUAL VISUA, P18
   Whitehand JWR, 2003, ENVIRON PLANN B, V30, P819, DOI 10.1068/b12997
   Wu J., 2000, GEOGRAPHIC INFORM SC, V6, P6, DOI 10.1080/10824000009480529
   Wu L, 2007, J ARCHIT CIV ENG, V1
   Yang JC, 2015, SENSORS-BASEL, V15, P19618, DOI 10.3390/s150819618
   Zhang S, 2014, IEEE IMAGE PROC, P2724, DOI 10.1109/ICIP.2014.7025551
   Zhang T, 2011, ARCHITECTS J, pS1
NR 54
TC 53
Z9 54
U1 12
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 17801
EP 17819
DI 10.1007/s11042-015-3095-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800012
DA 2024-07-18
ER

PT J
AU Wang, YF
   Zhu, KH
   Wu, J
   Zhu, Y
AF Wang, Yongfang
   Zhu, Kanghua
   Wu, Jian
   Zhu, Yun
TI Content aware video quality prediction model for HEVC encoded bitstream
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content type; HEVC; Video complexity; Quality prediction
AB In this paper, a novel content based video quality prediction model for High Efficiency Video Coding (HEVC) encoded video stream is proposed, which takes into account the quantization parameter (QP) and the newly proposed content type classification (CTC) metric. The CTC metric is derived by combining different types of information extracted from the encoded video sequences: temporal and spatial complexity, the standard deviation of the bitrate and the value of quantized transform coefficients. This metric can establish a logarithmic relationship with the quality of the video sequence, which is evidenced by extensive experimental results. The experimental results demonstrate that the proposed prediction model can achieve better correlation between the actual PSNR and the predicted PSNR in the training and testing process, and outperforms the other existing prediction methods in terms of accuracy. Furthermore, subjective testing results also show a good consistency between the proposed prediction metric and the subjective rankings.
C1 [Wang, Yongfang; Zhu, Kanghua; Wu, Jian; Zhu, Yun] Shanghai Univ, Key Lab Adv Display & Syst Applicat, Minist Educ, Shanghai, Peoples R China.
   [Wang, Yongfang] Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.
C3 Shanghai University; Shanghai University
RP Zhu, KH (corresponding author), Shanghai Univ, Key Lab Adv Display & Syst Applicat, Minist Educ, Shanghai, Peoples R China.
EM zhukanghuashu@163.com
RI li, Li/JPA-0218-2023; Li, Zilong/JEZ-8642-2023; Wang,
   Xuezhen/IUN-6267-2023
OI wu, jian/0000-0003-1445-2799
FU Natural Science Foundation of China [61671283, 61301113]; Shanghai
   National Natural Science [13ZR14165]
FX This work was supported by Natural Science Foundation of China under
   Grant No. 61671283, 61301113, and Shanghai National Natural Science
   under Grant No.13ZR14165.
CR Amirshahi SA, 2011, INT WORK QUAL MULTIM, P84, DOI 10.1109/QoMEX.2011.6065718
   Anegekuh L, 2015, IEEE T MULTIMEDIA, V17, P1323, DOI 10.1109/TMM.2015.2444098
   Anegekuh L, 2015, MULTIMED TOOLS APPL, V74, P3715, DOI 10.1007/s11042-013-1795-z
   [Anonymous], JCT VC DOC JCTVCG120
   [Anonymous], INT C AC SPEECH SIGN
   [Anonymous], 2013, VISUAL COMMUNICATION
   [Anonymous], 2 INT S WIR PERV COM
   [Anonymous], P 2003 INT C IM PROC
   Cranley N, 2005, MULTIMEDIA SYST, V10, P392, DOI 10.1007/s00530-005-0168-5
   Hu J, 2009, INT WORK QUAL MULTIM, P216, DOI 10.1109/QOMEX.2009.5246950
   Khan A, 2009, IEEE INT C COMMUNICA, P1
   Khan A, 2012, IEEE T MULTIMEDIA, V14, P431, DOI 10.1109/TMM.2011.2176324
   Konuk B, 2013, IEEE IMAGE PROC, P54, DOI 10.1109/ICIP.2013.6738012
   Kusuma TM, 2005, 2005 SYSTEMS COMMUNICATIONS, PROCEEDINGS, P178, DOI 10.1109/ICW.2005.60
   Liu M, 2010, IEEE IMAGE PROC, P1277, DOI 10.1109/ICIP.2010.5653340
   Mokhtari A, 2014, IEEE T SIGNAL PROCES, V62, P6089, DOI 10.1109/TSP.2014.2357775
   Nightingale J, 2012, IEEE T CONSUM ELECTR, V58, P404, DOI 10.1109/TCE.2012.6227440
   Pinson M, 2003, PROC SPIE, V5150, P573, DOI 10.1117/12.509908
   Ries M, 2007, IEEE WCNC, P2670
   Ries M, 2010, IEEE J SEL AREA COMM, V28, P501, DOI 10.1109/JSAC.2010.100420
   Rodríguez DZ, 2014, IEEE LAT AM T, V12, P740, DOI 10.1109/TLA.2014.6868878
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun L, 2012, APSIPA ASC, P1
   Van Wallendael G, 2012, INT WORK QUAL MULTIM, P7, DOI 10.1109/QoMEX.2012.6263845
   You AT, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P425, DOI 10.1109/CompComm.2015.7387609
NR 26
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 19191
EP 19209
DI 10.1007/s11042-017-4574-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800048
DA 2024-07-18
ER

PT J
AU You, JL
   Xue, HX
   Gao, LX
   Zhang, GQ
   Zhuo, Y
   Wang, JL
AF You, Jiali
   Xue, Hanxing
   Gao, Lixin
   Zhang, Guoqiang
   Zhuo, Yu
   Wang, Jinlin
TI Predicting the online performance of video service providers on the
   internet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video service provider; Performance analysis; Performance prediction;
   Time-series models
AB Video services on the Internet are not able to offer consistent and assured performance to users or third-party applications. Measuring levels of performance over time is difficult, and obtaining accurate measures in real time is problematic; thus, reactive measures to address loss of performance are also problematic. The ability to predict service performance can be viewed as an important added-value, one that can help users or third-part applications select the proper online service provider. With this aim in view, we have designed a measurement system and deployed it in eleven provinces and cities in China to monitor two popular websites, Youku and Tudou. The analysis indicates that the performance trend of these two service providers followed daily changing patterns, such as rush hour traffic and lower service workloads at midnight; this is consistent with user behaviors. It was also confirmed that the future performance was related to the historical records. Based on these findings, we have decided to investigate the use of modified time series models to forecast the performance of such video services. Meanwhile, some machine learning models are implemented and compared as baseline models, such as Artificial Neural Network, Support Vector Machine, and Decision Tree. In addition, a hybrid model, which is generated by combining different machine learning models, is also studied as the baseline. An investigation shows that time series models are much more suitable to this prediction problem than baseline models in most situations. To alleviate the data sparseness problem in training the predictor, a new predictor that combines different information sources is proposed, thus improving prediction precision. Furthermore, the predictor is quite stable, and we have discovered that the average performance estimation is more accurate if the model is updated within 2-3 days, which is useful in some applications, e.g., video source analysis and recommendation systems.
C1 [You, Jiali; Xue, Hanxing; Zhuo, Yu; Wang, Jinlin] Chinese Acad Sci, Inst Acoust, Natl Network New Media Engn Res Ctr, Beijing, Peoples R China.
   [Xue, Hanxing] Univ Chinese Acad Sci, Signal & Informat Proc, Beijing, Peoples R China.
   [Zhuo, Yu] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Gao, Lixin] Univ Massachusetts, Dept Elect & Comp Engn, Amherst, MA 01003 USA.
   [Zhang, Guoqiang] Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing, Jiangsu, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Acoustics, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; University of Massachusetts System; University of Massachusetts
   Amherst; Nanjing Normal University
RP You, JL (corresponding author), Chinese Acad Sci, Inst Acoust, Natl Network New Media Engn Res Ctr, Beijing, Peoples R China.
EM youjl@dsp.ac.cn
RI li, xiaomin/KCX-9845-2024
FU Research of smart TV platform and service support environment
   [XDA06040501]; Youth Innovation Promotion Association of the Chinese
   Academy of Sciences [Y529111601]
FX This work is supported by "Research of smart TV platform and service
   support environment" (XDA06040501) and "Youth Innovation Promotion
   Association of the Chinese Academy of Sciences" (Y529111601).
CR Adhikari R, 2012, 1 INT C REC ADV INF
   Adhikari VK, 2015, IEEE ACM T NETWORK, V23, P1984, DOI 10.1109/TNET.2014.2354262
   Adhikari VK, 2012, IEEE INFOCOM SER, P1620, DOI 10.1109/INFCOM.2012.6195531
   Anand NC, 2008, IEEE IFIP NETW OPER, P694, DOI 10.1109/NOMS.2008.4575191
   [Anonymous], HULU PALABRA CLAVE
   [Anonymous], 2015, A Review of Network Traffic Analysis and Prediction Techniques
   [Anonymous], 2013, Twenty Seventh AAAI Conf. Artif. Intell
   Attenberg J, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1067
   Balachandran A, 2013, ACM SIGCOMM COMP COM, V43, P339, DOI 10.1145/2534169.2486025
   Chabaa Samira, 2010, Journal of Intelligent Learning Systems and Applications, V2, P147, DOI 10.4236/jilsa.2010.23018
   CHEUNG YW, 1995, OXFORD B ECON STAT, V57, P411
   Cortez P, 2006, IEEE IJCNN, P2635
   Hoong P.K, 2012, INT J COMPUT NETW CO, V4, P143, DOI DOI 10.5121/IJCNC.2012.4409
   Iqbal M. F., 2012, 2012 IEEE International Symposium on Performance Analysis of Systems & Software (ISPASS), P112, DOI 10.1109/ISPASS.2012.6189212
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Ng Kar Hoong, 2011, Proceedings of the 2011 13th International Conference on Advanced Communication Technology (ICACT). Smart Service Innovation through Mobile Interactivity, P1199
   Radinsky K., 2012, P 21 INT C WORLD WID, P599, DOI DOI 10.1145/2187836.2187918
   Shu Y, 2003, ICC
   Sivakumar R, 2011, PACC 2011
   Vujicic B, 2006, IEEE INT SYMP CIRC S, P2637
   Wang YA, 2011, IEEE INFOCOM SER, P2372, DOI 10.1109/INFCOM.2011.5935057
   Xu Qiang., 2013, ACM MOBISYS
   Yanhua Yu, 2010, Proceedings 2010 International Conference on Intelligent System Design and Engineering Application (ISDEA 2010), P980, DOI 10.1109/ISDEA.2010.335
   Zeng DH, 2008, 2008 WORKSHOP ON POWER ELECTRONICS AND INTELLIGENT TRANSPORTATION SYSTEM, PROCEEDINGS, P621, DOI 10.1109/PEITS.2008.135
   Zhao H, 2009, IEEE IPCCC, P388, DOI 10.1109/PCCC.2009.5403856
   Zhou B, 2006, 2006 2ND CONFERENCE ON NEXT GENERATION INTERNET DESIGN AND ENGINEERING, P200
NR 26
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 19017
EP 19038
DI 10.1007/s11042-017-4460-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800041
DA 2024-07-18
ER

PT J
AU Zheng, S
   Zhu, GB
   Zhang, J
   Feng, W
AF Zheng, Si
   Zhu, GuoBin
   Zhang, Jie
   Feng, Wei
TI Towards an adaptive human-centric computing resource management
   framework based on resource prediction and multi-objective genetic
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Load balancing; Load prediction; Resource
   configuration; Multi-objective optimization
AB The complexity, scale and dynamic of data source in the human-centric computing bring great challenges to maintainers. It is problem to be solved that how to reduce manual intervention in large scale human-centric computing, such as cloud computing resource management so that system can automatically manage according to configuration strategies. To address the problem, a resource management framework based on resource prediction and multi-objective optimization genetic algorithm resource allocation (RPMGA-RMF) was proposed. It searches for optimal load cluster as training sample based on load similarity. The neural network (NN) algorithm was used to predict resource load. Meanwhile, the model also built virtual machine migration request in accordance with obtained predicted load value. The multi-objective genetic algorithm (GA) based on hybrid group encoding algorithm was introduced for virtual machine (VM) resource management, so as to provide optimal VM migration strategy, thus achieving adaptive optimization configuration management of resource. Experimental resource based on CloudSim platform shows that the RPMGA-RMF can decrease VM migration times while reduce physical node simultaneously. The system energy consumption can be reduced and load balancing can be achieved either.
C1 [Zheng, Si; Zhu, GuoBin] Wuhan Univ, Int Sch Software, Wuhan, Hubei, Peoples R China.
   [Zhang, Jie] Jianghan Univ, Wuhan, Hubei, Peoples R China.
   [Feng, Wei] Huazhong Normal Univ, Wuhan Media & Commun Coll, Wuhan, Hubei, Peoples R China.
C3 Wuhan University; Jianghan University; Central China Normal University
RP Zheng, S (corresponding author), Wuhan Univ, Int Sch Software, Wuhan, Hubei, Peoples R China.
EM zhengsimtap@163.com
RI PENG, CHENG/KCL-2506-2024
OI Zhu, Guobin/0000-0002-6280-1204
CR Buyya Rajkumar, 2009, 2009 International Conference on High Performance Computing & Simulation (HPCS), P1, DOI 10.1109/HPCSIM.2009.5192685
   Caron E., 2010, Proceedings of the 2010 IEEE 2nd International Conference on Cloud Computing Technology and Science (CloudCom 2010), P456, DOI 10.1109/CloudCom.2010.65
   Chen WL, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/829589
   Dörnemann T, 2009, CCGRID: 2009 9TH IEEE INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID, P140, DOI 10.1109/CCGRID.2009.30
   Dongwan Shin, 2010, Proceedings 2010 6th International Conference on Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom 2010)
   Doulamis N, 2007, COMPUT COMMUN, V30, P499, DOI 10.1016/j.comcom.2005.11.013
   Falkenauer E., 1996, Journal of Heuristics, V2, P5, DOI 10.1007/BF00226291
   Iosup A, 2011, IEEE T PARALL DISTR, V22, P931, DOI 10.1109/TPDS.2011.66
   [赖红松 Lai Hongsong], 2003, [系统工程, Systems Engineering], V21, P24
   Li Qiang, 2011, Chinese Journal of Computers, V34, P2253, DOI 10.3724/SP.J.1016.2011.02253
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8
   Liu S, 2014, APPL MATH COMPUT, V243, P767, DOI 10.1016/j.amc.2014.06.016
   Liu YL, 2007, ELECT POWER, V40, P82
   Lui S., 2017, Multimedia Tools and Applications, V76, P5787, DOI DOI 10.1007/S11042-014-2408-1
   Lv ZH, 2015, PERS UBIQUIT COMPUT, V19, P551, DOI 10.1007/s00779-015-0844-1
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Ma LY, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0070716
   Mengkun Li, 2010, 2010 Second International Conference on Communication Systems, Networks and Applications (ICCSNA 2010), P208, DOI 10.1109/ICCSNA.2010.5588886
   Qi WX, 2008, COMPUT DIGIT ENG, V36, P16
   Quiroz Andres, 2009, Proceedings of the 2009 10th IEEE/ACM International Conference on Grid Computing (GRID), P50, DOI 10.1109/GRID.2009.5353066
   Shin Dongwan., 2010, Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom), 2010 6th International Conference on, P1
   Woitaszek Matthew, 2010, Proceedings of the 2010 IEEE 10th International Conference on Computer and Information Technology (CIT 2010), P210, DOI 10.1109/CIT.2010.72
   You XD, 2009, FOURTH CHINAGRID ANNUAL CONFERENCE, PROCEEDINGS, P256, DOI 10.1109/ChinaGrid.2009.41
   Zheng Pai, 2010, Chinese Journal of Computers, V33, P1472, DOI 10.3724/SP.J.1016.2010.01472
   Zheng Z., 2015, Applied Mathematics Information Sciences, P3169, DOI DOI 10.12785/AMIS/090646
   Zhou WY, 2011, J HUAZHONG U SCI S1, V29, P130
   Zhu Q, 2010, P IEEE INT C CLOUD C, P327
NR 27
TC 3
Z9 4
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 17821
EP 17838
DI 10.1007/s11042-015-3096-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800013
DA 2024-07-18
ER

PT J
AU Ge, JX
   Liu, JM
AF Ge, Jianxin
   Liu, Jiaomin
TI Research on high precision matching optimization method and software
   testing analysis of regions with fuzzy details of multimedia images in
   cloud environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia image; Region with fuzzy details; Matching; Software testing;
   Cloud environment
AB Aiming for the low matching precision caused by the inaccurate segmentation of the region with fuzzy details when traditional methods are used for the matching of regions with fuzzy details in the multimedia images, a new high precision matching optimization method for regions with fuzzy details of multimedia images in cloud environment is proposed, LPP feature of the region with fuzzy details is extracted to calculate the similarity of features; using binary tree segmentation algorithm to segment the multimedia image region, through the combination of UFM improved algorithm and fuzzy binary tree structure to achieve the matching of fuzzy region based on fuzzy similarity, the optimized matching method is programmed, afterwards, the software is tested. The experimental results show that the proposed method has high matching accuracy.
C1 [Ge, Jianxin; Liu, Jiaomin] Yanshan Univ, Comp Sci & Technol, Qinhuangdao 066004, Hebei, Peoples R China.
C3 Yanshan University
RP Ge, JX (corresponding author), Yanshan Univ, Comp Sci & Technol, Qinhuangdao 066004, Hebei, Peoples R China.
EM coolsmile876@126.com
CR Ahmadi S, 2015, INT J HYDROGEN ENERG, V40, P12512, DOI 10.1016/j.ijhydene.2015.06.160
   Chen WL, 2015, CHEM ENG J, V260, P492, DOI 10.1016/j.cej.2014.08.087
   de Souza ID, 2015, TALANTA, V140, P166, DOI 10.1016/j.talanta.2015.03.032
   Garcia S, 2015, J BRAZIL CHEM SOC, V26, P3710
   Garcia-Aristizabal A., 2015, 12 INT C EXP EM TECH, P1
   Henderson N, 2015, CHEM ENG SCI, V127, P151, DOI 10.1016/j.ces.2015.01.029
   Lee S, 2015, B KOREAN CHEM SOC, V36, P485, DOI 10.1002/bkcs.10081
   Lin J, 2015, KNOWL-BASED SYST, V78, P59, DOI 10.1016/j.knosys.2015.01.017
   Mahapatra GS, 2015, ANN OPER RES, P1
   McVittie A, 2015, ECOL ECON, V110, P15, DOI 10.1016/j.ecolecon.2014.12.004
   Merrikh-Bayat F, 2014, IEEE T FUZZY SYST, V22, P1272, DOI 10.1109/TFUZZ.2013.2290140
   Nadeem AH, 2015, BLOOD, V29, P346
   Ooe H, 2016, REV SCI INSTRUM, V87, DOI 10.1063/1.4941065
   Paopang P, 2015, PREP BIOCH BIOTECHNO
   Poursalehi N, 2015, ANN NUCL ENERGY, V81, P263, DOI 10.1016/j.anucene.2015.02.047
   Ray P, 2016, ANN OPER RES, V237, P237, DOI 10.1007/s10479-014-1649-8
   Shaun P., 2015, OPT EXPRESS, V23, P71
   Son C, 2014, INFORM SCIENCES, V256, P211, DOI 10.1016/j.ins.2013.08.008
   Vinks AA, 2016, CLIN PHARMACOL THER, V99, P340, DOI 10.1002/cpt.339
   Vipparthi SK, 2015, INT J SIGNAL IMAGING, V8, P137, DOI 10.1504/IJSISE.2015.070485
   Wang GQ, 2016, SPECTROSC LETT, V49, P85, DOI 10.1080/00387010.2015.1084639
   Wang XF, 2015, PATTERN RECOGN, V48, P189, DOI 10.1016/j.patcog.2014.07.008
   Yin J, 2016, POLYM COMPOSITE, V37, P37
   Zoghi M, 2015, RENEW SUSTAIN ENERGY
   Zou M, 2015, BIOINFORMATICS, V31, P3330, DOI 10.1093/bioinformatics/btv374
NR 25
TC 0
Z9 0
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17019
EP 17035
DI 10.1007/s11042-016-3668-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500008
DA 2024-07-18
ER

PT J
AU Sayahi, I
   Elkefi, A
   Ben Amar, C
AF Sayahi, Ikbel
   Elkefi, Akram
   Ben Amar, Chokri
TI Blind watermarking algorithm based on spiral scanning method and
   error-correcting codes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Triangular and multiresolution mesh; 3D watermarking; Error-correcting
   code; Wavelet transform; Spiral scanning
AB This work is a connecting link between the field of digital transmission and (3 Dimension) 3D watermarking. In fact, we propose in this paper a blind and robust watermarking algorithm for 3D multiresolution meshes. This data type, before being watermarked, is divided into GOTs (Group Of Triangles) using a spiral scanning method. At every instant, only one GOT is loaded into memory. It undergoes a wavelet transform. Embedding modifies the wavelet coefficients vector thus generated after being presented in a cylindrical coordinate system. After being watermarked, the current GOT will be released from memory to upload the next GOT. Information is coded using a turbo encoder to generate the codeword to be inserted. Once the entire mesh is scanned, the watermarked mesh is reconstructed. During extraction, the same steps are applied only on the watermarked mesh: our algorithm is then blind. Extracted data are decoded using Error-Correcting Code (turbocode) to correct errors that occurred. The results show that our algorithm preserves mesh quality even with a very large insertion rate while significantly minimizing used memory. Data extraction was done correctly despite the application of various attacks. Our algorithm is robust against most popular attacks such as similarity transformation, noise addition, smoothing, coordinate quantization, simplification and compression.
C1 [Sayahi, Ikbel; Elkefi, Akram; Ben Amar, Chokri] Univ Sfax, Natl Sch Engineers, REGIM REs Grp Intelligent Machines, BP 1173, Sfax 3038, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Sayahi, I (corresponding author), Univ Sfax, Natl Sch Engineers, REGIM REs Grp Intelligent Machines, BP 1173, Sfax 3038, Tunisia.
EM phd.ikbel.sayahi@ieee.org; elkefi@gmail.com; chokri.benamar@ieee.org
RI Chokri, BEN AMAR/K-5237-2012
CR Basyoni Lamiaa, 2015, 7th International Conference on Information Technology, P612, DOI 10.15849/icit.2015.0107
   Che XJ, 2012, INT J PARALLEL EMERG, V27, P133, DOI 10.1080/17445760.2011.574631
   Chrysafis C, 2000, IEEE T IMAGE PROCESS, V9, P378, DOI 10.1109/83.826776
   Elkefi A, 2011, THESIS
   Garg H, 2014, INT CONF COMM SYST, P788, DOI 10.1109/CSNT.2014.165
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Hu R, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/305960
   Isenburg M, 2003, ACM T GRAPHIC, V22, P935, DOI 10.1145/882262.882366
   Kai Wang, 2010, Proceedings of the Shape Modeling International (SMI 2010), P231, DOI 10.1109/SMI.2010.33
   Kang H, 2014, IWIHC'14: PROCEEDINGS OF THE FIRST ACM INTERNATIONAL WORKSHOP ON INFORMATION HIDING AND ITS CRITERIA FOR EVALUATION, P9, DOI 10.1145/2598908.2598912
   Lin CH, 2013, INT J INNOV COMPUT I, V9, P1321
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Parisot C, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P403, DOI 10.1109/MMSP.2001.962767
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Roudet C, 2011, REV LECTRONIQUE FRAN, V5, P27
   Sayahi Ikbel, 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P150
   Su ZY, 2013, COMPUT AIDED DESIGN, V45, P1042, DOI 10.1016/j.cad.2013.04.001
   Tamane Sharvari C., 2012, International Journal of Computer Science & Information Technology, V4, P117, DOI 10.5121/ijcsit.2012.4110
   Tamane S.C., 2012, ADV COMPUTING, V2, P29
   VITERBI AJ, 1971, IEEE T COMMUN TECHN, VCO19, P751, DOI 10.1109/TCOM.1971.1090700
   Wang JT, 2014, 2014 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C 2014), P1095, DOI 10.1109/IS3C.2014.285
   Wang JR, 2012, VISUAL COMPUT, V28, P1049, DOI 10.1007/s00371-011-0650-3
   Wang K, 2007, COMPRESSION REPRSENT, P139
   Wang X, 2014, APPL MECH MATER, V443, P566, DOI 10.4028/www.scientific.net/AMM.443.566
   Xiao Zhou, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1509, DOI 10.1109/CECNet.2012.6201895
   XiaoYing Y., 2016, IEEE T VIS COMPUT GR, V23, P1
   Yuan YT, 2016, 3D RES, V7
   Zaid AO, 2015, MULTIMED TOOLS APPL, V74, P5897, DOI 10.1007/s11042-014-1896-3
NR 32
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16439
EP 16462
DI 10.1007/s11042-016-3920-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100017
DA 2024-07-18
ER

PT J
AU Tang, CP
   Yang, NA
AF Tang, Chengpei
   Yang, Nian
TI Virtual grid margin optimization and energy balancing scheme for mobile
   sinks in wireless sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile sinks; Energy hole; Wireless sensor networks; Virtual grid margin
   optimization; Energy consumption
ID EFFICIENT DATA-COLLECTION; LIFETIME
AB The energy consumption of each node in the sensor network can be effectively balanced by using mobile sinks for data gathering, thus avoiding resulting in energy hole problem. This paper proposes a virtual grid margin optimization and energy balancing (VGMEB) protocol for mobile sinks to balance zthe energy consumption in wireless sensor networks. VGMEB achieves high energy efficiency by designing a virtual grid margin method and determining a novel evaluation model for cluster head selection. In addition, an approach in multiple attribute decision making based on relative entropy is integrated for determining the weight value of each metric. The experimental results show that VGMEB outperforms these protocols and it can efficiently mitigate the energy hole problem and prolong the network lifetime.
C1 [Tang, Chengpei; Yang, Nian] Sun Yat Sen Univ, Sch Engn, Guangzhou 510275, Guangdong, Peoples R China.
C3 Sun Yat Sen University
RP Tang, CP (corresponding author), Sun Yat Sen Univ, Sch Engn, Guangzhou 510275, Guangdong, Peoples R China.
EM chengpei_t@163.com
FU Science and Technology Project of Guangdong Province [2013B010401012];
   Commissioned Development Project of China State Construction Engineering
   Corporation Limited [71010306, 71020355]; Science and Technology Project
   of Shenzhen [JCYJ20140424173418463]
FX This work was supported by Science and Technology Project of Guangdong
   Province under Grant No. 2013B010401012, Commissioned Development
   Project of China State Construction Engineering Corporation Limited
   under Grant No. 71010306 & 71020355, Science and Technology Project of
   Shenzhen under Grant No. JCYJ20140424173418463. The authors gratefully
   acknowledge the helpful comments and suggestions of the reviewers, which
   have improved the presentation.
CR [Anonymous], 2007, P 2007 INT C MOBILE
   Basagni S, 2008, WIREL NETW, V14, P831, DOI 10.1007/s11276-007-0017-x
   Bhadauria D, 2011, J FIELD ROBOT, V28, P388, DOI 10.1002/rob.20384
   Chen HY, 2010, IEEE T WIREL COMMUN, V9, P956, DOI 10.1109/TWC.2010.03.090706
   Ding Y, 2010, J PARALLEL DISTR COM, V70, P644, DOI 10.1016/j.jpdc.2010.03.002
   Gandham SR, 2003, GLOB TELECOMM CONF, P377
   Gao Shuai, 2011, Acta Electronica Sinica, V39, P742
   Gao SA, 2011, IEEE T MOBILE COMPUT, V10, P592, DOI 10.1109/TMC.2010.193
   He L, 2013, IEEE T MOBILE COMPUT, V12, P1308, DOI 10.1109/TMC.2012.105
   Heinzelman WB, 2002, IEEE T WIREL COMMUN, V1, P660, DOI 10.1109/TWC.2002.804190
   Jain S, 2006, MOBILE NETW APPL, V11, P327, DOI 10.1007/s11036-006-5186-9
   Li J, 2007, PERVASIVE MOB COMPUT, V3, P233, DOI 10.1016/j.pmcj.2006.11.001
   Luo J, 2005, IEEE INFOCOM SER, P1735
   Luo J, 2006, P INT C DISTR COMP
   Marta M, 2009, PERVASIVE MOB COMPUT, V5, P542, DOI 10.1016/j.pmcj.2009.01.001
   Martinic M, 2008, ICAP SER ALCOHOL SOC, P1
   Meng Zhonglou, 2009, Journal of Huazhong University of Science and Technology, V37, P67
   Olariu S, 2006, IEEE INFOCOM SER, P2505
   Shi Gao-Tao, 2007, Journal of Software, V18, P2235, DOI 10.1360/jos182235
   Somasundara AA, 2006, IEEE T MOBILE COMPUT, V5, P958, DOI 10.1109/TMC.2006.109
   Wang GJ, 2009, J SUPERCOMPUT, V47, P127, DOI 10.1007/s11227-008-0181-5
   Wang W., 2005, P 11 ANN INT C MOB C, P270, DOI DOI 10.1145/1080829.1080858
   Xing GL, 2008, MOBIHOC'08: PROCEEDINGS OF THE NINTH ACM INTERNATIONAL SYMPOSIUM ON MOBILE AD HOC NETWORKING AND COMPUTING, P231
   Yu Zhen-hua, 2009, Control and Decision, V24, P1436
   Zeng Zhi-Wen, 2010, Chinese Journal of Computers, V33, P12, DOI 10.3724/SP.J.1016.2010.00012
   Zheng Wei, 2010, Control and Decision, V25, P1035
   Zhong Zhi, 2010, Acta Automatica Sinica, V36, P1557, DOI 10.3724/SP.J.1004.2010.01557
NR 27
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 16929
EP 16948
DI 10.1007/s11042-016-3596-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500004
DA 2024-07-18
ER

PT J
AU Wu, QD
   Li, YB
   Lin, Y
AF Wu, Qidi
   Li, Yibing
   Lin, Yun
TI The application of nonlocal total variation in image denoising for
   mobile transmission
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Mobile communication; Total variation; Regularization;
   Nolocal model
ID RESTORATION; ALGORITHM; MINIMIZATION; EQUATIONS
AB Image transmission is one of the key techniques in image mobile communication. However, it is generally corrupted by noise in wireless channel, which will decrease the visual quality and affect the sub-sequential applications, such as pattern recognition, classification and so on. Total variation is widely used in the problems of image denoising, due to its advantage in preserving texture in image. In this paper, a novel minimization framework is presented where the objective function includes an usual l (2) data-fidelity term and two types of total variation regularizer. According to the theory analysis, the novel objective function can preserve the local geometric structure in restored image. Furthermore, we proposes to solve the novel framework with majorization- minimization and compares this novel algorithm with some current restoration method. The numerical experiments show the efficiency and effectiveness of the proposed algorithm.
C1 [Wu, Qidi; Li, Yibing; Lin, Yun] Harbin Engn Univ, Coll Informat & Commun Engn, Harbin, Peoples R China.
C3 Harbin Engineering University
RP Lin, Y (corresponding author), Harbin Engn Univ, Coll Informat & Commun Engn, Harbin, Peoples R China.
EM linyun@hrbeu.edu.cn
RI Yun, Lin/C-4759-2019
OI Yun, Lin/0000-0003-1379-9301
FU Key Development Program of Basic Research of China [JCKY2013604B001];
   Nation Nature Science Foundation of China [61301095]; Nature Science
   Foundation of Heilongjiang Province of China [F201408]; Fundamental
   Research Funds for the Central Universities [HEUCF100814, HEUCF100816]
FX This work was supported by the Key Development Program of Basic Research
   of China(JCKY2013604B001), the Nation Nature Science Foundation of China
   (61301095), Nature Science Foundation of Heilongjiang Province of China
   (F201408) and the Fundamental Research Funds for the Central
   Universities (No. HEUCF100814 and HEUCF100816).
CR [Anonymous], 2006, IEEE INT C AC SPEECH
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chan T, 2000, SIAM J SCI COMPUT, V22, P503, DOI 10.1137/S1064827598344169
   Chan TF, 2004, 0510 CAM UCLA DEP MA
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Dai SY, 2009, IEEE T IMAGE PROCESS, V18, P969, DOI 10.1109/TIP.2009.2012908
   Dobson DC, 1996, SIAM J APPL MATH, V56, P1181, DOI 10.1137/S003613999427560X
   Figueiredo MAT, 2006, IEEE IMAGE PROC, P2633
   Foi A, 2007, IEEE T IMAGE PROCESS, V16, P1395, DOI 10.1109/TIP.2007.891788
   Guo XX, 2009, SIAM J SCI COMPUT, V31, P2322, DOI 10.1137/080724435
   Hunter DR, 2004, AM STAT, V58, P30, DOI 10.1198/0003130042836
   Lefkimmiatis S, 2012, IEEE T IMAGE PROCESS, V21, P983, DOI 10.1109/TIP.2011.2168232
   Li A, 2013, OPT REV, V20, P491, DOI 10.1007/s10043-013-0083-5
   Marquina A, 2000, SIAM J SCI COMPUT, V22, P387, DOI 10.1137/S1064827599351751
   PHILLIPS DL, 1962, J ACM, V9, P84, DOI 10.1145/321105.321114
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   RUDIN LI, 1994, IEEE IMAGE PROC, P31
   Strong DM, 1997, C STAT STOCH METH 2, P222
   Tikhonov A.N., 1963, SOV MATH DOKL, V5, P1035, DOI DOI 10.1111/J.1365-246X.2012.05699.X
   Vese L, 2001, APPL MATH OPT, V44, P131, DOI 10.1007/s00245-001-0017-7
   Yang JF, 2009, SIAM J IMAGING SCI, V2, P569, DOI 10.1137/080730421
   Zhang XQ, 2010, SIAM J IMAGING SCI, V3, P253, DOI 10.1137/090746379
NR 25
TC 32
Z9 32
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17179
EP 17191
DI 10.1007/s11042-016-3760-0
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500017
DA 2024-07-18
ER

PT J
AU Vural, C
   Yildirim, I
AF Vural, Cabir
   Yildirim, Ibrahim
TI Reversible video watermarking through recursive histogram modification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible watermarking; Recursive histogram modification; Reversible
   video watermarking
ID DIGITAL WATERMARKING; ERROR EXPANSION; IMAGE
AB In this study, a new reversible video watermarking method is developed. Unlike the existing reversible video watermarking algorithms that are based on motion compensated prediction or interpolation error expansion, motion compensated interpolation errors in the proposed method are watermarked in a totally different manner with the aid of recursive histogram modification algorithm developed recently for the purpose of reversible image watermarking. However, the recursive histogram modification can not be used directly for reversible video watermarking since the important problems of ensuring reversibility for each frame and distribution of total capacity among frames are encountered. In this study, novel ideas are proposed to solve the aforementioned two problems. The proposed method is tested on the video sequences commonly used in the literature. It is shown to give better performance than the existing reversible video watermarking algorithms in terms of capacity and distortion by means of computer simulations. Also, a numerical example is provided.
C1 [Vural, Cabir] Marmara Univ, Fac Engn, Elect & Elect Engn, TR-34722 Istanbul, Turkey.
   [Yildirim, Ibrahim] Sakarya Univ, Fac Engn, Elect & Elect Engn, TR-54100 Serdivan, Sakarya, Turkey.
C3 Marmara University; Sakarya University
RP Vural, C (corresponding author), Marmara Univ, Fac Engn, Elect & Elect Engn, TR-34722 Istanbul, Turkey.
EM cabir.vural@marmara.edu.tr; ibrahimxyildirim@gmail.com.tr
RI YILDIRIM, İbrahim/L-6086-2018; yıldırım, ibrahim/IAQ-5372-2023; Vural,
   Cabir/V-3831-2019
OI YILDIRIM, İbrahim/0000-0002-1838-3850; 
CR Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chung K.L., 2009, P 2009 APSIPA ANN SU, P573
   Feng JB, 2006, INT J NETWORK SECURI, P2
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Hu XC, 2013, IEEE T INF FOREN SEC, V8, P779, DOI 10.1109/TIFS.2013.2256131
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Lin SJ, 2012, IEEE T INF FOREN SEC, V7, P1155, DOI 10.1109/TIFS.2012.2197614
   Moulin P, 2005, P IEEE, V93, P2083, DOI 10.1109/JPROC.2005.859599
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Podilchuk CI, 2001, IEEE SIGNAL PROC MAG, V18, P33, DOI 10.1109/79.939835
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Vural C, 2015, SIGNAL IMAGE VIDEO P, V9, P1613, DOI 10.1007/s11760-014-0618-7
   Willems F, 2004, 42 ANN ALL C COMM CO, P1
   Wolfgang RB, 1999, P IEEE, V87, P1108, DOI 10.1109/5.771067
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P685, DOI 10.1109/TIP.2003.810588
   Zeng XA, 2011, J INF SCI ENG, V27, P465
   Zhai JF, 2005, IEEE INT SYMP CIRC S, P4927
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
   Zhang XP, 2013, IEEE T MULTIMEDIA, V15, P316, DOI 10.1109/TMM.2012.2229262
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 25
TC 0
Z9 0
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15513
EP 15534
DI 10.1007/s11042-016-3854-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900014
DA 2024-07-18
ER

PT J
AU Zhao, HJ
   Lou, C
   Li, N
AF Zhao, Huijie
   Lou, Chen
   Li, Na
TI A real-time CFAR thresholding method for target detection in
   hyperspectral images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Target detection; CFAR detection; Gaussian mixture model
ID ADAPTIVE COHERENCE ESTIMATOR; LIKELIHOOD; MODELS
AB In order to support immediate decision-making in critical circumstances such as military reconnaissance and disaster rescue, real-time onboard implementation of target detection is greatly desired. In this paper, a real-time thresholding method (RT-THRES) is proposed to obtain the constant false alarm rate (CFAR) thresholds for target detection in real-time circumstances. RT-THRES utilizes Gaussian mixture model (GMM) to track and fit the distribution of the target detector's outputs. GMM is an extension to Gaussian probability density function, which could approximate any distribution smoothly. In this method, GMM is utilized to model the detector's output, and then the detection threshold is calculated to achieve a CFAR detection. The conventional GMM's parameter estimation by Expectation-Maximization (EM) requires all data samples in the dataset to be involved during the procedure and the the parameters would be re-estimated when new data samples available. Thus, GMM is difficult to be applied in real-time processing when newly observed data samples coming progressively. To improve GMM's application availability in time-critical circumstance, an optimization strategy is proposed by introducing the Incremental GMM(IGMM) which allows GMM's parameter to be estimated online incrementally. Experiments on real hyperspectral image and synthetic dataset suggest that RT-THRES can track and model the detection outputs' distribution accurately which ensures the accuracy of the calculation of CFAR thresholds. Moreover, by applying the optimization strategy the computational consumption of RT-THRES maintains relatively low.
C1 [Zhao, Huijie; Lou, Chen; Li, Na] Beihang Univ, Sch Instrument Sci & Optoelect Engn, Key Lab Precis Optomechatron Technol, Minist Educ, Beijing 100191, Peoples R China.
C3 Beihang University
RP Li, N (corresponding author), Beihang Univ, Sch Instrument Sci & Optoelect Engn, Key Lab Precis Optomechatron Technol, Minist Educ, Beijing 100191, Peoples R China.
EM lina_17@buaa.edu.cn
CR [Anonymous], 2014, NUMERICAL METHODS EN
   Basener B., 2007, P SPIE
   Bidon S, 2008, IEEE SIGNAL PROC LET, V15, P281, DOI 10.1109/LSP.2007.916044
   Calinon S., 2007, ACM IEEE INT C HUM R
   Cameron AC, 1997, J ECONOMETRICS, V77, P329
   Chang C.-I., 2016, Real-Time Progressive Hyperspectral Image Processing
   Chen C, 2012, INT C COMP SCI SERV
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   DeVore J. L., 2011, PROBABILITY STAT ENG, P508
   Du Q, 2007, PATTERN RECOGN, V40, P1510, DOI 10.1016/j.patcog.2006.08.006
   Du QA, 2009, J REAL-TIME IMAGE PR, V4, P273, DOI 10.1007/s11554-008-0106-9
   Ensafi E., 2008, P SPIE
   Frontera-Pons J, 2013, IEEE INT WORKSH COMP
   Gupta MR, 2010, FOUND TRENDS SIGNAL, V4, P223, DOI 10.1561/2000000034
   Kåsen I, 2004, P SOC PHOTO-OPT INS, V5612, P258, DOI 10.1117/12.578782
   Kraut S, 2005, IEEE T SIGNAL PROCES, V53, P427, DOI 10.1109/TSP.2004.840823
   Manolakis D, 2002, IEEE SIGNAL PROC MAG, V19, P29, DOI 10.1109/79.974724
   Manolakis D, 2000, PROC SPIE, V4049, P2, DOI 10.1117/12.410332
   Manolakis DG, 2005, SIGNAL PROCESSING MA, V44, P29
   Manolakis DG, 2001, P SOC PHOTO-OPT INS, V4381, P1953
   Pieper ML, 2011, PROC SPIE, V8158, DOI 10.1117/12.893950
   Pinto RC, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0141942
   Plaza AJ, 2008, CH CRC COMP INFO SCI, P1
   REED IS, 1990, IEEE T ACOUST SPEECH, V38, P1760, DOI 10.1109/29.60107
   Snyder D., 2008, P 2008 IEEE INT GEOS, V2, P915, DOI DOI 10.1109/IGARSS.2008
   Tarabalka Y, 2009, J REAL-TIME IMAGE PR, V4, P287, DOI 10.1007/s11554-008-0105-x
   Zhang Y, 2010, 2010 IE 10 INT C SIG
   Zhang Z., 2011, International Journal of Experimental Algorithms, V2, P21
NR 28
TC 4
Z9 4
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 15155
EP 15171
DI 10.1007/s11042-017-4693-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400034
DA 2024-07-18
ER

PT J
AU Kumari, S
AF Kumari, Saru
TI Design flaws of "an anonymous two-factor authenticated key agreement
   scheme for session initiation protocol using elliptic curve
   cryptography"
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Design flaw; Guessing attack
AB Recently, a two-factor authenticated key agreement scheme for session initiation protocol is published by Lu et al. in Multimedia Tools and Applications [doi:10.1007/s11042-015-3166-4]. I have examined this scheme and found some design flaws in it. Due to flaw in registration phase, the scheme is vulnerable to guessing attacks. However, flaws during key agreement phase hinder the functionality of the scheme in such a way that mutual authentication process between the user and the server is not viable.
C1 [Kumari, Saru] Ch Charan Singh Univ, Dept Math, Meerut 250004, Uttar Pradesh, India.
C3 Chaudhary Charan Singh University
RP Kumari, S (corresponding author), Ch Charan Singh Univ, Dept Math, Meerut 250004, Uttar Pradesh, India.
EM saryusiirohi@gmail.com
RI Kumari, Saru/K-2038-2019
OI Kumari, Saru/0000-0003-4929-5383
CR Lu YR, 2017, MULTIMED TOOLS APPL, V76, P1801, DOI 10.1007/s11042-015-3166-4
NR 1
TC 20
Z9 20
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13581
EP 13583
DI 10.1007/s11042-016-3771-x
PG 3
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900030
DA 2024-07-18
ER

PT J
AU Malik, A
   Sikka, G
   Verma, HK
AF Malik, Aruna
   Sikka, Geeta
   Verma, Harsh Kumar
TI An image interpolation based reversible data hiding scheme using pixel
   value adjusting feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Image interpolation; Steganography; Embedding
   capacity
ID HISTOGRAM-MODIFICATION; DIFFERENCE EXPANSION
AB In this paper, we propose an image interpolation based reversible data hiding scheme using pixel value adjusting feature. This scheme consists of two phases, namely: image interpolation and data hiding. In order to interpolate the original image, we propose a new image interpolation method which is based on the existing neighbor mean interpolation method. Our interpolation method takes into account all the neighboring pixels like the NMI method. However, it uses different weight-age as per their proximity. Thus, it provides the better quality interpolated image. In case of data hiding phase, secret data is embedded in the interpolated pixels in two passes. In the first pass, it embeds the secret data into the odd valued pixels and then in the second pass, the even valued pixels are used to embed the secret data. To ensure the reversibility of the proposed scheme, the location map is constructed for every pass. Basically, the proposed scheme only increases/decreases the pixel values during data hiding phase, which improves the performance of the proposed scheme in terms of computation complexity. Experimentally, our scheme is superior to the existing scheme in terms of data hiding capacity, image quality and computation complexity.
C1 [Malik, Aruna; Sikka, Geeta; Verma, Harsh Kumar] Natl Inst Technol, Dept Comp Sci & Engn, Jalandhar, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar
RP Malik, A (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Jalandhar, India.
EM arunacsrke@gmail.com; sikkag@nitj.ac.in; vermah@nitj.ac.in
RI Sikka, Geeta/X-8526-2019; Malik, Aruna/GOH-0709-2022; Verma, Harsh
   Kumar/Y-4606-2019; Malik, Aruna/AAL-1997-2020
OI Malik, Aruna/0000-0003-1136-6828; Verma, Harsh
   Kumar/0000-0003-4826-6150; Sikka, Geeta/0000-0003-4795-1842
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], 2004, Data hiding fundamentals and applications: content security in digital multimedia
   Celik MU, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P157
   Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   Chang CC, 2006, J SYST SOFTWARE, V79, P1754, DOI 10.1016/j.jss.2006.03.035
   Chang YT, 2013, J SUPERCOMPUT, V66, P1093, DOI 10.1007/s11227-013-1016-6
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Fallahpour M, 2007, IEICE ELECTRON EXPR, V4, P205, DOI 10.1587/elex.4.205
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   Hsiao JY, 2009, SIGNAL PROCESS, V89, P556, DOI 10.1016/j.sigpro.2008.10.018
   JBIG Committee, 1998, WD14492 ISOIEC JTC1S
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Katzenbeisser SC, 2000, ART H COMP SCI LIBR, P17
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Lin IC, 2009, COMPUT STAND INTER, V31, P458, DOI 10.1016/j.csi.2008.05.010
   Lu TC, 2014, MULTIMED TOOLS APPL, V72, P417, DOI 10.1007/s11042-013-1369-0
   Lu ZM, 2009, J SYST SOFTWARE, V82, P1016, DOI 10.1016/j.jss.2009.01.010
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang FS, 2012, DIGIT SIGNAL PROCESS, V22, P569, DOI 10.1016/j.dsp.2012.03.008
   Wang K, 2013, J SYST SOFTWARE, V86, P1965, DOI 10.1016/j.jss.2013.03.083
   Xuan GR, 2006, LECT NOTES COMPUT SC, V4283, P323
   Yalman Y., 2010, Proceedings 2010 IEEE 13th International Conference on Computational Science and Engineering (CSE 2010), P346, DOI 10.1109/CSE.2010.52
   Yang B, 2011, P INT J ELECT COMMUN, V65, P814, DOI DOI 10.1016/J.AEUE.2011.01.014
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 26
TC 19
Z9 19
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13025
EP 13046
DI 10.1007/s11042-016-3707-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900003
DA 2024-07-18
ER

PT J
AU Malik, A
   Sikka, G
   Verma, HK
AF Malik, Aruna
   Sikka, Geeta
   Verma, Harsh K.
TI A high payload data hiding scheme based on modified AMBTC technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Quantization level; Secret data; Stego image; Absolute
   moment block truncation coding
ID COMPRESSED IMAGES
AB In this paper, we propose a data hiding scheme which uses our modified AMBTC compression technique for embedding the secret data. Our modified AMBTC technique converts the one bit plane into two bit plane which helps in achieving better quality compressed image as well as high capacity. In this scheme, we first apply the original AMBTC technique on the given cover image then identify the smooth and complex blocks using a user defined threshold value. In case of the smooth blocks, it converts the one bit plane into two bit plane using mean value of the block and replaces all the bits of the bit plane with the secret data bits. It calculates four quantization levels in place of two old quantization levels. In case of complex blocks, it converts the one bit plane into two bit plane but here only the first LSBs of the newly constructed bit plane is replaced by the secret data bits. The four new quantization levels are calculated using the resultant bit plane. Thus, this scheme is able to embed 2 bits into each pixel of the smooth blocks and one bit in each pixel of complex blocks. It provides good quality stego image because the introduced error during the secret data embedding is reduced by having four quantization levels. Experimentally, our scheme is superior to the existing AMBTC based data hiding schemes in terms of both data hiding capacity and image quality. In fact, the proposed scheme hides approximately two times more secret data than the existing schemes with better image quality.
C1 [Malik, Aruna; Sikka, Geeta; Verma, Harsh K.] Natl Inst Technol, Dept Comp Sci & Engn, Jalandhar, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar
RP Malik, A (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Jalandhar, India.
EM arunacsrke@gmail.com; sikkag@nitj.ac.in; vermah@nitj.ac.in
RI Verma, Harsh Kumar/Y-4606-2019; Sikka, Geeta/X-8526-2019; Malik,
   Aruna/AAL-1997-2020; Malik, Aruna/GOH-0709-2022
OI Verma, Harsh Kumar/0000-0003-4826-6150; Malik,
   Aruna/0000-0003-1136-6828; Sikka, Geeta/0000-0003-4795-1842
CR Cai-Hua Li, 2011, Information Technology Journal, V10, P1421, DOI 10.3923/itj.2011.1421.1426
   Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   Chang CC, 2010, INFORM SCIENCES, V180, P3045, DOI 10.1016/j.ins.2010.03.027
   Chen J, 2010, IMAGING SCI J, V58, P177, DOI 10.1179/136821910X12651933390629
   Chuang J.-C., 2006, International Journal of Computers & Applications, V28, P329, DOI 10.2316/Journal.202.2006.4.202-1735
   Cox IJ., 2007, DIGITAL WATERMARKING
   Hu YC, 2000, OPT ENG, V39, P464, DOI 10.1117/1.602384
   Huang YH, 2017, MULTIMED TOOLS APPL, V76, P6159, DOI 10.1007/s11042-015-3208-y
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Li F, 2016, MULTIMED TOOLS APPL, V75, P16153, DOI 10.1007/s11042-015-2924-7
   Lin C, 2013, MULTIMED TOOLS APPL, V74, P3823, DOI DOI 10.1007/S11042-013-1801-5
   Lin IC, 2009, COMPUT STAND INTER, V31, P458, DOI 10.1016/j.csi.2008.05.010
   Lu ZM, 2009, J SYST SOFTWARE, V82, P1016, DOI 10.1016/j.jss.2009.01.010
   Ou DH, 2015, MULTIMED TOOLS APPL, V74, P9117, DOI 10.1007/s11042-014-2059-2
   Pan JS, 2014, COMM COM INF SC, V473, P427
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Sun W, 2013, SIGNAL IMAGE VIDEO P, V7, P297, DOI 10.1007/s11760-011-0238-4
   Wang K, 2013, J SYST SOFTWARE, V86, P1965, DOI 10.1016/j.jss.2013.03.083
   Xuan GR, 2006, LECT NOTES COMPUT SC, V4283, P323
   Yang B, 2011, P INT J ELECT COMMUN, V65, P814, DOI DOI 10.1016/J.AEUE.2011.01.014
   Zhang Y, 2013, IEICE T COMMUN, VE96B, P624, DOI 10.1587/transcom.E96.B.624
NR 22
TC 26
Z9 26
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 14151
EP 14167
DI 10.1007/s11042-016-3815-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800023
DA 2024-07-18
ER

PT J
AU Xue, BW
   Li, XL
   Wang, JW
   Guo, ZM
AF Xue, Bowen
   Li, Xiaolong
   Wang, Jinwei
   Guo, Zongming
TI Improved reversible data hiding based on two-dimensional
   difference-histogram modification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Difference-pair-mapping; Two-dimensional
   difference-histogram; Embedding performance
ID WATERMARKING; EXPANSION; STEGANALYSIS
AB Recently, a reversible data hiding (RDH) method based on difference-pair-mapping (DPM) is proposed for better employing the image redundancy. The DPM is a specifically designed injective mapping defined on difference-pairs, and it is an extension of the conventional expansion and shifting techniques used in prior histogram-based RDH. However, any injective mapping defined on difference-pairs with allowed modification directions can derive a RDH method and the embedding performance is closely related to the employed mapping. Then, enhanced performance can be expected if a better DPM is adopted. Based on this consideration, a new RDH method is presented in this paper to improve the previous DPM-based RDH. Specifically, based on the statistical distribution of difference-pairs, a new DPM is designed to better utilize the difference-pairs with high frequencies. Moreover, a fine adjusting strategy is introduced to further optimize the embedding performance by adaptively adjusting the proposed DPM. With the proposed DPM and the adjusting strategy, our method outperforms the previous DPM-based RDH. The superiority of our method over some other state-of-the-art works is also experimentally verified.
C1 [Xue, Bowen; Li, Xiaolong; Guo, Zongming] Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.
   [Wang, Jinwei] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Peking University; Nanjing University of Information Science &
   Technology
RP Guo, ZM (corresponding author), Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.
EM xuebowen15@pku.edu.cn; lixiaolong@pku.edu.cn; wjwei2004@163.com;
   guozongming@pku.edu.cn
RI Li, xiaolong/GRS-9148-2022; li, xiao/GSN-6181-2022
FU National Science Foundation of China [61572052, 61272421]; PAPD fund;
   CICAEET fund
FX This work is supported by the National Science Foundation of China (Nos.
   61572052 and 61272421), the PAPD fund, and the CICAEET fund.
CR An LL, 2012, IEEE T IMAGE PROCESS, V21, P3598, DOI 10.1109/TIP.2012.2191564
   [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Caldelli R, 2010, EURASIP J INF SECUR, DOI 10.1155/2010/134546
   Chang CC, 2012, AEU-INT J ELECTRON C, V66, P758, DOI 10.1016/j.aeue.2012.01.008
   Chen XY, 2015, MULTIMED TOOLS APPL, V74, P5747, DOI 10.1007/s11042-014-1881-x
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Cox IJ., 2007, DIGITAL WATERMARKING
   Dragoi IC, 2015, EUR SIGNAL PR CONF, P56, DOI 10.1109/EUSIPCO.2015.7362344
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Hong W, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/104835
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Huang F, 2015, IEEE T CIRCUITS SYST, V99, P1
   Lee JD, 2010, IEEE T INF FOREN SEC, V5, P638, DOI 10.1109/TIFS.2010.2066971
   Lee SK, 2006, P IEEE ICME
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin C-C, 2015, MOL BIOL CELL, P1
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shi YQ, 2004, P IWDW
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Yang YG, 2015, ADV METEOROL, V2015, DOI 10.1155/2015/157245
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
   Zhang XP, 2013, IEEE T MULTIMEDIA, V15, P316, DOI 10.1109/TMM.2012.2229262
NR 36
TC 6
Z9 6
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13473
EP 13491
DI 10.1007/s11042-016-3763-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900025
DA 2024-07-18
ER

PT J
AU Abubahia, A
   Cocea, M
AF Abubahia, Ahmed
   Cocea, Mihaela
TI Advancements in GIS map copyright protection schemes - a critical review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Geographic information system (GIS); Watermarking; Vector data; Digital
   map; Copyright protection
ID 2D VECTOR MAPS; REVERSIBLE FRAGILE WATERMARKING; BLIND WATERMARKING;
   SPATIAL DATA; ROBUST; ALGORITHM
AB Dramatic advancements in Geographic Information Systems (GIS) and computer technologies resulted in a wide availability of rich-knowledge GIS digital vector maps that are easily accessible and downloadable through the world wide web. This led to the need of copyright protection systems to protect the rights of the producers of these maps. Unlike the research on copyright protection for raster/image data types, the research for vector map data is less documented. This article surveys and classifies the GIS vector map copyright protection research papers published between 2000 and 2014, towards a thorough understanding of the-state-of-the-art, addressing significant limitations of previous review articles, and outlining effective recommendations for future research directions.
C1 [Abubahia, Ahmed; Cocea, Mihaela] Univ Portsmouth, Sch Comp, Portsmouth PO1 3HE, Hants, England.
C3 University of Portsmouth
RP Abubahia, A (corresponding author), Univ Portsmouth, Sch Comp, Portsmouth PO1 3HE, Hants, England.
EM ahmed.abubahia@port.ac.uk; mihaela.cocea@port.ac.uk
CR Abbas Tawfiq A., 2013, Oriental Journal of Computer Science and Technology, V6, P333
   Abubahia AM, 2014, PROC INT C TOOLS ART, P830, DOI 10.1109/ICTAI.2014.128
   Anbo L, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P989, DOI 10.1109/IIH-MSP.2008.130
   [Anonymous], INT C DAT SOFTW ENG
   [Anonymous], COMPUT ENG
   [Anonymous], J NANCHANG U ENG TEC
   [Anonymous], IEEE 7 WORKSH MULT S
   [Anonymous], 17 KOR JAP JOINT WOR
   [Anonymous], 2 INT C PERV COMP AP
   [Anonymous], INT C INF TECHN SOFT
   [Anonymous], CAN GEOM C S COMM
   [Anonymous], COMPUT SCI
   [Anonymous], TECH REP
   [Anonymous], INT J COMPUT ELECT R
   [Anonymous], J SHIHEZI U NAT SCI
   [Anonymous], GEO INF SCI
   [Anonymous], 18 INT C GEOINF
   [Anonymous], 2008, REMOTE SENSING SPATI
   [Anonymous], SPATIAL DATA WEB
   [Anonymous], ACAD J
   [Anonymous], 18 INT C GEOINF
   [Anonymous], 18 INT C GEOINF
   [Anonymous], ACOUST SPEECH SIG PR
   [Anonymous], CARTOGRAPHY POLE POL
   [Anonymous], SPIE
   [Anonymous], SPIE
   [Anonymous], SPIE
   [Anonymous], SCI SURV MAPP
   [Anonymous], COMPUT ENG APPL
   [Anonymous], SPIE
   [Anonymous], 14 ANN POSTGR S CONV
   [Anonymous], EUR C INF MAN
   [Anonymous], GEOM WORLD
   [Anonymous], USENIX SEC S
   [Anonymous], SCI SURV MAPP
   [Anonymous], 2007, INTELLIGENT MULTIMED
   [Anonymous], INT J INF ED TECHNOL
   [Anonymous], TECH REP
   [Anonymous], 2008, GEOINF 2008 JOINT C
   [Anonymous], J GEO INF SCI
   [Anonymous], SURVEY WATERMARKING
   [Anonymous], J GEOM SCI TECHNOL
   [Anonymous], J ZHENGZHOU I SURV M
   [Anonymous], INT S INT SIGN PROC
   [Anonymous], 7 BRAZ S INF SEC COM
   [Anonymous], 2000, INFORM HIDING TECHNI
   [Anonymous], SURV MAPP SICHUAN
   [Anonymous], TECH REP
   [Anonymous], ENG SURV MAPP
   [Anonymous], 2 INT C INF ENG COMP
   [Anonymous], 2011 7 INT C WIR COM
   [Anonymous], J GEOM SCI TECHNOL
   [Anonymous], P WORKSH MULT SEC MM
   [Anonymous], MANUFACTURE INF ENG
   [Anonymous], DIGITAL WATERMARKING
   [Anonymous], 17 INT C DIG SIGN PR
   [Anonymous], J OPTOELECTRON LASER
   [Anonymous], J EARTH SCI RES
   [Anonymous], WUHAN U J GEOM INF S
   [Anonymous], J GEOM SCI TECHNOL
   [Anonymous], J IMAGE GRAPH
   [Anonymous], J XIANGNAN U
   [Anonymous], J CENT S U
   [Anonymous], COMPUT KNOWL TECHNOL
   [Anonymous], 5 ACM WORKSH DIG RIG
   [Anonymous], 1 ACM WORKSH INF HID
   [Anonymous], 24 INT CART C
   [Anonymous], J ELECT INF TECHNOL
   [Anonymous], 2 INT C INT SCI INF
   [Anonymous], HYDROGRAPHIC SURVEYI
   [Anonymous], CCIS
   [Anonymous], GEOINFORMATICS
   [Anonymous], 2012, LNEE
   [Anonymous], ADV INTELLIGENCT SOF
   Aybet J, 2009, COMM COM INF SC, V45, P18
   Bird S, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P454, DOI 10.1109/DICTA.2009.78
   Bishr M., 2007, RES THEORY ADV SPATI, P245
   Cai ZC, 2005, INT C COMP AID DES C, P205, DOI 10.1109/CAD-CG.2005.87
   Cao L, 2014, SIVIP, P1
   Cao LJ, 2013, VISUAL COMPUT, V29, P231, DOI 10.1007/s00371-012-0732-x
   Cao LJ, 2013, DIGIT SIGNAL PROCESS, V23, P912, DOI 10.1016/j.dsp.2012.11.007
   [曹刘娟 Cao Liujuan], 2011, [哈尔滨工程大学学报, Journal of Harbin Engineering University], V32, P340
   Cao LJ, 2010, IEEE IMAGE PROC, P3685, DOI 10.1109/ICIP.2010.5652535
   Chao Wang, 2009, 2009 1st International Conference on Information Science and Engineering (ICISE 2009), P1959, DOI 10.1109/ICISE.2009.199
   Chaoguang Men, 2010, 2010 IEEE International Conference on Mechatronics and Automation (ICMA), P276, DOI 10.1109/ICMA.2010.5589062
   Chuanjian Wang, 2011, 2011 International Conference on Intelligent Computation Technology and Automation (ICICTA), P1243, DOI 10.1109/ICICTA.2011.589
   Chuanjian Wang, 2010, Proceedings 2010 International Conference on Computational and Information Sciences (ICCIS 2010), P590, DOI 10.1109/ICCIS.2010.149
   Chuanjian Wang, 2012, Multimedia Tools and Applications, V57, P67, DOI 10.1007/s11042-010-0536-9
   Dakroury Y, 2010, INT J COMPUT SCI NET, V10, P75
   Deng S, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P1236
   Döllner J, 2005, CARTOGR J, V42, P27, DOI 10.1179/000870405X57266
   Doncel VR, 2007, IEEE T VIS COMPUT GR, V13, P851, DOI 10.1109/TVCG.2007.1050
   Du QZ, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P890, DOI 10.1109/ISECS.2008.67
   Fei P, 2013, SECUR COMMUN NETW, V6, P1117, DOI 10.1002/sec.680
   Feng-juan Cheng, 2010, Proceedings 2010 International Conference on Challenges in Environmental Science and Computer Engineering (CESCE 2010), P101, DOI 10.1109/CESCE.2010.223
   Geng MQ, 2012, PROCEEDINGS OF THE 3RD IEEE INTERNATIONAL CONFERENCE ON NETWORK INFRASTRUCTURE AND DIGITAL CONTENT (IEEE IC-NIDC 2012), P521, DOI 10.1109/ICNIDC.2012.6418808
   Giannoula A, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA549
   Guo Re-si, 2010, Journal of Chinese Computer Systems, V31, P2096
   Han P, 2006, INT GEOSCI REMOTE SE, P2844, DOI 10.1109/IGARSS.2006.731
   Handan Hou, 2014, Information Technology Journal, V13, P869, DOI 10.3923/itj.2014.869.873
   He WT, 2013, IEEE INT CONF CON AU, P1098
   He XD, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON NETWORK INFRASTRUCTURE AND DIGITAL CONTENT, PROCEEDINGS, P1039, DOI 10.1109/ICNIDC.2009.5360931
   Horness Elias, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P2291
   Hu J, 2013, 2013 2ND INTERNATIONAL SYMPOSIUM ON INSTRUMENTATION AND MEASUREMENT, SENSOR NETWORK AND AUTOMATION (IMSNA), P1101, DOI 10.1109/IMSNA.2013.6743473
   [黄晓生 HUANG Xiaosheng], 2006, [工程图学学报, Journal of Engineering Graphics], V27, P158
   Huber S, 2010, IEEE INT CON MULTI, P480, DOI 10.1109/ICME.2010.5583049
   Huo Xiao-Jiao, 2011, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V14, P595
   Im DH, 2008, IEEE SIGNAL PROC LET, V15, P789, DOI 10.1109/LSP.2008.2006338
   Jia PH, 2006, CHINESE GEOGR SCI, V16, P276, DOI 10.1007/s11769-006-0276-y
   Jian-Guo Sun, 2014, International Journal of Network Security, V16, P40
   Jianguo Sun, 2012, Journal of Theoretical and Applied Information Technology, V46, P67
   Jingwen Wu, 2013, Advances in Swarm Intelligence. 4th International Conference, ICSI 2013. Proceedings, P215, DOI 10.1007/978-3-642-38715-9_26
   Jungyeop Kim, 2011, Proceedings of the 2011 7th International Conference on Digital Content, Multimedia Technology and its Applications (IDCTA 2011), P154
   Jungyeop Kim, 2010, Proceedings of the 2010 Sixth International Conference on Networked Computing and Advanced Information Management (NCM 2010), P417
   Kang H, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P234, DOI 10.1109/ITCC.2001.918797
   Kang HI, 2002, ELECTRON LETT, V38, P1645, DOI 10.1049/el:20021076
   Kang HI, 2001, ISIE 2001: IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS PROCEEDINGS, VOLS I-III, P1956, DOI 10.1109/ISIE.2001.932012
   Kang Jing-jing, 2009, Journal of Computer Applications, V29, P1648, DOI 10.3724/SP.J.1087.2009.01648
   Kim J, 2010, ADV INFO SCI SERV SC, V2, P79, DOI [DOI 10.4156/AISS.VOL2.ISSUE4.9, 10.4156/aiss.vol2.issue4.9]
   Kitamura I, 2001, INT GEOSCI REMOTE SE, P1191, DOI 10.1109/IGARSS.2001.976788
   Lafaye J, 2007, LECT NOTES COMPUT SC, V4605, P312
   Lafaye J, 2012, GEOINFORMATICA, V16, P245, DOI 10.1007/s10707-011-0133-8
   Lee SH, 2014, IEICE T INF SYST, VE97D, P34, DOI 10.1587/transinf.E97.D.34
   Lee SH, 2014, MULTIMED TOOLS APPL, V73, P1913, DOI 10.1007/s11042-013-1661-z
   Lee SH, 2013, MULTIMED TOOLS APPL, V63, P757, DOI 10.1007/s11042-011-0894-y
   Lee SH, 2010, DIGIT SIGNAL PROCESS, V20, P1379, DOI 10.1016/j.dsp.2010.01.003
   Li A, 2008, Int Arch Photogram Rem Sens Spatial Inf Sci, V37, P1783
   Li AB, 2012, PROCEDIA ENGINEER, V29, P1344, DOI 10.1016/j.proeng.2012.01.138
   Li B, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON INNOVATIVE DESIGN AND MANUFACTURING (ICIDM), P82, DOI 10.1109/IDAM.2014.6912675
   Li SS, 2012, PROCEDIA ENGINEER, V29, P1331, DOI 10.1016/j.proeng.2012.01.136
   [李媛媛 Li Yuanyuan], 2004, [光子学报, Acta Photonica sinica], V33, P97
   Li YY, 2003, ICCIMA 2003: FIFTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, PROCEEDINGS, P424
   Liangbin Zheng, 2011, 2011 International Conference on Uncertainty Reasoning and Knowledge Engineering (URKE), P17, DOI 10.1109/URKE.2011.6007894
   Liangbin Zheng, 2010, 2010 2nd International Conference on Computer Engineering and Technology (ICCET), P522, DOI 10.1109/ICCET.2010.5485995
   Liangbin Zheng, 2010, 2010 International Conference on Image Analysis and Signal Processing (IASP 2010), P699, DOI 10.1109/IASP.2010.5476177
   Liangbin Zheng, 2010, 2010 2nd International Workshop on Education Technology and Computer Science (ETCS), P535, DOI 10.1109/ETCS.2010.31
   Longley P. A., 2005, Geographic Information Systems and Science
   Lopez C, 2002, INT J GEOGR INF SCI, V16, P589, DOI 10.1080/13658810210129148
   Lucchese C, 2010, VLDB J, V19, P531, DOI 10.1007/s00778-010-0178-6
   Madelaine J, 2007, ACM S INF COMP COMM, P265
   Magalhaes K, 2009, IEEE INT C COMMUNICA, P1
   Men Chao-guang, 2009, Journal of the Harbin Institute of Technology, V41, P83
   [门朝光 Men Chaoguang], 2010, [高技术通讯, Chinese High Technology Letters], V20, P342
   Min LQ, 2012, ADV INTEL SOFT COMPU, V127, P51
   [闵连权 MIN Lianquan], 2007, [测绘通报, Bulletin of Surveying and Mapping], P43
   Mouhamed MR, 2012, 2012 2ND INTERNATIONAL CONFERENCE ON UNCERTAINTY REASONING AND KNOWLEDGE ENGINEERING (URKE), P67, DOI 10.1109/URKE.2012.6319586
   Mouhamed MR, 2013, COMM COM INF SC, V381, P84
   Murti K.C.S., 2011, INT ACM C COMM COMP, P545
   Muttoo Sunil Kumar, 2012, Annals of GIS, V18, P135, DOI 10.1080/19475683.2011.640640
   Neyman S.N., 2014, Telecommun. Comput. Electron. Control, V12, P367
   Neyman SN, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P179, DOI 10.1109/IC3INA.2013.6819170
   Neyman SN, 2013, PROC TECH, V11, P614, DOI 10.1016/j.protcy.2013.12.236
   Niu XM, 2006, INT J INNOV COMPUT I, V2, P1301
   Ohbuchi R, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P577, DOI 10.1109/ICME.2002.1035847
   Ohbuchi R, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P216
   Pan JJ, 2013, COMPUT AIDED DESIGN, V45, P144, DOI 10.1016/j.cad.2012.09.001
   Park KT, 2002, LECT NOTES COMPUT SC, V2532, P58
   Peng F, 2014, COMPUT AIDED DESIGN, V49, P42, DOI 10.1016/j.cad.2013.12.006
   Peng F, 2010, COMPUT AIDED DESIGN, V42, P1207, DOI 10.1016/j.cad.2010.08.004
   Pu YC, 2006, INT C PATT RECOG, P930
   Ramaswmay G., 2010, Journal of Theoretical and Applied Information Technology, V16, P116
   Ren N, 2014, INT CONF GEOINFORM
   Shao CY, 2006, IEICE T INF SYST, VE89D, P1290, DOI 10.1093/ietisy/e89-d.3.1290
   Solachidis V, 2004, IEEE COMPUT GRAPH, V24, P44, DOI 10.1109/MCG.2004.1297010
   Solachidis V, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P9, DOI 10.1109/ICIP.2000.899265
   Solachidis V, 2000, INT CONF ACOUST SPEE, P1955, DOI 10.1109/ICASSP.2000.859213
   Sonnet H, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P73, DOI 10.1109/PCCGA.2003.1238249
   Sun GL, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P544, DOI 10.1109/MINES.2009.244
   Sun JG, 2014, CHINA COMMUN, V11, P125, DOI 10.1109/CC.2014.6911094
   Sun JG, 2013, APPL MECH MATER, V333-335, P1219, DOI 10.4028/www.scientific.net/AMM.333-335.1219
   Tian Z, 2004, OCEANS '04 MTS/IEEE TECHNO-OCEAN '04, VOLS 1- 2, CONFERENCE PROCEEDINGS, VOLS. 1-4, P776
   VLACHOS M, 2008, P EDBT, P276
   Voigt M, 2005, P SOC PHOTO-OPT INS, V5681, P409, DOI 10.1117/12.588195
   Voigt M, 2002, P SOC PHOTO-OPT INS, V4675, P621, DOI 10.1117/12.465322
   Voigt M, 2003, P SOC PHOTO-OPT INS, V5020, P359, DOI 10.1117/12.476815
   Voigt M, 2004, P 2004 MULT SEC WORK, P160, DOI DOI 10.1145/1022431.1022459
   Voloshynovskiy S, 2001, IEEE COMMUN MAG, V39, P118, DOI 10.1109/35.940053
   Wang CJ, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 2, PROCEEDINGS, P71, DOI 10.1109/MINES.2009.195
   Wang NN, 2014, COMPUT AIDED DESIGN, V47, P108, DOI 10.1016/j.cad.2013.10.005
   Wang NN, 2013, MULTIMED TOOLS APPL, V67, P709, DOI 10.1007/s11042-012-1333-4
   Wang N, 2012, COMPUT AIDED DESIGN, V44, P320, DOI 10.1016/j.cad.2011.11.001
   Wang X, 2012, LECT NOTES ELECT ENG, P533, DOI DOI 10.1007/978-94-007-1839-5_56
   Wang X, 2007, IEEE T INF FOREN SEC, V2, P311, DOI 10.1109/TIFS.2007.902677
   Wang Xun, 2004, Journal of Computer Aided Design & Computer Graphics, V16, P1377
   Wu BY, 2010, GEO-SPAT INF SCI, V13, P40, DOI 10.1007/s11806-010-0196-y
   Wu BY, 2009, ICDIP 2009: INTERNATIONAL CONFERENCE ON DIGITAL IMAGE PROCESSING, PROCEEDINGS, P366, DOI 10.1109/ICDIP.2009.25
   Wu D, 2012, ADV INTEL SOFT COMPU, V115, P197
   Wu D, 2009, 2009 WRI INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND MOBILE COMPUTING: CMC 2009, VOL 3, P385, DOI 10.1109/CMC.2009.86
   Xiao-Jiao Huo, 2010, Proceedings 2010 3rd International Conference on Intelligent Networks and Intelligent Systems (ICINIS 2010), P649, DOI 10.1109/ICINIS.2010.115
   Xun Wang, 2012, Journal of Software, V7, P2349, DOI 10.4304/jsw.7.10.2349-2356
   Yamada T, 2006, 2006 INTERNATIONAL CONFERENCE ON SERVICE SYSTEMS AND SERVICE MANAGEMENT, VOLS 1 AND 2, PROCEEDINGS, P1637, DOI 10.1109/ICSSSM.2006.320791
   Yan HW, 2012, APPL GEOMAT, V4, P225, DOI 10.1007/s12518-011-0064-y
   Yan HW, 2011, COMPUT ENVIRON URBAN, V35, P485, DOI 10.1016/j.compenvurbsys.2010.10.004
   Yu Chen Zhou, 2010, Proceedings of the 2010 IEEE Congress on Services (SERVICES-1), P1, DOI 10.1109/SERVICES.2010.43
   Yu-Chi Pu, 2009, Information Technology Journal, V8, P982, DOI 10.3923/itj.2009.982.989
   Yue ML, 2014, LECT NOTES COMPUT SC, V8709, P129, DOI 10.1007/978-3-319-11116-2_12
   Yuwei Peng, 2012, 2012 International Conference on Computer Science and Service System (CSSS), P2095, DOI 10.1109/CSSS.2012.521
   Zhang C, 2008, International Conference on Intelligent Computation Technology and Automation, Vol 2, Proceedings, P127, DOI 10.1109/ICICTA.2008.108
   Zhang D, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL II, PROCEEDINGS, P469
   Zhang HL, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P549, DOI 10.1109/MINES.2009.224
   Zhang Junfeng, 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P179, DOI 10.1109/ICCSN.2011.6013689
   Zhang Lei, 2010, Wuhan University Journal of Natural Sciences, V15, P403, DOI 10.1007/s11859-010-0674-y
   Zhang Yanqun, 2011, 2011 Cross Strait Quad-Regional Radio Science and Wireless Technology Conference, P1430, DOI 10.1109/CSQRWC.2011.6037234
   Zhang Y, 2014, INT CONF SYST SCI EN, P7, DOI 10.1109/ICSSE.2014.6887894
   Zhang Zuo-li, 2009, Computer Engineering and Design, V30, P1473
   Zhang ZL, 2009, PROCEEDINGS OF THE FIRST INTERNATIONAL WORKSHOP ON EDUCATION TECHNOLOGY AND COMPUTER SCIENCE, VOL II, P1075, DOI 10.1109/ETCS.2009.505
   Zhao Hua, 2010, 2010 IEEE 11th International Conference on Computer-Aided Industrial Design & Conceptual Design (CAIDCD 2010), P1441, DOI 10.1109/CAIDCD.2010.5681939
   Zhao H, 2008, I C COMP AID DES CON, P518, DOI 10.1109/CAIDCD.2008.4730623
   [赵晶 Zhao Jing], 2010, [中国图象图形学报, Journal of Image and Graphics], V15, P1121
   Zheng LB, 2009, PROCEEDINGS OF THE FIRST INTERNATIONAL WORKSHOP ON EDUCATION TECHNOLOGY AND COMPUTER SCIENCE, VOL I, P304, DOI 10.1109/ETCS.2009.75
   Zhong SP, 2006, INT C COMMUN CIRCUIT, P24, DOI 10.1109/ICCCAS.2006.284578
   Zhou X, 2006, 2006 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, PTS 1 AND 2, PROCEEDINGS, P1199, DOI 10.1109/ICCIAS.2006.295245
   Zhou X, 2006, INT J COMPUT SCI NET, V6, P202
   [周旭 Zhou Xu], 2004, [中国图象图形学报. A, Journal of image and graphics], V9, P611
   [朱长青 Zhu Changqing], 2010, [测绘通报, Bulletin of Surveying and Mapping], P1
   Zope-Chaudhari S., 2012, 2012 International Conference on Computer and Communication Engineering (ICCCE), P594, DOI 10.1109/ICCCE.2012.6271256
   Zope-Chaudhari S., 2013, International Journal of Database Management Systems, V5, P29
   Zope-Chaudhari S, 2012, PROCEEDINGS OF THE ACM SIGSPATIAL INTERNATIONAL WORKSHOP ON GEOSTREAMING (IWGS) 2012, P78
NR 218
TC 26
Z9 32
U1 4
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12205
EP 12231
DI 10.1007/s11042-016-3441-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200003
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Liu, P
   Zhao, H
AF Liu, Peng
   Zhao, Heng
TI Altered salience network is related to functional dyspepsia: a
   structural and functional MRI data fusion study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal data; Brain networks; Conditional Granger causality;
   Voxel-based morphometry; MRI
ID BRAIN ACTIVITY; ALZHEIMERS-DISEASE; CONNECTIVITY; DISTENSION; ANXIETY;
   CORTEX; STATES; TRIAL; SCALE
AB Multimodal data fusion analysis has been applied in brain imaging, which could be important for understanding pathogenesis of disorders and medical diagnosis. Based on patients with functional dyspepsia (FD), the aim of this study was to investigate structural and functional alterations within the salience network (SN) associated with regulating the default mode network (DMN) and central-executive network (CEN). Independent component analysis (ICA) was applied to identify these resting state networks (RSNs). Conditional Granger causality analysis (CGCA) was used to evaluate effective connectivity among the isolated RSNs and certain brain regions of interest (ROIs). Voxel-based morphometry (VBM) was then used to assess structure of gray matter in the SN. Our results showed that FD patients showed significantly increased brain activity in SN compared with healthy controls (HCs). The causal influences from the SN to DMN and CEN were weaker in patients. The anterior cingulate cortex (ACC) served as the causal outflow hub among the ROIs in FD patients. And FD patients had structural abnormality in the ACC and AI. Our findings suggest that the critical causal role of insula is disrupted in FD patients, and ACC could compensate insula dysfunction of regulating other brain regions. Our results also show that combing multimodal media data is potentially valuable to enrich our understanding of pathogenesis of FD.
C1 [Liu, Peng; Zhao, Heng] Xidian Univ, Sch Life Sci & Technol, Life Sci Res Ctr, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Liu, P; Zhao, H (corresponding author), Xidian Univ, Sch Life Sci & Technol, Life Sci Res Ctr, Xian 710071, Shaanxi, Peoples R China.
EM liupengphd@gmail.com; hengzhao@mail.xidian.edu.cn
RI 刘, 鹏/AAK-7931-2021
FU National Natural Science Foundation of China [81471738]; Fundamental
   Research Funds for the Central Universities
FX This study was supported by the National Natural Science Foundation of
   China under Grant Nos. 81471738 and the Fundamental Research Funds for
   the Central Universities. The author would like to thank Fang Zeng
   (Acupuncture and Tuina School, Chengdu University of Traditional Chinese
   Medicine) for MRI data collection.
CR Bonnelle V, 2012, P NATL ACAD SCI USA, V109, P4690, DOI 10.1073/pnas.1113455109
   Büchel C, 2002, J NEUROSCI, V22, P970, DOI 10.1523/JNEUROSCI.22-03-00970.2002
   Chen JYW, 2011, BRAIN RES, V1392, P121, DOI 10.1016/j.brainres.2011.03.069
   Chiong W, 2013, BRAIN, V136, P1929, DOI 10.1093/brain/awt066
   Clark DL, 2001, Journal of Neuropsychiatry, V13, P525
   El-Serag HB, 2004, ALIMENT PHARM THER, V19, P643, DOI 10.1111/j.1365-2036.2004.01897.x
   Fox MD, 2007, NAT REV NEUROSCI, V8, P700, DOI 10.1038/nrn2201
   Good CD, 2001, NEUROIMAGE, V14, P21, DOI 10.1006/nimg.2001.0786
   Greicius MD, 2004, P NATL ACAD SCI USA, V101, P4637, DOI 10.1073/pnas.0308627101
   Greicius MD, 2009, CEREB CORTEX, V19, P72, DOI 10.1093/cercor/bhn059
   Lee IS, 2016, NEUROGASTROENT MOTIL, V28, P793, DOI 10.1111/nmo.12793
   Lee MH, 2013, AM J NEURORADIOL, V34, P1866, DOI 10.3174/ajnr.A3263
   Li YO, 2007, HUM BRAIN MAPP, V28, P1251, DOI 10.1002/hbm.20359
   Liao W, 2010, BIOL CYBERN, V102, P57, DOI 10.1007/s00422-009-0350-5
   Liu MX, 2015, HUM BRAIN MAPP, V36, P1847, DOI 10.1002/hbm.22741
   Liu P, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068205
   Manoliu A, 2014, SCHIZOPHRENIA BULL, V40, P428, DOI 10.1093/schbul/sbt037
   Mayer EA, 2006, GASTROENTEROLOGY, V131, P1925, DOI 10.1053/j.gastro.2006.10.026
   Menon Vinod, 2010, Brain Struct Funct, V214, P655, DOI 10.1007/s00429-010-0262-0
   Northoff G, 2006, NEUROIMAGE, V31, P440, DOI 10.1016/j.neuroimage.2005.12.002
   Seeley WW, 2007, J NEUROSCI, V27, P2349, DOI 10.1523/JNEUROSCI.5587-06.2007
   Seth AK, 2010, J NEUROSCI METH, V186, P262, DOI 10.1016/j.jneumeth.2009.11.020
   Shirer WR, 2012, CEREB CORTEX, V22, P158, DOI 10.1093/cercor/bhr099
   Sridharan D, 2008, P NATL ACAD SCI USA, V105, P12569, DOI 10.1073/pnas.0800005105
   Stevens MC, 2009, HUM BRAIN MAPP, V30, P2356, DOI 10.1002/hbm.20673
   Talley NJ, 1999, AM J GASTROENTEROL, V94, P2390
   Talley NJ, 1999, GUT, V45, P37
   Van Oudenhove L, 2004, BEST PRACT RES CL GA, V18, P663, DOI 10.1016/j.bpg.2004.04.010
   Van Oudenhove L, 2010, GASTROENTEROLOGY, V139, P36, DOI 10.1053/j.gastro.2010.04.015
   Van Oudenhove L, 2010, AM J GASTROENTEROL, V105, P913, DOI 10.1038/ajg.2010.39
   Vandenberghe J, 2007, GASTROENTEROLOGY, V132, P1684, DOI 10.1053/j.gastro.2007.03.037
   Watson KK, 2006, NEUROSCIENCE, V141, P1107, DOI 10.1016/j.neuroscience.2006.04.084
   Yan CG, 2010, FRONT SYST NEUROSCI, V4, DOI 10.3389/fnsys.2010.00013
   Zeng F, 2011, GASTROENTEROLOGY, V141, P499, DOI 10.1053/j.gastro.2011.05.003
   Zhang J, 2016, IEEE T MED IMAGING, V35, P2524, DOI 10.1109/TMI.2016.2582386
   Zhou GY, 2013, MAGN RESON IMAGING, V31, P996, DOI 10.1016/j.mri.2013.03.019
   Zhou GY, 2013, NMR BIOMED, V26, P410, DOI 10.1002/nbm.2878
   ZUNG WWK, 1971, PSYCHOSOMATICS, V12, P371
   ZUNG WWK, 1965, ARCH GEN PSYCHIAT, V13, P508, DOI 10.1001/archpsyc.1965.01730060026004
NR 39
TC 0
Z9 0
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 12083
EP 12096
DI 10.1007/s11042-016-4019-5
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000052
DA 2024-07-18
ER

PT J
AU Liu, XY
   Ma, LZ
   Liu, YP
AF Liu, Xianyong
   Ma, Lizhuang
   Liu, Yanping
TI Global Tone: using tone to draw in Pen-and-Ink illustration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE The human visual system; Visibility; Non-Photorealistic rendering;
   Spherical trigonometry
AB We present a new illustrating algorithm of global tone, enlightened by the skill called artistic tone. It is structure-aware and computationally driven by "visibility", which refers to quantitatively measuring how visible a point (or a region) on a mesh is within a virtual camera space. The feature lines are sketched by silhouettes and/or suggestive contours, which then are enhanced by colorful inks, mimicking tonal values. To overcome that computing tone throughout surfaces is prohibitive, the global shape descriptor of Gaussian visibility is proposed, which is fast and robust such that the rendering pipeline is finished in real-time. The line drawings are largely improved as the descriptor enables our approach to convey more shape cues beyond shades. We demonstrated the plausibility of global tone with various models, showing that our experimental results are comparable to or better than state-of-the-art.
C1 [Liu, Xianyong] Jiangsu Univ Technol, Sch Comp Engn, Changzhou, Jiangsu, Peoples R China.
   [Liu, Xianyong] Key Lab Cloud Comp & Intelligent Informat Proc Ch, Changzhou, Jiangsu, Peoples R China.
   [Ma, Lizhuang] Shanghai Jiao Tong Univ, Sch Comp Sci & Technol, Shanghai, Peoples R China.
   [Liu, Yanping] Zhejiang Ocean Univ, Sch Ocean Sci & Technol, Zhoushan, Peoples R China.
C3 Jiangsu University of Technology; Shanghai Jiao Tong University;
   Zhejiang Ocean University
RP Liu, XY (corresponding author), Jiangsu Univ Technol, Sch Comp Engn, Changzhou, Jiangsu, Peoples R China.; Liu, XY (corresponding author), Key Lab Cloud Comp & Intelligent Informat Proc Ch, Changzhou, Jiangsu, Peoples R China.; Liu, YP (corresponding author), Zhejiang Ocean Univ, Sch Ocean Sci & Technol, Zhoushan, Peoples R China.
EM xianyong.liu@outlook.com; liuyp@zjou.edu.cn
RI liu, yan/HGV-1365-2022; Sun, Peng/KDO-4243-2024; liu, yan/HCI-5542-2022
OI Liu, Xianyong/0000-0001-7777-0888
FU China Scholarship Council [201206230015]; China NSFC key project
   [61133009]; National 973 Program of China [2011CB302203]
FX We were sponsored by China Scholarship Council (No. 201206230015), China
   NSFC key project (No. 61133009), and National 973 Program of China (No.
   2011CB302203). We would like to appreciate the following groups and
   people for sharing their 3D models: the Stanford Graphics Group, the
   Princeton Graphics Group, SHREC, Y. Y. Zheng, C. L. Tai, G. Lavoue, and
   Mike Bailey. Also, we thank Jonathan Palacios who provided a software to
   generate images with crossing-stroke-like shades. The comments by the
   anonymous reviewers helped to improve this paper.
CR Appel Arthur., 1967, Proceedings of the ACM National Conference, P387
   Brummelen G., 2012, Heavenly Mathematics: The Forgotten Art of Spherical Trigonometry, V1st
   Cipolla R., 2000, VISUAL MOTION CURVES
   Cohen-Or D, 2003, IEEE T VIS COMPUT GR, V9, P412, DOI 10.1109/TVCG.2003.1207447
   Cole F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531334
   David HA, 1963, METHOD PAIRED COMP B
   DeCarlo D, 2003, ACM T GRAPHIC, V22, P848, DOI 10.1145/882262.882354
   DeCarlo Doug., 2004, P INT S NONPHOTOREAL, P15, DOI DOI 10.1145/987657.987661
   Decaudin P, 1996, SYNTIM PROJECT INRIA, V6
   Do Carmo M.P., 1976, DIFFERENTIAL GEOMETR, V2
   Gallier J., 2000, Geometric Methods and Applications: For Computer Science and Engineering
   Gooch A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P447, DOI 10.1145/280814.280950
   Gooch B., 2001, Non-photorealistic rendering
   Green S, 1999, SPRING EUROGRAP, P341
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Hertzmann A, 2003, IEEE COMPUT GRAPH, V23, P70, DOI 10.1109/MCG.2003.1210867
   Hertzmann A, 2000, COMP GRAPH, P517, DOI 10.1145/344779.345074
   Judd T, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239470
   Kalnins RD, 2002, ACM T GRAPHIC, V21, P755, DOI 10.1145/566570.566648
   Kalogerakis E, 2012, ACM T GRAPHIC, V31, DOI [10.1145/2077341.2077342, 10.1145/2185520.2185551]
   Kazi RH, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P351, DOI 10.1145/2556288.2556987
   Kazi RubaiatHabib., 2012, Proceedings of the ACM Conference on Human Factors in Computing Systems, P1727
   Lu Cewu., 2012, Proc. NPAR, P65
   Meier B. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P477, DOI 10.1145/237170.237288
   Meyer N, 2003, VISUALIZATION AND MATHEMATICS III, P35
   Miao YW, 2010, VISUAL COMPUT, V26, P433, DOI 10.1007/s00371-010-0458-6
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Northrup J. D., 2000, Proceedings of the 1st International Symposium on Non-photorealistic Animation and Rendering, P31, DOI DOI 10.1145/340916.340920
   Ohtake Y, 2004, ACM T GRAPHIC, V23, P609, DOI 10.1145/1015706.1015768
   Palacios J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276446, 10.1145/1239451.1239506]
   Rusinkiewicz S, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P486, DOI 10.1109/TDPVT.2004.1335277
   Rusinkiewicz S., 2005, ACM SIGGRAPH 2005 CO
   Salisbury M. P., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P401, DOI 10.1145/258734.258890
   Smith K, 2010, RR7194
   Winkenbach G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P91, DOI 10.1145/192161.192184
   WOLFE JM, 1994, PSYCHON B REV, V1, P202, DOI 10.3758/BF03200774
   Woop S, 2005, ACM T GRAPHIC, V24, P434, DOI 10.1145/1073204.1073211
   Wu JL, 2013, GRAPH MODELS, V75, P255, DOI 10.1016/j.gmod.2013.05.002
   Yan CR, 2008, IEEE T VIS COMPUT GR, V14, P468, DOI 10.1109/TVCG.2007.70440
   Yoshizawa Shin., 2005, S SOLID PHYS MODELIN, P227, DOI [10.1145/1060244.1060270, DOI 10.1145/1060244.1060270]
   Zhang E, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P267, DOI 10.1109/VISUAL.2002.1183784
   Zhou K, 2009, ACM SIGGRAPH ASIA 20
   Zhou K, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409079
NR 43
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12853
EP 12869
DI 10.1007/s11042-016-3649-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200030
DA 2024-07-18
ER

PT J
AU Song, W
   Wu, D
   Xi, YL
   Park, YW
   Cho, K
AF Song, Wei
   Wu, Dong
   Xi, Yulong
   Park, Yong Woon
   Cho, Kyungeun
TI Motion-based skin region of interest detection with a real-time
   connected component labeling algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion-based skin region detection; Real-time connected component
   labeling; Face and hand gesture recognition; Natural user interface
ID SEGMENTATION; TRACKING; MODELS
AB This paper presents a motion-based skin Region of Interest (ROI) detection method using a real-time connected component labeling algorithm to provide real-time and adaptive skin ROI detection in video images. Skin pixel segmentation in video images is a pre-processing step for face and hand gesture recognition, and motion is a cue for detecting foreground objects. We define skin ROIs as pixels of skin-like color where motion takes place. In the skin color estimation phase, RGB color histograms are utilized to define the skin color distribution and specify the threshold to segment skin-like regions. A parallel computed connected component labeling algorithm is also proposed to group the segmentation results into several clusters. If a cluster covers any motion pixel, this cluster is identified as a skin ROI. The method's results for real images are shown, and its speed is evaluated for various parameters. This technology is compatible with monitoring systems, scene understanding, and natural user interfaces.
C1 [Song, Wei; Wu, Dong] North China Univ Technol, Coll Comp Sci, 5 Jinyuanzhuang Rd, Beijing 100144, Peoples R China.
   [Xi, Yulong; Cho, Kyungeun] Dongguk Univ Seoul, Dept Multimedia Engn, 26 Pildong 3 Ga, Seoul 100715, South Korea.
   [Park, Yong Woon] Agcy Def Dev, Daejeon 305152, South Korea.
C3 North China University of Technology; Dongguk University; Agency of
   Defense Development (ADD), Republic of Korea
RP Cho, K (corresponding author), Dongguk Univ Seoul, Dept Multimedia Engn, 26 Pildong 3 Ga, Seoul 100715, South Korea.
EM cke@dongguk.edu
FU MSIP(Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC(Information Technology Research Center) [IITP-2015-H8501-15-1014];
   Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Science, ICT and future Planning
   [NRF-2015R1A2A2A01003779]; Beijing Municipal Education Commission
   [KM2015_10009006]; National Natural Science Foundation of China
   [61503005]
FX This research was supported by the MSIP(Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC(Information Technology Research
   Center) support program (IITP-2015-H8501-15-1014) supervised by the
   IITP(Institute for Information & communications Technology Promotion),
   by Basic Science Research Program through the National Research
   Foundation of Korea (NRF) funded by the Ministry of Science, ICT and
   future Planning (NRF-2015R1A2A2A01003779), by Science and Technology
   Project of Beijing Municipal Education Commission (KM2015_10009006), and
   by the National Natural Science Foundation of China (61503005).
CR Al-Tairi ZH, 2014, J INF PROCESS SYST, V10, P283, DOI 10.3745/JIPS.02.0002
   Appiah K, 2010, COMPUT VIS IMAGE UND, V114, P1282, DOI 10.1016/j.cviu.2010.03.021
   Dadgostar F, 2006, PATTERN RECOGN LETT, V27, P1342, DOI 10.1016/j.patrec.2006.01.007
   Ghadekar PP, 2014, J INFORM PROCESSING, V5, P105
   Hawick KA, 2010, PARALLEL COMPUT, V36, P655, DOI 10.1016/j.parco.2010.07.002
   He LF, 2009, PATTERN RECOGN, V42, P1977, DOI 10.1016/j.patcog.2008.10.013
   Karavasilis V, 2012, COMPUT VIS IMAGE UND, V116, P1135, DOI 10.1016/j.cviu.2012.07.004
   Kawulok M, 2014, PATTERN RECOGN LETT, V41, P3, DOI 10.1016/j.patrec.2013.08.028
   Kim JB, 2003, PATTERN RECOGN LETT, V24, P113, DOI 10.1016/S0167-8655(02)00194-0
   Kumar A, 2010, COMPUT VIS IMAGE UND, V114, P1139, DOI 10.1016/j.cviu.2010.03.013
   Lim T, 2012, PATTERN RECOGN, V45, P1696, DOI 10.1016/j.patcog.2011.10.018
   Lu JB, 2007, INT CONF ACOUST SPEE, P689
   Medina-Carnicer R, 2009, PATTERN RECOGN LETT, V30, P432, DOI 10.1016/j.patrec.2008.10.016
   Naji SA, 2012, DIGIT SIGNAL PROCESS, V22, P933, DOI 10.1016/j.dsp.2012.05.004
   Schmugge SJ, 2007, COMPUT VIS IMAGE UND, V108, P41, DOI 10.1016/j.cviu.2006.10.009
   Sharif MH, 2009, IEEE IMAGE PROC, P981, DOI 10.1109/ICIP.2009.5413802
   Si W, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION AND MULTIMEDIA TECHNOLOGY, PROCEEDINGS, P207, DOI 10.1109/ICIMT.2009.35
   Song W, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/795851
   Stefanov N, 2007, COMPUT VIS IMAGE UND, V108, P98, DOI 10.1016/j.cviu.2006.10.017
   Vanus Kucera P, 2014, COMPUT INF SCI, V4
   Vintache Damien, 2010, Tsinghua Science and Technology, V15, P11, DOI 10.1016/S1007-0214(10)70002-X
   Xu SC, 2008, COMPUT VIS IMAGE UND, V110, P1, DOI 10.1016/j.cviu.2006.12.002
   Zhao Y., 2013, Australasian Universities Power Engineering Conference, P1
NR 23
TC 12
Z9 12
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11199
EP 11214
DI 10.1007/s11042-015-3201-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000004
DA 2024-07-18
ER

PT J
AU Chen, F
   He, HJ
   Huo, YR
AF Chen, Fan
   He, Hongjie
   Huo, Yaoran
TI Self-embedding watermarking scheme against JPEG compression with
   superior imperceptibility
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Self-embedding; JPEG compression; Weight-function
   modulo; Survival quality factor (SQF)
ID FRAGILE WATERMARKING; IMAGE AUTHENTICATION; VECTOR
AB To improve the imperceptibility, security and tamper detection performance, a self-embedding watermarking scheme against JPEG compression is proposed in this work. The recovery watermark of all blocks in the host image, which consists of 6-bit DC-code and 5-bit AC-code and simultaneously used to both tamper detection and tamper recovery, is recombined based on the secret key and embedded in the quantized DCT coefficients. This strategy not only enhances the ability against the known forgery attacks due to introducing multi-blocks independency, but also improves the tamper detection performance by designing the tamper detection method based on the multi-neighbor characteristic and multi-threshold optimization. To achieve the better imperceptibility, the 7 middle frequency DCT coefficients of an 8 x 8 block are chosen to hide the 11-bit watermark by adopting the weight-function modulo based embedding method. Robustness against JPEG compression is enhanced by setting the quantization step of the chosen DCT coefficients according to the standard JPEG quantization table and an adjustable scaling factor which balances the robustness with imperceptibility. We also discuss the effects of different scaling factors on the imperceptibility and robustness in terms of peak signal to noise ratio (PSNR) and survival quality factor (SQF) of watermarked image generated by a given scaling factor. Experimental results demonstrate that the proposed method outperforms conventional semi-fragile restorable watermarking schemes in imperceptibility, tamper detection and tamper recovery in various forgery attacks especially for JPEG compression with low QFs.
C1 [Chen, Fan; He, Hongjie; Huo, Yaoran] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.
C3 Southwest Jiaotong University
RP Chen, F (corresponding author), Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.
EM Fchen@swjtu.edu.cn
FU National Natural Science Foundation of China [61373180, 61461047];
   Science and Technique Foundation of Tibet Autonomous Region; Science and
   Technology Innovation Talent Project of Sichuan Province [2014-058]
FX This work is supported in part by the National Natural Science
   Foundation of China (Grant No. 61373180, 61461047), the Science and
   Technique Foundation of Tibet Autonomous Region (2012), the Science and
   Technology Innovation Talent Project of Sichuan Province (No. 2014-058).
   Thanks authors of reference [18] for providing us the source codes.
CR Chamlawi R, 2010, INFORM SCIENCES, V180, P4909, DOI 10.1016/j.ins.2010.08.039
   Fridrich J, 2002, J ELECTRON IMAGING, V11, P262, DOI 10.1117/1.1459449
   FRIDRICH J, 1999, P ICIP 99 KOB JAP
   Han SH, 2010, INT J INF SECUR, V9, P19, DOI 10.1007/s10207-009-0093-2
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   He HJ, 2006, P 5 INT WORKSH DIG W
   He HJ, 2012, IEEE T INF FOREN SEC, V7, P185, DOI 10.1109/TIFS.2011.2162950
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Huang HC, 2007, CIRC SYST SIGNAL PR, V26, P671, DOI 10.1007/s00034-006-0104-z
   Huo YR, 2014, MULTIMED TOOLS APPL, V72, P123, DOI 10.1007/s11042-012-1317-4
   Huo YR, 2013, LNCS, V8389, P393
   Korus P, 2013, IEEE T IMAGE PROCESS, V22, P1134, DOI 10.1109/TIP.2012.2227769
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Mendoza NJ, 2010, P 53 IEEE INT MIDW S
   Pan JS, 2004, ELECTRON LETT, V40, P1409, DOI 10.1049/el:20046454
   Phadikar A, 2012, J VIS COMMUN IMAGE R, V23, P454, DOI 10.1016/j.jvcir.2012.01.005
   Preda RO, 2013, MEASUREMENT, V46, P367, DOI 10.1016/j.measurement.2012.07.010
   Qin C, 2013, SIGNAL PROCESS, V93, P933, DOI 10.1016/j.sigpro.2012.11.013
   Rosales-Roldan L, 2013, SIGNAL PROCESS-IMAGE, V28, P69, DOI 10.1016/j.image.2012.11.006
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Saxena A, 2013, IEEE T IMAGE PROCESS, V22, P3974, DOI 10.1109/TIP.2013.2265882
   Sun HM, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2423636.2423639
   Ullah R, 2013, COMPUT ELECTR ENG, V39, P2019, DOI 10.1016/j.compeleceng.2013.04.024
   Wang H., 2012, LNCS, V7128, P72, DOI DOI 10.1007/978-3-642-32205-1_8
   WANG S, 2015, J INFORM HIDING MULT, V6, P1264
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Yan B., 2015, J INFORM HIDING MULT, V6, P882
   Zhang HY, 2007, CHINESE J ELECTRON, V16, P525
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
NR 33
TC 18
Z9 20
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9681
EP 9712
DI 10.1007/s11042-016-3574-0
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300026
DA 2024-07-18
ER

PT J
AU Jiang, QP
   Shao, F
   Jiang, GY
   Yu, M
   Peng, ZJ
AF Jiang, Qiuping
   Shao, Feng
   Jiang, Gangyi
   Yu, Mei
   Peng, Zongju
TI Leveraging visual attention and neural activity for stereoscopic 3D
   visual comfort assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality of experience(QoE); Stereoscopic three-dimensional (S3D); Visual
   comfort assessment (VCA); Visual attention; Neural activity; Random
   forest (RF)
ID REFERENCE QUALITY ASSESSMENT; 3-D OBJECT RETRIEVAL; COMPUTATIONAL MODEL;
   DISCOMFORT; DISPARITY; IMAGES; FATIGUE; NEURONS; PERCEPTION; MT
AB Visual comfort assessment (VCA) for stereoscopic three-dimensional (S3D) images is a challenging problem in the community of 3D quality of experience (3D-QoE). The goal of VCA is to automatically predict the degree of perceived visual discomfort in line with subjective judgment. The challenges of VCA typically lie in the following two aspects: 1) formulating effective visual comfort-aware features, and 2) finding an appropriate way to pool them into an overall visual comfort score. In this paper, a novel two-stage framework is proposed to address these problems. In the first stage, primary predictive feature (PPF) and advanced predictive feature (APF) are separately extracted and then integrated to reflect the perceived visual discomfort for 3D viewing. Specifically, we compute the S3D visual attention-weighted disparity statistics and neural activities of the middle temporal (MT) area in human brain to construct the PPF and APF, respectively. Followed by the first stage, the integrated visual comfort-aware features are fused with a single visual comfort score by using random forest (RF) regression, mapping from a high-dimensional feature space into a low-dimensional quality (visual comfort) space. Comparison results with five state-of-the-art relevant models on a standard benchmark database confirm the superior performance of our proposed method.
C1 [Jiang, Qiuping; Shao, Feng; Jiang, Gangyi; Yu, Mei; Peng, Zongju] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
C3 Ningbo University
RP Shao, F (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
EM shaofeng@nbu.edu.cn
RI jiang, gang/KII-8233-2024; Peng, Zongju/AAA-2914-2020; Jiang,
   Qiuping/AAL-8273-2020
OI Peng, Zongju/0000-0001-8286-538X; 
FU Natural Science Foundation of China [61271021, U1301257]; Scientific
   Research Foundation of Graduate School of Ningbo University; K.C. Wong
   Magna Fund in Ningbo University; Natural Science Foundation of China
   [61271021, U1301257]; Scientific Research Foundation of Graduate School
   of Ningbo University; K.C. Wong Magna Fund in Ningbo University
FX The authors would like to thank the editor and all of the reviewers for
   their valuable comments and suggestions that have led to improvements in
   the quality and presentation of this paper. This work was supported in
   part by the Natural Science Foundation of China (grant 61271021,
   U1301257), in part by the Scientific Research Foundation of Graduate
   School of Ningbo University. It was also sponsored by the K.C. Wong
   Magna Fund in Ningbo University.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2002, BT500 ITUR
   [Anonymous], 2007, P IEEE INT C COMP VI
   [Anonymous], 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment
   [Anonymous], BT1438 ITUR
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chang B, 2013, ASIAPAC SIGN INFO PR
   Cumming BG, 1997, NATURE, V389, P280, DOI 10.1038/38487
   DeAngelis GC, 2003, J NEUROPHYSIOL, V89, P1094, DOI 10.1152/jn.00717.2002
   DeAngelis GC, 1999, J NEUROSCI, V19, P1398
   DeAngelis GC, 1998, NATURE, V394, P677, DOI 10.1038/29299
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P2625, DOI 10.1109/TIP.2014.2305100
   Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Hur N, 2011, IEEE T BROADCAST, V57, P395, DOI 10.1109/TBC.2011.2114710
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang QP, 2016, IEEE SIGNAL PROC LET, V23, P302, DOI 10.1109/LSP.2016.2516521
   Jiang QP, 2015, SIGNAL PROCESS-IMAGE, V38, P57, DOI 10.1016/j.image.2015.04.007
   Jiang QP, 2015, J VIS COMMUN IMAGE R, V33, P123, DOI 10.1016/j.jvcir.2015.09.009
   Jiang QP, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.4.043002
   Jung YJ, 2013, IEEE T CIRC SYST VID, V23, P2077, DOI 10.1109/TCSVT.2013.2270394
   Kim D, 2011, IEEE T CIRC SYST VID, V21, P231, DOI 10.1109/TCSVT.2011.2106275
   Lambooij M, 2011, DISPLAYS, V32, P209, DOI 10.1016/j.displa.2011.05.012
   Lambooij M, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.030201
   Lang C, 2012, P 12 EUR C COMP VIS
   Lee J, 2010, OPT ENG, V49, DOI 10.1117/1.3319760
   Lee SI, 2013, IEEE T BROADCAST, V59, P580, DOI 10.1109/TBC.2013.2268713
   Liu Y, 2011, IEEE T IMAGE PROCESS, V20, P2515, DOI 10.1109/TIP.2011.2118223
   Martinez LM, 2003, NEUROSCIENTIST, V9, P317, DOI 10.1177/1073858403252732
   Mittal A, 2011, 2011 IEEE DIGITAL SIGNAL PROCESSING WORKSHOP AND IEEE SIGNAL PROCESSING EDUCATION WORKSHOP (DSP/SPE), P338, DOI 10.1109/DSP-SPE.2011.5739236
   Moorthy AK, 2009, IEEE J-STSP, V3, P193, DOI 10.1109/JSTSP.2009.2015374
   Nojiri Y., 2006, Proc. IBC, P373
   Park J, 2014, IEEE J-STSP, V8, P415, DOI 10.1109/JSTSP.2014.2311885
   Shao F, 2015, IEEE T IMAGE PROCESS, V24, P2971, DOI 10.1109/TIP.2015.2436332
   Shao F, 2013, IEEE T IMAGE PROCESS, V22, P1940, DOI 10.1109/TIP.2013.2240003
   Shibata T, 2011, J VISION, V11, DOI 10.1167/11.8.11
   Sohn H, 2013, IEEE T BROADCAST, V59, P28, DOI 10.1109/TBC.2013.2238413
   Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939
   Tam WJ, 2011, IEEE T BROADCAST, V57, P335, DOI 10.1109/TBC.2011.2125070
   Ukai K, 2008, DISPLAYS, V29, P106, DOI 10.1016/j.displa.2007.09.004
   Urvoy M, 2013, ANN TELECOMMUN, V68, P641, DOI 10.1007/s12243-013-0394-3
   Wang JL, 2013, IEEE T IMAGE PROCESS, V22, P2151, DOI 10.1109/TIP.2013.2246176
   Wang Z, 2006, IEEE IMAGE PROC, P2945, DOI 10.1109/ICIP.2006.313136
   Yano S, 2002, DISPLAYS, V23, P191, DOI 10.1016/S0141-9382(02)00038-0
   Zhao SC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P879, DOI 10.1145/2733373.2806354
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
NR 50
TC 13
Z9 14
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9405
EP 9425
DI 10.1007/s11042-016-3548-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300013
DA 2024-07-18
ER

PT J
AU Singh, N
   Arya, R
   Agrawal, RK
AF Singh, Navjot
   Arya, Rinki
   Agrawal, R. K.
TI A novel position prior using fusion of rule of thirds and image center
   for salient object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object detection; Cluster validation; Gaussian mixture model;
   Expectation maximization; Rule of thirds; Spatial saliency
ID VISUAL-ATTENTION; FEATURES; MODEL
AB Salient object detection is one of the challenging problems in the field of computer vision. Most of the models use a center prior to detect salient objects. They give more weightage to the objects which are present near the center of the image and less weightage to the ones near the corners of the image. But there may be images in which object is placed near the image corner. In order to handle such situation, we propose a position prior based on the combined effect of the rule of thirds and the image center. In this paper, we first segment the image into an optimal number of clusters using Davies-Bouldin index. Then the pixels in these clusters are used as samples to build the Gaussian mixture model whose parameters are refined using Expectation-Maximization algorithm. Thereafter the spatial saliency of the clusters is computed based on the proposed position prior and then combined into a saliency map. The performance is evaluated both qualitatively and quantitatively on six publicly available datasets. Experimental results demonstrate that the proposed model outperforms the seventeen existing state-of-the-art methods in terms of F -measure and area under curve on all the six datasets.
C1 [Singh, Navjot; Arya, Rinki; Agrawal, R. K.] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi 110067, India.
   [Singh, Navjot] Natl Inst Technol, Srinagar 246174, Pauri Garhwal, India.
C3 Jawaharlal Nehru University, New Delhi; National Institute of Technology
   (NIT System); National Institute of Technology Uttarakhand
RP Singh, N (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi 110067, India.; Singh, N (corresponding author), Natl Inst Technol, Srinagar 246174, Pauri Garhwal, India.
EM navjot.singh.09@gmail.com
RI AGRAWAL, RAMESH/AAR-8896-2020; Singh, Navjot/I-5444-2017
OI Singh, Navjot/0000-0003-0409-8482; Agrawal, Ramesh
   kumar/0000-0003-3122-5096
CR Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   [Anonymous], CVPR
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], 2002, 2D TARGET DETECTION
   [Anonymous], 2014, COMPUT VISUAL MEDIA
   [Anonymous], 2015, COMPUT VIS MEDIA
   Arya R, 2016, MULTIMED TOOLS APPL, V75, P8267, DOI 10.1007/s11042-015-2750-y
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Frintrop S, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1658349.1658355
   Fu H, 2013, SYSTEMS MAN CYBERN A
   Gasparini F, 2007, OPT ENG, V46, DOI 10.1117/1.2721764
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Graefe V, 1996, PROCEEDINGS OF THE 1996 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P363, DOI 10.1109/IVS.1996.566407
   Halkidi M, 2001, J INTELL INF SYST, V17, P107, DOI 10.1023/A:1012801612483
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Imamoglu N, 2013, IEEE T MULTIMEDIA, V15, P96, DOI 10.1109/TMM.2012.2225034
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2000, MODELS BOTTOM TOP VI
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Karssemeijer N, 1996, IEEE T MED IMAGING, V15, P611, DOI 10.1109/42.538938
   Li X., 2013, SALIENCY DETECTION V
   Li ZC, 2011, IEEE T IMAGE PROCESS, V20, P2017, DOI 10.1109/TIP.2010.2099128
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Long Mai, 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P91, DOI 10.1109/ISM.2011.23
   Ren Z, 2010, ACM MM
   Rother C, 2006, ACM T GRAPHIC, V25, P847, DOI 10.1145/1141911.1141965
   Santella A., 2006, Conference on Human Factors in Computing Systems. CHI2006, P771
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Singh N, 2015, SIGNAL IMAGE VIDEO P, V9, P427, DOI 10.1007/s11760-013-0457-y
   Singh N, 2014, PATTERN RECOGN, V47, P1731, DOI 10.1016/j.patcog.2013.11.012
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vikram TN, 2012, PATTERN RECOGN, V45, P3114, DOI 10.1016/j.patcog.2012.02.009
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhu L, 2014, IEEE T IMAGE PROCESS, V23, P5094, DOI 10.1109/TIP.2014.2361024
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 47
TC 18
Z9 18
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10521
EP 10538
DI 10.1007/s11042-016-3676-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400013
DA 2024-07-18
ER

PT J
AU Mera, D
   Batko, M
   Zezula, P
AF Mera, David
   Batko, Michal
   Zezula, Pavel
TI Speeding up the multimedia feature extraction: a comparative study on
   the big data approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data; Image feature extraction; Map Reduce; Apache Storm; Apache
   Spark; Grid computing
AB The current explosion of multimedia data is significantly increasing the amount of potential knowledge. However, to get to the actual information requires to apply novel content-based techniques which in turn require time consuming extraction of indexable features from the raw data. In order to deal with large datasets, this task needs to be parallelized. However, there are multiple approaches to choose from, each with its own benefits and drawbacks. There are also several parameters that must be taken into consideration, for example the amount of available resources, the size of the data and their availability. In this paper, we empirically evaluate and compare approaches based on Apache Hadoop, Apache Storm, Apache Spark, and Grid computing, employed to distribute the extraction task over an outsourced and distributed infrastructure.
C1 [Mera, David] Univ Santiago Compostela, Ctr Singular Invest Tecnoloxias Informac CITIUS, Rua Jenaro Fuente Dominguez, Santiago de Compostela 15782, Spain.
   [Batko, Michal; Zezula, Pavel] Masaryk Univ, Fac Informat, Lab Data Intens Syst & Applicat, Brno, Czech Republic.
C3 Universidade de Santiago de Compostela; Masaryk University Brno
RP Mera, D (corresponding author), Univ Santiago Compostela, Ctr Singular Invest Tecnoloxias Informac CITIUS, Rua Jenaro Fuente Dominguez, Santiago de Compostela 15782, Spain.
EM david.mera@usc.es
RI Mera, David/I-2406-2015; Batko, Michal/D-9889-2012
OI Mera, David/0000-0002-0639-6574; 
FU European Union Seventh Framework Programme (FP7) [246016]; Czech Science
   Foundation [P103/12/G084]; Xunta de Galicia project [GPC2014/037];
   MetaCentrum [LM2010005]; CERIT-SC under the program Centre CERIT
   Scientific Cloud, part of the Operational Program Research and
   Development for Innovations [CZ.1.05/3.2.00/08.0144]
FX This work was carried out during the tenure of an ERCIM "Alain
   Bensoussan" Fellowship programme. The research leading to these results
   has received funding from the European Union Seventh Framework Programme
   (FP7/2007-2013) under grant agreement No. 246016. This work has been
   partially supported by both the Czech Science Foundation project number
   P103/12/G084 and the Xunta de Galicia project number GPC2014/037.
   Computational resources were provided by the MetaCentrum under the
   program LM2010005 and the CERIT-SC under the program Centre CERIT
   Scientific Cloud, part of the Operational Program Research and
   Development for Innovations, Reg. no. CZ.1.05/3.2.00/08.0144.
CR [Anonymous], 1593832002 ISOIEC
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2010, LARGE SCALE DISTRIB
   [Anonymous], 2012, NSDI
   Batko M, 2007, LECT NOTES COMPUT SC, V4877, P1
   Bolettieri P, 2009, COPHIR TEST COLLECTI
   Chen C. L. Philop, 2014, INFORM SCI
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Donahue J, 2014, PR MACH LEARN RES, V32
   Eyben Florian, 2010, P 18 ACM INT C MULT, P1459
   Huang FC, 2012, IEEE T CIRC SYST VID, V22, P340, DOI 10.1109/TCSVT.2011.2162760
   IBM research department, 2013, GLOB TECHN OUTL
   Jogalekar P, 2000, IEEE T PARALL DISTR, V11, P589, DOI 10.1109/71.862209
   Kao O, 2008, PARALLEL COMPUT, V34, P700, DOI 10.1016/j.parco.2008.09.002
   Karau H., 2015, Learning Spark: Lightning-Fast Big Data Analysis
   Klusacek D, 2012, COMPUT SCI, V13
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marz N., 2014, BIG DATA PRINCIPLES
   Moise D., 2013, Proceedings of the 3rd ACM International conference on multimedia retrieval - ICMR'13, P17, DOI DOI 10.1145/2461466.2461470
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Shvachko K., 2010, 2010 IEEE 26th Symposium on Mass Storage Systems and Technologies (MSST), P1
   Sustr Z, 2009, EGEE TECHNICAL FORUM
   Sweeney C., 2011, THESIS
   Toshniwa A, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P147, DOI 10.1145/2588555.2595641
   White T., 2012, HADOOP DEFINITIVE GU
   Zaharia Matei, 2010, 2 USENIX WORKSHOP HO
NR 26
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7497
EP 7517
DI 10.1007/s11042-016-3415-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400062
DA 2024-07-18
ER

PT J
AU Nematollahi, MA
   Gamboa-Rosales, H
   Martinez-Ruiz, FJ
   De la Rosa-Vargas, JI
   Al-Haddad, SAR
   Esmaeilpour, M
AF Nematollahi, Mohammad Ali
   Gamboa-Rosales, Hamurabi
   Martinez-Ruiz, Francisco J.
   De la Rosa-Vargas, Jose I.
   Al-Haddad, S. A. R.
   Esmaeilpour, Mansour
TI Multi-factor authentication model based on multipurpose speech
   watermarking and online speaker recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech watermarking; Online speaker recognition; Discrete wavelet packet
   transform; Threat model; Attack analysis; Multi-factor authentication
ID SECURITY IMPROVEMENT; VERIFICATION; IDENTIFICATION
AB In this paper, a Multi-Factor Authentication (MFA) method is developed by a combination of Personal Identification Number (PIN), One Time Password (OTP), and speaker biometric through the speech watermarks. For this reason, a multipurpose digital speech watermarking applied to embed semi-fragile and robust watermarks simultaneously in the speech signal, respectively to provide tamper detection and proof of ownership. Similarly, the blind semi-fragile speech watermarking technique, Discrete Wavelet Packet Transform (DWPT) and Quantization Index Modulation (QIM) are used to embed the watermark in an angle of the wavelet's sub-bands where more speaker specific information is available. For copyright protection of the speech, a blind and robust speech watermarking are used by applying DWPT and multiplication. Where less speaker specific information is available the robust watermark is embedded through manipulating the amplitude of the wavelet's sub-bands. Experimental results on TIMIT, MIT, and MOBIO demonstrate that there is a trade-off among recognition performance of speaker recognition systems, robustness, and capacity which are presented by various triangles. Furthermore, threat model and attack analysis are used to evaluate the feasibility of the developed MFA model. Accordingly, the developed MFA model is able to enhance the security of the systems against spoofing and communication attacks while improving the recognition performance via solving problems and overcoming limitations.
C1 [Gamboa-Rosales, Hamurabi; Martinez-Ruiz, Francisco J.; De la Rosa-Vargas, Jose I.] Autonomous Univ Zacatecas, Dept Elect Engn, Zacatecaszac 98000, Mexico.
   [Al-Haddad, S. A. R.] Univ Putra Malaysia, UPM, Fac Engn, Dept Comp & Commun Syst Engn, Serdang 43400, Selangor Darul, Malaysia.
   [Nematollahi, Mohammad Ali; Esmaeilpour, Mansour] Islamic Azad Univ, Hamedan Branch, Dept Comp Engn, Hamadan, Iran.
C3 Universiti Putra Malaysia; Islamic Azad University
RP Nematollahi, MA (corresponding author), Islamic Azad Univ, Hamedan Branch, Dept Comp Engn, Hamadan, Iran.
EM greencomputinguae@gmail.com
RI De la Rosa, José Ismael/N-7394-2019; De la Rosa, José/R-3971-2019;
   Al-Haddad, S. A. R./AAM-6449-2020; Esmaeilpour, Mansour/J-6458-2016
OI De la Rosa, José Ismael/0000-0002-7337-8974; Esmaeilpour,
   Mansour/0000-0002-2475-518X
CR Akhaee MA, 2009, IEEE INT C COMM ICC
   Akhaee MA, 2010, SIGNAL PROCESS, V90, P2487, DOI 10.1016/j.sigpro.2010.02.013
   Al-Nuaimy W, 2011, DIGIT SIGNAL PROCESS, V21, P764, DOI 10.1016/j.dsp.2011.01.013
   [Anonymous], WAVELET TOUR SIGNAL
   [Anonymous], SPEAK LANG REC WORKS
   Baroughi AF, 2014, IS T SPIE ELECT IMAG
   Besacier L, 2000, SPEECH COMMUN, V31, P89, DOI 10.1016/S0167-6393(99)00070-9
   Bimbot F, 2004, EURASIP J APPL SIG P, V2004, P430, DOI 10.1155/S1110865704310024
   BOLTEN JB, 2003, E AUTHENTICATION GUI
   Brookes M, 2006, VOICEBOX SPEECH TOOL
   Chaturvedi Ankita, 2013, Information Systems Security. 9th International Conference, ICISS 2013. Proceedings: LNCS 8303, P63, DOI 10.1007/978-3-642-45204-8_5
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Faundez-Zanuy M, 2006, SPEECH COMMUN, V48, P1608, DOI 10.1016/j.specom.2006.06.010
   Faundez-Zanuy M, 2007, PATTERN RECOGN, V40, P3027, DOI 10.1016/j.patcog.2007.02.016
   Garofolo John, 1993, TIMIT ACOUSTIC PHONE
   Heck L, 2013, MSR IDENTITY TOOLBOX
   HINKLEY DV, 1969, BIOMETRIKA, V56, P635, DOI 10.1093/biomet/56.3.635
   Huber R, 2011, COMMUNICATIONS MULTI
   Hyon S, 2012, SIGN INF PROC ASS AN
   Kenny P, 2012, PROC
   Khitrov M., 2013, Biometric Technology Today, V2013, P9
   Kim JJ, 2011, J INF PROCESS SYST, V7, P187, DOI 10.3745/JIPS.2011.7.1.187
   Kumar A, 2013, FUTURE INFORM COMMUN, P579
   Li CS, 2011, J STAT COMPUT SIM, V81, P1081, DOI 10.1080/00949651003677410
   Li Q, 2006, P 4 ACM INT WORKSH C
   Lu XG, 2008, SPEECH COMMUN, V50, P312, DOI 10.1016/j.specom.2007.10.005
   McCool C, 2012, MULT EXP WORKSH ICME
   Mohamed S, 2013, METHOD SPEECH WATERM
   Nematollahi MA, 2015, INT J HUMANOID ROB, V12, P1
   Nematollahi MA, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/372398
   Nematollahi MA, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0074-5
   O'Gorman L, 2003, P IEEE, V91, P2021, DOI 10.1109/JPROC.2003.819611
   Pathak MA, 2013, IEEE T AUDIO SPEECH, V21, P397, DOI 10.1109/TASL.2012.2215602
   REYNOLDS DA, 1995, SPEECH COMMUN, V17, P91, DOI 10.1016/0167-6393(95)00009-D
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Roberts C, 2007, COMPUT SECUR, V26, P14, DOI 10.1016/j.cose.2006.12.008
   Simon J, 2012, DATAHASH
   Wu ZZ, 2015, SPEECH COMMUN, V66, P130, DOI 10.1016/j.specom.2014.10.005
NR 38
TC 11
Z9 11
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7251
EP 7281
DI 10.1007/s11042-016-3350-1
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400051
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Peng, Y
   Lu, BL
AF Peng, Yong
   Lu, Bao-Liang
TI Robust structured sparse representation via half-quadratic optimization
   for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse representation; Structured sparsity; Robustness; Half-quadratic
   optimization; Face recognition
ID RECOVERY; SIGNAL; ILLUMINATION; MINIMIZATION; CORRENTROPY; ALGORITHMS;
   SELECTION
AB By representing a test sample with a linear combination of training samples, sparse representation-based classification (SRC) has shown promising performance in many applications such as computer vision and signal processing. However, there are several shortcomings in SRC such as 1) the l(2)-norm employed by SRC to measure the reconstruction fidelity is noise sensitive and 2) the l(1)-norm induced sparsity does not consider the correlation among the training samples. Furthermore, in real applications, face images with similar variations, such as illumination or expression, often have higher correlation than those from the same subject. Therefore, we correspondingly propose to improve the performance of SRC from two aspects by: 1) replacing the noise-sensitive l(2)-norm with an M-estimator to enhance its robustness and 2) emphasizing the sparsity in terms of the number of classes instead of the number of training samples, which leads to the structured sparsity. The formulated robust structured sparse representation (RGSR) model can be efficiently optimized via alternating minimization method under the half-quadratic (HQ) optimization framework. Extensive experiments on representative face data sets show that RGSR can achieve competitive performance in face recognition and outperforms several state-of-the-art methods in dealing with various types of noise such as corruption, occlusion and disguise.
C1 [Peng, Yong] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Zhejiang, Peoples R China.
   [Peng, Yong] Minist Educ, Key Lab Complex Syst Modeling & Simulat, Hangzhou 310018, Zhejiang, Peoples R China.
   [Lu, Bao-Liang] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
C3 Hangzhou Dianzi University; Shanghai Jiao Tong University
RP Peng, Y (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Zhejiang, Peoples R China.; Peng, Y (corresponding author), Minist Educ, Key Lab Complex Syst Modeling & Simulat, Hangzhou 310018, Zhejiang, Peoples R China.
EM stany.peng@gmail.com
RI Peng, Yong/JCO-0601-2023
OI Peng, Yong/0000-0003-1208-972X; Lu, Bao-Liang/0000-0001-8359-0058
FU National Natural Science Foundation of China [61272248]; National Basic
   Research Program of China [2013CB329401]; Science and Technology
   Commission of Shanghai Municipality [13511500200]; Hangzhou Dianzi
   University [KYS055616025]
FX The authors would like to thank the anonymous reviewers for their
   helpful comments on this paper. This work was partially supported by the
   National Natural Science Foundation of China (No. 61272248), the
   National Basic Research Program of China (No. 2013CB329401), the Science
   and Technology Commission of Shanghai Municipality (No. 13511500200) and
   the funding of Hangzhou Dianzi University (KYS055616025).
CR Bickel PJ, 2009, ANN STAT, V37, P1705, DOI 10.1214/08-AOS620
   Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319
   Boyd S., 2004, CONVEX OPTIMIZATION
   Combettes PL, 2005, MULTISCALE MODEL SIM, V4, P1168, DOI 10.1137/050626090
   Ding C., 2006, P 23 INT C MACH LEAR, P281, DOI DOI 10.1145/1143844.1143880
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100
   Du L, 2012, IEEE DATA MINING, P201, DOI 10.1109/ICDM.2012.39
   Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547
   GEMAN D, 1995, IEEE T IMAGE PROCESS, V4, P932, DOI 10.1109/83.392335
   GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Grave G. R., 2011, Adv. Neural Inf. Process.Syst., V24, P2187
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   He R, 2014, IEEE T PATTERN ANAL, V36, P261, DOI 10.1109/TPAMI.2013.102
   He R, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995328
   He R, 2011, IEEE T PATTERN ANAL, V33, P1561, DOI 10.1109/TPAMI.2010.220
   Huber P. J., 2011, ROBUST STAT INT ENCY
   Lai J, 2014, IEEE INT CON MULTI, DOI 10.1109/ICME.2014.6890246
   Lee HY, 2015, EXPERT SYST APPL, V42, P751, DOI 10.1016/j.eswa.2014.08.033
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Liu WF, 2007, IEEE T SIGNAL PROCES, V55, P5286, DOI 10.1109/TSP.2007.896065
   Lu CY, 2013, IEEE I CONF COMP VIS, P1801, DOI 10.1109/ICCV.2013.226
   Martinez A. M., 1998, THE AR FACE DATABASE
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Nikolova M, 2005, SIAM J SCI COMPUT, V27, P937, DOI 10.1137/030600862
   Rosas-Romero R, 2014, ENG APPL ARTIF INTEL, V29, P201, DOI 10.1016/j.engappai.2013.09.008
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wagner A, 2009, PROC CVPR IEEE, P597, DOI 10.1109/CVPRW.2009.5206654
   Yang AY, 2013, IEEE T IMAGE PROCESS, V22, P3234, DOI 10.1109/TIP.2013.2262292
   Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393
   Yang M, 2010, LECT NOTES COMPUT SC, V6316, P448, DOI 10.1007/978-3-642-15567-3_33
   Yang M, 2010, IEEE IMAGE PROC, P1601, DOI 10.1109/ICIP.2010.5652363
   Yang SY, 2013, ENG APPL ARTIF INTEL, V26, P2608, DOI 10.1016/j.engappai.2013.07.002
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhao P, 2006, J MACH LEARN RES, V7, P2541
NR 36
TC 14
Z9 15
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8859
EP 8880
DI 10.1007/s11042-016-3510-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800054
DA 2024-07-18
ER

PT J
AU Song, H
   Wu, XX
   Liang, W
   Jia, YD
AF Song, Hao
   Wu, Xinxiao
   Liang, Wei
   Jia, Yunde
TI Recognizing key segments of videos for video annotation by learning from
   web image sets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video annotation; Key segment; Image set; Transfer learning
AB In this paper, we propose an approach of inferring the labels of unlabeled consumer videos and at the same time recognizing the key segments of the videos by learning from Web image sets for video annotation. The key segments of the videos are automatically recognized by transferring the knowledge learned from related Web image sets to the videos. We introduce an adaptive latent structural SVM method to adapt the pre-learned classifiers using Web image sets to an optimal target classifier, where the locations of the key segments are modeled as latent variables because the ground-truth of key segments are not available. We utilize a limited number of labeled videos and abundant labeled Web images for training annotation models, which significantly alleviates the time-consuming and labor-expensive collection of a large number of labeled training videos. Experiment on the two challenge datasets Columbia's Consumer Video (CCV) and TRECVID 2014 Multimedia Event Detection (MED2014) shows our method performs better than state-of-art methods.
C1 [Song, Hao; Wu, Xinxiao; Liang, Wei; Jia, Yunde] Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Song, H; Wu, XX (corresponding author), Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
EM songhao@bit.edu.cn; wuxinxiao@bit.edu.cn; liangwei@bit.edu.cn;
   jiayunde@bit.edu.cn
FU 973 Program of China [2012CB720000]; Natural Science Foundation of
   China(NSFC) [61375044, 61472038]; Specialized Research Fund for the
   Doctoral Program of Higher Education of China [20121101120029];
   Specialized Fund for Joint Building Program of Beijing Municipal
   Education Commission; Excellent young scholars Research Fund of BIT
FX This work was supported in part by the 973 Program of China under grant
   No. 2012CB720000, the Natural Science Foundation of China(NSFC) under
   Grant No. 61375044 and 61472038, the Specialized Research Fund for the
   Doctoral Program of Higher Education of China (20121101120029), the
   Specialized Fund for Joint Building Program of Beijing Municipal
   Education Commission, and the Excellent young scholars Research Fund of
   BIT (2013).
CR [Anonymous], ENHANCING VIDEO EVEN
   [Anonymous], 2011, P 1 INT C MULT RETR
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], IEEE I CONF COMP VIS
   [Anonymous], P INT C MULT RETR
   [Anonymous], 2013, P 3 ACM C INT C MULT
   [Anonymous], DISCOVER DISCOVERING
   [Anonymous], P INT C MULT RETR
   Baktashmotlagh M, 2013, IEEE I CONF COMP VIS, P769, DOI 10.1109/ICCV.2013.100
   Bianco S, 2015, COMPUT VIS IMAGE UND, V131, P88, DOI 10.1016/j.cviu.2014.06.015
   Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57
   Chen L, 2013, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2013.344
   Cheng WH, 2008, IEEE T CIRC SYST VID, V18, P1639, DOI 10.1109/TCSVT.2008.2005608
   Do Trinh-Minh-Tri., 2009, ICML '09 Proceedings of the 26th Annual International Conference on Machine Learning, P265
   Duan Lixin, 2012, IEEE Trans Neural Netw Learn Syst, V23, P504, DOI 10.1109/TNNLS.2011.2178556
   Fang M, 2015, PATTERN RECOGN LETT, V51, P101, DOI 10.1016/j.patrec.2014.08.011
   Habibian A, 2014, COMPUT VIS IMAGE UND, V124, P110, DOI 10.1016/j.cviu.2014.02.003
   Ikizler-Cinbis N, 2009, IEEE I CONF COMP VIS, P995, DOI 10.1109/ICCV.2009.5459368
   Jia Y., 2014, P 22 ACM INT C MULT, P675
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li WX, 2013, PROC CVPR IEEE, P2587, DOI 10.1109/CVPR.2013.334
   Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167
   Liu JE, 2013, IEEE WORK APP COMP, P339, DOI 10.1109/WACV.2013.6475038
   Long MS, 2014, IEEE T KNOWL DATA EN, V26, P1076, DOI 10.1109/TKDE.2013.111
   Ni BB, 2011, IEEE T MULTIMEDIA, V13, P1217, DOI 10.1109/TMM.2011.2167317
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Schroff F, 2011, IEEE T PATTERN ANAL, V33, P754, DOI 10.1109/TPAMI.2010.133
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sun Qian, 2011, P ADV NEUR INF PROC, P505
   Tang Kevin, 2012, P INT C NEUR INF PRO, P647
   Wang H, 2014, IEEE T MULTIMEDIA, V16, P1282, DOI 10.1109/TMM.2014.2312251
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yang Y, 2014, IEEE T MULTIMEDIA, V16, P1677, DOI 10.1109/TMM.2014.2323014
NR 33
TC 1
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6111
EP 6126
DI 10.1007/s11042-016-3253-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400001
DA 2024-07-18
ER

PT J
AU Wang, XY
   Liu, CM
AF Wang, Xingyuan
   Liu, Chuanming
TI A novel and effective image encryption algorithm based on chaos and DNA
   encoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaos; DNA encoding; Piecewise linear chaotic map;
   Logistic map
ID SCHEME; IMPROVEMENT; CIPHER; SYSTEM
AB In this paper, we proposed a novel and effective image encryption algorithm based on Chaos and DNA encoding rules. Piecewise Linear Chaotic Map (PWLCM) and Logistic Map are applied to generate all parameters the presented algorithm needs and DNA encoding technology functions as an auxiliary tool. The proposed algorithm consists of these parts: firstly, use PWLCM to produce a key image, whose pixels are generated by Chaos; Secondly, encode the plain image and the key image with DNA rules by rows respectively and different rows are encoded according to various rules decided by logistic map; After that, employ encoded key image to conduct DNA operations with the encoded plain image row by row to obtain an intermediate image and the specific operation executed every row is chosen by logistic map; Then, decode the intermediate image as the plain image of next step. Finally, repeat steps above by columns again to get the ultimate cipher image. The experiment results and analysis indicate that the proposed algorithm is capable of withstanding typical attacks and has good character of security.
C1 [Wang, Xingyuan; Liu, Chuanming] Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian 116024, Peoples R China.
C3 Dalian University of Technology
RP Wang, XY (corresponding author), Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian 116024, Peoples R China.
EM wangxy@dlut.edu.cn; liuchuanming@outlook.com
RI Wang, Xing-yuan/I-6353-2015
FU National Natural Science Foundation of China [61370145, 61173183,
   60973152]; Doctoral Program Foundation of Institution of Higher
   Education of China [20070141014]; Program for Liaoning Excellent Talents
   in University [LR2012003]; National Natural Science Foundation of
   Liaoning province [20082165]; Fundamental Research Funds for the Central
   Universities [DUT12JB06]
FX This research is supported by the National Natural Science Foundation of
   China (Nos: 61370145, 61173183, and 60973152), the Doctoral Program
   Foundation of Institution of Higher Education of China (No:
   20070141014), Program for Liaoning Excellent Talents in University (No:
   LR2012003), the National Natural Science Foundation of Liaoning province
   (No: 20082165) and the Fundamental Research Funds for the Central
   Universities (No: DUT12JB06).
CR Akhavan A, 2015, OPT COMMUN, V350, P77, DOI 10.1016/j.optcom.2015.03.079
   [Anonymous], NONLINEAR DYN
   Barakat ML, 2014, IET IMAGE PROCESS, V8, P33, DOI 10.1049/iet-ipr.2012.0586
   Behnia S, 2007, PHYS LETT A, V366, P391, DOI 10.1016/j.physleta.2007.01.081
   Belazi A, 2014, NONLINEAR DYNAM, V76, P1989, DOI 10.1007/s11071-014-1263-y
   Blakely G. R., 1979, Computers & Mathematics with Applications, V5, P169, DOI 10.1016/0898-1221(79)90039-7
   Boriga Radu Eugen, 2014, IAENG International Journal of Computer Science, V41, P249
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Cheng H., 2014, INTELLIGENT DATA ITS, V298, P301, DOI DOI 10.1007/978-3-319-07773-4_30
   Elhoseny HM, 2014, DIGIT IMAG PROCESS, V6, P118
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Fouda JSAE, 2014, COMMUN NONLINEAR SCI, V19, P578, DOI 10.1016/j.cnsns.2013.07.016
   Guesmi R, 2016, MULTIMED TOOLS APPL, V75, P4753, DOI 10.1007/s11042-015-2501-0
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Hussain I, 2014, J VIB CONTROL, V20, P2133, DOI 10.1177/1077546313482960
   Hussain I, 2013, NONLINEAR DYNAM, V72, P399, DOI 10.1007/s11071-012-0723-5
   Jain A, 2015, MULTIMED TOOLS APPL, V74, P1, DOI DOI 10.1007/s11042-013-1647-x
   Khan M, 2014, NONLINEAR DYNAM, V76, P377, DOI 10.1007/s11071-013-1132-0
   Lindholm E, 2008, IEEE MICRO, V28, P39, DOI 10.1109/MM.2008.31
   Liu HJ, 2015, OPT COMMUN, V338, P340, DOI 10.1016/j.optcom.2014.10.021
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Monaghan DS, 2007, APPL OPTICS, V46, P6641, DOI 10.1364/AO.46.006641
   *NVIDIA CUDA, 2007, COMP UN DEV ARCH PRO
   Owens JD, 2008, P IEEE, V96, P879, DOI 10.1109/JPROC.2008.917757
   Rivest R., 1992, Tech. Rep.
   Roohbakhsh D, 2015, INT J COMPUT APPL, V113
   TANG Z, 2011, ICIC EXPRESS LETT B, V2, P1297
   Tang ZJ, 2015, MULTIMED TOOLS APPL, V74, P5429, DOI 10.1007/s11042-014-1861-1
   Vahidi J, 2014, J MATH COMPUT SCI-JM, V9, P451
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2014, CHINESE PHYS B, V23, DOI 10.1088/1674-1056/23/3/030503
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wang XY, 2015, NONLINEAR DYNAM, V79, P1141, DOI 10.1007/s11071-014-1729-y
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2014, NONLINEAR DYNAM, V78, P2975, DOI 10.1007/s11071-014-1639-z
   Wang XY, 2014, NONLINEAR DYNAM, V75, P567, DOI 10.1007/s11071-013-1086-2
   Wang XY, 2012, OPT COMMUN, V285, P562, DOI 10.1016/j.optcom.2011.10.098
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
   Zhang YS, 2014, NONLINEAR DYNAM, V76, P1645, DOI 10.1007/s11071-014-1235-2
   Zhang YS, 2014, OPTIK, V125, P1562, DOI 10.1016/j.ijleo.2013.09.018
   Zhenjun Tang, 2011, Journal of Multimedia, V6, P202, DOI 10.4304/jmm.6.2.202-206
NR 42
TC 125
Z9 128
U1 2
U2 72
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6229
EP 6245
DI 10.1007/s11042-016-3311-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400008
DA 2024-07-18
ER

PT J
AU Chen, C
   Jafari, R
   Kehtarnavaz, N
AF Chen, Chen
   Jafari, Roozbeh
   Kehtarnavaz, Nasser
TI A survey of depth and inertial sensor fusion for human action
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Activity recognition; 3Daction data; Depth
   sensor; Inertial sensor; Sensor fusion; Multimodal dataset
ID FALL DETECTION; MAPS
AB A number of review or survey articles have previously appeared on human action recognition where either vision sensors or inertial sensors are used individually. Considering that each sensor modality has its own limitations, in a number of previously published papers, it has been shown that the fusion of vision and inertial sensor data improves the accuracy of recognition. This survey article provides an overview of the recent investigations where both vision and inertial sensors are used together and simultaneously to perform human action recognition more effectively. The thrust of this survey is on the utilization of depth cameras and inertial sensors as these two types of sensors are cost-effective, commercially available, and more significantly they both provide 3D human action data. An overview of the components necessary to achieve fusion of data from depth and inertial sensors is provided. In addition, a review of the publicly available datasets that include depth and inertial data which are simultaneously captured via depth and inertial sensors is presented.
C1 [Chen, Chen; Kehtarnavaz, Nasser] Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75080 USA.
   [Jafari, Roozbeh] Texas A&M Univ, Dept Biomed Engn, College Stn, TX 77843 USA.
   [Jafari, Roozbeh] Texas A&M Univ, Comp Sci & Engn Dept, College Stn, TX 77843 USA.
   [Jafari, Roozbeh] Texas A&M Univ, Elect & Comp Engn Dept, College Stn, TX 77843 USA.
C3 University of Texas System; University of Texas Dallas; Texas A&M
   University System; Texas A&M University College Station; Texas A&M
   University System; Texas A&M University College Station; Texas A&M
   University System; Texas A&M University College Station
RP Chen, C (corresponding author), Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75080 USA.
EM chenchen870713@gmail.com; rjafari@tamu.edu; kehtar@utdallas.edu
OI Jafari, Roozbeh/0000-0002-6358-0458
FU National Science Foundation [CNS-1150079]
FX This work was supported in part by the National Science Foundation,
   under grant CNS-1150079. Any opinions, findings, conclusions, or
   recommendations expressed in this material are those of the authors and
   do not necessarily reflect the views of the funding organizations.
CR Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Altun K, 2010, LECT NOTES COMPUT SC, V6219, P38, DOI 10.1007/978-3-642-14715-9_5
   [Anonymous], 2015, P IEEE INT C IM PROC
   [Anonymous], COMP VIS PATT REC WO
   [Anonymous], CIRC SYST C DCAS 201
   [Anonymous], 2008, P BMVC 2008 19 BRIT
   [Anonymous], IEEE SENSORS J
   [Anonymous], 1976, DEMPSTERS RULE COMBI, DOI DOI 10.2307/J.CTV10VM1QB.7
   [Anonymous], 2013, Consumer Depth Cameras for Computer Vision, DOI DOI 10.1007/978-1-4471-4640-710
   [Anonymous], J AMB INTEL SMART EN
   Argyriou V, 2010, COMPUT VIS IMAGE UND, V114, P887, DOI 10.1016/j.cviu.2010.05.002
   Avci A., 2010, 23 INT C ARCH COMP S, P1
   Bidmeshki MM, 2013, ACM IEEE INT CONF CY, P81, DOI 10.1109/ICCPS.2013.6604002
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bulling A, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2499621
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Cao C, 2015, MULTIMEDIA EXPO ICME, P1
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   Chen C, 2015, IEEE T HUM-MACH SYST, V45, P51, DOI 10.1109/THMS.2014.2362520
   Chen C, 2014, IEEE ENG MED BIO, P4135, DOI 10.1109/EMBC.2014.6944534
   Chen C, 2014, IEEE ENG MED BIO, P4983, DOI 10.1109/EMBC.2014.6944743
   Chen LM, 2012, IEEE T SYST MAN CY C, V42, P790, DOI 10.1109/TSMCC.2012.2198883
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Cheng CF, 2013, EVID-BASED COMPL ALT, V2013, DOI [10.1155/2013/613950, 10.1155/2013/958025]
   Cippitelli E, 2015, IEEE INT CONF COMM, P265, DOI 10.1109/ICCW.2015.7247189
   Delachaux B, 2013, LECT NOTES COMPUT SC, V7903, P216
   Destelle F, 2014, EUR SIGNAL PR CONF, P371
   Eddy SR, 2004, NAT BIOTECHNOL, V22, P1315, DOI 10.1038/nbt1004-1315
   Ermes M, 2008, IEEE T INF TECHNOL B, V12, P20, DOI 10.1109/TITB.2007.899496
   Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772
   Gasparrini S, 2016, ADV INTELL SYST, V399, P99, DOI 10.1007/978-3-319-25733-4_11
   Gasparrini S, 2014, SENSORS-BASEL, V14, P2756, DOI 10.3390/s140202756
   Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   Guan D, 2011, IETE TECH REV, V28, P418, DOI 10.4103/0256-4602.85975
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Helten T, 2013, IEEE I CONF COMP VIS, P1105, DOI 10.1109/ICCV.2013.141
   Jia XF, 2012, INT C PATT RECOG, P3001
   Jovanov Emil, 2005, J Neuroeng Rehabil, V2, P6, DOI 10.1186/1743-0003-2-6
   Kwolek B, 2015, NEUROCOMPUTING, V168, P637, DOI 10.1016/j.neucom.2015.05.061
   Kwolek B, 2014, COMPUT METH PROG BIO, V117, P489, DOI 10.1016/j.cmpb.2014.09.005
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Li Q, 2009, SIXTH INTERNATIONAL WORKSHOP ON WEARABLE AND IMPLANTABLE BODY SENSOR NETWORKS, PROCEEDINGS, P138, DOI [10.1109/P3644.45, 10.1109/BSN.2009.46]
   Liu CY, 2013, INT CONF MACH LEARN, P381, DOI 10.1109/ICMLC.2013.6890498
   Liu K, 2014, IEEE SENS J, V14, P1898, DOI 10.1109/JSEN.2014.2306094
   Mao Ye, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P149, DOI 10.1007/978-3-642-44964-2_8
   Mukherjee S, 2011, IEEE T CIRC SYST VID, V21, P1228, DOI 10.1109/TCSVT.2011.2135290
   Ofli F, 2013, IEEE WORK APP COMP, P53, DOI 10.1109/WACV.2013.6474999
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Ramanathan M, 2014, IEEE T HUM-MACH SYST, V44, P650, DOI 10.1109/THMS.2014.2325871
   Ruffieux S, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P483, DOI 10.1145/2522848.2532590
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shan JJ, 2014, 2014 IEEE WORKSHOP ON ADVANCED ROBOTICS AND ITS SOCIAL IMPACTS (ARSO), P69, DOI 10.1109/ARSO.2014.7020983
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Spriggs EH, 2009, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2009.5204354
   Stein S, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P729, DOI 10.1145/2493432.2493482
   Theodoridis T, 2008, IEEE INT CONF ROBOT, P3064, DOI 10.1109/ROBOT.2008.4543676
   Tian YS, 2015, NEUROCOMPUTING, V159, P207, DOI 10.1016/j.neucom.2015.01.071
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Vieira Antonio W., 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P252, DOI 10.1007/978-3-642-33275-3_31
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Wong C., 2012, Proceedings of the 2012 Ninth International Conference on Wearable and Implantable Body Sensor Networks (BSN 2012), P166, DOI 10.1109/BSN.2012.26
   Wu JX, 2014, J MACH LEARN RES, V15, P3013
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Xie SD, 2014, WIRELESS PERS COMMUN, V78, P231, DOI 10.1007/s11277-014-1748-5
   Yang Allen Y., 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563176
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Yin Y, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P489, DOI 10.1145/2522848.2532588
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
NR 77
TC 239
Z9 262
U1 3
U2 225
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4405
EP 4425
DI 10.1007/s11042-015-3177-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200059
DA 2024-07-18
ER

PT J
AU Fan, HY
   Ma, JS
   Fan, HH
   Lv, ZH
AF Fan, Huaiyu
   Ma, Junshan
   Fan, Huaihai
   Lv, Zhihan
TI Iterative quadtree decomposition based automatic selection of the seed
   point for ultrasound breast tumor images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Seed region growing; Iterative quadtree; Ultrasonic breast tumor;
   Anisotropic diffusion
ID SEGMENTATION; CLASSIFICATION; LEVEL
AB Based on seed region growing method, lesion segmentation for ultrasound breast tumor images often requires manual selection of the seed point, which is both time-consuming and laborious. To overcome this limit, this paper attempts to explore an automatic method for finding the seed point inside the tumor. Two criteria combining iterative quadtree decomposition (QTD) and the gray characteristics of the lesion are thus designed to locate the seed point. One is to seek the biggest homogenous region and the other is to select the seed region where the seed point is found. Furthermore, this study validates the proposed algorithm through 110 ultrasonic breast tumor images (including 58 malignant tumor images and 52 benign tumor images). According to the needs of the seed region growing algorithm, if the seed point is found inside the tumor, it means the proposed method is correct. Otherwise, it means that the method is a failure. As the quantitative experiment results show, the proposed method in this paper can automatically find the seed point inside the tumor with an accuracy rate of 97.27 %.
C1 [Fan, Huaiyu; Ma, Junshan] Univ Shanghai Sci & Technol, Shanghai Key Lab Modern Opt Syst, Shanghai 200093, Peoples R China.
   [Fan, Huaiyu] Jining Med Univ, Dept Med Informat Engn, Jining 272067, Shandong, Peoples R China.
   [Fan, Huaihai] Taian City Cent Hosp, Tai An 271000, Shandong, Peoples R China.
   [Lv, Zhihan] Chinese Acad Sci, SIAT, Shenzhen 518055, Peoples R China.
C3 University of Shanghai for Science & Technology; Jining Medical
   University; Chinese Academy of Sciences; Shenzhen Institute of Advanced
   Technology, CAS
RP Ma, JS (corresponding author), Univ Shanghai Sci & Technol, Shanghai Key Lab Modern Opt Syst, Shanghai 200093, Peoples R China.; Lv, ZH (corresponding author), Chinese Acad Sci, SIAT, Shenzhen 518055, Peoples R China.
EM hyfan2007@163.com; junshanma@163.com; hhfanicu2008@163.com;
   lvzhihan@gmail.com
RI Lyu, Zhihan/I-3187-2014; Lv, Zhihan/GLR-6000-2022
OI Lyu, Zhihan/0000-0003-2525-3074; Lv, Zhihan/0000-0003-2525-3074
FU National Basic Research Program of China [2011CB707504]; Colleges and
   universities domestic visiting scholar project of young backbone
   teachers in Shandong province; Youth fund projects of Jining Medical
   University
FX This work is supported in part by the National Basic Research Program of
   China (2011CB707504), Colleges and universities domestic visiting
   scholar project of young backbone teachers in Shandong province and
   Youth fund projects of Jining Medical University.
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   Chen DR, 2005, CLIN IMAG, V29, P235, DOI 10.1016/j.clinimag.2004.11.024
   Cheng HD, 2010, PATTERN RECOGN, V43, P299, DOI 10.1016/j.patcog.2009.05.012
   El-Harby AA, 2008, INT J GRAPHICS VIS I, V8, P41
   Felzenszwalb PF, 1998, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.1998.698594
   Gholinezhad S, 2015, FUEL, V139, P659, DOI 10.1016/j.fuel.2014.09.039
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Gu P, 2016, ULTRASONICS, V65, P51, DOI 10.1016/j.ultras.2015.10.023
   Guo YH, 2016, COMPUT METH PROG BIO, V123, P43, DOI 10.1016/j.cmpb.2015.09.007
   Hojjatoleslami SA, 1998, IEEE T IMAGE PROCESS, V7, P1079, DOI 10.1109/83.701170
   Huang QH, 2015, ULTRASOUND MED BIOL, V41, P1737
   Kaur M, 2011, INT J ADV COMPUT SC, V2, P137
   Liu B, 2009, ULTRASOUND MED BIOL, V35, P1309, DOI 10.1016/j.ultrasmedbio.2008.12.007
   Ma F, 2007, PATTERN RECOGN, V40, P2592, DOI 10.1016/j.patcog.2006.12.011
   Madabhushi A, 2003, IEEE T MED IMAGING, V22, P155, DOI 10.1109/TMI.2002.808364
   Noble JA, 2006, IEEE T MED IMAGING, V25, P987, DOI 10.1109/TMI.2006.877092
   PISANI P, 1993, INT J CANCER, V55, P891, DOI 10.1002/ijc.2910550604
   Poonguzhali S, 2006, 2006 INTERNATIONAL CONFERENCE ON BIOMEDICAL AND PHARMACEUTICAL ENGINEERING, VOLS 1 AND 2, P88
   Shan J., 2008, 2008 19 INT C PATT R, P1, DOI DOI 10.1109/ICPR.2008.4761336
   Shan J, 2012, ULTRASOUND MED BIOL, V38, P262, DOI 10.1016/j.ultrasmedbio.2011.10.022
   Yap MH, 2008, J APPL CLIN MED PHYS, V9, P181, DOI 10.1120/jacmp.v9i4.2741
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
   Zhai GT, 2009, J VIS COMMUN IMAGE R, V20, P595, DOI 10.1016/j.jvcir.2009.06.004
   ZHANG H, 2004, IEEE INT WORKSH BIOM
NR 24
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3505
EP 3517
DI 10.1007/s11042-016-3761-z
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200017
DA 2024-07-18
ER

PT J
AU Joo, HJ
   Cho, MT
   Jeong, HY
AF Joo, Hae-Jong
   Cho, Moon-Taek
   Jeong, Hwa-Young
TI RFID-based scale model freight car system allowing realtime quantity
   checking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Freight car; Logistics; RFID reader; Middleware; Video scale model
ID MEDIUM ACCESS-CONTROL; CONTROL PROTOCOLS
AB The barcode system currently used in the market has a weakness in that identification is only made when the barcode is visible. Unlike the barcode system, the RFID system uses radio frequency technology, allowing more accurate and faster identification of objects than the barcode system. RFID is a method to identify object data using radio frequency technology by attaching a tag to identification objects to be monitored. Active research has been conducted recently, and a lot of attempts have been made to introduce RFID technology in logistics and manufacturing sectors. This paper presents a method to check the accurate number of articles loaded in the freight car using RFID technology. The present research concerns the method in which the RFID reader and middleware is used to accurately and quickly count the number of RFID-tagged articles in real-time. When the tagged articles arrive at the reader area, the information read by the reader is delivered to the middleware. Then, the middleware identifies the number of tags, displaying the results to the user.
C1 [Joo, Hae-Jong] Dongguk Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Cho, Moon-Taek] Daewon Univ, Dept Elect & Elect Engn, Chungbuk, South Korea.
   [Jeong, Hwa-Young] Kyung Hee Univ, Dept Humanitas Coll, Seoul, South Korea.
C3 Dongguk University; Kyung Hee University
RP Jeong, HY (corresponding author), Kyung Hee Univ, Dept Humanitas Coll, Seoul, South Korea.
EM hjjoo@dongguk.edu; mtcho@mail.daewon.ac.kr; hyjeong@khu.ac.kr
OI Jeong, Hwa-Young/0000-0002-5017-934X
CR Abawajy J, 2015, COMPUT STAND INTER, V38, P64, DOI 10.1016/j.csi.2014.08.005
   Adhikari R, 2014, J NETW COMPUT APPL, V41, P488, DOI 10.1016/j.jnca.2014.01.011
   Bahri Shamshul, 2013, Library Hi Tech News, V30, P21, DOI 10.1108/LHTN-03-2013-0012
   Bo Y, 2013, APPL MECH MATER, V336-338, P2516, DOI 10.4028/www.scientific.net/AMM.336-338.2516
   Cheng H, 2012, 2012 6TH INTERNATIONAL CONFERENCE ON NEW TRENDS IN INFORMATION SCIENCE, SERVICE SCIENCE AND DATA MINING (ISSDM2012), P628
   Fafoutis X, 2015, COMPUT NETW, V76, P55, DOI 10.1016/j.comnet.2014.11.002
   Gnanaraj JWK, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-16
   Habiba U, 2014, J INF PROCESS SYST, V10, P119, DOI 10.3745/JIPS.2014.10.1.119
   Huang CF, 2013, PROC EUR CONF ANTENN, P2580
   Mejjaouli S, 2015, J MANUF SYST, V35, P234, DOI 10.1016/j.jmsy.2015.02.005
   Merja J, 2013, COMP INT COMM SYST N, P77
   Mitropoulou CC, 2015, ENG STRUCT, V88, P138, DOI 10.1016/j.engstruct.2015.01.029
   Najera P, 2011, J NETW COMPUT APPL, V34, P980, DOI 10.1016/j.jnca.2010.04.011
   Novak M, 2013, ICTIS, V2013, P1900
   Pérez-Sanagustín M, 2012, J NETW COMPUT APPL, V35, P176, DOI 10.1016/j.jnca.2011.02.011
   Reddy YT, 2013, INT J ENG TRENDS TEC, V4, P938
   Shao CX, 2014, COMPUT COMMUN, V39, P11, DOI 10.1016/j.comcom.2013.11.002
   Shiau YJ, 2013, ADV MATER RES-SWITZ, V779-780, P1715, DOI 10.4028/www.scientific.net/AMR.779-780.1715
   Snyder RM, 2013, 2013 ASCUE P, P90
   Su X. J., 2012, P INT C MEAS INSTR A, V241-244, P2023
   Vo CC, 2011, J NETW COMPUT APPL, V34, P990, DOI 10.1016/j.jnca.2010.04.013
   Vukovic M, 2013, INT J COMMUN NETW DI, V11, P11, DOI 10.1504/IJCNDS.2013.054832
   Yao ZM, 2013, ADV MATER RES-SWITZ, V774-776, P1653, DOI 10.4028/www.scientific.net/AMR.774-776.1653
NR 23
TC 1
Z9 1
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5985
EP 6002
DI 10.1007/s11042-015-2815-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500060
DA 2024-07-18
ER

PT J
AU Park, YS
   Park, KR
   Kim, JM
   Jeong, HY
AF Park, Young-Soo
   Park, Koo-Rack
   Kim, Jin-Mook
   Jeong, Hwa-Young
TI Fast Fourier transform benchmark on X86 Xeon system for multimedia data
   processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fourier transform; Signal processing; Image processing; FFTW3; INTEL
   IPP; Numutils; Kiss-fft
ID FACTOR FFT ALGORITHM; IMPLEMENTATION
AB I benchmarking the well-known Fast Fourier Transforms Library at X86 Xeon E5 2690 v3 system. Fourier transform image processing is an important tool that is used to decompose the image into sine and cosine components. If the input image represented by the equation in the spatial domain, output from the Fourier transform represents the image in the fourier or the frequency domain. Each point represents a particular frequency included in the spatial domain image in the Fourier domain image. Fourier transform is used widely for image analysis, image filtering, image compression and image reconstruction as a wide variety of applications. Fourier transform plays a important role in signal processing, image processing and speech recognition. It has been used in a wide range of sectors. For example, this is often a signal processing, is used in digital signal processing applications, such as voice recognition, image processing. The Discrete Fourier transform is a specific kind of Fourier transform. It maps the sequence over time to sequence over frequencies. If it implemented as a discrete Fourier transform, the time complexity is O (N2). It's actually not a better way to use. Alternatively, the Fast Fourier Transform is possible to easily perform a Discrete Fourier Transform of parallelism with only O (n log n) algorithm. Fast Fourier Transform is widely used in a variety of scientific computing program. If you are using the correct library can improve the performance of the program, without any additional effort. I have a well-known fast Fourier transform library was going to perform a benchmarking on X86 based Intel Xeon E5 2690 systems. In the machine's current Intel Xeon X86 Linux system. I have installed Intel IPP library, FFTW3 Library (West FFT), Kiss -FFT library and the numutils library on Intel X86 Xeon E5 based systems. The benchmark performed at C, and measuring the performance over a range of a transform size. It benchmarks both real and complex transforms in one dimension.
C1 [Park, Young-Soo; Park, Koo-Rack] Kongju Natl Univ, Coll Engn, Div Comp Sci & Engn, Cheonan Daero 1223-24, Cheonan sI 330717, Chungnam, South Korea.
   [Kim, Jin-Mook] Sunmoon Univ, Div IT Educ, 70 Sunmoon Ro 221Beon Gil, Asan, Chungnam, South Korea.
   [Jeong, Hwa-Young] Kyung Hee Univ, Humanitas Coll, 24 Kyungheedae Ro, Seoul 130701, South Korea.
C3 Kongju National University; Sun Moon University; Kyung Hee University
RP Kim, JM (corresponding author), Sunmoon Univ, Div IT Educ, 70 Sunmoon Ro 221Beon Gil, Asan, Chungnam, South Korea.
EM 0soo.pk@gmail.com; ecgrpark@kongju.ac.kr; calf0425@sunmoon.ac.kr;
   hyjeong@khu.ac.kr
OI Jeong, Hwa-Young/0000-0002-5017-934X
CR [Anonymous], 1981, P 13 ANN ACM S THEOR, DOI DOI 10.1145/800076.802486
   [Anonymous], 1992, COMPUTATIONAL FRAMEW
   Blumofe R. D., 1996, SPAA '96. 8th Annual ACM Symposium on Parallel Algorithms and Architectures, P297, DOI 10.1145/237502.237574
   BLUMOFE RD, 1995, SIGPLAN NOTICES, V30, P207
   Cooley J. W., 1967, FAST FOURIER TRANSFO
   COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354
   Cormen T.H., 1990, Introduction to Algorithms
   DUHAMEL P, 1990, SIGNAL PROCESS, V19, P259, DOI 10.1016/0165-1684(90)90158-U
   GOOD IJ, 1958, J ROY STAT SOC B, V20, P361
   JOHNSON HW, 1983, IEEE T ACOUST SPEECH, V31, P378, DOI 10.1109/TASSP.1983.1164071
   PEREZ F, 1987, IEEE T ACOUST SPEECH, V35, P1221, DOI 10.1109/TASSP.1987.1165265
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Selesnick IW, 1996, IEEE T SIGNAL PROCES, V44, P14, DOI 10.1109/78.482008
   SINGLETO.RC, 1969, IEEE T ACOUST SPEECH, VAU17, P93, DOI 10.1109/TAU.1969.1162042
   Swarztrauber P.N., 1982, Vectorizing the FFT s. in Parallel C om putations, P51
   TEMPERTON C, 1988, J COMPUT PHYS, V75, P190, DOI 10.1016/0021-9991(88)90106-4
   TEMPERTON C, 1985, J COMPUT PHYS, V58, P283, DOI 10.1016/0021-9991(85)90164-0
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 21
TC 4
Z9 4
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 6015
EP 6030
DI 10.1007/s11042-015-2843-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500062
DA 2024-07-18
ER

PT J
AU Rijnsburger, W
   Kratz, S
AF Rijnsburger, Wyko
   Kratz, Sven
TI Personalized presentation annotations using optical HMDs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Head-mounted device (HMD); Smart spaces; Presentations; Annotations
ID HEAD-WORN DISPLAYS
AB It is difficult to adjust the content of traditional slide presentations to the knowledge level, interest and role of individuals. This might force presenters to include content that is irrelevant for part of the audience, which negatively affects the knowledge transfer of the presentation. In this work, we present a prototype that is able to eliminate non- pertinent information from slides by presenting annotations for individual attendees on optical headmounted displays. We first create guidelines for creating optimal annotations for HMDs by evaluating several types of annotations alongside different types of slides. Then we evaluate the knowledge acquisition of presentation attendees using the prototype versus traditional presentations. Our results show that annotations with a limited amount of information, such as text up to 5 words, can significantly increase the amount of knowledge gained from attending a group presentation. Additionally, presentations where part of the information is moved to annotations are judged more positively on attributes such as clarity and enjoyment.
C1 [Kratz, Sven] FX Palo Alto Lab, 3174 Porter Dr, Palo Alto, CA 94304 USA.
   [Rijnsburger, Wyko] Univ Amsterdam, Kruislaan 403, NL-1012 WX Amsterdam, Netherlands.
C3 University of Amsterdam
RP Rijnsburger, W (corresponding author), Univ Amsterdam, Kruislaan 403, NL-1012 WX Amsterdam, Netherlands.
EM utwijko@gmail.com; kratz@fxpal.com
CR [Anonymous], 1998, MILSTD1472F US DEP D
   Bartsch RA, 2003, COMPUT EDUC, V41, P77, DOI 10.1016/S0360-1315(03)00027-7
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Cakmakci O, 2006, J DISP TECHNOL, V2, P199, DOI 10.1109/JDT.2006.879846
   Edge Darren, 2013, P SIGCHI C HUM FACT, P671, DOI DOI 10.1145/2470654.2470749
   handlebars.js, 2015, HANDL JS SEM WEB TEM
   Hong J, 2013, COMMUN ACM, V56, P10, DOI 10.1145/2524713.2524717
   Jiang X, 2009, INFORM SCIENCES, V179, P2794, DOI 10.1016/j.ins.2009.04.005
   KELLEY DH, 1988, COMMUN EDUC, V37, P198, DOI 10.1080/03634528809378719
   Kobsa A., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P136
   Lai YS, 2011, EDUC TECHNOL SOC, V14, P43
   Lichtschlag L., 2012, P SIGCHI C HUM FACT, P1307, DOI DOI 10.1145/2207676.2208586
   Mann S, 1997, COMPUTER, V30, P25, DOI 10.1109/2.566147
   Mann S., 2014, MIT TECHNOL REV, P18
   Mayer RE, 2003, EDUC PSYCHOL-US, V38, P43, DOI 10.1207/S15326985EP3801_6
   Mayer RE, 2001, J EDUC PSYCHOL, V93, P187, DOI 10.1037//0022-0663.93.1.187
   Microsoft, 2015, MICR HOL
   Microsoft, 2015, POW
   Norman G, 2010, ADV HEALTH SCI EDUC, V15, P625, DOI 10.1007/s10459-010-9222-y
   Pschetz L, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1591, DOI 10.1145/2556288.2557389
   Qvarfordt P, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P243
   Rolland J, 2009, OPT PHOTONICS NEWS, V20, P20, DOI 10.1364/OPN.20.4.000020
   Rolland Jannick., 2005, ENCY OPTICAL ENG, P1, DOI DOI 10.1081/E-EOE-120009801
   Rolland JP, 2000, PRESENCE-VIRTUAL AUG, V9, P287, DOI 10.1162/105474600566808
   Savoy A, 2009, COMPUT EDUC, V52, P858, DOI 10.1016/j.compedu.2008.12.005
   Schulze Markus, 2003, Voting Matters, V17, P9
   Tribe Te, 2015, EYE TRIB TRACK
   Trinh H, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1739, DOI 10.1145/2702123.2702584
   Tufte EdwardR., 2003, The cognitive style of PowerPoint, V2006
   Van Krevelen D. W. F., 2010, Int. J. Virtual Real., V9, P1, DOI [10.20870/IJVR.2010.9.2.2767, DOI 10.20870/IJVR.2010.9.2.2767]
   Wikitude, 2015, WIK AUGM REAL SDK
   Yates J., 2007, The cultural turn: Communicative practices in workplaces and the professions, P67
NR 32
TC 2
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5607
EP 5629
DI 10.1007/s11042-016-4064-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500041
DA 2024-07-18
ER

PT J
AU Xu, JJ
   Zhang, WM
   Jiang, RQ
   Yu, NG
AF Xu, Jiajia
   Zhang, Weiming
   Jiang, Ruiqi
   Yu, Nenghai
TI Unified entropy-based sorting for reversible data hiding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Entropy-based sorting; Gradient-based tracking
   and weighting
ID IMAGE WATERMARKING; ALGORITHM
AB Reversible data hiding schemes compete against each other for a sharply distributed prediction error histogram, usually realized by utilizing prediction strategies together with sorting technique that aims to estimate the local context complexity for each pixel to optimize the embedding order. Sorting techniques benefit prediction a lot by picking out pixels located in smooth areas. In this paper, a novel entropy-based sorting (EBS) scheme is proposed for reversible data hiding, which uses entropy measurement to characterize local context complexity for each image pixel. Futhermore, by extending the EBS technique to the two-dimensional case, it shows generalized abilities for multi-dimensinal RDH scenarios. Additionally, a new gradient-based tracking and weighting (GBTW) pixel prediction method is introduced to be combined with the EBS technique. Experimental results apparently indicate that our proposed method outperforms the previous state-of-arts counterparts significantly in terms of both the prediction accuracy and the overall embedding performance.
C1 [Xu, Jiajia; Zhang, Weiming; Jiang, Ruiqi; Yu, Nenghai] Univ Sci & Technol China, CAS Key Lab Electromagnet Space Informat, Hefei 230026, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Zhang, WM (corresponding author), Univ Sci & Technol China, CAS Key Lab Electromagnet Space Informat, Hefei 230026, Peoples R China.
EM xujiajia@mail.ustc.edu.cn; weimingzhang@yahoo.cn;
   jrq123@mail.ustc.edu.cn; ynh@ustc.edu.cn
RI xu, jiawen/KGK-4238-2024; Xu, Jiawen/JEF-5028-2023; xu,
   jia/GSD-6347-2022
FU Natural Science Foundation of China [61170234, 61572452]; Strategic
   Priority Research Program through the Chinese Academy of Sciences
   [XDA06030601]; Science and Technology on Information Assurance
   Laboratory [KJ-13-003]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant 61170234 and Grant 61572452, in part by the Strategic
   Priority Research Program through the Chinese Academy of Sciences under
   Grant XDA06030601, and in part by the Science and Technology on
   Information Assurance Laboratory under Grant KJ-13-003.
CR Afsharizadeh M., 2013, 10 INT C INF SEC CRY, P98
   [Anonymous], 2013, P 1 ACM WORKSH INF H
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   DOMINGUEZMOLINA JA, PRACTICAL PROCEDURE
   Dragoi I.-C., 2014, P 2 ACM WORKSH INF H, P35
   Dragoi IC, 2012, EUR SIGNAL PR CONF, P1688
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Fallahpour M, 2008, IEICE ELECTRON EXPR, V5, P870, DOI 10.1587/elex.5.870
   Giller G. L., 2005, A generalized error distribution, DOI [10.2139/ssrn.2265027, DOI 10.2139/SSRN.2265027]
   Hu XC, 2013, IEEE T INF FOREN SEC, V8, P779, DOI 10.1109/TIFS.2013.2256131
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin SJ, 2012, IEEE T INF FOREN SEC, V7, P1155, DOI 10.1109/TIFS.2012.2197614
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Nadarajah S, 2005, J APPL STAT, V32, P685, DOI 10.1080/02664760500079464
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Rad RM, 2013, MULTIMEDIA SYST, V19, P103, DOI 10.1007/s00530-012-0282-0
   Renyi A., 1961, P 4 BERK S MATH STAT, V1, P547
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Weiming Zhang, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P255, DOI 10.1007/978-3-642-24178-9_18
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
   Zhang WM, 2012, IEEE T IMAGE PROCESS, V21, P2991, DOI 10.1109/TIP.2012.2187667
NR 31
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3829
EP 3850
DI 10.1007/s11042-016-3989-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200032
DA 2024-07-18
ER

PT J
AU Agarwal, S
   Mukherjee, DP
AF Agarwal, Swapna
   Mukherjee, Dipti Prasad
TI Facial expression recognition through adaptive learning of local motion
   descriptor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Motion descriptor; Expression descriptor;
   Bag-of-words; Adaptive learning
AB A novel bag-of-words based approach is proposed for recognizing facial expressions corresponding to each of the six basic prototypic emotions from a video sequence. Each video sequence is represented as a specific combination of local (in spatio-temporal scale) motion patterns. These local motion patterns are captured in motion descriptors (MDs) which are unique combinations of optical flow and image gradient. These MDs can be compared to the words in the bag-of-words setting. Generally, the key-words in the wordbook as reported in the literature, are rigid, i.e., are taken as it is from the training data and cannot generalize well. We propose a novel adaptive learning technique for the key-words. The adapted key-MDs better represent the local motion patterns of the videos and generalize well to the unseen data and thus give better expression recognition accuracy. To test the efficiency of the proposed approach, we have experimented extensively on three well known datasets. We have also compared the results with existing state-of-the-art expression descriptors. Our method gives better accuracy. The proposed approach have been able to reduce the training time including the time for feature-extraction more than nine times and test time more than twice as compared to current state-of-the-art descriptor.
C1 [Agarwal, Swapna; Mukherjee, Dipti Prasad] Indian Stat Inst, Elect & Commun Sci Unit, 203 BT Rd, Kolkata 700108, India.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata
RP Agarwal, S (corresponding author), Indian Stat Inst, Elect & Commun Sci Unit, 203 BT Rd, Kolkata 700108, India.
EM agarwal.swapna@gmail.com; dipti@isical.ac.in
FU DST, Govt. of India [SR/WOS-A/ET-53/2012(G)]
FX This work was supported by DST, Govt. of India project no.
   SR/WOS-A/ET-53/2012(G).
CR Abboud B, 2003, CVPR WORKSH, V5, DOI [10.1109/CVPRW.2003.10056, DOI 10.1109/CVPRW.2003.10056]
   Agarwal S, 2012, P 8 INDIAN C COMP VI
   Aleksic PS, 2006, IEEE T INF FOREN SEC, V1, P3, DOI 10.1109/TIFS.2005.863510
   [Anonymous], 10 IEEE INT C WORKSH
   [Anonymous], 2003, P 2003 C COMP VIS PA, DOI DOI 10.1109/CVPRW.2003.10057
   [Anonymous], 2004, 2004 C COMP VIS PATT
   [Anonymous], 2004, IEEE COMP SOC C COMP
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], ICME
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], 1862, Mecanisme de la Physionomie Humaine, ou Analyse Electro-Physiologique de L'expression des Passions
   [Anonymous], INT WORKSH IM AN MUL
   Bejani M, 2014, NEURAL COMPUT APPL, V24, P399, DOI 10.1007/s00521-012-1228-3
   Bihan Jiang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P314, DOI 10.1109/FG.2011.5771416
   Boughrara H, 2014, MULTIMED TOOLS APPL, P1
   Buenaposada JM, 2008, PATTERN ANAL APPL, V11, P101, DOI 10.1007/s10044-007-0084-8
   Chakraborty D, 2008, IEEE T NEURAL NETWOR, V19, P381, DOI 10.1109/TNN.2007.910730
   Chew SW, 2011, LECT NOTES COMPUT SC, V7088, P311, DOI 10.1007/978-3-642-25346-1_28
   Dhall Abhinav, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P878, DOI 10.1109/FG.2011.5771366
   Ekman P, 1978, FACIAL ACTION CODING
   Ekman P., 1999, HDB COGNITION EMOTIO
   Girard JM, 2013, IEEE INT CONF AUTOMA
   Hoque M, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P697
   Hsieh CC, 2016, MULTIMED TOOLS APPL, V75, P6663, DOI 10.1007/s11042-015-2598-1
   Hsu FS, 2014, MULTIMED TOOLS APPL, V73, P309, DOI 10.1007/s11042-013-1616-4
   Jain S., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1642, DOI 10.1109/ICCVW.2011.6130446
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Kaur M., 2010, INT J COMPUT APPL, V9, P36, DOI DOI 10.5120/1434-1933
   Lajevardi SM, 2012, SIGNAL IMAGE VIDEO P, V6, P159, DOI 10.1007/s11760-010-0177-5
   Li YQ, 2013, IEEE T IMAGE PROCESS, V22, P2559, DOI 10.1109/TIP.2013.2253477
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Matsumoto D., 2011, FBI LAW ENFORCEMENT
   McDuff D, 2014, IMAGE VISION COMPUT, V32, P630, DOI 10.1016/j.imavis.2014.01.004
   Mukherjee S, 2011, IEEE T CIRC SYST VID, V21, P1228, DOI 10.1109/TCSVT.2011.2135290
   Narayan BL, 2006, PATTERN RECOGN LETT, V27, P187, DOI 10.1016/j.patrec.2005.08.015
   Ojala M, 2010, J MACH LEARN RES, V11, P1833
   Rudovic O, 2012, PROC CVPR IEEE, P2634, DOI 10.1109/CVPR.2012.6247983
   Sanchez A, 2011, NEUROCOMPUTING, V74, P1272, DOI 10.1016/j.neucom.2010.07.017
   Shan C., 2006, Proc. BMVC, V1, P297
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Sikka K., 2013, 2013 10 IEEE INT C W, P1, DOI DOI 10.1109/FG.2013.6553762
   Suk M, 2014, IEEE COMPUT SOC CONF, P132, DOI 10.1109/CVPRW.2014.25
   Tariq U, 2013, 2013 10 IEEE INT C W, P1, DOI [10.1109/FG.2013.6553794, DOI 10.1109/FG.2013.6553794]
   Tian Y, 2001, RECOGNISING ACTION U, V23, P2
   VALSTAR M., 2005, COMPUTER VISION PATT, P76, DOI DOI 10.1109/CVPR.2005.457
   Valstar M. F., 2010, LREC
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang J, 2007, COMPUT VIS IMAGE UND, V108, P19, DOI 10.1016/j.cviu.2006.10.011
   Wang ZH, 2013, PROC CVPR IEEE, P3422, DOI 10.1109/CVPR.2013.439
   Xiao R, 2011, PATTERN RECOGN, V44, P107, DOI 10.1016/j.patcog.2010.07.017
   Yeasin M, 2004, PROC CVPR IEEE, P922
   Zhang LG, 2011, IEEE T AFFECT COMPUT, V2, P219, DOI 10.1109/T-AFFC.2011.13
   Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990
   Zhao G., 2007, IEEE T PATTERN ANAL, V29
NR 55
TC 12
Z9 17
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1073
EP 1099
DI 10.1007/s11042-015-3103-6
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000047
DA 2024-07-18
ER

PT J
AU Yu, JL
   Sun, JF
AF Yu, Jialin
   Sun, Jifeng
TI 3D human pose regression via robust sparse tensor subspace learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human pose estimation; Tensor learning; Sparse representation; Support
   tensor regression; Sparse projection transformation; Feature extraction
ID REAL-TIME; PROJECTION; SELECTION; MOTION; MODELS
AB In this paper, we present a novel algorithm called robust sparse tensor subspace learning (RSTSL) for 3D human pose regression, and it further extends the latest presented tensor learning to a sparse case. A set of interrelated sparse discriminant projection matrices for feature extraction can be obtained by introducing k-mode optimization and elastic-net algorithm into the objective function of RSTSL and each non-zero element in each discriminant projection matrix is selected from the most typical variables. Thus, the most important low-dimensional tensor feature (LDTF) that corresponds to a test image (i.e., high-order tensor) is extracted through sparse projection transformation. Moreover, we present a novel regression model called optimal-order support tensor regression (OOSTR) to build a finest mapping function between LDTF and 3D human pose configuration. Extensive simulations are conducted on two human motion databases, HumanEva and Brown databases, experimental results show that our proposed RSTSL can not only weaken the sensitivity to incoherent human motions caused by transient occlusion of cameras, sudden change in human velocity and low-frame rate but also strengthen the robustness to silhouette ambiguity, obstacle occlusion and random noise. All the results have confirmed that our tracking system achieves the most significant performance against the compared the state-of-the-art approaches, especially in the complicated human motion databases with different clustered backgrounds, human movements, clothing-style, illumination and subjects like HumanEva database.
C1 [Yu, Jialin; Sun, Jifeng] South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Guangdong, Peoples R China.
C3 South China University of Technology
RP Yu, JL (corresponding author), South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Guangdong, Peoples R China.
EM yu.jialin@mail.scut.edu.cn; ecjfsun@scut.edu.cn
OI Yu, Jialin/0000-0001-8286-7203
FU National Natural Science Foundation of China [61202292]; Guangdong
   Province National Science Foundation of China [9151064101000037]
FX This work is supported by The National Natural Science Foundation of
   China (Grant: 61202292), Guangdong Province National Science Foundation
   of China (Grant: 9151064101000037). The authors thank L. Sigal, A. O.
   Balan and M. J. Black for providing publicly available databases (i.e.,
   Brown and HumanEva databases) for free. The authors would like to thank
   the anonymous reviewers for their valuable comments that improved our
   paper.
CR Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21
   Bo LF, 2010, INT J COMPUT VISION, V87, P28, DOI 10.1007/s11263-008-0204-y
   Chrétien S, 2014, IEEE T INFORM THEORY, V60, P3970, DOI 10.1109/TIT.2014.2301162
   Deutscher J, 2005, INT J COMPUT VISION, V61, P185, DOI 10.1023/B:VISI.0000043757.18370.9c
   Frey B., 2007, MULTI DATABASE RETRI, Vvol. 315, ppp, DOI [DOI 10.1126/SCIENCE.1136800, 10.1126/science.1136800]
   He X., 2005, Advances in neural information processing systems, P499
   Horn R. A., 2012, MATRIX ANAL
   Hund M, 2015, LECT NOTES ARTIF INT, V9250, P358, DOI 10.1007/978-3-319-23344-4_35
   Ionescu C, 2014, PROC CVPR IEEE, P1661, DOI 10.1109/CVPR.2014.215
   Irene K, 2012, PATTERN RECOGN, V45, P4192
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Lai ZH, 2014, IEEE T CIRC SYST VID, V24, P1651, DOI 10.1109/TCSVT.2014.2305495
   Lai ZH, 2014, IEEE T NEUR NET LEAR, V25, P1779, DOI 10.1109/TNNLS.2013.2295717
   Lai ZH, 2013, IEEE T IMAGE PROCESS, V22, P3904, DOI 10.1109/TIP.2013.2264678
   Lee SC, 2014, MACH VISION APPL, V25, P133, DOI 10.1007/s00138-013-0516-y
   Lepetit V, 2005, PROC CVPR IEEE, P775
   Li Q, 2015, J FIBER BIOENG INF, V8, P117
   Li Y, 2014, MULTIMED TOOLS APPL, V69, P79, DOI 10.1007/s11042-012-1251-5
   [李毅 Li Yi], 2012, [自动化学报, Acta Automatica Sinica], V38, P732
   Lin WY, 2014, IEEE T CIRC SYST VID, V24, P826, DOI 10.1109/TCSVT.2013.2280849
   Ma L, 2015, IEEE T GEOSCI REMOTE, V53, P2832, DOI 10.1109/TGRS.2014.2365676
   Panagakis Y, 2010, IEEE T AUDIO SPEECH, V18, P576, DOI 10.1109/TASL.2009.2036813
   Qin ZW, 2013, MATH PROGRAM COMPUT, V5, P143, DOI 10.1007/s12532-013-0051-x
   Raskin L, 2011, COMPUT VIS IMAGE UND, V115, P503, DOI 10.1016/j.cviu.2010.12.002
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Rosales R, 2006, INT J COMPUT VISION, V67, P251, DOI 10.1007/s11263-006-5165-4
   Sigal L, 2004, PROC CVPR IEEE, P421
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Steve RG, 1997, SUPPORT VECTOR MACHI
   Tan X, 2015, IEEE T MULTIMEDIA, V17, P660, DOI 10.1109/TMM.2015.2410135
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Vapnik VN, 1995, NATURE STAT LEARNING, P219
   Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167
   Wu X, 2010, IET IMAGE PROCESS, V4, P486, DOI 10.1049/iet-ipr.2009.0278
   Yang SY, 2014, IEEE T GEOSCI REMOTE, V52, P3587, DOI 10.1109/TGRS.2013.2273798
   Yao A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.67
   Zhang Z, 2015, IEEE T COMPUT AID D, V34, P63, DOI 10.1109/TCAD.2014.2369505
   Zhao X, 2010, IEEE T CIRC SYST VID, V20, P957, DOI 10.1109/TCSVT.2010.2045916
   Zolfaghari M, 2014, MACH VISION APPL, V25, P1489, DOI 10.1007/s00138-014-0613-6
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
   Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430
NR 41
TC 5
Z9 5
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2399
EP 2439
DI 10.1007/s11042-015-3186-0
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000036
DA 2024-07-18
ER

PT J
AU Karayer, E
   Sayit, M
AF Karayer, Erdem
   Sayit, Muge
TI A path selection approach with genetic algorithm for P2P video streaming
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alternative path selection; Hybrid push-pull; Disjoint paths; Proactive
   method
ID PEER-TO-PEER; MULTICAST; DIVERSITY
AB In peer-to-peer (P2P) video streaming applications, the Quality of Experience (QoE) obtained by peers may vary according to the level of network congestion on the path between the peer and its parents. In this paper, we have proposed a parent selection approach for hybrid push-pull based video streaming systems, taking physical paths into account. In this approach, we proactively measured the disjunction of paths between peers and partners and chose the set of parents among partners having maximum disjoint paths by using a genetic algorithm at the beginning of the streaming session. The peers continue the paths of parent set to keep disjoint during streaming. The proposed system was tested on NS3 and the obtained results show that the proposed approach provides an increase up to 10 % in continuity index compared to hybrid push-pull based system which does not consider underlying network infrastructure. Furthermore, higher performance in terms of other parameters related to QoE such as Peak Signal to Noise Ratio (PSNR), reset count, and network related parameters such as video propagation success among peers and re-selection rates of new parents is observed with the proposed approach.
C1 [Karayer, Erdem; Sayit, Muge] Ege Univ, Int Comp Inst, TR-35100 Izmir, Turkey.
C3 Ege University
RP Sayit, M (corresponding author), Ege Univ, Int Comp Inst, TR-35100 Izmir, Turkey.
EM muge.fesci@ege.edu.tr
OI Sayit, Muge/0000-0002-7990-1463
FU the Scientific and Technological Research Council of Turkey (TUBITAK)
   Electric, Electronic and Informatics Research Group (EEEAG) [111E022]
FX This work is funded by the Scientific and Technological Research Council
   of Turkey (TUBITAK) Electric, Electronic and Informatics Research Group
   (EEEAG) under grant 111E022. We would like to thank to project members
   for them helping the implementation of the Coolstreaming-like framework.
CR Andersen D., 2001, Operating Systems Review, V35, P131, DOI 10.1145/502059.502048
   [Anonymous], 2000, 2914 RFC
   Apostolopoulos JG, 2004, IEEE COMMUN MAG, V42, P80, DOI 10.1109/MCOM.2004.1321395
   Baccaglini E, 2012, SIGNAL PROCESS-IMAGE, V27, P430, DOI 10.1016/j.image.2012.02.006
   Banerjee S, 2002, ACM SIGCOMM COMP COM, V32, P205, DOI 10.1145/964725.633045
   Banerjee S, 2006, IEEE ACM T NETWORK, V14, P237, DOI 10.1109/TNET.2006.872579
   Belmonte MV, 2013, J NETW COMPUT APPL, V36, P484, DOI 10.1016/j.jnca.2012.04.010
   CASTRO M, 2003, P SOSP
   Chu YH, 2002, IEEE J SEL AREA COMM, V20, P1456, DOI 10.1109/JSAC.2002.803066
   Fei T., 2006, P IEEE INFOCOM, P1, DOI [DOI 10.1109/INFOCOM.2006.48, DOI 10.1109/INFOCOM.2006.179]
   Fesci-Sayit M, 2012, SIGNAL PROCESS-IMAGE, V27, P113, DOI 10.1016/j.image.2011.11.004
   Frossard P, 2008, P IEEE, V96, P39, DOI 10.1109/JPROC.2007.909876
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   Habib A, 2006, IEEE T MULTIMEDIA, V8, P610, DOI 10.1109/TMM.2006.870724
   Hei X., 2007, IEEE T MULTIMEDIA, V9, P1
   Jeonghun Noh, 2012, Journal of Communications, V7, P202, DOI 10.4304/jcm.7.3.202-212
   Kaymak Y, 2013, P 21 IEEE SIGN PROC, P1
   Li B, 2008, IEEE INFOCOM SER, P1705
   Lin YY, 2010, IEEE T CIRC SYST VID, V20, P1018, DOI 10.1109/TCSVT.2010.2051280
   Liu JC, 2008, P IEEE, V96, P11, DOI 10.1109/JPROC.2007.909921
   Payberah AH, 2012, IEEE INT CONF PEER, P79
   Rubenstein D, 2002, IEEE ACM T NETWORK, V10, P381, DOI 10.1109/TNET.2002.1012369
   Rüngeler I, 2009, LECT NOTES COMPUT SC, V5550, P468, DOI 10.1007/978-3-642-01399-7_37
   SRINIVAS M, 1994, COMPUTER, V27, P17, DOI 10.1109/2.294849
   Sung-Ju L, 2008, P IEEE 27 C COMP COM
   TANG C, 2004, DISTRIBUTED MULTIPAT
   Tao S, 2004, 12TH IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS - PROCEEDINGS, P304, DOI 10.1109/ICNP.2004.1348120
   Teket K.D., 2013, PROC IEEE INT SYMP B, P1
   Wang F, 2008, IEEE INFOCOM SER, P2038
   Wang F, 2012, IEEE INFOCOM SER, P199, DOI 10.1109/INFCOM.2012.6195578
   Wang F, 2010, IEEE T PARALL DISTR, V21, P379, DOI 10.1109/TPDS.2009.77
   Wang WY, 2011, MULTIMED TOOLS APPL, V54, P445, DOI 10.1007/s11042-010-0547-6
   Xie S, 2007, IEEE T MULTIMEDIA, V9, P1661, DOI 10.1109/TMM.2007.907469
   Xu Y, SIGNAL PROCESS IMAGE, V27, P412
   Yin H, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823750
   Zeng WJ, 2009, IEEE T MULTIMEDIA, V11, P960, DOI 10.1109/TMM.2009.2021712
   Zhang JJ, 2008, J NETW COMPUT APPL, V31, P821, DOI 10.1016/j.jnca.2007.05.001
   Zhang M., 2004, P USENIX ANN TECHN C, DOI 10.1.1.111.3109
   Zhang XY, 2005, IEEE INFOCOM SER, P2102
   Zhao BY, P 11 IEEE INT C NETW, P246
NR 40
TC 4
Z9 4
U1 10
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16039
EP 16057
DI 10.1007/s11042-015-2912-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700052
DA 2024-07-18
ER

PT J
AU Lee, ML
   Ting, PY
   Wu, TS
AF Lee, Ming-Lun
   Ting, Pei-Yih
   Wu, Tzong-Sun
TI Photograph watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information hiding; Photograph watermarking; Discrete cosine transform;
   Print-and-photo process
ID PRINT-SCAN; CAMERA CALIBRATION; ROBUST
AB The protection of information is a very important issue in the digital world where the data can be easily copied, altered and transmitted. One of the well known ways to protect the multimedia is digital watermarking. For a common watermarking system, the test image is processed in digital form. Many researchers have devoted themselves to the studies of extracting watermarks from printed images by scanning. These schemes can resist the print-and-scan process. However, these schemes have some restrictions and weakness when they are applied to the situations of image authentication when images are not easy to be scanned. In this paper, we defined a new image processing manipulation named the print-and-photo (PP) process and proposed a photograph watermarking scheme that can resist it. It is useful especially in some cases when the scanner is not applicable, e.g., a picture on some moving bus. These captured images might be rotated, scaled or chroma distorted after the PP process, and even have perspective and barrel distortions. In our proposed photograph watermarking system, the watermark embedding and extraction procedures are to modify and compare the magnitude order of mean-DCT values in RGB color model. The watermark can be solely extracted from the stego image without the original cover image or any extra information. Further, the QR code is used as the error correction code for strengthening the robustness. Experiment results show that the stego images survive the PP process and the proposed scheme outperforms the related ones.
C1 [Lee, Ming-Lun; Ting, Pei-Yih; Wu, Tzong-Sun] Natl Taiwan Ocean Univ, Dept Comp Sci & Engn, Keelung 202, Taiwan.
C3 National Taiwan Ocean University
RP Wu, TS (corresponding author), Natl Taiwan Ocean Univ, Dept Comp Sci & Engn, Keelung 202, Taiwan.
EM mlli0401@gmail.com; pyt000123@gmail.com; ibox456@gmail.com
RI Ting, Pei-Yih/R-3303-2016
OI Ting, Pei-Yih/0000-0001-6727-5429
FU National Science Council of Republic of China [NSC 100-2221-E-019-046]
FX The authors would like to thank the anonymous referees for their
   invaluable comments. This work was supported in part by the National
   Science Council of Republic of China under the contract number NSC
   100-2221-E-019-046.
CR Battikh T, 2011, MULTIMED TOOLS APPL, V51, P997, DOI 10.1007/s11042-009-0434-1
   Bin He, 2009, 2009 WRI World Congress on Computer Science and Information Engineering, CSIE, P290, DOI 10.1109/CSIE.2009.830
   Chen TS, 1998, IEEE T IMAGE PROCESS, V7, P1485, DOI 10.1109/83.718488
   Cheng DF, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P894, DOI 10.1109/ISECS.2008.68
   Chiu YC, 2006, J INF SCI ENG, V22, P483
   Deng C, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P6, DOI 10.1109/CW.2008.50
   Guo CQ, 2010, 2010 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, NETWORKING AND INFORMATION SECURITY (WCNIS), VOL 1, P518, DOI 10.1109/WCINS.2010.5541833
   Harris C., 1988, ALVEY VISION C, P147151
   Harris T, 2014, LASER PRINTERS WORK
   Kim HY, 2007, SIBGRAPI, P105, DOI 10.1109/SIBGRAPI.2007.31
   Kutter M., 1998, Proceedings of SPIE, V3628, P423
   Li Jing, 2012, Journal of Multimedia, V7, P231, DOI 10.4304/jmm.7.3.231-238
   Lin C., 1999, INT S MULT INF PROC
   MCGILL R, 1978, AM STAT, V32, P12, DOI 10.2307/2683468
   Pourreza R, 2008, INT C INTELL COMP CO, P123, DOI 10.1109/ICCP.2008.4648363
   Pun CM, 2014, MULTIMED TOOLS APPL, DOI [10.1007/s11042-041-2025-z, DOI 10.1007/S11042-041-2025-Z]
   Shi DC, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 5, PROCEEDINGS, P697, DOI 10.1109/CISP.2008.662
   Shim JY, 2014, MULTIMED TOOLS APPL, V70, P1941, DOI 10.1007/s11042-012-1222-x
   Solanki K, 2005, PROC SPIE, V5681, P418, DOI 10.1117/12.588002
   Solanki K, 2006, IEEE T INF FOREN SEC, V1, P464, DOI 10.1109/TIFS.2006.885032
   Suran Kong, 2013, Journal of Multimedia, V8, P662, DOI 10.4304/jmm.8.6.662-668
   Tam A, 2003, CISST'03: PROCEEDING OF THE INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS AND TECHNOLOGY, VOLS 1 AND 2, P708
   Tan LN, 2012, RADIOENGINEERING, V21, P170
   Tirkel A. Z., 1993, Conference Proceedings DICTA-93 Digital Image Computing: Techniques and Applications, P666
   Varna AL, 2009, IEEE INT C AC SPEECH, P1937
   Wang DD, 2016, MULTIMED TOOLS APPL, V75, P3177, DOI 10.1007/s11042-014-2429-9
   Wang XY, 2010, COMPUT ELECTR ENG, V36, P31, DOI 10.1016/j.compeleceng.2009.04.005
   Yuan-Liang Tang, 2012, 2012 International Symposium on Biometrics and Security Technologies (ISBAST 2012), P113, DOI 10.1109/ISBAST.2012.31
   Yuan-Liang Tang, 2012, 2012 Computing, Communications and Applications Conference (ComComAp 2012), P411, DOI 10.1109/ComComAp.2012.6154883
   Yuan-Liang Tang, 2010, Proceedings 2010 First International Conference on Pervasive Computing, Signal Processing and Applications (PCSPA 2010), P357, DOI 10.1109/PCSPA.2010.93
   Zhang B, 2010, IEEE AUTOTESTCON, P130, DOI 10.1109/ICITIS.2010.5688742
   Zhang Y, 2008, LNCS, V5450, P103
NR 32
TC 3
Z9 3
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16173
EP 16189
DI 10.1007/s11042-015-2925-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700059
DA 2024-07-18
ER

PT J
AU Li, X
   Hijazi, I
   Xu, MC
   Lv, HB
   El Meouche, R
AF Li, Xin
   Hijazi, Ihab
   Xu, Mengchao
   Lv, Haibin
   El Meouche, Rani
TI Implementing two methods in GIS software for indoor routing: an
   empirical study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE TIN; Indoor navigation; Architectural drawings; Grid; Shortest route
ID MODEL
AB With increasing demands for indoor GIS, indoor routing and analysis attracts attention from both GIS and architecture worlds. This paper aimes to provide executable methods in GIS softwares eg ArcGIS for indoor path generation and to explore the possibilities for further analysis. In this paper, two methods are proposed and impletmented: Mesh and TIN. The Mesh method used a standard-sized grid graph as the referencing network for a floor and subsequently mapping the movement on a 2D plane to the movement along grid edges. On the other hand, TIN method utilized the TIN as the base, it generates a usable path network by appling two customized TIN. Considering the outputs, the result shows a value for both appling the methods in real use and research analysis of network in indoor environement. TIN provide a network suitable for indoor navigation but need less storage space compared to the Mesh method which provide more accurate network but required extra storage spaces.
C1 [Li, Xin] Wuhan Univ, Sch Urban Design, Wuhan, Peoples R China.
   [Hijazi, Ihab] An Najah Natl Univ, Urban Planning Engn Dept, Nablus, Palestine.
   [Xu, Mengchao] George Mason Univ, Dept Geog & Geoinformat Sci, Fairfax, VA 22030 USA.
   [Lv, Haibin] State Ocean Adm, Qingdao Huanhai Marine Engn Prospecting Inst, Qingdao, Peoples R China.
   [El Meouche, Rani] Univ Paris Est, ESTP, Inst Rech Constructibil, F-94230 Cachan, France.
C3 Wuhan University; An Najah National University; George Mason University
RP Hijazi, I (corresponding author), An Najah Natl Univ, Urban Planning Engn Dept, Nablus, Palestine.
EM li-xin@whu.edu.cn; eehab@najah.edu; mxu6@masonlive.gmu.edu;
   bhfjlhb@sina.com; relmeouche@estp-paris.eu
RI Lv, Haibin/AAX-7696-2020; hijazi, ihab/AAH-5439-2019
OI Lv, Haibin/0000-0003-1059-4765; EL MEOUCHE, Rani/0000-0001-5063-6638;
   Hijazi, Ihab/0000-0001-7152-8935
FU National Natural Science Foundation of China [51408442]
FX The authors gratefully acknowledge financial support from the National
   Natural Science Foundation of China (No. 51408442). They sincerely
   appreciate anonymous reviewers for their constructive comments and
   suggestions.
CR Afyouni I, 2012, J SPAT INF SCI, P85, DOI 10.5311/JOSIS.2012.4.73
   Chew PL, 1987, P 3 ANN S COMP GEOM
   Choi JW, 2007, AUTOMAT CONSTR, V16, P449, DOI 10.1016/j.autcon.2006.08.003
   Dudas PM, 2009, 10 INT C MOB DAT MAN, DOI [10.1109/MDM.2009.123, DOI 10.1109/MDM.2009.123]
   El-Mekawy M., 2010, Integrating BIM and GIS for 3D City Modelling - The Case of IFC and CityGML
   Franz G, 2005, GRAPH BASED MODELS S, P1
   Gröcer G, 2010, PHOTOGRAMM FERNERKUN, P195, DOI 10.1127/1432-8364/2010/0049
   Gu W, 2017, MULTIMED TOOLS APPL, V76, P17719, DOI 10.1007/s11042-015-2960-3
   Irizarry J, 2012, J INF TECHNOL CONSTR, V17, P351
   Jiang DD, 2016, WIRELESS PERS COMMUN, V86, P901, DOI 10.1007/s11277-015-2961-6
   Jiang DD, 2014, J NETW COMPUT APPL, V40, P292, DOI 10.1016/j.jnca.2013.09.014
   Jiang DD, 2011, COMPUT NETW, V55, P3533, DOI 10.1016/j.comnet.2011.06.027
   Jiang DD, 2009, IEEE COMMUN LETT, V13, P52, DOI 10.1109/LCOMM.2008.081271
   Lamarche F, 2004, CROWD VIRTUAL HUMANS, DOI [10.1111/j.1467-8659.2004.00782.x, DOI 10.1111/J.1467-8659.2004.00782.X]
   Lee J, 2004, GEOINFORMATICA, V8, P237, DOI 10.1023/B:GEIN.0000034820.93914.d0
   Lertlakkhanakul Jumphon, 2009, Proceedings of the 2009 Fifth International Joint Conference on INC, IMS and IDC, P382, DOI 10.1109/NCM.2009.179
   Li X, 2015, IEEE INT S CLUST CLO
   Lin YC, 2015, SENSORS-BASEL, V15, P20925, DOI 10.3390/s150820925
   Liu L, 2011, 3D INDOOR DOOR TO DO
   Lv Z, 2015, 36 ANN C EUR ASS COM
   Lv Z, 2015, IEEE COMPUT VIRTUAL
   Lv ZH, 2015, PERS UBIQUIT COMPUT, V19, P551, DOI 10.1007/s00779-015-0844-1
   Meijers M, 2005, P NEXT GEN 3D CIT MO, P21
   Rich S., 2010, Geographic information systems (GIS) for facility management
   Ruppel U, 2010, BIM BASED IMMERSIVE
   Stoffel E.P., 2008, Proceedings of the 16th ACM SIGSPATIAL international conference on Advances in geographic information systems-GIS '08, P1
   Stoffel EP, 2007, LECT NOTES COMPUT SC, V4802, P328
   Su TY, 2016, COMPUT GRAPH-UK, V54, P65, DOI 10.1016/j.cag.2015.07.019
   Tsetsos V, 2005, INTERNATIONAL CONFERENCE ON PERVASIVE SERVICES 2005, PROCEEDINGS, P146, DOI 10.1109/PERSER.2005.1506403
   Voronoï G, 1908, J REINE ANGEW MATH, V133, P97, DOI 10.1515/crll.1908.133.97
   Xu W, 2013, INT ARCH PHOTOGRAMM, V40-4-W4, P51, DOI 10.5194/isprsarchives-XL-4-W4-51-2013
   Yang JC, 2015, SENSORS-BASEL, V15, P19618, DOI 10.3390/s150819618
   Yang LP, 2015, INT J GEOGR INF SCI, V29, P1737, DOI 10.1080/13658816.2015.1041141
   Zhong C, 2012, COMM COM INF SC, V242, P299
   Zhong C, 2014, INT J GEOGR INF SCI, V28, P2178, DOI 10.1080/13658816.2014.914521
NR 35
TC 7
Z9 7
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17449
EP 17464
DI 10.1007/s11042-015-3156-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600032
DA 2024-07-18
ER

PT J
AU Tralic, D
   Grgic, S
   Sun, XF
   Rosin, PL
AF Tralic, Dijana
   Grgic, Sonja
   Sun, Xianfang
   Rosin, Paul L.
TI Combining cellular automata and local binary patterns for copy-move
   forgery detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move forgery; Duplicated regions; Cellular automata; Local binary
   pattern
AB Detection of duplicated regions in digital images has been a highly investigated field in recent years since the editing of digital images has been notably simplified by the development of advanced image processing tools. In this paper, we present a new method that combines Cellular Automata (CA) and Local Binary Patterns (LBP) to extract feature vectors for the purpose of detection of duplicated regions. The combination of CA and LBP allows a simple and reduced description of texture in the form of CA rules that represents local changes in pixel luminance values. The importance of CA lies in the fact that a very simple set of rules can be used to describe complex textures, while LBP, applied locally, allows efficient binary representation. CA rules are formed on a circular neighborhood, resulting in insensitivity to rotation of duplicated regions. Additionally, a new search method is applied to select the nearest neighbors and determine duplicated blocks. In comparison with similar methods, the proposed method showed good performance in the case of plain/multiple copy-move forgeries and rotation/scaling of duplicated regions, as well as robustness to post-processing methods such as blurring, addition of noise and JPEG compression. An important advantage of the proposed method is its low computational complexity and simplicity of its feature vector representation.
C1 [Tralic, Dijana; Grgic, Sonja] Univ Zagreb, Fac Elect Engn & Comp, Unska 3-12, HR-10000 Zagreb, Croatia.
   [Sun, Xianfang; Rosin, Paul L.] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF24 3AA, S Glam, Wales.
C3 University of Zagreb; Cardiff University
RP Tralic, D (corresponding author), Univ Zagreb, Fac Elect Engn & Comp, Unska 3-12, HR-10000 Zagreb, Croatia.
EM dijana.tralic@fer.hr
RI Vitas, Dijana/AAJ-7037-2021; Sun, Xianfang/ABG-8970-2021; Sun,
   Xianfang/D-2346-2010
OI Rosin, Paul/0000-0002-4965-3884; Grgic, Sonja/0000-0002-0802-3288; Sun,
   Xianfang/0000-0002-6114-0766
CR Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Bashar M, 2010, IEEE T IMAG IN RPESS
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Bhatnagar G, 2011, MULTIMED TOOLS APPL, V66, P179
   Bravo-Solorio S, 2011, INT CONF ACOUST SPEE, P1880
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Davarzani R, 2013, FORENSIC SCI INT, V231, P61, DOI 10.1016/j.forsciint.2013.04.023
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Hou XD, 2014, MULTIMED TOOLS APPL, V72, P1681, DOI 10.1007/s11042-013-1466-0
   Hwei-Jen Lin, 2009, WSEAS Transactions on Signal Processing, V5, P188
   Li L., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P46
   Luo WQ, 2006, INT C PATT RECOG, P746
   Muja M., 2012, 2012 Canadian Conference on Computer and Robot Vision, P404, DOI 10.1109/CRV.2012.60
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Popescu A.C., 2004, Comput. Sci. Tech. Rep, P1
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Rosin PL, 2006, IEEE T IMAGE PROCESS, V15, P2076, DOI 10.1109/TIP.2006.877040
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Sun XF, 2011, IEEE T SYST MAN CY B, V41, P749, DOI 10.1109/TSMCB.2010.2091271
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Tralic D., 2014, CELLULAR AUTOMATA IM, P105, DOI [10.1007/978-3-319-06431-4_6, DOI 10.1007/978-3-319-06431-4_6]
   Tralic D, 2014, INT CONF SYST SIGNAL, P167
   Wang Jun-Wen, 2009, Acta Automatica Sinica, V35, P1488, DOI 10.3724/SP.J.1004.2009.01488
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
NR 26
TC 17
Z9 17
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 16881
EP 16903
DI 10.1007/s11042-015-2961-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600008
DA 2024-07-18
ER

PT J
AU Vennila, G
   Manikandan, MSK
   Aswathi, S
AF Vennila, G.
   Manikandan, M. S. K.
   Aswathi, S.
TI A novel PQPR algorithm for SIP signaling race detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SIP; VoIP; Race condition; Packet reordering
ID SCHEMES
AB Session Initiation Protocol (SIP) is a significant protocol in Voice over Internet Protocol (VoIP) network to create, manage, control and tear down the sessions. During multimedia conversation, overlapping of signaling message occurs that is referred as SIP race condition which directly affects voice call quality. The existing solution is adjusting session timer would minimize race conditions, but media conversation phase is not constant over the time period, thereby not being a feasible solution for such conditions. In this paper, we propose a novel Priority Queue based Packet Rotating (PQPR) algorithm and design a handler to detect and minimize the signaling race packet before serving to the server thereby improving the voice call quality. This paper presents SIP signaling race condition and analyzed using an experimental test bed. The results of the experiment show that PQPR algorithm achieves better throughput with less than 3 % of false positive with minimal packet dropping.
C1 [Vennila, G.; Manikandan, M. S. K.; Aswathi, S.] Thiagarajar Coll Engn, Dept Elect & Commun Engn, Madurai, Tamil Nadu, India.
C3 Thiagarajar College of Engineering
RP Vennila, G (corresponding author), Thiagarajar Coll Engn, Dept Elect & Commun Engn, Madurai, Tamil Nadu, India.
EM vennilatg@tce.edu; manimsk@tce.edu; aswathis@tce.edu
RI MSK, Manikandan/AAP-9121-2020
CR [Anonymous], RFC3261 IETF
   Blanton E, 2002, ACM SIGCOMM COMP COM, V32, P20, DOI 10.1145/510726.510728
   Camarillo G, 2011, 6141 RFC IETF
   Cheung E, 2008, LECT NOTES COMPUT SC, V5310, P45
   Demestichas PP, 2004, IEEE T SYST MAN CY C, V34, P69, DOI 10.1109/TSMCC.2003.818500
   Haiyang Y, 2014, Patent no, Patent No. [2-EP 2383952 B1, 2383952]
   Haiyang Y, 2014, Patent No. [1-US 20110264746 A1, 20110264746]
   Hasebe M, 2008, 5407 RFC IETF
   Ho CY, 2008, COMPUT NETW, V52, P1308, DOI 10.1016/j.comnet.2007.12.012
   Janos S, 2011, BASIC QUEUING THEORY, P1
   Jarutis A, 2013, ELEKTRON ELEKTROTECH, V19, P89, DOI 10.5755/j01.eee.19.5.2908
   Jiang TG, 2012, IEEE J SEL AREA COMM, V30, P1215, DOI 10.1109/JSAC.2012.120807
   Lee M, 2014, IEEE ACM T NETWORK, V22, P1136, DOI 10.1109/TNET.2013.2272080
   Okumura S, 2011, 6337 RFC, P1
   Prabhavat S, 2011, IEEE T PARALL DISTR, V22, P1730, DOI 10.1109/TPDS.2011.43
   Qiang Duan, 2012, IEEE Transactions on Network and Service Management, V9, P373, DOI 10.1109/TNSM.2012.113012.120310
   Rottenstreich O, 2014, IEEE T COMPUT, V63, P1262, DOI 10.1109/TC.2012.288
   Serral-Gracia R., 2006, 2006 2 C NEXT GENERA, P269, DOI [DOI 10.1109/NGI.2006.1678251, 10.1109/NGI.2006.1678251]
   Vasilakos A, 1998, 1998 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AT THE IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE - PROCEEDINGS, VOL 1-2, P1488, DOI 10.1109/FUZZY.1998.686339
   Wang CH, 2011, J NETW COMPUT APPL, V34, P1545, DOI 10.1016/j.jnca.2010.10.011
   Wang Y, 2004, LECT NOTES COMPUT SC, V3090, P350
   Xiong NX, 2010, IEEE T PARALL DISTR, V21, P1254, DOI 10.1109/TPDS.2010.29
   Xiong NX, 2010, INFORM SCIENCES, V180, P2249, DOI 10.1016/j.ins.2009.12.001
NR 23
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15779
EP 15794
DI 10.1007/s11042-015-2888-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700040
DA 2024-07-18
ER

PT J
AU Chae, J
   Cho, Y
   Lee, M
   Lee, S
   Choi, M
   Park, S
AF Chae, Jeongmin
   Cho, Yoonah
   Lee, Minkyung
   Lee, Sangmi
   Choi, Munsuk
   Park, Seongbin
TI Design and implementation of a system for creating multimedia linked
   data and its applications in education
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Linked data; Semantic Web
AB The number of multimedia data has been constantly increasing and recently due to the popular SNS services as well as applications that run on smartphones, almost anyone can easily post video files or audio files on the Web. There are many tools by which lay users who do not have technical backrounds on the multimedia data format can create video files or audio files. While most existing tools for creating multimedia data have good user interfaces so that non-expert users can create different kinds of multimedia data easily, few tools allow users to semantically connect multimedia data so that semantics based searching can be supported. Linked data is a concrete example of the Semantic Web that aims for representing data in a form that machines can understand. In this paper, we present an easy-to-use system that helps novice users create multimedia linked data and show how the system can be used in education. The system has been implemented using open sources and all that users have to do is prepare data that needs to be provided as linked data in a simple format. Then the system automatically generates multimedia linked data and users can run a relation-based service that finds meaningful relations that exist in the linked data inside the system.
C1 [Chae, Jeongmin; Lee, Minkyung; Lee, Sangmi; Choi, Munsuk; Park, Seongbin] Korea Univ, Dept Comp Sci Educ, Seoul, South Korea.
   [Cho, Yoonah] Wolgye High Sch, Seoul, South Korea.
C3 Korea University
RP Park, S (corresponding author), Korea Univ, Dept Comp Sci Educ, Seoul, South Korea.
EM hyperspace@korea.ac.kr
CR Andriole SJ, 2010, COMMUN ACM, V53, P67, DOI 10.1145/1859204.1858225
   Bizer C, 2009, INT J SEMANT WEB INF, V5, P1, DOI 10.4018/jswis.2009081901
   d'Aquin M., 2013, Proceedings of the 5th Annual ACM Web Science Conference, P43, DOI [10.1145/2464464.2464487, DOI 10.1145/2464464.2464487]
   Dadzie AS, 2011, SEMANT WEB, V2, P89, DOI 10.3233/SW-2011-0037
   Heim P, 2009, LECT NOTES COMPUT SC, V5887, P182, DOI 10.1007/978-3-642-10543-2_21
   Herder E, 2013, UMAP EXTENDED P
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Li YJ, 2012, INT J SEMANT COMPUT, V6, P289, DOI 10.1142/S1793351X12400090
   Schandl B, 2012, MULTIMED TOOLS APPL, V59, P523, DOI 10.1007/s11042-011-0762-9
   Tiropanis T, 2009, IEEE INTELL SYST, V24, P49, DOI 10.1109/MIS.2009.121
   Vinyals O., 2014, ARXIV14114555
   Yao BZ, 2010, P IEEE, V98, P1485, DOI 10.1109/JPROC.2010.2050411
NR 12
TC 4
Z9 4
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13121
EP 13134
DI 10.1007/s11042-015-2895-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800009
DA 2024-07-18
ER

PT J
AU Chiang, HP
   Lai, CF
   Lai, YH
   Huang, YM
AF Chiang, Hua-Pei
   Lai, Chin-Feng
   Lai, Ying-Hsun
   Huang, Yueh-Min
TI A sensor-based feet motion recognition of graphical user interface
   controls
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feet motion; Recognition; Sensor-based; Graphical user interface
   controls
ID ACCELEROMETRY; WALKING
AB Motion sensing has now become one of the crucial parts of modern life. The tech products for entertainment create huge competition in the modern market, with the front runners such as game and handset manufacturers. Users can use their own bodies to control the systems without Conversational User Interfaces (CUIs) and Graph User Interfaces (GUIs). With many benefits, the technologies of NUI is getting more and more important, which also are usually accompanied by the sensor developments. Hence, system designers uses the sensors on the embedded platforms used to develop the system devices for different body movement control interfaces, such as using the gravitational sensor to control the systems or using touchscreen detection. However most of the body movement is restricted to the hand portion for the system platform, making it not as dynamic as the traditional monitor consoles. Thus, this restriction decreases the multitude and availability of controlling modes in system devices. In this study, a sensor-based gait recognition was proposed, in order to provide a novel natural user interface for control systems except the operating modes of gesture.
C1 [Chiang, Hua-Pei; Huang, Yueh-Min] Natl Cheng Kung Univ, Dept Engn Sci, Tainan 701, Taiwan.
   [Lai, Chin-Feng] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
   [Lai, Ying-Hsun] Inst Informat Ind, Smart Network Syst Inst, Taipei 105, Taiwan.
C3 National Cheng Kung University; National Chung Cheng University
RP Lai, CF (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
EM vchiang@fareastone.com.tw; cinfon@ieee.org; teddylai@iii.org.tw;
   huang@mail.ncku.edu.tw
RI Lai, Chin-Feng/IAP-5353-2023; Huang, Yueh-Min/B-4563-2009
OI lai, Ying-Hsin/0000-0003-0458-6435; Lai, Chin-Feng/0000-0001-7138-0272
FU National Science Council of the Republic of China, Taiwan [NSC
   101-2628-E-194-003-MY3, 101-2221-E-197-008-MY3, 102-2219-E-194-002];
   Ministry of Economy Affairs of the Republic of China
FX The authors would like to thank the National Science Council of the
   Republic of China, Taiwan for supporting this research under Contract
   NSC 101-2628-E-194-003-MY3, 101-2221-E-197-008-MY3 and
   102-2219-E-194-002. This study is also conducted under the Institute for
   Information Industry which is subsidized by the Ministry of Economy
   Affairs of the Republic of China.
CR Bergmann K, 2010, LECT NOTES ARTIF INT, V5934, P182, DOI 10.1007/978-3-642-12553-9_16
   Berman S, 2011, IEEE T SYST MAN CY C, V99, P1
   Bhavani R, 2012, INT J COMPUTERS, V6, P19
   BRENIERE Y, 1992, J BIOMECH, V25, P121, DOI 10.1016/0021-9290(92)90269-7
   ElSayed M, 2010, INT C BOD SENS NETW
   Karaulova IA, 2002, IMAGE VISION COMPUT, V20, P691, DOI 10.1016/S0262-8856(02)00059-8
   Kavanagh JJ, 2008, GAIT POSTURE, V28, P1, DOI 10.1016/j.gaitpost.2007.10.010
   Lomb PG, 2012, LECT NOTES COMPUTER, V7206, P24
   Mann S, SMART CLOTHING WEARA
   Peng P, DANCE YOUR HANDS ESE
   Sae-Bae N., 2012, Proceedings of the 2012 ACM Annual Conference on Human Factors in Computing Systems, P977, DOI DOI 10.1145/2207676.2208543
   Zijlstra A, 2008, GAIT POSTURE, V27, P164, DOI 10.1016/j.gaitpost.2007.02.010
NR 12
TC 3
Z9 3
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14125
EP 14141
DI 10.1007/s11042-015-2615-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500008
DA 2024-07-18
ER

PT J
AU Choi, J
   Lee, S
AF Choi, Jisung
   Lee, Sangjin
TI A study of user relationships in smartphone forensics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smartphone forensics; Android; iPhone; Relationship; Relation point
AB During a criminal investigation it is important to find the relation between criminals or people of interest, i.e. finding a person of interest will provide important evidence or lead in said investigation. A smartphone is a useful evidence to find related criminals because smartphones store their contacts information. However, simply using smartphone data can prove difficult to grasp the relationship between the user and connected people. In addition, due to the increase in smartphone data, a modern approach is needed for the investigation. If an investigator can use the recorded data on the smartphone and look at the contact data as a number, they therefore, can grasp the relationship between the user and the contact which will be a more efficient way of finding people of interest. I.e. a high number means they are close to one another. A close relationship is an indication of a high possibility that they may be criminally related. This paper proposes a method which shows connectivity, between a user and another as a numerical value, by using recorded data of SMS/MMS, Call applications, contact information and stored time information. This number is based on amount of times one user has contacted another user, we called the number 'Relation Point'. We use the normalization database to efficiently utilize various application data. Therefore, a relation point experiment is performed by smartphone forensic software, which uses the algorithm. The experiment result verifies effectiveness.
C1 [Choi, Jisung; Lee, Sangjin] Korea Univ, CIST, Seoul, South Korea.
C3 Korea University
RP Lee, S (corresponding author), Korea Univ, CIST, Seoul, South Korea.
EM sangjin@korea.ac.kr
FU Public Welfare & Safety Research Program through the National Research
   Foundation of Korea(NRF) - Ministry of Science, ICT & Future Planning
   [2012M3A2A1051106]
FX This research was supported by the Public Welfare & Safety Research
   Program through the National Research Foundation of Korea(NRF) funded by
   the Ministry of Science, ICT & Future Planning (2012M3A2A1051106).
CR Akbas MI, 2013, IEEE ICC, P1444, DOI 10.1109/ICC.2013.6654714
   Anwar T, 2014, DIGIT INVEST, V11, P349, DOI 10.1016/j.diin.2014.10.001
   Eagle N, 2009, P NATL ACAD SCI USA, V106, P15274, DOI 10.1073/pnas.0900282106
   Ferrara E, 2014, EXPERT SYST APPL, V41, P5733, DOI 10.1016/j.eswa.2014.03.024
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   Min J-k, CSCW, V13, P285
   Sarvari H, 2014, IEEE SEC PRIV WORKS, P84, DOI 10.1109/SPW.2014.22
   Tsai WT, 2013, 2013 IEEE SEVENTH INTERNATIONAL SYMPOSIUM ON SERVICE-ORIENTED SYSTEM ENGINEERING (SOSE 2013), P1, DOI 10.1109/SOSE.2013.44
NR 8
TC 5
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14971
EP 14983
DI 10.1007/s11042-016-3651-4
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500056
DA 2024-07-18
ER

PT J
AU Choi, W
   Jeong, H
AF Choi, Woonho
   Jeong, HwaYoung
TI Finding an appropriate lexical diversity measurement for a small-sized
   corpus and its application to a comparative study of L2 learners'
   writings
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE L2 learning; TTR(Type-Token Ratio); D-estimate; Yule's K; Guiraud's R;
   Lexical diversity
AB The present study investigates four kinds of lexical diversity measurement and a computational experiment with corpus processing and statistical test has been conducted to find out the most effective lexical diversity measurement in evaluating a small-sized corpus of 350 similar to 550 words. The results show that the D-estimate is the most appropriate among the four lexical diversity measurements which were compared in this research. Also the D-estimate showed more stable results than other measurements when the number of words varied between texts. The D-estimate was applied to measure the morphological and grammatical diversities of L2 learners of the Korean language, and conduct a statistical test on whether the mother tongues of L2 learners affect the degree of acquisition of grammatical morphemes. The test shows that the native languages of L2 learners learning Korean did not seem to have a significant impact.
C1 [Choi, Woonho] Mokpo Natl Univ, Dept Korean Language & Literature, 1666 Youngsan Ro, Muan Gun 534729, Jeonnam, South Korea.
   [Jeong, HwaYoung] Kyung Hee Univ, Humanitas Coll, 1 Hoegi dOng, Seoul 130701, South Korea.
C3 Mokpo National University; Kyung Hee University
RP Jeong, H (corresponding author), Kyung Hee Univ, Humanitas Coll, 1 Hoegi dOng, Seoul 130701, South Korea.
EM whchoi@mokpo.ac.kr; hyjeong@khu.ac.kr
OI Jeong, Hwa-Young/0000-0002-5017-934X
CR Baayen R.H., 2008, ANALYSING LINGUISTIC, DOI DOI 10.1017/CBO9780511801686
   Chang Kyunghee, 2008, [Korean Semantics, 한국어 의미학], V27, P225
   Durán P, 2004, APPL LINGUIST, V25, P220, DOI 10.1093/applin/25.2.220
   JIN DaeYeon, 2006, [Bilingual Research, 이중언어학], V30, P385
   Kang S. S., 2002, KOREAN MORPHOLOGICAL
   Lee HY, 2010, BILING RES, V44, P275
   Mellor A, 2011, MEM OSAKA I TECHNO B, V55, P1
   Ministry of Culture Sports and Tourism, 2010, RES ACT COND DEM KOR
   Park JE, 2014, J KOREAN LANG ED, V25, P1
   Tweedie FJ, 1998, COMPUT HUMANITIES, V32, P323, DOI 10.1023/A:1001749303137
NR 10
TC 1
Z9 1
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13015
EP 13022
DI 10.1007/s11042-015-2529-1
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800002
DA 2024-07-18
ER

PT J
AU Lee, CS
   Park, W
AF Lee, Chi-Seok
   Park, Wonhyung
TI Enhancing industrial security management system for multimedia
   environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia environment; Multimedia industrial security; Industrial
   security management system; Evaluation items
AB Since business and national competitiveness depends on the development and application of industrial technologies, firms have made a steady investment in research and development to secure competitive industrial technologies. However, as industrial technologies have been leaked to competitors or overseas by neglecting security management, the importance of industrial security is growing bigger. Due to this importance of industrial technology protection, there is a growing need for a comprehensive and systematic management system to prevent the leaking of industrial technologies. In particular, the industrial security management system certification is a management system established by the need of systematic management for organizational 'industrial technologies, business secret, intellectual property right and other managerial resources' etc. and sustainable industrial security management in the aspect of multimedia environment. This paper analyzes the differentiation from the existing certification system and improves evaluation items by applying the industrial security management system standard and its details in the aspect of multimedia environment.
C1 [Lee, Chi-Seok] Sang Myung Univ, Grad Sch, Dept Informat Secur Management, 20,Hongjimun 2 Gil, Seoul 110743, South Korea.
   [Park, Wonhyung] Far East Univ, Dept Cyber Secur, Eumseong Gun 369700, Chungcheongbuk, South Korea.
C3 Sangmyung University
RP Park, W (corresponding author), Far East Univ, Dept Cyber Secur, Eumseong Gun 369700, Chungcheongbuk, South Korea.
EM sundolri5555@daum.net; whpark@kdu.ac.kr
CR Byeong-il J, 2009, J KOREAN ASS IND SEC, V1, P1
   Byeonghee L, 2009, P KOR TECHN INN SOC, V2009, P365
   Han G, 2011, J KOREA POLICY I C P, V2011, P579
   Kim Y, 2014, SECUR COMMUN NETW, V7, P1622, DOI 10.1002/sec.814
   Kim Y, 2013, SENSOR LETT, V11, P1799, DOI 10.1166/sl.2013.3001
   Korean Association for Industrial Security, 2011, IND SUC
   Korean Association for Industrial Technology Security, 2011, ACT PLAN DET SEC IND
   Thuraisingham B, 2007, MULTIMED TOOLS APPL, V33, P13, DOI 10.1007/s11042-006-0096-1
   Yang CC, 2013, SUPPLY CHAIN MANAG, V18, P74, DOI 10.1108/13598541311293195
   Yun Wonyoung, 2011, [Journal of Korean Society for Quality Management, 품질경영학회지], V39, P141
   배영식, 2012, [Journal of Korea Academia-Industrial cooperation Society, 한국산학기술학회논문지], V13, P4224, DOI 10.5762/KAIS.2012.13.9.4224
   원형규, 2010, [Journal of Korean Society for Quality Management, 품질경영학회지], V38, P276
   최진혁, 2010, [Korean Security Journal, 시큐리티연구], V22, P197
NR 13
TC 0
Z9 0
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14597
EP 14615
DI 10.1007/s11042-015-2868-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500036
DA 2024-07-18
ER

PT J
AU Lu, W
   Xu, TJ
   Ren, YL
   He, LH
AF Lu, Wen
   Xu, Tianjiao
   Ren, Yuling
   He, Lihuo
TI Statistical modeling in the shearlet domain for blind image quality
   assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind image quality assessment; Human scores free; Natural scene
   statistics; Shearlet transform
AB The state-of-the-art blind image quality assessment (BIQA) metrics usually require a large amount of human scored images to train a regression model used to judge image quality, which makes the results are heavily dependent on the size of training data. In this paper, we present an efficient BIQA algorithm based on shearlet transform without using human scored images. This is mainly based on that the degradation of the image leads to significant variation in the spread discontinuities in all directions. However, shearlet transform has a strong ability to localize distributed discontinuities. The natural scene statistics (NSS) of shearlet coefficients are applicable to indicate the variation of image quality. Experimental results on benchmark databases illustrate that the proposed method has a good consistency with the subjective assessment of human beings.
C1 [Lu, Wen; Xu, Tianjiao; Ren, Yuling; He, Lihuo] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
C3 Xidian University
RP He, LH (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
EM luwen.xidian@gmail.com; tjxu_25@stu.xidian.edu.cn;
   renyuling@stu.xidian.edu.cn; lihuo.he@gmail.com
FU National Natural Science Foundation of China [61372130, 61432014,
   61501349, 61571343]; Fundamental Research Funds for the Central
   Universities [BDY081426, JB140214, XJS14042]; Program for New Scientific
   and Technological Star of Shaanxi Province [2014KJXX-47]; China
   Postdoctoral Science Foundation [2014 M562378]
FX This research was supported partially by the National Natural Science
   Foundation of China (Nos. 61372130, 61432014, 61501349, 61571343), the
   Fundamental Research Funds for the Central Universities (Nos. BDY081426,
   JB140214, XJS14042), the Program for New Scientific and Technological
   Star of Shaanxi Province (No. 2014KJXX-47), the Project Funded by China
   Postdoctoral Science Foundation (No. 2014 M562378).
CR [Anonymous], IEEE SIGNAL PROC LET
   [Anonymous], 2010, J ELECT IMAG
   [Anonymous], 2006, MODERN IMAGE QUALITY
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   Gao F, 2016, SIGNAL PROCESS, V124, P210, DOI 10.1016/j.sigpro.2015.08.012
   Gao F, 2015, IEEE T NEUR NET LEAR, V26, P2275, DOI 10.1109/TNNLS.2014.2377181
   Hassen R, 2010, INT CONF ACOUST SPEE, P2434, DOI 10.1109/ICASSP.2010.5496297
   Jayaraman D, 2012, CONF REC ASILOMAR C, P1693, DOI 10.1109/ACSSC.2012.6489321
   Kalayeh MM, 2013, IEEE T NUCL SCI, V60, P1609, DOI 10.1109/TNS.2013.2257183
   Lasmar NE, 2009, IEEE IMAGE PROC, P2281, DOI 10.1109/ICIP.2009.5414404
   Li JH, 2015, SPRINGER THESES-RECO, P1, DOI 10.1007/978-3-662-46991-0_1
   Li YM, 2014, SIGNAL PROCESS-IMAGE, V29, P748, DOI 10.1016/j.image.2014.05.007
   Lim WQ, 2013, IEEE T IMAGE PROCESS, V22, P2056, DOI 10.1109/TIP.2013.2244223
   Lu YA, 2015, IEEE SIGNAL PROC LET, V22, P1811, DOI 10.1109/LSP.2015.2436908
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Saha A, 2015, IEEE T IMAGE PROCESS, V24, P1879, DOI 10.1109/TIP.2015.2411436
   SHARIFI K, 1995, IEEE T CIRC SYST VID, V5, P52, DOI 10.1109/76.350779
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Srivastava A, 2003, J MATH IMAGING VIS, V18, P17, DOI 10.1023/A:1021889010444
   Xue WF, 2013, PROC CVPR IEEE, P995, DOI 10.1109/CVPR.2013.133
   Yang J, 2015, MULTIMED TOOLS APPL, P1, DOI DOI 10.3109/19401736.2015.1018206
   Yang JC, 2015, IEEE SENS J, V15, P4508, DOI 10.1109/JSEN.2015.2421518
   Yang JC, 2015, NEURAL NETWORKS, V71, P45, DOI 10.1016/j.neunet.2015.07.011
NR 28
TC 8
Z9 8
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14417
EP 14431
DI 10.1007/s11042-016-3519-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500024
DA 2024-07-18
ER

PT J
AU Nie, WZ
   Liu, AA
   Zhu, XR
   Su, YT
AF Nie, Weizhi
   Liu, Anan
   Zhu, Xiaorong
   Su, Yuting
TI Quality models for venue recommendation in location-based social network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality model; Location based social network; User recommendation
AB With the rapid development of location-based social networks (LBSNs), increasing media data is ceaselessly uploaded by users. The multimedia data is often scattered and not informative and consequently they can not directly represent the semantics of each venue. Most of prior works leverage the user' travelling histories to recommend new venues to users. However, these works often focus on the users' travelling histories, while ignore the concepts or the popular levels of venues. In this paper, we proposed a quality model for venue recommendation by utilizing multimedia data to predict the interested level of each venue. First, we apply the graph cut method to generate the latent textual topics. Second, we leverage visual data from Flickr to train concept detectors to automatically label visual information. Third, the weighted bipartite matching algorithm is implemented to generate the venue multimedia topics by bridging the textual information and the visual information. Finally, we utilize the matching cost to predict the popular level of venue for recommendation. The experiments have been conducted on the cross-platform datasets. The results demonstrate the superiority of the proposed model.
C1 [Nie, Weizhi; Liu, Anan; Zhu, Xiaorong; Su, Yuting] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University
RP Liu, AA (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
EM truman.nie@gmail.com; anan0422@gmail.com
RI Nie, Weizhi/ABF-5316-2021
OI nie, weizhi/0000-0002-0578-8138
FU National Natural Science Foundation of China [61472275, 61100124,
   21106095, 61170239, 61202168]; Elite Scholar Program of Tianjin
   University
FX I would like to express my deep gratitude to Prof. Chua and the NeXT
   group in National University of Singapore. This work was supported in
   part by the National Natural Science Foundation of China (61472275,
   61100124, 21106095, 61170239, and 61202168), the grant of Elite Scholar
   Program of Tianjin University.
CR Alonso O, 2010, LECT NOTES COMPUT SC, V6393, P290, DOI 10.1007/978-3-642-16321-0_30
   Amatriain X, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2201, DOI 10.1145/2505515.2514701
   Anwar H, 2013, ARXIV13046192 CORR
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Caster F, 2014, IEEE J SOLID-ST CIRC, V49, P1317, DOI 10.1109/JSSC.2014.2310744
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Choi J., 2012, P 21 ACM INT C INFOR, P1834, DOI DOI 10.1145/2396761.2398527
   Clements P., 2010, Proceedings of the 2010 IEEE 18th International Conference on Requirements Engineering (RE2010), P69, DOI 10.1109/RE.2010.18
   Csaba B, 2007, ARXIV07054673 CORR
   Felzenszwalb P.F., 2010, T PATTERN ANAL MACHI
   Fu QF, 2013, 2013 9TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P219, DOI 10.1109/CIS.2013.53
   Gao Y, 2014, DES AUT TEST EUROPE
   Gu Y, 2014, IEEE T KNOWL DATA EN, V26, P1117, DOI 10.1109/TKDE.2013.123
   Harvey M, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2309
   Hu H, 2013, IEEE T MULTIMEDIA, V15, P1638, DOI 10.1109/TMM.2013.2266092
   Huang J, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P248, DOI 10.1109/AFGR.1996.557272
   Ji Z., 2012, P 21 ACM INT C INF K, P2471, DOI DOI 10.1145/2396761.2398669
   Jiang X, 2014, EXPLORING PRINCIPLES
   Li F., 2012, CIKM, P1622
   Liu X, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P733
   Marín B, 2013, ACM T SOFTW ENG METH, V22, DOI 10.1145/2491509.2491520
   Mendelzon AO, 2000, ACM SIGMOD DIGIT REV, V1
   Pei WJ, 2014, LECT NOTES COMPUT SC, V8588, P715, DOI 10.1007/978-3-319-09333-8_78
   Roul RK, 2014, ARXIV14065617 CORR
   Sakai Tetsuya., 2013, SIGIR 13 P 36 INT AC, P473
   Severyn A, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1067, DOI 10.1145/2600428.2609511
   Takeuchi Y, 2006, LECT NOTES COMPUT SC, V4159, P625
   Tang Xuning., 2012, P 21 ACM INT C INFOR, P972
   WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P133
   Xing Wei, 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P178
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Zhang D, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P1223
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
   Zhang LM, 2014, INFORM SCIENCES, V254, P141, DOI 10.1016/j.ins.2013.08.020
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, SIGNAL PROCESS, V93, P1597, DOI 10.1016/j.sigpro.2012.05.012
   Zhang XG, 2013, IEEE T MULTIMEDIA, V15, P1446, DOI 10.1109/TMM.2013.2247988
   Zheng VW, 2010, P 19 INT C WORLD WID, P1029
   Zheng-Wu Yuan, 2012, 2012 9th International Conference on Fuzzy Systems and Knowledge Discovery, P2774, DOI 10.1109/FSKD.2012.6233723
   Zhu X, 2012, P 21 ACM INT C INF K, P1814
NR 40
TC 3
Z9 3
U1 3
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12521
EP 12534
DI 10.1007/s11042-014-2339-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700013
DA 2024-07-18
ER

PT J
AU Du, SY
   Liu, ZG
AF Du, Sheng-Yong
   Liu, Zhao-Guang
TI A comparative study of different color spaces in computer-vision-based
   flame detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Flame/fire detection; Color space; Scatter matrix; Divergence;
   Bag-of-features
ID FIRE-DETECTION METHOD; VIDEO; IMAGE; SYSTEM
AB Color information plays an important role in computer-vision-based fire/flame detection. The purpose of this study is to determine the most effective color space by performing an objective comparison among 18 different color spaces in terms of classification accuracy and class separability measures. In the comparison of classification accuracy, a bag-of-features (BoF) method is proposed in the paper. The experiments are based on 2000 images, including interfering objects collected from the Internet. According to the experiment results, the proposed BoF method can greatly improve classification accuracy for positive samples compared with alternative algorithms, while also ensuring the accurate classification of negative samples. The sRGB and PJF color spaces perform more effectively according to the experiment results. A trade-off can be found in the two color spaces in the classification accuracy of positive and negative samples; the best classification accuracy of all samples is achieved in the PJF color space with the J-F plane. In a comparison of class separability measures, the first three optimal values are also achieved by the sRGB and PJF color spaces. Therefore, the two color spaces are recommended in computer-vision-based flame detection systems according to our experiment results.
C1 [Du, Sheng-Yong] Shandong Univ Finance & Econ, Sch Management Sci & Engn, Jinan, Peoples R China.
   [Liu, Zhao-Guang] Shandong Univ, Sch Informat Sci & Engn, Jinan, Peoples R China.
   [Liu, Zhao-Guang] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Shandong Prov Key Lab Digital Media Technol, Jinan, Peoples R China.
C3 Shandong University of Finance & Economics; Shandong University;
   Shandong University of Finance & Economics
RP Liu, ZG (corresponding author), Shandong Univ, Sch Informat Sci & Engn, Jinan, Peoples R China.; Liu, ZG (corresponding author), Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Shandong Prov Key Lab Digital Media Technol, Jinan, Peoples R China.
EM liuzhg@sdufe.edu.cn
CR [Anonymous], 2011, DIGITAL IMAGE PROCES
   [Anonymous], 2007, Color Constancy
   Anthimopoulos MM, 2014, IEEE J BIOMED HEALTH, V18, P1261, DOI 10.1109/JBHI.2014.2308928
   Borges PVK, 2010, IEEE T CIRC SYST VID, V20, P721, DOI 10.1109/TCSVT.2010.2045813
   Celik T, 2007, J VIS COMMUN IMAGE R, V18, P176, DOI 10.1016/j.jvcir.2006.12.003
   Çelik T, 2009, FIRE SAFETY J, V44, P147, DOI 10.1016/j.firesaf.2008.05.005
   Changwoo Ha, 2012, 2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems (CISIS), P526, DOI 10.1109/CISIS.2012.25
   Chaves-González JM, 2010, DIGIT SIGNAL PROCESS, V20, P806, DOI 10.1016/j.dsp.2009.10.008
   Chen J, 2012, PROCEDIA ENGINEER, V45, P595, DOI 10.1016/j.proeng.2012.08.209
   Chen J, 2010, BUILD ENVIRON, V45, P1113, DOI 10.1016/j.buildenv.2009.10.017
   Chen TH, 2004, IEEE IMAGE PROC, P1707
   Choi JY, 2011, PATTERN RECOGN, V44, P412, DOI 10.1016/j.patcog.2010.08.020
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Günay O, 2009, FIRE SAFETY J, V44, P860, DOI 10.1016/j.firesaf.2009.04.003
   Habiboglu YH, 2012, MACH VISION APPL, V23, P1103, DOI 10.1007/s00138-011-0369-1
   Jackman P, 2012, MEAT SCI, V91, P402, DOI 10.1016/j.meatsci.2012.02.014
   Jing Shao, 2012, Proceedings of the 2012 International Conference on Computer Science and Information Processing (CSIP), P1008, DOI 10.1109/CSIP.2012.6309027
   Ko BC, 2009, FIRE SAFETY J, V44, P322, DOI 10.1016/j.firesaf.2008.07.006
   Lee DK, 2012, IET IMAGE PROCESS, V6, P891, DOI 10.1049/iet-ipr.2011.0507
   Liu CB, 2004, INT C PATT RECOG, P134, DOI 10.1109/HPD.2004.1346686
   Marbach G, 2006, FIRE SAFETY J, V41, P285, DOI 10.1016/j.firesaf.2006.02.001
   Matsukawa T, 2012, PATTERN RECOGN, V45, P707, DOI 10.1016/j.patcog.2011.07.018
   Olson D.L., 2008, ADV DATA MINING TECH, DOI https://doi.org/10.1007/978-3-540-76917-0
   Ono T, 2006, FIRE SAFETY J, V41, P279, DOI 10.1016/j.firesaf.2005.06.006
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Qazi IUH, 2010, PATTERN RECOGN, V43, P663, DOI 10.1016/j.patcog.2009.07.008
   Rinsurongkawong S, 2012, 2012 9 INT C EL ENG, P1, DOI DOI 10.1109/ECTICON.2012.6254144
   Rong JZ, 2013, OPT LASER TECHNOL, V47, P283, DOI 10.1016/j.optlastec.2012.08.040
   Tai Yu Lai, 2012, Proceedings of the 2012 Third International Conference on Innovations in Bio-Inspired Computing and Applications (IBICA), P139, DOI 10.1109/IBICA.2012.41
   Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1
   Töreyin BU, 2006, PATTERN RECOGN LETT, V27, P49, DOI 10.1016/j.patrec.2005.06.015
   Truong TX, 2012, ENG APPL ARTIF INTEL, V25, P1365, DOI 10.1016/j.engappai.2012.05.007
   Wang DC, 2013, FIRE SAFETY J, V55, P116, DOI 10.1016/j.firesaf.2012.10.011
   Wang SJ, 2009, J SYST SOFTWARE, V82, P656, DOI 10.1016/j.jss.2008.09.025
   Xuanfang Yang, 2012, Proceedings of the 2012 International Conference on Modelling, Identification and Control (ICMIC), P150
   Yang J, 2010, PATTERN RECOGN, V43, P1454, DOI 10.1016/j.patcog.2009.11.014
   Yuan FN, 2010, MACH VISION APPL, V21, P941, DOI 10.1007/s00138-010-0276-x
NR 37
TC 12
Z9 12
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10291
EP 10310
DI 10.1007/s11042-015-2990-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800010
DA 2024-07-18
ER

PT J
AU Rusek, K
   Guzik, P
AF Rusek, Krzysztof
   Guzik, Piotr
TI Two-stage neural network regression of eye location in face images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eye localization; Neural network; DCT; Computer vision
ID CASCADE
AB Automatic eye localization is a crucial part of many computer vision algorithms for processing face images. Some of the existing algorithms can be very accurate, albeit at the cost of computational complexity. In this paper, a new solution to the problem of automatic eye localization is proposed. Eye localization is posed as a nonlinear regression problem solved by two feed-forward multilayer perceptrons (MLP) working in a cascade. The input feature vector of the first network is constructed from coefficients of a two dimensional discrete cosine transform(DCT) of a face image. The second network generates corrections based on small image patches. Feature extraction and neural network prediction have known and efficient implementations, thus the entire procedure can be very fast. The paper hints at the neural network structure and the procedure for generating artificial training samples from a low number of face images. In terms of accuracy, the method is comparable to state-of-the-art techniques; however it is based on numerical procedures that could be highly optimized (fast Fourier transform and matrix multiplication).
C1 [Rusek, Krzysztof; Guzik, Piotr] AGH Univ Sci & Technol, Dept Telecommun, Mickiewicza 30, PL-30059 Krakow, Poland.
C3 AGH University of Krakow
RP Guzik, P (corresponding author), AGH Univ Sci & Technol, Dept Telecommun, Mickiewicza 30, PL-30059 Krakow, Poland.
EM guzik@kt.agh.edu.pl
RI Guzik, Piotr/Q-5022-2019; Guzik, Piotr/B-1313-2016; Rusek,
   Krzysztof/ABC-8573-2020
OI Guzik, Piotr/0000-0002-5019-4056; Rusek, Krzysztof/0000-0003-4336-7841
FU EU [218086]; PL-Grid Infrastructure
FX This work has been performed in the framework of the EU Project INDECT
   (Intelligent information system supporting observation, searching and
   detection for security of citizens in urban environment)-grant agreement
   number: 218086. This research was supported in part by PL-Grid
   Infrastructure.
CR [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2016, Pattern Recognition and Machine Learning, Softcover Reprint of the Original 1st ed., Information Science and Statistics, DOI DOI 10.1117/1.2819119
   Beale MH., 2012, Neural Network Toolbox, User's guide
   Campadelli P, 2009, INT J PATTERN RECOGN, V23, P359, DOI 10.1142/S0218001409007259
   Enge J, 2009, LECT NOTES COMPUT SC, V5630, P254, DOI 10.1007/978-3-642-02472-6_28
   Everingham M, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P441
   Fei Yang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P514, DOI 10.1109/FG.2011.5771450
   Ioannou S, 2006, LECT NOTES COMPUT SC, V4131, P81
   Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90
   Kroon B, 2009, COMPUT VIS IMAGE UND, V113, P921, DOI 10.1016/j.cviu.2009.03.013
   Riopka T., 2003, Proceedings of the 2003 ACM SIGMM Workshop on Biometrics methods and applications, P9
   Rusek K, 2013, COMM COM INF SC, V368, P204
   Rusek K, 2011, COMM COM INF SC, V149, P144
   Senechal T, 2010, LECT NOTES ARTIF INT, V5998, P141, DOI 10.1007/978-3-642-12159-3_13
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Valenti Roberto., 2008, 2008 IEEE Conference on Computer Vision and Pattern Recognition, P1
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   WILSON P.I., 2006, J COMPUT SMALL COLL, V21, P127
   Zhou ZH, 2004, PATTERN RECOGN, V37, P1049, DOI 10.1016/j.patcog.2003.09.006
NR 19
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10617
EP 10630
DI 10.1007/s11042-014-2114-z
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800025
OA hybrid
DA 2024-07-18
ER

PT J
AU Maity, SP
   Maity, HK
AF Maity, Santi P.
   Maity, Hirak Kumar
TI On adaptive distortion control in reversible watermarking using modified
   reversible contrast mapping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RW; RCM; M-ary; Kullback-Leibler distance; Adaptive distortion control
ID DIFFERENCE EXPANSION; HISTOGRAM-MODIFICATION
AB The use of reversible contrast mapping (RCM) on pair of pixels in images for reversible watermarking (RW) offers a flexible integer transform that leads to high embedding rate at low mathematical complexity and without requiring additional data compression. Mathematically RCM may be interpreted as a form of adaptive linear transformation on pair of pixels that controls distortion and leads to the retention of the structural information of the watermarked image. A generalized form of RCM, analogous to M-ary modulation in communication, is developed here for a set of points and their corresponding embedding spaces are shown geometrically with and without considering distortion control. Then an optimized distortion control framework adaptive to the choice of operating points is considered to improve data hiding capacity under embedding distortion constraint. Simulation results show that the combination of different M-ary approaches i.e. using the points representing the different transformation functions outperform the embedding rate, visual quality and security of the hidden information compared to the existing RCM, difference expansion (DE) and prediction error expansion (PEE) methods during over embedding. Numerical results show that an average of 13 % improvement in visual quality, 25 % improvement in security of the hidden data is achieved at 0.8 bpp embedding rate over existing PEE work. Performance in robustness against common signal processing operations, namely noise addition, smoothing filtering and some form of geometric operation like random bending attack are also studied. All these studies and the effectiveness are demonstrated with a large set of simulation results.
C1 [Maity, Santi P.] Indian Inst Engn Sci & Technol, Dept Informat Technol, Sibpur 711103, Howrah, India.
   [Maity, Hirak Kumar] Coll Engn & Management, Dept Elect & Commun Engn, Kolaghat 721171, Purba Medinipur, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST)
RP Maity, SP (corresponding author), Indian Inst Engn Sci & Technol, Dept Informat Technol, Sibpur 711103, Howrah, India.
EM santipmaity@it.iiests.ac.in; hirakmaity@gmail.com
RI Maity, Hirak Kumar/Y-2310-2019
OI Maity, Hirak/0000-0001-8085-4417
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Alattar AM, 2003, IEEE IMAGE PROC, P501
   Caldelli R, 2010, EURASIP J INF SECUR, DOI 10.1155/2010/134546
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2008, EUC 2008: PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON EMBEDDED AND UBIQUITOUS COMPUTING, VOL 1, MAIN CONFERENCE, P506, DOI 10.1109/EUC.2008.20
   Chen Biao, 2013, Wuhan University Journal of Natural Sciences, V18, P126, DOI 10.1007/s11859-013-0904-1
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Coltuc D, 2012, EUR SIGNAL PR CONF, P1791
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Dragoi IC, 2012, EUR SIGNAL PR CONF, P1688
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Feng J.B., 2006, IJ Network Security, V2, P161
   Georgiou TT, 2003, IEEE T INFORM THEORY, V49, P2910, DOI 10.1109/TIT.2003.819324
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Huo Yongjin, 2013, Wuhan University Journal of Natural Sciences, V18, P455, DOI 10.1007/s11859-013-0956-2
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Lin CC, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P8, DOI 10.1109/CISP.2008.64
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Maity D, 2012, INT C SIGN PROC COMM
   Maity HK, 2014, J SYST SOFTWARE, V96, P93, DOI 10.1016/j.jss.2014.05.079
   Maity HK, 2014, IEEE IPAS14
   Maity S. P., 2013, P NAT C COMP VIS PAT
   Nedelcu T, 2014, EUR SIGNAL PR CONF, P2455
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Thodi DM, 2004, IEEE IMAGE PROC, P1549
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tseng HW, 2009, INFORM SCIENCES, V179, P2460, DOI 10.1016/j.ins.2009.03.014
   Wang F, 2014, SCI WORLD J, DOI 10.1155/2014/656251
   Wang X, 2007, IEEE T INF FOREN SEC, V2, P311, DOI 10.1109/TIFS.2007.902677
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HC, 2009, J SYST SOFTWARE, V82, P1966, DOI 10.1016/j.jss.2009.06.056
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
   Zong TR, 2014, IEEE ICC, P878, DOI 10.1109/ICC.2014.6883430
NR 38
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7931
EP 7956
DI 10.1007/s11042-015-2710-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600023
DA 2024-07-18
ER

PT J
AU Tong, M
   Guo, JY
   Tao, SC
   Wu, YC
AF Tong, Ming
   Guo, Jinyu
   Tao, Shichang
   Wu, Yangcheng
TI Independent detection and self-recovery video authentication mechanism
   using extended NMF with different sparseness constraints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video authentication; Data integrity authentication; Video recovery;
   Tampering localization; Non-negative matrix factorization (NMF)
ID NONNEGATIVE MATRIX FACTORIZATION; WATERMARKING; SCHEME
AB With the emergence and maturity of various signal processing tools, it can be more convenient, much faster and more arbitrary for people to illegally tamper the original video to varying degrees and in different forms, which makes the video authentication become the focus of researchers in multimedia field. This paper aims to improve the tampered area's localization accuracy and maximize the degree of recovery for the tampered area, which are hot and difficult spots of research in video authentication. Firstly, a new non-negative matrix factorization method is proposed, which is implemented by setting different sparseness constraints on part of the basis matrix. Secondly, Hash function and the newly proposed method are used to generate the block-level watermark and frame-level watermark, which are self-embedded into the video, so as to authenticate the spatial tampering and temporal tampering separately. Finally, the intelligent characteristics of the basis matrix that the whole basis matrix can be recovered by the part and the spatial-temporal continuous characteristics of video are used to recover the tampered area. This paper's contribution is that the tampered area's localization accuracy and recovery quality are improved greatly compared with other similar methods. Experimental results show the effectiveness of this paper.
C1 [Tong, Ming; Guo, Jinyu; Tao, Shichang; Wu, Yangcheng] Xidian Univ, Sch Elect Engn, Xian, Peoples R China.
C3 Xidian University
RP Tong, M (corresponding author), Xidian Univ, Sch Elect Engn, Xian, Peoples R China.
EM mtong@xidian.edu.cn; 18392881468@163.com; taochangchang@126.com;
   757227432@qq.com
FU National Natural Science Foundation of China [61072110]; Natural Science
   Foundation of Shaanxi [SJ08F15]; Science and Technology Overall
   Innovation Project of Shaanxi Province [2013KTZB03-03-03]
FX This work was supported in part by National Natural Science Foundation
   of China (Grant No. 61072110), Natural Science Foundation of Shaanxi
   (Grant SJ08F15) and Science and Technology Overall Innovation Project of
   Shaanxi Province (Grant 2013KTZB03-03-03)
CR Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Chen SY, 2008, IEEE T CIRC SYST VID, V18, P704, DOI 10.1109/TCSVT.2008.918801
   El-Fouly THM, 2007, IET GENER TRANSM DIS, V1, P928, DOI 10.1049/iet-gtd:20060564
   Hassan A, 2009, WORLD ACAD SCI ENG T, V57, P69
   He HJ, 2012, IEEE T INF FOREN SEC, V7, P185, DOI 10.1109/TIFS.2011.2162950
   Hoyer PO, 2004, J MACH LEARN RES, V5, P1457
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Lin YC, 2012, IEEE T IMAGE PROCESS, V21, P273, DOI 10.1109/TIP.2011.2157515
   Liu Ce, 2009, THESIS
   Liu Z, 2012, BIOINFORMATICS, V28, P914, DOI 10.1093/bioinformatics/bts078
   Lo CC, 2014, SIGNAL PROCESS, V98, P174, DOI 10.1016/j.sigpro.2013.11.028
   Shi YJ, 2013, OPTIK, V124, P3827, DOI 10.1016/j.ijleo.2012.11.078
   Stadlthanner K, 2005, LECT NOTES COMPUT SC, V3512, P249
   [同鸣 Tong Ming], 2012, [电子与信息学报, Journal of Electronics & Information Technology], V34, P1819
   Wang JJY, 2013, PATTERN RECOGN, V46, P3249, DOI 10.1016/j.patcog.2013.05.001
   Wang JJY, 2013, PATTERN RECOGN, V46, P2840, DOI 10.1016/j.patcog.2013.03.007
   Wang JJY, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-107
   Wang JJY, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-307
   Xu DW, 2011, SIGNAL PROCESS-IMAGE, V26, P267, DOI 10.1016/j.image.2011.04.008
   Yang ZY, 2011, IEEE T IMAGE PROCESS, V20, P1112, DOI 10.1109/TIP.2010.2081678
   [张维纬 Zhang Weiwei], 2013, [电子与信息学报, Journal of Electronics & Information Technology], V35, P106
NR 21
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 8045
EP 8069
DI 10.1007/s11042-015-2722-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600028
DA 2024-07-18
ER

PT J
AU Xu, HJ
   Pan, P
   Xu, CY
   Lu, YS
   Chen, D
AF Xu, HaiJiao
   Pan, Peng
   Xu, ChunYan
   Lu, YanSheng
   Chen, Deng
TI Image auto-annotation via concept interdependency network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image auto-annotation; Concept interdependency network; Google distance;
   Machine learning
ID EFFICIENT; MODEL
AB With the explosive growth of multimedia data such as unlabeled images on the Web, image auto-annotation has been receiving increasing research interest. By automatically assigning a set of concepts to unlabeled images, image retrieval can be performed over labeled concepts. Most existing studies focus on the relations between images and concepts, and ignore the interdependencies between labeled concepts. In this paper, we propose a novel image auto-annotation model which utilizes the concept interdependency network to achieve better image auto-annotation. When a concept and its interdependent concepts have a high co-occurrence frequency in the training set, we consider boosting the chance of predicting this concept if there is strong visual evidence for the interdependent concepts in an unlabeled image. Additionally, we combine the global concept interdependency and the local concept interdependency to enhance the auto-annotation performance. Extensive experiments on Corel and IAPR datasets show that the proposed approach almost outperforms all existing methods.
C1 [Xu, HaiJiao; Pan, Peng; Lu, YanSheng; Chen, Deng] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Xu, ChunYan] Natl Univ Singapore, Elect & Comp Engn, 21 Lower Kent Ridge Rd, Singapore 119077, Singapore.
C3 Huazhong University of Science & Technology; National University of
   Singapore
RP Pan, P (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM guesskkk@hust.edu.cn; panpeng@mail.hust.edu.cn; xuchunyan01@gmail.com;
   lys@mail.hust.edu.cn; chendeng8899@hust.edu.cn
RI XU, HaiJiao/A-3222-2015; Lu, Rui/KCJ-8212-2024; Pan, Feng/IXN-2297-2023
OI XU, HaiJiao/0000-0002-3093-7246; 
FU HUST Independent Innovation Research Foundation [2014QN007]
FX This work is supported by HUST Independent Innovation Research
   Foundation project (No. 2014QN007). Thanks to the help from my
   colleagues in National University of Singapore.
CR [Anonymous], INT J
   [Anonymous], KNOWLEDGE GRID
   [Anonymous], 2009, Encyclopedia of Database Systems, DOI DOI 10.1007/978-0-387-39940-91318
   [Anonymous], INT J COMPUTER VISIO
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Nguyen CT, 2013, ACM T WEB, V7, DOI 10.1145/2516633.2516634
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen A., 2013, ICML, P1274
   Chen PI, 2011, EXPERT SYST APPL, V38, P7349, DOI 10.1016/j.eswa.2010.12.092
   Choi JH, 2003, LECT NOTES COMPUT SC, V2667, P79
   Cilibrasi RL, 2007, IEEE T KNOWL DATA EN, V19, P370, DOI 10.1109/TKDE.2007.48
   Cui CR, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P957
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Feng ZY, 2013, IEEE I CONF COMP VIS, P1609, DOI 10.1109/ICCV.2013.203
   Fu H, 2012, LECT NOTES COMPUT SC, V7577, P86, DOI 10.1007/978-3-642-33783-3_7
   GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008
   Grubinger M., 2006, INT WORKSHOP ONTOIMA, P13
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Hai ZG, 2010, ARTIF INTELL, V174, P190, DOI 10.1016/j.artint.2009.11.014
   Hu JW, 2013, PATTERN RECOGN, V46, P936, DOI 10.1016/j.patcog.2012.09.010
   Huang ZX, 2010, FUTURE GENER COMP SY, V26, P400, DOI 10.1016/j.future.2009.07.006
   Jeon J., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P119, DOI DOI 10.1145/860435.860459
   Jin R., 2004, Proceedings of the 12th annual ACM international conference on Multimedia, P892, DOI DOI 10.1145/1027527.1027732
   Lavrenko V., 2003, NIPS
   Liu J, 2009, PATTERN RECOGN, V42, P218, DOI 10.1016/j.patcog.2008.04.012
   Maji S, 2008, PROC CVPR IEEE, P2245
   Makadia A, 2010, INT J COMPUT VISION, V90, P88, DOI 10.1007/s11263-010-0338-6
   Manevitz LM, 2002, J MACH LEARN RES, V2, P139, DOI 10.1162/15324430260185574
   Metzler D, 2004, LECT NOTES COMPUT SC, V3115, P42
   Moran S., 2014, P INT C MULTIMEDIA R, P113
   Srikanth M., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P552, DOI 10.1145/1076034.1076128
   Verma Y, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.25
   Wang C., 2008, P INT C CONT BAS IM, P113
   Wang M, 2014, INFORM SCIENCES, V262, P159, DOI 10.1016/j.ins.2013.11.005
   Wang ZY, 2013, MULTIMED TOOLS APPL, V67, P607, DOI 10.1007/s11042-012-1060-x
   Wei XY, 2011, IEEE T CIRC SYST VID, V21, P62, DOI 10.1109/TCSVT.2011.2105597
   Xiang Y, 2009, PROC CVPR IEEE, P1153, DOI 10.1109/CVPRW.2009.5206518
   Xie L, 2013, IEEE INT SYM MULTIM, P155, DOI 10.1109/ISM.2013.33
   Xu HJ, 2014, INT CONF SEMANT, P177, DOI 10.1109/SKG.2014.12
   Yavlinsky A, 2005, LECT NOTES COMPUT SC, V3568, P507
   Yohan Jin, 2005, 13th Annual ACM International Conference on Multimedia, P706
   Yu Y, 2013, INT J APPROX REASON, V54, P1373, DOI 10.1016/j.ijar.2013.06.003
   Zhang D, 2012, PATTERN RECOGNIT
   Zhang ST, 2012, IEEE T SYST MAN CY B, V42, P838, DOI 10.1109/TSMCB.2011.2179533
   Zhuge H, 2011, ARTIF INTELL, V175, P988, DOI 10.1016/j.artint.2010.09.009
   Zhuge H, 2010, FUTURE GENER COMP SY, V26, P408, DOI 10.1016/j.future.2009.08.012
NR 49
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6237
EP 6261
DI 10.1007/s11042-015-2568-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700010
DA 2024-07-18
ER

PT J
AU Yang, ZF
   Liao, YT
AF Yang, Zhi-Fang
   Liao, Ying-Ti
TI Intensity contrast masks for gender classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AdaBoost; Gender classification; Intensity contrast
ID FACE-RECOGNITION
AB This work develops effective masks for AdaBoost-based gender classification. A set of intensity contrast masks around small regions of two neighbor pixels is proposed. The design exploits the sharp intensity contrast that is common to the male face and the smooth intensity contrast that is typically exhibited by the female face. The number of weak classifiers is only approximately 0.5 % of the set of weak classifiers based on pixel comparisons that were proposed by S. Baluja and H. Rowley (Int J Comput Vis 71(1): 111-119, 2007). Experimental results demonstrate the feasibility of the proposed approach, and confirm the basic ideas on which this study is based. The first is that intensity contrast in face images is essential to gender classification, and the number of intensity contrast features are more required than are those intensity contrast features designed based on pixel comparisons. Second, structural information in face images may not enable features to be distinguished. Third, although intensity contrast is important to gender classification, other factors should be considered in designing a complete set of gender-related features.
C1 [Yang, Zhi-Fang; Liao, Ying-Ti] Natl Taipei Univ, Dept Comp Sci & Informat Engn, Taipei 237, Taiwan.
C3 National Taipei University
RP Yang, ZF (corresponding author), Natl Taipei Univ, Dept Comp Sci & Informat Engn, Taipei 237, Taiwan.
EM zfyang@mail.ntpu.edu.tw
RI Yin, Jing/KDO-6274-2024
CR Aghajanian J, 2010, P IEEE INT C COMP VI, P1125
   Ahmed A, 2008, LECT NOTES COMPUT SC, V5304, P69, DOI 10.1007/978-3-540-88690-7_6
   Baluja S, 2007, INT J COMPUT VISION, V71, P111, DOI 10.1007/s11263-006-8910-9
   Bekios-Calfa J, 2011, IEEE T PATTERN ANAL, V33, P858, DOI 10.1109/TPAMI.2010.208
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Du P, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 4, PROCEEDINGS, P657
   Gallagher AC, 2009, IEEE I CONF COMP VIS, P1187, DOI 10.1109/ICCV.2009.5459340
   Gallagher AC, 2009, PROC CVPR IEEE, P256, DOI 10.1109/CVPRW.2009.5206828
   Grangeiro F, 2009, INT CONF ACOUST SPEE, P1945, DOI 10.1109/ICASSP.2009.4959991
   Guodong Guo, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P2032, DOI 10.1109/ICCVW.2009.5457531
   Hadid A, 2009, PATTERN RECOGN, V42, P2818, DOI 10.1016/j.patcog.2009.02.011
   Kumar N, 2008, LECT NOTES COMPUT SC, V5305, P340, DOI 10.1007/978-3-540-88693-8_25
   Li HL, 2009, IEEE T MULTIMEDIA, V11, P77, DOI 10.1109/TMM.2008.2008922
   Li Z, 2010, IEEE INT C IM PROC, P45
   Lu HC, 2008, J REAL-TIME IMAGE PR, V3, P109, DOI 10.1007/s11554-008-0072-2
   Maekinen E, 2008, PATTERN RECOGN LETT, V29, P1544, DOI 10.1016/j.patrec.2008.03.016
   Mäkinen E, 2008, IEEE T PATTERN ANAL, V30, P541, DOI 10.1109/TPAMI.2007.70800
   Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227
   Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Shakhnarovich G., 2002, P INT C AUT FAC GEST
   Shen BC, 2009, INT CONF ACOUST SPEE, P521, DOI 10.1109/ICASSP.2009.4959635
   Toews M, 2009, IEEE T PATTERN ANAL, V31, P1567, DOI 10.1109/TPAMI.2008.233
   Varma M., 2009, Proceedings of the 26th Annual International Conference on Machine Learning, P1065, DOI DOI 10.1145/1553374.1553510
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wen-Sheng Chu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2636, DOI 10.1109/ICPR.2010.646
   Wu J, 2010, IMAGE VISION COMPUT, V28, P1039, DOI 10.1016/j.imavis.2009.09.003
   Yu K., 2009, Advances in Neural Information Processing Systems, P1889
NR 28
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6683
EP 6696
DI 10.1007/s11042-015-2599-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700031
DA 2024-07-18
ER

PT J
AU Boutellaa, E
   Boulkenafet, Z
   Komulainen, J
   Hadid, A
AF Boutellaa, Elhocine
   Boulkenafet, Zinelabidine
   Komulainen, Jukka
   Hadid, Abdenour
TI Audiovisual synchrony assessment for replay attack detection in talking
   face biometrics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audiovisual speech synchrony; Replay attack; Liveness detection; Talking
   face biometrics
ID PERSON AUTHENTICATION; ROBUST; FUSION; MOTION
AB Audiovisual speech synchrony detection is an important liveness check for talking face verification systems in order to make sure that the input biometric samples are actually acquired from the same source. In prior work, the used visual speech features have been mainly describing facial appearance or mouth shape in frame-wise manner, thus ignoring the lip motion between consecutive frames. Since also the visual speech dynamics are important, we take the spatiotemporal information into account and propose the use of space-time auto-correlation of gradients (STACOG) for measuring the audiovisual synchrony. For evaluating the effectiveness of the proposed approach, a set of challenging and realistic attack scenarios are designed by augmenting publicly available BANCA and XM2VTS datasets with synthetic replay attacks. Our experimental analysis shows that the STACOG features outperform the state of the art, e.g. discrete cosine transform based features, in measuring the audiovisual synchrony.
C1 [Boutellaa, Elhocine; Boulkenafet, Zinelabidine; Komulainen, Jukka; Hadid, Abdenour] Univ Oulu, Ctr Machine Vis Res Comp Sci & Engn, Oulu, Finland.
   [Boutellaa, Elhocine] Ctr Dev Technol Avancees, Telecom Div, Algiers, Algeria.
C3 University of Oulu
RP Boutellaa, E (corresponding author), Univ Oulu, Ctr Machine Vis Res Comp Sci & Engn, Oulu, Finland.; Boutellaa, E (corresponding author), Ctr Dev Technol Avancees, Telecom Div, Algiers, Algeria.
EM eboutell@ee.oulu.fi; zboulken@ee.oulu.fi; jukmaatt@ee.oulu.fi;
   hadid@ee.oulu.fi
RI Komulainen, Jukka/O-6240-2017
OI Komulainen, Jukka/0000-0002-0102-7868; Boutellaa,
   Elhocine/0000-0003-4140-6130
FU Algerian MESRS; CDTA [060/PNE/ENS/FINLANDE/2014-2015]; Academy of
   Finland; Infotech Oulu Doctoral Program
FX E. Boutellaa is acknowledging the financial support of the Algerian
   MESRS and CDTA under the grant number 060/PNE/ENS/FINLANDE/2014-2015.
   The support of the Academy of Finland and Infotech Oulu Doctoral Program
   is also acknowledged.
CR [Anonymous], 2000, NIPS
   Rúa EA, 2009, PATTERN ANAL APPL, V12, P271, DOI 10.1007/s10044-008-0121-2
   Bailly-Bailliére E, 2003, LECT NOTES COMPUT SC, V2688, P625
   Ben-Yacoub S, 1999, IEEE T NEURAL NETWOR, V10, P1065, DOI 10.1109/72.788647
   Bredin H, 2008, INT CONF ACOUST SPEE, P1693, DOI 10.1109/ICASSP.2008.4517954
   Chetty G, 2010, STUD COMPUT INTELL, V282, P59
   Chetty G, 2009, FUSION: 2009 12TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION, VOLS 1-4, P2255
   El-Sallam AA, 2011, PATTERN RECOGN LETT, V32, P780, DOI 10.1016/j.patrec.2011.01.001
   Eveno N, 2005, ISPA 2005: PROCEEDINGS OF THE 4TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P257, DOI 10.1109/ISPA.2005.195419
   Faraj MI, 2007, PATTERN RECOGN LETT, V28, P1368, DOI 10.1016/j.patrec.2007.02.017
   Fauve B, 2008, INT CONF ACOUST SPEE, P4137, DOI 10.1109/ICASSP.2008.4518565
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Karam W, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/746481
   Kobayashi T, 2008, LECT NOTES COMPUT SC, V5302, P346, DOI 10.1007/978-3-540-88682-2_27
   Kobayashi T, 2012, PATTERN RECOGN LETT, V33, P1188, DOI 10.1016/j.patrec.2012.01.007
   Liu YY, 2010, PATTERN RECOGN LETT, V31, P696, DOI 10.1016/j.patrec.2009.07.019
   Marcel S, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6524-8
   Messer K., 1999, 2 INT C AUD VID BAS, V964, P965
   Rodrigues RN, 2009, J VISUAL LANG COMPUT, V20, P169, DOI 10.1016/j.jvlc.2009.01.010
   Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2
   Uricar M, 2015, IEEE INT C AUT FAC G
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
   Zhu ZY, 2013, INT CONF MACH LEARN, P973, DOI 10.1109/ICMLC.2013.6890423
NR 24
TC 14
Z9 17
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 5329
EP 5343
DI 10.1007/s11042-015-2848-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700028
DA 2024-07-18
ER

PT J
AU Lee, SK
   Yoo, S
   Kim, H
AF Lee, Suk Kyu
   Yoo, Seungho
   Kim, Hwangnam
TI Devising a user collaboration scheme to automatically generate videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile film; User collaboration scheme; Multimedia application;
   Automatic film editing
ID CLASSIFICATION
AB Nowadays, interacting video contents with the mobile device is a prevalent activity. Generating and sharing the created digitalized stories through a video sharing social networking service is popular among people. Nonetheless, there is no distinctive approach for creating contents with the mobile devices; rather, it follows the traditional media production method. Besides, generating contents does not embrace the idea of utilizing mobile devices' computing and communication abilities to generate a video content. In this paper, we propose EMVideo. EMVideo is a novel collaboration scheme for mobile devices to automatically edit video frames into a video. We believe that the proposed scheme can be utilized as an innovative application for digital storytelling.
C1 [Lee, Suk Kyu; Yoo, Seungho; Kim, Hwangnam] Korea Univ, Sch Elect Engn, Seoul, South Korea.
C3 Korea University
RP Kim, H (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM sklee25@korea.ac.kr; pen0423@korea.ac.kr; hnkim@korea.ac.kr
RI Yoo, Seungho/JCN-7474-2023
OI Yoo, Seungho/0000-0002-0510-535X
FU National Research Foundation of Korea (NRF) - Ministry of Education
   [NRF-2013R1A1A2010388]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2013R1A1A2010388).
CR Ahlstrom BD, 2010, US Patent, Patent No. [7,739,599, 7739599]
   Ahmed DT, 2012, MULTIMED TOOLS APPL, P1
   [Anonymous], 2011, TIMES LA
   [Anonymous], 1966, The hidden dimension: Man's use of space in public and private
   [Anonymous], 2013, KT 3 OLLEH INT SMART
   Botello S, 2014, PRODUCTIONS INT MOBI
   Bradley C, 2009, ISS ONLINE EDUC, P157
   Brezeale D, 2008, IEEE T SYST MAN CY C, V38, P416, DOI 10.1109/TSMCC.2008.919173
   Burgess J., 2009, YouTube: Online video and participatory culture
   Burrows G, 2005, LIVING GALLERY INVES
   Chambel T, 2007, COMPUT GRAPH-UK, V31, P837, DOI 10.1016/j.cag.2007.08.004
   Christie M, 2012, WORKSH INT CIN ED
   Daniyal F, 2010, MULTIMED TOOLS APPL, V46, P235, DOI 10.1007/s11042-009-0355-z
   Davis M, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P185
   Herrington A, 2009, FACULTY ED PAPERS, P78
   Lee SK, 2014, IEEE GLOB COMM CONF, P2941, DOI 10.1109/GLOCOM.2014.7037255
   Lee SK, 2009, IEEE INT CON MULTI, P1708, DOI 10.1109/ICME.2009.5202850
   Machnicki E., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4673, P208, DOI 10.1117/12.449981
   Philipose M., 2013, J VISUAL COMMUNICATI
   Ramirez A, 2004, P ICME 2004
   Roach MJ, 2001, INT CONF ACOUST SPEE, P1557, DOI 10.1109/ICASSP.2001.941230
   Roussel N, 2004, IEEE MULTIMEDIA, V11, P12, DOI 10.1109/MMUL.2004.15
   Scheible J., 2005, MULTIMEDIA 05, P199, DOI DOI 10.1145/1101149.1101178
   Sheppard Jennifer, 2009, Computers and Composition, V26, P122, DOI 10.1016/j.compcom.2009.02.004
   Thornton P, 2005, J COMPUT ASSIST LEAR, V21, P217, DOI 10.1111/j.1365-2729.2005.00129.x
   Truong BT, 2000, INT C PATT RECOG, P230, DOI 10.1109/ICPR.2000.902901
NR 26
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4615
EP 4638
DI 10.1007/s11042-015-2495-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700022
DA 2024-07-18
ER

PT J
AU Chen, Z
   Hou, XS
   Gong, C
   Qian, XM
AF Chen, Zan
   Hou, Xingsong
   Gong, Chen
   Qian, Xueming
TI Compressive sensing reconstruction for compressible signal based on
   projection replacement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressive sensing; Orthogonal projection; TSW-CS; OMP
AB Compressive sensing can reconstruct compressible or sparse signal at the under-sampling rate. However small coefficients of the compressible signal with large number but low energy are hard to be reconstructed, while also infect the accuracy of the big coefficients. In this reason, for the compressive sensing algorithms such as orthogonal match pursuit (OMP) and tree-structed wavelet compressive sensing (TSW-CS), an assumed error is in the measurement model, which makes the reconstructed results not satisfy the original measurement model. Aiming at this problem, we propose the projection replacement (PR) algorithm by building the measurement space and its orthogonal complement space with singular value decomposition, and replacing the projection in measurement space of the reconstructed result with the pseudo-inverse one. The proposed PR algorithm eliminates the hypothetic measurement error in OMP and TSW-CS reconstructed model, and it guarantees theoretically that the PR results have a smaller error. Its effectiveness is verified experimentally with OMP and TSW-CS. The proposed algorithm serves as a good reconstruction algorithm for the CS-based applications such as image coding, super-resolution, video retrieval etc.
C1 [Chen, Zan; Hou, Xingsong; Qian, Xueming] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
   [Gong, Chen] Univ Sci & Technol China, Sch Elect & Informat Engn, Hefei 230026, Peoples R China.
C3 Xi'an Jiaotong University; Chinese Academy of Sciences; University of
   Science & Technology of China, CAS
RP Hou, XS (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM zancheng.1989@stu.xjtu.edu.cn; houxs-xjtu@qq.com
RI GONG, CHEN/JDW-5727-2023
FU National Natural Science Foundation of China [61373113]; Fundamental
   Research for the Central University [xjj2012023]
FX This work was supported by National Natural Science Foundation of China
   (No. 61373113) and the Fundamental Research for the Central University
   (No. xjj2012023).
CR Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Deng CW, 2012, IEEE T MULTIMEDIA, V14, P278, DOI 10.1109/TMM.2011.2181491
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fannjiang A, 2012, CONF REC ASILOMAR C, P411, DOI 10.1109/ACSSC.2012.6489036
   He LH, 2010, IEEE SIGNAL PROC LET, V17, P233, DOI 10.1109/LSP.2009.2037532
   He LH, 2009, IEEE T SIGNAL PROCES, V57, P3488, DOI 10.1109/TSP.2009.2022003
   Hou XS, 2013, IEEE T GEOSCI REMOTE, V51, P527, DOI 10.1109/TGRS.2012.2203309
   Ji SH, 2008, IEEE T SIGNAL PROCES, V56, P2346, DOI 10.1109/TSP.2007.914345
   Kulkarin N, 2011, IEEE T CIRCUITS SYST, V22, P778
   Liu LW, 2015, MULTIMED TOOLS APPL, V74, P467, DOI 10.1007/s11042-014-2002-6
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Ruiz P, 2011, 2011 IEEE INT C MULT, P1
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Van Loan CF, 2013, MATRIX COMPUTATION
   Wang L. J., 2008, P IEEE WORKSH MULT S, V1, P445
   Xu L, 2010, LECT NOTES COMPUT SC, V6221, P338
NR 16
TC 6
Z9 6
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2565
EP 2578
DI 10.1007/s11042-015-2578-5
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000010
DA 2024-07-18
ER

PT J
AU Li, Q
   Han, YH
   Dang, JW
AF Li, Qiang
   Han, Yahong
   Dang, Jianwu
TI Sketch4Image: a novel framework for sketch-based image retrieval based
   on product quantization with coding residuals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sketch-based image retrieval; Product quantization; Sparse coding;
   Residual
ID CLASSIFICATION; MPEG-7
AB Sketch-based Image Retrieval (SBIR) is one important branch of Content-based Image Retrieval (CBIR). SBIR means dealing with retrieval using simple edge or contour images. However, SBIR is more difficult than CBIR due to the lack of visual information, this makes the Bag-of-Words (BoW) or codebook in SBIR hard to construct. In this paper, we propose a novel SBIR framework based on Product Quantization (PQ) with sparse coding (SC) to construct an optimized codebook. By using state-of-the-art local descriptors, we transform sketch images into features and then build the optimized codebook using PQ-based SC. In the retrieval stage, we can obtain a better representation of the query sketch and testing images by the optimized codebook with coding quantization residuals, by which the information loss during feature encoding process can be reduced; similarity computing is implemented by comparing the feature histograms between a query sketch and the testing data for the final results. We demonstrate the superiority and effectiveness of the proposed SBIR by comparing it with several state-of-the-art methods on three public sketch datasets.
C1 [Li, Qiang; Han, Yahong; Dang, Jianwu] Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
   [Han, Yahong; Dang, Jianwu] Tianjin Univ, Tianjin Key Lab Cognit Comp & Applicat, Tianjin 300072, Peoples R China.
   [Dang, Jianwu] Japan Adv Inst Sci & Technol, Sch Informat Sci, Nomi, Ishikawa, Japan.
C3 Tianjin University; Tianjin University; Japan Advanced Institute of
   Science & Technology (JAIST)
RP Han, YH (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.; Han, YH (corresponding author), Tianjin Univ, Tianjin Key Lab Cognit Comp & Applicat, Tianjin 300072, Peoples R China.
EM liqiang142601@hotmail.com; yahong@tju.edu.cn; jdang@jaist.ac.jp
RI Yu, Yue/JWP-9103-2024; zhen, li/KGK-6604-2024
FU National Program on Key Basic Research Project (973 Program)
   [2013CB329301]; Major Project of National Social Science Fund
   [14ZDB153]; NSFC [61202166, 61472276]; Ministry of Education of China
   [20120032120042]
FX This work is partly supported by National Program on Key Basic Research
   Project (973 Program, under Grant 2013CB329301), the Major Project of
   National Social Science Fund (under Grant 14ZDB153), the NSFC (under
   Grant 61202166 and 61472276), and Doctoral Fund of Ministry of Education
   of China (under Grant 20120032120042).
CR Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Cao XC, 2013, IEEE I CONF COMP VIS, P313, DOI 10.1109/ICCV.2013.46
   Cao Y, 2011, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2011.5995460
   Chalechale A, 2005, IEEE T SYST MAN CY A, V35, P28, DOI 10.1109/TSMCA.2004.838464
   Chang N. S., 1979, Proceedings of COMPSAC the IEEE Computer Society's Third International Computer Software and Applications Conference, P325
   Cover T. M., 1991, ELEMENTS INFORM THEO
   Eitz M., 2012, ACM T GRAPHIC, V31, P1, DOI DOI 10.1145/2185520.2335395
   Eitz M, 2011, IEEE T VIS COMPUT GR, V17, P1624, DOI 10.1109/TVCG.2010.266
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Ge TZ, 2014, PROC CVPR IEEE, P939, DOI 10.1109/CVPR.2014.125
   Ge TZ, 2014, IEEE T PATTERN ANAL, V36, P744, DOI 10.1109/TPAMI.2013.240
   Han YH, 2015, IEEE T NEUR NET LEAR, V26, P252, DOI 10.1109/TNNLS.2014.2314123
   Han YH, 2014, IEEE T MULTIMEDIA, V16, P1115, DOI 10.1109/TMM.2014.2306092
   Hu R, 2013, COMPUT VIS IMAGE UND, V117, P790, DOI 10.1016/j.cviu.2013.02.005
   Hurtut T., 2008, Pictorial analysis of line-drawings, P123
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Kalantidis Y, 2014, PROC CVPR IEEE, P2329, DOI 10.1109/CVPR.2014.298
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Martínez JM, 2002, IEEE MULTIMEDIA, V9, P83, DOI 10.1109/MMUL.2002.1022862
   Pauleve L, 2010, PATTERN RECOGN LETT, V31, P1348, DOI 10.1016/j.patrec.2010.04.004
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Saavedra J. M., 2013, MULTIMED TOOLS APPL, P1
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Wang JW, 2012, PATTERN RECOGN LETT, V33, P134, DOI 10.1016/j.patrec.2011.09.042
   Wang XG, 2011, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2011.5995696
   Won CS, 2002, ETRI J, V24, P23, DOI 10.4218/etrij.02.0102.0103
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang Y, 2014, IEEE T MULTIMEDIA, V16, P1677, DOI 10.1109/TMM.2014.2323014
   Yang Y, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2457450.2457456
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Zhang XM, 2012, WORLD WIDE WEB, V15, P233, DOI 10.1007/s11280-011-0132-6
   [No title captured]
NR 32
TC 6
Z9 7
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2419
EP 2434
DI 10.1007/s11042-015-2645-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000002
DA 2024-07-18
ER

PT J
AU Fu, HY
   Kong, XW
   Wang, ZF
AF Fu, Haiyan
   Kong, Xiangwei
   Wang, Zhenfan
TI Binary code reranking method with weighted hamming distance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Large-scale image retrieval; Image hashing; Binary code reranking;
   Distance weights based reranking method; Bit importance based reranking
   method
ID SEARCH
AB Due to its compact binary codes and efficient search scheme, image hashing method is suitable for large-scale image retrieval. In image hashing methods, Hamming distance is used to measure similarity between two points. For K-bit binary codes, the Hamming distance is an int and bounded by K. Therefore, there are many returned images sharing the same Hamming distances with the query. In this paper, we propose two efficient image ranking methods, which are distance weights based reranking method (DWR) and bit importance based reranking method (BIR). DWR method aim to rerank PCA hash codes. DWR averages Euclidean distance of equal hash bits to these bits with different values, so as to obtain the weights of hash codes. BIR method is suitable for all type of binary codes. Firstly, feedback technology is adopted to detect the importance of each binary bit, and then big weights are assigned to important bits and small weights are assigned to minor bits. The advantage of this proposed method is calculation efficiency. Evaluations on two large-scale image data sets demonstrate the efficacy of our methods.
C1 [Fu, Haiyan; Kong, Xiangwei; Wang, Zhenfan] Dalian Univ Technol, Sch Informat & Commun Engn, Dalian, Peoples R China.
C3 Dalian University of Technology
RP Kong, XW (corresponding author), Dalian Univ Technol, Sch Informat & Commun Engn, Dalian, Peoples R China.
EM fuhy@dlut.edu.cn; kongxwpurdue@gmail.com; wangzhf@dlut.edu.cn
RI Kong, Xiangwei/IWL-9350-2023
FU Fundamental Research Funds for the Central Universities [DUT14QY03]
FX The work is partially supported by the Fundamental Research Funds for
   the Central Universities DUT14QY03.
CR Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   [Anonymous], P 25 VLDB C ED SCOTL
   [Anonymous], 2008, Proceedings of the 21st International Conference on Neural Information Processing Systems
   Charikar M. S., 2002, P 34 ANN ACM S THEOR, P380
   Fu HY, 2013, NEUROCOMPUTING, V122, P480, DOI 10.1016/j.neucom.2013.05.033
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   Indyk P., 1998, 30 S THEOR COMP
   Jiang Y., 2011, P ACM INT C MULT RET
   Jianhui Zhou, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2481, DOI 10.1109/ICIP.2011.6116164
   Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994
   Wang Jun., 2010, ICML, P1127
   Wang M, 2010, ACM T INTEL SYST TEC, V1, DOI 10.1145/1858948.1858956
   Wang M, 2010, IEEE T MULTIMEDIA, V12, P829, DOI 10.1109/TMM.2010.2055045
   Xie X, 2008, P IEEE, V96, P589, DOI 10.1109/JPROC.2008.916351
   Xu H, 2011, IEEE I CONF COMP VIS, P1631, DOI 10.1109/ICCV.2011.6126424
   Zhang X, 2012, PROC CVPR IEEE, P2058, DOI 10.1109/CVPR.2012.6247910
NR 19
TC 5
Z9 7
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 3
BP 1391
EP 1408
DI 10.1007/s11042-014-2087-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HW
UT WOS:000371309600003
DA 2024-07-18
ER

PT J
AU Hong, CQ
   Zhu, JK
   Yu, J
   Cheng, J
   Chen, XH
AF Hong, Chaoqun
   Zhu, Jianke
   Yu, Jun
   Cheng, Jun
   Chen, Xuhui
TI Realtime and robust object matching with a large number of templates
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Realtime object matching; Dominant orientation templates; Compact
   representation; Partial occlusion handling
ID IMAGE; FEATURES; GRAPH
AB Most of conventional object matching methods are based on comparing local features, which are too computational demanding. Recently, Dominant Orientation Templates (DOT) were proposed to solve the efficiency issue. Although DOT obtains promising results, it still suffers the problem of wasting too many bits in representation and fragility when partial occlusion occurs. As the number of templates increase, the performance will decrease. Therefore, we propose a compact DOT representation with a fast partial occlusion handling approach. Instead of using seven orientations in the original implementation, we employ single orientation of the highest gradients for the proposed compact DOT representation (C-DOT). Consequently, the size of feature vectors is reduced from 8 bits to 3 bits. To efficiently tackle the partial occlusion, we introduce the C-DOT similarity map to store the matching scores of individual grids in each sliding window, which is used to further infer the occlusion map. The experimental results demonstrate that the proposed method outperforms DOT.
C1 [Hong, Chaoqun; Chen, Xuhui] Xiamen Univ Technol, Sch Comp & Informat Engn, Xiamen, Peoples R China.
   [Zhu, Jianke] Zhejiang Univ, Coll Comp Sci, Hangzhou 310003, Zhejiang, Peoples R China.
   [Yu, Jun] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Zhejiang, Peoples R China.
   [Cheng, Jun] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
   [Cheng, Jun] Chinese Univ Hong Kong, Shatin, Hong Kong, Peoples R China.
C3 Xiamen University of Technology; Zhejiang University; Hangzhou Dianzi
   University; Chinese Academy of Sciences; Shenzhen Institute of Advanced
   Technology, CAS; Chinese University of Hong Kong
RP Yu, J (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Zhejiang, Peoples R China.
EM zju.yujun@gmail.com
FU Natural Science Foundation of China [61472110, 61202145, 61100104,
   61065007]; Program for New Century Excellent Talents in University
   [NECT-12-0323]; Natural Science Foundation of Fujian Province of China
   [2012J01287, 2014J01256]
FX This work is supported by the Natural Science Foundation of China
   (61472110, 61202145, 61100104 and 61065007), the Program for New Century
   Excellent Talents in University (No. NECT-12-0323) and the Natural
   Science Foundation of Fujian Province of China (2012J01287 and
   2014J01256).
CR [Anonymous], ACM T MULTIMEDIA COM
   [Anonymous], 2009, P 17 ACM INT C MULTI
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bregonzio M, 2009, PROC CVPR IEEE, P1948, DOI 10.1109/CVPRW.2009.5206779
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Gavrila D. M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P87, DOI 10.1109/ICCV.1999.791202
   Guan NY, 2012, IEEE T NEUR NET LEAR, V23, P1087, DOI 10.1109/TNNLS.2012.2197827
   Guan NY, 2012, IEEE T SIGNAL PROCES, V60, P2882, DOI 10.1109/TSP.2012.2190406
   Hajdu A, 2007, IEEE T IMAGE PROCESS, V16, P2048, DOI 10.1109/TIP.2007.901819
   Hinterstoisser S, 2010, PROC CVPR IEEE, P2257, DOI 10.1109/CVPR.2010.5539908
   Hong Z, 2013, IEEE POW EN SOC GEN, P1
   Hong ZB, 2012, LECT NOTES COMPUT SC, V7572, P513, DOI 10.1007/978-3-642-33718-5_37
   Ke Y, 2004, PROC CVPR IEEE, P506
   Kim HY, 2010, PATTERN RECOGN, V43, P859, DOI 10.1016/j.patcog.2009.08.005
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Klimovitski A, 2001, INTEL DEV UPDATE MAR, P1
   Lampert CH, 2010, PROC CVPR IEEE, P1022, DOI 10.1109/CVPR.2010.5540107
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Lampert CH, 2009, IEEE T PATTERN ANAL, V31, P2129, DOI 10.1109/TPAMI.2009.144
   Li HJ, 2013, MULTIMEDIA SYST, V19, P37, DOI 10.1007/s00530-012-0265-1
   Li HJ, 2010, IEEE T CIRC SYST VID, V20, P351, DOI 10.1109/TCSVT.2009.2035833
   Li P, 2013, IEEE T MULTIMEDIA, V15, P141, DOI 10.1109/TMM.2012.2199970
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   McFee B, 2011, IEEE T IMAGE PROCESS, V20, P570, DOI 10.1109/TIP.2010.2068556
   Mezaris V, 2004, IEEE T CIRC SYST VID, V14, P606, DOI 10.1109/TCSVT.2004.826768
   Olson CF, 1997, IEEE T IMAGE PROCESS, V6, P103, DOI 10.1109/83.552100
   Ouyang WL, 2010, PROC CVPR IEEE, P3050, DOI 10.1109/CVPR.2010.5540058
   Rosten E, 2005, IEEE I CONF COMP VIS, P1508
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Santner J, 2010, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2010.5540145
   Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111
   Steger C, 2002, INT ARCH PHOTOGRAMME
   Takacs G, 2010, PROC CVPR IEEE, P934, DOI 10.1109/CVPR.2010.5540116
   Taylor S., 2009, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR'09), P15
   Wang M, 2013, IEEE T IMAGE PROCESS, V22, P1395, DOI 10.1109/TIP.2012.2231088
   Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397
   Wang M, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2333112.2333120
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wei YC, 2010, PROC CVPR IEEE, P3003, DOI 10.1109/CVPR.2010.5540049
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Willems Geert., 2008, PROCEEDING 1 ACM INT, P283
   Wu C., 2007, Siftgpu: A gpu implementation of david lowe's scale invariant feature transform (sift)
   Wu Z, 2009, PROC CVPR IEEE, P25, DOI 10.1109/CVPRW.2009.5206566
   Zha ZJ, 2013, IEEE T CIRC SYST VID, V23, P856, DOI 10.1109/TCSVT.2012.2226526
   Zha ZJ, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823747
   Zhang ZQ, 2010, PROC CVPR IEEE, P1086, DOI 10.1109/CVPR.2010.5540095
   Zhou Tianyi, 2013, Proceedings of the Twenty-Third international joint conference on Artificial Intelligence, P1946
NR 51
TC 10
Z9 10
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 3
BP 1459
EP 1480
DI 10.1007/s11042-014-2305-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HW
UT WOS:000371309600007
DA 2024-07-18
ER

PT J
AU Shen, ZY
   Ni, JQ
   Chen, CL
AF Shen, Zhaoyi
   Ni, Jiangqun
   Chen, Chenglong
TI Blind detection of median filtering using linear and nonlinear
   descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Median filtering; Digital image forensics; Linear prediction model; LBP
ID TRACES
AB Recently, for the recovery of images' processing history, passive forensics of possible manipulations has attracted wide interest. In particular, due to highly non-linearity, median filtering (MF) usually serves as an effective tool of counter forensic techniques for other image operations. Therefore, the importance of median filtering detection is self-evident. In this paper, through analysing the pixel differences of images, we found the indications to study the complex correlations introduced by median filtering and adopt two sets of describing features to measure them. More Specifically, we utilize a linear prediction model for the differences of image that is computed along a specific direction and estimate the prediction coefficients to construct a linear descriptor L. Besides, we make use of the histogram of rotation invariant local binary pattern (LBP) to form a nonlinear descriptor N. According to our observation, we also propose an enhanced feature EF to further improve the detection performance. Based on these, we present a novel median filtering detection scheme incorporating both the linear and nonlinear descriptors. Extensive experiments are carried out, which demonstrate that our proposed scheme gains favorable performance comparing to state-of-the-art methods, especially for low resolution images and JPEG compressed images, and shows resistance to noise attack.
C1 [Shen, Zhaoyi; Ni, Jiangqun; Chen, Chenglong] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University
RP Shen, ZY (corresponding author), Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
EM shenzhyi@foxmail.com; issjqni@mail.sysu.edu.cn; c.chenglong@gmail.com
FU National Natural Science Foundation of China [61379156]; National
   Research Foundation for the Doctoral Program of Higher Education of
   China [20120171110037]; Natural Science Foundation of Guangdong
   [S2012020011114]
FX This work is supported by National Natural Science Foundation of China
   (No. 61379156), the National Research Foundation for the Doctoral
   Program of Higher Education of China (No. 20120171110037), and the Key
   Program of Natural Science Foundation of Guangdong (No. S2012020011114).
CR [Anonymous], 2013, MATH PROBLEMS ENG
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bohme R., 2012, DIGITAL IMAGE FORENS, P327, DOI [DOI 10.1007/978-1-4614-0757-7_12, 10.1007/978-1-4614-0757-7_12]
   Cao G, 2010, IEEE INT CON MULTI, P89, DOI 10.1109/ICME.2010.5583869
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chenglong Chen, 2012, Digital-Forensics and Watermarking 10th International Workshop, IWDW 2011. Revised Selected Papers, P361, DOI 10.1007/978-3-642-32205-1_29
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Kirchner M, 2010, IS T SPIE ELECT IMAG, p[754, 110, 110]
   Kirchner M, 2008, IEEE T INF FOREN SEC, V3, P582, DOI 10.1109/TIFS.2008.2008214
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P480, DOI 10.1109/TIFS.2010.2051426
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Stamm MC, 2011, IEEE T INF FOREN SEC, V6, P1050, DOI 10.1109/TIFS.2011.2119314
   Stamm MC, 2010, IEEE IMAGE PROC, P2109, DOI 10.1109/ICIP.2010.5652553
   Stamm MC, 2010, INT CONF ACOUST SPEE, P1698, DOI 10.1109/ICASSP.2010.5495488
   *US DEP AGR, 2002, NAT RES CONS SERV PH
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
NR 19
TC 19
Z9 19
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 2327
EP 2346
DI 10.1007/s11042-014-2407-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000027
DA 2024-07-18
ER

PT J
AU Heo, K
   Kim, J
   Yoon, C
AF Heo, Kyoungwoo
   Kim, Jinsul
   Yoon, Changwoo
TI Tree construction algorithm for virtual content distribution network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual content delivery network; Rateless codes; Multi-tree structure;
   Source transmission rate
AB Recently, the technology of multimedia content delivery is spotlighted due to many multimedia services. Specially, the needs of a huge content delivery technology is increasing because the period of huge multimedia content creation becomes shorter. The content delivery network (CDN) is a popular solution for distributing a multimedia content using physical resources. However, the CDN cannot provide a flexible service to content providers because of cost issue. In this paper, we aim to build a virtual content delivery network (VCDN) that each service provider own their independent service delivery and distribution network virtually. The proposed VCDN system uses a rateless codes for avoiding computational overhead and limits increase of the streaming delay. The proposed VCDN system builds a hierarchical tree structure that minimizes the time complexity of source nodes and reduces content distribution time by using rateless codes. The proposed VCDN system can support variety of social media services because its flexibility.
C1 [Heo, Kyoungwoo; Yoon, Changwoo] Univ Sci & Technol, Elect & Telecommun Res Inst, 218 Gajeong Ro, Daejeon 305700, South Korea.
   [Kim, Jinsul] Chonnam Natl Univ, Dept Elect & Comp Engn, Kwangju 500757, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   University of Science & Technology (UST); Chonnam National University
RP Heo, K (corresponding author), Univ Sci & Technol, Elect & Telecommun Res Inst, 218 Gajeong Ro, Daejeon 305700, South Korea.
EM hkw06@etri.re.kr; jsworld@chonnam.ac.kr; cwyoon@etri.re.kr
FU Korea Communications Agency (KCA) in Korea
FX This research was supported in part by the Korea Communications Agency
   (KCA) in Korea under the title of "The development of Computing-Embedded
   Media Integrated Delivery System which supporting High Definition Media
   Services".
CR Adler M, 2011, COMPUT NETW
   Andreev K., 2011, CORR, Vabs/1109.4114
   Barla B, 2012, IEEE
   Barla IB, 2013, 2013 9 INT C IEEE
   Cho K, 2011, IEEE COMMUN MAG, V49, P156, DOI 10.1109/MCOM.2011.6035830
   Gibbs R, 2012, TECHNICAL REPORT
   Grangetto M, 2009, IEEE INT CON MULTI, P1500, DOI 10.1109/ICME.2009.5202788
   Krohn MN, 2004, SECURITY PRIVACY
   Liu C, 2012, SIGNAL PROCESS IMAGE
   Mladenov T, 2010, IEEE T CONSUM ELECT
   Oh HR, 2011, COMPUT NETW
   Um TW, 2013, MULTIMED TOOLS APPL, V65, P187, DOI 10.1007/s11042-011-0778-1
   Wu C, 2008, IEEE T PARALL DISTR, V19, P77, DOI 10.1109/TPDS.2007.1119
   Zhou F., 2012, ACM NOSSDAV
NR 14
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 131
EP 144
DI 10.1007/s11042-014-2277-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500007
DA 2024-07-18
ER

PT J
AU Savelonas, MA
   Pratikakis, I
   Sfikas, K
AF Savelonas, Michalis A.
   Pratikakis, Ioannis
   Sfikas, Konstantinos
TI An overview of partial 3D object retrieval methodologies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Partial 3D object retrieval; Interest point detection; View-based
   retrieval; Part-based retrieval; Bag of visual words
ID 3-D MODEL SEARCH; RECOGNITION; IMAGES; DESCRIPTORS; WORDS
AB This work offers an overview of the state-of-the-art on the emerging area of 3D object retrieval based on partial queries. This research area is associated with several application domains, including face recognition and digital libraries of cultural heritage objects. The existing partial 3D object retrieval methods can be mainly classified as: i) view-based, ii) part-based, iii) bag of visual words (BoVW)-based, and iv) hybrid methods combining these three main paradigms or methods which cannot be straightforwardly classified. Several methodological aspects are identified, including the use of interest points and the exploitation of 2.5D projections, whereas the available evaluation datasets and campaigns are addressed. A thorough discussion follows, identifying advantages and limitations.
C1 [Savelonas, Michalis A.; Pratikakis, Ioannis; Sfikas, Konstantinos] ATHENA Res & Innovat Ctr, GR-67100 Xanthi, Greece.
   [Savelonas, Michalis A.; Pratikakis, Ioannis] Democritus Univ Thrace, Dept Elect & Comp Engn, GR-67100 Xanthi, Greece.
C3 Democritus University of Thrace
RP Savelonas, MA (corresponding author), ATHENA Res & Innovat Ctr, GR-67100 Xanthi, Greece.
EM msavel@di.uoa.gr; ipratika@ee.duth.gr; ksfikas@di.uoa.gr
RI PRATIKAKIS, IOANNIS/AAD-3387-2019
OI PRATIKAKIS, IOANNIS/0000-0002-4124-3688; Sfikas,
   Konstantinos/0000-0002-9173-4557
FU European Union [600533 PRESIOUS]
FX This study received funding from the European Union's Seventh Framework
   Programme (FP7/2007-2013) under grant agreement no 600533 PRESIOUS.
CR Adán A, 2011, PATTERN RECOGN LETT, V32, P1337, DOI 10.1016/j.patrec.2011.03.016
   Agathos A, 2010, VISUAL COMPUT, V26, P1301, DOI 10.1007/s00371-010-0523-1
   Agathos A, 2010, VISUAL COMPUT, V26, P63, DOI 10.1007/s00371-009-0383-8
   Akgul C, 2009, P EUR 3DOR WORKSH
   [Anonymous], EUR WORKSH 3D OBJ RE
   [Anonymous], P IEEE SHAP MOD INT
   [Anonymous], SMI
   [Anonymous], P 20 ACM INT C MULT
   Atmosukarto I, 2013, INT J MULTIMED INF R, V2, P103, DOI 10.1007/s13735-012-0015-3
   Axenopoulos A, 2009, P EUR 3DOR WORKSH
   Biasotti S, 2006, COMPUT AIDED DESIGN, V38, P1002, DOI 10.1016/j.cad.2006.07.003
   BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Chen H, 2004, INT C PATT RECOG, P136, DOI 10.1109/ICPR.2004.1334487
   Chen H, 2007, PATTERN RECOGN LETT, V28, P1252, DOI 10.1016/j.patrec.2007.02.009
   Cornea ND, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P366, DOI 10.1109/SMI.2005.1
   Daras P, 2006, IEEE T MULTIMEDIA, V8, P101, DOI 10.1109/TMM.2005.861287
   Daras P, 2010, INT J COMPUT VISION, V89, P229, DOI 10.1007/s11263-009-0277-2
   Daras P, 2009, INT WORK CONTENT MUL, P115, DOI 10.1109/CBMI.2009.15
   Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113
   Dutagaci H, 2009, P 2 EUR WORKSH 3D OB, P69
   Eberhart R. C., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), P1927, DOI 10.1109/CEC.1999.785508
   Furuya T., 2009, P ACM INT C IM VID R, P1
   Gal R, 2007, IEEE T VIS COMPUT GR, V13, P261, DOI 10.1109/TVCG.2007.45
   Gao Y, 2010, P ACM INT C MULT FIR, P955
   Gao Y, 2010, P ACM C MULT, P1711
   Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Gao Y, 2011, SIGNAL PROCESS-IMAGE, V26, P39, DOI 10.1016/j.image.2010.10.006
   Gao Y, 2010, NEUROCOMPUTING, V73, P1900, DOI 10.1016/j.neucom.2009.11.050
   Gao Y, 2010, PATTERN RECOGN, V43, P1142, DOI 10.1016/j.patcog.2009.07.012
   Germann M, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P81
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Giorgi D, 2007, P EUR 3DOR WORKSH
   Hartveldt J, 2009, P EUR 3DOR WORKSH
   Hetzel G, 2001, PROC CVPR IEEE, P394
   Hoffman DD, 1997, COGNITION, V63, P29, DOI 10.1016/S0010-0277(96)00791-3
   Jayanti S, 2006, COMPUT AIDED DESIGN, V38, P939, DOI 10.1016/j.cad.2006.06.007
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Kazhdan M., 2003, Symposium on Geometry Processing, P156
   Kim DH, 2004, LECT NOTES COMPUT SC, V3332, P238
   Koutsoudis A, 2013, 3D POTTERY CONTENT B
   Lavoué G, 2012, VISUAL COMPUT, V28, P931, DOI 10.1007/s00371-012-0724-x
   Li B, 2013, MULTIMED TO IN PRESS
   Li F, 2010, SIGNAL PROCESS-IMAGE, V25, P18, DOI 10.1016/j.image.2009.11.001
   Li PJ, 2013, MULTIMED TOOLS APPL, V65, P335, DOI 10.1007/s11042-012-1000-9
   Lian ZH, 2010, INT J COMPUT VISION, V89, P130, DOI 10.1007/s11263-009-0295-0
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marton ZC, 2009, IEEE INT CONF ROBOT, P2829
   Mian AS, 2006, IEEE T PATTERN ANAL, V28, P1584, DOI 10.1109/TPAMI.2006.213
   O'hara Stephendraper., 2011, Introduction to the Bag of Features Paradigm for Image Classification and Retrieval
   Ohbuchi R, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P93, DOI 10.1109/SMI.2008.4547955
   Ohkita Y, 2012, IEEE INT CONF MULTI, P593, DOI 10.1109/ICMEW.2012.109
   Papadakis P, 2008, P EUR 3DOR WORKSH
   Papadakis P, 2007, PATTERN RECOGN, V40, P2437, DOI 10.1016/j.patcog.2006.12.026
   Papadakis P, 2010, INT J COMPUT VISION, V89, P177, DOI 10.1007/s11263-009-0281-6
   Pauly M., 2005, Proceedings of Eurographics/ACM SIGGRAPH Symposium on Geometry Processing, P23
   Pu J, 2005, P IDETC CIE
   Ruiz-Correa S, 2001, PROC CVPR IEEE, P769
   Sfikas K, 2013, P ICIAP MMC4H WORKSH
   Shilane P., 2004, Shape Modeling International
   Siddiqi K, 2008, MACH VISION APPL, V19, P261, DOI 10.1007/s00138-007-0097-8
   Sipiran I., 2013, 3DOR, P81
   Stavropoulos G, 2010, IEEE T MULTIMEDIA, V12, P692, DOI 10.1109/TMM.2010.2053023
   Tierny J, 2008, VISUAL COMPUT, V24, P155, DOI 10.1007/s00371-007-0181-0
   Tierny J, 2009, COMPUT GRAPH FORUM, V28, P41, DOI 10.1111/j.1467-8659.2008.01190.x
   Toldo R., 2009, Proceedings of the 2nd Eurographics Conference on 3D Object Retrieval, P21
   Veltkamp RC, 2010, P EUR ACM SIGGRAPH S, P63
   Vranic DV, 2004, THESIS
   Wahl E, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P474, DOI 10.1109/IM.2003.1240284
   Wang F, 2008, P SPIE, V6822
   Wang M, 2013, IEEE T IMAGE PROCESS, V22, P1395, DOI 10.1109/TIP.2012.2231088
   Zarpalas D, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/23912
   Zhou K, 2011, IEEE T VIS COMPUT GR, V17, P669, DOI 10.1109/TVCG.2010.75
NR 78
TC 22
Z9 23
U1 2
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11783
EP 11808
DI 10.1007/s11042-014-2267-9
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600036
DA 2024-07-18
ER

PT J
AU Choi, KH
   Lee, D
AF Choi, Kyong-Ho
   Lee, DongHwi
TI A study on strengthening security awareness programs based on an RFID
   access control system for inside information leakage prevention
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security awareness; RFID; Access control; Information security; Security
   training
AB Systematic security policies and plans of many organizations or enterprises can be degraded due to user's inattention and unconcern. Therefore, it is very important to guide establishing security policies through the education for users. However, existing security awareness program has problems that is not reflect for different user's security level and not evaluation of the security policy that is established and implemented, because it use educating for users in the form of a cluster education on uniform contents. Thus in this study, we proposed a strengthening security awareness program using an intensive training method for users based on detecting violations of the established security policy. For detecting violation of established security policy, we use a physical access control method by RFID that protects data from an information system accessed by unauthorized persons through physical ways for visual checking. The strengthening security awareness program proposed in this study increases security levels for the users who have low security awareness levels and can intercept potential leakage paths of important information through improving minimum security levels in organizations or enterprises.
C1 [Choi, Kyong-Ho] Kyonggi Univ, Ctr Ind, Suwon, Gyeonggi Do, South Korea.
   [Lee, DongHwi] Kyonggi Univ, Dept Ind Secur, Suwon, Gyeonggi Do, South Korea.
C3 Kyonggi University; Kyonggi University
RP Lee, D (corresponding author), Kyonggi Univ, Dept Ind Secur, San 94-6, Suwon, Gyeonggi Do, South Korea.
EM cyberckh@gmail.com; dhclub@naver.com
FU Kyonggi university advanced Industrial Security Center of Korea Ministry
   of Knowledge Economy
FX This work was supported by a grant from Kyonggi university advanced
   Industrial Security Center of Korea Ministry of Knowledge Economy
CR Andress Jason., 2011, The Basics of Information Security: Understanding the Fundamentals of InfoSec in Theory and Practice
   Broderick J. S., 2006, Information Security Technical Report, V11, P26, DOI 10.1016/j.istr.2005.12.001
   Choi KH, 2012, J INF SECUR, V12, P53
   Colwill Carl, 2009, Information Security Technical Report, V14, P186, DOI 10.1016/j.istr.2010.04.004
   Cone BD, 2007, COMPUT SECUR, V26, P63, DOI 10.1016/j.cose.2006.10.005
   Drevin L, 2007, COMPUT SECUR, V26, P36, DOI 10.1016/j.cose.2006.10.006
   Eminagaoglu Mete, 2009, Information Security Technical Report, V14, P223, DOI 10.1016/j.istr.2010.05.002
   Goucher W, 2011, COMPUT FRAUD SECUR, P17, DOI 10.1016/S1361-3723(11)70116-6
   Huang WH, 2006, MULTIMED TOOLS APPL, V30, P205, DOI 10.1007/s11042-006-0024-4
   Huber J, 2013, MULTIMED TOOLS APPL, V62, P209, DOI 10.1007/s11042-011-0980-1
   Kapsalis V, 2006, COMPUT SECUR, V25, P507, DOI 10.1016/j.cose.2006.05.004
   Kim JM, 2012, J INF SECUR, V12
   Kim Minsu, 2012, [Journal of convergence security, 융합보안 논문지], V12, P3
   Lee D, 2014, MULTIMED TOOLS APPL, V73, P601, DOI 10.1007/s11042-010-0675-z
   Long J, 2008, NO TECH HACKING
   Montoliu R, 2013, MULTIMED TOOLS APPL, V62, P179, DOI 10.1007/s11042-011-0982-z
   Preda S, 2011, J SYST SOFTWARE, V84, P1144, DOI 10.1016/j.jss.2011.02.005
NR 17
TC 9
Z9 11
U1 0
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 8927
EP 8937
DI 10.1007/s11042-013-1727-y
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600016
DA 2024-07-18
ER

PT J
AU Jeong, HJ
   Kim, TE
   Kim, HG
   Kim, MH
AF Jeong, Hyun Ji
   Kim, Tak-Eun
   Kim, Hyeon Gyu
   Kim, Myoung Ho
TI Automatic detection of slide transitions in lecture videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video segmentation; Video indexing; Recursive interval pruning; Backward
   slide transitions; Adaptive threshold; SIFT algorithm
AB This paper presents a method to automatically detect slide changes in lecture videos. For accurate detection, the regions capturing slide images are first identified from video frames. Then, SIFT features are extracted from the regions, which are invariant to image scaling and rotation. These features are used to compare similarity between frames. If the similarity is smaller than a threshold, slide transition is detected. The threshold is estimated based on the mean and standard deviation of sample frames' similarities. Using this method, high detection accuracy can be obtained without any supplementary slide images. The proposed method also supports detection of backward slide transitions that occur when a speaker returns to a previous slide to emphasize its contents. In experiments conducted on our test collection, the proposed method showed 87 % accuracy in forward transition detection and 86 % accuracy in backward transition detection.
C1 [Jeong, Hyun Ji; Kim, Tak-Eun; Kim, Myoung Ho] Korea Adv Inst Sci & Technol, Dept Comp Sci, Taejon 305701, South Korea.
   [Kim, Hyeon Gyu] Sahmyook Univ, Dept Comp Engn, Seoul 139742, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Sahmyook
   University
RP Kim, HG (corresponding author), Sahmyook Univ, Dept Comp Engn, Hwarangro 815, Seoul 139742, South Korea.
EM hjjung@dbserver.kaist.ac.kr; tekim@dbserver.kaist.ac.kr;
   hgkim@syu.ac.kr; mhkim@dbserver.kaist.ac.kr
RI Kim, Myoung Ho/C-1997-2011
FU MSIP(Ministry of Science, ICT and Future Planning) of Korea under the
   ITRC support program [NIPA-2013-H0301-13-4009]; National Research
   Foundation of Korea - Korea government(MEST) [2012R1A2A2A01046694];
   Sahmyook University
FX This research was supported by the MSIP(Ministry of Science, ICT and
   Future Planning) of Korea under the ITRC support
   program(NIPA-2013-H0301-13-4009), and the National Research Foundation
   of Korea grant funded by the Korea government(MEST) (No.
   2012R1A2A2A01046694).; This paper was supported by the Sahmyook
   University Research Fund in 2013.
CR [Anonymous], IEEE COMP SOC C COMP
   Cerneková Z, 2006, IEEE T CIRC SYST VID, V16, P82, DOI 10.1109/TCSVT.2005.856896
   Che X., 2013, P 21 ACM INT C MULT
   Cooper M, 2007, IEEE T MULTIMEDIA, V9, P610, DOI 10.1109/TMM.2006.888015
   Fan Q., 2006, P 8 ACM INT WORKSHOP, P239, DOI [10.1145/1178677.1178710., DOI 10.1145/1178677.1178710]
   Fan QF, 2007, INT CONF ACOUST SPEE, P989
   Hu W, 2001, IEEE T SYST MAN CY C, V41, P797
   Li DL, 2000, 2000 IEEE WORKSHOP ON SIGNAL PROCESSING SYSTEMS: DESIGN AND IMPLEMENTATION, P120, DOI 10.1109/SIPS.2000.886710
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma D, 2012, SPIE
   Mukhopadhyay S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P477, DOI 10.1145/319463.319690
   Ngo CW, 2003, IEEE FIFTH INTERNATIOANL SYMPOSIUM ON MULTIMEDIA SOFTWARE ENGINEERING, PROCEEDINGS, P215
   Ngo CW, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA533
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Porter Sarah Victoria, 2004, THESIS U BRISTOL
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Shafait F, 2008, PROC SPIE, V6815, DOI 10.1117/12.767755
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   Wang XY, 2009, LECT NOTES COMPUT SC, V5879, P311, DOI 10.1007/978-3-642-10467-1_27
   Wu X, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P808, DOI 10.1109/CISP.2008.12
   Xia DY, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P389, DOI 10.1109/ICIG.2007.11
   Zhao ZC, 2006, LECT NOTES COMPUT SC, V4222, P617
NR 22
TC 6
Z9 7
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7537
EP 7554
DI 10.1007/s11042-014-1990-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200006
DA 2024-07-18
ER

PT J
AU Lee, A
   Ra, I
AF Lee, Ahyoung
   Ra, Ilkyeun
TI Performance analysis of ad hoc routing protocols based on selective
   forwarding node algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ad hoc wireless networks; Ad hoc routing protocols; Optimized link state
   routing protocol; Gossip-based routing protocol; Adaptive-gossiping
   routing algorithm
AB Network resources are essential in resource critical environments as ad hoc wireless networks (AWNs) due to their dynamic topology and broadcasting of packets over the wireless medium without a central controller. In order to perform a routing algorithm with minimum resource consumption, an ideal ad hoc routing protocol should be designed for low consumed resources such as low power consumption. In this paper focus on ad hoc routing protocols, Optimized Link State Routing Protocol (OLSR) and gossip-based routing protocols, based on selective forwarding node algorithms that reduce the control message overheads. Thus, we present performance analytical results to thoroughly evaluate the routing protocols and demonstrate our Adaptive-Gossiping method advantages over Static-Gossiping routing and OLSR protocols in densely deployed networks. This paper is an extended version of ICISA 2013 conference paper [12].
C1 [Lee, Ahyoung] Georgia Inst Technol, Sch Elect & Comp Engn, Broadband Wireless Networking Lab, Atlanta, GA 30332 USA.
   [Ra, Ilkyeun] Univ Colorado, Dept Comp Sci & Engn, Denver, CO 80204 USA.
C3 University System of Georgia; Georgia Institute of Technology;
   University of Colorado System; University of Colorado Denver
RP Lee, A (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Broadband Wireless Networking Lab, Atlanta, GA 30332 USA.
EM ahyoung.lee@ece.gatech.edu; ilkyeun.ra@ucdenver.edu
RI RA, ILKYEUN/L-5956-2015
CR Arora D, 2012, INT CON ADV INFO NET, P406, DOI 10.1109/AINA.2012.93
   Bettstetter C, 2003, IEEE VTS VEH TECHNOL, P2286
   Chen L, 2007, IEEE NETWORK, V21, P30, DOI 10.1109/MNET.2007.4395108
   Chen SG, 1999, IEEE J SEL AREA COMM, V17, P1488, DOI 10.1109/49.780354
   Clausen T., 2003, RFC 3626
   Corson S., 1999, MOBILE AD HOC NETWOR
   Fall K, 2010, NS 2
   Goyal P, 2012, PROCEEDINGS OF THE 2012 WORLD CONGRESS ON INFORMATION AND COMMUNICATION TECHNOLOGIES, P283, DOI 10.1109/WICT.2012.6409089
   Haas ZJ, 2006, IEEE ACM T NETWORK, V14, P479, DOI 10.1109/TNET.2006.876186
   Huhtonen Aleksandr., 2004, Telecommunications Software and Multimedia, P1
   Lee A., 2011, P ICCCT 11, P269
   Lee A, 2013, P IEEE ICISA 13 PATT
   Penrose M., 2003, Oxford Stud. Probab., V5
   Perkins C., 2003, Internet RFCs
   Toutouh J, 2012, IEEE T VEH TECHNOL, V61, P1884, DOI 10.1109/TVT.2012.2188552
   Wagner T., 2011, CAMPUS QOS VOICE VID
NR 16
TC 0
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6443
EP 6452
DI 10.1007/s11042-014-2105-0
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700022
DA 2024-07-18
ER

PT J
AU Park, WH
   Lee, D
AF Park, Won Hyung
   Lee, DongHwi
TI Improvement of evidence collection module using live response technology
   on a windows system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Windows forensic; Evidence collection; Live response technology;
   Information leakage
AB Recently, A malware (or malicious code) of information leakage type is increasing for leaking personal data, credit information, financial information, etc. Also, this various forms is fast changing. However, a recent trend of an existing windows forensics module for the type of violation is a lack of adaptability. In this paper malware of information leakage type don't detection with windows forensic analysis tools. So there are improve new evidence collection module using live response technology to identify and respond more quickly technology can offer.
C1 [Park, Won Hyung] Far East Univ, Dept Cyber Secur, Chungbuk 369700, South Korea.
   [Lee, DongHwi] Kyonggi Univ, Dept Ind Secur, Suwon, Kyonggi Do, South Korea.
C3 Kyonggi University
RP Park, WH (corresponding author), Far East Univ, Dept Cyber Secur, Wangjang Ri,Gamgok Myeon, Chungbuk 369700, South Korea.
EM whpark@kdu.ac.kr; dhclub@naver.com
FU Kyonggi University advanced Industrial Security Center of Korea Ministry
   of Knowledge Economy
FX This work was supported by a grant from Kyonggi University advanced
   Industrial Security Center of Korea Ministry of Knowledge Economy.
CR Agent Special, 2002, SIMPLE SOUND TOOLS 1
   [Anonymous], 2010, GUID INC AN PROC
   ASEC Team, 2010, ASEC REP
   Jang YJ, 2008, TRAND MALWARE FORECA
   KISA, 2010, KOR INT INC PHISH RE
   Kornblum J., 2002, Preservation of fragile digital evidence by first responders Digital forensics research workshop
   Lee JS, 2004, STUDY NETWORK FORENS
   Lim CY, 2009, AHNREPORT ANAL
   Noblett M.G., 2000, RECOVERING EXAMINING, V2
   Sophos, 2008, SEC THREAT REP 2009, P13
   Sterbenz JPG, 2011, TELECOMMUN SYST J
   Whang HW, 2003, COMPUTER FORENSIC TR
   Whitcomb CM, 2002, INT J DIGTAL EVI SPR, V1
   Xun Dong, 2008, TELECOMMUN SYST J
NR 14
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6453
EP 6464
DI 10.1007/s11042-014-2098-8
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700023
DA 2024-07-18
ER

PT J
AU Degani, A
   Dalai, M
   Leonardi, R
   Migliorati, P
AF Degani, Alessio
   Dalai, Marco
   Leonardi, Riccardo
   Migliorati, Pierangelo
TI Comparison of tuning frequency estimation methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tuning frequency; Concert pitch; Concert-A; Estimation; Comparison
AB In this paper, a comparison of different algorithms for concert pitch (i.e., tuning frequency or reference frequency) estimation is presented and discussed. The unavailability of ground-truth datasets makes this evaluation on real music recordings less trivial than it may initially appear. Hence, in this paper we use two datasets, one of real music (covers80 provided by LabROSA) and one of synthesized music (MS2012, constructed by the authors). The algorithms have been compared in terms of speed of convergence and stability of the estimated value over an increasing length of the analysed signal. A local tuning frequency estimation was also performed in order to compare the ability of the algorithms to follow the local variations of the reference frequency in a real-time environment. Moreover, an analysis of the execution time have been provided. While the various algorithms perform comparably in terms of asymptotic precision, they show a quite different behaviour in terms of speed of convergence and local tuning frequency estimation accuracy.
C1 [Degani, Alessio; Dalai, Marco; Leonardi, Riccardo; Migliorati, Pierangelo] Univ Brescia, Dept Informat Engn DII, Signals & Commun Lab, I-25123 Brescia, Italy.
C3 University of Brescia
RP Degani, A (corresponding author), Univ Brescia, Dept Informat Engn DII, Signals & Commun Lab, Via Branze 38, I-25123 Brescia, Italy.
EM alessio.degani@ing.unibs.it; marco.dalai@ing.unibs.it;
   riccardo.leonardi@ing.unibs.it; pierangelo.migliorati@ing.unibs.it
RI Leonardi, Riccardo/F-5666-2010
OI Leonardi, Riccardo/0000-0003-0755-1924
CR Amatriain X., 2002, SPECTRAL PROCESSING, P373
   [Anonymous], P 7 INT C MUS INF RE
   Degani A, 2012, MS2012 SYMBOLIC MUSI
   Dixon S, 1996, P INT COMP MUS C SAN, P83
   Dixon S, 2011, P 12 INT C MUS INF R
   Dressler K, 2006, P 9 INT C DIG AUD EF
   Dressler K., 2007, P 8 INT C MUS INF RE, P357
   Ellis DPW, 2007, COVERS80 COV SONG DA
   Fastl H., 2006, Psychoacoustics: Facts and Models, V3rd
   Gnann V, 2011, P 131 AES CONV
   GOMEZ E, 2006, THESIS U P FABRA BAR
   Harte C., 2005, ISMIR
   International Organization for Standardization, 1975, ISO 16:1975 acoustics-standard tuning frequency
   Khadkevich M, 2009, P 12 INT C DIG AUD E
   Lee CT, 2012, IEEE T MULTIMEDIA, V14, P608, DOI 10.1109/TMM.2012.2191398
   Lerch A, 2006, P 7 INT C MUS INF RE, P212
   Mauch M, 2010, IEEE T AUDIO SPEECH, V18, P1280, DOI 10.1109/TASL.2009.2032947
   Peeters G., 2006, P INT C DIGITAL AUDI, P127
   Ryynanen Matti P, 2004, THESIS TAMPERE U TEC
   Serra X., 1997, Music. signal Process., P91
   Vincent E, 2008, INT CONF ACOUST SPEE, P109, DOI 10.1109/ICASSP.2008.4517558
   Zhu YW, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P30
NR 22
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5917
EP 5934
DI 10.1007/s11042-014-1897-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100027
DA 2024-07-18
ER

PT J
AU Kawano, Y
   Yanai, K
AF Kawano, Yoshiyuki
   Yanai, Keiji
TI FoodCam: A real-time food recognition system on a smartphone
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Food recognition; Dietary recording; Smartphone application; Fisher
   vector; Mobile image recognition
AB We propose a mobile food recognition system, FoodCam, the purposes of which are estimating calorie and nutrition of foods and recording a user's eating habits. In this paper, we propose image recognition methods which are suitable for mobile devices. The proposed method enables real-time food image recognition on a consumer smartphone. This characteristic is completely different from the existing systems which require to send images to an image recognition server. To recognize food items, a user draws bounding boxes by touching the screen first, and then the system starts food item recognition within the indicated bounding boxes. To recognize them more accurately, we segment each food item region by GrubCut, extract image features and finally classify it into one of the one hundred food categories with a linear SVM. As image features, we adopt two kinds of features: one is the combination of the standard bag-of-features and color histograms with chi(2) kernel feature maps, and the other is a HOG patch descriptor and a color patch descriptor with the state-of-the-art Fisher Vector representation. In addition, the system estimates the direction of food regions where the higher SVM output score is expected to be obtained, and it shows the estimated direction in an arrow on the screen in order to ask a user to move a smartphone camera. This recognition process is performed repeatedly and continuously. We implemented this system as a standalone mobile application for Android smartphones so as to use multiple CPU cores effectively for real-time recognition. In the experiments, we have achieved the 79.2 % classification rate for the top 5 category candidates for a 100-category food dataset with the ground-truth bounding boxes when we used HOG and color patches with the Fisher Vector coding as image features. In addition, we obtained positive evaluation by a user study compared to the food recording system without object recognition.
C1 [Kawano, Yoshiyuki; Yanai, Keiji] Univ Electrocommun, Chofu, Tokyo 1828585, Japan.
C3 University of Electro-Communications - Japan
RP Yanai, K (corresponding author), Univ Electrocommun, Tokyo 1-5-1 Chofugaoka, Chofu, Tokyo 1828585, Japan.
EM kawano-y@mm.inf.uec.ac.jp; yanai@cs.uec.ac.jp
OI Yanai, Keiji/0000-0002-0431-183X
FU Grants-in-Aid for Scientific Research [23650044] Funding Source: KAKEN
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], 2012, P IEEE INT C MULT EX
   [Anonymous], P EUR C COMP VIS
   [Anonymous], P IS T SPIE C COMP I
   [Anonymous], 2008, Proceeding of the 16th ACM international conference on Multimedia-MM'08, DOI [DOI 10.1145/1459359, 10.1145/1459359]
   [Anonymous], P IEEE COMP VIS PATT
   [Anonymous], P IEEE COMP VIS PATT
   [Anonymous], 2009, P ACM MULTIMEDIA 200
   [Anonymous], P EUR C COMP VIS
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2005, IEEE COMP SOC C COMP
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   He Y., 2013, P IEEE INT C MULT EX
   Jia D, 2012, IM LARG SCAL VIS REC
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mariappan A, 2009, P IS T SPIE C COMP I
   Maruyama T, 2012, P ACM MM WORKSH INT
   Perronnin F, 2007, P IEEE COMP VIS PATT
   Philbin J, 2008, P IEEE COMP VIS PATT
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Vedaldi A., 2012, IEEE T PATTERN ANAL
   Yu F, 2011, P ACM INT C MULT
NR 27
TC 92
Z9 107
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 14
BP 5263
EP 5287
DI 10.1007/s11042-014-2000-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XU
UT WOS:000358214900019
DA 2024-07-18
ER

PT J
AU Lim, C
   Chang, JH
AF Lim, Chungsoo
   Chang, Joon-Hyuk
TI Efficient implementation techniques of an SVM-based speech/music
   classifier in SMV
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech/music classification; Support vector machine; Selectable mode
   vocoder; Embedded system
ID SUPPORT VECTOR MACHINE
AB For real-time speech and audio encoders used in various multimedia applications, low-complexity encoding algorithms are required. Indeed, accurate classification of input signals is the key prerequisite for variable bit rate encoding, which has been introduced in order to effectively utilize limited communication bandwidth. This paper investigates implementation issues with a support vector machine (SVM)-based speech/music classifier in the selectable mode vocoder (SMV) framework, which is a standard codec adopted by the Third-Generation Partnership Project 2 (3GPP2). While a support vector machine is well known for its superior classification capability, it is accompanied by a high computational cost. In order to achieve a more realizable system, we propose two techniques for the SVM-based speech/music classifier, aimed at reducing the number of classification requests to the classifier. The first technique introduces a simpler classifier that processes some of the input frames instead of the SVM-based classifier, and the second technique skips a portion of input frames based on strong inter-frame correlation in speech and music frames. Our experimental results show that the proposed techniques can reduce the computational cost of the SVM-based classifier by 95.4 % with negligible performance degradation, making it plausible for integration into the SMV codec.
C1 [Lim, Chungsoo] Korea Natl Univ Transportat, Choungju Si, Chungbuk, South Korea.
   [Chang, Joon-Hyuk] Hanyang Univ, Sch Elect Engn, Seoul 133791, South Korea.
C3 Korea National University of Transportation; Hanyang University
RP Chang, JH (corresponding author), Hanyang Univ, Sch Elect Engn, 222 Wangsimni Ro, Seoul 133791, South Korea.
EM jchang@hanyang.ac.kr
FU NRF of Korea - MEST [2012R1A2A2A01004895]; MSIP, Korea, under ITRC
   support program [NIPA-2013-H0301-13-4005]
FX This work was supported by NRF of Korea grant funded by the MEST
   (2012R1A2A2A01004895) and this research was supported by the MSIP,
   Korea, under the ITRC support program supervised by the NIPA
   (NIPA-2013-H0301-13-4005)
CR 3GPP2 Specification, 2004, 3GPP2CS00300V30
   [Anonymous], 2005, INT C MACHINE LEARNI
   Burger D, 1997, 1342 U WISC MAD COMP
   Burges C. J. C., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P71
   CSR, 2006, BLUECORE5 MULT
   Dardas NH, 2014, MULTIMED TOOLS APPL, V70, P2211, DOI 10.1007/s11042-012-1236-4
   Farrugia RA, 2012, IEEE T MULTIMED, V11, P1323
   Fisher W.M., 1986, P DARPAR SPEECH REC, P93
   Gao Y, 2001, INT CONF ACOUST SPEE, P709, DOI 10.1109/ICASSP.2001.941013
   Hu HJ, 2014, MULTIMED TOOLS APPL, V69, P199, DOI 10.1007/s11042-012-1248-0
   Ji-hyun Song, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P2182, DOI 10.1109/CISP.2011.6100596
   Kim SK, 2010, IEICE T FUND ELECTR, VE93A, P316, DOI 10.1587/transfun.E93.A.316
   Kim SK, 2009, IEICE T FUND ELECTR, VE92A, P630, DOI 10.1587/transfun.E92.A.630
   Lavner Y, 2009, EURASIP J AUDIO SPEE, DOI 10.1155/2009/239892
   MAITRE X, 1988, IEEE J SEL AREA COMM, V6, P283, DOI 10.1109/49.605
   Nakashima Y, 2012, MULTIMEDIA SYST, V18, P157, DOI 10.1007/s00530-011-0244-y
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Zhan YQ, 2005, PATTERN RECOGN, V38, P157, DOI 10.1016/j.patcog.2004.06.001
NR 18
TC 8
Z9 9
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5375
EP 5400
DI 10.1007/s11042-014-1859-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100001
DA 2024-07-18
ER

PT J
AU Marciniak, T
   Chmielewska, A
   Weychan, R
   Parzych, M
   Dabrowski, A
AF Marciniak, Tomasz
   Chmielewska, Agata
   Weychan, Radoslaw
   Parzych, Marianna
   Dabrowski, Adam
TI Influence of low resolution of images on reliability of face detection
   and recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection and recognition; Biometric standards; Low-resolution
   images
AB In this paper we analyze reliability of the real-time system for face detection and recognition from low-resolution images, e.g., from video monitoring images. First, we briefly describe main features of the standards for biometric face images. Available scientific databases have been checked for compliance with these biometric standards. During the research we have considered both the correctness of extraction (location) of the face from the image as well as the correctness of the identification (based on the eigenfaces approach). To the tests we have used the face databases that allow to study tolerance to illumination and face positions. We have compared various face detection techniques and analyzed minimum requirements for the resolution of facial images. Finally, an influence of the resolution reduction on the FAR/FRR of the recognition is presented.
C1 [Marciniak, Tomasz; Chmielewska, Agata; Weychan, Radoslaw; Parzych, Marianna; Dabrowski, Adam] Poznan Univ Tech, Div Signal Proc & Elect Syst, Chair Control & Syst Engn, PL-60965 Poznan, Poland.
C3 Poznan University of Technology
RP Marciniak, T (corresponding author), Poznan Univ Tech, Div Signal Proc & Elect Syst, Chair Control & Syst Engn, Ul Piotrowo 3a, PL-60965 Poznan, Poland.
EM tomasz.marciniak@put.poznan.pl
RI Marciniak, Tomasz/L-4702-2014; Weychan, Radoslaw/O-4293-2014; Dabrowski,
   Adam M./O-6053-2014
OI Marciniak, Tomasz/0000-0001-6035-7325; 
CR Achermann database (FullFaces), 2013, FACE
   Agarwal M, 2010, 2010 INTERNATIONAL CONFERENCE ON SIGNAL ACQUISITION AND PROCESSING: ICSAP 2010, PROCEEDINGS, P310, DOI 10.1109/ICSAP.2010.51
   [Anonymous], 2013, FACE ANNOTATION INTE
   [Anonymous], 2004, 3852004 ANSIINCITS
   [Anonymous], 2013, INTRO BIOMETRICS CRO
   [Anonymous], 2010, PATTERN RECOGN
   [Anonymous], 1996, 501327 EN
   [Anonymous], 2012, ALGORITHM FACE DETEC
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Database of the Sheffield University, 2013, DATABASE SHEFFIELD U
   Davis M, 2011, STUD COMPUT INTELL, V332, P155
   Description of D-Link camera, 2013, DESCRIPTION D LINK C
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Haar Feature-based Cascade Classifier for Object Detection, 2009, IMAGE PROCESSING COM
   ISO/IEC, 2005, 1979452005 ISOIEC
   Jesorsky O, 2001, LECT NOTES COMPUT SC
   Jun Z, 2010, LECT NOTES COMPUT SC, V6111, P454
   KAPUR J, 1997, FACE DETECTION COLOR
   Leszczuk M, 2012, MULTIMED TOOLS APPL, DOI [10.1007/s11042-012-1199-5, DOI 10.1007/S11042-012-1199-5]
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Marciniak T, 2012, 2012 JOINT CONFERENCE NEW TRENDS IN AUDIO & VIDEO AND SIGNAL PROCESSING: ALGORITHMS, ARCHITECTURES, ARRANGEMENTS, & APPLICATIONS (NTAV-SPA 2012), P177
   Marciniak T, 2012, COMM COM INF SC, V287, P220
   Marciniak T, 2011, COMM COM INF SC, V149, P242
   Nilsson M, 2006, FACE DETECTION ALGOR
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Rosa L, 2013, FACE RECOGNITION SYS
   Rzepecki Sz, 2011, THESIS POZNAN U TECH
   SHARKAS M, 2008, 9 INT C SIGN PROC 20, P914
   Yong Xu, 2008, 2008 3rd International Conference on Innovative Computing Information and Control (ICICIC), DOI 10.1109/ICICIC.2008.234
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
NR 30
TC 36
Z9 41
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 12
BP 4329
EP 4349
DI 10.1007/s11042-013-1568-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CK4CW
UT WOS:000356168600009
OA hybrid
DA 2024-07-18
ER

PT J
AU Dedu, E
   Ramadan, W
   Bourgeois, J
AF Dedu, Eugen
   Ramadan, Wassim
   Bourgeois, Julien
TI A taxonomy of the parameters used by decision methods for adaptive video
   transmission
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video content adaptation; Rate control; Congestion control; Video
   streaming
ID CONGESTION CONTROL; EXTENSION; MECHANISM; QUALITY
AB Nowadays, video data transfers account for much of the Internet traffic and a huge number of users use this service on a daily base. Even if videos are usually stored in several bitrates on servers, the video sending rate does not take into account network conditions which are changing dynamically during transmission. Therefore, the best bitrate is not used which causes sub-optimal video quality when the video bitrate is under the available bandwidth or packet loss when it is over it. One solution is to deploy adaptive video, which adapts video parameters such as bitrate or frame resolution to network conditions. Many ideas are proposed in the literature, yet no paper provides a global view on adaptation methods in order to classify them. This article fills this gap by discussing several adaptation methods through a taxonomy of the parameters used for adaptation. We show that, in the research community, the sender generally takes the decision of adaptation whereas in the solutions supported by major current companies the receiver takes this decision. We notably suggest, without evaluation, a valuable and realistic adaptation method, gathering the advantages of the presented methods.
C1 [Dedu, Eugen; Ramadan, Wassim; Bourgeois, Julien] FEMTO ST Inst, DISC Dept, F-25200 Montbeliard, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Franche-Comte; Universite de Technologie de Belfort-Montbeliard (UTBM)
RP Dedu, E (corresponding author), FEMTO ST Inst, DISC Dept, 4 Pl Tharradin, F-25200 Montbeliard, France.
EM Eugen.Dedu@pu-pm.univ-fcomte.fr; Wassim.Ramadan@pu-pm.univ-fcomte.fr;
   Julien.Bourgeois@pu-pm.univ-fcomte.fr
OI Ramadan, Wassim/0000-0002-2196-6686
FU Ministry of High Education of Syria
FX W. Ramadan received a grant of PhD thesis from the Ministry of High
   Education of Syria.
CR Adzic V, 2011, MULTIMED TOOLS APPL, V51, P379, DOI 10.1007/s11042-010-0669-x
   [Anonymous], 2010, DYNAMIC STREAMING FL
   [Anonymous], 2011, 230091 ISOIEC
   [Anonymous], INT J DIGIT INF WIRE
   [Anonymous], HTTP LIVE S IN PRESS
   Arsan T, 2012, INT SYM HIGH CAPAC, P152
   Balk A, 2003, LECT NOTES COMPUT SC, V2601, P525
   Burnett IS, 2006, THE MPEG 21 BOOK
   Dai H., 2011, Acta Horticulturae, P169, DOI 10.1145/1943552.1943575
   Daronco LC, 2011, MULTIMED TOOLS APPL, P1
   De Cicco L., 2011, P 2 ANN ACM C MULTIM, P145
   De Cicco L, 2010, LECT NOTES COMPUT SC, V6389, P447
   Eberhard M, 2009, IEEE WIREL COMMUN, V16, P58, DOI 10.1109/MWC.2009.5300303
   Feng WC, 2002, J HIGH SPEED NETW, V11, P199
   Feng WC, 1999, IEEE T MULTIMEDIA, V1, P302, DOI 10.1109/6046.784468
   Floyd S, 2008, TCP FRIENDLY RATE CO, V5348
   Furini M, 2001, IEEE T MULTIMEDIA, V3, P33, DOI 10.1109/6046.909592
   Görkemli B, 2012, SIGNAL PROCESS-IMAGE, V27, P595, DOI 10.1016/j.image.2012.02.002
   Görkemli B, 2010, IEEE IMAGE PROC, P2913, DOI 10.1109/ICIP.2010.5652838
   Gürses E, 2005, COMPUT NETW, V48, P489, DOI 10.1016/j.comnet.2004.10.015
   Haddad RJ, 2013, IEEE COMMUN SURV TUT, V99, P1
   Hu NN, 2003, IEEE J SEL AREA COMM, V21, P879, DOI 10.1109/JSAC.2003.814505
   Huszak Arpad., 2006, International Symposium on Communication System Networks and Digital Signal Processing, V5, P125
   KAZANTZIDIS M, 2002, THESIS U CALIFORNIA
   Kofler I, 2008, SIGNAL IMAGE VIDEO P, V2, P355, DOI 10.1007/s11760-008-0088-x
   Laplante P., 2011, Real-Time Systems Design and Analysis: An Engineer's Handbook, V4th
   Lee S, 2008, COMPUT COMMUN, V31, P2621, DOI 10.1016/j.comcom.2008.02.011
   Lee S, 2006, LECT NOTES ARTIF INT, V4267, P74
   Lie A, 2008, MULTIMEDIA SYST, V14, P33, DOI 10.1007/s00530-007-0110-0
   Liu CH, 2010, IEEE ICC
   Cubero JM, 2012, BELL LABS TECH J, V16, P115, DOI 10.1002/bltj.20537
   Mascolo S, 1999, AUTOMATICA, V35, P1921, DOI 10.1016/S0005-1098(99)00128-4
   Nguyen DT, 2007, IEEE J-STSP, V1, P246, DOI 10.1109/JSTSP.2007.902068
   Oh S, 2008, IEEE T BROADCAST, V54, P36, DOI 10.1109/TBC.2007.910921
   Postel J., 1980, User datagram protocol
   POSTEL J, 1981, RFC791
   Pu J, 2000, SURVEY QOS ADAPTATIO
   Ramadan W, 2011, TELECOMMUNICATIONS S
   Ramadan W., 2010, INFLUENCE ORG CULTUR, P1
   Ramadan W, 2013, COMPUT J IN PRESS
   Roccetti M, 2001, MULTIMED TOOLS APPL, V14, P23, DOI 10.1023/A:1011303506685
   Sadaf T, 2010, INT C EL INF ENG IEE, V2, pV2
   Schierl T, 2004, 14 INT PACK VID WORK
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Stockhammer T, 2011, ACM C MULT SYST SANT, V2, P134
   Su YC, 2003, SIGNAL PROCESS-IMAGE, V18, P537, DOI 10.1016/S0923-5965(03)00047-X
   Van der Auwera G, 2008, ADV MULTIMED, V2008, DOI 10.1155/2008/164027
   Van der Auwera G, 2009, IEEE T BROADCAST, V55, P541, DOI 10.1109/TBC.2009.2027399
   Vandalore B, 2001, REAL-TIME IMAGING, V7, P221, DOI 10.1006/rtim.2001.0224
   Wakamiya N, 2001, P SOC PHOTO-OPT INS, V4211, P25, DOI 10.1117/12.417490
   Wien M, 2007, IEEE T CIRC SYST VID, V17, P1194, DOI 10.1109/TCSVT.2007.905530
   Wien M, 2007, IEEE T CIRC SYST VID, V17, P1227, DOI 10.1109/TCSVT.2007.905519
   Xie B, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1327, DOI 10.1109/ICME.2004.1394473
   Ye DJ, 2004, IEEE T MULTIMEDIA, V6, P611, DOI 10.1109/tmm.2004.830817
   Ye DJ, 2002, HSNMC 2002: 5TH IEEE INTERNATIONAL CONFERENCE ON HIGH SPEED NETWORKS AND MULTIMEDIA COMMUNICATIONS, P81, DOI 10.1109/HSNMC.2002.1032552
   Zambelli A., 2009, IIS Smooth Streaming Technical Overview
NR 56
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 9
BP 2963
EP 2989
DI 10.1007/s11042-013-1764-6
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CF7NI
UT WOS:000352742800006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Khil, AR
   Lee, KH
   Kim, SK
AF Khil, A-Ra
   Lee, Kang-Hee
   Kim, Soo-Kyun
TI Software robot authoring tools for sharing intelligence among users and
   content providers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Software robot; Sobot; Authoring tool; Transfer; Message; Intelligence
   sharing; Web 2.0
ID AUTONOMOUS AGENTS; PERSONALITY
AB This paper proposes the authoring tools of the software robot (Sobot) for sharing intelligence among users and content providers. The proposed authoring tool package, Sobot studio is accessible to both developers and end-users of Sobot content. The Sobot studio allows them to easily create interactive software robot message with programming features. It encourages openness to everyone, user participation, and common ownership of emotional Sobot content based on web 2.0 paradigm. The authored Sobots can connect with and move to any device such as PCs, mobile phones, PDAs, or web portal sites at anytime. The experimental results verify that the emotional pet-type Sobots can easily transfer among heterogeneous devices through the network based on the ubiquitous paradigm.
C1 [Khil, A-Ra] Soongsil Univ, Coll Informat Technol, Sch Comp Sci & Engn, Seoul, South Korea.
   [Lee, Kang-Hee] Soongsil Univ, Coll Informat Technol, Global Sch Media, Seoul, South Korea.
   [Kim, Soo-Kyun] PaiChai Univ, Dept Game Engn, Daejeon, South Korea.
C3 Soongsil University; Soongsil University; Pai Chai University
RP Lee, KH (corresponding author), Soongsil Univ, Coll Informat Technol, Global Sch Media, 511 Sangdo Dong, Seoul, South Korea.
EM ara@ssu.ac.kr; kanghee.lee@ssu.ac.kr; kimsk@pcu.ac.kr
OI Kim, Soo Kyun/0000-0001-6071-8231
FU National Research Foundation of Korea - Korean Government
   [NRF-2013-S1A5A8020988]
FX This research was supported by the National Research Foundation of Korea
   Grant funded by the Korean Government (NRF-2013-S1A5A8020988).
CR BLUMBERG B, 1996, THESIS MIT CAMBRIDGE
   Elliott C, 1998, AI MAG, V19, P13
   Kim Hyun, 2005, IEEE WORKSH ADV ROB
   Kim JH, 2009, IEEE T SYST MAN CY C, V39, P331, DOI 10.1109/TSMCC.2009.2013724
   Lee KH, 2012, ROBOT AUTON SYST, V60, P941, DOI 10.1016/j.robot.2012.01.007
   Lee KH, 2011, DATA KNOWL ENG, V70, P923, DOI 10.1016/j.datak.2011.06.002
   Lee KH, 2011, APPL SOFT COMPUT, V11, P2286, DOI 10.1016/j.asoc.2010.08.010
   Lee KH, 2006, THESIS
   Lee KH, 2012, J FUTURE GAME TECHNO, V2, P331
   MAES P, 1995, COMMUN ACM, V38, P108, DOI 10.1145/219717.219808
   Shim Hyun-Sik, 1 JAP KOR JOINT S NE
   Sims K, 1994, P COMP GRAPH P SIGGR, V94, P15
NR 12
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 10
BP 3345
EP 3360
DI 10.1007/s11042-014-1972-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI1GY
UT WOS:000354493000007
DA 2024-07-18
ER

PT J
AU He, RH
   Yang, B
   Sang, N
   Yu, YS
   Bai, GL
   Li, JZ
AF He, Ruhan
   Yang, Bing
   Sang, Nong
   Yu, Yongsheng
   Bai, Geli
   Li, Jizi
TI Integral region-based covariance tracking with occlusion detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Integral region; Covariance tracking; Symmetric positive definite
   matrix; Occlusion detection
AB Covariance tracking has achieved impressive successes in recent years due to its competent region covariance-based feature descriptor. Although adopt fast integral image computation, covariance tracking's brute-force search strategy is still inefficient and it possibly leads to inconsecutive tracking trajectory and distraction. In this work, a generalized, adaptive covariance tracking approach with novel integral region computation and occlusion detection is proposed. The integral region is much faster than integral image and adaptive to the tracking target and tracking condition. The adaptive search window can be adjusted dynamically by simple occlusion detection. The integral image and the global covariance tracking can be seen just a special case of integral region and the proposed approach, respectively. The proposed approach unifies the local and global search strategies in an elegant way and smoothly switches between them according to the tracking conditions (i.e. occlusion distraction or sudden motion) which are judged by occlusion detector. It gets much better efficiency, robustness of distraction, and stable trajectory by local search in normal steady state, while obtains more abilities for occlusion and re-identification by enlarged search window (until to global search) in abnormal situation at the same time. Our approach shows excellent target representation ability, faster speed, and more robustness, which has been verified on some video sequences.
C1 [He, Ruhan] Wuhan Text Univ, Coll Math & Comp Sci, Wuhan 430073, Peoples R China.
   [Yang, Bing] Hubei Univ, Sch Educ, Wuhan 430062, Peoples R China.
   [Sang, Nong] Huazhong Univ Sci & Technol, Inst Pattern Recognit & Artificial Intelligence, Wuhan 430074, Peoples R China.
   [Yu, Yongsheng] Wuhan Univ Technol, Minist Educ, Green Bldg Mat & Mfg Engn Res Ctr, Wuhan 430070, Peoples R China.
   [Bai, Geli] Inner Mongolia Agr Univ, Coll Comp & Informat Engn, Hohhot 010018, Peoples R China.
   [Li, Jizi] Wuhan Text Univ, Sch Management, Wuhan 430073, Peoples R China.
C3 Wuhan Textile University; Hubei University; Huazhong University of
   Science & Technology; Wuhan University of Technology; Inner Mongolia
   Agricultural University; Wuhan Textile University
RP Yang, B (corresponding author), Hubei Univ, Sch Educ, Wuhan 430062, Peoples R China.
EM heruhan@hotmail.com; hubuyangbing@gmail.com; nsang@hust.edu.cn;
   yongshengyu@whut.edu.cn
FU National Natural Science Foundation of China [61170093]; China
   Postdoctoral Science Foundation [20110491149]
FX This work is supported by National Natural Science Foundation of China
   (No. 61170093) and China Postdoctoral Science Foundation (No.
   20110491149).
CR [Anonymous], 2008, P 10 EUR C COMP VIS
   [Anonymous], 2013, P IEEE C COMP VIS PA
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2000, P IEEE C COMP VIS PA
   [Anonymous], 2012, P IEEE C COMP VIS PA
   [Anonymous], 2002, P 7 EUR C COMP VIS E
   [Anonymous], 2010, P IEEE C COMP VIS PA
   [Anonymous], 2012, P IEEE C COMP VIS PA
   Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996
   Arsigny V, 2006, MAGN RESON MED, V56, P411, DOI 10.1002/mrm.20965
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Cherian A, 2011, P 13 INT C COMP VIS
   COLLINS R, 2003, P IEEE C COMP VIS PA
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Duan G, 2012, P 12 EUR C COMP VIS
   Hare S, 2012, PROCEEDING OF THE IE
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Jia X., 2012, P IEEE C COMP VIS PA
   Jiang N, 2012, PROCEEDING OF THE IE
   Kalal Z, 2010, P INT C IM PROC ICIP
   Kwon J., 2010, P IEEE C COMP VIS PA
   Li X, 2012, P IEEE C COMP VIS PA
   Maggio E, 2005, P IEEE INT C IM PROC
   Mei X., 2009, P IEEE 12 INT C COMP
   Nguyen QA, 2007, P IEEE COMP SOC C CO
   Ning T. D. Zhang, 2012, P IEEE C COMP VIS PA
   Parameswaran V, 2006, P IEEE C COMP VIS PA
   Park DW, 2012, P IEEE C COMP VIS PA
   Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z
   PORIKLI F, 2005, P IEEE INT C MULT EX
   Porikli F., 2006, 2006 IEEE COMPUTER S, V1, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Rui Y, 2013, P IEEE C COMP VIS PA
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Tyagi A, 2008, P IEEE WORKSH MOT VI
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang J, 2008, P INT C PATT REC ICP
   Wu Y, 2009, P 12 INT C COMP VIS
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Wu Y, 2012, IEEE T IMAGE PROCESS, V21, P2824, DOI 10.1109/TIP.2011.2182521
   Xu D, 2005, P NZ C IM VIS COMP
   Xu J., 2012, P IEEE C COMP VIS PA
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zamir AR, 2012, P 12 EUR C COMP VIS
   Zhang L., 2013, P IEEE C COMP VIS PA
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 48
TC 3
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 6
BP 2157
EP 2178
DI 10.1007/s11042-013-1797-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CD9CN
UT WOS:000351394500022
DA 2024-07-18
ER

PT J
AU Jiang, B
   Lu, YY
   Li, XY
   Lin, L
AF Jiang, Bo
   Lu, Yongyi
   Li, Xiying
   Lin, Liang
TI Towards a solid solution of real-time fire and flame detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fire detection; Empirical study; Video surveillance; Region
   classification
ID IMAGE
AB Although the object detection and recognition has received growing attention for decades, a robust fire and flame detection method is rarely explored. This paper presents an empirical study, towards a general and solid approach for fast detection of fire and flame in videos, with the applications in video surveillance and event retrieval. Our system consists of three cascaded steps: (1) candidate regions proposing by a background model, (2) fire region classifying with color-texture features and a dictionary of visual words, and (3) temporal verifying. The experimental evaluation and analysis are done for each step. We believe that it is a useful service to both academic research and real-world application. In addition, we release the software of the proposed system with the source code, as well as a public benchmark and data set, including 64 video clips covered both indoor and outdoor scenes under different conditions. We achieve an 82 % Recall with 93 % Precision on the data set, and greatly improve the performance by state-of-the-arts methods.
C1 [Jiang, Bo; Lu, Yongyi; Li, Xiying; Lin, Liang] Sun Yat Sen Univ, Sch Engn, Guangzhou 510275, Guangdong, Peoples R China.
   [Lin, Liang] SYSU CMU Shunde Int Joint Res Inst, Shunde, Peoples R China.
C3 Sun Yat Sen University
RP Li, XY (corresponding author), Sun Yat Sen Univ, Sch Engn, Guangzhou 510275, Guangdong, Peoples R China.
EM stslxy@mail.sysu.edu.cn; linlng@mail.sysu.edu.cn
RI Lin, L/HKO-8213-2023; l, j/JVZ-8480-2024; l, j/HNC-5728-2023
FU Fundamental Science and Technology Program of Ministry of Public
   Security [2013GABJC013]; Program of Guangzhou Zhujiang Star of Science
   and Technology [2013J2200067]; Guangdong Science and Technology Program
   [2012B031500006]; Guangdong Natural Science Foundation [S2013050014548];
   Special Project on Integration of Industry, Education and Research of
   Guangdong Province [2012B091000101]; Fundamental Research Funds for the
   Central Universities [13lgjc26]
FX This work was supported by Fundamental Science and Technology Program of
   Ministry of Public Security (no. 2013GABJC013), Program of Guangzhou
   Zhujiang Star of Science and Technology (no. 2013J2200067), Guangdong
   Science and Technology Program (no. 2012B031500006), Guangdong Natural
   Science Foundation (no. S2013050014548), Special Project on Integration
   of Industry, Education and Research of Guangdong Province (no.
   2012B091000101) and Fundamental Research Funds for the Central
   Universities (no. 13lgjc26).
CR [Anonymous], 2006, P IEEE COMPUTER SOC, DOI DOI 10.1109/CVPR.2006.95
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Borges PVK, 2010, IEEE T CIRC SYST VID, V20, P721, DOI 10.1109/TCSVT.2010.2045813
   Celik T, 2007, J VIS COMMUN IMAGE R, V18, P176, DOI 10.1016/j.jvcir.2006.12.003
   Cetin A., 2007, COMPUTER VISION BASE
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen TH, 2004, IEEE IMAGE PROC, P1707
   Cho BH, 2008, INT C ADV LANG PROC, P65
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Duan XH, 2013, IEEE T MULTIMEDIA, V15, P167, DOI 10.1109/TMM.2012.2225029
   Habiboglu YH, 2012, MACH VISION APPL, V23, P1103, DOI 10.1007/s00138-011-0369-1
   Healey G., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P605, DOI 10.1109/CVPR.1993.341064
   Horng WB, 2005, 2005 IEEE NETWORKING, SENSING AND CONTROL PROCEEDINGS, P100
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   Ko BC, 2009, FIRE SAFETY J, V44, P322, DOI 10.1016/j.firesaf.2008.07.006
   Lai HJ, 2013, IEEE T COMPUT, V62, P1221, DOI 10.1109/TC.2012.62
   Lee BM, 2007, LECT NOTES COMPUT SC, V4681, P1209
   Lin L, 2012, IEEE T IMAGE PROCESS, V21, P4844, DOI 10.1109/TIP.2012.2211373
   Lin L, 2012, PATTERN RECOGN, V45, P231, DOI 10.1016/j.patcog.2011.06.011
   Lin LA, 2010, IEEE T PATTERN ANAL, V32, P1426, DOI 10.1109/TPAMI.2009.150
   Lin L, 2009, MULTIMED TOOLS APPL, V41, P235, DOI 10.1007/s11042-008-0227-y
   Liu CB, 2004, INT C PATT RECOG, P134, DOI 10.1109/HPD.2004.1346686
   Liu XB, 2013, IEEE T PATTERN ANAL, V35, P3010, DOI 10.1109/TPAMI.2013.84
   Liu XB, 2011, IEEE T CIRC SYST VID, V21, P393, DOI 10.1109/TCSVT.2010.2087570
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Luo RC, 2007, IEEE-ASME T MECH, V12, P274, DOI 10.1109/TMECH.2007.897260
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Phillips W, 2002, PATTERN RECOGN LETT, V23, P319, DOI 10.1016/S0167-8655(01)00135-0
   Podrzaj P, 2008, FIRE TECHNOL, V44, P65, DOI 10.1007/s10694-007-0021-9
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Toreyin B.U., 2007, IEEE 15 SIGNAL PROCE, P1, DOI DOI 10.1109/SIU.2007.4298709
   Töreyin BU, 2006, PATTERN RECOGN LETT, V27, P49, DOI 10.1016/j.patrec.2005.06.015
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   van de Weijer J, 2006, IEEE T PATTERN ANAL, V28, P150, DOI 10.1109/TPAMI.2006.3
   Yao BZ, 2010, P IEEE, V98, P1485, DOI 10.1109/JPROC.2010.2050411
NR 36
TC 15
Z9 20
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 3
BP 689
EP 705
DI 10.1007/s11042-014-2106-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZO
UT WOS:000349356400002
DA 2024-07-18
ER

PT J
AU Meraoumia, A
   Chitroub, S
   Bouridane, A
AF Meraoumia, Abdallah
   Chitroub, Salim
   Bouridane, Ahmed
TI Do multispectral palmprint images be reliable for person identification?
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Multispectral palmprint images; Feature extraction; 1D
   Log-Gabor filter; Multiresolution analysis; Discrete wavelet transform;
   Discrete cosine transform; Data fusion
ID INFORMATION FUSION; EXTRACTION
AB This paper is concerned with an investigation of multispectral palmprint images for improving person identification by replying to the question: can multispectral palmprint images be reliable for such purpose? Two biometric systems are then proposed. In the first system, each spectral image is aligned and then used for feature extraction using 1D Log-Gabor filter. The features are encoded and Hamming distance is used for matching. The fusion at matching score level is used before the decision making. The second system is based on multiresolution analysis for feature extraction. The spectral images are decomposed into frequency sub-images with different levels of decomposition. The extracted coefficients are used as features. The MGPDF is used for modeling the features and Log-Likelihood scores are used for matching. Fusion at the matching score level is used before decision making. A comparative study between the two systems is then developed. The experimental results are demonstrated using the PolyU multispectral database and the results show that the two proposed systems are more effective when using multispectral images than their monospectral counterpart images.
C1 [Meraoumia, Abdallah] Univ Kasdi Merbah Ouargla, Lab Genie Elect, Fac Sci & Technol & Sci Mat, Ouargla 30000, Algeria.
   [Chitroub, Salim] Univ Sci & Technol Houari Boumedienne, Elect & Comp Sci Fac, Telecommun Dept, Signal & Image Proc Lab, Algiers, Algeria.
   [Bouridane, Ahmed] Northumbria Univ Newcastle, Dept Comp Sci & Digital Technol, Newcastle Upon Tyne NE2 1XE, Tyne & Wear, England.
C3 Universite Kasdi Merbah Ouargla; University Science & Technology Houari
   Boumediene; Northumbria University
RP Chitroub, S (corresponding author), Univ Sci & Technol Houari Boumedienne, Elect & Comp Sci Fac, Telecommun Dept, Signal & Image Proc Lab, Algiers, Algeria.
EM Ameraoumia@gmail.com; s_chitroub@hotmail.com;
   Ahmed.Bouridane@northumbria.ac.uk
OI Meraoumia, Abdallah/0000-0002-1387-380X
CR [Anonymous], 2005, Biometric Systems: Technology, Design and Performance Evaluation
   [Anonymous], P IEEE INT WORKSH BI
   [Anonymous], 2007, Hyperspectral Data Exploitation: Theory and Applications
   [Anonymous], IEEE WORKSH EM TECHN
   [Anonymous], 2006, Handbook of Multibiometrics
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Cardinaux F, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P825, DOI 10.1109/AFGR.2004.1301636
   Chen YY, 2004, BIBE 2004: FOURTH IEEE SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING, PROCEEDINGS, P167, DOI 10.1109/BIBE.2004.1317339
   Cui JR, 2012, INT J BIOMETRICS, V4, P106, DOI 10.1504/IJBM.2012.046244
   Dabbaghchian S, 2010, PATTERN RECOGN, V43, P1431, DOI 10.1016/j.patcog.2009.11.001
   Dai QY, 2004, IEEE IMAGE PROC, P893
   Dong Han, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P2074, DOI 10.1109/ICOSP.2008.4697553
   Fierrez J, 2007, PATTERN RECOGN LETT, V28, P2325, DOI 10.1016/j.patrec.2007.07.012
   Guo ZH, 2009, LECT NOTES COMPUT SC, V5702, P50
   Hao Y, 2008, IEEE IMAGE PROC, P281, DOI 10.1109/ICIP.2008.4711746
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Kekre H. B., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P433, DOI 10.1109/ICB.2012.6199789
   Kong A, 2006, PATTERN RECOGN, V39, P478, DOI 10.1016/j.patcog.2005.08.014
   Kumar A, 2010, IEEE T INSTRUM MEAS, V59, P730, DOI 10.1109/TIM.2009.2028773
   Li W, 2009, IEEE SYS MAN CYBERN, P4847, DOI 10.1109/ICSMC.2009.5346053
   Noore A, 2007, INFORM FUSION, V8, P337, DOI 10.1016/j.inffus.2005.09.005
   Park JH, 2007, OPT ENG, V46
   Pietikinen MK, 2001, SERIES MACHINE PERCE, V40
   Prasad S. M., 2009, Proceedings of the 2009 World Congress on Nature & Biologically Inspired Computing (NaBIC 2009), P520, DOI 10.1109/NABIC.2009.5393383
   Richard AJ, 1990, APPL MULTIVARIATE ST
   Ross A, 2001, LECT NOTES COMPUT SC, V2091, P354
   Senapati S, 2007, INT J INTELL SYST, V2, P68
   Singh R, 2008, INFORM FUSION, V9, P200, DOI 10.1016/j.inffus.2006.06.002
   Sricharan KK, 2006, PROC SPIE, V6202, DOI 10.1117/12.666438
   Tahmasebi A., 2011, Proceedings of the 2011 International Conference on Intelligent Computation and Bio-Medical Instrumentation (ICBMI 2011), P208, DOI 10.1109/ICBMI.2011.36
   Tee C., 2003, Image and vision computing NZ, P227
   Varchol P, 2007, RADIOENGINEERING, V16, P82
   Wang CM, 2003, IEEE T MED IMAGING, V22, P50, DOI 10.1109/TMI.2002.806858
   Wang Fenghua, 2007, Journal of Xi'an Jiaotong University, V41, P889
   Wu XQ, 2006, IEEE T SYST MAN CY A, V36, P978, DOI 10.1109/TSMCA.2006.871797
   Xu XP, 2012, SENSORS-BASEL, V12, P4633, DOI 10.3390/s120404633
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang D, 2010, IEEE T INSTRUM MEAS, V59, P480, DOI 10.1109/TIM.2009.2028772
   Zhang Donghui, 2008, Power Tech 2007, P1
NR 39
TC 6
Z9 6
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 3
BP 955
EP 978
DI 10.1007/s11042-013-1706-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZO
UT WOS:000349356400014
DA 2024-07-18
ER

PT J
AU Yang, WC
   Chen, LH
AF Yang, Wen-Chao
   Chen, Ling-Hwei
TI A steganographic method via various animations in PowerPoint files
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; PowerPoint file; Animation effects; Timing effects;
   Transition effects
ID SCHEME; ROBUST
AB In a PowerPoint file, animation effects are used to emphasize objects, timing effects are used to control the presentation time, and slide transition effects are used to highlight particular slides. Thus, using various effects can make the presentation of a PowerPoint file more colorful and attractive. In this paper, we propose a steganographic method to embed message in a PowerPoint file via various effects. In contrast to other steganographic methods, we not only hide message naturally but also keep the content of the cover media intact. Furthermore, the proposed method can resist the format conversion attack. The experiment result demonstrates that the proposed method is undetectable under some visual and statistical attacks.
C1 [Yang, Wen-Chao; Chen, Ling-Hwei] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Chen, LH (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
EM wchy@debut.cis.nctu.edu.tw; lhchen@cc.nctu.edu.tw
FU National Science Council of Republic of China
   [NSC-100-2221-E-009-140-MY2]
FX This work is supported in part by National Science Council of Republic
   of China under grant NSC-100-2221-E-009-140-MY2.
CR [Anonymous], 2000, Digital Watermarking
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chou J, 2001, INT CONF ACOUST SPEE, P1349, DOI 10.1109/ICASSP.2001.941178
   Cox IJ, 2008, MKS MULTIMED INFORM, P425, DOI 10.1016/B978-012372585-1.50015-2
   Hu YC, 2006, PATTERN RECOGN, V39, P1715, DOI 10.1016/j.patcog.2006.02.005
   Jing MQ, 2009, INT C MACH LEARN CYB, P12
   Lee CC, 2008, PATTERN RECOGN, V41, P2097, DOI 10.1016/j.patcog.2007.11.018
   Lee YK, 2003, INT J PATTERN RECOGN, V17, P967, DOI 10.1142/S021800140300268X
   Lee YK, 2002, INT J PATTERN RECOGN, V16, P681, DOI 10.1142/S0218001402001952
   Lee YK, 2000, IEE P-VIS IMAGE SIGN, V147, P288, DOI 10.1049/ip-vis:20000341
   Liu SH, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3990
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qin C, 2012, PATTERN RECOGN LETT, V33, P2166, DOI 10.1016/j.patrec.2012.08.004
   Qin C, 2012, FUND INFORM, V120, P59, DOI 10.3233/FI-2012-749
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zou DK, 2005, IEEE INT SYMP CIRC S, P4971
NR 16
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 3
BP 1003
EP 1019
DI 10.1007/s11042-013-1708-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZO
UT WOS:000349356400016
DA 2024-07-18
ER

PT J
AU Barkowsky, M
   Sedano, I
   Brunnström, K
   Leszczuk, M
   Staelens, N
AF Barkowsky, Marcus
   Sedano, Inigo
   Brunnstrom, Kjell
   Leszczuk, Mikolaj
   Staelens, Nicolas
TI Hybrid video quality prediction: reviewing video quality measurement for
   widening application scope
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video quality assessment; Human visual system; Hybrid model development;
   Perceptual indicators; Quality of Experience
ID PACKET-LOSS VISIBILITY; CONTRAST; MECHANISMS; MASKING; VISION; MODEL
AB A tremendous number of objective video quality measurement algorithms have been developed during the last two decades. Most of them either measure a very limited aspect of the perceived video quality or they measure broad ranges of quality with limited prediction accuracy. This paper lists several perceptual artifacts that may be computationally measured in an isolated algorithm and some of the modeling approaches that have been proposed to predict the resulting quality from those algorithms. These algorithms usually have a very limited application scope but have been verified carefully. The paper continues with a review of some standardized and well-known video quality measurement algorithms that are meant for a wide range of applications, thus have a larger scope. Their individual artifacts prediction accuracy is usually lower but some of them were validated to perform sufficiently well for standardization. Several difficulties and shortcomings in developing a general purpose model with high prediction performance are identified such as a common objective quality scale or the behavior of individual indicators when confronted with stimuli that are out of their prediction scope. The paper concludes with a systematic framework approach to tackle the development of a hybrid video quality measurement in a joint research collaboration.
C1 [Barkowsky, Marcus] Univ Nantes, IRCCyN UMR CNRS 6597, LUNAM Univ, F-44306 Nantes, France.
   [Sedano, Inigo] ICT European Software Inst, TECNALIA, Zamudio 48170, Spain.
   [Brunnstrom, Kjell] Acreo Swedish ICT AB, Dept Netlab, Stockholm, Sweden.
   [Brunnstrom, Kjell] Mid Sweden Univ, Stockholm, Sweden.
   [Leszczuk, Mikolaj] AGH Univ Sci & Technol, PL-30059 Krakow, Poland.
   [Staelens, Nicolas] Univ Ghent, Dept Informat Technol, iMinds, B-9000 Ghent, Belgium.
C3 Centre National de la Recherche Scientifique (CNRS); Nantes Universite;
   Acreo AB; Mid-Sweden University; AGH University of Krakow; IMEC; Ghent
   University
RP Barkowsky, M (corresponding author), Univ Nantes, IRCCyN UMR CNRS 6597, LUNAM Univ, Rue Christian Pauc, F-44306 Nantes, France.
EM Marcus.Barkowsky@univ-nantes.fr; inigo.sedano@tecnalia.com;
   kjell.brunnstrom@acreo.se; leszczuk@agh.edu.pl;
   nicolas.staelens@intec.ugent.be
RI Leszczuk, Mikołaj I/C-4857-2011; Brunnström, Kjell/T-9793-2019
OI Leszczuk, Mikołaj I/0000-0001-9123-1039; Brunnström,
   Kjell/0000-0001-5060-9402; Sedano, Inigo/0000-0001-6279-641X
FU Polish National Centre for Research and Development (NCRD)
   [SP/I/1/77065/10]; Swedish Governmental Agency for Innovation Systems
   (Vinnova)
FX The authors would like to thank the members of the Video Quality Experts
   Group (VQEG), in particular Arthur Webster, for all the support they
   have received. Furthermore, the work of Mikolaj Leszczuk is supported by
   The Polish National Centre for Research and Development (NCRD) under
   Grant No. SP/I/1/77065/10 by the Strategic Scientific Research and
   Experimental Development programme: "Interdisciplinary System for
   Interactive Scientific and Scientific-Technical Information". The work
   of Kjell Brunnstrom has been supported by the Swedish Governmental
   Agency for Innovation Systems (Vinnova), which is hereby gratefully
   acknowledged.
CR Ahumada Jr AJ, 1998, P SPIE HUM VIS EL IM, V3299, P152
   [Anonymous], 2012, EUROPEAN NETWORK QUA
   [Anonymous], 2003, Final report from the video quality experts group on the validation of objective models of video quality assessment
   [Anonymous], 2003, Digital Video and HDTV Algorithms and Interfaces
   Argyropoulos S, 2011, 3 INT WORKSH QUAL MU
   Barkowsky M., 2012, QOEMCS 2012 3 WORKSH, P1
   Barkowsky M, 2006, IEEE IMAGE PROC, P429, DOI 10.1109/ICIP.2006.312449
   Barkowsky M, 2009, IEEE J-STSP, V3, P266, DOI 10.1109/JSTSP.2009.2015375
   Barten Peter G. J, 1999, Contrast sensitivity of the human eye and its effects on image quality
   Bradley R.A., 1984, NONPARAMETRIC METHOD, V4, P299, DOI DOI 10.1016/S0169-7161(84)04016-5
   Bruce V., 2003, Visual perception: Physiology, psychology, and ecology
   Brunnström K, 2002, OPT ENG, V41, P711, DOI 10.1117/1.1431551
   Brunnström K, 1999, PROC SPIE, V3644, P403, DOI 10.1117/12.348461
   Brunnstrom K, 2012, P 6 INT WORKSH VID P
   BURBECK CA, 1980, J OPT SOC AM, V70, P1121, DOI 10.1364/JOSA.70.001121
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   D'Angelo A, 2010, IEEE T IMAGE PROCESS, V19, P867, DOI 10.1109/TIP.2009.2035869
   Daly S, 1998, P SOC PHOTO-OPT INS, V3299, P180, DOI 10.1117/12.320110
   De Haan G, 1998, P IEEE, V86, P1839, DOI 10.1109/5.705528
   Engelke U, 2010, IEEE INT WORKSH QUAL
   FARINA Modesto., 2011, PEREZ, Clotilde. BASTOS, P01
   FOLEY JM, 1994, J OPT SOC AM A, V11, P1710, DOI 10.1364/JOSAA.11.001710
   Fredericksen RE, 1999, J OPT SOC AM A, V16, P2601, DOI 10.1364/JOSAA.16.002601
   GIROD B, 1989, P SOC PHOTO-OPT INS, V1077, P178
   GOLDSTEIN B, 2006, SENSATION PERCEPTION
   Hands DS, 2001, ELECTRON LETT, V37, P752, DOI 10.1049/el:20010522
   Hekstra AP, 2002, SIGNAL PROCESS-IMAGE, V17, P781, DOI 10.1016/S0923-5965(02)00056-5
   International Telecommunication Union Telecommunication standardization sector ITU-T, 2012, P1202 ITUT
   International Telecommunication Union Telecommunication standardization sector ITU-T, 2012, P1201 ITUT
   International Telecommunications Union (ITU), 2011, J342 ITU
   International Telecommunications Union (ITU), 2008, J246 ITU
   Kanumuri S, 2006, IEEE T MULTIMEDIA, V8, P341, DOI 10.1109/TMM.2005.864343
   Kanumuri S, 2006, IEEE IMAGE PROC, P2245, DOI 10.1109/ICIP.2006.312809
   Keimel C, 2012, EUR SIGNAL PR CONF, P1244
   KOENDERINK JJ, 1979, OPT LETT, V4, P32, DOI 10.1364/OL.4.000032
   Kooij R, 2009, P SOC PHOTO-OPT INS, V7240, P72401
   Lambrecht CJV, 1996, P SOC PHOTO-OPT INS, V2668, P450, DOI 10.1117/12.235440
   LEGGE GE, 1980, J OPT SOC AM, V70, P1458, DOI 10.1364/JOSA.70.001458
   Liao N, 2011, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2011-5
   LIU T, 2009, SALIENCY INSPIRED MO
   Lubin J., 1995, VISION MODELS TARGET, P245
   Lubin Jeffrey, 1993, P163
   Ma Z, 2012, IEEE T CIRC SYST VID, V22, P671, DOI 10.1109/TCSVT.2011.2177143
   Malacara D., 2001, COLOR VISION COLORIM
   Naccari M, 2009, IEEE T MULTIMEDIA, V11, P932, DOI 10.1109/TMM.2009.2021785
   NTIA / ITS, 2001, T1TRPP742001 ATIS
   PELI E, 1990, J OPT SOC AM A, V7, P2032, DOI 10.1364/JOSAA.7.002032
   POYNTON C, 2006, COLOR FAQ FREQUENTLY
   POYNTON CA, 1998, FREQUENTLY ASKED QUE
   Reibman AR, 2004, IEEE IMAGE PROC, P171
   Reibman AR, 2004, IEEE T MULTIMEDIA, V6, P327, DOI 10.1109/TMM.2003.822785
   Rodríguez DZ, 2012, IEEE T CONSUM ELECTR, V58, P985, DOI 10.1109/TCE.2012.6311346
   Romaniak P, 2012, CONSUM COMM NETWORK, P597, DOI 10.1109/CCNC.2012.6181021
   Staelens N, 2011, P 2011 3 INT WORKSH
   Strohmeier D, 2010, 5 INT WORKSH VID PRO
   Takahashi A, 2008, IEEE COMMUN MAG, V46, P78, DOI 10.1109/MCOM.2008.4473087
   TAM WJ, 1995, P SOC PHOTO-OPT INS, V2411, P111, DOI 10.1117/12.207532
   Tektronix Inc, 2001, T1TRPP762001 ATIS
   Thurstone LL, 1927, PSYCHOL REV, V34, P273, DOI 10.1037/h0070288
   Video Quality Experts Group, 2007, PROJ HOM VQEG JOINT
   VQEG Tools and Subjective Labs Setup, 2010, PROJ HOM VQEG STL
   Watson AB, 2005, J VISION, V5, P717, DOI 10.1167/5.9.6
   Watson AB, 1997, J OPT SOC AM A, V14, P2379, DOI 10.1364/JOSAA.14.002379
   Watson AB, 2002, DRAFT STANDARD SUBJE
   Westen SJP, 1996, INT CONF ACOUST SPEE, P2124, DOI 10.1109/ICASSP.1996.545735
   WINKLER S, 2000, THESIS ECOLE POLYTEC
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   Wolf S, 2009, ITU T CONTRIBUTION
   Yamagishi K, 2009, GLOB TEL C GLOBECOM
   Yang FZ, 2010, IEEE T CIRC SYST VID, V20, P1544, DOI 10.1109/TCSVT.2010.2087433
   Yining Q, 2006, P INT C INT INF HID
   Zhao M, 2005, PROC SPIE, V5685, P683, DOI 10.1117/12.586962
NR 72
TC 9
Z9 9
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 2
BP 323
EP 343
DI 10.1007/s11042-014-1978-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ8DP
UT WOS:000348445300002
OA Green Published, hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Sevillano, X
   Alías, F
AF Sevillano, Xavier
   Alias, Francesc
TI A one-shot domain-independent robust multimedia clustering methodology
   based on hybrid multimodal fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robust multimedia clustering; Hybrid multimodal fusion; Cluster
   ensembles; Self-refining consensus; Clustering indeterminacies
ID SPEAKER DIARIZATION; EVENT DETECTION; FEATURES; SEGMENTATION; CONSENSUS;
   AUDIO
AB The existence of multiple modalities poses a challenge to the design of multimedia data clustering systems, as the unsupervised nature of the problem makes it very difficult to determine a priori whether a single modality should dominate the clustering process, or if modalities should be combined somehow. In order to fight against these indeterminacies-which come on top of those referring to the selection of the optimal clustering algorithm and data representation for the problem at hand-, this work introduces robust multimedia clustering, a one-shot methodology for domain independent multimedia data clustering based on hybrid multimodal fusion. By means of experimentation, we firstly justify the motivation of the proposed methodology by proving the relevance of multimedia clustering indeterminacies. Subsequently, a specific multimedia clustering system based on the requirements of the methodology is implemented and evaluated on three multimedia clustering applications-music genres, photographic topics and audio-visual objects classification-as a proof of concept, analyzing the quality of the obtained partitions and the time complexity of the proposal. The experimental results reveal that the implemented system, which includes a self-refining consensus clustering procedure for attaining high levels of robustness, allows to obtain, in a fully unsupervised manner, better quality partitions than 93 % of the clusterers available in our experiments, being even able to improve the quality of the best ones and outperforming state-of-the-art alternatives.
C1 [Sevillano, Xavier; Alias, Francesc] La Salle Univ Ramon Llull, Grp Recerca Tecnol Media, Barcelona 08022, Spain.
C3 Universitat Ramon Llull
RP Sevillano, X (corresponding author), La Salle Univ Ramon Llull, Grp Recerca Tecnol Media, Quatre Camins 30, Barcelona 08022, Spain.
EM xavis@salle.url.edu; falias@salle.url.edu
RI Alías-Pujol, Francesc/L-1088-2014; Sevillano, Xavier/ABF-5507-2020
OI Alías-Pujol, Francesc/0000-0002-1921-2375; Sevillano,
   Xavier/0000-0002-6209-3033
CR [Anonymous], P CBMI
   [Anonymous], 2006, INT C INF FUS
   [Anonymous], P MLMI
   [Anonymous], PERCEPTUAL KNOWLEDGE
   [Anonymous], 2002, ADV NEURAL INFORM PR
   [Anonymous], 2004, Proceedings of the 12th ACM International Conference on Multimedia, DOI DOI 10.1145/1027527.1027747
   [Anonymous], THESIS SALLE U RAMON
   [Anonymous], DESIGNING BUILDING P
   [Anonymous], P ACM MM
   [Anonymous], P SDM
   [Anonymous], P ICPR
   [Anonymous], 2009, P 18 INT C WORLD WID
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Atrey PK, 2006, MULTIMEDIA SYST, V12, P239, DOI 10.1007/s00530-006-0063-8
   Ayache S, 2007, LECT NOTES COMPUT SC, V4425, P494
   Barnard K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P408, DOI 10.1109/ICCV.2001.937654
   Bassiou N, 2010, IEEE T AUDIO SPEECH, V18, P2134, DOI 10.1109/TASL.2010.2042121
   Bekkerman R, 2007, PROC IEEECVPR, P1
   Bendjebbour A, 2001, IEEE T GEOSCI REMOTE, V39, P1789, DOI 10.1109/36.942557
   Bin Gao, 2005, 13th Annual ACM International Conference on Multimedia, P112
   Chaudhuri K., 2009, P 26 ANN INT C MACH, P129
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Dy JG, 2004, J MACH LEARN RES, V5, P845
   Fern XZ, 2004, P 21 INT C MACH LEAR, P36, DOI [10.1145/1015330.1015414, DOI 10.1145/1015330.1015414]
   Frank A., 2010, UCI MACHINE LEARNING
   Fred ALN, 2005, IEEE T PATTERN ANAL, V27, P835, DOI 10.1109/TPAMI.2005.113
   Fred ALN, 2002, INT C PATT RECOG, P276, DOI 10.1109/ICPR.2002.1047450
   Friedland G, 2009, INT CONF ACOUST SPEE, P4069, DOI 10.1109/ICASSP.2009.4960522
   Ghosh J, 2011, WIRES DATA MIN KNOWL, V1, P305, DOI 10.1002/widm.32
   Gionis A., 2007, CLUSTERING AGGREGATI, DOI 10.1145/1217299.1217303
   Goder A, 2008, SIAM PROC S, P109
   Hoyer PO, 2004, J MACH LEARN RES, V5, P1457
   Hyvärinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71
   Iam-on N, 2010, BIOINFORMATICS, V26, P1513, DOI 10.1093/bioinformatics/btq226
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Jolliffe J., 1986, Principal component analysis
   Kaski S, 1998, IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, P413, DOI 10.1109/IJCNN.1998.682302
   Klosgen W., 2002, Handbook of Data Mining and Knowledge Discovery
   Kohavi R, 1998, Feature Selection forKnowledge Discovery and Data Mining, P33, DOI 10.1007/978-1-4615-5725-8_3.
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li T, 2007, IEEE DATA MINING, P577, DOI 10.1109/ICDM.2007.98
   Loeff N., 2006, P COLINGACL, P547
   Lu WT, 2011, PROC INT CONF DOC, P319, DOI 10.1109/ICDAR.2011.72
   Monti S, 2003, MACH LEARN, V52, P91, DOI 10.1023/A:1023949509487
   Ni JJ, 2004, ICIA 2004: Proceedings of 2004 International Conference on Information Acquisition, P323
   Pinto FR, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-44
   Sevillano X., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P697, DOI 10.1145/1148170.1148323
   Sevillano X, 2007, LECT NOTES COMPUT SC, V4666, P794
   Sevillano X, 2012, FUZZY SET SYST, V193, P1, DOI 10.1016/j.fss.2011.09.007
   Strehl A., 2002, J. Machine Learning Res, V3, P583
   Topchy A, 2004, SIAM PROC S, P379
   Torkkola K, 2003, PATTERN ANAL APPL, V6, P301, DOI 10.1007/s10044-003-0196-8
   Turnbull Douglas, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P439, DOI 10.1145/1277741.1277817
   Vajaria H, 2006, INT C PATT RECOG, P1150
   van Rijsbergen C. J, 1979, Information Retrieval, V2nd
   Witten I. H., 2005, DATA MINING PRACTICA
   Wu ZY, 2006, LECT NOTES COMPUT SC, V3832, P493
   Xu H, 2006, ACM T MULTIM COMPUT, V2, P44, DOI 10.1145/1126004.1126007
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Ye Y, 2010, P 16 ACM SIGKDD INT, P95
   Yu ZW, 2009, IEEE T NANOBIOSCI, V8, P147, DOI 10.1109/TNB.2009.2023321
   Yu ZW, 2008, IEEE IJCNN, P505, DOI 10.1109/IJCNN.2008.4633839
   Zhang XR, 2008, IEEE T GEOSCI REMOTE, V46, P2126, DOI 10.1109/TGRS.2008.918647
NR 64
TC 6
Z9 6
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1507
EP 1543
DI 10.1007/s11042-013-1655-x
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200019
DA 2024-07-18
ER

PT J
AU Li, JL
   Wang, XY
   Li, G
   Zhang, FQ
   Feng, D
AF Li, Junli
   Wang, Xiuying
   Li, Gang
   Zhang, Fuqiang
   Feng, David
TI Quality assessment of perceptual color video based on a top-down
   framework and quaternion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video quality assessment; Top-down framework; Cognitive analysis;
   Quaternion; Singular value decomposition; Edge; Chrominance; Temporal
   correlation
ID IMAGE QUALITY; MODEL
AB Objective video quality assessment is of great importance in a variety of video processing applications. Most existing video quality metrics either focus primarily on capturing spatial artifacts in the video signal, or are designed to assess only grayscale video thereby ignoring important chrominance information. In this paper, on the basis of the top-down visual analysis of cognitive understanding and video features, we propose and develop a novel full-reference perceptual video assessment technique that accepts visual information inputs in the form of a quaternion consisting of contour, color and temporal information. Because of the more important role of chrominance information in the "border-to-surface" mechanism at early stages of cognitive visual processing, our new metric takes into account the chrominance information rather than the luminance information utilized in conventional video quality assessment. Our perceptual quaternion model employs singular value decomposition (SVD) and utilizes the human visual psychological features for SVD block weighting to better reflect perceptual focus and interest. Our major contributions include: a new perceptual quaternion that takes chrominance as one spatial feature, and temporal information to model motion or changes across adjacent frames; a three-level video quality measure to reflect visual psychology; and the two weighting methods based on entropy and frame correlation. Our experimental validation on the video quality experts' group (VQEG) Phase I FR-TV test dataset demonstrated that our new assessment metric outperforms PSNR, SSIM, PVQM (P8) and has high correlation with perceived video quality.
C1 [Li, Junli] Sichuan Normal Univ, Coll Comp Sci, Chengdu 610066, Peoples R China.
   [Wang, Xiuying; Feng, David] Univ Sydney, Biomed & Multimedia Informat Technol Res Grp, Sch Informat Technol, Sydney, NSW 2006, Australia.
   [Li, Gang; Zhang, Fuqiang] Ningbo Univ, Coll Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
C3 Sichuan Normal University; University of Sydney; Ningbo University
RP Wang, XY (corresponding author), Univ Sydney, Biomed & Multimedia Informat Technol Res Grp, Sch Informat Technol, Sydney, NSW 2006, Australia.
EM jkxy_ljl@sicnu.edu.cn; xiuying@it.usyd.edu.au; feng@it.usyd.edu.au
RI wang, xiao/HZI-9156-2023; Wang, Guanhua/JXM-6373-2024
OI Wang, Xiu Ying/0000-0001-7160-5929; Feng, Dagan/0000-0002-3381-214X
FU National Natural Science Foundation of China [60832003]; Sichuan
   scientific and technical support plan [2013SZ0085]; natural science
   foundation of Ningbo City [2012A610047]
FX This research was supported by the National Natural Science Foundation
   of China under Grant No. 60832003, Sichuan scientific and technical
   support plan under Grant No. 2013SZ0085 and the natural science
   foundation of Ningbo City under Grant No. 2012A610047.
CR Alexiadis DS, 2009, COMPUT VIS IMAGE UND, V113, P212, DOI 10.1016/j.cviu.2008.08.013
   Alexiadis DS, 2009, IEEE T IMAGE PROCESS, V18, P168, DOI 10.1109/TIP.2008.2007603
   [Anonymous], P INT C MULT EXP
   [Anonymous], 43 ANN AS C SIGN SYS
   [Anonymous], ENCY ARTIFICIAL INTE
   [Anonymous], 2006, MODERN IMAGE QUALITY
   [Anonymous], FINAL REPORT VIDEO Q
   [Anonymous], 2002, DIGITAL IMAGE PROCES
   [Anonymous], ACTA ELECT SINICA
   [Anonymous], 2005, Digital Video Quality: Vision Models and Metrics
   [Anonymous], CONTR COM 12 60 EV N
   [Anonymous], P ROYAL IRISH ACAD
   [Anonymous], FINAL REPORT VIDEO Q
   [Anonymous], 2003, H 264 MPEG 4 VIDEO C
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Elder JH, 1998, VISION RES, V38, P143, DOI 10.1016/S0042-6989(97)00138-7
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   FINDLAY JM, 1980, PERCEPTION, V9, P7, DOI 10.1068/p090007
   Fuqiang Zhang, 2009, Proceedings of the 2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2009), P7, DOI 10.1109/FSKD.2009.332
   Grossberg S, 2006, SPATIAL VISION, V19, P263, DOI 10.1163/156856806776923399
   Hekstra AP, 2002, SIGNAL PROCESS-IMAGE, V17, P781, DOI 10.1016/S0923-5965(02)00056-5
   Hung CP, 2007, NAT NEUROSCI, V10, P1185, DOI 10.1038/nn1948
   Kantor I.L, 1989, Hypercomplex Numbers: An Ele-mentary Introduction to Algebras
   Le Bihan N, 2004, SIGNAL PROCESS, V84, P1177, DOI 10.1016/j.sigpro.2004.04.001
   Lee C, 2006, OPT ENG, V45, DOI 10.1117/1.2401154
   Ma XJ, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P233, DOI 10.1109/ICME.2008.4607414
   Osberger W, 1998, INT C PATT RECOG, P701, DOI 10.1109/ICPR.1998.711240
   Pei SC, 1996, ISCAS 96: 1996 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - CIRCUITS AND SYSTEMS CONNECTING THE WORLD, VOL 2, P684, DOI 10.1109/ISCAS.1996.541817
   Senders JW, 1997, P SOC PHOTO-OPT INS, V3016, P186, DOI 10.1117/12.274513
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Shnayderman A, 2006, IEEE T IMAGE PROCESS, V15, P422, DOI 10.1109/TIP.2005.860605
   Shnayderman A, 2005, P SOC PHOTO-OPT INS, V5668, P70, DOI 10.1117/12.584550
   Shnayderman A, 2004, P SOC PHOTO-OPT INS, V5294, P82, DOI 10.1117/12.530554
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Subakan ÖN, 2009, LECT NOTES COMPUT SC, V5681, P415, DOI 10.1007/978-3-642-03641-5_31
   Tsui TK, 2008, IEEE T INF FOREN SEC, V3, P16, DOI 10.1109/TIFS.2007.916275
   Wang YQ, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P433, DOI 10.1109/CISP.2008.269
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2007, J OPT SOC AM A, V24, pB61, DOI 10.1364/JOSAA.24.000B61
   Wang Z, 2006, IEEE IMAGE PROC, P2945, DOI 10.1109/ICIP.2006.313136
   Watson AB, 2001, J ELECTRON IMAGING, V10, P20, DOI 10.1117/1.1329896
   WEBSTER AA, 1993, P SOC PHOTO-OPT INS, V1913, P15, DOI 10.1117/12.152700
   Winkler S, 1999, PROC SPIE, V3644, P175, DOI 10.1117/12.348438
   Yang Chun-ling, 2007, Acta Electronica Sinica, V35, P1313
   Yang Wei, 2008, Journal of Beijing University of Aeronautics and Astronautics, V34, P1
   Zhang FZ, 1997, LINEAR ALGEBRA APPL, V251, P21, DOI 10.1016/0024-3795(95)00543-9
   Zhang Q, 2012, SIGNAL PROCESS, V92, P912, DOI 10.1016/j.sigpro.2011.10.004
NR 50
TC 0
Z9 0
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2871
EP 2893
DI 10.1007/s11042-013-1506-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300034
DA 2024-07-18
ER

PT J
AU Hou, XD
   Zhang, T
   Xiong, G
   Zhang, Y
   Ping, X
AF Hou, Xiaodan
   Zhang, Tao
   Xiong, Gang
   Zhang, Yan
   Ping, Xin
TI Image resampling detection based on texture classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensic; Steganalysis; Resampling detection; Texture analysis;
   Local linear transform
ID STEGANALYSIS
AB This study presents a method for resampling detection. By combining texture analysis with resampling detection, the task of resampling detection is considered as a texture classification problem. In other words, the influence of resampling operations on a raw single-sampled image is viewed as an alteration of the image texture in a fine scale. First, local linear transform is used to obtain textural detail sub-bands. A 36-D feature vector is then extracted from the normalized characteristic function moments of textural detail sub-bands to train a support vector machine classifier. Finally, experimental results are reported on three databases, with each having almost 10,000 images. Comparison with the previous study reveals that the proposed method is effective for resampling detection. In addition, extensive experiments on cover and stego bitmap images illustrate that the proposed method is essential for constructing accurate targeted and blind steganalysis methods for heterogeneous images, raw single-sampled images, and images resampled at different scales.
C1 [Hou, Xiaodan; Zhang, Tao; Xiong, Gang] Zhengzhou Informat Sci & Technol Inst, Zhengzhou 450002, Henan, Peoples R China.
   [Zhang, Yan; Ping, Xin] Zhengzhou Univ Light Ind, Zhengzhou 450002, Henan, Peoples R China.
C3 PLA Information Engineering University; Zhengzhou University of Light
   Industry
RP Hou, XD (corresponding author), Zhengzhou Informat Sci & Technol Inst, Zhengzhou 450002, Henan, Peoples R China.
EM hxd2305@163.com
FU National Natural Science Foundation of China [61272490, 60903221]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61272490 and 60903221). The authors would like to thank the
   reviewers for their insightful comments and helpful suggestions.
CR [Anonymous], IMAGE DATABASE STEGA
   Bin Li, 2008, Proceedings of the SPIE - The International Society for Optical Engineering, V6819, P681912, DOI 10.1117/12.765817
   Chang C.C., LIBSVM: a library for support vector machines
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Feng XY, 2012, IEEE T MULTIMEDIA, V14, P536, DOI 10.1109/TMM.2012.2191946
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   Gallagher AC, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P65, DOI 10.1109/CRV.2005.33
   Harmsen JJ, 2003, PROC SPIE, V5020, P131, DOI 10.1117/12.476813
   Kirchner M, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P11, DOI 10.1145/1411328.1411333
   Li X, 2014, MULTIMED TOOLS APPL, V68, P1051, DOI 10.1007/s11042-012-1112-2
   Lyu SW, 2006, IEEE T INF FOREN SEC, V1, P111, DOI 10.1109/TIFS.2005.863485
   Mahdian B, 2008, IEEE T INF FOREN SEC, V3, P529, DOI 10.1109/TIFS.2004.924603
   NG I, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P627, DOI 10.1109/ICPR.1992.202065
   Popescu AC, 2004, LECT NOTES COMPUT SC, V3200, P128
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Prasad S, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1325, DOI 10.1109/ICME.2006.262783
   Sallee P, 2004, LECT NOTES COMPUT SC, V2939, P154
   Sharp Toby, 2001, Information Hiding, V2137, P13, DOI 10.1007/3-540-45496-9_2
   Shi YQ, 2005, ITCC 2005: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 1, P768, DOI 10.1109/ITCC.2005.138
   Siwei L., 2003, LNCS, V2578, P340, DOI DOI 10.1007/3-540-36415-3_22
   Uccheddu F, 2010, EUR SIGNAL PR CONF, P1675
   UNSER M, 1986, SIGNAL PROCESS, V11, P61, DOI 10.1016/0165-1684(86)90095-2
   Wang Y, 2007, IEEE T INF FOREN SEC, V2, P31, DOI 10.1109/TIFS.2006.890517
   Xiong G, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.3.033015
   Xuan GR, 2005, LECT NOTES COMPUT SC, V3727, P262
   Zheng EG, 2011, KSII T INTERNET INF, V5, P840, DOI 10.3837/tiis.2011.04.012
NR 26
TC 12
Z9 12
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1681
EP 1708
DI 10.1007/s11042-013-1466-0
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300029
DA 2024-07-18
ER

PT J
AU Lin, CS
   Chang, RH
   Lin, JW
AF Lin, Chow-Sing
   Chang, Rong-Hua
   Lin, Jhe-Wei
TI TuBeck: a novel peer-to-peer streaming system with Loopback-MDC for
   scalable H.264/AVC videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Streaming; Peer-to-peer; Multiple description coding; Loopback-MDC;
   H.264
ID NETWORK; BANDWIDTH; SERVER
AB With the rapidly development of broadband networks, more and more users nowadays tend to acquire their desired videos from media-on-demand servers. How to efficiently provide multimedia contents for a large number of heterogeneous users on the Internet has become a noticeable issue. In our previous work, we proposed the Loopback-MDC scheme on CDN-P2P network to address such a scalability issue. In this paper, we present the design and implementation of a novel peer-to-peer streaming system with the Loopback-MDC on actual networks, named TuBeck. The TuBeck consists of preprocessor, server, peer, and player modules with the support of network infrastructure library. In TuBeck, multimedia sources are preprocessed to multiple descriptions. Each description is divided as a sequence of H.264/AVC chunks by modified JM encoder for real-time streaming. The network infrastructure library provides the nodes (server and peers) with the fundamental functionalities of network connections and communications. Message exchange and streaming control among nodes follow the pre-defined LM protocol. The server, peer, and player modules are functionally multithreaded in order to enhance the system performance. The experimental results show that the Loopback-MDC is practical for realizing a P2P streaming system in terms of the server loading, CPU/Memory usage, and efficiency of failure recovery with respect to various arrival rates, failure rates, and viewing qualities.
C1 [Lin, Chow-Sing; Chang, Rong-Hua; Lin, Jhe-Wei] Natl Univ Tainan, Dept Comp Sci & Informat Engn, Tainan 700, Taiwan.
C3 National University Tainan
RP Lin, CS (corresponding author), Natl Univ Tainan, Dept Comp Sci & Informat Engn, 33,Sec 2,Shu Lin St, Tainan 700, Taiwan.
EM mikelin@mail.nutn.edu.tw
RI Lin, Chow-Sing/JPX-6621-2023
FU National Science Council [NSC 97-2221-E-024-014-MY3]
FX This work was partially supported by National Science Council under
   contracts NSC 97-2221-E-024-014-MY3.
CR Akyol E, 2006, IEEE IMAGE PROC, P725, DOI 10.1109/ICIP.2006.312443
   Akyol E, 2007, IEEE J-STSP, V1, P231, DOI 10.1109/JSTSP.2007.901527
   [Anonymous], 2011, DISTRIBUTED MULTIPLE
   Campana O, 2006, P INT C WIR REC TERM, P217
   Castro M., 2003, Operating Systems Review, V37, P298, DOI 10.1145/1165389.945474
   Chen ZJ, 2007, GLOB TELECOMM CONF, P2086
   Dai L, 2007, IEEE ICC, P1734, DOI 10.1109/ICC.2007.290
   Dong Y, 2004, P 8 INT MULT SYST SP
   Fouliras P, 2004, SAC 04, P1226, DOI [10.1145/967900.968150, DOI 10.1145/967900.968150]
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   GUO Y, 2003, P 12 INT WORLD WID W
   Hua K. A., 1998, Proceedings ACM Multimedia 98, P191, DOI 10.1145/290747.290771
   Hunag C, 2008, P NOSSDAV08 ACM, P75
   Kusmierek E, 2006, IEEE T MULTIMEDIA, V8, P233, DOI 10.1109/TMM.2005.864277
   Lin CS, 2011, INT J COMMUN SYST, V24, P568, DOI 10.1002/dac.1173
   Lin CS, 2010, INT J COMMUN SYST, V23, P553, DOI 10.1002/dac.1087
   Lin CS, 2008, P IEEE 22 INT C ADV, P795
   Ma WH, 2004, IEEE T MULTIMEDIA, V6, P599, DOI 10.1109/TMM.2004.830819
   Ma WH, 2002, IEEE T MULTIMEDIA, V4, P539, DOI 10.1109/TMM.2002.806536
   Padmanabhan V.N., 2002, P 12 INT WORKSHOP NE, P177
   Padmanabhan VN, 2003, 11TH IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P16, DOI 10.1109/ICNP.2003.1249753
   Sheu S, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P110, DOI 10.1109/MMCS.1997.609583
   Tran DA, 2003, 22 ANN JOINT C IEEE
   Xiao X, 2008, MM 08 P 16 ACM INT C, P785
   Xu Dongyan., 2004, Computer Networks, V44, P353
NR 25
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1653
EP 1679
DI 10.1007/s11042-013-1482-0
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300028
DA 2024-07-18
ER

PT J
AU Zhou, SS
   Chen, QC
   Wang, XL
AF Zhou, Shusen
   Chen, Qingcai
   Wang, Xiaolong
TI Handwritten Chinese text editing and recognition system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Handwriting recognition; Chinese character; Handwritten Chinese text
   editing
ID FEATURE-EXTRACTION; NORMALIZATION; CLASSIFIER; ONLINE
AB This paper describes a handwritten Chinese text editing and recognition system that can edit handwritten text and recognize it with a client-server mode. First, the client end samples and redisplays the handwritten text by using digital ink technics, segments handwritten characters, edits them and saves original handwritten information into a self-defined document. The self-defined document saves coordinates of all sampled points of handwriting characters. Second, the server recognizes handwritten document based on the proposed Gabor feature extraction and affinity propagation clustering (GFAP) method, and returns the recognition results to client end. Moreover, the server can also collect the labeled handwritten characters and fine tune the recognizer automatically. Experimental results on HIT-OR3C database show that our handwriting recognition method improves the recognition performance remarkably.
C1 [Zhou, Shusen; Chen, Qingcai; Wang, Xiaolong] Harbin Inst Technol, Shenzhen Grad Sch, Key Lab Network Oriented Intelligent Computat, Shenzhen, Peoples R China.
C3 Harbin Institute of Technology
RP Chen, QC (corresponding author), Harbin Inst Technol, Shenzhen Grad Sch, Key Lab Network Oriented Intelligent Computat, Shenzhen, Peoples R China.
EM zhoushusen@hitsz.edu.cn; qingcai.chen@hitsz.edu.cn;
   wangxl@insun.hit.edu.cn
RI Chen, Qingcai/JVN-1580-2024
FU National Natural Science Foundation of China [61173075, 60973076];
   Shenzhen Foundation Research Plan [JC201005260175A]
FX We would like to thank Xinggang Fu, Huili Li, Xinyi Guo, Hui Li, Suqin
   Ao, Zou Chen, and Junqi Pu for their contributions in handwritten
   Chinese text editing and recognition system. We would also like to thank
   all the volunteers for their contributions in HIT-OR3C. We would also
   like to thank Chenglin Liu et al. in Chinese Academy of Sciences, and
   Lianwen Jin et al. in South China University of Technology, for their
   providing of CASIA-OLHWDB1 and SCUT-COUCH2009 databases. This work was
   supported in part by the National Natural Science Foundation of China
   (No. 61173075 and No. 60973076), and Shenzhen Foundation Research Plan
   (JC201005260175A).
CR [Anonymous], P 10 INT WORKSH FRON
   Avola Danilo, 2010, International Journal of Virtual Technology and Multimedia, V1, P104, DOI 10.1504/IJVTM.2010.032056
   Da-Han Wang, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1206, DOI 10.1109/ICDAR.2009.163
   Ding K, 2011, ICIC EL B, V2, P25
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Holzinger A., 2010, ICE B 2010 ICETE INT, P120
   Holzinger A, 2011, 2011 PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON E-BUSINESS (ICE-B 2011), P219
   Holzinger A, 2012, COMM COM INF SC, V222, P97
   Jin LW, 2011, INT J DOC ANAL RECOG, V14, P53, DOI 10.1007/s10032-010-0116-6
   Jin LW, 2010, NEUROCOMPUTING, V73, P1614, DOI 10.1016/j.neucom.2009.11.039
   Kim IJ, 2003, IEEE T PATTERN ANAL, V25, P1422, DOI 10.1109/TPAMI.2003.1240117
   KIMURA F, 1987, IEEE T PATTERN ANAL, V9, P149, DOI 10.1109/TPAMI.1987.4767881
   Liu CL, 2005, PATTERN RECOGN, V38, P2242, DOI 10.1016/j.patcog.2005.04.019
   Liu CL, 2004, IEEE T PATTERN ANAL, V26, P198, DOI 10.1109/TPAMI.2004.1262182
   Liu CL, 2004, PATTERN RECOGN, V37, P265, DOI 10.1016/S0031-3203(03)00224-3
   Long T, 2008, PATTERN RECOGN, V41, P2916, DOI 10.1016/j.patcog.2008.02.009
   Long T, 2008, TOP GERIATR REHABIL, V24, P1
   Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821
   Qiu-Feng Wang, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1036, DOI 10.1109/ICDAR.2009.96
   Wang XW, 2005, PATTERN RECOGN, V38, P369, DOI 10.1016/j.patcog.2004.08.004
   Welling M., 2006, FISHER LINEAR DISCRI
   Wu TL, 2003, PROC INT CONF DOC, P529
   Zhang H.-P., 2003, Proc. of the second SIGHAN workshop on Chinese language process, P184, DOI [10.3115/1119250.1119280, DOI 10.3115/1119250.1119280]
   Zhang P, 2007, PATTERN RECOGN, V40, P3415, DOI 10.1016/j.patcog.2007.03.022
   Zhao SY, 2003, PATTERN RECOGN, V36, P145, DOI 10.1016/S0031-3203(02)00041-9
   Zhibin Huang, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P91, DOI 10.1109/ICDAR.2009.28
   Zhou Shusen, 2010, P INT WORKSH DOC AN, P223, DOI 10.1145/1815330.1815359
NR 27
TC 1
Z9 1
U1 4
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1363
EP 1380
DI 10.1007/s11042-012-1270-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000018
DA 2024-07-18
ER

PT J
AU Pan, MS
   Jiang, JJ
   Rong, QS
   Zhang, F
   Zhou, HC
   Nie, FY
AF Pan, Mei-sen
   Jiang, Jian-jun
   Rong, Qiu-sheng
   Zhang, Fen
   Zhou, Hui-can
   Nie, Fang-yan
TI A modified medical image registration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image moment; Improved PSNR; Medical image; Image registration; Least
   square method
ID NONRIGID REGISTRATION; MUTUAL-INFORMATION; SIGNAL; RECONSTRUCTION
AB Medical image registration is commonly used in clinical diagnosis, treatment, quality assurance, evaluation of curative efficacy and so on. In this paper, the edges of the original reference and floating images are detected by the B-spline gradient operator and then the binarization images are acquired. By computing the binarization image moments, the centroids are obtained. Also, according to the binarization image coordinates, the rotation angles of the reference and floating images are computed respectively, on the foundation of which the initial values for registering the images are produced. When searching the optimal geometric transformation parameters, the modified peak signal-to-noise ratio (MPSNR) is viewed as the similarity metric between the reference and floating images. At the same time, the simplex method is chosen as multi-parameter optimization one. The experimental results show that, this proposed method has a fairly simple implementation, a low computational load, a fast registration and good registration accuracy. It also can effectively avoid trapping in the local optimum and is adapted to both mono-modality and multi-modality image registrations. Also, the improved iterative closest point algorithm based on acquiring the initial values for registration from the least square method (LICP) is introduced. The experiments reveal that the measure acquiring the initial values for registration from image moments and the least square method (LSM) is feasible and resultful strategy.
C1 [Pan, Mei-sen; Rong, Qiu-sheng; Zhang, Fen; Zhou, Hui-can; Nie, Fang-yan] Hunan Univ Arts & Sci, Coll Comp Sci & Technol, Changde 415000, Hunan, Peoples R China.
   [Jiang, Jian-jun] Lib Hunan Univ Arts & Sci, Changde 415000, Hunan, Peoples R China.
C3 Hunan University of Arts & Science; Hunan University of Arts & Science
RP Pan, MS (corresponding author), Hunan Univ Arts & Sci, Coll Comp Sci & Technol, Changde 415000, Hunan, Peoples R China.
EM pmsjjj@126.com
FU Key Discipline-Leader Foundation of Hunan Provincial Institutions of
   Higher Education, PRC; Outstanding Young Scientific Research Fund of
   Hunan Provincial Education Department, PRC [09B071]
FX This paper was partially supported by the Key Discipline-Leader
   Foundation of Hunan Provincial Institutions of Higher Education, PRC and
   supported by Outstanding Young Scientific Research Fund of Hunan
   Provincial Education Department, PRC(No.09B071).
CR Bergevin R, 1996, IEEE T PATTERN ANAL, V18, P540, DOI 10.1109/34.494643
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Blondel C, 2004, PHYS MED BIOL, V49, P2197, DOI 10.1088/0031-9155/49/11/006
   BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   Can A, 2002, IEEE T PATTERN ANAL, V24, P347, DOI 10.1109/34.990136
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Fei BW, 2002, PHYS MED BIOL, V47, P823, DOI 10.1088/0031-9155/47/5/309
   Gelfand N, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P260, DOI 10.1109/IM.2003.1240258
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Krücker JF, 2002, IEEE T MED IMAGING, V21, P1384, DOI 10.1109/TMI.2002.806424
   Kybic J, 2003, IEEE T IMAGE PROCESS, V12, P1427, DOI 10.1109/TIP.2003.813139
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Lu Zhen-tai, 2008, Acta Electronica Sinica, V36, P1974
   Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664
   Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8
   Pan MS, 2011, J INF SCI ENG, V27, P1761
   Park HJ, 2004, MED IMAGE ANAL, V8, P465, DOI 10.1016/j.media.2004.03.001
   Park SY, 2004, IMAGE VISION COMPUT, V22, P623, DOI 10.1016/j.imavis.2004.01.002
   Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867
   Radau PE, 2001, MED PHYS, V28, P1660, DOI 10.1118/1.1388894
   Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Saber E, 1997, J VIS COMMUN IMAGE R, V8, P3, DOI 10.1006/jvci.1997.0344
   Slomka PJ, 2001, ULTRASOUND MED BIOL, V27, P945, DOI 10.1016/S0301-5629(01)00387-8
   Stammberger T, 1999, MAGN RESON IMAGING, V17, P1033, DOI 10.1016/S0730-725X(99)00040-5
   Staring M, 2007, PHYS MED BIOL, V52, P6879, DOI 10.1088/0031-9155/52/23/007
   Szeliski R, 1997, INT J COMPUT VISION, V22, P199, DOI 10.1023/A:1007996332012
   Thévenaz P, 2000, IEEE T IMAGE PROCESS, V9, P2083, DOI 10.1109/83.887976
   UNSER M, 1993, IEEE T SIGNAL PROCES, V41, P834, DOI 10.1109/78.193221
   UNSER M, 1993, IEEE T SIGNAL PROCES, V41, P821, DOI 10.1109/78.193220
   Unser M, 1999, IEEE SIGNAL PROC MAG, V16, P22, DOI 10.1109/79.799930
   Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918
NR 33
TC 11
Z9 11
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1585
EP 1615
DI 10.1007/s11042-012-1180-3
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500010
DA 2024-07-18
ER

PT J
AU Cricri, F
   Dabov, K
   Curcio, IDD
   Mate, S
   Gabbouj, M
AF Cricri, Francesco
   Dabov, Kostadin
   Curcio, Igor D. D.
   Mate, Sujeet
   Gabbouj, Moncef
TI Multimodal extraction of events and of information about the recording
   activity in user generated videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal; Indexing; Sensor; Video; Multi-camera; Multi-user; Context;
   Event
ID STABILIZATION
AB In this work we propose methods that exploit context sensor data modalities for the task of detecting interesting events and extracting high-level contextual information about the recording activity in user generated videos. Indeed, most camera-enabled electronic devices contain various auxiliary sensors such as accelerometers, compasses, GPS receivers, etc. Data captured by these sensors during the media acquisition have already been used to limit camera degradations such as shake and also to provide some basic tagging information such as the location. However, exploiting the sensor-recordings modality for subsequent higher-level information extraction such as interesting events has been a subject of rather limited research, further constrained to specialized acquisition setups. In this work, we show how these sensor modalities allow inferring information (camera movements, content degradations) about each individual video recording. In addition, we consider a multi-camera scenario, where multiple user generated recordings of a common scene (e.g., music concerts) are available. For this kind of scenarios we jointly analyze these multiple video recordings and their associated sensor modalities in order to extract higher-level semantics of the recorded media: based on the orientation of cameras we identify the region of interest of the recorded scene, by exploiting correlation in the motion of different cameras we detect generic interesting events and estimate their relative position. Furthermore, by analyzing also the audio content captured by multiple users we detect more specific interesting events. We show that the proposed multimodal analysis methods perform well on various recordings obtained in real live music performances.
C1 [Cricri, Francesco; Dabov, Kostadin; Gabbouj, Moncef] Tampere Univ Technol, FIN-33101 Tampere, Finland.
   [Curcio, Igor D. D.; Mate, Sujeet] Nokia Res Ctr, Tampere, Finland.
C3 Tampere University; Nokia Corporation; Siemens AG; Nokia Siemens
   Networks; Nokia Finland
RP Cricri, F (corresponding author), Tampere Univ Technol, FIN-33101 Tampere, Finland.
EM francesco.cricri@tut.fi; kostadin.dabov@gmail.com;
   igor.curcio@nokia.com; sujeet.mate@nokia.com; moncef.gabbouj@tut.fi
RI Gabbouj, Moncef/G-4293-2014
OI Gabbouj, Moncef/0000-0002-9788-2323
CR Abdollahian G, 2010, IEEE T MULTIMEDIA, V12, P28, DOI 10.1109/TMM.2009.2036286
   Anjum N, 2007, INT CONF ACOUST SPEE, P281
   [Anonymous], P 3 INT WORKSH AUT I
   [Anonymous], P 18 ACM INT C MULT
   Bao Xuan., 2010, PROC MOBISYS 2010, P357, DOI DOI 10.1145/1814433.1814468
   Broilo M., 2010, P 3 INT WORKSH AUT I, P39
   Carlier Axel, 2010, P 18 ACM INT C MULT, P201
   Chiu-Kuo Liang, 2011, 2011 International Conference on Information Networking (ICOIN), P182, DOI 10.1109/ICOIN.2011.5723175
   Dong Y, 2007, INT WORKSH QUAL SERV, P87, DOI 10.1109/IWQOS.2007.376552
   Drahansky M, 2009, COMM COM INF SC, V58, P225
   FIELLER EC, 1957, BIOMETRIKA, V44, P470, DOI 10.2307/2332878
   Foote J., 2002, P ACM MULTIMEDIA 200, P553, DOI DOI 10.1145/641007.641119
   Huster A, 2001, OCEANS 2001 MTS/IEEE: AN OCEAN ODYSSEY, VOLS 1-4, CONFERENCE PROCEEDINGS, P1025, DOI 10.1109/OCEANS.2001.968257
   Jain R., 2010, INT C MULTIMEDIA, P1259, DOI DOI 10.1145/1873951.1874199
   Järvinen S, 2009, IEEE INT CON MULTI, P1756
   KAISER R, 2010, P ACM INT WORKSH EV, P29
   Kennedy Lyndon., 2009, WWW 09, P311, DOI [DOI 10.1145/1526709.1526752, 10.1145/1526709.1526752]
   Kim ET, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P630, DOI 10.1109/ICIP.1997.632200
   Lahti T, 2008, THESIS TAMPERE U TEC
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   MPEG, 15938 MPEG7 ISOIEC
   Ogino Ryuichi, 2008, SICE 2008 - 47th Annual Conference of the Society of Instrument and Control Engineers of Japan, P528, DOI 10.1109/SICE.2008.4654712
   Ong EP, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 1, PROCEEDINGS, P469, DOI 10.1109/ISSPA.2003.1224741
   Park HS, 2008, P IEEE RAS-EMBS INT, P109, DOI 10.1109/BIOROB.2008.4762876
   Peyrard N, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P409
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Shrestha P., 2010, Proceedings of the international conference on Multimedia (MM '10), P541, DOI DOI 10.1145/1873951.1874023
   Shrestha P, 2010, LECT NOTES COMPUT SC, V6475, P1, DOI 10.1007/978-3-642-17691-3_1
   Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5
   Sung-Hun Shin, 2011, 2011 International Conference on ICT Convergence, P772, DOI 10.1109/ICTC.2011.6082532
   VELIPASALAR S, 2006, P INT WORKSH SEM LEA, P110, DOI DOI 10.1109/CVPRW.2006.197
   [伍士国 Wu Shiguo], 2005, [火工品, Initiators & Pyrotechnics], V0, P1
   Yu HC, 2007, PHYS STATUS SOLIDI C, V4, P4647, DOI 10.1002/pssc.200777250
   Zakhor A, 1993, IEEE T IMAGE PROCESS, V2, P481, DOI 10.1109/83.242357
NR 34
TC 7
Z9 8
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 1
BP 119
EP 158
DI 10.1007/s11042-012-1085-1
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI4AK
UT WOS:000336807300006
OA hybrid
DA 2024-07-18
ER

PT J
AU Meixner, B
   Hoffmann, J
AF Meixner, Britta
   Hoffmann, Juergen
TI Intelligent download and cache management for interactive non-linear
   video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cache management; Download management; Interactive non-linear video;
   Video annotations
ID REPLACEMENT POLICIES; BUFFER MANAGEMENT; WEB; ALGORITHM; ARCHITECTURE;
   BROADCAST
AB Since the invention of digital video significant progress has been made in reducing the amount of data needed to be transferred in the World Wide Web while improving viewing experience. However the paradigm of linear behavior has not changed at all. While the feature set of traditional digital video may be sufficient for some applications, there are several use cases where a significantly improved way of interacting with the content is highly desirable. It is possible to organize a video in an interactive and non-linear way. Additional information (for example high resolution images) can be added to any scene of the video. The non-linearity of the video flow and the implementation of additional content not found in traditional videos may lead to an increased download volume and/or a playback with many breaks for downloading missing elements. This paper describes a player framework for interactive non-linear videos. We developed the framework and its associated algorithms to simulate the playback of non-linear video content. It minimizes interruption when the sequence of scenes is directly influenced by interaction, while the traditional viewing experience is not altered. The evaluation showed that it is possible to reach shorter startup times using our strategies than using the strategies of other players. Furthermore, we demonstrated that a prefetching of elements does not lead to an increased download volume in every case. In contrast, it can even decrease the download volume if the right delete strategy is selected. It can be noted that the knowledge of the structure of interactive non-linear videos can be used to minimize startup times at the beginning of scenes while the download volume is not increased.
C1 [Meixner, Britta] Univ Passau, Chair Distributed Informat Syst, D-94032 Passau, Germany.
   [Hoffmann, Juergen] Univ Passau, D-94032 Passau, Germany.
C3 University of Passau; University of Passau
RP Meixner, B (corresponding author), Univ Passau, Chair Distributed Informat Syst, Innstr 43, D-94032 Passau, Germany.
EM meixner@fim.uni-passau.de; hoffmanj@fim.uni-passau.de
RI Meixner, Britta/T-7013-2017
CR 5min LTD, 2010, 5MIN LIF VID BET
   Abhari A, 2006, FUTURE GENER COMP SY, V22, P16, DOI 10.1016/j.future.2005.08.003
   Abrams M., 1995, P 4 INT WORLD WID WE, P119
   Adzic V, 2011, MULTIMED TOOLS APPL, V51, P379, DOI 10.1007/s11042-010-0669-x
   Aggarwal C, 1999, IEEE T KNOWL DATA EN, V11, P94, DOI 10.1109/69.755618
   [Anonymous], 2011, P 19 ACM INT C MULT
   [Anonymous], 2010, P 18 ACM INT C MULT
   [Anonymous], 2002, P ACM MULT JUAN LES
   [Anonymous], 2008, SMIL 3 0 FLEXIBLE MU
   [Anonymous], 2011, ACM MULTIMEDIA
   [Anonymous], P WORLD C E LEARN CO
   Arlitt M, 2000, PERF E R SI, V27, P3, DOI [10.1145/362883.362920, 10.1145/346000.346003]
   AUBERT O., 2005, P 16 ACM C HYPERTEXT, P235
   Aubert O, 2008, MULTIMEDIA SYST, V14, P427, DOI 10.1007/s00530-008-0132-2
   Avramova Z, 2011, MULTIMEDIA SYST, V17, P5, DOI 10.1007/s00530-010-0201-1
   Bahn H, 2002, COMPUTER, V35, P65, DOI 10.1109/MC.2002.1009170
   Bhikharie W., 2010, XIMPEL OVERVIEW
   Bian NZ, 2007, FIRST INTERNATIONAL WORKSHOP ON KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS, P469, DOI 10.1109/WKDD.2008.124
   Bolot JC, 1996, COMPUT NETWORKS ISDN, V28, P1397, DOI 10.1016/0169-7552(96)00073-6
   Bota F, 2002, P IADIS INT C WWW IN, P620
   Branch P., 1999, IEEE International Conference on Networks. ICON '99 Proceedings (Cat. No.PR00243), P391, DOI 10.1109/ICON.1999.796202
   Bulterman Dick C.A., 2004, INT MULT C P 12 ANN, V10, P492
   BV VIDDIX, 2010, VIDD BET MIX VID WEB
   Cao P, 1997, PROCEEDINGS OF THE USENIX SYMPOSIUM ON INTERNET TECHNOLOGIES AND SYSTEMS, P193
   Carlsson N, 2008, IEEE T MULTIMEDIA, V10, P871, DOI 10.1109/TMM.2008.922847
   Cheng K, 2000, COMP SOFTW APPL C 20, P148, DOI [10.1109/CMPSAC.2000.884690, DOI 10.1109/CMPSAC.2000.884690]
   Chilamkurti N, 2010, MULTIMED TOOLS APPL, V47, P189, DOI 10.1007/s11042-009-0413-6
   Cho K, 2003, LECT NOTES COMPUT SC, V2869, P276
   Cohen E., 1998, Algorithms - ESA '98. 6th Annual European Symposium. Proceedings, P307
   De Vleeschauwer D, 2009, IEEE T BROADCAST, V55, P491, DOI 10.1109/TBC.2009.2015983
   Doherty John, 2003, P 11 ACM INT C MULT, P600, DOI [10.1145/957013.957140, DOI 10.1145/957013.957140]
   Fei ZM, 2005, IEEE T MULTIMEDIA, V7, P942, DOI 10.1109/TMM.2005.854403
   Foong AP, 2000, IC'2000: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTERNET COMPUTING, P269
   Friedrich M., 2000, Proceedings ACM Multimedia 2000, P117, DOI 10.1145/354384.354446
   GAO B., 2011, P NOSSDAV, P105, DOI DOI 10.1145/1989240.1989266
   Geetha K, 2009, WOR CONG NAT BIOL, P1405
   Gotz D., 2006, Proceedings of the 14th annual ACM international conference on Multimedia, P357, DOI DOI 10.1145/1180639.1180717
   Hammoud RI, 2006, SIG COM TEC, P3
   Hoffmann P, 2008, LECT NOTES COMPUT SC, V5066, P51
   Hollfelder S., 1998, Advances in Multimedia Information Systems. 4th International Workshop, MIS'98. Proceedings, P82
   Hollfelder S, 1999, MULTIMEDIA INFORM SY, P115
   InnoTeamS GmbH, 2010, ADIVI ADD DIG INF VI
   Jin S, 2001, COMPUT COMMUN, V24, P174, DOI 10.1016/S0140-3664(00)00312-1
   Kosch H, 2004, MULTIMED TOOLS APPL, V22, P235, DOI 10.1023/B:MTAP.0000017030.45487.43
   Krishnappa DK, 2011, LECT NOTES COMPUT SC, V6579, P72, DOI 10.1007/978-3-642-19260-9_8
   Laraspata R., 2010, 2010 IEEE Symposium on Computers and Communications (ISCC), P997, DOI 10.1109/ISCC.2010.5546653
   Lee I, 2010, MULTIMED TOOLS APPL, V47, P207, DOI 10.1007/s11042-009-0414-5
   Lee S, 2008, COMPUT COMMUN, V31, P2621, DOI 10.1016/j.comcom.2008.02.011
   Li YF, 2009, MULTIMED TOOLS APPL, V44, P65, DOI 10.1007/s11042-009-0264-1
   Li ZH, 2011, PROBAB APPL SER, P1, DOI 10.1007/978-3-642-15004-3_1
   Liao WK, 2002, IEEE IC COMP COM NET, P216, DOI 10.1109/ICCCN.2002.1043069
   Liebl G, 2005, LECT NOTES COMPUT SC, V3420, P882
   Liu JC, 2004, WORLD WIDE WEB, V7, P281, DOI 10.1023/B:WWWJ.0000028181.13079.80
   Makar M, 2010, IEEE IMAGE PROC, P4437, DOI 10.1109/ICIP.2010.5653982
   Mayer-Patel K, 2007, IEEE MULTIMEDIA, V14, P68, DOI 10.1109/MMUL.2007.63
   Mehmood R, 2011, MULTIMED TOOLS APPL, V54, P551, DOI 10.1007/s11042-010-0569-0
   Meixner B., 2010, Proceedings of the 18th ACM international conference on Multimedia, P1563, DOI [https://doi.org/10.1145/1873951.1874287, DOI 10.1145/1873951.1874287]
   Miller G, 2011, LECT NOTES COMPUT SC, V6972, P337, DOI 10.1007/978-3-642-24500-8_37
   Murta C. D., 1998, P 3 INT WWW CACH WOR
   Niclausse N, 1998, P WORKSH INT SERV PE
   Palau CE, 2011, MULTIMED TOOLS APPL, V53, P591, DOI 10.1007/s11042-010-0516-0
   ParandehGheibi A, 2011, IEEE J SEL AREA COMM, V29, P1064, DOI 10.1109/JSAC.2011.110516
   Park Y, 2007, LECT NOTES COMPUT SC, V4773, P612
   Podlipnig S, 2003, ACM COMPUT SURV, V35, P374, DOI 10.1145/954339.954341
   Qiang Yang, 2001, Proceedings of the 34th Annual Hawaii International Conference on System Sciences, DOI 10.1109/HICSS.2001.926537
   Quick TV Limited, 2010, MAK YOUR VID DYN INT
   Rizzo L, 2000, IEEE ACM T NETWORK, V8, P158, DOI 10.1109/90.842139
   Scheuermann P, 1997, COMPUT NETWORKS ISDN, V29, P997, DOI 10.1016/S0169-7552(97)00032-9
   Seitner FH, 2011, MULTIMED TOOLS APPL, V53, P431, DOI 10.1007/s11042-010-0501-7
   Sharman R, 2007, ACM T WEB, V1, DOI 10.1145/1281480.1281483
   Shipman F., 2003, P 11 ACM INT C MULT, P392, DOI DOI 10.1145/957013.957096
   Shipman F, 2008, ACM T MULTIM COMPUT, V5, DOI 10.1145/1413862.1413868
   Shreedhar M, 1996, IEEE ACM T NETWORK, V4, P375, DOI 10.1109/90.502236
   Sun HM, 2012, MULTIMED TOOLS APPL, V57, P587, DOI 10.1007/s11042-010-0659-z
   Tatarinov I, 1998, EFFICIENT LFU LIKE P
   Tsai MF, 2010, MULTIMED TOOLS APPL, V47, P49, DOI 10.1007/s11042-009-0406-5
   Velammal B. L., 2009, International Journal of Computer and Network Security, V1, P89
   Wauters T, 2006, EUROMICRO CONF PROC, P379, DOI 10.1109/EUROMICRO.2006.29
   WESSELS D, 1995, THESIS U COLORADO BO
   Williams S., 1996, Computer Communication Review, V26, P293, DOI 10.1145/248157.248182
   Wong KY, 2006, IEEE NETWORK, V20, P28, DOI 10.1109/MNET.2006.1580916
   Wooster RP, 1997, COMPUT NETWORKS ISDN, V29, P977, DOI 10.1016/S0169-7552(97)00041-X
   YouTube LLC, 2011, CREAT ED ANN
   Zhao YP, 2007, IEEE ACM T NETWORK, V15, P1149, DOI 10.1109/TNET.2007.896534
NR 84
TC 1
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 905
EP 948
DI 10.1007/s11042-012-1158-1
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900016
DA 2024-07-18
ER

PT J
AU Ruocco, M
   Ramampiaro, H
AF Ruocco, Massimiliano
   Ramampiaro, Heri
TI A scalable algorithm for extraction and clustering of event-related
   pictures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event detection; Image clustering; Suffix tree
AB The event detection problem, which is closely related to clustering, has gained a lot of attentions within event detection for textual documents. However, although image clustering is a problem that has been treated extensively in both Content-Based Image Retrieval (CBIR) and Text-Based Image Retrieval (TBIR) systems, event detection within image management is a relatively new area. Having this in mind, we propose a novel approach for event extraction and clustering of images, taking into account textual annotations, time and geographical positions. Our goal is to develop a clustering method based on the fact that an image may belong to an event cluster. Here, we stress the necessity of having an event clustering and cluster extraction algorithm that are both scalable and allow online applications. To achieve this, we extend a well-known clustering algorithm called Suffix Tree Clustering (STC), originally developed to cluster text documents using document snippets. The idea is that we consider an image along with its annotation as a document. Further, we extend it to also include time and geographical position so that we can capture the contextual information from each image during the clustering process. This has appeared to be particularly useful on images gathered from online photo-sharing applications such as Flickr. Hence, our STC-based approach is aimed at dealing with the challenges induced by capturing contextual information from Flickr images and extracting related events. We evaluate our algorithm using different annotated datasets mainly gathered from Flickr. As part of this evaluation we investigate the effects of using different parameters, such as time and space granularities, and compare these effects. In addition, we evaluate the performance of our algorithm with respect to mining events from image collections. Our experimental results clearly demonstrate the effectiveness of our STC-based algorithm in extracting and clustering events.
C1 [Ruocco, Massimiliano; Ramampiaro, Heri] Norwegian Univ Sci & Technol NTNU, Dept Comp & Informat Sci, N-7491 Trondheim, Norway.
C3 Norwegian University of Science & Technology (NTNU)
RP Ruocco, M (corresponding author), Norwegian Univ Sci & Technol NTNU, Dept Comp & Informat Sci, N-7491 Trondheim, Norway.
EM ruocco@idi.ntnu.no; heri@idi.ntnu.no
RI Ruocco, Massimiliano/M-6051-2013; Ramampiaro, Heri/AAG-6442-2020
OI Ruocco, Massimiliano/0000-0001-7038-5362; Ramampiaro,
   Heri/0000-0003-0534-5924
FU Research Council of Norway under VERDIKT program [176858]
FX We would like to thank Symeon Papadopoulos for being helpful and
   providing us the Barcelona dataset. This work is supported by the
   Research Council of Norway, grant number 176858 under the VERDIKT
   program.
CR Allan J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P37, DOI 10.1145/290941.290954
   Allan J., 1998, P DARPA BROADC NEWS
   [Anonymous], P 2008 INT C CONT BA
   [Anonymous], P MULT INF RETR 08 V
   [Anonymous], 2007, PROCEEDINGSOFTHE48TH
   [Anonymous], 2003, P 26 ANN INT ACM SIG, DOI DOI 10.1145/860435.860495
   [Anonymous], P ACM INT C MULT, DOI DOI 10.1145/1101149.1101167
   [Anonymous], 2010, P 3 ACM INT C WEB SE, DOI DOI 10.1145/1718487.1718524
   [Anonymous], 2008, 2008 IEEE C COMPUTER
   [Anonymous], P MEDIAEVAL 2010 WOR
   Baeza-Yates R A, 2011, MODERN INFORM RETRIE
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bttcher S., 2010, Information Retrieval: Implementing and Evaluating Search Engines
   Carpineto C, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1541880.1541884
   Chen L., 2009, Proceedings of the 18th ACM conference on Information and knowledge management, P523
   Das M, 2009, 2009 IEEE THIRD INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING (ICSC 2009), P116, DOI 10.1109/ICSC.2009.36
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   FIALHO A, 2010, EVENTS10
   Fung G.P. C., 2005, VLDB, P181
   Gammeter S, 2009, IEEE I CONF COMP VIS, P614, DOI 10.1109/ICCV.2009.5459180
   GRANVILLE B, 2007, INT C ENT INF SYST W
   GULLA JA, 2008, EMERGING TECHNOLOGIE, V3237, P184
   HERNANDEZARANDA D, 2010, MEDIAEVAL 2010 WORKI
   HU M, 2008, WIDM 08, P1
   Jin Y, 2007, INFORM PROCESS MANAG, V43, P365, DOI 10.1016/j.ipm.2006.07.007
   Kamps J, 2003, LECT NOTES COMPUT SC, V3237, P152
   Kurtz S, 1999, SOFTWARE PRACT EXPER, V29, P1149, DOI 10.1002/(SICI)1097-024X(199911)29:13<1149::AID-SPE274>3.0.CO;2-O
   Li LJ, 2007, IEEE I CONF COMP VIS, P345
   LIN Y, 2011, SIGIR, P405
   Loui AC, 2003, IEEE T MULTIMEDIA, V5, P390, DOI 10.1109/TMM.2003.814723
   NEMRAVA J, 2006, P 15 INT C KNOWL ENG, P33
   Papadopoulos S, 2011, IEEE MULTIMEDIA, V18, P52, DOI 10.1109/MMUL.2010.68
   PORTER MF, 1997, ALGORITHM SUFFIX STI
   RUOCCO M, 2010, 2010 IEEE INT S MULT, P41
   Serdyukov P., 2009, P 32 INT ACM SIGIR C
   Shapira B, 2005, ONLINE INFORM REV, V29, P374, DOI 10.1108/14684520510617820
   SMITH DA, 2002, JCDL 02
   Trieschnigg D., 2005, Journal of Digital Information Management, V3, P21
   TRONCY R, 2010, ACM INT C P SERIES
   UKKONEN E, 1995, ALGORITHMICA, V14, P249, DOI 10.1007/BF01206331
   WARTENA C, 2010, MEDIAEVAL 2010 WORKI
   Yang Y., 1998, P 21 ANN INT ACM SIG, P28, DOI DOI 10.1145/290941.290953
   Zamir O., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P46, DOI 10.1145/290941.290956
   ZHANG K, 2007, SIGIR 07, P215
   Zhang W, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P33, DOI 10.1109/3dpvt.2006.80
NR 45
TC 12
Z9 12
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 1
BP 55
EP 88
DI 10.1007/s11042-012-1087-z
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI4AK
UT WOS:000336807300004
DA 2024-07-18
ER

PT J
AU Chen, YM
   Wu, WC
AF Chen, Yi-Ming
   Wu, Wei-Chen
TI An anonymous DRM scheme for sharing multimedia files in P2P networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anonymity; P2P; DRM; Group key; Digital content sharing
AB Peer-to-Peer (P2P) systems enable efficient multimedia file sharing and are inherently scalable on the Internet. However, the absence of a centralized authority and a suitable Digital Right Management (DRM) mechanism prompts many securities-related challenges and discourages the widespread use of P2P networks for distributing copyright-protected multimedia files. To address these issues, we adopt the concept of a group Diffie-Hellman group key and threshold scheme to propose a novel anonymous DRM scheme for P2P users that wish to share multimedia files. Our scheme has four features: (1) the P2P users remain anonymous while sharing their files, (2) no online server is needed to perform the DRM operations, (3) an adjustable mechanism exists for efficiently distributing multimedia files with different popularities, and (4) users enjoy low communication and computation costs. In addition to explaining the operations of this scheme, we also compare its performance and security with Zhang et al.'s design, TLMS and Lua's Scheme within the context of this study.
C1 [Chen, Yi-Ming; Wu, Wei-Chen] Natl Cent Univ, Dept Informat Management, Jhongli 32001, Taoyuan County, Taiwan.
   [Wu, Wei-Chen] Hsin Sheng Coll Med Care & Management, Ctr Comp, Lungtan Township 32544, Taoyuan County, Taiwan.
C3 National Central University
RP Wu, WC (corresponding author), Hsin Sheng Coll Med Care & Management, Ctr Comp, 418 Kaoping Village, Lungtan Township 32544, Taoyuan County, Taiwan.
EM cym@cc.ncu.edu.tw; wwu@hsc.edu.tw
OI Wu, Wei-chen/0000-0002-2419-6453
CR Chaum D., 1983, Advances in Cryptology, Proceedings of Crypto 82, P199
   CHAUM D, 1988, LECT NOTES COMPUT SC, V304, P227
   Chaum D, 1982, ADV CRYPTOLOGY CRYPT, P153
   Chen HB, 2003, 37TH ANNUAL 2003 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P245
   Chu CC, 2006, CONSUM COMM NETWORK, P1119
   Douceur JR, 2002, LECT NOTES COMPUT SC, V2429, P251, DOI 10.1007/3-540-45748-8_24
   Einhorn Michael A., 2005, PEER TO PEER NETWORK
   Iwata T, 2003, APCC 2003: 9TH ASIA-PACIFIC CONFERENCE ON COMMUNICATION, VOLS 1-3, PROCEEDINGS, P806, DOI 10.1109/APCC.2003.1274471
   Koo S, 2005, P 9 WORLD MULT SYST, P10
   Lee J, 2007, ASTROPHYS J, V657, P30, DOI 10.1086/511003
   Levine Brian Neil, 2006, A survey of solutions to the Sybil Attack, V7, P224
   Lua EK, 2007, 2007 INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES, VOLS 1-3, P1213
   Schneier B., 1996, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Steiner M., 1996, 3rd ACM Conference on Computer and Communications Security, P31, DOI 10.1145/238168.238182
   Steiner M, 2000, IEEE T PARALL DISTR, V11, P769, DOI 10.1109/71.877936
   Steiner M, 1998, INT CON DISTR COMP S, P380, DOI 10.1109/ICDCS.1998.679745
   Sung JY, 2006, 8th International Conference on Advanced Communication Technology, Vols 1-3, pU487
   Wei-Chen Wu, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P873, DOI 10.1109/IIH-MSP.2009.176
   Zhang X, 2008, 15 SPIE ACM MULT COM, V6818
NR 20
TC 4
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 1041
EP 1065
DI 10.1007/s11042-012-1166-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300021
DA 2024-07-18
ER

PT J
AU Li, LY
   Wang, YT
   Tang, Z
   Gao, LC
AF Li, Luyuan
   Wang, Yongtao
   Tang, Zhi
   Gao, Liangcai
TI Automatic comic page segmentation based on polygon detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Comic image segmentation; Polygon detection; Line clustering; Line
   segment detection; Integral image
AB Comic page segmentation aims to automatically decompose scanned comic images into storyboards (frames), which is the key technique to produce digital comic documents that are suitable for reading on mobile devices. In this paper, we propose a novel method for comic page segmentation by finding the quadrilateral enclosing box of each storyboard. We first acquire the edge image of the input comic image, and then extract line segments with a heuristic line segment detection algorithm. We perform line clustering to further merge the overlapped line segments and remove the redundancy line segments. Finally, we perform another round of line clustering and post-processing to compose the obtained line segments into complete quadrilateral enclosing boxes of the storyboards. The proposed method is tested on 2,237 comic images from 12 different printed comic series, and the experimental results demonstrate that our method is effective for comic image segmentation and outperforms the existing methods.
C1 [Li, Luyuan; Wang, Yongtao; Tang, Zhi; Gao, Liangcai] Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.
   [Tang, Zhi] State Key Lab Digital Publishing Technol, Beijing, Peoples R China.
C3 Peking University
RP Wang, YT (corresponding author), Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.
EM liluyuan@pku.edu.cn; wyt@pku.edu.cn; tangzhi@pku.edu.cn;
   gaoliangcai@pku.edu.cn
RI gao, liangcai/P-8338-2017
FU National Basic Research Program of China, also Named "973 Program"
   [2010CB735908]
FX This work is supported by National Basic Research Program of China, also
   Named "973 Program" (No. 2010CB735908).
CR BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chung KL, 2010, PATTERN RECOGN LETT, V31, P11, DOI 10.1016/j.patrec.2009.09.013
   Forsyth DA, 2002, COMPUTER VISION MODE, P467
   Grana C, 2010, IEEE T IMAGE PROCESS, V19, P1596, DOI 10.1109/TIP.2010.2044963
   Ho CT, 1996, PATTERN RECOGN LETT, V17, P467, DOI 10.1016/0167-8655(96)00009-8
   In Yusuke, 2010, Advances in Visualization, Imaging and Simulation. 3rd WSEAS International Conference on Visualization, Imaging and Simulation (VIS 2010), P23
   Ishii D, 2010, WORKSH PICT COD IM P, P124
   Jain AK, 1998, IEEE T PATTERN ANAL, V20, P294, DOI 10.1109/34.667886
   LOT RC, 1995, PATTERN RECOGN, V28, P647, DOI 10.1016/0031-3203(94)00127-8
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Tanaka T, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2885
   Theodoridis S, 2008, PATTERN RECOGN, P20
   Tolle H., 2010, INT J UBIQUITOUS COM, V1, P1
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Xi J, 2002, PATTERN RECOGN, V35, P2695, DOI 10.1016/S0031-3203(01)00248-5
   Yamada M, 2004, IEICE T INF SYST, VE87D, P1370
NR 19
TC 15
Z9 15
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2014
VL 69
IS 1
BP 171
EP 197
DI 10.1007/s11042-012-1241-7
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AB3UH
UT WOS:000331715200009
DA 2024-07-18
ER

PT J
AU Li, X
   Zhang, T
   Zhang, Y
   Li, WX
   Li, KD
AF Li, Xing
   Zhang, Tao
   Zhang, Yan
   Li, Wenxiang
   Li, Kaida
TI A novel blind detector for additive noise steganography in JPEG
   decompressed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information hiding; Steganography; Steganalysis; JPEG decompressed
   images; Universal blind detection
ID LSB STEGANOGRAPHY; MULTIPLE SECRETS; SHARING SCHEME; STEGANALYSIS;
   DIFFERENCE
AB This paper proposes a novel universal steganalyzer for additive noise steganography in JPEG decompressed images. On the basis of the influence of the message embedding on the statistical distributions of alternating current (ac) discrete cosine transform (DCT) coefficients, we first develop a new steganalytic feature which is defined as the ratio between different ranges of the normalized ac coefficients histogram. Then a powerful blind detector is constructed with the proposed one-dimensional (1-D) feature. Extensive experimental results demonstrate that the proposed steganalyzer outperforms the existing state-of-the-art schemes significantly and even can detect the additive noise steganography effectively at a very low embedding rate. In addition, our method using a 1-D feature is not only practical and real-time, but also can provide a better control of the false positive rate and the false negative rate by adjusting the detection threshold. Moreover, the proposed feature can also be used to identify JPEG compression besides steganalysis, which indicates that our method has a great promise in practical applications.
C1 [Li, Xing; Zhang, Tao; Li, Wenxiang; Li, Kaida] Zhengzhou Informat Sci & Technol Inst, Zhengzhou 450002, Henan, Peoples R China.
   [Zhang, Yan] Zhengzhou Univ Light Ind, Zhengzhou 450002, Henan, Peoples R China.
C3 PLA Information Engineering University; Zhengzhou University of Light
   Industry
RP Li, X (corresponding author), Zhengzhou Informat Sci & Technol Inst, Zhengzhou 450002, Henan, Peoples R China.
EM listarcat@163.com
FU National Natural Science Foundation of China [60903221]
FX This work was supported by the National Natural Science Foundation of
   China (No. 60903221). The authors would like to thank the reviewers for
   their insightful comments and helpful suggestions.
CR [Anonymous], IMAGE DATABASE STEGA
   Cancelli G, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P795, DOI 10.1109/MMSP.2008.4665182
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Fridrich J, 2005, PROC SPIE, V5681, P595, DOI 10.1117/12.584426
   Fridrich J, 2003, PROC SPIE, V5020, P191, DOI 10.1117/12.479739
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Fridrich J, 2001, PROC SPIE, V4518, P275, DOI 10.1117/12.448213
   Goljan M, 2006, PROC SPIE, V6072, DOI 10.1117/12.643254
   Harmsen JJ, 2003, PROC SPIE, V5020, P131, DOI 10.1117/12.476813
   Holotyak T, 2005, LECT NOTES COMPUT SC, V3677, P273
   Ker Andrew D., 2009, Proceedings of the SPIE - The International Society for Optical Engineering, V7254, DOI 10.1117/12.805910
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Lin TL, 2010, INT J INNOV COMPUT I, V6, P5749
   Lin TL, 2010, EXPERT SYST APPL, V37, P7858, DOI 10.1016/j.eswa.2010.04.051
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P480, DOI 10.1109/TIFS.2010.2051426
   Marvel LM, 1999, IEEE T IMAGE PROCESS, V8, P1075, DOI 10.1109/83.777088
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Sharp Toby, 2001, Information Hiding, V2137, P13, DOI 10.1007/3-540-45496-9_2
   Theodoridis S, 2003, PATTERN RECOGN, V2nd
   Wang Y, 2007, IEEE T INF FOREN SEC, V2, P31, DOI 10.1109/TIFS.2006.890517
   Zhang J, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P385, DOI 10.1109/MMSP.2007.4412897
   Zhang J, 2010, IEEE SIGNAL PROC LET, V17, P141, DOI 10.1109/LSP.2009.2035379
   Zhang T, 2003, SIGNAL PROCESS, V83, P2085, DOI 10.1016/S0165-1684(03)00169-5
   Zhang T, 2010, INFORM SCIENCES, V180, P4685, DOI 10.1016/j.ins.2010.07.037
   Zheng EG, 2011, KSII T INTERNET INF, V5, P840, DOI 10.3837/tiis.2011.04.012
NR 28
TC 13
Z9 14
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 1051
EP 1068
DI 10.1007/s11042-012-1112-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000025
DA 2024-07-18
ER

PT J
AU Hamam, A
   Eid, M
   El Saddik, A
AF Hamam, Abdelwahab
   Eid, Mohamad
   El Saddik, Abdulmotaleb
TI Effect of kinesthetic and tactile haptic feedback on the quality of
   experience of edutainment applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Force feedback evaluation; Haptics in ambient environments; Human
   computer interaction; Quality of Experience (QoE); Tactile evaluation
ID TASKS
AB Haptic technologies and applications have received enormous attention in the last decade. The incorporation of haptic modality into multimedia applications adds excitement and enjoyment to an application. It also adds a more natural feel to multimedia applications, that otherwise would be limited to vision and audition, by engaging as well the user's sense of touch, giving a more intrinsic feel essential for ambient intelligent applications. However, the improvement of an application's Quality of Experience (QoE) by the addition of haptic feedback is still not completely understood. The research presented in this paper focuses on the effect of haptic feedback and what it potentially adds to the experience of the user as opposed to the traditional visual and auditory feedback. In essence, it investigates certain issues regarding stylus-based haptic education applications and haptic-enhanced entertainment videos. To this end, we used two haptic applications: the haptic handwriting learning tool to experiment with force feedback haptic interaction and the tactile YouTube application for tactile haptic feedback. In both applications, our analysis shows that the addition of haptic feedback will increase the QoE in the absence of fatigue or discomfort for this category of applications. This implies that the incorporation of haptic modality (both force feedback as well as tactile feedback) has positively contributed to the overall QoE for the users.
C1 [Hamam, Abdelwahab; Eid, Mohamad; El Saddik, Abdulmotaleb] Univ Ottawa, DISCOVER Lab, Ottawa, ON, Canada.
C3 University of Ottawa
RP Hamam, A (corresponding author), Univ Ottawa, DISCOVER Lab, Ottawa, ON, Canada.
EM ahamam@site.uottawa.ca
RI /D-4159-2009
OI /0000-0002-7690-8547
CR Aarts E, 2004, IEEE MULTIMEDIA, V11, P12, DOI 10.1109/MMUL.2004.1261101
   Andersson U, 2001, J Deaf Stud Deaf Educ, V6, P116, DOI 10.1093/deafed/6.2.116
   Aron E.N., 2003, STAT PSYCHOL
   Basdogan C., 2000, ACM Transactions on Computer-Human Interaction, V7, P443, DOI 10.1145/365058.365082
   Chen JYC, 2008, ERGONOMICS, V51, P1137, DOI 10.1080/00140130802030706
   Coles TR, 2011, IEEE T HAPTICS, V4, P51, DOI [10.1109/TOH.2010.19, 10.1109/ToH.2010.19]
   Ebrahimi T., 2009, P 17 ACM INT C MULTI, P3
   Eid M., 2007, International Journal of Advanced Media and Communication, V1, P71, DOI 10.1504/IJAMC.2007.013918
   Eid M.A., 2007, Proceedings of the international workshop on Educational multimedia and multimedia education (Emme '07), P103
   Eid M, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON VIRTUAL ENVIRONMENTS, HUMAN-COMPUTER INTERFACES AND MEASUREMENT SYSTEMS, P5, DOI 10.1109/VECIMS.2008.4592743
   El Saddik A, 2007, IEEE INSTRU MEAS MAG, V10, P10, DOI 10.1109/MIM.2007.339540
   GREENWAY RB, 1993, P SOC PHOTO-OPT INS, V1833, P317, DOI 10.1117/12.142121
   Gwilliam JC, 2009, IEEE INT CONF ROBOT, P3315
   Hamam A, 2008, HAVE 08
   Hamam A, 2008, HAS 08 P 2008 AMB SY
   Hamam A., 2010, Haptic Audio-Visual Environments and Games (HAVE), 2010 IEEE International Symposium on, P1
   Hamam A, 2008, LECT NOTES COMPUT SC, V5024, P129, DOI 10.1007/978-3-540-69057-3_14
   Jain R, 2004, IEEE MULTIMEDIA, V11, P96, DOI 10.1109/MMUL.2004.1261114
   King CH, 2009, IEEE T HAPTICS, V2, P103, DOI [10.1109/TOH.2009.4, 10.1109/ToH.2009.4]
   Mansour M., 2007, International Workshop on Educational Multimedia and Multimedia Education, P103
   Microsoft Inc, 2007, QUAL EXP STRAT COMP
   Naud M, 2009, JOINT VIRT REAL C EG
   Pawar VM, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P11, DOI 10.1109/VR.2009.4810992
   Rahman M.Abdur., 2010, Proceedings of the International Conference on Multimedia, P1643, DOI DOI 10.1145/1873951.1874310
   Robles-De-La-Torre G, 2006, IEEE MULTIMEDIA, V13, P24, DOI 10.1109/MMUL.2006.69
   Roid GH, 2004, INT TEST US C MELB A
   Srinivasan MA, 1997, COMPUT GRAPH-UK, V21, P393, DOI 10.1016/S0097-8493(97)00030-7
   Viau A, 2005, HUM FACTORS, V47, P816, DOI 10.1518/001872005775571023
   Wagner CR, 2007, PRESENCE-VIRTUAL AUG, V16, P252, DOI 10.1162/pres.16.3.252
   Westebring-van der Putten EP, 2010, IEEE T HAPTICS, V3, P280, DOI 10.1109/ToH.2010.23
   Whalen TE, 2003, VECIMS'03: 2003 IEEE INTERNATIONAL SYMPOSIUM ON VIRTUAL ENVIRONMENTS, HUMAN-COMPUTER INTERFACES AND MEASUREMENT SYSTEMS, P8
   Wu W, 2009, P 17 ACM INT C MULT, P81
NR 32
TC 19
Z9 21
U1 0
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 2
BP 455
EP 472
DI 10.1007/s11042-012-0990-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 205HY
UT WOS:000323435800007
DA 2024-07-18
ER

PT J
AU Kim, J
   Wang, X
   Wang, H
   Zhu, CS
   Kim, D
AF Kim, Jiman
   Wang, Xiaofei
   Wang, Hai
   Zhu, Chunsheng
   Kim, Daijin
TI Fast moving object detection with non-stationary background
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Harris corner detection; K-means optical flow clustering; Scatteredness;
   Motion compensation; Delaunay triangulation
ID SURVEILLANCE; TRACKING
AB The detection of moving objects under a free-moving camera is a difficult problem because the camera and object motions are mixed together and the objects are often detected into the separated components. To tackle this problem, we propose a fast moving object detection method using optical flow clustering and Delaunay triangulation as follows. First, we extract the corner feature points using Harris corner detector and compute optical flow vectors at the extracted corner feature points. Second, we cluster the optical flow vectors using K-means clustering method and reject the outlier feature points using Random Sample Consensus algorithm. Third, we classify each cluster into the camera and object motion using its scatteredness of optical flow vectors. Fourth, we compensate the camera motion using the multi-resolution block-based motion propagation method and detect the objects using the background subtraction between the previous frame and the motion compensated current frame. Finally, we merge the separately detected objects using Delaunay triangulation. The experimental results using Carnegie Mellon University database show that the proposed moving object detection method outperforms the existing other methods in terms of detection accuracy and processing time.
C1 [Kim, Jiman; Wang, Hai; Kim, Daijin] Pohang Univ Sci & Technol, Pohang, South Korea.
   [Wang, Xiaofei] Seoul Natl Univ, Sch Comp Sci & Engn, Seoul, South Korea.
   [Zhu, Chunsheng] St Francis Xavier Univ, Dept Comp Sci, Antigonish, NS B2G 2W5, Canada.
C3 Pohang University of Science & Technology (POSTECH); Seoul National
   University (SNU); Saint Francis Xavier University - Canada
RP Kim, D (corresponding author), Pohang Univ Sci & Technol, Pohang, South Korea.
EM jmk@postech.ac.kr; dobby@mmlab.snu.ac.kr; haiwang@postech.ac.kr;
   chunsheng.tom.zhu@gmail.com; dkim@postech.ac.kr
RI Zhu, Chunsheng/P-2182-2019
OI Zhu, Chunsheng/0000-0001-8041-0197
FU MKE (The Ministry of Knowledge Economy), Korea
   [NIPA-2010-C7000-1001-0006]; National Research Foundation of Korea(NRF);
   Ministry of Education, Science and Technology [2011-0027953]
FX This work was supported by the MKE (The Ministry of Knowledge Economy),
   Korea, under the Core Technology Development for Breakthrough of Robot
   Vision Research support program supervised by the NIPA (National IT
   Industry Promotion Agency) (NIPA-2010-C7000-1001-0006). And this
   research was supported by Basic Science Research Program through the
   National Research Foundation of Korea(NRF) funded by the Ministry of
   Education, Science and Technology (No. 2011-0027953).
CR Bajpai N., 2010, Business Statistics
   Barnich O, 2009, INT CONF ACOUST SPEE, P945, DOI 10.1109/ICASSP.2009.4959741
   Bouguet J-Y, 1999, Pyramidal implementation of the Lucas Kanade feature tracker
   Chen Min., 2013, The Journal of Supercomputing, V65, P287, DOI DOI 10.1007/S11227-010-0475-2
   Duda R. O., 2000, PATTERN CLASSIFICATI
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   GUIBAS LJ, 1992, ALGORITHMICA, V7, P381, DOI 10.1007/BF01758770
   Han B, 2008, IEEE T PATTERN ANAL, V30, P1186, DOI 10.1109/TPAMI.2007.70771
   Hayman E, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P67
   Jin Y, 2008, P IEEE ICIP
   Ke Q, 2001, P IEEE CVPR 2001
   Li L, 2003, P ACMMM 2003
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Malik J., 2007, Computer Vision and Pattern Recognition, P1
   Mittal A, 2000, PROC CVPR IEEE, P160, DOI 10.1109/CVPR.2000.854767
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Ren XB, 2007, LECT NOTES COMPUT SC, V4681, P1240
   Ren Y, 2003, PATTERN RECOGN LETT, V24, P183, DOI 10.1016/S0167-8655(02)00210-6
   Sand P., 2006, Proc. CVPR'06, V2, P2195
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Schoenemann T., 2008, CVPR, P1
   Sheikh Y, 2009, IEEE I CONF COMP VIS, P1219, DOI 10.1109/ICCV.2009.5459334
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Tao H, 2002, IEEE T PATTERN ANAL, V24, P75, DOI 10.1109/34.982885
   Uemura H, 2008, P BMVC 2008
   Xiao JJ, 2005, IEEE T PATTERN ANAL, V27, P1644, DOI 10.1109/TPAMI.2005.202
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
NR 27
TC 16
Z9 23
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 1
BP 311
EP 335
DI 10.1007/s11042-012-1075-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 196PN
UT WOS:000322787800016
DA 2024-07-18
ER

PT J
AU Um, TW
   Kim, J
   Lee, HW
   Kim, SH
AF Um, Tai-Won
   Kim, Jinsul
   Lee, Hyun-Woo
   Kim, Seok-Hun
TI Dynamic resource control mechanism for multimedia overlay transport in
   NGN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Resource and admission control system; NGN multimedia service
AB This paper investigates a dynamic resource control mechanism to efficiently deliver NGN multimedia services while supporting quality of service (QoS) requirements and bandwidth flexibility in next generation networks (NGN). The proposed resource control aims to realize the dynamic and automatic setup and release of multimedia resource sessions across heterogeneous transport networks including IP, SONET/SDH, and WDM technologies. It can also provide not only low cost operations but also flexibility for multimedia resource control.
C1 [Um, Tai-Won; Lee, Hyun-Woo] Elect & Telecommun Res Inst, Broadcasting & Telecommun Convergence Res Lab, Taejon 305700, South Korea.
   [Kim, Jinsul] Korea Nazarene Univ, Dept Multimedia, Cheonan, Chungnam, South Korea.
   [Kim, Seok-Hun] Mokwon Univ, Dept Comp Engn, Taejon 302318, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   Mokwon University
RP Kim, SH (corresponding author), Mokwon Univ, Dept Comp Engn, Mokwon Gil 21, Taejon 302318, South Korea.
EM twum@etri.re.kr; jsworld@kornu.ac.kr; hwlee@etri.re.kr;
   vambition@paran.com
FU KCC/IITA [2009-S-018-01]; Korea Nazarene University
FX This work was supported by the IT R&D program of KCC/IITA
   [2009-S-018-01, Development of Open-IPTV Platform Technologies for IPTV
   Convergence Service and Content Sharing], and the research program of
   Korea Nazarene University.
CR [Anonymous], FUNCT REQ ARCH NEXT
   Architecture for the Automatically Switched Optical Network (ASON), 2001, ARCH AUT SWITCH OPT
   Choi JK, 2004, RESOURCE MA IN PRESS
   Haché L, 2000, IEEE COMMUN MAG, V38, P74, DOI 10.1109/35.883492
   *ITU T, 2006, RES ADM CONTR FUNCT
   *ITU T, 2008, DISTR RACF ARCH MPLS
   Ji P, 2003, ACM SIGCOMM COMP COM, V33, P251
   JONES JD, 2004, OIFUNI010R2
   Lehman T, 2007, 2007 HIGH-SPEED NETWORKS WORKSHOP, P67, DOI 10.1109/HSNW.2007.4290549
   Otto K-H, 2006, OIFTDMP010
   Ou CHS, 2006, IEEE ACM T NETWORK, V14, P218, DOI 10.1109/TNET.2005.863462
   Um TW, 2002, ETRI J, V24, P69, DOI 10.4218/etrij.02.0402.0201
   Vigoureux M, 2005, IEEE COMMUN MAG, V43, P44, DOI 10.1109/MCOM.2005.1470810
   Yamanaka N, 2004, IEICE T COMMUN, VE87B, P573
NR 14
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2013
VL 65
IS 2
BP 187
EP 199
DI 10.1007/s11042-011-0778-1
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 141EJ
UT WOS:000318708100002
DA 2024-07-18
ER

PT J
AU Mejdoub, M
   Ben Amar, C
AF Mejdoub, Mahmoud
   Ben Amar, Chokri
TI Classification improvement of local feature vectors over the KNN
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature vectors; Categorization; Indexing; Wavelets; Lattice vector
   quantization; Semantic
AB The KNN classification algorithm is particularly suited to be used when classifying images described by local features. In this paper, we propose a novel image classification approach, based on local descriptors and the KNN algorithm. The proposed scheme is based on a hierarchical categorization tree that uses both supervised and unsupervised classification techniques. The unsupervised one is based on a hierarchical lattice vector quantization algorithm, while the supervised one is based on both feature vectors labelling and supervised feature selection method. The proposed tree improves the effectiveness of local feature vector classification and outperforms the exact KNN algorithm in terms of categorization accuracy.
C1 [Mejdoub, Mahmoud; Ben Amar, Chokri] Univ Sfax, Res Grp Intelligent Machines, ENIS, Sfax, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Mejdoub, M (corresponding author), Univ Sfax, Res Grp Intelligent Machines, ENIS, BP W 3038, Sfax, Tunisia.
EM mah.mejdoub@gmail.com; chokri.benamar@ieee.org
RI Chokri, BEN AMAR/K-5237-2012
OI Mejdoub, Mahmoud/0000-0002-9442-5784
CR Amato Giuseppe., 2010, Proceedings of the Third International Conference on SImilarity Search and APplications (New York, NY, USA), SISAP '10, P101
   [Anonymous], 2007, UCBCSD041366 CALTECH
   [Anonymous], 2007, MIR
   [Anonymous], INT C SIGN SYST DES
   [Anonymous], 2008, P 7 ACM INT C IMAGE
   Athitsos V, 2005, CVPR 05
   Ben Amar C, 2005, ADV ENG SOFTW, V36, P459, DOI 10.1016/j.advengsoft.2005.01.013
   Bouteldja N, 2006, 1 SPIE C MULT CONT A
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Garcia V., 2008, CVPR WORKSH COMP VIS
   Grira N, 2005, 7 ACM SIGMM INT WORK
   Kaski S., 1998, Neural Computing Surveys, V1
   Kimura A, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1895, DOI 10.1109/ICME.2004.1394629
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Mejdoub Mahmoud, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P1799
   Mejdoub M, 2007, INT C SIGN SYST DEV
   Mejdoub M, 2007, TRAITEMENT ANAL DIMA
   Mejdoub M, 2008, IEEE WORK CONT BAS M
   Mejdoub M, 2009, J VIS COMMUN IMAGE R, V20, P145, DOI 10.1016/j.jvcir.2008.12.003
   Mounira T, 2007, INT J COMPUT SCI, V3, P1544
   Moureaux JM, 1998, IEEE T COMMUN, V46, P1602, DOI 10.1109/26.737398
   Mouret M, 2009, INT WORK CONTENT MUL, P169, DOI 10.1109/CBMI.2009.22
   Piro P, 2009, ADV MULTIMEDIA MODEL
   Tao Y., 2010, INT MULT ENG COMP SC
   Todorovic S., 2006, CVPR
   van de Sande K.E. A., 2008, CIVR, P141, DOI DOI 10.1145/1386352.1386376
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Zhang H., 2006, 2006 IEEE COMP SOC C, V2, P2126, DOI DOI 10.1109/CVPR.2006.301
NR 28
TC 48
Z9 51
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 1
BP 197
EP 218
DI 10.1007/s11042-011-0900-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 114SU
UT WOS:000316763600010
DA 2024-07-18
ER

PT J
AU Lee, SH
   Kwon, KR
AF Lee, Suk-Hwan
   Kwon, Ki-Ryong
TI Vector watermarking scheme for GIS vector map management
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE GIS vector map; Digital watermarking; Copyright protection; GIS data
   management
AB A geographical information services (GIS) can be provided on the basis of a digital map, which is the fundamental form of representation of data in a GIS. Because the process of producing a digital map is considerably complex and the maintenance of a digital map requires substantial monetary and human resources, a digital map is very valuable and requires copyright protection. A digital map consists of a number of layers that are categorized in terms of topographical features and landmarks. Therefore, any unauthorized person can forge either an entire digital map or the feature layers of the map. In this paper, we present a robust and invisible watermarking scheme based on polylines and polygons for the copyright protection of a GIS digital map. The proposed scheme clusters all polylines and polygons in the feature layers of the map on the basis of the polyline length and the polygon area. And then a watermark is embedded in GIS vector data on the basis of the distribution of polyline length and polygon area in each group by moving all vertices in polylines and polygons within a specified tolerance. Experimental results confirm that the proposed scheme is more robust against geometric attacks, such as rotation, scaling, and translation (RST) transformations, data addition, cropping, breaking, and filleting attacks, and layer attacks with rearrangement and cropping, when compared with conventional schemes. Moreover, the scheme also satisfies data position accuracy.
C1 [Lee, Suk-Hwan] Tongmyong Univ, Dept Informat Secur, Pusan, South Korea.
   [Kwon, Ki-Ryong] Pukyong Natl Univ, Dept IT Convergence & Applicat Engn, Pusan, South Korea.
C3 Tongmyong University; Pukyong National University
RP Kwon, KR (corresponding author), Pukyong Natl Univ, Dept IT Convergence & Applicat Engn, Pusan, South Korea.
EM skylee@tu.ac.kr; krkwon@pknu.ac.kr
OI Lee, Suk-Hwan/0000-0003-4779-2888
FU Pukyong National University Research Abroad Fund [PS-2010-24]
FX This work was supported by the Pukyong National University Research
   Abroad Fund in 2011 (PS-2010-24).
CR Abolfathi M, 2012, TELECOMMUN SYST, V49, P171, DOI 10.1007/s11235-010-9366-3
   Airport Integrated Mapping System (AIMS), 2003, SJCACMAIMS2611
   [Anonymous], P WORKSH MULT SEC MM
   Bourke P., 2011, CALCULATING AREA CEN
   Buckey DJ, 2011, BGIS INTRO GIS
   Doncel VR, 2007, IEEE T VIS COMPUT GR, V13, P851, DOI 10.1109/TVCG.2007.1050
   Geographic Information Technology Training Alliance (GITTA), 2011, POS ACC
   Jia PH, 2006, CHINESE GEOGR SCI, V16, P276, DOI 10.1007/s11769-006-0276-y
   Jungyeop Kim, 2010, Proceedings of the 2010 Sixth International Conference on Networked Computing and Advanced Information Management (NCM 2010), P417
   KANG H, 2001, P 2001 WORKSH MULT S, P19
   Kim J.-S., 2011, 10 INT C ENV EL ENG, P1
   Kreyszig E., 1991, Differential Geometry. Differential Geometry
   Kumari BP, 2008, SIGNAL PROCESS, V88, P891, DOI 10.1016/j.sigpro.2007.10.009
   Lee SH, 2008, MULTIMEDIA SYST, V13, P323, DOI 10.1007/s00530-007-0095-8
   Lee SH, 2007, DIGIT SIGNAL PROCESS, V17, P396, DOI 10.1016/j.dsp.2005.04.014
   Lee SH, 2010, DIGIT SIGNAL PROCESS, V20, P1379, DOI 10.1016/j.dsp.2010.01.003
   Lopez C, 2002, INT J GEOGR INF SCI, V16, P589, DOI 10.1080/13658810210129148
   Luo JB, 2011, MULTIMED TOOLS APPL, V51, P187, DOI 10.1007/s11042-010-0623-y
   Niu XM, 2006, INT J INNOV COMPUT I, V2, P1301
   Ohbuchi R, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P577, DOI 10.1109/ICME.2002.1035847
   Ohbuchi R, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P216
   Park KT, 2002, LECT NOTES COMPUT SC, V2532, P58
   Sakamoto M., 2000, P S CRYPT INF SEC OK, P26
   Shao CY, 2006, IEICE T INF SYST, VE89D, P1290, DOI 10.1093/ietisy/e89-d.3.1290
   Solachidis V, 2004, IEEE COMPUT GRAPH, V24, P44, DOI 10.1109/MCG.2004.1297010
   Voigt M, 2002, P SOC PHOTO-OPT INS, V4675, P621, DOI 10.1117/12.465322
   Voigt M, 2003, P SOC PHOTO-OPT INS, V5020, P359, DOI 10.1117/12.476815
   Wang CJ, 2012, MULTIMED TOOLS APPL, V57, P67, DOI 10.1007/s11042-010-0536-9
   Yan HW, 2011, COMPUT ENVIRON URBAN, V35, P485, DOI 10.1016/j.compenvurbsys.2010.10.004
   Zafeiriou S, 2005, IEEE T VIS COMPUT GR, V11, P596, DOI 10.1109/TVCG.2005.71
   Zhang D, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL II, PROCEEDINGS, P469
   Zhang Lei, 2010, Wuhan University Journal of Natural Sciences, V15, P403, DOI 10.1007/s11859-010-0674-y
   ZHU CQ, 2008, INT ARCH PHOTOGRAMME, V37, P15
   Zimmer R, 2002, PROF SURV, V22
NR 34
TC 42
Z9 55
U1 0
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2013
VL 63
IS 3
BP 757
EP 790
DI 10.1007/s11042-011-0894-y
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 110YF
UT WOS:000316483000008
DA 2024-07-18
ER

PT J
AU Lee, YH
   Kim, SS
   Park, SI
   Park, JH
AF Lee, Yong Hee
   Kim, Soon Seok
   Park, Sea Il
   Park, Jong Hyuk
TI Extraction of enhanced evoked potentials using wavelet filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wavelet transform; DSP; Evoked potential; Artefacts
AB In order to remove physiological artefacts and gain the improved evoked potentials, we propose a filtering method using the multi-resolution wavelet transform. The wavelet transform is repeatedly performed until all resolution levels are obtained. It decomposes the measured evoked potentials into scale coefficients corresponding to low frequency components and wavelet coefficients corresponding to high frequency components. In the wavelet domain, artefacts are dispersed mainly at the wavelet coefficients rather than the scaling coefficients. Thus, when the inverse wavelet transform is performed, this method shrinks the wavelet coefficients to reduce artefacts with shrinkage functions. By repeatedly performing the inverse wavelet transform, an evoked potential having the reduced artefacts and background noise is obtained. In this study, quantitative evaluation with simulation data and actual clinical data were conducted. As a result, characteristic peaks of evoked potential could be gained removing background EEG and artefacts using suggested shrinkage function. It was improved more than 0.2-1.6Db compared to the conventional averaging method. Also, the system for measuring and analyzing evoked potentials using DSP is implemented.
C1 [Lee, Yong Hee; Kim, Soon Seok] Halla Univ, Dept Comp Engn, Wonju, Kangwon Do, South Korea.
   [Park, Sea Il] Halla Univ, Grad Sch Informat Ind, Wonju, Kangwon Do, South Korea.
   [Park, Jong Hyuk] Seoul Natl Univ Technol, Dept Comp Sci & Engn, Seoul, South Korea.
RP Lee, YH (corresponding author), Halla Univ, Dept Comp Engn, San 66, Wonju, Kangwon Do, South Korea.
EM yhlee@halla.ac.kr; sskim@halla.ac.kr; sipark@halla.ac.kr;
   jhpark1@snut.ac.kr
FU Ministry of Education, Science Technology (MEST); National Research
   Foundation of Korea(NRF) through the Human Resource Training Project for
   Regional Innovation
FX This research was financially supported by the Ministry of Education,
   Science Technology (MEST) and National Research Foundation of Korea(NRF)
   through the Human Resource Training Project for Regional Innovation.
CR Bischoff B, 2008, J NEUROLOGY NEUROSUR, V79
   Burton D, 2005, P ANN INT C, V27
   Cohen A, 1996, IEEE P, V84
   Davila CE, 1994, IEEE T BIOMED ENG, V41
   Donoho DL, 1995, IEEE T INFORM THEORY, V41
   Erdol N, 1996, IEEE T SIGNAL PROCES, V44
   Gong N, 1995, P ANN INT C, V17
   Herley C, 1994, IEEE T SIGNAL PROCES, V42
   Itakura T, 2008, CLIN NEUROPHYSIOLOGY, V119
   Jerbi K., 2010, J CONVERGENCE, V1, P85
   Kisilev P, 1999, P ANN INT C, V1
   Kong X, 1996, IEEE T BIOMED ENG, V43
   Li Z, 2005, P ANN INT C, V27
   Mirceva G, 2010, J CONVERGENCE, V1, P57
   Misulis KE, 1994, SPEHLMNNS EVOKED POT
   Parsa V, 1998, IEEE T BIOMEDICAL EN, V45
   Ranta-aho PO, 2003, IEEE T BIOMEDICAL EN, V50
   Sathappan O. L., 2011, International Journal of Information Technology, Communications and Convergence, V1, P146, DOI 10.1504/IJITCC.2011.039282
   Stecker MM, 2005, IEEE T BIOMEDICAL EN, V52
   Thakor NV, 1993, IEEE T BIOMED ENG, V40
   Tobimatsu S, 1996, ELECTROENCEPHALOGRAM, V100
   Unser M, 1996, IEEE P, V84
   Valeriani M., 2006, CLIN NEUROPHYSIOL, V59, P223
   Ye Y, 2009, INT J INF TECHNOL CO, V1, P206
   Yeganeh P, 2001, P ANN INT C, V23
   Zeng Y, 2007, J MED ENG TECHNOLOGY, V31
NR 26
TC 2
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 1
BP 45
EP 61
DI 10.1007/s11042-012-1031-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105KY
UT WOS:000316069400004
DA 2024-07-18
ER

PT J
AU Mannens, E
   Coppens, S
   De Pessemier, T
   Dacquin, H
   Van Deursen, D
   De Sutter, R
   Van de Walle, R
AF Mannens, Erik
   Coppens, Sam
   De Pessemier, Toon
   Dacquin, Hendrik
   Van Deursen, Davy
   De Sutter, Robbie
   Van de Walle, Rik
TI Automatic news recommendations via aggregated profiling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE News modelling; Profiling; Recommendation
AB Today, people have only limited, valuable leisure time at their hands which they want to fill in as good as possible according to their own interests, whereas broadcasters want to produce and distribute news items as fast and targeted as possible. These (developing) news stories can be characterised as dynamic, chained, and distributed events in addition to which it is important to aggregate, link, enrich, recommend, and distribute these news event items as targeted as possible to the individual, interested user. In this paper, we show how personalised recommendation and distribution of news events, described using an RDF/OWL representation of the NewsML-G2 standard, can be enabled by automatically categorising and enriching news events metadata via smart indexing and linked open datasets available on the web of data. The recommendations-based on a global, aggregated profile, which also takes into account the (dis)likings of peer friends-are finally fed to the user via a personalised RSS feed. As such, the ultimate goal is to provide an open, user-friendly recommendation platform that harnesses the end-user with a tool to access useful news event information that goes beyond basic information retrieval. At the same time, we provide the (inter)national community with standardised mechanisms to describe/distribute news event and profile information.
C1 [Mannens, Erik; Coppens, Sam; Van Deursen, Davy; Van de Walle, Rik] Univ Ghent, IBBT, ELIS Multimedia Lab, B-9000 Ghent, Belgium.
   [Van Deursen, Davy] Univ Ghent, IBBT, Multimedia Lab, Res Grp, B-9000 Ghent, Belgium.
   [Van de Walle, Rik] Univ Ghent, Multimedia Lab, B-9000 Ghent, Belgium.
   [De Pessemier, Toon] Univ Ghent, IBBT, INTEC WiCa, B-9000 Ghent, Belgium.
   [De Pessemier, Toon] Univ Ghent, Wireless & Cable Res Grp, B-9000 Ghent, Belgium.
   [Dacquin, Hendrik; De Sutter, Robbie] VRT, VRT Medialab, Brussels, Belgium.
C3 Ghent University; Ghent University; Ghent University; Ghent University;
   Ghent University
RP Mannens, E (corresponding author), Univ Ghent, IBBT, ELIS Multimedia Lab, B-9000 Ghent, Belgium.
EM erik.mannens@ugent.be; sam.coppens@ugent.be; tdpessem@intec.ugent.be;
   hendrik.dacquin@vrt.be; davy.vandeursen@ugent.be;
   robbie.desutter@vrt.be; rik.vandewalle@ugent.be
OI Mannens, Erik/0000-0001-7946-4884
FU Ghent University; Interdisciplinary Institute for Broadband Technology
   (IBBT); Institute for the Promotion of Innovation by Science and
   Technology in Flanders (IWT); Fund for Scientific Research-Flanders
   (FWO-Flanders); European Union
FX The research activities as described in this paper were funded by Ghent
   University, the Interdisciplinary Institute for Broadband Technology
   (IBBT), the Institute for the Promotion of Innovation by Science and
   Technology in Flanders (IWT), the Fund for Scientific Research-Flanders
   (FWO-Flanders), and the European Union.
CR [Anonymous], 1999, P ACM SIGIR WORKSH R
   [Anonymous], 2003, 1449610 ISOIEC AVC
   Bizer C, 2009, INT J SEMANT WEB INF, V5, P1, DOI 10.4018/jswis.2009081901
   Breese J. S., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P43
   Burke R., 2007, The adaptive web: methods and strategies of web personalization, P377, DOI [10.1007/978-3-540-72079-9_12, DOI 10.1007/978-3-540-72079-9_12]
   Cornelis C., 2005, Proceedings of the Second Indian International Conference on Artificial Intelligence (IICAI-05), Pune, INDIA, P2231
   De Geyter M, 2008, SMPTE MOTION IMAG J, V8, P38
   De Sutter R, 2008, P INT BROADC C AMST, P158
   Foster D. P., 1998, AAAI WORKSH REC SYST, P114
   Good N, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P439
   Heckerman D, 2001, J MACH LEARN RES, V1, P49, DOI 10.1162/153244301753344614
   Herlocker JL, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P230, DOI 10.1145/312624.312682
   Huang Z, 2007, IEEE INTELL SYST, V22, P68, DOI 10.1109/MIS.2007.4338497
   International Press Telecommunications Council, 2009, NEWSML G2 SPEC VERS
   Iskold A, 2007, ART SCI BUSINESS REC
   Karypis G., 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P247, DOI 10.1145/502585.502627
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   Mannens E, 2009, P 10 INT WORKSH IM A, P61
   Mannens E, 2008, MULTIMEDIA SYST, V14, P359, DOI 10.1007/s00530-008-0138-9
   McGuinness D. L., 2004, OWL WEB ONTOLOGY LAN, DOI DOI 10.2004-03
   Mobasher B, 2004, LECT NOTES COMPUT SC, V3209, P57, DOI 10.1007/978-3-540-30123-3_4
   Mooney R. J., 2000, ACM 2000. Digital Libraries. Proceedings of the Fifth ACM Conference on Digital Libraries, P195, DOI 10.1145/336597.336662
   O'Reilly T., 2006, What Is Web 2.0: Design patterns and business models for the next generation of software
   Papagelis M, 2005, LECT NOTES COMPUT SC, V3477, P224
   Pazzani M. J., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P325
   POPESCUL A., 2001, P 17 C UNCERTAINTY A, P437
   Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121
   S Corcoran, 2009, USING SOCIAL APPL AD
   Sarwar B., 2000, EC'00. Proceedings of the 2nd ACM Conference on Electronic Commerce, P158, DOI 10.1145/352871.352887
   Sarwar B, 2000, APPL DIMENSIONALITY
   SMPTE, 2004, 377M SMPTE
   Troncy R, 2008, LECT NOTES COMPUT SC, V5318, P483, DOI 10.1007/978-3-540-88564-1_31
   Weng J, 2006, P 5 INT JOINT C AUT, P1260, DOI DOI 10.1145/1160633.1160860
NR 33
TC 6
Z9 6
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 2
BP 407
EP 425
DI 10.1007/s11042-011-0844-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105MH
UT WOS:000316074200006
OA Green Published
DA 2024-07-18
ER

PT J
AU Nandzik, J
   Litz, B
   Flores-Herr, N
   Löhden, A
   Konya, I
   Baum, D
   Bergholz, A
   Schönfuss, D
   Fey, C
   Osterhoff, J
   Waitelonis, J
   Sack, H
   Köhler, R
   Ndjiki-Nya, P
AF Nandzik, Jan
   Litz, Berenike
   Flores-Herr, Nicolas
   Loehden, Aenne
   Konya, Iuliu
   Baum, Doris
   Bergholz, Andre
   Schoenfuss, Dirk
   Fey, Christian
   Osterhoff, Johannes
   Waitelonis, Joerg
   Sack, Harald
   Koehler, Ralf
   Ndjiki-Nya, Patrick
TI CONTENTUS-technologies for next generation multimedia libraries
   Automatic multimedia processing for semantic search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic information extraction; Semantic Web; Workflow automation;
   Multimedia search and retrieval; Digital libraries; Content analysis
ID IMAGE; RETRIEVAL; VIDEO
AB An ever-growing amount of digitized content urges libraries and archives to integrate new media types from a large number of origins such as publishers, record labels and film archives, into their existing collections. This is a challenging task, since the multimedia content itself as well as the associated metadata is inherently heterogeneous-the different sources lead to different data structures, data quality and trustworthiness. This paper presents the contentus approach towards an automated media processing chain for cultural heritage organizations and content holders. Our workflow allows for unattended processing from media ingest to availability thorough our search and retrieval interface. We aim to provide a set of tools for the processing of digitized print media, audio/visual, speech and musical recordings. Media specific functionalities include quality control for digitization of still image and audio/visual media and restoration of the most common quality issues encountered with these media. Furthermore, the contentus tools include modules for content analysis like segmentation of printed, audio and audio/visual media, optical character recognition (OCR), speech-to-text transcription, speaker recognition and the extraction of musical features from audio recordings, all aimed at a textual representation of information inherent within the media assets. Once the information is extracted and transcribed in textual form, media independent processing modules offer extraction and disambiguation of named entities and text classification. All contentus modules are designed to be flexibly recombined within a scalable workflow environment using cloud computing techniques. In the next step analyzed media assets can be retrieved and consumed through a search interface using all available metadata. The search engine combines Semantic Web technologies for representing relations between the media and entities such as persons, locations and organizations with a full-text approach for searching within transcribed information gathered through the preceding processing steps. The contentus unified search interface integrates text, images, audio and audio/visual content. Queries can be narrowed and expanded in an exploratory manner, search results can be refined by disambiguating entities and topics. Further, semantic relationships become not only apparent, but can also be navigated.
C1 [Nandzik, Jan; Flores-Herr, Nicolas] Acosta Consult GmbH, D-60318 Frankfurt, Germany.
   [Litz, Berenike; Loehden, Aenne] Deutsch Natl Bibliothek, D-60322 Frankfurt, Germany.
   [Konya, Iuliu; Baum, Doris; Bergholz, Andre] Fraunhofer IAIS, Schloss Birlinghoven, D-53754 St Augustin, Germany.
   [Schoenfuss, Dirk] Mufin GmbH, Buro Dresden, D-01219 Dresden, Germany.
   [Fey, Christian] Inst Rundfunktech GmbH, Prod Syst TV, D-80939 Munich, Germany.
   [Osterhoff, Johannes; Waitelonis, Joerg; Sack, Harald] Hasso Plattner Inst Softwaresyst Tech GmbH, D-14482 Potsdam, Germany.
   [Koehler, Ralf] Deutsch Thomson OHG, Hanover Image Proc Lab, Technicolor Corp Res Div, D-30625 Hannover, Germany.
   [Ndjiki-Nya, Patrick] Heinrich Hertz Inst Nachrichtentech Berlin GmbH, Fraunhofer Inst Nachrichtentech, D-10587 Berlin, Germany.
C3 Technicolor SA; Fraunhofer Gesellschaft
RP Nandzik, J (corresponding author), Acosta Consult GmbH, Zeisselstr 15 HH, D-60318 Frankfurt, Germany.
EM jn@acosta-consult.de; b.litz@dnb.de; nf@acosta-consult.de;
   a.loehden@dnb.de; iuliu.vasile.konya@iais.fraunhofer.de;
   doris.baum@iais.fraunhofer.de; andre.bergholz@iais.fraunhofer.de;
   dschoenfuss@mufin.com; fey@irt.de;
   johannes.osterhoff@hpi.uni-potsdam.de;
   joerg.waitelonis@hpi.uni-potsdam.de; harald.sack@hpi.uni-potsdam.de;
   ralf.koehler@technicolor.com; patrick.ndjiki-nya@hhi.fraunhofer.de
OI Sack, Harald/0000-0001-7069-9804
FU German Federal Ministry of Economy and Technology [01MQ07003]
FX We would like to kindly thank Andreas Hess for initial input, Jan
   Hannemann for coordination and supporting of the review process and
   Klaus Bossert for review. The project CONTENTUS was funded by means of
   the German Federal Ministry of Economy and Technology under the
   promotional reference "01MQ07003".
CR Agius H, 2009, MULTIMED TOOLS APPL, V41, P375, DOI 10.1007/s11042-008-0238-8
   Amato G, 2008, P 12 EUR C DIG LIB A
   [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   [Anonymous], 2006, DEF N AR REL SEM WEB
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], ISCAS
   Antonacopoulos A., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1370, DOI 10.1109/ICDAR.2009.275
   Bartolini I., 2010, Proceedings of the 3rd International Workshop on Automated Information Extraction in Media Production, P57
   Baum D, 2009, P IEEE AUT SPEECH RE
   Baum D, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1695
   Benitez AB, 2007, J AM SOC INF SCI TEC, V58, P1377, DOI 10.1002/asi.20582
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Bossert K, 2010, P 76 IFLA GEN C ASS
   Breuel T, 2002, P WORKSH DOC AN SYST, V3697, P188
   Breuel TM, 2003, HIGH PERFORMANCE DOC
   Cheng SS, 2010, IEEE T AUDIO SPEECH, V18, P141, DOI 10.1109/TASL.2009.2024730
   Corda U, 2008, MULTIMEDIA SEMANTICS
   Dasiopoulou S, 2009, METADATA AND SEMANTICS, P113, DOI 10.1007/978-0-387-77745-0_11
   Dasiopoulou S, 2007, MPEG 7 SEMANTIC WEB
   Dasiopoulou S, 2011, LECT NOTES ARTIF INT, V6050, P196, DOI 10.1007/978-3-642-20795-2_8
   Ding H., 2005, Journal of Digital Information Management, V3, P71
   Doshkov D, 2009, P INT WORKSH IM AN M
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Gatos B, 2005, LECT NOTES COMPUT SC, V3686, P609
   GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867
   GUHA R, 2003, WWW 2003, P700, DOI DOI 10.1145/775152.775250
   Hannemann J., 2010, WORLD LIB INF C 2010
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jain AK, 1998, IEEE T PATTERN ANAL, V20, P294, DOI 10.1109/34.667886
   Kett J, 2010, P 1 DGI K SEM WEB LI, P67
   Khoshgoftaar T.M., 2009, ADV ARTIFICIAL INTEL, DOI [10.1155/2009/421425, DOI 10.1155/2009/421425]
   Kim Hg, 2005, COMMUNICATION
   Kohler J, 2010, P SPEAK LANG REC WOR
   Kompatsiaris Y., 2008, SEMANTIC MULTIMEDIA
   Konya Iuliu, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P738, DOI 10.1109/ICDAR.2009.105
   Kruk SR, 2009, SEMANTIC DIGITAL LIB, P163, DOI [10.1007/978-3-540-85434-0_12, DOI 10.1007/978-3-540-85434-0_12]
   Lafferty John, 2001, INT C MACH LEARN ICM
   Lindbloom B, 1994, DELTA E CIE 1994
   Müller S, 2009, IEEE IMAGE PROC, P89, DOI 10.1109/ICIP.2009.5414090
   Ndjiki-Nya P, 2011, EURASIP IMAGE UNPUB
   Ndjiki-Nya P, 2009, P IEEE INT C IM PROC
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Paliouras G, 2009, P 1 ESWC WORKSH IND
   Petersohn C, 2009, P IEEE INT C IM PROC
   Petersohn C, 2004, P TREC VID RETR EV W
   Pfeifer B, 2011, GEMEINSAME NORMDATEI
   Plu M, 2006, P 1 INT C SEM DIG ME
   Ratinov L., 2009, Proceedings of the 13th conference on computational natural language learning, P147
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Sack H, 2011, CEUR WORKSHOP P, V694
   Sack H, 2010, P 4 IEEE ICSC PITTSB
   Schon J, 2008, P ACM SIGIR WORKSH S
   Schroeter B, 2010, MPEG2010M17744 ISOIE
   Smith K, 2006, CAPTURING ANALOG SOU
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   Snoek CGM, 2010, COMPUTER, V43, P76, DOI 10.1109/MC.2010.183
   Staab S, 2006, LECT NOTES COMPUTER, V4306, DOI [10.1007/11930334, DOI 10.1007/11930334]
   Tritschler A., 1999, Proceedings of Eurospeech
   Tsinaraki C, 2007, MULTIMEDIA SYST, V13, P131, DOI 10.1007/s00530-007-0091-z
   Ulges A, 2008, LECT NOTES COMPUT SC, V5008, P415
   Witten Ian H, 2009, BUILD DIGITAL LIB
   Worring M, 2007, IEEE T MULTIMEDIA, V9, P909, DOI 10.1109/TMM.2007.898913
   Wu L., 2008, P ACM INT C MULTIMED, P31, DOI DOI 10.1145/1459359.1459364
   Yan R, 2007, INFORM RETRIEVAL, V10, P445, DOI 10.1007/s10791-007-9031-y
   Yefeng Zheng, 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P699, DOI 10.1109/ICDAR.2001.953880
NR 65
TC 5
Z9 5
U1 0
U2 64
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 2
BP 287
EP 329
DI 10.1007/s11042-011-0971-2
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105MH
UT WOS:000316074200002
DA 2024-07-18
ER

PT J
AU Oh, JM
   Moon, N
AF Oh, Jung-Min
   Moon, NamMee
TI Towards a cultural user interface generation principles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cultural user interface; User interface generation; CTT; MB-UID;
   Cultural dimensions model; Cultural markers; Culture centered design
ID DESIGN; FRAMEWORK; COLOR; MODEL; HCI
AB As ubiquitous computing, and pervasive computing technology are being applied rapidly to the service industry, in the field of HCI, more complex and in-depth research are required at the moment. The efforts to make user experience more valuable using useful multimedia technologies around us, are being made in various parts of the world. In addition to this, generation studies for developing easier and faster UI are being conducted in the field of UI. Until now, the studies have been focused on generation studies using UI pattern models, but smart UI generation development, considering the cultural environment of users, is required. The purpose of this study is to suggest 3-D integrated design principles of modeling, design, and system for the design of cultural user interface generation reflecting the users' potential culture models. For this, a CTT model was designed based on MB-UID; and a cultural UI generation system architecture was designed by using cultural dimension models and cultural markers. To analyze the cultural factors, CISC (Cultural Index Score for Country) was derived in the process of culture profiling. Then, to verify the design model, culture UI was implemented, targeting the category UI of smartphone app stores.
C1 [Oh, Jung-Min; Moon, NamMee] Hoseo Univ Seoul, Dept IT App Tech GSV, Seoul, South Korea.
C3 Hoseo University
RP Moon, N (corresponding author), Hoseo Univ Seoul, Dept IT App Tech GSV, Seoul, South Korea.
EM mnm@hoseo.edu
CR [Anonymous], 2010, MOD BAS UI M 2 NOV L
   Badre AN, 2001, GITGVU01032000, P1
   Bamasak Omaima, 2011, International Journal of Information Technology, Communications and Convergence, V1, P173, DOI 10.1504/IJITCC.2011.039284
   Barber W., 1998, Proceedings of the 4th Conference on Human Factors and the Web, P1
   Budinsky FJ, 1996, IBM SYST J, V35, P151, DOI 10.1147/sj.352.0151
   Byeon J, 2011, J INF PROCESS SYST, V7, P355, DOI 10.3745/JIPS.2011.7.2.355
   Calvary G, 2003, INTERACT COMPUT, V15, P289, DOI 10.1016/S0953-5438(03)00010-9
   Cyr D, 2004, J AM SOC INF SCI TEC, V55, P1199, DOI 10.1002/asi.20075
   Daniel F, 2007, IEEE INTERNET COMPUT, V11, P59, DOI 10.1109/MIC.2007.74
   Deng J., 2005, CHINZ '05: Proceedings of the 6th ACM SIGCHI New Zealand Chapter's International Conference on Computer-Human Interaction, P31, DOI DOI 10.1145/1073943.1073951
   Fuchs C, 2010, FUTURE INTERNET, V2, P41, DOI 10.3390/fi2010041
   Fuchs C, 2010, INT J HUM-COMPUT INT, V26, P638, DOI 10.1080/10447311003781334
   Gao XP, 2007, COLOR RES APPL, V32, P223, DOI 10.1002/col.20321
   Green J, 2005, I DES STRAT C MAY
   Hochheiser H, 2007, INT J HUM-COMPUT INT, V23, P339, DOI 10.1080/10447310701702717
   HOFSTEDE G., 1980, MOTIVATION LEADERSHI
   Hofstede G., 2010, CULTURES ORG SOFTWAR
   Hofstede G., 1991, Cultures and organizations, DOI DOI 10.1016/S0005-7967(02)00184-5
   IBM, US EXP STRAT
   Jerbi K., 2010, J CONVERGENCE, V1, P85
   Jesse James Garrett JJ, 2002, ELEMENTS USER EXPERI, P22
   Juric R, 2003, ITI 2003: PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY INTERFACES, P309, DOI 10.1109/ITI.2003.1225362
   Kennard R, 2010, J SYST SOFTWARE, V83, P1896, DOI 10.1016/j.jss.2010.05.079
   Kim JH, 2003, J KOREAN SOC DESIGN, V16, P162
   Klyuev Vitaly, 2011, International Journal of Information Technology, Communications and Convergence, V1, P221, DOI 10.1504/IJITCC.2011.039287
   Kondratoca I, 2005, P EDMEDIA 2005 WORLD, P1255
   Kondratova I, 2007, LECT NOTES COMPUT SC, V4560, P123
   Kondratova I, 2006, LECT NOTES COMPUT SC, V4277, P926
   Landay JA, 1993, APP P 4 WORKSH WORKS, P1
   Limbourg Q., 2001, Interactive Systems: Design, Specification, and Verification, V2220, P164
   Lo B.W., 2005, Issues in Information Systems, V6, P182
   Martinez-Ruiz FJ, 2008, ICWE 2008 WORKSH
   McCandless D, 2009, COLOURS CULTURES INF
   오정민, 2010, [Journal of The Korea Society of Computer and Information, 한국컴퓨터정보학회논문지], V15, P45
   Morville P., 2004, USER EXPERIENCE DESI
   Myers B., 2000, ACM Transactions on Computer-Human Interaction, V7, P3, DOI 10.1145/344949.344959
   Myers B.A., 1995, ACM T COMPUT-HUM INT, V2, P64, DOI [10.1145/200968.200971, DOI 10.1145/200968.200971]
   Oh JM, 2008, THESIS SEOUL U VENTU
   Oh JM, 2011, J INF PROCESS SYST, V7, P209, DOI 10.3745/JIPS.2011.7.1.209
   Pyshkin E, 2010, J CONVERG, V1, P1
   Raffl C, 2009, WEB TECHNOSOCIAL SYS
   Saffer D., 2010, Designing for Interaction: Design Research
   Schramm A, 2010, LECT NOTES COMPUT SC, V6394, P271
   Schwartz S. H., 1994, Individualism and collectivism: Theory, method, and applications, P85
   Schwartz SH, 1999, APPL PSYCHOL-INT REV, V48, P23, DOI 10.1080/026999499377655
   Seunghun Y, 2008, KSDS, V21, P81
   Shen ST, 2006, INTERACT COMPUT, V18, P820, DOI 10.1016/j.intcom.2005.11.014
   Smith A, 2004, INTERACT COMPUT, V16, P63, DOI 10.1016/j.intcom.2003.11.005
   Sun H., 2001, ACM SPECIAL INTEREST, P95
NR 49
TC 5
Z9 8
U1 1
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 1
BP 195
EP 216
DI 10.1007/s11042-012-1017-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 105KY
UT WOS:000316069400013
DA 2024-07-18
ER

PT J
AU Pinheiro, B
   Nascimento, V
   Lopes, R
   Cerqueira, E
   Abelem, A
AF Pinheiro, Billy
   Nascimento, Vagner
   Lopes, Rafael
   Cerqueira, Eduardo
   Abelem, Antonio
TI A fuzzy queue-aware routing approach for wireless mesh networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless Mesh Networks; QoE; QoS; Multimedia
AB Recent advances in Wireless Mesh Networks (WMNs) have overcome the drawbacks of traditional wired and ad-hoc networks and now they are seen as a means of allowing last mile communications with quality level assurance in Future Multimedia Systems. However, new routing schemes are needed to provide end-to-end Quality of Service (QoS) and Quality of Experience (QoE) support for delay/loss/jitter-sensitive multimedia applications. The well-known OLSR (Optimized Link State Routing) protocol with ETX (Expected Transmission Count) metric brings many benefits to the path selection process, but has a drawback with regard to queue availability management, which reduces the system performance. This problem is caused when OLSR-EXT control messages are exchanged and the queues of mesh routers along the end-to-end communication path are overloaded. As a result, multimedia-related packets will suffer from loss/delay/jitter and the overall system performance will decrease. This paper proposes the Optimized Link State Routing-Fuzzy ETX Queue (OLSR-FEQ) protocol to overcome the limitations of OLSR-ETX regarding queue availability, QoS and QoE assurance. OLSR-FEQ optimizes network and user-based parameters by coordinating queue availability, QoS and fuzzy issues in the routing decision process as a way of allocating the best paths for multimedia applications. Performance evaluations were carried out with the Network Simulator (NS-2.34) to show the benefits of the proposed solution when compared with existing routing schemes, namely OLSR-ETX, OLSR-FLC, OLSR-MD and HWMP (IEEE 802.11s standard), regarding QoS (unsuccessful packet delivery and throughput) and QoE (PSNR, SSIM, VQM and MOS) parameters.
C1 [Pinheiro, Billy; Nascimento, Vagner; Cerqueira, Eduardo; Abelem, Antonio] Fed Univ Para, BR-66075110 Belem, Para, Brazil.
   [Lopes, Rafael] Univ Estadual Campinas, BR-13083852 Campinas, SP, Brazil.
C3 Universidade Federal do Para; Universidade Estadual de Campinas
RP Pinheiro, B (corresponding author), Fed Univ Para, Augusto Correa 01,Caixa postal 479, BR-66075110 Belem, Para, Brazil.
EM billy@ufpa.br; vagner@ufpa.br; rafaellgom@lrc.ic.unicamp.br;
   cerqueira@ufpa.br; abelem@ufpa.br
RI Cerqueira, Eduardo/HPC-8703-2023; Pinheiro, Billy/AAE-5872-2020; Gomes
   Abelem, Antonio Jorge/L-9678-2014
OI Cerqueira, Eduardo/0000-0003-2162-6523; Gomes Abelem, Antonio
   Jorge/0000-0003-4085-6674
FU Para State Government (Brazil); FAPESPA; UFPA; REDE TIC; CNPq
FX The authors would like to thank the Para State Government (Brazil),
   FAPESPA, UFPA, REDE TIC, and CNPq for sponsoring this research study.
CR [Anonymous], 3626 RFC
   [Anonymous], 2016, IEEE Standard 802.11-2020
   [Anonymous], INF SCI ENG ICISE 20
   [Anonymous], 2011, NETWORK SIMULATOR NS
   [Anonymous], 26 BRAZ S COMP NETW
   [Anonymous], P INT C WIR WIR INT
   [Anonymous], P IASTED INT C INT S
   [Anonymous], 2003, PROC 9 ANN INT C MO, DOI DOI 10.1145/938985.939000
   Balam J, 2007, IEEE T MULTIMEDIA, V9, P1073, DOI 10.1109/TMM.2007.898945
   Bruno R, 2009, MSWIM09; PROCEEDINGS OF THE 12TH ACM INTERNATIONAL CONFERENCE ON MODELING, ANALYSIS, AND SYSTEMS, P73
   Cordeiro W, 2007, IEEE IC COMP COM NET, P991
   Dely Peter, 2010, Proceedings of the 2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2010), P778, DOI 10.1109/FSKD.2010.5569346
   Gomes R, 2010, LECT NOTES COMPUT SC, V6157, P1, DOI 10.1007/978-3-642-13789-1_1
   MAMDANI EH, 1975, INT J MAN MACH STUD, V7, P1, DOI 10.1016/S0020-7373(75)80002-2
   Sgora A, 2009, L N INST COMP SCI SO, V13, P263
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   Yan H, 2010, INFOCOM IEEE C COMPU, P1
   ZADEH LA, 1965, INF CONTROL, V8
NR 18
TC 1
Z9 1
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2012
VL 61
IS 3
BP 747
EP 768
DI 10.1007/s11042-011-0933-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 021CA
UT WOS:000309861700012
DA 2024-07-18
ER

PT J
AU Ke, X
   Li, SZ
   Cao, DL
AF Ke, Xiao
   Li, Shaozi
   Cao, Donglin
TI A two-level model for automatic image annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic image annotation; Hierarchical annotation model; Expansion of
   relevant images; Semantics expansion
AB Image automatic annotation is a significant and challenging problem in pattern recognition and computer vision. Current image annotation models almost used all the training images to estimate joint generation probabilities between images and keywords, which would inevitably bring a lot of irrelevant images. To solve the above problem, we propose a hierarchical image annotation model which combines advantages of discriminative model and generative model. In first annotation layer, discriminative model is used to assign topic annotations to unlabeled images, and then relevant image set corresponding to each unlabeled image is obtained. In second annotation layer, we propose a keywords-oriented method to establish links between images and keywords, and then our iterative algorithm is used to expand relevant image sets. Candidate labels will be given higher weights by using our method based on visual keywords. Finally, generative model is used to assign detailed annotations to unlabeled images on expanded relevant image sets. Experiments conducted on Corel 5K datasets verify the effectiveness of our hierarchical image annotation model.
C1 [Ke, Xiao; Li, Shaozi; Cao, Donglin] Xiamen Univ, Dept Cognit Sci, Fujian Key Lab Brain Like Intelligent Syst, Xiamen, Peoples R China.
C3 Xiamen University
RP Ke, X (corresponding author), Xiamen Univ, Dept Cognit Sci, Fujian Key Lab Brain Like Intelligent Syst, Xiamen, Peoples R China.
EM kevinkexiao@sina.com
RI Li, SZ/G-3959-2010
FU National Natural Science Foundation of China [60873179, 60803078];
   Research Fund for the Doctoral Program of Higher Education of China
   [20090121110032]; Shenzhen Municipal Science and Technology Planning
   Program for Basic Research of China [JC200903180630A]
FX This work is partially supported by National Natural Science Foundation
   of China (No. 60873179, No. 60803078), Research Fund for the Doctoral
   Program of Higher Education of China (No. 20090121110032) and Shenzhen
   Municipal Science and Technology Planning Program for Basic Research of
   China (No. JC200903180630A). The authors also gratefully acknowledge the
   helpful comments and suggestions of the reviewers, which have improved
   the paper.
CR Andriluka M., 2008, P IEEE C COMPUTER VI
   [Anonymous], P ADV NEUTR INF PROC
   [Anonymous], P ACM SIGMM WORKSH M
   [Anonymous], 2009, CURR DIR PSYCHOL SCI
   Barrat Sabine, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1201, DOI 10.1109/ICDAR.2009.170
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Chang C., 2010, LIBSVM: A library for support vector machines 2010
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Jeon J., 2003, P 26 ANN INT ACM SIG
   Kang F., 2006, CVPR, V2, P1719
   Lindstaedt S, 2009, MULTIMED TOOLS APPL, V42, P97, DOI 10.1007/s11042-008-0247-7
   Mutch J, 2008, INT J COMPUT VISION, V80, P45, DOI 10.1007/s11263-007-0118-0
   Qi XJ, 2007, PATTERN RECOGN, V40, P728, DOI 10.1016/j.patcog.2006.04.042
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Wang Y, 2009, PATTERN RECOGN, V42, P259, DOI 10.1016/j.patcog.2008.05.010
   Zhao YF, 2009, EXPERT SYST APPL, V36, P9813, DOI 10.1016/j.eswa.2009.02.050
NR 19
TC 4
Z9 5
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2012
VL 61
IS 1
BP 195
EP 212
DI 10.1007/s11042-010-0706-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 973FP
UT WOS:000306345000012
DA 2024-07-18
ER

PT J
AU Wang, CT
   Yu, HF
AF Wang, Cheng-Tzu
   Yu, Hsiang-Fu
TI High-capacity reversible data hiding based on multi-histogram
   modification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Watermarking; Lossless
ID DIFFERENCE EXPANSION; IMAGE; SCHEME; VIDEO
AB Reversible data hiding is a technique that embeds a message into a host image with acceptable visual distortion and then recovers the image without any data loss while extracting the embedded message. The previous schemes mainly suffer from an unresolved problem that the imperceptibility of a marked image decreases severely as the embedding capacity increases. Extending the histogram modification technique, this study proposes a novel scheme that utilizes multiple histograms to increase embedding capacity while keeping marked-image quality. Unlike most histogram modification schemes, the multi-histogram scheme does not suffer from overflow and underflow during histogram shift. This scheme can yield the embedding capacity of 1 bit per pixel (bpp) at the PSNR of 48.13 db for a 512 x 512 grayscale image. To reduce the overhead during message embedding, the work further proposes an iterative multi-histogram scheme. Comprehensive experimental results show that both the schemes can achieve high embedding capacity and image quality.
C1 [Wang, Cheng-Tzu; Yu, Hsiang-Fu] Natl Taipei Univ Educ, Dept Comp Sci, Taipei, Taiwan.
C3 National Taipei University of Education
RP Yu, HF (corresponding author), Natl Taipei Univ Educ, Dept Comp Sci, Taipei, Taiwan.
EM yu@dslab.csie.ncu.edu.tw
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Fallahpour M, 2007, IEICE ELECTRON EXPR, V4, P205, DOI 10.1587/elex.4.205
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Fridrich J, 2001, P 4 INF HID WORKSH P, V2137, P27
   Horowitz E., 2007, Fundamentals of Data Structures in C++
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Hu YJ, 2008, IEEE T MULTIMEDIA, V10, P1500, DOI 10.1109/TMM.2008.2007341
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Lin CC, 2008, PATTERN RECOGN, V41, P1415, DOI 10.1016/j.patcog.2007.09.005
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, IET IMAGE PROCESS, V3, P100, DOI 10.1049/iet-ipr.2007.0220
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang X, 2007, IEEE T INF FOREN SEC, V2, P311, DOI 10.1109/TIFS.2007.902677
   Wang ZH, 2010, J SYST SOFTWARE, V83, P2073, DOI 10.1016/j.jss.2010.06.007
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P685, DOI 10.1109/TIP.2003.810588
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P696, DOI 10.1109/TIP.2003.810589
NR 24
TC 9
Z9 10
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2012
VL 61
IS 2
BP 299
EP 319
DI 10.1007/s11042-011-0838-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 985MK
UT WOS:000307270600003
DA 2024-07-18
ER

EF